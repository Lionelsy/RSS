<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 30 Apr 2025 14:15:18 +0800</lastBuildDate>
    <item>
      <title>Comments on the minimal training set for CNN: a case study of the frustrated $J_1$-$J_2$ Ising model on the square lattice</title>
      <link>http://arxiv.org/abs/2504.19795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  46 figures, 16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细探讨了训练工作CNN所需的最小训练集，并针对挫败的$J_1$-$J_2$伊辛模型在正方形格子上进行了研究。&lt;h4&gt;背景&lt;/h4&gt;考虑的模型是挫败的$J_1$-$J_2$伊辛模型，其中$J_1 &lt; 0$和$J_2 &gt; 0$分别是最近邻和次近邻耦合。&lt;h4&gt;目的&lt;/h4&gt;研究训练CNN所需的最小训练集，并利用训练好的CNN研究$g = 0.8$的相变。&lt;h4&gt;方法&lt;/h4&gt;使用$g = J_2/|J_1| = 0.7$的配置来训练CNN，并用训练好的CNN来研究$g = 0.8$的相变。发现转移学习是成功的，只需要两种温度下的配置（一个低于临界温度$T_c$，一个高于临界温度$T_c$）即可准确确定$g = 0.8$的$T_c$。&lt;h4&gt;主要发现&lt;/h4&gt;发现使用单个自旋翻转算法在低温区域采样配置时效率低下，因此训练集中关联的两个温度不应与$g = 0.7$的$T_c$相距太远，否则获得的CNN性能不高，无法准确确定$g = 0.8$的$T_c$。同时，揭示了只考虑两种温度配置作为训练集时训练成功CNN的条件。&lt;h4&gt;结论&lt;/h4&gt;通过转移学习，使用两种温度的配置即可准确确定$g = 0.8$的$T_c$，但需注意配置的温度不应与$g = 0.7$的$T_c$相差太远，以保证CNN的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The minimal training set to train a working CNN is explored in detail. Theconsidered model is the frustrated $J_1$-$J_2$ Ising model on the squarelattice. Here $J_1 &lt; 0$ and $J_2 &gt; 0$ are the nearest and next-to-nearestneighboring couplings, respectively. We train the CNN using the configurationsof $g \stackrel{\text{def}}{=} J_2/|J_1| = 0.7$ and employ the resulting CNN tostudy the phase transition of $g = 0.8$. We find that this transfer learning issuccessful. In particular, only configurations of two temperatures, one isbelow and one is above the critical temperature $T_c$ of $g=0.7$, are needed toreach accurately determination of the $T_c$ of $g=0.8$. However, it may besubtle to use this strategy for the training. Specifically, for the consideredmodel, due to the inefficiency of the single spin flip algorithm used insampling the configurations at the low-temperature region, the two temperaturesassociated with the training set should not be too far away from the $T_c$ of$g=0.7$, otherwise, the performance of the obtained CNN is not of high quality,hence cannot determine the $T_c$ of $g=0.8$ accurately. For the consideredmodel, we also uncover the condition for training a successful CNN when onlyconfigurations of two temperatures are considered as the training set.</description>
      <author>example@mail.com (Shang-Wei Li, Yuan-Heng Tseng, Ming-Che Hsieh, Fu-Jiun Jiang)</author>
      <guid isPermaLink="false">2504.19795v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
  <item>
      <title>ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery</title>
      <link>http://arxiv.org/abs/2504.19684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合生成域适应和高效对比学习的可扩展框架，以提升从低质量交通摄像头图像中准确分类天气的能力，特别是在夜间恶劣条件下。&lt;h4&gt;背景&lt;/h4&gt;准确从低质量交通摄像头图像中分类天气是一个具有挑战性的任务，尤其是在夜间不利条件下。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效提升夜间天气分类准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;使用基于CycleGAN的域转换技术提升夜间图像质量，结合SigLIP-2（Sigmoid对比损失）进行对比学习，以及结合Vision-SigLIP-2、Text-SigLIP-2、CycleGAN和对比训练。&lt;h4&gt;主要发现&lt;/h4&gt;使用CLIP对比损失的EVA-02模型在整体准确率上达到96.55%，但白天（97.21%）和夜间（63.40%）存在性能差距。替换CLIP为SigLIP-2后，整体准确率提升至94.00%，夜间准确率提高至85.90%。结合所有技术的模型在夜间准确率上达到85.90%，而EVA-02结合CycleGAN在整体准确率和每类准确率上保持最高（97.01%）。&lt;h4&gt;结论&lt;/h4&gt;域适应和高效对比学习结合的方法有望构建实用、资源高效的天气分类系统，适用于智能交通基础设施。&lt;h4&gt;翻译&lt;/h4&gt;Accurate weather classification from low-quality traffic camera imagery remains a challenging task, particularly under adverse nighttime conditions. In this study, we propose a scalable framework that combines generative domain adaptation with efficient contrastive learning to enhance classification performance. Using CycleGAN-based domain translation, we improve the quality of nighttime images, enabling better feature extraction by downstream models. While the baseline EVA-02 model employing CLIP-based contrastive loss achieves an overall accuracy of 96.55%, it exhibits a significant performance gap between daytime (97.21%) and nighttime conditions (63.40%). Replacing CLIP with the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitive overall accuracy of 94.00%, with substantial improvements in nighttime performance (85.90% accuracy). The combination of Vision-SigLIP-2, Text-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttime accuracy (85.90%) among all models tested, while EVA-02 with CycleGAN maintains the highest overall accuracy (97.01%) and per-class accuracies. These findings demonstrate the potential of combining domain adaptation and efficient contrastive learning to build practical, resource-efficient weather classification systems for intelligent transportation infrastructure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate weather classification from low-quality traffic camera imageryremains a challenging task, particularly under adverse nighttime conditions. Inthis study, we propose a scalable framework that combines generative domainadaptation with efficient contrastive learning to enhance classificationperformance. Using CycleGAN-based domain translation, we improve the quality ofnighttime images, enabling better feature extraction by downstream models.While the baseline EVA-02 model employing CLIP-based contrastive loss achievesan overall accuracy of 96.55\%, it exhibits a significant performance gapbetween daytime (97.21\%) and nighttime conditions (63.40\%). Replacing CLIPwith the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitiveoverall accuracy of 94.00\%, with substantial improvements in nighttimeperformance (85.90\% accuracy). The combination of Vision-SigLIP-2,Text-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttimeaccuracy (85.90\%) among all models tested, while EVA-02 with CycleGANmaintains the highest overall accuracy (97.01\%) and per-class accuracies.These findings demonstrate the potential of combining domain adaptation andefficient contrastive learning to build practical, resource-efficient weatherclassification systems for intelligent transportation infrastructure.</description>
      <author>example@mail.com (Anush Lakshman Sivaraman, Kojo Adu-Gyamfi, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2504.19684v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification</title>
      <link>http://arxiv.org/abs/2504.20930v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ChestX-Reasoner的放射学诊断多模态大型语言模型（MLLM），该模型通过利用从临床报告中挖掘的过程监督来增强推理能力，并提出了RadRBench-CXR基准和RadRScore评估指标，显著提升了诊断准确性和推理能力。&lt;h4&gt;背景&lt;/h4&gt;尽管推理增强的大型语言模型和多模态大型语言模型在复杂任务中的性能有了显著提升，但医疗AI模型往往忽略了临床实践中固有的结构化推理过程。&lt;h4&gt;目的&lt;/h4&gt;设计ChestX-Reasoner，以利用从临床报告中挖掘的过程监督，反映放射科医生逐步推理的过程。&lt;h4&gt;方法&lt;/h4&gt;通过从常规放射学报告中提取和细化推理链来构建大型数据集。采用两阶段训练框架，结合监督微调和由过程奖励引导的强化学习，以更好地使模型推理与临床标准对齐。&lt;h4&gt;主要发现&lt;/h4&gt;ChestX-Reasoner在诊断准确性和推理能力方面优于现有的医疗和通用领域MLLM，与最佳医疗MLLM、最佳通用MLLM及其基模型相比，推理能力分别提高了16%、5.9%和18%，在结果准确性方面分别提高了3.3%、24%和27%。&lt;h4&gt;结论&lt;/h4&gt;所有资源均已开源，以促进医疗推理MLLM的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces ChestX-Reasoner, a radiology diagnosis multimodal large language model (MLLM) designed to enhance reasoning capability by leveraging process supervision mined directly from clinical reports, and reflects the step-by-step reasoning followed by radiologists. We introduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual question answering samples with 301K clinically validated reasoning steps, and propose RadRScore, a metric evaluating reasoning factuality, completeness, and effectiveness. ChestX-Reasoner outperforms existing medical and general-domain MLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%, and 18% improvements in reasoning ability compared to the best medical MLLM, the best general MLLM, and its base model, respectively, as well as 3.3%, 24%, and 27% improvements in outcome accuracy. All resources are open-sourced to facilitate further research in medical reasoning MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in reasoning-enhanced large language models (LLMs) andmultimodal LLMs (MLLMs) have significantly improved performance in complextasks, yet medical AI models often overlook the structured reasoning processesinherent in clinical practice. In this work, we present ChestX-Reasoner, aradiology diagnosis MLLM designed to leverage process supervision mineddirectly from clinical reports, reflecting the step-by-step reasoning followedby radiologists. We construct a large dataset by extracting and refiningreasoning chains from routine radiology reports. Our two-stage trainingframework combines supervised fine-tuning and reinforcement learning guided byprocess rewards to better align model reasoning with clinical standards. Weintroduce RadRBench-CXR, a comprehensive benchmark featuring 59K visualquestion answering samples with 301K clinically validated reasoning steps, andpropose RadRScore, a metric evaluating reasoning factuality, completeness, andeffectiveness. ChestX-Reasoner outperforms existing medical and general-domainMLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%,and 18% improvements in reasoning ability compared to the best medical MLLM,the best general MLLM, and its base model, respectively, as well as 3.3%, 24%,and 27% improvements in outcome accuracy. All resources are open-sourced tofacilitate further research in medical reasoning MLLMs.</description>
      <author>example@mail.com (Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie)</author>
      <guid isPermaLink="false">2504.20930v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>CMT: A Cascade MAR with Topology Predictor for Multimodal Conditional CAD Generation</title>
      <link>http://arxiv.org/abs/2504.20830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CMT的CAD生成框架，用于解决现有CAD方法在复杂设计要求下的不足。同时，开发了一个大规模的多模态CAD数据集mmABC。&lt;h4&gt;背景&lt;/h4&gt;现有CAD方法在复杂设计要求下存在表现不足，原因在于其过于简化的表示或架构无法支持多模态设计需求。&lt;h4&gt;目的&lt;/h4&gt;通过改进方法和数据集来提高CAD生成的准确性和用户友好性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于边界表示（B-Rep）的多模态CAD生成框架CMT，包括拓扑预测器。同时，开发了一个包含超过130万个B-Rep模型的大规模数据集mmABC，包含点云、文本描述和多视角图像等多模态标注。&lt;h4&gt;主要发现&lt;/h4&gt;CMT在条件和无条件CAD生成任务中均表现出优越性。与现有方法相比，CMT在无条件的生成任务中提高了覆盖率和有效率的10.68%和10.3%，在mmABC上的图像条件CAD生成任务中Chamfer距离减少了4.01。&lt;h4&gt;结论&lt;/h4&gt;CMT框架和数据集mmABC能够显著提高CAD生成的质量和效率，并将相关资源（数据集、代码和预训练网络）公开。&lt;h4&gt;翻译&lt;/h4&gt;While accurate and user-friendly Computer-Aided Design (CAD) is crucial for industrial design and manufacturing, existing methods still struggle to achieve this due to their over-simplified representations or architectures incapable of supporting multimodal design requirements. In this paper, we attempt to tackle this problem from both methods and datasets aspects. First, we propose a cascade MAR with topology predictor (CMT), the first multimodal framework for CAD generation based on Boundary Representation (B-Rep). Specifically, the cascade MAR can effectively capture the 'edge-counters-surface' priors that are essential in B-Reps, while the topology predictor directly estimates topology in B-Reps from the compact tokens in MAR. Second, to facilitate large-scale training, we develop a large-scale multimodal CAD dataset, mmABC, which includes over 1.3 million B-Rep models with multimodal annotations, including point clouds, text descriptions, and multi-view images. Extensive experiments show the superior of CMT in both conditional and unconditional CAD generation tasks. For example, we improve Coverage and Valid ratio by +10.68% and +10.3%, respectively, compared to state-of-the-art methods on ABC in unconditional generation. CMT also improves +4.01 Chamfer on image conditioned CAD generation on mmABC. The dataset, code and pretrained network shall be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While accurate and user-friendly Computer-Aided Design (CAD) is crucial forindustrial design and manufacturing, existing methods still struggle to achievethis due to their over-simplified representations or architectures incapable ofsupporting multimodal design requirements. In this paper, we attempt to tacklethis problem from both methods and datasets aspects. First, we propose acascade MAR with topology predictor (CMT), the first multimodal framework forCAD generation based on Boundary Representation (B-Rep). Specifically, thecascade MAR can effectively capture the ``edge-counters-surface'' priors thatare essential in B-Reps, while the topology predictor directly estimatestopology in B-Reps from the compact tokens in MAR. Second, to facilitatelarge-scale training, we develop a large-scale multimodal CAD dataset, mmABC,which includes over 1.3 million B-Rep models with multimodal annotations,including point clouds, text descriptions, and multi-view images. Extensiveexperiments show the superior of CMT in both conditional and unconditional CADgeneration tasks. For example, we improve Coverage and Valid ratio by +10.68%and +10.3%, respectively, compared to state-of-the-art methods on ABC inunconditional generation. CMT also improves +4.01 Chamfer on image conditionedCAD generation on mmABC. The dataset, code and pretrained network shall bereleased.</description>
      <author>example@mail.com (Jianyu Wu, Yizhou Wang, Xiangyu Yue, Xinzhu Ma, Jingyang Guo, Dongzhan Zhou, Wanli Ouyang, Shixiang Tang)</author>
      <guid isPermaLink="false">2504.20830v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SAM-Guided Robust Representation Learning for One-Shot 3D Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.20501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RRL-MedSAM的新型框架，用于解决单次医学图像分割的问题，通过利用SAM编码器的泛化能力来学习更好的特征表示。&lt;h4&gt;背景&lt;/h4&gt;单次医学图像分割对于医学分析至关重要，但传统方法依赖于专家手动标注，且计算成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以适应单次3D医学图像分割，减少对专家标注的依赖和降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;1. 设计了RRL-MedSAM框架，利用SAM编码器的泛化能力。2. 采用双阶段知识蒸馏策略，从基础模型中提取自然和医学图像之间的通用知识。3. 使用互指数移动平均（mutual-EMA）更新通用轻量级编码器和医学特定编码器的权重。4. 引入自动提示（AP）分割解码器，利用通用轻量级模型生成的掩码来辅助医学特定模型。5. 使用伪标签进行互监督。&lt;h4&gt;主要发现&lt;/h4&gt;在OASIS、CT-lung等三个公开数据集上进行的实验表明，RRL-MedSAM在分割和配准任务上优于现有的单次医学图像分割方法。特别是，与SAM-Base的编码器相比，我们的轻量级编码器仅使用了3%的参数。&lt;h4&gt;结论&lt;/h4&gt;RRL-MedSAM框架能够有效提高单次医学图像分割的性能，同时减少计算资源的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One-shot medical image segmentation (MIS) is crucial for medical analysis dueto the burden of medical experts on manual annotation. The recent emergence ofthe segment anything model (SAM) has demonstrated remarkable adaptation in MISbut cannot be directly applied to one-shot medical image segmentation (MIS) dueto its reliance on labor-intensive user interactions and the high computationalcost. To cope with these limitations, we propose a novel SAM-guided robustrepresentation learning framework, named RRL-MedSAM, to adapt SAM to one-shot3D MIS, which exploits the strong generalization capabilities of the SAMencoder to learn better feature representation. We devise a dual-stageknowledge distillation (DSKD) strategy to distill general knowledge betweennatural and medical images from the foundation model to train a lightweightencoder, and then adopt a mutual exponential moving average (mutual-EMA) toupdate the weights of the general lightweight encoder and medical-specificencoder. Specifically, pseudo labels from the registration network are used toperform mutual supervision for such two encoders. Moreover, we introduce anauto-prompting (AP) segmentation decoder which adopts the mask generated fromthe general lightweight model as a prompt to assist the medical-specific modelin boosting the final segmentation performance. Extensive experiments conductedon three public datasets, i.e., OASIS, CT-lung demonstrate that the proposedRRL-MedSAM outperforms state-of-the-art one-shot MIS methods for bothsegmentation and registration tasks. Especially, our lightweight encoder usesonly 3\% of the parameters compared to the encoder of SAM-Base.</description>
      <author>example@mail.com (Jia Wang, Yunan Mei, Jiarui Liu, Xin Fan)</author>
      <guid isPermaLink="false">2504.20501v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual Explanations via Subgraph Matching for Malware Detection</title>
      <link>http://arxiv.org/abs/2504.20904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型双原型驱动的可解释框架，用于解释基于图神经网络（GNN）的恶意软件检测决策，在保持高检测性能的同时显著提高了恶意软件分析的可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统可解释方法在图神经网络中突出显示重要区域，但无法将它们与已知的良性或恶意行为模式关联起来，这在安全环境中限制了其效用。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以解释基于GNN的恶意软件检测决策，并提高其在安全环境中的可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的双可解释框架，该框架结合了基线解释器和一种名为SubMatch解释器的二级解释器。SubMatch解释器通过子图匹配技术为节点分配可解释的分数，从而在良性和恶意区域之间提供更精细的区别。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在保持高检测性能的同时，显著提高了恶意软件分析的可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为恶意软件分析提供了一种更加可解释、行为对齐的解释机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable malware detection is crucial for understanding harmfulbehaviors and building trust in automated security systems. Traditionalexplainable methods for Graph Neural Networks (GNNs) often highlight importantregions within a graph but fail to associate them with known benign ormalicious behavioral patterns. This limitation reduces their utility insecurity contexts, where alignment with verified prototypes is essential. Inthis work, we introduce a novel dual prototype-driven explainable frameworkthat interprets GNN-based malware detection decisions. This dual explainableframework integrates a base explainer (a state-of-the-art explainer) with anovel second-level explainer which is designed by subgraph matching technique,called SubMatch explainer. The proposed explainer assigns interpretable scoresto nodes based on their association with matched subgraphs, offering afine-grained distinction between benign and malicious regions. Thisprototype-guided scoring mechanism enables more interpretable, behavior-alignedexplanations. Experimental results demonstrate that our method preserves highdetection performance while significantly improving interpretability in malwareanalysis.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Roozbeh Razavi-Far, Griffin Higgins, Ali A. Ghorbani)</author>
      <guid isPermaLink="false">2504.20904v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.20869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Ubder Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于量化攻击强度的噪声概念，并提出基于此的攻击策略，通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络因其强大的学习能力被广泛应用于解决图相关任务，但近年来研究表明它们对恶意攻击不够鲁棒。&lt;h4&gt;目的&lt;/h4&gt;为了提高图神经网络的鲁棒性，本文旨在提出一种方法来量化攻击强度并选择合适的攻击策略。&lt;h4&gt;方法&lt;/h4&gt;本文提出了噪声的概念来量化每个对抗链接的攻击强度，并基于噪声和分类边界定义了三种攻击策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过在基准数据集上进行的实验，验证了所提出的攻击策略的有效性，并分析了有效对抗扰动节点的偏好模式。&lt;h4&gt;结论&lt;/h4&gt;本文提出的噪声概念和攻击策略能够有效提高图神经网络的鲁棒性，并提供了对抗扰动选择的可解释性。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks have been widely utilized to solve graph-related tasks because of their strong learning power in utilizing the local information of neighbors. However, recent studies on graph adversarial attacks have proved that current graph neural networks are not robust against malicious attacks. Yet much of the existing work has focused on the optimization objective based on attack performance to obtain (near) optimal perturbations, but paid less attention to the strength quantification of each perturbation such as the injection of a particular node/link, which makes the choice of perturbations a black-box model that lacks interpretability. In this work, we propose the concept of noise to quantify the attack strength of each adversarial link. Furthermore, we propose three attack strategies based on the defined noise and classification margins in terms of single and multiple steps optimization. Extensive experiments conducted on benchmark datasets against three representative graph neural networks demonstrate the effectiveness of the proposed attack strategies. Particularly, we also investigate the preferred patterns of effective adversarial perturbations by analyzing the corresponding properties of the selected perturbation nodes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been widely utilized to solve graph-related tasksbecause of their strong learning power in utilizing the local information ofneighbors. However, recent studies on graph adversarial attacks have proventhat current graph neural networks are not robust against malicious attacks.Yet much of the existing work has focused on the optimization objective basedon attack performance to obtain (near) optimal perturbations, but paid lessattention to the strength quantification of each perturbation such as theinjection of a particular node/link, which makes the choice of perturbations ablack-box model that lacks interpretability. In this work, we propose theconcept of noise to quantify the attack strength of each adversarial link.Furthermore, we propose three attack strategies based on the defined noise andclassification margins in terms of single and multiple steps optimization.Extensive experiments conducted on benchmark datasets against threerepresentative graph neural networks demonstrate the effectiveness of theproposed attack strategies. Particularly, we also investigate the preferredpatterns of effective adversarial perturbations by analyzing the correspondingproperties of the selected perturbation nodes.</description>
      <author>example@mail.com (Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse)</author>
      <guid isPermaLink="false">2504.20869v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability</title>
      <link>http://arxiv.org/abs/2504.20667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ILLUME的灵活且可解释的框架，用于理解黑盒机器学习模型，该框架可以与各种代理模型集成，提供对任何黑盒分类器的解释。&lt;h4&gt;背景&lt;/h4&gt;后验可解释性对于理解黑盒机器学习模型至关重要。基于代理的技术在局部和全局模型无关的解释中广泛使用，但存在显著局限性。&lt;h4&gt;目的&lt;/h4&gt;提出ILLUME框架，以提供准确、鲁棒且忠实于黑盒的特徵归因和决策规则，从而有效解决传统代理方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;ILLUME结合了一个全局训练的代理模型和通过元编码器学习的实例特定线性变换，以生成局部和全局解释。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实证评估，证明了ILLUME在生成特征归因和决策规则方面的有效性，这些规则不仅准确，而且鲁棒且忠实于黑盒。&lt;h4&gt;结论&lt;/h4&gt;ILLUME是一个统一的解释框架，能够有效解决传统代理方法的局限性，为理解黑盒机器学习模型提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Post-hoc explainability is essential for understanding black-box machinelearning models. Surrogate-based techniques are widely used for local andglobal model-agnostic explanations but have significant limitations. Localsurrogates capture non-linearities but are computationally expensive andsensitive to parameters, while global surrogates are more efficient butstruggle with complex local behaviors. In this paper, we present ILLUME, aflexible and interpretable framework grounded in representation learning, thatcan be integrated with various surrogate models to provide explanations for anyblack-box classifier. Specifically, our approach combines a globally trainedsurrogate with instance-specific linear transformations learned with ameta-encoder to generate both local and global explanations. Through extensiveempirical evaluations, we demonstrate the effectiveness of ILLUME in producingfeature attributions and decision rules that are not only accurate but alsorobust and faithful to the black-box, thus providing a unified explanationframework that effectively addresses the limitations of traditional surrogatemethods.</description>
      <author>example@mail.com (Simone Piaggesi, Riccardo Guidotti, Fosca Giannotti, Dino Pedreschi)</author>
      <guid isPermaLink="false">2504.20667v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DB-GNN: Dual-Branch Graph Neural Network with Multi-Level Contrastive Learning for Jointly Identifying Within- and Cross-Frequency Coupled Brain Networks</title>
      <link>http://arxiv.org/abs/2504.20744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种双重分支图神经网络（DB-GNN），用于联合识别脑网络中的频率内耦合（WFC）和跨频率耦合（CFC），并通过实验验证了其在情感识别任务中的高效性。&lt;h4&gt;背景&lt;/h4&gt;脑网络中的WFC和CFC分别反映了同一频率带内的神经同步和跨带振荡相互作用，它们的协同作用有助于理解认知状态如情感背后的神经机制。&lt;h4&gt;目的&lt;/h4&gt;提出DB-GNN以更全面地利用WFC和CFC的互补特性，从而更好地理解认知状态。&lt;h4&gt;方法&lt;/h4&gt;DB-GNN利用独特的双重分支学习架构来高效挖掘全局协作信息和局部跨频率及频率内耦合信息；采用Transformer架构来增强对全局信息的感知；通过整合先验的WFC和CFC信息来防止过拟合；引入多尺度图对比学习正则化项来增强全局和局部感知分支的联合感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，DB-GNN在情感识别数据集上实现了97.88%的测试准确率和97.87%的F1分数，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DB-GNN能够有效识别WFC和CFC，并显著提高情感识别任务的性能，为认知状态的理解提供了新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑网络中的频率内耦合（WFC）和跨频率耦合（CFC）分别反映了同一频率带内的神经同步和跨带振荡相互作用。它们的协同作用为理解认知状态（如情感）背后的神经机制提供了全面的视角。然而，现有的多通道脑电图（EEG）研究通常分别分析WFC或CFC，未能充分利用它们的互补特性。本研究提出了一种双重分支图神经网络（DB-GNN）来联合识别频率内和跨频率耦合的脑网络。首先，DB-GNN利用其独特的双重分支学习架构高效挖掘全局协作信息和局部跨频率及频率内耦合信息。其次，为了更全面地感知跨频率和频率内耦合的全局信息，DB-GNN的全局感知分支采用了Transformer架构。为了避免Transformer架构的过拟合，本研究将先验的WFC和CFC信息整合到Transformer推理过程中，从而增强了DB-GNN的泛化能力。最后，引入了多尺度图对比学习正则化项，以约束DB-GNN的全局和局部感知分支在图级别和节点级别，从而增强了其联合感知能力，并进一步提高了其泛化性能。在情感识别数据集上的实验验证表明，DB-GNN实现了97.88%的测试准确率和97.87%的F1分数，达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Within-frequency coupling (WFC) and cross-frequency coupling (CFC) in brainnetworks reflect neural synchronization within the same frequency band andcross-band oscillatory interactions, respectively. Their synergy provides acomprehensive understanding of neural mechanisms underlying cognitive statessuch as emotion. However, existing multi-channel EEG studies often analyze WFCor CFC separately, failing to fully leverage their complementary properties.This study proposes a dual-branch graph neural network (DB-GNN) to jointlyidentify within- and cross-frequency coupled brain networks. Firstly, DBGNNleverages its unique dual-branch learning architecture to efficiently mineglobal collaborative information and local cross-frequency and within-frequencycoupling information. Secondly, to more fully perceive the global informationof cross-frequency and within-frequency coupling, the global perception branchof DB-GNN adopts a Transformer architecture. To prevent overfitting of theTransformer architecture, this study integrates prior within- andcross-frequency coupling information into the Transformer inference process,thereby enhancing the generalization capability of DB-GNN. Finally, amulti-scale graph contrastive learning regularization term is introduced toconstrain the global and local perception branches of DB-GNN at bothgraph-level and node-level, enhancing its joint perception ability and furtherimproving its generalization performance. Experimental validation on theemotion recognition dataset shows that DB-GNN achieves a testing accuracy of97.88% and an F1- score of 97.87%, reaching the state-of-the-art performance.</description>
      <author>example@mail.com (Xiang Wang, Hui Xu, Jing Cai, Ta Zhou, Xibei Yang, Wei Xue)</author>
      <guid isPermaLink="false">2504.20744v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Autoencoder Models for Point Cloud Environmental Synthesis from WiFi Channel State Information: A Preliminary Study</title>
      <link>http://arxiv.org/abs/2504.20541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于深度学习的框架，用于从WiFi信道状态信息（CSI）数据生成点云。&lt;h4&gt;背景&lt;/h4&gt;研究背景为从无线信号数据中重建环境点云。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种方法，能够从WiFi数据中准确重建环境点云。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段自动编码器方法：使用具有卷积层的PointNet自动编码器进行点云生成，以及使用卷积神经网络自动编码器将CSI数据映射到匹配的潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法有效，突出了其在无线传感和环境制图应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法能够通过WiFi数据准确重建环境点云，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a deep learning framework for generating point clouds from WiFi Channel State Information data. We employ a two-stage autoencoder approach: a PointNet autoencoder with convolutional layers for point cloud generation, and a Convolutional Neural Network autoencoder to map CSI data to a matching latent space. By aligning these latent spaces, our method enables accurate environmental point cloud reconstruction from WiFi data. Experimental results validate the effectiveness of our approach, highlighting its potential for wireless sensing and environmental mapping applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a deep learning framework for generating point cloudsfrom WiFi Channel State Information data. We employ a two-stage autoencoderapproach: a PointNet autoencoder with convolutional layers for point cloudgeneration, and a Convolutional Neural Network autoencoder to map CSI data to amatching latent space. By aligning these latent spaces, our method enablesaccurate environmental point cloud reconstruction from WiFi data. Experimentalresults validate the effectiveness of our approach, highlighting its potentialfor wireless sensing and environmental mapping applications.</description>
      <author>example@mail.com (Daniele Pannone, Danilo Avola)</author>
      <guid isPermaLink="false">2504.20541v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.20464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于多模态大型语言模型（MLLMs）的图形用户界面（GUI）代理的最新进展进行了结构化总结，重点关注通过强化学习（RL）增强的架构。&lt;h4&gt;背景&lt;/h4&gt;GUI代理作为实现与数字系统智能交互的有前景的方法，近年来得到了快速发展。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对GUI代理领域最近进展的全面概述，特别是那些通过强化学习增强的架构。&lt;h4&gt;方法&lt;/h4&gt;首先，将GUI代理任务形式化为马尔可夫决策过程，并讨论了典型的执行环境和评估指标。接着，回顾了基于（M）LLM的GUI代理的模块化架构，包括感知、规划和行动模块，并追踪了它们的演变过程。此外，将GUI代理的训练方法分为基于提示、基于监督微调（SFT）和基于RL的方法，强调了从简单的提示工程到通过RL进行动态策略学习的进展。&lt;h4&gt;主要发现&lt;/h4&gt;本文说明了在多模态感知、决策推理和自适应动作生成方面的最新创新如何显著提高了GUI代理在复杂真实世界环境中的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;最后，本文确定了构建更强大和可靠的GUI代理的关键挑战和未来方向。&lt;h4&gt;翻译&lt;/h4&gt;Graphical User Interface (GUI) agents, driven by Multi-modal Large Language Models (MLLMs), have emerged as a promising paradigm for enabling intelligent interaction with digital systems. This paper provides a structured summary of recent advances in GUI agents, focusing on architectures enhanced by Reinforcement Learning (RL). We first formalize GUI agent tasks as Markov Decision Processes and discuss typical execution environments and evaluation metrics. We then review the modular architecture of (M)LLM-based GUI agents, covering Perception, Planning, and Acting modules, and trace their evolution through representative works. Furthermore, we categorize GUI agent training methodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and RL-based approaches, highlighting the progression from simple prompt engineering to dynamic policy learning via RL. Our summary illustrates how recent innovations in multimodal perception, decision reasoning, and adaptive action generation have significantly improved the generalization and robustness of GUI agents in complex real-world environments. We conclude by identifying key challenges and future directions for building more capable and reliable GUI agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphical User Interface (GUI) agents, driven by Multi-modal Large LanguageModels (MLLMs), have emerged as a promising paradigm for enabling intelligentinteraction with digital systems. This paper provides a structured summary ofrecent advances in GUI agents, focusing on architectures enhanced byReinforcement Learning (RL). We first formalize GUI agent tasks as MarkovDecision Processes and discuss typical execution environments and evaluationmetrics. We then review the modular architecture of (M)LLM-based GUI agents,covering Perception, Planning, and Acting modules, and trace their evolutionthrough representative works. Furthermore, we categorize GUI agent trainingmethodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, andRL-based approaches, highlighting the progression from simple promptengineering to dynamic policy learning via RL. Our summary illustrates howrecent innovations in multimodal perception, decision reasoning, and adaptiveaction generation have significantly improved the generalization and robustnessof GUI agents in complex real-world environments. We conclude by identifyingkey challenges and future directions for building more capable and reliable GUIagents.</description>
      <author>example@mail.com (Jiahao Li, Kaer Huang)</author>
      <guid isPermaLink="false">2504.20464v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features</title>
      <link>http://arxiv.org/abs/2504.20970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to IEEE International Workshop on Machine Learning  for Signal Processing (MLSP), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于奇异值分解的最小二乘法（SVD-LS）框架，用于多类肺炎分类，旨在通过高效的诊断工具辅助放射科医生做出更可靠和高效的决策。&lt;h4&gt;背景&lt;/h4&gt;准确且早期通过X光成像诊断肺炎对于有效治疗和改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的肺炎分类方法，以辅助放射科医生进行更准确的诊断。&lt;h4&gt;方法&lt;/h4&gt;利用最先进的自监督和迁移学习模型，采用闭式、非迭代的方法进行分类，避免了梯度优化的计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;SVD-LS在保持准确性的同时，显著降低了计算成本，在实验中表现出与现有方法相竞争的性能。&lt;h4&gt;结论&lt;/h4&gt;SVD-LS是一个可行的实时医学成像应用替代方案，能够提高肺炎诊断的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and early diagnosis of pneumonia through X-ray imaging is essentialfor effective treatment and improved patient outcomes. Recent advancements inmachine learning have enabled automated diagnostic tools that assistradiologists in making more reliable and efficient decisions. In this work, wepropose a Singular Value Decomposition-based Least Squares (SVD-LS) frameworkfor multi-class pneumonia classification, leveraging powerful featurerepresentations from state-of-the-art self-supervised and transfer learningmodels. Rather than relying on computationally expensive gradient basedfine-tuning, we employ a closed-form, non-iterative classification approachthat ensures efficiency without compromising accuracy. Experimental resultsdemonstrate that SVD-LS achieves competitive performance while offeringsignificantly reduced computational costs, making it a viable alternative forreal-time medical imaging applications.</description>
      <author>example@mail.com (Mete Erdogan, Sebnem Demirtas)</author>
      <guid isPermaLink="false">2504.20970v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.20384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FiLA-Video的轻量级视频理解框架，旨在解决长视频理解中的复杂性和处理限制问题。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉大语言模型（VLLMs）在视频理解方面取得了显著进展，但视频数据的复杂性和上下文处理限制仍然阻碍了长视频的理解。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的方法，即视频特征压缩，以减少大型语言模型的token输入，但许多方法要么未能优先考虑关键特征，导致冗余的帧间信息，要么引入了计算成本高的模块。&lt;h4&gt;方法&lt;/h4&gt;FiLA-Video采用了一种轻量级的动态权重多帧融合策略，自适应地将多个帧整合成一个单一表示，同时保留关键视频信息并降低计算成本。为了提高融合中的帧选择，引入了一种关键帧选择策略，有效地从更大的帧池中识别出信息丰富的帧，以改善总结。此外，还提出了一种简单而有效的长视频训练数据生成策略，无需大量手动标注即可提高模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，FiLA-Video在长视频理解方面实现了更高的效率和准确性。&lt;h4&gt;结论&lt;/h4&gt;FiLA-Video框架为长视频理解提供了一种高效且准确的方法，有望在视频理解领域得到广泛应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in video understanding within visual large languagemodels (VLLMs) have led to notable progress. However, the complexity of videodata and contextual processing limitations still hinder long-videocomprehension. A common approach is video feature compression to reduce tokeninput to large language models, yet many methods either fail to prioritizeessential features, leading to redundant inter-frame information, or introducecomputationally expensive modules.To address these issues, we proposeFiLA(Fine-grained Vision Language Model)-Video, a novel framework thatleverages a lightweight dynamic-weight multi-frame fusion strategy, whichadaptively integrates multiple frames into a single representation whilepreserving key video information and reducing computational costs. To enhanceframe selection for fusion, we introduce a keyframe selection strategy,effectively identifying informative frames from a larger pool for improvedsummarization. Additionally, we present a simple yet effective long-videotraining data generation strategy, boosting model performance without extensivemanual annotation. Experimental results demonstrate that FiLA-Video achievessuperior efficiency and accuracy in long-video comprehension compared toexisting methods.</description>
      <author>example@mail.com (Yanan Guo, Wenhui Dong, Jun Song, Shiding Zhu, Xuan Zhang, Hanqing Yang, Yingbo Wang, Yang Du, Xianing Chen, Bo Zheng)</author>
      <guid isPermaLink="false">2504.20384v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating the Structural Bias in Graph Adversarial Defenses</title>
      <link>http://arxiv.org/abs/2504.20848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种防御策略，旨在缓解图神经网络（GNNs）在对抗攻击下的结构偏差，并提高其鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络在处理与图结构相关的下游任务中展现出巨大潜力，但现有的GNNs易受恶意对抗攻击的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种防御策略，以减少GNNs在对抗攻击下的结构偏差，特别是针对低度节点（尾节点）的防御能力。&lt;h4&gt;方法&lt;/h4&gt;策略包括异同质增强图构建、kNN增强图构建和多视图节点级注意力模块。异同质增强图通过移除异质链接（特征不同的节点之间的链接）和为低度节点添加同质链接（特征相似的节点之间的链接）来构建。此外，采用注意力机制以自适应地结合两种图视图的表示。&lt;h4&gt;主要发现&lt;/h4&gt;该策略在基准数据集上展示了防御和去偏效果，表明其能有效缓解GNNs的结构偏差。&lt;h4&gt;结论&lt;/h4&gt;提出的防御策略能够有效提升GNNs在对抗攻击下的鲁棒性，特别是在低度节点方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，图神经网络（GNNs）在解决各种与图结构相关的下游任务中显示出巨大的潜力。然而，最近的研究发现，当前的GNNs容易受到恶意对抗攻击的影响。鉴于对抗攻击在现实世界中的不可避免性，已经提出了各种防御方法来对抗这些攻击并提高GNNs的鲁棒性。尽管这些防御方法表现出可嘉的性能，但我们观察到它们在防御能力上往往表现出对低度节点（即尾节点）的结构偏差，这与传统GNNs在干净图中对低度节点的结构偏差相似。因此，在本工作中，我们提出了一种防御策略，通过包括异同质增强图构建、kNN增强图构建和多视图节点级注意力模块来缓解GNNs对抗攻击的结构偏差。值得注意的是，异同质增强图由全局移除异质链接（即连接具有不同特征的节点的链接）和为低度节点添加同质链接（即连接具有相似特征的节点的链接）组成。为了进一步增强防御能力，采用了一种注意力机制来自适应地结合上述两种图视图的表示。我们进行了广泛的实验，以证明所提出的策略在基准数据集上的防御和去偏效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, graph neural networks (GNNs) have shown great potential inaddressing various graph structure-related downstream tasks. However, recentstudies have found that current GNNs are susceptible to malicious adversarialattacks. Given the inevitable presence of adversarial attacks in the realworld, a variety of defense methods have been proposed to counter these attacksand enhance the robustness of GNNs. Despite the commendable performance ofthese defense methods, we have observed that they tend to exhibit a structuralbias in terms of their defense capability on nodes with low degree (i.e., tailnodes), which is similar to the structural bias of traditional GNNs on nodeswith low degree in the clean graph. Therefore, in this work, we propose adefense strategy by including hetero-homo augmented graph construction, $k$NNaugmented graph construction, and multi-view node-wise attention modules tomitigate the structural bias of GNNs against adversarial attacks. Notably, thehetero-homo augmented graph consists of removing heterophilic links (i.e.,links connecting nodes with dissimilar features) globally and adding homophiliclinks (i.e., links connecting nodes with similar features) for nodes with lowdegree. To further enhance the defense capability, an attention mechanism isadopted to adaptively combine the representations from the above two kinds ofgraph views. We conduct extensive experiments to demonstrate the defense anddebiasing effect of the proposed strategy on benchmark datasets.</description>
      <author>example@mail.com (Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse)</author>
      <guid isPermaLink="false">2504.20848v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral Remote Sensing Imagery of the Andes</title>
      <link>http://arxiv.org/abs/2504.20303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了DeepAndes，一个专门为安第斯考古学设计的基于Transformer的视觉基础模型，通过大规模的自监督预训练，在考古遥感领域取得了显著成效。&lt;h4&gt;背景&lt;/h4&gt;利用遥感数据在大规模上对遗址进行映射，可以帮助考古学家深入了解长期人口趋势、区域间社会网络以及过去对气候变化的适应。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多光谱卫星图像的深度学习模型，以解决传统监督学习方法在标注考古特征时遇到的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出DeepAndes模型，该模型基于三百万张多光谱卫星图像进行训练，并采用了定制化的DINOv2自监督学习算法，针对8波段多光谱图像进行了优化。&lt;h4&gt;主要发现&lt;/h4&gt;DeepAndes在图像理解任务中表现出色，包括不平衡图像分类、图像实例检索和像素级语义分割，其F1分数、平均精度和Dice分数在少量样本学习场景中优于从头开始训练或在小数据集上预训练的模型。&lt;h4&gt;结论&lt;/h4&gt;大规模自监督预训练在考古遥感领域是有效的，DeepAndes模型为这一领域提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;通过在大规模上使用遥感数据对遗址进行映射，考古学家可以生成关于长期人口趋势、区域间社会网络和过去对气候变化适应的独特见解。遥感调查补充了基于现场的方法，当与深度学习和计算机视觉技术结合时，其范围可以特别广泛。然而，传统的监督深度学习方法在标注大规模精细考古特征时面临挑战。尽管最近的视觉基础模型在利用最小标注学习大规模遥感数据方面取得了显著的成功，但大多数现成的解决方案是为RGB图像而不是多光谱卫星图像（如我们研究中使用的8波段数据）设计的。在本文中，我们介绍了DeepAndes，这是一个基于Transformer的视觉基础模型，在300万张多光谱卫星图像上进行了训练，专门针对安第斯考古学进行了定制。DeepAndes集成了针对8波段多光谱图像优化的定制化DINOv2自监督学习算法，标志着第一个专门为安第斯地区设计的基座模型。我们通过不平衡图像分类、图像实例检索和像素级语义分割任务评估了其图像理解性能。我们的实验表明，DeepAndes在少量样本学习场景中实现了优越的F1分数、平均精度和Dice分数，显著优于从头开始训练或在小数据集上预训练的模型。这强调了大规模自监督预训练在考古遥感中的有效性。代码将在https://github.com/geopacha/DeepAndes上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By mapping sites at large scales using remotely sensed data, archaeologistscan generate unique insights into long-term demographic trends, inter-regionalsocial networks, and past adaptations to climate change. Remote sensing surveyscomplement field-based approaches, and their reach can be especially great whencombined with deep learning and computer vision techniques. However,conventional supervised deep learning methods face challenges in annotatingfine-grained archaeological features at scale. While recent vision foundationmodels have shown remarkable success in learning large-scale remote sensingdata with minimal annotations, most off-the-shelf solutions are designed forRGB images rather than multi-spectral satellite imagery, such as the 8-banddata used in our study. In this paper, we introduce DeepAndes, atransformer-based vision foundation model trained on three millionmulti-spectral satellite images, specifically tailored for Andean archaeology.DeepAndes incorporates a customized DINOv2 self-supervised learning algorithmoptimized for 8-band multi-spectral imagery, marking the first foundation modeldesigned explicitly for the Andes region. We evaluate its image understandingperformance through imbalanced image classification, image instance retrieval,and pixel-level semantic segmentation tasks. Our experiments show thatDeepAndes achieves superior F1 scores, mean average precision, and Dice scoresin few-shot learning scenarios, significantly outperforming models trained fromscratch or pre-trained on smaller datasets. This underscores the effectivenessof large-scale self-supervised pre-training in archaeological remote sensing.Codes will be available on https://github.com/geopacha/DeepAndes.</description>
      <author>example@mail.com (Junlin Guo, James R. Zimmer-Dauphinee, Jordan M. Nieusma, Siqi Lu, Quan Liu, Ruining Deng, Can Cui, Jialin Yue, Yizhe Lin, Tianyuan Yao, Juming Xiong, Junchao Zhu, Chongyu Qu, Yuechen Yang, Mitchell Wilkes, Xiao Wang, Parker VanValkenburgh, Steven A. Wernke, Yuankai Huo)</author>
      <guid isPermaLink="false">2504.20303v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>DRO: Doppler-Aware Direct Radar Odometry</title>
      <link>http://arxiv.org/abs/2504.20339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at RSS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于旋转频率调制连续波雷达的SE(2)里程计方法，用于移动机器人应用。&lt;h4&gt;背景&lt;/h4&gt;雷达在移动机器人应用中的重要性正在兴起，尤其是在需要穿透障碍物和恶劣天气条件的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要特征或点云提取的直接扫描到局部地图注册的方法，以提高移动机器人的定位精度。&lt;h4&gt;方法&lt;/h4&gt;该方法利用雷达强度信息进行直接注册，并考虑了运动和多普勒畸变。在特定频率调制模式下，还引入了基于多普勒的约束来提高速度估计。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在超过250公里的公共数据集上进行了验证，与现有方法相比，平均相对位置误差降低了0.26%。在具有适当多普勒调制模式的场景中，位置误差进一步降低至0.18%。&lt;h4&gt;结论&lt;/h4&gt;该方法在几何特征稀缺的场景中表现良好，并且实时实现已经公开。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于旋转频率调制连续波雷达的SE(2)里程计方法，用于移动机器人应用。与相机或激光雷达相比，毫米波雷达能够在薄墙、植被和恶劣天气条件下（如大雨、雾、雪和灰尘）进行探测。本文提出了一种新的SE(2)里程计方法，用于旋转频率调制连续波雷达。该方法以直接方式使用所有雷达强度信息进行输入雷达数据的扫描到局部地图注册，无需特征或点云提取。该方法执行局部连续轨迹估计，并考虑雷达扫描的运动和多普勒畸变。如果雷达具有使径向多普勒速度可观测的特定频率调制模式，则还制定了基于多普勒的约束，以提高速度估计并使里程计在几何特征稀缺的场景（例如无特征隧道）中成为可能。该方法已在超过250公里的公共数据集（Boreas和MulRan）上进行了验证，这些数据是通过我们的汽车平台收集的。在有陀螺仪的帮助下，它优于最先进的方法，在Boreas排行榜上实现了0.26%的平均相对位置误差。当使用具有适当多普勒启用频率调制模式的数据时，在类似环境中，位置误差降低至0.18%。我们还使用在具有不同结构级别的越野环境中收集的1.5小时数据对该算法进行了基准测试，以展示其多功能性。我们的实时实现已经公开：https://github.com/utiasASRL/dro。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A renaissance in radar-based sensing for mobile robotic applications isunderway. Compared to cameras or lidars, millimetre-wave radars have theability to `see' through thin walls, vegetation, and adversarial weatherconditions such as heavy rain, fog, snow, and dust. In this paper, we propose anovel SE(2) odometry approach for spinning frequency-modulated continuous-waveradars. Our method performs scan-to-local-map registration of the incomingradar data in a direct manner using all the radar intensity information withoutthe need for feature or point cloud extraction. The method performs locallycontinuous trajectory estimation and accounts for both motion and Dopplerdistortion of the radar scans. If the radar possesses a specific frequencymodulation pattern that makes radial Doppler velocities observable, anadditional Doppler-based constraint is formulated to improve the velocityestimate and enable odometry in geometrically feature-deprived scenarios (e.g.,featureless tunnels). Our method has been validated on over 250km of on-roaddata sourced from public datasets (Boreas and MulRan) and collected using ourautomotive platform. With the aid of a gyroscope, it outperformsstate-of-the-art methods and achieves an average relative translation error of0.26% on the Boreas leaderboard. When using data with the appropriateDoppler-enabling frequency modulation pattern, the translation error is reducedto 0.18% in similar environments. We also benchmarked our algorithm using 1.5hours of data collected with a mobile robot in off-road environments withvarious levels of structure to demonstrate its versatility. Our real-timeimplementation is publicly available: https://github.com/utiasASRL/dro.</description>
      <author>example@mail.com (Cedric Le Gentil, Leonardo Brizi, Daniil Lisus, Xinyuan Qiao, Giorgio Grisetti, Timothy D. Barfoot)</author>
      <guid isPermaLink="false">2504.20339v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning Preserving Ignorability and Covariate Matching for Treatment Effects</title>
      <link>http://arxiv.org/abs/2504.20579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了利用神经网络解决观察数据中治疗效应估计的挑战，包括隐藏混杂因素和协变量不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;由于隐藏混杂因素和协变量不匹配，从观察数据中估计治疗效应具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出神经网络架构，旨在学习有效的调整表示，并满足协变量匹配约束。&lt;h4&gt;方法&lt;/h4&gt;结合了基于梯度匹配的跨域神经网络和协变量匹配变换的神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;证明了近似不变表示可以产生近似有效的调整集，从而能够估计真实因果效应的区间。&lt;h4&gt;结论&lt;/h4&gt;该方法在ATE和PEHE误差方面优于多种基线模型，并在IHDP、Jobs、Cattaneo和基于图像的Crowd Management数据集等因果基准测试中表现良好。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从观察数据中估计治疗效应具有挑战性，主要由于隐藏混杂因素和协变量不匹配。针对这些问题，本文提出了神经网络架构，旨在学习有效的调整表示，并满足协变量匹配约束。结合了基于梯度匹配的跨域神经网络和协变量匹配变换的神经网络。证明了近似不变表示可以产生近似有效的调整集，从而能够估计真实因果效应的区间。在ATE和PEHE误差方面，该方法优于多种基线模型，并在多个因果基准测试中表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating treatment effects from observational data is challenging due totwo main reasons: (a) hidden confounding, and (b) covariate mismatch (controland treatment groups not having identical distributions). Long lines of worksexist that address only either of these issues. To address the former,conventional techniques that require detailed knowledge in the form of causalgraphs have been proposed. For the latter, covariate matching and importanceweighting methods have been used. Recently, there has been progress incombining testable independencies with partial side information for tacklinghidden confounding. A common framework to address both hidden confounding andselection bias is missing. We propose neural architectures that aim to learn arepresentation of pre-treatment covariates that is a valid adjustment and alsosatisfies covariate matching constraints. We combine two different neuralarchitectures: one based on gradient matching across domains created bysubsampling a suitable anchor variable that assumes causal side information,followed by the other, a covariate matching transformation. We prove thatapproximately invariant representations yield approximate valid adjustment setswhich would enable an interval around the true causal effect. In contrast tousual sensitivity analysis, where an unknown nuisance parameter is varied, wehave a testable approximation yielding a bound on the effect estimate. We alsooutperform various baselines with respect to ATE and PEHE errors on causalbenchmarks that include IHDP, Jobs, Cattaneo, and an image-based CrowdManagement dataset.</description>
      <author>example@mail.com (Praharsh Nanavati, Ranjitha Prasad, Karthikeyan Shanmugam)</author>
      <guid isPermaLink="false">2504.20579v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Under High-Dimensional Network Convolutional Regression Model</title>
      <link>http://arxiv.org/abs/2504.19979v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，用于处理网络数据中的依赖性，并通过仿真和实际应用证明了其在预测准确性上的提升。&lt;h4&gt;背景&lt;/h4&gt;迁移学习通过利用相关领域的知识来提高模型性能，尤其是在标注数据稀缺的情况下。然而，在处理网络数据中的依赖性时，现有的研究仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决网络数据中依赖性的处理问题，本文提出了一个基于NCR的迁移学习框架，旨在提高预测准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个两步迁移学习算法，用于解决源网络和目标网络之间的领域偏移，并包含一个源检测机制来识别信息丰富的领域。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在Erdos-Renyi模型假设下的随机图背景下，当存在信息丰富的源时，迁移学习可以改善收敛速度。实证评估显示，在目标域的标注数据有限的情况下，该方法在预测准确性上有了显著提升。&lt;h4&gt;结论&lt;/h4&gt;提出的NCR迁移学习框架在处理网络数据依赖性方面有效，并在预测准确性上取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过利用相关领域的知识，迁移学习可以增强模型性能，尤其是在标注数据稀缺的情况下。尽管现有研究在独立设置下解决了各种分布偏移的迁移学习问题，但处理网络数据中的依赖性仍然具有挑战性。为了应对这一挑战，我们提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，该框架受到图卷积网络（GCNs）成功应用的启发。NCR模型通过允许每个节点的响应依赖于其特征及其邻居的聚合特征，有效地捕捉了局部依赖性。我们的方法包括一个两步迁移学习算法，用于解决源网络和目标网络之间的领域偏移，以及一个源检测机制来识别信息丰富的领域。从理论上讲，我们在基于Erdos-Renyi模型假设的随机图背景下分析了lasso估计量，证明了当存在信息丰富的源时，迁移学习可以改善收敛速度。实证评估，包括模拟和利用SinaWeibo数据的实际应用，证明了在目标域的标注数据有限的情况下，该方法在预测准确性上有了显著提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances model performance by utilizing knowledge fromrelated domains, particularly when labeled data is scarce. While existingresearch addresses transfer learning under various distribution shifts inindependent settings, handling dependencies in networked data remainschallenging. To address this challenge, we propose a high-dimensional transferlearning framework based on network convolutional regression (NCR), inspired bythe success of graph convolutional networks (GCNs). The NCR model incorporatesrandom network structure by allowing each node's response to depend on itsfeatures and the aggregated features of its neighbors, capturing localdependencies effectively. Our methodology includes a two-step transfer learningalgorithm that addresses domain shift between source and target networks, alongwith a source detection mechanism to identify informative domains.Theoretically, we analyze the lasso estimator in the context of a random graphbased on the Erdos-Renyi model assumption, demonstrating that transfer learningimproves convergence rates when informative sources are present. Empiricalevaluations, including simulations and a real-world application using SinaWeibo data, demonstrate substantial improvements in prediction accuracy,particularly when labeled data in the target domain is limited.</description>
      <author>example@mail.com (Liyuan Wang, Jiachen Chen, Kathryn L. Lunetta, Danyang Huang, Huimin Cheng, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2504.19979v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting</title>
      <link>http://arxiv.org/abs/2504.20630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为ISDrama的多模态沉浸式空间戏剧生成模型，该模型通过多模态提示创建连续多说话者的双耳语音，并具有戏剧性的韵律，应用于AR、VR等领域。&lt;h4&gt;背景&lt;/h4&gt;多模态沉浸式空间戏剧生成需要同时模拟空间信息和戏剧韵律，且数据收集成本高，目前尚无解决这些挑战的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够通过多模态提示生成沉浸式空间戏剧的模型，并构建相应的数据集。&lt;h4&gt;方法&lt;/h4&gt;1) 构建了名为MRSDrama的多模态记录空间戏剧数据集，包含双耳戏剧音频、剧本、视频、几何姿态和文本提示。2) 提出了ISDrama模型，该模型包含以下主要组件：多模态姿态编码器（考虑移动说话者引起的多普勒效应，提取统一姿态信息）、沉浸式戏剧Transformer（基于流的mamba-transformer模型，结合Drama-MOE以增强韵律和姿态控制）以及上下文一致的分类器无关的指导策略以生成连贯的戏剧。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ISDrama在客观和主观指标上优于基线模型。&lt;h4&gt;结论&lt;/h4&gt;ISDrama模型能够有效地生成沉浸式空间戏剧，为相关应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal immersive spatial drama generation model named ISDrama, which creates continuous binaural speech with dramatic prosody based on multimodal prompts and has potential applications in AR and VR. The model simultaneously models spatial information and dramatic prosody based on multimodal inputs, with high data collection costs. The paper constructs the MRSDrama dataset, the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. Then, it proposes ISDrama, the first immersive spatial drama generation model through multimodal prompting. ISDrama consists of the following main components: 1) Multimodal Pose Encoder, which uses contrastive learning to consider the Doppler effect caused by moving speakers to extract unified pose information from multimodal prompts. 2) Immersive Drama Transformer, a flow-based mamba-transformer model that generates high-quality drama, incorporating Drama-MOE to select proper experts for enhanced prosody and pose control. It also designs a context-consistent classifier-free guidance strategy to generate coherent drama. Experimental results show that ISDrama outperforms baseline models on objective and subjective metrics. The demos and dataset are available at https://aaronz345.github.io/ISDramaDemo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal immersive spatial drama generation focuses on creating continuousmulti-speaker binaural speech with dramatic prosody based on multimodalprompts, with potential applications in AR, VR, and others. This task requiressimultaneous modeling of spatial information and dramatic prosody based onmultimodal inputs, with high data collection costs. To the best of ourknowledge, our work is the first attempt to address these challenges. Weconstruct MRSDrama, the first multimodal recorded spatial drama dataset,containing binaural drama audios, scripts, videos, geometric poses, and textualprompts. Then, we propose ISDrama, the first immersive spatial drama generationmodel through multimodal prompting. ISDrama comprises these primary components:1) Multimodal Pose Encoder, based on contrastive learning, considering theDoppler effect caused by moving speakers to extract unified pose informationfrom multimodal prompts. 2) Immersive Drama Transformer, a flow-basedmamba-transformer model that generates high-quality drama, incorporatingDrama-MOE to select proper experts for enhanced prosody and pose control. Wealso design a context-consistent classifier-free guidance strategy tocoherently generate complete drama. Experimental results show that ISDramaoutperforms baseline models on objective and subjective metrics. The demos anddataset are available at https://aaronz345.github.io/ISDramaDemo.</description>
      <author>example@mail.com (Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Tao Jin, Zhou Zhao)</author>
      <guid isPermaLink="false">2504.20630v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FreBIS: Frequency-Based Stratification for Neural Implicit Surface Representations</title>
      <link>http://arxiv.org/abs/2504.20222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 CV4Metaverse Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FreBIS是一种新的神经网络隐式表面表示方法，用于解决复杂场景中的表面建模问题。&lt;h4&gt;背景&lt;/h4&gt;神经网络隐式表面表示技术在增强现实/虚拟现实、数字孪生、自主导航等领域需求增加。&lt;h4&gt;目的&lt;/h4&gt;提出FreBIS方法以克服传统3D表面重建方法在处理复杂场景时的局限性。&lt;h4&gt;方法&lt;/h4&gt;FreBIS通过根据表面频率分层场景，并为每个频率级别（或一组频率级别）分配专用编码器。它还通过一个新颖的冗余感知加权模块鼓励编码器捕获互补信息。&lt;h4&gt;主要发现&lt;/h4&gt;在BlendedMVS数据集上的实证评估表明，使用FreBIS的频率分层编码器替换标准编码器，可以显著提高重建3D表面的质量和渲染的保真度。&lt;h4&gt;结论&lt;/h4&gt;FreBIS在处理复杂场景的表面建模方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：神经网络隐式表面表示技术在增强现实/虚拟现实、数字孪生、自主导航等多个技术领域需求日益增长。这种技术能够将场景中的物体表面建模为连续函数，近年来在超越经典3D表面重建方法（如使用体素或点云的方法）方面取得了显著进展。然而，这些方法在处理具有多样化和复杂表面的场景时存在困难，主要是因为它们使用单个编码网络来同时捕获场景中从低到高表面频率的全部信息。在这项工作中，我们提出了一种名为FreBIS的新型神经网络隐式表面表示方法，以克服这一挑战。FreBIS通过根据表面频率将场景分层到多个频率级别，并为每个级别（或一组级别）分配一个专门的编码器。此外，FreBIS通过一种新颖的冗余感知加权模块促进编码特征的相互差异，从而鼓励这些编码器捕获互补信息。在具有挑战性的BlendedMVS数据集上的实证评估表明，用我们的频率分层编码器替换标准编码器，可以显著提高3D表面重建的质量及其从任何视角的渲染保真度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural implicit surface representation techniques are in high demand foradvancing technologies in augmented reality/virtual reality, digital twins,autonomous navigation, and many other fields. With their ability to modelobject surfaces in a scene as a continuous function, such techniques have maderemarkable strides recently, especially over classical 3D surfacereconstruction methods, such as those that use voxels or point clouds. However,these methods struggle with scenes that have varied and complex surfacesprincipally because they model any given scene with a single encoder networkthat is tasked to capture all of low through high-surface frequency informationin the scene simultaneously. In this work, we propose a novel, neural implicitsurface representation approach called FreBIS to overcome this challenge.FreBIS works by stratifying the scene based on the frequency of surfaces intomultiple frequency levels, with each level (or a group of levels) encoded by adedicated encoder. Moreover, FreBIS encourages these encoders to capturecomplementary information by promoting mutual dissimilarity of the encodedfeatures via a novel, redundancy-aware weighting module. Empirical evaluationson the challenging BlendedMVS dataset indicate that replacing the standardencoder in an off-the-shelf neural surface reconstruction method with ourfrequency-stratified encoders yields significant improvements. Theseenhancements are evident both in the quality of the reconstructed 3D surfacesand in the fidelity of their renderings from any viewpoint.</description>
      <author>example@mail.com (Naoko Sawada, Pedro Miraldo, Suhas Lohit, Tim K. Marks, Moitreya Chatterjee)</author>
      <guid isPermaLink="false">2504.20222v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection</title>
      <link>http://arxiv.org/abs/2504.20498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript submitted to IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Style-Adaptive Detection Transformer (SA-DETR)的检测器，用于解决单源域泛化（SDG）在目标检测中的问题，该检测器能够使用源域数据实现强泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于CNN的检测器主要通过精心设计的数据增强策略和特征对齐技术来提高鲁棒性，但数据增强方法存在局限性，且DETR在域适应任务中表现出色，但在SDG任务中的应用潜力尚未探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够使用源域数据在未见过的目标域上展示强泛化能力的目标检测器。&lt;h4&gt;方法&lt;/h4&gt;提出了一种域风格适配器，将未见目标域的风格表示投影到训练域，实现动态风格适配；并提出了一种对象感知对比学习模块，通过对比学习引导检测器提取域不变特征；使用对象感知门控掩码在空间和语义维度上约束特征聚合，实现跨域实例级特征的对比，从而增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;SA-DETR在五个不同的天气场景下表现出了优越的性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SA-DETR是一种有效的SDG检测器，能够显著提高目标检测的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Single-source Domain Generalization (SDG) in object detection aims to develop a detector using only data from a source domain that can exhibit strong generalization capability when applied to unseen target domains. Existing methods are built upon CNN-based detectors and primarily improve robustness by employing carefully designed data augmentation strategies integrated with feature alignment techniques. However, data augmentation methods have inherent drawbacks; they are only effective when the augmented sample distribution approximates or covers the unseen scenarios, thus failing to enhance generalization across all unseen domains. Furthermore, while the recent Detection Transformer (DETR) has demonstrated superior generalization capability in domain adaptation tasks due to its efficient global information extraction, its potential in SDG tasks remains unexplored. To this end, we introduce a strong DETR-based detector named the Style-Adaptive Detection Transformer (SA-DETR) for SDG in object detection. Specifically, we present a domain style adapter that projects the style representation of the unseen target domain into the training domain, enabling dynamic style adaptation. Then, we propose an object-aware contrastive learning module to guide the detector in extracting domain-invariant features through contrastive learning. By using object-aware gating masks to constrain feature aggregation in both spatial and semantic dimensions, this module achieves cross-domain contrast of instance-level features, thereby enhancing generalization. Extensive experiments demonstrate the superior performance and generalization capability of SA-DETR across five different weather scenarios. Code is released at https://github.com/h751410234/SA-DETR.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-source Domain Generalization (SDG) in object detection aims to developa detector using only data from a source domain that can exhibit stronggeneralization capability when applied to unseen target domains. Existingmethods are built upon CNN-based detectors and primarily improve robustness byemploying carefully designed data augmentation strategies integrated withfeature alignment techniques. However, data augmentation methods have inherentdrawbacks; they are only effective when the augmented sample distributionapproximates or covers the unseen scenarios, thus failing to enhancegeneralization across all unseen domains. Furthermore, while the recentDetection Transformer (DETR) has demonstrated superior generalizationcapability in domain adaptation tasks due to its efficient global informationextraction, its potential in SDG tasks remains unexplored. To this end, weintroduce a strong DETR-based detector named the Style-Adaptive DetectionTransformer (SA-DETR) for SDG in object detection. Specifically, we present adomain style adapter that projects the style representation of the unseentarget domain into the training domain, enabling dynamic style adaptation.Then, we propose an object-aware contrastive learning module to guide thedetector in extracting domain-invariant features through contrastive learning.By using object-aware gating masks to constrain feature aggregation in bothspatial and semantic dimensions, this module achieves cross-domain contrast ofinstance-level features, thereby enhancing generalization. Extensiveexperiments demonstrate the superior performance and generalization capabilityof SA-DETR across five different weather scenarios. Code is released athttps://github.com/h751410234/SA-DETR.</description>
      <author>example@mail.com (Jianhong Han, Yupei Wang, Liang Chen)</author>
      <guid isPermaLink="false">2504.20498v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>VideoMultiAgents: A Multi-Agent Framework for Video Question Answering</title>
      <link>http://arxiv.org/abs/2504.20091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为VideoMultiAgents的视频问答框架，该框架通过整合专门用于视觉、场景图分析和文本处理的代理，利用多模态推理来增强视频内容的理解，并通过问题引导的标题生成来提高答案的准确性。&lt;h4&gt;背景&lt;/h4&gt;视频问答（VQA）需要多模态推理，结合视觉、时间和语言线索来深入理解视频内容。然而，许多现有方法依赖于将帧级标题输入到单个模型中，这使得难以充分捕捉时间和交互式上下文。&lt;h4&gt;目的&lt;/h4&gt;提出VideoMultiAgents框架，以解决现有方法在捕捉时间和交互式上下文方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;VideoMultiAgents框架通过整合专门代理，包括视觉代理、场景图分析代理和文本处理代理，以及问题引导的标题生成来提高视频问答的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在Intent-QA（79.0%，比之前的SOTA高6.2%）、EgoSchema子集（75.4%，比之前的SOTA高3.4%）和NExT-QA（79.6%，比之前的SOTA高0.4%）上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;VideoMultiAgents框架通过多模态推理和问题引导的标题生成，显著提高了视频问答的性能，并在多个数据集上取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Question Answering (VQA) inherently relies on multimodal reasoning,integrating visual, temporal, and linguistic cues to achieve a deeperunderstanding of video content. However, many existing methods rely on feedingframe-level captions into a single model, making it difficult to adequatelycapture temporal and interactive contexts. To address this limitation, weintroduce VideoMultiAgents, a framework that integrates specialized agents forvision, scene graph analysis, and text processing. It enhances videounderstanding leveraging complementary multimodal reasoning from independentlyoperating agents. Our approach is also supplemented with a question-guidedcaption generation, which produces captions that highlight objects, actions,and temporal transitions directly relevant to a given query, thus improving theanswer accuracy. Experimental results demonstrate that our method achievesstate-of-the-art performance on Intent-QA (79.0%, +6.2% over previous SOTA),EgoSchema subset (75.4%, +3.4%), and NExT-QA (79.6%, +0.4%).</description>
      <author>example@mail.com (Noriyuki Kugo, Xiang Li, Zixin Li, Ashish Gupta, Arpandeep Khatua, Nidhish Jain, Chaitanya Patel, Yuta Kyuragi, Masamoto Tanabiki, Kazuki Kozuka, Ehsan Adeli)</author>
      <guid isPermaLink="false">2504.20091v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning a General Model: Folding Clothing with Topological Dynamics</title>
      <link>http://arxiv.org/abs/2504.20720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种拓扑动力学模型，用于折叠复杂的服装。&lt;h4&gt;背景&lt;/h4&gt;服装具有高自由度和复杂结构，对服装操作提出了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法来折叠复杂的服装。&lt;h4&gt;方法&lt;/h4&gt;利用可见的折叠结构作为拓扑骨架，设计了一种新的拓扑图来表示服装状态。应用语义分割分析遮挡关系，并分解服装结构，结合关键点检测生成拓扑图。使用改进的图神经网络（GNN）学习一般动力学，预测服装变形并计算变形雅可比矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;拓扑图可以指示服装的约束，并预测服装的运动。&lt;h4&gt;结论&lt;/h4&gt;实验验证了算法在识别和折叠具有遮挡的复杂服装方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract of the paper is summarized as follows: The high degrees of freedom and complex structure of garments present significant challenges for clothing manipulation. In this paper, we propose a general topological dynamics model to fold complex clothing. By utilizing the visible folding structure as the topological skeleton, we design a novel topological graph to represent the clothing state. This topological graph is low-dimensional and applied for complex clothing in various folding states. It indicates the constraints of clothing and enables predictions regarding clothing movement. To extract graphs from self-occlusion, we apply semantic segmentation to analyze the occlusion relationships and decompose the clothing structure. The decomposed structure is then combined with keypoint detection to generate the topological graph. To analyze the behavior of the topological graph, we employ an improved Graph Neural Network (GNN) to learn the general dynamics. The GNN model can predict the deformation of clothing and is employed to calculate the deformation Jacobi matrix for control. Experiments using jackets validate the algorithm's effectiveness to recognize and fold complex clothing with self-occlusion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The high degrees of freedom and complex structure of garments presentsignificant challenges for clothing manipulation. In this paper, we propose ageneral topological dynamics model to fold complex clothing. By utilizing thevisible folding structure as the topological skeleton, we design a noveltopological graph to represent the clothing state. This topological graph islow-dimensional and applied for complex clothing in various folding states. Itindicates the constraints of clothing and enables predictions regardingclothing movement. To extract graphs from self-occlusion, we apply semanticsegmentation to analyze the occlusion relationships and decompose the clothingstructure. The decomposed structure is then combined with keypoint detection togenerate the topological graph. To analyze the behavior of the topologicalgraph, we employ an improved Graph Neural Network (GNN) to learn the generaldynamics. The GNN model can predict the deformation of clothing and is employedto calculate the deformation Jacobi matrix for control. Experiments usingjackets validate the algorithm's effectiveness to recognize and fold complexclothing with self-occlusion.</description>
      <author>example@mail.com (Yiming Liu, Lijun Han, Enlin Gu, Hesheng Wang)</author>
      <guid isPermaLink="false">2504.20720v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>FALCO: a Foundation model of Astronomical Light Curves for time dOmain astronomy</title>
      <link>http://arxiv.org/abs/2504.20290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FALCO是一种用于时域天文观测的光曲线分析基础模型，通过自监督学习在未标记的开普勒光曲线上训练，表现出强大的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;时域天文观测揭示了多种可变现象，但数据规模和复杂性以及快速分类的需求对分析提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理时域天文观测数据并具有良好泛化能力的模型。&lt;h4&gt;方法&lt;/h4&gt;使用基于Transformer的架构，通过自监督学习在未标记的开普勒光曲线上训练FALCO模型。&lt;h4&gt;主要发现&lt;/h4&gt;FALCO在三个不同任务上表现出色：在八类恒星可变性分类中达到95%的准确率，表面重力估计的RMSE为0.1305 dex，在耀斑识别中达到87%的精确度。&lt;h4&gt;结论&lt;/h4&gt;FALCO模型能够从光曲线中学习可泛化的表示，并能够轻松适应不同的任务。模型性能随着模型规模和输入序列长度的增加而提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-domain surveys have advanced astronomical research by revealing diversevariable phenomena, from stellar flares to transient events. The scale andcomplexity of survey data, along with the demand for rapid classification,present significant challenges for analysis. While machine learning offerssolutions, most existing models are tailored to single tasks, struggle togeneralize, and depend heavily on large, accurately labeled datasets. Weintroduce FALCO, a foundation model for astronomical light curve analysis intime-domain astronomy. This work presents the initial version of FALCO trainedvia self-supervised learning on unlabeled Kepler light curves using aTransformer-based architecture. The model has been evaluated on three distincttasks and demonstrates strong generalization: achieving 95 percent accuracy instellar variability classification across eight classes, an overall RMSE of0.1305 dex in surface gravity estimation (notably improved to below 0.08 dexwhen log g is less than 1, and approximately 0.02 dex near log g equals 3), and87 percent precision in flare identification. These results highlight themodel's versatility and ability to learn generalizable representations fromlight curves, enabling straightforward adaptation to diverse tasks. We furtheranalyze the impact of model scaling and sequence length, finding performanceimproves with larger models and longer input sequences. We also apply FALCO toderive surface gravity (log g) measurements for 179,732 Kepler stars from theirlight curves.</description>
      <author>example@mail.com (Xiaoxiong Zuo, Yihan Tao, Yang Huang, Zhixuan Kang, Huaxi Chen, Chenzhou Cui, Jiashu Pan, Xiao Kong, Xiaoyu Tang, Henggeng Han, Haiyang Mu, Yunfei Xu, Dongwei Fan, Guirong Xue, Ali Luo, Jifeng Liu)</author>
      <guid isPermaLink="false">2504.20290v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>SFi-Former: Sparse Flow Induced Attention for Graph Transformer</title>
      <link>http://arxiv.org/abs/2504.20666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICMR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的注意力机制SFi-attention，以及基于此的SFi-Former模型，用于处理具有长距离依赖的图数据，以提高图神经网络（GNN）的性能并解决传统GNN存在的问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Transformers在处理具有长距离依赖的图数据时表现出色，但传统的密集注意力机制导致诱导偏置弱、过拟合和过全局化等问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的注意力机制以缓解密集注意力带来的问题，并提高GNN模型在处理长距离依赖图数据时的性能。&lt;h4&gt;方法&lt;/h4&gt;引入SFi-attention，通过最小化基于网络流的能量函数来学习稀疏模式，并设计SFi-Former模型利用稀疏注意力模式生成稀疏网络流，从而从其他节点选择性地聚合特征。&lt;h4&gt;主要发现&lt;/h4&gt;SFi-Former在GNN基准数据集上获得了有竞争力的性能，在长距离图基准（LRGB）数据集上实现了SOTA性能，并且具有更小的泛化差距，表明它更不容易过拟合。&lt;h4&gt;结论&lt;/h4&gt;SFi-attention和SFi-Former模型为处理长距离依赖的图数据提供了一种有效的方法，并有望提高GNN模型的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers在许多研究中显示出比传统消息传递图神经网络（GNN）更优越的性能，尤其是在处理具有长距离依赖的图数据时。然而，由于密集注意力，GTs往往会遭受弱诱导偏置、过拟合和过全局化问题。在本文中，我们引入了SFi-attention，这是一种新的注意力机制，通过最小化基于网络流的能量函数（带有l1范数正则化）来学习稀疏模式，以缓解由密集注意力引起的问题。此外，相应地设计了SFi-Former，该模型可以利用SFi-attention的稀疏注意力模式在图数据的邻接矩阵之外生成稀疏网络流。具体来说，SFi-Former通过灵活地调整稀疏注意力来选择性地从其他节点聚合特征，从而得到一个更稳健的模型。我们在各种图数据集上验证了我们的SFi-Former，特别是那些表现出长距离依赖的图数据。实验结果表明，我们的SFi-Former在GNN基准数据集上获得了有竞争力的性能，在长距离图基准（LRGB）数据集上实现了SOTA性能。此外，我们的模型产生了更小的泛化差距，这表明它不太可能过拟合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated superior performance compared totraditional message-passing graph neural networks in many studies, especiallyin processing graph data with long-range dependencies. However, GTs tend tosuffer from weak inductive bias, overfitting and over-globalizing problems dueto the dense attention. In this paper, we introduce SFi-attention, a novelattention mechanism designed to learn sparse pattern by minimizing an energyfunction based on network flows with l1-norm regularization, to relieve thoseissues caused by dense attention. Furthermore, SFi-Former is accordinglydevised which can leverage the sparse attention pattern of SFi-attention togenerate sparse network flows beyond adjacency matrix of graph data.Specifically, SFi-Former aggregates features selectively from other nodesthrough flexible adaptation of the sparse attention, leading to a more robustmodel. We validate our SFi-Former on various graph datasets, especially thosegraph data exhibiting long-range dependencies. Experimental results show thatour SFi-Former obtains competitive performance on GNN Benchmark datasets andSOTA performance on LongRange Graph Benchmark (LRGB) datasets. Additionally,our model gives rise to smaller generalization gaps, which indicates that it isless prone to over-fitting. Click here for codes.</description>
      <author>example@mail.com (Zhonghao Li, Ji Shi, Xinming Zhang, Miao Zhang, Bo Li)</author>
      <guid isPermaLink="false">2504.20666v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Exploring internal representation of self-supervised networks: few-shot learning abilities and comparison with human semantics and recognition of objects</title>
      <link>http://arxiv.org/abs/2504.20364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自监督学习在机器学习和神经科学领域的最新进展，并研究了自监督学习方法在训练人工神经网络方面的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法不需要标注的监督信息，可以应用于不需要大量数据集的神经网络训练，并可能为大脑如何无监督地适应环境提供见解。&lt;h4&gt;目的&lt;/h4&gt;研究使用自监督对比学习算法训练的DCNN内部表示与人类语义和识别之间的对应关系。&lt;h4&gt;方法&lt;/h4&gt;采用少量样本学习评估程序，测量DCNN识别新概念的能力，并使用两种比较方法将少量样本学习结果与人类语义和识别联系起来。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比学习获得的表示与人类认知高度一致，表明自监督对比学习框架在无法获得明确监督的情况下，如人类婴儿在语言习得之前，具有模拟人类大脑学习机制的可能性。&lt;h4&gt;结论&lt;/h4&gt;自监督对比学习框架在模拟人类大脑学习机制方面具有潜力，尤其是在无法获得明确监督的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised learning have attracted significantattention from both machine learning and neuroscience. This is primarilybecause self-supervised methods do not require annotated supervisoryinformation, making them applicable to training artificial networks withoutrelying on large amounts of curated data, and potentially offering insightsinto how the brain adapts to its environment in an unsupervised manner.Although several previous studies have elucidated the correspondence betweenneural representations in deep convolutional neural networks (DCNNs) andbiological systems, the extent to which unsupervised or self-supervisedlearning can explain the human-like acquisition of categorically structuredinformation remains less explored. In this study, we investigate thecorrespondence between the internal representations of DCNNs trained using aself-supervised contrastive learning algorithm and human semantics andrecognition. To this end, we employ a few-shot learning evaluation procedure,which measures the ability of DCNNs to recognize novel concepts from limitedexposure, to examine the inter-categorical structure of the learnedrepresentations. Two comparative approaches are used to relate the few-shotlearning outcomes to human semantics and recognition, with results suggestingthat the representations acquired through contrastive learning are well alignedwith human cognition. These findings underscore the potential ofself-supervised contrastive learning frameworks to model learning mechanismssimilar to those of the human brain, particularly in scenarios where explicitsupervision is unavailable, such as in human infants prior to languageacquisition.</description>
      <author>example@mail.com (Asaki Kataoka, Yoshihiro Nagano, Masafumi Oizumi)</author>
      <guid isPermaLink="false">2504.20364v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.20403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于创建可编辑3D虚拟形象的框架，旨在为普通用户提供精确的区域定位、几何适应性和逼真的渲染效果。&lt;h4&gt;背景&lt;/h4&gt;个性化3D形象编辑因其用户友好性和在AR/VR和虚拟试穿等应用中的可用性而具有巨大潜力。然而，先前的研究在生成视觉上令人满意的结果方面遇到了困难，这可能是由于在复杂重建场景中混合优化几何和纹理下的不稳定表示学习。&lt;h4&gt;目的&lt;/h4&gt;旨在为普通用户提供一种创建精确区域定位、几何适应性和逼真渲染的3D可编辑形象的可访问解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一个精心设计的框架，该框架将编辑过程分解为局部空间适应和逼真外观学习，使用混合四面体约束高斯分层（TetGS）作为底层表示。TetGS结合了四面体网格的可控显式结构和3D高斯分层的精确渲染能力，并经过三个阶段的优化：从现实世界的单目视频实例化3D形象以提供TetGS初始化的准确先验；使用显式划分的四面体进行局部空间适应以引导高斯核的重新分配；以及基于几何的外观生成，采用由粗到细的激活策略。&lt;h4&gt;主要发现&lt;/h4&gt;定性和定量实验都证明了该方法在生成逼真的3D可编辑形象方面的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效地生成逼真的3D可编辑形象，为普通用户提供了创建个性化虚拟形象的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized 3D avatar editing holds significant promise due to itsuser-friendliness and availability to applications such as AR/VR and virtualtry-ons. Previous studies have explored the feasibility of 3D editing, butoften struggle to generate visually pleasing results, possibly due to theunstable representation learning under mixed optimization of geometry andtexture in complicated reconstructed scenarios. In this paper, we aim toprovide an accessible solution for ordinary users to create their editable 3Davatars with precise region localization, geometric adaptability, andphotorealistic renderings. To tackle this challenge, we introduce ameticulously designed framework that decouples the editing process into localspatial adaptation and realistic appearance learning, utilizing a hybridTetrahedron-constrained Gaussian Splatting (TetGS) as the underlyingrepresentation. TetGS combines the controllable explicit structure oftetrahedral grids with the high-precision rendering capabilities of 3D GaussianSplatting and is optimized in a progressive manner comprising three stages: 3Davatar instantiation from real-world monocular videos to provide accuratepriors for TetGS initialization; localized spatial adaptation with explicitlypartitioned tetrahedrons to guide the redistribution of Gaussian kernels; andgeometry-based appearance generation with a coarse-to-fine activation strategy.Both qualitative and quantitative experiments demonstrate the effectiveness andsuperiority of our approach in generating photorealistic 3D editable avatars.</description>
      <author>example@mail.com (Hanxi Liu, Yifang Men, Zhouhui Lian)</author>
      <guid isPermaLink="false">2504.20403v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>What Causes Knowledge Loss in Multilingual Language Models?</title>
      <link>http://arxiv.org/abs/2504.20356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了自然语言处理模型中的跨语言迁移问题，通过实验验证了参数共享在减轻遗忘和保留先验知识方面的效果。&lt;h4&gt;背景&lt;/h4&gt;跨语言迁移在自然语言处理中通过利用共享的语言知识来增强多语言性能。然而，传统方法在处理所有数据时往往无法模拟真实场景，导致灾难性遗忘等问题。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过实验评估参数共享通过适配器能否减轻遗忘同时保留先验知识。&lt;h4&gt;方法&lt;/h4&gt;研究在52种语言中使用不同阶数的LoRA适配器，对非共享、部分共享和完全共享的参数进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现使用非拉丁文字的语言更容易受到灾难性遗忘的影响，而使用拉丁文字的语言则更有利于有效的跨语言迁移。&lt;h4&gt;结论&lt;/h4&gt;参数共享通过适配器可以有效减轻遗忘并保留先验知识，特别是在使用拉丁文字的语言中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-lingual transfer in natural language processing (NLP) models enhancesmultilingual performance by leveraging shared linguistic knowledge. However,traditional methods that process all data simultaneously often fail to mimicreal-world scenarios, leading to challenges like catastrophic forgetting, wherefine-tuning on new tasks degrades performance on previously learned ones. Ourstudy explores this issue in multilingual contexts, focusing on linguisticdifferences affecting representational learning rather than just modelparameters. We experiment with 52 languages using LoRA adapters of varyingranks to evaluate non-shared, partially shared, and fully shared parameters.Our aim is to see if parameter sharing through adapters can mitigate forgettingwhile preserving prior knowledge. We find that languages using non-Latinscripts are more susceptible to catastrophic forgetting, whereas those writtenin Latin script facilitate more effective cross-lingual transfer.</description>
      <author>example@mail.com (Maria Khelli, Samuel Cahyawijaya, Ayu Purwarianti, Genta Indra Winata)</author>
      <guid isPermaLink="false">2504.20356v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning on a Random Lattice</title>
      <link>http://arxiv.org/abs/2504.20197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of ILIAD (2024),  https://www.iliadconference.com/proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将深度神经网络学习到的表示分解为可解释特征，以提高其安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;为了更好地理解特征，本文采用了几何视角，将特征视为学习到的坐标系统，用于映射嵌入数据分布。&lt;h4&gt;目的&lt;/h4&gt;通过分析数据分布的模型，提高对深度神经网络特征的理解。&lt;h4&gt;方法&lt;/h4&gt;将通用数据分布模型为一个随机晶格，并使用渗透理论分析其性质。&lt;h4&gt;主要发现&lt;/h4&gt;将学习到的特征分为上下文、组件和表面特征，模型与机制可解释性领域的近期发现相一致。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为未来研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;Decomposing a deep neural network's learned representations into interpretable features could greatly enhance its safety and reliability. To better understand features, we adopt a geometric perspective, viewing them as a learned coordinate system for mapping an embedded data distribution. We motivate a model of a generic data distribution as a random lattice and analyze its properties using percolation theory. Learned features are categorized into context, component, and surface features. The model is qualitatively consistent with recent findings in mechanistic interpretability and suggests directions for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decomposing a deep neural network's learned representations intointerpretable features could greatly enhance its safety and reliability. Tobetter understand features, we adopt a geometric perspective, viewing them as alearned coordinate system for mapping an embedded data distribution. Wemotivate a model of a generic data distribution as a random lattice and analyzeits properties using percolation theory. Learned features are categorized intocontext, component, and surface features. The model is qualitatively consistentwith recent findings in mechanistic interpretability and suggests directionsfor future research.</description>
      <author>example@mail.com (Aryeh Brill)</author>
      <guid isPermaLink="false">2504.20197v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Triadic Closure-Heterogeneity-Harmony GCN for Link Prediction</title>
      <link>http://arxiv.org/abs/2504.20492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了TriHetGCN模型，用于复杂网络的链接预测，通过结合拓扑指示符，提高了预测准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;链接预测在复杂网络分析中应用广泛，但传统方法依赖于预定义的节点连接假设，而基于GNN的方法常忽视节点属性和节点对之间的结构关系。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效处理节点属性和节点对之间结构关系的链接预测模型。&lt;h4&gt;方法&lt;/h4&gt;TriHetGCN模型包含拓扑特征构建、图结构表示和连接概率预测三个模块，利用三度闭包和度异质性等拓扑指示符来提高预测能力。&lt;h4&gt;主要发现&lt;/h4&gt;在九个真实世界数据集上的评估中，TriHetGCN模型取得了最先进的性能，超越了主流方法，表现出较强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TriHetGCN模型提供了一个连接统计物理和图深度学习的有希望的框架，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction aims to estimate the likelihood of connections between pairsof nodes in complex networks, which is beneficial to many applications fromfriend recommendation to metabolic network reconstruction. Traditionalheuristic-based methodologies in the field of complex networks typically dependon predefined assumptions about node connectivity, limiting theirgeneralizability across diverse networks. While recent graph neural network(GNN) approaches capture global structural features effectively, they oftenneglect node attributes and intrinsic structural relationships between nodepairs. To address this, we propose TriHetGCN, an extension of traditional GraphConvolutional Networks (GCNs) that incorporates explicit topological indicators-- triadic closure and degree heterogeneity. TriHetGCN consists of threemodules: topology feature construction, graph structural representation, andconnection probability prediction. The topology feature module constructs nodefeatures using shortest path distances to anchor nodes, enhancing globalstructure perception. The graph structural module integrates topologicalindicators into the GCN framework to model triadic closure and heterogeneity.The connection probability module uses deep learning to predict links.Evaluated on nine real-world datasets, from traditional networks without nodeattributes to large-scale networks with rich features, TriHetGCN achievesstate-of-the-art performance, outperforming mainstream methods. This highlightsits strong generalization across diverse network types, offering a promisingframework that bridges statistical physics and graph deep learning.</description>
      <author>example@mail.com (Ke-ke Shang, Junfan Yi, Michael Small, Yijie Zhou)</author>
      <guid isPermaLink="false">2504.20492v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TimeSoccer是一种新的足球视频多模态大型语言模型，用于全场比赛视频的密集视频字幕生成（SDVC），通过引入MoFA-Select模块和联合预测时间戳和字幕，实现了长视频理解并达到先进性能。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的运动赛事，通常具有长时间的赛程和独特的精彩时刻。现有的足球多模态大型语言模型在字幕生成时依赖时间先验知识，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的问题，提出TimeSoccer，旨在实现全场比赛视频的端到端密集视频字幕生成，并生成高质量、时间对齐准确、语义相关的评论。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer联合预测时间戳和字幕，一次生成，并在45分钟的比赛中进行全局上下文建模。MoFA-Select是一个无训练的动觉帧压缩模块，通过粗到细的策略自适应选择代表性帧，并采用补充训练范式加强模型处理长时序的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进（SoTA）的性能，能够生成高质量、时间对齐准确、语义相关的评论。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer在足球视频字幕生成方面取得了显著进步，为长视频理解提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v3</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Laplacian Positional Encodings for Heterophilous Graphs</title>
      <link>http://arxiv.org/abs/2504.20430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AISTATS 2025; version with full appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从理论上证明了当前图位置编码（PEs）在处理异质图任务时可能不利于性能，甚至可能损害性能。为了解决这一局限性，提出了可学习的拉普拉斯位置编码（LLPE），它能够利用图拉普拉斯的全谱，从而在亲缘性和异质图上捕捉图结构。&lt;h4&gt;背景&lt;/h4&gt;许多现实世界的网络表现出异质性，即使是高度同质性的图也可能包含局部强异质性的区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的PE方法，以有效捕捉异质图中的复杂结构。&lt;h4&gt;方法&lt;/h4&gt;提出了Learnable Laplacian Positional Encodings (LLPE)，并通过理论证明和实证评估来验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;LLPE能够近似一类通用的图距离，并在12个基准数据集上对多种GNN（包括图变换器）进行了评估，结果表明LLPE在合成和现实世界的图上分别提高了35%和14%的准确率。&lt;h4&gt;结论&lt;/h4&gt;LLPE是向开发能够有效捕捉异质图中复杂结构的位置编码方法迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we theoretically demonstrate that current graph positional encodings (PEs) are not beneficial and could potentially hurt performance in tasks involving heterophilous graphs, where nodes that are close tend to have different labels. This limitation is critical as many real-world networks exhibit heterophily, and even highly homophilous graphs can contain local regions of strong heterophily. To address this limitation, we propose Learnable Laplacian Positional Encodings (LLPE), a new PE that leverages the full spectrum of the graph Laplacian, enabling them to capture graph structure on both homophilous and heterophilous graphs. Theoretically, we prove LLPE's ability to approximate a general class of graph distances and demonstrate its generalization properties. Empirically, our evaluation on 12 benchmarks demonstrates that LLPE improves accuracy across a variety of GNNs, including graph transformers, by up to 35% and 14% on synthetic and real-world graphs, respectively. Going forward, our work represents a significant step towards developing PEs that effectively capture complex structures in heterophilous graphs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we theoretically demonstrate that current graph positionalencodings (PEs) are not beneficial and could potentially hurt performance intasks involving heterophilous graphs, where nodes that are close tend to havedifferent labels. This limitation is critical as many real-world networksexhibit heterophily, and even highly homophilous graphs can contain localregions of strong heterophily. To address this limitation, we propose LearnableLaplacian Positional Encodings (LLPE), a new PE that leverages the fullspectrum of the graph Laplacian, enabling them to capture graph structure onboth homophilous and heterophilous graphs. Theoretically, we prove LLPE'sability to approximate a general class of graph distances and demonstrate itsgeneralization properties. Empirically, our evaluation on 12 benchmarksdemonstrates that LLPE improves accuracy across a variety of GNNs, includinggraph transformers, by up to 35% and 14% on synthetic and real-world graphs,respectively. Going forward, our work represents a significant step towardsdeveloping PEs that effectively capture complex structures in heterophilousgraphs.</description>
      <author>example@mail.com (Michael Ito, Jiong Zhu, Dexiong Chen, Danai Koutra, Jenna Wiens)</author>
      <guid isPermaLink="false">2504.20430v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Understanding GNNs and Homophily in Dynamic Node Classification</title>
      <link>http://arxiv.org/abs/2504.20421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AISTATS 2025; version with full appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态图中的同质性，提出了一个新的同质性度量方法，并探讨了其在图神经网络（GNN）性能上的应用。&lt;h4&gt;背景&lt;/h4&gt;同质性作为度量，对于理解图神经网络（GNN）至关重要，但至今为止，这一度量仅在静态图环境中进行分析。&lt;h4&gt;目的&lt;/h4&gt;探索动态环境中的同质性，并提出一种适用于动态环境的新同质性度量方法。&lt;h4&gt;方法&lt;/h4&gt;重点关注图卷积网络（GCN），理论上证明了在动态环境中，当前GCN的判别性能由节点未来标签与其邻居当前标签相同性的概率决定。&lt;h4&gt;主要发现&lt;/h4&gt;提出了动态同质性，这一新度量与GNN的判别性能相关，并揭示了如何设计更强大的GNN以适应动态图。&lt;h4&gt;结论&lt;/h4&gt;本文的研究工作对于理解同质性和GNN在动态节点分类中的性能具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Homophily, as a measure, has been critical to increasing our understanding of graph neural networks (GNNs). However, to date this measure has only been analyzed in the context of static graphs. In our work, we explore homophily in dynamic settings. Focusing on graph convolutional networks (GCNs), we demonstrate theoretically that in dynamic settings, current GCN discriminative performance is characterized by the probability that a node's future label is the same as its neighbors' current labels. Based on this insight, we propose dynamic homophily, a new measure of homophily that applies in the dynamic setting. This new measure correlates with GNN discriminative performance and sheds light on how to potentially design more powerful GNNs for dynamic graphs. Leveraging a variety of dynamic node classification datasets, we demonstrate that popular GNNs are not robust to low dynamic homophily. Going forward, our work represents an important step towards understanding homophily and GNN performance in dynamic node classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Homophily, as a measure, has been critical to increasing our understanding ofgraph neural networks (GNNs). However, to date this measure has only beenanalyzed in the context of static graphs. In our work, we explore homophily indynamic settings. Focusing on graph convolutional networks (GCNs), wedemonstrate theoretically that in dynamic settings, current GCN discriminativeperformance is characterized by the probability that a node's future label isthe same as its neighbors' current labels. Based on this insight, we proposedynamic homophily, a new measure of homophily that applies in the dynamicsetting. This new measure correlates with GNN discriminative performance andsheds light on how to potentially design more powerful GNNs for dynamic graphs.Leveraging a variety of dynamic node classification datasets, we demonstratethat popular GNNs are not robust to low dynamic homophily. Going forward, ourwork represents an important step towards understanding homophily and GNNperformance in dynamic node classification.</description>
      <author>example@mail.com (Michael Ito, Danai Koutra, Jenna Wiens)</author>
      <guid isPermaLink="false">2504.20421v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs</title>
      <link>http://arxiv.org/abs/2504.20406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型和公开的脚本指南构建离线模拟框架的方法，以自动化任务和定制软件工作流程，旨在解决传统脚本创建的障碍。&lt;h4&gt;背景&lt;/h4&gt;脚本接口允许用户自动化任务和定制软件工作流程，但创建脚本通常需要编程专长和对特定API的熟悉度，这对许多用户来说构成了障碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决运行时代码生成的问题，如未验证的代码、安全风险、较长的响应时间和较高的计算成本，本文旨在通过构建一个离线模拟框架来创建软件特定的技能集。&lt;h4&gt;方法&lt;/h4&gt;该框架包括两个组件：（1）任务创建，使用自上而下的功能指导和自下而上的API协同探索来生成有用的任务；（2）技能生成，通过试验、优化和验证脚本，基于执行反馈来生成技能。为了高效地导航广泛的API景观，引入了一个基于图神经网络（GNN）的链接预测模型来捕捉API协同，从而生成涉及未充分利用的API的技能，并扩展技能集的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;Adobe Illustrator的实验表明，与传统的运行时代码生成相比，该框架显著提高了自动化成功率，减少了响应时间，并节省了运行时令牌成本。&lt;h4&gt;结论&lt;/h4&gt;这是首次尝试将软件脚本接口作为基于LLM系统的测试平台，强调了在受控环境中利用执行反馈的优势，并为将AI能力与用户需求对齐提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;Scripting interfaces enable users to automate tasks and customize software workflows, but creating scripts traditionally requires programming expertise and familiarity with specific APIs, posing barriers for many users. While Large Language Models (LLMs) can generate code from natural language queries, runtime code generation is severely limited due to unverified code, security risks, longer response times, and higher computational costs. To bridge the gap, we propose an offline simulation framework to curate a software-specific skillset, a collection of verified scripts, by exploiting LLMs and publicly available scripting guides. Our framework comprises two components: (1) task creation, using top-down functionality guidance and bottom-up API synergy exploration to generate helpful tasks; and (2) skill generation with trials, refining and validating scripts based on execution feedback. To efficiently navigate the extensive API landscape, we introduce a Graph Neural Network (GNN)-based link prediction model to capture API synergy, enabling the generation of skills involving underutilized APIs and expanding the skillset's diversity. Experiments with Adobe Illustrator demonstrate that our framework significantly improves automation success rates, reduces response time, and saves runtime token costs compared to traditional runtime code generation. This is the first attempt to use software scripting interfaces as a testbed for LLM-based systems, highlighting the advantages of leveraging execution feedback in a controlled environment and offering valuable insights into aligning AI capabilities with user needs in specialized software domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scripting interfaces enable users to automate tasks and customize softwareworkflows, but creating scripts traditionally requires programming expertiseand familiarity with specific APIs, posing barriers for many users. While LargeLanguage Models (LLMs) can generate code from natural language queries, runtimecode generation is severely limited due to unverified code, security risks,longer response times, and higher computational costs. To bridge the gap, wepropose an offline simulation framework to curate a software-specific skillset,a collection of verified scripts, by exploiting LLMs and publicly availablescripting guides. Our framework comprises two components: (1) task creation,using top-down functionality guidance and bottom-up API synergy exploration togenerate helpful tasks; and (2) skill generation with trials, refining andvalidating scripts based on execution feedback. To efficiently navigate theextensive API landscape, we introduce a Graph Neural Network (GNN)-based linkprediction model to capture API synergy, enabling the generation of skillsinvolving underutilized APIs and expanding the skillset's diversity.Experiments with Adobe Illustrator demonstrate that our framework significantlyimproves automation success rates, reduces response time, and saves runtimetoken costs compared to traditional runtime code generation. This is the firstattempt to use software scripting interfaces as a testbed for LLM-basedsystems, highlighting the advantages of leveraging execution feedback in acontrolled environment and offering valuable insights into aligning AIcapabilities with user needs in specialized software domains.</description>
      <author>example@mail.com (Paiheng Xu, Gang Wu, Xiang Chen, Tong Yu, Chang Xiao, Franck Dernoncourt, Tianyi Zhou, Wei Ai, Viswanathan Swaminathan)</author>
      <guid isPermaLink="false">2504.20406v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Generative Diffusion Models for Resource Allocation in Wireless Networks</title>
      <link>http://arxiv.org/abs/2504.20277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成扩散模型（GDMs）的监督训练算法，用于学习随机资源分配策略。&lt;h4&gt;背景&lt;/h4&gt;资源分配问题被表述为在满足稳态服务质量（QoS）约束下最大化稳态效用函数。&lt;h4&gt;目的&lt;/h4&gt;目的是训练一个GDM策略来模仿专家政策，并从最优分布中生成新的样本。&lt;h4&gt;方法&lt;/h4&gt;通过序列执行生成的样本来达到近最优性能。为了使算法适用于多种网络配置，使用图神经网络（GNN）架构参数化反向扩散过程。&lt;h4&gt;主要发现&lt;/h4&gt;在多用户干扰网络中的功率控制案例研究中，展示了数值结果。&lt;h4&gt;结论&lt;/h4&gt;该算法能够通过生成扩散模型学习到近最优的资源分配策略，并能够适应不同的网络配置。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a supervised training algorithm for learning stochasticresource allocation policies with generative diffusion models (GDMs). Weformulate the allocation problem as the maximization of an ergodic utilityfunction subject to ergodic Quality of Service (QoS) constraints. Given samplesfrom a stochastic expert policy that yields a near-optimal solution to theproblem, we train a GDM policy to imitate the expert and generate new samplesfrom the optimal distribution. We achieve near-optimal performance throughsequential execution of the generated samples. To enable generalization to afamily of network configurations, we parameterize the backward diffusionprocess with a graph neural network (GNN) architecture. We present numericalresults in a case study of power control in multi-user interference networks.</description>
      <author>example@mail.com (Yigit Berkay Uslu, Samar Hadou, Shirin Saeedi Bidokhti, Alejandro Ribeiro)</author>
      <guid isPermaLink="false">2504.20277v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hierarchical Interaction for Accurate Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.20127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HimNet的新型模型，用于预测分子的ADMET属性，通过层次交互信息传递机制，实现了对分子结构的有效捕捉和特征提取，提高了分子属性预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;在药物发现过程中，发现具有理想分子属性的分子至关重要。现有的方法通常使用深度学习模型，如图神经网络（GNNs）和Transformer，通过学习化学信息来预测这些分子属性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型在捕捉分子结构层次性和多级特征交互方面存在的不足，提出了一种新的层次交互信息传递机制。&lt;h4&gt;方法&lt;/h4&gt;该方法通过层次注意力引导的信息传递，实现了在原子、基序和分子层面的交互感知表示学习，从而有效平衡全局和局部信息。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的实验表明，HimNet在大多数分子属性预测任务中取得了最佳或接近最佳的性能，并且表现出良好的层次可解释性，与化学直觉相符。&lt;h4&gt;结论&lt;/h4&gt;HimNet为分子活性和ADMET属性预测提供了一种准确且高效的方法，对药物发现早期阶段的决策具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在药物发现中，发现具有理想分子属性（包括ADMET特性）的分子至关重要。现有方法通常采用深度学习模型，如图神经网络（GNNs）和Transformer，通过学习多样化的化学信息来预测这些分子属性。然而，这些模型往往无法有效地捕捉和利用分子结构的层次性，并且缺乏多级特征之间有效交互的机制。为了解决这些限制，我们提出了一种层次交互信息传递机制，作为我们新颖模型HimNet的基础。我们的方法通过层次注意力引导的信息传递，实现了在原子、基序和分子层面的交互感知表示学习。这种设计使得HimNet能够有效地平衡全局和局部信息，确保为下游属性预测任务（如血脑屏障通透性BBBP）提供丰富且与任务相关的特征提取。在多个基准数据集上的大量实验表明，HimNet在大多数分子属性预测任务中实现了最佳或接近最佳的性能。此外，我们的方法表现出有希望的结构可解释性，与代表性分子的化学直觉相吻合。我们相信，HimNet为分子活性和ADMET属性预测提供了一种准确且高效的方法，对药物发现早期阶段的决策具有重大贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discovering molecules with desirable molecular properties, including ADMET(Absorption, Distribution, Metabolism, Excretion, and Toxicity) profiles, is ofgreat importance in drug discovery. Existing approaches typically employ deeplearning models, such as Graph Neural Networks (GNNs) and Transformers, topredict these molecular properties by learning from diverse chemicalinformation. However, these models often fail to efficiently capture andutilize the hierarchical nature of molecular structures, and lack mechanismsfor effective interaction among multi-level features. To address theselimitations, we propose a Hierarchical Interaction Message Passing Mechanism,which serves as the foundation of our novel model, HimNet. Our method enablesinteraction-aware representation learning across atomic, motif, and molecularlevels via hierarchical attention-guided message passing. This design allowsHimNet to effectively balance global and local information, ensuring rich andtask-relevant feature extraction for downstream property prediction tasks, suchas Blood-Brain Barrier Permeability (BBBP). Extensive experiments on multiplebenchmark datasets demonstrate that HimNet achieves the best or near-bestperformance in most molecular property prediction tasks. Furthermore, ourmethod exhibits promising hierarchical interpretability, aligning well withchemical intuition on representative molecules. We believe that HimNet offersan accurate and efficient solution for molecular activity and ADMET propertyprediction, contributing significantly to advanced decision-making in the earlystages of drug discovery.</description>
      <author>example@mail.com (Huiyang Hong, Xinkai Wu, Hongyu Sun, Qi Wang, Yuquan Li)</author>
      <guid isPermaLink="false">2504.20127v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>If Concept Bottlenecks are the Question, are Foundation Models the Answer?</title>
      <link>http://arxiv.org/abs/2504.19774v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概念瓶颈模型（CBMs），这是一种结合高性能和先验可解释性的神经网络。&lt;h4&gt;背景&lt;/h4&gt;CBMs通过将输入（如图像）映射到高级概念（如可见物体及其属性），然后以可解释的方式使用这些概念解决下游任务（如图像标签或评分）。然而，这些模型的表现和可解释性依赖于它们学习到的概念质量。&lt;h4&gt;目的&lt;/h4&gt;研究使用VLM-CBM架构代替手动标注（专家标注）的方法，以及这种做法对学习到的概念质量的影响。&lt;h4&gt;方法&lt;/h4&gt;研究者通过实证分析，使用一系列重要的指标来测试最先进的VLM-CBMs，并评估其学习到的概念。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，VLM监督与专家标注在性能上可能存在明显差异，并且概念准确性和质量并不强烈相关。&lt;h4&gt;结论&lt;/h4&gt;本文的结论是，VLM监督在概念质量上可能不如专家标注，但其在某些任务中可以提供合理的性能。&lt;h4&gt;翻译&lt;/h4&gt;Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high-performance with ante-hoc interpretability. CBMs work by first mapping inputs (e.g., images) to high-level concepts (e.g., visible objects and their properties) and then use these to solve a downstream task (e.g., tagging or scoring an image) in an interpretable manner. Their performance and interpretability, however, hinge on the quality of the concepts they learn. The go-to strategy for ensuring good quality concepts is to leverage expert annotations, which are expensive to collect and seldom available in applications. Researchers have recently addressed this issue by introducing 'VLM-CBM' architectures that replace manual annotations with weak supervision from foundation models. It is, however, unclear what is the impact of doing so on the quality of the learned concepts. To answer this question, we put state-of-the-art VLM-CBMs to the test, analyzing their learned concepts empirically using a selection of significant metrics. Our results show that, depending on the task, VLM supervision can sensibly differ from expert annotations, and that concept accuracy and quality are not strongly correlated. Our code is available at https://github.com/debryu/CQA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Concept Bottleneck Models (CBMs) are neural networks designed to conjoin highperformance with ante-hoc interpretability. CBMs work by first mapping inputs(e.g., images) to high-level concepts (e.g., visible objects and theirproperties) and then use these to solve a downstream task (e.g., tagging orscoring an image) in an interpretable manner. Their performance andinterpretability, however, hinge on the quality of the concepts they learn. Thego-to strategy for ensuring good quality concepts is to leverage expertannotations, which are expensive to collect and seldom available inapplications. Researchers have recently addressed this issue by introducing"VLM-CBM" architectures that replace manual annotations with weak supervisionfrom foundation models. It is however unclear what is the impact of doing so onthe quality of the learned concepts. To answer this question, we putstate-of-the-art VLM-CBMs to the test, analyzing their learned conceptsempirically using a selection of significant metrics. Our results show that,depending on the task, VLM supervision can sensibly differ from expertannotations, and that concept accuracy and quality are not strongly correlated.Our code is available at https://github.com/debryu/CQA.</description>
      <author>example@mail.com (Nicola Debole, Pietro Barbiero, Francesco Giannini, Andrea Passerini, Stefano Teso, Emanuele Marconato)</author>
      <guid isPermaLink="false">2504.19774v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier</title>
      <link>http://arxiv.org/abs/2504.20124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于人工智能的诊断流程，利用Google的Health Acoustic Representations (HeAR)模型从儿童呼吸声音中检测哮喘的早期迹象。&lt;h4&gt;背景&lt;/h4&gt;早期检测儿童哮喘对于预防长期呼吸并发症和减少紧急干预至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够快速、非侵入性地筛查哮喘的方法。&lt;h4&gt;方法&lt;/h4&gt;使用SPRSound数据集，该数据集是第一个公开的、标注了1个月至18岁儿童呼吸声音的集合。数据集中的每个2秒音频片段被嵌入到512维度的表示中，使用的是在3亿个与健康相关的音频剪辑（包括1亿个咳嗽声音）上预训练的HeAR模型。然后，使用SVM、随机森林和MLP等多个分类器在这些嵌入上进行训练，以区分哮喘指示性声音和正常声音。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在分类任务上达到了超过91%的准确率，在正例的精确度-召回率指标上表现良好。通过PCA可视化学习到的嵌入，通过波形回放分析误分类，并提供了ROC和混淆矩阵的见解。&lt;h4&gt;结论&lt;/h4&gt;这种方法表明，由基础音频模型驱动的短、低资源的儿童录音可以实现快速、非侵入性的哮喘筛查，特别适用于远程或服务不足的医疗保健环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：儿童哮喘的早期检测对于预防长期呼吸并发症和减少紧急干预至关重要。本研究提出了一种基于人工智能的诊断流程，利用Google的Health Acoustic Representations (HeAR)模型从儿童呼吸声音中检测哮喘的早期迹象。使用SPRSound数据集，该数据集是第一个公开的、标注了1个月至18岁儿童呼吸声音的集合。数据集中的每个2秒音频片段被嵌入到512维度的表示中，使用的是在3亿个与健康相关的音频剪辑（包括1亿个咳嗽声音）上预训练的HeAR模型。然后，使用SVM、随机森林和MLP等多个分类器在这些嵌入上进行训练，以区分哮喘指示性声音和正常声音。该系统在分类任务上达到了超过91%的准确率，在正例的精确度-召回率指标上表现良好。通过PCA可视化学习到的嵌入，通过波形回放分析误分类，并提供了ROC和混淆矩阵的见解。这种方法表明，由基础音频模型驱动的短、低资源的儿童录音可以实现快速、非侵入性的哮喘筛查，特别适用于远程或服务不足的医疗保健环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early detection of asthma in children is crucial to prevent long-termrespiratory complications and reduce emergency interventions. This workpresents an AI-powered diagnostic pipeline that leverages Googles HealthAcoustic Representations (HeAR) model to detect early signs of asthma frompediatric respiratory sounds. The SPRSound dataset, the first open-accesscollection of annotated respiratory sounds in children aged 1 month to 18years, is used to extract 2-second audio segments labeled as wheeze, crackle,rhonchi, stridor, or normal. Each segment is embedded into a 512-dimensionalrepresentation using HeAR, a foundation model pretrained on 300 millionhealth-related audio clips, including 100 million cough sounds. Multipleclassifiers, including SVM, Random Forest, and MLP, are trained on theseembeddings to distinguish between asthma-indicative and normal sounds. Thesystem achieves over 91\% accuracy, with strong performance on precision-recallmetrics for positive cases. In addition to classification, learned embeddingsare visualized using PCA, misclassifications are analyzed through waveformplayback, and ROC and confusion matrix insights are provided. This methoddemonstrates that short, low-resource pediatric recordings, when powered byfoundation audio models, can enable fast, noninvasive asthma screening. Theapproach is especially promising for digital diagnostics in remote orunderserved healthcare settings.</description>
      <author>example@mail.com (Abul Ehtesham, Saket Kumar, Aditi Singh, Tala Talaei Khoei)</author>
      <guid isPermaLink="false">2504.20124v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Informed Neural Operator Transformer</title>
      <link>http://arxiv.org/abs/2504.19452v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GINOT的几何信息神经网络算子Transformer，该模型结合了transformer架构和神经网络算子框架，实现了对任意几何形状的前向预测。&lt;h4&gt;背景&lt;/h4&gt;基于机器学习的代理模型在计算效率方面优于传统的数值方法，尤其在需要重复评估偏微分方程的问题中。&lt;h4&gt;目的&lt;/h4&gt;提出GINOT的目的是为了实现任意几何形状的前向预测。&lt;h4&gt;方法&lt;/h4&gt;GINOT通过采样和分组机制结合注意力机制对几何形状的点云进行编码，确保对点顺序和填充的不变性，同时保持对点密度变化的鲁棒性。几何信息通过注意力机制与解解码器中的查询点无缝集成。&lt;h4&gt;主要发现&lt;/h4&gt;GINOT在多个具有挑战性的数据集上进行了验证，展示了其在复杂和任意2D和3D几何形状上的高精度和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;GINOT是一种高效且准确的方法，可以用于对任意几何形状进行前向预测。&lt;h4&gt;翻译&lt;/h4&gt;Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface point cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based surrogate models offer significant computationalefficiency and faster simulations compared to traditional numerical methods,especially for problems requiring repeated evaluations of partial differentialequations. This work introduces the Geometry-Informed Neural OperatorTransformer (GINOT), which integrates the transformer architecture with theneural operator framework to enable forward predictions for arbitrarygeometries. GINOT encodes the surface points cloud of a geometry using asampling and grouping mechanism combined with an attention mechanism, ensuringinvariance to point order and padding while maintaining robustness tovariations in point density. The geometry information is seamlessly integratedwith query points in the solution decoder through the attention mechanism. Theperformance of GINOT is validated on multiple challenging datasets, showcasingits high accuracy and strong generalization capabilities for complex andarbitrary 2D and 3D geometries.</description>
      <author>example@mail.com (Qibang Liu, Vincient Zhong, Hadi Meidani, Diab Abueidda, Seid Koric, Philippe Geubelle)</author>
      <guid isPermaLink="false">2504.19452v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Pretraining for Material Property Prediction</title>
      <link>http://arxiv.org/abs/2504.20112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 7 figures, 2 algorithms, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的监督预训练方法，用于材料性能预测，通过使用可用的类别信息作为代理标签，提高了模型的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;准确预测材料性能对于发现具有定制功能的新型材料至关重要。深度学习模型在捕捉结构-性能关系方面表现出色，但通常依赖于需要大量、标注良好的数据集的监督学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过使用自我监督学习（SSL）和监督预训练来预测材料性能，以减少对大量标注数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;研究者提出了监督预训练，其中可用的类别信息作为代理标签来指导学习，并评估了这种方法在两个最先进的SSL模型上的效果。此外，他们还提出了一种基于图的增强技术，通过向材料图注入噪声来提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在六个具有挑战性的材料性能预测任务上进行了微调，平均绝对误差（MAE）提高了2%至6.67%，并建立了新的基准。&lt;h4&gt;结论&lt;/h4&gt;这项研究是第一次探索在材料性能预测中使用代理标签进行监督预训练，推动了该领域的方法和应用的进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测材料属性有助于发现具有定制功能的新型材料。最近，深度学习模型在捕捉结构-属性关系方面显示出优异的准确性和灵活性。然而，这些模型通常依赖于需要大量、标注良好的数据集的监督学习。自我监督学习（SSL）通过在大规模无标签数据集上预训练来开发可以微调用于材料属性预测的基础模型，提供了一种有希望的选择。在本工作中，我们提出了监督预训练，其中可用的类别信息作为代理标签来引导学习，即使下游任务涉及无关的材料属性。我们评估了这种策略在两个最先进的SSL模型上的效果，并介绍了一种新的监督预训练框架。为了进一步提高表示学习，我们提出了一种基于图的增强技术，通过向材料图注入噪声来提高鲁棒性，而不破坏材料图的结构。所得到的基模模型用于六个具有挑战性的材料性能预测任务，与基线相比，平均绝对误差（MAE）提高了2%至6.67%，并在材料性能预测中建立了新的基准。这项研究是第一次在材料性能预测中探索使用代理标签进行监督预训练，推动了该领域的方法和应用的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of material properties facilitates the discovery of novelmaterials with tailored functionalities. Deep learning models have recentlyshown superior accuracy and flexibility in capturing structure-propertyrelationships. However, these models often rely on supervised learning, whichrequires large, well-annotated datasets an expensive and time-consumingprocess. Self-supervised learning (SSL) offers a promising alternative bypretraining on large, unlabeled datasets to develop foundation models that canbe fine-tuned for material property prediction. In this work, we proposesupervised pretraining, where available class information serves as surrogatelabels to guide learning, even when downstream tasks involve unrelated materialproperties. We evaluate this strategy on two state-of-the-art SSL models andintroduce a novel framework for supervised pretraining. To further enhancerepresentation learning, we propose a graph-based augmentation technique thatinjects noise to improve robustness without structurally deforming materialgraphs. The resulting foundation models are fine-tuned for six challengingmaterial property predictions, achieving significant performance gains overbaselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE)and establishing a new benchmark in material property prediction. This studyrepresents the first exploration of supervised pertaining with surrogate labelsin material property prediction, advancing methodology and application in thefield.</description>
      <author>example@mail.com (Chowdhury Mohammad Abid Rahman, Aldo H. Romero, Prashnna K. Gyawali)</author>
      <guid isPermaLink="false">2504.20112v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous network drug-target interaction prediction model based on graph wavelet transform and multi-level contrastive learning</title>
      <link>http://arxiv.org/abs/2504.20103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种异构网络药物靶点相互作用预测框架，结合图神经网络和多尺度信号处理技术，构建了一个既高效预测又具有多层次可解释性的模型。&lt;h4&gt;背景&lt;/h4&gt;药物-靶点相互作用预测在生物医学领域的药物开发和精准医学中是一个核心任务。然而，传统的机器学习方法通常存在黑盒问题，这使得揭示模型决策机制与生物分子间相互作用模式之间的深层相关性变得困难。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提供一种从黑盒预测到机制解码的完整解决方案，以发现药物靶点。&lt;h4&gt;方法&lt;/h4&gt;该框架的技术突破主要体现在以下三个方面：1. 设计了基于异构图卷积神经网络（HGCN）的多阶邻域聚合策略；2. 提出了多尺度图信号分解和生物解释模块；3. 结合多维度视角和层次表示的对比学习，通过比较学习模型，将HGCN和GWT两个视角的节点表示对齐和融合，使模型能够整合多维度信息并提高预测鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在所有数据集上均表现出优异的预测性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为药物靶点发现提供了一种完整的解决方案，其方法论对于建模复杂的生物分子相互作用系统具有重要参考价值。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a heterogeneous network drug target interaction prediction framework, integrating graph neural network and multi scale signal processing technology to construct a model with both efficient prediction and multi level interpretability. The technical breakthroughs are mainly reflected in the following three dimensions: Local global feature collaborative perception module based on Heterogeneous Graph Convolutional Neural Network (HGCN), multi scale graph signal decomposition and biological interpretation module, and contrastive learning combining multi dimensional perspectives and hierarchical representations. The experimental results show that our framework shows excellent prediction performance on all datasets. This study provides a complete solution for drug target discovery from black box prediction to mechanism decoding, and its methodology has important reference value for modeling complex biomolecular interaction systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug-target interaction (DTI) prediction is a core task in drug developmentand precision medicine in the biomedical field. However, traditional machinelearning methods generally have the black box problem, which makes it difficultto reveal the deep correlation between the model decision mechanism and theinteraction pattern between biological molecules. This study proposes aheterogeneous network drug target interaction prediction framework, integratinggraph neural network and multi scale signal processing technology to constructa model with both efficient prediction and multi level interpretability. Itstechnical breakthroughs are mainly reflected in the following threedimensions:Local global feature collaborative perception module. Based onheterogeneous graph convolutional neural network (HGCN), a multi order neighboraggregation strategy is designed.Multi scale graph signal decomposition andbiological interpretation module. A deep hierarchical node feature transform(GWT) architecture is proposed.Contrastive learning combining multi dimensionalperspectives and hierarchical representations. By comparing the learningmodels, the node representations from the two perspectives of HGCN and GWT arealigned and fused, so that the model can integrate multi dimensionalinformation and improve the prediction robustness. Experimental results showthat our framework shows excellent prediction performance on all datasets. Thisstudy provides a complete solution for drug target discovery from black boxprediction to mechanism decoding, and its methodology has important referencevalue for modeling complex biomolecular interaction systems.</description>
      <author>example@mail.com (Wenfeng Dai, Yanhong Wang, Shuai Yan, Qingzhi Yu, Xiang Cheng)</author>
      <guid isPermaLink="false">2504.20103v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Attention to Detail: Fine-Scale Feature Preservation-Oriented Geometric Pre-training for AI-Driven Surrogate Modeling</title>
      <link>http://arxiv.org/abs/2504.20110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自监督几何表示学习方法，用于从非参数3D模型中捕捉精细几何特征，以支持数据稀缺场景下的代理建模。&lt;h4&gt;背景&lt;/h4&gt;AI驱动的代理建模正成为3D设计、分析和制造中替代基于物理模拟的有效方法，但这些方法通常需要大量的标记CAD到模拟数据集。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够捕捉精细几何特征的自监督几何表示学习方法，以支持需要精细几何细节的复杂应用。&lt;h4&gt;方法&lt;/h4&gt;该方法将几何特征提取与下游物理任务解耦，通过几何重建损失来学习一个潜在空间嵌入。它使用近零级采样和创新的批量自适应注意力加权损失函数，以增强对复杂设计特征的编码。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在结构力学案例研究中得到了验证，表现出在捕捉设计特征和实现准确的少样本物理预测方面的强大性能。&lt;h4&gt;结论&lt;/h4&gt;与传统参数化代理建模相比，该方法有望弥合几何和基于物理的表示之间的差距，为数据稀缺场景下的代理建模提供有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;AI驱动的代理建模已经成为3D设计、分析和制造中替代基于物理模拟的有效方法。这些模型利用数据驱动的方法来预测通常需要计算昂贵的模拟的物理量。然而，标记的CAD到模拟数据集的稀缺推动了自监督和基础模型最近的进步，其中几何表示学习是在线进行的，然后针对特定的下游任务进行微调。尽管这些方法显示出希望，但它们在需要精细尺度几何细节保留的应用中效果有限。这项工作介绍了一种自监督几何表示学习方法，旨在从非参数3D模型中捕获精细几何特征。与传统的端到端代理模型不同，这种方法将几何特征提取与下游物理任务解耦，通过几何重建损失学习一个潜在空间嵌入。关键元素包括近零级采样的基本使用和创新的批量自适应注意力加权损失函数，这些函数增强了复杂设计特征的编码。该方法通过结构力学案例研究得到了验证，证明了在捕捉设计特征和实现准确的少样本物理预测方面的强大性能。与传统参数化代理建模的比较突出了其弥合几何和基于物理表示之间差距的潜力，为数据稀缺场景下的代理建模提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI-driven surrogate modeling has become an increasingly effective alternativeto physics-based simulations for 3D design, analysis, and manufacturing. Thesemodels leverage data-driven methods to predict physical quantitiestraditionally requiring computationally expensive simulations. However, thescarcity of labeled CAD-to-simulation datasets has driven recent advancementsin self-supervised and foundation models, where geometric representationlearning is performed offline and later fine-tuned for specific downstreamtasks. While these approaches have shown promise, their effectiveness islimited in applications requiring fine-scale geometric detail preservation.This work introduces a self-supervised geometric representation learning methoddesigned to capture fine-scale geometric features from non-parametric 3Dmodels. Unlike traditional end-to-end surrogate models, this approach decouplesgeometric feature extraction from downstream physics tasks, learning a latentspace embedding guided by geometric reconstruction losses. Key elements includethe essential use of near-zero level sampling and the innovative batch-adaptiveattention-weighted loss function, which enhance the encoding of intricatedesign features. The proposed method is validated through case studies instructural mechanics, demonstrating strong performance in capturing designfeatures and enabling accurate few-shot physics predictions. Comparisons withtraditional parametric surrogate modeling highlight its potential to bridge thegap between geometric and physics-based representations, providing an effectivesolution for surrogate modeling in data-scarce scenarios.</description>
      <author>example@mail.com (Yu-hsuan Chen, Jing Bi, Cyril Ngo Ngoc, Victor Oancea, Jonathan Cagan, Levent Burak Kara)</author>
      <guid isPermaLink="false">2504.20110v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics</title>
      <link>http://arxiv.org/abs/2504.20099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Currently under review at the International Journal of Interactive  Multimedia and Artificial Intelligence (IJIMAI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了时间序列基础模型产生的潜在空间的可解释性，重点关注其在视觉分析任务中的潜力。&lt;h4&gt;背景&lt;/h4&gt;该研究评估了MOMENT系列模型，这是一组基于Transformer的预训练架构，用于处理多元时间序列任务，如数据插补、预测、分类和异常检测。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估这些模型在五个数据集上的能力，以捕捉时间序列数据在其潜在空间投影中的底层结构，并验证微调是否可以改善结果嵌入空间的清晰度。&lt;h4&gt;方法&lt;/h4&gt;研究人员对MOMENT模型进行了评估，并进行了微调以观察性能改进，同时进行了可视化分析以评估嵌入的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;微调后观察到损失减少方面的显著性能提升。可视化分析显示，嵌入的可解释性改善有限，需要进一步研究。&lt;h4&gt;结论&lt;/h4&gt;尽管MOMENT等时间序列基础模型稳健，但其潜在空间可能需要额外的方法论改进才能得到充分解释，例如替代投影技术、损失函数或数据预处理策略。尽管MOMENT存在局限性，但基础模型在执行时间上提供了大幅减少，这对于交互式可视化分析是一个重大进步。&lt;h4&gt;翻译&lt;/h4&gt;The present study explores the interpretability of latent spaces produced by time series foundation models, focusing on their potential for visual analysis tasks. Specifically, we evaluate the MOMENT family of models, a set of transformer-based, pre-trained architectures for multivariate time series tasks such as: imputation, prediction, classification, and anomaly detection. We evaluate the capacity of these models on five datasets to capture the underlying structures in time series data within their latent space projection and validate whether fine tuning improves the clarity of the resulting embedding spaces. Notable performance improvements in terms of loss reduction were observed after fine tuning. Visual analysis shows limited improvement in the interpretability of the embeddings, requiring further work. Results suggest that, although Time Series Foundation Models such as MOMENT are robust, their latent spaces may require additional methodological refinements to be adequately interpreted, such as alternative projection techniques, loss functions, or data preprocessing strategies. Despite the limitations of MOMENT, foundation models supose a big reduction in execution time and so a great advance for interactive visual analytics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The present study explores the interpretability of latent spaces produced bytime series foundation models, focusing on their potential for visual analysistasks. Specifically, we evaluate the MOMENT family of models, a set oftransformer-based, pre-trained architectures for multivariate time series taskssuch as: imputation, prediction, classification, and anomaly detection. Weevaluate the capacity of these models on five datasets to capture theunderlying structures in time series data within their latent space projectionand validate whether fine tuning improves the clarity of the resultingembedding spaces. Notable performance improvements in terms of loss reductionwere observed after fine tuning. Visual analysis shows limited improvement inthe interpretability of the embeddings, requiring further work. Results suggestthat, although Time Series Foundation Models such as MOMENT are robust, theirlatent spaces may require additional methodological refinements to beadequately interpreted, such as alternative projection techniques, lossfunctions, or data preprocessing strategies. Despite the limitations of MOMENT,foundation models supose a big reduction in execution time and so a greatadvance for interactive visual analytics.</description>
      <author>example@mail.com (Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, Javier Huertas-Tato, Jong Hyuk Park, David Camacho)</author>
      <guid isPermaLink="false">2504.20099v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction</title>
      <link>http://arxiv.org/abs/2504.20102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HyboWaveNet的深度学习框架，用于蛋白质-蛋白质相互作用（PPI）的预测，该框架结合了双曲图神经网络和多尺度图小波变换，以解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;蛋白质-蛋白质相互作用对于理解细胞功能、疾病途径和药物发现至关重要。现有方法在PPI预测方面虽然准确，但缺乏可解释性和难以捕捉蛋白质之间的层次几何和动态相互作用模式。&lt;h4&gt;目的&lt;/h4&gt;提出HyboWaveNet以解决现有PPI预测方法的局限性，提高预测结果的因果解释性和对多尺度动态相互作用模式的捕捉能力。&lt;h4&gt;方法&lt;/h4&gt;HyboWaveNet通过将蛋白质特征映射到洛伦兹空间，利用双曲距离度量模拟生物分子之间的层次拓扑关系。它结合了图神经网络和图小波变换，以自适应地提取不同分辨率下的局部和全局交互特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HyboWaveNet在公共数据集上优于现有方法，并且多尺度图小波变换模块提高了HyboWaveNet的预测性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HyboWaveNet将几何深度学习和信号处理相结合，为分析复杂生物系统提供了一种原则性的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein-protein interactions (PPIs) are fundamental for deciphering cellularfunctions,disease pathways,and drug discovery.Although existing neural networksand machine learning methods have achieved high accuracy in PPIprediction,their black-box nature leads to a lack of causal interpretation ofthe prediction results and difficulty in capturing hierarchical geometries andmulti-scale dynamic interaction patterns among proteins.To address thesechallenges, we propose HyboWaveNet,a novel deep learning framework thatcollaborates with hyperbolic graphical neural networks (HGNNs) and multiscalegraphical wavelet transform for robust PPI prediction. Mapping protein featuresto Lorentz space simulates hierarchical topological relationships amongbiomolecules via a hyperbolic distance metric,enabling node featurerepresentations that better fit biological a priori.HyboWaveNet inherentlysimulates hierarchical and scale-free biological relationships, while theintegration of wavelet transforms enables adaptive extraction of local andglobal interaction features across different resolutions. Our frameworkgenerates node feature representations via a graph neural network under theLorenz model and generates pairs of positive samples under multiple differentviews for comparative learning, followed by further feature extraction viamulti-scale graph wavelet transforms to predict potential PPIs. Experiments onpublic datasets show that HyboWaveNet improves over both existingstate-of-the-art methods. We also demonstrate through ablation experimentalstudies that the multi-scale graph wavelet transform module improves thepredictive performance and generalization ability of HyboWaveNet. This worklinks geometric deep learning and signal processing to advance PPI prediction,providing a principled approach for analyzing complex biological systems</description>
      <author>example@mail.com (Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng)</author>
      <guid isPermaLink="false">2504.20102v1</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>Perception Encoder: The best visual embeddings are not at the output of the network</title>
      <link>http://arxiv.org/abs/2504.13181v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Updated refs, fixed typos, and added new COCO SotA: 66.0 val mAP!  Code, models, and data at  https://github.com/facebookresearch/perception_models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为感知编码器（PE）的先进视觉编码器，用于图像和视频理解。通过简单的视觉-语言学习进行训练，该编码器在多种下游任务上表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉编码器依赖于多种预训练目标，针对分类、字幕或定位等特定任务进行优化。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够通过简单的视觉-语言学习训练，并在多个下游任务上取得优异表现的视觉编码器。&lt;h4&gt;方法&lt;/h4&gt;采用精心调整的图像预训练食谱和强大的视频数据引擎进行训练，并通过语言对齐和空间对齐两种方法提取隐藏在中间层的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;对比视觉-语言训练单独就能产生强大的通用嵌入，适用于多种下游任务。PE系列模型在多种任务上达到最佳水平，包括零样本图像和视频分类与检索，文档、图像和视频问答，以及空间任务如检测、跟踪和深度估计。&lt;h4&gt;结论&lt;/h4&gt;PE系列模型在多个视觉理解任务上取得了最先进的成果，并发布了相关模型、代码和新型数据集。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为感知编码器（PE）的先进视觉编码器，用于图像和视频理解。通过简单的视觉-语言学习进行训练，该编码器在多种下游任务上表现出色。传统的视觉编码器依赖于多种预训练目标，针对分类、字幕或定位等特定任务进行优化。本文的目的是开发一种能够通过简单的视觉-语言学习训练，并在多个下游任务上取得优异表现的视觉编码器。采用精心调整的图像预训练食谱和强大的视频数据引擎进行训练，并通过语言对齐和空间对齐两种方法提取隐藏在中间层的嵌入。研究发现，对比视觉-语言训练单独就能产生强大的通用嵌入，适用于多种下游任务。PE系列模型在多种任务上达到最佳水平，包括零样本图像和视频分类与检索，文档、图像和视频问答，以及空间任务如检测、跟踪和深度估计。结论是，PE系列模型在多个视觉理解任务上取得了最先进的成果，并发布了相关模型、代码和新型数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Perception Encoder (PE), a state-of-the-art vision encoder forimage and video understanding trained via simple vision-language learning.Traditionally, vision encoders have relied on a variety of pretrainingobjectives, each tailored to specific downstream tasks such as classification,captioning, or localization. Surprisingly, after scaling our carefully tunedimage pretraining recipe and refining with our robust video data engine, wefind that contrastive vision-language training alone can produce strong,general embeddings for all of these downstream tasks. There is only one caveat:these embeddings are hidden within the intermediate layers of the network. Todraw them out, we introduce two alignment methods: language alignment formultimodal language modeling, and spatial alignment for dense prediction.Together, our PE family of models achieves best-in-class results on a widevariety of tasks, including (1) zero-shot image and video classification andretrieval, simultaneously obtaining 86.6 average zero-shot ImageNet robustnessand 76.9 zero-shot Kinetics-400 video classification; (2) document, image, andvideo Q&amp;A, enabling 94.6 DocVQA, 80.9 InfographicVQA, and 82.7 PerceptionTestwith an 8B LLM; and (3) spatial tasks such as detection, tracking, and depthestimation, setting a new COCO state-of-the-art of 66.0 box mAP. To fosterfurther research, we release our models, code, and novel dataset ofsynthetically and human-annotated videos:https://github.com/facebookresearch/perception_models</description>
      <author>example@mail.com (Daniel Bolya, Po-Yao Huang, Peize Sun, Jang Hyun Cho, Andrea Madotto, Chen Wei, Tengyu Ma, Jiale Zhi, Jathushan Rajasegaran, Hanoona Rasheed, Junke Wang, Marco Monteiro, Hu Xu, Shiyu Dong, Nikhila Ravi, Daniel Li, Piotr Dollár, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13181v2</guid>
      <pubDate>Wed, 30 Apr 2025 14:15:18 +0800</pubDate>
    </item>
    <item>
      <title>QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds</title>
      <link>http://arxiv.org/abs/2504.19716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级的解析方法，用于机器人抓取规划，特别是针对抗对称抓取，这种方法在六自由度空间中几乎不进行采样。&lt;h4&gt;背景&lt;/h4&gt;抓取一直是机器人与环境之间最终接口的一个长期挑战。随着环境和任务的复杂化，嵌入更高智能以从周围环境中推断并对其采取行动的需求变得必要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有抓取规划方法在现实生活中的泛化能力差、生成抓取计划所需时间过长以及缺乏可重复性等问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于优化的抓取规划算法，通过在物体表面上估计抓取点来解决问题，而不是直接估计末端执行器的位置。此外，提出了一种软区域生长算法，用于有效分割平面，即使在曲面上也能有效工作。&lt;h4&gt;主要发现&lt;/h4&gt;该抓取框架在多个模拟物体上与现有的抓取规划方法Grasp Pose Detection (GPD)进行了比较，并使用图像和点云数据在现实世界中进行了评估，结果显示了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;与GPD相比，本文提出的方法在模拟和现实世界的抓取规划中表现出更高的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：抓取一直是机器人与环境之间最终接口的一个长期挑战。随着环境和任务的复杂化，嵌入更高智能以从周围环境中推断并对其采取行动的需求变得必要。尽管大多数方法利用技术来通过在六自由度空间中采用纯采样方法或作为学习问题来处理估计抓取位姿的问题，但它们通常由于跨领域泛化能力差而在现实生活中的设置中失败。此外，由于采样效率低下和现有抓取规划方法的概率性质，生成抓取计划所需的时间以及缺乏可重复性严重限制了它们在现实世界任务中的应用。本文提出了一种轻量级的解析方法，用于机器人抓取规划，特别是抗对称抓取，这种方法在六自由度空间中几乎不进行采样。所提出的抓取规划算法被表述为一个优化问题，用于估计物体表面上的抓取点，而不是直接估计末端执行器的位置。为此，提出了一种软区域生长算法，用于有效分割平面，即使在曲面上也能有效工作。然后使用基于优化的质量指标来评估抓取点，以确保间接力闭合。所提出的抓取框架与现有的最先进的抓取规划方法Grasp Pose Detection (GPD)在多个模拟物体上进行了比较，作为一个基线。与GPD相比，本文提出的方法在模拟和现实世界的抓取规划中表现出更高的效率和质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping has been a long-standing challenge in facilitating the finalinterface between a robot and the environment. As environments and tasks becomecomplicated, the need to embed higher intelligence to infer from thesurroundings and act on them has become necessary. Although most methodsutilize techniques to estimate grasp pose by treating the problem via puresampling-based approaches in the six-degree-of-freedom space or as a learningproblem, they usually fail in real-life settings owing to poor generalizationacross domains. In addition, the time taken to generate the grasp plan and thelack of repeatability, owing to sampling inefficiency and the probabilisticnature of existing grasp planning approaches, severely limits their applicationin real-world tasks. This paper presents a lightweight analytical approachtowards robotic grasp planning, particularly antipodal grasps, with little tono sampling in the six-degree-of-freedom space. The proposed grasp planningalgorithm is formulated as an optimization problem towards estimating grasppoints on the object surface instead of directly estimating the end-effectorpose. To this extent, a soft-region-growing algorithm is presented foreffective plane segmentation, even in the case of curved surfaces. Anoptimization-based quality metric is then used for the evaluation of grasppoints to ensure indirect force closure. The proposed grasp framework iscompared with the existing state-of-the-art grasp planning approach, Grasp posedetection (GPD), as a baseline over multiple simulated objects. Theeffectiveness of the proposed approach in comparison to GPD is also evaluatedin a real-world setting using image and point-cloud data, with the plannedgrasps being executed using a ROBOTIQ gripper and UR5 manipulator.</description>
      <author>example@mail.com (Navin Sriram Ravie, Keerthi Vasan M, Asokan Thondiyath, Bijo Sebastian)</author>
      <guid isPermaLink="false">2504.19716v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
  <item>
      <title>WLTCL: Wide Field-of-View 3-D LiDAR Truck Compartment Automatic Localization System</title>
      <link>http://arxiv.org/abs/2504.18870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in IEEE TIM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种创新的宽视场3D激光雷达车辆舱自动定位系统，以提高物流自动化中的操作效率和安全性。&lt;h4&gt;背景&lt;/h4&gt;自动化装载系统是物流自动化的重要组成部分，但在不同尺寸的货车舱中进行精确自动定位存在挑战，包括适应性、统一坐标系和可靠性问题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有方法的局限性，实现大、中、小尺寸围栏式货车舱在杂乱环境中的关键点精确自动定位。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用LiDAR生成宽视场范围内高密度点云的方法，结合停车区域约束进行车辆点云分割，以及利用货车舱的几何特征进行关键点定位。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该系统具有可靠的定位精度和降低的计算资源消耗。&lt;h4&gt;结论&lt;/h4&gt;该系统能够应用于相关领域，提升物流自动化水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As an essential component of logistics automation, the automated loadingsystem is becoming a critical technology for enhancing operational efficiencyand safety. Precise automatic positioning of the truck compartment, whichserves as the loading area, is the primary step in automated loading. However,existing methods have difficulty adapting to truck compartments of varioussizes, do not establish a unified coordinate system for LiDAR and mobilemanipulators, and often exhibit reliability issues in cluttered environments.To address these limitations, our study focuses on achieving precise automaticpositioning of key points in large, medium, and small fence-style truckcompartments in cluttered scenarios. We propose an innovative widefield-of-view 3-D LiDAR vehicle compartment automatic localization system. Forvehicles of various sizes, this system leverages the LiDAR to generatehigh-density point clouds within an extensive field-of-view range. Byincorporating parking area constraints, our vehicle point cloud segmentationmethod more effectively segments vehicle point clouds within the scene. Ourcompartment key point positioning algorithm utilizes the geometric features ofthe compartments to accurately locate the corner points, providing stackablespatial regions. Extensive experiments on our collected data and publicdatasets demonstrate that this system offers reliable positioning accuracy andreduced computational resource consumption, leading to its application andpromotion in relevant fields.</description>
      <author>example@mail.com (Guodong Sun, Mingjing Li, Dingjie Liu, Mingxuan Liu, Bo Wu, Yang Zhang)</author>
      <guid isPermaLink="false">2504.18870v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning</title>
      <link>http://arxiv.org/abs/2504.20024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://spatial-reasoner.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为SpatialReasoner的新颖的大视觉语言模型（LVLM），用于解决3D空间推理问题，并通过显式的3D表示在3D感知、计算和推理阶段之间共享，从而提高了空间推理的性能，并研究了LVLM在3D空间推理中可能出现的错误。&lt;h4&gt;背景&lt;/h4&gt;近期研究探索了基于数据驱动的3D空间推理方法，并使用强化学习（RL）实现了空间推理性能的提升。然而，这些方法通常以隐式的方式进行空间推理，且未充分研究在训练过程中获得的3D知识是否能够泛化到未见过的问答类型。&lt;h4&gt;目的&lt;/h4&gt;提出SpatialReasoner模型，旨在通过显式的3D表示来增强3D空间推理，并研究LVLM在3D空间推理中可能出现的错误。&lt;h4&gt;方法&lt;/h4&gt;SpatialReasoner模型采用了大视觉语言模型，并在3D感知、计算和推理阶段之间共享显式的3D表示，以支持高级3D空间推理。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialReasoner在多种空间推理基准测试中实现了改进的性能，并且在评估新颖的3D空间推理问题时表现出更好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究将先前视觉基础模型的3D解析能力与大型语言模型的强大推理能力相结合，为3D空间推理开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;Recent studies in 3D spatial reasoning explore data-driven approaches and achieve enhanced spatial reasoning performance with reinforcement learning (RL). However, these methods typically perform spatial reasoning in an implicit manner, and it remains underexplored whether the acquired 3D knowledge generalizes to unseen question types at any stage of the training. In this work we introduce SpatialReasoner, a novel large vision-language model (LVLM) that address 3D spatial reasoning with explicit 3D representations shared between stages -- 3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and enable us to study the factual errors made by LVLMs. Results show that our SpatialReasoner achieve improved performance on a variety of spatial reasoning benchmarks and generalizes better when evaluating on novel 3D spatial reasoning questions. Our study bridges the 3D parsing capabilities of prior visual foundation models with the powerful reasoning abilities of large language models, opening new directions for 3D spatial reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies in 3D spatial reasoning explore data-driven approaches andachieve enhanced spatial reasoning performance with reinforcement learning(RL). However, these methods typically perform spatial reasoning in an implicitmanner, and it remains underexplored whether the acquired 3D knowledgegeneralizes to unseen question types at any stage of the training. In this workwe introduce SpatialReasoner, a novel large vision-language model (LVLM) thataddress 3D spatial reasoning with explicit 3D representations shared betweenstages -- 3D perception, computation, and reasoning. Explicit 3Drepresentations provide a coherent interface that supports advanced 3D spatialreasoning and enable us to study the factual errors made by LVLMs. Results showthat our SpatialReasoner achieve improved performance on a variety of spatialreasoning benchmarks and generalizes better when evaluating on novel 3D spatialreasoning questions. Our study bridges the 3D parsing capabilities of priorvisual foundation models with the powerful reasoning abilities of largelanguage models, opening new directions for 3D spatial reasoning.</description>
      <author>example@mail.com (Wufei Ma, Yu-Cheng Chou, Qihao Liu, Xingrui Wang, Celso de Melo, Jieneng Chen, Jianwen Xie, Alan Yuille)</author>
      <guid isPermaLink="false">2504.20024v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.19824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对比学习（CL）在自监督学习（SSL）中的应用，提出了一种新的参数化裁剪方法，以提高自标签的鲁棒性和模型性能。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）在深度学习，特别是计算机视觉（CV）领域，通过利用大量未标记数据来促进学习，对比学习（CL）是SSL方法中的一个成功分支。&lt;h4&gt;目的&lt;/h4&gt;为了提高自标签的鲁棒性和模型在下游任务中的准确性。&lt;h4&gt;方法&lt;/h4&gt;引入了两种新的参数化裁剪方法，并与非参数化的随机裁剪方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，使用这些方法在CIFAR-10分类任务上，模型的准确性提高了2.7%到12.4%，具体取决于裁剪大小。&lt;h4&gt;结论&lt;/h4&gt;提出的参数化裁剪方法能够有效提高对比学习在自监督学习中的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) approaches have gained great recognition as a verysuccessful subset of self-supervised learning (SSL) methods. SSL enableslearning from unlabeled data, a crucial step in the advancement of deeplearning, particularly in computer vision (CV), given the plethora of unlabeledimage data. CL works by comparing different random augmentations (e.g.,different crops) of the same image, thus achieving self-labeling. Nevertheless,randomly augmenting images and especially random cropping can result in animage that is semantically very distant from the original and therefore leadsto false labeling, hence undermining the efficacy of the methods. In thisresearch, two novel parameterized cropping methods are introduced that increasethe robustness of self-labeling and consequently increase the efficacy. Theresults show that the use of these methods significantly improves the accuracyof the model by between 2.7\% and 12.4\% on the downstream task of classifyingCIFAR-10, depending on the crop size compared to that of the non-parameterizedrandom cropping method.</description>
      <author>example@mail.com (Mohamed Hassan, Mohammad Wasil, Sebastian Houben)</author>
      <guid isPermaLink="false">2504.19824v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Category-Level and Open-Set Object Pose Estimation for Robotics</title>
      <link>http://arxiv.org/abs/2504.19572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Austrian Robotics Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文比较了用于解决类别级6D姿态估计的算法、数据集和精度指标，并分析了如何将类别级和开放集对象姿态估计连接起来以实现泛化，并提供有针对性的建议。&lt;h4&gt;背景&lt;/h4&gt;对象姿态估计在计算机视觉和机器人学中扮演重要角色，但类别级和开放集方法在处理未知纹理、形状和大小等基本材料属性时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;比较不同方法在类别级6D姿态估计中的表现，并分析如何实现泛化。&lt;h4&gt;方法&lt;/h4&gt;本文通过比较不同的数据集、精度指标和算法，对类别级6D姿态估计进行了研究。&lt;h4&gt;主要发现&lt;/h4&gt;类别级和开放集对象姿态估计面临复杂性和不确定性，需要多种数据集、精度指标和算法解决方案。&lt;h4&gt;结论&lt;/h4&gt;研究提供了将类别级和开放集对象姿态估计连接起来的方法，以实现更广泛的泛化，并为实际应用提供指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要：对象姿态估计在计算机视觉和机器人学中能够实现多种任务，包括场景理解和机器人抓取。姿态估计任务的复杂性取决于与目标对象相关的未知变量。尽管实例级方法在处理不透明和朗伯物体方面已经表现出色，但类别级和开放集方法（其中纹理、形状和大小部分或全部未知）在这些基本材料属性上仍然存在困难。在这些场景中，由于纹理未知，无法用于区分对象对称性，这是6D对象姿态估计的另一个核心挑战。估计具有如此众多未知因素的6D姿态的复杂性导致了各种数据集、精度指标和算法解决方案的出现。本文比较了用于解决类别级6D姿态估计的算法、数据集和精度指标。基于这种比较，我们分析了如何将类别级和开放集对象姿态估计连接起来以实现泛化，并提供有针对性的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation enables a variety of tasks in computer vision androbotics, including scene understanding and robotic grasping. The complexity ofa pose estimation task depends on the unknown variables related to the targetobject. While instance-level methods already excel for opaque and Lambertianobjects, category-level and open-set methods, where texture, shape, and sizeare partially or entirely unknown, still struggle with these basic materialproperties. Since texture is unknown in these scenarios, it cannot be used fordisambiguating object symmetries, another core challenge of 6D object poseestimation. The complexity of estimating 6D poses with such a manifold ofunknowns led to various datasets, accuracy metrics, and algorithmic solutions.This paper compares datasets, accuracy metrics, and algorithms for solving 6Dpose estimation on the category-level. Based on this comparison, we analyze howto bridge category-level and open-set object pose estimation to reachgeneralization and provide actionable recommendations.</description>
      <author>example@mail.com (Peter Hönig, Matthias Hirschmanner, Markus Vincze)</author>
      <guid isPermaLink="false">2504.19572v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Prediction of Nonlinear Optical Properties</title>
      <link>http://arxiv.org/abs/2504.19987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 2 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了非线性光学材料，通过深度学习技术预测其非线性光学性质，以加速新型光学材料的发现和设计。&lt;h4&gt;背景&lt;/h4&gt;非线性光学材料在激光生成领域有广泛应用，但发现具有显著二次谐波产生（SHG）性质的新材料困难重重，因为实验和理论计算耗时且成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于深度学习的方法，使用原子线图神经网络（ALIGNN）预测非线性光学材料的性质，以加快新型光学材料的发现和设计。&lt;h4&gt;方法&lt;/h4&gt;从新型光电材料发现数据库（NOEMD）中获取数据，以库尔特斯-佩里（KP）系数作为关键目标，构建了一个鲁棒的模型，该模型能够准确估计非线性光学响应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在可接受的绝对误差不超过1 pm/V和相对误差不超过0.5的条件下，实现了82.5%的准确率。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了深度学习在加速具有所需特性的先进光学材料发现和设计中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This abstract is a summary of a study that uses deep learning to predict nonlinear optical properties of materials for laser generation. The research aims to accelerate the discovery and design of new optical materials. Data from the NOEMD database is used, and the Kurtz-Perry coefficient is targeted. The model achieves high accuracy and highlights the potential of deep learning in this field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nonlinear optical (NLO) materials for generating lasers via second harmonicgeneration (SHG) are highly sought in today's technology. However, discoveringnovel materials with considerable SHG is challenging due to the time-consumingand costly nature of both experimental methods and first-principlescalculations. In this study, we present a deep learning approach using theAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.Sourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)database and using the Kurtz-Perry (KP) coefficient as the key target, wedeveloped a robust model capable of accurately estimating nonlinear opticalresponses. Our results demonstrate that the model achieves 82.5% accuracy at atolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.This work highlights the potential of deep learning in accelerating thediscovery and design of advanced optical materials with desired properties.</description>
      <author>example@mail.com (Yomn Alkabakibi, Congwei Xie, Artem R. Oganov)</author>
      <guid isPermaLink="false">2504.19987v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models</title>
      <link>http://arxiv.org/abs/2504.20020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为模块化机器学习（MML）的新颖学习范式，旨在解决大型语言模型（LLMs）在推理、事实一致性和可解释性方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管LLMs在自然语言处理、计算机视觉、数据挖掘等领域推动了机器学习研究，但它们在推理、事实一致性和可解释性方面仍存在关键局限性。&lt;h4&gt;目的&lt;/h4&gt;通过引入MML，旨在增强LLMs的逆事实推理能力、减轻幻觉现象，并促进公平性、安全性和透明度。&lt;h4&gt;方法&lt;/h4&gt;MML将LLMs的复杂结构分解为三个相互依存的组件：模块化表示、模块化模型和模块化推理。通过使用解耦表示学习、神经架构搜索和神经符号学习等技术实现MML。&lt;h4&gt;主要发现&lt;/h4&gt;MML范式可以：1）通过解耦语义组件来阐明LLMs的内部工作机制；2）允许灵活且适应任务的模型设计；3）实现可解释且基于逻辑的决策过程。&lt;h4&gt;结论&lt;/h4&gt;MML与LLMs的结合有望弥合统计（深度）学习和形式（逻辑）推理之间的差距，为广泛实际应用中的稳健、适应性强和值得信赖的AI系统铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Large language models (LLMs) have dramatically advanced machine learning research including natural language processing, computer vision, data mining, etc., yet they still exhibit critical limitations in reasoning, factual consistency, and interpretability. In this paper, we introduce a novel learning paradigm -- Modular Machine Learning (MML) -- as an essential approach toward new-generation LLMs. MML decomposes the complex structure of LLMs into three interdependent components: modular representation, modular model, and modular reasoning, aiming to enhance LLMs' capability of counterfactual reasoning, mitigating hallucinations, as well as promoting fairness, safety, and transparency. Specifically, the proposed MML paradigm can: i) clarify the internal working mechanism of LLMs through the disentanglement of semantic components; ii) allow for flexible and task-adaptive model design; iii) enable interpretable and logic-driven decision-making process. We present a feasible implementation of MML-based LLMs via leveraging advanced techniques such as disentangled representation learning, neural architecture search and neuro-symbolic learning. We critically identify key challenges, such as the integration of continuous neural and discrete symbolic processes, joint optimization, and computational scalability, present promising future research directions that deserve further exploration. Ultimately, the integration of the MML paradigm with LLMs has the potential to bridge the gap between statistical (deep) learning and formal (logical) reasoning, thereby paving the way for robust, adaptable, and trustworthy AI systems across a wide range of real-world applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have dramatically advanced machine learningresearch including natural language processing, computer vision, data mining,etc., yet they still exhibit critical limitations in reasoning, factualconsistency, and interpretability. In this paper, we introduce a novel learningparadigm -- Modular Machine Learning (MML) -- as an essential approach towardnew-generation LLMs. MML decomposes the complex structure of LLMs into threeinterdependent components: modular representation, modular model, and modularreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,mitigating hallucinations, as well as promoting fairness, safety, andtransparency. Specifically, the proposed MML paradigm can: i) clarify theinternal working mechanism of LLMs through the disentanglement of semanticcomponents; ii) allow for flexible and task-adaptive model design; iii) enableinterpretable and logic-driven decision-making process. We present a feasibleimplementation of MML-based LLMs via leveraging advanced techniques such asdisentangled representation learning, neural architecture search andneuro-symbolic learning. We critically identify key challenges, such as theintegration of continuous neural and discrete symbolic processes, jointoptimization, and computational scalability, present promising future researchdirections that deserve further exploration. Ultimately, the integration of theMML paradigm with LLMs has the potential to bridge the gap between statistical(deep) learning and formal (logical) reasoning, thereby paving the way forrobust, adaptable, and trustworthy AI systems across a wide range of real-worldapplications.</description>
      <author>example@mail.com (Xin Wang, Haoyang Li, Zeyang Zhang, Haibo Chen, Wenwu Zhu)</author>
      <guid isPermaLink="false">2504.20020v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Uncertainty-Aware Graph Neural Network</title>
      <link>http://arxiv.org/abs/2504.19820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HU-GNN的新型图神经网络架构，该架构通过统一多尺度表示学习、原理性不确定性估计和自监督嵌入多样性，有效缓解了数据稀疏性和利用结构属性。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络（GNNs）的研究探索了捕获局部不确定性和利用图层次结构来缓解数据稀疏性和利用结构属性的方法，但这两者之间的协同集成尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出HU-GNN的目的是为了解决上述问题，实现多尺度表示学习、不确定性估计和嵌入多样性的统一。&lt;h4&gt;方法&lt;/h4&gt;HU-GNN通过自适应形成节点簇，并在多个结构尺度上从单个节点到更高级别估计不确定性。这些不确定性估计引导了一个鲁棒的消息传递机制和注意力权重，从而有效缓解了噪声和对抗性扰动，同时保持了节点和图级别任务的预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了概率公式、严格的不确定性校准保证和正式的鲁棒性界限等关键理论贡献。通过结合图对比学习的最新进展，HU-GNN保持了多样性和结构上忠实嵌入。&lt;h4&gt;结论&lt;/h4&gt;在标准基准上的大量实验表明，该模型实现了最先进的鲁棒性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;最近关于图神经网络（GNNs）的研究探讨了捕获局部不确定性和利用图层次结构来缓解数据稀疏性和利用结构属性的方法。然而，这两种方法的协同集成尚未得到充分探索。在本工作中，我们引入了一种新的架构，即分层不确定性感知图神经网络（HU-GNN），它在一个端到端的框架内统一了多尺度表示学习、原理性不确定性估计和自监督嵌入多样性。具体来说，HU-GNN自适应地形成节点簇，并从单个节点到更高级别估计多个结构尺度的不确定性。这些不确定性估计引导了一个鲁棒的消息传递机制和注意力权重，有效地缓解了噪声和对抗性扰动，同时在节点和图级别任务上保持了预测精度。我们还提供了关键的理论贡献，包括概率公式、严格的不确定性校准保证和正式的鲁棒性界限。最后，通过结合图对比学习的最新进展，HU-GNN保持了多样性和结构上忠实嵌入。在标准基准上的大量实验表明，我们的模型实现了最先进的鲁棒性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research on graph neural networks (GNNs) has explored mechanisms forcapturing local uncertainty and exploiting graph hierarchies to mitigate datasparsity and leverage structural properties. However, the synergisticintegration of these two approaches remains underexplored. In this work, weintroduce a novel architecture, the Hierarchical Uncertainty-Aware Graph NeuralNetwork (HU-GNN), which unifies multi-scale representation learning, principleduncertainty estimation, and self-supervised embedding diversity within a singleend-to-end framework. Specifically, HU-GNN adaptively forms node clusters andestimates uncertainty at multiple structural scales from individual nodes tohigher levels. These uncertainty estimates guide a robust message-passingmechanism and attention weighting, effectively mitigating noise and adversarialperturbations while preserving predictive accuracy on both node- andgraph-level tasks. We also offer key theoretical contributions, including aprobabilistic formulation, rigorous uncertainty-calibration guarantees, andformal robustness bounds. Finally, by incorporating recent advances in graphcontrastive learning, HU-GNN maintains diverse, structurally faithfulembeddings. Extensive experiments on standard benchmarks demonstrate that ourmodel achieves state-of-the-art robustness and interpretability.</description>
      <author>example@mail.com (Yoonhyuk Choi, Chong-Kwon Kim)</author>
      <guid isPermaLink="false">2504.19820v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity</title>
      <link>http://arxiv.org/abs/2504.19581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAMBLE的方法，用于学习特定形状的点云采样策略，以实现更精确和高效的3D数据表示。&lt;h4&gt;背景&lt;/h4&gt;随着对3D数据精确和高效表示的需求增加，点云采样已成为3D计算机视觉中的一个关键研究课题。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有学习型采样方法存在的问题，如产生不可识别的采样模式或偏置采样结果，同时忽略不同形状点分布的自然变化。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于稀疏注意力图和分箱的SAMBLE方法，用于学习特定形状的点云采样策略。&lt;h4&gt;主要发现&lt;/h4&gt;SAMBLE有效地在采样边缘点以获得局部细节和保持全局形状均匀性之间实现了平衡，在多个常见的点云下游任务中取得了优越的性能，即使在少数点采样的情况下也是如此。&lt;h4&gt;结论&lt;/h4&gt;SAMBLE方法能够显著提高点云采样在3D数据表示中的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by the increasing demand for accurate and efficient representation of3D data in various domains, point cloud sampling has emerged as a pivotalresearch topic in 3D computer vision. Recently, learning-to-sample methods havegarnered growing interest from the community, particularly for their ability tobe jointly trained with downstream tasks. However, previous learning-basedsampling methods either lead to unrecognizable sampling patterns by generatinga new point cloud or biased sampled results by focusing excessively on sharpedge details. Moreover, they all overlook the natural variations in pointdistribution across different shapes, applying a similar sampling strategy toall point clouds. In this paper, we propose a Sparse Attention Map andBin-based Learning method (termed SAMBLE) to learn shape-specific samplingstrategies for point cloud shapes. SAMBLE effectively achieves an improvedbalance between sampling edge points for local details and preservinguniformity in the global shape, resulting in superior performance acrossmultiple common point cloud downstream tasks, even in scenarios with few-pointsampling.</description>
      <author>example@mail.com (Chengzhi Wu, Yuxin Wan, Hao Fu, Julius Pfrommer, Zeyun Zhong, Junwei Zheng, Jiaming Zhang, Jürgen Beyerer)</author>
      <guid isPermaLink="false">2504.19581v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Under High-Dimensional Network Convolutional Regression Model</title>
      <link>http://arxiv.org/abs/2504.19979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于网络卷积回归（NCR）的高维迁移学习框架，用于解决网络数据中的依赖性问题，并通过仿真和真实世界应用验证了其在预测精度上的提升。&lt;h4&gt;背景&lt;/h4&gt;迁移学习通过利用相关领域的知识提升模型性能，特别是在标注数据稀缺的情况下。然而，现有研究主要关注独立设置下的分布变化，而处理网络数据中的依赖性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种高维迁移学习框架，解决网络数据中的依赖性问题，并提高预测精度。&lt;h4&gt;方法&lt;/h4&gt;1. 基于网络卷积回归（NCR）模型，允许节点的响应依赖于其特征和邻居的聚合特征，有效捕获局部依赖性；2. 设计了两个步骤的迁移学习算法，处理源和目标网络之间的领域差异；3. 引入源检测机制来识别信息丰富的领域；4. 理论上分析基于Erdős-Rényi模型的随机图上的lasso估计器，证明在存在信息源时，迁移学习可以提高收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在预测精度上取得了显著提升，特别是在目标域的标注数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;提出的NCR迁移学习框架能够有效处理网络数据中的依赖性，并显著提高预测精度，特别是在数据稀缺的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances model performance by utilizing knowledge fromrelated domains, particularly when labeled data is scarce. While existingresearch addresses transfer learning under various distribution shifts inindependent settings, handling dependencies in networked data remainschallenging. To address this challenge, we propose a high-dimensional transferlearning framework based on network convolutional regression (NCR), inspired bythe success of graph convolutional networks (GCNs). The NCR model incorporatesrandom network structure by allowing each node's response to depend on itsfeatures and the aggregated features of its neighbors, capturing localdependencies effectively. Our methodology includes a two-step transfer learningalgorithm that addresses domain shift between source and target networks, alongwith a source detection mechanism to identify informative domains.Theoretically, we analyze the lasso estimator in the context of a random graphbased on the Erdos-Renyi model assumption, demonstrating that transfer learningimproves convergence rates when informative sources are present. Empiricalevaluations, including simulations and a real-world application using SinaWeibo data, demonstrate substantial improvements in prediction accuracy,particularly when labeled data in the target domain is limited.</description>
      <author>example@mail.com (Liyuan Wang, Jiachen Chen, Kathryn L. Lunetta, Danyang Huang, Huimin Cheng, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2504.19979v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Streaming Video Representation via Multitask Training</title>
      <link>http://arxiv.org/abs/2504.20041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report. Project Page:  https://go2heart.github.io/streamformer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了StreamFormer，一种新的流式视频处理框架，用于实时应用，如具身AI和自动驾驶。StreamFormer通过引入因果时序注意力机制，在预训练视觉Transformer中实现了高效的流式视频处理，同时保持了图像表示能力。&lt;h4&gt;背景&lt;/h4&gt;在实时应用中，理解连续视频流非常重要。与离线视频理解不同，流式视频理解需要逐帧处理视频流，保留历史信息，并做出低延迟决策。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决流式视频理解中的挑战，如高效处理视频流、保留历史信息和低延迟决策。&lt;h4&gt;方法&lt;/h4&gt;（i）开发了一种新的流式视频主干网络StreamFormer，通过将因果时序注意力机制整合到预训练视觉Transformer中；（ii）提出将多种时空视频理解任务统一到一个多任务视觉-语言对齐框架中，以训练StreamFormer；（iii）在在线动作检测、在线视频实例分割和视频问答等任务上进行了广泛的实验。&lt;h4&gt;主要发现&lt;/h4&gt;StreamFormer在保持效率的同时，在在线动作检测、在线视频实例分割和视频问答等任务上实现了有竞争力的结果，证明了其在实时应用中的潜力。&lt;h4&gt;结论&lt;/h4&gt;StreamFormer是一种高效的流式视频处理框架，适用于实时应用，如具身AI和自动驾驶，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Understanding continuous video streams plays a fundamental role in real-time applications including embodied AI and autonomous driving. Unlike offline video understanding, streaming video understanding requires the ability to process video streams frame by frame, preserve historical information, and make low-latency decisions. To address these challenges, our main contributions are three-fold. (i) We develop a novel streaming video backbone, termed as StreamFormer, by incorporating causal temporal attention into a pre-trained vision transformer. This enables efficient streaming video processing while maintaining image representation capability. (ii) To train StreamFormer, we propose to unify diverse spatial-temporal video understanding tasks within a multitask visual-language alignment framework. Hence, StreamFormer learns global semantics, temporal dynamics, and fine-grained spatial relationships simultaneously. (iii) We conduct extensive experiments on online action detection, online video instance segmentation, and video question answering. StreamFormer achieves competitive results while maintaining efficiency, demonstrating its potential for real-time applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding continuous video streams plays a fundamental role in real-timeapplications including embodied AI and autonomous driving. Unlike offline videounderstanding, streaming video understanding requires the ability to processvideo streams frame by frame, preserve historical information, and makelow-latency decisions.To address these challenges, our main contributions arethree-fold. (i) We develop a novel streaming video backbone, termed asStreamFormer, by incorporating causal temporal attention into a pre-trainedvision transformer. This enables efficient streaming video processing whilemaintaining image representation capability.(ii) To train StreamFormer, wepropose to unify diverse spatial-temporal video understanding tasks within amultitask visual-language alignment framework. Hence, StreamFormer learnsglobal semantics, temporal dynamics, and fine-grained spatial relationshipssimultaneously. (iii) We conduct extensive experiments on online actiondetection, online video instance segmentation, and video question answering.StreamFormer achieves competitive results while maintaining efficiency,demonstrating its potential for real-time applications.</description>
      <author>example@mail.com (Yibin Yan, Jilan Xu, Shangzhe Di, Yikun Liu, Yudi Shi, Qirui Chen, Zeqian Li, Yifei Huang, Weidi Xie)</author>
      <guid isPermaLink="false">2504.20041v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Review of 3D Object Detection with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.18738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对3D对象检测与视觉语言模型（VLMs）的综述进行了系统分析。&lt;h4&gt;背景&lt;/h4&gt;3D对象检测是3D视觉与多模态AI交叉领域的快速发展的一个领域。&lt;h4&gt;目的&lt;/h4&gt;提供首个针对3D对象检测与视觉语言模型的系统分析。&lt;h4&gt;方法&lt;/h4&gt;通过审查超过100篇研究论文，分析3D对象检测的独特挑战，比较传统方法和现代视觉语言框架，并回顾关键架构、预训练策略和提示工程方法。&lt;h4&gt;主要发现&lt;/h4&gt;分析了3D对象检测与视觉语言模型在空间推理和数据复杂性方面的差异，并讨论了性能和评估基准。&lt;h4&gt;结论&lt;/h4&gt;强调了当前挑战，如有限的3D语言数据集和计算需求，并提出了未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;This review provides a systematic analysis of comprehensive survey of 3Dobject detection with vision-language models(VLMs), a rapidly advancing areaat the intersection of 3D vision and multimodal AI. By examining over 100research papers, we provide the first systematic analysis dedicated to 3Dobject detection with vision-language models. We begin by outlining the uniquechallenges of 3D object detection with vision-language models, emphasizingdifferences from 2D detection in spatial reasoning and data complexity.Traditional approaches using point clouds and voxel grids are compared tomodern vision-language frameworks like CLIP and 3D LLMs, which enableopen-vocabulary detection and zero-shot generalization. We review keyarchitectures, pretraining strategies, and prompt engineering methods thatalign textual and 3D features for effective 3D object detection withvision-language models. Visualization examples and evaluation benchmarks arediscussed to illustrate performance and behavior. Finally, we highlight currentchallenges, such as limited 3D-language datasets and computational demands, andpropose future research directions to advance 3D object detection withvision-language models. &gt;Object Detection, Vision-Language Models, Agents,VLMs, LLMs, AI&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review provides a systematic analysis of comprehensive survey of 3Dobject detection with vision-language models(VLMs) , a rapidly advancing areaat the intersection of 3D vision and multimodal AI. By examining over 100research papers, we provide the first systematic analysis dedicated to 3Dobject detection with vision-language models. We begin by outlining the uniquechallenges of 3D object detection with vision-language models, emphasizingdifferences from 2D detection in spatial reasoning and data complexity.Traditional approaches using point clouds and voxel grids are compared tomodern vision-language frameworks like CLIP and 3D LLMs, which enableopen-vocabulary detection and zero-shot generalization. We review keyarchitectures, pretraining strategies, and prompt engineering methods thatalign textual and 3D features for effective 3D object detection withvision-language models. Visualization examples and evaluation benchmarks arediscussed to illustrate performance and behavior. Finally, we highlight currentchallenges, such as limited 3D-language datasets and computational demands, andpropose future research directions to advance 3D object detection withvision-language models. &gt;Object Detection, Vision-Language Models, Agents,VLMs, LLMs, AI</description>
      <author>example@mail.com (Ranjan Sapkota, Konstantinos I Roumeliotis, Rahul Harsha Cheppally, Marco Flores Calero, Manoj Karkee)</author>
      <guid isPermaLink="false">2504.18738v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>HJRNO: Hamilton-Jacobi Reachability with Neural Operators</title>
      <link>http://arxiv.org/abs/2504.19989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了HJRNO，一种基于神经操作符的框架，用于高效准确地解决向后可达管（BRTs），以保障自主系统在不确定环境下的安全性。&lt;h4&gt;背景&lt;/h4&gt;确保自主系统在不确定性下的安全性是关键挑战。传统的HJR分析方法在提供安全性保证的同时，受到维度灾难的限制，限制了其在高维系统或变化环境条件下的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即HJRNO，以解决传统HJR方法在处理高维系统时的可扩展性问题，并实现高效准确的安全分析。&lt;h4&gt;方法&lt;/h4&gt;HJRNO利用傅里叶神经网络操作符（FNO）学习值函数之间的映射，通过这种方式，可以实现快速推理并具有良好的泛化能力，能够适应不同的障碍物形状、系统配置和超参数。&lt;h4&gt;主要发现&lt;/h4&gt;HJRNO在随机障碍物场景中实现了低误差，并在不同的系统动力学下表现出有效的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HJRNO为自主系统提供了一种可扩展且实时的安全分析方法，是一种有前景的基础模型方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于神经操作符的框架HJRNO，用于解决向后可达管问题，以提高自主系统在不确定性环境下的安全性。传统方法在处理高维系统时受到限制，而HJRNO通过傅里叶神经网络操作符实现了高效和准确的解决方案，展现出良好的泛化能力，为自主系统的实时安全分析提供了有希望的基础模型方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of autonomous systems under uncertainty is a criticalchallenge. Hamilton-Jacobi reachability (HJR) analysis is a widely used methodfor guaranteeing safety under worst-case disturbances. Traditional HJR methodsprovide safety guarantees but suffer from the curse of dimensionality, limitingtheir scalability to high-dimensional systems or varying environmentalconditions. In this work, we propose HJRNO, a neural operator-based frameworkfor solving backward reachable tubes (BRTs) efficiently and accurately. Byleveraging the Fourier Neural Operator (FNO), HJRNO learns a mapping betweenvalue functions, enabling fast inference with strong generalization acrossdifferent obstacle shapes, system configurations, and hyperparameters. Wedemonstrate that HJRNO achieves low error on random obstacle scenarios andgeneralizes effectively across varying system dynamics. These results suggestthat HJRNO offers a promising foundation model approach for scalable, real-timesafety analysis in autonomous systems.</description>
      <author>example@mail.com (Yankai Li, Mo Chen)</author>
      <guid isPermaLink="false">2504.19989v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.19500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MPEC的新型掩码点-实体对比学习方法，用于开放词汇的3D语义分割，旨在通过实体-语言对齐和点-实体一致性来提升实体特征表示，实现了在ScanNet上的最先进性能和零样本场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;开放词汇的3D场景理解对于增强物理智能至关重要，因为它使具身智能体能够解释和动态交互于现实世界环境中。&lt;h4&gt;目的&lt;/h4&gt;提出MPEC方法，旨在改善语义区分能力，增强独特实例的区分度，并展示该方法在零样本场景理解上的优势。&lt;h4&gt;方法&lt;/h4&gt;MPEC方法结合了3D实体-语言对齐和点-实体一致性，用于开放词汇的3D语义分割，并在8个数据集上进行了广泛的微调实验，这些数据集涵盖了从低级感知到高级推理任务。&lt;h4&gt;主要发现&lt;/h4&gt;MPEC方法在ScanNet上取得了最先进的结果，并在多种3D场景理解任务上展示了稳定的表现。&lt;h4&gt;结论&lt;/h4&gt;MPEC方法展示了3D特征的潜力，并能够在不同的3D场景理解任务中带来持续的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：开放式词汇的3D场景理解对于提高物理智能至关重要，因为它允许具身智能体解释和动态地与真实世界环境互动。本文提出了一种名为MPEC的新型掩码点-实体对比学习方法，用于开放式词汇的3D语义分割，它利用了3D实体-语言对齐和不同点云视图中的点-实体一致性来培养特定于实体的特征表示。该方法提高了语义区分度，增强了独特实例的区分能力，在ScanNet开放式词汇的3D语义分割任务上取得了最先进的成果，并展示了卓越的零样本场景理解能力。在从低级感知到高级推理任务的8个数据集上进行的广泛微调实验展示了学习到的3D特征的潜力，推动在不同3D场景理解任务中的性能持续提升。项目网站：https://mpec-3d.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D scene understanding is pivotal for enhancing physicalintelligence, as it enables embodied agents to interpret and interactdynamically within real-world environments. This paper introduces MPEC, a novelMasked Point-Entity Contrastive learning method for open-vocabulary 3D semanticsegmentation that leverages both 3D entity-language alignment and point-entityconsistency across different point cloud views to foster entity-specificfeature representations. Our method improves semantic discrimination andenhances the differentiation of unique instances, achieving state-of-the-artresults on ScanNet for open-vocabulary 3D semantic segmentation anddemonstrating superior zero-shot scene understanding capabilities. Extensivefine-tuning experiments on 8 datasets, spanning from low-level perception tohigh-level reasoning tasks, showcase the potential of learned 3D features,driving consistent performance gains across varied 3D scene understandingtasks. Project website: https://mpec-3d.github.io/</description>
      <author>example@mail.com (Yan Wang, Baoxiong Jia, Ziyu Zhu, Siyuan Huang)</author>
      <guid isPermaLink="false">2504.19500v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Heterophily-informed Message Passing</title>
      <link>http://arxiv.org/abs/2504.19785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appearing in Transactions on Machine Learning Research (TMLR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）方法，旨在解决GNN过度平滑的问题，该方法通过调节消息的聚合来保护信息中的低频和高频成分。&lt;h4&gt;背景&lt;/h4&gt;GNNs由于其隐含的同质性假设而容易受到过度平滑的影响。&lt;h4&gt;目的&lt;/h4&gt;缓解GNN的过度平滑问题，同时保留信息中的低频和高频成分。&lt;h4&gt;方法&lt;/h4&gt;该方法依赖于学习到的嵌入，无需辅助标签，从而将异质性感知嵌入的好处扩展到更广泛的应用，例如生成建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在各种数据集和GNN架构上都有性能提升，并揭示了标准分类基准中的异质性模式。此外，在分子生成中的应用在化学信息学基准上展示了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;提出的方案有效地减轻了GNN的过度平滑问题，并提高了其性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due to their implicit homophily assumption. We mitigate this problem with a novel scheme that regulates the aggregation of messages, modulating the type and extent of message passing locally thereby preserving both the low and high-frequency components of information. Our approach relies solely on learned embeddings, obviating the need for auxiliary labels, thus extending the benefits of heterophily-aware embeddings to broader applications, e.g., generative modelling. Our experiments, conducted across various data sets and GNN architectures, demonstrate performance enhancements and reveal heterophily patterns across standard classification benchmarks. Furthermore, application to molecular generation showcases notable performance improvements on chemoinformatics benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are known to be vulnerable to oversmoothing dueto their implicit homophily assumption. We mitigate this problem with a novelscheme that regulates the aggregation of messages, modulating the type andextent of message passing locally thereby preserving both the low andhigh-frequency components of information. Our approach relies solely on learntembeddings, obviating the need for auxiliary labels, thus extending thebenefits of heterophily-aware embeddings to broader applications, e.g.,generative modelling. Our experiments, conducted across various data sets andGNN architectures, demonstrate performance enhancements and reveal heterophilypatterns across standard classification benchmarks. Furthermore, application tomolecular generation showcases notable performance improvements onchemoinformatics benchmarks.</description>
      <author>example@mail.com (Haishan Wang, Arno Solin, Vikas Garg)</author>
      <guid isPermaLink="false">2504.19785v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes</title>
      <link>http://arxiv.org/abs/2504.19557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE/CVF Conference on Computer Vision and Pattern  Recognition Workshops (CVPRW)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基于神经的点云合成方法，用于解决大规模自动驾驶场景中新型视图合成的问题。&lt;h4&gt;背景&lt;/h4&gt;当前基于点的三维点云地图在用于新型视图合成（NVS）时，由于可扩展性和渲染质量受限，导致可视化效果下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决渲染质量低的问题，提出了一种名为CE-NPBG的新方法，用于大规模自动驾驶场景中的新型视图合成。&lt;h4&gt;方法&lt;/h4&gt;该方法利用两种模态：摆姿势的图像（相机）和同步的原始3D点云（LiDAR）。它首先使用外观和几何之间的连接关系图，从当前相机视角检索3D点云图中的点进行渲染。此外，该方法将神经网络描述符与点关联，并使用它们来合成视图。为了提高描述符的编码质量和渲染质量，提出了联合对抗和点光栅化训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用连接关系图，该方法显著提高了渲染质量，并通过仅使用大型3D点云图的一小部分点来增强运行时间和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法对于提高渲染质量和可扩展性具有显著优势，并已集成到最近的3D高斯喷溅工作中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：当前基于点的三维点云地图在用于新型视图合成（NVS）时，由于可扩展性和渲染质量受限，导致可视化效果下降。我们识别出这些低质量渲染背后的主要问题是几何和外观之间的可见性不匹配，这是由于同时使用这两种模态造成的。为了解决这个问题，我们提出了CE-NPBG，这是一种用于大规模自动驾驶场景中新型视图合成（NVS）的新方法。我们的方法是一种神经点云技术，利用两种模态：摆姿势的图像（相机）和同步的原始3D点云（LiDAR）。我们首先使用外观和几何之间的连接关系图，从当前相机视角检索3D点云图中的点进行渲染。通过利用这种连接关系，我们的方法显著提高了渲染质量，并通过仅使用大型3D点云图的一小部分点来增强运行时间和可扩展性。我们的方法将神经网络描述符与点关联，并使用它们来合成视图。为了提高这些描述符的编码质量和渲染质量，我们提出了联合对抗和点光栅化训练。在训练期间，我们将图像合成网络与多分辨率判别器配对。在推理期间，我们将它们解耦，并使用图像合成网络生成新型视图。我们还把我们提出的方案集成到最近的3D高斯喷溅工作中，以突出其在提高渲染和可扩展性方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current point-based approaches encounter limitations in scalability andrendering quality when using large 3D point cloud maps because using themdirectly for novel view synthesis (NVS) leads to degraded visualizations. Weidentify the primary issue behind these low-quality renderings as a visibilitymismatch between geometry and appearance, stemming from using these twomodalities together. To address this problem, we present CE-NPBG, a newapproach for novel view synthesis (NVS) in large-scale autonomous drivingscenes. Our method is a neural point-based technique that leverages twomodalities: posed images (cameras) and synchronized raw 3D point clouds(LiDAR). We first employ a connectivity relationship graph between appearanceand geometry, which retrieves points from a large 3D point cloud map observedfrom the current camera perspective and uses them for rendering. By leveragingthis connectivity, our method significantly improves rendering quality andenhances run-time and scalability by using only a small subset of points fromthe large 3D point cloud map. Our approach associates neural descriptors withthe points and uses them to synthesize views. To enhance the encoding of thesedescriptors and elevate rendering quality, we propose a joint adversarial andpoint rasterization training. During training, we pair an image-synthesizernetwork with a multi-resolution discriminator. At inference, we decouple themand use the image-synthesizer to generate novel views. We also integrate ourproposal into the recent 3D Gaussian Splatting work to highlight its benefitsfor improved rendering and scalability.</description>
      <author>example@mail.com (Mohammad Altillawi, Fengyi Shen, Liudi Yang, Sai Manoj Prakhya, Ziyuan Liu)</author>
      <guid isPermaLink="false">2504.19557v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction</title>
      <link>http://arxiv.org/abs/2504.19545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Point2Quad的基于学习的四边形网格生成方法，用于从点云中生成四边形网格。&lt;h4&gt;背景&lt;/h4&gt;尽管基于学习的三角形网格生成方法取得了显著进展，但由于确保共面性、凸性和仅使用四边形的挑战，四边形网格生成仍然相对较少探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的学习算法，能够从点云中生成符合要求的四边形网格。&lt;h4&gt;方法&lt;/h4&gt;Point2Quad通过以下步骤实现：使用k-NN生成候选四边形，考虑共面性和正方形性；使用两个编码器提取几何和拓扑特征；结合四边形特定的特性来解决四边形相关约束问题；融合提取的特征以训练分类器，并设计复合损失函数；最后，通过四边形特定的后处理进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;在清晰和噪声数据上进行的广泛实验证明了Point2Quad的有效性和优越性，与基线方法相比，在综合指标下表现更优。&lt;h4&gt;结论&lt;/h4&gt;Point2Quad是一种有效的基于学习的方法，可以用于从点云中生成高质量的四边形网格。&lt;h4&gt;翻译&lt;/h4&gt;摘要：四边形网格在几何建模和计算力学中至关重要。尽管基于学习的三角形网格生成方法取得了显著进展，但由于确保共面性、凸性和仅使用四边形的挑战，四边形网格生成仍然相对较少探索。在本文中，我们提出了Point2Quad，这是第一个从点云生成仅四边形网格的基于学习的方法。其关键思想是学习识别融合了点级和面级特征的四边形网格。具体来说，Point2Quad从基于k-NN的候选生成开始，考虑共面性和正方形性。然后，跟随两个编码器提取几何和拓扑特征，以解决四边形相关约束的挑战，特别是通过结合深入的特定于四边形的特性。随后，提取的特征被融合以训练具有设计复合损失的分类器。最后，通过四边形特定的后处理进行细化。在清晰和噪声数据上的广泛实验证明了Point2Quad的有效性和优越性，与基线方法相比，在综合指标下表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3556130&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quad meshes are essential in geometric modeling and computational mechanics.Although learning-based methods for triangle mesh demonstrate considerableadvancements, quad mesh generation remains less explored due to the challengeof ensuring coplanarity, convexity, and quad-only meshes. In this paper, wepresent Point2Quad, the first learning-based method for quad-only meshgeneration from point clouds. The key idea is learning to identify quad meshwith fused pointwise and facewise features. Specifically, Point2Quad beginswith a k-NN-based candidate generation considering the coplanarity andsquareness. Then, two encoders are followed to extract geometric andtopological features that address the challenge of quad-related constraints,especially by combining in-depth quadrilaterals-specific characteristics.Subsequently, the extracted features are fused to train the classifier with adesigned compound loss. The final results are derived after the refinement by aquad-specific post-processing. Extensive experiments on both clear and noisedata demonstrate the effectiveness and superiority of Point2Quad, compared tobaseline methods under comprehensive metrics.</description>
      <author>example@mail.com (Zezeng Li, Zhihui Qi, Weimin Wang, Ziliang Wang, Junyi Duan, Na Lei)</author>
      <guid isPermaLink="false">2504.19545v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Do You Know the Way? Human-in-the-Loop Understanding for Fast Traversability Estimation in Mobile Robotics</title>
      <link>http://arxiv.org/abs/2504.19851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by RA-L. Code is available at  https://github.com/andreschreiber/CHUNGUS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于在非结构化环境中进行机器导航的可穿越性估计方法，旨在解决现有方法的局限性和提高可穿越性预测的性能。&lt;h4&gt;背景&lt;/h4&gt;随着机器人在非结构化环境中应用的增加，有效的感知和导航策略变得至关重要，特别是在可穿越性估计方面。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的方法来改善机器人在环境中移动的能力，通过准确地预测它们可以或不可以到达的区域。&lt;h4&gt;方法&lt;/h4&gt;提出了一个结合人工参与（HiL）的可穿越性估计方法，该方法根据需要向人类请求标注，并使用基础模型快速学习新标注，即使在标注数量较少的情况下也能提供准确的预测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在仿真和实际数据集上进行了广泛验证，证明了其能提供业界领先的可穿越性预测性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过结合人工智能和人工参与，在提高可穿越性估计准确性方面具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3563819&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of robots in unstructured environments necessitates thedevelopment of effective perception and navigation strategies to enable fieldrobots to successfully perform their tasks. In particular, it is key for suchrobots to understand where in their environment they can and cannot travel -- atask known as traversability estimation. However, existing geometric approachesto traversability estimation may fail to capture nuanced representations oftraversability, whereas vision-based approaches typically either involvemanually annotating a large number of images or require robot experience. Inaddition, existing methods can struggle to address domain shifts as theytypically do not learn during deployment. To this end, we propose ahuman-in-the-loop (HiL) method for traversability estimation that prompts ahuman for annotations as-needed. Our method uses a foundation model to enablerapid learning on new annotations and to provide accurate predictions even whentrained on a small number of quickly-provided HiL annotations. We extensivelyvalidate our method in simulation and on real-world data, and demonstrate thatit can provide state-of-the-art traversability prediction performance.</description>
      <author>example@mail.com (Andre Schreiber, Katherine Driggs-Campbell)</author>
      <guid isPermaLink="false">2504.19851v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Physical Reach: Comparing Head- and Cane-Mounted Cameras for Last-Mile Navigation by Blind Users</title>
      <link>http://arxiv.org/abs/2504.19345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过调查和实验研究，探讨了盲人在导航过程中面临的挑战，并提出了基于多传感器融合的导航辅助系统设计方案。&lt;h4&gt;背景&lt;/h4&gt;盲人在导航过程中存在困难，如定位入口、识别障碍物以及导航复杂或拥挤的空间。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有辅助系统设计的空白，本文通过两部分研究来指导设计：调查盲人的导航策略和偏好，以及通过实验研究不同视角下的导航效果。&lt;h4&gt;方法&lt;/h4&gt;首先，通过调查10位经验丰富的盲人使用拐杖的用户，了解他们的导航策略、痛点和技术偏好；其次，通过实验，让一位盲人使用同步的头戴式和拐杖式摄像头在五个真实环境中导航，以视角放置为变量，评估不同视角对空间感知的支持，包括SLAM性能和基于NeRF的3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;头戴式传感器提供了更高的定位精度，而拐杖式视角提供了更全面的地面覆盖和丰富的环境重建。头戴式和拐杖式结合的配置在性能上优于单独使用。&lt;h4&gt;结论&lt;/h4&gt;不同传感器的放置位置具有互补的优势，为开发感知能力强、鲁棒且用户友好的混合导航辅助系统提供了实际指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要：盲人在最后一英里导航中面临持续挑战，包括定位入口、识别障碍物以及导航复杂或拥挤的空间。尽管可穿戴摄像头在辅助系统中越来越被使用，但还没有系统性的、以视角为焦点的比较来指导其设计。本文通过两部分研究来填补这一空白。首先，我们调查了10位有经验的盲人拐杖使用者，揭示了导航策略、痛点和技术偏好。参与者强调了多感官整合、以目的地为导向的旅行和补充（而不是替代）拐杖触觉功能辅助工具的重要性。其次，我们进行了一项受控数据收集，让一位盲人在使用同步的头戴式和拐杖式摄像头在五个真实环境中导航，将视角放置作为主要变量。为了评估每个视角如何支持空间感知，我们评估了SLAM性能（用于定位和制图）和基于NeRF的3D重建（用于下游场景理解）。头戴式传感器提供了优越的定位精度，而拐杖式视角提供了更广泛的地面覆盖和更丰富的环境重建。头戴式和拐杖式结合的配置在性能上始终优于单独使用。这些结果突出了不同传感器放置位置的互补优势，并为开发感知能力强、鲁棒且用户友好的混合导航辅助系统提供了实际指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blind individuals face persistent challenges in last-mile navigation,including locating entrances, identifying obstacles, and navigating complex orcluttered spaces. Although wearable cameras are increasingly used in assistivesystems, there has been no systematic, vantage-focused comparison to guidetheir design. This paper addresses that gap through a two-part investigation.First, we surveyed ten experienced blind cane users, uncovering navigationstrategies, pain points, and technology preferences. Participants stressed theimportance of multi-sensory integration, destination-focused travel, andassistive tools that complement (rather than replace) the cane's tactileutility. Second, we conducted controlled data collection with a blindparticipant navigating five real-world environments using synchronized head-and cane-mounted cameras, isolating vantage placement as the primary variable.To assess how each vantage supports spatial perception, we evaluated SLAMperformance (for localization and mapping) and NeRF-based 3D reconstruction(for downstream scene understanding). Head-mounted sensors delivered superiorlocalization accuracy, while cane-mounted views offered broader ground-levelcoverage and richer environmental reconstructions. A combined (head+cane)configuration consistently outperformed both. These results highlight thecomplementary strengths of different sensor placements and offer actionableguidance for developing hybrid navigation aids that are perceptive, robust, anduser-aligned.</description>
      <author>example@mail.com (Apurv Varshney, Lucas Nadolskis, Tobias Höllerer, Michael Beyeler)</author>
      <guid isPermaLink="false">2504.19345v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Contextures: The Mechanism of Representation Learning</title>
      <link>http://arxiv.org/abs/2504.19792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD Dissertation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了情境理论，以数学方式描述了表示学习或预训练的机制。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在实证上取得了显著成功，但它们学习到的表示以及为什么这些表示对各种下游任务有用尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;对表示学习有一个科学理解，特别是在模型规模扩大导致回报递减，设计新的预训练方法对于进一步进步至关重要的时候。&lt;h4&gt;方法&lt;/h4&gt;情境理论提供了一个统一的框架来分析不同的表示学习方法，其核心论点是表示是通过输入X与情境变量A之间的关联来学习的。&lt;h4&gt;主要发现&lt;/h4&gt;如果编码器捕捉到这种关联的最大信息，即编码器学习到情境，那么它将在与情境兼容的任务类别中表现最优。此外，当X和A之间的关联既不过强也不过弱时，情境最有用。&lt;h4&gt;结论&lt;/h4&gt;情境理论的重要含义是，仅增加模型规模将导致回报递减，进一步的进步需要更好的情境。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了情境理论，用以数学化地刻画表示学习（预训练）的机制。尽管基础模型在实证上取得了显著的成功，但它们学习到的表示以及这些表示为何对各种下游任务有用尚不明确。对表示学习有一个科学理解至关重要，尤其是在模型规模扩大导致回报递减，设计新的预训练方法对于进一步进步变得至关重要的当下。先前的研究对不同的表示学习方法采取了不同的处理方式，而情境理论提供了一个统一的框架来分析这些方法。其核心论点是，表示是通过输入X与情境变量A之间的关联来学习的。我们证明了，如果编码器捕捉到这种关联的最大信息，在这种情况下我们说编码器学习到了情境，那么它将在与情境兼容的任务类别中表现最优。我们还表明，当X和A之间的关联既不过强也不过弱时，情境最有用。情境理论的重要含义是，仅增加模型规模将导致回报递减，进一步的进步需要更好的情境。我们证明了包括监督学习、自监督学习、生成模型等许多预训练目标都可以学习情境。然后，我们引入了两个用于学习情境的通用目标——SVME和KISE。我们还展示了如何混合多个情境，这是一种从现有情境中轻松创建更好情境的方法。然后，我们为表示学习证明了统计学习界限。最后，我们讨论了从预训练到下游任务的数据分布变化的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This dissertation establishes the contexture theory to mathematicallycharacterize the mechanism of representation learning, or pretraining. Despitethe remarkable empirical success of foundation models, it is not very clearwhat representations they learn, and why these representations are useful forvarious downstream tasks. A scientific understanding of representation learningis critical, especially at this point when scaling up the model size isproducing diminishing returns, and designing new pretraining methods isimperative for further progress.  Prior work treated different representation learning methods quitedifferently, whereas the contexture theory provides a unified framework foranalyzing these methods. The central argument is that a representation islearned from the association between the input X and a context variable A. Weprove that if an encoder captures the maximum information of this association,in which case we say that the encoder learns the contexture, then it will beoptimal on the class of tasks that are compatible with the context. We alsoshow that a context is the most useful when the association between X and A isneither too strong nor too weak. The important implication of the contexturetheory is that increasing the model size alone will achieve diminishingreturns, and further advancements require better contexts.  We demonstrate that many pretraining objectives can learn the contexture,including supervised learning, self-supervised learning, generative models,etc. Then, we introduce two general objectives -- SVME and KISE, for learningthe contexture. We also show how to mix multiple contexts together, aneffortless way to create better contexts from existing ones. Then, we provestatistical learning bounds for representation learning. Finally, we discussthe effect of the data distribution shift from pretraining to the downstreamtask.</description>
      <author>example@mail.com (Runtian Zhai)</author>
      <guid isPermaLink="false">2504.19792v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.19627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  VCM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VCM是一种端到端自监督视觉概念建模框架，旨在提高大型视觉语言模型（LVLMs）在现实世界应用中的效率和性能。&lt;h4&gt;背景&lt;/h4&gt;当前LVLMs在处理图像时效率低下，因为它们在标记级别处理整个图像，而人类可以在概念级别分析信息和生成内容。&lt;h4&gt;目的&lt;/h4&gt;提出VCM框架，以解决LVLMs缺乏视觉概念模型导致的效率低下问题。&lt;h4&gt;方法&lt;/h4&gt;VCM利用跨多个采样实例的隐式对比学习和视觉语言微调来构建视觉概念模型，无需昂贵的概念级别标注。&lt;h4&gt;主要发现&lt;/h4&gt;VCM显著降低了计算成本（例如，LLaVA-1.5-7B的FLOPs减少了85%）同时保持了在多种图像理解任务上的强大性能。此外，VCM增强了视觉编码器在经典视觉概念感知任务中的能力。&lt;h4&gt;结论&lt;/h4&gt;广泛的定量和定性实验验证了VCM的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks likeembodied intelligence due to their strong vision-language reasoning abilities.However, current LVLMs process entire images at the token level, which isinefficient compared to humans who analyze information and generate content atthe conceptual level, extracting relevant visual concepts with minimal effort.This inefficiency, stemming from the lack of a visual concept model, limitsLVLMs' usability in real-world applications. To address this, we propose VCM,an end-to-end self-supervised visual concept modeling framework. VCM leveragesimplicit contrastive learning across multiple sampled instances andvision-language fine-tuning to construct a visual concept model withoutrequiring costly concept-level annotations. Our results show that VCMsignificantly reduces computational costs (e.g., 85\% fewer FLOPs forLLaVA-1.5-7B) while maintaining strong performance across diverse imageunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities inclassic visual concept perception tasks. Extensive quantitative and qualitativeexperiments validate the effectiveness and efficiency of VCM.</description>
      <author>example@mail.com (Run Luo, Renke Shan, Longze Chen, Ziqiang Liu, Lu Wang, Min Yang, Xiaobo Xia)</author>
      <guid isPermaLink="false">2504.19627v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>OpenFusion++: An Open-vocabulary Real-time Scene Understanding System</title>
      <link>http://arxiv.org/abs/2504.19266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OpenFusion++是一种基于TSDF的实时3D语义-几何重建系统，旨在解决现有方法在实例分割、语义更新和复杂查询处理方面的不足。&lt;h4&gt;背景&lt;/h4&gt;实时开放词汇场景理解对于视觉语言导航、具身智能和增强现实等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的问题，如不精确的实例分割、静态语义更新和复杂查询处理能力有限。&lt;h4&gt;方法&lt;/h4&gt;OpenFusion++通过融合基础模型中的置信图来优化3D点云，使用基于实例面积的自适应缓存动态更新全局语义标签，并采用双路径编码框架将对象属性与环境上下文集成，以实现精确的查询响应。&lt;h4&gt;主要发现&lt;/h4&gt;在ICL、Replica、ScanNet和ScanNet++数据集上的实验表明，OpenFusion++在语义准确性和查询响应速度方面均显著优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;OpenFusion++能够有效提升3D感知的效率和准确性，为视觉语言导航、具身智能和增强现实等应用提供强有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;实时开放词汇场景理解对于高效的三维感知至关重要，对于如视觉语言导航、具身智能和增强现实等应用至关重要。然而，现有方法在实例分割、静态语义更新和复杂查询处理方面存在不足。为了解决这些问题，我们提出了一种基于TSDF的实时3D语义-几何重建系统，称为OpenFusion++。我们的方法通过融合基础模型的置信图来优化3D点云，通过基于实例面积的自适应缓存动态更新全局语义标签，并采用双路径编码框架将对象属性与环境上下文集成，以实现精确的查询响应。在ICL、Replica、ScanNet和ScanNet++数据集上的实验表明，OpenFusion++在语义准确性和查询响应速度方面均显著优于基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time open-vocabulary scene understanding is essential for efficient 3Dperception in applications such as vision-language navigation, embodiedintelligence, and augmented reality. However, existing methods suffer fromimprecise instance segmentation, static semantic updates, and limited handlingof complex queries. To address these issues, we present OpenFusion++, aTSDF-based real-time 3D semantic-geometric reconstruction system. Our approachrefines 3D point clouds by fusing confidence maps from foundational models,dynamically updates global semantic labels via an adaptive cache based oninstance area, and employs a dual-path encoding framework that integratesobject attributes with environmental context for precise query responses.Experiments on the ICL, Replica, ScanNet, and ScanNet++ datasets demonstratethat OpenFusion++ significantly outperforms the baseline in both semanticaccuracy and query responsiveness.</description>
      <author>example@mail.com (Xiaofeng Jin, Matteo Frosi, Matteo Matteucci)</author>
      <guid isPermaLink="false">2504.19266v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Fourier Transformer with Structure-Frequency Information</title>
      <link>http://arxiv.org/abs/2504.19740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Grafourierformer，一种结合了图傅里叶变换的图变换器（GTs），通过考虑节点频率信息来优化注意力机制，以提升图结构任务的性能。&lt;h4&gt;背景&lt;/h4&gt;虽然图变换器在图结构任务中表现出优势，但其自注意力机制忽略了图的一般化偏差，现有方法主要通过位置编码、注意力偏差和相对距离等方面进行补偿，但性能仍不理想。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理图的一般化偏差的方法，并提升图分类和节点分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;Grafourierformer通过将图傅里叶变换应用于注意力矩阵，使用图拉普拉斯矩阵的特征值构建特征值矩阵掩码，并通过傅里叶逆变换提取节点的高频和低频特征，构建节点频率能量矩阵，以实现注意力头对图结构信息和节点频率信息的优化。&lt;h4&gt;主要发现&lt;/h4&gt;Grafourierformer在多个基准测试中均优于GNN和基于GT的模型，消融实验进一步验证了该方法的有效性和必要性。&lt;h4&gt;结论&lt;/h4&gt;Grafourierformer通过结合图傅里叶变换和节点频率信息，有效地抑制了冗余信息干扰，提升了图结构任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers have shown advantages in numerous graph structure tasks but their self-attention mechanism ignores the generalization bias of graphs, with existing methods mainly compensating for this bias from aspects like position encoding, attention bias and relative distance yet still having sub-optimal performance and being insufficient by only considering the structural perspective of generalization bias. To address this, this paper proposes Grafourierformer, which innovatively combines GT with inductive bias containing Frequency-Structure information by applying Graph Fourier Transform to the Attention Matrix: specifically, eigenvalues from the Graph Laplacian matrix are used to construct an Eigenvalue matrix mask (reflecting node positions and structural relationships with neighboring nodes to enable consideration of node range structural characteristics and focus on local graph details), and inverse Fourier transform is employed to extract node high-frequency and low-frequency features, calculate low-frequency and high-frequency energy, and construct a node frequency-energy matrix to filter the eigenvalue matrix mask, allowing attention heads to incorporate both graph structural information and node frequency information optimization, adaptively distinguish global trends from local details, and effectively suppress redundant information interference. Extensive experiments on various benchmarks show Grafourierformer consistently outperforms GNN and GT-based models in graph classification and node classification tasks, with ablation experiments further validating the effectiveness and necessity of the method. Codes are available at https://github.com/Arichibald/Grafourierformer.git&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have shown advantages in numerous graph structuretasks but their self-attention mechanism ignores the generalization bias ofgraphs, with existing methods mainly compensating for this bias from aspectslike position encoding, attention bias and relative distance yet still havingsub-optimal performance and being insufficient by only considering thestructural perspective of generalization bias. To address this, this paperproposes Grafourierformer, which innovatively combines GT with inductive biascontaining Frequency-Structure information by applying Graph Fourier Transformto the Attention Matrix: specifically, eigenvalues from the Graph Laplacianmatrix are used to construct an Eigenvalue matrix mask (reflecting nodepositions and structural relationships with neighboring nodes to enableconsideration of node range structural characteristics and focus on local graphdetails), and inverse Fourier transform is employed to extract nodehigh-frequency and low-frequency features, calculate low-frequency andhigh-frequency energy, and construct a node frequency-energy matrix to filterthe eigenvalue matrix mask, allowing attention heads to incorporate both graphstructural information and node frequency information optimization, adaptivelydistinguish global trends from local details, and effectively suppressredundant information interference. Extensive experiments on various benchmarksshow Grafourierformer consistently outperforms GNN and GT-based models in graphclassification and node classification tasks, with ablation experiments furthervalidating the effectiveness and necessity of the method. Codes are availableat https://github.com/Arichibald/Grafourierformer.git</description>
      <author>example@mail.com (Yonghui Zhai, Yang Zhang, Minghao Shang, Lihua Pang, Yaxin Ren)</author>
      <guid isPermaLink="false">2504.19740v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model</title>
      <link>http://arxiv.org/abs/2504.19739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AffectVLM，这是一种用于从3D/4D数据中理解面部情感的多视角视觉语言模型。&lt;h4&gt;背景&lt;/h4&gt;该模型旨在通过集成多视角来提供语义丰富和视觉全面的情感理解。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够有效捕捉视觉特征并具有良好语言能力的模型，同时能够进行实时交互推理和分布式学习。&lt;h4&gt;方法&lt;/h4&gt;方法包括提出一个联合表示学习框架和新的梯度友好损失函数，引入增强文本提示和混合视角增强，以及开发一个Streamlit应用程序用于实时交互推理。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验验证了AffectVLM在多个基准测试中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;AffectVLM在面部情感理解方面表现出色，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce AffectVLM, a vision-language model designed tointegrate multiviews for a semantically rich and visually comprehensiveunderstanding of facial emotions from 3D/4D data. To effectively capture visualfeatures, we propose a joint representation learning framework paired with anovel gradient-friendly loss function that accelerates model convergencetowards optimal feature representation. Additionally, we introduce augmentedtextual prompts to enhance the model's linguistic capabilities and employ mixedview augmentation to expand the visual dataset. We also develop a Streamlit appfor a real-time interactive inference and enable the model for distributedlearning. Extensive experiments validate the superior performance of AffectVLMacross multiple benchmarks.</description>
      <author>example@mail.com (Muzammil Behzad, Guoying Zhao)</author>
      <guid isPermaLink="false">2504.19739v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis</title>
      <link>http://arxiv.org/abs/2504.19223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为CARL的模型，用于跨不同成像模态（如RGB、多光谱和超光谱成像）进行相机无关的表征学习，以解决光谱成像在人工智能应用中的挑战。&lt;h4&gt;背景&lt;/h4&gt;光谱成像在医学和城市场景理解等领域具有广泛应用前景，但在遥感领域已确立为关键模态。然而，不同光谱相机在通道维度和捕获波长上的差异阻碍了AI驱动方法的发展，导致具有有限泛化能力和不足跨相机适用性的相机特定模型。&lt;h4&gt;目的&lt;/h4&gt;提出CARL模型，旨在解决光谱成像在AI应用中的瓶颈，实现不同通道维度的光谱图像到相机无关嵌入的转换。&lt;h4&gt;方法&lt;/h4&gt;CARL模型通过波长位置编码和自注意力-交叉注意力机制，将光谱信息压缩到学习的查询表示中。采用一种新的基于JEPA的谱自监督策略进行光谱-空间预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在大规模实验中，CARL模型在医学成像、自动驾驶和卫星成像等领域显示出对光谱异质性的独特鲁棒性，在具有模拟和真实世界跨相机光谱变化的数据库上表现优于其他模型。&lt;h4&gt;结论&lt;/h4&gt;该模型的可扩展性和多功能性使其成为未来光谱基础模型的骨干。&lt;h4&gt;翻译&lt;/h4&gt;Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing. However, variability in channel dimensionality and captured wavelengths among spectral cameras impedes the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability. To address this bottleneck, we introduce $extbf{CARL}$, a model for $extbf{C}$amera-$extbf{A}$gnostic $extbf{R}$epresentation$extbf{L}$earning across RGB, multispectral, and hyperspectral imaging modalities. To enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic embedding, we introduce wavelength positional encoding and a self-attention-cross-attention mechanism to compress spectral information into learned query representations. Spectral-spatial pre-training is achieved with a novel spectral self-supervised JEPA-inspired strategy tailored to CARL. Large-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. The scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spectral imaging offers promising applications across diverse domains,including medicine and urban scene understanding, and is already established asa critical modality in remote sensing. However, variability in channeldimensionality and captured wavelengths among spectral cameras impede thedevelopment of AI-driven methodologies, leading to camera-specific models withlimited generalizability and inadequate cross-camera applicability. To addressthis bottleneck, we introduce $\textbf{CARL}$, a model for$\textbf{C}$amera-$\textbf{A}$gnostic $\textbf{R}$epresentation$\textbf{L}$earning across RGB, multispectral, and hyperspectral imagingmodalities. To enable the conversion of a spectral image with any channeldimensionality to a camera-agnostic embedding, we introduce wavelengthpositional encoding and a self-attention-cross-attention mechanism to compressspectral information into learned query representations. Spectral-spatialpre-training is achieved with a novel spectral self-supervised JEPA-inspiredstrategy tailored to CARL. Large-scale experiments across the domains ofmedical imaging, autonomous driving, and satellite imaging demonstrate ourmodel's unique robustness to spectral heterogeneity, outperforming on datasetswith simulated and real-world cross-camera spectral variations. The scalabilityand versatility of the proposed approach position our model as a backbone forfuture spectral foundation models.</description>
      <author>example@mail.com (Alexander Baumann, Leonardo Ayala, Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Berkin Özdemir, Lena Maier-Hein, Slobodan Ilic)</author>
      <guid isPermaLink="false">2504.19223v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Improving Pretrained YAMNet for Enhanced Speech Command Detection via Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.19030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究旨在提高语音命令识别系统的准确性和效率，通过使用预训练的YAMNet模型和迁移学习技术，显著提升了语音命令识别效果。&lt;h4&gt;背景&lt;/h4&gt;语音命令识别是智能应用中用户交互的关键组成部分，目前存在准确性和效率的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，以增强语音命令识别系统的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的YAMNet模型和迁移学习技术，对语音命令进行检测和解释，并在Speech Commands数据集上进行了细致的数据增强和特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，模型达到了95.28%的识别准确率，证明了高级机器学习技术在语音命令识别中的影响。&lt;h4&gt;结论&lt;/h4&gt;这一成果在音频处理技术方面取得了实质性进展，并为该领域未来的研究设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;This work addresses the need for enhanced accuracy and efficiency in speech command recognition systems, a critical component for improving user interaction in various smart applications. Leveraging the robust pretrained YAMNet model and transfer learning, this study develops a method that significantly improves speech command recognition. We adapt and train a YAMNet deep learning model to effectively detect and interpret speech commands from audio signals. Using the extensively annotated Speech Commands dataset (speech_commands_v0.01), our approach demonstrates the practical application of transfer learning to accurately recognize a predefined set of speech commands. The dataset is meticulously augmented, and features are strategically extracted to boost model performance. As a result, the final model achieved a recognition accuracy of 95.28%, underscoring the impact of advanced machine learning techniques on speech command recognition. This achievement marks substantial progress in audio processing technologies and establishes a new benchmark for future research in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICTIS62692.2024.10894266&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the need for enhanced accuracy and efficiency in speechcommand recognition systems, a critical component for improving userinteraction in various smart applications. Leveraging the robust pretrainedYAMNet model and transfer learning, this study develops a method thatsignificantly improves speech command recognition. We adapt and train a YAMNetdeep learning model to effectively detect and interpret speech commands fromaudio signals. Using the extensively annotated Speech Commands dataset(speech_commands_v0.01), our approach demonstrates the practical application oftransfer learning to accurately recognize a predefined set of speech commands.The dataset is meticulously augmented, and features are strategically extractedto boost model performance. As a result, the final model achieved a recognitionaccuracy of 95.28%, underscoring the impact of advanced machine learningtechniques on speech command recognition. This achievement marks substantialprogress in audio processing technologies and establishes a new benchmark forfuture research in the field.</description>
      <author>example@mail.com (Sidahmed Lachenani, Hamza Kheddar, Mohamed Ouldzmirli)</author>
      <guid isPermaLink="false">2504.19030v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Semantic-Aligned Learning with Collaborative Refinement for Unsupervised VI-ReID</title>
      <link>http://arxiv.org/abs/2504.19244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SALCR的无监督可见光-红外行人重识别框架，该框架通过语义对齐学习和协作优化来提高跨模态图像的重识别性能。&lt;h4&gt;背景&lt;/h4&gt;当前方法在统一跨模态图像的伪标签和设计对比学习框架时，忽略了特征表示和伪标签分布的跨模态变化。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有方法中由于只优化全局特征而导致的模态共享学习不足的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出DAGI模块双向统一跨模态实例的伪标签；2. 使用FGSAL模块探索跨模态实例中每种模态强调的语义对齐模式；3. 基于语义对齐特征及其对应的标签空间构建优化目标；4. 提出GPCR模块动态挖掘可靠的正样本集，优化实例间关系。&lt;h4&gt;主要发现&lt;/h4&gt;SALCR框架通过强调特定细粒度模式，实现了不同模态标签分布的互补对齐。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在性能上优于现有方法，并且代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;The proposed SALCR framework for unsupervised visible-infrared person re-identification addresses the insufficient modality-shared learning issue in existing methods by employing semantic-aligned learning and collaborative refinement. It achieves complementary alignment between the label distributions of different modalities by emphasizing specific fine-grained patterns. Extensive experiments demonstrate its superiority over state-of-the-art methods, and the code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised visible-infrared person re-identification (USL-VI-ReID) seeks tomatch pedestrian images of the same individual across different modalitieswithout human annotations for model learning. Previous methods unifypseudo-labels of cross-modality images through label association algorithms andthen design contrastive learning framework for global feature learning.However, these methods overlook the cross-modality variations in featurerepresentation and pseudo-label distributions brought by fine-grained patterns.This insight results in insufficient modality-shared learning when only globalfeatures are optimized. To address this issue, we propose a Semantic-AlignedLearning with Collaborative Refinement (SALCR) framework, which builds upoptimization objective for specific fine-grained patterns emphasized by eachmodality, thereby achieving complementary alignment between the labeldistributions of different modalities. Specifically, we first introduce a DualAssociation with Global Learning (DAGI) module to unify the pseudo-labels ofcross-modality instances in a bi-directional manner. Afterward, a Fine-GrainedSemantic-Aligned Learning (FGSAL) module is carried out to explore part-levelsemantic-aligned patterns emphasized by each modality from cross-modalityinstances. Optimization objective is then formulated based on thesemantic-aligned features and their corresponding label space. To alleviate theside-effects arising from noisy pseudo-labels, we propose a Global-PartCollaborative Refinement (GPCR) module to mine reliable positive sample setsfor the global and part features dynamically and optimize the inter-instancerelationships. Extensive experiments demonstrate the effectiveness of theproposed method, which achieves superior performances to state-of-the-artmethods. Our code is available at\href{https://github.com/FranklinLingfeng/code-for-SALCR}.</description>
      <author>example@mail.com (De Cheng, Lingfeng He, Nannan Wang, Dingwen Zhang, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.19244v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration</title>
      <link>http://arxiv.org/abs/2504.19847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Seg2HOI的新框架，该框架将基于分割的视觉基础模型与人类-物体交互任务相结合，区别于传统的基于检测的人类-物体交互方法。&lt;h4&gt;背景&lt;/h4&gt;在人类-物体交互（HOI）任务中，传统方法依赖于检测，而本文提出的方法采用分割技术。&lt;h4&gt;目的&lt;/h4&gt;提高HOI检测的准确性，并通过引入四元组扩展三元组，包括人类-物体对的分割掩码。&lt;h4&gt;方法&lt;/h4&gt;Seg2HOI继承了视觉基础模型（如可提示和交互机制）的特性，并包含一个解码器，将这些属性应用于HOI任务。尽管仅针对HOI进行训练，但没有对这些属性进行额外的训练机制，该框架仍然表现出高效的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共基准数据集上的大量实验表明，Seg2HOI即使在零样本场景下也能达到与最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;Seg2HOI可以从未在训练中使用的新型文本和视觉提示中生成HOI四元组和交互式HOI分割，这使得它能够通过这种灵活性在广泛的应用中发挥作用。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we introduce Segmentation to Human-Object Interaction (Seg2HOI) approach, a novel framework that integrates segmentation-based vision foundation models with the human-object interaction task, distinguished from traditional detection-based Human-Object Interaction (HOI) methods. Our approach enhances HOI detection by not only predicting the standard triplets but also introducing quadruplets, which extend HOI triplets by including segmentation masks for human-object pairs. More specifically, Seg2HOI inherits the properties of the vision foundation model (e.g., promptable and interactive mechanisms) and incorporates a decoder that applies these attributes to the HOI task. Despite training only for HOI, without additional training mechanisms for these properties, the framework demonstrates that such features still operate efficiently. Extensive experiments on two public benchmark datasets demonstrate that Seg2HOI achieves performance comparable to state-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that Seg2HOI can generate HOI quadruplets and interactive HOI segmentation from novel text and visual prompts that were not used during training, making it versatile for a wide range of applications by leveraging this flexibility.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce Segmentation to Human-Object Interaction(\textit{\textbf{Seg2HOI}}) approach, a novel framework that integratessegmentation-based vision foundation models with the human-object interactiontask, distinguished from traditional detection-based Human-Object Interaction(HOI) methods. Our approach enhances HOI detection by not only predicting thestandard triplets but also introducing quadruplets, which extend HOI tripletsby including segmentation masks for human-object pairs. More specifically,Seg2HOI inherits the properties of the vision foundation model (e.g.,promptable and interactive mechanisms) and incorporates a decoder that appliesthese attributes to HOI task. Despite training only for HOI, without additionaltraining mechanisms for these properties, the framework demonstrates that suchfeatures still operate efficiently. Extensive experiments on two publicbenchmark datasets demonstrate that Seg2HOI achieves performance comparable tostate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose thatSeg2HOI can generate HOI quadruplets and interactive HOI segmentation fromnovel text and visual prompts that were not used during training, making itversatile for a wide range of applications by leveraging this flexibility.</description>
      <author>example@mail.com (Juhan Park, Kyungjae Lee, Hyung Jin Chang, Jungchan Cho)</author>
      <guid isPermaLink="false">2504.19847v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information</title>
      <link>http://arxiv.org/abs/2504.18854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两相随机材料（TRM）的应力分析，提出了一种基于深度学习的应力预测框架。&lt;h4&gt;背景&lt;/h4&gt;应力分析是材料设计的重要部分，对于具有复杂微结构的材料，如两相随机材料，应力集中是材料失效的常见原因，而相界面是应力集中的关键。&lt;h4&gt;目的&lt;/h4&gt;减少相界面的应力预测误差，提高应力图像的分辨率，并实现多尺度分析。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MC U-net的神经网络来预测低分辨率材料微结构中的应力，并引入了相界面信息以减少预测误差；同时，提出了一种基于物理信息混合的神经网络（MPINN）的方法，用于应力图像超分辨率，无需成对训练数据，并能提高应力图像的分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效减少相界面的预测误差，提高应力图像的分辨率，并实现多尺度分析。&lt;h4&gt;结论&lt;/h4&gt;所提出的应力预测框架具有较高的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Stress analysis is an important part of material design. For materials with complex microstructures, such as two-phase random materials (TRMs), material failure is often accompanied by stress concentration. Phase interfaces in two-phase materials are critical for stress concentration. Therefore, the prediction error of stress at phase boundaries is crucial. In practical engineering, the pixels of the obtained material microstructure images are limited, which limits the resolution of stress images generated by deep learning methods, making it difficult to observe stress concentration regions. Existing Image Super-Resolution (ISR) technologies are all based on data-driven supervised learning. However, stress images have natural physical constraints, which provide new ideas for new ISR technologies. In this study, we constructed a stress prediction framework for TRMs. First, the framework uses a proposed Multiple Compositions U-net (MC U-net) to predict stress in low-resolution material microstructures. By considering the phase interface information of the microstructure, the MC U-net effectively reduces the problem of excessive prediction errors at phase boundaries. Secondly, a Mixed Physics-Informed Neural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By introducing the constraints of physical information, the new method does not require paired stress images for training and can increase the resolution of stress images to any multiple. This enables a multiscale analysis of the stress concentration regions at phase boundaries. Finally, we performed stress analysis on TRMs with different phase volume fractions and loading states through transfer learning. The results show the proposed stress prediction framework has satisfactory accuracy and generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.2139/ssrn.5096177&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stress analysis is an important part of material design. For materials withcomplex microstructures, such as two-phase random materials (TRMs), materialfailure is often accompanied by stress concentration. Phase interfaces intwo-phase materials are critical for stress concentration. Therefore, theprediction error of stress at phase boundaries is crucial. In practicalengineering, the pixels of the obtained material microstructure images arelimited, which limits the resolution of stress images generated by deeplearning methods, making it difficult to observe stress concentration regions.Existing Image Super-Resolution (ISR) technologies are all based on data-drivensupervised learning. However, stress images have natural physical constraints,which provide new ideas for new ISR technologies. In this study, we constructeda stress prediction framework for TRMs. First, the framework uses a proposedMultiple Compositions U-net (MC U-net) to predict stress in low-resolutionmaterial microstructures. By considering the phase interface information of themicrostructure, the MC U-net effectively reduces the problem of excessiveprediction errors at phase boundaries. Secondly, a Mixed Physics-InformedNeural Network (MPINN) based method for stress ISR (SRPINN) was proposed. Byintroducing the constraints of physical information, the new method does notrequire paired stress images for training and can increase the resolution ofstress images to any multiple. This enables a multiscale analysis of the stressconcentration regions at phase boundaries. Finally, we performed stressanalysis on TRMs with different phase volume fractions and loading statesthrough transfer learning. The results show the proposed stress predictionframework has satisfactory accuracy and generalization ability.</description>
      <author>example@mail.com (Tengfei Xing, Xiaodan Ren, Jie Li)</author>
      <guid isPermaLink="false">2504.18854v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Pair Selection</title>
      <link>http://arxiv.org/abs/2504.19178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code can be found at https://github.com/Cloudcatcher888/RCL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为RCL的相对对比学习框架，用于序列推荐模型的训练，以改善对比学习的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的对比学习方法通常依赖于数据增强策略来创建正样本和促进表示不变性，但可能会无意中改变用户意图。&lt;h4&gt;目的&lt;/h4&gt;解决监督对比学习（SCL）方法由于同目标序列稀缺而缺乏足够信号的问题。&lt;h4&gt;方法&lt;/h4&gt;提出使用相似序列（具有不同目标项目）作为额外的正样本，并引入RCL框架。RCL包括双级正样本选择模块和相对对比学习模块，分别用于选择强正样本和弱正样本，以及确保每个序列更接近其强正样本。&lt;h4&gt;主要发现&lt;/h4&gt;将RCL应用于两个主流的深度学习序列推荐模型，实验结果表明，在五个公共数据集和一个私有数据集上，RCL的平均性能比最先进的序列推荐方法提高了4.88%。&lt;h4&gt;结论&lt;/h4&gt;RCL能够有效提高序列推荐模型的性能，是一个有潜力的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3627673.3679681&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL) enhances the training of sequential recommendation(SR) models through informative self-supervision signals. Existing methodsoften rely on data augmentation strategies to create positive samples andpromote representation invariance. Some strategies such as item reordering anditem substitution may inadvertently alter user intent. Supervised ContrastiveLearning (SCL) based methods find an alternative to augmentation-based CLmethods by selecting same-target sequences (interaction sequences with the sametarget item) to form positive samples. However, SCL-based methods suffer fromthe scarcity of same-target sequences and consequently lack enough signals forcontrastive learning. In this work, we propose to use similar sequences (withdifferent target items) as additional positive samples and introduce a RelativeContrastive Learning (RCL) framework for sequential recommendation. RCLcomprises a dual-tiered positive sample selection module and a relativecontrastive learning module. The former module selects same-target sequences asstrong positive samples and selects similar sequences as weak positive samples.The latter module employs a weighted relative contrastive loss, ensuring thateach sequence is represented closer to its strong positive samples than itsweak positive samples. We apply RCL on two mainstream deep learning-based SRmodels, and our empirical results reveal that RCL can achieve 4.88% improvementaveragely than the state-of-the-art SR methods on five public datasets and oneprivate dataset.</description>
      <author>example@mail.com (Zhikai Wang, Yanyan Shen, Zexi Zhang, Li He, Yichun Li, Hao Gu, Yinghua Zhang)</author>
      <guid isPermaLink="false">2504.19178v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>FiberKAN: Kolmogorov-Arnold Networks for Nonlinear Fiber Optics</title>
      <link>http://arxiv.org/abs/2504.18833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Kolmogorov-Arnold网络（KAN）的人工智能科学（AI4S）框架FiberKAN，用于非线性光纤的科学研究与动态特性描述。&lt;h4&gt;背景&lt;/h4&gt;尽管许多系统动力学已经从严格的原理推导出理论，但仍有大量复杂的动力学尚未被发现和描述，这阻碍了相关领域科学进步。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种新的AI4S框架，用于科学发现和动态特性描述。&lt;h4&gt;方法&lt;/h4&gt;提出了FiberKAN框架，该框架使用KAN而非传统的多层感知器（MLP）结构，并具有可训练和透明的激活函数，增强了网络的物理可解释性和非线性特征描述能力。&lt;h4&gt;主要发现&lt;/h4&gt;KAN可以有效地发现和描述不同影响下的显式、隐式和非解析解，并且在与MLP具有等效可训练参数规模的情况下，性能更优。&lt;h4&gt;结论&lt;/h4&gt;这项工作突出了KAN的变革潜力，将其确立为AI4S的先驱范式，推动了非线性光纤光学领域的进步，并在广泛的科学和工程学科中促进了创新。&lt;h4&gt;翻译&lt;/h4&gt;Scientific discovery and dynamic characterization of the physical system play a critical role in understanding, learning, and modeling the physical phenomena and behaviors in various fields. Although theories and laws of many system dynamics have been derived from rigorous first principles, there are still a considerable number of complex dynamics that have not yet been discovered and characterized, which hinders the progress of science in corresponding fields. To address these challenges, artificial intelligence for science (AI4S) has emerged as a burgeoning research field. In this paper, a Kolmogorov-Arnold Network (KAN)-based AI4S framework named FiberKAN is proposed for scientific discovery and dynamic characterization of nonlinear fiber optics. Unlike the classic multi-layer perceptron (MLP) structure, the trainable and transparent activation functions in KAN make the network have stronger physical interpretability and nonlinear characterization abilities. Multiple KANs are established for fiber-optic system dynamics under various physical effects. Results show that KANs can well discover and characterize the explicit, implicit, and non-analytical solutions under different effects, and achieve better performance than MLPs with the equivalent scale of trainable parameters. Moreover, the effectiveness, computational cost, interactivity, noise resistance, transfer learning ability, and comparison between related algorithms in fiber-optic systems are also studied and analyzed. This work highlights the transformative potential of KAN, establishing it as a pioneering paradigm in AI4S that propels advancements in nonlinear fiber optics, and fosters groundbreaking innovations across a broad spectrum of scientific and engineering disciplines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific discovery and dynamic characterization of the physical system playa critical role in understanding, learning, and modeling the physical phenomenaand behaviors in various fields. Although theories and laws of many systemdynamics have been derived from rigorous first principles, there are still aconsiderable number of complex dynamics that have not yet been discovered andcharacterized, which hinders the progress of science in corresponding fields.To address these challenges, artificial intelligence for science (AI4S) hasemerged as a burgeoning research field. In this paper, a Kolmogorov-ArnoldNetwork (KAN)-based AI4S framework named FiberKAN is proposed for scientificdiscovery and dynamic characterization of nonlinear fiber optics. Unlike theclassic multi-layer perceptron (MLP) structure, the trainable and transparentactivation functions in KAN make the network have stronger physicalinterpretability and nonlinear characterization abilities. Multiple KANs areestablished for fiber-optic system dynamics under various physical effects.Results show that KANs can well discover and characterize the explicit,implicit, and non-analytical solutions under different effects, and achievebetter performance than MLPs with the equivalent scale of trainable parameters.Moreover, the effectiveness, computational cost, interactivity, noiseresistance, transfer learning ability, and comparison between relatedalgorithms in fiber-optic systems are also studied and analyzed. This workhighlights the transformative potential of KAN, establishing it as a pioneeringparadigm in AI4S that propels advancements in nonlinear fiber optics, andfosters groundbreaking innovations across a broad spectrum of scientific andengineering disciplines.</description>
      <author>example@mail.com (Xiaotian Jiang, Min Zhang, Xiao Luo, Zelai Yu, Yiming Meng, Danshi Wang)</author>
      <guid isPermaLink="false">2504.18833v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Informed Neural Operator Transformer</title>
      <link>http://arxiv.org/abs/2504.19452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GINOT的机器学习代理模型，该模型结合了transformer架构和神经算子框架，能够对任意几何形状进行正向预测，具有计算效率高、模拟速度快的特点。&lt;h4&gt;背景&lt;/h4&gt;传统的数值方法在需要重复求解偏微分方程的问题上计算效率较低，而基于机器学习的代理模型则提供了显著的计算效率提升。&lt;h4&gt;目的&lt;/h4&gt;提出GINOT模型，以实现对任意几何形状的高精度正向预测。&lt;h4&gt;方法&lt;/h4&gt;GINOT通过采样和分组机制以及注意力机制对几何形状的点云进行编码，确保对点顺序和填充的不变性，同时保持对点密度变化的鲁棒性。几何信息通过注意力机制与解的查询点无缝集成。&lt;h4&gt;主要发现&lt;/h4&gt;GINOT在多个具有挑战性的数据集上进行了验证，展示了其在复杂和任意2D和3D几何形状上的高精度和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;GINOT模型在计算效率和预测精度方面具有显著优势，适用于需要重复计算偏微分方程的问题。&lt;h4&gt;翻译&lt;/h4&gt;Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface points cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based surrogate models offer significant computationalefficiency and faster simulations compared to traditional numerical methods,especially for problems requiring repeated evaluations of partial differentialequations. This work introduces the Geometry-Informed Neural OperatorTransformer (GINOT), which integrates the transformer architecture with theneural operator framework to enable forward predictions for arbitrarygeometries. GINOT encodes the surface points cloud of a geometry using asampling and grouping mechanism combined with an attention mechanism, ensuringinvariance to point order and padding while maintaining robustness tovariations in point density. The geometry information is seamlessly integratedwith query points in the solution decoder through the attention mechanism. Theperformance of GINOT is validated on multiple challenging datasets, showcasingits high accuracy and strong generalization capabilities for complex andarbitrary 2D and 3D geometries.</description>
      <author>example@mail.com (Qibang Liu, Vincient Zhong, Hadi Meidani, Diab Abueidda, Seid Koric, Philippe Geubelle)</author>
      <guid isPermaLink="false">2504.19452v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Learning Efficiency Meets Symmetry Breaking</title>
      <link>http://arxiv.org/abs/2504.19738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于图神经网络的学习型规划器，该规划器能够学习适用于大搜索空间的搜索指导，但其在处理对称性方面的潜力尚未得到充分探索。&lt;h4&gt;背景&lt;/h4&gt;现有的学习型规划器虽然能够学习适用于大搜索空间的搜索指导，但尚未探索如何处理搜索空间中的对称性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够检测对称性并提高学习效率的图表示方法，以及两种剪枝方法（动作剪枝和状态剪枝）来管理搜索过程中的对称性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种图表示规划问题的方法，并整合了动作剪枝和状态剪枝技术，以提高规划器的学习效率和对称性处理能力。&lt;h4&gt;主要发现&lt;/h4&gt;将提出的方法整合到Fast Downward中，在最新的IPC学习轨迹数据集上首次成功超越LAMA。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在处理规划问题的对称性方面取得了显著成效。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a learning-based planner leveraging Graph Neural Networks, which can learn search guidance applicable to large search spaces, yet the potential to address symmetries remains largely unexplored. In this paper, we introduce a graph representation of planning problems, which combines learning efficiency with the ability to detect symmetries, along with two pruning methods, action pruning and state pruning, designed to manage symmetries during search. The integration of these techniques into Fast Downward achieves a first-time success over LAMA on the latest IPC learning track dataset. Code is released at: https://github.com/bybeye/Distincter.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based planners leveraging Graph Neural Networks can learn searchguidance applicable to large search spaces, yet their potential to addresssymmetries remains largely unexplored. In this paper, we introduce a graphrepresentation of planning problems allying learning efficiency with theability to detect symmetries, along with two pruning methods, action pruningand state pruning, designed to manage symmetries during search. The integrationof these techniques into Fast Downward achieves a first-time success over LAMAon the latest IPC learning track dataset. Code is released at:https://github.com/bybeye/Distincter.</description>
      <author>example@mail.com (Yingbin Bai, Sylvie Thiebaux, Felipe Trevizan)</author>
      <guid isPermaLink="false">2504.19738v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>ALF: Advertiser Large Foundation Model for Multi-Modal Advertiser Understanding</title>
      <link>http://arxiv.org/abs/2504.18785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALF的多模态Transformer架构，用于理解广告商在文本、图像、视频和结构化数据模态中的行为和意图。&lt;h4&gt;背景&lt;/h4&gt;研究者们在分析广告商行为和意图方面面临挑战，需要一种能够处理多种数据模态的模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效理解广告商行为和意图的模型，以应用于欺诈检测、违规政策识别和广告商相似度匹配等任务。&lt;h4&gt;方法&lt;/h4&gt;ALF通过对比学习和多任务优化，创建统一的广告商表示，捕捉内容和行为模式。其架构结合了多模态变换、样本间注意力机制、频谱归一化投影和校准概率输出。&lt;h4&gt;主要发现&lt;/h4&gt;ALF在关键任务上实现了最先进的性能，如欺诈检测、违规政策识别和广告商相似度匹配。在生产部署中，ALF将滥用检测任务中的误报率降低了90%，同时保持了99.8%的精确度。&lt;h4&gt;结论&lt;/h4&gt;ALF的有效性源于其新颖的多模态变换组合、样本间注意力机制、频谱归一化投影和校准概率输出的结合。&lt;h4&gt;翻译&lt;/h4&gt;We present ALF (Advertiser Large Foundation model), a multi-modal transformer architecture for understanding advertiser behavior and intent across text, image, video and structured data modalities. Through contrastive learning and multi-task optimization, ALF creates unified advertiser representations that capture both content and behavioral patterns. Our model achieves state-of-the-art performance on critical tasks including fraud detection, policy violation identification, and advertiser similarity matching. In production deployment, ALF reduces false positives by 90% while maintaining 99.8% precision on abuse detection tasks. The architecture's effectiveness stems from its novel combination of multi-modal transformations, inter-sample attention mechanism, spectrally normalized projections, and calibrated probabilistic outputs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ALF (Advertiser Large Foundation model), a multi-modal transformerarchitecture for understanding advertiser behavior and intent across text,image, video and structured data modalities. Through contrastive learning andmulti-task optimization, ALF creates unified advertiser representations thatcapture both content and behavioral patterns. Our model achievesstate-of-the-art performance on critical tasks including fraud detection,policy violation identification, and advertiser similarity matching. Inproduction deployment, ALF reduces false positives by 90% while maintaining99.8% precision on abuse detection tasks. The architecture's effectivenessstems from its novel combination of multi-modal transformations, inter-sampleattention mechanism, spectrally normalized projections, and calibratedprobabilistic outputs.</description>
      <author>example@mail.com (Santosh Rajagopalan, Jonathan Vronsky, Songbai Yan, S. Alireza Golestaneh, Shubhra Chandra, Min Zhou)</author>
      <guid isPermaLink="false">2504.18785v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Real-Time Event-Based Normal Flow Estimator</title>
      <link>http://arxiv.org/abs/2504.19417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种实时、异步的事件驱动正常流估计器，通过优化实现提升了性能。&lt;h4&gt;背景&lt;/h4&gt;传统方法将事件切片视为3D点云，编码局部几何为固定长度向量，使用多层感知器预测正常流，但计算复杂度较高。&lt;h4&gt;目的&lt;/h4&gt;开发一种更高效的事件相机正常流预测方法。&lt;h4&gt;方法&lt;/h4&gt;该方法利用事件坐标为整数的特性，将表示步骤重构为池化操作，降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法支持实时正常流预测，使用1 GB的CUDA内存，在RTX 3070上每秒处理400万个正常流，在RTX A5000上每秒处理600万个。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种高效的事件相机正常流预测方法，并发布了CUDA实现和Python接口。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种实时、异步的事件驱动正常流估计器。它遵循与《直接从事件邻域学习正常流》相同的算法，但具有更优化的实现。原始方法将事件切片视为3D点云，将每个事件的局部几何编码为固定长度的向量，并使用多层感知器来预测正常流。它通过将邻接矩阵与特征矩阵相乘来构建表示，从而在事件数量上具有二次时间复杂度。相比之下，我们利用事件坐标是整数的事实，将表示步骤重构成池化操作。这实现了与邻接矩阵相同的效果，但具有更低的计算成本。因此，我们的方法支持事件相机的实时正常流预测。我们的估计器使用1 GB的CUDA内存，在RTX 3070上每秒处理4百万个正常流，在RTX A5000上每秒处理600万个。我们在https://github.com/dhyuan99/VecKM_flow_cpp上发布了CUDA实现和Python接口。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time, asynchronous, event-based normal flowestimator. It follows the same algorithm as Learning Normal Flow Directly FromEvent Neighborhoods, but with a more optimized implementation. The originalmethod treats event slices as 3D point clouds, encodes each event's localgeometry into a fixed-length vector, and uses a multi-layer perceptron topredict normal flow. It constructs representations by multiplying an adjacencymatrix with a feature matrix, resulting in quadratic time complexity withrespect to the number of events. In contrast, we leverage the fact that eventcoordinates are integers and reformulate the representation step as a poolingoperation. This achieves the same effect as the adjacency matrix but with muchlower computational cost. As a result, our method supports real-time normalflow prediction on event cameras. Our estimator uses 1 GB of CUDA memory andruns at 4 million normal flows per second on an RTX 3070, or 6 million persecond on an RTX A5000. We release the CUDA implementation along with a Pythoninterface at https://github.com/dhyuan99/VecKM_flow_cpp.</description>
      <author>example@mail.com (Dehao Yuan, Cornelia Fermüller)</author>
      <guid isPermaLink="false">2504.19417v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Segmenting Objectiveness and Task-awareness Unknown Region for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.19183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SOTA的新框架，用于自动驾驶场景中的道路场景分割，该框架通过语义融合块（SFB）增强客观性分割，并通过场景理解引导的提示上下文适配器（SG-PCA）过滤与道路导航任务无关的异常。&lt;h4&gt;背景&lt;/h4&gt;随着基于transformer架构和大型语言模型（LLMs）的出现，道路场景感知的准确性得到了显著提高。然而，现有的道路场景分割方法主要在闭集数据上训练，导致对分布外（OOD）对象的检测能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，本文提出了SOTA框架，旨在提高自动驾驶场景中道路场景分割的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SOTA通过语义融合块（SFB）增强分割的客观性，并通过场景理解引导的提示上下文适配器（SG-PCA）过滤与道路导航任务无关的异常。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的广泛实证评估表明，SOTA在多个检测器上持续提高OOD检测性能，实现了鲁棒和准确的分割结果。&lt;h4&gt;结论&lt;/h4&gt;SOTA框架在自动驾驶场景中的道路场景分割方面具有显著优势，能够有效提高异常检测的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;With the emergence of transformer-based architectures and large language models (LLMs), the accuracy of road scene perception has substantially advanced. Nonetheless, current road scene segmentation approaches are predominantly trained on closed-set data, resulting in insufficient detection capabilities for out-of-distribution (OOD) objects. To overcome this limitation, road anomaly detection methods have been proposed. However, existing methods primarily depend on image inpainting and OOD distribution detection techniques, facing two critical issues: (1) inadequate consideration of the objectiveness attributes of anomalous regions, causing incomplete segmentation when anomalous objects share similarities with known classes, and (2) insufficient attention to environmental constraints, leading to the detection of anomalies irrelevant to autonomous driving tasks. In this paper, we propose a novel framework termed Segmenting Objectiveness and Task-Awareness (SOTA) for autonomous driving scenes. Specifically, SOTA enhances the segmentation of objectiveness through a Semantic Fusion Block (SFB) and filters anomalies irrelevant to road navigation tasks using a Scene-understanding Guided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations on multiple benchmark datasets, including Fishyscapes Lost and Found, Segment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTA consistently improves OOD detection performance across diverse detectors, achieving robust and accurate segmentation outcomes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the emergence of transformer-based architectures and large languagemodels (LLMs), the accuracy of road scene perception has substantiallyadvanced. Nonetheless, current road scene segmentation approaches arepredominantly trained on closed-set data, resulting in insufficient detectioncapabilities for out-of-distribution (OOD) objects. To overcome thislimitation, road anomaly detection methods have been proposed. However,existing methods primarily depend on image inpainting and OOD distributiondetection techniques, facing two critical issues: (1) inadequate considerationof the objectiveness attributes of anomalous regions, causing incompletesegmentation when anomalous objects share similarities with known classes, and(2) insufficient attention to environmental constraints, leading to thedetection of anomalies irrelevant to autonomous driving tasks. In this paper,we propose a novel framework termed Segmenting Objectiveness and Task-Awareness(SOTA) for autonomous driving scenes. Specifically, SOTA enhances thesegmentation of objectiveness through a Semantic Fusion Block (SFB) and filtersanomalies irrelevant to road navigation tasks using a Scene-understandingGuided Prompt-Context Adaptor (SG-PCA). Extensive empirical evaluations onmultiple benchmark datasets, including Fishyscapes Lost and Found,Segment-Me-If-You-Can, and RoadAnomaly, demonstrate that the proposed SOTAconsistently improves OOD detection performance across diverse detectors,achieving robust and accurate segmentation outcomes.</description>
      <author>example@mail.com (Mi Zheng, Guanglei Yang, Zitong Huang, Zhenhua Guo, Kevin Han, Wangmeng Zuo)</author>
      <guid isPermaLink="false">2504.19183v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification</title>
      <link>http://arxiv.org/abs/2504.19682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 3 figures, accepted for presentation at  xAI-World-Conference 2025, code is available at  https://github.com/nickhaidos/Vision-GNNs-Explainer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在视觉任务中的应用，分析了GNN图像分类器在不同层形成的图的语义一致性，并比较了标准与对抗环境下的解释性，通过可视化技术揭示了模型的解释性。&lt;h4&gt;背景&lt;/h4&gt;GNNs作为卷积方法在图像分类等视觉任务中的替代方案，利用图像块表示，通过块相似性或分类相关性建立边。&lt;h4&gt;目的&lt;/h4&gt;分析GNN图像分类器在不同层形成的图的语义一致性，评估其保留物体结构和有意义关系的能力。&lt;h4&gt;方法&lt;/h4&gt;通过量化层间图连接反映语义相似性和空间一致性的程度，比较标准与对抗环境下的解释性，使用基于热图的可视化技术展示信息流动。&lt;h4&gt;主要发现&lt;/h4&gt;模型的决策过程可以有效地解释，但其推理过程不一定与人类感知一致，尤其是在深层。&lt;h4&gt;结论&lt;/h4&gt;GNNs在视觉任务中的应用具有较高的解释性，但其推理过程与人类感知存在差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as an efficient alternative toconvolutional approaches for vision tasks such as image classification,leveraging patch-based representations instead of raw pixels. These methodsconstruct graphs where image patches serve as nodes, and edges are establishedbased on patch similarity or classification relevance. Despite theirefficiency, the explainability of GNN-based vision models remainsunderexplored, even though graphs are naturally interpretable. In this work, weanalyze the semantic consistency of the graphs formed at different layers ofGNN-based image classifiers, focusing on how well they preserve objectstructures and meaningful relationships. A comprehensive analysis is presentedby quantifying the extent to which inter-layer graph connections reflectsemantic similarity and spatial coherence. Explanations from standard andadversarial settings are also compared to assess whether they reflect theclassifiers' robustness. Additionally, we visualize the flow of informationacross layers through heatmap-based visualization techniques, therebyhighlighting the models' explainability. Our findings demonstrate that thedecision-making processes of these models can be effectively explained, whilealso revealing that their reasoning does not necessarily align with humanperception, especially in deeper layers.</description>
      <author>example@mail.com (Nikolaos Chaidos, Angeliki Dimitriou, Nikolaos Spanos, Athanasios Voulodimos, Giorgos Stamou)</author>
      <guid isPermaLink="false">2504.19682v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Co-Training with Active Contrastive Learning and Meta-Pseudo-Labeling on 2D Projections for Deep Semi-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.18666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Journal of the Brazilian Computer Society (JBCS)  [https://journals-sol.sbc.org.br]&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为active-DeepFA的方法，用于在标注数据稀缺、未标注数据丰富的情况下训练深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型的训练面临的一个主要挑战是准确标注数据的有限可用性，特别是在数据标注耗时且易出错的任务中。&lt;h4&gt;目的&lt;/h4&gt;提出active-DeepFA方法，以有效地结合聚类（CL）、基于教师-学生的元伪标签（meta-pseudo-labeling）和主动学习（AL）来训练非预训练的CNN架构，用于图像分类。&lt;h4&gt;方法&lt;/h4&gt;该方法将DeepFA集成到协同训练设置中，实现两个合作网络以减轻伪标签的确认偏差。它通过监督CL预热网络，然后定期进行标签传播和伪标签交换，同时将最有意义的样本标注并添加到标注集中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个具有挑战性的生物图像数据集上进行了评估，仅使用5%的标注样本，提高了基线并优于六种其他SoTA方法。此外，它通过仅使用3%的标注数据就达到了与对手相当的结果，从而减少了标注工作量。&lt;h4&gt;结论&lt;/h4&gt;active-DeepFA方法在标注数据稀缺的情况下，能够有效提高图像分类的准确率，并显著减少标注工作的工作量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenge that prevents the training of DL models is the limitedavailability of accurately labeled data. This shortcoming is highlighted inareas where data annotation becomes a time-consuming and error-prone task. Inthis regard, SSL tackles this challenge by capitalizing on scarce labeled andabundant unlabeled data; however, SoTA methods typically depend on pre-trainedfeatures and large validation sets to learn effective representations forclassification tasks. In addition, the reduced set of labeled data is oftenrandomly sampled, neglecting the selection of more informative samples. Here,we present active-DeepFA, a method that effectively combines CL,teacher-student-based meta-pseudo-labeling and AL to train non-pretrained CNNarchitectures for image classification in scenarios of scarcity of labeled andabundance of unlabeled data. It integrates DeepFA into a co-training setup thatimplements two cooperative networks to mitigate confirmation bias frompseudo-labels. The method starts with a reduced set of labeled samples bywarming up the networks with supervised CL. Afterward and at regular epochintervals, label propagation is performed on the 2D projections of thenetworks' deep features. Next, the most reliable pseudo-labels are exchangedbetween networks in a cross-training fashion, while the most meaningful samplesare annotated and added into the labeled set. The networks independentlyminimize an objective loss function comprising supervised contrastive,supervised and semi-supervised loss components, enhancing the representationstowards image classification. Our approach is evaluated on three challengingbiological image datasets using only 5% of labeled samples, improving baselinesand outperforming six other SoTA methods. In addition, it reduces annotationeffort by achieving comparable results to those of its counterparts with only3% of labeled data.</description>
      <author>example@mail.com (David Aparco-Cardenas, Jancarlo F. Gomes, Alexandre X. Falcão, Pedro J. de Rezende)</author>
      <guid isPermaLink="false">2504.18666v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models</title>
      <link>http://arxiv.org/abs/2504.19649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoGNNs-LLMEA的框架，用于优化HLS设计空间探索过程，通过结合图神经网络、任务自适应消息传递和大型语言模型增强的进化算法，提高预测准确性，减少预测误差。&lt;h4&gt;背景&lt;/h4&gt;HLS设计空间探索是电子设计自动化中的一个优化过程，旨在通过系统性地探索高级设计配置来实现性能、面积和功耗（PPA）平衡的硬件实现。&lt;h4&gt;目的&lt;/h4&gt;优化HLS预测任务，提高预测准确性，减少预测误差，同时减少对领域特定知识的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CoGNNs-LLMEA的框架，该框架集成了图神经网络、任务自适应消息传递和大型语言模型增强的进化算法。CoGNNs直接利用编译器前端处理后的源代码生成的中间表示，预测结果质量（QoR），无需调用HLS工具。&lt;h4&gt;主要发现&lt;/h4&gt;CoGNNs在HLS后的QoR预测中达到了最先进的预测准确性，与基线模型相比，平均预测误差在延迟方面降低了2.8倍，在资源利用率方面降低了3.4倍。&lt;h4&gt;结论&lt;/h4&gt;CoGNNs-LLMEA框架能够有效提高HLS设计空间探索的预测准确性，减少预测误差，并降低对领域特定知识的依赖。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高级综合（HLS）设计空间探索（DSE）是电子设计自动化（EDA）中的一个优化过程，它系统地探索高级设计配置，以实现平衡性能、面积和功耗（PPA）的帕累托最优硬件实现。为了优化此过程，HLS预测任务通常采用消息传递神经网络（MPNN），利用复杂的架构以实现高精度。这些预测器作为DSE过程中的评估者，有效地绕过了传统上由HLS工具要求的耗时估计。然而，现有的模型往往优先考虑结构复杂性和训练损失的优化，而忽略了特定任务的特性。此外，尽管进化算法在DSE中得到广泛应用，但它们通常需要大量的领域特定知识来设计有效的交叉和变异算子。为了解决这些限制，我们提出了一种名为CoGNNs-LLMEA的框架，该框架将图神经网络与任务自适应消息传递和大型语言模型增强的进化算法相结合。作为预测模型，CoGNNs直接利用源代码在编译器前端处理后的中间表示，能够在不调用HLS工具的情况下预测结果质量（QoR）。由于其强大的任务适应性，CoGNNs可以调整以预测HLS后和实现后的结果，有效地弥合了高级抽象和物理实现特性之间的差距。CoGNNs在HLS后的QoR预测中实现了最先进的预测准确性，与基线模型相比，平均预测误差在延迟方面降低了2.8倍，在资源利用率方面降低了3.4倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level synthesis (HLS) design space exploration (DSE) is an optimizationprocess in electronic design automation (EDA) that systematically exploreshigh-level design configurations to achieve Pareto-optimal hardwareimplementations balancing performance, area, and power (PPA). To optimize thisprocess, HLS prediction tasks often employ message-passing neural networks(MPNNs), leveraging complex architectures to achieve high accuracy. Thesepredictors serve as evaluators in the DSE process, effectively bypassing thetime-consuming estimations traditionally required by HLS tools. However,existing models often prioritize structural complexity and minimization oftraining loss, overlooking task-specific characteristics. Additionally, whileevolutionary algorithms are widely used in DSE, they typically requireextensive domain-specific knowledge to design effective crossover and mutationoperators. To address these limitations, we propose CoGNNs-LLMEA, a frameworkthat integrates a graph neural network with task-adaptive message passing and alarge language model-enhanced evolutionary algorithm. As a predictive model,CoGNNs directly leverages intermediate representations generated from sourcecode after compiler front-end processing, enabling prediction of quality ofresults (QoR) without invoking HLS tools. Due to its strong adaptability totasks, CoGNNs can be tuned to predict post-HLS and post-implementationoutcomes, effectively bridging the gap between high-level abstractions andphysical implementation characteristics. CoGNNs achieves state-of-the-artprediction accuracy in post-HLS QoR prediction, reducing mean prediction errorsby 2.8$\times$ for latency and 3.4$\times$ for resource utilization compared tobaseline models.</description>
      <author>example@mail.com (Lei Xu, Shanshan Wang, Emmanuel Casseau, Chenglong Xiao)</author>
      <guid isPermaLink="false">2504.19649v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation</title>
      <link>http://arxiv.org/abs/2504.19174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLR-Wire是一种基于3D曲线的线框生成框架，它将几何和拓扑整合到一个统一的连续潜在表示中。&lt;h4&gt;背景&lt;/h4&gt;传统方法将顶点、边和面解耦，而CLR-Wire将曲线及其拓扑连接编码为神经网络参数曲线，并使用注意力驱动的变分自编码器（VAE）将它们映射到连续且固定长度的潜在空间。&lt;h4&gt;目的&lt;/h4&gt;CLR-Wire旨在提供一种能够同时学习几何和拓扑的统一方法，并生成高质量的线框。&lt;h4&gt;方法&lt;/h4&gt;CLR-Wire使用流匹配模型将高斯噪声映射到潜在空间，然后解码为完整的3D线框。它支持无条件生成和基于点云或图像输入的生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的生成方法相比，CLR-Wire在准确性、新颖性和多样性方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;CLR-Wire为CAD设计、几何重建和3D内容创建提供了一种高效且全面的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为CLR-Wire的新型框架，该框架用于基于3D曲线的线框生成，它将几何和拓扑整合到一个统一的连续潜在表示中。与将顶点、边和面解耦的传统方法不同，CLR-Wire将曲线及其拓扑连接编码为神经网络参数曲线，并使用注意力驱动的变分自编码器（VAE）将它们映射到连续且固定长度的潜在空间。这种统一的方法促进了几何和拓扑的联合学习和生成。为了生成线框，我们使用流匹配模型将高斯噪声逐步映射到这些潜在空间，然后解码为完整的3D线框。我们的方法提供了对复杂形状和不规则拓扑的精细建模，并支持无条件生成和基于点云或图像输入的生成。实验结果表明，与最先进的生成方法相比，我们的方法在准确性、新颖性和多样性方面取得了显著提高，为CAD设计、几何重建和3D内容创作提供了一种高效且全面的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CLR-Wire, a novel framework for 3D curve-based wireframegeneration that integrates geometry and topology into a unified ContinuousLatent Representation. Unlike conventional methods that decouple vertices,edges, and faces, CLR-Wire encodes curves as Neural Parametric Curves alongwith their topological connectivity into a continuous and fixed-length latentspace using an attention-driven variational autoencoder (VAE). This unifiedapproach facilitates joint learning and generation of both geometry andtopology. To generate wireframes, we employ a flow matching model toprogressively map Gaussian noise to these latents, which are subsequentlydecoded into complete 3D wireframes. Our method provides fine-grained modelingof complex shapes and irregular topologies, and supports both unconditionalgeneration and generation conditioned on point cloud or image inputs.Experimental results demonstrate that, compared with state-of-the-artgenerative approaches, our method achieves substantial improvements inaccuracy, novelty, and diversity, offering an efficient and comprehensivesolution for CAD design, geometric reconstruction, and 3D content creation.</description>
      <author>example@mail.com (Xueqi Ma, Yilin Liu, Tianlong Gao, Qirui Huang, Hui Huang)</author>
      <guid isPermaLink="false">2504.19174v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>If Concept Bottlenecks are the Question, are Foundation Models the Answer?</title>
      <link>http://arxiv.org/abs/2504.19774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了概念瓶颈模型（CBMs），这是一种结合高性能和先验可解释性的神经网络。通过将输入映射到高级概念并使用这些概念解决下游任务，CBMs旨在提高可解释性。然而，模型性能和可解释性依赖于学习到的概念质量，而高质量概念的学习往往依赖于昂贵的专家标注。本文通过实验分析了使用弱监督的VLM-CBM架构对学习到的概念质量的影响。&lt;h4&gt;背景&lt;/h4&gt;概念瓶颈模型（CBMs）旨在结合高性能和可解释性，通过将输入映射到高级概念来解决下游任务。&lt;h4&gt;目的&lt;/h4&gt;研究使用弱监督的VLM-CBM架构对学习到的概念质量的影响，并分析其与专家标注的差异。&lt;h4&gt;方法&lt;/h4&gt;通过实验分析VLM-CBMs架构，使用一系列显著指标评估学习到的概念。&lt;h4&gt;主要发现&lt;/h4&gt;VLM监督与专家标注在任务上可能存在显著差异，概念准确性和质量之间没有强相关性。&lt;h4&gt;结论&lt;/h4&gt;VLM监督可以作为一种替代专家标注的方法，但需要根据具体任务调整以保持概念质量。&lt;h4&gt;翻译&lt;/h4&gt;Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high-performance with ante-hoc interpretability. CBMs work by first mapping inputs (e.g., images) to high-level concepts (e.g., visible objects and their properties) and then use these to solve a downstream task (e.g., tagging or scoring an image) in an interpretable manner. Their performance and interpretability, however, hinge on the quality of the concepts they learn. The go-to strategy for ensuring good quality concepts is to leverage expert annotations, which are expensive to collect and seldom available in applications. Researchers have recently addressed this issue by introducing 'VLM-CBM' architectures that replace manual annotations with weak supervision from foundation models. It is however unclear what is the impact of doing so on the quality of the learned concepts. To answer this question, we put state-of-the-art VLM-CBMs to the test, analyzing their learned concepts empirically using a selection of significant metrics. Our results show that, depending on the task, VLM supervision can sensibly differ from expert annotations, and that concept accuracy and quality are not strongly correlated. Our code is available at https://github.com/debryu/CQA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Concept Bottleneck Models (CBMs) are neural networks designed to conjoin highperformance with ante-hoc interpretability. CBMs work by first mapping inputs(e.g., images) to high-level concepts (e.g., visible objects and theirproperties) and then use these to solve a downstream task (e.g., tagging orscoring an image) in an interpretable manner. Their performance andinterpretability, however, hinge on the quality of the concepts they learn. Thego-to strategy for ensuring good quality concepts is to leverage expertannotations, which are expensive to collect and seldom available inapplications. Researchers have recently addressed this issue by introducing"VLM-CBM" architectures that replace manual annotations with weak supervisionfrom foundation models. It is however unclear what is the impact of doing so onthe quality of the learned concepts. To answer this question, we putstate-of-the-art VLM-CBMs to the test, analyzing their learned conceptsempirically using a selection of significant metrics. Our results show that,depending on the task, VLM supervision can sensibly differ from expertannotations, and that concept accuracy and quality are not strongly correlated.Our code is available at https://github.com/debryu/CQA.</description>
      <author>example@mail.com (Nicola Debole, Pietro Barbiero, Francesco Giannini, Andrea Passeggini, Stefano Teso, Emanuele Marconato)</author>
      <guid isPermaLink="false">2504.19774v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>An SE(3) Noise Model for Range-Azimuth-Elevation Sensors</title>
      <link>http://arxiv.org/abs/2504.19009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了点云配准在状态估计中的应用，特别是Scan matching技术。分析了当前方法中协方差表示不准确和忽略传感器与车辆外部不确定性以及里程计不确定性对权重的影响。&lt;h4&gt;背景&lt;/h4&gt;Scan matching是一种在状态估计中广泛使用的技术，其中点云配准是一种加权最小二乘问题，其权重由测量点的逆协方差确定。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过开发一个基于矩阵李群的测距-方位-高度传感器模型来解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;该方法允许无缝地结合外部和里程计不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;文章展示了模拟示例和实际水下激光扫描收集的点云子图的结果，说明了新模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;新模型能够更准确地处理Scan matching中的不确定性，提高估计的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scan matching is a widely used technique in state estimation. Point-cloudalignment, one of the most popular methods for scan matching, is a weightedleast-squares problem in which the weights are determined from the inversecovariance of the measured points. An inaccurate representation of thecovariance will affect the weighting of the least-squares problem. For example,if ellipsoidal covariance bounds are used to approximate the curved,"banana-shaped" noise characteristics of many scanning sensors, the weightingin the least-squares problem may be overconfident. Additionally,sensor-to-vehicle extrinsic uncertainty and odometry uncertainty during submapformation are two sources of uncertainty that are often overlooked in scanmatching applications, also likely contributing to overconfidence on the scanmatching estimate. This paper attempts to address these issues by developing amodel for range-azimuth-elevation sensors on matrix Lie groups. The modelallows for the seamless incorporation of extrinsic and odometry uncertainty.Illustrative results are shown both for a simulated example and for a realpoint-cloud submap collected with an underwater laser scanner.</description>
      <author>example@mail.com (Thomas Hitchcox, James Richard Forbes)</author>
      <guid isPermaLink="false">2504.19009v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Feature Fusion Revisited: Multimodal CTR Prediction for MMCTR Challenge</title>
      <link>http://arxiv.org/abs/2504.18961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A technical report for the MMCTR Challenge held by EReL@MIR Workshop  at WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在Multimodal Large Language Models (MLLMs)快速发展的背景下，研究人员在推荐系统中的应用探索，以及针对提高信息检索任务中多模态表示学习效率的各种方法的实验。&lt;h4&gt;背景&lt;/h4&gt;MLLMs的快速发展促使研究人员探索其在推荐系统中的应用，但大型模型的高延迟给此类应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;EREL@MIR研讨会为提高多模态表示学习效率提供了实验机会，要求参赛者提交技术报告详细说明他们的方法和发现。&lt;h4&gt;方法&lt;/h4&gt;我们的团队在竞赛中获得了Task 2 - Winner (Multimodal CTR Prediction)的奖项，并在报告中详细介绍了我们的方法和关键发现。&lt;h4&gt;主要发现&lt;/h4&gt;提出了如何有效地将推荐信号整合到多模态表示中的几个研究方向。&lt;h4&gt;结论&lt;/h4&gt;公开了我们的实现代码库和训练模型权重。&lt;h4&gt;翻译&lt;/h4&gt;With the rapid advancement of Multimodal Large Language Models (MLLMs), an increasing number of researchers are exploring their application in recommendation systems. However, the high latency associated with large models presents a significant challenge for such use cases. The EReL@MIR workshop provided a valuable opportunity to experiment with various approaches aimed at improving the efficiency of multimodal representation learning for information retrieval tasks. As part of the competition's requirements, participants were mandated to submit a technical report detailing their methodologies and findings. Our team was honored to receive the award for Task 2 - Winner (Multimodal CTR Prediction). In this technical report, we present our methods and key findings. Additionally, we propose several directions for future work, particularly focusing on how to effectively integrate recommendation signals into multimodal representations. The codebase for our implementation is publicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and the trained model weights can be accessed at: https://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of Multimodal Large Language Models (MLLMs), anincreasing number of researchers are exploring their application inrecommendation systems. However, the high latency associated with large modelspresents a significant challenge for such use cases. The EReL@MIR workshopprovided a valuable opportunity to experiment with various approaches aimed atimproving the efficiency of multimodal representation learning for informationretrieval tasks. As part of the competition's requirements, participants weremandated to submit a technical report detailing their methodologies andfindings. Our team was honored to receive the award for Task 2 - Winner(Multimodal CTR Prediction). In this technical report, we present our methodsand key findings. Additionally, we propose several directions for future work,particularly focusing on how to effectively integrate recommendation signalsinto multimodal representations. The codebase for our implementation ispublicly available at: https://github.com/Lattice-zjj/MMCTR_Code, and thetrained model weights can be accessed at:https://huggingface.co/FireFlyCourageous/MMCTR_DIN_MicroLens_1M_x1.</description>
      <author>example@mail.com (Junjie Zhou)</author>
      <guid isPermaLink="false">2504.18961v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>A Universal Spin-Orbit-Coupled Hamiltonian Model for Accelerated Quantum Material Discovery</title>
      <link>http://arxiv.org/abs/2504.19586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages,8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uni-HamGNN的通用自旋轨道耦合（SOC）哈密顿量图神经网络，用于准确模拟复杂系统中的SOC效应，同时解决了传统密度泛函理论（DFT）计算需求高和现有机器学习框架可迁移性有限的问题。&lt;h4&gt;背景&lt;/h4&gt;在模拟复杂系统中的SOC效应时，DFT的计算需求高，且现有机器学习框架的可迁移性有限，导致准确建模成为一大挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入Uni-HamGNN，旨在解决高计算需求和有限的可迁移性问题，实现复杂系统中SOC效应的准确建模。&lt;h4&gt;方法&lt;/h4&gt;该方法将SOC哈密顿量分解为自旋无关项和SOC校正项，以保持SU(2)对称性，并显著降低参数需求。基于这种分解，提出了delta-learning策略来分别拟合两个组成部分，从而解决由它们之间的幅度差异引起的训练困难，并实现高效训练。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在SOC相关组件上实现了显著的准确性（平均绝对误差为0.0025 meV），并通过GNoME数据集的高通量筛选和2D谷电子材料和过渡金属二硫化物（TMD）异质结构的精确预测，展示了其广泛的应用性。&lt;h4&gt;结论&lt;/h4&gt;这一突破消除了对系统特定重新训练和高成本的SOC-DFT计算的需求，为量子材料的快速发现铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;The accurate modeling of spin-orbit coupling (SOC) effects in diverse complex systems remains a significant challenge due to the high computational demands of density functional theory (DFT) and the limited transferability of existing machine-learning frameworks. This study addresses these limitations by introducing Uni-HamGNN, a universal SOC Hamiltonian graph neural network that is applicable across the periodic table. By decomposing the SOC Hamiltonian into spin-independent and SOC correction terms, our approach preserves SU(2) symmetry while significantly reducing parameter requirements. Based on this decomposition, we propose a delta-learning strategy to separately fit the two components, thereby addressing the training difficulties caused by magnitude discrepancies between them and enabling efficient training. The model achieves remarkable accuracy (mean absolute error of 0.0025 meV for the SOC-related component) and demonstrates broad applicability through high-throughput screening of the GNoME dataset for topological insulators, as well as precise predictions for 2D valleytronic materials and transition metal dichalcogenide (TMD) heterostructures. This breakthrough eliminates the need for system-specific retraining and costly SOC-DFT calculations, paving the way for rapid discovery of quantum materials.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate modeling of spin-orbit coupling (SOC) effects in diverse complexsystems remains a significant challenge due to the high computational demandsof density functional theory (DFT) and the limited transferability of existingmachine-learning frameworks. This study addresses these limitations byintroducing Uni-HamGNN, a universal SOC Hamiltonian graph neural network thatis applicable across the periodic table. By decomposing the SOC Hamiltonianinto spin-independent and SOC correction terms, our approach preserves SU(2)symmetry while significantly reducing parameter requirements. Based on thisdecomposition, we propose a delta-learning strategy to separately fit the twocomponents, thereby addressing the training difficulties caused by magnitudediscrepancies between them and enabling efficient training. The model achievesremarkable accuracy (mean absolute error of 0.0025 meV for the SOC-relatedcomponent) and demonstrates broad applicability through high-throughputscreening of the GNoME dataset for topological insulators, as well as precisepredictions for 2D valleytronic materials and transition metal dichalcogenide(TMD) heterostructures. This breakthrough eliminates the need forsystem-specific retraining and costly SOC-DFT calculations, paving the way forrapid discovery of quantum materials.</description>
      <author>example@mail.com (Yang Zhong, Rui Wang, Xingao Gong, Hongjun Xiang)</author>
      <guid isPermaLink="false">2504.19586v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks</title>
      <link>http://arxiv.org/abs/2504.19499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in the proceedings of the 2025 IEEE International  Conference on Communications (ICC), Seventh Workshop on Data Driven  Intelligence for Networks and Systems (DDINS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图强化学习的QoS感知负载均衡方法，用于优化多频段O-RAN中GBR和BE流量的性能，同时满足QoS和资源约束。&lt;h4&gt;背景&lt;/h4&gt;下一代无线蜂窝网络需要提供卓越的服务质量，以支持新兴无线应用，这要求严格的性能保证，如链路层数据速率。&lt;h4&gt;目的&lt;/h4&gt;解决满足QoS要求的关键挑战，即防止小区拥塞，通过平衡负载确保每个小区有足够的无线资源来服务其指定的用户设备。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于图强化学习（GRL），将QoS感知负载均衡建模为马尔可夫决策过程，状态表示为图。QoS考虑因素集成到状态表示和奖励信号设计中。使用基于GNN架构的离策略对抗深度Q网络（DQN）训练负载均衡代理。&lt;h4&gt;主要发现&lt;/h4&gt;与两种基线方法相比，GRL解决方案的性能显著提高，包括QoS违规减少了53%，BE流量的第5百分位数速率提高了四倍。&lt;h4&gt;结论&lt;/h4&gt;该方法确保了负载均衡策略对节点（UE或小区）的顺序不变，能够灵活处理各种网络大小，并在负载均衡决策中考虑空间节点依赖性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-generation wireless cellular networks are expected to provideunparalleled Quality-of-Service (QoS) for emerging wireless applications,necessitating strict performance guarantees, e.g., in terms of link-level datarates. A critical challenge in meeting these QoS requirements is the preventionof cell congestion, which involves balancing the load to ensure sufficientradio resources are available for each cell to serve its designated UserEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approachis developed to optimize the performance of Guaranteed Bit Rate (GBR) and BestEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoSand resource constraints. The proposed solution builds on Graph ReinforcementLearning (GRL), a powerful framework at the intersection of Graph NeuralNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,with states represented as graphs. QoS consideration are integrated into bothstate representations and reward signal design. The LB agent is then trainedusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-basedarchitecture. This design ensures the LB policy is invariant to the ordering ofnodes (UE or cell), flexible in handling various network sizes, and capable ofaccounting for spatial node dependencies in LB decisions. Performance of theGRL-based solution is compared with two baseline methods. Results showsubstantial performance gains, including a $53\%$ reduction in QoS violationsand a fourfold increase in the 5th percentile rate for BE traffic.</description>
      <author>example@mail.com (Omid Semiari, Hosein Nikopour, Shilpa Talwar)</author>
      <guid isPermaLink="false">2504.19499v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation</title>
      <link>http://arxiv.org/abs/2504.19718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 4 figures, to be published in Eurographics 2025 as a short  paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的方法，用于在3D人脸扫描中准确区分皮肤和非皮肤几何形状，以提高人脸注册的质量。&lt;h4&gt;背景&lt;/h4&gt;由于在非皮肤区域（如头发、胡须、配饰）中扫描质量通常下降，现有的人脸注册方法难以处理这些问题。&lt;h4&gt;目的&lt;/h4&gt;提高人脸注册的质量，通过在扫描网格上准确区分皮肤和非皮肤区域。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用冻结的图像基础模型从多视角图像中提取特征，并在3D空间中聚合这些特征。然后，将这些提升的2D特征与从扫描网格中提取的3D几何特征融合，以在扫描网格上直接预测分割掩码。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的分割结果比纯2D或3D分割方法分别提高了8.89%和14.3%的注册准确性。&lt;h4&gt;结论&lt;/h4&gt;尽管仅用合成数据进行训练，但该模型对真实数据具有良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel method for accurately separating skin from non-skin geometry on 3D human head scans to improve the quality of face registration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face registration deforms a template mesh to closely fit a 3D face scan, thequality of which commonly degrades in non-skin regions (e.g., hair, beard,accessories), because the optimized template-to-scan distance pulls thetemplate mesh towards the noisy scan surface. Improving registration qualityrequires a clean separation of skin and non-skin regions on the scan mesh.Existing image-based (2D) or scan-based (3D) segmentation methods howeverperform poorly. Image-based segmentation outputs multi-view inconsistent masks,and they cannot account for scan inaccuracies or scan-image misalignment, whilescan-based methods suffer from lower spatial resolution compared to images. Inthis work, we introduce a novel method that accurately separates skin fromnon-skin geometry on 3D human head scans. For this, our method extractsfeatures from multi-view images using a frozen image foundation model andaggregates these features in 3D. These lifted 2D features are then fused with3D geometric features extracted from the scan mesh, to then predict asegmentation mask directly on the scan mesh. We show that our segmentationsimprove the registration accuracy over pure 2D or 3D segmentation methods by8.89% and 14.3%, respectively. Although trained only on synthetic data, ourmodel generalizes well to real data.</description>
      <author>example@mail.com (Victoria Yue Chen, Daoye Wang, Stephan Garbin, Sebastian Winberg, Timo Bolkart, Thabo Beeler)</author>
      <guid isPermaLink="false">2504.19718v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.17676v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, submitted to IEEE conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的定位方法，该方法结合了基于模型和基于机器学习的方法，通过利用可用的地图信息来发挥各自的优势。&lt;h4&gt;背景&lt;/h4&gt;精确的移动设备定位对于新兴的5G/6G应用（如自动驾驶和增强现实）至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的方法，以提高定位精度，并避免监督学习。&lt;h4&gt;方法&lt;/h4&gt;通过融合几何估计和建筑布局来生成训练标签，避免监督学习；使用基于光线追踪的模拟来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在视线（LoS）用户和非视线（NLoS）用户的位置精度上均有显著提升；与完全监督的指纹识别相比，该方法在整体性能上具有竞争力，同时消除了繁琐的标签数据测量和收集的需求。&lt;h4&gt;结论&lt;/h4&gt;提出的统一方法能够显著提高定位精度，同时避免了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate mobile device localization is critical for emerging 5G/6Gapplications such as autonomous vehicles and augmented reality. In this paper,we propose a unified localization method that integrates model-based andmachine learning (ML)-based methods to reap their respective advantages byexploiting available map information. In order to avoid supervised learning, wegenerate training labels automatically via optimal transport (OT) by fusinggeometric estimates with building layouts. Ray-tracing based simulations arecarried out to demonstrate that the proposed method significantly improvespositioning accuracy for both line-of-sight (LoS) users (compared to ML-basedmethods) and non-line-of-sight (NLoS) users (compared to model-based methods).Remarkably, the unified method is able to achieve competitive overallperformance with the fully-supervised fingerprinting, while eliminating theneed for cumbersome labeled data measurement and collection.</description>
      <author>example@mail.com (Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch)</author>
      <guid isPermaLink="false">2504.17676v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>ReLU integral probability metric and its applications</title>
      <link>http://arxiv.org/abs/2504.18897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种参数化的积分概率度量（IPM）来衡量两个概率测度之间的差异，并在多个任务中展示了其有效性和优越性能。&lt;h4&gt;背景&lt;/h4&gt;在衡量两个概率测度之间的差异时，需要一种有效的度量方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的IPM，用于测量两个概率测度之间的差异，并应用于高维设置。&lt;h4&gt;方法&lt;/h4&gt;使用特定的参数化判别器家族，如具有ReLU激活的单节点神经网络，来区分分布，并通过优化所选判别器的参数来提高估计器的收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的IPM在多个任务中提供了强大的理论保证，并且实证实验表明，其性能与其他方法相当甚至更优。&lt;h4&gt;结论&lt;/h4&gt;该IPM在处理概率测度差异时表现出色，具有高效算法和较少的超参数，适用于高维设置，并在因果推断和公平表示学习等任务中具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种参数化的积分概率度量（IPM）来衡量两个概率测度之间的差异。所提出的IPM利用特定的参数化判别器家族，例如具有ReLU激活的单节点神经网络，以有效地区分分布，使其适用于高维设置。通过优化所选判别器类的参数，所提出的IPM表明其估计器具有良好的收敛速度，可以成为使用平滑非参数判别器类的其他IPM的替代品。我们提出了一种高效的算法用于实际计算，提供了一种简单的实现，并需要较少的超参数。此外，我们探讨了其在各种任务中的应用，如因果推断的协变量平衡和公平表示学习。在如此多样的应用中，我们证明了所提出的IPM提供了强大的理论保证，并且实证实验表明，它实现了与其他方法相当甚至更优的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a parametric integral probability metric (IPM) to measure thediscrepancy between two probability measures. The proposed IPM leverages aspecific parametric family of discriminators, such as single-node neuralnetworks with ReLU activation, to effectively distinguish betweendistributions, making it applicable in high-dimensional settings. By optimizingover the parameters of the chosen discriminator class, the proposed IPMdemonstrates that its estimators have good convergence rates and can serve as asurrogate for other IPMs that use smooth nonparametric discriminator classes.We present an efficient algorithm for practical computation, offering a simpleimplementation and requiring fewer hyperparameters. Furthermore, we explore itsapplications in various tasks, such as covariate balancing for causal inferenceand fair representation learning. Across such diverse applications, wedemonstrate that the proposed IPM provides strong theoretical guarantees, andempirical experiments show that it achieves comparable or even superiorperformance to other methods.</description>
      <author>example@mail.com (Yuha Park, Kunwoong Kim, Insung Kong, Yongdai Kim)</author>
      <guid isPermaLink="false">2504.18897v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>MASR: Self-Reflective Reasoning through Multimodal Hierarchical Attention Focusing for Agent-based Video Understanding</title>
      <link>http://arxiv.org/abs/2504.17213v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于代理的视频理解框架MASR，该框架在视频理解方面取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在快速发展的时代，视频理解仍然是一个极具挑战的任务。&lt;h4&gt;目的&lt;/h4&gt;针对视频信息丰富且冗余的问题，提出MASR框架以提高视频理解的全面性和准确性。&lt;h4&gt;方法&lt;/h4&gt;MASR通过多模态粗到细的相关性感知（MCRS）和膨胀时间扩展（DTE）来检测和优先处理与查询高度相关的视频片段，并在自反推理过程中迭代应用MCRS和DTE，以自适应调整注意力。&lt;h4&gt;主要发现&lt;/h4&gt;MASR在EgoSchema数据集上比之前的方法提高了5%的性能，在Next-QA和IntentQA数据集上分别超过了最先进的标准的0.2%和0.3%，在包含长期视频的Video-MME数据集上，MASR也优于其他基于代理的方法。&lt;h4&gt;结论&lt;/h4&gt;MASR框架在视频理解任务中表现优异，为提高视频理解性能提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even in the era of rapid advances in large models, video understandingremains a highly challenging task. Compared to texts or images, videos commonlycontain more information with redundancy, requiring large models to properlyallocate attention at a global level for comprehensive and accurateunderstanding. To address this, we propose a Multimodal hierarchical Attentionfocusing Self-reflective Reasoning (MASR) framework for agent-based videounderstanding. The key innovation lies in its ability to detect and prioritizesegments of videos that are highly relevant to the query. Firstly, MASRrealizes Multimodal Coarse-to-fine Relevance Sensing (MCRS) which enhances thecorrelation between the acquired contextual information and the query.Secondly, MASR employs Dilated Temporal Expansion (DTE) to mitigate the risk ofmissing crucial details when extracting semantic information from the focusedframes selected through MCRS. By iteratively applying MCRS and DTE in theself-reflective reasoning process, MASR is able to adaptively adjust theattention to extract highly query-relevant context and therefore improve theresponse accuracy. In the EgoSchema dataset, MASR achieves a remarkable 5%performance gain over previous leading approaches. In the Next-QA and IntentQAdatasets, it outperforms the state-of-the-art standards by 0.2% and 0.3%respectively. In the Video-MME dataset that contains long-term videos, MASRalso performs better than other agent-based methods.</description>
      <author>example@mail.com (Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen, Xiangbing Meng)</author>
      <guid isPermaLink="false">2504.17213v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>HeartSimSage: Attention-Enhanced Graph Neural Networks for Accelerating Cardiac Mechanics Modeling</title>
      <link>http://arxiv.org/abs/2504.18968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于注意力增强图神经网络的心脏生物力学有限元分析模拟器HeartSimSage，用于快速预测心脏被动双心室心肌位移。&lt;h4&gt;背景&lt;/h4&gt;有限元分析（FEA）是心脏生物力学建模的基础，但其计算成本高，限制了其在数字孪生创建中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发HeartSimSage以解决现有模拟器的限制，快速预测患者特定几何形状、心室压力和材料属性下的被动双心室心肌位移。&lt;h4&gt;方法&lt;/h4&gt;HeartSimSage能够有效处理不同的三维双心室几何形状、网格拓扑、纤维方向、基于结构的本构模型和生理边界条件。它支持可变节点数、排序和单元连接的灵活网格结构。通过设计受GraphSAGE启发的邻近连接策略，优化信息传播，并采用基于子集的训练提高效率。HeartSimSage集成了注意力机制，自适应地权衡邻居贡献并过滤无关信息，从而提高预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;HeartSimSage在GPU上实现了约13,000倍的加速，在CPU上实现了190倍的加速，同时保持预测双心室位移的平均误差为0.13% ± 0.12%。&lt;h4&gt;结论&lt;/h4&gt;通过使用HeartSimSage，可以在不牺牲精度的情况下显著提高心脏生物力学模拟的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Finite element analysis (FEA) forms the cornerstone of modeling cardiac biomechanics but is computationally expensive, limiting its clinical application for digital twin creation, which often requires tens to hundreds of simulations to estimate tissue parameters. We developed an attention-enhanced graph neural network (GNN)-based FEA emulator, HeartSimSage, to rapidly predict passive biventricular myocardial displacements from patient-specific geometries, chamber pressures, and material properties. HeartSimSage addresses the limitations of current emulators by effectively handling diverse three-dimensional (3D) biventricular geometries, mesh topologies, fiber directions, structurally based constitutive models, and physiological boundary conditions. It supports flexible mesh structures with variable node counts, orderings, and element connectivity. To optimize information propagation, we designed a neighboring connection strategy inspired by Graph Sample and Aggregate (GraphSAGE) that prioritizes local interactions while maintaining mid-to-long-range dependencies. We further incorporated Laplace-Dirichlet solutions for enhanced spatial encoding and employed subset-based training for improved efficiency. By integrating an attention mechanism, HeartSimSage adaptively weighs neighbor contributions and filters irrelevant information, enhancing prediction accuracy. HeartSimSage achieves approximately 13,000x speedup on GPU and 190x on CPU compared to traditional FEA, while maintaining a nominal averaged error of 0.13% ± 0.12% in predicting biventricular displacements. We validated our model using a published left ventricle dataset and conducted sensitivity analyses on hyperparameters, neighboring strategies, and the attention mechanism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finite element analysis (FEA) forms the cornerstone of modeling cardiacbiomechanics but is computationally expensive, limiting its clinicalapplication for digital twin creation, which often requires tens to hundreds ofsimulations to estimate tissue parameters. We developed an attention-enhancedgraph neural network (GNN)-based FEA emulator, HeartSimSage, to rapidly predictpassive biventricular myocardial displacements from patient-specificgeometries, chamber pressures, and material properties. HeartSimSage addressesthe limitations of current emulators by effectively handling diversethree-dimensional (3D) biventricular geometries, mesh topologies, fiberdirections, structurally based constitutive models, and physiological boundaryconditions. It supports flexible mesh structures with variable node counts,orderings, and element connectivity. To optimize information propagation, wedesigned a neighboring connection strategy inspired by Graph Sample andAggregate (GraphSAGE) that prioritizes local interactions while maintainingmid-to-long-range dependencies. We further incorporated Laplace-Dirichletsolutions for enhanced spatial encoding and employed subset-based training forimproved efficiency. By integrating an attention mechanism, HeartSimSageadaptively weighs neighbor contributions and filters irrelevant information,enhancing prediction accuracy. HeartSimSage achieves approximately 13,000xspeedup on GPU and 190x on CPU compared to traditional FEA, while maintaining anominal averaged error of 0.13% +- 0.12% in predicting biventriculardisplacements. We validated our model using a published left ventricle datasetand conducted sensitivity analyses on hyperparameters, neighboring strategies,and the attention mechanism.</description>
      <author>example@mail.com (Lei Shi, Yurui Chen, Vijay Vedula)</author>
      <guid isPermaLink="false">2504.18968v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy</title>
      <link>http://arxiv.org/abs/2504.18829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Robotics: Science and Systems (RSS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种高效的抓取合成方法，能够为任何抓取类型、物体和机械手合成丰富的接触、无穿透和物理上可行的抓取。&lt;h4&gt;背景&lt;/h4&gt;智能机器人需要掌握多样化的抓取技能，但收集涵盖多种抓取类型的海量高质量数据集极具挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够合成适用于任何抓取类型、物体和机械手的抓取的方法。&lt;h4&gt;方法&lt;/h4&gt;从每个手型和抓取类型的一个单一人工标注模板开始，通过两个阶段进行合成：首先优化物体以适应手模板，然后在模拟中对手进行局部细化以适应物体。引入了一种接触感知控制策略来验证合成的抓取，并允许手在接触点对物体施加适当的力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在模拟中显著优于之前的类型无关抓取合成基线。构建了一个包含10.7k个物体和9.5M个抓取的数据集，涵盖了GRASP分类法中的31种抓取类型。在现实世界实验中，通过训练的类型条件生成模型，从单视图物体点云中成功执行所需的抓取类型，成功率达到82.3%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了抓取合成问题，为智能机器人提供了强大的抓取能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：具有广泛适用性的灵活抓取是智能机器人的一项基本技能。开发这种技能需要一个大规模且高质量的数据集，该数据集涵盖了多种抓取类型（即至少那些由GRASP分类法归类的类型），但收集此类数据极为困难。现有的自动抓取合成方法通常局限于特定的抓取类型或物体类别，阻碍了可扩展性。这项工作提出了一种高效的管道，能够为任何抓取类型、物体和机械手合成丰富的接触、无穿透和物理上可行的抓取。从每个手型和抓取类型的一个单一人工标注模板开始，我们的管道通过两个阶段解决复杂的合成问题：首先优化物体以适应手模板，然后在模拟中对手进行局部细化以适应物体。为了验证合成的抓取，我们引入了一种接触感知控制策略，该策略允许手在每个接触点对物体施加适当的力。这些经过验证的抓取也可以用作新的抓取模板，以促进未来的合成。实验表明，我们的方法在模拟中显著优于之前的类型无关抓取合成基线。使用我们的算法，我们构建了一个包含10.7k个物体和9.5M个抓取的数据集，涵盖了GRASP分类法中的31种抓取类型。最后，我们训练了一个类型条件生成模型，该模型成功地从单视图物体点云中执行所需的抓取类型，在现实世界实验中的成功率为82.3%。项目页面：https://pku-epic.github.io/Dexonomy。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable dexterous grasping with suitable grasp types is a fundamentalskill for intelligent robots. Developing such skills requires a large-scale andhigh-quality dataset that covers numerous grasp types (i.e., at least thosecategorized by the GRASP taxonomy), but collecting such data is extremelychallenging. Existing automatic grasp synthesis methods are often limited tospecific grasp types or object categories, hindering scalability. This workproposes an efficient pipeline capable of synthesizing contact-rich,penetration-free, and physically plausible grasps for any grasp type, object,and articulated hand. Starting from a single human-annotated template for eachhand and grasp type, our pipeline tackles the complicated synthesis problemwith two stages: optimize the object to fit the hand template first, and thenlocally refine the hand to fit the object in simulation. To validate thesynthesized grasps, we introduce a contact-aware control strategy that allowsthe hand to apply the appropriate force at each contact point to the object.Those validated grasps can also be used as new grasp templates to facilitatefuture synthesis. Experiments show that our method significantly outperformsprevious type-unaware grasp synthesis baselines in simulation. Using ouralgorithm, we construct a dataset containing 10.7k objects and 9.5M grasps,covering 31 grasp types in the GRASP taxonomy. Finally, we train atype-conditional generative model that successfully performs the desired grasptype from single-view object point clouds, achieving an 82.3% success rate inreal-world experiments. Project page: https://pku-epic.github.io/Dexonomy.</description>
      <author>example@mail.com (Jiayi Chen, Yubin Ke, Lin Peng, He Wang)</author>
      <guid isPermaLink="false">2504.18829v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Multimodal Physiological Foundation Models: Handling Arbitrary Missing Modalities</title>
      <link>http://arxiv.org/abs/2504.19596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysioOmni是一种用于多模态生理信号分析的基础模型，旨在解决现有方法在处理不同数据集和缺失模态时的局限性。&lt;h4&gt;背景&lt;/h4&gt;多模态生理信号（如脑电图、心电图、眼电图和肌电图）在医疗和脑机接口领域至关重要，但现有方法依赖于特定架构和针对数据集的融合策略，难以学习通用的表示形式。&lt;h4&gt;目的&lt;/h4&gt;提出PhysioOmni模型，以实现跨数据集的泛化能力并处理推理时的缺失模态。&lt;h4&gt;方法&lt;/h4&gt;PhysioOmni训练了一个解耦的多模态分词器，通过模态不变和模态特定的目标进行掩码信号预训练。此外，通过原型对齐在下游数据集上进行鲁棒的微调，以确保对不同和缺失模态组合的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;在情绪识别、睡眠阶段分类、运动预测和心理负荷检测等四个下游任务上，PhysioOmni实现了最先进的性能，同时保持了对抗缺失模态的强大鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;PhysioOmni模型有效解决了多模态生理信号分析中的挑战，并将在未来发布代码和模型权重。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucialfor healthcare and brain-computer interfaces. While existing methods rely onspecialized architectures and dataset-specific fusion strategies, they struggleto learn universal representations that generalize across datasets and handlemissing modalities at inference time. To address these issues, we proposePhysioOmni, a foundation model for multimodal physiological signal analysisthat models both homogeneous and heterogeneous features to decouple multimodalsignals and extract generic representations while maintaining compatibilitywith arbitrary missing modalities. PhysioOmni trains a decoupled multimodaltokenizer, enabling masked signal pre-training via modality-invariant andmodality-specific objectives. To ensure adaptability to diverse and incompletemodality combinations, the pre-trained encoders undergo resilient fine-tuningwith prototype alignment on downstream datasets. Extensive experiments on fourdownstream tasks, emotion recognition, sleep stage classification, motorprediction, and mental workload detection, demonstrate that PhysioOmni achievesstate-of-the-art performance while maintaining strong robustness to missingmodalities. Our code and model weights will be released.</description>
      <author>example@mail.com (Xi Fu, Wei-Bang Jiang, Yi Ding, Cuntai Guan)</author>
      <guid isPermaLink="false">2504.19596v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>TSRM: A Lightweight Temporal Feature Encoding Architecture for Time Series Forecasting and Imputation</title>
      <link>http://arxiv.org/abs/2504.18878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为时间序列表示模型（TSRM）的时序特征编码架构，用于多变量时间序列的预测和插补。&lt;h4&gt;背景&lt;/h4&gt;在多变量时间序列预测和插补领域，现有方法存在复杂度高的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够高效学习时间序列模式并进行预测和插补的架构。&lt;h4&gt;方法&lt;/h4&gt;架构基于CNN的表示层，每个层负责独立的学习任务，以捕获多样化的时间模式。之后通过注意力机制提取特征，并使用合并层聚合提取的特征。架构灵感来源于Transformer编码器，核心机制为自注意力。&lt;h4&gt;主要发现&lt;/h4&gt;TSRM在大多数七个已建立的基准数据集上优于现有方法，同时显著减少了可学习参数的数量。&lt;h4&gt;结论&lt;/h4&gt;TSRM是一种高效且性能优越的时间序列预测和插补模型。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a temporal feature encoding architecture called Time SeriesRepresentation Model (TSRM) for multivariate time series forecasting andimputation. The architecture is structured around CNN-based representationlayers, each dedicated to an independent representation learning task anddesigned to capture diverse temporal patterns, followed by an attention-basedfeature extraction layer and a merge layer, designed to aggregate extractedfeatures. The architecture is fundamentally based on a configuration that isinspired by a Transformer encoder, with self-attention mechanisms at its core.The TSRM architecture outperforms state-of-the-art approaches on most of theseven established benchmark datasets considered in our empirical evaluation forboth forecasting and imputation tasks. At the same time, it significantlyreduces complexity in the form of learnable parameters. The source code isavailable at https://github.com/RobertLeppich/TSRM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a temporal feature encoding architecture called Time SeriesRepresentation Model (TSRM) for multivariate time series forecasting andimputation. The architecture is structured around CNN-based representationlayers, each dedicated to an independent representation learning task anddesigned to capture diverse temporal patterns, followed by an attention-basedfeature extraction layer and a merge layer, designed to aggregate extractedfeatures. The architecture is fundamentally based on a configuration that isinspired by a Transformer encoder, with self-attention mechanisms at its core.The TSRM architecture outperforms state-of-the-art approaches on most of theseven established benchmark datasets considered in our empirical evaluation forboth forecasting and imputation tasks. At the same time, it significantlyreduces complexity in the form of learnable parameters. The source code isavailable at https://github.com/RobertLeppich/TSRM.</description>
      <author>example@mail.com (Robert Leppich, Michael Stenger, Daniel Grillmeyer, Vanessa Borst, Samuel Kounev)</author>
      <guid isPermaLink="false">2504.18878v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Kinship Verification through a Forest Neural Network</title>
      <link>http://arxiv.org/abs/2504.18910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的概念的新方法，用于人脸表征在血缘关系验证中的应用，该方法在准确性上与从头开始学习的父母和子女人脸图像的联合表征算法相当。&lt;h4&gt;背景&lt;/h4&gt;早期方法在血缘关系验证中使用人脸表征，但这些表征的准确性不如从头开始学习的父母和子女人脸图像的联合表征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改善血缘关系验证中人脸表征的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种结合图神经网络概念的算法，并设计了分类模块的结构，引入了一种新的损失组合，以在训练网络时逐渐引入中心损失。&lt;h4&gt;主要发现&lt;/h4&gt;在KinFaceW-I和II数据集上进行了实验，证明了该方法的有效性，并在KinFaceW-II上取得了最佳结果，对所有血缘类型平均提高了近1.6，在KinFaceW-I上接近最佳。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在血缘关系验证中取得了显著的性能提升，并提供了可用的代码实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early methods used face representations in kinship verification, which areless accurate than joint representations of parents' and children's facialimages learned from scratch. We propose an approach featuring graph neuralnetwork concepts to utilize face representations and have comparable results tojoint representation algorithms. Moreover, we designed the structure of theclassification module and introduced a new combination of losses to engage thecenter loss gradually in training our network. Additionally, we conductedexperiments on KinFaceW-I and II, demonstrating the effectiveness of ourapproach. We achieved the best result on KinFaceW-II, an average improvement ofnearly 1.6 for all kinship types, and we were near the best on KinFaceW-I. Thecode is available at https://github.com/ali-nazari/Kinship-Verification</description>
      <author>example@mail.com (Ali Nazari, Mohsen Ebrahimi Moghaddam, Omidreza Borzoei)</author>
      <guid isPermaLink="false">2504.18910v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance</title>
      <link>http://arxiv.org/abs/2504.18866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Pattern Analysis and Machine  Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiercingEye的新颖的弱监督视频暴力检测（VVD）方法，该方法结合了欧几里得和双曲几何，以增强特征表示的判别性。&lt;h4&gt;背景&lt;/h4&gt;现有的弱监督视频暴力检测方法主要依赖于欧几里得表示学习，但往往难以区分视觉相似但语义不同的事件，这是由于有限的层次建模和不足的模糊训练样本。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的双空间学习框架。&lt;h4&gt;方法&lt;/h4&gt;PiercingEye引入了一种层敏感的双曲聚合策略，并使用双曲Dirichlet能量约束来逐步建模事件层次，同时引入了一种跨空间注意力机制，以促进欧几里得和双曲空间之间的互补特征交互。此外，为了缓解模糊样本的稀缺性，利用大型语言模型生成逻辑引导的模糊事件描述，并通过双曲视觉-语言对比损失实现显式监督，该损失通过动态相似度感知加权优先考虑高混淆样本。&lt;h4&gt;主要发现&lt;/h4&gt;在XD-Violence和UCF-Crime数据集上的大量实验表明，PiercingEye达到了最先进的性能，尤其是在新创建的模糊事件子集上，验证了其在细粒度暴力检测中的优越能力。&lt;h4&gt;结论&lt;/h4&gt;PiercingEye在视频暴力检测领域取得了显著的成果，为未来的研究提供了新的方向和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现有的弱监督视频暴力检测方法主要依赖于欧几里得表示学习，这往往由于有限的层次建模和不足的模糊训练样本，难以区分视觉相似但语义不同的事件。为了解决这一挑战，我们提出了PiercingEye，一种新的双空间学习框架，它结合了欧几里得和双曲几何来增强判别性特征表示。具体来说，PiercingEye引入了一种层敏感的双曲聚合策略，并使用双曲Dirichlet能量约束来逐步建模事件层次，同时引入了一种跨空间注意力机制，以促进欧几里得和双曲空间之间的互补特征交互。此外，为了缓解模糊样本的稀缺性，我们利用大型语言模型生成逻辑引导的模糊事件描述，通过双曲视觉-语言对比损失实现显式监督，该损失通过动态相似度感知加权优先考虑高混淆样本。在XD-Violence和UCF-Crime数据集上的大量实验表明，PiercingEye达到了最先进的性能，尤其是在新创建的模糊事件子集上，验证了其在细粒度暴力检测中的优越能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing weakly supervised video violence detection (VVD) methods primarilyrely on Euclidean representation learning, which often struggles to distinguishvisually similar yet semantically distinct events due to limited hierarchicalmodeling and insufficient ambiguous training samples. To address thischallenge, we propose PiercingEye, a novel dual-space learning framework thatsynergizes Euclidean and hyperbolic geometries to enhance discriminativefeature representation. Specifically, PiercingEye introduces a layer-sensitivehyperbolic aggregation strategy with hyperbolic Dirichlet energy constraints toprogressively model event hierarchies, and a cross-space attention mechanism tofacilitate complementary feature interactions between Euclidean and hyperbolicspaces. Furthermore, to mitigate the scarcity of ambiguous samples, we leveragelarge language models to generate logic-guided ambiguous event descriptions,enabling explicit supervision through a hyperbolic vision-language contrastiveloss that prioritizes high-confusion samples via dynamic similarity-awareweighting. Extensive experiments on XD-Violence and UCF-Crime benchmarksdemonstrate that PiercingEye achieves state-of-the-art performance, withparticularly strong results on a newly curated ambiguous event subset,validating its superior capability in fine-grained violence detection.</description>
      <author>example@mail.com (Jiaxu Leng, Zhanjie Wu, Mingpi Tan, Mengjingcheng Mo, Jiankang Zheng, Qingqing Li, Ji Gan, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.18866v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal graph representation learning for website generation based on visual sketch</title>
      <link>http://arxiv.org/abs/2504.18729v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用多模态图表示学习的新方法，用于将数字设计转换为功能性源代码，以解决设计到代码转换中的复杂性和耗时问题。&lt;h4&gt;背景&lt;/h4&gt;设计到代码转换是一个在软件开发中具有挑战性的问题，传统方法在准确解析网页设计的复杂视觉细节和结构关系方面存在困难，导致自动化和效率受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过整合设计草图中的视觉和结构信息，提高代码生成的准确性和效率，特别是生成语义正确和结构良好的HTML代码。&lt;h4&gt;方法&lt;/h4&gt;采用多模态图表示学习，结合视觉和结构信息，以增强代码生成的准确性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;对方法进行了全面评估，与现有技术相比，在准确性和效率方面均有显著提升，多模态图学习在现有技术中表现出显著的优势，突显了该方法在自动化设计到代码转换中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法有望革新设计到代码的自动化过程，相关代码可在https://github.com/HySonLab/Design2Code获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Design2Code problem, which involves converting digital designs intofunctional source code, is a significant challenge in software development dueto its complexity and time-consuming nature. Traditional approaches oftenstruggle with accurately interpreting the intricate visual details andstructural relationships inherent in webpage designs, leading to limitations inautomation and efficiency. In this paper, we propose a novel method thatleverages multimodal graph representation learning to address these challenges.By integrating both visual and structural information from design sketches, ourapproach enhances the accuracy and efficiency of code generation, particularlyin producing semantically correct and structurally sound HTML code. We presenta comprehensive evaluation of our method, demonstrating significantimprovements in both accuracy and efficiency compared to existing techniques.Extensive evaluation demonstrates significant improvements of multimodal graphlearning over existing techniques, highlighting the potential of our method torevolutionize design-to-code automation. Code available athttps://github.com/HySonLab/Design2Code</description>
      <author>example@mail.com (Tung D. Vu, Chung Hoang, Truong-Son Hy)</author>
      <guid isPermaLink="false">2504.18729v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Towards Faster and More Compact Foundation Models for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2504.19538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过减少模型尺寸来提高分子性质预测中机器学习模型的效率，同时保持性能。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在分子性质预测方面的准确性有所提高，但代价是更高的计算成本和更长的训练时间。&lt;h4&gt;目的&lt;/h4&gt;提高JMP模型在分子数据集上的微调效率，同时保持或提高性能。&lt;h4&gt;方法&lt;/h4&gt;分析了JMP模型的层贡献，通过剪枝预训练模型来探索模型压缩策略，并评估其对微调期间效率和准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;移除两个交互块可以最小化性能下降，将模型尺寸减少32%，同时将推理吞吐量提高1.3倍。&lt;h4&gt;结论&lt;/h4&gt;JMP-L模型存在过度参数化问题，一个更小、更高效的变体可以实现可比的性能，同时降低计算成本。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在分子性质预测的机器学习方面，尽管准确率有所提高，但代价是更高的计算成本和更长的训练时间。最近，联合多域预训练（JMP）基础模型在各种下游任务中表现出强大的性能，且训练时间低于之前的模型。尽管JMP具有优势，但将其在从小规模到大规模的分子数据集上进行微调需要相当多的时间和计算资源。在这项工作中，我们研究了通过减少模型尺寸来提高效率的策略，同时保持性能。为了更好地理解模型的效率，我们分析了JMP的层贡献，发现后续交互块提供的回报逐渐减少，这表明存在模型压缩的机会。我们通过剪枝预训练模型来探索块减少策略，并在微调期间评估其对效率和准确性的影响。我们的分析表明，移除两个交互块会导致最小的性能下降，将模型尺寸减少32%，同时将推理吞吐量提高1.3倍。这些结果表明，JMP-L模型过度参数化，一个更小、更高效的变体可以以更低的计算成本实现可比的性能。我们的研究为开发更轻量级、更快、更可扩展的基础模型提供了见解，用于分子和材料发现。代码可在以下链接公开获取：https://github.com/Yasir-Ghunaim/efficient-jmp。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in machine learning for molecular property prediction haveimproved accuracy but at the expense of higher computational cost and longertraining times. Recently, the Joint Multi-domain Pre-training (JMP) foundationmodel has demonstrated strong performance across various downstream tasks withreduced training time over previous models. Despite JMP's advantages,fine-tuning it on molecular datasets ranging from small-scale to large-scalerequires considerable time and computational resources. In this work, weinvestigate strategies to enhance efficiency by reducing model size whilepreserving performance. To better understand the model's efficiency, we analyzethe layer contributions of JMP and find that later interaction blocks providediminishing returns, suggesting an opportunity for model compression. Weexplore block reduction strategies by pruning the pre-trained model andevaluating its impact on efficiency and accuracy during fine-tuning. Ouranalysis reveals that removing two interaction blocks results in a minimalperformance drop, reducing the model size by 32% while increasing inferencethroughput by 1.3x. These results suggest that JMP-L is over-parameterized andthat a smaller, more efficient variant can achieve comparable performance withlower computational cost. Our study provides insights for developing lighter,faster, and more scalable foundation models for molecular and materialsdiscovery. The code is publicly available at:https://github.com/Yasir-Ghunaim/efficient-jmp.</description>
      <author>example@mail.com (Yasir Ghunaim, Andrés Villa, Gergo Ignacz, Gyorgy Szekely, Motasem Alfarra, Bernard Ghanem)</author>
      <guid isPermaLink="false">2504.19538v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Geometry aware inference of steady state PDEs using Equivariant Neural Fields representations</title>
      <link>http://arxiv.org/abs/2504.18591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于神经场的 enf2enf 方法，用于预测具有非参数化几何变异性稳态偏微分方程的解。&lt;h4&gt;背景&lt;/h4&gt;神经场在处理偏微分方程解的近似学习方面取得了进展，能够处理一般几何形状。&lt;h4&gt;目的&lt;/h4&gt;提出 enf2enf 方法，以预测具有非参数化几何变异性稳态偏微分方程的解。&lt;h4&gt;方法&lt;/h4&gt;enf2enf 方法通过将输入几何编码为潜在点云嵌入，保留几何基础并捕捉局部现象，然后将这些表示与全局参数结合，直接解码为连续输出场，从而有效地模拟几何与物理之间的耦合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法利用局部性和平移不变性的归纳偏置，能够捕捉精细的物理特征和复杂的形状变化，从而提高泛化能力和物理合规性。&lt;h4&gt;结论&lt;/h4&gt;在高质量空气动力学数据集、超弹性材料基准和多元素翼型几何形状上的实验表明，所提出的模型与最先进的基于图、操作学习和神经场的方法相比，实现了优越或具有竞争力的性能。该方法支持实时推理和零样本超分辨率，能够在低分辨率网格上高效训练，同时在全尺度离散化上保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在神经场方面的进展使得学习神经算子，该算子可以近似求解一般几何形状上的偏微分方程（PDEs）的解，成为了一种强大的、离散化不变的方法。基于这些进展，我们介绍了 enf2enf，这是一种编码器-解码器方法，用于预测具有非参数化几何变异性稳态偏微分方程。在 enf2enf 中，输入几何被编码为保留几何基础并捕捉局部现象的潜在点云嵌入。然后，这些表示与全局参数结合，直接解码为连续输出场，从而有效地模拟几何与物理之间的耦合。通过利用局部性和平移不变性的归纳偏置，我们的方法能够捕捉精细的物理特征以及复杂的形状变化，从而增强泛化能力和物理合规性。在高质量空气动力学数据集、超弹性材料基准和多元素翼型几何形状上的广泛实验表明，与最先进的基于图、操作学习和神经场的方法相比，所提出的模型实现了优越或具有竞争力的性能。值得注意的是，我们的方法支持实时推理和零样本超分辨率，能够在低分辨率网格上高效训练，同时在全尺度离散化上保持高精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Neural Fields have enabled powerful,discretization-invariant methods for learning neural operators that approximatesolutions of Partial Differential Equations (PDEs) on general geometries.Building on these developments, we introduce enf2enf, an encoder--decodermethodology for predicting steady-state Partial Differential Equations withnon-parameterized geometric variability, based on recently proposed EquivariantNeural Field architectures. In enf2enf, input geometries are encoded intolatent point cloud embeddings that inherently preserve geometric grounding andcapture local phenomena. The resulting representations are then combined withglobal parameters and directly decoded into continuous output fields, thusefficiently modeling the coupling between geometry and physics. By leveragingthe inductive biases of locality and translation invariance, our approach isable to capture fine-scale physical features as well as complex shapevariations, thereby enhancing generalization and physical compliance. Extensiveexperiments on a high-fidelity aerodynamic dataset, a hyper-elastic materialbenchmark, and multi-element airfoil geometries, demonstrate that the proposedmodel achieves superior or competitive performance compared to state-of-the-artgraph based, operator learning, and neural field methods. Notably, our methodsupports real time inference and zero-shot super-resolution, enabling efficienttraining on low-resolution meshes while maintaining high accuracy on full-scalediscretizations.</description>
      <author>example@mail.com (Giovanni Catalani, Michael Bauerheim, Frédéric Tost, Xavier Bertrand, Joseph Morlier)</author>
      <guid isPermaLink="false">2504.18591v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>High-order Graph Neural Networks with Common Neighbor Awareness for Link Prediction</title>
      <link>http://arxiv.org/abs/2504.18758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted By ICAIS&amp;ISAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于高阶图神经网络（HGNN-CNA）的动态图学习中的链接预测方法，通过考虑多跳共同邻居来捕捉节点间的复杂交互，并直接在动态图学习（DGL）中融合这种交互，从而显著提高了链接预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;链接预测是动态图学习中的一个基本任务，动态图神经网络的进步主要通过对节点间关系进行消息传递来建模，但它们依赖于成对节点交互，忽略了DGL中的共同邻居交互。&lt;h4&gt;目的&lt;/h4&gt;提出HGNN-CNA以解决DGL中共同邻居交互被忽略的问题，从而提高链接预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;HGNN-CNA通过以下两种方法实现：a) 通过考虑多跳共同邻居来估计相关性分数，以捕捉节点间的复杂交互；b) 将这种相关性融合到消息传递过程中，直接在DGL中考虑共同邻居交互。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实动态图上的实验结果表明，与几个最先进的模型相比，所提出的HGNN-CNA在链接预测任务上取得了显著的准确性提升。&lt;h4&gt;结论&lt;/h4&gt;HGNN-CNA通过直接考虑DGL中的共同邻居交互，显著提高了链接预测的准确性，为动态图学习中的链接预测提供了一种新的有效方法。&lt;h4&gt;翻译&lt;/h4&gt;链接预测是动态图学习中的基础任务，它被动态图（DG）的拓扑结构所塑造。动态图神经网络（DGNN）的最近进展，主要通过消息传递方案建模节点之间的关系，已经显著提高了链接预测的性能。然而，DGNNs高度依赖于成对节点交互，这忽略了DGL中的共同邻居交互。为了解决这一局限性，我们提出了一种具有共同邻居感知能力的高阶图神经网络（HGNN-CNA）用于链接预测，具有两个方面的想法：a）通过考虑多跳共同邻居来估计相关性分数，以捕捉节点之间的复杂交互；b）将相关性融合到消息传递过程中，直接在DGL中考虑共同邻居交互。在三个真实动态图上的实验结果表明，所提出的HGNN-CNA在链接预测任务上相对于几个最先进的模型取得了显著的准确性提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a fundamental task in dynamic graph learning (DGL),inherently shaped by the topology of the DG. Recent advancements in dynamicgraph neural networks (DGNN), primarily by modeling the relationships amongnodes via a message passing scheme, have significantly improved link predictionperformance. However, DGNNs heavily rely on the pairwise node interactions,which neglect the common neighbor interaction in DGL. To address thislimitation, we propose a High-order Graph Neural Networks with Common NeighborAwareness (HGNN-CNA) for link prediction with two-fold ideas: a) estimatingcorrelation score by considering multi-hop common neighbors for capturing thecomplex interaction between nodes; b) fusing the correlation into themessage-passing process to consider common neighbor interaction directly inDGL. Experimental results on three real DGs demonstrate that the proposedHGNN-CNA acquires a significant accuracy gain over several state-of-the-artmodels on the link prediction task.</description>
      <author>example@mail.com (Ling Wang, Minglian Han)</author>
      <guid isPermaLink="false">2504.18758v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>LLMs for Engineering: Teaching Models to Design High Powered Rockets</title>
      <link>http://arxiv.org/abs/2504.19394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了大型语言模型（LLMs）在火箭设计中的应用能力，发现RL训练的LLMs在复杂工程优化中具有潜力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）已经改变了软件工程，但其在物理工程领域的应用仍不充分。&lt;h4&gt;目的&lt;/h4&gt;评估LLMs在火箭设计中的能力。&lt;h4&gt;方法&lt;/h4&gt;通过RocketBench基准测试连接LLMs与高保真火箭模拟，测试模型在两个设计任务上的表现：目标高度优化和精度着陆挑战。&lt;h4&gt;主要发现&lt;/h4&gt;最先进的LLMs显示出强大的工程基础知识，但在给定模拟结果后难以迭代设计，最终性能低于人类水平。然而，通过强化学习（RL）增强后，一个7B参数的模型优于最先进的基础模型和人类专家。&lt;h4&gt;结论&lt;/h4&gt;RL训练的LLMs可以成为复杂工程优化的有效工具，有可能改变软件以外的工程领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have transformed software engineering, but theirapplication to physical engineering domains remains underexplored. This paperevaluates LLMs' capabilities in high-powered rocketry design throughRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.We test models on two increasingly complex design tasks: target altitudeoptimization and precision landing challenges. Our findings reveal that whilestate-of-the-art LLMs demonstrate strong baseline engineering knowledge, theystruggle to iterate on their designs when given simulation results andultimately plateau below human performance levels. However, when enhanced withreinforcement learning (RL), we show that a 7B parameter model outperforms bothSoTA foundation models and human experts. This research demonstrates thatRL-trained LLMs can serve as effective tools for complex engineeringoptimization, potentially transforming engineering domains beyond softwaredevelopment.</description>
      <author>example@mail.com (Toby Simonds)</author>
      <guid isPermaLink="false">2504.19394v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Explainable Deep-Learning Based Potentially Hazardous Asteroids Classification Using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的近地小行星（PHA）分类方法，用于行星防御和深空导航。&lt;h4&gt;背景&lt;/h4&gt;传统方法在近地小行星分类中往往忽略了小行星之间的动态关系。&lt;h4&gt;目的&lt;/h4&gt;通过模型识别具有潜在危害的小行星。&lt;h4&gt;方法&lt;/h4&gt;将小行星作为节点，利用轨道和物理特征建模，节点之间通过表示相似性的边连接。使用NASA的958,524条记录的数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在数据集极度不平衡（仅0.22%为危险标签）的情况下，实现了99%的总体准确率和0.99的AUC。应用合成少数类过采样技术后，对于危险小行星的召回率为78%，F1分数为37%。特征重要性分析显示反照率、近日点和半长轴为主要预测因子。&lt;h4&gt;结论&lt;/h4&gt;该框架支持行星防御任务，并证实了人工智能在实现未来任务如NASA的近地天体调查员和ESA的拉姆塞斯自主导航方面的潜力，为小行星危害评估提供了一种可解释和可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Classifying potentially hazardous asteroids (PHAs) is crucial for planetary defense and deep space navigation, yet traditional methods often overlook the dynamical relationships among asteroids. We introduce a Graph Neural Network (GNN) approach that models asteroids as nodes with orbital and physical features, connected by edges representing their similarities, using a NASA dataset of 958,524 records. Despite an extreme class imbalance with only 0.22% of the dataset with the hazardous label, our model achieves an overall accuracy of 99% and an AUC of 0.99, with a recall of 78% and an F1-score of 37% for hazardous asteroids after applying the Synthetic Minority Oversampling Technique. Feature importance analysis highlights albedo, perihelion distance, and semi-major axis as main predictors. This framework supports planetary defense missions and confirms AI's potential in enabling autonomous navigation for future missions such as NASA's NEO Surveyor and ESA's Ramses, offering an interpretable and scalable solution for asteroid hazard assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classifying potentially hazardous asteroids (PHAs) is crucial for planetarydefense and deep space navigation, yet traditional methods often overlook thedynamical relationships among asteroids. We introduce a Graph Neural Network(GNN) approach that models asteroids as nodes with orbital and physicalfeatures, connected by edges representing their similarities, using a NASAdataset of 958,524 records. Despite an extreme class imbalance with only 0.22%of the dataset with the hazardous label, our model achieves an overall accuracyof 99% and an AUC of 0.99, with a recall of 78% and an F1-score of 37% forhazardous asteroids after applying the Synthetic Minority OversamplingTechnique. Feature importance analysis highlights albedo, perihelion distance,and semi-major axis as main predictors. This framework supports planetarydefense missions and confirms AI's potential in enabling autonomous navigationfor future missions such as NASA's NEO Surveyor and ESA's Ramses, offering aninterpretable and scalable solution for asteroid hazard assessment.</description>
      <author>example@mail.com (Baimam Boukar Jean Jacques)</author>
      <guid isPermaLink="false">2504.18605v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Anyprefer: An Agentic Framework for Preference Data Synthesis</title>
      <link>http://arxiv.org/abs/2504.19276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Anyprefer的框架，旨在合成高质量偏好数据以对齐目标模型，并通过实验证明其能显著提升模型在不同应用中的对齐性能。&lt;h4&gt;背景&lt;/h4&gt;高质量偏好数据对于通过偏好学习使基础模型与人类价值观保持一致至关重要，但手动标注此类数据耗时且成本高。&lt;h4&gt;目的&lt;/h4&gt;提出Anyprefer框架，以合成高质量偏好数据，解决手动标注数据耗时且成本高的问题，并减少由于奖励模型与目标模型共享权重而导致的偏差。&lt;h4&gt;方法&lt;/h4&gt;Anyprefer将数据合成过程视为一个合作的双玩家马尔可夫博弈，其中目标模型和裁判模型协作。引入一系列外部工具协助裁判模型准确奖励目标模型的响应，并引入反馈机制优化模型的提示，以增强合作并提高数据质量。&lt;h4&gt;主要发现&lt;/h4&gt;Anyprefer-V1数据集包含58K高质量偏好对，实验表明Anyprefer在四个主要应用中显著提升了模型的对齐性能，平均提升18.55%在五个自然语言生成数据集，3.66%在九个视觉-语言理解数据集，30.05%在三个医学图像分析数据集，以及16.00%在四个视觉-运动控制任务中。&lt;h4&gt;结论&lt;/h4&gt;Anyprefer框架能够有效合成高质量偏好数据，并显著提升模型在不同应用中的对齐性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality preference data is essential for aligning foundation models withhuman values through preference learning. However, manual annotation of suchdata is often time-consuming and costly. Recent methods often adopt aself-rewarding approach, where the target model generates and annotates its ownpreference data, but this can lead to inaccuracies since the reward modelshares weights with the target model, thereby amplifying inherent biases. Toaddress these issues, we propose Anyprefer, a framework designed to synthesizehigh-quality preference data for aligning the target model. Anyprefer framesthe data synthesis process as a cooperative two-player Markov Game, where thetarget model and the judge model collaborate together. Here, a series ofexternal tools are introduced to assist the judge model in accurately rewardingthe target model's responses, mitigating biases in the rewarding process. Inaddition, a feedback mechanism is introduced to optimize prompts for bothmodels, enhancing collaboration and improving data quality. The synthesizeddata is compiled into a new preference dataset, Anyprefer-V1, consisting of 58Khigh-quality preference pairs. Extensive experiments show that Anyprefersignificantly improves model alignment performance across four mainapplications, covering 21 datasets, achieving average improvements of 18.55% infive natural language generation datasets, 3.66% in nine vision-languageunderstanding datasets, 30.05% in three medical image analysis datasets, and16.00% in four visuo-motor control tasks.</description>
      <author>example@mail.com (Yiyang Zhou, Zhaoyang Wang, Tianle Wang, Shangyu Xing, Peng Xia, Bo Li, Kaiyuan Zheng, Zijian Zhang, Zhaorun Chen, Wenhao Zheng, Xuchao Zhang, Chetan Bansal, Weitong Zhang, Ying Wei, Mohit Bansal, Huaxiu Yao)</author>
      <guid isPermaLink="false">2504.19276v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2504.19274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted to the Privacy Enhancing Technologies  Symposium (PETS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TeleSparse是一种ZK-friendly后处理机制，用于解决将ZK-SNARKs应用于现代神经网络时的计算开销问题。&lt;h4&gt;背景&lt;/h4&gt;验证深度学习推理的完整性对于确保模型应用正确至关重要，但通常需要访问模型权重和训练数据，这可能导致敏感信息泄露。&lt;h4&gt;目的&lt;/h4&gt;提出TeleSparse以解决将ZK-SNARKs应用于现代神经网络时的计算开销问题。&lt;h4&gt;方法&lt;/h4&gt;TeleSparse通过两种方式解决挑战：减少电路约束和最小化查找表的大小。具体包括：1）通过稀疏化神经网络模型来减少约束；2）通过神经遥传来优化激活范围。&lt;h4&gt;主要发现&lt;/h4&gt;TeleSparse在相同模型上减少了证明生成时间46%，内存使用减少了67%，精度损失约为1%。&lt;h4&gt;结论&lt;/h4&gt;TeleSparse为ZK-friendly模型设计开辟了新方向，推动了可扩展、资源高效的验证深度学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：验证深度学习推理的完整性对于理解模型是否被正确应用至关重要。然而，这种验证通常需要访问模型权重和（可能敏感或私有的）训练数据。所谓的零知识简明非交互式知识证明（ZK-SNARKs）似乎提供了在不访问此类敏感数据的情况下验证模型推理的能力。然而，将ZK-SNARKs应用于现代神经网络（如transformers和大型视觉模型）会引入显著的计算开销。我们提出了TeleSparse，这是一种ZK-friendly的后处理机制，用于提供实际的解决方案。TeleSparse解决了将ZK-SNARKs应用于现代神经网络时固有的两个基本挑战：（1）减少电路约束：过参数化的模型导致ZK-SNARK验证的约束数量众多，从而增加了内存和证明生成成本。我们通过应用稀疏化来解决这一问题，在不损害精度或安全性的情况下提高了证明效率。（2）通过优化激活范围，最小化非线性函数所需的查找表大小，这是一种新颖的神经网络遥传方法，用于缩小激活函数的范围。TeleSparse在相同模型上减少了证明生成时间46%，内存使用减少了67%，精度损失约为1%。我们使用Halo2证明系统实现了我们的框架，并在多个架构（Vision-transformer、ResNet、MobileNet）和数据集（ImageNet、CIFAR-10、CIFAR-100）上证明了其有效性。这项工作为ZK-friendly模型设计开辟了新方向，推动了可扩展、资源高效的验证深度学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Verification of the integrity of deep learning inference is crucial forunderstanding whether a model is being applied correctly. However, suchverification typically requires access to model weights and (potentiallysensitive or private) training data. So-called Zero-knowledge SuccinctNon-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide thecapability to verify model inference without access to such sensitive data.However, applying ZK-SNARKs to modern neural networks, such as transformers andlarge vision models, introduces significant computational overhead.  We present TeleSparse, a ZK-friendly post-processing mechanisms to producepractical solutions to this problem. TeleSparse tackles two fundamentalchallenges inherent in applying ZK-SNARKs to modern neural networks: (1)Reducing circuit constraints: Over-parameterized models result in numerousconstraints for ZK-SNARK verification, driving up memory and proof generationcosts. We address this by applying sparsification to neural network models,enhancing proof efficiency without compromising accuracy or security. (2)Minimizing the size of lookup tables required for non-linear functions, byoptimizing activation ranges through neural teleportation, a novel adaptationfor narrowing activation functions' range.  TeleSparse reduces prover memory usage by 67% and proof generation time by46% on the same model, with an accuracy trade-off of approximately 1%. Weimplement our framework using the Halo2 proving system and demonstrate itseffectiveness across multiple architectures (Vision-transformer, ResNet,MobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens newdirections for ZK-friendly model design, moving toward scalable,resource-efficient verifiable deep learning.</description>
      <author>example@mail.com (Mohammad M Maheri, Hamed Haddadi, Alex Davidson)</author>
      <guid isPermaLink="false">2504.19274v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Speaker Diarization for Low-Resource Languages Through Wav2vec Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.18582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究针对低资源语言如库尔德语的说话人分割问题进行了研究，提出了一种基于Wav2Vec 2.0模型的方法，通过迁移学习提高了低资源语言的说话人分割性能。&lt;h4&gt;背景&lt;/h4&gt;说话人分割是语音处理中的基础任务，但在低资源语言如库尔德语中由于数据有限、方言多样和代码转换频繁，存在独特挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在解决低资源语言库尔德语的说话人分割问题，提高其分割性能。&lt;h4&gt;方法&lt;/h4&gt;研究者通过在专门为库尔德语准备的语料库上训练Wav2Vec 2.0自监督学习模型，并利用迁移学习，将其他语言学到的多语言表示应用于库尔德语语音的语音学和声学特征。&lt;h4&gt;主要发现&lt;/h4&gt;与基线方法相比，该方法将分割错误率降低了7.2%，并将聚类纯度提高了13%。&lt;h4&gt;结论&lt;/h4&gt;这些发现表明，对现有模型的改进可以显著提高低资源语言的说话人分割性能，为其他研究不足的语言构建有效的说话人分割系统奠定了基础，有助于提高语音技术的公平性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：说话人分割是语音处理中的基本任务，它涉及将音频流分割成说话人。尽管最先进的模型在高资源语言上取得了先进的性能，但像库尔德语这样的低资源语言由于有限的注释数据、多种方言和频繁的代码转换而提出了独特的挑战。在本研究中，我们通过在专门的库尔德语语料库上训练Wav2Vec 2.0自监督学习模型来解决这些问题。通过迁移学习，我们将从其他语言学习到的多语言表示调整为捕获库尔德语语音的语音学和声学特征。与基线方法相比，我们的方法将分割错误率降低了7.2%，并将聚类纯度提高了13%。这些发现表明，对现有模型的改进可以显著提高低资源语言的分割性能。我们的工作对开发库尔德语媒体转录服务以及在多语言呼叫中心、电话会议和视频会议系统中的说话人分割具有实际意义。这些结果为构建其他研究不足的语言的有效分割系统奠定了基础，有助于提高语音技术的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speaker diarization is a fundamental task in speech processing that involvesdividing an audio stream by speaker. Although state-of-the-art models haveadvanced performance in high-resource languages, low-resource languages such asKurdish pose unique challenges due to limited annotated data, multiple dialectsand frequent code-switching. In this study, we address these issues by trainingthe Wav2Vec 2.0 self-supervised learning model on a dedicated Kurdish corpus.By leveraging transfer learning, we adapted multilingual representationslearned from other languages to capture the phonetic and acousticcharacteristics of Kurdish speech. Relative to a baseline method, our approachreduced the diarization error rate by seven point two percent and improvedcluster purity by thirteen percent. These findings demonstrate thatenhancements to existing models can significantly improve diarizationperformance for under-resourced languages. Our work has practical implicationsfor developing transcription services for Kurdish-language media and forspeaker segmentation in multilingual call centers, teleconferencing andvideo-conferencing systems. The results establish a foundation for buildingeffective diarization systems in other understudied languages, contributing togreater equity in speech technology.</description>
      <author>example@mail.com (Abdulhady Abas Abdullah, Sarkhel H. Taher Karim, Sara Azad Ahmed, Kanar R. Tariq, Tarik A. Rashid)</author>
      <guid isPermaLink="false">2504.18582v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:01 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions</title>
      <link>http://arxiv.org/abs/2504.19056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 main pages, 30 pages appendix, 21 figures, 8 tables, GitHub  Repository:  https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了生成式人工智能在艺术、游戏和动画领域的应用，特别是动画内容生产的成本和时间减少。文章全面分析了面部动画、表情渲染、图像合成、角色创建、手势建模、运动合成、物体生成和纹理合成等领域的最新进展。&lt;h4&gt;背景&lt;/h4&gt;生成式人工智能在动画领域的应用越来越广泛，但现有综述往往缺乏综合性，未能全面涵盖所有相关技术。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供一个综合性的视角，全面概述生成式人工智能在角色动画中的应用，并帮助新进入该领域的研究者和开发者。&lt;h4&gt;方法&lt;/h4&gt;文章首先回顾了面部动画、表情渲染等领域的最新研究，然后讨论了实际应用、常用数据集和新兴趋势。此外，还提供了基础模型和评估指标的相关背景介绍。&lt;h4&gt;主要发现&lt;/h4&gt;近年来，生成式人工智能在动画领域的应用取得了显著进展，包括面部动画、表情渲染、图像合成等方面的技术革新。&lt;h4&gt;结论&lt;/h4&gt;本文为生成式人工智能动画领域的研究者和开发者提供了一个资源，并指出了未来研究方向，以推动人工智能驱动的角色动画技术发展。&lt;h4&gt;翻译&lt;/h4&gt;Generative AI is reshaping art, gaming, and most notably animation. Recent breakthroughs in foundation and diffusion models have reduced the time and cost of producing animated content. Characters are central animation components, involving motion, emotions, gestures, and facial expressions. The pace and breadth of advances in recent months make it difficult to maintain a coherent view of the field, motivating the need for an integrative review. Unlike earlier overviews that treat avatars, gestures, or facial animation in isolation, this survey offers a single, comprehensive perspective on all the main generative AI applications for character animation. We begin by examining the state-of-the-art in facial animation, expression rendering, imagesynthesis, avatar creation, gesture modeling, motion synthesis, object generation, and texture synthesis. We highlight leading research, practical deployments, commonly used datasets, and emerging trends for each area. To support newcomers, we also provide a comprehensive background section that introduces foundational models and evaluation metrics, equipping readers with the knowledge needed to enter the field. We discuss open challenges and map future research directions, providing a roadmap to advance AI-driven character-animation technologies. This survey is intended as a resource for researchers and developers entering the field of generative AI animation or adjacent fields. Resources are available at: https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative AI is reshaping art, gaming, and most notably animation. Recentbreakthroughs in foundation and diffusion models have reduced the time and costof producing animated content. Characters are central animation components,involving motion, emotions, gestures, and facial expressions. The pace andbreadth of advances in recent months make it difficult to maintain a coherentview of the field, motivating the need for an integrative review. Unlikeearlier overviews that treat avatars, gestures, or facial animation inisolation, this survey offers a single, comprehensive perspective on all themain generative AI applications for character animation. We begin by examiningthe state-of-the-art in facial animation, expression rendering, imagesynthesis, avatar creation, gesture modeling, motion synthesis, objectgeneration, and texture synthesis. We highlight leading research, practicaldeployments, commonly used datasets, and emerging trends for each area. Tosupport newcomers, we also provide a comprehensive background section thatintroduces foundational models and evaluation metrics, equipping readers withthe knowledge needed to enter the field. We discuss open challenges and mapfuture research directions, providing a roadmap to advance AI-drivencharacter-animation technologies. This survey is intended as a resource forresearchers and developers entering the field of generative AI animation oradjacent fields. Resources are available at:https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Omid Ghahroodi, Pardis Sadat Zahraei, Hossein Behzadasl, Alireza Mirrokni, Mobina Salimipanah, Arash Rasouli, Bahar Behzadipour, Sara Azarnoush, Benyamin Maleki, Erfan Sadraiye, Kiarash Kiani Feriz, Mahdi Teymouri Nahad, Ali Moghadasi, Abolfazl Eshagh Abianeh, Nizi Nazar, Hamid R. Rabiee, Mahdieh Soleymani Baghshah, Meisam Ahmadi, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2504.19056v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>PyViT-FUSE: A Foundation Model for Multi-Sensor Earth Observation Data</title>
      <link>http://arxiv.org/abs/2504.18770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 13 figures, Published at ICLR 2025 - Machine Learning for  Remote Sensing (ML4RS) Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PyViT-FUSE的基础模型，专门设计用于处理多模态图像，通过注意力机制将任意数量的混合分辨率输入波段融合成一个单一表示。&lt;h4&gt;背景&lt;/h4&gt;针对地球观测数据的多模态图像处理需求。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够融合多模态图像的基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用注意力机制融合不同分辨率的输入波段，并通过具有新颖金字塔结构的视觉Transformer对融合后的块状标记进行处理。采用SwAV算法的核心概念进行自监督训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过可视化注意力分数展示了融合机制的可解释性，并证明了模型在下游任务中的应用能力。&lt;h4&gt;结论&lt;/h4&gt;PyViT-FUSE模型在地球观测数据的多模态图像处理方面具有良好的表现。&lt;h4&gt;翻译&lt;/h4&gt;We propose PyViT-FUSE, a foundation model for earth observation data explicitly designed to handle multi-modal imagery by learning to fuse an arbitrary number of mixed-resolution input bands into a single representation through an attention mechanism. The learned patch tokens are further processed by a stack of vision transformers with a novel pyramidal structure. We train the model on a globally sampled dataset in a self-supervised manner, leveraging core concepts of the SwAV algorithm. We show the interpretability of the fusion mechanism by visualization of the attention scores and the models applicability to downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose PyViT-FUSE, a foundation model for earth observation dataexplicitly designed to handle multi-modal imagery by learning to fuse anarbitrary number of mixed-resolution input bands into a single representationthrough an attention mechanism. The learned patch tokens are further processedby a stack of vision transformers with a novel pyramidal structure. We trainthe model on a globally sampled dataset in a self-supervised manner, leveragingcore concepts of the SwAV algorithm. We show the interpretability of the fusionmechanism by visualization of the attention scores and the models applicabilityto downstream tasks.</description>
      <author>example@mail.com (Manuel Weber, Carly Beneke)</author>
      <guid isPermaLink="false">2504.18770v1</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception</title>
      <link>http://arxiv.org/abs/2504.16616v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EHGCN的新方法，用于在欧几里得和双曲空间中感知事件流，通过自适应采样策略、运动感知超边生成方法和欧几里得-双曲GCN融合，实现了混合事件感知。&lt;h4&gt;背景&lt;/h4&gt;事件相机具有微秒级时间分辨率和高清特性，尽管基于图神经网络（GNN）的感知方法有进展，但它们在纯欧几里得空间中使用简单的成对连接机制，难以捕捉长距离依赖关系，也无法有效表征非均匀分布事件流的内在层次结构。&lt;h4&gt;目的&lt;/h4&gt;提出EHGCN方法，以改善事件流感知，尤其是在欧几里得和双曲空间中。&lt;h4&gt;方法&lt;/h4&gt;EHGCN中引入了自适应采样策略来动态调节采样率，通过保留判别性事件来降低噪声。此外，提出了基于运动状态转移概率的马尔可夫向量场（MVF）驱动的运动感知超边生成方法，以消除跨目标的虚假关联并提供拓扑先验，同时捕捉事件之间的长距离依赖关系。最后，提出了欧几里得-双曲GCN来融合在欧几里得和双曲空间中局部聚合和全局层次建模的信息。&lt;h4&gt;主要发现&lt;/h4&gt;EHGCN能够有效捕捉事件之间的长距离依赖关系，并通过融合欧几里得和双曲空间的信息实现混合事件感知。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，EHGCN在事件感知任务（如目标检测和识别）中是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：事件相机，具有微秒级时间分辨率和高动态范围（HDR）特性，为感知任务提供高速事件流。尽管基于图神经网络（GNN）的感知方法最近有了进展，但它们容易使用简单的成对连接机制在纯欧几里得空间中，这使它们难以捕捉长距离依赖关系，并且无法有效表征非均匀分布事件流的固有层次结构。为此，本文提出了一种名为EHGCN的新方法，这是首次在欧几里得和双曲空间中感知事件流。在EHGCN中，我们引入了一种自适应采样策略来动态调节采样率，在保留判别性事件的同时降低噪声。然后，我们提出了一种基于运动状态转移概率的马尔可夫向量场（MVF）驱动的运动感知超边生成方法，从而消除跨目标的虚假关联并提供关键拓扑先验，同时捕捉事件之间的长距离依赖关系。最后，我们提出了一个欧几里得-双曲GCN，以融合在欧几里得和双曲空间中分别局部聚合和全局层次建模的信息，以实现混合事件感知。在事件感知任务（如目标检测和识别）上的实验结果验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras, with microsecond temporal resolution and high dynamic range(HDR) characteristics, emit high-speed event stream for perception tasks.Despite the recent advancement in GNN-based perception methods, they are proneto use straightforward pairwise connectivity mechanisms in the pure Euclideanspace where they struggle to capture long-range dependencies and fail toeffectively characterize the inherent hierarchical structures of non-uniformlydistributed event stream. To this end, in this paper we propose a novelapproach named EHGCN, which is a pioneer to perceive event stream in bothEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce anadaptive sampling strategy to dynamically regulate sampling rates, retainingdiscriminative events while attenuating chaotic noise. Then we present a MarkovVector Field (MVF)-driven motion-aware hyperedge generation method based onmotion state transition probabilities, thereby eliminating cross-targetspurious associations and providing critically topological priors whilecapturing long-range dependencies between events. Finally, we propose aEuclidean-Hyperbolic GCN to fuse the information locally aggregated andglobally hierarchically modeled in Euclidean and hyperbolic spaces,respectively, to achieve hybrid event perception. Experimental results on eventperception tasks such as object detection and recognition validate theeffectiveness of our approach.</description>
      <author>example@mail.com (Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.16616v2</guid>
      <pubDate>Tue, 29 Apr 2025 14:21:02 +0800</pubDate>
    </item>
    <item>
      <title>A Generative Graph Contrastive Learning Model with Global Signal</title>
      <link>http://arxiv.org/abs/2504.18148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的对比信号生成框架CSG2L，用于精确的图学习，旨在解决现有图对比学习模型的性能退化问题。&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）通过自监督学习方式从图中学习复杂结构信息，但现有的GCL模型可能因为不适当的对比信号而性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有GCL模型的性能退化问题，提出CSG2L框架。&lt;h4&gt;方法&lt;/h4&gt;CSG2L框架包含以下两个方面的创新：1）构建SVD导向的增强模块（SVD-aug），以获得全局交互并避免随机噪声扰动；2）设计局部-全局依赖学习模块（LGDL）和自适应重加权策略，以区分硬样本对和易样本对的影响。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，提出的CSG2L优于现有基准模型，并且CSG2L与多种图神经网络（GNNs）兼容。&lt;h4&gt;结论&lt;/h4&gt;CSG2L是一种有效的图学习框架，可以提升图对比学习模型的性能，并具有广泛的适用性。&lt;h4&gt;翻译&lt;/h4&gt;Graph contrastive learning (GCL) has garnered significant attention recently since it learns complex structural information from graphs through self-supervised learning manner. However, prevalent GCL models may suffer from performance degradation due to inappropriate contrastive signals. Concretely, they commonly generate augmented views based on random perturbation, which leads to biased essential structures due to the introduction of noise. In addition, they assign equal weight to both hard and easy sample pairs, thereby ignoring the difference in importance of the sample pairs. To address these issues, this study proposes a novel Contrastive Signal Generative Framework for Accurate Graph Learning (CSG2L) with the following two-fold ideas: a) building a singular value decomposition (SVD)-directed augmented module (SVD-aug) to obtain the global interactions as well as avoiding the random noise perturbation; b) designing a local-global dependency learning module (LGDL) with an adaptive reweighting strategy which can differentiate the effects of hard and easy sample pairs. Extensive experiments on benchmark datasets demonstrate that the proposed CSG2L outperforms the state-of-art baselines. Moreover, CSG2L is compatible with a variety of GNNs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) has garnered significant attention recentlysince it learns complex structural information from graphs throughself-supervised learning manner. However, prevalent GCL models may suffer fromperformance degradation due to inappropriate contrastive signals. Concretely,they commonly generate augmented views based on random perturbation, whichleads to biased essential structures due to the introduction of noise. Inaddition, they assign equal weight to both hard and easy sample pairs, therebyignoring the difference in importance of the sample pairs. To address theseissues, this study proposes a novel Contrastive Signal Generative Framework forAccurate Graph Learning (CSG2L) with the following two-fold ideas: a) buildinga singular value decomposition (SVD)-directed augmented module (SVD-aug) toobtain the global interactions as well as avoiding the random noiseperturbation; b) designing a local-global dependency learning module (LGDL)with an adaptive reweighting strategy which can differentiate the effects ofhard and easy sample pairs. Extensive experiments on benchmark datasetsdemonstrate that the proposed CSG2L outperforms the state-of-art baselines.Moreover, CSG2L is compatible with a variety of GNNs.</description>
      <author>example@mail.com (Xiaofan Wei, Binyan Zhang)</author>
      <guid isPermaLink="false">2504.18148v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
  <item>
      <title>Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation</title>
      <link>http://arxiv.org/abs/2504.18096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MKMed的跨模态药物编码器，用于提高药物推荐系统的准确性和安全性，以解决药物推荐中的数据不平衡问题。&lt;h4&gt;背景&lt;/h4&gt;药物推荐在医疗保健中至关重要，依赖于患者的电子健康记录（EHR）。然而，不同药物的数据类型不均衡，限制了现有模型的表现，这被称为“桶效应”。&lt;h4&gt;目的&lt;/h4&gt;旨在解决药物推荐中的“桶效应”，提高药物推荐的准确性和安全性。&lt;h4&gt;方法&lt;/h4&gt;引入了MKMed框架，该框架使用对比学习在五种知识模态上预训练一个跨模态编码器，并将多知识药物表示与患者记录结合进行推荐。&lt;h4&gt;主要发现&lt;/h4&gt;数据分析揭示了药物推荐中“桶效应”的严重性，MKMed框架有效缓解了数据不平衡问题，并在MIMIC-III和MIMIC-IV数据集上显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;MKMed框架通过跨模态编码和多知识集成，显著提高了药物推荐的准确性和安全性，是解决药物推荐中数据不平衡问题的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medication recommendation is crucial in healthcare, offering effectivetreatments based on patient's electronic health records (EHR). Previous studiesshow that integrating more medication-related knowledge improves medicationrepresentation accuracy. However, not all medications encompass multiple typesof knowledge data simultaneously. For instance, some medications provide onlytextual descriptions without structured data. This imbalance in dataavailability limits the performance of existing models, a challenge we term the"bucket effect" in medication recommendation. Our data analysis uncovers theseverity of the "bucket effect" in medication recommendation. To fill this gap,we introduce a cross-modal medication encoder capable of seamlessly aligningdata from different modalities and propose a medication recommendationframework to integrate Multiple types of Knowledge, named MKMed. Specifically,we first pre-train a cross-modal encoder with contrastive learning on fiveknowledge modalities, aligning them into a unified space. Then, we combine themulti-knowledge medication representations with patient records forrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasetsdemonstrate that MKMed mitigates the "bucket effect" in data, and significantlyoutperforms state-of-the-art baselines in recommendation accuracy and safety.</description>
      <author>example@mail.com (Xiang Li, Haixu Ma, Guanyong Wu, Shi Mu, Chen Li, Shunpan Liang)</author>
      <guid isPermaLink="false">2504.18096v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Testing Individual Fairness in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了人工智能模型中的偏见可能导致歧视，并重点研究了图神经网络（GNNs）中的个体公平性问题。&lt;h4&gt;背景&lt;/h4&gt;当前研究主要集中在诊断和减轻各种AI模型中的偏见，但关于GNNs中个体公平性的研究较少。&lt;h4&gt;目的&lt;/h4&gt;本项目旨在开发一个测试框架，以评估和确保GNNs中的个体公平性。&lt;h4&gt;方法&lt;/h4&gt;首先，系统回顾个体公平性的文献，并对现有方法进行分类，创建个体公平性的分类法。其次，通过改编和扩展当前的公平性测试和缓解技术，开发一个测试和确保GNNs公平性的框架。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs能够捕捉节点间的图结构，但这也意味着偏见可能通过这些连接传播，从而增加了检测和缓解个体公平性违规的复杂性。&lt;h4&gt;结论&lt;/h4&gt;通过工业案例研究评估框架，重点关注基于图的的大型语言模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工智能（AI）模型中的偏见可能导致自动决策过程歧视基于性别和种族等敏感属性的群体和/或个人。尽管有许多关于诊断和减轻各种AI模型中偏见的研究，但关于图神经网络（GNNs）中个体公平性的研究却很少。与独立处理数据特征的传统模型不同，GNNs旨在捕捉节点间相互连接的图结构。这种关系方法使GNNs能够模拟复杂的依赖关系，但也意味着偏见可能通过这些连接传播，从而增加了检测和缓解个体公平性违规的复杂性。本博士项目旨在开发一个测试框架来评估和确保GNNs中的个体公平性。首先，系统地回顾个体公平性的文献，对现有方法进行分类，创建个体公平性的分类法。接下来，通过改编和扩展当前的公平性测试和缓解技术，开发一个测试和确保GNNs公平性的框架。该框架将通过工业案例研究进行评估，重点关注基于图的的大型语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The biases in artificial intelligence (AI) models can lead to automateddecision-making processes that discriminate against groups and/or individualsbased on sensitive properties such as gender and race. While there are manystudies on diagnosing and mitigating biases in various AI models, there islittle research on individual fairness in Graph Neural Networks (GNNs). Unliketraditional models, which treat data features independently and overlook theirinter-relationships, GNNs are designed to capture graph-based structure wherenodes are interconnected. This relational approach enables GNNs to modelcomplex dependencies, but it also means that biases can propagate through theseconnections, complicating the detection and mitigation of individual fairnessviolations. This PhD project aims to develop a testing framework to assess andensure individual fairness in GNNs. It first systematically reviews theliterature on individual fairness, categorizing existing approaches to define,measure, test, and mitigate model biases, creating a taxonomy of individualfairness. Next, the project will develop a framework for testing and ensuringfairness in GNNs by adapting and extending current fairness testing andmitigation techniques. The framework will be evaluated through industrial casestudies, focusing on graph-based large language models.</description>
      <author>example@mail.com (Roya Nasiri)</author>
      <guid isPermaLink="false">2504.18353v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>S3MOT: Monocular 3D Object Tracking with Selective State Space Model</title>
      <link>http://arxiv.org/abs/2504.18068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的单目三维多目标跟踪方法，该方法通过三种创新技术提高了异质信息的融合和利用。&lt;h4&gt;背景&lt;/h4&gt;在单目设置中，准确可靠的三维多目标跟踪是机器人学和计算机视觉应用发展的关键，但由于从二维视频流中挖掘三维时空关联的困难，这仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提高单目三维多目标跟踪的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;1) 引入匈牙利状态空间模型（HSSM），一种新的数据关联机制，通过压缩多个路径上的上下文跟踪线索，以线性复杂度实现高效全面的分配决策。2) 提出全卷积单阶段嵌入（FCOE），通过直接使用密集特征图进行对比学习，消除了ROI池化，从而在如视角变化和光照条件变化等具有挑战性的条件下提高了物体重识别的准确性。3) 通过VeloSSM增强6自由度姿态估计，这是一种编码器-解码器架构，它通过模拟速度中的时间依赖性来捕捉运动动力学，克服了基于帧的3D推理的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI公共测试基准上的实验表明，该方法达到了76.86 HOTA的新状态-of-the-art性能，在31 FPS下，优于以前的最佳方法，显著提高了2.63 HOTA和3.62 AssA。&lt;h4&gt;结论&lt;/h4&gt;该方法在单目三维多目标跟踪任务中表现出色，具有鲁棒性和效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel monocular 3D multi-object tracking method that improves the fusion and exploitation of heterogeneous information through three innovative techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and reliable multi-object tracking (MOT) in 3D space is essentialfor advancing robotics and computer vision applications. However, it remains asignificant challenge in monocular setups due to the difficulty of mining 3Dspatiotemporal associations from 2D video streams. In this work, we presentthree innovative techniques to enhance the fusion and exploitation ofheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian StateSpace Model (HSSM), a novel data association mechanism that compressescontextual tracking cues across multiple paths, enabling efficient andcomprehensive assignment decisions with linear complexity. HSSM features aglobal receptive field and dynamic weights, in contrast to traditional linearassignment algorithms that rely on hand-crafted association costs. (2) Wepropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROIpooling by directly using dense feature maps for contrastive learning, thusimproving object re-identification accuracy under challenging conditions suchas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimationthrough VeloSSM, an encoder-decoder architecture that models temporaldependencies in velocity to capture motion dynamics, overcoming the limitationsof frame-based 3D inference. Experiments on the KITTI public test benchmarkdemonstrate the effectiveness of our method, achieving a new state-of-the-artperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous bestby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustnessand efficiency for monocular 3D MOT tasks. The code and models are available athttps://github.com/bytepioneerX/s3mot.</description>
      <author>example@mail.com (Zhuohao Yan, Shaoquan Feng, Xingxing Li, Yuxuan Zhou, Chunxi Xia, Shengyu Li)</author>
      <guid isPermaLink="false">2504.18068v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Learning on Large Graphs using a Densifying Regularity Lemma</title>
      <link>http://arxiv.org/abs/2504.18273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Intersecting Block Graph (IBG)，一种基于交错二分组件的低秩分解的大规模有向图学习方法，旨在解决传统消息传递神经网络在处理大型图时计算和内存成本的问题。&lt;h4&gt;背景&lt;/h4&gt;传统消息传递神经网络在处理大型图时，计算和内存成本会随着边的数量线性增长，给学习大型图带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出IBG方法，通过降低非边的权重，有效地近似任何稀疏或密集的图，以降低计算和内存成本。&lt;h4&gt;方法&lt;/h4&gt;IBG方法基于交错二分组件的低秩分解，其中每个组件由一对社区组成，分别对应源节点和目标节点。通过证明弱正则性公理的构造性版本，证明了对于任何选择的精度，无论图的大小或稀疏性如何，都可以用一个低秩的密集IBG来近似。&lt;h4&gt;主要发现&lt;/h4&gt;IBG的秩仅取决于精度，而与稀疏程度无关，这与之前的弱正则性公理形式不同。此外，基于IBG的图神经网络在节点分类、时空图分析和知识图谱补全任务上表现出竞争力，同时具有与节点数量线性相关的内存和计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;IBG是一种有效的大规模图学习方法，可以显著降低计算和内存成本，并在多个图学习任务中取得良好性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在大型图上进行学习带来了重大挑战，传统的消息传递神经网络因计算和内存成本随边的数量线性增长而受到限制。我们引入了交错的块图（IBG），这是一种基于交错二分组件的大规模有向图低秩分解方法，每个组件由一对社区组成，分别对应源节点和目标节点。通过降低非边的权重，我们展示了如何有效地用密集的IBG近似任何图，无论是稀疏的还是密集的。具体来说，我们证明了弱正则性公理的构造性版本，表明对于任何选择的精度，无论图的大小或稀疏性如何，都可以用一个低秩的密集IBG来近似。这种秩仅依赖于精度，而不依赖于稀疏程度，这与之前的弱正则性公理形式不同。我们提出了一种在图的IBG表示上运行的图神经网络架构，并在节点分类、时空图分析和知识图谱补全任务上展示了有竞争力的性能，同时具有与节点数量线性相关的内存和计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning on large graphs presents significant challenges, with traditionalMessage Passing Neural Networks suffering from computational and memory costsscaling linearly with the number of edges. We introduce the Intersecting BlockGraph (IBG), a low-rank factorization of large directed graphs based oncombinations of intersecting bipartite components, each consisting of a pair ofcommunities, for source and target nodes. By giving less weight to non-edges,we show how to efficiently approximate any graph, sparse or dense, by a denseIBG. Specifically, we prove a constructive version of the weak regularitylemma, showing that for any chosen accuracy, every graph, regardless of itssize or sparsity, can be approximated by a dense IBG whose rank depends only onthe accuracy. This dependence of the rank solely on the accuracy, and not onthe sparsity level, is in contrast to previous forms of the weak regularitylemma. We present a graph neural network architecture operating on the IBGrepresentation of the graph and demonstrating competitive performance on nodeclassification, spatio-temporal graph analysis, and knowledge graph completion,while having memory and computational complexity linear in the number of nodesrather than edges.</description>
      <author>example@mail.com (Jonathan Kouchly, Ben Finkelshtein, Michael Bronstein, Ron Levie)</author>
      <guid isPermaLink="false">2504.18273v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.18419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法来检测三维物体，该方法利用激光雷达和RGB摄像头，通过混合级联方案结合RGB检测网络和3D激光雷达检测器。&lt;h4&gt;背景&lt;/h4&gt;现有的三维物体检测方法通常依赖于单一传感器，如激光雷达或RGB摄像头。&lt;h4&gt;目的&lt;/h4&gt;提高三维物体检测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用后期融合原理减少激光雷达的误报，通过将激光雷达的边界框投影到图像上来匹配激光雷达检测与RGB检测。利用级联融合原理，通过视差约束和由RGB检测生成的视锥恢复激光雷达的漏检。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以集成到任何底层的单模态检测器中，允许灵活的训练过程，可以利用预训练的激光雷达和RGB检测器，或者分别训练两个分支。在KITTI物体检测基准测试中，该方法显示出显著的性能提升，尤其是在行人自行车检测方面。&lt;h4&gt;结论&lt;/h4&gt;该方法为三维物体检测提供了一种有效且灵活的解决方案，提高了检测准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种从多模态输入中检测三维物体的新方法，该方法利用激光雷达和RGB摄像头，采用混合后期级联方案，结合RGB检测网络和3D激光雷达检测器。我们利用后期融合原理来减少激光雷达的误报，通过将激光雷达的边界框投影到图像上来匹配激光雷达检测与RGB检测。我们依靠级联融合原理，利用视差约束和由RGB检测生成的视锥恢复激光雷达的漏检。我们的解决方案可以集成到任何底层的单模态检测器中，允许灵活的训练过程，可以利用预训练的激光雷达和RGB检测器，或者分别训练两个分支。我们在KITTI物体检测基准测试中评估了我们的结果，显示出显著的性能提升，尤其是在行人自行车检测方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new way to detect 3D objects from multimodal inputs, leveragingboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines anRGB detection network and a 3D LiDAR detector. We exploit late fusionprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGBones by projecting the LiDAR bounding boxes on the image. We rely on cascadefusion principles to recover LiDAR False Negatives leveraging epipolarconstraints and frustums generated by RGB detections of separate views. Oursolution can be plugged on top of any underlying single-modal detectors,enabling a flexible training process that can take advantage of pre-trainedLiDAR and RGB detectors, or train the two branches separately. We evaluate ourresults on the KITTI object detection benchmark, showing significantperformance improvements, especially for the detection of Pedestrians andCyclists.</description>
      <author>example@mail.com (Carlo Sgaravatti, Roberto Basla, Riccardo Pieroni, Matteo Corno, Sergio M. Savaresi, Luca Magri, Giacomo Boracchi)</author>
      <guid isPermaLink="false">2504.18419v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient GNN Training Through Structure-Aware Randomized Mini-Batching</title>
      <link>http://arxiv.org/abs/2504.18082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COMM-RAND的新方法，用于GNN的小批量训练，该方法在保持模型精度的同时，显著提高了训练效率。&lt;h4&gt;背景&lt;/h4&gt;当前GNN的小批量训练策略大多忽略了效率考虑，现有的随机化方案虽然能提高准确性和收敛速度，但往往忽视了图的拓扑结构特性，导致内存访问模式不规律，影响了GPU缓存的利用效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的小批量训练方法，在保证模型准确度的同时，提高GNN训练的效率。&lt;h4&gt;方法&lt;/h4&gt;该方法称为Community-structure-aware Randomized Mini-batching (COMM-RAND)，它允许在构建小批量时探索介于纯随机性和纯图结构意识之间的空间。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果显示，COMM-RAND将GNN训练时间减少了高达2.76倍（平均1.8倍），同时与常见的随机小批量方法相比，准确度只降低了1.79个百分点（平均0.42个百分点）。&lt;h4&gt;结论&lt;/h4&gt;COMM-RAND是一种有效的GNN小批量训练方法，能够在保证模型精度的同时，显著提高训练效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a novel methodology called Community-structure-aware Randomized Mini-batching (COMM-RAND) for GNN mini-batch training, which significantly improves training efficiency while maintaining model accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) enable learning on realworld graphs andmini-batch training has emerged as the de facto standard for training GNNsbecause it can scale to very large graphs and improve convergence. Currentmini-batch construction policies largely ignore efficiency considerations ofGNN training. Specifically, existing mini-batching techniques employrandomization schemes to improve accuracy and convergence. However, theserandomization schemes are often agnostic to the structural properties of thegraph (for eg. community structure), resulting in highly irregular memoryaccess patterns during GNN training that make suboptimal use of on-chip GPUcaches. On the other hand, while deterministic mini-batching based solely ongraph structure delivers fast runtime performance, the lack of randomnesscompromises both the final model accuracy and training convergence speed. Inthis paper, we present Community-structure-aware Randomized Mini-batching(COMM-RAND), a novel methodology that bridges the gap between the aboveextremes. COMM-RAND allows practitioners to explore the space between purerandomness and pure graph structural awareness during mini-batch construction,leading to significantly more efficient GNN training with similar accuracy. Weevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RANDcuts down GNN training time by up to 2.76x (1.8x on average) while achieving anaccuracy that is within 1.79% points (0.42% on average) compared to popularrandom mini-batching approaches.</description>
      <author>example@mail.com (Vignesh Balaji, Christos Kozyrakis, Gal Chechik, Haggai Maron)</author>
      <guid isPermaLink="false">2504.18082v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning for Distributional Perturbation Extrapolation</title>
      <link>http://arxiv.org/abs/2504.18522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; work presented at the ICLR Workshop on Learning Meaningful  Representations of Life&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在未知扰动（如基因敲低或药物组合）对RNA测序等低层次测量数据影响建模的问题。&lt;h4&gt;背景&lt;/h4&gt;针对给定的扰动数据，研究者们试图预测新扰动下的测量分布。&lt;h4&gt;目的&lt;/h4&gt;通过证明在足够多样化的训练扰动下，扰动效果在空间表示上是可识别的，本研究旨在预测未知扰动的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为扰动分布自动编码器（PDAE）的新方法，通过最大化真实和预测扰动分布之间的分布相似性来估计模型。&lt;h4&gt;主要发现&lt;/h4&gt;PDAE模型能够有效预测未知扰动的影响，并在实证研究中显示出与现有方法和基线相比的优势。&lt;h4&gt;结论&lt;/h4&gt;PDAE方法为预测未知扰动提供了有力的工具，并有望在生物信息学等领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;We consider the problem of modeling the effects of unseen perturbations such as gene knockdowns or drug combinations on low-level measurements such as RNA sequencing data. Specifically, given data collected under some perturbations, we aim to predict the distribution of measurements for new perturbations. To address this challenging extrapolation task, we posit that perturbations act additively in a suitable, unknown embedding space. More precisely, we formulate the generative process underlying the observed data as a latent variable model, in which perturbations amount to mean shifts in latent space and can be combined additively. Unlike previous work, we prove that, given sufficiently diverse training perturbations, the representation and perturbation effects are identifiable up to affine transformation, and use this to characterize the class of unseen perturbations for which we obtain extrapolation guarantees. To estimate the model from data, we propose a new method, the perturbation distribution autoencoder (PDAE), which is trained by maximizing the distributional similarity between true and predicted perturbation distributions. The trained model can then be used to predict previously unseen perturbation distributions. Empirical evidence suggests that PDAE compares favorably to existing methods and baselines at predicting the effects of unseen perturbations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of modelling the effects of unseen perturbations suchas gene knockdowns or drug combinations on low-level measurements such as RNAsequencing data. Specifically, given data collected under some perturbations,we aim to predict the distribution of measurements for new perturbations. Toaddress this challenging extrapolation task, we posit that perturbations actadditively in a suitable, unknown embedding space. More precisely, we formulatethe generative process underlying the observed data as a latent variable model,in which perturbations amount to mean shifts in latent space and can becombined additively. Unlike previous work, we prove that, given sufficientlydiverse training perturbations, the representation and perturbation effects areidentifiable up to affine transformation, and use this to characterize theclass of unseen perturbations for which we obtain extrapolation guarantees. Toestimate the model from data, we propose a new method, the perturbationdistribution autoencoder (PDAE), which is trained by maximising thedistributional similarity between true and predicted perturbationdistributions. The trained model can then be used to predict previously unseenperturbation distributions. Empirical evidence suggests that PDAE comparesfavourably to existing methods and baselines at predicting the effects ofunseen perturbations.</description>
      <author>example@mail.com (Julius von Kügelgen, Jakob Ketterer, Xinwei Shen, Nicolai Meinshausen, Jonas Peters)</author>
      <guid isPermaLink="false">2504.18522v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>POET: Prompt Offset Tuning for Continual Human Action Adaptation</title>
      <link>http://arxiv.org/abs/2504.18059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024 (Oral), webpage  https://humansensinglab.github.io/POET-continual-action-recognition/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究扩展现实（XR）背景下的人体动作识别，提出了一种隐私感知的少量样本持续动作识别方法POET，旨在允许用户持续添加新动作类别到设备模型中，而不需要存储或回放敏感训练数据。&lt;h4&gt;背景&lt;/h4&gt;扩展现实（XR）技术正在改变用户与计算设备交互的方式，人体动作识别在沉浸式计算设备中的应用研究越来越受到重视。&lt;h4&gt;目的&lt;/h4&gt;提供用户和开发者持续添加新动作类别到设备模型的能力，实现低样本和高效的用户个性化体验。&lt;h4&gt;方法&lt;/h4&gt;提出POET方法，通过轻量级的预训练骨干网络和新的时空可学习提示偏移调整方法，首次将提示调整应用于图神经网络，并提出NTURGB+D和SHREC-2017两个新的基准数据集。&lt;h4&gt;主要发现&lt;/h4&gt;POET在持续学习和隐私保护方面表现出色，在多个基准数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;POET是一种有效且隐私友好的持续动作识别方法，为扩展现实技术中的人体动作识别提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;As extended reality (XR) is redefining how users interact with computing devices, research in human action recognition is gaining prominence. Typically, models deployed on immersive computing devices are static and limited to their default set of classes. The goal of our research is to provide users and developers with the capability to personalize their experience by adding new action classes to their device models continually. Importantly, a user should be able to add new classes in a low-shot and efficient manner, while this process should not require storing or replaying any of user's sensitivetraining data. We formalize this problem as privacy-aware few-shot continual action recognition. Towards this end, we propose POET: Prompt-Offset Tuning. While existing prompt tuning approaches have shown great promise for continual learning of image, text, and video modalities; they demand access to extensively pretrained transformers. Breaking away from this assumption, POET demonstrates the efficacy of prompt tuning a significantly lightweight backbone, pretrained exclusively on the base class data. We propose a novel spatial-temporal learnable prompt offset tuning approach, and are the first to apply such prompt tuning to Graph Neural Networks. We contribute two new benchmarks for our new problem setting in human action recognition: (i) NTURGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for handgesture recognition. We find that POET consistently outperforms comprehensive benchmarks. Source code at https://github.com/humansensinglab/POET-continual-action-recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-73039-9_25&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As extended reality (XR) is redefining how users interact with computingdevices, research in human action recognition is gaining prominence. Typically,models deployed on immersive computing devices are static and limited to theirdefault set of classes. The goal of our research is to provide users anddevelopers with the capability to personalize their experience by adding newaction classes to their device models continually. Importantly, a user shouldbe able to add new classes in a low-shot and efficient manner, while thisprocess should not require storing or replaying any of user's sensitivetraining data. We formalize this problem as privacy-aware few-shot continualaction recognition. Towards this end, we propose POET: Prompt-Offset Tuning.While existing prompt tuning approaches have shown great promise for continuallearning of image, text, and video modalities; they demand access toextensively pretrained transformers. Breaking away from this assumption, POETdemonstrates the efficacy of prompt tuning a significantly lightweightbackbone, pretrained exclusively on the base class data. We propose a novelspatio-temporal learnable prompt offset tuning approach, and are the first toapply such prompt tuning to Graph Neural Networks. We contribute two newbenchmarks for our new problem setting in human action recognition: (i) NTURGB+D dataset for activity recognition, and (ii) SHREC-2017 dataset for handgesture recognition. We find that POET consistently outperforms comprehensivebenchmarks. Source code athttps://github.com/humansensinglab/POET-continual-action-recognition.</description>
      <author>example@mail.com (Prachi Garg, Joseph K J, Vineeth N Balasubramanian, Necati Cihan Camgoz, Chengde Wan, Kenrick Kin, Weiguang Si, Shugao Ma, Fernando De La Torre)</author>
      <guid isPermaLink="false">2504.18059v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR-Guided Monocular 3D Object Detection for Long-Range Railway Monitoring</title>
      <link>http://arxiv.org/abs/2504.18203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for the Data-Driven Learning for Intelligent Vehicle  Applications Workshop at the 36th IEEE Intelligent Vehicles Symposium (IV)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的长距离3D物体检测方法，旨在解决铁路系统自动化中的感知挑战，并针对德国铁路系统进行优化。&lt;h4&gt;背景&lt;/h4&gt;德国铁路系统需要高度自动化来解决遗留基础设施挑战，并安全增加列车交通。&lt;h4&gt;目的&lt;/h4&gt;开发一种长距离感知技术，用于早期危险检测，如道口障碍物或铁轨上的行人。&lt;h4&gt;方法&lt;/h4&gt;该方法基于深度学习，仅使用单目图像，并借鉴了Faraway-Frustum方法。在训练过程中结合LiDAR数据以改进深度估计。主要模块包括：(1)修改后的YOLOv9进行2.5D物体检测，(2)深度估计网络，以及(3-4)专用短距离和长距离3D检测头。&lt;h4&gt;主要发现&lt;/h4&gt;在OSDaR23数据集上的评估显示，该方法能够检测到250米范围内的物体，具有在铁路自动化中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法在铁路自动化方面具有潜力，并指出了未来改进的领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：铁路系统，特别是在德国，需要高度自动化来解决遗留基础设施挑战并安全增加列车交通。自动化的关键组成部分是强大的长距离感知，这对于早期危险检测至关重要，例如道口的障碍物或铁轨上的行人。与制动距离约为70米的汽车系统不同，列车需要超过1公里的感知范围。本文提出了一种基于深度学习的方法，用于针对自动驾驶火车进行长距离3D物体检测。该方法仅依赖于单目图像，灵感来源于Faraway-Frustum方法，并在训练过程中结合LiDAR数据以改进深度估计。所提出的流程包括四个关键模块：(1)用于2.5D物体检测的修改后的YOLOv9，(2)深度估计网络，以及(3-4)专门的短距离和长距离3D检测头。在OSDaR23数据集上的评估表明，该方法在检测250米范围内的物体方面是有效的。结果突出了其在铁路自动化方面的潜力，并概述了未来改进的领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Railway systems, particularly in Germany, require high levels of automationto address legacy infrastructure challenges and increase train traffic safely.A key component of automation is robust long-range perception, essential forearly hazard detection, such as obstacles at level crossings or pedestrians ontracks. Unlike automotive systems with braking distances of ~70 meters, trainsrequire perception ranges exceeding 1 km. This paper presents andeep-learning-based approach for long-range 3D object detection tailored forautonomous trains. The method relies solely on monocular images, inspired bythe Faraway-Frustum approach, and incorporates LiDAR data during training toimprove depth estimation. The proposed pipeline consists of four key modules:(1) a modified YOLOv9 for 2.5D object detection, (2) a depth estimationnetwork, and (3-4) dedicated short- and long-range 3D detection heads.Evaluations on the OSDaR23 dataset demonstrate the effectiveness of theapproach in detecting objects up to 250 meters. Results highlight its potentialfor railway automation and outline areas for future improvement.</description>
      <author>example@mail.com (Raul David Dominguez Sanchez, Xavier Diaz Ortiz, Xingcheng Zhou, Max Peter Ronecker, Michael Karner, Daniel Watzenig, Alois Knoll)</author>
      <guid isPermaLink="false">2504.18203v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography</title>
      <link>http://arxiv.org/abs/2504.18400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Tract2Shape是一种新型多模态深度学习框架，用于预测白质束追踪的形状度量，具有计算效率高、预测准确和泛化能力强等特点。&lt;h4&gt;背景&lt;/h4&gt;传统的形状度量计算方法计算量大，不适用于大规模数据集。&lt;h4&gt;目的&lt;/h4&gt;提出Tract2Shape框架，以实现快速、准确和可泛化的白质形状度量预测。&lt;h4&gt;方法&lt;/h4&gt;Tract2Shape利用几何（点云）和标量（表格）特征预测十个白质束追踪的形状度量，并使用降维算法预测五个主要形状成分。&lt;h4&gt;主要发现&lt;/h4&gt;Tract2Shape在HCP-YA数据集上优于现有的深度学习模型，实现了最高的平均Pearson相关系数和最低的均方误差。消融研究表明，多模态输入和PCA对性能提升有贡献。在未见的PPMI数据集上，Tract2Shape保持了高Pearson相关系数和低均方误差，显示了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Tract2Shape框架为未来大规模白质形状分析提供了有希望的起点，支持数据集的可扩展分析。&lt;h4&gt;翻译&lt;/h4&gt;Shape measures have emerged as promising descriptors of white matter tractography, offering complementary insights into anatomical variability and associations with cognitive and clinical phenotypes. However, conventional methods for computing shape measures are computationally expensive and time-consuming for large-scale datasets due to reliance on voxel-based representations. We propose Tract2Shape, a novel multimodal deep learning framework that leverages geometric (point cloud) and scalar (tabular) featuresto predict ten white matter tractography shape measures. To enhance model efficiency, we utilize a dimensionality reduction algorithm for the model topredict five primary shape components. The model is trained and evaluated on two independently acquired datasets, the HCP-YA dataset, and the PPMI dataset. We evaluate the performance of Tract2Shape by training and testing it on the HCP-YA dataset and comparing the results with state-of-the-art models. To further assess its robustness and generalization ability, we also test Tract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep learning models across all ten shape measures, achieving the highest average Pearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows that both multimodal input and PCA contribute to performance gains. On the unseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low nMSE, demonstrating strong generalizability in cross-dataset evaluation. Tract2Shape enables fast, accurate, and generalizable prediction of white matter shape measures from tractography data, supporting scalable analysis across datasets. This framework lays a promising foundation for future large-scale white matter shape analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shape measures have emerged as promising descriptors of white mattertractography, offering complementary insights into anatomical variability andassociations with cognitive and clinical phenotypes. However, conventionalmethods for computing shape measures are computationally expensive andtime-consuming for large-scale datasets due to reliance on voxel-basedrepresentations. We propose Tract2Shape, a novel multimodal deep learningframework that leverages geometric (point cloud) and scalar (tabular) featuresto predict ten white matter tractography shape measures. To enhance modelefficiency, we utilize a dimensionality reduction algorithm for the model topredict five primary shape components. The model is trained and evaluated ontwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.We evaluate the performance of Tract2Shape by training and testing it on theHCP-YA dataset and comparing the results with state-of-the-art models. Tofurther assess its robustness and generalization ability, we also testTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deeplearning models across all ten shape measures, achieving the highest averagePearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study showsthat both multimodal input and PCA contribute to performance gains. On theunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and lownMSE, demonstrating strong generalizability in cross-dataset evaluation.Tract2Shape enables fast, accurate, and generalizable prediction of whitematter shape measures from tractography data, supporting scalable analysisacross datasets. This framework lays a promising foundation for futurelarge-scale white matter shape analysis.</description>
      <author>example@mail.com (Yui Lo, Yuqian Chen, Dongnan Liu, Leo Zekelman, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Fan Zhang, Weidong Cai, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2504.18400v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>TGDT: A Temporal Graph-based Digital Twin for Urban Traffic Corridors</title>
      <link>http://arxiv.org/abs/2504.18008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TGDT的基于时间图的城市交通数字孪生框架，用于解决城市信号交叉口拥堵问题。&lt;h4&gt;背景&lt;/h4&gt;城市信号交叉口的拥堵导致重大延误、经济损失和排放增加。现有的深度学习模型通常缺乏空间泛化能力，依赖于复杂的架构，并且难以实时部署。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有模型的局限性，提出一种能够动态、方向感知地建模和评估城市走廊交通的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了时间卷积网络和注意力图神经网络，能够估计交叉口和走廊层面的关键有效性指标（MOEs），如排队长度、等待时间、交通量和旅行时间。&lt;h4&gt;主要发现&lt;/h4&gt;TGDT模型能够准确产生高维、并发多输出估计，优于现有的基准模型。它在不同的交通条件下表现出高鲁棒性和准确性，包括极端情况，且仅依赖于最小数量的交通特征。&lt;h4&gt;结论&lt;/h4&gt;TGDT是一种成本效益高、可解释和实时的解决方案，可以快速模拟大量场景，为交通信号优化提供支持。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: We propose the TemporalGraph-based Digital Twin (TGDT) framework to address the issue of urban congestion at signalized intersections. This framework combines Temporal Convolutional Networks and Attentional Graph Neural Networks to dynamically and directionally model traffic on urban corridors, and estimates key Measures of Effectiveness (MOEs) for traffic flow optimization at both intersection and corridor levels. TGDT demonstrates high robustness and accuracy across diverse traffic conditions, and is a cost-effective, interpretable, and real-time solution for traffic signal optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban congestion at signalized intersections leads to significant delays,economic losses, and increased emissions. Existing deep learning models oftenlack spatial generalizability, rely on complex architectures, and struggle withreal-time deployment. To address these limitations, we propose the TemporalGraph-based Digital Twin (TGDT), a scalable framework that integrates TemporalConvolutional Networks and Attentional Graph Neural Networks for dynamic,direction-aware traffic modeling and assessment at urban corridors. TGDTestimates key Measures of Effectiveness (MOEs) for traffic flow optimization atboth the intersection level (e.g., queue length, waiting time) and the corridorlevel (e.g., traffic volume, travel time). Its modular architecture andsequential optimization scheme enable easy extension to any number ofintersections and MOEs. The model outperforms state-of-the-art baselines byaccurately producing high-dimensional, concurrent multi-output estimates. Italso demonstrates high robustness and accuracy across diverse trafficconditions, including extreme scenarios, while relying on only a minimal set oftraffic features. Fully parallelized, TGDT can simulate over a thousandscenarios within a matter of seconds, offering a cost-effective, interpretable,and real-time solution for traffic signal optimization.</description>
      <author>example@mail.com (Nooshin Yousefzadeh, Rahul Sengupta, Sanjay Ranka)</author>
      <guid isPermaLink="false">2504.18008v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Direct and Indirect Learning for Safe Control of Linear Systems</title>
      <link>http://arxiv.org/abs/2504.18331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2502.04195&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文旨在学习不确定离散时间线性系统在扰动下的安全控制器，同时实现两个关键目标：1)整合不同来源的信息（即物理知识的先验信息和流数据的后验信息），2)统一直接学习和间接学习。&lt;h4&gt;背景&lt;/h4&gt;研究不确定离散时间线性系统在扰动下的控制器设计。&lt;h4&gt;目的&lt;/h4&gt;学习安全控制器，并实现信息整合和学习方法的统一。&lt;h4&gt;方法&lt;/h4&gt;1)利用矩阵区群表示闭环系统，并通过数据对其进行特征化。2)通过添加等式一致性约束，将数据得到的矩阵区群转化为约束矩阵区群，并利用先验知识进行细化。3)利用基于区群的系统识别方法，从不同数据源中进行迁移学习。4)直接学习控制器，通过多边形和区群安全集来实现闭环系统的鲁棒安全性。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种结合先验知识和数据驱动的约束矩阵区群形式的闭环系统表示方法，并开发了一种针对多边形安全集的原对偶优化方法，以实现闭环系统的安全。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地实现闭环系统的安全控制，并支持信息整合和在线数据适应。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在学习不确定离散时间线性系统在扰动下的安全控制器，在实现以下两个关键目标的同时：1)整合不同来源的信息（即基于物理知识的先验信息和基于流数据的后验信息），2)统一直接学习与间接学习。这些目标通过表示与先验知识一致的参数化数据驱动的约束矩阵区群闭环系统而实现。为此，首先利用收集的数据通过矩阵区群来表征闭环系统，并展示通过添加等式一致性约束，可以使用先验知识的形式化地解释这些闭环系统，从而将数据得到的矩阵区群细化为约束矩阵区群。进一步地，通过使其与从基于区群的系统识别中获得的一组模型相一致来细化先验知识。用于基于区群的系统识别的数据源可以不同于用于闭环表示的数据源，从而允许进行迁移学习和在线新数据适应。然后利用参数化的闭环系统集直接学习一个鲁棒地对闭环系统施加安全性的控制器。考虑了多边形和区群安全集，并使用线性规划提供了集包含条件，以通过λ-收缩性实现安全性。对于多边形安全集，开发了一种原对偶优化来形式化线性规划优化，以证明集合包含。对于区群安全集，形成了所有下一个状态的有约束区群集，并通过确保该约束区群包含在安全集的λ缩放水平集中来实现集合包含。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims to learn safe controllers for uncertain discrete-time linearsystems under disturbances while achieving the following two crucial goals: 1)integration of different sources of information (i.e., prior information interms of physical knowledge and posterior information in terms of streamingdata), and 2) unifying direct learning with indirect learning. These goals areachieved by representing a parametrized data-driven constrained matrix zonotopeform of closed-loop systems that is conformant to prior knowledge. To this end,we first leverage collected data to characterize closed-loop systems by amatrix zonotope and then show that the explainability of these closed-loopsystems by prior knowledge can be formalized by adding an equality conformityconstraint, which refines the matrix zonotope obtained by data to a constrainedmatrix zonotope. The prior knowledge is further refined by conforming it to theset of models obtained from a novel zonotope-based system identifier. Thesource of data used for zonotope-based system identification can be differentthan the one used for closed-loop representation, allowing to perform transferlearning and online adaptation to new data. The parametrized closed-loop set ofsystems is then leveraged to directly learn a controller that robustly imposessafety on the closed-loop system. We consider both polytope and zonotope safesets and provide set inclusion conditions using linear programming to imposesafety through {\lambda}-contractivity. For polytope safe sets, a primal-dualoptimization is developed to formalize a linear programming optimization thatcertifies the set inclusion. For zonotope safe sets, the constrained zonotopeset of all next states is formed, and set inclusion is achieved by ensuring theinclusion of this constrained zonotope in a {\lambda}-scaled level set of thesafe set.</description>
      <author>example@mail.com (Amir Modares, Niyousha Ghiasi, Bahare Kiumarsi, Hamidreza Modares)</author>
      <guid isPermaLink="false">2504.18331v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Affordance Detection on 3D Point Clouds with Probabilistic Prototypes</title>
      <link>http://arxiv.org/abs/2504.18355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于原型学习的方法，用于3D点云上的可及性检测，旨在提高人机交互中的信任和安全。&lt;h4&gt;背景&lt;/h4&gt;机器人需要理解如何与环境中的物体进行交互，无论是自主操作还是与人类交互。传统的可及性检测依赖于深学习模型，如PointNet++、DGCNN或PointTransformerV3，但这些模型作为黑盒模型，缺乏决策过程的洞察。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的原型学习方法，以替代黑盒模型，并在3D点云的可及性检测中应用。&lt;h4&gt;方法&lt;/h4&gt;将原型学习方法应用于3D点云的可及性检测模型，并在3D-AffordanceNet基准数据集上进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;原型模型在3D-AffordanceNet数据集上实现了与最先进黑盒模型相当的性能，并提供了内在的可解释性。&lt;h4&gt;结论&lt;/h4&gt;原型模型在需要增加信任和安全的场景中，如人机交互，是一个有希望的候选方案。&lt;h4&gt;翻译&lt;/h4&gt;This abstract discusses the application of prototypical learning to affordance detection on 3D point clouds, aiming to enhance trust and safety in human-robot interaction scenarios. Traditional methods rely on deep learning models, which are black boxes and lack interpretability. The proposed prototypical models achieve competitive performance on a benchmark dataset and offer inherent interpretability, making them a promising candidate for human-robot interaction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic agents need to understand how to interact with objects in theirenvironment, both autonomously and during human-robot interactions. Affordancedetection on 3D point clouds, which identifies object regions that allowspecific interactions, has traditionally relied on deep learning models likePointNet++, DGCNN, or PointTransformerV3. However, these models operate asblack boxes, offering no insight into their decision-making processes.Prototypical Learning methods, such as ProtoPNet, provide an interpretablealternative to black-box models by employing a "this looks like that"case-based reasoning approach. However, they have been primarily applied toimage-based tasks. In this work, we apply prototypical learning to models foraffordance detection on 3D point clouds. Experiments on the 3D-AffordanceNetbenchmark dataset show that prototypical models achieve competitive performancewith state-of-the-art black-box models and offer inherent interpretability.This makes prototypical models a promising candidate for human-robotinteraction scenarios that require increased trust and safety.</description>
      <author>example@mail.com (Maximilian Xiling Li, Korbinian Rudolf, Nils Blank, Rudolf Lioutikov)</author>
      <guid isPermaLink="false">2504.18355v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>STP4D: Spatio-Temporal-Prompt Consistent Modeling for Text-to-4D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.18318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STP4D是一个用于高质量文本到4D生成的创新方法，通过集成空间-时间-提示一致性建模来解决现有方法中存在的问题。&lt;h4&gt;背景&lt;/h4&gt;文本到4D生成技术在各种场景中得到广泛应用，但现有方法往往缺乏统一框架内的充分空间-时间建模和提示对齐，导致时间不一致、几何扭曲或低质量4D内容。&lt;h4&gt;目的&lt;/h4&gt;提出STP4D，旨在整合空间-时间-提示一致性建模，以实现高质量的文本到4D生成。&lt;h4&gt;方法&lt;/h4&gt;STP4D采用三个精心设计的模块：时变提示嵌入、几何信息增强和时态扩展变形，共同实现目标。同时，STP4D是首批利用扩散模型生成4D高斯的方法之一，结合了4DGS的细粒度建模能力和实时渲染过程与扩散模型的快速推理速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，STP4D在生成高保真4D内容方面表现出色，效率极高（每资产大约4.6秒），在质量和速度上都优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;STP4D是文本到4D生成领域的一项重大进步，为该领域提供了高效、高质量的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-4D generation is rapidly developing and widely applied in variousscenarios. However, existing methods often fail to incorporate adequatespatio-temporal modeling and prompt alignment within a unified framework,resulting in temporal inconsistencies, geometric distortions, or low-quality 4Dcontent that deviates from the provided texts. Therefore, we propose STP4D, anovel approach that aims to integrate comprehensive spatio-temporal-promptconsistency modeling for high-quality text-to-4D generation. Specifically,STP4D employs three carefully designed modules: Time-varying Prompt Embedding,Geometric Information Enhancement, and Temporal Extension Deformation, whichcollaborate to accomplish this goal. Furthermore, STP4D is among the firstmethods to exploit the Diffusion model to generate 4D Gaussians, combining thefine-grained modeling capabilities and the real-time rendering process of 4DGSwith the rapid inference speed of the Diffusion model. Extensive experimentsdemonstrate that STP4D excels in generating high-fidelity 4D content withexceptional efficiency (approximately 4.6s per asset), surpassing existingmethods in both quality and speed.</description>
      <author>example@mail.com (Yunze Deng, Haijun Xiong, Bin Feng, Xinggang Wang, Wenyu Liu)</author>
      <guid isPermaLink="false">2504.18318v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>LaRI: Layered Ray Intersections for Single-view 3D Geometric Reasoning</title>
      <link>http://arxiv.org/abs/2504.18424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://ruili3.github.io/lari&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为分层光线交点（LaRI）的新方法，用于从单张图像中进行未见几何推理。&lt;h4&gt;背景&lt;/h4&gt;传统的深度估计方法仅限于可见表面，而LaRI通过使用分层点图来模拟被相机光线交错的多个表面。&lt;h4&gt;目的&lt;/h4&gt;LaRI旨在通过分层表示和高效推理，实现物体和场景级别的任务统一。&lt;h4&gt;方法&lt;/h4&gt;LaRI提出预测光线停止索引，以从其输出中识别有效的交点和层。此外，还建立了一个完整的训练数据生成流程，包括合成和真实世界数据，包括3D物体和场景，并进行了必要的数据清理和渲染引擎之间的协调。&lt;h4&gt;主要发现&lt;/h4&gt;LaRI在两个场景中验证了其性能：使用4%的训练数据和17%的参数，其物体级别结果与最近的大型生成模型相当。同时，它在仅一次前馈中实现了场景级别的遮挡几何推理。&lt;h4&gt;结论&lt;/h4&gt;LaRI是一种通用的方法，在物体和场景级别的几何推理方面表现良好，具有高效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present layered ray intersections (LaRI), a new method for unseen geometryreasoning from a single image. Unlike conventional depth estimation that islimited to the visible surface, LaRI models multiple surfaces intersected bythe camera rays using layered point maps. Benefiting from the compact andlayered representation, LaRI enables complete, efficient, and view-alignedgeometric reasoning to unify object- and scene-level tasks. We further proposeto predict the ray stopping index, which identifies valid intersecting pixelsand layers from LaRI's output. We build a complete training data generationpipeline for synthetic and real-world data, including 3D objects and scenes,with necessary data cleaning steps and coordination between rendering engines.As a generic method, LaRI's performance is validated in two scenarios: Ityields comparable object-level results to the recent large generative modelusing 4% of its training data and 17% of its parameters. Meanwhile, it achievesscene-level occluded geometry reasoning in only one feed-forward.</description>
      <author>example@mail.com (Rui Li, Biao Zhang, Zhenyu Li, Federico Tombari, Peter Wonka)</author>
      <guid isPermaLink="false">2504.18424v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset</title>
      <link>http://arxiv.org/abs/2504.17371v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DeepScenario Open 3D Dataset（DSC3D），一个高质量的、无遮挡的3D轨迹数据集，用于推进自动驾驶技术的发展。&lt;h4&gt;背景&lt;/h4&gt;传统的3D轨迹数据集通常由固定在车辆上的传感器捕获，容易受到遮挡，且只能精确地重建测量车辆附近动态环境，忽略了更远处的物体。&lt;h4&gt;目的&lt;/h4&gt;通过提供详细的3D环境表示，提高自动驾驶系统的障碍物交互和安全性能。&lt;h4&gt;方法&lt;/h4&gt;使用一种新型的单目相机无人机跟踪流程，收集了超过175,000条14种交通参与者的轨迹数据，数据集包括停车场的场景、拥挤的城市街道、陡峭的城市交叉口、联邦公路和郊区的交叉口等。&lt;h4&gt;主要发现&lt;/h4&gt;DSC3D数据集在多样性和规模上显著超过了现有数据集，包括许多前所未有的场景，如高度人口密集的城市街道上的复杂车辆-行人交互和从入口到出口的全面停车操作。&lt;h4&gt;结论&lt;/h4&gt;DSC3D数据集对多个应用有用，包括运动预测、运动规划、场景挖掘和生成式反应式交通代理。数据集和在线可视化平台公开可用，促进了运动预测、行为建模和安全验证的研究。&lt;h4&gt;翻译&lt;/h4&gt;Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at https://app.deepscenario.com, facilitating research in motion prediction, behavior modeling, and safety validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,traditional datasets are usually captured by fixed sensors mounted on a car andare susceptible to occlusion. Additionally, such an approach can preciselyreconstruct the dynamic environment in the close vicinity of the measurementvehicle only, while neglecting objects that are further away. In this paper, weintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,occlusion-free dataset of 6 degrees of freedom bounding box trajectoriesacquired through a novel monocular camera drone tracking pipeline. Our datasetincludes more than 175,000 trajectories of 14 types of traffic participants andsignificantly exceeds existing datasets in terms of diversity and scale,containing many unprecedented scenarios such as complex vehicle-pedestrianinteraction on highly populated urban streets and comprehensive parkingmaneuvers from entry to exit. DSC3D dataset was captured in five variouslocations in Europe and the United States and include: a parking lot, a crowdedinner-city, a steep urban intersection, a federal highway, and a suburbanintersection. Our 3D trajectory dataset aims to enhance autonomous drivingsystems by providing detailed environmental 3D representations, which couldlead to improved obstacle interactions and safety. We demonstrate its utilityacross multiple applications including motion prediction, motion planning,scenario mining, and generative reactive traffic agents. Our interactive onlinevisualization platform and the complete dataset are publicly available athttps://app.deepscenario.com, facilitating research in motion prediction,behavior modeling, and safety validation.</description>
      <author>example@mail.com (Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan, Holger Banzhaf, Daniel Cremers)</author>
      <guid isPermaLink="false">2504.17371v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Capability for Imitation Learning</title>
      <link>http://arxiv.org/abs/2504.18538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从信息论和数据分布性质出发，对模仿学习中的泛化能力进行了统一的理论分析。&lt;h4&gt;背景&lt;/h4&gt;模仿学习通过学习专家的演示来赋予机器人灵活的技能，但基于有限数据集训练的策略在超出训练分布的泛化上存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高模仿学习的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于信息论和数据分布性质的理论视角，通过分析条件信息瓶颈和模型参数与训练数据集之间的互信息来界定泛化差距。&lt;h4&gt;主要发现&lt;/h4&gt;1. 泛化差距可以通过中间表示的条件信息瓶颈和模型参数与训练数据集之间的互信息来界定。2. 输入到输出的高条件熵会使得似然度景观更平坦，从而减少泛化差距的上界。3. 高条件熵还能缩短随机梯度下降（SGD）从尖锐局部最小值逃逸的时间，提高在固定优化预算下达到全局优化的可能性。&lt;h4&gt;结论&lt;/h4&gt;这些发现解释了为什么模仿学习通常泛化能力有限，并强调了不仅需要扩展输入数据的多样性，还需要丰富同一输入条件下的输出标签的变异性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模仿学习有希望通过学习专家演示来赋予机器人多样化的技能。然而，在有限数据集上训练的策略往往难以泛化到训练分布之外。在这项工作中，我们提出了对模仿学习泛化能力的一个统一视角，该视角建立在信息论和数据分布性质的基础上。我们首先表明，泛化差距可以通过（i）中间表示的条件信息瓶颈和（ii）模型参数与训练数据集之间的互信息来上界。这种特征化提供了在模仿学习中设计有效训练策略的理论指导，特别是在确定是否冻结、微调或从头开始训练大型预训练编码器（例如视觉-语言模型或视觉基础模型）以实现更好的泛化方面。此外，我们表明，从输入到输出的高条件熵会诱导一个更平的似然度景观，从而降低泛化差距的上界。此外，它缩短了随机梯度下降（SGD）从尖锐局部最小值逃逸的时间，这可能会在固定的优化预算下增加达到全局优化的可能性。这些见解解释了为什么模仿学习经常表现出有限的泛化能力，并强调了不仅需要扩展输入数据的多样性，还需要丰富同一输入条件下的输出标签的变异性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning holds the promise of equipping robots with versatileskills by learning from expert demonstrations. However, policies trained onfinite datasets often struggle to generalize beyond the training distribution.In this work, we present a unified perspective on the generalization capabilityof imitation learning, grounded in both information theorey and datadistribution property. We first show that the generalization gap can be upperbounded by (i) the conditional information bottleneck on intermediaterepresentations and (ii) the mutual information between the model parametersand the training dataset. This characterization provides theoretical guidancefor designing effective training strategies in imitation learning, particularlyin determining whether to freeze, fine-tune, or train large pretrained encoders(e.g., vision-language models or vision foundation models) from scratch toachieve better generalization. Furthermore, we demonstrate that highconditional entropy from input to output induces a flatter likelihoodlandscape, thereby reducing the upper bound on the generalization gap. Inaddition, it shortens the stochastic gradient descent (SGD) escape time fromsharp local minima, which may increase the likelihood of reaching global optimaunder fixed optimization budgets. These insights explain why imitation learningoften exhibits limited generalization and underscore the importance of not onlyscaling the diversity of input data but also enriching the variability ofoutput labels conditioned on the same input.</description>
      <author>example@mail.com (Yixiao Wang)</author>
      <guid isPermaLink="false">2504.18538v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Guarantees for Multi-View Representation Learning and Application to Regularization via Gaussian Product Mixture Prior</title>
      <link>http://arxiv.org/abs/2504.18455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2502.15540&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式多视角表示学习问题，探讨了在没有明确协调的情况下，每个代理应从其视角中提取哪些信息以实现正确估计。&lt;h4&gt;背景&lt;/h4&gt;分布式多视角表示学习问题涉及多个代理各自观察不同的视角并独立提取表示，然后解码器使用这些表示来估计隐藏标签。&lt;h4&gt;目的&lt;/h4&gt;从泛化误差的角度研究如何让每个代理提取必要且足够的信息以实现正确估计。&lt;h4&gt;方法&lt;/h4&gt;建立了基于相对熵（表示提取分布与对称先验，即所有视角和训练测试数据集的潜在变量的最小描述长度）的泛化界限，并利用这些界限设计正则化器，深入研究选择合适先验的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于数据依赖的高斯混合先验和精心选择的权重可以带来良好的性能；对于单视角设置，实验结果优于现有的先验艺术变分信息瓶颈（VIB）和类别依赖VIB（CDVIB）方法；在多视角设置中，选择联合先验为高斯乘积混合导致每个边际视角的高斯混合边缘先验，并隐式鼓励代理提取和输出冗余特征。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在分布式多视角表示学习方面取得了良好的性能，并揭示了新的发现，如加权注意力机制和冗余特征提取的鼓励。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of distributed multi-view representation learning. Inthis problem, $K$ agents observe each one distinct, possibly statisticallycorrelated, view and independently extracts from it a suitable representationin a manner that a decoder that gets all $K$ representations estimatescorrectly the hidden label. In the absence of any explicit coordination betweenthe agents, a central question is: what should each agent extract from its viewthat is necessary and sufficient for a correct estimation at the decoder? Inthis paper, we investigate this question from a generalization errorperspective. First, we establish several generalization bounds in terms of therelative entropy between the distribution of the representations extracted fromtraining and "test" datasets and a data-dependent symmetric prior, i.e., theMinimum Description Length (MDL) of the latent variables for all views andtraining and test datasets. Then, we use the obtained bounds to devise aregularizer; and investigate in depth the question of the selection of asuitable prior. In particular, we show and conduct experiments that illustratethat our data-dependent Gaussian mixture priors with judiciously chosen weightslead to good performance. For single-view settings (i.e., $K=1$), ourexperimental results are shown to outperform existing prior art VariationalInformation Bottleneck (VIB) and Category-Dependent VIB (CDVIB) approaches.Interestingly, we show that a weighted attention mechanism emerges naturally inthis setting. Finally, for the multi-view setting, we show that the selectionof the joint prior as a Gaussians product mixture induces a Gaussian mixturemarginal prior for each marginal view and implicitly encourages the agents toextract and output redundant features, a finding which is somewhatcounter-intuitive.</description>
      <author>example@mail.com (Milad Sefidgaran, Abdellatif Zaidi, Piotr Krasnowski)</author>
      <guid isPermaLink="false">2504.18455v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Post-Transfer Learning Statistical Inference in High-Dimensional Regression</title>
      <link>http://arxiv.org/abs/2504.18212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PTL-SI（后迁移学习统计推断）的新统计推断框架，用于评估迁移学习高维回归（TL-HDR）中特征选择的可靠性。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在高维回归任务中非常重要，尤其是在目标任务样本量有限的情况下。然而，目前缺乏一种方法来量化TL-HDR设置中特征与响应之间的关系统计显著性。&lt;h4&gt;目的&lt;/h4&gt;目的是提供一个统计推断框架，用于在TL-HDR环境中评估特征选择的可靠性，并提供有效的p值来控制假阳性率。&lt;h4&gt;方法&lt;/h4&gt;PTL-SI框架能够为TL-HDR中选定的特征提供有效的p值，并通过结合战略性的分而治之方法来增强统计功效。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成和真实世界的高维数据集上进行广泛实验，验证了PTL-SI的有效性和实用性，并确认了其在测试迁移学习场景中特征选择可靠性方面的理论特性和效用。&lt;h4&gt;结论&lt;/h4&gt;PTL-SI是一种有效的工具，可以用于迁移学习高维回归中特征选择的可靠性评估，有助于提高模型性能和降低错误率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning (TL) for high-dimensional regression (HDR) is an importantproblem in machine learning, particularly when dealing with limited sample sizein the target task. However, there currently lacks a method to quantify thestatistical significance of the relationship between features and the responsein TL-HDR settings. In this paper, we introduce a novel statistical inferenceframework for assessing the reliability of feature selection in TL-HDR, calledPTL-SI (Post-TL Statistical Inference). The core contribution of PTL-SI is itsability to provide valid $p$-values to features selected in TL-HDR, therebyrigorously controlling the false positive rate (FPR) at desired significancelevel $\alpha$ (e.g., 0.05). Furthermore, we enhance statistical power byincorporating a strategic divide-and-conquer approach into our framework. Wedemonstrate the validity and effectiveness of the proposed PTL-SI throughextensive experiments on both synthetic and real-world high-dimensionaldatasets, confirming its theoretical properties and utility in testing thereliability of feature selection in TL scenarios.</description>
      <author>example@mail.com (Nguyen Vu Khai Tam, Cao Huyen My, Vo Nguyen Le Duy)</author>
      <guid isPermaLink="false">2504.18212v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ActionArt: Advancing Multimodal Large Models for Fine-Grained Human-Centric Video Understanding</title>
      <link>http://arxiv.org/abs/2504.18152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为ActionArt的细粒度视频描述数据集，旨在推进以人为本的多模态理解研究。&lt;h4&gt;背景&lt;/h4&gt;细粒度理解视频中的人类动作和姿态对于以人为本的AI应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出ActionArt数据集，以提升现有大型多模态模型在细粒度理解方面的能力。&lt;h4&gt;方法&lt;/h4&gt;数据集包含数千个视频，涵盖广泛的动作、人-物交互和场景，每个视频都有详细的标注，精确地标记了每个肢体的运动。开发了八个子任务来评估模型在不同维度上的细粒度理解能力。提出使用代理任务来增强模型在空间和时间维度上的感知能力，这些代理任务由自动生成数据驱动，以减少对昂贵的手动标注的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，尽管当前大型多模态模型在各项任务上表现良好，但它们在实现细粒度理解方面往往不足。这种限制归因于精心标注数据的稀缺性，这些数据既昂贵又难以手动扩展。&lt;h4&gt;结论&lt;/h4&gt;提出的代理任务显著缩小了与手动标注细粒度数据所达到的性能差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained understanding of human actions and poses in videos is essentialfor human-centric AI applications. In this work, we introduce ActionArt, afine-grained video-caption dataset designed to advance research inhuman-centric multimodal understanding. Our dataset comprises thousands ofvideos capturing a broad spectrum of human actions, human-object interactions,and diverse scenarios, each accompanied by detailed annotations thatmeticulously label every limb movement. We develop eight sub-tasks to evaluatethe fine-grained understanding capabilities of existing large multimodal modelsacross different dimensions. Experimental results indicate that, while currentlarge multimodal models perform commendably on various tasks, they often fallshort in achieving fine-grained understanding. We attribute this limitation tothe scarcity of meticulously annotated data, which is both costly and difficultto scale manually. Since manual annotations are costly and hard to scale, wepropose proxy tasks to enhance the model perception ability in both spatial andtemporal dimensions. These proxy tasks are carefully crafted to be driven bydata automatically generated from existing MLLMs, thereby reducing the relianceon costly manual labels. Experimental results show that the proposed proxytasks significantly narrow the gap toward the performance achieved withmanually annotated fine-grained data.</description>
      <author>example@mail.com (Yi-Xing Peng, Qize Yang, Yu-Ming Tang, Shenghao Fu, Kun-Yu Lin, Xihan Wei, Wei-Shi Zheng)</author>
      <guid isPermaLink="false">2504.18152v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation</title>
      <link>http://arxiv.org/abs/2504.18509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025. Project page and codes: https://eval3d.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Eval3D，一个用于评估3D生成数据质量的细粒度、可解释工具，它能够基于多种互补标准对生成的3D资产进行忠实评估。&lt;h4&gt;背景&lt;/h4&gt;尽管3D生成领域取得了前所未有的进展，但现有系统往往无法生成高质量且在多个视角下视觉吸引、几何和语义一致的3D资产。&lt;h4&gt;目的&lt;/h4&gt;为了有效评估生成3D数据的质量，需要一种可靠的3D评估工具。&lt;h4&gt;方法&lt;/h4&gt;Eval3D通过测量不同基础模型和工具之间的不一致性来捕捉3D生成中所需的属性，如语义和几何一致性，并利用多种模型和工具作为探针来评估生成3D资产在不同方面的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;Eval3D提供了像素级的测量，能够实现精确的3D空间反馈，并与人类判断更为接近。&lt;h4&gt;结论&lt;/h4&gt;使用Eval3D对现有的3D生成模型进行了全面评估，并突出了当前模型的局限性和挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在3D生成领域取得了前所未有的进步，但现有系统仍然常常无法生成高质量的3D资产，这些资产在视觉上吸引人，并且在多个视角下在几何和语义上保持一致。为了有效评估生成的3D数据的质量，需要一种可靠的3D评估工具。不幸的是，现有的3D评估指标往往忽略了生成资产的几何质量，或者仅仅依赖于黑盒多模态大型语言模型进行粗略评估。在本文中，我们介绍了Eval3D，这是一个细粒度、可解释的评估工具，可以根据各种不同但互补的标准忠实评估生成的3D资产的质量。我们的关键观察是，3D生成中许多期望的属性，如语义和几何一致性，可以通过测量各种基础模型和工具之间的一致性来有效地捕获。因此，我们利用多种模型和工具作为探针来评估生成的3D资产在不同方面的不一致性。与先前的工作相比，Eval3D提供了像素级的测量，实现了精确的3D空间反馈，并且与人类判断更为接近。我们使用Eval3D对现有的3D生成模型进行了全面评估，并突出了当前模型的局限性和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the unprecedented progress in the field of 3D generation, currentsystems still often fail to produce high-quality 3D assets that are visuallyappealing and geometrically and semantically consistent across multipleviewpoints. To effectively assess the quality of the generated 3D data, thereis a need for a reliable 3D evaluation tool. Unfortunately, existing 3Devaluation metrics often overlook the geometric quality of generated assets ormerely rely on black-box multimodal large language models for coarseassessment. In this paper, we introduce Eval3D, a fine-grained, interpretableevaluation tool that can faithfully evaluate the quality of generated 3D assetsbased on various distinct yet complementary criteria. Our key observation isthat many desired properties of 3D generation, such as semantic and geometricconsistency, can be effectively captured by measuring the consistency amongvarious foundation models and tools. We thus leverage a diverse set of modelsand tools as probes to evaluate the inconsistency of generated 3D assets acrossdifferent aspects. Compared to prior work, Eval3D provides pixel-wisemeasurement, enables accurate 3D spatial feedback, and aligns more closely withhuman judgments. We comprehensively evaluate existing 3D generation modelsusing Eval3D and highlight the limitations and challenges of current models.</description>
      <author>example@mail.com (Shivam Duggal, Yushi Hu, Oscar Michel, Aniruddha Kembhavi, William T. Freeman, Noah A. Smith, Ranjay Krishna, Antonio Torralba, Ali Farhadi, Wei-Chiu Ma)</author>
      <guid isPermaLink="false">2504.18509v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TimeSoccer的端到端足球多模态大型语言模型，用于对完整足球比赛视频进行密集视频字幕生成（SDVC）。该模型通过联合预测时间戳和生成字幕，以及引入MoFA-Select模块来增强对长视频内容的理解，实现了高质量字幕的生成。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的体育赛事，其评论生成需要精确的时间定位和丰富的语义描述。现有的足球多模态大型语言模型通常依赖于时间先验知识，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;解决现有足球多模态大型语言模型在时间定位和语义描述方面的不足，实现端到端的足球视频字幕生成。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer模型通过联合预测时间戳和生成字幕，实现全局上下文建模。同时，引入MoFA-Select模块，通过粗到细的策略自适应选择代表性帧，并采用补充训练范式来增强模型处理长时间序列的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进的性能，生成了具有准确时间对齐和强语义相关性的高质量字幕。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer是一种有效的足球视频字幕生成工具，能够提高足球比赛的评论质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology</title>
      <link>http://arxiv.org/abs/2504.18256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025, EarthVision workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自监督学习的生态遥感数据集SSL4Eco，用于解决全球生态研究中的数据稀缺和季节性问题。&lt;h4&gt;背景&lt;/h4&gt;生物多样性和气候变化加剧，全球生物多样性映射等宏观生态研究变得紧迫。遥感提供了丰富的地球观测数据，但标注数据集的稀缺是主要挑战。&lt;h4&gt;目的&lt;/h4&gt;为了更好地捕捉全球植被的季节性，提出了一种简单的基于物候的采样策略，并引入了SSL4Eco数据集。&lt;h4&gt;方法&lt;/h4&gt;使用多日期Sentinel-2数据集，通过季节对比目标训练现有模型，并在不同生态下游任务中比较从SSL4Eco学习到的表示。&lt;h4&gt;主要发现&lt;/h4&gt;简单采样方法能持续提高表示质量，强调数据集构建的重要性。在8个下游任务中，SSL4Eco预训练模型在7个任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SSL4Eco数据集有助于提升生态研究中的模型性能，并支持宏观生态和计算机视觉研究。&lt;h4&gt;翻译&lt;/h4&gt;With the exacerbation of the biodiversity and climate crises, macroecological pursuits such as global biodiversity mapping become more urgent. Remote sensing offers a wealth of Earth observation data for ecological studies, but the scarcity of labeled datasets remains a major challenge. Recently, self-supervised learning has enabled learning representations from unlabeled data, triggering the development of pretrained geospatial models with generalizable features. However, these models are often trained on datasets biased toward areas of high human activity, leaving entire ecological regions underrepresented. Additionally, while some datasets attempt to address seasonality through multi-date imagery, they typically follow calendar seasons rather than local phenological cycles. To better capture vegetation seasonality at a global scale, we propose a simple phenology-informed sampling strategy and introduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which we train an existing model with a season-contrastive objective. We compare representations learned from SSL4Eco against other datasets on diverse ecological downstream tasks and demonstrate that our straightforward sampling method consistently improves representation quality, highlighting the importance of dataset construction. The model pretrained on SSL4Eco reaches state of the art performance on 7 out of 8 downstream tasks spanning (multi-label) classification and regression. We release our code, data, and model weights to support macroecological and computer vision research at https://github.com/PlekhanovaElena/ssl4eco.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the exacerbation of the biodiversity and climate crises, macroecologicalpursuits such as global biodiversity mapping become more urgent. Remote sensingoffers a wealth of Earth observation data for ecological studies, but thescarcity of labeled datasets remains a major challenge. Recently,self-supervised learning has enabled learning representations from unlabeleddata, triggering the development of pretrained geospatial models withgeneralizable features. However, these models are often trained on datasetsbiased toward areas of high human activity, leaving entire ecological regionsunderrepresented. Additionally, while some datasets attempt to addressseasonality through multi-date imagery, they typically follow calendar seasonsrather than local phenological cycles. To better capture vegetation seasonalityat a global scale, we propose a simple phenology-informed sampling strategy andintroduce corresponding SSL4Eco, a multi-date Sentinel-2 dataset, on which wetrain an existing model with a season-contrastive objective. We comparerepresentations learned from SSL4Eco against other datasets on diverseecological downstream tasks and demonstrate that our straightforward samplingmethod consistently improves representation quality, highlighting theimportance of dataset construction. The model pretrained on SSL4Eco reachesstate of the art performance on 7 out of 8 downstream tasks spanning(multi-label) classification and regression. We release our code, data, andmodel weights to support macroecological and computer vision research athttps://github.com/PlekhanovaElena/ssl4eco.</description>
      <author>example@mail.com (Elena Plekhanova, Damien Robert, Johannes Dollinger, Emilia Arens, Philipp Brun, Jan Dirk Wegner, Niklaus Zimmermann)</author>
      <guid isPermaLink="false">2504.18256v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Kimi-Audio Technical Report</title>
      <link>http://arxiv.org/abs/2504.18425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Kimi-Audio，这是一个在音频理解、生成和对话方面表现卓越的开源音频基础模型。&lt;h4&gt;背景&lt;/h4&gt;Kimi-Audio是一个音频理解、生成和对话的模型。&lt;h4&gt;目的&lt;/h4&gt;详细描述了构建Kimi-Audio的过程，包括模型架构、数据整理、训练方案、推理部署和评估。&lt;h4&gt;方法&lt;/h4&gt;使用了12.5Hz音频标记器，设计了一种基于LLM的新型架构，以连续特征作为输入，以离散标记作为输出，并开发了基于流匹配的块级流解标记器。整理了一个包含超过1300万小时音频数据的预训练数据集，包括语音、声音和音乐等多种模态，并建立了一个管道来构建高质量的训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;Kimi-Audio在语音识别、音频理解、音频问答和语音对话等多个音频基准测试中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;发布了代码、模型检查点和评估工具包。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Kimi-Audio的开源音频基础模型，它在音频理解、生成和对话方面表现出色。我们详细介绍了构建Kimi-Audio的实践，包括模型架构、数据整理、训练方案、推理部署和评估。我们利用12.5Hz音频标记器，设计了一种基于LLM的新型架构，以连续特征作为输入，以离散标记作为输出，并开发了一种基于流匹配的块级流解标记器。我们整理了一个包含超过1300万小时音频数据的预训练数据集，包括语音、声音和音乐等多种模态，并建立了一个管道来构建高质量的训练数据。Kimi-Audio从预训练的LLM开始，在音频和文本数据上进行了连续预训练，并进行了精心设计的任务，然后进行了微调以支持各种音频相关任务。广泛的评估表明，Kimi-Audio在语音识别、音频理解、音频问答和语音对话等多个音频基准测试中达到了最先进的性能。我们在https://github.com/MoonshotAI/Kimi-Audio上发布了代码、模型检查点和评估工具包。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Kimi-Audio, an open-source audio foundation model that excels inaudio understanding, generation, and conversation. We detail the practices inbuilding Kimi-Audio, including model architecture, data curation, trainingrecipe, inference deployment, and evaluation. Specifically, we leverage a12.5Hz audio tokenizer, design a novel LLM-based architecture with continuousfeatures as input and discrete tokens as output, and develop a chunk-wisestreaming detokenizer based on flow matching. We curate a pre-training datasetthat consists of more than 13 million hours of audio data covering a wide rangeof modalities including speech, sound, and music, and build a pipeline toconstruct high-quality and diverse post-training data. Initialized from apre-trained LLM, Kimi-Audio is continual pre-trained on both audio and textdata with several carefully designed tasks, and then fine-tuned to support adiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audioachieves state-of-the-art performance on a range of audio benchmarks includingspeech recognition, audio understanding, audio question answering, and speechconversation. We release the codes, model checkpoints, as well as theevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.</description>
      <author>example@mail.com (KimiTeam, Ding Ding, Zeqian Ju, Yichong Leng, Songxiang Liu, Tong Liu, Zeyu Shang, Kai Shen, Wei Song, Xu Tan, Heyi Tang, Zhengtao Wang, Chu Wei, Yifei Xin, Xinran Xu, Jianwei Yu, Yutao Zhang, Xinyu Zhou, Y. Charles, Jun Chen, Yanru Chen, Yulun Du, Weiran He, Zhenxing Hu, Guokun Lai, Qingcheng Li, Yangyang Liu, Weidong Sun, Jianzhou Wang, Yuzhi Wang, Yuefeng Wu, Yuxin Wu, Dongchao Yang, Hao Yang, Ying Yang, Zhilin Yang, Aoxiong Yin, Ruibin Yuan, Yutong Zhang, Zaida Zhou)</author>
      <guid isPermaLink="false">2504.18425v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>A Model Zoo on Phase Transitions in Neural Networks</title>
      <link>http://arxiv.org/abs/2504.18072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用训练好的神经网络模型权重作为数据模态的研究领域——称为权重空间学习（WSL）。作者提出了一个新的方法，结合了模型动物园和相信息，以创造一个受控的多样性概念。他们创建了12个大型动物园，系统性地覆盖了已知的相和模型架构、大小和数据集，为WSL和更多应用提供了资源。&lt;h4&gt;背景&lt;/h4&gt;权重空间学习（WSL）是利用训练好的神经网络模型权重作为数据模态的研究领域，但现有的模型动物园结构不清晰，缺乏多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合模型动物园和相信息的方法，以创造一个受控的多样性概念，并为权重空间学习（WSL）和其他应用提供资源。&lt;h4&gt;方法&lt;/h4&gt;创建了12个大型动物园，系统性地覆盖了已知的相和模型架构、大小和数据集。为每个模型计算损失景观指标，并验证相的全覆盖。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个结合模型动物园和相信息的新方法，并创建了覆盖不同领域的动物园，如计算机视觉、自然语言处理和科学机器学习。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了广泛的资源，可能对模型训练、分析或稀疏化等应用中的损失景观相具有重要作用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用训练好的神经网络（NN）模型权重作为数据模态的研究领域——称为权重空间学习（WSL），最近已经成为一个研究领域。许多最近的研究提出了WSL方法来分析模型、评估方法或合成权重。权重空间学习方法需要训练好的模型群体作为开发和分析的数据集。然而，现有的模型集合——称为“模型动物园”——结构不清晰或遵循原始的多样性定义。与此同时，基于统计物理的研究已经确定了神经网络模型中的相和相变。在同一相中的模型是同质的，但彼此不同相的模型在质量上有所不同。我们将“模型动物园”的概念与相信息相结合，以创造一个受控的多样性概念。我们引入了12个大型动物园，系统地覆盖了已知的相以及模型架构、大小和数据集。这些数据集涵盖了不同的模态，如计算机视觉、自然语言处理和科学机器学习。对于每个模型，我们计算损失景观指标，并验证相的全覆盖。利用这个数据集，我们为社区提供了一个具有广泛潜在应用的资源，包括WSL以外的应用。证据表明，损失景观相在模型训练、分析或稀疏化等应用中起着作用。我们在下游方法（如迁移学习或模型权重平均）的探索性研究中证明了这一点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using the weights of trained Neural Network (NN) models as data modality hasrecently gained traction as a research field - dubbed Weight Space Learning(WSL). Multiple recent works propose WSL methods to analyze models, evaluatemethods, or synthesize weights. Weight space learning methods requirepopulations of trained models as datasets for development and evaluation.However, existing collections of models - called `model zoos' - areunstructured or follow a rudimentary definition of diversity. In parallel, workrooted in statistical physics has identified phases and phase transitions in NNmodels. Models are homogeneous within the same phase but qualitatively differfrom one phase to another. We combine the idea of `model zoos' with phaseinformation to create a controlled notion of diversity in populations. Weintroduce 12 large-scale zoos that systematically cover known phases and varyover model architecture, size, and datasets. These datasets cover differentmodalities, such as computer vision, natural language processing, andscientific ML. For every model, we compute loss landscape metrics and validatefull coverage of the phases. With this dataset, we provide the community with aresource with a wide range of potential applications for WSL and beyond.Evidence suggests the loss landscape phase plays a role in applications such asmodel training, analysis, or sparsification. We demonstrate this in anexploratory study of the downstream methods like transfer learning or modelweights averaging.</description>
      <author>example@mail.com (Konstantin Schürholt, Léo Meynent, Yefan Zhou, Haiquan Lu, Yaoqing Yang, Damian Borth)</author>
      <guid isPermaLink="false">2504.18072v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Label-independent hyperparameter-free self-supervised single-view deep subspace clustering</title>
      <link>http://arxiv.org/abs/2504.18179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages; 1 figure; 10 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对深度子空间聚类（DSC）算法的局限性，提出了一种新的单视图DSC方法。&lt;h4&gt;背景&lt;/h4&gt;DSC算法在实际应用中存在几个挑战，包括只使用编码器的输出层评估聚类质量、将表示学习和子空间聚类视为独立任务、假设存在用于超参数调整的保留数据集、训练终止基于聚类错误监控需要外部标签以及性能依赖于依赖标签数据的后处理技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的DSC方法，以解决上述局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：(i) 使用联合表示矩阵最小化分层自我表达损失；(ii) 优化子空间结构范数以增强聚类质量；(iii) 采用多阶段顺序学习框架，包括预训练和微调，允许使用多个正则化项而不需要超参数调整；(iv) 采用基于相对误差的自我停止机制，无需标签即可终止训练；(v) 根据先验知识保留学习表示矩阵中的前导系数。&lt;h4&gt;主要发现&lt;/h4&gt;在六个代表人脸、数字和物体的数据集上评估了该方法，结果表明该方法在性能上优于大多数线性SC算法，同时与最佳线性方法保持竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效解决DSC算法的局限性，并在实际应用中取得良好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep subspace clustering (DSC) algorithms face several challenges that hindertheir widespread adoption across variois application domains. First, clusteringquality is typically assessed using only the encoder's output layer,disregarding valuable information present in the intermediate layers. Second,most DSC approaches treat representation learning and subspace clustering asindependent tasks, limiting their effectiveness. Third, they assume theavailability of a held-out dataset for hyperparameter tuning, which is oftenimpractical in real-world scenarios. Fourth, learning termination is commonlybased on clustering error monitoring, requiring external labels. Finally, theirperformance often depends on post-processing techniques that rely on labeleddata. To address this limitations, we introduce a novel single-view DSCapproach that: (i) minimizes a layer-wise self expression loss using a jointrepresentation matrix; (ii) optimizes a subspace-structured norm to enhanceclustering quality; (iii) employs a multi-stage sequential learning framework,consisting of pre-training and fine-tuning, enabling the use of multipleregularization terms without hyperparameter tuning; (iv) incorporates arelative error-based self-stopping mechanism to terminate training withoutlabels; and (v) retains a fixed number of leading coefficients in the learnedrepresentation matrix based on prior knowledge. We evaluate the proposed methodon six datasets representing faces, digits, and objects. The results show thatour method outperforms most linear SC algorithms with careffulyl tunedhyperparameters while maintaining competitive performance with the bestperforming linear appoaches.</description>
      <author>example@mail.com (Lovro Sindicic, Ivica Kopriva)</author>
      <guid isPermaLink="false">2504.18179v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ShapeSpeak: Body Shape-Aware Textual Alignment for Visible-Infrared Person Re-Identification</title>
      <link>http://arxiv.org/abs/2504.18025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种Body Shape-aware Textual Alignment (BSaTa)框架，通过利用身体形状信息来提高VIReID的性能。&lt;h4&gt;背景&lt;/h4&gt;可见光和红外行人图像的匹配是一个挑战，因为模态差异和身份特征的复杂性。现有方法依赖于身份标签监督，难以提取高级语义信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法未显式建模身体形状特征的问题，提高跨模态匹配能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一个Body Shape Textual Alignment (BSTA)模块，使用人体解析模型提取身体形状信息，并通过CLIP将其转换为结构化文本表示。还设计了一个Text-Visual Consistency Regularizer (TVCR)来确保身体形状文本表示与视觉身体形状特征的对齐。此外，引入了一个Shape-aware Representation Learning (SRL)机制，结合多文本监督和分布一致性约束来指导视觉编码器学习模态不变和判别性身份特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在SYSU-MM01和RegDB数据集上实现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;验证了BSaTa框架在VIReID中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Visible-Infrared Person Re-identification (VIReID) aims to match visible and infrared pedestrian images, but the modality differences and the complexity of identity features make it challenging. Existing methods rely solely on identity label supervision, which makes it difficult to fully extract high-level semantic information. Recently, vision-language pre-trained models have been introduced to VIReID, enhancing semantic information modeling by generating textual descriptions. However, such methods do not explicitly model body shape features, which are crucial for cross-modal matching. To address this, we propose an effective Body Shape-aware Textual Alignment (BSaTa) framework that explicitly models and utilizes body shape information to improve VIReID performance. Specifically, we design a Body Shape Textual Alignment (BSTA) module that extracts body shape information using a human parsing model and converts it into structured text representations via CLIP. We also design a Text-Visual Consistency Regularizer (TVCR) to ensure alignment between body shape textual representations and visual body shape features. Furthermore, we introduce a Shape-aware Representation Learning (SRL) mechanism that combines Multi-text Supervision and Distribution Consistency Constraints to guide the visual encoder to learn modality-invariant and discriminative identity features, thus enhancing modality invariance. Experimental results demonstrate that our method achieves superior performance on the SYSU-MM01 and RegDB datasets, validating its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visible-Infrared Person Re-identification (VIReID) aims to match visible andinfrared pedestrian images, but the modality differences and the complexity ofidentity features make it challenging. Existing methods rely solely on identitylabel supervision, which makes it difficult to fully extract high-levelsemantic information. Recently, vision-language pre-trained models have beenintroduced to VIReID, enhancing semantic information modeling by generatingtextual descriptions. However, such methods do not explicitly model body shapefeatures, which are crucial for cross-modal matching. To address this, wepropose an effective Body Shape-aware Textual Alignment (BSaTa) framework thatexplicitly models and utilizes body shape information to improve VIReIDperformance. Specifically, we design a Body Shape Textual Alignment (BSTA)module that extracts body shape information using a human parsing model andconverts it into structured text representations via CLIP. We also design aText-Visual Consistency Regularizer (TVCR) to ensure alignment between bodyshape textual representations and visual body shape features. Furthermore, weintroduce a Shape-aware Representation Learning (SRL) mechanism that combinesMulti-text Supervision and Distribution Consistency Constraints to guide thevisual encoder to learn modality-invariant and discriminative identityfeatures, thus enhancing modality invariance. Experimental results demonstratethat our method achieves superior performance on the SYSU-MM01 and RegDBdatasets, validating its effectiveness.</description>
      <author>example@mail.com (Shuanglin Yan, Neng Dong, Shuang Li, Rui Yan, Hao Tang, Jing Qin)</author>
      <guid isPermaLink="false">2504.18025v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>VEU-Bench: Towards Comprehensive Understanding of Video Editing</title>
      <link>http://arxiv.org/abs/2504.17828v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VEU-Bench，一个用于视频编辑理解的综合基准，并提出了Oscars模型以提升Vid-LLMs在视频编辑理解任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;互联网上广泛共享的视频通常经过编辑，尽管Vid-LLMs在视频理解任务上取得了显著进展，但它们在视频编辑理解（VEU）任务上的能力尚未得到探索。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提出一个综合基准和模型，以提升Vid-LLMs在VEU任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;VEU-Bench将视频编辑组件按照帧内特征和帧间属性进行分类，并包含19个细粒度任务，分为识别、推理和判断三个阶段。为了自动增强VEU的标注，构建了一个与本体知识库集成的标注流程。通过使用11个最先进的Vid-LLMs进行实验，并开发了一个名为Oscars的VEU专家模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，当前的Vid-LLMs在VEU任务上面临重大挑战，某些模型的表现甚至不如随机选择。Oscars模型在VEU-Bench上的准确率比现有开源Vid-LLMs高出28.3%，且性能与商业模型如GPT-4o相当。VEU数据的引入显著提高了Vid-LLMs在一般视频理解基准上的性能，平均提升了8.3%。&lt;h4&gt;结论&lt;/h4&gt;VEU-Bench为VEU任务提供了一个全面的基准，Oscars模型有效地提升了Vid-LLMs在VEU任务上的性能，并为Vid-LLMs在视频理解任务上的应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：互联网上广泛共享的视频通常经过编辑。尽管Video Large Language Models (Vid-LLMs) 在一般视频理解任务上取得了巨大进步，但它们在视频编辑理解（VEU）任务上的能力仍然未被探索。为了解决这一差距，本文提出了VEU-Bench（视频编辑理解基准），这是一个全面基准，它从帧大小等帧内特征到剪辑类型和过渡等帧间属性等多个维度对视频编辑组件进行了分类。与主要关注编辑元素分类的先前视频编辑理解基准不同，VEU-Bench涵盖了三个阶段的19个细粒度任务：识别、推理和判断。为了自动增强VEU的标注，我们构建了一个与本体知识库集成的标注流程。通过使用11个最先进的Vid-LLMs进行的大量实验，我们发现当前的Vid-LLMs在VEU任务上面临重大挑战，一些模型的表现甚至不如随机选择。为了解决这个问题，我们开发了一个名为Oscars的VEU专家模型，它在VEU-Bench上的准确率比现有的开源Vid-LLMs高出28.3%，并且其性能与GPT-4o等商业模型相当。我们还证明，引入VEU数据显著提高了Vid-LLMs在一般视频理解基准上的性能，平均提高了8.3%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Widely shared videos on the internet are often edited. Recently, althoughVideo Large Language Models (Vid-LLMs) have made great progress in generalvideo understanding tasks, their capabilities in video editing understanding(VEU) tasks remain unexplored. To address this gap, in this paper, we introduceVEU-Bench (Video Editing Understanding Benchmark), a comprehensive benchmarkthat categorizes video editing components across various dimensions, fromintra-frame features like shot size to inter-shot attributes such as cut typesand transitions. Unlike previous video editing understanding benchmarks thatfocus mainly on editing element classification, VEU-Bench encompasses 19fine-grained tasks across three stages: recognition, reasoning, and judging. Toenhance the annotation of VEU automatically, we built an annotation pipelineintegrated with an ontology-based knowledge base. Through extensive experimentswith 11 state-of-the-art Vid-LLMs, our findings reveal that current Vid-LLMsface significant challenges in VEU tasks, with some performing worse thanrandom choice. To alleviate this issue, we develop Oscars, a VEU expert modelfine-tuned on the curated VEU-Bench dataset. It outperforms existingopen-source Vid-LLMs on VEU-Bench by over 28.3% in accuracy and achievesperformance comparable to commercial models like GPT-4o. We also demonstratethat incorporating VEU data significantly enhances the performance of Vid-LLMson general video understanding benchmarks, with an average improvement of 8.3%across nine reasoning tasks.</description>
      <author>example@mail.com (Bozheng Li, Yongliang Wu, Yi Lu, Jiashuo Yu, Licheng Tang, Jiawang Cao, Wenqing Zhu, Yuyang Sun, Jay Wu, Wenbo Zhu)</author>
      <guid isPermaLink="false">2504.17828v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>What is the Added Value of UDA in the VFM Era?</title>
      <link>http://arxiv.org/abs/2504.18190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了无监督领域自适应（UDA）在视觉基础模型（VFMs）中的应用，分析了其在不同数据场景下的表现，并讨论了UDA如何支持大规模的稳健自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;UDA可以从标记的源域改进感知模型的泛化能力到未标记的目标域。使用合成源数据的VFMs可以达到与使用真实目标数据的全监督学习相当的泛化性能。&lt;h4&gt;目的&lt;/h4&gt;研究UDA在更具代表性和多样性数据下的行为，以及仅使用源数据进行微调的VFMs在这些场景下的表现是否相同。&lt;h4&gt;方法&lt;/h4&gt;该研究关注语义分割作为代表性的感知任务，评估了UDA在合成到真实和真实到真实用例中的表现，并调查了在使用少量标记目标数据时UDA的效果。&lt;h4&gt;主要发现&lt;/h4&gt;使用更强的合成源数据时，UDA相对于仅源微调的VFMs的改进从+8 mIoU减少到+2 mIoU；使用更多样化的真实源数据时，UDA没有额外的价值；所有合成数据场景下的UDA泛化始终高于仅源微调；当只包含Cityscapes标签的1/16时，合成UDA获得与使用所有标签的全监督模型相同的85 mIoU分割质量。&lt;h4&gt;结论&lt;/h4&gt;UDA在某些情况下可以减少对大量标记数据的依赖，但并非总是提供额外的价值，且在更具现实性的场景下可能并不更具挑战性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Domain Adaptation (UDA) can improve a perception model'sgeneralization to an unlabeled target domain starting from a labeled sourcedomain. UDA using Vision Foundation Models (VFMs) with synthetic source datacan achieve generalization performance comparable to fully-supervised learningwith real target data. However, because VFMs have strong generalization fromtheir pre-training, more straightforward, source-only fine-tuning can alsoperform well on the target. As data scenarios used in academic research are notnecessarily representative for real-world applications, it is currently unclear(a) how UDA behaves with more representative and diverse data and (b) ifsource-only fine-tuning of VFMs can perform equally well in these scenarios.Our research aims to close these gaps and, similar to previous studies, wefocus on semantic segmentation as a representative perception task. We assessUDA for synth-to-real and real-to-real use cases with different source andtarget data combinations. We also investigate the effect of using a smallamount of labeled target data in UDA. We clarify that while these scenarios aremore realistic, they are not necessarily more challenging. Our results showthat, when using stronger synthetic source data, UDA's improvement oversource-only fine-tuning of VFMs reduces from +8 mIoU to +2 mIoU, and when usingmore diverse real source data, UDA has no added value. However, UDAgeneralization is always higher in all synthetic data scenarios thansource-only fine-tuning and, when including only 1/16 of Cityscapes labels,synthetic UDA obtains the same state-of-the-art segmentation quality of 85 mIoUas a fully-supervised model using all labels. Considering the mixed results, wediscuss how UDA can best support robust autonomous driving at scale.</description>
      <author>example@mail.com (Brunó B. Englert, Tommie Kerssies, Gijs Dubbelman)</author>
      <guid isPermaLink="false">2504.18190v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>FlexPINN: Modeling Fluid Dynamics and Mass Transfer in 3D Micromixer Geometries Using a Flexible Physics-Informed Neural Network</title>
      <link>http://arxiv.org/abs/2504.17896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用改进的物理信息神经网络（FlexPINN）研究了具有不同鳍形状和配置的3D T形微混器内的流体流动和浓度分布，分析了鳍几何形状和放置位置的影响。&lt;h4&gt;背景&lt;/h4&gt;研究使用了FlexPINN，这是对传统PINN架构的改进，以解决使用标准PINN模拟3D问题的挑战。&lt;h4&gt;目的&lt;/h4&gt;评估压力降系数、混合指数和混合效率，以FlexPINN方法为基础。&lt;h4&gt;方法&lt;/h4&gt;考虑了三种鳍形状（矩形、椭圆形和三角形）和四种鳍配置，在单单元（四个鳍）和双单元（八个鳍）配置下，以不同的雷诺数（5、20、40、80）进行模拟。&lt;h4&gt;主要发现&lt;/h4&gt;FlexPINN方法在预测压力降系数和混合指数时，与CFD结果相比，误差分别最大为3.25%和2.86%。在所有测试案例中，矩形鳍在双单元配置下的配置C在雷诺数40时显示出最高的混合效率，达到1.63。&lt;h4&gt;结论&lt;/h4&gt;FlexPINN框架在模拟复杂3D几何形状中的流体流动和物质传输方面表现出强大的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, fluid flow and concentration distribution inside a 3D T-shapedmicromixer with various fin shapes and configurations are investigated using aFlexible Physics-Informed Neural Network (FlexPINN), which includesmodifications over the vanilla PINN architecture. Three types of fins(rectangular, elliptical, and triangular) are considered to evaluate theinfluence of fin geometry, along with four different fin configurations insidethe 3D channel to examine the effect of placement. The simulations areconducted at four Reynolds numbers: 5, 20, 40, and 80, in both single-unit(four fins) and double-unit (eight fins) configurations. The goal is to assesspressure drop coefficient, mixing index, and mixing efficiency using theFlexPINN method. Given the challenges in simulating 3D problems with standardPINN, several improvements are introduced. The governing equations are injectedinto the network as first-order, dimensionless derivatives to enhance accuracy.Transfer learning is used to reduce computational cost, and adaptive lossweighting is applied to improve convergence compared to the vanilla PINNapproach. These modifications enable a consistent and flexible architecturethat can be used across numerous tested cases. Using the proposed FlexPINNmethod, the pressure drop coefficient and mixing index are predicted withmaximum errors of 3.25% and 2.86%, respectively, compared to ComputationalFluid Dynamics (CFD) results. Among all the tested cases, the rectangular finwith configuration C in the double-unit setup at Reynolds number 40 shows thehighest mixing efficiency, reaching a value of 1.63. The FlexPINN frameworkdemonstrates strong capabilities in simulating fluid flow and species transportin complex 3D geometries.</description>
      <author>example@mail.com (Meraj Hassanzadeh, Ehsan Ghaderi, Mohamad Ali Bijarchi)</author>
      <guid isPermaLink="false">2504.17896v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>L4P: Low-Level 4D Vision Perception Unified</title>
      <link>http://arxiv.org/abs/2502.13078v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为L4P的通用前馈架构，用于解决低级4D感知任务，该架构结合了预训练的ViT视频编码器和轻量级的任务头，能够在统一框架内解决多种任务，包括稠密任务（如深度或光流估计）和稀疏任务（如2D/3D跟踪）。&lt;h4&gt;背景&lt;/h4&gt;视频像素的空间时间关系对于低级4D感知任务至关重要，而大多数最先进的方法依赖于针对特定任务专门化的架构。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够解决多种低级4D感知任务的通用模型。&lt;h4&gt;方法&lt;/h4&gt;L4P架构利用预训练的ViT视频编码器，并结合轻量级的任务头，这些头轻量到不需要大量训练。&lt;h4&gt;主要发现&lt;/h4&gt;L4P在稠密和稀疏任务上均达到了或超过了现有专用方法的性能，并且能够在与单任务方法相当的时间内解决所有任务。&lt;h4&gt;结论&lt;/h4&gt;L4P是一种有效的通用架构，能够同时解决多种低级4D感知任务，且性能优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spatio-temporal relationship between the pixels of a video carriescritical information for low-level 4D perception tasks. A single model thatreasons about it should be able to solve several such tasks well. Yet, moststate-of-the-art methods rely on architectures specialized for the task athand. We present L4P, a feedforward, general-purpose architecture that solveslow-level 4D perception tasks in a unified framework. L4P leverages apre-trained ViT-based video encoder and combines it with per-task heads thatare lightweight and therefore do not require extensive training. Despite itsgeneral and feedforward formulation, our method matches or surpasses theperformance of existing specialized methods on both dense tasks, such as depthor optical flow estimation, and sparse tasks, such as 2D/3D tracking. Moreover,it solves all tasks at once in a time comparable to that of single-taskmethods.</description>
      <author>example@mail.com (Abhishek Badki, Hang Su, Bowen Wen, Orazio Gallo)</author>
      <guid isPermaLink="false">2502.13078v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Quadratic Interest Network for Multimodal Click-Through Rate Prediction</title>
      <link>http://arxiv.org/abs/2504.17699v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quadratic Interest Network (QIN)的新模型，用于多模态点击率预测，该模型在多模态CTR预测挑战中取得了优异成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态点击率预测是工业推荐系统中的关键技术，它通过利用文本、图像和行为日志等异构模态，捕捉用户与物品之间的高阶特征交互，从而增强系统对用户兴趣的理解和预测点击行为的能力。&lt;h4&gt;目的&lt;/h4&gt;为了促进这一领域的发展，WWW 2025 EReL@MIR Workshop的Multimodal CTR Prediction Challenge Track提出了两个任务：多模态物品嵌入和多模态CTR预测。&lt;h4&gt;方法&lt;/h4&gt;本文提出的QIN模型使用自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络捕获高阶特征交互。&lt;h4&gt;主要发现&lt;/h4&gt;QIN在挑战赛中的排行榜上取得了AUC 0.9798的成绩，排名第二。&lt;h4&gt;结论&lt;/h4&gt;QIN模型能够有效地利用多模态嵌入特征，实现更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal click-through rate (CTR) prediction is a key technique in industrial recommender systems. It leverages heterogeneous modalities such as text, images, and behavioral logs to capture high-order feature interactions between users and items, thereby enhancing the system's understanding of user interests and its ability to predict click behavior. The primary challenge in this field lies in effectively utilizing the rich semantic information from multiple modalities while satisfying the low-latency requirements of online inference in real-world applications. To foster progress in this area, the Multimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshop formulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding: this task aims to explore multimodal information extraction and item representation learning methods that enhance recommendation tasks; and (2) Task 2 of Multimodal CTR Prediction: this task aims to explore what multimodal recommendation model can effectively leverage multimodal embedding features and achieve better performance. In this paper, we propose a novel model for Task 2, named Quadratic Interest Network (QIN) for Multimodal CTR Prediction. Specifically, QIN employs adaptive sparse target attention to extract multimodal user behavior features, and leverages Quadratic Neural Networks to capture high-order feature interactions. As a result, QIN achieved an AUC of 0.9798 on the leaderboard and ranked second in the competition. The model code, training logs, hyperparameter configurations, and checkpoints are available at https://github.com/salmon1802/QIN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal click-through rate (CTR) prediction is a key technique inindustrial recommender systems. It leverages heterogeneous modalities such astext, images, and behavioral logs to capture high-order feature interactionsbetween users and items, thereby enhancing the system's understanding of userinterests and its ability to predict click behavior. The primary challenge inthis field lies in effectively utilizing the rich semantic information frommultiple modalities while satisfying the low-latency requirements of onlineinference in real-world applications. To foster progress in this area, theMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshopformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:this task aims to explore multimodal information extraction and itemrepresentation learning methods that enhance recommendation tasks; and (2) Task2 of Multimodal CTR Prediction: this task aims to explore what multimodalrecommendation model can effectively leverage multimodal embedding features andachieve better performance. In this paper, we propose a novel model for Task 2,named Quadratic Interest Network (QIN) for Multimodal CTR Prediction.Specifically, QIN employs adaptive sparse target attention to extractmultimodal user behavior features, and leverages Quadratic Neural Networks tocapture high-order feature interactions. As a result, QIN achieved an AUC of0.9798 on the leaderboard and ranked second in the competition. The model code,training logs, hyperparameter configurations, and checkpoints are available athttps://github.com/salmon1802/QIN.</description>
      <author>example@mail.com (Honghao Li, Hanwei Li, Jing Zhang, Yi Zhang, Ziniu Yu, Lei Sang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2504.17699v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization</title>
      <link>http://arxiv.org/abs/2504.18057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OCP的机会性协作规划方法，通过高效整合本地模型和云端模型，解决了自动驾驶车辆在开放场景中导航的挑战。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆在开放场景中导航面临处理未知物体的困难，现有解决方案要么依赖于小模型，难以泛化，要么依赖于大模型，资源消耗大。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以解决如何决定何时以及如何使用大模型的问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出大型视觉模型引导的模型预测控制（LVM-MPC），利用云端进行LVM感知和决策，云端输出作为本地MPC的全局指导，形成一个闭环的感知到控制系统。2. 提出协作时机优化（CTO），包括目标检测置信度阈值（ODCT）和云端前向模拟（CFS），以决定何时寻求云端帮助和何时提供云端服务。&lt;h4&gt;主要发现&lt;/h4&gt;OCP在导航时间和成功率方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;OCP方法通过高效整合本地和云端模型，提高了自动驾驶车辆在开放场景中的导航性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating autonomous vehicles in open scenarios is a challenge due to thedifficulties in handling unseen objects. Existing solutions either rely onsmall models that struggle with generalization or large models that areresource-intensive. While collaboration between the two offers a promisingsolution, the key challenge is deciding when and how to engage the large model.To address this issue, this paper proposes opportunistic collaborative planning(OCP), which seamlessly integrates efficient local models with powerful cloudmodels through two key innovations. First, we propose large vision model guidedmodel predictive control (LVM-MPC), which leverages the cloud for LVMperception and decision making. The cloud output serves as a global guidancefor a local MPC, thereby forming a closed-loop perception-to-control system.Second, to determine the best timing for large model query and service, wepropose collaboration timing optimization (CTO), including object detectionconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decidewhen to seek cloud assistance and when to offer cloud service. Extensiveexperiments show that the proposed OCP outperforms existing methods in terms ofboth navigation time and success rate.</description>
      <author>example@mail.com (Jiayi Chen, Shuai Wang, Guoliang Li, Wei Xu, Guangxu Zhu, Derrick Wing Kwan Ng, Chengzhong Xu)</author>
      <guid isPermaLink="false">2504.18057v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>On the workflow, opportunities and challenges of developing foundation model in geophysics</title>
      <link>http://arxiv.org/abs/2504.17384v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出一个完整的框架，系统探讨将基础模型与地球物理数据相结合的整个流程。&lt;h4&gt;背景&lt;/h4&gt;基础模型在人工智能领域成为主流技术，近年来在处理复杂任务和多种模态数据方面展现出巨大潜力。在地球物理学领域，尽管基础模型的应用逐渐扩展，但缺乏关于其与地球物理数据集成全流程的综合性综述。&lt;h4&gt;目的&lt;/h4&gt;填补地球物理学领域在基础模型全流程综述方面的空白，并为地球物理数据分析中的应用提供有价值的实践指导。&lt;h4&gt;方法&lt;/h4&gt;从数据收集和预处理到模型架构选择、预训练策略和模型部署，详细分析了每个阶段的关键技术和方法。特别讨论了针对地球物理数据多样性、复杂性和物理一致性约束的针对性解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用基础模型的迁移学习能力，减少对标记数据的依赖，提高计算效率，并将物理约束纳入模型训练，从而提高物理一致性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;本文不仅填补了地球物理学领域基础模型全流程综述的空白，还为该领域的技术创新和进步提供了宝贵的实践指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, as a mainstream technology in artificial intelligence,have demonstrated immense potential across various domains in recent years,particularly in handling complex tasks and multimodal data. In the field ofgeophysics, although the application of foundation models is graduallyexpanding, there is currently a lack of comprehensive reviews discussing thefull workflow of integrating foundation models with geophysical data. Toaddress this gap, this paper presents a complete framework that systematicallyexplores the entire process of developing foundation models in conjunction withgeophysical data. From data collection and preprocessing to model architectureselection, pre-training strategies, and model deployment, we provide a detailedanalysis of the key techniques and methodologies at each stage. In particular,considering the diversity, complexity, and physical consistency constraints ofgeophysical data, we discuss targeted solutions to address these challenges.Furthermore, we discuss how to leverage the transfer learning capabilities offoundation models to reduce reliance on labeled data, enhance computationalefficiency, and incorporate physical constraints into model training, therebyimproving physical consistency and interpretability. Through a comprehensivesummary and analysis of the current technological landscape, this paper notonly fills the gap in the geophysics domain regarding a full-process review offoundation models but also offers valuable practical guidance for theirapplication in geophysical data analysis, driving innovation and advancement inthe field.</description>
      <author>example@mail.com (Hanlin Sheng, Xinming Wu, Hang Gao, Haibin Di, Sergey Fomel, Jintao Li, Xu Si)</author>
      <guid isPermaLink="false">2504.17384v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Federated Client-tailored Adapter for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2504.18020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的联邦客户端定制适配器（FCA）框架，用于医学图像分割，该框架能够稳定且定制化地进行分割，而不需要共享敏感的本地数据。&lt;h4&gt;背景&lt;/h4&gt;现有的医学图像分割方法主要采用集中式学习范式，但在只有分布式数据岛屿的实际情况中不适用。联邦学习虽然具有分布式解决方案的潜力，但由于客户端域异质性（包括分布多样性和类别不平衡）而难以实现稳定的训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦客户端定制适配器（FCA）框架，用于医学图像分割，以实现稳定和客户端定制的自适应分割。&lt;h4&gt;方法&lt;/h4&gt;该框架通过在现成的医学基础模型中搅拌通用知识来稳定联邦训练过程。此外，开发了两种客户端定制的联邦更新策略，这些策略自适应地将适配器分解为公共和个体组件，然后分别全局和独立地更新与公共客户端不变和个体客户端特定单元相关的参数组。&lt;h4&gt;主要发现&lt;/h4&gt;FCA框架在三个大规模数据集上的广泛实验表明，该方法对于联邦医学分割是有效和优越的。&lt;h4&gt;结论&lt;/h4&gt;FCA框架能够实现稳定和客户端定制的医学图像分割，为联邦医学分割提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在X射线图像中进行医学图像分割对计算机辅助诊断和病变定位有益。现有方法主要属于集中式学习范式，这在只有访问分布式数据岛屿的实际医学场景中不适用。联邦学习有提供分布式解决方案的潜力，但由于客户端域异质性（包括分布多样性和类别不平衡）而难以实现稳定的训练。在本文中，我们提出了一种用于医学图像分割的新型联邦客户端定制适配器（FCA）框架，该框架在不共享敏感本地数据的情况下实现了稳定和客户端定制的自适应分割。具体来说，联邦适配器搅拌现成的医学基础模型中的通用知识，以稳定联邦训练过程。此外，我们开发了两种客户端定制的联邦更新策略，这些策略自适应地将适配器分解为公共和个体组件，然后分别全局和独立地更新与公共客户端不变和个体客户端特定单元相关的参数组。它们进一步稳定了异构联邦学习过程，并实现了最优的客户端定制而不是次优的全局妥协分割模型。在三个大规模数据集上的广泛实验证明了所提出的FCA框架对于联邦医学分割的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation in X-ray images is beneficial for computer-aideddiagnosis and lesion localization. Existing methods mainly fall into acentralized learning paradigm, which is inapplicable in the practical medicalscenario that only has access to distributed data islands. Federated Learninghas the potential to offer a distributed solution but struggles with heavytraining instability due to client-wise domain heterogeneity (includingdistribution diversity and class imbalance). In this paper, we propose a novelFederated Client-tailored Adapter (FCA) framework for medical imagesegmentation, which achieves stable and client-tailored adaptive segmentationwithout sharing sensitive local data. Specifically, the federated adapter stirsuniversal knowledge in off-the-shelf medical foundation models to stabilize thefederated training process. In addition, we develop two client-tailoredfederated updating strategies that adaptively decompose the adapter into commonand individual components, then globally and independently update the parametergroups associated with common client-invariant and individual client-specificunits, respectively. They further stabilize the heterogeneous federatedlearning process and realize optimal client-tailored instead of sub-optimalglobal-compromised segmentation models. Extensive experiments on threelarge-scale datasets demonstrate the effectiveness and superiority of theproposed FCA framework for federated medical segmentation.</description>
      <author>example@mail.com (Guyue Hu, Siyuan Song, Yukun Kang, Zhu Yin, Gangming Zhao, Chenglong Li, Jin Tang)</author>
      <guid isPermaLink="false">2504.18020v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation</title>
      <link>http://arxiv.org/abs/2504.18010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Sky-Drive是一个新型的分布式多智能体仿真平台，通过四个关键创新解决了现有仿真器的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管自主系统仿真平台在驾驶策略的安全和可扩展测试方面取得了进展，但现有仿真器尚未完全满足未来交通研究的需求。&lt;h4&gt;目的&lt;/h4&gt;Sky-Drive旨在解决建模具有社会意识驾驶代理和促进有效人机协作的挑战。&lt;h4&gt;方法&lt;/h4&gt;Sky-Drive的四个关键创新包括：分布式架构、多模态人机在环框架、人机协作机制和数字孪生框架。&lt;h4&gt;主要发现&lt;/h4&gt;Sky-Drive支持多种应用，如自动驾驶车辆与易受伤害道路使用者交互建模、人机在环训练、具有社会意识的强化学习、个性化驾驶策略和定制场景生成。&lt;h4&gt;结论&lt;/h4&gt;Sky-Drive有望成为下一代具有社会意识和以人为中心的自动驾驶交通研究的基础平台。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in autonomous system simulation platforms have significantly enhanced the safe and scalable testing of driving policies. However, existing simulators do not yet fully meet the needs of future transportation research, particularly in modeling socially-aware driving agents and enabling effective human-AI collaboration. This paper introduces Sky-Drive, a novel distributed multi-agent simulation platform that addresses these limitations through four key innovations: (a) a distributed architecture for synchronized simulation across multiple terminals; (b) a multi-modal human-in-the-loop framework integrating diverse sensors to collect rich behavioral data; (c) a human-AI collaboration mechanism supporting continuous and adaptive knowledge exchange; and (d) a digital twin (DT) framework for constructing high-fidelity virtual replicas of real-world transportation environments. Sky-Drive supports diverse applications such as autonomous vehicle (AV)-vulnerable road user (VRU) interaction modeling, human-in-the-loop training, socially-aware reinforcement learning, personalized driving policy, and customized scenario generation. Future extensions will incorporate foundation models for context-aware decision support and hardware-in-the-loop (HIL) testing for real-world validation. By bridging scenario generation, data collection, algorithm training, and hardware integration, Sky-Drive has the potential to become a foundational platform for the next generation of socially-aware and human-centered autonomous transportation research. The demo video and code are available at: https://sky-lab-uw.github.io/Sky-Drive-website/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in autonomous system simulation platforms have significantlyenhanced the safe and scalable testing of driving policies. However, existingsimulators do not yet fully meet the needs of future transportation research,particularly in modeling socially-aware driving agents and enabling effectivehuman-AI collaboration. This paper introduces Sky-Drive, a novel distributedmulti-agent simulation platform that addresses these limitations through fourkey innovations: (a) a distributed architecture for synchronized simulationacross multiple terminals; (b) a multi-modal human-in-the-loop frameworkintegrating diverse sensors to collect rich behavioral data; (c) a human-AIcollaboration mechanism supporting continuous and adaptive knowledge exchange;and (d) a digital twin (DT) framework for constructing high-fidelity virtualreplicas of real-world transportation environments. Sky-Drive supports diverseapplications such as autonomous vehicle (AV)-vulnerable road user (VRU)interaction modeling, human-in-the-loop training, socially-aware reinforcementlearning, personalized driving policy, and customized scenario generation.Future extensions will incorporate foundation models for context-aware decisionsupport and hardware-in-the-loop (HIL) testing for real-world validation. Bybridging scenario generation, data collection, algorithm training, and hardwareintegration, Sky-Drive has the potential to become a foundational platform forthe next generation of socially-aware and human-centered autonomoustransportation research. The demo video and code are availableat:https://sky-lab-uw.github.io/Sky-Drive-website/</description>
      <author>example@mail.com (Zilin Huang, Zihao Sheng, Zhengyang Wan, Yansong Qu, Yuhao Luo, Boyue Wang, Pei Li, Yen-Jung Chen, Jiancong Chen, Keke Long, Jiayi Meng, Yue Leng, Sikai Chen)</author>
      <guid isPermaLink="false">2504.18010v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Utility of Audio Foundation Models for Heart and Respiratory Sound Analysis</title>
      <link>http://arxiv.org/abs/2504.18004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 1 figure, and 4 tables. Accepted by IEEE EMBC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了现成的音频基础模型在呼吸和心脏声音任务中的实际有效性，通过比较其性能与最先进（SOTA）微调结果，发现模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能，并且通用音频模型优于呼吸声音模型，表明其更广泛的应用性。&lt;h4&gt;背景&lt;/h4&gt;预训练的深度学习模型，称为基础模型，已成为自然语言处理和图像领域机器学习的重要构建块，这一趋势扩展到了呼吸和心脏声音模型，它们作为现成的特征提取器已证明其有效性。&lt;h4&gt;目的&lt;/h4&gt;评估现成的音频基础模型在呼吸和心脏声音任务中的实际有效性。&lt;h4&gt;方法&lt;/h4&gt;通过比较这些模型在四个呼吸和心脏声音任务上的性能与SOTA微调结果来进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能。通用音频模型优于呼吸声音模型，显示了更广泛的应用性。&lt;h4&gt;结论&lt;/h4&gt;该研究通过实验结果和代码发布，为未来研究开发和使用基础模型进行呼吸和心脏声音分析做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预训练的深度学习模型，被称为基础模型，已成为机器学习领域，如自然语言处理和图像领域的必要构建块。这一趋势已经扩展到呼吸和心脏声音模型，这些模型作为现成的特征提取器已经证明其有效性。然而，它们的评估基准有限，导致与最先进（SOTA）性能的不兼容，从而阻碍了它们有效性的证明。本研究通过比较四个呼吸和心脏声音任务上的性能与SOTA微调结果，调查了现成音频基础模型的实际有效性。实验表明，模型在噪声数据任务上表现不佳，但在干净数据任务上达到了SOTA性能。此外，通用音频模型优于呼吸声音模型，突出了其更广泛的应用性。通过获得见解和发布的代码，我们为未来研究开发和利用基础模型进行呼吸和心脏声音分析做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained deep learning models, known as foundation models, have becomeessential building blocks in machine learning domains such as natural languageprocessing and image domains. This trend has extended to respiratory and heartsound models, which have demonstrated effectiveness as off-the-shelf featureextractors. However, their evaluation benchmarking has been limited, resultingin incompatibility with state-of-the-art (SOTA) performance, thus hinderingproof of their effectiveness. This study investigates the practicaleffectiveness of off-the-shelf audio foundation models by comparing theirperformance across four respiratory and heart sound tasks with SOTA fine-tuningresults. Experiments show that models struggled on two tasks with noisy databut achieved SOTA performance on the other tasks with clean data. Moreover,general-purpose audio models outperformed a respiratory sound model,highlighting their broader applicability. With gained insights and the releasedcode, we contribute to future research on developing and leveraging foundationmodels for respiratory and heart sounds.</description>
      <author>example@mail.com (Daisuke Niizumi, Daiki Takeuchi, Masahiro Yasuda, Binh Thien Nguyen, Yasunori Ohishi, Noboru Harada)</author>
      <guid isPermaLink="false">2504.18004v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Improving Significant Wave Height Prediction Using Chronos Models</title>
      <link>http://arxiv.org/abs/2504.16834v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2403.07815 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于大语言模型（LLM）的时间架构（Chronos），用于波高预测，通过历史波浪数据的时序模式识别，实现了多模态的改进。&lt;h4&gt;背景&lt;/h4&gt;精确的波高预测对航海安全和海岸韧性至关重要，但传统的物理模型和机器学习方法在计算效率和非线性动力学建模方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入Chronos，优化波高预测的计算效率，提高非线性动力学建模的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用大语言模型的时间架构（Chronos），利用历史波浪数据在西北太平洋三个选定的海洋区域进行时序模式识别。&lt;h4&gt;主要发现&lt;/h4&gt;（1）训练时间减少了14.3%，推理速度比PatchTST基准快2.5倍，实现了0.575的均方根误差（MASE）；（2）短期预测（1-24小时）在全面指标上表现优异；（3）在长期预测（1-120小时）中保持预测优势；（4）在没有额外训练的情况下，与专业操作模型相比，Chronos的平均性能达到第四名（12个模型中）。&lt;h4&gt;结论&lt;/h4&gt;LLM增强的时间建模范式在波高预测中建立了新的标准，提供了计算高效的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;h4&gt;翻译&lt;/h4&gt;Accurate wave height prediction is critical for maritime safety and coastal resilience, yet conventional physics-based models and traditional machine learning methods face challenges in computational efficiency and nonlinear dynamics modeling. This study introduces Chronos, the first implementation of a large language model (LLM)-powered temporal architecture (Chronos) optimized for wave forecasting. Through advanced temporal pattern recognition applied to historical wave data from three strategically chosen marine zones in the Northwest Pacific basin, our framework achieves multimodal improvements: (1) 14.3% reduction in training time with 2.5x faster inference speed compared to PatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units; (2) superior short-term forecasting (1-24h) across comprehensive metrics; (3) sustained predictive leadership in extended-range forecasts (1-120h); and (4) demonstrated zero-shot capability maintaining median performance (rank 4/12) against specialized operational models. This LLM-enhanced temporal modeling paradigm establishes a new standard in wave prediction, offering both computationally efficient solutions and a transferable framework for complex geophysical systems modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate wave height prediction is critical for maritime safety and coastalresilience, yet conventional physics-based models and traditional machinelearning methods face challenges in computational efficiency and nonlineardynamics modeling. This study introduces Chronos, the first implementation of alarge language model (LLM)-powered temporal architecture (Chronos) optimizedfor wave forecasting. Through advanced temporal pattern recognition applied tohistorical wave data from three strategically chosen marine zones in theNorthwest Pacific basin, our framework achieves multimodal improvements: (1)14.3% reduction in training time with 2.5x faster inference speed compared toPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)sustained predictive leadership in extended-range forecasts (1-120h); and (4)demonstrated zero-shot capability maintaining median performance (rank 4/12)against specialized operational models. This LLM-enhanced temporal modelingparadigm establishes a new standard in wave prediction, offering bothcomputationally efficient solutions and a transferable framework for complexgeophysical systems modeling.</description>
      <author>example@mail.com (Yilin Zhai, Hongyuan Shi, Chao Zhan, Qing Wang, Zaijin You, Nan Wang)</author>
      <guid isPermaLink="false">2504.16834v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2504.17811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OmniSage的大规模表示学习框架，该框架通过整合多种技术支持Pinterest上的多种应用。&lt;h4&gt;背景&lt;/h4&gt;表示学习是提高网络应用中搜索和推荐系统性能的关键任务，包括基于图的关系表示、基于序列的用户活动时序捕获和基于内容的文本及视觉内容利用等方法。&lt;h4&gt;目的&lt;/h4&gt;开发一个统一框架，整合各种表示学习技术以支持多种应用。&lt;h4&gt;方法&lt;/h4&gt;OmniSage通过采用多种对比学习任务，整合图神经网络、基于内容的模型和用户序列模型，并开发了一个高效的支撑数十亿节点Pinterest图的基础设施。&lt;h4&gt;主要发现&lt;/h4&gt;OmniSage生成的通用表示显著提升了Pinterest的用户体验，使站内收藏量增加了约2.5%。&lt;h4&gt;结论&lt;/h4&gt;本文强调了统一表示学习方法的重要性，并计划在论文发表时开源OmniSage代码。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning, a task of learning latent vectors to represententities, is a key task in improving search and recommender systems in webapplications. Various representation learning methods have been developed,including graph-based approaches for relationships among entities,sequence-based methods for capturing the temporal evolution of user activities,and content-based models for leveraging text and visual content. However, thedevelopment of a unifying framework that integrates these diverse techniques tosupport multiple applications remains a significant challenge. This paperpresents OmniSage, a large-scale representation framework that learns universalrepresentations for a variety of applications at Pinterest. OmniSage integratesgraph neural networks with content-based models and user sequence models byemploying multiple contrastive learning tasks to effectively process graphdata, user sequence data, and content signals. To support the training andinference of OmniSage, we developed an efficient infrastructure capable ofsupporting Pinterest graphs with billions of nodes. The universalrepresentations generated by OmniSage have significantly enhanced userexperiences on Pinterest, leading to an approximate 2.5% increase in sitewiderepins (saves) across five applications. This paper highlights the impact ofunifying representation learning methods, and we will open source the OmniSagecode by the time of publication.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning, a task of learning latent vectors to represententities, is a key task in improving search and recommender systems in webapplications. Various representation learning methods have been developed,including graph-based approaches for relationships among entities,sequence-based methods for capturing the temporal evolution of user activities,and content-based models for leveraging text and visual content. However, thedevelopment of a unifying framework that integrates these diverse techniques tosupport multiple applications remains a significant challenge. This paperpresents OmniSage, a large-scale representation framework that learns universalrepresentations for a variety of applications at Pinterest. OmniSage integratesgraph neural networks with content-based models and user sequence models byemploying multiple contrastive learning tasks to effectively process graphdata, user sequence data, and content signals. To support the training andinference of OmniSage, we developed an efficient infrastructure capable ofsupporting Pinterest graphs with billions of nodes. The universalrepresentations generated by OmniSage have significantly enhanced userexperiences on Pinterest, leading to an approximate 2.5% increase in sitewiderepins (saves) across five applications. This paper highlights the impact ofunifying representation learning methods, and we will open source the OmniSagecode by the time of publication.</description>
      <author>example@mail.com (Anirudhan Badrinath, Alex Yang, Kousik Rajesh, Prabhat Agarwal, Jaewon Yang, Haoyu Chen, Jiajing Xu, Charles Rosenberg)</author>
      <guid isPermaLink="false">2504.17811v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Optimism, Expectation, or Sarcasm? Multi-Class Hope Speech Detection in Spanish and English</title>
      <link>http://arxiv.org/abs/2504.17974v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了多语言细粒度希望语音数据集PolyHope V2，用于情感识别任务，并探讨了在区分不同希望类别和讽刺方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;希望是一种复杂且未被充分研究的情绪状态，在教育、心理健康和社会互动中扮演重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一个能够准确检测不同希望类别的多语言数据集，并评估预训练模型在识别希望和讽刺方面的性能。&lt;h4&gt;方法&lt;/h4&gt;研究人员创建了一个包含超过30,000条标注推文的PolyHope V2数据集，区分了四种希望子类型：一般化、现实主义、不切实际和讽刺。他们还在零样本和少样本情况下，将多个预训练变压器模型与大型语言模型（如GPT 4和Llama 3）进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，经过微调的变压器在区分细微的希望类别和讽刺方面优于基于提示的大型语言模型。&lt;h4&gt;结论&lt;/h4&gt;该数据集和结果为未来需要跨语言语义和语境敏感性的情感识别任务提供了一个坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：希望是一种复杂且未被充分研究的情绪状态，在教育、心理健康和社会互动中扮演着重要的角色。与基本情绪不同，希望以细微的形式表现出来，从基于现实的乐观到过度的愿望或讽刺，这使得自然语言处理系统难以准确检测。本研究介绍了PolyHope V2，这是一个多语言、细粒度的希望语音数据集，包含超过30,000条英语和西班牙语的标注推文。这个资源区分了四种希望子类型：一般化、现实主义、不切实际和讽刺，并通过明确标注讽刺实例来增强现有数据集。研究比较了多个预训练的变压器模型，以及在大语言模型（如GPT 4和Llama 3）下的零样本和少样本规则。研究发现，经过微调的变压器在区分细微的希望类别和讽刺方面优于基于提示的大型语言模型。通过定性分析和混淆矩阵，研究突出了在区分密切相关希望子类型方面的系统性挑战。该数据集和结果为未来需要跨语言语义和语境敏感性的情感识别任务提供了一个坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hope is a complex and underexplored emotional state that plays a significantrole in education, mental health, and social interaction. Unlike basicemotions, hope manifests in nuanced forms ranging from grounded optimism toexaggerated wishfulness or sarcasm, making it difficult for Natural LanguageProcessing systems to detect accurately. This study introduces PolyHope V2, amultilingual, fine-grained hope speech dataset comprising over 30,000 annotatedtweets in English and Spanish. This resource distinguishes between four hopesubtypes Generalized, Realistic, Unrealistic, and Sarcastic and enhancesexisting datasets by explicitly labeling sarcastic instances. We benchmarkmultiple pretrained transformer models and compare them with large languagemodels (LLMs) such as GPT 4 and Llama 3 under zero-shot and few-shot regimes.Our findings show that fine-tuned transformers outperform prompt-based LLMs,especially in distinguishing nuanced hope categories and sarcasm. Throughqualitative analysis and confusion matrices, we highlight systematic challengesin separating closely related hope subtypes. The dataset and results provide arobust foundation for future emotion recognition tasks that demand greatersemantic and contextual sensitivity across languages.</description>
      <author>example@mail.com (Sabur Butt, Fazlourrahman Balouchzahi, Ahmad Imam Amjad, Maaz Amjad, Hector G. Ceballos, Salud Maria Jimenez-Zafra)</author>
      <guid isPermaLink="false">2504.17974v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Subject-driven Video Generation via Disentangled Identity and Motion</title>
      <link>http://arxiv.org/abs/2504.17816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page :  https://carpedkm.github.io/projects/disentangled_sub/index.html&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种通过解耦主题特定学习与时间动态，在零样本情况下无需额外调整的训练主题驱动个性化视频生成模型的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的无调整视频定制方法通常依赖于大型、标注的视频数据集，这既计算成本高又需要大量的标注。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种更高效、成本更低的视频定制模型。&lt;h4&gt;方法&lt;/h4&gt;引入了图像定制数据集直接用于训练视频定制模型，将视频定制分为两个步骤：(1)通过图像定制数据集进行身份注入；(2)通过图像到视频的训练方法，使用少量未标注视频进行时间建模的保留。此外，在图像到视频微调期间采用随机图像标记丢弃和随机图像初始化来减轻复制粘贴问题。在联合优化主题特定和时间特征时引入随机切换，以减轻灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了强大的主题一致性和可扩展性，在零样本设置中优于现有的视频定制模型，证明了该框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在零样本设置中表现出色，为视频定制提供了一种高效且成本低的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose to train a subject-driven customized video generation modelthrough decoupling the subject-specific learning from temporal dynamics inzero-shot without additional tuning. A traditional method for videocustomization that is tuning-free often relies on large, annotated videodatasets, which are computationally expensive and require extensive annotation.In contrast to the previous approach, we introduce the use of an imagecustomization dataset directly on training video customization models,factorizing the video customization into two folds: (1) identity injectionthrough image customization dataset and (2) temporal modeling preservation witha small set of unannotated videos through the image-to-video training method.Additionally, we employ random image token dropping with randomized imageinitialization during image-to-video fine-tuning to mitigate the copy-and-pasteissue. To further enhance learning, we introduce stochastic switching duringjoint optimization of subject-specific and temporal features, mitigatingcatastrophic forgetting. Our method achieves strong subject consistency andscalability, outperforming existing video customization models in zero-shotsettings, demonstrating the effectiveness of our framework.</description>
      <author>example@mail.com (Daneul Kim, Jingxu Zhang, Wonjoon Jin, Sunghyun Cho, Qi Dai, Jaesik Park, Chong Luo)</author>
      <guid isPermaLink="false">2504.17816v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion</title>
      <link>http://arxiv.org/abs/2504.15920v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ScaleGNN的新框架，用于解决大规模图上的GNN模型面临的过平滑和可扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Networks (GNNs) 在图相关任务中表现出色，通过迭代消息传递有效地捕获节点之间的关系信息。然而，GNNs 存在过平滑和可扩展性两大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在同时解决GNN在大型图上的过平滑和可扩展性问题。&lt;h4&gt;方法&lt;/h4&gt;ScaleGNN通过自适应融合多级图特征来解决这些问题，包括构建每个阶数的邻接矩阵，学习通过可训练权重传递的相对信息，引入基于局部贡献分数（LCS）的高阶冗余特征掩码机制，以及低阶增强特征聚合。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ScaleGNN在真实世界数据集上，无论是在准确性还是计算效率方面，都优于最先进的GNN模型。&lt;h4&gt;结论&lt;/h4&gt;ScaleGNN框架能够有效地提高GNN模型在大型图上的性能，同时保持高效的计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong performance acrossvarious graph-based tasks by effectively capturing relational informationbetween nodes. These models rely on iterative message passing to propagate nodefeatures, enabling nodes to aggregate information from their neighbors. Recentresearch has significantly improved the message-passing mechanism, enhancingGNN scalability on large-scale graphs. However, GNNs still face two mainchallenges: over-smoothing, where excessive message passing results inindistinguishable node representations, especially in deep networksincorporating high-order neighbors; and scalability issues, as traditionalarchitectures suffer from high model complexity and increased inference timedue to redundant information aggregation. This paper proposes a novel frameworkfor large-scale graphs named ScaleGNN that simultaneously addresses bothchallenges by adaptively fusing multi-level graph features. We first constructneighbor matrices for each order, learning their relative information throughtrainable weights through an adaptive high-order feature fusion module. Thisallows the model to selectively emphasize informative high-order neighborswhile reducing unnecessary computational costs. Additionally, we introduce aHigh-order redundant feature masking mechanism based on a Local ContributionScore (LCS), which enables the model to retain only the most relevant neighborsat each order, preventing redundant information propagation. Furthermore,low-order enhanced feature aggregation adaptively integrates low-order andhigh-order features based on task relevance, ensuring effective capture of bothlocal and global structural information without excessive complexity. Extensiveexperiments on real-world datasets demonstrate that our approach consistentlyoutperforms state-of-the-art GNN models in both accuracy and computationalefficiency.</description>
      <author>example@mail.com (Xiang Li, Haobing Liu, Jianpeng Qi, Yuan Cao, Guoqing Chao, Yanwei Yu)</author>
      <guid isPermaLink="false">2504.15920v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss</title>
      <link>http://arxiv.org/abs/2504.17813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLOC的新方法，用于解决序数分类中相邻类别错误的重要性不同的问题。&lt;h4&gt;背景&lt;/h4&gt;在序数分类中，相邻类别的错误分类很常见，但这些错误的后果并不相同。例如，将良性肿瘤分类错误的重要性低于在癌前病变到癌症的转变阈值处的错误，后者可能会深刻影响治疗选择。&lt;h4&gt;目的&lt;/h4&gt;针对现有序数分类方法未考虑这些边界的不同重要性的局限性，本文提出了一种新的基于边界的对比学习方法CLOC，通过优化多个边缘来学习有序表示。&lt;h4&gt;方法&lt;/h4&gt;CLOC通过一个新颖的多边缘n对损失（MMNP）来学习有序表示，它允许在关键相邻类别之间灵活设置决策边界，从而促进类别之间的平滑过渡并减少对训练数据中存在的偏差过度拟合的风险。&lt;h4&gt;主要发现&lt;/h4&gt;本文提供了关于MMNP特性的实证讨论，并在五个真实世界图像数据集（Adience、Historical Colour Image Dating、Knee Osteoarthritis、Indian Diabetic Retinopathy Image和Breast Carcinoma Subtyping）以及一个模拟临床决策偏差的合成数据集上展示了实验结果。结果表明，CLOC优于现有的序数分类方法，并展示了CLOC在学习和有意义、有序表示方面的可解释性和可控性，这些表示与临床和实际需求相一致。&lt;h4&gt;结论&lt;/h4&gt;CLOC在序数分类中显示出优于现有方法的性能，并且能够学习到符合临床和实际需求的有序表示。&lt;h4&gt;翻译&lt;/h4&gt;在序数分类中，相邻类别的错误分类很常见，但这些错误的后果并不相同。例如，将良性肿瘤分类错误的重要性低于在癌前病变到癌症的转变阈值处的错误，后者可能会深刻影响治疗选择。尽管如此，现有的序数分类方法并没有考虑到这些边界的不同重要性，将所有相邻类别视为同等重要。为了解决这一局限性，我们提出了CLOC，一种基于边界的对比学习方法，用于序数分类，该方法通过优化多个边缘来学习有序表示，并使用一种新颖的多边缘n对损失（MMNP）。CLOC能够在关键相邻类别之间灵活设置决策边界，从而促进类别之间的平滑过渡并减少对训练数据中存在的偏差过度拟合的风险。我们对MMNP的特性进行了实证讨论，并在五个真实世界图像数据集（Adience、Historical Colour Image Dating、Knee Osteoarthritis、Indian Diabetic Retinopathy Image和Breast Carcinoma Subtyping）以及一个模拟临床决策偏差的合成数据集上展示了实验结果。我们的结果表明，CLOC优于现有的序数分类方法，并展示了CLOC在学习和有意义、有序表示方面的可解释性和可控性，这些表示与临床和实际需求相一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In ordinal classification, misclassifying neighboring ranks is common, yetthe consequences of these errors are not the same. For example, misclassifyingbenign tumor categories is less consequential, compared to an error at thepre-cancerous to cancerous threshold, which could profoundly influencetreatment choices. Despite this, existing ordinal classification methods do notaccount for the varying importance of these margins, treating all neighboringclasses as equally significant. To address this limitation, we propose CLOC, anew margin-based contrastive learning method for ordinal classification thatlearns an ordered representation based on the optimization of multiple marginswith a novel multi-margin n-pair loss (MMNP). CLOC enables flexible decisionboundaries across key adjacent categories, facilitating smooth transitionsbetween classes and reducing the risk of overfitting to biases present in thetraining data. We provide empirical discussion regarding the properties of MMNPand show experimental results on five real-world image datasets (Adience,Historical Colour Image Dating, Knee Osteoarthritis, Indian DiabeticRetinopathy Image, and Breast Carcinoma Subtyping) and one synthetic datasetsimulating clinical decision bias. Our results demonstrate that CLOCoutperforms existing ordinal classification methods and show theinterpretability and controllability of CLOC in learning meaningful, orderedrepresentations that align with clinical and practical needs.</description>
      <author>example@mail.com (Dileepa Pitawela, Gustavo Carneiro, Hsiang-Ting Chen)</author>
      <guid isPermaLink="false">2504.17813v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Class-Conditional Distribution Balancing for Group Robust Classification</title>
      <link>http://arxiv.org/abs/2504.17314v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的方法来解决由虚假相关性导致的模型错误预测问题，这些问题在现实世界的通用化中构成了一个关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的研究将这个问题归因于组不平衡，并通过最大化组平衡或最差组精度来解决这个问题，这依赖于昂贵的偏差注释。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种简单而有效的鲁棒学习方法，该方法不需要偏差注释或预测，以减少虚假因素与标签信息之间的互信息。&lt;h4&gt;方法&lt;/h4&gt;该方法通过样本重加权策略来实现类条件分布的平衡，自动突出少数群体和类别，从而有效消除虚假相关性，并生成用于分类的去偏差数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量的实验和分析，证明了该方法在性能上始终处于领先地位，与依赖于偏差监督的方法相媲美。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在处理虚假相关性方面取得了显著成果，为鲁棒学习和数据分布平衡提供了新的视角和有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spurious correlations that lead models to correct predictions for the wrongreasons pose a critical challenge for robust real-world generalization.Existing research attributes this issue to group imbalance and addresses it bymaximizing group-balanced or worst-group accuracy, which heavily relies onexpensive bias annotations. A compromise approach involves predicting biasinformation using extensively pretrained foundation models, which requireslarge-scale data and becomes impractical for resource-limited rare domains. Toaddress these challenges, we offer a novel perspective by reframing thespurious correlations as imbalances or mismatches in class-conditionaldistributions, and propose a simple yet effective robust learning method thateliminates the need for both bias annotations and predictions. With the goal ofreducing the mutual information between spurious factors and label information,our method leverages a sample reweighting strategy to achieve class-conditionaldistribution balancing, which automatically highlights minority groups andclasses, effectively dismantling spurious correlations and producing a debiaseddata distribution for classification. Extensive experiments and analysisdemonstrate that our approach consistently delivers state-of-the-artperformance, rivaling methods that rely on bias supervision.</description>
      <author>example@mail.com (Miaoyun Zhao, Qiang Zhang, Chenrong Li)</author>
      <guid isPermaLink="false">2504.17314v2</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>Research on Cloud Platform Network Traffic Monitoring and Anomaly Detection System based on Large Language Models</title>
      <link>http://arxiv.org/abs/2504.17807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of 2025 IEEE 7th International Conference on  Communications, Information System and Computer Engineering (CISCE 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型的网络流量监控和异常检测系统，以应对云计算平台快速发展和网络流量复杂性增加的挑战。&lt;h4&gt;背景&lt;/h4&gt;云计算平台迅速发展，网络流量复杂性不断提高，这要求有适当的网络流量监控和异常检测机制来确保网络的安全和性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于大型语言模型的网络流量监控和异常检测系统，以提高检测精度和计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合注意力机制的混合模型，将大型语言模型与监督学习框架结合，通过预训练的大型语言模型分析预测网络流量，并增加考虑时序性和上下文的异常检测层。同时，采用了一种基于迁移学习的方法，以增强模型快速适应未知网络结构和对抗条件的能力。&lt;h4&gt;主要发现&lt;/h4&gt;所设计的模型在检测准确率和计算效率方面优于传统方法，能够有效识别包括零日攻击和流量拥堵模式在内的各种网络异常，并显著降低误报率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的网络流量监控和异常检测系统在准确性和效率方面表现出色，为网络安全和性能提供了有效的保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapidly evolving cloud platforms and the escalating complexity of networktraffic demand proper network traffic monitoring and anomaly detection toensure network security and performance. This paper introduces a large languagemodel (LLM)-based network traffic monitoring and anomaly detection system. Inaddition to existing models such as autoencoders and decision trees, we harnessthe power of large language models for processing sequence data from networktraffic, which allows us a better capture of underlying complex patterns, aswell as slight fluctuations in the dataset. We show for a given detection task,the need for a hybrid model that incorporates the attention mechanism of thetransformer architecture into a supervised learning framework in order toachieve better accuracy. A pre-trained large language model analyzes andpredicts the probable network traffic, and an anomaly detection layer thatconsiders temporality and context is added. Moreover, we present a noveltransfer learning-based methodology to enhance the model's effectiveness toquickly adapt to unknown network structures and adversarial conditions withoutrequiring extensive labeled datasets. Actual results show that the designedmodel outperforms traditional methods in detection accuracy and computationalefficiency, effectively identify various network anomalies such as zero-dayattacks and traffic congestion pattern, and significantly reduce the falsepositive rate.</description>
      <author>example@mail.com (Ze Yang, Yihong Jin, Juntian Liu, Xinhe Xu, Yihan Zhang, Shuyang Ji)</author>
      <guid isPermaLink="false">2504.17807v1</guid>
      <pubDate>Mon, 28 Apr 2025 14:14:23 +0800</pubDate>
    </item>
    <item>
      <title>MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search</title>
      <link>http://arxiv.org/abs/2504.15865v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Medical Neural Network Search (MedNNS)，这是一个用于医学影像应用的新颖的神经网络搜索框架，旨在解决深度学习模型在医学任务中的适配问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学影像领域取得了显著进展，但将深度学习模型适配到医学任务仍然是一个重大挑战，主要由于架构选择和权重初始化的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效解决医学影像领域深度学习模型适配问题的框架。&lt;h4&gt;方法&lt;/h4&gt;MedNNS通过构建一个元空间来编码数据集和模型，优化架构选择和权重初始化。该框架使用基于超网络的策略，将模型动物园规模扩大了51倍，并引入了排名损失和弗雷歇起始距离损失来捕捉模型和数据集之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MedNNS在多个数据集上显著优于ImageNet预训练的深度学习模型和最先进的神经网络搜索方法，平均准确率提高了1.7%，并且收敛速度更快。&lt;h4&gt;结论&lt;/h4&gt;MedNNS是医学影像领域一个有效的神经网络搜索框架，有助于提高深度学习模型在医学任务中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度学习（DL）在医学影像领域取得了显著进展。然而，将深度学习模型适配到医学任务仍然是一个重大挑战，主要由于两个关键因素：（1）架构选择，因为不同的任务需要专门的设计；（2）权重初始化，这直接影响模型的收敛速度和最终性能。尽管从ImageNet迁移学习是一个广泛采用的策略，但其有效性受到自然图像和医学图像之间巨大差异的限制。为了解决这些挑战，我们引入了医学神经网络搜索（MedNNS），这是第一个用于医学影像应用的神经网络搜索框架。MedNNS通过构建一个元空间来联合优化架构选择和权重初始化，该空间根据数据集和模型共同表现的好坏来编码它们。我们使用基于超网络的策略构建这个空间，将模型动物园规模扩大了51倍，超过之前的最佳方法（SOTA）。此外，我们将排名损失和弗雷歇起始距离损失引入到空间构建中，以捕捉模型间和数据集间的关系，从而在元空间中实现更准确的校准。多个数据集上的实验结果表明，MedNNS在性能上显著优于ImageNet预训练的深度学习模型和SOTA神经网络搜索（NAS）方法，平均准确率在数据集上提高了1.7%，并且收敛速度更快。代码和处理的元空间可在https://github.com/BioMedIA-MBZUAI/MedNNS上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL) has achieved remarkable progress in the field of medicalimaging. However, adapting DL models to medical tasks remains a significantchallenge, primarily due to two key factors: (1) architecture selection, asdifferent tasks necessitate specialized model designs, and (2) weightinitialization, which directly impacts the convergence speed and finalperformance of the models. Although transfer learning from ImageNet is a widelyadopted strategy, its effectiveness is constrained by the substantialdifferences between natural and medical images. To address these challenges, weintroduce Medical Neural Network Search (MedNNS), the first Neural NetworkSearch framework for medical imaging applications. MedNNS jointly optimizesarchitecture selection and weight initialization by constructing a meta-spacethat encodes datasets and models based on how well they perform together. Webuild this space using a Supernetwork-based approach, expanding the model zoosize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, weintroduce rank loss and Fr\'echet Inception Distance (FID) loss into theconstruction of the space to capture inter-model and inter-datasetrelationships, thereby achieving more accurate alignment in the meta-space.Experimental results across multiple datasets demonstrate that MedNNSsignificantly outperforms both ImageNet pre-trained DL models and SOTA NeuralArchitecture Search (NAS) methods, achieving an average accuracy improvement of1.7% across datasets while converging substantially faster. The code and theprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.</description>
      <author>example@mail.com (Lotfi Abdelkrim Mecharbat, Ibrahim Almakky, Martin Takac, Mohammad Yaqub)</author>
      <guid isPermaLink="false">2504.15865v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
  <item>
      <title>Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset</title>
      <link>http://arxiv.org/abs/2504.17371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了DeepScenario Open 3D Dataset（DSC3D），这是一个高质量的、无遮挡的6自由度边界框轨迹数据集，通过新型单目相机无人机跟踪流程获取。该数据集包含超过17.5万条14种交通参与者的轨迹，在多样性和规模上显著超过现有数据集。&lt;h4&gt;背景&lt;/h4&gt;精确的3D轨迹数据对于自动驾驶技术的发展至关重要。传统的数据集通常由安装在汽车上的固定传感器捕获，容易受到遮挡，并且只能精确地重建测量车辆附近动态环境，而忽略了更远处的物体。&lt;h4&gt;目的&lt;/h4&gt;提高自动驾驶系统的性能，通过提供详细的3D环境表示，改善障碍物交互和安全性。&lt;h4&gt;方法&lt;/h4&gt;使用新型单目相机无人机跟踪流程采集数据，包括停车场、拥挤的内城区、陡峭的城市交叉口、联邦高速公路和郊外交叉口等五个不同地点的多种场景。&lt;h4&gt;主要发现&lt;/h4&gt;DSC3D数据集在多样性和规模上超过现有数据集，包含许多前所未有的场景，如高度人口密集的街道上的复杂车辆行人交互和从入口到出口的综合停车操作。&lt;h4&gt;结论&lt;/h4&gt;DSC3D数据集对多个应用有实用价值，包括运动预测、运动规划、场景挖掘和生成反应式交通代理。数据集的交互式在线可视化平台和完整数据集公开可用，促进了运动预测、行为建模和安全验证的研究。&lt;h4&gt;翻译&lt;/h4&gt;Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at app.deepscenario.com, facilitating research in motion prediction, behavior modeling, and safety validation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet,traditional datasets are usually captured by fixed sensors mounted on a car andare susceptible to occlusion. Additionally, such an approach can preciselyreconstruct the dynamic environment in the close vicinity of the measurementvehicle only, while neglecting objects that are further away. In this paper, weintroduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality,occlusion-free dataset of 6 degrees of freedom bounding box trajectoriesacquired through a novel monocular camera drone tracking pipeline. Our datasetincludes more than 175,000 trajectories of 14 types of traffic participants andsignificantly exceeds existing datasets in terms of diversity and scale,containing many unprecedented scenarios such as complex vehicle-pedestrianinteraction on highly populated urban streets and comprehensive parkingmaneuvers from entry to exit. DSC3D dataset was captured in five variouslocations in Europe and the United States and include: a parking lot, a crowdedinner-city, a steep urban intersection, a federal highway, and a suburbanintersection. Our 3D trajectory dataset aims to enhance autonomous drivingsystems by providing detailed environmental 3D representations, which couldlead to improved obstacle interactions and safety. We demonstrate its utilityacross multiple applications including motion prediction, motion planning,scenario mining, and generative reactive traffic agents. Our interactive onlinevisualization platform and the complete dataset are publicly available atapp.deepscenario.com, facilitating research in motion prediction, behaviormodeling, and safety validation.</description>
      <author>example@mail.com (Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan, Holger Banzhaf, Daniel Cremers)</author>
      <guid isPermaLink="false">2504.17371v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Continuous Touch-Based Authentication</title>
      <link>http://arxiv.org/abs/2504.17271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于触摸行为的连续用户认证方法，旨在为智能手机提供更可靠和有效的安全解决方案。&lt;h4&gt;背景&lt;/h4&gt;随着智能手机在日常生活中的普及，对安全控制的需求日益增加，尤其是在处理、存储和传输敏感信息时。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用触摸屏进行连续用户认证，以实现自然和无缝的安全解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种统一的对比学习框架，利用时间掩码自动编码器（TMAE）从原始多传感器数据流中提取时间模式，并集成到Siamese时间注意卷积网络中，以模型化序列和跨模态模式。同时，引入多头注意力和通道注意力机制来捕捉长距离依赖关系和优化通道间特征集成。&lt;h4&gt;主要发现&lt;/h4&gt;在公共基准数据集和自收集数据集上的实验表明，该方法优于现有方法，提供了可靠和有效的移动设备用户认证解决方案。&lt;h4&gt;结论&lt;/h4&gt;该方法为智能手机用户认证提供了一种有效的解决方案，具有较好的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart mobile devices have become indispensable in modern daily life, wheresensitive information is frequently processed, stored, and transmitted-posingcritical demands for robust security controls. Given that touchscreens are theprimary medium for human-device interaction, continuous user authenticationbased on touch behavior presents a natural and seamless security solution.While existing methods predominantly adopt binary classification undersingle-modal learning settings, we propose a unified contrastive learningframework for continuous authentication in a non-disruptive manner.Specifically, the proposed method leverages a Temporal Masked Autoencoder toextract temporal patterns from raw multi-sensor data streams, capturingcontinuous motion and gesture dynamics. The pre-trained TMAE is subsequentlyintegrated into a Siamese Temporal-Attentive Convolutional Network within acontrastive learning paradigm to model both sequential and cross-modalpatterns. To further enhance performance, we incorporate multi-head attentionand channel attention mechanisms to capture long-range dependencies andoptimize inter-channel feature integration. Extensive experiments on publicbenchmarks and a self-collected dataset demonstrate that our approachoutperforms state-of-the-art methods, offering a reliable and effectivesolution for user authentication on mobile devices.</description>
      <author>example@mail.com (Mengyu Qiao, Yunpeng Zhai, Yang Wang)</author>
      <guid isPermaLink="false">2504.17271v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link Weight Prediction</title>
      <link>http://arxiv.org/abs/2504.17749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了Graph Neural Networks（GNNs）在多种学习任务中的应用，特别是针对链接权重预测的新方法Multiplex Spatial Graph Convolution Network（MSGCN）。&lt;h4&gt;背景&lt;/h4&gt;GNNs在节点分类和链接预测等领域表现出色，但在链接权重预测，尤其是多层网络中的链接权重预测方面，由于复杂性较高而受到较少关注。&lt;h4&gt;目的&lt;/h4&gt;提出MSGCN方法，旨在解决多层网络中链接权重预测的挑战，通过在多个层之间嵌入信息来预测层间链接权重。&lt;h4&gt;方法&lt;/h4&gt;MSGCN模型将空间图卷积推广到复用网络，并捕捉多层节点间的几何结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MSGCN模型在各种复用网络结构中具有稳健、准确和可推广的链接权重预测性能。&lt;h4&gt;结论&lt;/h4&gt;MSGCN方法在多层网络链接权重预测方面是一种有效且可靠的方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）已被广泛应用于各种学习任务，从节点分类到链接预测。它们在涉及图结构数据的多个领域表现出卓越的性能。然而，由于与二元链接分类相比复杂性增加，链接权重预测这一重要类别的学习任务得到了较少的关注。当考虑多层网络时，节点可以在多个层之间相互连接，链接权重预测变得更加具有挑战性。为了解决这些挑战，我们提出了一种名为多路空间图卷积网络（MSGCN）的新方法，该方法在多个层之间空间嵌入信息以预测层间链接权重。MSGCN模型将空间图卷积推广到复用网络，并捕捉多层节点间的几何结构。使用具有已知层间链接信息的数据的广泛实验表明，MSGCN模型在各种复用网络结构中具有稳健、准确和可推广的链接权重预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have been widely used for various learningtasks, ranging from node classification to link prediction. They havedemonstrated excellent performance in multiple domains involvinggraph-structured data. However, an important category of learning tasks, namelylink weight prediction, has received less emphasis due to its increasedcomplexity compared to binary link classification. Link weight predictionbecomes even more challenging when considering multilayer networks, where nodescan be interconnected across multiple layers. To address these challenges, wepropose a new method named Multiplex Spatial Graph Convolution Network (MSGCN),which spatially embeds information across multiple layers to predict interlayerlink weights. The MSGCN model generalizes spatial graph convolution tomultiplex networks and captures the geometric structure of nodes acrossmultiple layers. Extensive experiments using data with known interlayer linkinformation show that the MSGCN model has robust, accurate, and generalizablelink weight prediction performance across a wide variety of multiplex networkstructures.</description>
      <author>example@mail.com (Steven E. Wilson, Sina Khanmohammadi)</author>
      <guid isPermaLink="false">2504.17749v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>PICO: Reconstructing 3D People In Contact with Objects</title>
      <link>http://arxiv.org/abs/2504.17695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR'25. Project Page: https://pico.is.tue.mpg.de&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从单色图像中恢复3D人-物交互的方法，以克服深度模糊、遮挡和物体形状和外观的巨大变化等挑战。&lt;h4&gt;背景&lt;/h4&gt;从单色图像中恢复3D人-物交互是一个挑战，因为深度模糊、遮挡和物体形状和外观的巨大变化。&lt;h4&gt;目的&lt;/h4&gt;开发能够泛化到自然图像和新型物体类别的3D人-物交互恢复方法。&lt;h4&gt;方法&lt;/h4&gt;（1）收集了PICO-db数据集，其中包含与密集3D接触唯一匹配的自然图像；（2）使用PICO-fit方法，通过渲染和比较拟合来恢复交互中的3D身体和物体网格。&lt;h4&gt;主要发现&lt;/h4&gt;PICO-fit方法能够处理许多现有方法无法处理的物体类别，对于在野外扩展人-物交互理解至关重要。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为从单色图像中恢复3D人-物交互提供了新的可能性，并促进了该领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从单色图像中恢复3D人-物交互（HOI）是一项挑战，因为深度模糊、遮挡和物体形状和外观的巨大变化。因此，过去的工作需要在已知物体形状和接触的受控环境中进行，并且只处理有限的物体类别。相反，我们需要泛化到自然图像和新型物体类别的方 法。我们以两种主要方式解决这个问题：（1）我们收集了PICO-db，这是一个新的数据集，其中包含与身体和物体网格上的密集3D接触唯一匹配的自然图像。为此，我们使用了与接触匹配的DAMON数据集中的图像，但这些接触仅在标准3D身体上进行了标注。相比之下，我们寻求在身体和物体上的接触标签。为了从图像中推断这些标签，我们通过利用视觉基础模型从数据库中检索适当的3D物体网格。然后，我们通过一种新的方法将DAMON的身体接触块投影到物体上，每个块只需要2次点击。这种最小的人为输入在身体和物体之间建立了丰富的接触对应关系。（2）我们利用我们新的接触对应关系数据集，通过一种称为PICO-fit的新渲染和比较拟合方法，来恢复交互中的3D身体和物体网格。PICO-fit推断SMPL-X身体的接触，从PICO-db检索该物体的可能3D物体网格和接触，并使用接触通过优化迭代地拟合3D身体和物体网格到图像证据。独特的是，PICO-fit对于许多现有方法无法处理的物体类别都表现良好。这对于在野外扩展HOI理解至关重要。我们的数据和代码可在https://pico.is.tue.mpg.de获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering 3D Human-Object Interaction (HOI) from single color images ischallenging due to depth ambiguities, occlusions, and the huge variation inobject shape and appearance. Thus, past work requires controlled settings suchas known object shapes and contacts, and tackles only limited object classes.Instead, we need methods that generalize to natural images and novel objectclasses. We tackle this in two main ways: (1) We collect PICO-db, a new datasetof natural images uniquely paired with dense 3D contact on both body and objectmeshes. To this end, we use images from the recent DAMON dataset that arepaired with contacts, but these contacts are only annotated on a canonical 3Dbody. In contrast, we seek contact labels on both the body and the object. Toinfer these given an image, we retrieve an appropriate 3D object mesh from adatabase by leveraging vision foundation models. Then, we project DAMON's bodycontact patches onto the object via a novel method needing only 2 clicks perpatch. This minimal human input establishes rich contact correspondencesbetween bodies and objects. (2) We exploit our new dataset of contactcorrespondences in a novel render-and-compare fitting method, called PICO-fit,to recover 3D body and object meshes in interaction. PICO-fit infers contactfor the SMPL-X body, retrieves a likely 3D object mesh and contact from PICO-dbfor that object, and uses the contact to iteratively fit the 3D body and objectmeshes to image evidence via optimization. Uniquely, PICO-fit works well formany object categories that no existing method can tackle. This is crucial toenable HOI understanding to scale in the wild. Our data and code are availableat https://pico.is.tue.mpg.de.</description>
      <author>example@mail.com (Alpár Cseke, Shashank Tripathi, Sai Kumar Dwivedi, Arjun Lakshmipathy, Agniv Chatterjee, Michael J. Black, Dimitrios Tzionas)</author>
      <guid isPermaLink="false">2504.17695v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.17264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in International Joint Conference on Neural Networks (IJCNN)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为JurisCTC的新模型，用于提高法律判决预测（LJP）任务的准确性，并在不同法律领域之间实现有效的知识迁移。&lt;h4&gt;背景&lt;/h4&gt;近年来，无监督领域自适应（UDA）在自然语言处理（NLP）领域受到关注，因为它能够增强模型在不同领域间的泛化能力。然而，其在不同法律领域间知识迁移的应用仍鲜有探索。&lt;h4&gt;目的&lt;/h4&gt;为了解决长篇复杂法律文本和大规模标注数据集有限可用的问题，提出JurisCTC模型。&lt;h4&gt;方法&lt;/h4&gt;JurisCTC通过对比学习区分不同领域的样本，实现民事法和刑法领域之间的知识迁移，以提高LJP任务的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法和特定的大型语言模型（LLMs）相比，JurisCTC在LJP任务上取得了显著的进展，分别达到了76.59%和78.83%的峰值准确率。&lt;h4&gt;结论&lt;/h4&gt;JurisCTC模型在法律判决预测任务中表现出色，为不同法律领域间的知识迁移提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Unsupervised Domain Adaptation (UDA) has gained significantattention in the field of Natural Language Processing (NLP) owing to itsability to enhance model generalization across diverse domains. However, itsapplication for knowledge transfer between distinct legal domains remainslargely unexplored. To address the challenges posed by lengthy and complexlegal texts and the limited availability of large-scale annotated datasets, wepropose JurisCTC, a novel model designed to improve the accuracy of LegalJudgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTCfacilitates effective knowledge transfer across various legal domains andemploys contrastive learning to distinguish samples from different domains.Specifically, for the LJP task, we enable knowledge transfer between civil andcriminal law domains. Compared to other models and specific large languagemodels (LLMs), JurisCTC demonstrates notable advancements, achieving peakaccuracies of 76.59% and 78.83%, respectively.</description>
      <author>example@mail.com (Zhaolu Kang, Hongtian Cai, Xiangyang Ji, Jinzhe Li, Nanfei Gu)</author>
      <guid isPermaLink="false">2504.17264v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Prototype-enhanced prediction in graph neural networks for climate applications</title>
      <link>http://arxiv.org/abs/2504.17492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过使用原型来提高数据驱动模拟器输出质量的方法，并展示了其在模拟大气扩散（对温室气体排放监测至关重要）中的应用。&lt;h4&gt;背景&lt;/h4&gt;数据驱动模拟器被广泛应用于学习并模拟基于物理的模拟，以减少计算成本和运行时间。&lt;h4&gt;目的&lt;/h4&gt;目的是通过使用原型来提高高维模拟输出的质量。&lt;h4&gt;方法&lt;/h4&gt;方法包括使用原型的近似输出作为输入，以改进模型并提高预测的准确性。此外，通过比较使用原型作为额外输入训练的模型与基线模型，来演示该方法在模拟大气扩散中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;原型模型即使在原型数量较少甚至随机选择的情况下，也实现了更好的性能。通过数据驱动方法（如k-means）选择原型，可以在某些指标上提高近10%的性能。&lt;h4&gt;结论&lt;/h4&gt;选择原型通过数据驱动方法可以提高模拟器的性能，特别是在关键的应用如大气扩散模拟中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven emulators are increasingly being used to learn and emulatephysics-based simulations, reducing computational expense and run time. Here,we present a structured way to improve the quality of these high-dimensionalemulated outputs, through the use of prototypes: an approximation of theemulator's output passed as an input, which informs the model and leads tobetter predictions. We demonstrate our approach to emulate atmosphericdispersion, key for greenhouse gas emissions monitoring, by comparing abaseline model to models trained using prototypes as an additional input. Theprototype models achieve better performance, even with few prototypes and evenif they are chosen at random, but we show that choosing the prototypes throughdata-driven methods (k-means) can lead to almost 10\% increased performance insome metrics.</description>
      <author>example@mail.com (Nawid Keshtmand, Elena Fillola, Jeffrey Nicholas Clark, Raul Santos-Rodriguez, Matthew Rigby)</author>
      <guid isPermaLink="false">2504.17492v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2504.17660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模拟的推理（SBI）方法，利用预训练的表格基础模型TabPFN，实现了高效的贝叶斯推理，并在模拟效率上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;SBI是一种灵活的贝叶斯推理方法，通过训练神经网络在模拟数据上进行快速后验分布推断。&lt;h4&gt;目的&lt;/h4&gt;减少SBI所需的模拟次数，特别是在昂贵模拟器的情况下。&lt;h4&gt;方法&lt;/h4&gt;使用TabPFN作为预训练的自回归条件密度估计器，提出了一种名为NPE-PF的神经网络后验估计方法，无需选择、训练和调整推理网络。&lt;h4&gt;主要发现&lt;/h4&gt;NPE-PF在基准任务和两个复杂的科学逆问题中，在准确性方面与现有SBI方法相当，但在模拟效率方面显著优于它们，有时需要的模拟次数少几个数量级。&lt;h4&gt;结论&lt;/h4&gt;NPE-PF为SBI提供了新的方向，提供了无训练、通用的推理模型，为广泛的随机逆问题提供了高效、易于使用和灵活的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Simulation-based inference (SBI) offers a flexible and general approach to performing Bayesian inference: In SBI, a neural network is trained on synthetic data simulated from a model and used to rapidly infer posterior distributions for observed data. A key goal for SBI is to achieve accurate inference with as few simulations as possible, especially for expensive simulators. In this work, we address this challenge by repurposing recent probabilistic foundation models for tabular data: We show how tabular foundation models -- specifically TabPFN-- can be used as pre-trained autoregressive conditional density estimators for SBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks (NPE-PF) and show that it is competitive with current SBI approaches in terms of accuracy for both benchmark tasks and two complex scientific inverse problems. Crucially, it often substantially outperforms them in terms of simulation efficiency, sometimes requiring orders of magnitude fewer simulations. NPE-PF eliminates the need for inference network selection, training, and hyperparameter tuning. We also show that it exhibits superior robustness to model misspecification and can be scaled to simulation budgets that exceed the context size limit of TabPFN. NPE-PF provides a new direction for SBI, where training-free, general-purpose inference models offer efficient, easy-to-use, and flexible solutions for a wide range of stochastic inverse problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation-based inference (SBI) offers a flexible and general approach toperforming Bayesian inference: In SBI, a neural network is trained on syntheticdata simulated from a model and used to rapidly infer posterior distributionsfor observed data. A key goal for SBI is to achieve accurate inference with asfew simulations as possible, especially for expensive simulators. In this work,we address this challenge by repurposing recent probabilistic foundation modelsfor tabular data: We show how tabular foundation models -- specifically TabPFN-- can be used as pre-trained autoregressive conditional density estimators forSBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks(NPE-PF) and show that it is competitive with current SBI approaches in termsof accuracy for both benchmark tasks and two complex scientific inverseproblems. Crucially, it often substantially outperforms them in terms ofsimulation efficiency, sometimes requiring orders of magnitude fewersimulations. NPE-PF eliminates the need for inference network selection,training, and hyperparameter tuning. We also show that it exhibits superiorrobustness to model misspecification and can be scaled to simulation budgetsthat exceed the context size limit of TabPFN. NPE-PF provides a new directionfor SBI, where training-free, general-purpose inference models offer efficient,easy-to-use, and flexible solutions for a wide range of stochastic inverseproblems.</description>
      <author>example@mail.com (Julius Vetter, Manuel Gloeckler, Daniel Gedon, Jakob H. Macke)</author>
      <guid isPermaLink="false">2504.17660v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>UNILoc: Unified Localization Combining Model-Based Geometry and Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.17676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, submitted to IEEE conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的定位方法，该方法结合了基于模型和机器学习的方法，通过利用可用的地图信息来发挥各自的优势。&lt;h4&gt;背景&lt;/h4&gt;准确的移动设备定位对于5G/6G应用，如自动驾驶和增强现实至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够提高定位精度的方法，同时避免监督学习的需求。&lt;h4&gt;方法&lt;/h4&gt;该方法通过最优传输（OT）自动生成训练标签，结合几何估计和建筑布局。还进行了基于光线追踪的模拟来验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在视线（LoS）用户和非视线（NLoS）用户中显著提高了定位精度，并且与完全监督的指纹识别相比，能够实现有竞争力的整体性能，同时消除了繁琐的标签数据测量和收集的需求。&lt;h4&gt;结论&lt;/h4&gt;所提出的统一方法在保持高性能的同时，简化了数据收集过程，为5G/6G应用中的定位问题提供了一种有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate mobile device localization is critical for emerging 5G/6Gapplications such as autonomous vehicles and augmented reality. In this paper,we propose a unified localization method that integrates model-based andmachine learning (ML)-based methods to reap their respective advantages byexploiting available map information. In order to avoid supervised learning, wegenerate training labels automatically via optimal transport (OT) by fusinggeometric estimates with building layouts. Ray-tracing based simulations arecarried out to demonstrate that the proposed method significantly improvespositioning accuracy for both line-of-sight (LoS) users (compared to ML-basedmethods) and non-line-of-sight (NLoS) users (compared to model-based methods).Remarkably, the unified method is able to achieve competitive overallperformance with the fully-supervised fingerprinting, while eliminating theneed for cumbersome labeled data measurement and collection.</description>
      <author>example@mail.com (Yuhao Zhang, Guangjin Pan, Musa Furkan Keskin, Ossi Kaltiokallio, Mikko Valkama, Henk Wymeersch)</author>
      <guid isPermaLink="false">2504.17676v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Range Image-Based Implicit Neural Compression for LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2504.17229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的高效压缩激光雷达点云的方案，使得高精度的3D场景归档成为可能，这些归档有助于深入理解相应的3D场景。&lt;h4&gt;背景&lt;/h4&gt;研究基于2D距离图像（RIs）作为表示3D激光雷达观测的轻量级格式。尽管传统的图像压缩技术可以适应以提高RIs的压缩效率，但由于自然图像和RIs在位精度和像素值分布特性上的差异，其实际性能预计会有限。&lt;h4&gt;目的&lt;/h4&gt;提出了一种基于隐式神经网络表示（INR）的RI压缩方法，以有效处理浮点值像素。&lt;h4&gt;方法&lt;/h4&gt;该方法将RIs分为深度图像和掩码图像，并分别使用带有模型剪枝和量化的块状和像素级INR架构进行压缩。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上的实验表明，该方法在低比特率和解码延迟方面优于现有的图像、点云、RI和基于INR的压缩方法，在3D重建和检测质量方面表现更优。&lt;h4&gt;结论&lt;/h4&gt;提出的基于INR的RI压缩方法在保持高压缩效率的同时，显著提升了3D场景的重建和检测质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel scheme to efficiently compress Light Detectionand Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives,and such archives pave the way for a detailed understanding of thecorresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweightformat for representing 3D LiDAR observations. Although conventional imagecompression techniques can be adapted to improve compression efficiency forRIs, their practical performance is expected to be limited due to differencesin bit precision and the distinct pixel value distribution characteristicsbetween natural images and RIs. We propose a novel implicit neuralrepresentation~(INR)--based RI compression method that effectively handlesfloating-point valued pixels. The proposed method divides RIs into depth andmask images and compresses them using patch-wise and pixel-wise INRarchitectures with model pruning and quantization, respectively. Experiments onthe KITTI dataset show that the proposed method outperforms existing image,point cloud, RI, and INR-based compression methods in terms of 3Dreconstruction and detection quality at low bitrates and decoding latency.</description>
      <author>example@mail.com (Akihiro Kuwabara, Sorachi Kato, Takuya Fujihashi, Toshiaki Koike-Akino, Takashi Watanabe)</author>
      <guid isPermaLink="false">2504.17229v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Quadratic Interest Network for Multimodal Click-Through Rate Prediction</title>
      <link>http://arxiv.org/abs/2504.17699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QIN的模型，用于多模态点击率预测，通过自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络捕获高阶特征交互，在竞赛中取得了优异成绩。&lt;h4&gt;背景&lt;/h4&gt;多模态点击率预测是工业推荐系统中的关键技术，它利用文本、图像和行为日志等异构模态信息来捕捉用户与物品之间的高阶特征交互，以增强系统对用户兴趣的理解和预测点击行为的能力。&lt;h4&gt;目的&lt;/h4&gt;为了推动这一领域的发展，WWW 2025 EReL@MIR Workshop提出了两个任务：多模态物品嵌入和多模态点击率预测，旨在探索如何有效地利用多种模态的丰富语义信息，同时满足在线推理的低延迟要求。&lt;h4&gt;方法&lt;/h4&gt;本文提出的QIN模型采用自适应稀疏目标注意力机制提取多模态用户行为特征，并利用二次神经网络来捕获高阶特征交互。&lt;h4&gt;主要发现&lt;/h4&gt;QIN模型在竞赛中取得了AUC 0.9798的好成绩，排名第二。&lt;h4&gt;结论&lt;/h4&gt;QIN模型能够有效地利用多模态信息进行点击率预测，为推荐系统提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态点击率（CTR）预测是工业推荐系统中的关键技术。它利用文本、图像和行为日志等异构模态来捕捉用户与物品之间的高阶特征交互，从而增强系统对用户兴趣的理解及其预测点击行为的能力。该领域的挑战在于如何有效地利用多种模态的丰富语义信息，同时满足实际应用中在线推理的低延迟需求。为了推动这一领域的发展，WWW 2025 EReL@MIR Workshop的Multimodal CTR Prediction Challenge Track将其问题定义为两个任务：（1）多模态物品嵌入任务1：该任务旨在探索多模态信息提取和物品表示学习方法，以增强推荐任务；（2）多模态点击率预测任务2：该任务旨在探索哪种多模态推荐模型能够有效地利用多模态嵌入特征并实现更好的性能。在本文中，我们提出了一个名为QIN的新模型，用于任务2的多模态点击率预测。具体来说，QIN采用自适应稀疏目标注意力机制来提取多模态用户行为特征，并利用二次神经网络来捕获高阶特征交互。因此，QIN在排行榜上取得了AUC 0.9798的成绩，并在比赛中排名第二。模型代码、训练日志、超参数配置和检查点可在https://github.com/salmon1802/QIN找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal click-through rate (CTR) prediction is a key technique inindustrial recommender systems. It leverages heterogeneous modalities such astext, images, and behavioral logs to capture high-order feature interactionsbetween users and items, thereby enhancing the system's understanding of userinterests and its ability to predict click behavior. The primary challenge inthis field lies in effectively utilizing the rich semantic information frommultiple modalities while satisfying the low-latency requirements of onlineinference in real-world applications. To foster progress in this area, theMultimodal CTR Prediction Challenge Track of the WWW 2025 EReL@MIR Workshopformulates the problem into two tasks: (1) Task 1 of Multimodal Item Embedding:this task aims to explore multimodal information extraction and itemrepresentation learning methods that enhance recommendation tasks; and (2) Task2 of Multimodal CTR Prediction: this task aims to explore what multimodalrecommendation model can effectively leverage multimodal embedding features andachieve better performance. In this paper, we propose a novel model for Task 2,named Quadratic Interest Network (QIN) for Multimodal CTR Prediction.Specifically, QIN employs adaptive sparse target attention to extractmultimodal user behavior features, and leverages Quadratic Neural Networks tocapture high-order feature interactions. As a result, QIN achieved an AUC of0.9798 on the leaderboard and ranked second in the competition. The model code,training logs, hyperparameter configurations, and checkpoints are available athttps://github.com/salmon1802/QIN.</description>
      <author>example@mail.com (Honghao Li, Hanwei Li, Jing Zhang, Yi Zhang, Ziniu Yu, Lei Sang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2504.17699v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Guide to Structureless Visual Localization</title>
      <link>http://arxiv.org/abs/2504.17636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了无结构视觉定位方法，与基于结构的视觉定位方法相比，无结构方法在场景变化后更新3D模型更加灵活。&lt;h4&gt;背景&lt;/h4&gt;视觉定位算法是自动驾驶汽车和增强/混合现实系统等应用的核心组件。&lt;h4&gt;目的&lt;/h4&gt;提供对无结构方法的首次全面讨论和比较。&lt;h4&gt;方法&lt;/h4&gt;通过实验比较了不同方法在姿态估计方面的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用更高程度的经典几何推理的方法通常能实现更高的姿态估计精度。&lt;h4&gt;结论&lt;/h4&gt;无结构方法在灵活性方面具有优势，但以略微降低的姿态估计精度为代价。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉定位算法，即估计查询图像在已知场景中相机位姿的方法，是许多应用的核心组件，包括自动驾驶汽车和增强/混合现实系统。最先进的视觉定位算法是基于结构的，即它们存储场景的3D模型，并使用查询图像与模型中3D点之间的2D-3D对应关系进行相机位姿估计。虽然这种方法非常准确，但在场景变化后调整底层3D模型时也相当不灵活。无结构定位方法将场景表示为已知姿态的图像数据库，从而提供了一种更加灵活的表示，可以通过添加或删除图像轻松更新。尽管关于基于结构的方法有大量的文献，但关于无结构方法的工作却相对较少。因此，本文致力于提供我们所知的关于无结构方法的首次全面讨论和比较。广泛的实验表明，使用更高程度的经典几何推理的方法通常能实现更高的姿态估计精度。特别是，基于经典绝对或半广义相对姿态估计的方法在精度上远远超过了基于姿态回归的非常最近的方法。与最先进的基于结构的方法相比，无结构方法的灵活性是以（略微）降低的姿态估计精度为代价的，这表明了未来工作的一个有趣方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization algorithms, i.e., methods that estimate the camera poseof a query image in a known scene, are core components of many applications,including self-driving cars and augmented / mixed reality systems.State-of-the-art visual localization algorithms are structure-based, i.e., theystore a 3D model of the scene and use 2D-3D correspondences between the queryimage and 3D points in the model for camera pose estimation. While suchapproaches are highly accurate, they are also rather inflexible when it comesto adjusting the underlying 3D model after changes in the scene. Structurelesslocalization approaches represent the scene as a database of images with knownposes and thus offer a much more flexible representation that can be easilyupdated by adding or removing images. Although there is a large amount ofliterature on structure-based approaches, there is significantly less work onstructureless methods. Hence, this paper is dedicated to providing the, to thebest of our knowledge, first comprehensive discussion and comparison ofstructureless methods. Extensive experiments show that approaches that use ahigher degree of classical geometric reasoning generally achieve higher poseaccuracy. In particular, approaches based on classical absolute orsemi-generalized relative pose estimation outperform very recent methods basedon pose regression by a wide margin. Compared with state-of-the-artstructure-based approaches, the flexibility of structureless methods comes atthe cost of (slightly) lower pose accuracy, indicating an interesting directionfor future work.</description>
      <author>example@mail.com (Vojtech Panek, Qunjie Zhou, Yaqing Ding, Sérgio Agostinho, Zuzana Kukelova, Torsten Sattler, Laura Leal-Taixé)</author>
      <guid isPermaLink="false">2504.17636v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</title>
      <link>http://arxiv.org/abs/2504.17365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TimeSoccer的端到端足球多模态大型语言模型（MLLM），用于对全场比赛视频进行单主播密集视频字幕生成（SDVC）。该模型通过引入MoFA-Select模块，实现了对足球比赛的长期视频理解，并在SDVC任务上达到了最先进（SoTA）的性能。&lt;h4&gt;背景&lt;/h4&gt;足球是一项全球流行的体育赛事，通常具有漫长的比赛时间和独特的精彩瞬间。现有的足球MLLM在字幕生成时通常依赖于时间先验，无法端到端处理足球视频。&lt;h4&gt;目的&lt;/h4&gt;解决现有足球MLLM在时间定位和语义描述方面的不足，实现端到端对全场比赛视频的理解。&lt;h4&gt;方法&lt;/h4&gt;TimeSoccer模型通过一次性预测时间戳并生成字幕，实现全局上下文建模。MoFA-Select模块通过自底向上的策略自适应选择代表性帧，并采用补充训练范式加强模型处理长时间序列的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TimeSoccer在SDVC任务上实现了最先进的性能，能够生成高质量的字幕，具有准确的时间对齐和强语义相关性。&lt;h4&gt;结论&lt;/h4&gt;TimeSoccer模型为足球比赛的长期视频理解提供了有效的解决方案，并在SDVC任务上取得了显著成果。&lt;h4&gt;翻译&lt;/h4&gt;Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer is a globally popular sporting event, typically characterized by longmatches and distinctive highlight moments. Recent advances in Multimodal LargeLanguage Models (MLLMs) offer promising capabilities in temporal grounding andvideo understanding, soccer commentary generation often requires precisetemporal localization and semantically rich descriptions over long-form video.However, existing soccer MLLMs often rely on the temporal a priori for captiongeneration, so they cannot process the soccer video end-to-end. While sometraditional approaches follow a two-step paradigm that is complex and fails tocapture the global context to achieve suboptimal performance. To solve theabove issues, we present TimeSoccer, the first end-to-end soccer MLLM forSingle-anchor Dense Video Captioning (SDVC) in full-match soccer videos.TimeSoccer jointly predicts timestamps and generates captions in a single pass,enabling global context modeling across 45-minute matches. To support longvideo understanding of soccer matches, we introduce MoFA-Select, atraining-free, motion-aware frame compression module that adaptively selectsrepresentative frames via a coarse-to-fine strategy, and incorporatescomplementary training paradigms to strengthen the model's ability to handlelong temporal sequences. Extensive experiments demonstrate that our TimeSoccerachieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-endform, generating high-quality commentary with accurate temporal alignment andstrong semantic relevance.</description>
      <author>example@mail.com (Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang)</author>
      <guid isPermaLink="false">2504.17365v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>PhysioSync: Temporal and Cross-Modal Contrastive Learning Inspired by Physiological Synchronization for EEG-Based Emotion Recognition</title>
      <link>http://arxiv.org/abs/2504.17163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code will be publicly available at  https://github.com/MSA-LMC/PhysioSync&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysioSync是一种新的预训练框架，利用时间和跨模态对比学习，以解决EEG信号在情感识别中的噪声和个体差异问题，并通过融合跨分辨率和跨模态特征来提高识别效果。&lt;h4&gt;背景&lt;/h4&gt;EEG信号提供关于情绪状态的脑活动信息，但通常受噪声和个体差异影响，导致情感识别复杂。多模态方法虽然使用PPS如GSR，但常忽视模态间的动态同步和语义一致性。&lt;h4&gt;目的&lt;/h4&gt;提出PhysioSync框架以解决EEG信号在情感识别中的挑战，包括噪声、个体差异、模态间动态同步和语义一致性以及情绪波动的时间动态问题。&lt;h4&gt;方法&lt;/h4&gt;PhysioSync利用时间对比学习和跨模态对比学习，结合交叉模态一致性对齐（CM-CA）和长短期时间对比学习（LS-TCL），以建模EEG和PPS之间的动态关系，并捕捉不同时间分辨率内的情绪同步。&lt;h4&gt;主要发现&lt;/h4&gt;PhysioSync在DEAP和DREAMER数据集上的实验表明，在单模态和跨模态条件下，其性能优于其他方法，证明了其在EEG中心情感识别中的有效性。&lt;h4&gt;结论&lt;/h4&gt;PhysioSync框架通过有效的预训练和特征融合方法，显著提高了EEG中心情感识别的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：脑电图（EEG）信号提供了关于情绪状态相关脑活动的有希望的无意识反映，相较于面部表情等行为线索具有显著优势。然而，EEG信号经常受到噪声和伪影的影响，并且因个体差异而变化，这使得情感识别变得复杂。虽然多模态方法使用了如皮肤电（GSR）等外周生理信号（PPS）来补充EEG，但它们往往忽视了模态间的动态同步和一致性语义。此外，PPS中情绪波动在不同时间分辨率上的时间动态仍被低估。为了解决这些挑战，我们提出了一种名为PhysioSync的新颖的预训练框架，该框架利用时间和跨模态对比学习，灵感来源于生理同步现象。PhysioSync结合了交叉模态一致性对齐（CM-CA）来建模EEG和补充PPS之间的动态关系，使跨模态的情绪同步成为可能。此外，它引入了长短期时间对比学习（LS-TCL）来捕捉模态内部不同时间分辨率上的情绪同步。预训练后，跨分辨率和跨模态特征被分层融合并微调以提高情感识别。在DEAP和DREAMER数据集上的实验证明了PhysioSync在单模态和跨模态条件下的先进性能，突出了其在EEG中心情感识别中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroencephalography (EEG) signals provide a promising and involuntaryreflection of brain activity related to emotional states, offering significantadvantages over behavioral cues like facial expressions. However, EEG signalsare often noisy, affected by artifacts, and vary across individuals,complicating emotion recognition. While multimodal approaches have usedPeripheral Physiological Signals (PPS) like GSR to complement EEG, they oftenoverlook the dynamic synchronization and consistent semantics between themodalities. Additionally, the temporal dynamics of emotional fluctuationsacross different time resolutions in PPS remain underexplored. To address thesechallenges, we propose PhysioSync, a novel pre-training framework leveragingtemporal and cross-modal contrastive learning, inspired by physiologicalsynchronization phenomena. PhysioSync incorporates Cross-Modal ConsistencyAlignment (CM-CA) to model dynamic relationships between EEG and complementaryPPS, enabling emotion-related synchronizations across modalities. Besides, itintroduces Long- and Short-Term Temporal Contrastive Learning (LS-TCL) tocapture emotional synchronization at different temporal resolutions withinmodalities. After pre-training, cross-resolution and cross-modal features arehierarchically fused and fine-tuned to enhance emotion recognition. Experimentson DEAP and DREAMER datasets demonstrate PhysioSync's advanced performanceunder uni-modal and cross-modal conditions, highlighting its effectiveness forEEG-centered emotion recognition.</description>
      <author>example@mail.com (Kai Cui, Jia Li, Yu Liu, Xuesong Zhang, Zhenzhen Hu, Meng Wang)</author>
      <guid isPermaLink="false">2504.17163v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>HeRB: Heterophily-Resolved Structure Balancer for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.17276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了图神经网络（GNNs）在图数据表示领域的显著进步，并提出了一种名为HeRB的方法来解决GNNs中结构不平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;GNNs在处理图数据时遇到了结构不平衡的挑战，先前的方法没有考虑图异质性的影响，导致效果不足。&lt;h4&gt;目的&lt;/h4&gt;提出HeRB方法，首先解决图异质性问题，然后转移同质性知识，以提升GNNs的性能。&lt;h4&gt;方法&lt;/h4&gt;HeRB方法包括两个创新组件：1) 一个减少跨类边并增加同类边的无异质性增强模块；2) 一个将同质性信息从头部节点传递到尾部节点的同质性知识转移机制。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HeRB在两个同质性和六个异质性基准数据集上实现了优异的性能，消融研究进一步验证了两个提出的组件的有效性。&lt;h4&gt;结论&lt;/h4&gt;HeRB方法有效提升了GNNs在处理图数据时的性能，特别是在解决结构不平衡问题上表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has witnessed the remarkable progress of Graph NeuralNetworks (GNNs) in the realm of graph data representation. However, GNNs stillencounter the challenge of structural imbalance. Prior solutions to thisproblem did not take graph heterophily into account, namely that connectednodes process distinct labels or features, thus resulting in a deficiency ineffectiveness. Upon verifying the impact of heterophily on solving thestructural imbalance problem, we propose to rectify the heterophily first andthen transfer homophilic knowledge. To the end, we devise a method named HeRB(Heterophily-Resolved Structure Balancer) for GNNs. HeRB consists of twoinnovative components: 1) A heterophily-lessening augmentation module whichserves to reduce inter-class edges and increase intra-class edges; 2) Ahomophilic knowledge transfer mechanism to convey homophilic information fromhead nodes to tail nodes. Experimental results demonstrate that HeRB achievessuperior performance on two homophilic and six heterophilic benchmark datasets,and the ablation studies further validate the efficacy of two proposedcomponents.</description>
      <author>example@mail.com (Ke-Jia Chen, Wenhui Mu, Zheng Liu)</author>
      <guid isPermaLink="false">2504.17276v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos</title>
      <link>http://arxiv.org/abs/2504.17343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TimeChat-Online的新型在线视频语言模型，它通过创新的Differential Token Drop（DTD）模块解决了在线视频理解中的视觉冗余问题，实现了实时视频交互。&lt;h4&gt;背景&lt;/h4&gt;随着在线视频平台的快速发展，尤其是直播服务，对实时视频理解系统的需求变得迫切。现有的视频大语言模型在处理完整视频方面表现出色，但在流媒体场景中存在处理密集、冗余帧的局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理连续视频流并即时响应用户查询的实时视频理解系统。&lt;h4&gt;方法&lt;/h4&gt;提出了TimeChat-Online，其核心是DTD模块，该模块通过模仿人类的视觉感知中的变化盲现象，在流媒体视频中保留有意义的时序变化，同时过滤掉帧之间的静态、冗余内容。&lt;h4&gt;主要发现&lt;/h4&gt;DTD模块实现了视频token数量的82.8%减少，同时在StreamingBench上的性能保持98%，表明超过80%的流媒体视频中的视觉内容是自然冗余的，不需要语言指导。TimeChat-Online还具备独特的主动响应能力，通过DTD模块连续监控视频场景转换。&lt;h4&gt;结论&lt;/h4&gt;TimeChat-Online在流媒体基准测试（StreamingBench和OvOBench）中表现出色，在长视频任务（如Video-MME和MLVU）上也能保持有竞争力的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着在线视频平台的快速增长，尤其是直播服务，对实时视频理解系统的需求变得迫切。这些系统必须处理连续的视频流并即时响应用户查询，这对当前的视频大语言模型（VideoLLMs）提出了独特的挑战。尽管现有的VideoLLMs在处理完整视频方面表现出色，但由于无法有效地处理密集、冗余的帧，它们在流媒体场景中存在显著的局限性。我们介绍了TimeChat-Online，这是一种新的在线VideoLLM，它革命性地改变了实时视频交互。其核心是我们的创新Differential Token Drop（DTD）模块，它解决了流媒体视频中视觉冗余的根本挑战。我们从人类视觉感知中的变化盲现象中汲取灵感，DTD在保留有意义的时序变化的同时，过滤掉帧之间的静态、冗余内容。令人惊讶的是，我们的实验表明DTD实现了视频token数量的82.8%减少，同时在StreamingBench上的性能保持98%，这表明超过80%的流媒体视频中的视觉内容是自然冗余的，不需要语言指导。为了实现无缝的实时交互，我们提出了TimeChat-Online-139K，这是一个综合的流媒体视频数据集，包括多种交互模式，如回溯、当前感知和未来响应场景。TimeChat-Online独特的主动响应能力，通过DTD模块自然地连续监控视频场景转换，使其区别于传统方法。我们广泛的评估表明TimeChat-Online在流媒体基准测试（StreamingBench和OvOBench）中表现出色，在长视频任务（如Video-MME和MLVU）上也能保持有竞争力的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of online video platforms, particularly live streamingservices, has created an urgent need for real-time video understanding systems.These systems must process continuous video streams and respond to user queriesinstantaneously, presenting unique challenges for current Video Large LanguageModels (VideoLLMs). While existing VideoLLMs excel at processing completevideos, they face significant limitations in streaming scenarios due to theirinability to handle dense, redundant frames efficiently. We introduceTimeChat-Online, a novel online VideoLLM that revolutionizes real-time videointeraction. At its core lies our innovative Differential Token Drop (DTD)module, which addresses the fundamental challenge of visual redundancy instreaming videos. Drawing inspiration from human visual perception's ChangeBlindness phenomenon, DTD preserves meaningful temporal changes while filteringout static, redundant content between frames. Remarkably, our experimentsdemonstrate that DTD achieves an 82.8% reduction in video tokens whilemaintaining 98% performance on StreamingBench, revealing that over 80% ofvisual content in streaming videos is naturally redundant without requiringlanguage guidance. To enable seamless real-time interaction, we presentTimeChat-Online-139K, a comprehensive streaming video dataset featuring diverseinteraction patterns including backward-tracing, current-perception, andfuture-responding scenarios. TimeChat-Online's unique Proactive Responsecapability, naturally achieved through continuous monitoring of video scenetransitions via DTD, sets it apart from conventional approaches. Our extensiveevaluation demonstrates TimeChat-Online's superior performance on streamingbenchmarks (StreamingBench and OvOBench) and maintaining competitive results onlong-form video tasks such as Video-MME and MLVU.</description>
      <author>example@mail.com (Linli Yao, Yicheng Li, Yuancheng Wei, Lei Li, Shuhuai Ren, Yuanxin Liu, Kun Ouyang, Lean Wang, Shicheng Li, Sida Li, Lingpeng Kong, Qi Liu, Yuanxing Zhang, Xu Sun)</author>
      <guid isPermaLink="false">2504.17343v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2504.17432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures, Project page: https://garygutc.github.io/UniME&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UniME是一种新型的两阶段框架，利用多模态大型语言模型（MLLMs）来学习各种下游任务的判别性表示。&lt;h4&gt;背景&lt;/h4&gt;CLIP框架在多模态表示学习中广泛使用，但存在文本标记截断、图像-文本编码孤立以及由于词袋行为导致的组合性不足等关键限制。&lt;h4&gt;目的&lt;/h4&gt;提出UniME框架，以克服CLIP框架的局限性，并通过MLLMs学习可迁移的多模态表示。&lt;h4&gt;方法&lt;/h4&gt;第一阶段，从基于强大LLM的教师模型进行文本判别性知识蒸馏，以增强MLLM语言组件的嵌入能力；第二阶段，引入增强的硬负样本指令微调，以进一步推进判别性表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;UniME在MMEB基准和多个检索任务上进行了广泛实验，包括短和长标题检索以及组合检索，结果表明UniME在所有任务上都实现了持续的性能提升，展现出优越的判别性和组合能力。&lt;h4&gt;结论&lt;/h4&gt;UniME通过改进判别能力和增强下游任务中的指令跟随能力，为多模态表示学习提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Contrastive Language-Image Pre-training (CLIP) framework has become awidely used approach for multimodal representation learning, particularly inimage-text retrieval and clustering. However, its efficacy is constrained bythree key limitations: (1) text token truncation, (2) isolated image-textencoding, and (3) deficient compositionality due to bag-of-words behavior.While recent Multimodal Large Language Models (MLLMs) have demonstratedsignificant advances in generalized vision-language understanding, theirpotential for learning transferable multimodal representations remainsunderexplored.In this work, we present UniME (Universal Multimodal Embedding),a novel two-stage framework that leverages MLLMs to learn discriminativerepresentations for diverse downstream tasks. In the first stage, we performtextual discriminative knowledge distillation from a powerful LLM-based teachermodel to enhance the embedding capability of the MLLM\'s language component. Inthe second stage, we introduce hard negative enhanced instruction tuning tofurther advance discriminative representation learning. Specifically, weinitially mitigate false negative contamination and then sample multiple hardnegatives per instance within each batch, forcing the model to focus onchallenging samples. This approach not only improves discriminative power butalso enhances instruction-following ability in downstream tasks. We conductextensive experiments on the MMEB benchmark and multiple retrieval tasks,including short and long caption retrieval and compositional retrieval. Resultsdemonstrate that UniME achieves consistent performance improvement across alltasks, exhibiting superior discriminative and compositional capabilities.</description>
      <author>example@mail.com (Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng)</author>
      <guid isPermaLink="false">2504.17432v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Fine-tune Smarter, Not Harder: Parameter-Efficient Fine-Tuning for Geospatial Foundation Models</title>
      <link>http://arxiv.org/abs/2504.17397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at https://github.com/IBM/peft-geofm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了地球观测（EO）中基础模型的应用和参数高效微调（PEFT）技术的效果，以实现准确和高效的地理信息提取。&lt;h4&gt;背景&lt;/h4&gt;地球观测对于监测环境变化、应对灾害和管理自然资源至关重要。然而，随着模型规模的增大，微调变得越来越困难，限制了其可访问性和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;通过实验评估PEFT技术在五个不同地球观测数据集上的有效性，并探讨其如何支持预训练地理空间模型的适应。&lt;h4&gt;方法&lt;/h4&gt;进行广泛的实验，涉及不同的基础模型架构和PEFT技术，并对结果进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;PEFT技术能够匹配甚至超过全微调的性能，同时增强模型对未见地理区域的泛化能力，并减少训练时间和内存需求。&lt;h4&gt;结论&lt;/h4&gt;PEFT技术是提高地球观测模型适应性的有效方法，且通过TerraTorch开源包实现了快速、可扩展和成本效益高的模型适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：地球观测（EO）对于监测环境变化、应对灾害以及管理自然资源至关重要。在此背景下，基础模型有助于远程传感图像分析，以准确和高效地获取相关地理信息。然而，随着这些模型规模的增大，由于相关的计算资源和成本，微调变得越来越具有挑战性，限制了其可访问性和可扩展性。此外，完全微调可能导致忘记预训练特征，甚至降低模型泛化能力。为了解决这个问题，参数高效微调（PEFT）技术提供了一种有希望的方法。在本文中，我们通过各种基础模型架构和PEFT技术进行了广泛的实验，以评估它们在五个不同地球观测数据集上的有效性。我们的结果提供了一个全面的比较，提供了关于何时以及如何使用PEFT方法支持预训练地理空间模型适应的见解。我们证明了PEFT技术匹配甚至超过全微调的性能，并增强了模型对未见地理区域的泛化能力，同时减少了训练时间和内存需求。另外的实验研究了架构选择的影响，如解码器类型或元数据的使用，建议使用UNet解码器和无需元数据的微调作为推荐配置。我们将所有评估的基础模型和技术整合到开源包TerraTorch中，以支持快速、可扩展和成本效益高的模型适应。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Earth observation (EO) is crucial for monitoring environmental changes,responding to disasters, and managing natural resources. In this context,foundation models facilitate remote sensing image analysis to retrieve relevantgeoinformation accurately and efficiently. However, as these models grow insize, fine-tuning becomes increasingly challenging due to the associatedcomputational resources and costs, limiting their accessibility andscalability. Furthermore, full fine-tuning can lead to forgetting pre-trainedfeatures and even degrade model generalization. To address this,Parameter-Efficient Fine-Tuning (PEFT) techniques offer a promising solution.In this paper, we conduct extensive experiments with various foundation modelarchitectures and PEFT techniques to evaluate their effectiveness on fivedifferent EO datasets. Our results provide a comprehensive comparison, offeringinsights into when and how PEFT methods support the adaptation of pre-trainedgeospatial models. We demonstrate that PEFT techniques match or even exceedfull fine-tuning performance and enhance model generalisation to unseengeographic regions, while reducing training time and memory requirements.Additional experiments investigate the effect of architecture choices such asthe decoder type or the use of metadata, suggesting UNet decoders andfine-tuning without metadata as the recommended configuration. We haveintegrated all evaluated foundation models and techniques into the open-sourcepackage TerraTorch to support quick, scalable, and cost-effective modeladaptation.</description>
      <author>example@mail.com (Francesc Marti-Escofet, Benedikt Blumenstiel, Linus Scheibenreif, Paolo Fraccaro, Konrad Schindler)</author>
      <guid isPermaLink="false">2504.17397v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm</title>
      <link>http://arxiv.org/abs/2504.17540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于深度学习的框架，用于自动检测猴痘，通过使用迁移学习、降维和高级机器学习技术，以提高早期和准确的诊断，从而有效管理疾病。&lt;h4&gt;背景&lt;/h4&gt;近年来，猴痘在全球范围内的传播，尤其是在以往没有流行过的地区，引发了重大的公共卫生关注。&lt;h4&gt;目的&lt;/h4&gt;为了有效管理疾病和控制猴痘，本研究旨在开发一个自动检测猴痘的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;研究使用了新的猴痘皮肤病变数据集（MSLD），其中包括猴痘、水痘和麻疹的图像，并采用了Xception架构进行深度特征提取，随后使用主成分分析（PCA）进行降维，并使用自然梯度提升（NGBoost）算法进行分类。为了优化模型性能和泛化能力，引入了非洲秃鹫优化算法（AVOA）进行超参数调整。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的AVOA-NGBoost模型实现了最先进的性能，准确率为97.53%，F1分数为97.72%，AUC为97.47%。此外，还使用Grad-CAM和LIME技术增强了模型的可解释性，揭示了决策过程和影响分类的关键特征。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种高度精确和高效的诊断工具，有助于医疗保健提供者在资源受限的环境中早期检测和诊断猴痘。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近猴痘在全球范围内的传播，尤其是在历史上未曾流行的地区，引起了重大的公共卫生担忧。早期和准确的诊断对于有效的疾病管理和控制至关重要。为此，本研究提出了一种基于深度学习的框架，用于从皮肤病变图像中自动检测猴痘，利用迁移学习、降维和高级机器学习技术的力量。我们使用了新开发的猴痘皮肤病变数据集（MSLD），该数据集包括猴痘、水痘和麻疹的图像，以训练和评估我们的模型。所提出的框架采用了Xception架构进行深度特征提取，随后使用主成分分析（PCA）进行降维，并使用自然梯度提升（NGBoost）算法进行分类。为了优化模型性能和泛化，我们引入了非洲秃鹫优化算法（AVOA）进行超参数调整，确保参数空间的效率探索。我们的结果表明，所提出的AVOA-NGBoost模型实现了最先进的性能，准确率为97.53%，F1分数为97.72%，AUC为97.47%。此外，我们还使用Grad-CAM和LIME技术增强了模型的可解释性，揭示了决策过程和影响分类的关键特征。该框架提供了一种高度精确和高效的诊断工具，可能有助于医疗保健提供者在资源受限的环境中早期检测和诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent global spread of monkeypox, particularly in regions where it hasnot historically been prevalent, has raised significant public health concerns.Early and accurate diagnosis is critical for effective disease management andcontrol. In response, this study proposes a novel deep learning-based frameworkfor the automated detection of monkeypox from skin lesion images, leveragingthe power of transfer learning, dimensionality reduction, and advanced machinelearning techniques. We utilize the newly developed Monkeypox Skin LesionDataset (MSLD), which includes images of monkeypox, chickenpox, and measles, totrain and evaluate our models. The proposed framework employs the Xceptionarchitecture for deep feature extraction, followed by Principal ComponentAnalysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting(NGBoost) algorithm for classification. To optimize the model's performance andgeneralization, we introduce the African Vultures Optimization Algorithm (AVOA)for hyperparameter tuning, ensuring efficient exploration of the parameterspace. Our results demonstrate that the proposed AVOA-NGBoost model achievesstate-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72%and an AUC of 97.47%. Additionally, we enhance model interpretability usingGrad-CAM and LIME techniques, providing insights into the decision-makingprocess and highlighting key features influencing classification. Thisframework offers a highly precise and efficient diagnostic tool, potentiallyaiding healthcare providers in early detection and diagnosis, particularly inresource-constrained environments.</description>
      <author>example@mail.com (Ahmadreza Shateri, Negar Nourani, Morteza Dorrigiv, Hamid Nasiri)</author>
      <guid isPermaLink="false">2504.17540v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing</title>
      <link>http://arxiv.org/abs/2504.17213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MCAF是一种基于代理的训练免费框架，通过多模态粗到细注意力聚焦进行视频理解，显著提高了视频理解性能。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在快速发展，但视频理解，尤其是长视频理解，仍然极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出MCAF框架，以解决视频信息冗余和全局注意力分配问题，实现准确的视频理解。&lt;h4&gt;方法&lt;/h4&gt;MCAF通过以下方式实现视频理解：1）通过多模态信息对高度相关的视频片段进行分层关注；2）采用时间扩展机制减少从集中帧中提取信息时遗漏关键细节的风险；3）利用模型响应的置信度作为反馈，实现自我反思。&lt;h4&gt;主要发现&lt;/h4&gt;MCAF在EgoSchema数据集上比领先方法提高了5%的性能；在Next-QA和IntentQA数据集上分别比当前最先进的标准提高了0.2%和0.3%；在Video-MME数据集上，也优于其他基于代理的方法。&lt;h4&gt;结论&lt;/h4&gt;MCAF在视频理解任务上优于现有的最先进方法，有效提高了视频理解的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even in the era of rapid advances in large models, video understanding,particularly long videos, remains highly challenging. Compared with textual orimage-based information, videos commonly contain more information withredundancy, requiring large models to strategically allocate attention at aglobal level for accurate comprehension. To address this, we propose MCAF, anagent-based, training-free framework perform video understanding throughMultimodal Coarse-to-fine Attention Focusing. The key innovation lies in itsability to sense and prioritize segments of the video that are highly relevantto the understanding task. First, MCAF hierarchically concentrates on highlyrelevant frames through multimodal information, enhancing the correlationbetween the acquired contextual information and the query. Second, it employs adilated temporal expansion mechanism to mitigate the risk of missing crucialdetails when extracting information from these concentrated frames. Inaddition, our framework incorporates a self-reflection mechanism utilizing theconfidence level of the model's responses as feedback. By iteratively applyingthese two creative focusing strategies, it adaptively adjusts attention tocapture highly query-connected context and thus improves response accuracy.MCAF outperforms comparable state-of-the-art methods on average. On theEgoSchema dataset, it achieves a remarkable 5% performance gain over theleading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperformsthe current state-of-the-art standard by 0.2% and 0.3% respectively. On theVideo-MME dataset, which features videos averaging nearly an hour in length,MCAF also outperforms other agent-based methods.</description>
      <author>example@mail.com (Shiwen Cao, Zhaoxing Zhang, Junming Jiao, Juyi Qiao, Guowen Song, Rong Shen)</author>
      <guid isPermaLink="false">2504.17213v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>On the workflow, opportunities and challenges of developing foundation model in geophysics</title>
      <link>http://arxiv.org/abs/2504.17384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一套完整的框架，用于系统地探讨与地球物理数据结合开发基础模型的全过程。&lt;h4&gt;背景&lt;/h4&gt;基础模型作为人工智能的主流技术，近年来在处理复杂任务和多模态数据方面展现出巨大潜力。在地球物理学领域，虽然基础模型的应用正在逐步扩展，但目前缺乏对整合基础模型与地球物理数据全工作流程的全面综述。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，本文旨在提供一个全面框架，系统地探讨与地球物理数据结合开发基础模型的全过程。&lt;h4&gt;方法&lt;/h4&gt;本文从数据收集和预处理到模型架构选择、预训练策略和模型部署，详细分析了每个阶段的关键技术和方法。特别地，考虑到地球物理数据的多样性、复杂性和物理一致性约束，本文讨论了针对这些挑战的特定解决方案。此外，本文还讨论了如何利用基础模型的迁移学习能力来减少对标记数据的依赖，提高计算效率，并将物理约束纳入模型训练，从而提高物理一致性和可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;本文不仅填补了地球物理学领域关于基础模型全流程综述的空白，还为地球物理数据分析中的应用提供了有价值的实践指导，推动了该领域的创新和进步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的框架为地球物理数据中的基础模型应用提供了系统的方法和策略，有助于提高模型性能和地球物理数据分析的效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a comprehensive framework for systematically exploring the entire process of developing foundation models in conjunction with geophysical data. From data collection and preprocessing to model architecture selection, pre-training strategies, and model deployment, a detailed analysis of the key techniques and methodologies at each stage is provided. In particular, considering the diversity, complexity, and physical consistency constraints of geophysical data, targeted solutions to address these challenges are discussed. Furthermore, strategies for leveraging the transfer learning capabilities of foundation models to reduce reliance on labeled data, enhance computational efficiency, and incorporate physical constraints into model training are presented, thereby improving physical consistency and interpretability. Through a comprehensive summary and analysis of the current technological landscape, this paper not only fills the gap in the geophysics domain regarding a full-process review of foundation models but also offers valuable practical guidance for their application in geophysical data analysis, driving innovation and advancement in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, as a mainstream technology in artificial intelligence,have demonstrated immense potential across various domains in recent years,particularly in handling complex tasks and multimodal data. In the field ofgeophysics, although the application of foundation models is graduallyexpanding, there is currently a lack of comprehensive reviews discussing thefull workflow of integrating foundation models with geophysical data. Toaddress this gap, this paper presents a complete framework that systematicallyexplores the entire process of developing foundation models in conjunction withgeophysical data. From data collection and preprocessing to model architectureselection, pre-training strategies, and model deployment, we provide a detailedanalysis of the key techniques and methodologies at each stage. In particular,considering the diversity, complexity, and physical consistency constraints ofgeophysical data, we discuss targeted solutions to address these challenges.Furthermore, we discuss how to leverage the transfer learning capabilities offoundation models to reduce reliance on labeled data, enhance computationalefficiency, and incorporate physical constraints into model training, therebyimproving physical consistency and interpretability. Through a comprehensivesummary and analysis of the current technological landscape, this paper notonly fills the gap in the geophysics domain regarding a full-process review offoundation models but also offers valuable practical guidance for theirapplication in geophysical data analysis, driving innovation and advancement inthe field.</description>
      <author>example@mail.com (Hanlin Sheng, Xinming Wu, Hang Gao, Haibin Di, Sergey Fomel, Jintao Li, Xu Si)</author>
      <guid isPermaLink="false">2504.17384v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs</title>
      <link>http://arxiv.org/abs/2504.17040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为DyMU的框架，该框架在无需训练的情况下，动态减少视觉语言模型（VLMs）的计算负担，同时保持高任务性能。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型在处理图像和文本数据时，计算负担较大，且固定长度的输出在视觉Transformer中存在固有低效问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，能够在不牺牲任务性能的情况下，降低视觉语言模型的计算成本。&lt;h4&gt;方法&lt;/h4&gt;DyMU包含两个关键组件：动态标记合并（DToMe）和虚拟标记解合并（VTU）。DToMe通过根据图像复杂度合并相似标记来减少视觉标记嵌入的数量；VTU通过高效重建完整序列的注意力动态来模拟大型语言模型（LLMs）期望的标记序列。&lt;h4&gt;主要发现&lt;/h4&gt;DyMU在图像和视频理解任务上进行了广泛的实验，结果表明，它可以平均减少32%-85%的视觉标记计数，同时在不同VLM架构上实现与全长模型相当的性能，包括流行的AnyRes视觉编码器。通过定性分析，发现DToMe能够根据图像复杂度有效地调整标记减少，并且与现有系统不同，为用户提供更多控制计算成本的能力。&lt;h4&gt;结论&lt;/h4&gt;DyMU是一种高效、无需训练的框架，能够动态地降低视觉语言模型的计算负担，同时保持高任务性能，适用于大多数最先进的VLM架构。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为DyMU的框架，该框架在无需训练的情况下，动态减少视觉语言模型（VLMs）的计算负担，同时保持高任务性能。我们的方法包含两个关键组件。首先，动态标记合并（DToMe）通过基于图像复杂度合并相似标记来减少视觉标记嵌入的数量，解决了视觉Transformer中固定长度输出的固有低效问题。其次，虚拟标记解合并（VTU）通过高效重建完整序列的注意力动态来模拟大型语言模型（LLMs）期望的标记序列，从而在不进行额外微调的情况下保持下游性能。与先前的方法不同，我们的方法根据图像内容动态调整标记压缩，并且完全无需训练，使其适用于大多数最先进的VLM架构。在图像和视频理解任务上的广泛实验表明，DyMU可以减少平均视觉标记计数32%-85%，同时在不同的VLM架构上实现与全长模型相当的性能，包括最近流行的基于AnyRes的视觉编码器。此外，通过定性分析，我们发现DToMe能够根据图像复杂度有效地调整标记减少，并且与现有系统不同，为用户提供更多控制计算成本的能力。项目页面：https://mikewangwzhl.github.io/dymu/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DyMU, an efficient, training-free framework that dynamicallyreduces the computational burden of vision-language models (VLMs) whilemaintaining high task performance. Our approach comprises two key components.First, Dynamic Token Merging (DToMe) reduces the number of visual tokenembeddings by merging similar tokens based on image complexity, addressing theinherent inefficiency of fixed-length outputs in vision transformers. Second,Virtual Token Unmerging (VTU) simulates the expected token sequence for largelanguage models (LLMs) by efficiently reconstructing the attention dynamics ofa full sequence, thus preserving the downstream performance without additionalfine-tuning. Unlike previous approaches, our method dynamically adapts tokencompression to the content of the image and operates completely training-free,making it readily applicable to most state-of-the-art VLM architectures.Extensive experiments on image and video understanding tasks demonstrate thatDyMU can reduce the average visual token count by 32%-85% while achievingcomparable performance to full-length models across diverse VLM architectures,including the recently popularized AnyRes-based visual encoders. Furthermore,through qualitative analyses, we demonstrate that DToMe effectively adaptstoken reduction based on image complexity and, unlike existing systems,provides users more control over computational costs. Project page:https://mikewangwzhl.github.io/dymu/.</description>
      <author>example@mail.com (Zhenhailong Wang, Senthil Purushwalkam, Caiming Xiong, Silvio Savarese, Heng Ji, Ran Xu)</author>
      <guid isPermaLink="false">2504.17040v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Discovering the Precursors of Traffic Breakdowns Using Spatiotemporal Graph Attribution Networks</title>
      <link>http://arxiv.org/abs/2504.17109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合时空图神经网络（ST-GNN）和Shapley值的方法，用于识别和解释交通拥堵的前兆，以改善道路安全和交通流管理。&lt;h4&gt;背景&lt;/h4&gt;理解和预测交通拥堵的前兆对于提高道路安全和交通流管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过将Shapley解释方法扩展到时空环境，本研究旨在连接黑盒神经网络预测和可解释原因之间的差距。&lt;h4&gt;方法&lt;/h4&gt;本研究采用了一种新的方法，结合了时空图神经网络（ST-GNN）和Shapley值，以识别和解释交通拥堵的前兆。&lt;h4&gt;主要发现&lt;/h4&gt;在I-24州际公路数据上，研究揭示了道路拓扑和急刹车是导致交通拥堵的主要因素。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于识别和理解导致交通拥堵的关键因素，从而为改善交通流和道路安全提供依据。&lt;h4&gt;翻译&lt;/h4&gt;Understanding and predicting the precursors of traffic breakdowns is critical for improving road safety and traffic flow management. This paper presents a novel approach combining spatiotemporal graph neural networks (ST-GNNs) with Shapley values to identify and interpret traffic breakdown precursors. By extending Shapley explanation methods to a spatiotemporal setting, our proposed method bridges the gap between black-box neural network predictions and interpretable causes. We demonstrate the method on the Interstate-24 data, and identify that road topology and abrupt braking are major factors that lead to traffic breakdowns.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and predicting the precursors of traffic breakdowns is criticalfor improving road safety and traffic flow management. This paper presents anovel approach combining spatiotemporal graph neural networks (ST-GNNs) withShapley values to identify and interpret traffic breakdown precursors. Byextending Shapley explanation methods to a spatiotemporal setting, our proposedmethod bridges the gap between black-box neural network predictions andinterpretable causes. We demonstrate the method on the Interstate-24 data, andidentify that road topology and abrupt braking are major factors that lead totraffic breakdowns.</description>
      <author>example@mail.com (Zhaobin Mo, Xiangyi Liao, Dominik A. Karbowski, Yanbing Wang)</author>
      <guid isPermaLink="false">2504.17109v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition</title>
      <link>http://arxiv.org/abs/2504.17349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DRC的个性化图像生成框架，用于解决现有方法在融合用户风格偏好和语义意图时的不足，通过解耦表示组合增强LMMs，以实现可控和有效的个性化图像生成。&lt;h4&gt;背景&lt;/h4&gt;个性化图像生成是跨模态内容创作中的一个有前景方向，旨在通过利用用户交互的历史图像和多模态指令来合成符合个人风格偏好和语义意图的图像。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在准确捕捉和融合用户风格偏好和语义意图时的不足，特别是解决LMMs中视觉特征纠缠导致的Guidance Collapse问题。&lt;h4&gt;方法&lt;/h4&gt;DRC框架包括两个关键的学习阶段：1）解耦学习，使用双塔解耦器显式分离风格和语义特征，并通过重构驱动的范式和困难感知的重要性采样进行优化；2）个性化建模，应用语义保持的增强来有效适应解耦表示，以实现鲁棒的个性化生成。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准测试上的大量实验表明，DRC在性能上具有竞争力，并有效地缓解了Guidance Collapse问题，强调了解耦表示学习对于可控和有效的个性化图像生成的重要性。&lt;h4&gt;结论&lt;/h4&gt;DRC框架通过解耦表示组合，有效提升了LMMs在个性化图像生成中的性能，为该领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized image generation has emerged as a promising direction inmultimodal content creation. It aims to synthesize images tailored toindividual style preferences (e.g., color schemes, character appearances,layout) and semantic intentions (e.g., emotion, action, scene contexts) byleveraging user-interacted history images and multimodal instructions. Despitenotable progress, existing methods -- whether based on diffusion models, largelanguage models, or Large Multimodal Models (LMMs) -- struggle to accuratelycapture and fuse user style preferences and semantic intentions. In particular,the state-of-the-art LMM-based method suffers from the entanglement of visualfeatures, leading to Guidance Collapse, where the generated images fail topreserve user-preferred styles or reflect the specified semantics.  To address these limitations, we introduce DRC, a novel personalized imagegeneration framework that enhances LMMs through Disentangled RepresentationComposition. DRC explicitly extracts user style preferences and semanticintentions from history images and the reference image, respectively, to formuser-specific latent instructions that guide image generation within LMMs.Specifically, it involves two critical learning stages: 1) Disentanglementlearning, which employs a dual-tower disentangler to explicitly separate styleand semantic features, optimized via a reconstruction-driven paradigm withdifficulty-aware importance sampling; and 2) Personalized modeling, whichapplies semantic-preserving augmentations to effectively adapt the disentangledrepresentations for robust personalized generation. Extensive experiments ontwo benchmarks demonstrate that DRC shows competitive performance whileeffectively mitigating the guidance collapse issue, underscoring the importanceof disentangled representation learning for controllable and effectivepersonalized image generation.</description>
      <author>example@mail.com (Yiyan Xu, Wuqiang Zheng, Wenjie Wang, Fengbin Zhu, Xinting Hu, Yang Zhang, Fuli Feng, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2504.17349v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Dargana: fine-tuning EarthPT for dynamic tree canopy mapping from space</title>
      <link>http://arxiv.org/abs/2504.17321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures, spotlight at `Tackling Climate Change with  Machine Learning', ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Dargana，这是对EarthPT时间序列基础模型进行微调的变体，通过使用不到3%的预训练数据量和5%的预训练计算量实现专业化。Dargana经过微调，能够以10米分辨率定期更新树木冠层覆盖的分类，区分针叶和阔叶树木类型。&lt;h4&gt;背景&lt;/h4&gt;本文的研究背景是利用预训练的大规模观测模型（如EarthPT）进行土地覆盖的精细动态监测。&lt;h4&gt;目的&lt;/h4&gt;本文旨在展示如何利用预训练模型实现土地覆盖的精细动态监测，为自然资源管理和保护提供有价值的、可扩展的工具。&lt;h4&gt;方法&lt;/h4&gt;Dargana模型通过微调EarthPT模型，使用Cornwall地区的卫星图像进行测试，识别10米分辨率的树木冠层覆盖，并区分不同类型的树木。&lt;h4&gt;主要发现&lt;/h4&gt;Dargana模型在未见过的卫星图像上实现了像素级的ROC-AUC为0.98和PR-AUC为0.83。它能够识别训练样本限制以下的精细结构，如树篱和砍伐地，并追踪冠层覆盖随时间的变化，如新林地的建立。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，预训练的大型观测模型可以通过微调来专门用于空间上的精细土地覆盖监测，为自然资源管理和保护提供了有价值的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Dargana, a fine-tuned variant of the EarthPT time-seriesfoundation model that achieves specialisation using &lt;3% of its pre-trainingdata volume and 5% of its pre-training compute. Dargana is fine-tuned togenerate regularly updated classification of tree canopy cover at 10mresolution, distinguishing conifer and broadleaved tree types. Using Cornwall,UK, as a test case, the model achieves a pixel-level ROC-AUC of 0.98 and aPR-AUC of 0.83 on unseen satellite imagery. Dargana can identify finestructures like hedgerows and coppice below the training sample limit, and cantrack temporal changes to canopy cover such as new woodland establishment. Ourresults demonstrate how pre-trained Large Observation Models like EarthPT canbe specialised for granular, dynamic land cover monitoring from space,providing a valuable, scalable tool for natural capital management andconservation.</description>
      <author>example@mail.com (Michael J. Smith, Luke Fleming, James E. Geach, Ryan J. Roberts, Freddie Kalaitzis, James Banister)</author>
      <guid isPermaLink="false">2504.17321v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>The Riemannian Means Field Classifier for EEG-Based BCI Data</title>
      <link>http://arxiv.org/abs/2504.17352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究证明了Riemannian最小距离到均值（MDM）分类器在各类基于脑电图（EEG）的脑机接口（BCI）中的鲁棒性和准确性。提出了一种改进的MDM方法，通过分析多个公共数据库，证明了该方法在性能上优于传统的MDM，同时保持了简单性和确定性。&lt;h4&gt;背景&lt;/h4&gt;大量研究表明，Riemannian最小距离到均值（MDM）分类器在所有类型的基于EEG的BCI中表现出鲁棒性和准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进的MDM方法，通过使用多个幂平均数代替单一的几何平均数，以提升分类器的性能。&lt;h4&gt;方法&lt;/h4&gt;通过分析20个公共数据库，包括10个用于运动想象BCI范式和10个用于P300 BCI范式的数据库，总共包含587个个体，来评估改进的MDM方法。&lt;h4&gt;主要发现&lt;/h4&gt;改进的MDM方法在性能上明显优于传统的MDM，接近当前的最佳水平，同时保持了简单性和确定性。&lt;h4&gt;结论&lt;/h4&gt;改进的MDM方法在保持简单性和确定性的同时，显著提升了分类器的性能，并计划将相关代码以开源形式发布，以促进可重复研究。&lt;h4&gt;翻译&lt;/h4&gt;大量研究证明了Riemannian最小距离到均值（MDM）分类器在所有类型的基于脑电图（EEG）的脑机接口（BCI）中的鲁棒性和准确性。该分类器简单、完全确定、对噪声鲁棒、计算效率高，且易于迁移学习。其训练非常简单，只需计算每个类别的对称正定（SPD）矩阵的几何平均值。我们提出了一种改进的MDM方法，涉及使用多个SPD矩阵的幂平均数而不是单一的几何平均数。通过分析20个公共数据库，其中10个用于运动想象BCI范式，10个用于P300 BCI范式，总共包含587个个体，我们表明所提出的分类器在性能上明显优于MDM，在性能上接近当前的最佳水平，同时保持了简单性和确定性。为了促进可重复研究，我们的代码将以开源形式发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25072305&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A substantial amount of research has demonstrated the robustness and accuracyof the Riemannian minimum distance to mean (MDM) classifier for all kinds ofEEG-based brain--computer interfaces (BCIs). This classifier is simple, fullydeterministic, robust to noise, computationally efficient, and prone totransfer learning. Its training is very simple, requiring just the computationof a geometric mean of a symmetric positive-definite (SPD) matrix per class. Wepropose an improvement of the MDM involving a number of power means of SPDmatrices instead of the sole geometric mean. By the analysis of 20 publicdatabases, 10 for the motor-imagery BCI paradigm and 10 for the P300 BCIparadigm, comprising 587 individuals in total, we show that the proposedclassifier clearly outperforms the MDM, approaching the state-of-the art interms of performance while retaining the simplicity and the deterministicbehavior. In order to promote reproducible research, our code will be releasedas open source.</description>
      <author>example@mail.com (Anton Andreev, Grégoire Cattan, Marco Congedo)</author>
      <guid isPermaLink="false">2504.17352v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Class-Conditional Distribution Balancing for Group Robust Classification</title>
      <link>http://arxiv.org/abs/2504.17314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种解决模型因错误原因作出正确预测的虚假相关性问题的方法。&lt;h4&gt;背景&lt;/h4&gt;现有研究将此问题归因于群体不平衡，并通过最大化平衡群体或最坏群体准确性来解决，但这依赖于昂贵的偏差标注。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要偏差标注和预测的简单而有效的鲁棒学习方法，以减少虚假因素与标签信息之间的互信息。&lt;h4&gt;方法&lt;/h4&gt;通过重新定义虚假相关性为条件分布中的不平衡或错配，利用样本重加权策略来实现条件分布平衡，自动突出少数群体和类别，从而消除虚假相关性并产生用于分类的无偏差数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验和分析表明，该方法在性能上持续优于依赖偏差监督的方法。&lt;h4&gt;结论&lt;/h4&gt;该论文提出的方法能够有效解决虚假相关性问题，并在分类任务中实现无偏差的数据分布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spurious correlations that lead models to correct predictions for the wrongreasons pose a critical challenge for robust real-world generalization.Existing research attributes this issue to group imbalance and addresses it bymaximizing group-balanced or worst-group accuracy, which heavily relies onexpensive bias annotations. A compromise approach involves predicting biasinformation using extensively pretrained foundation models, which requireslarge-scale data and becomes impractical for resource-limited rare domains. Toaddress these challenges, we offer a novel perspective by reframing thespurious correlations as imbalances or mismatches in class-conditionaldistributions, and propose a simple yet effective robust learning method thateliminates the need for both bias annotations and predictions. With the goal ofreducing the mutual information between spurious factors and label information,our method leverages a sample reweighting strategy to achieve class-conditionaldistribution balancing, which automatically highlights minority groups andclasses, effectively dismantling spurious correlations and producing a debiaseddata distribution for classification. Extensive experiments and analysisdemonstrate that our approach consistently delivers state-of-the-artperformance, rivaling methods that rely on bias supervision.</description>
      <author>example@mail.com (Miaoyun Zhao, Qiang Zhang, Chenrong Li)</author>
      <guid isPermaLink="false">2504.17314v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo</title>
      <link>http://arxiv.org/abs/2504.17252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 14 combined figures (19 total), includes horizontal  layouts. Submitted to arXiv for open access&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了基于神经机器翻译（NMT）和Transformer的迁移学习模型，用于英语到伊博语的翻译，伊博语是一种在尼日利亚和西非地区由超过4000万人使用的低资源非洲语言。&lt;h4&gt;背景&lt;/h4&gt;伊博语是一种低资源的非洲语言，而现有的英语到伊博语的翻译模型效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提高英语到伊博语的翻译准确性。&lt;h4&gt;方法&lt;/h4&gt;在经过专家验证的、由圣经、本地新闻、维基百科文章和Common Crawl组成的基准数据集上训练模型。模型架构包括RNN，如LSTM和GRU，并增强了注意力机制。此外，还使用了MarianNMT预训练模型和SimpleTransformers框架进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;基于RNN的系统达到了与现有英语到伊博语基准相当的结果。应用迁移学习后，性能提升了+4.83 BLEU分，估计翻译准确率达到70%。&lt;h4&gt;结论&lt;/h4&gt;将RNN与迁移学习相结合，可以有效地解决低资源语言翻译任务中的性能差距问题。&lt;h4&gt;翻译&lt;/h4&gt;本研究开发了一种基于神经机器翻译（NMT）和Transformer的迁移学习模型，用于英语到伊博语的翻译，伊博语是一种在尼日利亚和西非地区由超过4000万人使用的低资源非洲语言。模型在经过专家验证的、由圣经、本地新闻、维基百科文章和Common Crawl组成的基准数据集上训练，并利用了RNN架构，包括LSTM和GRU，以及注意力机制。此外，还采用了MarianNMT预训练模型和SimpleTransformers框架进行迁移学习。实验结果表明，基于RNN的系统在翻译准确率上与现有英语到伊博语的基准相当，应用迁移学习后，性能提升了+4.83 BLEU分，估计翻译准确率达到70%。这些发现突出了将RNN与迁移学习相结合在解决低资源语言翻译任务性能差距方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we develop Neural Machine Translation (NMT) andTransformer-based transfer learning models for English-to-Igbo translation - alow-resource African language spoken by over 40 million people across Nigeriaand West Africa. Our models are trained on a curated and benchmarked datasetcompiled from Bible corpora, local news, Wikipedia articles, and Common Crawl,all verified by native language experts. We leverage Recurrent Neural Network(RNN) architectures, including Long Short-Term Memory (LSTM) and GatedRecurrent Units (GRU), enhanced with attention mechanisms to improvetranslation accuracy. To further enhance performance, we apply transferlearning using MarianNMT pre-trained models within the SimpleTransformersframework. Our RNN-based system achieves competitive results, closely matchingexisting English-Igbo benchmarks. With transfer learning, we observe aperformance gain of +4.83 BLEU points, reaching an estimated translationaccuracy of 70%. These findings highlight the effectiveness of combining RNNswith transfer learning to address the performance gap in low-resource languagetranslation tasks.</description>
      <author>example@mail.com (Ocheme Anthony Ekle, Biswarup Das)</author>
      <guid isPermaLink="false">2504.17252v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation</title>
      <link>http://arxiv.org/abs/2504.17207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://apc-vlm.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过心理意象模拟实现视觉语言模型（VLMs）中的视角感知推理框架。&lt;h4&gt;背景&lt;/h4&gt;视角感知，即从不同视角感知环境或情况的能力，是人类视觉理解的关键基准，对于与自主代理的环境交互和协作至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了弥合VLMs与人类感知之间的差距，本文重点关注心理意象在视角转换中的作用。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个名为抽象视角变化（APC）的框架，该框架有效地利用视觉基础模型（如目标检测、分割和方向估计）来构建场景抽象并实现视角变换。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实图像基准上的实验表明，与各种VLMs相比，本文的框架在视角感知推理方面取得了显著改进，并优于微调的空間推理模型和基于新视角合成的方案。&lt;h4&gt;结论&lt;/h4&gt;APC框架为VLMs提供了视角感知推理的能力，有助于提高VLMs在环境交互和协作中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a framework for perspective-aware reasoning in vision-languagemodels (VLMs) through mental imagery simulation. Perspective-taking, theability to perceive an environment or situation from an alternative viewpoint,is a key benchmark for human-level visual understanding, essential forenvironmental interaction and collaboration with autonomous agents. Despiteadvancements in spatial reasoning within VLMs, recent research has shown thatmodern VLMs significantly lack perspective-aware reasoning capabilities andexhibit a strong bias toward egocentric interpretations. To bridge the gapbetween VLMs and human perception, we focus on the role of mental imagery,where humans perceive the world through abstracted representations thatfacilitate perspective shifts. Motivated by this, we propose a framework forperspective-aware reasoning, named Abstract Perspective Change (APC), thateffectively leverages vision foundation models, such as object detection,segmentation, and orientation estimation, to construct scene abstractions andenable perspective transformations. Our experiments on synthetic and real-imagebenchmarks, compared with various VLMs, demonstrate significant improvements inperspective-aware reasoning with our framework, further outperformingfine-tuned spatial reasoning models and novel-view-synthesis-based approaches.</description>
      <author>example@mail.com (Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung)</author>
      <guid isPermaLink="false">2504.17207v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs</title>
      <link>http://arxiv.org/abs/2504.17006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is a result of the collaboration by JACOBB, AMII(Alberta Machine  Intelligence Institute), Thales and AI Redefined (AIR) in 2021-2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多层分层人机交互深度强化学习（HITL DRL）算法，并探讨了HITL在解决复杂问题中的挑战、权衡和优势。&lt;h4&gt;背景&lt;/h4&gt;随着深度强化学习（DRL）的日益流行，人机交互（HITL）方法有望革新决策问题的处理方式，并为人类与人工智能合作创造新的机遇。&lt;h4&gt;目的&lt;/h4&gt;设计一种可扩展的HITL DRL算法，用于盟军无人机在中敌机到达受限区域前将其摧毁。&lt;h4&gt;方法&lt;/h4&gt;算法包含自我学习、模仿学习和迁移学习三种学习方式，并考虑了奖励、动作和演示三种人类输入形式。&lt;h4&gt;主要发现&lt;/h4&gt;HITL能够加快训练速度并提高性能，建议作为梯度方法的指导方向，降低方差，但建议的数量不应过多或过少，以避免过拟合和欠拟合。&lt;h4&gt;结论&lt;/h4&gt;HITL在解决复杂问题时具有重要作用，人类与人工智能的合作对于解决两个真实世界的复杂场景（如超载和诱饵攻击）至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着深度强化学习（DRL）的日益流行，人机交互（HITL）方法有潜力改变我们处理决策问题的方法，并为人类-人工智能合作开辟新的机会。在本文中，我们介绍了一种新颖的多层分层人机交互深度强化学习（HITL DRL）算法，该算法包括三种学习类型：自我学习、模仿学习和迁移学习。此外，我们考虑了三种形式的人类输入：奖励、动作和演示。此外，我们讨论了HITL在解决复杂问题中的主要挑战、权衡和优势以及如何系统地整合人类信息到人工智能解决方案中。为了验证我们的技术成果，我们提出一个真实世界的无人机问题，其中多个敌机攻击一个受限区域。目标是设计一个可扩展的HITL DRL算法，用于盟军无人机在中敌机到达受限区域前将其摧毁。为此，我们首先使用一个名为Cogment的获奖开源HITL软件实现了我们的解决方案。然后，我们展示了一些有趣的结果，例如（a）HITL导致更快的学习和更高的性能，（b）建议作为梯度方法的指导方向，降低方差，（c）建议的数量既不应过多也不应过少，以避免过拟合和欠拟合。最后，我们说明了人类-人工智能合作在解决两个真实世界复杂场景中的作用，即超载和诱饵攻击。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing popularity of deep reinforcement learning (DRL),human-in-the-loop (HITL) approach has the potential to revolutionize the way weapproach decision-making problems and create new opportunities for human-AIcollaboration. In this article, we introduce a novel multi-layered hierarchicalHITL DRL algorithm that comprises three types of learning: self learning,imitation learning and transfer learning. In addition, we consider three formsof human inputs: reward, action and demonstration. Furthermore, we discuss mainchallenges, trade-offs and advantages of HITL in solving complex problems andhow human information can be integrated in the AI solution systematically. Toverify our technical results, we present a real-world unmanned aerial vehicles(UAV) problem wherein a number of enemy drones attack a restricted area. Theobjective is to design a scalable HITL DRL algorithm for ally drones toneutralize the enemy drones before they reach the area. To this end, we firstimplement our solution using an award-winning open-source HITL software calledCogment. We then demonstrate several interesting results such as (a) HITL leadsto faster training and higher performance, (b) advice acts as a guidingdirection for gradient methods and lowers variance, and (c) the amount ofadvice should neither be too large nor too small to avoid over-training andunder-training. Finally, we illustrate the role of human-AI cooperation insolving two real-world complex scenarios, i.e., overloaded and decoy attacks.</description>
      <author>example@mail.com (Jalal Arabneydi, Saiful Islam, Srijita Das, Sai Krishna Gottipati, William Duguay, Cloderic Mars, Matthew E. Taylor, Matthew Guzdial, Antoine Fagette, Younes Zerouali)</author>
      <guid isPermaLink="false">2504.17006v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>A Genealogy of Multi-Sensor Foundation Models in Remote Sensing</title>
      <link>http://arxiv.org/abs/2504.17177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, submitted to ACM SigSpatial, currently under peer review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在遥感领域应用基础模型进行表征学习的情况，分析了不同方法的优缺点，并提出了未来改进方向。&lt;h4&gt;背景&lt;/h4&gt;基础模型在遥感领域的应用越来越受到关注，主要借鉴了在计算机视觉领域已取得成功的算法，但这一领域的发展仍处于初期阶段。&lt;h4&gt;目的&lt;/h4&gt;研究不同方法在计算机视觉领域的根源，分析其在遥感领域的潜在优势和不足，并展望未来改进方向。&lt;h4&gt;方法&lt;/h4&gt;讨论了学习到的表征质量、减少计算资源需求的方法，以及多传感器在地球观测和多模态基础模型训练中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;发现了多种竞争方法，每种方法都有其显著的优点和缺点，并提出了进一步利用大量未标记、季节性和多传感器遥感观测数据的机会。&lt;h4&gt;结论&lt;/h4&gt;强调了在遥感领域进一步发展基础模型的重要性，并指出了未来研究的方向和可能的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have garnered increasing attention for representationlearning in remote sensing, primarily adopting approaches that havedemonstrated success in computer vision with minimal domain-specificmodification. However, the development and application of foundation models inthis field are still burgeoning, as there are a variety of competing approachesthat each come with significant benefits and drawbacks. This paper examinesthese approaches along with their roots in the computer vision field in orderto characterize potential advantages and pitfalls while outlining futuredirections to further improve remote sensing-specific foundation models. Wediscuss the quality of the learned representations and methods to alleviate theneed for massive compute resources. We place emphasis on the multi-sensoraspect of Earth observations, and the extent to which existing approachesleverage multiple sensors in training foundation models in relation tomulti-modal foundation models. Finally, we identify opportunities for furtherharnessing the vast amounts of unlabeled, seasonal, and multi-sensor remotesensing observations.</description>
      <author>example@mail.com (Kevin Lane, Morteza Karimzadeh)</author>
      <guid isPermaLink="false">2504.17177v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks</title>
      <link>http://arxiv.org/abs/2504.16748v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络扩散模型的新的无增强图对比学习（GCL）框架，通过可学习的编码器产生多样化的视图，捕捉局部或全局信息，实现对比学习，且不需要负样本训练，适用于同质和异质数据集，并在多个数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）作为一种无监督的图表示学习方法，最近取得了进展。GCL方法可以分为基于增强和无需增强的方法。基于增强的方法依赖于复杂的数据增强，而无需增强的方法依赖于能够生成同一输入不同视图的编码器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无增强的GCL框架，该框架能够生成多样化的视图，实现对比学习，且不需要负样本训练。&lt;h4&gt;方法&lt;/h4&gt;使用受分数微分方程（FDE）控制的可学习编码器，每个FDE由微分算子的阶参数特性化。通过调整这些参数，产生能够生成多样化视图的可学习编码器，用于对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;模型不需要负样本进行训练，且适用于同质和异质数据集，在各种数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在多个数据集上有效，为图对比学习提供了一种新的无增强框架，具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has recently made progress as anunsupervised graph representation learning paradigm. GCL approaches can becategorized into augmentation-based and augmentation-free methods. The formerrelies on complex data augmentations, while the latter depends on encoders thatcan generate distinct views of the same input. Both approaches may requirenegative samples for training. In this paper, we introduce a novelaugmentation-free GCL framework based on graph neural diffusion models.Specifically, we utilize learnable encoders governed by Fractional DifferentialEquations (FDE). Each FDE is characterized by an order parameter of thedifferential operator. We demonstrate that varying these parameters allows usto produce learnable encoders that generate diverse views, capturing eitherlocal or global information, for contrastive learning. Our model does notrequire negative samples for training and is applicable to both homophilic andheterophilic datasets. We demonstrate its effectiveness across variousdatasets, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Yanan Zhao, Feng Ji, Kai Zhao, Xuhao Li, Qiyu Kang, Wenfei Liang, Yahya Alkhatib, Xingchao Jian, Wee Peng Tay)</author>
      <guid isPermaLink="false">2504.16748v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET</title>
      <link>http://arxiv.org/abs/2504.17122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at: https://github.com/tkartikay/PhysNRPET&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于隐式神经网络表示（INRs）的生理神经网络，用于个人化的动态正电子发射断层扫描（PET）葡萄糖代谢参数估计，以提高图像分辨率和数据效率。&lt;h4&gt;背景&lt;/h4&gt;传统的PET葡萄糖代谢参数估计方法计算量大，空间分辨率有限，而深度神经网络（DNNs）虽然是一种替代方案，但需要大量训练数据和计算资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于INRs的生理神经网络，以解决传统方法计算量大和DNNs需要大量数据资源的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了3D CT基础模型提供的解剖先验信息，以增强动力学的鲁棒性和精度，并在[$^{18}$F]FDG动态PET/CT数据集上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法具有更高的空间分辨率，更低的均方误差，以及在肿瘤和高血管化区域中更好的解剖一致性。&lt;h4&gt;结论&lt;/h4&gt;INRs在个性化、数据高效的同位素示踪剂动力学建模中具有潜力，可以应用于肿瘤特征描述、分割和预后评估。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables non-invasive quantification of glucose metabolism through kinetic analysis, often modelled by the two-tissue compartment model (TCKM). However, voxel-wise kinetic parameter estimation using conventional methods is computationally intensive and limited by spatial resolution. Deep neural networks (DNNs) offer an alternative but require large training datasets and significant computational resources. To address these limitations, we propose a physiological neural representation based on implicit neural representations (INRs) for personalized kinetic parameter estimation. INRs, which learn continuous functions, allow for efficient, high-resolution parametric imaging with reduced data requirements. Our method also integrates anatomical priors from a 3D CT foundation model to enhance robustness and precision in kinetic modelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset and compare it to state-of-the-art DNNs. Results demonstrate superior spatial resolution, lower mean-squared error, and improved anatomical consistency, particularly in tumour and highly vascularized regions. Our findings highlight the potential of INRs for personalized, data-efficient tracer kinetic modelling, enabling applications in tumour characterization, segmentation, and prognostic assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enablesnon-invasive quantification of glucose metabolism through kinetic analysis,often modelled by the two-tissue compartment model (TCKM). However, voxel-wisekinetic parameter estimation using conventional methods is computationallyintensive and limited by spatial resolution. Deep neural networks (DNNs) offeran alternative but require large training datasets and significantcomputational resources. To address these limitations, we propose aphysiological neural representation based on implicit neural representations(INRs) for personalized kinetic parameter estimation. INRs, which learncontinuous functions, allow for efficient, high-resolution parametric imagingwith reduced data requirements. Our method also integrates anatomical priorsfrom a 3D CT foundation model to enhance robustness and precision in kineticmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT datasetand compare it to state-of-the-art DNNs. Results demonstrate superior spatialresolution, lower mean-squared error, and improved anatomical consistency,particularly in tumour and highly vascularized regions. Our findings highlightthe potential of INRs for personalized, data-efficient tracer kineticmodelling, enabling applications in tumour characterization, segmentation, andprognostic assessment.</description>
      <author>example@mail.com (Kartikay Tehlan, Thomas Wendler)</author>
      <guid isPermaLink="false">2504.17122v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications</title>
      <link>http://arxiv.org/abs/2504.16972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了利用自动编码器和视觉Transformer进行无监督信号分析的最新进展，包括其架构、应用和新兴趋势。&lt;h4&gt;背景&lt;/h4&gt;无线通信、雷达、生物医学工程和物联网（IoT）等领域未标记时间序列数据的快速增长推动了无监督学习的进步。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨如何通过这些模型在多种信号类型中进行特征提取、异常检测和分类，如心电图、雷达波形和物联网传感器数据。&lt;h4&gt;方法&lt;/h4&gt;本文分析了混合架构和自监督学习的优势，同时识别了可解释性、可扩展性和领域泛化等方面的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;本文指出，混合架构和自监督学习具有优势，但在可解释性、可扩展性和领域泛化方面存在挑战。&lt;h4&gt;结论&lt;/h4&gt;通过结合方法创新和实际应用，本文为开发稳健、自适应的信号智能模型提供了路线图。&lt;h4&gt;翻译&lt;/h4&gt;This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of unlabeled time-series data in domains such as wirelesscommunications, radar, biomedical engineering, and the Internet of Things (IoT)has driven advancements in unsupervised learning. This review synthesizesrecent progress in applying autoencoders and vision transformers forunsupervised signal analysis, focusing on their architectures, applications,and emerging trends. We explore how these models enable feature extraction,anomaly detection, and classification across diverse signal types, includingelectrocardiograms, radar waveforms, and IoT sensor data. The review highlightsthe strengths of hybrid architectures and self-supervised learning, whileidentifying challenges in interpretability, scalability, and domaingeneralization. By bridging methodological innovations and practicalapplications, this work offers a roadmap for developing robust, adaptive modelsfor signal intelligence.</description>
      <author>example@mail.com (Hossein Ahmadi, Sajjad Emdadi Mahdimahalleh, Arman Farahat, Banafsheh Saffari)</author>
      <guid isPermaLink="false">2504.16972v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Vidi: Large Multimodal Models for Video Understanding and Editing</title>
      <link>http://arxiv.org/abs/2504.15681v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Vidi系列大型多模态模型（LMMs），用于广泛视频理解和编辑场景，并提出了VUE-TR基准，用于评估视频编辑中的时间检索任务。&lt;h4&gt;背景&lt;/h4&gt;人类自然地与他们联系的人共享信息，视频已成为互联网上主要的沟通和表达媒介。现代视频内容制作需要全面理解原始素材和编辑组件。&lt;h4&gt;目的&lt;/h4&gt;支持高质量大规模视频内容的创作，并解决视频编辑场景中对传统模型的挑战。&lt;h4&gt;方法&lt;/h4&gt;Vidi模型能够处理多种模态（如视觉、音频、文本）和灵活的输入长度（如时长为一小时的原始视频），并专注于时间检索任务。&lt;h4&gt;主要发现&lt;/h4&gt;Vidi在时间检索任务上显著优于GPT-4o和Gemini等领先模型，表明其在视频编辑场景中的优越性。VUE-TR基准引入了五个关键进步，包括视频时长、音频支持、多样化的查询格式、高质量的标注以及改进的评估指标。&lt;h4&gt;结论&lt;/h4&gt;Vidi在视频编辑场景中具有显著优势，为视频理解和编辑提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally share information with those they are connected to, andvideo has become one of the dominant mediums for communication and expressionon the Internet. To support the creation of high-quality large-scale videocontent, a modern pipeline requires a comprehensive understanding of both theraw input materials (e.g., the unedited footage captured by cameras) and theediting components (e.g., visual effects). In video editing scenarios, modelsmust process multiple modalities (e.g., vision, audio, text) with strongbackground knowledge and handle flexible input lengths (e.g., hour-long rawvideos), which poses significant challenges for traditional models. In thisreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for awide range of video understand editing scenarios. The first release focuses ontemporal retrieval, i.e., identifying the time ranges within the input videoscorresponding to a given text query, which plays a critical role in intelligentediting. The model is capable of processing hour-long videos with strongtemporal understanding capability, e.g., retrieve time ranges for certainqueries. To support a comprehensive evaluation in real-world scenarios, we alsopresent the VUE-TR benchmark, which introduces five key advancements. 1) Videoduration: significantly longer than videos of existing temporal retrivaldatasets, 2) Audio support: includes audio-based queries, 3) Query format:diverse query lengths/formats, 4) Annotation quality: ground-truth time rangesare manually annotated. 5) Evaluation metric: a refined IoU metric to supportevaluation over multiple time ranges. Remarkably, Vidi significantlyoutperforms leading proprietary models, e.g., GPT-4o and Gemini, on thetemporal retrieval task, indicating its superiority in video editing scenarios.</description>
      <author>example@mail.com (Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang, Lu Guo, Lusha Li, Longyin Wen, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin, Wei Lu, Wen Zhong, Xiaohui Shen, Xin Gu, Xing Mei, Xueqiong Qu)</author>
      <guid isPermaLink="false">2504.15681v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity</title>
      <link>http://arxiv.org/abs/2504.16956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GeneMamba，一个基于状态空间建模的可扩展和高效的单一细胞转录组学基础模型，用于解决单细胞RNA测序（scRNA-seq）分析中的复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;scRNA-seq技术能够进行高分辨率细胞异质性分析，但其复杂性（高维性、稀疏性和批次效应）给计算带来了挑战。基于Transformer的模型在此领域取得了进展，但往往受到二次复杂性和对长距离依赖处理不佳的限制。&lt;h4&gt;目的&lt;/h4&gt;提出GeneMamba模型，旨在解决scRNA-seq分析中的计算挑战，并提高模型的性能和效率。&lt;h4&gt;方法&lt;/h4&gt;GeneMamba利用Bi-Mamba架构，以线性时间复杂度捕捉双向基因上下文，并通过近3000万个细胞的预训练和生物信息学目标（如路径感知对比损失和基于排名的基因编码）来提高模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GeneMamba在多批次整合、细胞类型注释和基因-基因相关性等任务中表现出强大的性能、可解释性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;GeneMamba作为基于Transformer方法的实用且强大的替代品，推动了基于生物学的大规模单细胞数据分析工具的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis ofcellular heterogeneity, but its complexity, which is marked by highdimensionality, sparsity, and batch effects, which poses major computationalchallenges. Transformer-based models have made significant advances in thisdomain but are often limited by their quadratic complexity and suboptimalhandling of long-range dependencies. In this work, we introduce GeneMamba, ascalable and efficient foundation model for single-cell transcriptomics builton state space modeling. Leveraging the Bi-Mamba architecture, GeneMambacaptures bidirectional gene context with linear-time complexity, offeringsubstantial computational gains over transformer baselines. The model ispretrained on nearly 30 million cells and incorporates biologically informedobjectives, including pathway-aware contrastive loss and rank-based geneencoding. We evaluate GeneMamba across diverse tasks, including multi-batchintegration, cell type annotation, and gene-gene correlation, demonstratingstrong performance, interpretability, and robustness. These results positionGeneMamba as a practical and powerful alternative to transformer-based methods,advancing the development of biologically grounded, scalable tools forlarge-scale single-cell data analysis.</description>
      <author>example@mail.com (Cong Qi, Hanzhang Fang, Tianxing Hu, Siqi Jiang, Wei Zhi)</author>
      <guid isPermaLink="false">2504.16956v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15929v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MedTrim的新方法，通过多模态三元组学习来增强图像和文本的匹配，以优化医学影像诊断。&lt;h4&gt;背景&lt;/h4&gt;随着医学影像数据的增加，对医学专家的压力增大，导致错误增多和工作流程积压。现有的基于对比学习的对齐方法在处理疾病分类和精细病理属性时存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出MedTrim方法，通过元实体驱动的三元组挖掘来改善图像和文本的对齐，从而提高医学影像诊断的性能。&lt;h4&gt;方法&lt;/h4&gt;MedTrim方法包括：1）基于本体论的实体识别模块，从CXR报告中提取特定的元实体；2）一个新颖的评分函数，基于疾病分类和形容词/方向性描述符来衡量样本间的相似性；3）一个多模态三元组对齐目标，用于在具有详细病理特征的样本之间进行显式的跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MedTrim在下游检索和分类任务中比现有的对齐方法提高了性能。&lt;h4&gt;结论&lt;/h4&gt;MedTrim通过利用结构化的元实体信息和改进的三元组学习，在医学影像诊断中实现了更优的图像和文本对齐。&lt;h4&gt;翻译&lt;/h4&gt;诊断影像依赖于对图像和放射学报告的解释，但随着数据量的增加，对医学专家的压力增大，导致错误增加和工作流程积压。医学视觉语言模型（med-VLMs）已经成为高效处理多模态影像数据的有力框架，特别是在胸部X射线（CXR）评估中，尽管其性能取决于图像和文本表示的对齐程度。现有的基于对比学习的对齐方法主要优先考虑疾病类别的分离，而不是精细病理属性（如位置、大小或严重程度）的分离，导致表示不理想。在这里，我们提出了MedTrim（元实体驱动的三元组挖掘），一种新颖的方法，通过疾病类别以及形容词和方向性病理描述符协同引导的多模态三元组学习来增强图像-文本对齐。与常见的分离广泛疾病类别的对齐方法不同，MedTrim利用结构化的元实体信息来保留细微但具有临床意义的类内变异。为此，我们首先引入了一个基于本体的实体识别模块，从CXR报告中提取病理特定的元实体，因为公共数据集中病理属性的注释很少。然后，我们引入了一个新颖的评分函数，它基于疾病类别和形容词/方向性描述符来捕获样本间相似性的综合度量。最后，我们引入了一个多模态三元组对齐目标，用于在具有详细病理特征的样本之间进行显式的跨模态对齐。我们的演示表明，与最先进的对齐方法相比，MedTrim在下游检索和分类任务中提高了性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diagnostic imaging relies on interpreting both images and radiology reports,but the growing data volumes place significant pressure on medical experts,yielding increased errors and workflow backlogs. Medical vision-language models(med-VLMs) have emerged as a powerful framework to efficiently processmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeittheir performance hinges on how well image and text representations arealigned. Existing alignment methods, predominantly based on contrastivelearning, prioritize separation between disease classes over segregation offine-grained pathology attributes like location, size or severity, leading tosuboptimal representations. Here, we propose MedTrim (Meta-entity-drivenTriplet mining), a novel method that enhances image-text alignment throughmultimodal triplet learning synergistically guided by disease class as well asadjectival and directional pathology descriptors. Unlike common alignmentmethods that separate broad disease classes, MedTrim leverages structuredmeta-entity information to preserve subtle but clinically significantintra-class variations. For this purpose, we first introduce an ontology-basedentity recognition module that extracts pathology-specific meta-entities fromCXR reports, as annotations on pathology attributes are rare in publicdatasets. For refined sample selection in triplet mining, we then introduce anovel score function that captures an aggregate measure of inter-samplesimilarity based on disease classes and adjectival/directional descriptors.Lastly, we introduce a multimodal triplet alignment objective for explicitwithin- and cross-modal alignment between samples sharing detailed pathologycharacteristics. Our demonstrations indicate that MedTrim improves performancein downstream retrieval and classification tasks compared to state-of-the-artalignment methods.</description>
      <author>example@mail.com (Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur)</author>
      <guid isPermaLink="false">2504.15929v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2504.12597v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了GeoSense，一个用于评估多模态大型语言模型（MLLMs）几何推理能力的双语基准，并发现Gemini-2.0-pro-flash在该基准上表现最佳，但几何原理的识别和应用仍然是MLLMs推理能力的瓶颈。&lt;h4&gt;背景&lt;/h4&gt;几何问题解决（GPS）是一个需要视觉理解和符号推理的挑战性任务，可以有效地衡量MLLMs的推理能力。人类在该任务中表现出强大的推理能力，通过在视觉环境中准确识别和适应性应用几何原理。&lt;h4&gt;目的&lt;/h4&gt;为了系统地评估MLLMs的几何推理能力，论文提出了GeoSense，一个综合性的双语基准，旨在从几何原理的角度评估MLLMs的几何推理能力。&lt;h4&gt;方法&lt;/h4&gt;GeoSense具有一个涵盖平面和立体几何的五级层次框架的几何原理，以及一个包含1,789个问题的详细注释数据集和创新的评估策略。通过在GeoSense上对各种开源和闭源MLLMs进行广泛实验。&lt;h4&gt;主要发现&lt;/h4&gt;Gemini-2.0-pro-flash在GeoSense基准上取得了最佳成绩，总体得分为65.3。深入分析显示，几何原理的识别和应用仍然是领先MLLMs推理能力的瓶颈。&lt;h4&gt;结论&lt;/h4&gt;GeoSense有潜力指导未来MLLMs几何推理能力的进步，为人工智能中的更稳健和更类似人类的推理铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of 65.3. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem-solving (GPS), a challenging task requiring both visualcomprehension and symbolic reasoning, effectively measures the reasoningcapabilities of multimodal large language models (MLLMs). Humans exhibit strongreasoning ability in this task through accurate identification and adaptiveapplication of geometric principles within visual contexts. However, existingbenchmarks fail to jointly assess both dimensions of the human-like geometricreasoning mechanism in MLLMs, remaining a critical gap in assessing theirability to tackle GPS. To this end, we introduce GeoSense, the firstcomprehensive bilingual benchmark designed to systematically evaluate thegeometric reasoning abilities of MLLMs through the lens of geometricprinciples. GeoSense features a five-level hierarchical framework of geometricprinciples spanning plane and solid geometry, an intricately annotated datasetof 1,789 problems, and an innovative evaluation strategy. Through extensiveexperiments on GeoSense with various open-source and closed-source MLLMs, weobserve that Gemini-2.0-pro-flash performs best, achieving an overall score of$65.3$. Our in-depth analysis reveals that the identification and applicationof geometric principles remain a bottleneck for leading MLLMs, jointlyhindering their reasoning abilities. These findings underscore GeoSense'spotential to guide future advancements in MLLMs' geometric reasoningcapabilities, paving the way for more robust and human-like reasoning inartificial intelligence.</description>
      <author>example@mail.com (Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng)</author>
      <guid isPermaLink="false">2504.12597v2</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Intrinsic Barriers to Explaining Deep Foundation Models</title>
      <link>http://arxiv.org/abs/2504.16948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度基础模型（DFMs）的复杂性和内部工作原理，分析了当前可解释性方法在面对这一内在挑战时的局限性，并探讨了实现令人满意的解释的可行性以及这些强大技术验证和治理的启示。&lt;h4&gt;背景&lt;/h4&gt;深度基础模型提供了前所未有的能力，但其日益增加的复杂性给理解其内部工作原理带来了巨大挑战，这对于确保信任、安全和问责制至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究DFMs的基本特征，审查当前可解释性方法在面临这一内在挑战时的局限性，并探讨如何实现令人满意的解释以及这些技术的验证和治理。&lt;h4&gt;方法&lt;/h4&gt;对DFMs的基本特征进行分析，审查当前可解释性方法的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;发现了DFMs的内在复杂性及其对可解释性的挑战，并探讨了实现满意解释的可行性。&lt;h4&gt;结论&lt;/h4&gt;提出了对DFMs验证和治理的新方法，强调了理解和解释这些模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;This paper delves into the critical question of the complexity and internal working principles of Deep Foundation Models (DFMs), analyzes the limitations encountered by current explainability methods when faced with this inherent challenge, and explores the feasibility of achieving satisfactory explanations and the implications for how we must approach the verification and governance of these powerful technologies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Foundation Models (DFMs) offer unprecedented capabilities but theirincreasing complexity presents profound challenges to understanding theirinternal workings-a critical need for ensuring trust, safety, andaccountability. As we grapple with explaining these systems, a fundamentalquestion emerges: Are the difficulties we face merely temporary hurdles,awaiting more sophisticated analytical techniques, or do they stem from\emph{intrinsic barriers} deeply rooted in the nature of these large-scalemodels themselves? This paper delves into this critical question by examiningthe fundamental characteristics of DFMs and scrutinizing the limitationsencountered by current explainability methods when confronted with thisinherent challenge. We probe the feasibility of achieving satisfactoryexplanations and consider the implications for how we must approach theverification and governance of these powerful technologies.</description>
      <author>example@mail.com (Zhen Tan, Huan Liu)</author>
      <guid isPermaLink="false">2504.16948v1</guid>
      <pubDate>Fri, 25 Apr 2025 14:10:59 +0800</pubDate>
    </item>
    <item>
      <title>Rank-based transfer learning for high-dimensional survival data with application to sepsis data</title>
      <link>http://arxiv.org/abs/2504.11270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了MSSA脓毒症，通过扩展现有的迁移学习框架，提高了高维生存数据的转换模型，并提供了置信区间构建算法，通过模拟和数据分析证明了方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;脓毒症死亡率高，预后复杂，研究MSSA脓毒症存在数据限制。&lt;h4&gt;目的&lt;/h4&gt;解决MSSA脓毒症研究中数据限制的问题，提高目标模型的性能。&lt;h4&gt;方法&lt;/h4&gt;构建基于C-index的测量指数以智能识别有用的源数据集，通过迁移步骤和去偏步骤利用识别的源数据集信息，提供置信区间构建算法，并严格建立统计性质。&lt;h4&gt;主要发现&lt;/h4&gt;扩展的迁移学习框架提高了目标模型性能，置信区间构建算法有效，统计性质严格建立。&lt;h4&gt;结论&lt;/h4&gt;该方法在MSSA脓毒症的生存估计方面提供了显著改进。&lt;h4&gt;翻译&lt;/h4&gt;Sepsis remains a critical challenge due to its high mortality and complex prognosis. To address data limitations in studying MSSA sepsis, we extend existing transfer learning frameworks to accommodate transformation models for high-dimensional survival data. Specifically, we construct a measurement index based on C-index for intelligently identifying the helpful source datasets, and the target model performance is improved by leveraging information from the identified source datasets via performing the transfer step and debiasing step. We further provide an algorithm to construct confidence intervals for each coefficient component. Another significant development is that statistical properties are rigorously established, including l1/l2-estimation error bounds of the transfer learning algorithm, detection consistency property of the transferable source detection algorithm and asymptotic theories for the confidence interval construction. Extensive simulations and analysis of MIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, and practical advantages of our approach, providing significant improvements in survival estimates for MSSA sepsis patients.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sepsis remains a critical challenge due to its high mortality and complexprognosis. To address data limitations in studying MSSA sepsis, we extendexisting transfer learning frameworks to accommodate transformation models forhigh-dimensional survival data. Specifically, we construct a measurement indexbased on C-index for intelligently identifying the helpful source datasets, andthe target model performance is improved by leveraging information from theidentified source datasets via performing the transfer step and debiasing step.We further provide an algorithm to construct confidence intervals for eachcoefficient component. Another significant development is that statisticalproperties are rigorously established, including $\ell_1/\ell_2$-estimationerror bounds of the transfer learning algorithm, detection consistency propertyof the transferable source detection algorithm and asymptotic theories for theconfidence interval construction. Extensive simulations and analysis ofMIMIC-IV sepsis data demonstrate the estimation and prediction accuracy, andpractical advantages of our approach, providing significant improvements insurvival estimates for MSSA sepsis patients.</description>
      <author>example@mail.com (Nan Qiao, Haowei Jiang, Cunjie Lin)</author>
      <guid isPermaLink="false">2504.11270v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
  <item>
      <title>LIFT+: Lightweight Fine-Tuning for Long-Tail Learning</title>
      <link>http://arxiv.org/abs/2504.13282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在基础模型时代，微调策略对长尾学习性能的影响，并提出了一种名为LIFT+的创新轻量级微调框架，以优化基础模型的适应性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;微调已成为解决长尾学习任务的重要方法，但其对长尾学习性能的影响尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;研究微调策略对长尾学习性能的影响，并提出一种高效的微调框架。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和实验验证，发现重微调会导致尾部类别性能下降，而轻量级微调更有效。基于此，提出了LIFT+框架，包括语义感知初始化、最小化数据增强和测试时集成等方法。&lt;h4&gt;主要发现&lt;/h4&gt;重微调会导致尾部类别性能下降，而轻量级微调更有效，这一现象源于重微调导致的类别条件分布不一致。&lt;h4&gt;结论&lt;/h4&gt;LIFT+框架通过减少训练轮数和模型参数数量，提高了基础模型的适应性和泛化能力，在实验中表现优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：微调范式已成为基础模型时代解决长尾学习任务的重要方法。然而，微调策略对长尾学习性能的影响尚未得到充分探索。本研究发现，现有范式存在微调方法的滥用，在效率和精度上仍有很大的提升空间。具体而言，我们发现重微调（微调大量模型参数）会导致尾部类别性能显著下降，而轻量级微调表现出优越的有效性。通过全面的理论和实证验证，我们发现这种现象源于重微调导致的类别条件分布不一致。基于这一洞察，我们提出了LIFT+，一种创新的轻量级微调框架，以优化一致的类别条件。此外，LIFT+还包含了语义感知初始化、最小化数据增强和测试时集成等方法，以增强基础模型的适应性和泛化能力。我们的框架提供了一种高效且精确的流程，有助于快速收敛和模型紧凑性。广泛的实验表明，LIFT+显著减少了训练轮数（从约100轮减少到≤15轮）和学习的参数（少于1%），并且在大大超过现有方法。源代码可在https://github.com/shijxcs/LIFT-plus获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shijxcs/lift-plus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The fine-tuning paradigm has emerged as a prominent approach for addressinglong-tail learning tasks in the era of foundation models. However, the impactof fine-tuning strategies on long-tail learning performance remains unexplored.In this work, we disclose that existing paradigms exhibit a profound misuse offine-tuning methods, leaving significant room for improvement in bothefficiency and accuracy. Specifically, we reveal that heavy fine-tuning(fine-tuning a large proportion of model parameters) can lead to non-negligibleperformance deterioration on tail classes, whereas lightweight fine-tuningdemonstrates superior effectiveness. Through comprehensive theoretical andempirical validation, we identify this phenomenon as stemming from inconsistentclass conditional distributions induced by heavy fine-tuning. Building on thisinsight, we propose LIFT+, an innovative lightweight fine-tuning framework tooptimize consistent class conditions. Furthermore, LIFT+ incorporatessemantic-aware initialization, minimalist data augmentation, and test-timeensembling to enhance adaptation and generalization of foundation models. Ourframework provides an efficient and accurate pipeline that facilitates fastconvergence and model compactness. Extensive experiments demonstrate that LIFT+significantly reduces both training epochs (from $\sim$100 to $\leq$15) andlearned parameters (less than 1%), while surpassing state-of-the-art approachesby a considerable margin. The source code is available athttps://github.com/shijxcs/LIFT-plus.</description>
      <author>example@mail.com (Jiang-Xin Shi, Tong Wei, Yu-Feng Li)</author>
      <guid isPermaLink="false">2504.13282v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>An Accelerated Camera 3DMA Framework for Efficient Urban GNSS Multipath Estimation</title>
      <link>http://arxiv.org/abs/2504.16906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种加速框架，结合相机多视图立体重建和光线追踪技术，以提高城市环境中GNSS定位的鲁棒性，特别是在复杂信号传播条件下。&lt;h4&gt;背景&lt;/h4&gt;城市环境中的GNSS定位受多径效应的影响，特别是由于不同频率反射率表面的复杂信号传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以减少多径效应，同时保持计算效率和建模精度之间的平衡。&lt;h4&gt;方法&lt;/h4&gt;采用相机多视图立体重建和光线追踪技术，结合表面纹理假设，提出一个正交视觉特征融合框架，并整合多边形表面建模方案以细化重建。为了提高速度，采用重投影点云多平面拟合和两种复杂性控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在密集的城市环境中实现了平均2.4米的重建精度，并且在具有玻璃幕墙结构的困难案例中表现良好，同时基于光线追踪的多径校正速度达到每秒30帧图像，是当前基准的10倍。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效地减轻城市环境中的多径效应，显著提高GNSS定位的精度和速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust GNSS positioning in urban environments is still plagued by multipatheffects, particularly due to the complex signal propagation induced byubiquitous surfaces with varied radio frequency reflectivities. Current 3DMapping Aided (3DMA) GNSS techniques show great potentials in mitigatingmultipath but face a critical trade-off between computational efficiency andmodeling accuracy. Most approaches often rely on offline outdated oroversimplified 3D maps, while real-time LiDAR-based reconstruction boasts highaccuracy, it is problematic in low laser reflectivity conditions; camera 3DMAis a good candidate to balance accuracy and efficiency but current methodssuffer from extremely low reconstruction speed, a far cry from real-timemultipath-mitigated navigation. This paper proposes an accelerated frameworkincorporating camera multi-view stereo (MVS) reconstruction and ray tracing. Byhypothesizing on surface textures, an orthogonal visual feature fusionframework is proposed, which robustly addresses both texture-rich andtexture-poor surfaces, lifting off the reflectivity challenges in visualreconstruction. A polygonal surface modeling scheme is further integrated toaccurately delineate complex building boundaries, enhancing the reconstructiongranularity. To avoid excessively accurate reconstruction, reprojected pointcloud multi-plane fitting and two complexity control strategies are proposed,thus improving upon multipath estimation speed. Experiments were conducted inLujiazui, Shanghai, a typical multipath-prone district. The results show thatthe method achieves an average reconstruction accuracy of 2.4 meters in denseurban environments featuring glass curtain wall structures, a traditionallytough case for reconstruction, and achieves a ray-tracing-based multipathcorrection rate of 30 image frames per second, 10 times faster than thecontemporary benchmarks.</description>
      <author>example@mail.com (Shiyao Lv, Xin Zhang, Xingqun Zhan)</author>
      <guid isPermaLink="false">2504.16906v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>I-Con: A Unifying Framework for Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; website: https://aka.ms/i-con . Proceedings of the  Thirteenth International Conference on Learning Representations (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种信息论方程，它概括了机器学习中大量现代损失函数，并展示了一种框架，表明多种机器学习方法实际上是在最小化两个条件分布（监督表示和学到的表示）之间的集成KL散度。这一观点揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。该框架允许通过结合文献中的成功技术来开发新的损失函数。&lt;h4&gt;背景&lt;/h4&gt;随着表示学习领域的增长，出现了大量不同的损失函数来解决不同类别的问题。&lt;h4&gt;目的&lt;/h4&gt;引入一个信息论方程，概括机器学习中大量现代损失函数，并展示一个框架来揭示不同机器学习方法的共同特征。&lt;h4&gt;方法&lt;/h4&gt;提出一个框架，该框架表明多种机器学习方法实际上是在最小化两个条件分布之间的集成KL散度。通过结合文献中的成功技术来开发新的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。通过理论结果创建了先进的无监督图像分类器，在ImageNet-1K上的无监督分类上比之前的方法提高了8%。还证明了I-Con可以用于推导出提高对比表示学习者的原理性去偏方法。&lt;h4&gt;结论&lt;/h4&gt;该框架有助于理解和开发新的机器学习损失函数，同时提高了无监督图像分类的性能，并为去偏方法提供了理论基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着表示学习领域的增长，出现了大量不同的损失函数来解决不同类别的问题。我们引入了一个单一的信息论方程，它概括了机器学习中大量现代损失函数。特别是，我们引入了一个框架，表明多种机器学习方法实际上是在最小化两个条件分布之间的集成KL散度：监督表示和学到的表示。这一观点揭示了聚类、谱方法、降维、对比学习和监督学习背后的潜在信息几何。这个框架通过结合文献中的成功技术来开发新的损失函数。我们不仅提出了一系列证明，连接了23种不同的方法，而且利用这些理论结果创建了最先进的无监督图像分类器，在ImageNet-1K上的无监督分类上比之前的方法提高了8%。我们还证明了I-Con可以用于推导出提高对比表示学习者的原理性去偏方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the field of representation learning grows, there has been a proliferationof different loss functions to solve different classes of problems. Weintroduce a single information-theoretic equation that generalizes a largecollection of modern loss functions in machine learning. In particular, weintroduce a framework that shows that several broad classes of machine learningmethods are precisely minimizing an integrated KL divergence between twoconditional distributions: the supervisory and learned representations. Thisviewpoint exposes a hidden information geometry underlying clustering, spectralmethods, dimensionality reduction, contrastive learning, and supervisedlearning. This framework enables the development of new loss functions bycombining successful techniques from across the literature. We not only presenta wide array of proofs, connecting over 23 different approaches, but we alsoleverage these theoretical results to create state-of-the-art unsupervisedimage classifiers that achieve a +8% improvement over the priorstate-of-the-art on unsupervised classification on ImageNet-1K. We alsodemonstrate that I-Con can be used to derive principled debiasing methods whichimprove contrastive representation learners.</description>
      <author>example@mail.com (Shaden Alshammari, John Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton)</author>
      <guid isPermaLink="false">2504.16929v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>WiFi based Human Fall and Activity Recognition using Transformer based Encoder Decoder and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.16655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TED Net的新型架构，用于从WiFi信道状态信息中估计人体骨骼姿态，并应用于动作识别。&lt;h4&gt;背景&lt;/h4&gt;人体姿态估计和动作识别在医疗监测、康复和辅助技术中发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;设计TED Net以从WiFi信道状态信息中估计人体骨骼姿态，并使用估计的姿态作为输入进行动作识别。&lt;h4&gt;方法&lt;/h4&gt;TED Net结合了卷积编码器和基于transformer的注意力机制来捕捉CSI信号的时空特征。使用估计的骨骼姿态作为输入到定制的有向图神经网络（DGNN）中进行动作识别。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TED Net在姿态估计方面优于现有方法，DGNN使用基于CSI的骨骼进行动作分类时表现出可靠的性能，与基于RGB的系统相当。TED Net在跌倒和非跌倒情况下都保持了鲁棒的性能。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了CSI驱动的骨骼姿态估计在有效动作识别中的潜力，尤其是在家庭环境中的老人跌倒检测。在这些环境中，WiFi信号通常容易获得，为基于视觉的方法提供了一种保护隐私的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;Human pose estimation and action recognition have received attention due to their critical roles in healthcare monitoring, rehabilitation, and assistive technologies. In this study, we proposed a novel architecture named Transformer-based Encoder Decoder Network (TED Net) designed for estimating human skeleton poses from WiFi Channel State Information (CSI). TED Net integrates convolutional encoders with transformer based attention mechanisms to capture spatiotemporal features from CSI signals. The estimated skeleton poses were used as input to a customized Directed Graph Neural Network (DGNN) for action recognition. We validated our model on two datasets: a publicly available multimodal dataset for assessing general pose estimation, and a newly collected dataset focused on fall related scenarios involving 20 participants. Experimental results demonstrated that TED Net outperformed existing approaches in pose estimation, and that the DGNN achieves reliable action classification using CSI based skeletons, with performance comparable to RGB based systems. Notably, TED Net maintains robust performance across both fall and non fall cases. These findings highlight the potential of CSI driven human skeleton estimation for effective action recognition, particularly in home environments such as elderly fall detection. In such settings, WiFi signals are often readily available, offering a privacy preserving alternative to vision based methods, which may raise concerns about continuous camera monitoring.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human pose estimation and action recognition have received attention due totheir critical roles in healthcare monitoring, rehabilitation, and assistivetechnologies. In this study, we proposed a novel architecture named Transformerbased Encoder Decoder Network (TED Net) designed for estimating human skeletonposes from WiFi Channel State Information (CSI). TED Net integratesconvolutional encoders with transformer based attention mechanisms to capturespatiotemporal features from CSI signals. The estimated skeleton poses wereused as input to a customized Directed Graph Neural Network (DGNN) for actionrecognition. We validated our model on two datasets: a publicly available multimodal dataset for assessing general pose estimation, and a newly collecteddataset focused on fall related scenarios involving 20 participants.Experimental results demonstrated that TED Net outperformed existing approachesin pose estimation, and that the DGNN achieves reliable action classificationusing CSI based skeletons, with performance comparable to RGB based systems.Notably, TED Net maintains robust performance across both fall and non fallcases. These findings highlight the potential of CSI driven human skeletonestimation for effective action recognition, particularly in home environmentssuch as elderly fall detection. In such settings, WiFi signals are oftenreadily available, offering a privacy preserving alternative to vision basedmethods, which may raise concerns about continuous camera monitoring.</description>
      <author>example@mail.com (Younggeol Cho, Elisa Motta, Olivia Nocentini, Marta Lagomarsino, Andrea Merello, Marco Crepaldi, Arash Ajoudani)</author>
      <guid isPermaLink="false">2504.16655v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light</title>
      <link>http://arxiv.org/abs/2504.16922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://github.com/SHI-Labs/NATTEN/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了聚焦于局部性的稀疏注意力机制，并旨在分析其性能改进。提出了一种名为广义邻域注意力（GNA）的新机制，并在CUDA架构上实现了它。&lt;h4&gt;背景&lt;/h4&gt;传统的稀疏注意力机制如邻域注意力未能持续提升速度，原因是注意力基础设施的复杂性和AI硬件架构的快速演进。同时，许多基础模型，尤其在计算机视觉领域，受到注意力机制的严重限制，需要可靠的稀疏性来避免O(n^2)的复杂度。&lt;h4&gt;目的&lt;/h4&gt;研究一种聚焦于局部性的稀疏注意力机制，并分析其性能改进。&lt;h4&gt;方法&lt;/h4&gt;提出了广义邻域注意力（GNA）机制，考虑了实现这些方法的可能设计选择，并创建了一个模拟器以提供更真实的加速上限。在CUDA架构的CUTLASS上实现了GNA，并对其进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;GNA在许多完全块稀疏情况下能够实现理论上的最大加速，并且在FP16模式下实现了1.3 petaFLOPs/second的有效利用率。将GNA配置集成到现成的生成模型中，如Cosmos-7B、HunyuanVideo和FLUX，在B200上实现了28%到46%的端到端速度提升，无需微调。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GNA机制在提升模型速度方面具有潜力，且在实际应用中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了多种稀疏注意力机制，如邻域注意力等，通常未能持续提升速度。这主要是由于注意力基础设施的复杂性和AI硬件架构的快速演进。与此同时，许多最先进的底层模型，尤其是在计算机视觉领域，严重依赖于注意力机制，需要可靠的稀疏性来克服O(n^2)的复杂度。在本文中，我们研究了一类有前景的聚焦于局部性的稀疏注意力机制，旨在分析其性能改进。首先，我们引入了广义邻域注意力（GNA），它可以描述滑动窗口、步进滑动窗口和块注意力。然后，我们考虑了实现这些方法的可能设计选择，并创建了一个模拟器，可以为任何给定设置提供更真实的加速上限。最后，我们在CUDA架构的CUTLASS上实现了GNA，并对其进行了评估。我们的实现可以在许多完全块稀疏的情况下实现理论上的最大加速，并在FP16模式下实现了1.3 petaFLOPs/second的有效利用率。此外，我们将各种GNA配置集成到现成的生成模型中，如Cosmos-7B、HunyuanVideo和FLUX，并在B200上实现了28%到46%的端到端速度提升，无需微调。我们将通过NATTEN项目开源我们的模拟器和Blackwell内核。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many sparse attention mechanisms such as Neighborhood Attention havetypically failed to consistently deliver speedup over the self attentionbaseline. This is largely due to the level of complexity in attentioninfrastructure, and the rapid evolution of AI hardware architecture. At thesame time, many state-of-the-art foundational models, particularly in computervision, are heavily bound by attention, and need reliable sparsity to escapethe O(n^2) complexity. In this paper, we study a class of promising sparseattention mechanisms that focus on locality, and aim to develop a betteranalytical model of their performance improvements. We first introduceGeneralized Neighborhood Attention (GNA), which can describe sliding window,strided sliding window, and blocked attention. We then consider possible designchoices in implementing these approaches, and create a simulator that canprovide much more realistic speedup upper bounds for any given setting.Finally, we implement GNA on top of a state-of-the-art fused multi-headedattention (FMHA) kernel designed for the NVIDIA Blackwell architecture inCUTLASS. Our implementation can fully realize the maximum speedup theoreticallypossible in many perfectly block-sparse cases, and achieves an effectiveutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNAconfigurations into off-the-shelf generative models, such as Cosmos-7B,HunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-endspeedup on B200 without any fine-tuning. We will open source our simulator andBlackwell kernels directly through the NATTEN project.</description>
      <author>example@mail.com (Ali Hassani, Fengzhe Zhou, Aditya Kane, Jiannan Huang, Chieh-Yun Chen, Min Shi, Steven Walton, Markus Hoehnerbach, Vijay Thakkar, Michael Isaev, Qinsheng Zhang, Bing Xu, Haicheng Wu, Wen-mei Hwu, Ming-Yu Liu, Humphrey Shi)</author>
      <guid isPermaLink="false">2504.16922v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Common Functional Decompositions Can Mis-attribute Differences in Outcomes Between Populations</title>
      <link>http://arxiv.org/abs/2504.16864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, appearing in 2nd Workshop on Navigating and Addressing Data  Problems for Foundation Models (DATA-FM @ ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在科学和社会科学中解释两个群体之间结果差异的原因，提出了一种扩展Kitagawa-Oaxaca-Blinder（KOB）分解方法，以处理非线性关系。&lt;h4&gt;背景&lt;/h4&gt;在经济学中，KOB分解被用来解释两个群体之间均值结果的差异，但它假设了协变量和结果之间的线性关系。&lt;h4&gt;目的&lt;/h4&gt;目的是使用现代机器学习的非线性功能分解来扩展KOB分解，以更准确地解释结果差异。&lt;h4&gt;方法&lt;/h4&gt;研究了两种常见的分解方法——功能ANOVA和累积局部效应，并分析了它们在处理协变量和结果之间的非线性关系时的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;发现这两种分解方法可能会将差异归因于协变量，即使在这些协变量在两个群体中是相同的。&lt;h4&gt;结论&lt;/h4&gt;提出了一种避免归因错误的分解方法，即当分解与输入分布无关时，不会发生错误归因。并推测在依赖于协变量分布的任何合理的加性分解中，都可能发生错误归因。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在科学和社会科学中，我们经常希望解释为什么两个群体中的结果不同。例如，如果一个就业计划对一个城市的成员比对另一个城市的成员更有利，这是否是由于项目参与者的差异（特定的协变量）还是当地劳动市场的差异（给定协变量的结果）？Kitagawa-Oaxaca-Blinder（KOB）分解是计量经济学中解释两个群体之间均值结果差异的标准工具。然而，KOB分解假设协变量和结果之间存在线性关系，而真实关系可能是有意义的非线性。现代机器学习在单个人群中结果和协变量之间的关系方面拥有各种非线性功能分解。使用这些功能分解扩展KOB分解似乎是自然而然的。我们发现，一个成功的扩展不应将差异归因于协变量——或者相应地，给定协变量的结果——如果这些在两个群体中是相同的。不幸的是，我们证明了即使在简单的例子中，两种常见的分解——功能ANOVA和累积局部效应——也可以将差异归因于给定协变量的结果，即使它们在两个群体中是相同的。我们提供了功能ANOVA错误归因时的描述，以及任何离散分解必须满足的通用属性以避免错误归因。我们表明，如果分解与其输入分布无关，则不会发生错误归因。我们进一步推测，在任何合理的依赖于协变量分布的加性分解中，都可能发生错误归因。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In science and social science, we often wish to explain why an outcome isdifferent in two populations. For instance, if a jobs program benefits membersof one city more than another, is that due to differences in programparticipants (particular covariates) or the local labor markets (outcomes givencovariates)? The Kitagawa-Oaxaca-Blinder (KOB) decomposition is a standard toolin econometrics that explains the difference in the mean outcome across twopopulations. However, the KOB decomposition assumes a linear relationshipbetween covariates and outcomes, while the true relationship may bemeaningfully nonlinear. Modern machine learning boasts a variety of nonlinearfunctional decompositions for the relationship between outcomes and covariatesin one population. It seems natural to extend the KOB decomposition using thesefunctional decompositions. We observe that a successful extension should notattribute the differences to covariates -- or, respectively, to outcomes givencovariates -- if those are the same in the two populations. Unfortunately, wedemonstrate that, even in simple examples, two common decompositions --functional ANOVA and Accumulated Local Effects -- can attribute differences tooutcomes given covariates, even when they are identical in two populations. Weprovide a characterization of when functional ANOVA misattributes, as well as ageneral property that any discrete decomposition must satisfy to avoidmisattribution. We show that if the decomposition is independent of its inputdistribution, it does not misattribute. We further conjecture thatmisattribution arises in any reasonable additive decomposition that depends onthe distribution of the covariates.</description>
      <author>example@mail.com (Manuel Quintero, William T. Stephenson, Advik Shreekumar, Tamara Broderick)</author>
      <guid isPermaLink="false">2504.16864v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>A Low-Cost Photogrammetry System for 3D Plant Modeling and Phenotyping</title>
      <link>http://arxiv.org/abs/2504.16840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种开源、低成本的光测测距系统，用于3D植物建模和表型分析。&lt;h4&gt;背景&lt;/h4&gt;植物表型分析对于了解植物性状至关重要，传统方法成本高，操作复杂。&lt;h4&gt;目的&lt;/h4&gt;开发一个系统，以降低植物表型分析的成本并提高效率。&lt;h4&gt;方法&lt;/h4&gt;该系统采用运动结构法，通过点云重建植物的3D表示，并以小麦为例，展示了如何从点云中计算各种表型特征。&lt;h4&gt;主要发现&lt;/h4&gt;系统能够容易地计算植物高度、半径、叶片角度和凸包等标准测量值和手工测量困难的特征。&lt;h4&gt;结论&lt;/h4&gt;该系统对于客观分类直立型小麦和水平型小麦冠层结构等特定指标具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We present an open-source, low-cost photogrammetry system for 3D plant modeling and phenotyping. The system uses a structure-from-motion approach to reconstruct 3D representations of the plants via point clouds. Using wheat as an example, we demonstrate how various phenotypic traits can be computed easily from the point clouds. These include standard measurements such as plant height and radius, as well as features that would be more cumbersome to measure by hand, such as leaf angles and convex hull. We further demonstrate the utility of the system through the investigation of specific metrics that may yield objective classifications of erectophile versus planophile wheat canopy architectures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an open-source, low-cost photogrammetry system for 3D plantmodeling and phenotyping. The system uses a structure-from-motion approach toreconstruct 3D representations of the plants via point clouds. Using wheat asan example, we demonstrate how various phenotypic traits can be computed easilyfrom the point clouds. These include standard measurements such as plant heightand radius, as well as features that would be more cumbersome to measure byhand, such as leaf angles and convex hull. We further demonstrate the utilityof the system through the investigation of specific metrics that may yieldobjective classifications of erectophile versus planophile wheat canopyarchitectures.</description>
      <author>example@mail.com (Joe Hrzich, Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry, Kalhari Manawasinghe, Karen Tanino)</author>
      <guid isPermaLink="false">2504.16840v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Simple Graph Contrastive Learning via Fractional-order Neural Diffusion Networks</title>
      <link>http://arxiv.org/abs/2504.16748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于图神经扩散模型的新的无增强Graph Contrastive Learning (GCL)框架，该框架通过分数微分方程（FDE）生成的可学习编码器来生成多样化的视图，从而实现对比学习。该模型无需负样本进行训练，适用于同质和异质数据集，并在多个数据集上实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;Graph Contrastive Learning (GCL)作为无监督的图表示学习方法近年来取得了进展。GCL方法可分为基于增强和无需增强的方法，前者依赖于复杂的数据增强，而后者依赖于可以生成相同输入的不同视图的编码器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无增强的GCL框架，无需负样本训练，适用于同质和异质数据集，并在多个数据集上实现最先进的性能。&lt;h4&gt;方法&lt;/h4&gt;利用受分数微分方程（FDE）控制的可学习编码器，每个FDE由微分算子的阶数参数表征，通过改变这些参数来生成多样化的视图，捕捉局部或全局信息，用于对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;该模型不需要负样本进行训练，并且适用于同质和异质数据集。&lt;h4&gt;结论&lt;/h4&gt;该模型在多个数据集上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning (GCL)最近作为无监督的图表示学习方法取得了进展。GCL方法可以分为基于增强和无需增强的方法。前者依赖于复杂的数据增强，而后者依赖于可以生成相同输入的不同视图的编码器。在本文中，我们介绍了一种基于图神经扩散模型的新型无增强GCL框架。具体来说，我们利用受分数微分方程（FDE）控制的可学习编码器。每个FDE由微分算子的阶数参数表征。我们证明了通过改变这些参数，我们可以生成可学习编码器，生成多样化的视图，捕捉局部或全局信息，用于对比学习。我们的模型无需负样本进行训练，适用于同质和异质数据集。我们在多个数据集上证明了其有效性，实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has recently made progress as anunsupervised graph representation learning paradigm. GCL approaches can becategorized into augmentation-based and augmentation-free methods. The formerrelies on complex data augmentations, while the latter depends on encoders thatcan generate distinct views of the same input. Both approaches may requirenegative samples for training. In this paper, we introduce a novelaugmentation-free GCL framework based on graph neural diffusion models.Specifically, we utilize learnable encoders governed by Fractional DifferentialEquations (FDE). Each FDE is characterized by an order parameter of thedifferential operator. We demonstrate that varying these parameters allows usto produce learnable encoders that generate diverse views, capturing eitherlocal or global information, for contrastive learning. Our model does notrequire negative samples for training and is applicable to both homophilic andheterophilic datasets. We demonstrate its effectiveness across variousdatasets, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Yanan Zhao, Feng Ji, Kai Zhao, Xuhao Li, Qiyu Kang, Wenfei Liang, Yahya Alkhatib, Xingchao Jian, Wee Peng Tay)</author>
      <guid isPermaLink="false">2504.16748v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception</title>
      <link>http://arxiv.org/abs/2504.16616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EHGCN的新型方法，用于在欧几里得和双曲空间中感知事件流，以解决现有基于图神经网络的方法在处理非均匀分布事件流时难以捕捉长距离依赖和内在层次结构的问题。&lt;h4&gt;背景&lt;/h4&gt;事件相机具有微秒级时间分辨率和高动态范围特性，但在使用基于图神经网络的感知方法时，它们在纯欧几里得空间中使用简单的成对连接机制，难以捕捉长距离依赖和有效表征事件流的内在层次结构。&lt;h4&gt;目的&lt;/h4&gt;提出EHGCN方法，以感知事件流，同时解决长距离依赖和层次结构表征的问题。&lt;h4&gt;方法&lt;/h4&gt;EHGCN方法包括：1. 引入自适应采样策略以动态调节采样率，保留判别性事件同时降低混沌噪声；2. 基于运动状态转换概率的Markov向量场（MVF）驱动的运动感知超边生成方法，消除跨目标的虚假关联并提供关键拓扑先验，同时捕捉事件之间的长距离依赖；3. 提出欧几里得-双曲GCN，融合在欧几里得和双曲空间中局部聚合和全局层次建模的信息，以实现混合事件感知。&lt;h4&gt;主要发现&lt;/h4&gt;EHGCN方法在事件感知任务（如物体检测和识别）上验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;EHGCN方法能够有效提升事件感知任务的性能，特别是在处理非均匀分布事件流时，能够更好地捕捉长距离依赖和内在层次结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras, with microsecond temporal resolution and high dynamic range(HDR) characteristics, emit high-speed event stream for perception tasks.Despite the recent advancement in GNN-based perception methods, they are proneto use straightforward pairwise connectivity mechanisms in the pure Euclideanspace where they struggle to capture long-range dependencies and fail toeffectively characterize the inherent hierarchical structures of non-uniformlydistributed event stream. To this end, in this paper we propose a novelapproach named EHGCN, which is a pioneer to perceive event stream in bothEuclidean and hyperbolic spaces for event vision. In EHGCN, we introduce anadaptive sampling strategy to dynamically regulate sampling rates, retainingdiscriminative events while attenuating chaotic noise. Then we present a MarkovVector Field (MVF)-driven motion-aware hyperedge generation method based onmotion state transition probabilities, thereby eliminating cross-targetspurious associations and providing critically topological priors whilecapturing long-range dependencies between events. Finally, we propose aEuclidean-Hyperbolic GCN to fuse the information locally aggregated andglobally hierarchically modeled in Euclidean and hyperbolic spaces,respectively, to achieve hybrid event perception. Experimental results on eventperception tasks such as object detection and recognition validate theeffectiveness of our approach.</description>
      <author>example@mail.com (Haosheng Chen, Lian Luo, Mengjingcheng Mo, Zhanjie Wu, Guobao Xiao, Ji Gan, Jiaxu Leng, Xinbo Gao)</author>
      <guid isPermaLink="false">2504.16616v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>An Adaptive ML Framework for Power Converter Monitoring via Federated Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.16866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 IEEE. Personal use of this material is permitted. Permission  from IEEE must be obtained for all other uses, in any current or future  media, including reprinting/republishing this material for advertising or  promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了通过结合迁移学习和联邦学习，以分段方式调整热力学机器学习模型配置，以适应电力转换器。&lt;h4&gt;背景&lt;/h4&gt;研究旨在解决电力转换器在操作条件变化、数据共享限制和安全影响等方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究目的是开发一种框架，能够通过多种客户端增量地调整基础模型，以适应不同的应用场景。&lt;h4&gt;方法&lt;/h4&gt;该框架使用三种最先进的领域自适应技术：微调、迁移成分分析（TCA）和深度领域自适应（DDA）。联邦学习（FL）使用Flower框架和联邦平均进行聚合。&lt;h4&gt;主要发现&lt;/h4&gt;验证结果表明，微调是一种简单直接的迁移学习方法，具有高精度，适用于实际应用。基准测试结果揭示了这些方法在不同场景下的优缺点。本地部署的FL在数据聚合不可行时提高了性能，而基于云的FL在客户端数量显著增加时更加实用，解决了可扩展性和连接性问题。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架能够有效解决电力转换器中机器学习模型的适应性挑战，并通过不同的部署方式提高了模型的性能和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPEL.2025.3559132&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores alternative framework configurations for adapting thermalmachine learning (ML) models for power converters by combining transferlearning (TL) and federated learning (FL) in a piecewise manner. This approachinherently addresses challenges such as varying operating conditions, datasharing limitations, and security implications. The framework starts with abase model that is incrementally adapted by multiple clients via adapting threestate-of-the-art domain adaptation techniques: Fine-tuning, Transfer ComponentAnalysis (TCA), and Deep Domain Adaptation (DDA). The Flower framework isemployed for FL, using Federated Averaging for aggregation. Validation withfield data demonstrates that fine-tuning offers a straightforward TL approachwith high accuracy, making it suitable for practical applications. Benchmarkingresults reveal a comprehensive comparison of these methods, showcasing theirrespective strengths and weaknesses when applied in different scenarios.Locally hosted FL enhances performance when data aggregation is not feasible,while cloud-based FL becomes more practical with a significant increase in thenumber of clients, addressing scalability and connectivity challenges.</description>
      <author>example@mail.com (Panagiotis Kakosimos, Alireza Nemat Saberi, Luca Peretti)</author>
      <guid isPermaLink="false">2504.16866v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Decoupled Global-Local Alignment for Improving Compositional Understanding</title>
      <link>http://arxiv.org/abs/2504.16801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLIP模型通过图像和文本模态的对齐在多个下游任务中取得了成功，但全局对比学习的性质限制了其对组合概念（如关系和属性）的理解能力。本文提出了一种Decoupled Global-Local Alignment (DeGLA)框架，在提高组合理解能力的同时，显著减少了模型在一般能力上的损失。&lt;h4&gt;背景&lt;/h4&gt;CLIP模型通过图像和文本模态的对齐取得了成功，但其对组合概念的理解能力受到限制。&lt;h4&gt;目的&lt;/h4&gt;克服CLIP模型在组合理解能力上的限制，同时保持模型的一般能力。&lt;h4&gt;方法&lt;/h4&gt;引入Decoupled Global-Local Alignment (DeGLA)框架，通过自我蒸馏机制优化模型能力保留，并利用LLMs构建大量高质量负样本，同时提出Image-Grounded Contrast (IGC)和Text-Grounded Contrast (TGC)损失函数来增强视觉语言组合能力。&lt;h4&gt;主要发现&lt;/h4&gt;DeGLA框架在多个基准测试中表现出色，相比之前的方法，在VALSE、SugarCrepe和ARO基准测试上平均提升了3.5%，在零样本分类任务上平均提升了13.0%。&lt;h4&gt;结论&lt;/h4&gt;DeGLA框架能够有效提高CLIP模型对组合概念的理解能力，同时保持模型的一般能力。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP)通过对齐图像和文本模态在多个下游任务上取得了成功。然而，全局对比学习的性质限制了CLIP理解组合概念（如关系和属性）的能力。尽管最近的研究通过使用全局硬负样本来提高组合理解，但这些方法通过在嵌入空间中强制将文本负样本与图像分离，显著降低了模型固有的通用能力。为了克服这一限制，我们提出了一种解耦全局-局部对齐（DeGLA）框架，在提高组合理解能力的同时，显著减少了模型在一般能力上的损失。为了优化模型固有能力的保留，我们在全局对齐过程中引入了自我蒸馏机制，将可学习的图像-文本编码器与由指数移动平均得到的冻结教师模型对齐。在自我蒸馏的约束下，它有效地缓解了微调期间预训练知识的灾难性遗忘。为了提高组合理解，我们首先利用大型语言模型（LLMs）的上下文学习能力构建了约200万个高质量负标题。随后，我们提出了图像基础对比（IGC）损失和文本基础对比（TGC）损失来增强视觉-语言组合。广泛的实验结果表明了DeGLA框架的有效性。与之前的最先进方法相比，DeGLA在VALSE、SugarCrepe和ARO基准测试上平均提高了3.5%。同时，它在十一个数据集上的零样本分类任务上平均提高了13.0%。我们的代码将在https://github.com/xiaoxing2001/DeGLA上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Language-Image Pre-training (CLIP) has achieved success onmultiple downstream tasks by aligning image and text modalities. However, thenature of global contrastive learning limits CLIP's ability to comprehendcompositional concepts, such as relations and attributes. Although recentstudies employ global hard negative samples to improve compositionalunderstanding, these methods significantly compromise the model's inherentgeneral capabilities by forcibly distancing textual negative samples fromimages in the embedding space. To overcome this limitation, we introduce aDecoupled Global-Local Alignment (DeGLA) framework that improves compositionalunderstanding while substantially mitigating losses in general capabilities. Tooptimize the retention of the model's inherent capabilities, we incorporate aself-distillation mechanism within the global alignment process, aligning thelearnable image-text encoder with a frozen teacher model derived from anexponential moving average. Under the constraint of self-distillation, iteffectively mitigates the catastrophic forgetting of pretrained knowledgeduring fine-tuning. To improve compositional understanding, we first leveragethe in-context learning capability of Large Language Models (LLMs) to constructabout 2M high-quality negative captions across five types. Subsequently, wepropose the Image-Grounded Contrast (IGC) loss and Text-Grounded Contrast (TGC)loss to enhance vision-language compositionally. Extensive experimental resultsdemonstrate the effectiveness of the DeGLA framework. Compared to previousstate-of-the-art methods, DeGLA achieves an average enhancement of 3.5% acrossthe VALSE, SugarCrepe, and ARO benchmarks. Concurrently, it obtains an averageperformance improvement of 13.0% on zero-shot classification tasks acrosseleven datasets. Our code will be released athttps://github.com/xiaoxing2001/DeGLA</description>
      <author>example@mail.com (Xiaoxing Hu, Kaicheng Yang, Jun Wang, Haoran Xu, Ziyong Feng, Yupei Wang)</author>
      <guid isPermaLink="false">2504.16801v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Splatting is an Effective Data Generator for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.16740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了自动驾驶中3D物体检测的数据增强方法。&lt;h4&gt;背景&lt;/h4&gt;现有基于扩散的方法在基于鸟瞰图（BEV）布局下合成图像，而本研究利用基于高斯拼贴的3D重建技术。&lt;h4&gt;目的&lt;/h4&gt;通过在重建的3D空间中直接放置3D物体，确保物体放置的物理可行性和3D姿态及位置的精确标注。&lt;h4&gt;方法&lt;/h4&gt;使用3D重建技术，对3D物体进行直接放置，并应用几何变换；通过在真实场景中集成外部3D物体进行数据增强；比较了几何多样性和外观多样性对物体放置的影响；研究了通过最大化检测损失或增加视觉遮挡生成困难示例的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;将有限数量的外部3D物体集成到真实场景中，可以显著提高3D物体检测性能；高几何多样性在物体放置上的影响大于外观多样性；生成困难示例并不一定能提高基于摄像头的3D物体检测数据增强的效率。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的方法能够有效提高自动驾驶中3D物体检测的性能，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate data augmentation for 3D object detection in autonomousdriving. We utilize recent advancements in 3D reconstruction based on GaussianSplatting for 3D object placement in driving scenes. Unlike existingdiffusion-based methods that synthesize images conditioned on BEV layouts, ourapproach places 3D objects directly in the reconstructed 3D space withexplicitly imposed geometric transformations. This ensures both the physicalplausibility of object placement and highly accurate 3D pose and positionannotations.  Our experiments demonstrate that even by integrating a limited number ofexternal 3D objects into real scenes, the augmented data significantly enhances3D object detection performance and outperforms existing diffusion-based 3Daugmentation for object detection. Extensive testing on the nuScenes datasetreveals that imposing high geometric diversity in object placement has agreater impact compared to the appearance diversity of objects. Additionally,we show that generating hard examples, either by maximizing detection loss orimposing high visual occlusion in camera images, does not lead to moreefficient 3D data augmentation for camera-based 3D object detection inautonomous driving.</description>
      <author>example@mail.com (Farhad G. Zanjani, Davide Abati, Auke Wiggers, Dimitris Kalatzis, Jens Petersen, Hong Cai, Amirhossein Habibian)</author>
      <guid isPermaLink="false">2504.16740v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>From Past to Present: A Survey of Malicious URL Detection Techniques, Datasets and Code Repositories</title>
      <link>http://arxiv.org/abs/2504.16449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对恶意URL检测技术进行了全面综述，分析了从传统黑名单到高级深度学习方法（如Transformer、GNNs和LLMs）的各种方法。&lt;h4&gt;背景&lt;/h4&gt;恶意URL对网络安全生态系统构成持续威胁，通过欺骗用户泄露私人数据或分发有害有效载荷来渗透主机系统。&lt;h4&gt;目的&lt;/h4&gt;获得对当前恶意URL检测状态的及时洞察，并填补现有综述的四个关键差距。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模态的新颖分类法，将现有工作根据其主要数据模态（如URL、HTML、视觉等）进行分类。此外，收集并分析了公开数据集和开源实现，以建立可访问数据集的档案并解决标准化基准测试的缺乏问题。&lt;h4&gt;主要发现&lt;/h4&gt;1) 现有综述依赖于算法中心化的分类法，掩盖了检测方法如何利用特定的模态信息通道；2) 缺乏对基于LLM/Transformer的关键防御方法的考虑；3) 缺乏开源实现以促进基准测试；4) 数据集覆盖不足。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一个全面的恶意URL检测技术综述，并提出了未来研究的可行方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：恶意URL持续威胁网络安全生态系统，通过欺骗用户泄露私人数据或分发有害有效载荷来渗透主机系统。及时了解这场持续战争的当前状态具有重要意义。然而，现有的综述存在四个关键差距：1) 它们依赖于以算法为中心的分类法，掩盖了检测方法如何利用特定的模态信息通道；2) 它们未能纳入关键的LLM/Transformer-based防御方法；3) 没有收集开源实现以促进基准测试；4) 数据集覆盖不足。本文对恶意URL检测技术进行了全面综述，系统地分析了从传统黑名单到高级深度学习方法（例如Transformer、GNNs和LLMs）的各种方法。与先前的调查不同，我们提出了一种基于模态的新颖分类法，将现有工作根据它们的主要数据模态（如URL、HTML、视觉等）进行分类。这种分层分类使得既可以进行严格的技术分析，又可以对多模态信息利用有清晰的理解。此外，为了建立可访问数据集的档案并解决缺乏标准化基准测试的问题（当前研究往往缺乏适当的基线比较），我们收集并分析了：1) 公开数据集（2016-2024年），以及2) 已发表作品的开放源代码实现（2013-2025年）。然后，我们概述了产品级实现的基本设计原则和架构框架。综述的结论部分检查了新兴的挑战，并提出了未来研究的可行方向。我们维护一个GitHub存储库，用于持续收集数据集和开源实现：https://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Malicious URLs persistently threaten the cybersecurity ecosystem, by eitherdeceiving users into divulging private data or distributing harmful payloads toinfiltrate host systems. Gaining timely insights into the current state of thisongoing battle holds significant importance. However, existing reviews exhibit4 critical gaps: 1) Their reliance on algorithm-centric taxonomies obscuresunderstanding of how detection approaches exploit specific modal informationchannels; 2) They fail to incorporate pivotal LLM/Transformer-based defenses;3) No open-source implementations are collected to facilitate benchmarking; 4)Insufficient dataset coverage.This paper presents a comprehensive review ofmalicious URL detection technologies, systematically analyzing methods fromtraditional blacklisting to advanced deep learning approaches (e.g.Transformer, GNNs, and LLMs). Unlike prior surveys, we propose a novelmodality-based taxonomy that categorizes existing works according to theirprimary data modalities (URL, HTML, Visual, etc.). This hierarchicalclassification enables both rigorous technical analysis and clear understandingof multimodal information utilization. Furthermore, to establish a profile ofaccessible datasets and address the lack of standardized benchmarking (wherecurrent studies often lack proper baseline comparisons), we curate and analyze:1) publicly available datasets (2016-2024), and 2) open-source implementationsfrom published works(2013-2025). Then, we outline essential design principlesand architectural frameworks for product-level implementations. The reviewconcludes by examining emerging challenges and proposing actionable directionsfor future research. We maintain a GitHub repository for ongoing curatingdatasets and open-source implementations:https://github.com/sevenolu7/Malicious-URL-Detection-Open-Source/tree/master.</description>
      <author>example@mail.com (Ye Tian, Yanqiu Yu, Jianguo Sun, Yanbin Wang)</author>
      <guid isPermaLink="false">2504.16449v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections</title>
      <link>http://arxiv.org/abs/2504.16612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to MEDIA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过联邦学习训练基础模型，以解决数据共享限制，实现最小侵入性手术的协作模型训练，而不涉及数据传输。&lt;h4&gt;背景&lt;/h4&gt;联邦学习是一种隐私保护的数据共享方法，适用于需要保护患者隐私的医疗领域。&lt;h4&gt;目的&lt;/h4&gt;研究联邦学习在最小侵入性手术中的应用，以实现数据共享限制下的模型训练。&lt;h4&gt;方法&lt;/h4&gt;受EndoViT研究启发，将掩码自编码器应用于联邦学习，并增强其自适应锐度感知最小化（FedSAM）和随机权重平均（SWA）。模型在Endo700k数据集上预训练，然后针对语义分割、动作三元组识别和手术阶段识别等任务进行微调和评估。&lt;h4&gt;主要发现&lt;/h4&gt;将自适应FedSAM集成到联邦MAE方法中可以改善预训练，导致每块的重构损失减少。FL-EndoViT在手术下游任务中的表现与CEN-EndoViT相当。此外，当数据有限时，FL-EndoViT在手术场景分割方面优于CEN-EndoViT；当使用大型数据集时，在动作三元组识别方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了联邦学习在隐私保护性训练手术基础模型方面的潜力，为手术数据科学提供了一个稳健且可推广的解决方案。有效的协作需要调整联邦学习方法，如FedSAM的集成，以适应机构间固有的数据异质性。未来，探索基于视频的模型，通过结合对现实手术环境至关重要的时空动态，可能增强这些功能。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: In this study, we investigate the training of foundation modelsusing federated learning to address data-sharing limitations and enablecollaborative model training without data transfer for minimally invasivesurgery. Methods: Inspired by the EndoViT study, we adapt the MaskedAutoencoder for federated learning, enhancing it with adaptive Sharpness-AwareMinimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model ispretrained on the Endo700k dataset collection and later fine-tuned andevaluated for tasks such as Semantic Segmentation, Action Triplet Recognition,and Surgical Phase Recognition. Results: Our findings demonstrate thatintegrating adaptive FedSAM into the federated MAE approach improvespretraining, leading to a reduction in reconstruction loss per patch. Theapplication of FL-EndoViT in surgical downstream tasks results in performancecomparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages overCEN-EndoViT in surgical scene segmentation when data is limited and in actiontriplet recognition when large datasets are used. Conclusion: These findingshighlight the potential of federated learning for privacy-preserving trainingof surgical foundation models, offering a robust and generalizable solution forsurgical data science. Effective collaboration requires adapting federatedlearning methods, such as the integration of FedSAM, which can accommodate theinherent data heterogeneity across institutions. In future, exploring FL invideo-based models may enhance these capabilities by incorporatingspatiotemporal dynamics crucial for real-world surgical environments.</description>
      <author>example@mail.com (Max Kirchner, Alexander C. Jenke, Sebastian Bodenstedt, Fiona R. Kolbinger, Oliver Saldanha, Jakob N. Kather, Martin Wagner, Stefanie Speidel)</author>
      <guid isPermaLink="false">2504.16612v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Tri-FusionNet: Enhancing Image Description Generation with Transformer-based Fusion Network and Dual Attention Mechanism</title>
      <link>http://arxiv.org/abs/2504.16761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Tri-FusionNet的新型图像描述生成模型，该模型结合了ViT编码器、RoBERTa解码器和CLIP集成模块，通过双重注意力机制提高了图像描述的准确性。&lt;h4&gt;背景&lt;/h4&gt;图像描述生成对于提升可访问性和AI对视觉内容的理解至关重要。深度学习在自然语言处理和计算机视觉领域的进步为图像描述生成提供了新的可能性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成准确、丰富上下文和灵活的图像描述的模型。&lt;h4&gt;方法&lt;/h4&gt;Tri-FusionNet模型集成了ViT编码器、RoBERTa解码器和CLIP集成模块，并使用双重注意力机制来增强图像特征提取和文本描述生成。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在Flickr30k和Flickr8k数据集上表现出色，在MS-COCO数据集上也取得了良好的结果。&lt;h4&gt;结论&lt;/h4&gt;Tri-FusionNet在生成高质量图像描述方面是有效的，证明了其在图像描述生成领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Image description generation is essential for accessibility and AI understanding of visual content. Recent advancements in deep learning have significantly improved natural language processing and computer vision. In this work, we propose Tri-FusionNet, a novel image description generation model that integrates transformer modules: a Vision Transformer (ViT) encoder module with dual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decoder module, and a Contrastive Language-Image Pre-Training (CLIP) integrating module. The ViT encoder, enhanced with dual attention, focuses on relevant spatial regions and linguistic context, improving image feature extraction. The RoBERTa decoder is employed to generate precise textual descriptions. CLIP's integrating module aligns visual and textual data through contrastive learning, ensuring effective combination of both modalities. This fusion of ViT, RoBERTa, and CLIP, along with dual attention, enables the model to produce more accurate, contextually rich, and flexible descriptions. The proposed framework demonstrated competitive performance on the Flickr30k and Flickr8k datasets, with BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scores of 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of 0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scores of 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The results demonstrate the effectiveness of Tri-FusionNet in generating high-quality image descriptions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image description generation is essential for accessibility and AIunderstanding of visual content. Recent advancements in deep learning havesignificantly improved natural language processing and computer vision. In thiswork, we propose Tri-FusionNet, a novel image description generation model thatintegrates transformer modules: a Vision Transformer (ViT) encoder module withdual-attention mechanism, a Robustly Optimized BERT Approach (RoBERTa) decodermodule, and a Contrastive Language-Image Pre-Training (CLIP) integratingmodule. The ViT encoder, enhanced with dual attention, focuses on relevantspatial regions and linguistic context, improving image feature extraction. TheRoBERTa decoder is employed to generate precise textual descriptions. CLIP'sintegrating module aligns visual and textual data through contrastive learning,ensuring effective combination of both modalities. This fusion of ViT, RoBERTa,and CLIP, along with dual attention, enables the model to produce moreaccurate, contextually rich, and flexible descriptions. The proposed frameworkdemonstrated competitive performance on the Flickr30k and Flickr8k datasets,with BLEU scores ranging from 0.767 to 0.456 and 0.784 to 0.479, CIDEr scoresof 1.679 and 1.483, METEOR scores of 0.478 and 0.358, and ROUGE-L scores of0.567 and 0.789, respectively. On MS-COCO, the framework obtained BLEU scoresof 0.893 (B-1), 0.821 (B-2), 0.794 (B-3), and 0.725 (B-4). The resultsdemonstrate the effectiveness of Tri-FusionNet in generating high-quality imagedescriptions.</description>
      <author>example@mail.com (Lakshita Agarwal, Bindu Verma)</author>
      <guid isPermaLink="false">2504.16761v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Graph2Nav: 3D Object-Relation Graph Generation to Robot Navigation</title>
      <link>http://arxiv.org/abs/2504.16782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Graph2Nav的实时3D对象-关系图生成框架，用于现实世界的自主导航。&lt;h4&gt;背景&lt;/h4&gt;在室内和室外场景中，需要处理3D场景中的对象和语义关系。&lt;h4&gt;目的&lt;/h4&gt;生成和利用3D场景图中的3D对象和丰富的语义关系，以实现自主导航。&lt;h4&gt;方法&lt;/h4&gt;通过3D语义映射技术，将最先进的2D全景场景图工作扩展到3D世界，学习生成对象间的3D语义关系。避免直接从3D数据中学习3D场景图的训练数据限制。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了在3D场景图中定位3D对象和标注对象关系的高精度。通过将Graph2Nav与基于大型语言模型的顶尖规划器SayNav集成，评估了其在无人地面机器人在现实环境中的目标搜索任务中的影响。&lt;h4&gt;结论&lt;/h4&gt;在场景图中建模对象关系可以提高导航任务中的搜索效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Graph2Nav的实时3D对象-关系图生成框架，用于现实世界的自主导航。我们的框架能够全面生成和利用3D场景图中的3D对象和丰富的语义关系，适用于室内和室外场景。通过利用和推进最先进的2D全景场景图工作到3D世界，通过3D语义映射技术学习生成对象间的3D语义关系。这种方法避免了从3D数据直接学习3D场景图的训练数据限制。我们通过实验验证了在3D场景图中定位3D对象和标注对象关系的高精度。我们还通过将Graph2Nav与基于大型语言模型的顶尖规划器SayNav集成，评估了其在无人地面机器人在现实环境中的目标搜索任务中的影响。我们的结果表明，在场景图中建模对象关系可以提高这些导航任务中的搜索效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Graph2Nav, a real-time 3D object-relation graph generationframework, for autonomous navigation in the real world. Our framework fullygenerates and exploits both 3D objects and a rich set of semantic relationshipsamong objects in a 3D layered scene graph, which is applicable to both indoorand outdoor scenes. It learns to generate 3D semantic relations among objects,by leveraging and advancing state-of-the-art 2D panoptic scene graph works intothe 3D world via 3D semantic mapping techniques. This approach avoids previoustraining data constraints in learning 3D scene graphs directly from 3D data. Weconduct experiments to validate the accuracy in locating 3D objects andlabeling object-relations in our 3D scene graphs. We also evaluate the impactof Graph2Nav via integration with SayNav, a state-of-the-art planner based onlarge language models, on an unmanned ground robot to object search tasks inreal environments. Our results demonstrate that modeling object relations inour scene graphs improves search efficiency in these navigation tasks.</description>
      <author>example@mail.com (Tixiao Shan, Abhinav Rajvanshi, Niluthpol Mithun, Han-Pang Chiu)</author>
      <guid isPermaLink="false">2504.16782v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>PCF-Grasp: Converting Point Completion to Geometry Feature to Enhance 6-DoF Grasp</title>
      <link>http://arxiv.org/abs/2504.16320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于点云的6自由度抓取方法，通过利用完整点云特征和分数过滤器来提高抓取准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于单视图深度图像生成的点云（2.5D点）只能提供物体的一侧表面信息，导致抓取算法对目标物体形状的判断不准确，影响抓取精度。&lt;h4&gt;目的&lt;/h4&gt;提高机器人从单视角准确抓取物体的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的6自由度抓取框架，该框架将点云补全结果作为物体形状特征来训练6自由度抓取网络。点云补全可以从2.5D点生成近似完整的点，类似于人类的几何经验。此外，为了解决网络生成与实际执行之间的差距，框架中集成了分数过滤器，以选择更多可执行的抓取建议。&lt;h4&gt;主要发现&lt;/h4&gt;使用完整点云特征可以生成更准确的抓取建议，而分数过滤器的引入大大增强了现实世界机器人抓取的可靠性。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界实验中比现有方法提高了17.8%的成功率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于点云的6自由度（DoF）抓取方法在使机器人能够抓取目标物体方面显示出巨大的潜力。然而，大多数现有方法都是基于从单视图深度图像生成的点云（2.5D点）。这些点云只提供了物体的一侧表面信息，导致抓取算法对目标物体形状的判断不准确，从而降低了抓取精度。人类可以通过利用他们的几何经验来估计物体形状，从而从单视角准确抓取物体。受人类的启发，我们提出了一种新的6自由度抓取框架，该框架将点云补全结果作为物体形状特征来训练6自由度抓取网络。在这里，点云补全可以从2.5D点生成近似完整的点，类似于人类的几何经验，将其转换为形状特征是利用它的方式，以提高抓取效率。此外，由于网络生成与实际执行之间存在差距，我们将在我们的框架中集成一个分数过滤器，以选择更多可执行的抓取建议。这使得我们的方法能够在任何相机视图中保持高抓取质量。大量的实验表明，利用完整点云特征可以生成更准确的抓取建议，而分数过滤器的引入大大增强了现实世界机器人抓取的可靠性。我们的方法在现实世界实验中比现有方法提高了17.8%的成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 6-Degree of Freedom (DoF) grasp method based on point clouds has shownsignificant potential in enabling robots to grasp target objects. However, mostexisting methods are based on the point clouds (2.5D points) generated fromsingle-view depth images. These point clouds only have one surface side of theobject providing incomplete geometry information, which mislead the graspingalgorithm to judge the shape of the target object, resulting in low graspingaccuracy. Humans can accurately grasp objects from a single view by leveragingtheir geometry experience to estimate object shapes. Inspired by humans, wepropose a novel 6-DoF grasping framework that converts the point completionresults as object shape features to train the 6-DoF grasp network. Here, pointcompletion can generate approximate complete points from the 2.5D pointssimilar to the human geometry experience, and converting it as shape featuresis the way to utilize it to improve grasp efficiency. Furthermore, due to thegap between the network generation and actual execution, we integrate a scorefilter into our framework to select more executable grasp proposals for thereal robot. This enables our method to maintain a high grasp quality in anycamera viewpoint. Extensive experiments demonstrate that utilizing completepoint features enables the generation of significantly more accurate graspproposals and the inclusion of a score filter greatly enhances the credibilityof real-world robot grasping. Our method achieves a 17.8\% success rate higherthan the state-of-the-art method in real-world experiments.</description>
      <author>example@mail.com (Yaofeng Cheng, Fusheng Zha, Wei Guo, Pengfei Wang, Chao Zeng, Lining Sun, Chenguang Yang)</author>
      <guid isPermaLink="false">2504.16320v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Improving Significant Wave Height Prediction Using Chronos Models</title>
      <link>http://arxiv.org/abs/2504.16834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究介绍了Chronos，这是第一个使用大型语言模型（LLM）驱动的时序架构（Chronos），专门优化用于波浪预测。Chronos在波浪预测方面实现了多方面的改进。&lt;h4&gt;背景&lt;/h4&gt;准确预测波浪高度对海事安全和海岸韧性至关重要，但传统的基于物理的模型和传统的机器学习方法在计算效率和非线性动力学建模方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;引入Chronos，优化波浪预测的计算效率，并提高波浪预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过将高级时序模式识别应用于来自西北太平洋三个战略选定的海洋区域的历波数据，Chronos实现了多模态改进。&lt;h4&gt;主要发现&lt;/h4&gt;Chronos实现了以下改进：(1)与PatchTST基线相比，训练时间减少了14.3%，推理速度提高了2.5倍，达到0.575的平均绝对缩放误差（MASE）单位；(2)在短期预测（1-24小时）方面表现优异；(3)在长期预测（1-120小时）中持续保持预测优势；(4)在零样本能力方面表现出色，与专业操作模型相比，保持了中位性能（排名第4/12）。&lt;h4&gt;结论&lt;/h4&gt;LLM增强的时序建模范式在波浪预测中建立了新的标准，提供了计算效率高的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测波浪高度对海事安全和海岸韧性至关重要，然而，传统的基于物理的模型和传统的机器学习方法在计算效率和非线性动力学建模方面存在挑战。本研究引入了Chronos，这是第一个使用大型语言模型（LLM）驱动的时序架构（Chronos），专门用于波浪预测。通过将高级时序模式识别应用于来自西北太平洋三个战略选定的海洋区域的历波数据，我们的框架实现了多模态改进：(1)与PatchTST基线相比，训练时间减少了14.3%，推理速度提高了2.5倍，达到0.575的平均绝对缩放误差（MASE）单位；(2)在短期预测（1-24小时）方面表现优异；(3)在长期预测（1-120小时）中持续保持预测优势；(4)在零样本能力方面表现出色，与专业操作模型相比，保持了中位性能（排名第4/12）。这种LLM增强的时序建模范式在波浪预测中建立了新的标准，提供了计算效率高的解决方案，并为复杂地球物理系统建模提供了一个可转移的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate wave height prediction is critical for maritime safety and coastalresilience, yet conventional physics-based models and traditional machinelearning methods face challenges in computational efficiency and nonlineardynamics modeling. This study introduces Chronos, the first implementation of alarge language model (LLM)-powered temporal architecture (Chronos) optimizedfor wave forecasting. Through advanced temporal pattern recognition applied tohistorical wave data from three strategically chosen marine zones in theNorthwest Pacific basin, our framework achieves multimodal improvements: (1)14.3% reduction in training time with 2.5x faster inference speed compared toPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)sustained predictive leadership in extended-range forecasts (1-120h); and (4)demonstrated zero-shot capability maintaining median performance (rank 4/12)against specialized operational models. This LLM-enhanced temporal modelingparadigm establishes a new standard in wave prediction, offering bothcomputationally efficient solutions and a transferable framework for complexgeophysical systems modeling.</description>
      <author>example@mail.com (Yilin Zhai, Hongyuan Shi, Chao Zhan, Qing Wang, Zaijin You, Nan Wang)</author>
      <guid isPermaLink="false">2504.16834v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning via Non-Contrastive Mutual Information</title>
      <link>http://arxiv.org/abs/2504.16667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MINC的自监督目标函数，旨在结合对比学习和非对比学习的优点，以从无标签图像数据中学习更有意义的潜在表示。&lt;h4&gt;背景&lt;/h4&gt;标注数据耗时且昂贵，导致大量数据未标注。自监督表示学习方法如SimCLR和BYOL在从无标签图像数据中学习潜在表示方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;开发一个结合对比学习和非对比学习优点的自监督目标函数。&lt;h4&gt;方法&lt;/h4&gt;将特定的对比方法Spectral Contrastive Loss转换为更通用的非对比形式，以降低方差并防止模型坍塌。&lt;h4&gt;主要发现&lt;/h4&gt;MINC损失在ImageNet数据集上测试时，表现优于Spectral Contrastive Loss基线。&lt;h4&gt;结论&lt;/h4&gt;MINC损失能够有效地从无标签图像数据中学习潜在表示，并提高下游任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Labeling data is often very time consuming and expensive, leaving us with amajority of unlabeled data. Self-supervised representation learning methodssuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been verysuccessful at learning meaningful latent representations from unlabeled imagedata, resulting in much more general and transferable representations fordownstream tasks. Broadly, self-supervised methods fall into two types: 1)Contrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such asBYOL. Contrastive methods are generally trying to maximize mutual informationbetween related data points, so they need to compare every data point to everyother data point, resulting in high variance, and thus requiring large batchsizes to work well. Non-contrastive methods like BYOL have much lower varianceas they do not need to make pairwise comparisons, but are much trickier toimplement as they have the possibility of collapsing to a constant vector. Inthis paper, we aim to develop a self-supervised objective that combines thestrength of both types. We start with a particular contrastive method calledthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and weconvert it into a more general non-contrastive form; this removes the pairwisecomparisons resulting in lower variance, but keeps the mutual informationformulation of the contrastive method preventing collapse. We call our newobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC bylearning image representations on ImageNet (similar to SimCLR and BYOL) andshow that it consistently improves upon the Spectral Contrastive loss baseline.</description>
      <author>example@mail.com (Zhaohan Daniel Guo, Bernardo Avila Pires, Khimya Khetarpal, Dale Schuurmans, Bo Dai)</author>
      <guid isPermaLink="false">2504.16667v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Uncertainty in Shape Completion to Improve Grasp Quality</title>
      <link>http://arxiv.org/abs/2504.16183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种计算3D形状补全模型不确定性的方法，并更新了抓取姿态算法的质量评分，通过引入补全点云的不确定性。实验结果表明，该方法在抓取成功率上优于现有技术。&lt;h4&gt;背景&lt;/h4&gt;形状补全网络在真实世界机器人实验中用于完成物体缺失或隐藏信息，但现有模型由于非确定性推理可能存在不准确，影响抓取效果。&lt;h4&gt;目的&lt;/h4&gt;计算3D形状补全模型的不确定性，并提高抓取姿态算法的质量评分。&lt;h4&gt;方法&lt;/h4&gt;提出了一种计算不确定性的方法，并在抓取姿态算法中引入了补全点云的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够提高抓取成功率，特别是在排名前5的抓取候选者中。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在抓取成功率上优于现有技术，为形状补全模型的不确定性处理提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;Shape completion networks have been used recently in real-world robotic experiments to complete the missing/hidden information in environments where objects are only observed in one or few instances where self-occlusions are bound to occur. Nowadays, most approaches rely on deep neural networks that handle rich 3D point cloud data that lead to more precise and realistic object geometries. However, these models still suffer from inaccuracies due to its non-deterministic/stochastic inferences which could lead to poor performance in grasping scenarios where these errors compound to unsuccessful grasps. We present an approach to calculate the uncertainty of a 3D shape completion model during inference of single view point clouds of an object on a table top. In addition, we propose an update to grasp pose algorithms quality score by introducing the uncertainty of the completed point cloud present in the grasp candidates. To test our full pipeline we perform real world grasping with a 7dof robotic arm with a 2 finger gripper on a large set of household objects and compare against previous approaches that do not measure uncertainty. Our approach ranks the grasp quality better, leading to higher grasp success rate for the rank 5 grasp candidates compared to state of the art.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Shape completion networks have been used recently in real-world roboticexperiments to complete the missing/hidden information in environments whereobjects are only observed in one or few instances where self-occlusions arebound to occur. Nowadays, most approaches rely on deep neural networks thathandle rich 3D point cloud data that lead to more precise and realistic objectgeometries. However, these models still suffer from inaccuracies due to itsnondeterministic/stochastic inferences which could lead to poor performance ingrasping scenarios where these errors compound to unsuccessful grasps. Wepresent an approach to calculate the uncertainty of a 3D shape completion modelduring inference of single view point clouds of an object on a table top. Inaddition, we propose an update to grasp pose algorithms quality score byintroducing the uncertainty of the completed point cloud present in the graspcandidates. To test our full pipeline we perform real world grasping with a7dof robotic arm with a 2 finger gripper on a large set of household objectsand compare against previous approaches that do not measure uncertainty. Ourapproach ranks the grasp quality better, leading to higher grasp success ratefor the rank 5 grasp candidates compared to state of the art.</description>
      <author>example@mail.com (Nuno Ferreira Duarte, Seyed S. Mohammadi, Plinio Moreno, Alessio Del Bue, Jose Santos-Victor)</author>
      <guid isPermaLink="false">2504.16183v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Graph Representation Based on Substructure-Aware Graph Optimal Matching Kernel Convolutional Networks</title>
      <link>http://arxiv.org/abs/2504.16360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Graph Optimal Matching Kernel Convolutional Network (GOMKCN)的新方法，用于改进图表示学习，以解决现有方法在结构模式分析方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图表示学习中被广泛应用，但现有方法通常隐式且粗略地描述图结构，限制了图内结构模式分析。&lt;h4&gt;目的&lt;/h4&gt;提出GOMKCN以解决现有方法在结构模式分析方面的局限性，并提高图模式挖掘和预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;GOMKCN将图视为以节点为中心的子图，每个子图作为编码位置特定信息的结构因素。它引入了Graph Optimal Matching Kernel (GOMK)作为卷积算子，计算子图之间的相似性，并学习可调的图滤波器。GOMK将子图和滤波器映射到希尔伯特空间，将图表示为点集。通过将子图投影到任务优化的滤波器上，GOMKCN通过梯度下降自适应地捕获相关的结构模式。&lt;h4&gt;主要发现&lt;/h4&gt;GOMKCN通过局部对应关系在相似性测量中整合，解决了图核中可微性和准确性的权衡问题。&lt;h4&gt;结论&lt;/h4&gt;实验验证了GOMKCN在图模式挖掘和预测中的优越准确性和可解释性，为解耦图表示学习的理论基础做出了贡献。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new method called Graph Optimal Matching Kernel Convolutional Network (GOMKCN) to improve graph representation learning and address the limitations of existing methods in structural pattern analysis. GOMKCN treats graphs as node-centric subgraphs, where each subgraph acts as a structural factor encoding position-specific information. It introduces the Graph Optimal Matching Kernel (GOMK) as a convolutional operator, computing similarities between subgraphs and learnable graph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbert space, representing graphs as point sets. GOMKCN emerges from projecting subgraphs onto task-optimized filters, which adaptively capture relevant structural patterns via gradient descent. Crucially, GOMK incorporates local correspondences in similarity measurement, resolving the trade-off between differentiability and accuracy in graph kernels. Experiments validate that GOMKCN achieves superior accuracy and interpretability in graph pattern mining and prediction. The framework advances the theoretical foundation for disentangled graph representation learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs effectively characterize relational data, driving graph representationlearning methods that uncover underlying predictive information. Asstate-of-the-art approaches, Graph Neural Networks (GNNs) enable end-to-endlearning for diverse tasks. Recent disentangled graph representation learningenhances interpretability by decoupling independent factors in graph data.However, existing methods often implicitly and coarsely characterize graphstructures, limiting structural pattern analysis within the graph. This paperproposes the Graph Optimal Matching Kernel Convolutional Network (GOMKCN) toaddress this limitation. We view graphs as node-centric subgraphs, where eachsubgraph acts as a structural factor encoding position-specific information.This transforms graph prediction into structural pattern recognition. Inspiredby CNNs, GOMKCN introduces the Graph Optimal Matching Kernel (GOMK) as aconvolutional operator, computing similarities between subgraphs and learnablegraph filters. Mathematically, GOMK maps subgraphs and filters into a Hilbertspace, representing graphs as point sets. Disentangled representations emergefrom projecting subgraphs onto task-optimized filters, which adaptively capturerelevant structural patterns via gradient descent. Crucially, GOMK incorporateslocal correspondences in similarity measurement, resolving the trade-offbetween differentiability and accuracy in graph kernels. Experiments validatethat GOMKCN achieves superior accuracy and interpretability in graph patternmining and prediction. The framework advances the theoretical foundation fordisentangled graph representation learning.</description>
      <author>example@mail.com (Mao Wang, Tao Wu, Xingping Xian, Shaojie Qiao, Weina Niu, Canyixing Cui)</author>
      <guid isPermaLink="false">2504.16360v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Radar Camera Alignment by Contrastive Learning for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.16368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RCAlign的新对齐模型，用于雷达和摄像头融合的3D目标检测，显著提升了实时3D检测的性能。&lt;h4&gt;背景&lt;/h4&gt;基于雷达和摄像头融合的3D目标检测算法在自动驾驶感知任务中表现出色，但现有方法在处理雷达和摄像头之间的特征错位问题方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出RCAlign模型以解决雷达和摄像头特征对齐中的问题，并提高3D目标检测的性能。&lt;h4&gt;方法&lt;/h4&gt;RCAlign模型包括一个基于对比学习的双路由对齐模块（DRA），用于对齐和融合雷达与摄像头之间的特征；以及一个雷达特征增强模块（RFE），通过知识蒸馏损失来提高雷达BEV特征的密度。&lt;h4&gt;主要发现&lt;/h4&gt;RCAlign在公共nuScenes基准测试中实现了雷达摄像头融合3D目标检测的新纪录，并且在实时3D检测中相比最新最先进的方法，性能提升了4.3% NDS和8.4% mAP。&lt;h4&gt;结论&lt;/h4&gt;RCAlign模型在雷达摄像头融合的3D目标检测中具有显著优势，为自动驾驶感知任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, 3D object detection algorithms based on radar and camera fusionhave shown excellent performance, setting the stage for their application inautonomous driving perception tasks. Existing methods have focused on dealingwith feature misalignment caused by the domain gap between radar and camera.However, existing methods either neglect inter-modal features interactionduring alignment or fail to effectively align features at the same spatiallocation across modalities. To alleviate the above problems, we propose a newalignment model called Radar Camera Alignment (RCAlign). Specifically, wedesign a Dual-Route Alignment (DRA) module based on contrastive learning toalign and fuse the features between radar and camera. Moreover, considering thesparsity of radar BEV features, a Radar Feature Enhancement (RFE) module isproposed to improve the densification of radar BEV features with the knowledgedistillation loss. Experiments show RCAlign achieves a new state-of-the-art onthe public nuScenes benchmark in radar camera fusion for 3D Object Detection.Furthermore, the RCAlign achieves a significant performance gain (4.3\% NDS and8.4\% mAP) in real-time 3D detection compared to the latest state-of-the-artmethod (RCBEVDet).</description>
      <author>example@mail.com (Linhua Kong, Dongxia Chang, Lian Liu, Zisen Kong, Pengyuan Li, Yao Zhao)</author>
      <guid isPermaLink="false">2504.16368v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms</title>
      <link>http://arxiv.org/abs/2504.16420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基于基础模型（FM）的推荐系统（FM4RecSys），探讨了FM在特征增强、生成推荐和交互式系统中的应用。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在过滤信息和个性化内容方面变得至关重要，传统的推荐系统技术依赖于用户与物品之间交互的建模以及内容特征的建模。&lt;h4&gt;目的&lt;/h4&gt;提供对FM4RecSys的全面概述，包括其集成在三个范式中的方式：特征表示增强、生成式推荐方法和代理交互系统。&lt;h4&gt;方法&lt;/h4&gt;首先回顾了推荐系统的数据基础，然后介绍了FM及其在推荐系统环境中的表示学习、自然语言理解和多模态推理的能力，接着讨论了FM在不同范式下如何增强推荐系统，并分析了FM在各个推荐任务中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析近期研究，突出了实现的关键机会以及遇到的挑战，并概述了下一代FM4RecSys的开放研究方向和技术挑战。&lt;h4&gt;结论&lt;/h4&gt;本文不仅回顾了最先进的方法，还对基于特征、生成和代理的范式之间的权衡进行了批判性分析，概述了关键开放问题和未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) have become essential in filtering information andpersonalizing content for users. RS techniques have traditionally relied onmodeling interactions between users and items as well as the features ofcontent using models specific to each task. The emergence of foundation models(FMs), large scale models trained on vast amounts of data such as GPT, LLaMAand CLIP, is reshaping the recommendation paradigm. This survey provides acomprehensive overview of the Foundation Models for Recommender Systems(FM4RecSys), covering their integration in three paradigms: (1) Feature-Basedaugmentation of representations, (2) Generative recommendation approaches, and(3) Agentic interactive systems. We first review the data foundations of RS,from traditional explicit or implicit feedback to multimodal content sources.We then introduce FMs and their capabilities for representation learning,natural language understanding, and multi-modal reasoning in RS contexts. Thecore of the survey discusses how FMs enhance RS under different paradigms.Afterward, we examine FM applications in various recommendation tasks. Throughan analysis of recent research, we highlight key opportunities that have beenrealized as well as challenges encountered. Finally, we outline open researchdirections and technical challenges for next-generation FM4RecSys. This surveynot only reviews the state-of-the-art methods but also provides a criticalanalysis of the trade-offs among the feature-based, the generative, and theagentic paradigms, outlining key open issues and future research directions.</description>
      <author>example@mail.com (Chengkai Huang, Hongtao Huang, Tong Yu, Kaige Xie, Junda Wu, Shuai Zhang, Julian Mcauley, Dietmar Jannach, Lina Yao)</author>
      <guid isPermaLink="false">2504.16420v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models</title>
      <link>http://arxiv.org/abs/2504.16357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为DP2FL的个性化联邦学习框架，旨在解决在数据隐私保护的同时，如何提高在数据有限情况下的深度学习模型性能的问题。&lt;h4&gt;背景&lt;/h4&gt;个性化联邦学习（PFL）在处理异构客户端数据分布和保持数据隐私方面受到关注。然而，当本地客户端数据有限时，深度学习模型往往因训练不足而导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出DP2FL框架，以解决上述问题，通过引入双提示和自适应聚合策略，结合全局任务意识和本地数据驱动见解，使本地模型能够实现有效的泛化，同时适应特定的数据分布。&lt;h4&gt;方法&lt;/h4&gt;DP2FL框架结合了全局模型和本地数据，通过双提示和自适应聚合策略，实现新数据的预测和无缝集成新客户端，而无需重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;在高度异构的环境中进行的实验验证了DP2FL提示设计和聚合策略的有效性，强调了在新型数据源上进行预测的优势，并展示了新客户端无缝集成到联邦学习框架中的能力。&lt;h4&gt;结论&lt;/h4&gt;DP2FL框架通过其创新的设计，为解决联邦学习中的数据隐私和模型性能问题提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized federated learning (PFL) has garnered significant attention forits ability to address heterogeneous client data distributions while preservingdata privacy. However, when local client data is limited, deep learning modelsoften suffer from insufficient training, leading to suboptimal performance.Foundation models, such as CLIP (Contrastive Language-Image Pretraining),exhibit strong feature extraction capabilities and can alleviate this issue byfine-tuning on limited local data. Despite their potential, foundation modelsare rarely utilized in federated learning scenarios, and challenges related tointegrating new clients remain largely unresolved. To address these challenges,we propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,which introduces dual prompts and an adaptive aggregation strategy. DP2FLcombines global task awareness with local data-driven insights, enabling localmodels to achieve effective generalization while remaining adaptable tospecific data distributions. Moreover, DP2FL introduces a global model thatenables prediction on new data sources and seamlessly integrates newly addedclients without requiring retraining. Experimental results in highlyheterogeneous environments validate the effectiveness of DP2FL's prompt designand aggregation strategy, underscoring the advantages of prediction on noveldata sources and demonstrating the seamless integration of new clients into thefederated learning framework.</description>
      <author>example@mail.com (Ying Chang, Xiaohu Shi, Xiaohui Zhao, Zhaohuang Chen, Deyin Ma)</author>
      <guid isPermaLink="false">2504.16357v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance</title>
      <link>http://arxiv.org/abs/2504.16505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了TraveLLaMA，一个专为城市场景理解和旅行辅助设计的多模态语言模型，并展示了其在旅行特定任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态AI系统在处理城市环境时缺乏专业知识，而旅行规划和旅游越来越依赖于数字辅助。&lt;h4&gt;目的&lt;/h4&gt;开发实用的AI旅行助手，并提高城市场景理解和旅行辅助的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个包含220k个问答对的大规模数据集，结合从真实旅行论坛中精心挑选的130k个文本问答对和GPT增强的响应，以及90k个专注于地图理解和场景理解的视觉-语言问答对。在LLaVA、Qwen-VL和Shikra等最先进的视觉-语言模型上进行广泛的微调实验。&lt;h4&gt;主要发现&lt;/h4&gt;TraveLLaMA在纯文本旅行理解和视觉问答任务上的性能提高了6.5%-9.4%，在提供上下文旅行推荐、解释地图位置、理解特定场所的图像以及提供实用信息（如开放时间和游客评论）方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;TraveLLaMA在旅行特定任务上显著优于通用模型，为多模态旅行辅助系统设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：旅游和旅行规划越来越依赖数字辅助，但现有的多模态AI系统通常缺乏对城市环境的专门知识和上下文理解。我们提出了TraveLLaMA，这是一个专为城市场景理解和旅行辅助设计的多模态语言模型。我们的工作通过一个包含220k个问答对的创新大规模数据集来解决开发实用AI旅行助手的基本挑战。这个综合数据集独特地结合了从真实旅行论坛中精心挑选的130k个文本问答对和GPT增强的响应，以及90k个专注于地图理解和场景理解的视觉-语言问答对。通过对最先进的视觉-语言模型（LLaVA、Qwen-VL、Shikra）进行广泛的微调实验，我们在纯文本旅行理解和视觉问答任务上展示了显著的性能提升，范围从6.5%-9.4%。我们的模型在提供上下文旅行推荐、解释地图位置、理解特定场所的图像以及提供实用信息（如开放时间和游客评论）方面表现出色。比较评估表明，TraveLLaMA在旅行特定任务上显著优于通用模型，为多模态旅行辅助系统设定了新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tourism and travel planning increasingly rely on digital assistance, yetexisting multimodal AI systems often lack specialized knowledge and contextualunderstanding of urban environments. We present TraveLLaMA, a specializedmultimodal language model designed for urban scene understanding and travelassistance. Our work addresses the fundamental challenge of developingpractical AI travel assistants through a novel large-scale dataset of 220kquestion-answer pairs. This comprehensive dataset uniquely combines 130k textQA pairs meticulously curated from authentic travel forums with GPT-enhancedresponses, alongside 90k vision-language QA pairs specifically focused on mapunderstanding and scene comprehension. Through extensive fine-tuningexperiments on state-of-the-art vision-language models (LLaVA, Qwen-VL,Shikra), we demonstrate significant performance improvements ranging from6.5\%-9.4\% in both pure text travel understanding and visual questionanswering tasks. Our model exhibits exceptional capabilities in providingcontextual travel recommendations, interpreting map locations, andunderstanding place-specific imagery while offering practical information suchas operating hours and visitor reviews. Comparative evaluations show TraveLLaMAsignificantly outperforms general-purpose models in travel-specific tasks,establishing a new benchmark for multi-modal travel assistance systems.</description>
      <author>example@mail.com (Meng Chu, Yukang Chen, Haokun Gui, Shaozuo Yu, Yi Wang, Jiaya Jia)</author>
      <guid isPermaLink="false">2504.16505v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Unified Molecule Generation and Property Prediction</title>
      <link>http://arxiv.org/abs/2504.16559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Hyformer的基于Transformer的联合模型，该模型结合了生成和预测功能，并展示了其在分子表示学习、命中识别和抗菌肽设计等下游任务中的优势。&lt;h4&gt;背景&lt;/h4&gt;建模数据样本及其属性的联合分布可以构建用于数据生成和属性预测的单个模型，其协同能力超越了纯生成或预测模型。&lt;h4&gt;目的&lt;/h4&gt;提出Hyformer模型，以解决联合模型训练中的架构和优化挑战。&lt;h4&gt;方法&lt;/h4&gt;Hyformer使用交替注意力掩码和统一的预训练方案来成功融合生成和预测功能。&lt;h4&gt;主要发现&lt;/h4&gt;Hyformer在与其他联合模型以及最先进的分子生成和属性预测模型中表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;联合建模在分子表示学习、命中识别和抗菌肽设计的下游任务中具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过建模数据样本及其属性的联合分布，可以构建用于数据生成和属性预测的单个模型，其协同能力超越了纯生成或预测模型。然而，联合模型的训练面临着严峻的架构和优化挑战。在此，我们提出了Hyformer，一种基于Transformer的联合模型，该模型成功融合了生成和预测功能，使用了交替注意力掩码和统一的预训练方案。我们发现Hyformer与其他联合模型以及最先进的分子生成和属性预测模型相媲美。此外，我们还展示了联合建模在分子表示学习、命中识别和抗菌肽设计的下游任务中的益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling the joint distribution of the data samples and their propertiesallows to construct a single model for both data generation and propertyprediction, with synergistic capabilities reaching beyond purely generative orpredictive models. However, training joint models presents dauntingarchitectural and optimization challenges. Here, we propose Hyformer, atransformer-based joint model that successfully blends the generative andpredictive functionalities, using an alternating attention mask together with aunified pre-training scheme. We show that Hyformer rivals other joint models,as well as state-of-the-art molecule generation and property prediction models.Additionally, we show the benefits of joint modeling in downstream tasks ofmolecular representation learning, hit identification and antimicrobial peptidedesign.</description>
      <author>example@mail.com (Adam Izdebski, Jan Olszewski, Pankhil Gawade, Krzysztof Koras, Serra Korkmaz, Valentin Rauscher, Jakub M. Tomczak, Ewa Szczurek)</author>
      <guid isPermaLink="false">2504.16559v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>On the Consistency of GNN Explanations for Malware Detection</title>
      <link>http://arxiv.org/abs/2504.16316v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于动态构建CFG并使用混合方法嵌入节点特征，以检测恶意行为。该框架结合了基于规则的编码和基于自动编码器的嵌入，并使用GNN进行分类。此外，还引入了RankFusion方法来提高解释质量，并使用多种解释技术进行评估。&lt;h4&gt;背景&lt;/h4&gt;CFG在分析程序执行和恶意软件行为特征中至关重要，而GNN在恶意软件检测中表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，用于准确识别恶意软件样本并生成可靠且可解释的解释。&lt;h4&gt;方法&lt;/h4&gt;使用混合方法结合规则编码和自动编码器嵌入节点特征，构建基于GNN的分类器，并应用多种解释技术如GNNExplainer、PGExplainer和CaptumExplainer，以及RankFusion方法。还提出了Greedy Edge-wise Composition (GEC)方法来提取子图。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架在准确识别恶意软件样本和生成可靠解释方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效检测恶意软件，并生成可解释的解释，提高了模型的可理解性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：控制流图（CFGs）对于分析程序执行和描述恶意软件行为至关重要。随着图神经网络（GNNs）的广泛应用，基于CFG的表示在恶意软件检测中已被证明非常有效。本研究提出了一种新的框架，该框架动态构建CFG，并使用结合基于规则的编码和基于自动编码器嵌入的混合方法来嵌入节点特征。然后构建了一个基于GNN的分类器，用于从生成的图表示中检测恶意行为。为了提高模型的可解释性，我们应用了最先进的解释技术，包括GNNExplainer、PGExplainer和CaptumExplainer，其中CaptumExplainer使用了三种归因方法：集成梯度、引导反向传播和显著性。此外，我们引入了一种新的聚合方法，称为RankFusion，该方法集成了表现最好的解释器的输出，以增强解释质量。我们还使用两种子图提取策略评估了解释，包括用于提高结构一致性的提出的贪婪边缘组合（GEC）方法。使用准确度、保真度和一致性指标进行的全面评估表明，所提出的框架在准确识别恶意软件样本和生成可靠且可解释的解释方面是有效的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Control Flow Graphs (CFGs) are critical for analyzing program execution andcharacterizing malware behavior. With the growing adoption of Graph NeuralNetworks (GNNs), CFG-based representations have proven highly effective formalware detection. This study proposes a novel framework that dynamicallyconstructs CFGs and embeds node features using a hybrid approach combiningrule-based encoding and autoencoder-based embedding. A GNN-based classifier isthen constructed to detect malicious behavior from the resulting graphrepresentations. To improve model interpretability, we apply state-of-the-artexplainability techniques, including GNNExplainer, PGExplainer, andCaptumExplainer, the latter is utilized three attribution methods: IntegratedGradients, Guided Backpropagation, and Saliency. In addition, we introduce anovel aggregation method, called RankFusion, that integrates the outputs of thetop-performing explainers to enhance the explanation quality. We also evaluateexplanations using two subgraph extraction strategies, including the proposedGreedy Edge-wise Composition (GEC) method for improved structural coherence. Acomprehensive evaluation using accuracy, fidelity, and consistency metricsdemonstrates the effectiveness of the proposed framework in terms of accurateidentification of malware samples and generating reliable and interpretableexplanations.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Griffin Higgins, Roozbeh Razavi-Far, Hesamodin Mohammadian, Ali A. Ghorbani)</author>
      <guid isPermaLink="false">2504.16316v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Time-aware Continual User Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DITTO的新型用户表示学习方法，用于解决传统用户建模方法在任务泛化适应性和时间推移下的泛化能力问题。&lt;h4&gt;背景&lt;/h4&gt;传统用户建模方法主要针对单一特定任务设计模型，但在处理多个任务时存在泛化和适应性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于连续学习的通用用户表示学习方法，以适应任务泛化并提高模型的适应性。&lt;h4&gt;方法&lt;/h4&gt;设计了DITTO框架，该框架能够在项目分布持续变化的情况下缓解灾难性遗忘，同时允许先前任务获取的知识适应当前变化的项目分布。&lt;h4&gt;主要发现&lt;/h4&gt;在实践评估场景下，DITTO优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DITTO在连续学习的通用用户表示学习方面取得进展，提高了模型的泛化和适应性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Traditional user modeling (UM) approaches have primarily focused on designing models for a single specific task, but they face limitations in generalization and adaptability across various tasks. Recognizing these challenges, recent studies have shifted towards continual learning (CL)-based universal user representation learning aiming to develop a single model capable of handling multiple tasks. Despite advancements, existing methods are in fact evaluated under an unrealistic scenario that does not consider the passage of time as tasks progress, which overlooks newly emerged items that may change the item distribution of previous tasks. In this paper, we introduce a practical evaluation scenario on which CL-based universal user representation learning approaches should be evaluated, which takes into account the passage of time as tasks progress. Then, we propose a novel framework Dynamic Time-aware continual user representation learner, named DITTO, designed to alleviate catastrophic forgetting despite continuous shifts in item distribution, while also allowing the knowledge acquired from previous tasks to adapt to the current shifted item distribution. Through our extensive experiments, we demonstrate the superiority of DITTO over state-of-the-art methods under a practical evaluation scenario. Our source code is available at https://github.com/seungyoon-Choi/DITTO_official.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional user modeling (UM) approaches have primarily focused on designingmodels for a single specific task, but they face limitations in generalizationand adaptability across various tasks. Recognizing these challenges, recentstudies have shifted towards continual learning (CL)-based universal userrepresentation learning aiming to develop a single model capable of handlingmultiple tasks. Despite advancements, existing methods are in fact evaluatedunder an unrealistic scenario that does not consider the passage of time astasks progress, which overlooks newly emerged items that may change the itemdistribution of previous tasks. In this paper, we introduce a practicalevaluation scenario on which CL-based universal user representation learningapproaches should be evaluated, which takes into account the passage of time astasks progress. Then, we propose a novel framework Dynamic Time-aware continualuser representation learner, named DITTO, designed to alleviate catastrophicforgetting despite continuous shifts in item distribution, while also allowingthe knowledge acquired from previous tasks to adapt to the current shifted itemdistribution. Through our extensive experiments, we demonstrate the superiorityof DITTO over state-of-the-art methods under a practical evaluation scenario.Our source code is available athttps://github.com/seungyoon-Choi/DITTO_official.</description>
      <author>example@mail.com (Seungyoon Choi, Sein Kim, Hongseok Kang, Wonjoong Kim, Chanyoung Park)</author>
      <guid isPermaLink="false">2504.16501v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Pseudo-Label Refining for Source-free Domain Adaptation</title>
      <link>http://arxiv.org/abs/2504.16692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures, accepted by PRL. code at  https://github.com/Sthen111/EBPR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Energy-Based Pseudo-Label Refining (EBPR)的方法，用于无源数据域适应（SFDA），该方法旨在减少由于伪标签噪声引起的负迁移。&lt;h4&gt;背景&lt;/h4&gt;无源域适应（SFDA）是一个挑战性任务，因为它需要调整模型而不访问源数据。现有的SFDA技术通常依赖于从置信度生成伪标签，这导致负迁移。&lt;h4&gt;目的&lt;/h4&gt;旨在解决现有SFDA技术中由于伪标签噪声导致的负迁移问题。&lt;h4&gt;方法&lt;/h4&gt;EBPR方法为所有样本簇根据其能量分数创建伪标签。计算全局和类别能量阈值以选择性过滤伪标签。此外，引入了对比学习策略来过滤困难样本，将它们与其增强版本对齐，以学习更具判别性的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在Office-31、Office-Home和VisDA-C数据集上验证了该方法，发现我们的模型在性能上优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;EBPR方法在无源域适应任务中表现出色，优于现有的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无源域适应（SFDA），即在不访问源数据的情况下调整模型的过程，是一项既要求高又具有挑战性的任务。现有的SFDA技术通常依赖于从置信度生成的伪标签，这导致由于显著的噪声引起的负迁移。为了解决这一问题，提出了一种基于能量的伪标签细化（EBPR）方法用于SFDA。根据它们的能量分数为所有样本簇创建伪标签。计算全局和类别能量阈值以选择性地过滤伪标签。此外，引入了一种对比学习策略来过滤困难样本，将它们与它们的增强版本对齐，以学习更具判别性的特征。在Office-31、Office-Home和VisDA-C数据集上验证了我们的方法，一致地发现我们的模型在性能上优于最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.patrec.2025.04.004&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Source-free domain adaptation (SFDA), which involves adapting models withoutaccess to source data, is both demanding and challenging. Existing SFDAtechniques typically rely on pseudo-labels generated from confidence levels,leading to negative transfer due to significant noise. To tackle this problem,Energy-Based Pseudo-Label Refining (EBPR) is proposed for SFDA. Pseudo-labelsare created for all sample clusters according to their energy scores. Globaland class energy thresholds are computed to selectively filter pseudo-labels.Furthermore, a contrastive learning strategy is introduced to filter difficultsamples, aligning them with their augmented versions to learn morediscriminative features. Our method is validated on the Office-31, Office-Home,and VisDA-C datasets, consistently finding that our model outperformedstate-of-the-art methods.</description>
      <author>example@mail.com (Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou)</author>
      <guid isPermaLink="false">2504.16692v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Large Language Models for Enhanced Traffic Safety: A Comprehensive Review and Future Trends</title>
      <link>http://arxiv.org/abs/2504.16134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了多模态大型语言模型（MLLMs）在解决传统高级驾驶辅助系统（ADAS）在动态真实场景中的局限性，以及对抗条件下的敏感性，其通过整合跨模态数据如视觉、空间和环境输入，实现全面场景理解，并展望了其在下一代交通安全系统中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;交通安全是全球面临的重大挑战，传统ADAS系统在动态真实场景中往往表现不佳，容易受到对抗条件的影响。&lt;h4&gt;目的&lt;/h4&gt;探讨MLLMs在提高ADAS感知能力、决策能力和对抗鲁棒性方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;对基于MLLMs的方法进行了全面分析，并考察了关键数据集（如KITTI、DRAMA、ML4RoadSafety）在推动研究进展中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;MLLMs能够通过整合多模态数据提升ADAS的感知、决策和对抗鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;MLLMs作为下一代交通安全系统的基础，有望革命化该领域，提供可扩展、情境感知的解决方案，主动降低风险并提高道路安全性。&lt;h4&gt;翻译&lt;/h4&gt;Traffic safety remains a critical global challenge, with traditional Advanced Driver-Assistance Systems (ADAS) often struggling in dynamic real-world scenarios due to fragmented sensor processing and susceptibility to adversarial conditions. This paper reviews the transformative potential of Multimodal Large Language Models (MLLMs) in addressing these limitations by integrating cross-modal data such as visual, spatial, and environmental inputs to enable holistic scene understanding. Through a comprehensive analysis of MLLM-based approaches, we highlight their capabilities in enhancing perception, decision-making, and adversarial robustness, while also examining the role of key datasets (e.g., KITTI, DRAMA, ML4RoadSafety) in advancing research. Furthermore, we outline future directions, including real-time edge deployment, causality-driven reasoning, and human-AI collaboration. By positioning MLLMs as a cornerstone for next-generation traffic safety systems, this review underscores their potential to revolutionize the field, offering scalable, context-aware solutions that proactively mitigate risks and improve overall road safety.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic safety remains a critical global challenge, with traditional AdvancedDriver-Assistance Systems (ADAS) often struggling in dynamic real-worldscenarios due to fragmented sensor processing and susceptibility to adversarialconditions. This paper reviews the transformative potential of Multimodal LargeLanguage Models (MLLMs) in addressing these limitations by integratingcross-modal data such as visual, spatial, and environmental inputs to enableholistic scene understanding. Through a comprehensive analysis of MLLM-basedapproaches, we highlight their capabilities in enhancing perception,decision-making, and adversarial robustness, while also examining the role ofkey datasets (e.g., KITTI, DRAMA, ML4RoadSafety) in advancing research.Furthermore, we outline future directions, including real-time edge deployment,causality-driven reasoning, and human-AI collaboration. By positioning MLLMs asa cornerstone for next-generation traffic safety systems, this reviewunderscores their potential to revolutionize the field, offering scalable,context-aware solutions that proactively mitigate risks and improve overallroad safety.</description>
      <author>example@mail.com (Mohammad Abu Tami, Mohammed Elhenawy, Huthaifa I. Ashqar)</author>
      <guid isPermaLink="false">2504.16134v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits</title>
      <link>http://arxiv.org/abs/2504.16350v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了QAOA-GPT，一个利用生成预训练变压器（GPT）直接合成量子电路的生成框架，用于解决二次无约束二进制优化问题，并在图的最大割问题上进行演示。&lt;h4&gt;背景&lt;/h4&gt;量子计算有潜力提高解决经典计算机计算困难的优化问题的能力，通过提供可能提供加速的新算法方法。&lt;h4&gt;目的&lt;/h4&gt;研究QAOA-GPT框架在生成量子电路方面的有效性，并比较其与传统方法在计算开销和优化效率上的差异。&lt;h4&gt;方法&lt;/h4&gt;采用自适应QAOA方法生成合成数据集，用于训练QAOA-GPT，并通过在精确的图实例集上进行的实验来评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;QAOA-GPT能够生成高质量的新问题实例的量子电路，并成功参数化QAOA，显著降低了经典QAOA和自适应方法的计算开销。&lt;h4&gt;结论&lt;/h4&gt;生成式AI可能是以可扩展方式生成紧凑量子电路的有希望的途径。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces QAOA-GPT, a generative framework that leverages Generative Pretrained Transformers (GPT) to directly synthesize quantum circuits for solving quadratic unconstrained binary optimization problems, and demonstrates it on the MaxCut problem on graphs. To diversify the training circuits and ensure their quality, we have generated a synthetic dataset using the adaptive QAOA approach, a method that incrementally builds and optimizes problem-specific circuits. The experiments conducted on a curated set of graph instances demonstrate that QAOA-GPT, generates high-quality quantum circuits for new problem instances unseen in the training as well as successfully parametrizes QAOA. Our results show that using QAOA-GPT to generate quantum circuits will significantly decrease both the computational overhead of classical QAOA and adaptive approaches that often use gradient evaluation to generate the circuit and the classical optimization of the circuit parameters. Our work shows that generative AI could be a promising avenue to generate compact quantum circuits in a scalable way.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum computing has the potential to improve our ability to solve certainoptimization problems that are computationally difficult for classicalcomputers, by offering new algorithmic approaches that may provide speedupsunder specific conditions. In this work, we introduce QAOA-GPT, a generativeframework that leverages Generative Pretrained Transformers (GPT) to directlysynthesize quantum circuits for solving quadratic unconstrained binaryoptimization problems, and demonstrate it on the MaxCut problem on graphs. Todiversify the training circuits and ensure their quality, we have generated asynthetic dataset using the adaptive QAOA approach, a method that incrementallybuilds and optimizes problem-specific circuits. The experiments conducted on acurated set of graph instances demonstrate that QAOA-GPT, generates highquality quantum circuits for new problem instances unseen in the training aswell as successfully parametrizes QAOA. Our results show that using QAOA-GPT togenerate quantum circuits will significantly decrease both the computationaloverhead of classical QAOA and adaptive approaches that often use gradientevaluation to generate the circuit and the classical optimization of thecircuit parameters. Our work shows that generative AI could be a promisingavenue to generate compact quantum circuits in a scalable way.</description>
      <author>example@mail.com (Ilya Tyagin, Marwa H. Farag, Kyle Sherbert, Karunya Shirali, Yuri Alexeev, Ilya Safro)</author>
      <guid isPermaLink="false">2504.16350v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Generalizable Infrared Small Target Detection: A Real-scene Benchmark and Cross-view Representation Learning</title>
      <link>http://arxiv.org/abs/2504.16487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A benchmark associated with real-world scenes for the Infrared Small  Target Detection (ISTD) is presented&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强领域适应性的红外小目标检测（ISTD）框架，旨在解决ISTD模型在不同场景下泛化能力受限的问题。&lt;h4&gt;背景&lt;/h4&gt;ISTD对传感器类型、观测条件和目标内在特性非常敏感，这些因素可能导致红外图像数据分布的显著差异，即领域偏移，从而阻碍ISTD模型在不同场景下的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，本文旨在提出一种方法来减轻数据集之间的分布偏移，实现跨样本对齐，并提高ISTD模型在噪声环境下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出了以下方法：1. 引入跨视图通道对齐（CCA）来减轻数据集之间的分布偏移；2. 提出跨视图Top-K融合策略，将目标信息与多种背景特征整合，增强模型提取关键数据特征的能力；3. 开发了一种噪声引导的表示学习策略，使模型学习更具噪声鲁棒性的特征表示；4. 制定了专门的红外小目标数据集RealScene-ISTD。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，本文提出的方法在检测概率（Pd）、误报率（Fa）和交并比（IoU）方面表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高ISTD模型的泛化能力，特别是在噪声环境下，并且通过RealScene-ISTD数据集展示了其优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：红外小目标检测（ISTD）对传感器类型、观测条件和目标内在特性高度敏感。这些因素可能导致获取的红外图像数据分布产生显著差异，即领域偏移，这会显著阻碍ISTD模型在多种场景下的泛化能力。为了应对这一挑战，本文提出了一种增强领域适应性的ISTD框架。为了减轻数据集之间的分布偏移并实现跨样本对齐，我们引入了跨视图通道对齐（CCA）。此外，我们提出了跨视图Top-K融合策略，该策略将目标信息与多种背景特征整合，增强了模型提取关键数据特征的能力。为了进一步减轻噪声对ISTD的影响，我们开发了一种噪声引导的表示学习策略。这种方法使模型能够学习更具噪声鲁棒性的特征表示，从而提高其在不同噪声环境下的泛化能力。最后，我们开发了一个专门的红外小目标数据集RealScene-ISTD。与最先进的方法相比，我们的方法在检测概率（Pd）、误报率（Fa）和交并比（IoU）方面表现出了优越的性能。代码可在以下链接找到：https://github.com/luy0222/RealScene-ISTD。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Infrared small target detection (ISTD) is highly sensitive to sensor type,observation conditions, and the intrinsic properties of the target. Thesefactors can introduce substantial variations in the distribution of acquiredinfrared image data, a phenomenon known as domain shift. Such distributiondiscrepancies significantly hinder the generalization capability of ISTD modelsacross diverse scenarios. To tackle this challenge, this paper introduces anISTD framework enhanced by domain adaptation. To alleviate distribution shiftbetween datasets and achieve cross-sample alignment, we introduce Cross-viewChannel Alignment (CCA). Additionally, we propose the Cross-view Top-K Fusionstrategy, which integrates target information with diverse background features,enhancing the model' s ability to extract critical data characteristics. Tofurther mitigate the impact of noise on ISTD, we develop a Noise-guidedRepresentation learning strategy. This approach enables the model to learn morenoise-resistant feature representations, to improve its generalizationcapability across diverse noisy domains. Finally, we develop a dedicatedinfrared small target dataset, RealScene-ISTD. Compared to state-of-the-artmethods, our approach demonstrates superior performance in terms of detectionprobability (Pd), false alarm rate (Fa), and intersection over union (IoU). Thecode is available at: https://github.com/luy0222/RealScene-ISTD.</description>
      <author>example@mail.com (Yahao Lu, Yuehui Li, Xingyuan Guo, Shuai Yuan, Yukai Shi, Liang Lin)</author>
      <guid isPermaLink="false">2504.16487v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>SparseJEPA: Sparse Representation Learning of Joint Embedding Predictive Architectures</title>
      <link>http://arxiv.org/abs/2504.16140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SparseJEPA是一种结合了稀疏表示学习的JEPA框架扩展，旨在提高学习到的表示质量。&lt;h4&gt;背景&lt;/h4&gt;JEPA框架虽然强大，但通常缺乏可解释性，且由于密集的嵌入表示而效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出SparseJEPA，旨在通过集成稀疏表示学习来提高JEPA框架中学习到的表示质量。&lt;h4&gt;方法&lt;/h4&gt;SparseJEPA使用一种惩罚方法，鼓励具有强语义关系的数据特征在潜在空间变量中共享，同时保持预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-100数据集上训练并预训练轻量级视觉Transformer，证明了SparseJEPA的有效性。改进的嵌入在图像分类和低级任务的线性探针迁移学习中得到应用，展示了该架构在不同迁移任务中的多功能性。理论证明表明，分组机制增强了表示质量，通过减少潜在变量间的多信息量，并证明了多信息量的数据处理不等式。&lt;h4&gt;结论&lt;/h4&gt;将稀疏性引入不仅细化了潜在空间，还促进了更有意义和可解释的表示的学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联合嵌入预测架构（JEPA）已成为学习通用表示的有力框架。然而，这些模型通常缺乏可解释性，并且由于密集的嵌入表示而效率低下。我们提出了SparseJEPA，这是一种将稀疏表示学习集成到JEPA框架中的扩展，以提高学习到的表示质量。SparseJEPA采用一种惩罚方法，鼓励具有强语义关系的数据特征在潜在空间变量中共享，同时保持预测性能。我们通过在CIFAR-100数据集上训练并预训练轻量级视觉Transformer来证明SparseJEPA的有效性。改进的嵌入被用于图像分类和低级任务的线性探针迁移学习，展示了该架构在不同迁移任务中的多功能性。此外，我们提供了一个理论证明，表明分组机制增强了表示质量。这是通过显示分组减少了潜在变量之间的多信息量，并证明了多信息量的数据处理不等式。我们的结果表明，引入稀疏性不仅细化了潜在空间，还促进了更有意义和可解释的表示的学习。在进一步的工作中，希望通过以对象为中心的表示学习找到利用分组机制的新方法来进一步扩展这种方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint Embedding Predictive Architectures (JEPA) have emerged as a powerfulframework for learning general-purpose representations. However, these modelsoften lack interpretability and suffer from inefficiencies due to denseembedding representations. We propose SparseJEPA, an extension that integratessparse representation learning into the JEPA framework to enhance the qualityof learned representations. SparseJEPA employs a penalty method that encourageslatent space variables to be shared among data features with strong semanticrelationships, while maintaining predictive performance. We demonstrate theeffectiveness of SparseJEPA by training on the CIFAR-100 dataset andpre-training a lightweight Vision Transformer. The improved embeddings areutilized in linear-probe transfer learning for both image classification andlow-level tasks, showcasing the architecture's versatility across differenttransfer tasks. Furthermore, we provide a theoretical proof that demonstratesthat the grouping mechanism enhances representation quality. This was done bydisplaying that grouping reduces Multiinformation among latent-variables,including proofing the Data Processing Inequality for Multiinformation. Ourresults indicate that incorporating sparsity not only refines the latent spacebut also facilitates the learning of more meaningful and interpretablerepresentations. In further work, hope to further extend this method by findingnew ways to leverage the grouping mechanism through object-centricrepresentation learning.</description>
      <author>example@mail.com (Max Hartman, Lav Varshney)</author>
      <guid isPermaLink="false">2504.16140v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation</title>
      <link>http://arxiv.org/abs/2504.16576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 8 figures. This manuscript is currently under major  revision for ACM Transactions on Multimedia Computing, Communications, and  Applications (ACM TOMM)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态超图对比学习框架（MMHCL）用于用户推荐。&lt;h4&gt;背景&lt;/h4&gt;多模态内容分享平台的兴起推动了个性化推荐系统的发展，但以往工作存在数据稀疏和冷启动问题，且无法充分探索多模态数据中的语义用户-产品关联。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出MMHCL框架以用于用户推荐。&lt;h4&gt;方法&lt;/h4&gt;构建了两个超图，即用户到用户（u2u）超图和项目到项目（i2i）超图，分别挖掘用户间的共享偏好和项目间的复杂多模态语义相似性。通过融合一级用户-项目交互作为补充，以缓解数据稀疏性问题。然后，通过应用协同对比学习设计对比特征增强范式，通过最大化/最小化相同/不同用户和项目的二级（如用户共享偏好模式）和一级（用户选择的物品信息）嵌入之间的互信息，有效增强特征可区分性。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用稀疏的用户-项目交互相比，MMHCL获得了更密集的二级超图，挖掘了更丰富的共享属性来探索用户-产品关联，在一定程度上缓解了数据稀疏和冷启动问题。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验全面证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The burgeoning presence of multimodal content-sharing platforms propels the development of personalized recommender systems. Previous works usually suffer from data sparsity and cold-start problems, and may fail to adequately explore semantic user-product associations from multimodal data. To address these issues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL) framework for user recommendation. For a comprehensive information exploration from user-product relations, we construct two hypergraphs, i.e. a user-to-user (u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared preferences among users and intricate multimodal semantic resemblance among items, respectively. This process yields denser second-order semantics that are fused with first-order user-item interaction as complementary to alleviate the data sparsity issue. Then, we design a contrastive feature enhancement paradigm by applying synergistic contrastive learning. By maximizing/minimizing the mutual information between second-order (e.g. shared preference pattern for users) and first-order (information of selected items for users) embeddings of the same/different users and items, the feature distinguishability can be effectively enhanced. Compared with using sparse primary user-item interaction only, our MMHCL obtains denser second-order hypergraphs and excavates more abundant shared attributes to explore the user-product associations, which to a certain extent alleviates the problems of data sparsity and cold-start. Extensive experiments have comprehensively demonstrated the effectiveness of our method. Our code is publicly available at: https://github.com/Xu107/MMHCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burgeoning presence of multimodal content-sharing platforms propels thedevelopment of personalized recommender systems. Previous works usually sufferfrom data sparsity and cold-start problems, and may fail to adequately exploresemantic user-product associations from multimodal data. To address theseissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)framework for user recommendation. For a comprehensive information explorationfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine sharedpreferences among users and intricate multimodal semantic resemblance amongitems, respectively. This process yields denser second-order semantics that arefused with first-order user-item interaction as complementary to alleviate thedata sparsity issue. Then, we design a contrastive feature enhancement paradigmby applying synergistic contrastive learning. By maximizing/minimizing themutual information between second-order (e.g. shared preference pattern forusers) and first-order (information of selected items for users) embeddings ofthe same/different users and items, the feature distinguishability can beeffectively enhanced. Compared with using sparse primary user-item interactiononly, our MMHCL obtains denser second-order hypergraphs and excavates moreabundant shared attributes to explore the user-product associations, which to acertain extent alleviates the problems of data sparsity and cold-start.Extensive experiments have comprehensively demonstrated the effectiveness ofour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.</description>
      <author>example@mail.com (Xu Guo, Tong Zhang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui)</author>
      <guid isPermaLink="false">2504.16576v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>SignX: The Foundation Model for Sign Recognition</title>
      <link>http://arxiv.org/abs/2504.16315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SignX的用于手语识别的基础模型框架，旨在解决手语数据处理中的复杂性。&lt;h4&gt;背景&lt;/h4&gt;手语数据处理具有复杂性，目前的手语识别方法试图通过姿态信息将RGB手语视频翻译成基于英语的ID词，以唯一标识手语手势。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够识别手语视频并产生准确预测词表示的手语识别模型。&lt;h4&gt;方法&lt;/h4&gt;SignX框架包括一个基于逆扩散模型的Pose2Gloss组件，它包含一个多轨迹姿态融合层，统一了五种最强大的姿态信息来源。同时，还训练了一个基于ViT的Video2Pose模块，可以直接将原始视频转换为手势姿态表示。&lt;h4&gt;主要发现&lt;/h4&gt;SignX能够识别手语视频，并产生比先前工作更准确的预测词表示。&lt;h4&gt;结论&lt;/h4&gt;SignX为手语识别提供了兼容现有姿态格式的模型，为手语识别所需的通用姿态估计奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;The complexity of sign language data processing brings many challenges. The current approach to recognition of ASL signs aims to translate RGB sign language videos through pose information into English-based ID glosses, which serve to uniquely identify ASL signs. Note that there is no shared convention for assigning such glosses to ASL signs, so it is essential that the same glossing conventions are used for all of the data in the datasets that are employed. This paper proposes SignX, a foundation model framework for sign recognition. It is a concise yet powerful framework applicable to multiple human activity recognition scenarios. First, we developed a Pose2Gloss component based on an inverse diffusion model, which contains a multi-track pose fusion layer that unifies five of the most powerful pose information sources--SMPLer-X, DWPose, Mediapipe, PrimeDepth, and SapiensSegmentation--into a single latent pose representation. Second, we trained a Video2Pose module based on ViT that can directly convert raw video into signer pose representation. Through this 2-stage training framework, we enable sign language recognition models to be compatible with existing pose formats, laying the foundation for the common pose estimation necessary for sign recognition. Experimental results show that SignX can recognize signs from sign language video, producing predicted gloss representations with greater accuracy than has been reported in prior work.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity of sign language data processing brings many challenges. Thecurrent approach to recognition of ASL signs aims to translate RGB signlanguage videos through pose information into English-based ID glosses, whichserve to uniquely identify ASL signs. Note that there is no shared conventionfor assigning such glosses to ASL signs, so it is essential that the sameglossing conventions are used for all of the data in the datasets that areemployed. This paper proposes SignX, a foundation model framework for signrecognition. It is a concise yet powerful framework applicable to multiplehuman activity recognition scenarios. First, we developed a Pose2Glosscomponent based on an inverse diffusion model, which contains a multi-trackpose fusion layer that unifies five of the most powerful pose informationsources--SMPLer-X, DWPose, Mediapipe, PrimeDepth, and SapiensSegmentation--into a single latent pose representation. Second, we trained aVideo2Pose module based on ViT that can directly convert raw video into signerpose representation. Through this 2-stage training framework, we enable signlanguage recognition models to be compatible with existing pose formats, layingthe foundation for the common pose estimation necessary for sign recognition.Experimental results show that SignX can recognize signs from sign languagevideo, producing predicted gloss representations with greater accuracy than hasbeen reported in prior work.</description>
      <author>example@mail.com (Sen Fang, Chunyu Sui, Hongwei Yi, Carol Neidle, Dimitris N. Metaxas)</author>
      <guid isPermaLink="false">2504.16315v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Active Learning Methods for Efficient Data Utilization and Model Performance Enhancement</title>
      <link>http://arxiv.org/abs/2504.16136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细介绍了主动学习（AL）在数据驱动智能时代的重要性，探讨了其在计算机视觉、自然语言处理、迁移学习等领域的应用，并讨论了相关的研究主题和挑战。&lt;h4&gt;背景&lt;/h4&gt;数据丰富但标注稀缺成为机器学习发展的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提高模型性能，使用更少的标注样本。&lt;h4&gt;方法&lt;/h4&gt;介绍主动学习的基本概念，讨论其在不同领域的应用，并关注不确定性估计、处理类别不平衡、领域自适应、公平性、创建强评估指标和基准等问题。&lt;h4&gt;主要发现&lt;/h4&gt;主动学习方法可以改善数据效率，帮助模型更有效地学习；主动学习通常比被动学习效果更好，特别是当使用良好的评估指标时。&lt;h4&gt;结论&lt;/h4&gt;本文旨在为研究人员和实践者提供关键见解，并就主动学习的未来进展提出方向。&lt;h4&gt;翻译&lt;/h4&gt;在数据驱动智能时代，数据丰富与标注稀缺的悖论已成为机器学习发展的关键瓶颈。本文详细介绍了主动学习（AL），这是机器学习中一种利用更少的标注样本帮助模型实现更好性能的策略。本文介绍了AL的基本概念，并讨论了其在计算机视觉、自然语言处理、迁移学习以及现实世界应用中的使用。本文重点关注不确定性估计、处理类别不平衡、领域自适应、公平性以及创建强大评估指标和基准等重要研究主题。此外，本文还展示了受人类启发并由问题引导的学习方法如何提高数据效率并帮助模型更有效地学习。此外，本文还讨论了该领域的当前挑战，包括重建信任、确保可重复性和处理不一致的方法。本文指出，在良好的评估指标下，主动学习往往比被动学习效果更好。本工作的目标是通过对主动学习的关键见解和未来进展方向的提出，为研究人员和实践者提供帮助。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of data-driven intelligence, the paradox of data abundance andannotation scarcity has emerged as a critical bottleneck in the advancement ofmachine learning. This paper gives a detailed overview of Active Learning (AL),which is a strategy in machine learning that helps models achieve betterperformance using fewer labeled examples. It introduces the basic concepts ofAL and discusses how it is used in various fields such as computer vision,natural language processing, transfer learning, and real-world applications.The paper focuses on important research topics such as uncertainty estimation,handling of class imbalance, domain adaptation, fairness, and the creation ofstrong evaluation metrics and benchmarks. It also shows that learning methodsinspired by humans and guided by questions can improve data efficiency and helpmodels learn more effectively. In addition, this paper talks about currentchallenges in the field, including the need to rebuild trust, ensurereproducibility, and deal with inconsistent methodologies. It points out thatAL often gives better results than passive learning, especially when goodevaluation measures are used. This work aims to be useful for both researchersand practitioners by providing key insights and proposing directions for futureprogress in active learning.</description>
      <author>example@mail.com (Chiung-Yi Tseng, Junhao Song, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Ming Liu)</author>
      <guid isPermaLink="false">2504.16136v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Capturing Symmetry and Antisymmetry in Language Models through Symmetry-Aware Training Objectives</title>
      <link>http://arxiv.org/abs/2504.16312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了基于Wikidata的自然语言推理数据集，用于评估大型语言模型在捕捉对称和反对称关系方面的性能，并探讨了通过对比学习和k近邻方法改进编码器以增强关系理解。&lt;h4&gt;背景&lt;/h4&gt;捕捉对称和反对称关系对于多种应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;评估大型语言模型在关系理解上的表现，并探索改进方法。&lt;h4&gt;方法&lt;/h4&gt;使用基于Wikidata的数据集评估LLMs，并通过对比学习结合k近邻方法重新训练编码器。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在关系理解上的表现与随机机会相当，存在关系理解上的差距。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习和k近邻方法重新训练的编码器在性能上与微调的分类头相当，同时在少样本学习和减轻灾难性遗忘方面具有额外优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：捕捉对称（例如，国家边界另一国家）和反对称（例如，父母与子女关系）关系对于多种应用至关重要。本文通过引入一个基于Wikidata的自然语言推理数据集来评估大型语言模型（LLMs）来解决这一挑战。我们的发现显示LLMs在基准测试上的表现与随机机会相当，突显了关系理解的差距。为了解决这个问题，我们探索了通过带有k近邻的对比学习方法重新训练编码器。重新训练的编码器在性能上与微调的分类头相当，同时提供了额外的优势，包括在少样本学习中的更高效率和改善灾难性遗忘的缓解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Capturing symmetric (e.g., country borders another country) and antisymmetric(e.g., parent_of) relations is crucial for a variety of applications. Thispaper tackles this challenge by introducing a novel Wikidata-derived naturallanguage inference dataset designed to evaluate large language models (LLMs).Our findings reveal that LLMs perform comparably to random chance on thisbenchmark, highlighting a gap in relational understanding. To address this, weexplore encoder retraining via contrastive learning with k-nearest neighbors.The retrained encoder matches the performance of fine-tuned classificationheads while offering additional benefits, including greater efficiency infew-shot learning and improved mitigation of catastrophic forgetting.</description>
      <author>example@mail.com (Zhangdie Yuan, Andreas Vlachos)</author>
      <guid isPermaLink="false">2504.16312v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Trends in Frontier AI Model Count: A Forecast to 2028</title>
      <link>http://arxiv.org/abs/2504.16138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于训练计算量对AI模型的要求，分析了不同计算阈值下模型数量的变化趋势。&lt;h4&gt;背景&lt;/h4&gt;欧洲AI法案和美国AI扩散框架都对训练计算量超过特定阈值的AI模型提出了要求。&lt;h4&gt;目的&lt;/h4&gt;研究这些计算阈值在未来能捕捉多少模型，以及每年超过这些阈值的模型数量增长趋势。&lt;h4&gt;方法&lt;/h4&gt;通过估计，预测了到2028年底，将有超过欧盟AI法案和AI扩散框架定义的阈值模型数量。&lt;h4&gt;主要发现&lt;/h4&gt;预计到2028年底，将有103-306个基础模型超过欧盟AI法案的$10^{25}$ FLOP阈值，45-148个模型超过美国AI扩散框架的$10^{26}$ FLOP阈值。每年超过这些阈值的模型数量将呈超线性增长。以目前最大的训练运行规模为基准定义的阈值，从2025年到2028年的平均预测值为每年捕获14-16个模型。&lt;h4&gt;结论&lt;/h4&gt;计算阈值对AI模型的监管将随着时间的推移而扩大，且每年捕获的模型数量将呈现指数增长趋势。&lt;h4&gt;翻译&lt;/h4&gt;Governments are beginning to impose requirements on AI models based on how much compute was used to train them. For example, the EU AI Act imposes requirements on providers of general-purpose AI with systemic risk, which includes systems trained using greater than $10^{25}$ floating point operations (FLOP). In the United States' AI Diffusion Framework, a training compute threshold of $10^{26}$ FLOP is used to identify 'controlled models' which face a number of requirements. We explore how many models such training compute thresholds will capture over time. We estimate that by the end of 2028, there will be between 103-306 foundation models exceeding the $10^{25}$ FLOP threshold put forward in the EU AI Act (90% CI), and 45-148 models exceeding the $10^{26}$ FLOP threshold that defines controlled models in the AI Diffusion Framework (90% CI). We also find that the number of models exceeding these absolute compute thresholds each year will increase superlinearly—that is, each successive year will see more new models captured within the threshold than the year before. Thresholds that are defined with respect to the largest training run to date (for example, such that all models within one order of magnitude of the largest training run to date are captured by the threshold) see a more stable trend, with a median forecast of 14-16 models being captured by this definition annually from 2025-2028.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Governments are starting to impose requirements on AI models based on howmuch compute was used to train them. For example, the EU AI Act imposesrequirements on providers of general-purpose AI with systemic risk, whichincludes systems trained using greater than $10^{25}$ floating point operations(FLOP). In the United States' AI Diffusion Framework, a training computethreshold of $10^{26}$ FLOP is used to identify "controlled models" which facea number of requirements. We explore how many models such training computethresholds will capture over time. We estimate that by the end of 2028, therewill be between 103-306 foundation models exceeding the $10^{25}$ FLOPthreshold put forward in the EU AI Act (90% CI), and 45-148 models exceedingthe $10^{26}$ FLOP threshold that defines controlled models in the AI DiffusionFramework (90% CI). We also find that the number of models exceeding theseabsolute compute thresholds each year will increase superlinearly -- that is,each successive year will see more new models captured within the thresholdthan the year before. Thresholds that are defined with respect to the largesttraining run to date (for example, such that all models within one order ofmagnitude of the largest training run to date are captured by the threshold)see a more stable trend, with a median forecast of 14-16 models being capturedby this definition annually from 2025-2028.</description>
      <author>example@mail.com (Iyngkarran Kumar, Sam Manning)</author>
      <guid isPermaLink="false">2504.16138v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning for Tabular Data: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2504.16109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对表格数据表示学习领域进行了系统介绍，涵盖了背景、挑战、基准以及使用深度神经网络（DNNs）的优缺点，并按照泛化能力将现有方法分为三类：专用模型、可迁移模型和通用模型。&lt;h4&gt;背景&lt;/h4&gt;表格数据是机器学习分类和回归应用中最常见的数据类型之一。深度神经网络（DNNs）在表示学习能力方面的近期成果表明，其在该领域具有应用潜力。&lt;h4&gt;目的&lt;/h4&gt;对表格表示学习领域的背景、挑战、基准以及使用DNNs的优缺点进行系统介绍。&lt;h4&gt;方法&lt;/h4&gt;将现有方法根据泛化能力分为专用、可迁移和通用模型三类，并详细介绍了专用模型的层次分类法及其特征、样本和目标关键方面的策略，以及可迁移模型和通用模型在不同数据集上的应用策略。&lt;h4&gt;主要发现&lt;/h4&gt;专用模型关注训练和评估在相同数据分布中的任务；可迁移模型在多个数据集上预训练后，在下游任务中进行微调；通用模型允许直接应用于下游任务而不需要微调。&lt;h4&gt;结论&lt;/h4&gt;本文对表格学习领域的各种方法进行了全面的概述，并讨论了表格学习的代表性扩展，如开放环境表格机器学习、多模态学习与表格数据结合以及表格理解。&lt;h4&gt;翻译&lt;/h4&gt;This abstract provides a summary of a survey paper on tabular representation learning in machine learning. The paper introduces the field, discusses challenges and benchmarks, evaluates the pros and cons of using deep neural networks, and categorizes existing methods into specialized, transferable, and general models based on their generalization capabilities. It also explores ensemble methods and discusses extensions of tabular learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular data, structured as rows and columns, is among the most prevalentdata types in machine learning classification and regression applications.Models for learning from tabular data have continuously evolved, with DeepNeural Networks (DNNs) recently demonstrating promising results through theircapability of representation learning. In this survey, we systematicallyintroduce the field of tabular representation learning, covering thebackground, challenges, and benchmarks, along with the pros and cons of usingDNNs. We organize existing methods into three main categories according totheir generalization capabilities: specialized, transferable, and generalmodels. Specialized models focus on tasks where training and evaluation occurwithin the same data distribution. We introduce a hierarchical taxonomy forspecialized models based on the key aspects of tabular data -- features,samples, and objectives -- and delve into detailed strategies for obtaininghigh-quality feature- and sample-level representations. Transferable models arepre-trained on one or more datasets and subsequently fine-tuned on downstreamtasks, leveraging knowledge acquired from homogeneous or heterogeneous sources,or even cross-modalities such as vision and language. General models, alsoknown as tabular foundation models, extend this concept further, allowingdirect application to downstream tasks without fine-tuning. We group thesegeneral models based on the strategies used to adapt across heterogeneousdatasets. Additionally, we explore ensemble methods, which integrate thestrengths of multiple tabular models. Finally, we discuss representativeextensions of tabular learning, including open-environment tabular machinelearning, multimodal learning with tabular data, and tabular understanding.More information can be found in the following repository:https://github.com/LAMDA-Tabular/Tabular-Survey.</description>
      <author>example@mail.com (Jun-Peng Jiang, Si-Yang Liu, Hao-Run Cai, Qile Zhou, Han-Jia Ye)</author>
      <guid isPermaLink="false">2504.16109v1</guid>
      <pubDate>Thu, 24 Apr 2025 14:14:46 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis</title>
      <link>http://arxiv.org/abs/2504.16047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究评估了三种不同的视觉-语言基础模型（RAD-DINO、CheXagent和BiomedCLIP）在捕捉细粒度成像特征方面的能力，并在胸部X光片上的气胸和心增大分类、分割和回归任务中进行了评估。&lt;h4&gt;背景&lt;/h4&gt;基于大量数据使用自监督技术训练的基础模型在医学领域的AI应用中成为了一个有前景的前沿。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估RAD-DINO、CheXagent和BiomedCLIP三种基础模型在放射学任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;模型在气胸和心增大分类、分割和回归任务中进行了评估，并创建了一个结合全局和局部特征的定制分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;RAD-DINO在分割任务中表现优异，CheXagent在分类任务中表现优越，BiomedCLIP在任务间表现不一致。定制分割模型显著提高了所有基础模型的表现，特别是在挑战性的气胸分割任务中。自监督的RAD-DINO在分割任务中表现更好，而文本监督的模型在分类和可解释性方面有优势。&lt;h4&gt;结论&lt;/h4&gt;预训练方法对特定下游任务中的模型性能有显著影响。对于细粒度分割任务，无文本监督训练的模型表现更好，而文本监督模型在分类和可解释性方面有优势。这些见解为根据特定的临床应用选择基础模型提供了指导。&lt;h4&gt;翻译&lt;/h4&gt;This study evaluates three different vision-language foundation models (RAD-DINO, CheXagent, and BiomedCLIP) on their ability to capture fine-grained imaging features for radiology tasks. The models were assessed across classification, segmentation, and regression tasks for pneumothorax and cardiomegaly on chest radiographs. Self-supervised RAD-DINO consistently excelled in segmentation tasks, while text-supervised CheXagent demonstrated superior classification performance. BiomedCLIP showed inconsistent performance across tasks. A custom segmentation model that integrates global and local features substantially improved performance for all foundation models, particularly for challenging pneumothorax segmentation. The findings highlight that pre-training methodology significantly influences model performance on specific downstream tasks. For fine-grained segmentation tasks, models trained without text supervision performed better, while text-supervised models offered advantages in classification and interpretability. These insights provide guidance for selecting foundation models based on specific clinical applications in radiology.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models, trained on vast amounts of data using self-supervisedtechniques, have emerged as a promising frontier for advancing artificialintelligence (AI) applications in medicine. This study evaluates threedifferent vision-language foundation models (RAD-DINO, CheXagent, andBiomedCLIP) on their ability to capture fine-grained imaging features forradiology tasks. The models were assessed across classification, segmentation,and regression tasks for pneumothorax and cardiomegaly on chest radiographs.Self-supervised RAD-DINO consistently excelled in segmentation tasks, whiletext-supervised CheXagent demonstrated superior classification performance.BiomedCLIP showed inconsistent performance across tasks. A custom segmentationmodel that integrates global and local features substantially improvedperformance for all foundation models, particularly for challengingpneumothorax segmentation. The findings highlight that pre-training methodologysignificantly influences model performance on specific downstream tasks. Forfine-grained segmentation tasks, models trained without text supervisionperformed better, while text-supervised models offered advantages inclassification and interpretability. These insights provide guidance forselecting foundation models based on specific clinical applications inradiology.</description>
      <author>example@mail.com (Frank Li, Hari Trivedi, Bardia Khosravi, Theo Dapamede, Mohammadreza Chavoshi, Abdulhameed Dere, Rohan Satya Isaac, Aawez Mansuri, Janice Newsome, Saptarshi Purkayastha, Judy Gichoya)</author>
      <guid isPermaLink="false">2504.16047v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
  <item>
      <title>Vision language models are unreliable at trivial spatial cognition</title>
      <link>http://arxiv.org/abs/2504.16061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉语言模型（VLMs）在提取图像中的视觉空间信息方面的能力，并探讨了其在场景理解和处理关系信息方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;VLMs旨在从图像中提取相关视觉空间信息，部分研究表明VLMs能够表现出类似人类的场景理解能力，但其他研究指出它们在处理关系信息方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了测试VLMs在处理简单空间认知任务上的可靠性，例如在无杂乱场景中识别一个物体是否位于另一个物体的左侧。&lt;h4&gt;方法&lt;/h4&gt;研究人员开发了一个名为TableTest的基准数据集，其中的图像描绘了物体排列在桌子上的3D场景，并使用该数据集评估了最先进的VLMs。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，使用逻辑等价描述的提示的微小变化可能会降低性能，这表明VLMs在现实应用中推理空间关系的能力存在局限性。&lt;h4&gt;结论&lt;/h4&gt;这些分析揭示了通过增强图像标题语料库来提高训练和测试效率的新机会。&lt;h4&gt;翻译&lt;/h4&gt;Vision language models (VLMs) are designed to extract relevant visuospatial information from images. Some research suggests that VLMs can exhibit human-like scene understanding, while other investigations reveal difficulties in their ability to process relational information. To achieve widespread applicability, VLMs must perform reliably, yielding comparable competence across a wide variety of related tasks. We sought to test how reliable these architectures are at engaging in trivial spatial cognition, e.g., recognizing whether one object is left of another in an uncluttered scene. We developed a benchmark dataset -- TableTest -- whose images depict 3D scenes of objects arranged on a table, and used it to evaluate state-of-the-art VLMs. Results show that performance could be degraded by minor variations of prompts that use logically equivalent descriptions. These analyses suggest limitations in how VLMs may reason about spatial relations in real-world applications. They also reveal novel opportunities for bolstering image caption corpora for more efficient training and testing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision language models (VLMs) are designed to extract relevant visuospatialinformation from images. Some research suggests that VLMs can exhibit humanlikescene understanding, while other investigations reveal difficulties in theirability to process relational information. To achieve widespread applicability,VLMs must perform reliably, yielding comparable competence across a widevariety of related tasks. We sought to test how reliable these architecturesare at engaging in trivial spatial cognition, e.g., recognizing whether oneobject is left of another in an uncluttered scene. We developed a benchmarkdataset -- TableTest -- whose images depict 3D scenes of objects arranged on atable, and used it to evaluate state-of-the-art VLMs. Results show thatperformance could be degraded by minor variations of prompts that use logicallyequivalent descriptions. These analyses suggest limitations in how VLMs mayreason about spatial relations in real-world applications. They also revealnovel opportunities for bolstering image caption corpora for more efficienttraining and testing.</description>
      <author>example@mail.com (Sangeet Khemlani, Tyler Tran, Nathaniel Gyory, Anthony M. Harrison, Wallace E. Lawson, Ravenna Thielstrom, Hunter Thompson, Taaren Singh, J. Gregory Trafton)</author>
      <guid isPermaLink="false">2504.16061v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining</title>
      <link>http://arxiv.org/abs/2504.15669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FS-DINO的少样本语义分割方法，通过结合DINOv2和SAM的知识，实现轻量级的分割器，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;少样本语义分割因其泛化能力而受到关注，即通过少量标注图像对新型类别的像素进行分割。现有研究主要集中于元学习和支持-查询匹配，包括基于原型和聚合的方法。为了解决数据稀缺问题，最近的方法转向使用基础模型来增强新型类别分割的可迁移性。&lt;h4&gt;目的&lt;/h4&gt;探索是否可以构建一个统一模型，结合基础模型的知识。&lt;h4&gt;方法&lt;/h4&gt;FS-DINO使用DINOv2的编码器和轻量级分割器。分割器包括瓶颈适配器、基于密集相似性和语义嵌入的元视觉提示生成器以及解码器。通过粗到细的跨模型蒸馏，将SAM的知识有效集成到轻量级分割器中，并通过支持-查询对的4D相关性挖掘进一步增强。&lt;h4&gt;主要发现&lt;/h4&gt;FS-DINO在COCO-20i、PASCAL-5i和FSS-1000数据集上的实验表明，该方法具有有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;FS-DINO是一种有效的少样本语义分割方法，通过结合DINOv2和SAM的知识，实现了轻量级分割器的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot semantic segmentation has gained increasing interest due to itsgeneralization capability, i.e., segmenting pixels of novel classes requiringonly a few annotated images. Prior work has focused on meta-learning forsupport-query matching, with extensive development in both prototype-based andaggregation-based methods. To address data scarcity, recent approaches haveturned to foundation models to enhance representation transferability for novelclass segmentation. Among them, a hybrid dual-modal framework including bothDINOv2 and SAM has garnered attention due to their complementary capabilities.We wonder "can we build a unified model with knowledge from both foundationmodels?" To this end, we propose FS-DINO, with only DINOv2's encoder and alightweight segmenter. The segmenter features a bottleneck adapter, ameta-visual prompt generator based on dense similarities and semanticembeddings, and a decoder. Through coarse-to-fine cross-model distillation, weeffectively integrate SAM's knowledge into our lightweight segmenter, which canbe further enhanced by 4D correlation mining on support-query pairs. Extensiveexperiments on COCO-20i, PASCAL-5i, and FSS-1000 demonstrate the effectivenessand superiority of our method.</description>
      <author>example@mail.com (Wei Zhuo, Zhiyue Tang, Wufeng Xue, Hao Ding, Linlin Shen)</author>
      <guid isPermaLink="false">2504.15669v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.15616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages,6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SocialMOIF的方法，用于分析和预测智能系统中代理的轨迹，以提高决策过程的准确性。&lt;h4&gt;背景&lt;/h4&gt;当前研究在量化建模代理及其社会互动方面存在局限性，主要因为代理意图的不确定性和相邻群体之间复杂的高阶影响。&lt;h4&gt;目的&lt;/h4&gt;SocialMOIF旨在解决上述挑战，通过融合多阶意图信息，实现对直接和间接意图信息的更全面理解。&lt;h4&gt;方法&lt;/h4&gt;SocialMOIF方法包括：1) 设计一个轨迹分布近似器，引导轨迹值更接近实际数据；2) 引入全局轨迹优化器，实现更准确和高效的并行预测；3) 使用考虑距离和方向的损失函数进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SocialMOIF模型在动态和静态数据集上，多个指标上均优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;SocialMOIF模型能够有效提高代理轨迹预测的准确性，对智能系统的决策过程具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要：智能系统中代理轨迹的分析和预测对决策过程至关重要，精确的短期轨迹预测在众多应用中具有重要意义。研究者们从不同角度量化并建模了代理及其社会互动；然而，由于代理意图的不确定性和相邻群体之间复杂的高阶影响，当前工作存在重大局限性。SocialMOIF被提出以应对这些挑战，它专注于相邻群体之间的高阶意图交互，同时强化邻居和目标代理之间的一阶意图交互的首要作用。该方法通过开发一个多阶意图融合模型来实现对直接和间接意图信息的更全面理解。在SocialMOIF中，设计了一个轨迹分布近似器，以引导轨迹向更接近实际数据的值发展，从而提高模型的可解释性。此外，引入了一个全局轨迹优化器，以实现更准确和高效的并行预测。通过在训练过程中考虑距离和方向的损失函数，实验结果证明了该模型在动态和静态数据集上，多个指标上均优于现有的最先进基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The analysis and prediction of agent trajectories are crucial fordecision-making processes in intelligent systems, with precise short-termtrajectory forecasting being highly significant across a range of applications.Agents and their social interactions have been quantified and modeled byresearchers from various perspectives; however, substantial limitations existin the current work due to the inherent high uncertainty of agent intentionsand the complex higher-order influences among neighboring groups. SocialMOIF isproposed to tackle these challenges, concentrating on the higher-orderintention interactions among neighboring groups while reinforcing the primaryrole of first-order intention interactions between neighbors and the targetagent. This method develops a multi-order intention fusion model to achieve amore comprehensive understanding of both direct and indirect intentioninformation. Within SocialMOIF, a trajectory distribution approximator isdesigned to guide the trajectories toward values that align more closely withthe actual data, thereby enhancing model interpretability. Furthermore, aglobal trajectory optimizer is introduced to enable more accurate and efficientparallel predictions. By incorporating a novel loss function that accounts fordistance and direction during training, experimental results demonstrate thatthe model outperforms previous state-of-the-art baselines across multiplemetrics in both dynamic and static datasets.</description>
      <author>example@mail.com (Kai Chen, Xiaodong Zhao, Yujie Huang, Guoyu Fang, Xiao Song, Ruiping Wang, Ziyuan Wang)</author>
      <guid isPermaLink="false">2504.15616v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Intent-aware Diffusion with Contrastive Learning for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2504.16077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at SIGIR 2025. 10 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为InDiRec的序列推荐模型，通过结合对比学习和意图感知扩散来提高推荐效果。&lt;h4&gt;背景&lt;/h4&gt;现有的序列推荐模型通过随机数据增强来生成多个视图，但这种方法可能引入噪声，破坏原始交互序列中的潜在意图信息。&lt;h4&gt;目的&lt;/h4&gt;提出InDiRec旨在解决现有方法中噪声引入和意图信息丢失的问题，以学习更鲁棒的用户行为模式。&lt;h4&gt;方法&lt;/h4&gt;InDiRec首先使用K-means对序列表示进行意图聚类，构建意图引导信号。然后，检索目标交互序列的意图表示，引导条件扩散模型生成具有相同意图的正面视图。最后，应用对比学习以最大化意图对齐视图和原始序列之间的表示一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公开数据集上的实验表明，InDiRec相较于现有基线方法，在噪声和稀疏数据条件下也能实现更优的性能。&lt;h4&gt;结论&lt;/h4&gt;InDiRec通过结合对比学习和意图感知扩散，能够生成更可靠的增强视图，从而提高序列推荐模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730010&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven effective in training sequentialrecommendation models by incorporating self-supervised signals from augmentedviews. Most existing methods generate multiple views from the same interactionsequence through stochastic data augmentation, aiming to align theirrepresentations in the embedding space. However, users typically have specificintents when purchasing items (e.g., buying clothes as gifts or cosmetics forbeauty). Random data augmentation used in existing methods may introduce noise,disrupting the latent intent information implicit in the original interactionsequence. Moreover, using noisy augmented sequences in contrastive learning maymislead the model to focus on irrelevant features, distorting the embeddingspace and failing to capture users' true behavior patterns and intents. Toaddress these issues, we propose Intent-aware Diffusion with contrastivelearning for sequential Recommendation (InDiRec). The core idea is to generateitem sequences aligned with users' purchasing intents, thus providing morereliable augmented views for contrastive learning. Specifically, InDiRec firstperforms intent clustering on sequence representations using K-means to buildintent-guided signals. Next, it retrieves the intent representation of thetarget interaction sequence to guide a conditional diffusion model, generatingpositive views that share the same underlying intent. Finally, contrastivelearning is applied to maximize representation consistency between theseintent-aligned views and the original sequence. Extensive experiments on fivepublic datasets demonstrate that InDiRec achieves superior performance comparedto existing baselines, learning more robust representations even under noisyand sparse data conditions.</description>
      <author>example@mail.com (Yuanpeng Qu, Hajime Nobuhara)</author>
      <guid isPermaLink="false">2504.16077v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable graph neural network simulator for forward and inverse modeling of multi-layered slope system with multiple material properties</title>
      <link>http://arxiv.org/abs/2504.15938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多层坡系统的可微分图神经网络模拟器（GNS）框架，用于模拟颗粒流。&lt;h4&gt;背景&lt;/h4&gt;现有的颗粒流模拟主要针对简化的几何形状和材料特性，通常只考虑摩擦角，这不能反映实际地质工程中斜坡等系统的复杂性。&lt;h4&gt;目的&lt;/h4&gt;设计一个可以同时进行正向和逆向建模的GNS框架，用于模拟多层斜坡系统。&lt;h4&gt;方法&lt;/h4&gt;正向建模组件使用微调的GNS，该GNS结合了摩擦角和凝聚力。逆向建模组件利用训练好的GNS、反向模式自动微分和L-BFGS-B优化，从目标溃决几何形状推断材料特性。&lt;h4&gt;主要发现&lt;/h4&gt;GNS在模拟多材料流动力学时，实现了高达145倍的比材料点方法（MPM）的计算速度提升。通过柱状倒塌和多层斜坡溃决模拟，验证了其性能。逆向建模可以快速（几分钟内）得到与目标强度值良好的吻合。&lt;h4&gt;结论&lt;/h4&gt;该框架为现实斜坡系统中正向溃决评估和逆向强度反演提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural network simulators (GNS) have emerged as a computationallyefficient tool for simulating granular flows. Previous efforts have beenlimited to simplified geometries and material characterizations, typicallyconsidering only friction angle, which does not reflect the complexity ofrealistic geotechnical systems such as slopes encountered in engineeringpractice. This study introduces a differentiable GNS framework designed formulti-layered slope systems comprising both forward and inverse modelingcomponents. The forward component relies on a fine-tuned GNS that incorporatesboth friction angle and cohesion. Its performance is demonstrated throughcolumn collapse and multi-layered slope runout simulations, where GNSreplicates multi-material flow dynamics while achieving up to 145xcomputational speedup over the Material Point Method (MPM). The inversemodeling component leverages the trained GNS, reverse-mode automaticdifferentiation, and L-BFGS-B optimization to infer material properties from atarget runout geometry. Its performance is demonstrated by back-calculating thematerial strengths that led to failure-induced runout in a dam system composedof multiple materials. Results are obtained within minutes and show goodagreement with the target strength values. The framework introduced in thisstudy provides an efficient approach for forward runout assessments and inversestrength back-calculation in realistic slope systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural network simulators (GNS) have emerged as a computationallyefficient tool for simulating granular flows. Previous efforts have beenlimited to simplified geometries and material characterizations, typicallyconsidering only friction angle, which does not reflect the complexity ofrealistic geotechnical systems such as slopes encountered in engineeringpractice. This study introduces a differentiable GNS framework designed formulti-layered slope systems comprising both forward and inverse modelingcomponents. The forward component relies on a fine-tuned GNS that incorporatesboth friction angle and cohesion. Its performance is demonstrated throughcolumn collapse and multi-layered slope runout simulations, where GNSreplicates multi-material flow dynamics while achieving up to 145xcomputational speedup over the Material Point Method (MPM). The inversemodeling component leverages the trained GNS, reverse-mode automaticdifferentiation, and L-BFGS-B optimization to infer material properties from atarget runout geometry. Its performance is demonstrated by back-calculating thematerial strengths that led to failure-induced runout in a dam system composedof multiple materials. Results are obtained within minutes and show goodagreement with the target strength values. The framework introduced in thisstudy provides an efficient approach for forward runout assessments and inversestrength back-calculation in realistic slope systems.</description>
      <author>example@mail.com (Yongjin Choi, Jorge Macedo, Chenying Liu)</author>
      <guid isPermaLink="false">2504.15938v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>MR. Video: "MapReduce" is the Principle for Long Video Understanding</title>
      <link>http://arxiv.org/abs/2504.16082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MR. Video的智能长视频理解框架，该框架采用MapReduce原理处理长视频，通过独立密集感知短视频片段和联合聚合所有片段信息来提高视频理解能力。&lt;h4&gt;背景&lt;/h4&gt;当前视频理解技术通常受限于视频的上下文长度，而MR. Video通过MapReduce原理来克服这一限制。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效处理长视频并提高视频理解准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;MR. Video采用MapReduce两阶段处理：第一阶段（Captioning）生成短视频片段的标题，并将重复的字符和对象标准化为共享名称；第二阶段（Analysis）针对用户问题，从单个短视频中分析相关信息，并将其整合为最终答案。&lt;h4&gt;主要发现&lt;/h4&gt;MR. Video在LVBench挑战性测试中，与最先进的VLMs和视频智能体相比，实现了超过10%的准确率提升。&lt;h4&gt;结论&lt;/h4&gt;MR. Video框架通过MapReduce原理有效地提高了长视频理解能力，适用于VLMs和视频智能体。&lt;h4&gt;翻译&lt;/h4&gt;We propose MR. Video, an agentic long video understanding framework thatdemonstrates the simple yet effective MapReduce principle for processing longvideos: (1) Map: independently and densely perceiving short video clips, and(2) Reduce: jointly aggregating information from all clips. Compared withsequence-to-sequence vision-language models (VLMs), MR. Video performs detailedshort video perception without being limited by context length. Compared withexisting video agents that typically rely on sequential key segment selection,the Map operation enables simpler and more scalable sequence parallelperception of short video segments. Its Reduce step allows for morecomprehensive context aggregation and reasoning, surpassing explicit keysegment retrieval. This MapReduce principle is applicable to both VLMs andvideo agents, and we use LLM agents to validate its effectiveness. In practice, MR. Video employs two MapReduce stages: (A) Captioning: generating captions for short video clips (map), then standardizing repeated characters and objects into shared names (reduce); (B) Analysis: for each user question, analyzing relevant information from individual short videos (map), and integrating them into a final answer (reduce). MR. Video achieves over 10%accuracy improvement on the challenging LVBench compared to state-of-the-artVLMs and video agents. Code is available at: https://github.com/ziqipang/MR-Video&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose MR. Video, an agentic long video understanding framework thatdemonstrates the simple yet effective MapReduce principle for processing longvideos: (1) Map: independently and densely perceiving short video clips, and(2) Reduce: jointly aggregating information from all clips. Compared withsequence-to-sequence vision-language models (VLMs), MR. Video performs detailedshort video perception without being limited by context length. Compared withexisting video agents that typically rely on sequential key segment selection,the Map operation enables simpler and more scalable sequence parallelperception of short video segments. Its Reduce step allows for morecomprehensive context aggregation and reasoning, surpassing explicit keysegment retrieval. This MapReduce principle is applicable to both VLMs andvideo agents, and we use LLM agents to validate its effectiveness.  In practice, MR. Video employs two MapReduce stages: (A) Captioning:generating captions for short video clips (map), then standardizing repeatedcharacters and objects into shared names (reduce); (B) Analysis: for each userquestion, analyzing relevant information from individual short videos (map),and integrating them into a final answer (reduce). MR. Video achieves over 10%accuracy improvement on the challenging LVBench compared to state-of-the-artVLMs and video agents.  Code is available at: https://github.com/ziqipang/MR-Video</description>
      <author>example@mail.com (Ziqi Pang, Yu-Xiong Wang)</author>
      <guid isPermaLink="false">2504.16082v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting</title>
      <link>http://arxiv.org/abs/2504.15485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and data: https://github.com/atinpothiraj/CAPTURe&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的任务CAPTURe，用于测试模型对遮挡物体的推理能力，并评估了视觉语言模型在理解遮挡模式和空间理解方面的能力。&lt;h4&gt;背景&lt;/h4&gt;遮挡在现实世界中很常见，对空间理解构成障碍，因此识别和理解遮挡物体对于理解视觉场景至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计CAPTURe任务以测试模型在推理多个遮挡物体方面的能力，并评估视觉语言模型是否能够理解遮挡模式并具备空间理解技能。&lt;h4&gt;方法&lt;/h4&gt;CAPTURe包括两部分：CAPTURe-real使用真实物体的手动过滤图像，CAPTURe-synthetic使用生成的图案图像进行控制诊断。研究人员评估了四个强大的视觉语言模型在CAPTURe上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，模型在遮挡和非遮挡图案上的计数都存在困难，且在遮挡情况下的表现更差，表明视觉语言模型在推断未见的空间关系方面也存在不足。&lt;h4&gt;结论&lt;/h4&gt;尽管最强视觉语言模型GPT-4o在遮挡情况下也未能成功计数，但人类在CAPTURe任务上几乎不出错。此外，提供遮挡物体位置的辅助信息可以提高模型性能，这表明模型错误既来自于处理遮挡的能力不足，也来自于在图像中计数时的困难。&lt;h4&gt;翻译&lt;/h4&gt;Recognizing and reasoning about occluded objects is vital to understanding visual scenes, as occlusions frequently occur in real-world environments and act as obstacles for spatial comprehension. To test models' ability to reason about multiple occluded objects, we introduce a novel task, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which requires a model to count objects arranged in a pattern by inferring how the pattern continues behind an occluder (an object which blocks parts of the scene). CAPTURe requires both recognizing visual patterns and reasoning, making it a useful testbed for evaluating vision-language models (VLMs) on whether they understand occluded patterns and possess spatial understanding skills. By requiring models to reason about occluded objects, CAPTURe also tests VLMs' ability to form world models that would allow them to fill in missing information. CAPTURe consists of two parts: (1) CAPTURe-real, with manually filtered images of real objects in patterns and (2) CAPTURe-synthetic, a controlled diagnostic with generated patterned images. We evaluate four strong VLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models struggle to count on both occluded and unoccluded patterns. Crucially, we find that models perform worse with occlusion, suggesting that VLMs are also deficient in inferring unseen spatial relationships: even the strongest VLMs like GPT-4o fail to count with occlusion. In contrast, we find that humans achieve very little error on CAPTURe. We also find that providing auxiliary information of occluded object locations increases performance, underscoring that the model error comes both from an inability to handle occlusion as well as difficulty counting in images.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recognizing and reasoning about occluded (partially or fully hidden) objectsis vital to understanding visual scenes, as occlusions frequently occur inreal-world environments and act as obstacles for spatial comprehension. To testmodels' ability to reason about multiple occluded objects, we introduce a noveltask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), whichrequires a model to count objects arranged in a pattern by inferring how thepattern continues behind an occluder (an object which blocks parts of thescene). CAPTURe requires both recognizing visual patterns and reasoning, makingit a useful testbed for evaluating vision-language models (VLMs) on whetherthey understand occluded patterns and possess spatial understanding skills. Byrequiring models to reason about occluded objects, CAPTURe also tests VLMs'ability to form world models that would allow them to fill in missinginformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manuallyfiltered images of real objects in patterns and (2) CAPTURe-synthetic, acontrolled diagnostic with generated patterned images. We evaluate four strongVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that modelsstruggle to count on both occluded and unoccluded patterns. Crucially, we findthat models perform worse with occlusion, suggesting that VLMs are alsodeficient in inferring unseen spatial relationships: even the strongest VLMslike GPT-4o fail to count with occlusion. In contrast, we find that humansachieve very little error on CAPTURe. We also find that providing auxiliaryinformation of occluded object locations increases performance, underscoringthat the model error comes both from an inability to handle occlusion as wellas difficulty counting in images.</description>
      <author>example@mail.com (Atin Pothiraj, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal)</author>
      <guid isPermaLink="false">2504.15485v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了MedTrim，一种基于元实体驱动的三元组挖掘方法，用于提高医学图像和文本之间的对齐，特别是在胸部X光片（CXR）评估中。&lt;h4&gt;背景&lt;/h4&gt;诊断影像学依赖于对图像和放射学报告的解释，但随着数据量的增加，给医学专家带来了巨大的压力，导致错误增加和工作流程积压。&lt;h4&gt;目的&lt;/h4&gt;提出MedTrim方法，旨在通过多模态三元组学习，协同地利用疾病类别以及形容词和方向性病理描述符来增强图像-文本对齐。&lt;h4&gt;方法&lt;/h4&gt;MedTrim方法包括：1）引入基于本体论的实体识别模块，从CXR报告中提取病理特定的元实体；2）提出一个新的评分函数，基于疾病类别和形容词/方向性描述符来捕捉样本间相似性的综合度量；3）引入一个多模态三元组对齐目标，用于显式地实现具有详细病理特征的样本之间的跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MedTrim在下游检索和分类任务中的性能优于现有的对齐方法。&lt;h4&gt;结论&lt;/h4&gt;MedTrim通过利用结构化元实体信息和改进的三元组挖掘，提高了医学图像和文本对齐的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：诊断影像学依赖于对图像和放射学报告的解释，但随着数据量的增加，给医学专家带来了巨大的压力，导致错误增加和工作流程积压。医学视觉-语言模型（med-VLMs）已成为一种强大的框架，用于高效处理多模态影像数据，尤其是在胸部X光片（CXR）评估中，尽管其性能取决于图像和文本表示的对齐程度。现有的对齐方法，主要基于对比学习，优先考虑疾病类别之间的分离，而不是精细的病理属性（如位置、大小或严重程度）的分离，导致表示不佳。在这里，我们提出了MedTrim（元实体驱动的三元组挖掘），一种新颖的方法，通过疾病类别以及形容词和方向性病理描述符协同引导的多模态三元组学习来增强图像-文本对齐。与常见的对齐方法不同，MedTrim利用结构化元实体信息来保留临床上有意义的类内细微差异。为此，我们首先引入了一个基于本体论的实体识别模块，从CXR报告中提取病理特定的元实体，因为公共数据集中病理属性的注释很少。然后，为了在三元组挖掘中进行精细的样本选择，我们引入了一个新的评分函数，该函数基于疾病类别和形容词/方向性描述符捕捉样本间相似性的综合度量。最后，我们引入了一个多模态三元组对齐目标，用于显式地在具有详细病理特征的样本之间实现跨模态对齐。我们的演示表明，与最先进的对齐方法相比，MedTrim在下游检索和分类任务中的性能得到了改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diagnostic imaging relies on interpreting both images and radiology reports,but the growing data volumes place significant pressure on medical experts,yielding increased errors and workflow backlogs. Medical vision-language models(med-VLMs) have emerged as a powerful framework to efficiently processmultimodal imaging data, particularly in chest X-ray (CXR) evaluations, albeittheir performance hinges on how well image and text representations arealigned. Existing alignment methods, predominantly based on contrastivelearning, prioritize separation between disease classes over segregation offine-grained pathology attributes like location, size or severity, leading tosuboptimal representations. Here, we propose MedTrim (Meta-entity-drivenTriplet mining), a novel method that enhances image-text alignment throughmultimodal triplet learning synergistically guided by disease class as well asadjectival and directional pathology descriptors. Unlike common alignmentmethods that separate broad disease classes, MedTrim leverages structuredmeta-entity information to preserve subtle but clinically significantintra-class variations. For this purpose, we first introduce an ontology-basedentity recognition module that extracts pathology-specific meta-entities fromCXR reports, as annotations on pathology attributes are rare in publicdatasets. For refined sample selection in triplet mining, we then introduce anovel score function that captures an aggregate measure of inter-samplesimilarity based on disease classes and adjectival/directional descriptors.Lastly, we introduce a multimodal triplet alignment objective for explicitwithin- and cross-modal alignment between samples sharing detailed pathologycharacteristics. Our demonstrations indicate that MedTrim improves performancein downstream retrieval and classification tasks compared to state-of-the-artalignment methods.</description>
      <author>example@mail.com (Saban Ozturk, Melih B. Yilmaz, Muti Kara, M. Talat Yavuz, Aykut Koç, Tolga Çukur)</author>
      <guid isPermaLink="false">2504.15929v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ZeroSlide: Is Zero-Shot Classification Adequate for Lifelong Learning in Whole-Slide Image Analysis in the Era of Pathology Vision-Language Foundation Models?</title>
      <link>http://arxiv.org/abs/2504.15627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 1 table, conference submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了终身学习在整张切片图像（WSIs）上的挑战，并比较了传统的持续学习方法和视觉-语言零样本分类方法。&lt;h4&gt;背景&lt;/h4&gt;在临床和医院环境中，WSIs由于数据量大，需要存储、处理和传输时间，因此训练新模型以执行多种WSI相关任务（如癌症亚型和肿瘤分类）具有实际应用价值。&lt;h4&gt;目的&lt;/h4&gt;研究旨在确定仅使用零样本分类的视觉-语言基础模型是否足以进行终身WSI学习，以及是否需要进一步研究持续学习策略以提高性能。&lt;h4&gt;方法&lt;/h4&gt;该研究首次比较了传统的持续学习方法与视觉-语言零样本分类方法在WSI上的应用。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果将很快公开，包括源代码和实验结果。&lt;h4&gt;结论&lt;/h4&gt;论文未提供明确的结论，但强调了需要进一步研究以确定最佳的学习策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong learning for whole slide images (WSIs) poses the challenge oftraining a unified model to perform multiple WSI-related tasks, such as cancersubtyping and tumor classification, in a distributed, continual fashion. Thisis a practical and applicable problem in clinics and hospitals, as WSIs arelarge, require storage, processing, and transfer time. Training new modelswhenever new tasks are defined is time-consuming. Recent work has appliedregularization- and rehearsal-based methods to this setting. However, the riseof vision-language foundation models that align diagnostic text with pathologyimages raises the question: are these models alone sufficient for lifelong WSIlearning using zero-shot classification, or is further investigation intocontinual learning strategies needed to improve performance? To our knowledge,this is the first study to compare conventional continual-learning approacheswith vision-language zero-shot classification for WSIs. Our source code andexperimental results will be available soon.</description>
      <author>example@mail.com (Doanh C. Bui, Hoai Luan Pham, Vu Trung Duong Le, Tuan Hai Vu, Van Duy Tran, Yasuhiko Nakashima)</author>
      <guid isPermaLink="false">2504.15627v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>RiskNet: Interaction-Aware Risk Forecasting for Autonomous Driving in Long-Tail Scenarios</title>
      <link>http://arxiv.org/abs/2504.15541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RiskNet的交互感知风险预测框架，用于解决自动驾驶车辆在长尾场景下的安全问题。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆在长尾场景下的安全性保证是一个关键挑战，尤其是在高不确定性和复杂多智能体交互的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，提出了RiskNet框架，以实现对风险的全面评估。&lt;h4&gt;方法&lt;/h4&gt;RiskNet集成了确定性风险模型和概率行为预测，通过场理论模型捕捉自我车辆、周围智能体和基础设施之间的交互。此外，引入了基于图神经网络（GNN）的轨迹预测模块，以学习多模态的未来运动分布。&lt;h4&gt;主要发现&lt;/h4&gt;RiskNet在多种场景（高速公路、交叉口和环岛）中支持多维风险评估，并在高风险和长尾设置下表现出鲁棒性。在highD、inD和roundD数据集上的评估显示，该方法在准确性、响应性和方向敏感性方面显著优于传统方法，同时在场景间保持良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该框架支持实时、场景自适应的风险预测，并在不确定的驾驶环境中表现出强大的泛化能力，为长尾场景中的安全关键决策提供了统一的基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为RiskNet的交互感知风险预测框架，旨在解决自动驾驶车辆在长尾场景下的安全性问题。该框架结合确定性风险模型和概率行为预测，通过场理论模型捕捉自我车辆、周围智能体和基础设施之间的交互，并引入了基于图神经网络的轨迹预测模块。在多个数据集上的评估表明，该方法在准确性、响应性和方向敏感性方面优于传统方法，并在不确定的驾驶环境中具有强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of autonomous vehicles (AVs) in long-tail scenariosremains a critical challenge, particularly under high uncertainty and complexmulti-agent interactions. To address this, we propose RiskNet, aninteraction-aware risk forecasting framework, which integrates deterministicrisk modeling with probabilistic behavior prediction for comprehensive riskassessment. At its core, RiskNet employs a field-theoretic model that capturesinteractions among ego vehicle, surrounding agents, and infrastructure viainteraction fields and force. This model supports multidimensional riskevaluation across diverse scenarios (highways, intersections, and roundabouts),and shows robustness under high-risk and long-tail settings. To capture thebehavioral uncertainty, we incorporate a graph neural network (GNN)-basedtrajectory prediction module, which learns multi-modal future motiondistributions. Coupled with the deterministic risk field, it enables dynamic,probabilistic risk inference across time, enabling proactive safety assessmentunder uncertainty. Evaluations on the highD, inD, and rounD datasets, spanninglane changes, turns, and complex merges, demonstrate that our methodsignificantly outperforms traditional approaches (e.g., TTC, THW, RSS, NCField) in terms of accuracy, responsiveness, and directional sensitivity, whilemaintaining strong generalization across scenarios. This framework supportsreal-time, scenario-adaptive risk forecasting and demonstrates stronggeneralization across uncertain driving environments. It offers a unifiedfoundation for safety-critical decision-making in long-tail scenarios.</description>
      <author>example@mail.com (Qichao Liu, Heye Huang, Shiyue Zhao, Lei Shi, Soyoung Ahn, Xiaopeng Li)</author>
      <guid isPermaLink="false">2504.15541v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion</title>
      <link>http://arxiv.org/abs/2504.15920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ScaleGNN的新型框架，用于解决大规模图上的GNNs的过平滑和可扩展性问题，通过自适应融合多级图特征来同时解决这两个挑战。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图相关任务中表现出色，但存在过平滑和可扩展性问题，传统架构复杂度高，推理时间增加。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够同时解决GNNs过平滑和可扩展性问题的框架。&lt;h4&gt;方法&lt;/h4&gt;ScaleGNN通过自适应融合多级图特征，构建每个阶数的邻接矩阵，并通过可训练权重学习它们之间的相对信息。此外，引入基于局部贡献分数（LCS）的高阶冗余特征掩码机制，以保留每个阶数中最相关的邻居，防止冗余信息传播。&lt;h4&gt;主要发现&lt;/h4&gt;ScaleGNN在真实世界数据集上的实验表明，该方法在准确性和计算效率方面均优于最先进的GNN模型。&lt;h4&gt;结论&lt;/h4&gt;ScaleGNN框架有效地解决了GNNs在处理大规模图数据时的过平滑和可扩展性问题，提高了模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have demonstrated strong performance across various graph-based tasks by effectively capturing relational information between nodes. These models rely on iterative message passing to propagate node features, enabling nodes to aggregate information from their neighbors. Recent research has significantly improved the message-passing mechanism, enhancing GNN scalability on large-scale graphs. However, GNNs still face two main challenges: over-smoothing, where excessive message passing results in indistinguishable node representations, especially in deep networks incorporating high-order neighbors; and scalability issues, as traditional architectures suffer from high model complexity and increased inference time due to redundant information aggregation. This paper proposes a novel framework for large-scale graphs named ScaleGNN that simultaneously addresses both challenges by adaptively fusing multi-level graph features. We first construct neighbor matrices for each order, learning their relative information through trainable weights through an adaptive high-order feature fusion module. This allows the model to selectively emphasize informative high-order neighbors while reducing unnecessary computational costs. Additionally, we introduce a High-order redundant feature masking mechanism based on a Local Contribution Score (LCS), which enables the model to retain only the most relevant neighbors at each order, preventing redundant information propagation. Furthermore, low-order enhanced feature aggregation adaptively integrates low-order and high-order features based on task relevance, ensuring effective capture of both local and global structural information without excessive complexity. Extensive experiments on real-world datasets demonstrate that our approach consistently outperforms state-of-the-art GNN models in both accuracy and computational efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong performance acrossvarious graph-based tasks by effectively capturing relational informationbetween nodes. These models rely on iterative message passing to propagate nodefeatures, enabling nodes to aggregate information from their neighbors. Recentresearch has significantly improved the message-passing mechanism, enhancingGNN scalability on large-scale graphs. However, GNNs still face two mainchallenges: over-smoothing, where excessive message passing results inindistinguishable node representations, especially in deep networksincorporating high-order neighbors; and scalability issues, as traditionalarchitectures suffer from high model complexity and increased inference timedue to redundant information aggregation. This paper proposes a novel frameworkfor large-scale graphs named ScaleGNN that simultaneously addresses bothchallenges by adaptively fusing multi-level graph features. We first constructneighbor matrices for each order, learning their relative information throughtrainable weights through an adaptive high-order feature fusion module. Thisallows the model to selectively emphasize informative high-order neighborswhile reducing unnecessary computational costs. Additionally, we introduce aHigh-order redundant feature masking mechanism based on a Local ContributionScore (LCS), which enables the model to retain only the most relevant neighborsat each order, preventing redundant information propagation. Furthermore,low-order enhanced feature aggregation adaptively integrates low-order andhigh-order features based on task relevance, ensuring effective capture of bothlocal and global structural information without excessive complexity. Extensiveexperiments on real-world datasets demonstrate that our approach consistentlyoutperforms state-of-the-art GNN models in both accuracy and computationalefficiency.</description>
      <author>example@mail.com (Xiang Li, Haobing Liu, Jianpeng Qi, Yuan Cao, Guoqing Chao, Yanwei Yu)</author>
      <guid isPermaLink="false">2504.15920v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>ViSMaP: Unsupervised Hour-long Video Summarisation by Meta-Prompting</title>
      <link>http://arxiv.org/abs/2504.15921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ViSMap是一种无监督视频摘要系统，可以用于总结长达数小时的视频。&lt;h4&gt;背景&lt;/h4&gt;现有的视频理解模型在处理短视频时效果良好，但在处理长视频时，由于相关事件分布稀疏且未预分段，效果不佳。此外，长视频理解通常依赖于需要大量标注的监督式分层训练，这既耗时又昂贵，且容易产生不一致性。&lt;h4&gt;目的&lt;/h4&gt;ViSMap旨在弥合短视频（标注数据丰富）和长视频（标注数据稀缺）之间的差距。&lt;h4&gt;方法&lt;/h4&gt;ViSMap利用LLM（大型语言模型）创建长视频的优化伪摘要，这些伪摘要使用来自短视频的片段描述。这些伪摘要作为训练数据，用于生成长视频摘要，从而避免了长视频标注的昂贵成本。具体来说，ViSMap采用元提示策略，通过迭代生成和优化长视频的伪摘要。策略利用从监督式短视频模型获得的短片段描述来指导摘要。每个迭代使用三个LLM依次工作：一个用于从片段描述生成伪摘要，另一个用于评估它，第三个用于优化生成器的提示。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上广泛评估了ViSMap的摘要，结果显示ViSMap在性能上与完全监督的顶尖模型相当，同时能够在多个领域中进行泛化，而不会牺牲性能。&lt;h4&gt;结论&lt;/h4&gt;ViSMap在发布后将发布代码。&lt;h4&gt;翻译&lt;/h4&gt;We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, a system to summarise hour long videos with no-supervision. Most existing video understanding models work well on short videos of pre-segmented events, yet they struggle to summarise longer videos where relevant events are sparsely distributed and not pre-segmented. Moreover, long-form video understanding often relies on supervised hierarchical training that needs extensive annotations which are costly, slow and prone to inconsistency. With ViSMaP we bridge the gap between short videos (where annotated data is plentiful) and long ones (where it's not). We rely on LLMs to create optimised pseudo-summaries of long videos using segment descriptions from short ones. These pseudo-summaries are used as training data for a model that generates long-form video summaries, bypassing the need for expensive annotations of long videos. Specifically, we adopt a meta-prompting strategy to iteratively generate and refine creating pseudo-summaries of long videos. The strategy leverages short clip descriptions obtained from a supervised short video model to guide the summary. Each iteration uses three LLMs working in sequence: one to generate the pseudo-summary from clip descriptions, another to evaluate it, and a third to optimise the prompt of the generator. This iteration is necessary because the quality of the pseudo-summaries is highly dependent on the generator prompt, and varies widely among videos. We evaluate our summaries extensively on multiple datasets; our results show that ViSMaP achieves performance comparable to fully supervised state-of-the-art models while generalising across domains without sacrificing performance. Code will be released upon publication.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ViSMap: Unsupervised Video Summarisation by Meta Prompting, asystem to summarise hour long videos with no-supervision. Most existing videounderstanding models work well on short videos of pre-segmented events, yetthey struggle to summarise longer videos where relevant events are sparselydistributed and not pre-segmented. Moreover, long-form video understandingoften relies on supervised hierarchical training that needs extensiveannotations which are costly, slow and prone to inconsistency. With ViSMaP webridge the gap between short videos (where annotated data is plentiful) andlong ones (where it's not). We rely on LLMs to create optimisedpseudo-summaries of long videos using segment descriptions from short ones.These pseudo-summaries are used as training data for a model that generateslong-form video summaries, bypassing the need for expensive annotations of longvideos. Specifically, we adopt a meta-prompting strategy to iterativelygenerate and refine creating pseudo-summaries of long videos. The strategyleverages short clip descriptions obtained from a supervised short video modelto guide the summary. Each iteration uses three LLMs working in sequence: oneto generate the pseudo-summary from clip descriptions, another to evaluate it,and a third to optimise the prompt of the generator. This iteration isnecessary because the quality of the pseudo-summaries is highly dependent onthe generator prompt, and varies widely among videos. We evaluate our summariesextensively on multiple datasets; our results show that ViSMaP achievesperformance comparable to fully supervised state-of-the-art models whilegeneralising across domains without sacrificing performance. Code will bereleased upon publication.</description>
      <author>example@mail.com (Jian Hu, Dimitrios Korkinof, Shaogang Gong, Mariano Beguerisse-Diaz)</author>
      <guid isPermaLink="false">2504.15921v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>GraphEdge: Dynamic Graph Partition and Task Scheduling for GNNs Computing in Edge Network</title>
      <link>http://arxiv.org/abs/2504.15905v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的边缘计算架构GraphEdge，用于在图结构场景下提供高效服务，以解决现有方法在处理关联用户数据时的通信成本问题。&lt;h4&gt;背景&lt;/h4&gt;随着物联网设备的指数级增长，边缘计算在提供成本效益服务方面发挥着越来越重要的作用。然而，现有方法在处理交通流量预测和社会关系推荐系统等用户数据相关联的图结构场景时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决图神经网络（GNN）方法导致的昂贵的服务器通信成本问题。&lt;h4&gt;方法&lt;/h4&gt;GraphEdge架构首先感知用户拓扑，将数据关联表示为每个时间步的图布局。然后，通过调用提出的分层遍历图切分算法（HiCut）优化图布局，该算法根据GNN的聚合特征将图布局切割成多个弱关联的子图，并最小化GNN推理过程中不同子图之间的通信成本。最后，基于优化的图布局执行基于深度强化学习（DRL）的图卸载算法（DRLGO），以获取用户任务的优化卸载策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的架构具有良好的有效性和动态适应性，即使在动态场景中也能表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;GraphEdge架构有效地解决了图结构场景中的通信成本问题，为边缘计算提供了高效的服务。&lt;h4&gt;翻译&lt;/h4&gt;With the exponential growth of Internet of Things (IoT) devices, edge computing (EC) is gradually playing an important role in providing cost-effective services. However, existing approaches struggle to perform well in graph-structured scenarios where user data is correlated, such as traffic flow prediction and social relationship recommender systems. In particular, graph neural network (GNN)-based approaches lead to expensive server communication cost. To address this problem, we propose GraphEdge, an efficient GNN-based EC architecture. It considers the EC system of GNN tasks, where there are associations between users and it needs to take into account the task data of its neighbors when processing the tasks of a user. Specifically, the architecture first perceives the user topology and represents their data associations as a graph layout at each time step. Then the graph layout is optimized by calling our proposed hierarchical traversal graph cut algorithm (HiCut), which cuts the graph layout into multiple weakly associated subgraphs based on the aggregation characteristics of GNN, and the communication cost between different subgraphs during GNN inference is minimized. Finally, based on the optimized graph layout, our proposed deep reinforcement learning (DRL) based graph offloading algorithm (DRLGO) is executed to obtain the optimal offloading strategy for the tasks of users, the offloading strategy is subgraph-based, it tries to offload user tasks in a subgraph to the same edge server as possible while minimizing the task processing time and energy consumption of the EC system. Experimental results show the good effectiveness and dynamic adaptation of our proposed architecture and it also performs well even in dynamic scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the exponential growth of Internet of Things (IoT) devices, edgecomputing (EC) is gradually playing an important role in providingcost-effective services. However, existing approaches struggle to perform wellin graph-structured scenarios where user data is correlated, such as trafficflow prediction and social relationship recommender systems. In particular,graph neural network (GNN)-based approaches lead to expensive servercommunication cost. To address this problem, we propose GraphEdge, an efficientGNN-based EC architecture. It considers the EC system of GNN tasks, where thereare associations between users and it needs to take into account the task dataof its neighbors when processing the tasks of a user. Specifically, thearchitecture first perceives the user topology and represents their dataassociations as a graph layout at each time step. Then the graph layout isoptimized by calling our proposed hierarchical traversal graph cut algorithm(HiCut), which cuts the graph layout into multiple weakly associated subgraphsbased on the aggregation characteristics of GNN, and the communication costbetween different subgraphs during GNN inference is minimized. Finally, basedon the optimized graph layout, our proposed deep reinforcement learning (DRL)based graph offloading algorithm (DRLGO) is executed to obtain the optimaloffloading strategy for the tasks of users, the offloading strategy issubgraph-based, it tries to offload user tasks in a subgraph to the same edgeserver as possible while minimizing the task processing time and energyconsumption of the EC system. Experimental results show the good effectivenessand dynamic adaptation of our proposed architecture and it also performs welleven in dynamic scenarios.</description>
      <author>example@mail.com (Wenjing Xiao, Chenglong Shi, Miaojiang Chen, Zhiquan Liu, Min Chen, H. Herbert Song)</author>
      <guid isPermaLink="false">2504.15905v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Survey of Video Diffusion Models: Foundations, Implementations, and Applications</title>
      <link>http://arxiv.org/abs/2504.16081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了扩散模型在视频生成领域的应用，与传统的基于生成对抗网络的方法相比，扩散模型在时间一致性和视觉质量方面有显著提升。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在视频生成领域取得了重大进展，但仍面临运动一致性、计算效率和伦理考量等挑战。&lt;h4&gt;目的&lt;/h4&gt;提供对基于扩散的视频生成技术的全面审查，包括其演变、技术基础和应用。&lt;h4&gt;方法&lt;/h4&gt;对现有方法进行系统分类，分析架构创新和优化策略，并探讨在去噪和超分辨率等低级视觉任务中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;本文探讨了扩散模型视频生成与其他领域（如视频表示学习、问答和检索）的协同作用，并提供了比现有综述更全面、更新、更细致的视角。&lt;h4&gt;结论&lt;/h4&gt;本文为在扩散模型和视频生成交叉领域工作的研究人员和从业者提供了基础资源，涵盖了该领域快速发展的理论框架和实践实施。&lt;h4&gt;翻译&lt;/h4&gt;This survey provides a comprehensive review of diffusion-based video generation, examining its evolution, technical foundations, and practical applications. We present a systematic taxonomy of current methodologies, analyze architectural innovations and optimization strategies, and investigate applications across low-level vision tasks such as denoising and super-resolution. Additionally, we explore the synergies between diffusion-based video generation and related domains, including video representation learning, question answering, and retrieval. Compared to the existing surveys (Lei et al., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) which focus on specific aspects of video generation, such as human video synthesis (Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), our work provides a broader, more updated, and more fine-grained perspective on diffusion-based approaches with a special section for evaluation metrics, industry solutions, and training engineering techniques in video generation. This survey serves as a foundational resource for researchers and practitioners working at the intersection of diffusion models and video generation, providing insights into both the theoretical frameworks and practical implementations that drive this rapidly evolving field. A structured list of related works involved in this survey is also available on https://github.com/Eyeline-Research/Survey-Video-Diffusion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in diffusion models have revolutionized video generation,offering superior temporal consistency and visual quality compared totraditional generative adversarial networks-based approaches. While thisemerging field shows tremendous promise in applications, it faces significantchallenges in motion consistency, computational efficiency, and ethicalconsiderations. This survey provides a comprehensive review of diffusion-basedvideo generation, examining its evolution, technical foundations, and practicalapplications. We present a systematic taxonomy of current methodologies,analyze architectural innovations and optimization strategies, and investigateapplications across low-level vision tasks such as denoising andsuper-resolution. Additionally, we explore the synergies between diffusionbasedvideo generation and related domains, including video representation learning,question answering, and retrieval. Compared to the existing surveys (Lei etal., 2024a;b; Melnik et al., 2024; Cao et al., 2023; Xing et al., 2024c) whichfocus on specific aspects of video generation, such as human video synthesis(Lei et al., 2024a) or long-form content generation (Lei et al., 2024b), ourwork provides a broader, more updated, and more fine-grained perspective ondiffusion-based approaches with a special section for evaluation metrics,industry solutions, and training engineering techniques in video generation.This survey serves as a foundational resource for researchers and practitionersworking at the intersection of diffusion models and video generation, providinginsights into both the theoretical frameworks and practical implementationsthat drive this rapidly evolving field. A structured list of related worksinvolved in this survey is also available onhttps://github.com/Eyeline-Research/Survey-Video-Diffusion.</description>
      <author>example@mail.com (Yimu Wang, Xuye Liu, Wei Pang, Li Ma, Shuai Yuan, Paul Debevec, Ning Yu)</author>
      <guid isPermaLink="false">2504.16081v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning</title>
      <link>http://arxiv.org/abs/2504.16023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointLoRA的简单有效的点云模型微调方法，通过结合低秩适应（LoRA）和多尺度标记选择，以降低计算和存储资源需求。&lt;h4&gt;背景&lt;/h4&gt;自监督表示学习在提升预训练模型性能方面表现良好，但随着预训练模型复杂度的增加，完全微调需要大量的计算和存储资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种参数高效的微调（PEFT）方法，以减轻资源需求。&lt;h4&gt;方法&lt;/h4&gt;PointLoRA方法将LoRA层嵌入到点云变压器中最参数密集的部分，减少可调参数数量，同时增强全局特征捕捉。多尺度标记选择提取关键局部信息作为下游微调的提示，补充LoRA捕获的全局上下文。&lt;h4&gt;主要发现&lt;/h4&gt;在多个预训练模型和三个公开数据集上的实验结果表明，PointLoRA在仅使用3.43%的可训练参数的情况下，实现了有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;PointLoRA是一种高度有效的资源受限应用的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes PointLoRA, a simple yet effective method that combines low-rank adaptation (LoRA) with multi-scale token selection to efficiently fine-tune point cloud models. Our approach embeds LoRA layers within the most parameter-intensive components of point cloud transformers, reducing the need for tunable parameters while enhancing global feature capture. Additionally, multi-scale token selection extracts critical local information to serve as prompts for downstream fine-tuning, effectively complementing the global context captured by LoRA. Experimental results across various pre-trained models and three challenging public datasets demonstrate that our approach achieves competitive performance with only 3.43% of the trainable parameters, making it highly effective for resource-constrained applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised representation learning for point cloud has demonstratedeffectiveness in improving pre-trained model performance across diverse tasks.However, as pre-trained models grow in complexity, fully fine-tuning them fordownstream applications demands substantial computational and storageresources. Parameter-efficient fine-tuning (PEFT) methods offer a promisingsolution to mitigate these resource requirements, yet most current approachesrely on complex adapter and prompt mechanisms that increase tunable parameters.In this paper, we propose PointLoRA, a simple yet effective method thatcombines low-rank adaptation (LoRA) with multi-scale token selection toefficiently fine-tune point cloud models. Our approach embeds LoRA layerswithin the most parameter-intensive components of point cloud transformers,reducing the need for tunable parameters while enhancing global featurecapture. Additionally, multi-scale token selection extracts critical localinformation to serve as prompts for downstream fine-tuning, effectivelycomplementing the global context captured by LoRA. The experimental resultsacross various pre-trained models and three challenging public datasetsdemonstrate that our approach achieves competitive performance with only 3.43%of the trainable parameters, making it highly effective forresource-constrained applications. Source code is available at:https://github.com/songw-zju/PointLoRA.</description>
      <author>example@mail.com (Song Wang, Xiaolu Liu, Lingdong Kong, Jianyun Xu, Chunyong Hu, Gongfan Fang, Wentong Li, Jianke Zhu, Xinchao Wang)</author>
      <guid isPermaLink="false">2504.16023v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Vidi: Large Multimodal Models for Video Understanding and Editing</title>
      <link>http://arxiv.org/abs/2504.15681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Vidi的用于视频理解和编辑的Large Multimodal Models（LMMs）系列，旨在支持高质量大规模视频内容的创作。&lt;h4&gt;背景&lt;/h4&gt;人类自然地与他们的联系者分享信息，视频已成为互联网上主要的沟通和表达媒介。现代视频制作流程需要全面理解原始素材和编辑组件。&lt;h4&gt;目的&lt;/h4&gt;为了支持高质量大规模视频内容的创作，开发能够处理多模态信息且具有强背景知识的模型，以应对传统模型在处理长视频和多种输入长度时的挑战。&lt;h4&gt;方法&lt;/h4&gt;Vidi模型专注于时间检索，即识别输入视频中与给定文本查询相对应的时间范围。此外，还提出了VUE-TR基准，包括视频时长、音频支持、查询格式、标注质量和评估指标等五个关键进展。&lt;h4&gt;主要发现&lt;/h4&gt;Vidi在时间检索任务上显著优于GPT-4o和Gemini等领先模型，表明其在视频编辑场景中的优越性。&lt;h4&gt;结论&lt;/h4&gt;Vidi模型在视频编辑场景中表现出色，能够有效处理长视频和多种输入长度，支持智能编辑。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类自然地与他们联系的人分享信息，视频已成为互联网上主要的沟通和表达媒介。为了支持高质量大规模视频内容的创作，现代视频制作流程需要全面理解原始素材和编辑组件。在视频编辑场景中，模型必须处理多种模态（例如，视觉、音频、文本）并具有强大的背景知识，同时处理灵活的输入长度（例如，长达数小时的原始视频），这对传统模型提出了重大挑战。在本报告中，我们介绍了一组用于广泛视频理解和编辑场景的Large Multimodal Models（LMMs）——Vidi。首个版本专注于时间检索，即识别输入视频中与给定文本查询相对应的时间范围，这在智能编辑中起着关键作用。该模型能够处理长达数小时的视频，并具有强大的时间理解能力，例如检索特定查询的时间范围。为了支持在现实场景中的全面评估，我们还提出了VUE-TR基准，该基准引入了五个关键进展：1）视频时长：比现有的时间检索数据集长得多；2）音频支持：包括基于音频的查询；3）查询格式：多样化的查询长度/格式；4）标注质量：地面实况时间范围是手动标注的；5）评估指标：一个精细的IoU指标，支持对多个时间范围进行评估。值得注意的是，Vidi在时间检索任务上显著优于领先的专有模型，例如GPT-4o和Gemini，这表明其在视频编辑场景中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally share information with those they are connected to, andvideo has become one of the dominant mediums for communication and expressionon the Internet. To support the creation of high-quality large-scale videocontent, a modern pipeline requires a comprehensive understanding of both theraw input materials (e.g., the unedited footage captured by cameras) and theediting components (e.g., visual effects). In video editing scenarios, modelsmust process multiple modalities (e.g., vision, audio, text) with strongbackground knowledge and handle flexible input lengths (e.g., hour-long rawvideos), which poses significant challenges for traditional models. In thisreport, we introduce Vidi, a family of Large Multimodal Models (LMMs) for awide range of video understand editing scenarios. The first release focuses ontemporal retrieval, i.e., identifying the time ranges within the input videoscorresponding to a given text query, which plays a critical role in intelligentediting. The model is capable of processing hour-long videos with strongtemporal understanding capability, e.g., retrieve time ranges for certainqueries. To support a comprehensive evaluation in real-world scenarios, we alsopresent the VUE-TR benchmark, which introduces five key advancements. 1) Videoduration: significantly longer than existing temporal retrival datasets, 2)Audio support: includes audio-based queries, 3) Query format: diverse querylengths/formats, 4) Annotation quality: ground-truth time ranges are manuallyannotated. 5) Evaluation metric: a refined IoU metric to support evaluationover multiple time ranges. Remarkably, Vidi significantly outperforms leadingproprietary models, e.g., GPT-4o and Gemini, on the temporal retrieval task,indicating its superiority in video editing scenarios.</description>
      <author>example@mail.com (Vidi Team, Celong Liu, Chia-Wen Kuo, Dawei Du, Fan Chen, Guang Chen, Jiamin Yuan, Lingxi Zhang, Lu Guo, Lusha Li, Longyin Wen, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin, Wei Lu, Wen Zhong, Xiaohui Shen, Xin Gu, Xing Mei, Xueqiong Qu)</author>
      <guid isPermaLink="false">2504.15681v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>AdaViP: Aligning Multi-modal LLMs via Adaptive Vision-enhanced Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.15619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应视觉增强偏好优化（AdaViP）方法，通过两个关键创新解决了现有方法在多模态大语言模型（MLLMs）与人类偏好对齐中忽视视觉上下文的问题。&lt;h4&gt;背景&lt;/h4&gt;DPO方法在多模态大语言模型与人类偏好对齐方面显示出显著效果，但现有方法主要关注语言偏好，而忽略了视觉上下文的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出AdaViP方法，以解决现有方法忽视视觉上下文的局限性。&lt;h4&gt;方法&lt;/h4&gt;AdaViP方法包括：(1)基于视觉的偏好对构建，通过整合多个视觉基础模型策略性地去除图像中的关键视觉元素，增强MLLMs对视觉细节的敏感性；(2)自适应偏好优化，动态平衡视觉和语言偏好，以实现更精确的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;AdaViP方法在不同基准测试中表现出有效性，其中AdaViP-7B在Object HalBench上实现了93.7%和96.4%的响应级和提及级幻觉减少，显著优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;AdaViP方法通过视觉增强和自适应优化，提高了多模态大语言模型与人类偏好对齐的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Preference alignment through Direct Preference Optimization (DPO) hasdemonstrated significant effectiveness in aligning multimodal large languagemodels (MLLMs) with human preferences. However, existing methods focusprimarily on language preferences while neglecting the critical visual context.In this paper, we propose an Adaptive Vision-enhanced Preference optimization(AdaViP) that addresses these limitations through two key innovations: (1)vision-based preference pair construction, which integrates multiple visualfoundation models to strategically remove key visual elements from the image,enhancing MLLMs' sensitivity to visual details; and (2) adaptive preferenceoptimization that dynamically balances vision- and language-based preferencesfor more accurate alignment. Extensive evaluations across different benchmarksdemonstrate our effectiveness. Notably, our AdaViP-7B achieves 93.7% and 96.4%reductions in response-level and mentioned-level hallucination respectively onthe Object HalBench, significantly outperforming current state-of-the-artmethods.</description>
      <author>example@mail.com (Jinda Lu, Jinghan Li, Yuan Gao, Junkang Wu, Jiancan Wu, Xiang Wang, Xiangnan He)</author>
      <guid isPermaLink="false">2504.15619v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Topological model selection: a case-study in tumour-induced angiogenesis</title>
      <link>http://arxiv.org/abs/2504.15442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的参数推断和模型选择流程，用于处理模拟高维时空数据的概率模型。&lt;h4&gt;背景&lt;/h4&gt;比较数学模型是评估竞争性科学理论的方法，但精确的模型校准方法不适用于许多模拟高维时空数据的概率模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种灵活的流程，用于参数推断和模型选择，以处理模拟高维时空数据的概率模型。&lt;h4&gt;方法&lt;/h4&gt;该流程结合了近似贝叶斯计算和拓扑数据分析，用于识别拓扑摘要统计量，量化时空数据，并使用这些统计量来近似参数和模型后验分布。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在肿瘤诱导血管生成模型上得到了验证，推断出三个模型中的四个参数，并在合成测试案例中确定了正确的模型。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地进行参数推断和模型选择，适用于模拟高维时空数据的概率模型。&lt;h4&gt;翻译&lt;/h4&gt;Comparing mathematical models offers a means to evaluate competing scientific theories. However, exact methods of model calibration are not applicable to many probabilistic models which simulate high-dimensional spatio-temporal data. Approximate Bayesian Computation is a widely-used method for parameter inference and model selection in such scenarios, and it may be combined with Topological Data Analysis to study models which simulate data with fine spatial structure. We develop a flexible pipeline for parameter inference and model selection in spatio-temporal models. Our pipeline identifies topological summary statistics which quantify spatio-temporal data and uses them to approximate parameter and model posterior distributions. We validate our pipeline on models of tumour-induced angiogenesis, inferring four parameters in three established models and identifying the correct model in synthetic test-cases.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Comparing mathematical models offers a means to evaluate competing scientifictheories. However, exact methods of model calibration are not applicable tomany probabilistic models which simulate high-dimensional spatio-temporal data.Approximate Bayesian Computation is a widely-used method for parameterinference and model selection in such scenarios, and it may be combined withTopological Data Analysis to study models which simulate data with fine spatialstructure. We develop a flexible pipeline for parameter inference and modelselection in spatio-temporal models. Our pipeline identifies topologicalsummary statistics which quantify spatio-temporal data and uses them toapproximate parameter and model posterior distributions. We validate ourpipeline on models of tumour-induced angiogenesis, inferring four parameters inthree established models and identifying the correct model in synthetictest-cases.</description>
      <author>example@mail.com (Robert A McDonald, Helen M Byrne, Heather A Harrington, Thomas Thorne, Bernadette J Stolz)</author>
      <guid isPermaLink="false">2504.15442v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Adaptation of Deep Neural Networks for Semantic Segmentation in Space Applications</title>
      <link>http://arxiv.org/abs/2504.15991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度学习技术在行星探测中的应用，特别是针对月球和火星地表岩石分割任务，探讨了使用适配器进行高效迁移学习的可行性。&lt;h4&gt;背景&lt;/h4&gt;近年来，深度学习技术在计算机视觉任务中取得了显著成功，为在行星探测中的应用奠定了基础。然而，在新的环境中，标记数据的稀缺性问题成为了一个挑战。&lt;h4&gt;目的&lt;/h4&gt;评估在行星探测中，特别是月球和火星地表岩石分割任务中，使用适配器进行高效迁移学习的可行性。&lt;h4&gt;方法&lt;/h4&gt;研究采用了两种内存节省策略：层融合（将推理开销降至零）和“适配器排名”（降低传输成本）。这些策略被整合到一个预训练的骨干模型中。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，将适配器策略集成到预训练骨干模型中，可以有效地减少目标外星设备的数据传输带宽和内存需求。&lt;h4&gt;结论&lt;/h4&gt;本研究在任务性能、内存和计算方面评估了结果，证实了在特定条件下存在权衡，为该领域进一步的研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, the application of Deep Learning techniques has shown remarkable success in various computer vision tasks, paving the way for their deployment in extraterrestrial exploration. Transfer learning has emerged as a powerful strategy for addressing the scarcity of labeled data in these novel environments. This paper represents one of the first efforts in evaluating the feasibility of employing adapters toward efficient transfer learning for rock segmentation in extraterrestrial landscapes, mainly focusing on lunar and Martian terrains. Our work suggests that the use of adapters, strategically integrated into a pre-trained backbone model, can be successful in reducing both bandwidth and memory requirements for the target extraterrestrial device. In this study, we considered two memory-saving strategies: layer fusion (to reduce to zero the inference overhead) and an ``adapter ranking'' (to also reduce the transmission cost). Finally, we evaluate these results in terms of task performance, memory, and computation on embedded devices, evidencing trade-offs that open the road to more research in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the application of Deep Learning techniques has shownremarkable success in various computer vision tasks, paving the way for theirdeployment in extraterrestrial exploration. Transfer learning has emerged as apowerful strategy for addressing the scarcity of labeled data in these novelenvironments. This paper represents one of the first efforts in evaluating thefeasibility of employing adapters toward efficient transfer learning for rocksegmentation in extraterrestrial landscapes, mainly focusing on lunar andmartian terrains. Our work suggests that the use of adapters, strategicallyintegrated into a pre-trained backbone model, can be successful in reducingboth bandwidth and memory requirements for the target extraterrestrial device.In this study, we considered two memory-saving strategies: layer fusion (toreduce to zero the inference overhead) and an ``adapter ranking'' (to alsoreduce the transmission cost). Finally, we evaluate these results in terms oftask performance, memory, and computation on embedded devices, evidencingtrade-offs that open the road to more research in the field.</description>
      <author>example@mail.com (Leonardo Olivi, Edoardo Santero Mormile, Enzo Tartaglione)</author>
      <guid isPermaLink="false">2504.15991v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>IV-Bench: A Benchmark for Image-Grounded Video Perception and Reasoning in Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2504.15415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出IV-Bench，这是第一个全面评估图像基础视频感知和推理的基准。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型（MLLMs）评估框架主要关注图像推理或一般视频理解任务，很大程度上忽略了图像在视频理解中的重要作用。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出了IV-Bench，用于评估图像基础视频感知和推理。&lt;h4&gt;方法&lt;/h4&gt;IV-Bench包含967个视频和2,585个精心注释的图像-文本查询，涉及13个任务（7个感知和6个推理任务）和5个代表性类别。对最先进的开源和闭源MLLMs进行了广泛的评估。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示，当前模型在图像基础视频感知和推理方面表现不佳，最高准确率仅为28.9%。进一步分析揭示了影响模型在IV-Bench上表现的关键因素，包括推理模式、帧数和分辨率。通过简单的数据合成方法，我们证明了IV-Bench的挑战不仅在于训练过程中数据格式的对齐。&lt;h4&gt;结论&lt;/h4&gt;这些发现为未来的研究提供了宝贵的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes IV-Bench, which is the first comprehensive benchmark for evaluating image-grounded video perception and reasoning. The existing evaluation frameworks for Multimodal Large Language Models (MLLMs) primarily focus on image reasoning or general video understanding tasks, largely overlooking the significant role of image context in video comprehension. To bridge this gap, we propose IV-Bench, the first comprehensive benchmark for evaluating Image-Grounded Video Perception and Reasoning. IV-Bench consists of 967 videos paired with 2,585 meticulously annotated image-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5 representative categories. Extensive evaluations of state-of-the-art open-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o, Gemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current models substantially underperform in image-grounded video Perception and Reasoning, merely achieving at most 28.9% accuracy. Further analysis reveals key factors influencing model performance on IV-Bench, including inference pattern, frame number, and resolution. Additionally, through a simple data synthesis approach, we demonstrate the challenges of IV-Bench extend beyond merely aligning the data format in the training process. These findings collectively provide valuable insights for future research. Our codes and data are released in https://github.com/multimodal-art-projection/IV-Bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing evaluation frameworks for Multimodal Large Language Models (MLLMs)primarily focus on image reasoning or general video understanding tasks,largely overlooking the significant role of image context in videocomprehension. To bridge this gap, we propose IV-Bench, the first comprehensivebenchmark for evaluating Image-Grounded Video Perception and Reasoning.IV-Bench consists of 967 videos paired with 2,585 meticulously annotatedimage-text queries across 13 tasks (7 perception and 6 reasoning tasks) and 5representative categories. Extensive evaluations of state-of-the-artopen-source (e.g., InternVL2.5, Qwen2.5-VL) and closed-source (e.g., GPT-4o,Gemini2-Flash and Gemini2-Pro) MLLMs demonstrate that current modelssubstantially underperform in image-grounded video Perception and Reasoning,merely achieving at most 28.9% accuracy. Further analysis reveals key factorsinfluencing model performance on IV-Bench, including inference pattern, framenumber, and resolution. Additionally, through a simple data synthesis approach,we demonstratethe challenges of IV- Bench extend beyond merely aligning thedata format in the training proecss. These findings collectively providevaluable insights for future research. Our codes and data are released inhttps://github.com/multimodal-art-projection/IV-Bench.</description>
      <author>example@mail.com (David Ma, Yuanxing Zhang, Jincheng Ren, Jarvis Guo, Yifan Yao, Zhenlin Wei, Zhenzhu Yang, Zhongyuan Peng, Boyu Feng, Jun Ma, Xiao Gu, Zhoufutu Wen, King Zhu, Yancheng He, Meng Cao, Shiwen Ni, Jiaheng Liu, Wenhao Huang, Ge Zhang, Xiaojie Jin)</author>
      <guid isPermaLink="false">2504.15415v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness</title>
      <link>http://arxiv.org/abs/2504.15796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Saliency Map-based Data Sampling Block (SM-DSB)的新方法，用于解决点云数据在未知或分布外场景下的分类问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云无监督领域自适应（UDA）方法通常采用多任务学习（MTL）框架，结合主要分类任务和辅助自监督任务来弥合跨域特征分布之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解决方案，以减轻自监督任务中梯度冲突的影响，并提高分类性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于3D显著性图偏度的评分机制来估计梯度冲突，无需目标标签。基于此，开发了一种样本选择策略，动态过滤掉对分类无益的自监督梯度样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在性能上优于现有方法，并且具有可扩展性和较低的计算开销，可以集成到所有点云UDA MTL框架中。&lt;h4&gt;结论&lt;/h4&gt;通过反向传播分析，本文提供了一个理解UDA问题的新视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用点云数据的对象分类模型对于3D媒体理解至关重要，但它们在未知或分布外（OOD）场景中往往表现不佳。现有的点云无监督领域自适应（UDA）方法通常采用多任务学习（MTL）框架，将主要分类任务与辅助自监督任务相结合，以弥合跨域特征分布之间的差距。然而，我们的进一步实验表明，并非所有来自自监督任务的梯度都是有益的，其中一些可能对分类性能产生负面影响。在本文中，我们提出了一种新的解决方案，称为基于显著性图的数据采样块（SM-DSB），以减轻这些梯度冲突。具体来说，我们的方法设计了一种基于3D显著性图偏度的评分机制，以估计梯度冲突，而无需目标标签。利用这一点，我们开发了一种样本选择策略，动态过滤掉对分类无益的自监督梯度样本。我们的方法可扩展，引入了适度的计算开销，并且可以集成到所有点云UDA MTL框架中。广泛的评估表明，我们的方法在性能上优于现有方法。此外，我们通过反向传播分析提供了一个理解UDA问题的新视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object classification models utilizing point cloud data are fundamental for3D media understanding, yet they often struggle with unseen orout-of-distribution (OOD) scenarios. Existing point cloud unsupervised domainadaptation (UDA) methods typically employ a multi-task learning (MTL) frameworkthat combines primary classification tasks with auxiliary self-supervisiontasks to bridge the gap between cross-domain feature distributions. However,our further experiments demonstrate that not all gradients fromself-supervision tasks are beneficial and some may negatively impact theclassification performance. In this paper, we propose a novel solution, termedSaliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradientconflicts. Specifically, our method designs a new scoring mechanism based onthe skewness of 3D saliency maps to estimate gradient conflicts withoutrequiring target labels. Leveraging this, we develop a sample selectionstrategy that dynamically filters out samples whose self-supervision gradientsare not beneficial for the classification. Our approach is scalable,introducing modest computational overhead, and can be integrated into all thepoint cloud UDA MTL frameworks. Extensive evaluations demonstrate that ourmethod outperforms state-of-the-art approaches. In addition, we provide a newperspective on understanding the UDA problem through back-propagation analysis.</description>
      <author>example@mail.com (Jiaqi Tang, Yinsong Xu, Qingchao Chen)</author>
      <guid isPermaLink="false">2504.15796v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Generative Image Modeling via Joint Image-Feature Synthesis</title>
      <link>http://arxiv.org/abs/2504.16064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的生成图像建模框架，通过联合建模低级图像潜变量和高级语义特征，实现了高质量的图像生成，同时提高了训练效率。&lt;h4&gt;背景&lt;/h4&gt;虽然潜在扩散模型（LDMs）在高质量图像生成中占据主导地位，但将表示学习与生成建模相结合仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，无缝连接表示学习与生成建模，以实现更高质量的图像生成。&lt;h4&gt;方法&lt;/h4&gt;利用扩散模型联合建模来自变分自编码器的低级图像潜变量和来自预训练自监督编码器（如DINO）的高级语义特征。该方法通过 Representation Guidance 策略，利用学习到的语义来引导和细化图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法从纯噪声中生成一致的图像-特征对，显著提高了生成质量和训练效率，同时只需对标准的扩散Transformer架构进行最小修改。&lt;h4&gt;结论&lt;/h4&gt;该方法在条件和无条件设置中均取得了实质性的改进，在图像质量和训练收敛速度方面表现出色，为具有表示意识的生成建模开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;We introduce a novel generative image modeling framework that seamlessly bridges this gap by leveraging a diffusion model to jointly model low-level image latents (from a variational autoencoder) and high-level semantic features (from a pretrained self-supervised encoder like DINO). Our latent-semantic diffusion approach learns to generate coherent image-feature pairs from pure noise, significantly enhancing both generative quality and training efficiency, all while requiring only minimal modifications to standard Diffusion Transformer architectures. By eliminating the need for complex distillation objectives, our unified design simplifies training and unlocks a powerful new inference strategy: Representation Guidance, which leverages learned semantics to steer and refine image generation. Evaluated in both conditional and unconditional settings, our method delivers substantial improvements in image quality and training convergence speed, establishing a new direction for representation-aware generative modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent diffusion models (LDMs) dominate high-quality image generation, yetintegrating representation learning with generative modeling remains achallenge. We introduce a novel generative image modeling framework thatseamlessly bridges this gap by leveraging a diffusion model to jointly modellow-level image latents (from a variational autoencoder) and high-levelsemantic features (from a pretrained self-supervised encoder like DINO). Ourlatent-semantic diffusion approach learns to generate coherent image-featurepairs from pure noise, significantly enhancing both generative quality andtraining efficiency, all while requiring only minimal modifications to standardDiffusion Transformer architectures. By eliminating the need for complexdistillation objectives, our unified design simplifies training and unlocks apowerful new inference strategy: Representation Guidance, which leverageslearned semantics to steer and refine image generation. Evaluated in bothconditional and unconditional settings, our method delivers substantialimprovements in image quality and training convergence speed, establishing anew direction for representation-aware generative modeling.</description>
      <author>example@mail.com (Theodoros Kouzelis, Efstathios Karypidis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis)</author>
      <guid isPermaLink="false">2504.16064v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>MedNNS: Supernet-based Medical Task-Adaptive Neural Network Search</title>
      <link>http://arxiv.org/abs/2504.15865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于医学影像的深度学习模型，提出了Medical Neural Network Search (MedNNS)框架，以解决架构选择和权重初始化的挑战。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学影像领域取得了显著进展，但将深度学习模型应用于医学任务仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MedNNS框架，以优化架构选择和权重初始化，提高医学影像模型的效果。&lt;h4&gt;方法&lt;/h4&gt;MedNNS通过构建元空间来编码数据集和模型，使用基于Supernetwork的方法扩大模型库，并引入排名损失和FID损失以捕捉模型和数据集之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;MedNNS在多个数据集上显著优于ImageNet预训练的深度学习模型和SOTA的神经网络搜索方法，平均准确率提高了1.7%，且收敛速度更快。&lt;h4&gt;结论&lt;/h4&gt;MedNNS是医学影像领域首个神经网络搜索框架，有效解决了深度学习模型在医学任务中的应用挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：深度学习（DL）在医学影像领域取得了显著的进步。然而，将深度学习模型应用于医学任务仍然是一个重大挑战，主要由于两个关键因素：（1）架构选择，因为不同的任务需要专门的设计；（2）权重初始化，这直接影响模型的收敛速度和最终性能。尽管从ImageNet迁移学习是一种广泛采用的策略，但其有效性受到自然图像和医学图像之间巨大差异的限制。为了解决这些挑战，我们引入了Medical Neural Network Search（MedNNS），这是第一个用于医学影像应用的神经网络搜索框架。MedNNS通过构建一个元空间来联合优化架构选择和权重初始化，该空间基于数据集和模型如何一起表现来编码它们。我们使用基于Supernetwork的方法构建这个空间，将模型库的大小扩大了51倍，超过了以前的最先进（SOTA）方法。此外，我们将排名损失和FID损失引入到空间构建中，以捕捉模型间和数据集间的关系，从而在元空间中实现更精确的对齐。在多个数据集上的实验结果表明，MedNNS在性能上显著优于ImageNet预训练的深度学习模型和SOTA的神经网络搜索方法，在数据集上的平均准确率提高了1.7%，同时收敛速度大大加快。代码和处理的元空间可在https://github.com/BioMedIA-MBZUAI/MedNNS上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL) has achieved remarkable progress in the field of medicalimaging. However, adapting DL models to medical tasks remains a significantchallenge, primarily due to two key factors: (1) architecture selection, asdifferent tasks necessitate specialized model designs, and (2) weightinitialization, which directly impacts the convergence speed and finalperformance of the models. Although transfer learning from ImageNet is a widelyadopted strategy, its effectiveness is constrained by the substantialdifferences between natural and medical images. To address these challenges, weintroduce Medical Neural Network Search (MedNNS), the first Neural NetworkSearch framework for medical imaging applications. MedNNS jointly optimizesarchitecture selection and weight initialization by constructing a meta-spacethat encodes datasets and models based on how well they perform together. Webuild this space using a Supernetwork-based approach, expanding the model zoosize by 51x times over previous state-of-the-art (SOTA) methods. Moreover, weintroduce rank loss and Fr\'echet Inception Distance (FID) loss into theconstruction of the space to capture inter-model and inter-datasetrelationships, thereby achieving more accurate alignment in the meta-space.Experimental results across multiple datasets demonstrate that MedNNSsignificantly outperforms both ImageNet pre-trained DL models and SOTA NeuralArchitecture Search (NAS) methods, achieving an average accuracy improvement of1.7% across datasets while converging substantially faster. The code and theprocessed meta-space is available at https://github.com/BioMedIA-MBZUAI/MedNNS.</description>
      <author>example@mail.com (Lotfi Abdelkrim Mecharbat, Ibrahim Elmakky, Martin Takac, Mohammed Yaqub)</author>
      <guid isPermaLink="false">2504.15865v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning Dynamic Graphs via Tensorized and Lightweight Graph Convolutional Networks</title>
      <link>http://arxiv.org/abs/2504.15613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的动态图卷积网络（TLGCN）来准确学习动态图，该网络通过联合传播时空信息，并采用张量轻量级图卷积，显著减少了模型的内存占用。&lt;h4&gt;背景&lt;/h4&gt;动态图（DG）在许多实际场景中很常见，而动态图卷积网络（DGCN）在动态图上的精确表示学习方面取得了成功。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统DGCN中时空依赖性被分割的问题，提出了一种新的Tensorized Lightweight Graph Convolutional Network（TLGCN）。&lt;h4&gt;方法&lt;/h4&gt;该方法主要包括两个关键概念：a) 基于张量M-乘积框架设计了一种新的时空信息传播方法，用于联合传播时空信息；b) 提出了一种基于上述方法的张量轻量级图卷积网络，通过省略复杂的特征转换和非线性激活，显著减少了模型的内存占用。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的数值实验表明，所提出的TLGCN在动态图上的权重估计任务中优于最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;TLGCN在动态图学习方面具有更高的准确性和更低的内存占用，是一种有效的动态图卷积网络。&lt;h4&gt;翻译&lt;/h4&gt;A dynamic graph (DG) is frequently encountered in numerous real-world scenarios. Consequently, A dynamic graph convolutional network (DGCN) has been successfully applied to perform precise representation learning on a DG. However, conventional DGCNs typically consist of a static GCN coupled with a sequence neural network (SNN) to model spatial and temporal patterns separately. This decoupled modeling mechanism inherently disrupts the intricate spatio-temporal dependencies. To address the issue, this study proposes a novel Tensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamic graph learning. It mainly contains the following two key concepts: a) designing a novel spatio-temporal information propagation method for joint propagation of spatio-temporal information based on the tensor M-product framework; b) proposing a tensorized lightweight graph convolutional network based on the above method, which significantly reduces the memory occupation of the model by omitting complex feature transformation and nonlinear activation. Numericalexperiments on four real-world datasets demonstrate that the proposed TLGCN outperforms the state-of-the-art models in the weight estimation task on DGs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A dynamic graph (DG) is frequently encountered in numerous real-worldscenarios. Consequently, A dynamic graph convolutional network (DGCN) has beensuccessfully applied to perform precise representation learning on a DG.However, conventional DGCNs typically consist of a static GCN coupled with asequence neural network (SNN) to model spatial and temporal patternsseparately. This decoupled modeling mechanism inherently disrupts the intricatespatio-temporal dependencies. To address the issue, this study proposes a novelTensorized Lightweight Graph Convolutional Network (TLGCN) for accurate dynamicgraph learning. It mainly contains the following two key concepts: a) designinga novel spatio-temporal information propagation method for joint propagation ofspatio-temporal information based on the tensor M-product framework; b)proposing a tensorized lightweight graph convolutional network based on theabove method, which significantly reduces the memory occupation of the model byomitting complex feature transformation and nonlinear activation. Numericalexperiments on four real-world datasets demonstrate that the proposed TLGCNoutperforms the state-of-the-art models in the weight estimation task on DGs.</description>
      <author>example@mail.com (Minglian Han)</author>
      <guid isPermaLink="false">2504.15613v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Measuring Interest Group Positions on Legislation: An AI-Driven Analysis of Lobbying Reports</title>
      <link>http://arxiv.org/abs/2504.15333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了美国特殊利益集团（SIGs）在政治活动中的参与情况，包括游说和竞选捐款，以影响政策决策。通过大规模数据集和先进的人工智能框架，分析了SIGs的政策立场及其对全球问题的潜在影响。&lt;h4&gt;背景&lt;/h4&gt;SIGs在立法和行政部门中参与各种政治活动，其利益冲突对国际贸易政策、移民、气候变化和全球健康等全球性问题有深远影响。&lt;h4&gt;目的&lt;/h4&gt;直接测量和预测第111至117届国会期间提出的所有法案的立场（支持、反对、参与）。&lt;h4&gt;方法&lt;/h4&gt;使用包括大型语言模型（LLMs）和图神经网络（GNNs）在内的高级AI框架，开发了一个可扩展的流程，从游说活动中自动提取这些立场，并创建了一个包含42k法案和279k SIGs法案立场的数据库。&lt;h4&gt;主要发现&lt;/h4&gt;发现法案在立法过程中的进展与利益集团立场之间存在强烈相关性；公司规模与游说立场之间存在显著关系；根据法案主题，游说立场分布存在显著差异；以及政策偏好在不同行业中的分布存在异质性。&lt;h4&gt;结论&lt;/h4&gt;引入了新的框架来检查游说策略，并提供了探索利益集团如何塑造政治格局的机会。&lt;h4&gt;翻译&lt;/h4&gt;摘要：美国特殊利益集团（SIGs）参与各种政治活动，如游说和竞选捐款，以影响立法和行政部门的政策决策。这些SIGs的利益冲突对国际贸易政策、移民、气候变化和全球健康等全球性问题有深远影响。尽管理解SIGs政策立场的重要性不言而喻，但观察SIGs的实证挑战往往导致研究人员依赖于间接测量或专注于公开支持或反对有限范围立法的少数SIGs。本研究首次大规模地直接测量和预测了第111至117届国会期间提出的所有法案的立场——支持、反对、参与（修订和监控）。我们利用包括大型语言模型（LLMs）和图神经网络（GNNs）在内的高级AI框架，开发了一个可扩展的流程，从游说活动中自动提取这些立场，从而创建了一个包含42k法案和279k SIGs法案立场的数据库。利用这个大规模数据集，我们发现（i）法案在立法过程中的进展与利益集团立场之间存在强烈相关性；（ii）公司规模与游说立场之间存在显著关系；（iii）根据法案主题，游说立场分布存在显著差异；（iv）政策偏好在不同行业中的分布存在异质性。我们引入了一个新的框架来检查游说策略，并提供了探索利益集团如何塑造政治格局的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Special interest groups (SIGs) in the U.S. participate in a range ofpolitical activities, such as lobbying and making campaign donations, toinfluence policy decisions in the legislative and executive branches. Thecompeting interests of these SIGs have profound implications for global issuessuch as international trade policies, immigration, climate change, and globalhealth challenges. Despite the significance of understanding SIGs' policypositions, empirical challenges in observing them have often led researchers torely on indirect measurements or focus on a select few SIGs that publiclysupport or oppose a limited range of legislation. This study introduces thefirst large-scale effort to directly measure and predict a wide range of billpositions-Support, Oppose, Engage (Amend and Monitor)- across all legislativebills introduced from the 111th to the 117th Congresses. We leverage anadvanced AI framework, including large language models (LLMs) and graph neuralnetworks (GNNs), to develop a scalable pipeline that automatically extractsthese positions from lobbying activities, resulting in a dataset of 42k billsannotated with 279k bill positions of 12k SIGs. With this large-scale dataset,we reveal (i) a strong correlation between a bill's progression throughlegislative process stages and the positions taken by interest groups, (ii) asignificant relationship between firm size and lobbying positions, (iii)notable distinctions in lobbying position distribution based on bill subject,and (iv) heterogeneity in the distribution of policy preferences acrossindustries. We introduce a novel framework for examining lobbying strategiesand offer opportunities to explore how interest groups shape the politicallandscape.</description>
      <author>example@mail.com (Jiseon Kim, Dongkwan Kim, Joohye Jeong, Alice Oh, In Song Kim)</author>
      <guid isPermaLink="false">2504.15333v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for High-dimensional Reduced Rank Time Series Models</title>
      <link>http://arxiv.org/abs/2504.15691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages accepted by AISTATS2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间序列模型中的迁移学习，特别是在具有时间依赖性和复杂模型参数结构的高维向量自回归（VAR）模型中。&lt;h4&gt;背景&lt;/h4&gt;迁移学习旨在通过利用从其他数据源获得的知识来增强目标数据的估计和推理。尽管在复杂、高维模型中已经探索了迁移学习，但针对时间序列模型的研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;本文专注于对具有时间依赖性和复杂模型参数结构的序列观察数据应用迁移学习。&lt;h4&gt;方法&lt;/h4&gt;本文研究了VAR模型，该模型是一种广泛用于时间序列数据的标准模型。提出了一个针对具有低秩和稀疏结构的VAR模型估计的新迁移学习算法，并提出了从辅助数据集中选择信息观察的新方法。&lt;h4&gt;主要发现&lt;/h4&gt;建立了理论保证，包括模型参数一致性、信息集选择，以及估计量在温和条件下的渐近分布。这有助于构建模型参数的逐项置信区间。&lt;h4&gt;结论&lt;/h4&gt;通过模拟和真实世界数据集展示了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在研究时间序列模型中的迁移学习，特别是在具有时间依赖性和复杂模型参数结构的高维向量自回归（VAR）模型中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective of transfer learning is to enhance estimation and inference ina target data by leveraging knowledge gained from additional sources. Recentstudies have explored transfer learning for independent observations incomplex, high-dimensional models assuming sparsity, yet research on time seriesmodels remains limited. Our focus is on transfer learning for sequences ofobservations with temporal dependencies and a more intricate model parameterstructure. Specifically, we investigate the vector autoregressive model (VAR),a widely recognized model for time series data, where the transition matrix canbe deconstructed into a combination of a sparse matrix and a low-rank one. Wepropose a new transfer learning algorithm tailored for estimatinghigh-dimensional VAR models characterized by low-rank and sparse structures.Additionally, we present a novel approach for selecting informativeobservations from auxiliary datasets. Theoretical guarantees are established,encompassing model parameter consistency, informative set selection, and theasymptotic distribution of estimators under mild conditions. The latterfacilitates the construction of entry-wise confidence intervals for modelparameters. Finally, we demonstrate the empirical efficacy of our methodologiesthrough both simulated and real-world datasets.</description>
      <author>example@mail.com (Mingliang Ma Abolfazl Safikhani)</author>
      <guid isPermaLink="false">2504.15691v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Fourier analysis of the physics of transfer learning for data-driven subgrid-scale models of ocean turbulence</title>
      <link>http://arxiv.org/abs/2504.15487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了迁移学习（TL）在神经网络（NNs）性能提升中的应用，特别是在天气和气候预测以及湍流建模等领域。通过使用9层卷积神经网络预测二维海洋准地转系统的亚网格强迫，本文探讨了哪些指标最能描述其性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是一种强大的工具，可以增强神经网络在应用中的性能，尤其是在训练数据有限的情况下，它允许模型泛化到分布外数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在探讨如何使用迁移学习来提高神经网络在预测未知动态系统时的性能和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了一个9层的卷积神经网络来预测二维海洋准地转系统的亚网格强迫，并通过傅里叶分析来研究神经网络的滤波特性。他们还分析了激活频谱，以了解神经网络为何在没有迁移学习的情况下无法泛化，以及迁移学习如何克服这些限制。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，神经网络学习到的权重和偏差会低估分布外样本的频谱，导致输出频谱的低估。通过仅用目标系统的数据重新训练一个层，这种低估得到纠正，使得神经网络能够产生与目标频谱匹配的预测。&lt;h4&gt;结论&lt;/h4&gt;这些发现对于数据驱动的动态系统参数化具有广泛的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习（TL）是一种强大的工具，可以增强神经网络（NNs）在应用中的性能，特别是在天气和气候预测以及湍流建模等领域。它允许模型在仅从新系统获取少量训练数据的情况下，泛化到分布外数据。在本研究中，我们使用一个9层的卷积神经网络来预测二维海洋准地转系统的亚网格强迫，并检验哪些指标最能描述其性能和泛化能力。神经网络的核的傅里叶分析表明，无论训练数据是各向同性还是各向异性，它们都学会了低通、高斯和带通滤波器。通过分析激活频谱，我们确定了为什么神经网络在没有迁移学习的情况下无法泛化，以及迁移学习如何克服这些限制：从一个数据集学习到的权重和偏差低估了通过网络传递的分布外样本频谱，导致输出频谱的低估。通过仅用目标系统的数据重新训练一个层，这种低估得到纠正，使得神经网络能够产生与目标频谱匹配的预测。这些发现对于数据驱动的动态系统参数化具有广泛的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning (TL) is a powerful tool for enhancing the performance ofneural networks (NNs) in applications such as weather and climate predictionand turbulence modeling. TL enables models to generalize to out-of-distributiondata with minimal training data from the new system. In this study, we employ a9-layer convolutional NN to predict the subgrid forcing in a two-layer oceanquasi-geostrophic system and examine which metrics best describe itsperformance and generalizability to unseen dynamical regimes. Fourier analysisof the NN kernels reveals that they learn low-pass, Gabor, and high-passfilters, regardless of whether the training data are isotropic or anisotropic.By analyzing the activation spectra, we identify why NNs fail to generalizewithout TL and how TL can overcome these limitations: the learned weights andbiases from one dataset underestimate the out-of-distribution sample spectra asthey pass through the network, leading to an underestimation of output spectra.By re-training only one layer with data from the target system, thisunderestimation is corrected, enabling the NN to produce predictions that matchthe target spectra. These findings are broadly applicable to data-drivenparameterization of dynamical systems.</description>
      <author>example@mail.com (Moein Darman, Pedram Hassanzadeh, Laure Zanna, Ashesh Chattopadhyay)</author>
      <guid isPermaLink="false">2504.15487v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification</title>
      <link>http://arxiv.org/abs/2504.15041v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的Lifelong Person Re-identification (LReID)模型，通过探索跨域共享表示学习和特定领域分布集成，解决了在保留旧知识的同时适应新信息的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;LReID面临在保留旧知识的同时适应新信息的挑战，现有方法包括基于复述和无复述的方法，但存在复述方法持续积累遗忘和无复述方法学习分布不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，旨在解决LReID中的遗忘问题，同时提高跨域共享表示学习和领域特定分布集成。&lt;h4&gt;方法&lt;/h4&gt;提出了Distribution-aware Forgetting Compensation (DAFC)模型，包括Text-driven Prompt Aggregation (TPA)和Distribution-based Awareness and Integration (DAI)。TPA利用文本特征丰富提示元素，指导模型学习细粒度表示；DAI通过专用专家网络捕获每个领域的特定分布，并将其适应性地整合到高维空间中的共享区域。此外，还开发了知识巩固机制(KCM)，包括实例级区分和跨域一致性对齐策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DAFC模型优于现有方法，能够有效解决LReID中的遗忘问题，并提高跨域共享表示学习和领域特定分布集成。&lt;h4&gt;结论&lt;/h4&gt;DAFC模型通过创新的跨域共享表示学习和领域特定分布集成方法，在LReID任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel Lifelong Person Re-identification (LReID) model that addresses the key challenge of preserving old knowledge while adapting to new information by exploring cross-domain shared representation learning and domain-specific distribution integration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LiuShiBen/DAFC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong Person Re-identification (LReID) suffers from a key challenge inpreserving old knowledge while adapting to new information. The existingsolutions include rehearsal-based and rehearsal-free methods to address thischallenge. Rehearsal-based approaches rely on knowledge distillation,continuously accumulating forgetting during the distillation process.Rehearsal-free methods insufficiently learn the distribution of each domain,leading to forgetfulness over time. To solve these issues, we propose a novelDistribution-aware Forgetting Compensation (DAFC) model that explorescross-domain shared representation learning and domain-specific distributionintegration without using old exemplars or knowledge distillation. We propose aText-driven Prompt Aggregation (TPA) that utilizes text features to enrichprompt elements and guide the prompt model to learn fine-grainedrepresentations for each instance. This can enhance the differentiation ofidentity information and establish the foundation for domain distributionawareness. Then, Distribution-based Awareness and Integration (DAI) is designedto capture each domain-specific distribution by a dedicated expert network andadaptively consolidate them into a shared region in high-dimensional space. Inthis manner, DAI can consolidate and enhance cross-domain shared representationlearning while alleviating catastrophic forgetting. Furthermore, we develop aKnowledge Consolidation Mechanism (KCM) that comprises instance-leveldiscrimination and cross-domain consistency alignment strategies to facilitatemodel adaptive learning of new knowledge from the current domain and promoteknowledge consolidation learning between acquired domain-specificdistributions, respectively. Experimental results show that our DAFCoutperforms state-of-the-art methods. Our code is available athttps://github.com/LiuShiBen/DAFC.</description>
      <author>example@mail.com (Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2504.15041v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Learning of Reaction Pathways from Geometric Priors</title>
      <link>http://arxiv.org/abs/2504.15370v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures; Supporting Information in ancillary files&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MEPIN的机器学习方法，用于高效预测化学反应中的最小能量路径（MEPs），以理解化学反应机制。&lt;h4&gt;背景&lt;/h4&gt;识别MEPs对于理解化学反应机制至关重要，但目前这一任务在计算上非常耗时。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖过渡态几何或预先优化的反应路径的机器学习方法，以高效预测MEPs。&lt;h4&gt;方法&lt;/h4&gt;MEPIN方法基于对称破缺等变神经网络，该网络生成灵活数量的中间结构，并通过能量基础目标进行训练，同时结合几何先验作为初始插值或预训练目标，以提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在不同化学反应中具有普遍适用性，并在小分子反应和[3+2]环加成反应中实现了与参考内禀反应坐标的准确对齐。&lt;h4&gt;结论&lt;/h4&gt;该方法能够以高效、数据驱动的预测探索大型化学反应空间中的反应路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifying minimum-energy paths (MEPs) is crucial for understanding chemicalreaction mechanisms but remains computationally demanding. We introduce MEPIN,a scalable machine-learning method for efficiently predicting MEPs fromreactant and product configurations, without relying on transition-stategeometries or pre-optimized reaction paths during training. The task is definedas predicting deviations from geometric interpolations along reactioncoordinates. We address this task with a continuous reaction path model basedon a symmetry-broken equivariant neural network that generates a flexiblenumber of intermediate structures. The model is trained using an energy-basedobjective, with efficiency enhanced by incorporating geometric priors fromgeodesic interpolation as initial interpolations or pre-training objectives.Our approach generalizes across diverse chemical reactions and achievesaccurate alignment with reference intrinsic reaction coordinates, asdemonstrated on various small molecule reactions and [3+2] cycloadditions. Ourmethod enables the exploration of large chemical reaction spaces withefficient, data-driven predictions of reaction pathways.</description>
      <author>example@mail.com (Juno Nam, Miguel Steiner, Max Misterka, Soojung Yang, Avni Singhal, Rafael Gómez-Bombarelli)</author>
      <guid isPermaLink="false">2504.15370v1</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Histogram-based Parameter-efficient Tuning for Passive Sonar Classification</title>
      <link>http://arxiv.org/abs/2504.15214v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures. Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于直方图的参数高效调整（HPT）技术，用于改进参数高效的迁移学习（PETL）方法，以提高下游任务中的模型性能。&lt;h4&gt;背景&lt;/h4&gt;现有的PETL方法在适应下游任务时，往往难以捕捉到中间特征嵌入中的分布变化。&lt;h4&gt;目的&lt;/h4&gt;提出HPT技术，以捕获目标域的统计信息并调整嵌入，从而提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;HPT技术通过直方图方法来调整模型嵌入，使其更适应目标域。&lt;h4&gt;主要发现&lt;/h4&gt;在三个下游被动声纳数据集（ShipsEar、DeepShip、VTUAD）上的实验结果表明，HPT优于传统的适配器方法。在VTUAD数据集上，HPT达到了91.8%的准确率，而传统适配器为89.8%。此外，HPT训练速度更快，且生成的特征表示更接近全微调模型。&lt;h4&gt;结论&lt;/h4&gt;HPT在参数节省和性能之间取得了平衡，为现有适配器提供了一种分布感知的替代方案，并为资源受限环境中的可扩展迁移学习指明了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;Parameter-efficient transfer learning (PETL) methods adapt large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods, such as adapters, sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a novel histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) methods adapt large artificialneural networks to downstream tasks without fine-tuning the entire model.However, existing additive methods, such as adapters, sometimes struggle tocapture distributional shifts in intermediate feature embeddings. We propose anovel histogram-based parameter-efficient tuning (HPT) technique that capturesthe statistics of the target domain and modulates the embeddings. Experimentalresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yieldsfeature representations closer to those of fully fine-tuned models. Overall,HPT balances parameter savings and performance, providing a distribution-awarealternative to existing adapters and shows a promising direction for scalabletransfer learning in resource-constrained environments. The code is publiclyavailable:https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.</description>
      <author>example@mail.com (Amirmohammad Mohammadi, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples)</author>
      <guid isPermaLink="false">2504.15214v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>HoLa: B-Rep Generation using a Holistic Latent Representation</title>
      <link>http://arxiv.org/abs/2504.14257v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM TOG and SIGGRAPH 2025 (Patent Protected); Project page:  https://vcc.tech/research/2025/HolaBrep&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的边界表示（B-Reps）方法，用于学习和生成计算机辅助设计（CAD）模型，该方法在整体潜在空间（HoLa）中统一了不同顺序的B-Reps原初的连续几何属性和它们的离散拓扑关系。&lt;h4&gt;背景&lt;/h4&gt;基于观察，两个表面的拓扑连接本质上与它们相交曲线的几何属性相关。&lt;h4&gt;目的&lt;/h4&gt;通过将拓扑学习在B-Reps中重新定义为欧几里得空间中的几何重建问题，减少生成的B-Reps原初之间的歧义、冗余和不一致性，同时降低训练复杂性。&lt;h4&gt;方法&lt;/h4&gt;通过神经网络交点网络学习区分和推导曲线几何，消除潜在空间中的曲线、顶点和所有拓扑连接。&lt;h4&gt;主要发现&lt;/h4&gt;该方法定义在表面上，但能够编码完整的B-Reps模型，包括表面的几何、曲线、顶点及其拓扑关系。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了生成B-Reps原初的有效性，达到82%，远超现有技术的50%左右。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新的表示方法，用于学习和生成计算机辅助设计（CAD）模型，其形式为边界表示（B-Reps）。我们的表示方法在整体潜在空间（HoLa）中统一了不同顺序的B-Reps原初的连续几何属性及其离散拓扑关系。这是基于一个简单的观察：两个表面的拓扑连接本质上与它们相交曲线的几何属性相关。这样的先验条件允许我们将B-Reps中的拓扑学习重新定义为欧几里得空间中的几何重建问题。具体来说，我们通过学习从一对表面原初推导曲线几何来消除潜在空间中的曲线、顶点和所有拓扑连接。为此，我们的整体潜在空间仅定义在表面上，但能够编码完整的B-Reps模型，包括表面的几何、曲线、顶点及其拓扑关系。我们的紧凑且整体潜在空间简化了基于扩散的第一代生成器的开发，该生成器可以处理包括点云、单/多视图图像、2D草图和文本提示在内的各种输入。我们的方法显著减少了生成的B-Reps原初之间的歧义、冗余和不一致性，以及先前多步B-Reps学习管道中固有的训练复杂性，同时实现了比现有技术大幅提高的有效性率：82%对约50%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel representation for learning and generatingComputer-Aided Design (CAD) models in the form of $\textit{boundaryrepresentations}$ (B-Reps). Our representation unifies the continuous geometricproperties of B-Rep primitives in different orders (e.g., surfaces and curves)and their discrete topological relations in a $\textit{holistic latent}$ (HoLa)space. This is based on the simple observation that the topological connectionbetween two surfaces is intrinsically tied to the geometry of theirintersecting curve. Such a prior allows us to reformulate topology learning inB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,we eliminate the presence of curves, vertices, and all the topologicalconnections in the latent space by learning to distinguish and derive curvegeometries from a pair of surface primitives via a neural intersection network.To this end, our holistic latent space is only defined on surfaces but encodesa full B-Rep model, including the geometry of surfaces, curves, vertices, andtheir topological relations. Our compact and holistic latent space facilitatesthe design of a first diffusion-based generator to take on a large variety ofinputs including point clouds, single/multi-view images, 2D sketches, and textprompts. Our method significantly reduces ambiguities, redundancies, andincoherences among the generated B-Rep primitives, as well as trainingcomplexities inherent in prior multi-step B-Rep learning pipelines, whileachieving greatly improved validity rate over current state of the art: 82% vs.$\approx$50%.</description>
      <author>example@mail.com (Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang)</author>
      <guid isPermaLink="false">2504.14257v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems</title>
      <link>http://arxiv.org/abs/2504.13768v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  permission not yet received for arXiv&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Equi-Euler GraphNet的物理信息图神经网络，用于多体动力学系统的实时建模，以实现工业中的数字孪生应用。该方法在预测内部载荷和系统轨迹方面表现优异，适用于故障检测和预测性维护。&lt;h4&gt;背景&lt;/h4&gt;准确的多体动力学系统建模对于实现数字孪生技术至关重要。现有数据驱动方法在系统动力学学习方面取得了进展，但联合预测内部载荷和系统轨迹仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时预测多体系统内部力和全局轨迹的模型，以支持故障检测、预测性维护、损伤预测和剩余寿命估计。&lt;h4&gt;方法&lt;/h4&gt;Equi-Euler GraphNet是一种基于物理信息的图神经网络，它使用节点表示系统组件，边编码交互。该模型引入了两种归纳偏差：等效消息传递方案和基于欧拉积分的时间感知迭代节点更新机制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在圆柱滚子轴承中解耦了环状动力学和滚动元件的约束运动。在高级多物理场模拟上训练后，Equi-Euler GraphNet在未见过的速度、载荷和配置下准确地预测了载荷和轨迹，超越了现有基于轨迹预测的GNN，并且具有更高的效率。&lt;h4&gt;结论&lt;/h4&gt;Equi-Euler GraphNet在保持高准确度的同时，实现了比传统求解器高达200倍的速度提升，是数字孪生、设计和维护领域的高效降阶模型。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads such as contact forces act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivalent message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate real-time modeling of multi-body dynamical systems is essential forenabling digital twin applications across industries. While many data-drivenapproaches aim to learn system dynamics, jointly predicting internal loads andsystem trajectories remains a key challenge. This dual prediction is especiallyimportant for fault detection and predictive maintenance, where internalloads-such as contact forces-act as early indicators of faults, reflecting wearor misalignment before affecting motion. These forces also serve as inputs todegradation models (e.g., crack growth), enabling damage prediction andremaining useful life estimation. We propose Equi-Euler GraphNet, aphysics-informed graph neural network (GNN) that simultaneously predictsinternal forces and global trajectories in multi-body systems. In thismesh-free framework, nodes represent system components and edges encodeinteractions. Equi-Euler GraphNet introduces two inductive biases: (1) anequivariant message-passing scheme, interpreting edge messages as interactionforces consistent under Euclidean transformations; and (2) a temporal-awareiterative node update mechanism, based on Euler integration, to captureinfluence of distant interactions over time. Tailored for cylindrical rollerbearings, it decouples ring dynamics from constrained motion of rollingelements. Trained on high-fidelity multiphysics simulations, Equi-EulerGraphNet generalizes beyond the training distribution, accurately predictingloads and trajectories under unseen speeds, loads, and configurations. Itoutperforms state-of-the-art GNNs focused on trajectory prediction, deliveringstable rollouts over thousands of time steps with minimal error accumulation.Achieving up to a 200x speedup over conventional solvers while maintainingcomparable accuracy, it serves as an efficient reduced-order model for digitaltwins, design, and maintenance.</description>
      <author>example@mail.com (Vinay Sharma, Rémi Tanguy Oddon, Pietro Tesini, Jens Ravesloot, Cees Taal, Olga Fink)</author>
      <guid isPermaLink="false">2504.13768v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration</title>
      <link>http://arxiv.org/abs/2504.11907v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, submitted to the 2025 IEEE/RSJ International  Conference on Intelligent Robots and Systems (IROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络探索贪婪策略和安全盾牌的新方法，以保障在杂乱环境中导航时的安全，并通过强化学习和近端策略优化算法来提高探索效率。&lt;h4&gt;背景&lt;/h4&gt;自主探索杂乱环境需要有效的探索策略，以防止与未知随机障碍物发生碰撞。&lt;h4&gt;目的&lt;/h4&gt;确保在杂乱环境中进行高效且安全的探索。&lt;h4&gt;方法&lt;/h4&gt;使用基于图神经网络的探索贪婪策略和安全盾牌，通过强化学习和近端策略优化算法进行网络训练。当策略选择不可行动作时，安全盾牌介入选择最佳可行替代方案。此外，提出了一种奖励函数，该函数包括基于代理与未探索区域接近程度的势场和到达这些区域预期的信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结合了强化学习驱动探索策略的适应性和显式安全机制提供的保证。&lt;h4&gt;结论&lt;/h4&gt;在模拟环境中的大量评估表明，该方法能够在杂乱环境中实现高效且安全的探索。&lt;h4&gt;翻译&lt;/h4&gt;Autonomous exploration of cluttered environments requires efficient exploration strategies that guarantee safety against potential collisions with unknown random obstacles. This paper presents a novel approach combining a graph neural network-based exploration greedy policy with a safety shield to ensure safe navigation goal selection. The network is trained using reinforcement learning and the proximal policy optimization algorithm to maximize exploration efficiency while reducing the safety shield interventions. However, if the policy selects an infeasible action, the safety shield intervenes to choose the best feasible alternative, ensuring system consistency. Moreover, this paper proposes a reward function that includes a potential field based on the agent's proximity to unexplored regions and the expected information gain from reaching them. Overall, the approach investigated in this paper merges the benefits of the adaptability of reinforcement learning-driven exploration policies and the guarantee ensured by explicit safety mechanisms. Extensive evaluations in simulated environments demonstrate that the approach enables efficient and safe exploration in cluttered environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration of cluttered environments requires efficientexploration strategies that guarantee safety against potential collisions withunknown random obstacles. This paper presents a novel approach combining agraph neural network-based exploration greedy policy with a safety shield toensure safe navigation goal selection. The network is trained usingreinforcement learning and the proximal policy optimization algorithm tomaximize exploration efficiency while reducing the safety shield interventions.However, if the policy selects an infeasible action, the safety shieldintervenes to choose the best feasible alternative, ensuring systemconsistency. Moreover, this paper proposes a reward function that includes apotential field based on the agent's proximity to unexplored regions and theexpected information gain from reaching them. Overall, the approachinvestigated in this paper merges the benefits of the adaptability ofreinforcement learning-driven exploration policies and the guarantee ensured byexplicit safety mechanisms. Extensive evaluations in simulated environmentsdemonstrate that the approach enables efficient and safe exploration incluttered environments.</description>
      <author>example@mail.com (Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2504.11907v2</guid>
      <pubDate>Wed, 23 Apr 2025 14:13:18 +0800</pubDate>
    </item>
    <item>
      <title>3D-PointZshotS: Geometry-Aware 3D Point Cloud Zero-Shot Semantic Segmentation Narrowing the Visual-Semantic Gap</title>
      <link>http://arxiv.org/abs/2504.12442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为3D-PointZshotS的几何感知零样本3D点云分割框架，旨在解决现有方法在从已见类别到未见类别以及从语义到视觉空间的迁移性方面的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的零样本3D点云分割方法在将特征从已见类别迁移到未见类别，以及从语义空间到视觉空间的对齐方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出3D-PointZshotS框架，以增强特征生成和对齐，使用潜在的几何原型（LGPs）。&lt;h4&gt;方法&lt;/h4&gt;通过交叉注意力机制将LGPs集成到生成器中，丰富语义特征以包含精细的几何细节。引入自一致性损失，增强特征对点扰动的不变性。此外，在共享空间中重新表示视觉和语义特征，以弥合语义-视觉差距并促进知识迁移到未见类别。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet、SemanticKITTI和S3DIS三个真实世界数据集上的实验表明，该方法在和谐mIoU方面优于四个基线。&lt;h4&gt;结论&lt;/h4&gt;3D-PointZshotS在3D点云分割任务中取得了优异的性能，并且代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a geometric-aware zero-shot 3D point cloud segmentation framework named 3D-PointZshotS, aiming to address the difficulties of existing methods in transferring features from seen classes to unseen classes and aligning from semantic to visual space. The 3D-PointZshotS framework is proposed to enhance feature generation and alignment using latent geometric prototypes (LGPs). Specifically, LGPs are integrated into a generator via a cross-attention mechanism to enrich semantic features with fine-grained geometric details. To further enhance stability and generalization, a self-consistency loss is introduced to enforce feature robustness against point-wise perturbations. Additionally, visual and semantic features are re-represented in a shared space to bridge the semantic-visual gap and facilitate knowledge transfer to unseen classes. Experiments on three real-world datasets, namely ScanNet, SemanticKITTI, and S3DIS, demonstrate that the proposed method achieves superior performance over four baselines in terms of harmonic mIoU. The code is available at Github.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing zero-shot 3D point cloud segmentation methods often struggle withlimited transferability from seen classes to unseen classes and from semanticto visual space. To alleviate this, we introduce 3D-PointZshotS, ageometry-aware zero-shot segmentation framework that enhances both featuregeneration and alignment using latent geometric prototypes (LGPs).Specifically, we integrate LGPs into a generator via a cross-attentionmechanism, enriching semantic features with fine-grained geometric details. Tofurther enhance stability and generalization, we introduce a self-consistencyloss, which enforces feature robustness against point-wise perturbations.Additionally, we re-represent visual and semantic features in a shared space,bridging the semantic-visual gap and facilitating knowledge transfer to unseenclasses. Experiments on three real-world datasets, namely ScanNet,SemanticKITTI, and S3DIS, demonstrate that our method achieves superiorperformance over four baselines in terms of harmonic mIoU. The code isavailable at \href{https://github.com/LexieYang/3D-PointZshotS}{Github}.</description>
      <author>example@mail.com (Minmin Yang, Huantao Ren, Senem Velipasalar)</author>
      <guid isPermaLink="false">2504.12442v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
  <item>
      <title>The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman Problem with Drone and Neural Acceleration</title>
      <link>http://arxiv.org/abs/2504.15147v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了迭代链式分割（ICP）算法及其用于解决无人机旅行商问题（TSP-D）的神经网络加速方法。&lt;h4&gt;背景&lt;/h4&gt;研究背景是旅行商问题（TSP）及其在无人机配送中的应用。&lt;h4&gt;目的&lt;/h4&gt;研究目的是提出一种新的算法来优化无人机配送路径。&lt;h4&gt;方法&lt;/h4&gt;提出的ICP算法将TSP-D解决方案分解为更小的链式片段，每个片段通过动态规划子程序单独优化。通过迭代更新改进最大的链式片段，直到不再可能进一步改进。算法的子程序调用次数与问题规模线性相关，保证了算法的可扩展性。为了减少子程序调用的必要性，引入了图神经网络（GNN）来预测增量改进。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ICP在解决方案质量和计算时间上优于现有算法。在1059个基准实例上测试，ICP在解决方案质量上平均提高了2.75%，同时将计算时间减少了79.8%。神经网络加速后的Neuro ICP（NICP）在保持解决方案质量的同时，将总计算时间减少了49.7%，目标函数值增加仅限于0.12%。&lt;h4&gt;结论&lt;/h4&gt;该框架适应性强，是开发高效的卡车-无人机同步路由算法的有价值基础。&lt;h4&gt;翻译&lt;/h4&gt;This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine. The chainlet with the highest improvement is updated and the procedure is repeated until no further improvement is possible. The number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability. Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time. Tested over 1,059 benchmark instances, ICP yields an average improvement of 2.75% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 79.8%. The procedure is deterministic, ensuring reliability without requiring multiple runs. The subroutine is the computational bottleneck in the already efficient ICP algorithm. To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements. We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality. Compared to ICP, NICP reduces the total computational time by 49.7%, while the objective function value increase is limited to 0.12%. The framework's adaptability to various operational constraints makes it a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces the Iterative Chainlet Partitioning (ICP) algorithm andits neural acceleration for solving the Traveling Salesman Problem with Drone(TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smallersegments called chainlets, each optimized individually by a dynamic programmingsubroutine. The chainlet with the highest improvement is updated and theprocedure is repeated until no further improvement is possible. The number ofsubroutine calls is bounded linearly in problem size for the first iterationand remains constant in subsequent iterations, ensuring algorithmicscalability. Empirical results show that ICP outperforms existing algorithms inboth solution quality and computational time. Tested over 1,059 benchmarkinstances, ICP yields an average improvement of 2.75% in solution quality overthe previous state-of-the-art algorithm while reducing computational time by79.8%. The procedure is deterministic, ensuring reliability without requiringmultiple runs. The subroutine is the computational bottleneck in the alreadyefficient ICP algorithm. To reduce the necessity of subroutine calls, weintegrate a graph neural network (GNN) to predict incremental improvements. Wedemonstrate that the resulting Neuro ICP (NICP) achieves substantialacceleration while maintaining solution quality. Compared to ICP, NICP reducesthe total computational time by 49.7%, while the objective function valueincrease is limited to 0.12%. The framework's adaptability to variousoperational constraints makes it a valuable foundation for developing efficientalgorithms for truck-drone synchronized routing problems.</description>
      <author>example@mail.com (Jae Hyeok Lee, Minjun Kim, Jinkyoo Park, Changhyun Kwon)</author>
      <guid isPermaLink="false">2504.15147v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention</title>
      <link>http://arxiv.org/abs/2504.15075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE TNSE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为 DegFairGT 的图神经网络（GNN）改进方法，旨在通过学习非相邻节点的结构相似性来缓解图中的度偏见问题，并提高了节点分类和聚类任务的性能。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的图往往存在长尾度的分布，高度节点在信息传递中占据主导地位，导致低度节点代表性不足。&lt;h4&gt;目的&lt;/h4&gt;解决图中的度偏见问题，使得低度节点得到更充分的表示。&lt;h4&gt;方法&lt;/h4&gt;提出 DegFairGT，通过学习性结构增强和结构自注意力机制发现非相邻节点间的结构相似性，利用结构自注意力来捕捉节点对之间的相似性，并设计了一个自监督学习任务以保持全局图结构。&lt;h4&gt;主要发现&lt;/h4&gt; DegFairGT 在六个数据集上表现出优于现有基线的度公平性分析、节点分类和节点聚类任务性能。&lt;h4&gt;结论&lt;/h4&gt; DegFairGT 是一种有效的缓解图神经网络中度偏见问题的方法，能够提升图分析任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) update node representations through messagepassing, which is primarily based on the homophily principle, assuming thatadjacent nodes share similar features. However, in real-world graphs withlong-tailed degree distributions, high-degree nodes dominate message passing,causing a degree bias where low-degree nodes remain under-represented due toinadequate messages. The main challenge in addressing degree bias is how todiscover non-adjacent nodes to provide additional messages to low-degree nodeswhile reducing excessive messages for high-degree nodes. Nevertheless,exploiting non-adjacent nodes to provide valuable messages is challenging, asit could generate noisy information and disrupt the original graph structures.To solve it, we propose a novel Degree Fairness Graph Transformer, namedDegFairGT, to mitigate degree bias by discovering structural similaritiesbetween non-adjacent nodes through learnable structural augmentation andstructural self-attention. Our key idea is to exploit non-adjacent nodes withsimilar roles in the same community to generate informative edges under ouraugmentation, which could provide informative messages between nodes withsimilar roles while ensuring that the homophily principle is maintained withinthe community. To enable DegFairGT to learn such structural similarities, wethen propose a structural self-attention to capture the similarities betweennode pairs. To preserve global graph structures and prevent graph augmentationfrom hindering graph structure, we propose a Self-Supervised Learning task topreserve p-step transition probability and regularize graph augmentation.Extensive experiments on six datasets showed that DegFairGT outperformedstate-of-the-art baselines in degree fairness analysis, node classification,and node clustering tasks.</description>
      <author>example@mail.com (Van Thuy Hoang, Hyeon-Ju Jeon, O-Joun Lee)</author>
      <guid isPermaLink="false">2504.15075v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Survey of Loss Augmented Knowledge Tracing</title>
      <link>http://arxiv.org/abs/2504.15163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, no figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了使用高级损失函数训练的基于深度学习的知识追踪（DKT）算法，并讨论了其相较于先前技术的改进。&lt;h4&gt;背景&lt;/h4&gt;人工神经网络训练高度依赖于损失函数的精心选择，常见的损失函数如交叉熵和均方误差（MSE）虽然在广泛任务中通常足够，但数据质量问题或学习过程中的低效可能导致挑战。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过集成补充项到损失函数中解决这些挑战，并提高模型性能和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;分析了损失正则化和对比学习作为增强损失函数能力在人工神经网络中的有效策略，并讨论了对比知识追踪算法，如Bi-CLKT，CL4KT，SP-CLKT，CoSKT和预测一致DKT。&lt;h4&gt;主要发现&lt;/h4&gt;提供了性能基准，并探讨了实际部署中的挑战。&lt;h4&gt;结论&lt;/h4&gt;总结了未来研究方向，包括混合损失策略和上下文感知建模。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工神经网络训练高度依赖于适当损失函数的仔细选择。虽然常用的损失函数，如交叉熵和均方误差（MSE），通常适用于广泛的任务，但数据质量限制或学习过程中的低效往往导致挑战。在这种情况下，将补充项集成到损失函数中可以用来解决这些挑战，从而提高模型性能和鲁棒性。损失正则化和对比学习是两种已识别的有效策略，用于增强人工神经网络中损失函数的能力。知识追踪是一个引人注目的研究领域，它利用预测人工智能来促进个性化高效学习体验的自动化。在本文中，我们提供了一种基于深度学习的知识追踪（DKT）算法的全面回顾，讨论了它们相对于先前技术的改进。我们讨论了对比知识追踪算法，如Bi-CLKT，CL4KT，SP-CLKT，CoSKT和预测一致的DKT，提供了性能基准和实际部署挑战的见解。调查以未来研究方向总结，包括混合损失策略和上下文感知建模。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The training of artificial neural networks is heavily dependent on thecareful selection of an appropriate loss function. While commonly used lossfunctions, such as cross-entropy and mean squared error (MSE), generallysuffice for a broad range of tasks, challenges often emerge due to limitationsin data quality or inefficiencies within the learning process. In suchcircumstances, the integration of supplementary terms into the loss functioncan serve to address these challenges, enhancing both model performance androbustness. Two prominent techniques, loss regularization and contrastivelearning, have been identified as effective strategies for augmenting thecapacity of loss functions in artificial neural networks.  Knowledge tracing is a compelling area of research that leverages predictiveartificial intelligence to facilitate the automation of personalized andefficient educational experiences for students. In this paper, we provide acomprehensive review of the deep learning-based knowledge tracing (DKT)algorithms trained using advanced loss functions and discuss their improvementsover prior techniques. We discuss contrastive knowledge tracing algorithms,such as Bi-CLKT, CL4KT, SP-CLKT, CoSKT, and prediction-consistent DKT,providing performance benchmarks and insights into real-world deploymentchallenges. The survey concludes with future research directions, includinghybrid loss strategies and context-aware modeling.</description>
      <author>example@mail.com (Altun Shukurlu)</author>
      <guid isPermaLink="false">2504.15163v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots</title>
      <link>http://arxiv.org/abs/2504.14604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RoboOcc的3D占用预测方法，用于增强机器人对周围场景的几何和语义理解。&lt;h4&gt;背景&lt;/h4&gt;3D占用预测对于机器人的空间感知至关重要，但现有基于3D高斯的方法未能有效利用高斯的几何和透明度属性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改善机器人对复杂环境的估计和对场景的描述。&lt;h4&gt;方法&lt;/h4&gt;RoboOcc使用透明度引导的自编码器（OSE）来减轻重叠高斯的语义模糊性，以及几何感知的交叉编码器（GCE）来完成周围场景的精细几何建模。&lt;h4&gt;主要发现&lt;/h4&gt;在Occ-ScanNet和EmbodiedOcc-ScanNet数据集上进行的实验表明，RoboOcc在局部和全局相机设置中均取得了最先进的性能。在消融研究中，RoboOcc在IoU和mIoU指标上分别比最先进的方法高出8.47和6.27。&lt;h4&gt;结论&lt;/h4&gt;RoboOcc是一种有效的3D占用预测方法，能够显著提升机器人在复杂环境中的空间感知能力。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a 3D occupancy prediction method named RoboOcc, which enhances the geometric and semantic understanding of the surrounding scene for robots.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D occupancy prediction enables the robots to obtain spatial fine-grainedgeometry and semantics of the surrounding scene, and has become an essentialtask for embodied perception. Existing methods based on 3D Gaussians instead ofdense voxels do not effectively exploit the geometry and opacity properties ofGaussians, which limits the network's estimation of complex environments andalso limits the description of the scene by 3D Gaussians. In this paper, wepropose a 3D occupancy prediction method which enhances the geometric andsemantic scene understanding for robots, dubbed RoboOcc. It utilizes theOpacity-guided Self-Encoder (OSE) to alleviate the semantic ambiguity ofoverlapping Gaussians and the Geometry-aware Cross-Encoder (GCE) to accomplishthe fine-grained geometric modeling of the surrounding scene. We conductextensive experiments on Occ-ScanNet and EmbodiedOcc-ScanNet datasets, and ourRoboOcc achieves state-of the-art performance in both local and global camerasettings. Further, in ablation studies of Gaussian parameters, the proposedRoboOcc outperforms the state-of-the-art methods by a large margin of (8.47,6.27) in IoU and mIoU metric, respectively. The codes will be released soon.</description>
      <author>example@mail.com (Zhang Zhang, Qiang Zhang, Wei Cui, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang)</author>
      <guid isPermaLink="false">2504.14604v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models</title>
      <link>http://arxiv.org/abs/2504.15271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Eagle 2.5，这是一系列前沿视觉-语言模型（VLMs）用于长上下文多模态学习。Eagle 2.5在长视频理解和高分辨率图像理解方面解决了挑战，并提出了一个适用于这两个任务的通用框架。&lt;h4&gt;背景&lt;/h4&gt;在长视频理解和高分辨率图像理解方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个通用的框架来解决长视频理解和高分辨率图像理解的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个包含自动降采样和图像区域保持的技术框架，以保持上下文完整性和视觉细节。同时，在长上下文数据训练过程中，对流程进行了多个效率优化。此外，还提出了一个新的数据集Eagle-Video-110K，它集成了故事级别和剪辑级别的标注，以促进长视频理解。&lt;h4&gt;主要发现&lt;/h4&gt;Eagle 2.5在长上下文多模态基准测试中表现出显著改进，为现有VLMs的局限性提供了稳健的解决方案。最佳模型Eagle 2.5-8B在Video-MME上达到了72.4%的准确率，与顶级商业模型如GPT-4o以及大规模开源模型如Qwen2.5-VL-72B和InternVL2.5-78B相当。&lt;h4&gt;结论&lt;/h4&gt;Eagle 2.5为长视频理解和多模态学习提供了一个有效的解决方案，并在性能上达到了现有顶级模型的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Eagle 2.5, a family of frontier vision-language models (VLMs)for long-context multimodal learning. Our work addresses the challenges in longvideo comprehension and high-resolution image understanding, introducing ageneralist framework for both tasks. The proposed training frameworkincorporates Automatic Degrade Sampling and Image Area Preservation, twotechniques that preserve contextual integrity and visual details. The frameworkalso includes numerous efficiency optimizations in the pipeline forlong-context data training. Finally, we propose Eagle-Video-110K, a noveldataset that integrates both story-level and clip-level annotations,facilitating long-video understanding. Eagle 2.5 demonstrates substantialimprovements on long-context multimodal benchmarks, providing a robust solutionto the limitations of existing VLMs. Notably, our best model Eagle 2.5-8Bachieves 72.4% on Video-MME with 512 input frames, matching the results oftop-tier commercial model such as GPT-4o and large-scale open-source modelslike Qwen2.5-VL-72B and InternVL2.5-78B.</description>
      <author>example@mail.com (Guo Chen, Zhiqi Li, Shihao Wang, Jindong Jiang, Yicheng Liu, Lidong Lu, De-An Huang, Wonmin Byeon, Matthieu Le, Tuomas Rintamaki, Tyler Poon, Max Ehrlich, Tuomas Rintamaki, Tyler Poon, Tong Lu, Limin Wang, Bryan Catanzaro, Jan Kautz, Andrew Tao, Zhiding Yu, Guilin Liu)</author>
      <guid isPermaLink="false">2504.15271v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Robust and Real-time Surface Normal Estimation from Stereo Disparities using Affine Transformations</title>
      <link>http://arxiv.org/abs/2504.15121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种从校正立体图像对中估计表面法线的新方法，该方法利用从视差值导出的仿射变换以实现快速和准确的结果。&lt;h4&gt;背景&lt;/h4&gt;通过校正立体图像对简化表面法线估计过程，减少了计算复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种快速且准确的表面法线估计方法。&lt;h4&gt;方法&lt;/h4&gt;开发了一种受卷积操作启发的自定义算法，用于高效处理视差数据；引入了自适应启发式技术，以高效检测图像中的连接表面组件，进一步提高方法的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在GPU上实施时，在实时性能和准确性方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该方法能够生成密集且定向的点云作为最终输出，且在模拟环境和Middlebury、Cityscapes数据集的真实立体图像上得到验证。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种从校正立体图像对中估计表面法线的新方法，利用视差值导出的仿射变换以实现快速和准确的结果。通过校正立体图像对简化表面法线估计过程，减少了计算复杂性。为解决噪声问题，开发了一种受卷积操作启发的自定义算法，用于高效处理视差数据。同时，引入了自适应启发式技术，以高效检测图像中的连接表面组件，进一步提高方法的鲁棒性。通过整合这些方法，构建了一个既快速又准确的表面法线估计器，生成密集且定向的点云作为最终输出。该方法在GPU上实施时，在实时性能和准确性方面有显著提升。一旦被接受，将公开提供着色器源代码，以促进进一步研究和可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces a novel method for surface normal estimation fromrectified stereo image pairs, leveraging affine transformations derived fromdisparity values to achieve fast and accurate results. We demonstrate how therectification of stereo image pairs simplifies the process of surface normalestimation by reducing computational complexity. To address noise reduction, wedevelop a custom algorithm inspired by convolutional operations, tailored toprocess disparity data efficiently. We also introduce adaptive heuristictechniques for efficiently detecting connected surface components within theimages, further improving the robustness of the method. By integrating thesemethods, we construct a surface normal estimator that is both fast andaccurate, producing a dense, oriented point cloud as the final output. Ourmethod is validated using both simulated environments and real-world stereoimages from the Middlebury and Cityscapes datasets, demonstrating significantimprovements in real-time performance and accuracy when implemented on a GPU.Upon acceptance, the shader source code will be made publicly available tofacilitate further research and reproducibility.</description>
      <author>example@mail.com (Csongor Csanad Kariko, Muhammad Rafi Faisal, Levente Hajder)</author>
      <guid isPermaLink="false">2504.15121v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Visual Class-Incremental Learning for Fish Feeding intensity Assessment in Aquaculture</title>
      <link>http://arxiv.org/abs/2504.15171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的鱼料强度评估方法，并引入了音频-视觉类增量学习框架，以解决现有方法在适应新鱼种或环境时的局限性。&lt;h4&gt;背景&lt;/h4&gt;鱼料强度评估在工业水产养殖管理中至关重要，但现有的多模态方法在适应新鱼种或环境时面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在提高鱼料强度评估的鲁棒性和效率，并解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为AV-CIL-FFIA的新数据集，包含81,932个标签音频-视觉剪辑，覆盖了六种不同鱼种在水产养殖环境中的喂食强度。同时，引入了基于原型的新音频-视觉类增量学习框架HAIL-FFIA，该框架通过层次表示学习和双重路径知识保留机制来克服现有方法的限制。&lt;h4&gt;主要发现&lt;/h4&gt;HAIL-FFIA在AV-CIL-FFIA数据集上的表现优于现有方法，实现了更高的准确率，同时降低了存储需求并有效缓解了增量鱼种学习中的灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;HAIL-FFIA是一个有效的鱼料强度评估方法，能够提高水产养殖管理的效率和质量。&lt;h4&gt;翻译&lt;/h4&gt;Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculture management. Recent multi-modal approaches have shown promise in improving FFIA robustness and efficiency. However, these methods face significant challenges when adapting to new fish species or environments due to catastrophic forgetting and the lack of suitable datasets. To address these limitations, we first introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelled audio-visual clips capturing feeding intensities across six different fish species in real aquaculture environments. Then, we pioneer audio-visual class incremental learning (CIL) for FFIA and demonstrate through benchmarking on AV-CIL-FFIA that it significantly outperforms single-modality methods. Existing CIL methods rely heavily on historical data. Exemplar-based approaches store raw samples, creating storage challenges, while exemplar-free methods avoid data storage but struggle to distinguish subtle feeding intensity variations across different fish species. To overcome these limitations, we introduce HAIL-FFIA, a novel audio-visual class-incremental learning framework that bridges this gap with a prototype-based approach that achieves exemplar-free efficiency while preserving essential knowledge through compact feature representations. Specifically, HAIL-FFIA employs hierarchical representation learning with a dual-path knowledge preservation mechanism that separates general intensity knowledge from fish-specific characteristics. Additionally, it features a dynamic modality balancing system that adaptively adjusts the importance of audio versus visual information based on feeding behaviours stages. Experimental results show that HAIL-FFIA is superior to SOTA methods on AV-CIL-FFIA, achieving higher accuracy with lower storage needs while effectively mitigating catastrophic forgetting in incremental fish species learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fish Feeding Intensity Assessment (FFIA) is crucial in industrial aquaculturemanagement. Recent multi-modal approaches have shown promise in improving FFIArobustness and efficiency. However, these methods face significant challengeswhen adapting to new fish species or environments due to catastrophicforgetting and the lack of suitable datasets. To address these limitations, wefirst introduce AV-CIL-FFIA, a new dataset comprising 81,932 labelledaudio-visual clips capturing feeding intensities across six different fishspecies in real aquaculture environments. Then, we pioneer audio-visual classincremental learning (CIL) for FFIA and demonstrate through benchmarking onAV-CIL-FFIA that it significantly outperforms single-modality methods. ExistingCIL methods rely heavily on historical data. Exemplar-based approaches storeraw samples, creating storage challenges, while exemplar-free methods avoiddata storage but struggle to distinguish subtle feeding intensity variationsacross different fish species. To overcome these limitations, we introduceHAIL-FFIA, a novel audio-visual class-incremental learning framework thatbridges this gap with a prototype-based approach that achieves exemplar-freeefficiency while preserving essential knowledge through compact featurerepresentations. Specifically, HAIL-FFIA employs hierarchical representationlearning with a dual-path knowledge preservation mechanism that separatesgeneral intensity knowledge from fish-specific characteristics. Additionally,it features a dynamic modality balancing system that adaptively adjusts theimportance of audio versus visual information based on feeding behaviourstages. Experimental results show that HAIL-FFIA is superior to SOTA methods onAV-CIL-FFIA, achieving higher accuracy with lower storage needs whileeffectively mitigating catastrophic forgetting in incremental fish specieslearning.</description>
      <author>example@mail.com (Meng Cui, Xianghu Yue, Xinyuan Qian, Jinzheng Zhao, Haohe Liu, Xubo Liu, Daoliang Li, Wenwu Wang)</author>
      <guid isPermaLink="false">2504.15171v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Histogram-based Parameter-efficient Tuning for Passive Sonar Classification</title>
      <link>http://arxiv.org/abs/2504.15214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures. Submitted to IEEE WASPAA 2025 for possible  publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于直方图的参数高效调整（HPT）技术，用于适应下游任务，在参数高效迁移学习（PETL）方面优于传统的适配器方法。&lt;h4&gt;背景&lt;/h4&gt;现有的PETL方法，如适配器，在处理中间特征嵌入的分布变化时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HPT技术，以捕捉目标域的统计信息并调整嵌入。&lt;h4&gt;方法&lt;/h4&gt;在三个下游被动声纳数据集（ShipsEar、DeepShip、VTUAD）上进行了实验，以验证HPT方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;HPT在VTUAD数据集上实现了91.8%的准确率，优于传统的适配器（89.8%）。HPT训练速度更快，生成的特征表示更接近全微调模型。&lt;h4&gt;结论&lt;/h4&gt;HPT在参数节省和性能之间取得了平衡，为现有适配器提供了一个分布感知的替代方案，并为资源受限环境中的可扩展迁移学习提供了一个有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel histogram-based parameter-efficient tuning (HPT) technique for adapting large artificial neural networks to downstream tasks without fine-tuning the entire model. However, existing additive methods such as adapters sometimes struggle to capture distributional shifts in intermediate feature embeddings. We propose a new histogram-based parameter-efficient tuning (HPT) technique that captures the statistics of the target domain and modulates the embeddings. Experimental results on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD) demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves 91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yields feature representations closer to those of fully fine-tuned models. Overall, HPT balances parameter savings and performance, providing a distribution-aware alternative to existing adapters and shows a promising direction for scalable transfer learning in resource-constrained environments. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) methods adapt large artificialneural networks to downstream tasks without fine-tuning the entire model.However, existing additive methods, such as adapters, sometimes struggle tocapture distributional shifts in intermediate feature embeddings. We propose anovel histogram-based parameter-efficient tuning (HPT) technique that capturesthe statistics of the target domain and modulates the embeddings. Experimentalresults on three downstream passive sonar datasets (ShipsEar, DeepShip, VTUAD)demonstrate that HPT outperforms conventional adapters. Notably, HPT achieves91.8% vs. 89.8% accuracy on VTUAD. Furthermore, HPT trains faster and yieldsfeature representations closer to those of fully fine-tuned models. Overall,HPT balances parameter savings and performance, providing a distribution-awarealternative to existing adapters and shows a promising direction for scalabletransfer learning in resource-constrained environments. The code is publiclyavailable:https://github.com/Advanced-Vision-and-Learning-Lab/HLAST_DeepShip_ParameterEfficient.</description>
      <author>example@mail.com (Amirmohammad Mohammadi, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples)</author>
      <guid isPermaLink="false">2504.15214v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking</title>
      <link>http://arxiv.org/abs/2504.15135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGIR 2025 (Short)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为KGMEL的新型实体链接框架，该框架利用知识图谱（KG）三元组来增强多模态实体链接（MEL）的准确性。&lt;h4&gt;背景&lt;/h4&gt;实体链接（EL）将文本提及与知识库中的对应实体对齐，有助于语义搜索和问答等应用。多模态实体链接（MEL）结合文本和图像可以减少歧义并提高对齐精度，但现有方法往往忽略了知识图谱（KG）三元组中的丰富结构信息。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用知识图谱（KG）三元组来提高多模态实体链接（MEL）的准确性。&lt;h4&gt;方法&lt;/h4&gt;KGMEL框架分为三个阶段：生成高质量的三元组、通过对比学习学习联合提及-实体表示以及重新排序候选实体的KG三元组，并使用大型语言模型识别最佳匹配的实体。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，KGMEL优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;KGMEL框架能够有效地利用知识图谱（KG）三元组来提高多模态实体链接（MEL）的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code and datasets are available at: https://github.com/juyeonnn/KGMEL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3730217&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/juyeonnn/kgmel&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Entity linking (EL) aligns textual mentions with their corresponding entitiesin a knowledge base, facilitating various applications such as semantic searchand question answering. Recent advances in multimodal entity linking (MEL) haveshown that combining text and images can reduce ambiguity and improve alignmentaccuracy. However, most existing MEL methods overlook the rich structuralinformation available in the form of knowledge-graph (KG) triples. In thispaper, we propose KGMEL, a novel framework that leverages KG triples to enhanceMEL. Specifically, it operates in three stages: (1) Generation: Produceshigh-quality triples for each mention by employing vision-language models basedon its text and images. (2) Retrieval: Learns joint mention-entityrepresentations, via contrastive learning, that integrate text, images, and(generated or KG) triples to retrieve candidate entities for each mention. (3)Reranking: Refines the KG triples of the candidate entities and employs largelanguage models to identify the best-matching entity for the mention. Extensiveexperiments on benchmark datasets demonstrate that KGMEL outperforms existingmethods. Our code and datasets are available at:https://github.com/juyeonnn/KGMEL.</description>
      <author>example@mail.com (Juyeon Kim, Geon Lee, Taeuk Kim, Kijung Shin)</author>
      <guid isPermaLink="false">2504.15135v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Rhythm of Opinion: A Hawkes-Graph Framework for Dynamic Propagation Analysis</title>
      <link>http://arxiv.org/abs/2504.15072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多维Hawkes过程和图神经网络的方法，用于模拟社交网络中意见传播的动态，同时考虑评论之间的复杂层级关系。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的快速发展改变了公众意见的动态，传统的模型无法有效捕捉这些复杂的互动。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了一种新的方法来模拟和解释公众意见的传播。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了多维Hawkes过程和图神经网络，同时引入了一个新的数据集VISTA，该数据集包含了不同领域的热点话题及其对应的评论。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够捕捉到意见传播的多维性和层级结构，并通过VISTA数据集提供了对情感传播和评论层级关系的深入理解。&lt;h4&gt;结论&lt;/h4&gt;该方法为未来的研究提供了一个稳健的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着社交媒体的快速发展，公众意见的动态发生了显著变化，导致传统模型无法有效捕捉的复杂互动。为了应对这一挑战，我们提出了一种创新的方法，该方法结合了多维Hawkes过程和图神经网络，用于模拟社交网络中节点之间的意见传播动态，同时考虑评论之间的复杂层级关系。扩展的多维Hawkes过程能够捕捉到层级结构、多维交互以及不同主题之间的相互影响，形成一个复杂的传播网络。此外，鉴于缺乏能够全面捕捉公众意见动态演变的高质量数据集，我们引入了一个新的数据集VISTA。它包括159个热点话题，对应47,207篇帖子，327,015条二级评论和29,578条三级评论，涵盖了政治、娱乐、体育、健康和医学等多个领域。该数据集在11个类别中标注了详细的情感标签，并清晰地定义了层级关系。当与我们的方法结合时，它通过将情感传播与评论层级和时间演变联系起来，提供了强大的可解释性。我们的方法为未来的研究提供了一个稳健的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of social media has significantly reshaped the dynamicsof public opinion, resulting in complex interactions that traditional modelsfail to effectively capture. To address this challenge, we propose aninnovative approach that integrates multi-dimensional Hawkes processes withGraph Neural Network, modeling opinion propagation dynamics among nodes in asocial network while considering the intricate hierarchical relationshipsbetween comments. The extended multi-dimensional Hawkes process captures thehierarchical structure, multi-dimensional interactions, and mutual influencesacross different topics, forming a complex propagation network. Moreover,recognizing the lack of high-quality datasets capable of comprehensivelycapturing the evolution of public opinion dynamics, we introduce a new dataset,VISTA. It includes 159 trending topics, corresponding to 47,207 posts, 327,015second-level comments, and 29,578 third-level comments, covering diversedomains such as politics, entertainment, sports, health, and medicine. Thedataset is annotated with detailed sentiment labels across 11 categories andclearly defined hierarchical relationships. When combined with our method, itoffers strong interpretability by linking sentiment propagation to the commenthierarchy and temporal evolution. Our approach provides a robust baseline forfuture research.</description>
      <author>example@mail.com (Yulong Li, Zhixiang Lu, Feilong Tang, Simin Lai, Ming Hu, Yuxuan Zhang, Haochen Xue, Zhaodong Wu, Imran Razzak, Qingxia Li, Jionglong Su)</author>
      <guid isPermaLink="false">2504.15072v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Are Vision LLMs Road-Ready? A Comprehensive Benchmark for Safety-Critical Driving Video Understanding</title>
      <link>http://arxiv.org/abs/2504.14526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了VLLMs在视觉任务中的表现，特别关注其在自动驾驶等安全关键领域的应用，提出了DVBench基准来评估VLLMs在理解安全关键驾驶视频方面的能力。&lt;h4&gt;背景&lt;/h4&gt;VLLMs在通用视觉任务中表现出色，但在安全关键领域如自动驾驶中的应用效果尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;开发DVBench基准，以评估VLLMs在理解安全关键驾驶视频方面的性能。&lt;h4&gt;方法&lt;/h4&gt;DVBench基于层次化的能力分类法，包含10,000道多选题，并提供人工标注的答案，用于全面评估VLLMs的感知和推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，14个SOTA VLLMs在DVBench上的表现存在显著差异，没有模型准确率超过40%，揭示了在理解复杂驾驶场景方面的关键局限性。通过在DVBench特定数据上微调模型，准确率提高了5.24到10.94个百分点，相对改进达到43.59%。&lt;h4&gt;结论&lt;/h4&gt;DVBench为开发满足实际自动驾驶系统安全性和鲁棒性要求的VLLMs提供了必要的评估框架和研究路线图。&lt;h4&gt;翻译&lt;/h4&gt;Vision Large Language Models (VLLMs) have demonstrated impressive capabilities in general visual tasks such as image captioning and visual question answering. However, their effectiveness in specialized, safety-critical domains like autonomous driving remains largely unexplored. Autonomous driving systems require sophisticated scene understanding in complex environments, yet existing multimodal benchmarks primarily focus on normal driving conditions, failing to adequately assess VLLMs' performance in safety-critical scenarios. To address this, we introduce DVBench, a pioneering benchmark designed to evaluate the performance of VLLMs in understanding safety-critical driving videos. Built around a hierarchical ability taxonomy that aligns with widely adopted frameworks for describing driving scenarios used in assessing highly automated driving systems, DVBench features 10,000 multiple-choice questions with human-annotated ground-truth answers, enabling a comprehensive evaluation of VLLMs' capabilities in perception and reasoning. Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, reveal significant performance gaps, with no model achieving over 40% accuracy, highlighting critical limitations in understanding complex driving scenarios. To probe adaptability, we fine-tuned selected models using domain-specific data from DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentage points, with relative improvements of up to 43.59%. This improvement underscores the necessity of targeted adaptation to bridge the gap between general-purpose VLLMs and mission-critical driving applications. DVBench establishes an essential evaluation framework and research roadmap for developing VLLMs that meet the safety and robustness requirements for real-world autonomous systems. We released the benchmark toolbox and the fine-tuned model at: https://github.com/tong-zeng/DVBench.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tong-zeng/dvbench&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Large Language Models (VLLMs) have demonstrated impressivecapabilities in general visual tasks such as image captioning and visualquestion answering. However, their effectiveness in specialized,safety-critical domains like autonomous driving remains largely unexplored.Autonomous driving systems require sophisticated scene understanding in complexenvironments, yet existing multimodal benchmarks primarily focus on normaldriving conditions, failing to adequately assess VLLMs' performance insafety-critical scenarios. To address this, we introduce DVBench, a pioneeringbenchmark designed to evaluate the performance of VLLMs in understandingsafety-critical driving videos. Built around a hierarchical ability taxonomythat aligns with widely adopted frameworks for describing driving scenariosused in assessing highly automated driving systems, DVBench features 10,000multiple-choice questions with human-annotated ground-truth answers, enabling acomprehensive evaluation of VLLMs' capabilities in perception and reasoning.Experiments on 14 SOTA VLLMs, ranging from 0.5B to 72B parameters, revealsignificant performance gaps, with no model achieving over 40% accuracy,highlighting critical limitations in understanding complex driving scenarios.To probe adaptability, we fine-tuned selected models using domain-specific datafrom DVBench, achieving accuracy gains ranging from 5.24 to 10.94 percentagepoints, with relative improvements of up to 43.59%. This improvementunderscores the necessity of targeted adaptation to bridge the gap betweengeneral-purpose VLLMs and mission-critical driving applications. DVBenchestablishes an essential evaluation framework and research roadmap fordeveloping VLLMs that meet the safety and robustness requirements forreal-world autonomous systems. We released the benchmark toolbox and thefine-tuned model at: https://github.com/tong-zeng/DVBench.git.</description>
      <author>example@mail.com (Tong Zeng, Longfeng Wu, Liang Shi, Dawei Zhou, Feng Guo)</author>
      <guid isPermaLink="false">2504.14526v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>An LMM for Efficient Video Understanding via Reinforced Compression of Video Cubes</title>
      <link>http://arxiv.org/abs/2504.15270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quicksviewer的LMM，通过新的感知范式，将视频分割成不同密度的立方体，并统一对每个立方体进行重采样，以实现高效的视频理解。&lt;h4&gt;背景&lt;/h4&gt;大型多模态模型（LMMs）在处理具有不同时间信息密度的视频时存在计算效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在提高视频理解的效率，同时减少时空冗余。&lt;h4&gt;方法&lt;/h4&gt;使用Gumbel Softmax将视频分割成不同密度的立方体，并对每个立方体进行统一重采样，通过三个渐进阶段训练模型，每个阶段使用平均420秒/1fps的长时间视频。&lt;h4&gt;主要发现&lt;/h4&gt;Quicksviewer模型在训练时仅需0.8M个视频-文本样本，就能在Video-MME上达到SOTA性能，并且仅使用基准模型所需帧中5%的token。&lt;h4&gt;结论&lt;/h4&gt;Quicksviewer模型在性能上优于使用固定分割策略的基线模型，证明了其在视频理解中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents Quicksviewer, an LMM with a new perceiving paradigm that partitions a video of nonuniform density into varying cubes using Gumbel Softmax, followed by a unified resampling for each cube to achieve efficient video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Multimodal Models (LMMs) uniformly perceive video frames, creatingcomputational inefficiency for videos with inherently varying temporalinformation density. This paper present \textbf{Quicksviewer}, an LMM with newperceiving paradigm that partitions a video of nonuniform density into varyingcubes using Gumbel Softmax, followed by a unified resampling for each cube toachieve efficient video understanding. This simple and intuitive approachdynamically compress video online based on its temporal density, significantlyreducing spatiotemporal redundancy (overall 45$\times$ compression rate), whileenabling efficient training with large receptive field. We train the model froma language backbone through three progressive stages, each incorporatinglengthy videos on average of 420s/1fps thanks to the perceiving efficiency.With only 0.8M total video-text samples for training, our model outperforms thedirect baseline employing a fixed partitioning strategy by a maximum of 8.72 inaccuracy, demonstrating the effectiveness in performance. On Video-MME,Quicksviewer achieves SOTA under modest sequence lengths using just up to 5\%of tokens per frame required by baselines. With this paradigm, scaling up thenumber of input frames reveals a clear power law of the model capabilities. Itis also empirically verified that the segments generated by the cubing networkcan help for analyzing continuous events in videos.</description>
      <author>example@mail.com (Ji Qi, Yuan Yao, Yushi Bai, Bin Xu, Juanzi Li, Zhiyuan Liu, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2504.15270v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Is Intelligence the Right Direction in New OS Scheduling for Multiple Resources in Cloud Environments?</title>
      <link>http://arxiv.org/abs/2504.15021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 14 figures, to be published in ACM Transactions on Storage&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于机器学习的资源调度机制OSML+，用于协同定位云服务的系统/操作系统设计。&lt;h4&gt;背景&lt;/h4&gt;将智能引入系统/操作系统设计是一种有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;提高资源调度效率，实现更智能的资源管理。&lt;h4&gt;方法&lt;/h4&gt;OSML+通过多模型协作学习方式同时智能调度内存层次中的缓存和主内存带宽资源，以及计算核心资源。&lt;h4&gt;主要发现&lt;/h4&gt;OSML+能够处理复杂情况，如避免资源悬崖、在不同优先级的应用间共享资源、为不同优先级的应用启用不同的调度策略等。使用机器学习模型，OSML+能够比以往研究更快地收敛。此外，OSML+可以自动动态学习并相应地处理动态变化的工作负载。通过迁移学习技术，证明了该设计在包括最新市售大规模服务器在内的各种云服务器上均能良好工作。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，OSML+支持比以往研究更高的负载，并且具有更低的开销，同时达到了QoS目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Making it intelligent is a promising way in System/OS design. This paperproposes OSML+, a new ML-based resource scheduling mechanism for co-locatedcloud services. OSML+ intelligently schedules the cache and main memorybandwidth resources at the memory hierarchy and the computing core resourcessimultaneously. OSML+ uses a multi-model collaborative learning approach duringits scheduling and thus can handle complicated cases, e.g., avoiding resourcecliffs, sharing resources among applications, enabling different schedulingpolicies for applications with different priorities, etc. OSML+ can convergefaster using ML models than previous studies. Moreover, OSML+ can automaticallylearn on the fly and handle dynamically changing workloads accordingly. Usingtransfer learning technologies, we show our design can work well across variouscloud servers, including the latest off-the-shelf large-scale servers. Ourexperimental results show that OSML+ supports higher loads and meets QoStargets with lower overheads than previous studies.</description>
      <author>example@mail.com (Xinglei Dou, Lei Liu, Limin Xiao)</author>
      <guid isPermaLink="false">2504.15021v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Uni3C: Unifying Precisely 3D-Enhanced Camera and Human Motion Controls for Video Generation</title>
      <link>http://arxiv.org/abs/2504.14899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://github.com/ewrfcas/Uni3C&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uni3C的统一3D增强框架，用于在视频生成中精确控制相机和人类运动，以解决现有方法通常分别处理相机和人类运动控制，且数据标注有限的问题。&lt;h4&gt;背景&lt;/h4&gt;相机和人类运动控制已被广泛研究，但现有方法通常分别处理它们，导致高质量标注的数据有限。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提出一种能够统一控制视频生成中相机和人类运动的框架。&lt;h4&gt;方法&lt;/h4&gt;Uni3C包括两个主要贡献：一是提出了一种名为PCDController的即插即用控制模块，利用单目深度图的不投影点云进行精确的相机控制；二是提出了一个联合对齐的3D世界引导，无缝集成场景点云和SMPL-X角色，以统一相机和人类运动的控制信号。&lt;h4&gt;主要发现&lt;/h4&gt;PCDController在驱动相机运动方面表现出强大的鲁棒性，无论推理骨干是冻结还是微调。Uni3C在相机可控性和人类运动质量方面显著优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;Uni3C通过收集具有挑战性相机运动和人类动作的定制验证集，验证了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Camera and human motion controls have been extensively studied for video generation, but existing approaches typically address them separately, suffering from limited data with high-quality annotations for both aspects. To overcome this, we present Uni3C, a unified 3D-enhanced framework for precise control of both camera and human motion in video generation. Uni3C includes two key contributions. First, we propose a plug-and-play control module trained with a frozen video generative backbone, PCDController, which utilizes unprojected point clouds from monocular depth to achieve accurate camera control. By leveraging the strong 3D priors of point clouds and the powerful capacities of video foundational models, PCDController shows impressive generalization, performing well regardless of whether the inference backbone is frozen or fine-tuned. This flexibility enables different modules of Uni3C to be trained in specific domains, i.e., either camera control or human motion control, reducing the dependency on jointly annotated data. Second, we propose a jointly aligned 3D world guidance for the inference phase that seamlessly integrates both scenic point clouds and SMPL-X characters to unify the control signals for camera and human motion, respectively. Extensive experiments confirm that PCDController enjoys strong robustness in driving camera motion for fine-tuned backbones of video generation. Uni3C substantially outperforms competitors in both camera controllability and human motion quality. Additionally, we collect tailored validation sets featuring challenging camera movements and human actions to validate the effectiveness of our method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ewrfcas/uni3c&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Camera and human motion controls have been extensively studied for videogeneration, but existing approaches typically address them separately,suffering from limited data with high-quality annotations for both aspects. Toovercome this, we present Uni3C, a unified 3D-enhanced framework for precisecontrol of both camera and human motion in video generation. Uni3C includes twokey contributions. First, we propose a plug-and-play control module trainedwith a frozen video generative backbone, PCDController, which utilizesunprojected point clouds from monocular depth to achieve accurate cameracontrol. By leveraging the strong 3D priors of point clouds and the powerfulcapacities of video foundational models, PCDController shows impressivegeneralization, performing well regardless of whether the inference backbone isfrozen or fine-tuned. This flexibility enables different modules of Uni3C to betrained in specific domains, i.e., either camera control or human motioncontrol, reducing the dependency on jointly annotated data. Second, we proposea jointly aligned 3D world guidance for the inference phase that seamlesslyintegrates both scenic point clouds and SMPL-X characters to unify the controlsignals for camera and human motion, respectively. Extensive experimentsconfirm that PCDController enjoys strong robustness in driving camera motionfor fine-tuned backbones of video generation. Uni3C substantially outperformscompetitors in both camera controllability and human motion quality.Additionally, we collect tailored validation sets featuring challenging cameramovements and human actions to validate the effectiveness of our method.</description>
      <author>example@mail.com (Chenjie Cao, Jingkai Zhou, Shikai Li, Jingyun Liang, Chaohui Yu, Fan Wang, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2504.14899v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Improving Coding Agent</title>
      <link>http://arxiv.org/abs/2504.15228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at an ICLR 2025 workshop on Scaling Self-Improving  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;展示了装备基本编码工具的LLM编码智能体能够自主编辑自身，从而提高其在基准任务上的性能。&lt;h4&gt;背景&lt;/h4&gt;研究了智能体系统在自动和开放设计方面的进步。&lt;h4&gt;目的&lt;/h4&gt;为那些寻求在工具使用和其他智能体任务上对LLM进行后续训练的人提供参考智能体框架。&lt;h4&gt;方法&lt;/h4&gt;利用装备基本编码工具的LLM编码智能体进行自主编辑，并在SWEBench Verified的随机子集以及LiveCodeBench和合成智能体基准上测试其性能。&lt;h4&gt;主要发现&lt;/h4&gt;在SWEBench Verified的随机子集上，性能提升从17%到53%，在LiveCodeBench上也有额外性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究代表了在智能体系统自动化和开放设计方面的一项进步。&lt;h4&gt;翻译&lt;/h4&gt;我们证明了一个装备基本编码工具的LLM编码智能体可以自主编辑自身，从而在基准任务上提高其性能。我们在SWEBench Verified的随机子集上发现了17%到53%的性能提升，在LiveCodeBench上也有额外的性能提升，以及在合成智能体基准上也有性能提升。我们的工作代表了在智能体系统的自动化和开放设计方面的一项进步，并为那些寻求在工具使用和其他智能体任务上对LLM进行后续训练的人提供了一个参考智能体框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We demonstrate that an LLM coding agent, equipped with basic coding tools,can autonomously edit itself, and thereby improve its performance on benchmarktasks. We find performance gains from 17% to 53% on a random subset of SWEBench Verified, with additional performance gains on LiveCodeBench, as well assynthetically generated agent benchmarks. Our work represents an advancement inthe automated and open-ended design of agentic systems, and provides areference agent framework for those seeking to post-train LLMs on tool use andother agentic tasks.</description>
      <author>example@mail.com (Maxime Robeyns, Martin Szummer, Laurence Aitchison)</author>
      <guid isPermaLink="false">2504.15228v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification</title>
      <link>http://arxiv.org/abs/2504.15041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对Lifelong Person Re-identification（LReID）在保留旧知识的同时适应新信息的关键挑战，提出了一种新的Distribution-aware Forgetting Compensation（DAFC）模型，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;LReID在长期学习和适应新信息时，面临着保留旧知识和适应新信息之间的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;解决LReID中保留旧知识的同时适应新信息的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的DAFC模型，该模型通过探索跨域共享表示学习和特定域分布集成来解决这个问题，同时使用Text-driven Prompt Aggregation（TPA）来丰富提示元素，并设计Distribution-based Awareness and Integration（DAI）来捕捉每个特定域的分布。此外，还开发了知识巩固机制（KCM），包括实例级别区分和跨域一致性对齐策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DAFC在两个训练顺序上的平均AP/R@1至少比最先进的模型高出9.8%/6.6%和6.4%/6.2%。&lt;h4&gt;结论&lt;/h4&gt;DAFC模型在LReID任务中表现出色，有效解决了知识遗忘和模型适应性学习的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LiuShiBen/DAFC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong Person Re-identification (LReID) suffers from a key challenge inpreserving old knowledge while adapting to new information. The existingsolutions include rehearsal-based and rehearsal-free methods to address thischallenge. Rehearsal-based approaches rely on knowledge distillation,continuously accumulating forgetting during the distillation process.Rehearsal-free methods insufficiently learn the distribution of each domain,leading to forgetfulness over time. To solve these issues, we propose a novelDistribution-aware Forgetting Compensation (DAFC) model that explorescross-domain shared representation learning and domain-specific distributionintegration without using old exemplars or knowledge distillation. We propose aText-driven Prompt Aggregation (TPA) that utilizes text features to enrichprompt elements and guide the prompt model to learn fine-grainedrepresentations for each instance. This can enhance the differentiation ofidentity information and establish the foundation for domain distributionawareness. Then, Distribution-based Awareness and Integration (DAI) is designedto capture each domain-specific distribution by a dedicated expert network andadaptively consolidate them into a shared region in high-dimensional space. Inthis manner, DAI can consolidate and enhance cross-domain shared representationlearning while alleviating catastrophic forgetting. Furthermore, we develop aKnowledge Consolidation Mechanism (KCM) that comprises instance-leveldiscrimination and cross-domain consistency alignment strategies to facilitatemodel adaptive learning of new knowledge from the current domain and promoteknowledge consolidation learning between acquired domain-specificdistributions, respectively. Experimental results show that our DAFC outperformstate-of-the-art methods by at least 9.8\%/6.6\% and 6.4\%/6.2\% of averagemAP/R@1 on two training orders.</description>
      <author>example@mail.com (Shiben Liu, Huijie Fan, Qiang Wang, Baojie Fan, Yandong Tang, Liangqiong Qu)</author>
      <guid isPermaLink="false">2504.15041v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Improving Sound Source Localization with Joint Slot Attention on Image and Audio</title>
      <link>http://arxiv.org/abs/2504.15118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的声音源定位（SSL）方法，通过联合图像和音频的特征注意力来解决现有方法的不足，并在公共基准测试中取得了最佳性能。&lt;h4&gt;背景&lt;/h4&gt;声音源定位（SSL）任务是在图像中定位声音源。由于缺乏定位标签，SSL中通常将图像和音频表示为单个嵌入向量，并通过对比学习来学习SSL。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在噪声和背景无关特征存在时的不足，提出一种新的SSL方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过联合图像和音频的槽位注意力来分解特征，只使用图像和音频的目标表示进行对比学习，并引入跨模态注意力匹配以进一步对齐图像和音频的局部特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个公共SSL基准测试中几乎所有设置中都取得了最佳性能，并且在跨模态检索中显著优于所有先前的工作。&lt;h4&gt;结论&lt;/h4&gt;该方法通过改进的特征表示和注意力机制，提高了SSL任务的性能，为音频和图像的跨模态检索提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sound source localization (SSL) is the task of locating the source of soundwithin an image. Due to the lack of localization labels, the de facto standardin SSL has been to represent an image and audio as a single embedding vectoreach, and use them to learn SSL via contrastive learning. To this end, previouswork samples one of local image features as the image embedding and aggregatesall local audio features to obtain the audio embedding, which is far fromoptimal due to the presence of noise and background irrelevant to the actualtarget in the input. We present a novel SSL method that addresses this chronicissue by joint slot attention on image and audio. To be specific, two slotscompetitively attend image and audio features to decompose them into target andoff-target representations, and only target representations of image and audioare used for contrastive learning. Also, we introduce cross-modal attentionmatching to further align local features of image and audio. Our methodachieved the best in almost all settings on three public benchmarks for SSL,and substantially outperformed all the prior work in cross-modal retrieval.</description>
      <author>example@mail.com (Inho Kim, Youngkil Song, Jicheol Park, Won Hwa Kim, Suha Kwak)</author>
      <guid isPermaLink="false">2504.15118v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Edge-boosted graph learning for functional brain connectivity analysis</title>
      <link>http://arxiv.org/abs/2504.14796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IEEE International Symposium on Biomedical Imaging (ISBI)  2025, 4 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的脑网络分析方法，通过强调边功能连接（eFC）来预测严重神经退行性疾病如阿尔茨海默病和帕金森病的疾病状态，并引入了共嵌入技术以有效整合边功能连接。&lt;h4&gt;背景&lt;/h4&gt;目前研究通常使用图神经网络（GNNs）从基于节点的脑连接矩阵中推断临床诊断，但近期神经科学研究表明，这种基于节点的连接无法准确捕捉大脑中的功能连接。&lt;h4&gt;目的&lt;/h4&gt;为了提高对严重神经退行性疾病的早期诊断能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法强调边功能连接（eFC），并引入了共嵌入技术来有效整合边功能连接。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI和PPMI数据集上的实验结果表明，该方法在分类功能脑网络方面显著优于最先进的GNN方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够更准确地预测严重神经退行性疾病的疾病状态，为早期诊断提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Predicting disease states from functional brain connectivity is critical for the early diagnosis of severe neurodegenerative diseases such as Alzheimer's Disease and Parkinson's Disease. Existing studies commonly employ Graph Neural Networks (GNNs) to infer clinical diagnoses from node-based brain connectivity matrices generated through node-to-node similarities of regionally averaged fMRI signals. However, recent neuroscience studies found that such node-based connectivity does not accurately capture "functional connections" within the brain. This paper proposes a novel approach to brain network analysis that emphasizes edge functional connectivity (eFC), shifting the focus to inter-edge relationships. Additionally, we introduce a co-embedding technique to integrate edge functional connections effectively. Experimental results on the ADNI and PPMI datasets demonstrate that our method significantly outperforms state-of-the-art GNN methods in classifying functional brain networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting disease states from functional brain connectivity is critical forthe early diagnosis of severe neurodegenerative diseases such as Alzheimer'sDisease and Parkinson's Disease. Existing studies commonly employ Graph NeuralNetworks (GNNs) to infer clinical diagnoses from node-based brain connectivitymatrices generated through node-to-node similarities of regionally averagedfMRI signals. However, recent neuroscience studies found that such node-basedconnectivity does not accurately capture ``functional connections" within thebrain. This paper proposes a novel approach to brain network analysis thatemphasizes edge functional connectivity (eFC), shifting the focus to inter-edgerelationships. Additionally, we introduce a co-embedding technique to integrateedge functional connections effectively. Experimental results on the ADNI andPPMI datasets demonstrate that our method significantly outperformsstate-of-the-art GNN methods in classifying functional brain networks.</description>
      <author>example@mail.com (David Yang, Mostafa Abdelmegeed, John Modl, Minjeong Kim)</author>
      <guid isPermaLink="false">2504.14796v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>The 1st EReL@MIR Workshop on Efficient Representation Learning for Multimodal Information Retrieval</title>
      <link>http://arxiv.org/abs/2504.14788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW2025 Workshop Summary&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多模态表示学习受到广泛关注，大型预训练多模态基础模型在信息检索任务中表现优异，但同时也带来了效率挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习在人工智能领域受到重视，大型的预训练多模态基础模型如LLaMA、GPT、Mistral和CLIP在信息检索任务中取得了显著成绩。&lt;h4&gt;目的&lt;/h4&gt;为了解决大型基础模型在训练、部署和推理阶段的效率问题，提出组织首次EREL@MIR研讨会，探讨新解决方案和问题。&lt;h4&gt;方法&lt;/h4&gt;在Web Conference 2025上组织EREL@MIR研讨会，邀请参与者讨论新解决方案、问题、挑战、效率评估指标和基准。&lt;h4&gt;主要发现&lt;/h4&gt;大型基础模型在信息检索任务中的代表学习存在效率挑战，需要进一步的研究和改进。&lt;h4&gt;结论&lt;/h4&gt;研讨会旨在为学术界和工业界研究者提供一个平台，共同推动高效和有效的多模态信息检索表示学习。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal representation learning has garnered significant attention in the AI community, largely due to the success of large pre-trained multimodal foundation models like LLaMA, GPT, Mistral, and CLIP. These models have achieved remarkable performance across various tasks of multimodal information retrieval (MIR), including web search, cross-modal retrieval, and recommenders systems, etc. However, due to their enormous parameter sizes, significant efficiency challenges emerge across training, deployment, and inference stages when adapting these models' representation for IR tasks. These challenges present substantial obstacles to the practical adaptation of foundation models for representation learning in information retrieval tasks. To address these pressing issues, we propose organizing the first EReL@MIR workshop at the Web Conference 2025, inviting participants to explore novel solutions, emerging problems, challenges, efficiency evaluation metrics and benchmarks. This workshop aims to provide a platform for both academic and industry researchers to engage in discussions, share insights, and foster collaboration toward achieving efficient and effective representation learning for multimodal information retrieval in the era of large foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning has garnered significant attention in theAI community, largely due to the success of large pre-trained multimodalfoundation models like LLaMA, GPT, Mistral, and CLIP. These models haveachieved remarkable performance across various tasks of multimodal informationretrieval (MIR), including web search, cross-modal retrieval, and recommendersystems, etc. However, due to their enormous parameter sizes, significantefficiency challenges emerge across training, deployment, and inference stageswhen adapting these models' representation for IR tasks. These challengespresent substantial obstacles to the practical adaptation of foundation modelsfor representation learning in information retrieval tasks.  To address these pressing issues, we propose organizing the first EReL@MIRworkshop at the Web Conference 2025, inviting participants to explore novelsolutions, emerging problems, challenges, efficiency evaluation metrics andbenchmarks. This workshop aims to provide a platform for both academic andindustry researchers to engage in discussions, share insights, and fostercollaboration toward achieving efficient and effective representation learningfor multimodal information retrieval in the era of large foundation models.</description>
      <author>example@mail.com (Junchen Fu, Xuri Ge, Xin Xin, Haitao Yu, Yue Feng, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose)</author>
      <guid isPermaLink="false">2504.14788v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Centric Representation-Efficient Fine-Tuning for Robust Universal Foreground Segmentation</title>
      <link>http://arxiv.org/abs/2504.14481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级的参数高效微调框架LSR-ST，用于提高视觉基础模型的鲁棒性，特别适用于纹理稀疏的环境。&lt;h4&gt;背景&lt;/h4&gt;当前视觉基础模型在复杂场景下（如伪装和红外图像）的参数高效微调往往失败，原因在于模型内在的纹理偏差在微调过程中加剧，限制了泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为LSR-ST的框架，通过引入形状偏差归纳先验来增强模型的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;LSR-ST使用简单的HDConv块捕获形状感知特征，该块结合了大核注意力机制和残差学习。该方法满足了引起形状偏差的三个关键条件：大感受野、多阶特征交互和稀疏连接。&lt;h4&gt;主要发现&lt;/h4&gt;通过信息瓶颈理论，发现这些改进来源于表示效率，即在不增加冗余的情况下提取与任务相关的结构化特征的能力。&lt;h4&gt;结论&lt;/h4&gt;与传统的NLP范式不同，视觉任务需要模型提取任务定义的语义，而不是仅仅依赖预编码的特征。LSR-ST在SAM2-UNet上进行微调，在17个数据集和6个任务上实现了一致的改进，使用了仅4.719M个可训练参数，突出了表示效率在复杂视觉环境中的鲁棒和适应性强的基础模型的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：前景分割对于场景理解至关重要，然而在复杂场景，如伪装和红外图像中，视觉基础模型（VFMs）的参数高效微调（PEFT）往往失败。我们把这个挑战归因于VFMs固有的纹理偏差，这种偏差在微调过程中加剧，限制了在纹理稀疏环境中的泛化。为了解决这个问题，我们提出了Ladder Shape-bias Representation Side-tuning（LSR-ST），一个轻量级的PEFT框架，通过引入形状偏差归纳先验来增强模型的鲁棒性。LSR-ST使用一个简单的HDConv块捕获形状感知特征，该块结合了大核注意力和残差学习。该方法满足了引起形状偏差的三个关键条件：大感受野、多阶特征交互和稀疏连接。我们的分析揭示，这些改进来源于表示效率——在最小化冗余的同时提取与任务相关的结构化特征的能力。我们通过信息瓶颈理论形式化这个概念，并倡导将其作为关键PEFT目标。与传统的NLP范式不同，视觉任务需要模型提取任务定义的语义，而不是仅仅依赖预编码的特征。这种转变使得我们的方法能够超越传统的权衡，为视觉任务提供更鲁棒和更通用的解决方案。LSR-ST对SAM2-UNet进行了最小化修改，在17个数据集和6个任务上仅使用4.719M个可训练参数实现了一致的改进。这些结果突出了在复杂视觉环境中，表示效率对鲁棒和自适应VFMs的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foreground segmentation is crucial for scene understanding, yetparameter-efficient fine-tuning (PEFT) of vision foundation models (VFMs) oftenfails in complex scenarios, such as camouflage and infrared imagery. Weattribute this challenge to the inherent texture bias in VFMs, which isexacerbated during fine-tuning and limits generalization in texture-sparseenvironments. To address this, we propose Ladder Shape-bias RepresentationSide-tuning (LSR-ST), a lightweight PEFT framework that enhances modelrobustness by introducing shape-biased inductive priors. LSR-ST capturesshape-aware features using a simple HDConv Block, which integrates large-kernelattention and residual learning. The method satisfies three key conditions forinducing shape bias: large receptive fields, multi-order feature interactions,and sparse connectivity. Our analysis reveals that these improvements stem fromrepresentation efficiency-the ability to extract task-relevant, structurallygrounded features while minimizing redundancy. We formalize this concept viaInformation Bottleneck theory and advocate for it as a key PEFT objective.Unlike traditional NLP paradigms that focus on optimizing parameters andmemory, visual tasks require models that extract task-defined semantics, ratherthan just relying on pre-encoded features. This shift enables our approach tomove beyond conventional trade-offs, offering more robust and generalizablesolutions for vision tasks. With minimal changes to SAM2-UNet, LSR-ST achievesconsistent improvements across 17 datasets and 6 tasks using only 4.719Mtrainable parameters. These results highlight the potential of representationefficiency for robust and adaptable VFMs within complex visual environments.</description>
      <author>example@mail.com (Guoyi Zhang, Siyang Chen, Guangsheng Xu, Han Wang, Xiaohu Zhang)</author>
      <guid isPermaLink="false">2504.14481v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>AltGDmin: Alternating GD and Minimization for Partly-Decoupled (Federated) Optimization</title>
      <link>http://arxiv.org/abs/2504.14741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in Foundations and Trends in Optimization (NOW publishers)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文描述了一种名为交替梯度下降（AltGDmin）的新优化解决方案框架，适用于许多适用于交替最小化（AltMin）的优化问题。&lt;h4&gt;背景&lt;/h4&gt;AltMin是块坐标下降算法的特殊情况，适用于最小化关于一个变量子集的问题，同时保持其他变量固定，且这些问题的最小化是闭式或可靠解决的。&lt;h4&gt;目的&lt;/h4&gt;AltGDmin旨在为那些通过AltMin解决的问题提供一种更快的解决方案。&lt;h4&gt;方法&lt;/h4&gt;AltGDmin框架通过将优化变量Z分为两个块/子集Za和Zb，并交替优化这些块来实现。这种方法在Zb上的最小化比Za快，并且成本函数对Za是可微的。&lt;h4&gt;主要发现&lt;/h4&gt;AltGDmin在以下情况下通常比AltMin更快：Zb上的最小化比Za快得多，且成本函数对Za是可微的。这种方法的快速性通常是因为问题对于Zb是解耦的，且每个解耦问题都易于解决。&lt;h4&gt;结论&lt;/h4&gt;AltGDmin在联邦设置中通信效率高，适用于多种问题，如低秩列压缩感知、低秩矩阵补全、鲁棒PCA、相干重建、张量扩展和部分离散问题。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为交替梯度下降（AltGDmin）的新型优化解决方案框架，适用于许多适用于交替最小化（AltMin）的优化问题。AltMin是块坐标下降算法的一种特殊情况，适用于最小化关于一个变量子集的问题，同时保持其他变量固定，且这些问题的最小化是闭式或可靠解决的。将优化变量Z分为两个块/子集Za和Zb，AltGDmin通过交替优化这些块来实现。这种方法在Zb上的最小化比Za快得多，且成本函数对Za是可微的。在以下情况下，AltGDmin通常比AltMin更快：Zb上的最小化比Za快得多，且成本函数对Za是可微的。这种方法的快速性通常是因为问题对于Zb是解耦的，且每个解耦问题都易于解决。AltGDmin在联邦设置中通信效率高，适用于多种问题，如低秩列压缩感知、低秩矩阵补全、鲁棒PCA、相干重建、张量扩展和部分离散问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article describes a novel optimization solution framework, calledalternating gradient descent (GD) and minimization (AltGDmin), that is usefulfor many problems for which alternating minimization (AltMin) is a popularsolution. AltMin is a special case of the block coordinate descent algorithmthat is useful for problems in which minimization w.r.t one subset of variableskeeping the other fixed is closed form or otherwise reliably solved. Denote thetwo blocks/subsets of the optimization variables Z by Za, Zb, i.e., Z = {Za,Zb}. AltGDmin is often a faster solution than AltMin for any problem for which(i) the minimization over one set of variables, Zb, is much quicker than thatover the other set, Za; and (ii) the cost function is differentiable w.r.t. Za.Often, the reason for one minimization to be quicker is that the problem is``decoupled" for Zb and each of the decoupled problems is quick to solve. Thisdecoupling is also what makes AltGDmin communication-efficient for federatedsettings.  Important examples where this assumption holds include (a) low rankcolumn-wise compressive sensing (LRCS), low rank matrix completion (LRMC), (b)their outlier-corrupted extensions such as robust PCA, robust LRCS and robustLRMC; (c) phase retrieval and its sparse and low-rank model based extensions;(d) tensor extensions of many of these problems such as tensor LRCS and tensorcompletion; and (e) many partly discrete problems where GD does not apply --such as clustering, unlabeled sensing, and mixed linear regression. LRCS findsimportant applications in multi-task representation learning and few shotlearning, federated sketching, and accelerated dynamic MRI. LRMC and robust PCAfind important applications in recommender systems, computer vision and videoanalytics.</description>
      <author>example@mail.com (Namrata Vaswani)</author>
      <guid isPermaLink="false">2504.14741v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding</title>
      <link>http://arxiv.org/abs/2504.14692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OmniV-Med的统一框架，用于多模态医学理解，旨在解决现有模型在处理文本数据和多种视觉模态（如2D/3D图像和视频）时的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的医学视觉-语言模型（Med-VLMs）通常使用不同的编码器处理不同的模态，这限制了它们在实际部署中的无缝集成。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够统一处理文本数据和多种视觉模态的医学理解框架。&lt;h4&gt;方法&lt;/h4&gt;1. 构建了一个包含252K个指导样本的OmniV-Med-Instruct多模态医学数据集，涵盖14种医学图像模态和11个临床任务。2. 设计了一个旋转位置自适应编码器，能够在统一架构中处理多分辨率2D/3D图像和视频。3. 引入了一种医学感知的token剪枝机制，利用体积数据（如连续的CT切片）和医学视频的空间-时间冗余，有效减少了60%的视觉token，而不会降低性能。&lt;h4&gt;主要发现&lt;/h4&gt;OmniV-Med-7B在涵盖2D/3D医学成像和视频理解任务的7个基准测试中实现了最先进的性能。其轻量级版本（OmniV-Med-1.5B）在训练时仅需要8个RTX3090 GPU，同时支持高效的长时间视频推理。&lt;h4&gt;结论&lt;/h4&gt;OmniV-Med框架能够有效地整合文本数据和多种视觉模态，为医学视觉-语言模型在实际应用中提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The practical deployment of medical vision-language models (Med-VLMs) necessitates seamless integration of textual data with diverse visual modalities, including 2D/3D images and videos, yet existing models typically employ separate encoders for different modalities. To address this limitation, we present OmniV-Med, a unified framework for multimodal medical understanding. Our technical contributions are threefold: First, we construct OmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252K instructional samples spanning 14 medical image modalities and 11 clinical tasks. Second, we devise a rotary position-adaptive encoder that processes multi-resolution 2D/3D images and videos within a unified architecture, diverging from conventional modality-specific encoders. Third, we introduce a medical-aware token pruning mechanism that exploits spatial-temporal redundancy in volumetric data (e.g., consecutive CT slices) and medical videos, effectively reducing 60% of visual tokens without performance degradation. Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-art performance on 7 benchmarks spanning 2D/3D medical imaging and video understanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attains comparable performance while requiring only 8 RTX3090 GPUs for training and supporting efficient long-video inference. Data, code and model will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The practical deployment of medical vision-language models (Med-VLMs)necessitates seamless integration of textual data with diverse visualmodalities, including 2D/3D images and videos, yet existing models typicallyemploy separate encoders for different modalities. To address this limitation,we present OmniV-Med, a unified framework for multimodal medical understanding.Our technical contributions are threefold: First, we constructOmniV-Med-Instruct, a comprehensive multimodal medical dataset containing 252Kinstructional samples spanning 14 medical image modalities and 11 clinicaltasks. Second, we devise a rotary position-adaptive encoder that processesmulti-resolution 2D/3D images and videos within a unified architecture,diverging from conventional modality-specific encoders. Third, we introduce amedical-aware token pruning mechanism that exploits spatial-temporal redundancyin volumetric data (e.g., consecutive CT slices) and medical videos,effectively reducing 60\% of visual tokens without performance degradation.Empirical evaluations demonstrate that OmniV-Med-7B achieves state-of-the-artperformance on 7 benchmarks spanning 2D/3D medical imaging and videounderstanding tasks. Notably, our lightweight variant (OmniV-Med-1.5B) attainscomparable performance while requiring only 8 RTX3090 GPUs for training andsupporting efficient long-video inference. Data, code and model will bereleased.</description>
      <author>example@mail.com (Songtao Jiang, Yuan Wang, Sibo Song, Yan Zhang, Zijie Meng, Bohan Lei, Jian Wu, Jimeng Sun, Zuozhu Liu)</author>
      <guid isPermaLink="false">2504.14692v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PIV-FlowDiffuser:Transfer-learning-based denoising diffusion models for PIV</title>
      <link>http://arxiv.org/abs/2504.14952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了基于深度学习的粒子图像测速（PIV）的降噪扩散模型（PIV-FlowDiffuser），通过迁移学习策略提高了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;深度学习算法在降低PIV的计算时间并提高其空间分辨率方面取得了显著成效，但基于合成数据集训练的模型在实际粒子图像上可能存在性能下降的问题。&lt;h4&gt;目的&lt;/h4&gt;减少PIV分析中的特殊噪声，提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;使用FlowDiffuser模型进行降噪，并通过迁移学习策略进行训练，包括：(1) 使用多个视觉光流数据集对FlowDiffuser模型进行预训练，如Sintel、KITTI等；(2) 在合成PIV数据集上微调预训练模型。将PIV图像上采样两倍以解决小尺度湍流结构。&lt;h4&gt;主要发现&lt;/h4&gt;PIV-FlowDiffuser有效抑制了噪声模式，将经典Cai数据集上RAFT256-PIV的末端误差（AEE）降低了59.4%。PIV-FlowDiffuser在未见过的粒子图像上表现出增强的泛化性能。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了基于迁移学习的降噪扩散模型在PIV中的应用，并推荐读者查阅相关实现代码。&lt;h4&gt;翻译&lt;/h4&gt;This research proposes a denoising diffusion model (PIV-FlowDiffuser) for particle image velocimetry (PIV) based on deep learning, which improves the model's performance through transfer learning strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhu-qianyu/piv-flowdiffuser&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning algorithms have significantly reduced the computational timeand improved the spatial resolution of particle image velocimetry~(PIV).However, the models trained on synthetic datasets might have a degradedperformance on practical particle images due to domain gaps. As a result,special residual patterns are often observed for the vector fields of deeplearning-based estimators. To reduce the special noise step-by-step, we employa denoising diffusion model~(FlowDiffuser) for PIV analysis. And thedata-hungry iterative denoising diffusion model is trained via a transferlearning strategy, resulting in our PIV-FlowDiffuser method. Specifically, (1)pre-training a FlowDiffuser model with multiple optical flow datasets of thecomputer vision community, such as Sintel, KITTI, etc; (2) fine-tuning thepre-trained model on synthetic PIV datasets. Note that the PIV images areupsampled by a factor of two to resolve the small-scale turbulent flowstructures. The visualized results indicate that our PIV-FlowDiffusereffectively suppresses the noise patterns. Therefore, the denoising diffusionmodel reduces the average end-point error~($AEE$) by 59.4% over RAFT256-PIVbaseline on the classic Cai's dataset. Besides, PIV-FlowDiffuser exhibitsenhanced generalization performance on unseen particle images due to transferlearning. Overall, this study highlights the transfer-learning-based denoisingdiffusion models for PIV. And a detailed implementation is recommended forinterested readers in the repositoryhttps://github.com/Zhu-Qianyu/PIV-FlowDiffuser.</description>
      <author>example@mail.com (Qianyu Zhu, Junjie Wang, Jeremiah Hu, Jia Ai, Yong Lee)</author>
      <guid isPermaLink="false">2504.14952v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>An Iterative Task-Driven Framework for Resilient LiDAR Place Recognition in Adverse Weather</title>
      <link>http://arxiv.org/abs/2504.14806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ITDNet的迭代任务驱动框架，用于在恶劣天气条件下提高激光雷达位置识别（LPR）的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的LPR方法在雨、雪、雾等恶劣天气条件下难以保持鲁棒性，因为天气引起的噪声和点云退化影响了激光雷达的可靠性和感知精度。&lt;h4&gt;目的&lt;/h4&gt;提出ITDNet框架的目的是为了解决恶劣天气条件下LPR方法的鲁棒性问题。&lt;h4&gt;方法&lt;/h4&gt;ITDNet框架通过迭代学习策略，集成了激光雷达数据恢复（LDR）模块和激光雷达位置识别（LPR）模块。这些模块通过端到端联合训练和交替优化来提高性能。ITDNet利用LDR模块恢复损坏的点云，同时保持与清洁数据的结构一致性，从而提高恶劣天气下的LPR准确性。LPR任务提供特征伪标签以指导LDR模块的训练，使其更有效地与LPR任务对齐。为了实现这一目标，设计了一个任务驱动的LPR损失和重建损失来共同监督LDR模块的优化。此外，对于LDR模块，提出了双域混合（DDM）块进行频率-空间特征融合和语义感知生成（SAG）块进行语义引导的恢复。对于LPR模块，引入了多频率变换器（MFT）块和小波金字塔NetVLAD（WPN）块来聚合多尺度、鲁棒的全球描述符。&lt;h4&gt;主要发现&lt;/h4&gt;在Weather-KITTI、Boreas和提出的Weather-Apollo数据集上的大量实验表明，ITDNet优于现有的LPR方法，在恶劣天气条件下实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;ITDNet框架通过其创新的方法在恶劣天气条件下显著提高了LPR的准确性，其数据和代码将在GitHub上公开提供。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR位置识别（LPR）在自主导航中起着至关重要的作用。然而，现有的LPR方法在雨、雪、雾等恶劣天气条件下难以保持鲁棒性，其中天气引起的噪声和点云退化损害了激光雷达的可靠性和感知精度。为了应对这些挑战，我们提出了一种迭代任务驱动框架（ITDNet），该框架通过迭代学习策略集成了激光雷达数据恢复（LDR）模块和激光雷达位置识别（LPR）模块。这些模块通过端到端联合训练和交替优化来增强性能。ITDNet的核心原理是利用LDR模块恢复损坏的点云，同时保持与清洁数据的结构一致性，从而提高恶劣天气下的LPR准确性。同时，LPR任务提供特征伪标签以指导LDR模块的训练，使其更有效地与LPR任务对齐。为了实现这一目标，我们首先设计了一个任务驱动的LPR损失和重建损失来共同监督LDR模块的优化。此外，对于LDR模块，我们提出了一个双域混合（DDM）块进行频率-空间特征融合和一个语义感知生成（SAG）块进行语义引导的恢复。对于LPR模块，我们引入了一个多频率变换器（MFT）块和小波金字塔NetVLAD（WPN）块来聚合多尺度、鲁棒的全球描述符。最后，在Weather-KITTI、Boreas和我们提出的Weather-Apollo数据集上的大量实验表明，ITDNet优于现有的LPR方法，在恶劣天气条件下实现了最先进的性能。数据集和代码将在https://github.com/Grandzxw/ITDNet上公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR place recognition (LPR) plays a vital role in autonomous navigation.However, existing LPR methods struggle to maintain robustness under adverseweather conditions such as rain, snow, and fog, where weather-induced noise andpoint cloud degradation impair LiDAR reliability and perception accuracy. Totackle these challenges, we propose an Iterative Task-Driven Framework(ITDNet), which integrates a LiDAR Data Restoration (LDR) module and a LiDARPlace Recognition (LPR) module through an iterative learning strategy. Thesemodules are jointly trained end-to-end, with alternating optimization toenhance performance. The core rationale of ITDNet is to leverage the LDR moduleto recover the corrupted point clouds while preserving structural consistencywith clean data, thereby improving LPR accuracy in adverse weather.Simultaneously, the LPR task provides feature pseudo-labels to guide the LDRmodule's training, aligning it more effectively with the LPR task. To achievethis, we first design a task-driven LPR loss and a reconstruction loss tojointly supervise the optimization of the LDR module. Furthermore, for the LDRmodule, we propose a Dual-Domain Mixer (DDM) block for frequency-spatialfeature fusion and a Semantic-Aware Generator (SAG) block for semantic-guidedrestoration. In addition, for the LPR module, we introduce a Multi-FrequencyTransformer (MFT) block and a Wavelet Pyramid NetVLAD (WPN) block to aggregatemulti-scale, robust global descriptors. Finally, extensive experiments on theWeather-KITTI, Boreas, and our proposed Weather-Apollo datasets demonstratethat, demonstrate that ITDNet outperforms existing LPR methods, achievingstate-of-the-art performance in adverse weather. The datasets and code will bemade publicly available at https://github.com/Grandzxw/ITDNet.</description>
      <author>example@mail.com (Xiongwei Zhao, Yang Wang, Qihao Sun, Haojie Bai, Xingxiang Xie)</author>
      <guid isPermaLink="false">2504.14806v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Safety Co-Option and Compromised National Security: The Self-Fulfilling Prophecy of Weakened AI Risk Thresholds</title>
      <link>http://arxiv.org/abs/2504.15088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了风险阈值在技术系统安全评估中的作用，指出目前全球治理尚未就AI系统的适当风险容忍度达成共识，导致AI技术专家通过“安全修正主义”替代传统安全方法，以加速军事AI应用的采用，从而降低安全标准。&lt;h4&gt;背景&lt;/h4&gt;冷战时期，风险分析如核系统分析确立了社会可接受的风险阈值，这些阈值现在是评估安全关键和防御系统的标准。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨AI风险阈值的重要性以及当前AI风险评估方法可能带来的风险。&lt;h4&gt;方法&lt;/h4&gt;本文通过案例分析，展示了AI技术专家如何通过替代传统安全方法来推进军事AI的快速发展。&lt;h4&gt;主要发现&lt;/h4&gt;AI技术专家倾向于通过“安全修正主义”来加速军事AI的采用，这可能降低安全标准，损害国家安全利益。&lt;h4&gt;结论&lt;/h4&gt;开发基于AI的军事系统评估框架时，必须保持与既定风险阈值的对齐，并确保美国关键和防御基础设施的安全，同时遵守国际人道法。&lt;h4&gt;翻译&lt;/h4&gt;Risk thresholds provide a measure of the level of risk exposure that a society or individual is willing to withstand, ultimately shaping how we determine the safety of technological systems. Against the backdrop of the Cold War, the first risk analyses, such as those devised for nuclear systems, cemented societally accepted risk thresholds against which safety-critical and defense systems are now evaluated. But today, the appropriate risk tolerances for AI systems have yet to be agreed on by global governing efforts, despite the need for democratic deliberation regarding the acceptable levels of harm to human life. Absent such AI risk thresholds, AI technologists—primarily industry labs, as well as “AI safety” focused organizations—have instead advocated for risk tolerances skewed by a purported AI arms race and speculative “existential” risks, taking over the arbitration of risk determinations with life-or-death consequences, subverting democratic processes. In this paper, we demonstrate how such approaches have allowed AI technologists to engage in “safety revisionism,” substituting traditional safety methods and terminology with ill-defined alternatives that vie for the accelerated adoption of military AI uses at the cost of lowered safety and security thresholds. We explore how the current trajectory for AI risk determination and evaluation for foundation model use within national security is poised for a race to the bottom, to the detriment of the US's national security interests. Safety-critical and defense systems must comply with assurance frameworks that are aligned with established risk thresholds, and foundation models are no exception. As such, development of evaluation frameworks for AI-based military systems must preserve the safety and security of US critical and defense infrastructure, and remain in alignment with international humanitarian law.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Risk thresholds provide a measure of the level of risk exposure that asociety or individual is willing to withstand, ultimately shaping how wedetermine the safety of technological systems. Against the backdrop of the ColdWar, the first risk analyses, such as those devised for nuclear systems,cemented societally accepted risk thresholds against which safety-critical anddefense systems are now evaluated. But today, the appropriate risk tolerancesfor AI systems have yet to be agreed on by global governing efforts, despitethe need for democratic deliberation regarding the acceptable levels of harm tohuman life. Absent such AI risk thresholds, AI technologists-primarily industrylabs, as well as "AI safety" focused organizations-have instead advocated forrisk tolerances skewed by a purported AI arms race and speculative"existential" risks, taking over the arbitration of risk determinations withlife-or-death consequences, subverting democratic processes.  In this paper, we demonstrate how such approaches have allowed AItechnologists to engage in "safety revisionism," substituting traditionalsafety methods and terminology with ill-defined alternatives that vie for theaccelerated adoption of military AI uses at the cost of lowered safety andsecurity thresholds. We explore how the current trajectory for AI riskdetermination and evaluation for foundation model use within national securityis poised for a race to the bottom, to the detriment of the US's nationalsecurity interests. Safety-critical and defense systems must comply withassurance frameworks that are aligned with established risk thresholds, andfoundation models are no exception. As such, development of evaluationframeworks for AI-based military systems must preserve the safety and securityof US critical and defense infrastructure, and remain in alignment withinternational humanitarian law.</description>
      <author>example@mail.com (Heidy Khlaaf, Sarah Myers West)</author>
      <guid isPermaLink="false">2504.15088v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.14204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于差分对比表示学习框架的时间序列异常检测方法（DConAD），用于增强模型捕获时间序列正常模式的能力，并避免对高质量先验知识的依赖所引起的建模能力退化。&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测在风险识别和故障检测中具有重要价值。无监督学习方法因其无需标签而受到青睐，但面对多种异常模式、异常数据的稀疏性以及数据规模和复杂性的增长，这些方法往往难以捕捉时间序列中的鲁棒和代表性依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出DConAD方法以增强模型对时间序列正常模式的捕获能力，并避免建模能力的退化。&lt;h4&gt;方法&lt;/h4&gt;DConAD通过生成差分数据提供关于时间序列的额外信息，并利用基于transformer的架构来捕捉时空依赖关系，从而增强无偏表示学习能力的鲁棒性。此外，DConAD采用了一种基于KL散度的对比学习范式，仅使用正样本以避免重建偏差，并部署停止梯度策略以促进收敛。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公开数据集上的广泛实验表明，DConAD与九个基线相比表现出优越性和有效性。&lt;h4&gt;结论&lt;/h4&gt;DConAD方法在时间序列异常检测方面具有优越性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;Time series anomaly detection holds notable importance for risk identification and fault detection across diverse application domains. Unsupervised learning methods have become popular because they have no requirement for labels. However, due to the challenges posed by the multiplicity of abnormal patterns, the sparsity of anomalies, and the growth of data scale and complexity, these methods often fail to capture robust and representative dependencies within the time series for identifying anomalies. To enhance the ability of models to capture normal patterns of time series and avoid the retrogression of modeling ability triggered by the dependencies on high-quality prior knowledge, we propose a differencing-based contrastive representation learning framework for time series anomaly detection (DConAD). Specifically, DConAD generates differential data to provide additional information about time series and utilizes transformer-based architecture to capture spatiotemporal dependencies, which enhances the robustness of unbiased representation learning ability. Furthermore, DConAD implements a novel KL divergence-based contrastive learning paradigm that only uses positive samples to avoid deviation from reconstruction and deploys the stop-gradient strategy to compel convergence. Extensive experiments on five public datasets show the superiority and effectiveness of DConAD compared with nine baselines. The code is available at https://github.com/shaieesss/DConAD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly detection holds notable importance for riskidentification and fault detection across diverse application domains.Unsupervised learning methods have become popular because they have norequirement for labels. However, due to the challenges posed by themultiplicity of abnormal patterns, the sparsity of anomalies, and the growth ofdata scale and complexity, these methods often fail to capture robust andrepresentative dependencies within the time series for identifying anomalies.To enhance the ability of models to capture normal patterns of time series andavoid the retrogression of modeling ability triggered by the dependencies onhigh-quality prior knowledge, we propose a differencing-based contrastiverepresentation learning framework for time series anomaly detection (DConAD).Specifically, DConAD generates differential data to provide additionalinformation about time series and utilizes transformer-based architecture tocapture spatiotemporal dependencies, which enhances the robustness of unbiasedrepresentation learning ability. Furthermore, DConAD implements a novel KLdivergence-based contrastive learning paradigm that only uses positive samplesto avoid deviation from reconstruction and deploys the stop-gradient strategyto compel convergence. Extensive experiments on five public datasets show thesuperiority and effectiveness of DConAD compared with nine baselines. The codeis available at https://github.com/shaieesss/DConAD.</description>
      <author>example@mail.com (Wenxin Zhang, Xiaojian Lin, Wenjun Yu, Guangzhen Yao, jingxiang Zhong, Yu Li, Renda Han, Songcheng Xu, Hao Shi, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14204v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Uncovering Issues in the Radio Access Network by Looking at the Neighbors</title>
      <link>http://arxiv.org/abs/2504.14686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的RAN上下文异常检测监控工具c-ANEMON，用于识别独立于外部移动因素的异常行为，帮助网络操作团队关注网络问题。&lt;h4&gt;背景&lt;/h4&gt;移动网络运营商管理着跨越多个无线电世代（2G-5G）的大量基站，为了处理这种复杂性，操作团队依赖监控系统，包括异常检测工具来识别意外行为。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测RAN中异常行为的监控工具，帮助网络操作团队专注于网络问题。&lt;h4&gt;方法&lt;/h4&gt;c-ANEMON通过分析单个基站与其局部邻域之间的关系来捕捉时空变化，从而检测独立于外部移动因素的异常。使用真实世界数据对c-ANEMON进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;GNN模型在未见过的区域中表现出良好的泛化能力，检测到的异常被手动检查并定义了几个持续时间较长的异常类别，其中45.95%的异常可能需要操作团队的干预。&lt;h4&gt;结论&lt;/h4&gt;c-ANEMON能够有效检测RAN中的异常，有助于网络操作团队专注于网络问题，并可能在一个广泛的部署区域中使用单一模型。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents c-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on GraphNeural Networks (GNNs). Our solution captures spatio-temporal variations by analyzing the behavior of individual cells in relation to their local neighborhoods, enabling the detection of anomalies that are independent of external mobility factors. This, in turn, allows focusing on anomalies associated with network issues (e.g., misconfigurations, equipment failures). We evaluate c-ANEMON using real-world data from a large European metropolitan area (7,890 cells; 3 months). First, we show that the GNN model within our solution generalizes effectively to cells from previously unseen areas, suggesting the possibility of using a single model across extensive deployment regions. Then, we analyze the anomalies detected by c-ANEMON through manual inspection and define several categories of long-lasting anomalies (6+ hours). Notably, 45.95% of these anomalies fall into a category that is more likely to require intervention by operations teams.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile network operators (MNOs) manage Radio Access Networks (RANs) withmassive amounts of cells over multiple radio generations (2G-5G). To handlesuch complexity, operations teams rely on monitoring systems, including anomalydetection tools that identify unexpected behaviors. In this paper, we presentc-ANEMON, a Contextual ANomaly dEtection MONitor for the RAN based on GraphNeural Networks (GNNs). Our solution captures spatio-temporal variations byanalyzing the behavior of individual cells in relation to their localneighborhoods, enabling the detection of anomalies that are independent ofexternal mobility factors. This, in turn, allows focusing on anomaliesassociated with network issues (e.g., misconfigurations, equipment failures).We evaluate c-ANEMON using real-world data from a large European metropolitanarea (7,890 cells; 3 months). First, we show that the GNN model within oursolution generalizes effectively to cells from previously unseen areas,suggesting the possibility of using a single model across extensive deploymentregions. Then, we analyze the anomalies detected by c-ANEMON through manualinspection and define several categories of long-lasting anomalies (6+ hours).Notably, 45.95% of these anomalies fall into a category that is more likely torequire intervention by operations teams.</description>
      <author>example@mail.com (José Suárez-Varela, Andra Lutu)</author>
      <guid isPermaLink="false">2504.14686v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning via mechanosensitivity and activity in cytoskeletal networks</title>
      <link>http://arxiv.org/abs/2504.15107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 9 figurs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了如何通过受肌动蛋白细胞骨架粗粒度描述启发的网络，在对比学习框架中，通过赋予其机械敏感蛋白和马达，从环境扰动中学习。这项工作证明了力敏感蛋白和分子马达可以作为在生物系统中学习的一般策略的基础，并确定了最小化的生物合理学习机制，同时探讨了其在适应和稳态等常见现象中的意义。&lt;h4&gt;背景&lt;/h4&gt;本文研究的是如何利用受肌动蛋白细胞骨架启发的网络进行学习。&lt;h4&gt;目的&lt;/h4&gt;研究力敏感蛋白和分子马达在生物系统中作为学习策略的基础，并探讨其在生物现象中的应用。&lt;h4&gt;方法&lt;/h4&gt;在对比学习框架中，通过赋予网络机械敏感蛋白和马达，使其能够从环境扰动中学习。&lt;h4&gt;主要发现&lt;/h4&gt;发现了最小化的生物合理学习机制，并探讨了其在适应和稳态等常见现象中的应用。&lt;h4&gt;结论&lt;/h4&gt;力敏感蛋白和分子马达可以作为生物系统中学习的一般策略的基础，并具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;In this work, we show how a network inspired by a coarse-grained description of actomyosin cytoskeleton can learn from environmental perturbations in a contrastive learning framework if it is endowed with mechanosensitive proteins and motors. Our work is a proof of principle for how force-sensitive proteins and molecular motors can form the basis of a general strategy to learn in biological systems. Our work identifies a minimal biologically plausible learning mechanism and also explores its implications for commonly occurring phenomenology such as adaptation and homeostasis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we show how a network inspired by a coarse-grained descriptionof actomyosin cytoskeleton can learn - in a contrastive learning framework -from environmental perturbations if it is endowed with mechanosensitiveproteins and motors. Our work is a proof of principle for how force-sensitiveproteins and molecular motors can form the basis of a general strategy to learnin biological systems. Our work identifies a minimal biologically plausiblelearning mechanism and also explores its implications for commonly occuringphenomenolgy such as adaptation and homeostatis.</description>
      <author>example@mail.com (Deb S. Banerjee, Martin J. Falk, Margaret L Gardel, Aleksandra M. Walczak, Thierry Mora, Suriyanarayanan Vaikuntanathan)</author>
      <guid isPermaLink="false">2504.15107v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Matrix Factorization with Dynamic Multi-view Clustering for Recommender System</title>
      <link>http://arxiv.org/abs/2504.14565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MFDMC的矩阵分解方法，旨在解决传统推荐系统在处理大规模数据时的计算成本问题，并提高了模型的解释性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;矩阵分解是推荐系统的基础，但传统的矩阵分解方法在处理大规模应用时，如电子商务和物联网，存在计算成本高的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效且通用的矩阵分解框架，以平衡高效端到端训练和充分利用大规模数据。&lt;h4&gt;方法&lt;/h4&gt;MFDMC利用动态多视图聚类学习用户和物品表示，自适应地修剪不良形成的聚类，并将每个实体的表示建模为稳健聚类的加权投影。&lt;h4&gt;主要发现&lt;/h4&gt;MFDMC在推荐系统和其他表示学习领域（如计算机视觉）中表现出优异的性能，显示出其可扩展性和多功能性。&lt;h4&gt;结论&lt;/h4&gt;MFDMC是一种高效且可解释的矩阵分解方法，适用于处理大规模推荐系统和其他领域的数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Matrix factorization (MF), a cornerstone of recommender systems, decomposesuser-item interaction matrices into latent representations. Traditional MFapproaches, however, employ a two-stage, non-end-to-end paradigm, sequentiallyperforming recommendation and clustering, resulting in prohibitivecomputational costs for large-scale applications like e-commerce and IoT, wherebillions of users interact with trillions of items. To address this, we proposeMatrix Factorization with Dynamic Multi-view Clustering (MFDMC), a unifiedframework that balances efficient end-to-end training with comprehensiveutilization of web-scale data and enhances interpretability. MFDMC leveragesdynamic multi-view clustering to learn user and item representations,adaptively pruning poorly formed clusters. Each entity's representation ismodeled as a weighted projection of robust clusters, capturing its diverseroles across views. This design maximizes representation space utilization,improves interpretability, and ensures resilience for downstream tasks.Extensive experiments demonstrate MFDMC's superior performance in recommendersystems and other representation learning domains, such as computer vision,highlighting its scalability and versatility.</description>
      <author>example@mail.com (Shangde Gao, Ke Liu, Yichao Fu, Hongxia Xu, Jian Wu)</author>
      <guid isPermaLink="false">2504.14565v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Grounding-MD: Grounded Video-language Pre-training for Open-World Moment Detection</title>
      <link>http://arxiv.org/abs/2504.14553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Grounding-MD的创新视频语言预训练框架，旨在解决开放世界情境下的动作检测和瞬间检索问题。&lt;h4&gt;背景&lt;/h4&gt;动作检测和瞬间检索是视频理解中的关键任务，而现有的方法主要针对封闭集场景，限制了它们在开放世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，研究提出了Grounding-MD框架，用于开放世界的瞬间检测。&lt;h4&gt;方法&lt;/h4&gt;Grounding-MD通过结构化提示机制集成任意数量的开放自然语言查询，利用跨模态融合编码器和文本引导融合解码器，实现视频和文本的全面对齐，并促进跨任务的协作。&lt;h4&gt;主要发现&lt;/h4&gt;通过在大量动作检测和瞬间检索数据集上进行预训练，Grounding-MD展示了出色的语义表示学习能力，有效处理了多样化和复杂查询条件。在ActivityNet、THUMOS14、ActivityNet-Captions和Charades-STA等四个基准数据集上的综合评估表明，Grounding-MD在开放世界的瞬间检测场景中建立了新的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;所有源代码和训练模型将被发布，以促进开放世界瞬间检测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Action Detection and Moment Retrieval constitute two pivotal tasksin video understanding, focusing on precisely localizing temporal segmentscorresponding to specific actions or events. Recent advancements introducedMoment Detection to unify these two tasks, yet existing approaches remainconfined to closed-set scenarios, limiting their applicability in open-worldcontexts. To bridge this gap, we present Grounding-MD, an innovative, groundedvideo-language pre-training framework tailored for open-world moment detection.Our framework incorporates an arbitrary number of open-ended natural languagequeries through a structured prompt mechanism, enabling flexible and scalablemoment detection. Grounding-MD leverages a Cross-Modality Fusion Encoder and aText-Guided Fusion Decoder to facilitate comprehensive video-text alignment andenable effective cross-task collaboration. Through large-scale pre-training ontemporal action detection and moment retrieval datasets, Grounding-MDdemonstrates exceptional semantic representation learning capabilities,effectively handling diverse and complex query conditions. Comprehensiveevaluations across four benchmark datasets including ActivityNet, THUMOS14,ActivityNet-Captions, and Charades-STA demonstrate that Grounding-MDestablishes new state-of-the-art performance in zero-shot and supervisedsettings in open-world moment detection scenarios. All source code and trainedmodels will be released.</description>
      <author>example@mail.com (Weijun Zhuang, Qizhang Li, Xin Li, Ming Liu, Xiaopeng Hong, Feng Gao, Fan Yang, Wangmeng Zuo)</author>
      <guid isPermaLink="false">2504.14553v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Implicit Neural Compression of Point Clouds via Learnable Activation in Latent Space</title>
      <link>http://arxiv.org/abs/2504.14471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于隐式神经网络表示（INR）的静态点云压缩框架PICO，该框架通过几何压缩和属性压缩两个阶段实现点云压缩，并引入了LeAFNet网络架构，提高了压缩效率。&lt;h4&gt;背景&lt;/h4&gt;隐式神经网络表示（INR），也称为神经网络场，是一种在深度学习中强大的范式，使用基于坐标的神经网络参数化连续空间场。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的点云压缩方法。&lt;h4&gt;方法&lt;/h4&gt;将点云压缩任务分解为几何压缩和属性压缩两个阶段，并使用LeAFNet网络架构，该架构利用可学习的激活函数在潜在空间中更好地逼近目标信号的隐函数。通过量化熵编码进一步提高了压缩效率。&lt;h4&gt;主要发现&lt;/h4&gt;LeAFNet在基于INR的点云压缩中优于传统的MLP，PICO在几何压缩方面优于当前的MPEG点云压缩标准，平均D1 PSNR提高了4.92 dB。在联合几何和属性压缩中，该方法表现出极具竞争力的结果，平均PCQM增益为2.7×10^-3。&lt;h4&gt;结论&lt;/h4&gt;PICO框架和LeAFNet网络架构在点云压缩中表现出优异的性能，为点云数据的高效压缩提供了一种新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit Neural Representations (INRs), also known as neural fields, haveemerged as a powerful paradigm in deep learning, parameterizing continuousspatial fields using coordinate-based neural networks. In this paper, wepropose \textbf{PICO}, an INR-based framework for static point cloudcompression. Unlike prevailing encoder-decoder paradigms, we decompose thepoint cloud compression task into two separate stages: geometry compression andattribute compression, each with distinct INR optimization objectives. Inspiredby Kolmogorov-Arnold Networks (KANs), we introduce a novel networkarchitecture, \textbf{LeAFNet}, which leverages learnable activation functionsin the latent space to better approximate the target signal's implicitfunction. By reformulating point cloud compression as neural parametercompression, we further improve compression efficiency through quantization andentropy coding. Experimental results demonstrate that \textbf{LeAFNet}outperforms conventional MLPs in INR-based point cloud compression.Furthermore, \textbf{PICO} achieves superior geometry compression performancecompared to the current MPEG point cloud compression standard, yielding anaverage improvement of $4.92$ dB in D1 PSNR. In joint geometry and attributecompression, our approach exhibits highly competitive results, with an averagePCQM gain of $2.7 \times 10^{-3}$.</description>
      <author>example@mail.com (Yichi Zhang, Qianqian Yang)</author>
      <guid isPermaLink="false">2504.14471v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>RealisDance-DiT: Simple yet Strong Baseline towards Controllable Character Animation in the Wild</title>
      <link>http://arxiv.org/abs/2504.14977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page:  https://thefoxofsky.github.io/project_pages_new/RealisDance-DiT/index&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的可控角色动画方法，通过模型修改和微调策略解决角色动画中的难题，并构建了RealisDance-DiT模型。&lt;h4&gt;背景&lt;/h4&gt;可控角色动画在处理罕见姿势、风格化角色、角色与物体交互、复杂光照和动态场景时具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过模型修改和灵活的微调策略，在野外环境中实现可控角色动画。&lt;h4&gt;方法&lt;/h4&gt;基于Wan-2.1视频基础模型，提出RealisDance-DiT，并对基础模型进行最小修改，引入低噪声预热和“大批次与小迭代”策略加速模型收敛。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示，广泛使用的Reference Net设计对大规模DiT模型不是最优的；基础模型架构的最小修改可以产生强大的基线；新测试数据集能够捕捉多样化的真实世界挑战。&lt;h4&gt;结论&lt;/h4&gt;RealisDance-DiT在实验中优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;可控角色动画在处理罕见姿势、风格化角色、角色与物体交互、复杂光照和动态场景时仍然是一个具有挑战性的问题。为了解决这些问题，先前的工作主要集中在通过精心设计的旁路网络注入姿态和外观指导，但通常难以推广到开放世界场景。在这篇论文中，我们提出了一种新的观点，即只要基础模型足够强大，简单的模型修改和灵活的微调策略可以很大程度上解决上述挑战，向在野外环境中实现可控角色动画迈出一步。具体来说，我们引入了基于Wan-2.1视频基础模型的RealisDance-DiT。我们充分的分析表明，广泛采用的Reference Net设计对于大规模DiT模型不是最优的。相反，我们证明了基础模型架构的最小修改会产生令人惊讶的强大基线。我们进一步提出了低噪声预热和“大批次和小迭代”策略，以在微调期间加速模型收敛，同时最大限度地保留基础模型的前验信息。此外，我们引入了一个新的测试数据集，该数据集能够捕捉多样化的真实世界挑战，补充了现有的基准，如TikTok数据集和UBC时尚视频数据集，以全面评估所提出的方法。广泛的实验表明，RealisDance-DiT在性能上显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controllable character animation remains a challenging problem, particularlyin handling rare poses, stylized characters, character-object interactions,complex illumination, and dynamic scenes. To tackle these issues, prior workhas largely focused on injecting pose and appearance guidance via elaboratebypass networks, but often struggles to generalize to open-world scenarios. Inthis paper, we propose a new perspective that, as long as the foundation modelis powerful enough, straightforward model modifications with flexiblefine-tuning strategies can largely address the above challenges, taking a steptowards controllable character animation in the wild. Specifically, weintroduce RealisDance-DiT, built upon the Wan-2.1 video foundation model. Oursufficient analysis reveals that the widely adopted Reference Net design issuboptimal for large-scale DiT models. Instead, we demonstrate that minimalmodifications to the foundation model architecture yield a surprisingly strongbaseline. We further propose the low-noise warmup and "large batches and smalliterations" strategies to accelerate model convergence during fine-tuning whilemaximally preserving the priors of the foundation model. In addition, weintroduce a new test dataset that captures diverse real-world challenges,complementing existing benchmarks such as TikTok dataset and UBC fashion videodataset, to comprehensively evaluate the proposed method. Extensive experimentsshow that RealisDance-DiT outperforms existing methods by a large margin.</description>
      <author>example@mail.com (Jingkai Zhou, Yifan Wu, Shikai Li, Min Wei, Chao Fan, Weihua Chen, Wei Jiang, Fan Wang)</author>
      <guid isPermaLink="false">2504.14977v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Spiking Point Mamba for Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2504.14371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Mamba的3D领域SNN（Spiking Neural Networks）模型，名为Spiking Point Mamba（SPM），旨在高效提取3D时空特征。&lt;h4&gt;背景&lt;/h4&gt;现有的3D SNN在处理长距离依赖关系方面存在困难，直到Mamba的出现，它提供了卓越的计算效率和序列建模能力。&lt;h4&gt;目的&lt;/h4&gt;设计SPM以利用Mamba的序列建模能力和SNN的时间特征提取能力，提高3D SNN的性能。&lt;h4&gt;方法&lt;/h4&gt;SPM通过引入分层动态编码（HDE）和Spiking Mamba块（SMB）来实现。HDE是一种改进的直接编码方法，有效引入动态时间机制，促进时间交互；SMB在Mamba的基础上学习跨时间步的特征，并最小化由脉冲引起的信损失。此外，采用非对称SNN-ANN架构进行脉冲预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;SPM在ScanObjectNN的三个变体上提高了OA（平均精度）分别为+6.2%、+6.1%和+7.4%，在ShapeNetPart上提升了instance mIOU（实例交并比）+1.9%。同时，其能耗至少比其ANN（人工神经网络）对应版本低3.5倍。&lt;h4&gt;结论&lt;/h4&gt;SPM是一个高效的3D SNN模型，在保持高性能的同时，具有显著降低能耗的优势。&lt;h4&gt;翻译&lt;/h4&gt;Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing 3D SNNs have struggled with long-range dependencies until the recent emergence of Mamba, which offers superior computational efficiency and sequence modeling capability. In this work, we propose Spiking Point Mamba (SPM), the first Mamba-based SNN in the 3D domain. Due to the poor performance of simply transferring Mamba to 3D SNNs, SPM is designed to utilize both the sequence modeling capabilities of Mamba and the temporal feature extraction of SNNs. Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), an improved direct encoding method that effectively introduces dynamic temporal mechanism, thereby facilitating temporal interactions. Then, we propose a Spiking Mamba Block (SMB), which builds upon Mamba while learning inter-time-step features and minimizing information loss caused by spikes. Finally, to further enhance model performance, we adopt an asymmetric SNN-ANN architecture for spike-based pre-training and finetune. Compared with the previous state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and +7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% on ShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower than that of its ANN counterpart. The code will be made publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bio-inspired Spiking Neural Networks (SNNs) provide an energy-efficient wayto extract 3D spatio-temporal features. However, existing 3D SNNs havestruggled with long-range dependencies until the recent emergence of Mamba,which offers superior computational efficiency and sequence modelingcapability. In this work, we propose Spiking Point Mamba (SPM), the firstMamba-based SNN in the 3D domain. Due to the poor performance of simplytransferring Mamba to 3D SNNs, SPM is designed to utilize both the sequencemodeling capabilities of Mamba and the temporal feature extraction of SNNs.Specifically, we first introduce Hierarchical Dynamic Encoding (HDE), animproved direct encoding method that effectively introduces dynamic temporalmechanism, thereby facilitating temporal interactions. Then, we propose aSpiking Mamba Block (SMB), which builds upon Mamba while learninginter-time-step features and minimizing information loss caused by spikes.Finally, to further enhance model performance, we adopt an asymmetric SNN-ANNarchitecture for spike-based pre-training and finetune. Compared with theprevious state-of-the-art SNN models, SPM improves OA by +6.2%, +6.1%, and+7.4% on three variants of ScanObjectNN, and boosts instance mIOU by +1.9% onShapeNetPart. Meanwhile, its energy consumption is at least 3.5x lower thanthat of its ANN counterpart. The code will be made publicly available.</description>
      <author>example@mail.com (Peixi Wu, Bosong Chai, Menghua Zheng, Wei Li, Zhangchi Hu, Jie Chen, Zheyu Zhang, Hebei Li, Xiaoyan Sun)</author>
      <guid isPermaLink="false">2504.14371v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Generative Semantic Communications: Principles and Practices</title>
      <link>http://arxiv.org/abs/2504.14947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了基于人工智能技术的语义通信新范式，旨在降低通信成本，并探讨了在向通用人工智能（AGI）发展的背景下，语义通信面临的新挑战及解决方案。&lt;h4&gt;背景&lt;/h4&gt;语义通信利用人工智能技术从数据中提取语义信息，以实现高效传输。随着通用人工智能（AGI）的演进，对AGI服务的需求增加，给语义通信带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的通信范式，称为生成式语义通信（GSC），以应对AGI驱动下的通信需求。&lt;h4&gt;方法&lt;/h4&gt;介绍了GSC的基本概念和与现有语义通信的区别，提出了GSC的一般框架，并通过两个案例研究验证了GSC在AGI驱动应用中的优势。&lt;h4&gt;主要发现&lt;/h4&gt;GSC利用了如基础模型和生成模型等先进的人工智能技术，能够有效降低通信成本，并在AGI驱动应用中展现出优势。&lt;h4&gt;结论&lt;/h4&gt;论文讨论了语义通信在AGI时代的开放挑战和新研究方向，以促进该领域的研究，并为实际应用铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new paradigm for semantic communication based on artificial intelligence technologies, aiming to reduce communication costs and discusses the new challenges and solutions for semantic communication in the context of the evolution towards artificial general intelligence (AGI).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic communication leverages artificial intelligence (AI) technologies toextract semantic information from data for efficient transmission, therabysignificantly reducing communication cost. With the evolution towardsartificial general intelligence (AGI), the increasing demands for AGI servicespose new challenges to semantic communication. In response, we propose a newparadigm for AGI-driven communications, called generative semanticcommunication (GSC), which utilizes advanced AI technologies such as foundationmodels and generative models. We first describe the basic concept of GSC andits difference from existing semantic communications, and then introduce ageneral framework of GSC, followed by two case studies to verify the advantagesof GSC in AGI-driven applications. Finally, open challenges and new researchdirections are discussed to stimulate this line of research and pave the wayfor practical applications.</description>
      <author>example@mail.com (Xiaojun Yuan, Haoming Ma, Yinuo Huang, Zhoufan Hua, Yong Zuo, Zhi Ding)</author>
      <guid isPermaLink="false">2504.14947v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>CSI2Dig: Recovering Digit Content from Smartphone Loudspeakers Using Channel State Information</title>
      <link>http://arxiv.org/abs/2504.14812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CSI2Dig的方案，用于从手机扬声器的信道状态信息（CSI）中恢复数字内容，以应对通过扬声器发出的声音被窃听所可能泄露的敏感数字信息。&lt;h4&gt;背景&lt;/h4&gt;现有的窃听方案可能需要昂贵的专用设备、依赖间谍软件，或者仅限于近距离信号采集，存在安全风险。&lt;h4&gt;目的&lt;/h4&gt;设计一种方案，能够从手机扬声器的CSI中恢复数字内容，提高数字信息的安全性。&lt;h4&gt;方法&lt;/h4&gt;该方案基于对比学习和降噪自编码器，构建了一个双分支自动编码器网络，以放大扬声器音频信号产生的电磁干扰对CSI的影响。引入了TS-Net模型，用于从CSI数据的时空维度捕捉相关特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方案在各种设备、距离、音量和其他设置下都能达到72.97%的准确率。&lt;h4&gt;结论&lt;/h4&gt;CSI2Dig方案能够有效从手机扬声器的CSI中恢复数字内容，提高数字信息的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Eavesdropping on sounds emitted by mobile device loudspeakers can capturesensitive digital information, such as SMS verification codes, credit cardnumbers, and withdrawal passwords, which poses significant security risks.Existing schemes either require expensive specialized equipment, rely onspyware, or are limited to close-range signal acquisition. In this paper, wepropose a scheme, CSI2Dig, for recovering digit content from Channel StateInformation (CSI) when digits are played through a smartphone loudspeaker. Weobserve that the electromagnetic interference caused by the audio signals fromthe loudspeaker affects the WiFi signals emitted by the phone's WiFi antenna.Building upon contrastive learning and denoising autoencoders, we develop atwo-branch autoencoder network designed to amplify the impact of thiselectromagnetic interference on CSI. For feature extraction, we introduce theTS-Net, a model that captures relevant features from both the temporal andspatial dimensions of the CSI data. We evaluate our scheme across variousdevices, distances, volumes, and other settings. Experimental resultsdemonstrate that our scheme can achieve an accuracy of 72.97%.</description>
      <author>example@mail.com (Yangyang Gu, Xianglong Li, Haolin Wu, Jing Chen, Kun He, Ruiying Du, Cong Wu)</author>
      <guid isPermaLink="false">2504.14812v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>LBM-GNN: Graph Neural Network Enhanced Lattice Boltzmann Method</title>
      <link>http://arxiv.org/abs/2504.14494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LBM-GNN的新方法，该方法通过结合格点Boltzmann方法（LBM）和图神经网络（GNN）来提升传统LBM的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的LBM方法在流体动力学模拟中存在稳定性和精度的问题。&lt;h4&gt;目的&lt;/h4&gt;通过将GNN与LBM结合，旨在提高LBM的稳定性和精度。&lt;h4&gt;方法&lt;/h4&gt;应用LBM-GNN方法到流体动力学模拟中，并与标准LBM方法进行比较。验证方法包括使用泰勒-格林涡旋等基准问题，关注精度、守恒性质和不同雷诺数及网格分辨率下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GNN增强的LBM在更高雷诺数下能够保持更好的守恒性质，同时提高数值稳定性。&lt;h4&gt;结论&lt;/h4&gt;LBM-GNN方法在流体动力学模拟中显示出优于传统LBM方法的表现。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种名为LBM-GNN的新方法，该方法通过结合传统的格点Boltzmann方法（LBM）与图神经网络（GNN）来提升性能。我们将此方法应用于流体动力学模拟，与标准LBM实现相比，展示了更高的稳定性和精度。该方法通过基准问题如泰勒-格林涡旋进行验证，关注精度、守恒特性和在不同雷诺数和网格分辨率下的性能。我们的结果表明，GNN增强的LBM能够在更高雷诺数下保持更好的守恒性质，同时提高数值稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present LBM-GNN, a novel approach that enhances thetraditional Lattice Boltzmann Method (LBM) with Graph Neural Networks (GNNs).We apply this method to fluid dynamics simulations, demonstrating improvedstability and accuracy compared to standard LBM implementations. The method isvalidated using benchmark problems such as the Taylor-Green vortex, focusing onaccuracy, conservation properties, and performance across different Reynoldsnumbers and grid resolutions. Our results indicate that GNN-enhanced LBM canmaintain better conservation properties while improving numerical stability athigher Reynolds numbers.</description>
      <author>example@mail.com (Yue Li)</author>
      <guid isPermaLink="false">2504.14494v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Score</title>
      <link>http://arxiv.org/abs/2504.14302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在目标标签不可用但存在相关附加信息的情况下，如何利用这些信息进行机器学习。&lt;h4&gt;背景&lt;/h4&gt;常见的机器学习设置包括监督学习、半监督学习和弱监督学习，以及无监督学习。本文关注的是无标签数据的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的评分模型，用于处理无标签数据，并通过附加信息提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为包含三个语义组件的集成：表示学习、附加信息和度量学习。&lt;h4&gt;主要发现&lt;/h4&gt;该评分模型在医疗保健领域具有应用潜力，例如创建疾病严重度评分，其中已知症状但疾病进展标准不明确。&lt;h4&gt;结论&lt;/h4&gt;提出的评分系统在标准数据集和生物医学患者记录上证明了其效用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：常见的机器学习设置从可访问准确标记数据的监督任务，到目标标签稀缺或噪声的半监督和弱监督任务，再到无标签任务，其中标签无法获得。在本文中，我们研究了一种目标标签不可用但附加相关信息可用的情况。这些信息，称为侧信息，要么与未知标签相关联，要么对特征空间施加约束。我们将问题建模为三个语义组件的集成：表示学习、侧信息和学习度量。所提出的评分模型对多个用例具有优势。例如，在医疗保健领域，它可以用于创建已知症状但疾病进展标准不明确的疾病的严重度评分。我们展示了所提出的评分系统在标准数据集和生物医学患者记录上的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Common machine learning settings range from supervised tasks, whereaccurately labeled data is accessible, through semi-supervised andweakly-supervised tasks, where target labels are scant or noisy, tounsupervised tasks where labels are unobtainable. In this paper we study ascenario where the target labels are not available but additional relatedinformation is at hand. This information, referred to as Side Information, iseither correlated with the unknown labels or imposes constraints on the featurespace. We formulate the problem as an ensemble of three semantic components:representation learning, side information and metric learning. The proposedscoring model is advantageous for multiple use-cases. For example, in thehealthcare domain it can be used to create a severity score for diseases wherethe symptoms are known but the criteria for the disease progression are notwell defined. We demonstrate the utility of the suggested scoring system onwell-known benchmark data-sets and bio-medical patient records.</description>
      <author>example@mail.com (Yogev Kriger, Shai Fine)</author>
      <guid isPermaLink="false">2504.14302v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>ResNetVLLM -- Multi-modal Vision LLM for the Video Understanding Task</title>
      <link>http://arxiv.org/abs/2504.14432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ResNetVLLM（ResNet视觉LLM），这是一种新型的跨模态框架，用于零样本视频理解，它将基于ResNet的视觉编码器与大型语言模型（LLM）相结合。&lt;h4&gt;背景&lt;/h4&gt;本文旨在解决零样本视频模型面临的挑战，避免依赖预训练的视频理解模型，而是使用未预训练的ResNet提取视觉特征。&lt;h4&gt;目的&lt;/h4&gt;该设计确保模型在统一架构中学习视觉和语义表示，提高其从视频输入生成准确且与上下文相关的文本描述的能力。&lt;h4&gt;方法&lt;/h4&gt;ResNetVLLM通过结合ResNet视觉编码器和LLM，避免了依赖预训练模型，并实现了视觉和语义表示的统一学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ResNetVLLM在多个基准测试中实现了零样本视频理解（ZSVU）的最先进性能，包括MSRVTT-QA、MSVD-QA、TGIF-QA FrameQA和ActivityNet-QA。&lt;h4&gt;结论&lt;/h4&gt;ResNetVLLM在零样本视频理解领域取得了显著成果，为视频理解技术的发展提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce ResNetVLLM (ResNet Vision LLM), a novel cross-modal framework for zero-shot video understanding that integrates a ResNet-based visual encoder with a Large Language Model (LLM). ResNetVLLM addresses the challenges associated with zero-shot video models by avoiding reliance on pre-trained video understanding models and instead employing an unpretrained ResNet to extract visual features. This design ensures the model learns visual and semantic representations within a unified architecture, enhancing its ability to generate accurate and contextually relevant textual descriptions from video inputs. Our experimental results demonstrate that ResNetVLLM achieves state-of-the-art performance in zero-shot video understanding (ZSVU) on several benchmarks, including MSRVTT-QA, MSVD-QA, TGIF-QA FrameQA, and ActivityNet-QA.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce ResNetVLLM (ResNet Vision LLM), a novelcross-modal framework for zero-shot video understanding that integrates aResNet-based visual encoder with a Large Language Model (LLM. ResNetVLLMaddresses the challenges associated with zero-shot video models by avoidingreliance on pre-trained video understanding models and instead employing anon-pretrained ResNet to extract visual features. This design ensures the modellearns visual and semantic representations within a unified architecture,enhancing its ability to generate accurate and contextually relevant textualdescriptions from video inputs. Our experimental results demonstrate thatResNetVLLM achieves state-of-the-art performance in zero-shot videounderstanding (ZSVU) on several benchmarks, including MSRVTT-QA, MSVD-QA,TGIF-QA FrameQA, and ActivityNet-QA.</description>
      <author>example@mail.com (Ahmad Khalil, Mahmoud Khalil, Alioune Ngom)</author>
      <guid isPermaLink="false">2504.14432v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Multispectral airborne laser scanning for tree species classification: a benchmark of machine learning and deep learning algorithms</title>
      <link>http://arxiv.org/abs/2504.14337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过对比多种机器学习和深度学习方法在树木物种分类中的应用，探讨了高密度多光谱激光扫描数据在森林资源调查中的潜力。&lt;h4&gt;背景&lt;/h4&gt;精准的森林资源信息对于智能林业和生物多样性保护至关重要。多光谱空中激光扫描（ALS）在自动化点云处理和树木分割方面显示出潜力，但在识别稀有树种和利用深度学习技术方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;通过基准测试，评估机器学习和深度学习方法在树木物种分类中的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用FGI开发的HeliALS系统收集高密度多光谱ALS数据（&gt;1000个点/m²）和Optech Titan数据（35个点/m²），在芬兰南部的测试站点评估算法的物种分类准确率。&lt;h4&gt;主要发现&lt;/h4&gt;基于5261个测试段，点云深度学习方法，尤其是点Transformer模型，在处理高密度多光谱点云时优于传统机器学习和基于图像的深度学习方法。点Transformer模型在处理高密度ALS数据时，准确率达到87.9%（宏平均），而最佳图像深度学习方法DetailView的准确率为84.3%（宏平均），随机森林（RF）分类器的准确率为83.2%（宏平均）。&lt;h4&gt;结论&lt;/h4&gt;点Transformer模型在集成所有三个通道的光谱信息后，分类准确率从没有光谱信息的73.0%提高到单通道反射率的84.7%，最终达到87.9%。&lt;h4&gt;翻译&lt;/h4&gt;This study investigates the potential of high-density multispectral laser scanning data in forest resource surveys through a comprehensive benchmark of machine learning and deep learning methods for tree species classification.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Climate-smart and biodiversity-preserving forestry demands preciseinformation on forest resources, extending to the individual tree level.Multispectral airborne laser scanning (ALS) has shown promise in automatedpoint cloud processing and tree segmentation, but challenges remain inidentifying rare tree species and leveraging deep learning techniques. Thisstudy addresses these gaps by conducting a comprehensive benchmark of machinelearning and deep learning methods for tree species classification. For thestudy, we collected high-density multispectral ALS data (&gt;1000 pts/m$^2$) atthree wavelengths using the FGI-developed HeliALS system, complemented byexisting Optech Titan data (35 pts/m$^2$), to evaluate the speciesclassification accuracy of various algorithms in a test site located inSouthern Finland. Based on 5261 test segments, our findings demonstrate thatpoint-based deep learning methods, particularly a point transformer model,outperformed traditional machine learning and image-based deep learningapproaches on high-density multispectral point clouds. For the high-density ALSdataset, a point transformer model provided the best performance reaching anoverall (macro-average) accuracy of 87.9% (74.5%) with a training set of 1065segments and 92.0% (85.1%) with 5000 training segments. The best image-baseddeep learning method, DetailView, reached an overall (macro-average) accuracyof 84.3% (63.9%), whereas a random forest (RF) classifier achieved an overall(macro-average) accuracy of 83.2% (61.3%). Importantly, the overallclassification accuracy of the point transformer model on the HeliALS dataincreased from 73.0% with no spectral information to 84.7% with single-channelreflectance, and to 87.9% with spectral information of all the three channels.</description>
      <author>example@mail.com (Josef Taher, Eric Hyyppä, Matti Hyyppä, Klaara Salolahti, Xiaowei Yu, Leena Matikainen, Antero Kukko, Matti Lehtomäki, Harri Kaartinen, Sopitta Thurachen, Paula Litkey, Ville Luoma, Markus Holopainen, Gefei Kong, Hongchao Fan, Petri Rönnholm, Antti Polvivaara, Samuli Junttila, Mikko Vastaranta, Stefano Puliti, Rasmus Astrup, Joel Kostensalo, Mari Myllymäki, Maksymilian Kulicki, Krzysztof Stereńczak, Raul de Paula Pires, Ruben Valbuena, Juan Pedro Carbonell-Rivera, Jesús Torralba, Yi-Chen Chen, Lukas Winiwarter, Markus Hollaus, Gottfried Mandlburger, Narges Takhtkeshha, Fabio Remondino, Maciej Lisiewicz, Bartłomiej Kraszewski, Xinlian Liang, Jianchang Chen, Eero Ahokas, Kirsi Karila, Eugeniu Vezeteu, Petri Manninen, Roope Näsi, Heikki Hyyti, Siiri Pyykkönen, Peilun Hu, Juha Hyyppä)</author>
      <guid isPermaLink="false">2504.14337v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment</title>
      <link>http://arxiv.org/abs/2504.14805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; 23 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比技能学习（DCSL）的新框架，用于解决强化学习在长时程任务和复杂决策中的扩展问题。&lt;h4&gt;背景&lt;/h4&gt;强化学习在多个领域取得了显著进展，但在处理长时程任务和复杂决策时，其扩展性仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DCSL框架，以解决现有方法在识别相似行为和技能长度固定方面的问题，从而提高技能学习的灵活性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;DCSL框架包含三个关键思想：基于状态转换的技能表示、技能相似性函数学习以及动态技能长度调整。&lt;h4&gt;主要发现&lt;/h4&gt;DCSL通过关注状态转换和利用对比学习，有效地捕捉了行为语义上下文，并能够根据行为的时间跨度动态调整技能长度。&lt;h4&gt;结论&lt;/h4&gt;DCSL在复杂或噪声数据集上实现了更灵活和自适应的技能提取，并在任务完成和效率方面与现有方法相比表现出竞争力。&lt;h4&gt;翻译&lt;/h4&gt;Reinforcement learning (RL) has made significant progress in various domains,but scaling it to long-horizon tasks with complex decision-making remainschallenging. Skill learning attempts to address this by abstracting actionsinto higher-level behaviors. However, current approaches often fail torecognize semantically similar behaviors as the same skill and use fixed skilllengths, limiting flexibility and generalization. To address this, we proposeDynamic Contrastive Skill Learning (DCSL), a novel framework that redefinesskill representation and learning. DCSL introduces three key ideas:state-transition based skill representation, skill similarity function learning, anddynamic skill length adjustment. By focusing on state transitions andleveraging contrastive learning, DCSL effectively captures the semanticcontext of behaviors and adapts skill lengths to match the appropriate temporalextent of behaviors. Our approach enables more flexible and adaptive skillextraction, particularly in complex or noisy datasets, and demonstratescompetitive performance compared to existing methods in task completion andefficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has made significant progress in various domains,but scaling it to long-horizon tasks with complex decision-making remainschallenging. Skill learning attempts to address this by abstracting actionsinto higher-level behaviors. However, current approaches often fail torecognize semantically similar behaviors as the same skill and use fixed skilllengths, limiting flexibility and generalization. To address this, we proposeDynamic Contrastive Skill Learning (DCSL), a novel framework that redefinesskill representation and learning. DCSL introduces three key ideas:state-transition based skill representation, skill similarity functionlearning, and dynamic skill length adjustment. By focusing on state transitionsand leveraging contrastive learning, DCSL effectively captures the semanticcontext of behaviors and adapts skill lengths to match the appropriate temporalextent of behaviors. Our approach enables more flexible and adaptive skillextraction, particularly in complex or noisy datasets, and demonstratescompetitive performance compared to existing methods in task completion andefficiency.</description>
      <author>example@mail.com (Jinwoo Choi, Seung-Woo Seo)</author>
      <guid isPermaLink="false">2504.14805v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Beamforming Design and Association Scheme for Multi-RIS Multi-User mmWave Systems Through Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.14464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Wireless Communications(TWC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的异构图神经网络（GNN）来有效地利用无线通信环境的拓扑结构，以提高多RIS多用户毫米波通信系统的容量。&lt;h4&gt;背景&lt;/h4&gt;可重构智能表面（RIS）技术是下一代无线通信网络的有希望的技术，它能够定制通信环境，部署多个RIS可以减轻基站与用户之间的信号阻塞，从而提高服务覆盖率。&lt;h4&gt;目的&lt;/h4&gt;为了充分发挥多RIS辅助通信系统的潜力，本文旨在解决非凸优化问题，并采用基于学习的策略来确定最优策略。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一种关联方案，为每个用户选择合适的RIS，并通过迭代优化RIS关联方案和波束成形设计来最大化所有用户的加权总和速率（WSR），直到异构GNN收敛。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，提出的异构GNN在考虑的多RIS辅助通信系统中接近高复杂度交替优化（AO）算法的性能，并且优于其他基准方案。RIS关联方案带来的性能提升达到30%。&lt;h4&gt;结论&lt;/h4&gt;基于所提出的方法，每个用户都关联到最佳的RIS，显著提高了多RIS多用户毫米波通信系统的容量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可重构智能表面（RIS）作为下一代无线通信网络的很有希望的技术正在兴起，它提供了一系列优点，如定制通信环境的能力。此外，部署多个RIS有助于减轻基站（BS）和用户之间的严重信号阻塞，为增强服务覆盖范围提供了一个实际且高效的解决方案。然而，要充分发挥多RIS辅助通信系统的潜力，需要解决非凸优化问题。这一挑战促使采用基于学习的策略来确定最优策略。在本文中，我们介绍了一种新型的异构图神经网络（GNN），以有效地利用无线通信环境的拓扑结构。具体而言，我们设计了一种关联方案，为每个用户选择合适的RIS。然后，我们通过迭代优化RIS关联方案和波束成形设计，直到考虑的异构GNN收敛，来最大化所有用户的加权总和速率（WSR）。基于所提出的方法，每个用户都关联到最佳的RIS，这表明显著提高了多RIS多用户毫米波通信系统的容量。特别是，仿真结果表明，所提出的异构GNN在考虑的多RIS辅助通信系统中接近高复杂度交替优化（AO）算法的性能，并且优于其他基准方案。此外，通过RIS关联方案获得的性能提升表明，其性能提升的量级为30%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconfigurable intelligent surface (RIS) is emerging as a promisingtechnology for next-generation wireless communication networks, offering avariety of merits such as the ability to tailor the communication environment.Moreover, deploying multiple RISs helps mitigate severe signal blocking betweenthe base station (BS) and users, providing a practical and efficient solutionto enhance the service coverage. However, fully reaping the potential of amulti-RIS aided communication system requires solving a non-convex optimizationproblem. This challenge motivates the adoption of learning-based methods fordetermining the optimal policy. In this paper, we introduce a novelheterogeneous graph neural network (GNN) to effectively leverage the graphtopology of a wireless communication environment. Specifically, we design anassociation scheme that selects a suitable RIS for each user. Then, we maximizethe weighted sum rate (WSR) of all the users by iteratively optimizing the RISassociation scheme, and beamforming designs until the considered heterogeneousGNN converges. Based on the proposed approach, each user is associated with thebest RIS, which is shown to significantly improve the system capacity inmulti-RIS multi-user millimeter wave (mmWave) communications. Specifically,simulation results demonstrate that the proposed heterogeneous GNN closelyapproaches the performance of the high-complexity alternating optimization (AO)algorithm in the considered multi-RIS aided communication system, and itoutperforms other benchmark schemes. Moreover, the performance improvementachieved through the RIS association scheme is shown to be of the order of 30%.</description>
      <author>example@mail.com (Mengbing Liu, Chongwen Huang, Ahmed Alhammadi, Marco Di Renzo, Merouane Debbah, Chau Yuen)</author>
      <guid isPermaLink="false">2504.14464v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?</title>
      <link>http://arxiv.org/abs/2504.14391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;公开的生物医学视频，如YouTube上的视频，是医学学生的宝贵教育资源。本研究探讨了这些非标准化和异构的视频是否能够有效地教授通用领域视觉-语言模型生物医学知识。&lt;h4&gt;背景&lt;/h4&gt;公开的生物医学视频通常包含医疗图像、解说、解释图表和情境框架，旨在为人类学习者提供教育资源。&lt;h4&gt;目的&lt;/h4&gt;研究非标准化和异构的生物医学视频是否能够有效地教学通用领域视觉-语言模型生物医学知识。&lt;h4&gt;方法&lt;/h4&gt;引入了OpenBiomedVi数据集，包含1031小时的视频-字幕和问答对，通过多步骤人工干预的流程精心整理。此外，还引入了两个新的专家精心编制的基准测试：MIMICEchoQA和SurgeryVideoQA。&lt;h4&gt;主要发现&lt;/h4&gt;尽管这些视频非正式且异构，但微调后的Qwen-2-VL模型在大多数基准测试中表现出显著的性能提升。2B模型在视频任务上提高了98.7%，在图像任务上提高了71.2%，在文本任务上提高了0.2%。7B模型在视频任务上提高了37.09%，在图像任务上提高了11.2%，但在文本任务上略有下降，比基线模型降低了2.7%。&lt;h4&gt;结论&lt;/h4&gt;为人类学习而创建的教育视频为生物医学视觉-语言模型提供了惊人的有效训练信号。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Publicly available biomedical videos, such as those on YouTube, serve asvaluable educational resources for medical students. Unlike standard machinelearning datasets, these videos are designed for human learners, often mixingmedical imagery with narration, explanatory diagrams, and contextual framing.In this work, we investigate whether such pedagogically rich, yetnon-standardized and heterogeneous videos can effectively teach general-domainvision-language models biomedical knowledge. To this end, we introduceOpenBiomedVi, a biomedical video instruction tuning dataset comprising 1031hours of video-caption and Q/A pairs, curated through a multi-stephuman-in-the-loop pipeline. Diverse biomedical video datasets are rare, andOpenBiomedVid fills an important gap by providing instruction-style supervisiongrounded in real-world educational content. Surprisingly, despite the informaland heterogeneous nature of these videos, the fine-tuned Qwen-2-VL modelsexhibit substantial performance improvements across most benchmarks. The 2Bmodel achieves gains of 98.7% on video tasks, 71.2% on image tasks, and 0.2% ontext tasks. The 7B model shows improvements of 37.09% on video and 11.2% onimage tasks, with a slight degradation of 2.7% on text tasks compared to theirrespective base models. To address the lack of standardized biomedical videoevaluation datasets, we also introduce two new expert curated benchmarks,MIMICEchoQA and SurgeryVideoQA. On these benchmarks, the 2B model achievesgains of 99.1% and 98.1%, while the 7B model shows gains of 22.5% and 52.1%,respectively, demonstrating the models' ability to generalize and performbiomedical video understanding on cleaner and more standardized datasets thanthose seen during training. These results suggest that educational videoscreated for human learning offer a surprisingly effective training signal forbiomedical VLMs.</description>
      <author>example@mail.com (Rahul Thapa, Andrew Li, Qingyang Wu, Bryan He, Yuki Sahashi, Christina Binder, Angela Zhang, Ben Athiwaratkun, Shuaiwen Leon Song, David Ouyang, James Zou)</author>
      <guid isPermaLink="false">2504.14391v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>HoLa: B-Rep Generation using a Holistic Latent Representation</title>
      <link>http://arxiv.org/abs/2504.14257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的表示方法，用于学习和生成计算机辅助设计（CAD）模型，该表示方法采用边界表示（B-Reps）的形式，并基于整体潜在空间（HoLa）统一了不同顺序的B-Reps原语的连续几何属性及其离散拓扑关系。&lt;h4&gt;背景&lt;/h4&gt;现有方法在处理B-Reps模型时存在模糊性、冗余和不一致性，以及训练复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以减少生成的B-Reps原语之间的模糊性、冗余和不一致性，同时降低训练复杂性，并显著提高模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过学习区分和从一对表面原语中推导曲线几何形状，消除潜在空间中曲线、顶点和所有拓扑连接的存在，将拓扑学习在B-Reps中重新表述为欧几里得空间中的几何重建问题。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在表面、曲线、顶点和它们的拓扑关系上编码了一个完整的B-Reps模型，并设计了一个基于扩散的第一代生成器，能够处理包括点云、单/多视图图像、2D草图和文本提示在内的各种输入。&lt;h4&gt;结论&lt;/h4&gt;该方法显著减少了生成的B-Reps原语之间的模糊性、冗余和不一致性，以及先前多步B-Reps学习管道中固有的训练复杂性，同时实现了比当前最先进技术更高的有效性率：82% 对 50% 左右。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel representation for learning and generatingComputer-Aided Design (CAD) models in the form of $\textit{boundaryrepresentations}$ (B-Reps). Our representation unifies the continuous geometricproperties of B-Rep primitives in different orders (e.g., surfaces and curves)and their discrete topological relations in a $\textit{holistic latent}$ (HoLa)space. This is based on the simple observation that the topological connectionbetween two surfaces is intrinsically tied to the geometry of theirintersecting curve. Such a prior allows us to reformulate topology learning inB-Reps as a geometric reconstruction problem in Euclidean space. Specifically,we eliminate the presence of curves, vertices, and all the topologicalconnections in the latent space by learning to distinguish and derive curvegeometries from a pair of surface primitives via a neural intersection network.To this end, our holistic latent space is only defined on surfaces but encodesa full B-Rep model, including the geometry of surfaces, curves, vertices, andtheir topological relations. Our compact and holistic latent space facilitatesthe design of a first diffusion-based generator to take on a large variety ofinputs including point clouds, single/multi-view images, 2D sketches, and textprompts. Our method significantly reduces ambiguities, redundancies, andincoherences among the generated B-Rep primitives, as well as trainingcomplexities inherent in prior multi-step B-Rep learning pipelines, whileachieving greatly improved validity rate over current state of the art: 82% vs.$\approx$50%.</description>
      <author>example@mail.com (Yilin Liu, Duoteng Xu, Xingyao Yu, Xiang Xu, Daniel Cohen-Or, Hao Zhang, Hui Huang)</author>
      <guid isPermaLink="false">2504.14257v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>SuperCL: Superpixel Guided Contrastive Learning for Medical Image Segmentation Pre-training</title>
      <link>http://arxiv.org/abs/2504.14737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SuperCL的新型对比学习方法，用于医学图像分割预训练，以解决现有方法在获取高质量标注图像数据集方面的困难。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割是关键但具有挑战性的任务，主要因为难以获取大量高质量、专家标注的图像数据集。&lt;h4&gt;目的&lt;/h4&gt;提出SuperCL以解决现有方法在提取实例级或像素到像素表示时忽略图像内部相似像素组特征的问题，并提高对比对生成效率。&lt;h4&gt;方法&lt;/h4&gt;SuperCL通过引入两种新颖的对比对生成策略（图像内部局部对比对生成和图像间全局对比对生成）来利用图像的结构先验和像素相关性。此外，还提出了两个模块（平均超像素特征图生成和连通组件标签生成）以更好地利用先验结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;在8个医学图像数据集上的实验表明，SuperCL优于现有的12种方法，实现了更精确的预测，在MMWHS、CHAOS、脾脏数据集上分别提高了3.15%、5.44%、7.89%的DSC。&lt;h4&gt;结论&lt;/h4&gt;SuperCL在医学图像分割预训练方面取得了显著的性能提升，代码将在接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation is a critical yet challenging task, primarily dueto the difficulty of obtaining extensive datasets of high-quality,expert-annotated images. Contrastive learning presents a potential but stillproblematic solution to this issue. Because most existing methods focus onextracting instance-level or pixel-to-pixel representation, which ignores thecharacteristics between intra-image similar pixel groups. Moreover, whenconsidering contrastive pairs generation, most SOTA methods mainly rely onmanually setting thresholds, which requires a large number of gradientexperiments and lacks efficiency and generalization. To address these issues,we propose a novel contrastive learning approach named SuperCL for medicalimage segmentation pre-training. Specifically, our SuperCL exploits thestructural prior and pixel correlation of images by introducing two novelcontrastive pairs generation strategies: Intra-image Local Contrastive Pairs(ILCP) Generation and Inter-image Global Contrastive Pairs (IGCP) Generation.Considering superpixel cluster aligns well with the concept of contrastivepairs generation, we utilize the superpixel map to generate pseudo masks forboth ILCP and IGCP to guide supervised contrastive learning. Moreover, we alsopropose two modules named Average SuperPixel Feature Map Generation (ASP) andConnected Components Label Generation (CCL) to better exploit the priorstructural information for IGCP. Finally, experiments on 8 medical imagedatasets indicate our SuperCL outperforms existing 12 methods. i.e. Our SuperCLachieves a superior performance with more precise predictions fromvisualization figures and 3.15%, 5.44%, 7.89% DSC higher than the previous bestresults on MMWHS, CHAOS, Spleen with 10% annotations. Our code will be releasedafter acceptance.</description>
      <author>example@mail.com (Shuang Zeng, Lei Zhu, Xinliang Zhang, Hangzhou He, Yanye Lu)</author>
      <guid isPermaLink="false">2504.14737v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted (Poster) to the 3rd CV4MR Workshop at CVPR 2025:  https://openreview.net/forum?id=00RQ8Cv3ia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GATE3D的弱监督框架，专门用于单目3D物体检测，通过结合2D和3D预测的一致性损失来有效弥合领域差距，并实现了在KITTI基准数据集和室内办公数据集上的良好性能。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉领域正趋向于开发能够同时处理多个不同任务的通用模型。然而，单目3D物体检测在多领域训练中面临挑战，特别是在标注有精确3D地面真实标签的数据集稀缺的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的弱监督框架，以实现通用单目3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;GATE3D通过使用伪标签和结合2D与3D预测的一致性损失来有效地弥合领域差距。它旨在解决当前预训练模型在非道路环境中检测行人的困难，并扩展到单目3D检测领域。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和自收集的室内办公数据集上实现了有竞争力的性能，显著加速了从有限标注数据中的学习过程。&lt;h4&gt;结论&lt;/h4&gt;GATE3D框架在加速从有限标注数据中学习方面具有显著潜力，对机器人、增强现实和虚拟现实应用具有广泛的影响。&lt;h4&gt;翻译&lt;/h4&gt;The paper introduces a novel weakly supervised framework called GATE3D, specifically designed for generalized monocular 3D object detection by bridging domain gaps through consistency losses between 2D and 3D predictions. The model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset, demonstrating its significant potential for broader impacts in robotics, augmented reality, and virtual reality applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Changhyun Jee, Jung Kwon Lee)</author>
      <guid isPermaLink="false">2504.11014v3</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>sEEG-based Encoding for Sentence Retrieval: A Contrastive Learning Approach to Brain-Language Alignment</title>
      <link>http://arxiv.org/abs/2504.14468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster presentation at the CVPR 2025 Workshop on  Multimodal Foundation Models (MMFM3)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了通过多模态基础模型将侵入性脑记录与自然语言对齐的潜力，并提出了一种名为SSENSE的对比学习框架，该框架能够将个体立体脑电图（sEEG）信号投影到预训练的CLIP模型的句子嵌入空间，从而直接从脑活动中检索句子级信息。&lt;h4&gt;背景&lt;/h4&gt;解释神经活动通过有意义的潜在表示是一个复杂且不断发展的挑战，位于神经科学和人工智能的交汇点。&lt;h4&gt;目的&lt;/h4&gt;研究多模态基础模型在将侵入性脑记录与自然语言对齐方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了SSENSE，一个对比学习框架，该框架使用InfoNCE损失在sEEG的频谱表示上训练一个神经编码器，而不对文本编码器进行微调。在自然电影观看数据集上评估了该方法。&lt;h4&gt;主要发现&lt;/h4&gt;尽管数据有限，SSENSE仍然取得了有希望的结果，表明通用语言表示可以作为神经解码的有效先验。&lt;h4&gt;结论&lt;/h4&gt;SSENSE框架有效地将脑电图信号与自然语言联系起来，表明通用语言表示在神经解码中具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Interpreting neural activity through meaningful latent representations remains a complex and evolving challenge at the intersection of neuroscience and artificial intelligence. We investigate the potential of multimodal foundation models to align invasive brain recordings with natural language. We present SSENSE, a contrastive learning framework that projects single-subject stereo-electroencephalography (sEEG) signals into the sentence embedding space of a frozen CLIP model, enabling sentence-level retrieval directly from brain activity. SSENSE trains a neural encoder on spectral representations of sEEG using InfoNCE loss, without fine-tuning the text encoder. We evaluate our method on time-aligned sEEG and spoken transcripts from a naturalistic movie-watching dataset. Despite limited data, SSENSE achieves promising results, demonstrating that general-purpose language representations can serve as effective priors for neural decoding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpreting neural activity through meaningful latent representationsremains a complex and evolving challenge at the intersection of neuroscienceand artificial intelligence. We investigate the potential of multimodalfoundation models to align invasive brain recordings with natural language. Wepresent SSENSE, a contrastive learning framework that projects single-subjectstereo-electroencephalography (sEEG) signals into the sentence embedding spaceof a frozen CLIP model, enabling sentence-level retrieval directly from brainactivity. SSENSE trains a neural encoder on spectral representations of sEEGusing InfoNCE loss, without fine-tuning the text encoder. We evaluate ourmethod on time-aligned sEEG and spoken transcripts from a naturalisticmovie-watching dataset. Despite limited data, SSENSE achieves promisingresults, demonstrating that general-purpose language representations can serveas effective priors for neural decoding.</description>
      <author>example@mail.com (Yijun Liu)</author>
      <guid isPermaLink="false">2504.14468v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2504.14915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为StableQuant的新型自适应后训练量化（PTQ）算法，用于广泛使用的语音基础模型（SFMs）。该算法在语音识别任务中表现出色，实现了模型压缩和推理速度提升。&lt;h4&gt;背景&lt;/h4&gt;虽然PTQ技术在压缩大型语言模型（LLMs）方面取得了成功，但直接应用于SFMs可能不会得到最佳结果，因为SFMs使用了不同的网络架构进行特征提取。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的PTQ算法，以优化SFMs的量化性能。&lt;h4&gt;方法&lt;/h4&gt;StableQuant通过分析每一层的尺度分布和整体性能，自适应地确定每个层的量化范围，从而在保证性能的同时实现量化。&lt;h4&gt;主要发现&lt;/h4&gt;在两个SFMs（HuBERT和wav2vec2.0）上进行评估，StableQuant相较于传统PTQ方法实现了更好的性能。该算法将SFM模型的大小减少到四分之一，同时将推理速度提高了一倍，并且在8位量化下将词错误率（WER）性能下降限制在小于0.3%。&lt;h4&gt;结论&lt;/h4&gt;StableQuant是一种有效的PTQ算法，能够在保证性能的同时显著减小SFM模型的大小并加快推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose StableQuant, a novel adaptive post-trainingquantization (PTQ) algorithm for widely used speech foundation models (SFMs).While PTQ has been successfully employed for compressing large language models(LLMs) due to its ability to bypass additional fine-tuning, directly applyingthese techniques to SFMs may not yield optimal results, as SFMs utilizedistinct network architecture for feature extraction. StableQuant demonstratesoptimal quantization performance regardless of the network architecture type,as it adaptively determines the quantization range for each layer by analyzingboth the scale distributions and overall performance. We evaluate our algorithmon two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)task, and achieve superior performance compared to traditional PTQ methods.StableQuant successfully reduces the sizes of SFM models to a quarter anddoubles the inference speed while limiting the word error rate (WER)performance drop to less than 0.3% with 8-bit quantization.</description>
      <author>example@mail.com (Yeona Hong, Hyewon Han, Woo-jin Chung, Hong-Goo Kang)</author>
      <guid isPermaLink="false">2504.14915v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Towards NSFW-Free Text-to-Image Generation via Safety-Constraint Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.14290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SC-DPO的新框架，用于解决文本到图像（T2I）生成中的内容安全性问题。&lt;h4&gt;背景&lt;/h4&gt;确保生成内容的安全性是T2I生成的基本挑战，现有研究要么无法保证在潜在有害概念下的完全安全性，要么难以在安全性和生成质量之间取得平衡。&lt;h4&gt;目的&lt;/h4&gt;提出SC-DPO以解决这些问题，旨在最大化生成人类偏好样本的可能性，同时最小化生成输出的安全成本。&lt;h4&gt;方法&lt;/h4&gt;SC-DPO将安全约束集成到一般的人类偏好校准中，引入了一个安全成本模型来准确量化图像的有害程度，并使用对比学习和成本锚定目标来有效训练它。此外，构建了SCP-10K数据集，并提出了动态聚焦机制（DFM）。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SC-DPO在防御各种不适宜内容的同时，保持了最优样本质量和人类偏好的一致性，并对旨在生成有害内容的对抗性提示表现出韧性。&lt;h4&gt;结论&lt;/h4&gt;SC-DPO是一种有效且安全的T2I生成方法，能够平衡安全性和生成质量。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring the safety of generated content remains a fundamental challenge for Text-to-Image (T2I) generation. Existing studies either fail to guarantee complete safety under potentially harmful concepts or struggle to balance safety with generation quality. To address these issues, we propose Safety-Constrained Direct Preference Optimization (SC-DPO), a novel framework for safety alignment in T2I models. SC-DPO integrates safety constraints into the general human preference calibration, aiming to maximize the likelihood of generating human-preferred samples while minimizing the safety cost of the generated outputs. In SC-DPO, we introduce a safety cost model to accurately quantify harmful levels for images, and train it effectively using the proposed contrastive learning and cost anchoring objectives. To apply SC-DPO for effective T2I safety alignment, we constructed SCP-10K, a safety-constrained preference dataset containing rich harmful concepts, which blends safety-constrained preference pairs under both harmful and clean instructions, further mitigating the trade-off between safety and sample quality. Additionally, we propose a Dynamic Focusing Mechanism (DFM) for SC-DPO, promoting the model's learning of difficult preference pair samples. Extensive experiments demonstrate that SC-DPO outperforms existing methods, effectively defending against various NSFW content while maintaining optimal sample quality and human preference alignment. Additionally, SC-DPO exhibits resilience against adversarial prompts designed to generate harmful content.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of generated content remains a fundamental challenge forText-to-Image (T2I) generation. Existing studies either fail to guaranteecomplete safety under potentially harmful concepts or struggle to balancesafety with generation quality. To address these issues, we proposeSafety-Constrained Direct Preference Optimization (SC-DPO), a novel frameworkfor safety alignment in T2I models. SC-DPO integrates safety constraints intothe general human preference calibration, aiming to maximize the likelihood ofgenerating human-preferred samples while minimizing the safety cost of thegenerated outputs. In SC-DPO, we introduce a safety cost model to accuratelyquantify harmful levels for images, and train it effectively using the proposedcontrastive learning and cost anchoring objectives. To apply SC-DPO foreffective T2I safety alignment, we constructed SCP-10K, a safety-constrainedpreference dataset containing rich harmful concepts, which blendssafety-constrained preference pairs under both harmful and clean instructions,further mitigating the trade-off between safety and sample quality.Additionally, we propose a Dynamic Focusing Mechanism (DFM) for SC-DPO,promoting the model's learning of difficult preference pair samples. Extensiveexperiments demonstrate that SC-DPO outperforms existing methods, effectivelydefending against various NSFW content while maintaining optimal sample qualityand human preference alignment. Additionally, SC-DPO exhibits resilienceagainst adversarial prompts designed to generate harmful content.</description>
      <author>example@mail.com (Shouwei Ruan, Zhenyu Wu, Yao Huang, Ruochen Zhang, Yitong Sun, Caixin Kang, Xingxing Wei)</author>
      <guid isPermaLink="false">2504.14290v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Single-Cell Foundation Models with Graph Neural Networks for Drug Response Prediction</title>
      <link>http://arxiv.org/abs/2504.14361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种通过集成scGPT基础模型到DeepCDR模型中预测癌症药物反应（CDR）的创新方法。&lt;h4&gt;背景&lt;/h4&gt;该研究旨在解决癌症药物反应预测的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提高CDR预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法使用scGPT从基因表达数据生成嵌入，这些嵌入随后作为DeepCDR模型的基因表达输入数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于scGPT的方法在性能上优于之前的相关工作，包括原始DeepCDR模型和基于scFoundation的模型。&lt;h4&gt;结论&lt;/h4&gt;研究强调了scGPT嵌入在提高CDR预测准确性方面的潜力，并为现有方法提供了有希望的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;In this study, we propose an innovative methodology for predicting CancerDrug Response (CDR) through the integration of the scGPT foundation model within the DeepCDR model. Our approach utilizes scGPT to generate embeddings from gene expression data, which are then used as gene expression input data for DeepCDR. The experimental findings demonstrate the efficacy of this scGPT-based method in outperforming previous related works, including the original DeepCDR model and the scFoundation-based model. This study highlights the potential of scGPT embeddings to enhance the accuracy of CDR predictions and offers a promising alternative to existing approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we propose an innovative methodology for predicting CancerDrug Response (CDR) through the integration of the scGPT foundation modelwithin the DeepCDR model. Our approach utilizes scGPT to generate embeddingsfrom gene expression data, which are then used as gene expression input datafor DeepCDR. The experimental findings demonstrate the efficacy of thisscGPT-based method in outperforming previous related works, including theoriginal DeepCDR model and the scFoundation-based model. This study highlightsthe potential of scGPT embeddings to enhance the accuracy of CDR predictionsand offers a promising alternative to existing approaches.</description>
      <author>example@mail.com (Till Rossner, Ziteng Li, Jonas Balke, Nikoo Salehfard, Tom Seifert, Ming Tang)</author>
      <guid isPermaLink="false">2504.14361v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>BMRL: Bi-Modal Guided Multi-Perspective Representation Learning for Zero-Shot Deepfake Attribution</title>
      <link>http://arxiv.org/abs/2504.14129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的双模态引导的多视角表示学习框架，用于零样本深度伪造归因（ZS-DFA），以有效地追踪未见生成器。&lt;h4&gt;背景&lt;/h4&gt;由于生成模型的快速进步，追踪伪造面孔的来源归因问题引起了广泛关注。然而，现有的深度伪造归因（DFA）工作主要关注视觉模态中各个领域之间的交互，而其他模态如文本和面部解析尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高深度伪造归因的泛化性能，使其能够细粒度地评估对未见生成器的归因能力。&lt;h4&gt;方法&lt;/h4&gt;设计了多视角视觉编码器（MPVE）来探索不同视角（图像、噪声和边缘）的深度伪造视觉特征；提出了新的解析编码器，专注于全局面部属性嵌入，通过视觉-解析匹配实现解析引导的DFA表示学习；提出了语言编码器来捕获细粒度语言嵌入，通过视觉-语言对齐实现语言引导的通用视觉伪造表示学习；还提出了深度伪造归因对比中心（DFACC）损失，以增强归因的追踪能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种协议评估中优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在零样本深度伪造归因任务上表现优异，为追踪未见生成器提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于生成模型的快速进步，追踪伪造面孔的来源归因问题受到了广泛关注。然而，现有的深度伪造归因（DFA）工作主要关注视觉模态中各个领域之间的交互，而其他模态如文本和面部解析尚未充分探索。此外，它们往往无法以细粒度的方式评估深度伪造归因器对未见生成器的泛化性能。在本文中，我们提出了一种新的双模态引导的多视角表示学习框架，用于零样本深度伪造归因（ZS-DFA），以促进对未见生成器的有效追踪。具体来说，我们设计了一个多视角视觉编码器（MPVE）来探索跨越三个视角（即图像、噪声和边缘）的通用深度伪造归因视觉特征。我们设计了一个新的解析编码器，专注于全局面部属性嵌入，通过视觉-解析匹配实现解析引导的DFA表示学习。我们提出了一个语言编码器来捕获细粒度语言嵌入，通过视觉-语言对齐实现语言引导的通用视觉伪造表示学习。此外，我们提出了一个新的深度伪造归因对比中心（DFACC）损失，以将相关生成器拉近，将不相关的生成器推开，这可以引入到DFA模型中以提高追踪能力。实验结果表明，我们的方法在各种协议评估中优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenge of tracing the source attribution of forged faces has gainedsignificant attention due to the rapid advancement of generative models.However, existing deepfake attribution (DFA) works primarily focus on theinteraction among various domains in vision modality, and other modalities suchas texts and face parsing are not fully explored. Besides, they tend to fail toassess the generalization performance of deepfake attributors to unseengenerators in a fine-grained manner. In this paper, we propose a novel bi-modalguided multi-perspective representation learning (BMRL) framework for zero-shotdeepfake attribution (ZS-DFA), which facilitates effective traceability tounseen generators. Specifically, we design a multi-perspective visual encoder(MPVE) to explore general deepfake attribution visual characteristics acrossthree views (i.e., image, noise, and edge). We devise a novel parsing encoderto focus on global face attribute embeddings, enabling parsing-guided DFArepresentation learning via vision-parsing matching. A language encoder isproposed to capture fine-grained language embeddings, facilitatinglanguage-guided general visual forgery representation learning throughvision-language alignment. Additionally, we present a novel deepfakeattribution contrastive center (DFACC) loss, to pull relevant generators closerand push irrelevant ones away, which can be introduced into DFA models toenhance traceability. Experimental results demonstrate that our methodoutperforms the state-of-the-art on the ZS-DFA task through various protocolsevaluation.</description>
      <author>example@mail.com (Yaning Zhang, Jiahe Zhang, Chunjie Ma, Weili Guan, Tian Gan, Zan Gao)</author>
      <guid isPermaLink="false">2504.14129v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Decomposition-based multi-scale transformer framework for time series anomaly detection</title>
      <link>http://arxiv.org/abs/2504.14206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于分解的Transformer框架（TransDe）用于多变量时间序列异常检测，旨在解决现有方法的挑战。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列异常检测方法面临两个主要挑战：直接建模复杂序列中的依赖关系困难，以及使用均方误差优化参数的方法在处理时间序列噪声时性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出TransDe框架，结合时间序列分解和Transformer的优势，有效学习正常时间序列数据中的复杂模式。&lt;h4&gt;方法&lt;/h4&gt;TransDe框架采用多尺度补丁的Transformer架构来利用时间序列分解后每个组件的代表性依赖关系。此外，提出了一种基于补丁操作的对比学习范式，利用KL散度对齐不同补丁级视图之间的正常模式纯表示。还引入了一种新的异步损失函数和stop-gradient策略，以增强TransDe的性能，避免优化过程中的耗时和劳动密集型计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;在五个公共数据集上进行的广泛实验表明，TransDe在F1分数方面优于十二个基线方法。&lt;h4&gt;结论&lt;/h4&gt;TransDe在多变量时间序列异常检测方面表现出优越性，其代码可在https://github.com/shaieesss/TransDe上获得。&lt;h4&gt;翻译&lt;/h4&gt;时间序列异常检测对于保持系统稳定至关重要。现有方法面临两个主要挑战。首先，直接建模序列中各种复杂模式的依赖关系很困难。其次，许多使用均方误差优化参数的方法在处理时间序列噪声时表现不佳，导致性能下降。为了解决这些挑战，我们提出了一种基于分解的Transformer框架（TransDe）用于多变量时间序列异常检测。其关键思想是将时间序列分解和Transformer的优势结合起来，有效地学习正常时间序列数据中的复杂模式。我们提出了一种基于多尺度补丁的Transformer架构，以利用时间序列分解后每个组件的代表性依赖关系。此外，我们还提出了一种基于补丁操作的对比学习范式，利用KL散度对齐不同补丁级视图之间的正常模式纯表示。为了进一步提高TransDe的性能，我们还引入了一种新的异步损失函数和stop-gradient策略，以避免优化过程中的耗时和劳动密集型计算成本。在五个公共数据集上进行的广泛实验表明，与十二个基线方法相比，TransDe在F1分数方面表现出优越性。我们的代码可在https://github.com/shaieesss/TransDe上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly detection is crucial for maintaining stable systems.Existing methods face two main challenges. First, it is difficult to directlymodel the dependencies of diverse and complex patterns within the sequences.Second, many methods that optimize parameters using mean squared error strugglewith noise in the time series, leading to performance deterioration. To addressthese challenges, we propose a transformer-based framework built ondecomposition (TransDe) for multivariate time series anomaly detection. The keyidea is to combine the strengths of time series decomposition and transformersto effectively learn the complex patterns in normal time series data. Amulti-scale patch-based transformer architecture is proposed to exploit therepresentative dependencies of each decomposed component of the time series.Furthermore, a contrastive learn paradigm based on patch operation is proposed,which leverages KL divergence to align the positive pairs, namely the purerepresentations of normal patterns between different patch-level views. A novelasynchronous loss function with a stop-gradient strategy is further introducedto enhance the performance of TransDe effectively. It can avoid time-consumingand labor-intensive computation costs in the optimization process. Extensiveexperiments on five public datasets are conducted and TransDe shows superioritycompared with twelve baselines in terms of F1 score. Our code is available athttps://github.com/shaieesss/TransDe.</description>
      <author>example@mail.com (Wenxin Zhang, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14206v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>ROI-Guided Point Cloud Geometry Compression Towards Human and Machine Vision</title>
      <link>http://arxiv.org/abs/2504.14240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的区域兴趣引导点云几何压缩方法，用于解决点云数据在存储和传输中的挑战。&lt;h4&gt;背景&lt;/h4&gt;点云数据在自动驾驶、虚拟现实和机器人等领域至关重要，但其大量数据体积给存储和传输带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的压缩方法，以获得高压缩比，同时保证下游任务的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用双分支并行结构，基础层编码和解码简化版点云，增强层关注几何细节，并通过ROI预测网络进行残差信息细化。该网络生成掩码信息，作为强大的监督信号，并在速率-失真（RD）优化过程中应用这些掩码细节，每个点在失真计算中都有权重。&lt;h4&gt;主要发现&lt;/h4&gt;RPCGC在ScanNet和SUN RGB-D数据集上实现了卓越的压缩性能和比一些基于学习的压缩方法更高的检测精度（10%提升）。&lt;h4&gt;结论&lt;/h4&gt;RPCGC方法在保证点云数据准确性的同时，实现了高压缩比，为点云数据的存储和传输提供了有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云数据在自动驾驶、虚拟现实和机器人等应用中至关重要。然而，其大量数据体积在存储和传输中带来了显著挑战。为了获得高压缩比，关键语义细节通常会受到严重损害，导致保证下游任务准确性的困难。为了解决这个问题，我们首次提出了一种新的区域兴趣（ROI）引导点云几何压缩（RPCGC）方法，用于人类和机器视觉。我们的框架采用双分支并行结构，其中基础层编码和解码点云的简化版本，增强层通过关注几何细节来细化这一版本。此外，增强层的残差信息通过ROI预测网络进行细化。该网络生成掩码信息，然后将其纳入残差中，作为强大的监督信号。此外，我们在速率-失真（RD）优化过程中巧妙地应用了这些掩码细节，每个点在失真计算中都有权重。我们的损失函数包括RD损失和检测损失，以更好地指导机器的点云编码。实验结果表明，RPCGC在ScanNet和SUN RGB-D数据集上实现了比一些基于学习的压缩方法在高速率下更好的压缩性能和检测精度（10%提升）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data is pivotal in applications like autonomous driving, virtualreality, and robotics. However, its substantial volume poses significantchallenges in storage and transmission. In order to obtain a high compressionratio, crucial semantic details usually confront severe damage, leading todifficulties in guaranteeing the accuracy of downstream tasks. To tackle thisproblem, we are the first to introduce a novel Region of Interest (ROI)-guidedPoint Cloud Geometry Compression (RPCGC) method for human and machine vision.Our framework employs a dual-branch parallel structure, where the base layerencodes and decodes a simplified version of the point cloud, and theenhancement layer refines this by focusing on geometry details. Furthermore,the residual information of the enhancement layer undergoes refinement throughan ROI prediction network. This network generates mask information, which isthen incorporated into the residuals, serving as a strong supervision signal.Additionally, we intricately apply these mask details in the Rate-Distortion(RD) optimization process, with each point weighted in the distortioncalculation. Our loss function includes RD loss and detection loss to betterguide point cloud encoding for the machine. Experiment results demonstrate thatRPCGC achieves exceptional compression performance and better detectionaccuracy (10% gain) than some learning-based compression methods at highbitrates in ScanNet and SUN RGB-D datasets.</description>
      <author>example@mail.com (Xie Liang, Gao Wei, Zhenghui Ming, Li Ge)</author>
      <guid isPermaLink="false">2504.14240v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>CHAINSFORMER: Numerical Reasoning on Knowledge Graphs from a Chain Perspective</title>
      <link>http://arxiv.org/abs/2504.14282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICDE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ChainsFormer的新型链式框架，用于支持知识图谱中的数值推理，通过构建逻辑链和扩展推理深度，提高了推理准确性和透明度。&lt;h4&gt;背景&lt;/h4&gt;在知识图谱中，数值属性在描述实体和关系方面变得越来越重要，而现有方法如图神经网络（GNN）和知识图谱嵌入（KGE）在利用逻辑路径方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的局限性，提出ChainsFormer，旨在提高数值推理的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;ChainsFormer通过以下方式实现：1）显式构建逻辑链；2）扩展推理深度到多跳；3）引入关系-属性链（RA-Chains）来模拟顺序推理模式；4）采用序列上下文学习来捕捉多跳推理的逐步性质；5）提出双曲亲和力评分机制以选择相关的逻辑链；6）整合注意力机制的数值推理器以识别关键推理路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ChainsFormer在性能上显著优于现有方法，实现了高达20.0%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;ChainsFormer框架在数值推理方面表现优异，为知识图谱推理提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graph completion or question answering systems, providing richer and more accurate triples and attributes. As numerical attributes become increasingly essential in characterizing entities and relations in KGs, the ability to reason over these attributes has gained significant importance. Existing graph-based methods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings (KGEs), primarily focus on aggregating homogeneous local neighbors and implicitly embedding diverse triples. However, these approaches often fail to fully leverage the potential of logical paths within the graph, limiting their effectiveness in exploiting the reasoning process. To address these limitations, we propose ChainsFormer, a novel chain-based framework designed to support numerical reasoning. Chainsformer not only explicitly constructs logical chains but also expands the reasoning depth to multiple hops. Specially, we introduce Relation-Attribute Chains (RA-Chains), a specialized logic chain, to model sequential reasoning patterns. ChainsFormer captures the step-by-step nature of multi-hop reasoning along RA-Chains by employing sequential in-context learning. To mitigate the impact of noisy chains, we propose a hyperbolic affinity scoring mechanism that selects relevant logic chains in a variable-resolution space. Furthermore, ChainsFormer incorporates an attention-based numerical reasoner to identify critical reasoning paths, enhancing both reasoning accuracy and transparency. Experimental results demonstrate that ChainsFormer significantly outperforms state-of-the-art methods, achieving up to a 20.0% improvement in performance. The implementations are available at https://github.com/zhaodazhuang2333/ChainsFormer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graphcompletion or question answering systems, providing richer and more accuratetriples and attributes. As numerical attributes become increasingly essentialin characterizing entities and relations in KGs, the ability to reason overthese attributes has gained significant importance. Existing graph-basedmethods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings(KGEs), primarily focus on aggregating homogeneous local neighbors andimplicitly embedding diverse triples. However, these approaches often fail tofully leverage the potential of logical paths within the graph, limiting theireffectiveness in exploiting the reasoning process. To address theselimitations, we propose ChainsFormer, a novel chain-based framework designed tosupport numerical reasoning. Chainsformer not only explicitly constructslogical chains but also expands the reasoning depth to multiple hops.Specially, we introduces Relation-Attribute Chains (RA-Chains), a specializedlogic chain, to model sequential reasoning patterns. ChainsFormer captures thestep-by-step nature of multi-hop reasoning along RA-Chains by employingsequential in-context learning. To mitigate the impact of noisy chains, wepropose a hyperbolic affinity scoring mechanism that selects relevant logicchains in a variable-resolution space. Furthermore, ChainsFormer incorporatesan attention-based numerical reasoner to identify critical reasoning paths,enhancing both reasoning accuracy and transparency. Experimental resultsdemonstrate that ChainsFormer significantly outperforms state-of-the-artmethods, achieving up to a 20.0% improvement in performance. Theimplementations are available athttps://github.com/zhaodazhuang2333/ChainsFormer.</description>
      <author>example@mail.com (Ze Zhao, Bin Lu, Xiaoying Gan, Gu Tang, Luoyi Fu, Xinbing Wang)</author>
      <guid isPermaLink="false">2504.14282v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Modality Guidance to Enhance VFM-based Feature Fusion for UDA in 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.14231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了视觉基础模型（VFMs）在3D语义分割任务中的应用，特别是从标记源数据到无标记目标数据的适应能力。&lt;h4&gt;背景&lt;/h4&gt;VFMs已成为图像分类、图像分割和对象定位等视觉任务的默认选择，同时也可用于利用跨模态信息（如配对图像数据）的下游3D任务。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用VFMs从标记源数据迁移到无标记目标数据，以实现基于LiDAR的3D语义分割。&lt;h4&gt;方法&lt;/h4&gt;提出了一种方法，该方法使用配对的2D-3D（图像和点云）数据，并依赖VFM的鲁棒（跨域）特征来训练3D骨干网络。该方法的核心是一个融合网络，该网络由图像和点云流引导，其相对贡献根据目标域进行调整。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最佳方法相比，该方法在多个设置中实现了显著的性能提升，平均提高了6.5 mIoU。&lt;h4&gt;结论&lt;/h4&gt;验证了VFMs在3D语义分割任务中的有效性和迁移学习的能力，特别是在处理从标记源到无标记目标数据的转换时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) have become a de facto choice for manydownstream vision tasks, like image classification, image segmentation, andobject localization. However, they can also provide significant utility fordownstream 3D tasks that can leverage the cross-modal information (e.g., frompaired image data). In our work, we further explore the utility of VFMs foradapting from a labeled source to unlabeled target data for the task ofLiDAR-based 3D semantic segmentation. Our method consumes paired 2D-3D (imageand point cloud) data and relies on the robust (cross-domain) features from aVFM to train a 3D backbone on a mix of labeled source and unlabeled targetdata. At the heart of our method lies a fusion network that is guided by boththe image and point cloud streams, with their relative contributions adjustedbased on the target domain. We extensively compare our proposed methodologywith different state-of-the-art methods in several settings and achieve strongperformance gains. For example, achieving an average improvement of 6.5 mIoU(over all tasks), when compared with the previous state-of-the-art.</description>
      <author>example@mail.com (Johannes Spoecklberger, Wei Lin, Pedro Hermosilla, Sivan Doveh, Horst Possegger, M. Jehanzeb Mirza)</author>
      <guid isPermaLink="false">2504.14231v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Traffic Flow Forecasting: From Transition to Generatation</title>
      <link>http://arxiv.org/abs/2504.14248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为EMBSFormer的交通流量预测模型，该模型针对现有模型忽略流量生成过程的问题，通过数据分析和相似性分析模块等方法，实现了更准确的流量预测。&lt;h4&gt;背景&lt;/h4&gt;交通流量预测在智能交通系统的交通管理和城市规划中扮演重要角色，现有模型主要关注流量过渡建模，而忽略了流量生成过程。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的多分支相似性转换器EMBSFormer，以解决现有模型在流量生成过程建模上的不足。&lt;h4&gt;方法&lt;/h4&gt;通过数据分析和相似性分析模块，对节点级别的流量生成和图级别的流量过渡进行建模。使用多分支编码捕捉流量生成模式，以及时空自注意力机制和图神经网络（GNN）以及时间卷积来建模节点间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;EMBSFormer在长期和短期预测任务上均优于基线模型，并且参数数量相比基于流量过渡建模的模型减少了18%，但性能相同。&lt;h4&gt;结论&lt;/h4&gt;EMBSFormer能够更有效地预测交通流量，并在实际应用中具有较好的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Traffic flow prediction plays an important role in Intelligent Transportation Systems in traffic management and urban planning. There have been extensive successful works in this area. However, these approaches focus only on modelling the flow transition and ignore the flow generation process, which manifests itself in two ways: (i) The models are based on Markovian assumptions, ignoring the multi-periodicity of the flow generation in nodes. (ii) The same structure is designed to encode both the transition and generation processes, ignoring the differences between them. To address these problems, we propose an Effective Multi-Branch Similarity Transformer for Traffic Flow Prediction, namely EMBSFormer. Through data analysis, we find that the factors affecting traffic flow include node-level traffic generation and graph-level traffic transition, which describe the multi-periodicity and interaction pattern of nodes, respectively. Specifically, to capture traffic generation patterns, we propose a similarity analysis module that supports multi-branch encoding to dynamically expand significant cycles. For traffic transition, we employ a temporal and spatial self-attention mechanism to maintain global node interactions, and use GNN and time conv to model local node interactions, respectively. Model performance is evaluated on three real-world datasets on both long-term and short-term prediction tasks. Experimental results show that EMBSFormer outperforms baselines on both tasks. Moreover, compared to models based on flow transition modelling (e.g. GMAN, 513k), the variant of EMBSFormer (93K) only uses 18% of the parameters, achieving the same performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic flow prediction plays an important role in Intelligent TransportationSystems in traffic management and urban planning. There have been extensivesuccessful works in this area. However, these approaches focus only onmodelling the flow transition and ignore the flow generation process, whichmanifests itself in two ways: (i) The models are based on Markovianassumptions, ignoring the multi-periodicity of the flow generation in nodes.(ii) The same structure is designed to encode both the transition andgeneration processes, ignoring the differences between them. To address theseproblems, we propose an Effective Multi-Branch Similarity Transformer forTraffic Flow Prediction, namely EMBSFormer. Through data analysis, we find thatthe factors affecting traffic flow include node-level traffic generation andgraph-level traffic transition, which describe the multi-periodicity andinteraction pattern of nodes, respectively. Specifically, to capture trafficgeneration patterns, we propose a similarity analysis module that supportsmulti-branch encoding to dynamically expand significant cycles. For traffictransition, we employ a temporal and spatial self-attention mechanism tomaintain global node interactions, and use GNN and time conv to model localnode interactions, respectively. Model performance is evaluated on threereal-world datasets on both long-term and short-term prediction tasks.Experimental results show that EMBSFormer outperforms baselines on both tasks.Moreover, compared to models based on flow transition modelling (e.g. GMAN,513k), the variant of EMBSFormer(93K) only uses 18\% of the parameters,achieving the same performance.</description>
      <author>example@mail.com (Li Shijiao, Ma Zhipeng, He Huajun, Chen Haiyue)</author>
      <guid isPermaLink="false">2504.14248v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Transformation of audio embeddings into interpretable, concept-based representations</title>
      <link>http://arxiv.org/abs/2504.14076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to International Joint Conference on Neural Networks (IJCNN)  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了音频神经网络中提取的音频嵌入的语义可解释性，并提出了一种基于对比学习的模型CLAP，用于将音频和文本嵌入到共享的嵌入空间中，以实现更好的可解释性。&lt;h4&gt;背景&lt;/h4&gt;音频神经网络在音频任务上取得了最先进的结果，但其内部音频表示的黑色盒结构使其难以解释。&lt;h4&gt;目的&lt;/h4&gt;探索从音频神经网络中提取的音频嵌入的语义可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用CLAP模型将音频和文本嵌入到共享的嵌入空间中，并通过后处理方法将CLAP嵌入转换为基于概念、稀疏的表示，从而提高可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;基于概念的表示在下游任务上的性能优于或等同于原始音频嵌入，同时提供了可解释性；微调基于概念的表示可以进一步提高其在下游任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法和模型能够有效地提高音频嵌入的可解释性，并在下游任务中提升性能。&lt;h4&gt;翻译&lt;/h4&gt;Advancements in audio neural networks have established state-of-the-art results on downstream audio tasks. However, the black-box structure of these models makes it difficult to interpret the information encoded in their internal audio representations. In this work, we explore the semantic interpretability of audio embeddings extracted from these neural networks by leveraging CLAP, a contrastive learning model that brings audio and text into a shared embedding space. We implement a post-hoc method to transform CLAP embeddings into concept-based, sparse representations with semantic interpretability. Qualitative and quantitative evaluations show that the concept-based representations outperform or match the performance of original audio embeddings on downstream tasks while providing interpretability. Additionally, we demonstrate that fine-tuning the concept-based representations can further improve their performance on downstream tasks. Lastly, we publish three audio-specific vocabularies for concept-based interpretability of audio embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in audio neural networks have established state-of-the-artresults on downstream audio tasks. However, the black-box structure of thesemodels makes it difficult to interpret the information encoded in theirinternal audio representations. In this work, we explore the semanticinterpretability of audio embeddings extracted from these neural networks byleveraging CLAP, a contrastive learning model that brings audio and text into ashared embedding space. We implement a post-hoc method to transform CLAPembeddings into concept-based, sparse representations with semanticinterpretability. Qualitative and quantitative evaluations show that theconcept-based representations outperform or match the performance of originalaudio embeddings on downstream tasks while providing interpretability.Additionally, we demonstrate that fine-tuning the concept-based representationscan further improve their performance on downstream tasks. Lastly, we publishthree audio-specific vocabularies for concept-based interpretability of audioembeddings.</description>
      <author>example@mail.com (Alice Zhang, Edison Thomaz, Lie Lu)</author>
      <guid isPermaLink="false">2504.14076v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.14221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages. Dataset and code: https://realiad4ad.github.io/Real-IAD D3&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Real-IAD D3，一个用于工业异常检测的高精度多模态数据集，并通过有效的方法整合了RGB、点云和伪3D深度信息，以提高检测性能。&lt;h4&gt;背景&lt;/h4&gt;随着工业异常检测（IAD）的复杂性增加，多模态检测方法已成为机器视觉研究的热点。然而，针对IAD的多模态数据集仍然有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有数据集在规模和分辨率上的限制，本文旨在提出一个能够更好地模拟真实工业环境的多模态数据集，并提高IAD的检测性能。&lt;h4&gt;方法&lt;/h4&gt;Real-IAD D3数据集结合了RGB图像、微米级3D点云和通过光测立体法生成的伪3D模态。此外，还介绍了一种有效的方法来整合不同模态的信息。&lt;h4&gt;主要发现&lt;/h4&gt;Real-IAD D3数据集提供了更细小的缺陷、多样化的异常和更大的规模，为多模态IAD提供了挑战性的基准。实验表明，这些模态在提高检测鲁棒性和整体IAD性能方面至关重要。&lt;h4&gt;结论&lt;/h4&gt;Real-IAD D3数据集和代码已公开，可供研究使用，为工业异常检测的研究提供了重要的工具和资源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着工业异常检测（IAD）的复杂性增加，多模态检测方法已成为机器视觉研究的热点。然而，针对IAD的多模态数据集仍然有限。开创性的数据集如MVTec 3D通过整合RGB+3D数据为多模态IAD奠定了基础，但由于规模和分辨率的限制，仍然面临与真实工业环境之间的差距。为了解决这些挑战，我们引入了Real-IAD D3，这是一个独特地结合了通过光测立体法生成的额外伪3D模态、高分辨率RGB图像和微米级3D点云的高精度多模态数据集。Real-IAD D3具有更细小的缺陷、多样化的异常和20个类别中的更大规模，为多模态IAD提供了一个具有挑战性的基准。此外，我们还介绍了一种有效的方法，该方法整合了RGB、点云和伪-3D深度信息，以利用每个模态的互补优势，提高检测性能。我们的实验强调了这些模态在提高检测鲁棒性和整体IAD性能方面的重要性。该数据集和代码可供研究目的公开访问，网址为https://realiad4ad.github.io/Real-IAD D3。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing complexity of industrial anomaly detection (IAD) haspositioned multimodal detection methods as a focal area of machine visionresearch. However, dedicated multimodal datasets specifically tailored for IADremain limited. Pioneering datasets like MVTec 3D have laid essentialgroundwork in multimodal IAD by incorporating RGB+3D data, but still facechallenges in bridging the gap with real industrial environments due tolimitations in scale and resolution. To address these challenges, we introduceReal-IAD D3, a high-precision multimodal dataset that uniquely incorporates anadditional pseudo3D modality generated through photometric stereo, alongsidehigh-resolution RGB images and micrometer-level 3D point clouds. Real-IAD D3features finer defects, diverse anomalies, and greater scale across 20categories, providing a challenging benchmark for multimodal IAD Additionally,we introduce an effective approach that integrates RGB, point cloud, andpseudo-3D depth information to leverage the complementary strengths of eachmodality, enhancing detection performance. Our experiments highlight theimportance of these modalities in boosting detection robustness and overall IADperformance. The dataset and code are publicly accessible for research purposesat https://realiad4ad.github.io/Real-IAD D3</description>
      <author>example@mail.com (Wenbing Zhu, Lidong Wang, Ziqing Zhou, Chengjie Wang, Yurui Pan, Ruoyi Zhang, Zhuhao Chen, Linjie Cheng, Bin-Bin Gao, Jiangning Zhang, Zhenye Gan, Yuxie Wang, Yulong Chen, Shuguang Qian, Mingmin Chi, Bo Peng, Lizhuang Ma)</author>
      <guid isPermaLink="false">2504.14221v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Dual-channel Heterophilic Message Passing for Graph Fraud Detection</title>
      <link>http://arxiv.org/abs/2504.14205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DHMP的新型框架，用于欺诈检测，以解决现有基于空间图神经网络方法中图结构增强的问题。&lt;h4&gt;背景&lt;/h4&gt;欺诈活动在电子商务、在线评论平台和社交网络等各个领域显著增加，使得欺诈检测变得至关重要。空间图神经网络（GNNs）因其强大的归纳学习能力，在欺诈检测任务中得到了成功应用。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在消息传递过程中排除异质邻居以适应GNNs的同质偏差，从而可能破坏原始图拓扑并增加预测不确定性的问题，提出DHMP框架。&lt;h4&gt;方法&lt;/h4&gt;DHMP利用异质分离模块将图分为同质和异质子图，以减轻传统GNNs的低通归纳偏差。然后，它独立地应用共享权重来捕获不同频率的信号，并引入了定制的采样策略进行训练。这允许节点根据其标签自适应地平衡各种信号的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的大量实验表明，DHMP优于现有方法，突出了分离不同频率信号对于提高欺诈检测的重要性。&lt;h4&gt;结论&lt;/h4&gt;DHMP框架通过分离不同频率的信号，有效提高了欺诈检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着各种领域，如电子商务、在线评论平台和社交网络中的欺诈活动显著增加，欺诈检测成为一项关键任务。由于强大的归纳学习能力，空间图神经网络（GNNs）在欺诈检测任务中得到了成功应用。然而，现有的基于空间GNN的方法通常通过在消息传递过程中排除异质邻居来增强图结构，以适应GNNs的同质偏差。不幸的是，这种方法可能会破坏原始图拓扑并增加预测的不确定性。为了解决这些局限性，本文提出了一种新的框架，即双通道异质消息传递（DHMP），用于欺诈检测。DHMP利用异质分离模块将图分为同质和异质子图，减轻了传统GNNs的低通归纳偏差。然后，它独立地应用共享权重来捕获不同频率的信号，并引入了定制的采样策略进行训练。这允许节点根据其标签自适应地平衡各种信号的贡献。在三个真实世界数据集上的大量实验表明，DHMP优于现有方法，突出了分离不同频率信号对于提高欺诈检测的重要性。代码可在https://github.com/shaieesss/DHMP上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fraudulent activities have significantly increased across various domains,such as e-commerce, online review platforms, and social networks, making frauddetection a critical task. Spatial Graph Neural Networks (GNNs) have beensuccessfully applied to fraud detection tasks due to their strong inductivelearning capabilities. However, existing spatial GNN-based methods oftenenhance the graph structure by excluding heterophilic neighbors during messagepassing to align with the homophilic bias of GNNs. Unfortunately, this approachcan disrupt the original graph topology and increase uncertainty inpredictions. To address these limitations, this paper proposes a novelframework, Dual-channel Heterophilic Message Passing (DHMP), for frauddetection. DHMP leverages a heterophily separation module to divide the graphinto homophilic and heterophilic subgraphs, mitigating the low-pass inductivebias of traditional GNNs. It then applies shared weights to capture signals atdifferent frequencies independently and incorporates a customized samplingstrategy for training. This allows nodes to adaptively balance thecontributions of various signals based on their labels. Extensive experimentson three real-world datasets demonstrate that DHMP outperforms existingmethods, highlighting the importance of separating signals with differentfrequencies for improved fraud detection. The code is available athttps://github.com/shaieesss/DHMP.</description>
      <author>example@mail.com (Wenxin Zhang, Jingxing Zhong, Guangzhen Yao, Renda Han, Xiaojian Lin, Zeyu Zhang, Cuicui Luo)</author>
      <guid isPermaLink="false">2504.14205v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Locate 3D: Real-World Object Localization via Self-Supervised Learning in 3D</title>
      <link>http://arxiv.org/abs/2504.14151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了LOCATE 3D模型，该模型能够从描述性表达中定位3D场景中的物体，如'沙发和灯之间的那个小咖啡桌'。该模型在标准参照性基准测试中达到了新的技术水平，并展示了强大的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景物体定位方法通常依赖于复杂的模型和大量的标注数据。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够从自然语言描述中定位3D场景中物体的模型，并实现其在实际应用中的部署。&lt;h4&gt;方法&lt;/h4&gt;LOCATE 3D模型使用3D-JEPA自监督学习算法，该算法适用于传感器点云数据，并使用CLIP和DINO等2D基础模型对3D点云进行特征化。模型通过在潜在空间中进行掩码预测作为前缀任务来辅助自监督学习。训练完成后，3D-JEPA编码器与语言条件解码器联合微调，以预测3D掩码和边界框。&lt;h4&gt;主要发现&lt;/h4&gt;LOCATE 3D在标准参照性基准测试中达到了新的技术水平，并展示了强大的泛化能力。此外，还引入了LOCATE 3D DATASET，这是一个新的3D参照性基准数据集，包含超过130K个标注，涵盖了多个捕获设置。&lt;h4&gt;结论&lt;/h4&gt;LOCATE 3D模型能够有效地从自然语言描述中定位3D场景中的物体，并具有强大的泛化能力，适合在机器人和平板增强现实设备上部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LOCATE 3D, a model for localizing objects in 3D scenes fromreferring expressions like "the small coffee table between the sofa and thelamp." LOCATE 3D sets a new state-of-the-art on standard referential groundingbenchmarks and showcases robust generalization capabilities. Notably, LOCATE 3Doperates directly on sensor observation streams (posed RGB-D frames), enablingreal-world deployment on robots and AR devices. Key to our approach is 3D-JEPA,a novel self-supervised learning (SSL) algorithm applicable to sensor pointclouds. It takes as input a 3D pointcloud featurized using 2D foundation models(CLIP, DINO). Subsequently, masked prediction in latent space is employed as apretext task to aid the self-supervised learning of contextualized pointcloudfeatures. Once trained, the 3D-JEPA encoder is finetuned alongside alanguage-conditioned decoder to jointly predict 3D masks and bounding boxes.Additionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referentialgrounding, spanning multiple capture setups with over 130K annotations. Thisenables a systematic study of generalization capabilities as well as a strongermodel.</description>
      <author>example@mail.com (Sergio Arnaud, Paul McVay, Ada Martin, Arjun Majumdar, Krishna Murthy Jatavallabhula, Phillip Thomas, Ruslan Partsey, Daniel Dugas, Abha Gejji, Alexander Sax, Vincent-Pierre Berges, Mikael Henaff, Ayush Jain, Ang Cao, Ishita Prasad, Mrinal Kalakrishnan, Michael Rabbat, Nicolas Ballas, Mido Assran, Oleksandr Maksymets, Aravind Rajeswaran, Franziska Meier)</author>
      <guid isPermaLink="false">2504.14151v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex</title>
      <link>http://arxiv.org/abs/2504.12474v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BiGTex的新型架构，用于解决文本归属性图（TAGs）的表示学习问题，该架构通过堆叠图-文本融合单元，紧密整合了图神经网络（GNNs）和大型语言模型（LLMs）。&lt;h4&gt;背景&lt;/h4&gt;在表示学习过程中，TAGs需要模型同时捕捉节点关联文本的语义丰富性和图的拓扑结构依赖性。GNNs擅长建模拓扑信息，但无法处理非结构化文本；而LLMs擅长文本理解，但通常不了解图结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理TAGs的表示学习方法。&lt;h4&gt;方法&lt;/h4&gt;BiGTex通过堆叠图-文本融合单元，实现文本和结构表示之间的相互注意力，使信息在两个方向上流动，文本影响结构，结构引导文本解释。使用参数高效的微调（LoRA）进行训练，同时冻结LLM以适应特定任务的信号。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的实验表明，BiGTex在节点分类和链接预测方面取得了最先进的性能。消融研究进一步强调了软提示和双向注意力在模型成功中的重要性。&lt;h4&gt;结论&lt;/h4&gt;BiGTex是一种有效的TAGs表示学习方法，在节点分类和链接预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-attributed graphs (TAGs) present unique challenges in representationlearning by requiring models to capture both the semantic richness ofnode-associated texts and the structural dependencies of the graph. While graphneural networks (GNNs) excel at modeling topological information, they lack thecapacity to process unstructured text. Conversely, large language models (LLMs)are proficient in text understanding but are typically unaware of graphstructure. In this work, we propose BiGTex (Bidirectional Graph Text), a novelarchitecture that tightly integrates GNNs and LLMs through stacked Graph-TextFusion Units. Each unit allows for mutual attention between textual andstructural representations, enabling information to flow in both directions,text influencing structure and structure guiding textual interpretation. Theproposed architecture is trained using parameter-efficient fine-tuning (LoRA),keeping the LLM frozen while adapting to task-specific signals. Extensiveexperiments on five benchmark datasets demonstrate that BiGTex achievesstate-of-the-art performance in node classification and generalizes effectivelyto link prediction. An ablation study further highlights the importance of softprompting and bi-directional attention in the model's success.</description>
      <author>example@mail.com (Azadeh Beiranvand, Seyed Mehdi Vahidipour)</author>
      <guid isPermaLink="false">2504.12474v2</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Temporal Plasticity in Foundation Time Series Models for Incremental Fine-tuning</title>
      <link>http://arxiv.org/abs/2504.14677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究调查了时间序列基础模型通过增量学习持续改进性能的能力，发现与传统模型相比，如Time-MoE和Chronos这样的基础模型在预测精度上表现出持续的改进。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型在多样化的时间序列预测任务中表现出色，但它们通过增量学习持续改进的能力尚未被探索。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在全面研究这些模型的时序可塑性，即它们通过持续学习渐进式提升性能同时保持现有能力的能力。&lt;h4&gt;方法&lt;/h4&gt;通过在具有分布转移的实际数据集上进行的实验，使用一个新颖的持续学习框架评估了传统的深度学习模型和时间序列基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在增量微调期间，传统模型会遭受性能下降的问题，而如Time-MoE和Chronos这样的基础模型则在预测精度上展现了持续的改进。&lt;h4&gt;结论&lt;/h4&gt;优化基础模型微调策略可能比开发特定领域的中小型模型更有价值。研究引入了新的评估方法和见解，以开发具有鲁棒持续学习能力的基础时间序列模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：时间序列基础模型在多样化的时间序列预测任务中表现出色，但它们通过增量学习持续改进的能力尚未被探索。我们提出了第一个全面研究这些模型时序可塑性的研究，即它们通过持续学习渐进式提升性能同时保持现有能力的能力。通过在具有分布转移的实际数据集上进行的实验，我们使用一个新颖的持续学习框架评估了传统的深度学习模型和时间序列基础模型。我们的研究揭示了，尽管传统模型在增量微调期间会遭遇性能下降的问题，但如Time-MoE和Chronos这样的基础模型在预测精度上表现出持续的改进。这表明，优化基础模型微调策略可能比开发特定领域的中小型模型更有价值。本研究为开发具有鲁棒持续学习能力的基础时间序列模型引入了新的评估方法和见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models excel at diverse time series forecasting tasks,but their capacity for continuous improvement through incremental learningremains unexplored. We present the first comprehensive study investigatingthese models' temporal plasticity - their ability to progressively enhanceperformance through continual learning while maintaining existing capabilities.Through experiments on real-world datasets exhibiting distribution shifts, weevaluate both conventional deep learning models and foundation models using anovel continual learning framework. Our findings reveal that while traditionalmodels struggle with performance deterioration during incremental fine-tuning,foundation models like Time-MoE and Chronos demonstrate sustained improvementin predictive accuracy. This suggests that optimizing foundation modelfine-tuning strategies may be more valuable than developing domain-specificsmall models. Our research introduces new evaluation methodologies and insightsfor developing foundation time series models with robust continuous learningcapabilities.</description>
      <author>example@mail.com (Jia Liu, Cheng Jinguo, Xia Fang, Zhenyuan Ma, Yuankai Wu)</author>
      <guid isPermaLink="false">2504.14677v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>HFBRI-MAE: Handcrafted Feature Based Rotation-Invariant Masked Autoencoder for 3D Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2504.14132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures, accepted by IJCNN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于手工特征的旋转不变掩码自编码器（HFBRI-MAE），用于改进3D点云分析中的自监督学习方法，特别是通过解决现有MAE方法在处理任意旋转点云时的旋转不变性问题。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）在3D点云分析中取得了显著成功，但基于掩码自编码器（MAE）的方法缺乏旋转不变性，导致在现实场景中处理任意旋转点云时性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决MAE方法的旋转不变性问题，提出HFBRI-MAE框架，确保在不同方向上稳定地学习特征。&lt;h4&gt;方法&lt;/h4&gt;HFBRI-MAE通过利用旋转不变的局部和全局特征进行标记嵌入和位置嵌入，有效消除旋转依赖性，同时保留丰富的几何结构。此外，将重建目标定义为输入的规范对齐版本，以减少旋转模糊。&lt;h4&gt;主要发现&lt;/h4&gt;在ModelNet40、ScanObjectNN和ShapeNetPart上的大量实验表明，HFBRI-MAE在物体分类、分割和少样本学习方面均优于现有方法，突显了其在现实世界3D应用中的鲁棒性和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;HFBRI-MAE是一种有效的3D点云分析方法，能够处理任意旋转的点云，并展现出优异的性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has demonstrated remarkable success in 3Dpoint cloud analysis, particularly through masked autoencoders (MAEs). However,existing MAE-based methods lack rotation invariance, leading to significantperformance degradation when processing arbitrarily rotated point clouds inreal-world scenarios. To address this limitation, we introduce HandcraftedFeature-Based Rotation-Invariant Masked Autoencoder (HFBRI-MAE), a novelframework that refines the MAE design with rotation-invariant handcraftedfeatures to ensure stable feature learning across different orientations. Byleveraging both rotation-invariant local and global features for tokenembedding and position embedding, HFBRI-MAE effectively eliminates rotationaldependencies while preserving rich geometric structures. Additionally, weredefine the reconstruction target to a canonically aligned version of theinput, mitigating rotational ambiguities. Extensive experiments on ModelNet40,ScanObjectNN, and ShapeNetPart demonstrate that HFBRI-MAE consistentlyoutperforms existing methods in object classification, segmentation, andfew-shot learning, highlighting its robustness and strong generalizationability in real-world 3D applications.</description>
      <author>example@mail.com (Xuanhua Yin, Dingxin Zhang, Jianhui Yu, Weidong Cai)</author>
      <guid isPermaLink="false">2504.14132v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Statistical Analysis and End-to-End Performance Evaluation of Traffic Models for Automotive Data</title>
      <link>http://arxiv.org/abs/2504.14017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对自动驾驶技术，研究了基于LiDAR传感器的数据统计特性，提出了用于数据压缩的统计模型，并通过实验验证了模型的有效性。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶是交通运输领域的一次重大变革，可以提高安全性、优化交通拥堵和减少燃料消耗。自动驾驶车辆需要依靠先进的传感器和车载计算系统进行导航，同时也需要通过V2X通信与其他车辆进行协作。&lt;h4&gt;目的&lt;/h4&gt;研究自动驾驶车辆中的LiDAR传感器数据，提出用于数据压缩的统计模型，以优化V2X通信。&lt;h4&gt;方法&lt;/h4&gt;本文对汽车数据进行统计描述，特别是针对LiDAR传感器，提供了原始和压缩点云大小的模型。使用统计交通模型进行仿真，并通过Kolmogorov-Smirnoff测试和Bootstrap重采样方案进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;统计模型可以提供比真实数据更快的仿真速度、更低的存储需求，以及更大的应用设计灵活性。与真实数据相比，使用统计模型在延迟和吞吐量方面具有可比性。&lt;h4&gt;结论&lt;/h4&gt;提出的统计模型能够有效地用于自动驾驶车辆的数据压缩，提高了V2X通信的效率。&lt;h4&gt;翻译&lt;/h4&gt;Autonomous driving is a major paradigm shift in transportation, with the potential to enhance safety, optimize traffic congestion, and reduce fuel consumption. Although autonomous vehicles rely on advanced sensors and on-board computing systems to navigate without human control, full awareness of the driving environment also requires a cooperative effort via Vehicle-To-Everything (V2X) communication. Specifically, vehicles send and receive sensor perceptions to/from other vehicles to extend perception beyond their own sensing range. However, transmitting large volumes of data can be challenging for current V2X communication technologies, so data compression represents a crucial solution to reduce the message size and link congestion. In this paper, we present a statistical characterization of automotive data, focusing on LiDAR sensors. Notably, we provide models for the size of both raw and compressed point clouds. The use of statistical traffic models offers several advantages compared to using real data, such as faster simulations, reduced storage requirements, and greater flexibility in the application design. Furthermore, statistical models can be used for understanding traffic patterns and analyzing statistics, which is crucial to design and optimize wireless networks. We validate our statistical models via a Kolmogorov-Smirnoff test implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3 simulations that using statistical models yields comparable results in terms of latency and throughput compared to real data, which also demonstrates the accuracy of the models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving is a major paradigm shift in transportation, with thepotential to enhance safety, optimize traffic congestion, and reduce fuelconsumption. Although autonomous vehicles rely on advanced sensors and on-boardcomputing systems to navigate without human control, full awareness of thedriving environment also requires a cooperative effort viaVehicle-To-Everything (V2X) communication. Specifically, vehicles send andreceive sensor perceptions to/from other vehicles to extend perception beyondtheir own sensing range. However, transmitting large volumes of data can bechallenging for current V2X communication technologies, so data compressionrepresents a crucial solution to reduce the message size and link congestion.In this paper, we present a statistical characterization of automotive data,focusing on LiDAR sensors. Notably, we provide models for the size of both rawand compressed point clouds. The use of statistical traffic models offersseveral advantages compared to using real data, such as faster simulations,reduced storage requirements, and greater flexibility in the applicationdesign. Furthermore, statistical models can be used for understanding trafficpatterns and analyzing statistics, which is crucial to design and optimizewireless networks. We validate our statistical models via a Kolmogorov-Smirnofftest implementing a Bootstrap Resampling scheme. Moreover, we show via ns-3simulations that using statistical models yields comparable results in terms oflatency and throughput compared to real data, which also demonstrates theaccuracy of the models.</description>
      <author>example@mail.com (Marcello Bullo, Amir Ashtari Gargari, Paolo Testolina, Michele Zorzi, Marco Giordani)</author>
      <guid isPermaLink="false">2504.14017v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>SG-Reg: Generalizable and Efficient Scene Graph Registration</title>
      <link>http://arxiv.org/abs/2504.14440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Transactions Robotics Regular Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将两个刚体语义场景图进行注册的挑战，并设计了一种新的方法来提高注册的成功率。&lt;h4&gt;背景&lt;/h4&gt;在自主代理需要将其地图与远程代理或先前地图进行注册时，场景图的注册是一个基本能力。传统的语义辅助注册和基于学习的场景图注册在现实世界中应用受限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，设计了一种场景图网络来编码语义节点的多种模态，并融合这些模态以创建紧凑的语义节点特征。&lt;h4&gt;方法&lt;/h4&gt;该方法包括使用匹配层以粗到细的方式寻找对应关系，以及使用鲁棒的姿态估计器来决定变换。此外，还设计了一种新的数据生成方法，使用视觉基础模型和语义映射模块来重建语义场景图。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个代理SLAM基准测试中验证有效，显著优于手工制作的基线，在注册成功率方面表现优异。与视觉环路闭合网络相比，该方法在通信带宽方面具有优势。&lt;h4&gt;结论&lt;/h4&gt;该方法在多代理任务中需要更少的GPU资源和通信带宽，并显著提高了注册的成功率。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了将两个刚体语义场景图进行注册的挑战，并设计了一种新的方法来提高注册的成功率。为了解决这些挑战，设计了一种场景图网络来编码语义节点的多种模态，并融合这些模态以创建紧凑的语义节点特征。该方法包括使用匹配层以粗到细的方式寻找对应关系，以及使用鲁棒的姿态估计器来决定变换。此外，还设计了一种新的数据生成方法，使用视觉基础模型和语义映射模块来重建语义场景图。该方法在两个代理SLAM基准测试中验证有效，显著优于手工制作的基线，在注册成功率方面表现优异。与视觉环路闭合网络相比，该方法在通信带宽方面具有优势。该方法在多代理任务中需要更少的GPU资源和通信带宽，并显著提高了注册的成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hkust-aerial-robotics/sg-reg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenges of registering two rigid semantic scenegraphs, an essential capability when an autonomous agent needs to register itsmap against a remote agent, or against a prior map. The hand-crafteddescriptors in classical semantic-aided registration, or the ground-truthannotation reliance in learning-based scene graph registration, impede theirapplication in practical real-world environments. To address the challenges, wedesign a scene graph network to encode multiple modalities of semantic nodes:open-set semantic feature, local topology with spatial awareness, and shapefeature. These modalities are fused to create compact semantic node features.The matching layers then search for correspondences in a coarse-to-fine manner.In the back-end, we employ a robust pose estimator to decide transformationaccording to the correspondences. We manage to maintain a sparse andhierarchical scene representation. Our approach demands fewer GPU resources andfewer communication bandwidth in multi-agent tasks. Moreover, we design a newdata generation approach using vision foundation models and a semantic mappingmodule to reconstruct semantic scene graphs. It differs significantly fromprevious works, which rely on ground-truth semantic annotations to generatedata. We validate our method in a two-agent SLAM benchmark. It significantlyoutperforms the hand-crafted baseline in terms of registration success rate.Compared to visual loop closure networks, our method achieves a slightly higherregistration recall while requiring only 52 KB of communication bandwidth foreach query frame. Code available at:\href{http://github.com/HKUST-Aerial-Robotics/SG-Reg}{http://github.com/HKUST-Aerial-Robotics/SG-Reg}.</description>
      <author>example@mail.com (Chuhao Liu, Zhijian Qiao, Jieqi Shi, Ke Wang, Peize Liu, Shaojie Shen)</author>
      <guid isPermaLink="false">2504.14440v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning on Graphs for Mobile Network Topology Generation</title>
      <link>http://arxiv.org/abs/2504.13991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 6 figures, submitted to IEEE Networking Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了移动网络拓扑结构的重要性，并提出了基于图深度学习的方法来确定移动网络的移动关系（边），同时评估了不同方法的准确性和精确度。&lt;h4&gt;背景&lt;/h4&gt;移动网络由地理区域内的无线电节点组成，这些节点的连接关系（即移动网络拓扑）对于网络基础设施的建设至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在使用图深度学习方法确定移动网络的移动关系，并评估其在实际移动网络中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了基于图的深度学习方法和自动邻接关系（ANR）设置的可信移动关系来训练模型，并进行了综合实验以评估两种深度学习模型：图神经网络（GNN）和多层感知器。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，考虑图结构可以改善结果，这促使了GNN的使用。此外，通过基于无线电节点之间距离的启发式方法减少训练时间，显著提高了精确度和准确度。&lt;h4&gt;结论&lt;/h4&gt;图神经网络模型和多层感知器在移动网络拓扑结构分析中是有效的，且启发式方法可以有效地提高模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile networks consist of interconnected radio nodes strategicallypositioned across various geographical regions to provide connectivityservices. The set of relations between these radio nodes, referred to as the\emph{mobile network topology}, is vital in the construction of the networkinginfrastructure. Typically, the connections between radio nodes and theirassociated cells are defined by software features that establish mobilityrelations (referred to as \emph{edges} in this paper) within the mobile networkgraph through heuristic methods. Although these approaches are efficient, theyencounter significant limitations, particularly since edges can only beestablished prior to the installation of physical hardware.  In this work, we use graph-based deep learning methods to determine mobilityrelations (edges), trained on radio node configuration data and reliablemobility relations set by Automatic Neighbor Relations (ANR) in stablenetworks. This paper focuses on measuring the accuracy and precision ofdifferent graph-based deep learning approaches applied to real-world mobilenetworks. We evaluated two deep learning models. Our comprehensive experimentson Telecom datasets obtained from operational Telecom Networks demonstrate theeffectiveness of the graph neural network (GNN) model and multilayerperceptron. Our evaluation showed that considering graph structure improvesresults, which motivates the use of GNNs. Additionally, we investigated the useof heuristics to reduce the training time based on the distance between radionodes to eliminate irrelevant cases. Our investigation showed that the use ofthese heuristics improved precision and accuracy considerably.</description>
      <author>example@mail.com (Felix Nannesson Meli, Johan Tell, Shirwan Piroti, Tahar Zanouda, Elias Jarlebring)</author>
      <guid isPermaLink="false">2504.13991v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating LLM Inference with Flexible N:M Sparsity via A Fully Digital Compute-in-Memory Accelerator</title>
      <link>http://arxiv.org/abs/2504.14365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种灵活的N:M稀疏性选择方法FLOW，以及一种灵活的、低开销的数字内存计算架构FlexCiM，用于解决大型语言模型（LLM）稀疏化过程中遇到的表达能力受限和硬件开销过大的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的LLM稀疏化方法限制了模型的表达能力，而支持多种N:M模式则增加了硬件的开销。&lt;h4&gt;目的&lt;/h4&gt;为了解决LLM稀疏化中的挑战，提出了一种新的稀疏性选择方法和计算架构。&lt;h4&gt;方法&lt;/h4&gt;提出了FLOW方法，通过同时考虑异常值的存在和分布来识别最优的层间N和M值。FlexCiM架构通过将数字CiM宏分区成更小的子宏，并通过分配和合并机制适应不同的N和M值来支持不同的稀疏模式。&lt;h4&gt;主要发现&lt;/h4&gt;FLOW在Transformer和递归基础的状态空间模型（SSMs）上优于现有方法，准确率提高了36%。FlexCiM比现有稀疏加速器实现了高达1.75倍的推理延迟降低和1.5倍的能耗降低。&lt;h4&gt;结论&lt;/h4&gt;FLOW和FlexCiM为LLM的稀疏化提供了有效的解决方案，显著提高了模型性能和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a flexible N:M sparsity selection method called FLOW and a flexible, low-overhead digital compute-in-memory architecture called FlexCiM to address the challenges of large language model (LLM) sparsification, which include limited expressivity and high hardware overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language model (LLM) pruning with fixed N:M structured sparsitysignificantly limits the expressivity of the sparse model, yielding sub-optimalperformance. In contrast, supporting multiple N:M patterns to provide sparserepresentational freedom introduces costly overhead in hardware. To addressthese challenges for LLMs, we first present a flexible layer-wiseoutlier-density-aware N:M sparsity (FLOW) selection method. FLOW enables theidentification of optimal layer-wise N and M values (from a given range) bysimultaneously accounting for the presence and distribution of outliers,allowing a higher degree of representational freedom. To deploy sparse modelswith such N:M flexibility, we then introduce a flexible, low-overhead digitalcompute-in-memory architecture (FlexCiM). FlexCiM supports diverse sparsitypatterns by partitioning a digital CiM (DCiM) macro into smaller sub-macros,which are adaptively aggregated and disaggregated through distribution andmerging mechanisms for different N and M values. Extensive experiments on bothtransformer-based and recurrence-based state space foundation models (SSMs)demonstrate that FLOW outperforms existing alternatives with an accuracyimprovement of up to 36%, while FlexCiM achieves up to 1.75x lower inferencelatency and 1.5x lower energy consumption compared to existing sparseaccelerators. Code is available at: https://github.com/FLOW-open-project/FLOW</description>
      <author>example@mail.com (Akshat Ramachandran, Souvik Kundu, Arnab Raha, Shamik Kundu, Deepak K. Mathaikutty, Tushar Krishna)</author>
      <guid isPermaLink="false">2504.14365v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Visual Consensus Prompting for Co-Salient Object Detection</title>
      <link>http://arxiv.org/abs/2504.14254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对共显著目标检测（CoSOD）任务的高效且参数节约的架构，解决了现有方法的两个主要限制。&lt;h4&gt;背景&lt;/h4&gt;现有的CoSOD方法通常采用三阶段架构（编码、共识提取与分散、预测）和全微调范式。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法的局限性，提出一种交互有效且参数高效的CoSOD任务架构。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了一种参数高效的提示调整范式，并将共识嵌入到提示中，形成特定的视觉共识提示（VCP）。通过限制可调整参数，使共识提示生成器（CPG）专注于共显著表示，并生成共识提示。共识提示分散器（CPD）利用共识提示形成特定任务的视觉共识提示，从而激发预训练模型在CoSOD任务上的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的VCP优于13个先进的全微调模型，在最具挑战性的CoCA数据集上实现了F_m指标的新纪录（提高了6.8%）。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在CoSOD任务上取得了显著的性能提升，并提供了高效的参数使用和知识表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现有的共显著目标检测（CoSOD）方法通常采用三阶段架构（即编码、共识提取与分散和预测）以及典型的全微调范式。虽然它们带来了一定的好处，但存在两个显著的局限性：1）该架构依赖于编码特征来促进共识提取，但精心提取的共识不能及时为编码阶段提供指导。2）该范式涉及全局更新模型的全部参数，这既参数效率低下，又阻碍了基础模型在此任务中有效表示知识。因此，本文提出了一种针对CoSOD任务的高效且参数节约的交互式架构，解决了两个关键局限性。它首次引入了一种参数高效的提示调整范式，并将共识无缝嵌入到提示中，形成特定任务的视觉共识提示（VCP）。我们的VCP旨在通过制定特定任务的视觉共识提示来最小化可调整参数，以使冻结的基础模型在CoSOD任务上表现更好。具体而言，有目的的共识提示生成器（CPG）的主要见解是强制执行有限的可调整参数，以关注共显著表示并生成共识提示。制定的共识提示分散器（CPD）利用共识提示形成特定任务的视觉共识提示，从而激发预训练模型在解决CoSOD任务中的强大潜力。广泛的实验表明，我们的简洁VCP优于13个最先进的全微调模型，在最具挑战性的CoCA数据集上实现了新的最先进水平（F_m指标提高了6.8%）。源代码可在https://github.com/WJ-CV/VCP上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wj-cv/vcp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing co-salient object detection (CoSOD) methods generally employ athree-stage architecture (i.e., encoding, consensus extraction &amp; dispersion,and prediction) along with a typical full fine-tuning paradigm. Although theyyield certain benefits, they exhibit two notable limitations: 1) Thisarchitecture relies on encoded features to facilitate consensus extraction, butthe meticulously extracted consensus does not provide timely guidance to theencoding stage. 2) This paradigm involves globally updating all parameters ofthe model, which is parameter-inefficient and hinders the effectiverepresentation of knowledge within the foundation model for this task.Therefore, in this paper, we propose an interaction-effective andparameter-efficient concise architecture for the CoSOD task, addressing two keylimitations. It introduces, for the first time, a parameter-efficient prompttuning paradigm and seamlessly embeds consensus into the prompts to formulatetask-specific Visual Consensus Prompts (VCP). Our VCP aims to induce the frozenfoundation model to perform better on CoSOD tasks by formulating task-specificvisual consensus prompts with minimized tunable parameters. Concretely, theprimary insight of the purposeful Consensus Prompt Generator (CPG) is toenforce limited tunable parameters to focus on co-salient representations andgenerate consensus prompts. The formulated Consensus Prompt Disperser (CPD)leverages consensus prompts to form task-specific visual consensus prompts,thereby arousing the powerful potential of pre-trained models in addressingCoSOD tasks. Extensive experiments demonstrate that our concise VCP outperforms13 cutting-edge full fine-tuning models, achieving the new state of the art(with 6.8% improvement in F_m metrics on the most challenging CoCA dataset).Source code has been available at https://github.com/WJ-CV/VCP.</description>
      <author>example@mail.com (Jie Wang, Nana Yu, Zihao Zhang, Yahong Han)</author>
      <guid isPermaLink="false">2504.14254v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild</title>
      <link>http://arxiv.org/abs/2504.11326v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop Page: https://pvuw.github.io/. arXiv admin note: text  overlap with arXiv:2504.00476, arXiv:2504.05178&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该报告全面概述了在CVPR 2025期间举办的第4届像素级视频理解野外挑战赛，总结了挑战结果、参与的方法和未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;挑战赛与CVPR 2025联合举办，旨在推动视频理解技术的发展。&lt;h4&gt;目的&lt;/h4&gt;提供对复杂视频分割领域当前状态和新兴趋势的深入理解。&lt;h4&gt;方法&lt;/h4&gt;挑战赛包含两个赛道：MOSE（复杂场景视频对象分割）和MeViS（基于运动的视频分割），并引入了新的、更具挑战性的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细评估和分析，挑战赛揭示了复杂视频分割领域的最新进展和趋势。&lt;h4&gt;结论&lt;/h4&gt;更多信息可在挑战赛官方网站上找到：https://pvuw.github.io/。&lt;h4&gt;翻译&lt;/h4&gt;This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025. It summarizes the challenge outcomes, participating methodologies, and future research directions. The challenge features two tracks: MOSE, which focuses on complex scene video object segmentation, and MeViS, which targets motion-guided, language-based video segmentation. Both tracks introduce new, more challenging datasets designed to better reflect real-world scenarios. Through detailed evaluation and analysis, the challenge offers valuable insights into the current state-of-the-art and emerging trends in complex video segmentation. More information can be found on the workshop website: https://pvuw.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.It summarizes the challenge outcomes, participating methodologies, and futureresearch directions. The challenge features two tracks: MOSE, which focuses oncomplex scene video object segmentation, and MeViS, which targetsmotion-guided, language-based video segmentation. Both tracks introduce new,more challenging datasets designed to better reflect real-world scenarios.Through detailed evaluation and analysis, the challenge offers valuableinsights into the current state-of-the-art and emerging trends in complex videosegmentation. More information can be found on the workshop website:https://pvuw.github.io/.</description>
      <author>example@mail.com (Henghui Ding, Chang Liu, Nikhila Ravi, Shuting He, Yunchao Wei, Song Bai, Philip Torr, Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang, Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Mengjiao Wang, Junpei Zhang, Xu Liu, Yuting Yang, Mengru Ma, Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Chen, Wei Zhang, Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu, Haobo Yuan, Xiangtai Li, Tao Zhang, Lu Qi, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.11326v2</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>PRISM: A Unified Framework for Photorealistic Reconstruction and Intrinsic Scene Modeling</title>
      <link>http://arxiv.org/abs/2504.14219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一个统一的框架，允许在单个基础模型中执行多种图像生成和编辑任务。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常需要单独的模型或分别推断内在属性，而PRISM通过联合生成所有内在层来保持模态间的一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一个有效的微调策略，从预训练的文本到图像扩散模型生成RGB图像和内在图（X层），并支持多种图像处理任务。&lt;h4&gt;方法&lt;/h4&gt;PRISM通过联合生成所有内在层来维护模态间的一致性，并支持文本到RGBX生成、RGB到X分解和X到RGBX条件生成等多种任务。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM在内在图像分解和条件图像生成方面表现出竞争力，同时保留了基础模型的文本到图像生成能力。&lt;h4&gt;结论&lt;/h4&gt;PRISM是一个高效且功能全面的框架，可以用于多种图像生成和编辑任务，具有广泛的适用性和竞争力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出PRISM，一个统一的框架，它允许在单个基础模型中执行多种图像生成和编辑任务。从预训练的文本到图像扩散模型开始，PRISM提出了一种有效的微调策略，以同时生成RGB图像和内在图（称为X层）。与之前的方法不同，这些方法单独推断内在属性或需要单独的模型进行分解和条件生成，PRISM通过联合生成所有内在层来保持模态间的一致性。它支持多种任务，包括文本到RGBX生成、RGB到X分解和X到RGBX条件生成。此外，PRISM通过在选定的内在层和文本提示上条件化，使全局和局部图像编辑成为可能。大量实验表明，PRISM在内在图像分解和条件图像生成方面都具有竞争力，同时保留了基础模型的文本到图像生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present PRISM, a unified framework that enables multiple image generationand editing tasks in a single foundational model. Starting from a pre-trainedtext-to-image diffusion model, PRISM proposes an effective fine-tuning strategyto produce RGB images along with intrinsic maps (referred to as X layers)simultaneously. Unlike previous approaches, which infer intrinsic propertiesindividually or require separate models for decomposition and conditionalgeneration, PRISM maintains consistency across modalities by generating allintrinsic layers jointly. It supports diverse tasks, including text-to-RGBXgeneration, RGB-to-X decomposition, and X-to-RGBX conditional generation.Additionally, PRISM enables both global and local image editing throughconditioning on selected intrinsic layers and text prompts. Extensiveexperiments demonstrate the competitive performance of PRISM both for intrinsicimage decomposition and conditional image generation while preserving the basemodel's text-to-image generation capability.</description>
      <author>example@mail.com (Alara Dirik, Tuanfeng Wang, Duygu Ceylan, Stefanos Zafeiriou, Anna Frühstück)</author>
      <guid isPermaLink="false">2504.14219v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>6G WavesFM: A Foundation Model for Sensing, Communication, and Localization</title>
      <link>http://arxiv.org/abs/2504.14100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了WavesFM，这是一种新型的无线基础模型（WFM）框架，能够支持多种通信、感知和定位任务。&lt;h4&gt;背景&lt;/h4&gt;WavesFM结合了共享的视觉Transformer（ViT）骨干网络和特定任务的多层感知器（MLP）头部，并采用了低秩自适应（LoRA）进行参数高效的微调。&lt;h4&gt;目的&lt;/h4&gt;该设计旨在在任务之间促进参数的完全共享，显著减少计算和内存占用，同时不牺牲性能。&lt;h4&gt;方法&lt;/h4&gt;模型处理类似图像的无线模态，如频谱图和信道状态信息（CSI），以及作为正交频分复用（OFDM）资源网格的对准和正交（IQ）信号。&lt;h4&gt;主要发现&lt;/h4&gt;通过在四个下游任务上的广泛实验，WavesFM展示了强大的泛化能力，包括5G NR定位、MIMO-OFDM信道估计、人类活动感知和射频（RF）信号分类。&lt;h4&gt;结论&lt;/h4&gt;与单独训练的监督基线相比，该方法在共享80%参数的情况下实现了更优的性能。此外，通过在领域相关数据上预训练，不仅提高了性能，还加速了收敛，将训练时间减少了高达5倍。这些结果表明，统一的WFM可以支持多样化的任务，并在性能和效率方面实现显著提升，突显了基础模型在未来第六代（6G）网络中推动AI原生范式变革的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces WavesFM, a novel Wireless Foundation Model (WFM) framework, capable of supporting a wide array of communication, sensing, and localization tasks. Our proposed architecture combines a shared VisionTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP) heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. This design promotes full parameter sharing across tasks, significantly reducing the computational and memory footprint without sacrificing performance. The model processes both image-like wireless modalities, such as spectrograms and channel state information (CSI), and in-phase and quadrature (IQ) signals arranged as orthogonal frequency-division multiplexing (OFDM) resource grids. We demonstrate the strong generalization capabilities of WavesFM through extensive experiments on four downstream tasks: Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-output OFDM (MIMO-OFDM) channel estimation; human activity sensing; and radio-frequency (RF) signal classification. Compared to supervised baselines trained individually, our approach achieves superior performance while sharing 80% of its parameters across tasks. Furthermore, we show that pretraining on domain-relevant data not only boosts performance but also accelerates convergence, reducing training time by up to 5x. These results demonstrate that our unified WFM can support diverse tasks and deliver significant gains in both performance and efficiency, highlighting the transformative potential of foundation models to drive AI-native paradigms in future sixth-generation (6G) networks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces WavesFM, a novel Wireless Foundation Model (WFM)framework, capable of supporting a wide array of communication, sensing, andlocalization tasks. Our proposed architecture combines a shared VisionTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP)heads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficientfine-tuning. This design promotes full parameter sharing across tasks,significantly reducing the computational and memory footprint withoutsacrificing performance. The model processes both image-like wirelessmodalities, such as spectrograms and channel state information (CSI), andin-phase and quadrature (IQ) signals arranged as orthogonal frequency-divisionmultiplexing (OFDM) resource grids. We demonstrate the strong generalizationcapabilities of WavesFM through extensive experiments on four downstream tasks:Fifth Generation New Radio (5G NR) positioning; multiple-input multiple-outputOFDM (MIMO-OFDM) channel estimation; human activity sensing; andradio-frequency (RF) signal classification. Compared to supervised baselinestrained individually, our approach achieves superior performance while sharing80% of its parameters across tasks. Furthermore, we show that pretraining ondomain-relevant data not only boosts performance but also acceleratesconvergence, reducing training time by up to 5x. These results demonstrate thatour unified WFM can support diverse tasks and deliver significant gains in bothperformance and efficiency, highlighting the transformative potential offoundation models to drive AI-native paradigms in future sixth-generation (6G)networks.</description>
      <author>example@mail.com (Ahmed Aboulfotouh, Elsayed Mohammed, Hatem Abou-Zeid)</author>
      <guid isPermaLink="false">2504.14100v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.14032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种用于特征上采样以提升视觉基础模型在像素级理解应用中的性能的方法。&lt;h4&gt;背景&lt;/h4&gt;虽然DINOv2和CLIP等视觉基础模型在下游任务上取得了显著成果，但它们的特征分辨率有限，这限制了在需要像素级理解的应用中的性能。&lt;h4&gt;目的&lt;/h4&gt;通过特征上采样来提升模型在需要高分辨率细节的应用中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了两个关键因素：上采样架构和训练目标。上采样架构方面，引入了一种基于坐标的交叉注意力Transformer，用于结合高分辨率图像和低分辨率视觉基础模型特征。训练目标方面，通过使用无类别的掩码和自蒸馏来构建高分辨率伪真实特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效捕捉了细粒度细节，并能够灵活适应各种输入和特征分辨率。实验表明，该方法在各种下游任务上显著优于现有的特征上采样技术。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法对于提升视觉基础模型在需要高分辨率细节的应用中的性能具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved impressive results on various downstream tasks, but their limited feature resolution hampers performance in applications requiring pixel-level understanding. Feature upsampling offers a promising direction to address this challenge. In this work, we identify two critical factors for enhancing feature upsampling: the upsampler architecture and the training objective. For the upsampler architecture, we introduce a coordinate-based cross-attention transformer that integrates the high-resolution images with coordinates and low-resolution VFM features to generate sharp, high-quality features. For the training objective, we propose constructing high-resolution pseudo-groundtruth features by leveraging class-agnostic masks and self-distillation. Our approach effectively captures fine-grained details and adapts flexibly to various input and feature resolutions. Through experiments, we demonstrate that our approach significantly outperforms existing feature upsampling techniques across various downstream tasks. Our code is released at https://github.com/andrehuang/loftup.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/andrehuang/loftup&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) such as DINOv2 and CLIP have achievedimpressive results on various downstream tasks, but their limited featureresolution hampers performance in applications requiring pixel-levelunderstanding. Feature upsampling offers a promising direction to address thischallenge. In this work, we identify two critical factors for enhancing featureupsampling: the upsampler architecture and the training objective. For theupsampler architecture, we introduce a coordinate-based cross-attentiontransformer that integrates the high-resolution images with coordinates andlow-resolution VFM features to generate sharp, high-quality features. For thetraining objective, we propose constructing high-resolution pseudo-groundtruthfeatures by leveraging class-agnostic masks and self-distillation. Our approacheffectively captures fine-grained details and adapts flexibly to various inputand feature resolutions. Through experiments, we demonstrate that our approachsignificantly outperforms existing feature upsampling techniques across variousdownstream tasks. Our code is released at https://github.com/andrehuang/loftup.</description>
      <author>example@mail.com (Haiwen Huang, Anpei Chen, Volodymyr Havrylov, Andreas Geiger, Dan Zhang)</author>
      <guid isPermaLink="false">2504.14032v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Memory-efficient Streaming VideoLLMs for Real-time Procedural Video Understanding</title>
      <link>http://arxiv.org/abs/2504.13915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures; https://dibschat.github.io/ProVideLLM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为ProVideLLM的端到端框架，用于实时过程视频理解。&lt;h4&gt;背景&lt;/h4&gt;当前方法在表示长时间观察时存在token计数过多的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够有效减少token计数、同时捕捉短期观察中细粒度细节的框架。&lt;h4&gt;方法&lt;/h4&gt;ProVideLLM整合了一个多模态缓存，存储两种类型的token：文本token和视觉token。文本token提供对长期观察的压缩文本摘要，视觉token使用DETR-QFormer编码，以捕捉短期观察的细粒度细节。&lt;h4&gt;主要发现&lt;/h4&gt;该设计将表示一小时的长期观察的token计数减少了22倍，同时有效地编码了当前的细粒度信息。通过在多模态缓存中交错这些token，ProVideLLM确保了内存和计算随着视频长度的线性增长，实现了每帧10FPS的流式推理和25FPS的流式对话，同时GPU内存占用仅为2GB。&lt;h4&gt;结论&lt;/h4&gt;ProVideLLM在四个数据集上的六个过程任务上达到了新的最先进结果。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为ProVideLLM的端到端框架，用于实时过程视频理解。ProVideLLM集成了一个配置为存储两种类型token的多模态缓存——口头化的文本token，它提供了对长期观察的压缩文本摘要；以及视觉token，使用DETR-QFormer进行编码，以捕捉短期观察的细粒度细节。这种设计在表示一小时的长期观察时，与现有方法相比减少了22倍的token计数，同时有效地编码了当前的细粒度信息。通过在多模态缓存中交错这些token，ProVideLLM确保了内存和计算随着视频长度的线性增长，实现了每帧10FPS的流式推理和25FPS的流式对话，同时GPU内存占用仅为2GB。ProVideLLM在四个数据集上的六个过程任务上达到了新的最先进结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ProVideLLM, an end-to-end framework for real-time proceduralvideo understanding. ProVideLLM integrates a multimodal cache configured tostore two types of tokens - verbalized text tokens, which provide compressedtextual summaries of long-term observations, and visual tokens, encoded withDETR-QFormer to capture fine-grained details from short-term observations. Thisdesign reduces token count by 22x over existing methods in representing onehour of long-term observations while effectively encoding fine-granularity ofthe present. By interleaving these tokens in our multimodal cache, ProVideLLMensures sub-linear scaling of memory and compute with video length, enablingper-frame streaming inference at 10 FPS and streaming dialogue at 25 FPS, witha minimal 2GB GPU memory footprint. ProVideLLM also sets new state-of-the-artresults on six procedural tasks across four datasets.</description>
      <author>example@mail.com (Dibyadip Chatterjee, Edoardo Remelli, Yale Song, Bugra Tekin, Abhay Mittal, Bharat Bhatnagar, Necati Cihan Camgöz, Shreyas Hampali, Eric Sauser, Shugao Ma, Angela Yao, Fadime Sener)</author>
      <guid isPermaLink="false">2504.13915v1</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>Digital Twin Buildings: 3D Modeling, GIS Integration, and Visual Descriptions Using Gaussian Splatting, ChatGPT/Deepseek, and Google Maps Platform</title>
      <link>http://arxiv.org/abs/2502.05769v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  -Fixed minor typo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对单栋建筑规模的数字孪生框架，旨在通过多源数据和数据分析优化城市规划、基础设施管理和决策。&lt;h4&gt;背景&lt;/h4&gt;城市数字孪生是使用多源数据和数据分析来优化城市规划、基础设施管理和决策的虚拟城市复制品。&lt;h4&gt;目的&lt;/h4&gt;提出一个专注于单栋建筑规模的框架，以优化城市规划、基础设施管理和决策。&lt;h4&gt;方法&lt;/h4&gt;该框架通过连接到云地图平台（如谷歌地图平台API），利用基于ChatGPT(4o)和Deepseek-V3/R1的最新多智能体大型语言模型数据分析，以及使用基于高斯喷溅的网格提取管道来检索建筑的3D模型、视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;h4&gt;主要发现&lt;/h4&gt;通过该框架，可以检索建筑的3D模型和视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个有效的框架，用于创建城市建筑的单栋数字孪生，以支持城市规划和基础设施管理的优化。&lt;h4&gt;翻译&lt;/h4&gt;城市数字孪生是使用多源数据以及数据分析来优化城市规划、基础设施管理和决策的虚拟城市复制品。为了这个目的，我们提出一个聚焦于单栋建筑规模的框架。通过连接到谷歌地图平台API等云地图平台，利用ChatGPT(4o)和Deepseek-V3/R1的最新多智能体大型语言模型数据分析，以及使用基于高斯喷溅的网格提取管道，我们的数字孪生建筑框架能够检索建筑的3D模型、视觉描述，并实现基于地址、邮政编码或地理坐标的云映射集成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are virtual replicas of cities that use multi-source dataand data analytics to optimize urban planning, infrastructure management, anddecision-making. Towards this, we propose a framework focused on thesingle-building scale. By connecting to cloud mapping platforms such as GoogleMap Platforms APIs, by leveraging state-of-the-art multi-agent Large LanguageModels data analysis using ChatGPT(4o) and Deepseek-V3/R1, and by using ourGaussian Splatting-based mesh extraction pipeline, our Digital Twin Buildingsframework can retrieve a building's 3D model, visual descriptions, and achievecloud-based mapping integration with large language model-based data analyticsusing a building's address, postal code, or geographic coordinates.</description>
      <author>example@mail.com (Kyle Gao, Dening Lu, Liangzhi Li, Nan Chen, Hongjie He, Linlin Xu, Jonathan Li)</author>
      <guid isPermaLink="false">2502.05769v3</guid>
      <pubDate>Tue, 22 Apr 2025 14:21:18 +0800</pubDate>
    </item>
    <item>
      <title>CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning</title>
      <link>http://arxiv.org/abs/2504.13820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CheXWorld的自监督世界模型，旨在通过编码常识知识来建立通用机器学习模型，特别是在放射影像学领域。&lt;h4&gt;背景&lt;/h4&gt;人类能够发展内部世界模型，这些模型能够编码常识知识，告诉我们世界如何运作，并预测自己行为的后果。这一概念在建立通用机器学习模型方面展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发CheXWorld，第一个针对放射影像的自监督世界模型，以同时模拟医疗放射科医生所需的三个关键医学知识方面。&lt;h4&gt;方法&lt;/h4&gt;CheXWorld框架同时模拟了以下三个方面：1）局部解剖结构；2）全局解剖布局；3）领域变化。通过定制的定性和定量分析，验证CheXWorld成功捕捉了这三个维度的医学知识。&lt;h4&gt;主要发现&lt;/h4&gt;CheXWorld成功捕捉了医学知识的三个维度，并在八个医学图像分类和分割基准测试中显示出优于现有自监督学习方法和大型医学基础模型的表现。&lt;h4&gt;结论&lt;/h4&gt;CheXWorld是一个强大的自监督世界模型，在放射影像学领域具有显著优势，并可通过迁移学习在多个医学图像任务中取得良好效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类可以发展内部世界模型，这些模型编码常识知识，告诉他们世界如何运作，并预测他们行为的后果。这一概念在近期初步工作中成为建立通用机器学习模型的一个有希望的途径，例如用于视觉表示学习。在这篇论文中，我们提出了CheXWorld，这是第一个针对放射影像的自监督世界模型的努力。具体来说，我们的工作开发了一个统一的框架，同时模拟了医疗放射科医生所需的三个关键医学知识方面，包括1）描述局部组织细粒度特征的局部解剖结构（例如，结构、形状和纹理）；2）描述人体全局组织的全局解剖布局（例如，器官和骨骼的布局）；3）领域变化，鼓励CheXWorld模拟放射影像不同外观领域的转变（例如，由于从不同医院、设备或患者收集放射影像而引起的清晰度、对比度和曝光度的变化）。经验上，我们设计了定制的定性和定量分析，揭示了CheXWorld成功捕捉了这些三个维度的医学知识。此外，八个医学图像分类和分割基准测试的迁移学习实验表明，CheXWorld在性能上显著优于现有的自监督学习方法和大型医学基础模型。代码和预训练模型可在https://github.com/LeapLabTHU/CheXWorld上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LeapLabTHU/CheXWorld&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can develop internal world models that encode common sense knowledge,telling them how the world works and predicting the consequences of theiractions. This concept has emerged as a promising direction for establishinggeneral-purpose machine-learning models in recent preliminary works, e.g., forvisual representation learning. In this paper, we present CheXWorld, the firsteffort towards a self-supervised world model for radiographic images.Specifically, our work develops a unified framework that simultaneously modelsthree aspects of medical knowledge essential for qualified radiologists,including 1) local anatomical structures describing the fine-grainedcharacteristics of local tissues (e.g., architectures, shapes, and textures);2) global anatomical layouts describing the global organization of the humanbody (e.g., layouts of organs and skeletons); and 3) domain variations thatencourage CheXWorld to model the transitions across different appearancedomains of radiographs (e.g., varying clarity, contrast, and exposure caused bycollecting radiographs from different hospitals, devices, or patients).Empirically, we design tailored qualitative and quantitative analyses,revealing that CheXWorld successfully captures these three dimensions ofmedical knowledge. Furthermore, transfer learning experiments across eightmedical image classification and segmentation benchmarks showcase thatCheXWorld significantly outperforms existing SSL methods and large-scalemedical foundation models. Code &amp; pre-trained models are available athttps://github.com/LeapLabTHU/CheXWorld.</description>
      <author>example@mail.com (Yang Yue, Yulin Wang, Chenxin Tao, Pan Liu, Shiji Song, Gao Huang)</author>
      <guid isPermaLink="false">2504.13820v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
  <item>
      <title>On the Relationship Between Robustness and Expressivity of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.13786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at AISTAST 2025, will add DOI when available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）对位翻转攻击（BFAs）的脆弱性，通过引入一个分析框架来研究架构特征、图属性及其相互作用的影響。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在区分非同构图的能力上具有表达性，这取决于节点邻居的编码。本文考察了用于此目的的神经多重集函数的脆弱性，并建立了正式标准来描述GNN因BFAs而失去表达性的敏感性。&lt;h4&gt;目的&lt;/h4&gt;分析同质化、图结构多样性、特征编码和激活函数对GNN鲁棒性的影响，并得出理论界限来量化在数据集上降低GNN表达性所需的位翻转数量。&lt;h4&gt;方法&lt;/h4&gt;引入分析框架，建立正式标准，进行理论分析，使用十个真实世界数据集进行实证研究。&lt;h4&gt;主要发现&lt;/h4&gt;ReLU激活的GNN在高度同质化的图上，使用低维或one-hot编码特征时，特别容易受到BFAs的影响。&lt;h4&gt;结论&lt;/h4&gt;实证结果表明，理论洞察具有统计显著性，并提供了减轻表达性关键应用中BFA风险的可行方法。&lt;h4&gt;翻译&lt;/h4&gt;We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flip attacks (BFAs) by introducing an analytical framework to study the influence of architectural features, graph properties, and their interaction. The expressivity of GNNs refers to their ability to distinguish non-isomorphic graphs and depends on the encoding of node neighborhoods. We examine the vulnerability of neural multiset functions commonly used for this purpose and establish formal criteria to characterize a GNN's susceptibility to losing expressivity due to BFAs. This enables an analysis of the impact of homophily, graph structural variety, feature encoding, and activation functions on GNN robustness. We derive theoretical bounds for the number of bit flips required to degrade GNN expressivity on a dataset, identifying ReLU-activated GNNs operating on highly homophilous graphs with low-dimensional or one-hot encoded features as particularly susceptible. Empirical results using ten real-world datasets confirm the statistical significance of our key theoretical insights and offer actionable results to mitigate BFA risks in expressivity-critical applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flipattacks (BFAs) by introducing an analytical framework to study the influence ofarchitectural features, graph properties, and their interaction.  The expressivity of GNNs refers to their ability to distinguishnon-isomorphic graphs and depends on the encoding of node neighborhoods. Weexamine the vulnerability of neural multiset functions commonly used for thispurpose and establish formal criteria to characterize a GNN's susceptibility tolosing expressivity due to BFAs. This enables an analysis of the impact ofhomophily, graph structural variety, feature encoding, and activation functionson GNN robustness. We derive theoretical bounds for the number of bit flipsrequired to degrade GNN expressivity on a dataset, identifying ReLU-activatedGNNs operating on highly homophilous graphs with low-dimensional or one-hotencoded features as particularly susceptible. Empirical results using tenreal-world datasets confirm the statistical significance of our key theoreticalinsights and offer actionable results to mitigate BFA risks inexpressivity-critical applications.</description>
      <author>example@mail.com (Lorenz Kummer, Wilfried N. Gansterer, Nils M. Kriege)</author>
      <guid isPermaLink="false">2504.13786v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis</title>
      <link>http://arxiv.org/abs/2504.13754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CMSwinKAN的病理图像分类模型，用于克服现有自动化病理图像分类方法的局限性，提高诊断准确性。&lt;h4&gt;背景&lt;/h4&gt;神经母细胞瘤是儿童最常见的实体恶性肿瘤之一，其病理诊断对于患者预后至关重要。然而，当前的诊断实践主要依赖病理医生的主观手动检查，导致准确性不一致。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于对比学习的多尺度特征融合模型CMSwinKAN，以提高病理图像分类的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;CMSwinKAN通过在SwinTransformer架构中集成核激活网络，增强其多层感知器和分类头模块，从而提高模型的可解释性和准确性。此外，还引入了一种启发式软投票机制，以指导将补丁级预测无缝桥接到全切片图像级分类。&lt;h4&gt;主要发现&lt;/h4&gt;CMSwinKAN在PpNTs数据集和BreakHis数据集上进行了验证，结果显示其性能优于基于大数据集预训练的现有最先进病理学模型。&lt;h4&gt;结论&lt;/h4&gt;CMSwinKAN能够有效提高病理图像分类的准确性和可解释性，为临床诊断提供了一种新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the SwinTransformer architecture by integrating a Kernel Activation Network within its multi-layer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics clinicians' comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at https://github.com/JSLiam94/CMSwinKAN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuroblastoma, adrenal-derived, is among the most common pediatric solidmalignancies, characterized by significant clinical heterogeneity. Timely andaccurate pathological diagnosis from hematoxylin and eosin-stained whole slideimages is critical for patient prognosis. However, current diagnostic practicesprimarily rely on subjective manual examination by pathologists, leading toinconsistent accuracy. Existing automated whole slide image classificationmethods encounter challenges such as poor interpretability, limited featureextraction capabilities, and high computational costs, restricting theirpractical clinical deployment. To overcome these limitations, we proposeCMSwinKAN, a contrastive-learning-based multi-scale feature fusion modeltailored for pathological image classification, which enhances the SwinTransformer architecture by integrating a Kernel Activation Network within itsmultilayer perceptron and classification head modules, significantly improvingboth interpretability and accuracy. By fusing multi-scale features andleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'comprehensive approach, effectively capturing global and local tissuecharacteristics. Additionally, we introduce a heuristic soft voting mechanismguided by clinical insights to seamlessly bridge patch-level predictions towhole slide image-level classifications. We validate CMSwinKAN on the PpNTsdataset, which was collaboratively established with our partner hospital andthe publicly accessible BreakHis dataset. Results demonstrate that CMSwinKANperforms better than existing state-of-the-art pathology-specific modelspre-trained on large datasets. Our source code is available athttps://github.com/JSLiam94/CMSwinKAN.</description>
      <author>example@mail.com (Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu)</author>
      <guid isPermaLink="false">2504.13754v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>RefComp: A Reference-guided Unified Framework for Unpaired Point Cloud Completion</title>
      <link>http://arxiv.org/abs/2504.13788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无配对点云补全框架，即参考引导补全（RefComp）框架，该框架在类感知和类非感知训练设置中均表现出强大的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无配对点云补全方法具有类感知性，即每个对象类别都需要一个单独的模型，它们的泛化能力有限，在面临广泛的三维对象点云时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无配对点云补全框架，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;RefComp框架将无配对补全问题转化为形状转换问题，并在部分点云的潜在特征空间中解决。使用部分-完整点云对作为参考数据来指导补全过程，并使用具有共享参数的参考分支和目标分支，通过潜在形状融合模块（LSFM）进行形状融合和形状转换，以增强补全过程中的结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;RefComp框架在类感知训练设置中实现了最先进的性能，在类非感知训练设置中在虚拟扫描和真实世界数据集上取得了具有竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;RefComp框架能够有效提高无配对点云补全的性能，适用于不同类型的点云数据。&lt;h4&gt;翻译&lt;/h4&gt;The unpaired point cloud completion task aims to complete a partial point cloud by using models trained with no ground truth. Existing unpaired point cloud completion methods are class-aware, i.e., a separate model is needed for each object class. Since they have limited generalization capabilities, these methods perform poorly in real-world scenarios when confronted with a wide range of point clouds of generic 3D objects. In this paper, we propose a novel unpaired point cloud completion framework, namely the Reference-guided Completion (RefComp) framework, which attains strong performance in both the class-aware and class-agnostic training settings. The RefComp framework transforms the unpaired completion problem into a shape translation problem, which is solved in the latent feature space of the partial point clouds. To this end, we introduce the use of partial-complete point cloud pairs, which are retrieved by using the partial point cloud to be completed as a template. These point cloud pairs are used as reference data to guide the completion process. Our RefComp framework uses a reference branch and a target branch with shared parameters for shape fusion and shape translation via a Latent Shape Fusion Module (LSFM) to enhance the structural features along the completion pipeline. Extensive experiments demonstrate that the RefComp framework achieves not only state-of-the-art performance in the class-aware training setting but also competitive results in the class-agnostic training setting on both virtual scans and real-world datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unpaired point cloud completion task aims to complete a partial pointcloud by using models trained with no ground truth. Existing unpaired pointcloud completion methods are class-aware, i.e., a separate model is needed foreach object class. Since they have limited generalization capabilities, thesemethods perform poorly in real-world scenarios when confronted with a widerange of point clouds of generic 3D objects. In this paper, we propose a novelunpaired point cloud completion framework, namely the Reference-guidedCompletion (RefComp) framework, which attains strong performance in both theclass-aware and class-agnostic training settings. The RefComp frameworktransforms the unpaired completion problem into a shape translation problem,which is solved in the latent feature space of the partial point clouds. Tothis end, we introduce the use of partial-complete point cloud pairs, which areretrieved by using the partial point cloud to be completed as a template. Thesepoint cloud pairs are used as reference data to guide the completion process.Our RefComp framework uses a reference branch and a target branch with sharedparameters for shape fusion and shape translation via a Latent Shape FusionModule (LSFM) to enhance the structural features along the completion pipeline.Extensive experiments demonstrate that the RefComp framework achieves not onlystate-of-the-art performance in the class-aware training setting but alsocompetitive results in the class-agnostic training setting on both virtualscans and real-world datasets.</description>
      <author>example@mail.com (Yixuan Yang, Jinyu Yang, Zixiang Zhao, Victor Sanchez, Feng Zheng)</author>
      <guid isPermaLink="false">2504.13788v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering</title>
      <link>http://arxiv.org/abs/2504.13590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication through the upcoming CVPR Workshop on open  scene understanding with foundation models (OPENSUN3D)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HAEC（Hierarchical vocab-Agnostic Expert Clustering）的3D场景理解技术，用于处理城市规模的三维数据集，并通过无标注的合成标签流程进行数据标注。&lt;h4&gt;背景&lt;/h4&gt;传统的3D场景理解技术依赖于手动标注的标签集，而近年来，一类新的开放词汇3D场景理解技术出现，尽管在小场景上取得成功，但现有方法无法高效扩展到城市规模的三维数据集。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理城市规模三维数据集的开放词汇场景理解技术，并实现无标注的合成标签流程。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于超级点图的聚类方法HAEC，其核心是一个新的混合专家图Transformer模型。该方法在Sensat Urban city-scale数据集上进行了首次应用，并展示了从原始点云中衍生出的合成标签流程。&lt;h4&gt;主要发现&lt;/h4&gt;HAEC技术能够高效处理城市规模的三维数据集，并通过合成标签流程实现了无标注的数据标注。&lt;h4&gt;结论&lt;/h4&gt;HAEC技术有助于解锁对密集城市三维场景的复杂操作，并为数字孪生的处理开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的3D场景理解技术通常基于手动标注的标签集，但近年来，一类新的开放词汇3D场景理解技术已经出现。尽管这种范式在小场景上取得了成功，但现有方法无法有效地扩展到城市规模的三维数据集。在本文中，我们提出了Hierarchical vocab-Agnostic Expert Clustering（HAEC），这是一个基于超级点图的聚类方法，它使用一个新颖的混合专家图Transformer作为其骨干。我们将这种高度可扩展的方法应用于开放词汇场景理解的首次应用，在Sensat Urban city-scale数据集上。我们还展示了一个完全由原始点云衍生出的合成标签流程，无需手动标注。我们的技术可以帮助解锁对密集城市三维场景的复杂操作，并为数字孪生的处理开辟新的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional 3D scene understanding techniques are generally predicated onhand-annotated label sets, but in recent years a new class of open-vocabulary3D scene understanding techniques has emerged. Despite the success of thisparadigm on small scenes, existing approaches cannot scale efficiently tocity-scale 3D datasets. In this paper, we present Hierarchical vocab-AgnosticExpert Clustering (HAEC), after the latin word for 'these', a superpoint graphclustering based approach which utilizes a novel mixture of experts graphtransformer for its backbone. We administer this highly scalable approach tothe first application of open-vocabulary scene understanding on the SensatUrbancity-scale dataset. We also demonstrate a synthetic labeling pipeline which isderived entirely from the raw point clouds with no hand-annotation. Ourtechnique can help unlock complex operations on dense urban 3D scenes and opena new path forward in the processing of digital twins.</description>
      <author>example@mail.com (Alexander Rusnak, Frédéric Kaplan)</author>
      <guid isPermaLink="false">2504.13590v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration</title>
      <link>http://arxiv.org/abs/2504.13717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Personal adaptation and expansion of doctoral thesis (originally  submitted in Oct 2024, revisioned in Jan 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究旨在将深度学习与人类推理能力相结合，以实现更高效、可解释和鲁棒的医疗图像分类。研究从可解释性、因果性和生物视觉三个角度进行探索。&lt;h4&gt;背景&lt;/h4&gt;研究首先评估了神经网络的可视化技术在医学图像中的应用，并验证了一种用于乳腺肿块分类的“设计可解释”方法。接着，对XAI和因果性交叉领域的综合回顾，并介绍了一个通用的研究框架。&lt;h4&gt;目的&lt;/h4&gt;目的是使深度学习模型更符合人类的推理能力，提高图像分类的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;方法包括：提出新的模块以利用医学图像中的特征共现，提出CROCODILE框架整合因果概念、对比学习、特征解耦和先验知识，以及探索生物视觉并设计CoCoReco网络。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现包括：简单激活最大化缺乏对医学图像深度学习模型的洞察；原型-部分学习有效且与放射学一致；XAI和因果机器学习紧密相连；在无需先验信息的情况下，可以利用弱因果信号来提高性能和可解释性；框架在医学领域和分布外数据中具有泛化能力；结合生物电路模式可以提高与人类一致的识别。&lt;h4&gt;结论&lt;/h4&gt;该研究为与人类对齐的深度学习做出了贡献，并指出了连接研究和临床应用的方法，对提高信任、诊断准确性和安全部署具有意义。&lt;h4&gt;翻译&lt;/h4&gt;这项工作将深度学习与人类推理能力相结合，旨在实现更高效、可解释和鲁棒的图像分类。我们从可解释性、因果性和生物视觉三个角度来探讨这个问题。在介绍和背景之后，我们首先评估了神经网络的可视化技术在医学图像中的应用，并验证了一种用于乳腺肿块分类的“设计可解释”方法。接着，我们对XAI和因果性交叉领域的综合回顾，并介绍了一个通用的研究框架。在因果关系方向上，我们提出了利用医学图像中特征共现的新模块，导致更有效和可解释的预测。我们进一步引入了CROCODILE，这是一个整合因果概念、对比学习、特征解耦和先验知识的通用框架，以增强泛化能力。最后，我们探索了生物视觉，检查人类如何识别物体，并提出了受连接性启发的网络CoCoReco，具有上下文感知的注意力机制。我们的关键发现包括：（i）简单激活最大化缺乏对医学图像深度学习模型的洞察；（ii）原型-部分学习有效且与放射学一致；（iii）XAI和因果机器学习紧密相连；（iv）在无需先验信息的情况下，可以利用弱因果信号来提高性能和可解释性；（v）我们的框架在医学领域和分布外数据中具有泛化能力；（vi）结合生物电路模式可以提高与人类一致的识别。这项工作为与人类对齐的深度学习做出了贡献，并指出了连接研究和临床应用的方法，对提高信任、诊断准确性和安全部署具有意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work aligns deep learning (DL) with human reasoning capabilities andneeds to enable more efficient, interpretable, and robust image classification.We approach this from three perspectives: explainability, causality, andbiological vision. Introduction and background open this work before divinginto operative chapters. First, we assess neural networks' visualizationtechniques for medical images and validate an explainable-by-design method forbreast mass classification. A comprehensive review at the intersection of XAIand causality follows, where we introduce a general scaffold to organize pastand future research, laying the groundwork for our second perspective. In thecausality direction, we propose novel modules that exploit featureco-occurrence in medical images, leading to more effective and explainablepredictions. We further introduce CROCODILE, a general framework thatintegrates causal concepts, contrastive learning, feature disentanglement, andprior knowledge to enhance generalization. Lastly, we explore biologicalvision, examining how humans recognize objects, and propose CoCoReco, aconnectivity-inspired network with context-aware attention mechanisms. Overall,our key findings include: (i) simple activation maximization lacks insight formedical imaging DL models; (ii) prototypical-part learning is effective andradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weakcausal signals can be leveraged without a priori information to improveperformance and interpretability; (v) our framework generalizes across medicaldomains and out-of-distribution data; (vi) incorporating biological circuitmotifs improves human-aligned recognition. This work contributes towardhuman-aligned DL and highlights pathways to bridge the gap between research andclinical adoption, with implications for improved trust, diagnostic accuracy,and safe deployment.</description>
      <author>example@mail.com (Gianluca Carloni)</author>
      <guid isPermaLink="false">2504.13717v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2504.13647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级的多模态框架，用于3D物体检测和轨迹预测，以帮助移动机器人实时感知3D空间中的行人、车辆和骑行者。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在执行任务时需要避开动态物体，但通常只有有限的计算资源。&lt;h4&gt;目的&lt;/h4&gt;开发一个轻量级的框架，以实现高精度和计算效率的3D物体检测和轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了激光雷达和摄像头输入，并提出了两个新型模块：Cross-Modal Deformable Transformer (CMDT) 用于物体检测，Reference Trajectory-based Multi-Class Transformer (RTMCT) 用于多类物体轨迹预测。&lt;h4&gt;主要发现&lt;/h4&gt;在CODa基准测试中，该系统在检测和轨迹预测方面优于现有方法，且在轮椅机器人上实现实时推理。&lt;h4&gt;结论&lt;/h4&gt;该系统具有出色的部署性和可重复性，相关代码和ROS推理版本已公开发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：移动服务机器人通常需要在执行任务时避开动态物体，但它们通常只有有限的计算资源。因此，我们提出了一种用于3D物体检测和轨迹预测的轻量级多模态框架。我们的系统协同整合了激光雷达和摄像头输入，以实现3D空间中行人、车辆和骑行者的实时感知。该框架提出了两个新颖的模块：1）用于高精度和可接受计算量的物体检测的跨模态可变形变换器（CMDT），2）用于多类物体高效和多样化轨迹预测的基于参考轨迹的多类变换器（RTMCT）。在CODa基准测试中的评估表明，该系统在检测（mAP提高2.03%）和轨迹预测（行人minADE5降低0.408m）方面优于现有方法。值得注意的是，该系统具有出色的部署性——当在配备入门级NVIDIA 3060 GPU的轮椅机器人上实现时，它以13.2 fps的速度实现实时推理。为了促进可重复性和实际部署，我们在https://github.com/TossherO/3D_Perception发布了该方法的相关代码，并在https://github.com/TossherO/ros_packages发布了其ROS推理版本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service mobile robots are often required to avoid dynamic objects whileperforming their tasks, but they usually have only limited computationalresources. So we present a lightweight multi-modal framework for 3D objectdetection and trajectory prediction. Our system synergistically integratesLiDAR and camera inputs to achieve real-time perception of pedestrians,vehicles, and riders in 3D space. The framework proposes two novel modules: 1)a Cross-Modal Deformable Transformer (CMDT) for object detection with highaccuracy and acceptable amount of computation, and 2) a ReferenceTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diversetrajectory prediction of mult-class objects with flexible trajectory lengths.Evaluations on the CODa benchmark demonstrate superior performance overexisting methods across detection (+2.03% in mAP) and trajectory prediction(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibitsexceptional deployability - when implemented on a wheelchair robot with anentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. Tofacilitate reproducibility and practical deployment, we release the relatedcode of the method at https://github.com/TossherO/3D_Perception and its ROSinference version at https://github.com/TossherO/ros_packages.</description>
      <author>example@mail.com (Yushen He, Lei Zhao, Tianchen Deng, Zipeng Fang, Weidong Chen)</author>
      <guid isPermaLink="false">2504.13647v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>KAN or MLP? Point Cloud Shows the Way Forward</title>
      <link>http://arxiv.org/abs/2504.13593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointKAN的新方法，应用于点云分析，通过引入Kolmogorov-Arnold Networks (KANs)来提高特征表示的效率。&lt;h4&gt;背景&lt;/h4&gt;多层感知器（MLPs）在点云分析中是基础组件，但在处理复杂几何结构时，其固定激活函数难以有效捕捉局部几何特征，且存在参数效率低和模型冗余的问题。&lt;h4&gt;目的&lt;/h4&gt;研究KANs在点云分析中分层特征表示的有效性。&lt;h4&gt;方法&lt;/h4&gt;PointKAN包括几何仿射模块（GAM）来转换局部特征，提高模型对几何变化的鲁棒性；局部特征处理（LFP）中并行结构提取组级特征和全局上下文；全局特征处理（GFP）结合并处理这些特征；通过重复操作，感受野逐渐扩大，使模型能够捕捉点云的完整几何信息。此外，PointKAN-elite变体开发了高效的KANs（Efficient-KANs），以降低参数数量和计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PointKAN在基准数据集（如ModelNet40、ScanObjectNN和ShapeNetPart）上优于PointMLP，尤其在少样本学习任务中表现突出，同时显著降低了参数数量和计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;PointKAN展示了基于KANs架构在3D视觉中的潜力，并为点云理解的研究开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多层感知器（MLPs）已成为点云分析中的基本架构组件，由于其有效的特征学习机制。然而，当处理点云中的复杂几何结构时，MLPs的固定激活函数难以有效地捕捉局部几何特征，同时存在参数效率低和模型冗余的问题。在本文中，我们提出了PointKAN，将Kolmogorov-Arnold Networks（KANs）应用于点云分析任务，以研究其在分层特征表示中的有效性。首先，我们引入了几何仿射模块（GAM）来转换局部特征，提高了模型对几何变化的鲁棒性。其次，在局部特征处理（LFP）中，并行结构提取了组级特征和全局上下文，提供了对细粒度和整体结构的丰富表示。最后，这些特征在全局特征处理（GFP）中被结合并处理。通过重复这些操作，感受野逐渐扩大，使模型能够捕捉点云的完整几何信息。为了克服标准KANs的高参数计数和计算效率低下的问题，我们在PointKAN-elite变体中开发了高效的KANs（Efficient-KANs），显著降低了参数数量同时保持了准确性。实验结果表明，PointKAN在基准数据集（如ModelNet40、ScanObjectNN和ShapeNetPart）上优于PointMLP，尤其是在少样本学习任务中表现突出。此外，PointKAN在参数数量和计算复杂度（FLOPs）方面实现了显著降低。这项工作突出了基于KANs架构在3D视觉中的潜力，并为点云理解的研究开辟了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-Layer Perceptrons (MLPs) have become one of the fundamentalarchitectural component in point cloud analysis due to its effective featurelearning mechanism. However, when processing complex geometric structures inpoint clouds, MLPs' fixed activation functions struggle to efficiently capturelocal geometric features, while suffering from poor parameter efficiency andhigh model redundancy. In this paper, we propose PointKAN, which appliesKolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigatetheir efficacy in hierarchical feature representation. First, we introduce aGeometric Affine Module (GAM) to transform local features, improving themodel's robustness to geometric variations. Next, in the Local FeatureProcessing (LFP), a parallel structure extracts both group-level features andglobal context, providing a rich representation of both fine details andoverall structure. Finally, these features are combined and processed in theGlobal Feature Processing (GFP). By repeating these operations, the receptivefield gradually expands, enabling the model to capture complete geometricinformation of the point cloud. To overcome the high parameter counts andcomputational inefficiency of standard KANs, we develop Efficient-KANs in thePointKAN-elite variant, which significantly reduces parameters whilemaintaining accuracy. Experimental results demonstrate that PointKANoutperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN,and ShapeNetPart, with particularly strong performance in Few-shot Learningtask. Additionally, PointKAN achieves substantial reductions in parametercounts and computational complexity (FLOPs). This work highlights the potentialof KANs-based architectures in 3D vision and opens new avenues for research inpoint cloud understanding.</description>
      <author>example@mail.com (Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su)</author>
      <guid isPermaLink="false">2504.13593v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.13580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Github Page: https://github.com/stefan-ainetter/SCANnotatepp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了高级3D场景理解的重要性，并提出了使用自动检索合成CAD模型的方法来生成高质量的3D标注数据，以训练深度学习模型。&lt;h4&gt;背景&lt;/h4&gt;生成准确的3D标注数据对深度学习模型的发展是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;利用自动检索合成CAD模型的方法，将生成的数据作为训练监督深度学习模型的高质量真实数据。&lt;h4&gt;方法&lt;/h4&gt;采用与之前用于自动标注ScanNet场景中物体9D姿态和CAD模型相似的流程，应用于ScanNet++ v1数据集，该数据集之前缺乏此类标注。&lt;h4&gt;主要发现&lt;/h4&gt;不仅能够在自动获取的标注数据上训练深度学习模型，而且这些模型的表现优于在手动标注数据上训练的模型。&lt;h4&gt;结论&lt;/h4&gt;自动3D标注具有提高模型性能的潜力，同时显著降低标注成本。作者将发布他们的标注数据（SCANnotate++）和训练模型，以支持未来3D场景理解的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高级3D场景理解在许多应用中至关重要。然而，生成准确3D标注的挑战使得深度学习模型的发展困难。我们转向最近在自动检索合成CAD模型方面的进展，并表明此类方法生成的数据可以用作训练监督深度学习模型的高质量真实数据。更确切地说，我们采用了与之前用于自动标注ScanNet场景中物体9D姿态和CAD模型相似的流程。这次，我们将其应用于之前缺乏此类标注的ScanNet++ v1数据集。我们的发现表明，不仅可以在这些自动获取的标注数据上训练深度学习模型，而且这些模型的表现优于在手动标注数据上训练的模型。我们在两个不同的任务上验证了这一点：点云补全和单视图CAD模型检索与对齐。我们的结果强调了自动3D标注提高模型性能的潜力，同时显著降低标注成本。为了支持未来3D场景理解的研究，我们将发布我们的标注数据，我们称之为SCANnotate++，以及我们的训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-level 3D scene understanding is essential in many applications. However,the challenges of generating accurate 3D annotations make development of deeplearning models difficult. We turn to recent advancements in automaticretrieval of synthetic CAD models, and show that data generated by such methodscan be used as high-quality ground truth for training supervised deep learningmodels. More exactly, we employ a pipeline akin to the one previously used toautomatically annotate objects in ScanNet scenes with their 9D poses and CADmodels. This time, we apply it to the recent ScanNet++ v1 dataset, whichpreviously lacked such annotations. Our findings demonstrate that it is notonly possible to train deep learning models on these automatically-obtainedannotations but that the resulting models outperform those trained on manuallyannotated data. We validate this on two distinct tasks: point cloud completionand single-view CAD model retrieval and alignment. Our results underscore thepotential of automatic 3D annotations to enhance model performance whilesignificantly reducing annotation costs. To support future research in 3D sceneunderstanding, we will release our annotations, which we call SCANnotate++,along with our trained models.</description>
      <author>example@mail.com (Yuchen Rao, Stefan Ainetter, Sinisa Stekovic, Vincent Lepetit, Friedrich Fraundorfer)</author>
      <guid isPermaLink="false">2504.13580v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems</title>
      <link>http://arxiv.org/abs/2504.13768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Equi-Euler GraphNet的物理信息图神经网络，用于多体动态系统的实时建模，同时预测内部力和全局轨迹，以支持故障检测和预测性维护。&lt;h4&gt;背景&lt;/h4&gt;准确的多体动态系统实时建模对于实现跨行业的数字孪生应用至关重要。然而，联合预测内部载荷和系统轨迹仍然是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够同时预测多体系统的内部力和全局轨迹，以支持故障检测和预测性维护。&lt;h4&gt;方法&lt;/h4&gt;Equi-Euler GraphNet是一种基于物理信息的图神经网络，它引入了两种归纳偏差：一是等变消息传递方案，二是基于欧拉积分的时间感知迭代节点更新机制。该方法适用于圆柱滚子轴承，并能够在未经训练的速度、载荷和配置下准确预测载荷和轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;Equi-Euler GraphNet在圆柱滚子轴承上表现出色，能够将环动力学与滚动元件的约束运动解耦。它在高保真多物理场仿真上训练，并在未见过的速度、载荷和配置下准确预测载荷和轨迹，优于现有的专注于轨迹预测的GNNs。&lt;h4&gt;结论&lt;/h4&gt;Equi-Euler GraphNet实现了一个高达200倍的速度提升，同时保持了与传统求解器相当的精度，为数字孪生、设计和维护提供了一个高效的降阶模型。&lt;h4&gt;翻译&lt;/h4&gt;Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads such as contact forces act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivariant message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate real-time modeling of multi-body dynamical systems is essential forenabling digital twin applications across industries. While many data-drivenapproaches aim to learn system dynamics, jointly predicting internal loads andsystem trajectories remains a key challenge. This dual prediction is especiallyimportant for fault detection and predictive maintenance, where internalloads-such as contact forces-act as early indicators of faults, reflecting wearor misalignment before affecting motion. These forces also serve as inputs todegradation models (e.g., crack growth), enabling damage prediction andremaining useful life estimation. We propose Equi-Euler GraphNet, aphysics-informed graph neural network (GNN) that simultaneously predictsinternal forces and global trajectories in multi-body systems. In thismesh-free framework, nodes represent system components and edges encodeinteractions. Equi-Euler GraphNet introduces two inductive biases: (1) anequivariant message-passing scheme, interpreting edge messages as interactionforces consistent under Euclidean transformations; and (2) a temporal-awareiterative node update mechanism, based on Euler integration, to captureinfluence of distant interactions over time. Tailored for cylindrical rollerbearings, it decouples ring dynamics from constrained motion of rollingelements. Trained on high-fidelity multiphysics simulations, Equi-EulerGraphNet generalizes beyond the training distribution, accurately predictingloads and trajectories under unseen speeds, loads, and configurations. Itoutperforms state-of-the-art GNNs focused on trajectory prediction, deliveringstable rollouts over thousands of time steps with minimal error accumulation.Achieving up to a 200x speedup over conventional solvers while maintainingcomparable accuracy, it serves as an efficient reduced-order model for digitaltwins, design, and maintenance.</description>
      <author>example@mail.com (Vinay Sharma, Rémi Tanguy Oddon, Pietro Tesini, Jens Ravesloot, Cees Taal, Olga Fink)</author>
      <guid isPermaLink="false">2504.13768v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems</title>
      <link>http://arxiv.org/abs/2504.13648v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于YOLOv8-seg模型的公路异常检测方法，用于自动识别和表征路面坑洼，旨在提高道路维护和行车安全。&lt;h4&gt;背景&lt;/h4&gt;传统的路面坑洼检测需要人工分析，过程繁琐且耗时。现有的机器学习方法在全面表征路面坑洼方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;利用迁移学习，采用预训练的YOLOv8-seg模型，通过数字图像自动表征路面坑洼。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含图像及其对应深度图的新数据集，收集自沙特阿拉伯Al-Khobar城市和KFUPM校园的不同道路环境。方法包括坑洼检测和分割，以精确定位坑洼并计算其面积。然后将分割图像与其深度图合并，以提取坑洼的详细深度信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的集成分割和深度数据提供了比先前基于深度学习的公路异常检测系统更全面的表征。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅能够显著提高自动驾驶导航的检测和表征能力，还有助于道路维护部门更有效地应对道路损害。&lt;h4&gt;翻译&lt;/h4&gt;摘要：道路异常检测在道路维护和增强驾驶员及车辆安全方面起着至关重要的作用。最近的道路异常检测机器学习方法克服了人工分析和异常计数繁琐耗时的过程；然而，它们往往在提供路面坑洼的完整表征方面存在不足。在本文中，我们利用迁移学习，通过采用预训练的YOLOv8-seg模型，利用仪表盘摄像头捕获的数字图像自动表征坑洼。我们的工作包括创建一个包含图像及其对应深度图的新数据集，这些图像和深度图是从沙特阿拉伯Al-Khobar城市和KFUPM校园的不同道路环境中收集的。我们的方法执行坑洼检测和分割，以精确定位坑洼并计算其面积。随后，将分割图像与其深度图合并，以提取关于坑洼的详细深度信息。这种分割和深度数据的集成提供了比先前基于深度学习的公路异常检测系统更全面的表征。总的来说，这种方法不仅有可能显著提高自动驾驶导航的检测和表征能力，还有助于道路维护部门更有效地应对道路损害。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road anomaly detection plays a crucial role in road maintenance and inenhancing the safety of both drivers and vehicles. Recent machine learningapproaches for road anomaly detection have overcome the tedious andtime-consuming process of manual analysis and anomaly counting; however, theyoften fall short in providing a complete characterization of road potholes. Inthis paper, we leverage transfer learning by adopting a pre-trained YOLOv8-segmodel for the automatic characterization of potholes using digital imagescaptured from a dashboard-mounted camera. Our work includes the creation of anovel dataset, comprising both images and their corresponding depth maps,collected from diverse road environments in Al-Khobar city and the KFUPM campusin Saudi Arabia. Our approach performs pothole detection and segmentation toprecisely localize potholes and calculate their area. Subsequently, thesegmented image is merged with its depth map to extract detailed depthinformation about the potholes. This integration of segmentation and depth dataoffers a more comprehensive characterization compared to previous deeplearning-based road anomaly detection systems. Overall, this method not onlyhas the potential to significantly enhance autonomous vehicle navigation byimproving the detection and characterization of road hazards but also assistsroad maintenance authorities in responding more effectively to road damage.</description>
      <author>example@mail.com (Uthman Baroudi, Alala BaHamid, Yasser Elalfy, Ziad Al Alami)</author>
      <guid isPermaLink="false">2504.13648v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Consensus-aware Contrastive Learning for Group Recommendation</title>
      <link>http://arxiv.org/abs/2504.13703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoCoRec的共识感知对比学习方法，旨在解决小组推荐中共识获取和个性化平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;小组推荐旨在为用户群体提供个性化的项目建议，但如何充分反映个体成员的多样化兴趣是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过共识感知对比学习方法，解决小组推荐中共识获取和个性化平衡的问题。&lt;h4&gt;方法&lt;/h4&gt;CoCoRec通过对比学习来建模小组共识，使用transformer编码器共同学习用户和小组表示，以更好地模拟小组内部动态。此外，对比目标有助于减少高频用户交互引起的过拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准数据集上的实验表明，CoCoRec在个人和小组推荐场景中均优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;共识感知对比学习方法在小组推荐任务中是有效的，并能够提供更稳健和有代表性的小组嵌入。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CoCoRec的共识感知对比学习方法，旨在解决小组推荐中共识获取和个性化平衡的问题。小组推荐旨在为用户群体提供个性化的项目建议，但如何充分反映个体成员的多样化兴趣是一个挑战。旨在通过共识感知对比学习方法，解决小组推荐中共识获取和个性化平衡的问题。CoCoRec通过对比学习来建模小组共识，使用transformer编码器共同学习用户和小组表示，以更好地模拟小组内部动态。此外，对比目标有助于减少高频用户交互引起的过拟合。在四个基准数据集上的实验表明，CoCoRec在个人和小组推荐场景中均优于最先进的方法。共识感知对比学习方法在小组推荐任务中是有效的，并能够提供更稳健和有代表性的小组嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Group recommendation aims to provide personalized item suggestions to a groupof users by reflecting their collective preferences. A fundamental challenge inthis task is deriving a consensus that adequately represents the diverseinterests of individual group members. Despite advancements made by deeplearning-based models, existing approaches still struggle in two main areas:(1) Capturing consensus in small-group settings, which are more prevalent inreal-world applications, and (2) Balancing individual preferences with overallgroup performance, particularly in hypergraph-based methods that tend toemphasize group accuracy at the expense of personalization. To address thesechallenges, we introduce a Consensus-aware Contrastive Learning for GroupRecommendation (CoCoRec) that models group consensus through contrastivelearning. CoCoRec utilizes a transformer encoder to jointly learn user andgroup representations, enabling richer modeling of intra-group dynamics.Additionally, the contrastive objective helps reduce overfitting fromhigh-frequency user interactions, leading to more robust and representativegroup embeddings. Experiments conducted on four benchmark datasets show thatCoCoRec consistently outperforms state-of-the-art baselines in both individualand group recommendation scenarios, highlighting the effectiveness ofconsensus-aware contrastive learning in group recommendation tasks.</description>
      <author>example@mail.com (Soyoung Kim, Dongjun Lee, Jaekwang Kim)</author>
      <guid isPermaLink="false">2504.13703v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation</title>
      <link>http://arxiv.org/abs/2504.13614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ALDA4Rec的推荐系统方法，旨在解决基于图神经网络的推荐系统中的噪声和静态表示问题。&lt;h4&gt;背景&lt;/h4&gt;互联网的快速发展使得个性化推荐系统变得不可或缺，但基于图神经网络的推荐系统在处理噪声和静态表示方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效捕获用户-项目交互复杂性的推荐系统模型，同时提高推荐的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ALDA4Rec方法通过构建项目-项目图、通过社区检测过滤噪声并丰富用户-项目交互，使用图卷积网络学习短期表示，利用平均、GRU和注意力机制建模长期嵌入，并通过基于MLP的自适应加权策略动态优化长期用户偏好。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界数据集上的实验表明，ALDA4Rec在准确性和鲁棒性方面优于现有基线方法。&lt;h4&gt;结论&lt;/h4&gt;ALDA4Rec是一种有效的推荐系统方法，能够显著提高推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;The rapid growth of the internet has made personalized recommendation systems indispensable. Graph-based sequential recommendation systems, powered by GraphNeural Networks (GNNs), effectively capture complex user-item interactions but often face challenges such as noise and static representations. In this paper, we introduce the Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation (ALDA4Rec) method, a novel model that constructs an item-item graph, filters noise through community detection, and enriches user-item interactions. Graph Convolutional Networks (GCNs) are then employed to learn short-term representations, while averaging, GRUs, and attention mechanisms are utilized to model long-term embeddings. An MLP-based adaptive weighting strategy is further incorporated to dynamically optimize long-term user preferences. Experiments conducted on four real-world datasets demonstrate that ALDA4Rec outperforms state-of-the-art baselines, delivering notable improvements in both accuracy and robustness. The source code is available at https://github.com/zahraakhlaghi/ALDA4Rec.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of the internet has made personalized recommendation systemsindispensable. Graph-based sequential recommendation systems, powered by GraphNeural Networks (GNNs), effectively capture complex user-item interactions butoften face challenges such as noise and static representations. In this paper,we introduce the Adaptive Long-term Embedding with Denoising and Augmentationfor Recommendation (ALDA4Rec) method, a novel model that constructs anitem-item graph, filters noise through community detection, and enrichesuser-item interactions. Graph Convolutional Networks (GCNs) are then employedto learn short-term representations, while averaging, GRUs, and attentionmechanisms are utilized to model long-term embeddings. An MLP-based adaptiveweighting strategy is further incorporated to dynamically optimize long-termuser preferences. Experiments conducted on four real-world datasets demonstratethat ALDA4Rec outperforms state-of-the-art baselines, delivering notableimprovements in both accuracy and robustness. The source code is available athttps://github.com/zahraakhlaghi/ALDA4Rec.</description>
      <author>example@mail.com (Zahra Akhlaghi, Mostafa Haghir Chehreghani)</author>
      <guid isPermaLink="false">2504.13614v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Designing a reliable lateral movement detector using a graph foundation model</title>
      <link>http://arxiv.org/abs/2504.13527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型在网络安全领域的应用潜力，特别是通过图基础模型（GFMs）在横向移动检测中的实用性。&lt;h4&gt;背景&lt;/h4&gt;基础模型作为机器学习的新范式，通过在大规模和多样化的数据集上预训练，可以应用于各种下游任务，无需或仅需少量再训练。&lt;h4&gt;目的&lt;/h4&gt;研究GFMs在网络安全领域的可用性，特别是通过横向移动检测这一具体用例。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的GFM构建检测器，并在无需针对特定领域数据进行训练的情况下达到最先进的性能。&lt;h4&gt;主要发现&lt;/h4&gt;GFMs在横向移动检测中表现出色，证明了其在网络安全领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;GFMs在网络安全领域具有应用前景，有望加速创新。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近，基础模型作为机器学习（ML）的新范式而出现。这些模型在大规模和多样化的数据集上预训练，随后可以应用于各种下游任务，无需或仅需少量再训练。这使得没有高级ML专业知识的人也能构建ML应用，从而加速了许多领域的创新。然而，由于无法有效地处理网络流量捕获或二进制可执行文件等数据，基础模型在网络安全领域的应用受到阻碍。最近引入的图基础模型（GFMs）可能带来重大差异，因为图非常适合表示这些类型的数据。我们通过一个具体用例，即横向移动检测，来研究GFMs在网络安全中的可用性。使用预训练的GFM，我们构建了一个检测器，在不要求对特定领域数据进行任何训练的情况下达到了最先进的性能。因此，这项案例研究提供了关于GFMs在网络安全领域潜力的有力证据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have recently emerged as a new paradigm in machine learning(ML). These models are pre-trained on large and diverse datasets and cansubsequently be applied to various downstream tasks with little or noretraining. This allows people without advanced ML expertise to build MLapplications, accelerating innovation across many fields. However, the adoptionof foundation models in cybersecurity is hindered by their inability toefficiently process data such as network traffic captures or binaryexecutables. The recent introduction of graph foundation models (GFMs) couldmake a significant difference, as graphs are well-suited to representing thesetypes of data. We study the usability of GFMs in cybersecurity through the lensof one specific use case, namely lateral movement detection. Using apre-trained GFM, we build a detector that reaches state-of-the-art performancewithout requiring any training on domain-specific data. This case study thusprovides compelling evidence of the potential of GFMs for cybersecurity.</description>
      <author>example@mail.com (Corentin Larroche)</author>
      <guid isPermaLink="false">2504.13527v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Weak Cube R-CNN: Weakly Supervised 3D Detection using only 2D Bounding Boxes</title>
      <link>http://arxiv.org/abs/2504.13297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures. Accepted for 23rd Scandinavian Conference, SCIA  2025, Reykjavik, Iceland&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种弱监督的3D检测方法，用于减少数据需求，通过单目方法利用单个摄像头系统来减少昂贵的光达传感器或多摄像头设置的依赖。&lt;h4&gt;背景&lt;/h4&gt;单目3D目标检测在计算机视觉中至关重要，并在机器人和虚拟现实领域有广泛应用。然而，3D检测器通常以完全监督的方式进行训练，依赖于劳动密集且昂贵的3D标注数据。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过使用弱监督方法，降低对3D标注数据的依赖，同时提高检测精度。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为Weak Cube R-CNN的通用模型，该模型能够在推理时预测3D物体，仅需要2D框标注进行训练，通过利用3D立方体的二维投影之间的关系。该方法利用预训练的冻结基础2D模型来估计训练集中的深度和方向信息，并在训练过程中将这些估计值作为伪真实标签。设计损失函数时，通过结合外部模型的信息来避免3D标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与标注时间相等的Cube R-CNN基线相比，该方法在SUN RGB-D数据集上提高了准确性。虽然该方法在厘米级测量上不够精确，但为未来的研究提供了一个强大的基础。&lt;h4&gt;结论&lt;/h4&gt;该方法为3D检测提供了一种减少对3D标注数据依赖的新途径，为未来的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D object detection is an essential task in computer vision, and ithas several applications in robotics and virtual reality. However, 3D objectdetectors are typically trained in a fully supervised way, relying extensivelyon 3D labeled data, which is labor-intensive and costly to annotate. This workfocuses on weakly-supervised 3D detection to reduce data needs using amonocular method that leverages a singlecamera system over expensive LiDARsensors or multi-camera setups. We propose a general model Weak Cube R-CNN,which can predict objects in 3D at inference time, requiring only 2D boxannotations for training by exploiting the relationship between 2D projectionsof 3D cubes. Our proposed method utilizes pre-trained frozen foundation 2Dmodels to estimate depth and orientation information on a training set. We usethese estimated values as pseudo-ground truths during training. We design lossfunctions that avoid 3D labels by incorporating information from the externalmodels into the loss. In this way, we aim to implicitly transfer knowledge fromthese large foundation 2D models without having access to 3D bounding boxannotations. Experimental results on the SUN RGB-D dataset show increasedperformance in accuracy compared to an annotation time equalized Cube R-CNNbaseline. While not precise for centimetre-level measurements, this methodprovides a strong foundation for further research.</description>
      <author>example@mail.com (Andreas Lau Hansen, Lukas Wanzeck, Dim P. Papadopoulos)</author>
      <guid isPermaLink="false">2504.13297v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation</title>
      <link>http://arxiv.org/abs/2504.13440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于手术场景分割的新方法，旨在解决现有方法在处理静态图像限制和动态视频复杂性时的挑战。&lt;h4&gt;背景&lt;/h4&gt;手术场景分割对于机器人辅助腹腔镜手术的理解至关重要，但现有方法面临静态图像限制和动态视频复杂性的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决手术视频流中空间特征提取和忽略时间依赖性的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法名为时间非对称特征传播网络，是一种双向注意力架构，允许跨帧特征传播。它包含一个时间查询传播器，用于整合多方向一致性约束以增强帧特定特征表示，以及一个聚合的非对称特征金字塔模块，用于保留解剖结构和手术器械的判别性特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个公共基准测试上进行了评估，结果显示其在EndoVis2018上比当前SOTA方法提高了16.4%的mIoU，在Endoscapes2023上提高了3.3%的mAP。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提供时间指导和上下文推理，为手术场景理解提供了一种独特的框架，并在性能上优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical scene segmentation is crucial for robot-assisted laparoscopicsurgery understanding. Current approaches face two challenges: (i) static imagelimitations including ambiguous local feature similarities and fine-grainedstructural details, and (ii) dynamic video complexities arising from rapidinstrument motion and persistent visual occlusions. While existing methodsmainly focus on spatial feature extraction, they fundamentally overlooktemporal dependencies in surgical video streams. To address this, we presenttemporal asymmetric feature propagation network, a bidirectional attentionarchitecture enabling cross-frame feature propagation. The proposed methodcontains a temporal query propagator that integrates multi-directionalconsistency constraints to enhance frame-specific feature representation, andan aggregated asymmetric feature pyramid module that preserves discriminativefeatures for anatomical structures and surgical instruments. Our frameworkuniquely enables both temporal guidance and contextual reasoning for surgicalscene understanding. Comprehensive evaluations on two public benchmarks showthe proposed method outperforms the current SOTA methods by a large margin,with +16.4\% mIoU on EndoVis2018 and +3.3\% mAP on Endoscapes2023. The codewill be publicly available after paper acceptance.</description>
      <author>example@mail.com (Cheng Yuan, Yutong Ban)</author>
      <guid isPermaLink="false">2504.13440v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration</title>
      <link>http://arxiv.org/abs/2504.13568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures. Accepted by DAC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的跨工作负载CPU架构设计空间探索（DSE）方法，称为MetaDSE，旨在解决现有DSE方法中存在的过拟合、数据模糊性和工作负载差异等问题。&lt;h4&gt;背景&lt;/h4&gt;现有的跨工作负载设计空间探索方法通常使用迁移学习技术，从源工作负载中利用知识，以减少目标工作负载的模拟需求。&lt;h4&gt;目的&lt;/h4&gt;通过将跨工作负载CPU DSE任务重新定义为几样本元学习问题，并引入MetaDSE，旨在提高跨工作负载CPU DSE的效率。&lt;h4&gt;方法&lt;/h4&gt;MetaDSE利用模型无关的元学习来快速适应新的目标工作负载，并引入了一种称为工作负载自适应架构掩码算法的新颖知识迁移方法，以揭示架构的固有属性。&lt;h4&gt;主要发现&lt;/h4&gt;在SPEC CPU 2017上的实验表明，与最先进的方法相比，MetaDSE将预测误差减少了44.3%。&lt;h4&gt;结论&lt;/h4&gt;MetaDSE是一种高效且准确的设计空间探索方法，其开源代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨工作负载设计空间探索（DSE）在CPU架构设计中至关重要。现有的DSE方法通常采用迁移学习技术来利用源工作负载的知识，旨在最小化目标工作负载的模拟需求。然而，这些方法在过拟合、数据模糊性和工作负载差异方面存在困难。为了解决这些挑战，我们将跨工作负载CPU DSE任务重新定义为几样本元学习问题，并进一步引入MetaDSE。通过利用模型无关的元学习，MetaDSE快速适应新的目标工作负载，大大提高了跨工作负载CPU DSE的效率。此外，MetaDSE引入了一种名为工作负载自适应架构掩码算法的新颖知识迁移方法，以揭示架构的固有属性。在SPEC CPU 2017上的实验表明，与最先进的方法相比，MetaDSE将预测误差减少了44.3%。MetaDSE是开源的，可在https://anonymous.4open.science/r/Meta_DSE-02F8的匿名GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-workload design space exploration (DSE) is crucial in CPU architecturedesign. Existing DSE methods typically employ the transfer learning techniqueto leverage knowledge from source workloads, aiming to minimize the requirementof target workload simulation. However, these methods struggle withoverfitting, data ambiguity, and workload dissimilarity.  To address these challenges, we reframe the cross-workload CPU DSE task as afew-shot meta-learning problem and further introduce MetaDSE. By leveragingmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,greatly enhancing the efficiency of cross-workload CPU DSE. Additionally,MetaDSE introduces a novel knowledge transfer method called theworkload-adaptive architectural mask algorithm, which uncovers the inherentproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate thatMetaDSE significantly reduces prediction error by 44.3\% compared to thestate-of-the-art. MetaDSE is open-sourced and available at this\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}</description>
      <author>example@mail.com (Runzhen Xue, Hao Wu, Mingyu Yan, Ziheng Xiao, Xiaochun Ye, Dongrui Fan)</author>
      <guid isPermaLink="false">2504.13568v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation</title>
      <link>http://arxiv.org/abs/2504.13599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为ViG3D-UNet的3D视觉图神经网络框架，用于血管分割，以解决现有方法在血管连续分割和端点缺失问题上的挑战。&lt;h4&gt;背景&lt;/h4&gt;精确的血管分割对于冠状动脉可视化和冠心病诊断至关重要。然而，现有的血管分割方法面临着血管连续分割不连续和端点缺失的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进血管分割的连续性和准确性。&lt;h4&gt;方法&lt;/h4&gt;ViG3D-UNet方法结合了3D图表示和聚合在一个U型架构中，以促进连续的血管分割。ViG3D模块捕获体积血管连通性和拓扑结构，而卷积模块提取精细的血管细节。这两个分支通过通道注意力结合形成编码器特征。随后，一个纸夹形状的偏移解码器在稀疏特征空间中减少冗余计算，并将特征图尺寸恢复到原始输入尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共数据集ASOCA和ImageCAS上的评估表明，ViG3D-UNet在保持血管分割连通性的同时，实现了高分割精度，超过了竞争方法。&lt;h4&gt;结论&lt;/h4&gt;ViG3D-UNet是一种有效的血管分割方法，能够提高血管连续分割的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Accurate vascular segmentation is essential for coronary visualization and the diagnosis of coronary heart disease. This task involves the extraction of sparse tree-like vascular branches from the volumetric space. However, existing methods have faced significant challenges due to discontinuous vascular segmentation and missing endpoints. To address this issue, a 3D vision graph neural network framework, named ViG3D-UNet, was introduced. This method integrates 3D graph representation and aggregation within a U-shaped architecture to facilitate continuous vascular segmentation. The ViG3D module captures volumetric vascular connectivity and topology, while the convolutional module extracts fine vascular details. These two branches are combined through channel attention to form the encoder feature. Subsequently, a paperclip-shaped offset decoder minimizes redundant computations in the sparse feature space and restores the feature map size to match the original input dimensions. To evaluate the effectiveness of the proposed approach for continuous vascular segmentation, evaluations were performed on two public datasets, ASOCA and ImageCAS. The segmentation results show that the ViG3D-UNet surpassed competing methods in maintaining vascular segmentation connectivity while achieving high segmentation accuracy. Our code will be available soon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate vascular segmentation is essential for coronary visualization andthe diagnosis of coronary heart disease. This task involves the extraction ofsparse tree-like vascular branches from the volumetric space. However, existingmethods have faced significant challenges due to discontinuous vascularsegmentation and missing endpoints. To address this issue, a 3D vision graphneural network framework, named ViG3D-UNet, was introduced. This methodintegrates 3D graph representation and aggregation within a U-shapedarchitecture to facilitate continuous vascular segmentation. The ViG3D modulecaptures volumetric vascular connectivity and topology, while the convolutionalmodule extracts fine vascular details. These two branches are combined throughchannel attention to form the encoder feature. Subsequently, a paperclip-shapedoffset decoder minimizes redundant computations in the sparse feature space andrestores the feature map size to match the original input dimensions. Toevaluate the effectiveness of the proposed approach for continuous vascularsegmentation, evaluations were performed on two public datasets, ASOCA andImageCAS. The segmentation results show that the ViG3D-UNet surpassed competingmethods in maintaining vascular segmentation connectivity while achieving highsegmentation accuracy. Our code will be available soon.</description>
      <author>example@mail.com (Bowen Liu, Chunlei Meng, Wei Lin, Hongda Zhang, Ziqing Zhou, Zhongxue Gan, Chun Ouyang)</author>
      <guid isPermaLink="false">2504.13599v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>A Reinforcement Learning Method to Factual and Counterfactual Explanations for Session-based Recommendation</title>
      <link>http://arxiv.org/abs/2504.13632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FCESR的新型框架，用于解释会话推荐系统（SR）的预测，通过强调推荐项的充分性（事实性）和必要性（反事实性），提升推荐系统的透明度和可信度。&lt;h4&gt;背景&lt;/h4&gt;现有的会话推荐系统虽然取得了显著成功，但其复杂的“黑盒”性质往往难以解释推荐的原因，现有解释方法难以准确指出真正有影响力的因素。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架，能够揭示会话推荐系统推荐背后的真正原因，并提升推荐系统的透明度和可信度。&lt;h4&gt;方法&lt;/h4&gt;FCESR通过将解释生成视为组合优化挑战，并利用强化学习，发现影响推荐的最小但关键的商品序列。同时，创新性地利用这些事实性和反事实洞察，在对比学习范式下作为高质量的正负样本，以微调和显著提高会话推荐系统的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;FCESR框架不仅提高了推荐准确性，还显著提升了解释的质量和可解释性。&lt;h4&gt;结论&lt;/h4&gt;FCESR框架为更透明、更可信的推荐系统铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Session-based Recommendation (SR) systems have recently achieved considerable success, yet their complex, 'black box' nature often obscures why certain recommendations are made. Existing explanation methods struggle to pinpoint truly influential factors, as they frequently depend on static user profiles or fail to grasp the intricate dynamics within user sessions. In response, we introduce FCESR (Factual and Counterfactual Explanations for Session-based Recommendation), a novel framework designed to illuminate SR model predictions by emphasizing both the sufficiency (factual) and necessity (counterfactual) of recommended items. By recasting explanation generation as a combinatorial optimization challenge and leveraging reinforcement learning, our method uncovers the minimal yet critical sequence of items influencing recommendations. Moreover, recognizing the intrinsic value of robust explanations, we innovatively utilize these factual and counterfactual insights within a contrastive learning paradigm, employing them as high-quality positive and negative samples to fine-tune and significantly enhance SR accuracy. Extensive qualitative and quantitative evaluations across diverse datasets and multiple SR architectures confirm that our framework not only boosts recommendation accuracy but also markedly elevates the quality and interpretability of explanations, thereby paving the way for more transparent and trustworthy recommendation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Session-based Recommendation (SR) systems have recently achieved considerablesuccess, yet their complex, "black box" nature often obscures why certainrecommendations are made. Existing explanation methods struggle to pinpointtruly influential factors, as they frequently depend on static user profiles orfail to grasp the intricate dynamics within user sessions. In response, weintroduce FCESR (Factual and Counterfactual Explanations for Session-basedRecommendation), a novel framework designed to illuminate SR model predictionsby emphasizing both the sufficiency (factual) and necessity (counterfactual) ofrecommended items. By recasting explanation generation as a combinatorialoptimization challenge and leveraging reinforcement learning, our methoduncovers the minimal yet critical sequence of items influencingrecommendations. Moreover, recognizing the intrinsic value of robustexplanations, we innovatively utilize these factual and counterfactual insightswithin a contrastive learning paradigm, employing them as high-quality positiveand negative samples to fine-tune and significantly enhance SR accuracy.Extensive qualitative and quantitative evaluations across diverse datasets andmultiple SR architectures confirm that our framework not only boostsrecommendation accuracy but also markedly elevates the quality andinterpretability of explanations, thereby paving the way for more transparentand trustworthy recommendation systems.</description>
      <author>example@mail.com (Han Zhou, Hui Fang, Zhu Sun, Wentao Hu)</author>
      <guid isPermaLink="false">2504.13632v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion</title>
      <link>http://arxiv.org/abs/2504.13442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SatelliteCalculator，这是一种针对定量遥感反演的视觉基础模型，旨在解决遥感数据在生态变量估计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;定量遥感反演在环境监测中至关重要，但视觉基础模型在物理可解释回归中的应用尚未充分探索，且遥感数据的多元光谱和地理空间异质性给泛化和迁移性带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发SatelliteCalculator，以解决遥感数据在生态变量估计中的挑战，并验证基础模型在定量反演中的应用可行性。&lt;h4&gt;方法&lt;/h4&gt;SatelliteCalculator利用物理定义的指数公式自动构建了一个包含超过一百万对样本的大型数据集，并集成了冻结的Swin Transformer骨干网络和提示引导架构，包括交叉注意力适配器和轻量级任务特定MLP解码器。&lt;h4&gt;主要发现&lt;/h4&gt;在Open-Canopy基准测试中，SatelliteCalculator在所有任务上实现了具有竞争力的准确率，同时显著降低了推理成本。&lt;h4&gt;结论&lt;/h4&gt;研究结果验证了将基础模型应用于定量反演的可行性，并为任务自适应遥感估计提供了一个可扩展的框架。&lt;h4&gt;翻译&lt;/h4&gt;摘要：定量遥感反演在环境监测中发挥着关键作用，它使得估计关键生态变量（如植被指数、冠层结构和碳储量）成为可能。尽管视觉基础模型在分类和分割任务上取得了显著的进展，但它们在物理可解释回归中的应用仍然鲜有探索。此外，遥感数据的多元光谱特性和地理空间异质性为泛化和迁移性带来了重大挑战。为了解决这些问题，我们引入了SatelliteCalculator，这是第一个针对定量遥感反演定制的视觉基础模型。通过利用物理定义的指数公式，我们自动构建了一个包含超过一百万对样本的大型数据集，涵盖了八个核心生态指标。该模型集成了冻结的Swin Transformer骨干网络和提示引导架构，包括交叉注意力适配器和轻量级任务特定MLP解码器。在Open-Canopy基准测试中进行的实验表明，SatelliteCalculator在所有任务上实现了具有竞争力的准确率，同时显著降低了推理成本。我们的结果验证了将基础模型应用于定量反演的可行性，并为任务自适应遥感估计提供了一个可扩展的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative remote sensing inversion plays a critical role in environmentalmonitoring, enabling the estimation of key ecological variables such asvegetation indices, canopy structure, and carbon stock. Although visionfoundation models have achieved remarkable progress in classification andsegmentation tasks, their application to physically interpretable regressionremains largely unexplored. Furthermore, the multi-spectral nature andgeospatial heterogeneity of remote sensing data pose significant challenges forgeneralization and transferability. To address these issues, we introduceSatelliteCalculator, the first vision foundation model tailored forquantitative remote sensing inversion. By leveraging physically defined indexformulas, we automatically construct a large-scale dataset of over one millionpaired samples across eight core ecological indicators. The model integrates afrozen Swin Transformer backbone with a prompt-guided architecture, featuringcross-attentive adapters and lightweight task-specific MLP decoders.Experiments on the Open-Canopy benchmark demonstrate that SatelliteCalculatorachieves competitive accuracy across all tasks while significantly reducinginference cost. Our results validate the feasibility of applying foundationmodels to quantitative inversion, and provide a scalable framework fortask-adaptive remote sensing estimation.</description>
      <author>example@mail.com (Zhenyu Yu, Mohd. Yamani Idna Idris, Pei Wang)</author>
      <guid isPermaLink="false">2504.13442v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Learning-Based Supervised Transfer Learning Framework for DOA Estimation with Array Imperfections</title>
      <link>http://arxiv.org/abs/2504.13394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的迁移学习策略，有效缓解了阵列不完美对深度学习DOA估计性能的影响。&lt;h4&gt;背景&lt;/h4&gt;在实际场景中，传感器设计、制造和安装过程中会引入误差，传感器接收信号时也会发生相互干扰，这些缺陷称为阵列不完美，会显著降低DOA估计的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以缓解阵列不完美对DOA估计性能的降低。&lt;h4&gt;方法&lt;/h4&gt;1. 提出基于Vision Transformer (ViT)的DOA估计方法，在低信噪比和有限快照的情景下表现优异。2. 引入迁移学习框架，将深度学习模型从理想仿真场景扩展到存在阵列不完美的复杂真实场景。3. 通过利用理想仿真数据的先验知识，显著提高存在阵列不完美时深度学习DOA估计的性能，而无需大量真实世界数据。4. 结合可视化工具和评估指标来评估DOA估计算法的性能。&lt;h4&gt;主要发现&lt;/h4&gt;1. 基于ViT的DOA估计方法在低信噪比和有限快照的情景下具有优异性能。2. 迁移学习框架显著提高了DOA估计性能。3. 可视化和评估指标有助于更全面地评估算法并验证所提出的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于深度学习的迁移学习策略能够有效缓解阵列不完美对DOA估计性能的影响，提高了算法的实用性。&lt;h4&gt;翻译&lt;/h4&gt;In practical scenarios, processes such as sensor design, manufacturing, and installation will introduce certain errors. Furthermore, mutual interference occurs when the sensors receive signals. These defects in array systems are referred to as array imperfections, which can significantly degrade the performance of Direction of Arrival (DOA) estimation. In this study, we propose a deep-learning based transfer learning approach, which effectively mitigates the degradation of deep-learning based DOA estimation performance caused by array imperfections. In the proposed approach, we highlight three major contributions. First, we propose a Vision Transformer (ViT) based method for DOA estimation, which achieves excellent performance in scenarios with low signal-to-noise ratios (SNR) and limited snapshots. Second, we introduce a transfer learning framework that extends deep learning models from ideal simulation scenarios to complex real-world scenarios with array imperfections. By leveraging prior knowledge from ideal simulation data, the proposed transfer learning framework significantly improves deep learning-based DOA estimation performance in the presence of array imperfections, without the need for extensive real-world data. Finally, we incorporate visualization and evaluation metrics to assess the performance of DOA estimation algorithms, which allow for a more thorough evaluation of algorithms and further validate the proposed method. Our code can be accessed at https://github.com/zzb-nice/DOA_est_Master.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In practical scenarios, processes such as sensor design, manufacturing, andinstallation will introduce certain errors. Furthermore, mutual interferenceoccurs when the sensors receive signals. These defects in array systems arereferred to as array imperfections, which can significantly degrade theperformance of Direction of Arrival (DOA) estimation. In this study, we proposea deep-learning based transfer learning approach, which effectively mitigatesthe degradation of deep-learning based DOA estimation performance caused byarray imperfections.  In the proposed approach, we highlight three major contributions. First, wepropose a Vision Transformer (ViT) based method for DOA estimation, whichachieves excellent performance in scenarios with low signal-to-noise ratios(SNR) and limited snapshots. Second, we introduce a transfer learning frameworkthat extends deep learning models from ideal simulation scenarios to complexreal-world scenarios with array imperfections. By leveraging prior knowledgefrom ideal simulation data, the proposed transfer learning frameworksignificantly improves deep learning-based DOA estimation performance in thepresence of array imperfections, without the need for extensive real-worlddata. Finally, we incorporate visualization and evaluation metrics to assessthe performance of DOA estimation algorithms, which allow for a more thoroughevaluation of algorithms and further validate the proposed method. Our code canbe accessed at https://github.com/zzb-nice/DOA_est_Master.</description>
      <author>example@mail.com (Bo Zhou, Kaijie Xu, Yinghui Quan, Mengdao Xing)</author>
      <guid isPermaLink="false">2504.13394v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2504.13419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于单目几何估计的改进方法，以提高多视角3D重建的鲁棒性，特别是在弱纹理区域和低光照条件下。&lt;h4&gt;背景&lt;/h4&gt;近年来，数据驱动的几何多视角3D重建基础模型（如DUSt3R）在各种3D视觉任务中表现出色，得益于大规模、高质量的3D数据集的发布。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有模型在匹配原则下的局限性，特别是在具有有限匹配线索的挑战区域（如弱纹理区域和低光照条件）中的重建质量下降问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个单目引导的细化模块，该模块将单目几何先验集成到多视角重建框架中，从而增强了多视角重建系统的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个基准测试中实现了显著的改进，包括多视角相机姿态估计和点云精度。&lt;h4&gt;结论&lt;/h4&gt;通过将单目几何估计与多视角重建相结合，可以显著提高重建质量，特别是在具有挑战性的区域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in data-driven geometric multi-view 3D reconstructionfoundation models (e.g., DUSt3R) have shown remarkable performance acrossvarious 3D vision tasks, facilitated by the release of large-scale,high-quality 3D datasets. However, as we observed, constrained by theirmatching-based principles, the reconstruction quality of existing modelssuffers significant degradation in challenging regions with limited matchingcues, particularly in weakly textured areas and low-light conditions. Tomitigate these limitations, we propose to harness the inherent robustness ofmonocular geometry estimation to compensate for the inherent shortcomings ofmatching-based methods. Specifically, we introduce a monocular-guidedrefinement module that integrates monocular geometric priors into multi-viewreconstruction frameworks. This integration substantially enhances therobustness of multi-view reconstruction systems, leading to high-qualityfeed-forward reconstructions. Comprehensive experiments across multiplebenchmarks demonstrate that our method achieves substantial improvements inboth mutli-view camera pose estimation and point cloud accuracy.</description>
      <author>example@mail.com (Wenyu Li, Sidun Liu, Peng Qiao, Yong Dou)</author>
      <guid isPermaLink="false">2504.13419v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>AI-Empowered Integrated Sensing and Communications</title>
      <link>http://arxiv.org/abs/2504.13363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 10 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在集成感知与通信（ISAC）设计中应用人工智能（AI）以提升效率和降低复杂度。&lt;h4&gt;背景&lt;/h4&gt;ISAC技术有助于克服频谱有限和硬件昂贵的挑战，从而提高能源和成本效率。&lt;h4&gt;目的&lt;/h4&gt;实现ISAC的最佳性能需要高效的设计，包括统一波形和波束成形器。&lt;h4&gt;方法&lt;/h4&gt;文章强调了通过AI驱动的ISAC设计实现集成优势，重点发展统一波形、星座和波束成形策略。&lt;h4&gt;主要发现&lt;/h4&gt;案例研究表明，无监督学习和基于神经网络的优化可以有效平衡性能、复杂性和实施约束。&lt;h4&gt;结论&lt;/h4&gt;AI在ISAC设计中的应用有助于提高效率并减少复杂性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：整合感知与通信（ISAC）可以帮助克服频谱有限和硬件昂贵的挑战，从而提高能源和成本效率。虽然感知与通信之间的完全合作可以带来显著的性能提升，但要实现最佳性能，需要为联合感知和通信任务设计高效的统一波形和波束成形器。复杂的统计信号处理和多目标优化技术对于平衡联合感知和通信任务的设计要求是必要的。由于基于模型的解析方法可能是不最优的或过于复杂，深度学习作为一种强大的工具，在开发数据驱动的信号处理算法方面脱颖而出，尤其是在最优算法未知或已知算法过于复杂难以实时实现时。ISAC的统一波形和波束成形器设计问题属于此类问题，其中感知和通信性能指标之间存在基本的设计权衡，而基础模型可能是不充分或不完整的。本文探讨了在ISAC设计中应用人工智能（AI）以增强效率和降低复杂度。我们强调通过AI驱动的ISAC设计实现集成优势，优先发展统一波形、星座和波束成形策略。为了展示AI驱动的ISAC的实践潜力，我们展示了波形和波束成形设计的两个案例研究，展示了无监督学习和基于神经网络的优化如何有效地平衡性能、复杂性和实施约束。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating sensing and communication (ISAC) can help overcome the challengesof limited spectrum and expensive hardware, leading to improved energy and costefficiency. While full cooperation between sensing and communication can resultin significant performance gains, achieving optimal performance requiresefficient designs of unified waveforms and beamformers for joint sensing andcommunication. Sophisticated statistical signal processing and multi-objectiveoptimization techniques are necessary to balance the competing designrequirements of joint sensing and communication tasks. Since model-basedanalytical approaches may be suboptimal or overly complex, deep learningemerges as a powerful tool for developing data-driven signal processingalgorithms, particularly when optimal algorithms are unknown or when knownalgorithms are too complex for real-time implementation. Unified waveform andbeamformer design problems for ISAC fall into this category, where fundamentaldesign trade-offs exist between sensing and communication performance metrics,and the underlying models may be inadequate or incomplete. This articleexplores the application of artificial intelligence (AI) in ISAC designs toenhance efficiency and reduce complexity. We emphasize the integration benefitsthrough AI-driven ISAC designs, prioritizing the development of unifiedwaveforms, constellations, and beamforming strategies for both sensing andcommunication. To illustrate the practical potential of AI-driven ISAC, wepresent two case studies on waveform and beamforming design, demonstrating howunsupervised learning and neural network-based optimization can effectivelybalance performance, complexity, and implementation constraints.</description>
      <author>example@mail.com (Mojtaba Vaezi, Gayan Aruma Baduge, Esa Ollila, Sergiy A. Vorobyov)</author>
      <guid isPermaLink="false">2504.13363v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs</title>
      <link>http://arxiv.org/abs/2504.13429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2302.02914 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出NODESAFE，通过限制节点极端分数的产生，显著提高图神经网络（GNNs）在检测节点级异常数据（OOD）方面的能力。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在现实世界应用中扮演着关键角色，并且对安全性要求高。检测异常数据是提高GNNs性能的重要问题。&lt;h4&gt;目的&lt;/h4&gt;提高GNNs检测节点级异常数据的能力。&lt;h4&gt;方法&lt;/h4&gt;通过添加两个优化项，限制负能量分数的范围并减轻logit偏移，减少节点极端分数的产生。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法显著提高了GNNs检测节点级异常数据的能力，例如在检测结构操作引起的异常数据时，FPR95指标在无（有）异常数据暴露的情景下比现有SOTA降低了28.4%（22.7%）。&lt;h4&gt;结论&lt;/h4&gt;NODESAFE方法有效地提高了GNNs检测节点级异常数据的能力，为GNNs在实际应用中的安全性提供了保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given the critical role of graphs in real-world applications and theirhigh-security requirements, improving the ability of graph neural networks(GNNs) to detect out-of-distribution (OOD) data is an urgent research problem.The recent work GNNSAFE proposes a framework based on the aggregation ofnegative energy scores that significantly improves the performance of GNNs todetect node-level OOD data. However, our study finds that score aggregationamong nodes is susceptible to extreme values due to the unboundedness of thenegative energy scores and logit shifts, which severely limits the accuracy ofGNNs in detecting node-level OOD data. In this paper, we propose NODESAFE:reducing the generation of extreme scores of nodes by adding two optimizationterms that make the negative energy scores bounded and mitigate the logitshift. Experimental results show that our approach dramatically improves theability of GNNs to detect OOD data at the node level, e.g., in detecting OODdata induced by Structure Manipulation, the metric of FPR95 (lower is better)in scenarios without (with) OOD data exposure are reduced from the current SOTAby 28.4% (22.7%).</description>
      <author>example@mail.com (Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang)</author>
      <guid isPermaLink="false">2504.13429v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion</title>
      <link>http://arxiv.org/abs/2504.13561v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了WeatherGen，一个统一的多样化天气LiDAR数据扩散生成框架，显著提高了生成数据的保真度。&lt;h4&gt;背景&lt;/h4&gt;3D场景感知需要大量的恶劣天气LiDAR数据，但LiDAR数据收集的成本很高，这是一个重大的扩展挑战。&lt;h4&gt;目的&lt;/h4&gt;提高LiDAR数据在恶劣天气条件下的保真度和可用性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于地图的数据生成器，提供大量高质量的多样化天气数据用于训练。利用扩散去噪范式构建扩散模型，提出了一种蜘蛛蟒生成器来逐步恢复被干扰的多样化天气数据。设计了潜在特征对齐器和基于对比学习的控制器，通过语言监督为天气控制信号赋予紧凑的语义知识，指导扩散模型生成更具判别性的数据。&lt;h4&gt;主要发现&lt;/h4&gt;WeatherGen显著提高了LiDAR数据在多样化天气条件下的生成质量，并构建了mini-weather数据集，促进了下游任务在恶劣天气条件下的性能。&lt;h4&gt;结论&lt;/h4&gt;WeatherGen是一个有效的工具，可以生成高质量的LiDAR数据，有助于提高恶劣天气条件下的3D场景感知性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes WeatherGen, a unified diverse-weather LiDAR data diffusion generation framework that significantly improves the fidelity of the generated data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene perception demands a large amount of adverse-weather LiDAR data, yetthe cost of LiDAR data collection presents a significant scaling-up challenge.To this end, a series of LiDAR simulators have been proposed. Yet, they canonly simulate a single adverse weather with a single physical model, and thefidelity of the generated data is quite limited. This paper presentsWeatherGen, the first unified diverse-weather LiDAR data diffusion generationframework, significantly improving fidelity. Specifically, we first design amap-based data producer, which can provide a vast amount of high-qualitydiverse-weather data for training purposes. Then, we utilize thediffusion-denoising paradigm to construct a diffusion model. Among them, wepropose a spider mamba generator to restore the disturbed diverse weather datagradually. The spider mamba models the feature interactions by scanning theLiDAR beam circle or central ray, excellently maintaining the physicalstructure of the LiDAR data. Subsequently, following the generator to transferreal-world knowledge, we design a latent feature aligner. Afterward, we devisea contrastive learning-based controller, which equips weather control signalswith compact semantic knowledge through language supervision, guiding thediffusion model to generate more discriminative data. Extensive evaluationsdemonstrate the high generation quality of WeatherGen. Through WeatherGen, weconstruct the mini-weather dataset, promoting the performance of the downstreamtask under adverse weather conditions. Code is available:https://github.com/wuyang98/weathergen</description>
      <author>example@mail.com (Yang Wu, Yun Zhu, Kaihua Zhang, Jianjun Qian, Jin Xie, Jian Yang)</author>
      <guid isPermaLink="false">2504.13561v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告提出针对StreamPETR框架的针对性改进，旨在提高速度估计能力，这是影响NuScenes检测得分的关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度均值较高，但在NuScenes数据集上的速度估计分析中被识别为一个瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估，使用了ViT-L主干网络。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的方法使用ViT-L主干网络实现了70.86%的NDS，达到了最先进的水平，为仅使用摄像头的3D目标检测设定了新的基准。&lt;h4&gt;结论&lt;/h4&gt;通过改进的StreamPETR框架，显著提升了速度估计的准确性，为NuScenes数据集上的3D目标检测设定了新的性能标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v2</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning at Scale: Characterizing and Optimizing Pre-Propagation GNNs</title>
      <link>http://arxiv.org/abs/2504.13266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在图学习中应用中的邻居爆炸问题，并提出了预传播GNNs（PP-GNNs）来解决此问题。通过比较PP-GNNs与基于图采样的方法，文章分析了PP-GNNs在训练效率、可扩展性和准确性方面的表现，并提出了优化方案。&lt;h4&gt;背景&lt;/h4&gt;GNNs在图学习中应用广泛，但随着层数增加，其计算和内存需求呈指数增长，导致邻居爆炸问题。图采样是目前解决该问题的主流方法，但并未完全解决。&lt;h4&gt;目的&lt;/h4&gt;本文旨在全面描述PP-GNNs，并与基于图采样的方法进行比较，以分析其在训练效率、可扩展性和准确性方面的表现。&lt;h4&gt;方法&lt;/h4&gt;本文提出了优化数据加载方案和定制训练方法，以提高PP-GNNs的训练吞吐量，并在大型图基准测试上与基于采样的GNNs进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;PP-GNNs在准确性上与基于图采样的方法相当，但数据加载成为训练效率的关键瓶颈，而输入扩展是主要的可扩展性挑战。&lt;h4&gt;结论&lt;/h4&gt;通过优化数据加载方案和定制训练方法，PP-GNNs的训练吞吐量平均提高了15倍，与基于采样的GNNs相比，在大型图基准测试上的速度提高了两个数量级。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are widely used for learning node embeddings in graphs, typically adopting a message-passing scheme. This approach, however, leads to the neighbor explosion problem, with exponentially growing computational and memory demands as layers increase. Graph sampling has become the predominant method for scaling GNNs to large graphs, mitigating but not fully solving the issue. Pre-propagation GNNs (PP-GNNs) represent a new class of models that decouple feature propagation from training through pre-processing, addressing neighbor explosion in theory. Yet, their practical advantages and system-level optimizations remain underexplored. This paper provides a comprehensive characterization of PP-GNNs, comparing them with graph-sampling-based methods in training efficiency, scalability, and accuracy. While PP-GNNs achieve comparable accuracy, we identify data loading as the key bottleneck for training efficiency and input expansion as a major scalability challenge. To address these issues, we propose optimized data loading schemes and tailored training methods that improve PP-GNN training throughput by an average of 15 times over the PP-GNN baselines, with speedup of up to 2 orders of magnitude compared to sampling-based GNNs on large graph benchmarks. Our implementation is publicly available at https://github.com/cornell-zhang/preprop-gnn.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are widely used for learning node embeddings ingraphs, typically adopting a message-passing scheme. This approach, however,leads to the neighbor explosion problem, with exponentially growingcomputational and memory demands as layers increase. Graph sampling has becomethe predominant method for scaling GNNs to large graphs, mitigating but notfully solving the issue. Pre-propagation GNNs (PP-GNNs) represent a new classof models that decouple feature propagation from training throughpre-processing, addressing neighbor explosion in theory. Yet, their practicaladvantages and system-level optimizations remain underexplored. This paperprovides a comprehensive characterization of PP-GNNs, comparing them withgraph-sampling-based methods in training efficiency, scalability, and accuracy.While PP-GNNs achieve comparable accuracy, we identify data loading as the keybottleneck for training efficiency and input expansion as a major scalabilitychallenge. To address these issues, we propose optimized data loading schemesand tailored training methods that improve PP-GNN training throughput by anaverage of 15$\times$ over the PP-GNN baselines, with speedup of up to 2 ordersof magnitude compared to sampling-based GNNs on large graph benchmarks. Ourimplementation is publicly available athttps://github.com/cornell-zhang/preprop-gnn.</description>
      <author>example@mail.com (Zichao Yue, Chenhui Deng, Zhiru Zhang)</author>
      <guid isPermaLink="false">2504.13266v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>CytoFM: The first cytology foundation model</title>
      <link>http://arxiv.org/abs/2504.13402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了CytoFM，第一个用于细胞学的自监督基础模型，通过iBOT框架进行预训练，用于提高细胞学图像的分析能力。&lt;h4&gt;背景&lt;/h4&gt;细胞学在癌症诊断和筛查中至关重要，但数字细胞学由于样本制备方法的异质性、器官间差异以及大量多样化标注数据集的有限可用性，发展稳健的深度学习模型具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出并开发了一个通用的自监督基础模型CytoFM，用于从细胞学数据中学习鲁棒和可迁移的特征。&lt;h4&gt;方法&lt;/h4&gt;使用iBOT，一个结合掩码图像建模和自蒸馏的自监督视觉Transformer（ViT）训练框架，在多样化的细胞学数据集上预训练CytoFM。使用基于注意力的多实例学习框架评估CytoFM在乳腺癌分类和细胞类型识别等下游细胞学任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;CytoFM在三个下游任务中有两个比在病理学（UNI）或自然图像（iBOT-Imagenet）上预训练的现有基础模型表现更好。可视化学习到的表示表明，该模型能够关注到与细胞学相关的特征。&lt;h4&gt;结论&lt;/h4&gt;尽管预训练数据集规模较小，但CytoFM的有望结果突出了无任务预训练方法从细胞学数据中学习鲁棒和可迁移特征的能力。&lt;h4&gt;翻译&lt;/h4&gt;Cytology is essential for cancer diagnostics and screening due to its minimally invasive nature. However, the development of robust deep learning models for digital cytology is challenging due to the heterogeneity in staining and preparation methods of samples, differences across organs, and the limited availability of large, diverse, annotated datasets. Developing a task-specific model for every cytology application is impractical and non-cytology-specific foundation models struggle to generalize to tasks in this domain where the emphasis is on cell morphology. To address these challenges, we introduce CytoFM, the first cytology self-supervised foundation model. Using iBOT, a self-supervised Vision Transformer (ViT) training framework incorporating masked image modeling and self-distillation, we pretrain CytoFM on a diverse collection of cytology datasets to learn robust, transferable representations. We evaluate CytoFM on multiple downstream cytology tasks, including breast cancer classification and cell type identification, using an attention-based multiple instance learning framework. Our results demonstrate that CytoFM performs better on two out of three downstream tasks than existing foundation models pretrained on histopathology (UNI) or natural images (iBOT-Imagenet). Visualizations of learned representations demonstrate our model is able to attend to cytologically relevant features. Despite a small pre-training dataset, CytoFM's promising results highlight the ability of task-agnostic pre-training approaches to learn robust and generalizable features from cytology data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cytology is essential for cancer diagnostics and screening due to itsminimally invasive nature. However, the development of robust deep learningmodels for digital cytology is challenging due to the heterogeneity in stainingand preparation methods of samples, differences across organs, and the limitedavailability of large, diverse, annotated datasets. Developing a task-specificmodel for every cytology application is impractical and non-cytology-specificfoundation models struggle to generalize to tasks in this domain where theemphasis is on cell morphology. To address these challenges, we introduceCytoFM, the first cytology self-supervised foundation model. Using iBOT, aself-supervised Vision Transformer (ViT) training framework incorporatingmasked image modeling and self-distillation, we pretrain CytoFM on a diversecollection of cytology datasets to learn robust, transferable representations.We evaluate CytoFM on multiple downstream cytology tasks, including breastcancer classification and cell type identification, using an attention-basedmultiple instance learning framework. Our results demonstrate that CytoFMperforms better on two out of three downstream tasks than existing foundationmodels pretrained on histopathology (UNI) or natural images (iBOT-Imagenet).Visualizations of learned representations demonstrate our model is able toattend to cytologically relevant features. Despite a small pre-trainingdataset, CytoFM's promising results highlight the ability of task-agnosticpre-training approaches to learn robust and generalizable features fromcytology data.</description>
      <author>example@mail.com (Vedrana Ivezić, Ashwath Radhachandran, Ekaterina Redekop, Shreeram Athreya, Dongwoo Lee, Vivek Sant, Corey Arnold, William Speier)</author>
      <guid isPermaLink="false">2504.13402v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>PSG-MAE: Robust Multitask Sleep Event Monitoring using Multichannel PSG Reconstruction and Inter-channel Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.13229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于掩码自动编码器（MAE）的预训练框架PSG-MAE，用于自动睡眠监测和睡眠事件分析。&lt;h4&gt;背景&lt;/h4&gt;多导睡眠图（PSG）信号对研究睡眠过程和诊断睡眠障碍至关重要。使用深度神经网络（DNNs）分析PSG数据成为可能，但数据集的有限性导致模型难以泛化到新的睡眠事件。&lt;h4&gt;目的&lt;/h4&gt;提出PSG-MAE框架以解决数据集有限性和模型泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;PSG-MAE通过在大量的未标记PSG数据上执行自监督学习，开发了一个鲁棒的特征提取网络，可以广泛用于各种睡眠事件监测任务。它采用多通道信号重建方法，并使用自监督跨通道对比学习（ICCL）策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PSG-MAE能够有效地从PSG信号中捕获时间细节和跨通道信息。经过预训练的编码器在下游特征分解网络中微调后，睡眠分期准确率达到83.7%，阻塞性睡眠呼吸暂停检测准确率达到90.45%。&lt;h4&gt;结论&lt;/h4&gt;PSG-MAE框架具有鲁棒性和广泛的应用性，能够提高睡眠事件监测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Polysomnography (PSG) signals are essential for studying sleep processes anddiagnosing sleep disorders. Analyzing PSG data through deep neural networks(DNNs) for automated sleep monitoring has become increasingly feasible.However, the limited availability of datasets for certain sleep events oftenleads to DNNs focusing on a single task with a single-sourced training dataset.As a result, these models struggle to transfer to new sleep events and lackrobustness when applied to new datasets. To address these challenges, wepropose PSG-MAE, a mask autoencoder (MAE) based pre-training framework. Byperforming self-supervised learning on a large volume of unlabeled PSG data,PSG-MAE develops a robust feature extraction network that can be broadlyapplied to various sleep event monitoring tasks. Unlike conventional MAEs,PSG-MAE generates complementary masks across PSG channels, integrates amultichannel signal reconstruction method, and employs a self-supervisedinter-channel contrastive learning (ICCL) strategy. This approach enables theencoder to capture temporal features from each channel while simultaneouslylearning latent relationships between channels, thereby enhancing theutilization of multichannel information. Experimental results show that PSG-MAEeffectively captures both temporal details and inter-channel information fromPSG signals. When the encoder pre-trained through PSG-MAE is fine-tuned withdownstream feature decomposition networks, it achieves an accuracy of 83.7% forsleep staging and 90.45% for detecting obstructive sleep apnea, whichhighlights the framework's robustness and broad applicability.</description>
      <author>example@mail.com (Yifei Wang, Qi Liu, Fuli Min, Honghao Wang)</author>
      <guid isPermaLink="false">2504.13229v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.13234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NUCS的非均匀类-wise Coreset选择框架，用于解决迁移学习模型和数据集日益增长时，高效适应和存储优化的需求。&lt;h4&gt;背景&lt;/h4&gt;随着迁移学习模型和数据集的增大，如何高效地适应和优化存储变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出NUCS框架，以克服现有方法主要依赖实例级难度评估，忽略类别级特征和少数类代表性不足的局限性。&lt;h4&gt;方法&lt;/h4&gt;NUCS框架结合了类别级和实例级标准，根据内在类别难度自动为每个类别分配数据选择预算，并在最佳难度范围内自适应选择样本。&lt;h4&gt;主要发现&lt;/h4&gt;通过明确纳入类别特定见解，NUCS实现了更平衡和具有代表性的coreset，并解决了先前方法的关键不足。&lt;h4&gt;结论&lt;/h4&gt;理论分析和广泛实验验证了自适应预算分配和样本选择的合理性，NUCS在14个不同数据集和模型架构上的表现优于现有方法，实现了更高的准确性和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As transfer learning models and datasets grow larger, efficient adaptationand storage optimization have become critical needs. Coreset selectionaddresses these challenges by identifying and retaining the most informativesamples, constructing a compact subset for target domain training. However,current methods primarily rely on instance-level difficulty assessments,overlooking crucial category-level characteristics and consequentlyunder-representing minority classes. To overcome this limitation, we proposeNon-Uniform Class-Wise Coreset Selection (NUCS), a novel framework thatintegrates both class-level and instance-level criteria. NUCS automaticallyallocates data selection budgets for each class based on intrinsic categorydifficulty and adaptively selects samples within optimal difficulty ranges. Byexplicitly incorporating category-specific insights, our approach achieves amore balanced and representative coreset, addressing key shortcomings of priormethods. Comprehensive theoretical analysis validates the rationale behindadaptive budget allocation and sample selection, while extensive experimentsacross 14 diverse datasets and model architectures demonstrate NUCS'sconsistent improvements over state-of-the-art methods, achieving superioraccuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCSmatches full-data training accuracy while retaining just 30% of samples andreducing computation time by 60%. Our work highlights the importance ofcharacterizing category difficulty in coreset selection, offering a robust anddata-efficient solution for transfer learning.</description>
      <author>example@mail.com (Hanyu Zhang, Zhen Xing, Wenxuan Yang, Chenxi Ma, Weimin Tan, Bo Yan)</author>
      <guid isPermaLink="false">2504.13234v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Data-Efficient Visual Transfer Learning</title>
      <link>http://arxiv.org/abs/2504.13219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了数据高效视觉迁移学习的第一个实用框架，分析了不同数据量级下的视觉任务，提出了蒸馏边界理论，揭示了蒸馏效率的关键转折点。&lt;h4&gt;背景&lt;/h4&gt;当前视觉AI模型的缩放定律主要关注大规模预训练，但对于数据受限的后台任务，其性能缩放机制的理解存在差距。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一局限，本文旨在建立数据高效视觉迁移学习的缩放定律框架，回答两个基本问题：1）当下游任务数据有限时，缩放行为如何变化？2）在如此限制下，知识蒸馏的效力由何控制？&lt;h4&gt;方法&lt;/h4&gt;通过系统分析1K到1M样本范围内的视觉任务，提出了蒸馏边界理论，并在不同模型规模（2.5M到38M参数）和数据量下进行实证验证。&lt;h4&gt;主要发现&lt;/h4&gt;1）蒸馏优势：在数据稀缺条件下，蒸馏模型显著优于非蒸馏模型，有效地利用继承的知识来补偿有限的训练样本。2）预训练主导：当预训练数据超过临界阈值时，非蒸馏模型逐渐超越蒸馏版本，表明当有足够的特定任务数据时，知识继承的回报递减。&lt;h4&gt;结论&lt;/h4&gt;本文重新定义了数据受限领域的缩放定律，弥合了大规模预训练与实际下游适应之间的知识差距，解决了理解视觉模型缩放行为和优化计算资源分配的关键障碍。&lt;h4&gt;翻译&lt;/h4&gt;This paper establishes the first practical framework for data-efficient visual transfer learning, analyzes visual tasks across different data regimes (1K-1M samples), and proposes the distillation boundary theory, revealing a critical turning point in distillation efficiency: 1) Distillation superiority: In data-scarce conditions, distilled models significantly outperform their non-distillation counterparts, efficiently leveraging inherited knowledge to compensate for limited training samples. 2) Pre-training dominance: As pre-training data increases beyond a critical threshold, non-distilled models gradually surpass distilled versions, suggesting diminishing returns from knowledge inheritance when sufficient task-specific data becomes available. Empirical validation across various model scales (2.5M to 38M parameters) and data volumes demonstrates these performance inflection points, with error difference curves transitioning from positive to negative values at critical data thresholds, confirming our theoretical predictions. This work redefines scaling laws for data-limited regimes, bridging the knowledge gap between large-scale pretraining and practical downstream adaptation, addressing a critical barrier to understanding vision model scaling behaviors and optimizing computational resource allocation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current scaling laws for visual AI models focus predominantly on large-scalepretraining, leaving a critical gap in understanding how performance scales fordata-constrained downstream tasks. To address this limitation, this paperestablishes the first practical framework for data-efficient scaling laws invisual transfer learning, addressing two fundamental questions: 1) How doscaling behaviors shift when downstream tasks operate with limited data? 2)What governs the efficacy of knowledge distillation under such constraints?Through systematic analysis of vision tasks across data regimes (1K-1Msamples), we propose the distillation boundary theory, revealing a criticalturning point in distillation efficiency: 1) Distillation superiority: Indata-scarce conditions, distilled models significantly outperform theirnon-distillation counterparts, efficiently leveraging inherited knowledge tocompensate for limited training samples. 2) Pre-training dominance: Aspre-training data increases beyond a critical threshold, non-distilled modelsgradually surpass distilled versions, suggesting diminishing returns fromknowledge inheritance when sufficient task-specific data becomes available.Empirical validation across various model scales (2.5M to 38M parameters) anddata volumes demonstrate these performance inflection points, with errordifference curves transitioning from positive to negative values at criticaldata thresholds, confirming our theoretical predictions. This work redefinesscaling laws for data-limited regimes, bridging the knowledge gap betweenlarge-scale pretraining and practical downstream adaptation, addressing acritical barrier to understanding vision model scaling behaviors and optimizingcomputational resource allocation.</description>
      <author>example@mail.com (Wenxuan Yang, Qingqu Wei, Chenxi Ma, Weimin Tan, Bo Yan)</author>
      <guid isPermaLink="false">2504.13219v1</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond</title>
      <link>http://arxiv.org/abs/2504.13037v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了Cardiac magnetic resonance imaging（心脏磁共振成像）在非侵入性心脏评估中的重要性，并提出了ViTa模型，该模型通过结合心脏磁共振数据和患者水平因素，提供对心脏健康和疾病风险的全面理解。&lt;h4&gt;背景&lt;/h4&gt;Cardiac magnetic resonance imaging是心脏评估的金标准，但单独使用无法捕捉到患者级别的健康因素，如人口统计学、代谢和生活方式，这些因素对心血管健康和疾病风险有显著影响。&lt;h4&gt;目的&lt;/h4&gt;为了全面理解心脏健康并准确解释个体的疾病风险，需要在一个综合框架内联合利用CMR和患者水平因素。&lt;h4&gt;方法&lt;/h4&gt;ViTa模型通过整合来自42,000名英国生物样本库参与者的数据，将3D+T cine stacks从短轴和长轴视图融合，并与详细的表格患者级别因素结合，从而实现心脏周期的完整捕捉和上下文感知洞察。&lt;h4&gt;主要发现&lt;/h4&gt;ViTa模型支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及心脏和代谢疾病的分类，通过学习一个连接丰富成像特征和患者背景的共享潜在表示，超越了传统的任务特定模型。&lt;h4&gt;结论&lt;/h4&gt;ViTa模型有望提高临床应用和心脏分析的可扩展性，为心脏健康评估提供了一种新的、患者特定的理解方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac magnetic resonance imaging is the gold standard for non-invasivecardiac assessment, offering rich spatio-temporal views of the cardiac anatomyand physiology. Patient-level health factors, such as demographics, metabolic,and lifestyle, are known to substantially influence cardiovascular health anddisease risk, yet remain uncaptured by CMR alone. To holistically understandcardiac health and to enable the best possible interpretation of anindividual's disease risk, CMR and patient-level factors must be jointlyexploited within an integrated framework. Recent multi-modal approaches havebegun to bridge this gap, yet they often rely on limited spatio-temporal dataand focus on isolated clinical tasks, thereby hindering the development of acomprehensive representation for cardiac health evaluation. To overcome theselimitations, we introduce ViTa, a step toward foundation models that delivers acomprehensive representation of the heart and a precise interpretation ofindividual disease risk. Leveraging data from 42,000 UK Biobank participants,ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enablinga complete capture of the cardiac cycle. These imaging data are then fused withdetailed tabular patient-level factors, enabling context-aware insights. Thismulti-modal paradigm supports a wide spectrum of downstream tasks, includingcardiac phenotype and physiological feature prediction, segmentation, andclassification of cardiac and metabolic diseases within a single unifiedframework. By learning a shared latent representation that bridges rich imagingfeatures and patient context, ViTa moves beyond traditional, task-specificmodels toward a universal, patient-specific understanding of cardiac health,highlighting its potential to advance clinical utility and scalability incardiac analysis.</description>
      <author>example@mail.com (Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan)</author>
      <guid isPermaLink="false">2504.13037v2</guid>
      <pubDate>Mon, 21 Apr 2025 14:11:51 +0800</pubDate>
    </item>
    <item>
      <title>It's All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization</title>
      <link>http://arxiv.org/abs/2504.13173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究如何设计高效和有效的建筑背骨，以提高基础模型的能力，并引入了注意力偏差的概念来重新构思神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;设计高效和有效的建筑背骨是提升基础模型能力的研究核心。&lt;h4&gt;目的&lt;/h4&gt;通过模仿人类的注意力偏差现象，将神经网络架构视为关联记忆模块，并学习使用内部目标（注意力偏差）来映射键值。&lt;h4&gt;方法&lt;/h4&gt;提出了新的注意力偏差配置及其有效近似，重新解释了深度学习架构中的遗忘机制，并提出了针对序列模型的遗忘门。建立了Miras框架，通过四种选择来设计深度学习架构：关联记忆架构、注意力偏差目标、保留门和记忆学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;大多数现有序列模型使用点积相似度或L2回归目标作为注意力偏差，并提出了一系列新的注意力偏差配置以稳定训练过程。&lt;h4&gt;结论&lt;/h4&gt;Miras框架的设计选择导致了具有不同优势的模型，某些Miras实例在特定任务（如语言建模、常识推理和召回密集型任务）中表现出色，甚至超越了Transformer和其他现代线性循环模型。&lt;h4&gt;翻译&lt;/h4&gt;Designing efficient and effective architectural backbones has been in thecore of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neuralarchitectures, including Transformers, Titans, and modern linear recurrentneural networks as associative memory modules that learn a mapping of keys andvalues using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequencemodels. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing efficient and effective architectural backbones has been in thecore of research efforts to enhance the capability of foundation models.Inspired by the human cognitive phenomenon of attentional bias-the naturaltendency to prioritize certain events or stimuli-we reconceptualize neuralarchitectures, including Transformers, Titans, and modern linear recurrentneural networks as associative memory modules that learn a mapping of keys andvalues using an internal objective, referred to as attentional bias.Surprisingly, we observed that most existing sequence models leverage either(1) dot-product similarity, or (2) L2 regression objectives as theirattentional bias. Going beyond these objectives, we present a set ofalternative attentional bias configurations along with their effectiveapproximations to stabilize their training procedure. We then reinterpretforgetting mechanisms in modern deep learning architectures as a form ofretention regularization, providing a novel set of forget gates for sequencemodels. Building upon these insights, we present Miras, a general framework todesign deep learning architectures based on four choices of: (i) associativememory architecture, (ii) attentional bias objective, (iii) retention gate, and(iv) memory learning algorithm. We present three novel sequence models-Moneta,Yaad, and Memora-that go beyond the power of existing linear RNNs whilemaintaining a fast parallelizable training process. Our experiments showdifferent design choices in Miras yield models with varying strengths. Forexample, certain instances of Miras achieve exceptional performance in specialtasks such as language modeling, commonsense reasoning, and recall intensivetasks, even outperforming Transformers and other modern linear recurrentmodels.</description>
      <author>example@mail.com (Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni)</author>
      <guid isPermaLink="false">2504.13173v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
  <item>
      <title>Machine Learning Methods for Gene Regulatory Network Inference</title>
      <link>http://arxiv.org/abs/2504.12610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 3 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于机器学习的基因调控网络（GRN）推断方法进行了全面综述，并讨论了常用的数据集和评估指标，特别强调了深度学习技术在提高推断性能方面的作用，同时探讨了改进GRN推断的未来方向。&lt;h4&gt;背景&lt;/h4&gt;基因调控网络是复杂的生物系统，响应环境和发展信号控制基因表达和调控。计算生物学和测序技术的进步显著提高了GRN推断和建模的准确性。&lt;h4&gt;目的&lt;/h4&gt;支持GRN推断在研究基因调控中的应用，以及新型机器学习方法的开发。&lt;h4&gt;方法&lt;/h4&gt;介绍了机器学习在GRN推断中的应用，包括监督学习、无监督学习、半监督学习和对比学习等，并分析了大规模组学数据以揭示调控基因相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;重点介绍了深度学习技术在提高GRN推断性能方面的作用，并讨论了改进GRN推断的潜在未来方向。&lt;h4&gt;结论&lt;/h4&gt;深度学习技术在GRN推断中扮演着重要角色，未来研究应进一步探索和优化这些方法，以实现更精确的基因调控网络推断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gene Regulatory Networks (GRNs) are intricate biological systems that controlgene expression and regulation in response to environmental and developmentalcues. Advances in computational biology, coupled with high throughputsequencing technologies, have significantly improved the accuracy of GRNinference and modeling. Modern approaches increasingly leverage artificialintelligence (AI), particularly machine learning techniques includingsupervised, unsupervised, semi-supervised, and contrastive learning to analyzelarge scale omics data and uncover regulatory gene interactions. To supportboth the application of GRN inference in studying gene regulation and thedevelopment of novel machine learning methods, we present a comprehensivereview of machine learning based GRN inference methodologies, along with thedatasets and evaluation metrics commonly used. Special emphasis is placed onthe emerging role of cutting edge deep learning techniques in enhancinginference performance. The potential future directions for improving GRNinference are also discussed.</description>
      <author>example@mail.com (Akshata Hegde, Tom Nguyen, Jianlin Cheng)</author>
      <guid isPermaLink="false">2504.12610v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework</title>
      <link>http://arxiv.org/abs/2504.12576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CM3AE的新型预训练框架，用于RGB-Event感知，该框架旨在解决现有方法在多模态融合场景中的应用局限性。&lt;h4&gt;背景&lt;/h4&gt;事件相机因其在高动态范围、高时间分辨率、低功耗和低延迟方面的优势而受到越来越多的关注。然而，直接在事件数据上进行的预训练研究往往难以与RGB帧建立强连接，限制了其在多模态融合场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出CM3AE框架的目的是为了解决上述问题，使其能够有效支持基于事件和RGB-Event融合的后续任务。&lt;h4&gt;方法&lt;/h4&gt;CM3AE框架接受包括RGB图像、事件图像和事件体素在内的多模态/视角数据作为输入，设计了一个多模态融合重建模块，以及一个多模态对比学习策略来对齐跨模态特征表示，从而增强模型的多模态理解和捕捉全局依赖的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建包含2,535,759个RGB-Event数据对的的大型数据集进行预训练，并在五个下游任务上的广泛实验充分证明了CM3AE框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;CM3AE框架在多模态融合感知任务中表现出色，并将在https://github.com/Event-AHU/CM3AE上发布源代码和预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;Event cameras have attracted increasing attention in recent years due to their advantages in high dynamic range, high temporal resolution, low power consumption, and low latency. Some researchers have begun exploring pre-training directly on event data. Nevertheless, these efforts often fail to establish strong connections with RGB frames, limiting their applicability in multi-modal fusion scenarios. To address these issues, we propose a novel CM3AE pre-training framework for the RGB-Event perception. This framework accepts multi-modalities/views of data as input, including RGB images, event images, and event voxels, providing robust support for both event-based and RGB-event fusion based downstream tasks. Specifically, we design a multi-modal fusion reconstruction module that reconstructs the original image from fused multi-modal features, explicitly enhancing the model's ability to aggregate cross-modal complementary information. Additionally, we employ a multi-modal contrastive learning strategy to align cross-modal feature representations in a shared latent space, which effectively enhances the model's capability for multi-modal understanding and capturing global dependencies. We construct a large-scale dataset containing 2,535,759 RGB-Event data pairs for the pre-training. Extensive experiments on five downstream tasks fully demonstrated the effectiveness of CM3AE. Source code and pre-trained models will be released on https://github.com/Event-AHU/CM3AE.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras have attracted increasing attention in recent years due totheir advantages in high dynamic range, high temporal resolution, low powerconsumption, and low latency. Some researchers have begun exploringpre-training directly on event data. Nevertheless, these efforts often fail toestablish strong connections with RGB frames, limiting their applicability inmulti-modal fusion scenarios. To address these issues, we propose a novel CM3AEpre-training framework for the RGB-Event perception. This framework acceptsmulti-modalities/views of data as input, including RGB images, event images,and event voxels, providing robust support for both event-based and RGB-eventfusion based downstream tasks. Specifically, we design a multi-modal fusionreconstruction module that reconstructs the original image from fusedmulti-modal features, explicitly enhancing the model's ability to aggregatecross-modal complementary information. Additionally, we employ a multi-modalcontrastive learning strategy to align cross-modal feature representations in ashared latent space, which effectively enhances the model's capability formulti-modal understanding and capturing global dependencies. We construct alarge-scale dataset containing 2,535,759 RGB-Event data pairs for thepre-training. Extensive experiments on five downstream tasks fully demonstratedthe effectiveness of CM3AE. Source code and pre-trained models will be releasedon https://github.com/Event-AHU/CM3AE.</description>
      <author>example@mail.com (Wentao Wu, Xiao Wang, Chenglong Li, Bo Jiang, Jin Tang, Bin Luo, Qi Liu)</author>
      <guid isPermaLink="false">2504.12576v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Digital Twin Generation from Visual Data: A Survey</title>
      <link>http://arxiv.org/abs/2504.13159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了从视频中生成数字孪生的最新进展。&lt;h4&gt;背景&lt;/h4&gt;数字孪生可以应用于机器人技术、媒体内容创作或设计和施工工作。&lt;h4&gt;目的&lt;/h4&gt;分析各种方法，包括3D高斯分层、生成性修复、语义分割和基础模型，并讨论它们的优缺点。&lt;h4&gt;方法&lt;/h4&gt;讨论了诸如遮挡、光照变化和可扩展性等挑战，以及潜在的未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;该调查旨在提供对最先进方法的全面概述及其对现实世界应用的影响。&lt;h4&gt;翻译&lt;/h4&gt;本调查探讨了从视频中生成数字孪生的最新进展。这些数字孪生可用于机器人应用、媒体内容创作或设计和施工工作。我们分析了各种方法，包括3D高斯分层、生成性修复、语义分割和基础模型，并强调了它们的优缺点。此外，我们还讨论了遮挡、光照变化和可扩展性等挑战，以及潜在的未来研究方向。本调查旨在提供一个对最先进方法的全面概述及其对现实世界应用的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey explores recent developments in generating digital twins fromvideos. Such digital twins can be used for robotics application, media contentcreation, or design and construction works. We analyze various approaches,including 3D Gaussian Splatting, generative in-painting, semantic segmentation,and foundation models highlighting their advantages and limitations.Additionally, we discuss challenges such as occlusions, lighting variations,and scalability, as well as potential future research directions. This surveyaims to provide a comprehensive overview of state-of-the-art methodologies andtheir implications for real-world applications. Awesome list:https://github.com/ndrwmlnk/awesome-digital-twins</description>
      <author>example@mail.com (Andrew Melnik, Benjamin Alt, Giang Nguyen, Artur Wilkowski, Maciej Stefańczyk, Qirui Wu, Sinan Harms, Helge Rhodin, Manolis Savva, Michael Beetz)</author>
      <guid isPermaLink="false">2504.13159v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>All-in-One Transferring Image Compression from Human Perception to Multi-Machine Perception</title>
      <link>http://arxiv.org/abs/2504.12997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种不对称适配器框架，用于高效地将学习图像压缩（LIC）模型从人类感知转移到机器感知，以解决现有方法在下游任务中单任务适应的效率低、缺乏任务交互和产生多个特定任务比特流的问题。&lt;h4&gt;背景&lt;/h4&gt;在视觉中心表示学习中，将LIC模型从人类感知转移到机器感知是一个新兴的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以支持在单个模型内进行多任务适应，提高效率和任务交互性。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了共享适配器来学习通用语义特征，以及特定任务的适配器来保持任务级别的区分度。通过轻量级的插件模块和冻结的基编码器，该方法在多个任务上实现了强大的性能，同时保持了压缩效率。&lt;h4&gt;主要发现&lt;/h4&gt;在PASCAL-Context基准测试中，该方法优于全微调和其他参数高效微调（PEFT）基线，验证了多视觉转移的有效性。&lt;h4&gt;结论&lt;/h4&gt;不对称适配器框架在视觉中心表示学习中提供了有效的方法，以实现LIC模型的高效跨任务适应。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently transferring Learned Image Compression (LIC) model from humanperception to machine perception is an emerging challenge in vision-centricrepresentation learning. Existing approaches typically adapt LIC to downstreamtasks in a single-task manner, which is inefficient, lacks task interaction,and results in multiple task-specific bitstreams. To address these limitations,we propose an asymmetric adaptor framework that supports multi-task adaptationwithin a single model. Our method introduces a shared adaptor to learn generalsemantic features and task-specific adaptors to preserve task-leveldistinctions. With only lightweight plug-in modules and a frozen base codec,our method achieves strong performance across multiple tasks while maintainingcompression efficiency. Experiments on the PASCAL-Context benchmark demonstratethat our method outperforms both Fully Fine-Tuned and other Parameter EfficientFine-Tuned (PEFT) baselines, and validating the effectiveness of multi-visiontransferring.</description>
      <author>example@mail.com (Jiancheng Zhao, Xiang Ji, Zhuoxiao Li, Zunian Wan, Weihang Ran, Mingze Ma, Muyao Niu, Yifan Zhan, Cheng-Ching Tseng, Yinqiang Zheng)</author>
      <guid isPermaLink="false">2504.12997v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>UncAD: Towards Safe End-to-end Autonomous Driving via Online Map Uncertainty</title>
      <link>http://arxiv.org/abs/2504.12826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为UncAD的新型自动驾驶范式，通过估计在线地图的不确定性来提升自动驾驶的安全性。&lt;h4&gt;背景&lt;/h4&gt;当前大多数自动驾驶方法将感知、预测和规划模块集成到一个可微分的网络中，虽然具有很好的可扩展性，但通常依赖于确定性建模的在线地图来指导或约束车辆规划，这可能导致错误的信息并危及规划安全。&lt;h4&gt;目的&lt;/h4&gt;提出UncAD范式，以解决在线地图不确定性对自动驾驶安全性的影响。&lt;h4&gt;方法&lt;/h4&gt;UncAD首先在感知模块中估计在线地图的不确定性，然后利用这种不确定性来指导运动预测和规划模块生成多模态轨迹。此外，根据在线地图的不确定性，UncAD提出了一个不确定性-碰撞感知的规划选择策略，以评估和选择最佳轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验表明，将UncAD集成到最先进的端到端方法中，仅参数增加1.9%，可以降低碰撞率高达26%，降低可行驶区域冲突率高达42%。&lt;h4&gt;结论&lt;/h4&gt;UncAD通过引入在线地图不确定性，显著提升了自动驾驶的安全性。&lt;h4&gt;翻译&lt;/h4&gt;End-to-end autonomous driving aims to produce planning trajectories from raw sensors directly. Currently, most approaches integrate perception, prediction, and planning modules into a fully differentiable network, promising great scalability. However, these methods typically rely on deterministic modeling of online maps in the perception module for guiding or constraining vehicle planning, which may incorporate erroneous perception information and further compromise planning safety. To address this issue, we delve into the importance of online map uncertainty for enhancing autonomous driving safety and propose a novel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty of the online map in the perception module. It then leverages the uncertainty to guide motion prediction and planning modules to produce multi-modal trajectories. Finally, to achieve safer autonomous driving, UncAD proposes an uncertainty-collision-aware planning selection strategy according to the online map uncertainty to evaluate and select the best trajectory. In this study, we incorporate UncAD into various state-of-the-art (SOTA) end-to-end methods. Experiments on the nuScenes dataset show that integrating UncAD, with only a 1.9% increase in parameters, can reduce collision rates by up to 26% and drivable area conflict rate by up to 42%. Codes, pre-trained models, and demo videos can be accessed at https://github.com/pengxuanyang/UncAD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end autonomous driving aims to produce planning trajectories from rawsensors directly. Currently, most approaches integrate perception, prediction,and planning modules into a fully differentiable network, promising greatscalability. However, these methods typically rely on deterministic modeling ofonline maps in the perception module for guiding or constraining vehicleplanning, which may incorporate erroneous perception information and furthercompromise planning safety. To address this issue, we delve into the importanceof online map uncertainty for enhancing autonomous driving safety and propose anovel paradigm named UncAD. Specifically, UncAD first estimates the uncertaintyof the online map in the perception module. It then leverages the uncertaintyto guide motion prediction and planning modules to produce multi-modaltrajectories. Finally, to achieve safer autonomous driving, UncAD proposes anuncertainty-collision-aware planning selection strategy according to the onlinemap uncertainty to evaluate and select the best trajectory. In this study, weincorporate UncAD into various state-of-the-art (SOTA) end-to-end methods.Experiments on the nuScenes dataset show that integrating UncAD, with only a1.9% increase in parameters, can reduce collision rates by up to 26% anddrivable area conflict rate by up to 42%. Codes, pre-trained models, and demovideos can be accessed at https://github.com/pengxuanyang/UncAD.</description>
      <author>example@mail.com (Pengxuan Yang, Yupeng Zheng, Qichao Zhang, Kefei Zhu, Zebin Xing, Qiao Lin, Yun-Fu Liu, Zhiguo Su, Dongbin Zhao)</author>
      <guid isPermaLink="false">2504.12826v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning via Auxiliary Labels with Application to Cold-Hardiness Prediction</title>
      <link>http://arxiv.org/abs/2504.13142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TAL（通过辅助标签转移）的新迁移学习框架，帮助农民利用植物物候数据来预测水果作物的抗寒性，即使在缺乏抗寒性数据的情况下也能提高预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;低温会对水果作物造成冻害，抗寒性是影响冻害的关键因素，且抗寒性在休眠期会变化。目前，由于设备和专业知识的要求，抗寒性数据仅限于部分水果品种，而农民通常收集了多年的物候数据。&lt;h4&gt;目的&lt;/h4&gt;利用农民已有的物候数据，通过TAL框架预测特定作物的抗寒性，即使没有该作物的抗寒性数据。&lt;h4&gt;方法&lt;/h4&gt;TAL框架基于源任务（已知品种）的源标签（抗寒性）和辅助标签（物候），目标任务（新品种）只有辅助标签。通过模型选择和平均的方法，利用深度多任务模型进行抗寒性预测。&lt;h4&gt;主要发现&lt;/h4&gt;TAL框架在真实世界的抗寒性和物候数据上表现出色，能够提高预测准确性。&lt;h4&gt;结论&lt;/h4&gt;TAL框架为农民提供了一种有效的方法，利用物候数据预测抗寒性，即使在缺乏抗寒性数据的情况下也能提高预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：低温可能会对水果作物造成显著的冻害，这取决于它们的抗寒性，抗寒性在休眠期会变化。这导致了预测抗寒性模型的开发，帮助农民决定何时采取昂贵的防霜措施。不幸的是，由于需要专门的设备和专业知识，用于模型训练的抗寒性数据仅适用于某些水果品种。相反，农民通常拥有多年的物候数据（例如芽萌发日期），他们定期收集这些数据用于他们的作物。在这项工作中，我们介绍了一种新的迁移学习框架，称为TAL（通过辅助标签转移），它允许农民利用物候数据来生成更准确的抗寒性预测，即使在他们的特定作物没有抗寒性数据的情况下也是如此。该框架假设一组源任务（品种）中的每个任务都有关联的源标签（抗寒性）和辅助标签（物候）。然而，目标任务（新品种）仅假设有辅助标签。TAL的目标是通过从源任务中迁移来预测目标任务的目标标签。令人惊讶的是，尽管关于迁移学习的文献浩如烟海，据我们所知，TAL的公式以前从未被解决。因此，我们提出了几种基于模型选择和平均的新TAL方法，可以利用最新的深度多任务模型进行抗寒性预测。我们在多个葡萄品种的真实世界抗寒性和物候数据上的结果表明，TAL可以利用物候数据在没有抗寒性数据的情况下提高抗寒性预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cold temperatures can cause significant frost damage to fruit crops dependingon their resilience, or cold hardiness, which changes throughout the dormancyseason. This has led to the development of predictive cold-hardiness models,which help farmers decide when to deploy expensive frost-mitigation measures.Unfortunately, cold-hardiness data for model training is only available forsome fruit cultivars due to the need for specialized equipment and expertise.Rather, farmers often do have years of phenological data (e.g. date ofbudbreak) that they regularly collect for their crops. In this work, weintroduce a new transfer-learning framework, Transfer via Auxiliary Labels(TAL), that allows farmers to leverage the phenological data to produce moreaccurate cold-hardiness predictions, even when no cold-hardiness data isavailable for their specific crop. The framework assumes a set of source tasks(cultivars) where each has associated primary labels (cold hardiness) andauxiliary labels (phenology). However, the target task (new cultivar) isassumed to only have the auxiliary labels. The goal of TAL is to predictprimary labels for the target task via transfer from the source tasks.Surprisingly, despite the vast literature on transfer learning, to ourknowledge, the TAL formulation has not been previously addressed. Thus, wepropose several new TAL approaches based on model selection and averaging thatcan leverage recent deep multi-task models for cold-hardiness prediction. Ourresults on real-world cold-hardiness and phenological data for multiple grapecultivars demonstrate that TAL can leverage the phenological data to improvecold-hardiness predictions in the absence of cold-hardiness data.</description>
      <author>example@mail.com (Kristen Goebel, Paola Pesantez-Cabrera, Markus Keller, Alan Fern)</author>
      <guid isPermaLink="false">2504.13142v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Feature Learning for Medical Point Clouds via State Space Model</title>
      <link>http://arxiv.org/abs/2504.13015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于SSM的分层特征学习框架，用于医疗点云的理解。&lt;h4&gt;背景&lt;/h4&gt;深度学习在点云建模中已得到广泛研究，但针对医疗点云的研究有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的框架来理解和处理医疗点云数据，以支持疾病诊断和治疗。&lt;h4&gt;方法&lt;/h4&gt;通过远点采样对输入点云进行下采样，使用KNN查询聚合多尺度结构信息，引入坐标顺序和内外扫描策略进行高效序列化，以及通过vanilla和group Point SSM块逐步计算点特征。&lt;h4&gt;主要发现&lt;/h4&gt;在MedPointS数据集上的实验表明，该方法在解剖分类、补全和分割任务中均表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为医疗点云的理解提供了有效的解决方案，并促进了相关数据集和代码的公开。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning-based point cloud modeling has been widely investigated as an indispensable component of general shape analysis. Recently, transformer and state space model (SSM) have shown promising capacities in point cloud learning. However, limited research has been conducted on medical point clouds, which have great potential in disease diagnosis and treatment. This paper presents an SSM-based hierarchical feature learning framework for medical point cloud understanding. Specifically, we down-sample input into multiple levels through the farthest point sampling. At each level, we perform a series of k-nearest neighbor (KNN) queries to aggregate multi-scale structural information. To assist SSM in processing point clouds, we introduce coordinate-order and inside-out scanning strategies for efficient serialization of irregular points. Point features are calculated progressively from short neighbor sequences and long point sequences through vanilla and group Point SSM blocks, to capture both local patterns and long-range dependencies. To evaluate the proposed method, we build a large-scale medical point cloud dataset named MedPointS for anatomy classification, completion, and segmentation. Extensive experiments conducted on MedPointS demonstrate that our method achieves superior performance across all tasks. The dataset is available at https://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to a public medical imaging platform: https://github.com/wlsdzyzl/flemme.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based point cloud modeling has been widely investigated as anindispensable component of general shape analysis. Recently, transformer andstate space model (SSM) have shown promising capacities in point cloudlearning. However, limited research has been conducted on medical point clouds,which have great potential in disease diagnosis and treatment. This paperpresents an SSM-based hierarchical feature learning framework for medical pointcloud understanding. Specifically, we down-sample input into multiple levelsthrough the farthest point sampling. At each level, we perform a series ofk-nearest neighbor (KNN) queries to aggregate multi-scale structuralinformation. To assist SSM in processing point clouds, we introducecoordinate-order and inside-out scanning strategies for efficient serializationof irregular points. Point features are calculated progressively from shortneighbor sequences and long point sequences through vanilla and group Point SSMblocks, to capture both local patterns and long-range dependencies. To evaluatethe proposed method, we build a large-scale medical point cloud dataset namedMedPointS for anatomy classification, completion, and segmentation. Extensiveexperiments conducted on MedPointS demonstrate that our method achievessuperior performance across all tasks. The dataset is available athttps://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged toa public medical imaging platform: https://github.com/wlsdzyzl/flemme.</description>
      <author>example@mail.com (Guoqing Zhang, Jingyun Yang, Yang Li)</author>
      <guid isPermaLink="false">2504.13015v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum Autoencoders</title>
      <link>http://arxiv.org/abs/2504.13113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Quorum的量子异常检测框架，旨在解决在金融、医疗和能源等行业中检测关键任务异常事件和数据的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;量子计算作为处理机器学习任务的强大工具，但训练量子机器学习模型面临挑战，特别是在梯度计算方面。对于异常检测，无监督学习方法至关重要，但这一挑战更为严峻。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出Quorum框架，它是第一个专为无监督学习设计的量子异常检测框架，且无需任何训练。&lt;h4&gt;方法&lt;/h4&gt;Quorum框架的设计和应用。&lt;h4&gt;主要发现&lt;/h4&gt;Quorum框架能够有效解决量子机器学习模型训练中的梯度计算难题，并适用于无监督学习的异常检测。&lt;h4&gt;结论&lt;/h4&gt;Quorum框架为量子异常检测提供了一种新的解决方案，有助于推动相关领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;Detecting mission-critical anomalous events and data is a crucial challenge across various industries, including finance, healthcare, and energy. Quantum computing has recently emerged as a powerful tool for tackling several machine learning tasks, but training quantum machine learning models remains challenging, particularly due to the difficulty of gradient calculation. The challenge is even greater for anomaly detection, where unsupervised learning methods are essential to ensure practical applicability. To address these issues, we propose Quorum, the first quantum anomaly detection framework designed for unsupervised learning that operates without requiring any training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting mission-critical anomalous events and data is a crucial challengeacross various industries, including finance, healthcare, and energy. Quantumcomputing has recently emerged as a powerful tool for tackling several machinelearning tasks, but training quantum machine learning models remainschallenging, particularly due to the difficulty of gradient calculation. Thechallenge is even greater for anomaly detection, where unsupervised learningmethods are essential to ensure practical applicability. To address theseissues, we propose Quorum, the first quantum anomaly detection frameworkdesigned for unsupervised learning that operates without requiring anytraining.</description>
      <author>example@mail.com (Jason Zev Ludmir, Sophia Rebello, Jacob Ruiz, Tirthak Patel)</author>
      <guid isPermaLink="false">2504.13113v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Perception Encoder: The best visual embeddings are not at the output of the network</title>
      <link>http://arxiv.org/abs/2504.13181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Initial Submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为感知编码器（PE）的最新图像和视频理解编码器，通过简单的视觉-语言学习进行训练。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉编码器依赖于各种预训练目标，针对特定的下游任务如分类、字幕或定位进行优化。&lt;h4&gt;目的&lt;/h4&gt;探索仅通过对比视觉-语言训练是否能够生成适用于多种下游任务的强大、通用嵌入。&lt;h4&gt;方法&lt;/h4&gt;采用精心调整的图像预训练食谱和鲁棒的视频数据引擎进行训练，并引入语言对齐和空间对齐方法以提取中间层中的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;对比视觉-语言训练能够生成适用于多种下游任务的强大嵌入，包括零样本图像和视频分类、检索、文档、图像和视频问答以及空间任务如检测、深度估计和跟踪。&lt;h4&gt;结论&lt;/h4&gt;PE模型系列在各种任务上取得了最先进的性能，并发布了模型、代码以及一个由合成和人工标注的视频组成的新数据集，以促进进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为感知编码器（PE）的最新图像和视频理解编码器，它通过简单的视觉-语言学习进行训练。传统上，视觉编码器依赖于各种预训练目标，每个目标都针对特定的下游任务，如分类、字幕或定位进行优化。令人惊讶的是，在扩展我们精心调整的图像预训练食谱并使用我们鲁棒的视频数据引擎进行优化后，我们发现仅对比视觉-语言训练就能为所有这些下游任务生成强大、通用的嵌入。只有一个注意事项：这些嵌入隐藏在网络的中间层中。为了提取它们，我们引入了两种对齐方法，即用于多模态语言模型的语言对齐和用于密集预测的空间对齐。与核心对比检查点一起，我们的PE模型系列在各种任务上实现了最先进的性能，包括零样本图像和视频分类和检索；文档、图像和视频问答；以及检测、深度估计和跟踪等空间任务。为了促进进一步的研究，我们发布了我们的模型、代码以及一个由合成和人工标注的视频组成的新数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Perception Encoder (PE), a state-of-the-art encoder for imageand video understanding trained via simple vision-language learning.Traditionally, vision encoders have relied on a variety of pretrainingobjectives, each tailored to specific downstream tasks such as classification,captioning, or localization. Surprisingly, after scaling our carefully tunedimage pretraining recipe and refining with our robust video data engine, wefind that contrastive vision-language training alone can produce strong,general embeddings for all of these downstream tasks. There is only one caveat:these embeddings are hidden within the intermediate layers of the network. Todraw them out, we introduce two alignment methods, language alignment formultimodal language modeling, and spatial alignment for dense prediction.Together with the core contrastive checkpoint, our PE family of models achievesstate-of-the-art performance on a wide variety of tasks, including zero-shotimage and video classification and retrieval; document, image, and video Q&amp;A;and spatial tasks such as detection, depth estimation, and tracking. To fosterfurther research, we are releasing our models, code, and a novel dataset ofsynthetically and human-annotated videos.</description>
      <author>example@mail.com (Daniel Bolya, Po-Yao Huang, Peize Sun, Jang Hyun Cho, Andrea Madotto, Chen Wei, Tengyu Ma, Jiale Zhi, Jathushan Rajasegaran, Hanoona Rasheed, Junke Wang, Marco Monteiro, Hu Xu, Shiyu Dong, Nikhila Ravi, Daniel Li, Piotr Dollár, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13181v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs</title>
      <link>http://arxiv.org/abs/2504.13153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需训练的框架，直接从高斯原语构建超点图，以解决现有方法在3D几何与自然语言结合中的效率低下和3D语义不一致问题。&lt;h4&gt;背景&lt;/h4&gt;自然语言与3D几何的结合对于灵活的、语言驱动的场景理解至关重要。虽然3D高斯分层（3DGS）在场景重建方面取得了进展，但现有方法存在效率低下和3D语义不一致的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以解决现有3DGS方法中存在的效率低下和3D语义不一致问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于超点图的训练免费框架，该框架直接从高斯原语构建超点图，并设计了一种高效的重新投影策略，将2D语义特征提升到超点上，避免多视图迭代训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了最先进的开放词汇分割性能，语义场重建速度提高了30倍以上，并支持层次化理解，在统一语义场内实现粗粒度和细粒度的开放词汇感知。&lt;h4&gt;结论&lt;/h4&gt;该方法在开放词汇分割方面取得了显著的性能提升，为自然语言与3D几何的结合提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Bridging natural language and 3D geometry is a crucial step toward flexible,language-driven scene understanding. While recent advances in 3D GaussianSplatting (3DGS) have enabled fast and high-quality scene reconstruction, research has also explored incorporating open-vocabulary understanding into 3DGS. However, most existing methods require iterative optimization over per-view 2D semantic feature maps, which not only results in inefficiencies but also leads to inconsistent 3D semantics across views. To address these limitations, we introduce a training-free framework that constructs a superpoint graph directly from Gaussian primitives. The superpoint graph partitions the scene into spatially compact and semantically coherent regions, forming view-consistent 3D entities and providing a structured foundation for open-vocabulary understanding. Based on the graph structure, we design an efficient reprojection strategy that lifts 2D semantic features onto the superpoints, avoiding costly multi-view iterative training. The resulting representation ensures strong 3D semantic coherence and naturally supports hierarchical understanding, enabling both coarse- and fine-grained open-vocabulary perception within a unified semantic field. Extensive experiments demonstrate that our method achieves state-of-the-art open-vocabulary segmentation performance, with semantic field reconstruction completed over 30 times faster. Our code will be available at https://github.com/Atrovast/THGS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bridging natural language and 3D geometry is a crucial step toward flexible,language-driven scene understanding. While recent advances in 3D GaussianSplatting (3DGS) have enabled fast and high-quality scene reconstruction,research has also explored incorporating open-vocabulary understanding into3DGS. However, most existing methods require iterative optimization overper-view 2D semantic feature maps, which not only results in inefficiencies butalso leads to inconsistent 3D semantics across views. To address theselimitations, we introduce a training-free framework that constructs asuperpoint graph directly from Gaussian primitives. The superpoint graphpartitions the scene into spatially compact and semantically coherent regions,forming view-consistent 3D entities and providing a structured foundation foropen-vocabulary understanding. Based on the graph structure, we design anefficient reprojection strategy that lifts 2D semantic features onto thesuperpoints, avoiding costly multi-view iterative training. The resultingrepresentation ensures strong 3D semantic coherence and naturally supportshierarchical understanding, enabling both coarse- and fine-grainedopen-vocabulary perception within a unified semantic field. Extensiveexperiments demonstrate that our method achieves state-of-the-artopen-vocabulary segmentation performance, with semantic field reconstructioncompleted over $30\times$ faster. Our code will be available athttps://github.com/Atrovast/THGS.</description>
      <author>example@mail.com (Shaohui Dai, Yansong Qu, Zheyan Li, Xinyang Li, Shengchuan Zhang, Liujuan Cao)</author>
      <guid isPermaLink="false">2504.13153v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Pre-training with Combined Datasets for 3D Perception in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2504.12709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用大规模未标记数据进行3D感知预训练的方法，旨在提高自动驾驶中的3D感知模型性能。&lt;h4&gt;背景&lt;/h4&gt;基于在自然语言处理和2D视觉领域使用大量数据进行预训练模型取得的显著成果，研究者们希望探索大量数据预训练在自动驾驶3D感知中的潜力。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用来自异构数据集的大量未标记数据来预训练3D感知模型，以提升自动驾驶中的3D感知能力。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种自监督预训练框架，从无标签数据中从头开始学习有效的3D表示，并结合基于提示适配器的领域自适应策略以减少数据集偏差。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在3D物体检测、BEV分割、3D物体跟踪和占用预测等下游任务上显著提升了模型性能，并且随着训练数据量的增加，性能持续提升，展示了3D感知模型在自动驾驶中持续受益的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了3D感知模型在自动驾驶中的持续受益潜力，并计划发布源代码以激励社区进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种利用大规模未标记数据进行3D感知预训练的方法，旨在提高自动驾驶中的3D感知模型性能。基于在自然语言处理和2D视觉领域使用大量数据进行预训练模型取得的显著成果，研究者们希望探索大量数据预训练在自动驾驶3D感知中的潜力。旨在通过使用来自异构数据集的大量未标记数据来预训练3D感知模型，以提升自动驾驶中的3D感知能力。论文提出了一种自监督预训练框架，从无标签数据中从头开始学习有效的3D表示，并结合基于提示适配器的领域自适应策略以减少数据集偏差。该方法在3D物体检测、BEV分割、3D物体跟踪和占用预测等下游任务上显著提升了模型性能，并且随着训练数据量的增加，性能持续提升，展示了3D感知模型在自动驾驶中持续受益的潜力。该研究证明了3D感知模型在自动驾驶中的持续受益潜力，并计划发布源代码以激励社区进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The significant achievements of pre-trained models leveraging large volumesof data in the field of NLP and 2D vision inspire us to explore the potentialof extensive data pre-training for 3D perception in autonomous driving. Towardthis goal, this paper proposes to utilize massive unlabeled data fromheterogeneous datasets to pre-train 3D perception models. We introduce aself-supervised pre-training framework that learns effective 3D representationsfrom scratch on unlabeled data, combined with a prompt adapter based domainadaptation strategy to reduce dataset bias. The approach significantly improvesmodel performance on downstream tasks such as 3D object detection, BEVsegmentation, 3D object tracking, and occupancy prediction, and shows steadyperformance increase as the training data volume scales up, demonstrating thepotential of continually benefit 3D perception models for autonomous driving.We will release the source code to inspire further investigations in thecommunity.</description>
      <author>example@mail.com (Shumin Wang, Zhuoran Yang, Lidian Wang, Zhipeng Tang, Heng Li, Lehan Pan, Sha Zhang, Jie Peng, Jianmin Ji, Yanyong Zhang)</author>
      <guid isPermaLink="false">2504.12709v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Explainable Scene Understanding with Qualitative Representations and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2504.12817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop "Advancing Automated Driving in Highly Interactive Scenarios  through Behavior Prediction, Trustworthy AI, and Remote Operations" @ 36th  IEEE Intelligent Vehicles Symposium (IV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将图神经网络（GNN）与定性可解释图（QXG）集成，以用于自动驾驶中的场景理解。&lt;h4&gt;背景&lt;/h4&gt;场景理解是任何进一步反应性或前瞻性决策的基础，而场景理解及相关推理本质上是解释任务，如为什么其他交通参与者会这样做，什么或谁导致了他们的行为。&lt;h4&gt;目的&lt;/h4&gt;通过结合定性表示与深度学习方法，实现自动驾驶系统中可解释的场景理解。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的GNN架构，该架构处理整个图结构以识别交通场景中的相关对象。在nuScenes数据集上评估了该方法，该数据集富含DriveLM的人类标注的相关标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基线方法相比，基于GNN的方法实现了更好的性能。该模型有效地处理了相关对象识别任务中的固有类别不平衡问题，同时考虑了场景中所有对象之间的完整时空关系。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了将定性表示与深度学习方法结合用于自动驾驶系统中可解释场景理解的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the integration of graph neural networks (GNNs) withQualitative Explainable Graphs (QXGs) for scene understanding in automateddriving. Scene understanding is the basis for any further reactive or proactivedecision-making. Scene understanding and related reasoning is inherently anexplanation task: why is another traffic participant doing something, what orwho caused their actions? While previous work demonstrated QXGs' effectivenessusing shallow machine learning models, these approaches were limited toanalysing single relation chains between object pairs, disregarding the broaderscene context. We propose a novel GNN architecture that processes entire graphstructures to identify relevant objects in traffic scenes. We evaluate ourmethod on the nuScenes dataset enriched with DriveLM's human-annotatedrelevance labels. Experimental results show that our GNN-based approachachieves superior performance compared to baseline methods. The modeleffectively handles the inherent class imbalance in relevant objectidentification tasks while considering the complete spatial-temporalrelationships between all objects in the scene. Our work demonstrates thepotential of combining qualitative representations with deep learningapproaches for explainable scene understanding in autonomous driving systems.</description>
      <author>example@mail.com (Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar, Helge Spieker)</author>
      <guid isPermaLink="false">2504.12817v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.12569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MagMatch的新框架，用于解决开放集半监督学习中的挑战，通过原型对比学习范式自然隔离异常样本，并在多个数据集上证明了其在分类准确率和异常检测方面的优越性。&lt;h4&gt;背景&lt;/h4&gt;开放集半监督学习（OSSL）旨在从可能包含分布内（ID）和未知分布外（OOD）类别的未标记数据中学习。然而，现有的OSSL方法在特征空间中形成次优结构，要么排除OOD样本，要么干扰它们，或者过度信任它们的信息。&lt;h4&gt;目的&lt;/h4&gt;提出MagMatch框架，旨在通过原型对比学习范式自然隔离OOD样本，并提高封闭集分类准确率和OOD检测AUROC。&lt;h4&gt;方法&lt;/h4&gt;MagMatch不将原型分配给OOD样本，而是使用ID-Selective Magnetic（ISM）模块选择性地将ID样本与类别原型对齐，同时允许OOD样本在特征空间中保持未对齐状态。此外，还提出了Selective Magnetic Alignment（SMA）损失函数，该函数根据样本置信度动态调整对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集上的实验表明，MagMatch在封闭集分类准确率和OOD检测AUROC方面显著优于现有方法，特别是在泛化到未见过的OOD数据方面。&lt;h4&gt;结论&lt;/h4&gt;MagMatch框架通过有效隔离OOD样本和动态调整对齐，提高了开放集半监督学习的性能。&lt;h4&gt;翻译&lt;/h4&gt;Open-Set Semi-Supervised Learning (OSSL) addresses the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the 'others' - to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge oflearning from unlabeled data that may include both in-distribution (ID) andunknown out-of-distribution (OOD) classes. However, existing OSSL methods formsuboptimal feature spaces by either excluding OOD samples, interfering withthem, or overtrusting their information during training. In this work, weintroduce MagMatch, a novel framework that naturally isolates OOD samplesthrough a prototype-based contrastive learning paradigm. Unlike conventionalmethods, MagMatch does not assign any prototypes to OOD samples; instead, itselectively aligns ID samples with class prototypes using an ID-SelectiveMagnetic (ISM) module, while allowing OOD samples - the "others" - to remainunaligned in the feature space. To support this process, we propose SelectiveMagnetic Alignment (SMA) loss for unlabeled data, which dynamically adjustsalignment based on sample confidence. Extensive experiments on diverse datasetsdemonstrate that MagMatch significantly outperforms existing methods in bothclosed-set classification accuracy and OOD detection AUROC, especially ingeneralizing to unseen OOD data.</description>
      <author>example@mail.com (You Rim Choi, Subeom Park, Seojun Heo, Eunchung Noh, Hyung-Sin Kim)</author>
      <guid isPermaLink="false">2504.12569v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>AdaVid: Adaptive Video-Language Pretraining</title>
      <link>http://arxiv.org/abs/2504.12513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPRW 2025. Project Page: https://chaitanya100100.github.io/AdaVid/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AdaVid是一种灵活的架构框架，旨在学习高效的视频编码器，能够根据可用资源动态调整其计算开销。&lt;h4&gt;背景&lt;/h4&gt;现有的对比视频语言预训练模型在计算资源受限的边缘设备上部署存在挑战，且通常只训练处理短视频片段。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVid框架，以学习高效的视频编码器，并能在计算资源有限的情况下动态调整计算量。&lt;h4&gt;方法&lt;/h4&gt;AdaVid的核心是一个自适应变换器块，它能够根据Matryoshka表示学习原理在推理时调整隐藏嵌入维度。此外，还提出了一种轻量级分层网络，用于聚合短片段特征。&lt;h4&gt;主要发现&lt;/h4&gt;AdaVid-EgoVLP在Ego4D数据集上训练，使用一半的计算资源即可匹配标准EgoVLP在短视频语言基准测试上的性能，并且在相同计算资源下表现更优。在Diving48分类基准测试中，AdaVid允许使用更多帧数而不超过计算限制。&lt;h4&gt;结论&lt;/h4&gt;AdaVid在保持计算效率的同时，实现了在多个长视频基准测试中的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive video-language pretraining has demonstrated great success in learning rich and robust video representations. However, deploying such video encoders on compute-constrained edge devices remains challenging due to their high computational demands. Additionally, existing models are typically trained to process only short video clips, often limited to 4 to 64 frames. In this paper, we introduce AdaVid, a flexible architectural framework designed to learn efficient video encoders that can dynamically adapt their computational footprint based on available resources. At the heart of AdaVid is an adaptive transformer block, inspired by Matryoshka Representation Learning, which allows the model to adjust its hidden embedding dimension at inference time. We show that AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4D dataset, matches the performance of the standard EgoVLP on short video-language benchmarks using only half the compute, and even outperforms EgoVLP when given equal computational resources. We further explore the trade-off between frame count and compute on the challenging Diving48 classification benchmark, showing that AdaVid enables the use of more frames without exceeding computational limits. To handle longer videos, we also propose a lightweight hierarchical network that aggregates short clip features, achieving a strong balance between compute efficiency and accuracy across several long video benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive video-language pretraining has demonstrated great success inlearning rich and robust video representations. However, deploying such videoencoders on compute-constrained edge devices remains challenging due to theirhigh computational demands. Additionally, existing models are typically trainedto process only short video clips, often limited to 4 to 64 frames. In thispaper, we introduce AdaVid, a flexible architectural framework designed tolearn efficient video encoders that can dynamically adapt their computationalfootprint based on available resources. At the heart of AdaVid is an adaptivetransformer block, inspired by Matryoshka Representation Learning, which allowsthe model to adjust its hidden embedding dimension at inference time. We showthat AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4Ddataset, matches the performance of the standard EgoVLP on short video-languagebenchmarks using only half the compute, and even outperforms EgoVLP when givenequal computational resources. We further explore the trade-off between framecount and compute on the challenging Diving48 classification benchmark, showingthat AdaVid enables the use of more frames without exceeding computationallimits. To handle longer videos, we also propose a lightweight hierarchicalnetwork that aggregates short clip features, achieving a strong balance betweencompute efficiency and accuracy across several long video benchmarks.</description>
      <author>example@mail.com (Chaitanya Patel, Juan Carlos Niebles, Ehsan Adeli)</author>
      <guid isPermaLink="false">2504.12513v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard</title>
      <link>http://arxiv.org/abs/2504.13125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型语言模型（LLMs）在金融任务中的应用。&lt;h4&gt;背景&lt;/h4&gt;基于Open FinLLMLeaderboard作为基准，对基础模型进行了微调。&lt;h4&gt;目的&lt;/h4&gt;通过微调模型提升其金融能力。&lt;h4&gt;方法&lt;/h4&gt;使用了包括监督微调（SFT）、直接偏好优化（DPO）和强化学习（RL）等技术。&lt;h4&gt;主要发现&lt;/h4&gt;微调模型在多种金融任务中展现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;工作展示了大型语言模型（LLMs）在金融应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLMLeaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the application of large language models (LLMs) tofinancial tasks. We fine-tuned foundation models using the Open FinLLMLeaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employedtechniques including supervised fine-tuning (SFT), direct preferenceoptimization (DPO), and reinforcement learning (RL) to enhance their financialcapabilities. The fine-tuned models demonstrated substantial performance gainsacross a wide range of financial tasks. Moreover, we measured the data scalinglaw in the financial domain. Our work demonstrates the potential of largelanguage models (LLMs) in financial applications.</description>
      <author>example@mail.com (Varun Rao, Youran Sun, Mahendra Kumar, Tejas Mutneja, Agastya Mukherjee, Haizhao Yang)</author>
      <guid isPermaLink="false">2504.13125v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise</title>
      <link>http://arxiv.org/abs/2504.12856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Perlin噪声和表面参数化的3D异常生成方法，用于解决工业制造中3D数据表面质量检测的挑战。&lt;h4&gt;背景&lt;/h4&gt;大型预训练视觉基础模型在多种视觉任务中显示出巨大潜力，但在工业异常检测中，真实缺陷样本的稀缺限制了这些模型的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D异常生成方法，以解决3D数据在工业质量检测中的潜在问题。&lt;h4&gt;方法&lt;/h4&gt;使用3D-PNAS方法，通过将点云投影到二维平面，从Perlin噪声场中采样多尺度噪声值，并沿法线方向扰动点云来生成真实的3D表面异常。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过控制噪声尺度、扰动强度和八度等关键参数，可以精细控制生成的异常，从而创建从显著变形到细微表面变化的多样化缺陷模式。&lt;h4&gt;结论&lt;/h4&gt;该方法在不同物体类型上产生了一致且几何上合理的异常，适应了它们的特定表面特征，并提供了完整的代码库和可视化工具包，以促进未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;Large pretrained vision foundation models have shown significant potential in various vision tasks. However, for industrial anomaly detection, the scarcity of real defect samples poses a critical challenge in leveraging these models. While 2D anomaly generation has significantly advanced with established generative models, the adoption of 3D sensors in industrial manufacturing has made leveraging 3D data for surface quality inspection an emerging trend. In contrast to 2D techniques, 3D anomaly generation remains largely unexplored, limiting the potential of 3D data in industrial quality inspection. To address this gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS, based on Perlin noise and surface parameterization. Our method generates realistic 3D surface anomalies by projecting the point cloud onto a 2D plane, sampling multi-scale noise values from a Perlin noise field, and perturbing the point cloud along its normal direction. Through comprehensive visualization experiments, we demonstrate how key parameters - including noise scale, perturbation strength, and octaves, provide fine-grained control over the generated anomalies, enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations. Additionally, our cross-category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types, adapting to their specific surface characteristics. We also provide a comprehensive codebase and visualization toolkit to facilitate future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large pretrained vision foundation models have shown significant potential invarious vision tasks. However, for industrial anomaly detection, the scarcityof real defect samples poses a critical challenge in leveraging these models.While 2D anomaly generation has significantly advanced with establishedgenerative models, the adoption of 3D sensors in industrial manufacturing hasmade leveraging 3D data for surface quality inspection an emerging trend. Incontrast to 2D techniques, 3D anomaly generation remains largely unexplored,limiting the potential of 3D data in industrial quality inspection. To addressthis gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS,based on Perlin noise and surface parameterization. Our method generatesrealistic 3D surface anomalies by projecting the point cloud onto a 2D plane,sampling multi-scale noise values from a Perlin noise field, and perturbing thepoint cloud along its normal direction. Through comprehensive visualizationexperiments, we demonstrate how key parameters - including noise scale,perturbation strength, and octaves, provide fine-grained control over thegenerated anomalies, enabling the creation of diverse defect patterns frompronounced deformations to subtle surface variations. Additionally, ourcross-category experiments show that the method produces consistent yetgeometrically plausible anomalies across different object types, adapting totheir specific surface characteristics. We also provide a comprehensivecodebase and visualization toolkit to facilitate future research.</description>
      <author>example@mail.com (Yifeng Cheng, Juan Du)</author>
      <guid isPermaLink="false">2504.12856v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex</title>
      <link>http://arxiv.org/abs/2504.12474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BiGTex的新型架构，该架构通过堆叠图-文本融合单元，紧密整合了图神经网络（GNNs）和大型语言模型（LLMs），以解决在表示学习中捕获节点关联文本语义丰富性和图结构依赖性的挑战。&lt;h4&gt;背景&lt;/h4&gt;GNNs擅长建模拓扑信息，但缺乏处理非结构化文本的能力；而LLMs在文本理解方面表现优异，但通常不了解图结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够同时处理文本和图结构信息的模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为BiGTex的新架构，它通过堆叠图-文本融合单元将GNNs和LLMs紧密结合，并使用参数高效的微调（LoRA）进行训练，同时保持LLM冻结。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的广泛实验表明，BiGTex在节点分类和链接预测任务中实现了最先进的性能，且能够有效泛化。消融研究表明，软提示和双向注意力在模型成功中起着重要作用。&lt;h4&gt;结论&lt;/h4&gt;BiGTex是一种有效的模型，能够同时处理文本和图结构信息，并在节点分类和链接预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-attributed graphs (TAGs) present unique challenges in representationlearning by requiring models to capture both the semantic richness ofnode-associated texts and the structural dependencies of the graph. While graphneural networks (GNNs) excel at modeling topological information, they lack thecapacity to process unstructured text. Conversely, large language models (LLMs)are proficient in text understanding but are typically unaware of graphstructure. In this work, we propose BiGTex (Bidirectional Graph Text), a novelarchitecture that tightly integrates GNNs and LLMs through stacked Graph-TextFusion Units. Each unit allows for mutual attention between textual andstructural representations, enabling information to flow in both directions,text influencing structure and structure guiding textual interpretation. Theproposed architecture is trained using parameter-efficient fine-tuning (LoRA),keeping the LLM frozen while adapting to task-specific signals. Extensiveexperiments on five benchmark datasets demonstrate that BiGTex achievesstate-of-the-art performance in node classification and generalizes effectivelyto link prediction. An ablation study further highlights the importance of softprompting and bi-directional attention in the model's success.</description>
      <author>example@mail.com (Azadeh Beiranvand, Seyed Mehdi Vahidipour)</author>
      <guid isPermaLink="false">2504.12474v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation</title>
      <link>http://arxiv.org/abs/2504.12800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于笼子的3D高斯喷射（3DGS）变形方法CAGE-GS，该方法能够将源3DGS场景与用户定义的目标形状无缝对齐，并在变形过程中保持原始细节。&lt;h4&gt;背景&lt;/h4&gt;随着3D高斯喷射作为真实场景的3D表示越来越受欢迎，如何实现用户友好的变形以创建新的场景，同时保留原始3DGS的精细细节，已成为研究热点。&lt;h4&gt;目的&lt;/h4&gt;提出CAGE-GS方法，以实现3DGS场景与用户定义的目标形状的无缝对齐，并在变形过程中保持细节。&lt;h4&gt;方法&lt;/h4&gt;CAGE-GS方法通过学习目标形状的变形笼来引导源场景的几何变换。为了保持纹理的准确性，该方法使用基于雅可比矩阵的策略来更新每个高斯函数的协方差参数。该方法灵活，可以适应多种目标形状表示，包括文本、图像、点云、网格和3DGS模型。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集和新提出的场景上的大量实验和消融研究表明，CAGE-GS方法在效率和变形质量方面均显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;CAGE-GS方法为3DGS场景的变形提供了一种高效且质量优良的新方法，为创建新颖的场景提供了有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of real scenes, enabling user-friendly deformation to create novel scenes while preserving fine details from the original 3DGS has attracted significant research attention. We introduce CAGE-GS, a cage-based 3DGS deformation method that seamlessly aligns a source 3DGS scene with a user-defined target shape. Our approach learns a deformation cage from the target, which guides the geometric transformation of the source scene. While the cages effectively control structural alignment, preserving the textural appearance of 3DGS remains challenging due to the complexity of covariance parameters. To address this, we employ a Jacobian matrix-based strategy to update the covariance parameters of each Gaussian, ensuring texture fidelity post-deformation. Our method is highly flexible, accommodating various target shape representations, including texts, images, point clouds, meshes and 3DGS models. Extensive experiments and ablation studies on both public datasets and newly proposed scenes demonstrate that our method significantly outperforms existing techniques in both efficiency and deformation quality.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation ofreal scenes, enabling user-friendly deformation to create novel scenes whilepreserving fine details from the original 3DGS has attracted significantresearch attention. We introduce CAGE-GS, a cage-based 3DGS deformation methodthat seamlessly aligns a source 3DGS scene with a user-defined target shape.Our approach learns a deformation cage from the target, which guides thegeometric transformation of the source scene. While the cages effectivelycontrol structural alignment, preserving the textural appearance of 3DGSremains challenging due to the complexity of covariance parameters. To addressthis, we employ a Jacobian matrix-based strategy to update the covarianceparameters of each Gaussian, ensuring texture fidelity post-deformation. Ourmethod is highly flexible, accommodating various target shape representations,including texts, images, point clouds, meshes and 3DGS models. Extensiveexperiments and ablation studies on both public datasets and newly proposedscenes demonstrate that our method significantly outperforms existingtechniques in both efficiency and deformation quality.</description>
      <author>example@mail.com (Yifei Tong, Runze Tian, Xiao Han, Dingyao Liu, Fenggen Yu, Yan Zhang)</author>
      <guid isPermaLink="false">2504.12800v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding</title>
      <link>http://arxiv.org/abs/2504.13180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在完全开放和可复现的框架下构建感知语言模型（PLM），以实现图像和视频理解的透明研究。&lt;h4&gt;背景&lt;/h4&gt;许多高性能的视觉语言模型是封闭源代码的，这遮蔽了它们的数据、设计和训练方法，影响了科学进步的测量。&lt;h4&gt;目的&lt;/h4&gt;开发一个透明的研究框架，以促进图像和视频理解领域的科学进步。&lt;h4&gt;方法&lt;/h4&gt;分析标准的训练流程，不依赖从封闭模型中提取的蒸馏数据，并探索大规模合成数据来识别关键数据差距，特别是详细视频理解方面的差距。发布2.8M个精细粒度视频问答对和时空定位的视频字幕。引入PLM-VideoBench，用于评估视频理解任务，重点关注对视频中的“什么”、“哪里”、“何时”和“如何”进行推理的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过开放和可复现的研究框架，可以识别视频理解中的关键数据差距，并通过发布标注数据集和评估工具来弥合这些差距。&lt;h4&gt;结论&lt;/h4&gt;通过提供数据、训练方法、代码和模型，使得研究工作可复现，从而推动视觉语言模型研究的透明度和科学进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型在计算机视觉研究中至关重要，但许多高性能模型仍然是封闭源代码的，这掩盖了它们的数据、设计和训练方法。研究界通过从黑盒模型中提取蒸馏数据来标记训练数据，实现了强大的基准结果，但这也以可测量的科学进步为代价。然而，没有了解教师模型及其数据源的具体细节，科学进步仍然难以衡量。在本文中，我们研究了在完全开放和可复现的框架下构建感知语言模型（PLM），以实现图像和视频理解的透明研究。我们分析了不依赖封闭模型蒸馏数据的标准训练流程，并探索了大规模合成数据来识别关键数据差距，特别是在详细视频理解方面。为了弥合这些差距，我们发布了2.8M个精细粒度视频问答对和时空定位的视频字幕。此外，我们引入了PLM-VideoBench，一套用于评估具有挑战性的视频理解任务的工具，重点关注对视频中的“什么”、“哪里”、“何时”和“如何”进行推理的能力。通过提供数据、训练方法、代码和模型，使我们的工作完全可复现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models are integral to computer vision research, yet manyhigh-performing models remain closed-source, obscuring their data, design andtraining recipe. The research community has responded by using distillationfrom black-box models to label training data, achieving strong benchmarkresults, at the cost of measurable scientific progress. However, withoutknowing the details of the teacher model and its data sources, scientificprogress remains difficult to measure. In this paper, we study building aPerception Language Model (PLM) in a fully open and reproducible framework fortransparent research in image and video understanding. We analyze standardtraining pipelines without distillation from proprietary models and explorelarge-scale synthetic data to identify critical data gaps, particularly indetailed video understanding. To bridge these gaps, we release 2.8Mhuman-labeled instances of fine-grained video question-answer pairs andspatio-temporally grounded video captions. Additionally, we introducePLM-VideoBench, a suite for evaluating challenging video understanding tasksfocusing on the ability to reason about "what", "where", "when", and "how" of avideo. We make our work fully reproducible by providing data, training recipes,code &amp; models.</description>
      <author>example@mail.com (Jang Hyun Cho, Andrea Madotto, Effrosyni Mavroudi, Triantafyllos Afouras, Tushar Nagarajan, Muhammad Maaz, Yale Song, Tengyu Ma, Shuming Hu, Suyog Jain, Miguel Martin, Huiyu Wang, Hanoona Rasheed, Peize Sun, Po-Yao Huang, Daniel Bolya, Nikhila Ravi, Shashank Jain, Tammy Stark, Shane Moon, Babak Damavandi, Vivian Lee, Andrew Westbury, Salman Khan, Philipp Krähenbühl, Piotr Dollár, Lorenzo Torresani, Kristen Grauman, Christoph Feichtenhofer)</author>
      <guid isPermaLink="false">2504.13180v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding</title>
      <link>http://arxiv.org/abs/2504.12643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本技术报告介绍了对StreamPETR框架的针对性改进，旨在提高速度估计能力，这是影响NuScenes检测评分的关键因素。&lt;h4&gt;背景&lt;/h4&gt;StreamPETR在3D边界框检测方面表现出色，平均精度较高，但在NuScenes数据集上的速度估计存在瓶颈。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一限制，提出了一种定制化的位置嵌入策略，以增强时间建模能力。&lt;h4&gt;方法&lt;/h4&gt;在NuScenes测试集上进行了实验评估，使用ViT-L骨干网络实现了70.86%的NuScenes检测评分（NDS），达到了相机仅3D目标检测的新基准。&lt;h4&gt;主要发现&lt;/h4&gt;速度估计是StreamPETR在NuScenes数据集上的一个瓶颈，通过改进方法，达到了业界领先的NDS。&lt;h4&gt;结论&lt;/h4&gt;改进的StreamPETR框架在NuScenes测试集上实现了卓越的速度估计性能，为相机仅3D目标检测设定了新标准。&lt;h4&gt;翻译&lt;/h4&gt;This technical report introduces a targeted improvement to the StreamPETR framework, specifically aimed at enhancing velocity estimation, a critical factor influencing the overall NuScenes Detection Score. While StreamPETR exhibits strong 3D bounding box detection performance as reflected by its high mean Average Precision, our analysis identified velocity estimation as a substantial bottleneck when evaluated on the NuScenes dataset. To overcome this limitation, we propose a customized positional embedding strategy tailored to enhance temporal modeling capabilities. Experimental evaluations conducted on the NuScenes test set demonstrate that our improved approach achieves a state-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new benchmark for camera-only 3D object detection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report introduces a targeted improvement to the StreamPETRframework, specifically aimed at enhancing velocity estimation, a criticalfactor influencing the overall NuScenes Detection Score. While StreamPETRexhibits strong 3D bounding box detection performance as reflected by its highmean Average Precision our analysis identified velocity estimation as asubstantial bottleneck when evaluated on the NuScenes dataset. To overcome thislimitation, we propose a customized positional embedding strategy tailored toenhance temporal modeling capabilities. Experimental evaluations conducted onthe NuScenes test set demonstrate that our improved approach achieves astate-of-the-art NDS of 70.86% using the ViT-L backbone, setting a newbenchmark for camera-only 3D object detection.</description>
      <author>example@mail.com (Hang Ji, Tao Ni, Xufeng Huang, Tao Luo, Xin Zhan, Junbo Chen)</author>
      <guid isPermaLink="false">2504.12643v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Cocoa Pod Disease Classification via Transfer Learning and Ensemble Methods: Toward Robust Predictive Modeling</title>
      <link>http://arxiv.org/abs/2504.12992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于集成学习方法的可可豆病害分类方法，该方法结合了迁移学习和三种集成学习策略：Bagging、Boosting和Stacking。&lt;h4&gt;背景&lt;/h4&gt;可可豆病害是影响可可产量和质量的重要因素。&lt;h4&gt;目的&lt;/h4&gt;提高可可豆病害分类的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;使用预训练的卷积神经网络（如VGG16、VGG19、ResNet50等）作为基础学习器，通过迁移学习和集成学习策略进行病害分类。构建了一个包含6000张可可豆图像的平衡数据集，并对图像进行了增强处理，以适应光照、方向和病害严重程度的变化。使用准确率、精确率、召回率和F1分数评估了每种集成学习方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Bagging方法在测试中实现了100%的准确率，优于Boosting（97%）和Stacking（92%）。&lt;h4&gt;结论&lt;/h4&gt;将迁移学习与集成技术相结合可以改善模型泛化能力和可靠性，为精准农业和自动化作物病害管理提供了有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;This study presents an ensemble-based approach for cocoa pod diseaseclassification by integrating transfer learning with three ensemble learningstrategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neuralnetworks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, andXception, were fine-tuned and employed as base learners to detect three diseasecategories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000cocoa pod images was curated and augmented to ensure robustness againstvariations in lighting, orientation, and disease severity. The performance ofeach ensemble method was evaluated using accuracy, precision, recall, andF1-score. Experimental results show that Bagging consistently achieved superiorclassification performance with a test accuracy of 100%, outperforming Boosting(97%) and Stacking (92%). The findings confirm that combining transfer learningwith ensemble techniques improves model generalization and reliability, makingit a promising direction for precision agriculture and automated crop diseasemanagement.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents an ensemble-based approach for cocoa pod diseaseclassification by integrating transfer learning with three ensemble learningstrategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neuralnetworks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, andXception, were fine-tuned and employed as base learners to detect three diseasecategories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000cocoa pod images was curated and augmented to ensure robustness againstvariations in lighting, orientation, and disease severity. The performance ofeach ensemble method was evaluated using accuracy, precision, recall, andF1-score. Experimental results show that Bagging consistently achieved superiorclassification performance with a test accuracy of 100%, outperforming Boosting(97%) and Stacking (92%). The findings confirm that combining transfer learningwith ensemble techniques improves model generalization and reliability, makingit a promising direction for precision agriculture and automated crop diseasemanagement.</description>
      <author>example@mail.com (Devina Anduyan, Nyza Cabillo, Navy Gultiano, Mark Phil Pacot)</author>
      <guid isPermaLink="false">2504.12992v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>DG-MVP: 3D Domain Generalization via Multiple Views of Point Clouds for Classification</title>
      <link>http://arxiv.org/abs/2504.12456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D点云域泛化方法，通过使用多个2D投影来缓解缺失点的难题，并采用了一种简单而有效的基于卷积的模型来提取特征，以应对不同点云域之间的差异。&lt;h4&gt;背景&lt;/h4&gt;虽然深度神经网络在3D点云分类中取得了显著成功，但它们依赖于大规模、标注过的点云数据集，这些数据集的构建非常耗时。与使用LiDAR传感器捕获数据并进行标注相比，从CAD模型中采样点云相对容易，但CAD模型中的点云是规则的，不包含遮挡和缺失点，这导致了与LiDAR数据之间的较大域差异。&lt;h4&gt;目的&lt;/h4&gt;针对3D点云域泛化问题，提出一种能够泛化到未见点云域的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过分析基于点的方法的点利用率和观察不同域的点云几何形状，发现大量点特征被基于点的通过max-pooling操作丢弃。为了解决这些问题，提出了一种新的方法，该方法使用3D点云的多个2D投影来缓解缺失点的问题，并涉及一个简单而有效的基于卷积的模型来提取特征。&lt;h4&gt;主要发现&lt;/h4&gt;基于点的3D域泛化方法通过max-pooling操作丢弃了大量点特征，这在域泛化中是一个显著的浪费，因为域泛化比监督学习更具挑战性，而点云本身就已经受到缺失点和遮挡的影响。&lt;h4&gt;结论&lt;/h4&gt;在PointDA-10和Sim-to-Real基准测试上进行的实验表明，所提出的方法是有效的，优于不同的基线，并且可以从合成域很好地迁移到现实世界域。&lt;h4&gt;翻译&lt;/h4&gt;Deep neural networks have achieved significant success in 3D point cloud classification while relying on large-scale, annotated point cloud datasets, which are labor-intensive to build. Compared to capturing data with LiDAR sensors and then performing annotation, it is relatively easier to sample point clouds from CAD models. Yet, data sampled from CAD models is regular, and does not suffer from occlusion and missing points, which are very common for LiDAR data, creating a large domain shift. Therefore, it is critical to develop methods that can generalize well across different point cloud domains. In this paper, we focus on the 3D point cloud domain generalization problem. Existing 3D domain generalization methods employ point-based backbones to extract point cloud features. Yet, by analyzing point utilization of point-based methods and observing the geometry of point clouds from different domains, we have found that a large number of point features are discarded by point-based methods through the max-pooling operation. This is a significant waste especially considering the fact that domain generalization is more challenging than supervised learning, and point clouds are already affected by missing points and occlusion to begin with. To address these issues, we propose a novel method for 3D point cloud domain generalization, which can generalize to unseen domains of point clouds. Our proposed method employs multiple 2D projections of a 3D point cloud to alleviate the issue of missing points and involves a simple yet effective convolution-based model to extract features. The experiments, performed on the PointDA-10 and Sim-to-Real benchmarks, demonstrate the effectiveness of our proposed method, which outperforms different baselines, and can transfer well from synthetic domain to real-world domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks have achieved significant success in 3D point cloudclassification while relying on large-scale, annotated point cloud datasets,which are labor-intensive to build. Compared to capturing data with LiDARsensors and then performing annotation, it is relatively easier to sample pointclouds from CAD models. Yet, data sampled from CAD models is regular, and doesnot suffer from occlusion and missing points, which are very common for LiDARdata, creating a large domain shift. Therefore, it is critical to developmethods that can generalize well across different point cloud domains. %In thispaper, we focus on the 3D point cloud domain generalization problem. Existing3D domain generalization methods employ point-based backbones to extract pointcloud features. Yet, by analyzing point utilization of point-based methods andobserving the geometry of point clouds from different domains, we have foundthat a large number of point features are discarded by point-based methodsthrough the max-pooling operation. This is a significant waste especiallyconsidering the fact that domain generalization is more challenging thansupervised learning, and point clouds are already affected by missing pointsand occlusion to begin with. To address these issues, we propose a novel methodfor 3D point cloud domain generalization, which can generalize to unseendomains of point clouds. Our proposed method employs multiple 2D projections ofa 3D point cloud to alleviate the issue of missing points and involves a simpleyet effective convolution-based model to extract features. The experiments,performed on the PointDA-10 and Sim-to-Real benchmarks, demonstrate theeffectiveness of our proposed method, which outperforms different baselines,and can transfer well from synthetic domain to real-world domain.</description>
      <author>example@mail.com (Huantao Ren, Minmin Yang, Senem Velipasalar)</author>
      <guid isPermaLink="false">2504.12456v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models</title>
      <link>http://arxiv.org/abs/2504.13122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and Data: https://github.com/HaroldChen19/VistaDPO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VistaDPO，一个用于视频分层时空直接偏好优化的新框架，旨在解决大型视频模型在视频理解中与人类直觉不符和视频幻觉问题。&lt;h4&gt;背景&lt;/h4&gt;大型视频模型（LVMs）基于大型语言模型（LLMs）在视频理解方面有潜力，但往往存在与人类直觉不匹配和视频幻觉问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出VistaDPO框架，以提高文本-视频偏好对齐。&lt;h4&gt;方法&lt;/h4&gt;VistaDPO在三个层次上增强文本-视频偏好对齐：实例级别、时间级别和感知级别。此外，构建了VistaDPO-7k数据集，包含7.2K个问答对，并附有时间戳、关键帧和边界框等时空定位信息。&lt;h4&gt;主要发现&lt;/h4&gt;在视频幻觉、视频问答和字幕性能任务等基准测试中，VistaDPO显著提高了现有LVMs的性能，有效地缓解了视频-语言不匹配和幻觉问题。&lt;h4&gt;结论&lt;/h4&gt;VistaDPO框架和VistaDPO-7k数据集为视频理解提供了有效的方法和数据支持。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces VistaDPO, a novel framework for Video Hierarchical Spatial-Temporal Direct Preference Optimization, aiming to address the challenges of misalignment with human intuition and video hallucination in large video models (LVMs) based on large language models (LLMs). VistaDPO enhances text-video preference alignment across three hierarchical levels: instance level, temporal level, and perceptual level. In addition, the VistaDPO-7k dataset, containing 7.2K QA pairs annotated with selected and rejected responses, along with spatial-temporal grounding information such as timestamps, keyframes, and bounding boxes, has been constructed. Extensive experiments on benchmarks such as Video Hallucination, Video QA, and Captioning performance tasks demonstrate that VistaDPO significantly improves the performance of existing LVMs, effectively mitigating video-language misalignment and hallucination. The code and data are available at https://github.com/HaroldChen19/VistaDPO.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Video Models (LVMs) built upon Large Language Models (LLMs) have shownpromise in video understanding but often suffer from misalignment with humanintuition and video hallucination issues. To address these challenges, weintroduce VistaDPO, a novel framework for Video Hierarchical Spatial-TemporalDirect Preference Optimization. VistaDPO enhances text-video preferencealignment across three hierarchical levels: i) Instance Level, aligning overallvideo content with responses; ii) Temporal Level, aligning video temporalsemantics with event descriptions; and iii) Perceptive Level, aligning spatialobjects with language tokens. Given the lack of datasets for fine-grainedvideo-language preference alignment, we construct VistaDPO-7k, a dataset of7.2K QA pairs annotated with chosen and rejected responses, along withspatial-temporal grounding information such as timestamps, keyframes, andbounding boxes. Extensive experiments on benchmarks such as VideoHallucination, Video QA, and Captioning performance tasks demonstrate thatVistaDPO significantly improves the performance of existing LVMs, effectivelymitigating video-language misalignment and hallucination. The code and data areavailable at https://github.com/HaroldChen19/VistaDPO.</description>
      <author>example@mail.com (Haojian Huang, Haodong Chen, Shengqiong Wu, Meng Luo, Jinlan Fu, Xinya Du, Hanwang Zhang, Hao Fei)</author>
      <guid isPermaLink="false">2504.13122v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration</title>
      <link>http://arxiv.org/abs/2504.12773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GeoGen的几何问题求解方法，用于自动生成几何图的逐步推理路径，并通过GeoLogic模型增强MLLM的逻辑推理能力，以解决几何问题求解中的挑战。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型（MLLMs）在多模态数学推理方面取得了显著进展，但在几何问题求解（GPS）中应用存在挑战，如缺乏精确的逐步解决方案数据和推理过程中的幻觉问题。&lt;h4&gt;目的&lt;/h4&gt;提出GeoGen和GeoLogic模型，旨在解决几何问题求解中的挑战，提高MLLMs的推理能力和准确性。&lt;h4&gt;方法&lt;/h4&gt;GeoGen通过利用精确的符号推理生成大规模、高质量的问答对；GeoLogic则通过使用GeoGen生成的合成数据训练，作为自然语言和符号系统之间的桥梁，帮助验证MLLMs的输出。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GeoGen和GeoLogic模型能够显著提高MLLMs在几何推理任务上的性能，并通过结合LLMs和符号系统的优势，实现更可靠和可解释的GPS方法。&lt;h4&gt;结论&lt;/h4&gt;GeoGen和GeoLogic模型为几何问题求解提供了一种可靠和可解释的方法，有助于提高MLLMs的推理准确性和减少幻觉。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning. However, applying MLLMs to geometry problem solving (GPS) remains challenging due to lack of accurate step-by-step solution data and severe hallucinations during reasoning. In this paper, we propose GeoGen, a pipeline that can automatically generates step-wise reasoning paths for geometry diagrams. By leveraging the precise symbolic reasoning, GeoGen produces large-scale, high-quality question-answer pairs. To further enhance the logical reasoning ability of MLLMs, we train GeoLogic, a Large Language Model (LLM) using synthetic data generated by GeoGen. Serving as a bridge between natural language and symbolic systems, GeoLogic enables symbolic tools to help verifying MLLM outputs, making the reasoning process more rigorous and alleviating hallucinations. Experimental results show that our approach consistently improves the performance of MLLMs, achieving remarkable results on benchmarks for geometric reasoning tasks. This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task. Codes are available at https://github.com/ycpNotFound/GeoGen.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Multimodal Large Language Models (MLLMs) have achievedremarkable progress in general domains and demonstrated promise in multimodalmathematical reasoning. However, applying MLLMs to geometry problem solving(GPS) remains challenging due to lack of accurate step-by-step solution dataand severe hallucinations during reasoning. In this paper, we propose GeoGen, apipeline that can automatically generates step-wise reasoning paths forgeometry diagrams. By leveraging the precise symbolic reasoning,\textbf{GeoGen} produces large-scale, high-quality question-answer pairs. Tofurther enhance the logical reasoning ability of MLLMs, we train\textbf{GeoLogic}, a Large Language Model (LLM) using synthetic data generatedby GeoGen. Serving as a bridge between natural language and symbolic systems,GeoLogic enables symbolic tools to help verifying MLLM outputs, making thereasoning process more rigorous and alleviating hallucinations. Experimentalresults show that our approach consistently improves the performance of MLLMs,achieving remarkable results on benchmarks for geometric reasoning tasks. Thisimprovement stems from our integration of the strengths of LLMs and symbolicsystems, which enables a more reliable and interpretable approach for the GPStask. Codes are available at https://github.com/ycpNotFound/GeoGen.</description>
      <author>example@mail.com (Yicheng Pan, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma)</author>
      <guid isPermaLink="false">2504.12773v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Quantification in Graph Neural Networks with Shallow Ensembles</title>
      <link>http://arxiv.org/abs/2504.12627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习势（MLPs）和图神经网络（GNNs）在材料发现中的应用，通过不确定性量化技术，特别是直接传播浅层集成（DPOSE），提高了GNN在材料建模中的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;机器学习势（MLPs）和图神经网络（GNNs）在材料科学中扮演重要角色，但GNNs在处理未知领域数据时容易产生不可靠的预测。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过不确定性量化技术，特别是DPOSE，提高GNN在材料建模中的预测准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;将DPOSE集成到SchNet模型中，并在多个密度泛函理论（DFT）数据集上，如QM9、OC20和Gold Molecular Dynamics，评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;DPOSE能够有效地区分领域内和领域外样本，对于未观察到的分子和材料类别表现出更高的不确定性。&lt;h4&gt;结论&lt;/h4&gt;本文强调了轻量级不确定性量化方法在提高基于GNN的材料建模鲁棒性中的潜力，并为未来与主动学习策略的结合奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;This abstract summarizes a study on the application of machine-learned potentials (MLPs) and graph neural networks (GNNs) in materials discovery. By exploring uncertainty quantification techniques, particularly Direct Propagation of Shallow Ensembles (DPOSE), the robustness of GNN-based material modeling is improved. The study integrates DPOSE into the SchNet model and evaluates its performance on various Density Functional Theory (DFT) datasets, such as QM9, OC20, and Gold Molecular Dynamics. The main findings demonstrate that DPOSE effectively distinguishes between in-domain and out-of-domain samples, showing higher uncertainty for unobserved molecule and material classes. This work highlights the potential of lightweight uncertainty quantification methods in enhancing the robustness of GNN-based materials modeling and lays the foundation for future integration with active learning strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned potentials (MLPs) have revolutionized materials discovery byproviding accurate and efficient predictions of molecular and materialproperties. Graph Neural Networks (GNNs) have emerged as a state-of-the-artapproach due to their ability to capture complex atomic interactions. However,GNNs often produce unreliable predictions when encountering out-of-domain dataand it is difficult to identify when that happens. To address this challenge,we explore Uncertainty Quantification (UQ) techniques, focusing on DirectPropagation of Shallow Ensembles (DPOSE) as a computationally efficientalternative to deep ensembles. By integrating DPOSE into the SchNet model, weassess its ability to provide reliable uncertainty estimates across diverseDensity Functional Theory datasets, including QM9, OC20, and Gold MolecularDynamics. Our findings often demonstrate that DPOSE successfully distinguishesbetween in-domain and out-of-domain samples, exhibiting higher uncertainty forunobserved molecule and material classes. This work highlights the potential oflightweight UQ methods in improving the robustness of GNN-based materialsmodeling and lays the foundation for future integration with active learningstrategies.</description>
      <author>example@mail.com (Tirtha Vinchurkar, Kareem Abdelmaqsoud, John R. Kitchin)</author>
      <guid isPermaLink="false">2504.12627v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SmartFreeEdit: Mask-Free Spatial-Aware Image Editing with Complex Instruction Understanding</title>
      <link>http://arxiv.org/abs/2504.12704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SmartFreeEdit是一个集成多模态大型语言模型和超图增强修复架构的端到端框架，通过自然语言指令实现精确的无掩码图像编辑。&lt;h4&gt;背景&lt;/h4&gt;图像编辑在空间推理、精确区域分割和保持语义一致性方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;克服上述挑战，实现精确、无掩码的图像编辑。&lt;h4&gt;方法&lt;/h4&gt;SmartFreeEdit的关键创新包括：(1)引入区域感知标记和掩码嵌入范式，增强对复杂场景的空间理解；(2)设计推理分割流程，优化基于自然语言指令的编辑掩码生成；(3)超图增强的修复模块，确保在复杂编辑中保持结构完整性和语义连贯性。&lt;h4&gt;主要发现&lt;/h4&gt;在Reason-Edit基准测试中，SmartFreeEdit在多个评估指标上超越了现有最先进的方法，包括分割精度、指令遵循和视觉质量保持，同时解决了局部信息关注的问题，并提高了编辑图像的全局一致性。&lt;h4&gt;结论&lt;/h4&gt;SmartFreeEdit是一个有效的图像编辑框架，可在https://github.com/smileformylove/SmartFreeEdit上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in image editing have utilized large-scale multimodalmodels to enable intuitive, natural instruction-driven interactions. However,conventional methods still face significant challenges, particularly in spatialreasoning, precise region segmentation, and maintaining semantic consistency,especially in complex scenes. To overcome these challenges, we introduceSmartFreeEdit, a novel end-to-end framework that integrates a multimodal largelanguage model (MLLM) with a hypergraph-enhanced inpainting architecture,enabling precise, mask-free image editing guided exclusively by naturallanguage instructions. The key innovations of SmartFreeEdit include:(1)theintroduction of region aware tokens and a mask embedding paradigm that enhancethe spatial understanding of complex scenes;(2) a reasoning segmentationpipeline designed to optimize the generation of editing masks based on naturallanguage instructions;and (3) a hypergraph-augmented inpainting module thatensures the preservation of both structural integrity and semantic coherenceduring complex edits, overcoming the limitations of local-based imagegeneration. Extensive experiments on the Reason-Edit benchmark demonstrate thatSmartFreeEdit surpasses current state-of-the-art methods across multipleevaluation metrics, including segmentation accuracy, instruction adherence, andvisual quality preservation, while addressing the issue of local informationfocus and improving global consistency in the edited image. Our project will beavailable at https://github.com/smileformylove/SmartFreeEdit.</description>
      <author>example@mail.com (Qianqian Sun, Jixiang Luo, Dell Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2504.12704v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins</title>
      <link>http://arxiv.org/abs/2504.13059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025 Highlight. 22 pages. Project page:  https://robotwin-benchmark.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RoboTwin是一个生成式数字孪生框架，旨在解决机器人领域双臂协调和复杂物体操作能力发展的限制，通过生成多样化的专家数据集和提供与真实世界对齐的评估平台来提升双臂机器人任务的表现。&lt;h4&gt;背景&lt;/h4&gt;在机器人领域，双臂协调和复杂物体操作是开发高级自主系统的重要能力。然而，高质量演示数据的稀缺和真实世界对齐的评估基准的缺乏严重限制了这种发展。&lt;h4&gt;目的&lt;/h4&gt;提出RoboTwin框架，以解决上述问题，促进双臂机器人任务的发展。&lt;h4&gt;方法&lt;/h4&gt;RoboTwin利用3D生成基础模型和大型语言模型来创建从单张2D图像生成的多样化物体数字孪生，生成逼真的交互式场景。同时，引入一个空间关系感知的代码生成框架，结合对象注释和大型语言模型来分解任务、确定空间约束并生成更精确的机器人运动代码。&lt;h4&gt;主要发现&lt;/h4&gt;RoboTwin提供了包含模拟和真实世界数据的全面基准，使标准化评估和模拟训练与真实世界性能之间的更好对齐成为可能。使用开源COBOT Magic Robot平台验证了该方法，在RoboTwin生成的数据上预训练并在有限的现实世界样本上进行微调的策略，与仅使用真实世界数据进行训练的模型相比，在单臂任务的成功率提高了超过70%，在双臂任务中提高了超过40%。&lt;h4&gt;结论&lt;/h4&gt;RoboTwin框架为双臂机器人操作系统提供了显著改进的潜力，通过提高成功率和更有效的训练过程，有助于推动机器人技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the rapidly advancing field of robotics, dual-arm coordination and complexobject manipulation are essential capabilities for developing advancedautonomous systems. However, the scarcity of diverse, high-qualitydemonstration data and real-world-aligned evaluation benchmarks severely limitssuch development. To address this, we introduce RoboTwin, a generative digitaltwin framework that uses 3D generative foundation models and large languagemodels to produce diverse expert datasets and provide a real-world-alignedevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin createsvaried digital twins of objects from single 2D images, generating realistic andinteractive scenarios. It also introduces a spatial relation-aware codegeneration framework that combines object annotations with large languagemodels to break down tasks, determine spatial constraints, and generate preciserobotic movement code. Our framework offers a comprehensive benchmark with bothsimulated and real-world data, enabling standardized evaluation and betteralignment between simulated training and real-world performance. We validatedour approach using the open-source COBOT Magic Robot platform. Policiespre-trained on RoboTwin-generated data and fine-tuned with limited real-worldsamples demonstrate significant potential for enhancing dual-arm roboticmanipulation systems by improving success rates by over 70% for single-armtasks and over 40% for dual-arm tasks compared to models trained solely onreal-world data.</description>
      <author>example@mail.com (Yao Mu, Tianxing Chen, Zanxin Chen, Shijia Peng, Zhiqian Lan, Zeyu Gao, Zhixuan Liang, Qiaojun Yu, Yude Zou, Mingkun Xu, Lunkai Lin, Zhiqiang Xie, Mingyu Ding, Ping Luo)</author>
      <guid isPermaLink="false">2504.13059v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Geographical Context Matters: Bridging Fine and Coarse Spatial Information to Enhance Continental Land Cover Mapping</title>
      <link>http://arxiv.org/abs/2504.12368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为BRIDGE-LC的深度学习框架，用于土地覆盖分类，该框架通过整合多尺度地理空间信息来提高土地覆盖地图的准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;土地覆盖和土地覆盖图在可持续土地和资源管理中至关重要，而现有的机器学习和深度学习算法在分析地球观测数据时往往忽略了关键的地理空间元数据信息。&lt;h4&gt;目的&lt;/h4&gt;提出BRIDGE-LC框架，以解决现有算法忽略地理空间元数据信息的问题，并提高土地覆盖分类的准确性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;BRIDGE-LC框架通过同时利用细粒度（经纬度）和粗粒度（生物地理区域）的空间信息，在训练期间学习两种信息，但在推理时只需使用细粒度信息，从而分离特定区域和区域无关的土地覆盖特征，同时保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用开放获取的现场数据集和几种竞争性的分类方法，评估了该框架的质量。结果表明，整合地理空间信息提高了土地覆盖地图的性能，特别是通过联合利用细粒度和粗粒度空间信息获得的收益最大。&lt;h4&gt;结论&lt;/h4&gt;整合地理空间信息对于提高土地覆盖地图的性能至关重要，并且该框架能够有效地处理不同尺度的地理空间信息，从而提高分类的准确性和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Land use and land cover mapping from Earth Observation (EO) data is acritical tool for sustainable land and resource management. While advancedmachine learning and deep learning algorithms excel at analyzing EO imagerydata, they often overlook crucial geospatial metadata information that couldenhance scalability and accuracy across regional, continental, and globalscales. To address this limitation, we propose BRIDGE-LC (Bi-levelRepresentation Integration for Disentangled GEospatial Land Cover), a noveldeep learning framework that integrates multi-scale geospatial information intothe land cover classification process. By simultaneously leveragingfine-grained (latitude/longitude) and coarse-grained (biogeographical region)spatial information, our lightweight multi-layer perceptron architecture learnsfrom both during training but only requires fine-grained information forinference, allowing it to disentangle region-specific from region-agnostic landcover features while maintaining computational efficiency. To assess thequality of our framework, we use an open-access in-situ dataset and adoptseveral competing classification approaches commonly considered for large-scaleland cover mapping. We evaluated all approaches through two scenarios: anextrapolation scenario in which training data encompasses samples from allbiogeographical regions, and a leave-one-region-out scenario where one regionis excluded from training. We also explore the spatial representation learnedby our model, highlighting a connection between its internal manifold and thegeographical information used during training. Our results demonstrate thatintegrating geospatial information improves land cover mapping performance,with the most substantial gains achieved by jointly leveraging both fine- andcoarse-grained spatial information.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Land use and land cover mapping from Earth Observation (EO) data is acritical tool for sustainable land and resource management. While advancedmachine learning and deep learning algorithms excel at analyzing EO imagerydata, they often overlook crucial geospatial metadata information that couldenhance scalability and accuracy across regional, continental, and globalscales. To address this limitation, we propose BRIDGE-LC (Bi-levelRepresentation Integration for Disentangled GEospatial Land Cover), a noveldeep learning framework that integrates multi-scale geospatial information intothe land cover classification process. By simultaneously leveragingfine-grained (latitude/longitude) and coarse-grained (biogeographical region)spatial information, our lightweight multi-layer perceptron architecture learnsfrom both during training but only requires fine-grained information forinference, allowing it to disentangle region-specific from region-agnostic landcover features while maintaining computational efficiency. To assess thequality of our framework, we use an open-access in-situ dataset and adoptseveral competing classification approaches commonly considered for large-scaleland cover mapping. We evaluated all approaches through two scenarios: anextrapolation scenario in which training data encompasses samples from allbiogeographical regions, and a leave-one-region-out scenario where one regionis excluded from training. We also explore the spatial representation learnedby our model, highlighting a connection between its internal manifold and thegeographical information used during training. Our results demonstrate thatintegrating geospatial information improves land cover mapping performance,with the most substantial gains achieved by jointly leveraging both fine- andcoarse-grained spatial information.</description>
      <author>example@mail.com (Babak Ghassemi, Cassio Fraga-Dantas, Raffaele Gaetano, Dino Ienco, Omid Ghorbanzadeh, Emma Izquierdo-Verdiguier, Francesco Vuolo)</author>
      <guid isPermaLink="false">2504.12368v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal single-cell foundation models via dynamic token adaptation</title>
      <link>http://arxiv.org/abs/2504.13049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在基因组学中应用深度学习的最新进展，包括DNA语言和单细胞基础模型，并提出了一种动态标记适应方法，以预测不同遗传背景下单细胞水平的基因调控。&lt;h4&gt;背景&lt;/h4&gt;目前深度学习在基因组学中的应用包括DNA语言和单细胞基础模型，但这些模型仅接受一种数据类型作为输入。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态标记适应方法，将不同模型结合以预测不同遗传背景下单细胞水平的基因调控。&lt;h4&gt;方法&lt;/h4&gt;通过训练一个从DNA序列嵌入到单细胞基础模型标记嵌入空间的适配器，对转录因子GATA4的转录起始位点进行模拟突变，评估DNA序列变化对模型学习到的基因调控网络的影响。&lt;h4&gt;主要发现&lt;/h4&gt;动态标记适应方法能够结合不同模型预测基因调控，并通过模拟突变实验观察到模型预测的靶基因表达变化。&lt;h4&gt;结论&lt;/h4&gt;该方法具有通用性，并通过实例证明了其在预测基因调控方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in applying deep learning in genomics include DNA-language and single-cell foundation models. However, these models take only one datatype as input. We introduce dynamic token adaptation and demonstrate how it combines these models to predict gene regulation at the single-cell level in different genetic contexts. Although the method is generalisable, we focus on an illustrative example by training an adapter from DNA-sequence embeddings to a single-cell foundation model's token embedding space. As a qualitative evaluation, we assess the impact of DNA sequence changes on the model's learned gene regulatory networks by mutating the transcriptional start site of the transcription factor GATA4 in silico, observing predicted expression changes in its target genes in fetal cardiomyocytes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in applying deep learning in genomics include DNA-languageand single-cell foundation models. However, these models take only one datatype as input. We introduce dynamic token adaptation and demonstrate how itcombines these models to predict gene regulation at the single-cell level indifferent genetic contexts. Although the method is generalisable, we focus onan illustrative example by training an adapter from DNA-sequence embeddings toa single-cell foundation model's token embedding space. As a qualitativeevaluation, we assess the impact of DNA sequence changes on the model's learnedgene regulatory networks by mutating the transcriptional start site of thetranscription factor GATA4 in silico, observing predicted expression changes inits target genes in fetal cardiomyocytes.</description>
      <author>example@mail.com (Wenmin Zhao, Ana Solaguren-Beascoa, Grant Neilson, Louwai Muhammed, Liisi Laaniste, Sera Aylin Cakiroglu)</author>
      <guid isPermaLink="false">2504.13049v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Computing Supported Adversarial Attack-Resilient Autonomous Vehicle Perception Module for Traffic Sign Classification</title>
      <link>http://arxiv.org/abs/2504.12644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究创建了混合经典-量子深度学习模型（HCQ-DL），并与经典深度学习模型（C-DL）进行了比较，以展示其在对抗攻击下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在自动驾驶汽车的感知模块中至关重要，而对抗攻击可能导致模型预测错误，如误分类交通标志。&lt;h4&gt;目的&lt;/h4&gt;研究HCQ-DL模型在对抗攻击下的鲁棒性，以提升自动驾驶汽车感知模块的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用迁移学习模型AlexNet和VGG-16作为特征提取器，测试了超过1000个量子电路，包括针对投影梯度下降（PGD）、快速梯度符号攻击（FGSA）和梯度攻击（GA）的测试，并在对抗攻击和无攻击场景下评估了所有模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;HCQ-DL模型在无攻击场景下保持准确率高于95%，在GA和FGSA攻击下保持准确率高于91%，而在PGD攻击中，基于AlexNet的HCQ-DL模型准确率保持在85%，而C-DL模型准确率低于21%。&lt;h4&gt;结论&lt;/h4&gt;与经典模型相比，HCQ-DL模型在对抗攻击设置下对交通标志分类的准确性有所提高。&lt;h4&gt;翻译&lt;/h4&gt;In this study, we created and compared hybrid classical-quantum deep learning (HCQ-DL) models with classical deep learning (C-DL) models to demonstrate robustness against adversarial attacks for perception modules. Before feeding them into the quantum system, we used transfer learning models, alexnet and vgg-16, as feature extractors. We tested over 1000 quantum circuits in our HCQ-DL models for projected gradient descent (PGD), fast gradient sign attack (FGSA), and gradient attack (GA), which are three well-known untargeted adversarial approaches. We evaluated the performance of all models during adversarial attacks and no-attack scenarios. Our HCQ-DL models maintain accuracy above 95% during a no-attack scenario and above 91% for GA and FGSA attacks, which is higher than C-DL models. During the PGD attack, our alexnet-based HCQ-DL model maintained an accuracy of 85% compared to C-DL models that achieved accuracies below 21%. Our results highlight that the HCQ-DL models provide improved accuracy for traffic sign classification under adversarial settings compared to their classical counterparts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning (DL)-based image classification models are essential forautonomous vehicle (AV) perception modules since incorrect categorization mighthave severe repercussions. Adversarial attacks are widely studied cyberattacksthat can lead DL models to predict inaccurate output, such as incorrectlyclassified traffic signs by the perception module of an autonomous vehicle. Inthis study, we create and compare hybrid classical-quantum deep learning(HCQ-DL) models with classical deep learning (C-DL) models to demonstraterobustness against adversarial attacks for perception modules. Before feedingthem into the quantum system, we used transfer learning models, alexnet andvgg-16, as feature extractors. We tested over 1000 quantum circuits in ourHCQ-DL models for projected gradient descent (PGD), fast gradient sign attack(FGSA), and gradient attack (GA), which are three well-known untargetedadversarial approaches. We evaluated the performance of all models duringadversarial attacks and no-attack scenarios. Our HCQ-DL models maintainaccuracy above 95\% during a no-attack scenario and above 91\% for GA and FGSAattacks, which is higher than C-DL models. During the PGD attack, ouralexnet-based HCQ-DL model maintained an accuracy of 85\% compared to C-DLmodels that achieved accuracies below 21\%. Our results highlight that theHCQ-DL models provide improved accuracy for traffic sign classification underadversarial settings compared to their classical counterparts.</description>
      <author>example@mail.com (Reek Majumder, Mashrur Chowdhury, Sakib Mahmud Khan, Zadid Khan, Fahim Ahmad, Frank Ngeni, Gurcan Comert, Judith Mwakalonge, Dimitra Michalaka)</author>
      <guid isPermaLink="false">2504.12644v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>EventVAD: Training-Free Event-Aware Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.13092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EventVAD的事件感知视频异常检测框架，旨在提高视频异常检测的准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;传统的视频异常检测方法需要大量的训练数据，且难以泛化到未见过的异常情况。无监督方法虽然利用了大型语言模型（LLMs）的世界知识，但在定位精细的视觉转换和多样化事件方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出EventVAD框架，结合定制动态图架构和多模态LLMs，通过时间-事件推理来检测视频中的异常。&lt;h4&gt;方法&lt;/h4&gt;EventVAD首先使用动态时空图建模和时间衰减约束来捕捉事件感知的视频特征，然后通过自适应噪声滤波和信号比阈值检测事件边界。统计边界检测模块简化了处理长视频的复杂度，并通过事件一致性提高了MLLM的时间推理能力。最后，采用分层提示策略引导MLLM在做出最终决策前进行推理。&lt;h4&gt;主要发现&lt;/h4&gt;在UCF-Crime和XD-Violence数据集上进行的广泛实验表明，使用7B MLLM的EventVAD在无监督设置中达到了最先进（SOTA）的性能，超过了使用7B或更大MLLM的强基线。&lt;h4&gt;结论&lt;/h4&gt;EventVAD框架在无监督视频异常检测方面具有显著优势，能够有效提高检测准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Video Anomaly Detection (VAD) focuses on identifying anomalies within videos. Supervised methods require an amount of in-domain training data and often struggle to generalize to unseen anomalies. In contrast, training-free methods leverage the intrinsic world knowledge of large language models (LLMs) to detect anomalies but face challenges in localizing fine-grained visual transitions and diverse events. Therefore, we propose EventVAD, an event-aware video anomaly detection framework that combines tailored dynamic graph architectures and multimodal LLMs through temporal-event reasoning. Specifically, EventVAD first employs dynamic spatiotemporal graph modeling with time-decay constraints to capture event-aware video features. Then, it performs adaptive noise filtering and uses signal ratio thresholding to detect event boundaries via unsupervised statistical features. The statistical boundary detection module reduces the complexity of processing long videos for MLLMs and improves their temporal reasoning through event consistency. Finally, it utilizes a hierarchical prompting strategy to guide MLLMs in performing reasoning before determining final decisions. We conducted extensive experiments on the UCF-Crime and XD-Violence datasets. The results demonstrate that EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free settings, outperforming strong baselines that use 7B or larger MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos.Supervised methods require an amount of in-domain training data and oftenstruggle to generalize to unseen anomalies. In contrast, training-free methodsleverage the intrinsic world knowledge of large language models (LLMs) todetect anomalies but face challenges in localizing fine-grained visualtransitions and diverse events. Therefore, we propose EventVAD, an event-awarevideo anomaly detection framework that combines tailored dynamic grapharchitectures and multimodal LLMs through temporal-event reasoning.Specifically, EventVAD first employs dynamic spatiotemporal graph modeling withtime-decay constraints to capture event-aware video features. Then, it performsadaptive noise filtering and uses signal ratio thresholding to detect eventboundaries via unsupervised statistical features. The statistical boundarydetection module reduces the complexity of processing long videos for MLLMs andimproves their temporal reasoning through event consistency. Finally, itutilizes a hierarchical prompting strategy to guide MLLMs in performingreasoning before determining final decisions. We conducted extensiveexperiments on the UCF-Crime and XD-Violence datasets. The results demonstratethat EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-freesettings, outperforming strong baselines that use 7B or larger MLLMs.</description>
      <author>example@mail.com (Yihua Shao, Haojin He, Sijie Li, Siyu Chen, Xinwei Long, Fanhu Zeng, Yuxuan Fan, Muyang Zhang, Ziyang Yan, Ao Ma, Xiaochen Wang, Hao Tang, Yan Wang, Shuyan Li)</author>
      <guid isPermaLink="false">2504.13092v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Based Robust LiDAR Place Recognition</title>
      <link>http://arxiv.org/abs/2504.12412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在建筑工地上进行自主测绘和检查任务时，移动机器人对准确姿态估计的需求。由于存在重复特征如平整的粉刷墙壁以及由于楼层布局相似而产生的感知混淆问题，建筑工地的定位是一个特别具有挑战性的问题。&lt;h4&gt;背景&lt;/h4&gt;建筑工地的定位由于重复特征和感知混淆而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过仅使用LiDAR数据来实现对建筑精确扫描网格的机器人全局定位。&lt;h4&gt;方法&lt;/h4&gt;采用了一种基于合成LiDAR点云的方法，这些点云是通过模拟真实场景中的LiDAR在大规模网格中生成的。使用PointNet++作为骨干网络训练了一个扩散模型，从而能够从单个LiDAR点云中建模多个位置候选。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够成功预测LiDAR在封闭和复杂环境中的全局位置，即使在感知混淆的负面效应下也能做到。学习到的潜在全局位置分布可以提供多模态位置分布。&lt;h4&gt;结论&lt;/h4&gt;在五个真实世界数据集上评估了该方法，平均识别精度为77% +/-2米，在平均误差方面优于基线模型2倍。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the need for accurate pose estimation for mobile robots on construction sites to perform autonomous surveying and inspection missions. Localization in construction sites is particularly challenging due to the presence of repetitive features such as flat plastered walls and perceptual aliasing due to apartments with similar layouts inter and intra floors. In this paper, we focus on the global re-positioning of a robot with respect to an accurate scanned mesh of the building solely using LiDAR data. In our approach, a neural network is trained on synthetic LiDAR point clouds generated by simulating a LiDAR in an accurate real-life large-scale mesh. We train a diffusion model with a PointNet++ backbone, which allows us to model multiple position candidates from a single LiDAR point cloud. The resulting model can successfully predict the global position of LiDAR in confined and complex sites despite the adverse effects of perceptual aliasing. The learned distribution of potential global positions can provide multi-modal position distribution. We evaluate our approach across five real-world datasets and show the place recognition accuracy of 77% +/-2m on average while outperforming baselines at a factor of 2 in mean error.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots on construction sites require accurate pose estimation toperform autonomous surveying and inspection missions. Localization inconstruction sites is a particularly challenging problem due to the presence ofrepetitive features such as flat plastered walls and perceptual aliasing due toapartments with similar layouts inter and intra floors. In this paper, we focuson the global re-positioning of a robot with respect to an accurate scannedmesh of the building solely using LiDAR data. In our approach, a neural networkis trained on synthetic LiDAR point clouds generated by simulating a LiDAR inan accurate real-life large-scale mesh. We train a diffusion model with aPointNet++ backbone, which allows us to model multiple position candidates froma single LiDAR point cloud. The resulting model can successfully predict theglobal position of LiDAR in confined and complex sites despite the adverseeffects of perceptual aliasing. The learned distribution of potential globalpositions can provide multi-modal position distribution. We evaluate ourapproach across five real-world datasets and show the place recognitionaccuracy of 77% +/-2m on average while outperforming baselines at a factor of 2in mean error.</description>
      <author>example@mail.com (Benjamin Krummenacher, Jonas Frey, Turcan Tuna, Olga Vysotska, Marco Hutter)</author>
      <guid isPermaLink="false">2504.12412v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2504.12597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GeoSense，一个用于评估多模态大型语言模型（MLLMs）几何推理能力的双语基准。&lt;h4&gt;背景&lt;/h4&gt;几何问题解决（GPS）是一项挑战性任务，需要视觉理解和符号推理，可以有效地衡量MLLMs的推理能力。人类在此任务中表现出强大的推理能力，通过准确识别和适应视觉环境中的几何原理。&lt;h4&gt;目的&lt;/h4&gt;现有的基准未能联合评估MLLMs中类似人类几何推理机制的这两个维度，这是评估其解决GPS能力的一个关键差距。&lt;h4&gt;方法&lt;/h4&gt;GeoSense引入了一个五级层次结构的几何原理框架，涵盖了平面和立体几何，一个包含1789个问题的复杂注释数据集，以及一种创新的评估策略。&lt;h4&gt;主要发现&lt;/h4&gt;在GeoSense上进行的广泛实验表明，Gemini-2.0-pro-flash表现最佳，总分为65.3。深入分析显示，几何原理的识别和应用仍然是领先MLLMs的瓶颈，共同阻碍了它们的推理能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现强调了GeoSense在指导未来MLLMs几何推理能力进步方面的潜力，为人工智能中更强大和更类似人类的推理铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of 65.3. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry problem-solving (GPS), a challenging task requiring both visualcomprehension and symbolic reasoning, effectively measures the reasoningcapabilities of multimodal large language models (MLLMs). Humans exhibit strongreasoning ability in this task through accurate identification and adaptiveapplication of geometric principles within visual contexts. However, existingbenchmarks fail to jointly assess both dimensions of the human-like geometricreasoning mechanism in MLLMs, remaining a critical gap in assessing theirability to tackle GPS. To this end, we introduce GeoSense, the firstcomprehensive bilingual benchmark designed to systematically evaluate thegeometric reasoning abilities of MLLMs through the lens of geometricprinciples. GeoSense features a five-level hierarchical framework of geometricprinciples spanning plane and solid geometry, an intricately annotated datasetof 1,789 problems, and an innovative evaluation strategy. Through extensiveexperiments on GeoSense with various open-source and closed-source MLLMs, weobserve that Gemini-2.0-pro-flash performs best, achieving an overall score of$65.3$. Our in-depth analysis reveals that the identification and applicationof geometric principles remain a bottleneck for leading MLLMs, jointlyhindering their reasoning abilities. These findings underscore GeoSense'spotential to guide future advancements in MLLMs' geometric reasoningcapabilities, paving the way for more robust and human-like reasoning inartificial intelligence.</description>
      <author>example@mail.com (Liangyu Xu, Yingxiu Zhao, Jingyun Wang, Yingyao Wang, Bu Pi, Chen Wang, Mingliang Zhang, Jihao Gu, Xiang Li, Xiaoyong Zhu, Jun Song, Bo Zheng)</author>
      <guid isPermaLink="false">2504.12597v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond</title>
      <link>http://arxiv.org/abs/2504.13037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ViTa，一个用于心脏健康评估的综合模型，它结合了心脏磁共振成像（CMR）数据和患者级别的健康因素，以提供对心脏健康和疾病风险的全面理解。&lt;h4&gt;背景&lt;/h4&gt;心脏磁共振成像是非侵入性心脏评估的金标准，但单独使用CMR无法捕捉到影响心血管健康和疾病风险的患者级别健康因素。&lt;h4&gt;目的&lt;/h4&gt;为了全面理解心脏健康并准确解释个体的疾病风险，需要将CMR和患者级别因素联合起来。&lt;h4&gt;方法&lt;/h4&gt;ViTa利用42,000名英国生物样本库参与者的数据，结合了3D+T cine stacks从短轴和长轴视图，并与详细的表格患者级别因素融合，以实现上下文感知洞察。&lt;h4&gt;主要发现&lt;/h4&gt;ViTa支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及心脏和代谢疾病的分类。&lt;h4&gt;结论&lt;/h4&gt;ViTa通过学习连接丰富成像特征和患者背景的共享潜在表示，超越了传统的任务特定模型，向通用、个体化的心脏健康理解迈进，突出了其在心脏分析中的临床应用和可扩展性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：心脏磁共振成像是非侵入性心脏评估的金标准，提供了丰富的时空心脏解剖和生理视图。患者级别的健康因素，如人口统计学、代谢和生活方式，已知会显著影响心血管健康和疾病风险，但单独的心脏磁共振成像无法捕捉到这些因素。为了全面理解心脏健康并使个体疾病风险的解释达到最佳，必须在综合框架内联合利用心脏磁共振成像和患者级别因素。最近的多模态方法开始弥合这一差距，但它们通常依赖于有限的时空数据，并专注于孤立的临床任务，从而阻碍了心脏健康评估的全面表示的发展。为了克服这些限制，我们引入了ViTa，这是向基础模型迈进的一步，它提供了心脏的全面表示和个体疾病风险的精确解释。利用42,000名英国生物样本库参与者的数据，ViTa结合了短轴和长轴视图的3D+T cine stacks，实现了对心脏周期的完整捕捉。然后，这些成像数据与详细的表格患者级别因素融合，以实现上下文感知洞察。这种多模态范式支持广泛的下游任务，包括心脏表型和生理特征预测、分割以及在一个单一统一框架内对心脏和代谢疾病的分类。通过学习连接丰富成像特征和患者背景的共享潜在表示，ViTa超越了传统的任务特定模型，向通用、个体化的心脏健康理解迈进，突出了其在心脏分析中的临床应用和可扩展性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiac magnetic resonance imaging is the gold standard for non-invasivecardiac assessment, offering rich spatio-temporal views of the cardiac anatomyand physiology. Patient-level health factors, such as demographics, metabolic,and lifestyle, are known to substantially influence cardiovascular health anddisease risk, yet remain uncaptured by CMR alone. To holistically understandcardiac health and to enable the best possible interpretation of anindividual's disease risk, CMR and patient-level factors must be jointlyexploited within an integrated framework. Recent multi-modal approaches havebegun to bridge this gap, yet they often rely on limited spatio-temporal dataand focus on isolated clinical tasks, thereby hindering the development of acomprehensive representation for cardiac health evaluation. To overcome theselimitations, we introduce ViTa, a step toward foundation models that delivers acomprehensive representation of the heart and a precise interpretation ofindividual disease risk. Leveraging data from 42,000 UK Biobank participants,ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enablinga complete capture of the cardiac cycle. These imaging data are then fused withdetailed tabular patient-level factors, enabling context-aware insights. Thismulti-modal paradigm supports a wide spectrum of downstream tasks, includingcardiac phenotype and physiological feature prediction, segmentation, andclassification of cardiac and metabolic diseases within a single unifiedframework. By learning a shared latent representation that bridges rich imagingfeatures and patient context, ViTa moves beyond traditional, task-specificmodels toward a universal, patient-specific understanding of cardiac health,highlighting its potential to advance clinical utility and scalability incardiac analysis.</description>
      <author>example@mail.com (Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan)</author>
      <guid isPermaLink="false">2504.13037v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving CNN Training with Transfer Learning: Two Hidden Layers</title>
      <link>http://arxiv.org/abs/2504.12623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用全同态加密（FHE）训练四层神经网络的方法，支持单输出和多输出分类任务，并在非交互式环境中实现。&lt;h4&gt;背景&lt;/h4&gt;在加密数据上训练神经网络是一个挑战，因为传统的加密方法不支持直接的模型训练。&lt;h4&gt;目的&lt;/h4&gt;研究如何使用全同态加密在加密数据上训练神经网络，并提高分类任务的性能。&lt;h4&gt;方法&lt;/h4&gt;使用全同态加密训练神经网络，并通过替换Softmax函数为Sigmoid函数，结合二元交叉熵（BCE）损失函数，实现有效的同态分类。同时，改进了数据编码方案Double Volley Revolver，以优化计算和内存效率。&lt;h4&gt;主要发现&lt;/h4&gt;发现使用Sigmoid和BCE损失函数可以有效地进行同态分类，并且BCE损失函数可以自然地扩展到多类设置。此外，指出了先前损失函数（如SLE损失和2019 CVPR Workshop中提出的一种）的局限性，即随着网络深度的增加，梯度消失问题。&lt;h4&gt;结论&lt;/h4&gt;全同态加密可以用于训练神经网络，并在非交互式环境中支持分类任务，同时通过改进数据编码方案，使得基于FHE的神经网络训练更加实际。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种使用全同态加密（FHE）训练四层神经网络的方法，支持单输出和多输出分类任务，并在非交互式环境中实现。我们的工作贡献在于，通过使用Sigmoid函数替换Softmax函数，并结合二元交叉熵（BCE）损失函数，为同态分类提供了一种有效且可扩展的解决方案。此外，我们展示了BCE损失函数，最初是为多输出任务设计的，可以自然地扩展到多类设置，从而使其应用范围更广。我们还强调了先前损失函数（如SLE损失和2019 CVPR Workshop中提出的一种）的局限性，这些损失函数随着网络深度的增加会遭受梯度消失问题。为了解决大规模加密数据带来的挑战，我们进一步引入了之前提出的改进版数据编码方案Double Volley Revolver，实现了计算效率和内存效率之间的更好权衡，使得基于FHE的神经网络训练更加可行。完整的、可运行的C++代码可以在以下链接找到：https://github.com/petitioner/ML.NNtraining&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present the demonstration of training a four-layer neuralnetwork entirely using fully homomorphic encryption (FHE), supporting bothsingle-output and multi-output classification tasks in a non-interactivesetting. A key contribution of our work is identifying that replacing\textit{Softmax} with \textit{Sigmoid}, in conjunction with the BinaryCross-Entropy (BCE) loss function, provides an effective and scalable solutionfor homomorphic classification. Moreover, we show that the BCE loss function,originally designed for multi-output tasks, naturally extends to themulti-class setting, thereby enabling broader applicability. We also highlightthe limitations of prior loss functions such as the SLE loss and the oneproposed in the 2019 CVPR Workshop, both of which suffer from vanishinggradients as network depth increases. To address the challenges posed bylarge-scale encrypted data, we further introduce an improved version of thepreviously proposed data encoding scheme, \textit{Double Volley Revolver},which achieves a better trade-off between computational and memory efficiency,making FHE-based neural network training more practical. The complete, runnableC++ code to implement our work can be found at:\href{https://github.com/petitioner/ML.NNtraining}{$\texttt{https://github.com/petitioner/ML.NNtraining}$}.</description>
      <author>example@mail.com (John Chiang)</author>
      <guid isPermaLink="false">2504.12623v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Prototypes are Balanced Units for Efficient and Effective Partially Relevant Video Retrieval</title>
      <link>http://arxiv.org/abs/2504.13035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种部分相关视频检索（PRVR）框架，旨在同时提高检索的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;在检索系统中，同时实现搜索准确性和效率是一个挑战，特别是在部分相关视频检索中，引入更多样化的上下文表示可以增强准确性，但也会增加计算和内存成本。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一矛盾，本文提出了一种将视频中的多样化上下文编码为固定数量原型的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法包括：将上下文编码为原型、引入策略增强文本关联和视频理解、实现跨模态和单模态重建任务、使用视频混合技术提供弱指导以进一步对齐原型和文本表示。&lt;h4&gt;主要发现&lt;/h4&gt;在TVR、ActivityNet-Captions和QVHighlights上的广泛评估验证了该方法的有效性，且未牺牲效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在提高PRVR的准确性和效率方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;In a retrieval system, simultaneously achieving search accuracy and efficiency is inherently challenging. This challenge is particularly pronounced in partially relevant video retrieval (PRVR), where incorporating more diverse context representations at varying temporal scales for each video enhances accuracy but increases computational and memory costs. To address this dichotomy, we propose a prototypical PRVR framework that encodes diverse contexts within a video into a fixed number of prototypes. We then introduce several strategies to enhance text association and video understanding within the prototypes, along with an orthogonal objective to ensure that the prototypes capture a diverse range of content. To keep the prototypes searchable via text queries while accurately encoding video contexts, we implement cross- and uni-modal reconstruction tasks. The cross-modal reconstruction task aligns the prototypes with textual features within a shared space, while the uni-modal reconstruction task preserves all video contexts during encoding. Additionally, we employ a video mixing technique to provide weak guidance to further align prototypes and associated textual representations. Extensive evaluations on TVR, ActivityNet-Captions, and QVHighlights validate the effectiveness of our approach without sacrificing efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a retrieval system, simultaneously achieving search accuracy andefficiency is inherently challenging. This challenge is particularly pronouncedin partially relevant video retrieval (PRVR), where incorporating more diversecontext representations at varying temporal scales for each video enhancesaccuracy but increases computational and memory costs. To address thisdichotomy, we propose a prototypical PRVR framework that encodes diversecontexts within a video into a fixed number of prototypes. We then introduceseveral strategies to enhance text association and video understanding withinthe prototypes, along with an orthogonal objective to ensure that theprototypes capture a diverse range of content. To keep the prototypessearchable via text queries while accurately encoding video contexts, weimplement cross- and uni-modal reconstruction tasks. The cross-modalreconstruction task aligns the prototypes with textual features within a sharedspace, while the uni-modal reconstruction task preserves all video contextsduring encoding. Additionally, we employ a video mixing technique to provideweak guidance to further align prototypes and associated textualrepresentations. Extensive evaluations on TVR, ActivityNet-Captions, andQVHighlights validate the effectiveness of our approach without sacrificingefficiency.</description>
      <author>example@mail.com (WonJun Moon, Cheol-Ho Cho, Woojin Jun, Minho Shim, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Jae-Pil Heo)</author>
      <guid isPermaLink="false">2504.13035v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Sparks of Science: Hypothesis Generation Using Structured Paper Data</title>
      <link>http://arxiv.org/abs/2504.12976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures. Comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HypoGen的数据集，用于科学假设生成（SHG），并通过在Bit-Flip-Spark架构上微调语言模型，提高了生成假设的总体质量。&lt;h4&gt;背景&lt;/h4&gt;生成新颖且可行的科学假设是实现通用人工智能的关键。然而，现有的基础模型在生成新颖且可行的科学想法方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来系统地创建、选择和验证科学假设，并提高假设生成的质量。&lt;h4&gt;方法&lt;/h4&gt;引入了HypoGen数据集，包含约5500个结构化的问题-假设对，并采用Bit-Flip-Spark架构。通过将假设生成作为条件语言建模，并在Bit-Flip-Spark和推理过程中使用链式推理组件进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过在HypoGen数据集上微调，提高了生成假设的新颖性、可行性和总体质量。&lt;h4&gt;结论&lt;/h4&gt;HypoGen数据集有助于提高科学假设生成的质量，并为未来研究提供了有价值的资源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成新颖的创造性科学假设是实现通用人工智能的基石。大型语言和推理模型有潜力帮助系统地创建、选择和验证基于科学的信息假设。然而，当前的基础模型往往难以产生既新颖又可行的科学想法。一个原因是缺乏将科学假设生成（SHG）作为自然语言生成（NLG）任务的专用数据集。在本文中，我们引入了HypoGen，这是第一个包含约5500个结构化问题-假设对的数据集，这些对是从顶级计算机科学会议中提取的，并使用Bit-Flip-Spark架构进行结构化，其中Bit是传统假设，Spark是关键洞察或概念飞跃，Flip是产生的反提案。HypoGen独特地集成了反映从Bit到Flip的智力过程的明确链式推理组件。我们表明，将假设生成作为条件语言建模，通过在Bit-Flip-Spark和链式推理（在推理时仅提供Bit）上进行微调，可以改善假设的总体质量。我们的评估采用自动指标和LLM评委排名进行总体质量评估。我们表明，通过在HypoGen数据集上微调，我们提高了生成假设的新颖性、可行性和总体质量。HypoGen数据集在huggingface.co/datasets/UniverseTBD/hypogen-dr1上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating novel and creative scientific hypotheses is a cornerstone inachieving Artificial General Intelligence. Large language and reasoning modelshave the potential to aid in the systematic creation, selection, and validationof scientifically informed hypotheses. However, current foundation models oftenstruggle to produce scientific ideas that are both novel and feasible. Onereason is the lack of a dedicated dataset that frames Scientific HypothesisGeneration (SHG) as a Natural Language Generation (NLG) task. In this paper, weintroduce HypoGen, the first dataset of approximately 5500 structuredproblem-hypothesis pairs extracted from top-tier computer science conferencesstructured with a Bit-Flip-Spark schema, where the Bit is the conventionalassumption, the Spark is the key insight or conceptual leap, and the Flip isthe resulting counterproposal. HypoGen uniquely integrates an explicitChain-of-Reasoning component that reflects the intellectual process from Bit toFlip. We demonstrate that framing hypothesis generation as conditional languagemodelling, with the model fine-tuned on Bit-Flip-Spark and theChain-of-Reasoning (and where, at inference, we only provide the Bit), leads toimprovements in the overall quality of the hypotheses. Our evaluation employsautomated metrics and LLM judge rankings for overall quality assessment. Weshow that by fine-tuning on our HypoGen dataset we improve the novelty,feasibility, and overall quality of the generated hypotheses. The HypoGendataset is publicly available athuggingface.co/datasets/UniverseTBD/hypogen-dr1.</description>
      <author>example@mail.com (Charles O'Neill, Tirthankar Ghosal, Roberta Răileanu, Mike Walmsley, Thang Bui, Kevin Schawinski, Ioana Ciucă)</author>
      <guid isPermaLink="false">2504.12976v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency</title>
      <link>http://arxiv.org/abs/2504.12080v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  V1 has been withdrawn due to a template issue, because of the arXiv  policy, we can't delete it. Please refer to the newest version v2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DC-SAM的方法，用于图像和视频的情境分割，通过prompt-tuning技术改进了Segment Anything Models（SAM）和SAM2。&lt;h4&gt;背景&lt;/h4&gt;情境分割在视觉任务中具有重要意义，而现有的Segment Anything Models在交互式分割方面表现优异，但无法直接应用于情境分割。&lt;h4&gt;目的&lt;/h4&gt;旨在提高情境分割模型的泛化能力，并应用于图像和视频分割任务。&lt;h4&gt;方法&lt;/h4&gt;DC-SAM通过提供高质量视觉提示来增强SAM的prompt encoder特征，融合SAM特征以更好地对齐prompt encoder，并设计了一个循环一致的交叉注意力机制。此外，采用双重分支设计，并设计了一个简单的mask-tube训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;DC-SAM在图像分割任务中取得了良好的性能，并在视频分割领域进行了扩展，通过构建第一个视频分割基准IC-VOS来评估模型在情境分割方面的能力。&lt;h4&gt;结论&lt;/h4&gt;DC-SAM在多个基准数据集上实现了优异的性能，证明其在情境分割领域的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于提示调整的双一致性SAM（DC-SAM）方法，用于图像和视频的情境分割。该方法通过提供高质量的视觉提示来增强SAM的提示编码器特征，融合SAM特征以更好地对齐提示编码器，并设计了一个循环一致的交叉注意力机制。此外，采用了双重分支设计，并设计了一个简单的mask-tube训练策略。虽然DC-SAM最初是为图像设计的，但通过SAM2的支持，可以无缝地扩展到视频领域。由于视频领域中缺乏情境分割，我们手动构建了第一个基准，名为情境视频对象分割（IC-VOS），以更好地评估模型的情境分割能力。大量实验表明，该方法在COCO-20i上实现了55.5（+1.4）mIoU，在PASCAL-5i上实现了73.0（+1.1）mIoU，在提出的IC-VOS基准上实现了71.52的J&amp;F分数。源代码和基准可在https://github.com/zaplm/DC-SAM上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a single labeled example, in-context segmentation aims to segmentcorresponding objects. This setting, known as one-shot segmentation in few-shotlearning, explores the segmentation model's generalization ability and has beenapplied to various vision tasks, including scene understanding and image/videoediting. While recent Segment Anything Models have achieved state-of-the-artresults in interactive segmentation, these approaches are not directlyapplicable to in-context segmentation. In this work, we propose the DualConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2for in-context segmentation of both images and videos. Our key insights are toenhance the features of the SAM's prompt encoder in segmentation by providinghigh-quality visual prompts. When generating a mask prior, we fuse the SAMfeatures to better align the prompt encoder. Then, we design a cycle-consistentcross-attention on fused features and initial visual prompts. Next, adual-branch design is provided by using the discriminative positive andnegative prompts in the prompt encoder. Furthermore, we design a simplemask-tube training strategy to adopt our proposed dual consistency method intothe mask tube. Although the proposed DC-SAM is primarily designed for images,it can be seamlessly extended to the video domain with the support of SAM2.Given the absence of in-context segmentation in the video domain, we manuallycurate and construct the first benchmark from existing video segmentationdatasets, named In-Context Video Object Segmentation (IC-VOS), to better assessthe in-context capability of the model. Extensive experiments demonstrate thatour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU onPASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Oursource code and benchmark are available at https://github.com/zaplm/DC-SAM.</description>
      <author>example@mail.com (Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.12080v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</title>
      <link>http://arxiv.org/abs/2504.11536v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  fix typos&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReTool的推理模型，旨在通过工具集成学习来增强长文本推理能力，解决强化学习模型在几何推理、简洁计算和复杂方程求解等需要结构化问题解决场景中的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管使用强化学习训练的推理模型在文本推理方面表现优秀，但在需要结构化问题解决的场景中（如几何推理、简洁计算或复杂方程求解）存在困难，这些场景中计算工具（如代码解释器）显示出独特的优势。&lt;h4&gt;目的&lt;/h4&gt;提出ReTool模型，以解决上述问题，并通过工具集成学习来增强长文本推理。&lt;h4&gt;方法&lt;/h4&gt;ReTool模型包括两个关键特性：（1）在自然语言推理过程中动态交织实时代码执行；（2）一个自动化的强化学习范式，允许多轮实时代码执行的政策部署，并通过结果反馈来指导模型学习何时以及如何调用工具。ReTool采用系统化的训练框架，从合成冷启动数据生成开始，生成代码增强的长文本推理轨迹以微调基础模型。后续的强化学习训练利用任务结果作为奖励，迭代地细化模型的工具使用策略，使模型能够自主发现最优的工具调用模式。&lt;h4&gt;主要发现&lt;/h4&gt;在MATH Olympiad基准AIME上的实验表明，ReTool优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，超过OpenAI的o1-preview 27.9%。进一步的分析揭示了代码自我校正等涌现行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。&lt;h4&gt;结论&lt;/h4&gt;ReTool展示了结果驱动工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While reasoning models (e.g., DeepSeek R1) trained with reinforcementlearning (RL), excel in textual reasoning, they struggle in scenarios requiringstructured problem-solving, such as geometric reasoning, concise computation,or complex equation solving-areas where computational tools like codeinterpreters (CI) demonstrate distinct advantages. To bridge this gap, wepropose ReTool, which enhances long-form reasoning with tool-integratedlearning, including two key features: (1) dynamic interleaving of real-timecode execution within natural language reasoning processes, and (2) anautomated RL paradigm that allows policy rollouts with multi-turn real-timecode execution and teaches the model in learning when and how to invoke toolsbased on outcome feedback. ReTool employs a systematic training framework,beginning with synthetic cold-start data generation to produce code-augmentedlong-form reasoning traces for fine-tuning base models. Subsequent RL trainingleverages task outcomes as rewards to iteratively refine the model's tool usestrategy, enabling autonomous discovery of optimal tool invocation patternswithout human priors. Experiments on the challenging MATH Olympiad benchmarkAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with400 training steps, outperforming text-based RL baseline (40% accuracy, 1080steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Furtheranalysis reveals emergent behaviors such as code self-correction, signaling an''aha moment'' in which the model autonomously masters adaptive tool use. Thesefindings highlight the promise of outcome-driven tool integration for advancingcomplex mathematical reasoning and offer new insights into hybridneuro-symbolic systems.</description>
      <author>example@mail.com (Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong)</author>
      <guid isPermaLink="false">2504.11536v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>3D Object Reconstruction with mmWave Radars</title>
      <link>http://arxiv.org/abs/2504.12348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RFconstruct的框架，该框架利用商用毫米波雷达实现自动驾驶场景下的3D形状重建。&lt;h4&gt;背景&lt;/h4&gt;该框架解决了雷达在低角分辨率、反光和稀疏点云等方面的局限性。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一个能够准确重建物体3D形状的系统，用于自动驾驶场景。&lt;h4&gt;方法&lt;/h4&gt;RFconstruct通过融合两个雷达设备捕获的数据，这些设备能够成像正交平面，然后执行里程计感知的时间融合以生成更密集的3D点云。接着，使用一个定制的编码器-解码器模型来重建物体的3D形状，该模型不需要物体边界框的先验知识。&lt;h4&gt;主要发现&lt;/h4&gt;RFconstruct的性能与配备激光雷达的深度相机提取的3D模型进行了比较，结果显示RFconstruct可以准确生成汽车、自行车和行人的3D形状。&lt;h4&gt;结论&lt;/h4&gt;RFconstruct能够有效地克服雷达的局限性，并在自动驾驶场景中实现高精度的3D形状重建。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为RFconstruct的框架，该框架利用商用毫米波雷达实现自动驾驶场景下的3D形状重建。RFconstruct通过融合两个雷达设备捕获的数据，这些设备能够成像正交平面，然后执行里程计感知的时间融合以生成更密集的3D点云。接着，使用一个定制的编码器-解码器模型来重建物体的3D形状，该模型不需要物体边界框的先验知识。RFconstruct的性能与配备激光雷达的深度相机提取的3D模型进行了比较，结果显示RFconstruct可以准确生成汽车、自行车和行人的3D形状。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents RFconstruct, a framework that enables 3D shapereconstruction using commercial off-the-shelf (COTS) mmWave radars forself-driving scenarios. RFconstruct overcomes radar limitations of low angularresolution, specularity, and sparsity in radar point clouds through a holisticsystem design that addresses hardware, data processing, and machine learningchallenges. The first step is fusing data captured by two radar devices thatimage orthogonal planes, then performing odometry-aware temporal fusion togenerate denser 3D point clouds. RFconstruct then reconstructs 3D shapes ofobjects using a customized encoder-decoder model that does not require priorknowledge of the object's bound box. The shape reconstruction performance ofRFconstruct is compared against 3D models extracted from a depth cameraequipped with a LiDAR. We show that RFconstruct can accurately generate 3Dshapes of cars, bikes, and pedestrians.</description>
      <author>example@mail.com (Samah Hussein, Junfeng Guan, Swathi Narashiman, Saurabh Gupta, Haitham Hassanieh)</author>
      <guid isPermaLink="false">2504.12348v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Stronger, Steadier &amp; Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2504.12753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将深度信息与视觉基金模型（VFMs）特征结合，以提高图像中的几何一致性和VFMs的泛化性能。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉基金模型在领域通用语义分割（DGSS）中表现出色，但最近的方法往往忽略了视觉线索的脆弱性和底层几何的稳定性，这使得深度信息更加鲁棒。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为DepthForge的新型微调DGSS框架，旨在通过整合深度信息和视觉特征来提高几何一致性和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;DepthForge框架整合了冻结的DINOv2或EVA02的视觉线索和冻结的Depth Anything V2的深度线索。在每个VFMs层中，引入了深度感知可学习标记，以解耦领域不变的视觉和空间信息，并增强VFMs的深度感知和注意力。此外，开发了一种深度细化解码器，并将其集成到模型架构中，以自适应地细化多层的VFM特征和深度感知可学习标记。&lt;h4&gt;主要发现&lt;/h4&gt;在基于各种DGSS设置和五个不同数据集的广泛实验中，DepthForge方法在性能、视觉-空间注意力的稳定性和泛化能力方面显著优于其他方法。特别是在极端条件下（如夜晚和雪天），DepthForge表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;DepthForge是一种有效的DGSS框架，能够显著提高模型的性能和泛化能力，并且代码可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Foundation Models (VFMs) have delivered remarkable performance inDomain Generalized Semantic Segmentation (DGSS). However, recent methods oftenoverlook the fact that visual cues are susceptible, whereas the underlyinggeometry remains stable, rendering depth information more robust. In thispaper, we investigate the potential of integrating depth information withfeatures from VFMs, to improve the geometric consistency within an image andboost the generalization performance of VFMs. We propose a novel fine-tuningDGSS framework, named DepthForge, which integrates the visual cues from frozenDINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer ofthe VFMs, we incorporate depth-aware learnable tokens to continuously decoupledomain-invariant visual and spatial information, thereby enhancing depthawareness and attention of the VFMs. Finally, we develop a depth refinementdecoder and integrate it into the model architecture to adaptively refinemulti-layer VFM features and depth-aware learnable tokens. Extensiveexperiments are conducted based on various DGSS settings and five differentdatsets as unseen target domains. The qualitative and quantitative resultsdemonstrate that our method significantly outperforms alternative approacheswith stronger performance, steadier visual-spatial attention, and superiorgeneralization ability. In particular, DepthForge exhibits outstandingperformance under extreme conditions (e.g., night and snow). Code is availableat https://github.com/anonymouse-xzrptkvyqc/DepthForge.</description>
      <author>example@mail.com (Siyu Chen, Ting Han, Changshe Zhang, Xin Luo, Meiliu Wu, Guorong Cai, Jinhe Su)</author>
      <guid isPermaLink="false">2504.12753v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Post-pre-training for Modality Alignment in Vision-Language Foundation Models</title>
      <link>http://arxiv.org/abs/2504.12717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025; Code: https://github.com/yshinya6/clip-refine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CLIP-Refine是一种改进CLIP模型的前训练方法，旨在减少模态间隙，提升零样本性能。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP在下游任务上表现出色，但多模态特征空间存在模态间隙，限制了下游任务的表现。&lt;h4&gt;目的&lt;/h4&gt;CLIP-Refine旨在在不降低零样本性能的情况下，通过小规模图像-文本数据集在预训练和微调之间的一轮训练中对齐特征空间。&lt;h4&gt;方法&lt;/h4&gt;引入了两种技术：随机特征对齐（RaFA）和混合对比蒸馏（HyCD）。RaFA通过最小化到先验分布中随机参考向量的距离来对齐图像和文本特征。HyCD通过结合真实图像-文本对标签和预训练CLIP模型的输出生成混合软标签来更新模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLIP-Refine成功地减轻了模态间隙并提高了零样本性能。&lt;h4&gt;结论&lt;/h4&gt;CLIP-Refine是一个有效的方法，可以在不牺牲零样本性能的情况下减少模态间隙，提高下游任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive language image pre-training (CLIP) is an essential component ofbuilding modern vision-language foundation models. While CLIP demonstratesremarkable zero-shot performance on downstream tasks, the multi-modal featurespaces still suffer from a modality gap, which is a gap between image and textfeature clusters and limits downstream task performance. Although existingworks attempt to address the modality gap by modifying pre-training orfine-tuning, they struggle with heavy training costs with large datasets ordegradations of zero-shot performance. This paper presents CLIP-Refine, apost-pre-training method for CLIP models at a phase between pre-training andfine-tuning. CLIP-Refine aims to align the feature space with 1 epoch trainingon small image-text datasets without zero-shot performance degradations. Tothis end, we introduce two techniques: random feature alignment (RaFA) andhybrid contrastive-distillation (HyCD). RaFA aligns the image and text featuresto follow a shared prior distribution by minimizing the distance to randomreference vectors sampled from the prior. HyCD updates the model with hybridsoft labels generated by combining ground-truth image-text pair labels andoutputs from the pre-trained CLIP model. This contributes to achieving bothmaintaining the past knowledge and learning new knowledge to align features.Our extensive experiments with multiple classification and retrieval tasks showthat CLIP-Refine succeeds in mitigating the modality gap and improving thezero-shot performance.</description>
      <author>example@mail.com (Shin'ya Yamaguchi, Dewei Feng, Sekitoshi Kanai, Kazuki Adachi, Daiki Chijiwa)</author>
      <guid isPermaLink="false">2504.12717v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image</title>
      <link>http://arxiv.org/abs/2504.11230v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025 (Highlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在机器人操作任务中关节物体的类别级姿态估计，并引入了一个新的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;现有方法在类别级别估计部件姿态和大小时，通常依赖于几何线索和复杂的分阶段流程，首先从点云中分割部件，然后进行标准化部件坐标空间（NPCS）的6D姿态估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一个单阶段网络CAP-Net，用于估计类别关节部件的6D姿态和尺寸。&lt;h4&gt;方法&lt;/h4&gt;CAP-Net结合RGB-D特征以端到端方式生成实例分割和NPCS表示。该网络使用统一网络同时预测点级类别标签、质心偏移和NPCS图。然后，通过基于估计的质心距离对同一预测类别的点进行聚类，以隔离每个部件。最后，将每个部件的NPCS区域与点云对齐以恢复其最终姿态和尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，该方法在RGBD-Art数据集上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;模型在机器人任务中的实际部署强调了其鲁棒性和出色的仿真到现实迁移能力，证实了其实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文针对机器人操作任务中关节物体的类别级姿态估计问题，引入了一个新的基准数据集。虽然近期方法在类别级别估计部件姿态和大小时，往往依赖于几何线索和复杂的分阶段流程，首先从点云中分割部件，然后进行标准化部件坐标空间（NPCS）的6D姿态估计。这些方法忽略了来自RGB图像的密集语义线索，导致精度不佳，尤其是对于部件较小的物体。为了解决这些局限性，我们提出了一种单阶段网络CAP-Net，用于估计类别关节部件的6D姿态和尺寸。该方法结合RGB-D特征以端到端方式生成实例分割和NPCS表示。CAP-Net使用统一网络同时预测点级类别标签、质心偏移和NPCS图。然后，通过基于估计的质心距离对同一预测类别的点进行聚类，以隔离每个部件。最后，将每个部件的NPCS区域与点云对齐以恢复其最终姿态和尺寸。为了缩小仿真与现实之间的差距，我们引入了RGBD-Art数据集，这是迄今为止最大的RGB-D关节数据集，具有逼真的RGB图像和从真实传感器模拟的深度噪声。在RGBD-Art数据集上的实验评估表明，我们的方法在性能上显著优于现有方法。我们模型在机器人任务中的实际部署强调了其鲁棒性和出色的仿真到现实迁移能力，证实了其实际应用价值。我们的数据集、代码和预训练模型可在项目页面上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles category-level pose estimation of articulated objects inrobotic manipulation tasks and introduces a new benchmark dataset. While recentmethods estimate part poses and sizes at the category level, they often rely ongeometric cues and complex multi-stage pipelines that first segment parts fromthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimationfor 6D poses. These approaches overlook dense semantic cues from RGB images,leading to suboptimal accuracy, particularly for objects with small parts. Toaddress these limitations, we propose a single-stage Network, CAP-Net, forestimating the 6D poses and sizes of Categorical Articulated Parts. This methodcombines RGB-D features to generate instance segmentation and NPCSrepresentations for each part in an end-to-end manner. CAP-Net uses a unifiednetwork to simultaneously predict point-wise class labels, centroid offsets,and NPCS maps. A clustering algorithm then groups points of the same predictedclass based on their estimated centroid distances to isolate each part.Finally, the NPCS region of each part is aligned with the point cloud torecover its final pose and size. To bridge the sim-to-real domain gap, weintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,featuring photorealistic RGB images and depth noise simulated from realsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that ourmethod significantly outperforms the state-of-the-art approach. Real-worlddeployments of our model in robotic tasks underscore its robustness andexceptional sim-to-real transfer capabilities, confirming its substantialpractical utility. Our dataset, code and pre-trained models are available onthe project page.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Xiangyang Xue, Yi Zhu)</author>
      <guid isPermaLink="false">2504.11230v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>TransST: Transfer Learning Embedded Spatial Factor Modeling of Spatial Transcriptomics Data</title>
      <link>http://arxiv.org/abs/2504.12353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为TransST的新型迁移学习框架，用于从目标空间转录组数据中推断细胞异质性，有效识别细胞亚群和相应的驱动生物标志物。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学是生物医学研究中的重要工具，但由于技术限制，如分辨率较低和测序深度不足，难以从数据中可靠地提取真实生物学信号。&lt;h4&gt;目的&lt;/h4&gt;提出TransST框架，以解决现有空间转录组学技术的局限性，提高从数据中提取真实生物学信号的能力。&lt;h4&gt;方法&lt;/h4&gt;通过迁移学习框架，自适应地利用外部来源的细胞标记信息，推断目标空间转录组数据的细胞级异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在多个实际研究和模拟设置中的应用表明，TransST方法显著提高了现有技术。例如，在乳腺癌研究中，TransST成功识别了五个具有生物学意义的细胞簇，包括原位癌和侵袭性癌的亚组，并且是唯一能够从所有研究方法中区分脂肪组织和结缔组织的方法。&lt;h4&gt;结论&lt;/h4&gt;TransST方法在识别空间转录组数据中的细胞亚群和检测相应的驱动生物标志物方面既有效又稳健。&lt;h4&gt;翻译&lt;/h4&gt;Background: Spatial transcriptomics have emerged as a powerful tool inbiomedical research because of its ability to capture both the spatial contextsand abundance of the complete RNA transcript profile in organs of interest.However, limitations of the technology such as the relatively low resolutionand comparatively insufficient sequencing depth make it difficult to reliablyextract real biological signals from these data. To alleviate this challenge,we propose a novel transfer learning framework, referred to as TransST, toadaptively leverage the cell-labeled information from external sources ininferring cell-level heterogeneity of a target spatial transcriptomics data.  Results: Applications in several real studies as well as a number ofsimulation settings show that our approach significantly improves existingtechniques. For example, in the breast cancer study, TransST successfullyidentifies five biologically meaningful cell clusters, including the two subgroups of cancer in situ and invasive cancer; in addition, only TransST is able to separate the adipose tissues from the connective issues among all thestudied methods.  Conclusions: In summary, the proposed method TransST is both effective androbust in identifying cell subclusters and detecting corresponding drivingbiomarkers in spatial transcriptomics data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background: Spatial transcriptomics have emerged as a powerful tool inbiomedical research because of its ability to capture both the spatial contextsand abundance of the complete RNA transcript profile in organs of interest.However, limitations of the technology such as the relatively low resolutionand comparatively insufficient sequencing depth make it difficult to reliablyextract real biological signals from these data. To alleviate this challenge,we propose a novel transfer learning framework, referred to as TransST, toadaptively leverage the cell-labeled information from external sources ininferring cell-level heterogeneity of a target spatial transcriptomics data.  Results: Applications in several real studies as well as a number ofsimulation settings show that our approach significantly improves existingtechniques. For example, in the breast cancer study, TransST successfullyidentifies five biologically meaningful cell clusters, including the twosubgroups of cancer in situ and invasive cancer; in addition, only TransST isable to separate the adipose tissues from the connective issues among all thestudied methods.  Conclusions: In summary, the proposed method TransST is both effective androbust in identifying cell subclusters and detecting corresponding drivingbiomarkers in spatial transcriptomics data.</description>
      <author>example@mail.com (Shuo Shuo Liu, Shikun Wang, Yuxuan Chen, Anil K. Rustgi, Ming Yuan, Jianhua Hu)</author>
      <guid isPermaLink="false">2504.12353v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2504.12680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Embodied-R，一个结合大规模视觉语言模型（VLMs）和少量语言模型（LMs）的协同框架，用于感知和推理。通过强化学习和新颖的奖励系统，该模型在有限的计算资源下实现了慢思考能力，并在多项任务中达到或超过了最先进的模型。&lt;h4&gt;背景&lt;/h4&gt;人类能通过连续视觉观察，如自视角视频流，感知和推理空间关系。然而，预训练模型如何获得这种能力，特别是高级推理能力，尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型如何获得空间关系感知和高级推理能力，并开发一个能够在有限计算资源下实现慢思考能力的模型。&lt;h4&gt;方法&lt;/h4&gt;Embodied-R框架结合了大规模视觉语言模型（VLMs）进行感知和少量语言模型（LMs）进行推理。使用强化学习（RL）和考虑思考-回答逻辑一致性的新颖奖励系统来训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;在仅使用5k个具身视频样本进行训练后，Embodied-R（含3B LM）在分布内和分布外的具身空间推理任务上均达到了最先进的模型水平。Embodied-R还展现出诸如系统分析和情境整合等自发生成的思维模式。&lt;h4&gt;结论&lt;/h4&gt;Embodied-R框架为理解和实现高级推理能力提供了一种新的方法，并通过实验证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Humans can perceive and reason about spatial relationships from sequential visual observations, such as egocentric video streams. However, how pretrained models acquire such abilities, especially high-level reasoning, remains unclear. This paper introduces Embodied-R, a collaborative framework combining large-scale Vision-Language Models (VLMs) for perception and small-scale Language Models (LMs) for reasoning. Using Reinforcement Learning (RL) with an novel reward system considering think-answer logical consistency, the model achieves slow-thinking capabilities with limited computational resources. After training on only 5k embodied video samples, Embodied-R with a 3B LM matches state-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on both in-distribution and out-of-distribution embodied spatial reasoning tasks. Embodied-R also exhibits emergent thinking patterns such as systematic analysis and contextual integration. We further explore research questions including response length, training on VLM, strategies for reward design, and differences in model generalization after SFT (Supervised Fine-Tuning) and RL training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can perceive and reason about spatial relationships from sequentialvisual observations, such as egocentric video streams. However, how pretrainedmodels acquire such abilities, especially high-level reasoning, remainsunclear. This paper introduces Embodied-R, a collaborative framework combininglarge-scale Vision-Language Models (VLMs) for perception and small-scaleLanguage Models (LMs) for reasoning. Using Reinforcement Learning (RL) with anovel reward system considering think-answer logical consistency, the modelachieves slow-thinking capabilities with limited computational resources. Aftertraining on only 5k embodied video samples, Embodied-R with a 3B LM matchesstate-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) onboth in-distribution and out-of-distribution embodied spatial reasoning tasks.Embodied-R also exhibits emergent thinking patterns such as systematic analysisand contextual integration. We further explore research questions includingresponse length, training on VLM, strategies for reward design, and differencesin model generalization after SFT (Supervised Fine-Tuning) and RL training.</description>
      <author>example@mail.com (Baining Zhao, Ziyou Wang, Jianjie Fang, Chen Gao, Fanhang Man, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li, Wenwu Zhu)</author>
      <guid isPermaLink="false">2504.12680v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SAM-Based Building Change Detection with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping</title>
      <link>http://arxiv.org/abs/2504.12619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于SegmentAnything Model (SAM)的建筑物变化检测网络FAEWNet，用于解决建筑物变化检测中的挑战。&lt;h4&gt;背景&lt;/h4&gt;建筑物变化检测在城市发展、灾害评估和军事侦察中具有挑战性，现有的基于适配器的微调方法在建筑物分布不平衡、细微变化检测和边缘提取方面存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的网络FAEWNet，以解决建筑物变化检测中的挑战，包括领域差距、不平衡的建筑物分布、双时相不匹配和噪声干扰。&lt;h4&gt;方法&lt;/h4&gt;FAEWNet利用SAM编码器从遥感图像中提取丰富视觉特征，并引入分布感知傅里叶聚合适配器来关注特定地面物体，同时设计了一个新的流模块来优化建筑物边缘提取和变化建筑物的感知。&lt;h4&gt;主要发现&lt;/h4&gt;FAEWNet在LEVIR-CD、S2Looking和WHU-CD数据集上取得了最先进的检测结果。&lt;h4&gt;结论&lt;/h4&gt;FAEWNet能够有效解决建筑物变化检测中的挑战，并通过提高检测精度和边缘识别能力来提升变化检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;Building change detection remains challenging for urban development, disaster assessment, and military reconnaissance. While foundation models like SegmentAnything Model (SAM) show strong segmentation capabilities, SAM is limited in the task of building change detection due to domain gap issues. Existing adapter-based fine-tuning approaches face challenges with imbalanced building distribution, resulting in poor detection of subtle changes and inaccurate edge extraction. Additionally, bi-temporal misalignment in change detection, typically addressed by optical flow, remains vulnerable to background noises. This affects the detection of building changes and compromises both detection accuracy and edge recognition. To tackle these challenges, we propose a new SAM-Based Network with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping (FAEWNet) for building change detection. FAEWNet utilizes the SAM encoder to extract rich visual features from remote sensing images. To guide SAM in focusing on specific ground objects in remote sensing scenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate task-oriented changed information. This adapter not only effectively addresses the domain gap issue, but also pays attention to the distribution of changed buildings. Furthermore, to mitigate noise interference and misalignment in height offset estimation, we design a novel flow module that refines building edge extraction and enhances the perception of changed buildings. Our state-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets highlight the effectiveness of FAEWNet. The code is available at https://github.com/SUPERMAN123000/FAEWNet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building change detection remains challenging for urban development, disasterassessment, and military reconnaissance. While foundation models like SegmentAnything Model (SAM) show strong segmentation capabilities, SAM is limited inthe task of building change detection due to domain gap issues. Existingadapter-based fine-tuning approaches face challenges with imbalanced buildingdistribution, resulting in poor detection of subtle changes and inaccurate edgeextraction. Additionally, bi-temporal misalignment in change detection,typically addressed by optical flow, remains vulnerable to background noises.This affects the detection of building changes and compromises both detectionaccuracy and edge recognition. To tackle these challenges, we propose a newSAM-Based Network with Distribution-Aware Fourier Adaptation andEdge-Constrained Warping (FAEWNet) for building change detection. FAEWNetutilizes the SAM encoder to extract rich visual features from remote sensingimages. To guide SAM in focusing on specific ground objects in remote sensingscenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregatetask-oriented changed information. This adapter not only effectively addressesthe domain gap issue, but also pays attention to the distribution of changedbuildings. Furthermore, to mitigate noise interference and misalignment inheight offset estimation, we design a novel flow module that refines buildingedge extraction and enhances the perception of changed buildings. Ourstate-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasetshighlight the effectiveness of FAEWNet. The code is available athttps://github.com/SUPERMAN123000/FAEWNet.</description>
      <author>example@mail.com (Yun-Cheng Li, Sen Lei, Yi-Tao Zhao, Heng-Chao Li, Jun Li, Antonio Plaza)</author>
      <guid isPermaLink="false">2504.12619v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Temporal Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10925v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上的时序链接预测问题，并提出了一种新的迁移学习方法，以增强记忆密集型模型的迁移效果。&lt;h4&gt;背景&lt;/h4&gt;链接预测在推荐系统和药物发现等领域有广泛应用。时序链接预测（TLP）是指在动态图上预测未来的链接，其复杂性在于图的动态性质。&lt;h4&gt;目的&lt;/h4&gt;开发迁移有效的时序链接预测方法，特别是针对记忆密集型模型。&lt;h4&gt;方法&lt;/h4&gt;本文受结构信号对时序链接预测任务信息量的启发，将结构映射模块添加到现有的TLP模型架构中，该模块学习从图结构（拓扑）特征到记忆嵌入的映射。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法为时序链接预测提供了一种无需记忆的模型基础。&lt;h4&gt;结论&lt;/h4&gt;本研究为时序链接预测的迁移学习提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/google-research/google-research/tree/master/fm4tlp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction on graphs has applications spanning from recommender systemsto drug discovery. Temporal link prediction (TLP) refers to predicting futurelinks in a temporally evolving graph and adds additional complexity related tothe dynamic nature of graphs. State-of-the-art TLP models incorporate memorymodules alongside graph neural networks to learn both the temporal mechanismsof incoming nodes and the evolving graph topology. However, memory modules onlystore information about nodes seen at train time, and hence such models cannotbe directly transferred to entirely new graphs at test time and deployment. Inthis work, we study a new transfer learning task for temporal link prediction,and develop transfer-effective methods for memory-laden models. Specifically,motivated by work showing the informativeness of structural signals for the TLPtask, we augment a structural mapping module to the existing TLP modelarchitectures, which learns a mapping from graph structural (topological)features to memory embeddings. Our work paves the way for a memory-freefoundation model for TLP.</description>
      <author>example@mail.com (Ayan Chatterjee, Barbara Ikica, Babak Ravandi, John Palowitch)</author>
      <guid isPermaLink="false">2504.10925v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving Operating Room Workflow Analysis using Digital Twins</title>
      <link>http://arxiv.org/abs/2504.12552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种保护隐私的手术室视频分析和事件检测的两阶段流程。&lt;h4&gt;背景&lt;/h4&gt;手术室是一个复杂的场所，优化工作流程对于降低成本和提高患者结果至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究利用计算机视觉方法自动识别围手术期事件，以识别手术室优化的瓶颈。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段的隐私保护手术室视频分析和事件检测流程。第一阶段利用视觉基础模型进行深度估计和语义分割，从常规RGB视频中生成去识别的数字孪生（DT）。第二阶段采用SafeOR模型，这是一种融合了两流处理分割掩码和深度图的手术室事件检测方法。&lt;h4&gt;主要发现&lt;/h4&gt;基于DT的手术室事件检测模型在检测手术室事件方面表现出与原始RGB视频模型相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;数字孪生（DT）可以实现对手术室工作流程的隐私保护分析，促进去识别数据在不同机构之间的共享，并可能通过减轻特定领域的外观差异来提高模型的可泛化性。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Purpose: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. The use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for OR optimization. However, privacy concerns limit the use of computer vision for automated event detection from OR videos, which makes privacy-preserving approaches needed for OR workflow analysis. Methods: We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. In the first stage, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. In the second stage, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. We evaluate this method on an internal dataset of 38 simulated surgical trials with five event classes. Results: Our results indicate that this DT-based approach to the OR event detection model achieves performance on par and sometimes even better than raw RGB video-based models on detecting OR events. Conclusion: DTs enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and they can potentially enhance model generalizability by mitigating domain-specific appearance differences.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: The operating room (OR) is a complex environment where optimizingworkflows is critical to reduce costs and improve patient outcomes. The use ofcomputer vision approaches for the automatic recognition of perioperativeevents enables identification of bottlenecks for OR optimization. However,privacy concerns limit the use of computer vision for automated event detectionfrom OR videos, which makes privacy-preserving approaches needed for ORworkflow analysis. Methods: We propose a two-stage pipeline forprivacy-preserving OR video analysis and event detection. In the first stage,we leverage vision foundation models for depth estimation and semanticsegmentation to generate de-identified Digital Twins (DT) of the OR fromconventional RGB videos. In the second stage, we employ the SafeOR model, afused two-stream approach that processes segmentation masks and depth maps forOR event detection. We evaluate this method on an internal dataset of 38simulated surgical trials with five event classes. Results: Our resultsindicate that this DT-based approach to the OR event detection model achievesperformance on par and sometimes even better than raw RGB video-based models ondetecting OR events. Conclusion: DTs enable privacy-preserving OR workflowanalysis, facilitating the sharing of de-identified data across institutionsand they can potentially enhance model generalizability by mitigatingdomain-specific appearance differences.</description>
      <author>example@mail.com (Alejandra Perez, Han Zhang, Yu-Chun Ku, Lalithkumar Seenivasan, Roger Soberanis, Jose L. Porras, Richard Day, Jeff Jopling, Peter Najjar, Mathias Unberath)</author>
      <guid isPermaLink="false">2504.12552v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>You Don't Need All Attentions: Distributed Dynamic Fine-Tuning for Foundation Models</title>
      <link>http://arxiv.org/abs/2504.12471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为D2FT的新型分布式动态微调框架，旨在降低基础模型微调的计算成本和通信成本。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型规模的增加，在有限内存带宽的商业设备上进行微调面临挑战。&lt;h4&gt;目的&lt;/h4&gt;减少基础模型微调的计算工作量和通信成本。&lt;h4&gt;方法&lt;/h4&gt;D2FT通过观察并非所有注意力模块在微调过程中都是必要的，基于此，采用三种创新的选择策略，并利用多背包优化来优化这些策略，以实现计算工作量的平衡。&lt;h4&gt;主要发现&lt;/h4&gt;D2FT在CIFAR-10、CIFAR-100和Stanford Cars数据集上，将训练计算成本降低了40%，通信成本降低了50%，同时只降低了1%到2%的准确率。&lt;h4&gt;结论&lt;/h4&gt;D2FT框架在降低计算成本和通信成本的同时，保持了较高的准确率，并且可以扩展到LoRA等先进的参数高效微调技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning plays a crucial role in adapting models to downstream tasks withminimal training efforts. However, the rapidly increasing size of foundationmodels poses a daunting challenge for accommodating foundation modelfine-tuning in most commercial devices, which often have limited memorybandwidth. Techniques like model sharding and tensor parallelism address thisissue by distributing computation across multiple devices to meet memoryrequirements. Nevertheless, these methods do not fully leverage theirfoundation nature in facilitating the fine-tuning process, resulting in highcomputational costs and imbalanced workloads. We introduce a novel DistributedDynamic Fine-Tuning (D2FT) framework that strategically orchestrates operationsacross attention modules based on our observation that not all attentionmodules are necessary for forward and backward propagation in fine-tuningfoundation models. Through three innovative selection strategies, D2FTsignificantly reduces the computational workload required for fine-tuningfoundation models. Furthermore, D2FT addresses workload imbalances indistributed computing environments by optimizing these selection strategies viamultiple knapsack optimization. Our experimental results demonstrate that theproposed D2FT framework reduces the training computational costs by 40% andtraining communication costs by 50% with only 1% to 2% accuracy drops on theCIFAR-10, CIFAR-100, and Stanford Cars datasets. Moreover, the results showthat D2FT can be effectively extended to recent LoRA, a state-of-the-artparameter-efficient fine-tuning technique. By reducing 40% computational costor 50% communication cost, D2FT LoRA top-1 accuracy only drops 4% to 6% onStanford Cars dataset.</description>
      <author>example@mail.com (Shiwei Ding, Lan Zhang, Zhenlin Wang, Giuseppe Ateniese, Xiaoyong Yuan)</author>
      <guid isPermaLink="false">2504.12471v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Activated LoRA: Fine-tuned LLMs for Intrinsics</title>
      <link>http://arxiv.org/abs/2504.12397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2504.11704&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Activated LoRA（aLoRA）的框架，用于提高多轮对话中LoRA的效率，通过仅在aLoRA被调用后调整序列中的权重，从而避免重新计算整个轮次的KV缓存。&lt;h4&gt;背景&lt;/h4&gt;LoRA是一种高效的基础模型权重微调框架，但多轮对话中频繁切换LoRA效率低下，因为需要重新计算整个轮次的KV缓存。&lt;h4&gt;目的&lt;/h4&gt;提出aLoRA以提高多轮对话中LoRA的效率，避免重新计算KV缓存。&lt;h4&gt;方法&lt;/h4&gt;修改LoRA框架，使其仅在aLoRA被调用后调整序列中的权重，接受基础模型的KV缓存，实现即时激活。&lt;h4&gt;主要发现&lt;/h4&gt;aLoRA可以显著提高多轮对话中LoRA的效率，同时保持与标准LoRA相当的准确率，并实现显著的推理效益。&lt;h4&gt;结论&lt;/h4&gt;aLoRA是一种有效的LoRA改进方法，可以显著提高多轮对话中LoRA的效率，并保持良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA)已经成为微调大型基础模型权重的高效框架，并成为数据驱动LLM定制的首选方法。尽管具有高度定制的行为和能力，但在多轮对话中切换相关的LoRA效率非常低，因为必须在生成开始之前使用LoRA权重重新计算整个轮次的键值（KV）缓存。为了解决这个问题，我们提出了Activated LoRA（aLoRA），它修改了LoRA框架，使其仅在aLoRA被调用后调整序列中的权重。这种改变关键地允许aLoRA接受基础模型的输入字符串的KV缓存，这意味着aLoRA可以在需要时立即在链中激活，而无需重新计算缓存。这使得构建所谓的“内建”模型成为可能，即用于对输入链或对话的一部分执行定义明确的操作的非常专业的模型。我们使用aLoRA训练了一组内建模型，证明了与标准LoRA相当的准确率，同时实现了显著的推理效益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework forfinetuning the weights of large foundation models, and has become the go-tomethod for data-driven customization of LLMs. Despite the promise of highlycustomized behaviors and capabilities, switching between relevant LoRAs in amultiturn setting is highly inefficient, as the key-value (KV) cache of theentire turn history must be recomputed with the LoRA weights before generationcan begin. To address this problem, we propose Activated LoRA (aLoRA), whichmodifies the LoRA framework to only adapt weights for the tokens in thesequence \emph{after} the aLoRA is invoked. This change crucially allows aLoRAto accept the base model's KV cache of the input string, meaning that aLoRA canbe instantly activated whenever needed in a chain without recomputing thecache. This enables building what we call \emph{intrinsics}, i.e. highlyspecialized models invoked to perform well-defined operations on portions of aninput chain or conversation that otherwise uses the base model by default. Weuse aLoRA to train a set of intrinsics models, demonstrating competitiveaccuracy with standard LoRA while achieving significant inference benefits.</description>
      <author>example@mail.com (Kristjan Greenewald, Luis Lastras, Thomas Parnell, Vraj Shah, Lucian Popa, Giulio Zizzo, Chulaka Gunasekara, Ambrish Rawat, David Cox)</author>
      <guid isPermaLink="false">2504.12397v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Causal integration of chemical structures improves representations of microscopy images for morphological profiling</title>
      <link>http://arxiv.org/abs/2504.09544v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文介绍了MICON（分子-图像对比学习）这一表示学习框架，用于在自监督深度学习中提高对高通量显微镜屏幕中细胞形态变化的量化能力，并探讨了将化学化合物结构信息纳入学习过程的有效性。&lt;h4&gt;背景&lt;/h4&gt;目前大多数高通量显微镜屏幕的方法仅从图像中学习，而忽略了这些屏幕的多模态特性，即既涉及化学或基因扰动，也涉及基于图像的读数。&lt;h4&gt;目的&lt;/h4&gt;提出通过在自监督预训练中整合化学化合物结构信息，来改善高通量显微镜屏幕中图像学习表示的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了MICON框架，将化学化合物视为诱导细胞表型反事实变换的治疗手段，并在具有挑战性的评估环境中进行测试，该环境要求模型能够识别药物在独立复制品和数据生成中心之间的可重复效果。&lt;h4&gt;主要发现&lt;/h4&gt;MICON在识别药物效果方面显著优于CellProfiler等经典手工特征和现有的基于深度学习的表示学习方法。将化合物信息纳入学习过程提高了评估设置中的性能，并且将化合物作为治疗手段在因果框架中进行建模优于直接在单一表示空间中对齐图像和化合物的方法。&lt;h4&gt;结论&lt;/h4&gt;该研究为形态分析中的表示学习开辟了新的方向，表明方法应明确考虑显微镜筛选数据的多模态特性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in self-supervised deep learning have improved our ability to quantify cellular morphological changes in high-throughput microscopy screens, a process known as morphological profiling. However, most current methods only learn from images, despite many screens being inherently multimodal, as they involve both a chemical or genetic perturbation as well as an image-based readout. We hypothesized that incorporating chemical compound structure during self-supervised pre-training could improve learned representations of images in high-throughput microscopy screens. We introduce a representation learning framework, MICON (Molecular-Image Contrastive Learning), that models chemical compounds as treatments that induce counterfactual transformations of cell phenotypes. MICON significantly outperforms classical hand-crafted features such as CellProfiler and existing deep-learning-based representation learning methods in challenging evaluation settings where models must identify reproducible effects of drugs across independent replicates and data-generating centers. We demonstrate that incorporating chemical compound information into the learning process provides consistent improvements in our evaluation setting and that modeling compounds specifically as treatments in a causal framework outperforms approaches that directly align images and compounds in a single representation space. Our findings point to a new direction for representation learning in morphological profiling, suggesting that methods should explicitly account for the multimodal nature of microscopy screening data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised deep learning have improved our ability toquantify cellular morphological changes in high-throughput microscopy screens,a process known as morphological profiling. However, most current methods onlylearn from images, despite many screens being inherently multimodal, as theyinvolve both a chemical or genetic perturbation as well as an image-basedreadout. We hypothesized that incorporating chemical compound structure duringself-supervised pre-training could improve learned representations of images inhigh-throughput microscopy screens. We introduce a representation learningframework, MICON (Molecular-Image Contrastive Learning), that models chemicalcompounds as treatments that induce counterfactual transformations of cellphenotypes. MICON significantly outperforms classical hand-crafted featuressuch as CellProfiler and existing deep-learning-based representation learningmethods in challenging evaluation settings where models must identifyreproducible effects of drugs across independent replicates and data-generatingcenters. We demonstrate that incorporating chemical compound information intothe learning process provides consistent improvements in our evaluation settingand that modeling compounds specifically as treatments in a causal frameworkoutperforms approaches that directly align images and compounds in a singlerepresentation space. Our findings point to a new direction for representationlearning in morphological profiling, suggesting that methods should explicitlyaccount for the multimodal nature of microscopy screening data.</description>
      <author>example@mail.com (Yemin Yu, Neil Tenenholtz, Lester Mackey, Ying Wei, David Alvarez-Melis, Ava P. Amini, Alex X. Lu)</author>
      <guid isPermaLink="false">2504.09544v2</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Regist3R: Incremental Registration with Stereo Foundation Model</title>
      <link>http://arxiv.org/abs/2504.12356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Regist3R的新型立体基础模型，用于高效和可扩展的增量重建，解决了多视角3D重建中的计算成本高和累积误差大等问题。&lt;h4&gt;背景&lt;/h4&gt;多视角3D重建在计算机视觉领域是一个重要且具有挑战性的问题，现有的方法在扩展到多视角场景时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出Regist3R模型，旨在解决多视角3D重建中的计算成本高和累积误差大等问题。&lt;h4&gt;方法&lt;/h4&gt;Regist3R利用增量重建范式，从无序的多视角图像集中进行大规模3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;Regist3R在公共数据集上的实验表明，其性能与基于优化的方法相当，同时显著提高了计算效率，并优于现有的多视角重建模型。此外，通过点云图基础模型首次实现了包含数千个视角的大规模场景重建。&lt;h4&gt;结论&lt;/h4&gt;Regist3R在多视角3D重建任务中具有潜在的应用价值，包括城市建模、航空测绘等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view 3D reconstruction has remained an essential yet challengingproblem in the field of computer vision. While DUSt3R and its successors haveachieved breakthroughs in 3D reconstruction from unposed images, these methodsexhibit significant limitations when scaling to multi-view scenarios, includinghigh computational cost and cumulative error induced by global alignment. Toaddress these challenges, we propose Regist3R, a novel stereo foundation modeltailored for efficient and scalable incremental reconstruction. Regist3Rleverages an incremental reconstruction paradigm, enabling large-scale 3Dreconstructions from unordered and many-view image collections. We evaluateRegist3R on public datasets for camera pose estimation and 3D reconstruction.Our experiments demonstrate that Regist3R achieves comparable performance withoptimization-based methods while significantly improving computationalefficiency, and outperforms existing multi-view reconstruction models.Furthermore, to assess its performance in real-world applications, we introducea challenging oblique aerial dataset which has long spatial spans and hundredsof views. The results highlight the effectiveness of Regist3R. We alsodemonstrate the first attempt to reconstruct large-scale scenes encompassingover thousands of views through pointmap-based foundation models, showcasingits potential for practical applications in large-scale 3D reconstructiontasks, including urban modeling, aerial mapping, and beyond.</description>
      <author>example@mail.com (Sidun Liu, Wenyu Li, Peng Qiao, Yong Dou)</author>
      <guid isPermaLink="false">2504.12356v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation Model Performance with Minimal Clinical Data</title>
      <link>http://arxiv.org/abs/2504.12351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种原型引导的扩散模型，用于生成高保真度的合成病理数据，从而在大规模的自监督学习中减少对真实患者样本的依赖，同时保持下游性能。&lt;h4&gt;背景&lt;/h4&gt;数字病理中的基础模型使用大量数据集学习复杂的组织学图像的有用紧凑特征表示，但数据集大小与性能之间的相关性透明度有限，引发了对仅通过增加数据来提高性能是否总是必要的疑问。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来生成高质量的合成病理数据，以促进自监督学习，减少对真实患者样本的依赖，并保持或提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种原型引导的扩散模型，在采样过程中使用组织学原型的指导，以确保生成数据的生物学和诊断意义。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据集上训练的自监督特征在数据量减少了60倍至760倍的情况下仍然取得了有竞争力的性能，并且在多个评估指标和任务上与训练在大型真实世界数据集上的模型具有统计上相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;混合使用合成数据和真实数据的方法进一步提升了性能，在多项评估中达到了最佳结果，强调了生成式AI在为数字病理学创建引人注目的训练数据方面的潜力，显著减少了对外延广泛的临床数据集的依赖，并突出了该方法的高效性。&lt;h4&gt;翻译&lt;/h4&gt;Using a prototype-guided diffusion model, this study generates high-fidelity synthetic pathology data to enable large-scale self-supervised learning while reducing reliance on real patient samples and maintaining downstream performance. This approach, guided by histological prototypes, ensures biologically and diagnostically meaningful variations in the generated data. The results demonstrate that self-supervised features trained on the synthetic dataset achieve competitive performance with significantly less data than those trained on large real-world datasets, showing statistical equivalence or even superiority across multiple evaluation metrics and tasks. The hybrid approach using synthetic and real data enhances performance, reaching top results in several evaluations, highlighting the potential of generative AI in creating compelling training data for digital pathology and significantly reducing the reliance on extensive clinical datasets, while emphasizing the efficiency of the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models in digital pathology use massive datasets to learn usefulcompact feature representations of complex histology images. However, there islimited transparency into what drives the correlation between dataset size andperformance, raising the question of whether simply adding more data toincrease performance is always necessary. In this study, we propose aprototype-guided diffusion model to generate high-fidelity synthetic pathologydata at scale, enabling large-scale self-supervised learning and reducingreliance on real patient samples while preserving downstream performance. Usingguidance from histological prototypes during sampling, our approach ensuresbiologically and diagnostically meaningful variations in the generated data. Wedemonstrate that self-supervised features trained on our synthetic datasetachieve competitive performance despite using ~60x-760x less data than modelstrained on large real-world datasets. Notably, models trained using oursynthetic data showed statistically comparable or better performance acrossmultiple evaluation metrics and tasks, even when compared to models trained onorders of magnitude larger datasets. Our hybrid approach, combining syntheticand real data, further enhanced performance, achieving top results in severalevaluations. These findings underscore the potential of generative AI to createcompelling training data for digital pathology, significantly reducing thereliance on extensive clinical datasets and highlighting the efficiency of ourapproach.</description>
      <author>example@mail.com (Ekaterina Redekop, Mara Pleasure, Vedrana Ivezic, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey Arnold)</author>
      <guid isPermaLink="false">2504.12351v1</guid>
      <pubDate>Fri, 18 Apr 2025 14:19:43 +0800</pubDate>
    </item>
    <item>
      <title>SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields</title>
      <link>http://arxiv.org/abs/2504.12262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 5 main figures, 3 tables, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SCENT的新型框架，用于可扩展且基于连续性的时空表示学习。&lt;h4&gt;背景&lt;/h4&gt;时空学习因空间和时间依赖关系的复杂交互、数据的高维性和可扩展性限制而具有挑战性。在科学领域，数据的非规则分布（如传感器故障导致的缺失值）和高体积（如高保真模拟）进一步加剧了这些挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决时空学习中的可扩展性和连续性问题。&lt;h4&gt;方法&lt;/h4&gt;SCENT通过一个基于transformer的编码器-处理器-解码器架构统一了插值、重建和预测。它引入了可学习的查询来增强泛化能力，并采用查询级别的交叉注意力机制以有效地捕获多尺度依赖。为了确保数据规模和模型复杂度的可扩展性，SCENT集成了稀疏注意力机制，允许灵活的输出表示和高效的评价。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模拟和真实世界实验验证了SCENT的有效性，证明了其在多个具有挑战性的任务中实现了最先进的性能，同时实现了卓越的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;SCENT是一种有效的时空表示学习方法，能够处理高维和大规模数据，并在多个任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal learning is challenging due to the intricate interplay betweenspatial and temporal dependencies, the high dimensionality of the data, andscalability constraints. These challenges are further amplified in scientificdomains, where data is often irregularly distributed (e.g., missing values fromsensor failures) and high-volume (e.g., high-fidelity simulations), posingadditional computational and modeling difficulties. In this paper, we presentSCENT, a novel framework for scalable and continuity-informed spatiotemporalrepresentation learning. SCENT unifies interpolation, reconstruction, andforecasting within a single architecture. Built on a transformer-basedencoder-processor-decoder backbone, SCENT introduces learnable queries toenhance generalization and a query-wise cross-attention mechanism toeffectively capture multi-scale dependencies. To ensure scalability in bothdata size and model complexity, we incorporate a sparse attention mechanism,enabling flexible output representations and efficient evaluation at arbitraryresolutions. We validate SCENT through extensive simulations and real-worldexperiments, demonstrating state-of-the-art performance across multiplechallenging tasks while achieving superior scalability.</description>
      <author>example@mail.com (David Keetae Park, Xihaier Luo, Guang Zhao, Seungjun Lee, Miruna Oprescu, Shinjae Yoo)</author>
      <guid isPermaLink="false">2504.12262v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
  <item>
      <title>FLIP Reasoning Challenge</title>
      <link>http://arxiv.org/abs/2504.12256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at First Workshop on Open Science for Foundation Models at  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了FLIP数据集，用于评估人工智能推理能力，并探讨了现有推理模型的局限性。&lt;h4&gt;背景&lt;/h4&gt;近年来，人工智能在感知和生成任务方面取得了显著进展，但在推理方面仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FLIP数据集，作为一个基于人类验证任务的基准，以评估AI的推理能力。&lt;h4&gt;方法&lt;/h4&gt;FLIP挑战要求用户从两组4张图片中识别出逻辑上连贯的一组，强调顺序推理、视觉叙事和常识。&lt;h4&gt;主要发现&lt;/h4&gt;即使是最先进的开源和闭源模型在零样本设置下的最大准确率也仅为75.5%和77.9%，而人类的表现为95.3%。图像字幕模型通过提供图像的文本描述来辅助推理模型，提高了准确率。结合15个模型的预测，准确率可提高至85.2%。&lt;h4&gt;结论&lt;/h4&gt;现有推理模型的局限性需要像FLIP这样的鲁棒的多模态基准。&lt;h4&gt;翻译&lt;/h4&gt;在过去的几年里，人工智能（AI）的进步展示了AI如何解决许多感知和生成任务，如图像分类和文本写作，但推理仍然是一个挑战。本文介绍了一个名为FLIP的数据集，它是一个基于人类在Idena区块链上进行的验证任务的AI推理能力基准。FLIP挑战向用户提供了两组4张图片的顺序，要求他们识别出逻辑上连贯的一组。通过强调顺序推理、视觉叙事和常识，FLIP为多模态AI系统提供了一个独特的测试平台。我们的实验评估了最先进的模型，利用了视觉语言模型（VLMs）和大型语言模型（LLMs）。结果表明，即使在零样本设置下，即使是最好的开源和闭源模型也仅达到75.5%和77.9%的最大准确率，而人类的准确率为95.3%。图像字幕模型通过提供图像的文本描述来辅助推理模型，比直接使用原始图像获得了更好的结果，Gemini 1.5Pro的准确率分别为69.6%和75.2%。结合15个模型的预测，准确率可提高至85.2%。这些发现突出了现有推理模型的局限性，以及像FLIP这样的鲁棒的多模态基准的需求。完整的代码库和数据集将在https://github.com/aplesner/FLIP-Reasoning-Challenge上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past years, advances in artificial intelligence (AI) havedemonstrated how AI can solve many perception and generation tasks, such asimage classification and text writing, yet reasoning remains a challenge. Thispaper introduces the FLIP dataset, a benchmark for evaluating AI reasoningcapabilities based on human verification tasks on the Idena blockchain. FLIPchallenges present users with two orderings of 4 images, requiring them toidentify the logically coherent one. By emphasizing sequential reasoning,visual storytelling, and common sense, FLIP provides a unique testbed formultimodal AI systems. Our experiments evaluate state-of-the-art models,leveraging both vision-language models (VLMs) and large language models (LLMs).Results reveal that even the best open-sourced and closed-sourced modelsachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shotsettings, compared to human performance of 95.3%. Captioning models aidreasoning models by providing text descriptions of images, yielding betterresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5Pro. Combining the predictions from 15 models in an ensemble increases theaccuracy to 85.2%. These findings highlight the limitations of existingreasoning models and the need for robust multimodal benchmarks like FLIP. Thefull codebase and dataset will be available athttps://github.com/aplesner/FLIP-Reasoning-Challenge.</description>
      <author>example@mail.com (Andreas Plesner, Turlan Kuzhagaliyev, Roger Wattenhofer)</author>
      <guid isPermaLink="false">2504.12256v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition</title>
      <link>http://arxiv.org/abs/2504.12011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the Web Conference (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上的自监督学习（SSL），特别是在使用图神经网络（GNNs）和预处理任务方面的应用，如对比学习和特征重建。研究发现，现有方法在反映图的基本属性和邻居表示相似性方面存在差异，并提出了一种平衡图SSL中平滑性的新框架BSG，通过引入新的损失函数来提高SSL的表现。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在图上的应用引起了广泛关注，特别是在使用GNNs和预处理任务方面，如对比学习和特征重建。&lt;h4&gt;目的&lt;/h4&gt;探讨现有自监督学习方法是否有效反映图的基本属性，以及如何改进这些方法以提升表现。&lt;h4&gt;方法&lt;/h4&gt;通过信息论框架将SSL目标分解为三个部分，并提出了一种名为BSG的框架，该框架引入了新的损失函数来平衡这三个部分：邻居损失、最小损失和发散损失。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有方法在反映图的基本属性和邻居表示相似性方面存在差异，并揭示了这种差异的原因是三个部分的不平衡。BSG框架能够平衡这些部分，从而在更广泛的下游任务中提高性能。&lt;h4&gt;结论&lt;/h4&gt;BSG框架通过引入新的损失函数平衡图SSL中的平滑性，实现了在节点分类和链接预测任务上的最佳性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates self-supervised learning (SSL) on graphs, particularly the application of Graph Neural Networks (GNNs) and pretext tasks initially designed for other domains, such as contrastive learning and feature reconstruction. It finds that existing methods differ in reflecting essential graph properties and neighbor representation similarity, and proposes a new framework called BSG to balance the smoothness in graph-based SSL by introducing new loss functions to improve the performance of SSL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714611&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) in graphs has garnered significant attention,particularly in employing Graph Neural Networks (GNNs) with pretext tasksinitially designed for other domains, such as contrastive learning and featurereconstruction. However, it remains uncertain whether these methods effectivelyreflect essential graph properties, precisely representation similarity withits neighbors. We observe that existing methods position opposite ends of aspectrum driven by the graph embedding smoothness, with each end correspondingto outperformance on specific downstream tasks. Decomposing the SSL objectiveinto three terms via an information-theoretic framework with a neighborrepresentation variable reveals that this polarization stems from an imbalanceamong the terms, which existing methods may not effectively maintain. Furtherinsights suggest that balancing between the extremes can lead to improvedperformance across a wider range of downstream tasks. A framework, BSG(Balancing Smoothness in Graph SSL), introduces novel loss functions designedto supplement the representation quality in graph-based SSL by balancing thederived three terms: neighbor loss, minimal loss, and divergence loss. Wepresent a theoretical analysis of the effects of these loss functions,highlighting their significance from both the SSL and graph smoothnessperspectives. Extensive experiments on multiple real-world datasets across nodeclassification and link prediction consistently demonstrate that BSG achievesstate-of-the-art performance, outperforming existing methods. Ourimplementation code is available at https://github.com/steve30572/BSG.</description>
      <author>example@mail.com (Heesoo Jung, Hogun Park)</author>
      <guid isPermaLink="false">2504.12011v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Correlation Ratio for Unsupervised Learning of Multi-modal Deformable Registration</title>
      <link>http://arxiv.org/abs/2504.12265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SPIE MI'25 ((c) SPIE). Code available at  https://github.com/junyuchen245/Correlation_Ratio&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可微分的相关比率作为损失函数的多模态变形图像配准的深度学习方法。&lt;h4&gt;背景&lt;/h4&gt;近年来，无监督学习在变形图像配准方面成为研究热点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以改进基于深度学习的多模态图像配准性能。&lt;h4&gt;方法&lt;/h4&gt;使用移动和固定图像对训练配准网络，并引入结合图像相似度测量和变形正则化的损失函数。使用帕累托窗函数近似扩展传统不可微分的相关比率实现，以便与深度神经网络配合进行反向传播。&lt;h4&gt;主要发现&lt;/h4&gt;提出的可微分相关比率在多模态神经影像数据集上进行了验证，并建立了一个贝叶斯训练框架来研究变形正则化器与相似度度量（包括互信息和所提出的相关比率）之间的权衡如何影响配准性能。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地提高了多模态图像配准的性能，并提供了新的见解来优化配准过程中的参数调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, unsupervised learning for deformable image registration hasbeen a major research focus. This approach involves training a registrationnetwork using pairs of moving and fixed images, along with a loss function thatcombines an image similarity measure and deformation regularization. Formulti-modal image registration tasks, the correlation ratio has been awidely-used image similarity measure historically, yet it has beenunderexplored in current deep learning methods. Here, we propose adifferentiable correlation ratio to use as a loss function for learning-basedmulti-modal deformable image registration. This approach extends thetraditionally non-differentiable implementation of the correlation ratio byusing the Parzen windowing approximation, enabling backpropagation with deepneural networks. We validated the proposed correlation ratio on a multi-modalneuroimaging dataset. In addition, we established a Bayesian training frameworkto study how the trade-off between the deformation regularizer and similaritymeasures, including mutual information and our proposed correlation ratio,affects the registration performance.</description>
      <author>example@mail.com (Xiaojian Chen, Yihao Liu, Shuwen Wei, Aaron Carass, Yong Du, Junyu Chen)</author>
      <guid isPermaLink="false">2504.12265v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>TacoDepth: Towards Efficient Radar-Camera Depth Estimation with One-stage Fusion</title>
      <link>http://arxiv.org/abs/2504.11773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025 (Oral Presentation)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TacoDepth的雷达-摄像头深度估计模型，旨在通过融合输入图像和雷达数据来预测密集和精确的度量深度。&lt;h4&gt;背景&lt;/h4&gt;雷达-摄像头深度估计对于自动驾驶车辆和机器人平台中的实时处理至关重要，但雷达回波稀疏性导致现有方法采用多阶段框架，效率低下且鲁棒性不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且准确的雷达-摄像头深度估计模型，以实现实时处理。&lt;h4&gt;方法&lt;/h4&gt;TacoDepth采用了一阶段融合，包括基于图的雷达结构提取器和基于金字塔的雷达融合模块，以捕获和整合雷达点云的图结构，从而提高模型效率和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;TacoDepth在深度准确性和处理速度上比现有最先进的方法提高了12.8%和91.8%，并且能够灵活适应不同的推理模式，在速度和精度之间提供更好的平衡。&lt;h4&gt;结论&lt;/h4&gt;TacoDepth为高效雷达-摄像头深度估计提供了一种新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar-Camera depth estimation aims to predict dense and accurate metric depthby fusing input images and Radar data. Model efficiency is crucial for thistask in pursuit of real-time processing on autonomous vehicles and roboticplatforms. However, due to the sparsity of Radar returns, the prevailingmethods adopt multi-stage frameworks with intermediate quasi-dense depth, whichare time-consuming and not robust. To address these challenges, we proposeTacoDepth, an efficient and accurate Radar-Camera depth estimation model withone-stage fusion. Specifically, the graph-based Radar structure extractor andthe pyramid-based Radar fusion module are designed to capture and integrate thegraph structures of Radar point clouds, delivering superior model efficiencyand robustness without relying on the intermediate depth results. Moreover,TacoDepth can be flexible for different inference modes, providing a betterbalance of speed and accuracy. Extensive experiments are conducted todemonstrate the efficacy of our method. Compared with the previousstate-of-the-art approach, TacoDepth improves depth accuracy and processingspeed by 12.8% and 91.8%. Our work provides a new perspective on efficientRadar-Camera depth estimation.</description>
      <author>example@mail.com (Yiran Wang, Jiaqi Li, Chaoyi Hong, Ruibo Li, Liusheng Sun, Xiao Song, Zhe Wang, Zhiguo Cao, Guosheng Lin)</author>
      <guid isPermaLink="false">2504.11773v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>A Complex-valued SAR Foundation Model Based on Physically Inspired Representation Learning</title>
      <link>http://arxiv.org/abs/2504.11999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于复值合成孔径雷达（SAR）数据的遥感基础模型，用于SAR图像解释，解决了信息利用不足和可解释性差的问题。&lt;h4&gt;背景&lt;/h4&gt;遥感基础模型在下游任务中表现出优越的泛化能力，SAR提供了全天候、全天时的成像能力，对地球观测具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;建立能够有效利用信息并具有物理可解释性的SAR图像解释基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过模拟极化分解过程进行预训练，将像素散射强度表示为散射基和散射系数的加权组合，构建了一系列散射查询，以与SAR特征交互并输出相应的散射系数。同时，设计了极化分解损失和功率自监督损失来指导预训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;该基础模型在六个典型下游任务上验证了其性能，实现了最先进的结果，能够提取稳定的特征表示，并在数据稀缺条件下表现出强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的基础模型在SAR图像解释方面具有显著优势，为遥感领域提供了新的研究思路。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models in remote sensing have been extensively studied due to their superior generalization on various downstream tasks. Synthetic Aperture Radar (SAR) offers all-day, all-weather imaging capabilities, providing significant advantages for Earth observation. However, establishing a foundation model for SAR image interpretation inevitably encounters the challenges of insufficient information utilization and poor interpretability. In this paper, we propose a remote sensing foundation model based on complex-valued SAR data, which simulates the polarimetric decomposition process for pre-training, i.e., characterizing pixel scattering intensity as a weighted combination of scattering bases and scattering coefficients, thereby endowing the foundation model with physical interpretability. Specifically, we construct a series of scattering queries, each representing an independent and meaningful scattering basis, which interact with SAR features in the scattering query decoder and output the corresponding scattering coefficient. To guide the pre-training process, polarimetric decomposition loss and power self-supervision loss are constructed. The former aligns the predicted coefficients with Yamaguchi coefficients, while the latter reconstructs power from the predicted coefficients and compares it to the input image's power. The performance of our foundation model is validated on six typical downstream tasks, achieving state-of-the-art results. Notably, the foundation model can extract stable feature representations and exhibits strong generalization, even in data-scarce conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models in remote sensing have been extensively studied dueto their superior generalization on various downstream tasks. SyntheticAperture Radar (SAR) offers all-day, all-weather imaging capabilities,providing significant advantages for Earth observation. However, establishing afoundation model for SAR image interpretation inevitably encounters thechallenges of insufficient information utilization and poor interpretability.In this paper, we propose a remote sensing foundation model based oncomplex-valued SAR data, which simulates the polarimetric decomposition processfor pre-training, i.e., characterizing pixel scattering intensity as a weightedcombination of scattering bases and scattering coefficients, thereby endowingthe foundation model with physical interpretability. Specifically, we constructa series of scattering queries, each representing an independent and meaningfulscattering basis, which interact with SAR features in the scattering querydecoder and output the corresponding scattering coefficient. To guide thepre-training process, polarimetric decomposition loss and powerself-supervision loss are constructed. The former aligns the predictedcoefficients with Yamaguchi coefficients, while the latter reconstructs powerfrom the predicted coefficients and compares it to the input image's power. Theperformance of our foundation model is validated on six typical downstreamtasks, achieving state-of-the-art results. Notably, the foundation model canextract stable feature representations and exhibits strong generalization, evenin data-scarce conditions.</description>
      <author>example@mail.com (Mengyu Wang, Hanbo Bi, Yingchao Feng, Linlin Xin, Shuo Gong, Tianqi Wang, Zhiyuan Yan, Peijin Wang, Wenhui Diao, Xian Sun)</author>
      <guid isPermaLink="false">2504.11999v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>CodingHomo: Bootstrapping Deep Homography With Video Coding</title>
      <link>http://arxiv.org/abs/2504.12165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于视频编码的Homography估计新方法，通过利用视频中的运动矢量，提高了估计的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;Homography估计在计算机视觉中是一个基础任务，广泛应用于多个领域。深度学习在Homography估计方面的应用，尤其是无监督学习方法，已经取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;为了提高复杂运动情况下Homography的准确预测。&lt;h4&gt;方法&lt;/h4&gt;提出了CodingHomo，一个无监督的Homography估计框架，包括Mask-Guided Fusion（MGF）模块和Mask-Guided Homography Estimation（MGHE）模块，用于识别和利用运动矢量中的有益特征，并消除不希望的特征。&lt;h4&gt;主要发现&lt;/h4&gt;CodingHomo在无监督方法中表现优于现有技术，具有良好的鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过视频编码和运动矢量的利用，为Homography估计提供了一种新的思路和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Homography估计是计算机视觉中的一个基本任务，在多个领域有应用。近年来，深度学习在Homography估计方面的应用，尤其是无监督学习方法，已经取得了显著的进展。然而，在复杂运动情况下准确预测Homography仍然是一个挑战。为此，本研究提出了一种基于视频编码的新方法，通过利用视频中的内在运动矢量（MVs）来提高鲁棒性和泛化能力。本研究提出了CodingHomo，一个用于Homography估计的无监督框架。该框架具有一个Mask-Guided Fusion（MGF）模块，用于识别和利用MVs中的有益特征，从而提高Homography预测的准确性。此外，还提出了Mask-Guided Homography Estimation（MGHE）模块，用于在粗到细的Homography细化过程中消除不希望的特征。CodingHomo在无监督方法中优于现有技术，提供了良好的鲁棒性和泛化能力。代码和数据集可在以下链接找到：[GitHub](https://github.com/liuyike422/CodingHomo)&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2024.3418771&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Homography estimation is a fundamental task in computer vision withapplications in diverse fields. Recent advances in deep learning have improvedhomography estimation, particularly with unsupervised learning approaches,offering increased robustness and generalizability. However, accuratelypredicting homography, especially in complex motions, remains a challenge. Inresponse, this work introduces a novel method leveraging video coding,particularly by harnessing inherent motion vectors (MVs) present in videos. Wepresent CodingHomo, an unsupervised framework for homography estimation. Ourframework features a Mask-Guided Fusion (MGF) module that identifies andutilizes beneficial features among the MVs, thereby enhancing the accuracy ofhomography prediction. Additionally, the Mask-Guided Homography Estimation(MGHE) module is presented for eliminating undesired features in thecoarse-to-fine homography refinement process. CodingHomo outperforms existingstate-of-the-art unsupervised methods, delivering good robustness andgeneralizability. The code and dataset are available at:\href{github}{https://github.com/liuyike422/CodingHomo</description>
      <author>example@mail.com (Yike Liu, Haipeng Li, Shuaicheng Liu, Bing Zeng)</author>
      <guid isPermaLink="false">2504.12165v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision</title>
      <link>http://arxiv.org/abs/2504.11754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025 Spotlight. Code and data are available at:  https://github.com/vLAR-group/GrabS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在复杂点云中进行3D物体分割的难题，提出了一种名为GrabS的两阶段流程，通过学习生成和判别性物体中心先验，并在第二阶段设计了一个具身智能体来发现多个物体，显著提升了分割性能。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督方法通常依赖于预训练的2D特征或外部信号，如运动，来分组3D点作为物体，但这些方法在识别简单物体时有限，且分割效果较差，因为缺乏物体性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督3D物体分割方法，以提高在复杂点云中的分割性能。&lt;h4&gt;方法&lt;/h4&gt; GrabS流程分为两个阶段：第一阶段学习生成和判别性物体中心先验；第二阶段设计具身智能体通过查询预训练的生成先验来学习发现多个物体。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界数据集和一个新创建的合成数据集上，GrabS方法展现了显著的分割性能，超越了所有现有的无监督方法。&lt;h4&gt;结论&lt;/h4&gt;GrabS方法通过学习物体中心先验和设计具身智能体，有效地解决了复杂点云中的3D物体分割问题，并显著提升了分割效果。&lt;h4&gt;翻译&lt;/h4&gt;We study the hard problem of 3D object segmentation in complex point clouds without requiring human labels of 3D scenes for supervision. By relying on the similarity of pretrained 2D features or external signals such as motion to group 3D points as objects, existing unsupervised methods are usually limited to identifying simple objects like cars or their segmented objects are often inferior due to the lack of objectness in pretrained features. In this paper, we propose a new two-stage pipeline called GrabS. The core concept of our method is to learn generative and discriminative object-centric priors as a foundation from object datasets in the first stage, and then design an embodied agent to learn to discover multiple objects by querying against the pretrained generative priors in the second stage. We extensively evaluate our method on two real-world datasets and a newly created synthetic dataset, demonstrating remarkable segmentation performance, clearly surpassing all existing unsupervised methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the hard problem of 3D object segmentation in complex point cloudswithout requiring human labels of 3D scenes for supervision. By relying on thesimilarity of pretrained 2D features or external signals such as motion togroup 3D points as objects, existing unsupervised methods are usually limitedto identifying simple objects like cars or their segmented objects are ofteninferior due to the lack of objectness in pretrained features. In this paper,we propose a new two-stage pipeline called GrabS. The core concept of ourmethod is to learn generative and discriminative object-centric priors as afoundation from object datasets in the first stage, and then design an embodiedagent to learn to discover multiple objects by querying against the pretrainedgenerative priors in the second stage. We extensively evaluate our method ontwo real-world datasets and a newly created synthetic dataset, demonstratingremarkable segmentation performance, clearly surpassing all existingunsupervised methods.</description>
      <author>example@mail.com (Zihui Zhang, Yafei Yang, Hongtao Wen, Bo Yang)</author>
      <guid isPermaLink="false">2504.11754v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization</title>
      <link>http://arxiv.org/abs/2504.12083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自对齐框架，帮助大型视频语言模型（LVLMs）从自身错误中学习，以解决LVLMs在细粒度时间理解、幻觉生成和简单视频问答任务中的错误问题。&lt;h4&gt;背景&lt;/h4&gt;尽管大型视频语言模型（LVLMs）近年来取得了进展，但它们在细粒度时间理解、幻觉生成和简单视频问答任务中仍然存在困难，这给它们在现实世界中的应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决LVLMs的这些局限性，提出了一种自对齐框架，使LVLMs能够从自己的错误中学习。&lt;h4&gt;方法&lt;/h4&gt;该框架首先获得一组首选和非首选响应对，其中非首选响应是通过结合常见的错误模式生成的，这些错误模式通常是由于时空理解不足、概念之间的虚假相关性、过度依赖语言线索而忽视视觉模态等引起的。为了促进LVLMs与构建的首选和非首选响应对的自对齐，引入了精细正则化偏好优化（RRPO），这是一种新的偏好优化方法，它使用子序列级别的精细奖励和基于标记的KL正则化来解决直接偏好优化（DPO）的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;实验和分析验证了该方法在包括视频幻觉、短视频和长视频理解以及细粒度时间推理在内的各种视频任务中的有效性，RRPO比DPO实现了更精确的对齐和更稳定的训练。&lt;h4&gt;结论&lt;/h4&gt;RRPO方法能够有效提升LVLMs的性能，使其在视频问答任务中更加可靠和安全。&lt;h4&gt;翻译&lt;/h4&gt;尽管大型视频语言模型（LVLMs）近年来取得了进展，但它们在细粒度时间理解、幻觉生成和简单视频问答任务中仍然存在困难，这给它们在现实世界中的应用带来了挑战。为了解决LVLMs的这些局限性，本文提出了一种自对齐框架，使LVLMs能够从自己的错误中学习。该框架首先获得一组首选和非首选响应对，其中非首选响应是通过结合常见的错误模式生成的，这些错误模式通常是由于时空理解不足、概念之间的虚假相关性、过度依赖语言线索而忽视视觉模态等引起的。为了促进LVLMs与构建的首选和非首选响应对的自对齐，引入了精细正则化偏好优化（RRPO），这是一种新的偏好优化方法，它使用子序列级别的精细奖励和基于标记的KL正则化来解决直接偏好优化（DPO）的局限性。实验和分析验证了该方法在包括视频幻觉、短视频和长视频理解以及细粒度时间推理在内的各种视频任务中的有效性，RRPO比DPO实现了更精确的对齐和更稳定的训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in Large Video Language Models (LVLMs), they stillstruggle with fine-grained temporal understanding, hallucinate, and often makesimple mistakes on even simple video question-answering tasks, all of whichpose significant challenges to their safe and reliable deployment in real-worldapplications. To address these limitations, we propose a self-alignmentframework that enables LVLMs to learn from their own errors. Our proposedframework first obtains a training set of preferred and non-preferred responsepairs, where non-preferred responses are generated by incorporating commonerror patterns that often occur due to inadequate spatio-temporalunderstanding, spurious correlations between co-occurring concepts, andover-reliance on linguistic cues while neglecting the vision modality, amongothers. To facilitate self-alignment of LVLMs with the constructed preferredand non-preferred response pairs, we introduce Refined Regularized PreferenceOptimization (RRPO), a novel preference optimization method that utilizessub-sequence-level refined rewards and token-wise KL regularization to addressthe limitations of Direct Preference Optimization (DPO). We demonstrate thatRRPO achieves more precise alignment and more stable training compared to DPO.Our experiments and analysis validate the effectiveness of our approach acrossdiverse video tasks, including video hallucination, short- and long-videounderstanding, and fine-grained temporal reasoning.</description>
      <author>example@mail.com (Pritam Sarkar, Ali Etemad)</author>
      <guid isPermaLink="false">2504.12083v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data</title>
      <link>http://arxiv.org/abs/2504.12185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NAACL 2025 main. 15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SALAD的新方法，用于增强预训练语言模型的鲁棒性和泛化能力，通过生成结构感知和反事实增强的数据进行对比学习来解决NLP任务中的伪相关性问题。&lt;h4&gt;背景&lt;/h4&gt;在自然语言处理任务中，微调预训练语言模型时经常出现伪相关性问题，这会负面影响性能，尤其是在处理无分布数据时。&lt;h4&gt;目的&lt;/h4&gt;提出SALAD方法，旨在解决NLP任务中的伪相关性问题，提高模型的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;SALAD方法通过以下步骤实现：利用基于标记的方法生成结构感知的正面样本，并利用大型语言模型生成具有多样句式模式的反事实负面样本。通过对比学习，使模型专注于学习关键句子成分之间的结构关系，同时最小化对伪相关性的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;通过在情感分类、性别歧视检测和自然语言推理三个任务上的实验验证了SALAD方法的有效性，结果表明SALAD不仅提高了模型在不同环境下的鲁棒性和性能，还增强了模型对无分布数据集和跨域场景的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SALAD方法能够有效提升预训练语言模型的鲁棒性和泛化能力，对于解决NLP任务中的伪相关性问题具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In various natural language processing (NLP) tasks, fine-tuning Pre-trainedLanguage Models (PLMs) often leads to the issue of spurious correlations, whichnegatively impacts performance, particularly when dealing without-of-distribution data. To address this problem, we propose SALAD}(StructureAware and LLM-driven Augmented Data), a novel approach designed to enhancemodel robustness and generalization by generating structure-aware andcounterfactually augmented data for contrastive learning. Our method leveragesa tagging-based approach to generate structure-aware positive samples andutilizes large language models (LLMs) to generate counterfactual negativesamples with diverse sentence patterns. By applying contrastive learning, SALADenables the model to focus on learning the structural relationships between keysentence components while minimizing reliance on spurious correlations. Wevalidate our approach through experiments on three tasks: SentimentClassification, Sexism Detection, and Natural Language Inference. The resultsdemonstrate that SALAD not only improves model robustness and performanceacross different environments but also enhances generalization toout-of-distribution datasets and cross-domain scenarios.</description>
      <author>example@mail.com (Suyoung Bae, Hyojun Kim, YunSeok Choi, Jee-Hyong Lee)</author>
      <guid isPermaLink="false">2504.12185v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 1 supple&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE3D的新型弱监督框架，旨在解决多领域数据集在单目3D物体检测中的训练挑战。&lt;h4&gt;背景&lt;/h4&gt;当前计算机视觉趋势强调开发能够同时处理多种不同任务的通用模型，这通常需要跨多领域数据集进行联合训练以确保有效的泛化。&lt;h4&gt;目的&lt;/h4&gt;解决单目3D物体检测在多领域训练中由于数据集标注3D地面实况标签稀缺而面临的独特挑战。&lt;h4&gt;方法&lt;/h4&gt;GATE3D通过利用2D和3D预测之间的一致性损失来有效弥合领域差距，并利用伪标签进行弱监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和自收集的室内办公数据集上实现了有竞争力的性能，显著加速了从有限标注数据中的学习过程。&lt;h4&gt;结论&lt;/h4&gt;GATE3D在机器人、增强现实和虚拟现实应用中具有广泛的潜在影响，特别是在从有限标注数据中学习方面表现突出。&lt;h4&gt;翻译&lt;/h4&gt;摘要：计算机视觉领域的最新趋势强调开发能够同时解决多种不同任务的通用模型。这种通用性通常需要跨多领域数据集进行联合训练以确保有效的泛化。然而，由于数据集标注3D地面实况标签稀缺，尤其是在典型的基于道路的自动驾驶环境之外，单目3D物体检测在多领域训练中面临着独特的挑战。为了应对这一挑战，我们引入了一种新颖的弱监督框架，利用伪标签。由于数据集固有的偏差，当前预训练模型往往难以在非道路环境中准确检测行人。与通用的基于图像的2D物体检测模型不同，在单目3D检测中实现类似的泛化仍然在很大程度上未被探索。在本文中，我们提出了一种名为GATE3D的新框架，专门用于通过弱监督进行通用的单目3D物体检测。GATE3D通过采用2D和3D预测之间的一致性损失来有效弥合领域差距。值得注意的是，我们的模型在KITTI基准数据集以及我们收集的用于评估我们框架泛化能力的室内办公数据集上实现了有竞争力的性能。我们的结果表明，GATE3D通过有效的预训练策略显著加速了从有限标注数据中的学习过程，突显了其在机器人、增强现实和虚拟现实应用中广泛的潜在影响。项目页面：https://ies0411.github.io/GATE3D/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Jung Kwon Lee, Changhyun Jee)</author>
      <guid isPermaLink="false">2504.11014v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency</title>
      <link>http://arxiv.org/abs/2504.12080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DC-SAM的新方法，用于在上下文中对图像和视频进行对象分割，并在视频分割领域构建了第一个基准IC-VOS。&lt;h4&gt;背景&lt;/h4&gt;在上下文分割中，使用单个标记示例对对象进行分割，称为少样本学习中的单次分割，用于测试分割模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出DC-SAM方法，以适应SAM和SAM2进行上下文分割，并评估模型在视频分割领域的性能。&lt;h4&gt;方法&lt;/h4&gt;DC-SAM通过提供高质量视觉提示来增强SAM的提示编码器特征，并在生成掩码之前融合SAM特征以更好地对齐提示编码器。此外，还设计了循环一致交叉注意力和双重分支设计，以及简单的mask-tube训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;DC-SAM在图像分割任务中取得了优异的性能，并在视频分割领域首次实现了有效的上下文分割。&lt;h4&gt;结论&lt;/h4&gt;DC-SAM方法在图像和视频分割任务中表现出色，并在提出的IC-VOS基准上取得了显著的效果。&lt;h4&gt;翻译&lt;/h4&gt;Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation model's generalization ability and has been applied to various vision tasks, including scene understanding and image/video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAM's prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at https://github.com/zaplm/DC-SAM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a single labeled example, in-context segmentation aims to segmentcorresponding objects. This setting, known as one-shot segmentation in few-shotlearning, explores the segmentation model's generalization ability and has beenapplied to various vision tasks, including scene understanding and image/videoediting. While recent Segment Anything Models have achieved state-of-the-artresults in interactive segmentation, these approaches are not directlyapplicable to in-context segmentation. In this work, we propose the DualConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2for in-context segmentation of both images and videos. Our key insights are toenhance the features of the SAM's prompt encoder in segmentation by providinghigh-quality visual prompts. When generating a mask prior, we fuse the SAMfeatures to better align the prompt encoder. Then, we design a cycle-consistentcross-attention on fused features and initial visual prompts. Next, adual-branch design is provided by using the discriminative positive andnegative prompts in the prompt encoder. Furthermore, we design a simplemask-tube training strategy to adopt our proposed dual consistency method intothe mask tube. Although the proposed DC-SAM is primarily designed for images,it can be seamlessly extended to the video domain with the support of SAM2.Given the absence of in-context segmentation in the video domain, we manuallycurate and construct the first benchmark from existing video segmentationdatasets, named In-Context Video Object Segmentation (IC-VOS), to better assessthe in-context capability of the model. Extensive experiments demonstrate thatour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU onPASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Oursource code and benchmark are available at https://github.com/zaplm/DC-SAM.</description>
      <author>example@mail.com (Mengshi Qi, Pengfei Zhu, Xiangtai Li, Xiaoyang Bi, Lu Qi, Huadong Ma, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.12080v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Reinforcement Learning Approach with Frontier Potential Based Reward for Safe Cluttered Environment Exploration</title>
      <link>http://arxiv.org/abs/2504.11907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, submitted to the 2025 IEEE/RSJ International  Conference on Intelligent Robots and Systems (IROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络探索贪婪策略和安全性保护层的新型方法，用于在杂乱环境中进行自主探索，确保在未知随机障碍物附近的安全导航。&lt;h4&gt;背景&lt;/h4&gt;在杂乱环境中进行自主探索需要有效的探索策略，以避免与未知随机障碍物发生碰撞。&lt;h4&gt;目的&lt;/h4&gt;研究一种能够在杂乱环境中高效且安全地进行探索的方法。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络为基础的探索贪婪策略和安全性保护层，利用强化学习和近端策略优化算法进行网络训练，以最大化探索效率并减少安全性保护层的干预。同时，提出了一种奖励函数，该函数基于智能体与未探索区域的接近程度和到达这些区域的预期信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;该方法结合了强化学习驱动的探索策略的适应性和显式安全机制确保的保证。&lt;h4&gt;结论&lt;/h4&gt;在模拟环境中的广泛评估表明，该方法能够实现杂乱环境中的高效和安全探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration of cluttered environments requires efficientexploration strategies that guarantee safety against potential collisions withunknown random obstacles. This paper presents a novel approach combining agraph neural network-based exploration greedy policy with a safety shield toensure safe navigation goal selection. The network is trained usingreinforcement learning and the proximal policy optimization algorithm tomaximize exploration efficiency while reducing the safety shield interventions.However, if the policy selects an infeasible action, the safety shieldintervenes to choose the best feasible alternative, ensuring systemconsistency. Moreover, this paper proposes a reward function that includes apotential field based on the agent's proximity to unexplored regions and theexpected information gain from reaching them. Overall, the approachinvestigated in this paper merges the benefits of the adaptability ofreinforcement learning-driven exploration policies and the guarantee ensured byexplicit safety mechanisms. Extensive evaluations in simulated environmentsdemonstrate that the approach enables efficient and safe exploration incluttered environments.</description>
      <author>example@mail.com (Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2504.11907v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Search is All You Need for Few-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2504.11895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为VisionAD的简单邻近搜索框架，用于少量样本下的异常检测（FSAD），在单类和多类FSAD场景中均超越了现有方法。&lt;h4&gt;背景&lt;/h4&gt;在工业检测中，FSAD是一个关键但具有挑战性的任务，需要使用少量正常图像进行正常分布建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要复杂提示工程和大量手动调优的方法，用于FSAD。&lt;h4&gt;方法&lt;/h4&gt;VisionAD包括以下四个简单但关键的组件：可扩展的视觉基础模型提取通用和区分性特征；双重增强策略，包括支持增强和查询增强；多层特征集成以捕捉低频全局上下文和高频局部细节；以及一个类感知视觉记忆库，用于高效的多类检测。&lt;h4&gt;主要发现&lt;/h4&gt;在MVTec-AD、VisA和Real-IAD基准上的广泛评估表明，使用仅1个正常图像作为支持，VisionAD在图像级AUROC分数上分别达到97.4%、94.8%和70.8%，显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;VisionAD的无训练特性和卓越的少量样本能力使其在样本稀缺或获取成本高昂的实际情况中特别有吸引力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Few-shot anomaly detection (FSAD)已经成为工业检测中的一个关键且具有挑战性的任务，在这个任务中，必须仅使用少量正常图像来完成正常分布建模。尽管现有的方法通常采用结合语言和视觉模态的多模态基础模型进行提示引导的异常检测，但这些方法往往需要复杂的提示工程和大量的手动调优。在本文中，我们证明了一个简单的邻近搜索框架可以超越单类和多类FSAD场景中的最先进性能。我们提出的方法，VisionAD，由以下四个简单但关键的组件组成：（1）可扩展的视觉基础模型，提取通用和区分性特征；（2）双重增强策略——支持增强以提高特征匹配适应性，查询增强以解决单视图预测的疏漏；（3）多层特征集成，以最小的计算开销捕捉低频全局上下文和高频局部细节；（4）一个类感知视觉记忆库，实现高效的一对多多类检测。在MVTec-AD、VisA和Real-IAD基准上的广泛评估表明VisionAD的卓越性能。使用仅1个正常图像作为支持，我们的方法在图像级AUROC分数上分别达到97.4%、94.8%和70.8%，显著优于现有方法（分别高出1.6%、3.2%和1.4%）。VisionAD的无训练特性和卓越的少量样本能力使其在样本稀缺或获取成本高昂的实际情况中特别有吸引力。代码可在https://github.com/Qiqigeww/VisionAD上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot anomaly detection (FSAD) has emerged as a crucial yet challengingtask in industrial inspection, where normal distribution modeling must beaccomplished with only a few normal images. While existing approaches typicallyemploy multi-modal foundation models combining language and vision modalitiesfor prompt-guided anomaly detection, these methods often demand sophisticatedprompt engineering and extensive manual tuning. In this paper, we demonstratethat a straightforward nearest-neighbor search framework can surpassstate-of-the-art performance in both single-class and multi-class FSADscenarios. Our proposed method, VisionAD, consists of four simple yet essentialcomponents: (1) scalable vision foundation models that extract universal anddiscriminative features; (2) dual augmentation strategies - supportaugmentation to enhance feature matching adaptability and query augmentation toaddress the oversights of single-view prediction; (3) multi-layer featureintegration that captures both low-frequency global context and high-frequencylocal details with minimal computational overhead; and (4) a class-aware visualmemory bank enabling efficient one-for-all multi-class detection. Extensiveevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrateVisionAD's exceptional performance. Using only 1 normal images as support, ourmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%respectively, outperforming current state-of-the-art approaches by significantmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superiorfew-shot capabilities of VisionAD make it particularly appealing for real-worldapplications where samples are scarce or expensive to obtain. Code is availableat https://github.com/Qiqigeww/VisionAD.</description>
      <author>example@mail.com (Qishan Wang, Jia Guo, Shuyong Gao, Haofen Wang, Li Xiong, Junjie Hu, Hanqi Guo, Wenqiang Zhang)</author>
      <guid isPermaLink="false">2504.11895v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems</title>
      <link>http://arxiv.org/abs/2504.11885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperSAT的新型神经网络方法，用于解决加权MaxSAT问题，并通过实验证明其性能优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在解决布尔可满足性（SAT）和最大可满足性（MaxSAT）问题方面表现出色，但加权MaxSAT问题的GNN方法尚未得到充分发展。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的神经网络方法来解决加权MaxSAT问题。&lt;h4&gt;方法&lt;/h4&gt;HyperSAT采用无监督的超图神经网络模型，为加权MaxSAT实例设计了一种超图表示，并设计了一个交叉注意力机制以及共享表示约束损失函数，以捕捉超图中正负文字节点之间的逻辑交互。&lt;h4&gt;主要发现&lt;/h4&gt;在多个加权MaxSAT数据集上的实验表明，HyperSAT的性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;HyperSAT是一种有效的解决加权MaxSAT问题的神经网络方法，在逻辑交互捕捉方面具有优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown promising performance in solving bothBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems dueto their ability to efficiently model and capture the structural dependenciesbetween literals and clauses. However, GNN methods for solving Weighted MaxSATproblems remain underdeveloped. The challenges arise from the non-lineardependency and sensitive objective function, which are caused by thenon-uniform distribution of weights across clauses. In this paper, we presentHyperSAT, a novel neural approach that employs an unsupervised hypergraphneural network model to solve Weighted MaxSAT problems. We propose a hypergraphrepresentation for Weighted MaxSAT instances and design a cross-attentionmechanism along with a shared representation constraint loss function tocapture the logical interactions between positive and negative literal nodes inthe hypergraph. Extensive experiments on various Weighted MaxSAT datasetsdemonstrate that HyperSAT achieves better performance than state-of-the-artcompetitors.</description>
      <author>example@mail.com (Qiyue Chen, Shaolin Tan, Suixiang Gao, Jinhu Lü)</author>
      <guid isPermaLink="false">2504.11885v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets</title>
      <link>http://arxiv.org/abs/2504.11990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at IEEE Symposium on Security and Privacy 2025, 20 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在资源受限的迁移学习场景下如何减轻潜在的后门风险。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在机器学习中变得至关重要，但预训练和下游自适应的结合扩大了攻击面，使模型容易受到复杂后门嵌入的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减轻资源受限的迁移学习场景中的后门风险。&lt;h4&gt;方法&lt;/h4&gt;对现有的防御策略进行了彻底的分析，并引入了T-Core Bootstrapping框架，该框架侧重于识别干净元素。&lt;h4&gt;主要发现&lt;/h4&gt;许多现有的防御策略基于无法扩展到未知威胁、新型攻击类型或不同训练范式的假设。&lt;h4&gt;结论&lt;/h4&gt;T-Core框架在五个基准数据集上对5种编码器中毒攻击、7种数据集中毒攻击和14种基线防御进行了实证评估，证明了其在应对三种潜在后门威胁场景中的有效性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从预训练编码器中进行迁移学习在现代机器学习中变得至关重要，它使得模型能够高效地适应各种任务。然而，这种预训练和下游自适应的结合扩大了攻击面，使模型容易受到编码器和数据集级别的复杂后门嵌入的影响——这是先前研究中经常被忽视的一个领域。此外，预训练编码器用户通常可用的有限计算资源限制了通用后门防御的有效性，与从头开始端到端训练相比。在本工作中，我们研究了如何在资源受限的迁移学习场景中减轻潜在的后门风险。具体而言，我们对现有的防御策略进行了彻底的分析，发现许多策略遵循基于假设的被动工作流程，这些假设无法扩展到未知威胁、新型攻击类型或不同的训练范式。作为回应，我们引入了一种主动的心态，侧重于识别干净元素，并提出了T-Core Bootstrapping框架，该框架强调确定可信数据和神经元的重要性以增强模型的安全性。我们的实证评估证明了T-Core的有效性和优越性，特别是在五个基准数据集上对5种编码器中毒攻击、7种数据集中毒攻击和14种基线防御进行了评估，解决了三种潜在后门威胁的四种场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning from pre-trained encoders has become essential in modernmachine learning, enabling efficient model adaptation across diverse tasks.However, this combination of pre-training and downstream adaptation creates anexpanded attack surface, exposing models to sophisticated backdoor embeddingsat both the encoder and dataset levels--an area often overlooked in priorresearch. Additionally, the limited computational resources typically availableto users of pre-trained encoders constrain the effectiveness of genericbackdoor defenses compared to end-to-end training from scratch. In this work,we investigate how to mitigate potential backdoor risks in resource-constrainedtransfer learning scenarios. Specifically, we conduct an exhaustive analysis ofexisting defense strategies, revealing that many follow a reactive workflowbased on assumptions that do not scale to unknown threats, novel attack types,or different training paradigms. In response, we introduce a proactive mindsetfocused on identifying clean elements and propose the Trusted Core (T-Core)Bootstrapping framework, which emphasizes the importance of pinpointingtrustworthy data and neurons to enhance model security. Our empiricalevaluations demonstrate the effectiveness and superiority of T-Core,specifically assessing 5 encoder poisoning attacks, 7 dataset poisoningattacks, and 14 baseline defenses across five benchmark datasets, addressingfour scenarios of 3 potential backdoor threats.</description>
      <author>example@mail.com (Yechao Zhang, Yuxuan Zhou, Tianyu Li, Minghui Li, Shengshan Hu, Wei Luo, Leo Yu Zhang)</author>
      <guid isPermaLink="false">2504.11990v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Non-uniform Point Cloud Upsampling via Local Manifold Distribution</title>
      <link>http://arxiv.org/abs/2504.11701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于流形分布约束的点云上采样新方法，通过使用高斯函数的拟合能力，迭代优化高斯成分及其权重，提高处理稀疏和非均匀点云时的上采样质量。&lt;h4&gt;背景&lt;/h4&gt;现有的基于学习的点云上采样方法往往忽略了点云的内在数据分布特性，导致处理稀疏和非均匀点云时结果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的点云上采样方法，以解决现有方法在处理稀疏和非均匀点云时的不足。&lt;h4&gt;方法&lt;/h4&gt;使用高斯函数的拟合能力，通过网络迭代优化高斯成分及其权重，构建统一的统计流形对点云施加分布约束。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在处理稀疏和非均匀输入时，生成的密集点云质量更高，分布更均匀，优于现有的点云上采样技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在处理稀疏和非均匀点云上采样方面具有显著优势，能够生成高质量的密集点云。&lt;h4&gt;翻译&lt;/h4&gt;An innovative approach to point cloud upsampling by imposing constraints from the perspective of manifold distributions, using the strong fitting capability of Gaussian functions to iteratively optimize Gaussian components and their weights, and constructing a unified statistical manifold to impose distribution constraints on the point cloud, which has been proven to generate higher-quality and more uniformly distributed dense point clouds compared to existing state-of-the-art techniques.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing learning-based point cloud upsampling methods often overlook theintrinsic data distribution charac?teristics of point clouds, leading tosuboptimal results when handling sparse and non-uniform point clouds. Wepropose a novel approach to point cloud upsampling by imposing constraints fromthe perspective of manifold distributions. Leveraging the strong fittingcapability of Gaussian functions, our method employs a network to iterativelyoptimize Gaussian components and their weights, accurately representing localmanifolds. By utilizing the probabilistic distribution properties of Gaussianfunctions, we construct a unified statistical manifold to impose distributionconstraints on the point cloud. Experimental results on multiple datasetsdemonstrate that our method generates higher-quality and more uniformlydistributed dense point clouds when processing sparse and non-uniform inputs,outperforming state-of-the-art point cloud upsampling techniques.</description>
      <author>example@mail.com (Yaohui Fang, Xingce Wang)</author>
      <guid isPermaLink="false">2504.11701v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs</title>
      <link>http://arxiv.org/abs/2504.11808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two listed authors contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于谱图神经网络（GNN）和神经常微分方程（ODE）的新型联邦学习方法，用于解决GNN训练中数据隐私和可扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;由于隐私、监管和商业竞争等原因，集中化大量现实世界图数据进行GNN训练是不切实际的。&lt;h4&gt;目的&lt;/h4&gt;提出一种联邦学习方法，在保持数据隐私的同时，实现GNN的训练。&lt;h4&gt;方法&lt;/h4&gt;该方法使用谱GNN并配备ODE以更好地捕捉信息，有效处理非独立同分布（non-IID）数据，同时性能可与仅操作于独立同分布（IID）数据的现有方法相媲美。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在同质和异质图上均显示出良好的结果，尤其是在非IID异质图上的联邦学习方面取得了显著的改进。&lt;h4&gt;结论&lt;/h4&gt;该研究突出了联邦学习在多样化和具有挑战性的图环境中的潜力，并提供了开源代码。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Network (GNN) 研究由于 GNN 能够从图结构数据中学习分布式表示而迅速发展。然而，由于隐私关注、监管限制和商业竞争，集中大量现实世界图数据用于 GNN 训练往往是不切实际的。联邦学习 (FL)，一种分布式学习范式，通过协作模型训练保留数据隐私，提供了一个解决方案。尽管在训练大型视觉和语言模型方面取得了进展，但 GNN 的联邦学习仍然未得到充分探索。为了应对这一挑战，我们提出了一种基于谱 GNN 并配备神经常微分方程 (ODE) 的新型联邦学习方法，以更好地捕捉信息，在同质和异质图上显示出有希望的结果。我们的方法有效地处理了非独立同分布（non-IID）数据，同时实现了与仅操作于独立同分布（IID）数据的现有方法相当的性能。它被设计为保护隐私和优化带宽，使其适用于涉及复杂、非 IID 和异质图结构的社会网络分析、推荐系统和欺诈检测等现实世界应用。我们在非 IID 异质图上的联邦学习领域的结果表明了显著的改进，同时在同质图上也实现了更好的性能。这项工作突出了联邦学习在多样化和具有挑战性的图环境中的潜力。GitHub 上有开源代码（https://github.com/SpringWiz11/Fed-GNODEFormer）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN) research is rapidly advancing due to GNNs'capacity to learn distributed representations from graph-structured data.However, centralizing large volumes of real-world graph data for GNN trainingis often impractical due to privacy concerns, regulatory restrictions, andcommercial competition. Federated learning (FL), a distributed learningparadigm, offers a solution by preserving data privacy with collaborative modeltraining. Despite progress in training huge vision and language models,federated learning for GNNs remains underexplored. To address this challenge,we present a novel method for federated learning on GNNs based on spectral GNNsequipped with neural ordinary differential equations (ODE) for betterinformation capture, showing promising results across both homophilic andheterophilic graphs. Our approach effectively handles non-Independent andIdentically Distributed (non-IID) data, while also achieving performancecomparable to existing methods that only operate on IID data. It is designed tobe privacy-preserving and bandwidth-optimized, making it suitable forreal-world applications such as social network analysis, recommendationsystems, and fraud detection, which often involve complex, non-IID, andheterophilic graph structures. Our results in the area of federated learning onnon-IID heterophilic graphs demonstrate significant improvements, while alsoachieving better performance on homophilic graphs. This work highlights thepotential of federated learning in diverse and challenging graph settings.Open-source code available on GitHub(https://github.com/SpringWiz11/Fed-GNODEFormer).</description>
      <author>example@mail.com (Kishan Gurumurthy, Himanshu Pal, Charu Sharma)</author>
      <guid isPermaLink="false">2504.11808v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>FedEPA: Enhancing Personalization and Modality Alignment in Multimodal Federated Learning</title>
      <link>http://arxiv.org/abs/2504.12025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedEPA的联邦学习框架，用于多模态学习，以解决现有FL系统对单模态数据假设和数据标签不足的问题。&lt;h4&gt;背景&lt;/h4&gt;大多数FL系统假设客户端仅持有单模态数据，且缺乏标签数据，这限制了它们在实际中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出FedEPA框架，旨在解决多模态数据和标签数据不足的问题，以提高多模态学习的效果。&lt;h4&gt;方法&lt;/h4&gt;FedEPA采用个性化的局部模型聚合策略，利用客户端上的标签数据学习个性化的聚合权重，以缓解数据异质性的影响。同时，提出了一种无监督的模态对齐策略，将多模态特征分解为对齐特征和上下文特征，并通过对比学习实现跨模态特征的对齐，确保对齐特征与上下文特征在每个模态中的独立性，并促进上下文特征的多样性。此外，引入了一种多模态特征融合策略以获得联合嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在有限的标签数据条件下，FedEPA在多模态分类任务中的性能显著优于现有的FL方法。&lt;h4&gt;结论&lt;/h4&gt;FedEPA框架在处理多模态学习和标签数据不足的问题上具有显著优势，能够有效提升多模态分类任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) enables decentralized model training across multiple parties while preserving privacy. However, most FL systems assume clients hold only unimodal data, limiting their real-world applicability, as institutions often possess multimodal data. Moreover, the lack of labeled data further constrains the performance of most FL methods. In this work, we propose FedEPA, a novel FL framework for multimodal learning. FedEPA employs a personalized local model aggregation strategy that leverages labeled data on clients to learn personalized aggregation weights, thereby alleviating the impact of data heterogeneity. We also propose an unsupervised modality alignment strategy that works effectively with limited labeled data. Specifically, we decompose multimodal features into aligned features and context features. We then employ contrastive learning to align the aligned features across modalities, ensure the independence between aligned features and context features within each modality, and promote the diversity of context features. A multimodal feature fusion strategy is introduced to obtain a joint embedding. The experimental results show that FedEPA significantly outperforms existing FL methods in multimodal classification tasks under limited labeled data conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) enables decentralized model training across multipleparties while preserving privacy. However, most FL systems assume clients holdonly unimodal data, limiting their real-world applicability, as institutionsoften possess multimodal data. Moreover, the lack of labeled data furtherconstrains the performance of most FL methods. In this work, we propose FedEPA,a novel FL framework for multimodal learning. FedEPA employs a personalizedlocal model aggregation strategy that leverages labeled data on clients tolearn personalized aggregation weights, thereby alleviating the impact of dataheterogeneity. We also propose an unsupervised modality alignment strategy thatworks effectively with limited labeled data. Specifically, we decomposemultimodal features into aligned features and context features. We then employcontrastive learning to align the aligned features across modalities, ensurethe independence between aligned features and context features within eachmodality, and promote the diversity of context features. A multimodal featurefusion strategy is introduced to obtain a joint embedding. The experimentalresults show that FedEPA significantly outperforms existing FL methods inmultimodal classification tasks under limited labeled data conditions.</description>
      <author>example@mail.com (Yu Zhang, Qingfeng Du, Jiaqi Lv)</author>
      <guid isPermaLink="false">2504.12025v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video Object Detection</title>
      <link>http://arxiv.org/abs/2504.11779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSGNet的新型多模态时空图学习网络，用于无对齐RGB-T视频目标检测问题，通过利用鲁棒的图表示学习模型，解决了传统RGB-T融合任务中依赖手动对齐多模态图像对的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的RGB视频目标检测在复杂光照条件下存在局限性，而RGB-T视频目标检测可以解决这个问题，使其在实际应用中更加实用和有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需对齐的RGB-T视频目标检测方法，以提高检测的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;1. 设计自适应分区层（APL）来估计热图像在RGB图像中的对应区域，实现初步的不精确对齐。2. 引入空间稀疏图学习模块（S-SGLM），在估计的不精确对齐上采用稀疏信息传递机制，以实现不同模态之间的可靠信息交互。3. 为了充分利用时间线索，引入混合结构时间建模（HSTM），包括时间稀疏图学习模块（T-SGLM）和时间星块（TSB）。T-SGLM通过在时间图上采用稀疏聚合机制来过滤相邻帧之间的冗余信息。TSB致力于实现局部空间关系的互补学习。&lt;h4&gt;主要发现&lt;/h4&gt;在VT-VOD50对齐数据集和UVT-VOD2024非对齐数据集上进行的广泛比较实验证明了所提出方法的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在RGB-T视频目标检测任务中表现出色，将免费公开于网站供公众访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation oftraditional RGB-based VOD in challenging lighting conditions, making it morepractical and effective in many applications.  However, similar to most RGBT fusion tasks, it still mainly relies onmanually aligned multimodal image pairs.  In this paper, we propose a novel Multimodal Spatio-temporal Graph learningNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robustgraph representation learning model.  Specifically, we first design an Adaptive Partitioning Layer (APL) toestimate the corresponding regions of the Thermal image within the RGB image(high-resolution), achieving a preliminary inexact alignment.  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) whichemploys a sparse information passing mechanism on the estimated inexactalignment to achieve reliable information interaction between differentmodalities.  Moreover, to fully exploit the temporal cues for RGBT VOD problem, weintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a TemporalSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLMaims to filter out some redundant information between adjacent frames byemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,TSB is dedicated to achieving the complementary learning of local spatialrelationships.  Extensive comparative experiments conducted on both the aligned datasetVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectivenessand superiority of our proposed method. Our project will be made available onour website for free public access.</description>
      <author>example@mail.com (Qishun Wang, Zhengzheng Tu, Chenglong Li, Bo Jiang)</author>
      <guid isPermaLink="false">2504.11779v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2504.11893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Context-Aware Gaussian Splatting (CAGS)的新框架，用于解决开放词汇3D场景理解中的跨视图粒度不一致性问题，通过引入空间上下文信息，提高了3D实例分割的准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;开放词汇3D场景理解对于需要自然语言驱动的空间解释的应用至关重要，如机器人和增强现实。3D Gaussian Splatting (3DGS) 提供了一种强大的场景重建表示方法，但其与开放词汇框架的结合面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CAGS框架，以解决3DGS在开放词汇框架中遇到的关键挑战：跨视图粒度不一致性。&lt;h4&gt;方法&lt;/h4&gt;CAGS通过以下方式解决挑战：构建局部图传播上下文特征、采用以掩码为中心的对比学习平滑来自SAM的特征、利用预计算策略减少计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;CAGS显著提高了3D实例分割的准确性，并减少了在LERF-OVS和ScanNet等数据集上的碎片化错误。&lt;h4&gt;结论&lt;/h4&gt;通过整合空间上下文，CAGS实现了鲁棒的基于语言的3D场景理解。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary 3D scene understanding is crucial for applications requiring natural language-driven spatial interpretation, such as robotics and augmented reality. While 3D Gaussian Splatting (3DGS) offers a powerful representation for scene reconstruction, integrating it with open-vocabulary frameworks reveals a key challenge: cross-view granularity inconsistency. This issue, stemming from 2D segmentation methods like SAM, results in inconsistent object segmentations across views (e.g., a 'coffee set' segmented as a single entity in one view but as 'cup + coffee + spoon' in another). Existing 3DGS-based methods often rely on isolated per-Gaussian feature learning, neglecting the spatial context needed for cohesive object reasoning, leading to fragmented representations. We propose Context-Aware Gaussian Splatting (CAGS), a novel framework that addresses this challenge by incorporating spatial context into 3DGS. CAGS constructs local graphs to propagate contextual features across Gaussians, reduces noise from inconsistent granularity, employs mask-centric contrastive learning to smooth SAM-derived features across views, and leverages a precomputation strategy to reduce computational cost by precomputing neighborhood relationships, enabling efficient training in large-scale scenes. By integrating spatial context, CAGS significantly improves 3D instance segmentation and reduces fragmentation errors on datasets like LERF-OVS and ScanNet, enabling robust language-guided 3D scene understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D scene understanding is crucial for applications requiringnatural language-driven spatial interpretation, such as robotics and augmentedreality. While 3D Gaussian Splatting (3DGS) offers a powerful representationfor scene reconstruction, integrating it with open-vocabulary frameworksreveals a key challenge: cross-view granularity inconsistency. This issue,stemming from 2D segmentation methods like SAM, results in inconsistent objectsegmentations across views (e.g., a "coffee set" segmented as a single entityin one view but as "cup + coffee + spoon" in another). Existing 3DGS-basedmethods often rely on isolated per-Gaussian feature learning, neglecting thespatial context needed for cohesive object reasoning, leading to fragmentedrepresentations. We propose Context-Aware Gaussian Splatting (CAGS), a novelframework that addresses this challenge by incorporating spatial context into3DGS. CAGS constructs local graphs to propagate contextual features acrossGaussians, reducing noise from inconsistent granularity, employs mask-centriccontrastive learning to smooth SAM-derived features across views, and leveragesa precomputation strategy to reduce computational cost by precomputingneighborhood relationships, enabling efficient training in large-scale scenes.By integrating spatial context, CAGS significantly improves 3D instancesegmentation and reduces fragmentation errors on datasets like LERF-OVS andScanNet, enabling robust language-guided 3D scene understanding.</description>
      <author>example@mail.com (Wei Sun, Yanzhao Zhou, Jianbin Jiao, Yuan Li)</author>
      <guid isPermaLink="false">2504.11893v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization</title>
      <link>http://arxiv.org/abs/2504.11840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脉冲神经网络（SNN）的线性时间图变换器（GT-SVQ），用于节点分类，旨在解决传统图变换器（GTs）在处理大规模图时的复杂性和能耗问题。&lt;h4&gt;背景&lt;/h4&gt;图变换器（GTs）在图预测任务中表现出色，但其在处理大规模图时存在复杂度和能耗问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图变换器方法，以降低计算和存储开销，提高节点分类的效率。&lt;h4&gt;方法&lt;/h4&gt;GT-SVQ通过脉冲神经元输出重构码本，并将码本注入自注意力块中，以线性复杂度聚合全局信息。此外，脉冲向量量化（SVQ）有效缓解了码本崩溃和依赖复杂机制的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GT-SVQ在大多数数据集上取得了与最先进基准相当的性能，同时比其他GTs快130倍。&lt;h4&gt;结论&lt;/h4&gt;GT-SVQ是一种有效的节点分类方法，能够显著提高计算效率，适用于大规模图处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs), which simultaneously integrate message-passing andself-attention mechanisms, have achieved promising empirical results in somegraph prediction tasks. Although these approaches show the potential ofTransformers in capturing long-range graph topology information, issuesconcerning the quadratic complexity and high computing energy consumptionseverely limit the scalability of GTs on large-scale graphs. Recently, asbrain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate thedevelopment of graph representation learning methods with lower computationaland storage overhead through the unique event-driven spiking neurons. Inspiredby these characteristics, we propose a linear-time Graph Transformer usingSpiking Vector Quantization (GT-SVQ) for node classification. GT-SVQreconstructs codebooks based on rate coding outputs from spiking neurons, andinjects the codebooks into self-attention blocks to aggregate globalinformation in linear complexity. Besides, spiking vector quantizationeffectively alleviates codebook collapse and the reliance on complex machinery(distance measure, auxiliary loss, etc.) present in previous vectorquantization-based graph learning methods. In experiments, we compare GT-SVQwith other state-of-the-art baselines on node classification datasets rangingfrom small to large. Experimental results show that GT-SVQ has achievedcompetitive performances on most datasets while maintaining up to 130x fasterinference speed compared to other GTs.</description>
      <author>example@mail.com (Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2504.11840v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</title>
      <link>http://arxiv.org/abs/2504.11218v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first large-scale 3D Gaussians Affordance Reasoning Benchmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D高斯散布（3DGS）的3D affordance reasoning方法，并构建了首个大规模多模态数据集3DAffordSplat，同时引入了AffordSplatNet模型，提高了affordance recognition的准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;3D affordance reasoning对于将人类指令与3D物体的功能区域关联起来至关重要，但现有方法依赖于稀疏的3D点云，存在泛化性和鲁棒性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出3DAffordSplat数据集和AffordSplatNet模型，以克服现有方法的局限性，提高affordance recognition的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;构建了包含23,677个高斯实例、8,354个点云实例和6,631个手动标注的affordance标签的大规模数据集3DAffordSplat。基于此数据集，设计了AffordSplatNet模型，该模型具有创新的跨模态结构对齐模块，用于对齐3D点云和3DGS表示。&lt;h4&gt;主要发现&lt;/h4&gt;3DAffordSplat数据集显著推进了3DGS领域的affordance学习，AffordSplatNet在已见和未见场景下均优于现有方法，显示出其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;3DGS在affordance reasoning中具有巨大潜力，通过构建大规模数据集和设计特定模型，可以显著提高affordance recognition的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D affordance reasoning is essential in associating human instructions withthe functional regions of 3D objects, facilitating precise, task-orientedmanipulations in embodied AI. However, current methods, which predominantlydepend on sparse 3D point clouds, exhibit limited generalizability androbustness due to their sensitivity to coordinate variations and the inherentsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivershigh-fidelity, real-time rendering with minimal computational overhead byrepresenting scenes as dense, continuous distributions. This positions 3DGS asa highly effective approach for capturing fine-grained affordance details andimproving recognition accuracy. Nevertheless, its full potential remainslargely untapped due to the absence of large-scale, 3DGS-specific affordancedatasets. To overcome these limitations, we present 3DAffordSplat, the firstlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.This dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,and 6,631 manually annotated affordance labels, encompassing 21 objectcategories and 18 affordance types. Building upon this dataset, we introduceAffordSplatNet, a novel model specifically designed for affordance reasoningusing 3DGS representations. AffordSplatNet features an innovative cross-modalstructure alignment module that exploits structural consistency priors to align3D point cloud and 3DGS representations, resulting in enhanced affordancerecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplatdataset significantly advances affordance learning within the 3DGS domain,while AffordSplatNet consistently outperforms existing methods across both seenand unseen settings, highlighting its robust generalization capabilities.</description>
      <author>example@mail.com (Zeming Wei, Junyi Lin, Yang Liu, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin)</author>
      <guid isPermaLink="false">2504.11218v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Multi-View Stereo with Depth Foundation Model in the Absence of Real-World Labels</title>
      <link>http://arxiv.org/abs/2504.11845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度基础模型的多视图立体（MVS）方法DFM-MVS，用于在缺乏真实世界标签的情况下训练网络，并显著提升了MVS的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于学习的MVS方法取得了显著进展，但如何在没有真实世界标签的情况下有效地训练网络仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的方法，利用深度基础模型生成有效的深度先验，以在没有真实世界标签的情况下提升MVS的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度先验的伪监督训练机制，用于模拟真实的立体对应关系，从而为MVS网络构建有效的监督。此外，还提出了一种基于深度先验的误差校正策略，以减轻粗到细网络结构中固有的误差传播问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的DFM-MVS在DTU和Tanks &amp; Temples数据集上显著优于现有的MVS方法，且无需使用真实世界标签。&lt;h4&gt;结论&lt;/h4&gt;DFM-MVS是一种有效的MVS方法，可以在没有真实世界标签的情况下显著提升MVS的性能。&lt;h4&gt;翻译&lt;/h4&gt;Based on the recent advancements of vision foundation models, this paper proposes a novel method named DFM-MVS to leverage the depth foundation model to generate effective depth prior, so as to enhance the performance of MVS in the absence of real-world labels. Specifically, a depth prior-based pseudo-supervised training mechanism is developed to simulate realistic stereo correspondences using the generated depth prior, thereby constructing effective supervision for the MVS network. Besides, a depth prior-guided error correction strategy is presented to leverage the depth prior as guidance to mitigate the error propagation problem inherent in the widely-used coarse-to-fine network structure. Experimental results on DTU and Tanks &amp; Temples datasets demonstrate that the proposed DFM-MVS significantly outperforms existing MVS methods without using real-world labels.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based Multi-View Stereo (MVS) methods have made remarkable progressin recent years. However, how to effectively train the network without usingreal-world labels remains a challenging problem. In this paper, driven by therecent advancements of vision foundation models, a novel method termed DFM-MVS,is proposed to leverage the depth foundation model to generate the effectivedepth prior, so as to boost MVS in the absence of real-world labels.Specifically, a depth prior-based pseudo-supervised training mechanism isdeveloped to simulate realistic stereo correspondences using the generateddepth prior, thereby constructing effective supervision for the MVS network.Besides, a depth prior-guided error correction strategy is presented toleverage the depth prior as guidance to mitigate the error propagation probleminherent in the widely-used coarse-to-fine network structure. Experimentalresults on DTU and Tanks &amp; Temples datasets demonstrate that the proposedDFM-MVS significantly outperforms existing MVS methods without using real-worldlabels.</description>
      <author>example@mail.com (Jie Zhu, Bo Peng, Zhe Zhang, Bingzheng Liu, Jianjun Lei)</author>
      <guid isPermaLink="false">2504.11845v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Universal Vibration Analysis Dataset: A Framework for Transfer Learning in Predictive Maintenance and Structural Health Monitoring</title>
      <link>http://arxiv.org/abs/2504.11581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于振动分析的通用数据集框架，旨在通过预训练和微调提高模型性能，并推动预测维护、结构健康监测等领域的发展。&lt;h4&gt;背景&lt;/h4&gt;ImageNet在迁移学习方面取得了成功，但振动分析领域缺乏类似的大型标注数据集。&lt;h4&gt;目的&lt;/h4&gt;创建一个适用于振动分析的大规模、标注数据集，以促进振动分析领域的发展。&lt;h4&gt;方法&lt;/h4&gt;提出的数据集框架以轴承振动数据为基础，收集了来自多个公开数据集的振动信号。使用深度学习架构进行实验，展示在预训练和微调后的模型性能提升。&lt;h4&gt;主要发现&lt;/h4&gt;使用预训练和微调的模型在轴承振动数据集上表现出色，这表明该框架在振动分析领域具有与ImageNet在视觉计算领域相似的潜力。&lt;h4&gt;结论&lt;/h4&gt;该数据集有望标准化振动数据预处理、特征提取和模型训练的方法，加速预测维护、结构健康监测等领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：ImageNet已经成为迁移学习的一个可靠资源，它使得开发高效的机器学习模型成为可能，减少了训练时间和数据需求。然而，在预测维护、结构健康监测和故障诊断中的振动分析，缺乏一个类似的大型、标注数据集来促进类似的进步。为了解决这个问题，提出了一种数据集框架，它从轴承振动数据作为创建适用于所有机械的基于振动频谱分析通用数据集的第一步。该初始框架包括来自多个公开数据集的轴承振动信号的集合。为了证明该框架的优势，使用深度学习架构进行了实验，显示在预训练于轴承振动数据并微调于较小的特定领域数据集时，模型性能得到了提高。这些发现突出了在振动分析领域与ImageNet在视觉计算领域成功并驾齐驱的潜力。对于未来的工作，这项研究将包括来自多种类型机械的更广泛的振动信号，强调基于频谱的数据表示。每个样本将根据机械类型、操作状态以及故障的存在或类型进行标记，确保其用于监督和无监督学习任务的实用性。此外，将开发一个专门针对振动数据的数据预处理、特征提取和模型训练框架。这个框架将标准化研究社区的方法，允许合作并加速预测维护、结构健康监测和相关领域的研究进展。通过模仿ImageNet在视觉计算中的成功，这个数据集有望改善工业应用中智能系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; ImageNet has become a reputable resource for transfer learning, allowing thedevelopment of efficient ML models with reduced training time and datarequirements. However, vibration analysis in predictive maintenance, structuralhealth monitoring, and fault diagnosis, lacks a comparable large-scale,annotated dataset to facilitate similar advancements. To address this, adataset framework is proposed that begins with bearing vibration data as aninitial step towards creating a universal dataset for vibration-basedspectrogram analysis for all machinery. The initial framework includes acollection of bearing vibration signals from various publicly availabledatasets. To demonstrate the advantages of this framework, experiments wereconducted using a deep learning architecture, showing improvements in modelperformance when pre-trained on bearing vibration data and fine-tuned on asmaller, domain-specific dataset. These findings highlight the potential toparallel the success of ImageNet in visual computing but for vibrationanalysis. For future work, this research will include a broader range ofvibration signals from multiple types of machinery, emphasizingspectrogram-based representations of the data. Each sample will be labeledaccording to machinery type, operational status, and the presence or type offaults, ensuring its utility for supervised and unsupervised learning tasks.Additionally, a framework for data preprocessing, feature extraction, and modeltraining specific to vibration data will be developed. This framework willstandardize methodologies across the research community, allowing forcollaboration and accelerating progress in predictive maintenance, structuralhealth monitoring, and related fields. By mirroring the success of ImageNet invisual computing, this dataset has the potential to improve the development ofintelligent systems in industrial applications.</description>
      <author>example@mail.com (Mert Sehri, Igor Varejão, Zehui Hua, Vitor Bonella, Adriano Santos, Francisco de Assis Boldt, Patrick Dumond, Flavio Miguel Varejão)</author>
      <guid isPermaLink="false">2504.11581v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards Forceful Robotic Foundation Models: a Literature Survey</title>
      <link>http://arxiv.org/abs/2504.11827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了机器人操作策略学习中的力整合方法，包括本体感觉和触觉感知。&lt;h4&gt;背景&lt;/h4&gt;文章回顾了力、数据收集、行为克隆、触觉表征学习和低级机器人控制等方法的比较分析。&lt;h4&gt;目的&lt;/h4&gt;明确何时以及为什么需要力，并突出提高基于触觉的机器人基础模型的学习机会。&lt;h4&gt;方法&lt;/h4&gt;进行了关于感力量、数据收集、行为克隆、触觉表征学习和低级机器人控制方法的比较分析。&lt;h4&gt;主要发现&lt;/h4&gt;尽管有如倒水、钉孔插入和搬运精细物体等任务，但模仿学习模型的性能并未达到力真正起作用的高度动态水平。&lt;h4&gt;结论&lt;/h4&gt;力和触觉是可以通过多种方式推断的抽象量，通常隐性地测量和控制。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了在机器人操作策略学习过程中，如何整合包括本体感觉和触觉感知在内的力的方法。我们对感力量、数据收集、行为克隆、触觉表征学习和低级机器人控制等多种方法进行了比较分析。通过分析，我们明确了力的需求及其原因，并强调了在向高度智能的触觉机器人基础模型发展的过程中，提高富含接触信息的通用机器人策略学习的机会。总的来说，尽管存在像倒水、钉孔插入和搬运精细物体等少数任务，但模仿学习模型的性能还没有达到力真正起作用的高度动态水平。此外，力和触觉是可以通过广泛的方式推断的抽象量，它们通常被隐性地测量和控制。我们希望通过比较当前使用的不同方法，帮助读者获得系统的理解，并激发下一代机器人基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article reviews contemporary methods for integrating force, includingboth proprioception and tactile sensing, in robot manipulation policy learning.We conduct a comparative analysis on various approaches for sensing force, datacollection, behavior cloning, tactile representation learning, and low-levelrobot control. From our analysis, we articulate when and why forces are needed,and highlight opportunities to improve learning of contact-rich, generalistrobot policies on the path toward highly capable touch-based robot foundationmodels. We generally find that while there are few tasks such as pouring,peg-in-hole insertion, and handling delicate objects, the performance ofimitation learning models is not at a level of dynamics where force trulymatters. Also, force and touch are abstract quantities that can be inferredthrough a wide range of modalities and are often measured and controlledimplicitly. We hope that juxtaposing the different approaches currently in usewill help the reader to gain a systemic understanding and help inspire the nextgeneration of robot foundation models.</description>
      <author>example@mail.com (William Xie, Nikolaus Correll)</author>
      <guid isPermaLink="false">2504.11827v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Extended Short- and Long-Range Mesh Learning for Fast and Generalized Garment Simulation</title>
      <link>http://arxiv.org/abs/2504.11763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的新型三维服装模拟框架，通过LSDMP和GSA模块提高模拟效率。&lt;h4&gt;背景&lt;/h4&gt;3D服装模拟是生产基于布料的图形的关键组成部分，而GNN在服装模拟方面展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;为了解决GNN在模拟中信息传播和接触感知的效率问题。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含LSDMP和GSA模块的GNN框架，LSDMP通过拉普拉斯特征平滑过程增强信息传播，GSA则通过引入测地距离嵌入和注意力机制来捕捉全局网格信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在减少层数和降低推理延迟的同时，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的GNN框架为高效的三维服装模拟提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D garment simulation is a critical component for producing cloth-basedgraphics. Recent advancements in graph neural networks (GNNs) offer a promisingapproach for efficient garment simulation. However, GNNs require extensivemessage-passing to propagate information such as physical forces and maintaincontact awareness across the entire garment mesh, which becomes computationallyinefficient at higher resolutions. To address this, we devise a novel GNN-basedmesh learning framework with two key components to extend the message-passingrange with minimal overhead, namely the Laplacian-Smoothed Dual Message-Passing(LSDMP) and the Geodesic Self-Attention (GSA) modules. LSDMP enhancesmessage-passing with a Laplacian features smoothing process, which efficientlypropagates the impact of each vertex to nearby vertices. Concurrently, GSAintroduces geodesic distance embeddings to represent the spatial relationshipbetween vertices and utilises attention mechanisms to capture global meshinformation. The two modules operate in parallel to ensure both short- andlong-range mesh modelling. Extensive experiments demonstrate thestate-of-the-art performance of our method, requiring fewer layers and lowerinference latency.</description>
      <author>example@mail.com (Aoran Liu, Kun Hu, Clinton Mo, Changyang Li, Zhiyong Wang)</author>
      <guid isPermaLink="false">2504.11763v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</title>
      <link>http://arxiv.org/abs/2504.11536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ReTool的推理模型，该模型通过工具集成学习增强了长文本推理能力，特别适用于需要结构化问题解决的场景，如几何推理、简洁计算或复杂方程求解。&lt;h4&gt;背景&lt;/h4&gt;尽管基于强化学习的推理模型在文本推理方面表现出色，但在需要结构化问题解决的场景中表现不佳，如几何推理、简洁计算或复杂方程求解，这些场景中计算工具（如代码解释器）具有明显优势。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，提出了ReTool模型，旨在通过工具集成学习提升长文本推理能力。&lt;h4&gt;方法&lt;/h4&gt;ReTool模型具有两个关键特性：(1) 在自然语言推理过程中动态交织实时代码执行；(2) 一种自动化的强化学习范式，允许进行多轮实时代码执行的政策展开，并根据结果反馈来指导模型何时以及如何调用工具。ReTool采用系统性的训练框架，从生成合成冷启动数据开始，以生产代码增强的长文本推理轨迹，用于微调基础模型。后续的RL训练利用任务结果作为奖励，迭代地改进模型的工具使用策略，使模型能够自主发现最优的工具调用模式。&lt;h4&gt;主要发现&lt;/h4&gt;在MATH奥林匹克基准AIME上的实验表明，ReTool模型优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，比OpenAI的o1-preview高出27.9%。进一步的分析揭示了代码自我纠正等新兴行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了基于结果驱动的工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然使用强化学习（如DeepSeek R1）训练的推理模型在文本推理方面表现出色，但在需要结构化问题解决的场景中，如几何推理、简洁计算或复杂方程求解等方面存在困难，这些领域是计算工具（如代码解释器）具有明显优势的地方。为了弥合这一差距，我们提出了ReTool，它通过工具集成学习增强了长文本推理能力，包括两个关键特性：(1) 在自然语言推理过程中动态交织实时代码执行；(2) 一种自动化的强化学习范式，允许进行多轮实时代码执行的政策展开，并根据结果反馈来指导模型何时以及如何调用工具。ReTool采用系统性的训练框架，从生成合成冷启动数据开始，以生产代码增强的长文本推理轨迹，用于微调基础模型。后续的RL训练利用任务结果作为奖励，迭代地改进模型的工具使用策略，使模型能够自主发现最优的工具调用模式。在具有挑战性的MATH奥林匹克基准AIME上的实验表明，ReTool模型优于基于文本的强化学习基线。ReTool-32B模型在400个训练步骤后达到67%的准确率，在效率和性能上优于基线（40%的准确率，1080个步骤）。在扩展设置中，ReTool-32B达到72.5%的准确率，比OpenAI的o1-preview高出27.9%。进一步的分析揭示了代码自我纠正等新兴行为，表明模型在自主掌握适应性工具使用时达到了“啊哈”时刻。这些发现突出了基于结果驱动的工具集成在推进复杂数学推理方面的潜力，并为混合神经符号系统提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While reasoning models (e.g., DeepSeek R1) trained with reinforcementlearning (RL), excel in textual reasoning, they struggle in scenarios requiringstructured problem-solving, such as geometric reasoning, concise computation,or complex equation solving-areas where computational tools like codeinterpreters (CI) demonstrate distinct advantages. To bridge this gap, wepropose ReTool, which enhances long-form reasoning with tool-integratedlearning, including two key features: (1) dynamic interleaving of real-timecode execution within natural language reasoning processes, and (2) anautomated RL paradigm that allows policy rollouts with multi-turn real-timecode execution and teaches the model in learning when and how to invoke toolsbased on outcome feedback. ReTool employs a systematic training framework,beginning with synthetic cold-start data generation to produce code-augmentedlong-form reasoning traces for fine-tuning base models. Subsequent RL trainingleverages task outcomes as rewards to iteratively refine the model's tool usestrategy, enabling autonomous discovery of optimal tool invocation patternswithout human priors. Experiments on the challenging MATH Olympiad benchmarkAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with400 training steps, outperforming text-based RL baseline (40% accuracy, 1080steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Furtheranalysis reveals emergent behaviors such as code self-correction, signaling an''aha moment'' in which the model autonomously masters adaptive tool use. Thesefindings highlight the promise of outcome-driven tool integration for advancingcomplex mathematical reasoning and offer new insights into hybridneuro-symbolic systems.</description>
      <author>example@mail.com (Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong)</author>
      <guid isPermaLink="false">2504.11536v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Clustering and analysis of user behaviour in blockchain: A case study of Planet IX</title>
      <link>http://arxiv.org/abs/2504.11702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, submitted to Blockchain: Research and  Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于公共区块链的dApps的隐私问题，提出了一种用户行为分析流程，用于提取和分析用户在游戏中的行为，并使用图神经网络和聚类算法对用户行为进行分类。&lt;h4&gt;背景&lt;/h4&gt;公共区块链上的dApps具有透明性和可信性，但同时也存在隐私泄露的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种用户行为分析流程，以识别用户在游戏中的行为模式，并评估其隐私风险。&lt;h4&gt;方法&lt;/h4&gt;1. 收集基于区块链游戏Planet IX的交易数据，包括智能合约和交易事件。2. 从数据中形成游戏动作，并形成用户流程。3. 使用扩展的用户流程展示NFT在用户行为中的应用。4. 将用户流程作为输入，使用图神经网络模型提供图嵌入。5. 利用聚类算法将用户行为聚类。6. 对比评估了多种聚类算法。7. 分析和可视化用户行为聚类。&lt;h4&gt;主要发现&lt;/h4&gt;1. 用户行为信息可以揭示用户行为模式。2. 恶意用户可能利用这些信息。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以有效地识别用户行为，但同时也存在隐私风险。&lt;h4&gt;翻译&lt;/h4&gt;Decentralised applications (dApps) that run on public blockchains have the benefit of trustworthiness and transparency as every activity that happens on the blockchain can be publicly traced through the transaction data. However, this introduces a potential privacy problem as this data can be tracked and analyzed, which can reveal user-behavior information. A user behavior analysis pipeline was proposed to present how this type of information can be extracted and analyzed to identify separate behavioral clusters that can describe how users behave in the game. The pipeline starts with the collection of transaction data, involving smart contracts, that is collected from a blockchain-based game called Planet IX. Both the raw transaction information and the transaction events are considered in the data collection. From this data, separate game actions can be formed and those are leveraged to present how and when the users conducted their in-game activities in the form of user flows. An extended version of these user flows also presents how the Non-Fungible Tokens (NFTs) are being leveraged in the user actions. The latter is given as input for a Graph Neural Network (GNN) model to provide graph embeddings for these flows which then can be leveraged by clustering algorithms to cluster user behaviors into separate behavioral clusters. We benchmark and compare well-known clustering algorithms as a part of the proposed method. The user behavior clusters were analyzed and visualized in a graph format. It was found that behavioral information can be extracted regarding the users that belong to these clusters. Such information can be exploited by malicious users to their advantage. To demonstrate this, a privacy threat model was also presented based on the results that correspond to multiple potentially affected areas.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decentralised applications (dApps) that run on public blockchains have thebenefit of trustworthiness and transparency as every activity that happens onthe blockchain can be publicly traced through the transaction data. However,this introduces a potential privacy problem as this data can be tracked andanalysed, which can reveal user-behaviour information. A user behaviouranalysis pipeline was proposed to present how this type of information can beextracted and analysed to identify separate behavioural clusters that candescribe how users behave in the game. The pipeline starts with the collectionof transaction data, involving smart contracts, that is collected from ablockchain-based game called Planet IX. Both the raw transaction informationand the transaction events are considered in the data collection. From thisdata, separate game actions can be formed and those are leveraged to presenthow and when the users conducted their in-game activities in the form of userflows. An extended version of these user flows also presents how theNon-Fungible Tokens (NFTs) are being leveraged in the user actions. The latteris given as input for a Graph Neural Network (GNN) model to provide graphembeddings for these flows which then can be leveraged by clustering algorithmsto cluster user behaviours into separate behavioural clusters. We benchmark andcompare well-known clustering algorithms as a part of the proposed method. Theuser behaviour clusters were analysed and visualised in a graph format. It wasfound that behavioural information can be extracted regarding the users thatbelong to these clusters. Such information can be exploited by malicious usersto their advantage. To demonstrate this, a privacy threat model was alsopresented based on the results that correspond to multiple potentially affectedareas.</description>
      <author>example@mail.com (Dorottya Zelenyanszki, Zhe Hou, Kamanashis Biswas, Vallipuram Muthukkumarasamy)</author>
      <guid isPermaLink="false">2504.11702v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation</title>
      <link>http://arxiv.org/abs/2504.11786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The IEEE/CVF Conference on Computer Vision and Pattern Recognition  (CVPR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种名为DART的框架，旨在通过自动生成放射学报告来提高报告的准确性。&lt;h4&gt;背景&lt;/h4&gt;自动生成放射学报告已成为一种减少耗时任务并准确捕捉X射线图像中疾病相关发现的有前景解决方案。&lt;h4&gt;目的&lt;/h4&gt;旨在通过确保检索的报告包含与X射线图像中相似的疾病相关发现，并改进生成的报告，进一步提高报告的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种疾病感知的图像-文本对齐和自校正重对齐方法，分为两个阶段：首先基于图像到文本的检索和疾病匹配生成初始报告，然后将报告与X射线图像重新对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在两个广泛使用的基准测试中取得了最先进的结果，在报告生成和临床效度指标方面均优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;该框架增强了放射学报告的可信度，为放射学报告的自动化生成提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The automatic generation of radiology reports has emerged as a promisingsolution to reduce a time-consuming task and accurately capture criticaldisease-relevant findings in X-ray images. Previous approaches for radiologyreport generation have shown impressive performance. However, there remainssignificant potential to improve accuracy by ensuring that retrieved reportscontain disease-relevant findings similar to those in the X-ray images and byrefining generated reports. In this study, we propose a Disease-awareimage-text Alignment and self-correcting Re-alignment for Trustworthy radiologyreport generation (DART) framework. In the first stage, we generate initialreports based on image-to-text retrieval with disease-matching, embedding bothimages and texts in a shared embedding space through contrastive learning. Thisapproach ensures the retrieval of reports with similar disease-relevantfindings that closely align with the input X-ray images. In the second stage,we further enhance the initial reports by introducing a self-correction modulethat re-aligns them with the X-ray images. Our proposed framework achievesstate-of-the-art results on two widely used benchmarks, surpassing previousapproaches in both report generation and clinical efficacy metrics, therebyenhancing the trustworthiness of radiology reports.</description>
      <author>example@mail.com (Sang-Jun Park, Keun-Soo Heo, Dong-Hee Shin, Young-Han Son, Ji-Hye Oh, Tae-Eui Kam)</author>
      <guid isPermaLink="false">2504.11786v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Real-World Depth Recovery via Structure Uncertainty Modeling and Inaccurate GT Depth Fitting</title>
      <link>http://arxiv.org/abs/2504.11820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对真实世界RGB-D数据集中原始深度图低质量结构问题的深度恢复方法，该方法通过设计新的深度生成流程和结构不确定性模块，提高了深度恢复的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在真实世界RGB-D数据集中，原始深度图普遍存在低质量结构，这使得深度恢复成为一项关键任务。然而，缺乏配对的原始-真实深度数据（raw-GT）数据给泛化深度恢复带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提高真实世界深度恢复的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 设计新的原始深度生成流程，丰富原始深度图中结构错位多样性，避免网络对特定条件过拟合。2. 设计结构不确定性模块，明确识别输入原始深度图中的错位结构，以更好地泛化到未见过的场景。3. 训练好的深度基础模型（DFM）帮助结构不确定性模块更好地估计结构不确定性。4. 设计鲁棒的特征对齐模块，精确对齐RGB图像的准确结构，避免不准确的真实深度的影响。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上的实验表明，在各种具有挑战性的原始深度图中，该方法实现了具有竞争力的准确性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过设计新的深度生成流程和结构不确定性模块，有效地提高了真实世界深度恢复的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;The low-quality structure in raw depth maps is prevalent in real-world RGB-D datasets, which makes real-world depth recovery a critical task in recent years. However, the lack of paired raw-ground truth (raw-GT) data in the real world poses challenges for generalized depth recovery. Existing methods insufficiently consider the diversity of structure misalignment in raw depth maps, which leads to poor generalization in real-world depth recovery. Notably, random structure misalignments are not limited to raw depth data but also affect GT depth in real-world datasets. In the proposed method, we tackle the generalization problem from both input and output perspectives. For input, we enrich the diversity of structure misalignment in raw depth maps by designing a new raw depth generation pipeline, which helps the network avoid overfitting to a specific condition. Furthermore, a structure uncertainty module is designed to explicitly identify the misaligned structure for input raw depth maps to better generalize in unseen scenarios. Notably the well-trained depth foundation model (DFM) can help the structure uncertainty module estimate the structure uncertainty better. For output, a robust feature alignment module is designed to precisely align with the accurate structure of RGB images avoiding the interference of inaccurate GT depth. Extensive experiments on multiple datasets demonstrate the proposed method achieves competitive accuracy and generalization capabilities across various challenging raw depth maps.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The low-quality structure in raw depth maps is prevalent in real-world RGB-Ddatasets, which makes real-world depth recovery a critical task in recentyears. However, the lack of paired raw-ground truth (raw-GT) data in the realworld poses challenges for generalized depth recovery. Existing methodsinsufficiently consider the diversity of structure misalignment in raw depthmaps, which leads to poor generalization in real-world depth recovery. Notably,random structure misalignments are not limited to raw depth data but alsoaffect GT depth in real-world datasets. In the proposed method, we tackle thegeneralization problem from both input and output perspectives. For input, weenrich the diversity of structure misalignment in raw depth maps by designing anew raw depth generation pipeline, which helps the network avoid overfitting toa specific condition. Furthermore, a structure uncertainty module is designedto explicitly identify the misaligned structure for input raw depth maps tobetter generalize in unseen scenarios. Notably the well-trained depthfoundation model (DFM) can help the structure uncertainty module estimate thestructure uncertainty better. For output, a robust feature alignment module isdesigned to precisely align with the accurate structure of RGB images avoidingthe interference of inaccurate GT depth. Extensive experiments on multipledatasets demonstrate the proposed method achieves competitive accuracy andgeneralization capabilities across various challenging raw depth maps.</description>
      <author>example@mail.com (Delong Suzhang, Meng Yang)</author>
      <guid isPermaLink="false">2504.11820v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>H$^3$GNNs: Harmonizing Heterophily and Homophily in GNNs via Joint Structural Node Encoding and Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2504.11699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;H$^3$GNNs是一种端到端自监督学习框架，通过两种关键创新解决了GNNs在异质性和同质性问题上的挑战，并在多个基准数据集上取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;GNNs在异质性和同质性的平衡上存在困难，特别是在自监督学习设置中。&lt;h4&gt;目的&lt;/h4&gt;提出H$^3$GNNs框架，以解决GNNs在自监督学习中的异质性和同质性问题。&lt;h4&gt;方法&lt;/h4&gt;H$^3$GNNs通过以下两种方法实现平衡：(i) 联合结构节点编码，使用加权图卷积网络结合线性和非线性特征投影以及K-hop结构表示；(ii) 使用教师-学生预测架构，并引入节点难度驱动的动态掩码策略。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集（四个异质性和三个同质性数据集）上的实验证实了H$^3$GNNs的有效性和效率，在四个异质性数据集上达到了最先进的性能，在三个同质性数据集上保持了与之前最先进方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;H$^3$GNNs是一种有效的框架，可以解决GNNs在自监督学习中的异质性和同质性问题，并在多个图类型的数据集上取得了优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs)在表示学习中难以平衡异质性和同质性，这一挑战在自监督设置中进一步加剧。我们提出了H$^3$GNNs，这是一种端到端自监督学习框架，通过两种关键创新来协调这两种结构属性：(i) 联合结构节点编码。我们通过加权图卷积网络(WGCN)将节点嵌入到一个统一的空间中，该空间结合了线性和非线性特征投影以及K-hop结构表示。跨注意力机制增强了对外异质性和同质性的意识和适应性。(ii) 使用教师-学生预测架构，并采用节点难度驱动的动态掩码策略进行自监督学习。我们使用教师-学生模型，学生看到掩码输入图，并预测教师推断的节点特征，而教师看到的是联合编码空间中的完整输入图。为了提高学习难度，我们引入了两种基于节点预测难度的创新掩码策略。在七个基准（四个异质性和三个同质性数据集）上的实验证实了H$^3$GNNs在多种图类型上的有效性和效率。我们的H$^3$GNNs在四个异质性数据集上实现了整体最先进的性能，同时在三个同质性数据集上保持了与之前最先进方法相当的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) struggle to balance heterophily and homophily inrepresentation learning, a challenge further amplified in self-supervisedsettings. We propose H$^3$GNNs, an end-to-end self-supervised learningframework that harmonizes both structural properties through two keyinnovations: (i) Joint Structural Node Encoding. We embed nodes into a unifiedspace combining linear and non-linear feature projections with K-hop structuralrepresentations via a Weighted Graph Convolution Network(WGCN). Across-attention mechanism enhances awareness and adaptability to heterophilyand homophily. (ii) Self-Supervised Learning Using Teacher-Student PredictiveArchitectures with Node-Difficulty Driven Dynamic Masking Strategies. We use ateacher-student model, the student sees the masked input graph and predictsnode features inferred by the teacher that sees the full input graph in thejoint encoding space. To enhance learning difficulty, we introduce two novelnode-predictive-difficulty-based masking strategies. Experiments on sevenbenchmarks (four heterophily datasets and three homophily datasets) confirm theeffectiveness and efficiency of H$^3$GNNs across diverse graph types. OurH$^3$GNNs achieves overall state-of-the-art performance on the four heterophilydatasets, while retaining on-par performance to previous state-of-the-artmethods on the three homophily datasets.</description>
      <author>example@mail.com (Rui Xue, Tianfu Wu)</author>
      <guid isPermaLink="false">2504.11699v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Towards Interpretable Deep Generative Models via Causal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.11609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文概述了因果表示学习（CRL）领域的最新进展，从统计学的角度对其进行了回顾，并强调了其与经典模型、统计和因果可识别性结果之间的联系。&lt;h4&gt;背景&lt;/h4&gt;近年来，生成式人工智能（AI）在多个领域取得了显著的进展，这得益于深度学习和生成建模等机器学习技术。然而，深度神经网络作为黑盒模型，使得其内部表示难以解释和分析。&lt;h4&gt;目的&lt;/h4&gt;构建新的可解释神经网络模型，以解决深度神经网络难以解释的问题，并推动因果表示学习（CRL）的发展。&lt;h4&gt;方法&lt;/h4&gt;CRL利用因果关系作为构建灵活、可解释和可迁移的生成AI的工具。它综合了潜在变量模型、因果图模型和深度学习等统计和机器学习技术。&lt;h4&gt;主要发现&lt;/h4&gt;论文回顾了CRL在统计视角下的最新进展，并强调了其与经典模型和统计因果可识别性结果之间的联系。&lt;h4&gt;结论&lt;/h4&gt;CRL是解决深度神经网络解释性问题的一个新兴领域，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The paper summarizes the latest progress in the field of causal representation learning (CRL), reviews it from a statistical perspective, and highlights its connections to classical models and statistical and causal identifiability results. The background is that recent developments in generative artificial intelligence (AI) rely on machine learning techniques such as deep learning and generative modeling to achieve state-of-the-art performance across a wide range of domains. However, deep neural networks are notorious black boxes that obscure these representations, making them difficult to interpret or analyze. The goal is to build new interpretable neural network models to resolve these difficulties and promote the development of causal representation learning (CRL). CRL uses causality as a vector to build flexible, interpretable, and transferable generative AI, integrating statistical and machine learning techniques such as latent variable models, causal graphical models, and deep learning. The main findings are that the paper reviews the latest progress in CRL from a statistical perspective and highlights its connections to classical models and statistical and causal identifiability results. The conclusion is that CRL is an emerging field that addresses the interpretability problem of deep neural networks and has wide application prospects.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developments in generative artificial intelligence (AI) rely onmachine learning techniques such as deep learning and generative modeling toachieve state-of-the-art performance across wide-ranging domains. Thesemethods' surprising performance is due in part to their ability to learnimplicit "representations'' of complex, multi-modal data. Unfortunately, deepneural networks are notoriously black boxes that obscure these representations,making them difficult to interpret or analyze. To resolve these difficulties,one approach is to build new interpretable neural network models from theground up. This is the goal of the emerging field of causal representationlearning (CRL) that uses causality as a vector for building flexible,interpretable, and transferable generative AI. CRL can be seen as a culminationof three intrinsically statistical problems: (i) latent variable models such asfactor analysis; (ii) causal graphical models with latent variables; and (iii)nonparametric statistics and deep learning. This paper reviews recent progressin CRL from a statistical perspective, focusing on connections to classicalmodels and statistical and causal identifiablity results. This review alsohighlights key application areas, implementation strategies, and openstatistical questions in CRL.</description>
      <author>example@mail.com (Gemma E. Moran, Bryon Aragam)</author>
      <guid isPermaLink="false">2504.11609v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>EgoExo-Gen: Ego-centric Video Prediction by Watching Exo-centric Videos</title>
      <link>http://arxiv.org/abs/2504.11732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨视图视频预测任务，提出了一种名为EgoExo-Gen的模型，用于生成第一人称视角视频的未来帧。&lt;h4&gt;背景&lt;/h4&gt;生成第一人称视角的视频在增强现实和具身智能领域有广泛的应用前景。&lt;h4&gt;目的&lt;/h4&gt;目标是给定一个外视角视频、相应内视角视频的第一帧和文本指令，生成内视角视频的未来帧。&lt;h4&gt;方法&lt;/h4&gt;EgoExo-Gen包括两个阶段：首先设计了一个跨视图手-物交互（HOI）掩码预测模型，通过建模时空内-外对应关系来预测未来内视角帧的HOI掩码；其次，使用视频扩散模型，结合文本指令和HOI掩码作为结构指导，预测未来的内视角帧。&lt;h4&gt;主要发现&lt;/h4&gt;通过Ego-Exo4D和H2O基准数据集的实验，EgoExo-Gen在视频预测性能上优于之前的模型，且HOI掩码显著提升了内视角视频中手和交互对象的生成质量。&lt;h4&gt;结论&lt;/h4&gt;EgoExo-Gen模型通过模型化手-物动态和结合HOI掩码，在跨视图视频预测任务中取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在增强现实和具身智能领域，以第一人称视角生成视频具有广泛的应用前景。在本研究中，我们探索了跨视图视频预测任务，即给定一个外视角视频、相应内视角视频的第一帧和文本指令，目标是生成内视角视频的未来帧。受内视角视频中手-物交互（HOI）代表当前演员主要意图和动作这一观点的启发，我们提出了EgoExo-Gen模型，该模型显式地建模了手-物动态以进行跨视图视频预测。EgoExo-Gen包括两个阶段。首先，我们设计了一个跨视图HOI掩码预测模型，通过建模时空内-外对应关系来预测未来内视角帧的HOI掩码。接下来，我们采用视频扩散模型，结合第一内视角帧和文本指令预测未来的内视角帧，同时将HOI掩码作为结构指导以提高预测质量。为了方便训练，我们开发了一个自动化管道，通过利用视觉基础模型生成伪HOI掩码，为内视角视频和外视角视频。广泛的实验表明，我们提出的EgoExo-Gen在Ego-Exo4D和H2O基准数据集上比之前的视频预测模型实现了更好的预测性能，且HOI掩码显著提高了内视角视频中手和交互对象的生成质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating videos in the first-person perspective has broad applicationprospects in the field of augmented reality and embodied intelligence. In thiswork, we explore the cross-view video prediction task, where given anexo-centric video, the first frame of the corresponding ego-centric video, andtextual instructions, the goal is to generate futur frames of the ego-centricvideo. Inspired by the notion that hand-object interactions (HOI) inego-centric videos represent the primary intentions and actions of the currentactor, we present EgoExo-Gen that explicitly models the hand-object dynamicsfor cross-view video prediction. EgoExo-Gen consists of two stages. First, wedesign a cross-view HOI mask prediction model that anticipates the HOI masks infuture ego-frames by modeling the spatio-temporal ego-exo correspondence. Next,we employ a video diffusion model to predict future ego-frames using the firstego-frame and textual instructions, while incorporating the HOI masks asstructural guidance to enhance prediction quality. To facilitate training, wedevelop an automated pipeline to generate pseudo HOI masks for both ego- andexo-videos by exploiting vision foundation models. Extensive experimentsdemonstrate that our proposed EgoExo-Gen achieves better prediction performancecompared to previous video prediction models on the Ego-Exo4D and H2O benchmarkdatasets, with the HOI masks significantly improving the generation of handsand interactive objects in the ego-centric videos.</description>
      <author>example@mail.com (Jilan Xu, Yifei Huang, Baoqi Pei, Junlin Hou, Qingqiu Li, Guo Chen, Yuejie Zhang, Rui Feng, Weidi Xie)</author>
      <guid isPermaLink="false">2504.11732v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
      <link>http://arxiv.org/abs/2504.11454v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://bytedance.github.io/dplm/dplm-2.1/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态蛋白质语言模型（PLMs）的设计空间，以克服其局限性，并显著提高了蛋白质模型、生成和设计的能力。&lt;h4&gt;背景&lt;/h4&gt;多模态PLMs结合序列和基于标记的结构信息，是蛋白质建模、生成和设计的强大基础。然而，将3D结构标记化成离散标记会导致关于细粒度结构细节和关联的保真度损失。&lt;h4&gt;目的&lt;/h4&gt;系统阐述多模态PLMs的设计空间，以克服其局限性，并提高蛋白质模型的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的设计空间包括改进的生成建模、结构感知架构和表示学习以及数据探索。通过更细粒度的监督，证明了基于标记的多模态PLMs可以实现鲁棒的结构建模。&lt;h4&gt;主要发现&lt;/h4&gt;识别出标记化损失和PLM的结构标记预测不准确是主要瓶颈。改进的设计方法显著提高了结构生成多样性，特别是折叠能力。650M模型在PDB测试集上的RMSD从5.52降低到2.36，甚至超过了3B基线，与专门的折叠模型相当。&lt;h4&gt;结论&lt;/h4&gt;通过改进的设计方法，多模态PLMs能够实现更精确和多样化的蛋白质结构建模，显著提升了蛋白质折叠能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal protein language models (PLMs) integrate sequence and token-basedstructural information, serving as a powerful foundation for protein modeling,generation, and design. However, the reliance on tokenizing 3D structures intodiscrete tokens causes substantial loss of fidelity about fine-grainedstructural details and correlations. In this paper, we systematically elucidatethe design space of multimodal PLMs to overcome their limitations. We identifytokenization loss and inaccurate structure token predictions by the PLMs asmajor bottlenecks. To address these, our proposed design space covers improvedgenerative modeling, structure-aware architectures and representation learning,and data exploration. Our advancements approach finer-grained supervision,demonstrating that token-based multimodal PLMs can achieve robust structuralmodeling. The effective design methods dramatically improve the structuregeneration diversity, and notably, folding abilities of our 650M model byreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3Bbaselines and on par with the specialized folding models.</description>
      <author>example@mail.com (Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu)</author>
      <guid isPermaLink="false">2504.11454v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>FACT: Foundation Model for Assessing Cancer Tissue Margins with Mass Spectrometry</title>
      <link>http://arxiv.org/abs/2504.11519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种针对REIMS数据的专用基础模型，用于实时术中组织边缘评估，以解决手术环境中标注数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;准确分类癌症手术中的组织边缘对于确保完全切除肿瘤至关重要。快速蒸发电离质谱（REIMS）是一种实时术中边缘评估工具，但其生成的光谱需要机器学习模型来支持临床决策。&lt;h4&gt;目的&lt;/h4&gt;开发一个专门针对REIMS数据的基础模型，以解决手术环境中标注数据稀缺的问题，并推进实时术中边缘评估。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为FACT的基础模型，它是针对文本-音频关联设计的基础模型的改编，并使用基于三元组损失的监督对比预训练方法进行预训练。通过消融研究来比较所提出的模型与其他模型和预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型显著提高了分类性能，达到了82.4% ± 0.8的AUROC，表明了所提出的预训练方法和所选骨干网络相对于自监督和半监督基线和替代模型的优势。&lt;h4&gt;结论&lt;/h4&gt;研究发现，通过使用新颖的方法进行改编和预训练的基础模型，即使在有限的标注示例下也能有效地分类REIMS数据。这突出了基础模型在数据稀缺的临床环境中增强实时术中边缘评估的可行性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：目的：在癌症手术中准确分类组织边缘对于确保完全切除肿瘤至关重要。快速蒸发电离质谱（REIMS）是一种用于实时术中边缘评估的工具，它生成需要机器学习模型来支持临床决策的光谱。然而，手术环境中标注数据的稀缺性提出了一个重大的挑战。本研究首次开发了一个专门针对REIMS数据的基础模型，解决了这一限制并推进了实时术中边缘评估。方法：我们提出了用于评估癌症组织边缘的基础模型FACT。FACT是对最初为文本-音频关联设计的基模型的改编，使用我们提出的基于三元组损失的监督对比预训练方法进行预训练。通过消融研究来比较我们提出的模型与其他模型和预训练方法。结果：我们提出的模型显著提高了分类性能，达到了82.4% ± 0.8的AUROC，表明了我们的预训练方法和所选骨干网络相对于自监督和半监督基线和替代模型的优势。结论：我们的发现表明，通过使用新颖的方法进行改编和预训练的基础模型，即使在有限的标注示例下也能有效地分类REIMS数据。这突出了基础模型在数据稀缺的临床环境中增强实时术中边缘评估的可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11548-025-03355-8&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Accurately classifying tissue margins during cancer surgeries iscrucial for ensuring complete tumor removal. Rapid Evaporative Ionization MassSpectrometry (REIMS), a tool for real-time intraoperative margin assessment,generates spectra that require machine learning models to support clinicaldecision-making. However, the scarcity of labeled data in surgical contextspresents a significant challenge. This study is the first to develop afoundation model tailored specifically for REIMS data, addressing thislimitation and advancing real-time surgical margin assessment. Methods: Wepropose FACT, a Foundation model for Assessing Cancer Tissue margins. FACT isan adaptation of a foundation model originally designed for text-audioassociation, pretrained using our proposed supervised contrastive approachbased on triplet loss. An ablation study is performed to compare our proposedmodel against other models and pretraining methods. Results: Our proposed modelsignificantly improves the classification performance, achievingstate-of-the-art performance with an AUROC of $82.4\% \pm 0.8$. The resultsdemonstrate the advantage of our proposed pretraining method and selectedbackbone over the self-supervised and semi-supervised baselines and alternativemodels. Conclusion: Our findings demonstrate that foundation models, adaptedand pretrained using our novel approach, can effectively classify REIMS dataeven with limited labeled examples. This highlights the viability of foundationmodels for enhancing real-time surgical margin assessment, particularly indata-scarce clinical environments.</description>
      <author>example@mail.com (Mohammad Farahmand, Amoon Jamzad, Fahimeh Fooladgar, Laura Connolly, Martin Kaufmann, Kevin Yi Mi Ren, John Rudan, Doug McKay, Gabor Fichtinger, Parvin Mousavi)</author>
      <guid isPermaLink="false">2504.11519v1</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Seedream 3.0 Technical Report</title>
      <link>http://arxiv.org/abs/2504.11346v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Seedream 3.0 Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Seedream 3.0 是一个高性能的中英双语图像生成基础模型，通过多项技术改进解决了 Seedream 2.0 中的问题，如复杂提示的匹配、精细的字体生成、视觉美感和保真度不足以及有限的图像分辨率。&lt;h4&gt;背景&lt;/h4&gt;Seedream 3.0 是在 Seedream 2.0 的基础上开发的，旨在解决其存在的挑战。&lt;h4&gt;目的&lt;/h4&gt;提高 Seedream 2.0 的性能，特别是在复杂中文字符的文本渲染、精细字体生成和图像分辨率方面。&lt;h4&gt;方法&lt;/h4&gt;Seedream 3.0 通过以下方法实现改进：数据层面采用缺陷感知训练范式和双轴协作数据采样框架，预训练阶段使用混合分辨率训练、跨模态 RoPE、表示对齐损失和分辨率感知时间步采样技术，后训练阶段使用多样化的美学标题和基于 VLM 的奖励模型，以及采用一致的噪声期望和重要性感知时间步采样以实现加速。&lt;h4&gt;主要发现&lt;/h4&gt;Seedream 3.0 在 Seedream 2.0 的基础上取得了显著改进，特别是在复杂中文字符的文本渲染和图像分辨率方面，能够生成高达 2K 分辨率的图像。&lt;h4&gt;结论&lt;/h4&gt;Seedream 3.0 是一个更加强大和高效的图像生成模型，能够满足专业字体生成和高质量图像生成的需求。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了 Seedream 3.0，一个高性能的中英双语图像生成基础模型。我们开发了多项技术改进来解决 Seedream 2.0 中存在的挑战，包括与复杂提示的对齐、精细的字体生成、视觉美感和保真度不足以及有限的图像分辨率。特别是，Seedream 3.0 的进步源于整个流程的改进，从数据构建到模型部署。在数据层，我们使用缺陷感知训练范式和双轴协作数据采样框架将数据集翻倍。此外，在预训练阶段，我们采用了混合分辨率训练、跨模态 RoPE、表示对齐损失和分辨率感知时间步采样等有效技术。在后训练阶段，我们利用多样化的美学标题进行强化学习，并采用基于 VLM 的奖励模型进行缩放，从而实现与人类偏好良好的对齐。此外，Seedream 3.0 领先采用了一种新的加速范式。通过采用一致的噪声期望和重要性感知时间步采样，我们实现了 4 到 8 倍的速度提升，同时保持了图像质量。Seedream 3.0 在 Seedream 2.0 的基础上取得了显著改进：它增强了整体能力，特别是在复杂中文字符的文本渲染方面，这对于专业字体生成非常重要。此外，它提供了原生的高分辨率输出（高达 2K），使其能够生成高质量的图像。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Seedream 3.0, a high-performance Chinese-English bilingual imagegeneration foundation model. We develop several technical improvements toaddress existing challenges in Seedream 2.0, including alignment withcomplicated prompts, fine-grained typography generation, suboptimal visualaesthetics and fidelity, and limited image resolutions. Specifically, theadvancements of Seedream 3.0 stem from improvements across the entire pipeline,from data construction to model deployment. At the data stratum, we double thedataset using a defect-aware training paradigm and a dual-axis collaborativedata-sampling framework. Furthermore, we adopt several effective techniquessuch as mixed-resolution training, cross-modality RoPE, representationalignment loss, and resolution-aware timestep sampling in the pre-trainingphase. During the post-training stage, we utilize diversified aestheticcaptions in SFT, and a VLM-based reward model with scaling, thereby achievingoutputs that well align with human preferences. Furthermore, Seedream 3.0pioneers a novel acceleration paradigm. By employing consistent noiseexpectation and importance-aware timestep sampling, we achieve a 4 to 8 timesspeedup while maintaining image quality. Seedream 3.0 demonstrates significantimprovements over Seedream 2.0: it enhances overall capabilities, in particularfor text-rendering in complicated Chinese characters which is important toprofessional typography generation. In addition, it provides nativehigh-resolution output (up to 2K), allowing it to generate images with highvisual quality.</description>
      <author>example@mail.com (Yu Gao, Lixue Gong, Qiushan Guo, Xiaoxia Hou, Zhichao Lai, Fanshi Li, Liang Li, Xiaochen Lian, Chao Liao, Liyang Liu, Wei Liu, Yichun Shi, Shiqi Sun, Yu Tian, Zhi Tian, Peng Wang, Rui Wang, Xuanda Wang, Xun Wang, Ye Wang, Guofeng Wu, Jie Wu, Xin Xia, Xuefeng Xiao, Zhonghua Zhai, Xinyu Zhang, Qi Zhang, Yuwei Zhang, Shijia Zhao, Jianchao Yang, Weilin Huang)</author>
      <guid isPermaLink="false">2504.11346v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.10143v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态表示学习，特别是使用图像-文本对的多模态对比学习（MMCL），旨在通过跨模态对齐线索来学习强大的表示。研究指出，现实数据集中存在模态对齐问题，并提出了两种解决观点：缓解对齐错误和利用对齐错误。通过引入选择偏差和扰动偏差两种机制，作者将模态对齐问题形式化，并通过理论分析和实证研究验证了其观点。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在通过跨模态对齐来学习强大的表示，但现实数据集中存在模态对齐问题。&lt;h4&gt;目的&lt;/h4&gt;寻求解决模态对齐问题的方法，并为实践者提供指导。&lt;h4&gt;方法&lt;/h4&gt;使用潜在变量模型，引入选择偏差和扰动偏差两种机制来形式化模态对齐问题，并通过理论分析和实证研究验证。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在轻微的假设下，MMCL学习到的表示恰好捕捉了与选择和扰动偏差无关的语义变量子集的信息。&lt;h4&gt;结论&lt;/h4&gt;提供了对模态对齐问题的统一理解视角，并基于此为现实世界机器学习系统的设计提供了可操作的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习，以使用图像-文本对的多模态对比学习（MMCL）为例，旨在通过跨模态对齐线索来学习强大的表示。这种方法依赖于一个核心假设，即示例图像-文本对构成了一个相同概念的两种表示。然而，最近的研究表明，现实世界的数据集往往存在对齐错误。关于如何解决这个问题，有两种不同的观点：一种建议减轻对齐错误，另一种则利用对齐错误。在这里，我们试图调和这些看似对立的观点，并为实践者提供实用的指南。因此，我们使用潜在变量模型，通过引入两种特定的机制来形式化对齐错误：选择偏差，其中一些语义变量缺失，以及扰动偏差，其中语义变量被扭曲——两者都影响跨模态共享的潜在变量。我们的理论分析表明，在轻微的假设下，MMCL学习到的表示恰好捕捉了与选择和扰动偏差无关的语义变量子集的信息。这为理解对齐错误提供了一个统一的视角。基于此，我们进一步提供了关于如何将对齐错误纳入现实世界机器学习系统设计的可操作见解。我们通过在合成数据和真实图像-文本数据集上进行的广泛实证研究验证了我们的理论发现，揭示了对齐错误对多模态表示学习的微妙影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning, exemplified by multimodal contrastivelearning (MMCL) using image-text pairs, aims to learn powerful representationsby aligning cues across modalities. This approach relies on the core assumptionthat the exemplar image-text pairs constitute two representations of anidentical concept. However, recent research has revealed that real-worlddatasets often exhibit misalignment. There are two distinct viewpoints on howto address this issue: one suggests mitigating the misalignment, and the otherleveraging it. We seek here to reconcile these seemingly opposing perspectives,and to provide a practical guide for practitioners. Using latent variablemodels we thus formalize misalignment by introducing two specific mechanisms:selection bias, where some semantic variables are missing, and perturbationbias, where semantic variables are distorted -- both affecting latent variablesshared across modalities. Our theoretical analysis demonstrates that, undermild assumptions, the representations learned by MMCL capture exactly theinformation related to the subset of the semantic variables invariant toselection and perturbation biases. This provides a unified perspective forunderstanding misalignment. Based on this, we further offer actionable insightsinto how misalignment should inform the design of real-world ML systems. Wevalidate our theoretical findings through extensive empirical studies on bothsynthetic data and real image-text datasets, shedding light on the nuancedimpact of misalignment on multimodal representation learning.</description>
      <author>example@mail.com (Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi)</author>
      <guid isPermaLink="false">2504.10143v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2504.08713v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于原型学习的深度学习模型ProtoECGNet，用于可解释的多标签ECG分类，以提高临床决策的可信度。&lt;h4&gt;背景&lt;/h4&gt;深度学习在ECG分类中表现出色，但临床应用受到缺乏透明和忠实解释的阻碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于原型学习的深度学习模型，以实现可解释的ECG分类，并提高临床决策的透明度和可信度。&lt;h4&gt;方法&lt;/h4&gt;ProtoECGNet采用结构化的多分支架构，结合1D CNN和全局原型进行节律分类，2D CNN和时间局部原型进行形态推理，以及2D CNN和全局原型进行弥漫性异常检测。每个分支使用专门设计的原型损失进行多标签学习。&lt;h4&gt;主要发现&lt;/h4&gt;ProtoECGNet在PTB-XL数据集上对所有71个诊断标签进行了评估，与最先进的黑盒模型相比表现出竞争力，同时提供了结构化的基于案例的解释。&lt;h4&gt;结论&lt;/h4&gt;原型学习可以有效地扩展到复杂的多标签时间序列分类，为临床决策支持提供了一种透明且可信的深度学习模型。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bbj-lab/protoecgnet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based electrocardiogram (ECG) classification has shownimpressive performance but clinical adoption has been slowed by the lack oftransparent and faithful explanations. Post hoc methods such as saliency mapsmay fail to reflect a model's true decision process. Prototype-based reasoningoffers a more transparent alternative by grounding decisions in similarity tolearned representations of real ECG segments, enabling faithful, case-basedexplanations. We introduce ProtoECGNet, a prototype-based deep learning modelfor interpretable, multi-label ECG classification. ProtoECGNet employs astructured, multi-branch architecture that reflects clinical interpretationworkflows: it integrates a 1D CNN with global prototypes for rhythmclassification, a 2D CNN with time-localized prototypes for morphology-basedreasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Eachbranch is trained with a prototype loss designed for multi-label learning,combining clustering, separation, diversity, and a novel contrastive loss thatencourages appropriate separation between prototypes of unrelated classes whileallowing clustering for frequently co-occurring diagnoses. We evaluateProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstratingcompetitive performance relative to state-of-the-art black-box models whileproviding structured, case-based explanations. To assess prototype quality, weconduct a structured clinician review of the final model's projectedprototypes, finding that they are rated as representative and clear.ProtoECGNet shows that prototype learning can be effectively scaled to complex,multi-label time-series classification, offering a practical path towardtransparent and trustworthy deep learning models for clinical decision support.</description>
      <author>example@mail.com (Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.08713v2</guid>
      <pubDate>Thu, 17 Apr 2025 14:12:55 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Enhanced Robotic Subretinal Injection with Real-Time Retinal Motion Compensation</title>
      <link>http://arxiv.org/abs/2504.03939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种完全自动化的视网膜下注射系统，该系统通过结合术中光学相干断层扫描成像和基于深度学习的运动预测，以同步针头运动与视网膜位移，从而提高视网膜微手术的安全性和准确性。&lt;h4&gt;背景&lt;/h4&gt;视网膜下注射是治疗如年龄相关性黄斑变性等视网膜疾病的关键程序。然而，由于呼吸和心跳等生理因素引起的视网膜运动，对精确针头定位产生了显著影响，增加了视网膜色素上皮（RPE）受损的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统，能够同步针头运动与视网膜位移，减少视网膜下注射过程中的误差。&lt;h4&gt;方法&lt;/h4&gt;该系统集成了术中光学相干断层扫描（iOCT）成像和基于长短期记忆（LSTM）神经网络的运动预测。使用LSTM神经网络预测内部限制膜（ILM）运动，并优于基于快速傅里叶变换（FFT）的基线模型。此外，一个实时注册框架将针头尖端位置与机器人的坐标系对齐，并采用动态比例速度控制策略确保针头插入的平滑和自适应。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和离体开放式猪眼实验中，该系统实现了精确的运动同步和成功的视网膜下注射。实验在插入前阶段达到了平均跟踪误差低于16.4微米。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，人工智能驱动的机器人辅助系统具有提高视网膜微手术安全性和准确性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Subretinal injection is a critical procedure for delivering therapeuticagents to treat retinal diseases such as age-related macular degeneration(AMD). However, retinal motion caused by physiological factors such asrespiration and heartbeat significantly impacts precise needle positioning,increasing the risk of retinal pigment epithelium (RPE) damage. This paperpresents a fully autonomous robotic subretinal injection system that integratesintraoperative optical coherence tomography (iOCT) imaging and deeplearning-based motion prediction to synchronize needle motion with retinaldisplacement. A Long Short-Term Memory (LSTM) neural network is used to predictinternal limiting membrane (ILM) motion, outperforming a Fast Fourier Transform(FFT)-based baseline model. Additionally, a real-time registration frameworkaligns the needle tip position with the robot's coordinate frame. Then, adynamic proportional speed control strategy ensures smooth and adaptive needleinsertion. Experimental validation in both simulation and ex vivo open-skyporcine eyes demonstrates precise motion synchronization and successfulsubretinal injections. The experiment achieves a mean tracking error below 16.4{\mu}m in pre-insertion phases. These results show the potential of AI-drivenrobotic assistance to improve the safety and accuracy of retinal microsurgery.</description>
      <author>example@mail.com (Tianle Wu, Mojtaba Esfandiari, Peiyao Zhang, Russell H. Taylor, Peter Gehlbach, Iulian Iordachita)</author>
      <guid isPermaLink="false">2504.03939v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
  <item>
      <title>Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2504.11268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了针对多任务模型中单输入多输出（SIMO）设置的模型合并方法，通过重新对齐合并后的编码器与任务特定解码器的特征表示来提升性能。&lt;h4&gt;背景&lt;/h4&gt;现有的模型合并方法主要针对单输入单输出（SISO）设置，而忽略了多任务场景中可能存在多个任务对同一样本进行处理的情况。&lt;h4&gt;目的&lt;/h4&gt;针对SIMO设置提出一种有效的模型合并方法，以提升多任务模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出两种简单的修正方法，用于在模型合并后重新对齐特征表示。通过在NYUv2、Cityscapes和Taskonomy数据集的子集上进行实验验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;1. 对于多任务能力，任务算术是足够的；2. 合并后的编码器生成的表示需要与任务特定的头部重新对齐；3. 所提出的架构在性能上与传统多任务学习相媲美，但通过利用任务特定模型的存在，需要更少的样本和训练步骤。&lt;h4&gt;结论&lt;/h4&gt;本文提出的SIMO设置下的模型合并方法，在保持高性能的同时，计算效率高且灵活，能够在线下方式识别任务关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging is a flexible and computationally tractable approach to mergesingle-task checkpoints into a multi-task model. Prior work has solely focusedon constrained multi-task settings where there is a one-to-one mapping betweena sample and a task, overlooking the paradigm where multiple tasks may operateon the same sample, e.g., scene understanding. In this paper, we focus on themulti-task setting with single-input-multiple-outputs (SIMO) and show that itqualitatively differs from the single-input-single-output model mergingsettings studied in the literature due to the existence of task-specificdecoders and diverse loss objectives. We identify that existing model mergingmethods lead to significant performance degradation, primarily due torepresentation misalignment between the merged encoder and task-specificdecoders. We propose two simple and efficient fixes for the SIMO setting tore-align the feature representation after merging. Compared to jointfine-tuning, our approach is computationally effective and flexible, and shedslight into identifying task relationships in an offline manner. Experiments onNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) taskarithmetic suffices to enable multi-task capabilities; however, therepresentations generated by the merged encoder has to be re-aligned with thetask-specific heads; (2) the proposed architecture rivals traditionalmulti-task learning in performance but requires fewer samples and trainingsteps by leveraging the existence of task-specific models.</description>
      <author>example@mail.com (Juan Garcia Giraldo, Nikolaos Dimitriadis, Ke Wang, Pascal Frossard)</author>
      <guid isPermaLink="false">2504.11268v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>PARTFIELD: Learning 3D Feature Fields for Part Segmentation and Beyond</title>
      <link>http://arxiv.org/abs/2504.11451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://research.nvidia.com/labs/toronto-ai/partfield-release/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为PartField的前馈方法，用于学习基于部分的三维特征，能够捕获部分及其层次结构的一般概念，不依赖于预定义的模板或基于文本的名称，并适用于各种模态的开放世界三维形状。&lt;h4&gt;背景&lt;/h4&gt;现有方法在三维形状的部分分解中依赖于预定义的模板或文本名称，限制了模型的通用性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，能够有效地学习三维形状的部分特征，同时提高模型的运行时间和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过从标注数据集和大型无监督数据集上的图像分割中提取二维和三维部分提议，使用对比学习公式对模型进行训练，生成连续的特征场，该特征场可以聚类以产生层次化的部分分解。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的无监督部分分割方法相比，PartField在准确性和速度方面均有显著提升，最高可达20%的准确度提升和多个数量级的速度提升。&lt;h4&gt;结论&lt;/h4&gt;PartField不仅能够实现单形状的部分分解，而且学习到的特征场在不同形状之间保持一致性，这有助于实现诸如共分割和对应关系等任务，并展示了这些通用、层次化和一致的三维特征场在多个应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;We propose PartField, a feedforward approach for learning part-based 3D features, which captures the general concept of parts and their hierarchy without relying on predefined templates or text-based names, and can be applied to open-world 3D shapes across various modalities. PartField requires only a 3D feedforward pass at inference time, significantly improving runtime and robustness compared to prior approaches. Our model is trained by distilling 2D and 3D part proposals from a mix of labeled datasets and image segmentations on large unsupervised datasets, via a contrastive learning formulation. It produces a continuous feature field which can be clustered to yield a hierarchical part decomposition. Comparisons show that PartField is up to 20% more accurate and often orders of magnitude faster than other recent class-agnostic part-segmentation methods. Beyond single-shape part decomposition, consistency in the learned field emerges across shapes, enabling tasks such as co-segmentation and correspondence, which we demonstrate in several applications of these general-purpose, hierarchical, and consistent 3D feature fields. Check our Webpage!https://research.nvidia.com/labs/toronto-ai/partfield-release/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose PartField, a feedforward approach for learning part-based 3Dfeatures, which captures the general concept of parts and their hierarchywithout relying on predefined templates or text-based names, and can be appliedto open-world 3D shapes across various modalities. PartField requires only a 3Dfeedforward pass at inference time, significantly improving runtime androbustness compared to prior approaches. Our model is trained by distilling 2Dand 3D part proposals from a mix of labeled datasets and image segmentations onlarge unsupervised datasets, via a contrastive learning formulation. Itproduces a continuous feature field which can be clustered to yield ahierarchical part decomposition. Comparisons show that PartField is up to 20%more accurate and often orders of magnitude faster than other recentclass-agnostic part-segmentation methods. Beyond single-shape partdecomposition, consistency in the learned field emerges across shapes, enablingtasks such as co-segmentation and correspondence, which we demonstrate inseveral applications of these general-purpose, hierarchical, and consistent 3Dfeature fields. Check our Webpage!https://research.nvidia.com/labs/toronto-ai/partfield-release/</description>
      <author>example@mail.com (Minghua Liu, Mikaela Angelina Uy, Donglai Xiang, Hao Su, Sanja Fidler, Nicholas Sharp, Jun Gao)</author>
      <guid isPermaLink="false">2504.11451v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal Conditioning and Cross-context Attention</title>
      <link>http://arxiv.org/abs/2504.11150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于车道图的车辆运动预测模型，通过融合多个上下文元素，实现了对未来车辆轨迹的预测。&lt;h4&gt;背景&lt;/h4&gt;车辆运动预测模型依赖于所提供的上下文信息，这些信息可以是静态的（如车道、交通标志等）或动态的（如交通参与者）。&lt;h4&gt;目的&lt;/h4&gt;研究如何提高运动预测模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;模型采用编码器-交互器-解码器架构，使用轻量级的门控循环单元（GRU）编码场景上下文，交互器对编码的场景特征和图目标建议应用交叉注意力，解码器通过拉普拉斯混合密度网络从聚合编码中回归多模态轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;使用基于图的目标建议的交叉注意力提供了鲁棒的轨迹估计，因为模型学会了关注未来目标相关的场景元素。&lt;h4&gt;结论&lt;/h4&gt;在nuScenes运动预测数据集上评估，该模型实现了最先进的结果。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于车道图的车辆运动预测模型，该模型首先预测基于图的目标建议，然后通过跨多个上下文元素的交叉注意力将它们融合。我们遵循著名的编码器-交互器-解码器架构，其中编码器使用轻量级的门控循环单元（GRU）编码场景上下文，交互器对编码的场景特征和图目标建议应用交叉注意力，解码器通过拉普拉斯混合密度网络从聚合编码中回归多模态轨迹。使用基于图的目标建议的交叉注意力提供了鲁棒的轨迹估计，因为模型学会了关注未来目标相关的场景元素。我们在nuScenes运动预测数据集上评估了我们的工作，实现了最先进的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting future trajectories of surrounding vehicles heavily relies on whatcontextual information is given to a motion prediction model. The contextitself can be static (lanes, regulatory elements, etc) or dynamic (trafficparticipants). This paper presents a lane graph-based motion prediction modelthat first predicts graph-based goal proposals and later fuses them with crossattention over multiple contextual elements. We follow the famousencoder-interactor-decoder architecture where the encoder encodes scene contextusing lightweight Gated Recurrent Units, the interactor applies cross-contextattention over encoded scene features and graph goal proposals, and the decoderregresses multimodal trajectories via Laplacian Mixture Density Network fromthe aggregated encodings. Using cross-attention over graph-based goal proposalsgives robust trajectory estimates since the model learns to attend to futuregoal-relevant scene elements for the intended agent. We evaluate our work onnuScenes motion prediction dataset, achieving state-of-the-art results.</description>
      <author>example@mail.com (Mahir Gulzar, Yar Muhammad, Naveed Muhammad)</author>
      <guid isPermaLink="false">2504.11150v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Safe-Construct: Redefining Construction Safety Violation Recognition as 3D Multi-View Engagement Task</title>
      <link>http://arxiv.org/abs/2504.10880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR Workshop 2025; Project Website:  https://Safe-Construct.github.io/Safe-Construct&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Safe-Construct的框架，用于在建筑环境中识别安全违规行为，并通过3D多视角理解和合成数据生成技术，实现了可扩展且鲁棒的安全监控。&lt;h4&gt;背景&lt;/h4&gt;当前在计算机视觉领域，建筑环境中的安全违规识别研究不足，现有的模型主要依赖于2D目标检测，无法捕捉真实违规行为的复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的不足，提出了Safe-Construct框架，旨在改进安全违规行为的识别。&lt;h4&gt;方法&lt;/h4&gt;Safe-Construct将违规识别重新定义为3D多视角参与任务，利用场景级工人-物体上下文和3D空间理解。同时，提出了合成室内建筑场地生成器（SICSG）以创建多样化的可扩展训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;Safe-Construct在四种违规类型上相对于现有最佳方法提高了7.6%的性能。在接近真实的环境中进行严格评估，包括四种违规、四种工人、14种物体，以及遮挡（工人-物体、工人-工人）和多变光照（背光、过曝、日光）等挑战条件。&lt;h4&gt;结论&lt;/h4&gt;Safe-Construct通过集成3D多视角空间理解和合成数据生成，为高风险行业的安全监控设定了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译为：在建筑环境中识别安全违规行为至关重要，但在计算机视觉领域中仍处于探索阶段。现有的模型主要依赖于2D目标检测，由于以下原因，无法捕捉现实违规行为的复杂性：（i）将违规识别简化为目标检测的任务定义，（ii）在现实条件下的验证不足，（iii）缺乏标准基线，（iv）由于缺乏多样化的建筑场景合成数据生成器，可扩展性有限。为了解决这些挑战，我们引入了Safe-Construct，这是第一个将违规识别重新定义为3D多视角参与任务的框架，利用场景级的工人-物体上下文和3D空间理解。我们还提出了合成室内建筑场地生成器（SICSG）来创建多样化的可扩展训练数据，克服了数据限制。Safe-Construct在四种违规类型上相对于现有最佳方法实现了7.6%的性能提升。我们在接近真实的环境中对我们的方法进行了严格的评估，包括四种违规、四种工人、14种物体以及如遮挡（工人-物体、工人-工人）和多变光照（背光、过曝、日光）等挑战条件。通过集成3D多视角空间理解和合成数据生成，Safe-Construct为高风险行业的安全监控设定了新的基准。项目网站：https://Safe-Construct.github.io/Safe-Construct&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recognizing safety violations in construction environments is critical yetremains underexplored in computer vision. Existing models predominantly rely on2D object detection, which fails to capture the complexities of real-worldviolations due to: (i) an oversimplified task formulation treating violationrecognition merely as object detection, (ii) inadequate validation underrealistic conditions, (iii) absence of standardized baselines, and (iv) limitedscalability from the unavailability of synthetic dataset generators for diverseconstruction scenarios. To address these challenges, we introduceSafe-Construct, the first framework that reformulates violation recognition asa 3D multi-view engagement task, leveraging scene-level worker-object contextand 3D spatial understanding. We also propose the Synthetic Indoor ConstructionSite Generator (SICSG) to create diverse, scalable training data, overcomingdata limitations. Safe-Construct achieves a 7.6% improvement overstate-of-the-art methods across four violation types. We rigorously evaluateour approach in near-realistic settings, incorporating four violations, fourworkers, 14 objects, and challenging conditions like occlusions (worker-object,worker-worker) and variable illumination (back-lighting, overexposure,sunlight). By integrating 3D multi-view spatial understanding and syntheticdata generation, Safe-Construct sets a new benchmark for scalable and robustsafety monitoring in high-risk industries. Project Website:https://Safe-Construct.github.io/Safe-Construct</description>
      <author>example@mail.com (Aviral Chharia, Tianyu Ren, Tomotake Furuhata, Kenji Shimada)</author>
      <guid isPermaLink="false">2504.10880v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution</title>
      <link>http://arxiv.org/abs/2504.11369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review with ARR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出OpenTuringBench，一个基于OLLMs的新基准，用于训练和评估机器生成文本检测器，并在图灵测试和作者归属问题中进行评估。&lt;h4&gt;背景&lt;/h4&gt;OLLMs在生成AI应用中越来越受欢迎，但其输出检测带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计OpenTuringBench，以训练和评估机器生成文本检测器，解决OLLMs输出检测的挑战。&lt;h4&gt;方法&lt;/h4&gt;OpenTuringBench关注一组代表性的OLLMs，并包括多个具有挑战性的评估任务，如人类/机器操作文本、域外文本和来自未见模型的文本。同时提供OTBDetector，一个对比学习框架，用于检测和归因基于OLLMs的机器生成文本。&lt;h4&gt;主要发现&lt;/h4&gt;OpenTuringBench任务的相关性和难度各不相同，检测器在各个任务中表现出显著的能力，并优于大多数现有检测器。&lt;h4&gt;结论&lt;/h4&gt;OpenTuringBench是一个有效的工具，用于评估和训练机器生成文本检测器，资源可在Hugging Face仓库找到。&lt;h4&gt;翻译&lt;/h4&gt;Open Large Language Models (OLLMs) 在生成AI应用中越来越被利用，这给检测它们的输出带来了新的挑战。我们提出了基于OLLMs的新基准OpenTuringBench，用于训练和评估机器生成文本检测器在图灵测试和作者归属问题上的表现。OpenTuringBench专注于一组代表性的OLLMs，并具有一系列具有挑战性的评估任务，包括人类/机器操作文本、域外文本和来自之前未见模型的文本。我们还提供了OTBDetector，一个对比学习框架，用于检测和归因基于OLLMs的机器生成文本。结果表明，OpenTuringBench任务的相关性和难度各不相同，我们的检测器在各个任务中表现出显著的能力，并优于大多数现有检测器。资源可在Hugging Face仓库 https://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench 找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open Large Language Models (OLLMs) are increasingly leveraged in generativeAI applications, posing new challenges for detecting their outputs. We proposeOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluatemachine-generated text detectors on the Turing Test and Authorship Attributionproblems. OpenTuringBench focuses on a representative set of OLLMs, andfeatures a number of challenging evaluation tasks, includinghuman/machine-manipulated texts, out-of-domain texts, and texts from previouslyunseen models. We also provide OTBDetector, a contrastive learning framework todetect and attribute OLLM-based machine-generated texts. Results highlight therelevance and varying degrees of difficulty of the OpenTuringBench tasks, withour detector achieving remarkable capabilities across the various tasks andoutperforming most existing detectors. Resources are available on theOpenTuringBench Hugging Face repository athttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench</description>
      <author>example@mail.com (Lucio La Cava, Andrea Tagarelli)</author>
      <guid isPermaLink="false">2504.11369v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Remote Sensing: An Analysis of MLLMs for Object Localization</title>
      <link>http://arxiv.org/abs/2504.10727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, CVPR MORSE Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）在计算机视觉领域的应用，特别是其在地球观测（EO）图像处理任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在计算机视觉任务中取得了显著成果，尤其在零样本设置下。然而，它们在处理地球观测图像等分布外领域时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;分析最新MLLMs在地球观测对象定位任务上的表现，并探讨如何优化这些模型。&lt;h4&gt;方法&lt;/h4&gt;对特定训练以包含细粒度空间推理能力的MLLMs进行基准测试，并讨论了提示选择、地面样本距离（GSD）优化和分析失败案例。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型在特定设置下表现良好，适合零样本场景。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果对评估MLLMs是否适合特定EO定位任务以及如何优化它们具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）已经改变了计算机视觉的格局，在广泛的任务中取得了令人印象深刻的成果，尤其是在零样本设置下。不幸的是，它们的强大性能并不能总是转移到分布外领域，如地球观测（EO）图像。先前的研究表明，MLLMs在图像描述和场景理解等某些EO任务上表现出色，而在需要更细粒度空间推理的任务，如对象定位上则表现不佳。然而，MLLMs正在快速发展，见解迅速过时。在这项工作中，我们分析了最近专门训练以包括细粒度空间推理能力的MLLMs，并在EO对象定位任务上对它们进行了基准测试。我们证明了这些模型在特定设置下表现良好，使它们非常适合零样本场景。此外，我们还提供了关于提示选择、地面样本距离（GSD）优化和分析失败案例的详细讨论。我们希望这项工作将证明对其他人评估MLLM是否适合给定的EO定位任务以及如何优化它们是有价值的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have altered the landscape ofcomputer vision, obtaining impressive results across a wide range of tasks,especially in zero-shot settings. Unfortunately, their strong performance doesnot always transfer to out-of-distribution domains, such as earth observation(EO) imagery. Prior work has demonstrated that MLLMs excel at some EO tasks,such as image captioning and scene understanding, while failing at tasks thatrequire more fine-grained spatial reasoning, such as object localization.However, MLLMs are advancing rapidly and insights quickly become out-dated. Inthis work, we analyze more recent MLLMs that have been explicitly trained toinclude fine-grained spatial reasoning capabilities, benchmarking them on EOobject localization tasks. We demonstrate that these models are performant incertain settings, making them well suited for zero-shot scenarios.Additionally, we provide a detailed discussion focused on prompt selection,ground sample distance (GSD) optimization, and analyzing failure cases. We hopethat this work will prove valuable as others evaluate whether an MLLM is wellsuited for a given EO localization task and how to optimize it.</description>
      <author>example@mail.com (Darryl Hannan, John Cooper, Dylan White, Timothy Doster, Henry Kvinge, Yijing Watkins)</author>
      <guid isPermaLink="false">2504.10727v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Subset-Contrastive Multi-Omics Network Embedding</title>
      <link>http://arxiv.org/abs/2504.11321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SCONE的方法，用于多组学数据的网络嵌入分析，旨在解决现有方法在单细胞数据分析中的内存和空间密集问题，并提高多组学网络分析的有效性。&lt;h4&gt;背景&lt;/h4&gt;网络分析在组学数据中应用广泛，但许多方法在单细胞数据分析中内存和空间需求大，且多组学网络分析通常依赖于基于相似性的网络，缺乏结构上离散的拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Subset-Contrastive multi-Omics Network Embedding (SCONE)的方法，通过可扩展的子图对比学习技术在大数据集上应用对比学习技术，以实现可扩展和有效的分析。&lt;h4&gt;方法&lt;/h4&gt;SCONE方法利用网络方法中成对相似性的基础，将其转化为优势，旨在实现可扩展和有效的分析。&lt;h4&gt;主要发现&lt;/h4&gt;SCONE在细胞类型聚类中表现出协同的多组学整合能力，并在批量多组学整合场景中表现出与现有最佳方法相当的性能，尽管使用了原始数据的有限视图。&lt;h4&gt;结论&lt;/h4&gt;SCONE方法为组学数据应用子集对比方法提供了新的思路，并有望促进进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Motivation: Network-based analyses of omics data are widely used, and while many of these methods have been adapted to single-cell scenarios, they often remain memory- and space-intensive. As a result, they are better suited to batch data or smaller datasets. Furthermore, the application of network-based methods in multi-omics often relies on similarity-based networks, which lack structurally-discrete topologies. This limitation may reduce the effectiveness of graph-based methods that were initially designed for topologies with better defined structures. Results: We propose Subset-Contrastive multi-Omics Network Embedding (SCONE), a method that employs contrastive learning techniques on large datasets through a scalable subgraph contrastive approach. By exploiting the pairwise similarity basis of many network-based omics methods, we transformed this characteristic into a strength, developing an approach that aims to achieve scalable and effective analysis. Our method demonstrates synergistic omics integration for cell type clustering in single-cell data. Additionally, we evaluate its performance in a bulk multi-omics integration scenario, where SCONE performs comparable to the state-of-the-art despite utilising limited views of the original data. We anticipate that our findings will motivate further research into the use of subset contrastive methods for omics data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivation: Network-based analyses of omics data are widely used, and whilemany of these methods have been adapted to single-cell scenarios, they oftenremain memory- and space-intensive. As a result, they are better suited tobatch data or smaller datasets. Furthermore, the application of network-basedmethods in multi-omics often relies on similarity-based networks, which lackstructurally-discrete topologies. This limitation may reduce the effectivenessof graph-based methods that were initially designed for topologies with betterdefined structures. Results: We propose Subset-Contrastive multi-Omics NetworkEmbedding (SCONE), a method that employs contrastive learning techniques onlarge datasets through a scalable subgraph contrastive approach. By exploitingthe pairwise similarity basis of many network-based omics methods, wetransformed this characteristic into a strength, developing an approach thataims to achieve scalable and effective analysis. Our method demonstratessynergistic omics integration for cell type clustering in single-cell data.Additionally, we evaluate its performance in a bulk multi-omics integrationscenario, where SCONE performs comparable to the state-of-the-art despiteutilising limited views of the original data. We anticipate that our findingswill motivate further research into the use of subset contrastive methods foromics data.</description>
      <author>example@mail.com (Pedro Henrique da Costa Avelar, Min Wu, Sophia Tsoka)</author>
      <guid isPermaLink="false">2504.11321v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Seedream 3.0 Technical Report</title>
      <link>http://arxiv.org/abs/2504.11346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Seedream 3.0 Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Seedream 3.0，一个高性能的中英双语图像生成基础模型。&lt;h4&gt;背景&lt;/h4&gt;Seedream 3.0是在解决Seedream 2.0中存在的问题的基础上开发的，这些问题包括复杂提示的匹配、精细的字体生成、视觉效果和真实感不理想以及有限的图像分辨率。&lt;h4&gt;目的&lt;/h4&gt;通过改进数据构建到模型部署的整个流程，提高Seedream 3.0的性能。&lt;h4&gt;方法&lt;/h4&gt;在数据层面，使用缺陷感知训练范式和双轴协作数据采样框架将数据集翻倍。在预训练阶段，采用混合分辨率训练、跨模态RoPE、表征对齐损失和分辨率感知时间步采样等有效技术。在训练后阶段，使用多样化的审美描述和基于VLM的奖励模型以及缩放功能。此外，Seedream 3.0采用了一种新的加速范式，通过使用一致的噪声预期和重要性感知时间步采样，在保持图像质量的同时实现了4到8倍的速度提升。&lt;h4&gt;主要发现&lt;/h4&gt;Seedream 3.0在Seedream 2.0的基础上实现了显著改进，特别是在复杂的中文文字渲染能力上，这对于专业字体生成非常重要。此外，它提供原生的高分辨率输出（高达2K），能够生成高视觉质量的图像。&lt;h4&gt;结论&lt;/h4&gt;Seedream 3.0在提高图像生成性能和视觉质量方面取得了重要进展，特别是在处理复杂提示和字体生成方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Seedream 3.0, a high-performance Chinese-English bilingual imagegeneration foundation model. We develop several technical improvements toaddress existing challenges in Seedream 2.0, including alignment withcomplicated prompts, fine-grained typography generation, suboptimal visualaesthetics and fidelity, and limited image resolutions. Specifically, theadvancements of Seedream 3.0 stem from improvements across the entire pipeline,from data construction to model deployment. At the data stratum, we double thedataset using a defect-aware training paradigm and a dual-axis collaborativedata-sampling framework. Furthermore, we adopt several effective techniquessuch as mixed-resolution training, cross-modality RoPE, representationalignment loss, and resolution-aware timestep sampling in the pre-trainingphase. During the post-training stage, we utilize diversified aestheticcaptions in SFT, and a VLM-based reward model with scaling, thereby achievingoutputs that well align with human preferences. Furthermore, Seedream 3.0pioneers a novel acceleration paradigm. By employing consistent noiseexpectation and importance-aware timestep sampling, we achieve a 4 to 8 timesspeedup while maintaining image quality. Seedream 3.0 demonstrates significantimprovements over Seedream 2.0: it enhances overall capabilities, in particularfor text-rendering in complicated Chinese characters which is important toprofessional typography generation. In addition, it provides nativehigh-resolution output (up to 2K), allowing it to generate images with highvisual quality.</description>
      <author>example@mail.com (Yu Gao, Lixue Gong, Qiushan Guo, Xiaoxia Hou, Zhichao Lai, Fanshi Li, Liang Li, Xiaochen Lian, Chao Liao, Liyang Liu, Wei Liu, Yichun Shi, Shiqi Sun, Yu Tian, Zhi Tian, Peng Wang, Rui Wang, Xuanda Wang, Xun Wang, Ye Wang, Guofeng Wu, Jie Wu, Xin Xia, Xuefeng Xiao, Zhonghua Zhai, Xinyu Zhang, Qi Zhang, Yuwei Zhang, Shijia Zhao, Jianchao Yang, Weilin Huang)</author>
      <guid isPermaLink="false">2504.11346v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TMCIR: Token Merge Benefits Composed Image Retrieval</title>
      <link>http://arxiv.org/abs/2504.10995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2310.05473 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TMCIR的新框架，用于改进组合图像检索（CIR），通过两个关键创新解决了视觉和文本信息融合的挑战。&lt;h4&gt;背景&lt;/h4&gt;组合图像检索（CIR）通过结合参考图像和描述所需修改的文本进行检索，但现有的跨模态特征融合方法在意图解释上存在固有的偏差。&lt;h4&gt;目的&lt;/h4&gt;提出TMCIR框架，以解决CIR中视觉和文本信息融合的挑战，并提高检索结果的准确性。&lt;h4&gt;方法&lt;/h4&gt;TMCIR框架包括两个关键创新：1）意图感知跨模态对齐，通过使用扩散模型合成的伪目标图像来微调CLIP编码器；2）自适应标记融合，通过比较自适应标记融合特征与目标图像来进一步微调所有编码器。&lt;h4&gt;主要发现&lt;/h4&gt;在Fashion-IQ和CIRR数据集上的实验表明，TMCIR在捕捉细微用户意图方面显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;TMCIR框架通过改进意图感知和自适应融合，提高了组合图像检索的准确性，特别是在捕捉用户细微意图方面表现突出。&lt;h4&gt;翻译&lt;/h4&gt;Composed Image Retrieval (CIR) retrieves target images using a multi-modal query that combines a reference image with text describing desired modifications. The primary challenge is effectively fusing this visual and textual information. Current cross-modal feature fusion approaches for CIR exhibit an inherent bias in intention interpretation. These methods tend to disproportionately emphasize either the reference image features (visual-dominant fusion) or the textual modification intent (text-dominant fusion through image-to-text conversion). Such an imbalanced representation often fails to accurately capture and reflect the actual search intent of the user in the retrieval results. To address this challenge, we propose TMCIR, a novel framework that advances composed image retrieval through two key innovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP encoders contrastively using intent-reflecting pseudo-target images, synthesized from reference images and textual descriptions via a diffusion model. This step enhances the encoder ability of text to capture nuanced intents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune all encoders contrastively by comparing adaptive token-fusion features with the target image. This mechanism dynamically balances visual and textual representations within the contrastive learning pipeline, optimizing the composed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR datasets demonstrate that TMCIR significantly outperforms state-of-the-art methods, particularly in capturing nuanced user intent.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Composed Image Retrieval (CIR) retrieves target images using a multi-modalquery that combines a reference image with text describing desiredmodifications. The primary challenge is effectively fusing this visual andtextual information. Current cross-modal feature fusion approaches for CIRexhibit an inherent bias in intention interpretation. These methods tend todisproportionately emphasize either the reference image features(visual-dominant fusion) or the textual modification intent (text-dominantfusion through image-to-text conversion). Such an imbalanced representationoften fails to accurately capture and reflect the actual search intent of theuser in the retrieval results. To address this challenge, we propose TMCIR, anovel framework that advances composed image retrieval through two keyinnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIPencoders contrastively using intent-reflecting pseudo-target images,synthesized from reference images and textual descriptions via a diffusionmodel. This step enhances the encoder ability of text to capture nuancedintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tuneall encoders contrastively by comparing adaptive token-fusion features with thetarget image. This mechanism dynamically balances visual and textualrepresentations within the contrastive learning pipeline, optimizing thecomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRRdatasets demonstrate that TMCIR significantly outperforms state-of-the-artmethods, particularly in capturing nuanced user intent.</description>
      <author>example@mail.com (Chaoyang Wang, Zeyu Zhang, Long Teng, Zijun Li, Shichao Kan)</author>
      <guid isPermaLink="false">2504.10995v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images</title>
      <link>http://arxiv.org/abs/2504.10972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AFiRe是一个用于增强放射图像分析的细粒度表示的自监督框架，它通过结合解剖一致性和Vision Transformer的独特处理方式来改进现有的自监督方法。&lt;h4&gt;背景&lt;/h4&gt;当前自监督方法如对比学习主要关注全局区分，忽视了准确放射学分析所需的细粒度解剖细节。&lt;h4&gt;目的&lt;/h4&gt;提出AFiRe框架以解决现有方法的不足，提高放射图像分析的准确性。&lt;h4&gt;方法&lt;/h4&gt;AFiRe执行两种自监督方案：(i) 基于解剖结构的token对比学习；(ii) 像素级异常去除和修复。此外，引入了合成病变掩码以增强解剖多样性。&lt;h4&gt;主要发现&lt;/h4&gt;AFiRe实现了以下发现：(i) 提供了稳健的解剖区分，与最先进的对比学习方法相比，特征聚类更紧密；(ii) 在多标签分类任务中展现出优越的泛化能力；(iii) 仅使用图像级注释即可实现精确的异常检测。&lt;h4&gt;结论&lt;/h4&gt;AFiRe能够有效地增强放射图像分析的细粒度表示，提高了解剖区分和异常检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1609/aaai.v39i18.34091&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current self-supervised methods, such as contrastive learning, predominantlyfocus on global discrimination, neglecting the critical fine-grained anatomicaldetails required for accurate radiographic analysis. To address this challenge,we propose an Anatomy-driven self-supervised framework for enhancingFine-grained Representation in radiographic image analysis (AFiRe). The coreidea of AFiRe is to align the anatomical consistency with the uniquetoken-processing characteristics of Vision Transformer. Specifically, AFiResynergistically performs two self-supervised schemes: (i) Token-wiseanatomy-guided contrastive learning, which aligns image tokens based onstructural and categorical consistency, thereby enhancing fine-grainedspatial-anatomical discrimination; (ii) Pixel-level anomaly-removalrestoration, which particularly focuses on local anomalies, thereby refiningthe learned discrimination with detailed geometrical information. Additionally,we propose Synthetic Lesion Mask to enhance anatomical diversity whilepreserving intra-consistency, which is typically corrupted by traditional dataaugmentations, such as Cropping and Affine transformations. Experimentalresults show that AFiRe: (i) provides robust anatomical discrimination,achieving more cohesive feature clusters compared to state-of-the-artcontrastive learning methods; (ii) demonstrates superior generalization,surpassing 7 radiography-specific self-supervised methods in multi-labelclassification tasks with limited labeling; and (iii) integrates fine-grainedinformation, enabling precise anomaly detection using only image-levelannotations.</description>
      <author>example@mail.com (Yihang Liu, Lianghua He, Ying Wen, Longzhen Yang, Hongzhou Chen)</author>
      <guid isPermaLink="false">2504.10972v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>How to Enhance Downstream Adversarial Robustness (almost) without Touching the Pre-Trained Foundation Model?</title>
      <link>http://arxiv.org/abs/2504.10850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 2 figures, 12 tables. Include 10 pages of appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种提高下游任务鲁棒性的方法，无需更新或访问基础模型的权重。&lt;h4&gt;背景&lt;/h4&gt;随着强大基础模型的出现，预训练-微调范式越来越流行。然而，由于对抗训练的计算复杂性高，无法对基础模型进行微调以提高其在下游任务上的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;在不更新/访问基础模型权重的情况下提高下游任务的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;从鲁棒性继承文献（Kim et al., 2020）中受到启发，通过理论调查，确定了鲁棒对比学习与监督学习的对抗鲁棒性之间的紧密关系。设计了一种简单而有效的鲁棒自动编码器作为数据预处理方法，在将数据输入基础模型之前使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法在提高下游任务的鲁棒性方面是有效的，验证了特征鲁棒性（由小的对抗对比损失隐含）与下游任务鲁棒性之间的联系。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高下游任务的鲁棒性，同时保持对基础模型的零访问。&lt;h4&gt;翻译&lt;/h4&gt;With the rise of powerful foundation models, a pre-training-fine-tuning paradigm becomes increasingly popular these days: A foundation model is pre-trained using a huge amount of data from various sources, and then the downstream users only need to fine-tune and adapt it to specific downstream tasks. However, due to the high computation complexity of adversarial training, it is not feasible to fine-tune the foundation model to improve its robustness on the downstream task. Observing the above challenge, we want to improve the downstream robustness without updating/accessing the weights in the foundation model. Inspired from existing literature in robustness inheritance (Kim et al., 2020), through theoretical investigation, we identify a close relationship between robust contrastive learning with the adversarial robustness of supervised learning. To further validate and utilize this theoretical insight, we design a simple-yet-effective robust auto-encoder as a data pre-processing method before feeding the data into the foundation model. The proposed approach has zero access to the foundation model when training the robust auto-encoder. Extensive experiments demonstrate the effectiveness of the proposed method in improving the robustness of downstream tasks, verifying the connection between the feature robustness (implied by small adversarial contrastive loss) and the robustness of the downstream task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of powerful foundation models, a pre-training-fine-tuningparadigm becomes increasingly popular these days: A foundation model ispre-trained using a huge amount of data from various sources, and then thedownstream users only need to fine-tune and adapt it to specific downstreamtasks. However, due to the high computation complexity of adversarial training,it is not feasible to fine-tune the foundation model to improve its robustnesson the downstream task. Observing the above challenge, we want to improve thedownstream robustness without updating/accessing the weights in the foundationmodel. Inspired from existing literature in robustness inheritance (Kim et al.,2020), through theoretical investigation, we identify a close relationshipbetween robust contrastive learning with the adversarial robustness ofsupervised learning. To further validate and utilize this theoretical insight,we design a simple-yet-effective robust auto-encoder as a data pre-processingmethod before feeding the data into the foundation model. The proposed approachhas zero access to the foundation model when training the robust auto-encoder.Extensive experiments demonstrate the effectiveness of the proposed method inimproving the robustness of downstream tasks, verifying the connection betweenthe feature robustness (implied by small adversarial contrastive loss) and therobustness of the downstream task.</description>
      <author>example@mail.com (Meiqi Liu, Zhuoqun Huang, Yue Xing)</author>
      <guid isPermaLink="false">2504.10850v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning</title>
      <link>http://arxiv.org/abs/2504.11195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为R-TPT的鲁棒测试时提示调优方法，用于减轻视觉语言模型在推理阶段的对抗攻击影响，并通过实验证明了其有效性。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型（如CLIP）因其流行而成为基础模型，但它们存在固有脆弱性，且使用开源模型的选择有限，导致对抗攻击风险较高。&lt;h4&gt;目的&lt;/h4&gt;提出R-TPT方法，旨在在不要求标签训练数据的情况下增强对抗攻击防御，并提高推理任务的灵活性。&lt;h4&gt;方法&lt;/h4&gt;R-TPT通过重新定义边缘熵目标函数，并引入基于可靠性的可插入式加权集成策略，以增强防御能力。&lt;h4&gt;主要发现&lt;/h4&gt;R-TPT在广泛使用的基准测试和多种攻击中表现出有效性，且无需标签训练数据。&lt;h4&gt;结论&lt;/h4&gt;R-TPT是一种有效的对抗攻击防御方法，适用于视觉语言模型，且对推理任务具有高度灵活性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉语言模型（VLMs），如CLIP，作为基础模型已经获得了显著的流行度，为了提升其在下游任务上的性能，已经开发了许多微调方法。然而，由于它们固有的脆弱性和从有限的开放源代码模型中进行选择的常见做法，VLMs相对于传统的视觉模型面临更高的对抗攻击风险。现有的防御技术通常依赖于训练过程中的对抗微调，这需要标签数据和缺乏对下游任务的灵活性。为了解决这些限制，我们提出了鲁棒测试时提示调优（R-TPT），它在推理阶段减轻了对抗攻击的影响。我们首先通过消除在对抗条件下引起冲突的项，仅保留点熵最小化，重新定义了经典的边缘熵目标函数。此外，我们引入了一种基于可靠性的可插入式加权集成策略，它通过聚合可靠的增强视图中的有用信息来加强防御。R-TPT在不要求标签训练数据的同时，提高了对抗攻击防御能力，并为推理任务提供了高度灵活性。在广泛使用的基准测试和多种攻击上的大量实验证明了R-TPT的有效性。代码可在https://github.com/TomSheng21/R-TPT上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs), such as CLIP, have gained significantpopularity as foundation models, with numerous fine-tuning methods developed toenhance performance on downstream tasks. However, due to their inherentvulnerability and the common practice of selecting from a limited set ofopen-source models, VLMs suffer from a higher risk of adversarial attacks thantraditional vision models. Existing defense techniques typically rely onadversarial fine-tuning during training, which requires labeled data and lacksof flexibility for downstream tasks. To address these limitations, we proposerobust test-time prompt tuning (R-TPT), which mitigates the impact ofadversarial attacks during the inference stage. We first reformulate theclassic marginal entropy objective by eliminating the term that introducesconflicts under adversarial conditions, retaining only the pointwise entropyminimization. Furthermore, we introduce a plug-and-play reliability-basedweighted ensembling strategy, which aggregates useful information from reliableaugmented views to strengthen the defense. R-TPT enhances defense againstadversarial attacks without requiring labeled training data while offering highflexibility for inference tasks. Extensive experiments on widely usedbenchmarks with various attacks demonstrate the effectiveness of R-TPT. Thecode is available in https://github.com/TomSheng21/R-TPT.</description>
      <author>example@mail.com (Lijun Sheng, Jian Liang, Zilei Wang, Ran He)</author>
      <guid isPermaLink="false">2504.11195v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data</title>
      <link>http://arxiv.org/abs/2504.11172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraMesh是一个全球多样化的多模态数据集，结合了光学、合成孔径雷达、高程和土地覆盖模态，旨在通过利用大量未标记数据来学习灵活、高效的表示。&lt;h4&gt;背景&lt;/h4&gt;现有的公共数据集在规模、地理覆盖范围或传感器多样性方面通常有限。&lt;h4&gt;目的&lt;/h4&gt;引入TerraMesh数据集，以促进大规模预训练和鲁棒的跨模态相关性学习。&lt;h4&gt;方法&lt;/h4&gt;TerraMesh包括超过900万个样本，具有八个时空对齐的模态，并提供了详细的数据处理步骤、全面的数据统计和实证证据。&lt;h4&gt;主要发现&lt;/h4&gt;在TerraMesh上预训练的模型性能得到了提高。&lt;h4&gt;结论&lt;/h4&gt;TerraMesh数据集将以许可协议的形式公开提供。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大规模地球观测基础模型可以通过利用大量未标记数据来学习灵活、高效的表示。然而，现有的公共数据集在规模、地理覆盖范围或传感器多样性方面通常有限。我们引入了TerraMesh，这是一个新的全球多样化的多模态数据集，结合了光学、合成孔径雷达、高程和土地覆盖模态，以分析准备数据格式。TerraMesh包括超过900万个样本，具有八个时空对齐的模态，使大规模预训练成为可能，并促进了鲁棒的跨模态相关性学习。我们提供了详细的数据处理步骤、全面的数据统计和实证证据，证明了在TerraMesh上预训练的模型性能得到提高。该数据集将以许可协议的形式公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models in Earth Observation can learn versatile,label-efficient representations by leveraging massive amounts of unlabeleddata. However, existing public datasets are often limited in scale, geographiccoverage, or sensor variety. We introduce TerraMesh, a new globally diverse,multimodal dataset combining optical, synthetic aperture radar, elevation, andland-cover modalities in an Analysis-Ready Data format. TerraMesh includes over9 million samples with eight spatiotemporal aligned modalities, enablinglarge-scale pre-training and fostering robust cross-modal correlation learning.We provide detailed data processing steps, comprehensive statistics, andempirical evidence demonstrating improved model performance when pre-trained onTerraMesh. The dataset will be made publicly available with a permissivelicense.</description>
      <author>example@mail.com (Benedikt Blumenstiel, Paolo Fraccaro, Valerio Marsocci, Johannes Jakubik, Stefano Maurogiovanni, Mikolaj Czerkawski, Rocco Sedona, Gabriele Cavallaro, Thomas Brunschwiler, Juan Bernabe-Moreno, Nicolas Longépé)</author>
      <guid isPermaLink="false">2504.11172v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>TerraMind: Large-Scale Generative Multimodality for Earth Observation</title>
      <link>http://arxiv.org/abs/2504.11171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TerraMind是一种新的地球观测（EO）生成式多模态基础模型，首次实现了任意模态之间的生成。&lt;h4&gt;背景&lt;/h4&gt;目前的多模态模型在地球观测领域存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出TerraMind模型，以提升地球观测数据的处理能力。&lt;h4&gt;方法&lt;/h4&gt;TerraMind在双尺度表示上预训练，结合了跨模态的标记级和像素级数据。在标记级别，TerraMind编码高层上下文信息以学习跨模态关系；在像素级别，利用精细的表示来捕捉关键的空间细微差别。模型在包含九种地理空间模态的全球大规模数据集上进行了预训练。&lt;h4&gt;主要发现&lt;/h4&gt;TerraMind的双尺度早期融合方法为地球观测解锁了零样本和少样本应用；TerraMind引入了“Thinking-in-Modalities”（TiM）能力，在微调和推理过程中生成额外的数据以提高模型输出；TerraMind在地球观测社区标准基准（如PANGAEA）上实现了超越现有最佳性能。&lt;h4&gt;结论&lt;/h4&gt;TerraMind是一个开放源代码的项目，其预训练数据集、模型权重和代码以许可协议开放。&lt;h4&gt;翻译&lt;/h4&gt;We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances. We pretrained TerraMind on nine geospatial modalities of a global, large-scale dataset. In this paper, we demonstrate that (i) TerraMind's dual-scale early fusion approach unlocks a range of zero-shot and few-shot applications for Earth observation, (ii) TerraMind introduces 'Thinking-in-Modalities' (TiM) -- the capability of generating additional artificial data during finetuning and inference to improve the model output -- and (iii) TerraMind achieves beyond state-of-the-art performance in community-standard benchmarks for EO like PANGAEA. The pretraining dataset, the model weights, and our code is open-sourced under a permissive license.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present TerraMind, the first any-to-any generative, multimodal foundationmodel for Earth observation (EO). Unlike other multimodal models, TerraMind ispretrained on dual-scale representations combining both token-level andpixel-level data across modalities. On a token level, TerraMind encodeshigh-level contextual information to learn cross-modal relationships, while ona pixel level, TerraMind leverages fine-grained representations to capturecritical spatial nuances. We pretrained TerraMind on nine geospatial modalitiesof a global, large-scale dataset. In this paper, we demonstrate that (i)TerraMind's dual-scale early fusion approach unlocks a range of zero-shot andfew-shot applications for Earth observation, (ii) TerraMind introduces"Thinking-in-Modalities" (TiM) -- the capability of generating additionalartificial data during finetuning and inference to improve the model output --and (iii) TerraMind achieves beyond state-of-the-art performance incommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, themodel weights, and our code is open-sourced under a permissive license.</description>
      <author>example@mail.com (Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis, Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Longépé)</author>
      <guid isPermaLink="false">2504.11171v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models</title>
      <link>http://arxiv.org/abs/2504.11054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的无监督强化学习算法，旨在解决现有方法在复杂环境中的局限性。&lt;h4&gt;背景&lt;/h4&gt;尽管无监督强化学习取得了进展，但现有方法存在需要针对每个下游任务运行RL过程、需要高质量的数据集以及预训练策略与下游任务相关性差等问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的算法，通过模仿未标记行为数据集的轨迹来正则化无监督强化学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为“前向-后向表示与条件策略正则化”的方法，该方法训练前向-后向表示来嵌入未标记轨迹到与状态、奖励和政策表示相同的潜在空间，并使用一个潜在条件判别器来鼓励策略“覆盖”未标记行为数据集中的状态。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够学习到与数据集中的行为良好对齐的策略，同时保持基于奖励和模仿任务的零样本泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在一个人形控制问题中，该方法通过仅利用观察数据集，训练了Meta Motivo，这是第一个可以提示解决包括运动跟踪、目标到达和奖励优化在内的各种全身任务的类人形行为基础模型。该模型能够表达类似人类的行为，并在性能上优于最先进的无监督强化学习和基于模型的基线方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的无监督强化学习算法，旨在解决现有方法在复杂环境中的局限性。尽管无监督强化学习取得了进展，但现有方法存在需要针对每个下游任务运行RL过程、需要高质量的数据集以及预训练策略与下游任务相关性差等问题。本文提出了一种名为“前向-后向表示与条件策略正则化”的方法，该方法训练前向-后向表示来嵌入未标记轨迹到与状态、奖励和政策表示相同的潜在空间，并使用一个潜在条件判别器来鼓励策略“覆盖”未标记行为数据集中的状态。该方法能够学习到与数据集中的行为良好对齐的策略，同时保持基于奖励和模仿任务的零样本泛化能力。在一个人形控制问题中，该方法通过仅利用观察数据集，训练了Meta Motivo，这是第一个可以提示解决包括运动跟踪、目标到达和奖励优化在内的各种全身任务的类人形行为基础模型。该模型能够表达类似人类的行为，并在性能上优于最先进的无监督强化学习和基于模型的基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised reinforcement learning (RL) aims at pre-training agents that cansolve a wide range of downstream tasks in complex environments. Despite recentadvancements, existing approaches suffer from several limitations: they mayrequire running an RL process on each downstream task to achieve a satisfactoryperformance, they may need access to datasets with good coverage orwell-curated task-specific samples, or they may pre-train policies withunsupervised losses that are poorly correlated with the downstream tasks ofinterest. In this paper, we introduce a novel algorithm regularizingunsupervised RL towards imitating trajectories from unlabeled behaviordatasets. The key technical novelty of our method, called Forward-BackwardRepresentations with Conditional-Policy Regularization, is to trainforward-backward representations to embed the unlabeled trajectories to thesame latent space used to represent states, rewards, and policies, and use alatent-conditional discriminator to encourage policies to ``cover'' the statesin the unlabeled behavior dataset. As a result, we can learn policies that arewell aligned with the behaviors in the dataset, while retaining zero-shotgeneralization capabilities for reward-based and imitation tasks. Wedemonstrate the effectiveness of this new approach in a challenging humanoidcontrol problem: leveraging observation-only motion capture datasets, we trainMeta Motivo, the first humanoid behavioral foundation model that can beprompted to solve a variety of whole-body tasks, including motion tracking,goal reaching, and reward optimization. The resulting model is capable ofexpressing human-like behaviors and it achieves competitive performance withtask-specific methods while outperforming state-of-the-art unsupervised RL andmodel-based baselines.</description>
      <author>example@mail.com (Andrea Tirinzoni, Ahmed Touati, Jesse Farebrother, Mateusz Guzek, Anssi Kanervisto, Yingchen Xu, Alessandro Lazaric, Matteo Pirotta)</author>
      <guid isPermaLink="false">2504.11054v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Defending Against Frequency-Based Attacks with Diffusion Models</title>
      <link>http://arxiv.org/abs/2504.11034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Computer Vision and Pattern Recognition Workshops  (CVPRW), 5th Workshop on Adversarial Machine Learning in Computer Vision:  Foundation Models + X&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对抗训练和对抗净化在提高模型鲁棒性方面的应用，特别是通过扩散模型进行噪声净化以应对对抗攻击。&lt;h4&gt;背景&lt;/h4&gt;对抗训练虽然能增强模型对特定攻击类型的鲁棒性，但其泛化能力有限，难以应对未见过的攻击模型。&lt;h4&gt;目的&lt;/h4&gt;探索对抗净化方法在应对不同类型对抗攻击，特别是频谱和空间攻击方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;利用生成模型进行对抗净化，独立训练净化器，以应对未见过的攻击场景。使用扩散模型进行噪声净化，不仅针对像素级对抗扰动，也应对非对抗数据偏移。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，对抗净化在处理不同频率区域的多种扭曲模式方面非常有效。&lt;h4&gt;结论&lt;/h4&gt;对抗净化是一种有效的提高模型鲁棒性的方法，特别是在应对频谱和空间对抗攻击方面具有显著效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adversarial training is a common strategy for enhancing model robustnessagainst adversarial attacks. However, it is typically tailored to the specificattack types it is trained on, limiting its ability to generalize to unseenthreat models. Adversarial purification offers an alternative by leveraging agenerative model to remove perturbations before classification. Since thepurifier is trained independently of both the classifier and the threat models,it is better equipped to handle previously unseen attack scenarios. Diffusionmodels have proven highly effective for noise purification, not only incountering pixel-wise adversarial perturbations but also in addressingnon-adversarial data shifts. In this study, we broaden the focus beyondpixel-wise robustness to explore the extent to which purification can mitigateboth spectral and spatial adversarial attacks. Our findings highlight itseffectiveness in handling diverse distortion patterns across low- tohigh-frequency regions.</description>
      <author>example@mail.com (Fatemeh Amerehi, Patrick Healy)</author>
      <guid isPermaLink="false">2504.11034v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Temporal Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图上链接预测，特别是时间序列链接预测（TLP），并提出了针对记忆模块模型的迁移学习方法。&lt;h4&gt;背景&lt;/h4&gt;链接预测在推荐系统和药物发现等领域有广泛应用。TLP需要处理图随时间演变的动态特性，现有模型结合记忆模块和图神经网络学习节点的时间机制和图拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;研究新的迁移学习方法，使记忆模块模型能够在测试和部署时应用于全新的图。&lt;h4&gt;方法&lt;/h4&gt;通过增强结构映射模块，将图结构特征映射到记忆嵌入中，从而提高模型在TLP任务中的信息量。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法为TLP构建了一个无需记忆的基座模型。&lt;h4&gt;结论&lt;/h4&gt;该研究为TLP领域提供了新的迁移学习策略，有助于提高模型在处理全新图数据时的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction on graphs has applications spanning from recommender systemsto drug discovery. Temporal link prediction (TLP) refers to predicting futurelinks in a temporally evolving graph and adds additional complexity related tothe dynamic nature of graphs. State-of-the-art TLP models incorporate memorymodules alongside graph neural networks to learn both the temporal mechanismsof incoming nodes and the evolving graph topology. However, memory modules onlystore information about nodes seen at train time, and hence such models cannotbe directly transferred to entirely new graphs at test time and deployment. Inthis work, we study a new transfer learning task for temporal link prediction,and develop transfer-effective methods for memory-laden models. Specifically,motivated by work showing the informativeness of structural signals for the TLPtask, we augment a structural mapping module to the existing TLP modelarchitectures, which learns a mapping from graph structural (topological)features to memory embeddings. Our work paves the way for a memory-freefoundation model for TLP.</description>
      <author>example@mail.com (Ayan Chatterjee, Barbara Ikica, Babak Ravandi, John Palowitch)</author>
      <guid isPermaLink="false">2504.10925v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization</title>
      <link>http://arxiv.org/abs/2504.10900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在Transformer架构中应用的领域感知自适应归一化策略，以解决在大型、多样化数据集上进行预训练时由于数据分布不匹配带来的挑战，尤其是在时间序列数据上。通过实验验证，该方法在分类和预测任务上显著优于传统预训练技术，并能有效减轻预训练过程中的分布偏移带来的负面影响。&lt;h4&gt;背景&lt;/h4&gt;基础模型在多个机器学习领域取得了显著成功，但大规模预训练引入了数据分布不匹配的挑战，尤其是在时间序列数据上。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决预训练数据分布不匹配问题的方法。&lt;h4&gt;方法&lt;/h4&gt;在Transformer架构中，用原型引导的动态归一化机制（ProtoNorm）替换传统的LayerNorm，通过学习原型来封装不同的数据分布，并利用样本到原型的亲和度确定适当的归一化层。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效捕捉了时间序列特性的异质性，使预训练表示与下游任务对齐。在分类和预测任务上，该方法显著优于传统预训练技术，并能有效减轻分布偏移的负面影响。&lt;h4&gt;结论&lt;/h4&gt;通过在真实世界的时间序列基准上的广泛实验，验证了该方法在鲁棒性和泛化性方面的有效性，推动了更通用的时间序列基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：通过在大型、多样化的数据集上进行大规模预训练，基础模型在多个机器学习领域取得了显著的成就。然而，在如此数据集上进行预训练引入了数据分布不匹配的显著挑战，这一问题在时间序列数据上尤为突出。在本文中，我们通过在Transformer架构内提出一种领域感知的自适应归一化策略来应对这一挑战。具体来说，我们用原型引导的动态归一化机制（ProtoNorm）替换了传统的层归一化（LayerNorm），其中学习的原型封装了不同的数据分布，而样本到原型的亲和度决定了适当的归一化层。这种机制有效地捕捉了时间序列特性的异质性，使预训练表示与下游任务相匹配。通过全面的实证评估，我们证明了该方法在分类和预测任务上显著优于传统的预训练技术，同时有效地减轻了预训练过程中分布偏移的负面影响。引入ProtoNorm就像替换一行代码一样简单。在真实世界的时间序列基准上的广泛实验验证了该方法的鲁棒性和泛化性，推动了更通用的时间序列基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved remarkable success across diversemachine-learning domains through large-scale pretraining on large, diversedatasets. However, pretraining on such datasets introduces significantchallenges due to substantial mismatches in data distributions, a problemparticularly pronounced with time series data. In this paper, we tackle thisissue by proposing a domain-aware adaptive normalization strategy within theTransformer architecture. Specifically, we replace the traditional LayerNormwith a prototype-guided dynamic normalization mechanism (ProtoNorm), wherelearned prototypes encapsulate distinct data distributions, andsample-to-prototype affinity determines the appropriate normalization layer.This mechanism effectively captures the heterogeneity of time seriescharacteristics, aligning pretrained representations with downstream tasks.Through comprehensive empirical evaluation, we demonstrate that our methodsignificantly outperforms conventional pretraining techniques across bothclassification and forecasting tasks, while effectively mitigating the adverseeffects of distribution shifts during pretraining. Incorporating ProtoNorm isas simple as replacing a single line of code. Extensive experiments on diversereal-world time series benchmarks validate the robustness and generalizabilityof our approach, advancing the development of more versatile time seriesfoundation models.</description>
      <author>example@mail.com (Peiliang Gong, Emadeldeen Eldele, Min Wu, Zhenghua Chen, Xiaoli Li, Daoqiang Zhang)</author>
      <guid isPermaLink="false">2504.10900v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>LVLM_CSP: Accelerating Large Vision Language Models via Clustering, Scattering, and Pruning for Reasoning Segmentation</title>
      <link>http://arxiv.org/abs/2504.10854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LVLM_CSP的新颖的视觉标记剪枝方法，用于基于大型视觉语言模型（LVLM）的推理分割任务，以降低计算开销。&lt;h4&gt;背景&lt;/h4&gt;LVLMs在视觉基础模型中用于推理分割任务表现出色，但它们的高计算开销是一个挑战，主要来源于处理大量图像标记。&lt;h4&gt;目的&lt;/h4&gt;设计一种剪枝方法，减少图像标记的数量，同时保持高分割精度。&lt;h4&gt;方法&lt;/h4&gt;LVLM_CSP包含三个阶段：聚类、散射和剪枝。首先使用选定的图像标记子集进行粗粒度视觉推理，然后进行细粒度推理，最后在最后一个阶段剪枝掉大多数视觉标记。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LVLM_CSP在图像标记推理FLOPs上实现了65%的减少，几乎没有精度下降，并且在7B LVLM上实现了70%的减少，精度仅下降了1%。&lt;h4&gt;结论&lt;/h4&gt;LVLM_CSP是一种有效的剪枝方法，能够在保持高分割精度的同时显著减少计算开销。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision Language Models (LVLMs) have been widely adopted to guide visionfoundation models in performing reasoning segmentation tasks, achievingimpressive performance. However, the substantial computational overheadassociated with LVLMs presents a new challenge. The primary source of thiscomputational cost arises from processing hundreds of image tokens. Therefore,an effective strategy to mitigate such overhead is to reduce the number ofimage tokens, a process known as image token pruning. Previous studies on imagetoken pruning for LVLMs have primarily focused on high level visualunderstanding tasks, such as visual question answering and image captioning. Incontrast, guiding vision foundation models to generate accurate visual masksbased on textual queries demands precise semantic and spatial reasoningcapabilities. Consequently, pruning methods must carefully control individualimage tokens throughout the LVLM reasoning process. Our empirical analysisreveals that existing methods struggle to adequately balance reductions incomputational overhead with the necessity to maintain high segmentationaccuracy. In this work, we propose LVLM_CSP, a novel training free visual tokenpruning method specifically designed for LVLM based reasoning segmentationtasks. LVLM_CSP consists of three stages: clustering, scattering, and pruning.Initially, the LVLM performs coarse-grained visual reasoning using a subset ofselected image tokens. Next, fine grained reasoning is conducted, and finally,most visual tokens are pruned in the last stage. Extensive experimentsdemonstrate that LVLM_CSP achieves a 65% reduction in image token inferenceFLOPs with virtually no accuracy degradation, and a 70% reduction with only aminor 1% drop in accuracy on the 7B LVLM.</description>
      <author>example@mail.com (Hanning Chen, Yang Ni, Wenjun Huang, Hyunwoo Oh, Yezi Liu, Tamoghno Das, Mohsen Imani)</author>
      <guid isPermaLink="false">2504.10854v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
      <link>http://arxiv.org/abs/2504.11454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://bytedance.github.io/dplm/dplm-2.1/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的多模态蛋白质语言模型（PLM）设计空间，以解决现有模型在3D结构细节和相关性上的精度损失问题。&lt;h4&gt;背景&lt;/h4&gt;多模态PLM整合序列和基于标记的结构信息，是蛋白质建模、生成和设计的基础，但依赖于将3D结构分割成离散标记会导致结构细节和相关性信息的损失。&lt;h4&gt;目的&lt;/h4&gt;系统地阐述多模态PLM的设计空间，以克服其局限性。&lt;h4&gt;方法&lt;/h4&gt;通过识别tokenization loss和PLM的不准确结构token预测，提出改进的生成建模、结构感知架构和表示学习方法，以及数据探索方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过更精细的监督，证明了基于token的多模态PLM可以实现鲁棒的结构建模。有效的设计方法显著提高了结构生成多样性和折叠能力，将650M模型在PDB测试集上的RMSD从5.52降低到2.36，甚至优于3B基线，与专业折叠模型相当。&lt;h4&gt;结论&lt;/h4&gt;本文提出的改进设计空间能够有效提升多模态PLM的性能，使其在蛋白质结构建模方面达到新的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal protein language models (PLMs) integrate sequence and token-basedstructural information, serving as a powerful foundation for protein modeling,generation, and design. However, the reliance on tokenizing 3D structures intodiscrete tokens causes substantial loss of fidelity about fine-grainedstructural details and correlations. In this paper, we systematically elucidatethe design space of multimodal PLMs to overcome their limitations. We identifytokenization loss and inaccurate structure token predictions by the PLMs asmajor bottlenecks. To address these, our proposed design space covers improvedgenerative modeling, structure-aware architectures and representation learning,and data exploration. Our advancements approach finer-grained supervision,demonstrating that token-based multimodal PLMs can achieve robust structuralmodeling. The effective design methods dramatically improve the structuregeneration diversity, and notably, folding abilities of our 650M model byreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3Bbaselines and on par with the specialized folding models.</description>
      <author>example@mail.com (Cheng-Yen, Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu)</author>
      <guid isPermaLink="false">2504.11454v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Out-of-Distribution Detection with Extended Logit Normalization</title>
      <link>http://arxiv.org/abs/2504.11434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的超参数无关的扩展Logit Normalization方法，旨在提高机器学习模型在分布外检测（OOD）方面的性能。&lt;h4&gt;背景&lt;/h4&gt;分布外检测对于机器学习模型的安全部署至关重要。尽管最近的研究在改进分类损失和表示学习方法方面取得了进展，但这些方法通常针对特定的后处理检测技术，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决Logit Normalization（LogitNorm）在提高某些后处理OOD检测方法有效性方面存在的问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出了Extended Logit Normalization（ELogitNorm），该方法通过将特征距离感知性融入LogitNorm，实现了比前驱方法更鲁棒的分布外分离和分布内（ID）置信度校准。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准上的广泛实验表明，该方法在OOD检测方面优于现有的训练时方法，同时在ID分类精度方面表现良好。&lt;h4&gt;结论&lt;/h4&gt;ELogitNorm方法能够显著提升后处理检测方法的性能，为机器学习模型的安全部署提供了有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分布外（OOD）检测对于机器学习模型的安全部署至关重要。最近的研究探索了改进分类损失和表示学习策略以提高OOD检测。然而，这些方法通常针对特定的后处理检测技术，限制了它们的泛化能力。在这项工作中，我们确定了Logit Normalization（LogitNorm）中的一个关键问题，这阻碍了它在提高某些后处理OOD检测方法有效性方面的效果。为了解决这个问题，我们提出了Extended Logit Normalization（ELogitNorm），这是一种新颖的超参数无关的公式，它显著提高了广泛的后处理检测方法的性能。通过将特征距离感知性融入LogitNorm，ELogitNorm比其前驱方法显示了更强的分布外分离和分布内（ID）置信度校准。在标准基准上的广泛实验表明，我们的方法在分布外检测方面优于最先进的方法，同时保持了强大的分布内分类精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection is essential for the safe deployment ofmachine learning models. Recent advances have explored improved classificationlosses and representation learning strategies to enhance OOD detection.However, these methods are often tailored to specific post-hoc detectiontechniques, limiting their generalizability. In this work, we identify acritical issue in Logit Normalization (LogitNorm), which inhibits itseffectiveness in improving certain post-hoc OOD detection methods. To addressthis, we propose Extended Logit Normalization ($\textbf{ELogitNorm}$), a novelhyperparameter-free formulation that significantly benefits a wide range ofpost-hoc detection methods. By incorporating feature distance-awareness toLogitNorm, $\textbf{ELogitNorm}$ shows more robust OOD separability andin-distribution (ID) confidence calibration than its predecessor. Extensiveexperiments across standard benchmarks demonstrate that our approachoutperforms state-of-the-art training-time methods in OOD detection whilemaintaining strong ID classification accuracy.</description>
      <author>example@mail.com (Yifan Ding, Xixi Liu, Jonas Unger, Gabriel Eilertsen)</author>
      <guid isPermaLink="false">2504.11434v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Network Alignment</title>
      <link>http://arxiv.org/abs/2504.11367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了网络对齐研究的最新进展，包括网络对齐的特性分析和不同领域的应用进展。&lt;h4&gt;背景&lt;/h4&gt;复杂网络常用于模拟物理或虚拟复杂系统，网络对齐对于揭示不同系统间实体关系至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过网络对齐增强对复杂系统结构和行为的理解，促进理论物理研究在复杂系统领域的验证和扩展。&lt;h4&gt;方法&lt;/h4&gt;本文分析了基于结构一致性、网络嵌入和图神经网络的各种网络对齐方法，并讨论了在不同网络类型（如属性网络、异构网络、有向网络和动态网络）下的对齐方法。&lt;h4&gt;主要发现&lt;/h4&gt;不同领域的网络对齐研究存在术语和概念的不一致性，本文详细分析了各种方法的实现原理、过程和性能差异。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了网络对齐领域面临的挑战和开放性问题，为未来的研究提供了方向。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the latest advancements in network alignment research, including the analysis of network alignment characteristics and progress in various domains such as social network analysis, bioinformatics, computational linguistics, and privacy protection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.physrep.2024.11.006&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex networks are frequently employed to model physical or virtual complexsystems. When certain entities exist across multiple systems simultaneously,unveiling their corresponding relationships across the networks becomescrucial. This problem, known as network alignment, holds significantimportance. It enhances our understanding of complex system structures andbehaviours, facilitates the validation and extension of theoretical physicsresearch about studying complex systems, and fosters diverse practicalapplications across various fields. However, due to variations in thestructure, characteristics, and properties of complex networks across differentfields, the study of network alignment is often isolated within each domain,with even the terminologies and concepts lacking uniformity. This reviewcomprehensively summarizes the latest advancements in network alignmentresearch, focusing on analyzing network alignment characteristics and progressin various domains such as social network analysis, bioinformatics,computational linguistics and privacy protection. It provides a detailedanalysis of various methods' implementation principles, processes, andperformance differences, including structure consistency-based methods, networkembedding-based methods, and graph neural network-based (GNN-based) methods.Additionally, the methods for network alignment under different conditions,such as in attributed networks, heterogeneous networks, directed networks, anddynamic networks, are presented. Furthermore, the challenges and the openissues for future studies are also discussed.</description>
      <author>example@mail.com (Rui Tang, Ziyun Yong, Shuyu Jiang, Xingshu Chen, Yaofang Liu, Yi-Cheng Zhang, Gui-Quan Sun, Wei Wang)</author>
      <guid isPermaLink="false">2504.11367v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*</title>
      <link>http://arxiv.org/abs/2504.11014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9pages, 1 supple&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE3D的新框架，专门用于通用单目3D目标检测，通过弱监督学习提高模型在多领域数据集上的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉领域正在发展通用模型，这些模型能够同时处理多种不同的任务。这种通用性通常需要跨多领域数据集的联合训练以确保有效的泛化。然而，由于缺乏标注准确的3D真实标签的数据集，特别是在典型的基于道路的自动驾驶环境之外，单目3D目标检测在多领域训练中面临着独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，本文提出了一种利用伪标签的弱监督框架，旨在提高单目3D目标检测的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文提出的GATE3D框架通过在2D和3D预测之间应用一致性损失来有效地弥合领域差距。该框架利用了预训练策略，以加速从有限的标注数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;GATE3D在KITTI基准数据集和作者收集的室内办公数据集上均取得了有竞争力的性能，证明了该框架在泛化能力方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;GATE3D显著加速了从有限标注数据中的学习，显示出在机器人、增强现实和虚拟现实应用中的广泛潜力。&lt;h4&gt;翻译&lt;/h4&gt;The emerging trend in computer vision emphasizes developing universal models capable of simultaneously addressing multiple diverse tasks. Such universality typically requires joint training across multi-domain datasets to ensure effective generalization. However, monocular 3D object detection presents unique challenges in multi-domain training due to the scarcity of datasets annotated with accurate 3D ground-truth labels, especially beyond typical road-based autonomous driving contexts. To address this challenge, we introduce a novel weakly supervised framework leveraging pseudo-labels. Current pretrained models often struggle to accurately detect pedestrians in non-road environments due to inherent dataset biases. Unlike generalized image-based 2D object detection models, achieving similar generalization in monocular 3D detection remains largely unexplored. In this paper, we propose GATE3D, a novel framework designed specifically for generalized monocular 3D object detection via weak supervision. GATE3D effectively bridges domain gaps by employing consistency losses between 2D and 3D predictions. Remarkably, our model achieves competitive performance on the KITTI benchmark as well as on an indoor-office dataset collected by us to evaluate the generalization capabilities of our framework. Our results demonstrate that GATE3D significantly accelerates learning from limited annotated data through effective pre-training strategies, highlighting substantial potential for broader impacts in robotics, augmented reality, and virtual reality applications. Project page: https://ies0411.github.io/GATE3D/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging trend in computer vision emphasizes developing universal modelscapable of simultaneously addressing multiple diverse tasks. Such universalitytypically requires joint training across multi-domain datasets to ensureeffective generalization. However, monocular 3D object detection presentsunique challenges in multi-domain training due to the scarcity of datasetsannotated with accurate 3D ground-truth labels, especially beyond typicalroad-based autonomous driving contexts. To address this challenge, we introducea novel weakly supervised framework leveraging pseudo-labels. Currentpretrained models often struggle to accurately detect pedestrians in non-roadenvironments due to inherent dataset biases. Unlike generalized image-based 2Dobject detection models, achieving similar generalization in monocular 3Ddetection remains largely unexplored. In this paper, we propose GATE3D, a novelframework designed specifically for generalized monocular 3D object detectionvia weak supervision. GATE3D effectively bridges domain gaps by employingconsistency losses between 2D and 3D predictions. Remarkably, our modelachieves competitive performance on the KITTI benchmark as well as on anindoor-office dataset collected by us to evaluate the generalizationcapabilities of our framework. Our results demonstrate that GATE3Dsignificantly accelerates learning from limited annotated data througheffective pre-training strategies, highlighting substantial potential forbroader impacts in robotics, augmented reality, and virtual realityapplications. Project page: https://ies0411.github.io/GATE3D/</description>
      <author>example@mail.com (Eunsoo Im, Jung Kwon Lee, Changhyun Jee)</author>
      <guid isPermaLink="false">2504.11014v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction</title>
      <link>http://arxiv.org/abs/2504.11264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DeepSelective的深度学习框架，用于利用电子健康记录（EHRs）预测患者预后，该框架结合了数据压缩技术和创新的特征选择方法，旨在提高模型的准确性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;随着电子健康记录的快速积累，传统的机器学习模型在临床预测和诊断中发挥了作用，但它们往往缺乏鲁棒的表现学习，并且高度依赖专家手工制作的特征。虽然深度学习提供了强大的解决方案，但通常因其缺乏可解释性而受到批评。&lt;h4&gt;目的&lt;/h4&gt;提出DeepSelective框架，以增强模型的可解释性，并提高使用EHR数据预测患者预后的准确性。&lt;h4&gt;方法&lt;/h4&gt;DeepSelective结合了数据压缩技术和创新的特征选择方法，包括自定义设计的模块，以改善准确性和可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DeepSelective不仅提高了预测准确性，还显著提高了可解释性，使其成为临床决策的有价值工具。&lt;h4&gt;结论&lt;/h4&gt;DeepSelective是一种有效的深度学习框架，可用于提高基于EHR数据的患者预后预测的准确性和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电子健康记录（EHRs）的快速积累通过提供增强临床预测和诊断的有价值数据而改变了医疗保健。虽然传统的机器学习模型已被证明是有效的，但它们通常缺乏鲁棒的表现学习，并且高度依赖于专家手工制作的特征。尽管深度学习提供了强大的解决方案，但它通常因其缺乏可解释性而受到批评。为了解决这些挑战，我们提出了一种名为DeepSelective的新型端到端深度学习框架，用于使用EHR数据预测患者预后，该框架特别强调增强模型的可解释性。DeepSelective结合了数据压缩技术与创新的特征选择方法，整合了协同工作的自定义设计模块，以提高准确性和可解释性。我们的实验表明，DeepSelective不仅提高了预测准确性，还显著提高了可解释性，使其成为临床决策的有价值工具。源代码可在http://www.healthinformaticslab.org/supp/resources.php免费获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid accumulation of Electronic Health Records (EHRs) has transformedhealthcare by providing valuable data that enhance clinical predictions anddiagnoses. While conventional machine learning models have proven effective,they often lack robust representation learning and depend heavily onexpert-crafted features. Although deep learning offers powerful solutions, itis often criticized for its lack of interpretability. To address thesechallenges, we propose DeepSelective, a novel end to end deep learningframework for predicting patient prognosis using EHR data, with a strongemphasis on enhancing model interpretability. DeepSelective combines datacompression techniques with an innovative feature selection approach,integrating custom-designed modules that work together to improve both accuracyand interpretability. Our experiments demonstrate that DeepSelective not onlyenhances predictive accuracy but also significantly improves interpretability,making it a valuable tool for clinical decision-making. The source code isfreely available at http://www.healthinformaticslab.org/supp/resources.php .</description>
      <author>example@mail.com (Ruochi Zhang, Qian Yang, Xiaoyang Wang, Haoran Wu, Qiong Zhou, Yu Wang, Kewei Li, Yueying Wang, Yusi Fan, Jiale Zhang, Lan Huang, Chang Liu, Fengfeng Zhou)</author>
      <guid isPermaLink="false">2504.11264v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Features in Long-tailed Data Using Large Vision Mode</title>
      <link>http://arxiv.org/abs/2504.10852v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究使用大型视觉模型（LVMs）或视觉基础模型（VFMs）来增强长尾数据特征，而不依赖于语言信息。&lt;h4&gt;背景&lt;/h4&gt;语言模型如大型语言模型（LLMs）或大型视觉-语言模型（LVLMs）在长尾识别中已被广泛研究，但并非所有实际任务都需要语言数据。&lt;h4&gt;目的&lt;/h4&gt;探索使用LVMs或VFMs来增强长尾数据特征，无需语言信息。&lt;h4&gt;方法&lt;/h4&gt;从LVM提取特征，与基线网络的图和潜在空间中的特征融合，获得增强特征。设计几个基于原型的损失函数在潜在空间中进一步挖掘增强特征潜力。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet-LT和iNaturalist2018两个基准数据集上验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地利用视觉模型增强长尾数据特征，无需语言信息。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the use of large visual models (LVMs) or visual foundation models (VFMs) to enhance long-tailed data features without the need for linguistic information. In particular, features are extracted from the LVM and fused with features in the map and latent space of the baseline network to obtain augmented features. Additionally, several prototype-based losses are designed in the latent space to further exploit the potential of the augmented features. In the experimental section, our approach is validated on two benchmark datasets: ImageNet-LT and iNaturalist2018.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language-based foundation models, such as large language models (LLMs) orlarge vision-language models (LVLMs), have been widely studied in long-tailedrecognition. However, the need for linguistic data is not applicable to allpractical tasks. In this study, we aim to explore using large vision models(LVMs) or visual foundation models (VFMs) to enhance long-tailed data featureswithout any language information. Specifically, we extract features from theLVM and fuse them with features in the baseline network's map and latent spaceto obtain the augmented features. Moreover, we design several prototype-basedlosses in the latent space to further exploit the potential of the augmentedfeatures. In the experimental section, we validate our approach on twobenchmark datasets: ImageNet-LT and iNaturalist2018.</description>
      <author>example@mail.com (Pengxiao Han, Changkun Ye, Jinguang Tong, Cuicui Jiang, Jie Hong, Li Fang, Xuesong Li)</author>
      <guid isPermaLink="false">2504.10852v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Point Transformers for Detecting Anatomical Landmarks in Digital Dentistry</title>
      <link>http://arxiv.org/abs/2504.11418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages + references, 3 figures, MICCAI2024 3DTeethland Challenge  submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了口腔扫描设备在临床正畸中的重要性，并提出了一种基于点云学习的Transformer架构方法，用于自动识别患者牙齿的关键地标。&lt;h4&gt;背景&lt;/h4&gt;随着口腔扫描设备的普及，其在现代临床正畸中的应用越来越重要。正畸医生利用计算机辅助设计技术创建患者专属的治疗计划，需要费力地识别诸如牙尖、近远中位置、面部轴线点和牙齿牙龈边界等关键地标。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种自动识别牙齿关键地标的方法，以解决现有方法中存在的数据集规模有限、个体间解剖学差异大以及数据几何性质带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;本文提出的实验来自2024年MICCAI的3DTeethLandGrand Challenge。方法利用最近在点云学习方面的进展，设计了一个受PointTransformer v3启发的模块，用于捕获有意义的几何和解剖特征。这些特征经过轻量级解码器处理后预测每点的距离，再通过基于图的非最小抑制进一步处理。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在识别牙齿关键地标方面取得了有希望的结果，并讨论了学习到的特征的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该方法为自动识别牙齿关键地标提供了一种有效的解决方案，有助于提高临床正畸的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;随着口腔扫描设备的日益普及，其在现代临床正畸中的应用日益重要。临床医生利用先进的计算机辅助设计技术创建患者专属的治疗计划，包括费力地识别关键地标，如牙尖、近远中位置、面部轴线点和牙齿牙龈边界。自动检测此类地标提出了挑战，包括数据集规模有限、个体间解剖学差异显著以及数据的几何性质。我们展示了我们在MICCAI 2024年3DTeethLandGrand Challenge中的实验。我们的方法利用了点云学习方面的最新进展，通过Transformer架构。我们设计了一个受PointTransformer v3启发的模块，以捕获有意义的几何和解剖特征，这些特征通过轻量级解码器处理以预测每点的距离，然后通过基于图的非最小抑制进一步处理。我们报告了有希望的结果，并讨论了学习到的特征的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing availability of intraoral scanning devices has heightenedtheir importance in modern clinical orthodontics. Clinicians utilize advancedComputer-Aided Design techniques to create patient-specific treatment plansthat include laboriously identifying crucial landmarks such as cusps,mesial-distal locations, facial axis points, and tooth-gingiva boundaries.Detecting such landmarks automatically presents challenges, including limiteddataset sizes, significant anatomical variability among subjects, and thegeometric nature of the data. We present our experiments from the 3DTeethLandGrand Challenge at MICCAI 2024. Our method leverages recent advancements inpoint cloud learning through transformer architectures. We designed a PointTransformer v3 inspired module to capture meaningful geometric and anatomicalfeatures, which are processed by a lightweight decoder to predict per-pointdistances, further processed by graph-based non-minima suppression. We reportpromising results and discuss insights on learned feature interpretability.</description>
      <author>example@mail.com (Tibor Kubík, Oldřich Kodym, Petr Šilling, Kateřina Trávníčková, Tomáš Mojžiš, Jan Matula)</author>
      <guid isPermaLink="false">2504.11418v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis</title>
      <link>http://arxiv.org/abs/2504.11082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态融合在多模态情感分析中的深度和容量分配问题，提出了DeepMLF模型，并通过实验验证了深度融合和融合深度对性能的影响。&lt;h4&gt;背景&lt;/h4&gt;多模态融合在多模态情感分析中已得到广泛研究，但融合深度和容量分配仍需进一步探索。&lt;h4&gt;目的&lt;/h4&gt;将融合深度、可扩展性和专用的多模态容量定位为有效融合的主要因素，并提出一种新的多模态语言模型DeepMLF。&lt;h4&gt;方法&lt;/h4&gt;DeepMLF模型利用音频视觉编码器和预训练的解码器语言模型，并在其层中集成多模态信息。模型通过可学习的标记捕获模态交互，并通过因果自注意力机制和交叉注意力机制实现融合。&lt;h4&gt;主要发现&lt;/h4&gt;DeepMLF在三个具有不同数据集特性的多模态情感分析基准测试中达到了最先进的性能，证明了更深层次的融合和适当的融合深度（5-7）优于现有方法。实验还表明，小的标记集（约20个）可以达到最佳性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和模型在多模态情感分析中具有优越性，并提供了对DeepMLF可扩展性和每个训练目标的全面考察。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然多模态融合在多模态情感分析（MSA）中已被广泛研究，但融合深度和多模态容量分配仍被低估。在这项工作中，我们将融合深度、可扩展性和专用多模态容量定位为有效融合的主要因素。我们引入了DeepMLF，这是一种新的面向深度融合的多模态语言模型（LM），具有可学习的标记。DeepMLF利用音频视觉编码器和预训练的解码器LM，在其层中集成多模态信息。我们向LM添加可学习的标记，这些标记：1）以受控的方式捕获模态交互，2）为每个模态保留独立的信息流。这些融合标记通过LM块中的因果自注意力机制收集语言信息，并通过交叉注意力MM块与音频视觉信息集成。作为专用的多模态容量，这种设计使多个层之间的融合逐步进行，在融合过程中提供深度。我们的训练方法结合了模态特定损失和语言模型损失，解码器LM的任务是预测真实极性。在三个具有不同数据集特性的MSA基准测试中，DeepMLF实现了最先进的性能。我们的结果表明，更深层次的融合会导致更好的性能，最佳融合深度（5-7）优于现有方法。此外，我们对融合标记数量的分析表明，小的标记集（约20个）可以达到最佳性能。我们通过音频视觉编码器初始化实验检查了表示学习顺序（融合课程）的重要性。我们的消融研究表明，所提出的融合设计和门控提供了对DeepMLF可扩展性的全面考察，以及每个训练目标和嵌入正则化的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While multimodal fusion has been extensively studied in Multimodal SentimentAnalysis (MSA), the role of fusion depth and multimodal capacity allocationremains underexplored. In this work, we position fusion depth, scalability, anddedicated multimodal capacity as primary factors for effective fusion. Weintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokenstailored toward deep fusion. DeepMLF leverages an audiovisual encoder and apretrained decoder LM augmented with multimodal information across its layers.We append learnable tokens to the LM that: 1) capture modality interactions ina controlled fashion and 2) preserve independent information flow for eachmodality. These fusion tokens gather linguistic information via causalself-attention in LM Blocks and integrate with audiovisual information throughcross-attention MM Blocks. Serving as dedicated multimodal capacity, thisdesign enables progressive fusion across multiple layers, providing depth inthe fusion process. Our training recipe combines modality-specific losses andlanguage modelling loss, with the decoder LM tasked to predict ground truthpolarity. Across three MSA benchmarks with varying dataset characteristics,DeepMLF achieves state-of-the-art performance. Our results confirm that deeperfusion leads to better performance, with optimal fusion depths (5-7) exceedingthose of existing approaches. Additionally, our analysis on the number offusion tokens reveals that small token sets ($\sim$20) achieve optimalperformance. We examine the importance of representation learning order (fusioncurriculum) through audiovisual encoder initialization experiments. Ourablation studies demonstrate the superiority of the proposed fusion design andgating while providing a holistic examination of DeepMLF's scalability to LLMs,and the impact of each training objective and embedding regularization.</description>
      <author>example@mail.com (Efthymios Georgiou, Vassilis Katsouros, Yannis Avrithis, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2504.11082v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Accurate Machine Learning Interatomic Potentials for Polyacene Molecular Crystals: Application to Single Molecule Host-Guest Systems</title>
      <link>http://arxiv.org/abs/2504.11224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过开发一种基于图神经网络MACE架构和主动学习策略的通用机器学习原子间势（MLIP），对一系列聚芴基分子晶体（如萘、蒽、四芴和五芴）的振动动力学进行了准确描述。&lt;h4&gt;背景&lt;/h4&gt;尽管MLIP在大型材料模拟中具有潜力，但关于分子晶体振动动力学的严格测试还很少。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够准确描述分子晶体振动动力学的通用MLIP。&lt;h4&gt;方法&lt;/h4&gt;使用MACE架构和主动学习策略，对聚芴基分子晶体进行模拟，并通过仔细的错误传播验证了势能的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;这些势能能够准确描述非谐波振动特性、振动寿命和振动耦合。特别研究了基于这些分子晶体的宿主-客体系统，展示了基于分子动力学的技术能够解释和量化宿主和客体核运动之间的振动耦合。&lt;h4&gt;结论&lt;/h4&gt;本研究建立了一个理解大型复杂分子系统振动特征的平台，对于在分子环境中设计振动相互作用具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging machine learning interatomic potentials (MLIPs) offer a promisingsolution for large-scale accurate material simulations, but stringent testsrelated to the description of vibrational dynamics in molecular crystals remainscarce. Here, we develop a general MLIP by leveraging the graph neuralnetwork-based MACE architecture and active-learning strategies to accuratelycapture vibrational dynamics across a range of polyacene-based molecularcrystals, namely naphthalene, anthracene, tetracene and pentacene. Throughcareful error propagation, we show that these potentials are accurate andenable the study of anharmonic vibrational features, vibrational lifetimes, andvibrational coupling. In particular, we investigate large-scale host-guestsystems based on these molecular crystals, showing the capacity ofmolecular-dynamics-based techniques to explain and quantify vibrationalcoupling between host and guest nuclear motion. Our results establish aframework for understanding vibrational signatures in large-scale complexmolecular systems and thus represent an important step for engineeringvibrational interactions in molecular environments.</description>
      <author>example@mail.com (Burak Gurlek, Shubham Sharma, Paolo Lazzaroni, Angel Rubio, Mariana Rossi)</author>
      <guid isPermaLink="false">2504.11224v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust Trajectory Embedding for Similarity Computation: When Triangle Inequality Violations in Distance Metrics Matter</title>
      <link>http://arxiv.org/abs/2504.10933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于非欧几里得几何（双曲空间）的轨迹表示学习方法，以解决传统相似度函数计算复杂度高和依赖特定距离度量的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的轨迹相似度函数存在计算复杂度高和依赖于特定距离度量的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决欧几里得嵌入中三角形不等式约束的限制。&lt;h4&gt;方法&lt;/h4&gt;通过设计Lorentz距离度量，结合Cosh函数优化的投影方法，以及动态融合距离，将双曲空间嵌入到现有的表示学习流程中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过实验验证，有效地提高了多个真实世界数据集上最先进模型的轨迹相似度度量准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅解决了三角形不等式问题，还显著提高了轨迹相似度计算的精确度，在轨迹表示学习领域取得了实质性进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：轨迹相似性是轨迹数据管理和分析的基础。传统的相似度函数往往具有高计算复杂性和对特定距离度量的依赖性，这促使人们转向欧几里得空间中的深度表示学习。然而，现有的基于欧几里得空间的轨迹嵌入通常面临着由于三角形不等式约束而导致的挑战，这些约束并不适用于所有轨迹数据。为了解决这个问题，本文通过将非欧几里得几何（特别是双曲空间）引入轨迹表示学习，提出了一种新颖的方法。我们提出了首次将双曲空间整合到解决欧几里得嵌入中三角形不等式内在限制的方法。特别是，我们通过设计Lorentz距离度量来实现这一点，该度量已被证明可以克服三角形不等式约束。此外，我们设计了一个模型无关的框架LH-plugin，以无缝地将双曲嵌入集成到现有的表示学习流程中。这包括一个使用Cosh函数优化的新型投影方法，该方法具有理论基础，以防止距离的减少。此外，我们提出了一种动态融合距离，它智能地适应不同轨迹对之间三角形不等式约束的变化，通过结合洛伦兹距离和欧几里得距离来进行更稳健的相似度计算。全面的实验评估表明，我们的方法有效地提高了多个真实世界数据集上最先进模型的轨迹相似度度量的准确性。LH-plugin不仅解决了三角形不等式问题，而且显著提高了轨迹相似度计算的精确度，标志着轨迹表示学习领域的重大进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory similarity is a cornerstone of trajectory data management andanalysis. Traditional similarity functions often suffer from high computationalcomplexity and a reliance on specific distance metrics, prompting a shifttowards deep representation learning in Euclidean space. However, existingEuclidean-based trajectory embeddings often face challenges due to the triangleinequality constraints that do not universally hold for trajectory data. Toaddress this issue, this paper introduces a novel approach by incorporatingnon-Euclidean geometry, specifically hyperbolic space, into trajectoryrepresentation learning. We present the first-ever integration of hyperbolicspace to resolve the inherent limitations of the triangle inequality inEuclidean embeddings. In particular, we achieve it by designing a Lorentzdistance measure, which is proven to overcome triangle inequality constraints.Additionally, we design a model-agnostic framework LH-plugin to seamlesslyintegrate hyperbolic embeddings into existing representation learningpipelines. This includes a novel projection method optimized with the Coshfunction to prevent the diminishment of distances, supported by a theoreticalfoundation. Furthermore, we propose a dynamic fusion distance thatintelligently adapts to variations in triangle inequality constraints acrossdifferent trajectory pairs, blending Lorentzian and Euclidean distances formore robust similarity calculations. Comprehensive experimental evaluationsdemonstrate that our approach effectively enhances the accuracy of trajectorysimilarity measures in state-of-the-art models across multiple real-worlddatasets. The LH-plugin not only addresses the triangle inequality issues butalso significantly refines the precision of trajectory similarity computations,marking a substantial advancement in the field of trajectory representationlearning.</description>
      <author>example@mail.com (Jianing Si, Haitao Yuan, Nan Jiang, Minxiao Chen, Xiao Ma, Shangguang Wang)</author>
      <guid isPermaLink="false">2504.10933v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Meta-learning For Few-Shot Time Series Crop Type Classification: A Benchmark On The EuroCropsML Dataset</title>
      <link>http://arxiv.org/abs/2504.11022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究对转移学习和多种元学习算法在农作物类型分类任务中的应用进行了评估。&lt;h4&gt;背景&lt;/h4&gt;作物类型数据的空间不均衡对遥感应用中的准确分类构成重大挑战。&lt;h4&gt;目的&lt;/h4&gt;评估元学习算法在现实世界应用中的性能，并建立评价转移和元学习方法的基准。&lt;h4&gt;方法&lt;/h4&gt;在EuroCropsML时间序列数据集上，对基于MAML的元学习算法（包括(FO)-MAML、ANIL和TIML）进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;与简单的迁移学习方法相比，基于MAML的元学习算法在爱沙尼亚的农作物类型分类任务中取得了略微更高的准确率，但代价是更高的计算需求和训练时间。&lt;h4&gt;结论&lt;/h4&gt;不同地区间知识迁移具有挑战性，强调了在真实世界农作物类型分类任务中选择机器学习方法时准确性和计算资源需求之间的权衡。&lt;h4&gt;翻译&lt;/h4&gt;Spatial imbalances in crop type data pose significant challenges for accurate classification in remote sensing applications. Algorithms aiming at transferring knowledge from data-rich to data-scarce tasks have thus surged in popularity. However, despite their effectiveness in previous evaluations, their performance in challenging real-world applications is unclear and needs to be evaluated. This study benchmarks transfer learning and several meta-learning algorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML), Almost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on the real-world EuroCropsML time series dataset, which combines farmer-reported crop data with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal. Our findings indicate that MAML-based meta-learning algorithms achieve slightly higher accuracy compared to simpler transfer learning methods when applied to crop type classification tasks in Estonia after pre-training on data from Latvia. However, this improvement comes at the cost of increased computational demands and training time. Moreover, we find that the transfer of knowledge between geographically disparate regions, such as Estonia and Portugal, poses significant challenges to all investigated algorithms. These insights underscore the trade-offs between accuracy and computational resource requirements in selecting machine learning methods for real-world crop type classification tasks and highlight the difficulties of transferring knowledge between different regions of the Earth. To facilitate future research in this domain, we present the first comprehensive benchmark for evaluating transfer and meta-learning methods for crop type classification under real-world conditions. The corresponding code is publicly available at https://github.com/dida-do/eurocrops-meta-learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial imbalances in crop type data pose significant challenges for accurateclassification in remote sensing applications. Algorithms aiming attransferring knowledge from data-rich to data-scarce tasks have thus surged inpopularity. However, despite their effectiveness in previous evaluations, theirperformance in challenging real-world applications is unclear and needs to beevaluated. This study benchmarks transfer learning and several meta-learningalgorithms, including (First-Order) Model-Agnostic Meta-Learning ((FO)-MAML),Almost No Inner Loop (ANIL), and Task-Informed Meta-Learning (TIML), on thereal-world EuroCropsML time series dataset, which combines farmer-reported cropdata with Sentinel-2 satellite observations from Estonia, Latvia, and Portugal.Our findings indicate that MAML-based meta-learning algorithms achieve slightlyhigher accuracy compared to simpler transfer learning methods when applied tocrop type classification tasks in Estonia after pre-training on data fromLatvia. However, this improvement comes at the cost of increased computationaldemands and training time. Moreover, we find that the transfer of knowledgebetween geographically disparate regions, such as Estonia and Portugal, posessignificant challenges to all investigated algorithms. These insightsunderscore the trade-offs between accuracy and computational resourcerequirements in selecting machine learning methods for real-world crop typeclassification tasks and highlight the difficulties of transferring knowledgebetween different regions of the Earth. To facilitate future research in thisdomain, we present the first comprehensive benchmark for evaluating transferand meta-learning methods for crop type classification under real-worldconditions. The corresponding code is publicly available athttps://github.com/dida-do/eurocrops-meta-learning.</description>
      <author>example@mail.com (Joana Reuss, Jan Macdonald, Simon Becker, Konrad Schultka, Lorenz Richter, Marco Körner)</author>
      <guid isPermaLink="false">2504.11022v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild</title>
      <link>http://arxiv.org/abs/2504.11326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop Page: https://pvuw.github.io/. arXiv admin note: text  overlap with arXiv:2504.00476, arXiv:2504.05178&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本报告全面概述了与CVPR 2025联合举办的第4届像素级视频理解挑战赛（PVUW），总结了挑战赛结果、参赛方法和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;挑战赛与CVPR 2025联合举办，为像素级视频理解领域提供了一个综合性的平台。&lt;h4&gt;目的&lt;/h4&gt;报告旨在总结挑战赛成果，分析参赛方法，并指出未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;挑战赛分为两个赛道：MOSE（关注复杂场景视频目标分割）和MeViS（针对运动引导、基于语言的视频分割）。两个赛道都引入了新的、更具挑战性的数据集，以更好地反映现实场景。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细评估和分析，挑战赛提供了关于复杂视频分割当前最先进技术和新兴趋势的宝贵见解。&lt;h4&gt;结论&lt;/h4&gt;更多信息可在挑战赛网站（https://pvuw.github.io/）找到。&lt;h4&gt;翻译&lt;/h4&gt;This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025. It summarizes the challenge outcomes, participating methodologies, and future research directions. The challenge features two tracks: MOSE, which focuses on complex scene video object segmentation, and MeViS, which targets motion-guided, language-based video segmentation. Both tracks introduce new, more challenging datasets designed to better reflect real-world scenarios. Through detailed evaluation and analysis, the challenge offers valuable insights into the current state-of-the-art and emerging trends in complex video segmentation. More information can be found on the workshop website: https://pvuw.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report provides a comprehensive overview of the 4th Pixel-level VideoUnderstanding in the Wild (PVUW) Challenge, held in conjunction with CVPR 2025.It summarizes the challenge outcomes, participating methodologies, and futureresearch directions. The challenge features two tracks: MOSE, which focuses oncomplex scene video object segmentation, and MeViS, which targetsmotion-guided, language-based video segmentation. Both tracks introduce new,more challenging datasets designed to better reflect real-world scenarios.Through detailed evaluation and analysis, the challenge offers valuableinsights into the current state-of-the-art and emerging trends in complex videosegmentation. More information can be found on the workshop website:https://pvuw.github.io/.</description>
      <author>example@mail.com (Henghui Ding, Chang Liu, Nikhila Ravi, Shuting He, Yunchao Wei, Song Bai, Philip Torr, Kehuan Song, Xinglin Xie, Kexin Zhang, Licheng Jiao, Lingling Li, Shuyuan Yang, Xuqiang Cao, Linnan Zhao, Jiaxuan Zhao, Fang Liu, Mengjiao Wang, Junpei Zhang, Xu Liu, Yuting Yang, Mengru Ma, Hao Fang, Runmin Cong, Xiankai Lu, Zhiyang Che, Wei Zhan, Tianming Liang, Haichao Jiang, Wei-Shi Zheng, Jian-Fang Hu, Haobo Yuan, Xiangtai Li, Tao Zhang, Lu Qi, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2504.11326v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control</title>
      <link>http://arxiv.org/abs/2504.10831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SafeGPT的两层框架，该框架将生成预训练变压器（GPT）与强化学习（RL）结合，以提高无人机（UAV）最后一公里配送的效率和可靠性。&lt;h4&gt;背景&lt;/h4&gt;无人机配送领域需要一种既能进行高效决策又能保证安全的系统。&lt;h4&gt;目的&lt;/h4&gt;开发一个既能实现高效配送又能保证安全的无人机配送系统。&lt;h4&gt;方法&lt;/h4&gt;SafeGPT框架包括一个全局GPT模块负责高级任务如区域分配，以及一个设备端GPT负责实时本地路径规划。一个基于RL的安全过滤器监控GPT的决策，并覆盖可能导致电池耗尽或重复访问的不安全行动。此外，双回放缓冲机制帮助GPT模块和RL代理随着时间的推移改进其策略。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，SafeGPT相比仅使用GPT的基线，实现了更高的配送成功率，同时大幅降低了电池消耗和行驶距离。&lt;h4&gt;结论&lt;/h4&gt;将基于GPT的语义推理与正式的安全保证相结合是有效的，为鲁棒且节能的无人机物流提供了一种可行的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为SafeGPT的两层框架，该框架将生成预训练变压器（GPT）与强化学习（RL）结合，以提高无人机（UAV）最后一公里配送的效率和可靠性。在所提出的设计中，一个全局GPT模块负责分配高级任务，如区域分配，而一个设备端GPT负责实时本地路径规划。一个基于强化学习（RL）的安全过滤器监控每个GPT的决策，并覆盖可能导致电池耗尽或重复访问的不安全行动，有效地减轻了幻觉。此外，一个双回放缓冲机制帮助GPT模块和RL代理随着时间的推移改进他们的策略。模拟结果表明，与仅使用GPT的基线相比，SafeGPT实现了更高的配送成功率，同时大幅降低了电池消耗和行驶距离。这些发现验证了将基于GPT的语义推理与正式的安全保证相结合的有效性，为鲁棒且节能的无人机物流提供了一个可行的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes SafeGPT, a two-tiered framework that integratesgenerative pretrained transformers (GPTs) with reinforcement learning (RL) forefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. Inthe proposed design, a Global GPT module assigns high-level tasks such assector allocation, while an On-Device GPT manages real-time local routeplanning. An RL-based safety filter monitors each GPT decision and overridesunsafe actions that could lead to battery depletion or duplicate visits,effectively mitigating hallucinations. Furthermore, a dual replay buffermechanism helps both the GPT modules and the RL agent refine their strategiesover time. Simulation results demonstrate that SafeGPT achieves higher deliverysuccess rates compared to a GPT-only baseline, while substantially reducingbattery consumption and travel distance. These findings validate the efficacyof combining GPT-based semantic reasoning with formal safety guarantees,contributing a viable solution for robust and energy-efficient UAV logistics.</description>
      <author>example@mail.com (Hyojun Ahn, Seungcheol Oh, Gyu Seon Kim, Soyi Jung, Soohyun Park, Joongheon Kim)</author>
      <guid isPermaLink="false">2504.10831v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning</title>
      <link>http://arxiv.org/abs/2504.10753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为BDECF的贝叶斯深度集成协同过滤方法，旨在解决传统推荐系统在处理显式反馈和稀疏数据时的过拟合和预测中未考虑认知不确定性等问题。&lt;h4&gt;背景&lt;/h4&gt;推荐系统是一个基础任务，研究一直在努力改进。现有的许多模型使用表示学习将用户和物品映射到统一嵌入空间进行匹配评估，但存在过拟合和未考虑不确定性等局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的推荐方法，以提高模型泛化能力和预测质量，并解决过拟合和不确定性问题。&lt;h4&gt;方法&lt;/h4&gt;采用贝叶斯神经网络，结合注意力机制引入可解释的非线性匹配方法，并使用集成模型生成更稳健可靠的预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛实验和消融研究，验证了BDECF方法的有效性及其组成部分的重要性。&lt;h4&gt;结论&lt;/h4&gt;BDECF方法在处理显式反馈和稀疏数据时表现出色，为推荐系统领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommending items to users has long been a fundamental task, and studieshave tried to improve it ever since. Most well-known models commonly employrepresentation learning to map users and items into a unified embedding spacefor matching assessment. These approaches have primary limitations, especiallywhen dealing with explicit feedback and sparse data contexts. Two primarylimitations are their proneness to overfitting and failure to incorporateepistemic uncertainty in predictions. To address these problems, we propose anovel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. Toimprove model generalization and quality, we utilize Bayesian Neural Networks,which incorporate uncertainty within their weight parameters. In addition, weintroduce a new interpretable non-linear matching approach for the user anditem embeddings, leveraging the advantages of the attention mechanism.Furthermore, we endorse the implementation of an ensemble-based supermodel togenerate more robust and reliable predictions, resulting in a more completemodel. Empirical evaluation through extensive experiments and ablation studiesacross a range of publicly accessible real-world datasets with differingsparsity characteristics confirms our proposed method's effectiveness and theimportance of its components.</description>
      <author>example@mail.com (Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee)</author>
      <guid isPermaLink="false">2504.10753v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image</title>
      <link>http://arxiv.org/abs/2504.11230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in CVPR 2025 (Highlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在机器人操作任务中关节物体的类别级姿态估计，并引入了一个新的基准数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在类别级别估计部分姿态和大小时，通常依赖于几何线索和复杂的多阶段流程，包括从点云中分割部分，然后进行标准化部分坐标空间（NPCS）的6D姿态估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，本文提出了一种名为CAP-Net的单阶段网络，用于估计类别级关节部分的6D姿态和尺寸。&lt;h4&gt;方法&lt;/h4&gt;CAP-Net结合RGB-D特征，以端到端的方式生成每个部分的实例分割和NPCS表示。该网络使用统一的网络同时预测点级类别标签、质心偏移和NPCS图。然后，基于估计的质心距离将同一预测类别的点聚类，以隔离每个部分。最后，将每个部分的NPCS区域与点云对齐，以恢复其最终姿态和尺寸。&lt;h4&gt;主要发现&lt;/h4&gt;本文引入的RGBD-Art数据集是迄今为止最大的RGB-D关节数据集，具有逼真的RGB图像和从真实传感器模拟的深度噪声。在RGBD-Art数据集上的实验评估表明，该方法显著优于现有方法。在机器人任务中的实际部署强调了该模型的鲁棒性和卓越的仿真到现实迁移能力，证实了其实际应用价值。&lt;h4&gt;结论&lt;/h4&gt;本文提出的CAP-Net方法在姿态估计方面取得了显著的性能提升，同时引入的RGBD-Art数据集为该领域提供了重要的资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles category-level pose estimation of articulated objects inrobotic manipulation tasks and introduces a new benchmark dataset. While recentmethods estimate part poses and sizes at the category level, they often rely ongeometric cues and complex multi-stage pipelines that first segment parts fromthe point cloud, followed by Normalized Part Coordinate Space (NPCS) estimationfor 6D poses. These approaches overlook dense semantic cues from RGB images,leading to suboptimal accuracy, particularly for objects with small parts. Toaddress these limitations, we propose a single-stage Network, CAP-Net, forestimating the 6D poses and sizes of Categorical Articulated Parts. This methodcombines RGB-D features to generate instance segmentation and NPCSrepresentations for each part in an end-to-end manner. CAP-Net uses a unifiednetwork to simultaneously predict point-wise class labels, centroid offsets,and NPCS maps. A clustering algorithm then groups points of the same predictedclass based on their estimated centroid distances to isolate each part.Finally, the NPCS region of each part is aligned with the point cloud torecover its final pose and size. To bridge the sim-to-real domain gap, weintroduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date,featuring photorealistic RGB images and depth noise simulated from realsensors. Experimental evaluations on the RGBD-Art dataset demonstrate that ourmethod significantly outperforms the state-of-the-art approach. Real-worlddeployments of our model in robotic tasks underscore its robustness andexceptional sim-to-real transfer capabilities, confirming its substantialpractical utility. Our dataset, code and pre-trained models are available onthe project page.</description>
      <author>example@mail.com (Jingshun Huang, Haitao Lin, Tianyu Wang, Yanwei Fu, Xiangyang Xue, Yi Zhu)</author>
      <guid isPermaLink="false">2504.11230v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Visual Re-Ranking with Non-Visual Side Information</title>
      <link>http://arxiv.org/abs/2504.11134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Scandinavian Conference on Image Analysis (SCIA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于图神经网络的重新排序方法GCSA，用于视觉场景识别，旨在提高检索和定位任务的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉场景识别方法使用全局图像描述符进行检索，并通过重新排序方法改进结果，但现有方法主要基于相同的描述符进行重新排序，这限制了额外信号的获取。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，利用除了视觉描述符之外的其他类型的信息，如传感器数据或几何属性，以提高场景识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;开发了GCSA，它利用亲和向量允许对异构多模态输入进行共享编码，并在两个大规模数据集上进行了训练和评估。&lt;h4&gt;主要发现&lt;/h4&gt;在图像检索和下游视觉定位任务上，该方法显示出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;GCSA作为一种基于图神经网络的重新排序方法，能够有效提高视觉场景识别的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The standard approach for visual place recognition is to use global imagedescriptors to retrieve the most similar database images for a given queryimage. The results can then be further improved with re-ranking methods thatre-order the top scoring images. However, existing methods focus on re-rankingbased on the same image descriptors that were used for the initial retrieval,which we argue provides limited additional signal.  In this work we propose Generalized Contextual Similarity Aggregation (GCSA),which is a graph neural network-based re-ranking method that, in addition tothe visual descriptors, can leverage other types of available side information.This can for example be other sensor data (such as signal strength of nearbyWiFi or BlueTooth endpoints) or geometric properties such as camera poses fordatabase images. In many applications this information is already present orcan be acquired with low effort. Our architecture leverages the concept ofaffinity vectors to allow for a shared encoding of the heterogeneousmulti-modal input. Two large-scale datasets, covering both outdoor and indoorlocalization scenarios, are utilized for training and evaluation. Inexperiments we show significant improvement not only on image retrievalmetrics, but also for the downstream visual localization task.</description>
      <author>example@mail.com (Gustav Hanning, Gabrielle Flood, Viktor Larsson)</author>
      <guid isPermaLink="false">2504.11134v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>3DAffordSplat: Efficient Affordance Reasoning with 3D Gaussians</title>
      <link>http://arxiv.org/abs/2504.11218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first large-scale 3D Gaussians Affordance Reasoning Benchmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了3D affordance reasoning在关联人类指令与3D物体功能区域中的重要性，并提出了3DAffordSplat和AffordSplatNet，旨在提高3DGS在 affordance reasoning 中的表现。&lt;h4&gt;背景&lt;/h4&gt;现有的3D affordance reasoning方法依赖于稀疏的3D点云，存在泛化性和鲁棒性不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于3D Gaussian Splatting (3DGS) 的 affordance reasoning 方法，并构建一个大规模的、多模态的3DGS-specific affordance dataset。&lt;h4&gt;方法&lt;/h4&gt;构建了3DAffordSplat，一个包含23,677个高斯实例、8,354个点云实例和6,631个手动标注的affordance标签的大规模数据集。提出了AffordSplatNet模型，该模型具有创新的跨模态结构对齐模块，用于对齐3D点云和3DGS表示，以提高affordance recognition的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;3DAffordSplat数据集显著推进了3DGS领域的affordance学习，AffordSplatNet在已见和未见设置中均优于现有方法，展示了其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;3DAffordSplat和AffordSplatNet为3D affordance reasoning提供了新的解决方案，提高了affordance recognition的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D affordance reasoning is essential in associating human instructions withthe functional regions of 3D objects, facilitating precise, task-orientedmanipulations in embodied AI. However, current methods, which predominantlydepend on sparse 3D point clouds, exhibit limited generalizability androbustness due to their sensitivity to coordinate variations and the inherentsparsity of the data. By contrast, 3D Gaussian Splatting (3DGS) delivershigh-fidelity, real-time rendering with minimal computational overhead byrepresenting scenes as dense, continuous distributions. This positions 3DGS asa highly effective approach for capturing fine-grained affordance details andimproving recognition accuracy. Nevertheless, its full potential remainslargely untapped due to the absence of large-scale, 3DGS-specific affordancedatasets. To overcome these limitations, we present 3DAffordSplat, the firstlarge-scale, multi-modal dataset tailored for 3DGS-based affordance reasoning.This dataset includes 23,677 Gaussian instances, 8,354 point cloud instances,and 6,631 manually annotated affordance labels, encompassing 21 objectcategories and 18 affordance types. Building upon this dataset, we introduceAffordSplatNet, a novel model specifically designed for affordance reasoningusing 3DGS representations. AffordSplatNet features an innovative cross-modalstructure alignment module that exploits structural consistency priors to align3D point cloud and 3DGS representations, resulting in enhanced affordancerecognition accuracy. Extensive experiments demonstrate that the 3DAffordSplatdataset significantly advances affordance learning within the 3DGS domain,while AffordSplatNet consistently outperforms existing methods across both seenand unseen settings, highlighting its robust generalization capabilities.</description>
      <author>example@mail.com (Zeming wei, Junyi Lin, Yang Liu, Weixing Chen, Jingzhou Luo, Guanbin Li, Liang Lin)</author>
      <guid isPermaLink="false">2504.11218v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>OmniVDiff: Omni Controllable Video Diffusion for Generation and Understanding</title>
      <link>http://arxiv.org/abs/2504.10825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our project page: https://tele-ai.github.io/OmniVDiff/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OmniVDiff的新型可控视频扩散框架，旨在通过单个扩散模型合成和理解多种视频视觉内容。&lt;h4&gt;背景&lt;/h4&gt;当前视频处理方法通常需要多个模型来处理不同的视觉模态，这增加了复杂性和计算成本。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在一个扩散模型中合成和理解多种视频视觉内容的框架。&lt;h4&gt;方法&lt;/h4&gt;OmniVDiff将所有视频视觉模态处理为颜色空间中的联合分布，并采用自适应控制策略，动态调整每个视觉模态在扩散过程中的角色，可以是生成模态或条件模态。&lt;h4&gt;主要发现&lt;/h4&gt;OmniVDiff支持三种关键功能：(1) 文本条件视频生成；(2) 视频理解；(3) X条件视频生成。通过将这些任务整合到一个统一的视频扩散框架中，OmniVDiff提高了可控视频扩散的灵活性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验证明了该方法的有效性，并突出了其在各种视频相关应用中的潜力，如视频到视频的翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel framework for controllable video diffusion,OmniVDiff, aiming to synthesize and comprehend multiple video visual content ina single diffusion model. To achieve this, OmniVDiff treats all video visualmodalities in the color space to learn a joint distribution, while employing anadaptive control strategy that dynamically adjusts the role of each visualmodality during the diffusion process, either as a generation modality or aconditioning modality. This allows flexible manipulation of each modality'srole, enabling support for a wide range of tasks. Consequently, our modelsupports three key functionalities: (1) Text-conditioned video generation:multi-modal visual video sequences (i.e., rgb, depth, canny, segmentaion) aregenerated based on the text conditions in one diffusion process; (2) Videounderstanding: OmniVDiff can estimate the depth, canny map, and semanticsegmentation across the input rgb frames while ensuring coherence with the rgbinput; and (3) X-conditioned video generation: OmniVDiff generates videosconditioned on fine-grained attributes (e.g., depth maps or segmentation maps).By integrating these diverse tasks into a unified video diffusion framework,OmniVDiff enhances the flexibility and scalability for controllable videodiffusion, making it an effective tool for a variety of downstreamapplications, such as video-to-video translation. Extensive experimentsdemonstrate the effectiveness of our approach, highlighting its potential forvarious video-related applications.</description>
      <author>example@mail.com (Dianbing Xi, Jiepeng Wang, Yuanzhi Liang, Xi Qiu, Yuchi Huo, Rui Wang, Chi Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2504.10825v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Textual Embeddings from Contrastive Learning with Generative Recommender for Enhanced Personalization</title>
      <link>http://arxiv.org/abs/2504.10545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at https://www.github.com/snapfinger/HSTU-BLaIR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合生成模型和预训练语言模型的混合框架，用于改进推荐系统。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在近期发展强调了生成建模和预训练语言模型的优势互补。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合框架，以增强Hierarchical Sequential Transduction Unit（HSTU）生成推荐器。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了HSTU和对比文本嵌入模型BLaIR，以丰富物品表示并保留HSTU的序列建模能力。&lt;h4&gt;主要发现&lt;/h4&gt;在Amazon Reviews 2023数据集的两个领域上评估了该方法，与原始HSTU和结合OpenAI的text-embedding-3-large模型的变体相比，轻量级的BLaIR增强方法在计算高效的环境中表现出色。&lt;h4&gt;结论&lt;/h4&gt;BLaIR增强的轻量级方法在特定领域数据上预训练，能够在计算高效的环境中实现更好的性能，证明了对比文本嵌入的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in recommender systems have highlighted the complementarystrengths of generative modeling and pretrained language models. We propose ahybrid framework that augments the Hierarchical Sequential Transduction Unit(HSTU) generative recommender with BLaIR -- a contrastive text embedding model.This integration enriches item representations with semantic signals fromtextual metadata while preserving HSTU's powerful sequence modelingcapabilities.  We evaluate our method on two domains from the Amazon Reviews 2023 dataset,comparing it against the original HSTU and a variant that incorporatesembeddings from OpenAI's state-of-the-art text-embedding-3-large model. Whilethe OpenAI embedding model is likely trained on a substantially larger corpuswith significantly more parameters, our lightweight BLaIR-enhanced approach --pretrained on domain-specific data -- consistently achieves better performance,highlighting the effectiveness of contrastive text embeddings incompute-efficient settings.</description>
      <author>example@mail.com (Yijun Liu)</author>
      <guid isPermaLink="false">2504.10545v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Tabular foundation model to detect empathy from visual cues</title>
      <link>http://arxiv.org/abs/2504.10808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从视频中检测同理心，提出使用表格基础模型进行同理心检测，实验结果表明该方法在交叉主体同理心检测精度上有显著提升。&lt;h4&gt;背景&lt;/h4&gt;由于隐私和伦理问题，视频数据集通常以提取的特征（表格数据）形式发布，而非原始视频。&lt;h4&gt;目的&lt;/h4&gt;探索使用表格基础模型从表格视觉特征中检测同理心。&lt;h4&gt;方法&lt;/h4&gt;实验中使用了TabPFN v2和TabICL两个表格基础模型，通过上下文学习和微调的方式进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;在公共人机交互基准测试中，该方法在交叉主体同理心检测精度上比多个基线模型有显著提升（精度从0.590提升到0.730；AUC从0.564提升到0.669）。&lt;h4&gt;结论&lt;/h4&gt;该方法在同理心检测上有效，且有望应用于未来同理心检测视频数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从视频交互中检测同理心是研究的一个新兴领域。然而，由于隐私和伦理问题的考虑，视频数据集通常以提取的特征（即表格数据）的形式发布，而不是原始视频。先前对这类表格数据集的研究已经确定了基于树的经典机器学习方法为最佳性能模型。受文本基础模型（即大型语言模型）近期成功的影响，我们探索了在表格视觉特征中检测同理心时使用表格基础模型。我们通过上下文学习和微调设置，对两个最近的表格基础模型——TabPFN v2和TabICL进行了实验。我们在公共人机交互基准测试上的实验表明，与多个基线相比，该方法在交叉主体同理心检测精度上有显著的提升（精度：0.590 → 0.730；AUC：0.564 → 0.669）。除了性能提升外，我们还贡献了新的见解和评估设置，以确保在公共基准测试中未见过的主体上的泛化。鉴于发布视频特征作为表格数据集的做法可能因隐私限制而持续，我们的发现也将广泛适用于未来的同理心检测视频数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting empathy from video interactions is an emerging area of research.Video datasets, however, are often released as extracted features (i.e.,tabular data) rather than raw footage due to privacy and ethical concerns.Prior research on such tabular datasets established tree-based classicalmachine learning approaches as the best-performing models. Motivated by therecent success of textual foundation models (i.e., large language models), weexplore the use of tabular foundation models in empathy detection from tabularvisual features. We experiment with two recent tabular foundation models $-$TabPFN v2 and TabICL $-$ through in-context learning and fine-tuning setups.Our experiments on a public human-robot interaction benchmark demonstrate asignificant boost in cross-subject empathy detection accuracy over severalstrong baselines (accuracy: $0.590 \rightarrow 0.730$; AUC: $0.564 \rightarrow0.669$). In addition to performance improvement, we contribute novel insightsand an evaluation setup to ensure generalisation on unseen subjects in thispublic benchmark. As the practice of releasing video features as tabulardatasets is likely to persist due to privacy constraints, our findings will bewidely applicable to future empathy detection video datasets as well.</description>
      <author>example@mail.com (Md Rakibul Hasan, Shafin Rahman, Md Zakir Hossain, Aneesh Krishna, Tom Gedeon)</author>
      <guid isPermaLink="false">2504.10808v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>SDFs from Unoriented Point Clouds using Neural Variational Heat Distances</title>
      <link>http://arxiv.org/abs/2504.11212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 16 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的变分方法，用于从无向点云计算神经符号距离场（SDF）。该方法使用热方法替代常见的波动方程，将离散表面上计算距离的标准实践扩展到神经域。&lt;h4&gt;背景&lt;/h4&gt;传统的计算SDF的方法通常使用波动方程，但在神经域中计算距离时，这种方法并不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以计算无向点云的神经SDF，并证明该方法在表面重建和SDF梯度计算上的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用热方法替代波动方程，通过计算无向点云的加权密度作为初始数据，通过一小段时间步的热流来计算无符号距离场的神经近似梯度。然后，使用这个梯度来计算SDF的神经近似。证明了变分问题是有良好定义的。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提供了最先进的表面重建和一致的SDF梯度，并且通过概念验证表明，它足够准确，可以解决零水平集上的偏微分方程。&lt;h4&gt;结论&lt;/h4&gt;该方法在计算神经SDF方面是有效的，并且对于解决零水平集上的偏微分方程是准确的。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的变分方法，用于从无向点云计算神经符号距离场（SDF）。为此，我们用热方法替换了常用的波动方程，将离散表面上计算距离的标准实践扩展到神经域。这产生了两个凸优化问题，我们使用神经网络来解决它们：我们首先通过一小段时间步的热流，使用加权点云密度作为初始数据，计算无符号距离场梯度的神经近似。然后，我们使用它来计算SDF的神经近似。我们证明了背后的变分问题是有良好定义的。通过数值实验，我们证明了我们的方法提供了最先进的表面重建和一致的SDF梯度。此外，我们在一个概念验证中表明，它足够准确，可以解决零水平集上的偏微分方程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel variational approach for computing neural Signed DistanceFields (SDF) from unoriented point clouds. To this end, we replace the commonlyused eikonal equation with the heat method, carrying over to the neural domainwhat has long been standard practice for computing distances on discretesurfaces. This yields two convex optimization problems for whose solution weemploy neural networks: We first compute a neural approximation of thegradients of the unsigned distance field through a small time step of heat flowwith weighted point cloud densities as initial data. Then we use it to computea neural approximation of the SDF. We prove that the underlying variationalproblems are well-posed. Through numerical experiments, we demonstrate that ourmethod provides state-of-the-art surface reconstruction and consistent SDFgradients. Furthermore, we show in a proof-of-concept that it is accurateenough for solving a PDE on the zero-level set.</description>
      <author>example@mail.com (Samuel Weidemaier, Florine Hartwig, Josua Sassen, Sergio Conti, Mirela Ben-Chen, Martin Rumpf)</author>
      <guid isPermaLink="false">2504.11212v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification</title>
      <link>http://arxiv.org/abs/2504.11091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端的人工智能引导的抗生素发现流程，该流程涵盖了从靶点识别到化合物实现的整个过程。&lt;h4&gt;背景&lt;/h4&gt;抗生素耐药性成为全球性的健康危机，需要新的治疗策略来针对新型细菌机制。蛋白质结构预测和机器学习驱动的分子生成在药物发现中提供了加速的机会。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将蛋白质结构预测和机器学习模型集成到实际流程中的抗生素发现流程。&lt;h4&gt;方法&lt;/h4&gt;利用基于结构的聚类分析，对多种病原体的预测蛋白质组进行聚类，以识别保守的、必要的、非人类同源靶点。对六种领先的3D结构感知生成模型进行系统性评估，包括扩散模型、自回归模型、图神经网络和语言模型架构，评估其可用性、化学有效性和生物学相关性。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的后期处理过滤和商业类似物搜索，将生成的超过10万个化合物减少到一个聚焦且可合成的集合。DeepBlock和TamGen在多个标准上表现出色，同时揭示了模型复杂性、可用性和输出质量之间的关键权衡。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一个比较基准和蓝图，用于在抗生素早期开发中部署人工智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Antibiotic resistance presents a growing global health crisis, demanding newtherapeutic strategies that target novel bacterial mechanisms. Recent advancesin protein structure prediction and machine learning-driven molecule generationoffer a promising opportunity to accelerate drug discovery. However, practicalguidance on selecting and integrating these models into real-world pipelinesremains limited. In this study, we develop an end-to-end, artificialintelligence-guided antibiotic discovery pipeline that spans targetidentification to compound realization. We leverage structure-based clusteringacross predicted proteomes of multiple pathogens to identify conserved,essential, and non-human-homologous targets. We then systematically evaluatesix leading 3D-structure-aware generative models$\unicode{x2014}$spanningdiffusion, autoregressive, graph neural network, and language modelarchitectures$\unicode{x2014}$on their usability, chemical validity, andbiological relevance. Rigorous post-processing filters and commercial analoguesearches reduce over 100 000 generated compounds to a focused, synthesizableset. Our results highlight DeepBlock and TamGen as top performers acrossdiverse criteria, while also revealing critical trade-offs between modelcomplexity, usability, and output quality. This work provides a comparativebenchmark and blueprint for deploying artificial intelligence in early-stageantibiotic development.</description>
      <author>example@mail.com (Maximilian G. Schuh, Joshua Hesse, Stephan A. Sieber)</author>
      <guid isPermaLink="false">2504.11091v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Q-Cluster: Quantum Error Mitigation Through Noise-Aware Unsupervised Learning</title>
      <link>http://arxiv.org/abs/2504.10801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Q-Cluster的新型量子错误缓解(QEM)方法，通过无监督学习(聚类)重塑测量到的比特串分布，以减少预容错时代中的噪声影响，并预期将补充容错量子计算(FTQC)中的错误纠正。&lt;h4&gt;背景&lt;/h4&gt;量子错误缓解在减少预容错时代噪声影响方面至关重要，并且预计将在容错量子计算中补充错误纠正。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的量子错误缓解方法，以降低量子计算中的噪声影响。&lt;h4&gt;方法&lt;/h4&gt;Q-Cluster方法首先使用简化的比特翻转噪声模型，然后基于汉明距离对噪声测量结果（即比特串）进行聚类。每个聚类的中心通过量子比特多数投票计算得出。接着，使用贝叶斯推理调整噪声分布，同时考虑聚类结果和比特翻转错误率。为了适应复杂的噪声环境，方法中使用了Pauli旋转和ExtraTrees回归器来估计比特翻转错误率。&lt;h4&gt;主要发现&lt;/h4&gt;Q-Cluster可以在简单的比特翻转噪声模型下缓解高达40%的噪声率。在低熵基准测试中，与未经缓解的输出分布相比，Q-Cluster方案平均提高了1.46倍的保真度，并在五台不同的IBM量子机器上优于现有的QEM方法M3、Hammer和QBEEP。&lt;h4&gt;结论&lt;/h4&gt;Q-Cluster方案在提高量子计算保真度方面具有显著优势，是一种有效的量子错误缓解方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum error mitigation (QEM) is critical in reducing the impact of noise inthe pre-fault-tolerant era, and is expected to complement error correction infault-tolerant quantum computing (FTQC). In this paper, we propose a novel QEMapproach, Q-Cluster, that uses unsupervised learning (clustering) to reshapethe measured bit-string distribution. Our approach starts with a simplifiedbit-flip noise model. It first performs clustering on noisy measurementresults, i.e., bit-strings, based on the Hamming distance. The centroid of eachcluster is calculated using a qubit-wise majority vote. Next, the noisydistribution is adjusted with the clustering outcomes and the bit-flip errorrates using Bayesian inference. Our simulation results show that Q-Cluster canmitigate high noise rates (up to 40% per qubit) with the simple bit-flip noisemodel. However, real quantum computers do not fit such a simple noise model. Toaddress the problem, we (a) apply Pauli twirling to tailor the complex noisechannels to Pauli errors, and (b) employ a machine learning model, ExtraTreesregressor, to estimate an effective bit-flip error rate using a feature vectorconsisting of machine calibration data (gate &amp; measurement error rates),circuit features (number of qubits, numbers of different types of gates, etc.)and the shape of the noisy distribution (entropy). Our experimental resultsshow that our proposed Q-Cluster scheme improves the fidelity by a factor of1.46x, on average, compared to the unmitigated output distribution, for a setof low-entropy benchmarks on five different IBM quantum machines. Our approachoutperforms the state-of-art QEM approaches M3 [24], Hammer [35], and QBEEP[33] by 1.29x, 1.47x, and 2.65x, respectively.</description>
      <author>example@mail.com (Hrushikesh Pramod Patil, Dror Baron, Huiyang Zhou)</author>
      <guid isPermaLink="false">2504.10801v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE</title>
      <link>http://arxiv.org/abs/2504.10700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The 34th ACM International Symposium on High-Performance  Parallel and Distributed Computing (HPDC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对Chemistry Foundation Models（CFMs）的优化方法，特别是针对MACE这一先进的CFM模型，通过优化数据分布和模型训练过程，提高了CFM的训练效率。&lt;h4&gt;背景&lt;/h4&gt;利用图神经网络（GNNs）在3D分子图结构上运行的CFMs已成为计算化学家和材料科学家不可或缺的工具，它们有助于理解物质并发现新的分子和材料。&lt;h4&gt;目的&lt;/h4&gt;针对CFM训练的两个关键阶段——数据分布和模型训练，提出优化策略，以提高MACE的训练效率。&lt;h4&gt;方法&lt;/h4&gt;将数据分布中的负载平衡问题建模为多目标装箱问题，并提出一个迭代算法来优化数据分布；识别对称张量收缩为MACE的关键计算内核，并对其进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的方法显著提高了MACE的训练过程，实验结果显示，在740个GPU上使用2.6M样本数据集进行训练时，每轮执行时间从12分钟缩短到2分钟。&lt;h4&gt;结论&lt;/h4&gt;本文提出的优化方法可以显著提高CFM的训练效率，对计算化学和材料科学领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces optimization methods for Chemistry Foundation Models (CFMs), especially for the state-of-the-art CFM MACE, by optimizing the two critical phases of CFM training - data distribution and model training, to improve the training efficiency of CFMs. Utilizing Graph Neural Networks (GNNs) operating on 3D molecular graph structures, CFMs have become indispensable tools for computational chemists and materials scientists, which help to understand matter and discover new molecules and materials. The purpose of this paper is to optimize the two critical phases of CFM training - data distribution and model training, for the advanced CFM MACE, to improve the training efficiency. The method is to model the load balancing problem in data distribution as a multi-objective bin packing problem, and propose an iterative algorithm to optimize data distribution; identify symmetric tensor contraction as the key computational kernel in MACE, and optimize this kernel. The optimized method significantly improves the training process of MACE, and the experimental results show that the per-epoch execution time for training is reduced from 12 minutes to 2 minutes on 740 GPUs with a 2.6M sample dataset. The conclusion is that the proposed optimization methods can significantly improve the training efficiency of CFMs, which is of great significance to the fields of computational chemistry and materials science.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs)operating on 3D molecular graph structures are becoming indispensable tools forcomputational chemists and materials scientists. These models facilitate theunderstanding of matter and the discovery of new molecules and materials. Incontrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMsprocess a large number of geometric graphs of varying sizes, requiringdifferent optimization strategies than those developed for large homogeneousGNNs. This paper presents optimizations for two critical phases of CFMtraining: data distribution and model training, targeting MACE - astate-of-the-art CFM. We address the challenge of load balancing in datadistribution by formulating it as a multi-objective bin packing problem. Wepropose an iterative algorithm that provides a highly effective, fast, andpractical solution, ensuring efficient data distribution. For the trainingphase, we identify symmetric tensor contraction as the key computational kernelin MACE and optimize this kernel to improve the overall performance. Ourcombined approach of balanced data distribution and kernel optimizationsignificantly enhances the training process of MACE. Experimental resultsdemonstrate a substantial speedup, reducing per-epoch execution time fortraining from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.</description>
      <author>example@mail.com (Jesun Firoz, Franco Pellegrini, Mario Geiger, Darren Hsu, Jenna A. Bilbrey, Han-Yi Chou, Maximilian Stadler, Markus Hoehnerbach, Tingyu Wang, Dejun Lin, Emine Kucukbenli, Henry W. Sprueill, Ilyes Batatia, Sotiris S. Xantheas, MalSoon Lee, Chris Mundy, Gabor Csanyi, Justin S. Smith, Ponnuswamy Sadayappan, Sutanay Choudhury)</author>
      <guid isPermaLink="false">2504.10700v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2504.10331v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LL-Gaussian的新框架，用于从低光照sRGB图像中进行3D重建和增强，实现伪正常光照的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;低光照场景下的新视角合成（NVS）是一个重大挑战，由于输入质量下降，存在严重噪声、低动态范围（LDR）和不稳定的初始化。&lt;h4&gt;目的&lt;/h4&gt;为了解决低光照场景下的NVS挑战，提高合成图像的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;LL-Gaussian框架包含三个关键创新：1）端到端的低光照高斯初始化模块（LLGIM），利用基于学习的方法的密集先验生成高质量的初始点云；2）双分支高斯分解模型，将场景的固有属性（反射率和照明）从瞬态干扰中分离出来，实现稳定和可解释的优化；3）一种受物理约束和扩散先验指导的无监督优化策略，以联合引导分解和增强。&lt;h4&gt;主要发现&lt;/h4&gt;LL-Gaussian在极端低光照环境下收集的数据集上展示了有效性，与最先进的基于NeRF的方法相比，LL-Gaussian实现了高达2000倍的推理速度提升，并将训练时间缩短到2%，同时提供了更高质量的重建和渲染。&lt;h4&gt;结论&lt;/h4&gt;LL-Gaussian框架为低光照场景下的新视角合成提供了一种有效且高效的解决方案，显著提高了合成图像的质量和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis (NVS) in low-light scenes remains a significantchallenge due to degraded inputs characterized by severe noise, low dynamicrange (LDR) and unreliable initialization. While recent NeRF-based approacheshave shown promising results, most suffer from high computational costs, andsome rely on carefully captured or pre-processed data--such as RAW sensorinputs or multi-exposure sequences--which severely limits their practicality.In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering withcompetitive visual fidelity; however, existing 3DGS-based methods struggle withlow-light sRGB inputs, resulting in unstable Gaussian initialization andineffective noise suppression. To address these challenges, we proposeLL-Gaussian, a novel framework for 3D reconstruction and enhancement fromlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Ourmethod introduces three key innovations: 1) an end-to-end Low-Light GaussianInitialization Module (LLGIM) that leverages dense priors from learning-basedMVS approach to generate high-quality initial point clouds; 2) a dual-branchGaussian decomposition model that disentangles intrinsic scene properties(reflectance and illumination) from transient interference, enabling stable andinterpretable optimization; 3) an unsupervised optimization strategy guided byboth physical constrains and diffusion prior to jointly steer decomposition andenhancement. Additionally, we contribute a challenging dataset collected inextreme low-light environments and demonstrate the effectiveness ofLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussianachieves up to 2,000 times faster inference and reduces training time to just2%, while delivering superior reconstruction and rendering quality.</description>
      <author>example@mail.com (Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou)</author>
      <guid isPermaLink="false">2504.10331v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Why am I seeing this? Towards recognizing social media recommender systems with missing recommendations</title>
      <link>http://arxiv.org/abs/2504.11000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at RLDM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;社交媒体在塑造社会方面起着关键作用，它往往加剧了极化和传播错误信息。这些影响源于用户互动、个人特性和驱动内容选择的推荐算法的复杂动态。推荐系统对用户看到的内容和所做的决策有重大影响，为干预和监管提供了机会。然而，由于算法的不透明性和数据可用性的限制，评估其影响具有挑战性。为了有效地模拟用户决策，认识到平台采用的推荐系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;社交媒体在塑造社会方面起着关键作用，但同时也加剧了极化和错误信息的传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络（GNN）的自动推荐识别方法，仅使用网络结构和观察到的行为来识别隐藏的推荐系统。&lt;h4&gt;方法&lt;/h4&gt;首先，使用GNN和改进的后见之明学术网络推荐器训练一个推荐中立用户模型（RNU），以减少对实际推荐器的数据依赖。然后，通过将RNU与不同的已知推荐器结合生成多个推荐假设特定合成数据集（RHSD），为测试生成真实情况。最后，在多种假设下训练推荐假设特定用户模型（RHU），并将每个候选模型与生成RHSD的原模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够准确检测隐藏的推荐系统和它们对用户行为的影响，并且与基于审计的方法不同，它直接捕捉系统行为，无需进行无法反映真实平台的临时代验。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了关于推荐系统如何塑造行为的见解，有助于减少极化和错误信息。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces a method for Automatic Recommender Recognition using Graph Neural Networks (GNNs), based solely on network structure and observed behavior. To infer the hidden recommender, we first train a Recommender Neutral User model (RNU) using a GNN and an adapted hindsight academic network recommender, aiming to reduce reliance on the actual recommender in the data. We then generate several Recommender Hypothesis-specific Synthetic Datasets (RHSD) by combining the RNU with different known recommenders, producing groundtruths for testing. Finally, we train Recommender Hypothesis-specific User models (RHU) under various hypotheses and compare each candidate with the original used to generate the RHSD. Our approach enables accurate detection of hidden recommenders and their influence on user behavior. Unlike audit-based methods, it captures system behavior directly, without ad hoc experiments that often fail to reflect real platforms. This study provides insights into how recommenders shape behavior, aiding efforts to reduce polarization and misinformation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social media plays a crucial role in shaping society, often amplifyingpolarization and spreading misinformation. These effects stem from complexdynamics involving user interactions, individual traits, and recommenderalgorithms driving content selection. Recommender systems, which significantlyshape the content users see and decisions they make, offer an opportunity forintervention and regulation. However, assessing their impact is challenging dueto algorithmic opacity and limited data availability. To effectively model userdecision-making, it is crucial to recognize the recommender system adopted bythe platform.  This work introduces a method for Automatic Recommender Recognition usingGraph Neural Networks (GNNs), based solely on network structure and observedbehavior. To infer the hidden recommender, we first train a Recommender NeutralUser model (RNU) using a GNN and an adapted hindsight academic networkrecommender, aiming to reduce reliance on the actual recommender in the data.We then generate several Recommender Hypothesis-specific Synthetic Datasets(RHSD) by combining the RNU with different known recommenders, producing groundtruths for testing. Finally, we train Recommender Hypothesis-specific Usermodels (RHU) under various hypotheses and compare each candidate with theoriginal used to generate the RHSD.  Our approach enables accurate detection of hidden recommenders and theirinfluence on user behavior. Unlike audit-based methods, it captures systembehavior directly, without ad hoc experiments that often fail to reflect realplatforms. This study provides insights into how recommenders shape behavior,aiding efforts to reduce polarization and misinformation.</description>
      <author>example@mail.com (Sabrina Guidotti, Sabrina Patania, Giuseppe Vizzari, Dimitri Ognibene, Gregor Donabauer, Udo Kruschwitz, Davide Taibi)</author>
      <guid isPermaLink="false">2504.11000v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Assisted XgBoost For Adaptable Cyberattack Detection In Battery Packs</title>
      <link>http://arxiv.org/abs/2504.10658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于XgBoost模型的电动汽车充电过程中的传感器数据攻击检测算法，旨在确保充电安全。&lt;h4&gt;背景&lt;/h4&gt;电动汽车的充电安全依赖于电池包到云控制器的可靠传感器测量，但存在攻击者可能篡改电压传感器数据的风险。&lt;h4&gt;目的&lt;/h4&gt;实时检测传感器网络攻击，以确保电动汽车充电安全，并使检测算法能够适应不同的电池包配置。&lt;h4&gt;方法&lt;/h4&gt;使用PyBaMM和`liionpack'包中的高保真充电实验数据来训练和测试检测算法，并对两个大型电池包进行了传感器交换和重放攻击的模拟。&lt;h4&gt;主要发现&lt;/h4&gt;提出的检测算法在两种大型电池包的传感器交换和重放攻击下表现出良好的适应性和有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的检测算法能够适应电池包配置的变化，并有效检测传感器数据攻击，为电动汽车的安全充电提供了保障。&lt;h4&gt;翻译&lt;/h4&gt;摘要：电动汽车（EV）的最佳充电依赖于智能充电站电池包到云控制器的可靠传感器测量。然而，攻击者可能在传输过程中篡改电压传感器数据，这可能导致局部到广泛的干扰。因此，实时检测传感器网络攻击对于确保安全充电至关重要，并且所开发的算法必须能够适应包括包配置在内的变化。为了应对这些挑战，我们提出了基于XgBoost的电池级模型的自适应微调，使用有限的电池包级数据用于电压预测和残差生成。我们使用了来自PyBaMM和`liionpack'包的高保真充电实验中的电池单元和电池包数据来训练和测试检测算法。该算法的性能已在两个大型电池包的传感器交换和重放攻击下进行了评估。模拟结果还突出了我们提出的检测算法的适应性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimal charging of electric vehicle (EVs) depends heavily on reliable sensormeasurements from the battery pack to the cloud-controller of the smartcharging station. However, an adversary could corrupt the voltage sensor dataduring transmission, potentially causing local to wide-scale disruptions.Therefore, it is essential to detect sensor cyberattacks in real-time to ensuresecure EV charging, and the developed algorithms must be readily adaptable tovariations, including pack configurations. To tackle these challenges, wepropose adaptable fine-tuning of an XgBoost-based cell-level model usinglimited pack-level data to use for voltage prediction and residual generation.We used battery cell and pack data from high-fidelity charging experiments inPyBaMM and `liionpack' package to train and test the detection algorithm. Thealgorithm's performance has been evaluated for two large-format battery packsunder sensor swapping and replay attacks. The simulation results also highlightthe adaptability and efficacy of our proposed detection algorithm.</description>
      <author>example@mail.com (Sanchita Ghosh, Tanushree Roy)</author>
      <guid isPermaLink="false">2504.10658v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Towards A Universal Graph Structural Encoder</title>
      <link>http://arxiv.org/abs/2504.10917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该摘要介绍了一种名为GFSE的通用图结构编码器，用于在不同图域中捕获和转移结构信息，以解决现有模型在捕捉复杂图结构方面的不足。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在下游任务中学习可泛化表示的潜力已被证明，但在图域中，由于不同图域之间拓扑模式的不同，捕获和转移结构信息仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了一种名为GFSE的通用图结构编码器，旨在捕捉不同领域（如分子图、社交网络和引文网络）中可转移的结构模式。&lt;h4&gt;方法&lt;/h4&gt;GFSE基于图Transformer，结合了图归纳偏差的注意力机制，能够编码多层次和细粒度的拓扑特征。它通过多个自监督学习目标进行跨域预训练。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的GFSE产生了通用的和理论上有表达力的位置和结构编码，可以无缝集成到各种下游图特征编码器中，包括用于矢量化特征的图神经网络和用于文本属性图的Large Language Models。实验表明，GFSE能够显著提高模型性能，同时需要较少的任务特定微调。&lt;h4&gt;结论&lt;/h4&gt;GFSE在81.6%的评估案例中实现了最先进的性能，覆盖了多种图模型和数据集，突显了其作为强大且多用途的图结构数据编码器的潜力。&lt;h4&gt;翻译&lt;/h4&gt;In this abstract, a universal graph structural encoder called GFSE is introduced, designed to capture and transfer structural information across different graph domains, addressing the limitations of existing models in capturing complex graph structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large-scale pre-training have shown the potential tolearn generalizable representations for downstream tasks. In the graph domain,however, capturing and transferring structural information across differentgraph domains remains challenging, primarily due to the inherent differences intopological patterns across various contexts. Additionally, most existingmodels struggle to capture the complexity of rich graph structures, leading toinadequate exploration of the embedding space. To address these challenges, wepropose GFSE, a universal graph structural encoder designed to capturetransferable structural patterns across diverse domains such as moleculargraphs, social networks, and citation networks. GFSE is the first cross-domaingraph structural encoder pre-trained with multiple self-supervised learningobjectives. Built on a Graph Transformer, GFSE incorporates attentionmechanisms informed by graph inductive bias, enabling it to encode intricatemulti-level and fine-grained topological features. The pre-trained GFSEproduces generic and theoretically expressive positional and structuralencoding for graphs, which can be seamlessly integrated with various downstreamgraph feature encoders, including graph neural networks for vectorized featuresand Large Language Models for text-attributed graphs. Comprehensive experimentson synthetic and real-world datasets demonstrate GFSE's capability tosignificantly enhance the model's performance while requiring substantiallyless task-specific fine-tuning. Notably, GFSE achieves state-of-the-artperformance in 81.6% evaluated cases, spanning diverse graph models anddatasets, highlighting its potential as a powerful and versatile encoder forgraph-structured data.</description>
      <author>example@mail.com (Jialin Chen, Haolan Zuo, Haoyu Peter Wang, Siqi Miao, Pan Li, Rex Ying)</author>
      <guid isPermaLink="false">2504.10917v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery</title>
      <link>http://arxiv.org/abs/2504.10655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，几何机器学习模型如图神经网络在化学和材料科学研究中的应用，如高通量虚拟筛选和原子模拟，取得了显著成功。然而，这些模型对数据的需求较高，限制了它们在数据稀疏问题中的应用。为了解决这一限制，预训练的机器学习模型的发展正在增加，这些模型在原子数据中学习了通用的基本几何关系，可以针对更小的特定应用数据集进行微调。为了充分利用这些基础模型，本文介绍了MatterTune，这是一个模块化和可扩展的框架，提供了高级微调能力和无缝集成原子基础模型到下游材料信息学和模拟工作流程的能力，从而降低了采用门槛并促进了材料科学中的多样化应用。&lt;h4&gt;背景&lt;/h4&gt;几何机器学习模型如图神经网络在化学和材料科学研究中取得了成功，但需要大量数据，限制了在数据稀疏问题中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据需求高的问题，提出了一种新的框架MatterTune，以降低采用门槛并促进材料科学中的多样化应用。&lt;h4&gt;方法&lt;/h4&gt;开发了一个模块化和可扩展的框架MatterTune，它支持高级微调能力和无缝集成原子基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;MatterTune支持多种先进的原子基础模型，如ORB、MatterSim、JMP和EquformerV2，并提供模块化设计、分布式和可定制的微调、广泛支持下游信息学任务等功能。&lt;h4&gt;结论&lt;/h4&gt;MatterTune框架的提出，为利用原子基础模型提供了便利，有助于推动材料科学领域的研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Geometric machine learning models such as graph neural networks have achieved remarkable success in recent years in chemical and materials science research for applications such as high-throughput virtual screening and atomistic simulations. The success of these models can be attributed to their ability to effectively learn latent representations of atomic structures directly from the training data. Conversely, this also results in high data requirements for these models, hindering their application to problems which are data sparse which are common in this domain. To address this limitation, there is a growing development in the area of pre-trained machine learning models which have learned general, fundamental, geometric relationships in atomistic data, and which can then be fine-tuned to much smaller application-specific datasets. In particular, models which are pre-trained on diverse, large-scale atomistic datasets have shown impressive generalizability and flexibility to downstream applications, and are increasingly referred to as atomistic foundation models. To leverage the untapped potential of these foundation models, we introduce MatterTune, a modular and extensible framework that provides advanced fine-tuning capabilities and seamless integration of atomistic foundation models into downstream materials informatics and simulation workflows, thereby lowering the barriers to adoption and facilitating diverse applications in materials science. In its current state, MatterTune supports a number of state-of-the-art foundation models such as ORB, MatterSim, JMP, and EquformerV2, and hosts a wide range of features including a modular and flexible design, distributed and customizable fine-tuning, broad support for downstream informatics tasks, and more.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric machine learning models such as graph neural networks have achievedremarkable success in recent years in chemical and materials science researchfor applications such as high-throughput virtual screening and atomisticsimulations. The success of these models can be attributed to their ability toeffectively learn latent representations of atomic structures directly from thetraining data. Conversely, this also results in high data requirements forthese models, hindering their application to problems which are data sparsewhich are common in this domain. To address this limitation, there is a growingdevelopment in the area of pre-trained machine learning models which havelearned general, fundamental, geometric relationships in atomistic data, andwhich can then be fine-tuned to much smaller application-specific datasets. Inparticular, models which are pre-trained on diverse, large-scale atomisticdatasets have shown impressive generalizability and flexibility to downstreamapplications, and are increasingly referred to as atomistic foundation models.To leverage the untapped potential of these foundation models, we introduceMatterTune, a modular and extensible framework that provides advancedfine-tuning capabilities and seamless integration of atomistic foundationmodels into downstream materials informatics and simulation workflows, therebylowering the barriers to adoption and facilitating diverse applications inmaterials science. In its current state, MatterTune supports a number ofstate-of-the-art foundation models such as ORB, MatterSim, JMP, andEquformerV2, and hosts a wide range of features including a modular andflexible design, distributed and customizable fine-tuning, broad support fordownstream informatics tasks, and more.</description>
      <author>example@mail.com (Lingyu Kong, Nima Shoghi, Guoxiang Hu, Pan Li, Victor Fung)</author>
      <guid isPermaLink="false">2504.10655v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent driving vehicle front multi-target tracking and detection based on YOLOv5 and point cloud 3D projection</title>
      <link>http://arxiv.org/abs/2504.11310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in Chinese language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于YOLOv5和点云3D投影的多目标跟踪和检测方法，用于智能驾驶车辆的前方多目标跟踪和检测。&lt;h4&gt;背景&lt;/h4&gt;多目标跟踪和检测任务需要连续跟踪多个目标，如车辆、行人等，并实时更新目标状态。&lt;h4&gt;目的&lt;/h4&gt;实现智能驾驶车辆前方多目标的高精度跟踪和检测。&lt;h4&gt;方法&lt;/h4&gt;使用Retinex算法增强车辆前方环境图像，去除图像中的光干扰，并基于YOLOv5网络结构构建智能检测模型。通过特征提取和目标定位识别车辆前方的多个目标。结合点云3D投影技术，推断相邻帧图像在投影坐标系中的位置变化关系，并将连续帧图像的多目标识别结果投影到3D激光点云环境中，实现所有目标运动轨迹的有效跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在智能驾驶车辆前方多目标跟踪和检测中的应用，MOTA（跟踪精度）值超过30，显示出其优越的跟踪和检测性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高智能驾驶车辆前方多目标跟踪和检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-target tracking and detection tasks, it is necessary to continuouslytrack multiple targets, such as vehicles, pedestrians, etc. To achieve thisgoal, the system must be able to continuously acquire and process image framescontaining these targets. These consecutive frame images enable the algorithmto update the position and state of the target in real-time in each frame ofthe image. How to accurately associate the detected target with the target inthe previous or next frame to form a stable trajectory is a complex problem.Therefore, a multi object tracking and detection method for intelligent drivingvehicles based on YOLOv5 and point cloud 3D projection is proposed. UsingRetinex algorithm to enhance the image of the environment in front of thevehicle, remove light interference in the image, and build an intelligentdetection model based on YOLOv5 network structure. The enhanced image is inputinto the model, and multiple targets in front of the vehicle are identifiedthrough feature extraction and target localization. By combining point cloud 3Dprojection technology, the correlation between the position changes of adjacentframe images in the projection coordinate system can be inferred. Bysequentially projecting the multi-target recognition results of multipleconsecutive frame images into the 3D laser point cloud environment, effectivetracking of the motion trajectories of all targets in front of the vehicle canbe achieved. The experimental results show that the application of this methodfor intelligent driving vehicle front multi-target tracking and detectionyields a MOTA (Tracking Accuracy) value greater than 30, demonstrating itssuperior tracking and detection performance.</description>
      <author>example@mail.com (Dayong Liu, Qingrui Zhang, Zeyang Meng)</author>
      <guid isPermaLink="false">2504.11310v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation</title>
      <link>http://arxiv.org/abs/2504.10541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HeLLM的新型框架，用于增强大型语言模型（LLM）在多模态推荐系统中的性能。该框架通过融合图级别上下文信号和序列级别行为模式，使LLM能够捕捉复杂的语义相关性。&lt;h4&gt;背景&lt;/h4&gt;现有基于LLM的方法未能充分探索推荐场景中固有的多视图图结构相关性。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架，使LLM能够捕捉复杂的语义相关性。&lt;h4&gt;方法&lt;/h4&gt;1. 设计用户超图和物品超图，以揭示用户之间的共同兴趣偏好和物品之间的多模态相似性相关性。2. 引入超图卷积和协同对比学习机制，以增强学习表示的可区分性。3. 在LLM微调阶段，将学习到的图结构嵌入直接注入LLM架构，并集成捕获每个用户时间序列行为的序列特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法优于现有最佳基线，证实了在LLM中融合基于超图上下文与序列用户行为的优势。&lt;h4&gt;结论&lt;/h4&gt;HeLLM框架能够有效提升LLM在推荐系统中的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大型语言模型（LLM）的日益普及正在推动个性化推荐系统的发展。大多数现有的基于LLM的方法未能充分探索推荐场景中固有的多视图图结构相关性。为此，我们提出了一种新的框架，称为Hypergraph Enhanced LLM Learning for multimodal Recommendation（HeLLM），旨在使LLM具备通过融合图级别上下文信号与序列级别行为模式来捕捉复杂高阶语义相关性的能力。在推荐预训练阶段，我们设计了用户超图以揭示用户之间的共同兴趣偏好，以及物品超图以捕捉物品之间的多模态相似性相关性。引入了超图卷积和协同对比学习机制来增强学习表示的可区分性。在LLM微调阶段，我们将学习到的图结构嵌入直接注入LLM的架构中，并集成捕获每个用户时间序列行为的序列特征。这一过程使超图能够利用图结构信息作为全局上下文，增强LLM感知复杂关系模式和整合多模态信息的能力，同时模拟局部时间动态。广泛的实验表明，我们提出的方法优于现有最佳基线，证实了在LLM中融合基于超图上下文与序列用户行为的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The burgeoning presence of Large Language Models (LLM) is propelling thedevelopment of personalized recommender systems. Most existing LLM-basedmethods fail to sufficiently explore the multi-view graph structurecorrelations inherent in recommendation scenarios. To this end, we propose anovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation(HeLLM), designed to equip LLMs with the capability to capture intricatehigher-order semantic correlations by fusing graph-level contextual signalswith sequence-level behavioral patterns. In the recommender pre-training phase,we design a user hypergraph to uncover shared interest preferences among usersand an item hypergraph to capture correlations within multimodal similaritiesamong items. The hypergraph convolution and synergistic contrastive learningmechanism are introduced to enhance the distinguishability of learnedrepresentations. In the LLM fine-tuning phase, we inject the learnedgraph-structured embeddings directly into the LLM's architecture and integratesequential features capturing each user's chronological behavior. This processenables hypergraphs to leverage graph-structured information as global context,enhancing the LLM's ability to perceive complex relational patterns andintegrate multimodal information, while also modeling local temporal dynamics.Extensive experiments demonstrate the superiority of our proposed method overstate-of-the-art baselines, confirming the advantages of fusinghypergraph-based context with sequential user behavior in LLMs forrecommendation.</description>
      <author>example@mail.com (Xu Guo, Tong Zhang, Yuanzhi Wang, Chenxu Wang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui)</author>
      <guid isPermaLink="false">2504.10541v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>The Code Barrier: What LLMs Actually Understand?</title>
      <link>http://arxiv.org/abs/2504.10557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究通过代码混淆作为结构化测试框架，评估了大型语言模型（LLM）的语义理解能力，并引入了一种新的评估方法来衡量语言模型对代码的理解。&lt;h4&gt;背景&lt;/h4&gt;理解代码是自动化软件开发任务的核心能力。尽管基础模型如LLM在许多软件工程挑战中表现出令人印象深刻的结果，但其真正的语义理解程度，尤其是超出简单标记识别之外的程度，尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;使用代码混淆来评估LLM的语义理解能力，并建立一种新的评估方法，用于衡量语言模型对代码的理解。&lt;h4&gt;方法&lt;/h4&gt;本研究通过系统地应用受控的混淆更改到源代码中，并通过生成混淆代码的准确描述和执行去混淆任务来衡量理解能力。测试包括13个先进模型，涵盖代码专用（如StarCoder2）和通用（如GPT-4o）架构，并在由CodeNet创建的基准测试上评估，该基准测试包含250个Java编程问题和它们的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;随着混淆复杂性的增加，性能出现统计学上的显著下降，与专注于代码的模型相比，通用模型显示出意外的弹性。虽然一些模型能够识别混淆技术，但它们重建底层程序逻辑的能力仍然受到限制，这表明它们在语义表示机制上存在局限性。&lt;h4&gt;结论&lt;/h4&gt;本研究引入了一种新的评估代码理解的方法，并建立了安全关键代码分析应用（如逆向工程和对抗性代码分析）的实证基准。&lt;h4&gt;翻译&lt;/h4&gt;Understanding code represents a core ability needed for automating software development tasks. While foundation models like LLMs show impressive results across many software engineering challenges, the extent of their true semantic understanding beyond simple token recognition remains unclear. This research uses code obfuscation as a structured testing framework to evaluate LLMs' semantic understanding capabilities. We methodically apply controlled obfuscation changes to source code and measure comprehension through two complementary tasks: generating accurate descriptions of obfuscated code and performing deobfuscation, a skill with important implications for reverse engineering applications. Our testing approach includes 13 cutting-edge models, covering both code-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o) architectures, evaluated on a benchmark created from CodeNet and consisting of filtered 250 Java programming problems and their solutions. Findings show a statistically significant performance decline as obfuscation complexity increases, with unexpected resilience shown by general-purpose models compared to their code-focused counterparts. While some models successfully identify obfuscation techniques, their ability to reconstruct the underlying program logic remains constrained, suggesting limitations in their semantic representation mechanisms. This research introduces a new evaluation approach for assessing code comprehension in language models and establishes empirical baselines for advancing research in security-critical code analysis applications such as reverse engineering and adversarial code analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding code represents a core ability needed for automating softwaredevelopment tasks. While foundation models like LLMs show impressive resultsacross many software engineering challenges, the extent of their true semanticunderstanding beyond simple token recognition remains unclear. This researchuses code obfuscation as a structured testing framework to evaluate LLMs'semantic understanding capabilities. We methodically apply controlledobfuscation changes to source code and measure comprehension through twocomplementary tasks: generating accurate descriptions of obfuscated code andperforming deobfuscation, a skill with important implications for reverseengineering applications.  Our testing approach includes 13 cutting-edge models, covering bothcode-specialized (e.g., StarCoder2) and general-purpose (e.g., GPT-4o)architectures, evaluated on a benchmark created from CodeNet and consisting offiltered 250 Java programming problems and their solutions. Findings show astatistically significant performance decline as obfuscation complexityincreases, with unexpected resilience shown by general-purpose models comparedto their code-focused counterparts. While some models successfully identifyobfuscation techniques, their ability to reconstruct the underlying programlogic remains constrained, suggesting limitations in their semanticrepresentation mechanisms. This research introduces a new evaluation approachfor assessing code comprehension in language models and establishes empiricalbaselines for advancing research in security-critical code analysisapplications such as reverse engineering and adversarial code analysis.</description>
      <author>example@mail.com (Serge Lionel Nikiema, Jordan Samhi, Abdoul Kader Kaboré, Jacques Klein, Tegawendé F. Bissyandé)</author>
      <guid isPermaLink="false">2504.10557v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos</title>
      <link>http://arxiv.org/abs/2504.08222v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025; Website URL: https://lzyandy.github.io/f3set-website/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了F$^3$Set，一个用于精确F$^3$事件检测的视频数据集基准，旨在解决视频分析和多模态LLMs中快速、频繁和精细粒度事件分析的挑战。&lt;h4&gt;背景&lt;/h4&gt;当前方法在识别满足F$^3$标准的快速、频繁和精细粒度事件时存在困难，主要因为运动模糊和细微的视觉差异等问题。&lt;h4&gt;目的&lt;/h4&gt;为了推进视频理解的研究，提出了F$^3$Set基准，以解决F$^3$事件检测的挑战。&lt;h4&gt;方法&lt;/h4&gt;F$^3$Set包含大量数据集，具有广泛规模和详细程度，通常包含超过1,000种事件类型，并支持多级粒度。论文评估了流行的时序动作理解方法在F$^3$Set上的表现，并提出了一个新的F$^3$事件检测方法F$^3$ED。&lt;h4&gt;主要发现&lt;/h4&gt;F$^3$Set揭示了现有技术存在的挑战，并提出的新方法F$^3$ED在F$^3$事件检测方面取得了优异的性能。&lt;h4&gt;结论&lt;/h4&gt;F$^3$Set和F$^3$ED方法为视频分析和多模态LLMs中的F$^3$事件检测提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents a significant challenge in video analytics and multi-modal LLMs. Current methods struggle to identify events that satisfy all the F$^3$ criteria with high accuracy due to challenges such as motion blur and subtle visual discrepancies. To advance research in video understanding, we introduce F$^3$Set, a benchmark that consists of video datasets for precise F$^3$ event detection. Datasets in F$^3$Set are characterized by their extensive scale and comprehensive detail, usually encompassing over 1,000 event types with precise timestamps and supporting multi-level granularity. Currently, F$^3$Set contains several sports datasets, and this framework may be extended to other applications as well. We evaluated popular temporal action understanding methods on F$^3$Set, revealing substantial challenges for existing techniques. Additionally, we propose a new method, F$^3$ED, for F$^3$ event detections, achieving superior performance. The dataset, model, and benchmark code are available at https://github.com/F3Set/F3Set.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/f3set/f3set&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents asignificant challenge in video analytics and multi-modal LLMs. Current methodsstruggle to identify events that satisfy all the F$^3$ criteria with highaccuracy due to challenges such as motion blur and subtle visual discrepancies.To advance research in video understanding, we introduce F$^3$Set, a benchmarkthat consists of video datasets for precise F$^3$ event detection. Datasets inF$^3$Set are characterized by their extensive scale and comprehensive detail,usually encompassing over 1,000 event types with precise timestamps andsupporting multi-level granularity. Currently, F$^3$Set contains several sportsdatasets, and this framework may be extended to other applications as well. Weevaluated popular temporal action understanding methods on F$^3$Set, revealingsubstantial challenges for existing techniques. Additionally, we propose a newmethod, F$^3$ED, for F$^3$ event detections, achieving superior performance.The dataset, model, and benchmark code are available athttps://github.com/F3Set/F3Set.</description>
      <author>example@mail.com (Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong)</author>
      <guid isPermaLink="false">2504.08222v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training</title>
      <link>http://arxiv.org/abs/2504.09210v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为FairACE的新型图神经网络框架，旨在解决图神经网络中的公平性问题。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络中，节点度的不平衡可能导致不同度数节点预测性能的不公平。&lt;h4&gt;目的&lt;/h4&gt;提出FairACE框架，通过整合非对称对比学习和对抗训练来改善节点度的不公平问题。&lt;h4&gt;方法&lt;/h4&gt;FairACE利用一跳局部邻域信息和两跳的单向相似性来创建更公平的节点表示，并采用度数公平性调节器来平衡高度数和低度数节点的性能。同时，引入了一种新颖的组平衡公平损失函数来最小化不同度数组之间的分类差异。此外，还提出了一个公平性指标——准确度分布差距（ADG），用于定量评估并确保不同度数节点组的性能均衡。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据和真实世界数据集上的实验结果表明，FairACE在显著提高度数公平性指标的同时，与最先进的图神经网络模型相比保持了竞争力。&lt;h4&gt;结论&lt;/h4&gt;FairACE是一个有效的图神经网络框架，能够提高不同度数节点之间的预测公平性，同时在准确性上保持竞争力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公平性一直是图神经网络（GNNs）中的一个重大挑战，因为度数偏差往往会导致具有不同度数的节点预测性能不平等。现有的GNN模型侧重于预测准确性，往往忽视了不同度数组之间的公平性。为了解决这一问题，我们提出了一种名为公平感知非对称对比集成（FairACE）的新型GNN框架，该框架整合了非对称对比学习与对抗训练以改善度数公平性。FairACE捕捉了一跳局部邻域信息和两跳的单向相似性，以创建更公平的节点表示，并采用度数公平性调节器来平衡高度数和低度数节点的性能。在模型训练过程中，提出了一种新的组平衡公平损失，以最小化度数组之间的分类差异。此外，我们还提出了一种新的公平性指标——准确度分布差距（ADG），可以定量评估并确保基于不同度数的节点组的公平性能。在合成数据和真实世界数据集上的实验结果表明，与最先进的GNN模型相比，FairACE显著提高了度数公平性指标，同时在准确性上保持了竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fairness has been a significant challenge in graph neural networks (GNNs)since degree biases often result in un-equal prediction performance among nodeswith varying degrees. Existing GNN models focus on prediction accuracy,frequently overlooking fairness across different degree groups. To addressthisissue, we propose a novel GNN framework, namely Fairness- Aware AsymmetricContrastive Ensemble (FairACE), which inte-grates asymmetric contrastivelearning with adversarial training to improve degree fairness. FairACE capturesone-hop local neighborhood information and two-hop monophily similarity tocreate fairer node representations and employs a degree fairness regulator tobalance performance between high-degree and low-degree nodes. During modeltraining, a novel group-balanced fairness loss is proposed to minimizeclassification disparities across degree groups. In addition, we also propose anovel fairness metric, the Accuracy Distribution Gap (ADG), which canquantitatively assess and ensure equitable performance across differentdegree-based node groups. Experimental results on both synthetic and real-worlddatasets demonstrate that FairACE significantly improves degree fairnessmetrics while maintaining competitive accuracy in comparison to thestate-of-the-art GNN models.</description>
      <author>example@mail.com (Jiaxin Liu, Xiaoqian Jiang, Xiang Li, Bohan Zhang, Jing Zhang)</author>
      <guid isPermaLink="false">2504.09210v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset</title>
      <link>http://arxiv.org/abs/2504.08217v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DrivAer Transformer (DAT)的点云学习框架，用于评估车辆空气动力学性能，旨在提高预测准确性和通用性，以推动汽车设计的进步。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法在评估空气动力学性能方面表现出色，但处理复杂的三维车辆模型时，由于数据集和训练资源的缺乏，以及不同车辆模型几何形状的多样性和复杂性，预测准确性和通用性尚未达到生产要求。&lt;h4&gt;目的&lt;/h4&gt;提出DAT框架，利用Transformer模型在自然语言处理和图像处理领域的成功经验，提高点云数据处理能力，实现快速准确的空气阻力预测。&lt;h4&gt;方法&lt;/h4&gt;DAT框架使用DrivAerNet++数据集，包含工业标准三维车辆形状的高保真CFD数据，直接从三维网格中估计空气阻力，避免传统方法的限制。&lt;h4&gt;主要发现&lt;/h4&gt;DAT框架能够实现快速准确的空气阻力预测，推动空气动力学评估过程的进化，为汽车设计引入数据驱动方法奠定基础。&lt;h4&gt;结论&lt;/h4&gt;DAT框架预计将加速车辆设计过程，提高开发效率。&lt;h4&gt;翻译&lt;/h4&gt;在当前阶段，基于深度学习的方法在评估空气动力学性能方面表现出卓越的能力，显著减少了传统计算流体动力学（CFD）模拟所需的时间和成本。然而，面对处理极其复杂的三维（3D）车辆模型的任务时，由于缺乏大规模数据集和训练资源，以及不同车辆模型几何形状的固有多样性和复杂性，这些网络的预测准确性和通用性仍然没有达到当前生产所需的水平。鉴于Transformer模型在自然语言处理领域的显著成功及其在图像处理领域的强大潜力，本研究创新性地提出了一种名为DrivAer Transformer（DAT）的点云学习框架。DAT结构使用DrivAerNet++数据集，该数据集包含工业标准3D车辆形状的高保真CFD数据，能够直接从3D网格中准确估计空气阻力，从而避免了传统方法（如2D图像渲染或符号距离场（SDF））的限制。DAT能够实现快速准确的阻力预测，推动空气动力学评估过程的进化，为引入数据驱动方法到汽车设计奠定关键基础。该框架预计将加速车辆设计过程，提高开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At the current stage, deep learning-based methods have demonstrated excellentcapabilities in evaluating aerodynamic performance, significantly reducing thetime and cost required for traditional computational fluid dynamics (CFD)simulations. However, when faced with the task of processing extremely complexthree-dimensional (3D) vehicle models, the lack of large-scale datasets andtraining resources, coupled with the inherent diversity and complexity of thegeometry of different vehicle models, means that the prediction accuracy andversatility of these networks are still not up to the level required forcurrent production. In view of the remarkable success of Transformer models inthe field of natural language processing and their strong potential in thefield of image processing, this study innovatively proposes a point cloudlearning framework called DrivAer Transformer (DAT). The DAT structure uses theDrivAerNet++ dataset, which contains high-fidelity CFD data ofindustrial-standard 3D vehicle shapes. enabling accurate estimation of air dragdirectly from 3D meshes, thus avoiding the limitations of traditional methodssuch as 2D image rendering or signed distance fields (SDF). DAT enables fastand accurate drag prediction, driving the evolution of the aerodynamicevaluation process and laying the critical foundation for introducing adata-driven approach to automotive design. The framework is expected toaccelerate the vehicle design process and improve development efficiency.</description>
      <author>example@mail.com (Jiaqi He, Xiangwen Luo, Yiping Wang)</author>
      <guid isPermaLink="false">2504.08217v2</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture</title>
      <link>http://arxiv.org/abs/2504.10512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;JEPA4Rec是一个结合了联合嵌入预测架构和物品文本描述语言建模的推荐框架，能够捕捉语义丰富且可迁移的表示，从而提高推荐性能并减少对大规模预训练数据的依赖。&lt;h4&gt;背景&lt;/h4&gt;语言表示学习在序列推荐中表现出潜力，但仍然面临数据稀疏性和对常识用户偏好理解有限的问题。&lt;h4&gt;目的&lt;/h4&gt;提出JEPA4Rec框架以解决语言表示学习在推荐任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;JEPA4Rec通过将项目表示为文本句子，并使用双向Transformer编码器及其修改后的嵌入层来编码这些句子。同时，采用掩码技术预测未掩码句子的表示，以及采用两阶段训练策略结合自监督学习损失来提高推荐性能和语言理解。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界数据集上的实验表明，JEPA4Rec在跨领域、跨平台和低资源场景中持续优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;JEPA4Rec框架能够有效提升推荐系统的性能，特别是在面对数据稀疏性和跨域推荐任务时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language representation learning has emerged as a promising approach forsequential recommendation, thanks to its ability to learn generalizablerepresentations. However, despite its advantages, this approach still struggleswith data sparsity and a limited understanding of common-sense userpreferences. To address these limitations, we propose $\textbf{JEPA4Rec}$, aframework that combines $\textbf{J}$oint $\textbf{E}$mbedding$\textbf{P}$redictive $\textbf{A}$rchitecture with language modeling of itemtextual descriptions. JEPA4Rec captures semantically rich and transferablerepresentations, improving recommendation performance and reducing reliance onlarge-scale pre-training data. Specifically, JEPA4Rec represents items as textsentences by flattening descriptive information such as $\textit{title,category}$, and other attributes. To encode these sentences, we employ abidirectional Transformer encoder with modified embedding layers tailored forcapturing item information in recommendation datasets. We apply masking to textsentences and use them to predict the representations of the unmaskedsentences, helping the model learn generalizable item embeddings. To furtherimprove recommendation performance and language understanding, we employ atwo-stage training strategy incorporating self-supervised learning losses.Experiments on six real-world datasets demonstrate that JEPA4Rec consistentlyoutperforms state-of-the-art methods, particularly in cross-domain,cross-platform, and low-resource scenarios.</description>
      <author>example@mail.com (Minh-Anh Nguyen, Dung D. Le)</author>
      <guid isPermaLink="false">2504.10512v1</guid>
      <pubDate>Wed, 16 Apr 2025 14:18:21 +0800</pubDate>
    </item>
    <item>
      <title>GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions</title>
      <link>http://arxiv.org/abs/2504.10146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoUni是一种统一的几何专家模型，能够在单个框架内生成问题解决方案和图表，创建独特和个性化的几何问题。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习处理几何问题的解决和图表生成是两个独立的任务，没有模型能够成功整合这两个功能以支持问题创建。&lt;h4&gt;目的&lt;/h4&gt;GeoUni旨在通过无缝集成解决几何问题的所有技能（从解决问题到可视化几何关系，再到定制问题）来掌握几何。&lt;h4&gt;方法&lt;/h4&gt;GeoUni使用了1.5B参数，在几何推理任务中达到了与DeepSeek-R1（671B参数）相当的性能，并且能够生成精确的几何图表，超越了文本到图像模型和统一模型，包括GPT-4o图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;GeoUni是唯一能够基于特定知识点成功生成匹配图表的文本问题的模型，从而提供超越现有模型的更广泛的能力。&lt;h4&gt;结论&lt;/h4&gt;GeoUni通过整合几何问题的解决和图表生成，在几何推理和图表生成方面表现出色，并且具有创建个性化几何问题的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose GeoUni, the first unified geometry expert model capable ofgenerating problem solutions and diagrams within a single framework in a waythat enables the creation of unique and individualized geometry problems.Traditionally, solving geometry problems and generating diagrams have beentreated as separate tasks in machine learning, with no models successfullyintegrating both to support problem creation. However, we believe that masteryin geometry requires frictionless integration of all of these skills, fromsolving problems to visualizing geometric relationships, and finally, craftingtailored problems. Our extensive experiments demonstrate that GeoUni, with only1.5B parameters, achieves performance comparable to larger models such asDeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni alsoexcels in generating precise geometric diagrams, surpassing both text-to-imagemodels and unified models, including the GPT-4o image generation. Mostimportantly, GeoUni is the only model capable of successfully generatingtextual problems with matching diagrams based on specific knowledge points,thus offering a wider range of capabilities that extend beyond current models.</description>
      <author>example@mail.com (Jo-Ku Cheng, Zeren Zhang, Ran Chen, Jingyang Deng, Ziran Qin, Jinwen Ma)</author>
      <guid isPermaLink="false">2504.10146v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
  <item>
      <title>Foundation models for electronic health records: representation dynamics and transferability</title>
      <link>http://arxiv.org/abs/2504.10422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于电子健康记录的基金会模型在临床预测任务中的性能，并评估了模型在不同医疗体系中的适应性和可移植性。&lt;h4&gt;背景&lt;/h4&gt;虽然基于电子健康记录的基金会模型在临床预测任务中表现出色，但将其适应到本地医疗体系中由于数据可用性和资源限制而存在挑战。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在调查这些模型学到了什么，评估在MIMIC-IV上训练的基金会模型转移到芝加哥大学医学中心机构电子健康记录数据集的可移植性。&lt;h4&gt;方法&lt;/h4&gt;研究了模型识别异常患者的能力，并考察了与未来临床结果相关的表示空间中患者轨迹。此外，还在源数据和目标数据集上评估了监督微调分类器的性能。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果提供了关于基金会模型在不同医疗体系间适应性的见解，强调了有效实施时的考虑因素，并对有助于其预测性能的潜在因素进行了实证分析。&lt;h4&gt;结论&lt;/h4&gt;本研究对基金会模型在不同医疗体系中的适应性进行了实证研究，为模型的有效实施提供了指导，并对模型预测性能背后的因素进行了深入分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) trained on electronic health records (EHRs) haveshown strong performance on a range of clinical prediction tasks. However,adapting these models to local health systems remains challenging due tolimited data availability and resource constraints. In this study, weinvestigated what these models learn and evaluated the transferability of an FMtrained on MIMIC-IV to an institutional EHR dataset at the University ofChicago Medical Center. We assessed their ability to identify outlier patientsand examined representation-space patient trajectories in relation to futureclinical outcomes. We also evaluated the performance of supervised fine-tunedclassifiers on both source and target datasets. Our findings offer insightsinto the adaptability of FMs across different healthcare systems, highlightconsiderations for their effective implementation, and provide an empiricalanalysis of the underlying factors that contribute to their predictiveperformance.</description>
      <author>example@mail.com (Michael C. Burkhart, Bashar Ramadan, Zewei Liao, Kaveri Chhikara, Juan C. Rojas, William F. Parker, Brett K. Beaulieu-Jones)</author>
      <guid isPermaLink="false">2504.10422v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Combining Forecasts using Meta-Learning: A Comparative Study for Complex Seasonality</title>
      <link>http://arxiv.org/abs/2504.08940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE 10th International Conference on Data Science and Advanced  Analytics, DSAA'23, pp. 1-10, 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了通过元学习结合不同类型模型生成的预测，以提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的预测结合方法通常涉及简单的平均，而机器学习技术通过元学习实现了更复杂的结合方法。&lt;h4&gt;目的&lt;/h4&gt;通过元学习提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用线性回归、k近邻、多层感知器、随机森林和长短期记忆作为元学习器。定义了针对具有复杂季节性的时间序列的全球和局部元学习变体，并在多个预测问题上对元学习器进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;元学习器在多个预测问题上的表现优于简单的平均方法。&lt;h4&gt;结论&lt;/h4&gt;元学习在结合不同类型模型生成的预测中具有优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we investigate meta-learning for combining forecasts generated by models of different types. While typical approaches for combining forecasts involve simple averaging, machine learning techniques enable more sophisticated methods of combining through meta-learning, leading to improved forecasting accuracy. We use linear regression, $k$-nearest neighbors, multilayer perceptron, random forest, and long short-term memory as meta-learners. We define global and local meta-learning variants for time series with complex seasonality and compare meta-learners on multiple forecasting problems, demonstrating their superior performance compared to simple averaging.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/DSAA60987.2023.10302585&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate meta-learning for combining forecasts generatedby models of different types. While typical approaches for combining forecastsinvolve simple averaging, machine learning techniques enable more sophisticatedmethods of combining through meta-learning, leading to improved forecastingaccuracy. We use linear regression, $k$-nearest neighbors, multilayerperceptron, random forest, and long short-term memory as meta-learners. Wedefine global and local meta-learning variants for time series with complexseasonality and compare meta-learners on multiple forecasting problems,demonstrating their superior performance compared to simple averaging.</description>
      <author>example@mail.com (Grzegorz Dudek)</author>
      <guid isPermaLink="false">2504.08940v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Long Video Modeling Based on Temporal Dynamic Context</title>
      <link>http://arxiv.org/abs/2504.10443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Dynamic Context (TDC)的动态长视频编码方法，以解决现有长视频理解模型在处理长视频时信息丢失和模态融合问题。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）在视频理解方面取得了显著进展，但现有的模型仍然难以处理长视频，因为LLMs的上下文长度限制和视频中的大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理长视频的编码方法，减少信息丢失，并融合视频和音频等多模态信息。&lt;h4&gt;方法&lt;/h4&gt;1. 将视频分割成语义上一致的场景；2. 使用视觉-音频编码器将每帧编码成标记；3. 提出一种新颖的时间上下文压缩器，以减少每个段落的标记数量；4. 使用基于查询的Transformer聚合视频、音频和指令文本标记；5. 将静态帧标记和时间上下文标记输入LLM进行视频理解；6. 提出一种无训练的思考链策略，用于处理极长视频。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在通用视频理解和音视频理解基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Temporal Dynamic Context (TDC)方法能够有效处理长视频，并在视频理解任务中取得良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;最近，大型语言模型（LLMs）在视频理解方面的进步导致了显著的突破。然而，由于LLMs的上下文长度限制和视频中的大量信息，现有的模型在处理长视频时仍然存在困难。尽管一些最近的方法是为长视频理解设计的，但它们在标记压缩过程中通常会丢失关键信息，并且难以处理音频等附加模态。在本工作中，我们提出了一种利用帧之间时间关系的动态长视频编码方法，称为Temporal Dynamic Context（TDC）。首先，我们根据帧间的相似性将视频分割成语义上一致的场景，然后使用视觉-音频编码器将每个帧编码成标记。其次，我们提出了一种新颖的时间上下文压缩器，以减少每个段落的标记数量。具体来说，我们采用基于查询的Transformer将视频、音频和指令文本标记聚合到一组有限的时间上下文标记中。最后，我们将静态帧标记和时间上下文标记输入LLM进行视频理解。此外，为了处理极长视频，我们提出了一种无需训练的思考链策略，该策略逐步从多个视频段中提取答案。这些中间答案作为推理过程的一部分，有助于最终答案。我们在通用视频理解和音视频理解基准测试上进行了广泛的实验，我们的方法在这些实验中表现出了强大的性能。代码和模型可在https://github.com/Hoar012/TDC-Video上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Large Language Models (LLMs) have led to significantbreakthroughs in video understanding. However, existing models still strugglewith long video processing due to the context length constraint of LLMs and thevast amount of information within the video. Although some recent methods aredesigned for long video understanding, they often lose crucial informationduring token compression and struggle with additional modality like audio. Inthis work, we propose a dynamic long video encoding method utilizing thetemporal relationship between frames, named Temporal Dynamic Context (TDC).Firstly, we segment the video into semantically consistent scenes based oninter-frame similarities, then encode each frame into tokens using visual-audioencoders. Secondly, we propose a novel temporal context compressor to reducethe number of tokens within each segment. Specifically, we employ a query-basedTransformer to aggregate video, audio, and instruction text tokens into alimited set of temporal context tokens. Finally, we feed the static frametokens and the temporal context tokens into the LLM for video understanding.Furthermore, to handle extremely long videos, we propose a training-freechain-of-thought strategy that progressively extracts answers from multiplevideo segments. These intermediate answers serve as part of the reasoningprocess and contribute to the final answer. We conduct extensive experiments ongeneral video understanding and audio-video understanding benchmarks, where ourmethod demonstrates strong performance. The code and models are available athttps://github.com/Hoar012/TDC-Video.</description>
      <author>example@mail.com (Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue)</author>
      <guid isPermaLink="false">2504.10443v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LMFormer: Lane based Motion Prediction Transformer</title>
      <link>http://arxiv.org/abs/2504.10275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted: Autonomous Driving Workshop, CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LMFormer的路径预测网络，用于自动驾驶中的运动预测。&lt;h4&gt;背景&lt;/h4&gt;运动预测在自动驾驶中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提供一种简单机制动态优先级排序车道，并引入网络学习行为的可解释性。&lt;h4&gt;方法&lt;/h4&gt;LMFormer使用车道连接信息学习车道结构中的长距离依赖，并提出了一种通过堆叠变换器层进行迭代精炼预测轨迹的有效方法。&lt;h4&gt;主要发现&lt;/h4&gt;LMFormer在多个指标上实现了SOTA性能，并展示了跨数据集网络性能以及LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;h4&gt;结论&lt;/h4&gt;LMFormer是一种有效的路径预测网络，在自动驾驶中具有广泛应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：运动预测在自动驾驶中起着重要作用。本研究提出了LMFormer，一种用于轨迹预测任务的车道感知变换器网络。与先前的研究相比，我们的工作提供了一个简单的机制来动态优先级排序车道，并表明这种机制引入了网络学习行为的可解释性。此外，LMFormer使用交叉口、车道合并和车道分叉的车道连接信息，以学习车道结构中的长距离依赖。此外，我们还解决了预测轨迹的细化问题，并提出了一种通过堆叠变换器层进行迭代精炼的有效方法。为了基准测试，我们在nuScenes数据集上评估了LMFormer，并证明它在多个指标上实现了SOTA性能。此外，还使用了Deep Scenario数据集，不仅说明了跨数据集网络性能，还说明了LMFormer在多个数据集上训练并取得更好性能的统一能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion prediction plays an important role in autonomous driving. This studypresents LMFormer, a lane-aware transformer network for trajectory predictiontasks. In contrast to previous studies, our work provides a simple mechanism todynamically prioritize the lanes and shows that such a mechanism introducesexplainability into the learning behavior of the network. Additionally,LMFormer uses the lane connection information at intersections, lane merges,and lane splits, in order to learn long-range dependency in lane structure.Moreover, we also address the issue of refining the predicted trajectories andpropose an efficient method for iterative refinement through stackedtransformer layers. For benchmarking, we evaluate LMFormer on the nuScenesdataset and demonstrate that it achieves SOTA performance across multiplemetrics. Furthermore, the Deep Scenario dataset is used to not only illustratecross-dataset network performance but also the unification capabilities ofLMFormer to train on multiple datasets and achieve better performance.</description>
      <author>example@mail.com (Harsh Yadav, Maximilian Schaefer, Kun Zhao, Tobias Meisen)</author>
      <guid isPermaLink="false">2504.10275v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis</title>
      <link>http://arxiv.org/abs/2504.10352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的伪自回归（PAR）编解码器语言建模方法，该方法统一了自回归（AR）和非自回归（NAR）建模。通过结合AR模型的显式时间建模和NAR模型的并行生成，PAR能够在固定时间步长生成动态长度的跨度。基于PAR，提出了PALLE，一个两阶段TTS系统，利用PAR进行初始生成，随后进行NAR细化。&lt;h4&gt;背景&lt;/h4&gt;现有的零样本文本到语音（TTS）系统面临共同困境：自回归模型在生成速度上较慢且缺乏时长控制能力，而非自回归模型缺乏时间建模且通常需要复杂的设计。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的TTS系统，解决现有零样本TTS系统中自回归模型和非自回归模型的问题。&lt;h4&gt;方法&lt;/h4&gt;采用PAR codec语言建模方法，结合AR模型的显式时间建模和NAR模型的并行生成。PALLE系统包括两个阶段：第一阶段使用PAR逐步生成语音标记，每步并行预测所有位置但只保留最左侧跨度；第二阶段迭代地并行细化低置信度标记，利用全局上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;在LibriTTS上训练的PALLE系统在LibriSpeech test-clean数据集上，在语音质量、说话人相似度和可懂度方面优于使用大规模数据训练的F5-TTS、E2-TTS和MaskGCT等最先进系统，同时推理速度可达十倍。&lt;h4&gt;结论&lt;/h4&gt;PALLE系统在保持高语音质量的同时，实现了快速推理，为TTS系统提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies autoregressive (AR) and non-autoregressive (NAR) modeling. By combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Based on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://anonymous-palle.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent zero-shot text-to-speech (TTS) systems face a common dilemma:autoregressive (AR) models suffer from slow generation and lack durationcontrollability, while non-autoregressive (NAR) models lack temporal modelingand typically require complex designs. In this paper, we introduce a novelpseudo-autoregressive (PAR) codec language modeling approach that unifies ARand NAR modeling. Combining explicit temporal modeling from AR with parallelgeneration from NAR, PAR generates dynamic-length spans at fixed time steps.Building on PAR, we propose PALLE, a two-stage TTS system that leverages PARfor initial generation followed by NAR refinement. In the first stage, PARprogressively generates speech tokens along the time dimension, with each steppredicting all positions in parallel but only retaining the left-most span. Inthe second stage, low-confidence tokens are iteratively refined in parallel,leveraging the global contextual information. Experiments demonstrate thatPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained onlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeechtest-clean set in terms of speech quality, speaker similarity, andintelligibility, while achieving up to ten times faster inference speed. Audiosamples are available at https://anonymous-palle.github.io.</description>
      <author>example@mail.com (Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen)</author>
      <guid isPermaLink="false">2504.10352v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MonoDiff9D: Monocular Category-Level 9D Object Pose Estimation via Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.10433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoDiff9D是一种基于扩散的9D单目对象姿态估计方法，无需形状先验或CAD模型即可实现高精度的对象姿态估计。&lt;h4&gt;背景&lt;/h4&gt;对象姿态估计对于机器人理解和交互环境至关重要，单目方法因其只需要单个RGB相机而受到青睐。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需形状先验、CAD模型或深度传感器的单目9D对象姿态估计方法。&lt;h4&gt;方法&lt;/h4&gt;首先使用DINOv2在零样本方式下估计粗略深度并将其转换为点云；然后融合点云的全局特征和输入图像；最后，使用融合的特征和时间步长来条件化MonoDiff9D，并通过基于transformer的降噪器从高斯噪声中恢复对象姿态。&lt;h4&gt;主要发现&lt;/h4&gt;在两个流行的基准数据集上，MonoDiff9D实现了在没有形状先验或CAD模型的情况下最先进的单目9D对象姿态估计精度。&lt;h4&gt;结论&lt;/h4&gt;MonoDiff9D代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;h4&gt;翻译&lt;/h4&gt;对象姿态估计是机器人理解和交互环境的核心手段。对于这一任务，单目分类级方法因其仅需单个RGB相机而具有吸引力。然而，当前方法依赖于形状先验或已知对象内类的CAD模型。我们提出了一种基于扩散的单目分类级9D对象姿态生成方法，称为MonoDiff9D。我们的动机是利用扩散模型的概率性质来减轻对形状先验、CAD模型或深度传感器对内类未知对象姿态估计的需求。我们首先以零样本方式从单目图像中估计粗略深度，并将其转换为点云。然后，我们将点云的全局特征与输入图像融合，并使用融合的特征以及编码的时间步长来条件化MonoDiff9D。最后，我们设计了一种基于transformer的降噪器，以从高斯噪声中恢复对象姿态。在两个流行基准数据集上的大量实验表明，MonoDiff9D在不需要任何阶段的形状先验或CAD模型的情况下实现了最先进的单目分类级9D对象姿态估计精度。我们的代码将公开在https://github.com/CNJianLiu/MonoDiff9D上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation is a core means for robots to understand and interactwith their environment. For this task, monocular category-level methods areattractive as they require only a single RGB camera. However, current methodsrely on shape priors or CAD models of the intra-class known objects. We proposea diffusion-based monocular category-level 9D object pose generation method,MonoDiff9D. Our motivation is to leverage the probabilistic nature of diffusionmodels to alleviate the need for shape priors, CAD models, or depth sensors forintra-class unknown object pose estimation. We first estimate coarse depth viaDINOv2 from the monocular image in a zero-shot manner and convert it into apoint cloud. We then fuse the global features of the point cloud with the inputimage and use the fused features along with the encoded time step to conditionMonoDiff9D. Finally, we design a transformer-based denoiser to recover theobject pose from Gaussian noise. Extensive experiments on two popular benchmarkdatasets show that MonoDiff9D achieves state-of-the-art monocularcategory-level 9D object pose estimation accuracy without the need for shapepriors or CAD models at any stage. Our code will be made public athttps://github.com/CNJianLiu/MonoDiff9D.</description>
      <author>example@mail.com (Jian Liu, Wei Sun, Hui Yang, Jin Zheng, Zichen Geng, Hossein Rahmani, Ajmal Mian)</author>
      <guid isPermaLink="false">2504.10433v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>SoccerNet-v3D: Leveraging Sports Broadcast Replays for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2504.10106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了SoccerNet-v3D和ISSIA-3D两个用于足球转播分析中3D场景理解的数据集，并提出了单目3D球定位方法，以及用于评估标注质量的指标和优化技术。&lt;h4&gt;背景&lt;/h4&gt;体育视频分析是计算机视觉的关键领域，通过多视图对应关系实现详细的空间理解。&lt;h4&gt;目的&lt;/h4&gt;建立新的基准，增强体育分析中的空间和时间分析。&lt;h4&gt;方法&lt;/h4&gt;提出了基于三角测量的单目3D球定位任务，并引入了基于场线摄像校准和多视图同步的扩展数据集，以及用于评估标注质量的校准和重投影指标。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入场线摄像校准和多视图同步，实现了3D物体定位；提出了单目3D球定位方法作为基线；引入了边界框优化技术以细化2D标注。&lt;h4&gt;结论&lt;/h4&gt;提出的SoccerNet-v3D和ISSIA-3D数据集为3D足球场景理解提供了新的基准，提高了体育分析中的空间和时间分析能力。&lt;h4&gt;翻译&lt;/h4&gt;Sports video analysis is a key domain in computer vision, enabling detailed spatial understanding through multi-view correspondences. In this work, we introduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasets designed for 3D scene understanding in soccer broadcast analysis. These datasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based camera calibration and multi-view synchronization, enabling 3D object localization through triangulation. We propose a monocular 3D ball localization task built upon the triangulation of ground-truth 2D ball annotations, along with several calibration and reprojection metrics to assess annotation quality on demand. Additionally, we present a single-image 3D ball localization method as a baseline, leveraging camera calibration and ball size priors to estimate the ball's position from a monocular viewpoint. To further refine 2D annotations, we introduce a bounding box optimization technique that ensures alignment with the 3D scene representation. Our proposed datasets establish new benchmarks for 3D soccer scene understanding, enhancing both spatial and temporal analysis in sports analytics. Finally, we provide code to facilitate access to our annotations and the generation pipelines for the datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sports video analysis is a key domain in computer vision, enabling detailedspatial understanding through multi-view correspondences. In this work, weintroduce SoccerNet-v3D and ISSIA-3D, two enhanced and scalable datasetsdesigned for 3D scene understanding in soccer broadcast analysis. Thesedatasets extend SoccerNet-v3 and ISSIA by incorporating field-line-based cameracalibration and multi-view synchronization, enabling 3D object localizationthrough triangulation. We propose a monocular 3D ball localization task builtupon the triangulation of ground-truth 2D ball annotations, along with severalcalibration and reprojection metrics to assess annotation quality on demand.Additionally, we present a single-image 3D ball localization method as abaseline, leveraging camera calibration and ball size priors to estimate theball's position from a monocular viewpoint. To further refine 2D annotations,we introduce a bounding box optimization technique that ensures alignment withthe 3D scene representation. Our proposed datasets establish new benchmarks for3D soccer scene understanding, enhancing both spatial and temporal analysis insports analytics. Finally, we provide code to facilitate access to ourannotations and the generation pipelines for the datasets.</description>
      <author>example@mail.com (Marc Gutiérrez-Pérez, Antonio Agudo)</author>
      <guid isPermaLink="false">2504.10106v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks</title>
      <link>http://arxiv.org/abs/2504.10403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种卫星-地面协同联邦微调框架，旨在解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能和低地球轨道卫星的发展，大型遥感基础模型在地面进行微调受到隐私和带宽限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种卫星-地面协同联邦微调框架，以解决卫星计算能力不足和通信挑战。&lt;h4&gt;方法&lt;/h4&gt;该框架通过合理分解和分配模型组件，减轻卫星计算能力不足的问题。在微调过程中，卫星与地面站或其他卫星交换中间结果，以应对空间传输网络中的通信挑战。此外，还引入了定制通信策略，包括并行轨道内通信策略、拓扑感知卫星-地面通信策略和最小化延迟的轨道间通信策略，以减少空间通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，采用该框架可以显著减少训练时间，提高约33%。&lt;h4&gt;结论&lt;/h4&gt;卫星-地面协同联邦微调框架能够有效解决大型基础模型在卫星上进行微调时的计算能力不足和通信挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in artificial intelligence (AI) and low-earth orbit (LEO)satellites have promoted the application of large remote sensing foundationmodels for various downstream tasks. However, direct downloading of thesemodels for fine-tuning on the ground is impeded by privacy concerns and limitedbandwidth. Satellite federated learning (FL) offers a solution by enablingmodel fine-tuning directly on-board satellites and aggregating model updateswithout data downloading. Nevertheless, for large foundation models, thecomputational capacity of satellites is insufficient to support effectiveon-board fine-tuning in traditional satellite FL frameworks. To address thesechallenges, we propose a satellite-ground collaborative federated fine-tuningframework. The key of the framework lies in how to reasonably decompose andallocate model components to alleviate insufficient on-board computationcapabilities. During fine-tuning, satellites exchange intermediate results withground stations or other satellites for forward propagation and backpropagation, which brings communication challenges due to the specialcommunication topology of space transmission networks, such as intermittentsatellite-ground communication, short duration of satellite-groundcommunication windows, and unstable inter-orbit inter-satellite links (ISLs).To reduce transmission delays, we further introduce tailored communicationstrategies that integrate both communication and computing resources.Specifically, we propose a parallel intra-orbit communication strategy, atopology-aware satellite-ground communication strategy, and alatency-minimalization inter-orbit communication strategy to reduce spacecommunication costs. Simulation results demonstrate significant reductions intraining time with improvements of approximately 33%.</description>
      <author>example@mail.com (Yan zhu, Jingyang zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief)</author>
      <guid isPermaLink="false">2504.10403v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Invariance Matters: Empowering Social Recommendation via Graph Invariant Learning</title>
      <link>http://arxiv.org/abs/2504.10432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Social Graph Invariant Learning（SGIL）方法，用于解决基于图的社会推荐系统中数据稀疏性和社交网络噪声问题，以增强推荐性能。&lt;h4&gt;背景&lt;/h4&gt;基于图的社会推荐系统利用图神经网络（GNNs）捕捉用户偏好，但现有方法往往忽略社交网络的噪声和冗余关系，影响用户偏好学习的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出SGIL方法，旨在从输入社交图中揭示稳定的用户偏好，从而增强基于图的社会推荐系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SGIL通过图生成器模拟多个噪声社交环境，并通过最小化这些环境中的不变风险来学习环境不变的用户偏好。同时，采用对抗性训练策略以生成更多潜在的社会噪声分布，促进生成社交环境的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SGIL方法有效地提高了基于图的社会推荐系统的推荐性能。&lt;h4&gt;结论&lt;/h4&gt;SGIL方法为解决社交推荐系统中的噪声问题提供了一种新的思路，有助于提高推荐系统的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based social recommendation systems have shown significant promise in enhancing recommendation performance, particularly in addressing the issue of data sparsity in user behaviors. Typically, these systems leverage Graph Neural Networks (GNNs) to capture user preferences by incorporating high-order social influences from observed social networks. However, existing graph-based social recommendations often overlook the fact that social networks are inherently noisy, containing task-irrelevant relationships that can hinder accurate user preference learning. The removal of these redundant social relations is crucial, yet it remains challenging due to the lack of ground truth. In this paper, we approach the social denoising problem from the perspective of graph invariant learning and propose a novel method, Social Graph Invariant Learning (SGIL). Specifically, SGIL aims to uncover stable user preferences within the input social graph, thereby enhancing the robustness of graph-based social recommendation systems. To achieve this goal, SGIL first simulates multiple noisy social environments through graph generators. It then seeks to learn environment-invariant user preferences by minimizing invariant risk across these environments. To further promote diversity in the generated social environments, we employ an adversarial training strategy to simulate more potential social noisy distributions. Extensive experimental results demonstrate the effectiveness of the proposed SGIL. The code is available at https://github.com/yimutianyang/SIGIR2025-SGIL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based social recommendation systems have shown significant promise inenhancing recommendation performance, particularly in addressing the issue ofdata sparsity in user behaviors. Typically, these systems leverage Graph NeuralNetworks (GNNs) to capture user preferences by incorporating high-order socialinfluences from observed social networks. However, existing graph-based socialrecommendations often overlook the fact that social networks are inherentlynoisy, containing task-irrelevant relationships that can hinder accurate userpreference learning. The removal of these redundant social relations iscrucial, yet it remains challenging due to the lack of ground truth. In thispaper, we approach the social denoising problem from the perspective of graphinvariant learning and propose a novel method, Social Graph InvariantLearning(SGIL). Specifically,SGIL aims to uncover stable user preferenceswithin the input social graph, thereby enhancing the robustness of graph-basedsocial recommendation systems. To achieve this goal, SGIL first simulatesmultiple noisy social environments through graph generators. It then seeks tolearn environment-invariant user preferences by minimizing invariant riskacross these environments. To further promote diversity in the generated socialenvironments, we employ an adversarial training strategy to simulate morepotential social noisy distributions. Extensive experimental resultsdemonstrate the effectiveness of the proposed SGIL. The code is available athttps://github.com/yimutianyang/SIGIR2025-SGIL.</description>
      <author>example@mail.com (Yonghui Yang, Le Wu, Yuxin Liao, Zhuangzhuang He, Pengyang Shao, Richang Hong, Meng Wang)</author>
      <guid isPermaLink="false">2504.10432v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Representation Learning Techniques for Comprehensive Facial State Analysis</title>
      <link>http://arxiv.org/abs/2504.10351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICME2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全面的多模态面部状态分析方法。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型通过整合多模态信息显著提高了特征表示，适用于更广泛的应用。然而，对于理解感知的多模态面部表示研究有限。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够理解和分析面部状态（如动作单元（AU）和情感）的综合且稳健的框架，该框架能够桥接视觉和语言模态。&lt;h4&gt;方法&lt;/h4&gt;1. 编制一个新的多模态面部数据集（MFA），通过利用GPT-4生成详细的多层次语言描述，包括AU和情感描述。2. 引入一个针对AU和情感识别的新型多层次多模态面部基础模型（MF^2），该模型在面部图像的局部和全局层面上进行全面的视觉特征建模。3. 开发了一个解耦微调网络（DFN），能够高效地在不同任务和数据集上调整MF^2。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在AU和情感检测任务上表现出优异的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提升多模态面部状态分析的准确性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal foundation models have significantly improved feature representation by integrating information from multiple modalities, making them highly suitable for a broader set of applications. However, the exploration of multimodal facial representation for understanding perception has been limited. Understanding and analyzing facial states, such as Action Units (AUs) and emotions, require a comprehensive and robust framework that bridges visual and linguistic modalities. In this paper, we present a comprehensive pipeline for multimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face, incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o. Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2) tailored for Action Unit (AU) and emotion recognition. Our model incorporates comprehensive visual feature modeling at both local and global levels of face image, enhancing its ability to represent detailed facial appearances. This design aligns visual representations with structured AU and emotion descriptions, ensuring effective cross-modal integration. Third, we develop a Decoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across various tasks and datasets. This approach not only reduces computational overhead but also broadens the applicability of the foundation model to diverse scenarios. Experimentation show superior performance for AU and emotion detection tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models have significantly improved featurerepresentation by integrating information from multiple modalities, making themhighly suitable for a broader set of applications. However, the exploration ofmultimodal facial representation for understanding perception has been limited.Understanding and analyzing facial states, such as Action Units (AUs) andemotions, require a comprehensive and robust framework that bridges visual andlinguistic modalities. In this paper, we present a comprehensive pipeline formultimodal facial state analysis. First, we compile a new Multimodal FaceDataset (MFA) by generating detailed multilevel language descriptions of face,incorporating Action Unit (AU) and emotion descriptions, by leveraging GPT-4o.Second, we introduce a novel Multilevel Multimodal Face Foundation model (MF^2)tailored for Action Unit (AU) and emotion recognition. Our model incorporatescomprehensive visual feature modeling at both local and global levels of faceimage, enhancing its ability to represent detailed facial appearances. Thisdesign aligns visual representations with structured AU and emotiondescriptions, ensuring effective cross-modal integration. Third, we develop aDecoupled Fine-Tuning Network (DFN) that efficiently adapts MF^2 across varioustasks and datasets. This approach not only reduces computational overhead butalso broadens the applicability of the foundation model to diverse scenarios.Experimentation show superior performance for AU and emotion detection tasks.</description>
      <author>example@mail.com (Kaiwen Zheng, Xuri Ge, Junchen Fu, Jun Peng, Joemon M. Jose)</author>
      <guid isPermaLink="false">2504.10351v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pillar-Voxel Fusion Network for 3D Object Detection in Airborne Hyperspectral Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PiV-AHPC的3D目标检测网络，用于空中高光谱点云（HPCs）数据，以解决融合技术和障碍物遮挡导致的几何-光谱失真问题。&lt;h4&gt;背景&lt;/h4&gt;高光谱点云可以同时描述地面物体的3D空间和光谱信息，但目前的方法在融合高光谱图像和LiDAR点云时，容易产生几何-光谱失真，影响下游任务的表现。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的3D目标检测网络PiV-AHPC。&lt;h4&gt;方法&lt;/h4&gt;PiV-AHPC采用柱状体-体素双分支编码器，分别从HPCs中提取光谱和垂直结构特征，以及从点云中提取准确的3D空间特征。同时，设计了一种多级特征融合机制，增强两个分支之间的信息交互，实现邻域特征对齐和通道自适应选择，从而有机地整合异构特征并减轻几何失真。&lt;h4&gt;主要发现&lt;/h4&gt;在两个空中HPCs数据集上的实验表明，PiV-AHPC具有最先进的检测性能和较高的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;PiV-AHPC是首次尝试针对HPCs任务的3D目标检测网络，能够有效解决现有方法中的几何-光谱失真问题，并在空中应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatial and spectral information of ground objects, offering excellent 3D perception and target recognition capabilities. Current approaches for generating HPCs often involve fusion techniques with hyperspectral images and LiDAR point clouds, which inevitably lead to geometric-spectral distortions due to fusion errors and obstacle occlusions. These adverse effects limit their performance in downstream fine-grained tasks across multiple scenarios, particularly in airborne applications. To address these issues, we propose PiV-AHPC, a 3D object detection network for airborne HPCs. To the best of our knowledge, this is the first attempt at this HPCs task. Specifically, we first develop a pillar-voxel dual-branch encoder, where the former captures spectral and vertical structural features from HPCs to overcome spectral distortion, while the latter emphasizes extracting accurate 3D spatial features from point clouds. A multi-level feature fusion mechanism is devised to enhance information interaction between the two branches, achieving neighborhood feature alignment and channel-adaptive selection, thereby organically integrating heterogeneous features and mitigating geometric distortion. Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPC possesses state-of-the-art detection performance and high generalization capability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral point clouds (HPCs) can simultaneously characterize 3D spatialand spectral information of ground objects, offering excellent 3D perceptionand target recognition capabilities. Current approaches for generating HPCsoften involve fusion techniques with hyperspectral images and LiDAR pointclouds, which inevitably lead to geometric-spectral distortions due to fusionerrors and obstacle occlusions. These adverse effects limit their performancein downstream fine-grained tasks across multiple scenarios, particularly inairborne applications. To address these issues, we propose PiV-AHPC, a 3Dobject detection network for airborne HPCs. To the best of our knowledge, thisis the first attempt at this HPCs task. Specifically, we first develop apillar-voxel dual-branch encoder, where the former captures spectral andvertical structural features from HPCs to overcome spectral distortion, whilethe latter emphasizes extracting accurate 3D spatial features from pointclouds. A multi-level feature fusion mechanism is devised to enhanceinformation interaction between the two branches, achieving neighborhoodfeature alignment and channel-adaptive selection, thereby organicallyintegrating heterogeneous features and mitigating geometric distortion.Extensive experiments on two airborne HPCs datasets demonstrate that PiV-AHPCpossesses state-of-the-art detection performance and high generalizationcapability.</description>
      <author>example@mail.com (Yanze Jiang, Yanfeng Gu, Xian Li)</author>
      <guid isPermaLink="false">2504.09506v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2504.10143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态表示学习，特别是通过图像-文本对进行的多模态对比学习（MMCL），以及如何处理现实数据集中存在的模态间不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在通过跨模态对齐线索来学习强大的表示。然而，现实数据集常常表现出模态间的不匹配。&lt;h4&gt;目的&lt;/h4&gt;旨在调和缓解和不利用不匹配的两种观点，并为从业者提供实用指南。&lt;h4&gt;方法&lt;/h4&gt;使用潜在变量模型，通过引入选择偏差和扰动偏差两种机制来形式化不匹配。选择偏差指某些语义变量缺失，扰动偏差指语义变量被扭曲，这两种偏差都影响跨模态共享的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。&lt;h4&gt;结论&lt;/h4&gt;这为理解不匹配提供了一个统一的视角，并基于此提供了关于如何设计现实世界机器学习系统的可操作见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态表示学习，以多模态对比学习（MMCL）使用图像-文本对为例，旨在通过跨模态对齐线索来学习强大的表示。这种方法依赖于核心假设，即示例图像-文本对构成了一个相同概念的两种表示。然而，最近的研究表明，现实世界的数据集往往表现出不匹配。关于如何解决这个问题，有两种不同的观点：一种建议缓解不匹配，另一种则利用它。在这里，我们试图调和这些看似对立的观点，并为从业者提供实用指南。因此，我们使用潜在变量模型，通过引入两种特定的机制来形式化不匹配：选择偏差，其中一些语义变量缺失；以及扰动偏差，其中语义变量被扭曲——两者都影响跨模态共享的潜在变量。我们的理论分析表明，在温和的假设下，MMCL学习到的表示恰好捕捉了与不受选择和扰动偏差影响的语义变量子集相关的信息。这为理解不匹配提供了一个统一的视角。基于此，我们进一步提供了关于如何设计现实世界机器学习系统的可操作见解。我们通过在合成数据和真实图像-文本数据集上进行的广泛实证研究验证了我们的理论发现，揭示了不匹配对多模态表示学习的微妙影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning, exemplified by multimodal contrastivelearning (MMCL) using image-text pairs, aims to learn powerful representationsby aligning cues across modalities. This approach relies on the core assumptionthat the exemplar image-text pairs constitute two representations of anidentical concept. However, recent research has revealed that real-worlddatasets often exhibit misalignment. There are two distinct viewpoints on howto address this issue: one suggests mitigating the misalignment, and the otherleveraging it. We seek here to reconcile these seemingly opposing perspectives,and to provide a practical guide for practitioners. Using latent variablemodels we thus formalize misalignment by introducing two specific mechanisms:selection bias, where some semantic variables are missing, and perturbationbias, where semantic variables are distorted -- both affecting latent variablesshared across modalities. Our theoretical analysis demonstrates that, undermild assumptions, the representations learned by MMCL capture exactly theinformation related to the subset of the semantic variables invariant toselection and perturbation biases. This provides a unified perspective forunderstanding misalignment. Based on this, we further offer actionable insightsinto how misalignment should inform the design of real-world ML systems. Wevalidate our theoretical findings through extensive empirical studies on bothsynthetic data and real image-text datasets, shedding light on the nuancedimpact of misalignment on multimodal representation learning.</description>
      <author>example@mail.com (Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi)</author>
      <guid isPermaLink="false">2504.10143v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Relation-augmented Representation Generalization for Few-shot Action Recognition</title>
      <link>http://arxiv.org/abs/2504.10079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HR2G-shot是一个用于Few-shot动作识别（FSAR）的框架，旨在通过统一三种关系建模（帧间、视频间和任务间）来学习特定任务的时序模式。&lt;h4&gt;背景&lt;/h4&gt;现有的FSAR方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示，但忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。&lt;h4&gt;目的&lt;/h4&gt;提出HR2G-shot框架，以解决现有FSAR方法中忽视视频与任务关系建模的问题，从而能够学习到跨视频的共享时序模式。&lt;h4&gt;方法&lt;/h4&gt;HR2G-shot框架包括以下两个组件：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;h4&gt;结论&lt;/h4&gt;HR2G-shot框架能够有效地提高Few-shot动作识别的性能，为FSAR领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Few-shot动作识别（FSAR）旨在通过少量示例识别新的动作类别。现有方法通常通过设计各种帧间时序建模策略独立地为每个视频学习帧级表示。然而，它们忽略了视频与任务之间的显式关系建模，因此未能捕捉视频之间的共享时序模式并重用历史任务中的时序知识。鉴于这一点，我们提出了HR2G-shot，一个用于FSAR的分层关系增强表示泛化框架，它统一了三种类型的关系建模（帧间、视频间和任务间）来从整体角度学习特定任务的时序模式。除了执行帧间时序交互之外，我们还设计了两个组件来分别探索视频间和任务间关系：i) Inter-video Semantic Correlation（ISC）以细粒度方式执行跨视频帧级交互，从而捕获特定任务的查询特征并学习支持特征之间的类内和类间时序相关性；ii) Inter-task Knowledge Transfer（IKT）从存储历史任务中不同时序模式的数据库中检索和聚合相关时序知识。在五个基准数据集上的大量实验表明，HR2G-shot优于当前的顶尖FSAR方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot action recognition (FSAR) aims to recognize novel action categorieswith few exemplars. Existing methods typically learn frame-levelrepresentations independently for each video by designing various inter-frametemporal modeling strategies. However, they neglect explicit relation modelingbetween videos and tasks, thus failing to capture shared temporal patternsacross videos and reuse temporal knowledge from historical tasks. In light ofthis, we propose HR2G-shot, a Hierarchical Relation-augmented RepresentationGeneralization framework for FSAR, which unifies three types of relationmodeling (inter-frame, inter-video, and inter-task) to learn task-specifictemporal patterns from a holistic view. In addition to conducting inter-frametemporal interactions, we further devise two components to respectively exploreinter-video and inter-task relationships: i) Inter-video Semantic Correlation(ISC) performs cross-video frame-level interactions in a fine-grained manner,thereby capturing task-specific query features and learning intra- andinter-class temporal correlations among support features; ii) Inter-taskKnowledge Transfer (IKT) retrieves and aggregates relevant temporal knowledgefrom the bank, which stores diverse temporal patterns from historical tasks.Extensive experiments on five benchmarks show that HR2G-shot outperformscurrent top-leading FSAR methods.</description>
      <author>example@mail.com (Hongyu Qu, Ling Xing, Rui Yan, Yazhou Yao, Guo-Sen Xie, Xiangbo Shu)</author>
      <guid isPermaLink="false">2504.10079v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Inferring genotype-phenotype maps using attention models</title>
      <link>http://arxiv.org/abs/2504.10388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究从基因型预测表型的遗传学挑战，提出了基于注意力机制的机器学习方法作为传统线性回归方法的替代方案。&lt;h4&gt;背景&lt;/h4&gt;传统遗传学方法通常使用线性回归分析基因型与表型之间的关系，但这种方法在处理复杂基因-环境相互作用和上位性模式时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;探讨注意力机制在预测表型方面的潜力，并评估其在遗传学中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;本研究应用注意力模型分析模拟数据和实验数据，比较了其在不同上位性复杂程度下的预测性能。&lt;h4&gt;主要发现&lt;/h4&gt;注意力模型在预测上位性环境下的表型方面表现出优于传统方法的预测能力。此外，多环境注意力模型能够通过有限的训练数据在新的环境条件下预测表型。&lt;h4&gt;结论&lt;/h4&gt;注意力机制在遗传学中预测表型具有潜力，特别是在处理复杂遗传和环境相互作用时，且能够实现跨环境的迁移学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测表型从基因型是遗传学的核心挑战。传统的数量遗传学方法通常使用基于线性回归的方法来分析这个问题。这些方法通常假设复杂性状的遗传结构可以用加性模型来参数化，其中位点的效应是独立的，加上（在某些情况下）位点之间的成对上位性相互作用。然而，这些模型在分析更复杂的上位性模式或微妙的基因-环境相互作用方面存在困难。最近机器学习领域的进展，尤其是基于注意力的模型，提供了一个有前景的替代方案。最初为自然语言处理开发的注意力模型在捕捉上下文相关的交互方面表现出色，并在预测蛋白质结构和功能方面表现出卓越的性能。在这里，我们将注意力模型应用于数量遗传学。我们使用模拟数据分析了基于注意力的方法在预测基因型从表型方面的性能，这些数据覆盖了具有增加上位性复杂性的各种模型，并使用芽殖酵母中最近的数量性状位点映射研究的实验数据。我们发现，与标准方法相比，我们的模型在上位性环境下表现出优越的样本外预测能力。我们还探索了一个更通用的多环境注意力模型，以联合分析跨多个环境的基因型-表型映射，并显示这种架构可以用于“迁移学习”——在新环境中用有限的训练数据预测表型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting phenotype from genotype is a central challenge in genetics.Traditional approaches in quantitative genetics typically analyze this problemusing methods based on linear regression. These methods generally assume thatthe genetic architecture of complex traits can be parameterized in terms of anadditive model, where the effects of loci are independent, plus (in some cases)pairwise epistatic interactions between loci. However, these models struggle toanalyze more complex patterns of epistasis or subtle gene-environmentinteractions. Recent advances in machine learning, particularly attention-basedmodels, offer a promising alternative. Initially developed for natural languageprocessing, attention-based models excel at capturing context-dependentinteractions and have shown exceptional performance in predicting proteinstructure and function. Here, we apply attention-based models to quantitativegenetics. We analyze the performance of this attention-based approach inpredicting phenotype from genotype using simulated data across a range ofmodels with increasing epistatic complexity, and using experimental data from arecent quantitative trait locus mapping study in budding yeast. We find thatour model demonstrates superior out-of-sample predictions in epistatic regimescompared to standard methods. We also explore a more general multi-environmentattention-based model to jointly analyze genotype-phenotype maps acrossmultiple environments and show that such architectures can be used for"transfer learning" - predicting phenotypes in novel environments with limitedtraining data.</description>
      <author>example@mail.com (Krishna Rijal, Caroline M. Holmes, Samantha Petti, Gautam Reddy, Michael M. Desai, Pankaj Mehta)</author>
      <guid isPermaLink="false">2504.10388v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>LL-Gaussian: Low-Light Scene Reconstruction and Enhancement via Gaussian Splatting for Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2504.10331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LL-Gaussian的新框架，用于从低光sRGB图像中进行3D重建和增强，实现了伪自然光的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;在低光场景中进行新颖视图合成（NVS）是一个重大挑战，因为输入质量下降，具有严重的噪声、低动态范围（LDR）和不稳定的初始化。&lt;h4&gt;目的&lt;/h4&gt;旨在解决低光场景下NVS的挑战，实现快速、高质量的3D重建和渲染。&lt;h4&gt;方法&lt;/h4&gt;LL-Gaussian引入了三个关键创新：1）一个端到端的低光高斯初始化模块（LLGIM），利用基于学习的MVS方法的密集先验来生成高质量的初始点云；2）一个双分支高斯分解模型，将场景的内在属性（反射率和照明）与瞬时的干扰分离，以实现稳定和可解释的优化；3）一个由物理约束和扩散先验引导的无监督优化策略，以联合引导分解和增强。&lt;h4&gt;主要发现&lt;/h4&gt;LL-Gaussian在速度和效果上优于现有的NeRF方法，实现了高达2000倍的速度提升，并将训练时间缩短到2%，同时提供更高质量的重建和渲染。&lt;h4&gt;结论&lt;/h4&gt;LL-Gaussian框架在低光环境下实现了有效的3D重建和渲染，为低光场景下的NVS提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis (NVS) in low-light scenes remains a significantchallenge due to degraded inputs characterized by severe noise, low dynamicrange (LDR) and unreliable initialization. While recent NeRF-based approacheshave shown promising results, most suffer from high computational costs, andsome rely on carefully captured or pre-processed data--such as RAW sensorinputs or multi-exposure sequences--which severely limits their practicality.In contrast, 3D Gaussian Splatting (3DGS) enables real-time rendering withcompetitive visual fidelity; however, existing 3DGS-based methods struggle withlow-light sRGB inputs, resulting in unstable Gaussian initialization andineffective noise suppression. To address these challenges, we proposeLL-Gaussian, a novel framework for 3D reconstruction and enhancement fromlow-light sRGB images, enabling pseudo normal-light novel view synthesis. Ourmethod introduces three key innovations: 1) an end-to-end Low-Light GaussianInitialization Module (LLGIM) that leverages dense priors from learning-basedMVS approach to generate high-quality initial point clouds; 2) a dual-branchGaussian decomposition model that disentangles intrinsic scene properties(reflectance and illumination) from transient interference, enabling stable andinterpretable optimization; 3) an unsupervised optimization strategy guided byboth physical constrains and diffusion prior to jointly steer decomposition andenhancement. Additionally, we contribute a challenging dataset collected inextreme low-light environments and demonstrate the effectiveness ofLL-Gaussian. Compared to state-of-the-art NeRF-based methods, LL-Gaussianachieves up to 2,000 times faster inference and reduces training time to just2%, while delivering superior reconstruction and rendering quality.</description>
      <author>example@mail.com (Hao Sun, Fenggen Yu, Huiyao Xu, Tao Zhang, Changqing Zou)</author>
      <guid isPermaLink="false">2504.10331v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Contrastive Learning's Capability of Neighborhood Aggregation for Collaborative Filtering</title>
      <link>http://arxiv.org/abs/2504.10113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGIR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightCCF的个性化推荐方法，基于图对比学习，通过理论推导和实验验证，发现CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，并提出改进的邻域聚合目标，提高了推荐系统的训练效率和推荐准确性。&lt;h4&gt;背景&lt;/h4&gt;个性化推荐在网页应用中广泛应用，图对比学习（GCL）成为推荐系统的主要方法之一，因为它能够从原始交互数据中提取自监督信号，有效缓解数据稀疏性问题。&lt;h4&gt;目的&lt;/h4&gt;揭示GCL方法性能提升的原因，并提出改进方法以提高推荐系统的训练效率和推荐准确性。&lt;h4&gt;方法&lt;/h4&gt;通过理论推导证明CL目标函数的梯度下降过程等同于图卷积，提出LightCCF方法，引入新的邻域聚合目标，实现高质量邻域聚合。&lt;h4&gt;主要发现&lt;/h4&gt;CL目标函数的梯度下降过程等同于图卷积，支持在交互图上的邻域聚合，现有方法在正样本选择上存在误区，限制了CL目标函数的潜力。&lt;h4&gt;结论&lt;/h4&gt;LightCCF方法在三个高度稀疏的公共数据集上，有效聚合邻域信息，防止图过度平滑，在训练效率和推荐准确性方面均优于现有GCL方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：个性化推荐在网页应用中得到广泛应用，图对比学习（GCL）逐渐成为推荐系统中的主流方法，主要归功于其从原始交互数据中提取自监督信号的能力，有效缓解了数据稀疏性问题。一个典型的基于GCL的方法通常在图卷积期间进行数据增强，以生成更多的对比视图，并对这些新视图进行对比以获得丰富的自监督信号。尽管这种范式是有效的，但其性能提升背后的原因仍然是个谜。在这篇论文中，我们首先通过理论推导揭示，CL目标的梯度下降过程形式上等同于图卷积，这意味着CL目标函数本质上支持在交互图上的邻域聚合。我们进一步通过实验验证这一能力，并确定了先前方法中选择正样本的常见误区，这些误区限制了CL目标函数的潜力。基于这一发现，我们提出了Light Contrastive Collaborative Filtering（LightCCF）方法，该方法引入了一个新的邻域聚合目标，在将用户推向所有互动项目的同时，将他们推向其他正对，从而以非常低的时间复杂度实现高质量的邻域聚合。在三个高度稀疏的公共数据集上，所提出的方法有效地聚合了邻域信息，同时防止了图过度平滑，在训练效率和推荐准确性方面均优于现有的基于GCL的方法。我们的实现是公开可访问的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized recommendation is widely used in the web applications, and graphcontrastive learning (GCL) has gradually become a dominant approach inrecommender systems, primarily due to its ability to extract self-supervisedsignals from raw interaction data, effectively alleviating the problem of datasparsity. A classic GCL-based method typically uses data augmentation duringgraph convolution to generates more contrastive views, and performs contrast onthese new views to obtain rich self-supervised signals. Despite this paradigmis effective, the reasons behind the performance gains remain a mystery. Inthis paper, we first reveal via theoretical derivation that the gradientdescent process of the CL objective is formally equivalent to graphconvolution, which implies that CL objective inherently supports neighborhoodaggregation on interaction graphs. We further substantiate this capabilitythrough experimental validation and identify common misconceptions in theselection of positive samples in previous methods, which limit the potential ofCL objective. Based on this discovery, we propose the Light ContrastiveCollaborative Filtering (LightCCF) method, which introduces a novelneighborhood aggregation objective to bring users closer to all interacteditems while pushing them away from other positive pairs, thus achievinghigh-quality neighborhood aggregation with very low time complexity. On threehighly sparse public datasets, the proposed method effectively aggregateneighborhood information while preventing graph over-smoothing, demonstratingsignificant improvements over existing GCL-based counterparts in both trainingefficiency and recommendation accuracy. Our implementations are publiclyaccessible.</description>
      <author>example@mail.com (Yu Zhang, Yiwen Zhang, Yi Zhang, Lei Sang, Yun Yang)</author>
      <guid isPermaLink="false">2504.10113v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EmbodiedOcc++: Boosting Embodied 3D Occupancy Prediction with Plane Regularization and Uncertainty Sampler</title>
      <link>http://arxiv.org/abs/2504.09540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EmbodiedOcc++的在线3D占用预测框架，通过引入几何引导优化模块（GRM）和语义感知不确定性采样器（SUS）两个关键创新，提升了原始框架的性能。&lt;h4&gt;背景&lt;/h4&gt;在线3D占用预测对于理解虚拟环境具有重要意义，然而现有的EmbodiedOcc框架未能充分利用室内环境的几何特性。&lt;h4&gt;目的&lt;/h4&gt;提高EmbodiedOcc框架在室内环境占用预测中的几何一致性。&lt;h4&gt;方法&lt;/h4&gt;1. 引入GRM模块，通过平面正则化约束高斯更新，使语义高斯与平面表面准确对齐。2. 引入SUS模块，在连续帧的重叠区域进行更有效的更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，EmbodiedOcc++在EmbodiedOcc-ScanNet基准测试中取得了最先进的性能，提高了边缘精度并保留了更多几何细节，同时保证了计算效率。&lt;h4&gt;结论&lt;/h4&gt;EmbodiedOcc++是一种有效的在线3D占用预测方法，对于在线实体感知具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Online 3D occupancy prediction provides a comprehensive spatial understanding of embodied environments. While the innovative EmbodiedOcc framework utilizes 3D semantic Gaussians for progressive indoor occupancy prediction, it overlooks the geometric characteristics of indoor environments, which are primarily characterized by planar structures. This paper introduces EmbodiedOcc++, enhancing the original framework with two key innovations: a Geometry-guided Refinement Module (GRM) that constrains Gaussian updates through planar regularization, along with a Semantic-aware Uncertainty Sampler (SUS) that enables more effective updates in overlapping regions between consecutive frames. GRM regularizes the position update to align with surface normals. It determines the adaptive regularization weight using curvature-based and depth-based constraints, allowing semantic Gaussians to align accurately with planar surfaces while adapting in complex regions. To effectively improve geometric consistency from different views, SUS adaptively selects proper Gaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNet benchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performance across different settings. Our method demonstrates improved edge accuracy and retains more geometric details while ensuring computational efficiency, which is essential for online embodied perception. The code will be released at: https://github.com/PKUHaoWang/EmbodiedOcc2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online 3D occupancy prediction provides a comprehensive spatial understandingof embodied environments. While the innovative EmbodiedOcc framework utilizes3D semantic Gaussians for progressive indoor occupancy prediction, it overlooksthe geometric characteristics of indoor environments, which are primarilycharacterized by planar structures. This paper introduces EmbodiedOcc++,enhancing the original framework with two key innovations: a Geometry-guidedRefinement Module (GRM) that constrains Gaussian updates through planeregularization, along with a Semantic-aware Uncertainty Sampler (SUS) thatenables more effective updates in overlapping regions between consecutiveframes. GRM regularizes the position update to align with surface normals. Itdetermines the adaptive regularization weight using curvature-based anddepth-based constraints, allowing semantic Gaussians to align accurately withplanar surfaces while adapting in complex regions. To effectively improvegeometric consistency from different views, SUS adaptively selects properGaussians to update. Comprehensive experiments on the EmbodiedOcc-ScanNetbenchmark demonstrate that EmbodiedOcc++ achieves state-of-the-art performanceacross different settings. Our method demonstrates improved edge accuracy andretains more geometric details while ensuring computational efficiency, whichis essential for online embodied perception. The code will be released at:https://github.com/PKUHaoWang/EmbodiedOcc2.</description>
      <author>example@mail.com (Hao Wang, Xiaobao Wei, Xiaoan Zhang, Jianing Li, Chengyu Bai, Ying Li, Ming Lu, Wenzhao Zheng, Shanghang Zhang)</author>
      <guid isPermaLink="false">2504.09540v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>UP-Person: Unified Parameter-Efficient Transfer Learning for Text-based Person Retrieval</title>
      <link>http://arxiv.org/abs/2504.10084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, first submited to IEEE TCSVT on 2024 May. Under  review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为UP-Person的新型统一参数高效迁移学习方法，用于基于文本的人物检索任务，该方法通过仅微调少量参数实现了良好的性能。&lt;h4&gt;背景&lt;/h4&gt;基于文本的人物检索（TPR）是一个多模态任务，它利用CLIP等预训练模型来提取人物图像和文本特征，并在这一领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种参数高效的方法，用于基于文本的人物检索，以解决全量微调大模型容易过拟合且泛化能力受限的问题。&lt;h4&gt;方法&lt;/h4&gt;UP-Person方法集成了三个轻量级PETL组件：Prefix、LoRA和Adapter。Prefix和LoRA用于挖掘局部信息，Adapter用于调整全局特征表示。同时优化了S-Prefix和L-Adapter两个子模块以适应统一的TPR架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UP-Person在各种人物检索数据集上取得了最先进的结果，包括CUHK-PEDES、ICFG-PEDES和RSTPReid，而仅微调了4.7%的参数。&lt;h4&gt;结论&lt;/h4&gt;UP-Person方法通过微调少量参数实现了高效的人物检索，为基于文本的人物检索任务提供了一个新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Based on text, the paper proposes a novel unified parameter-efficient transfer learning method (UP-Person) for person retrieval, achieving advanced performance by merely fine-tuning a small number of parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-based Person Retrieval (TPR) as a multi-modal task, which aims toretrieve the target person from a pool of candidate images given a textdescription, has recently garnered considerable attention due to the progressof contrastive visual-language pre-trained model. Prior works leveragepre-trained CLIP to extract person visual and textual features and fullyfine-tune the entire network, which have shown notable performance improvementscompared to uni-modal pre-training models. However, full-tuning a large modelis prone to overfitting and hinders the generalization ability. In this paper,we propose a novel Unified Parameter-Efficient Transfer Learning (PETL) methodfor Text-based Person Retrieval (UP-Person) to thoroughly transfer themulti-modal knowledge from CLIP. Specifically, UP-Person simultaneouslyintegrates three lightweight PETL components including Prefix, LoRA andAdapter, where Prefix and LoRA are devised together to mine local informationwith task-specific information prompts, and Adapter is designed to adjustglobal feature representations. Additionally, two vanilla submodules areoptimized to adapt to the unified architecture of TPR. For one thing, S-Prefixis proposed to boost attention of prefix and enhance the gradient propagationof prefix tokens, which improves the flexibility and performance of the vanillaprefix. For another thing, L-Adapter is designed in parallel with layernormalization to adjust the overall distribution, which can resolve conflictscaused by overlap and interaction among multiple submodules. Extensiveexperimental results demonstrate that our UP-Person achieves state-of-the-artresults across various person retrieval datasets, including CUHK-PEDES,ICFG-PEDES and RSTPReid while merely fine-tuning 4.7\% parameters. Code isavailable at https://github.com/Liu-Yating/UP-Person.</description>
      <author>example@mail.com (Yating Liu, Yaowei Li, Xiangyuan Lan, Wenming Yang, Zimo Liu, Qingmin Liao)</author>
      <guid isPermaLink="false">2504.10084v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Text To 3D Object Generation For Scalable Room Assembly</title>
      <link>http://arxiv.org/abs/2504.09328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at the ICLR 2025 Workshop on Synthetic Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种端到端系统，用于生成高质量的3D室内场景合成数据，以解决数据稀缺的问题，并旨在通过合成数据增强机器学习模型的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。&lt;h4&gt;目的&lt;/h4&gt;为了解决数据稀缺的问题，该研究旨在提出一种可扩展、高质量、可定制的3D室内场景合成数据生成系统。&lt;h4&gt;方法&lt;/h4&gt;系统通过整合和适应文本到图像和多视图扩散模型，结合基于Neural Radiance Field的网格化技术，从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。同时，引入了新颖的损失函数和训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。&lt;h4&gt;结论&lt;/h4&gt;该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代场景理解机器学习模型，如深度估计和物体跟踪，依赖于大量、高质量的模拟真实部署场景的数据集。为了解决数据稀缺问题，我们提出了一种用于生成可扩展、高质量、可定制3D室内场景合成数据的端到端系统。通过整合和适应文本到图像和多视图扩散模型与基于Neural Radiance Field的网格化，该系统从文本提示中生成高保真3D物体资产，并使用渲染工具将它们整合到预定义的平面图中。通过引入新颖的损失函数和训练策略到现有方法中，该系统支持按需场景生成，旨在缓解当前可用数据的稀缺性，这些数据通常由艺术家手工制作。该系统推进了合成数据在解决机器学习训练限制中的作用，使得能够开发出更鲁棒和泛化的现实应用模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern machine learning models for scene understanding, such as depthestimation and object tracking, rely on large, high-quality datasets that mimicreal-world deployment scenarios. To address data scarcity, we propose anend-to-end system for synthetic data generation for scalable, high-quality, andcustomizable 3D indoor scenes. By integrating and adapting text-to-image andmulti-view diffusion models with Neural Radiance Field-based meshing, thissystem generates highfidelity 3D object assets from text prompts andincorporates them into pre-defined floor plans using a rendering tool. Byintroducing novel loss functions and training strategies into existing methods,the system supports on-demand scene generation, aiming to alleviate thescarcity of current available data, generally manually crafted by artists. Thissystem advances the role of synthetic data in addressing machine learningtraining limitations, enabling more robust and generalizable models forreal-world applications.</description>
      <author>example@mail.com (Sonia Laguna, Alberto Garcia-Garcia, Marie-Julie Rakotosaona, Stylianos Moschoglou, Leonhard Helminger, Sergio Orts-Escolano)</author>
      <guid isPermaLink="false">2504.09328v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Model Zoo of Vision Transformers</title>
      <link>http://arxiv.org/abs/2504.10231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the ICLR Workshop on Neural Network Weights as a New Data  Modality 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了第一个视觉变压器（ViT）模型动物园，旨在扩展现有模型动物园的功能和应用范围。&lt;h4&gt;背景&lt;/h4&gt;随着“模型动物园”的出现，神经网络模型分析、表示学习以及神经网络的参数生成等下游任务得到了发展。然而，现有的模型动物园在规模和架构上有限，且忽略了当前最成功的神经网络架构之一——Transformer。&lt;h4&gt;目的&lt;/h4&gt;填补现有模型动物园的不足，引入视觉变压器（ViT）模型动物园，并开发新的模型动物园生成蓝图。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的模型动物园生成蓝图，包括预训练和微调步骤，并发布250个独特的模型。这些模型通过大量生成因素生成，并通过权重空间和行为指标验证其多样性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型动物园允许研究人员将基于模型种群的方法从小型模型扩展到最先进架构。&lt;h4&gt;结论&lt;/h4&gt;该模型动物园可在github.com/ModelZoos/ViTModelZoo上获取，有助于推动神经网络模型种群方法的发展。&lt;h4&gt;翻译&lt;/h4&gt;The availability of large, structured populations of neural networks - called 'model zoos' - has led to the development of a multitude of downstream tasks ranging from model analysis, to representation learning on model weights or generative modeling of neural network parameters. However, existing model zoos are limited in size and architecture and neglect the transformer, which is among the currently most successful neural network architectures. We address this gap by introducing the first model zoo of vision transformers (ViT). To better represent recent training approaches, we develop a new blueprint for model zoo generation that encompasses both pre-training and fine-tuning steps, and publish 250 unique models. They are carefully generated with a large span of generating factors, and their diversity is validated using a thorough choice of weight-space and behavioral metrics. To further motivate the utility of our proposed dataset, we suggest multiple possible applications grounded in both extensive exploratory experiments and a number of examples from the existing literature. By extending previous lines of similar work, our model zoo allows researchers to push their model population-based methods from the small model regime to state-of-the-art architectures. We make our model zoo available at github.com/ModelZoos/ViTModelZoo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of large, structured populations of neural networks - called'model zoos' - has led to the development of a multitude of downstream tasksranging from model analysis, to representation learning on model weights orgenerative modeling of neural network parameters. However, existing model zoosare limited in size and architecture and neglect the transformer, which isamong the currently most successful neural network architectures. We addressthis gap by introducing the first model zoo of vision transformers (ViT). Tobetter represent recent training approaches, we develop a new blueprint formodel zoo generation that encompasses both pre-training and fine-tuning steps,and publish 250 unique models. They are carefully generated with a large spanof generating factors, and their diversity is validated using a thorough choiceof weight-space and behavioral metrics. To further motivate the utility of ourproposed dataset, we suggest multiple possible applications grounded in bothextensive exploratory experiments and a number of examples from the existingliterature. By extending previous lines of similar work, our model zoo allowsresearchers to push their model population-based methods from the small modelregime to state-of-the-art architectures. We make our model zoo available atgithub.com/ModelZoos/ViTModelZoo.</description>
      <author>example@mail.com (Damian Falk, Léo Meynent, Florence Pfammatter, Konstantin Schürholt, Damian Borth)</author>
      <guid isPermaLink="false">2504.10231v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance Software Maintainability</title>
      <link>http://arxiv.org/abs/2504.10412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了图神经网络（GNNs）在代码重构中的应用，利用抽象语法树（AST）提高软件可维护性。&lt;h4&gt;背景&lt;/h4&gt;通过分析来自CodeSearchNet的200万个代码片段和75000个文件的GitHub Python语料库，研究对比了GNNs与基于规则的SonarQube和决策树。&lt;h4&gt;目的&lt;/h4&gt;利用GNNs提高代码重构的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用GNNs对代码进行重构，并与SonarQube和决策树进行对比，评估了复杂度、耦合度和重构精度等指标。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在重构代码时达到了92%的准确率，将复杂度降低了35%，耦合度降低了33%，超过了SonarQube（78%，16%）和决策树（85%，25%）。预处理固定了60%的语法错误。&lt;h4&gt;结论&lt;/h4&gt;GNNs提供了一个可扩展的人工智能驱动的路径，以实现更清洁的代码库，这对于软件工程至关重要。&lt;h4&gt;翻译&lt;/h4&gt;This study explores Graph Neural Networks (GNNs) as a transformative tool for code refactoring, using abstract syntax trees (ASTs) to boost software maintainability. It analyzes a dataset of 2 million snippets from CodeSearchNet and a custom 75000-file GitHub Python corpus, comparing GNNs against rule-based SonarQube and decision trees. Metrics include cyclomatic complexity (target below 10), coupling (target below 5), and refactoring precision. GNNs achieve 92% accuracy, reducing complexity by 35% and coupling by 33%, outperforming SonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% of syntax errors. Bar graphs, tables, and AST visuals clarify results. This offers a scalable AI-driven path to cleaner codebases, which is crucial for software engineering.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores Graph Neural Networks (GNNs) as a transformative tool forcode refactoring, using abstract syntax trees (ASTs) to boost softwaremaintainability. It analyzes a dataset of 2 million snippets from CodeSearchNetand a custom 75000-file GitHub Python corpus, comparing GNNs against rule-basedSonarQube and decision trees. Metrics include cyclomatic complexity (targetbelow 10), coupling (target below 5), and refactoring precision. GNNs achieve92% accuracy, reducing complexity by 35% and coupling by 33%, outperformingSonarQube (78%, 16%) and decision trees (85%, 25%). Preprocessing fixed 60% ofsyntax errors. Bar graphs, tables, and AST visuals clarify results. This offersa scalable AI-driven path to cleaner codebases, which is crucial for softwareengineering.</description>
      <author>example@mail.com (Gopichand Bandarupalli)</author>
      <guid isPermaLink="false">2504.10412v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection</title>
      <link>http://arxiv.org/abs/2504.09086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于雷达回波分布模型的雷达-相机融合方法，以提高雷达-相机检测性能。&lt;h4&gt;背景&lt;/h4&gt;雷达回波在物体边界和内部点反射，导致雷达回波分布复杂，依赖于物体类别、大小和方向等因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过雷达回波分布模型辅助融合，以提高雷达-相机检测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 建立模型预测基于单目检测器获得的物体属性条件下的雷达回波分布。2. 使用预测分布作为核函数匹配单目检测附近的实际测量雷达点，生成附近位置的匹配分数。3. 融合阶段结合上下文和核检测器来细化匹配分数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在nuScenes数据集上实现了最先进的雷达-相机检测性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过雷达回波分布模型辅助融合，有效提升了雷达-相机检测性能。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper proposes a radar-camera fusion method based on a radar hit distribution model to improve radar-camera detection performance. Radar hits reflect from points on both the boundary and internal to object outlines, resulting in a complex distribution of radar hits that depends on factors including object category, size, and orientation. The proposed method explicitly utilizes a radar hit distribution model to assist fusion. First, a model is built to predict radar hit distributions conditioned on object properties obtained from a monocular detector. Second, the predicted distribution is used as a kernel to match actual measured radar points in the neighborhood of the monocular detections, generating matching scores at nearby positions. Finally, a fusion stage combines context with the kernel detector to refine the matching scores. The method achieves the state-of-the-art radar-camera detection performance on nuScenes. The source code is available at https://github.com/longyunf/riccardo.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar hits reflect from points on both the boundary and internal to objectoutlines. This results in a complex distribution of radar hits that depends onfactors including object category, size, and orientation. Current radar-camerafusion methods implicitly account for this with a black-box neural network. Inthis paper, we explicitly utilize a radar hit distribution model to assistfusion. First, we build a model to predict radar hit distributions conditionedon object properties obtained from a monocular detector. Second, we use thepredicted distribution as a kernel to match actual measured radar points in theneighborhood of the monocular detections, generating matching scores at nearbypositions. Finally, a fusion stage combines context with the kernel detector torefine the matching scores. Our method achieves the state-of-the-artradar-camera detection performance on nuScenes. Our source code is available athttps://github.com/longyunf/riccardo.</description>
      <author>example@mail.com (Yunfei Long, Abhinav Kumar, Xiaoming Liu, Daniel Morris)</author>
      <guid isPermaLink="false">2504.09086v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mavors: Multi-granularity Video Representation for Multimodal Large Language Model</title>
      <link>http://arxiv.org/abs/2504.10068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mavors是一个针对多模态大型语言模型（MLLMs）长视频理解的新框架，旨在平衡计算效率与保留精细时空模式。&lt;h4&gt;背景&lt;/h4&gt;长视频理解在MLLMs中面临挑战，现有方法如稀疏采样、低分辨率密集采样和标记压缩在处理复杂运动或不同分辨率的视频时，会在时间动态、空间细节或微妙交互方面损失大量信息。&lt;h4&gt;目的&lt;/h4&gt;提出Mavors框架，旨在解决上述问题，实现整体长视频建模。&lt;h4&gt;方法&lt;/h4&gt;Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。&lt;h4&gt;主要发现&lt;/h4&gt;Mavors在保持空间保真度和时间连续性方面表现出优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Mavors框架在长视频理解中提供了一种有效的解决方案，能够平衡计算效率与时空信息保留。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在多模态大型语言模型（MLLMs）中进行长视频理解面临一个关键挑战：在保持精细时空模式的同时平衡计算效率。现有方法（例如稀疏采样、低分辨率密集采样和标记压缩）在处理复杂运动或不同分辨率的视频时，在时间动态、空间细节或微妙交互方面存在显著的信息损失。为了解决这个问题，我们提出了Mavors，这是一个用于整体长视频建模的新框架。具体来说，Mavors通过两个核心组件直接将原始视频内容编码成潜在表示：1) 内部块视觉编码器（IVE），通过3D卷积和视觉Transformer保留高分辨率空间特征；2) 交叉块特征聚合器（IFA），使用基于transformer的依赖建模和块级旋转位置编码建立块之间的时间一致性。此外，该框架通过将图像视为单帧视频，通过子图像分解统一图像和视频理解。在多个基准测试中的实验表明，Mavors在保持空间保真度和时间连续性方面具有优越性，在需要精细时空推理的任务中显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-context video understanding in multimodal large language models (MLLMs)faces a critical challenge: balancing computational efficiency with theretention of fine-grained spatio-temporal patterns. Existing approaches (e.g.,sparse sampling, dense sampling with low resolution, and token compression)suffer from significant information loss in temporal dynamics, spatial details,or subtle interactions, particularly in videos with complex motion or varyingresolutions. To address this, we propose $\mathbf{Mavors}$, a novel frameworkthat introduces $\mathbf{M}$ulti-gr$\mathbf{a}$nularity$\mathbf{v}$ide$\mathbf{o}$ $\mathbf{r}$epre$\mathbf{s}$entation for holisticlong-video modeling. Specifically, Mavors directly encodes raw video contentinto latent representations through two core components: 1) an Intra-chunkVision Encoder (IVE) that preserves high-resolution spatial features via 3Dconvolutions and Vision Transformers, and 2) an Inter-chunk Feature Aggregator(IFA) that establishes temporal coherence across chunks using transformer-baseddependency modeling with chunk-level rotary position encodings. Moreover, theframework unifies image and video understanding by treating images assingle-frame videos via sub-image decomposition. Experiments across diversebenchmarks demonstrate Mavors' superiority in maintaining both spatial fidelityand temporal continuity, significantly outperforming existing methods in tasksrequiring fine-grained spatio-temporal reasoning.</description>
      <author>example@mail.com (Yang Shi, Jiaheng Liu, Yushuo Guan, Zhenhua Wu, Yuanxing Zhang, Zihao Wang, Weihong Lin, Jingyun Hua, Zekun Wang, Xinlong Chen, Bohan Zeng, Wentao Zhang, Fuzheng Zhang, Wenjing Yang, Di Zhang)</author>
      <guid isPermaLink="false">2504.10068v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>The topology of synergy: linking topological and information-theoretic approaches to higher-order interactions in complex systems</title>
      <link>http://arxiv.org/abs/2504.10140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不可约高阶相互作用在复杂系统中的研究，比较了拓扑数据分析和多变量信息理论在描述多变量数据中高阶相互作用的方法。&lt;h4&gt;背景&lt;/h4&gt;高阶相互作用成为复杂系统研究的核心，拓扑数据分析和多变量信息理论是识别高阶相互作用的主要框架。&lt;h4&gt;目的&lt;/h4&gt;评估两种框架在定义“高阶结构”方面的异同。&lt;h4&gt;方法&lt;/h4&gt;通过玩具示例和自然数据（如fMRI信号）进行对比研究，并使用PCA进行降维分析。&lt;h4&gt;主要发现&lt;/h4&gt;高阶协同信息与点云中的三维洞穴相关，fMRI数据中协同信息与三维洞穴的数量和大小有强相关性，PCA倾向于表示高阶冗余，但未能保留高阶信息和拓扑结构。&lt;h4&gt;结论&lt;/h4&gt;这些结果指向了发展一个涵盖拓扑和信息理论方法，同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不可约高阶相互作用的研究已成为复杂系统研究的核心主题。拓扑数据分析和多变量信息理论是识别经验数据中高阶相互作用的最发达的两种框架。尽管这两者有相似的宗旨，但它们建立在明显不同的数学基础上，并且主要是平行发展的。在本研究中，我们展示了拓扑数据分析和信息理论方法在描述多变量数据中高阶相互作用方面的直接比较；目的是评估这些框架在定义“高阶结构”方面的相似性和差异性。我们从具有已知拓扑的玩具示例开始，然后转向自然数据：从人脑收集的fMRI信号。我们发现内在的高阶协同信息与点云中的三维洞穴相关：如球体这样的形状是协同主导的。在fMRI数据中，我们发现协同信息与三维洞穴的数量和大小之间存在强相关性。此外，我们发现降维技术如PCA优先表示高阶冗余，并且很大程度上未能保留高阶信息和拓扑结构，这表明基于流形的常见方法在系统地识别数据的重要特征方面存在系统性失败。这些结果指向了发展一个涵盖拓扑和信息理论方法，同时同时强调更传统方法局限性的丰富的高阶相互作用理论的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of irreducible higher-order interactions has become a core topic ofstudy in complex systems. Two of the most well-developed frameworks,topological data analysis and multivariate information theory, aim to provideformal tools for identifying higher-order interactions in empirical data.Despite similar aims, however, these two approaches are built on markedlydifferent mathematical foundations and have been developed largely in parallel.In this study, we present a head-to-head comparison of topological dataanalysis and information-theoretic approaches to describing higher-orderinteractions in multivariate data; with the aim of assessing the similaritiesand differences between how the frameworks define ``higher-order structures."We begin with toy examples with known topologies, before turning tonaturalistic data: fMRI signals collected from the human brain. We find thatintrinsic, higher-order synergistic information is associated withthree-dimensional cavities in a point cloud: shapes such as spheres aresynergy-dominated. In fMRI data, we find strong correlations betweensynergistic information and both the number and size of three-dimensionalcavities. Furthermore, we find that dimensionality reduction techniques such asPCA preferentially represent higher-order redundancies, and largely fail topreserve both higher-order information and topological structure, suggestingthat common manifold-based approaches to studying high-dimensional data aresystematically failing to identify important features of the data. Theseresults point towards the possibility of developing a rich theory ofhigher-order interactions that spans topological and information-theoreticapproaches while simultaneously highlighting the profound limitations of moreconventional methods.</description>
      <author>example@mail.com (Thomas F. Varley, Pedro A. M. Mediano, Alice Patania, Josh Bongard)</author>
      <guid isPermaLink="false">2504.10140v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust Unsupervised Domain Adaptation for 3D Point Cloud Segmentation Under Source Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2504.01659v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对抗鲁棒的领域自适应（UDA）框架，用于3D点云语义分割模型，通过 stealthy adversarial point cloud generation attack 和 Adversarial Adaptation Framework（AAF）来增强模型在对抗扰动下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督领域自适应（UDA）框架在干净数据上对3D点云语义分割模型具有良好的泛化能力，但忽略了当源域本身受到损害时的对抗鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;全面探索UDA框架的鲁棒性，并提出对抗鲁棒的解决方案。&lt;h4&gt;方法&lt;/h4&gt;设计了一种 stealthy adversarial point cloud generation attack，用于生成受污染的LiDAR点云数据集AdvSynLiDAR。基于此，提出了一种新的对抗自适应框架（AAF），通过扩展关键点敏感（KPS）损失到鲁棒长尾损失（RLT loss）并利用解码分支，使模型在预训练阶段关注长尾类别，并在适应阶段利用高置信度的解码点云信息来恢复点云结构。&lt;h4&gt;主要发现&lt;/h4&gt;在AdvSynLiDAR数据集上评估了AAF方法，结果表明AAF方法可以减轻3D点云分割应用中源对抗扰动下的性能下降。&lt;h4&gt;结论&lt;/h4&gt;本文提出的AAF方法能够有效提高3D点云语义分割模型在对抗扰动下的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised domain adaptation (UDA) frameworks have shown good generalization capabilities for 3D point cloud semantic segmentation models on clean data. However, existing works overlook adversarial robustness when the source domain itself is compromised. To comprehensively explore the robustness of the UDA frameworks, we first design a stealthy adversarial point cloud generation attack that can significantly contaminate datasets with only minor perturbations to the point cloud surface. Based on that, we propose a novel dataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds. With the generated corrupted data, we further develop the Adversarial Adaptation Framework (AAF) as the countermeasure. Specifically, by extending the key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss) and utilizing a decoder branch, our approach enables the model to focus on long-tail classes during the pre-training phase and leverages high-confidence decoded point cloud information to restore point cloud structures during the adaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, where the results demonstrate that our AAF method can mitigate performance degradation under source adversarial perturbations for UDA in the 3D point cloud segmentation application.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) frameworks have shown goodgeneralization capabilities for 3D point cloud semantic segmentation models onclean data. However, existing works overlook adversarial robustness when thesource domain itself is compromised. To comprehensively explore the robustnessof the UDA frameworks, we first design a stealthy adversarial point cloudgeneration attack that can significantly contaminate datasets with only minorperturbations to the point cloud surface. Based on that, we propose a noveldataset, AdvSynLiDAR, comprising synthesized contaminated LiDAR point clouds.With the generated corrupted data, we further develop the AdversarialAdaptation Framework (AAF) as the countermeasure. Specifically, by extendingthe key point sensitive (KPS) loss towards the Robust Long-Tail loss (RLT loss)and utilizing a decoder branch, our approach enables the model to focus onlong-tail classes during the pre-training phase and leverages high-confidencedecoded point cloud information to restore point cloud structures during theadaptation phase. We evaluated our AAF method on the AdvSynLiDAR dataset, wherethe results demonstrate that our AAF method can mitigate performancedegradation under source adversarial perturbations for UDA in the 3D pointcloud segmentation application.</description>
      <author>example@mail.com (Haosheng Li, Junjie Chen, Yuecong Xu, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01659v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data</title>
      <link>http://arxiv.org/abs/2504.10097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的模型STaRFormer，用于处理非平稳和 irregularly sampled的时空数据，以准确预测智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;背景&lt;/h4&gt;准确预测序列时空数据对于多种应用至关重要，但现实场景中的环境因素和传感器限制导致数据非平稳和不规则采样，带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;通过使用真实世界数据，学习智能设备用户在车辆周围受限区域内的意图。&lt;h4&gt;方法&lt;/h4&gt;开发了STaRFormer模型，它是一个通用的序列建模框架，采用了一种新颖的动态注意力区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;在15个不同类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用的实验数据集上，STaRFormer展示了其有效性和实用性，并取得了比现有方法显著的改进。&lt;h4&gt;结论&lt;/h4&gt;STaRFormer代码和数据将公开提供，以供进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测序列时空数据对于各种应用至关重要。利用真实世界数据，我们旨在学习智能设备用户在车辆周围受限区域内的意图。然而，在现实场景中，环境因素和传感器限制导致非平稳和不规则采样的数据，带来了重大挑战。为了解决这些问题，我们开发了一种基于Transformer的方法，即STaRFormer，它是一个用于序列建模的通用框架。STaRFormer采用了一种新颖的、基于动态注意力的区域掩码方案，并结合半监督对比学习来增强特定任务的潜在表示。在15个类型（包括非平稳和不规则采样的）、领域、序列长度、训练样本和应用不同的数据集上进行的综合实验，证明了STaRFormer的有效性和实用性。我们实现了对现有方法的显著改进。代码和数据将被公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions using sequential spatiotemporal data are crucial forvarious applications. Utilizing real-world data, we aim to learn the intent ofa smart device user within confined areas of a vehicle's surroundings. However,in real-world scenarios, environmental factors and sensor limitations result innon-stationary and irregularly sampled data, posing significant challenges. Toaddress these issues, we developed a Transformer-based approach, STaRFormer,which serves as a universal framework for sequential modeling. STaRFormeremploys a novel, dynamic attention-based regional masking scheme combined withsemi-supervised contrastive learning to enhance task-specific latentrepresentations. Comprehensive experiments on 15 datasets varying in types(including non-stationary and irregularly sampled), domains, sequence lengths,training samples, and applications, demonstrate the efficacy and practicalityof STaRFormer. We achieve notable improvements over state-of-the-artapproaches. Code and data will be made available.</description>
      <author>example@mail.com (Maxmilian Forstenhäusler, Daniel Külzer, Christos Anagnostopoulos, Shameem Puthiya Parambath, Natascha Weber)</author>
      <guid isPermaLink="false">2504.10097v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Harmonize Cross-vendor X-ray Images by Non-linear Image Dynamics Correction</title>
      <link>http://arxiv.org/abs/2504.10080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了传统图像增强方法在医疗图像分析中如何提高模型鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;通过对不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。&lt;h4&gt;目的&lt;/h4&gt;为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题。&lt;h4&gt;方法&lt;/h4&gt;将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。&lt;h4&gt;主要发现&lt;/h4&gt;GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;h4&gt;翻译&lt;/h4&gt;本研究探讨了如何在医疗图像分析中通过传统图像增强提高模型的鲁棒性。通过对来自不同供应商的图像应用常见的归一化方法，研究了这些方法对迁移学习中模型泛化的影响。为了解决领域特定图像动态的非线性特性无法通过简单线性变换解决的问题，将图像调和任务重新定义为曝光校正问题，并提出了一种名为全局深度曲线估计（GDCE）的方法来减少领域特定的曝光不匹配。GDCE通过预定义的多项式函数进行增强，并利用“领域判别器”进行训练，旨在与现有的黑盒方法相比，提高下游任务中模型的透明度。研究表明，通过这种方法，可以提高医疗图像分析中模型的鲁棒性和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore how conventional image enhancement can improvemodel robustness in medical image analysis. By applying commonly usednormalization methods to images from various vendors and studying theirinfluence on model generalization in transfer learning, we show that thenonlinear characteristics of domain-specific image dynamics cannot be addressedby simple linear transforms. To tackle this issue, we reformulate the imageharmonization task as an exposure correction problem and propose a methodtermed Global Deep Curve Estimation (GDCE) to reduce domain-specific exposuremismatch. GDCE performs enhancement via a pre-defined polynomial function andis trained with the help of a ``domain discriminator'', aiming to improve modeltransparency in downstream tasks compared to existing black-box methods.</description>
      <author>example@mail.com (Yucheng Lu, Shunxin Wang, Dovile Juodelyte, Veronika Cheplygina)</author>
      <guid isPermaLink="false">2504.10080v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>CROSSAN: Towards Efficient and Effective Adaptation of Multiple Multimodal Foundation Models for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2504.10307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CROSSAN的跨模态侧适配网络，用于解决多模态基础模型在序列推荐任务中的高效适配问题。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在表示不同原始模态（如文本、图像、音频、视频等）方面表现出色，但其在序列推荐中的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以高效且有效地适配多个多模态基础模型进行序列推荐任务。&lt;h4&gt;方法&lt;/h4&gt;CROSSAN利用完全解耦的侧适配器范式，并结合Mixture of Modality Expert Fusion (MOMEF)机制，实现跨模态学习并优化多模态融合的最终阶段。&lt;h4&gt;主要发现&lt;/h4&gt;CROSSAN在公开数据集上表现出色，能够适配四个基础模型并实现性能提升。随着适配的多模态基础模型增多，性能持续提升。&lt;h4&gt;结论&lt;/h4&gt;CROSSAN能够有效解决多模态基础模型在序列推荐任务中的适配问题，并有望促进相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a plug-and-play Cross-modal Side Adapter Network (CROSSAN) to address the issue of efficient adaptation of multimodal foundation models in the sequential recommendation task.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Foundation Models (MFMs) excel at representing diverse rawmodalities (e.g., text, images, audio, videos, etc.). As recommender systemsincreasingly incorporate these modalities, leveraging MFMs to generate betterrepresentations has great potential. However, their application in sequentialrecommendation remains largely unexplored. This is primarily because mainstreamadaptation methods, such as Fine-Tuning and even Parameter-EfficientFine-Tuning (PEFT) techniques (e.g., Adapter and LoRA), incur highcomputational costs, especially when integrating multiple modality encoders,thus hindering research progress. As a result, it remains unclear whether wecan efficiently and effectively adapt multiple (&gt;2) MFMs for the sequentialrecommendation task.  To address this, we propose a plug-and-play Cross-modal Side Adapter Network(CROSSAN). Leveraging the fully decoupled side adapter-based paradigm, CROSSANachieves high efficiency while enabling cross-modal learning across diversemodalities. To optimize the final stage of multimodal fusion across diversemodalities, we adopt the Mixture of Modality Expert Fusion (MOMEF) mechanism.CROSSAN achieves superior performance on the public datasets for adapting fourfoundation models with raw modalities. Performance consistently improves asmore MFMs are adapted. We will release our code and datasets to facilitatefuture research.</description>
      <author>example@mail.com (Junchen Fu, Yongxin Ni, Joemon M. Jose, Ioannis Arapakis, Kaiwen Zheng, Youhua Li, Xuri Ge)</author>
      <guid isPermaLink="false">2504.10307v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ProtoGuard-guided PROPEL: Class-Aware Prototype Enhancement and Progressive Labeling for Incremental 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2504.01648v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D点云语义分割技术在现实场景中环境不断变化导致的灾难性遗忘问题，提出了ProtoGuard和PROPEL方法，显著提升了3D点云分割的mIoU值。&lt;h4&gt;背景&lt;/h4&gt;3D点云语义分割技术被广泛应用，但在实际环境中，由于环境不断变化，离线训练的分割模型可能会导致对先前类别的灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决离线训练的分割模型在现实场景中可能出现的灾难性遗忘问题，并提出有效的CIL方法来提高3D点云分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了ProtoGuard和PROPEL方法。ProtoGuard在基础类别训练阶段维护每个类别的几何和语义原型，并通过注意力机制将其组合成原型特征。PROPEL在新型类别训练阶段继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值提高了最多20.39%。&lt;h4&gt;结论&lt;/h4&gt;ProtoGuard和PROPEL方法能够有效解决3D点云语义分割中的灾难性遗忘问题，并显著提高分割性能。&lt;h4&gt;翻译&lt;/h4&gt;3D点云语义分割技术已被广泛应用。然而，在现实场景中，环境是不断演变的。因此，离线训练的分割模型可能会导致先前看到的类别的灾难性遗忘。类增量学习（CIL）旨在解决灾难性遗忘的问题。虽然点云很常见，但我们观察到不同类别之间存在高度相似性和不清晰的边界。同时，它们在类别分布上是不平衡的。这些问题导致了包括相似类别之间的误分类和长尾问题，这些问题在先前的CIL方法中尚未得到充分解决。因此，我们提出了ProtoGuard和PROPEL（伪标签的渐进式细化）。在基础类别训练阶段，ProtoGuard为每个类别维护几何和语义原型，这些原型通过注意力机制组合成原型特征。在新型类别训练阶段，PROPEL继承基础特征提取器和分类器，基于密度分布和语义相似性指导伪标签的传播和更新。大量的实验表明，我们的方法在S3DIS和ScanNet数据集上取得了显著的效果，在S3DIS数据集的5步CIL场景下，3D点云分割的mIoU值最多提高了20.39%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud semantic segmentation technology has been widely used.However, in real-world scenarios, the environment is evolving. Thus,offline-trained segmentation models may lead to catastrophic forgetting ofpreviously seen classes. Class-incremental learning (CIL) is designed toaddress the problem of catastrophic forgetting. While point clouds are common,we observe high similarity and unclear boundaries between different classes.Meanwhile, they are known to be imbalanced in class distribution. These lead toissues including misclassification between similar classes and the long-tailproblem, which have not been adequately addressed in previous CIL methods. Wethus propose ProtoGuard and PROPEL (Progressive Refinement Of PsEudo-Labels).In the base-class training phase, ProtoGuard maintains geometric and semanticprototypes for each class, which are combined into prototype features using anattention mechanism. In the novel-class training phase, PROPEL inherits thebase feature extractor and classifier, guiding pseudo-label propagation andupdates based on density distribution and semantic similarity. Extensiveexperiments show that our approach achieves remarkable results on both theS3DIS and ScanNet datasets, improving the mIoU of 3D point cloud segmentationby a maximum of 20.39% under the 5-step CIL scenario on S3DIS.</description>
      <author>example@mail.com (Haosheng Li, Yuecong Xu, Junjie Chen, Kemi Ding)</author>
      <guid isPermaLink="false">2504.01648v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction</title>
      <link>http://arxiv.org/abs/2504.10240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Data will be made available on request&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的电路连接预测框架GNN-ACLP，旨在解决现有电路连接预测方法面临的三个主要挑战：拓扑模式利用不足、数据稀缺和适应不同网表格式有限。&lt;h4&gt;背景&lt;/h4&gt;电路连接预测在自动化模拟电路设计中至关重要，但现有方法存在三个主要问题：1) 在电路图中拓扑模式的利用不足；2) 由于标注复杂导致数据稀缺；3) 对不同网表格式的适应性有限。&lt;h4&gt;目的&lt;/h4&gt;提出GNN-ACLP框架，通过引入创新方法来解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;1) 引入SEAL框架，实现端口级别的电路连接预测精度；2) 提出Netlist Babel Fish工具，利用检索增强生成（RAG）和大型语言模型（LLM）增强网表格式的兼容性；3) 构建SpiceNetlist数据集，包含775个标注电路，涵盖10种不同类别的组件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在SpiceNetlist数据集上，GNN-ACLP方法相较于现有方法提高了15.05%的准确率，在Image2Net数据集上提高了12.01%的准确率。&lt;h4&gt;结论&lt;/h4&gt;GNN-ACLP框架能够有效解决电路连接预测中的挑战，并显著提高预测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit link prediction identifying missing component connections fromincomplete netlists is crucial in automating analog circuit design. However,existing methods face three main challenges: 1) Insufficient use of topologicalpatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due tothe complexity of annotations hinders model generalization; 3) Limitedadaptability to various netlist formats. We propose GNN-ACLP, a Graph NeuralNetworks (GNNs) based framework featuring three innovations to tackle thesechallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributesfor Link Prediction) framework and achieve port-level accuracy in circuit linkprediction. Second, we propose Netlist Babel Fish, a netlist format conversiontool leveraging retrieval-augmented generation (RAG) with large language model(LLM) to enhance the compatibility of netlist formats. Finally, we constructSpiceNetlist, a comprehensive dataset that contains 775 annotated circuitsacross 10 different classes of components. The experimental results demonstratean improvement of 15.05% on the SpiceNetlist dataset and 12.01% on theImage2Net dataset over the existing approach.</description>
      <author>example@mail.com (Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Shuai Wang)</author>
      <guid isPermaLink="false">2504.10240v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling</title>
      <link>http://arxiv.org/abs/2504.09960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Camera-ready version for CVPRW 2025. Accepted for presentation at the  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops  (CVPRW 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于事件的眼睛跟踪技术在增强现实和人类-计算机交互中成为一个关键技术。为了解决现实世界中的挑战，如突发的眼睛运动和环境噪声，本研究提出了两个主要进展。&lt;h4&gt;背景&lt;/h4&gt;事件驱动的眼睛跟踪技术在增强现实和人类-计算机交互领域的重要性。&lt;h4&gt;目的&lt;/h4&gt;提高模型对现实世界挑战的鲁棒性，减少误差。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除。2. 提出KnightPupil混合架构，结合EfficientNet-B3骨干网络、双向GRU和线性时变状态空间模块。&lt;h4&gt;主要发现&lt;/h4&gt;1. 数据增强流程减少了12%的欧几里得距离误差。2. KnightPupil架构在CVPR 2025的3ET+基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;KnightPupil架构在AR/VR系统中的实际部署方面显示出其有效性，并为神经形态视觉的未来创新提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于事件的眼睛跟踪技术已成为增强现实和人类-计算机交互的关键技术。然而，现有方法难以应对现实世界的挑战，如突然的眼动和环境噪声。基于轻量级时空网络（一种针对边缘设备优化的因果架构）的效率，我们引入了两项关键进展。首先，一个鲁棒的数据增强流程，包括时间位移、空间翻转和事件删除，提高了模型的鲁棒性，在具有挑战性的样本上减少了12%的欧几里得距离误差（从1.70到1.61）。其次，我们提出了KnightPupil，一个结合EfficientNet-B3骨干网络用于空间特征提取、双向GRU用于上下文时序建模和线性时变状态空间模块以动态适应稀疏输入和噪声的混合架构。在CVPR 2025的3ET+基准测试中评估，我们的框架在事件驱动的眼睛跟踪挑战的私有测试集上实现了1.61的欧几里得距离，证明了其在AR/VR系统中的实际部署有效性，并为神经形态视觉的未来创新提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event-based eye tracking has become a pivotal technology for augmentedreality and human-computer interaction. Yet, existing methods struggle withreal-world challenges such as abrupt eye movements and environmental noise.Building on the efficiency of the Lightweight Spatiotemporal Network-a causalarchitecture optimized for edge devices-we introduce two key advancements.First, a robust data augmentation pipeline incorporating temporal shift,spatial flip, and event deletion improves model resilience, reducing Euclideandistance error by 12% (1.61 vs. 1.70 baseline) on challenging samples. Second,we propose KnightPupil, a hybrid architecture combining an EfficientNet-B3backbone for spatial feature extraction, a bidirectional GRU for contextualtemporal modeling, and a Linear Time-Varying State-Space Module to adapt tosparse inputs and noise dynamically. Evaluated on the 3ET+ benchmark, ourframework achieved 1.61 Euclidean distance on the private test set of theEvent-based Eye Tracking Challenge at CVPR 2025, demonstrating itseffectiveness for practical deployment in AR/VR systems while providing afoundation for future innovations in neuromorphic vision.</description>
      <author>example@mail.com (Hoang M. Truong, Vinh-Thuan Ly, Huy G. Tran, Thuan-Phat Nguyen, Tram T. Doan)</author>
      <guid isPermaLink="false">2504.09960v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Object Grounding via Hierarchical Contrastive Siamese Transformers</title>
      <link>http://arxiv.org/abs/2504.10048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为H-COST的算法，用于在3D场景中根据自然语言输入定位多个对象，通过对比增强Siamese Transformer框架增强了模型对复杂点云数据的处理能力。&lt;h4&gt;背景&lt;/h4&gt;以往的多对象定位研究主要集中在单对象定位上，而现实场景中往往需要定位多个对象。&lt;h4&gt;目的&lt;/h4&gt;解决多对象定位的挑战，提高复杂语言指令的理解能力。&lt;h4&gt;方法&lt;/h4&gt;采用分层处理策略，逐步细化对象定位。引入对比增强Siamese Transformer框架，其中一个辅助网络处理来自真实标签的稳健对象关系，指导并增强第二个网络（参考网络），该网络处理分割的点云数据。&lt;h4&gt;主要发现&lt;/h4&gt;H-COST算法在多对象定位基准测试中比现有最先进的方法提升了9.5%。&lt;h4&gt;结论&lt;/h4&gt;H-COST算法在处理复杂点云数据和多对象定位方面表现出色，为解决现实世界中的多对象定位问题提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object grounding in 3D scenes involves localizing multiple objectsbased on natural language input. While previous work has primarily focused onsingle-object grounding, real-world scenarios often demand the localization ofseveral objects. To tackle this challenge, we propose Hierarchical ContrastiveSiamese Transformers (H-COST), which employs a Hierarchical Processing strategyto progressively refine object localization, enhancing the understanding ofcomplex language instructions. Additionally, we introduce a Contrastive SiameseTransformer framework, where two networks with the identical structure areused: one auxiliary network processes robust object relations from ground-truthlabels to guide and enhance the second network, the reference network, whichoperates on segmented point-cloud data. This contrastive mechanism strengthensthe model' s semantic understanding and significantly enhances its ability toprocess complex point-cloud data. Our approach outperforms previousstate-of-the-art methods by 9.5% on challenging multi-object groundingbenchmarks.</description>
      <author>example@mail.com (Chengyi Du, Keyan Jin)</author>
      <guid isPermaLink="false">2504.10048v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning</title>
      <link>http://arxiv.org/abs/2504.09641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TinyLLaVA-Video-R1，一个小型视频推理模型，它通过强化学习在通用视频问答数据集上提高了推理能力，并展示了“啊哈时刻”的涌现特性。&lt;h4&gt;背景&lt;/h4&gt;目前，通过强化学习提高大型多模态模型推理能力的研究取得了进展，但这些研究大多基于高度推理密集型数据集，并使用大规模模型作为基础。&lt;h4&gt;目的&lt;/h4&gt;提出探索小型模型推理能力的重要性，并使模型能够在通用问答数据集上解释其推理过程。&lt;h4&gt;方法&lt;/h4&gt;提出TinyLLaVA-Video-R1，这是一个基于TinyLLaVA-Video的视频理解模型，该模型经过可追踪的训练，参数不超过4B，并在通用视频问答数据集上应用强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;TinyLLaVA-Video-R1在通用视频问答数据集上表现出显著的推理和思维能力提升，并展示了“啊哈时刻”的涌现特性。同时，分享了实验发现，为小型模型视频推理能力的研究提供实用见解。&lt;h4&gt;结论&lt;/h4&gt;TinyLLaVA-Video-R1证明了在小规模模型中探索推理能力的价值，并为未来研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;最近，通过强化学习提高大型多模态模型（LMMs）的推理能力取得了重大进展。然而，大多数现有工作都是基于高度推理密集型数据集，如数学和代码，研究人员通常选择大型模型作为基础。我们认为，对于计算资源有限的研究人员来说，探索小型模型的推理能力仍然具有价值。此外，使模型能够在通用问答数据集上解释其推理过程同样有意义。因此，我们提出了小型视频推理模型TinyLLaVA-Video-R1。基于TinyLLaVA-Video，这是一个参数不超过4B的可追踪训练视频理解模型，它不仅在使用强化学习后显著提高了在通用视频问答数据集上的推理和思维能力，还表现出“啊哈时刻”的涌现特性。此外，我们分享了一系列实验发现，旨在为未来探索小型模型视频推理（思考）能力提供实用见解。该模型可在https://github.com/ZhangXJ199/TinyLLaVA-Video-R1上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, improving the reasoning ability of large multimodal models (LMMs)through reinforcement learning has made great progress. However, most existingworks are based on highly reasoning-intensive datasets such as mathematics andcode, and researchers generally choose large-scale models as the foundation. Weargue that exploring small-scale models' reasoning capabilities remainsvaluable for researchers with limited computational resources. Moreover,enabling models to explain their reasoning processes on generalquestion-answering datasets is equally meaningful. Therefore, we present thesmall-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video,a traceably trained video understanding model with no more than 4B parameters,it not only demonstrates significantly improved reasoning and thinkingcapabilities after using reinforcement learning on general Video-QA datasets,but also exhibits the emergent characteristic of "aha moments". Furthermore, weshare a series of experimental findings, aiming to provide practical insightsfor future exploration of video reasoning (thinking) abilities in small-scalemodels. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.</description>
      <author>example@mail.com (Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang)</author>
      <guid isPermaLink="false">2504.09641v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification</title>
      <link>http://arxiv.org/abs/2504.09993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AimTS的预训练框架，用于时间序列分类任务，旨在解决现有方法在训练数据不足时准确率下降的问题。&lt;h4&gt;背景&lt;/h4&gt;现有时间序列分类方法主要在单一领域分别训练，当某些领域的训练样本不足时，准确性会下降。&lt;h4&gt;目的&lt;/h4&gt;提出AimTS框架，通过多源时间序列数据学习可泛化的表示，以提高时间序列分类的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;AimTS采用基于原型的高层对比学习方法，结合多种数据增强策略进行多源预训练。同时，引入图像模态补充结构信息，建立序列-图像对比学习，以增强泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AimTS在多源预训练后，在各种下游时间序列分类数据集上实现了良好的泛化性能，支持高效学习和少量样本学习。&lt;h4&gt;结论&lt;/h4&gt;AimTS是一种有效的时间序列分类预训练框架，能够提高模型在不同领域的泛化能力，适用于各种时间序列分类任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification (TSC) is an important task in time seriesanalysis. Existing TSC methods mainly train on each single domain separately,suffering from a degradation in accuracy when the samples for training areinsufficient in certain domains. The pre-training and fine-tuning paradigmprovides a promising direction for solving this problem. However, time seriesfrom different domains are substantially divergent, which challenges theeffective pre-training on multi-source data and the generalization ability ofpre-trained models. To handle this issue, we introduce Augmented Series andImage Contrastive Learning for Time Series Classification (AimTS), apre-training framework that learns generalizable representations frommulti-source time series data. We propose a two-level prototype-basedcontrastive learning method to effectively utilize various augmentations inmulti-source pre-training, which learns representations for TSC that can begeneralized to different domains. In addition, considering augmentations withinthe single time series modality are insufficient to fully addressclassification problems with distribution shift, we introduce the imagemodality to supplement structural information and establish a series-imagecontrastive learning to improve the generalization of the learnedrepresentations for TSC tasks. Extensive experiments show that aftermulti-source pre-training, AimTS achieves good generalization performance,enabling efficient learning and even few-shot learning on various downstreamTSC datasets.</description>
      <author>example@mail.com (Yuxuan Chen, Shanshan Huang, Yunyao Cheng, Peng Chen, Zhongwen Rao, Yang Shu, Bin Yang, Lujia Pan, Chenjuan Guo)</author>
      <guid isPermaLink="false">2504.09993v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Autonomous Microscopy for Scalable and Intelligent Characterization of 2D Materials</title>
      <link>http://arxiv.org/abs/2504.10281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为ATOMIC的自动实验系统，用于二维材料的自主表征，通过集成多种模型和算法，实现了无需额外训练的自动分析和图像识别。&lt;h4&gt;背景&lt;/h4&gt;原子尺度材料的表征通常需要经过长时间专业培训的专家，对于新发现的二维材料，即使是经过培训的专家也难以准确表征。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需大量训练数据集即可理解研究目标的全自动实验系统，以实现二维材料的零样本自主表征。&lt;h4&gt;方法&lt;/h4&gt;ATOMIC系统集成了视觉基础模型（如Segment Anything Model）、大型语言模型（如ChatGPT）、无监督聚类和拓扑分析，通过提示工程自动化显微镜控制、样品扫描、图像分割和智能分析。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在分析典型MoS2样品时，实现了99.7%的单层识别准确率，并能检测到人眼难以识别的晶界裂缝。此外，系统在各种条件下仍保持稳健的准确性。&lt;h4&gt;结论&lt;/h4&gt;ATOMIC系统通过集成基础模型实现了自主分析，建立了一种可扩展且数据高效的表征范式，从根本上改变了纳米尺度材料研究的方法。&lt;h4&gt;翻译&lt;/h4&gt;Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging when examining newly discovered materials such as two-dimensional (2D) structures. This bottleneck drives demand for fully autonomous experimentation systems capable of comprehending research objectives without requiring large training datasets. In this work, we present ATOMIC (Autonomous Technology for Optical Microscopy &amp; Intelligent Characterization), an end-to-end framework that integrates foundation models to enable fully autonomous, zero-shot characterization of 2D materials. Our system integrates the vision foundation model (i.e., Segment Anything Model), large language models (i.e., ChatGPT), unsupervised clustering, and topological analysis to automate microscope control, sample scanning, image segmentation, and intelligent analysis through prompt engineering, eliminating the need for additional training. When analyzing typical MoS2 samples, our approach achieves 99.7% segmentation accuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundary slits that are challenging to identify with human eyes. Furthermore, the system retains robust accuracy despite variable conditions including defocus, color temperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanical exfoliation. This work represents the implementation of foundation models to achieve autonomous analysis, establishing a scalable and data-efficient characterization paradigm that fundamentally transforms the approach to nanoscale materials research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Characterization of atomic-scale materials traditionally requires humanexperts with months to years of specialized training. Even for trained humanoperators, accurate and reliable characterization remains challenging whenexamining newly discovered materials such as two-dimensional (2D) structures.This bottleneck drives demand for fully autonomous experimentation systemscapable of comprehending research objectives without requiring large trainingdatasets. In this work, we present ATOMIC (Autonomous Technology for OpticalMicroscopy &amp; Intelligent Characterization), an end-to-end framework thatintegrates foundation models to enable fully autonomous, zero-shotcharacterization of 2D materials. Our system integrates the vision foundationmodel (i.e., Segment Anything Model), large language models (i.e., ChatGPT),unsupervised clustering, and topological analysis to automate microscopecontrol, sample scanning, image segmentation, and intelligent analysis throughprompt engineering, eliminating the need for additional training. Whenanalyzing typical MoS2 samples, our approach achieves 99.7% segmentationaccuracy for single layer identification, which is equivalent to that of humanexperts. In addition, the integrated model is able to detect grain boundaryslits that are challenging to identify with human eyes. Furthermore, the systemretains robust accuracy despite variable conditions including defocus, colortemperature fluctuations, and exposure variations. It is applicable to a broadspectrum of common 2D materials-including graphene, MoS2, WSe2, SnSe-regardlessof whether they were fabricated via chemical vapor deposition or mechanicalexfoliation. This work represents the implementation of foundation models toachieve autonomous analysis, establishing a scalable and data-efficientcharacterization paradigm that fundamentally transforms the approach tonanoscale materials research.</description>
      <author>example@mail.com (Jingyun Yang, Ruoyan Avery Yin, Chi Jiang, Yuepeng Hu, Xiaokai Zhu, Xingjian Hu, Sutharsika Kumar, Xiao Wang, Xiaohua Zhai, Keran Rong, Yunyue Zhu, Tianyi Zhang, Zongyou Yin, Jing Kong, Neil Zhenqiang Gong, Zhichu Ren, Haozhe Wang)</author>
      <guid isPermaLink="false">2504.10281v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Transfer Learning for Multi-Pass Fundus Image Restoration</title>
      <link>http://arxiv.org/abs/2504.10025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 12 figures including appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于渐进式迁移学习（PTL）的多次迭代图像质量恢复方法，用于改善糖尿病视网膜病变（DR）图像的质量，以支持更可靠的DR筛查。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是导致视力障碍的主要原因之一，早期通过眼底成像进行诊断对于有效治疗规划至关重要。然而，由于照明不足、噪声、模糊和其他运动伪影等因素，眼底图像质量差给DR筛查带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过PTL方法迭代增强退化眼底图像的质量，确保更可靠的DR筛查。&lt;h4&gt;方法&lt;/h4&gt;研究首先训练一个Cycle GAN模型来恢复低质量图像，然后通过PTL方法在最新恢复的输出上进行多次迭代恢复，以提高每次迭代的整体质量。该方法能够在不需要任何配对数据的情况下学习盲恢复，并通过利用渐进学习和微调策略来最小化失真并保留关键视网膜特征。&lt;h4&gt;主要发现&lt;/h4&gt;在DeepDRiD大型眼底成像数据集上进行的实验表明，PTL在多次迭代图像质量恢复方面具有最先进的性能，表明PTL是一种优于迭代图像质量恢复的先进方法。&lt;h4&gt;结论&lt;/h4&gt;PTL方法在多遍修复方面表现出色，有望成为迭代图像质量恢复的优选方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic retinopathy is a leading cause of vision impairment, making itsearly diagnosis through fundus imaging critical for effective treatmentplanning. However, the presence of poor quality fundus images caused by factorssuch as inadequate illumination, noise, blurring and other motion artifactsyields a significant challenge for accurate DR screening. In this study, wepropose progressive transfer learning for multi pass restoration to iterativelyenhance the quality of degraded fundus images, ensuring more reliable DRscreening. Unlike previous methods that often focus on a single passrestoration, multi pass restoration via PTL can achieve a superior blindrestoration performance that can even improve most of the good quality fundusimages in the dataset. Initially, a Cycle GAN model is trained to restore lowquality images, followed by PTL induced restoration passes over the latestrestored outputs to improve overall quality in each pass. The proposed methodcan learn blind restoration without requiring any paired data while surpassingits limitations by leveraging progressive learning and fine tuning strategiesto minimize distortions and preserve critical retinal features. To evaluatePTL's effectiveness on multi pass restoration, we conducted experiments onDeepDRiD, a large scale fundus imaging dataset specifically curated fordiabetic retinopathy detection. Our result demonstrates state of the artperformance, showcasing PTL's potential as a superior approach to iterativeimage quality restoration.</description>
      <author>example@mail.com (Uyen Phan, Ozer Can Devecioglu, Serkan Kiranyaz, Moncef Gabbouj)</author>
      <guid isPermaLink="false">2504.10025v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</title>
      <link>http://arxiv.org/abs/2504.09862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Radar-LLM的框架，利用大型语言模型（LLM）通过毫米波雷达进行人体运动理解，解决了毫米波雷达在语义理解上的挑战。&lt;h4&gt;背景&lt;/h4&gt;毫米波雷达在人体运动分析中提供隐私保护解决方案，但其稀疏点云对语义理解构成挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用毫米波雷达进行人体运动理解的方法，并实现隐私敏感应用中的运动理解。&lt;h4&gt;方法&lt;/h4&gt;1. 引入一个基于Aggregate VQ-VAE架构的运动引导雷达标记器，将时空点云编码为紧凑的语义标记；2. 建立雷达感知语言模型，在共享嵌入空间中实现雷达和文本之间的跨模态对齐；3. 提出一种基于物理感知的合成管道，从运动文本数据集中生成真实的雷达文本对。&lt;h4&gt;主要发现&lt;/h4&gt;Radar-LLM在合成和真实世界基准测试中实现了最先进的性能，能够将毫米波信号准确翻译成自然语言描述。&lt;h4&gt;结论&lt;/h4&gt;这一突破促进了在医疗保健和智能家居等隐私敏感应用中的全面运动理解。&lt;h4&gt;翻译&lt;/h4&gt;该框架能够将毫米波雷达信号转换为自然语言描述，为隐私敏感应用提供了有效的运动理解解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millimeter-wave radar provides a privacy-preserving solution for human motionanalysis, yet its sparse point clouds pose significant challenges for semanticunderstanding. We present Radar-LLM, the first framework that leverages largelanguage models (LLMs) for human motion understanding using millimeter-waveradar as the sensing modality. Our approach introduces two key innovations: (1)a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture thatincorporates deformable body templates and masked trajectory modeling to encodespatiotemporal point clouds into compact semantic tokens, and (2) a radar-awarelanguage model that establishes cross-modal alignment between radar and text ina shared embedding space. To address data scarcity, we introduce aphysics-aware synthesis pipeline that generates realistic radar-text pairs frommotion-text datasets. Extensive experiments demonstrate that Radar-LLM achievesstate-of-the-art performance across both synthetic and real-world benchmarks,enabling accurate translation of millimeter-wave signals to natural languagedescriptions. This breakthrough facilitates comprehensive motion understandingin privacy-sensitive applications like healthcare and smart homes. We willrelease the full implementation to support further research onhttps://inowlzy.github.io/RadarLLM/.</description>
      <author>example@mail.com (Zengyuan Lai, Jiarui Yang, Songpengcheng Xia, Lizhou Lin, Lan Sun, Renwen Wang, Jianran Liu, Qi Wu, Ling Pei)</author>
      <guid isPermaLink="false">2504.09862v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Beamform for Cooperative Localization and Communication: A Link Heterogeneous GNN-Based Approach</title>
      <link>http://arxiv.org/abs/2504.10060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于协同感知通信（CoISAC）系统联合波束成形的方法，旨在解决CoISAC波束成形设计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;集成感知和通信（ISAC）是下一代无线网络的关键使能技术，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站联合优化通信和感知性能来进一步增强这些能力。&lt;h4&gt;目的&lt;/h4&gt;针对CoISAC波束成形设计面临的系统异质性、大规模问题复杂性和对参数估计误差的敏感性等挑战，提出了一种新的解决方案。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种链路异构图神经网络（LHGNN）用于CoISAC系统的联合波束成形。LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，以捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明，所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地解决了CoISAC波束成形设计中的挑战，为CoISAC系统的性能提升提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：集成感知与通信（ISAC）已成为下一代无线网络的关键推动力，支持高精度定位和环境重建等高级应用。协同ISAC（CoISAC）通过多个基站协同优化通信和感知性能进一步增强了这些能力。然而，CoISAC波束成形设计面临着系统异质性、大规模问题复杂性和对参数估计误差敏感性的重大挑战。传统的基于深度学习的技术未能充分利用CoISAC系统的独特结构特性，从而限制了其增强系统性能的能力。为了解决这些挑战，我们提出了一种用于CoISAC系统联合波束成形的方法——链路异构图神经网络（LHGNN）。与传统的方案不同，LHGNN将通信和感知链路建模为异构节点，并将它们的交互建模为边，从而能够捕捉CoISAC系统的异质性和复杂交互。此外，还引入了图注意力机制，以动态调整节点和链路的重要性，提高对信道和位置估计误差的鲁棒性。数值结果证明了所提出的注意力增强的LHGNN在保持感知准确性的同时，在功率约束下实现了更高的通信速率，并且对通信信道和位置估计误差具有强鲁棒性。所提出的方法也表现出对通信信道和位置估计误差的强鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrated sensing and communication (ISAC) has emerged as a key enabler fornext-generation wireless networks, supporting advanced applications such ashigh-precision localization and environment reconstruction. Cooperative ISAC(CoISAC) further enhances these capabilities by enabling multiple base stations(BSs) to jointly optimize communication and sensing performance throughcoordination. However, CoISAC beamforming design faces significant challengesdue to system heterogeneity, large-scale problem complexity, and sensitivity toparameter estimation errors. Traditional deep learning-based techniques fail toexploit the unique structural characteristics of CoISAC systems, therebylimiting their ability to enhance system performance. To address thesechallenges, we propose a Link-Heterogeneous Graph Neural Network (LHGNN) forjoint beamforming in CoISAC systems. Unlike conventional approaches, LHGNNmodels communication and sensing links as heterogeneous nodes and theirinteractions as edges, enabling the capture of the heterogeneous nature andintricate interactions of CoISAC systems. Furthermore, a graph attentionmechanism is incorporated to dynamically adjust node and link importance,improving robustness to channel and position estimation errors. Numericalresults demonstrate that the proposed attention-enhanced LHGNN achievessuperior communication rates while maintaining sensing accuracy under powerconstraints. The proposed method also exhibits strong robustness tocommunication channel and position estimation error.</description>
      <author>example@mail.com (Lixiang Lian, Chuanqi Bai, Yihan Xu, Huanyu Dong, Rui Cheng, Shunqing Zhang)</author>
      <guid isPermaLink="false">2504.10060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Masked Autoencoder Self Pre-Training for Defect Detection in Microelectronics</title>
      <link>http://arxiv.org/abs/2504.10021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了微电子缺陷检测中，由于数据和标签成本导致卷积神经网络（CNN）依然被广泛应用，而Transformer架构较少使用的问题。&lt;h4&gt;背景&lt;/h4&gt;传统上，计算机视觉领域Transformer架构成为标准，但在微电子缺陷检测领域，由于数据和标签生成成本高，导致CNN依然占据主导地位。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种基于掩码自编码器（MAE）的视觉Transformer（ViT）预训练框架，以解决微电子缺陷检测中的数据稀疏问题。&lt;h4&gt;方法&lt;/h4&gt;作者提出对目标数据集进行自预训练，使用少于10,000张扫描声学显微镜（SAM）图像，这些图像通过瞬态热分析（TTA）进行标记。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与监督ViT、在自然图像数据集上预训练的ViT以及文献中的最先进CNN缺陷检测模型相比，该方法带来了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;自预训练的模型通过聚焦于缺陷相关特征，如焊料材料中的裂纹，提供了故障特定的特征表示，表明该方法在实际微电子缺陷检测中具有可行性。&lt;h4&gt;翻译&lt;/h4&gt;While in general computer vision, transformer-based architectures have quickly become the gold standard, microelectronics defect detection still heavily relies on convolutional neural networks (CNNs). We hypothesize that this is due to the fact that a) transformers have an increased need for data and b) labelled image generation procedures for microelectronics are costly, and labelled data is therefore sparse. Whereas in other domains, pre-training on large natural image datasets can mitigate this problem, in microelectronics transfer learning is hindered due to the dissimilarity of domain data and natural images. Therefore, we evaluate self pre-training, where models are pre-trained on the target dataset, rather than another dataset. We propose a vision transformer (ViT) pre-training framework for defect detection in microelectronics based on masked autoencoders (MAE). In MAE, a large share of image patches is masked and reconstructed by the model during pre-training. We perform pre-training and defect detection using a dataset of less than 10,000 scanning acoustic microscopy (SAM) images labelled using transient thermal analysis (TTA). Our experimental results show that our approach leads to substantial performance gains compared to a) supervised ViT, b) ViT pre-trained on natural image datasets, and c) state-of-the-art CNN-based defect detection models used in the literature. Additionally, interpretability analysis reveals that our self pre-trained models, in comparison to ViT baselines, correctly focus on defect-relevant features such as cracks in the solder material. This demonstrates that our approach yields fault-specific feature representations, making our self pre-trained models viable for real-world defect detection in microelectronics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whereas in general computer vision, transformer-based architectures havequickly become the gold standard, microelectronics defect detection stillheavily relies on convolutional neural networks (CNNs). We hypothesize thatthis is due to the fact that a) transformers have an increased need for dataand b) labelled image generation procedures for microelectronics are costly,and labelled data is therefore sparse. Whereas in other domains, pre-trainingon large natural image datasets can mitigate this problem, in microelectronicstransfer learning is hindered due to the dissimilarity of domain data andnatural images. Therefore, we evaluate self pre-training, where models arepre-trained on the target dataset, rather than another dataset. We propose avision transformer (ViT) pre-training framework for defect detection inmicroelectronics based on masked autoencoders (MAE). In MAE, a large share ofimage patches is masked and reconstructed by the model during pre-training. Weperform pre-training and defect detection using a dataset of less than 10.000scanning acoustic microscopy (SAM) images labelled using transient thermalanalysis (TTA). Our experimental results show that our approach leads tosubstantial performance gains compared to a) supervised ViT, b) ViT pre-trainedon natural image datasets, and c) state-of-the-art CNN-based defect detectionmodels used in the literature. Additionally, interpretability analysis revealsthat our self pre-trained models, in comparison to ViT baselines, correctlyfocus on defect-relevant features such as cracks in the solder material. Thisdemonstrates that our approach yields fault-specific feature representations,making our self pre-trained models viable for real-world defect detection inmicroelectronics.</description>
      <author>example@mail.com (Nikolai Röhrich, Alwin Hoffmann, Richard Nordsieck, Emilio Zarbali, Alireza Javanmardi)</author>
      <guid isPermaLink="false">2504.10021v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Representation Learning for Robust Gene Expression Modeling and Cancer Prognosis</title>
      <link>http://arxiv.org/abs/2504.09704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GexBERT是一种基于Transformer的自动编码器框架，用于基因表达数据的鲁棒性表示学习，在癌症研究中表现出色。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在自然语言和视觉任务中取得成功，但在基因表达分析中的应用受到数据稀疏性、高维度和缺失值的影响。&lt;h4&gt;目的&lt;/h4&gt;提出GexBERT，以解决基因表达数据分析中的挑战，并提高其在癌症研究中的应用。&lt;h4&gt;方法&lt;/h4&gt;GexBERT通过在大规模转录组图谱上进行预训练，学习上下文感知的基因嵌入，并使用掩码和恢复目标来捕捉数千个基因之间的共表达关系。&lt;h4&gt;主要发现&lt;/h4&gt;GexBERT在癌症研究中三个关键任务上表现出色：泛癌症分类、癌症特异性生存预测和缺失值填补。它提高了分类准确率，改善了生存预测，并在高缺失率下优于传统填补方法。此外，其基于注意力的可解释性揭示了具有生物学意义的基因模式。&lt;h4&gt;结论&lt;/h4&gt;GexBERT是一个可扩展且有效的基因表达建模工具，在基因覆盖有限或不完整的环境中具有转化潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models have achieved remarkable success in natural languageand vision tasks, but their application to gene expression analysis remainslimited due to data sparsity, high dimensionality, and missing values. Wepresent GexBERT, a transformer-based autoencoder framework for robustrepresentation learning of gene expression data. GexBERT learns context-awaregene embeddings by pretraining on large-scale transcriptomic profiles with amasking and restoration objective that captures co-expression relationshipsamong thousands of genes. We evaluate GexBERT across three critical tasks incancer research: pan-cancer classification, cancer-specific survivalprediction, and missing value imputation. GexBERT achieves state-of-the-artclassification accuracy from limited gene subsets, improves survival predictionby restoring expression of prognostic anchor genes, and outperformsconventional imputation methods under high missingness. Furthermore, itsattention-based interpretability reveals biologically meaningful gene patternsacross cancer types. These findings demonstrate the utility of GexBERT as ascalable and effective tool for gene expression modeling, with translationalpotential in settings where gene coverage is limited or incomplete.</description>
      <author>example@mail.com (Shuai Jiang, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2504.09704v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EthCluster: An Unsupervised Static Analysis Method for Ethereum Smart Contract</title>
      <link>http://arxiv.org/abs/2504.09977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了智能合约的设计问题，提出了一种利用无监督学习来识别以太坊智能合约Solidity源代码中的漏洞的方法。&lt;h4&gt;背景&lt;/h4&gt;设计不当的智能合约容易受到攻击，可能被攻击者利用漏洞窃取管理的虚拟货币。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来检测智能合约中的特定漏洞。&lt;h4&gt;方法&lt;/h4&gt;使用无监督学习训练模型，从实际漏洞样本中获取数据，包括SmartBugs Curated和SolidiFI Benchmark数据集，用于开发一种健壮的无监督静态分析方法。该方法使用聚类算法来识别异常，随后将这些异常分类为有漏洞的智能合约。&lt;h4&gt;主要发现&lt;/h4&gt;检测到了五种特定漏洞：重入性、访问控制、时间戳依赖、tx.origin和未检查的低级别调用。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，可以有效地识别和分类有漏洞的智能合约。&lt;h4&gt;翻译&lt;/h4&gt;Poorly designed smart contracts are particularly vulnerable, as they may allow attackers to exploit weaknesses and steal the virtual currency they manage. In this study, we train a model using unsupervised learning to identify vulnerabilities in the Solidity source code of Ethereum smart contracts. To address the challenges associated with real-world smart contracts, our training data is derived from actual vulnerability samples obtained from datasets such as SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us to develop a robust unsupervised static analysis method for detecting five specific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency, tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms to identify outliers, which are subsequently classified as vulnerable smart contracts.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Poorly designed smart contracts are particularly vulnerable, as they mayallow attackers to exploit weaknesses and steal the virtual currency theymanage. In this study, we train a model using unsupervised learning to identifyvulnerabilities in the Solidity source code of Ethereum smart contracts. Toaddress the challenges associated with real-world smart contracts, our trainingdata is derived from actual vulnerability samples obtained from datasets suchas SmartBugs Curated and the SolidiFI Benchmark. These datasets enable us todevelop a robust unsupervised static analysis method for detecting fivespecific vulnerabilities: Reentrancy, Access Control, Timestamp Dependency,tx.origin, and Unchecked Low-Level Calls. We employ clustering algorithms toidentify outliers, which are subsequently classified as vulnerable smartcontracts.</description>
      <author>example@mail.com (Hong-Sheng Huang, Jen-Yi Ho, Hao-Wen Chen, Hung-Min Sun)</author>
      <guid isPermaLink="false">2504.09977v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoAds for Fast-Paced Video Understanding: Where Opensource Foundation Models Beat GPT-4o &amp; Gemini-1.5 Pro</title>
      <link>http://arxiv.org/abs/2504.09282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了VideoAds，这是一个专门用于评估多模态大型语言模型（MLLMs）在广告视频上性能的数据集。该数据集包含经过精心挑选的广告视频和手动标注的多样化问题，涉及视觉发现、视频摘要和视觉推理三个核心任务。&lt;h4&gt;背景&lt;/h4&gt;广告视频由于其结构化的叙事和快速的场景转换，通常比同等长度的普通视频复杂得多，这对MLLMs提出了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;创建VideoAds数据集，以评估MLLMs在处理广告视频方面的性能。&lt;h4&gt;方法&lt;/h4&gt;VideoAds数据集包含复杂的广告视频和针对三个核心任务（视觉发现、视频摘要和视觉推理）的手动标注问题。还提出了一种定量方法来比较VideoAds与现有基准在视频复杂度方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;开源模型Qwen2.5-VL-72B在VideoAds上达到了73.35%的准确率，超过了GPT-4o（66.82%）和Gemini-1.5 Pro（69.66%）。在视频摘要和推理方面，两个专有模型落后于开源模型，但在视觉发现方面表现最佳。人类专家的准确率达到了94.27%。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，提高MLLMs的时间建模能力是必要的，并且VideoAds数据集可能成为未来研究理解需要高FPS采样的视频的关键基准。&lt;h4&gt;翻译&lt;/h4&gt;本文提出VideoAds数据集，旨在评估多模态大型语言模型在广告视频上的性能。数据集包含复杂广告视频和针对视觉发现、视频摘要和视觉推理的手动标注问题。实验发现，开源模型Qwen2.5-VL-72B在VideoAds上表现最佳，而人类专家的准确率高达94.27%。这强调了提升MLLMs时间建模能力的重要性，并指出VideoAds数据集作为理解高FPS采样视频的关键基准的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advertisement videos serve as a rich and valuable source of purpose-driveninformation, encompassing high-quality visual, textual, and contextual cuesdesigned to engage viewers. They are often more complex than general videos ofsimilar duration due to their structured narratives and rapid scenetransitions, posing significant challenges to multi-modal large language models(MLLMs). In this work, we introduce VideoAds, the first dataset tailored forbenchmarking the performance of MLLMs on advertisement videos. VideoAdscomprises well-curated advertisement videos with complex temporal structures,accompanied by \textbf{manually} annotated diverse questions across three coretasks: visual finding, video summary, and visual reasoning. We propose aquantitative measure to compare VideoAds against existing benchmarks in termsof video complexity. Through extensive experiments, we find thatQwen2.5-VL-72B, an opensource MLLM, achieves 73.35\% accuracy on VideoAds,outperforming GPT-4o (66.82\%) and Gemini-1.5 Pro (69.66\%); the twoproprietary models especially fall behind the opensource model in videosummarization and reasoning, but perform the best in visual finding. Notably,human experts easily achieve a remarkable accuracy of 94.27\%. These resultsunderscore the necessity of advancing MLLMs' temporal modeling capabilities andhighlight VideoAds as a potentially pivotal benchmark for future research inunderstanding video that requires high FPS sampling. The dataset and evaluationcode will be publicly available at https://videoadsbenchmark.netlify.app.</description>
      <author>example@mail.com (Zheyuan Zhang, Monica Dou, Linkai Peng, Hongyi Pan, Ulas Bagci, Boqing Gong)</author>
      <guid isPermaLink="false">2504.09282v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>IsoSEL: Isometric Structural Entropy Learning for Deep Graph Clustering in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2504.09970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE TPAMI, 33 pages, including technical appendix of 16  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的深度图聚类方法，旨在解决传统方法在处理不平衡图和识别少数群体时的局限性。&lt;h4&gt;背景&lt;/h4&gt;图聚类是机器学习中的一个长期研究主题。尽管深度学习方法在近年来取得了令人鼓舞的结果，但它们通常需要预先定义的聚类数量K，并且在处理不平衡图时，特别是在识别少数群体方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究一个既具有挑战性又实用的深度图聚类问题，即在不考虑现实中的不平衡性的情况下，不使用K值进行图聚类。&lt;h4&gt;方法&lt;/h4&gt;从信息理论的新视角（即结构信息）来解决这个问题。首先，建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。随后，提出了一种名为IsoSEL的深度图聚类框架，设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。&lt;h4&gt;主要发现&lt;/h4&gt;该方法理论上证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。&lt;h4&gt;结论&lt;/h4&gt;在五个基准数据集上的大量实验表明，IsoSEL的平均NMI（归一化互信息）比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图聚类是机器学习中的一个长期研究主题。近年来，深度学习方法取得了令人鼓舞的结果，但它们仍然需要预先定义的聚类数量K，并且通常在处理不平衡图时遇到困难，特别是在识别少数群体方面。这些局限性促使我们研究一个既具有挑战性又实用的难题：在不考虑现实中的不平衡性的情况下，不使用K值的深度图聚类。我们从信息理论（即结构信息）的新视角来解决这个问题。在文献中，结构信息在深度聚类中很少被触及，经典定义在离散形式主义中存在不足，忽略了节点属性，并表现出难以承受的复杂性。在本文中，我们首先建立了一种新的可微结构信息，将离散形式主义推广到连续领域，以便通过梯度反向传播创建最佳的分区树，揭示聚类结构。从理论上讲，我们证明了其在不要求K值的情况下进行聚类的能力，并在不平衡图中识别少数群体，同时将时间复杂度降低到与节点数量O(N)相关。随后，我们提出了一种名为IsoSEL的深度图聚类框架，其中我们设计了一种双曲神经网络来学习双曲空间洛伦兹模型中的分区树，并进一步进行了洛伦兹树对比学习，同时使用等距增强。结果，分区树通过互信息最大化结合了节点属性，而聚类分配则通过所提出的树对比学习得到细化。在五个基准数据集上的大量实验表明，IsoSEL的平均NMI比14个最近的基线高出+1.3%，证明了该方法的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph clustering is a longstanding topic in machine learning. In recentyears, deep learning methods have achieved encouraging results, but they stillrequire predefined cluster numbers K, and typically struggle with imbalancedgraphs, especially in identifying minority clusters. The limitations motivateus to study a challenging yet practical problem: deep graph clustering withoutK considering the imbalance in reality. We approach this problem from a freshperspective of information theory (i.e., structural information). In theliterature, structural information has rarely been touched in deep clustering,and the classic definition falls short in its discrete formulation, neglectingnode attributes and exhibiting prohibitive complexity. In this paper, we firstestablish a new Differentiable Structural Information, generalizing thediscrete formalism to continuous realm, so that the optimal partitioning tree,revealing the cluster structure, can be created by the gradientbackpropagation. Theoretically, we demonstrate its capability in clusteringwithout requiring K and identifying the minority clusters in imbalanced graphs,while reducing the time complexity to O(N) w.r.t. the number of nodes.Subsequently, we present a novel IsoSEL framework for deep graph clustering,where we design a hyperbolic neural network to learn the partitioning tree inthe Lorentz model of hyperbolic space, and further conduct Lorentz TreeContrastive Learning with isometric augmentation. As a result, the partitioningtree incorporates node attributes via mutual information maximization, whilethe cluster assignment is refined by the proposed tree contrastive learning.Extensive experiments on five benchmark datasets show the IsoSEL outperforms 14recent baselines by an average of +1.3% in NMI.</description>
      <author>example@mail.com (Li Sun, Zhenhao Huang, Yujie Wang, Hongbo Lv, Chunyang Liu, Hao Peng, Philip S. Yu)</author>
      <guid isPermaLink="false">2504.09970v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multi-task Learning Capability of Medical Generalist Foundation Model via Image-centric Multi-annotation Data</title>
      <link>http://arxiv.org/abs/2504.09967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为IMAX的图像中心多标注X射线数据集，旨在通过数据构建层面增强医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;背景&lt;/h4&gt;医疗通用基础模型的出现改变了传统的特定任务模型开发范式，但近期进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。&lt;h4&gt;目的&lt;/h4&gt;提出IMAX数据集，旨在提升医疗多模态大型语言模型的多任务学习能力。&lt;h4&gt;方法&lt;/h4&gt;IMAX具有高质量的数据整理，包含超过354K条适用于多种医疗任务的数据条目。每个X射线图像都与平均4.10个任务和7.46个训练条目相关联。与DMAX相比，IMAX在七个开源最先进的医疗MLLMs上展现出显著的性能提升。同时，研究了IMAX和DMAX训练过程中的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性，并提出了基于DMAX的优化训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;IMAX在七个开源最先进的医疗MLLMs上展现了3.20%到21.05%的显著多任务平均性能提升。IMAX和DMAX训练过程中表现出不同的统计模式，优化动态与多任务性能之间存在潜在相关性。&lt;h4&gt;结论&lt;/h4&gt;IMAX数据集能够有效提升医疗多模态大型语言模型的多任务学习能力，并通过优化训练策略解决获取高质量IMAX数据的实际困境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：医疗通用基础模型的出现颠覆了传统的特定任务模型开发范式，旨在通过在大规模医疗数据集上进行联合训练更好地处理多个任务。然而，近期的进展过于强调简单数据扩展或架构组件增强，而忽视了从数据中心的视角重新审视多任务学习。关键的是，简单地汇总现有数据资源会导致图像任务对齐分散，无法培养全面图像理解或与多维图像解释的临床需求相一致。在本文中，我们介绍了图像中心的多标注X射线数据集（IMAX），这是第一次从数据构建层面尝试增强医疗多模态大型语言模型（MLLMs）的多任务学习能力。具体来说，IMAX具有以下特点：1）高质量的数据整理。包含适用于七种不同医疗任务的综合数据集，超过354K条条目。2）图像中心的密集标注。每个X射线图像与平均4.10个任务和7.46个训练条目相关联，确保每张图像的多任务表示丰富性。与通用的分散多标注X射线数据集（DMAX）相比，IMAX在七个开源最先进的医疗MLLMs上始终显示出3.20%到21.05%的显著多任务平均性能提升。此外，我们研究了IMAX和DMAX训练过程中表现出的统计模式差异，探讨了优化动态与多任务性能之间的潜在相关性。最后，利用IMAX数据构建的核心概念，我们提出了一种基于DMAX的优化训练策略，以缓解在实际场景中获取高质量IMAX数据的困境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of medical generalist foundation models has revolutionizedconventional task-specific model development paradigms, aiming to better handlemultiple tasks through joint training on large-scale medical datasets. However,recent advances prioritize simple data scaling or architectural componentenhancement, while neglecting to re-examine multi-task learning from adata-centric perspective. Critically, simply aggregating existing dataresources leads to decentralized image-task alignment, which fails to cultivatecomprehensive image understanding or align with clinical needs formulti-dimensional image interpretation. In this paper, we introduce theimage-centric multi-annotation X-ray dataset (IMAX), the first attempt toenhance the multi-task learning capabilities of medical multi-modal largelanguage models (MLLMs) from the data construction level. To be specific, IMAXis featured from the following attributes: 1) High-quality data curation. Acomprehensive collection of more than 354K entries applicable to sevendifferent medical tasks. 2) Image-centric dense annotation. Each X-ray image isassociated with an average of 4.10 tasks and 7.46 training entries, ensuringmulti-task representation richness per image. Compared to the generaldecentralized multi-annotation X-ray dataset (DMAX), IMAX consistentlydemonstrates significant multi-task average performance gains ranging from3.20% to 21.05% across seven open-source state-of-the-art medical MLLMs.Moreover, we investigate differences in statistical patterns exhibited by IMAXand DMAX training processes, exploring potential correlations betweenoptimization dynamics and multi-task performance. Finally, leveraging the coreconcept of IMAX data construction, we propose an optimized DMAX-based trainingstrategy to alleviate the dilemma of obtaining high-quality IMAX data inpractical scenarios.</description>
      <author>example@mail.com (Xun Zhu, Fanbin Mo, Zheng Zhang, Jiaxi Wang, Yiming Shi, Ming Wu, Chuang Zhang, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2504.09967v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>3D CoCa: Contrastive Learners are 3D Captioners</title>
      <link>http://arxiv.org/abs/2504.09518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为3D CoCa的3D场景描述方法，通过结合对比视觉-语言学习和3D字幕生成，有效描述3D场景内容。&lt;h4&gt;背景&lt;/h4&gt;由于点云的稀疏性和现有方法的跨模态对齐较弱，3D场景描述在自然语言中仍然是一个高度挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的统一框架，以解决3D场景描述中的挑战。&lt;h4&gt;方法&lt;/h4&gt;3D CoCa利用冻结的CLIP视觉-语言骨干网络提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。&lt;h4&gt;主要发现&lt;/h4&gt;与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。&lt;h4&gt;结论&lt;/h4&gt;在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。&lt;h4&gt;翻译&lt;/h4&gt;3D字幕描述，旨在用自然语言描述3D场景的内容，由于点云固有的稀疏性和现有方法中存在的弱跨模态对齐，这仍然是一个高度具有挑战性的任务。为了解决这些挑战，我们提出了一种名为3D CoCa的新颖统一框架，该框架无缝地将对比视觉-语言学习与3D字幕生成结合到一个架构中。我们的方法利用一个冻结的CLIP视觉-语言骨干网络来提供丰富的语义先验，一个空间感知的3D场景编码器来捕获几何上下文，以及一个多模态解码器来生成描述性字幕。与依赖于显式物体提议的前两阶段方法不同，3D CoCa在共享特征空间中联合优化对比和字幕生成目标，消除了对外部检测器或手工提议的需求。这种联合训练范式通过对齐3D和文本表示，实现了更强的空间推理和更丰富的语义基础。在ScanRefer和Nr3D基准测试上，3D CoCa在CIDEr指标上分别比现有最佳方法提高了10.2%和5.76%，0.5IoU。代码可在https://github.com/AIGeeksGroup/3DCoCa上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D captioning, which aims to describe the content of 3D scenes in naturallanguage, remains highly challenging due to the inherent sparsity of pointclouds and weak cross-modal alignment in existing methods. To address thesechallenges, we propose 3D CoCa, a novel unified framework that seamlesslycombines contrastive vision-language learning with 3D caption generation in asingle architecture. Our approach leverages a frozen CLIP vision-languagebackbone to provide rich semantic priors, a spatially-aware 3D scene encoder tocapture geometric context, and a multi-modal decoder to generate descriptivecaptions. Unlike prior two-stage methods that rely on explicit objectproposals, 3D CoCa jointly optimizes contrastive and captioning objectives in ashared feature space, eliminating the need for external detectors orhandcrafted proposals. This joint training paradigm yields stronger spatialreasoning and richer semantic grounding by aligning 3D and textualrepresentations. Extensive experiments on the ScanRefer and Nr3D benchmarksdemonstrate that 3D CoCa significantly outperforms current state-of-the-arts by10.2% and 5.76% in CIDEr at 0.5IoU, respectively. Code will be available athttps://github.com/AIGeeksGroup/3DCoCa.</description>
      <author>example@mail.com (Ting Huang, Zeyu Zhang, Yemin Wang, Hao Tang)</author>
      <guid isPermaLink="false">2504.09518v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>OVERLORD: Ultimate Scaling of DataLoader for Multi-Source Large Foundation Model Training</title>
      <link>http://arxiv.org/abs/2504.09844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了现代大型基础模型（LFMs）训练框架中的数据并行范式和数据加载器，分析了其面临的挑战，并提出了一种名为OVERLORD的工业级分布式数据加载架构以解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;现代框架使用数据加载器进行数据并行训练，这种设计简单但存在两个基本挑战：工作负载不平衡和资源消耗问题。&lt;h4&gt;目的&lt;/h4&gt;提高大型基础模型的训练效率和资源利用率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为OVERLORD的分布式数据加载架构，包含以下三个创新点：集中式和声明式的数据平面、分角色的源加载器和数据构造者、以及具有差异检查点的影子加载器。&lt;h4&gt;主要发现&lt;/h4&gt;OVERLORD在多千GPU的生产集群上实现了以下效果：4.5倍的端到端训练吞吐量提升，CPU内存使用量至少减少了3.6倍。&lt;h4&gt;结论&lt;/h4&gt;OVERLORD是一种有效的解决方案，能够显著提升大型基础模型的训练效率和资源利用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern frameworks for training large foundation models (LFMs) employ dataloaders in a data parallel paradigm. While this design offers implementationsimplicity, it introduces two fundamental challenges. First, due to thequadratic computational complexity of the attention operator, the non-uniformsample distribution over data-parallel ranks leads to a significant workloadimbalance among loaders, which degrades the training efficiency. This paradigmalso impedes the implementation of data mixing algorithms (e.g., curriculumlearning) over different datasets. Second, to acquire a broad range ofcapability, LFMs training ingests data from diverse sources, each with distinctfile access states. Colocating massive datasets within loader instances caneasily exceed local pod memory capacity. Additionally, heavy sources withhigher transformation latency require larger worker pools, further exacerbatingmemory consumption.  We present OVERLORD, an industrial-grade distributed data loadingarchitecture with three innovations: (1) A centralized and declarative dataplane, which facilitates elastic data orchestration strategy, such aslong-short context, multimodal, and curriculum learning; (2) Disaggregatedmultisource preprocessing through role-specific actors, i.e., Source Loadersand Data Constructors, leveraging autoscaling for Source Loaders towardsheterogeneous and evolving source preprocessing cost; (3) Shadow Loaders withdifferential checkpointing for uninterrupted fault recovery. Deployed onproduction clusters scaling to multi-thousand GPU, OVERLORD achieves: (1) 4.5xend-to-end training throughput improvement, (2) a minimum 3.6x reduction in CPUmemory usage, with further improvements to be added in later experiments.</description>
      <author>example@mail.com (Juntao Zhao, Qi Lu, Wei Jia, Borui Wan, Lei Zuo, Junda Feng, Jianyu Jiang, Yangrui Chen, Shuaishuai Cao, Jialing He, Kaihua Jiang, Yuanzhe Hu, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu)</author>
      <guid isPermaLink="false">2504.09844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>COUNTER: Cluster GCN based Energy Efficient Resource Management for Sustainable Cloud Computing Environments</title>
      <link>http://arxiv.org/abs/2504.09995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint version accepted at IEEE ICDCS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为COUNTER的模型，用于可持续的云资源管理，通过集成集群图神经网络在模拟云环境中评估，旨在减少能源消耗并保持服务质量参数。&lt;h4&gt;背景&lt;/h4&gt;云计算提供了灵活的IT应用开发环境，但大型数据中心因信息通信技术组件而消耗大量电力，随着大型人工智能模型的部署增加，这一问题更加严重，对全球环境产生重大影响。&lt;h4&gt;目的&lt;/h4&gt;提出COUNTER模型，旨在减少云计算中的能源消耗，同时保持服务质量。&lt;h4&gt;方法&lt;/h4&gt;COUNTER模型与集群图神经网络集成，并在模拟云环境中进行评估，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与HUNTER模型相比，COUNTER模型在资源利用率、能源消耗和成本效益方面均有改进。&lt;h4&gt;结论&lt;/h4&gt;COUNTER模型为可持续的云资源管理提供了一种有效的方法，有助于减少能源消耗并提高云服务的效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：云计算，得益于信息技术的普及，为IT应用的开发提供了一个基础环境，为企业提供了几乎无限的、按使用付费的计算资源。然而，由于信息通信技术（ICT）组件，云计算服务托管的大型数据中心每年消耗大量的电力。这一问题因大型人工智能（AI）模型的增加部署而加剧，这些模型通常依赖于分布式数据中心，从而对全球环境产生重大影响。本研究提出了一种名为COUNTER的模型，旨在实现可持续的云资源管理。COUNTER与集群图神经网络集成，并在模拟云环境中进行评估，旨在在保持服务质量参数的同时减少能源消耗。实验结果表明，与基于门控图神经网络的、旨在实现云计算碳中性的HUNTER基线模型相比，COUNTER在资源利用率、能源消耗和成本效益方面均有改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cloud computing, thanks to the pervasiveness of information technologies,provides a foundational environment for developing IT applications, offeringorganizations virtually unlimited and flexible computing resources on apay-per-use basis. However, the large data centres where cloud computingservices are hosted consume significant amounts of electricity annually due toInformation and Communication Technology (ICT) components. This issue isexacerbated by the increasing deployment of large artificial intelligence (AI)models, which often rely on distributed data centres, thereby significantlyimpacting the global environment. This study proposes the COUNTER model,designed for sustainable cloud resource management. COUNTER is integrated withcluster graph neural networks and evaluated in a simulated cloud environment,aiming to reduce energy consumption while maintaining quality of serviceparameters. Experimental results demonstrate improvements in resourceutilisation, energy consumption, and cost effectiveness compared to thebaseline model, HUNTER, which employs a gated graph neural network aimed atachieving carbon neutrality in cloud computing for modern ICT systems.</description>
      <author>example@mail.com (Han Wang, Sukhpal Singh Gill, Steve Uhlig)</author>
      <guid isPermaLink="false">2504.09995v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Causal integration of chemical structures improves representations of microscopy images for morphological profiling</title>
      <link>http://arxiv.org/abs/2504.09544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MICON（分子-图像对比学习）框架，该框架通过将化学化合物作为诱导细胞表型反事实变换的治疗方法，在自我监督预训练中提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;背景&lt;/h4&gt;尽管许多高通量显微镜屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出，但大多数当前方法仅从图像中学习。&lt;h4&gt;目的&lt;/h4&gt;研究假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。&lt;h4&gt;方法&lt;/h4&gt;提出了MICON框架，该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。&lt;h4&gt;主要发现&lt;/h4&gt;MICON在识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。&lt;h4&gt;结论&lt;/h4&gt;将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。这表明了形态分析中表示学习的新方向，即方法应明确考虑显微镜筛选数据的模态性质。&lt;h4&gt;翻译&lt;/h4&gt;最近，自我监督深度学习在量化高通量显微镜屏幕中的细胞形态变化（称为形态分析）方面取得了进展。然而，大多数当前方法仅从图像中学习，尽管许多屏幕本质上是多模态的，因为它们涉及化学或遗传扰动以及基于图像的读出。我们假设在自我监督预训练期间结合化学化合物结构可以提高高通量显微镜屏幕中图像的学习表示。我们引入了一个表示学习框架，MICON（分子-图像对比学习），该框架将化学化合物建模为诱导细胞表型反事实变换的治疗方法。MICON在需要识别药物在独立重复和数据生成中心之间可重复效应的挑战性评估环境中，显著优于CellProfiler和现有的基于深度学习的表示学习方法。我们证明，将化学化合物信息纳入学习过程可以在评估环境中提供一致的改进，并且将化合物在因果框架中特别建模为治疗方法，优于直接在单一表示空间中对齐图像和化合物的方法。我们的发现指向了形态分析中表示学习的新方向，表明方法应明确考虑显微镜筛选数据的模态性质。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in self-supervised deep learning have improved our ability toquantify cellular morphological changes in high-throughput microscopy screens,a process known as morphological profiling. However, most current methods onlylearn from images, despite many screens being inherently multimodal, as theyinvolve both a chemical or genetic perturbation as well as an image-basedreadout. We hypothesized that incorporating chemical compound structure duringself-supervised pre-training could improve learned representations of images inhigh-throughput microscopy screens. We introduce a representation learningframework, MICON (Molecular-Image Contrastive Learning), that models chemicalcompounds as treatments that induce counterfactual transformations of cellphenotypes. MICON significantly outperforms classical hand-crafted featuressuch as CellProfiler and existing deep-learning-based representation learningmethods in challenging evaluation settings where models must identifyreproducible effects of drugs across independent replicates and data-generatingcenters. We demonstrate that incorporating chemical compound information intothe learning process provides consistent improvements in our evaluation settingand that modeling compounds specifically as treatments in a causal frameworkoutperforms approaches that directly align images and compounds in a singlerepresentation space. Our findings point to a new direction for representationlearning in morphological profiling, suggesting that methods should explicitlyaccount for the multimodal nature of microscopy screening data.</description>
      <author>example@mail.com (Yemin Yu, Neil Tenenholtz, Lester Mackey, Ying Wei, David Alvarez-Melis, Ava P. Amini, Alex X. Lu)</author>
      <guid isPermaLink="false">2504.09544v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Comorbidity-Informed Transfer Learning for Neuro-developmental Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2504.09463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Comorbidity-Informed Transfer Learning（CITL）的框架，用于通过fMRI诊断神经发育障碍，以提高深度学习辅助诊断（CAD）的准确性。&lt;h4&gt;背景&lt;/h4&gt;神经发育障碍表现为认知、沟通、行为和适应性的功能障碍，而基于深度学习的CAD可以缓解神经影像学方面的医疗资源压力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效诊断神经发育障碍的CAD方法，特别是在fMRI数据上。&lt;h4&gt;方法&lt;/h4&gt;CITL框架结合了迁移学习和伪标签技术，去除fMRI时间域中的干扰模式，并使用编码器-解码器架构生成新的表示。这些新表示在结构简单的分类网络中进行训练，以获得CAD模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CITL在检测自闭症谱系障碍和注意力缺陷多动障碍方面分别达到了76.32%和73.15%的准确性，优于现有的相关迁移学习工作。&lt;h4&gt;结论&lt;/h4&gt;CITL框架在神经发育障碍的诊断中具有竞争力，并提供了跨学科的新视角。&lt;h4&gt;翻译&lt;/h4&gt;Neuro-developmental disorders are manifested as dysfunctions in cognition, communication, behavior and adaptability, and deep learning-based computer-aided diagnosis (CAD) can alleviate the increasingly strained healthcare resources on neuroimaging. However, neuroimaging such as fMRI contains complex spatio-temporal features, which makes the corresponding representations susceptible to a variety of distractions, thus leading to less effective in CAD. For the first time, we present a Comorbidity-Informed Transfer Learning (CITL) framework for diagnosing neuro-developmental disorders using fMRI. In CITL, a new reinforced representation generation network is proposed, which first combines transfer learning with pseudo-labelling to remove interfering patterns from the temporal domain of fMRI and generates new representations using encoder-decoder architecture. The new representations are then trained in an architecturally simple classification network to obtain CAD model. In particular, the framework fully considers the comorbidity mechanisms of neuro-developmental disorders and effectively integrates them with semi-supervised learning and transfer learning, providing new perspectives on interdisciplinary. Experimental results demonstrate that CITL achieves competitive accuracies of 76.32% and 73.15% for detecting autism spectrum disorder and attention deficit hyperactivity disorder, respectively, which outperforms existing related transfer learning work for 7.2% and 0.5% respectively.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-developmental disorders are manifested as dysfunctions in cognition,communication, behaviour and adaptability, and deep learning-basedcomputer-aided diagnosis (CAD) can alleviate the increasingly strainedhealthcare resources on neuroimaging. However, neuroimaging such as fMRIcontains complex spatio-temporal features, which makes the correspondingrepresentations susceptible to a variety of distractions, thus leading to lesseffective in CAD. For the first time, we present a Comorbidity-InformedTransfer Learning(CITL) framework for diagnosing neuro-developmental disordersusing fMRI. In CITL, a new reinforced representation generation network isproposed, which first combines transfer learning with pseudo-labelling toremove interfering patterns from the temporal domain of fMRI and generates newrepresentations using encoder-decoder architecture. The new representations arethen trained in an architecturally simple classification network to obtain CADmodel. In particular, the framework fully considers the comorbidity mechanismsof neuro-developmental disorders and effectively integrates them withsemi-supervised learning and transfer learning, providing new perspectives oninterdisciplinary. Experimental results demonstrate that CITL achievescompetitive accuracies of 76.32% and 73.15% for detecting autism spectrumdisorder and attention deficit hyperactivity disorder, respectively, whichoutperforms existing related transfer learning work for 7.2% and 0.5%respectively.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Jie Xiang, Xiaobo Liu, Jintai Chen)</author>
      <guid isPermaLink="false">2504.09463v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>NetTAG: A Multimodal RTL-and-Layout-Aligned Netlist Foundation Model via Text-Attributed Graph</title>
      <link>http://arxiv.org/abs/2504.09260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Design Automation Conference (DAC), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NetTAG是一种融合门语义与图结构的基础模型，用于网表表示学习，在电子设计自动化（EDA）领域有显著潜力。&lt;h4&gt;背景&lt;/h4&gt;电路表示学习在推进电子设计自动化（EDA）方面显示出前景，通过捕捉电路的结构和功能特性来处理各种任务。&lt;h4&gt;目的&lt;/h4&gt;为了提升网表表示学习，NetTAG旨在融合门语义与图结构，处理多样化的门类型，并支持多种功能和物理任务。&lt;h4&gt;方法&lt;/h4&gt;NetTAG将网表构造成文本属性图，门由符号逻辑表达式注解，物理特性作为文本属性。其多模态架构结合了基于LLM的文本编码器（用于门语义）和图变换器（用于全局结构）。通过门和图的自监督目标预训练，并与RTL和布局阶段对齐，NetTAG捕捉了电路的内在特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，NetTAG在四个功能性和物理任务上持续优于每种特定任务的方法，并超越了最先进的AIG编码器，展示了其多功能性。&lt;h4&gt;结论&lt;/h4&gt;NetTAG在电子设计自动化领域展现出强大的应用潜力，特别是在网表表示学习方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit representation learning has shown promise in advancing ElectronicDesign Automation (EDA) by capturing structural and functional circuitproperties for various tasks. Existing pre-trained solutions rely on graphlearning with complex functional supervision, such as truth table simulation.However, they only handle simple and-inverter graphs (AIGs), struggling tofully encode other complex gate functionalities. While large language models(LLMs) excel at functional understanding, they lack the structural awarenessfor flattened netlists. To advance netlist representation learning, we presentNetTAG, a netlist foundation model that fuses gate semantics with graphstructure, handling diverse gate types and supporting a variety of functionaland physical tasks. Moving beyond existing graph-only methods, NetTAGformulates netlists as text-attributed graphs, with gates annotated by symboliclogic expressions and physical characteristics as text attributes. Itsmultimodal architecture combines an LLM-based text encoder for gate semanticsand a graph transformer for global structure. Pre-trained with gate and graphself-supervised objectives and aligned with RTL and layout stages, NetTAGcaptures comprehensive circuit intrinsics. Experimental results show thatNetTAG consistently outperforms each task-specific method on four largelydifferent functional and physical tasks and surpasses state-of-the-art AIGencoders, demonstrating its versatility.</description>
      <author>example@mail.com (Wenji Fang, Wenkai Li, Shang Liu, Yao Lu, Hongce Zhang, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09260v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Psychological Health Knowledge-Enhanced LLM-based Social Network Crisis Intervention Text Transfer Recognition Method</title>
      <link>http://arxiv.org/abs/2504.07983v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的文本传输识别方法，用于社交网络危机干预，该方法增强了特定领域的心理健康知识。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体平台上心理健康危机的普遍增加，识别和预防潜在伤害已成为一项紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种多层次的框架，该框架结合了使用BERT的迁移学习，并整合了心理健康知识、情感分析和行为预测技术，以提高危机检测的准确性和对细微情绪和语境变化的敏感性。&lt;h4&gt;方法&lt;/h4&gt;该方法包括一个基于真实世界事件社交媒体数据集训练的危机标注工具，使模型能够检测微妙的情感线索和识别心理危机。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在危机检测准确性方面优于传统模型，并且对细微的情感和语境变化表现出更高的敏感性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法对于识别和预防社交媒体平台上的心理健康危机具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the prevalence of mental health crises increases on social mediaplatforms, identifying and preventing potential harm has become an urgentchallenge. This study introduces a large language model (LLM)-based texttransfer recognition method for social network crisis intervention, enhancedwith domain-specific mental health knowledge. We propose a multi-levelframework that incorporates transfer learning using BERT, and integrates mentalhealth knowledge, sentiment analysis, and behavior prediction techniques. Theframework includes a crisis annotation tool trained on social media datasetsfrom real-world events, enabling the model to detect nuanced emotional cues andidentify psychological crises. Experimental results show that the proposedmethod outperforms traditional models in crisis detection accuracy and exhibitsgreater sensitivity to subtle emotional and contextual variations.</description>
      <author>example@mail.com (Shurui Wu, Xinyi Huang, Dingxin Lu)</author>
      <guid isPermaLink="false">2504.07983v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Confounding Factors-Inhibition Adversarial Learning Framework for Multi-site fMRI Mental Disorder Identification</title>
      <link>http://arxiv.org/abs/2504.09179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MSalNET的新型多站点对抗学习网络，用于基于fMRI的脑部疾病检测。&lt;h4&gt;背景&lt;/h4&gt;fMRI数据集的异质性通常归因于扫描程序的不同、混杂效应的存在以及多个站点之间的群体多样性，这些因素影响了表示学习和分类过程的效率。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了一种新的多站点对抗学习网络（MSalNET）来提高fMRI基于脑部疾病的检测效果。&lt;h4&gt;方法&lt;/h4&gt;首先，引入了一个具有节点信息组装（NIA）机制的表现学习模块，以更好地从功能连接（FC）中提取特征。其次，为了在不同站点之间泛化特征，提出了一种站点级特征提取模块，该模块可以从单个FC数据中学习，避免了额外的先验信息。最后，提出了一种对抗学习网络，通过引入一个新颖的损失函数来平衡个体分类和站点回归任务之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;在ABIDE和ADHD-200数据集上评估了该方法，结果表明，与相关算法相比，该方法在ABIDE和ADHD-200数据集上分别达到了75.56和68.92的准确率。此外，站点回归的结果表明，该方法从数据驱动的角度减少了站点之间的变异性。NIA揭示的最具判别性的脑区与统计发现一致，在一定程度上揭示了深度学习的‘黑盒’。&lt;h4&gt;结论&lt;/h4&gt;MSalNET在提高fMRI基于脑部疾病的检测性能方面表现出色，同时减少了站点间的数据变异性，有助于揭示深度学习的内部机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In open data sets of functional magnetic resonance imaging (fMRI), theheterogeneity of the data is typically attributed to a combination of factors,including differences in scanning procedures, the presence of confoundingeffects, and population diversities between multiple sites. These factorscontribute to the diminished effectiveness of representation learning, which inturn affects the overall efficacy of subsequent classification procedures. Toaddress these limitations, we propose a novel multi-site adversarial learningnetwork (MSalNET) for fMRI-based mental disorder detection. Firstly, arepresentation learning module is introduced with a node information assembly(NIA) mechanism to better extract features from functional connectivity (FC).This mechanism aggregates edge information from both horizontal and verticaldirections, effectively assembling node information. Secondly, to generalizethe feature across sites, we proposed a site-level feature extraction modulethat can learn from individual FC data, which circumvents additional priorinformation. Lastly, an adversarial learning network is proposed as a means ofbalancing the trade-off between individual classification and site regressiontasks, with the introduction of a novel loss function. The proposed method wasevaluated on two multi-site fMRI datasets, i.e., Autism Brain Imaging DataExchange (ABIDE) and ADHD-200. The results indicate that the proposed methodachieves a better performance than other related algorithms with the accuracyof 75.56 and 68.92 in ABIDE and ADHD-200 datasets, respectively. Furthermore,the result of the site regression indicates that the proposed method reducessite variability from a data-driven perspective. The most discriminative brainregions revealed by NIA are consistent with statistical findings, uncoveringthe "black box" of deep learning to a certain extent.</description>
      <author>example@mail.com (Xin Wen, Shijie Guo, Wenbo Ning, Rui Cao, Yan Niu, Bin Wan, Peng Wei, Xiaobo Liu, Jie Xiang)</author>
      <guid isPermaLink="false">2504.09179v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ToolTipNet: A Segmentation-Driven Deep Learning Baseline for Surgical Instrument Tip Detection</title>
      <link>http://arxiv.org/abs/2504.09700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于深度学习的手术器械尖端检测方法，以解决机器人辅助腹腔镜根治性前列腺切除术中器械尖端定位不准确的问题。&lt;h4&gt;背景&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端的位置对于将超声框架与腹腔镜摄像机框架对准至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于视觉的方法，直接计算工具尖端在摄像机框架中的位置，以提高手术精确性。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术，结合分割基础模型（Segment Anything），实现手术器械尖端的检测，并通过与手工图像处理方法进行比较实验。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在模拟和真实数据集上优于手工图像处理方法，能够有效检测小型且可动手术器械的尖端。&lt;h4&gt;结论&lt;/h4&gt;基于深度学习的手术器械尖端检测方法能够有效解决手术器械尖端定位问题，具有提高手术精度的潜力。&lt;h4&gt;翻译&lt;/h4&gt;在机器人辅助腹腔镜根治性前列腺切除术中，器械尖端位置对超声框架与腹腔镜摄像机框架的对准至关重要。现有方法中，由da Vinci API获取的器械尖端位置不准确，需要手动校正。因此，直接使用基于视觉的方法计算工具尖端在摄像机框架中的位置成为一个吸引人的解决方案。此外，手术器械尖端检测是其他任务（如手术技能评估和手术自动化）的关键组成部分。然而，由于工具尖端尺寸小且手术器械可动，这一任务具有挑战性。随着分割基础模型（Segment Anything）的出现，手术器械分割变得相对容易。基于这一进步，我们探索了基于深度学习的手术器械尖端检测方法，该方法以部分级器械分割掩码作为输入。与手工图像处理方法的比较实验表明，所提出的方法在模拟和真实数据集上均优于手工图像处理方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robot-assisted laparoscopic radical prostatectomy (RALP), the location ofthe instrument tip is important to register the ultrasound frame with thelaparoscopic camera frame. A long-standing limitation is that the instrumenttip position obtained from the da Vinci API is inaccurate and requires hand-eyecalibration. Thus, directly computing the position of the tool tip in thecamera frame using the vision-based method becomes an attractive solution.Besides, surgical instrument tip detection is the key component of other tasks,like surgical skill assessment and surgery automation. However, this task ischallenging due to the small size of the tool tip and the articulation of thesurgical instrument. Surgical instrument segmentation becomes relatively easydue to the emergence of the Segmentation Foundation Model, i.e., SegmentAnything. Based on this advancement, we explore the deep learning-basedsurgical instrument tip detection approach that takes the part-level instrumentsegmentation mask as input. Comparison experiments with a hand-craftedimage-processing approach demonstrate the superiority of the proposed method onsimulated and real datasets.</description>
      <author>example@mail.com (Zijian Wu, Shuojue Yang, Yueming Jin, Septimiu E Salcudean)</author>
      <guid isPermaLink="false">2504.09700v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards Unbiased Federated Graph Learning: Label and Topology Perspectives</title>
      <link>http://arxiv.org/abs/2504.09963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairFGL的新型框架，旨在通过细粒度图挖掘和协作学习来提高联邦图学习（FGL）中的公平性。&lt;h4&gt;背景&lt;/h4&gt;Federated Graph Learning（FGL）允许在不共享原始数据的情况下，对图神经网络进行隐私保护、分布式训练。subgraph-FL成为主流方法，但现有方法往往忽略了公平性，特别是在处理具有不利属性的节点时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了两个公平性目标：(1) 提高少数类节点的表示以实现类间公平性；(2) 减少异质连接带来的拓扑偏差以实现拓扑感知公平性。&lt;h4&gt;方法&lt;/h4&gt;FairFGL框架包括客户端和服务器端。客户端使用历史保持模块防止对主导局部类过度拟合，使用多数对齐模块细化异质多数类节点的表示，使用梯度修改模块将少数类知识从结构上优势的客户端传递以改善公平性。服务器端仅上传受影响最大的参数子集以减少通信成本，并更好地反映局部分布。基于集群的聚合策略协调冲突的更新并抑制全局多数主导。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准测试上的广泛评估表明，FairFGL显著提高了少数群体的性能，实现了高达22.62%的Macro-F1增益，同时增强了收敛性。&lt;h4&gt;结论&lt;/h4&gt;FairFGL框架通过提高少数类节点的表示和减少异质连接的拓扑偏差，有效地提升了联邦图学习中的公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) enables privacy-preserving, distributedtraining of graph neural networks without sharing raw data. Among itsapproaches, subgraph-FL has become the dominant paradigm, with most workfocused on improving overall node classification accuracy. However, thesemethods often overlook fairness due to the complexity of node features, labels,and graph structures. In particular, they perform poorly on nodes withdisadvantaged properties, such as being in the minority class within subgraphsor having heterophilous connections (neighbors with dissimilar labels ormisleading features). This reveals a critical issue: high accuracy can maskdegraded performance on structurally or semantically marginalized nodes. Toaddress this, we advocate for two fairness goals: (1) improving representationof minority class nodes for class-wise fairness and (2) mitigating topologicalbias from heterophilous connections for topology-aware fairness. We proposeFairFGL, a novel framework that enhances fairness through fine-grained graphmining and collaborative learning. On the client side, the History-PreservingModule prevents overfitting to dominant local classes, while the MajorityAlignment Module refines representations of heterophilous majority-class nodes.The Gradient Modification Module transfers minority-class knowledge fromstructurally favorable clients to improve fairness. On the server side, FairFGLuploads only the most influenced subset of parameters to reduce communicationcosts and better reflect local distributions. A cluster-based aggregationstrategy reconciles conflicting updates and curbs global majority dominance .Extensive evaluations on eight benchmarks show FairFGL significantly improvesminority-group performance , achieving up to a 22.62 percent Macro-F1 gainwhile enhancing convergence over state-of-the-art baselines.</description>
      <author>example@mail.com (Zhengyu Wu, Boyang Pang, Xunkai Li, Yinlin Zhu, Daohan Su, Bowen Fan, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09963v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Shape-Experts (MoSE): End-to-End Shape Dictionary Framework to Prompt SAM for Generalizable Medical Segmentation</title>
      <link>http://arxiv.org/abs/2504.09601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025 workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的Mixture-of-Shape-Experts (MoSE)框架，用于提高医学图像分割中的单域泛化能力。&lt;h4&gt;背景&lt;/h4&gt;单域泛化（SDG）在医学图像分割中越来越受到关注，但现有的字典学习方法存在表示能力有限或过拟合的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效捕捉多样化和鲁棒形状先验的方法，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;MoSE框架将混合专家（MoE）训练的理念整合到字典学习中，将每个字典原子视为一个形状专家，并使用门控网络动态融合这些专家，以生成鲁棒的形状图。SAM编码用于指导稀疏激活，防止过拟合。形状图作为提示被用于SAM，实现双向集成。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个公共数据集上进行了广泛实验，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MoSE框架能够有效提高医学图像分割中的单域泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Single domain generalization (SDG) has recently attracted growing attention in medical image segmentation. One promising strategy for SDG is to leverage consistent semantic shape priors across different imaging protocols, scanner vendors, and clinical sites. However, existing dictionary learning methods that encode shape priors often suffer from limited representational power with a small set of offline computed shape elements, or overfitting when the dictionary size grows. Moreover, they are not readily compatible with large foundation models such as the Segment Anything Model (SAM). In this paper, we propose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlessly integrates the idea of mixture-of-experts (MoE) training into dictionary learning to efficiently capture diverse and robust shape priors. Our method conceptualizes each dictionary atom as a shape expert, which specializes in encoding distinct semantic shape information. A gating network dynamically fuses these shape experts into a robust shape map, with sparse activation guided by SAM encoding to prevent overfitting. We further provide this shape map as a prompt to SAM, utilizing the powerful generalization capability of SAM through bidirectional integration. All modules, including the shape dictionary, are trained in an end-to-end manner. Extensive experiments on multiple public datasets demonstrate its effectiveness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single domain generalization (SDG) has recently attracted growing attentionin medical image segmentation. One promising strategy for SDG is to leverageconsistent semantic shape priors across different imaging protocols, scannervendors, and clinical sites. However, existing dictionary learning methods thatencode shape priors often suffer from limited representational power with asmall set of offline computed shape elements, or overfitting when thedictionary size grows. Moreover, they are not readily compatible with largefoundation models such as the Segment Anything Model (SAM). In this paper, wepropose a novel Mixture-of-Shape-Experts (MoSE) framework that seamlesslyintegrates the idea of mixture-of-experts (MoE) training into dictionarylearning to efficiently capture diverse and robust shape priors. Our methodconceptualizes each dictionary atom as a shape expert, which specializes inencoding distinct semantic shape information. A gating network dynamicallyfuses these shape experts into a robust shape map, with sparse activationguided by SAM encoding to prevent overfitting. We further provide this shapemap as a prompt to SAM, utilizing the powerful generalization capability of SAMthrough bidirectional integration. All modules, including the shape dictionary,are trained in an end-to-end manner. Extensive experiments on multiple publicdatasets demonstrate its effectiveness.</description>
      <author>example@mail.com (Jia Wei, Xiaoqi Zhao, Jonghye Woo, Jinsong Ouyang, Georges El Fakhri, Qingyu Chen, Xiaofeng Liu)</author>
      <guid isPermaLink="false">2504.09601v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Glucose-Only Assessment: Advancing Nocturnal Hypoglycemia Prediction in Children with Type 1 Diabetes</title>
      <link>http://arxiv.org/abs/2504.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICLR 2025 Workshop on AI for Children&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过生理数据和机器学习技术，旨在改善1型糖尿病患者夜间低血糖的预测。&lt;h4&gt;背景&lt;/h4&gt;死在床上的综合症描述了年轻1型糖尿病患者突然无征兆的死亡，这种死亡被假设与夜间低血糖有关。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过利用生理数据和机器学习技术，提高1型糖尿病儿童夜间低血糖的预测能力。&lt;h4&gt;方法&lt;/h4&gt;研究分析了来自16名1型糖尿病儿童的内部数据集，整合了可穿戴传感器的生理指标。通过特征工程、模型选择、架构和过采样来探索预测性能。为了解决数据限制，应用了从公共成人数据集的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究在内部数据集上实现了AUROC为0.75 +- 0.21的结果，通过迁移学习进一步提高了到0.78 +- 0.05。&lt;h4&gt;结论&lt;/h4&gt;研究超越了仅基于血糖的预测，通过结合生理参数，展示了机器学习在增强夜间低血糖检测和改善儿童糖尿病管理临床决策中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The dead-in-bed syndrome describes the sudden and unexplained death of young individuals with Type 1 Diabetes (T1D) without prior long-term complications. One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia (NH), a dangerous drop in blood glucose during sleep. This study aims to improve NH prediction in children with T1D by leveraging physiological data and machine learning (ML) techniques. We analyze an in-house dataset collected from 16 children with T1D, integrating physiological metrics from wearable sensors. We explore predictive performance through feature engineering, model selection, architectures, and oversampling. To address data limitations, we apply transfer learning from a publicly available adult dataset. Our results achieve an AUROC of 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 with transfer learning. This research moves beyond glucose-only predictions by incorporating physiological parameters, showcasing the potential of ML to enhance NH detection and improve clinical decision-making for pediatric diabetes management.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dead-in-bed syndrome describes the sudden and unexplained death of youngindividuals with Type 1 Diabetes (T1D) without prior long-term complications.One leading hypothesis attributes this phenomenon to nocturnal hypoglycemia(NH), a dangerous drop in blood glucose during sleep. This study aims toimprove NH prediction in children with T1D by leveraging physiological data andmachine learning (ML) techniques. We analyze an in-house dataset collected from16 children with T1D, integrating physiological metrics from wearable sensors.We explore predictive performance through feature engineering, model selection,architectures, and oversampling. To address data limitations, we apply transferlearning from a publicly available adult dataset. Our results achieve an AUROCof 0.75 +- 0.21 on the in-house dataset, further improving to 0.78 +- 0.05 withtransfer learning. This research moves beyond glucose-only predictions byincorporating physiological parameters, showcasing the potential of ML toenhance NH detection and improve clinical decision-making for pediatricdiabetes management.</description>
      <author>example@mail.com (Marco Voegeli, Sonia Laguna, Heike Leutheuser, Marc Pfister, Marie-Anne Burckhardt, Julia E Vogt)</author>
      <guid isPermaLink="false">2504.09299v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Predicting ulcer in H&amp;E images of inflammatory bowel disease using domain-knowledge-driven graph neural network</title>
      <link>http://arxiv.org/abs/2504.09430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work accepted at ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DomainGCN的弱监督模型，用于在炎症性肠病（IBD）中预测溃疡区域，以提高个性化治疗的选择。&lt;h4&gt;背景&lt;/h4&gt;炎症性肠病（IBD）是一种慢性炎症性疾病，其治疗常常受到副作用的影响。免疫细胞在IBD中起关键作用，而在全切片图像（WSIs）中准确识别溃疡区域对于表征这些细胞和探索潜在疗法至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够利用特定领域知识（如上皮、淋巴细胞和碎片的存在）的模型，以在IBD中预测WSI级别的溃疡区域。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DomainGCN的模型，该模型结合了图卷积神经网络（GCN）和特定于溃疡特征的领域知识，用于WSI级别的溃疡预测。&lt;h4&gt;主要发现&lt;/h4&gt;DomainGCN在多个实例学习（MIL）方法中表现优于最先进的（SOTA）方法，并展示了领域知识带来的额外价值。&lt;h4&gt;结论&lt;/h4&gt;DomainGCN模型能够有效地利用领域知识提高IBD中溃疡区域的预测准确性，为个性化治疗提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Inflammatory bowel disease (IBD) involves chronic inflammation of the digestive tract, with treatment options often burdened by adverse effects. Identifying biomarkers for personalized treatment is crucial. While immune cells play a key role in IBD, accurately identifying ulcer regions in whole slide images (WSIs) is essential for characterizing these cells and exploring potential therapeutics. Multiple instance learning (MIL) approaches have advanced WSI analysis but they lack spatial context awareness. In this work, we propose a weakly-supervised model called DomainGCN that employs a graph convolution neural network (GCN) and incorporates domain-specific knowledge of ulcer features, specifically, the presence of epithelium, lymphocytes, and debris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCN outperforms various state-of-the-art (SOTA) MIL methods and show the added value of domain knowledge.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inflammatory bowel disease (IBD) involves chronic inflammation of thedigestive tract, with treatment options often burdened by adverse effects.Identifying biomarkers for personalized treatment is crucial. While immunecells play a key role in IBD, accurately identifying ulcer regions in wholeslide images (WSIs) is essential for characterizing these cells and exploringpotential therapeutics. Multiple instance learning (MIL) approaches haveadvanced WSI analysis but they lack spatial context awareness. In this work, wepropose a weakly-supervised model called DomainGCN that employs a graphconvolution neural network (GCN) and incorporates domain-specific knowledge ofulcer features, specifically, the presence of epithelium, lymphocytes, anddebris for WSI-level ulcer prediction in IBD. We demonstrate that DomainGCNoutperforms various state-of-the-art (SOTA) MIL methods and show the addedvalue of domain knowledge.</description>
      <author>example@mail.com (Ruiwen Ding, Lin Li, Rajath Soans, Tosha Shah, Radha Krishnan, Marc Alexander Sze, Sasha Lukyanov, Yash Deshpande, Antong Chen)</author>
      <guid isPermaLink="false">2504.09430v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Query-based Knowledge Transfer for Heterogeneous Learning Environments</title>
      <link>http://arxiv.org/abs/2504.09205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICLR'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为QKT的新型框架，用于解决在数据异质性和隐私约束下的去中心化协作学习问题。&lt;h4&gt;背景&lt;/h4&gt;在数据异质性和隐私约束下，现有的联邦学习、集成学习和迁移学习方法无法充分满足客户独特的需求，尤其是在本地数据表示有限的情况下。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，提出了QKT框架，以实现针对特定客户需求的定制化知识获取，而不需要直接交换数据。&lt;h4&gt;方法&lt;/h4&gt;QKT采用数据无关的掩码策略，以实现高效的查询焦点知识迁移，同时优化任务特定参数，以减轻知识干扰和遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准和临床基准上的实验表明，QKT在单类别查询设置中平均优于现有协作学习方法20.91%，在多类别查询场景中平均优于14.32%。进一步的分析和消融研究显示，QKT有效地平衡了新知识和现有知识的学习，显示出其在去中心化学习中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;QKT框架能够有效地解决数据异质性和隐私约束下的去中心化协作学习问题，具有在去中心化学习领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decentralized collaborative learning under data heterogeneity and privacyconstraints has rapidly advanced. However, existing solutions like federatedlearning, ensembles, and transfer learning, often fail to adequately serve theunique needs of clients, especially when local data representation is limited.To address this issue, we propose a novel framework called Query-basedKnowledge Transfer (QKT) that enables tailored knowledge acquisition to fulfillspecific client needs without direct data exchange. QKT employs a data-freemasking strategy to facilitate communication-efficient query-focused knowledgetransfer while refining task-specific parameters to mitigate knowledgeinterference and forgetting. Our experiments, conducted on both standard andclinical benchmarks, show that QKT significantly outperforms existingcollaborative learning methods by an average of 20.91\% points in single-classquery settings and an average of 14.32\% points in multi-class query scenarios.Further analysis and ablation studies reveal that QKT effectively balances thelearning of new and existing knowledge, showing strong potential for itsapplication in decentralized learning.</description>
      <author>example@mail.com (Norah Alballa, Wenxuan Zhang, Ziquan Liu, Ahmed M. Abdelmoniem, Mohamed Elhoseiny, Marco Canini)</author>
      <guid isPermaLink="false">2504.09205v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding</title>
      <link>http://arxiv.org/abs/2504.09516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为FSSUAVL的单个深度模型，用于解决无配对数据情况下多模态音频和图像识别的问题。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，配对的多模态音频图像表示可以有效地通过视觉模型学习。然而，在联邦学习（FL）等场景中，数据往往是去中心化、异构的，且缺乏可靠的数据配对保证。&lt;h4&gt;目的&lt;/h4&gt;旨在通过FSSUAVL模型解决无配对模态深度学习表示的挑战。&lt;h4&gt;方法&lt;/h4&gt;FSSUAVL模型在FL中通过自监督对比学习（SSL）进行预训练，不通过模态对齐，而是通过对比SSL将音频和图像投影到共同的嵌入空间中。&lt;h4&gt;主要发现&lt;/h4&gt;与使用单独深度模型进行每个模态相比，FSSUAVL在CNN和ViT上的实验表明，它在各种基于图像和音频的下游任务中显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;FSSUAVL能够学习多模态特征表示，并允许集成辅助信息以提高识别精度。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，当配对时，视觉模型可以有效地学习多模态音频-图像表示。然而，使深度模型从无配对模态中学习表示的挑战仍未解决。这个问题在联邦学习（FL）等场景中尤为重要，在这些场景中，数据通常是去中心化的、异构的，并且缺乏可靠的数据配对保证。以前的努力通过在本地客户端使用辅助预训练编码器或生成模型来解决这个问题，这不可避免地随着模态数量的增加而增加计算成本。与这些方法不同，本文旨在通过使用在FL中预训练的自监督对比学习（SSL）的单个深度模型FSSUAVL来处理无配对音频和图像识别任务。FSSUAVL通过对比SSL将音频和图像联合区分，而不是对齐它们，将它们投影到共同的嵌入空间中。这扩展了FSSUAVL在配对和无配对音频和图像识别任务中的效用。我们在CNN和ViT上的实验表明，与为每个模态使用单独的深度模型相比，FSSUAVL在各种基于图像和音频的下游任务中显著提高了性能。此外，FSSUAVL学习多模态特征表示的能力允许集成辅助信息（如果可用）以提高识别精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies have demonstrated that vision models can effectively learnmultimodal audio-image representations when paired. However, the challenge ofenabling deep models to learn representations from unpaired modalities remainsunresolved. This issue is especially pertinent in scenarios like FederatedLearning (FL), where data is often decentralized, heterogeneous, and lacks areliable guarantee of paired data. Previous attempts tackled this issue throughthe use of auxiliary pretrained encoders or generative models on local clients,which invariably raise computational cost with increasing number modalities.Unlike these approaches, in this paper, we aim to address the task of unpairedaudio and image recognition using \texttt{FSSUAVL}, a single deep modelpretrained in FL with self-supervised contrastive learning (SSL). Instead ofaligning the audio and image modalities, \texttt{FSSUAVL} jointly discriminatesthem by projecting them into a common embedding space using contrastive SSL.This extends the utility of \texttt{FSSUAVL} to paired and unpaired audio andimage recognition tasks. Our experiments with CNN and ViT demonstrate that\texttt{FSSUAVL} significantly improves performance across various image- andaudio-based downstream tasks compared to using separate deep models for eachmodality. Additionally, \texttt{FSSUAVL}'s capacity to learn multimodal featurerepresentations allows for integrating auxiliary information, if available, toenhance recognition accuracy.</description>
      <author>example@mail.com (Yasar Abbas Ur Rehman, Kin Wai Lau, Yuyang Xie, Ma Lan, JiaJun Shen)</author>
      <guid isPermaLink="false">2504.09516v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Directional Dual-Attention GAT for Spatial Fluoride Health Risk Modeling</title>
      <link>http://arxiv.org/abs/2504.09416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SDD-GAT的新型空间图神经网络，用于细粒度健康风险预测，并在贵州地区的氟化物监测样本和氟斑牙记录数据集上取得了显著效果。&lt;h4&gt;背景&lt;/h4&gt;氟化物环境暴露是公共卫生问题，特别是在氟化物浓度自然升高的地区。准确建模氟化物相关的健康风险，如牙氟斑病，需要能够捕捉地理和语义异质性的空间感知学习框架。&lt;h4&gt;目的&lt;/h4&gt;提出SDD-GAT，以实现氟化物相关健康风险的准确预测。&lt;h4&gt;方法&lt;/h4&gt;SDD-GAT引入了双图架构，将地理邻近性和属性相似性解耦，并采用方向性注意力机制将空间方向和距离显式编码到消息传递过程中。为了进一步提高空间一致性，引入了空间平滑度正则化项。&lt;h4&gt;主要发现&lt;/h4&gt;SDD-GAT在回归和分类任务中均显著优于传统模型和最先进的图神经网络，并且表现出改善的空间自相关性。&lt;h4&gt;结论&lt;/h4&gt;SDD-GAT为复杂环境设置下的空间健康风险建模和地理空间学习提供了一个可推广的基础。&lt;h4&gt;翻译&lt;/h4&gt;Environmental exposure to fluoride is a major public health concern, particularly in regions with naturally elevated fluoride concentrations. Accurate modeling of fluoride-related health risks, such as dental fluorosis, requires spatially aware learning frameworks capable of capturing both geographic and semantic heterogeneity. In this work, we propose Spatially Directional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatial graph neural network designed for fine-grained health risk prediction. SDD-GAT introduces a dual-graph architecture that disentangles geographic proximity and attribute similarity, and incorporates a directional attention mechanism that explicitly encodes spatial orientation and distance into the message passing process. To further enhance spatial coherence, we introduce a spatial smoothness regularization term that enforces consistency in predictions across neighboring locations. We evaluate SDD-GAT on a large-scale dataset covering over 50,000 fluoride monitoring samples and fluorosis records across Guizhou Province, China. Results show that SDD-GAT significantly outperforms traditional models and state-of-the-art GNNs in both regression and classification tasks, while also exhibiting improved spatial autocorrelation as measured by Moran's I. Our framework provides a generalizable foundation for spatial health risk modeling and geospatial learning under complex environmental settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Environmental exposure to fluoride is a major public health concern,particularly in regions with naturally elevated fluoride concentrations.Accurate modeling of fluoride-related health risks, such as dental fluorosis,requires spatially aware learning frameworks capable of capturing bothgeographic and semantic heterogeneity. In this work, we propose SpatiallyDirectional Dual-Attention Graph Attention Network (SDD-GAT), a novel spatialgraph neural network designed for fine-grained health risk prediction. SDD-GATintroduces a dual-graph architecture that disentangles geographic proximity andattribute similarity, and incorporates a directional attention mechanism thatexplicitly encodes spatial orientation and distance into the message passingprocess. To further enhance spatial coherence, we introduce a spatialsmoothness regularization term that enforces consistency in predictions acrossneighboring locations. We evaluate SDD-GAT on a large-scale dataset coveringover 50,000 fluoride monitoring samples and fluorosis records across GuizhouProvince, China. Results show that SDD-GAT significantly outperformstraditional models and state-of-the-art GNNs in both regression andclassification tasks, while also exhibiting improved spatial autocorrelation asmeasured by Moran's I. Our framework provides a generalizable foundation forspatial health risk modeling and geospatial learning under complexenvironmental settings.</description>
      <author>example@mail.com (Da Yuan)</author>
      <guid isPermaLink="false">2504.09416v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>EasyREG: Easy Depth-Based Markerless Registration and Tracking using Augmented Reality Device for Surgical Guidance</title>
      <link>http://arxiv.org/abs/2504.09498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导，通过深度传感器实现高精度和实时性能，避免了传统标记方法带来的不便。&lt;h4&gt;背景&lt;/h4&gt;传统的手术引导方法依赖外部标记物，虽然能实现高精度和实时性，但需要繁琐的校准过程，且在临床环境中部署困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种无标记的手术引导框架，以提高手术引导的准确性和实时性。&lt;h4&gt;方法&lt;/h4&gt;该框架包含两个模块：注册模块和跟踪模块。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。&lt;h4&gt;结论&lt;/h4&gt;该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于增强现实（AR）设备的无标记框架，用于手术引导。该框架利用AR设备的深度传感器，避免了传统标记方法带来的不便。注册模块通过深度传感器误差校正、区域过滤技术和鲁棒的全球对齐来实现高精度、鲁棒的目标解剖定位。跟踪模块使用快速鲁棒的注册算法，利用注册模块的初始姿态估计实时目标姿态。通过仿真和实际测量，该无标记系统在注册方面表现优于工业解决方案，在跟踪方面与工业解决方案相当。该两模块设计使系统成为手术过程中目标解剖结构移动或静止时的全方位解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of Augmented Reality (AR) devices for surgical guidance has gainedincreasing traction in the medical field. Traditional registration methodsoften rely on external fiducial markers to achieve high accuracy and real-timeperformance. However, these markers introduce cumbersome calibration proceduresand can be challenging to deploy in clinical settings. While commercialsolutions have attempted real-time markerless tracking using the native RGBcameras of AR devices, their accuracy remains questionable for medicalguidance, primarily due to occlusions and significant outliers between the livesensor data and the preoperative target anatomy point cloud derived from MRI orCT scans. In this work, we present a markerless framework that relies only onthe depth sensor of AR devices and consists of two modules: a registrationmodule for high-precision, outlier-robust target anatomy localization, and atracking module for real-time pose estimation. The registration moduleintegrates depth sensor error correction, a human-in-the-loop region filteringtechnique, and a robust global alignment with curvature-aware feature sampling,followed by local ICP refinement, for markerless alignment of preoperativemodels with patient anatomy. The tracking module employs a fast and robustregistration algorithm that uses the initial pose from the registration moduleto estimate the target pose in real-time. We comprehensively evaluated theperformance of both modules through simulation and real-world measurements. Theresults indicate that our markerless system achieves superior performance forregistration and comparable performance for tracking to industrial solutions.The two-module design makes our system a one-stop solution for surgicalprocedures where the target anatomy moves or stays static during surgery.</description>
      <author>example@mail.com (Yue Yang, Christoph Leuze, Brian Hargreaves, Bruce Daniel, Fred Baik)</author>
      <guid isPermaLink="false">2504.09498v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic Aircraft Trajectory Generation Using Time-Based VQ-VAE</title>
      <link>http://arxiv.org/abs/2504.09101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was presented at the 25th Integrated Communications,  Navigation and Surveillance Conference (ICNS 2025), April 8--10, 2025,  Brussels, Belgium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时间向量量化变分自编码器（TimeVQVAE）的飞行轨迹合成新方法，用于解决航空交通管理中的数据稀缺、信息保护以及大规模分析等问题。&lt;h4&gt;背景&lt;/h4&gt;现代航空交通管理中，生成合成飞行轨迹已成为解决数据稀缺、保护敏感信息和支持大规模分析的有前途的解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轨迹合成方法，以适应TimeVQVAE，利用时间-频率域处理、向量量化和基于transformer的先验，捕捉飞行数据的全局和局部动态。&lt;h4&gt;方法&lt;/h4&gt;通过离散化潜在空间和整合transformer先验，模型学习长程时空依赖性，并保持整个飞行路径的连贯性。使用质量、统计和分布性指标以及开源航空交通模拟器中的可飞性评估来评估改进的TimeVQVAE。&lt;h4&gt;主要发现&lt;/h4&gt;TimeVQVAE在空间精度、时间一致性和统计特性方面优于时间卷积VAE基线，生成的合成轨迹与真实飞行数据相似。模拟器评估显示，大多数生成的轨迹保持操作可行性，但偶尔的异常值强调了需要额外的特定领域约束。&lt;h4&gt;结论&lt;/h4&gt;研究强调了多尺度表示学习在捕捉复杂飞行行为中的重要性，并证明了TimeVQVAE在生成具有代表性的合成轨迹方面的潜力，可用于下游任务如模型训练、空域设计和航空交通预测。&lt;h4&gt;翻译&lt;/h4&gt;In modern air traffic management, generating synthetic flight trajectories has emerged as a promising solution for addressing data scarcity, protecting sensitive information, and supporting large-scale analyses. In this paper, we propose a novel method for trajectory synthesis by adapting the Time-Based Vector Quantized Variational Autoencoder (TimeVQVAE). Our approach leverages time-frequency domain processing, vector quantization, and transformer-based priors to capture both global and local dynamics in flight data. By discretizing the latent space and integrating transformer priors, the model learns long-range spatiotemporal dependencies and preserves coherence across entire flight paths. We evaluate the adapted TimeVQVAE using an extensive suite of quality, statistical, and distributional metrics, as well as a flyability assessment conducted in an open-source air traffic simulator. Results indicate that TimeVQVAE outperforms a temporal convolutional VAE baseline, generating synthetic trajectories that mirror real flight data in terms of spatial accuracy, temporal consistency, and statistical properties. Furthermore, the simulator-based assessment shows that most generated trajectories maintain operational feasibility, although occasional outliers underscore the potential need for additional domain-specific constraints. Overall, our findings underscore the importance of multi-scale representation learning for capturing complex flight behaviors and demonstrate the promise of TimeVQVAE in producing representative synthetic trajectories for downstream tasks such as model training, airspace design, and air traffic forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern air traffic management, generating synthetic flight trajectorieshas emerged as a promising solution for addressing data scarcity, protectingsensitive information, and supporting large-scale analyses. In this paper, wepropose a novel method for trajectory synthesis by adapting the Time-BasedVector Quantized Variational Autoencoder (TimeVQVAE). Our approach leveragestime-frequency domain processing, vector quantization, and transformer-basedpriors to capture both global and local dynamics in flight data. Bydiscretizing the latent space and integrating transformer priors, the modellearns long-range spatiotemporal dependencies and preserves coherence acrossentire flight paths. We evaluate the adapted TimeVQVAE using an extensive suiteof quality, statistical, and distributional metrics, as well as a flyabilityassessment conducted in an open-source air traffic simulator. Results indicatethat TimeVQVAE outperforms a temporal convolutional VAE baseline, generatingsynthetic trajectories that mirror real flight data in terms of spatialaccuracy, temporal consistency, and statistical properties. Furthermore, thesimulator-based assessment shows that most generated trajectories maintainoperational feasibility, although occasional outliers underscore the potentialneed for additional domain-specific constraints. Overall, our findingsunderscore the importance of multi-scale representation learning for capturingcomplex flight behaviors and demonstrate the promise of TimeVQVAE in producingrepresentative synthetic trajectories for downstream tasks such as modeltraining, airspace design, and air traffic forecasting.</description>
      <author>example@mail.com (Abdulmajid Murad, Massimiliano Ruocco)</author>
      <guid isPermaLink="false">2504.09101v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised learning of non-Abelian multi-gap topological phases</title>
      <link>http://arxiv.org/abs/2504.09198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近实验成功实现了具有时间反演对称性的多带非阿贝尔拓扑绝缘体。它们的拓扑分类超越了传统的十倍分类，需要使用非阿贝尔群，表现出不能用整数拓扑不变量描述的新特性。&lt;h4&gt;背景&lt;/h4&gt;非阿贝尔群的唯一非交换乘积以及同伦分类（带或不带固定基点）的独特性，使得不同非阿贝尔拓扑相的识别比阿贝尔情况下更加复杂和具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本工作提出了一种基于扩散映射的无监督学习方法，用于分类非阿贝尔多能隙拓扑相。&lt;h4&gt;方法&lt;/h4&gt;该方法通过自动绝热路径寻找过程，能够正确对属于同一相的样本进行排序，即使这些样本在样本集中没有通过绝热路径连接。更重要的是，该方法能够以数据驱动的方式推断非阿贝尔拓扑电荷的乘法表，而不需要先验知识。此外，该算法可以提供同伦（带或不带固定基点）样本的正确分类。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以正确识别非阿贝尔拓扑相，即使它们之间没有绝热路径连接，并且可以数据驱动地推断拓扑电荷的乘法表。&lt;h4&gt;结论&lt;/h4&gt;这些结果为使用机器学习方法研究非阿贝尔相的未来研究提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent experiments have successfully realized multi-band non-Abelian topological insulators with parity-time symmetry. Their topological classification transcends the conventional ten-fold classification, necessitating the use of non-Abelian groups, manifesting novel properties that cannot be described using integer topological invariants. The unique non-commutative multiplication of non-Abelian groups, along with the distinct topological classifications in the context of homotopy with or without a fixed base point, makes the identification of different non-Abelian topological phases more nuanced and challenging than in the Abelian case. In this work, we present an unsupervised learning method based on diffusion maps to classify non-Abelian multi-gap topological phases. The automatic adiabatic pathfinding process in our method can correctly sort the samples in the same phase even though they are not connected by adiabatic paths in the sample set. Most importantly, our method can deduce the multiplication table of the non-Abelian topological charges in a data-driven manner without requiring extit{a priori} knowledge. Additionally, our algorithm can provide the correct classifications for the samples within both the homotopy with and without a fixed base point. Our results provide insights for future studies on non-Abelian phase studies using machine learning approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent experiments have successfully realized multi-band non-Abeliantopological insulators with parity-time symmetry. Their topologicalclassification transcends the conventional ten-fold classification,necessitating the use of non-Abelian groups, manifesting novel properties thatcannot be described using integer topological invariants. The uniquenon-commutative multiplication of non-Abelian groups, along with the distincttopological classifications in the context of homotopy with or without a fixedbase point, makes the identification of different non-Abelian topologicalphases more nuanced and challenging than in the Abelian case. In this work, wepresent an unsupervised learning method based on diffusion maps to classifynon-Abelian multi-gap topological phases. The automatic adiabatic pathfindingprocess in our method can correctly sort the samples in the same phase eventhough they are not connected by adiabatic paths in the sample set. Mostimportantly, our method can deduce the multiplication table of the non-Abeliantopological charges in a data-driven manner without requiring \textit{a priori}knowledge. Additionally, our algorithm can provide the correct classificationsfor the samples within both the homotopy with and without a fixed base point.Our results provide insights for future studies on non-Abelian phase studiesusing machine learning approaches.</description>
      <author>example@mail.com (Xiangxu He, Ruo-Yang Zhang, Xiaohan Cui, Lei Zhang, C. T. Chan)</author>
      <guid isPermaLink="false">2504.09198v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>FairACE: Achieving Degree Fairness in Graph Neural Networks via Contrastive and Adversarial Group-Balanced Training</title>
      <link>http://arxiv.org/abs/2504.09210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FairACE的新型图神经网络框架，旨在解决图神经网络中存在的公平性问题，通过不对称对比学习和对抗训练来提高不同度数节点的预测公平性。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）中，度数偏差经常导致不同度数节点的预测性能不平等，现有模型主要关注预测精度，而忽略了不同度数组之间的公平性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出FairACE框架，旨在提高图神经网络中不同度数节点的预测公平性。&lt;h4&gt;方法&lt;/h4&gt;FairACE通过集成不对称对比学习和对抗训练来改进度数公平性，同时捕捉一跳局部邻域信息和两跳单边相似性，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练过程中，提出了一个新的组平衡公平损失函数，以最小化不同度数组之间的分类差异。此外，还提出了一种新的公平性度量指标——准确度分布差距（ADG），可以定量评估并确保不同度数节点组的公平性能。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界数据集上的实验结果表明，FairACE在提高度数公平性指标的同时，与最先进的GNN模型相比，保持了有竞争力的精度。&lt;h4&gt;结论&lt;/h4&gt;FairACE是一种有效的图神经网络框架，能够显著提高不同度数节点的预测公平性，同时保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要：公平性一直是图神经网络（GNNs）的一个重要挑战，因为度数偏差通常会导致不同度数节点的预测性能不平等。现有的GNN模型主要关注预测精度，常常忽略了不同度数组之间的公平性。为了解决这个问题，我们提出了一种名为Fairness-Aware Asymmetric Contrastive Ensemble（FairACE）的新颖GNN框架，该框架将不对称对比学习和对抗训练集成在一起，以提高度数公平性。FairACE捕捉了一跳局部邻域信息和两跳单边相似性，以创建更公平的节点表示，并采用度数公平性调节器来平衡高度和低度节点的性能。在模型训练期间，提出了一种新的组平衡公平损失，以最小化不同度数组之间的分类差异。此外，我们还提出了一种新的公平性度量指标，即准确度分布差距（ADG），它可以定量评估并确保不同度数节点组的公平性能。在合成和真实世界数据集上的实验结果表明，与最先进的GNN模型相比，FairACE在提高度数公平性指标的同时，保持了有竞争力的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fairness has been a significant challenge in graph neural networks (GNNs)since degree biases often result in un-equal prediction performance among nodeswith varying degrees. Existing GNN models focus on prediction accuracy,frequently overlooking fairness across different degree groups. To addressthisissue, we propose a novel GNN framework, namely Fairness- Aware AsymmetricContrastive Ensemble (FairACE), which inte-grates asymmetric contrastivelearning with adversarial training to improve degree fairness. FairACE capturesone-hop local neighborhood information and two-hop monophily similarity tocreate fairer node representations and employs a degree fairness regulator tobalance performance between high-degree and low-degree nodes. During modeltraining, a novel group-balanced fairness loss is proposed to minimizeclassification disparities across degree groups. In addition, we also propose anovel fairness metric, the Accuracy Distribution Gap (ADG), which canquantitatively assess and ensure equitable performance across differentdegree-based node groups. Experimental results on both synthetic and real-worlddatasets demonstrate that FairACE significantly improves degree fairnessmetrics while maintaining competitive accuracy in comparison to thestate-of-the-art GNN models.</description>
      <author>example@mail.com (Jiaxin Liu, Xiaoqian Jiang, Cangqi Zhou, Jing Zhang)</author>
      <guid isPermaLink="false">2504.09210v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning-Driven Multi-Vessel Association: Fusing Multimodal Data for Maritime Intelligence</title>
      <link>http://arxiv.org/abs/2504.09197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图学习的多船关联（GMvA）方法，用于解决海事多模态数据融合中的挑战，如数据维度差异、目标计数不匹配、船舶规模变化、遮挡和来自AIS和CCTV等系统的异步数据流。&lt;h4&gt;背景&lt;/h4&gt;随着航道变得越来越拥挤和复杂，确保海事安全和优化交通管理需要有效的航道监控。当前方法在处理多模态数据时面临挑战，尤其是在交通密集的航道中。&lt;h4&gt;目的&lt;/h4&gt;提出GMvA方法以克服上述挑战，实现海事多模态数据的有效融合。&lt;h4&gt;方法&lt;/h4&gt;GMvA方法通过整合AIS和CCTV数据，利用时间序列学习和图神经网络来捕捉船舶轨迹的时空特征。该方法还引入了时间图注意力和时空注意力，以增强特征表示，并使用多层感知器计算鲁棒的相似度分数。此外，采用匈牙利算法确保全局一致和准确的目标匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界的海事数据集上的实验表明，GMvA在多目标关联方面表现出优异的准确性和鲁棒性，即使在船舶密度高、AIS和CCTV数据不完整或不均匀分布的挑战场景中也优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GMvA方法为海事多模态数据融合提供了一种有效的解决方案，能够提高航道监控的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring maritime safety and optimizing traffic management in increasingly crowded and complex waterways require effective waterway monitoring. However, current methods struggle with challenges arising from multimodal data, such as dimensional disparities, mismatched target counts, vessel scale variations, occlusions, and asynchronous data streams from systems like the automatic identification system (AIS) and closed-circuit television (CCTV). Traditional multi-target association methods often struggle with these complexities, particularly in densely trafficked waterways. To overcome these issues, we propose a graph learning-driven multi-vessel association (GMvA) method tailored for maritime multimodal data fusion. By integrating AIS and CCTV data, GMvA leverages time series learning and graph neural networks to capture the spatiotemporal features of vessel trajectories effectively. To enhance feature representation, the proposed method incorporates temporal graph attention and spatiotemporal attention, effectively capturing both local and global vessel interactions. Furthermore, a multi-layer perceptron-based uncertainty fusion module computes robust similarity scores, and the Hungarian algorithm is adopted to ensure globally consistent and accurate target matching. Extensive experiments on real-world maritime datasets confirm that GMvA delivers superior accuracy and robustness in multi-target association, outperforming existing methods even in challenging scenarios with high vessel density and incomplete or unevenly distributed AIS and CCTV data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring maritime safety and optimizing traffic management in increasinglycrowded and complex waterways require effective waterway monitoring. However,current methods struggle with challenges arising from multimodal data, such asdimensional disparities, mismatched target counts, vessel scale variations,occlusions, and asynchronous data streams from systems like the automaticidentification system (AIS) and closed-circuit television (CCTV). Traditionalmulti-target association methods often struggle with these complexities,particularly in densely trafficked waterways. To overcome these issues, wepropose a graph learning-driven multi-vessel association (GMvA) method tailoredfor maritime multimodal data fusion. By integrating AIS and CCTV data, GMvAleverages time series learning and graph neural networks to capture thespatiotemporal features of vessel trajectories effectively. To enhance featurerepresentation, the proposed method incorporates temporal graph attention andspatiotemporal attention, effectively capturing both local and global vesselinteractions. Furthermore, a multi-layer perceptron-based uncertainty fusionmodule computes robust similarity scores, and the Hungarian algorithm isadopted to ensure globally consistent and accurate target matching. Extensiveexperiments on real-world maritime datasets confirm that GMvA delivers superioraccuracy and robustness in multi-target association, outperforming existingmethods even in challenging scenarios with high vessel density and incompleteor unevenly distributed AIS and CCTV data.</description>
      <author>example@mail.com (Yuxu Lu, Kaisen Yang, Dong Yang, Haifeng Ding, Jinxian Weng, Ryan Wen Liu)</author>
      <guid isPermaLink="false">2504.09197v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation</title>
      <link>http://arxiv.org/abs/2504.09532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型的新框架，用于使类人机器人能够从文本指令中自主规划行动，以执行复杂的非结构化环境中的行走和操作任务。&lt;h4&gt;背景&lt;/h4&gt;在复杂、非结构化环境中使类人机器人自主执行行走和操作任务具有重大挑战，这要求机器人具备在长时间范围内规划行动的能力，并利用多模态技术来弥合高级规划和实际任务执行之间的差距。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从文本指令中自主规划行动的方法，以帮助类人机器人在非结构化环境中执行行走和操作任务。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了类人机器人特有的思维链方法，包括详细的可用性和身体运动分析，将任务分解为一系列行走和操作动作。此外，它还整合了基于观察和目标物体属性的空间推理，以有效地导航到可能看不见或被遮挡的目标位置。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的实验设置，在现实世界环境中对物体重新排列、操作和行走和操作任务进行了评估，证明了该方法在分离上半身和下半身控制方面的有效性，并展示了机器人行动推理策略在理解人类指令方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在提高类人机器人在复杂环境中的自主操作能力方面具有潜力，尤其是在理解人类指令并执行相应的行动方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enabling humanoid robots to autonomously perform loco-manipulation tasks incomplex, unstructured environments poses significant challenges. This entailsequipping robots with the capability to plan actions over extended horizonswhile leveraging multi-modality to bridge gaps between high-level planning andactual task execution. Recent advancements in multi-modal foundation modelshave showcased substantial potential in enhancing planning and reasoningabilities, particularly in the comprehension and processing of semanticinformation for robotic control tasks. In this paper, we introduce a novelframework based on foundation models that applies the embodied chain of actionreasoning methodology to autonomously plan actions from textual instructionsfor humanoid loco-manipulation. Our method integrates humanoid-specific chainof thought methodology, including detailed affordance and body movementanalysis, which provides a breakdown of the task into a sequence of locomotionand manipulation actions. Moreover, we incorporate spatial reasoning based onthe observation and target object properties to effectively navigate wheretarget position may be unseen or occluded. Through rigorous experimental setupson object rearrangement, manipulations and loco-manipulation tasks on areal-world environment, we evaluate our method's efficacy on the decoupledupper and lower body control and demonstrate the effectiveness of the chain ofrobotic action reasoning strategies in comprehending human instructions.</description>
      <author>example@mail.com (Yu Hao, Geeta Chandra Raju Bethala, Niraj Pudasaini, Hao Huang, Shuaihang Yuan, Congcong Wen, Baoru Huang, Anh Nguyen, Yi Fang)</author>
      <guid isPermaLink="false">2504.09532v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules</title>
      <link>http://arxiv.org/abs/2504.08912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HyperCore，一个用于构建跨多种模态的球面基础模型的全面开源框架。&lt;h4&gt;背景&lt;/h4&gt;球面神经网络成为建模跨多种模态层次数据的强大工具，研究表明球面空间比欧几里得空间更适合许多预训练和下游任务。&lt;h4&gt;目的&lt;/h4&gt;解决现有工具缺乏构建球面基础模型所需核心组件的问题，以利用最新的进展。&lt;h4&gt;方法&lt;/h4&gt;HyperCore提供核心模块，可轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LViT优于其欧几里得对应版本，并且HyperCore在球面GNNs、CNNs、Transformers和视觉Transformer中具有优势。&lt;h4&gt;结论&lt;/h4&gt;HyperCore框架可以有效地促进球面神经网络的发展和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双曲神经网络已成为跨多种模态建模层次数据的强大工具。近期研究表明，基础模型中的词分布表现出无标度特性，这表明球面空间比欧几里得空间更适合许多预训练和下游任务。然而，现有的工具缺乏构建球面基础模型所需的核心组件，这使得利用最新的进展变得困难。我们引入了HyperCore，这是一个全面的开源框架，它为在多个模态上构建球面基础模型提供了核心模块。HyperCore的模块可以轻松组合以开发新的球面基础模型，无需从头开始大量修改欧几里得模块，从而避免了可能的研究冗余。为了展示其多功能性，我们构建并测试了第一个完全球面的视觉Transformer（LViT）以及一个微调管道，第一个完全球面的多模态CLIP模型（L-CLIP）和一个混合的Graph RAG，它具有球面图编码器。我们的实验表明，LViT优于其欧几里得对应版本。此外，我们还对球面GNNs、CNNs、Transformers和视觉Transformer的实验进行了基准测试和重现，以突出HyperCore的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperbolic neural networks have emerged as a powerful tool for modelinghierarchical data across diverse modalities. Recent studies show that tokendistributions in foundation models exhibit scale-free properties, suggestingthat hyperbolic space is a more suitable ambient space than Euclidean space formany pre-training and downstream tasks. However, existing tools lack essentialcomponents for building hyperbolic foundation models, making it difficult toleverage recent advancements. We introduce HyperCore, a comprehensiveopen-source framework that provides core modules for constructing hyperbolicfoundation models across multiple modalities. HyperCore's modules can beeffortlessly combined to develop novel hyperbolic foundation models,eliminating the need to extensively modify Euclidean modules from scratch andpossible redundant research efforts. To demonstrate its versatility, we buildand test the first fully hyperbolic vision transformers (LViT) with afine-tuning pipeline, the first fully hyperbolic multimodal CLIP model(L-CLIP), and a hybrid Graph RAG with a hyperbolic graph encoder. Ourexperiments demonstrate that LViT outperforms its Euclidean counterpart.Additionally, we benchmark and reproduce experiments across hyperbolic GNNs,CNNs, Transformers, and vision Transformers to highlight HyperCore'sadvantages.</description>
      <author>example@mail.com (Neil He, Menglin Yang, Rex Ying)</author>
      <guid isPermaLink="false">2504.08912v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs</title>
      <link>http://arxiv.org/abs/2504.09504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE International Conference on Multimedia &amp; Expo 2025  (ICME 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MADLLM的多变量异常检测方法，通过预训练的大型语言模型来解决异常检测任务中的多变量时间序列与语言模型文本模态不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;在将预训练的大型语言模型应用于异常检测任务时，多变量时间序列（MTS）模态与语言模型的文本模态不匹配，现有方法简单地将MTS数据转换为多个单变量时间序列序列，这可能导致许多问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的三重编码技术，以将MTS模态与LLMs的文本模态对齐，从而提高异常检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了传统的补丁嵌入方法以及两种新的嵌入方法：跳过嵌入和特征嵌入。跳过嵌入通过改变传统方法中补丁处理的顺序，帮助LLMs保留先前特征的知识；特征嵌入利用对比学习，使模型更好地理解不同特征之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在各种公共异常检测数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MADLLM方法在多变量异常检测任务中表现优异，为解决LLMs在处理MTS数据时的模态不匹配问题提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When applying pre-trained large language models (LLMs) to address anomalydetection tasks, the multivariate time series (MTS) modality of anomalydetection does not align with the text modality of LLMs. Existing methodssimply transform the MTS data into multiple univariate time series sequences,which can cause many problems. This paper introduces MADLLM, a novelmultivariate anomaly detection method via pre-trained LLMs. We design a newtriple encoding technique to align the MTS modality with the text modality ofLLMs. Specifically, this technique integrates the traditional patch embeddingmethod with two novel embedding approaches: Skip Embedding, which alters theorder of patch processing in traditional methods to help LLMs retain knowledgeof previous features, and Feature Embedding, which leverages contrastivelearning to allow the model to better understand the correlations betweendifferent features. Experimental results demonstrate that our methodoutperforms state-of-the-art methods in various public anomaly detectiondatasets.</description>
      <author>example@mail.com (Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Guokuan Li, Jianzong Wang)</author>
      <guid isPermaLink="false">2504.09504v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation</title>
      <link>http://arxiv.org/abs/2504.09149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, SIGGRAPH 2025 Accept - Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MASH的新颖的多视角和参数化3D形状表示方法。&lt;h4&gt;背景&lt;/h4&gt;受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性。&lt;h4&gt;目的&lt;/h4&gt;将3D形状表示为一系列可观察的局部表面补丁的集合。&lt;h4&gt;方法&lt;/h4&gt;使用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。&lt;h4&gt;主要发现&lt;/h4&gt;开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。&lt;h4&gt;结论&lt;/h4&gt;MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了一种名为MASH的新颖的多视角和参数化3D形状表示方法。受多视图几何的启发，并鉴于感知形状理解对学习3D形状的重要性，MASH将3D形状表示为一系列可观察的局部表面补丁的集合。我们进一步利用球谐函数的紧凑性来编码MASH函数，并结合具有参数化基的广义视锥体，以局部化球面函数的空间范围。我们开发了一种可微优化算法，可以将任何点云转换为MASH表示，该表示能够准确近似具有任意几何和拓扑的地面真实表面。大量实验表明，MASH在多个应用中表现出优越的性能，包括表面重建、形状生成、补全和混合，这得益于其独特的表示，涵盖了隐式和显式特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-viewand parametrized representation of 3D shapes. Inspired by multi-view geometryand motivated by the importance of perceptual shape understanding for learning3D shapes, MASH represents a 3D shape as a collection of observable localsurface patches, each defined by a spherical distance function emanating froman anchor point. We further leverage the compactness of spherical harmonics toencode the MASH functions, combined with a generalized view cone with aparameterized base that masks the spatial extent of the spherical function toattain locality. We develop a differentiable optimization algorithm capable ofconverting any point cloud into a MASH representation accurately approximatingground-truth surfaces with arbitrary geometry and topology. Extensiveexperiments demonstrate that MASH is versatile for multiple applicationsincluding surface reconstruction, shape generation, completion, and blending,achieving superior performance thanks to its unique representation encompassingboth implicit and explicit features.</description>
      <author>example@mail.com (Changhao Li, Yu Xin, Xiaowei Zhou, Ariel Shamir, Hao Zhang, Ligang Liu, Ruizhen Hu)</author>
      <guid isPermaLink="false">2504.09149v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Additive Parameter Updates of Vision Transformers for Few-Shot Continual Learning</title>
      <link>http://arxiv.org/abs/2504.08982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的FSCIL框架，通过冻结预训练的ViT参数并使用参数高效的增量更新机制，解决了增量学习中的灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;在人工智能中，整合新类别信息而不丢失先前获得的知识是一个核心挑战，通常被称为灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;解决增量学习中的灾难性遗忘问题，提出一种新的FSCIL框架。&lt;h4&gt;方法&lt;/h4&gt;冻结预训练的ViT参数，通过添加更新机制选择性地将可训练权重注入到自注意力模块中，仅更新一小部分参数以适应新类别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基准数据集上实现了与基线FSCIL方法相比的最优性能。&lt;h4&gt;结论&lt;/h4&gt;通过冻结ViT参数和参数高效的增量更新，该框架能够有效减少过拟合风险，同时避免覆盖先前学习到的知识。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在人工智能中，整合新类别信息而不丢失先前获得的知识仍然是一个核心挑战，通常被称为灾难性遗忘。少量样本类别增量学习（FSCIL）通过首先在基类稳健数据集上训练模型，然后在连续会话中仅使用少量每个新类别的标记示例来增量适应模型来解决此问题。然而，这种方法容易在有限的新数据上过拟合，这可能会损害整体性能并加剧遗忘。在这项工作中，我们提出了一种简单而有效的FSCIL新框架，该框架利用冻结的视觉Transformer（ViT）骨干网络，并辅以参数高效的增量更新。我们的方法冻结了预训练的ViT参数，并通过添加更新机制选择性地将可训练权重注入到自注意力模块中。这种设计仅更新一小部分参数以适应新类别，而不牺牲基会话期间学习到的表示。通过微调有限数量的参数，我们的方法在冻结的ViT中保留了可推广的特征，同时降低了过拟合的风险。此外，由于大多数参数保持不变，当引入小的新的数据批次时，模型避免了覆盖先前学习到的知识。在基准数据集上的大量实验表明，与基线FSCIL方法相比，我们的方法实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating new class information without losing previously acquiredknowledge remains a central challenge in artificial intelligence, oftenreferred to as catastrophic forgetting. Few-shot class incremental learning(FSCIL) addresses this by first training a model on a robust dataset of baseclasses and then incrementally adapting it in successive sessions using only afew labeled examples per novel class. However, this approach is prone tooverfitting on the limited new data, which can compromise overall performanceand exacerbate forgetting. In this work, we propose a simple yet effectivenovel FSCIL framework that leverages a frozen Vision Transformer (ViT) backboneaugmented with parameter-efficient additive updates. Our approach freezes thepre-trained ViT parameters and selectively injects trainable weights into theself-attention modules via an additive update mechanism. This design updatesonly a small subset of parameters to accommodate new classes withoutsacrificing the representations learned during the base session. By fine-tuninga limited number of parameters, our method preserves the generalizable featuresin the frozen ViT while reducing the risk of overfitting. Furthermore, as mostparameters remain fixed, the model avoids overwriting previously learnedknowledge when small novel data batches are introduced. Extensive experimentson benchmark datasets demonstrate that our approach yields state-of-the-artperformance compared to baseline FSCIL methods.</description>
      <author>example@mail.com (Kyle Stein, Andrew Arash Mahyari, Guillermo Francia III, Eman El-Sheikh)</author>
      <guid isPermaLink="false">2504.08982v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Towards On-Device Learning and Reconfigurable Hardware Implementation for Encoded Single-Photon Signal Processing</title>
      <link>http://arxiv.org/abs/2504.09028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于OSOS-ELM的在线训练算法，用于提高深度神经网络从时间分辨光子到达信号中重构关键参数的准确性和效率，同时优化了硬件资源利用。&lt;h4&gt;背景&lt;/h4&gt;传统的基于反向传播的深度神经网络在重构关键参数时对光学设置和生物样本参数非常敏感，需要频繁重新训练，且数据存储和传输引入了延迟和存储开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种在线训练算法，解决传统DNNs性能依赖参数和频繁重新训练的问题，并提高硬件效率。&lt;h4&gt;方法&lt;/h4&gt;采用基于One-Sided Jacobi旋转的在线序列极端学习机（OSOS-ELM）算法，利用FPGA的异构并行处理能力，并实现了一种整体的计算原型。&lt;h4&gt;主要发现&lt;/h4&gt;OSOS-ELM和OSELM在不同网络维度上达到可比的准确度，且OSOS-ELM更具有硬件效率。通过案例研究验证了算法的有效性，并在Xilinx ZCU104 FPGA上实现了整体计算原型。&lt;h4&gt;结论&lt;/h4&gt;OSOS-ELM算法能够有效提高深度神经网络重构关键参数的性能，并通过硬件优化进一步提升了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an online training algorithm based on OSOS-ELM to improve the accuracy and efficiency of reconstructing key parameters from time-resolved photon arrival signals using deep neural networks. The algorithm addresses the issues of performance dependence on optical setup and biological sample parameters in conventional DNNs, which require frequent retraining. By leveraging the parallel processing capabilities of heterogeneous FPGAs, the proposed algorithm optimizes hardware resource utilization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) enhance the accuracy and efficiency ofreconstructing key parameters from time-resolved photon arrival signalsrecorded by single-photon detectors. However, the performance of conventionalbackpropagation-based DNNs is highly dependent on various parameters of theoptical setup and biological samples under examination, necessitating frequentnetwork retraining, either through transfer learning or from scratch. Newlycollected data must also be stored and transferred to a high-performance GPUserver for retraining, introducing latency and storage overhead. To addressthese challenges, we propose an online training algorithm based on a One-SidedJacobi rotation-based Online Sequential Extreme Learning Machine (OSOS-ELM). Wefully exploit parallelism in executing OSOS-ELM on a heterogeneous FPGA withintegrated ARM cores. Extensive evaluations of OSOS-ELM and OSELM demonstratethat both achieve comparable accuracy across different network dimensions(i.e., input, hidden, and output layers), while OSOS-ELM proves to be morehardware-efficient. By leveraging the parallelism of OSOS-ELM, we implement aholistic computing prototype on a Xilinx ZCU104 FPGA, which integrates amulti-core CPU and programmable logic fabric. We validate our approach throughthree case studies involving single-photon signal analysis: sensing through fogusing commercial single-photon LiDAR, fluorescence lifetime estimation in FLIM,and blood flow index reconstruction in DCS, all utilizing one-dimensional dataencoded from photonic signals. From a hardware perspective, we optimize theOSOS-ELM workload by employing multi-tasked processing on ARM CPU cores andpipelined execution on the FPGA's logic fabric. We also implement our OSOS-ELMon the NVIDIA Jetson Xavier NX GPU to comprehensively investigate its computingperformance on another type of heterogeneous computing platform.</description>
      <author>example@mail.com (Zhenya Zang, Xingda Li, David Day Uei Li)</author>
      <guid isPermaLink="false">2504.09028v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>A Constrained Optimization Approach for Gaussian Splatting from Coarsely-posed Images and Noisy Lidar Point Clouds</title>
      <link>http://arxiv.org/abs/2504.09129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于约束优化的3D Gaussian Splatting (3DGS)方法，用于同时估计相机姿态和进行3D重建，无需依赖SfM算法。&lt;h4&gt;背景&lt;/h4&gt;3DGS是一种强大的重建技术，但需要从精确的相机姿态和高保真点云中进行初始化。通常，初始化来自SfM算法，但SfM过程耗时且限制了3DGS在现实场景和大规模场景重建中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要SfM支持的3DGS初始化方法，以提高重建效率和适用性。&lt;h4&gt;方法&lt;/h4&gt;将相机姿态分解为相机到（设备）中心和（设备）中心到世界的优化序列。提出两个优化约束，根据每个参数组的敏感性来限制搜索空间。直接从噪声点云中学习场景几何，并引入几何约束以提高重建质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在收集的数据集和两个公开基准测试上，都显著优于现有的3DGS基线和补充COLMAP的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地进行3DGS的初始化，无需SfM支持，且重建质量优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) is a powerful reconstruction technique, but itneeds to be initialized from accurate camera poses and high-fidelity pointclouds. Typically, the initialization is taken from Structure-from-Motion (SfM)algorithms; however, SfM is time-consuming and restricts the application of3DGS in real-world scenarios and large-scale scene reconstruction. We introducea constrained optimization method for simultaneous camera pose estimation and3D reconstruction that does not require SfM support. Core to our approach isdecomposing a camera pose into a sequence of camera-to-(device-)center and(device-)center-to-world optimizations. To facilitate, we propose twooptimization constraints conditioned to the sensitivity of each parameter groupand restricts each parameter's search space. In addition, as we learn the scenegeometry directly from the noisy point clouds, we propose geometric constraintsto improve the reconstruction quality. Experiments demonstrate that theproposed method significantly outperforms the existing (multi-modal) 3DGSbaseline and methods supplemented by COLMAP on both our collected dataset andtwo public benchmarks.</description>
      <author>example@mail.com (Jizong Peng, Tze Ho Elden Tse, Kai Xu, Wenchao Gao, Angela Yao)</author>
      <guid isPermaLink="false">2504.09129v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>PCM-SAR: Physics-Driven Contrastive Mutual Learning for SAR Classification</title>
      <link>http://arxiv.org/abs/2504.09502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于物理驱动的对比互学习SAR图像分类方法PCM-SAR，旨在解决现有方法在SAR数据样本生成和特征提取上的不足。&lt;h4&gt;背景&lt;/h4&gt;现有的基于对比学习的SAR图像分类方法常常依赖于为光学图像设计的样本生成策略，未能充分捕捉SAR数据的独特语义和物理特征。&lt;h4&gt;目的&lt;/h4&gt;提出PCM-SAR方法，通过结合领域特定的物理洞察力，改善样本生成和特征提取过程。&lt;h4&gt;方法&lt;/h4&gt;PCM-SAR利用灰度共生矩阵（GLCM）模拟真实的噪声模式，并应用语义检测进行无监督的局部采样，以确保生成的样本准确反映SAR成像特性。此外，采用基于互学习的多级特征融合机制，实现特征表示的协作优化。PCM-SAR通过细化SAR特征表示，显著提升了小型模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;PCM-SAR在多个数据集和SAR分类任务上，一致优于现有最先进（SOTA）的方法。&lt;h4&gt;结论&lt;/h4&gt;PCM-SAR方法有效提高了SAR图像分类的性能，尤其是在处理小型模型时，能够补偿其有限的容量。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a physics-driven contrastive mutual learning method, PCM-SAR, for SAR image classification. PCM-SAR addresses the limitations of existing methods by incorporating domain-specific physical insights to improve sample generation and feature extraction. Utilizing the gray-level co-occurrence matrix (GLCM) and semantic detection, PCM-SAR ensures that the generated samples accurately reflect SAR imaging properties. Furthermore, a multi-level feature fusion mechanism based on mutual learning refines feature representations collaboratively. Notably, PCM-SAR significantly enhances the performance of smaller models by refining SAR feature representations, compensating for their limited capacity. Experimental results demonstrate that PCM-SAR consistently outperforms state-of-the-art (SOTA) methods across diverse datasets and SAR classification tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing SAR image classification methods based on Contrastive Learning oftenrely on sample generation strategies designed for optical images, failing tocapture the distinct semantic and physical characteristics of SAR data. Toaddress this, we propose Physics-Driven Contrastive Mutual Learning for SARClassification (PCM-SAR), which incorporates domain-specific physical insightsto improve sample generation and feature extraction. PCM-SAR utilizes thegray-level co-occurrence matrix (GLCM) to simulate realistic noise patterns andapplies semantic detection for unsupervised local sampling, ensuring generatedsamples accurately reflect SAR imaging properties. Additionally, a multi-levelfeature fusion mechanism based on mutual learning enables collaborativerefinement of feature representations. Notably, PCM-SAR significantly enhancessmaller models by refining SAR feature representations, compensating for theirlimited capacity. Experimental results show that PCM-SAR consistentlyoutperforms SOTA methods across diverse datasets and SAR classification tasks.</description>
      <author>example@mail.com (Pengfei Wang, Hao Zheng, Zhigang Hu, Aikun Xu, Meiguang Zheng, Liu Yang)</author>
      <guid isPermaLink="false">2504.09502v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning</title>
      <link>http://arxiv.org/abs/2504.06958v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用强化学习中的RFT（Reinforcement Fine-Tuning）和GRPO（Group Relative Policy Optimization）方法，对视频多模态大语言模型（MLLMs）进行系统性的探索，旨在提升时空感知能力的同时保持通用能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，强化学习在多模态大语言模型（MLLMs）的推理能力方面取得了显著进展。然而，GRPO和基于规则的奖励机制在文本和图像领域表现出潜力，但在视频理解领域的应用仍然有限。&lt;h4&gt;目的&lt;/h4&gt;通过RFT方法，提升视频MLLMs的时空感知能力，同时保持其通用能力。&lt;h4&gt;方法&lt;/h4&gt;论文通过在时空感知目标上进行多任务RFT，并在有限的样本下进行实验，开发出VideoChat-R1，这是一种强大的视频MLLM，在时空感知任务上达到了最先进的性能，同时不牺牲聊天能力，并展现出时空推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;VideoChat-R1在时空定位（+31.8）和对象跟踪（+31.2）等任务上，相比于Qwen2.5-VL-7B提升了数倍性能。此外，它在VideoMME（+0.9）、MVBench（+1.0）和感知测试（+0.9）等通用QAbenchmarks上也显著改进。&lt;h4&gt;结论&lt;/h4&gt;RFT对于视频MLLMs的特定任务增强具有潜力，研究结果为未来视频MLLMs的RL研究提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a systematic exploration of Reinforcement Fine-Tuning (RFT) with Group Relative Policy Optimization (GRPO) for video multimodal large language models (MLLMs), aiming to enhance spatio-temporal perception while maintaining general capabilities. Our experiments reveal that RFT is highly data-efficient for task-specific improvements. Through multi-task RFT on spatio-temporal perception objectives with limited samples, we develop VideoChat-R1, a powerful video MLLM that achieves state-of-the-art performance on spatio-temporal perception tasks without sacrificing chat ability, while exhibiting emerging spatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1 boosts performance several-fold in tasks like temporal grounding (+31.8) and object tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9). Our findings underscore the potential of RFT for specialized task enhancement of Video MLLMs. We hope our work offers valuable insights for future RL research in video MLLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in reinforcement learning have significantly advanced thereasoning capabilities of multimodal large language models (MLLMs). Whileapproaches such as Group Relative Policy Optimization (GRPO) and rule-basedreward mechanisms demonstrate promise in text and image domains, theirapplication to video understanding remains limited. This paper presents asystematic exploration of Reinforcement Fine-Tuning (RFT) with GRPO for videoMLLMs, aiming to enhance spatio-temporal perception while maintaining generalcapabilities. Our experiments reveal that RFT is highly data-efficient fortask-specific improvements. Through multi-task RFT on spatio-temporalperception objectives with limited samples, we develop VideoChat-R1, a powerfulvideo MLLM that achieves state-of-the-art performance on spatio-temporalperception tasks without sacrificing chat ability, while exhibiting emergingspatio-temporal reasoning abilities. Compared to Qwen2.5-VL-7B, VideoChat-R1boosts performance several-fold in tasks like temporal grounding (+31.8) andobject tracking (+31.2). Additionally, it significantly improves on general QAbenchmarks such as VideoMME (+0.9), MVBench (+1.0), and Perception Test (+0.9).Our findings underscore the potential of RFT for specialized task enhancementof Video MLLMs. We hope our work offers valuable insights for future RLresearch in video MLLMs.</description>
      <author>example@mail.com (Xinhao Li, Ziang Yan, Desen Meng, Lu Dong, Xiangyu Zeng, Yinan He, Yali Wang, Yu Qiao, Yi Wang, Limin Wang)</author>
      <guid isPermaLink="false">2504.06958v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Federated Prototype Graph Learning</title>
      <link>http://arxiv.org/abs/2504.09493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated Graph Learning (FGL)在分布式训练和隐私保护方面具有显著优势，但多级FGL异构性带来了挑战。&lt;h4&gt;背景&lt;/h4&gt;FGL在图机器智能应用中具有分布式训练能力，可以缓解数据孤岛问题，但多级FGL异构性带来了模型、数据和通信层面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出FedPG，一种通用的原型引导优化方法，以解决多级FGL异构性问题。&lt;h4&gt;方法&lt;/h4&gt;在客户端，集成多级拓扑感知原型来捕捉局部图语义；在服务器端，利用上传的原型，采用拓扑引导的对比学习和个性化技术来定制每个客户端的全局原型，并通过广播提高局部训练。&lt;h4&gt;主要发现&lt;/h4&gt;FedPG在准确率上优于现有基准，平均提高了3.57%，同时将通信成本降低了168倍。&lt;h4&gt;结论&lt;/h4&gt;FedPG是解决多级FGL异构性问题的一种有效方法，可以提高性能并降低通信成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Federated Graph Learning (FGL) has gained significantattention for its distributed training capabilities in graph-based machineintelligence applications, mitigating data silos while offering a newperspective for privacy-preserve large-scale graph learning. However,multi-level FGL heterogeneity presents various client-server collaborationchallenges: (1) Model-level: The variation in clients for expected performanceand scalability necessitates the deployment of heterogeneous models.Unfortunately, most FGL methods rigidly demand identical client models due tothe direct model weight aggregation on the server. (2) Data-level: Theintricate nature of graphs, marked by the entanglement of node profiles andtopology, poses an optimization dilemma. This implies that models obtained byfederated training struggle to achieve superior performance. (3)Communication-level: Some FGL methods attempt to increase message sharing amongclients or between clients and the server to improve training, which inevitablyleads to high communication costs. In this paper, we propose FedPG as a generalprototype-guided optimization method for the above multi-level FGLheterogeneity. Specifically, on the client side, we integrate multi-leveltopology-aware prototypes to capture local graph semantics. Subsequently, onthe server side, leveraging the uploaded prototypes, we employ topology-guidedcontrastive learning and personalized technology to tailor global prototypesfor each client, broadcasting them to improve local training. Experimentsdemonstrate that FedPG outperforms SOTA baselines by an average of 3.57\% inaccuracy while reducing communication costs by 168x.</description>
      <author>example@mail.com (Zhengyu Wu, Xunkai Li, Yinlin Zhu, Rong-Hua Li, Guoren Wang, Chenghu Zhou)</author>
      <guid isPermaLink="false">2504.09493v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Distilling and exploiting quantitative insights from Large Language Models for enhanced Bayesian optimization of chemical reactions</title>
      <link>http://arxiv.org/abs/2504.08874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了如何从大型语言模型（LLMs）中提取化学信息用于迁移学习，以加速化学反应的优化。&lt;h4&gt;背景&lt;/h4&gt;机器学习和贝叶斯优化算法可以显著加速化学反应的优化。迁移学习可以通过利用现有化学信息或与直接优化任务无关的数据来提高贝叶斯优化算法在低数据环境下的有效性。&lt;h4&gt;目的&lt;/h4&gt;考察LLM中的化学信息如何被提取并用于迁移学习，以加速通过最大化产量来优化反应条件。&lt;h4&gt;方法&lt;/h4&gt;使用调查式的提示方案和偏好学习来推断效用函数，该效用函数模型化LLM中嵌入在化学参数空间中的先前化学信息；利用效用函数来集中在参数空间的有希望的区域内，从而提高初始贝叶斯优化查询的产量并增强优化。&lt;h4&gt;主要发现&lt;/h4&gt;效用函数与实际实验测量（产量）在参数空间中显示出适度相关性，即使在零样本设置下也是如此；利用效用函数可以增强优化在6个数据集中4个数据集的优化效果。&lt;h4&gt;结论&lt;/h4&gt;这项工作将LLM中嵌入的化学知识与原理性贝叶斯优化方法加速反应优化的能力联系起来，被视为填补这一差距的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning and Bayesian optimization (BO) algorithms can significantlyaccelerate the optimization of chemical reactions. Transfer learning canbolster the effectiveness of BO algorithms in low-data regimes by leveragingpre-existing chemical information or data outside the direct optimization task(i.e., source data). Large language models (LLMs) have demonstrated thatchemical information present in foundation training data can give them utilityfor processing chemical data. Furthermore, they can be augmented with and helpsynthesize potentially multiple modalities of source chemical data germane tothe optimization task. In this work, we examine how chemical information fromLLMs can be elicited and used for transfer learning to accelerate the BO ofreaction conditions to maximize yield. Specifically, we show that a survey-likeprompting scheme and preference learning can be used to infer a utilityfunction which models prior chemical information embedded in LLMs over achemical parameter space; we find that the utility function shows modestcorrelation to true experimental measurements (yield) over the parameter spacedespite operating in a zero-shot setting. Furthermore, we show that the utilityfunction can be leveraged to focus BO efforts in promising regions of theparameter space, improving the yield of the initial BO query and enhancingoptimization in 4 of the 6 datasets studied. Overall, we view this work as astep towards bridging the gap between the chemistry knowledge embedded in LLMsand the capabilities of principled BO methods to accelerate reactionoptimization.</description>
      <author>example@mail.com (Roshan Patel, Saeed Moayedpour, Louis De Lescure, Lorenzo Kogler-Anele, Alan Cherney, Sven Jager, Yasser Jangjou)</author>
      <guid isPermaLink="false">2504.08874v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Application of Contrastive Learning on ECG Data: Evaluating Performance in Japanese and Classification with Around 100 Labels</title>
      <link>http://arxiv.org/abs/2504.09302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了心电图（ECG）在心血管诊断中的应用，探讨了如何利用机器学习从ECG数据中提取信息，以及如何将多模态机器学习框架应用于非英语语言的临床研究。&lt;h4&gt;背景&lt;/h4&gt;ECG是心血管诊断的基本工具，具有强大且非侵入性的特点，常用于确定是否需要更详细的检查。由于用户专业水平各异，避免关键错误变得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过机器学习从ECG数据中提取有价值的信息，并实现多模态模型的分类，以帮助用户避免关键错误。&lt;h4&gt;方法&lt;/h4&gt;研究者使用了来自日本医院的常规患者ECG数据，并利用对比学习框架进行分类。他们使用了一个基于日本的、具有98个标签的语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;即使在只有98个标签的情况下，基于日本的语言模型在分类准确率上与之前的研究相当，这表明了多模态机器学习框架在非英语语言临床研究中的适用性。&lt;h4&gt;结论&lt;/h4&gt;该研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：心电图（ECG）由于其强大且非侵入性的特性，是心血管诊断的基本工具。其最关键的应用之一是确定是否需要更详细的检查，用户涵盖不同专业水平。鉴于这种专业水平的多样性，帮助用户避免关键错误至关重要。近年来，机器学习研究通过从ECG数据中提取有价值信息来解决这一挑战。利用语言模型，这些研究实现了旨在根据标记术语对ECG进行分类的多模态模型。然而，类别数量有所减少，并且这种方法是否适用于英语以外的语言还不确定。为了向实际应用迈进，我们使用了来自日本医院常规患者的ECG数据，并维护了大量从实际ECG读数中获得的日本标签。使用对比学习框架，我们发现即使有98个分类标签，我们的基于日本的语模型也实现了与先前研究相当的准确率。这项研究扩展了多模态机器学习框架在更广泛的临床研究和非英语语言中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The electrocardiogram (ECG) is a fundamental tool in cardiovasculardiagnostics due to its powerful and non-invasive nature. One of the mostcritical usages is to determine whether more detailed examinations arenecessary, with users ranging across various levels of expertise. Given thisdiversity in expertise, it is essential to assist users to avoid criticalerrors. Recent studies in machine learning have addressed this challenge byextracting valuable information from ECG data. Utilizing language models, thesestudies have implemented multimodal models aimed at classifying ECGs accordingto labeled terms. However, the number of classes was reduced, and it remainsuncertain whether the technique is effective for languages other than English.To move towards practical application, we utilized ECG data from regularpatients visiting hospitals in Japan, maintaining a large number of Japaneselabels obtained from actual ECG readings. Using a contrastive learningframework, we found that even with 98 labels for classification, ourJapanese-based language model achieves accuracy comparable to previousresearch. This study extends the applicability of multimodal machine learningframeworks to broader clinical studies and non-English languages.</description>
      <author>example@mail.com (Junichiro Takahashi, JingChuan Guan, Masataka Sato, Kaito Baba, Kazuto Haruguchi, Daichi Nagashima, Satoshi Kodera, Norihiko Takeda)</author>
      <guid isPermaLink="false">2504.09302v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence Augmented Medical Imaging Reconstruction in Radiation Therapy</title>
      <link>http://arxiv.org/abs/2504.08844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一系列基于人工智能的医学影像重建框架，旨在提升放射治疗的效果。&lt;h4&gt;背景&lt;/h4&gt;高效获取和精确重建的影像对于现代放射治疗至关重要，CT和MRI是常见的治疗规划和指导/监测手段。&lt;h4&gt;目的&lt;/h4&gt;设计AI驱动的医学影像重建框架，以提升CT图像重建的质量和速度，优化双能量CT（DECT）的多材料分解（MMD），并显著加速4D MRI的采集。&lt;h4&gt;方法&lt;/h4&gt;利用人工智能技术进行医学影像的重建。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架能够改善CT图像重建质量、提高速度、优化DECT的多材料分解以及加速4D MRI的采集。&lt;h4&gt;结论&lt;/h4&gt;AI驱动的医学影像重建框架对于增强放射治疗具有显著的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Efficiently acquired and precisely reconstructed imaging are crucial to the success of modern radiation therapy (RT). Computed tomography (CT) and magnetic resonance imaging (MRI) are two common modalities for providing RT treatment planning and delivery guidance/monitoring. In recent decades, artificial intelligence (AI) has emerged as a powerful and widely adopted technique across various fields, valued for its efficiency and convenience enabled by implicit function definition and data-driven feature representation learning. Here, we present a series of AI-driven medical imaging reconstruction frameworks for enhanced radiotherapy, designed to improve CT image reconstruction quality and speed, refine dual-energy CT (DECT) multi-material decomposition (MMD), and significantly accelerate 4D MRI acquisition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently acquired and precisely reconstructed imaging are crucial to thesuccess of modern radiation therapy (RT). Computed tomography (CT) and magneticresonance imaging (MRI) are two common modalities for providing RT treatmentplanning and delivery guidance/monitoring. In recent decades, artificialintelligence (AI) has emerged as a powerful and widely adopted technique acrossvarious fields, valued for its efficiency and convenience enabled by implicitfunction definition and data-driven feature representation learning. Here, wepresent a series of AI-driven medical imaging reconstruction frameworks forenhanced radiotherapy, designed to improve CT image reconstruction quality andspeed, refine dual-energy CT (DECT) multi-material decomposition (MMD), andsignificantly accelerate 4D MRI acquisition.</description>
      <author>example@mail.com (Di Xu)</author>
      <guid isPermaLink="false">2504.08844v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Generation of Musical Timbres using a Text-Guided Diffusion Model</title>
      <link>http://arxiv.org/abs/2504.09219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，文本到音频系统在直接从文本描述生成完整音频片段方面取得了显著成功，但往往限制了人类创造性和有意表达。本研究提出了一种系统，允许作曲家、编曲家和表演者创建音乐创作的基本构建块：用于电子乐器和数字音频工作站的音乐音符音频。&lt;h4&gt;背景&lt;/h4&gt;文本到音频系统在音乐创作中的应用日益广泛，但现有系统往往缺乏人类创造性和有意表达。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统，使作曲家、编曲家和表演者能够创建音乐创作的基本音频构建块。&lt;h4&gt;方法&lt;/h4&gt;该系统结合了潜在扩散模型和多模态对比学习，根据文本描述生成音乐音色。该方法通过联合生成频谱图的幅度和相位，消除了后续运行相位检索算法的需要。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种基于文本描述生成音乐音色的系统，该系统通过联合生成频谱图的幅度和相位，无需额外的相位检索算法。&lt;h4&gt;结论&lt;/h4&gt;该系统为音乐创作提供了新的工具，允许用户通过文本提示指定音频的音色特征。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, text-to-audio systems have achieved remarkable success, enabling the generation of complete audio segments directly from text descriptions. While these systems also facilitate music creation, the element of human creativity and deliberate expression is often limited. In contrast, the present work allows composers, arrangers, and performers to create the basic building blocks for music creation: audio of individual musical notes for use in electronic instruments and DAWs. Through text prompts, the user can specify the timbre characteristics of the audio. We introduce a system that combines a latent diffusion model and multi-modal contrastive learning to generate musical timbres conditioned on text descriptions. By jointly generating the magnitude and phase of the spectrogram, our method eliminates the need for subsequently running a phase retrieval algorithm, as related methods do. Audio examples, source code, and a web app are available at https://wxuanyuan.github.io/Musical-Note-Generation/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, text-to-audio systems have achieved remarkable success,enabling the generation of complete audio segments directly from textdescriptions. While these systems also facilitate music creation, the elementof human creativity and deliberate expression is often limited. In contrast,the present work allows composers, arrangers, and performers to create thebasic building blocks for music creation: audio of individual musical notes foruse in electronic instruments and DAWs. Through text prompts, the user canspecify the timbre characteristics of the audio. We introduce a system thatcombines a latent diffusion model and multi-modal contrastive learning togenerate musical timbres conditioned on text descriptions. By jointlygenerating the magnitude and phase of the spectrogram, our method eliminatesthe need for subsequently running a phase retrieval algorithm, as relatedmethods do.  Audio examples, source code, and a web app are available athttps://wxuanyuan.github.io/Musical-Note-Generation/</description>
      <author>example@mail.com (Weixuan Yuan, Qadeer Khan, Vladimir Golkov)</author>
      <guid isPermaLink="false">2504.09219v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Repetitive Contrastive Learning Enhances Mamba's Selectivity in Time Series Prediction</title>
      <link>http://arxiv.org/abs/2504.09185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Repetitive Contrastive Learning (RCL)的框架，旨在增强Mamba模型在时间序列预测中的选择性能力，并通过实验证明了其在提升模型性能方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测是长期序列预测的关键挑战，Mamba模型虽然表现出色，但存在选择性能力不足和噪声抑制不完整的问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决Mamba模型在选择性能力上的不足，提出了RCL框架，旨在增强其选择性能力，并提高时间序列预测的性能。&lt;h4&gt;方法&lt;/h4&gt;RCL通过序列增强和对比学习，使Mamba模块能够优先考虑信息丰富的时步，同时忽略噪声。具体方法包括：对Mamba块进行预训练，并将预训练参数转移到不同的骨干模型中，以及使用高斯噪声进行序列增强。&lt;h4&gt;主要发现&lt;/h4&gt;RCL显著提升了骨干模型的性能，超越了现有方法，并达到了最先进的水平。此外，还提出了两个指标来量化Mamba的选择性能力，为RCL带来的改进提供了理论、定性和定量证据。&lt;h4&gt;结论&lt;/h4&gt;RCL框架有效增强了Mamba模型的选择性能力，显著提升了时间序列预测的性能，为该领域的研究提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long sequence prediction is a key challenge in time series forecasting. WhileMamba-based models have shown strong performance due to their sequenceselection capabilities, they still struggle with insufficient focus on criticaltime steps and incomplete noise suppression, caused by limited selectiveabilities. To address this, we introduce Repetitive Contrastive Learning (RCL),a token-level contrastive pretraining framework aimed at enhancing Mamba'sselective capabilities. RCL pretrains a single Mamba block to strengthen itsselective abilities and then transfers these pretrained parameters toinitialize Mamba blocks in various backbone models, improving their temporalprediction performance. RCL uses sequence augmentation with Gaussian noise andapplies inter-sequence and intra-sequence contrastive learning to help theMamba module prioritize information-rich time steps while ignoring noisy ones.Extensive experiments show that RCL consistently boosts the performance ofbackbone models, surpassing existing methods and achieving state-of-the-artresults. Additionally, we propose two metrics to quantify Mamba's selectivecapabilities, providing theoretical, qualitative, and quantitative evidence forthe improvements brought by RCL.</description>
      <author>example@mail.com (Wenbo Yan, Hanzhong Cao, Ying Tan)</author>
      <guid isPermaLink="false">2504.09185v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Accuracy Limit of Foundation Neural Network Models with Quantum Monte Carlo Forces and Path Integrals</title>
      <link>http://arxiv.org/abs/2504.07948v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种端到端集成策略，旨在生成高精度的量子化学合成数据集（能量和力），用于推导分子模拟的基础机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;基于密度泛函理论（DFT）和大规模GPU加速软件的“雅各布楼梯”方法，在提高计算精度方面取得了进展。&lt;h4&gt;目的&lt;/h4&gt;通过Exascale计算，首次在完全基组极限下进行计算密集型量子蒙特卡罗力（QMC）的计算，以及将多态QMC能量和力与选定的配置相互作用波函数相结合。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习提高基于DFT的FeNNix-Bio1基础模型，并与路径积分自适应采样量子动力学相结合，以进行前所未有的纳米秒级反应模拟。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法展示了Exascale在深化我们对复杂生物系统内部机制理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法有望在分子模拟领域产生重大影响，并为理解复杂生物系统提供新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an end-to-end integrated strategy to produce highly accuratequantum chemistry (QC) synthetic datasets (energies and forces) aimed atderiving Foundation Machine Learning models for molecular simulation. Startingfrom Density Functional Theory (DFT), a "Jacob's Ladder" approach leveragescomputationally-optimized layers of massively GPU-accelerated software withincreasing accuracy. Thanks to Exascale, this is the first time that thecomputationally intensive calculation of Quantum Monte Carlo forces (QMC), andthe combination of multi-determinant QMC energies and forces withselected-Configuration Interaction wavefunctions, are computed at such scale atthe complete basis-set limit. To bridge the gap between accurate QC andcondensed-phase Molecular Dynamics, we leverage transfer learning to improvethe DFT-based FeNNix-Bio1 foundation model. The resulting approach is coupledto path integrals adaptive sampling quantum dynamics to perform nanosecondreactive simulations at unprecedented accuracy. These results demonstrate thepromise of Exascale to deepen our understanding of the inner machinery ofcomplex biosystems.</description>
      <author>example@mail.com (Anouar Benali, Thomas Plé, Olivier Adjoua, Valay Agarawal, Thomas Applencourt, Marharyta Blazhynska, Raymond Clay III, Kevin Gasperich, Khalid Hossain, Jeongnim Kim, Christopher Knight, Jaron T. Krogel, Yvon Maday, Maxime Maria, Matthieu Montes, Ye Luo, Evgeny Posenitskiy, Corentin Villot, Venkatram Vishwanath, Louis Lagardère, Jean-Philip Piquemal)</author>
      <guid isPermaLink="false">2504.07948v3</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>GenEDA: Unleashing Generative Reasoning on Netlist via Multimodal Encoder-Decoder Aligned Foundation Model</title>
      <link>http://arxiv.org/abs/2504.09485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, and 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GenEDA，这是一个将电路编码器与解码器在共享潜在空间中对齐的框架，旨在提高集成电路设计过程的效率。&lt;h4&gt;背景&lt;/h4&gt;现有预训练的电路模型通常仅限于作为预测任务的独立编码器或生成任务的解码器。这两种模型类型独立开发，运行在不同的电路模式上，并位于不同的潜在空间中，这限制了它们在更高级应用中相互补充的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，将电路编码器与解码器在共享潜在空间中对齐，以便在电路设计过程中提供更强大的功能。&lt;h4&gt;方法&lt;/h4&gt;提出两种范式来支持开源可训练的大语言模型和商业冻结的大语言模型。基于对齐的架构，GenEDA能够执行三种前所未有的生成推理任务，从低级别的网表中以不同粒度逆向生成高级功能。&lt;h4&gt;主要发现&lt;/h4&gt;GenEDA将基于图的电路表示与基于文本的大语言模型（LLMs）连接起来，使得它们各自的潜在空间之间能够进行通信。实验表明，GenEDA显著提升了高级LLMs（如GPT-4o和DeepSeek-V3）在所有任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;GenEDA通过共享潜在空间对齐电路编码器与解码器，为集成电路设计提供了一种新的、更有效的工具，并显著提升了LLMs的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of foundation AI has motivated the research of circuit foundationmodels, which are customized to assist the integrated circuit (IC) designprocess. However, existing pre-trained circuit models are typically limited tostandalone encoders for predictive tasks or decoders for generative tasks.These two model types are developed independently, operate on different circuitmodalities, and reside in separate latent spaces, which restricts their abilityto complement each other for more advanced applications. In this work, wepresent GenEDA, the first framework that aligns circuit encoders with decoderswithin a shared latent space. GenEDA bridges the gap between graph-basedcircuit representations and text-based large language models (LLMs), enablingcommunication between their respective latent spaces. To achieve the alignment,we propose two paradigms that support both open-source trainable LLMs andcommercial frozen LLMs. Built on this aligned architecture, GenEDA enablesthree unprecedented generative reasoning tasks over netlists, where the modelreversely generates the high-level functionality from low-level netlists indifferent granularities. These tasks extend traditional gate-type prediction todirect generation of full-circuit functionality. Experiments demonstrate thatGenEDA significantly boosts advanced LLMs' (e.g., GPT-4o and DeepSeek-V3)performance in all tasks.</description>
      <author>example@mail.com (Wenji Fang, Jing Wang, Yao Lu, Shang Liu, Zhiyao Xie)</author>
      <guid isPermaLink="false">2504.09485v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation</title>
      <link>http://arxiv.org/abs/2504.09480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A Review and Evaluation about Vision-Language Model for Object  Detection and Segmentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于视觉-语言模型（VLM）的检测和分割技术进行了系统回顾，评估了VLM在不同下游任务中的效果，并分析了模型架构、任务特性和训练方法之间的关系。&lt;h4&gt;背景&lt;/h4&gt;VLM在开放词汇（OV）物体检测和分割任务中得到了广泛应用，但在传统视觉任务中的有效性尚未得到评估。&lt;h4&gt;目的&lt;/h4&gt;评估VLM在不同检测和分割任务中的表现，并分析其相关因素。&lt;h4&gt;方法&lt;/h4&gt;1）对VLM在不同检测（如封闭集检测、领域自适应、拥挤物体等）和分割（如少样本、开放世界、小物体等）场景中的表现进行了评估；2）对检测任务中的VLM在不同微调粒度（零预测、视觉微调、文本提示）下的表现进行了评估；3）基于实证研究，分析了任务特征、模型架构和训练方法之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;1）揭示了不同VLM架构在不同任务中的性能优势和局限性；2）不同微调策略对性能的影响；3）任务特征、模型架构和训练方法之间存在关联。&lt;h4&gt;结论&lt;/h4&gt;该研究为计算机视觉、多模态学习和视觉基础模型领域的模式识别专家提供了有价值的信息，并指出了未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉-语言模型（VLM）在开放词汇（OV）物体检测和分割任务中得到了广泛应用。尽管它们在OV相关任务中显示出前景，但它们在传统视觉任务中的有效性至今尚未得到评估。在这项工作中，我们进行了基于VLM的检测和分割的系统性回顾，将VLM视为基础模型，并首次对多个下游任务进行了全面评估：1）评估涵盖了八个检测场景（封闭集检测、领域自适应、拥挤物体等）和八个分割场景（少样本、开放世界、小物体等），揭示了不同VLM架构在任务中的不同性能优势和局限性。2）对于检测任务，我们在三个微调粒度下评估了VLM：零预测、视觉微调和文本提示，并进一步分析了不同的微调策略在不同任务下的性能影响。3）基于实证发现，我们对任务特征、模型架构和训练方法之间的关系进行了深入分析，为未来的VLM设计提供了见解。4）我们认为这项工作将对计算机视觉、多模态学习和视觉基础模型领域的模式识别专家有价值，通过介绍他们了解问题，熟悉当前的研究进展，并为其未来的研究提供有希望的方向。与这次回顾和评估相关的项目已在https://github.com/better-chao/perceptual_abilities_evaluation创建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Model (VLM) have gained widespread adoption inOpen-Vocabulary (OV) object detection and segmentation tasks. Despite they haveshown promise on OV-related tasks, their effectiveness in conventional visiontasks has thus far been unevaluated. In this work, we present the systematicreview of VLM-based detection and segmentation, view VLM as the foundationalmodel and conduct comprehensive evaluations across multiple downstream tasksfor the first time: 1) The evaluation spans eight detection scenarios(closed-set detection, domain adaptation, crowded objects, etc.) and eightsegmentation scenarios (few-shot, open-world, small object, etc.), revealingdistinct performance advantages and limitations of various VLM architecturesacross tasks. 2) As for detection tasks, we evaluate VLMs under threefinetuning granularities: \textit{zero prediction}, \textit{visualfine-tuning}, and \textit{text prompt}, and further analyze how differentfinetuning strategies impact performance under varied task. 3) Based onempirical findings, we provide in-depth analysis of the correlations betweentask characteristics, model architectures, and training methodologies, offeringinsights for future VLM design. 4) We believe that this work shall be valuableto the pattern recognition experts working in the fields of computer vision,multimodal learning, and vision foundation models by introducing them to theproblem, and familiarizing them with the current status of the progress whileproviding promising directions for future research. A project associated withthis review and evaluation has been created athttps://github.com/better-chao/perceptual_abilities_evaluation.</description>
      <author>example@mail.com (Yongchao Feng, Yajie Liu, Shuai Yang, Wenrui Cai, Jinqing Zhang, Qiqi Zhan, Ziyue Huang, Hongxi Yan, Qiao Wan, Chenguang Liu, Junzhe Wang, Jiahui Lv, Ziqi Liu, Tengyuan Shi, Qingjie Liu, Yunhong Wang)</author>
      <guid isPermaLink="false">2504.09480v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Effectiveness and Interpretability of Texts in LLM-based Time Series Models</title>
      <link>http://arxiv.org/abs/2504.08808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了将文本数据融入大型语言模型（LLMs）进行时间序列预测的有效性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）被应用于时间序列预测任务，通过利用预训练的语言模型作为基础，并结合文本数据来增强LLMs的综合能力。&lt;h4&gt;目的&lt;/h4&gt;研究旨在调查文本数据融入LLMs进行时间序列预测的实际效果和可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过一系列关于文本提示和文本原型的实证实验，研究者提出了新的指标——语义匹配指数（SMI），用于评估时间序列与文本之间的匹配度。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，两种模态之间存在不匹配，文本信息在许多情况下并没有显著提高时间序列预测的性能。可视化分析表明，现有框架学习到的文本表示在应用于时间序列数据时缺乏足够的可解释性。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了当前时间序列LLMs中文本的不匹配和可解释性有限的问题，并希望这一研究能够提高对文本时间序列可解释性的认识。&lt;h4&gt;翻译&lt;/h4&gt;The study investigates the effectiveness and interpretability of incorporating textual data into large language models (LLMs) for time series forecasting. LLMs have been applied to time series forecasting tasks, leveraging pre-trained language models as the backbone and incorporating textual data to enhance the comprehensive capabilities of LLMs for time series. However, this study aims to investigate the actual efficacy and interpretability of such textual incorporations. Through a series of empirical experiments on textual prompts and textual prototypes, the study reveals the misalignment between two modalities and finds that textual information does not significantly improve time series forecasting performance in many cases. Visualization analysis indicates that the textual representations learned by existing frameworks lack sufficient interpretability when applied to time series data. A novel metric named Semantic Matching Index (SMI) is proposed to better evaluate the matching degree between time series and texts during the post hoc interpretability investigation. The study reveals the misalignment and limited interpretability of texts in current time-series LLMs and hopes to raise awareness of the interpretability of texts for time series. The code is available at https://github.com/zachysun/TS-Lang-Exp.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been applied to time series forecastingtasks, leveraging pre-trained language models as the backbone and incorporatingtextual data to purportedly enhance the comprehensive capabilities of LLMs fortime series. However, are these texts really helpful for interpretation? Thisstudy seeks to investigate the actual efficacy and interpretability of suchtextual incorporations. Through a series of empirical experiments on textualprompts and textual prototypes, our findings reveal that the misalignmentbetween two modalities exists, and the textual information does notsignificantly improve time series forecasting performance in many cases.Furthermore, visualization analysis indicates that the textual representationslearned by existing frameworks lack sufficient interpretability when applied totime series data. We further propose a novel metric named Semantic MatchingIndex (SMI) to better evaluate the matching degree between time series andtexts during our post hoc interpretability investigation. Our analysis revealsthe misalignment and limited interpretability of texts in current time-seriesLLMs, and we hope this study can raise awareness of the interpretability oftexts for time series. The code is available athttps://github.com/zachysun/TS-Lang-Exp.</description>
      <author>example@mail.com (Zhengke Sun, Hangwei Qian, Ivor Tsang)</author>
      <guid isPermaLink="false">2504.08808v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>ReferGPT: Towards Zero-Shot Referring Multi-Object Tracking</title>
      <link>http://arxiv.org/abs/2504.09195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted CVPR 2025 Workshop on Distillation of Foundation Models for  Autonomous Driving&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ReferGPT的新型零样本多目标跟踪框架，该框架通过结合语言理解和目标关联实现基于文本查询的物体跟踪。&lt;h4&gt;背景&lt;/h4&gt;基于文本查询的多目标跟踪任务具有挑战性，因为它需要将语言理解与帧间的目标关联联系起来。现有的方法通常需要监督训练，且在处理开放式查询时可能存在泛化问题。&lt;h4&gt;目的&lt;/h4&gt;提出ReferGPT框架，以实现无需监督训练即可进行多目标跟踪。&lt;h4&gt;方法&lt;/h4&gt;ReferGPT使用一个多模态大型语言模型（MLLM）并赋予其空间知识，使其能够生成3D感知的描述性文本。此外，还提出了一种鲁棒的查询匹配策略，利用基于CLIP的语义编码和模糊匹配将MLLM生成的文本与用户查询关联起来。&lt;h4&gt;主要发现&lt;/h4&gt;在Refer-KITTI、Refer-KITTIv2和Refer-KITTI+数据集上的实验表明，ReferGPT在多目标跟踪任务中取得了与训练方法相当的性能，展示了其在自动驾驶场景中的鲁棒性和零样本能力。&lt;h4&gt;结论&lt;/h4&gt;ReferGPT是一种有效的零样本多目标跟踪框架，适用于无需监督训练的情境，并具有在自动驾驶等领域的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces a novel zero-shot multi-object tracking framework called ReferGPT, which combines language understanding with object association to achieve object tracking based on textual queries.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracking multiple objects based on textual queries is a challenging task thatrequires linking language understanding with object association across frames.Previous works typically train the whole process end-to-end or integrate anadditional referring text module into a multi-object tracker, but they bothrequire supervised training and potentially struggle with generalization toopen-set queries. In this work, we introduce ReferGPT, a novel zero-shotreferring multi-object tracking framework. We provide a multi-modal largelanguage model (MLLM) with spatial knowledge enabling it to generate 3D-awarecaptions. This enhances its descriptive capabilities and supports a moreflexible referring vocabulary without training. We also propose a robustquery-matching strategy, leveraging CLIP-based semantic encoding and fuzzymatching to associate MLLM generated captions with user queries. Extensiveexperiments on Refer-KITTI, Refer-KITTIv2 and Refer-KITTI+ demonstrate thatReferGPT achieves competitive performance against trained methods, showcasingits robustness and zero-shot capabilities in autonomous driving. The codes areavailable on https://github.com/Tzoulio/ReferGPT</description>
      <author>example@mail.com (Tzoulio Chamiti, Leandro Di Bella, Adrian Munteanu, Nikos Deligiannis)</author>
      <guid isPermaLink="false">2504.09195v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Large Self-Supervised Time-Series Models for Transferable Diagnosis in Cross-Aircraft Type Bleed Air System</title>
      <link>http://arxiv.org/abs/2504.09090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于自监督学习的Bleed Air System (BAS)诊断模型，该模型可以将成熟机型（如A320、A330）的诊断知识迁移到新机型（如C919），以提高系统可靠性。&lt;h4&gt;背景&lt;/h4&gt;Bleed Air System对于维持飞行安全和运营效率至关重要，但其故障（如过压、低压和过热）会带来严重风险。当前诊断方法在应用于不同机型时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在开发一种能够将诊断知识从成熟机型迁移到新机型的自监督学习模型。&lt;h4&gt;方法&lt;/h4&gt;本文提出的模型利用自监督预训练学习通用特征表示，无需标注数据，从而在数据稀缺的场景下有效。此外，还引入了跨模型数据集和适用于真实飞行数据的联合基准和异常检测损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够提高异常检测和基准信号预测的准确性，从而提高系统可靠性，并确保在新机型的早期运营阶段提供稳健的支持。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为大型飞行信号模型的研究奠定了基础，并提供了在模型容量和迁移性之间关系方面的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Bleed Air System（BAS）对于维持飞行安全与运营效率至关重要，支持诸如客舱增压、空调和发动机防冰等功能。然而，BAS的故障，包括过压、低压和过热，会带来诸如客舱失压、设备故障或发动机损坏等重大风险。当前的诊断方法在应用于不同飞机类型时面临显著限制，尤其是在缺乏足够运营数据的较新型号上。为了应对这些挑战，本文提出了一种基于自监督学习的基座模型，该模型使得将诊断知识从成熟机型（例如A320、A330）迁移到新机型（例如C919）成为可能。利用自监督预训练，该模型从飞行信号中学习通用的特征表示，而无需标注数据，这使得它在数据稀缺的场景下非常有效。该模型提高了异常检测和基准信号预测，从而增强了系统可靠性。本文引入了跨模型数据集，这是一个用于BAS诊断的自监督学习框架，以及一个针对真实飞行数据的创新性联合基准和异常检测损失函数。这些创新促进了诊断知识在飞机类型间的有效迁移，确保了对新机型早期运营阶段的稳健支持。此外，本文还探讨了模型容量与迁移性之间的关系，为未来关于大规模飞行信号模型的研究提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bleed Air System (BAS) is critical for maintaining flight safety andoperational efficiency, supporting functions such as cabin pressurization, airconditioning, and engine anti-icing. However, BAS malfunctions, includingoverpressure, low pressure, and overheating, pose significant risks such ascabin depressurization, equipment failure, or engine damage. Current diagnosticapproaches face notable limitations when applied across different aircrafttypes, particularly for newer models that lack sufficient operational data. Toaddress these challenges, this paper presents a self-supervised learning-basedfoundation model that enables the transfer of diagnostic knowledge from matureaircraft (e.g., A320, A330) to newer ones (e.g., C919). Leveragingself-supervised pretraining, the model learns universal feature representationsfrom flight signals without requiring labeled data, making it effective indata-scarce scenarios. This model enhances both anomaly detection and baselinesignal prediction, thereby improving system reliability. The paper introduces across-model dataset, a self-supervised learning framework for BAS diagnostics,and a novel Joint Baseline and Anomaly Detection Loss Function tailored toreal-world flight data. These innovations facilitate efficient transfer ofdiagnostic knowledge across aircraft types, ensuring robust support for earlyoperational stages of new models. Additionally, the paper explores therelationship between model capacity and transferability, providing a foundationfor future research on large-scale flight signal models.</description>
      <author>example@mail.com (Yilin Wang, Peixuan Lei, Xuyang Wang, Liangliang Jiang, Liming Xuan, Wei Cheng, Honghua Zhao, Yuanxiang Li)</author>
      <guid isPermaLink="false">2504.09090v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal 3D Genome Pre-training</title>
      <link>http://arxiv.org/abs/2504.09060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MIX-HIC是第一个多模态3D基因组基础模型，它整合了3D基因组结构和表观基因组轨迹，并设计了跨模态交互和映射块，用于准确融合异质语义，显著提高了3D基因组知识聚合的准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习技术在计算生物学中的3D基因组分析任务中取得了显著进展，但对3D基因组知识的整体理解仍处于探索阶段。&lt;h4&gt;目的&lt;/h4&gt;提出MIX-HIC模型，以实现对3D基因组知识的统一和全面语义理解。&lt;h4&gt;方法&lt;/h4&gt;设计了跨模态交互和映射块，并引入了包含超过100万对Hi-C接触图和表观基因组轨迹样本的大规模数据集，用于高质量预训练。&lt;h4&gt;主要发现&lt;/h4&gt;MIX-HIC在多个下游任务中显著超越了现有最先进的方法，为3D基因组研究提供了宝贵资源。&lt;h4&gt;结论&lt;/h4&gt;MIX-HIC模型为3D基因组研究提供了新的方法和工具，有望推动该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques have driven significant progress in variousanalytical tasks within 3D genomics in computational biology. However, aholistic understanding of 3D genomics knowledge remains underexplored. Here, wepropose MIX-HIC, the first multimodal foundation model of 3D genome thatintegrates both 3D genome structure and epigenomic tracks, which obtainsunified and comprehensive semantics. For accurate heterogeneous semanticfusion, we design the cross-modal interaction and mapping blocks for robustunified representation, yielding the accurate aggregation of 3D genomeknowledge. Besides, we introduce the first large-scale dataset comprising over1 million pairwise samples of Hi-C contact maps and epigenomic tracks forhigh-quality pre-training, enabling the exploration of functional implicationsin 3D genomics. Extensive experiments show that MIX-HIC can significantlysurpass existing state-of-the-art methods in diverse downstream tasks. Thiswork provides a valuable resource for advancing 3D genomics research.</description>
      <author>example@mail.com (Minghao Yang, Pengteng Li, Yan Liang, Qianyi Cai, Zhihang Zheng, Shichen Zhang, Pengfei Zhang, Zhi-An Huang, Hui Xiong)</author>
      <guid isPermaLink="false">2504.09060v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Parameter-Free Fine-tuning via Redundancy Elimination for Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了视觉基础模型（VFMs）中的冗余特征，并提出了一种参数免费的微调方法来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;VFMs是各种视觉任务的基础，但它们通常包含大量的特征冗余，这可能限制了它们对新任务的适应性。&lt;h4&gt;目的&lt;/h4&gt;旨在提高VFMs对新任务的适应性和微调效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模型输出差异的通道选择算法，以识别冗余和有效的通道，并通过选择性替换冗余通道来增强预训练特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在域内和域外数据集上均表现出高效性和有效性，并且可以与现有的微调策略（如LoRA、Adapter）无缝集成，进一步提升了已微调模型的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法显著降低了计算和GPU内存开销，为模型微调提供了一种新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Vision foundation models (VFMs) are large pre-trained models that form the backbone of various vision tasks. Fine-tuning VFMs can further unlock their potential for downstream tasks or scenarios. However, VFMs often contain significant feature redundancy, which may limit their adaptability to new tasks. In this paper, we investigate the redundancies in the segment anything model (SAM) and then propose a parameter-free fine-tuning method to address this issue. Unlike traditional fine-tuning methods that adjust parameters, our method emphasizes selecting, reusing, and enhancing pre-trained features, offering a new perspective on model fine-tuning. Specifically, we introduce a channel selection algorithm based on the model's output difference to identify redundant and effective channels. By selectively replacing the redundant channels with more effective ones, we filter out less useful features and reuse the more relevant features to downstream tasks, thereby enhancing the task-specific feature representation. Experiments on both out-of-domain and in-domain datasets demonstrate the efficiency and effectiveness of our method. Notably, our approach can seamlessly integrate with existing fine-tuning strategies (e.g., LoRA, Adapter), further boosting the performance of already fine-tuned models. Moreover, since our channel selection involves only model inference, our method significantly reduces computational and GPU memory overhead.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) are large pre-trained models that form thebackbone of various vision tasks. Fine-tuning VFMs can further unlock theirpotential for downstream tasks or scenarios. However, VFMs often containsignificant feature redundancy, which may limit their adaptability to newtasks. In this paper, we investigate the redundancies in the segment anythingmodel (SAM) and then propose a parameter-free fine-tuning method to addressthis issue. Unlike traditional fine-tuning methods that adjust parameters, ourmethod emphasizes selecting, reusing, and enhancing pre-trained features,offering a new perspective on model fine-tuning. Specifically, we introduce achannel selection algorithm based on the model's output difference to identifyredundant and effective channels. By selectively replacing the redundantchannels with more effective ones, we filter out less useful features and reusethe more relevant features to downstream tasks, thereby enhancing thetask-specific feature representation. Experiments on both out-of-domain andin-domain datasets demonstrate the efficiency and effectiveness of our method.Notably, our approach can seamlessly integrate with existing fine-tuningstrategies (e.g., LoRA, Adapter), further boosting the performance of alreadyfine-tuned models. Moreover, since our channel selection involves only modelinference, our method significantly reduces computational and GPU memoryoverhead.</description>
      <author>example@mail.com (Jiahuan Long, Tingsong Jiang, Wen Yao, Yizhe Xiong, Zhengqin Xu, Shuai Jia, Chao Ma)</author>
      <guid isPermaLink="false">2504.08915v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>InfoGain Wavelets: Furthering the Design of Diffusion Wavelets for Graph-Structured Data</title>
      <link>http://arxiv.org/abs/2504.08802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work was accepted to be presented at the Graph Signal Processing  Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于信息理论的新方法来选择扩散尺度，以从不同分辨率提取图信号信息。&lt;h4&gt;背景&lt;/h4&gt;扩散小波通过使用不同幂次的图扩散算子（称为扩散尺度）从图信号中提取信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来选择扩散尺度。&lt;h4&gt;方法&lt;/h4&gt;该方法基于信息理论，并展示了如何将其整合到基于小波的图神经网络中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够通过图分类实验整合到波let-based GNNs中。&lt;h4&gt;结论&lt;/h4&gt;该研究为图信号处理提供了一种新的无监督选择扩散尺度的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散小波通过利用不同幂次的图扩散算子（称为扩散尺度）从不同分辨率提取图信号信息。传统上，扩散尺度被选为二进制整数（2^j）。在这里，我们提出了一种基于信息理论的新颖无监督方法来选择扩散尺度。然后，我们展示了该方法可以通过图分类实验整合到基于小波的图神经网络中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion wavelets extract information from graph signals at different scalesof resolution by utilizing graph diffusion operators raised to various powers,known as diffusion scales. Traditionally, the diffusion scales are chosen to bedyadic integers, $\mathbf{2^j}$. Here, we propose a novel, unsupervised methodfor selecting the diffusion scales based on ideas from information theory. Wethen show that our method can be incorporated into wavelet-based GNNs via graphclassification experiments.</description>
      <author>example@mail.com (David R. Johnson, Smita Krishnaswamy, Michael Perlmutter)</author>
      <guid isPermaLink="false">2504.08802v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Robust SAM: On the Adversarial Robustness of Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2504.08906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对Segment Anything Model (SAM)的对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;SAM是一个广泛应用于图像分割、检测和跟踪等领域的视觉基础模型。然而，关于SAM鲁棒性的研究还处于早期阶段，现有攻击方法往往忽略了提示在评估SAM鲁棒性中的作用，且对防御方法的探索不足。&lt;h4&gt;目的&lt;/h4&gt;为了填补这些空白，本文提出了一个对抗鲁棒性框架，旨在评估和增强SAM的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文引入了一种跨提示攻击方法来提高攻击在不同提示类型之间的可迁移性。此外，还提出了一种参数适应策略来防御SAM的各种对抗攻击。为了平衡鲁棒性和准确性，使用奇异值分解（SVD）来约束可训练参数的空间，其中只有奇异值是可调整的。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的跨提示攻击方法在SAM和SAM 2上的攻击成功率优于先前的方法。通过仅调整512个参数，我们实现了至少15%的平均交并率（mIoU）的提升，对抗各种对抗攻击。与先前的方法相比，该方法在增强SAM鲁棒性的同时，最大限度地保持了其原始性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法有效地提高了SAM的鲁棒性，同时保持了其性能，为SAM在实际应用中的部署提供了保障。&lt;h4&gt;翻译&lt;/h4&gt;The Segment Anything Model (SAM) is a widely used vision foundation model with diverse applications, including image segmentation, detection, and tracking. Given SAM's wide applications, understanding its robustness against adversarial attacks is crucial for real-world deployment. However, research on SAM's robustness is still in its early stages. Existing attacks often overlook the role of prompts in evaluating SAM's robustness, and there has been insufficient exploration of defense methods to balance the robustness and accuracy. To address these gaps, this paper proposes an adversarial robustness framework designed to evaluate and enhance the robustness of SAM. Specifically, we introduce a cross-prompt attack method to enhance the attack transferability across different prompt types. Besides attacking, we propose a few-parameter adaptation strategy to defend SAM against various adversarial attacks. To balance robustness and accuracy, we use the singular value decomposition (SVD) to constrain the space of trainable parameters, where only singular values are adaptable. Experiments demonstrate that our cross-prompt attack method outperforms previous approaches in terms of attack success rate on both SAM and SAM 2. By adapting only 512 parameters, we achieve at least a 15% improvement in mean intersection over union (mIoU) against various adversarial attacks. Compared to previous defense methods, our approach enhances the robustness of SAM while maximally maintaining its original performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM) is a widely used vision foundation modelwith diverse applications, including image segmentation, detection, andtracking. Given SAM's wide applications, understanding its robustness againstadversarial attacks is crucial for real-world deployment. However, research onSAM's robustness is still in its early stages. Existing attacks often overlookthe role of prompts in evaluating SAM's robustness, and there has beeninsufficient exploration of defense methods to balance the robustness andaccuracy. To address these gaps, this paper proposes an adversarial robustnessframework designed to evaluate and enhance the robustness of SAM. Specifically,we introduce a cross-prompt attack method to enhance the attack transferabilityacross different prompt types. Besides attacking, we propose a few-parameteradaptation strategy to defend SAM against various adversarial attacks. Tobalance robustness and accuracy, we use the singular value decomposition (SVD)to constrain the space of trainable parameters, where only singular values areadaptable. Experiments demonstrate that our cross-prompt attack methodoutperforms previous approaches in terms of attack success rate on both SAM andSAM 2. By adapting only 512 parameters, we achieve at least a 15\% improvementin mean intersection over union (mIoU) against various adversarial attacks.Compared to previous defense methods, our approach enhances the robustness ofSAM while maximally maintaining its original performance.</description>
      <author>example@mail.com (Jiahuan Long, Zhengqin Xu, Tingsong Jiang, Wen Yao, Shuai Jia, Chao Ma, Xiaoqian Chen)</author>
      <guid isPermaLink="false">2504.08906v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Position: Beyond Euclidean -- Foundation Models Should Embrace Non-Euclidean Geometries</title>
      <link>http://arxiv.org/abs/2504.08896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了在大型语言模型和基础模型时代，欧几里得空间在机器学习架构中的应用及其局限性，并提出了非欧几里得几何在模型中的必要性。&lt;h4&gt;背景&lt;/h4&gt;在当前机器学习领域，欧几里得空间是主流的几何设置。然而，现实世界数据往往具有非欧几里得结构，如多向关系、层次结构、对称性和非各向同性尺度。&lt;h4&gt;目的&lt;/h4&gt;提出超越欧几里得几何是必要的，以维持下一代基础模型的扩展规律。&lt;h4&gt;方法&lt;/h4&gt;通过理论研究和实证调查来支持这一观点，并概述了将非欧几里得几何整合到基础模型中的路线图，包括通过微调、从头训练和混合方法构建几何基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;欧几里得空间难以有效捕捉现实世界数据中的非欧几里得结构，而采用非欧几里得几何可以更有效地利用这些结构。&lt;h4&gt;结论&lt;/h4&gt;非欧几里得几何对于下一代基础模型的发展至关重要，任务感知适应性可以进一步提高效率和表达性。&lt;h4&gt;翻译&lt;/h4&gt;In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of foundation models and Large Language Models (LLMs), Euclideanspace has been the de facto geometric setting for machine learningarchitectures. However, recent literature has demonstrated that this choicecomes with fundamental limitations. At a large scale, real-world data oftenexhibit inherently non-Euclidean structures, such as multi-way relationships,hierarchies, symmetries, and non-isotropic scaling, in a variety of domains,such as languages, vision, and the natural sciences. It is challenging toeffectively capture these structures within the constraints of Euclideanspaces. This position paper argues that moving beyond Euclidean geometry is notmerely an optional enhancement but a necessity to maintain the scaling law forthe next-generation of foundation models. By adopting these geometries,foundation models could more efficiently leverage the aforementionedstructures. Task-aware adaptability that dynamically reconfigures embeddings tomatch the geometry of downstream applications could further enhance efficiencyand expressivity. Our position is supported by a series of theoretical andempirical investigations of prevalent foundation models.Finally, we outline aroadmap for integrating non-Euclidean geometries into foundation models,including strategies for building geometric foundation models via fine-tuning,training from scratch, and hybrid approaches.</description>
      <author>example@mail.com (Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Menglin Yang, Irwin King, Melanie Weber, Rex Ying)</author>
      <guid isPermaLink="false">2504.08896v1</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    <item>
      <title>Neural Encoding and Decoding at Scale</title>
      <link>http://arxiv.org/abs/2504.08201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为NEDS的多模态、多任务模型，旨在同时进行大规模的神经编码和解码，以更好地理解神经活动和行为之间的关系。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模模型要么从行为预测神经活动（编码），要么从神经活动预测行为（解码），限制了它们捕捉神经活动和行为之间双向关系的能力。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一差距，研究引入了NEDS模型，以实现神经编码和解码的同步进行。&lt;h4&gt;方法&lt;/h4&gt;NEDS模型的核心是一个新颖的多任务掩码策略，该策略在神经、行为、同一模态和跨模态掩码之间交替。该方法在包含83只动物进行相同视觉决策任务的重复站点数据集上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;与其它大规模模型相比，NEDS在预训练于多动物数据并在新动物上微调后，在编码和解码方面均达到了最先进的性能。此外，NEDS学习到的嵌入表现出涌现性质，即使没有明确的训练，它们也能高度预测每条记录中的大脑区域。&lt;h4&gt;结论&lt;/h4&gt;这一方法朝着构建一个能够无缝翻译神经活动和行为的脑部基础模型迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-04-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has demonstrated that large-scale, multi-animal models arepowerful tools for characterizing the relationship between neural activity andbehavior. Current large-scale approaches, however, focus exclusively on eitherpredicting neural activity from behavior (encoding) or predicting behavior fromneural activity (decoding), limiting their ability to capture the bidirectionalrelationship between neural activity and behavior. To bridge this gap, weintroduce a multimodal, multi-task model that enables simultaneous NeuralEncoding and Decoding at Scale (NEDS). Central to our approach is a novelmulti-task-masking strategy, which alternates between neural, behavioral,within-modality, and cross-modality masking. We pretrain our method on theInternational Brain Laboratory (IBL) repeated site dataset, which includesrecordings from 83 animals performing the same visual decision-making task. Incomparison to other large-scale models, we demonstrate that NEDS achievesstate-of-the-art performance for both encoding and decoding when pretrained onmulti-animal data and then fine-tuned on new animals. Surprisingly, NEDS'slearned embeddings exhibit emergent properties: even without explicit training,they are highly predictive of the brain regions in each recording. Altogether,our approach is a step towards a foundation model of the brain that enablesseamless translation between neural activity and behavior.</description>
      <author>example@mail.com (Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, The International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz)</author>
      <guid isPermaLink="false">2504.08201v2</guid>
      <pubDate>Tue, 15 Apr 2025 14:28:49 +0800</pubDate>
    </item>
    </channel>
</rss>