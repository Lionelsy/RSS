<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 25 Feb 2025 19:23:13 +0800</lastBuildDate>
    <item>
      <title>Building reliable sim driving agents by scaling self-play</title>
      <link>http://arxiv.org/abs/2502.14706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于大规模自我游戏训练的方法，旨在提高模拟代理的可靠性，并应用于Waymo开放运动数据集中的数千个场景。&lt;h4&gt;背景&lt;/h4&gt;设计和测试与人类交互的系统（如自动驾驶汽车）时需要可靠的仿真代理。这些代理在评估自动驾驶性能、压力测试等方面都有应用，但所有用例都需要高度可靠的表现，以确保分析的有效性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够解决大规模训练集并在未见过的场景中有效推广的方法，并展示其对分布外场景的部分鲁棒性以及通过微调快速达到近乎完美表现的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自我游戏的大规模训练策略，利用Waymo开放运动数据集中的数千个半现实主义限制造成的场景进行训练。所有训练均在单GPU上从零开始完成，并且能够在一天内几乎解决整个训练集。&lt;h4&gt;主要发现&lt;/h4&gt;经过训练的代理能够达到99.8%的目标完成率，在10,000个未见过的场景中，碰撞和脱轨事件的发生率低于0.8%，展示了有效的推广能力。此外，这些代理对分布外场景表现出部分鲁棒性，并且可以通过微调在几分钟内实现近乎完美的性能。&lt;h4&gt;结论&lt;/h4&gt;通过开放源代码库提供了预训练的代理以及完整的代码基础，以便于研究者进一步探索和改进仿真代理技术。&lt;h4&gt;翻译&lt;/h4&gt;该论文探讨了如何通过大规模自我游戏来提升自动驾驶车辆等与人类交互系统的模拟代理的可靠性。通过对Waymo Open Motion Dataset进行半现实限制造成的大规模场景训练，在单GPU上从零开始训练的代理能够实现高可靠性和有效推广，同时展示出对分布外情况的部分鲁棒性，并可以通过快速微调达到近乎完美的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation agents are essential for designing and testing systems thatinteract with humans, such as autonomous vehicles (AVs). These agents servevarious purposes, from benchmarking AV performance to stress-testing thesystem's limits, but all use cases share a key requirement: reliability. Asimulation agent should behave as intended by the designer, minimizingunintended actions like collisions that can compromise the signal-to-noiseratio of analyses. As a foundation for reliable sim agents, we propose scalingself-play to thousands of scenarios on the Waymo Open Motion Dataset undersemi-realistic limits on human perception and control. Training from scratch ona single GPU, our agents nearly solve the full training set within a day. Theygeneralize effectively to unseen test scenes, achieving a 99.8% goal completionrate with less than 0.8% combined collision and off-road incidents across10,000 held-out scenarios. Beyond in-distribution generalization, our agentsshow partial robustness to out-of-distribution scenes and can be fine-tuned inminutes to reach near-perfect performance in those cases. Demonstrations ofagent behaviors can be found at this link. We open-source both the pre-trainedagents and the complete code base. Demonstrations of agent behaviors can befound at \url{https://sites.google.com/view/reliable-sim-agents}.</description>
      <author>example@mail.com (Daphne Cornelisse, Aarav Pandya, Kevin Joseph, Joseph Suárez, Eugene Vinitsky)</author>
      <guid isPermaLink="false">2502.14706v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
  <item>
      <title>Enhancing CoMP-RSMA Performance with Movable Antennas: A Meta-Learning Optimization Framework</title>
      <link>http://arxiv.org/abs/2502.17389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本研究探讨了一种下行链路速率分割多址接入（RSMA）场景，在该场景中，多个基站采用协同多点（CoMP）传输方案为配备移动天线（MA）技术的用户提供服务。与传统的固定位置天线（FPA）相比，后者受无线信道随机变化的影响，MAs可以战略性地重新定位到信道条件更优的位置，从而实现增强的空间分集增益。&lt;h4&gt;背景&lt;/h4&gt;在传统FPA受限于无线信道随机性的情况下，移动天线技术通过优化位置来改善无线通信性能。这种改进带来了更高的空间多样性收益，并且可以通过调整基站的发射波束成形矢量、不同用户的公共流分配以及MA的最佳定位进一步提高总的可达和速率。&lt;h4&gt;目的&lt;/h4&gt;为了最大化可达到的总速率并确保符合服务质量（QoS）约束，研究提出一个优化问题以确定BS的最佳传输波束形成矢量、各用户之间的共同流分配以及移动天线的最优位置。但该问题由于变量间的强依赖关系而复杂且计算上具有挑战性。&lt;h4&gt;方法&lt;/h4&gt;为了解决大规模优化任务中的计算难题，提出了一种无需预训练的基于梯度的元学习（GML）算法，这种方法特别适合于处理大型优化任务，并通过数值结果证明了其有效性和准确性。该方法能够实现接近最优的结果（与最佳解决方案相比超过97%）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，移动天线增强型CoMP-RSMA模型在性能上显著优于传统基准方案，在空间分割多址接入(SDMA)方案和基于固定位置天线的RSMA模型上分别实现了高达190%和80%的性能提升。此外，该方法能够减轻SDMA中总速率受限于干扰的问题，并通过较少的基站实现更优表现。&lt;h4&gt;结论&lt;/h4&gt;所提出的GML算法在优化移动天线增强型CoMP-RSMA场景中的总体可达速率方面取得了显著成效，特别是在处理大规模复杂优化问题时展示了其优越性。该研究为未来的无线通信系统设计提供了一种有效的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates a downlink rate-splitting multiple access (RSMA)scenario in which multiple base stations (BSs), employing a coordinatedmulti-point (CoMP) transmission scheme, serve users equipped with movableantenna (MA) technology. Unlike traditional fixed-position antennas (FPAs),which are subject to random variations in wireless channels, MAs can bestrategically repositioned to locations with more favorable channel conditions,thereby achieving enhanced spatial diversity gains.To leverage these advantagesand maximize the achievable sum rate, we formulate an optimization problem thatjointly determines the optimal transmit beamforming vectors at the BSs, thecommon stream allocation for different users, and the optimal positioning ofthe MAs, all while ensuring compliance with quality of service (QoS)constraints. However, the formulated problem is non-convex and computationallychallenging due to the strong interdependence among the optimization variables.Traditional methods for solving large-scale optimization problems typicallyincur prohibitively high computational complexity. To address the abovechallenge, we propose a gradient-based meta-learning (GML) algorithm thatoperates without pre-training and is well-suited for handling large-scaleoptimization tasks. Numerical results demonstrate the effectiveness andaccuracy of the proposed approach, achieving near-optimal performance(exceeding 97% compared to the optimal solution). Moreover, the MA-enabledCoMP-RSMA model significantly outperforms conventional benchmark schemes,yielding performance gains of up to 190% over the spatial division multipleaccess (SDMA) scheme and 80% over the RSMA FPA-based model. Finally, theproposed approach is shown to mitigate the sum-rate limitations imposed byinterference in SDMA, achieving superior performance with fewer BSs.</description>
      <author>example@mail.com (Ali Amhaz, Shreya Khisa, Mohamed Elhattab, Chadi Assi, Sanaa Sharafeddine)</author>
      <guid isPermaLink="false">2502.17389v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Sustainable Greenhouse Management: A Comparative Analysis of Recurrent and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.17371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种使用时空图神经网络（STGNN）对温室微气候进行建模的新方法，与传统的递归神经网络（RNN）相比，该方法在考虑环境变量之间的空间依赖关系及其方向性方面具有优势。&lt;h4&gt;背景&lt;/h4&gt;将光伏系统集成到温室中可以优化土地利用并促进可持续农业实践，同时提供食品生产和可再生能源发电的双重效益。然而，准确预测内部环境条件对于确保作物生长最佳和最大化能源生产至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过引入STGNN方法来改善温室微气候建模，提高对环境变量间空间依赖关系的理解，并在传统RNN模型的基础上进一步优化性能。&lt;h4&gt;方法&lt;/h4&gt;论文使用从希腊沃洛斯的一个温室每15分钟收集的高频数据进行实验。这些数据用于评估STGNN和RNN在不同季节条件下的表现差异。&lt;h4&gt;主要发现&lt;/h4&gt;RNN模型在冬季条件下表现出卓越的准确性（R^2 = 0.985），但在夏季冷却系统运行期间显示出局限性；相比之下，尽管目前STGNN的表现略低（冬季R^2 = 0.947），但其架构为整合诸如光伏发电和作物生长指标等额外变量提供了更大的潜力。&lt;h4&gt;结论&lt;/h4&gt;虽然现有的STGNN模型在性能上不如传统RNN，在温室微气候建模方面表现出一定的限制，但是考虑到它们在未来应用中的潜在优势，研究认为进一步探索STGNN的应用是值得的。&lt;h4&gt;翻译&lt;/h4&gt;该摘要描述了将时空图神经网络应用于温室内部环境条件预测的研究成果。论文通过对比分析不同模型在特定时间段内的表现，强调了STGNN的独特优势和未来可能的发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of photovoltaic (PV) systems into greenhouses not onlyoptimizes land use but also enhances sustainable agricultural practices byenabling dual benefits of food production and renewable energy generation.However, accurate prediction of internal environmental conditions is crucial toensure optimal crop growth while maximizing energy production. This studyintroduces a novel application of Spatio-Temporal Graph Neural Networks(STGNNs) to greenhouse microclimate modeling, comparing their performance withtraditional Recurrent Neural Networks (RNNs). While RNNs excel at temporalpattern recognition, they cannot explicitly model the directional relationshipsbetween environmental variables. Our STGNN approach addresses this limitationby representing these relationships as directed graphs, enabling the model tocapture both spatial dependencies and their directionality. Usinghigh-frequency data collected at 15-minute intervals from a greenhouse inVolos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winterconditions (R^2 = 0.985) but show limitations during summer cooling systemoperation. Though STGNNs currently show lower performance (winter R^2 = 0.947),their architecture offers greater potential for integrating additionalvariables such as PV generation and crop growth indicators.</description>
      <author>example@mail.com (Emiliano Seri, Marcello Petitta, Cristina Cornaro)</author>
      <guid isPermaLink="false">2502.17371v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation</title>
      <link>http://arxiv.org/abs/2502.17349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种名为HybridLinker的框架，旨在解决药物设计中分子片段组合生成的有效性和多样性之间的权衡问题。&lt;h4&gt;背景&lt;/h4&gt;在药物发现应用如先导优化和PROTAC设计过程中，链接子生成是关键步骤。现有方法主要分为PC-Free（不使用3D点云）和PC-Aware（依赖于3D点云约束）两类。前者注重多样性但有效性较低；后者确保高有效性但限制了多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外训练就能提高有效性和多样性的新框架HybridLinker。&lt;h4&gt;方法&lt;/h4&gt;通过将预训练的PC-Free模型提供的多样化键合拓扑结构作为指导，增强了PC-Aware模型的推理能力。核心是提出了首个跨PC-Free和PC-Aware空间的操作的方法——LinkerDPS（链接子扩散后验采样），利用能量启发式函数连接分子拓扑与3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;HybridLinker框架通过将PC-Free模型中多样化的采样分布转换为PC-Aware模型中的分布，显著且一致地提高了基础分子设计和应用属性优化任务的有效性和多样性。&lt;h4&gt;结论&lt;/h4&gt;本文建立了一种新的扩散后验采样（DPS）框架，在分子和图域内超越了成像领域，具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;链接子生成在药物发现中的先导优化和PROTAC设计等应用中至关重要。现有的方法根据是否使用3D点云划分为PC-Free和PC-Aware两类。前者追求多样性但有效性较低；后者确保高有效性但限制了多样性。为解决此权衡问题，我们提出了HybridLinker框架，通过引入预训练的PC-Free模型提供的多样化键合拓扑结构来增强PC-Aware模型的推理能力。我们的核心贡献是提出了一种新的扩散后验采样方法LinkerDPS，在分子和图域内建立了有效的连接，显著提高了有效性和多样性，开创了新的研究领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Linker generation is critical in drug discovery applications such as leadoptimization and PROTAC design, where molecular fragments are assembled intodiverse drug candidates. Existing methods fall into PC-Free and PC-Awarecategories based on their use of 3D point clouds (PC). PC-Free modelsprioritize diversity but suffer from lower validity due to overlooking PCconstraints, while PC-Aware models ensure higher validity but restrictdiversity by enforcing strict PC constraints. To overcome these trade-offswithout additional training, we propose HybridLinker, a framework that enhancesPC-Aware inference by providing diverse bonding topologies from a pretrainedPC-Free model as guidance. At its core, we propose LinkerDPS, the firstdiffusion posterior sampling (DPS) method operating across PC-Free and PC-Awarespaces, bridging molecular topology with 3D point clouds via an energy-inspiredfunction. By transferring the diverse sampling distribution of PC-Free modelsinto the PC-Aware distribution, HybridLinker significantly and consistentlysurpasses baselines, improving both validity and diversity in foundationalmolecular design and applied property optimization tasks, establishing a newDPS framework in the molecular and graph domains beyond imaging.</description>
      <author>example@mail.com (Minyeong Hwang, Ziseok Lee, Gwangsoo Kim, Kyungsu Kim, Eunho Yang)</author>
      <guid isPermaLink="false">2502.17349v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>LCV2I: Communication-Efficient and High-Performance Collaborative Perception Framework with Low-Resolution LiDAR</title>
      <link>http://arxiv.org/abs/2502.17039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种新的车辆到基础设施（V2I）协同感知框架LCV2I，该框架使用低成本低分辨率激光雷达和摄像头数据来提高协作感知的性能。&lt;h4&gt;背景&lt;/h4&gt;当前V2I合作感知系统主要依赖于高成本的高分辨率激光雷达，但这种传感器价格昂贵且难以普及。同时，传统通信方法带宽利用率较低。&lt;h4&gt;目的&lt;/h4&gt;为了实现低成本的V2I协同感知，研究旨在降低车辆端使用高分辨率激光雷达的成本，并提高数据传输效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架LCV2I，该框架采用低分辨率激光雷达和摄像头的数据作为输入，并利用特征偏移校正模块和区域特征增强算法来改进特征表示。此外，通过区域差异图和区域评分图评估协作内容的价值，从而提高通信带宽效率。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的LCV2I方法在保持高水平感知性能的同时，显著减少了对车辆端高分辨率传感器的需求，并且在真实世界场景中的3D目标检测测试中超越了现有算法的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究成功开发了一种高效的低成本V2I协同感知框架，能够通过低分辨率激光雷达和摄像头的数据实现高质量的感知结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle-to-Infrastructure (V2I) collaborative perception leverages datacollected by infrastructure's sensors to enhance vehicle perceptualcapabilities. LiDAR, as a commonly used sensor in cooperative perception, iswidely equipped in intelligent vehicles and infrastructure. However, itssuperior performance comes with a correspondingly high cost. To achievelow-cost V2I, reducing the cost of LiDAR is crucial. Therefore, we studyadopting low-resolution LiDAR on the vehicle to minimize cost as much aspossible. However, simply reducing the resolution of vehicle's LiDAR results insparse point clouds, making distant small objects even more blurred.Additionally, traditional communication methods have relatively low bandwidthutilization efficiency. These factors pose challenges for us. To balance costand perceptual accuracy, we propose a new collaborative perception framework,namely LCV2I. LCV2I uses data collected from cameras and low-resolution LiDARas input. It also employs feature offset correction modules and regionalfeature enhancement algorithms to improve feature representation. Finally, weuse regional difference map and regional score map to assess the value ofcollaboration content, thereby improving communication bandwidth efficiency. Insummary, our approach achieves high perceptual performance while substantiallyreducing the demand for high-resolution sensors on the vehicle. To evaluatethis algorithm, we conduct 3D object detection in the real-world scenario ofDAIR-V2X, demonstrating that the performance of LCV2I consistently surpassescurrently existing algorithms.</description>
      <author>example@mail.com (Xinxin Feng, Haoran Sun, Haifeng Zheng, Huacong Chen, Wenqiang Chen)</author>
      <guid isPermaLink="false">2502.17039v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning from weakly-labeled audio segments for musical version matching</title>
      <link>http://arxiv.org/abs/2502.16936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 6 figures, 7 tables; includes Appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;检测音乐版本是一项具有挑战性的任务，现有方法通常在曲目级别上匹配音乐版本，而实际应用中需要在片段级别进行匹配。&lt;h4&gt;背景描述&lt;/h4&gt;现有的音乐版本检测技术大多基于整个音频文件的完全标注，并使用分类和三元组损失等传统方法，忽略了更现代的损失函数可能带来的改进。&lt;h4&gt;研究目的&lt;/h4&gt;开发一种可以在弱监督学习条件下工作的新方法，该方法利用对比损失变体在片段级别上提高性能。&lt;h4&gt;主要方法&lt;/h4&gt;{'弱标记段学习': '基于成对的音乐片段距离减少进行训练', '对比损失修改': '通过解耦、超参数和几何学考虑改进现有损失函数'}&lt;h4&gt;关键发现&lt;/h4&gt;提出的方法不仅在标准曲目级评估中达到了最先进的性能，在片段级别上也实现了突破性的效果。&lt;h4&gt;结论&lt;/h4&gt;由于所解决问题的通用性，该方法可能超越音频或音乐版本匹配领域，在其他领域找到应用价值。&lt;h4&gt;翻译&lt;/h4&gt;检测音乐版本是一项具有挑战性的任务，并且具有重要的实际应用场景。现有的方法通常基于完全标注数据进行曲目级别的匹配（例如整首歌曲）。然而大多数实际应用场景需要在片段级别上进行匹配（例如20秒的音频段落）。此外，现有研究大多依赖于分类和三元组损失函数，而忽视了更现代的损失函数可能带来的性能提升。本文中我们提出了一种基于弱监督学习的新型方法以及一种改进的对比损失变体，在片段级别的评估上达到了前所未有的性能水平，并且在传统的曲目级别评估上也取得了领先的结果。我们认为由于所解决问题的普遍性，该方法有望在音频或音乐版本匹配之外的其他领域找到应用机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting musical versions (different renditions of the same piece) is achallenging task with important applications. Because of the ground truthnature, existing approaches match musical versions at the track level (e.g.,whole song). However, most applications require to match them at the segmentlevel (e.g., 20s chunks). In addition, existing approaches resort toclassification and triplet losses, disregarding more recent losses that couldbring meaningful improvements. In this paper, we propose a method to learn fromweakly annotated segments, together with a contrastive loss variant thatoutperforms well-studied alternatives. The former is based on pairwise segmentdistance reductions, while the latter modifies an existing loss followingdecoupling, hyper-parameter, and geometric considerations. With these twoelements, we do not only achieve state-of-the-art results in the standardtrack-level evaluation, but we also obtain a breakthrough performance in asegment-level evaluation. We believe that, due to the generality of thechallenges addressed here, the proposed methods may find utility in domainsbeyond audio or musical version matching.</description>
      <author>example@mail.com (Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2502.16936v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models are Powerful EHR Encoders</title>
      <link>http://arxiv.org/abs/2502.17403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探索了使用通用大型语言模型（LLM）嵌入方法作为电子健康记录（EHR）编码器的潜力，特别是在临床预测任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;电子健康记录数据复杂且异质性高，传统机器学习方法难以有效利用这些资源。领域特定的EHR基础模型虽然在提高预测准确性方面表现出色，但其训练受到高质量多样化数据集有限和编码标准不一致的影响。&lt;h4&gt;目的&lt;/h4&gt;评估通用LLM嵌入方法作为EHR编码器的有效性和潜在优势。&lt;h4&gt;方法&lt;/h4&gt;通过将患者记录转换为结构化的Markdown文本并利用预训练的大型语言模型（GTE-Qwen2-7B-Instruct和LLM2Vec-Llama3.1-8B-Instruct）进行代码转译，研究者在EHRSHOT基准测试的15个不同临床预测任务上比较了这些方法与特定于EHR的基础模型CLIMBR-T-Base及传统机器学习基线的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在少量样本的情况下，LLM基于嵌入的方法经常能够达到甚至超过专门模型的性能，并且其有效性随着基础LLM规模和上下文窗口大小的增长而提高。&lt;h4&gt;结论&lt;/h4&gt;重新利用LLM作为EHR编码器提供了一种可扩展且有效的临床预测方法，有助于克服传统EHR建模中的局限性并促进更互操作性和普遍性的医疗保健应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electronic Health Records (EHRs) offer rich potential for clinicalprediction, yet their inherent complexity and heterogeneity pose significantchallenges for traditional machine learning approaches. Domain-specific EHRfoundation models trained on large collections of unlabeled EHR data havedemonstrated promising improvements in predictive accuracy and generalization;however, their training is constrained by limited access to diverse,high-quality datasets and inconsistencies in coding standards and healthcarepractices. In this study, we explore the possibility of using general-purposeLarge Language Models (LLMs) based embedding methods as EHR encoders. Byserializing patient records into structured Markdown text, transforming codesinto human-readable descriptors, we leverage the extensive generalizationcapabilities of LLMs pretrained on vast public corpora, thereby bypassing theneed for proprietary medical datasets. We systematically evaluate twostate-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct andLLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks fromthe EHRSHOT benchmark, comparing their performance to an EHRspecific foundationmodel, CLIMBR-T-Base, and traditional machine learning baselines. Our resultsdemonstrate that LLM-based embeddings frequently match or exceed theperformance of specialized models, even in few-shot settings, and that theireffectiveness scales with the size of the underlying LLM and the availablecontext window. Overall, our findings demonstrate that repurposing LLMs for EHRencoding offers a scalable and effective approach for clinical prediction,capable of overcoming the limitations of traditional EHR modeling andfacilitating more interoperable and generalizable healthcare applications.</description>
      <author>example@mail.com (Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild)</author>
      <guid isPermaLink="false">2502.17403v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Electrical Load Forecasting over Multihop Smart Metering Networks with Federated Learning</title>
      <link>http://arxiv.org/abs/2502.17226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2411.10619&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本论文提出了一个新型的个性化联邦学习(PFL) 方法，用于电表网络中的高质量负载预测。&lt;h4&gt;背景&lt;/h4&gt;电力负载预测对于智能电网的管理与稳定性至关重要。传统机器学习方法在负载预测中通常被使用，但会涉及到数据交换从而引发隐私问题。联邦学习（FL）可以通过不进行数据交换而在本地智能电表上运行分布式机器学习模型来解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型个性化联邦学习(PFL) 方法以实现高效的负载预测，并减少延迟。&lt;h4&gt;方法&lt;/h4&gt;提出了基于元学习的策略，用于处理本地智能电表中的数据异质性。同时研究了一种新的基于最优资源分配的新延迟优化问题来降低PFL模型中负载预测延迟。&lt;h4&gt;主要发现&lt;/h4&gt;通过详尽的真实世界数据集仿真表明本论文的方法在负载预测和运营延迟成本方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法为联邦学习的设计提供了理论收敛性分析，以提供关于联合负荷预测的见解。&lt;h4&gt;翻译&lt;/h4&gt;电力负载预测对于智能电网管理和稳定性至关重要。通常通过高级计量基础设施实现这一点，在这种基础设施中，智能电表记录家庭能耗数据。虽然传统机器学习方法被广泛用于负荷预测，但它们需要数据共享并且引发了隐私问题。联邦学习可以通过在本地智能电表上运行分布式模型而无需交换数据来解决这个问题。然而，当前基于FL的方法由于异构智能电表之间的数据分布不平衡而难以实现有效的负载预测。本文提出了一种新的个性化联邦学习（PFL）方法用于计量网络中的高质量负荷预测。研究团队开发了一个基于元学习的策略来处理在本地智能电表中联合训练本地负荷预测模型时的数据异质性问题。此外，为了最小化我们提出的PFL模型中的负载预测延迟，他们研究了一种新的基于最优资源分配的延迟优化问题。还进行了理论收敛性分析以提供关于联邦学习设计用于联邦负荷预测的见解。大量来自真实数据集的仿真显示该方法在提高负荷预测质量和减少运营延迟成本方面优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electric load forecasting is essential for power management and stability insmart grids. This is mainly achieved via advanced metering infrastructure,where smart meters (SMs) record household energy data. Traditional machinelearning (ML) methods are often employed for load forecasting but require datasharing which raises data privacy concerns. Federated learning (FL) can addressthis issue by running distributed ML models at local SMs without data exchange.However, current FL-based approaches struggle to achieve efficient loadforecasting due to imbalanced data distribution across heterogeneous SMs. Thispaper presents a novel personalized federated learning (PFL) method forhigh-quality load forecasting in metering networks. A meta-learning-basedstrategy is developed to address data heterogeneity at local SMs in thecollaborative training of local load forecasting models. Moreover, to minimizethe load forecasting delays in our PFL model, we study a new latencyoptimization problem based on optimal resource allocation at SMs. A theoreticalconvergence analysis is also conducted to provide insights into FL design forfederated load forecasting. Extensive simulations from real-world datasets showthat our method outperforms existing approaches in terms of better loadforecasting and reduced operational latency costs.</description>
      <author>example@mail.com (Ratun Rahman, Pablo Moriano, Samee U. Khan, Dinh C. Nguyen)</author>
      <guid isPermaLink="false">2502.17226v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PFSD: A Multi-Modal Pedestrian-Focus Scene Dataset for Rich Tasks in Semi-Structured Environments</title>
      <link>http://arxiv.org/abs/2502.15342v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近的自动驾驶感知技术在结构化的车辆主导环境中展示了卓越的能力，但在半结构化环境中存在显著限制。这些限制主要是由于高质量数据集缺乏造成的，尤其是在行人感知和预测方面。&lt;h4&gt;背景&lt;/h4&gt;当前的自动驾驶感知模型在半结构化环境（如动态行人频繁出现的地方）中表现出明显的局限性，因为现有的数据集中缺乏足够高质量的数据来支持这类场景的研究。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的多模态数据集——Pedestrian-Focused Scene Dataset (PFSD)，专门针对半结构化的复杂环境，并提出了Hybrid Multi-Scale Fusion Network（HMFN）模型以解决行人检测的挑战问题。&lt;h4&gt;方法&lt;/h4&gt;{'PFSD': '该数据集包含超过130,000个行人的实例，涵盖了各种密度、移动模式和遮挡情况。它提供了全面的多模态数据注释，包括点云分割、检测以及对象ID追踪。', 'HMFN': '为了在密集且被部分阻挡的情况下更好地识别行人，该方法使用精心设计的混合框架捕获并融合多尺度特征，整合了稀疏和标准卷积技术。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在PFSD上进行测试时，所提出的HMFN模型相比现有方法在3D行人检测方面实现了更高的平均精度(mAP)提升。&lt;h4&gt;结论&lt;/h4&gt;通过提出新的数据集和有效的网络架构来解决半结构化环境中复杂的行人感知挑战问题，证明了该工作的实用性和创新性。&lt;h4&gt;翻译&lt;/h4&gt;近期自动驾驶车辆的感知技术在高度结构化的交通场景中展示出了卓越的能力。然而，在行人活动更为多样且复杂遮挡更加普遍的半结构化环境下，现有的感知模型表现出了明显的局限性。这种现象主要是由于缺乏高质量的数据集，特别是关于行人的感知和预测数据。本文提出了一种新的多模态行人聚焦场景数据集（PFSD），它在nuScenes格式下被详细标注，并提供了全面的多模态注释，包括点云分割、检测及对象ID追踪等信息。该数据集覆盖了超过130,000个行人的实例，它们涵盖了不同密度、移动模式和遮挡情况下的各种场景。为了应对半结构化环境中更加多样复杂的情况带来的挑战，我们提出了一种新的混合多尺度融合网络（HMFN）。具体而言，在人口密集且存在部分阻挡的情况下，我们的方法通过精心设计的框架有效地捕捉并融合了多种规模特征，该框架集成了稀疏和传统卷积技术。在PFSD上的大量实验表明，与现有方法相比，HMFN在网络架构中实现了显著提高的平均精度（mAP），这证明了其解决半结构化环境中3D行人检测挑战的有效性。代码和基准测试结果已经开放提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in autonomous driving perception have revealedexceptional capabilities within structured environments dominated by vehiculartraffic. However, current perception models exhibit significant limitations insemi-structured environments, where dynamic pedestrians with more diverseirregular movement and occlusion prevail. We attribute this shortcoming to thescarcity of high-quality datasets in semi-structured scenes, particularlyconcerning pedestrian perception and prediction. In this work, we present themulti-modal Pedestrian-Focused Scene Dataset(PFSD), rigorously annotated insemi-structured scenes with the format of nuScenes. PFSD provides comprehensivemulti-modal data annotations with point cloud segmentation, detection, andobject IDs for tracking. It encompasses over 130,000 pedestrian instancescaptured across various scenarios with varying densities, movement patterns,and occlusions. Furthermore, to demonstrate the importance of addressing thechallenges posed by more diverse and complex semi-structured environments, wepropose a novel Hybrid Multi-Scale Fusion Network (HMFN). Specifically, todetect pedestrians in densely populated and occluded scenarios, our methodeffectively captures and fuses multi-scale features using a meticulouslydesigned hybrid framework that integrates sparse and vanilla convolutions.Extensive experiments on PFSD demonstrate that HMFN attains improvement in meanAverage Precision (mAP) over existing methods, thereby underscoring itsefficacy in addressing the challenges of 3D pedestrian detection in complexsemi-structured environments. Coding and benchmark are available.</description>
      <author>example@mail.com (Yueting Liu, Hanshi Wang, Yunfei Lei, Zhengjun Zha, Weiming Hu, Jin Gao)</author>
      <guid isPermaLink="false">2502.15342v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Applications of Large Models in Medicine</title>
      <link>http://arxiv.org/abs/2502.17132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了大规模模型在医疗领域的进展与应用，特别关注医学大型模型（MedLMs）的应用。&lt;h4&gt;背景&lt;/h4&gt;这些模型包括大型语言模型（LLMs）、视觉模型、3D大型模型和多模态模型。它们通过增强疾病预测、诊断辅助、个性化治疗计划及药物发现来革新医疗服务。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在提供大规模模型在医学领域现状与未来方向的全面概述，强调其在全球健康进步中的重要性。&lt;h4&gt;方法&lt;/h4&gt;论文重点介绍了大型图神经网络如何融入医疗知识图谱和药物发现中，以及视觉-语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模及假肢设计方面的应用。&lt;h4&gt;主要发现&lt;/h4&gt;尽管存在挑战，但这些技术正在为医疗服务设定新的标准，并为个性化健康解决方案铺平道路。&lt;h4&gt;结论&lt;/h4&gt;大规模模型正在医疗领域实现变革性的进步，通过改善诊断准确性来推动全球卫生的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文翻译为：本文探讨了大型规模模型在医学领域的进展和应用，特别关注医学大模型（MedLMs）。这些模型包括大型语言模型、视觉模型、3D大型模型以及多模态模型。它们正在通过增强疾病预测、诊断辅助、个性化治疗计划及药物发现等方面革新医疗服务。研究还强调了大型图模型（LGMs）在理解复杂生物医学关系中的潜力，特别是在医疗知识图谱和药物发现中的集成应用。视觉-语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模以及假肢设计方面的使用也得到突出展示。尽管存在挑战，这些技术正在为医疗服务设定新的标准，提高诊断准确性，并推动个性化健康解决方案的发展。本文旨在提供大规模模型在医学领域现状与未来方向的全面概述，强调它们在全球健康进步中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.71423/aimed.20250105&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the advancements and applications of large-scale modelsin the medical field, with a particular focus on Medical Large Models (MedLMs).These models, encompassing Large Language Models (LLMs), Vision Models, 3DLarge Models, and Multimodal Models, are revolutionizing healthcare byenhancing disease prediction, diagnostic assistance, personalized treatmentplanning, and drug discovery. The integration of graph neural networks inmedical knowledge graphs and drug discovery highlights the potential of LargeGraph Models (LGMs) in understanding complex biomedical relationships. Thestudy also emphasizes the transformative role of Vision-Language Models (VLMs)and 3D Large Models in medical image analysis, anatomical modeling, andprosthetic design. Despite the challenges, these technologies are setting newbenchmarks in medical innovation, improving diagnostic accuracy, and paving theway for personalized healthcare solutions. This paper aims to provide acomprehensive overview of the current state and future directions of largemodels in medicine, underscoring their significance in advancing global health.</description>
      <author>example@mail.com (YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang)</author>
      <guid isPermaLink="false">2502.17132v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>CAR-LOAM: Color-Assisted Robust LiDAR Odometry and Mapping</title>
      <link>http://arxiv.org/abs/2502.17249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合颜色信息的稳健框架，用于准确的LiDAR里程计和地图构建（LOAM），通过同时利用LiDAR点云和相机图像中的边缘及平面特征来提高定位精度。&lt;h4&gt;背景&lt;/h4&gt;现有的LiDAR Odometry and Mapping (LOAM)技术在使用单模态数据时存在局限性，难以处理复杂的环境场景。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够融合颜色信息的稳健框架，以实现更加准确和鲁棒性的LiDAR里程计及地图构建方法。&lt;h4&gt;方法&lt;/h4&gt;该框架包括：1）利用相机图像中的颜色为LiDAR点云着色；2）采用感知均匀的颜色差异权重策略来排除颜色对应异常值；3）使用基于Welsch函数的稳健误差度量法处理位置对应异常值。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在复杂森林和校园等挑战性场景中表现出更高的准确性和鲁棒性，相较于当前最先进的技术有所改进。&lt;h4&gt;结论&lt;/h4&gt;利用相机图像中的颜色信息能够显著提高LiDAR里程计及地图构建的精度与稳定性。&lt;h4&gt;翻译&lt;/h4&gt;在这封信中，我们提出了一种结合颜色信息用于精确LiDAR里程估计和制图（LOAM）的稳健框架。同时从激光雷达和摄像机接收数据，该框架利用摄像机图像中的颜色信息对激光雷达点云进行着色，然后执行迭代姿态优化。对于每个激光雷达扫描，提取边缘和平面特征，并使用相应图像对其着色并匹配到全局地图中。特别地，我们采用感知均匀的颜色差异权重策略来排除颜色对应异常值，并基于Welsch函数的稳健误差度量法在姿态优化过程中减少位置对应异常值的影响。因此，该系统实现了精确定位，并重建了环境密集、准确、彩色且三维的地图。具有挑战性的场景（包括复杂森林和校园）中的彻底实验表明，我们的方法相比当前最先进的技术提供了更高的鲁棒性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we propose a color-assisted robust framework for accurateLiDAR odometry and mapping (LOAM). Simultaneously receiving data from both theLiDAR and the camera, the framework utilizes the color information from thecamera images to colorize the LiDAR point clouds and then performs iterativepose optimization. For each LiDAR scan, the edge and planar features areextracted and colored using the corresponding image and then matched to aglobal map. Specifically, we adopt a perceptually uniform color differenceweighting strategy to exclude color correspondence outliers and a robust errormetric based on the Welsch's function to mitigate the impact of positionalcorrespondence outliers during the pose optimization process. As a result, thesystem achieves accurate localization and reconstructs dense, accurate, coloredand three-dimensional (3D) maps of the environment. Thorough experiments withchallenging scenarios, including complex forests and a campus, show that ourmethod provides higher robustness and accuracy compared with currentstate-of-the-art methods.</description>
      <author>example@mail.com (Yufei Lu, Yuetao Li, Zhizhou Jia, Qun Hao, Shaohui Zhang)</author>
      <guid isPermaLink="false">2502.17249v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.16389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Robotics Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自动驾驶汽车的安全性是实现完全自主驾驶的关键，特别是在检测超出操作设计领域的异常情况方面。论文提出了一种新颖的无监督异常检测专家系统来解决这个问题。&lt;h4&gt;背景&lt;/h4&gt;随着自动化车辆进入公共道路，确保无数驾驶场景中的安全性成为广泛采用全自动驾驶的重要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;为了提高自动驾驶系统的可信度，研究提出了能够检测出道路上不常见情况的方法。&lt;h4&gt;方法&lt;/h4&gt;{'三类无监督异常检测专家': ['场景专家：专注于帧级别的外观来识别异常场景和未预期的场景运动；交互专家：建立两个道路参与者的相对正常移动模型，并在出现异常互动时发出警告；行为专家：通过未来轨迹预测监测个体对象的异常行为。'], '专家集成系统(Xen)': '利用卡尔曼滤波器将所有模块的优点结合起来，最终异常得分被作为其中一个状态，而观察结果则由各个专家生成。', '新颖评估协议': '采用了一种新的模型性能评估协议来测试实际应用中的表现'}&lt;h4&gt;主要发现&lt;/h4&gt;{'优越性': '实验结果显示该方法在检测道路上的异常情况时比先前的方法更胜一筹', '潜力': '通过无监督学习处理大规模数据集，该框架有分类不同类型的异常行为的潜力'}&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖且有效的方法来实现自动驾驶汽车中的安全性和可靠性，并展示了其在现实世界应用中的潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;随着自动化车辆进入公共道路，确保无数驾驶场景中的安全性成为广泛采用全自动驾驶的重要挑战之一。论文提出了三种无监督异常检测专家：场景专家、交互专家和行为专家，以及一个通过卡尔曼滤波器将各模块的优点结合起来的专家集成系统(Xen)。实验显示该方法在道路上检测异常情况方面优于先前的方法，并且具有利用大规模数据集进行无监督学习来分类不同类型的异常行为的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1177/02783649241297998&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As automated vehicles enter public roads, safety in a near-infinite number ofdriving scenarios becomes one of the major concerns for the widespread adoptionof fully autonomous driving. The ability to detect anomalous situations outsideof the operational design domain is a key component in self-driving cars,enabling us to mitigate the impact of abnormal ego behaviors and to realizetrustworthy driving systems. On-road anomaly detection in egocentric videosremains a challenging problem due to the difficulties introduced by complex andinteractive scenarios. We conduct a holistic analysis of common on-road anomalypatterns, from which we propose three unsupervised anomaly detection experts: ascene expert that focuses on frame-level appearances to detect abnormal scenesand unexpected scene motions; an interaction expert that models normal relativemotions between two road participants and raises alarms whenever anomalousinteractions emerge; and a behavior expert which monitors abnormal behaviors ofindividual objects by future trajectory prediction. To combine the strengths ofall the modules, we propose an expert ensemble (Xen) using a Kalman filter, inwhich the final anomaly score is absorbed as one of the states and theobservations are generated by the experts. Our experiments employ a novelevaluation protocol for realistic model performance, demonstrate superioranomaly detection performance than previous methods, and show that ourframework has potential in classifying anomaly types using unsupervisedlearning on a large-scale on-road anomaly dataset.</description>
      <author>example@mail.com (Tianchen Ji, Neeloy Chakraborty, Andre Schreiber, Katherine Driggs-Campbell)</author>
      <guid isPermaLink="false">2502.16389v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Code Vulnerabilities with Heterogeneous GNN Training</title>
      <link>http://arxiv.org/abs/2502.16835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;检测源代码中的漏洞是软件安全保障的关键任务。图神经网络（GNN）机器学习通过将源代码建模为图形，可以成为一种有前途的方法。&lt;h4&gt;背景&lt;/h4&gt;早期方法将代码元素统一处理，限制了其模拟多样化关系的能力，这些关系有助于识别各种类型的漏洞。最近的研究通过考虑节点类型的不同性，并使用门控图神经网络（GGNN）来解决这一问题，以不同的边类型聚合节点信息。&lt;h4&gt;目的&lt;/h4&gt;介绍Inter-Procedural Abstract Graphs (IPAG)作为一种高效的、与语言无关的源代码表示方法，结合异构GNN训练进行漏洞预测。提出Heterogeneous Attention GNN（HAGNN）模型来集成捕捉源代码不同特征的多个子图。&lt;h4&gt;方法&lt;/h4&gt;该模型使用异构注意力机制将这些分别学习到的不同子图结合起来，并通过全连接神经网络进行最终分类。&lt;h4&gt;主要发现&lt;/h4&gt;提出的这种方法在包含108种漏洞类型的大型C数据集上达到了高达96.6%的准确性，在包含114种漏洞类型的大型Java数据集上达到了97.8%，优于现有最先进的方法。此外，该方法应用于各种实际软件项目时也显示出了较低的假阳性率。&lt;h4&gt;结论&lt;/h4&gt;通过引入Inter-Procedural Abstract Graphs（IPAG）和Heterogeneous Attention GNN（HAGNN），为源代码漏洞检测提供了一种高效且准确的方法，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;检测源代码中的漏洞是软件安全保障的关键任务。图神经网络（GNN）机器学习通过将源代码建模为图形，可以成为一种有前途的方法。早期方法统一处理代码元素，限制了其对导致各种类型漏洞的多样化关系进行建模的能力。最近的研究通过考虑节点类型的异质性，并使用门控图神经网络（GGNN）来解决这一问题，以不同的边类型聚合节点信息。然而，这些边缘主要作为传递节点信息的渠道，可能无法捕捉到不同类型的详细特征。本文提出了Inter-Procedural Abstract Graphs (IPAG)作为一种高效的、与语言无关的源代码表示方法，并结合异构GNN训练进行漏洞预测。IPAG捕获了代码元素及其关系的结构和上下文属性。我们还提出了一种Heterogeneous Attention GNN（HAGNN）模型，该模型集成了捕捉源代码不同特征的多个子图。这些子图分别学习并通过全局注意力机制结合在一起，并通过全连接神经网络进行最终分类。在大型C数据集中，提出的这种方法达到了高达96.6%的准确性，涵盖了108种漏洞类型；而在包含114种漏洞类型的大型Java数据集中，则达到了97.8%，优于现有最先进的方法。此外，在各种实际软件项目中的应用也显示出了较低的假阳性率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting vulnerabilities in source code is a critical task for softwaresecurity assurance. Graph Neural Network (GNN) machine learning can be apromising approach by modeling source code as graphs. Early approaches treatedcode elements uniformly, limiting their capacity to model diverse relationshipsthat contribute to various vulnerabilities. Recent research addresses thislimitation by considering the heterogeneity of node types and using Gated GraphNeural Networks (GGNN) to aggregate node information through different edgetypes. However, these edges primarily function as conduits for passing nodeinformation and may not capture detailed characteristics of distinct edgetypes. This paper presents Inter-Procedural Abstract Graphs (IPAGs) as anefficient, language-agnostic representation of source code, complemented byheterogeneous GNN training for vulnerability prediction. IPAGs capture thestructural and contextual properties of code elements and their relationships.We also propose a Heterogeneous Attention GNN (HAGNN) model that incorporatesmultiple subgraphs capturing different features of source code. These subgraphsare learned separately and combined using a global attention mechanism,followed by a fully connected neural network for final classification. Theproposed approach has achieved up to 96.6% accuracy on a large C dataset of 108vulnerability types and 97.8% on a large Java dataset of 114 vulnerabilitytypes, outperforming state-of-the-art methods. Its applications to variousreal-world software projects have also demonstrated low false positive rates.</description>
      <author>example@mail.com (Yu Luo, Weifeng Xu, Dianxiang Xu)</author>
      <guid isPermaLink="false">2502.16835v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Scatterplot and Image Moments for Time-Varying Bivariate Field Analysis of Electronic Structure Evolution</title>
      <link>http://arxiv.org/abs/2502.17118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的时间变化双变量场分析方法，用于理解光诱导动力学中电子结构的变化。&lt;h4&gt;背景&lt;/h4&gt;由于光照吸收引起的电子在能级间的跃迁是一个复杂的量子力学过程，这会影响分子内的核几何和电子结构。研究这些密度场有助于了解分子内供体区域与受体区域之间的电荷移动情况。&lt;h4&gt;目的&lt;/h4&gt;通过连续散点图（Continuous Scatterplots, CSP）及基于图像的时刻描述符来分析时间变化中的双变量字段，并针对光激发后的不断变化的电子结构，提出一种特征导向可视化探索的方法。&lt;h4&gt;方法&lt;/h4&gt;核运动产生的多个时间步长，使用CSP和基于图像的时刻描述符进行动态场数据的探索性分析。将每个时间步骤的CSP表示为四个长度的图矩向量，并形成一个R^4中的点云。&lt;h4&gt;主要发现&lt;/h4&gt;选取适当的主要成分可以将点云表示为平面上的一条曲线，从而有助于识别关键的时间步长、发现双变量字段内的模式以及追踪其随时间的变化。文中通过两个光激发分子动力学的案例研究展示了这种方法的应用。&lt;h4&gt;结论&lt;/h4&gt;此方法可有效揭示电子结构变化规律，并提供具有应用特定洞察力的方法来深入理解光诱导过程中的物理和化学机制。&lt;h4&gt;翻译&lt;/h4&gt;光致电子跃迁是由于光照吸收引起的复杂量子力学过程，其中电子在能级之间移动。这会引起电子结构和核几何的变化，推动了光生物学、材料设计以及医学等领域的重要物理和化学进程。不断演变的电子结构可以通过两个电子密度场来表征：空穴自然过渡轨道（NTO）和粒子自然过渡轨道（NTO）。研究这些密度领域有助于了解分子内供体区域与受体区域之间的电荷移动情况。以往的研究多依赖于等值面并排视觉比较、统计方法或双变量字段分析，实例较少。我们提出了一种新的时间变化双变量场分析方法，适用于理解大量实例下的光诱导电子结构变化。由于NTO领域取决于核几何，因此需通过许多时间步长来解析由核运动产生的复杂现象。本文采用连续散点图（Continuous Scatterplots, CSP）及基于图像的时刻描述符来进行动态场数据探索性分析，并针对光激发后的不断变化的电子结构，提出一种特征导向可视化探索的方法。每个时间步骤中的CSP通过四个长度的图矩向量来表示；将所有矢量描述符集合形成R^4空间里的点云并利用主成分分析技术进行可视化呈现。选择适当的主成分可以简化点云为平面上的一条曲线，有助于识别关键的时间步长、发现双变量字段内的模式以及追踪其随时间的变化。我们通过两个光激发分子动力学案例研究展示这种方法的有效性，并展示了双变量场分析在特定应用中提供的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photoinduced electronic transitions are complex quantum-mechanical processeswhere electrons move between energy levels due to light absorption. Thisinduces dynamics in electronic structure and nuclear geometry, drivingimportant physical and chemical processes in fields like photobiology,materials design, and medicine. The evolving electronic structure can becharacterized by two electron density fields: hole and particle naturaltransition orbitals (NTOs). Studying these density fields helps understandelectronic charge movement between donor and acceptor regions within amolecule. Previous works rely on side-by-side visual comparisons ofisosurfaces, statistical approaches, or bivariate field analysis with fewinstances. We propose a new method to analyze time-varying bivariate fieldswith many instances, which is relevant for understanding electronic structurechanges during light-induced dynamics. Since NTO fields depend on nucleargeometry, the nuclear motion results in numerous time steps to analyze. Thispaper presents a structured approach to feature-directed visual exploration oftime-varying bivariate fields using continuous scatterplots (CSPs) and imagemoment-based descriptors, tailored for studying evolving electronic structurespost-photoexcitation. The CSP of the bivariate field at each time step isrepresented by a four-length image moment vector. The collection of all vectordescriptors forms a point cloud in R^4, visualized using principal componentanalysis. Selecting appropriate principal components results in arepresentation of the point cloud as a curve on the plane, aiding tasks such asidentifying key time steps, recognizing patterns within the bivariate field,and tracking the temporal evolution. We demonstrate this with two case studieson excited-state molecular dynamics, showing how bivariate field analysisprovides application-specific insights.</description>
      <author>example@mail.com (Mohit Sharma, Talha Bin Masood, Nanna Holmgaard List, Ingrid Hotz, Vijay Natarajan)</author>
      <guid isPermaLink="false">2502.17118v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns</title>
      <link>http://arxiv.org/abs/2502.16813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TKDE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的列级语义连接发现框架Snoopy，通过使用代理列来计算列嵌入以解决现有方法在有效性和效率方面的问题。&lt;h4&gt;背景&lt;/h4&gt;语义连接发现旨在从表库中找到与查询列有高语义连接性的列。现有方法分为单元格级别和列级别两种方法，但两者都无法同时保证有效性和效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架Snoopy来解决当前方法中存在的有效性低、效率不足的问题。&lt;h4&gt;方法&lt;/h4&gt;通过使用代理列计算列嵌入，并引入了一个基于排名的对比学习范式来获取指导列投影的良好代理列，提出了一个轻量级近似图匹配基线的列投射以捕捉隐式的列到代理列关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Snoopy在Recall@25和NDCG@25上分别比现有最佳方法高出16%和10%，并且至少快五倍于单元级解决方案，在速度上是现有的列级方法的3.5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的框架Snoopy不仅提高了语义连接发现的有效性，同时显著提升了效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语义连接发现旨在从表库中找到与查询列有高语义连接性的列。现存的方法可以分为两种类型：单元格级别方法和列级别方法。然而，两者都无法同时保证有效性和效率。单元级方法通过计算列之间的单元匹配来计算连接性，具有理想的有效性但效率低下。相比之下，列级别方法仅通过计算列嵌入的相似度来确定连接性，虽然效率尚可但由于其在列嵌入中存在的问题（i）语义-连接差距，（ii）大小限制，和（iii）排列敏感性而导致有效性较差。为了解决这些问题，本文提出使用代理列来计算列嵌入；此外还提出了一种新的列级语义连接发现框架Snoopy，利用基于代理列的嵌入在有效性和效率之间建立桥梁。具体而言，提出的列嵌入来自隐式的列到代理列关系，通过轻量级近似图匹配基线捕捉该关系。为了获取指导列投影的良好代理列，我们引入了一个排名感知对比学习范式。大量的实验结果表明，Snoopy在Recall@25和NDCG@25上分别比现有最佳方法高出16%和10%，并且至少快五倍于单元级解决方案，在速度上是现有的列级方法的3.5倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic join discovery, which aims to find columns in a table repositorywith high semantic joinabilities to a query column, is crucial for datasetdiscovery. Existing methods can be divided into two categories: cell-levelmethods and column-level methods. However, neither of them ensures botheffectiveness and efficiency simultaneously. Cell-level methods, which computethe joinability by counting cell matches between columns, enjoy idealeffectiveness but suffer poor efficiency. In contrast, column-level methods,which determine joinability only by computing the similarity of columnembeddings, enjoy proper efficiency but suffer poor effectiveness due to theissues occurring in their column embeddings: (i) semantics-joinability-gap,(ii) size limit, and (iii) permutation sensitivity. To address these issues,this paper proposes to compute column embeddings via proxy columns;furthermore, a novel column-level semantic join discovery framework, Snoopy, ispresented, leveraging proxy-column-based embeddings to bridge effectiveness andefficiency. Specifically, the proposed column embeddings are derived from theimplicit column-to-proxy-column relationships, which are captured by thelightweight approximate-graph-matching-based column projection.To acquire goodproxy columns for guiding the column projection, we introduce a rank-awarecontrastive learning paradigm. Extensive experiments on four real-worlddatasets demonstrate that Snoopy outperforms SOTA column-level methods by 16%in Recall@25 and 10% in NDCG@25, and achieves superior efficiency--being atleast 5 orders of magnitude faster than cell-level solutions, and 3.5x fasterthan existing column-level methods.</description>
      <author>example@mail.com (Yuxiang Guo, Yuren Mao, Zhonghao Hu, Lu Chen, Yunjun Gao)</author>
      <guid isPermaLink="false">2502.16813v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Image Translation-Based Unsupervised Cross-Modality Domain Adaptation for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.15193v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图像转换的无监督跨模态领域适应方法，通过将带注释的源模态图像转换为未注释的目标模态，并使用其注释来实现目标模态的监督学习。该方法在跨模态领域适应挑战中的验证阶段表现出色。&lt;h4&gt;背景&lt;/h4&gt;在医学影像中进行监督深度学习通常面临更多挑战，因为标注需要医生的专业知识且耗时费钱；无监督学习方法虽然被采用但性能降低不可避免；医学图像可能来自不同的医疗中心、使用不同设备和采集协议，导致模态差异，进一步降低了深度学习方法的适用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能有效解决跨模态领域适应问题的方法，并在真实场景中验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;通过将带注释的源模态图像转换为目标模态未标注图像，利用目标模态伪图像上的自训练方法克服细微差异，进一步提高深度学习任务性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在跨模态领域适应挑战中的验证阶段中，针对内耳神经瘤（VS）分割任务取得了平均Dice相似系数(DSC)为0.8351 ± 0.1152和对侧半规管（cochlea）的平均对称表面距离(ASSD)为1.6712±2.1948，在针对内耳神经瘤VS及耳蜗分割任务中取得了平均Dice相似系数(DSC)为0.8098 ± 0.0233和平均对称表面距离(ASSD)为0.2317±0.1577。&lt;h4&gt;结论&lt;/h4&gt;所提方法在跨模态领域适应问题上具有显著优势，能够有效应对医学图像的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised deep learning usually faces more challenges in medical images thanin natural images. Since annotations in medical images require the expertise ofdoctors and are more time-consuming and expensive. Thus, some researchers turnto unsupervised learning methods, which usually face inevitable performancedrops. In addition, medical images may have been acquired at different medicalcenters with different scanners and under different image acquisitionprotocols, so the modalities of the medical images are often inconsistent. Thismodality difference (domain shift) also reduces the applicability of deeplearning methods. In this regard, we propose an unsupervised crossmodalitydomain adaptation method based on image translation by transforming the sourcemodality image with annotation into the unannotated target modality and usingits annotation to achieve supervised learning of the target modality. Inaddition, the subtle differences between translated pseudo images and realimages are overcome by self-training methods to further improve the taskperformance of deep learning. The proposed method showed mean Dice SimilarityCoefficient (DSC) and Average Symmetric Surface Distance (ASSD) of $0.8351 \pm0.1152$ and $1.6712 \pm 2.1948$ for vestibular schwannoma (VS), $0.8098 \pm0.0233$ and $0.2317 \pm 0.1577$ for cochlea on the VS and cochlea segmentationtask of the Cross-Modality Domain Adaptation (crossMoDA 2022) challengevalidation phase leaderboard.</description>
      <author>example@mail.com (Tao Yang, Lisheng Wang)</author>
      <guid isPermaLink="false">2502.15193v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PointSea: Point Cloud Completion via Self-structure Augmentation</title>
      <link>http://arxiv.org/abs/2502.17053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Journal of Computer Vision. arXiv admin  note: text overlap with arXiv:2307.08492&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;点云补全是3D视觉中的一个基本但尚未完全解决的问题。现有的方法通常依赖于3D坐标信息和/或其他数据（如图像和扫描视角）来填补缺失部分。与这些方法不同，我们探索了自结构增强，并提出了用于全局到局部点云补全的PointSea。&lt;h4&gt;背景&lt;/h4&gt;点云补全是3D视觉中一个基本但仍未完全解决的问题，现有方法通常依赖于额外的数据来进行补全。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法PointSea，利用自投影深度图进行数据增强，并通过特征融合模块从跨模态输入重建紧凑的全局形状，同时在局部阶段揭示高度详细的结构。&lt;h4&gt;方法&lt;/h4&gt;{'全局阶段': 'PointSea通过使用来自多个视角的自我投影深度图像来增强数据表示。它还集成了一种特性融合模块以融合跨视图和同视图级别特征，以便从跨模态输入中重建紧凑的整体形状。', '局部阶段': '在局部阶段，为了揭示高度详细的结构，我们引入了一个名为自结构对偶生成器的点生成器。该生成器结合了学习到的形状先验知识和几何自相似性来进行形状细化。与现有技术使用统一策略不同的是，我们的双路径设计根据每个点的结构类型适应不同的细化策略。', '创新': 'PointSea提出了一种新的方法来处理全局到局部点云补全的问题，通过利用自投影深度图增强数据表示，并采用特征融合模块和自结构对偶生成器进行形状细化。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PointSea能够有效地理解整体形状并从不完整输入中生成详细信息，明显优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的PointSea在广泛的基准测试中展示了优越的表现，证明了其在全球和局部点云补全中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion is a fundamental yet not well-solved problem in 3Dvision. Current approaches often rely on 3D coordinate information and/oradditional data (e.g., images and scanning viewpoints) to fill in missingparts. Unlike these methods, we explore self-structure augmentation and proposePointSea for global-to-local point cloud completion. In the global stage,consider how we inspect a defective region of a physical object, we may observeit from various perspectives for a better understanding. Inspired by this,PointSea augments data representation by leveraging self-projected depth imagesfrom multiple views. To reconstruct a compact global shape from the cross-modalinput, we incorporate a feature fusion module to fuse features at bothintra-view and inter-view levels. In the local stage, to reveal highly detailedstructures, we introduce a point generator called the self-structuredual-generator. This generator integrates both learned shape priors andgeometric self-similarities for shape refinement. Unlike existing efforts thatapply a unified strategy for all points, our dual-path design adapts refinementstrategies conditioned on the structural type of each point, addressing thespecific incompleteness of each point. Comprehensive experiments on widely-usedbenchmarks demonstrate that PointSea effectively understands global shapes andgenerates local details from incomplete input, showing clear improvements overexisting methods.</description>
      <author>example@mail.com (Zhe Zhu, Honghua Chen, Xing He, Mingqiang Wei)</author>
      <guid isPermaLink="false">2502.17053v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Closer Look at TabPFN v2: Strength, Limitation, and Extension</title>
      <link>http://arxiv.org/abs/2502.17361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2)模型进行了详尽评估，确认其在小规模至中等规模任务中的卓越泛化能力。&lt;h4&gt;背景&lt;/h4&gt;表格数据集具有内在异质性，给预训练基础模型的发展带来了巨大挑战。最近引入的基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2) 在多个表格数据集中实现了前所未有的上下文学习准确度。&lt;h4&gt;目的&lt;/h4&gt;全面评估TabPFN v2在超过300个数据集上的性能，揭示其成功的机制，并提出扩大其适用性的策略。&lt;h4&gt;方法&lt;/h4&gt;采用随机化特征标记将异质性数据集统一为固定维度表示；通过leave-one-fold-out方法将其转化为特征提取器；引入Chain-of-Thought提示的分而治之机制以支持大规模任务。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示，随机化特征令牌是TabPFN v2成功的关键因素。此外，该模型能够简化数据分布并提高准确性。&lt;h4&gt;结论&lt;/h4&gt;通过揭示TabPFN v2背后的机制，并提出策略来扩大其适用范围，这项研究为未来表格基础模型的发展提供了关键见解。&lt;h4&gt;翻译&lt;/h4&gt;表格数据集具有内在异质性，给预训练基础模型的发展带来了巨大挑战。最近引入的基于Transformer的Tabular Prior-data Fitted Network v2 (TabPFN v2) 在多个表格数据集中实现了前所未有的上下文学习准确度，标志着表格基础模型的重要进展。在该论文中，我们全面评估了TabPFN v2在超过300个数据集上的性能，确认其卓越的小到中等规模任务的泛化能力。我们的分析确定随机化特征令牌是TabPFN v2成功的关键因素，因为它们将异质性表格数据集统一为固定维度表示，从而更有效的训练和推理。为了进一步理解TabPFN v2的预测结果，我们提出了一种leave-one-fold-out方法，使TabPFN v2转变为一个特征提取器，并揭示其简化数据分布并提高准确性的能力。最后，针对TabPFN v2在高维、大规模和多类别任务中的局限性，我们引入了受Chain-of-Thought提示启发的分而治之机制，实现可扩展推理。通过揭示TabPFN v2成功背后的机制并提出策略来扩大其适用范围，这项研究为未来表格基础模型的发展提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular datasets are inherently heterogeneous, posing significant challengesfor developing pre-trained foundation models. The recently introducedtransformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achievesunprecedented in-context learning accuracy across multiple tabular datasets,marking a pivotal advancement in tabular foundation models. In this paper, wecomprehensively evaluate TabPFN v2 on over 300 datasets, confirming itsexceptional generalization capabilities on small- to medium-scale tasks. Ouranalysis identifies randomized feature tokens as a key factor behind TabPFNv2's success, as they unify heterogeneous datasets into a fixed-dimensionalrepresentation, enabling more effective training and inference. To furtherunderstand TabPFN v2's predictions, we propose a leave-one-fold-out approach,transforming TabPFN v2 into a feature extractor and revealing its capability tosimplify data distributions and boost accuracy. Lastly, to address TabPFN v2'slimitations in high-dimensional, large-scale, and many-category tasks, weintroduce a divide-and-conquer mechanism inspired by Chain-of-Thoughtprompting, enabling scalable inference. By uncovering the mechanisms behindTabPFN v2's success and introducing strategies to expand its applicability,this study provides key insights into the future of tabular foundation models.</description>
      <author>example@mail.com (Han-Jia Ye, Si-Yang Liu, Wei-Lun Chao)</author>
      <guid isPermaLink="false">2502.17361v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>In-context learning of evolving data streams with tabular foundational models</title>
      <link>http://arxiv.org/abs/2502.16840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;监督分类中的数据流挖掘传统上依赖于增量决策树集成。然而，大型表格模型（即为结构化数值数据设计的transformer）标志着一个重要的范式转变。&lt;h4&gt;目的&lt;/h4&gt;探索实时模型适应性，并探讨transformer在动态环境下的自适应学习能力。&lt;h4&gt;方法&lt;/h4&gt;使用预训练模型和在线提示调整进行上下文学习。通过利用滑动窗口内存策略，TabPFN能够有效处理无限流数据。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，TabPFN结合简单的滑动内存策略，在所有非平稳基准测试中始终优于Hoeffding树集成。&lt;h4&gt;结论&lt;/h4&gt;论文概述了几种有前景的研究方向，并鼓励社区探索这些想法，以便在上下文流学习方面取得进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了当前监督分类中的数据流挖掘技术从传统的增量决策树转向大型表格模型（transformer）的转变。通过引入在线提示调整和预训练模型来处理无界流数据，实现了实时模型适应性研究，并展示了TabPFN在这种场景下的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art data stream mining in supervised classification hastraditionally relied on ensembles of incremental decision trees. However, theemergence of large tabular models, i.e., transformers designed for structurednumerical data, marks a significant paradigm shift. These models move beyondtraditional weight updates, instead employing in-context learning throughprompt tuning. By using on-the-fly sketches to summarize unbounded streamingdata, one can feed this information into a pre-trained model for efficientprocessing. This work bridges advancements from both areas, highlighting howtransformers' implicit meta-learning abilities, pre-training on driftingnatural data, and reliance on context optimization directly address the corechallenges of adaptive learning in dynamic environments. Exploring real-timemodel adaptation, this research demonstrates that TabPFN, coupled with a simplesliding memory strategy, consistently outperforms ensembles of Hoeffding treesacross all non-stationary benchmarks. Several promising research directions areoutlined in the paper. The authors urge the community to explore these ideas,offering valuable opportunities to advance in-context stream learning.</description>
      <author>example@mail.com (Afonso Lourenço, João Gama, Eric P. Xing, Goreti Marreiros)</author>
      <guid isPermaLink="false">2502.16840v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.16793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为VGFL-SA的新颖图对抗攻击，旨在通过修改本地客户端的结构而不使用标签信息来降低垂直联邦学习（VGFL）框架的性能。&lt;h4&gt;背景&lt;/h4&gt;由于隐私保护和利益冲突，需要开发出能够在不直接分享图数据的情况下进行协作训练的垂直联邦图神经网络。现有的对抗性攻击依赖于标签信息的有效性受到限制，这在实际应用中存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有VGFL框架中的未标记客户端问题并提高其安全性，研究人员提出了一种新的对抗攻击方法。&lt;h4&gt;方法&lt;/h4&gt;研究者采用对比学习的方法，在本地客户端训练之前完成攻击任务。具体来说，该方法利用图结构和节点特征信息生成对比视图，并通过共享的图编码器获取每个视图的嵌入表示，进而获得邻接矩阵的梯度并生成扰动边。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，提出的VGFL-SA在现实世界数据集上的节点分类任务中展现了良好的攻击效果和可转移性。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习技术完成无标签信息参与的图对抗攻击可以有效地降低基于垂直联邦框架下GNNs模型的学习性能，这为未来的安全研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have gained attention for their ability to learnrepresentations from graph data. Due to privacy concerns and conflicts ofinterest that prevent clients from directly sharing graph data with oneanother, Vertical Graph Federated Learning (VGFL) frameworks have beendeveloped. Recent studies have shown that VGFL is vulnerable to adversarialattacks that degrade performance. However, it is a common problem that clientnodes are often unlabeled in the realm of VGFL. Consequently, the existingattacks, which rely on the availability of labeling information to obtaingradients, are inherently constrained in their applicability. This limitationprecludes their deployment in practical, real-world environments. To addressthe above problems, we propose a novel graph adversarial attack against VGFL,referred to as VGFL-SA, to degrade the performance of VGFL by modifying thelocal clients structure without using labels. Specifically, VGFL-SA uses acontrastive learning method to complete the attack before the local clients aretrained. VGFL-SA first accesses the graph structure and node featureinformation of the poisoned clients, and generates the contrastive views bynode-degree-based edge augmentation and feature shuffling augmentation. Then,VGFL-SA uses the shared graph encoder to get the embedding of each view, andthe gradients of the adjacency matrices are obtained by the contrastivefunction. Finally, perturbed edges are generated using gradient modificationrules. We validated the performance of VGFL-SA by performing a nodeclassification task on real-world datasets, and the results show that VGFL-SAachieves good attack effectiveness and transferability.</description>
      <author>example@mail.com (Yang Chen, Bin Zhou)</author>
      <guid isPermaLink="false">2502.16793v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MetaSym: A Symplectic Meta-learning Framework for Physical Intelligence</title>
      <link>http://arxiv.org/abs/2502.16667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8+10 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的深度学习架构MetaSym，结合了强对称归纳偏差和自回归解码器，用于解决物理感知深度学习的挑战。&lt;h4&gt;背景&lt;/h4&gt;具有广泛应用领域的可扩展且通用的物理感知深度学习长期以来一直被视为重大难题。几乎所有物理系统的核心都是辛形式，它支撑着能量、动量等基本不变性。&lt;h4&gt;目的&lt;/h4&gt;引入MetaSym架构，确保核心物理不变性的完整性和灵活的数据高效适应系统异质性。&lt;h4&gt;方法&lt;/h4&gt;将一个获得自对称编码器的强辛归纳偏差和一个具有元注意力机制的自回归解码器相结合来构建新型深度学习架构MetaSym。&lt;h4&gt;主要发现&lt;/h4&gt;在包括高维弹簧网格系统、开放量子系统以及四旋翼动态等多样化数据集上的基准测试中，MetaSym表现出色，在少样本适应情况下模型性能优于现有的最先进的基线方法，并且使用远小于这些基线方法的规模模型就达到了这一效果。&lt;h4&gt;结论&lt;/h4&gt;提出的MetaSym架构在物理感知深度学习任务上具有显著优势，尤其适用于需要灵活适应系统异质性的场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scalable and generalizable physics-aware deep learning has long beenconsidered a significant challenge with various applications across diversedomains ranging from robotics to molecular dynamics. Central to almost allphysical systems are symplectic forms, the geometric backbone that underpinsfundamental invariants like energy and momentum. In this work, we introduce anovel deep learning architecture, MetaSym. In particular, MetaSym combines astrong symplectic inductive bias obtained from a symplectic encoder and anautoregressive decoder with meta-attention. This principled design ensures thatcore physical invariants remain intact while allowing flexible, data-efficientadaptation to system heterogeneities. We benchmark MetaSym on highly varieddatasets such as a high-dimensional spring mesh system (Otness et al., 2021),an open quantum system with dissipation and measurement backaction, androbotics-inspired quadrotor dynamics. Our results demonstrate superiorperformance in modeling dynamics under few-shot adaptation, outperformingstate-of-the-art baselines with far larger models.</description>
      <author>example@mail.com (Pranav Vaidhyanathan, Aristotelis Papatheodorou, Mark T. Mitchison, Natalia Ares, Ioannis Havoutis)</author>
      <guid isPermaLink="false">2502.16667v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>RELICT: A Replica Detection Framework for Medical Image Generation</title>
      <link>http://arxiv.org/abs/2502.17360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;尽管合成医疗数据在增强和提高深度学习模型的泛化能力方面具有潜力，但生成模型中的记忆效应可能导致敏感患者信息意外泄露，并限制了模型的实用性。因此，在医学领域使用能够记住训练数据的生成模型可能会危及患者的隐私。&lt;h4&gt;背景&lt;/h4&gt;在医疗领域，利用合成医疗数据来增强和提高深度学习模型的泛化能力是一个潜在的重要研究方向。然而，生成模型中存在的记忆问题可能导致敏感患者信息的泄露，并限制了这些模型的实际应用价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架用于识别合成医学图像数据集中的副本（即与训练数据几乎相同的近似拷贝），旨在为医疗成像领域负责任和伦理地使用合成图像提供标准化且易于使用的工具。&lt;h4&gt;方法&lt;/h4&gt;RELICT框架通过三种互补的方法评估图像的相似性：1）体素级别分析；2）由预训练的医学基础模型进行特征级别分析；3）分割级别分析。针对两种临床相关的三维生成建模应用场景进行了研究：非对比头CT与脑内出血（N=774）和圈套动脉的时间飞跃磁共振血管成像（TOF-MRA，N=1,782）。使用专家视觉评分作为参考标准来评估副本的存在。&lt;h4&gt;主要发现&lt;/h4&gt;对于NCCT用例，在选择了最佳阈值的情况下，图像级别和特征级别测量方法可以完美地分类副本，平衡准确率为1；而对于TOF-MRA案例，则无法在任何阈值下实现完美的副本分类，但分割级别分析的平衡准确性为0.79。&lt;h4&gt;结论&lt;/h4&gt;副本检测是生成模型开发中的一个关键但被忽视的验证步骤。RELICT框架提供了一个标准化、易于使用的工具来识别副本，并旨在促进医学图像合成的责任感和伦理规范。&lt;h4&gt;其他细节&lt;/h4&gt;本研究强调了在医疗影像领域发展生成模型时，防止敏感信息泄露的重要性，并提出了一种新的评估方法用于检测合成数据集中可能出现的真实训练数据副本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the potential of synthetic medical data for augmenting and improvingthe generalizability of deep learning models, memorization in generative modelscan lead to unintended leakage of sensitive patient information and limit modelutility. Thus, the use of memorizing generative models in the medical domaincan jeopardize patient privacy. We propose a framework for identifyingreplicas, i.e. nearly identical copies of the training data, in syntheticmedical image datasets. Our REpLIca deteCTion (RELICT) framework for medicalimage generative models evaluates image similarity using three complementaryapproaches: (1) voxel-level analysis, (2) feature-level analysis by apretrained medical foundation model, and (3) segmentation-level analysis. Twoclinically relevant 3D generative modelling use cases were investigated:non-contrast head CT with intracerebral hemorrhage (N=774) and time-of-flightMR angiography of the Circle of Willis (N=1,782). Expert visual scoring wasused as the reference standard to assess the presence of replicas. We reportthe balanced accuracy at the optimal threshold to assess replica classificationperformance. The reference visual rating identified 45 of 50 and 5 of 50generated images as replicas for the NCCT and TOF-MRA use cases, respectively.Image-level and feature-level measures perfectly classified replicas with abalanced accuracy of 1 when an optimal threshold was selected for the NCCT usecase. A perfect classification of replicas for the TOF-MRA case was notpossible at any threshold, with the segmentation-level analysis achieving abalanced accuracy of 0.79. Replica detection is a crucial but neglectedvalidation step for the development of generative models in medical imaging.The proposed RELICT framework provides a standardized, easy-to-use tool forreplica detection and aims to facilitate responsible and ethical medical imagesynthesis.</description>
      <author>example@mail.com (Orhun Utku Aydin, Alexander Koch, Adam Hilbert, Jana Rieger, Felix Lohrke, Fujimaro Ishida, Satoru Tanioka, Dietmar Frey)</author>
      <guid isPermaLink="false">2502.17360v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Cross-domain Few-shot Object Detection with Multi-modal Textual Enrichment</title>
      <link>http://arxiv.org/abs/2502.16469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2403.16188&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于元学习的框架，通过引入丰富的文本语义作为辅助模态来解决跨域多模态少样本目标检测中的领域偏移问题。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态物体检测方法在遇到显著的领域变化时会表现出性能下降。现有的跨模态特征提取和集成的进步提高了少量样本学习任务的表现，但仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过结合丰富的文本信息来增强模型建立视觉实例与其语言描述之间的知识关系的能力，从而减轻领域偏移带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架用于解决跨域多模态少样本目标检测问题。该框架包含两个关键组件：一个多模态特征聚合模块和一个丰富文本语义修正模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在常见的跨域物体检测基准上，所提方法显著超越了现有的少样本物体检测方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入元学习的框架并利用丰富的文本信息，论文成功地提高了模型在领域偏移情况下的适应性和准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个旨在解决跨域多模态少样本目标检测问题的方法。该方法结合了视觉和语言特征，并采用了文本语义修正模块来增强其性能。实验结果显示，在标准基准测试中，这种方法优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in cross-modal feature extraction and integration havesignificantly enhanced performance in few-shot learning tasks. However, currentmulti-modal object detection (MM-OD) methods often experience notableperformance degradation when encountering substantial domain shifts. We proposethat incorporating rich textual information can enable the model to establish amore robust knowledge relationship between visual instances and theircorresponding language descriptions, thereby mitigating the challenges ofdomain shift. Specifically, we focus on the problem of Cross-Domain Multi-ModalFew-Shot Object Detection (CDMM-FSOD) and introduce a meta-learning-basedframework designed to leverage rich textual semantics as an auxiliary modalityto achieve effective domain adaptation. Our new architecture incorporates twokey components: (i) A multi-modal feature aggregation module, which alignsvisual and linguistic feature embeddings to ensure cohesive integration acrossmodalities. (ii) A rich text semantic rectification module, which employsbidirectional text feature generation to refine multi-modal feature alignment,thereby enhancing understanding of language and its application in objectdetection. We evaluate the proposed method on common cross-domain objectdetection benchmarks and demonstrate that it significantly surpasses existingfew-shot object detection approaches.</description>
      <author>example@mail.com (Zeyu Shangguan, Daniel Seita, Mohammad Rostami)</author>
      <guid isPermaLink="false">2502.16469v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Utilizing AI and Machine Learning for Predictive Analysis of Post-Treatment Cancer Recurrence</title>
      <link>http://arxiv.org/abs/2502.15825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;探讨了人工智能和机器学习在癌症复发预测中的应用，以及它们如何通过分析大量遗传学、临床表现和治疗数据来提高个性化医疗水平。&lt;h4&gt;背景&lt;/h4&gt;肿瘤复发是肿瘤学中一个主要挑战，传统的癌症复发预测依赖于统计模型支持的临床观察，但无法完全解释其复杂的多因素特性。&lt;h4&gt;目的&lt;/h4&gt;研究AI和ML在癌症复发预测中的潜在应用，以改善治疗后的患者生存率和生活质量。&lt;h4&gt;方法&lt;/h4&gt;描述了使用监督学习和无监督学习技术来识别模式并预测癌症患者的结局的各种AI和ML技术。&lt;h4&gt;主要发现&lt;/h4&gt;AI和ML技术能够提供早期干预的机会，并有助于设计更有效的治疗计划。&lt;h4&gt;结论&lt;/h4&gt;AI和ML为个性化医学和患者管理提供了新的机会，提高了复发预测的准确性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已从英文翻译为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.60087/jklst.vol2.n3.p599&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In oncology, recurrence after treatment is one of the major challenges,related to patients' survival and quality of life. Conventionally, predictionof cancer relapse has always relied on clinical observation with statisticalmodel support, which almost fails to explain the complex, multifactorial natureof tumor recurrence. This research explores how AI and ML models may increasethe accuracy and reliability of recurrence prediction in cancer. Therefore, AIand ML create new opportunities not only for personalized medicine but also forproactive management of patients through analyzing large volumes of data ongenetics, clinical manifestations, and treatment. The paper describes thevarious AI and ML techniques for pattern identification and outcome predictionin cancer patients using supervised and unsupervised learning. Clinicalimplications provide an opportunity to review how early interventions couldhappen and the design of treatment planning.</description>
      <author>example@mail.com (Muhammad Umer Qayyum, Muhammad Fahad, Nasrullah Abbasi)</author>
      <guid isPermaLink="false">2502.15825v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Trunk-branch Contrastive Network with Multi-view Deformable Aggregation for Multi-view Action Recognition</title>
      <link>http://arxiv.org/abs/2502.16493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的称为TBCNet的框架，用于基于RGB多视角的动作识别。该网络通过主干和分支的对比学习过程获得融合特征，并补充关键细节。&lt;h4&gt;背景&lt;/h4&gt;传统的动作识别研究通常从每个视图中提取精炼特征，然后实现配对交互和整合，但这种方法可能会忽视每个视图中的重要局部特征。&lt;h4&gt;目的&lt;/h4&gt;为了模拟人类从多个角度观察物体时形成的综合印象以及随后填补具体细节的认知过程，提出了一种新的网络框架TBCNet。&lt;h4&gt;方法&lt;/h4&gt;设计了两个核心组件：多视角可变形聚集（MVDA）和主干-分支对比学习。 MVDA利用全局汇聚模块强调重要的空间信息，并通过复合相对位置偏差捕捉视图内的及跨视图的相对位置，而主干-分支对比损失则是在聚合特征与每个视图中的精炼细节之间构建。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示TBCNet在NTU-RGB+D 60, NTU-RGB+D 120, PKU-MMD和N-UCLA等四个数据集上优于其他基于RGB的方法，尤其在跨主体（Cross-Subject）及跨场景（Cross-View）协议下取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为RGB多视角动作识别提供了一种有效的新方法TBCNet，并通过实验验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view action recognition aims to identify actions in a given multi-viewscene. Traditional studies initially extracted refined features from each view,followed by implemented paired interaction and integration, but theypotentially overlooked the critical local features in each view. When observingobjects from multiple perspectives, individuals typically form a comprehensiveimpression and subsequently fill in specific details. Drawing inspiration fromthis cognitive process, we propose a novel trunk-branch contrastive network(TBCNet) for RGB-based multi-view action recognition. Distinctively, TBCNetfirst obtains fused features in the trunk block and then implicitly supplementsvital details provided by the branch block via contrastive learning, generatinga more informative and comprehensive action representation. Within thisframework, we construct two core components: the multi-view deformableaggregation and the trunk-branch contrastive learning. MVDA employed in thetrunk block effectively facilitates multi-view feature fusion and adaptivecross-view spatio-temporal correlation, where a global aggregation module isutilized to emphasize significant spatial information and a composite relativeposition bias is designed to capture the intra- and cross-view relativepositions. Moreover, a trunk-branch contrastive loss is constructed betweenaggregated features and refined details from each view. By incorporating twodistinct weights for positive and negative samples, a weighted trunk-branchcontrastive loss is proposed to extract valuable information and emphasizesubtle inter-class differences. The effectiveness of TBCNet is verified byextensive experiments on four datasets including NTU-RGB+D 60, NTU-RGB+D 120,PKU-MMD, and N-UCLA dataset. Compared to other RGB-based methods, our approachachieves state-of-the-art performance in cross-subject and cross-settingprotocols.</description>
      <author>example@mail.com (Yingyuan Yang, Guoyuan Liang, Can Wang, Xiaojun Wu)</author>
      <guid isPermaLink="false">2502.16493v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Layer-Wise Evolution of Representations in Fine-Tuned Transformers: Insights from Sparse AutoEncoders</title>
      <link>http://arxiv.org/abs/2502.16722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了预训练变压器微调过程中的内部机制，特别是BERT模型，并通过分析激活相似性、训练稀疏自编码器以及可视化不同层的标记级激活来探索这一过程。&lt;h4&gt;背景&lt;/h4&gt;微调预训练的变换器是增强基础模型在特定任务上性能的强大技术。这种方法对于将通用架构适应于专门的任务非常关键，从早期应用到如BERT这样的模型到现在用于大型语言模型（LLM）的应用。&lt;h4&gt;目的&lt;/h4&gt;理解微调过程对于揭示变压器如何根据具体目标进行调整、保留一般表示以及获取任务特有特征至关重要。&lt;h4&gt;方法&lt;/h4&gt;论文通过分析激活相似性、训练稀疏自编码器和可视化不同层的标记级激活来探索微调机制，特别是针对BERT变换器。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示随着深度增加，特征如何适应任务的变化：早期层次主要保留一般表示；中间层次充当通用与任务特有特征之间的过渡；后期层次完全专注于任务适应。&lt;h4&gt;结论&lt;/h4&gt;这些发现在理解微调过程和它对转换架构内表征学习的影响方面提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained transformers is a powerful technique for enhancingthe performance of base models on specific tasks. From early applications inmodels like BERT to fine-tuning Large Language Models (LLMs), this approach hasbeen instrumental in adapting general-purpose architectures for specializeddownstream tasks. Understanding the fine-tuning process is crucial foruncovering how transformers adapt to specific objectives, retain generalrepresentations, and acquire task-specific features. This paper explores theunderlying mechanisms of fine-tuning, specifically in the BERT transformer, byanalyzing activation similarity, training Sparse AutoEncoders (SAEs), andvisualizing token-level activations across different layers. Based onexperiments conducted across multiple datasets and BERT layers, we observe asteady progression in how features adapt to the task at hand: early layersprimarily retain general representations, middle layers act as a transitionbetween general and task-specific features, and later layers fully specializein task adaptation. These findings provide key insights into the inner workingsof fine-tuning and its impact on representation learning within transformerarchitectures.</description>
      <author>example@mail.com (Suneel Nadipalli)</author>
      <guid isPermaLink="false">2502.16722v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning of English Language and Crystal Graphs for Multimodal Representation of Materials Knowledge</title>
      <link>http://arxiv.org/abs/2502.16451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 14 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了用于材料逆向设计的人工智能（AI）在晶体领域的应用，提出了对比语言-晶体模型CLaC，并通过实验验证了其优越性。&lt;h4&gt;背景&lt;/h4&gt;人工智能技术越来越多地应用于材料的逆向设计中，尤其是在分子领域，已经成功将化学结构与文本知识结合使用。然而，在晶体研究方面，由于偏斜的数据分布和学术文献中的语义监督不足，这种方法难以实现。&lt;h4&gt;目的&lt;/h4&gt;为了克服数据稀缺问题，并展示合成数据在解决这一问题上的优势，提出了一种新的对比语言-晶体模型CLaC。&lt;h4&gt;方法&lt;/h4&gt;通过构建包含126k晶体结构文本对的新合成数据集和一个从学术论文中提取的相似数据集，预训练了CLaC模型。然后评估其跨模态任务和下游应用中的零样本泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLaC在理解晶体结构方面实现了最新的零样本泛化性能，并且超越了现有的大型语言模型。&lt;h4&gt;结论&lt;/h4&gt;所提出的CLaC模型展示了其在理解和设计晶体材料方面的潜力，为未来的AI辅助逆向材料设计提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的原文是关于介绍了一种对比语言-晶体模型（CLaC），该模型基于126K个合成的数据集进行预训练，并通过跨模态任务和下游应用验证了其优越性，特别是在零样本泛化性能方面超越了当前的大规模语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) is increasingly used for the inverse design ofmaterials, such as crystals and molecules. Existing AI research on moleculeshas integrated chemical structures of molecules with textual knowledge to adaptto complex instructions. However, this approach has been unattainable forcrystals due to data scarcity from the biased distribution of investigatedcrystals and the lack of semantic supervision in peer-reviewed literature. Inthis work, we introduce a contrastive language-crystals model (CLaC)pre-trained on a newly synthesized dataset of 126k crystal structure-textpairs. To demonstrate the advantage of using synthetic data to overcome datascarcity, we constructed a comparable dataset extracted from academic papers.We evaluate CLaC's generalization ability through various zero-shot cross-modaltasks and downstream applications. In experiments, CLaC achievesstate-of-the-art zero-shot generalization performance in understanding crystalstructures, surpassing latest large language models.</description>
      <author>example@mail.com (Yang Jeong Park, Mayank Kumaran, Chia-Wei Hsu, Elsa Olivetti, Ju Li)</author>
      <guid isPermaLink="false">2502.16451v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI</title>
      <link>http://arxiv.org/abs/2502.17092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Shakti VLM是一个包含10亿和40亿参数的视觉-语言模型家族，旨在解决多模态学习中的数据效率挑战。&lt;h4&gt;背景&lt;/h4&gt;近年来，许多视觉-语言模型通过大量训练数据取得了优异的成绩。然而，在大规模数据集不可用的情况下，现有方法难以有效解决问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以利用架构创新来减少对海量训练数据依赖的视觉-语言模型。&lt;h4&gt;方法&lt;/h4&gt;1. 使用QK-Normalization提高注意力机制的稳定性2. 引入混合归一化技术以增强模型性能3. 采用改进的位置编码提升多模态理解能力4. 实施三阶段训练策略优化学习效率&lt;h4&gt;主要发现&lt;/h4&gt;Shakti VLM-1B和Shakti VLM-4B在文档理解、视觉推理、光学字符识别提取以及通用的多模态推理任务中表现出色，证明了良好的模型设计和有效的训练策略同样可以实现高精度。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过精心设计的架构和技术创新可以使模型更加高效地处理大规模的多模态任务，并且不必依赖海量的数据集。Shakti VLM为解决企业级应用场景中的问题提供了一个高效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：我们介绍了Shakti VLM，这是一个参数容量分别为10亿和40亿的视觉-语言模型家族，旨在应对多模态学习中数据效率方面的挑战。尽管最近的一些视觉-语言模型通过大量训练数据取得了良好的成绩，但Shakti模型则利用架构创新，在较少的数据量下也能取得竞争性的结果。关键改进包括用于提高注意力机制稳定性的QK归一化技术、混合归一化方法以及增强的位置编码策略。此外，一种三阶段的训练策略进一步优化了学习效率。评估结果显示，无论是文档理解还是视觉推理等多模态任务，Shakti VLM-1B和Shakti VLM-4B均表现出色。我们的研究结果表明，通过模型设计和有效的训练策略可以实现高精度，而不需要依靠大量数据集的支持。这使得Shakti成为大规模多模态应用场景下的一种高效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Shakti VLM, a family of vision-language models in the capacityof 1B and 4B parameters designed to address data efficiency challenges inmultimodal learning. While recent VLMs achieve strong performance throughextensive training data, Shakti models leverage architectural innovations toattain competitive results with fewer tokens. Key advancements includeQK-Normalization for attention stability, hybrid normalization techniques, andenhanced positional encoding. A three-stage training strategy further optimizeslearning efficiency. Evaluations show that Shakti-Shakti-VLM-1B andShakti-VLM-4B excel in document understanding, Visual Reasoning, OCRextraction, and general multimodal reasoning. Our results highlight that highperformance can be achieved through model design and training strategy ratherthan sheer data volume, making Shakti an efficient solution forenterprise-scale multimodal tasks.</description>
      <author>example@mail.com (Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi)</author>
      <guid isPermaLink="false">2502.17092v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DemoGen: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning</title>
      <link>http://arxiv.org/abs/2502.16932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://demo-generation.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种低成本的合成数据生成方法DemoGen，该方法能够在不需要大量人工采集的情况下自动生成演示任务，并通过3D点云和场景编辑来增强空间推广能力。&lt;h4&gt;背景&lt;/h4&gt;视觉运动策略在机器人操作中显示出巨大潜力，但由于其有限的空间泛化能力，通常需要大量的手工收集的数据以实现有效性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个低成本、全合成的方法DemoGen，用于自动生成演示，仅需少量的人类收集的示例即可推广到新的对象配置上。&lt;h4&gt;方法&lt;/h4&gt;通过使用3D点云作为观察模式，并通过场景编辑重新排列主体来生成视觉观测。这种方法允许将已有的动作轨迹适应于新的物体布局中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DemoGen能够显著提高在各种现实世界操作任务中的策略性能，甚至包括复杂的情境如变形对象、灵巧的手末端执行器和双臂平台的操作。&lt;h4&gt;结论&lt;/h4&gt;除了改进空间推广能力外，DemoGen还可以扩展以提供额外的分布外功能，例如对干扰的抵抗能力和避障能力。&lt;h4&gt;翻译&lt;/h4&gt;视觉运动策略在机器人操作中已显示出巨大的潜力，但为了实现有效性能，通常需要大量的手工收集的数据。一个主要原因在于其有限的空间泛化能力，这要求必须跨越不同物体配置广泛地采集数据。在这项工作中，我们提出了DemoGen，这是一种低成本、完全合成的方法来自动生成演示。利用仅需一次的人工收集的示例，DemoGen通过适应已展示的动作轨迹到新的物体布局中来生成空间增强的演示。视觉观测是通过使用3D点云作为模态并重新排列场景中的主体以实现3D编辑的方式进行合成。实证上，DemoGen显著提升了在各种现实世界操作任务中的策略性能，并展示了其在涉及可变形对象、灵巧手末端执行器和双臂平台的挑战性情况下的应用潜力。此外，DemoGen可以扩展以提供额外的分布外功能，包括干扰抵抗能力和避障能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor policies have shown great promise in robotic manipulation butoften require substantial amounts of human-collected data for effectiveperformance. A key reason underlying the data demands is their limited spatialgeneralization capability, which necessitates extensive data collection acrossdifferent object configurations. In this work, we present DemoGen, a low-cost,fully synthetic approach for automatic demonstration generation. Using only onehuman-collected demonstration per task, DemoGen generates spatially augmenteddemonstrations by adapting the demonstrated action trajectory to novel objectconfigurations. Visual observations are synthesized by leveraging 3D pointclouds as the modality and rearranging the subjects in the scene via 3Dediting. Empirically, DemoGen significantly enhances policy performance acrossa diverse range of real-world manipulation tasks, showing its applicabilityeven in challenging scenarios involving deformable objects, dexterous handend-effectors, and bimanual platforms. Furthermore, DemoGen can be extended toenable additional out-of-distribution capabilities, including disturbanceresistance and obstacle avoidance.</description>
      <author>example@mail.com (Zhengrong Xue, Shuying Deng, Zhenyang Chen, Yixuan Wang, Zhecheng Yuan, Huazhe Xu)</author>
      <guid isPermaLink="false">2502.16932v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Training for Defense Against Label Poisoning Attacks</title>
      <link>http://arxiv.org/abs/2502.17121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the International Conference on Learning Representations  (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的对抗训练防御策略FLORAL，该策略基于支持向量机（SVM）来应对模型训练过程中标签中毒攻击的威胁。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习模型越来越复杂且依赖于公共数据源进行训练，例如大规模语言模型使用的标注数据，这些模型更容易受到标签中毒攻击。这种攻击方式是通过对手微妙地改变训练集中的标签来进行的，这可能导致模型性能严重下降，在关键应用中造成重大风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的防御策略FLORAL来对抗由标签中毒造成的威胁。&lt;h4&gt;方法&lt;/h4&gt;基于支持向量机（SVM）和双层优化框架，将训练过程描述为攻防双方的非零和斯塔克伯格博弈。该方法适应多种模型架构，并使用带有核函数的支持向量机进行投影梯度下降算法以执行对抗训练。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明了算法收敛性的特性，实验结果证实FLORAL在各种分类任务中均能取得比Robust基线和RoBERTa等基础模型更好的鲁棒准确性。当攻击者预算增加时，FLORAL仍然能够保持更高的稳健精度。&lt;h4&gt;结论&lt;/h4&gt;FLORAL策略具有提高机器学习模型对抗标签中毒威胁的鲁棒性的潜力，在敌对环境中确保分类任务的安全性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;随着机器学习模型变得越来越复杂，并且越来越多地依赖于公开来源的数据，例如在训练大型语言模型时使用的由人类标注的标签，这些模型更容易受到标签中毒攻击。这种攻击方式是通过对手微妙地改变训练数据集中的标签来执行的，这可能导致模型性能严重下降，在关键应用中造成重大风险。在这篇论文中，我们提出了FLORAL策略，这是一种基于支持向量机（SVM）的新对抗性训练防御策略，用于应对这些威胁。使用双层优化框架，我们将训练过程描述为攻防双方之间的非零和斯塔克伯格博弈，一方是战略性地污染关键训练标签的攻击者，另一方是试图从这些攻击中恢复过来的模型。该方法适用于多种架构，并采用带有核函数的支持向量机进行投影梯度下降算法来进行对抗性训练。我们提供了该算法收敛性质的理论分析，并通过实验证明了FLORAL策略在各种分类任务中的有效性。与鲁棒基线和基础模型（如RoBERTa）相比，随着攻击者预算增加时，FLORAL始终能保持更高的稳健精度。这些结果强调了FLORAL提高机器学习模型对抗标签中毒威胁的韧性潜力，在敌对环境中确保分类任务的安全性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As machine learning models grow in complexity and increasingly rely onpublicly sourced data, such as the human-annotated labels used in traininglarge language models, they become more vulnerable to label poisoning attacks.These attacks, in which adversaries subtly alter the labels within a trainingdataset, can severely degrade model performance, posing significant risks incritical applications. In this paper, we propose FLORAL, a novel adversarialtraining defense strategy based on support vector machines (SVMs) to counterthese threats. Utilizing a bilevel optimization framework, we cast the trainingprocess as a non-zero-sum Stackelberg game between an attacker, whostrategically poisons critical training labels, and the model, which seeks torecover from such attacks. Our approach accommodates various modelarchitectures and employs a projected gradient descent algorithm with kernelSVMs for adversarial training. We provide a theoretical analysis of ouralgorithm's convergence properties and empirically evaluate FLORAL'seffectiveness across diverse classification tasks. Compared to robust baselinesand foundation models such as RoBERTa, FLORAL consistently achieves higherrobust accuracy under increasing attacker budgets. These results underscore thepotential of FLORAL to enhance the resilience of machine learning modelsagainst label poisoning threats, thereby ensuring robust classification inadversarial settings.</description>
      <author>example@mail.com (Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach)</author>
      <guid isPermaLink="false">2502.17121v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unified Semantic and ID Representation Learning for Deep Recommenders</title>
      <link>http://arxiv.org/abs/2502.16474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合ID和语义表示的推荐系统框架，旨在解决传统基于ID令牌的推荐系统的冗余问题以及新项目冷启动时的表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的推荐系统依赖于ID令牌来唯一标识项目，但在处理项目重复和新项目的推荐方面存在不足。最近的方法尝试使用语义令牌作为替代方案，但面临挑战如项目复制和不一致的性能提升。&lt;h4&gt;目的&lt;/h4&gt;开发一种综合了ID和语义表示的学习框架以克服现有方法的局限性，并探索余弦相似度和欧几里得距离在嵌入搜索中的作用。&lt;h4&gt;方法&lt;/h4&gt;提出了一个统一的ID与语义表示学习框架，该框架利用两种令牌类型的优势。在这个框架中，ID令牌捕捉项目独特属性，而语义令牌则代表共享、可转移的特点。此外，还分析了余弦相似度和欧几里得距离在嵌入搜索中的作用，并整合这两种方法来优化表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法显著优于现有的基准模型，在三个基准数据集上的性能提高了6%至17%，并且令牌大小减少了超过80%。&lt;h4&gt;结论&lt;/h4&gt;本文证明了将ID和语义标记结合可以增强推荐系统的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;有效的推荐对大型在线平台至关重要。传统的推荐系统主要依赖于标识符（ID）令牌来唯一识别项目，能够有效捕捉特定项目的联系，但在冗余性和冷启动场景中的表现不佳。最近的研究探索了使用语义令牌作为替代方法，但面临诸如项目复制和不一致性能收益的问题。为解决这些局限性，本文提出了一种综合ID与语义表示的学习框架，利用两种标记类型的优势。实验显示该方法在三个基准数据集上显著优于现有基线模型，改善幅度从6%到17%，并且令牌大小减少了超过80%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective recommendation is crucial for large-scale online platforms.Traditional recommendation systems primarily rely on ID tokens to uniquelyidentify items, which can effectively capture specific item relationships butsuffer from issues such as redundancy and poor performance in cold-startscenarios. Recent approaches have explored using semantic tokens as analternative, yet they face challenges, including item duplication andinconsistent performance gains, leaving the potential advantages of semantictokens inadequately examined. To address these limitations, we propose aUnified Semantic and ID Representation Learning framework that leverages thecomplementary strengths of both token types. In our framework, ID tokenscapture unique item attributes, while semantic tokens represent shared,transferable characteristics. Additionally, we analyze the role of cosinesimilarity and Euclidean distance in embedding search, revealing that cosinesimilarity is more effective in decoupling accumulated embeddings, whileEuclidean distance excels in distinguishing unique items. Our frameworkintegrates cosine similarity in earlier layers and Euclidean distance in thefinal layer to optimize representation learning. Experiments on three benchmarkdatasets show that our method significantly outperforms state-of-the-artbaselines, with improvements ranging from 6\% to 17\% and a reduction in tokensize by over 80%. These results demonstrate the effectiveness of combining IDand semantic tokenization to enhance the generalization ability of recommendersystems.</description>
      <author>example@mail.com (Guanyu Lin, Zhigang Hua, Tao Feng, Shuang Yang, Bo Long, Jiaxuan You)</author>
      <guid isPermaLink="false">2502.16474v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Separated Contrastive Learning for Matching in Cross-domain Recommendation with Curriculum Scheduling</title>
      <link>http://arxiv.org/abs/2502.16239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SCCDR的新框架，用于解决跨域推荐任务中的训练不稳定问题。&lt;h4&gt;背景&lt;/h4&gt;跨域推荐(CDR)旨在通过利用源领域信息来改善目标领域的推荐性能。对比学习方法在处理同一领域内的用户或项目时被广泛采用，并且对于知识迁移和表示学习也很有效。&lt;h4&gt;目的&lt;/h4&gt;解决直接应用对比学习于混合的同域内和跨域任务所带来的训练不稳定问题，这会导致表示学习过程恶化以及生成嵌入质量降低的问题。&lt;h4&gt;方法&lt;/h4&gt;SCCDR基于分离的同域内和跨域内的对比学习模式以及一个停止梯度操作来处理这一不足。该框架包括两个专门的课程阶段：同异域分离和跨域课程调度。前者为源域和目标域分别使用了两种不同的对比视角，后者则通过考虑重叠用户所锚定的负样本难度，采用了课程调度策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明SCCDR在多个基准上达到了最新的性能水平，并且在线A/B测试也验证了这一点。&lt;h4&gt;结论&lt;/h4&gt;提出的框架能够有效地解决跨域推荐任务中的训练不稳定问题，并提高表示学习的质量和生成嵌入的效果，从而提升整体推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了SCCDR框架的创新方法及其在解决跨域推荐（CDR）中对比学习时遇到的问题方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3701716.3715260&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain recommendation (CDR) is a task that aims to improve therecommendation performance in a target domain by leveraging the informationfrom source domains. Contrastive learning methods have been widely adoptedamong intra-domain (intra-CL) and inter-domain (inter-CL) users/items for theirrepresentation learning and knowledge transfer during the matching stage ofCDR. However, we observe that directly employing contrastive learning onmixed-up intra-CL and inter-CL tasks ignores the difficulty of learning frominter-domain over learning from intra-domain, and thus could cause severetraining instability. Therefore, this instability deteriorates therepresentation learning process and hurts the quality of generated embeddings.To this end, we propose a novel framework named SCCDR built up on a separatedintra-CL and inter-CL paradigm and a stop-gradient operation to handle thedrawback. Specifically, SCCDR comprises two specialized curriculum stages:intra-inter separation and inter-domain curriculum scheduling. The former stageexplicitly uses two distinct contrastive views for the intra-CL task in thesource and target domains, respectively. Meanwhile, the latter stagedeliberately tackles the inter-CL tasks with a curriculum scheduling strategythat derives effective curricula by accounting for the difficulty of negativesamples anchored by overlapping users. Empirical experiments on variousopen-source datasets and an offline proprietary industrial dataset extractedfrom a real-world recommender system, and an online A/B test verify that SCCDRachieves state-of-the-art performance over multiple baselines.</description>
      <author>example@mail.com (Heng Chang, Liang Gu, Cheng Hu, Zhinan Zhang, Hong Zhu, Yuhui Xu, Yuan Fang, Zhen Chen)</author>
      <guid isPermaLink="false">2502.16239v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Set a Thief to Catch a Thief: Combating Label Noise through Noisy Meta Learning</title>
      <link>http://arxiv.org/abs/2502.16104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一个新颖的噪声元标签校正框架STCT，旨在利用带有噪声的数据来纠正标签错误，并通过实验验证了其在高噪声率场景下的卓越性能。&lt;h4&gt;背景&lt;/h4&gt;从嘈杂的标签中学习（LNL）的目标是使用带噪数据集训练高性能深度模型。基于元学习的方法已经在LNL任务上表现出色，但需要额外的干净验证集来执行标签校正，这限制了其实用性。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一问题，本文提出了一种新颖的噪声元标签校正框架STCT，该框架可以使用带噪数据作为验证集，并在不依赖于额外干净数据的情况下进行标签校正。&lt;h4&gt;方法&lt;/h4&gt;STCT通过将复杂的双层优化分解为表示学习和标签校正两个部分，并采用交替训练策略来解决这个问题。具体来说，在元学习框架中利用与训练数据独立同分布的噪声数据作为验证集评估模型性能并执行标签校正。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STCT在合成数据集和真实世界数据集上展示了卓越的表现，特别是在高噪声率场景下。当CIFAR-10数据集中含有80%对称噪声时，STCT的标签校正准确率为96.9%，分类性能为95.2%，显著优于现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;与现有的基于元学习的LNL方法相比，所提出的STCT框架通过利用带噪数据进行自我纠正，在不依赖额外干净验证集的情况下实现了更优的标签校正和模型训练效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from noisy labels (LNL) aims to train high-performance deep modelsusing noisy datasets. Meta learning based label correction methods havedemonstrated remarkable performance in LNL by designing various meta labelrectification tasks. However, extra clean validation set is a prerequisite forthese methods to perform label correction, requiring extra labor and greatlylimiting their practicality. To tackle this issue, we propose a novel noisymeta label correction framework STCT, which counterintuitively uses noisy datato correct label noise, borrowing the spirit in the saying ``Set a Thief toCatch a Thief''. The core idea of STCT is to leverage noisy data which isi.i.d. with the training data as a validation set to evaluate model performanceand perform label correction in a meta learning framework, eliminating the needfor extra clean data. By decoupling the complex bi-level optimization in metalearning into representation learning and label correction, STCT is solvedthrough an alternating training strategy between noisy meta correction andsemi-supervised representation learning. Extensive experiments on synthetic andreal-world datasets demonstrate the outstanding performance of STCT,particularly in high noise rate scenarios. STCT achieves 96.9% label correctionand 95.2% classification performance on CIFAR-10 with 80% symmetric noise,significantly surpassing the current state-of-the-art.</description>
      <author>example@mail.com (Hanxuan Wang, Na Lu, Xueying Zhao, Yuxuan Yan, Kaipeng Ma, Kwoh Chee Keong, Gustavo Carneiro)</author>
      <guid isPermaLink="false">2502.16104v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Institution-Specific Bias in Pathology Foundation Models: Detriments, Causes, and Potential Solutions</title>
      <link>http://arxiv.org/abs/2502.16889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages,1 figure,14 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;病理基础模型在提取有价值的区别性特征方面具有优势，但存在图像特异性信息污染的问题，影响了其泛化能力。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型简化了深度学习模型的开发，并通过利用先验知识提高了诊断准确性。然而，在实际临床应用中，由于机构特定的信息干扰，这些模型的表现可能会下降。&lt;h4&gt;目的&lt;/h4&gt;揭示病理基础模型中的特征污染问题及其对性能的影响，并探讨其背后的原因及可能的解决方案。&lt;h4&gt;方法&lt;/h4&gt;识别并验证了病理图像中的机构特定信息如何被当前的基础模型捕捉到，通过广泛的实验展示了非诊断相关的信息在出界分布场景下对性能的负面影响。&lt;h4&gt;主要发现&lt;/h4&gt;病理基础模型容易提取与疾病无关但又存在于不同医疗机构之间的特征信息。这些污染导致了虚假的相关性，削弱了模型的应用能力。&lt;h4&gt;结论&lt;/h4&gt;提出了减轻机构特定信息影响的方法，并呼吁未来的研究关注创新训练策略而非单纯依赖规模效应来发展更具有泛化的病理基础模型。&lt;h4&gt;翻译&lt;/h4&gt;病理基础模型（PFMs）从图像中提取有价值的区别性特征用于下游临床任务。虽然它们简化了深度学习模型的开发，有效利用先验知识提高了不同场景下的诊断准确性，但发现PFMs有时面临挑战：从图像中提取出的特性经常受到与诊断无关的信息干扰，即特定机构相关的特性，这可能导致虚假的相关性并削弱模型在现实中的应用能力。在这项研究中，我们揭示了特征污染的问题，展示了病理基础模型中存在的机构特有特性，并深入调查其负面影响、分析原因并提出见解。我们发现当前的PFMs可以轻易捕捉到病理图像中的特定信息，通过广泛的实验表明，非诊断相关信息对性能有害，特别是在出界分布设置下，依赖于这些被污染的特征会导致显著的表现下降。这揭示了模型可能受到误导的因素。进一步探讨了PFMs提取机构特定信息的原因，并验证了这一发现。最后提出了一个简单而有效的方法来缓解无关信息的影响。这项研究并非旨在批评现有的病理基础模型，而是要启发未来的科研专注于创新训练策略而非仅依赖规模效应以实现更加泛化的病理基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology foundation models (PFMs) extract valuable discriminative featuresfrom images for downstream clinical tasks. PFMs have simplified the developmentof deep learning models, effectively leveraging prior knowledge to improvediagnostic accuracy in diverse scenarios. However, we find that PFMs sometimesstruggle with certain challenges. Specifically, features extracted by PFMs areoften contaminated by diagnosis-irrelevant information, i.e.,institution-specific features associated with the images. This contaminationcan lead to spurious correlations, undermining the models' generalizationability when applied in real-world clinical settings. In this work, we firstreveal the issue of feature contamination in PFMs, demonstrate the presence ofinstitution-specific features, thoroughly investigate its negative impacts,analyze the underlying causes, and provide insights into potential solutions.Specifically, we find that institution-specific information is embedded inpathological images and can be readily captured by current PFMs. Throughextensive experiments, we demonstrate the detrimental impact of this irrelevantinformation, particularly in out-of-distribution (OOD) settings, where relianceon contaminated features leads to significant performance degradation. Thisindicates that the models are being misled by non-diagnostic information. Wefurther delve into the reasons PFMs extract such institution-specificinformation and validate our findings. Finally, we propose a simple yeteffective solution to mitigate the influence of irrelevant information. Thisstudy is not intended to criticize existing PFMs, as they have indeed greatlyadvanced the development of computational pathology. our aim is to inspirefuture research to focus on innovative training strategies, rather than relyingexclusively on scaling laws, to realize more generalized PFMs.</description>
      <author>example@mail.com (Weiping Lin, Shen Liu, Runchen Zhu, Liansheng Wang)</author>
      <guid isPermaLink="false">2502.16889v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Subsampling Graphs with GNN Performance Guarantees</title>
      <link>http://arxiv.org/abs/2502.16703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的图数据子采样方法，利用树移动距离减少图的数量和大小，该方法在理论上保证了训练后的模型损失相比完整数据集的增加是有限制的。&lt;h4&gt;背景&lt;/h4&gt;如何从大规模图数据集中有效地选择一个子样本进行GNN训练，使得其性能与整个数据集上的训练效果相当是一个重要的研究问题。较小的数据集可以减少标注成本、存储需求和所需的计算资源。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的基于理论支持的图数据子采样方法，能够在不牺牲模型性能的情况下减小数据集规模。&lt;h4&gt;方法&lt;/h4&gt;利用树移动距离作为度量标准来选择一个有效的子样本。该方法既对模型架构无特定要求也无需完全标注训练集即可实施。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示所提出的方法在多个数据集上优于现有的子采样技术，同时证明了其理论上的性能保证。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以在早期的数据预处理阶段进行有效的图数据子采样，从而减少存储、标注和训练所需的资源。该方法具有广泛的适用性，因为它对模型架构和标签信息没有强依赖性。&lt;h4&gt;翻译&lt;/h4&gt;如何从大规模图数据集中有效地选择一个子样本进行GNN训练，使得其性能与整个数据集上的训练效果相当是一个重要的研究问题。较小的数据集可以减少标注成本、存储需求和所需的计算资源。现有技术的不足之处在于它们可能严重降低模型性能或需要大量实验来验证质量，从而消除了子采样的好处。因此，作者提出了一种新的基于理论支持的方法：利用树移动距离进行图数据子采样，并且证明了在子样本上训练GNN会导致损失增加是有限制的。这种方法具有广泛的适用性，因为它对模型架构和标签信息没有强依赖性。实验结果验证了该方法的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How can we subsample graph data so that a graph neural network (GNN) trainedon the subsample achieves performance comparable to training on the fulldataset? This question is of fundamental interest, as smaller datasets reducelabeling costs, storage requirements, and computational resources needed fortraining. Selecting an effective subset is challenging: a poorly chosensubsample can severely degrade model performance, and empirically testingmultiple subsets for quality obviates the benefits of subsampling. Therefore,it is critical that subsampling comes with guarantees on model performance. Inthis work, we introduce new subsampling methods for graph datasets thatleverage the Tree Mover's Distance to reduce both the number of graphs and thesize of individual graphs. To our knowledge, our approach is the first that issupported by rigorous theoretical guarantees: we prove that training a GNN onthe subsampled data results in a bounded increase in loss compared to trainingon the full dataset. Unlike existing methods, our approach is bothmodel-agnostic, requiring minimal assumptions about the GNN architecture, andlabel-agnostic, eliminating the need to label the full training set. Thisenables subsampling early in the model development pipeline (before dataannotation, model selection, and hyperparameter tuning) reducing costs andresources needed for storage, labeling, and training. We validate ourtheoretical results with experiments showing that our approach outperformsexisting subsampling methods across multiple datasets.</description>
      <author>example@mail.com (Mika Sarkin Jain, Stefanie Jegelka, Ishani Karmarkar, Luana Ruiz, Ellen Vitercik)</author>
      <guid isPermaLink="false">2502.16703v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.16198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Communications Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;6G网络旨在实现全球覆盖、海量连接和超严格的要求。为了实现这些目标，空间-空中-地面综合网络（SAGIN）和语义通信（SemCom）是必不可少的组成部分，但它们在资源调配方面带来了相当大的复杂性。&lt;h4&gt;背景&lt;/h4&gt;当前的研究提出了利用大型语言模型（LLMs）来解决上述问题的一种可行方法。尽管最近在网络调度中使用LLMs已经引起了关注，但现有的解决方案并没有充分解决LLMs幻觉或适应网络动态的问题。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种名为自主强化协调（ARC）的框架，该框架针对具有语义通信功能的空间-空中-地面综合网络设计。&lt;h4&gt;方法&lt;/h4&gt;ARC框架利用基于大型语言模型增强检索生成器(RAG)来监控服务、用户和资源，并处理收集到的数据。同时，分层行动规划器(HAP)负责资源调度工作。ARC通过两个层次来分解资源调配任务：高层使用LLMs进行计划，低层由强化学习(Reinforcement Learning, RL)代理进行决策。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs利用链式思维(CoT)推理进行少样本学习，并通过对比学习增强能力；RL代理则采用重放缓冲区管理来实现持续学习。因此，这种方法可以达到高效、准确和适应性。&lt;h4&gt;结论&lt;/h4&gt;论文通过模拟展示了ARC的有效性，并提供了一个关于如何进一步改进和完善ARC的深入讨论，包括未来的潜在研究方向。&lt;h4&gt;翻译&lt;/h4&gt;6G网络追求全球覆盖、海量连接以及超高标准的要求。空间-空中-地面综合网络(SAGIN)与语义通信技术为实现上述目标是不可或缺的技术手段，然而它们带来了资源协调上的巨大挑战。借鉴机器人领域的研究成果，本文提出了一种运用大型语言模型(如LLMs)作为解决方案的思路来应对这种复杂性，并设计了一个名为自主强化协调(ARC)的新框架以支持SAGIN内的语义通信系统。该框架通过分层架构实现对网络资源的有效管理与优化，在高层采用LLMs进行策略规划，低层使用RL代理作出具体决策；并且针对LLMs易产生的“幻觉”问题及适应网络动态的需求提出了改进方案。实验结果表明该方法具备高效的性能、准确的预测能力和良好的适应性，并探讨了未来可能的研究方向以进一步完善ARC框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6G networks aim to achieve global coverage, massive connectivity, andultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) andSemantic Communication (SemCom) are essential for realizing these goals, yetthey introduce considerable complexity in resource orchestration. Drawinginspiration from research in robotics, a viable solution to manage thiscomplexity is the application of Large Language Models (LLMs). Although the useof LLMs in network orchestration has recently gained attention, existingsolutions have not sufficiently addressed LLM hallucinations or theiradaptation to network dynamics. To address this gap, this paper proposes aframework called Autonomous Reinforcement Coordination (ARC) for aSemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-AugmentedGenerator (RAG) monitors services, users, and resources and processes thecollected data, while a Hierarchical Action Planner (HAP) orchestratesresources. ARC decomposes orchestration into two tiers, utilizing LLMs forhigh-level planning and Reinforcement Learning (RL) agents for low-leveldecision-making, in alignment with the Mixture of Experts (MoE) concept. TheLLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empoweredby contrastive learning, while the RL agents employ replay buffer managementfor continual learning, thereby achieving efficiency, accuracy, andadaptability. Simulations are provided to demonstrate the effectiveness of ARC,along with a comprehensive discussion on potential future research directionsto enhance and upgrade ARC.</description>
      <author>example@mail.com (Masoud Shokrnezhad, Tarik Taleb)</author>
      <guid isPermaLink="false">2502.16198v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives</title>
      <link>http://arxiv.org/abs/2502.16841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;确保医疗保健中的人工智能（AI）公平性需要能够跨越所有人口群体做出无偏见决策的系统，这要求技术革新与伦理原则相结合。&lt;h4&gt;背景&lt;/h4&gt;基础模型(FMs)通过自我监督学习训练于大规模数据集上，可以在各种医学影像任务中高效地进行适应，同时减少对标注数据的依赖。然而，在不同的人口群体间实现一致性能面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;回顾表明，有效的偏见缓解需要在开发过程的所有阶段采取系统性干预措施，不仅包括模型层面的偏见缓解方法，还需要从数据文档到部署协议的一体化介入。&lt;h4&gt;方法&lt;/h4&gt;本文分析强调了公平基础模型(FMs)在整个开发管道中的综合干预的需求，并展示了如何通过结合系统性的偏见缓解和政策参与来有效地解决技术及机构障碍以实现医疗保健中公正的AI。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，为了推动面向服务不足人群和地区（尤其是那些基础设施有限、计算资源匮乏的地方）的先进医疗技术民主化，公平基础模型(FMs)的发展是至关重要的一步。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种综合框架来推进当前知识，展示了系统性偏见缓解结合政策参与如何有效解决技术及机构障碍，以实现医疗保健中公正的人工智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring equitable Artificial Intelligence (AI) in healthcare demands systemsthat make unbiased decisions across all demographic groups, bridging technicalinnovation with ethical principles. Foundation Models (FMs), trained on vastdatasets through self-supervised learning, enable efficient adaptation acrossmedical imaging tasks while reducing dependency on labeled data. These modelsdemonstrate potential for enhancing fairness, though significant challengesremain in achieving consistent performance across demographic groups. Ourreview indicates that effective bias mitigation in FMs requires systematicinterventions throughout all stages of development. While previous approachesfocused primarily on model-level bias mitigation, our analysis reveals thatfairness in FMs requires integrated interventions throughout the developmentpipeline, from data documentation to deployment protocols. This comprehensiveframework advances current knowledge by demonstrating how systematic biasmitigation, combined with policy engagement, can effectively address bothtechnical and institutional barriers to equitable AI in healthcare. Thedevelopment of equitable FMs represents a critical step toward democratizingadvanced healthcare technologies, particularly for underserved populations andregions with limited medical infrastructure and computational resources.</description>
      <author>example@mail.com (Dilermando Queiroz, Anderson Carlos, André Anjos, Lilian Berton)</author>
      <guid isPermaLink="false">2502.16841v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DUNIA: Pixel-Sized Embeddings via Cross-Modal Alignment for Earth Observation Applications</title>
      <link>http://arxiv.org/abs/2502.17066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为DUNIA的方法，该方法通过图像与全波形LiDAR数据之间的跨模态对齐来学习像素级别的嵌入。这种方法能够直接应用于各种环境监测任务，并在零样本设置下展示了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的自我监督多模式学习方法为地球观测应用生成的是粗糙的补丁大小的嵌入，这限制了它们的有效性和与其他模式（如LiDAR）的集成能力。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有方法的不足，提出了一种新的跨模态对齐方法来学习像素级别的嵌入。&lt;h4&gt;方法&lt;/h4&gt;通过对比训练方式，该模型学会了在零样本设置下应用于各种环境监测任务的像素级别嵌入。具体来说，该研究使用图像和全波形LiDAR数据之间的跨模态对齐进行像素级嵌入的学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在七项环境监测任务中（包括冠层高度测绘、分层冠层覆盖率等），这些嵌入及其零样本分类器通常优于专门的监督模型，即使在低数据量环境下也是如此。此外，在微调设置下，DUNIA展示了强大的低样本能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的方法来解决地球观测任务中像素级别嵌入的学习问题，并展示了其优越的表现和潜力。&lt;h4&gt;翻译&lt;/h4&gt;大量的努力已经被投入到自监督多模态学习为地球观察应用进行适应。然而，现有的方法产生的是粗糙的补丁大小的嵌入，这限制了它们的有效性和与其他模式（如LiDAR）的集成能力。为了弥补这一差距，我们提出了DUNIA——一种通过图像和全波形LiDAR数据之间的跨模态对齐来学习像素级别的嵌入的方法。由于模型以对比方式训练，因此这些嵌入可以直接在各种环境监测任务中零样本设置下应用。在我们的实验中，我们展示了这些嵌入对于七项此类任务的有效性（包括冠层高度测绘、分层冠层覆盖率等）。结果表明，这些嵌入与零样本分类器经常优于专门的监督模型，在低数据量环境下也是如此。在微调设置下，我们在五项任务中的表现接近或超过最新技术水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Significant efforts have been directed towards adapting self-supervisedmultimodal learning for Earth observation applications. However, existingmethods produce coarse patch-sized embeddings, limiting their effectiveness andintegration with other modalities like LiDAR. To close this gap, we presentDUNIA, an approach to learn pixel-sized embeddings through cross-modalalignment between images and full-waveform LiDAR data. As the model is trainedin a contrastive manner, the embeddings can be directly leveraged in thecontext of a variety of environmental monitoring tasks in a zero-shot setting.In our experiments, we demonstrate the effectiveness of the embeddings forseven such tasks (canopy height mapping, fractional canopy cover, land covermapping, tree species identification, plant area index, crop typeclassification, and per-pixel waveform-based vertical structure mapping). Theresults show that the embeddings, along with zero-shot classifiers, oftenoutperform specialized supervised models, even in low data regimes. In thefine-tuning setting, we show strong low-shot capabilities with performancesnear or better than state-of-the-art on five out of six tasks.</description>
      <author>example@mail.com (Ibrahim Fayad, Max Zimmer, Martin Schwartz, Philippe Ciais, Fabian Gieseke, Gabriel Belouze, Sarah Brood, Aurelien De Truchis, Alexandre d'Aspremont)</author>
      <guid isPermaLink="false">2502.17066v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation</title>
      <link>http://arxiv.org/abs/2502.16907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种名为MambaFlow的新型场景流估算网络，该网络利用基于Mamba的状态空间模型（SSM）的解码器来解决现有的点云帧间3D运动预测方法在时空建模和特征丢失方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;场景流估计是自动驾驶领域的一个重要研究方向，旨在从连续的点云帧中预测3D运动。现有方法面临时空建模不足以及体素化过程中细粒度特征损失的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Mamba的状态空间模型（SSM）解码器的方法，以解决现有场景流估计方法中的问题，并提升模型在不同场景下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了名为MambaFlow的新型场景流估算网络。该网络利用一个设计良好的主干网，通过高效的基于Mamba的解码器来指导体素特征的全局注意力建模，学习体素到点的模式，并将共享体素表示去体素化为点级别的特性。&lt;h4&gt;主要发现&lt;/h4&gt;提出了用于增强模型泛化的场景自适应损失函数。在Argoverse 2基准上的大量实验表明，MambaFlow实现了现有的实时推理速度和最先进的性能，能够准确估计现实世界的城市场景中的流。&lt;h4&gt;结论&lt;/h4&gt;MambaFlow展示了其解决现有方法问题的能力，并且证明了使用基于Mamba的解码器进行全局注意力建模的有效性。此外，提出的自适应损失函数进一步增强了模型在不同场景下的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;场景流估计旨在从连续的点云帧中预测3D运动，在自动驾驶领域备受关注。现有方法面临时空建模不足和体素化过程中细粒度特征丢失的问题。然而，Mamba的成功展示了全局建模和线性复杂性的可能性。本文提出了一种基于Mamba的状态空间模型（SSM）解码器的新型场景流估计网络——MambaFlow，它可以利用设计良好的主干网实现时空特征的深度交互耦合，并且提出了一个全新的场景自适应损失函数来提升泛化能力。在Argoverse 2基准上的大量实验表明，MambaFlow实现了现有方法中的实时推理速度和最先进的性能，在现实世界的城市环境中能够准确估计流。代码可以从 https://github.com/SCNU-RISLAB/MambaFlow 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene flow estimation aims to predict 3D motion from consecutive point cloudframes, which is of great interest in autonomous driving field. Existingmethods face challenges such as insufficient spatio-temporal modeling andinherent loss of fine-grained feature during voxelization. However, the successof Mamba, a representative state space model (SSM) that enables global modelingwith linear complexity, provides a promising solution. In this paper, wepropose MambaFlow, a novel scene flow estimation network with a mamba-baseddecoder. It enables deep interaction and coupling of spatio-temporal featuresusing a well-designed backbone. Innovatively, we steer the global attentionmodeling of voxel-based features with point offset information using anefficient Mamba-based decoder, learning voxel-to-point patterns that are usedto devoxelize shared voxel representations into point-wise features. To furtherenhance the model's generalization capabilities across diverse scenarios, wepropose a novel scene-adaptive loss function that automatically adapts todifferent motion patterns.Extensive experiments on the Argoverse 2 benchmarkdemonstrate that MambaFlow achieves state-of-the-art performance with real-timeinference speed among existing works, enabling accurate flow estimation inreal-world urban scenarios. The code is available athttps://github.com/SCNU-RISLAB/MambaFlow.</description>
      <author>example@mail.com (Jiehao Luo, Jintao Cheng, Xiaoyu Tang, Qingwen Zhang, Bohuan Xue, Rui Fan)</author>
      <guid isPermaLink="false">2502.16907v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>UniDyG: A Unified and Effective Representation Learning Approach for Large Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2502.16431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'背景': '动态图在连续时间（CTDGs）和离散时间（DTDGs）下被定义，分别展现出快速局部变化和逐渐全局更新的特点。现有的表示学习研究主要针对其中一种类型的动态图进行，并且通常只关注时间域内的局部动态传播，难以准确捕捉与每种时间粒度相关的结构演变。', '目的': '为了更好地建模这两种类型的动态图，并提升模型的鲁棒性和有效性，提出了一种统一有效的表示学习方法UniDyG。', '方法': '该研究首先提出了一个新颖的傅立叶图注意力（FGAT）机制，可以基于最近邻居和复数选择性聚合来同时建模局部和全局结构相关性，并在理论上确保动态图的时间一致性。通过设计能量门控单元增强FGAT对抗时间噪声的能力，并利用频率增强线性函数进行节点级的动态更新。', '主要发现': '实验表明，所提出的UniDyG方法相较于16个基准模型，在9种动态图上平均改进了14.4%。', '结论': '这项工作提出了一种新的表示学习框架，能够有效应对CTDGs和DTDGs中的挑战，并通过实证研究证明其优越性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs are formulated in continuous-time or discrete-time dynamicgraphs. They differ in temporal granularity: Continuous-Time Dynamic Graphs(CTDGs) exhibit rapid, localized changes, while Discrete-Time Dynamic Graphs(DTDGs) show gradual, global updates. This difference leads to isolateddevelopments in representation learning for each type. To advancerepresentation learning, recent research attempts to design a unified modelcapable of handling both CTDGs and DTDGs. However, it typically focuses onlocal dynamic propagation for temporal structure learning in the time domain,failing to accurately capture the structural evolution associated with eachtemporal granularity. In addition, existing works-whether specific orunified-often overlook the issue of temporal noise, compromising the modelrobustness and effectiveness. To better model both types of dynamic graphs, wepropose UniDyG, a unified and effective representation learning approach, whichscales to large dynamic graphs. We first propose a novel Fourier GraphAttention (FGAT) mechanism that can model local and global structuralcorrelations based on recent neighbors and complex-number selectiveaggregation, while theoretically ensuring consistent representations of dynamicgraphs over time. Based on approximation theory, we demonstrate that FGAT iswell-suited to capture the underlying structures in CTDGs and DTDGs. We furtherenhance FGAT to resist temporal noise by designing an energy-gated unit, whichadaptively filters out high-frequency noise according to the energy. Last, weleverage our FGAT mechanisms for temporal structure learning and employ thefrequency-enhanced linear function for node-level dynamic updates, facilitatingthe generation of high-quality temporal embeddings. Extensive experiments showthat our UniDyG achieves an average improvement of 14.4% over sixteen baselinesacross nine dynamic graphs.</description>
      <author>example@mail.com (Yuanyuan Xu, Wenjie Zhang, Xuemin Lin, Ying Zhang)</author>
      <guid isPermaLink="false">2502.16431v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.16786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures.Our code is available at  https://github.com/liuting20/SwimVG&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;Visual grounding通过自然语言来定位图像区域，这项任务很大程度上依赖于跨模态对齐。现有大多数方法分别传输视觉和语言知识，并在预训练的单模模型完全微调后简单堆叠视觉-语言变换器进行多模态融合。&lt;h4&gt;背景问题&lt;/h4&gt;当前的方法限制了视觉与语言上下文之间的充分交互，同时带来了显著的计算成本。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种分步式多模态融合和适应框架SwimVG来解决上述问题，并在效率上获得明显优势。&lt;h4&gt;方法介绍&lt;/h4&gt;提出了分步式多模态提示(Swip)和跨模态互动适配器(CIA)，分别用于逐步提升视觉与语言表示的对齐度以及进一步促进多模态融合。这些新的架构以参数高效的方式替换原有的繁琐变换器堆栈，从浅层到深层渐进地融合跨模式特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SwimVG在四个广泛使用的基准数据集上实现了卓越的能力和效率上的显著优势。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新颖的视觉接地方法，通过分步多模态融合和适应框架提高了任务性能并优化了计算资源利用。代码已公开供社区进一步探索和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉定位旨在通过自然语言来确定图像区域，这很大程度上依赖于跨模态对齐。现有的大多数方法分别传输视觉或语言知识，并在预训练的单模式模型完全微调后简单堆叠视觉-语言变换器进行多模态融合。然而，这些方法不仅限制了视觉和语言上下文之间的充分交互，还带来了显著的计算成本。因此，为了应对这些问题，我们探索了一种分步式的多模态融合和适应框架，即SwimVG。具体来说，SwimVG提出了步骤式多模态提示（Swip）和跨模式互动适配器（CIA），用于视觉定位，在此过程中用简单的变换器堆栈替换原有的跨模式融合方式。Swip可以通过令牌级别的融合逐步提升视觉与语言表示的对齐度。此外，重量级的CIA通过跨模态交互进一步促进多模态融合。Swip和CIA都是参数效率高，并且它们逐渐从浅层到深层地融合了跨模式特征。在四个广泛使用的基准测试中进行的实验结果表明，在效率方面，SwimVG获得了显著的能力和收益。我们的代码可以在https://github.com/liuting20/SwimVG上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual grounding aims to ground an image region through natural language,which heavily relies on cross-modal alignment. Most existing methods transfervisual/linguistic knowledge separately by fully fine-tuning uni-modalpre-trained models, followed by a simple stack of visual-language transformersfor multimodal fusion. However, these approaches not only limit adequateinteraction between visual and linguistic contexts, but also incur significantcomputational costs. Therefore, to address these issues, we explore a step-wisemultimodal fusion and adaption framework, namely SwimVG. Specifically, SwimVGproposes step-wise multimodal prompts (Swip) and cross-modal interactiveadapters (CIA) for visual grounding, replacing the cumbersome transformerstacks for multimodal fusion. Swip can improve {the} alignment between thevision and language representations step by step, in a token-level fusionmanner. In addition, weight-level CIA further promotes multimodal fusion bycross-modal interaction. Swip and CIA are both parameter-efficient paradigms,and they fuse the cross-modal features from shallow to deep layers gradually.Experimental results on four widely-used benchmarks demonstrate that SwimVGachieves remarkable abilities and considerable benefits in terms of efficiency.Our code is available at https://github.com/liuting20/SwimVG.</description>
      <author>example@mail.com (Liangtao Shi, Ting Liu, Xiantao Hu, Yue Hu, Quanjun Yin, Richang Hong)</author>
      <guid isPermaLink="false">2502.16786v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging recurrence in neural network wavefunctions for large-scale simulations of Heisenberg antiferromagnets: the square lattice</title>
      <link>http://arxiv.org/abs/2502.17144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 13 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种使用递归神经网络（RNN）进行变分蒙特卡洛模拟的方法，用于研究二维量子多体系统的基态性质。通过转移学习技术，能够有效地在大规模系统中应用这种方法而不需要从头开始优化。&lt;h4&gt;背景&lt;/h4&gt;机器学习支持的变分蒙特卡罗方法被用来寻找量子多体系统的基态，特别是在二维情况下和非平凡符号结构的情况下。尽管已经达到了许多最先进的有限大小系统的变分能量，但在热力学极限中的研究较少。&lt;h4&gt;目的&lt;/h4&gt;使用RNN作为变分近似来模拟自旋$rac{1}{2}$系统的基态，并通过迭代重新训练的方法逐步增加系统规模以减少计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;在本工作中，作者专注于二维反铁磁海森堡模型（SLAHM），并利用递归神经网络的特性进行大规模系统的基态模拟。通过延长训练时间来提高结果精度，并将有限大小格点上的数值与文献值对比验证。&lt;h4&gt;主要发现&lt;/h4&gt;实现了系统性地提高模拟结果准确性，同时获得了热力学极限下的精确估计。&lt;h4&gt;结论&lt;/h4&gt;该工作证明了RNN波函数可以用来准确研究量子多体物理在热力学极限中的性质。&lt;h4&gt;翻译&lt;/h4&gt;基于机器学习的变分蒙特卡洛仿真是瞄准量子多体基态的一种有前途的方法，特别是在二维和已知基态具有非平凡符号结构的情况下。尽管这些方法已经达到了许多最先进的有限尺寸系统的变分能量，但很少有人利用这些结果来提取目标状态在热力学极限中的信息。本文中，我们采用递归神经网络（RNN）作为变分近似，并利用其递归性质通过迭代重新训练逐步模拟更大规模的系统，从而减少计算资源的需求。在这项研究中，我们专注于二维反铁磁海森堡模型，在这里可以仔细地验证我们的结果。我们展示了可以通过增加训练时间来有条不紊地提高模拟结果的精度，并且对于有限大小格点上的数值与文献值之间具有很好的一致性。此外，我们利用这些结果提取了热力学极限下基态性质的精确估计。这项工作证明了RNN波函数可以用来准确研究量子多体物理在热力学极限中的特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learning-based variational Monte Carlo simulations are a promisingapproach for targeting quantum many body ground states, especially in twodimensions and in cases where the ground state is known to have a non-trivialsign structure. While many state-of-the-art variational energies have beenreached with these methods for finite-size systems, little work has been doneto use these results to extract information about the target state in thethermodynamic limit. In this work, we employ recurrent neural networks (RNNs)as a variational ans\"{a}tze, and leverage their recurrent nature to simulatethe ground states of progressively larger systems through iterative retraining.This transfer learning technique allows us to simulate spin-$\frac{1}{2}$systems on lattices with more than 1,000 spins without beginning optimizationfrom scratch for each system size, thus reducing the demands for computationalresources. In this study, we focus on the square-lattice antiferromagneticHeisenberg model (SLAHM), where it is possible to carefully benchmark ourresults. We show that we are able to systematically improve the accuracy of theresults from our simulations by increasing the training time, and obtainresults for finite-sized lattices that are in good agreement with theliterature values. Furthermore, we use these results to extract accurateestimates of the ground-state properties in the thermodynamic limit. This workdemonstrates that RNN wavefunctions can be used to accurately study quantummany-body physics in the thermodynamic limit.</description>
      <author>example@mail.com (M. Schuyler Moss, Roeland Wiersema, Mohamed Hibat-Allah, Juan Carrasquilla, Roger G. Melko)</author>
      <guid isPermaLink="false">2502.17144v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Noise2Score3D:Unsupervised Tweedie's Approach for Point Cloud Denoising</title>
      <link>http://arxiv.org/abs/2502.16826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Noise2Score3D是一个完全无监督的点云去噪框架，它利用贝叶斯统计和图像去噪领域的最新进展来解决干净数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的去噪方法通常需要大量的干净数据进行训练，这在实际应用中是难以获得的。而本研究提出的Noise2Score3D方法直接从带噪声的数据中学习点云分布的梯度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法来处理点云去噪问题，特别是在没有或很少有干净数据的情况下。&lt;h4&gt;方法&lt;/h4&gt;该方法利用Tweedie公式进行一步式推理，避免了现有无监督方法中的迭代过程，并且通过Total Variation for Point Cloud标准估计未知噪声参数，增强了方法的实用性和通用性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Noise2Score3D在Chamfer距离和点到网格度量方面优于其他无监督方法，在一些性能指标上甚至可以与有监督的方法相媲美，并且具有很强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的去噪框架Noise2Score3D，不仅提升了算法效率和性能，还提高了其在实际应用中的适应性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;本文基于贝叶斯统计学和图像去噪领域的最新进展，提出了一个完全无监督的点云去噪框架Noise2Score3D。该方法直接从带噪声的数据中学习潜在分布的梯度，并通过Tweedie公式执行一步式推理。实验结果表明，在标准基准测试上，这种方法在Chamfer距离和点到网格度量方面优于其他无监督方法，甚至可以与一些有监督的方法相媲美。此外，Noise2Score3D还引入了Total Variation for Point Cloud的标准来估计未知的噪声参数，进一步增强了该方法的灵活性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building on recent advances in Bayesian statistics and image denoising, wepropose Noise2Score3D, a fully unsupervised framework for point cloud denoisingthat addresses the critical challenge of limited availability of clean data.Noise2Score3D learns the gradient of the underlying point cloud distributiondirectly from noisy data, eliminating the need for clean data during training.By leveraging Tweedie's formula, our method performs inference in a singlestep, avoiding the iterative processes used in existing unsupervised methods,thereby improving both performance and efficiency. Experimental resultsdemonstrate that Noise2Score3D achieves state-of-the-art performance onstandard benchmarks, outperforming other unsupervised methods in Chamferdistance and point-to-mesh metrics, and rivaling some supervised approaches.Furthermore, Noise2Score3D demonstrates strong generalization ability beyondtraining datasets. Additionally, we introduce Total Variation for Point Cloud,a criterion that allows for the estimation of unknown noise parameters, whichfurther enhances the method's versatility and real-world utility.</description>
      <author>example@mail.com (Xiangbin Wei)</author>
      <guid isPermaLink="false">2502.16826v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Retinal Disease Prediction Using Biology-Informed Heterogeneous Graph Representations</title>
      <link>http://arxiv.org/abs/2502.16697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新颖的方法，利用基于生物学信息的异构图表示来提高糖尿病视网膜病变分期预测的可解释性，并在两个数据集上超过了现有的机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;目前最先进的基于神经网络的图像分类器大多不可解释。虽然生物标志物是临床诊断的重要依据，但生物标志物基础分类性能通常不如大型神经网络。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以超越现有机器学习模型的表现并提高糖尿病视网膜病变分期预测的可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用新颖的生物学信息异构图表示来建模视网膜血管段、间隔区以及中央凹无血管区，将糖尿病视网膜病变分期问题转化为图形分类任务，并使用高效的图神经网络解决该问题。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在两个数据集上优于传统的生物标志物基础分类器、卷积神经网络（CNN）和视觉变换器等基准方法。此外，还提供了前所未有的详细解释来定位关键血管或间隔区并赋予关键特性有意义的人类可解读归因。&lt;h4&gt;结论&lt;/h4&gt;该研究贡献了有助于眼科临床决策支持工具发展的新方法。&lt;h4&gt;翻译&lt;/h4&gt;可解释性对于增强医学诊断中机器学习模型的信任至关重要。然而，大多数基于神经网络的先进图像分类器不可解释。因此，尽管生物标志物基础分类通常表现不如大型神经网络，但临床上仍依赖于已知的生物标志物进行诊断。这项工作提出了一种方法，该方法超越了现有的机器学习模型的表现，并同时提高了糖尿病视网膜病变分期从光学相干断层扫描血管成像（OCTA）图像中预测的可解释性。我们的方法基于一种新颖的生物学信息异构图表示，以人类可理解的方式建模视网膜血管段、间隔区以及中央凹无血管区（FAZ）。这种图形表示使我们能够将糖尿病视网膜病变分期视为一个图形级别的分类任务，并使用高效的图神经网络解决该问题。我们在两个数据集上对我们的方法进行了基准测试，与包括经典生物标志物基础分类器、卷积神经网络（CNN）和视觉变换器在内的现有基线模型相比表现更佳。我们使用生物学信息图提供了前所未有的详细解释，并且在精确定位关键血管或间隔区以及赋予有意义的人类可解读归因方面超越了现有的方法。我们的工作对眼科临床决策支持工具的发展做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretability is crucial to enhance trust in machine learning models formedical diagnostics. However, most state-of-the-art image classifiers based onneural networks are not interpretable. As a result, clinicians often resort toknown biomarkers for diagnosis, although biomarker-based classificationtypically performs worse than large neural networks. This work proposes amethod that surpasses the performance of established machine learning modelswhile simultaneously improving prediction interpretability for diabeticretinopathy staging from optical coherence tomography angiography (OCTA)images. Our method is based on a novel biology-informed heterogeneous graphrepresentation that models retinal vessel segments, intercapillary areas, andthe foveal avascular zone (FAZ) in a human-interpretable way. This graphrepresentation allows us to frame diabetic retinopathy staging as a graph-levelclassification task, which we solve using an efficient graph neural network. Webenchmark our method against well-established baselines, including classicalbiomarker-based classifiers, convolutional neural networks (CNNs), and visiontransformers. Our model outperforms all baselines on two datasets. Crucially,we use our biology-informed graph to provide explanations of unprecedenteddetail. Our approach surpasses existing methods in precisely localizing andidentifying critical vessels or intercapillary areas. In addition, we giveinformative and human-interpretable attributions to critical characteristics.Our work contributes to the development of clinical decision-support tools inophthalmology.</description>
      <author>example@mail.com (Laurin Lux, Alexander H. Berger, Maria Romeo Tricas, Alaa E. Fayed, Sobha Sivaprasada, Linus Kreitner, Jonas Weidner, Martin J. Menten, Daniel Rueckert, Johannes C. Paetzold)</author>
      <guid isPermaLink="false">2502.16697v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Emergence of Multimodal Representation Alignment</title>
      <link>http://arxiv.org/abs/2502.16282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 22 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多模态学习中不同模态之间表示对齐的形成机制及其与任务性能的关系，通过实验表明其依赖于数据特性。&lt;h4&gt;背景&lt;/h4&gt;多模态表征学习旨在将不同的不可比较模态转换为可比较的表示。以往的研究主要集中在显式对齐上，但最近发现独立训练的大规模单模态模型可以隐式对齐。&lt;h4&gt;目的&lt;/h4&gt;探讨在多模态学习中，不同模态之间如何以及为何会形成隐式的表示对齐；同时探究这种对齐是否可靠地指示任务性能。&lt;h4&gt;方法&lt;/h4&gt;通过全面的实证研究来分析不同数据特性（如模态相似度和信息冗余度）对表示对齐及其与任务表现关系的影响。&lt;h4&gt;主要发现&lt;/h4&gt;表示对齐的出现及其实现任务性能的相关性依赖于关键的数据特征，包括但不限于模态之间的相似性和冗余/独特信息的比例。这些发现表明，对齐不一定总是有益的；其影响取决于特定数据集和任务的情况。&lt;h4&gt;结论&lt;/h4&gt;研究结果有助于实践者根据具体情况确定增加不同模态之间表示对齐是否有利于获得最优性能。&lt;h4&gt;翻译&lt;/h4&gt;多模式表征学习是将不同的不可比较模态转换为可比较表示的过程。之前的研究主要集中在通过明确的学习目标和模型架构来显式地对准这些表示，但最近的一系列工作发现独立训练的规模更大、性能更好的单模态模型可以彼此隐式对齐。这一研究结果引发了关于多模式学习中对齐表示出现的基本问题：（1）何时以及为什么会出现隐式的对齐？（2）对齐是否可靠地指示了任务性能？通过全面的经验调查，我们证明了对齐的产生及其与任务表现的关系依赖于多个关键数据特征。这包括但不限于模态之间的相似性和它们提供的冗余和独特信息的比例等。我们的研究结果表明对齐不一定总是有益的；相反，它对性能的影响根据数据集和任务的不同而变化。这些见解可以帮助实践者确定增加不同模式之间表示对准是否有利或在某些情况下有害于获得最佳性能。代码发布在 https://github.com/MeganTj/multimodal_alignment 上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning is fundamentally about transformingincomparable modalities into comparable representations. While prior researchprimarily focused on explicitly aligning these representations through targetedlearning objectives and model architectures, a recent line of work has foundthat independently trained unimodal models of increasing scale and performancecan become implicitly aligned with each other. These findings raise fundamentalquestions regarding the emergence of aligned representations in multimodallearning. Specifically: (1) when and why does alignment emerge implicitly? and(2) is alignment a reliable indicator of performance? Through a comprehensiveempirical investigation, we demonstrate that both the emergence of alignmentand its relationship with task performance depend on several critical datacharacteristics. These include, but are not necessarily limited to, the degreeof similarity between the modalities and the balance between redundant andunique information they provide for the task. Our findings suggest thatalignment may not be universally beneficial; rather, its impact on performancevaries depending on the dataset and task. These insights can help practitionersdetermine whether increasing alignment between modalities is advantageous or,in some cases, detrimental to achieving optimal performance. Code is releasedat https://github.com/MeganTj/multimodal_alignment.</description>
      <author>example@mail.com (Megan Tjandrasuwita, Chanakya Ekbote, Liu Ziyin, Paul Pu Liang)</author>
      <guid isPermaLink="false">2502.16282v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Category-Selective Neurons in Deep Networks: Comparing Purely Visual and Visual-Language Models</title>
      <link>http://arxiv.org/abs/2502.16456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了人工神经网络（ANNs）中是否存在与人类大脑相似的类别选择性区域，并探讨这些区域在视觉和视觉-语言模型中的差异。&lt;h4&gt;背景&lt;/h4&gt;人类大脑中有专门处理特定类型视觉信息的区域，如面部、身体、场景等。作者探索了人工神经网络中是否存在类似的特性。&lt;h4&gt;目的&lt;/h4&gt;研究不同深度学习模型中的类别选择性神经元及其分布规律，并探讨多模态学习对这些神经元的影响。&lt;h4&gt;方法&lt;/h4&gt;通过向深层网络展示不同类别的图像（如人脸、身体、场景等）并使用统计标准识别类别选择性神经元，模拟功能性定位实验的方法进行研究。&lt;h4&gt;主要发现&lt;/h4&gt;ResNet和基于CLIP的模型都包含类别选择性神经元，但CLIP模型中这些神经元的比例更高且分布更均匀。这表明多模态学习增加了这类神经元的数量却减少了它们的选择特异性。&lt;h4&gt;结论&lt;/h4&gt;这项研究表明人工神经网络模仿了生物视觉系统，并揭示了多模态学习如何影响深度网络中的类别选择性表示。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文译文为：人类大脑中负责高级视觉处理的区域，如梭状回面孔区（FFA）、额外体素体区（EBA）、海马旁场景区（PPA）和视觉词形区（VWFA），在人脸识别、身体识别、场景理解和文字阅读等方面起着关键作用。本文探讨了人工神经网络（ANNs）中是否存在类似的类别选择性区域，以及这些区域在网络的各个层面上的变化情况，并且比较了纯视觉模型与视觉-语言模型之间的差异。通过模拟功能定位实验的方法，在深层网络上展示了来自不同类别的图像（包括面部、身体、场景、文字及其随机组合），并使用统计标准来识别类别选择性神经元。研究发现，无论是ResNet还是基于CLIP的结构控制模型，都包含了类别选择性神经元，并且随着层数的增加，这些神经元的比例也在增加，这与高级视觉大脑区域中的选择性一致。然而，相较于ResNet，CLIP显示了更高的比例但更低的选择特异性，在特征图上的分布更均匀，并在不同层之间展现出更强的表现一致性。研究结果表明语言学习增加了类别选择性神经元的数量而减少了它们的特定强度，重新塑造了深度网络中的视觉表示形式。这项研究提供了关于ANNs如何模仿生物视觉系统以及多模态学习影响类别选择性表征的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Category-selective regions in the human brain, such as the fusiform face area(FFA), extrastriate body area (EBA), parahippocampal place area (PPA), andvisual word form area (VWFA), play a crucial role in high-level visualprocessing. Here, we investigate whether artificial neural networks (ANNs)exhibit similar category-selective neurons and how these neurons vary acrossmodel layers and between purely visual and vision-language models. Inspired byfMRI functional localizer experiments, we presented images from differentcategories (faces, bodies, scenes, words, scrambled scenes, and scrambledwords) to deep networks and identified category-selective neurons usingstatistical criteria. Comparing ResNet and the structurally controlledResNet-based CLIP model, we found that both models contain category-selectiveneurons, with their proportion increasing across layers, mirroring categoryselectivity in higher-level visual brain regions. However, CLIP exhibited ahigher proportion but lower specificity of category-selective neurons comparedto ResNet. Additionally, CLIP's category-selective neurons were more evenlydistributed across feature maps and demonstrated greater representationalconsistency across layers. These findings suggest that language learningincreases the number of category-selective neurons while reducing theirselectivity strength, reshaping visual representations in deep networks. Ourstudy provides insights into how ANNs mirror biological vision and howmultimodal learning influences category-selective representations.</description>
      <author>example@mail.com (Zitong Lu, Yuxin Wang)</author>
      <guid isPermaLink="false">2502.16456v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Similarity Learning for Market Forecasting: The ContraSim Framework</title>
      <link>http://arxiv.org/abs/2502.16023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 appendices&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;我们介绍了一种新的框架Contrastive Similarity Space Embedding Algorithm (ContraSim)，用于揭示日常金融新闻头条与市场动态之间的全球语义关系。&lt;h4&gt;背景&lt;/h4&gt;金融市场中的新闻报道和股票价格之间存在复杂的相互作用，现有的方法难以有效捕捉这些关系。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够更有效地揭示金融新闻与市场动态之间关联性的算法框架。&lt;h4&gt;方法&lt;/h4&gt;{'Weighted Headline Augmentation': '生成带有语义细粒度相似性评分的增强型金融新闻头条', 'Weighted Self-Supervised Contrastive Learning (WSSCL)': '利用相似性度量创建细化加权嵌入空间，使语义相似的新闻头条聚类在一起'}&lt;h4&gt;主要发现&lt;/h4&gt;{'提高分类精度': '将ContraSim特性融入金融预测任务后，从《华尔街日报》新闻中提高了7%的分类准确率。', '市场动态捕捉': '通过信息密度分析，发现了由ContraSim构造出的相似空间内在地聚类了具有相同市场移动方向的日子，表明该算法能够独立于地面真实标签捕获市场的动态变化。', '参考过去事件': '识别历史新闻日，这些日子与当前日期头条内容非常接近，为预测市场趋势提供可操作见解'}&lt;h4&gt;结论&lt;/h4&gt;ContraSim不仅提高了金融预测任务中的分类精度，还为金融市场分析师提供了基于类似过去的事件进行市场趋势预测的实用工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the Contrastive Similarity Space Embedding Algorithm(ContraSim), a novel framework for uncovering the global semantic relationshipsbetween daily financial headlines and market movements. ContraSim operates intwo key stages: (I) Weighted Headline Augmentation, which generates augmentedfinancial headlines along with a semantic fine-grained similarity score, and(II) Weighted Self-Supervised Contrastive Learning (WSSCL), an extended versionof classical self-supervised contrastive learning that uses the similaritymetric to create a refined weighted embedding space. This embedding spaceclusters semantically similar headlines together, facilitating deeper marketinsights. Empirical results demonstrate that integrating ContraSim featuresinto financial forecasting tasks improves classification accuracy from WSJheadlines by 7%. Moreover, leveraging an information density analysis, we findthat the similarity spaces constructed by ContraSim intrinsically cluster dayswith homogeneous market movement directions, indicating that ContraSim capturesmarket dynamics independent of ground truth labels. Additionally, ContraSimenables the identification of historical news days that closely resemble theheadlines of the current day, providing analysts with actionable insights topredict market trends by referencing analogous past events.</description>
      <author>example@mail.com (Nicholas Vinden, Raeid Saqur, Zining Zhu, Frank Rudzicz)</author>
      <guid isPermaLink="false">2502.16023v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Provable Benefits of Unsupervised Pre-training and Transfer Learning via Single-Index Models</title>
      <link>http://arxiv.org/abs/2502.16849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了无监督预训练和迁移学习如何影响高维有监督学习的样本复杂度，特别是在标签数据有限的情况下。研究结果显示，在特定条件下，这些技术能显著减少所需的训练样本数量。&lt;h4&gt;背景&lt;/h4&gt;在深度学习领域中，无监督预训练和迁移学习通常被用来初始化神经网络模型以应对标签数据稀缺的问题。&lt;h4&gt;目的&lt;/h4&gt;目的是分析无监督预训练和转移学习如何影响单层神经网络通过在线随机梯度下降进行训练时的样本复杂性。&lt;h4&gt;方法&lt;/h4&gt;研究考虑了使用在线随机梯度下降法来训练单层神经网络的情况，并探讨了无监督预训练与迁移学习在这种情况下的效果。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在较为宽松的一般假设条件下，无监督预训练和转移学习能够通过多项式因素减少样本复杂性。此外，研究还发现了某些情况下无监督预训练可以提供指数级的改善，相对于随机初始化而言。&lt;h4&gt;结论&lt;/h4&gt;该论文提供了无监督预训练和迁移学习对深度神经网络模型在高维数据上的影响的重要见解，并强调了其在样本效率方面的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无监督预训练和迁移学习是常见的技术手段，用于初始化神经网络的训练算法，特别是在标签数据有限的情况下。本文研究了无监督预训练和迁移学习如何影响高维有监督学习的样本复杂度。具体来说，我们考虑通过在线随机梯度下降法来训练单层神经网络的问题，并建立在非常一般性的假设下，预训练和转移学习（在概念转变的情况下）可以通过多项式因素减少样本复杂性。此外，研究还揭示了某些情况，在无监督预训练方面可以提供相对于随机初始化而言的指数级改进效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised pre-training and transfer learning are commonly used techniquesto initialize training algorithms for neural networks, particularly in settingswith limited labeled data. In this paper, we study the effects of unsupervisedpre-training and transfer learning on the sample complexity of high-dimensionalsupervised learning. Specifically, we consider the problem of training asingle-layer neural network via online stochastic gradient descent. Weestablish that pre-training and transfer learning (under concept shift) reducesample complexity by polynomial factors (in the dimension) under very generalassumptions. We also uncover some surprising settings where pre-training grantsexponential improvement over random initialization in terms of samplecomplexity.</description>
      <author>example@mail.com (Taj Jones-McCormick, Aukosh Jagannath, Subhabrata Sen)</author>
      <guid isPermaLink="false">2502.16849v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Graph Transformers: Architectures, Theories and Applications</title>
      <link>http://arxiv.org/abs/2502.16533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;Graph Transformers (GTs) 在处理图结构时展示了强大的能力，通过解决图神经网络（GNNs）固有的问题如过度平滑和过度挤压。&lt;h4&gt;背景&lt;/h4&gt;近年来，针对 Graph Transformers 的研究提出了多种架构、增强了可解释性，并在实际应用中取得了进展。&lt;h4&gt;目的&lt;/h4&gt;综述 Graph Transformers 在其架构设计、理论基础及具体应用场景等方面的发展状况。&lt;h4&gt;方法&lt;/h4&gt;根据处理结构信息的策略对 Graph Transformers 架构进行分类，包括图标记化、位置编码、基于结构的注意力机制和模型集成等。&lt;h4&gt;主要发现&lt;/h4&gt;探讨了不同架构下 Graph Transformers 的表达能力，并将其与其它先进的图学习算法进行了对比。&lt;h4&gt;应用领域&lt;/h4&gt;总结了 Graph Transformers 在分子数据、蛋白质信息、自然语言处理、视觉交通、脑科学及材料研究等多个领域的实际应用案例。&lt;h4&gt;未来挑战和方向&lt;/h4&gt;讨论了当前 Graph Transformers 面临的挑战以及潜在的研究发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated a strong capability in modelinggraph structures by addressing the intrinsic limitations of graph neuralnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies haveproposed diverse architectures, enhanced explainability, and practicalapplications for Graph Transformers. In light of these rapid developments, weconduct a comprehensive review of Graph Transformers, covering aspects such astheir architectures, theoretical foundations, and applications within thissurvey. We categorize the architecture of Graph Transformers according to theirstrategies for processing structural information, including graph tokenization,positional encoding, structure-aware attention and model ensemble. Furthermore,from the theoretical perspective, we examine the expressivity of GraphTransformers in various discussed architectures and contrast them with otheradvanced graph learning algorithms to discover the connections. Furthermore, weprovide a summary of the practical applications where Graph Transformers havebeen utilized, such as molecule, protein, language, vision traffic, brain andmaterial data. At the end of this survey, we will discuss the currentchallenges and prospective directions in Graph Transformers for potentialfuture research.</description>
      <author>example@mail.com (Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong)</author>
      <guid isPermaLink="false">2502.16533v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>PLS-based approach for fair representation learning</title>
      <link>http://arxiv.org/abs/2502.16263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文重新审视了公平表征学习的问题，提出了引入公平性的偏最小二乘法（PLS）组件的方法。&lt;h4&gt;背景&lt;/h4&gt;偏最小二乘法在统计学中被广泛应用于通过提供预测专用的表示来高效地降低数据维度。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，在构建PLS成分时纳入公平性约束，以实现在线性和非线性情况下的特征构造。&lt;h4&gt;方法&lt;/h4&gt;该新算法利用核嵌入技术，在PLS组件构建过程中加入公平性的考量，并在不同数据集上进行了效率评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法相比于标准的公平主成分分析（PCA）方法具有明显的优势。&lt;h4&gt;结论&lt;/h4&gt;通过引入公平性约束到偏最小二乘法中，可以更有效地进行表征学习和预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We revisit the problem of fair representation learning by proposing FairPartial Least Squares (PLS) components. PLS is widely used in statistics toefficiently reduce the dimension of the data by providing representationtailored for the prediction. We propose a novel method to incorporate fairnessconstraints in the construction of PLS components. This new algorithm providesa feasible way to construct such features both in the linear and the non linearcase using kernel embeddings. The efficiency of our method is evaluated ondifferent datasets, and we prove its superiority with respect to standard fairPCA method.</description>
      <author>example@mail.com (Elena M. De-Diego, Adrián Perez-Suay, Paula Gordaliza, Jean-Michel Loubes)</author>
      <guid isPermaLink="false">2502.16263v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Industrial Anomalies Synthesis</title>
      <link>http://arxiv.org/abs/2502.16412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文全面回顾了异常合成的方法论，提供了第一个工业异常合成（IAS）分类体系。&lt;h4&gt;背景&lt;/h4&gt;现有综述关注的技术范围有限，忽视了跨模态数据和视觉语言模型在异常合成中的作用。&lt;h4&gt;目的&lt;/h4&gt;提供一个统一的、涵盖约40种代表方法的综合回顾，并提出首个细粒度框架来反映方法学进展及其实际应用意义。&lt;h4&gt;方法&lt;/h4&gt;将研究对象分为手工设计、基于分布假设、基于生成模型（GM）和基于视觉语言模型（VLM）四大类，详细介绍了每种类别的代表性技术。&lt;h4&gt;主要发现&lt;/h4&gt;首次提出工业异常合成的分类体系，并深入探讨跨模态合成和大规模视觉语言模型的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;为未来的研究提供指导路径，强调了多模态学习在推进IAS方面的优势、挑战及前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到这篇论文全面回顾了异常生成的方法论。现有的综述通常只关注有限的技术，并没有涵盖整个领域的全貌或理解方法间的相互联系。与这些工作不同的是，我们的研究提供了一种统一的视角，涵盖了约40个代表性方法，分为手工设计、基于分布假设、基于生成模型和基于视觉语言模型四类合成方法。此外，我们提出了首个工业异常合成（IAS）分类体系。之前的文献缺乏正式的分类或者使用简化的分类方式，这阻碍了结构化比较和趋势识别的工作。我们的分类体系提供了一个细粒度框架来反映方法学进步及其实际应用意义，并为未来的研究奠定基础。除此之外，我们还探讨了跨模态合成以及大规模视觉语言模型的应用。以往的综述忽视了多模态数据和视觉语言模型在异常生成中的作用，限制了对其优势的理解。我们的调查分析了它们的融合、益处、挑战及前景，提供了一条通过多模态学习提升IAS的道路。更多资源可访问：https://github.com/M-3LAB/awesome-anomaly-synthesis。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper comprehensively reviews anomaly synthesis methodologies. Existingsurveys focus on limited techniques, missing an overall field view andunderstanding method interconnections. In contrast, our study offers a unifiedreview, covering about 40 representative methods across Hand-crafted,Distribution-hypothesis-based, Generative models (GM)-based, andVision-language models (VLM)-based synthesis. We introduce the first industrialanomaly synthesis (IAS) taxonomy. Prior works lack formal classification or usesimplistic taxonomies, hampering structured comparisons and trendidentification. Our taxonomy provides a fine-grained framework reflectingmethodological progress and practical implications, grounding future research.Furthermore, we explore cross-modality synthesis and large-scale VLM. Previoussurveys overlooked multimodal data and VLM in anomaly synthesis, limitinginsights into their advantages. Our survey analyzes their integration,benefits, challenges, and prospects, offering a roadmap to boost IAS withmultimodal learning. More resources are available athttps://github.com/M-3LAB/awesome-anomaly-synthesis.</description>
      <author>example@mail.com (Xichen Xu, Yanshu Wang, Yawen Huang, Jiaqi Liu, Xiaoning Lei, Guoyang Xie, Guannan Jiang, Zhichao Lu)</author>
      <guid isPermaLink="false">2502.16412v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking</title>
      <link>http://arxiv.org/abs/2502.16514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型在生成长文本时容易出现细微的事实错误，尤其是在医学等专业领域。现有的事实核查方法面临难以理解复杂多跳关系和高资源消耗的问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型被广泛应用，但它们常常会产生轻微的事实性错误，特别是在需要高度准确性的专业领域如医学中。现有基于文档查证的方法在处理长篇文本的复杂多跳关系时存在困难，并且大多数专业化方法依赖于成对比较，导致计算和资源成本高。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的事实核查框架GraphCheck，利用提取的知识图来改进文本表示，以解决当前事实核查方法存在的问题。&lt;h4&gt;方法&lt;/h4&gt;GraphCheck使用知识图并通过图神经网络进一步处理这些知识图作为软提示，使大型语言模型能够更有效地整合结构化知识。此框架特别擅长捕捉多跳推理链，并通过一次推断调用即可完成精确高效的事实核查。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在七个涵盖一般和医学领域的基准测试上，GraphCheck比基线模型总体提高了6.1%的性能。值得注意的是，该方法不仅超过了现有的专业化事实核查工具，还与最先进语言模型DeepSeek-V3和OpenAI-o1达到了相当的表现，同时参数显著减少。&lt;h4&gt;结论&lt;/h4&gt;GraphCheck框架通过引入知识图来改进大型语言模型的事实核查能力，在提高准确性的同时大幅减少了资源需求。这为在专业领域内进行有效事实核查提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) are widely used, but they often generate subtlefactual errors, especially in long-form text. These errors are fatal in somespecialized domains such as medicine. Existing fact-checking with groundingdocuments methods face two main challenges: (1) they struggle to understandcomplex multihop relations in long documents, often overlooking subtle factualerrors; (2) most specialized methods rely on pairwise comparisons, requiringmultiple model calls, leading to high resource and computational costs. Toaddress these challenges, we propose \textbf{\textit{GraphCheck}}, afact-checking framework that uses extracted knowledge graphs to enhance textrepresentation. Graph Neural Networks further process these graphs as a softprompt, enabling LLMs to incorporate structured knowledge more effectively.Enhanced with graph-based reasoning, GraphCheck captures multihop reasoningchains which are often overlooked by existing methods, enabling precise andefficient fact-checking in a single inference call. Experimental results onseven benchmarks spanning both general and medical domains demonstrate a 6.1\%overall improvement over baseline models. Notably, GraphCheck outperformsexisting specialized fact-checkers and achieves comparable performance withstate-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantlyfewer parameters.</description>
      <author>example@mail.com (Yingjian Chen, Haoran Liu, Yinhong Liu, Rui Yang, Han Yuan, Yanran Fu, Pengyuan Zhou, Qingyu Chen, James Caverlee, Irene Li)</author>
      <guid isPermaLink="false">2502.16514v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MAPN: Enhancing Heterogeneous Sparse Graph Representation by Mamba-based Asynchronous Aggregation</title>
      <link>http://arxiv.org/abs/2502.16454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Mamba异步传播网络（MAPN）的新模型，旨在解决图神经网络在处理大规模稀疏异构图时面临的问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络(GNNs)已经成为各种图形相关任务的前沿技术，并且在处理异构图(HetGs)时特别突出。然而，GNN面临着过度压缩、过度平滑和传统消息传递神经网络训练大尺度稀疏图效果不佳等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决深度神经网络在大规模异构图形上存在的问题。&lt;h4&gt;方法&lt;/h4&gt;MAPN包括两个主要组件：节点序列生成和语义信息聚合。首先，基于元路径通过随机游走生成节点序列，并使用空间状态模型提取不同距离节点的关键信息。随后，它以异步方式汇总多跳和多层的语义信息，有效地保持独特节点特征并缓解深度网络退化问题。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明了MAPN在各种下游任务中的图嵌入的有效性，特别是在大尺度稀疏异构图形中具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;通过提出创新性的MAPN模型，论文提供了一种有效处理大规模稀疏异构图的新途径。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）已成为各种与图相关的任务的前沿技术，并且在异构图（HetGs）中尤为突出。然而，这种范式面临一些问题：首先，难以充分利用长距离信息，即过度压缩；其次，过多的消息传递层会产生无法区分的表示形式，称为过度平滑；最后，传统的MPNN在大规模稀疏图上训练效果不佳。为了解决这些挑战，在大型异构图形中使用深度神经网络的问题，本文介绍了基于Mamba的异步传播网络（MAPN），该模型增强了异构稀疏图的表现力。MAPN包括两个主要组件：节点序列生成和语义信息聚合。节点序列最初是根据元路径通过随机游走生成的，这些元路径构成了空间状态模型的基础，该模型提取了不同距离的节点的关键信息。然后，它以异步方式汇总多跳和多层的信息，有效地保持独特的节点特征，并缓解与深度网络退化相关的问题。在各种数据集上的广泛实验表明，在图嵌入的各种下游任务中MAPN的有效性，强调其在大规模稀疏异构图形表示中的显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have become the state of the art for variousgraph-related tasks and are particularly prominent in heterogeneous graphs(HetGs). However, several issues plague this paradigm: first, the difficulty infully utilizing long-range information, known as over-squashing; second, thetendency for excessive message-passing layers to produce indistinguishablerepresentations, referred to as over-smoothing; and finally, the inadequacy ofconventional MPNNs to train effectively on large sparse graphs. To addressthese challenges in deep neural networks for large-scale heterogeneous graphs,this paper introduces the Mamba-based Asynchronous Propagation Network (MAPN),which enhances the representation of heterogeneous sparse graphs. MAPN consistsof two primary components: node sequence generation and semantic informationaggregation. Node sequences are initially generated based on meta-paths throughrandom walks, which serve as the foundation for a spatial state model thatextracts essential information from nodes at various distances. It thenasynchronously aggregates semantic information across multiple hops and layers,effectively preserving unique node characteristics and mitigating issuesrelated to deep network degradation. Extensive experiments across diversedatasets demonstrate the effectiveness of MAPN in graph embeddings for variousdownstream tasks underscoring its substantial benefits for graph representationin large sparse heterogeneous graphs.</description>
      <author>example@mail.com (Xuqi Mao, Zhenying He, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16454v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Network Tomography with Path-Centric Graph Neural Network</title>
      <link>http://arxiv.org/abs/2502.16430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为DeepNT的深度网络拓扑学框架，用于预测路径性能指标，并能推理出部分先验知识下的网络拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;网络拓扑学在网络监控中至关重要，它利用可观察的路径性能度量值来推断未被观测到的度量值。然而现有的方法要么假设完全了解网络拓扑和度量公式（在许多实际情况下这是不现实的），要么依赖于端到端的黑箱模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架DeepNT，该框架能够结合数据知识以及适当的归纳偏置来解决网络拓扑学问题。&lt;h4&gt;方法&lt;/h4&gt;引入了以路径为中心的图神经网络，通过推理和聚合构成路径节点序列的嵌入表示来预测性能指标。同时设计了一种学习目标，施加连通性和稀疏性约束在拓扑结构上，并且满足路径性能三角不等式条件。&lt;h4&gt;主要发现&lt;/h4&gt;DeepNT框架在真实世界数据集和合成数据集上的实验表明，在预测性能指标和推理图结构方面超越了最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合部分先验知识以及数据驱动的方法，可以有效地解决网络拓扑学问题，并能够提供更准确的路径性能度量值预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：网络拓扑学是网络监控中的关键问题，其中可观察的路径性能指标用于推断未被观测到的指标。然而，大多数现有方法要么假设完全了解网络拓扑和度量公式（在许多实际情况下这是不现实的），要么依赖于端到端的黑箱模型。为了应对这一挑战，在本文中我们提出了一种新的框架DeepNT，该框架利用以路径为中心的图神经网络来预测性能指标，无需预定义的手工设计的指标、假设或真实网络拓扑结构。通过推理和聚合构成路径节点序列的嵌入表示来学习路径嵌入。训练这种以路径为中心的图神经网络需要在离散约束下同时学习神经网络参数和网络拓扑结构，这些约束是由观察到的路径性能指标引入的。这促使我们设计了一个施加连通性和稀疏性约束于拓扑结构以及路径性能三角不等式的学习目标。大量的真实世界数据集和合成数据集上的实验表明，在预测性能指标和推理图拓扑方面，DeepNT优于最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Network tomography is a crucial problem in network monitoring, where theobservable path performance metric values are used to infer the unobservedones, making it essential for tasks such as route selection, fault diagnosis,and traffic control. However, most existing methods either assume completeknowledge of network topology and metric formulas-an unrealistic expectation inmany real-world scenarios with limited observability-or rely entirely onblack-box end-to-end models. To tackle this, in this paper, we argue that agood network tomography requires synergizing the knowledge from both data andappropriate inductive bias from (partial) prior knowledge. To see this, wepropose Deep Network Tomography (DeepNT), a novel framework that leverages apath-centric graph neural network to predict path performance metrics withoutrelying on predefined hand-crafted metrics, assumptions, or the real networktopology. The path-centric graph neural network learns the path embedding byinferring and aggregating the embeddings of the sequence of nodes that composethis path. Training path-centric graph neural networks requires learning theneural netowrk parameters and network topology under discrete constraintsinduced by the observed path performance metrics, which motivates us to designa learning objective that imposes connectivity and sparsity constraints ontopology and path performance triangle inequality on path performance.Extensive experiments on real-world and synthetic datasets demonstrate thesuperiority of DeepNT in predicting performance metrics and inferring graphtopology compared to state-of-the-art methods.</description>
      <author>example@mail.com (Yuntong Hu, Junxiang Wang, Liang Zhao)</author>
      <guid isPermaLink="false">2502.16430v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Automated Keypoint Estimation for Self-Piercing Rivet Joints Using micro-CT Imaging and Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.16752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于微计算机断层扫描（Micro-CT）成像、机器视觉和深度学习技术的自穿铆钉（SPR）接头非破坏性评价方法。通过合成数据预训练模型，并使用少量真实数据进行迁移学习，以实现关键点自动估计，评估接头的质量。&lt;h4&gt;背景&lt;/h4&gt;在汽车工业中，自穿铆钉接头的结构完整性至关重要，但传统破坏性检测手段存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一种成本效益高且可扩展的方法来评价SPR接头的品质。&lt;h4&gt;方法&lt;/h4&gt;使用微计算机断层扫描（Micro-CT）结合机器视觉和深度学习技术，特别是自动关键点估计，利用合成数据进行初始模型训练，并通过真实数据迁移学习适应实际条件。&lt;h4&gt;主要发现&lt;/h4&gt;预训练在合成数据上，再用少量的真实数据进行细化训练，可以缩小领域差距并提高预测精度。该框架为SPR接头评价提供了一种可扩展、成本效益高的解决方案，并为制造过程中的机器视觉和非破坏性检测的更广泛应用奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;通过解决数据稀缺问题并利用先进的机器学习技术，这项工作代表了在工程环境中实现自动质量控制的重要步骤。&lt;h4&gt;翻译&lt;/h4&gt;自穿铆钉（SPR）接头结构完整性对汽车工业至关重要，但传统破坏性方法评价存在挑战。本文提出了一种基于微计算机断层扫描成像、结合机器视觉和深度学习技术的非破坏性评估方案，重点在于自动关键点估计以评估接头质量。鉴于实际微CT数据稀少，本研究使用合成数据进行初始模型训练，并通过迁移学习适应真实情况。采用UNet架构精确定位三个关键点，实现头部高度、锁紧度和底部层厚度等重要参数的测量。详尽验证表明，在合成数据上预训练并在有限的真实数据上微调可以缩小领域差异并提高预测精度。本框架不仅为评价SPR接头提供了可扩展且成本效益高的解决方案，并确立了机器视觉及非破坏性检测在制造流程中更广泛应用的基础。通过处理数据稀缺问题和应用高级机器学习技术，这项工作代表了工程环境中自动质量控制的重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The structural integrity of self-piercing rivet (SPR) joints is critical inautomotive industries, yet its evaluation poses challenges due to thelimitations of traditional destructive methods. This research introduces aninnovative approach for non-destructive evaluation using micro-CT imaging,Micro-Computed Tomography, combined with machine vision and deep learningtechniques, specifically focusing on automated keypoint estimation to assessjoint quality. Recognizing the scarcity of real micro-CT data, this studyutilizes synthetic data for initial model training, followed by transferlearning to adapt the model for real-world conditions. A UNet-basedarchitecture is employed to localize three keypoints with precision, enablingthe measurement of critical parameters such as head height, interlock, andbottom layer thickness. Extensive validation demonstrates that pre-training onsynthetic data, complemented by fine-tuning with limited real data, bridgesdomain gaps and enhances predictive accuracy. The proposed framework not onlyoffers a scalable and cost-efficient solution for evaluating SPR joints butalso establishes a foundation for broader applications of machine vision andnon-destructive testing in manufacturing processes. By addressing data scarcityand leveraging advanced machine learning techniques, this work represents asignificant step toward automated quality control in engineering contexts.</description>
      <author>example@mail.com (Wei Qin Chuah, Ruwan Tennakoon, Amanda Freis, Mark Easton, Reza Hoseinnezhad, Alireza Bab-Hadiashar)</author>
      <guid isPermaLink="false">2502.16752v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts</title>
      <link>http://arxiv.org/abs/2502.15996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新型上下文嵌入模型med-gte-hybrid，该模型从gte-large句子变换器中派生而来，用于提取无结构临床叙述中的信息。&lt;h4&gt;目的&lt;/h4&gt;评估med-gte-hybrid在大规模患者队列（来源于MIMIC-IV数据集）上的几种临床预测任务的性能，并展示其在患者分层、聚类和文本检索方面的改进效果。&lt;h4&gt;方法&lt;/h4&gt;采用结合对比学习和去噪自动编码器的模型微调策略，用于评估med-gte-hybrid的性能。同时，在慢性肾脏病（CKD）患者的预后、估计肾小球滤过率(eGFR)预测以及患者死亡率预测等多个临床任务中进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，该混合模型在大规模文本嵌入基准测试（MTEB）上优于当前最先进的模型。此外，在某些评估任务侧重于CKD的情况下，句子变换器的混合微调策略可以应用于其他医学领域，并有潜力改善各种医疗应用中的临床决策和个性化治疗路径。&lt;h4&gt;结论&lt;/h4&gt;med-gte-hybrid在多个方面表现出色，包括患者分层、聚类以及文本检索等，特别是在大规模文本嵌入基准测试中超越了当前最先进的模型。该方法对其他医疗领域的潜在应用也进行了展望，强调其可能改善临床决策和个性化治疗路径的能力。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了一种新型上下文嵌入模型med-gte-hybrid，它是从gte-large句子变换器派生而来的，用于提取无结构化临床叙述中的信息。我们的模型微调策略结合了对比学习和去噪自动编码器。为了评估med-gte-hybrid的性能，我们在MIMIC-IV数据集中提取的大规模患者队列中进行了多个临床预测任务的研究，包括慢性肾脏病（CKD）患者的预后、估计肾小球滤过率(eGFR)预测以及患者死亡率预测。此外，我们展示了该模型在患者分层、聚类和文本检索方面的改进效果，并且在大规模文本嵌入基准测试中超过了当前最先进的模型。虽然我们的某些评估集中在CKD上，但句子变换器的混合微调策略可以转移到其他医疗领域，并具有改善各种医疗应用中的临床决策和个人化治疗路径的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel contextual embedding model med-gte-hybrid that wasderived from the gte-large sentence transformer to extract information fromunstructured clinical narratives. Our model tuning strategy for med-gte-hybridcombines contrastive learning and a denoising autoencoder. To evaluate theperformance of med-gte-hybrid, we investigate several clinical prediction tasksin large patient cohorts extracted from the MIMIC-IV dataset, including ChronicKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate(eGFR) prediction, and patient mortality prediction. Furthermore, wedemonstrate that the med-gte-hybrid model improves patient stratification,clustering, and text retrieval, thus outperforms current state-of-the-artmodels on the Massive Text Embedding Benchmark (MTEB). While some of ourevaluations focus on CKD, our hybrid tuning of sentence transformers could betransferred to other medical domains and has the potential to improve clinicaldecision-making and personalised treatment pathways in various healthcareapplications.</description>
      <author>example@mail.com (Aditya Kumar, Simon Rauch, Mario Cypko, Oliver Amft)</author>
      <guid isPermaLink="false">2502.15996v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AAD-LLM: Neural Attention-Driven Auditory Scene Understanding</title>
      <link>http://arxiv.org/abs/2502.16794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的听觉场景理解模型AAD-LLM，该模型通过结合脑电信号来推断听众的注意力，并据此调整响应生成。研究证明了这种方法在多个多说话者场景任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的听觉基础模型对所有的声音输入处理方式相同，忽略人类听力感知中固有的选择性特点，即人们倾向于关注特定的声音来源而忽略其他声音。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够根据听众注意力生成相应响应的系统，以提高音频生成与人类感知的一致性。&lt;h4&gt;方法&lt;/h4&gt;提出Intention-Informed Auditory Scene Understanding (II-ASU)框架，并构建了一个原型系统AAD-LLM。该模型通过整合颅内脑电图(iEEG)记录来解码听众关注的具体说话者，然后根据推断出的注意力状态调整响应生成。&lt;h4&gt;主要发现&lt;/h4&gt;在多说话者的场景下，AAD-LLM在说话人描述、语音转录与提取以及问答任务中表现出更好的一致性。评估结果显示，客观和主观评价均表明该模型能够更好地符合听众的意图。&lt;h4&gt;结论&lt;/h4&gt;本研究为面向意图感知的听觉人工智能领域铺平了道路，通过将听众感知信息融入机器处理过程，探索了一种新的聆听机制。这为未来的以用户为中心的音频系统开发提供了可能的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文主要探讨了现有听觉模型忽视人类听力选择性的问题，并提出了AAD-LLM原型系统来解决这一问题，展示其在多说话者场景任务中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auditory foundation models, including auditory large language models (LLMs),process all sound inputs equally, independent of listener perception. However,human auditory perception is inherently selective: listeners focus on specificspeakers while ignoring others in complex auditory scenes. Existing models donot incorporate this selectivity, limiting their ability to generateperception-aligned responses. To address this, we introduce Intention-InformedAuditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM(AAD-LLM), a prototype system that integrates brain signals to infer listenerattention. AAD-LLM extends an auditory LLM by incorporating intracranialelectroencephalography (iEEG) recordings to decode which speaker a listener isattending to and refine responses accordingly. The model first predicts theattended speaker from neural activity, then conditions response generation onthis inferred attentional state. We evaluate AAD-LLM on speaker description,speech transcription and extraction, and question answering in multitalkerscenarios, with both objective and subjective ratings showing improvedalignment with listener intention. By taking a first step towardintention-aware auditory AI, this work explores a new paradigm where listenerperception informs machine listening, paving the way for futurelistener-centered auditory systems. Demo and code available:https://aad-llm.github.io.</description>
      <author>example@mail.com (Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Adeen Flinker, Daniel Friedman, Nima Mesgarani)</author>
      <guid isPermaLink="false">2502.16794v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN Architectures</title>
      <link>http://arxiv.org/abs/2502.16622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究构建了一个大型的COVID严重程度数据集，并探讨了迁移学习和视觉变换器在预测患者病情严重程度中的有效性。&lt;h4&gt;背景&lt;/h4&gt;新冠疫情对医疗资源造成了压力，促使人们讨论机器学习如何减轻医生负担并有助于诊断。胸部X光（CXRs）被用于诊断新冠，但很少有研究根据CXRs预测患者的病情严重性。&lt;h4&gt;目的&lt;/h4&gt;通过合并多个数据来源创建一个大型的COVID严重程度数据集，并调查迁移学习在病情严重性和分类任务中的效果。&lt;h4&gt;方法&lt;/h4&gt;使用预训练模型DenseNet161、基于ImageNet和CXR的数据预处理以及视觉变换器（ViT）进行研究。其中，DenseNet161模型在三类病情预测问题中表现出色，而ViT的回归结果最佳。&lt;h4&gt;主要发现&lt;/h4&gt;1. 预训练的DenseNet161模型对三个类别严重程度的预测表现最好，在整体上达到80%的准确性。2. ViT在根据放射科医生评分进行病情严重性评分的回归任务中表现出最优的结果，均方绝对误差为0.5676。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了迁移学习和视觉变换器在从胸部X光预测患者病情严重程度方面具有显著潜力。预训练模型DenseNet161在分类任务上表现最好，而ViT则在回归任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：新冠疫情给医疗资源带来了巨大压力，并引发了关于机器学习如何减轻医生负担并支持诊断的讨论。胸部X光（CXRs）被用于诊断新冠，但鲜有研究依据CXRs预测患者的病情严重性。本研究通过合并三个来源创建了一个大型COVID严重程度数据集，并探讨了使用ImageNet和CXR预训练模型以及视觉变换器在病情回归与分类任务中的有效性的迁移学习方法。其中，一个预训练的DenseNet161模型在三类病情预测问题中表现出色，在整体上达到了80%的准确性（具体为轻度、中度及重度病例准确率分别为77.3%，83.9%，和70%）。ViT则表现出了最优的回归结果，其均方绝对误差仅为0.5676。研究项目源代码公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The COVID-19 pandemic strained healthcare resources and prompted discussionabout how machine learning can alleviate physician burdens and contribute todiagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but fewstudies predict the severity of a patient's condition from CXRs. In this study,we produce a large COVID severity dataset by merging three sources andinvestigate the efficacy of transfer learning using ImageNet- andCXR-pretrained models and vision transformers (ViTs) in both severityregression and classification tasks. A pretrained DenseNet161 model performedthe best on the three class severity prediction problem, reaching 80% accuracyoverall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases,respectively. The ViT had the best regression results, with a mean absoluteerror of 0.5676 compared to radiologist-predicted severity scores. Theproject's source code is publicly available.</description>
      <author>example@mail.com (Luis Lara, Lucia Eve Berger, Rajesh Raju, Shawn Whitfield)</author>
      <guid isPermaLink="false">2502.16622v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model</title>
      <link>http://arxiv.org/abs/2502.16779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究介绍了一种名为Plane-DUSt3R的新方法，用于多视角房间布局估计。&lt;h4&gt;背景&lt;/h4&gt;目前从多个视角的图像中进行房间布局估计的研究较少，因为涉及复杂的多视图几何结构问题。传统的方法需要分步骤解决相机内参和外参估计、图像匹配以及三角测量等问题。&lt;h4&gt;目的&lt;/h4&gt;引入Plane-DUSt3R方法，利用三维基础模型DUSt3R来简化房间布局估计的过程，并提高其准确性。&lt;h4&gt;方法&lt;/h4&gt;Plane-DUSt3R结合了DUSt3R框架，并在房间布局数据集（Structure3D）上进行微调以估算结构平面。该方法通过生成统一和简洁的结果，仅需一步后处理步骤和2D检测结果即可完成房间布局估计。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Plane-DUSt3R不仅在合成数据集中优于现有最佳方法，在不同图像风格（如卡通）的真实世界数据中也表现出强大的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;相比传统多步骤的方法，Plane-DUSt3R提供了一种更直接、更有效的解决方案。该模型能够处理多个视角的图像，并且减少了错误累积。&lt;h4&gt;翻译&lt;/h4&gt;房间布局估计从多个视角的图像出发受到的关注较少，这是由于复杂的多视图几何结构问题造成的，需要进行相机内参和外参估计、图像匹配以及三角测量等步骤。然而，在三维重建领域，近期3D基础模型（如DUSt3R）的发展改变了传统的基于结构的运动过程到端到端一步式的转变。为此，我们介绍了一种名为Plane-DUSt3R的方法，利用3D基础模型DUSt3R来进行多视角房间布局估计。通过在房间布局数据集上微调并修改目标以估算结构平面，生成一致且简洁的结果使仅需要一个后处理步骤和2D检测结果就可完成房间布局的估计。与依赖于单视角或全景图像的方法不同，Plane-DUSt3R可以处理多视角图像，并提供了一种简化流程减少错误累积的端到端解决方案。实验结果显示，无论是合成数据还是真实世界中具有多种风格（如卡通）的数据集，Plane-DUSt3R都优于现有最佳方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Room layout estimation from multiple-perspective images is poorlyinvestigated due to the complexities that emerge from multi-view geometry,which requires muti-step solutions such as camera intrinsic and extrinsicestimation, image matching, and triangulation. However, in 3D reconstruction,the advancement of recent 3D foundation models such as DUSt3R has shifted theparadigm from the traditional multi-step structure-from-motion process to anend-to-end single-step approach. To this end, we introduce Plane-DUSt3R}, anovel method for multi-view room layout estimation leveraging the 3D foundationmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes ona room layout dataset (Structure3D) with a modified objective to estimatestructural planes. By generating uniform and parsimonious results, Plane-DUSt3Renables room layout estimation with only a single post-processing step and 2Ddetection results. Unlike previous methods that rely on single-perspective orpanorama image, Plane-DUSt3R extends the setting to handle multiple-perspectiveimages. Moreover, it offers a streamlined, end-to-end solution that simplifiesthe process and reduces error accumulation. Experimental results demonstratethat Plane-DUSt3R not only outperforms state-of-the-art methods on thesynthetic dataset but also proves robust and effective on in the wild data withdifferent image styles such as cartoon.</description>
      <author>example@mail.com (Yaxuan Huang, Xili Dai, Jianan Wang, Xianbiao Qi, Yixing Yuan, Xiangyu Yue)</author>
      <guid isPermaLink="false">2502.16779v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SDA-DDA Semi-supervised Domain Adaptation with Dynamic Distribution Alignment Network For Emotion Recognition Using EEG Signals</title>
      <link>http://arxiv.org/abs/2502.16485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的半监督领域适应框架SDA-DDA，该框架使用动态分布对齐机制和伪标签置信度过滤模块来解决情感脑机接口技术中个体间EEG数据差异的问题。&lt;h4&gt;背景&lt;/h4&gt;情感脑机接口（aBCI）通过监测并识别人类情绪状态促进情感感知技术的发展。然而，不同个体间的EEG信号存在显著的变异性，这阻碍了有效且广泛适用的情感脑机接口模型的发展。&lt;h4&gt;目的&lt;/h4&gt;为了应对这种挑战，研究旨在开发一种新的迁移学习框架，以提高aBCI在跨受试者和跨时段条件下的情感识别准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为SDA-DDA的新半监督领域适应框架。该框架通过最大均值差异（MMD）和条件最大均值差异（CMMD）来对齐源域与目标域的边际及条件概率分布，并引入动态分布对齐机制以在整个训练过程中调整差异，提高适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明SDA-DDA框架在情感识别方面优于现有方法，在跨受试者和跨时段条件下表现尤为突出。这证明了该方法的强大鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;这项研究推进了情感脑机接口技术的发展，提高了情绪识别的泛化能力和准确性，有助于实现个性化的情感脑机接口应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们专注于解决个体差异在情感脑机接口（aBCI）中的挑战。通过EEG信号监测和识别人类的情绪状态，从而促进情感感知技术的发展。然而，不同个体间的EEG数据变异性是开发有效且广泛应用的情感脑机接口模型的主要障碍。为了解决这一问题，我们提出了一种新的迁移学习框架——半监督领域适应与动态分布对齐（SDA-DDA）。该方法使用最大均值差异（MMD）和条件最大均值差异（CMMD）来对齐源域与目标域的边际及条件概率分布。引入了动态分布对齐机制在整个训练过程中调整差异，提高适应性。此外，在半监督流程中集成了伪标签置信度过滤模块以优化伪标签生成并改善条件分布估计。在EEG基准数据库（SEED、SEED-IV和DEAP）上的广泛实验验证了SDA-DDA的强大鲁棒性和有效性。结果表明，相较于现有方法，该框架在各种场景下的情感识别中具有优越性，包括跨受试者和跨时段条件。这项进步增强了情感识别的泛化能力和准确性，可能促进个性化aBCI应用的发展。源代码可从https://github.com/XuanSuTrum/SDA-DDA获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we focus on the challenge of individual variability inaffective brain-computer interfaces (aBCI), which employs electroencephalogram(EEG) signals to monitor and recognize human emotional states, therebyfacilitating the advancement of emotion-aware technologies. The variability inEEG data across individuals poses a significant barrier to the development ofeffective and widely applicable aBCI models. To tackle this issue, we propose anovel transfer learning framework called Semi-supervised Domain Adaptation withDynamic Distribution Alignment (SDA-DDA). This approach aligns the marginal andconditional probability distribution of source and target domains using maximummean discrepancy (MMD) and conditional maximum mean discrepancy (CMMD). Weintroduce a dynamic distribution alignment mechanism to adjust differencesthroughout training and enhance adaptation. Additionally, a pseudo-labelconfidence filtering module is integrated into the semi-supervised process torefine pseudo-label generation and improve the estimation of conditionaldistributions. Extensive experiments on EEG benchmark databases (SEED, SEED-IVand DEAP) validate the robustness and effectiveness of SDA-DDA. The resultsdemonstrate its superiority over existing methods in emotion recognition acrossvarious scenarios, including cross-subject and cross-session conditions. Thisadvancement enhances the generalization and accuracy of emotion recognition,potentially fostering the development of personalized aBCI applications. Thesource code is accessible at https://github.com/XuanSuTrum/SDA-DDA.</description>
      <author>example@mail.com (Jiahao Tang)</author>
      <guid isPermaLink="false">2502.16485v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Keeping up with dynamic attackers: Certifying robustness to adaptive online data poisoning</title>
      <link>http://arxiv.org/abs/2502.16737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 28th International Conference on Artificial  Intelligence and Statistics (AISTATS) 2025, Mai Khao, Thailand. PMLR: Volume  258&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文研究了在在线学习环境中，动态对手进行数据投毒攻击对机器学习算法的影响，并提出了计算这种影响的认证边界的新框架。&lt;h4&gt;背景&lt;/h4&gt;随着基于人类反馈微调基础模型的发展，不信任用户提供的人类反馈增加了对抗性数据中毒的风险。现有研究表明静态对手通过修改训练集可以降低模型鲁棒性，但在实际应用中，动态对手能够观察和响应学习过程，并更有效地注入毒害样本以优化其目标。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架来计算动态投毒影响的认证边界，并利用这些证书设计出更加稳健的学习算法。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个新的计算认证边界的框架，并通过均值估计和二元分类问题进行了说明，展示了如何使用该框架设计对抗数据投毒攻击更为有效的学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;在线动态对手相较于静态对手更具威胁性。提出的框架能够帮助构建更稳健的机器学习模型，抵御更复杂的数据中毒攻击。&lt;h4&gt;结论&lt;/h4&gt;研究为解决在线学习中的动态数据投毒问题提供了新方法和理论支持，并指出未来工作应进一步探索该领域。&lt;h4&gt;翻译&lt;/h4&gt;基础模型根据潜在不可信用户的人类反馈进行微调的风险增加了对抗性数据中毒的风险，这需要对学习算法在面对此类攻击时的鲁棒性的研究。现有关于可证明认证鲁棒性以抵御数据投毒攻击的研究主要集中在静态对手上，这些对手可以在训练算法应用前修改一部分用于训练模型的数据集。但在实践中，尤其是在根据人类反馈进行在线学习的情况下，对抗者可以观察和响应学习过程，并注入优化其目标的有毒样本，比他们仅被限制在一次性中毒静态数据集中时更有效。事实上，在先前的工作中已经表明，在线动态对手可能远比静态对手更为强大。我们提出了一种用于计算动态投毒影响认证边界的新型框架，并使用这些证书来设计稳健的学习算法。论文展示了该框架在均值估计和二元分类问题上的应用示例，并概述了进一步工作的扩展方向。实现我们的证书并复制结果的代码可在https://github.com/Avinandan22/Certified-Robustness上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of foundation models fine-tuned on human feedback from potentiallyuntrusted users has increased the risk of adversarial data poisoning,necessitating the study of robustness of learning algorithms against suchattacks. Existing research on provable certified robustness against datapoisoning attacks primarily focuses on certifying robustness for staticadversaries who modify a fraction of the dataset used to train the model beforethe training algorithm is applied. In practice, particularly when learning fromhuman feedback in an online sense, adversaries can observe and react to thelearning process and inject poisoned samples that optimize adversarialobjectives better than when they are restricted to poisoning a static datasetonce, before the learning algorithm is applied. Indeed, it has been shown inprior work that online dynamic adversaries can be significantly more powerfulthan static ones. We present a novel framework for computing certified boundson the impact of dynamic poisoning, and use these certificates to design robustlearning algorithms. We give an illustration of the framework for the meanestimation and binary classification problems and outline directions forextending this in further work. The code to implement our certificates andreplicate our results is available athttps://github.com/Avinandan22/Certified-Robustness.</description>
      <author>example@mail.com (Avinandan Bose, Laurent Lessard, Maryam Fazel, Krishnamurthy Dj Dvijotham)</author>
      <guid isPermaLink="false">2502.16737v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Improving Monocular Visual-Inertial Initialization with Structureless Visual-Inertial Bundle Adjustment</title>
      <link>http://arxiv.org/abs/2502.16598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;单目视觉惯性里程计（VIO）在实时运动追踪应用中表现出色，得益于传感器套件的小巧和低功耗。为了成功启动VIO算法，初始化模块非常重要。&lt;h4&gt;背景&lt;/h4&gt;大多数初始化方法依赖于三维视觉点云的重建。这些方法由于状态向量包含运动状态和三维特征点而导致计算成本较高。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，并提高无结构初始化法的准确性，提出了新的无结构视觉惯性捆绑调整方法以进一步细化先前的无结构解。&lt;h4&gt;方法&lt;/h4&gt;该论文提出了一种新型的无结构视觉惯性捆绑调整算法来改进初始状态估计问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在保持实时性能的同时显著提高了VIO初始化精度。&lt;h4&gt;结论&lt;/h4&gt;通过新的无结构视觉惯性捆绑调整技术，不仅解决了计算效率的问题，还提升了VIO系统的初始化准确性。&lt;h4&gt;翻译&lt;/h4&gt;单目视觉惯性里程计（VIO）由于传感器套件的小巧和低功耗，在实时运动追踪应用中得到广泛应用。为了成功启动这些算法，初始化模块至关重要。大多数现有方法依赖于三维点云重建，这导致计算成本较高。为解决此问题并提升无结构化方法的性能准确性，研究者提出了新的无结构视觉惯性捆绑调整技术以进一步优化初始状态估计。实验结果表明，该方法显著提高了VIO系统的初始化精度，并保持了实时处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular visual inertial odometry (VIO) has facilitated a wide range ofreal-time motion tracking applications, thanks to the small size of the sensorsuite and low power consumption. To successfully bootstrap VIO algorithms, theinitialization module is extremely important. Most initialization methods relyon the reconstruction of 3D visual point clouds. These methods suffer from highcomputational cost as state vector contains both motion states and 3D featurepoints. To address this issue, some researchers recently proposed astructureless initialization method, which can solve the initial state withoutrecovering 3D structure. However, this method potentially compromisesperformance due to the decoupled estimation of rotation and translation, aswell as linear constraints. To improve its accuracy, we propose novelstructureless visual-inertial bundle adjustment to further refine previousstructureless solution. Extensive experiments on real-world datasets show ourmethod significantly improves the VIO initialization accuracy, whilemaintaining real-time performance.</description>
      <author>example@mail.com (Junlin Song, Antoine Richard, Miguel Olivares-Mendez)</author>
      <guid isPermaLink="false">2502.16598v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MOB-GCN: A Novel Multiscale Object-Based Graph Neural Network for Hyperspectral Image Classification</title>
      <link>http://arxiv.org/abs/2502.16289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为MOB-GCN的新型多尺度对象基于图神经网络，用于高光谱图像(HSI)分类。该研究的主要目标是通过利用多尺度对象基础影像分析(OBIA)，提高特征提取和分类性能。&lt;h4&gt;背景&lt;/h4&gt;传统的像素级方法通常由于准确性低和斑点噪声问题而效果不佳，单一尺度的OBIA方法可能忽略了不同细节层次下影像物体的重要信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，MOB-GCN通过从多个分割尺度中提取并整合特征来提升分类结果。该模型利用多分辨率图网络（MGN）架构捕捉细粒度和全局空间模式。&lt;h4&gt;方法&lt;/h4&gt;通过构建动态的多尺度图层级结构，MOB-GCN提供了对HSI复杂细节与全局上下文更全面的理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与单一尺度图卷积网络(GCN)相比，MOB-GCN在分类准确性、计算效率和降噪方面表现更为出色，尤其是在标注数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;MOB-GCN的实现代码可在https://github.com/HySonLab/MultiscaleHSI 上公开获得。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一种名为MOB-GCN的新颖多尺度对象基于图神经网络以改进高光谱图像(HSI)分类中的特征提取和分类性能。传统像素级方法因准确性低及斑点噪声而受限，单一尺度OBIA方法容易忽略不同层次细节下的关键信息。为了克服这些问题，MOB-GCN通过从多个分割层级中整合并提取特征来增强其性能，并采用多分辨率图网络（MGN）架构捕捉细粒度与全局空间模式。构建的动态多尺度图层级结构使对HSI复杂性有更深入理解的同时提高了准确性、效率及抗噪能力，特别是在数据标记有限的情况下表现更加突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel multiscale object-based graph neural networkcalled MOB-GCN for hyperspectral image (HSI) classification. The central aim ofthis study is to enhance feature extraction and classification performance byutilizing multiscale object-based image analysis (OBIA). Traditionalpixel-based methods often suffer from low accuracy and speckle noise, whilesingle-scale OBIA approaches may overlook crucial information of image objectsat different levels of detail. MOB-GCN overcomes these challenges by extractingand integrating features from multiple segmentation scales, leveraging theMultiresolution Graph Network (MGN) architecture to capture both fine-grainedand global spatial patterns. MOB-GCN addresses this issue by extracting andintegrating features from multiple segmentation scales to improveclassification results using the Multiresolution Graph Network (MGN)architecture that can model fine-grained and global spatial patterns. Byconstructing a dynamic multiscale graph hierarchy, MOB-GCN offers a morecomprehensive understanding of the intricate details and global context ofHSIs. Experimental results demonstrate that MOB-GCN consistently outperformssingle-scale graph convolutional networks (GCNs) in terms of classificationaccuracy, computational efficiency, and noise reduction, particularly whenlabeled data is limited. The implementation of MOB-GCN is publicly available athttps://github.com/HySonLab/MultiscaleHSI</description>
      <author>example@mail.com (Tuan-Anh Yang, Truong-Son Hy, Phuong D. Dao)</author>
      <guid isPermaLink="false">2502.16289v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models</title>
      <link>http://arxiv.org/abs/2502.16671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究介绍了一种新的数据集MimeQA，旨在促进社会智能AI的发展。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能越来越深入人们的日常生活，理解并进行无缝交流的社交智能AI变得愈发重要。然而当前的人工智能在非语言交互的理解上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过利用哑剧视频这一富含非言语和社交互动的数据源，改进现有模型对非语言社会互动的理解能力。&lt;h4&gt;方法&lt;/h4&gt;创建了一个新的数据集MimeQA，该数据集中包含221个源自YouTube的哑剧视频，并从中选取了101个视频进行详细标注，形成了806个问题答案配对。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用MimeQA评估最先进的视频大型语言模型(vLLMs)，研究者们发现这些模型在解释非言语互动时准确性较低（15%-30%），且存在过分依赖文本提示而忽视微妙的非言语互动的问题。&lt;h4&gt;结论&lt;/h4&gt;发布数据集旨在推动基础模型的发展，使其能更好地理解非言语的人类交互，促进真正具备社会智能的AI系统的发展。&lt;h4&gt;翻译&lt;/h4&gt;社交智慧型人工智能能够理解和无缝地与人类进行日常生活的交流变得越来越重要。然而目前关于人工社交推理的研究都依赖于语言或以语言为主的方法来进行基准测试和训练模型，导致这些系统在口头沟通方面有所进步但在非言语的社会理解上存在困难。为了克服这一局限性，我们利用了一个新的数据源——哑剧视频来研究非言语社会互动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Socially intelligent AI that can understand and interact seamlessly withhumans in daily lives is increasingly important as AI becomes more closelyintegrated with peoples' daily activities. However, current works in artificialsocial reasoning all rely on language-only, or language-dominant approaches tobenchmark and training models, resulting in systems that are improving inverbal communication but struggle with nonverbal social understanding. Toaddress this limitation, we tap into a novel source of data rich in nonverbaland social interactions -- mime videos. Mimes refer to the art of expressionthrough gesture and movement without spoken words, which presents uniquechallenges and opportunities in interpreting non-verbal social communication.We contribute a new dataset called MimeQA, obtained by sourcing 221 videos fromYouTube, through rigorous annotation and verification, resulting in a benchmarkwith 101 videos and 806 question-answer pairs. Using MimeQA, we evaluatestate-of-the-art video large language models (vLLMs) and find that theiroverall accuracy ranges from 15-30%. Our analysis reveals that vLLMs often failto ground imagined objects and over-rely on the text prompt while ignoringsubtle nonverbal interactions. Our data resources are released athttps://github.com/MIT-MI/MimeQA to inspire future work in foundation modelsthat embody true social intelligence capable of interpreting non-verbal humaninteractions.</description>
      <author>example@mail.com (Hengzhi Li, Megan Tjandrasuwita, Yi R. Fung, Armando Solar-Lezama, Paul Pu Liang)</author>
      <guid isPermaLink="false">2502.16671v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-Aware 3D Salient Object Detection Network</title>
      <link>http://arxiv.org/abs/2502.16488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于几何感知的3D显著对象检测网络，该网络通过将点聚类成超级点来提升物体的几何边界，并清晰地分割出具有复杂背景的对象。&lt;h4&gt;背景&lt;/h4&gt;近年来，研究人员对点云显著性目标检测产生了兴趣。然而，现有的工作未能充分利用3D对象的几何上下文，在处理具有复杂背景的对象时会导致模糊边界。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用3D对象的几何信息来清晰分割出完整物体的网络模型。&lt;h4&gt;方法&lt;/h4&gt;首先设计了一个简单的超级点划分模块以将点聚类成超级点，并提出了一种无类别感知损失函数来提高超级点的质量。然后，通过超级点-点注意力机制聚合几何信息到点特征中，预测具有清晰边界的显著图。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在PCSOD数据集上取得了最新的最优性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提升3D显著对象检测的效果，并且对于处理复杂背景下的物体分割任务特别有效。&lt;h4&gt;翻译&lt;/h4&gt;点云显著性目标检测已经引起了研究人员的注意。由于现有的工作未能充分利用3D对象的几何上下文，当对具有复杂背景的对象进行分割时会产生模糊边界。在这篇论文中，我们提出了一种基于几何感知的3D显著性对象检测网络，该网络通过将点显式地聚类成超级点来增强物体的几何边界，从而清晰地分割出具有完整边界的物体。具体来说，首先设计了一个简单的超级点划分模块以将点聚类成超级点，并提出了一种无类别感知损失函数来提高超级点的质量。然后，通过超级点-点注意力机制聚合几何信息到点特征中，预测具有清晰边界的显著图。广泛的实验表明，该方法在PCSOD数据集上取得了最新的最优性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud salient object detection has attracted the attention ofresearchers in recent years. Since existing works do not fully utilize thegeometry context of 3D objects, blurry boundaries are generated when segmentingobjects with complex backgrounds. In this paper, we propose a geometry-aware 3Dsalient object detection network that explicitly clusters points intosuperpoints to enhance the geometric boundaries of objects, thereby segmentingcomplete objects with clear boundaries. Specifically, we first propose a simpleyet effective superpoint partition module to cluster points into superpoints.In order to improve the quality of superpoints, we present a point cloudclass-agnostic loss to learn discriminative point features for clusteringsuperpoints from the object. After obtaining superpoints, we then propose ageometry enhancement module that utilizes superpoint-point attention toaggregate geometric information into point features for predicting the salientmap of the object with clear boundaries. Extensive experiments show that ourmethod achieves new state-of-the-art performance on the PCSOD dataset.</description>
      <author>example@mail.com (Chen Wang, Liyuan Zhang, Le Hui, Qi Liu, Yuchao Dai)</author>
      <guid isPermaLink="false">2502.16488v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HetFS: A Method for Fast Similarity Search with Ad-hoc Meta-paths on Heterogeneous Information Networks</title>
      <link>http://arxiv.org/abs/2502.16288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实世界的信息网络形成了异构信息网络（HIN），节点和边表示为不同类型的对象和关系。相似性衡量的是两个节点的接近程度，并且主要基于它们连接到的其他节点的相似性递归地确定。&lt;h4&gt;问题定义&lt;/h4&gt;用户可能只对特定类型的链接感兴趣，这些链接在相似性的定义中作为元路径（meta-paths）表示。现有方法要么需要为不同的元路径重新训练异构图神经网络（HGNN），要么使用基于路径的方法进行灵活转换但准确性较低。&lt;h4&gt;目的&lt;/h4&gt;提出HetFS（Fast Similarity for Hetereogeneous information networks with user-given meta-paths）以解决实时查询中的问题，能够根据用户指定的元路径快速提供相似性结果。&lt;h4&gt;方法&lt;/h4&gt;HetFS利用满足元路径限制的路径信息和节点内容来计算相似度。它结合了路径信息与节点本身的特性，提高了准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证，HetFS在处理实时查询方面表现出色，超越现有的HGNN和基于路径的方法，并且在下游应用中也展现了强大的性能，包括链路预测、节点分类以及聚类。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的方法HetFS来解决异构信息网络中的相似性搜索问题，它能够灵活应对用户指定的元路径并提高准确性与效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上面内容是根据摘要总结和翻译的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11280-024-01303-1&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous real-world information networks form Heterogeneous InformationNetworks (HINs) with diverse objects and relations represented as nodes andedges in heterogeneous graphs. Similarity between nodes quantifies how closelytwo nodes resemble each other, mainly depending on the similarity of the nodesthey are connected to, recursively. Users may be interested in only specifictypes of connections in the similarity definition, represented as meta-paths,i.e., a sequence of node and edge types. Existing Heterogeneous Graph NeuralNetwork (HGNN)-based similarity search methods may accommodate meta-paths, butrequire retraining for different meta-paths. Conversely, existing path-basedsimilarity search methods may switch flexibly between meta-paths but oftensuffer from lower accuracy, as they rely solely on path information. This paperproposes HetFS, a Fast Similarity method for ad-hoc queries with user-givenmeta-paths on Heterogeneous information networks. HetFS provides similarityresults based on path information that satisfies the meta-path restriction, aswell as node content. Extensive experiments demonstrate the effectiveness andefficiency of HetFS in addressing ad-hoc queries, outperformingstate-of-the-art HGNNs and path-based approaches, and showing strongperformance in downstream applications, including link prediction, nodeclassification, and clustering.</description>
      <author>example@mail.com (Xuqi Mao, Zhenyi Chen, Zhenying He, Yinan Jing, Kai Zhang, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16288v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Gaussian Mixture Variational Autoencoder for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.16140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于变分自编码器（VAE）的顺序推荐模型SIGMA，以克服现有VAE在处理用户多重兴趣时能力有限的问题。&lt;h4&gt;背景&lt;/h4&gt;目前大多数基于VAE的顺序推荐系统假设序列表示遵循单一高斯分布作为先验分布。然而，在实际应用中，由于用户的多种多样的兴趣，这种单峰分布难以捕捉复杂且多元化的兴趣模式，导致推荐效果受限。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一个新的基于VAE的顺序推荐模型SIGMA，旨在更好地适应用户的不同兴趣并提高推荐性能。&lt;h4&gt;方法&lt;/h4&gt;SIGMA通过假设序列表示遵循混合高斯分布作为先验来建立一个多模态的兴趣模型。此外，为了将这些多模态兴趣纳入序列表示学习中，SIGMA设计了一个概率多重兴趣提取模块和一个兼容混合高斯先验的多兴趣感知ELBO。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SIGMA在公共数据集上的推荐性能明显优于传统的基于VAE的方法。该模型通过考虑用户的多个兴趣点来提高用户个性化体验。&lt;h4&gt;结论&lt;/h4&gt;SIGMA为顺序推荐提供了一种新的方法论，特别是在处理用户复杂和多元化的兴趣方面显示出潜力。这将对未来的推荐系统设计产生积极影响。&lt;h4&gt;翻译&lt;/h4&gt;变分自编码器（VAE）在序列推荐中通过学习每个用户-项目交互序列的连续分布而不是确定性嵌入来提高数据缺乏下的稳健性和性能表现。然而，现有的基于VAE的序列推荐模型假设序列表示遵循单一高斯分布作为先验，这限制了捕捉复杂用户兴趣的能力，并且当用户具有多种兴趣时会降低推荐性能。由于用户通常会有多个不同的兴趣点，因此，在顺序推荐场景中建立多模态而非单峰的先验更为合理。本文提出了一种新的VAE基于序列推荐模型SIGMA。SIGMA假设序列表示遵循高斯混合分布作为先验，并且每个分量代表一个单独的兴趣。为了提取多重兴趣，SIGMA包括一个多兴趣概率抽取模块以学习每个兴趣的单一高斯分布根据隐含项目超类别进行学习。此外，SIGMA建立了与混合高斯先验兼容的多兴趣感知ELBO，以将多重兴趣整合到序列表示学习中。广泛的实验表明了SIGMA的有效性，代码可以在GitHub上获取（https://github.com/libeibei95/SIGMA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Variational AutoEncoder (VAE) for Sequential Recommendation (SR), whichlearns a continuous distribution for each user-item interaction sequence ratherthan a determinate embedding, is robust against data deficiency and achievessignificant performance. However, existing VAE-based SR models assume aunimodal Gaussian distribution as the prior distribution of sequencerepresentations, leading to restricted capability to capture complex userinterests and limiting recommendation performance when users have more than oneinterest. Due to that it is common for users to have multiple disparateinterests, we argue that it is more reasonable to establish a multimodal priordistribution in SR scenarios instead of a unimodal one. Therefore, in thispaper, we propose a novel VAE-based SR model named SIGMA. SIGMA assumes thatthe prior of sequence representation conforms to a Gaussian mixturedistribution, where each component of the distribution semantically correspondsto one of multiple interests. For multi-interest elicitation, SIGMA includes aprobabilistic multi-interest extraction module that learns a unimodal Gaussiandistribution for each interest according to implicit item hyper-categories.Additionally, to incorporate the multimodal interests into sequencerepresentation learning, SIGMA constructs a multi-interest-aware ELBO, which iscompatible with the Gaussian mixture prior. Extensive experiments on publicdatasets demonstrate the effectiveness of SIGMA. The code is available athttps://github.com/libeibei95/SIGMA.</description>
      <author>example@mail.com (Beibei Li, Tao Xiang, Beihong Jin, Yiyuan Zheng, Rui Zhao)</author>
      <guid isPermaLink="false">2502.16140v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly preserving contrastive neural embeddings for end-to-end model-independent searches at the LHC</title>
      <link>http://arxiv.org/abs/2502.15926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了通过对比神经嵌入学习强大的低维表示以解决大型强子对撞机(LHC)中异常检测的问题。&lt;h4&gt;背景&lt;/h4&gt;在LHC这样的设备中，由于数据集的规模和复杂性，异常检测是一项关键挑战。通常采用的方法是将高维度探测器数据转换为具有物理意义的低维度特征。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在通过对比神经嵌入方法从数据中提取物理信号并识别潜在的新物理现象。&lt;h4&gt;方法&lt;/h4&gt;文中比较了监督和自我监督的对比学习方法，包括多层感知机(MLP)和Transformer架构。这些方法基于LHC碰撞事件中的动力学可观测属性进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;利用学习到的嵌入表示作为信号无关统计检测方法的输入，在包含所有最终状态中实现了超过十倍于原始特征表现的异常检测性能，并且相对于相同维度的物理信息选择，最多有四倍的改进。研究还展示了这些模型在搜索多种信号时的有效性。&lt;h4&gt;结论&lt;/h4&gt;发现用于背景分类的最佳表示不一定最大化新物理信号的敏感度，表明保持背景结构和增强异常之间存在内在权衡。该论文强调了基础模型在粒子物理学数据中的应用潜力，能够显著提高神经特征提取，并为全包含最终状态下的科学发现提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;异常检测——识别与标准模型预测的偏差——是大型强子对撞机(LHC)面临的关键挑战，由于其数据集的巨大规模和复杂性。这通常通过将高维度探测器数据转换成低维度、物理意义明确的功能来解决。我们利用对比神经嵌入学习强大的低维表示方式处理特征提取以用于异常检测。这种方法保留了潜在的异常信号，这些信号可能指示新物理学，并且使用基于新型机器学习的统计方法进行无信号假设检验，从而可以提取稀有信号。我们比较了监督和自我监督对比学习方法，包括多层感知机(MLP)和Transformer架构，训练时使用的都是LHC碰撞事件中物理对象的动力学可观测属性。所学到的嵌入表示作为包含所有最终状态中的信号无关统计检测方法的输入，在异常检测性能方面比原始特征表现提高了十倍以上，并且相对于相同维度的基于物理学的选择最多提高四倍。我们证明了对于罕见的新物理信号和罕见的标准模型过程，无论在何种最终状态中都能显著提升发现能力，表明其能够同时有效地搜索多种信号。研究还指出背景分类的最佳表示不总是最大化对新物理信号的敏感度，揭示了保持背景结构与异常增强之间的固有权衡。本研究表明基础模型对于粒子物理学数据具有重要的改进潜力，能够提高神经特征提取，并为全包含最终状态下的科学发现提供可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection -- identifying deviations from Standard Model predictions-- is a key challenge at the Large Hadron Collider due to the size andcomplexity of its datasets. This is typically addressed by transforminghigh-dimensional detector data into lower-dimensional, physically meaningfulfeatures. We tackle feature extraction for anomaly detection by learningpowerful low-dimensional representations via contrastive neural embeddings.This approach preserves potential anomalies indicative of new physics andenables rare signal extraction using novel machine learning-based statisticalmethods for signal-independent hypothesis testing. We compare supervised andself-supervised contrastive learning methods, for both MLP- andTransformer-based neural embeddings, trained on the kinematic observables ofphysics objects in LHC collision events. The learned embeddings serve as inputrepresentations for signal-agnostic statistical detection methods in inclusivefinal states, achieving over ten fold improved detection performance over theoriginal feature representation and up to four fold improvement over using aphysics-informed selections of the same dimensionality. We achieve significantimprovement in discovery power for both rare new physics signals and rareStandard Model processes across diverse final states, demonstrating itsapplicability for efficiently searching for diverse signals simultaneously. Weshow that the optimal representation for background classification does notalways maximize sensitivity to new physics signals, revealing an inherenttrade-off between background structure preservation and anomaly enhancement.Our findings demonstrate that foundation models for particle physics data holdsignificant potential for improving neural feature extraction, enablingscientific discovery in inclusive final states at collider experiments.</description>
      <author>example@mail.com (Kyle Metzger, Lana Xu, Mia Sodini, Thea K. Arrestad, Katya Govorkova, Gaia Grosso, Philip Harris)</author>
      <guid isPermaLink="false">2502.15926v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>FHGE: A Fast Heterogeneous Graph Embedding with Ad-hoc Meta-paths</title>
      <link>http://arxiv.org/abs/2502.16281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Graph神经网络(GNNs)在各种与图相关的任务中取得了最先进的成果，并被广泛应用于异构图(HetGs)，其中元路径有助于编码不同节点类型之间的特定语义。尽管现有的异构GNNs（HGNNs）由于其专注于改进对异质性的捕捉效果而具有革命性的表示能力，但高昂的训练成本阻碍了它们在需要处理基于用户定义元路径的即时查询的真实场景中的实际部署。&lt;h4&gt;背景&lt;/h4&gt;现有技术通过改进对异构图中不同节点类型之间特定语义的理解达到了最先进的水平，然而这些方法面临着高昂的计算开销，这使得它们难以应用于实时应用场景。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，本文提出了一种快速异构图嵌入(FHGE)框架，旨在实现高效、无需重新训练即可生成元路径引导下的图嵌入。&lt;h4&gt;方法&lt;/h4&gt;FHGE采用了两部分设计：分割和重构模块。该系统利用元路径单元(MPUs)将图形分解为局部和全局组件，并在重组过程中迅速整合相关MPU的节点嵌入，使快速适应特定元路径成为可能；此外还应用了双重注意力机制来增强语义捕捉能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，FHGE框架在生成基于元路径引导下的图嵌入以及下游任务（例如链路预测和节点分类）方面既有效又高效，证明其对实时图形分析具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;FHGE框架提供了一种经济高效的解决方案，在处理异构图中的即时查询时能够快速生成所需的图表示，从而在实际应用中展示出良好的性能和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have emerged as the state of the art for avariety of graph-related tasks and have been widely used in HeterogeneousGraphs (HetGs), where meta-paths help encode specific semantics between variousnode types. Despite the revolutionary representation capabilities of existingheterogeneous GNNs (HGNNs) due to their focus on improving the effectiveness ofheterogeneity capturing, the huge training costs hinder their practicaldeployment in real-world scenarios that frequently require handling ad-hocqueries with user-defined meta-paths. To address this, we propose FHGE, a FastHeterogeneous Graph Embedding designed for efficient, retraining-freegeneration of meta-path-guided graph embeddings. The key design of the proposedframework is two-fold: segmentation and reconstruction modules. It employsMeta-Path Units (MPUs) to segment the graph into local and global components,enabling swift integration of node embeddings from relevant MPUs duringreconstruction and allowing quick adaptation to specific meta-paths. Inaddition, a dual attention mechanism is applied to enhance semantics capturing.Extensive experiments across diverse datasets demonstrate the effectiveness andefficiency of FHGE in generating meta-path-guided graph embeddings anddownstream tasks, such as link prediction and node classification, highlightingits significant advantages for real-time graph analysis in ad-hoc queries.</description>
      <author>example@mail.com (Xuqi Mao, Zhenying He, X. Sean Wang)</author>
      <guid isPermaLink="false">2502.16281v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs</title>
      <link>http://arxiv.org/abs/2502.16610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SPIE Medical Imaging 2025 Runner-up 2025 Robert F. Wagner  All-Conference Best Student Paper Award&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdverX-Ray的方法，用于评估医疗影像的质量。该方法利用对抗生成网络的高频率伪影来训练一个判别器，以检测数据分布的变化（即协变量偏移），从而保证基于深度学习的计算机辅助诊断和检测系统的性能。&lt;h4&gt;背景&lt;/h4&gt;医学影像质量对基于深度学习的计算机辅助诊断和检测系统至关重要。协变量偏移（由不同成像设备或设置引起的细微数据分布变化）会严重降低模型性能，类似于对抗攻击的影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种快速、轻量的方法来评估医疗影像的质量，以便在使用计算机辅助诊断和检测模型之前进行质量检查。&lt;h4&gt;方法&lt;/h4&gt;AdverX-Ray是一个图像质量评估层，它通过利用生成器产生的次优输出作为负面样本来微调判别器的能力。该系统训练于特定机器型号的X射线图像补丁，并能判断扫描是否符合训练分布或同一设备在不同设置下采集。&lt;h4&gt;主要发现&lt;/h4&gt;AdverX-Ray与各种异常数据检测方法相比，显著优于现有的技术，在使用64个随机选取的X射线图像补丁时达到了96.2%的平均AUROC。&lt;h4&gt;结论&lt;/h4&gt;该系统的轻量级和快速架构使其适合实时应用，并增强医疗成像系统的可靠性。代码和预训练模型公开可用。&lt;h4&gt;翻译&lt;/h4&gt;确保医学影像的质量与完整性对于保持基于深度学习的计算机辅助诊断（CAD）和检测（CAD）系统中的诊断准确性至关重要。协变量偏移是由不同成像设备或设置引起的数据分布细微变化，可严重降低模型性能，类似于对抗攻击的影响。因此，评估这些图像质量的方法必须是快速且轻量级的，以便在使用CAD模型之前完成。AdverX-Ray通过充当一个影像质量评估层来满足此需求，并有效检测协变量偏移。经过特定型号机器X射线图像补丁训练的AdverX-Ray能够判断扫描是否符合训练分布或同一设备不同设置下采集的图像。与各种异常数据检测方法相比，AdverX-Ray显著优于现有的技术，在使用64个随机选取的X射线图像补丁时达到了96.2%的平均AUROC。该系统轻量级和快速架构适合实时应用，并增强了医疗成像系统的可靠性。代码和预训练模型公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the quality and integrity of medical images is crucial formaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosisand Computer-Aided Detection (CAD) systems. Covariate shifts are subtlevariations in the data distribution caused by different imaging devices orsettings and can severely degrade model performance, similar to the effects ofadversarial attacks. Therefore, it is vital to have a lightweight and fastmethod to assess the quality of these images prior to using CAD models.AdverX-Ray addresses this need by serving as an image-quality assessment layer,designed to detect covariate shifts effectively. This Adversarial VariationalAutoencoder prioritizes the discriminator's role, using the suboptimal outputsof the generator as negative samples to fine-tune the discriminator's abilityto identify high-frequency artifacts. Images generated by adversarial networksoften exhibit severe high-frequency artifacts, guiding the discriminator tofocus excessively on these components. This makes the discriminator ideal forthis approach. Trained on patches from X-ray images of specific machine models,AdverX-Ray can evaluate whether a scan matches the training distribution, or ifa scan from the same machine is captured under different settings. Extensivecomparisons with various OOD detection methods show that AdverX-Raysignificantly outperforms existing techniques, achieving a 96.2% average AUROCusing only 64 random patches from an X-ray. Its lightweight and fastarchitecture makes it suitable for real-time applications, enhancing thereliability of medical imaging systems. The code and pretrained models arepublicly available.</description>
      <author>example@mail.com (Francisco Caetano, Christiaan Viviers, Lena Filatova, Peter H. N. de With, Fons van der Sommen)</author>
      <guid isPermaLink="false">2502.16610v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Iterative Auto-Annotation for Scientific Named Entity Recognition Using BERT-Based Models</title>
      <link>http://arxiv.org/abs/2502.16312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种使用基于BERT的模型进行科学命名实体识别（SciNER）的迭代方法，并利用少量高质量的手动标注数据集通过迁移学习来微调预训练模型。&lt;h4&gt;背景&lt;/h4&gt;在缺乏大规模标注数据的情况下，如何有效地提高自然语言处理任务中的预测准确性是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于BERT的SciNER迭代改进方法，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;采用两种不同的模型（dslim/bert-large-NER和bert-large-cased），通过高质量的手动注释数据集进行微调，然后使用微调后的模型自动标注更大的数据集，并进一步进行多轮微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于BERT的模型在预测准确性和F1分数方面有了显著提高，特别是对于较少见的实体类。bert-large-cased模型始终优于dslim/bert-large-NER模型。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了一种有效的SciNER迭代改进技术，在标注数据有限的情况下具有广泛的应用潜力，并且未来的研究可以考虑使用未标记的数据进行微调以及探索更强力的编码器如RoBERTa。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：本文提出了一种使用基于BERT的模型进行科学命名实体识别（SciNER）的迭代方法。利用转移学习来对预训练模型进行微调，其中使用了少量但高质量的手动标注数据集。通过使用经过微调后的模型自动标注更大的数据集，并随后进一步多轮微调这一过程得到了反复精炼。我们评估了两种模型（dslim/bert-large-NER和bert-largecased），结果表明后者始终优于前者。该方法在预测准确性和F1分数方面表现出了显著的改进，尤其是对于较少见的实体类。未来的研究可以考虑使用未标注的数据进行微调，并探索更强大的编码器如RoBERTa以及扩展手动注释的范围。这一方法在自然语言处理任务中具有广泛应用潜力，尤其是在数据标签受限的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an iterative approach to performing Scientific NamedEntity Recognition (SciNER) using BERT-based models. We leverage transferlearning to fine-tune pretrained models with a small but high-quality set ofmanually annotated data. The process is iteratively refined by using thefine-tuned model to auto-annotate a larger dataset, followed by additionalrounds of fine-tuning. We evaluated two models, dslim/bert-large-NER andbert-largecased, and found that bert-large-cased consistently outperformed theformer. Our approach demonstrated significant improvements in predictionaccuracy and F1 scores, especially for less common entity classes. Future workcould include pertaining with unlabeled data, exploring more powerful encoderslike RoBERTa, and expanding the scope of manual annotations. This methodologyhas broader applications in NLP tasks where access to labeled data is limited.</description>
      <author>example@mail.com (Kartik Gupta)</author>
      <guid isPermaLink="false">2502.16312v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Verifying Quantized Graph Neural Networks is PSPACE-complete</title>
      <link>http://arxiv.org/abs/2502.16244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究验证量化图神经网络（GNNs）的可行性，其中使用固定宽度算术表示数。&lt;h4&gt;目的&lt;/h4&gt;引入线性约束有效性问题(LVP)来验证GNNs属性，并提供一个从LVP实例到逻辑语言的有效翻译。&lt;h4&gt;方法&lt;/h4&gt;提出了一种证明系统并展示了对于任何合理的激活函数，LVP属于PSPACE复杂度类别。同时表明了PSPACE难度，暗示虽然关于量化GNN的推理是可行的，但仍然是计算上具有挑战性的任务。&lt;h4&gt;主要发现&lt;/h4&gt;验证量化GNNs属性的问题(LVP)被定义为在PSPACE中，并证明了其PSPACE难解性。&lt;h4&gt;结论&lt;/h4&gt;尽管存在一定的计算难度，但对于合理激活函数而言，在PSPACE复杂度类别内解决问题是可能的。这表明对量化GNN的推理虽然具有挑战性但仍可实现。&lt;h4&gt;翻译&lt;/h4&gt;本论文研究使用固定宽度算术表示数的量化图神经网络（GNNs）的验证问题，并引入线性约束有效性(LVP)问题，以验证GNN属性的有效性和提供LVP实例到逻辑语言的高效转换。结果显示，对于任何合理激活函数来说，该问题属于PSPACE复杂度类别；同时证明了其PSPACE难度。表明虽然对量化GNN进行推理是可行的，但计算上仍然具有挑战性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate verification of quantized Graph Neural Networks(GNNs), where some fixed-width arithmetic is used to represent numbers. Weintroduce the linear-constrained validity (LVP) problem for verifying GNNsproperties, and provide an efficient translation from LVP instances into alogical language. We show that LVP is in PSPACE, for any reasonable activationfunctions. We provide a proof system. We also prove PSPACE-hardness, indicatingthat while reasoning about quantized GNNs is feasible, it remains generallycomputationally challenging.</description>
      <author>example@mail.com (Marco Sälzer, François Schwarzentruber, Nicolas Troquard)</author>
      <guid isPermaLink="false">2502.16244v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SelaVPR++: Towards Seamless Adaptation of Foundation Models for Efficient Place Recognition</title>
      <link>http://arxiv.org/abs/2502.16601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种改进的视觉地方识别(SelaVPR++)方法，通过使用轻量级多尺度卷积(MultiConv)适配器来提高基础模型向视觉地方识别任务适应的有效性和性能。&lt;h4&gt;背景&lt;/h4&gt;近期研究表明，利用预训练的视觉基础模型进行视觉位置识别(VPR)可以取得良好的效果。作者之前的工作提出了SelaVPR方法，该方法通过参数高效的方法实现了基础模型向VPR的无缝转换。&lt;h4&gt;目的&lt;/h4&gt;为了提高效率和性能，论文提出了一种SelaVPR的扩展版本——SelaVPR++。&lt;h4&gt;方法&lt;/h4&gt;引入了参数、时间和内存高效的适应策略，利用轻量级多尺度卷积适配器来细化从冻结基础骨干网络获得的中间特征；创新性地提出了更有效的重新排序范式，通过使用紧凑型二进制特征进行初步检索，并采用鲁棒的浮点特征进行重新排序。&lt;h4&gt;主要发现&lt;/h4&gt;提出的相似度约束深度哈希方法可以获得这样的二进制特征，并且可以很容易地集成到VPR流程中；优化了训练策略，统一了几种常见训练数据集的训练协议以更好地培训VPR模型。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明……&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，使用预训练视觉基础模型进行视觉位置识别（VPR）可以实现令人满意的结果。在我们的先前工作中，我们提出了一种方法，将视觉基础模型无缝转换为VPR（SelaVPR）。这种适应方法可以通过参数高效的方法产生全局和局部特征来区分地标，从而用于两阶段的视觉位置识别。尽管SelaVPR已经取得了具有竞争力的效果，但我们认为之前的适应方法在训练时间和GPU内存使用上是低效的，并且重新排序范式在检索延迟和存储使用方面也是昂贵的。为了追求更高的效率和更好的性能，我们提出了SelaVPR的一种扩展版本——SelaVPR++。具体来说，首先设计了一种参数、时间、内存高效的适应方法，该方法利用轻量级多尺度卷积（MultiConv）适配器来细化来自冻结基础骨干网络的中间特征，在训练期间不会反向传播通过基础模型的梯度，并且这种MultiConv适配器可以促进沿空间轴上的特征交互并引入适当的局部先验，从而实现更高的效率和更好的性能。此外，我们提出了一种创新性的重新排序范式以实现更高效的VPR：不依赖于本地特征进行重新排序，这在延迟和存储使用方面会产生巨大的开销，而是采用紧凑的二进制特征用于初步检索，并用鲁棒的浮点（全局）特征用于重新排序。为了获得这些二进制特征，我们提出了一种相似度约束深度哈希方法，可以很容易地整合到VPR流程中。最后，我们改进了我们的训练策略并统一了几种常见训练数据集的训练协议以合并它们以便更好地培训VPR模型。广泛的实验表明……&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent studies show that the visual place recognition (VPR) method usingpre-trained visual foundation models can achieve promising performance. In ourprevious work, we propose a novel method to realize seamless adaptation offoundation models to VPR (SelaVPR). This method can produce both global andlocal features that focus on discriminative landmarks to recognize places fortwo-stage VPR by a parameter-efficient adaptation approach. Although SelaVPRhas achieved competitive results, we argue that the previous adaptation isinefficient in training time and GPU memory usage, and the re-ranking paradigmis also costly in retrieval latency and storage usage. In pursuit of higherefficiency and better performance, we propose an extension of the SelaVPR,called SelaVPR++. Concretely, we first design a parameter-, time-, andmemory-efficient adaptation method that uses lightweight multi-scaleconvolution (MultiConv) adapters to refine intermediate features from thefrozen foundation backbone. This adaptation method does not back-propagategradients through the backbone during training, and the MultiConv adapterfacilitates feature interactions along the spatial axes and introduces properlocal priors, thus achieving higher efficiency and better performance.Moreover, we propose an innovative re-ranking paradigm for more efficient VPR.Instead of relying on local features for re-ranking, which incurs huge overheadin latency and storage, we employ compact binary features for initial retrievaland robust floating-point (global) features for re-ranking. To obtain suchbinary features, we propose a similarity-constrained deep hashing method, whichcan be easily integrated into the VPR pipeline. Finally, we improve ourtraining strategy and unify the training protocol of several common trainingdatasets to merge them for better training of VPR models. Extensive experimentsshow that ......</description>
      <author>example@mail.com (Feng Lu, Tong Jin, Xiangyuan Lan, Lijun Zhang, Yunpeng Liu, Yaowei Wang, Chun Yuan)</author>
      <guid isPermaLink="false">2502.16601v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Graph Attention Convolutional U-NET: A Semantic Segmentation Model for Identifying Flooded Areas</title>
      <link>http://arxiv.org/abs/2502.15907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络的自动化洪水区域识别模型，即Graph Attention Convolutional U-NET (GAC-UNET)，该模型结合了图注意力机制和Chebyshev层，并在实验中显示出优于其他方法的表现。&lt;h4&gt;背景&lt;/h4&gt;近年来，由于人为气候变化和无规划的城市建设导致洪灾事件增多。准确地识别洪水区域对于有效的灾害管理和城市规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于图神经网络的方法来自动识别洪水区域，利用转移学习和模型重新编程以提高洪水区域分割模型的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用Graph Attention Convolutional U-NET (GAC-UNET) 模型，该模型将图注意力机制和Chebyshev层融入到U-Net架构中，并探索了转移学习的应用。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GAC-UNET模型在mAP、Dice分数和IoU指标上分别达到了91%，94%和89%，超过了其他方法，显示出了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究为洪水易发区域未来的基础设施规划提供了有价值的见解，并表明图神经网络可以在自动化识别洪水区域方面提供改进的机会。&lt;h4&gt;翻译&lt;/h4&gt;不断加剧的人类活动导致的气候变化以及未规划的城市建设在过去几年里增加了洪灾事件。准确地辨识受影响地区对于有效的灾害管理和城市规划至关重要。虽然有少量研究采用卷积神经网络和基于变压器的语义分割技术来识别航空影像中的洪水区域，但图神经网络的发展创造了许多改进的机会。这篇论文提出了一种创新的方法——基于图神经网络（GAC-UNET）模型，用于自动化地辨识洪水区域，并在实验中展示了显著优于其他方法的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing impact of human-induced climate change and unplanned urbanconstructions has increased flooding incidents in recent years. Accurateidentification of flooded areas is crucial for effective disaster managementand urban planning. While few works have utilized convolutional neural networksand transformer-based semantic segmentation techniques for identifying floodedareas from aerial footage, recent developments in graph neural networks havecreated improvement opportunities. This paper proposes an innovative approach,the Graph Attention Convolutional U-NET (GAC-UNET) model, based on graph neuralnetworks for automated identification of flooded areas. The model incorporatesa graph attention mechanism and Chebyshev layers into the U-Net architecture.Furthermore, this paper explores the applicability of transfer learning andmodel reprogramming to enhance the accuracy of flood area segmentation models.Empirical results demonstrate that the proposed GAC-UNET model, outperformsother approaches with 91\% mAP, 94\% dice score, and 89\% IoU, providingvaluable insights for informed decision-making and better planning of futureinfrastructures in flood-prone areas.</description>
      <author>example@mail.com (Muhammad Umair Danish, Madhushan Buwaneswaran, Tehara Fonseka, Katarina Grolinger)</author>
      <guid isPermaLink="false">2502.15907v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control</title>
      <link>http://arxiv.org/abs/2502.16475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单张图像3D生成已成为一个重要的研究领域，在虚拟现实、三维建模和数字内容创作中起着重要作用。&lt;h4&gt;问题&lt;/h4&gt;现有的方法面临多视角几何一致性不足及生成过程可控性有限的问题，这些问题显著限制了它们的实用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法Drage3D来解决这些挑战，该方法利用3D高斯斑点实现具有几何一致性和可控制性的3D生成。&lt;h4&gt;方法&lt;/h4&gt;{'Anchor-Gaussian变分自编码器(AGSVAE)': '将点云和单张图像编码成锚定潜在变量，并通过解码锚定潜在变量生成3DGS，从而实现高效的潜在空间生成。', 'Seed-Point-Driven策略': '该策略包括两步：首先生成稀疏种子点作为粗糙的几何表示；其次通过Seed-Anchor映射模块将这些种子点映射到锚定潜在变量。这种策略确保了几何一致性，并且用户可以直观地拖动种子点来变形最终3DGS几何，变化会通过锚定潜在变量传播。', '无需2D扩散先验': '我们是首个实现不依赖于2D扩散先验的几何可控制性3D高斯生成和编辑的方法。'}&lt;h4&gt;主要发现&lt;/h4&gt;Drage3D在保持高质量3D生成的同时，实现了多视角几何一致性和用户可控性。&lt;h4&gt;结论&lt;/h4&gt;Drage3D为单图像到三维生成开辟了新的道路，显著提高了现有技术的实用性。&lt;h4&gt;翻译&lt;/h4&gt;单张图像3D生成已作为一项重要研究课题崛起，在虚拟现实、3D建模和数字内容创建中扮演着至关重要的角色。然而，现存的方法面临着诸如缺乏多视角几何一致性以及在生成过程中可控性有限等挑战，这些严重限制了它们的实用性。为了解决这些问题，我们引入了一种名为Drage3D的新方法，利用三维高斯斑点（3DGS）实现了具有几何一致性和可控制性的3D生成。通过Anchor-Gaussian变分自编码器(AGSVAE)，该模型将点云和单张图像编码为锚定潜在变量，并通过这些潜在变量解码出3DGS，从而实现高效的潜在空间生成。为了达成多视角几何一致性及可控性生成目标，我们提出了一种Seed-Point驱动策略：首先生成稀疏种子点作为粗糙的几何表示；其次通过Seed-Anchor映射模块将它们映射到锚定潜在变量。这种策略确保了几何一致性，并且用户可以直观地拖动这些种子点来变形最终3DGS几何，变化会经过锚定潜在变量传播。据我们所知，我们在不依赖于2D扩散先验的情况下首次实现了具有可控制性三维高斯生成和编辑的方法，同时保持了与最先进方法相当的3D生成质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single-image 3D generation has emerged as a prominent research topic, playinga vital role in virtual reality, 3D modeling, and digital content creation.However, existing methods face challenges such as a lack of multi-viewgeometric consistency and limited controllability during the generationprocess, which significantly restrict their usability. % To tackle thesechallenges, we introduce Dragen3D, a novel approach that achieves geometricallyconsistent and controllable 3D generation leveraging 3D Gaussian Splatting(3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GSVAE), which encodes a point cloud and a single image into anchor latents anddecode these latents into 3DGS, enabling efficient latent-space generation. Toenable multi-view geometry consistent and controllable generation, we propose aSeed-Point-Driven strategy: first generate sparse seed points as a coarsegeometry representation, then map them to anchor latents via the Seed-AnchorMapping Module. Geometric consistency is ensured by the easily learned sparseseed points, and users can intuitively drag the seed points to deform the final3DGS geometry, with changes propagated through the anchor latents. To the bestof our knowledge, we are the first to achieve geometrically controllable 3DGaussian generation and editing without relying on 2D diffusion priors,delivering comparable 3D generation quality to state-of-the-art methods.</description>
      <author>example@mail.com (Jinbo Yan, Alan Zhao, Yixin Hu)</author>
      <guid isPermaLink="false">2502.16475v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Graph Self-Supervised Learning with Learnable Structural and Positional Encodings</title>
      <link>http://arxiv.org/abs/2502.16233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by The World Wide Web Conference (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了新型图自监督学习框架GenHopNet，该框架旨在解决传统GSSL难以捕捉复杂结构特征的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的图自监督学习（GSSL）在捕获复杂的结构性质方面存在困难。这主要是由于两个原因：一是常规图神经网络（GNNs）无法很好地表示复杂的拓扑特征；二是自监督学习仅仅关注最终的图表示，而忽略了整个过程中的结构信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服这些限制，并增强在区分具有相似局部但不同全局拓扑的图形的能力。&lt;h4&gt;方法&lt;/h4&gt;引入了GenHopNet框架，这是一个融合$k$-跳消息传递机制的GNN框架。此外还提出了一个既考虑结构性又注重位置信息的自监督学习框架，该框架能够在整个学习过程中整合图的拓扑信息。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明GenHopNet超越了经典的Weisfeiler-Lehman（WL）测试在图同构上的表达能力，并且实验结果显示这种方法在图分类数据集上优于现有方法，特别是在那些用于测试结构敏感性的数据集上表现尤为突出。同时保持计算效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的GenHopNet框架及其相关的自监督学习策略显著增强了GSSL区分具有相似局部但不同全局拓扑的图形的能力。&lt;h4&gt;翻译&lt;/h4&gt;传统的图自我监督学习(GSSL)在捕捉复杂的结构特性方面存在困难，这主要是由于两个因素：(1) 常规图神经网络（GNNs）无法充分代表复杂的拓扑特征；(2) 自我监督学习仅关注最终的图表示。为了解决这些问题，我们提出了一个新的框架GenHopNet，它是一个融合了$k$-跳消息传递机制的GNN架构，增强了捕捉局部结构信息的能力而无需显式地提取子结构。理论证明表明，GenHopNet在表达能力上超越了经典的Weisfeiler-Lehman (WL) 测试用于图同构测试。此外，我们还提出了一种基于位置和结构感知的GSSL框架，在整个学习过程中整合拓扑信息，使模型能够同时敏感于图形的拓扑且对特定的结构及特征增强保持不变性。在包括旨在测试结构敏感性的图分类数据集上的全面实验表明，我们的方法在性能上始终优于现有的方法，并且计算效率高。我们的重要贡献在于大幅提升了GSSL区分具有相似局部但不同全局拓扑的图形的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714745&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Graph Self-Supervised Learning (GSSL) struggles to capturecomplex structural properties well. This limitation stems from two mainfactors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) inrepresenting sophisticated topological features, and (2) the focus ofself-supervised learning solely on final graph representations. To addressthese issues, we introduce \emph{GenHopNet}, a GNN framework that integrates a$k$-hop message-passing scheme, enhancing its ability to capture localstructural information without explicit substructure extraction. Wetheoretically demonstrate that \emph{GenHopNet} surpasses the expressiveness ofthe classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore,we propose a structural- and positional-aware GSSL framework that incorporatestopological information throughout the learning process. This approach enablesthe learning of representations that are both sensitive to graph topology andinvariant to specific structural and feature augmentations. Comprehensiveexperiments on graph classification datasets, including those designed to teststructural sensitivity, show that our method consistently outperforms theexisting approaches and maintains computational efficiency. Our worksignificantly advances GSSL's capability in distinguishing graphs with similarlocal structures but different global topologies.</description>
      <author>example@mail.com (Asiri Wijesinghe, Hao Zhu, Piotr Koniusz)</author>
      <guid isPermaLink="false">2502.16233v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>COMPASS: Cross-embodiment Mobility Policy via Residual RL and Skill Synthesis</title>
      <link>http://arxiv.org/abs/2502.16372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的工作流程COMPASS，旨在开发跨机器人形态的移动策略，通过结合模仿学习（IL）、残差强化学习（RL）和策略蒸馏的方法来克服现有方法在面对新硬件平台或不同环境时所面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着机器人应用领域的扩展，通用且可应用于多种物理形态的移动策略变得日益重要。传统的移动栈虽然在特定平台上有效，但在新的机器人形态上难以大规模部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够解决现有方法中普遍存在的协变量偏移、稀疏采样和环境适应性问题的工作流程，实现高效的跨身体形式（embodiment）的移动策略开发。&lt;h4&gt;方法&lt;/h4&gt;通过模仿学习在移动机器人上训练基础模型，结合世界模型与移动策略；使用残差强化学习进一步微调特定身体形态的策略，并利用预训练表示提高采样效率以处理各种物理约束和传感器模式；最后通过策略蒸馏将这些专家策略合并为单一稳健的跨身形态策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，COMPASS能够有效扩展至不同的机器人平台，在适应不同环境配置的同时保持高成功率（相较于预训练模仿学习策略高出约5倍）。&lt;h4&gt;结论&lt;/h4&gt;提出的框架提供了高效且可扩展的方法来实现跨身体形式的移动策略，使具有不同设计的机器人能够在复杂场景中安全有效地导航。&lt;h4&gt;翻译&lt;/h4&gt;随着机器人的广泛应用领域越来越多，通用化的跨形态机动性策略变得越来越重要。经典机动栈在特定平台上已经证明是有效的，但在新的实体上进行规模化部署存在挑战。基于学习的方法（如模仿学习和强化学习）提供了解决方案，但它们也面临协变量漂移、大型环境中的稀疏采样以及实体特异性约束的问题。本文介绍了COMPASS，这是一个通过结合模仿学习、残差RL和策略蒸馏来开发跨实体机动性策略的新工作流程。我们首先在移动机器人上进行模仿学习，并利用易于访问的教师策略训练一个基础模型，该模型将世界模型与机动策略相结合。在此基础上，我们使用残差RL来微调特定实体上的策略，利用预训练表示提高采样效率，在处理各种物理约束和传感器模式方面更加高效。最后，通过策略蒸馏将这些实体专家策略合并为单一稳健的跨实体策略。实验证明了COMPASS能够有效地在不同的机器人平台上扩展，同时保持对不同环境配置的适应性，实现了一个成功率比预训练模仿学习策略高约5倍的一般策略。该框架提供了一种高效且可扩展的方法来解决跨实体机动问题，使设计不同的机器人能够在复杂场景中安全和有效地导航。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As robots are increasingly deployed in diverse application domains,generalizable cross-embodiment mobility policies are increasingly essential.While classical mobility stacks have proven effective on specific robotplatforms, they pose significant challenges when scaling to new embodiments.Learning-based methods, such as imitation learning (IL) and reinforcementlearning (RL), offer alternative solutions but suffer from covariate shift,sparse sampling in large environments, and embodiment-specific constraints.  This paper introduces COMPASS, a novel workflow for developingcross-embodiment mobility policies by integrating IL, residual RL, and policydistillation. We begin with IL on a mobile robot, leveraging easily accessibleteacher policies to train a foundational model that combines a world model witha mobility policy. Building on this base, we employ residual RL to fine-tuneembodiment-specific policies, exploiting pre-trained representations to improvesampling efficiency in handling various physical constraints and sensormodalities. Finally, policy distillation merges these embodiment-specialistpolicies into a single robust cross-embodiment policy.  We empirically demonstrate that COMPASS scales effectively across diverserobot platforms while maintaining adaptability to various environmentconfigurations, achieving a generalist policy with a success rate approximately5X higher than the pre-trained IL policy. The resulting framework offers anefficient, scalable solution for cross-embodiment mobility, enabling robotswith different designs to navigate safely and efficiently in complex scenarios.</description>
      <author>example@mail.com (Wei Liu, Huihua Zhao, Chenran Li, Joydeep Biswas, Soha Pouya, Yan Chang)</author>
      <guid isPermaLink="false">2502.16372v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Robust Dynamic Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2502.16129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Robust Dynamic Facial Expression Recognition (RDFER)的新方法，该方法旨在解决动态面部表情识别中的硬样本和噪声样本共存的问题。&lt;h4&gt;背景&lt;/h4&gt;目前关于动态面部表情识别的研究主要集中在学习在有噪音或难以处理的数据下的表示形式上，但如何同时处理这两种类型的数据仍然是一个未解之谜。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有问题并提高模型的鲁棒性，该研究设计了一个能够区分硬样本和噪声样本的方法，并提出了一种关键表情重采样框架以及双重流分层网络来增强模型对主要表达的理解能力。&lt;h4&gt;方法&lt;/h4&gt;通过评估模型在不同视频片段上的预测一致性来识别硬样本和噪声样本。采用关键表情重新采样的框架来减少非目标表情带来的干扰，同时使用双序列模型分离短期面部运动与长期情绪变化。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在DFEW和FERV39K等基准数据集上进行了广泛的实验，并证明了其优于现有的最先进的动态面部表情识别方法。&lt;h4&gt;结论&lt;/h4&gt;该工作对于促进动态面部表情识别领域的进一步发展具有重要意义，特别是在噪声一致的鲁棒学习方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：动态面部表情识别（DFER）的研究是一个新兴领域，涉及视频数据中自动识别面部表情。尽管现有研究主要集中在处理噪音和难以处理样本的学习表示上，但如何同时解决这两种类型的问题仍然没有得到很好的解决。为了克服这一挑战，本文提出了一种区分硬样本和噪声样本的稳健方法。通过评估模型在不同采样片段上的预测一致性来实现这一点，并随后采用强化学习难例和削弱噪声影响的方法。此外，为识别视频中的主要表情并增强模型表示学习的能力，提出了关键表情重采样的框架以及双流分层网络，即鲁棒动态面部表情识别（RDFER）。该方法通过在DFEW和FERV39K等基准数据集上的广泛实验展示出优于现有最先进的DFER方法的表现。综合分析提供了关于所提一致性的有价值见解与观察结果。这项工作对动态面部表情识别领域具有重要意义，并促进了噪声一致性鲁棒学习领域的进一步发展。代码可以从[https://github.com/Cross-Innovation-Lab/RDFER]获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of Dynamic Facial Expression Recognition (DFER) is a nascent fieldof research that involves the automated recognition of facial expressions invideo data. Although existing research has primarily focused on learningrepresentations under noisy and hard samples, the issue of the coexistence ofboth types of samples remains unresolved. In order to overcome this challenge,this paper proposes a robust method of distinguishing between hard and noisysamples. This is achieved by evaluating the prediction agreement of the modelon different sampled clips of the video. Subsequently, methodologies thatreinforce the learning of hard samples and mitigate the impact of noisy samplescan be employed. Moreover, to identify the principal expression in a video andenhance the model's capacity for representation learning, comprising a keyexpression re-sampling framework and a dual-stream hierarchical network isproposed, namely Robust Dynamic Facial Expression Recognition (RDFER). The keyexpression re-sampling framework is designed to identify the key expression,thereby mitigating the potential confusion caused by non-target expressions.RDFER employs two sequence models with the objective of disentanglingshort-term facial movements and long-term emotional changes. The proposedmethod has been shown to outperform current State-Of-The-Art approaches in DFERthrough extensive experimentation on benchmark datasets such as DFEW andFERV39K. A comprehensive analysis provides valuable insights and observationsregarding the proposed agreement. This work has significant implications forthe field of dynamic facial expression recognition and promotes the furtherdevelopment of the field of noise-consistent robust learning in dynamic facialexpression recognition. The code is available from[https://github.com/Cross-Innovation-Lab/RDFER].</description>
      <author>example@mail.com (Feng Liu, Hanyang Wang, Siyuan Shen)</author>
      <guid isPermaLink="false">2502.16129v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Asteroid shape inversion with light curves using deep learning</title>
      <link>http://arxiv.org/abs/2502.16455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;小行星形状反演利用光度数据一直是行星科学和天文研究的关键领域，但现有方法需要大量的迭代计算，使过程耗时且容易陷入局部最优解。我们直接通过深度神经网络建立了光度数据与形状分布之间的映射关系，并使用3D点云表示小行星的形状。&lt;h4&gt;背景&lt;/h4&gt;利用光度数据进行小行星形状反演是天文研究中的一个重要课题。然而，现有的方法需要大量的迭代计算过程耗时且容易陷入局部最优解。&lt;h4&gt;目的&lt;/h4&gt;通过深度学习建立光度数据与小行星形状分布之间的直接映射关系，并开发一种预测非凸小行星凹陷区域的新方法。&lt;h4&gt;方法&lt;/h4&gt;采用3D点云表示小行星的形状，利用非凸小行星光线曲线与其凸包之间的偏差来预测非凸小行星上的凹陷区域。使用Chamfer距离评估传统方法与新方法的结果，并利用Lowell天文台观测数据验证该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用深度学习技术，我们能够更有效地反演小行星的形状，特别是在处理特殊形状时表现更好。对于凸包上凹陷区域的检测，预测结果的IoU达到0.89，表明了方法的高度准确性。&lt;h4&gt;结论&lt;/h4&gt;实验结果显示该方法具有很强的鲁棒性和适应性，并且优于传统的光度曲线拟合方法。&lt;h4&gt;翻译&lt;/h4&gt;使用基于深度学习的方法进行小行星形状反演的研究。这种方法通过直接映射关系减少了计算时间和局部最优的问题，提高了处理非凸小行星时的效果和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Asteroid shape inversion using photometric data has been a key area of studyin planetary science and astronomical research.However, the current methods forasteroid shape inversion require extensive iterative calculations, making theprocess time-consuming and prone to becoming stuck in local optima. We directlyestablished a mapping between photometric data and shape distribution throughdeep neural networks. In addition, we used 3D point clouds to representasteroid shapes and utilized the deviation between the light curves ofnon-convex asteroids and their convex hulls to predict the concave areas ofnon-convex asteroids. We compared the results of different shape models usingthe Chamfer distance between traditional methods and ours and found that ourmethod performs better, especially when handling special shapes. For thedetection of concave areas on the convex hull, the intersection over union(IoU) of our predictions reached 0.89. We further validated this method usingobservational data from the Lowell Observatory to predict the convex shapes ofthe asteroids 3337 Milo and 1289 Kuta, and conducted light curve fittingexperiments. The experimental results demonstrated the robustness andadaptability of the method</description>
      <author>example@mail.com (YiJun Tang, ChenChen Ying, ChengZhe Xia, XiaoMing Zhang, XiaoJun Jiang)</author>
      <guid isPermaLink="false">2502.16455v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Interpreting core forms of urban morphology linked to urban functions with explainable graph neural network</title>
      <link>http://arxiv.org/abs/2502.16210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了核心城市形态表示的概念，发展了一种可解释的深度学习框架，用于将复杂的都市形式解析为一种新的表示（CoMo），从而揭示了都市功能与形态之间的联系。&lt;h4&gt;背景&lt;/h4&gt;理解城市的高阶关系对于可持续城市发展至关重要。然而，准确地描述复杂的城市形式并使其易于人类理解是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;提出核心城市形态表示的概念，并开发可解释的深度学习框架将复杂的都市形式解析为新的表示（CoMo）。&lt;h4&gt;方法&lt;/h4&gt;利用一个稳定的加权F1分数为89.14%的经过训练的深度学习模型进行解释，以揭示基于核心城市形态表示的城市功能与形态之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;['波士顿的研究显示，在个人建筑、街区和社区层面上的核心城市形式对相应城市功能非常重要。', '住宅核心形式沿都市脊线呈现出渐进的形态模式，并且这种模式与从市中心到郊区的过渡一致。', '城市形态直接影响土地使用效率，二者具有显著的相关性（R2=0.721, p&lt;0.001）']&lt;h4&gt;结论&lt;/h4&gt;CoMo能够可解释地表示都市形式，提供经典城市位置理论的支持，并为数字孪生体提供了机制见解。&lt;h4&gt;翻译&lt;/h4&gt;理解城市形态与功能之间的高阶关系对于建模可持续城市的内在机制至关重要。然而，准确描述复杂的城市形式并使其易于人类理解是一项挑战。本研究提出核心城市形态表示的概念，并开发了一种可解释的深度学习框架，用于将复杂的都市形式解析为新的表示（CoMo）。通过解释经过良好训练的深度学习模型（稳定的加权F1分数89.14%），CoMo为揭示基于核心城市形态表示的城市功能与形态之间的联系提供了一个有希望的方法。以波士顿作为研究区域，分析了个人建筑、街区和社区层面的核心城市形式对相应城市功能的重要性。住宅核心形式沿都市脊线呈现出渐进的形态模式，并且这种模式与从市中心到郊区的过渡一致。此外，研究表明城市形态直接影响土地使用效率，并具有显著的相关性（R2=0.721, p&lt;0.001）。总的来说，CoMo能够可解释地表示都市形式，提供经典城市位置理论的支持，并为数字孪生体提供了机制见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the high-order relationship between urban form and function isessential for modeling the underlying mechanisms of sustainable urban systems.Nevertheless, it is challenging to establish an accurate data representationfor complex urban forms that are readily explicable in human terms. This studyproposed the concept of core urban morphology representation and developed anexplainable deep learning framework for explicably symbolizing complex urbanforms into the novel representation, which we call CoMo. By interpretating thewell-trained deep learning model with a stable weighted F1-score of 89.14%,CoMo presents a promising approach for revealing links between urban functionand urban form in terms of core urban morphology representation. Using Bostonas a study area, we analyzed the core urban forms at the individual-building,block, and neighborhood level that are important to corresponding urbanfunctions. The residential core forms follow a gradual morphological patternalong the urban spine, which is consistent with a center-urban-suburbantransition. Furthermore, we prove that urban morphology directly affects landuse efficiency, which has a significantly strong correlation with the location(R2=0.721, p&lt;0.001). Overall, CoMo can explicably symbolize urban forms,provide evidence for the classic urban location theory, and offer mechanisticinsights for digital twins.</description>
      <author>example@mail.com (Dongsheng Chen, Yu Feng, Xun Li, Mingya Qu, Peng Luo, Liqiu Meng)</author>
      <guid isPermaLink="false">2502.16210v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Weather Station Data and Radar for Precipitation Nowcasting: SmaAt-fUsion and SmaAt-Krige-GNet</title>
      <link>http://arxiv.org/abs/2502.16116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了两种新的深度学习架构，旨在通过整合多变量气象站数据和雷达数据来提高降水短时预报的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于数据驱动和深度学习的方法在降水短时预报中引起了广泛关注，并取得了显著成果。然而，许多现有的模型未能充分利用广泛可用的大气信息，主要依赖于降水量数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入新的深度学习架构来改善降水短时预报的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了两种新型深度学习架构：SmaAt-fUsion 和 SmaAt-Krige-GNet。SmaAt-fUsion 扩展了 SmaAt-UNet 架构，通过卷积层将气象站数据整合到网络瓶颈部分。而 SmaAt-Krige-GNet 结合了降水图与使用 Kriging 方法处理的气象站数据，生成特定变量的地图，并在基于 SmaAt-GNet 的双编码器架构中利用这些地图进行多级数据集成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在低降水量场景下，SmaAt-Krige-GNet 比仅依赖降水雷达数据的标准 SmaAt-UNet 表现更好；而在低和高降水量场景下，SmaAt-fUsion 超过了 SmaAt-UNet。&lt;h4&gt;结论&lt;/h4&gt;本研究强调了将离散的气象站数据整合到深度学习天气短时预报模型中以提高性能的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经涵盖了上述各个要点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, data-driven, deep learning-based approaches forprecipitation nowcasting have attracted significant attention, showingpromising results. However, many existing models fail to fully exploit theextensive atmospheric information available, relying primarily on precipitationdata alone. This study introduces two novel deep learning architectures,SmaAt-fUsion and SmaAt-Krige-GNet, specifically designed to enhanceprecipitation nowcasting by integrating multi-variable weather station datawith radar datasets. By leveraging additional meteorological information, thesemodels improve representation learning in the latent space, resulting inenhanced nowcasting performance. The SmaAt-fUsion model extends the SmaAt-UNetframework by incorporating weather station data through a convolutional layer,integrating it into the bottleneck of the network. Conversely, theSmaAt-Krige-GNet model combines precipitation maps with weather station dataprocessed using Kriging, a geo-statistical interpolation method, to generatevariable-specific maps. These maps are then utilized in a dual-encoderarchitecture based on SmaAt-GNet, allowing multi-level data integration.Experimental evaluations were conducted using four years (2016--2019) ofweather station and precipitation radar data from the Netherlands. Resultsdemonstrate that SmaAt-Krige-GNet outperforms the standard SmaAt-UNet, whichrelies solely on precipitation radar data, in low precipitation scenarios,while SmaAt-fUsion surpasses SmaAt-UNet in both low and high precipitationscenarios. This highlights the potential of incorporating discrete weatherstation data to enhance the performance of deep learning-based weathernowcasting models.</description>
      <author>example@mail.com (Aleksej Cornelissen, Jie Shi, Siamak Mehrkanoon)</author>
      <guid isPermaLink="false">2502.16116v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Ultra fast, event-by-event heavy-ion simulations for next generation experiments</title>
      <link>http://arxiv.org/abs/2502.16330v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型深度生成框架，利用概率扩散模型进行重离子碰撞事件级别的快速模拟。&lt;h4&gt;背景&lt;/h4&gt;当前的物理实验中，对重离子碰撞数据的模拟是一项耗时的任务。传统方法难以满足大规模和高精度需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效、精准地模拟重离子碰撞输出的新框架。&lt;h4&gt;方法&lt;/h4&gt;该框架基于概率扩散模型，结合归一化流条件生成器和粒子点云合成模块，从UrQMD级联数据中学习并生成包含26种不同介子物种的完整碰撞事件输出。&lt;h4&gt;主要发现&lt;/h4&gt;提出的条件点云扩散模型能够产生逼真的重离子碰撞结果，成功再现了UrQMD分布中的多重性、动量和快度特性。&lt;h4&gt;结论&lt;/h4&gt;该框架不仅在质量和速度上优于现有方法，还为逆向问题求解和参数估计提供了便利，并且可以轻松适应加速任何事件级别的模型计算或探测器模拟任务。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新颖的深度生成框架，利用概率扩散模型进行超快速、逐事件重离子碰撞输出模拟。此新框架基于UrQMD级联数据训练，以生成包含26个不同介子物种的完整碰撞事件输出。每个点由粒子动量向量及其对应种类信息（ID）定义。架构中整合了基于归一化流的条件生成器，将全局事件特征编码为潜在矢量，并利用扩散模型根据此条件合成粒子点云。详细描述了模型及深入分析其性能。有条件点云扩散模型学习产生真实碰撞事件输出的颗粒物，成功再现了UrQMD分布中的多重性、动量和快度特性。灵活的点云表示方法保留了完整的事件级粒度，直接应用于逆向问题求解和参数估计任务，并且易于适应加速任何逐事件模型计算或探测器模拟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel deep generative framework that uses probabilisticdiffusion models for ultra fast, event-by-event simulations of heavy-ioncollision output. This new framework is trained on UrQMD cascade data togenerate a full collision event output containing 26 distinct hadron species.The output is represented as a point cloud, where each point is defined by aparticle's momentum vector and its corresponding species information (ID). Ourarchitecture integrates a normalizing flow-based condition generator thatencodes global event features into a latent vector, and a diffusion model thatsynthesizes a point cloud of particles based on this condition. A detaileddescription of the model and an in-depth analysis of its performance isprovided. The conditional point cloud diffusion model learns to generaterealistic output particles of collision events which successfully reproduce theUrQMD distributions for multiplicity, momentum and rapidity of each hadrontype. The flexible point cloud representation of the event output preservesfull event-level granularity, enabling direct application to inverse problemsand parameter estimation tasks while also making it easily adaptable foraccelerating any event-by-event model calculation or detector simulation.</description>
      <author>example@mail.com (Manjunath Omana Kuttan, Kai Zhou, Jan Steinheimer, Horst Stoecker)</author>
      <guid isPermaLink="false">2502.16330v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Multimodal Imbalance Learning</title>
      <link>http://arxiv.org/abs/2502.10816v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个全面评估多模态不平衡算法的基准测试平台BalanceBenchmark，包括多个常用的数据集和评价指标，并开发了一个标准化实验流程的工具包。&lt;h4&gt;背景&lt;/h4&gt;多模态学习通过整合不同模态的信息得到了广泛关注。然而，该领域常受到模态失衡问题的影响，即某些模态过于主导而其他模态被利用不足。&lt;h4&gt;目的&lt;/h4&gt;系统分类主流多模态不平衡算法，并提供一个全面的评估方法以促进研究的发展。&lt;h4&gt;方法&lt;/h4&gt;引入BalanceBenchmark基准测试平台和标准化实验流程工具包，通过多个数据集从性能、失衡程度及复杂性三个角度进行综合评价。&lt;h4&gt;主要发现&lt;/h4&gt;基于实验结果，识别出不同方法在性能、平衡度以及计算复杂性方面的特征与优势。&lt;h4&gt;结论&lt;/h4&gt;此分析有望激发未来研究中更有效的不平衡问题解决方案，并可能影响基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其整合多种信息模态的能力而备受关注。然而，它常因模态失衡问题受到限制，即某些模态主导其他未充分利用的模态。尽管最近的研究提出了各种方法来缓解该问题，但缺乏全面且公平的比较。本文将主流的多模态不平衡算法基于其减轻不平衡的方法分为四大类，并引入BalanceBenchmark基准测试平台以促进综合评估。为确保公平比较，开发了标准化实验流程工具包。通过使用BalanceBenchmark进行实验，识别出不同方法组在性能、平衡度和计算复杂性方面的特征与优势。我们期待这种分析能够启发未来更高效地解决不平衡问题的方法，并可能影响基础模型的发展。工具代码可在https://github.com/GeWu-Lab/BalanceBenchmark获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gewu-lab/balancebenchmark&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, Di Hu)</author>
      <guid isPermaLink="false">2502.10816v3</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Co-evolution-based Metal-binding Residue Prediction with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.16189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为MBGNN的金属结合预测模型，该模型利用共进化残基网络并使用图神经网络来捕捉蛋白质结构中的复杂依赖关系。&lt;h4&gt;背景&lt;/h4&gt;预测金属结合位点及其对应的金属类型在计算结构生物学中具有挑战性，因为涉及到蛋白质结构和相互作用的复杂性。传统的方法无法有效捕获驱动这些相互作用的复杂进化关系，而基于共进化的最近方法没有充分考虑整个共进化残基网络。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的预测模型MBGNN，以改进金属结合位点及其相关金属类型的预测性能。&lt;h4&gt;方法&lt;/h4&gt;MBGNN利用完整的共进化残基网络并通过图神经网络有效捕捉蛋白质结构中的复杂依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MBGNN在公共数据集上的表现优于现有的基于共进化的金属结合预测方法，并且在序列基础上的方法中具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;该模型展示了将共进化见解与高级机器学习技术相结合的潜力，有助于深入理解蛋白质-金属相互作用。MBGNN的代码可在GitHub上公开获得。&lt;h4&gt;翻译&lt;/h4&gt;在计算结构生物学领域，由于蛋白质结构和相互作用的复杂性，预测金属结合位点及其对应的金属类型极具挑战性。传统基于序列和结构的方法无法有效捕捉这些交互背后的复杂进化关系以促进理解，而最近基于共进化的技术未能充分考虑整个共进化残基网络的结构。本文提出了一种名为MBGNN（Metal-Binding Graph Neural Network）的新方法，该模型利用了完整的共进化残基网络并通过图神经网络有效地捕获蛋白质结构中的复杂依赖关系，以提高共进化金属结合位点及其相关金属类型的预测能力。公共数据集上的实验结果表明，MBGNN在基于共进化的金属结合预测方法中表现出色，并且也与最近的序列基础方法相媲美，展示了将共进化见解与高级机器学习相结合的潜力，有助于深入了解蛋白质-金属相互作用。MBGNN代码可以在https://github.com/SRastegari/MBGNN上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In computational structural biology, predicting metal-binding sites and theircorresponding metal types is challenging due to the complexity of proteinstructures and interactions. Conventional sequence- and structure-basedprediction approaches cannot capture the complex evolutionary relationshipsdriving these interactions to facilitate understanding, while recentco-evolution-based approaches do not fully consider the entire structure of theco-evolved residue network. In this paper, we introduce MBGNN (Metal-BindingGraph Neural Network) that utilizes the entire co-evolved residue network andeffectively captures the complex dependencies within protein structures viagraph neural networks to enhance the prediction of co-evolved metal-bindingresidues and their associated metal types. Experimental results on a publicdataset show that MBGNN outperforms existing co-evolution-based metal-bindingprediction methods, and it is also competitive against recent sequence-basedmethods, showing the potential of integrating co-evolutionary insights withadvanced machine learning to deepen our understanding of protein-metalinteractions. The MBGNN code is publicly available athttps://github.com/SRastegari/MBGNN.</description>
      <author>example@mail.com (Sayedmohammadreza Rastegari, Sina Tabakhi, Xianyuan Liu, Wei Sang, Haiping Lu)</author>
      <guid isPermaLink="false">2502.16189v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Supermarket-6DoF: A Real-World Grasping Dataset and Grasp Pose Representation Analysis</title>
      <link>http://arxiv.org/abs/2502.16311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究名称': 'Supermarket-6DoF', '数据规模': '包含1500次抓取尝试，涉及20种超市物品', '特点': '提供真实机器人执行的地面实况抓取结果，并且包含完全的6自由度抓取姿势注释，包括初始抓取成功和被抓取后受到外部扰动的稳定性', '用途': '用于分析三种抓取姿态表示方法对点云中抓取成功的预测准确性'}&lt;h4&gt;背景&lt;/h4&gt;现有的大多数抓取数据集依赖于解析指标或模拟进行抓取标注。相比之下，Supermarket-6DoF提供了物理机器人执行的真实地面实况结果&lt;h4&gt;目的&lt;/h4&gt;展示一个真实的超市物品抓取数据集，并验证其在基于点云的抓取姿态表示中的价值和准确性&lt;h4&gt;方法&lt;/h4&gt;通过分析三种不同的抓取姿态表示来预测抓取成功的准确度，比较了显式表达夹爪几何形状的点云表示与传统的四元数编码的表现&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，将夹爪几何结构作为点云明确表示的方法比传统基于四元数的姿态表示方法在抓取成功率预测中更加精确&lt;h4&gt;结论&lt;/h4&gt;Supermarket-6DoF数据集为研究真实环境中的机器人手部操作提供了一个宝贵的资源，并且证明了使用点云来表达夹爪姿态的有效性&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Supermarket-6DoF, a real-world dataset of 1500 grasp attemptsacross 20 supermarket objects with publicly available 3D models. Unlike mostexisting grasping datasets that rely on analytical metrics or simulation forgrasp labeling, our dataset provides ground-truth outcomes from physical robotexecutions. Among the few real-world grasping datasets, wile more modest insize, Supermarket-6DoF uniquely features full 6-DoF grasp poses annotated withboth initial grasp success and post-grasp stability under externalperturbation. We demonstrate the dataset's utility by analyzing three grasppose representations for grasp success prediction from point clouds. Ourresults show that representing the gripper geometry explicitly as a point cloudachieves higher prediction accuracy compared to conventional quaternion-basedgrasp pose encoding.</description>
      <author>example@mail.com (Jason Toskov, Akansel Cosgun)</author>
      <guid isPermaLink="false">2502.16311v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Advanced Text Analytics -- Graph Neural Network for Fake News Detection in Social Media</title>
      <link>http://arxiv.org/abs/2502.16157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNN）在假新闻检测中通常依赖于辅助的非文本数据，如用户互动历史或内容传播模式。然而这些数据源并不总是可以获取到，限制了方法的有效性和适用性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文提出了一种先进的文本分析图神经网络（ATA-GNN），该模型仅基于文本数据进行操作。&lt;h4&gt;方法&lt;/h4&gt;ATA-GNN采用了创新的主题建模技术来识别每个主题的典型词汇，并通过多维聚类实现对文本内容的全面语义理解。这种多层次的设计使模型能够发现复杂的文本模式，同时将这些模式置于更广泛的语境中以增强其解释能力。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛使用的基准数据集上的大量评估表明，ATA-GNN的表现优于现有的基于GNN的方法，在假新闻检测方面更加可靠和专注于文本信息。&lt;h4&gt;结论&lt;/h4&gt;这项研究证明了在图神经网络架构中整合先进的文本聚类方法具有实现更可靠且以文本为中心的解决方案的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;传统的图神经网络（GNN）通常依赖于辅助非文本数据，如用户互动历史或内容传播模式来进行假新闻检测。然而这些数据源并不总是可得，这限制了现有方法的有效性和应用范围。此外，现有的模型常常难以捕捉到文本信息中的详细且复杂的关系，从而降低其整体准确性。为了应对这一挑战，本文提出了一种先进的文本分析图神经网络（ATA-GNN），该模型仅基于文本数据进行操作，并采用了创新的主题建模技术来识别每个主题的典型词汇。通过多维聚类和多层次设计，实现了对文本内容的全面语义理解及复杂模式的发现，在广泛的基准数据集上，该方法的表现超过了现有的GNN方法，表明在图神经网络架构中结合先进的文本聚类方法可以实现更可靠且以文本为中心的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Graph Neural Network (GNN) approaches for fake news detection(FND) often depend on auxiliary, non-textual data such as user interactionhistories or content dissemination patterns. However, these data sources arenot always accessible, limiting the effectiveness and applicability of suchmethods. Additionally, existing models frequently struggle to capture thedetailed and intricate relationships within textual information, reducing theiroverall accuracy. In order to address these challenges Advanced Text AnalysisGraph Neural Network (ATA-GNN) is proposed in this paper. The proposed model isdesigned to operate solely on textual data. ATA-GNN employs innovative topicmodelling (clustering) techniques to identify typical words for each topic,leveraging multiple clustering dimensions to achieve a comprehensive semanticunderstanding of the text. This multi-layered design enables the model touncover intricate textual patterns while contextualizing them within a broadersemantic framework, significantly enhancing its interpretative capabilities.Extensive evaluations on widely used benchmark datasets demonstrate thatATA-GNN surpasses the performance of current GNN-based FND methods. Thesefindings validate the potential of integrating advanced text clustering withinGNN architectures to achieve more reliable and text-focused detectionsolutions.</description>
      <author>example@mail.com (Anantram Patel, Vijay Kumar Sutrakar)</author>
      <guid isPermaLink="false">2502.16157v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>voc2vec: A Foundation Model for Non-Verbal Vocalization</title>
      <link>http://arxiv.org/abs/2502.16298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;提出了一种新的非言语人类数据基础模型voc2vec，旨在克服现有语音和音频基础模型在处理非语言声音时的不足。&lt;h4&gt;背景信息&lt;/h4&gt;现有的语音基础模型虽然在相关的任务中表现出色，但在处理如婴儿哭泣等非语言音频数据方面存在困难。同样地，传统的音频基础模型虽然能够很好地处理非言语音频，但无法捕捉到人类声音中的细微特征。&lt;h4&gt;研究目的&lt;/h4&gt;旨在克服现有模型的缺点，并提出了一种新的基础模型voc2vec，专门用于处理非言语人类数据。&lt;h4&gt;所用方法&lt;/h4&gt;采用了包含10个数据集、总计约125小时非言语音频的数据集合。这些数据集完全由开源资源构成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，voc2vec在非语言声音分类任务中表现优异，并且超越了传统的语音和音频基础模型以及强大的基准线OpenSmile和emotion2vec。&lt;h4&gt;结论&lt;/h4&gt;据作者所知，voc2vec是首个为发声任务设计的通用表示模型。&lt;h4&gt;翻译&lt;/h4&gt;语音基础模型已经在相关的任务中显示出了非凡的能力。然而，在处理诸如婴儿哭泣等非语言音频数据时，这些模型常常面临困难。这类非语言音频对于各种现实世界的应用至关重要。传统音频基础模型能够很好地处理非言语数据，但无法捕捉到人类声音中的细微特征。本研究旨在克服上述不足，并提出了一种新的基础模型voc2vec，专门设计用于处理非言语人类数据，仅使用开源的非言语音频数据集。实验结果证明，voc2vec在非语言发声分类任务中表现出色，超越了传统的语音和音频基础模型。此外，voc2vec在六个不同的基准测试数据集中也始终优于强大的基准线OpenSmile和emotion2vec。据作者所知，voc2vec是首个为发声任务设计的通用表示模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models have demonstrated exceptional capabilities inspeech-related tasks. Nevertheless, these models often struggle with non-verbalaudio data, such as vocalizations, baby crying, etc., which are critical forvarious real-world applications. Audio foundation models well handle non-speechdata but also fail to capture the nuanced features of non-verbal human sounds.In this work, we aim to overcome the above shortcoming and propose a novelfoundation model, termed voc2vec, specifically designed for non-verbal humandata leveraging exclusively open-source non-verbal audio datasets. We employ acollection of 10 datasets covering around 125 hours of non-verbal audio.Experimental results prove that voc2vec is effective in non-verbal vocalizationclassification, and it outperforms conventional speech and audio foundationmodels. Moreover, voc2vec consistently outperforms strong baselines, namelyOpenSmile and emotion2vec, on six different benchmark datasets. To the best ofthe authors' knowledge, voc2vec is the first universal representation model forvocalization tasks.</description>
      <author>example@mail.com (Alkis Koudounas, Moreno La Quatra, Marco Sabato Siniscalchi, Elena Baralis)</author>
      <guid isPermaLink="false">2502.16298v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Discovery and Deployment of Emergent Robot Swarm Behaviors via Representation Learning and Real2Sim2Real Transfer</title>
      <link>http://arxiv.org/abs/2502.15937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures. To be included in Proc. of the 24th  International Conference on Autonomous Agents and Multiagent Systems (AAMAS  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于自监督表示学习的Real2Sim2Real行为发现方法，该方法可以在仿真环境中自动发现可能的行为模式，并将这些行为直接部署到真实机器人集群中。&lt;h4&gt;背景&lt;/h4&gt;之前的方法依赖于人工反馈或手工设计的行为度量来表征和进化行为，仅限于在模拟环境中发现行为，未考虑将这些新行为部署到实际的机器人集群上。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以自动探索有限能力机器人群体潜在可出现行为集合的方法，并能够直接应用这些行为到真实的机器人集群中。&lt;h4&gt;方法&lt;/h4&gt;结合表示学习和新颖性搜索，在模拟环境中发现可能的行为，同时通过引入群集sim2real迁移的最新工作缩小现实差距，使得所有在仿真中发现的行为可以直接部署到真实机器人上。&lt;h4&gt;主要发现&lt;/h4&gt;提出的自监督表示学习方法优于手工设计的度量标准，能够更准确地表征潜在行为空间，并且可以通过轻量化模拟器实现从模拟直接转移到实际应用。&lt;h4&gt;结论&lt;/h4&gt;通过展示方法的有效性及其实现的可行性，表明这种方法为自动探索机器人集群中可能出现的行为提供了新途径，并可以无缝地部署到真实环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given a swarm of limited-capability robots, we seek to automatically discoverthe set of possible emergent behaviors. Prior approaches to behavior discoveryrely on human feedback or hand-crafted behavior metrics to represent and evolvebehaviors and only discover behaviors in simulation, without testing orconsidering the deployment of these new behaviors on real robot swarms. In thiswork, we present Real2Sim2Real Behavior Discovery via Self-SupervisedRepresentation Learning, which combines representation learning and noveltysearch to discover possible emergent behaviors automatically in simulation andenable direct controller transfer to real robots. First, we evaluate our methodin simulation and show that our proposed self-supervised representationlearning approach outperforms previous hand-crafted metrics by more accuratelyrepresenting the space of possible emergent behaviors. Then, we address thereality gap by incorporating recent work in sim2real transfer for swarms intoour lightweight simulator design, enabling direct robot deployment of allbehaviors discovered in simulation on an open-source and low-cost robotplatform.</description>
      <author>example@mail.com (Connor Mattson, Varun Raveendra, Ricardo Vega, Cameron Nowzari, Daniel S. Drew, Daniel S. Brown)</author>
      <guid isPermaLink="false">2502.15937v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2502.15635v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Conference on 3D Vision (3DV) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了评估端到端的自主驾驶系统，需要一个基于新颖视图合成技术（NVS）的模拟环境来生成逼真的图像和点云。本文介绍了一个新的多车道数据集和基准测试，用于评价现有的NeRF和3DGS方法在真实世界场景中的表现。&lt;h4&gt;背景&lt;/h4&gt;当前的基于场景的NVS数据集中存在缺少与实际捕捉到的真实性和细节的问题，特别是针对跨车道的评估场景仍然不足。&lt;h4&gt;目的&lt;/h4&gt;为了进一步评估现有基于NeRF和3DGS的方法，在逼真的多传感器环境中建立一个可用于自主驾驶系统性能测试的数据集。&lt;h4&gt;方法&lt;/h4&gt;开发了一个包含25组关联序列的多车道数据集，这些序列由实际世界扫描生成，包括16,000张前视图图像、64,000张环视图像和16,000帧LiDAR点云。所有帧都进行了标注以区分移动物体与静止元素。&lt;h4&gt;主要发现&lt;/h4&gt;通过该数据集可以对现有方法在不同车道和距离下的测试场景中进行性能评估，并解决了多传感器姿态求解及质量评价的问题，从而实现了跨模态数据的对齐。&lt;h4&gt;结论&lt;/h4&gt;计划持续添加新的序列以测试现有方法在各种情况下的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;为了评估端到端自主驾驶系统的性能，基于新颖视图合成技术（NVS）创建一个模拟环境是必要的，它可以从先前记录的序列中生成逼真的图像和点云，特别是在跨车道场景下。因此，开发一个多车道数据集和基准测试是必不可少的。尽管最近的一些基于合成场景的NVS数据集已经为跨车道基准测试做好了准备，但它们仍然缺乏真实捕捉到的图像和点云的真实感。为了进一步评估现有的基于NeRF和3DGS方法的性能，我们提出了第一个注册平行扫描的多车道数据集，特别针对新型驾驶视图合成的数据集，该数据集由实际世界扫描衍生而来，包含25组相关序列，包括16,000张前视图像、64,000张环绕视图图像和16,000帧LiDAR帧。所有帧都进行了标注以区分移动对象与静态元素。利用这个数据集，在不同的车道和距离下对现有方法在各种测试场景中的性能进行评估。此外，我们的方法提供了求解并评估多模态数据对齐的多传感器姿态质量的问题解决方案，以便策划这样的数据集。我们计划继续添加新的序列以测试现有方法在不同情况下的泛化能力。该数据集已公开发布于项目页面：https://nizqleo.github.io/paralane-dataset/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To evaluate end-to-end autonomous driving systems, a simulation environmentbased on Novel View Synthesis (NVS) techniques is essential, which synthesizesphoto-realistic images and point clouds from previously recorded sequencesunder new vehicle poses, particularly in cross-lane scenarios. Therefore, thedevelopment of a multi-lane dataset and benchmark is necessary. While recentsynthetic scene-based NVS datasets have been prepared for cross-lanebenchmarking, they still lack the realism of captured images and point clouds.To further assess the performance of existing methods based on NeRF and 3DGS,we present the first multi-lane dataset registering parallel scans specificallyfor novel driving view synthesis dataset derived from real-world scans,comprising 25 groups of associated sequences, including 16,000 front-viewimages, 64,000 surround-view images, and 16,000 LiDAR frames. All frames arelabeled to differentiate moving objects from static elements. Using thisdataset, we evaluate the performance of existing approaches in various testingscenarios at different lanes and distances. Additionally, our method providesthe solution for solving and assessing the quality of multi-sensor poses formulti-modal data alignment for curating such a dataset in real-world. We planto continually add new sequences to test the generalization of existing methodsacross different scenarios. The dataset is released publicly at the projectpage: https://nizqleo.github.io/paralane-dataset/.</description>
      <author>example@mail.com (Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang)</author>
      <guid isPermaLink="false">2502.15635v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Model for Lossless Image Compression with Visual Prompts</title>
      <link>http://arxiv.org/abs/2502.16163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大规模语言模型（LLM）进行无损图像压缩的新范式，通过将视觉提示与LLM结合来改进熵编码。&lt;h4&gt;背景&lt;/h4&gt;近年来深度学习在无损图像压缩方面取得了显著进展。随着大型语言模型的出现，初步尝试开始探索如何利用预训练模型中的丰富先验知识来增强无损图像压缩性能，特别是在改进熵模型方面的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服将LLM中嵌入的文字先验信息与无损图像压缩技术有效结合的问题，并挖掘出该方法的潜力，本文提出了一种新的方案。&lt;h4&gt;方法&lt;/h4&gt;首先生成输入图像的一个有损重建版本作为视觉提示，从中提取特征以作为LLM的视觉嵌入。然后将原始图像和这个有损重建版本之间的残差与这些视觉嵌入一起传递给LLM，使LLM能够充当熵模型来预测该残差的概率分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个基准数据集上，本文的方法在无损压缩性能方面达到了当前的最佳水平，并超越了传统的和基于学习的无损图像编码方法。此外，所提出的技术还能方便地扩展到其他领域中的图像（如医学影像和屏幕内容），并显示出出色的效果。&lt;h4&gt;结论&lt;/h4&gt;结果表明LLM对于无损图像压缩具有巨大潜力，并有望激励相关领域的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;最近在深度学习上的进步极大地推动了无损图像压缩技术的发展。随着大规模语言模型的出现，初步尝试开始利用这些预训练模型中的丰富先验知识来改进熵编码，从而增强无损图像压缩性能。然而，在将文本型先前知识与图像无损压缩之间建立联系仍面临挑战。为了应对这一难题并发掘LLM的应用潜能，本文介绍了一种新颖的方法，即通过生成输入图像的有损重建版本作为视觉提示，并从这些提示中提取特征供大型语言模型使用，以此来改进熵编码的过程。研究发现该方法在多个基准数据集上表现出了卓越的压缩效果，超越了传统和基于学习的无损图像编码器。此外，这种方法还可以方便地应用于其他领域的图像（如医学影像和屏幕内容），并取得出色的表现。这些结果凸显了LLM对于无损图像压缩技术的巨大潜力，并有可能激发更多相关方向的研究工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in deep learning have driven significant progress inlossless image compression. With the emergence of Large Language Models (LLMs),preliminary attempts have been made to leverage the extensive prior knowledgeembedded in these pretrained models to enhance lossless image compression,particularly by improving the entropy model. However, a significant challengeremains in bridging the gap between the textual prior knowledge within LLMs andlossless image compression. To tackle this challenge and unlock the potentialof LLMs, this paper introduces a novel paradigm for lossless image compressionthat incorporates LLMs with visual prompts. Specifically, we first generate alossy reconstruction of the input image as visual prompts, from which weextract features to serve as visual embeddings for the LLM. The residualbetween the original image and the lossy reconstruction is then fed into theLLM along with these visual embeddings, enabling the LLM to function as anentropy model to predict the probability distribution of the residual.Extensive experiments on multiple benchmark datasets demonstrate our methodachieves state-of-the-art compression performance, surpassing both traditionaland learning-based lossless image codecs. Furthermore, our approach can beeasily extended to images from other domains, such as medical and screencontent images, achieving impressive performance. These results highlight thepotential of LLMs for lossless image compression and may inspire furtherresearch in related directions.</description>
      <author>example@mail.com (Junhao Du, Chuqin Zhou, Ning Cao, Gang Chen, Yunuo Chen, Zhengxue Cheng, Li Song, Guo Lu, Wenjun Zhang)</author>
      <guid isPermaLink="false">2502.16163v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MedForge: Building Medical Foundation Models Like Open Source Software Development</title>
      <link>http://arxiv.org/abs/2502.16055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了Medical Foundation Models Merging (MedForge)框架，用于促进社区驱动的医疗基础模型开发。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）在医疗领域取得了显著进展。然而，在医疗系统中数据孤岛问题和隐私保护仍然是阻碍安全医学数据共享和跨机构合作的主要障碍。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战并收集和整理可扩展的临床数据集，用于训练强大的基础模型，提出了MedForge框架。&lt;h4&gt;方法&lt;/h4&gt;MedForge通过灵活地合并特定任务的低秩适应（LoRA）模块来提供一种自下而上的模型构建机制。该方法可以同时调整下游任务且保留原始模型参数，并利用异步LoRA模块集成方案逐步增强复合模型在各种临床任务中的综合性能。&lt;h4&gt;主要发现&lt;/h4&gt;MedForge框架展示了其在多个临床数据集（如乳腺癌、肺癌和结肠癌）上的强大性能，这些数据集来自不同机构。研究表明，协作基础模型可以有效并一致地推进多中心临床合作。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了跨医疗机构协同开发医疗基础模型的重要性，并公开发布了相关代码以便其他研究人员使用。&lt;h4&gt;翻译&lt;/h4&gt;在该研究中提出了一种名为Medical Foundation Models Merging (MedForge)的框架，该框架旨在通过灵活合并特定任务的低秩适应（LoRA）模块来促进社区驱动的医学基础模型的发展。此方法能够避免原始患者数据的信息泄露，并解决跨临床机构同步开发模型的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models (FMs) have made significant strides in the healthcaredomain. Yet the data silo challenge and privacy concern remain in healthcaresystems, hindering safe medical data sharing and collaborative modeldevelopment among institutions. The collection and curation of scalableclinical datasets increasingly become the bottleneck for training strong FMs.In this study, we propose Medical Foundation Models Merging (MedForge), acooperative framework enabling a community-driven medical foundation modeldevelopment, meanwhile preventing the information leakage of raw patient dataand mitigating synchronization model development issues across clinicalinstitutions. MedForge offers a bottom-up model construction mechanism byflexibly merging task-specific Low-Rank Adaptation (LoRA) modules, which canadapt to downstream tasks while retaining original model parameters. Through anasynchronous LoRA module integration scheme, the resulting composite model canprogressively enhance its comprehensive performance on various clinical tasks.MedForge shows strong performance on multiple clinical datasets (e.g., breastcancer, lung cancer, and colon cancer) collected from different institutions.Our major findings highlight the value of collaborative foundation models inadvancing multi-center clinical collaboration effectively and cohesively. Ourcode is publicly available at https://github.com/TanZheling/MedForge.</description>
      <author>example@mail.com (Zheling Tan, Kexin Ding, Jin Gao, Mu Zhou, Dimitris Metaxas, Shaoting Zhang, Dequan Wang)</author>
      <guid isPermaLink="false">2502.16055v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>DiffCheck: a Scan-CAD Evaluation Tool for Digital Manufacturing and Assembly Processes in Timber Construction</title>
      <link>http://arxiv.org/abs/2502.15864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Andrea Settimi, Damien Gilliard and Eleni Skevaki contributed equally  to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一款名为diffCheck的软件，该软件使用先进的点云分析技术来比较木质结构的扫描结果与其CAD模型之间的差异。&lt;h4&gt;背景&lt;/h4&gt;在数字木材建造中，由于3D传感器、摄影测量和用户友好的CAD工具易于获得，因此广泛采用扫描技术和点云数据。然而，这些工具通常不用于精度检查，因为标准机械可以提供更高的精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为diffCheck的软件来填补这一空白，以便于实验研究和原型制作中评估精确度和准确性。&lt;h4&gt;方法&lt;/h4&gt;diffCheck是一个用C++/Python编写的软件，集成到了Grasshopper平台。它利用先进的点云分析技术进行精度检查，并且可以与各种木材元件和数字制造方法（如机器人装配、AR辅助木工以及数控机床）兼容。&lt;h4&gt;主要发现&lt;/h4&gt;通过测试不同的木材元素和数字制造方法，diffCheck旨在建立一个用户友好的基准框架，用于评估使用木材组件的数字制造系统。此外，该软件及其源代码可以以开放许可的方式与数字化制造社区分享。&lt;h4&gt;结论&lt;/h4&gt;diffCheck具有在其他材料中找到应用潜力的能力，并且其设计是为了促进更高效的精度和准确性检查。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在数字木材建造中，由于3D传感器、摄影测量和用户友好的CAD工具易于获得，因此广泛采用扫描技术和点云数据。虽然通常不用于准确性的校验，因为标准机械可以提供更高的精确度，但是实验研究和原型制作可以从精度和准确性评估工具中获益。我们介绍了一款名为diffCheck的软件，它使用先进的点云分析技术比较加工木材结构的扫描结果与相应的CAD模型之间的差异，并且能够帮助识别出不一致的地方。经过各种木材元件及如机器人装配、AR辅助木工以及数控机床等数字制造方法的测试后，diffCheck旨在为采用木材组件的数字制造系统建立一个用户友好的基准框架，同时具有在其他材料中找到应用潜力的能力。其源代码和分析数据以开放许可的方式与数字化制造社区共享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In digital timber construction, scanning technologies and point cloud dataare widely used due to the accessibility of affordable 3D sensors,photogrammetry, and user-friendly CAD tools. While typically not employed foraccuracy checks in timber fabrication due to the precision of standardmachinery, experimental research and prototyping with joinery and assembly canbenefit from precision and accuracy evaluation tools.  We introduce diffCheck, a C++/Python software integrated into Grasshopper toaddress this need. It uses advanced point cloud analysis to compare scans offabricated timber structures with their respective CAD models, helping toidentify discrepancies. Tested on various timber elements and digitalfabrication methods like robotic assembly, AR-assisted woodworking, and CNCmachining, diffCheck aims to establish a user-friendly benchmark framework fordigital fabrication systems using timber components, with the potential to findapplications in other materials. Its source code and the analyzed data areopenly shared with the digital fabrication community under a permissivelicense.</description>
      <author>example@mail.com (Andrea Settimi, Damien Gilliard, Eleni Skevaki, Marirena Kladeftira, Julien Gamerro, Stefana Parascho, Yves Weinand)</author>
      <guid isPermaLink="false">2502.15864v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>AutoMedPrompt: A New Framework for Optimizing LLM Medical Prompts Using Textual Gradients</title>
      <link>http://arxiv.org/abs/2502.15944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为AutoMedPrompt的技术，利用文本梯度优化系统提示来提高通用基础模型在医学领域的问题解答能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）已在医疗和知识领域展示了越来越复杂的性能。传统的专家化方法需要对大量数据集进行广泛的微调和训练。然而，最近的提示工程方法展示出不通过微调也能提升一般基础模型的能力，但这些方法在特定子领域的适用性有限。&lt;h4&gt;目的&lt;/h4&gt;探索使用文本梯度来优化系统提示，从而激发医学相关推理，并评估这种方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;利用TextGrad的自动文本差异化技术改进通用基础LLM的表现。测试了开源大型语言模型Llama 3，在MedQA、PubMedQA和特定肾脏病亚专业的NephSAP等多个问答基准上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;与先前的方法相比，使用文本梯度进行提示在开源LLMs上表现更优，并且超越了专有模型如GPT-4、Claude 3 Opus和Med-PaLM 2。AutoMedPrompt在PubMedQA上的准确率为82.6%，超过了此前所有方法的表现。&lt;h4&gt;结论&lt;/h4&gt;文本梯度引导的提示技术展示了其在医学领域问答任务中的显著优势，有望成为未来模型改进的一个方向。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）已经在医疗和其他知识领域展示出越来越高级别的性能。传统的创建专业LLM的方法需要对大量数据集进行广泛的微调和训练。然而，最近的提示工程方法展示了无需微调即可提升通用基础模型的能力的潜力。但是，例如链式思考（CoT）的提示方法可能不适用于所有子专科，并且k-shot方法可能会在上下文中引入无关词汇。我们提出了AutoMedPrompt，该技术探索了利用文本梯度通过优化系统提示来激发医学相关推理的可能性。AutoMedPrompt使用TextGrad的基于文本的自动微分技术提高了一般基础LLMs的能力。我们在开源LLM Llama 3上评估了AutoMedPrompt，在包括MedQA、PubMedQA和特定肾脏病亚专业的NephSAP等多个问答基准中进行了测试。我们的结果表明，使用文本梯度进行提示超越了以往方法在开源LLMs上的表现，并且超过了GPT-4、Claude 3 Opus以及Med-PaLM 2等专有模型的表现。AutoMedPrompt在PubMedQA上达到了新的最先进（SOTA）性能水平，准确率为82.6%，并且在开源模型中为MedQA（77.7%）和NephSAP（63.8%）的问答任务表现也优于先前的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated increasingly sophisticatedperformance in medical and other fields of knowledge. Traditional methods ofcreating specialist LLMs require extensive fine-tuning and training of modelson large datasets. Recently, prompt engineering, instead of fine-tuning, hasshown potential to boost the performance of general foundation models. However,prompting methods such as chain-of-thought (CoT) may not be suitable for allsubspecialty, and k-shot approaches may introduce irrelevant tokens into thecontext space. We present AutoMedPrompt, which explores the use of textualgradients to elicit medically relevant reasoning through system promptoptimization. AutoMedPrompt leverages TextGrad's automatic differentiation viatext to improve the ability of general foundation LLMs. We evaluatedAutoMedPrompt on Llama 3, an open-source LLM, using several QA benchmarks,including MedQA, PubMedQA, and the nephrology subspecialty-specific NephSAP.Our results show that prompting with textual gradients outperforms previousmethods on open-source LLMs and surpasses proprietary models such as GPT-4,Claude 3 Opus, and Med-PaLM 2. AutoMedPrompt sets a new state-of-the-art (SOTA)performance on PubMedQA with an accuracy of 82.6$\%$, while also outperformingprevious prompting strategies on open-sourced models for MedQA (77.7$\%$) andNephSAP (63.8$\%$).</description>
      <author>example@mail.com (Sean Wu, Michael Koo, Fabien Scalzo, Ira Kurtz)</author>
      <guid isPermaLink="false">2502.15944v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors</title>
      <link>http://arxiv.org/abs/2502.14627v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多语言音频文本检索（ML-ATR）方案，通过理论分析和实验验证了现有方法在跨语种实例相似性匹配中的不一致性问题，并提出了改进策略。&lt;h4&gt;背景&lt;/h4&gt;多语言音频文本检索是一个具有挑战性的任务，目标是从数据库中检索音频片段或多种语言的文本。当前的方法存在跨语种实例相似性匹配的不一致问题。&lt;h4&gt;目的&lt;/h4&gt;分析和解决现有ML-ATR方案在不同语言之间匹配上的不一致性，并提出改进措施来提高召回率和一致性。&lt;h4&gt;方法&lt;/h4&gt;通过1-to-k对比学习和音频-英语共锚对比学习，设计了一种新的多语言音频文本检索框架以减少数据分布误差对结果的影响。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，跨语种实例相似性匹配的不一致问题是由于随机采样语言造成的数据分布错误所引起的。新方法在召回率和一致性指标上取得了主流八种语言（包括英语）的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的学习策略来解决多语言音频文本检索中的数据分布问题，该研究为提高跨语言信息检索的精度提供了理论依据和技术支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已经以中文形式给出，无需再次翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/atri-acl/atri-acl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims toretrieve audio clips or multilingual texts from databases. However, existingML-ATR schemes suffer from inconsistencies for instance similarity matchingacross languages. We theoretically analyze the inconsistency in terms of bothmultilingual modal alignment direction error and weight error, and propose thetheoretical weight error upper bound for quantifying the inconsistency. Basedon the analysis of the weight error upper bound, we find that the inconsistencyproblem stems from the data distribution error caused by random sampling oflanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastivelearning and audio-English co-anchor contrastive learning, aiming to mitigatethe negative impact of data distribution error on recall and consistency inML-ATR. Experimental results on the translated AudioCaps and Clotho datasetsshow that our scheme achieves state-of-the-art performance on recall andconsistency metrics for eight mainstream languages, including English. Our codewill be available at https://github.com/ATRI-ACL/ATRI-ACL.</description>
      <author>example@mail.com (Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou)</author>
      <guid isPermaLink="false">2502.14627v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Directional Gradient Projection for Robust Fine-Tuning of Foundation Models</title>
      <link>http://arxiv.org/abs/2502.15895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鲁棒微调的目标是将大规模基础模型适应到下游任务，同时保持其对分布变化的稳健性。现有方法主要集中在基于微调权重和预训练权重之间幅度来约束和投影当前模型向预训练初始化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分层可训练的方法——方向梯度投影（DiGraP），该方法利用梯度的方向信息，以弥合正则化与多目标优化之间的差距，并将其推广到多模态评估设置中鲁棒微调的场景。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种称为Directional Gradient Projection (DiGraP)的新技术，它通过结合从梯度方向获取的信息来连接正则化和多目标优化。该研究不仅在图像分类上展示了其效果，还将其扩展到视觉问答（VQA）等多模态评估设置。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有基准方法相比，DiGraP 在图像分类及具备判别性和生成性骨干的 VQA 任务中均有更好的性能表现，尤其是在分布变化上具有较高的稳健性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法有效地解决了当前鲁棒微调方法中存在的问题，并证明了其在多模态评估设置中的应用潜力。DiGraP 方法展示了其对现有基准方法的优势，在多种任务和设置中均显示出更好的性能，包括改进的分布内泛化能力和分布外稳健性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust fine-tuning aims to adapt large foundation models to downstream taskswhile preserving their robustness to distribution shifts. Existing methodsprimarily focus on constraining and projecting current model towards thepre-trained initialization based on the magnitudes between fine-tuned andpre-trained weights, which often require extensive hyper-parameter tuning andcan sometimes result in underfitting. In this work, we propose DirectionalGradient Projection (DiGraP), a novel layer-wise trainable method thatincorporates directional information from gradients to bridge regularizationand multi-objective optimization. Besides demonstrating our method on imageclassification, as another contribution we generalize this area to themulti-modal evaluation settings for robust fine-tuning. Specifically, we firstbridge the uni-modal and multi-modal gap by performing analysis on ImageClassification reformulated Visual Question Answering (VQA) benchmarks andfurther categorize ten out-of-distribution (OOD) VQA datasets by distributionshift types and degree (i.e. near versus far OOD). Experimental results showthat DiGraP consistently outperforms existing baselines across ImageClassfication and VQA tasks with discriminative and generative backbones,improving both in-distribution (ID) generalization and OOD robustness.</description>
      <author>example@mail.com (Chengyue Huang, Junjiao Tian, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira)</author>
      <guid isPermaLink="false">2502.15895v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Token Adaptation via Side Graph Convolution for Efficient Fine-tuning of 3D Point Cloud Transformers</title>
      <link>http://arxiv.org/abs/2502.14142v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个名为Side Token Adaptation on a neighborhood Graph (STAG)的新PEFT算法，用于提高3D点云变换器的时序和空间效率。&lt;h4&gt;背景&lt;/h4&gt;参数高效的微调（PEFT）技术已成为分析3D点云的一种有前景的方法。然而现有的PEFT方法在减少可调节参数的同时，往往面临高计算成本的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的名为STAG的技术，以同时提高时序和空间效率。&lt;h4&gt;方法&lt;/h4&gt;STAG采用图卷积侧面网络，在冻结的骨干Transformer并行操作中适应令牌以便进行下游任务。通过高效的图卷积、参数共享以及减少梯度计算来显著降低微调的时间和空间成本。&lt;h4&gt;主要发现&lt;/h4&gt;提出的STAG算法能够保持与其他现有方法相当的分类准确性，同时将可调节参数减少到仅0.43M，并且在微调时大大减少了时间和内存消耗。此外，还提出了一个新的基准测试Point Cloud Classification 13 (PCC13)。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证了STAG的有效性，表明它能够显著降低计算成本并保持较高的分类精度。&lt;h4&gt;翻译&lt;/h4&gt;参数高效的微调（PEFT）技术在3D点云分析中崭露头角。尽管现有的PEFT方法试图减少可调节参数的数量，但在细调过程中经常遭受高时间和空间计算成本的问题。本文提出了一种名为Side Token Adaptation on a neighborhood Graph (STAG)的新型PEFT算法以实现卓越的时间和空间效率。STAG采用图卷积侧网络，并行于冻结的骨干Transformer进行操作，以将令牌适应到下游任务中。通过高效的图卷积、参数共享以及减少梯度计算，STAG显著降低了微调过程中的时间和空间成本。此外还介绍了一个新的基准测试Point Cloud Classification 13 (PCC13)，该基准集包括多种公开的3D点云数据集以促进全面评估。使用多个预训练模型和PCC13进行的广泛实验显示了STAG的有效性，特别是保持分类精度与现有方法相当的同时将可调节参数减少到仅0.43M，并且在计算时间和内存消耗方面取得显著降低。代码和基准将在https://github.com/takahikof/STAG提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/takahikof/stag&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient fine-tuning (PEFT) of pre-trained 3D point cloudTransformers has emerged as a promising technique for 3D point cloud analysis.While existing PEFT methods attempt to minimize the number of tunableparameters, they often suffer from high temporal and spatial computationalcosts during fine-tuning. This paper proposes a novel PEFT algorithm calledSide Token Adaptation on a neighborhood Graph (STAG) to achieve superiortemporal and spatial efficiency. STAG employs a graph convolutional sidenetwork operating in parallel with a frozen backbone Transformer to adapttokens to downstream tasks. Through efficient graph convolution, parametersharing, and reduced gradient computation, STAG significantly reduces bothtemporal and spatial costs for fine-tuning. We also present Point CloudClassification 13 (PCC13), a new benchmark comprising diverse publiclyavailable 3D point cloud datasets to facilitate comprehensive evaluation.Extensive experiments using multiple pre-trained models and PCC13 demonstratesthe effectiveness of STAG. Specifically, STAG maintains classification accuracycomparable to existing methods while reducing tunable parameters to only 0.43Mand achieving significant reductions in both computation time and memoryconsumption for fine-tuning. Code and benchmark will be available at:https://github.com/takahikof/STAG.</description>
      <author>example@mail.com (Takahiko Furuya)</author>
      <guid isPermaLink="false">2502.14142v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation</title>
      <link>http://arxiv.org/abs/2502.12490v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to 47th International Conference on Software Engineering  (ICSE 2025), NIER track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于深度学习的代码生成已彻底改变了当今开发人员编写程序的方式。&lt;h4&gt;背景&lt;/h4&gt;现有的代码生成方法要么集中在序列到序列（Sequence-to-Sequence）范式，即以标记序列的形式生成目标代码；要么是序列到树（Sequence-to-Tree）范式，即输出作为动作序列的目标代码。这两个范式的结合尚未被探索过。&lt;h4&gt;目的&lt;/h4&gt;通过比较这两种范式下产生的代码，作者发现了整合两者的潜在价值，并提出了一种名为UniGenCoder的新模型来解决与代码生成相关的任务。&lt;h4&gt;方法&lt;/h4&gt;UniGenCoder包含一个共享编码器、一个带有最小额外参数集的共享解码器以及一个选择器，该选择器动态地为每个实例选择最优范式。在模型训练过程中，作者首先实施多任务学习和蒸馏策略来促进两个范式的知识转移，并利用对比学习方法训练选择器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证明了所提出模型在文本到代码以及代码到代码生成任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的UniGenCoder模型展示了将序列到序列（Sequence-to-Sequence）和序列到树（Sequence-to-Tree）范式结合的潜力，并通过实验证明其优越性。&lt;h4&gt;翻译&lt;/h4&gt;基于深度学习的代码生成已彻底改变了当今开发人员编写程序的方式。现有方法要么集中在序列到序列或序列到树的方法上，这两种方式都存在一定的局限性。为了克服这些限制，作者提出了一种新的模型UniGenCoder，并证明了它在文本到代码和代码到代码任务上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based code generation has completely transformed the waydevelopers write programs today. Existing approaches to code generation havefocused either on the Sequence-to-Sequence paradigm, which generates targetcode as a sequence of tokens, or the Sequence-to-Tree paradigm, which outputscode as a sequence of actions. While these two paradigms are intuitivelycomplementary, their combination has not been previously explored. By comparingthe code generated under these two paradigms, we find that integrating themholds significant potential. In this paper, we propose UniGenCoder forcode-related generation tasks, which consists of a shared encoder, a shareddecoder with a minimal set of additional parameters to unify two paradigms, anda selector that dynamically chooses optimal paradigm for each instance. Also,during the model training, we first perform the multi-task learning anddistillation strategies to facilitate knowledge transfer between two paradigms,and then leverage contrastive learning to train the selector. Experimentalresults on the text-to-code and code-to-code generation tasks demonstrate theeffectiveness of our proposed model. We release our code athttps://github.com/DeepLearnXMU/UniGenCoder.</description>
      <author>example@mail.com (Liangying Shao, Yanfu Yan, Denys Poshyvanyk, Jinsong Su)</author>
      <guid isPermaLink="false">2502.12490v2</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Breast Lump Detection and Localization with a Tactile Glove Using Deep Learning</title>
      <link>http://arxiv.org/abs/2502.15767v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于柔性织物的可穿戴触觉手套，用于通过深度学习技术检测模拟乳房模型内的肿块。&lt;h4&gt;背景&lt;/h4&gt;乳腺癌是女性死亡的主要原因之一。通过触摸检查乳房以早期发现肿瘤至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一种利用深度学习方法来定位乳房内肿块的可穿戴触觉手套。&lt;h4&gt;方法&lt;/h4&gt;该研究使用了定制的硅胶乳房原型（SBPs）以及球形硅胶肿瘤，其中包含不同直径大小的模拟肿块。采用InceptionTime深度学习架构结合迁移学习技术，并收集了10名普通参与者和一位肿瘤-乳腺科医生的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;深度学习模型在判断肿块存在、大小及位置上的准确率分别为82.22%，67.08%和62.63%；同时，该模型对未见过的有经验用户数据的表现也非常好，准确率达到95.01%，88.54%以及82.98%。&lt;h4&gt;结论&lt;/h4&gt;这项技术可以帮助没有经验的人或医疗保健提供者进行更频繁的常规检查，有助于早期发现乳腺癌。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast cancer is the leading cause of mortality among women. Inspection ofbreasts by palpation is the key to early detection. We aim to create a wearabletactile glove that could localize the lump in breasts using deep learning (DL).In this work, we present our flexible fabric-based and soft wearable tactileglove for detecting the lumps within custom-made silicone breast prototypes(SBPs). SBPs are made of soft silicone that imitates the human skin and theinner part of the breast. Ball-shaped silicone tumors of 1.5-, 1.75- and 2.0-cmdiameters are embedded inside to create another set with lumps. Our approach isbased on the InceptionTime DL architecture with transfer learning betweenexperienced and non-experienced users. We collected a dataset from 10 naiveparticipants and one oncologist-mammologist palpating SBPs. We demonstratedthat the DL model can classify lump presence, size and location with anaccuracy of 82.22%, 67.08% and 62.63%, respectively. In addition, we showedthat the model adapted to unseen experienced users with an accuracy of 95.01%,88.54% and 82.98% for lump presence, size and location classification,respectively. This technology can assist inexperienced users or healthcareproviders, thus facilitating more frequent routine checks.</description>
      <author>example@mail.com (Togzhan Syrymova, Amir Yelenov, Karina Burunchina, Nazgul Abulkhanova, Huseyin Atakan Varol, Juan Antonio Corrales Ramon, Zhanat Kappassov)</author>
      <guid isPermaLink="false">2502.15767v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>V-HOP: Visuo-Haptic 6D Object Pose Tracking</title>
      <link>http://arxiv.org/abs/2502.17434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个结合视觉和触觉反馈的新型统一触觉表示法，旨在提高物体姿态估计在现实世界中的性能。&lt;h4&gt;背景&lt;/h4&gt;人类自然地通过视觉和触觉来感知物体，在抓取过程中丢失任何一种感觉都会影响性能。尽管早期研究尝试结合这两种感觉以改善对象姿态估计，但在实际应用中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的统一化表示法以及基于该表示法的新型视觉-触觉变换器模型，旨在提高跨不同夹持器、传感器布局或仿真与现实环境下的物体跟踪性能。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新统一化的触觉表征来处理多个夹持器实现，并在此基础上提出一种新的视觉-触觉转换器基对象姿态追踪器，该追踪器能够无缝集成视觉和触觉输入。&lt;h4&gt;主要发现&lt;/h4&gt;在自定义数据集和Feelsight数据集中验证了该模型的有效性，证明其在挑战序列中表现出显著性能提升。特别是在面对新型夹持方式、物体及传感器类型时，本方法显示出卓越的泛化性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过现实世界实验表明，所提出的方法大大优于现有的视觉跟踪器，并且能够实现精确的操作任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally integrate vision and haptics for robust object perceptionduring manipulation. The loss of either modality significantly degradesperformance. Inspired by this multisensory integration, prior object poseestimation research has attempted to combine visual and haptic/tactilefeedback. Although these works demonstrate improvements in controlledenvironments or synthetic datasets, they often underperform vision-onlyapproaches in real-world settings due to poor generalization across diversegrippers, sensor layouts, or sim-to-real environments. Furthermore, theytypically estimate the object pose for each frame independently, resulting inless coherent tracking over sequences in real-world deployments. To addressthese limitations, we introduce a novel unified haptic representation thateffectively handles multiple gripper embodiments. Building on thisrepresentation, we introduce a new visuo-haptic transformer-based object posetracker that seamlessly integrates visual and haptic input. We validate ourframework in our dataset and the Feelsight dataset, demonstrating significantperformance improvement on challenging sequences. Notably, our method achievessuperior generalization and robustness across novel embodiments, objects, andsensor types (both taxel-based and vision-based tactile sensors). In real-worldexperiments, we demonstrate that our approach outperforms state-of-the-artvisual trackers by a large margin. We further show that we can achieve precisemanipulation tasks by incorporating our real-time object tracking result intomotion plans, underscoring the advantages of visuo-haptic perception. Our modeland dataset will be made open source upon acceptance of the paper. Projectwebsite: https://lhy.xyz/projects/v-hop/</description>
      <author>example@mail.com (Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar)</author>
      <guid isPermaLink="false">2502.17434v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning</title>
      <link>http://arxiv.org/abs/2502.17432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website at https://jasonjzliu.com/factr/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一个低成本且直观的双边遥操作系统，该系统将从动臂接收到的外部力传递给主动臂，促进复杂接触密集任务的数据收集，并引入了一个基于课程学习的策略学习方法FACTR。', '背景': '许多人类操作任务依赖于力反馈以可靠执行，但机器人领域中这种力量信息未得到充分利用，导致机器人行为局限于不需要精细力反馈的任务。', '目的': '开发一种能够利用外部力数据进行复杂接触密集型任务的有效遥操作系统和策略学习方法。', '方法': '首先设计了一种低成本且直观的双边遥操作平台，其次提出了一种名为FACTR的策略学习方法，该方法通过在训练过程中逐渐减少视觉输入的干扰来防止过度拟合，并引导策略关注力模态。', '主要发现': '该研究展示了通过充分使用力信息，与不采用课程学习的基线方法相比，在未见过物体上的泛化性能提高了43%。', '结论': '利用力反馈信息可以显著改善机器人在复杂任务中的表现和适应性。'}&lt;h4&gt;翻译&lt;/h4&gt;许多人类执行的任务，如拾取盒子或擀面团，都依赖于力反馈以确保可靠的完成。然而，在大多数机器人手臂中容易获得的这种力信息并未被广泛用于遥操作和策略学习。因此，机器人的行为通常仅限于不需要复杂力反馈的准静态动力学任务。在这篇论文中，我们首先提出了一种低成本且直观的双边遥操作系统，该系统将从动臂接收到的外部力量传递给主动臂，以促进复杂接触密集型任务的数据收集。接下来，我们介绍了FACTR策略学习方法，该方法在训练过程中采用一种课程，通过逐渐减少视觉输入的干扰来防止基于变压器的政策过度拟合，并引导策略正确关注力模态。我们证明了充分利用力量信息能够显著提高与基线相比，在未见过物体上的泛化性能达43%。视频结果和指南可在https://jasonjzliu.com/factr/获得&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many contact-rich tasks humans perform, such as box pickup or rolling dough,rely on force feedback for reliable execution. However, this force information,which is readily available in most robot arms, is not commonly used inteleoperation and policy learning. Consequently, robot behavior is oftenlimited to quasi-static kinematic tasks that do not require intricateforce-feedback. In this paper, we first present a low-cost, intuitive,bilateral teleoperation setup that relays external forces of the follower armback to the teacher arm, facilitating data collection for complex, contact-richtasks. We then introduce FACTR, a policy learning method that employs acurriculum which corrupts the visual input with decreasing intensity throughouttraining. The curriculum prevents our transformer-based policy fromover-fitting to the visual input and guides the policy to properly attend tothe force modality. We demonstrate that by fully utilizing the forceinformation, our method significantly improves generalization to unseen objectsby 43\% compared to baseline approaches without a curriculum. Video results andinstructions at https://jasonjzliu.com/factr/</description>
      <author>example@mail.com (Jason Jingzhou Liu, Yulong Li, Kenneth Shaw, Tony Tao, Ruslan Salakhutdinov, Deepak Pathak)</author>
      <guid isPermaLink="false">2502.17432v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Enriching Physical-Virtual Interaction in AR Gaming by Tracking Identical Real Objects</title>
      <link>http://arxiv.org/abs/2502.17399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的增强现实(AR)技术，旨在改善同质物体在动态环境中的追踪问题，并通过农场到餐桌的游戏展示了该方法的有效性和实用性。&lt;h4&gt;背景&lt;/h4&gt;随着硬件和软件的进步，头戴式AR游戏变得越来越流行。然而，大多数AR游戏仍然依赖于预先扫描的静态场景，互动方式也有限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决AR游戏中相同物体追踪的问题，并丰富物理与虚拟环境之间的交互体验。&lt;h4&gt;方法&lt;/h4&gt;通过使用AR头盔的部分场景观察数据，结合整数规划解决问题标签分配问题来确定场景中对象的身份，并采用基于Voronoi图的剪枝方法提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够有效地追踪和区分相同的物体，展示了其在增强现实游戏、故事讲述和模拟机器人中的多功能性和实用性。&lt;h4&gt;结论&lt;/h4&gt;新方法证明了其实用性，在农场到餐桌AR游戏中表现良好，并且通过视频演示展现了其潜力。未来的研究可以探索更多实际应用场景来进一步验证该技术的有效性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;增强现实(AR)游戏，尤其是专为头戴设备设计的游戏，随着硬件和软件的进步变得越来越普遍。然而，大多数AR游戏仍然依赖于预扫描或静态场景，并且交互机制通常限制在控制器或手部跟踪上。此外，在AR游戏中存在相同物体的挑战，传统的对象跟踪技术往往难以区分这些物体或者需要安装固定摄像机来追踪全球物体运动。为了解决这些问题，我们提出了一种新的方法，以解决AR场景中相同物体的跟踪问题，从而丰富物理虚拟交互体验。我们的方法利用了AR头盔捕捉的部分场景观察数据，并结合提供的视角和空间信息，通过整数规划解决方案中的标签分配问题确定场景内对象的身份。为了提高计算效率，我们在方法中引入了一种基于Voronoi图的剪枝技术。在农场到餐桌AR游戏中实现该方法展示了其满意的性能和稳健性。此外，我们通过增强现实故事讲述以及模拟游戏机器人的应用展现了该方法的多功能性和实用性。我们的视频演示可在以下链接查看：https://youtu.be/rPGkLYuKvCQ。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Augmented reality (AR) games, particularly those designed for headsets, havebecome increasingly prevalent with advancements in both hardware and software.However, the majority of AR games still rely on pre-scanned or static scenes,and interaction mechanisms are often limited to controllers or hand-tracking.Additionally, the presence of identical objects in AR games poses challengesfor conventional object tracking techniques, which often struggle todifferentiate between identical objects or necessitate the installation offixed cameras for global object movement tracking. In response to theselimitations, we present a novel approach to address the tracking of identicalobjects in an AR scene to enrich physical-virtual interaction. Our methodleverages partial scene observations captured by an AR headset, utilizing theperspective and spatial data provided by this technology. Object identitieswithin the scene are determined through the solution of a label assignmentproblem using integer programming. To enhance computational efficiency, weincorporate a Voronoi diagram-based pruning method into our approach. Ourimplementation of this approach in a farm-to-table AR game demonstrates itssatisfactory performance and robustness. Furthermore, we showcase theversatility and practicality of our method through applications in ARstorytelling and a simulated gaming robot. Our video demo is available at:https://youtu.be/rPGkLYuKvCQ.</description>
      <author>example@mail.com (Liuchuan Yu, Ching-I Huang, Hsueh-Cheng Wang, Lap-Fai Yu)</author>
      <guid isPermaLink="false">2502.17399v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Experimental validation of UAV search and detection system in real wilderness environment</title>
      <link>http://arxiv.org/abs/2502.17372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文研究了在地中海喀斯特环境中利用自主无人机搜索人类的实验设计与实施，以提高搜救任务效率并增强参与人员的安全性。&lt;h4&gt;背景&lt;/h4&gt;搜索和救援任务需要可靠的搜索方法来定位幸存者，尤其是在挑战性强或难以到达的环境中。因此引入无人驾驶飞机可以在提高搜救任务效率的同时增加所有参与者在任务中的安全性。&lt;h4&gt;目的&lt;/h4&gt;设计并实验验证了一种基于热方程驱动区域覆盖（HEDAC）控制方法和计算机视觉对象检测框架的自主无人机搜索系统，并评估其性能是否与实际情况相符。&lt;h4&gt;方法&lt;/h4&gt;该研究通过概率搜索模型、运动控制系统以及计算机视觉目标检测组成的感知框架，使用热方程驱动区域覆盖（HEDAC）控制方法并根据已知的概率密度和检测函数来指导无人飞机。实验中使用了YOLO算法为基础的目标检测模型，并通过先前收集的正射影像数据库进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过对运动控制系统、目标检测以及搜索验证进行了全面分析，表明设计的目标检测模型与实际世界结果相一致，为无人机控制算法提供了强有力的证据支持。&lt;h4&gt;结论&lt;/h4&gt;研究证明了基于HEDAC方法和YOLO算法的自主无人飞机系统在实际搜救任务中的有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Search and rescue (SAR) missions require reliable search methods to locatesurvivors, especially in challenging or inaccessible environments. This is whyintroducing unmanned aerial vehicles (UAVs) can be of great help to enhance theefficiency of SAR missions while simultaneously increasing the safety ofeveryone involved in the mission. Motivated by this, we design and experimentwith autonomous UAV search for humans in a Mediterranean karst environment. TheUAVs are directed using Heat equation-driven area coverage (HEDAC) ergodiccontrol method according to known probability density and detection function.The implemented sensing framework consists of a probabilistic search model,motion control system, and computer vision object detection. It enablescalculation of the probability of the target being detected in the SAR mission,and this paper focuses on experimental validation of proposed probabilisticframework and UAV control. The uniform probability density to ensure the evenprobability of finding the targets in the desired search area is achieved byassigning suitably thought-out tasks to 78 volunteers. The detection model isbased on YOLO and trained with a previously collected ortho-photo imagedatabase. The experimental search is carefully planned and conducted, while asmany parameters as possible are recorded. The thorough analysis consists of themotion control system, object detection, and the search validation. Theassessment of the detection and search performance provides strong indicationthat the designed detection model in the UAV control algorithm is aligned withreal-world results.</description>
      <author>example@mail.com (Stella Dumenčić, Luka Lanča, Karlo Jakac, Stefan Ivić)</author>
      <guid isPermaLink="false">2502.17372v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>HATPIC: An Open-Source Single Axis Haptic Joystick for Robotic Development</title>
      <link>http://arxiv.org/abs/2502.17362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2 pages, 1 figure, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;人类通过触觉处理的信息远超视觉，因此远程操作中的触觉技术将在未来变得至关重要。当前的触觉设备要么难以获取，要么提供的力反馈质量较低，本文提出了一种单轴开源触觉设备设计方案来解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;人的大部分信息处理是依靠触觉完成的，在极端条件下尤其如此，这意味着触觉对于远程操作的重要性将日益增加。&lt;h4&gt;目的&lt;/h4&gt;设计一种易于访问且具有高质量力反馈功能的开源单轴触觉装置以促进远程操作技术的发展和应用。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种新的触觉设备，并展示了其与常见机器人工具集成的可能性。&lt;h4&gt;主要发现&lt;/h4&gt;新设计的手柄式控制器有可能加速各种机器人应用程序中触觉技术的应用，从而提高操作人员的反馈质量和控制水平。&lt;h4&gt;结论&lt;/h4&gt;通过引入这种低成本、高质量力反馈的触觉装置可以极大地促进远程操作技术的发展和广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：人类处理的信息中有相当大的一部分是通过触觉完成的，而不是视觉。因此，在未来几年中，用于远程操控的触觉技术将变得至关重要，因为它为运营商提供了一种额外的感觉通道，这对于在极端条件下进行解释非常重要。然而，目前的触觉设备设置要么难以访问，要么提供的力反馈质量低劣。这项工作提出了一个旨在解决这些问题的单轴、开源的远程操作设计方案。首先介绍了该触觉装置，并展示了其与常见机器人工具集成的可能性。所提出的操纵杆有望加速各种机器人应用中触觉技术的发展和部署，从而增强操作人员的反馈和控制能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans process significantly more information through the sense of touch thanthrough vision. Consequently, haptics for telemanipulation is poised to becomeessential in the coming years, as it offers operators an additional sensorychannel crucial for interpretation in extreme conditions. However, currenthaptic device setups are either difficult to access or provide low-qualityforce feedback rendering. This work proposes the design of a single-axis,open-source setup for telemanipulation development, aimed at addressing theseissues. We first introduce the haptic device and demonstrate its integrationwith common robotic tools. The proposed joystick has the potential toaccelerate the development and deployment of haptic technology in a wide rangeof robotics applications, enhancing operator feedback and control.</description>
      <author>example@mail.com (Julien Mellet, Fabio Ruggiero, Vincenzo Lippiello)</author>
      <guid isPermaLink="false">2502.17362v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>MegaLoc: One Retrieval to Place Them All</title>
      <link>http://arxiv.org/abs/2502.17237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Tech Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MegaLoc的检索模型，该模型结合了多种现有技术，在多个计算机视觉任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;从给定查询获取相同位置的图像对于多项计算机视觉任务至关重要。然而，现有的解决方案仅针对单一任务设计，并且在遇到需求变化或未见数据时可能会失败。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在不同任务和环境要求下均能高效工作的通用检索模型。&lt;h4&gt;方法&lt;/h4&gt;结合了多种现有技术和训练技术来构建MegaLoc模型。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'MegaLoc在大量视觉位置识别数据集上达到最新技术水平，', '2': '在常见的地标检索数据集中表现出色，', '3': '在LaMAR数据集的图像定位任务中引入新方法后，设定了新的性能标准。'}&lt;h4&gt;结论&lt;/h4&gt;MegaLoc展示出了跨多个计算机视觉任务领域的强大适应性和通用性。&lt;h4&gt;翻译&lt;/h4&gt;从给定查询获取相同位置的图像是多项重要视觉任务（如视觉地方识别、地标检索、图像定位、三维重建和SLAM）的关键部分。然而，现有的解决方案通常只为特定任务设计，在遇到需求变化或未见数据时表现不佳。本文通过结合多种现有方法和技术训练出了一种名为MegaLoc的新模型，该模型在多个计算机视觉任务中均表现出色，并且其代码开源可获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieving images from the same location as a given query is an importantcomponent of multiple computer vision tasks, like Visual Place Recognition,Landmark Retrieval, Visual Localization, 3D reconstruction, and SLAM. However,existing solutions are built to specifically work for one of these tasks, andare known to fail when the requirements slightly change or when they meetout-of-distribution data. In this paper we combine a variety of existingmethods, training techniques, and datasets to train a retrieval model, calledMegaLoc, that is performant on multiple tasks. We find that MegaLoc (1)achieves state of the art on a large number of Visual Place Recognitiondatasets, (2) impressive results on common Landmark Retrieval datasets, and (3)sets a new state of the art for Visual Localization on the LaMAR datasets,where we only changed the retrieval method to the existing localizationpipeline. The code for MegaLoc is available athttps://github.com/gmberton/MegaLoc</description>
      <author>example@mail.com (Gabriele Berton, Carlo Masone)</author>
      <guid isPermaLink="false">2502.17237v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SoFFT: Spatial Fourier Transform for Modeling Continuum Soft Robots</title>
      <link>http://arxiv.org/abs/2502.17347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于傅里叶变换的方法，用于紧凑地描述连续软机器人的变形，并通过数值模拟和实验验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;连续软机器人由柔性材料组成，理论上具有无限自由度，在非结构化环境中表现出色的适应能力。Cosserat Rod理论作为建模这些机器人的有效框架已得到广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于信号处理的方法来描述和建模连续软机器人的变形过程。&lt;h4&gt;方法&lt;/h4&gt;将机器人骨架视为时空中的信号，应用傅里叶变换将其变形简化为频域表示。该方法不仅统一了现有建模策略，并提供了实验捕捉机器人变形的基于数据驱动的方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值模拟和现实原型实验验证了所提方法的有效性，表明在减少自由度的同时保持变形准确性的能力。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法为连续软机器人的研究提供了一种有效途径，展示了傅里叶变换用于机器人建模的潜力。&lt;h4&gt;翻译&lt;/h4&gt;连续软机器人由柔性材料组成，在非结构化环境中表现出高度适应性。基于Cosserat Rod理论的应用提出了将机器人骨架视为时空信号的方法，并通过傅里叶变换来描述其变形过程。这种方法不仅统一了现有的建模策略，还提供了一种实验捕捉机器人变形的数据驱动方法。数值模拟和现实原型实验验证了该方法的有效性，在减少自由度的同时保持了变形的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuum soft robots, composed of flexible materials, exhibit theoreticallyinfinite degrees of freedom, enabling notable adaptability in unstructuredenvironments. Cosserat Rod Theory has emerged as a prominent framework formodeling these robots efficiently, representing continuum soft robots astime-varying curves, known as backbones. In this work, we propose viewing therobot's backbone as a signal in space and time, applying the Fourier transformto describe its deformation compactly. This approach unifies existing modelingstrategies within the Cosserat Rod Theory framework, offering insights intocommonly used heuristic methods. Moreover, the Fourier transform enables thedevelopment of a data-driven methodology to experimentally capture the robot'sdeformation. The proposed approach is validated through numerical simulationsand experiments on a real-world prototype, demonstrating a reduction in thedegrees of freedom while preserving the accuracy of the deformationrepresentation.</description>
      <author>example@mail.com (Daniele Caradonna, Diego Bianchi, Franco Angelini, Egidio Falotico)</author>
      <guid isPermaLink="false">2502.17347v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Modeling, Simulation, and Application of Spatio-Temporal Characteristics Detection in Incipient Slip</title>
      <link>http://arxiv.org/abs/2502.17335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，用于检测机器人抓握和操作任务中的初始滑动。该方法通过分析局部位移现象建立了特征应变率极端事件与局部滑动状态之间的关系。&lt;h4&gt;背景&lt;/h4&gt;早期滑动检测对于机器人抓取和操作任务至关重要，但由于物体属性的多样性和复杂的工作条件，保持其适应性仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来完全表示滑动的空间-时间特征，并建立特征应变率极端事件与局部滑动状态之间的关系。&lt;h4&gt;方法&lt;/h4&gt;基于局部位移现象分析建立了特征应变率极端事件和局部滑动状态之间的联系，该方法能检测到粘着-滑动区域的时空分布。同时，这种方法可以应用于基于视觉的触觉传感器等应变分布传感设备。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟和原型实验验证了在不同接触条件下（包括不同的接触几何形状、摩擦系数和组合负载）此方法的有效性。实验表明，该方法不仅能够准确可靠地界定初始滑动，还促进了摩擦参数估计和适应性抓握控制的实现。&lt;h4&gt;结论&lt;/h4&gt;提出的模型及其检测方法具有广泛的适用性和可靠性，在复杂的工作条件下表现出色，并为机器人抓取任务提供了关键反馈。&lt;h4&gt;翻译&lt;/h4&gt;初期滑动检测对于机器人的抓取与操作至关重要。然而，使其在多样的物体特性和复杂的作业环境下保持适应性依然面临挑战。本文重点在于完全表示滑移的时空特性，并提出了一种新的模型来捕捉初期滑动现象及其检测方法。通过对局部位移的研究建立了应变率极端事件和本地化滑动状态之间的联系，该方法可以识别出粘着-滑移区域的空间分布与时间动力学特征，且适用于基于视觉的触觉传感设备等应变分布传感器的应用场景。模拟及原型实验验证了其在不同接触条件下的有效性（比如不同的几何形状、摩擦系数和组合负载），并表明这种新方法不仅能够精确地描绘初期滑动现象，并有助于实现摩擦参数估计与自适应抓取控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incipient slip detection provides critical feedback for robotic grasping andmanipulation tasks. However, maintaining its adaptability under diverse objectproperties and complex working conditions remains challenging. This articlehighlights the importance of completely representing spatio-temporal featuresof slip, and proposes a novel approach for incipient slip modeling anddetection. Based on the analysis of localized displacement phenomenon, weestablish the relationship between the characteristic strain rate extremeevents and the local slip state. This approach enables the detection of boththe spatial distribution and temporal dynamics of stick-slip regions. Also, theproposed method can be applied to strain distribution sensing devices, such asvision-based tactile sensors. Simulations and prototype experiments validatedthe effectiveness of this approach under varying contact conditions, includingdifferent contact geometries, friction coefficients, and combined loads.Experiments demonstrated that this method not only accurately and reliablydelineates incipient slip, but also facilitates friction parameter estimationand adaptive grasping control.</description>
      <author>example@mail.com (Mingxuan Li, Lunwei Zhang, Qiyin Huang, Tiemin Li, Yao Jiang)</author>
      <guid isPermaLink="false">2502.17335v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Computation Offloading Strategies in Integrated Terrestrial and Non-Terrestrial Networks</title>
      <link>http://arxiv.org/abs/2502.15903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted as chapter to Elsevier&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了集成地面和非地面网络（IT-NTNs）在计算密集型应用中的作用，这些应用包括增强现实、自动驾驶、远程医疗和智能城市等。&lt;h4&gt;背景&lt;/h4&gt;传统地面网络由于覆盖不足、容量有限以及偏远地区的高延迟而限制了上述应用的发展。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过集成的地面与非地面网络来应对这些问题，并实现高效的计算卸载。&lt;h4&gt;方法&lt;/h4&gt;首先介绍了移动边缘计算（MEC）及其向多接入边缘计算演化的路径，接着详细探讨了IT-NTNs架构，包括地面基站、无人机、高空平台和低轨卫星如何协同工作以提供无缝连接。文章还分析了几种不同的计算卸载策略，并讨论了关键使能技术。&lt;h4&gt;主要发现&lt;/h4&gt;各种计算卸载方法各有优缺点；关键技术如非正交多址接入（NOMA）、毫米波/太赫兹通信和可重构智能表面等对于现有资源分配、任务卸载决策及移动管理算法至关重要。&lt;h4&gt;结论&lt;/h4&gt;本文强调了计算卸载在IT-NTNs中的变革性影响，展望未来的研究方向，并指出了此类网络在未来重新定义通信与计算范式的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of computation-intensive applications like augmentedreality, autonomous driving, remote healthcare, and smart cities has exposedthe limitations of traditional terrestrial networks, particularly in terms ofinadequate coverage, limited capacity, and high latency in remote areas. Thischapter explores how integrated terrestrial and non-terrestrial networks(IT-NTNs) can address these challenges and enable efficient computationoffloading. We examine mobile edge computing (MEC) and its evolution towardmultiple-access edge computing, highlighting the critical role computationoffloading plays for resource-constrained devices. We then discuss thearchitecture of IT-NTNs, focusing on how terrestrial base stations, unmannedaerial vehicles (UAVs), high-altitude platforms (HAPs), and LEO satellites worktogether to deliver ubiquitous connectivity. Furthermore, we analyze variouscomputation offloading strategies, including edge, cloud, and hybridoffloading, outlining their strengths and weaknesses. Key enabling technologiessuch as NOMA, mmWave/THz communication, and reconfigurable intelligent surfaces(RIS) are also explored as essential components of existing algorithms forresource allocation, task offloading decisions, and mobility management.Finally, we conclude by highlighting the transformative impact of computationoffloading in IT-NTNs across diverse application areas and discuss keychallenges and future research directions, emphasizing the potential of thesenetworks to revolutionize communication and computation paradigms.</description>
      <author>example@mail.com (Muhammad Ahmed Mohsin, Muhammad Umer, Amara Umar, Hatem Abou-Zeid, Syed Ali Hassan)</author>
      <guid isPermaLink="false">2502.15903v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.18032v4</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种名为GraphTeam的多代理系统，用于基于大型语言模型（LLM）进行图分析。&lt;h4&gt;背景&lt;/h4&gt;现有的图数据分析方法要么将图形神经网络与特定机器学习任务相结合，限制了其可移植性；要么仅依赖于LLMs内部推理能力，导致性能不佳。为解决这些问题，本文利用最近关于LLM代理的进展来提高外部知识或工具使用的能力。&lt;h4&gt;目的&lt;/h4&gt;通过模拟人类解决问题策略（如类比和协作），提出一种基于多代理系统的图分析解决方案GraphTeam。&lt;h4&gt;方法&lt;/h4&gt;{'输入-输出标准化模块': '包括问题代理提取并细化四个关键参数，以促进问题理解；答案代理组织结果以满足输出要求。', '外部知识检索模块': '构建了一个包含相关文档和经验信息的知识库，并通过搜索代理为每个问题检索最相关的条目。', '问题解决模块': '编码代理根据从搜索代理获得的信息使用编程生成解决方案，如果编码代理无法工作，则推理代理将直接计算结果。'}&lt;h4&gt;主要发现&lt;/h4&gt;在六个图分析基准上的广泛实验显示，GraphTeam实现了最先进的性能，比最佳基线平均提高了25.85%的准确性。&lt;h4&gt;结论&lt;/h4&gt;GraphTeam通过模拟人类问题解决策略并有效利用外部知识和工具，为复杂图形数据分析任务提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要提供了关于GraphTeam系统的设计细节、模块功能以及实验结果的信息。该研究展示了在图数据处理方面的新进展，并强调了LLM代理协同工作的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bupt-gamma/graphteam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description>
      <author>example@mail.com (Xin Sky Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang)</author>
      <guid isPermaLink="false">2410.18032v4</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control</title>
      <link>http://arxiv.org/abs/2502.17322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SIRL框架，通过模仿任务相关的轨迹来改进强化学习算法在高维空间中的表现。&lt;h4&gt;背景&lt;/h4&gt;复杂高维度的空间对于配备灵巧手的人形机器人等系统来说，在有限样本预算下平衡探索和利用方面对强化学习算法构成了挑战。可行的任务完成区域通常非常狭窄。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习框架，以改善在复杂行动空间中任务表现的问题。&lt;h4&gt;方法&lt;/h4&gt;通过引入自模仿强化学习（SIRL）框架，该框架使RL算法能够模仿潜在任务相关的轨迹，并根据轨迹回报调整行为克隆的权重。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的算法在HumanoidBench上实现了120%的性能提升，同时仅增加了5%的计算开销。进一步的可视化分析表明，这种性能改进确实带来了有意义的行为改善。&lt;h4&gt;结论&lt;/h4&gt;SIRL框架提供了一种有效的方法来增强RL算法处理复杂高维空间任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;复杂的高维度空间（具有大量自由度和复杂行动空间），如装备灵巧手的人形机器人，对强化学习算法构成了重大挑战。这类算法需要在有限的样本预算下巧妙地平衡探索与利用之间的关系。通常情况下，在这种复杂的高维空间中完成任务的有效区域极其狭窄。例如，在人形机器人的运动控制领域，绝大多数的空间都对应于跌倒的状态，而能够执行后续任务的小部分状态则仅占微不足道的比例。一旦机器人进入了潜在的任务相关区域，它应该更加重视该区域内的数据。基于这一见解，我们提出了自模仿强化学习（SIRL）框架，在此框架下RL算法也模仿潜在的任务相关的轨迹。具体来说，使用轨迹回报来确定其任务的相关性，并采用额外的行为克隆方法，权重根据轨迹回报动态调整。结果表明，所提出的算法在具有挑战性的HumanoidBench上实现了120%的性能提升，同时仅增加了5%的计算开销。通过进一步可视化分析发现，显著的性能改进确实导致了有意义的行为改善，成功解决了多个任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex high-dimensional spaces with high Degree-of-Freedom and complicatedaction spaces, such as humanoid robots equipped with dexterous hands, posesignificant challenges for reinforcement learning (RL) algorithms, which needto wisely balance exploration and exploitation under limited sample budgets. Ingeneral, feasible regions for accomplishing tasks within complexhigh-dimensional spaces are exceedingly narrow. For instance, in the context ofhumanoid robot motion control, the vast majority of space corresponds tofalling, while only a minuscule fraction corresponds to standing upright, whichis conducive to the completion of downstream tasks. Once the robot exploresinto a potentially task-relevant region, it should place greater emphasis onthe data within that region. Building on this insight, we propose the$\textbf{S}$elf-$\textbf{I}$mitative $\textbf{R}$einforcement$\textbf{L}$earning ($\textbf{SIRL}$) framework, where the RL algorithm alsoimitates potentially task-relevant trajectories. Specifically, trajectoryreturn is utilized to determine its relevance to the task and an additionalbehavior cloning is adopted whose weight is dynamically adjusted based on thetrajectory return. As a result, our proposed algorithm achieves 120%performance improvement on the challenging HumanoidBench with 5% extracomputation overhead. With further visualization, we find the significantperformance gain does lead to meaningful behavior improvement that severaltasks are solved successfully.</description>
      <author>example@mail.com (Zifeng Zhuang, Diyuan Shi, Runze Suo, Xiao He, Hongyin Zhang, Ting Wang, Shangke Lyu, Donglin Wang)</author>
      <guid isPermaLink="false">2502.17322v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Inverse Kinematics on Guiding Vector Fields for Robot Path Following</title>
      <link>http://arxiv.org/abs/2502.17313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Yu Zhou and Jes\'us Bautista contributed equally to this work. In the  proceedings of the IEEE International Conference on Robotics and Automation  (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;逆向运动学是一种在机器人学中用于姿态和定位控制的基础技术，通常应用于末端执行器。然而，在这篇论文中，研究者们扩展了逆向运动学的概念，将其应用到自主移动机器人的路径跟随上的导向矢量场。&lt;h4&gt;目的&lt;/h4&gt;为了使机器人能够沿着期望的路径收敛并行进，文章提出了如何使用逆向运动学方法构建误差信号，并驱动导向矢量场朝向期望路径。&lt;h4&gt;方法&lt;/h4&gt;首先，从形式上展示了如何将逆向运动学应用于单积分器机器人的导向矢量场上。然后利用逆向运动学确保层次集误差信号表现为线性系统，从而方便对机器人在向目标路径过渡时的行为进行控制，并允许注入前馈信号以实现沿路径的精确运动行为。&lt;h4&gt;主要发现&lt;/h4&gt;研究提出了如何将该技术应用于常速单轮车（如固定翼无人机），以便它们能够跟踪二维路径并具有精细的瞬态控制能力。&lt;h4&gt;结论&lt;/h4&gt;通过实际飞行测试验证了预测的理论结果，表明这种方法在指导自主移动机器人沿特定路径精确运动方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;逆向运动学被扩展应用于导向矢量场中，使自主移动机器人能够准确地跟踪预定路径。该技术不仅确保了层次集误差信号呈线性系统特征，还通过注入前馈信号提升了瞬态控制性能，并在实际应用中证明其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inverse kinematics is a fundamental technique for motion and positioningcontrol in robotics, typically applied to end-effectors. In this paper, weextend the concept of inverse kinematics to guiding vector fields for pathfollowing in autonomous mobile robots. The desired path is defined by itsimplicit equation, i.e., by a collection of points belonging to one or morezero-level sets. These level sets serve as a reference to construct an errorsignal that drives the guiding vector field toward the desired path, enablingthe robot to converge and travel along the path by following such a vectorfield. We start with the formal exposition on how inverse kinematics can beapplied to guiding vector fields for single-integrator robots in anm-dimensional Euclidean space. Then, we leverage inverse kinematics to ensurethat the level-set error signal behaves as a linear system, facilitatingcontrol over the robot's transient motion toward the desired path and allowingfor the injection of feed-forward signals to induce precise motion behavioralong the path. We then propose solutions to the theoretical and practicalchallenges of applying this technique to unicycles with constant speeds tofollow 2D paths with precise transient control. We finish by validating thepredicted theoretical results through real flights with fixed-wing drones.</description>
      <author>example@mail.com (Yu Zhou, Jesús Bautista, Weijia Yao, Héctor García de Marina)</author>
      <guid isPermaLink="false">2502.17313v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Human-Machine Perception via Adaptive LiDAR for Advanced Driver Assistance Systems</title>
      <link>http://arxiv.org/abs/2502.17309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;准确的环境感知对于高级驾驶辅助系统（ADAS）至关重要。激光雷达（LiDAR）在ADAS中起着至关重要的作用，可以可靠地检测障碍物并帮助确保交通安全。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，根据环境特性调整激光雷达的分辨率和范围可以提高机器感知能力。然而，目前针对ADAS的自适应激光雷达方法尚未探索将车辆感知能力和驾驶员视觉感知结合起来的可能性，这可能进一步提升探测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的系统，该系统可根据驾驶员的视觉感知来调整LiDAR特性，以增强超出人类视野范围外的LiDAR感应。在虚拟环境CARLA中开发系统的概念验证原型。&lt;h4&gt;方法&lt;/h4&gt;系统整合实时数据监控驾驶员视线，识别环境中驾驶员正在观察的区域，并通过动态增加外围未关注区域的激光雷达的范围和分辨率来优化激光雷达资源。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，这种基于注视的LiDAR相对于基准独立式LiDAR，在雾等具有挑战性的环境条件下性能更佳。该混合的人机感知方法在实时驾驶场景中为ADAS应用提供更好的安全性和态势感知能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合车辆和驾驶员的感知能力来优化激光雷达特性，可以提高复杂环境下ADAS系统的检测性能和安全性。&lt;h4&gt;翻译&lt;/h4&gt;准确的环境感知对高级驾驶辅助系统（ADAS）至关重要。现有的研究表明，根据环境特征调整LiDAR的分辨率和范围可以改善机器感知。然而，目前用于ADAS的自适应LiDAR方法还没有探索将车辆感知能力与驾驶员视觉感知结合的可能性，这有可能进一步提升检测性能。本文提出了一种新的系统，该系统可根据人类驾驶员的视觉感知来定制LiDAR特性，以增强超出人眼视野之外的LiDAR感应。我们开发了一个在虚拟环境CARLA中的概念验证原型系统。该系统集成了实时数据监控司机视线的功能，可以识别出环境中司机正在查看的区域，并通过动态增加未被注视周围区域中激光雷达的范围和分辨率来优化其资源分配。模拟结果表明，这种基于目光追踪的LiDAR相对于独立式LiDAR基准在具有挑战性的环境条件下（例如雾）表现更佳。该混合的人机感知方法可能为ADAS应用中的实时驾驶场景提供增强的安全性和态势感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate environmental perception is critical for advanced driver assistancesystems (ADAS). Light detection and ranging (LiDAR) systems play a crucial rolein ADAS; they can reliably detect obstacles and help ensure traffic safety.Existing research on LiDAR sensing has demonstrated that adapting the LiDAR'sresolution and range based on environmental characteristics can improve machineperception. However, current adaptive LiDAR approaches for ADAS have notexplored the possibility of combining the perception abilities of the vehicleand the human driver, which can potentially further enhance the detectionperformance. In this paper, we propose a novel system that adapts LiDARcharacteristics to human driver's visual perception to enhance LiDAR sensingoutside human's field of view. We develop a proof-of-concept prototype of thesystem in the virtual environment CARLA. Our system integrates real-time dataon the driver's gaze to identify regions in the environment that the driver ismonitoring. This allows the system to optimize LiDAR resources by dynamicallyincreasing the LiDAR's range and resolution in peripheral areas that the drivermay not be attending to. Our simulations show that this gaze-aware LiDARenhances detection performance compared to a baseline standalone LiDAR,particularly in challenging environmental conditions like fog. Our hybridhuman-machine sensing approach potentially offers improved safety andsituational awareness in real-time driving scenarios for ADAS applications.</description>
      <author>example@mail.com (Federico Scarì, Nitin Jonathan Myers, Chen Quan, Arkady Zgonnikov)</author>
      <guid isPermaLink="false">2502.17309v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning</title>
      <link>http://arxiv.org/abs/2502.15762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了SmartEdge系统，该系统利用边缘计算和云端协同工作，在糖尿病预测中实现了低延迟、高效能的解决方案。通过集成多种风险因素，并使用投票算法提高了模型预测准确率。&lt;h4&gt;背景&lt;/h4&gt;物联网（IoT）正在推动智能城市的医疗、交通、工业和教育等领域的发展。特别是在智能医院和远程患者监测（RPM）方面，互联网医疗事物（IoMT）变得尤为重要。然而，现有基于云计算的方法在延迟敏感的应用中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的AI驱动的边缘计算与云协同系统SmartEdge，旨在解决糖尿病预测中的低延迟问题，并展示其在健康应用中的有效性和可扩展性。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个基于边缘和云端的框架，在不同配置下部署糖尿病预测模型。评估了系统的性能指标包括延迟、准确性及响应时间。&lt;h4&gt;主要发现&lt;/h4&gt;使用集成机器学习投票算法，可以将预测准确率提高5%，优于单一模型。&lt;h4&gt;结论&lt;/h4&gt;SmartEdge系统展示了在医疗领域中边缘计算和云服务结合的有效性和潜力，并为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Internet of Things (IoT) revolutionizes smart city domains such ashealthcare, transportation, industry, and education. The Internet of MedicalThings (IoMT) is gaining prominence, particularly in smart hospitals and RemotePatient Monitoring (RPM). The vast volume of data generated by IoMT devicesshould be analyzed in real-time for health surveillance, prognosis, andprediction of diseases. Current approaches relying on Cloud computing toprovide the necessary computing and storage capabilities do not scale for theselatency-sensitive applications. Edge computing emerges as a solution bybringing cloud services closer to IoMT devices. This paper introducesSmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloudcomputing system for diabetes prediction. This work addresses latency concernsand demonstrates the efficacy of edge resources in healthcare applicationswithin an end-to-end system. The system leverages various risk factors fordiabetes prediction. We propose an Edge and Cloud-enabled framework to deploythe proposed diabetes prediction models on various configurations using edgenodes and main cloud servers. Performance metrics are evaluated using, latency,accuracy, and response time. By using ensemble machine learning votingalgorithms we can improve the prediction accuracy by 5% versus a single modelprediction.</description>
      <author>example@mail.com (Alain Hennebelle, Qifan Dieng, Leila Ismail, Rajkumar Buyya)</author>
      <guid isPermaLink="false">2502.15762v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Co-Designing Augmented Reality Tools for High-Stakes Clinical Teamwork</title>
      <link>http://arxiv.org/abs/2502.17295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, submitted to DIS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究探讨了医疗工作者如何利用增强现实头戴式显示器（AR-HMDs）来提高急诊团队的工作效率，通过参与性设计与医疗工作者合作，发现了七个基于角色的AR-HMD应用场景，并提供了针对高风险环境下的团队工作的设计建议。&lt;h4&gt;背景&lt;/h4&gt;尽管AR-HMD在支持医疗环境中团队协作方面显示出巨大潜力，但在急诊科（ER）团队中的应用却很少得到研究。ER具有特殊的挑战，如程序记忆、医疗错误和沟通障碍。&lt;h4&gt;目的&lt;/h4&gt;通过与医疗工作者的合作进行参与性设计研究，探索AR-HMD如何促进急诊流程中团队合作的潜在能力。&lt;h4&gt;方法&lt;/h4&gt;进行了一个参与者驱动的设计研究项目，旨在了解HCWs在ER环境中利用AR-HMD的可能性。&lt;h4&gt;主要发现&lt;/h4&gt;AR-HMD可以作为信息共享和检索系统使用，在知识鸿沟方面发挥作用，并解决了将AR-HMD集成到ER工作流程中的担忧。提出了七种基于角色的场景设计建议，适用于不同专业背景、执行多项医疗任务的HCWs。&lt;h4&gt;结论&lt;/h4&gt;希望通过这项研究激发设计师开发新的AR-HMD应用程序，用于高风险团队环境。&lt;h4&gt;翻译&lt;/h4&gt;医护人员如何利用增强现实头戴式显示器（AR-HMDs）来改善急诊科内的团队协作？尽管在支持医疗服务中的团队合作方面显示了巨大潜力，但专门针对ER团队的设计却很少见。这项研究通过与医疗工作者的合作设计研究，揭示了AR-HMD可以作为信息共享和检索系统使用，解决了将AR-HMD集成到ER工作流程中的问题，并提出了适用于不同专业背景的HCWs在执行多种医疗任务时的角色基于的应用场景设计建议。希望此项研究能激发设计师开发新的适合高风险团队环境下的AR-HMD应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How might healthcare workers (HCWs) leverage augmented reality head-mounteddisplays (AR-HMDs) to enhance teamwork? Although AR-HMDs have shown immensepromise in supporting teamwork in healthcare settings, design for EmergencyDepartment (ER) teams has received little attention. The ER presents uniquechallenges, including procedural recall, medical errors, and communicationgaps. To address this gap, we engaged in a participatory design study withhealthcare workers to gain a deep understanding of the potential for AR-HMDs tofacilitate teamwork during ER procedures. Our results reveal that AR-HMDs canbe used as an information-sharing and information-retrieval system to bridgeknowledge gaps, and concerns about integrating AR-HMDs in ER workflows. Wecontribute design recommendations for seven role-based AR-HMD applicationscenarios involving HCWs with various expertise, working across multiplemedical tasks. We hope our research inspires designers to embark on thedevelopment of new AR-HMD applications for high-stakes, team environments.</description>
      <author>example@mail.com (Angelique Taylor, Tauhid Tanjim, Huajie Cao, Jalynn Blu Nicoly, Jonathan I. Segal, Jonathan St. George, Soyon Kim, Kevin Ching, Francisco R. Ortega, Hee Rin Lee)</author>
      <guid isPermaLink="false">2502.17295v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework</title>
      <link>http://arxiv.org/abs/2502.17265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. Project website:  https://hsp-iit.github.io/hannes-wrist-control&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于计算机视觉的系统，该系统结合用户和自动系统的合作，在共享自主框架中实现假肢腕关节连续控制。&lt;h4&gt;背景&lt;/h4&gt;大多数用于假肢抓握的技术集中在灵巧的手指控制上，而忽视了手腕动作。这迫使用户通过肘部、肩部和臀部的动作来适应手腕的抓取需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合计算机视觉的方法，在假肢臂中实现腕关节自由度的连续控制，以促进更自然的接近目标物体并根据用户的意图进行抓握。&lt;h4&gt;方法&lt;/h4&gt;该系统利用用户与自动系统的协作，采用基于计算机视觉的技术来无缝控制假肢手腕。系统可以追踪目标对象，并最终按照用户意愿调整手腕姿态。&lt;h4&gt;主要发现&lt;/h4&gt;通过定量分析评估了每个系统组件的有效性，并在Hannes假肢臂上部署该方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统能够有效改善假肢的自然抓握能力，提供更好的用户体验。&lt;h4&gt;翻译&lt;/h4&gt;大多数用于假肢抓握的技术集中在灵巧的手指控制上，而忽视了手腕动作。这迫使用户通过肘部、肩部和臀部的动作来适应手腕的抓取需求。我们提出了一种基于计算机视觉的方法，在共享自主框架中结合用户与自动系统的合作，实现假肢腕关节自由度的连续控制，以促进更自然的接近目标物体并根据用户的意图进行抓握。我们的系统可以无缝地控制假肢手腕追踪目标对象，并最终按照用户意愿调整手腕姿态。我们通过定量分析评估了每个系统组件的有效性，并在Hannes假肢臂上部署该方法。代码和视频：https://hsp-iit.github.io/hannes-wrist-control.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most control techniques for prosthetic grasping focus on dexterous fingerscontrol, but overlook the wrist motion. This forces the user to performcompensatory movements with the elbow, shoulder and hip to adapt the wrist forgrasping. We propose a computer vision-based system that leverages thecollaboration between the user and an automatic system in a shared autonomyframework, to perform continuous control of the wrist degrees of freedom in aprosthetic arm, promoting a more natural approach-to-grasp motion. Our pipelineallows to seamlessly control the prosthetic wrist to follow the target objectand finally orient it for grasping according to the user intent. We assess theeffectiveness of each system component through quantitative analysis andfinally deploy our method on the Hannes prosthetic arm. Code and videos:https://hsp-iit.github.io/hannes-wrist-control.</description>
      <author>example@mail.com (Federico Vasile, Elisa Maiettini, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale)</author>
      <guid isPermaLink="false">2502.17265v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Tidiness Score-Guided Monte Carlo Tree Search for Visual Tabletop Rearrangement</title>
      <link>http://arxiv.org/abs/2502.17235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的框架TSMCTS，该框架利用RGB-D相机解决桌面整理问题。&lt;h4&gt;背景&lt;/h4&gt;当前的桌面整理研究面临两大挑战：缺乏公开的数据集和基准以及难以指定未见物体的目标配置。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，作者提出了一个结构化的数据集（TTU），并开发了一种基于视觉的判别器来预测整洁度分数，并结合蒙特卡洛树搜索算法寻找整理轨迹。&lt;h4&gt;方法&lt;/h4&gt;1. 创建了一个桌面整理数据集(TTU)；2. 利用该数据训练出一种能够评估不同配置下整洁度的基于视觉的判别器；3. 使用MCTS在不指定具体目标的情况下找到整理路径，并利用整洁度分数作为指导；4. 提出了TSMCTS，它将一个清洁度判断器与一个基于MCTS的整理规划器结合在一起。&lt;h4&gt;主要发现&lt;/h4&gt;提出的TSMCTS框架能够在多种环境中有效工作，包括咖啡桌、餐桌、办公桌和浴室等场景。&lt;h4&gt;结论&lt;/h4&gt;通过使用TTU数据集训练出的视觉判别器和MCTS算法相结合的方法能够有效地解决桌面整理问题，并且具有较高的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种基于整洁度分数指导的蒙特卡洛树搜索(TSMCTS)框架，旨在仅使用RGB-D相机来解决桌面上的清理问题。该研究解决了两个主要难题：缺乏公开数据集和基准以及难以指定未见物体的目标配置。为了解决第一个问题，我们提供了桌面整理（TTU）数据集，在模拟中收集了一个结构化的数据集。利用这个数据集，我们训练出一种基于视觉的判别器能够预测整洁度分数。这种判别器可以一致地评估未知配置下的整洁程度，包括真实世界中的场景。为了解决第二个问题，我们采用了蒙特卡洛树搜索(MCTS)方法在不指定明确目标的情况下寻找整理路径。而不是提供特定的目标，我们展示我们的MCTS基规划程序能够使用整洁度分数作为指导找到多样化的整理配置。因此，我们提出了TSMCTS，它将一个清洁度判断器与一个基于MCTS的整理规划器结合在一起以找到最优的整理排列。在咖啡桌、餐桌、办公桌和浴室等各种环境中，TSMCTS已经展示了其能力。TTU数据集可以在 https://github.com/rllab-snu/TTU-Dataset 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present the tidiness score-guided Monte Carlo tree search(TSMCTS), a novel framework designed to address the tabletop tidying up problemusing only an RGB-D camera. We address two major problems for tabletop tidyingup problem: (1) the lack of public datasets and benchmarks, and (2) thedifficulty of specifying the goal configuration of unseen objects. We addressthe former by presenting the tabletop tidying up (TTU) dataset, a structureddataset collected in simulation. Using this dataset, we train a vision-baseddiscriminator capable of predicting the tidiness score. This discriminator canconsistently evaluate the degree of tidiness across unseen configurations,including real-world scenes. Addressing the second problem, we employ MonteCarlo tree search (MCTS) to find tidying trajectories without specifyingexplicit goals. Instead of providing specific goals, we demonstrate that ourMCTS-based planner can find diverse tidied configurations using the tidinessscore as a guidance. Consequently, we propose TSMCTS, which integrates atidiness discriminator with an MCTS-based tidying planner to find optimaltidied arrangements. TSMCTS has successfully demonstrated its capability acrossvarious environments, including coffee tables, dining tables, office desks, andbathrooms. The TTU dataset is available at:https://github.com/rllab-snu/TTU-Dataset.</description>
      <author>example@mail.com (Hogun Kee, Wooseok Oh, Minjae Kang, Hyemin Ahn, Songhwai Oh)</author>
      <guid isPermaLink="false">2502.17235v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>A Reinforcement Learning Approach to Non-prehensile Manipulation through Sliding</title>
      <link>http://arxiv.org/abs/2502.17221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种针对非抓握式任务的深度确定性策略梯度（DDPG）强化学习框架，用于高效地在水平表面上滑动物体。该算法通过精确控制机械臂的加速度生成线性轨迹，实现了物体的相对操作。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数技术主要集中在基于抓握的操作上，这限制了它们在非抓握任务中的适用性。为了满足日益增长的需求，本文提出了一种新的方法来解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;引入一种DDPG强化学习框架，以实现高效的非抓握操作，特别是在滑动物体方面的应用。&lt;h4&gt;方法&lt;/h4&gt;算法通过精确控制机器人臂的加速度生成线性轨迹，实现了物体在水平表面上滑动时的操作。此外还开发了两种不同的算法来动态估计滑动过程中的摩擦力。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法能够在线估算每次操作后的摩擦力，并将其反馈到演员模型中作为关键反馈，从而提高了策略的适应性和鲁棒性。实验结果表明该框架能够有效推广滑动物体的操作并适应不同表面。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过模拟和实际实验验证了其有效性，展示了零样本仿真到现实环境的转移能力。&lt;h4&gt;翻译&lt;/h4&gt;虽然机器人应用程序越来越需要多功能和动态的对象处理，但大多数现有技术主要集中在基于抓握的操作上，限制了它们在非抓握任务中的适用性。为了解决这一需求，本文介绍了一种用于有效进行非抓取操作（特别是物体在水平表面上滑动）的深度确定性策略梯度（DDPG）强化学习框架。该算法通过精确控制与水平表面刚性连接的机器人臂加速度生成线性轨迹，实现了滑动物体时相对的操作。此外还开发了两种不同的算法来动态估算滑动过程中的摩擦力。这些算法在线提供了每次动作后的摩擦估计，并将其反馈到演员模型中作为关键反馈，增强了策略的适应性和鲁棒性，确保在不同表面条件下更精确地控制平台加速度。所提出的算法通过模拟和实际实验进行了验证。结果表明该框架能够有效推广滑动物体操作，并且特别能够在不同摩擦性质表面上进行调整。值得注意的是，训练后的模型展示了零样本仿真到现实环境的转移能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although robotic applications increasingly demand versatile and dynamicobject handling, most existing techniques are predominantly focused ongrasp-based manipulation, limiting their applicability in non-prehensile tasks.To address this need, this study introduces a Deep Deterministic PolicyGradient (DDPG) reinforcement learning framework for efficient non-prehensilemanipulation, specifically for sliding an object on a surface. The algorithmgenerates a linear trajectory by precisely controlling the acceleration of arobotic arm rigidly coupled to the horizontal surface, enabling the relativemanipulation of an object as it slides on top of the surface. Furthermore, twodistinct algorithms have been developed to estimate the frictional forcesdynamically during the sliding process. These algorithms provide onlinefriction estimates after each action, which are fed back into the actor modelas critical feedback after each action. This feedback mechanism enhances thepolicy's adaptability and robustness, ensuring more precise control of theplatform's acceleration in response to varying surface condition. The proposedalgorithm is validated through simulations and real-world experiments. Resultsdemonstrate that the proposed framework effectively generalizes slidingmanipulation across varying distances and, more importantly, adapts todifferent surfaces with diverse frictional properties. Notably, the trainedmodel exhibits zero-shot sim-to-real transfer capabilities.</description>
      <author>example@mail.com (Hamidreza Raei, Elena De Momi, Arash Ajoudani)</author>
      <guid isPermaLink="false">2502.17221v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid Whole-Body Locomotion on Narrow Terrain via Dynamic Balance and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.17219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动态平衡和强化学习的新型全身行走算法，使类人机器人能够仅通过本体感觉在极端地形上行走。&lt;h4&gt;背景&lt;/h4&gt;人类具有精细的动力平衡机制，能够在各种地形和极端条件下保持稳定。然而，现有的类人机器人步行算法难以应对缺乏外部感知（如视觉或激光雷达）的极端环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全身行走算法来解决现有方法在处理不可见障碍物和突然失去平衡方面的能力不足问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一个动态平衡机制，通过扩展的零力矩点(ZMP)驱动奖励和任务驱动奖励，在一个全身演员-评论家框架中实现上肢与下肢的协调动作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该算法能够使机器人在极其狭窄的地面上保持平衡，并且对外部干扰具有适应性。&lt;h4&gt;结论&lt;/h4&gt;通过这种新型方法，类人机器人的行走能力得到了显著增强，使其能更好地应对复杂环境。&lt;h4&gt;翻译&lt;/h4&gt;人类拥有精细的动力平衡机制，在各种地形和极端条件下都能维持稳定。然而，尽管最近取得了重大进展，现有的类人机器人步行算法仍然难以穿越极端环境，尤其是在缺乏外部感知（如视觉或激光雷达）的情况下。这是因为当前的方法通常依赖于基于步态的或者需要特定感知条件的奖励策略，缺少有效处理不可见障碍物和突然失去平衡的有效机制。为了解决这一挑战，我们提出了一种新的全身行走算法，该算法基于动力平衡和强化学习（RL），使类人机器人能够仅通过本体感觉在极端地形上行走，特别是在狭窄路径和意外障碍的情况下。具体来说，我们引入了一个动态平衡机制，利用了扩展的零力矩点(ZMP)驱动奖励和任务驱动奖励，在一个全身演员-评论家框架中实现上下肢体的协调动作。全尺寸Unitree H1-2机器人的实验验证了该方法在极端狭窄地形上保持平衡以及对抗外部干扰的能力，证明了其增强机器人对复杂环境适应性的有效性。视频可以在https://whole-body-loco.github.io观看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess delicate dynamic balance mechanisms that enable them tomaintain stability across diverse terrains and under extreme conditions.However, despite significant advances recently, existing locomotion algorithmsfor humanoid robots are still struggle to traverse extreme environments,especially in cases that lack external perception (e.g., vision or LiDAR). Thisis because current methods often rely on gait-based or perception-conditionrewards, lacking effective mechanisms to handle unobservable obstacles andsudden balance loss. To address this challenge, we propose a novel whole-bodylocomotion algorithm based on dynamic balance and Reinforcement Learning (RL)that enables humanoid robots to traverse extreme terrains, particularly narrowpathways and unexpected obstacles, using only proprioception. Specifically, weintroduce a dynamic balance mechanism by leveraging an extended measure ofZero-Moment Point (ZMP)-driven rewards and task-driven rewards in a whole-bodyactor-critic framework, aiming to achieve coordinated actions of the upper andlower limbs for robust locomotion. Experiments conducted on a full-sizedUnitree H1-2 robot verify the ability of our method to maintain balance onextremely narrow terrains and under external disturbances, demonstrating itseffectiveness in enhancing the robot's adaptability to complex environments.The videos are given at https://whole-body-loco.github.io.</description>
      <author>example@mail.com (Weiji Xie, Chenjia Bai, Jiyuan Shi, Junkai Yang, Yunfei Ge, Weinan Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.17219v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Mechanical non-reciprocity programmed by shear jamming in soft composite solids</title>
      <link>http://arxiv.org/abs/2502.17083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种通过利用颗粒物理中的剪切堵塞转换来设计非互易机械性的原理，从而在软复合固体中实现可调、方向依赖的不对称性。&lt;h4&gt;背景&lt;/h4&gt;传统的非互易性通常通过复杂结构非线性在超材料中实现。而具有内在非互易力学特性的连续体固体由于其潜在的应用前景（如波导、机器人技术及自适应材料）却未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;引入一种设计原则，利用颗粒物理中的剪切堵塞转换来工程化软复合固体中的非互易机械性。&lt;h4&gt;方法&lt;/h4&gt;通过控制包含接触网络与基质弹性之间的相互作用，在软复合固体中实现了对剪切和正交力学响应的方向依赖的不对称性。结合响应性磁轮廓线，展示了程序化的非互易动力学特性。&lt;h4&gt;主要发现&lt;/h4&gt;实现了可调、方向相关的不对称性；展示了通过组合响应性磁图案和剪切堵塞系统的各向异性特性的程序化非互易动力学；以及在软材料中实现之前难以达到的不对称时空控制运动传输的能力。&lt;h4&gt;结论&lt;/h4&gt;此项工作为设计非互易物质开创了一个新的范例，将颗粒物理与软材料工程相结合以实现对机械智能系统至关重要的功能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mechanical non-reciprocity-manifested as asymmetric responses to opposingmechanical stimuli-has traditionally been achieved through intricate structuralnonlinearities in metamaterials. However, continuum solids with inherentnon-reciprocal mechanics remain underexplored, despite their promisingpotential for applications such as wave guiding, robotics, and adaptivematerials. Here, we introduce a design principle by employing the shear jammingtransition from granular physics to engineering non-reciprocal mechanics insoft composite solids. Through the control of the interplay between inclusioncontact networks and matrix elasticity, we achieve tunable, direction-dependentasymmetry in both shear and normal mechanical responses. In addition to staticregimes, we demonstrate programmable non-reciprocal dynamics by combiningresponsive magnetic profiles with the anisotropic characteristics ofshear-jammed systems. This strategy enables asymmetric spatiotemporal controlover motion transmission, a previously challenging feat in soft materials. Ourwork establishes a novel paradigm for designing non-reciprocal matter, bridginggranular physics with soft material engineering to realize functionalitiesessential for mechano-intelligent systems.</description>
      <author>example@mail.com (Chang Xu, Shuaihu Wang, Hong Wang, Xu Liu, Zemin Liu, Yiqiu Zhao, Wenqi Hu, Qin Xu)</author>
      <guid isPermaLink="false">2502.17083v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Evolution 6.0: Evolving Robotic Capabilities Through Generative Design</title>
      <link>http://arxiv.org/abs/2502.17034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IROS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出Evolution 6.0的概念，这是一种由生成式人工智能驱动的机器人技术进化。当机器人缺乏完成任务所需的工具时，它能够自主设计所需工具并学习如何使用它们来实现目标。&lt;h4&gt;背景&lt;/h4&gt;随着Generative AI的发展，机器人系统需要更加智能化和自适应以应对各种复杂任务的需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的机器人系统Evolution 6.0，使其能够在没有事先准备的情况下完成人类请求的任务，并且自主设计必要的工具和学习使用方法。&lt;h4&gt;方法&lt;/h4&gt;该系统包括两个关键模块：工具生成模块和动作生成模块。前者利用视觉-语言模型（VLM）和3D工具生成器来根据任务需求设计并制造专用工具；后者则通过自然语言指令转为机器人行动。具体实现中采用了QwenVLM、OpenVLA和Llama-Mesh等技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该系统在10秒内能以90%的成功率生成所需工具，并且83.5%的物理和视觉泛化能力，在动作生成方面表现良好。然而，在运动和语义泛化上还有待提高。&lt;h4&gt;结论&lt;/h4&gt;尽管初步结果令人鼓舞，但为了进一步提升其在现实世界中的适用性，未来的工作将重点放在双臂操作、扩展任务范围以及增强环境理解等方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要的原始英文内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a new concept, Evolution 6.0, which represents the evolution ofrobotics driven by Generative AI. When a robot lacks the necessary tools toaccomplish a task requested by a human, it autonomously designs the requiredinstruments and learns how to use them to achieve the goal. Evolution 6.0 is anautonomous robotic system powered by Vision-Language Models (VLMs),Vision-Language Action (VLA) models, and Text-to-3D generative models for tooldesign and task execution. The system comprises two key modules: the ToolGeneration Module, which fabricates task-specific tools from visual and textualdata, and the Action Generation Module, which converts natural languageinstructions into robotic actions. It integrates QwenVLM for environmentalunderstanding, OpenVLA for task execution, and Llama-Mesh for 3D toolgeneration. Evaluation results demonstrate a 90% success rate for toolgeneration with a 10-second inference time, and action generation achieving83.5% in physical and visual generalization, 70% in motion generalization, and37% in semantic generalization. Future improvements will focus on bimanualmanipulation, expanded task capabilities, and enhanced environmentalinterpretation to improve real-world adaptability.</description>
      <author>example@mail.com (Muhammad Haris Khan, Artyom Myshlyaev, Artyom Lykov, Miguel Altamirano Cabrera, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.17034v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Task-Oriented 6-DoF Grasp Pose Detection in Clutters</title>
      <link>http://arxiv.org/abs/2502.16976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了任务导向的6自由度抓取姿态检测在杂乱环境中的问题，并构建了一个大规模的数据集以解决这一难题。提出了一种名为One-Stage TaskGrasp（OSTG）的方法，该方法采用了基于特定任务的对象点选择策略以及基于任务的手势生成模块来确定如何抓取。&lt;h4&gt;背景&lt;/h4&gt;人类会根据不同任务采取不同的抓握方式，例如刀具的把手用于切割而刀片则用于传递。现有的机器人抓握姿态检测研究在一定程度上考虑了这种任务导向性的问题，并且已经取得了一些进展；然而这些方法通常受制于低自由度夹爪类型或非杂乱设置。&lt;h4&gt;目的&lt;/h4&gt;为了解决更通用和实用的抓取模型问题，本文提出了一个名为Task-Oriented 6-DoF Grasp Pose Detection in Clutters（TO6DGC）的问题，并构造了一个大规模的数据集用于解决这一问题。&lt;h4&gt;方法&lt;/h4&gt;提出了OSTG方法，该方法采用了任务导向点选择策略来确定何处抓握，以及一种任务导向手势生成模块以决定如何抓取特定对象。实验是在构建的大型数据集上进行的。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，在多个指标下，本文提出的方法均优于现有基线；实际机器人实验也验证了OSTG方法在识别任务导向抓握点和6自由度抓握姿态上的优越性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个处理杂乱环境中具有任务导向性的6自由度抓取问题的有效解决方案，并展示了其对于实现更通用且实用的机器人抓取模型的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的是关于人类基于不同任务选择不同的抓握方式，研究者们在机器人抓取姿态检测领域进行了一些任务导向性的工作并取得了进展。然而这些工作大多数局限于低自由度夹爪或者非杂乱场景下，并不适用于现实生活中的辅助需求。本文旨在开发更通用和实际的应用模型，提出了一个名为“任务导向的6自由度抓取姿态检测在复杂环境下的问题”，并且构建了一个大规模的数据集来支持这一研究。此外还提出了一种名为One-Stage TaskGrasp（OSTG）的方法来解决这个问题，并通过大量实验验证了该方法的有效性及其对于实际应用的意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In general, humans would grasp an object differently for different tasks,e.g., "grasping the handle of a knife to cut" vs. "grasping the blade to handover". In the field of robotic grasp pose detection research, some existingworks consider this task-oriented grasping and made some progress, but they aregenerally constrained by low-DoF gripper type or non-cluttered setting, whichis not applicable for human assistance in real life. With an aim to get moregeneral and practical grasp models, in this paper, we investigate the problemnamed Task-Oriented 6-DoF Grasp Pose Detection in Clutters (TO6DGC), whichextends the task-oriented problem to a more general 6-DOF Grasp Pose Detectionin Cluttered (multi-object) scenario. To this end, we construct a large-scale6-DoF task-oriented grasping dataset, 6-DoF Task Grasp (6DTG), which features4391 cluttered scenes with over 2 million 6-DoF grasp poses. Each grasp isannotated with a specific task, involving 6 tasks and 198 objects in total.Moreover, we propose One-Stage TaskGrasp (OSTG), a strong baseline to addressthe TO6DGC problem. Our OSTG adopts a task-oriented point selection strategy todetect where to grasp, and a task-oriented grasp generation module to decidehow to grasp given a specific task. To evaluate the effectiveness of OSTG,extensive experiments are conducted on 6DTG. The results show that our methodoutperforms various baselines on multiple metrics. Real robot experiments alsoverify that our OSTG has a better perception of the task-oriented grasp pointsand 6-DoF grasp poses.</description>
      <author>example@mail.com (An-Lan Wang, Nuo Chen, Kun-Yu Lin, Li Yuan-Ming, Wei-Shi Zheng)</author>
      <guid isPermaLink="false">2502.16976v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Design of a low-cost and lightweight 6 DoF bimanual arm for dynamic and contact-rich manipulation</title>
      <link>http://arxiv.org/abs/2502.16908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了ARMADA，一个专为动态操作研究设计的双臂机器人。它采用了低成本和易于组装的设计，能够执行打击、抢夺、锤击等复杂任务。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数机器人由于硬件限制（如高惯性设计、有限的柔韧性以及对昂贵扭矩传感器的依赖）难以处理具有挑战性的动态接触操作任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种经济且灵活的双臂机器人，用于动态手动动作的研究和实验。&lt;h4&gt;方法&lt;/h4&gt;ARMADA采用了低惯量、反驱能力强的执行器，并使用了轻质设计以及现成可用组件和3D打印链接。整个系统的成本仅为6100美元。&lt;h4&gt;主要发现&lt;/h4&gt;ARMADA可以达到每秒高达6.16米的速度，负载为2.5公斤；在真实环境中能完成诸如抢夺、锤击等动态操作任务，并且通过强化学习训练后可以在现实世界中进行零样本迁移。&lt;h4&gt;结论&lt;/h4&gt;ARMADA的开源性质提供了详细的组装指南、CAD模型和仿真代码，方便研究者使用。推荐观看补充视频以获得更多信息。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了ARMADA（用于操纵与动态动作的可承受机器人），一个专为动态操作研究设计的双臂机器人。它采用了低成本且易于在实验室中组装的设计，结合低惯量、反驱能力执行器和轻质结构，使用现成组件及3D打印链接构建。整个系统的成本仅为6100美元，每只手臂的速度可达每秒6.16米，与大多数协作机器人相比几乎快了一倍，负载为2.5公斤。展示的动态操作包括抢夺、锤击和双手抛掷等任务，并且在强化学习中表现出色：能够在模拟环境中训练非抓取式操纵策略并在现实世界中实现零样本迁移；以及通过人体动作阴影进行双臂物体抛掷研究。ARMADA是完全开源的，包含详细的组装说明、CAD模型、URDFs（Universal Robot Description Format）、仿真和学习代码。强烈推荐查看补充视频了解更多信息：https://sites.google.com/view/im2-humanoid-arm&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic and contact-rich object manipulation, such as striking, snatching, orhammering, remains challenging for robotic systems due to hardware limitations.Most existing robots are constrained by high-inertia design, limitedcompliance, and reliance on expensive torque sensors. To address this, weintroduce ARMADA (Affordable Robot for Manipulation and Dynamic Actions), a 6degrees-of-freedom bimanual robot designed for dynamic manipulation research.ARMADA combines low-inertia, back-drivable actuators with a lightweight design,using readily available components and 3D-printed links for ease of assembly inresearch labs. The entire system, including both arms, is built for just$6,100. Each arm achieves speeds up to 6.16m/s, almost twice that of mostcollaborative robots, with a comparable payload of 2.5kg. We demonstrate ARMADAcan perform dynamic manipulation like snatching, hammering, and bimanualthrowing in real-world environments. We also showcase its effectiveness inreinforcement learning (RL) by training a non-prehensile manipulation policy insimulation and transferring it zero-shot to the real world, as well as humanmotion shadowing for dynamic bimanual object throwing. ARMADA is fullyopen-sourced with detailed assembly instructions, CAD models, URDFs,simulation, and learning codes. We highly recommend viewing the supplementaryvideo at https://sites.google.com/view/im2-humanoid-arm.</description>
      <author>example@mail.com (Jaehyung Kim, Jiho Kim, Dongryung Lee, Yujin Jang, Beomjoon Kim)</author>
      <guid isPermaLink="false">2502.16908v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Gazing at Failure: Investigating Human Gaze in Response to Robot Failure in Collaborative Tasks</title>
      <link>http://arxiv.org/abs/2502.16899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  this paper is accepted in HRI conference as a full paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了人类的非语言行为，特别是目光动态如何作为机器人故障的信号，并分析不同类型的机器人失败对人们感知机器人的影响。&lt;h4&gt;背景&lt;/h4&gt;机器人在与人类用户合作完成任务时可能会出现错误，这些错误会损害它们作为团队成员的信任度。检测和恢复此类故障对于维持有效的信任水平至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过分析人类的目光动态来检测机器人未察觉的失败，并探讨不同类型及时间发生的失败如何影响人们对机器人的看法。&lt;h4&gt;方法&lt;/h4&gt;进行了一项针对27名参与者的研究，他们与移动机械臂协作解决拼图游戏。机器人被编程以经历两种类型的故障——执行型和决策型，在任务开始或结束时发生，且有时会承认这些故障的存在。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现显示，不同类型及时间发生的机器人的失败显著影响了参与者的目光行为和对机器人的看法。例如，执行性故障导致更多的目光转移以及更关注机器人；而决策性故障则在任务末尾时导致目标区域间的眼球运动熵降低。&lt;h4&gt;结论&lt;/h4&gt;研究表明，通过观察人类的目光动态可以作为识别机器人故障及其类型的可靠指标，并且这些信息可用来预测适当的恢复行动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots are prone to making errors, which can negatively impact theircredibility as teammates during collaborative tasks with human users. Detectingand recovering from these failures is crucial for maintaining effective levelof trust from users. However, robots may fail without being aware of it. Oneway to detect such failures could be by analysing humans' non-verbal behavioursand reactions to failures. This study investigates how human gaze dynamics cansignal a robot's failure and examines how different types of failures affectpeople's perception of robot. We conducted a user study with 27 participantscollaborating with a robotic mobile manipulator to solve tangram puzzles. Therobot was programmed to experience two types of failures -- executional anddecisional -- occurring either at the beginning or end of the task, with orwithout acknowledgement of the failure. Our findings reveal that the type andtiming of the robot's failure significantly affect participants' gaze behaviourand perception of the robot. Specifically, executional failures led to moregaze shifts and increased focus on the robot, while decisional failuresresulted in lower entropy in gaze transitions among areas of interest,particularly when the failure occurred at the end of the task. These resultshighlight that gaze can serve as a reliable indicator of robot failures andtheir types, and could also be used to predict the appropriate recoveryactions.</description>
      <author>example@mail.com (Ramtin Tabatabaei, Vassilis Kostakos, Wafa Johal)</author>
      <guid isPermaLink="false">2502.16899v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Variations of Augmented Lagrangian for Robotic Multi-Contact Simulation</title>
      <link>http://arxiv.org/abs/2502.16898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新的多接触非线性互补问题（NCP）求解器系列，基于增广拉格朗日理论。&lt;h4&gt;背景&lt;/h4&gt;多接触非线性互补问题是机器人模拟中自然出现的挑战。在涉及密集接触和刚性相互作用的情况下，同时实现高精度和效率是一个重大难题。&lt;h4&gt;目的&lt;/h4&gt;介绍一类新的多接触NCP求解器，并展示其在机器人模拟中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;通过迭代替代问题解决方案并更新原始-对偶变量的方式，将传统的增广拉格朗日理论应用于处理多接触NCP。提出了两种针对机器人仿真的特定变体：级联牛顿增广拉格朗日（CANAL）和基于子系统的交替方向乘子法（SubADMM）。&lt;h4&gt;主要发现&lt;/h4&gt;CANAL能够准确且稳健地管理多接触NCP，而SubADMM则提供了计算速度、可扩展性和并行处理能力方面的优势。&lt;h4&gt;结论&lt;/h4&gt;所提出的求解器框架在各种机器人操纵场景中展示了其有效性，特别是在高自由度和大量接触点的多体系统中表现出了显著的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的描述已经被中文内容替代，作为对原文本信息的理解与总结，无需额外添加此键值对。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multi-contact nonlinear complementarity problem (NCP) is a naturallyarising challenge in robotic simulations. Achieving high performance in termsof both accuracy and efficiency remains a significant challenge, particularlyin scenarios involving intensive contacts and stiff interactions. In thisarticle, we introduce a new class of multi-contact NCP solvers based on thetheory of the Augmented Lagrangian (AL). We detail how the standard derivationof AL in convex optimization can be adapted to handle multi-contact NCP throughthe iteration of surrogate problem solutions and the subsequent update ofprimal-dual variables. Specifically, we present two tailored variations of ALfor robotic simulations: the Cascaded Newton-based Augmented Lagrangian (CANAL)and the Subsystem-based Alternating Direction Method of Multipliers (SubADMM).We demonstrate how CANAL can manage multi-contact NCP in an accurate and robustmanner, while SubADMM offers superior computational speed, scalability, andparallelizability for high degrees-of-freedom multibody systems with numerouscontacts. Our results showcase the effectiveness of the proposed solverframework, illustrating its advantages in various robotic manipulationscenarios.</description>
      <author>example@mail.com (Jeongmin Lee, Minji Lee, Sunkyung Park, Jinhee Yun, Dongjun Lee)</author>
      <guid isPermaLink="false">2502.16898v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Primitive-Planner: An Ultra Lightweight Quadrotor Planner with Time-optimal Primitives</title>
      <link>http://arxiv.org/abs/2502.16882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种超轻量级四旋翼飞行器轨迹规划方法，该方法利用时间最优的基本运动单元，在保证轨迹质量和系统轻量化的同时实现高效率。&lt;h4&gt;背景&lt;/h4&gt;目前许多研究致力于解决四旋翼飞行器同时满足高质量轨迹和低计算负载的问题，但现有的解决方案与实际需求之间仍存在差距。&lt;h4&gt;目的&lt;/h4&gt;提出一种超轻量级的四旋翼飞行器规划方法，以实现实时高效、碰撞安全且用户可定制的最优路径规划。&lt;h4&gt;方法&lt;/h4&gt;{'1': '设计了一种新的运动基本单元库，用于生成时间最优化和动力学可行性的轨迹，并实现离线计算。', '2': '提出了一种快速的碰撞检测算法，该算法具有确定的时间消耗且与采样分辨率无关。', '3': '根据用户的定义需求从安全的基本运动中选择最低成本的路径进行执行。', '4': '利用局部轨迹之间的转换关系来确保全局轨迹的平滑性。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '该方法能生成最短飞行时间和距离且计算负担最小化的最优轨迹。', '2': '现实世界中的挑战实验验证了所提方法在各种环境下的鲁棒性。'}&lt;h4&gt;结论&lt;/h4&gt;提出的规划方法通过减少在线计算的功率消耗，同时确保高质量的轨迹，并展示了其在实际应用中优越的时间效率和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is a significant requirement for a quadrotor trajectory planner tosimultaneously guarantee trajectory quality and system lightweight. Manyresearchers focus on this problem, but there's still a gap between theirperformance and our common wish. In this paper, we propose an ultra lightweightquadrotor planner with time-optimal primitives. Firstly, a novel motionprimitive library is proposed to generate time-optimal and dynamical feasibletrajectories offline. Secondly, we propose a fast collision checking methodwith a deterministic time consumption, independent of the sampling resolutionof the primitives. Finally, we select the minimum cost trajectory to executeamong the safe primitives based on user-defined requirements. The propsedtransformation relation between the local trajectories ensures the smoothnessof the global trajectory. The planner reduces unnecessary online computingpower consumption as much as possible, while ensuring a high-qualitytrajectory. Benchmark comparisons show that our method can generate theshortest flight time and distance of trajectory with the lowest computationoverload. Challenging real-world experiments validate the robustness of ourmethod.</description>
      <author>example@mail.com (Jialiang Hou, Neng Pan, Zhepei Wang, Jialin Ji, Yuxiang Guan, Zhongxue Gan, Fei Gao)</author>
      <guid isPermaLink="false">2502.16882v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Fast Finite-Time Sliding Mode Control for Chattering-Free Trajectory Tracking of Robotic Manipulators</title>
      <link>http://arxiv.org/abs/2502.16867v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种无颤振快速终端滑模控制（FTSMC）策略，用于提高三自由度机械臂的轨迹跟踪精度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;传统滑模控制由于系统不确定性及抖动效应，在实现高精度高效轨迹追踪方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新型无颤振快速终端滑模控制策略，以增强机械臂的跟踪精度和稳定性，并确保有限时间内收敛。&lt;h4&gt;方法&lt;/h4&gt;采用牛顿-欧拉动力学建立控制框架并转化为状态空间表示形式。通过引入改进后的滑动面以及基于李雅普诺夫稳定性的分析来设计控制器，从而减少颤振同时保持了传统滑模控制的优点如快速响应和强大的抗干扰能力。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果显示该策略在轨迹跟踪性能、更快的收敛速度及更强稳定性方面优于传统的PD滑模控制（PDSMC）和终端滑模控制（TSMC），尤其适用于高精度机器人应用。&lt;h4&gt;结论&lt;/h4&gt;提出的FTSMC方法为解决机械臂精确轨迹追踪中的挑战提供了有前景的解决方案，展示了其在实现高性能、快速响应及稳健控制方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;实现机器人手臂的精确且高效的轨迹跟踪依然是一个关键难题，因为传统滑模控制（SMC）面临系统不确定性和抖动效应的问题。本文提出了一种无颤振快速终端滑模控制（FTSMC）策略用于三自由度（3-DOF）机械臂设计中，旨在增强其跟踪精度和鲁棒性，并确保有限时间内的收敛。该控制系统框架基于牛顿-欧拉动力学建立并进一步转化为状态空间表示形式以捕捉系统的角位移与速度信息。通过采用改进的滑动面以及李雅普诺夫稳定性分析为基础的设计方法，所提出的FTSMC有效减轻了颤振现象，同时保留了传统滑模控制的优点，如快速响应和强大的干扰抑制能力。经过与常规PD滑模控制（PDSMC）及终端滑模控制（TSMC）的对比实验严格评估控制器性能后发现，本论文提出的方法在轨迹跟踪性能、更快的收敛速度以及更强稳定性方面都优于现有方法，为高精度机器人应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving precise and efficient trajectory tracking in robotic arms remains akey challenge due to system uncertainties and chattering effects inconventional sliding mode control (SMC). This paper presents a chattering-freefast terminal sliding mode control (FTSMC) strategy for athree-degree-of-freedom (3-DOF) robotic arm, designed to enhance trackingaccuracy and robustness while ensuring finite-time convergence. The controlframework is developed using Newton-Euler dynamics, followed by a state-spacerepresentation that captures the system's angular position and velocity. Byincorporating an improved sliding surface and a Lyapunov-based stabilityanalysis, the proposed FTSMC effectively mitigates chattering while preservingthe advantages of SMC, such as fast response and strong disturbance rejection.The controller's performance is rigorously evaluated through comparisons withconventional PD sliding mode control (PDSMC) and terminal sliding mode control(TSMC). Simulation results demonstrate that the proposed approach achievessuperior trajectory tracking performance, faster convergence, and enhancedstability compared to existing methods, making it a promising solution forhigh-precision robotic applications.</description>
      <author>example@mail.com (Momammad Ali Ranjbar)</author>
      <guid isPermaLink="false">2502.16867v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>SLABIM: A SLAM-BIM Coupled Dataset in HKUST Main Building</title>
      <link>http://arxiv.org/abs/2502.16856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025. Dataset aviliable at  https://github.com/HKUST-Aerial-Robotics/SLABIM . Video attachment at  https://youtu.be/7NckgY15ABQ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种新的数据集SLABIM，该数据集结合了室内定位和建筑信息模型（BIM），旨在解决现有室内SLAM数据集中缺乏建筑物结构信息的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的室内SLAM数据集主要关注机器人传感器的数据采集，较少包含详细的建筑结构信息。这种不足限制了研究者们对真实场景中SLAM算法性能的全面评估和优化。&lt;h4&gt;目的&lt;/h4&gt;设计并建立首个结合BIM与SLAM技术的公开数据集SLABIM，用于促进室内定位系统的研究进展，并提高其在实际环境中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;该数据集基于香港科技大学的一栋大学建筑进行构建。首先建立了详细的BIM模型；然后通过多传感器套件采集真实场景下的数据，并生成施工后模型（As-Built Model）；最后，所有数据均进行了时间戳标注并组织成易于访问的形式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果展示了SLABIM在三个关键任务上的性能表现：注册、定位以及语义地图构建。这些测试验证了该数据集的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;通过发布开源的SLABIM数据集，研究者们可以更好地进行室内定位算法的研究，并且能够更有效地评估和改进相关技术的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;现有室内同步定位与建图（SLAM）数据集主要关注机器人感知信息，缺乏对建筑结构的关注。为弥补这一不足，我们设计并构建了首个将SLAM和BIM相结合的数据集——SLABIM。该数据集提供了针对大学建筑的传感器数据，并将其分解、转换成易于使用的格式。通过多传感器套件采集多个会话下的数据及地图制作，我们获取到实际施工模型。所有相关数据均被时间戳标记并组织好，方便用户部署和测试使用。此外，我们部署了先进方法并在注册、定位和语义映射三项任务上报告实验结果，证明SLABIM的有效性和实用性。该数据集已在https://github.com/HKUST-Aerial-Robotics/SLABIM开放源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing indoor SLAM datasets primarily focus on robot sensing, often lackingbuilding architectures. To address this gap, we design and construct the firstdataset to couple the SLAM and BIM, named SLABIM. This dataset provides BIM andSLAM-oriented sensor data, both modeling a university building at HKUST. Theas-designed BIM is decomposed and converted for ease of use. We employ amulti-sensor suite for multi-session data collection and mapping to obtain theas-built model. All the related data are timestamped and organized, enablingusers to deploy and test effectively. Furthermore, we deploy advanced methodsand report the experimental results on three tasks: registration, localizationand semantic mapping, demonstrating the effectiveness and practicality ofSLABIM. We make our dataset open-source athttps://github.com/HKUST-Aerial-Robotics/SLABIM.</description>
      <author>example@mail.com (Haoming Huang, Zhijian Qiao, Zehuan Yu, Chuhao Liu, Shaojie Shen, Fumin Zhang, Huan Yin)</author>
      <guid isPermaLink="false">2502.16856v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Characterizing Structured versus Unstructured Environments based on Pedestrians' and Vehicles' Motion Trajectories</title>
      <link>http://arxiv.org/abs/2502.16847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过分析不同环境类型中行人和车辆的轨迹特征，提出了一种区分结构化和非结构化环境的方法，并利用K-means聚类和广义线性模型对现有数据集进行了分类。&lt;h4&gt;背景&lt;/h4&gt;行人在接近车辆运行时的行为在无结构环境中与有结构环境中存在差异。然而，现有的行人和车辆的轨迹数据集并未根据它们所处环境的性质进行分类，且关于无结构和有结构环境的定义难以量化。&lt;h4&gt;目的&lt;/h4&gt;开发一种更定量的方法来区分不同类型的行进环境，并为现有数据集提供一个基于环境特性的分类。&lt;h4&gt;方法&lt;/h4&gt;采用从各种轨迹中提取出来的特征（如平均速度、轨迹变化率）进行分析，利用K-means聚类和广义线性模型对这些特征进行处理以量化不同环境类型之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;行人轨迹的变异性和停车频率以及行人的密度在两种类型的环境中表现出明显的不同，可以用来分类现有的数据集。&lt;h4&gt;结论&lt;/h4&gt;通过对现有数据集中行人与车辆轨迹行为的研究，提出了一种区分结构化和非结构化环境的新方法。这种方法有助于改善自动驾驶汽车的行为预测算法。&lt;h4&gt;翻译&lt;/h4&gt;行人在接近车辆运行时的行为在无结构环境中（如繁忙的街道）与有结构环境中（如专用的人行道或公园）存在差异。这种行为上的差异对于开发适用于自动行驶车辆的轨迹预测算法非常重要，因为现有的行人和车辆的轨迹数据集并未根据它们所处环境的性质进行分类，并且关于非结构化和结构化环境的标准定义通常难以量化。本文通过分析不同数据集中提取出的各种特征（例如平均速度、路径变化率），应用K-means聚类与广义线性模型，提出了一种新方法来区分这些不同的环境类型。研究结果表明，行人轨迹的变异性和停止频率以及行人的密度在两种类型的环境中显著不同，可以用于现有数据集的分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ITSC55140.2022.9921899&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory behaviours of pedestrians and vehicles operating close to eachother can be different in unstructured compared to structured environments.These differences in the motion behaviour are valuable to be considered in thetrajectory prediction algorithm of an autonomous vehicle. However, theavailable datasets on pedestrians' and vehicles' trajectories that are commonlyused as benchmarks for trajectory prediction have not been classified based onthe nature of their environment. On the other hand, the definitions providedfor unstructured and structured environments are rather qualitative and hard tobe used for justifying the type of a given environment. In this paper, we havecompared different existing datasets based on a couple of extracted trajectoryfeatures, such as mean speed and trajectory variability. Through K-meansclustering and generalized linear models, we propose more quantitative measuresfor distinguishing the two different types of environments. Our results showthat features such as trajectory variability, stop fraction and density ofpedestrians are different among the two environmental types and can be used toclassify the existing datasets.</description>
      <author>example@mail.com (Mahsa Golchoubian, Moojan Ghafurian, Nasser Lashgarian Azad, Kerstin Dautenhahn)</author>
      <guid isPermaLink="false">2502.16847v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>Online Friction Coefficient Identification for Legged Robots on Slippery Terrain Using Smoothed Contact Gradients</title>
      <link>http://arxiv.org/abs/2502.16843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, IEEE RA-L (2025) accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在线识别腿足机器人在滑坡地形上摩擦系数的框架，通过最小化实际状态和预测状态之间的残差来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;在腿足机器人的动态环境下，尤其是在滑坡地形上，准确地估计地面摩擦力对机器人的稳定性和效率至关重要。传统的摩擦系数识别方法在面对非光滑接触动力学时会产生无信息梯度。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于刚体接触动力学的优化问题框架，通过引入平滑处理后的互补条件下的库仑摩擦来解决非光滑接触动力学带来的挑战，并利用拒绝法过滤掉不适宜的数据。&lt;h4&gt;方法&lt;/h4&gt;该框架将优化问题参数化为最小化实际状态和预测状态之间的残差之和。利用了分析的光滑梯度，解决了由非平滑接触动力学引发的无信息梯度的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，在各种初始条件下，所提出的框架能够快速且一致地识别出摩擦系数，并在使用四足机器人平台KAIST HOUND进行实验时验证了该框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种有效的在线方法来估计腿足机器人的摩擦系数，从而为实际应用中的运动规划和控制奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3541428&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an online friction coefficient identification frameworkfor legged robots on slippery terrain. The approach formulates the optimizationproblem to minimize the sum of residuals between actual and predicted statesparameterized by the friction coefficient in rigid body contact dynamics.Notably, the proposed framework leverages the analytic smoothed gradient ofcontact impulses, obtained by smoothing the complementarity condition ofCoulomb friction, to solve the issue of non-informative gradients induced fromthe nonsmooth contact dynamics. Moreover, we introduce the rejection method tofilter out data with high normal contact velocity following contact initiationsduring friction coefficient identification for legged robots. To validate theproposed framework, we conduct the experiments using a quadrupedal robotplatform, KAIST HOUND, on slippery and nonslippery terrain. We observe that ourframework achieves fast and consistent friction coefficient identificationwithin various initial conditions.</description>
      <author>example@mail.com (Hajun Kim, Dongyun Kang, Min-Gyu Kim, Gijeong Kim, Hae-Won Park)</author>
      <guid isPermaLink="false">2502.16843v1</guid>
      <pubDate>Tue, 25 Feb 2025 19:23:13 +0800</pubDate>
    </item>
    <item>
      <title>NavigateDiff: Visual Predictors are Zero-Shot Navigation Assistants</title>
      <link>http://arxiv.org/abs/2502.13894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的导航方法，通过将大型视觉-语言模型与扩散网络结合来实现零样本学习环境下的机器人导航。这种方法利用预训练的基础模型进行知识迁移和泛化能力的传递。&lt;h4&gt;背景&lt;/h4&gt;家庭机器人在陌生环境中面临挑战，需要能够识别并推理关于新装饰和布局的信息。现有的强化学习方法无法直接应用于新的环境，因为它们通常依赖于广泛的映射和探索，导致耗时且效率低下。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，论文试图将预训练基础模型的逻辑知识和泛化能力转移到零样本导航中。&lt;h4&gt;方法&lt;/h4&gt;通过结合大型视觉-语言模型与扩散网络构建了一个视觉预测器，能够连续预测代理人在下一步可能观察到的内容。此外，为适应导航的时间特性，引入了历史时间信息以确保预测图像与导航场景对齐。最后设计了一种信息融合框架，将预测的未来帧嵌入目标导向策略中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在模拟和真实环境中增强了导航控制，并展示了其强大的鲁棒性和通用性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证了所提出方法的有效性和效率，展现了它改善机器人在各种场景下导航能力的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating unfamiliar environments presents significant challenges forhousehold robots, requiring the ability to recognize and reason about noveldecoration and layout. Existing reinforcement learning methods cannot bedirectly transferred to new environments, as they typically rely on extensivemapping and exploration, leading to time-consuming and inefficient. To addressthese challenges, we try to transfer the logical knowledge and thegeneralization ability of pre-trained foundation models to zero-shotnavigation. By integrating a large vision-language model with a diffusionnetwork, our approach named \mname ~constructs a visual predictor thatcontinuously predicts the agent's potential observations in the next step whichcan assist robots generate robust actions. Furthermore, to adapt the temporalproperty of navigation, we introduce temporal historical information to ensurethat the predicted image is aligned with the navigation scene. We thencarefully designed an information fusion framework that embeds the predictedfuture frames as guidance into goal-reaching policy to solve downstream imagenavigation tasks. This approach enhances navigation control and generalizationacross both simulated and real-world environments. Through extensiveexperimentation, we demonstrate the robustness and versatility of our method,showcasing its potential to improve the efficiency and effectiveness of roboticnavigation in diverse settings.</description>
      <author>example@mail.com (Yiran Qin, Ao Sun, Yuze Hong, Benyou Wang, Ruimao Zhang)</author>
      <guid isPermaLink="false">2502.13894v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
  <item>
      <title>Appeal prediction for AI up-scaled Images</title>
      <link>http://arxiv.org/abs/2502.14013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过开发一个包含136个基础图像和五种不同上采样方法的全面数据集，评估了各种深度学习模型在图像上采样任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;基于DNN或AI的上采样算法由于机器学习的进步变得越来越流行。然而，缺乏对真实世界图像范围广泛且包含主观评价的表现评测。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究空白，通过对大量实际图像进行主观和客观评估来比较不同上采样方法的效果，并训练用于检测这些方法的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;使用136个基础图像和五种不同的上采样方法（Real-ESRGAN, BSRGAN, waifu2x, KXNet以及Lanczos）构建数据集，总共包含1496张注释图像。通过众包服务进行主观评价，并开发了开源工具AVRate Voyager来辅助标注。&lt;h4&gt;主要发现&lt;/h4&gt;在主观评价中，Real-ESRGAN和BSRGAN表现最佳。训练的深度神经网络能够有效地检测不同的上采样方法。同时评估了现有最先进的图像吸引力和质量模型的表现，结果表明这些模型预测性能不高，并因此开发了自己的两种新模型以改进性能。&lt;h4&gt;结论&lt;/h4&gt;研究证明了主观评价的重要性以及对广泛数据集进行详细评测的价值，并通过提供开源工具与数据促进了该领域的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于深度神经网络或人工智能的上采样算法由于机器学习的进步而变得越来越流行。使用卷积神经网络、生成对抗网络或者混合方法的各种上采样模型已发表。大多数模型仅利用PSNR和SSIM进行评估，或是通过少量示例图像来进行评价。然而，缺乏广泛的现实世界图像以及主观评价的表现评测，这是我们研究论文要解决的问题。为此，我们描述了开发的数据集，该数据集使用136个基础图像并采用五种不同的上采样方法，即Real-ESRGAN、BSRGAN、waifu2x、KXNet和Lanczos。总体而言，整个数据集中包含有1496张注释的图像。我们的数据集标注专注于图像吸引力，并使用众包工具AVRate Voyager进行操作。我们评估了不同方法在吸引力上的表现，结果显示Real-ESRGAN和BSRGAN是最好的。此外，我们也训练了一个深度神经网络来检测用于上采样的哪种方法，在评估中这些模型表现出较好的总体性能。除此之外，还对现有最先进的图像吸引力与质量模型进行了评估，结果表明没有一个模型显示出高的预测性能，因此我们又开发了两个自己的方法。第一个采用迁移学习并具有最佳表现，第二个模型则使用信号基特征和随机森林模型并具备整体优秀的性能。为促进开放科学领域的进一步研究，我们将数据集、标注工具及实现方法对外公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; DNN- or AI-based up-scaling algorithms are gaining in popularity due to theimprovements in machine learning. Various up-scaling models using CNNs, GANs ormixed approaches have been published. The majority of models are evaluatedusing PSRN and SSIM or only a few example images. However, a performanceevaluation with a wide range of real-world images and subjective evaluation ismissing, which we tackle in the following paper. For this reason, we describeour developed dataset, which uses 136 base images and five different up-scalingmethods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall thedataset consists of 1496 annotated images. The labeling of our dataset focusedon image appeal and has been performed using crowd-sourcing employing ouropen-source tool AVRate Voyager. We evaluate the appeal of the differentmethods, and the results indicate that Real-ESRGAN and BSRGAN are the best.Furthermore, we train a DNN to detect which up-scaling method has been used,the trained models have a good overall performance in our evaluation. Inaddition to this, we evaluate state-of-the-art image appeal and quality models,here none of the models showed a high prediction performance, therefore we alsotrained two own approaches. The first uses transfer learning and has the bestperformance, and the second model uses signal-based features and a randomforest model with good overall performance. We share the data andimplementation to allow further research in the context of open science.</description>
      <author>example@mail.com (Steve Göring, Rasmus Merten, Alexander Raake)</author>
      <guid isPermaLink="false">2502.14013v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Game State and Spatio-temporal Action Detection in Soccer using Graph Neural Networks and 3D Convolutional Networks</title>
      <link>http://arxiv.org/abs/2502.15462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合视觉信息和比赛状态信息的时空动作检测方法，通过图神经网络与先进的3D卷积神经网络相结合，实现了更好的性能。&lt;h4&gt;背景&lt;/h4&gt;足球数据分析依赖于两种数据源：球员在场上的位置以及他们执行的动作序列。大约每场比赛有2000个球事件需要进行精确和详尽的标注，这是一项繁琐且成本高昂的手动任务。&lt;h4&gt;目的&lt;/h4&gt;为了减少人工注释的工作量并提高自动化程度，本文旨在探索结合视觉信息和比赛状态信息的方法来改进动作检测算法。&lt;h4&gt;方法&lt;/h4&gt;假设职业球员的行为是相互依赖的，并认为加入周围球员的信息（例如位置、速度和团队归属）可以增强纯视觉预测。为此，作者提出了一种基于图神经网络与3D卷积神经网络相结合的方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过将比赛状态信息整合进模型中，该方法展示了改进后的性能指标。&lt;h4&gt;结论&lt;/h4&gt;结合视觉和游戏状态数据能够提高时空动作检测的准确性，并为自动化足球分析提供了一个有前景的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：足球数据分析依赖于两种数据源：球员在场上的位置以及他们执行的动作序列。大约每场比赛有2000个球事件需要进行精确且详尽的手动注释，这是一项繁琐和成本高昂的任务。尽管最先进的时空动作检测方法显示出自动化此任务的前景，但它们缺乏对游戏上下文的理解。假设职业球员的行为是相互依赖的，我们假定将周围球员的信息（如位置、速度及团队归属）加入到纯粹视觉预测中可以增强其准确性。我们提出了一种结合图神经网络与最先进的3D卷积神经网络相结合的方法，展示了通过整合比赛状态信息而改进的性能指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soccer analytics rely on two data sources: the player positions on the pitchand the sequences of events they perform. With around 2000 ball events pergame, their precise and exhaustive annotation based on a monocular video streamremains a tedious and costly manual task. While state-of-the-artspatio-temporal action detection methods show promise for automating this task,they lack contextual understanding of the game. Assuming professional players'behaviors are interdependent, we hypothesize that incorporating surroundingplayers' information such as positions, velocity and team membership canenhance purely visual predictions. We propose a spatio-temporal actiondetection approach that combines visual and game state information via GraphNeural Networks trained end-to-end with state-of-the-art 3D CNNs, demonstratingimproved metrics through game state integration.</description>
      <author>example@mail.com (Jeremie Ochin, Guillaume Devineau, Bogdan Stanciulescu, Sotiris Manitsaris)</author>
      <guid isPermaLink="false">2502.15462v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification</title>
      <link>http://arxiv.org/abs/2502.15637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，人们对开发能够跨多种下游任务泛化的时序数据基础模型产生了浓厚的兴趣。虽然已经引入了大量面向预测的基础模型，但针对时间序列分类的专门模型却相对稀缺。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一空白，我们提出了一种新的开源基础模型Mantis，该模型基于视觉变换器（ViT）架构，并通过对比学习方法进行预训练，以用于时间序列分类任务。&lt;h4&gt;方法&lt;/h4&gt;Mantis模型采用了对比学习方法来进行预训练。此外，还提出了几个适配器来处理多变量设置，这可以减少内存需求并建模通道间的相互依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，无论是在骨干网络被冻结的情况下还是在经过微调之后，Mantis都优于现有的基础模型，并且实现了最低的校准误差。&lt;h4&gt;结论&lt;/h4&gt;Mantis为时间序列分类提供了一种有效的解决方案，同时通过引入适配器机制处理多变量设置问题，进一步优化了性能和内存使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, there has been increasing interest in developing foundationmodels for time series data that can generalize across diverse downstreamtasks. While numerous forecasting-oriented foundation models have beenintroduced, there is a notable scarcity of models tailored for time seriesclassification. To address this gap, we present Mantis, a new open-sourcefoundation model for time series classification based on the Vision Transformer(ViT) architecture that has been pre-trained using a contrastive learningapproach. Our experimental results show that Mantis outperforms existingfoundation models both when the backbone is frozen and when fine-tuned, whileachieving the lowest calibration error. In addition, we propose severaladapters to handle the multivariate setting, reducing memory requirements andmodeling channel interdependence.</description>
      <author>example@mail.com (Vasilii Feofanov, Songkang Wen, Marius Alonso, Romain Ilbert, Hongbo Guo, Malik Tiomoko, Lujia Pan, Jianfeng Zhang, Ievgen Redko)</author>
      <guid isPermaLink="false">2502.15637v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>A Universal Framework for Compressing Embeddings in CTR Prediction</title>
      <link>http://arxiv.org/abs/2502.15355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种模型无关的嵌入压缩框架（MEC），用于压缩点击率预测中的嵌入表，以减少内存使用和延迟，同时保持推荐质量。&lt;h4&gt;背景&lt;/h4&gt;准确的点击率预测对在线广告和推荐系统至关重要。虽然深度学习技术进步提高了捕捉特征交互和理解用户兴趣的能力，但是优化嵌入层仍常常被忽视。大型嵌入表会超过GPU内存限制，并且需要存储在CPU内存中，导致高内存消耗和频繁的数据传输延迟。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的压缩方法来解决现有推荐系统中的内存使用量过大和延迟问题。&lt;h4&gt;方法&lt;/h4&gt;1. 应用流行度加权正则化以平衡高频和低频特征的代码分布。2. 集成对比学习机制，确保量化码的均匀分布，提高嵌入的独特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在三个数据集上，我们的方法能够将内存使用量减少超过50倍，并且保持或提高了推荐性能。&lt;h4&gt;结论&lt;/h4&gt;提出的MEC框架可以有效地压缩嵌入表，降低内存消耗和延迟，同时不牺牲推荐质量。这为构建高效、大规模的推荐系统提供了一个新的途径。&lt;h4&gt;翻译&lt;/h4&gt;准确点击率预测对在线广告与推荐系统至关重要。近期深度学习的进步提高了捕捉特征交互及理解用户兴趣的能力，但优化嵌入层常被忽视。本文提出了一种模型无关的嵌入压缩（MEC）框架，通过量化预训练嵌入来压缩嵌入表，在不牺牲推荐质量的前提下减少内存使用和延迟。实验表明该方法在三个数据集上可以将内存消耗降低50倍以上，并保持或提高推荐性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate click-through rate (CTR) prediction is vital for online advertisingand recommendation systems. Recent deep learning advancements have improved theability to capture feature interactions and understand user interests. However,optimizing the embedding layer often remains overlooked. Embedding tables,which represent categorical and sequential features, can become excessivelylarge, surpassing GPU memory limits and necessitating storage in CPU memory.This results in high memory consumption and increased latency due to frequentGPU-CPU data transfers. To tackle these challenges, we introduce aModel-agnostic Embedding Compression (MEC) framework that compresses embeddingtables by quantizing pre-trained embeddings, without sacrificing recommendationquality. Our approach consists of two stages: first, we applypopularity-weighted regularization to balance code distribution between high-and low-frequency features. Then, we integrate a contrastive learning mechanismto ensure a uniform distribution of quantized codes, enhancing thedistinctiveness of embeddings. Experiments on three datasets reveal that ourmethod reduces memory usage by over 50x while maintaining or improvingrecommendation performance compared to existing models. The implementation codeis accessible in our project repository https://github.com/USTC-StarTeam/MEC.</description>
      <author>example@mail.com (Kefan Wang, Hao Wang, Kenan Song, Wei Guo, Kai Cheng, Zhi Li, Yong Liu, Defu Lian, Enhong Chen)</author>
      <guid isPermaLink="false">2502.15355v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Drug-Target Interaction/Affinity Prediction: Deep Learning Models and Advances Review</title>
      <link>http://arxiv.org/abs/2502.15346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  64 pages, 7 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;药物研发是一个耗时且成本高昂的过程，涉及到从目标结构检测到获得食品药品监督管理局(FDA)批准的多个步骤，并常伴随着安全问题。&lt;h4&gt;背景&lt;/h4&gt;传统方法在预测药物与靶标之间的相互作用方面存在局限性，特别是在捕捉复杂关系上。为此，深度学习模型被提出以克服这一挑战并提供精确和高效的预测结果。&lt;h4&gt;目的&lt;/h4&gt;通过概述有前途的研究方向和模型，各具有不同解决方案但针对同一问题，这篇论文旨在为研究人员提供更多准确且高效地预测药物-靶标相互作用的方法，从而加速更有效药物的开发。&lt;h4&gt;方法&lt;/h4&gt;从2016年到2025年间，总共分析了基于机器学习（主要是深度学习和图神经网络）的不同框架下的180种药物-靶标交互预测方法。&lt;h4&gt;主要发现&lt;/h4&gt;论文讨论了这些模型的新颖性、架构以及输入表示。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的技术和更优的方法，有可能加速药物研发过程并提高药物安全性。深度学习和图神经网络等先进技术在该领域展现出巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;药物发现仍是一个缓慢且成本高昂的过程，包括从目标结构检测到获得FDA批准的多个步骤，并经常伴随着安全问题。准确预测药物与其靶标之间的相互作用以及使用更好的方法和技术开发新药，具有极大可能加速这一过程，最终实现更快地提供救命药物。传统的药物-靶标交互预测方法显示出局限性，在捕捉复杂关系方面尤其如此。因此，深度学习模型被提出以通过其精确和高效的最终结果克服这些挑战。通过概述有前途的研究方向和模型，各具不同的解决方案但针对同一问题，这篇论文旨在为研究人员提供更准确且高效地预测药物-靶标相互作用的方法的更好理解，从而加速开发出更有效的药物。在2016年到2025年间，总共分析了基于机器学习（主要是深度学习和图神经网络）的不同框架下的180种药物-靶标交互预测方法。此外，该论文还讨论了这些模型的新颖性、架构以及输入表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery remains a slow and expensive process that involves many steps,from detecting the target structure to obtaining approval from the Food andDrug Administration (FDA), and is often riddled with safety concerns. Accurateprediction of how drugs interact with their targets and the development of newdrugs by using better methods and technologies have immense potential to speedup this process, ultimately leading to faster delivery of life-savingmedications. Traditional methods used for drug-target interaction predictionshow limitations, particularly in capturing complex relationships between drugsand their targets. As an outcome, deep learning models have been presented toovercome the challenges of interaction prediction through their precise andefficient end results. By outlining promising research avenues and models, eachwith a different solution but similar to the problem, this paper aims to giveresearchers a better idea of methods for even more accurate and efficientprediction of drug-target interaction, ultimately accelerating the developmentof more effective drugs. A total of 180 prediction methods for drug-targetinteractions were analyzed throughout the period spanning 2016 to 2025 usingdifferent frameworks based on machine learning, mainly deep learning and graphneural networks. Additionally, this paper discusses the novelty, architecture,and input representation of these models.</description>
      <author>example@mail.com (Ali Vefghi, Zahed Rahmati, Mohammad Akbari)</author>
      <guid isPermaLink="false">2502.15346v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Fixed Variables: Expanding-variate Time Series Forecasting via Flat Scheme and Spatio-temporal Focal Learning</title>
      <link>http://arxiv.org/abs/2502.15296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一个新的时间序列预测任务：扩展变量的时间序列预测（EVTSF），并提出了一个新的灵活的时空预测框架STEV来应对新增变量带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列预测（MTSF）长期是研究重点。传统研究假设固定的变量数量，但实际应用中随着新传感器部署，系统的变量会增多。&lt;h4&gt;目的&lt;/h4&gt;解决由于新变量加入导致的数据形状不一致和时空学习不平衡的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了STEV框架，包括一个新的Flat Scheme来处理数据形状不一致问题，并引入了一种新的时空聚焦学习策略，解决了对比学习与图表示之间的潜在冲突。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STEV在扩展变量上的表现显著优于其竞争对手。即使只使用5%的观察值，STEV也能达到最先进的MTSF模型的表现水平。&lt;h4&gt;结论&lt;/h4&gt;STEV是一个通用性强、性能优越的时空预测框架，适用于实际应用中的各种扩展策略。&lt;h4&gt;翻译&lt;/h4&gt;多变量时间序列预测（MTSF）一直是研究的核心领域。传统方法假设固定的变量数量，但在现实世界的应用中，随着新传感器部署，Cyber-Physical系统的变量会增加。为此，我们提出了一个新的任务——扩展变量的时间序列预测（EVTSF）。这个任务面临两个挑战：一是处理新增变量导致的数据形状不一致问题；二是解决时空学习不平衡的问题，即由于需要及时操作而新加入的变量观测数据有限。为了解决这些问题，我们提出了一种灵活的时空预测框架STEV，它包含了一个新的Flat Scheme来应对数据形状不一致，并引入了新颖的时空聚焦学习策略。通过三个真实世界的数据集对EVTSF的表现进行了基准测试，并与三个可能解决方案（采用最先进的MTSF模型定制为EVSTF）进行了比较。实验结果表明，STEV在扩展变量上的表现显著优于竞争对手，甚至使用仅5%的新增时期观察值时也能达到最佳水平的效果。进一步研究各种扩展策略证实了STEV在现实应用中的通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate Time Series Forecasting (MTSF) has long been a key researchfocus. Traditionally, these studies assume a fixed number of variables, but inreal-world applications, Cyber-Physical Systems often expand as new sensors aredeployed, increasing variables in MTSF. In light of this, we introduce a noveltask, Expanding-variate Time Series Forecasting (EVTSF). This task presentsunique challenges, specifically (1) handling inconsistent data shapes caused byadding new variables, and (2) addressing imbalanced spatio-temporal learning,where expanding variables have limited observed data due to the necessity fortimely operation. To address these challenges, we propose STEV, a flexiblespatio-temporal forecasting framework. STEV includes a new Flat Scheme totackle the inconsistent data shape issue, which extends the graph-basedspatio-temporal modeling architecture into 1D space by flattening the 2Dsamples along the variable dimension, making the model variable-scale-agnosticwhile still preserving dynamic spatial correlations through a holistic graph.We introduce a novel Spatio-temporal Focal Learning strategy that incorporatesa negative filter to resolve potential conflicts between contrastive learningand graph representation, and a focal contrastive loss as its core to guide theframework to focus on optimizing the expanding variables. We benchmark EVTSFperformance using three real-world datasets and compare it against threepotential solutions employing SOTA MTSF models tailored for EVSTF. Experimentalresults show that STEV significantly outperforms its competitors, particularlyon expanding variables. Notably, STEV, with only 5% of observations from theexpanding period, is on par with SOTA MTSF models trained with completeobservations. Further exploration of various expanding strategies underscoresthe generalizability of STEV in real-world applications.</description>
      <author>example@mail.com (Minbo Ma, Kai Tang, Huan Li, Fei Teng, Dalin Zhang, Tianrui Li)</author>
      <guid isPermaLink="false">2502.15296v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Learning Maritime Inventory Routing Optimization</title>
      <link>http://arxiv.org/abs/2502.15244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于机器学习的局部搜索方法，用于解决大规模海洋库存路由优化问题。&lt;h4&gt;背景&lt;/h4&gt;海洋物流中的库存路由优化问题是组合复杂性很高的问题。&lt;h4&gt;目的&lt;/h4&gt;为了提高大规模海洋库存路由问题解决方案的质量和效率。&lt;h4&gt;方法&lt;/h4&gt;集成图神经网络（GNN）来选择邻域以提升局部搜索的效率，实现对船舶邻近区域的有结构探索。&lt;h4&gt;主要发现&lt;/h4&gt;在大量实际案例中证明了该方法比直接使用混合整数规划法更加高效。&lt;h4&gt;结论&lt;/h4&gt;新方法提高了大规模海洋库存路由优化问题求解的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种基于机器学习的局部搜索方法，用于寻找大规模海上库存路由优化问题的可行解决方案。鉴于此类问题组合复杂度高，我们将图神经网络（GNN）为基础的邻域选择法融入进来以增强局部搜索效率。该方法实现了对船舶邻近区域有结构化的探索，在改善了解质量的同时也保证了计算效率。通过大量的实证实验验证，我们证明在真实案例中本研究的方法相比直接应用混合整数规划方法在求解时间上表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a machine learning-based local search approach for findingfeasible solutions of large-scale maritime inventory routing optimizationproblems. Given the combinatorial complexity of the problems, we integrate agraph neural network-based neighborhood selection method to enhance localsearch efficiency. Our approach enables a structured exploration of vesselneighborhoods, improving solution quality while maintaining computationalefficiency. Through extensive computational experiments on realistic instances,we demonstrate that our method outperforms direct mixed-integer programming insolution time.</description>
      <author>example@mail.com (Rui Chen, Defeng Liu, Nan Jiang, Rishabh Gupta, Mustafa Kilinc, Andrea Lodi)</author>
      <guid isPermaLink="false">2502.15244v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>SiMHand: Mining Similar Hands for Large-Scale 3D Hand Pose Pre-training</title>
      <link>http://arxiv.org/abs/2502.15251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025. arXiv admin note: text overlap with arXiv:2409.09714&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于从野外视频中获取的手图像预训练三维手部姿态估计的框架SimHand。&lt;h4&gt;背景&lt;/h4&gt;现有的3D手部姿势预训练方法未能充分利用来自野外视频中的多样化手部图像的潜力。&lt;h4&gt;目的&lt;/h4&gt;为了实现可扩展性的预训练，准备了一个广泛的包含200多万张手部图像的数据池，并设计了基于对比学习的方法。&lt;h4&gt;方法&lt;/h4&gt;从最近的人类中心视频中收集超过2.0M的手部图像；通过关注手部相似性来提取区分信息，即非相同样本但具有类似手部姿势的成对样本；提出了一种新的对比学习方法，将类似的双手对在特征空间中嵌得更近，并根据样本间的距离自适应地调整对比学习损失权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法优于基于单张图像数据增强生成正例的传统对比学习方法。相比最先进的方法PeCLR，在FreiHand、DexYCB和AssemblyHands数据集上的表现分别提高了15%、10%和4%&lt;h4&gt;结论&lt;/h4&gt;我们的SimHand方法在预训练3D手部姿态估计方面提供了显著的性能改进。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种框架，用于从具有类似手部特征的手图像中进行三维手部姿势的预训练。使用大规模图像可以在各种任务中实现令人满意的结果，但现有的3D手部姿势预训练方法尚未充分利用从野外视频中获取的各种手部图像的潜力。为了促进可扩展性的预训练，我们首先准备了一个包含超过2.0M手部图像的数据池，并设计了一种基于对比学习的方法进行预训练。通过关注手部相似性来提取区分信息：即非相同的样本但具有类似的手部姿势对。然后，我们提出了一种新的对比学习方法，该方法将类似的双手对在特征空间中嵌得更近，并根据样本间的距离自适应地调整对比学习损失权重。实验表明，我们的方法优于基于单张图像数据增强生成正例的传统对比学习方法。在FreiHand、DexYCB和AssemblyHands数据集上，相比最先进的方法PeCLR，我们实现了显著的性能提升（分别提高了15%、10%和4%）。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/ut-vision/SiMHand&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a framework for pre-training of 3D hand pose estimation fromin-the-wild hand images sharing with similar hand characteristics, dubbedSimHand. Pre-training with large-scale images achieves promising results invarious tasks, but prior methods for 3D hand pose pre-training have not fullyutilized the potential of diverse hand images accessible from in-the-wildvideos. To facilitate scalable pre-training, we first prepare an extensive poolof hand images from in-the-wild videos and design our pre-training method withcontrastive learning. Specifically, we collect over 2.0M hand images fromrecent human-centric videos, such as 100DOH and Ego4D. To extractdiscriminative information from these images, we focus on the similarity ofhands: pairs of non-identical samples with similar hand poses. We then proposea novel contrastive learning method that embeds similar hand pairs closer inthe feature space. Our method not only learns from similar samples but alsoadaptively weights the contrastive learning loss based on inter-sampledistance, leading to additional performance gains. Our experiments demonstratethat our method outperforms conventional contrastive learning approaches thatproduce positive pairs sorely from a single image with data augmentation. Weachieve significant improvements over the state-of-the-art method (PeCLR) invarious datasets, with gains of 15% on FreiHand, 10% on DexYCB, and 4% onAssemblyHands.  Our code is available at https://github.com/ut-vision/SiMHand.</description>
      <author>example@mail.com (Nie Lin, Takehiko Ohkawa, Yifei Huang, Mingfang Zhang, Minjie Cai, Ming Li, Ryosuke Furuta, Yoichi Sato)</author>
      <guid isPermaLink="false">2502.15251v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>ELIP: Enhanced Visual-Language Foundation Models for Image Retrieval</title>
      <link>http://arxiv.org/abs/2502.15682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架ELIP，用于增强大规模预训练的视觉-语言模型在文本到图像检索中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的大型预训练视觉-语言模型难以直接应用于文本到图像重排序任务。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个新框架来提高大规模预训练视觉-语言模型在文本到图像检索上的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种增强的语言-图像预训练（ELIP）方法，该方法利用文本查询预测一组视觉提示以调节ViT图像编码。此方法可以应用于CLIP/SigLIP和最先进的BLIP-2架构，并开发了适用于计算资源有限情况下的'学生友好型'最佳实践。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，ELIP框架显著提高了CLIP/SigLIP的性能，并在文本到图像检索任务上超过了当前最先进模型BLIP-2的表现。&lt;h4&gt;结论&lt;/h4&gt;使用新架构和数据整理方法能够有效提升大规模视觉语言预训练模型用于文本到图像检索时的效果。&lt;h4&gt;翻译&lt;/h4&gt;该论文的目标是改进从文本到图像检索的性能。为此，研究者们提出了一种新的框架，可以增强大规模预训练视觉-语言模型的表现力，使其可用于重排序任务中。通过使用文本查询预测一组视觉提示来调节ViT图象编码的方法被称作ELIP，并且可以在常见的CLIP/SigLIP和最先进BLIP-2架构上应用。为了在计算资源有限的情况下训练该框架，研究者们开发了一种友好的实践方法，包括全局难例挖掘、大规模数据集的选择与整理等措施。评估方面，论文设立了两个新的分布外基准测试（Occluded COCO 和 ImageNet-R），用以衡量模型在不同领域中的零样本泛化能力。实验表明，由于新颖的架构和数据整理技术，增强后的网络显著提高了CLIP/SigLIP的表现，并且在文本到图像检索任务上超过了最先进的BLIP-2模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective in this paper is to improve the performance of text-to-imageretrieval. To this end, we introduce a new framework that can boost theperformance of large-scale pre-trained vision-language models, so that they canbe used for text-to-image re-ranking. The approach, Enhanced Language-ImagePre-training (ELIP), uses the text query to predict a set of visual prompts tocondition the ViT image encoding. ELIP can easily be applied to the commonlyused CLIP/SigLIP and the state-of-the-art BLIP-2 architectures. To train thearchitecture with limited computing resources, we develop a 'student friendly'best practice involving global hard sample mining, and selection and curationof a large-scale dataset. On the evaluation side, we set up two newout-of-distribution benchmarks, Occluded COCO and ImageNet-R, to assess thezero-shot generalisation of the models to different domains. Benefiting fromthe novel architecture and data curation, experiments show our enhanced networksignificantly boosts CLIP/SigLIP performance and outperforms thestate-of-the-art BLIP-2 model on text-to-image retrieval.</description>
      <author>example@mail.com (Guanqi Zhan, Yuanpei Liu, Kai Han, Weidi Xie, Andrew Zisserman)</author>
      <guid isPermaLink="false">2502.15682v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>GNN-Coder: Boosting Semantic Code Retrieval with Combined GNNs and Transformer</title>
      <link>http://arxiv.org/abs/2502.15202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GNN-Coder是一种基于图神经网络（GNN）的新型框架，用于利用抽象语法树（AST），该方法旨在提高代码检索任务中的结构和语义特征捕捉能力。&lt;h4&gt;背景&lt;/h4&gt;现有的依赖于序列模型的方法在大型项目中难以完全发挥代码内在结构依赖的作用，尤其是在处理复杂结构的代码片段时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过研究如何将GNN与Transformer结合来促进语义检索任务的发展，并引入一种新颖的图池化方法以及一个新的量化代码嵌入分布均匀性的度量指标MAM。&lt;h4&gt;方法&lt;/h4&gt;提出了基于抽象语法树（AST）的图神经网络框架GNN-Coder，该框架使用子节点数量作为关键特征来突出AST内的内在拓扑关系。同时引入了新的度量标准Mean Angular Margin (MAM) 来衡量代码嵌入分布的一致性和特征分离性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，GNN-Coder在CSN数据集上的MRR（平均准确率）提高了1%-10%，在CosQA数据集上的零样本性能显著提升了20%。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的框架GNN-Coder可以有效提高代码检索任务中的结构和语义特征捕捉能力，从而增强模型对不同代码片段的区分能力和检索准确性。&lt;h4&gt;翻译&lt;/h4&gt;代码检索是现代软件开发的关键组成部分，在大型项目中尤为重要。然而，现有的序列模型方法往往未能充分利用代码固有的结构性依赖关系，导致在复杂结构代码片段上的检索性能不佳。本文介绍了一种基于图神经网络（GNN）的新框架——GNN-Coder，用于利用抽象语法树（AST）。这是首次尝试研究如何通过捕获代码的结构和语义特征来促进语义检索任务的发展，并引入了一个新的针对AST设计的图池化方法，使用子节点数量作为关键特性以突出显示AST内的内在拓扑关系。该设计有效集成了序列表示与层次表示，增强了模型捕捉代码结构和语义的能力。此外，还提出了一种新的度量指标——均值角度余量（MAM），用于量化代码嵌入分布的均匀性，提供了特征分离性的标准化衡量方法。所提出的这种方法实现了更低的MAM值，表明了更具有区分性的特征表示能力。这强调了GNN-Coder在区分不同代码片段方面的优越能力，并提高了检索准确性。实验结果表明，GNN-Coder显著提升了检索性能，在CSN数据集上平均准确率（MRR）提高了1%-10%，在CosQA数据集上的零样本性能显著提升20%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Code retrieval is a crucial component in modern software development,particularly in large-scale projects. However, existing approaches relying onsequence-based models often fail to fully exploit the structural dependenciesinherent in code, leading to suboptimal retrieval performance, particularlywith structurally complex code fragments. In this paper, we introduceGNN-Coder, a novel framework based on Graph Neural Network (GNN) to utilizeAbstract Syntax Tree (AST). We make the first attempt to study howGNN-integrated Transformer can promote the development of semantic retrievaltasks by capturing the structural and semantic features of code. We furtherpropose an innovative graph pooling method tailored for AST, utilizing thenumber of child nodes as a key feature to highlight the intrinsic topologicalrelationships within the AST. This design effectively integrates bothsequential and hierarchical representations, enhancing the model's ability tocapture code structure and semantics. Additionally, we introduce the MeanAngular Margin (MAM), a novel metric for quantifying the uniformity of codeembedding distributions, providing a standardized measure of featureseparability. The proposed method achieves a lower MAM, indicating a morediscriminative feature representation. This underscores GNN-Coder's superiorability to distinguish between code snippets, thereby enhancing retrievalaccuracy. Experimental results show that GNN-Coder significantly boostsretrieval performance, with a 1\%-10\% improvement in MRR on the CSN dataset,and a notable 20\% gain in zero-shot performance on the CosQA dataset.</description>
      <author>example@mail.com (Yufan Ye, Pu Pang, Ting Zhang, Hua Huang)</author>
      <guid isPermaLink="false">2502.15202v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Context Transformer for Multi-level Semantic Scene Understanding</title>
      <link>http://arxiv.org/abs/2502.15184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by the IEEE TCSVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种多层次语义场景理解（MSSU）的方法，用于手术场景的理解，并设计了一个层次化上下文变换器（HCT）网络。&lt;h4&gt;背景&lt;/h4&gt;在开发基于上下文感知的计算机辅助系统中，对手术场景的全面理解和显式认识至关重要。然而，很少有研究提供系统的分析以实现分层的手术场景理解。&lt;h4&gt;目的&lt;/h4&gt;提出一个多层级语义场景理解的方法和层次化上下文变换器网络来解决现有不足，并探索不同级别任务之间的关系。&lt;h4&gt;方法&lt;/h4&gt;设计了一个层次化相关聚合模块（HRAM），同时关联多级交互信息内部条目，然后增强特定于任务的特征。为了进一步促进各种任务的表示学习，提出了跨任务对比学习（ICL）以引导模型通过吸收其他任务提供的补充信息来学习具有任务特性的功能。&lt;h4&gt;主要发现&lt;/h4&gt;通过在白内障数据集和公共可用的内窥镜PSI-AVA数据集上的广泛实验，显示了该方法卓越的性能，并且始终大幅超越现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;提出的HCT+能够利用空间和时间适配器，在大量可调参数减少的情况下实现竞争力的表现。这些发现表明该方法在手术场景理解方面具有重要潜力。&lt;h4&gt;翻译&lt;/h4&gt;对手术场景进行全面而明确的理解对开发基于上下文感知的计算机辅助系统至关重要，但关于分层手术场景理解的研究较少提供系统分析。这项工作提出了将任务集表示为多层次语义场景理解（MSSU），并提出了一种新型层次化上下文变换器（HCT）网络来解决这一问题，并彻底探索了不同级别任务之间的关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A comprehensive and explicit understanding of surgical scenes plays a vitalrole in developing context-aware computer-assisted systems in the operatingtheatre. However, few works provide systematical analysis to enablehierarchical surgical scene understanding. In this work, we propose torepresent the tasks set [phase recognition --&gt; step recognition --&gt; action andinstrument detection] as multi-level semantic scene understanding (MSSU). Forthis target, we propose a novel hierarchical context transformer (HCT) networkand thoroughly explore the relations across the different level tasks.Specifically, a hierarchical relation aggregation module (HRAM) is designed toconcurrently relate entries inside multi-level interaction information and thenaugment task-specific features. To further boost the representation learning ofthe different tasks, inter-task contrastive learning (ICL) is presented toguide the model to learn task-wise features via absorbing complementaryinformation from other tasks. Furthermore, considering the computational costsof the transformer, we propose HCT+ to integrate the spatial and temporaladapter to access competitive performance on substantially fewer tunableparameters. Extensive experiments on our cataract dataset and a publiclyavailable endoscopic PSI-AVA dataset demonstrate the outstanding performance ofour method, consistently exceeding the state-of-the-art methods by a largemargin. The code is available at https://github.com/Aurora-hao/HCT.</description>
      <author>example@mail.com (Luoying Hao, Yan Hu, Yang Yue, Li Wu, Huazhu Fu, Jinming Duan, Jiang Liu)</author>
      <guid isPermaLink="false">2502.15184v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Expansion for Hypergraph Learning</title>
      <link>http://arxiv.org/abs/2502.15564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了新的自适应扩展方法AdE，该方法通过基于团的扩展方式将超图转换为加权图，并利用全局模拟网络和距离感知核函数来保持高阶结构信息。&lt;h4&gt;背景&lt;/h4&gt;近年来，随着对捕获更高阶关系能力的要求，超图受到了广泛关注。许多超图表示学习方法也随之出现。&lt;h4&gt;目的&lt;/h4&gt;为了克服经典扩展方法在固定边权重设计中导致的信息丢失或冗余问题，提出了一种新的自适应扩展方法AdE。&lt;h4&gt;方法&lt;/h4&gt;通过引入全局模拟网络选择每个超边中的两个代表性节点，并将同一超边中的其余节点连接到相应的选定节点。设计了距离感知核函数，动态调整边缘权重以确保相似的节点具有更大的重量。&lt;h4&gt;主要发现&lt;/h4&gt;AdE相比经典的扩展模型在理论合理性、泛化能力和有效性方面都表现出色&lt;h4&gt;结论&lt;/h4&gt;提出的AdE方法能够更好地保持和利用超图中的高阶结构信息&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypergraph, with its powerful ability to capture higher-order relationships,has gained significant attention recently. Consequently, many hypergraphrepresentation learning methods have emerged to model the complex relationshipsamong hypergraphs. In general, these methods leverage classic expansion methodsto convert hypergraphs into weighted or bipartite graphs, and further employmessage passing mechanisms to model the complex structures within hypergraphs.However, classical expansion methods are designed in straightforward mannerswith fixed edge weights, resulting in information loss or redundancy. In lightof this, we design a novel clique expansion-based Adaptive Expansion methodcalled AdE to adaptively expand hypergraphs into weighted graphs that preservethe higher-order structure information. Specifically, we introduce a novelGlobal Simulation Network to select two representative nodes for adaptivelysymbolizing each hyperedge and connect the rest of the nodes within the samehyperedge to the corresponding selected nodes. Afterward, we design adistance-aware kernel function, dynamically adjusting edge weights to ensuresimilar nodes within a hyperedge are connected with larger weights. Extensivetheoretical justifications and empirical experiments over seven benchmarkhypergraph datasets demonstrate that AdE has excellent rationality,generalization, and effectiveness compared to classic expansion models.</description>
      <author>example@mail.com (Tianyi Ma, Yiyue Qian, Shinan Zhang, Chuxu Zhang, Yanfang Ye)</author>
      <guid isPermaLink="false">2502.15564v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>mStyleDistance: Multilingual Style Embeddings and their Evaluation</title>
      <link>http://arxiv.org/abs/2502.15168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2410.12757&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一种多语言风格嵌入模型mStyleDistance，该模型使用合成数据和对比学习进行训练。', '背景': '现有的风格嵌入仅限于英语，缺乏对多种语言的支持。', '目的': '开发一种能够在多种语言中有效工作的风格嵌入模型，并用于评估其质量和性能。', '方法': '利用来自九种不同语言的数据训练mStyleDistance模型；创建一个多语言的STEL或内容基准测试来评估嵌入的质量；在跨语种作者身份验证任务中应用该模型。', '主要发现': '实验结果表明，mStyleDistance风格嵌入优于现有模型，在多语言风格基准上表现出色，并且能够很好地推广到未见过的语言和特征。', '结论': '展示了mStyleDistance的潜在价值及其在跨语种分析中的优势；源代码已公开发布。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的多语言风格嵌入模型，名为Multilingual Style Distance (mStyleDistance)，该模型通过合成数据和对比学习进行了训练，并用于评估其质量和性能。研究显示了该方法在处理多种语言的风格分析任务中的优越性，并且能够很好地推广到新场景中去使用。研究成果已经公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Style embeddings are useful for stylistic analysis and style transfer;however, only English style embeddings have been made available. We introduceMultilingual StyleDistance (mStyleDistance), a multilingual style embeddingmodel trained using synthetic data and contrastive learning. We train the modelon data from nine languages and create a multilingual STEL-or-Content benchmark(Wegmann et al., 2022) that serves to assess the embeddings' quality. We alsoemploy our embeddings in an authorship verification task involving differentlanguages. Our results show that mStyleDistance embeddings outperform existingmodels on these multilingual style benchmarks and generalize well to unseenfeatures and languages. We make our model publicly available athttps://huggingface.co/StyleDistance/mstyledistance .</description>
      <author>example@mail.com (Justin Qiu, Jiacheng Zhu, Ajay Patel, Marianna Apidianaki, Chris Callison-Burch)</author>
      <guid isPermaLink="false">2502.15168v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Para-Lane: Multi-Lane Dataset Registering Parallel Scans for Benchmarking Novel View Synthesis</title>
      <link>http://arxiv.org/abs/2502.15635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了评估端到端的自动驾驶系统，基于新颖视图合成（NVS）技术的模拟环境是必不可少的。这种模拟可以生成新的车辆姿态下的真实感图像和点云数据，尤其是在跨车道场景中。&lt;h4&gt;目的&lt;/h4&gt;由于现有的合成场景基础的NVS数据集在现实性和捕捉到的图像及点云的真实度方面仍然存在不足，因此开发一个多车道的数据集和基准是必要的。该研究旨在基于NeRF和3DGS方法进一步评估现有方法的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法来创建第一个多车道数据集，通过并行扫描真实世界获取25组相关序列，其中包括16,000张前置视图图像、64,000张环视图像以及16,000个LiDAR帧。所有帧都被标记以区分移动物体和静态元素。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用该数据集，在不同车道和距离的多种测试场景中评估现有方法的表现，并提供解决多传感器姿态问题的方法，实现跨模式数据对齐。&lt;h4&gt;结论&lt;/h4&gt;该研究公开了一个名为Paralane的数据集（网址：https://nizqleo.github.io/paralane-dataset/），用于持续添加新的序列以测试现有的方法在不同场景中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;为了评估端到端的自动驾驶系统，一个基于新颖视图合成技术的模拟环境是必要的。该研究提出了一种新型多车道数据集和基准，旨在进一步检验NeRF和3DGS等现有方法的表现。新创建的数据集包括来自真实世界扫描并行扫描25组相关序列，含16000张前置视角图像、64,000环视图像及16,000个LiDAR帧，并且提供了解决跨模式数据对齐的多传感器姿态问题的方法。研究者计划持续添加新的序列以测试现有方法在不同场景中的泛化能力，数据集公开于项目页面：https://nizqleo.github.io/paralane-dataset/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To evaluate end-to-end autonomous driving systems, a simulation environmentbased on Novel View Synthesis (NVS) techniques is essential, which synthesizesphoto-realistic images and point clouds from previously recorded sequencesunder new vehicle poses, particularly in cross-lane scenarios. Therefore, thedevelopment of a multi-lane dataset and benchmark is necessary. While recentsynthetic scene-based NVS datasets have been prepared for cross-lanebenchmarking, they still lack the realism of captured images and point clouds.To further assess the performance of existing methods based on NeRF and 3DGS,we present the first multi-lane dataset registering parallel scans specificallyfor novel driving view synthesis dataset derived from real-world scans,comprising 25 groups of associated sequences, including 16,000 front-viewimages, 64,000 surround-view images, and 16,000 LiDAR frames. All frames arelabeled to differentiate moving objects from static elements. Using thisdataset, we evaluate the performance of existing approaches in various testingscenarios at different lanes and distances. Additionally, our method providesthe solution for solving and assessing the quality of multi-sensor poses formulti-modal data alignment for curating such a dataset in real-world. We planto continually add new sequences to test the generalization of existing methodsacross different scenarios. The dataset is released publicly at the projectpage: https://nizqleo.github.io/paralane-dataset/.</description>
      <author>example@mail.com (Ziqian Ni, Sicong Du, Zhenghua Hou, Chenming Wu, Sheng Yang)</author>
      <guid isPermaLink="false">2502.15635v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Deep Learning on Stereo EEG for Predicting Seizure Freedom in Epilepsy Patients</title>
      <link>http://arxiv.org/abs/2502.15198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;预测癫痫患者无发作状态对于个性化治疗至关重要。然而，传统的预测方法难以在不同类型的患者群体中实现准确的预测。&lt;h4&gt;背景&lt;/h4&gt;难治性癫痫患者的预后评估需要更有效的工具来提高治疗效果和减少副作用。&lt;h4&gt;目的&lt;/h4&gt;开发基于深度学习的图神经网络（GNN）模型以预测从立体脑电图（sEEG）数据中获得的无发作状态。&lt;h4&gt;方法&lt;/h4&gt;利用15名儿科难治性癫痫患者的高质量sEEG数据训练模型，使用图形卷积和多尺度注意力机制捕捉局部与全局连接性。&lt;h4&gt;主要发现&lt;/h4&gt;{'准确性': '在二元分类分析、患者级分析及多类分析中分别达到了92.4%、86.6%和81.4%的准确率；', '关键区域': '前扣带皮层与额极是预测无发作状态的关键脑区，并且这些区域更可能对应于癫痫发作起始区。', '模型识别': '模型标识出的节点更有可能重合于癫痫发作起始区，强调了基于连接性的新深度学习模型对于提高无发作状态预测、定位癫痫发作起始区及大脑在癫痫期间的连接性分析的重要性。'}&lt;h4&gt;结论&lt;/h4&gt;新型基于连接性的深度学习模型如GNN为改善难治性癫痫患者的个性化治疗提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;预测癫痫患者无发作状态对于个性化治疗至关重要。然而，传统的预测方法难以在不同类型的患者群体中实现准确的预测。本研究开发了一种基于深度学习的图神经网络（GNN）模型以预测从立体脑电图（sEEG）数据获得的无发作状态结果，并加深了对癫痫起始区大脑连接性的理解。该模型结合局部和全局连接性使用图形卷积与多尺度注意力机制来捕捉如丘脑及运动区域这样难以研究区域之间的连接，成功提高了预测精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting seizure freedom is essential for tailoring epilepsy treatment. Butaccurate prediction remains challenging with traditional methods, especiallywith diverse patient populations. This study developed a deep learning-basedgraph neural network (GNN) model to predict seizure freedom from stereoelectroencephalography (sEEG) data in patients with refractory epilepsy. Weutilized high-quality sEEG data from 15 pediatric patients to train a deeplearning model that can accurately predict seizure freedom outcomes and advanceunderstanding of brain connectivity at the seizure onset zone. Our modelintegrates local and global connectivity using graph convolutions withmulti-scale attention mechanisms to capture connections betweendifficult-to-study regions such as the thalamus and motor regions. The modelachieved an accuracy of 92.4% in binary class analysis, 86.6% in patient-wiseanalysis, and 81.4% in multi-class analysis. Node and edge-level featureanalysis highlighted the anterior cingulate and frontal pole regions as keycontributors to seizure freedom outcomes. The nodes identified by our modelwere also more likely to coincide with seizure onset zones. Our findingsunderscore the potential of new connectivity-based deep learning models such asGNNs for enhancing the prediction of seizure freedom, predicting seizure onsetzones, connectivity analysis of the brain during seizure, as well as informingAI-assisted personalized epilepsy treatment planning.</description>
      <author>example@mail.com (Artur Agaronyan, Syeda Abeera Amir, Nunthasiri Wittayanakorn, John Schreiber, Marius G. Linguraru, William Gaillard, Chima Oluigbo, Syed Muhammad Anwar)</author>
      <guid isPermaLink="false">2502.15198v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Fine-tuning foundation models of materials interatomic potentials with frozen transfer learning</title>
      <link>http://arxiv.org/abs/2502.15582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习的原子间势能是通过提供训练数据覆盖范围内准确且可扩展的预测来革新原子材料模拟，但生成一个精确且稳健的数据集仍然是个挑战。本文展示了使用迁移学习可以提高基础模型的准确性，并构建了一个更为高效的人工智能模拟工作流程。&lt;h4&gt;背景&lt;/h4&gt;机器学习的原子间势能能够提供训练数据覆盖范围内准确和可扩展的预测，然而，要生成这种精准而健壮的数据集，通常需要数千次第一原理计算。现在开始出现一种旨在创建可以适用于广泛材料领域的基础模型。&lt;h4&gt;目的&lt;/h4&gt;展示通过迁移学习提高基础模型势能准确性，并构建一个改进了数据效率和计算效率的人工智能模拟工作流程。&lt;h4&gt;方法&lt;/h4&gt;利用部分冻结的权重和偏差进行微调，使用两个具有挑战性的表面反应化学以及三元合金稳定性和弹性性质的数据集作为案例研究。&lt;h4&gt;主要发现&lt;/h4&gt;通过迁移学习，在只使用少量（几百个数据点）的情况下可以达到与从零开始训练模型相媲美的精度。此外，还可以利用这种经过调整的势能构建一个准确度相当但更高效的代理模型。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种改进了机器学习潜在效率的人工智能模拟工作流程，该流程提高了数据和计算使用率。&lt;h4&gt;翻译&lt;/h4&gt;机器学习原子间势场通过提供训练数据范围内的精确且可扩展的预测来革新原子材料模拟。生成准确且稳健的数据集仍然是一个挑战，通常需要数千次第一性原理计算才能获得高精度。现在正在出现一种基础模型，其目标是在广泛的材料中通用适用潜在场。虽然这些基础模型可以是健壮和转移的，但它们尚未达到预测反应势垒、相变以及物质稳定性所需的精确度。这项工作展示了通过使用部分冻结权重和偏差进行迁移学习微调的基础模型潜力可以实现化学精度。对于两个具有挑战性的数据集：表面反应化学与三元合金稳定性和弹性性质的研究表明，在使用10-20%的数据（几百个数据点）情况下，冻结转移学习达到的准确度与从头开始训练模型相仿（需要数千个数据点）。此外还展示了可以建立一个同样精确但计算更高效的替代模型，该模型以迁移学习后的势能为真值。综合来看，我们提出了一种改进了机器学习潜在效率的人工智能模拟工作流程，此流程提高了数据和计算使用率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine-learned interatomic potentials are revolutionising atomisticmaterials simulations by providing accurate and scalable predictions within thescope covered by the training data. However, generation of an accurate androbust training data set remains a challenge, often requiring thousands offirst-principles calculations to achieve high accuracy. Foundation models havestarted to emerge with the ambition to create universally applicable potentialsacross a wide range of materials. While foundation models can be robust andtransferable, they do not yet achieve the accuracy required to predict reactionbarriers, phase transitions, and material stability. This work demonstratesthat foundation model potentials can reach chemical accuracy when fine-tunedusing transfer learning with partially frozen weights and biases. For twochallenging datasets on reactive chemistry at surfaces and stability andelastic properties of tertiary alloys, we show that frozen transfer learningwith 10-20% of the data (hundreds of datapoints) achieves similar accuracies tomodels trained from scratch (on thousands of datapoints). Moreover, we showthat an equally accurate, but significantly more efficient surrogate model canbe built using the transfer learned potential as the ground truth. Incombination, we present a simulation workflow for machine learning potentialsthat improves data efficiency and computational efficiency.</description>
      <author>example@mail.com (Mariia Radova, Wojciech G. Stark, Connor S. Allen, Reinhard J. Maurer, Albert P. Bartók)</author>
      <guid isPermaLink="false">2502.15582v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:43 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors</title>
      <link>http://arxiv.org/abs/2502.15540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a Spotlight Paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文建立了表示学习算法的期望和尾部泛化误差界限，并通过相对熵来描述训练集和测试集中提取出的表征分布之间的差异。&lt;h4&gt;背景&lt;/h4&gt;当前对于表示学习算法的泛化误差研究较少，现有的界限无法充分反映编码器结构与简单性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据依赖性对称先验（即训练和测试数据集潜在变量的最小描述长度）来建立更精确的泛化误差界限。&lt;h4&gt;方法&lt;/h4&gt;利用期望边界设计了一种合适的数据依赖正则项，并提出了同时学习数据依赖高斯混合先验并用其作为正则化的系统性方法，显示出了加权注意力机制的自然出现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法优于流行的变分信息瓶颈（VIB）和最近的类别依赖的VIB（CDVIB）。&lt;h4&gt;结论&lt;/h4&gt;新提出的界限和学习先验的方法有助于改善表示学习算法的表现。&lt;h4&gt;翻译&lt;/h4&gt;我们建立了表示学习类型算法的期望和尾部泛化误差界，这些边界以训练集和“测试”数据集中提取出的表征分布之间的相对熵来描述，并且相对于一个数据依赖性对称先验（即，对于训练和测试数据集潜在变量的最小描述长度）。我们证明了我们的界限反映了编码器的“结构”和“简单性”，并且显著改进了现有的少量边界。然后，我们将期望界用于设计合适的数据依赖正则项；并详细探讨了重要的先验选择问题。我们提出了一种系统方法，可以同时学习数据依赖高斯混合先验，并将其用作正则化器。有趣的是，在此过程中自然地出现了加权注意力机制。我们的实验表明，我们提出的方法优于流行的变分信息瓶颈（VIB）方法以及最近的类别依赖的VIB（CDVIB）方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We establish in-expectation and tail bounds on the generalization error ofrepresentation learning type algorithms. The bounds are in terms of therelative entropy between the distribution of the representations extracted fromthe training and "test'' datasets and a data-dependent symmetric prior, i.e.,the Minimum Description Length (MDL) of the latent variables for the trainingand test datasets. Our bounds are shown to reflect the "structure" and"simplicity'' of the encoder and significantly improve upon the few existingones for the studied model. We then use our in-expectation bound to devise asuitable data-dependent regularizer; and we investigate thoroughly theimportant question of the selection of the prior. We propose a systematicapproach to simultaneously learning a data-dependent Gaussian mixture prior andusing it as a regularizer. Interestingly, we show that a weighted attentionmechanism emerges naturally in this procedure. Our experiments show that ourapproach outperforms the now popular Variational Information Bottleneck (VIB)method as well as the recent Category-Dependent VIB (CDVIB).</description>
      <author>example@mail.com (Milad Sefidgaran, Abdellatif Zaidi, Piotr Krasnowski)</author>
      <guid isPermaLink="false">2502.15540v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PDeepPP:A Deep learning framework with Pretrained Protein language for peptide classification</title>
      <link>http://arxiv.org/abs/2502.15610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, submitted to arXiv&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;蛋白质后翻译修饰（PTMs）和生物活性肽（BPs）在各种生物学过程中起着关键作用，并具有重要的治疗潜力。然而，通过实验方法识别这些位点既耗时又成本高昂。&lt;h4&gt;背景&lt;/h4&gt;现有计算工具，尤其是基于深度学习的方法，在预测PTM位点和肽类生物活性方面表现出色，但仍然面临蛋白质序列复杂性和跨不同数据集提供高质量预测的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合预训练蛋白质语言模型与融合Transformer和CNN的神经网络框架，以提高特征提取能力和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架应用于多项任务中，包括PTM位点及生物活性肽预测，并通过大规模数据集提升模型鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在33项任务比较中，此模型在其中25项达到最先进水平，超越现有方法并展示出跨不同数据集的多功能性。&lt;h4&gt;结论&lt;/h4&gt;这种新方法为大规模肽类发现和PTM分析提供了可扩展且有效的方法，开启了更高效地肽类分类及功能注释的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Protein post-translational modifications (PTMs) and bioactive peptides (BPs)play critical roles in various biological processes and have significanttherapeutic potential. However, identifying PTM sites and bioactive peptidesthrough experimental methods is often labor-intensive, costly, andtime-consuming. As a result, computational tools, particularly those based ondeep learning, have become effective solutions for predicting PTM sites andpeptide bioactivity. Despite progress in this field, existing methods stillstruggle with the complexity of protein sequences and the challenge ofrequiring high-quality predictions across diverse datasets.  To address these issues, we propose a deep learning framework that integratespretrained protein language models with a neural network combining transformerand CNN for peptide classification. By leveraging the ability of pretrainedmodels to capture complex relationships within protein sequences, combined withthe predictive power of parallel networks, our approach improves featureextraction while enhancing prediction accuracy.  This framework was applied to multiple tasks involving PTM site and bioactivepeptide prediction, utilizing large-scale datasets to enhance the model'srobustness. In the comparison across 33 tasks, the model achievedstate-of-the-art (SOTA) performance in 25 of them, surpassing existing methodsand demonstrating its versatility across different datasets. Our resultssuggest that this approach provides a scalable and effective solution forlarge-scale peptide discovery and PTM analysis, paving the way for moreefficient peptide classification and functional annotation.</description>
      <author>example@mail.com (Jixiu Zhai, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan Liu, Xueying Wang, Dan Huang)</author>
      <guid isPermaLink="false">2502.15610v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>P2W: From Power Traces to Weights Matrix -- An Unconventional Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2502.14968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的非传统迁移学习方法，用于在嵌入式SoC中训练机器学习模型。该方法通过提取已部署在SoC中的现有ML模型的权重来初始化新模型，而不是直接访问这些模型。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习（ML）模型在嵌入式芯片系统（SoCs）上的快速部署，医疗保健和自动驾驶汽车等领域发生了变革性的变化。然而，在这些场景中训练嵌入式ML模型的一个主要挑战是缺乏高质量的公开训练数据。&lt;h4&gt;目的&lt;/h4&gt;解决现有迁移学习方法需要直接访问已存在模型这一限制问题，特别是在嵌入式SoC上运行的情况下。&lt;h4&gt;方法&lt;/h4&gt;通过从执行机器学习模型的SoC捕获功耗测量值并将这些值转换为权重矩阵来初始化新的ML模型。这种方法不需要直接获取嵌入式系统中的现有模型的具体信息。&lt;h4&gt;主要发现&lt;/h4&gt;新方法可以显著提高在数据稀缺环境下的模型准确性和预测性能，相比传统训练方式，在使用相同数量的受限训练数据的情况下，可以使新模型的准确性提升高达3倍。&lt;h4&gt;结论&lt;/h4&gt;提出的方法提供了一种有效的途径来利用现有的嵌入式ML模型的知识，以改进新模型的学习效率和预测表现。这种方法对于那些难以直接访问已有模型场景下的机器学习应用来说特别有用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在芯片上的系统（SoCs）上部署的机器学习（ML）模型数量快速增长已经对医疗保健、自动驾驶汽车等领域带来了变革性的变化。然而，在这些领域训练嵌入式ML模型的一个主要挑战是缺乏高质量的公共可用训练数据。迁移学习方法通过利用现有ML模型中的知识作为起点来应对这一挑战，从而用于训练新的ML模型。但是，现有的迁移学习方法需要直接访问现有的模型，这在许多情况下是不可行的，尤其是在部署在嵌入式SoC上的ML模型的情况下。因此，在本文中，我们提出了一种新颖的方法：通过提取并使用一个运行在嵌入式SoC中的现有ML模型的权重来训练一个新的ML模型，而不需要直接访问该模型。我们的方法采集了执行ML模型时从SoC捕捉到的能量消耗测量值，并将其转换为用于初始化新ML模型的大致权重矩阵。这提高了新模型的学习效率和预测性能，尤其是在可用来培训模型的数据量有限的情况下。与使用相同数量的受限训练数据的传统训练方式相比，我们新颖的方法可以有效提高新ML模型的准确度高达3倍。&lt;h4&gt;其他信息&lt;/h4&gt;{'关键词': ['迁移学习', '嵌入式SoC', '机器学习', '功耗测量', '权重初始化']}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of deploying machine learning (ML) models within embeddedsystems on a chip (SoCs) has led to transformative shifts in fields likehealthcare and autonomous vehicles. One of the primary challenges for trainingsuch embedded ML models is the lack of publicly available high-quality trainingdata. Transfer learning approaches address this challenge by utilizing theknowledge encapsulated in an existing ML model as a starting point for traininga new ML model. However, existing transfer learning approaches require directaccess to the existing model which is not always feasible, especially for MLmodels deployed on embedded SoCs. Therefore, in this paper, we introduce anovel unconventional transfer learning approach to train a new ML model byextracting and using weights from an existing ML model running on an embeddedSoC without having access to the model within the SoC. Our approach capturespower consumption measurements from the SoC while it is executing the ML modeland translates them to an approximated weights matrix used to initialize thenew ML model. This improves the learning efficiency and predictive performanceof the new model, especially in scenarios with limited data available to trainthe model. Our novel approach can effectively increase the accuracy of the newML model up to 3 times compared to classical training methods using the sameamount of limited training data.</description>
      <author>example@mail.com (Roozbeh Siyadatzadeh, Fatemeh Mehrafrooz, Nele Mentens, Todor Stefanov)</author>
      <guid isPermaLink="false">2502.14968v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Riemannian Sparse Representation Learning Network for Polarimetric SAR Image Classification</title>
      <link>http://arxiv.org/abs/2502.15302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Riemannian稀疏表示学习网络(SRSR CNN)用于极化合成孔径雷达(PolSAR)图像分类。&lt;h4&gt;背景&lt;/h4&gt;深度学习是Polarimetric SAR图像分类的有效方法，但缺乏相关的数学原理指导，并且通常将复数协方差矩阵转换为欧几里得空间中的向量输入，这可能破坏了矩阵结构和通道关系。&lt;h4&gt;目的&lt;/h4&gt;通过引入Riemannian度量来更好地处理PolSAR的复杂矩阵结构，以提高分类准确性和边缘细节准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于超像素的Riemannian稀疏表示模型(SRSR)，该模型能够在黎曼空间中学习几何结构和稀疏特征。然后将其展开为一个网络，可以自动地学习稀疏系数和字典原子，并添加了CNN增强模块以提高上下文高级特征的学习能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明所提出的方法在保持准确的边缘细节和正确的区域同质性方面优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的基于SR指导的深度学习模型可以直接使用协方差矩阵作为网络输入，并且可以利用黎曼度量来学习复数矩阵在黎曼空间中的几何结构和稀疏特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning is an effective end-to-end method for Polarimetric SyntheticAperture Radar(PolSAR) image classification, but it lacks the guidance ofrelated mathematical principle and is essentially a black-box model. Inaddition, existing deep models learn features in Euclidean space, where PolSARcomplex matrix is commonly converted into a complex-valued vector as thenetwork input, distorting matrix structure and channel relationship. However,the complex covariance matrix is Hermitian positive definite (HPD), and resideson a Riemannian manifold instead of a Euclidean one. Existing methods cannotmeasure the geometric distance of HPD matrices and easily cause somemisclassifications due to inappropriate Euclidean measures. To address theseissues, we propose a novel Riemannian Sparse Representation Learning Network(SRSR CNN) for PolSAR images. Firstly, a superpixel-based Riemannian SparseRepresentation (SRSR) model is designed to learn the sparse features withRiemannian metric. Then, the optimization procedure of the SRSR model isinferred and further unfolded into an SRSRnet, which can automatically learnthe sparse coefficients and dictionary atoms. Furthermore, to learn contextualhigh-level features, a CNN-enhanced module is added to improve classificationperformance. The proposed network is a Sparse Representation (SR) guided deeplearning model, which can directly utilize the covariance matrix as the networkinput, and utilize Riemannian metric to learn geometric structure and sparsefeatures of complex matrices in Riemannian space. Experiments on three realPolSAR datasets demonstrate that the proposed method surpasses state-of-the-arttechniques in ensuring accurate edge details and correct region homogeneity forclassification.</description>
      <author>example@mail.com (Junfei Shi, Mengmeng Nie, Weisi Lin, Haiyan Jin, Junhuai Li, Rui Wang)</author>
      <guid isPermaLink="false">2502.15302v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Depth-aware Fusion Method based on Image and 4D Radar Spectrum for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.15516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文讨论了毫米波雷达和相机在自动驾驶环境感知中的互补作用，通过结合4D毫米波雷达和深度感知的摄像机图像来提高3D物体检测精度。&lt;h4&gt;背景&lt;/h4&gt;安全性和可靠性对于公众接受自动驾驶至关重要。传统的3D毫米波雷达只能提供目标的距离、多普勒频移及方位信息，在恶劣天气条件下仍能保持良好性能，但点云稀疏。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过结合4D毫米波雷达和相机的优势来增强环境感知的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;['利用4D毫米波雷达提供的深度感知数据与相机图像进行融合，采用注意机制在鸟瞰图视角下将丰富的纹理图像与深度信息相结合', '提出了一种基于GAN的方法，在没有深度传感器的情况下从雷达频谱生成深度图像']&lt;h4&gt;主要发现&lt;/h4&gt;['通过结合4D毫米波雷达和相机可以有效提升环境感知的准确性，特别是在恶劣天气条件下。', '使用注意力机制能够更好地融合不同类型的感知数据，提高3D物体检测精度。', '基于GAN的方法有助于在缺乏直接深度信息的情况下生成有效的深度图像']&lt;h4&gt;结论&lt;/h4&gt;该研究证明了将4D毫米波雷达与相机结合可以显著提升自动驾驶系统的环境感知能力，并提出了一种新颖的解决方案来克服现有技术局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safety and reliability are crucial for the public acceptance of autonomousdriving. To ensure accurate and reliable environmental perception, intelligentvehicles must exhibit accuracy and robustness in various environments.Millimeter-wave radar, known for its high penetration capability, can operateeffectively in adverse weather conditions such as rain, snow, and fog.Traditional 3D millimeter-wave radars can only provide range, Doppler, andazimuth information for objects. Although the recent emergence of 4Dmillimeter-wave radars has added elevation resolution, the radar point cloudsremain sparse due to Constant False Alarm Rate (CFAR) operations. In contrast,cameras offer rich semantic details but are sensitive to lighting and weatherconditions. Hence, this paper leverages these two highly complementary andcost-effective sensors, 4D millimeter-wave radar and camera. By integrating 4Dradar spectra with depth-aware camera images and employing attentionmechanisms, we fuse texture-rich images with depth-rich radar data in theBird's Eye View (BEV) perspective, enhancing 3D object detection. Additionally,we propose using GAN-based networks to generate depth images from radar spectrain the absence of depth sensors, further improving detection accuracy.</description>
      <author>example@mail.com (Yue Sun, Yeqiang Qian, Chunxiang Wang, Ming Yang)</author>
      <guid isPermaLink="false">2502.15516v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Decoding lithium's subtle phase stability with a machine learning force field</title>
      <link>http://arxiv.org/abs/2502.15190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了锂金属在锂-金属电池阳极中的相稳定性，揭示了量子效应和非谐性对锂的热力学性质的重要性。&lt;h4&gt;背景&lt;/h4&gt;锂金属在作为锂电池阳极材料时表现出复杂的多晶型特性，这对优化其性能至关重要。然而，这种看似简单的金属具有平坦的能量地形图，需要考虑量子效应、声子重整化和热膨胀效应来准确描述。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图形神经网络的机器学习势场，并进行高效自洽声子计算，以研究在近环境条件下bcc-，fcc-和9R-Li相的稳定性。&lt;h4&gt;方法&lt;/h4&gt;利用了图神经网络机器学习力场以及声子重整化效应并考虑量子、热力学膨胀影响下的自洽声子计算来模拟锂的不同晶型结构。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明非谐性在决定Li的热力学性质中起着重要作用。fcc-Li在零温度和压力下被确认为基态，预测的bcc-fcc相边界与实验相变线具有定性的匹配。&lt;h4&gt;结论&lt;/h4&gt;这些研究提供了锂多晶型复杂特性的关键见解，并建立了一种有效的计算方法来模拟更现实条件下锂的大规模原子尺度仿真，以支持实际能源存储应用。&lt;h4&gt;翻译&lt;/h4&gt;理解元素锂的相稳定性对于优化其在锂-金属电池阳极中的性能至关重要。然而，这种看似简单的金属表现出复杂的多晶型特性，需要准确考虑量子效应和非谐性来捕捉平坦能量地形图中的细微差别。为了应对这一挑战，我们开发了一种基于图形神经网络的机器学习力场，并进行了高效的自洽声子计算，在近环境条件下对bcc-、fcc-和9R-Li进行了研究，将量子效应、声子重整化以及热膨胀效应结合考虑在内。我们的研究表明非谐性在决定锂的热力学性质中起着重要作用。这些相之间的自由能差值（特别是fcc-与9R-Li）仅几毫电子伏特/原子，解释了实验上难以获得纯相样品的问题，并暗示了堆垛层错和相关缺陷形成的可能性。在零温度和压力下确认了fcc-Li为基态，预测的bcc-fcc相边界虽然低估了相变温度和压力斜率，但与实验相变线具有定性的匹配。这些发现提供了锂复杂多晶型的关键见解，并建立了一种有效的计算方法来模拟更现实条件下锂的大规模原子尺度仿真，以支持实际能源存储应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1039/D4TA08860C&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the phase stability of elemental lithium (Li) is crucial foroptimizing its performance in lithium-metal battery anodes, yet this seeminglysimple metal exhibits complex polymorphism that requires proper accounting forquantum and anharmonic effects to capture the subtleties in its flat energylandscape. Here we address this challenge by developing an accurate graphneural network-based machine learning force field and performing efficientself-consistent phonon calculations for bcc-, fcc-, and 9R-Li undernear-ambient conditions, incorporating quantum, phonon renormalization andthermal expansion effects. Our results reveal the important role ofanharmonicity in determining Li's thermodynamic properties. The free energydifferences between these phases, particularly fcc- and 9R-Li are found to beonly a few meV/atom, explaining the experimental challenges in obtainingphase-pure samples and suggesting a propensity for stacking faults and relateddefect formation. fcc-Li is confirmed as the ground state at zero temperatureand pressure, and the predicted bcc-fcc phase boundary qualitatively matchesexperimental phase transition lines, despite overestimation of the transitiontemperature and pressure slope. These findings provide crucial insights intoLi's complex polymorphism and establish an effective computational approach forlarge-scale atomistic simulations of Li in more realistic settings forpractical energy storage applications.</description>
      <author>example@mail.com (Yiheng Shen, Wei Xie)</author>
      <guid isPermaLink="false">2502.15190v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PFSD: A Multi-Modal Pedestrian-Focus Scene Dataset for Rich Tasks in Semi-Structured Environments</title>
      <link>http://arxiv.org/abs/2502.15342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个新的多模态行人场景数据集PFSD，旨在解决半结构化环境中行人感知和预测的挑战。同时提出了一种新的混合多尺度融合网络(HMFN)，以提高在复杂半结构化环境中的3D行人检测性能。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶感知系统在处理车辆主导的结构化环境时表现出色，但在存在更多动态行人的半结构化环境中表现不佳，这主要是由于高质量数据集的缺乏，特别是在涉及行人场景的数据集中。&lt;h4&gt;目的&lt;/h4&gt;开发一个多模态、全面标注的数据集PFSD，并提出了一种新的方法HMFN来应对半结构化环境中行人检测和预测的问题。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含130,000多个人行实例的PFSD数据集，该数据集在nuScenes格式下对点云进行了详细的分割、检测和对象ID跟踪。此外，提出了一个混合多尺度融合网络(HMFN)，用于处理高密度人群场景中的行人检测问题。&lt;h4&gt;主要发现&lt;/h4&gt;HMFN通过捕获并融合多种规模的特征显著提高了3D行人检测的性能，在PFSD数据集上达到了更高的平均精度(mAP)。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了高质量的数据和先进的算法在解决半结构化环境中行人感知挑战方面的必要性，并为未来的相关工作奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;最近，自主驾驶领域的感知技术取得了显著进展，尤其是在以车辆为主的结构化环境中。然而，目前的感知模型在半结构化的场景中面临重大局限性，特别是在存在动态行人的复杂和多样运动模式以及遮挡情况下表现不佳。我们归因于高质量数据集的缺乏，尤其是关于行人感知的数据集。在此研究中，我们提出了一个多模态行人焦点场景数据集PFSD，在nuScenes格式下为半结构化的场景提供了全面的多模态数据标注，包括点云分割、检测和对象ID用于追踪。该数据集涵盖了超过130,000个在各种情况下捕捉到的行人实例，包括不同的密度、移动模式及遮挡情况。为了证明解决多样且复杂的半结构化环境中的挑战的重要性，我们提出了一种新颖的混合多尺度融合网络(HMFN)。具体而言，在处理高密度人群场景中的行人检测时，我们的方法通过精心设计的混合框架有效捕捉并融合了多种规模的特征，该框架集成了稀疏和常规卷积。在PFSD上的广泛实验表明，HMFN在平均精度(mAP)上优于现有的方法，从而证明其在复杂半结构化环境中3D行人检测方面的有效性。代码和基准测试可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in autonomous driving perception have revealedexceptional capabilities within structured environments dominated by vehiculartraffic. However, current perception models exhibit significant limitations insemi-structured environments, where dynamic pedestrians with more diverseirregular movement and occlusion prevail. We attribute this shortcoming to thescarcity of high-quality datasets in semi-structured scenes, particularlyconcerning pedestrian perception and prediction. In this work, we present themulti-modal Pedestrian-Focused Scene Dataset(PFSD), rigorously annotated insemi-structured scenes with the format of nuScenes. PFSD provides comprehensivemulti-modal data annotations with point cloud segmentation, detection, andobject IDs for tracking. It encompasses over 130,000 pedestrian instancescaptured across various scenarios with varying densities, movement patterns,and occlusions. Furthermore, to demonstrate the importance of addressing thechallenges posed by more diverse and complex semi-structured environments, wepropose a novel Hybrid Multi-Scale Fusion Network (HMFN). Specifically, todetect pedestrians in densely populated and occluded scenarios, our methodeffectively captures and fuses multi-scale features using a meticulouslydesigned hybrid framework that integrates sparse and vanilla convolutions.Extensive experiments on PFSD demonstrate that HMFN attains improvement in meanAverage Precision (mAP) over existing methods, thereby underscoring itsefficacy in addressing the challenges of 3D pedestrian detection in complexsemi-structured environments. Coding and benchmark are available.</description>
      <author>example@mail.com (Yueting Liu, Hanshi Wang, Yunfei Lei, Zhengjun Zha, Weiming Hu, Jin Gao)</author>
      <guid isPermaLink="false">2502.15342v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking machine learning for bowel sound pattern classification from tabular features to pretrained models</title>
      <link>http://arxiv.org/abs/2502.15607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures and 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了电子听诊器和可穿戴记录传感器的发展如何推动了肠鸣音信号的自动化分析，从而通过数据驱动的方法研究肠鸣音模式及其与不同病理的关系。&lt;h4&gt;背景&lt;/h4&gt;随着电子听诊器和可穿戴记录设备的进步，可以自动分析肠鸣音（BS）信号，这为基于数据的研究肠鸣音模式、它们之间的相互关系以及它们与各种疾病的相关性提供了可能性。&lt;h4&gt;目的&lt;/h4&gt;利用来自16名健康受试者的标注良好的BS数据集来评估机器学习模型在检测和/或分类BS模式方面的性能。&lt;h4&gt;方法&lt;/h4&gt;该研究使用了基于表格特征的模型，以光谱图为输入的卷积神经网络（CNN），以及预训练的大规模音频数据集上的模型，并对其进行了性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，特别是对于样本较少的类别的检测任务中，预训练模型表现出了明显的优越性。使用HuBERT模型在区分肠鸣音信号和非肠鸣音信号上实现了AUC为0.89；使用Wav2Vec 2.0模型在不同肠鸣音模式之间区分时也达到了AUC为0.89。&lt;h4&gt;结论&lt;/h4&gt;这些结果为进一步理解肠鸣音及其潜在的机器学习辅助诊断应用铺平了道路，特别是在胃肠检查方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of electronic stethoscopes and wearable recording sensorsopened the door to the automated analysis of bowel sound (BS) signals. Thisenables a data-driven analysis of bowel sound patterns, their interrelations,and their correlation to different pathologies. This work leverages a BSdataset collected from 16 healthy subjects that was annotated according to fourestablished BS patterns. This dataset is used to evaluate the performance ofmachine learning models to detect and/or classify BS patterns. The selection ofconsidered models covers models using tabular features, convolutional neuralnetworks based on spectrograms and models pre-trained on large audio datasets.The results highlight the clear superiority of pre-trained models, particularlyin detecting classes with few samples, achieving an AUC of 0.89 indistinguishing BS from non-BS using a HuBERT model and an AUC of 0.89 indifferentiating bowel sound patterns using a Wav2Vec 2.0 model. These resultspave the way for an improved understanding of bowel sounds in general andfuture machine-learning-driven diagnostic applications for gastrointestinalexaminations</description>
      <author>example@mail.com (Zahra Mansour, Verena Uslar, Dirk Weyhe, Danilo Hollosi, Nils Strodthoff)</author>
      <guid isPermaLink="false">2502.15607v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>GiGL: Large-Scale Graph Neural Networks at Snapchat</title>
      <link>http://arxiv.org/abs/2502.15054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文介绍了GiGL，一个用于大规模分布式图机器学习的开源库。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNNs）的发展，它们在商业应用中的兴趣日益增长。然而，由于规模挑战，工业界对GNNs的应用仍然落后于研究领域。&lt;h4&gt;目的&lt;/h4&gt;分享Snapchat采用GiGL进行大规模分布式图机器学习的方法和经验。&lt;h4&gt;方法&lt;/h4&gt;开发了GiGL库以解决大型社交数据上的图形ML的规模化问题，并简化内部实践者在建模方面的工作，同时支持与学术界常用的开源GNN建模库（如PyTorch Geometric）的接口。&lt;h4&gt;主要发现&lt;/h4&gt;GiGL已在多个生产环境中使用，在过去的两年中推动了超过35个跨多种业务领域的发布，包括好友推荐、内容推荐和广告领域。&lt;h4&gt;结论&lt;/h4&gt;论文详细描述了GiGL的设计、提供的工具、缩放属性以及在大规模社交图上的应用案例研究，并总结了一些关键经验教训。&lt;h4&gt;翻译&lt;/h4&gt;近期的图机器学习（ML）进展引入了图形神经网络（GNNs），这引发了将这些方法应用于商业规模应用的兴趣。GNNs使根据给定的图结构进行端到端(E2E)模型参数微分学习成为可能，从而优化流行节点、边（链接）和图级任务的目标函数。虽然在新GNN层和训练策略方面取得了迅速的研究创新，但由于大规模图形ML问题所特有的规模挑战，工业界对GNNs的应用明显滞后。在这项工作中，我们分享了Snapchat在培训、推理以及利用GNN时的方法。为此，我们介绍了GiGL（Gigantic Graph Learning），这是一个开源库，旨在使大型分布式图机器学习能够服务于研究人员、ML工程师和实践者的需求。我们在内部使用GiGL来处理GNN工作流程的繁重任务，包括从关系数据库中进行图数据预处理、子图采样、分布式训练、推理以及编排。GiGL的设计目的是清晰地与学术界常用的开源GNN建模库（如PyTorch Geometric）接口，并解决规模和生产化挑战，以使内部实践者能够专注于模型构建。GiGL在多个生产环境中使用，在过去的两年中推动了超过35个跨多种业务领域的发布，包括好友推荐、内容推荐以及广告领域。本工作详细描述了该库的高级设计和工具提供情况，扩展特性，并在各种行业规模图中的实际应用案例研究，以及在大规模社交数据上采用图形ML的关键经验教训。GiGL在https://github.com/snap-research/GiGL开源可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in graph machine learning (ML) with the introduction of GraphNeural Networks (GNNs) have led to a widespread interest in applying theseapproaches to business applications at scale. GNNs enable differentiableend-to-end (E2E) learning of model parameters given graph structure whichenables optimization towards popular node, edge (link) and graph-level tasks.While the research innovation in new GNN layers and training strategies hasbeen rapid, industrial adoption and utility of GNNs has lagged considerably dueto the unique scale challenges that large-scale graph ML problems create. Inthis work, we share our approach to training, inference, and utilization ofGNNs at Snapchat. To this end, we present GiGL (Gigantic Graph Learning), anopen-source library to enable large-scale distributed graph ML to the benefitof researchers, ML engineers, and practitioners. We use GiGL internally atSnapchat to manage the heavy lifting of GNN workflows, including graph datapreprocessing from relational DBs, subgraph sampling, distributed training,inference, and orchestration. GiGL is designed to interface cleanly withopen-source GNN modeling libraries prominent in academia like PyTorch Geometric(PyG), while handling scaling and productionization challenges that make iteasier for internal practitioners to focus on modeling. GiGL is used inmultiple production settings, and has powered over 35 launches across multiplebusiness domains in the last 2 years in the contexts of friend recommendation,content recommendation and advertising. This work details high-level design andtools the library provides, scaling properties, case studies in diversebusiness settings with industry-scale graphs, and several key lessons learnedin employing graph ML at scale on large social data. GiGL is open-sourced athttps://github.com/snap-research/GiGL.</description>
      <author>example@mail.com (Tong Zhao, Yozen Liu, Matthew Kolodner, Kyle Montemayor, Elham Ghazizadeh, Ankit Batra, Zihao Fan, Xiaobin Gao, Xuan Guo, Jiwen Ren, Serim Park, Peicheng Yu, Jun Yu, Shubham Vij, Neil Shah)</author>
      <guid isPermaLink="false">2502.15054v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Realm: Real-Time Line-of-Sight Maintenance in Multi-Robot Navigation with Unknown Obstacles</title>
      <link>http://arxiv.org/abs/2502.15162v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, accepted by IEEE ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的多机器人导航框架，该框架在未知且复杂环境中通过实时点云测量来维护线视（LoS）连接约束。提出了一个基于点云可见性分析的新LoS距离度量方法，并设计了融合函数以确保机器人之间的协作移动和保持LoS连接。&lt;h4&gt;背景&lt;/h4&gt;多机器人系统在复杂环境中的导航需要依赖于机器人之间的通信与相互观测，而以前的研究工作大多是在已知的环境中进行的，难以应用于未知且复杂的场景中。&lt;h4&gt;目的&lt;/h4&gt;研究解决未知复杂环境中多机器人导航问题的方法，并提出一种新的LoS距离度量方法和融合函数来保持机器人的连接性。&lt;h4&gt;方法&lt;/h4&gt;通过实时点云测量直接定义了机器人之间的线视（LoS）约束，利用点云可见性分析技术量化了由于潜在的机器人移动而可能失去LoS的重要性与敏感程度。设计了一个新的融合函数以确保两个机器人之间丢失LoS的需求平衡，并将LoS约束编码到势能函数中。&lt;h4&gt;主要发现&lt;/h4&gt;提出了新颖的基于点云的LoS距离度量方法，能够同时考虑保持连接性和紧急性；设计了一种新的融合功能来处理两台机器人的紧迫感不均衡的问题；实现了结合上述方法的多机器人探索框架，并通过分布式传感和通信确保了未知环境下的持续导航。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架在复杂且未知的环境中，通过点云测量实现LoS约束的有效维护，增强了机器人的合作能力和实时感知能力。此成果对于未来自主系统的开发具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;多机器人系统在复杂环境中的导航需要依靠机器人之间的通信和相互观察来协调并提高态势感知能力。本文研究了未知环境中基于视距（LoS）连接限制的多机器人导航问题，而以前的工作仅限于从已知的环境模型中推导出LoS约束条件，本论文通过实时点云测量直接建立了这些约束，并利用点云可见性分析技术来实现这一点。我们提出了一种新的LoS距离度量方法，该方法可以量化由于潜在的机器人移动而可能失去视距的重要性和敏感性。此外，为了应对两个机器人之间丢失视距时紧迫感不均衡的问题，设计了一个融合功能以捕捉整体紧迫感并生成有利于保持视距的协作运动梯度。&lt;h4&gt;开源链接&lt;/h4&gt;https://github.com/bairuofei/LoS_constrained_navigation&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot navigation in complex environments relies on inter-robotcommunication and mutual observations for coordination and situationalawareness. This paper studies the multi-robot navigation problem in unknownenvironments with line-of-sight (LoS) connectivity constraints. While previousworks are limited to known environment models to derive the LoS constraints,this paper eliminates such requirements by directly formulating the LoSconstraints between robots from their real-time point cloud measurements,leveraging point cloud visibility analysis techniques. We propose a novelLoS-distance metric to quantify both the urgency and sensitivity of losing LoSbetween robots considering potential robot movements. Moreover, to address theimbalanced urgency of losing LoS between two robots, we design a fusionfunction to capture the overall urgency while generating gradients thatfacilitate robots' collaborative movement to maintain LoS. The LoS constraintsare encoded into a potential function that preserves the positivity of theFiedler eigenvalue of the robots' network graph to ensure connectivity.Finally, we establish a LoS-constrained exploration framework that integratesthe proposed connectivity controller. We showcase its applications inmulti-robot exploration in complex unknown environments, where robots canalways maintain the LoS connectivity through distributed sensing andcommunication, while collaboratively mapping the unknown environment. Theimplementations are open-sourced athttps://github.com/bairuofei/LoS_constrained_navigation.</description>
      <author>example@mail.com (Ruofei Bai, Shenghai Yuan, Kun Li, Hongliang Guo, Wei-Yun Yau, Lihua Xie)</author>
      <guid isPermaLink="false">2502.15162v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and efficient machine learning interatomic potentials for finite temperature modeling of molecular crystals</title>
      <link>http://arxiv.org/abs/2502.15530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了机器学习（ML）势能模型在分子晶体计算中的应用，特别是用于准确高效地计算升华焓。通过利用化学和材料科学领域的基础模型以及量子扩散蒙特卡洛基准测试的最新进展，该研究展示了使用少量高质量数据结构生成高精度MLIP的能力。&lt;h4&gt;背景&lt;/h4&gt;机器学习势能（MLIP）在模拟分子晶体方面具有革命性意义，但准确高效地计算升华焓仍面临挑战。现有方法需要大量的高精度参考结构，并且依赖于可能不够可靠的密度泛函理论来产生这些数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够使用较少的数据生成准确的机器学习势能模型的方法，以改进分子晶体在有限温度和压力下的描述能力。&lt;h4&gt;方法&lt;/h4&gt;利用化学和材料科学领域的基础模型以及量子扩散蒙特卡洛（QDMC）基准测试，通过训练数据集中的约200个高质量结构来构建MLIP模型。该框架还考虑了非谐性和核量子效应，并应用于X23数据集。&lt;h4&gt;主要发现&lt;/h4&gt;生成的机器学习势能模型在计算升华焓时达到了次化学精度水平，甚至可以推广到具有药物相关性的晶体系统中，准确捕捉核量子效应（如对天青酸的研究）。&lt;h4&gt;结论&lt;/h4&gt;这项工作为研究药理学和生物学系统的环境条件下的精确模拟铺平了道路。通过减少所需的数据量，它不仅提高了计算效率，还提供了关于药物分子稳定性的重要见解。&lt;h4&gt;翻译&lt;/h4&gt;机器学习在模拟分子晶体方面的潜力巨大，但准确计算升华焓仍存在挑战。本文提出了一种新方法，使用更少的高质量数据结构生成精确的MLIP模型，并通过X23数据集验证了该框架的有效性及对药物相关系统的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As with many parts of the natural sciences, machine learning interatomicpotentials (MLIPs) are revolutionizing the modeling of molecular crystals.However, challenges remain for the accurate and efficient calculation ofsublimation enthalpies - a key thermodynamic quantity measuring the stabilityof a molecular crystal. Specifically, two key stumbling blocks are: (i) theneed for thousands of ab initio quality reference structures to generatetraining data; and (ii) the sometimes unreliable nature of density functionaltheory, the main technique for generating such data. Exploiting recentdevelopments in foundational models for chemistry and materials sciencealongside accurate quantum diffusion Monte Carlo benchmarks, offers a promisingpath forward. Herein, we demonstrate the generation of MLIPs capable ofdescribing molecular crystals at finite temperature and pressure withsub-chemical accuracy, using as few as $\sim 200$ data structures; an order ofmagnitude improvement over the current state-of-the-art. We apply thisframework to compute the sublimation enthalpies of the X23 dataset, accountingfor anharmonicity and nuclear quantum effects, achieving sub-chemical accuracywith respect to experiment. Importantly, we show that our framework can begeneralized to crystals of pharmaceutical relevance, including paracetamol andaspirin. Nuclear quantum effects are also accurately captured as shown for thecase of squaric acid. By enabling accurate modeling at ambient conditions, thiswork paves the way for deeper insights into pharmaceutical and biologicalsystems.</description>
      <author>example@mail.com (Flaviano Della Pia, Benjamin X. Shi, Venkat Kapil, Andrea Zen, Dario Alfè, Angelos Michaelides)</author>
      <guid isPermaLink="false">2502.15530v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Android Malware Detection: Rethinking the Role of Traditional and Deep Learning Models</title>
      <link>http://arxiv.org/abs/2502.15041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文系统地评估了Android恶意软件检测模型，比较了传统的机器学习和深度学习方法在不同数据集上的表现。&lt;h4&gt;背景&lt;/h4&gt;近年来，使用传统机器学习（ML）和深度学习（DL）技术对Android恶意软件进行检测的研究得到了广泛的关注。然而，尽管基于DL的方法声称具有优越的性能，它们往往依赖于有限的对比测试，并且缺乏与传统ML模型在多样化数据集上的全面基准比较。&lt;h4&gt;目的&lt;/h4&gt;通过使用四个不同数据集来评估不同的Android恶意软件检测模型（包括传统的随机森林和CatBoost以及先进的Capsule Graph Neural Networks等），论文旨在探讨各种模型的表现，并为未来的研究提供更加全面的基准测试。&lt;h4&gt;方法&lt;/h4&gt;该研究实施了一系列传统机器学习模型，如Random Forests (RF) 和 CatBoost，同时对比了先进的深度学习模型，例如CapsGNN、BERT和ExcelFormer等。使用的数据集包括三个最近发布的公开可用的数据集以及一个大规模的数据集（作者系统地收集的）。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，尽管高级DL模型可以实现强大的性能，但它们通常只与少量的传统ML基线进行比较。在许多情况下，更简单且计算效率更高的传统ML模型实现了可比甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;论文强调了Android恶意软件检测研究中需要更加严格基准测试的重要性，并建议未来的研究应进行全面的对比研究以确保对检测能力的准确评估。此外，为促进进一步的研究，作者提供了其数据集的访问权限。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Android malware detection has been extensively studied using both traditionalmachine learning (ML) and deep learning (DL) approaches. While manystate-of-the-art detection models, particularly those based on DL, claimsuperior performance, they often rely on limited comparisons, lackingcomprehensive benchmarking against traditional ML models across diversedatasets. This raises concerns about the robustness of DL-based approaches'performance and the potential oversight of simpler, more efficient ML models.In this paper, we conduct a systematic evaluation of Android malware detectionmodels across four datasets: three recently published, publicly availabledatasets and a large-scale dataset we systematically collected. We implement arange of traditional ML models, including Random Forests (RF) and CatBoost,alongside advanced DL models such as Capsule Graph Neural Networks (CapsGNN),BERT-based models, and ExcelFormer based models. Our results reveal that whileadvanced DL models can achieve strong performance, they are often comparedagainst an insufficient number of traditional ML baselines. In many cases,simpler and more computationally efficient ML models achieve comparable or evensuperior performance. These findings highlight the need for rigorousbenchmarking in Android malware detection research. We encourage future studiesto conduct more comprehensive benchmarking comparisons between traditional andadvanced models to ensure a more accurate assessment of detection capabilities.To facilitate further research, we provide access to our dataset, including appIDs, hash values, and labels.</description>
      <author>example@mail.com (Guojun Liu, Doina Caragea, Xinming Ou, Sankardas Roy)</author>
      <guid isPermaLink="false">2502.15041v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Data Scarcity in Time Series Analysis: A Foundation Model with Series-Symbol Data Generation</title>
      <link>http://arxiv.org/abs/2502.15466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个针对时间序列分析（TSA）的数据生成机制和预训练模型，旨在克服数据稀缺性和不平衡的问题。&lt;h4&gt;背景&lt;/h4&gt;在时间序列分析领域，基础模型正受到越来越多的关注。然而，由于数据稀缺和数据不平衡等问题的存在，其发展受到了阻碍。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，研究者们提出了一种新的方法来建模复杂系统，并引入了一系列-符号（S2）双模式数据生成机制。&lt;h4&gt;方法&lt;/h4&gt;通过这种机制，可以无限制地创建高质量的时间序列数据并配以相应的符号表示。基于这些数据，他们开发了SymTime预训练基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;SymTime在五个主要时间序列分析任务中表现出竞争力，并且其性能与直接用真实世界数据集进行预训练的基础模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了双模态数据生成和预训练机制在克服数据稀缺性、提升任务性能方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;基础模型用于时间序列分析（TSA）吸引了大量的关注。然而，诸如数据稀缺和不平衡等问题依然阻碍着其发展。为解决这些问题，我们考虑通过符号表达式来建模复杂系统，这些符号表达式可以作为时间序列的语义描述符。在此基础上，我们引入了一种系列-符号（S2）双模式性数据生成机制，能够无限制地创建高质量的时间序列数据及其相应的符号表示。利用S2数据集，我们开发了SymTime，这是一个为TSA设计的预训练基础模型。当在下游任务中进行微调时，SymTime在五个主要TSA任务中的表现是竞争性的，并且其性能可以与直接基于真实世界数据集预训练的基础模型相媲美。这种方法强调了双模态数据生成和预训练机制在克服数据稀缺性和提升任务性能方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for time series analysis (TSA) have attracted significantattention. However, challenges such as data scarcity and data imbalancecontinue to hinder their development. To address this, we consider modelingcomplex systems through symbolic expressions that serve as semantic descriptorsof time series. Building on this concept, we introduce a series-symbol (S2)dual-modulity data generation mechanism, enabling the unrestricted creation ofhigh-quality time series data paired with corresponding symbolicrepresentations. Leveraging the S2 dataset, we develop SymTime, a pre-trainedfoundation model for TSA. SymTime demonstrates competitive performance acrossfive major TSA tasks when fine-tuned with downstream task, rivaling foundationmodels pre-trained on real-world datasets. This approach underscores thepotential of dual-modality data generation and pretraining mechanisms inovercoming data scarcity and enhancing task performance.</description>
      <author>example@mail.com (Wenxuan Wang, Kai Wu, Yujian Betterest Li, Dan Wang, Xiaoyu Zhang, Jing Liu)</author>
      <guid isPermaLink="false">2502.15466v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Graph in the Vault: Protecting Edge GNN Inference with Trusted Execution Environment</title>
      <link>http://arxiv.org/abs/2502.15012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is accepted by DAC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为GNNVault的安全策略，用于在边缘设备上部署基于TEE的图神经网络模型。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在边缘设备上的广泛应用使得其知识产权和数据隐私面临威胁。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于TEE的解决方案来保护图神经网络(GNN)模型及其使用的私有图形数据的安全性。&lt;h4&gt;方法&lt;/h4&gt;GNNVault采用'训练前划分'的设计理念，并结合了私人GNN校正器与公共骨干模型。在推理过程中，重要的GNN参数和使用到的私有图表均被安全地隔离在TEE中。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的应用（例如Intel SGX环境）证明，GNNVault能够有效防御最先进的链接盗窃攻击，并且对精度的影响微乎其微（小于2%）。&lt;h4&gt;结论&lt;/h4&gt;提出的GNNVault方案为保护部署于边缘设备上的图神经网络模型提供了一种新颖而有效的安全机制。&lt;h4&gt;翻译&lt;/h4&gt;广泛地在边缘设备上部署机器学习模型已经使得这些模型的知识产权和数据隐私变得脆弱。我们提出了基于可信执行环境(TEE)的第一个安全图形神经网络(GNN)部署策略，称为GNNVault。该策略遵循'训练前划分'的设计理念，并且包括了一个私人GNN校正器来补充公共骨干模型。通过这种方式，在推理过程中使用的关键性GNN模型参数和私有图都被保护在安全的TEE隔间中。基于Intel SGX的真实世界实现表明，GNNVault可以有效地抵御最先进的链接盗窃攻击，同时不会导致精度显著下降（小于2%）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wide deployment of machine learning models on edge devices has rendered themodel intellectual property (IP) and data privacy vulnerable. We proposeGNNVault, the first secure Graph Neural Network (GNN) deployment strategy basedon Trusted Execution Environment (TEE). GNNVault follows the design of'partition-before-training' and includes a private GNN rectifier to complementwith a public backbone model. This way, both critical GNN model parameters andthe private graph used during inference are protected within secure TEEcompartments. Real-world implementations with Intel SGX demonstrate thatGNNVault safeguards GNN inference against state-of-the-art link stealingattacks with negligible accuracy degradation (&lt;2%).</description>
      <author>example@mail.com (Ruyi Ding, Tianhong Xu, Aidong Adam Ding, Yunsi Fei)</author>
      <guid isPermaLink="false">2502.15012v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Synth It Like KITTI: Synthetic Data Generation for Object Detection in Driving Scenarios</title>
      <link>http://arxiv.org/abs/2502.15076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, to appear in ROBOVIS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文旨在通过改进仿真数据集生成流程，提高从虚拟环境到真实世界场景的自主驾驶系统物体检测模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在推进自动驾驶系统的进程中，模拟技术是一个重要因素。然而，目前尚无显著进展解决虚拟与现实之间转换的问题，特别是在基于LiDAR点云进行3D目标检测方面。&lt;h4&gt;目的&lt;/h4&gt;该研究重新审视了从仿真数据到真实世界应用的转化问题，并提出了一种新的数据集生成管道以增强模型在真实环境中的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;采用CARLA模拟器，结合领域随机化策略和细致建模技术来训练基于合成数据的目标检测模型。同时对比不同虚拟传感器变体，探究哪些传感器属性是导致域间隙的主要因素。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用少量真实世界的数据进行微调，该模型几乎可以达到基准性能；而当使用完整的真实训练集时，则能够超过基准表现。&lt;h4&gt;结论&lt;/h4&gt;利用精心设计的模拟数据生成流程和领域随机化策略可以使仿真训练的目标检测器在现实世界的任务中表现出色。进一步的研究应该集中在如何最小化传感器属性差异，以进一步提高模型的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：推动自动驾驶系统发展的关键因素之一是模拟技术的应用。然而，在虚拟环境向真实世界场景迁移的问题上进展甚微。我们重新审视了针对基于LiDAR点云进行3D物体检测任务中的领域转移问题，提出了一种基于CARLA仿真器的生成数据集管道。通过采用领域随机化策略和精心建模方法，我们在合成数据上训练了一个目标探测器，并展示了其在KITTI数据集上的强大泛化能力。此外，我们对比了不同虚拟传感器变体以获得洞见，哪些传感器特性可能造成显著的域间隙现象。最后，在少量真实世界数据的基础上进行微调几乎可以达到基准性能水平；而使用完整的真实训练集时则超过了该基准线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important factor in advancing autonomous driving systems is simulation.Yet, there is rather small progress for transferability between the virtual andreal world. We revisit this problem for 3D object detection on LiDAR pointclouds and propose a dataset generation pipeline based on the CARLA simulator.Utilizing domain randomization strategies and careful modeling, we are able totrain an object detector on the synthetic data and demonstrate stronggeneralization capabilities to the KITTI dataset. Furthermore, we comparedifferent virtual sensor variants to gather insights, which sensor attributescan be responsible for the prevalent domain gap. Finally, fine-tuning with asmall portion of real data almost matches the baseline and with the fulltraining set slightly surpasses it.</description>
      <author>example@mail.com (Richard Marcus, Christian Vogel, Inga Jatzkowski, Niklas Knoop, Marc Stamminger)</author>
      <guid isPermaLink="false">2502.15076v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning</title>
      <link>http://arxiv.org/abs/2502.15436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Raghav Singhal and Kaustubh Ponkshe contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Fed-SB，一种使用LoRA-SB方法进行联邦微调的新颖方式。该方法通过学习两个适配器之间的小型正方形矩阵来优化低秩适应过程，并直接平均该矩阵以减少通信成本和保证精确更新。&lt;h4&gt;背景&lt;/h4&gt;低秩适应（LoRA）已成为有效调整基础模型的普遍技术，但使用LoRA进行联邦微调存在挑战，因为传统的个体适配器平均方法会导致次优更新。现有解决方案要么导致高昂的通信成本，要么由于表达能力受限而性能下降。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的联邦微调方法，既能减少通信开销又能保证高性能。&lt;h4&gt;方法&lt;/h4&gt;提出Fed-SB，该方法基于最近提出的LoRA-SB低秩适应技术。在两个适配器之间学习一个小型正方形矩阵R，并直接平均这个矩阵以确保精确更新和降低通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;Fed-SB在常识推理、算术推理和语言推断任务上实现了最先进的性能，同时将通信开销最多减少了230倍。此外，在私人设置下，通过减少可训练参数数量来提高隐私保护，并避免其他方法引入的噪声放大问题。&lt;h4&gt;结论&lt;/h4&gt;总体而言，Fed-SB在通信成本与性能之间的权衡中开辟了一个新的帕累托前沿，为私有和非私有的联邦微调提供了高效且可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Lo-Rank 适应（LoRA）已成为有效调整基础模型的标准技术。然而，使用 LoRA 进行联邦细调具有挑战性，因为传统的个体适配器平均会导致次优更新。现有的解决方法要么导致高昂的通信成本，要么由于表达能力受限而降低性能表现。我们介绍了一种新的方法 Fed-SB，它利用了最近提出的低秩适应技术 LoRA-SB 来进行大规模语言模型（LLMs）的联邦细调。LoRA-SB 通过在适配器之间学习一个小方阵矩阵 R，并保持其他组件不变来优化适应过程。直接平均这个小方阵保证了精确更新，大大降低了通信成本，使其不受客户端数量的影响，从而实现了可扩展性。Fed-SB 在常识推理、算术推理和语言推断任务上达到了最先进的性能，同时将通信成本最多减少了230倍。在私人设置中，Fed-SB 通过减少训练参数的数量来提高差分隐私的噪声需求，并避免了其他方法引入的噪声放大问题，进一步提高了表现。总体而言，Fed-SB 在通信和性能之间的权衡上开辟了一个新的帕累托前沿，为私有和非私有的联邦细调提供了高效且可扩展的解决方案。我们的代码公开可用：https://github.com/CERT-Lab/fed-sb。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/CERT-Lab/fed-sb&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuningfoundation models. However, federated fine-tuning using LoRA is challenging dueto suboptimal updates arising from traditional federated averaging ofindividual adapters. Existing solutions either incur prohibitively highcommunication cost that scales linearly with the number of clients or sufferfrom performance degradation due to limited expressivity. We introduceFederated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning ofLLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SBoptimally aligns the optimization trajectory with the ideal low-rank fullfine-tuning projection by learning a small square matrix (R) between adapters Band A, keeping other components fixed. Direct averaging of R guarantees exactupdates, substantially reducing communication cost, which remains independentof the number of clients, and enables scalability. Fed-SB achievesstate-of-the-art performance across commonsense reasoning, arithmeticreasoning, and language inference tasks while reducing communication costs byup to 230x. In private settings, Fed-SB further improves performance by (1)reducing trainable parameters, thereby lowering the noise required fordifferential privacy and (2) avoiding noise amplification introduced by othermethods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoffbetween communication and performance, offering an efficient and scalablesolution for both private and non-private federated fine-tuning. Our code ispublicly available at https://github.com/CERT-Lab/fed-sb.</description>
      <author>example@mail.com (Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Lav R. Varshney, Praneeth Vepakomma)</author>
      <guid isPermaLink="false">2502.15436v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Design Principles of Link Prediction in Directed Settings</title>
      <link>http://arxiv.org/abs/2502.15008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图表示学习中有向链接预测的挑战，提出了适用于该任务的有效启发式方法，并展示了这些改进能够与为无向图设计的最佳图神经网络相媲美。&lt;h4&gt;背景&lt;/h4&gt;传统的图表示学习理论基于对称邻接矩阵假设，即认为数据是无方向性的。然而，现实世界中的关系经常包含通过方向传达的重要信息，这限制了现有模型捕捉复杂有向交互的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决有向链接预测的问题，并提出适用于该任务的有效方法。&lt;h4&gt;方法&lt;/h4&gt;在论文中评估了一些成功应用于无向图的关键启发式算法，然后对其进行了简单但有效的改进以适应有向链接预测的任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列广泛的实验研究，作者开发了一个新颖的框架来解决有向链接预测问题。该框架不仅超过了基线方法，在多个基准上的性能也优于为无向图设计的最佳图神经网络。&lt;h4&gt;结论&lt;/h4&gt;这项工作表明，对现有启发式算法进行简单的调整可以在有向图任务中实现与复杂神经网络模型相竞争的性能，并且这些改进可以提供对图表示学习框架发展的宝贵见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3701716.3717803&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a widely studied task in Graph Representation Learning(GRL) for modeling relational data. The early theories in GRL were based on theassumption of a symmetric adjacency matrix, reflecting an undirected setting.As a result, much of the following state-of-the-art research has continued tooperate under this symmetry assumption, even though real-world data ofteninvolve crucial information conveyed through the direction of relationships.This oversight limits the ability of these models to fully capture thecomplexity of directed interactions. In this paper, we focus on the challengeof directed link prediction by evaluating key heuristics that have beensuccessful in undirected settings. We propose simple but effective adaptationsof these heuristics to the directed link prediction task and demonstrate thatthese modifications produce competitive performance compared to the leadingGraph Neural Networks (GNNs) originally designed for undirected graphs. Throughan extensive set of experiments, we derive insights that inform the developmentof a novel framework for directed link prediction, which not only surpassesbaseline methods but also outperforms state-of-the-art GNNs on multiplebenchmarks.</description>
      <author>example@mail.com (Jun Zhai, Muberra Ozmen, Thomas Markovich)</author>
      <guid isPermaLink="false">2502.15008v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Chitrarth: Bridging Vision and Language for a Billion People</title>
      <link>http://arxiv.org/abs/2502.15392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Chitrarth，这是一个针对印度10种语言的包容性视觉-语言模型。该模型结合了最先进的多语言大型语言模型和视觉模块，并主要在多语言图像文本数据上进行训练。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态基础模型主要是基于英语或高资源欧洲语言的数据集进行训练，这限制了它们在中低资源语言中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一局限性，研究者们引入了一个名为Chitrarth的视觉-语言模型，旨在支持印度丰富的语言多样性及跨10种主要印度语言的视觉推理。&lt;h4&gt;方法&lt;/h4&gt;研究团队使用最先进的多语言大型语言模型与视觉模块相结合的方法，并且这种结合主要是通过在包含多种语言图像文本数据集上进行训练来实现的。&lt;h4&gt;主要发现&lt;/h4&gt;该模型不仅在低资源语言基准测试中取得了最佳结果，同时在英语中的效率也得以保持。此外，他们还提出了BharatBench框架用于评估跨不同印度语言的视觉-语言模型的表现。&lt;h4&gt;结论&lt;/h4&gt;通过这项研究，研究者们旨在为多语种和多模态能力设置新的基准，并为未来的发展提供基础。&lt;h4&gt;翻译&lt;/h4&gt;最近的多种模态基础模型主要是基于英语或高资源欧洲语言的数据进行训练，这限制了它们在中低资源语言中的应用。为了应对这一局限性，我们介绍了Chitrarth（图像：图片；意义：含义），这是一个面向10种主要印度语言的语言多样性及视觉推理问题的目标包容性视觉-语言模型(VLM)。我们的模型有效地集成了最先进的多语言大型语言模型和一个视觉模块，主要是基于多种语言的图文数据进行训练。此外，我们还引入了BharatBench，这个框架用于在不同印度语中评估VLM的表现，最终促进了更加多样化的AI系统的发展。我们的模型在低资源语言基准测试中取得了最佳结果，并保持了其在英语中的效率。通过我们的研究，我们旨在为多语种和多模态能力设立新的基准，并对现有模型进行实质性的改进，从而为基础未来在这个领域的进步奠定基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent multimodal foundation models are primarily trained on English or highresource European language data, which hinders their applicability to othermedium and low-resource languages. To address this limitation, we introduceChitrarth (Chitra: Image; Artha: Meaning), an inclusive Vision-Language Model(VLM), specifically targeting the rich linguistic diversity and visualreasoning across 10 prominent Indian languages. Our model effectivelyintegrates a state-of-the-art (SOTA) multilingual Large Language Model (LLM)with a vision module, primarily trained on multilingual image-text data.Furthermore, we also introduce BharatBench, a comprehensive framework forevaluating VLMs across various Indian languages, ultimately contributing tomore diverse and effective AI systems. Our model achieves SOTA results forbenchmarks across low resource languages while retaining its efficiency inEnglish. Through our research, we aim to set new benchmarks inmultilingual-multimodal capabilities, offering substantial improvements overexisting models and establishing a foundation to facilitate future advancementsin this arena.</description>
      <author>example@mail.com (Shaharukh Khan, Ayush Tarun, Abhinav Ravi, Ali Faraz, Akshat Patidar, Praveen Kumar Pokala, Anagha Bhangare, Raja Kolla, Chandra Khatri, Shubham Agarwal)</author>
      <guid isPermaLink="false">2502.15392v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CrossOver: 3D Scene Cross-Modal Alignment</title>
      <link>http://arxiv.org/abs/2502.15011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: sayands.github.io/crossover/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CrossOver是一种用于多模态3D场景理解的新框架，通过灵活的场景级别模式对齐来解决传统方法需要所有对象实例都具有严格对齐的模式数据的问题。&lt;h4&gt;背景&lt;/h4&gt;当前的方法通常假设完全的数据可用性以及各模式之间的刚性对齐，这在实际应用中可能难以实现。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的框架CrossOver，该框架旨在通过灵活、场景级别的模式对齐进行跨模态3D场景理解，并且无需显式的对象语义即可学习统一的多模式无关嵌入空间。&lt;h4&gt;方法&lt;/h4&gt;利用特定于维度的编码器和多阶段训练管道，CrossOver支持具有缺失模式的数据场景检索和物体定位任务。该框架包括RGB图像、点云、CAD模型、平面图以及文本描述等多种类型的数据输入。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果在ScanNet和3RScan数据集上表现出色，显示了其在各种指标上的优越性能，并强调了适应现实世界应用的能力。&lt;h4&gt;结论&lt;/h4&gt;CrossOver框架展示了它在多模态3D场景理解中的强大能力，尤其是在处理不完整或缺失的模式时的表现。这为未来的研究提供了坚实的基础和新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;跨模式三维物体理解已经获得了相当的关注，然而当前的方法往往假设完全的数据可用性以及各模式之间的刚性对齐。我们提出了一种新的框架CrossOver，该框架通过灵活、场景级别的模式对齐进行跨模态3D场景理解，并且无需显式的对象语义即可学习统一的多模式无关嵌入空间。实验结果在ScanNet和3RScan数据集上表现出色，显示了其适应现实世界应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal 3D object understanding has gained significant attention, yetcurrent approaches often assume complete data availability and rigid alignmentacross all modalities. We present CrossOver, a novel framework for cross-modal3D scene understanding via flexible, scene-level modality alignment. Unliketraditional methods that require aligned modality data for every objectinstance, CrossOver learns a unified, modality-agnostic embedding space forscenes by aligning modalities - RGB images, point clouds, CAD models,floorplans, and text descriptions - with relaxed constraints and withoutexplicit object semantics. Leveraging dimensionality-specific encoders, amulti-stage training pipeline, and emergent cross-modal behaviors, CrossOversupports robust scene retrieval and object localization, even with missingmodalities. Evaluations on ScanNet and 3RScan datasets show its superiorperformance across diverse metrics, highlighting adaptability for real-worldapplications in 3D scene understanding.</description>
      <author>example@mail.com (Sayan Deb Sarkar, Ondrej Miksik, Marc Pollefeys, Daniel Barath, Iro Armeni)</author>
      <guid isPermaLink="false">2502.15011v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation</title>
      <link>http://arxiv.org/abs/2502.15309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种动态、高保真和开放词汇的场景图生成系统（DynamicGSG），用于机器人在不断变化的环境中有效理解和适应。&lt;h4&gt;背景&lt;/h4&gt;现实世界中，环境由于代理或人类活动的变化使得机器人执行长期任务变得非常具有挑战性。感知系统需要提取实例级别的语义信息并根据环境变化更新内存中的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够构建层次化场景图、优化高保真重建以及动态适应长时环境变化的系统。&lt;h4&gt;方法&lt;/h4&gt;{'构造层次化场景图': '使用先进的视觉基础模型来表示环境中对象的空间和语义关系', '设计联合特征损失': '为了增量式地提高高质量重建，优化高斯地图', '更新高斯地图与场景图': '根据实际环境变化进行动态更新'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能实验': '在语义分割、语言引导的对象检索和重建质量方面展示了所提方法的效能。', '真实实验室验证': '验证了系统动态更新能力的有效性'}&lt;h4&gt;结论&lt;/h4&gt;DynamicGSG能够有效提高机器人在复杂多变环境中的适应性和执行长期任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一个叫做DynamicGSG的新提出的用于机器人感知系统的解决方案，它能帮助机器人在不断变化的环境中更高效地理解和工作。该系统主要由三个部分构成：一是使用先进的视觉基础模型构建描述物体空间和语义关系的层次化场景图；二是通过设计联合特征损失来优化高斯地图，以获得增量式的高质量重建效果；三是根据真实环境的变化更新高斯地图和场景图，实现长时间内的环境适应。实验结果表明该方法在关键任务如语义分割、语言引导对象检索以及重建质量方面表现出色，并且其动态更新能力已经在实验室环境中得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world scenarios, the environment changes caused by agents or humanactivities make it extremely challenging for robots to perform variouslong-term tasks. To effectively understand and adapt to dynamic environments,the perception system of a robot needs to extract instance-level semanticinformation, reconstruct the environment in a fine-grained manner, and updateits environment representation in memory according to environment changes. Toaddress these challenges, We propose \textbf{DynamicGSG}, a dynamic,high-fidelity, open-vocabulary scene graph generation system leveragingGaussian splatting. Our system comprises three key components: (1) constructinghierarchical scene graphs using advanced vision foundation models to representthe spatial and semantic relationships of objects in the environment, (2)designing a joint feature loss to optimize the Gaussian map for incrementalhigh-fidelity reconstruction, and (3) updating the Gaussian map and scene graphaccording to real environment changes for long-term environment adaptation.Experiments and ablation studies demonstrate the performance and efficacy ofthe proposed method in terms of semantic segmentation, language-guided objectretrieval, and reconstruction quality. Furthermore, we have validated thedynamic updating capabilities of our system in real laboratory environments.The source code will be releasedat:~\href{https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/DynamicGSG}.</description>
      <author>example@mail.com (Luzhou Ge, Xiangyu Zhu, Zhuo Yang, Xuesong Li)</author>
      <guid isPermaLink="false">2502.15309v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Lung-DDPM: Semantic Layout-guided Diffusion Models for Thoracic CT Image Synthesis</title>
      <link>http://arxiv.org/abs/2502.15204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code and pretrained models are available at  https://github.com/Manem-Lab/Lung-DDPM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种基于AI的胸部CT影像合成方法Lung-DDPM，旨在解决肺癌早期筛查中数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能技术的发展，AI辅助医学影像分析在肺癌早期筛查方面表现出色。然而，高昂的数据标注成本和隐私问题限制了大规模医疗数据集的构建，阻碍了AI在医疗领域的进一步应用。&lt;h4&gt;目的&lt;/h4&gt;为了应对肺癌筛查中的数据稀缺问题，提出了一种胸部CT图像合成方法Lung-DDPM，以生成高质量的3D合成CT影像，并应用于下游肺结节分割任务中。&lt;h4&gt;方法&lt;/h4&gt;该方法基于语义布局引导去噪扩散概率模型（DDPM），能够从不完整的语义布局中生成解剖学合理的、无缝且一致的样本图像。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，Lung-DDPM在图像质量评估和下游肺结节分割任务方面优于其他最先进的生成模型。具体而言，在验证队列中FID为0.0047、MMD为0.0070、MSE为0.0024，分别比第二好的竞争对手高7.4倍、3.1倍和29.5倍。此外，结合真实数据与Lung-DDPM生成的数据训练的肺结节分割模型在Dice系数和敏感性方面分别优于单独使用真实数据模型8.8%和18.6%。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明Lung-DDPM具有更广泛的应用潜力，例如肿瘤分割、癌症生存估计以及风险预测等方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着人工智能（AI）的快速发展，基于AI的医学影像分析在肺癌早期筛查中展现出显著的效果。然而，高昂的数据标注成本和隐私问题限制了大规模医疗数据集的构建，阻碍了AI在医疗领域的进一步应用。为了应对肺癌筛查中的数据稀缺问题，本文提出了一种胸部CT图像合成方法Lung-DDPM，该方法能够有效生成高保真的3D合成CT影像，在下游肺结节分割任务中证明很有帮助。本研究基于语义布局引导去噪扩散概率模型（DDPM），即使从不完整的语义布局也能生成解剖学合理的、无缝且一致的样本图像。实验结果显示，该方法在图像质量评估和下游肺结节分割任务方面优于其他最先进的生成模型。具体而言，在验证队列中分别取得了FID为0.0047、MMD为0.0070以及MSE为0.0024的成绩，并且这些结果分别为第二好的竞争对手的7.4倍、3.1倍和29.5倍更好。此外，结合真实数据与Lung-DDPM生成的数据训练的肺结节分割模型在Dice系数和敏感性方面分别达到了0.3914和0.4393的成绩，比单独使用真实数据模型高8.8%和18.6%。实验结果表明Lung-DDPM具有更广泛的应用潜力，例如肿瘤分割、癌症生存估计以及风险预测等方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of artificial intelligence (AI), AI-assistedmedical imaging analysis demonstrates remarkable performance in early lungcancer screening. However, the costly annotation process and privacy concernslimit the construction of large-scale medical datasets, hampering the furtherapplication of AI in healthcare. To address the data scarcity in lung cancerscreening, we propose Lung-DDPM, a thoracic CT image synthesis approach thateffectively generates high-fidelity 3D synthetic CT images, which prove helpfulin downstream lung nodule segmentation tasks. Our method is based on semanticlayout-guided denoising diffusion probabilistic models (DDPM), enablinganatomically reasonable, seamless, and consistent sample generation even fromincomplete semantic layouts. Our results suggest that the proposed methodoutperforms other state-of-the-art (SOTA) generative models in image qualityevaluation and downstream lung nodule segmentation tasks. Specifically,Lung-DDPM achieved superior performance on our large validation cohort, with aFr\'echet inception distance (FID) of 0.0047, maximum mean discrepancy (MMD) of0.0070, and mean squared error (MSE) of 0.0024. These results were 7.4$\times$,3.1$\times$, and 29.5$\times$ better than the second-best competitors,respectively. Furthermore, the lung nodule segmentation model, trained on adataset combining real and Lung-DDPM-generated synthetic samples, attained adice coefficient (Dice) of 0.3914 and sensitivity of 0.4393. This represents8.8\% and 18.6\% improvements in DICE and sensitivity compared to the modeltrained solely on real samples. The experimental results highlight Lung-DDPM'spotential for a broader range of medical imaging applications, such as generaltumor segmentation, cancer survival estimation, and risk prediction.</description>
      <author>example@mail.com (Yifan Jiang, Yannick Lemaréchal, Josée Bafaro, Jessica Abi-Rjeile, Philippe Joubert, Philippe Després, Venkata Manem)</author>
      <guid isPermaLink="false">2502.15204v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>FacaDiffy: Inpainting Unseen Facade Parts Using Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.14940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for GeoSpatial Week 2025, ISPRS Annals&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了FacaDiffy，这是一种利用个性化稳定扩散模型填补2D冲突地图中未见立面部分的方法，从而提高高精度3D语义建筑重建中的开口位置检测率。&lt;h4&gt;背景&lt;/h4&gt;在创建高细节的三维建筑物模型时，2D冲突图用于识别建筑物外墙上的开口位置。然而，在实际激光扫描过程中，这些2D冲突图由于障碍物的影响往往是不完整的。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来填补2D冲突地图中未见立面部分，并使用个性化稳定扩散模型来完成冲突地图的绘制。&lt;h4&gt;方法&lt;/h4&gt;{'1': '首先提出了一个确定性的光线分析方法，从现有的3D建筑模型和对应的激光扫描点云数据中推导出2D冲突图', '2': '利用个性化稳定扩散模型的能力将未见立面对象填充到这些2D冲突图中。', '3': '为了补充真实世界训练数据的不足，开发了一条可扩展的数据生成流水线，使用随机城市模型生成器和标记后的立面图像来创建合成冲突地图。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，FacaDiffy在与各种填补基线相比时，在2D冲突图完成方面达到了最先进的性能，并且当应用到高精度3D语义建筑重建中时，检测率提高了22%。&lt;h4&gt;结论&lt;/h4&gt;该方法通过个性化稳定扩散模型有效地解决了实际激光扫描过程中遇到的建筑物外墙部分缺失的问题，为高细节三维模型创建提供了强有力的支持。&lt;h4&gt;翻译&lt;/h4&gt;详细摘要的中文翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-detail semantic 3D building models are frequently utilized in robotics,geoinformatics, and computer vision. One key aspect of creating such models isemploying 2D conflict maps that detect openings' locations in building facades.Yet, in reality, these maps are often incomplete due to obstacles encounteredduring laser scanning. To address this challenge, we introduce FacaDiffy, anovel method for inpainting unseen facade parts by completing conflict mapswith a personalized Stable Diffusion model. Specifically, we first propose adeterministic ray analysis approach to derive 2D conflict maps from existing 3Dbuilding models and corresponding laser scanning point clouds. Furthermore, wefacilitate the inpainting of unseen facade objects into these 2D conflict mapsby leveraging the potential of personalizing a Stable Diffusion model. Tocomplement the scarcity of real-world training data, we also develop a scalablepipeline to produce synthetic conflict maps using random city model generatorsand annotated facade images. Extensive experiments demonstrate that FacaDiffyachieves state-of-the-art performance in conflict map completion compared tovarious inpainting baselines and increases the detection rate by $22\%$ whenapplying the completed conflict maps for high-definition 3D semantic buildingreconstruction. The code is be publicly available in the corresponding GitHubrepository: https://github.com/ThomasFroech/InpaintingofUnseenFacadeObjects</description>
      <author>example@mail.com (Thomas Froech, Olaf Wysocki, Yan Xia, Junyu Xie, Benedikt Schwab, Daniel Cremers, Thomas H. Kolbe)</author>
      <guid isPermaLink="false">2502.14940v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>TransMamba: Fast Universal Architecture Adaption from Transformers to Mamba</title>
      <link>http://arxiv.org/abs/2502.15130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了利用现有的Transformer模型如LLaVA、CLIP和DEIT的知识，通过跨架构训练来增强Mamba架构的性能。提出了TransMamba方法，并采用两阶段策略加速新Mamba模型的训练。&lt;h4&gt;背景&lt;/h4&gt;Transformer因其注意力模块在单模态和多模态基础模型中的灵活扩展性而受到青睐，但从头开始为特定任务培训专门的次二次架构既耗时又耗费资源。&lt;h4&gt;目的&lt;/h4&gt;探索如何通过跨架构训练将现有的预训练Transformer模型的知识转移到Mamba架构上，以提升其性能并减少所需的训练时间和计算资源。&lt;h4&gt;方法&lt;/h4&gt;采用两种主要策略：一是引入Weight Subcloning and Adaptive Bidirectional distillation (WSAB) 方法来实现不受层数限制的知识迁移；二是设计了一个跨模态学习模块——cross-Mamba模块，该模块将语言感知与Mamba的视觉特征相结合，从而增强其处理跨模态任务的能力。&lt;h4&gt;主要发现&lt;/h4&gt;TransMamba在使用不到常规从头训练所需75%的数据量的情况下，在各种网络架构和下游任务中（如图像分类、视觉问答、文本视频检索等）表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过将现有的Transformer模型的知识转移到Mamba架构上，可以显著提高后者的性能，并且代码将在未来公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have been favored in both uni-modal and multi-modal foundationmodels for their flexible scalability in attention modules. Consequently, anumber of pre-trained Transformer models, e.g., LLaVA, CLIP, and DEIT, arepublicly available. Recent research has introduced subquadratic architectureslike Mamba, which enables global awareness with linear complexity.Nevertheless, training specialized subquadratic architectures from scratch forcertain tasks is both resource-intensive and time-consuming. As a motivator, weexplore cross-architecture training to transfer the ready knowledge in existingTransformer models to alternative architecture Mamba, termed TransMamba. Ourapproach employs a two-stage strategy to expedite training new Mamba models,ensuring effectiveness in across uni-modal and cross-modal tasks. Concerningarchitecture disparities, we project the intermediate features into an alignedlatent space before transferring knowledge. On top of that, a Weight Subcloningand Adaptive Bidirectional distillation method (WSAB) is introduced forknowledge transfer without limitations on varying layer counts. For cross-modallearning, we propose a cross-Mamba module that integrates language awarenessinto Mamba's visual features, enhancing the cross-modal interactioncapabilities of Mamba architecture. Despite using less than 75% of the trainingdata typically required for training from scratch, TransMamba boastssubstantially stronger performance across various network architectures anddownstream tasks, including image classification, visual question answering,and text-video retrieval. The code will be publicly available.</description>
      <author>example@mail.com (Xiuwei Chen, Sihao Lin, Xiao Dong, Zisheng Chen, Meng Cao, Jianhua Han, Hang Xu, Xiaodan Liang)</author>
      <guid isPermaLink="false">2502.15130v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning</title>
      <link>http://arxiv.org/abs/2502.15082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Vaidehi99/UPCORE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UPCORE是一种用于减轻遗忘过程中附带损害的数据选择框架。该方法通过减少模型在忘记集上的表示方差来最小化模型退化。&lt;h4&gt;背景&lt;/h4&gt;当需要从预训练模型中删除特定信息时，通常会导致模型性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够平衡信息删除和保留模型其他能力的方法，避免因失去平衡导致的模型不可用或效果不佳。&lt;h4&gt;方法&lt;/h4&gt;UPCORE是一种与方法无关的数据选择框架。通过选择性修剪忘记集来减少离群值，以最小化遗忘后的模型退化。&lt;h4&gt;主要发现&lt;/h4&gt;在三种标准删除方法上评估了UPCORE的表现，并引入了一个新的度量标准（AUC），用于衡量其效果优于其他现有技术。&lt;h4&gt;结论&lt;/h4&gt;UPCORE不仅提高了标准指标和AUC的得分，还通过减少负面迁移并利用核心集与修剪点之间的积极迁移效应来增强模型性能。&lt;h4&gt;翻译&lt;/h4&gt;用户规格或法律法规通常要求从预训练模型（包括大型语言模型）中移除信息。这需要删除或“忘记”一组已训练模型中的数据点，通常会导致其在其他数据点上的表现下降。因此，在去除信息和保持模型其余功能之间必须找到平衡，否则可能导致较差的删除效果或不可用的模型。为此，我们提出了UPCORE（Utility-Preserving Coreset Selection），这是一种用于减轻遗忘过程中附带损害的方法无关的数据选择框架。发现模型损坏与忘记集上表示方差相关，通过选择性地修剪该集合来去除离群值从而最小化遗忘后的退化。我们在三种标准删除方法中评估了UPCORE，并始终达到在删除有效性和模型保留之间竞争目标的优越平衡。为了更好地衡量这种权衡，我们引入了一个新的度量指标（AUC），其结果表明UPCORE提高了标准指标和AUC的得分，通过减少负面迁移并利用核心集与修剪点之间的积极迁移效应来增强模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User specifications or legal frameworks often require information to beremoved from pretrained models, including large language models (LLMs). Thisrequires deleting or "forgetting" a set of data points from an already-trainedmodel, which typically degrades its performance on other data points. Thus, abalance must be struck between removing information and keeping the model'sother abilities intact, with a failure to balance this trade-off leading topoor deletion or an unusable model. To this end, we propose UPCORE(Utility-Preserving Coreset Selection), a method-agnostic data selectionframework for mitigating collateral damage during unlearning. Finding that themodel damage is correlated with the variance of the model's representations onthe forget set, we selectively prune the forget set to remove outliers, therebyminimizing model degradation after unlearning. We evaluate UPCORE across threestandard unlearning methods consistently achieving a superior balance betweenthe competing objectives of deletion efficacy and model preservation. To betterevaluate this trade-off, we introduce a new metric, measuring thearea-under-the-curve (AUC) across standard metrics. We find that UPCOREimproves both standard metrics and AUC, benefitting from positive transferbetween the coreset and pruned points while reducing negative transfer from theforget set to points outside of it.</description>
      <author>example@mail.com (Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal)</author>
      <guid isPermaLink="false">2502.15082v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Towards Physics-Guided Foundation Models</title>
      <link>http://arxiv.org/abs/2502.15013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的物理引导基础模型（PGFM），旨在将广泛领域的物理知识集成到传统基础模型中。&lt;h4&gt;背景&lt;/h4&gt;传统的基础模型是通过大规模数据集预训练的，目的是减少微调大量下游任务所需的资源。&lt;h4&gt;目的&lt;/h4&gt;解决传统基础模型在处理分布外预测时的问题，并避免产生不现实或物理上不可行的输出。&lt;h4&gt;方法&lt;/h4&gt;提出将广泛领域的（例如科学领域）通用知识集成到基础模型中的方法，形成物理引导基础模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的基础模型通过大规模数据集进行预训练，以减少在广泛的下游任务中微调所需的资源（如时间、能量和标记样本）。然而，传统的基础模型难以处理分布外预测，并且会产生不现实或物理上不可行的输出。我们提出了物理引导基础模型（PGFM）的概念，即将适用于广泛下游任务的广义或通用领域知识（例如科学领域的知识）集成到基础模型中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional foundation models are pre-trained on broad datasets to reduce thetraining resources (e.g., time, energy, labeled samples) needed for fine-tuninga wide range of downstream tasks. However, traditional foundation modelsstruggle with out-of-distribution prediction and can produce outputs that areunrealistic and physically infeasible. We propose the notation ofphysics-guided foundation models (PGFM), that is, foundation models integratedwith broad or general domain (e.g., scientific) physical knowledge applicableto a wide range of downstream tasks.</description>
      <author>example@mail.com (Majid Farhadloo, Arun Sharma, Mingzhou Yang, Bharat Jayaprakash, William Northrop, Shashi Shekhar)</author>
      <guid isPermaLink="false">2502.15013v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models</title>
      <link>http://arxiv.org/abs/2502.15010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近的版权协议强调了对语言模型复制受版权保护的内容的能力进行精确控制的需求。提出了一种名为Obliviate的新方法，该方法是一种新型的后训练技术，能够选择性地防止特定文本的逐字复制，同时保持语义理解。&lt;h4&gt;背景&lt;/h4&gt;AI公司与内容创作者之间的最近版权协议强调了对语言模型在复制受版权保护的内容时进行精确控制的需求。现有方法依赖于通过去学习或简单输出过滤来完全移除概念。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的后训练技术Obliviate，该技术能够选择性地防止逐字复制特定文本，同时保持语义理解。&lt;h4&gt;方法&lt;/h4&gt;Obliviate通过在记忆序列中选择标记并修改模型的概率分布以防止精确复制来工作，同时维持上下文理解。评估了多个大型语言模型（LLaMA-3.1 8B、LLaMA-3.1-instruct 8B、Qwen-2.5-7B 和 Yi-1.5 6B）在合成记忆任务和有机版权内容上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Obliviate实现了逐字记忆的数个数量级（例如100倍）的减少，同时保持了模型性能与基准线相比仅下降不到1%。这对于解决预训练模型中的版权问题尤其有效，而不损害其通用能力。&lt;h4&gt;结论&lt;/h4&gt;由于在解决语言模型中出现的版权复制风险方面表现出了显著的效果，并且能够在不影响整体功能的情况下大幅度降低逐字记忆的风险，Obliviate非常适合于实际部署场景。&lt;h4&gt;翻译&lt;/h4&gt;最近的版权协议强调了对AI语言模型复制受版权保护内容能力进行精确控制的需求。现有方法依赖完全移除概念或简单输出过滤来解决此问题。然而，这项研究提出了一种名为Obliviate的新后训练技术，该技术能够选择性地防止逐字复现特定文本，同时保持语义理解。通过在大型语言模型上进行了测试，证明了这种方法可以大幅度减少复制风险，而不会影响模型的性能和通用能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent copyright agreements between AI companies and content creators havehighlighted the need for precise control over language models' ability toreproduce copyrighted content. While existing approaches rely on eithercomplete concept removal through unlearning or simple output filtering, wepropose Obliviate, a novel post-training technique that selectively preventsverbatim reproduction of specific text while preserving semantic understanding.  Obliviate operates by selecting tokens within memorized sequences andmodifying the model's probability distribution to prevent exact reproductionwhile maintaining contextual understanding. We evaluate Obliviate on multiplelarge language models (LLaMA-3.1 8B, LLaMA-3.1-instruct 8B, Qwen-2.5-7B, andYi-1.5 6B) across both synthetic memorization tasks and organic copyrightcontent. Our results demonstrate that Obliviate achieves orders of magnitudereduction, e.g., 100x, in verbatim memorization while maintaining modelperformance within 1% of baseline on standard benchmarks (HellaSwag, MMLU,TruthfulQA, and Winogrande). This makes Obliviate particularly suitable forpractical deployment scenarios where companies need to efficiently addresscopyright concerns in pretrained models without compromising their generalcapabilities.</description>
      <author>example@mail.com (Mark Russinovich, Ahmed Salem)</author>
      <guid isPermaLink="false">2502.15010v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Vision Foundation Models in Medical Image Analysis: Advances and Challenges</title>
      <link>http://arxiv.org/abs/2502.14584v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉基础模型在医学图像分割领域适应性的最新研究进展，重点讨论了域适应、模型压缩和联邦学习的挑战，并提出了未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;随着Vision Foundation Models (VFMs)的发展，特别是ViT和SAM模型，在医疗影像分析中的应用显示出卓越的能力。然而，将这些大型模型应用于医学图像分析面临多个挑战，包括医学图像与自然图像之间的领域差异、高效的适应策略需求以及小规模数据集的限制。&lt;h4&gt;目的&lt;/h4&gt;该论文旨在提供关于视觉基础模型在医学图像分割中适应性的最新研究进展的一个全面概述，并指出未来研究的关键领域以推动下一轮创新。&lt;h4&gt;方法&lt;/h4&gt;文章回顾了基于适配器改进的方法、知识蒸馏技术以及多尺度上下文特征建模的发展。&lt;h4&gt;主要发现&lt;/h4&gt;最新的发展包括通过新兴的技术如联邦学习和模型压缩，增强了视觉基础模型在医学图像分析领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;文中强调了VFMs的未来应用前景，并指出了克服现有瓶颈的关键方法。文章呼吁研究者们关注这些领域以推动医疗影像分割技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了Vision Foundation Models (VFMs)迅速发展，特别是在医学图像分析中展示了出色的能力。但是将它们应用于医疗图像存在许多挑战，如领域差异、模型适应策略效率需求和小规模数据集的限制。本文综述了相关最新研究，并提出了未来的研究方向以克服这些瓶颈。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of Vision Foundation Models (VFMs), particularly VisionTransformers (ViT) and Segment Anything Model (SAM), has sparked significantadvances in the field of medical image analysis. These models have demonstratedexceptional capabilities in capturing long-range dependencies and achievinghigh generalization in segmentation tasks. However, adapting these large modelsto medical image analysis presents several challenges, including domaindifferences between medical and natural images, the need for efficient modeladaptation strategies, and the limitations of small-scale medical datasets.This paper reviews the state-of-the-art research on the adaptation of VFMs tomedical image segmentation, focusing on the challenges of domain adaptation,model compression, and federated learning. We discuss the latest developmentsin adapter-based improvements, knowledge distillation techniques, andmulti-scale contextual feature modeling, and propose future directions toovercome these bottlenecks. Our analysis highlights the potential of VFMs,along with emerging methodologies such as federated learning and modelcompression, to revolutionize medical image analysis and enhance clinicalapplications. The goal of this work is to provide a comprehensive overview ofcurrent approaches and suggest key areas for future research that can drive thenext wave of innovation in medical image segmentation.</description>
      <author>example@mail.com (Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang)</author>
      <guid isPermaLink="false">2502.14584v2</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>M2LADS Demo: A System for Generating Multimodal Learning Analytics Dashboards</title>
      <link>http://arxiv.org/abs/2502.15363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in the Workshop on Innovation and Responsibility in  AI-Supported Education (iRAISE25) at AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种基于Web的系统M2LADS，该系统旨在整合、同步并可视化在计算机学习过程中通过生物传感器记录的多模态数据。&lt;h4&gt;目的&lt;/h4&gt;提供详细的生理和活动相关的指标见解，并帮助数据科学家通过综合视图展示参与者的体验以及简化错误活动信息的数据重标记过程。&lt;h4&gt;方法&lt;/h4&gt;使用EEG数据评估注意力和大脑活动，心率指标、眼动追踪数据测量视觉注意，网络摄像头视频录制以及监控任务的日志记录等多模态数据进行可视化。&lt;h4&gt;主要发现&lt;/h4&gt;M2LADS系统能将多种生物信号及视频同步，并通过基于Web的仪表板展示参与者的行为和生理数据，使研究人员能够更详细地了解学习者在不同活动中的表现。&lt;h4&gt;结论&lt;/h4&gt;该系统的使用为教育研究领域提供了新的视角，增强了对计算机辅助学习环境中学生行为和生理状态的理解。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一个名为M2LADS的基于Web的系统（用于生成多模态学习分析仪表板），旨在整合、同步、可视化并分析在使用生物传感器记录计算机辅助学习过程中的多模态数据。该系统在一个Web仪表板上展示了广泛的生物测量和行为数据，提供了对各种生理和活动相关指标的深入了解。可视化的多模态数据包括用于评估注意力和大脑活动的脑电图（EEG）数据、心率指标、通过眼动追踪来衡量视觉关注的数据、网络摄像头视频记录以及监控任务的日志。M2LADS旨在以两种关键方式帮助数据科学家：(1)提供参与者体验的综合视图，将所有数据按参与者的活动进行分类展示；(2)同步所有的生物信号和视频，使在错误活动中更容易重标记数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a demonstration of a web-based system called M2LADS ("System forGenerating Multimodal Learning Analytics Dashboards"), designed to integrate,synchronize, visualize, and analyze multimodal data recorded duringcomputer-based learning sessions with biosensors. This system presents a rangeof biometric and behavioral data on web-based dashboards, providing detailedinsights into various physiological and activity-based metrics. The multimodaldata visualized include electroencephalogram (EEG) data for assessing attentionand brain activity, heart rate metrics, eye-tracking data to measure visualattention, webcam video recordings, and activity logs of the monitored tasks.M2LADS aims to assist data scientists in two key ways: (1) by providing acomprehensive view of participants' experiences, displaying all datacategorized by the activities in which participants are engaged, and (2) bysynchronizing all biosignals and videos, facilitating easier data relabeling ifany activity information contains errors.</description>
      <author>example@mail.com (Alvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Julian Fierrez)</author>
      <guid isPermaLink="false">2502.15363v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Research advances on fish feeding behavior recognition and intensity quantification methods in aquaculture</title>
      <link>http://arxiv.org/abs/2502.15311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了基于计算机视觉、声学和传感器单一模态的鱼类进食行为识别与强度量化方法的研究进展，并探讨了当前新兴多模态融合技术在鱼类进食行为识别与强度量化的应用。&lt;h4&gt;背景&lt;/h4&gt;鱼饲料投喂行为的识别与定量分析是水产养殖管理的关键部分，对于监测鱼类健康、指导饲喂工作和提高水产养殖效率具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;为了更好地进行未来相关研究，本论文回顾了基于单一模态技术（计算机视觉、声学及传感器）的研究进展，并探讨多模态融合在该领域的应用。此外还分析了各种方法的优缺点并展望了未来的研发方向。&lt;h4&gt;方法&lt;/h4&gt;论文首先总结了单模态技术如计算机视觉、声学和传感器技术在此研究领域内的研究成果，随后详细介绍了新兴的多模态融合技术的应用情况。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比分析不同技术的优点与不足之处，揭示未来的研究趋势和方向。&lt;h4&gt;结论&lt;/h4&gt;基于对已有工作的回顾以及当前研究状况的理解，论文认为结合多种数据源和技术手段（特别是多模态方法）来解决鱼类进食行为识别及强度量化问题具有广阔的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a key part of aquaculture management, fish feeding behavior recognitionand intensity quantification has been a hot area of great concern toresearchers, and it plays a crucial role in monitoring fish health, guidingbaiting work and improving aquaculture efficiency. In order to better carry outthe related work in the future, this paper firstly reviews the researchadvances of fish feeding behavior recognition and intensity quantificationmethods based on computer vision, acoustics and sensors in a single modality.Then the application of the current emerging multimodal fusion in fish feedingbehavior recognition and intensity quantification methods is expounded.Finally, the advantages and disadvantages of various techniques are comparedand analyzed, and the future research directions are envisioned.</description>
      <author>example@mail.com (Shulong Zhang, Daoliang Li, Jiayin Zhao, Mingyuan Yao, Yingyi Chen, Yukang Huo, Xiao Liu, Haihua Wang)</author>
      <guid isPermaLink="false">2502.15311v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.15488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的量化感知位置嵌入变换(Q-PETR)方法，以提高多视角3D物体检测模型在INT8推理时的精度。&lt;h4&gt;背景&lt;/h4&gt;PETR系列的方法在3D感知领域占据主导地位，并成为现代自动驾驶系统的关键组件。但是，在需要INT8推理的情况下，这些模型的量化性能显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的量化感知位置嵌入变换方法(Q-PETR)，以解决PETR系列方法在INT8推理时精度下降的问题。&lt;h4&gt;方法&lt;/h4&gt;设计了一种针对多视角3D物体检测任务的量化友好的位置嵌入转换机制，即Q-PETR，它可以在保持原始性能的同时提供更友好的部署环境。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在标准的8位定点后训练量化中，该方法将mAP和NDS下降限制在1%以内。此外，该方法还超过了原PETR模型在浮点精度上的表现，并且具有广泛的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Q-PETR提供了一种同时解决性能和部署问题的有效解决方案，在INT8推理时能够大幅缩小与FP32推理之间的准确度差距。&lt;h4&gt;翻译&lt;/h4&gt;基于PETR的方法已经在3D感知领域占据主导地位，越来越成为现代自动驾驶系统中的关键组件。然而，当需要进行INT8推理时，它们的量化表现显著下降，例如在NuScenes数据集上分别导致了58.2% mAP和36.9% NDS的性能损失。为了解决这一问题，我们提出了一种针对多视角3D物体检测任务的量化感知位置嵌入变换方法(Q-PETR)，它提供了更加友好的量化部署环境同时保持了PETR的原始性能。此外，该方法在标准8位定点后训练量化下大幅缩小了INT8和FP32推理之间的准确度差距，并且在浮点精度上超过了原PETR模型的表现。通过针对多种PETR系列模型进行广泛的实验验证了其泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PETR-based methods have dominated benchmarks in 3D perception and areincreasingly becoming a key component in modern autonomous driving systems.However, their quantization performance significantly degrades when INT8inference is required, with a degradation of 58.2% in mAP and 36.9% in NDS onthe NuScenes dataset. To address this issue, we propose a quantization-awareposition embedding transformation for multi-view 3D object detection, termedQ-PETR. Q-PETR offers a quantizationfriendly and deployment-friendlyarchitecture while preserving the original performance of PETR. Itsubstantially narrows the accuracy gap between INT8 and FP32 inference forPETR-series methods. Without bells and whistles, our approach reduces the mAPand NDS drop to within 1% under standard 8-bit per-tensor post-trainingquantization. Furthermore, our method exceeds the performance of the originalPETR in terms of floating-point precision. Extensive experiments across avariety of PETR-series models demonstrate its broad generalization.</description>
      <author>example@mail.com (Jiangyong Yu, Changyong Shu, Dawei Yang, Zichen Yu, Xing Hu, Yan Chen)</author>
      <guid isPermaLink="false">2502.15488v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.14891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;合作3D物体检测在自动驾驶领域具有重要意义，它通过多代理系统之间的信息交换极大地增强了单个代理的感知能力。&lt;h4&gt;背景&lt;/h4&gt;由于姿态估计误差和时间延迟的影响，在实际应用中，跨多个代理的信息融合通常会导致带有空间和时间噪声的功能表示，并导致检测错误。&lt;h4&gt;目的&lt;/h4&gt;为了应对多代理系统之间存在的噪音问题，我们探索了使用扩散模型来净化嘈杂样本并将其转化为理想数据的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出了CoDiff框架，该框架利用预训练的自编码器的强大潜在空间将高维特征图转换为低维度，并通过条件引导的方式让各个代理的信息指导扩散模型进行采样。这一过程可以去除粗糙特征图中的噪声，并逐步细化融合后的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界数据集上的实验研究表明，所提出的CoDiff框架在合作物体检测性能方面比现有的相关方法更加出色，尤其当代理的姿态信息和延迟带有高水平的噪音时，其表现出高度期望的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;这是首次将扩散模型应用于多代理协作感知的工作。该工作表明了扩散模型解决多代理系统中噪声问题的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了合作3D物体检测在自动驾驶中的重要性，指出当前方法面临的挑战，并提出了一种新的框架CoDiff，利用扩散模型来提高特征表示的质量和清晰度，实验结果证明其优越性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collaborative 3D object detection holds significant importance in the fieldof autonomous driving, as it greatly enhances the perception capabilities ofeach individual agent by facilitating information exchange among multipleagents. However, in practice, due to pose estimation errors and time delays,the fusion of information across agents often results in featurerepresentations with spatial and temporal noise, leading to detection errors.Diffusion models naturally have the ability to denoise noisy samples to theideal data, which motivates us to explore the use of diffusion models toaddress the noise problem between multi-agent systems. In this work, we proposeCoDiff, a novel robust collaborative perception framework that leverages thepotential of diffusion models to generate more comprehensive and clearerfeature representations. To the best of our knowledge, this is the first workto apply diffusion models to multi-agent collaborative perception.Specifically, we project high-dimensional feature map into the latent space ofa powerful pre-trained autoencoder. Within this space, individual agentinformation serves as a condition to guide the diffusion model's sampling. Thisprocess denoises coarse feature maps and progressively refines the fusedfeatures. Experimental study on both simulated and real-world datasetsdemonstrates that the proposed framework CoDiff consistently outperformsexisting relevant methods in terms of the collaborative object detectionperformance, and exhibits highly desired robustness when the pose and delayinformation of agents is with high-level noise.</description>
      <author>example@mail.com (Zhe Huang, Shuo Wang, Yongcai Wang, Lei Wang)</author>
      <guid isPermaLink="false">2502.14891v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Network Resource Optimization for ML-Based UAV Condition Monitoring with Vibration Analysis</title>
      <link>http://arxiv.org/abs/2502.15491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Networking Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着智慧城市的发展，无人飞行器（UAVs）及其可靠性变得越来越重要。本文通过优化基于机器学习的UAV条件监测框架中的网络资源利用来提高其在边缘计算环境下的效率。&lt;h4&gt;背景&lt;/h4&gt;智慧城市的构建推动了对UAV可靠性的需求，其中机器学习模型用于识别异常和不利条件是关键环节之一。&lt;h4&gt;目的&lt;/h4&gt;探索如何最小化下一代边缘网络中珍贵的网络资源使用，并优化基于ML的UAV状态监测框架中的网络资源配置。&lt;h4&gt;方法&lt;/h4&gt;开发了一种利用实验数据并调整特征提取聚合间隔来选择最有效机器学习模型的方法，同时采用维度降低技术减少了99.9%的网络资源消耗。&lt;h4&gt;主要发现&lt;/h4&gt;通过上述方法，在保证准确性的前提下显著降低了网络资源使用量。&lt;h4&gt;结论&lt;/h4&gt;提出的框架能够有效地减少基于ML的UAV状态监测系统所需的网络资源，并提高了在有限资源条件下的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;随着智慧城市的发展，无人飞行器（UAVs）及其可靠性变得越来越重要。本文通过优化基于机器学习的UAV条件监测框架中的网络资源利用来提高其在边缘计算环境下的效率。研究指出，在资源受限的下一代边缘网络环境中，需要尽可能地减少珍贵的网络资源使用量。所提出的方法通过调整特征提取聚合间隔，并采用维度降低技术实现了这一目标，同时保证了模型性能和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As smart cities begin to materialize, the role of Unmanned Aerial Vehicles(UAVs) and their reliability becomes increasingly important. One aspect ofreliability relates to Condition Monitoring (CM), where Machine Learning (ML)models are leveraged to identify abnormal and adverse conditions. Given theresource-constrained nature of next-generation edge networks, the utilizationof precious network resources must be minimized. This work explores theoptimization of network resources for ML-based UAV CM frameworks. The developedframework uses experimental data and varies the feature extraction aggregationinterval to optimize ML model selection. Additionally, by leveragingdimensionality reduction techniques, there is a 99.9% reduction in networkresource consumption.</description>
      <author>example@mail.com (Alexandre Gemayel, Dimitrios Michael Manias, Abdallah Shami)</author>
      <guid isPermaLink="false">2502.15491v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>BOSS: Benchmark for Observation Space Shift in Long-Horizon Task</title>
      <link>http://arxiv.org/abs/2502.15679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于评估观察空间移位（OSS）对长时任务影响的新基准测试BOSS，并展示了几种模仿学习算法在面对此类问题时的性能下降情况。&lt;h4&gt;背景&lt;/h4&gt;视觉伺服机器人旨在完成前所未见的长期任务，而分层方法通过执行由任务计划器安排的技能组合来实现这一目标。然而，在简单如技巧串联的任务中，观察空间移位的问题会破坏单独训练的技能策略的表现。&lt;h4&gt;目的&lt;/h4&gt;提出并验证BOSS基准测试，评估模仿学习算法在面对观察空间移位问题时的性能下降情况，并探索解决OSS的方法。&lt;h4&gt;方法&lt;/h4&gt;引入了BOSS（观察空间移位基准）来衡量和评估观察空间移位对长时任务的影响。BOSS包括三个不同的挑战：单一谓词转移、累积谓词转移和技巧串联，用于测试不同方面的负面影响。此外，作者还测试了几种流行的模仿学习算法在BOSS上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在最简单的挑战下，各种算法性能下降显著，分别为67%，35%，34%和54%。增加训练数据的规模以解决OSS问题的方法并未达到预期效果。&lt;h4&gt;结论&lt;/h4&gt;观察空间移位对长时任务中技能策略的表现具有负面影响，而现有解决方案不足以完全解决这一问题。&lt;h4&gt;翻译&lt;/h4&gt;机器人技术长期以来一直致力于开发能够完成未见过的长期任务的视觉伺服机器人。分层方法通过执行由任务计划器安排的技能组合来实现这个目标，并且每个视觉运动技能都使用特定的模仿学习（IL）算法预先训练。然而，即使在简单的长期任务如技巧串联中，分层方法也常常因观察空间移位问题而难以实现目标。为了验证这一问题并评估其对长期任务的影响，我们引入了BOSS基准测试来衡量这个问题。BOSS包括三个不同的挑战：“单一谓词转移”、“累积谓词转移”和“技巧串联”，每个挑战都旨在评估OSS的负面影响的不同方面。我们在BOSS上评估了几种最近流行的IL算法，其中包括三种行为克隆方法和视觉语言动作模型OpenVLA。即使在最简单的挑战中，我们观察到当技能性能在有无观察空间移位的情况下对比时，平均性能下降分别为67%，35%，34%和54%。此外，我们研究了一种解决OSS的潜在解决方案，即通过使用更大且视觉上更加多样的示例数据集来增加每个技能训练数据的规模，但结果显示这种方法不足以解决问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotics has long sought to develop visual-servoing robots capable ofcompleting previously unseen long-horizon tasks. Hierarchical approaches offera pathway for achieving this goal by executing skill combinations arranged by atask planner, with each visuomotor skill pre-trained using a specific imitationlearning (IL) algorithm. However, even in simple long-horizon tasks like skillchaining, hierarchical approaches often struggle due to a problem we identifyas Observation Space Shift (OSS), where the sequential execution of precedingskills causes shifts in the observation space, disrupting the performance ofsubsequent individually trained skill policies. To validate OSS and evaluateits impact on long-horizon tasks, we introduce BOSS (a Benchmark forObservation Space Shift). BOSS comprises three distinct challenges: "SinglePredicate Shift", "Accumulated Predicate Shift", and "Skill Chaining", eachdesigned to assess a different aspect of OSS's negative effect. We evaluatedseveral recent popular IL algorithms on BOSS, including three BehavioralCloning methods and the Visual Language Action model OpenVLA. Even on thesimplest challenge, we observed average performance drops of 67%, 35%, 34%, and54%, respectively, when comparing skill performance with and without OSS.Additionally, we investigate a potential solution to OSS that scales up thetraining data for each skill with a larger and more visually diverse set ofdemonstrations, with our results showing it is not sufficient to resolve OSS.The project page is: https://boss-benchmark.github.io/</description>
      <author>example@mail.com (Yue Yang, Linfeng Zhao, Mingyu Ding, Gedas Bertasius, Daniel Szafir)</author>
      <guid isPermaLink="false">2502.15679v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>VaViM and VaVAM: Autonomous Driving through Video Generative Modeling</title>
      <link>http://arxiv.org/abs/2502.15672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and model: https://github.com/valeoai/VideoActionModel, project  page: https://valeoai.github.io/vavim-vavam/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了大规模生成式视频模型在自动驾驶中的潜力，介绍了开源的自回归视频模型（VaViM）和其辅助视频动作模型（VaVAM），以探索视频预训练如何应用于实际驾驶。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的发展，视频生成技术被引入到自动驾驶领域，特别是在理解和预测复杂的动态场景方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;研究的目的是通过开发新的视频预训练模型来提升自动驾驶系统在真实世界中的表现和安全性。&lt;h4&gt;方法&lt;/h4&gt;VaViM是一个简单的自回归视频模型，通过时空令牌序列预测帧；VaVAM则利用VaViM学习到的表示生成驾驶轨迹。两个模型共同形成了从感知到动作的完整管道，并且研究者们对其进行了开放循环和闭环驾驶场景评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，基于视频的预训练对于自动驾驶具有前景，包括所学表示的语义丰富性、视频合成中规模效应的好处以及在闭环评估中的模型大小与数据之间的复杂关系及其对安全度量的影响。&lt;h4&gt;结论&lt;/h4&gt;通过发布代码和模型权重，研究团队希望促进相关领域的进一步发展，并鼓励其他研究人员探索该方向的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们探讨了大规模生成式视频模型在自主驾驶中的潜力，介绍了开源自回归视频模型（VaViM）及其辅助动作视频模型（VaVAM），以探究视频预训练如何应用于现实世界的自动驾驶。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We explore the potential of large-scale generative video models forautonomous driving, introducing an open-source auto-regressive video model(VaViM) and its companion video-action model (VaVAM) to investigate how videopre-training transfers to real-world driving. VaViM is a simple auto-regressivevideo model that predicts frames using spatio-temporal token sequences. We showthat it captures the semantics and dynamics of driving scenes. VaVAM, thevideo-action model, leverages the learned representations of VaViM to generatedriving trajectories through imitation learning. Together, the models form acomplete perception-to-action pipeline. We evaluate our models in open- andclosed-loop driving scenarios, revealing that video-based pre-training holdspromise for autonomous driving. Key insights include the semantic richness ofthe learned representations, the benefits of scaling for video synthesis, andthe complex relationship between model size, data, and safety metrics inclosed-loop evaluations. We release code and model weights athttps://github.com/valeoai/VideoActionModel</description>
      <author>example@mail.com (Florent Bartoccioni, Elias Ramzi, Victor Besnier, Shashanka Venkataramanan, Tuan-Hung Vu, Yihong Xu, Loick Chambon, Spyros Gidaris, Serkan Odabas, David Hurych, Renaud Marlet, Alexandre Boulch, Mickael Chen, Éloi Zablocki, Andrei Bursuc, Eduardo Valle, Matthieu Cord)</author>
      <guid isPermaLink="false">2502.15672v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network</title>
      <link>http://arxiv.org/abs/2502.15662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于技能-环境贝叶斯网络(SEBN)的方法，以减少强化学习训练时间或提高目标任务的性能。&lt;h4&gt;背景&lt;/h4&gt;在强化学习中，自动生成课程以减少训练时间和提升性能是主要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;通过使用SEBN模型来预测代理在各种任务上的表现，并根据这些预测来加权可能的任务，从而开发一种算法来优化课程设置。&lt;h4&gt;方法&lt;/h4&gt;利用SEBN模型对代理成功概率的推断估计来评估下一个潜在任务的预期改进。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在三种不同环境中（离散格子世界、连续控制和模拟机器人）使用SEBN构建的课程比其他基准线更有效。&lt;h4&gt;结论&lt;/h4&gt;通过将技能与环境特征及奖励结构相关联，SEBN能够预测代理在各种任务上的表现并优化学习过程中的课程设置。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了SEBN模型及其用于减少训练时间和提升性能的方法，并展示了它优于传统基线的实验结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenge for reinforcement learning is automatically generatingcurricula to reduce training time or improve performance in some target task.We introduce SEBNs (Skill-Environment Bayesian Networks) which model aprobabilistic relationship between a set of skills, a set of goals that relateto the reward structure, and a set of environment features to predict policyperformance on (possibly unseen) tasks. We develop an algorithm that uses theinferred estimates of agent success from SEBN to weigh the possible next tasksby expected improvement. We evaluate the benefit of the resulting curriculum onthree environments: a discrete gridworld, continuous control, and simulatedrobotics. The results show that curricula constructed using SEBN frequentlyoutperform other baselines.</description>
      <author>example@mail.com (Vincent Hsiao, Mark Roberts, Laura M. Hiatt, George Konidaris, Dana Nau)</author>
      <guid isPermaLink="false">2502.15662v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A Simulation Pipeline to Facilitate Real-World Robotic Reinforcement Learning Applications</title>
      <link>http://arxiv.org/abs/2502.15649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to be presented at IEEE SysCon 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种帮助减少仿真与现实差距、促进在真实世界机器人系统中开发和部署强化学习策略的流水线。&lt;h4&gt;背景&lt;/h4&gt;强化学习（RL）在解决复杂任务方面取得成功，特别是在机器人应用领域。然而，在物理机器人上实现它仍然充满挑战性，主要是由于安全风险和高昂的训练成本。为了解决这些问题，通常是在模拟器中训练RL代理，这又引入了关于仿真与现实之间差距的新问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种流水线来帮助减少仿真实验到现实操作之间的差距，并促进强化学习策略在实际机器人系统中的开发和部署。&lt;h4&gt;方法&lt;/h4&gt;该流程将RL的培训过程组织为初始的系统识别阶段，以及三个训练阶段：核心仿真培训、高保真仿真，然后是实地部署。每个阶段都会增加现实感的程度以减少模拟到真实之间的差距，并且通过迭代传递并改进策略来逐步达到所需性能。&lt;h4&gt;主要发现&lt;/h4&gt;该流水线的有效性在一项案例研究中得到证明，在这项研究中使用了Boston Dynamics Spot移动机器人执行监控应用。&lt;h4&gt;结论&lt;/h4&gt;提出的RL流程展示了通过各个阶段如何逐渐减少仿真与现实之间的差距，使开发的策略能够成功部署于真实环境中的机器人系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has gained traction for its success in solvingcomplex tasks for robotic applications. However, its deployment on physicalrobots remains challenging due to safety risks and the comparatively high costsof training. To avoid these problems, RL agents are often trained onsimulators, which introduces a new problem related to the gap betweensimulation and reality. This paper presents an RL pipeline designed to helpreduce the reality gap and facilitate developing and deploying RL policies forreal-world robotic systems. The pipeline organizes the RL training process intoan initial step for system identification and three training stages: coresimulation training, high-fidelity simulation, and real-world deployment, eachadding levels of realism to reduce the sim-to-real gap. Each training stagetakes an input policy, improves it, and either passes the improved policy tothe next stage or loops it back for further improvement. This iterative processcontinues until the policy achieves the desired performance. The pipeline'seffectiveness is shown through a case study with the Boston Dynamics Spotmobile robot used in a surveillance application. The case study presents thesteps taken at each pipeline stage to obtain an RL agent to control the robot'sposition and orientation.</description>
      <author>example@mail.com (Jefferson Silveira, Joshua A. Marshall, Sidney N. Givigi Jr)</author>
      <guid isPermaLink="false">2502.15649v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Reduced-Order Model Guided Contact-Implicit Model Predictive Control for Humanoid Locomotion</title>
      <link>http://arxiv.org/abs/2502.15630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种结合简化的混合线性倒立摆模型（HLIP）和接触隐式模型预测控制（CI-MPC）优点的控制框架，旨在提高人形机器人的灵活性和实用性。&lt;h4&gt;背景&lt;/h4&gt;人形机器人在人类环境中操作具有巨大的应用潜力，但由于高维度非线性混合动力学的复杂性，部署面临挑战。虽然HLIP简化了模型，但丧失了全身表达能力；而CI-MPC能够处理多种接触模式下的规划问题，但仍存在局部最优和大量调优需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合HLIP与CI-MPC优点的新控制框架，以克服当前方法的局限性，并增强人形机器人的适应性和实用性。&lt;h4&gt;方法&lt;/h4&gt;该框架利用HLIP生成名义步态模式，同时使用CI-MPC处理全身动力学并根据需要调整接触序列。实验在24自由度的人形机器人Achilles上进行模拟测试。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的控制框架能够在粗糙地形行走、恢复外部干扰后的稳定性以及面对模型和状态不确定性时保持鲁棒性，同时能够与环境中的障碍物互动，并且以50Hz的频率实现实时在线运行。&lt;h4&gt;结论&lt;/h4&gt;结合HLIP和CI-MPC的优点可以显著提升人形机器人在复杂环境下的控制性能和适应能力。该框架为未来的人形机器人开发提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;人形机器人的潜在应用领域因它们能在为人设计的环境中操作而广受期待，但其部署受到管理高维度非线性混合动力学挑战的影响。虽然简化的模型如HLIP简单且计算效率高，但这些模型缺乏全身表达能力。最近在CI-MPC上的进展使机器人能够通过多个混合接触模式进行规划，但仍容易陷入局部最优，并需要大量的调优工作。我们提出了一种结合HLIP和CI-MPC优点的控制框架：简化的模型产生名义步态，而CI-MPC管理全身动力学并根据需要调整接触安排。我们在模拟中使用一个新型24自由度的人形机器人Achilles展示了这种方法的有效性。我们的方法实现了粗糙地形行走、干扰恢复能力，在面对模型和状态不确定性时保持鲁棒性，并且能够与环境中的障碍物互动，所有这一切都在实时在线环境中以50Hz的频率运行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots have great potential for real-world applications due to theirability to operate in environments built for humans, but their deployment ishindered by the challenge of controlling their underlying high-dimensionalnonlinear hybrid dynamics. While reduced-order models like the Hybrid LinearInverted Pendulum (HLIP) are simple and computationally efficient, they losewhole-body expressiveness. Meanwhile, recent advances in Contact-Implicit ModelPredictive Control (CI-MPC) enable robots to plan through multiple hybridcontact modes, but remain vulnerable to local minima and require significanttuning. We propose a control framework that combines the strengths of HLIP andCI-MPC. The reduced-order model generates a nominal gait, while CI-MPC managesthe whole-body dynamics and modifies the contact schedule as needed. Wedemonstrate the effectiveness of this approach in simulation with a novel 24degree-of-freedom humanoid robot: Achilles. Our proposed framework achievesrough terrain walking, disturbance recovery, robustness under model and stateuncertainty, and allows the robot to interact with obstacles in theenvironment, all while running online in real-time at 50 Hz.</description>
      <author>example@mail.com (Sergio A. Esteban, Vince Kurtz, Adrian B. Ghansah, Aaron D. Ames)</author>
      <guid isPermaLink="false">2502.15630v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Pick-and-place Manipulation Across Grippers Without Retraining: A Learning-optimization Diffusion Policy Approach</title>
      <link>http://arxiv.org/abs/2502.15613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Video and code are available at https://github.com/yaoxt3/GADP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于扩散的策略和混合学习优化框架，使机器人能在零样本条件下适应新的夹爪配置。&lt;h4&gt;背景&lt;/h4&gt;当前大多数抓取放置策略需要在训练和推理阶段保持一致的夹爪设置，这会导致高昂的成本，特别是在使用模仿学习方法时。当要适应新类型的末端执行器（即夹爪）时，这一问题尤为突出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略以减少为适应不同夹爪而进行额外训练或微调的需求。&lt;h4&gt;方法&lt;/h4&gt;利用基于扩散的优化策略，在推理阶段动态地强制执行机械和安全约束。通过这种受限的去噪过程，该策略能够根据具体的夹爪参数（如工具中心点偏移量、颚宽）调整轨迹，同时确保碰撞避免和任务可行性。&lt;h4&gt;主要发现&lt;/h4&gt;在六种不同的夹爪配置上进行实验验证后，提出的方法实现了93.3%的平均任务成功率，而扩散政策基线方法的成功率仅为23.3-26.7%。该策略支持工具中心点偏移量从16至23.5厘米以及颚宽从7.5到11.5厘米的变化。&lt;h4&gt;结论&lt;/h4&gt;通过引入受限的扩散过程，可以实现跨夹爪操作的鲁棒性，并且保持了模仿学习方法的样本效率。这消除了针对特定夹爪进行重新训练的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的具体中文翻译：当前抓取放置策略通常需要在训练和推理阶段维持一致的机械臂末端执行器设置，这一要求导致了高成本的再训练或微调需求，特别是在基于模仿学习的方法中。为解决这个问题，我们提出了一种扩散式的策略结合混合学习优化框架，使得机器人可以无须额外的数据收集便能在新的夹爪上进行零样本适应。在训练过程中，该政策通过使用基础夹爪采集的演示数据来学习抓取和放置的基本操作方法。而在推理阶段，基于扩散的优化策略动态地施加机械和安全约束，确保生成的动作轨迹与未见过的新夹爪的实际物理特性相匹配。这一过程通过一个受限去噪程序实现，该程序能够适应特定夹爪参数（例如工具中心点偏移量、颚宽）的同时保持碰撞避免和任务可行性。我们在Franka Panda机器人上进行了一系列实验测试，在六种不同的夹爪配置中验证了我们的方法的有效性，包括3D打印的手指末端执行器、柔软的硅胶抓手以及Robotiq 2F-85夹爪等。与扩散政策基线相比，我们提出的策略达到了93.3%的平均任务成功率（相比之下基线为23.3至26.7%），支持工具中心点偏移量从16到23.5厘米和颚宽范围从7.5到11.5厘米的变化。实验结果表明，受限扩散过程能够实现跨不同夹爪配置操作的鲁棒性同时维持了模仿学习方法的样本效率，并且无需为特定类型夹爪重新训练策略。代码与视频可在https://github.com/yaoxt3/GADP上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current robotic pick-and-place policies typically require consistent gripperconfigurations across training and inference. This constraint imposes highretraining or fine-tuning costs, especially for imitation learning-basedapproaches, when adapting to new end-effectors. To mitigate this issue, wepresent a diffusion-based policy with a hybrid learning-optimization framework,enabling zero-shot adaptation to novel grippers without additional datacollection for retraining policy. During training, the policy learnsmanipulation primitives from demonstrations collected using a base gripper. Atinference, a diffusion-based optimization strategy dynamically enforceskinematic and safety constraints, ensuring that generated trajectories alignwith the physical properties of unseen grippers. This is achieved through aconstrained denoising procedure that adapts trajectories to gripper-specificparameters (e.g., tool-center-point offsets, jaw widths) while preservingcollision avoidance and task feasibility. We validate our method on a FrankaPanda robot across six gripper configurations, including 3D-printed fingertips,flexible silicone gripper, and Robotiq 2F-85 gripper. Our approach achieves a93.3% average task success rate across grippers (vs. 23.3-26.7% for diffusionpolicy baselines), supporting tool-center-point variations of 16-23.5 cm andjaw widths of 7.5-11.5 cm. The results demonstrate that constrained diffusionenables robust cross-gripper manipulation while maintaining the sampleefficiency of imitation learning, eliminating the need for gripper-specificretraining. Video and code are available at https://github.com/yaoxt3/GADP.</description>
      <author>example@mail.com (Xiangtong Yao, Yirui Zhou, Yuan Meng, Liangyu Dong, Lin Hong, Zitao Zhang, Zhenshan Bing, Kai Huang, Fuchun Sun, Alois Knoll)</author>
      <guid isPermaLink="false">2502.15613v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Autonomous helicopter aerial refueling: controller design and performance guarantees</title>
      <link>http://arxiv.org/abs/2502.15562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于自主直升机空中加油的控制设计方法、稳定性标准和性能界限。&lt;h4&gt;背景&lt;/h4&gt;自主空中加油由于加油机尾流的影响、接触敏感操作特性和加油管运动不确定性而变得十分困难。此外，探针位于直升机重心之外，其位置与速度对直升机姿态及其角速率非常敏感。&lt;h4&gt;目的&lt;/h4&gt;为了提高自主空中加油的性能和稳定性，提出了一种新的外环位置控制器，并使用闭环误差动力学中的极限有界性特性来提供分析保证。&lt;h4&gt;方法&lt;/h4&gt;提出了一个将探针的位置和速度纳入反馈回路的新外环位置控制器。通过在高保真UH60直升机模型中进行仿真测试，验证了新控制策略的有效性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;新的控制方法能够显著减少2-范数对接误差，与现有标准控制器相比改进了36%。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了所提出的自主空中加油控制系统在复杂和动态环境中的有效性，并为未来的应用提供了理论基础和技术支持。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中，我们提出了一种用于无人直升机空中加油的控制设计方法、稳定性标准和性能界限。自主空中加油由于受到加油机尾流影响、操作接触敏感性和加油管运动不确定性的限制而变得非常困难。探针位置远离直升机重心，其位置（速度）对直升机姿态（角速率）极其敏感。此外，为了匹配加油机的速度，直升机需要高速运行并保持特定的姿态，这使得对接更加具有挑战性。我们提出了一种新的外环位置控制器，将探针的位置和速度纳入反馈回路中。通过闭环误差动态的极限有界特性，推导了关于对接性能与加油管运动不确定性及直升机角加速度之间的关系的分析保证。在考虑风力影响的情况下，利用高保真度UH60直升机模型进行了仿真测试，以验证新方法在现实场景中的有效性。高保真度模拟显示，相比于现有标准控制器，所提出的控制策略能将2-范数对接误差减少36%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a control design methodology, stability criteria,and performance bounds for autonomous helicopter aerial refueling. Autonomousaerial refueling is particularly difficult due to the aerodynamic interactionbetween the wake of the tanker, the contact-sensitive nature of the maneuver,and the uncertainty in drogue motion. Since the probe tip is locatedsignificantly away from the helicopter's center-of-gravity, its position (andvelocity) is strongly sensitive to the helicopter's attitude (and angularrates). In addition, the fact that the helicopter is operating at high speedsto match the velocity of the tanker forces it to maintain a particularorientation, making the docking maneuver especially challenging. In this paper,we propose a novel outer-loop position controller that incorporates the probeposition and velocity into the feedback loop. The position and velocity of theprobe tip depend both on the position (velocity) and on the attitude (angularrates) of the aircraft. We derive analytical guarantees for docking performancein terms of the uncertainty of the drogue motion and the angular accelerationof the helicopter, using the ultimate boundedness property of the closed-looperror dynamics. Simulations are performed on a high-fidelity UH60 helicoptermodel with a high-fidelity drogue motion under wind effects to validate theproposed approach for realistic refueling scenarios. These high-fidelitysimulations reveal that the proposed control methodology yields an improvementof 36% in the 2-norm docking error compared to the existing standardcontroller.</description>
      <author>example@mail.com (Damsara Jayarathne, Santiago Paternain, Sandipan Mishra)</author>
      <guid isPermaLink="false">2502.15562v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Probabilistic Collision Detection for Motion Planning Under Sensing Uncertainty</title>
      <link>http://arxiv.org/abs/2502.15525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了用于机器人在非结构化环境中的运动规划的增强概率碰撞检测（PCD）方法。&lt;h4&gt;背景&lt;/h4&gt;现有的PCD方法主要使用简化的几何模型，且仅考虑位置估计误差，未充分考虑到姿态估计误差和形状精度的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种改进的方法，以提高在感知不确定性下的鲁棒性，并减少路径长度与规划时间。&lt;h4&gt;方法&lt;/h4&gt;{'要点1': '利用超二次曲面（superquadrics）进行更精确的形状近似', '要点2': '考虑位置和姿态估计误差，通过扩大每个物体的表面来封装其观察到的所有旋转副本'}&lt;h4&gt;主要发现&lt;/h4&gt;该PCD方法比现有最佳方法更接近蒙特卡洛采样的基线，并且在减少路径长度和规划时间方面分别表现出色。&lt;h4&gt;结论&lt;/h4&gt;研究证明了考虑姿态估计误差的重要性，当仅考虑位置估计误差或忽略时，在仿真中执行计划路径的碰撞概率远高于此方法。&lt;h4&gt;翻译&lt;/h4&gt;概率碰撞检测（PCD）对于操作于非结构化环境中的机器人运动规划至关重要，通过考虑到感知不确定性有助于防止损坏。现有PCD方法主要使用简化的几何模型，并且仅解决位置估计误差问题。本文提出了一种增强的PCD方法，具有两个关键改进：(a) 使用超二次曲面进行更准确的形状近似；(b) 考虑到位置和姿态估计误差以提高在感知不确定性下的鲁棒性。该方法首先为每个对象计算一个扩大的表面，该表面封装了其观察到的所有旋转副本，从而解决了姿态估计误差问题。然后将位置估计误差下的碰撞概率作为机会约束问题进行公式化，并通过超二次曲面的正常参数化求解紧致上限。结果表明，与现有最佳PCD方法相比，该方法更接近蒙特卡洛采样的基线，并且在减少路径长度和规划时间方面表现出色。一种Real2Sim管道进一步验证了考虑姿态估计误差的重要性：执行仿真中计划路径的碰撞概率仅为2%，而仅考虑位置估计误差或完全不考虑时则分别为9% 和 29%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic collision detection (PCD) is essential in motion planning forrobots operating in unstructured environments, where considering sensinguncertainty helps prevent damage. Existing PCD methods mainly used simplifiedgeometric models and addressed only position estimation errors. This paperpresents an enhanced PCD method with two key advancements: (a) usingsuperquadrics for more accurate shape approximation and (b) accounting for bothposition and orientation estimation errors to improve robustness under sensinguncertainty. Our method first computes an enlarged surface for each object thatencapsulates its observed rotated copies, thereby addressing the orientationestimation errors. Then, the collision probability under the positionestimation errors is formulated as a chance-constraint problem that is solvedwith a tight upper bound. Both the two steps leverage the recently developednormal parameterization of superquadric surfaces. Results show that our PCDmethod is twice as close to the Monte-Carlo sampled baseline as the bestexisting PCD method and reduces path length by 30% and planning time by 37%,respectively. A Real2Sim pipeline further validates the importance ofconsidering orientation estimation errors, showing that the collisionprobability of executing the planned path in simulation is only 2%, compared to9% and 29% when considering only position estimation errors or none at all.</description>
      <author>example@mail.com (Xiaoli Wang, Sipu Ruan, Xin Meng, Gregory Chirikjian)</author>
      <guid isPermaLink="false">2502.15525v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Robust 4D Radar-aided Inertial Navigation for Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2502.15452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于高效且鲁棒的误差状态卡尔曼滤波器(ESKF)雷达惯性导航系统的开发方案，用于无人驾驶飞行器(UAV)，并利用毫米波(MMW)雷达提供的稳健3D测距和多普勒速度测量来增强UAV在复杂环境下的导航能力。&lt;h4&gt;背景&lt;/h4&gt;随着激光雷达和摄像头在无人机上的广泛应用，在挑战性的环境中它们可能会变得不那么有效。相反，能够提供稳健的三维测距和多普勒速度测量的4D毫米波(MMW)雷达对于空中导航来说利用不够充分。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于ESKF的方法来提高UAV利用毫米波雷达进行导航时的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种点对分布雷达扫描匹配技术，以提供具有适当不确定性资格的动作约束，并结合多普勒速度测量结果紧密耦合地更新导航状态。此外还设计了一个基于关键帧的方法来对抗先前地图（如果可用的话），从而限制累积的导航误差并提供高精度的雷达辅助全局定位解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的现实世界实验验证，该提出的雷达增强惯性导航方法在准确性和鲁棒性方面都超过了现有的最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;基于毫米波雷达和惯性传感器的数据融合技术可以提高UAV在复杂环境下的导航性能，并具有广阔的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While LiDAR and cameras are becoming ubiquitous for unmanned aerial vehicles(UAVs) but can be ineffective in challenging environments, 4D millimeter-wave(MMW) radars that can provide robust 3D ranging and Doppler velocitymeasurements are less exploited for aerial navigation. In this paper, wedevelop an efficient and robust error-state Kalman filter (ESKF)-basedradar-inertial navigation for UAVs. The key idea of the proposed approach isthe point-to-distribution radar scan matching to provide motion constraintswith proper uncertainty qualification, which are used to update the navigationstates in a tightly coupled manner, along with the Doppler velocitymeasurements. Moreover, we propose a robust keyframe-based matching schemeagainst the prior map (if available) to bound the accumulated navigation errorsand thus provide a radar-based global localization solution with high accuracy.Extensive real-world experimental validations have demonstrated that theproposed radar-aided inertial navigation outperforms state-of-the-art methodsin both accuracy and robustness.</description>
      <author>example@mail.com (Jinwen Zhu, Jun Hu, Xudong Zhao, Xiaoming Lang, Yinian Mao, Guoquan Huang)</author>
      <guid isPermaLink="false">2502.15452v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Learning Long-Horizon Robot Manipulation Skills via Privileged Action</title>
      <link>http://arxiv.org/abs/2502.15442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种结构化的框架，利用特权动作和课程学习来解决长期接触密集型任务中的强化学习挑战。&lt;h4&gt;背景&lt;/h4&gt;在处理长时序的、高维度状态空间的任务时，传统强化学习方法由于稀疏奖励导致探索效率低下且容易陷入局部最优。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的学习框架，在不依赖大量人工设计奖励或参考轨迹的情况下，使策略能够掌握长期技能。&lt;h4&gt;方法&lt;/h4&gt;在模拟环境中使用特权动作进行训练，包括放松约束条件和虚拟力等手段来增强对象交互和探索。通过课程学习逐步移除这些特权以逼近真实世界情况。&lt;h4&gt;主要发现&lt;/h4&gt;成功完成了涉及非抓取姿势物体提升的复杂多阶段长期任务，展示了方法的一般性和奖励结构的简洁性，并且在多种环境中都能达到收敛。&lt;h4&gt;结论&lt;/h4&gt;实验表明所学技能可以转移到现实世界中表现得既稳健又细腻。相比于现有方法，在这些任务上的性能更优。&lt;h4&gt;翻译&lt;/h4&gt;长时序接触密集型任务由于高维状态空间和稀疏奖励的存在，对强化学习来说是一个挑战。传统的解决方案往往陷入局部最优并且需要针对特定任务进行复杂的奖励调参。为了解决这些问题，我们提出了一种使用特权动作与课程学习相结合的方法框架。该方法通过模拟中的特权训练提升了对象交互和探索效率，并且逐步移除这些特权以适应真实环境的约束条件。最终结果表明所提出的算法能够成功完成多种复杂任务，并在不同环境中展现出多样性和鲁棒性的行为模式，证明了其有效性和普遍性。此外，现实世界实验进一步验证了学到技能的有效转移能力以及在实际应用中的卓越性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-horizon contact-rich tasks are challenging to learn with reinforcementlearning, due to ineffective exploration of high-dimensional state spaces withsparse rewards. The learning process often gets stuck in local optimum anddemands task-specific reward fine-tuning for complex scenarios. In this work,we propose a structured framework that leverages privileged actions withcurriculum learning, enabling the policy to efficiently acquire long-horizonskills without relying on extensive reward engineering or referencetrajectories. Specifically, we use privileged actions in simulation with ageneral training procedure that would be infeasible to implement in real-worldscenarios. These privileges include relaxed constraints and virtual forces thatenhance interaction and exploration with objects. Our results successfullyachieve complex multi-stage long-horizon tasks that naturally combinenon-prehensile manipulation with grasping to lift objects from non-graspableposes. We demonstrate generality by maintaining a parsimonious reward structureand showing convergence to diverse and robust behaviors across variousenvironments. Additionally, real-world experiments further confirm that theskills acquired using our approach are transferable to real-world environments,exhibiting robust and intricate performance. Our approach outperformsstate-of-the-art methods in these tasks, converging to solutions where othersfail.</description>
      <author>example@mail.com (Xiaofeng Mao, Yucheng Xu, Zhaole Sun, Elle Miller, Daniel Layeghi, Michael Mistry)</author>
      <guid isPermaLink="false">2502.15442v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Self-Mixing Laser Interferometry for Robotic Tactile Sensing</title>
      <link>http://arxiv.org/abs/2502.15390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种利用自混合干涉仪（SMI）技术的机器人指尖，用于检测物体滑动和外部接触。研究通过实验验证了该设计的有效性，并将其与声学传感器进行了比较。&lt;h4&gt;背景&lt;/h4&gt;自混合干涉仪因其在无需物理接触的情况下探测微振动的高度敏感性而受到赞誉。在机器人领域中，微振动通常被视为物体滑动的标志，最近也被认为是外接触的重要指标。&lt;h4&gt;目的&lt;/h4&gt;展示首个采用SMI技术检测滑动和外部接触信号的机器人指尖，并比较其与声学传感器的效果。&lt;h4&gt;方法&lt;/h4&gt;通过测量控制下的振动源进行设计验证，包括封装读取电路前后的情况。然后进行了三个实验将SMI指尖与声学传感相比较。&lt;h4&gt;主要发现&lt;/h4&gt;SMI对细微滑动事件更加敏感且在背景噪声下表现出显著更高的鲁棒性&lt;h4&gt;结论&lt;/h4&gt;将自混合干涉仪集成到机器人指尖中为触觉感应提供了新的有前景的分支技术&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-mixing interferometry (SMI) has been lauded for its sensitivity indetecting microvibrations, while requiring no physical contact with its target.In robotics, microvibrations have traditionally been interpreted as a markerfor object slip, and recently as a salient indicator of extrinsic contact. Wepresent the first-ever robotic fingertip making use of SMI for slip andextrinsic contact sensing. The design is validated through measurement ofcontrolled vibration sources, both before and after encasing the readoutcircuit in its fingertip package. Then, the SMI fingertip is compared toacoustic sensing through three experiments. The results are distilled into atechnology decision map. SMI was found to be more sensitive to subtle slipevents and significantly more robust against ambient noise. We conclude thatthe integration of SMI in robotic fingertips offers a new, promising branch oftactile sensing in robotics.</description>
      <author>example@mail.com (Remko Proesmans, Ward Goossens, Lowiek Van den Stockt, Lowie Christiaen, Francis wyffels)</author>
      <guid isPermaLink="false">2502.15390v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Rapid Online Learning of Hip Exoskeleton Assistance Preferences</title>
      <link>http://arxiv.org/abs/2502.15366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Copyright 2025 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;髋部外骨骼装置在各种场景中表现出色，能够适应不同用户的需求。然而，个性化调整通常需要复杂的调参过程和计算密集型算法，并且大多数现有方法不考虑用户的反馈。&lt;h4&gt;背景&lt;/h4&gt;随着技术的发展，髋部外骨骼因其适应性广、适用性强而越来越受欢迎。但是，在个性化提供帮助方面仍存在挑战，如长时间的调整过程以及缺乏用户反馈整合机制。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于快速学习用户偏好来调整个体化辅助扭矩配置的方法。&lt;h4&gt;方法&lt;/h4&gt;通过随机生成不同助行方案进行成对比较，并主动向参与者提问以收集其偏好的信息。这些反馈被集成到一个优先级学习算法中，该算法根据个人行为动态更新奖励函数并相应调整外骨骼的助力模式。&lt;h4&gt;主要发现&lt;/h4&gt;来自八位健康受试者的实验数据显示了不同的最佳扭矩配置；用户的选择在面对微调后的方案时依然保持一致；用户偏好与个体步行策略有密切联系；助行力矩不会干扰运动学关节协同作用，且参与者倾向于选择与其步态模式同步的助力。&lt;h4&gt;结论&lt;/h4&gt;这一方法简单有效地实现了快速学习用户的偏好和奖励机制，为基于奖励的人机交互奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;髋部外骨骼由于其在各种场景中的有效性以及能够适应不同用户的能力而日益流行。然而，个性化调整通常需要长时间的调优过程和计算密集型算法，并且大多数现有方法没有整合用户反馈。本文提出了一种快速学习用户对髋部外骨骼辅助偏好并据此优化助动力矩配置的新方法。通过随机生成不同的助力方案进行成对比较，并收集参与者的选择偏好的方式，研究发现不同受试者拥有各自的最优扭矩模式；用户的偏好与他们的步行策略紧密相关；且被测的力矩不会破坏关节协同运动关系，用户更倾向于那些与其步态一致的辅助力矩。这种方法为未来基于奖励的人机交互的研究提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hip exoskeletons are increasing in popularity due to their effectivenessacross various scenarios and their ability to adapt to different users.However, personalizing the assistance often requires lengthy tuning proceduresand computationally intensive algorithms, and most existing methods do notincorporate user feedback. In this work, we propose a novel approach forrapidly learning users' preferences for hip exoskeleton assistance. We performpairwise comparisons of distinct randomly generated assistive profiles, andcollect participants preferences through active querying. Users' feedback isintegrated into a preference-learning algorithm that updates its belief, learnsa user-dependent reward function, and changes the assistive torque profilesaccordingly. Results from eight healthy subjects display distinct preferredtorque profiles, and users' choices remain consistent when compared to aperturbed profile. A comprehensive evaluation of users' preferences reveals aclose relationship with individual walking strategies. The tested torqueprofiles do not disrupt kinematic joint synergies, and participants favorassistive torques that are synchronized with their movements, resulting inlower negative power from the device. This straightforward approach enables therapid learning of users preferences and rewards, grounding future studies onreward-based human-exoskeleton interaction.</description>
      <author>example@mail.com (Giulia Ramella, Auke Ijspeert, Mohamed Bouri)</author>
      <guid isPermaLink="false">2502.15366v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions</title>
      <link>http://arxiv.org/abs/2502.15336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  81 pages, submitted to a journal for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了嵌入式多模态大型模型（EMLMs）的发展，包括大语言模型、大视觉模型及其他相关模型，并探讨了这些模型在感知、导航和交互等方面的应用。&lt;h4&gt;背景介绍&lt;/h4&gt;近年来，由于EMLMs具有连接感知、认知和行动的潜力，在复杂现实环境中引起了广泛关注。EMLMs试图解决大规模环境下的多种挑战，如数据多样性与质量等。&lt;h4&gt;目的陈述&lt;/h4&gt;本文旨在详细分析EMLMs的发展历程及其面临的挑战，并探讨未来的方向，强调跨模态感知、推理及动作的重要性以促进更加自主系统的发展。&lt;h4&gt;方法概述&lt;/h4&gt;文章讨论了EMLMs的演化过程，重点关注嵌入式感知、导航、交互和模拟等方面。同时，对训练与评估这些模型所使用的数据集进行了深入分析，并指出了多样化高质量数据对于有效学习的重要意义。&lt;h4&gt;主要发现&lt;/h4&gt;文中指出了当前EMLMs面临的关键挑战，包括规模性问题、泛化能力和实时决策制定等方面的难题。&lt;h4&gt;未来方向&lt;/h4&gt;文章最后概述了未来的研究方向，强调多模态感知、推理和动作的集成是推进自主系统发展的关键。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied multimodal large models (EMLMs) have gained significant attention inrecent years due to their potential to bridge the gap between perception,cognition, and action in complex, real-world environments. This comprehensivereview explores the development of such models, including Large Language Models(LLMs), Large Vision Models (LVMs), and other models, while also examiningother emerging architectures. We discuss the evolution of EMLMs, with a focuson embodied perception, navigation, interaction, and simulation. Furthermore,the review provides a detailed analysis of the datasets used for training andevaluating these models, highlighting the importance of diverse, high-qualitydata for effective learning. The paper also identifies key challenges faced byEMLMs, including issues of scalability, generalization, and real-timedecision-making. Finally, we outline future directions, emphasizing theintegration of multimodal sensing, reasoning, and action to advance thedevelopment of increasingly autonomous systems. By providing an in-depthanalysis of state-of-the-art methods and identifying critical gaps, this paperaims to inspire future advancements in EMLMs and their applications acrossdiverse domains.</description>
      <author>example@mail.com (Shoubin Chen, Zehao Wu, Kai Zhang, Chunyu Li, Baiyang Zhang, Fei Ma, Fei Richard Yu, Qingquan Li)</author>
      <guid isPermaLink="false">2502.15336v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models</title>
      <link>http://arxiv.org/abs/2502.15252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;理解集体行人运动对于人群管理、自主导航和人机交互至关重要。本文探讨了使用序列深度学习模型，包括循环神经网络（RNN）、长短期记忆（LSTM）网络和变压器，用于多行人轨迹中的实时群体检测。&lt;h4&gt;背景&lt;/h4&gt;理解和预测人群的行为对于许多应用如安全、交通规划以及机器人与人类的互动非常重要。&lt;h4&gt;目的&lt;/h4&gt;调查并开发基于序列深度学习模型的方法来识别多个人行进动轨迹中形成的集体运动模式（例如鸟群）。&lt;h4&gt;方法&lt;/h4&gt;{'两阶段过程': '首先，使用预训练的二元分类模型进行成对行人轨迹分类；其次，利用学到的表示动态地确定多代理群体。', '使用的模型': ['循环神经网络（RNN）', '长短期记忆网络（LSTM）', '变压器']}&lt;h4&gt;主要发现&lt;/h4&gt;{'实验结果': '所提出的方法在真实世界的群体运动数据集上进行了验证，显示了其在不同序列长度和多样化移动模式下的鲁棒性。', '准确性与稳定性': '模型可以高精度且稳定地检测行人群体，即使是在动态和嘈杂的环境中也能表现出色。', '进一步应用': '该方法被扩展以识别其他形式的集体运动，如车队和蜂群，为更全面的多代理行为分析铺平了道路。'}&lt;h4&gt;结论&lt;/h4&gt;提出的基于序列深度学习的方法在检测行人群体及其动态变化方面展示了优异的表现，并为进一步研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;理解集体行人的移动模式对于人群管理、自主导航和人机交互至关重要。这项工作探讨了使用包括循环神经网络（RNN）、长短期记忆（LSTM）网络和变压器在内的序列深度学习模型，来实现实时群体检测在多行人轨迹中的应用。提出的方法包含两个阶段：首先利用预训练的二元分类模型对成对的人行进动轨迹进行分类；然后使用学到的表示动态地识别多代理群体。通过真实世界人群运动数据集验证了方法的有效性，证明其具有跨变序列长度和多样移动模式的稳健性。实验结果显示，该模型能在高精度和稳定性下检测行人群体，即使在动态且嘈杂的情况下也能保持良好的表现。此外，还扩展到识别其他形式的集体运动（如车队、蜂群），为多代理行为分析铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding collective pedestrian movement is crucial for applications incrowd management, autonomous navigation, and human-robot interaction. Thispaper investigates the use of sequential deep learning models, includingRecurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, andTransformers, for real-time flock detection in multi-pedestrian trajectories.Our proposed approach consists of a two-stage process: first, a pre-trainedbinary classification model is used for pairwise trajectory classification, andsecond, the learned representations are applied to identify multi-agent flocksdynamically.  We validate our method using real-world group movement datasets,demonstrating its robustness across varying sequence lengths and diversemovement patterns. Experimental results indicate that our model consistentlydetects pedestrian flocks with high accuracy and stability, even in dynamic andnoisy environments. Furthermore, we extend our approach to identify other formsof collective motion, such as convoys and swarms, paving the way for morecomprehensive multi-agent behavior analysis.</description>
      <author>example@mail.com (Amartaivan Sanjjamts, Hiroshi Morita, Togootogtokh Enkhtogtokh)</author>
      <guid isPermaLink="false">2502.15252v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>OccProphet: Pushing Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with Observer-Forecaster-Refiner Framework</title>
      <link>http://arxiv.org/abs/2502.15180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新颖的框架OccProphet，用于有效和高效地学习占用预测，显著降低计算需求并提高预测精度。&lt;h4&gt;背景&lt;/h4&gt;在复杂的交通环境中预测变化对于自动驾驶的安全性至关重要。最近的进步使通过观察历史2D图像来预测驾驶环境中的未来3D占用状态成为可能。然而，高计算需求使得占用预测在训练和推理阶段效率较低，限制了其在边缘设备上的可行性。&lt;h4&gt;目的&lt;/h4&gt;提出OccProphet框架以降低占用预测的计算要求，并提高预测精度。&lt;h4&gt;方法&lt;/h4&gt;OccProphet包含三个轻量级组件：观察者、预报器和精炼器。观察者通过提出的Efficient 4D Aggregation with Tripling-Attention Fusion从3D多帧体素中提取时空特征，而预报器和精炼器则有条件地预测并细化未来的占用状态。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上的实验结果表明OccProphet训练友好且推理效率高。与最先进的Cam4DOcc相比，OccProphet减少了58%~78%的计算成本，并提高了2.6倍的速度；此外，它还实现了4%~18%相对更高的预测精度。&lt;h4&gt;结论&lt;/h4&gt;OccProphet在保持或提高预测准确性的同时显著降低了计算需求，显示出其部署到边缘设备中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;预测复杂的交通环境中变化对于自动驾驶的安全性至关重要。最近的进步使通过观察历史2D图像来预测驾驶环境中的未来3D占用状态成为可能。然而，高计算需求使得占用预测在训练和推理阶段效率较低，限制了其在边缘设备上的可行性。在这篇论文中，我们提出了一种新颖的框架OccProphet，用于有效且高效地学习占用预测，显著降低计算需求并提高预测精度。OccProphet包含三个轻量级组件：观察者、预报器和精炼器。观察者通过提出的Efficient 4D Aggregation with Tripling-Attention Fusion从3D多帧体素中提取时空特征，而预报器和精炼器则有条件地预测并细化未来的占用状态。实验结果表明OccProphet在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上训练友好且推理效率高。与最先进的Cam4DOcc相比，OccProphet减少了58%~78%的计算成本，并提高了2.6倍的速度；此外，它还实现了4%~18%相对更高的预测精度。代码和模型可在https://github.com/JLChen-C/OccProphet上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting variations in complex traffic environments is crucial for thesafety of autonomous driving. Recent advancements in occupancy forecasting haveenabled forecasting future 3D occupied status in driving environments byobserving historical 2D images. However, high computational demands makeoccupancy forecasting less efficient during training and inference stages,hindering its feasibility for deployment on edge agents. In this paper, wepropose a novel framework, i.e., OccProphet, to efficiently and effectivelylearn occupancy forecasting with significantly lower computational requirementswhile improving forecasting accuracy. OccProphet comprises three lightweightcomponents: Observer, Forecaster, and Refiner. The Observer extractsspatio-temporal features from 3D multi-frame voxels using the proposedEfficient 4D Aggregation with Tripling-Attention Fusion, while the Forecasterand Refiner conditionally predict and refine future occupancy inferences.Experimental results on nuScenes, Lyft-Level5, and nuScenes-Occupancy datasetsdemonstrate that OccProphet is both training- and inference-friendly.OccProphet reduces 58\%$\sim$78\% of the computational cost with a 2.6$\times$speedup compared with the state-of-the-art Cam4DOcc. Moreover, it achieves4\%$\sim$18\% relatively higher forecasting accuracy. Code and models arepublicly available at https://github.com/JLChen-C/OccProphet.</description>
      <author>example@mail.com (Junliang Chen, Huaiyuan Xu, Yi Wang, Lap-Pui Chau)</author>
      <guid isPermaLink="false">2502.15180v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2502.15119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;确保自动驾驶系统的安全性是当前面临的关键挑战，尤其是在处理罕见但可能造成严重后果的安全临界场景时。尽管现有研究已经探讨了生成用于自主车辆（AV）测试的安全临界场景的方法，但在将这些场景有效地融入策略学习以提升安全性能方面的工作仍相对有限。此外，开发适应自主车辆行为模式和性能瓶颈变化的训练课程也尚未得到充分探索。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统中的安全性是目前研究的重点领域之一，特别是如何处理那些虽然罕见但可能导致严重事故的安全临界场景问题。&lt;h4&gt;目的&lt;/h4&gt;提出CurricuVLM框架以解决现有方法在生成安全临界测试场景和适应自主车辆行为模式方面存在的不足。该框架利用视觉语言模型（VLM）来实现个性化课程学习，从而提升自动驾驶系统的整体性能与安全性。&lt;h4&gt;方法&lt;/h4&gt;CurricuVLM通过运用VLM的多模态理解能力分析自动驾驶代理的行为、识别其性能弱点，并动态生成量身定制的训练场景进行课程适应。通过对不安全驾驶情况及其叙述性描述进行全面分析，该框架能够深入推理评估AV的能力并确定关键行为模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在Waymo Open Motion数据集上，CurricuVLM在常规及安全临界情景中均优于现有的基准方法，特别是在导航成功率、行驶效率和安全性指标方面表现更优。此外，进一步的分析揭示了CurricuVLM作为一种通用方法可以与各种强化学习算法相结合以增强自动驾驶系统。&lt;h4&gt;结论&lt;/h4&gt;CurricuVLM框架通过利用视觉语言模型的独特能力来改善自主驾驶代理的安全性和整体性能，并且它可以被广泛应用于不同的强化学习环境中。此外，该框架的源代码和演示视频可在GitHub页面上获取。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要已经以中文形式呈现，无需再次翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safety in autonomous driving systems remains a critical challenge,particularly in handling rare but potentially catastrophic safety-criticalscenarios. While existing research has explored generating safety-criticalscenarios for autonomous vehicle (AV) testing, there is limited work oneffectively incorporating these scenarios into policy learning to enhancesafety. Furthermore, developing training curricula that adapt to an AV'sevolving behavioral patterns and performance bottlenecks remains largelyunexplored. To address these challenges, we propose CurricuVLM, a novelframework that leverages Vision-Language Models (VLMs) to enable personalizedcurriculum learning for autonomous driving agents. Our approach uniquelyexploits VLMs' multimodal understanding capabilities to analyze agent behavior,identify performance weaknesses, and dynamically generate tailored trainingscenarios for curriculum adaptation. Through comprehensive analysis of unsafedriving situations with narrative descriptions, CurricuVLM performs in-depthreasoning to evaluate the AV's capabilities and identify critical behavioralpatterns. The framework then synthesizes customized training scenariostargeting these identified limitations, enabling effective and personalizedcurriculum learning. Extensive experiments on the Waymo Open Motion Datasetshow that CurricuVLM outperforms state-of-the-art baselines across both regularand safety-critical scenarios, achieving superior performance in terms ofnavigation success, driving efficiency, and safety metrics. Further analysisreveals that CurricuVLM serves as a general approach that can be integratedwith various RL algorithms to enhance autonomous driving systems. The code anddemo video are available at: https://zihaosheng.github.io/CurricuVLM/.</description>
      <author>example@mail.com (Zihao Sheng, Zilin Huang, Yansong Qu, Yue Leng, Sruthi Bhavanam, Sikai Chen)</author>
      <guid isPermaLink="false">2502.15119v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories</title>
      <link>http://arxiv.org/abs/2502.15043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种利用扩散模型生成机器人动态可接受轨迹的方法，名为DDAT。通过在训练和推理过程中将预测投影到动态可接受流形上，该方法解决了传统扩散模型与机器人动力学方程之间不匹配的问题。&lt;h4&gt;背景&lt;/h4&gt;扩散模型因其多模态生成能力而在图像和视频创建中表现出色，并逐渐被应用于机器人研究以生成机器人运动。然而，由于其随机性质，它难以满足描述可行机器人运动的精确动态方程。&lt;h4&gt;目的&lt;/h4&gt;解决利用扩散模型生成符合动力学约束的机器人轨迹的问题，提高长时域规划性能。&lt;h4&gt;方法&lt;/h4&gt;DDAT通过迭代采样预测状态前一个状态的可达集多面体下近似，并将预测状态投影到该集合中来确保动态可接受性。这种方法减少了扩散模型需要不断重新计划的需求，从而能够进行一次性长时间范围内的轨迹规划。&lt;h4&gt;主要发现&lt;/h4&gt;提出的框架在四旋翼飞行器和各种MuJoCo环境的广泛模拟以及Unitree GO1和GO2的真实世界实验中生成了更高品质的动态可接受机器人轨迹。&lt;h4&gt;结论&lt;/h4&gt;DDAT通过在扩散模型预测过程中引入动力学可行性约束，有效地解决了利用这种随机生成方法进行精确机器人运动规划的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：扩散模型因其多模态生成能力而擅长创建图像和视频，在机器人研究中也越来越流行，用于生成机器人运动。然而，扩散模型的本质随机性与描述可行机器人运动的动力学方程不一致。因此，利用扩散模型生成动态可接受的机器人轨迹是一个挑战。为解决这一问题，我们引入了DDAT：适用于动态可接受轨迹的扩散策略，以使用扩散模型对黑盒机器人系统进行能够被证明是可接受的轨迹生成。如果序列中的每个状态都属于其前驱者按照机器人运动方程计算出的可达集合，则称该序列是一条动力学上可接受的轨迹。为了生成这样的轨迹，我们的扩散策略在训练和推理过程中将预测投影到动态可接受流形上来使去噪神经网络的目标与动力学可行性约束对齐。这些预测的自回归性质以及机器人动力学的黑盒特性使得这种投影非常具有挑战性。因此，我们通过迭代采样状态可达集的一个多面体下近似，并将其预测的后继投影到该集合上，来强制执行可接受性；随后将此过程重复应用于经过投影后的后续状态。这种方法生成了准确轨迹，从而消除了扩散模型不断重新计划的需求，使得一次性长时域规划成为可能。我们通过广泛的四旋翼飞行器模拟和各种MuJoCo环境中的实验以及Unitree GO1和GO2的真实世界测试来证明我们的框架能够生成更高品质的动态可接受机器人轨迹。&lt;h4&gt;关键词&lt;/h4&gt;扩散模型, 动态可行性, 机器人运动规划&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models excel at creating images and videos thanks to theirmultimodal generative capabilities. These same capabilities have made diffusionmodels increasingly popular in robotics research, where they are used forgenerating robot motion. However, the stochastic nature of diffusion models isfundamentally at odds with the precise dynamical equations describing thefeasible motion of robots. Hence, generating dynamically admissible robottrajectories is a challenge for diffusion models. To alleviate this issue, weintroduce DDAT: Diffusion policies for Dynamically Admissible Trajectories togenerate provably admissible trajectories of black-box robotic systems usingdiffusion models. A sequence of states is a dynamically admissible trajectoryif each state of the sequence belongs to the reachable set of its predecessorby the robot's equations of motion. To generate such trajectories, ourdiffusion policies project their predictions onto a dynamically admissiblemanifold during both training and inference to align the objective of thedenoiser neural network with the dynamical admissibility constraint. Theauto-regressive nature of these projections along with the black-box nature ofrobot dynamics render these projections immensely challenging. We thus enforceadmissibility by iteratively sampling a polytopic under-approximation of thereachable set of a state onto which we project its predicted successor, beforeiterating this process with the projected successor. By producing accuratetrajectories, this projection eliminates the need for diffusion models tocontinually replan, enabling one-shot long-horizon trajectory planning. Wedemonstrate that our framework generates higher quality dynamically admissiblerobot trajectories through extensive simulations on a quadcopter and variousMuJoCo environments, along with real-world experiments on a Unitree GO1 andGO2.</description>
      <author>example@mail.com (Jean-Baptiste Bouvier, Kanghyun Ryu, Kartik Nagpal, Qiayuan Liao, Koushil Sreenath, Negar Mehr)</author>
      <guid isPermaLink="false">2502.15043v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>DEFT: Differentiable Branched Discrete Elastic Rods for Modeling Furcated DLOs in Real-Time</title>
      <link>http://arxiv.org/abs/2502.15037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的框架DEFT，用于实时建模复杂的分支柔性线性物体（BDLOs），解决了机器人自动化电线束装配中的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的研究已经成功地对单一线性的可变形物体进行了建模，但对于具有复杂力交互和应变传播模式的分支结构来说，这些方法难以直接适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够准确预测分支柔性线性物体动态行为的方法，并实现高效的实时计算以及规划能力。&lt;h4&gt;方法&lt;/h4&gt;DEFT结合了基于物理的模型与机器学习框架，用于建模BDLO的动力学特性、动态传播和抓取操作。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列现实世界的实验展示了DEFT在准确性、计算速度和泛化性方面的优越性能。&lt;h4&gt;结论&lt;/h4&gt;DEFT为复杂柔性线性物体的自动化装配提供了强大的工具，并且展示了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;自主电线束组装要求机器人能够高精度地操作复杂的分支电缆。现有的研究虽然对单一线性的可变形对象建模取得了一定进展，但对于具有复杂力交互和应变传播模式的分支结构来说，这些方法难以直接适用。为了解决这一挑战，本文提出了一种新的框架DEFT，该框架结合了基于物理模型的方法与机器学习技术，能够准确地模拟BDLO的动力学特性，并实现了高效的实时计算及规划能力，在一系列现实世界的实验中证明了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous wire harness assembly requires robots to manipulate complexbranched cables with high precision and reliability. A key challenge inautomating this process is predicting how these flexible and branchedstructures behave under manipulation. Without accurate predictions, it isdifficult for robots to reliably plan or execute assembly operations. Whileexisting research has made progress in modeling single-threaded DeformableLinear Objects (DLOs), extending these approaches to Branched Deformable LinearObjects (BDLOs) presents fundamental challenges. The junction points in BDLOscreate complex force interactions and strain propagation patterns that cannotbe adequately captured by simply connecting multiple single-DLO models. Toaddress these challenges, this paper presents Differentiable discrete branchedElastic rods for modeling Furcated DLOs in real-Time (DEFT), a novel frameworkthat combines a differentiable physics-based model with a learning frameworkto: 1) accurately model BDLO dynamics, including dynamic propagation atjunction points and grasping in the middle of a BDLO, 2) achieve efficientcomputation for real-time inference, and 3) enable planning to demonstratedexterous BDLO manipulation. A comprehensive series of real-world experimentsdemonstrates DEFT's efficacy in terms of accuracy, computational speed, andgeneralizability compared to state-of-the-art alternatives. Projectpage:https://roahmlab.github.io/DEFT/.</description>
      <author>example@mail.com (Yizhou Chen, Xiaoyue Wu, Yeheng Zong, Anran Li, Yuzhen Chen, Julie Wu, Bohao Zhang, Ram Vasudevan)</author>
      <guid isPermaLink="false">2502.15037v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural Control Barrier Functions</title>
      <link>http://arxiv.org/abs/2502.15006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'问题描述': '在实践中使用模型预测控制（MPC）时，满足超出预测范围的安全规范是一个常见问题。', '现有方法的局限性': '理论研究表明可以通过施加合适的终端集约束或足够长的预测范围来保证安全性。然而这些技术难以应用且很少被实际操作者采用，特别是在处理一般非线性动态系统的情况下。', '提出的解决方案': '提出了一种新的方法，通过学习一个近似的离散时间控制屏障函数，并将其融入到变分推理MPC（VIMPC）中来解决上述问题。这种方法在精确递归可行性、计算可行性和适用于‘黑盒’动力学之间做出权衡。', '改进措施': '提出了一种新的采样策略，该策略显著减少了估计的最优控制方差，并提高了采样的效率，从而可以在CPU上实现实时规划。', '性能验证': 'Neural Shield-VIMPC（NS-VIMPC）控制器在模拟和实际硬件实验中均显示出比现有基于采样的MPC控制器更高的安全性改进。特别是在成本函数设计不佳的情况下也能获得显著的安全性提升。', '技术实现': '通过学习近似离散时间控制屏障函数，并将其集成到变分推理MPC（VIMPC）框架中的方式来解决上述问题，同时引入了一种新的采样策略以优化状态约束处理。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在实际应用中使用模型预测控制时遇到的安全性保障难题以及现有的理论方法难以实施的问题。研究提出通过结合变分推理MPC与近似离散时间控制屏障函数的学习来解决这一挑战，同时引入了新的采样策略以提高计算效率和实时规划能力。实验表明，这种新方法在实际应用中表现出色，尤其是在处理复杂动态系统时有显著的安全性提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A common problem when using model predictive control (MPC) in practice is thesatisfaction of safety specifications beyond the prediction horizon. Whiletheoretical works have shown that safety can be guaranteed by enforcing asuitable terminal set constraint or a sufficiently long prediction horizon,these techniques are difficult to apply and thus are rarely used bypractitioners, especially in the case of general nonlinear dynamics. To solvethis problem, we impose a tradeoff between exact recursive feasibility,computational tractability, and applicability to ''black-box'' dynamics bylearning an approximate discrete-time control barrier function andincorporating it into a variational inference MPC (VIMPC), a sampling-based MPCparadigm. To handle the resulting state constraints, we further propose a newsampling strategy that greatly reduces the variance of the estimated optimalcontrol, improving the sample efficiency, and enabling real-time planning on aCPU. The resulting Neural Shield-VIMPC (NS-VIMPC) controller yields substantialsafety improvements compared to existing sampling-based MPC controllers, evenunder badly designed cost functions. We validate our approach in bothsimulation and real-world hardware experiments.</description>
      <author>example@mail.com (Ji Yin, Oswin So, Eric Yang Yu, Chuchu Fan, Panagiotis Tsiotras)</author>
      <guid isPermaLink="false">2502.15006v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Ultra-High-Frequency Harmony: mmWave Radar and Event Camera Orchestrate Accurate Drone Landing</title>
      <link>http://arxiv.org/abs/2502.14992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by ACM SenSys 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了实现精确、高效和安全的无人机着陆，地面平台需要实时且准确地定位下降中的无人机，并引导它们到达指定位置。虽然毫米波（mmWave）感应与相机结合可以提高定位精度，但传统帧照相机较低的采样频率相比毫米波雷达形成了系统吞吐量瓶颈。本文通过在地面平台设置中用新型事件摄像机取代传统的帧照相机来解决这一问题，并引入了针对无人机着陆设计的高度精确且低延迟的地面对准系统mmE-Loc。&lt;h4&gt;背景&lt;/h4&gt;传统的方法结合毫米波雷达和帧照相机构建定位系统，但其较低的采样频率限制了系统的吞吐量。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的高精度、低延迟地面定位系统（mmE-Loc）用于无人机着陆，以改善现有的瓶颈问题，并提高整体性能。&lt;h4&gt;方法&lt;/h4&gt;将事件摄像机与毫米波雷达结合使用，在这种设置中，采样频率得到了统一。为了充分利用这两种模式之间的时间一致性以及空间互补性，提出了两个创新模块：时间一致性指导的协作跟踪和基于图信息自适应联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实地实验表明，mmE-Loc在定位精度和延迟方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的mmE-Loc系统能够提供更精确、低延迟的无人机着陆支持，并且在实际应用中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For precise, efficient, and safe drone landings, ground platforms shouldreal-time, accurately locate descending drones and guide them to designatedspots. While mmWave sensing combined with cameras improves localizationaccuracy, the lower sampling frequency of traditional frame cameras compared tommWave radar creates bottlenecks in system throughput. In this work, we replacethe traditional frame camera with event camera, a novel sensor that harmonizesin sampling frequency with mmWave radar within the ground platform setup, andintroduce mmE-Loc, a high-precision, low-latency ground localization systemdesigned for drone landings. To fully leverage the \textit{temporalconsistency} and \textit{spatial complementarity} between these modalities, wepropose two innovative modules, \textit{consistency-instructed collaborativetracking} and \textit{graph-informed adaptive joint optimization}, for accuratedrone measurement extraction and efficient sensor fusion. Extensive real-worldexperiments in landing scenarios from a leading drone delivery companydemonstrate that mmE-Loc outperforms state-of-the-art methods in bothlocalization accuracy and latency.</description>
      <author>example@mail.com (Haoyang Wang, Jingao Xu, Xinyu Luo, Xuecheng Chen, Ting Zhang, Ruiyang Duan, Yunhao Liu, Xinlei Chen)</author>
      <guid isPermaLink="false">2502.14992v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>A novel step-by-step procedure for the kinematic calibration of robots using a single draw-wire encoder</title>
      <link>http://arxiv.org/abs/2502.14983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;机器人定位精度在进行高精度制造任务时是一个关键因素。为了有效提高机械臂的精度，校准扮演着至关重要的角色。&lt;h4&gt;背景&lt;/h4&gt;现有的文献中提出了多种机器人校准方法，这些方法使用的测量系统和识别算法差异很大。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型逐步运动学校准程序，仅使用通过拉线编码器获取的一维距离测量数据来逐次估计参数。&lt;h4&gt;方法&lt;/h4&gt;为了实现这一目标，我们推导了一种分析方法，在这种方法中，对于每个未知参数，可以找到一组校准点，其中测得的距离与预测的距离之间的差异只依赖于那个未知参数。这减少了识别过程中的计算负担，并有可能提高其精度。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和实验测试中，该策略的有效性得到了证实。结果表明，所提出的逐步校准方法为标准校准方法提供了一种实用、成本效益高且计算需求较低的替代方案。&lt;h4&gt;结论&lt;/h4&gt;这种校准方法使得机器人校准更加易于实现，从而提高了机械臂执行任务时的精度和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;机器人定位精度是进行精密制造作业的关键。为提高机械臂精度，提出了一种使用拉线编码器一维距离测量数据逐步校准的新方法，并通过推导分析法验证了其有效性。该方法是一种成本效益高、计算负担小的替代方案，使机器人校准更加简便和经济。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s00170-024-13219-1&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot positioning accuracy is a key factory when performing high-precisionmanufacturing tasks. To effectively improve the accuracy of a manipulator,often up to a value close to its repeatability, calibration plays a crucialrole. In the literature, various approaches to robot calibration have beenproposed, and they range considerably in the type of measurement system andidentification algorithm used. Our aim was to develop a novel step-by-stepkinematic calibration procedure - where the parameters are subsequentlyestimated one at a time - that only uses 1D distance measurement data obtainedthrough a draw-wire encoder. To pursue this objective, we derived an analyticalapproach to find, for each unknown parameter, a set of calibration points wherethe discrepancy between the measured and predicted distances only depends onthat unknown parameter. This reduces the computational burden of theidentification process while potentially improving its accuracy. Simulationsand experimental tests were carried out on a 6 degrees-of-freedom robot arm:the results confirmed the validity of the proposed strategy. As a result, theproposed step-by-step calibration approach represents a practical,cost-effective and computationally less demanding alternative to standardcalibration approaches, making robot calibration more accessible and easier toperform.</description>
      <author>example@mail.com (Giovanni Boschetti, Teresa Sinico)</author>
      <guid isPermaLink="false">2502.14983v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration</title>
      <link>http://arxiv.org/abs/2502.14795v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架Humanoid-VLA，该框架整合了语言理解、自我中心场景感知和运动控制，旨在实现通用的人形机器人控制。&lt;h4&gt;背景&lt;/h4&gt;当前人形机器人的控制系统主要依赖于反应机制，并且由于数据稀缺缺乏自主互动能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够解决现有局限性的新方法，即Humanoid-VLA框架，以提高人形机器人在理解和执行任务时的自主性和适应性。&lt;h4&gt;方法&lt;/h4&gt;该研究通过使用非自我中心的人体运动数据集与文本描述进行语言-动作预对齐来开始。然后利用参数高效的视频条件微调技术融入自我中心视觉上下文。此外还提出了一种自监督数据增强策略，可以直接从运动数据中生成伪标注。&lt;h4&gt;主要发现&lt;/h4&gt;Humanoid-VLA框架能够通过利用大规模未标记的视频数据进行训练，提高在物体互动和环境探索任务中的情境意识能力。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，基于全身控制架构的人形机器人控制系统实现了更像人类的行为表现，具备更强适应性和智能性交互能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，此JSON格式包含对摘要内容的中文总结与分类&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the limitations of current humanoid robot controlframeworks, which primarily rely on reactive mechanisms and lack autonomousinteraction capabilities due to data scarcity. We propose Humanoid-VLA, a novelframework that integrates language understanding, egocentric scene perception,and motion control, enabling universal humanoid control. Humanoid-VLA beginswith language-motion pre-alignment using non-egocentric human motion datasetspaired with textual descriptions, allowing the model to learn universal motionpatterns and action semantics. We then incorporate egocentric visual contextthrough a parameter efficient video-conditioned fine-tuning, enablingcontext-aware motion generation. Furthermore, we introduce a self-superviseddata augmentation strategy that automatically generates pseudoannotationsdirectly derived from motion data. This process converts raw motion sequencesinto informative question-answer pairs, facilitating the effective use oflarge-scale unlabeled video data. Built upon whole-body control architectures,extensive experiments show that Humanoid-VLA achieves object interaction andenvironment exploration tasks with enhanced contextual awareness, demonstratinga more human-like capacity for adaptive and intelligent engagement.</description>
      <author>example@mail.com (Pengxiang Ding, Jianfei Ma, Xinyang Tong, Binghong Zou, Xinxin Luo, Yiguo Fan, Ting Wang, Hongchao Lu, Panzhong Mo, Jinxin Liu, Yuefan Wang, Huaicheng Zhou, Wenshuo Feng, Jiacheng Liu, Siteng Huang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.14795v2</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>Design of a Visual Pose Estimation Algorithm for Moon Landing</title>
      <link>http://arxiv.org/abs/2502.14942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, Presented in 11th Nano-Satellite Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;为了实现月球精确着陆，提出了一种基于地形的绝对导航算法来估计航天器的位置和姿态。&lt;h4&gt;背景&lt;/h4&gt;在月球着陆任务中，需要提高航天器导航系统的准确性以减少惯性传感器引起的漂移误差。&lt;h4&gt;目的&lt;/h4&gt;通过使用预定的陨石坑数据库对拍摄到的陨石坑进行识别与匹配，并利用这些信息来校正导航偏差，从而实现精确导航。&lt;h4&gt;方法&lt;/h4&gt;该算法采用基于影像处理和地面特征识别的技术，但为了专注于估计算法的研究，在实验中跳过了图像处理及陨石坑匹配步骤。进行了仿真实验以评估算法的准确性以及使用不同数量的陨石坑进行估算的效果。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真验证了提出的绝对导航方法的有效性和准确性，并探讨了用于估计所需的陨石坑数量的影响。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种有效的地形绝对导航解决方案，可以显著提高月球着陆任务中航天器导航的精度。&lt;h4&gt;翻译&lt;/h4&gt;为了实现月球精确着陆，需要校正惯性传感器引起的导航漂移。本研究提出了一种基于地面特征识别技术的绝对导航方法，并通过仿真验证了其有效性及准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to make a pinpoint landing on the Moon, the spacecraft's navigationsystem must be accurate. To achieve the desired accuracy, navigational driftcaused by the inertial sensors must be corrected. One way to correct this driftis to use absolute navigation solutions. In this study, a terrain absolutenavigation method to estimate the spacecraft's position and attitude isproposed. This algorithm uses the position of the craters below the spacecraftfor estimation. Craters seen by the camera onboard the spacecraft are detectedand identified using a crater database known beforehand. In order to focus onestimation algorithms, image processing and crater matching steps are skipped.The accuracy of the algorithm and the effect of the crater number used forestimation are inspected by performing simulations.</description>
      <author>example@mail.com (Atakan Süslü, Betül Rana Kuran, Halil Ersin Söken)</author>
      <guid isPermaLink="false">2502.14942v1</guid>
      <pubDate>Mon, 24 Feb 2025 17:04:44 +0800</pubDate>
    </item>
    <item>
      <title>PLDR-LLMs Learn A Generalizable Tensor Operator That Can Replace Its Own Deep Neural Net At Inference</title>
      <link>http://arxiv.org/abs/2502.13502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 1 figure, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型PLDR-LLM通过学习一个奇异性条件，使得在推理时可以使用能量曲率张量G_{LM}来代替生成演绎输出的深度神经网络。&lt;h4&gt;背景&lt;/h4&gt;研究探讨了一种基于幂律解码表示（Power Law Decoder Representations）的大型语言模型PLDR-LLM，并揭示了其演绎输出具有高度不变性和可泛化性，且能够通过缓存机制提高推理效率。&lt;h4&gt;目的&lt;/h4&gt;展示PLDR-LLM作为一种基础模型的特点及其在不同条件下的表现特性；探讨演绎输出不变性的原因和影响；提出一种有效的推理框架来优化模型性能。&lt;h4&gt;方法&lt;/h4&gt;构建了一个学习奇异性条件的框架，该框架允许使用能量曲率张量G_{LM}替换原有的深度神经网络进行推理，并通过缓存机制（包括KV-cache和G-cache）加速推理过程。&lt;h4&gt;主要发现&lt;/h4&gt;演绎输出具有高度不变性，在缓存后仍保持相同均方根误差(RMSE)及行列式值，且零样本基准分数未受影响；学习到的演绎输出与使用转移初始化、随机初始化或单位张量作为常数操作符预训练模型在损失和准确性上有不同特征。&lt;h4&gt;结论&lt;/h4&gt;观察到不变性特性引入了训练和推理阶段之间的新颖不对称关系，并为PLDR-LLM提供了一个有效的训练和推理框架，该框架利用KV-cache和G-cache来优化性能。&lt;h4&gt;翻译&lt;/h4&gt;我们展示了基于幂律解码表示的大型语言模型(PLDR-LLM)是一种基础模型，其演绎输出在小扰动下是不变张量。PLDR-LLM学习了一个奇异性条件，使得生成演绎输出的深度神经网络（如幂定律图注意力PLGA）可以在推理阶段被能量曲率张量G_{LM}所替代。我们证明了可以通过简单的实现缓存机制来提高推理时间效率，包括用于G_{LM}和KV-cache的缓存。在缓存后，演绎输出具有非常高的不变性和可泛化性（例如RMSE和行列式的值保持到15位小数）。消融研究显示，学习得到的演绎输出与使用转移初始化、随机初始化或单位张量作为常数操作符预训练模型有不同的损失和准确性特征。观察到了一个由缓存所引入的新颖不对称关系在训练和推理阶段之间。我们提出了PLDR-LLM的学习奇异性条件的共同特性，并提供了一个带有KV-cache和G-cache的有效训练和推理框架实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We show that Large Language Model from Power Law Decoder Representations(PLDR-LLM) is a foundational model whose deductive outputs are invarianttensors up to a small perturbation. PLDR-LLM learns a singularity condition forthe deductive outputs that enable the once-inferred energy-curvature tensor$\mathbf{G}_{LM}$ to replace the deep neural network of power law graphattention (PLGA) generating the deductive outputs at inference. We demonstratethat a cache for $\mathbf{G}_{LM}$ (G-cache) and KV-cache can be implemented ina straightforward manner to improve the inference time. The invariance andgeneralizable nature of deductive outputs is at a very high fidelity wheredeductive outputs have same RMSE and determinant values up to 15 decimal placesafter caching, and zero-shot benchmark scores remain unchanged. Ablationstudies show that learned deductive outputs have distinct loss and accuracycharacteristics from models pretrained with transferred, randomly initializedor identity tensors as a constant tensor operator and an LLM with scaled-dotproduct attention (SDPA) is a special case of PLDR-LLM where $\mathbf{G}_{LM}$is predefined as identity. The observed invariance characteristic introduces anovel asymmetry between training and inference phases with caching. We outlineobserved common characteristics of the deductive outputs for the learnedsingularity condition. We provide an implementation of a training and inferenceframework for PLDR-LLM with KV-cache and G-cache.</description>
      <author>example@mail.com (Burc Gokden)</author>
      <guid isPermaLink="false">2502.13502v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
  <item>
      <title>Large Language-Geometry Model: When LLM meets Equivariance</title>
      <link>http://arxiv.org/abs/2502.11149v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为EquiLLM的新框架，该框架旨在准确预测物理系统的3D结构和动态。EquiLLM通过整合几何感知提示、等变编码器、大型语言模型（LLMs）以及等变适配器，实现了E(3)-等方性与LLMs能力的无缝融合。&lt;h4&gt;背景&lt;/h4&gt;在科学应用中，准确预测物理系统的3D结构和动态至关重要。现有的基于几何图神经网络（GNNs）的方法虽然有效执行了E(3)等方性，但难以充分利用广泛的外部信息。直接使用大型语言模型则可以融入外部知识，但在空间推理方面缺乏保证的等方性能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架EquiLLM，以解决现有方法在预测物理系统3D结构和动态时存在的局限性和不足。&lt;h4&gt;方法&lt;/h4&gt;EquiLLM主要由四个关键组件组成：几何感知提示、等变编码器、大型语言模型（LLMs）以及等变适配器。这些组件协同工作，使LLM能够作为高级不变特征处理器，并且3D方向信息则完全由等变的编码器和适配器处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，EquiLLM在分子动力学模拟、人类运动仿真和抗体设计方面均显著优于先前的方法，展现了其出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了通过融合大型语言模型与等变性特征处理技术，可以更有效地预测物理系统的3D结构及其动态。这一方法为解决实际问题提供了新的途径，并且显示出在多个领域中的广泛应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;准确地预测物理系统的三维结构和动力学是科学应用中至关重要的任务。现有的基于几何图神经网络（GNNs）的方法虽然成功实现了E(3)等方性，但往往难以充分利用广泛的外部信息。而直接使用大型语言模型可以融入外部知识，但在进行空间推理时缺乏保证的等方性能力。在本文中，我们提出了EquiLLM这一新框架，它能够无缝地将E(3)-等方性和大型语言模型的能力结合起来来表示三维物理系统。具体来说，EquiLLM包括四个关键部分：几何感知提示、等变编码器、一个大型语言模型以及等变适配器。在这种情况下，通过指导性提示引导的大型语言模型可以作为一个高级不变特征处理器，而3D方向信息则完全由等方性编码器和适配器处理模块来管理。实验结果表明，在分子动力学模拟、人类运动仿真和抗体设计方面，EquiLLM方法都显著优于先前的方法，这凸显了它的泛化能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D structures and dynamics of physical systems iscrucial in scientific applications. Existing approaches that rely on geometricGraph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,but they often fall in leveraging extensive broader information. While directapplication of Large Language Models (LLMs) can incorporate external knowledge,they lack the capability for spatial reasoning with guaranteed equivariance. Inthis paper, we propose EquiLLM, a novel framework for representing 3D physicalsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.Specifically, EquiLLM comprises four key components: geometry-aware prompting,an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, theLLM guided by the instructive prompt serves as a sophisticated invariantfeature processor, while 3D directional information is exclusively handled bythe equivariant encoder and adaptor modules. Experimental results demonstratethat EquiLLM delivers significant improvements over previous methods acrossmolecular dynamics simulation, human motion simulation, and antibody design,highlighting its promising generalizability.</description>
      <author>example@mail.com (Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao)</author>
      <guid isPermaLink="false">2502.11149v2</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Covering a Point Set by $m$ Disks with Minimum Total Area</title>
      <link>http://arxiv.org/abs/2502.13773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 Pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人感知中的一个常见问题是放置传感器以确保对一组资产进行稳健监控。&lt;h4&gt;目的&lt;/h4&gt;研究如何在最小化总观察区域的前提下，通过特定数量的圆盘形状传感区来监测给定的一组资产。&lt;h4&gt;方法&lt;/h4&gt;提供并分析了一个快速启发式算法，并利用该算法初始化精确的整数规划解决方案。随后对整数程序进行修改，以强制传感器之间的分离约束。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个有效的解决策略用于优化机器人系统中传感器布局问题。&lt;h4&gt;结论&lt;/h4&gt;通过将启发式方法与改进后的整数编程相结合，可以有效地确定传感器的位置，以便在给定条件下最小化监测所需的空间区域。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个研究方向，旨在使用圆盘形状传感区的m个传感器来稳健地监控n个资产。目标是通过确保每个资产由至少kappa(p)数量的传感器监视的同时尽量减少总观察面积。为了解决这个问题，作者提出了一种快速启发式算法，并利用该方法初始化精确整数规划解决方案，从而进一步优化传感器布局以满足分离约束条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A common robotics sensing problem is to place sensors to robustly monitor aset of assets, where robustness is assured by requiring asset $p$ to bemonitored by at least $\kappa(p)$ sensors. Given $n$ assets that must beobserved by $m$ sensors, each with a disk-shaped sensing region, where shouldthe sensors be placed to minimize the total area observed? We provide andanalyze a fast heuristic for this problem. We then use the heuristic toinitialize an exact Integer Programming solution. Subsequently, we enforceseparation constraints between the sensors by modifying the integer programformulation and by changing the disk candidate set.</description>
      <author>example@mail.com (Mariem Guitouni, Chek-Manh Loi, Sándor P. Fekete, Michael Perk, Aaron T. Becker)</author>
      <guid isPermaLink="false">2502.13773v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-dataset synergistic in supervised learning to pre-label structural components in point clouds from shell construction scenes</title>
      <link>http://arxiv.org/abs/2502.14721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 8 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在壳式建筑工地中，通过利用标准数据集和最新的Transformer模型架构来适应点云语义分割的方法。&lt;h4&gt;背景&lt;/h4&gt;构建新的训练数据集所需的重大努力阻碍了计算机视觉研究和建筑业中的机器学习发展。传统的室内物体分割方法无法有效应对复杂结构组件的语义分割挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在AEC领域中复杂结构性件分割的问题，通过利用现有的大规模室内数据集进行跨域推理，并应用迁移学习以最小化新标注数据的需求来最大化分割性能。&lt;h4&gt;方法&lt;/h4&gt;建立了通过监督训练和自定义验证数据集建立基准的方法；评估了跨域推理与大型室内数据集的使用效果；并利用转移学习策略在小规模注释下最大化语义分割性能。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的Transformer架构即使经过最小限度的微调也能提供有效的建筑组件分割策略，这为自动化新未见过的数据标注以及频繁出现的对象分割提供了有前景的方法。&lt;h4&gt;结论&lt;/h4&gt;利用迁移学习和现有的大规模室内数据集进行训练可以有效地解决AEC领域中复杂结构性件语义分割的问题，并且能够显著减少新的标注工作量。这种方法对于构建更大规模的训练资源具有重要意义，同时也为自动化注释新类型的数据提供了一条可行的道路。&lt;h4&gt;翻译&lt;/h4&gt;创建用于建筑工地点云语义分割的新数据集是一个劳动密集型的过程，这阻碍了计算机视觉研究和建筑业中机器学习的发展。本文探索了使用标准数据集以及最近的Transformer模型架构来处理壳式建筑工地中的问题。与通常专注于建筑物内部家具物体分割的方法不同，本研究侧重于在AEC（建筑、工程和施工）领域内复杂结构组件的语义分割挑战。我们通过监督训练建立了一个基准，并用一个自定义验证数据集进行了评估；同时利用大规模室内数据集进行跨域推理，并尝试了转移学习策略以最小化新标注数据的需求来优化性能。研究发现表明，即使是经过少量微调，预训练的Transformer架构也能提供有效的建筑组件分割策略，这为构建更大规模的训练资源以及自动化注释未见过的数据类型提供了有前景的方法和可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The significant effort required to annotate data for new training datasetshinders computer vision research and machine learning in the constructionindustry. This work explores adapting standard datasets and the latesttransformer model architectures for point cloud semantic segmentation in thecontext of shell construction sites. Unlike common approaches focused on objectsegmentation of building interiors and furniture, this study addressed thechallenges of segmenting complex structural components in Architecture,Engineering, and Construction (AEC). We establish a baseline through supervisedtraining and a custom validation dataset, evaluate the cross-domain inferencewith large-scale indoor datasets, and utilize transfer learning to maximizesegmentation performance with minimal new data. The findings indicate that withminimal fine-tuning, pre-trained transformer architectures offer an effectivestrategy for building component segmentation. Our results are promising forautomating the annotation of new, previously unseen data when creating largertraining resources and for the segmentation of frequently recurring objects.</description>
      <author>example@mail.com (Lukas Rauch, Thomas Braml)</author>
      <guid isPermaLink="false">2502.14721v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting</title>
      <link>http://arxiv.org/abs/2502.14525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Yannick W\"olker and Arash Hajisafi contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的图神经网络模型DeepStateGNN，用于分析交通数据，并展示了其在预测和重建任务中的有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的GNN方法将每个交通传感器视为图节点，而新提出的DeepStateGNN通过相似性标准对传感器进行聚类形成更高层次的图节点（称为深层状态节点），从而固定了图中节点的数量。&lt;h4&gt;目的&lt;/h4&gt;提出并验证一种新的用于分析大规模交通数据的高效和准确的方法DeepStateGNN。&lt;h4&gt;方法&lt;/h4&gt;DeepStateGNN根据空间接近度、功能相似性和特定条件下行为相似性对传感器进行聚类，形成深层状态节点。这种聚类方式允许动态且适应性的节点分组，并支持更快更精确的大规模交通网络分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，DeepStateGNN在可扩展性、训练速度和预测及重建准确性方面均优于传统方法，在大规模传感器网络中表现出色。&lt;h4&gt;结论&lt;/h4&gt;DeepStateGNN作为一种创新的图神经网络模型，在处理复杂且动态变化的大规模交通数据时具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, foranalyzing traffic data, demonstrating its efficacy in two critical tasks:forecasting and reconstruction. Unlike typical GNN methods that treat eachtraffic sensor as an individual graph node, DeepStateGNN clusters sensors intohigher-level graph nodes, dubbed Deep State Nodes, based on various similaritycriteria, resulting in a fixed number of nodes in a Deep State graph. The term"Deep State" nodes is a play on words, referencing hidden networks of powerthat, like these nodes, secretly govern traffic independently of visiblesensors. These Deep State Nodes are defined by several similarity factors,including spatial proximity (e.g., sensors located nearby in the road network),functional similarity (e.g., sensors on similar types of freeways), andbehavioral similarity under specific conditions (e.g., traffic behavior duringrain). This clustering approach allows for dynamic and adaptive node grouping,as sensors can belong to multiple clusters and clusters may evolve over time.Our experimental results show that DeepStateGNN offers superior scalability andfaster training, while also delivering more accurate results than competitors.It effectively handles large-scale sensor networks, outperforming other methodsin both traffic forecasting and reconstruction accuracy.</description>
      <author>example@mail.com (Yannick Wölker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz)</author>
      <guid isPermaLink="false">2502.14525v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2502.14235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。随着3DGaussian Splatting（3DGS）技术的进步，先前的研究已经将其应用于复杂动态驾驶场景的重建。然而，这些方法通常需要昂贵的LiDAR传感器和预注释的数据集来处理动态对象。为了解决这些问题，我们提出了一种新的方法OG-Gaussian。&lt;h4&gt;背景&lt;/h4&gt;准确且真实的3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术对昂贵设备和复杂手动标注的依赖，研究者提出了一个新框架来优化动态驾驶场景的三维重建过程。&lt;h4&gt;方法&lt;/h4&gt;我们提出了一种新的方法OG-Gaussian，该方法使用来自周围视图相机图像生成的Occupancy Grids（OGs）代替LiDAR点云。通过在ONet的帮助下预测占位网格中的语义信息，我们的方法能够将动态车辆与静态街道背景分离，并将其转换为用于重建静态和动态对象的初始点云集合。此外，我们采用基于学习的方法来估计动态物体的轨迹和姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，OG-Gaussian在Waymo Open数据集上，在重建质量和渲染速度方面与当前最先进技术相当，平均PSNR达到35.13，渲染速率达到143 FPS。同时，我们的方法显著降低了计算成本和经济负担。&lt;h4&gt;结论&lt;/h4&gt;提出的OG-Gaussian提供了一种高效且经济的方法来实现高质量的动态驾驶场景三维重建。&lt;h4&gt;翻译&lt;/h4&gt;准确且真实的3D场景重建对于创建逼真的自动驾驶模拟环境至关重要。随着3DGaussian Splatting（3DGS）技术的进步，先前的研究已经将其应用于复杂动态驾驶场景的重建。然而，这些方法通常需要昂贵的LiDAR传感器和预注释的数据集来处理动态对象。为了解决这些问题，我们提出了一种新的方法OG-Gaussian，该方法使用来自周围视图相机图像生成的Occupancy Grids（OGs）代替LiDAR点云，并在ONet的帮助下预测占位网格中的语义信息，将动态车辆与静态街道背景分离并转换为用于重建的初始点云集合。此外，我们采用基于学习的方法来估计动态物体的轨迹和姿态。实验结果表明，在Waymo Open数据集上，OG-Gaussian在重建质量和渲染速度方面表现优异（平均PSNR：35.13；FPS：143），同时显著降低了计算成本和经济负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and realistic 3D scene reconstruction enables the lifelike creationof autonomous driving simulation environments. With advancements in 3D GaussianSplatting (3DGS), previous studies have applied it to reconstruct complexdynamic driving scenes. These methods typically require expensive LiDAR sensorsand pre-annotated datasets of dynamic objects. To address these challenges, wepropose OG-Gaussian, a novel approach that replaces LiDAR point clouds withOccupancy Grids (OGs) generated from surround-view camera images usingOccupancy Prediction Network (ONet). Our method leverages the semanticinformation in OGs to separate dynamic vehicles from static street background,converting these grids into two distinct sets of initial point clouds forreconstructing both static and dynamic objects. Additionally, we estimate thetrajectories and poses of dynamic objects through a learning-based approach,eliminating the need for complex manual annotations. Experiments on Waymo Opendataset demonstrate that OG-Gaussian is on par with the currentstate-of-the-art in terms of reconstruction quality and rendering speed,achieving an average PSNR of 35.13 and a rendering speed of 143 FPS, whilesignificantly reducing computational costs and economic overhead.</description>
      <author>example@mail.com (Yedong Shen, Xinran Zhang, Yifan Duan, Shiqi Zhang, Heng Li, Yilong Wu, Jianmin Ji, Yanyong Zhang)</author>
      <guid isPermaLink="false">2502.14235v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>DAG: Deep Adaptive and Generative $K$-Free Community Detection on Attributed Graphs</title>
      <link>http://arxiv.org/abs/2502.14294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种用于社区检测的新模型DAG，该模型能够自动寻找最佳的社团数量，并无需人工指定社团的数量。通过在节点表示学习、社区隶属度读取和社团数量搜索三个模块的设计上进行创新，实现了端到端的学习过程。&lt;h4&gt;背景&lt;/h4&gt;带有丰富语义和拓扑信息的图上的社区检测对于现实世界网络分析尤其是在线游戏中的用户匹配具有巨大潜力。然而，在现有的深度图聚类方法中，确定最优社区数量需要昂贵的人工成本以及可能侵犯隐私的数据获取方式。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需事先指定社团数量K的方法来解决社区发现问题，即K-Free Community Detection问题。&lt;h4&gt;方法&lt;/h4&gt;设计了Deep Adaptive and Generative (DAG)模型。该模型包含三个关键组成部分：带掩码属性重建的节点表示学习模块、社区隶属度读取模块以及采用群稀疏策略寻找社团数量的搜索模块。通过这些创新，实现了端到端同时进行社区检测和社团数量搜索。&lt;h4&gt;主要发现&lt;/h4&gt;提出的DAG模型在五个公共数据集及一个真实在线手游数据集中表现出了优越性。特别是在腾讯的一个游戏中，相对于最佳竞争方法，DAG提高了7.35%的团队效率。&lt;h4&gt;结论&lt;/h4&gt;通过创新性的算法设计，所提出的方法克服了传统社区检测面临的参数选择难题，并展现了实际应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;带有丰富语义和拓扑信息的图上的社区发现为现实世界网络分析提供了巨大潜力，特别是在在线游戏用户匹配方面。近年来，图神经网络（GNN）使深度图聚类方法能够从语义和拓扑信息中学习社团分配。然而，其成功依赖于关于社群数量K的先验知识，这在获取成本高昂以及存在隐私问题的情况下是不现实的。本文探讨了无需先验知识确定社区数量的情况下的社区发现问题，并提出了一种新颖的深度自适应与生成模型（DAG），该模型能够在不指定社团数量的前提下进行社区检测。此外还设计了一个新指标EDGE，用于在标签难以获取的真实世界应用中评估社区检测方法的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Community detection on attributed graphs with rich semantic and topologicalinformation offers great potential for real-world network analysis, especiallyuser matching in online games. Graph Neural Networks (GNNs) have recentlyenabled Deep Graph Clustering (DGC) methods to learn cluster assignments fromsemantic and topological information. However, their success depends on theprior knowledge related to the number of communities $K$, which is unrealisticdue to the high costs and privacy issues of acquisition.In this paper, weinvestigate the community detection problem without prior $K$, referred to as$K$-Free Community Detection problem. To address this problem, we propose anovel Deep Adaptive and Generative model~(DAG) for community detection withoutspecifying the prior $K$. DAG consists of three key components, \textit{i.e.,}a node representation learning module with masked attribute reconstruction, acommunity affiliation readout module, and a community number search module withgroup sparsity. These components enable DAG to convert the process ofnon-differentiable grid search for the community number, \textit{i.e.,} adiscrete hyperparameter in existing DGC methods, into a differentiable learningprocess. In such a way, DAG can simultaneously perform community detection andcommunity number search end-to-end. To alleviate the cost of acquiringcommunity labels in real-world applications, we design a new metric, EDGE, toevaluate community detection methods even when the labels are not feasible.Extensive offline experiments on five public datasets and a real-world onlinemobile game dataset demonstrate the superiority of our DAG over the existingstate-of-the-art (SOTA) methods. DAG has a relative increase of 7.35\% in teamsin a Tencent online game compared with the best competitor.</description>
      <author>example@mail.com (Chang Liu, Yuwen Yang, Yue Ding, Hongtao Lu, Wenqing Lin, Ziming Wu, Wendong Bi)</author>
      <guid isPermaLink="false">2502.14294v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis</title>
      <link>http://arxiv.org/abs/2502.14807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为FetalCLIP的视觉-语言基础模型，该模型能够生成胎儿超声图像的通用表示。&lt;h4&gt;背景&lt;/h4&gt;尽管基础模型在医疗领域变得越来越有效，但胎儿超声图像仍然是一个具有挑战性的领域，因为它们自身复杂性高，并且缺乏配对的多模态数据。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，引入了FetalCLIP这一视觉-语言基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用包含210,035张胎儿超声图像与文本配对的大规模多样本数据集进行预训练。这是迄今为止用于基础模型开发的最大规模的配对数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的基准测试中，FetalCLIP在分类、妊娠年龄估计、先天性心脏病检测和胎儿结构分割等关键胎儿超声应用中表现优于所有基线，并且展示了出色的泛化能力，在有限标签数据的情况下仍表现出色。&lt;h4&gt;结论&lt;/h4&gt;计划公开发布FetalCLIP模型以造福更广泛的科学界。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在医疗领域的有效性正在不断提升，提供了可以轻松适应下游任务的大型数据集上的预训练模型。尽管取得了进展，胎儿超声图像仍然是一个具有挑战性的领域，因为它们固有的复杂性通常需要大量的额外训练，并且由于多模态配对数据的缺乏而面临限制。为了克服这些挑战，我们引入了FetalCLIP这一视觉-语言基础模型，它可以生成胎儿超声图像的通用表示。FetalCLIP使用包含210,035张胎儿超声图像与文本配对的大规模多样本数据集进行预训练。这是迄今为止用于基础模型开发的最大规模的配对数据集。这种独特的培训方法使FetalCLIP能够有效地学习胎儿超声图像中复杂的解剖特征，从而产生可用于多种下游应用的强大表示。在广泛的基准测试中，包括分类、妊娠年龄估计、先天性心脏病(CHD)检测和胎儿结构分割等关键胎儿超声应用，FetalCLIP的表现优于所有基线，并且展示了出色的泛化能力，在有限标签数据的情况下仍表现出色。我们计划公开发布FetalCLIP模型以造福更广泛的科学界。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are becoming increasingly effective in the medical domain,offering pre-trained models on large datasets that can be readily adapted fordownstream tasks. Despite progress, fetal ultrasound images remain achallenging domain for foundation models due to their inherent complexity,often requiring substantial additional training and facing limitations due tothe scarcity of paired multimodal data. To overcome these challenges, here weintroduce FetalCLIP, a vision-language foundation model capable of generatinguniversal representation of fetal ultrasound images. FetalCLIP was pre-trainedusing a multimodal learning approach on a diverse dataset of 210,035 fetalultrasound images paired with text. This represents the largest paired datasetof its kind used for foundation model development to date. This unique trainingapproach allows FetalCLIP to effectively learn the intricate anatomicalfeatures present in fetal ultrasound images, resulting in robustrepresentations that can be used for a variety of downstream applications. Inextensive benchmarking across a range of key fetal ultrasound applications,including classification, gestational age estimation, congenital heart defect(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed allbaselines while demonstrating remarkable generalizability and strongperformance even with limited labeled data. We plan to release the FetalCLIPmodel publicly for the benefit of the broader scientific community.</description>
      <author>example@mail.com (Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring, Saudabi Valappi, Leanne Bricker, Mohammad Yaqub)</author>
      <guid isPermaLink="false">2502.14807v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Dual-level Mixup for Graph Few-shot Learning with Fewer Tasks</title>
      <link>http://arxiv.org/abs/2502.14158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为SMILE的方法，用于在少量任务的情况下进行图的少样本学习。该方法通过双层mixup策略增强了元学习中的节点和任务多样性，并利用了图中节点度数提供的先验信息。&lt;h4&gt;背景&lt;/h4&gt;当前领先的图形模型需要大量的标记样本以避免在少样本场景下出现过拟合的情况，而最近的研究试图通过结合图学习与元学习来缓解这一问题。然而，这样的假设可能不现实，因为构建任务和涉及的成本很高。&lt;h4&gt;目的&lt;/h4&gt;提出一个简单有效的方法（SMILE），用于解决图形元学习中需要大量任务的问题，并在少样本场景下提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入双层mixup策略，包括在同一任务内的以及跨任务的混合技术。此外，利用图中的节点度数信息来编码更表达式的节点表示。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了SMILE能够增强模型的泛化能力；实验上，在所有评估数据集（无论是领域内还是跨域）中，SMILE均以显著优势超过了其他竞争性模型。&lt;h4&gt;结论&lt;/h4&gt;SMILE是一种简单有效的解决图形少样本学习问题的方法，通过丰富元学习中的节点和任务多样性，并利用图结构的先验信息来提升模型性能。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络已经被证明可以在网络上有效地学习图数据并从中挖掘内容。然而，现有的领先图形模型需要大量标记样本以避免在少量样本场景下的过拟合问题。最近的研究试图通过结合图学习与元学习来缓解这一问题。但是，这样的假设可能不现实，因为构建任务和涉及的成本很高。因此，我们提出了一种称为SMILE的方法，用于解决图形少样本学习中的任务数量较少的问题。该方法引入了双层mixup策略，在丰富元学习中可获得的节点和任务的同时，利用图结构提供的先验信息（即节点度数），以编码表达式的节点表示。理论上证明了SMILE可以提高模型的泛化能力；在实验上，SMILE在所有评估的数据集下均优于其他竞争性模型。我们的匿名代码可以在给定链接处找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714905&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been demonstrated as a powerful paradigm foreffectively learning graph-structured data on the web and mining content fromit.Current leading graph models require a large number of labeled samples fortraining, which unavoidably leads to overfitting in few-shot scenarios. Recentresearch has sought to alleviate this issue by simultaneously leveraging graphlearning and meta-learning paradigms. However, these graph meta-learning modelsassume the availability of numerous meta-training tasks to learn transferablemeta-knowledge. Such assumption may not be feasible in the real world due tothe difficulty of constructing tasks and the substantial costs involved.Therefore, we propose a SiMple yet effectIve approach for graph few-shotLearning with fEwer tasks, named SMILE. We introduce a dual-level mixupstrategy, encompassing both within-task and across-task mixup, tosimultaneously enrich the available nodes and tasks in meta-learning. Moreover,we explicitly leverage the prior information provided by the node degrees inthe graph to encode expressive node representations. Theoretically, wedemonstrate that SMILE can enhance the model generalization ability.Empirically, SMILE consistently outperforms other competitive models by a largemargin across all evaluated datasets with in-domain and cross-domain settings.Our anonymous code can be found here.</description>
      <author>example@mail.com (Yonghao Liu, Mengyu Li, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan)</author>
      <guid isPermaLink="false">2502.14158v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>LXLv2: Enhanced LiDAR Excluded Lean 3D Object Detection with Fusion of 4D Radar and Camera</title>
      <link>http://arxiv.org/abs/2502.14503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Robotics and Automation Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了LXLv2，改进了之前最先进的4D雷达相机融合的3D目标检测方法（LXL），通过新的深度监督策略和基于通道与空间注意力机制的融合模块，提升了模型的准确性、速度和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的LXL方法利用预测的图像深度分布图和雷达三维占用网格来辅助样本基础的图像视角转换。然而，该方法在深度预测的准确性和一致性上存在不足，并且基于拼接的融合方式影响了模型的健壮性。&lt;h4&gt;目的&lt;/h4&gt;改进现有技术中的缺陷，提高3D目标检测的精度、速度及鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;[{'一到多深度监督策略': '该策略通过雷达点的位置误差进行设计，并利用雷达散射截面（RCS）值调整监管区域以增强对象级别的深度一致性。'}, {'CSAFusion模块': '引入了基于通道和空间注意机制的融合模块，用于提高特征适应性。'}]&lt;h4&gt;主要发现&lt;/h4&gt;['在View-of-Delft和TJ4DRadSet数据集上的实验结果表明LXLv2优于原始方法LXL，在检测精度、推断速度以及鲁棒性方面均表现出显著优势。', '模型的改进策略有效提升了3D目标检测任务的整体性能。']&lt;h4&gt;结论&lt;/h4&gt;通过改进深度预测和特征融合机制，可以有效地解决现有雷达-相机融合技术中的问题，并提高其在复杂场景下的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;作为之前的最先进的4D雷达-相机融合基础的3D对象检测方法LXL使用了预测的图像深度分布图和雷达三维占用网格来辅助基于采样的图像视角转换。然而，深度预测缺乏准确性和一致性，而LXL中的基于拼接的融合方式阻碍了模型的鲁棒性。在这项工作中，我们提出了LXLv2，在该版本中进行了修改以克服限制并提高性能。具体来说，考虑到雷达测量的位置误差，我们设计了一种通过雷达点实现的一对多深度监督策略，并利用雷达散射截面（RCS）值进一步调整监管区域以增强对象级别的深度一致性。此外，引入了一个名为CSAFusion的通道和空间注意机制融合模块来提高特征适应性。在View-of-Delft和TJ4DRadSet数据集上的实验结果表明所提出的LXLv2能够优于原始方法LXL，在检测精度、推理速度和鲁棒性方面都有改进，显示了模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3536840&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the previous state-of-the-art 4D radar-camera fusion-based 3D objectdetection method, LXL utilizes the predicted image depth distribution maps andradar 3D occupancy grids to assist the sampling-based image viewtransformation. However, the depth prediction lacks accuracy and consistency,and the concatenation-based fusion in LXL impedes the model robustness. In thiswork, we propose LXLv2, where modifications are made to overcome thelimitations and improve the performance. Specifically, considering the positionerror in radar measurements, we devise a one-to-many depth supervision strategyvia radar points, where the radar cross section (RCS) value is furtherexploited to adjust the supervision area for object-level depth consistency.Additionally, a channel and spatial attention-based fusion module namedCSAFusion is introduced to improve feature adaptiveness. Experimental resultson the View-of-Delft and TJ4DRadSet datasets show that the proposed LXLv2 canoutperform LXL in detection accuracy, inference speed and robustness,demonstrating the effectiveness of the model.</description>
      <author>example@mail.com (Weiyi Xiong, Zean Zou, Qiuchi Zhao, Fengchun He, Bing Zhu)</author>
      <guid isPermaLink="false">2502.14503v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors</title>
      <link>http://arxiv.org/abs/2502.14627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多语言音频-文本检索（ML-ATR）方案，旨在解决跨语言实例相似性匹配的不一致性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的ML-ATR方案在跨语言相似性匹配中存在不一致性问题。这些问题源于跨模态对齐方向误差和权重误差。&lt;h4&gt;目的&lt;/h4&gt;理论分析了权重误差上限，并提出了一种基于1-to-k对比学习和音频-英语共锚对比学习的一致性ML-ATR方案，以减轻数据分布误差对召回率和一致性的负面影响。&lt;h4&gt;方法&lt;/h4&gt;使用1-to-k对比学习和音频-英语共锚对比学习来解决多语言模态对齐问题，并通过理论分析确定权重误差上限。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在翻译的AudioCaps和Clotho数据集上，该方案在八种主流语言（包括英语）上的召回率和一致性指标方面达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的ML-ATR方案有效提高了多语言音频-文本检索的一致性和召回率，并且源代码可在指定网址获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims toretrieve audio clips or multilingual texts from databases. However, existingML-ATR schemes suffer from inconsistencies for instance similarity matchingacross languages. We theoretically analyze the inconsistency in terms of bothmultilingual modal alignment direction error and weight error, and propose thetheoretical weight error upper bound for quantifying the inconsistency. Basedon the analysis of the weight error upper bound, we find that the inconsistencyproblem stems from the data distribution error caused by random sampling oflanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastivelearning and audio-English co-anchor contrastive learning, aiming to mitigatethe negative impact of data distribution error on recall and consistency inML-ATR. Experimental results on the translated AudioCaps and Clotho datasetsshow that our scheme achieves state-of-the-art performance on recall andconsistency metrics for eight mainstream languages, including English. Our codewill be available at https://github.com/ATRI-ACL/ATRI-ACL.</description>
      <author>example@mail.com (Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou)</author>
      <guid isPermaLink="false">2502.14627v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare Text Multi-Label Classification</title>
      <link>http://arxiv.org/abs/2502.14189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为QUAD-LLM-MLTC的方法，该方法使用四种大型语言模型（LLMs）来处理多标签文本分类问题，尤其是在医疗领域的应用。&lt;h4&gt;背景描述&lt;/h4&gt;随着医疗领域内收集到的文本数据量不断增加，传统的机器学习模型难以有效应对这种大规模且复杂的数据集。此外，标记化的训练样本稀缺且具有复杂的语义特征。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种利用大型语言模型（LLMs）进行多标签文本分类的新方法，并证明这种方法在医疗文本分类上的有效性。&lt;h4&gt;采用的方法&lt;/h4&gt;引入了QUAD-LLM-MLTC框架，该框架结合了四个不同的预训练模型：BERT、PEGASUS、GPT-4o和BART。这些模型分别用于提取关键词、增强数据、执行分类以及提供标签概率。&lt;h4&gt;实验结果&lt;/h4&gt;通过三个标注文本样本的评估对比传统方法与单一模型的方法，结果显示在F1分数和一致性上均有显著提高（分别为78.17%和80.16%，标准偏差为0.025和0.011）。&lt;h4&gt;结论&lt;/h4&gt;此研究展示了大型语言模型在多标签文本分类上的强大潜力，并提出了一种无需额外训练即可快速准确地处理医疗领域内海量数据的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The escalating volume of collected healthcare textual data presents a uniquechallenge for automated Multi-Label Text Classification (MLTC), which isprimarily due to the scarcity of annotated texts for training and their nuancednature. Traditional machine learning models often fail to fully capture thearray of expressed topics. However, Large Language Models (LLMs) havedemonstrated remarkable effectiveness across numerous Natural LanguageProcessing (NLP) tasks in various domains, which show impressive computationalefficiency and suitability for unsupervised learning through promptengineering. Consequently, these LLMs promise an effective MLTC of medicalnarratives. However, when dealing with various labels, different prompts can berelevant depending on the topic. To address these challenges, the proposedapproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,PEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in whichBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, andBART provides topics' assignment probabilities, which results in fourclassifications, all in a 0-shot setting. The outputs are then combined usingensemble learning and processed through a meta-classifier to produce the finalMLTC result. The approach is evaluated using three samples of annotated texts,which contrast it with traditional and single-model methods. The results showsignificant improvements across the majority of the topics in theclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and80.16% with standard deviations of 0.025 and 0.011, respectively). Thisresearch advances MLTC using LLMs and provides an efficient and scalablesolution to rapidly categorize healthcare-related text data without furthertraining.</description>
      <author>example@mail.com (Hajar Sakai, Sarah S. Lam)</author>
      <guid isPermaLink="false">2502.14189v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Spiking Neural Networks from an Ensemble Learning Perspective</title>
      <link>http://arxiv.org/abs/2502.14218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;该论文提出了一种新的方法来提高脉冲神经网络（SNNs）的性能。&lt;h4&gt;背景信息&lt;/h4&gt;SNNs具有较高的能源效率，但存在性能不足的问题。研究者发现时间步长之间的初始状态差异过大是导致不稳定输出和性能下降的关键原因。&lt;h4&gt;主要目的&lt;/h4&gt;通过减少初始膜电位分布及其输出在不同时间步上的不一致性来提高SNN的稳定性和整体性能。&lt;h4&gt;提出方法&lt;/h4&gt;{'膜电位平滑': '一种改进措施，旨在促进信息向前传播并解决时间梯度消失问题。', '相邻子网络指导': '另一种策略，通过调整相邻的时间子网之间的关系以进一步提升稳定性。'}&lt;h4&gt;主要发现&lt;/h4&gt;该技术只需对脉冲神经元进行轻微修改而不需改变网络结构，并在1D语音、2D物体和3D点云识别任务中展示了稳定且一致的性能改进。&lt;h4&gt;具体成就&lt;/h4&gt;在CIFAR10-DVS数据集上，仅使用四个时间步就达到了83.20%的准确率。&lt;h4&gt;结论与意义&lt;/h4&gt;该研究为释放SNNs潜力提供了宝贵见解，并可能对神经形态计算领域产生深远影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spiking neural networks (SNNs) exhibit superior energy efficiency but sufferfrom limited performance. In this paper, we consider SNNs as ensembles oftemporal subnetworks that share architectures and weights, and highlight acrucial issue that affects their performance: excessive differences in initialstates (neuronal membrane potentials) across timesteps lead to unstablesubnetwork outputs, resulting in degraded performance. To mitigate this, wepromote the consistency of the initial membrane potential distribution andoutput through membrane potential smoothing and temporally adjacent subnetworkguidance, respectively, to improve overall stability and performance. Moreover,membrane potential smoothing facilitates forward propagation of information andbackward propagation of gradients, mitigating the notorious temporal gradientvanishing problem. Our method requires only minimal modification of the spikingneurons without adapting the network structure, making our method generalizableand showing consistent performance gains in 1D speech, 2D object, and 3D pointcloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset,we achieved 83.20\% accuracy with only four timesteps. This provides valuableinsights into unleashing the potential of SNNs.</description>
      <author>example@mail.com (Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Hanpu Deng)</author>
      <guid isPermaLink="false">2502.14218v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing PDF Data for Improving Japanese Large Multimodal Models</title>
      <link>http://arxiv.org/abs/2502.14778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用日本PDF数据训练大模态模型（LMM）以提高其在日本语言环境中的效果。&lt;h4&gt;背景&lt;/h4&gt;当前的大模态模型在英语中表现出色，但在日语环境中由于高质量训练数据的缺乏，性能受限。现有的日语大模态模型往往依赖于翻译后的英文数据集，限制了它们捕捉日本特定文化知识的能力。&lt;h4&gt;目的&lt;/h4&gt;探索利用日本PDF文档作为训练资源的可能性，并构建一个自动化流程来从这些文档中提取图像-文本对以丰富日语大模态模型的训练数据。&lt;h4&gt;方法&lt;/h4&gt;提出了一个完全自动化的管道，该管道使用预训练模型通过版面分析、OCR和视觉语言配对技术从PDF文件中抽取图像-文本对。此外，还构建了指令数据集来进一步增强训练数据。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，基于PDF的数据显著提高了日语大模态模型的性能，在Heron-Bench上的表现提升了3.9%到13.8%不等。&lt;h4&gt;结论&lt;/h4&gt;PDF文档作为多模态资源对各种因素（如模型大小和语言模型）的影响得到了强化，证明了其在提高日语文本模型性能方面的价值。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要描述了一个旨在提升日本大模态模型训练效果的研究项目。该项目探索利用未充分利用的日本PDF数据集，并开发了一种自动化流程来从这些文档中提取高质量的数据对进行模型训练。研究结果表明，这种方法显著改善了日语大模态模型在特定基准上的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Multimodal Models (LMMs) have demonstrated strong performance inEnglish, but their effectiveness in Japanese remains limited due to the lack ofhigh-quality training data. Current Japanese LMMs often rely on translatedEnglish datasets, restricting their ability to capture Japan-specific culturalknowledge. To address this, we explore the potential of Japanese PDF data as atraining resource, an area that remains largely underutilized. We introduce afully automated pipeline that leverages pretrained models to extract image-textpairs from PDFs through layout analysis, OCR, and vision-language pairing,removing the need for manual annotation. Additionally, we construct instructiondata from extracted image-text pairs to enrich the training data. To evaluatethe effectiveness of PDF-derived data, we train Japanese LMMs and assess theirperformance on the Japanese LMM Benchmark. Our results demonstrate substantialimprovements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.Further analysis highlights the impact of PDF-derived data on various factors,such as model size and language models, reinforcing its value as a multimodalresource for Japanese LMMs. We plan to make the source code and data publiclyavailable upon acceptance.</description>
      <author>example@mail.com (Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa)</author>
      <guid isPermaLink="false">2502.14778v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains</title>
      <link>http://arxiv.org/abs/2502.14293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了AdaGraph-T3，一种针对跨领域图异常检测的测试时训练框架。&lt;h4&gt;背景&lt;/h4&gt;在新兴应用中，图结构数据中的标签异常通常稀缺，现有的监督式图异常检测方法由于分布偏移和异构特征空间的问题，在跨域情况下效果不佳或不可用。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，提出了一个新颖的测试时训练框架AdaGraph-T3，旨在解决跨领域图异常检测问题。&lt;h4&gt;方法&lt;/h4&gt;AdaGraph-T3结合了监督学习和自监督学习，并在测试阶段仅使用自监督学习进行领域适应，通过基于同质性的亲和力分数捕捉异常的域不变属性。引入四种关键创新：有效的自监督方案、基于注意力机制的学习边权重的方法、处理异构特征的特定领域的编码器以及解决不平衡问题的类别感知正则化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AdaGraph-T3在多个跨领域设置下显著优于现有方法，在AUROC和AUPRC上平均分别提高了6.6%和7.9%。&lt;h4&gt;结论&lt;/h4&gt;AdaGraph-T3能够有效地应对标签稀缺的挑战，并且在不同的图结构数据异常检测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Anomaly Detection (GAD) has demonstrated great effectiveness inidentifying unusual patterns within graph-structured data. However, whilelabeled anomalies are often scarce in emerging applications, existingsupervised GAD approaches are either ineffective or not applicable when movedacross graph domains due to distribution shifts and heterogeneous featurespaces. To address these challenges, we present AdaGraph-T3, a novel test-timetraining framework for cross-domain GAD. AdaGraph-T3 combines supervised andself-supervised learning during training while adapting to a new domain duringtest time using only self-supervised learning by leveraging a homophily-basedaffinity score that captures domain-invariant properties of anomalies. Ourframework introduces four key innovations to cross-domain GAD: an effectiveself-supervision scheme, an attention-based mechanism that dynamically learnsedge importance weights during message passing, domain-specific encoders forhandling heterogeneous features, and class-aware regularization to addressimbalance. Experiments across multiple cross-domain settings demonstrate thatAdaGraph-T3 significantly outperforms existing approaches, achieving averageimprovements of over 6.6% in AUROC and 7.9% in AUPRC compared to the bestcompeting model.</description>
      <author>example@mail.com (Delaram Pirhayati, Arlei Silva)</author>
      <guid isPermaLink="false">2502.14293v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Nearshore Underwater Target Detection Meets UAV-borne Hyperspectral Remote Sensing: A Novel Hybrid-level Contrastive Learning Framework and Benchmark Dataset</title>
      <link>http://arxiv.org/abs/2502.14495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18pages,13figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HUCLNet的新框架，用于改进近岸区域水下目标检测（UTD）的准确性。该方法利用对比学习和自适应学习策略来提取受光谱畸变影响的数据中具有区分性的特征。&lt;h4&gt;背景&lt;/h4&gt;无人机携带的高光谱遥感技术在水下目标探测领域展现出巨大潜力，但在近岸环境中的光谱扭曲限制了其效果。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的网络框架以克服传统基于海底模型的高光谱水下目标检测方法面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为HUCLNet的新框架，该框架结合对比学习和自适应学习策略，从受畸变影响的数据中提取区分性特征。此外，还使用了可靠性引导的聚类策略来增强所学表示的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在新的近岸高光谱水下目标检测基准数据集ATR2-HUTD上进行广泛的实验表明，HUCLNet显著优于现有的先进方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效地提高无人机携带的高光谱遥感技术在复杂水域中进行水下目标探测的能力。&lt;h4&gt;翻译&lt;/h4&gt;无人机搭载的高光谱遥感技术已经成为一种有前景的水下目标检测（UTD）方法，但其在近岸环境中的效能受到光谱畸变的影响。这些畸变降低了传统基于海底模型的高光谱UTD方法的有效性，并增加了目标和背景光谱的不确定性。为了应对这一挑战，我们提出了一种新的框架——Hyperspectral Underwater Contrastive Learning Network (HUCLNet)，它结合了对比学习与自适应学习策略来增强近岸区域水下目标检测的鲁棒性。此外，在一系列实验中，通过一个新的基准数据集ATR2-HUTD证明了该方法的有效性，并显示出优于现有最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAV-borne hyperspectral remote sensing has emerged as a promising approachfor underwater target detection (UTD). However, its effectiveness is hinderedby spectral distortions in nearshore environments, which compromise theaccuracy of traditional hyperspectral UTD (HUTD) methods that rely onbathymetric model. These distortions lead to significant uncertainty in targetand background spectra, challenging the detection process. To address this, wepropose the Hyperspectral Underwater Contrastive Learning Network (HUCLNet), anovel framework that integrates contrastive learning with a self-paced learningparadigm for robust HUTD in nearshore regions. HUCLNet extracts discriminativefeatures from distorted hyperspectral data through contrastive learning, whilethe self-paced learning strategy selectively prioritizes the most informativesamples. Additionally, a reliability-guided clustering strategy enhances therobustness of learned representations.To evaluate the method effectiveness, weconduct a novel nearshore HUTD benchmark dataset, ATR2-HUTD, covering threediverse scenarios with varying water types and turbidity, and target types.Extensive experiments demonstrate that HUCLNet significantly outperformsstate-of-the-art methods. The dataset and code will be publicly available at:https://github.com/qjh1996/HUTD</description>
      <author>example@mail.com (Jiahao Qi, Chuanhong Zhou, Xingyue Liu, Chen Chen, Dehui Zhu, Kangcheng Bin, Ping Zhong)</author>
      <guid isPermaLink="false">2502.14495v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration</title>
      <link>http://arxiv.org/abs/2502.14156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为Mixed Signals的全面车辆到一切（V2X）数据集，该数据集旨在解决现有V2X数据集中存在的局限性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的V2X数据集在范围、多样性和质量方面存在限制，这影响了单个车辆感知系统的性能。&lt;h4&gt;目的&lt;/h4&gt;为了填补这些空白，作者创建了一个名为Mixed Signals的数据集，它包含来自三辆配备两种不同类型的LiDAR传感器的连接自主汽车（CAVs）以及路边单元的数据。&lt;h4&gt;方法&lt;/h4&gt;该数据集提供了精确对齐的点云和跨越10类别的边界框注释，并且还进行了详细的统计分析和现有V2X方法的基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;Mixed Signals V2X Dataset是目前公开可用的用于V2X感知研究的最高质量和大规模的数据集之一。&lt;h4&gt;结论&lt;/h4&gt;该数据集提供了高质量、多样的数据，有助于推动V2X协作感知技术的发展，并为未来的相关研究奠定了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;车辆到一切（V2X）协作感知作为一种解决方案已出现，旨在解决单个车辆感知系统中的限制。然而，现有的V2X数据集在范围、多样性和质量方面存在局限性。为了填补这些空白，我们提出了Mixed Signals，这是一个综合的V2X数据集，其中包含45.1k点云和来自三个配备两种不同类型的LiDAR传感器的连接自主汽车（CAVs）以及一个带有双LiDAR的路边单元采集到的240.6k边界框。该数据集提供精确对齐的点云和跨越十类别的边界框注释，确保了用于感知训练的数据可靠且高质量。我们提供了关于数据集质量的详细统计分析，并对其进行了广泛的基准测试以评估现有的V2X方法。Mixed Signals V2X Dataset是目前公开可用的质量最高、规模最大的V2X感知研究数据集之一。详情请访问我们的网站 https://mixedsignalsdataset.cs.cornell.edu/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle-to-everything (V2X) collaborative perception has emerged as apromising solution to address the limitations of single-vehicle perceptionsystems. However, existing V2X datasets are limited in scope, diversity, andquality. To address these gaps, we present Mixed Signals, a comprehensive V2Xdataset featuring 45.1k point clouds and 240.6k bounding boxes collected fromthree connected autonomous vehicles (CAVs) equipped with two different types ofLiDAR sensors, plus a roadside unit with dual LiDARs. Our dataset providesprecisely aligned point clouds and bounding box annotations across 10 classes,ensuring reliable data for perception training. We provide detailed statisticalanalysis on the quality of our dataset and extensively benchmark existing V2Xmethods on it. Mixed Signals V2X Dataset is one of the highest quality,large-scale datasets publicly available for V2X perception research. Details onthe website https://mixedsignalsdataset.cs.cornell.edu/.</description>
      <author>example@mail.com (Katie Z Luo, Minh-Quan Dao, Zhenzhen Liu, Mark Campbell, Wei-Lun Chao, Kilian Q. Weinberger, Ezio Malis, Vincent Fremont, Bharath Hariharan, Mao Shan, Stewart Worrall, Julie Stephany Berrio Perez)</author>
      <guid isPermaLink="false">2502.14156v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies</title>
      <link>http://arxiv.org/abs/2502.14197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Anomaly Detection in Scientific Domains AAAI Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于学习时空交互的图神经网络的新方法。&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络依赖于预定义的图结构，这可能模糊了模型中被精确描述的关系。现有的方法通常基于固定的空间位置来定义节点，这种策略在动态环境中（如海洋环境）并不适用。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的图表示方法，旨在明确捕捉时间依赖关系和空间交互，并适用于动态环境。&lt;h4&gt;方法&lt;/h4&gt;将时间戳作为独立节点建模，通过图边显式地捕获时间依赖性。这种方法被扩展以构建多船图，能够有效地捕捉空间互动同时保持图形稀疏性。使用图卷积网络层处理该图，用于捕获时空模式，并结合预测层和变分图自编码器进行特征预测及重构。&lt;h4&gt;主要发现&lt;/h4&gt;新方法能够在动态环境中有效学习时空交互，通过创新的节点定义策略增强对时间依赖性的捕捉能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为在复杂且动态的环境下利用图神经网络建模提供了新的视角，并具有强大的异常检测能力。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络已经成为学习时空交互的强大工具。然而，传统的做法通常依赖于预定义的图结构，这可能会模糊模型中被精确描述的关系。此外，现有的方法一般基于固定的空间位置来定义节点，这种方法对于像海洋环境这样的动态环境是不合适的。我们的方法引入了一种创新的图表示方式，其中时间戳被建模为独立的节点，允许通过图边显式地捕获时间依赖性。此设置被扩展以构建一个多船图，能够有效地捕捉空间互动同时保持图形稀疏性。该图使用图卷积网络层来处理，用于捕捉时空模式，并结合预测层和变分图自编码器进行特征预测及重构，从而实现强大的异常检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have emerged as a powerful tool for learningspatiotemporal interactions. However, conventional approaches often rely onpredefined graphs, which may obscure the precise relationships being modeled.Additionally, existing methods typically define nodes based on fixed spatiallocations, a strategy that is ill-suited for dynamic environments like maritimeenvironments. Our method introduces an innovative graph representation wheretimestamps are modeled as distinct nodes, allowing temporal dependencies to beexplicitly captured through graph edges. This setup is extended to construct amulti-ship graph that effectively captures spatial interactions whilepreserving graph sparsity. The graph is processed using Graph ConvolutionalNetwork layers to capture spatiotemporal patterns, with a forecasting layer forfeature prediction and a Variational Graph Autoencoder for reconstruction,enabling robust anomaly detection.</description>
      <author>example@mail.com (Jeehong Kim, Minchan Kim, Jaeseong Ju, Youngseok Hwang, Wonhee Lee, Hyunwoo Park)</author>
      <guid isPermaLink="false">2502.14197v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Distribution Matching for Self-Supervised Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.14424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个新颖的自监督迁移学习方法——分布匹配(DM)，该方法在保持增强不变性的同时，驱动表示向预定义的参考分布靠拢。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督迁移学习方法可能难以解释其内部结构和超参数的意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够提供直观且易于理解的表示空间的设计，并通过理论保证来证明该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的自监督转移学习方法，称为分布匹配(DM)，这种方法使得学习到的表示空间具有结构性并且其超参数可解释。此外，提供了DM的方法论上的保证，包括一个总体定理和端到端样本理论。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明了在多个现实世界数据集上以及评估指标中，相对于现有的自监督迁移学习方法，DM在目标分类任务上有竞争力的表现。即使样本数量有限的情况下，如果未标记的样本足够大，DM也可以提供出色的分类性能。&lt;h4&gt;结论&lt;/h4&gt;通过理论和实验结果证实了分布匹配(DM)方法的有效性，并且其设计使得表示空间具有结构化、可解释的特性。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新颖的自监督迁移学习方法，称为分布匹配（DM），该方法在保持增强不变性的前提下驱动表示向预定义的参考分布靠拢。实验结果显示，在多个真实世界的数据集和评估指标上，与现有的自监督转移学习方法相比，DM在目标分类任务上有竞争力的表现。此外，我们还为DM提供了坚实的理论保证，包括总体定理和端到端样本定理。总体定理连接了自我监督学习任务和目标分类准确性之间的差距，而样本定理表明，即使从目标领域得到的样本数量有限，如果未标记的样本数量足够大，DM也能提供卓越的分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vincen-github/DM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel self-supervised transfer learning methodcalled Distribution Matching (DM), which drives the representation distributiontoward a predefined reference distribution while preserving augmentationinvariance. The design of DM results in a learned representation space that isintuitively structured and offers easily interpretable hyperparameters.Experimental results across multiple real-world datasets and evaluation metricsdemonstrate that DM performs competitively on target classification taskscompared to existing self-supervised transfer learning methods. Additionally,we provide robust theoretical guarantees for DM, including a population theoremand an end-to-end sample theorem. The population theorem bridges the gapbetween the self-supervised learning task and target classification accuracy,while the sample theorem shows that, even with a limited number of samples fromthe target domain, DM can deliver exceptional classification performance,provided the unlabeled sample size is sufficiently large.</description>
      <author>example@mail.com (Yuling Jiao, Wensen Ma, Defeng Sun, Hansheng Wang, Yang Wang)</author>
      <guid isPermaLink="false">2502.14424v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Token Adaptation via Side Graph Convolution for Temporally and Spatially Efficient Fine-tuning of 3D Point Cloud Transformers</title>
      <link>http://arxiv.org/abs/2502.14142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Currently under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;参数高效的微调（PEFT）是3D点云分析中预训练的3D点云Transformer的一种有前景的技术。尽管现有的PEFT方法试图减少可调整参数的数量，但在微调过程中仍然存在较高的时间和空间计算成本。&lt;h4&gt;背景&lt;/h4&gt;当前基于PEFT的方法虽然减少了可调参数的数量，但是在微调过程中的时间与空间效率仍然不尽如人意。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的针对3D点云Transformer的PEFT算法STAG，以在不牺牲性能的前提下提高时间和空间效率。&lt;h4&gt;方法&lt;/h4&gt;采用图卷积侧网络（Side Token Adaptation on a neighborhood Graph, STAG）作为冻结主干Transformer的并行组件，通过连接、参数共享框架和高效的图卷积来实现高效率。同时提出Point Cloud Classification 13 (PCC13)基准测试集，涵盖多种公开的3D点云数据集。&lt;h4&gt;主要发现&lt;/h4&gt;STAG算法在保持现有方法分类准确率的同时，将可调参数数量减少至0.43M，并且显著降低了微调过程中的计算时间和内存消耗。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，STAG不仅实现了高精度和高效的PEFT，在多项预训练模型上的表现均优于其他方法。这一成果为未来的3D点云分析提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;参数高效微调（PEFT）是针对预训练的3D点云Transformer的一种有前景的技术，用于3D点云分析。尽管现有的PEFT方法尝试减少可调整参数的数量，但在精细调节过程中仍然存在高计算时间和空间成本的问题。本文提出了一种名为Side Token Adaptation on a neighborhood Graph (STAG) 的新颖PEFT算法，旨在实现卓越的时间和空间效率。STAG使用与冻结主干Transformer并行工作的图卷积侧网络来适应下游任务的令牌。通过连接、参数共享框架以及高效的图卷积，STAG的侧面网络实现了高效率。我们还提出了一个新的基准测试集Point Cloud Classification 13 (PCC13)，该基准集合成了多种公开可用的3D点云数据集，可以全面评估PEFT方法。使用多个预训练模型和PCC13进行广泛的实验表明了STAG的有效性。具体而言，STAG在保持现有方法的分类准确性的同时，将可调参数减少到仅0.43M，并显著减少了微调过程中的计算时间和内存消耗。代码和基准测试将在以下网址提供：https://github.com/takahikof/STAG&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient fine-tuning (PEFT) of pre-trained 3D point cloudTransformers has emerged as a promising technique for 3D point cloud analysis.While existing PEFT methods attempt to minimize the number of tunableparameters, they still suffer from high temporal and spatial computationalcosts during fine-tuning. This paper proposes a novel PEFT algorithm for 3Dpoint cloud Transformers, called Side Token Adaptation on a neighborhood Graph(STAG), to achieve superior temporal and spatial efficiency. STAG employs agraph convolutional side network that operates in parallel with a frozenbackbone Transformer to adapt tokens to downstream tasks. STAG's side networkrealizes high efficiency through three key components: connection with thebackbone that enables reduced gradient computation, parameter sharingframework, and efficient graph convolution. Furthermore, we present Point CloudClassification 13 (PCC13), a new benchmark comprising diverse publiclyavailable 3D point cloud datasets, enabling comprehensive evaluation of PEFTmethods. Extensive experiments using multiple pre-trained models and PCC13demonstrates the effectiveness of STAG. Specifically, STAG maintainsclassification accuracy comparable to existing methods while reducing tunableparameters to only 0.43M and achieving significant reductions in bothcomputational time and memory consumption for fine-tuning. Code and benchmarkwill be available at: https://github.com/takahikof/STAG</description>
      <author>example@mail.com (Takahiko Furuya)</author>
      <guid isPermaLink="false">2502.14142v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Geometry Scalable Coding Using a Resolution and Quality-conditioned Latents Probability Estimator</title>
      <link>http://arxiv.org/abs/2502.14099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE and currently under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了一种新的点云（PC）编码可扩展解决方案，名为SRQH。这种方案能够在单个比特流中实现不同质量和分辨率的解码。&lt;h4&gt;背景&lt;/h4&gt;当前多媒体内容消费场景多样化，对网络、硬件和显示能力要求各异，传统的编码方法难以适应这些需求而不会导致存储和计算成本大幅增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于基于深度学习点云编码的标准JPEG Pleno的新可扩展编码方案SRQH。&lt;h4&gt;方法&lt;/h4&gt;该方案通过同时实现质量和分辨率的可扩展性来解决传统问题，能够建模由不同RD折衷训练的模型获得潜在变量之间的关系，并且在不同分辨率下仍有效。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SRQH能够在单个比特流中解码出不同质量和分辨率的点云，同时仅稍微增加复杂性和损失一些压缩效率。&lt;h4&gt;结论&lt;/h4&gt;SRQH是一种创新性的可扩展编码方案，在JPEG Pleno标准中的集成证明了其有效性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;在当今时代，用户以各种各样的网络、硬件和显示能力场景消费多媒体内容。一个简单的解决方案是为每种可能的客户需求生成独立流，但这种做法会大大增加存储和计算需求。通过使用能够生成渐进式比特流（包含基础层后跟多个增强层）的编码器可以避免这些问题，从而允许多次解码相同的比特流以满足不同重建和显示要求。虽然可扩展编码在传统图像和视频编解码器中已为人所知且得到解决，但本论文关注的是开发一种基于深度学习点云（PC）的新问题解决方案。由于这种3D表示的特性，实现灵活而不损害编解码器其他功能的方案难度很大。本文提出了一种名为可伸缩分辨率和质量超先验(SRQH)的联合质量和分辨率可扩展性方案，该方案与先前的方法不同，能够建模使用针对不同RD权衡训练模型获得潜在变量之间的关系，并且在不同分辨率下仍有效。实验结果表明，当将SRQH集成到新兴的JPEG Pleno学习PC编码标准中时，SRQH允许仅通过单个比特流解码具有不同质量和分辨率的PC，同时相较于需要针对每种编解码配置单独比特流的非可扩展性JPEG PCC只带来有限的RD惩罚和复杂度增量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the current age, users consume multimedia content in very heterogeneousscenarios in terms of network, hardware, and display capabilities. A naivesolution to this problem is to encode multiple independent streams, eachcovering a different possible requirement for the clients, with an obviousnegative impact in both storage and computational requirements. These drawbackscan be avoided by using codecs that enable scalability, i.e., the ability togenerate a progressive bitstream, containing a base layer followed by multipleenhancement layers, that allow decoding the same bitstream serving multiplereconstructions and visualization specifications. While scalable coding is awell-known and addressed feature in conventional image and video codecs, thispaper focuses on a new and very different problem, notably the development ofscalable coding solutions for deep learning-based Point Cloud (PC) coding. Thepeculiarities of this 3D representation make it hard to implement flexiblesolutions that do not compromise the other functionalities of the codec. Thispaper proposes a joint quality and resolution scalability scheme, namedScalable Resolution and Quality Hyperprior (SRQH), that, contrary to previoussolutions, can model the relationship between latents obtained with modelstrained for different RD tradeoffs and/or at different resolutions.Experimental results obtained by integrating SRQH in the emerging JPEG Plenolearning-based PC coding standard show that SRQH allows decoding the PC atdifferent qualities and resolutions with a single bitstream while incurringonly in a limited RD penalty and increment in complexity w.r.t. non-scalableJPEG PCC that would require one bitstream per coding configuration.</description>
      <author>example@mail.com (Daniele Mari, André F. R. Guarda, Nuno M. M. Rodrigues, Simone Milani, Fernando Pereira)</author>
      <guid isPermaLink="false">2502.14099v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Data-Efficient Pretraining with Group-Level Data Influence Modeling</title>
      <link>http://arxiv.org/abs/2502.14709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Group-Level Data Influence Modeling (Group-MATES) 的新方法，用于高效的数据预训练。这种方法通过收集数据集对预训练模型的群体级影响，并利用关系加权聚合的个体影响力来优化群体级别的数据效用。&lt;h4&gt;背景&lt;/h4&gt;数据高效的预训练在提升缩放规律方面展示了巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，能够更有效地进行数据预训练，特别是在群组级别而不是独立数据点上优化数据的使用效率。&lt;h4&gt;方法&lt;/h4&gt;Group-MATES 方法包括：收集群体级别的影响力，通过本地探测预训练模型来获得；随后微调一个关系性数据影响模型以近似这些群体级影响力，并选择具有最大预测群体级影响力的子集数据。该过程还采用影响力感知聚类技术，以便更高效地进行推断。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Group-MATES 方法在22个下游任务上比DCLM-Baseline提高了10%的相对核心评分，比基于个体影响的方法提高5%，确立了新的状态-of-the-art。&lt;h4&gt;结论&lt;/h4&gt;关系性数据影响模型能够有效地捕捉到数据点之间的复杂交互作用，从而提升预训练模型的效果和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到数据高效预训练展现了巨大的潜力，提出一种新方法Group-Level Data Influence Modeling (Group-MATES)，该方法旨在通过收集和优化群组级别的数据效用来改进预训练过程。经过实验验证，这种方法在特定基准测试中表现出色，确立了新的最佳实践标准，并展示了捕捉复杂数据点交互的模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-efficient pretraining has shown tremendous potential to elevate scalinglaws. This paper argues that effective pretraining data should be curated atthe group level, treating a set of data points as a whole rather than asindependent contributors. To achieve that, we propose Group-Level DataInfluence Modeling (Group-MATES), a novel data-efficient pretraining methodthat captures and optimizes group-level data utility. Specifically, Group-MATEScollects oracle group-level influences by locally probing the pretraining modelwith data sets. It then fine-tunes a relational data influence model toapproximate oracles as relationship-weighted aggregations of individualinfluences. The fine-tuned model selects the data subset by maximizing itsgroup-level influence prediction, with influence-aware clustering to enableefficient inference. Experiments on the DCLM benchmark demonstrate thatGroup-MATES achieves a 10% relative core score improvement on 22 downstreamtasks over DCLM-Baseline and 5% over individual-influence-based methods,establishing a new state-of-the-art. Further analyses highlight theeffectiveness of relational data influence models in capturing intricateinteractions between data points.</description>
      <author>example@mail.com (Zichun Yu, Fei Peng, Jie Lei, Arnold Overwijk, Wen-tau Yih, Chenyan Xiong)</author>
      <guid isPermaLink="false">2502.14709v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Macro- and Micro-Hierarchical Transfer Learning Framework for Cross-Domain Fake News Detection</title>
      <link>http://arxiv.org/abs/2502.14403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;跨域假新闻检测旨在通过在不同领域之间转移知识来减轻领域的偏移，从而改善检测性能。&lt;h4&gt;背景&lt;/h4&gt;现有的方法是基于从源域到目标域的新闻内容和用户互动的知识迁移。然而，这些方法存在两个主要限制，阻碍了有效的知识传输及最优的假新闻检测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的宏观和微观层级传递学习框架（MMHT），以解决现有方法在跨领域假新闻检测中的局限性。&lt;h4&gt;方法&lt;/h4&gt;{'微层级模块': '提出了一个用于从源域的新闻内容中区分事实相关和无关特征，从而改进目标领域的假新闻检测性能的微层级解构模块。', '宏观层级模块': '提出了一种基于不同领域之间常见用户共享行为生成参与度特征的宏观层级传递学习模块，以提高知识迁移的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过在现实世界数据集上的广泛实验，证明了该框架显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;提出的MMHT框架有效解决了跨域假新闻检测中的挑战，并展示了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714517&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain fake news detection aims to mitigate domain shift and improvedetection performance by transferring knowledge across domains. Existingapproaches transfer knowledge based on news content and user engagements from asource domain to a target domain. However, these approaches face two mainlimitations, hindering effective knowledge transfer and optimal fake newsdetection performance. Firstly, from a micro perspective, they neglect thenegative impact of veracity-irrelevant features in news content whentransferring domain-shared features across domains. Secondly, from a macroperspective, existing approaches ignore the relationship between userengagement and news content, which reveals shared behaviors of common usersacross domains and can facilitate more effective knowledge transfer. To addressthese limitations, we propose a novel macro- and micro- hierarchical transferlearning framework (MMHT) for cross-domain fake news detection. Firstly, wepropose a micro-hierarchical disentangling module to disentangleveracity-relevant and veracity-irrelevant features from news content in thesource domain for improving fake news detection performance in the targetdomain. Secondly, we propose a macro-hierarchical transfer learning module togenerate engagement features based on common users' shared behaviors indifferent domains for improving effectiveness of knowledge transfer. Extensiveexperiments on real-world datasets demonstrate that our framework significantlyoutperforms the state-of-the-art baselines.</description>
      <author>example@mail.com (Xuankai Yang, Yan Wang, Xiuzhen Zhang, Shoujin Wang, Huaxiong Wang, Kwok Yan Lam)</author>
      <guid isPermaLink="false">2502.14403v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Vision Foundation Models in Medical Image Analysis: Advances and Challenges</title>
      <link>http://arxiv.org/abs/2502.14584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本文综述了视觉基础模型（VFMs）在医学图像分析中的适应性研究，特别关注领域适应、模型压缩和联邦学习的挑战。&lt;h4&gt;背景&lt;/h4&gt;随着Vision Foundation Models (VFMs)的发展，尤其是Vision Transformers(ViT)和Segment Anything Model(SAM)，医学影像分析领域取得了显著进展。这些模型展现了捕捉长距离依赖性和实现高泛化的卓越能力。&lt;h4&gt;目的&lt;/h4&gt;探讨将大型视觉基础模型适应于医学图像分割的挑战，并讨论最新的基于适配器的方法改进、知识蒸馏技术和多尺度上下文特征建模的发展，同时提出未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;本文回顾了VFMs在医学图像分割中的最新研究成果，重点关注领域适应、模型压缩和联邦学习的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;VFMs和其他新兴技术（如联邦学习和模型压缩）具有革新医学影像分析和增强临床应用的巨大潜力。论文强调了当前的研究方向，并指出了未来研究的关键领域。&lt;h4&gt;结论&lt;/h4&gt;该工作旨在提供一个全面的方法概述，为驱动医学图像分割领域的下一波创新提出关键建议。&lt;h4&gt;翻译&lt;/h4&gt;视觉基础模型在医疗影像分析中的快速发展，特别是在Vision Transformers和Segment Anything Model的应用，已引发了该领域的显著进步。这些模型展现出了捕捉长距离依赖关系及实现高泛化的出色能力。然而，将大型视觉基础模型应用于医学图像分析面临着诸如医学与自然图像之间的领域差异、有效适应策略的需求以及小型医疗数据集限制等挑战。本文综述了VFMs在医学图像分割中的最新研究进展，重点探讨了领域适应、模型压缩和联邦学习的挑战，并讨论了基于适配器的改进方法、知识蒸馏技术及多尺度上下文特征建模的发展趋势，同时提出了未来的潜在发展方向。我们的分析强调了VFMs及其他新兴如联邦学习和模型压缩的技术在革新医学影像分析与提高临床应用方面所具有的巨大潜力。本文旨在为当前的研究方法提供全面概述，并建议未来关键研究领域以驱动下一轮创新浪潮的到来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of Vision Foundation Models (VFMs), particularly VisionTransformers (ViT) and Segment Anything Model (SAM), has sparked significantadvances in the field of medical image analysis. These models have demonstratedexceptional capabilities in capturing long-range dependencies and achievinghigh generalization in segmentation tasks. However, adapting these large modelsto medical image analysis presents several challenges, including domaindifferences between medical and natural images, the need for efficient modeladaptation strategies, and the limitations of small-scale medical datasets.This paper reviews the state-of-the-art research on the adaptation of VFMs tomedical image segmentation, focusing on the challenges of domain adaptation,model compression, and federated learning. We discuss the latest developmentsin adapter-based improvements, knowledge distillation techniques, andmulti-scale contextual feature modeling, and propose future directions toovercome these bottlenecks. Our analysis highlights the potential of VFMs,along with emerging methodologies such as federated learning and modelcompression, to revolutionize medical image analysis and enhance clinicalapplications. The goal of this work is to provide a comprehensive overview ofcurrent approaches and suggest key areas for future research that can drive thenext wave of innovation in medical image segmentation.</description>
      <author>example@mail.com (Pengchen Liang, Bin Pu, Haishan Huang, Yiwei Li, Hualiang Wang, Weibo Ma, Qing Chang)</author>
      <guid isPermaLink="false">2502.14584v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SALTY: Explainable Artificial Intelligence Guided Structural Analysis for Hardware Trojan Detection</title>
      <link>http://arxiv.org/abs/2502.14116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;硬件木马是在数字设计中由不可信供应链实体插入的恶意修改。这些木马可以导致信息泄露（例如MOLES木马）和拒绝服务等多样化的攻击向量。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效检测数字设计中的恶意修改的技术，特别是那些来自第三方知识产权供应商的设计。&lt;h4&gt;方法&lt;/h4&gt;提出了一个框架（SALTY），该框架使用新颖的图神经网络架构（利用跳跃知识机制生成初步预测）以及可解释的人工智能（XAI）方法进行后续处理来细化结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法能够达到98%的真实正样本率（TPR）和真实负样本率（TNR），在一系列标准基准测试中显著优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效解决了现有检测技术的可扩展性问题，并且大大减少了误报的数量。&lt;h4&gt;翻译&lt;/h4&gt;硬件木马是数字设计中的一种恶意修改，可能由不可信供应链中的实体插入。它们会导致信息泄露（例如MOLES木马）和拒绝服务等多样化的攻击向量。这些攻击在关键系统（如医疗保健和航空领域）中可能导致人员伤亡及巨大的经济损失。已经开发了几种技术来检测数字设计中的这类恶意修改，尤其是从第三方知识产权供应商获取的设计。然而，大多数方法存在可扩展性问题（由于评估过程中不合理的假设），并且会产生大量的误报。我们的框架（SALTY）通过使用一种基于跳跃知识机制的新型图神经网络架构生成初步预测，并且利用可解释人工智能(XAI)的方法进行细化处理来缓解这些问题。实验结果表明，该方法在一系列标准基准测试中实现了98%的真实正样本率(TPR)和真实负样本率(TNR)，显著优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hardware Trojans are malicious modifications in digital designs that can beinserted by untrusted supply chain entities. Hardware Trojans can give rise todiverse attack vectors such as information leakage (e.g. MOLES Trojan) anddenial-of-service (rarely triggered bit flip). Such an attack in criticalsystems (e.g. healthcare and aviation) can endanger human lives and lead tocatastrophic financial loss. Several techniques have been developed to detectsuch malicious modifications in digital designs, particularly for designssourced from third-party intellectual property (IP) vendors. However, mosttechniques have scalability concerns (due to unsound assumptions duringevaluation) and lead to large number of false positive detections (falsealerts). Our framework (SALTY) mitigates these concerns through the use of anovel Graph Neural Network architecture (using Jumping-Knowledge mechanism) forgenerating initial predictions and an Explainable Artificial Intelligence (XAI)approach for fine tuning the outcomes (post-processing). Experiments show 98%True Positive Rate (TPR) and True Negative Rate (TNR), significantlyoutperforming state-of-the-art techniques across a large set of standardbenchmarks.</description>
      <author>example@mail.com (Tanzim Mahfuz, Pravin Gaikwad, Tasneem Suha, Swarup Bhunia, Prabuddha Chakraborty)</author>
      <guid isPermaLink="false">2502.14116v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes for Global Encoding</title>
      <link>http://arxiv.org/abs/2502.13797v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RANGE是一个模型无关的框架，旨在解决图神经网络在处理长程相互作用时的信息瓶颈问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）被广泛应用于分子物理、社会科学和经济学等领域。然而，GNN本质上是局部性的，并且当用于模拟具有长程相互作用的大规模分子系统时容易产生信息流动瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决大规模分子系统的计算成本高以及模型扩展性差的问题。&lt;h4&gt;方法&lt;/h4&gt;RANGE采用基于注意力的聚合-广播机制，该机制能够显著减少过度压缩效应，并以几乎可以忽略不计的计算成本捕捉长程相互作用。此外，这是首次在虚拟节点消息传递中整合注意力机制、位置编码和正则化来动态扩展虚拟表示的方法。&lt;h4&gt;主要发现&lt;/h4&gt;RANGE框架不仅大幅提高了对大规模分子系统中的长程相互作用建模的能力，而且保持了较低的计算成本。&lt;h4&gt;结论&lt;/h4&gt;该研究为下一代机器学习力场奠定了基础，并提供了既准确又高效的长期互动模型。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）经常用于模拟分子物理、社会科学和经济学中类似图形系统中的多体相互作用。然而，GNN本质上是局部性的并且在信息传递时可能会遭遇瓶颈问题。特别是在大规模分子系统的建模过程中，分散力和局部电场变化会驱动结构上的集体性改变，这使得问题更为复杂。现有的解决方案面临着计算成本高、可扩展性差的挑战。我们提出了一种模型无关的方法——RANGE，它采用了基于注意力机制的聚合-广播方法，大幅度减少了信息过度压缩的问题，并以极低的成本实现了长程相互作用的有效捕捉。值得注意的是，RANGE是首个将位置编码和正则化与注意力相结合，从而动态扩展虚拟表示的虚拟节点消息传递实现方案。这项研究为下一代机器学习力场奠定了基础，提供了一种既准确又高效的对大规模分子系统中的长程互动进行建模的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are routinely used in molecular physics, socialsciences, and economics to model many-body interactions in graph-like systems.However, GNNs are inherently local and can suffer from information flowbottlenecks. This is particularly problematic when modeling large molecularsystems, where dispersion forces and local electric field variations drivecollective structural changes. Existing solutions face challenges related tocomputational cost and scalability. We introduce RANGE, a model-agnosticframework that employs an attention-based aggregation-broadcast mechanism thatsignificantly reduces oversquashing effects, and achieves remarkable accuracyin capturing long-range interactions at a negligible computational cost.Notably, RANGE is the first virtual-node message-passing implementation tointegrate attention with positional encodings and regularization to dynamicallyexpand virtual representations. This work lays the foundation fornext-generation of machine-learned force fields, offering accurate andefficient modeling of long-range interactions for simulating large molecularsystems.</description>
      <author>example@mail.com (Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi)</author>
      <guid isPermaLink="false">2502.13797v2</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling</title>
      <link>http://arxiv.org/abs/2502.14553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '字节构成了数字世界的基石，是多模态基础模型的潜在构建块。提出了Multiscale Byte Language Model (MBLM)，这是一种基于层次解码器堆栈、能够以全精度在单个GPU上使用5M字节上下文窗口进行训练的模型。', '背景': 'Byte语言模型（BLMs）最近出现，旨在克服分词问题，但字节流过长需要新的架构范式。MBLM是一个与模型无关的层次解码器堆栈，可以高效处理极长的字节序列并在生成效率上接近线性增长。', '目的': '介绍并评估Multiscale Byte Language Model (MBLM)，探讨其在视觉问答任务中的表现，并展示其适应各种数据表示的能力。', '方法': '通过Transformer和Mamba块对单模态和多模态任务进行全面性能测试，展示了混合架构的有效性。另外，首次评估了BLMs在视觉问答任务上的表现。', '主要发现': '尽管序列化图像且没有编码器，MBLM仅基于纯下一个令牌预测就可与专用的CNN-LSTM架构相匹配，后者具有指定分类头。', '结论': 'MBLM展示了强大的适应性，在集成各种数据表示（包括像素和图像文件流字节）方面表现出巨大潜力，这使其成为通用多模态基础模型的发展方向。'}&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到了Bytes在数字世界中的重要性，并介绍了Multiscale Byte Language Model (MBLM)，这种模型可以高效处理极长的序列数据并适用于视觉问答任务等多模态场景。研究结果表明，MBLM在生成效率上接近线性增长，且其表现可与复杂的CNN-LSTM架构相媲美。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bytes form the basis of the digital world and thus are a promising buildingblock for multimodal foundation models. Recently, Byte Language Models (BLMs)have emerged to overcome tokenization, yet the excessive length of bytestreamsrequires new architectural paradigms. Therefore, we present the Multiscale ByteLanguage Model (MBLM), a model-agnostic hierarchical decoder stack that allowstraining with context windows of $5$M bytes on single GPU in full modelprecision. We thoroughly examine MBLM's performance with Transformer and Mambablocks on both unimodal and multimodal tasks. Our experiments demonstrate thathybrid architectures are efficient in handling extremely long byte sequencesduring training while achieving near-linear generational efficiency. To thebest of our knowledge, we present the first evaluation of BLMs on visual Q\&amp;Atasks and find that, despite serializing images and the absence of an encoder,a MBLM with pure next token prediction can match custom CNN-LSTM architectureswith designated classification heads. We show that MBLMs exhibit strongadaptability in integrating diverse data representations, including pixel andimage filestream bytes, underlining their potential toward omnimodal foundationmodels. Source code is publicly available at:https://github.com/ai4sd/multiscale-byte-lm</description>
      <author>example@mail.com (Eric Egli, Matteo Manica, Jannis Born)</author>
      <guid isPermaLink="false">2502.14553v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Asymmetric Co-Training for Source-Free Few-Shot Domain Adaptation</title>
      <link>http://arxiv.org/abs/2502.14214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个针对源无标签领域自适应（SFFSDA）场景的不对称协同训练(ACT)方法，该方法旨在解决传统无监督域自适应在缺乏大量目标数据时表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的无监督域自适应依赖于有标签的源数据的持续可用性。然而，在实际应用中获取大量的未标记目标数据是不现实的，因此需要寻求一种新的解决方案来克服这个限制。&lt;h4&gt;目的&lt;/h4&gt;提出了一种针对SFFSDA场景的有效方法，即不对称协同训练（ACT），通过该方法可以在少量有标签的目标数据的基础上对预训练模型进行适应性改进。&lt;h4&gt;方法&lt;/h4&gt;ACT方法首先采用弱强增强技术增加数据多样性。然后利用两步优化过程来训练目标模型：第一步优化标签平滑交叉熵损失、条件分布的熵以及反向熵损失，以提高模型区分能力并减少过拟合；第二步则通过最小化分类器确定性差异来降低输出空间中的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准上的广泛实验表明，所提出的ACT方法优于现有的源无标签领域自适应（SFUDA）方法和迁移学习技术。&lt;h4&gt;结论&lt;/h4&gt;使用少量的有标签目标数据调整预训练模型可以提供一种实用且可靠的方法来解决域自适应问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要提供了关于如何克服传统无监督域自适应方法依赖大量未标记目标数据的问题，提出了一种新的源无标签领域自适应（SFFSDA）方法。该方法通过不对称协同训练技术在少量有标签的目标数据基础上优化预训练模型性能，并展示了优于现有方法的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Source-free unsupervised domain adaptation (SFUDA) has gained significantattention as an alternative to traditional unsupervised domain adaptation(UDA), which relies on the constant availability of labeled source data.However, SFUDA approaches come with inherent limitations that are frequentlyoverlooked. These challenges include performance degradation when the unlabeledtarget data fails to meet critical assumptions, such as having a closed-setlabel distribution identical to that of the source domain, or when sufficientunlabeled target data is unavailable-a common situation in real-worldapplications. To address these issues, we propose an asymmetric co-training(ACT) method specifically designed for the SFFSDA scenario. SFFSDA presents amore practical alternative to SFUDA, as gathering a few labeled targetinstances is more feasible than acquiring large volumes of unlabeled targetdata in many real-world contexts. Our ACT method begins by employing aweak-strong augmentation to enhance data diversity. Then we use a two-stepoptimization process to train the target model. In the first step, we optimizethe label smoothing cross-entropy loss, the entropy of the class-conditionaldistribution, and the reverse-entropy loss to bolster the model'sdiscriminative ability while mitigating overfitting. The second step focuses onreducing redundancy in the output space by minimizing classifier determinacydisparity. Extensive experiments across four benchmarks demonstrate thesuperiority of our ACT approach, which outperforms state-of-the-art SFUDAmethods and transfer learning techniques. Our findings suggest that adapting asource pre-trained model using only a small amount of labeled target dataoffers a practical and dependable solution. The code is available athttps://github.com/gengxuli/ACT.</description>
      <author>example@mail.com (Gengxu Li, Yuan Wu)</author>
      <guid isPermaLink="false">2502.14214v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks</title>
      <link>http://arxiv.org/abs/2502.14546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文摘要强调了在图学习应用于药物设计和分子属性预测方面的挑战，提出需要改进的基准测试方法以促进研究的进步。&lt;h4&gt;背景&lt;/h4&gt;机器学习在图上的应用显示出其在药物设计和分子性质预测中的潜力，但目前存在的大量基准测试问题阻碍了这些领域的进一步发展和相关性。&lt;h4&gt;目的&lt;/h4&gt;论文呼吁进行范式转变，采用更具意义的基准测试、严格的评估协议，并与领域专家加强合作，以推动有意义且可靠的图学习研究进展。&lt;h4&gt;方法&lt;/h4&gt;摘要中并未详细描述具体的方法论或实验过程。&lt;h4&gt;主要发现&lt;/h4&gt;当前的基准测试实践中倾向于关注狭窄的应用域如二维分子图，而不是更广泛和有影响力的应用领域。此外，许多基准数据集未能准确反映基础数据特征，导致抽象不充分且应用场景与实际脱节。&lt;h4&gt;结论&lt;/h4&gt;需要建立更加合理、更具代表性的基准体系来推动图学习技术在真实世界中的有效应用。&lt;h4&gt;翻译&lt;/h4&gt;虽然基于图的机器学习在药物设计和分子属性预测方面展现出了巨大潜力，但现有的基准测试挑战阻碍了其进一步的发展和实用性。当前的基准测试方法倾向于关注如二维分子图等狭窄领域，而不是更广泛且有影响力的应用领域，例如组合优化、关系数据库或芯片设计。此外，许多数据集未能准确反映实际基础数据特征，导致抽象不充分及应用场景与需求不符的问题加剧。这种碎片化的评估和对准确性过度重视的情况进一步促进了过拟合问题的出现，从而阻碍了通用性见解的发展。这些局限性已经阻止了真正有用的基础图模型的发展。这篇立场论文呼吁进行范式转变，采用更加有意义的基准测试标准、严格的评价流程，并与领域专家加强合作，以推动有影响力的和可靠的图学习研究进展，释放基于图的学习技术的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While machine learning on graphs has demonstrated promise in drug design andmolecular property prediction, significant benchmarking challenges hinder itsfurther progress and relevance. Current benchmarking practices often lack focuson transformative, real-world applications, favoring narrow domains liketwo-dimensional molecular graphs over broader, impactful areas such ascombinatorial optimization, relational databases, or chip design. Additionally,many benchmark datasets poorly represent the underlying data, leading toinadequate abstractions and misaligned use cases. Fragmented evaluations and anexcessive focus on accuracy further exacerbate these issues, incentivizingoverfitting rather than fostering generalizable insights. These limitationshave prevented the development of truly useful graph foundation models. Thisposition paper calls for a paradigm shift toward more meaningful benchmarks,rigorous evaluation protocols, and stronger collaboration with domain expertsto drive impactful and reliable advances in graph learning research, unlockingthe potential of graph learning.</description>
      <author>example@mail.com (Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis Müller, Jan Tönshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, Christopher Morris)</author>
      <guid isPermaLink="false">2502.14546v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Precise Geolocation Inference Capabilities of Vision Language Models</title>
      <link>http://arxiv.org/abs/2502.14412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 Workshop DATASAFE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;视觉语言模型（VLMs）的广泛应用引发了关于隐私的问题，尤其是在图像信息越来越容易获得的时代。这项研究专注于评估这些基础模型从之前未见过的图像数据中推断地理位置的能力。&lt;h4&gt;背景&lt;/h4&gt;随着视觉信息变得日益丰富和易于获取，视觉语言模型（Vision-Language Models, VLMs）的应用变得广泛起来，这引发了一系列关于隐私保护的问题。基础VLM模型虽然展现出了广博的知识和学习能力，但研究人员特别关注它们从新图像中推断地理位置的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在评估基础VLM模型在未见过的图像数据上进行地理位置推测的有效性，并探讨其对在线隐私可能带来的风险。&lt;h4&gt;方法&lt;/h4&gt;研究团队创建了一个基准数据集，该数据集是从Google Street View收集的数据，涵盖了全球范围内的地理分布。这些基础模型被用来测试单张图片地理位置推断的能力。此外，研究人员还评估了具有额外工具访问权限的VLM '代理'的表现，并观察到了最高30.6%的距离误差减少。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，现代的基础视觉语言模型在没有专门训练的情况下也能成为强大的图像地理定位工具；它们可以有效地从新图片中推断出地理位置信息。当这些模型变得越来越容易获取时，这给在线隐私带来了更大的挑战和风险。&lt;h4&gt;结论&lt;/h4&gt;尽管基础VLM具有作为高效图像地理定位工具的潜力，但研究人员强调了这对个人数据保护可能造成的潜在威胁，并提出了进一步研究的方向来缓解这些问题&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of Vision-Language Models (VLMs) raises important questionsabout privacy in an era where visual information is increasingly available.While foundation VLMs demonstrate broad knowledge and learned capabilities, wespecifically investigate their ability to infer geographic location frompreviously unseen image data. This paper introduces a benchmark datasetcollected from Google Street View that represents its global distribution ofcoverage. Foundation models are evaluated on single-image geolocationinference, with many achieving median distance errors of &lt;300 km. We furtherevaluate VLM "agents" with access to supplemental tools, observing up to a30.6% decrease in distance error. Our findings establish that modern foundationVLMs can act as powerful image geolocation tools, without being specificallytrained for this task. When coupled with increasing accessibility of thesemodels, our findings have greater implications for online privacy. We discussthese risks, as well as future work in this area.</description>
      <author>example@mail.com (Neel Jay, Hieu Minh Nguyen, Trung Dung Hoang, Jacob Haimes)</author>
      <guid isPermaLink="false">2502.14412v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SegAnyPET: Universal Promptable Segmentation from Positron Emission Tomography Images</title>
      <link>http://arxiv.org/abs/2502.14351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种专门用于PET图像分割的3D基础模型SegAnyPET，并通过大规模数据集PETS-5k验证了其性能。&lt;h4&gt;背景&lt;/h4&gt;正电子发射断层扫描（PET）成像在现代医学诊断中发挥重要作用，但PET图像的低对比度和边界模糊使其难以进行有效分割。现有的自然图像分割方法对于结构化的医疗影像表现出较差的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门针对PET图像的通用可提示分割基础模型，并解决其标注质量差异带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;构建了大规模PET图像分割数据集PETS-5k，包含超过1.3M张2D图像；提出SegAnyPET模型，采用交叉提示自信学习策略提高低质量和高质量标签之间的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有基础模型和特定任务的监督模型相比，SegAnyPET在分割精度和泛化能力方面表现出更佳性能，仅使用少量提示点即可正确分割已知及未知目标。&lt;h4&gt;结论&lt;/h4&gt;作为首个专门针对PET图像的基础模型，SegAnyPET将推进分子成像下游任务的应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Positron Emission Tomography (PET) imaging plays a crucial role in modernmedical diagnostics by revealing the metabolic processes within a patient'sbody, which is essential for quantification of therapy response and monitoringtreatment progress. However, the segmentation of PET images presents uniquechallenges due to their lower contrast and less distinct boundaries compared toother structural medical modalities. Recent developments in segmentationfoundation models have shown superior versatility across diverse natural imagesegmentation tasks. Despite the efforts of medical adaptations, these worksprimarily focus on structural medical images with detailed physiologicalstructural information and exhibit poor generalization ability when adapted tomolecular PET imaging. In this paper, we collect and construct PETS-5k, thelargest PET segmentation dataset to date, comprising 5,731 three-dimensionalwhole-body PET images and encompassing over 1.3M 2D images. Based on theestablished dataset, we develop SegAnyPET, a modality-specific 3D foundationmodel for universal promptable segmentation from PET images. To issue thechallenge of discrepant annotation quality of PET images, we adopt a crossprompting confident learning (CPCL) strategy with an uncertainty-guidedself-rectification process to robustly learn segmentation from high-qualitylabeled data and low-quality noisy labeled data. Experimental resultsdemonstrate that SegAnyPET can correctly segment seen and unseen targets usingonly one or a few prompt points, outperforming state-of-the-art foundationmodels and task-specific fully supervised models with higher accuracy andstrong generalization ability for universal segmentation. As the firstfoundation model for PET images, we believe that SegAnyPET will advance theapplications to various downstream tasks for molecular imaging.</description>
      <author>example@mail.com (Yichi Zhang, Le Xue, Wenbo Zhang, Lanlan Li, Yuchen Liu, Chen Jiang, Yuan Cheng, Yuan Qi)</author>
      <guid isPermaLink="false">2502.14351v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>On the Trustworthiness of Generative Foundation Models: Guideline, Assessment, and Perspective</title>
      <link>http://arxiv.org/abs/2502.14296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一套全面的框架，旨在解决生成式基础模型（GenFMs）在可信赖性方面面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;Generative Foundation Models (GenFMs) 作为变革性的工具出现，但其广泛应用引发了一系列关于信任度的重要问题。&lt;h4&gt;目的&lt;/h4&gt;通过系统地审查全球AI治理法规和政策、行业实践及标准，并提出一套整合了技术、伦理、法律和社会视角的指导原则来解决这些问题。&lt;h4&gt;方法&lt;/h4&gt;{'第一部分': '全面评估现有法律法规与行业标准，提出跨学科合作产生的指导原则。', '第二部分': '引入TrustGen平台，这是一个动态基准测试工具，用于从多个维度和模型类型中评估可信赖性。', '第三部分': '深入讨论当前挑战及未来的方向，强调实用性和可信度之间的复杂权衡，以及针对不同下游应用的考虑。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'TrustGen平台功能': '通过模块化组件实现灵活、迭代的评估方法，并揭示了在多个维度上可信赖性的进步和持续存在的挑战。', '未来方向': '论文指出了可信生成式基础模型在未来研究中的复杂性和演变性质。'}&lt;h4&gt;结论&lt;/h4&gt;该工作为推进GenAI领域的信任度提供了全面框架，为进一步的研究和应用奠定了坚实的基础，并公开了动态评估工具包以促进社区发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含英文翻译内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative Foundation Models (GenFMs) have emerged as transformative tools.However, their widespread adoption raises critical concerns regardingtrustworthiness across dimensions. This paper presents a comprehensiveframework to address these challenges through three key contributions. First,we systematically review global AI governance laws and policies fromgovernments and regulatory bodies, as well as industry practices and standards.Based on this analysis, we propose a set of guiding principles for GenFMs,developed through extensive multidisciplinary collaboration that integratestechnical, ethical, legal, and societal perspectives. Second, we introduceTrustGen, the first dynamic benchmarking platform designed to evaluatetrustworthiness across multiple dimensions and model types, includingtext-to-image, large language, and vision-language models. TrustGen leveragesmodular components--metadata curation, test case generation, and contextualvariation--to enable adaptive and iterative assessments, overcoming thelimitations of static evaluation methods. Using TrustGen, we reveal significantprogress in trustworthiness while identifying persistent challenges. Finally,we provide an in-depth discussion of the challenges and future directions fortrustworthy GenFMs, which reveals the complex, evolving nature oftrustworthiness, highlighting the nuanced trade-offs between utility andtrustworthiness, and consideration for various downstream applications,identifying persistent challenges and providing a strategic roadmap for futureresearch. This work establishes a holistic framework for advancingtrustworthiness in GenAI, paving the way for safer and more responsibleintegration of GenFMs into critical applications. To facilitate advancement inthe community, we release the toolkit for dynamic evaluation.</description>
      <author>example@mail.com (Yue Huang, Chujie Gao, Siyuan Wu, Haoran Wang, Xiangqi Wang, Yujun Zhou, Yanbo Wang, Jiayi Ye, Jiawen Shi, Qihui Zhang, Yuan Li, Han Bao, Zhaoyi Liu, Tianrui Guan, Dongping Chen, Ruoxi Chen, Kehan Guo, Andy Zou, Bryan Hooi Kuen-Yew, Caiming Xiong, Elias Stengel-Eskin, Hongyang Zhang, Hongzhi Yin, Huan Zhang, Huaxiu Yao, Jaehong Yoon, Jieyu Zhang, Kai Shu, Kaijie Zhu, Ranjay Krishna, Swabha Swayamdipta, Taiwei Shi, Weijia Shi, Xiang Li, Yiwei Li, Yuexing Hao, Yuexing Hao, Zhihao Jia, Zhize Li, Xiuying Chen, Zhengzhong Tu, Xiyang Hu, Tianyi Zhou, Jieyu Zhao, Lichao Sun, Furong Huang, Or Cohen Sasson, Prasanna Sattigeri, Anka Reuel, Max Lamparth, Yue Zhao, Nouha Dziri, Yu Su, Huan Sun, Heng Ji, Chaowei Xiao, Mohit Bansal, Nitesh V. Chawla, Jian Pei, Jianfeng Gao, Michael Backes, Philip S. Yu, Neil Zhenqiang Gong, Pin-Yu Chen, Bo Li, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2502.14296v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Transfer-Prompting: Enhancing Cross-Task Adaptation in Large Language Models via Dual-Stage Prompts Optimization</title>
      <link>http://arxiv.org/abs/2502.14211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Transfer-Prompting的新型框架，旨在改进大型语言模型（LLM）在不同任务之间的适应能力。&lt;h4&gt;背景&lt;/h4&gt;LLMs面临平衡生成连贯、相关且高质量响应与跨多种任务高效适应的重要挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种两阶段框架以增强提示生成过程中的跨任务适应性。&lt;h4&gt;方法&lt;/h4&gt;{'源提示构建': '通过在原始数据集上改进原始提示，创建具有更强泛化能力的源提示。', '目标提示生成': '通过对一组高分源提示进行微调，在特定于任务的数据集上增强目标提示的跨任务适应能力。', '反馈循环': '参考LLM根据历史提示-分数对和任务描述生成候选提示，并通过评分LLM使用多维度指标评估其有效性，从而形成一个促进持续改进的反馈回路。'}&lt;h4&gt;主要发现&lt;/h4&gt;在包括7个基础模型和18个专业化模型在内的25种不同LLMs上进行的广泛实验显示了Transfer-Prompting可以显著改善特定任务性能。&lt;h4&gt;结论&lt;/h4&gt;该框架对增强LLM中的跨任务适应性有潜在价值，并且代码已公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) face significant challenges when balancingmultiple high-level objectives, such as generating coherent, relevant, andhigh-quality responses while maintaining efficient task adaptation acrossdiverse tasks. To address these challenges, we introduce Transfer-Prompting, anovel two-stage framework designed to enhance cross-task adaptation in promptgeneration. The framework comprises two key components: (1) source promptconstruction, which refines the original prompts on source task datasets togenerate source prompts with enhanced generalization ability, and (2) targetprompt generation, which enhances cross-task adaptation of target prompts byfine-tuning a set of high-scored source prompts on task-specific datasets. Ineach optimization cycle, a reference LLM generates candidate prompts based onhistorical prompt-score pairs and task descriptions in our designed referenceprompt. These candidate prompts are refined iteratively, while a scorer LLMevaluates their effectiveness using the multi-dimensional metrics designed inthe objective prompts evaluator-a novel contribution in this work that providesa holistic evaluation of prompt quality and task performance. This feedbackloop facilitates continuous refinement, optimizing both prompt quality andtask-specific outcomes. We validate Transfer-Prompting through extensiveexperiments across 25 LLMs, including 7 foundational models and 18 specializedmodels, evaluated on 9 diverse datasets. The results demonstrate thatTransfer-Prompting significantly improves task-specific performance,highlighting its potential for enhancing cross-task adaptation in LLMs. Thecode is available at https://github.com/llm172/Transfer-Prompting.</description>
      <author>example@mail.com (Yupeng Chang, Yi Chang, Yuan Wu)</author>
      <guid isPermaLink="false">2502.14211v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging</title>
      <link>http://arxiv.org/abs/2502.14064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的3D MRI视觉基础模型Triad，该模型采用自编码器架构从大量MRI数据集中学习鲁棒的表示，并通过器官无关的成像描述来约束语义分布。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉基础模型主要针对CT图像进行了预训练，这使得它们在处理MRI特定应用时可能遇到性能和适应性问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于3D MRI的新型视觉基础模型Triad，并评估其在多个下游任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;使用大规模MRI数据集（称为Triad-131K）对模型进行预训练，然后将其应用于多种下游任务并比较与未经过预训练的模型相比的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在器官和成像模式一致的情况下，采用Triad预训练权重的模型在分割、分类和图像配准等任务上取得了显著性能提升。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了针对MRI数据进行预训练可以最大化下游任务中的表现，并为开发专用于医学影像领域的视觉基础模型提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models (VFMs) are pre-trained on extensive image datasetsto learn general representations for diverse types of data. These models cansubsequently be fine-tuned for specific downstream tasks, significantlyboosting performance across a broad range of applications. However, existingvision foundation models that claim to be applicable to various radiology tasksare mostly pre-trained on 3D computed tomography (CT), which benefits from theavailability of extensive 3D CT databases. Significant differences between CTand magnetic resonance imaging (MRI) in imaging principles, signalcharacteristics, and data distribution may hinder their practical performanceand versatility in MRI-specific applications. Here, we propose Triad, a visionfoundation model for 3D MRI. Triad adopts a widely used autoencoderarchitecture to learn robust representations from 131,170 3D MRI volumes anduses organ-independent imaging descriptions to constrain the semanticdistribution of the visual modality. The above pre-training dataset is calledTriad-131K, which is currently the largest 3D MRI pre-training dataset. Weevaluate Triad across three tasks, namely, organ/tumor segmentation,organ/cancer classification, and medical image registration, in two datamodalities (within-domain and out-of-domain) settings using 25 downstreamdatasets. By initializing models with Triad's pre-trained weights, nnUNet-Triadimproves segmentation performance by 6.88% compared to nnUNet-Scratch across 17datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch inclassification tasks across five datasets. SwinUNETR-Triad improves by 4.00%compared to SwinUNETR-Scratch in registration tasks across two datasets. Ourstudy demonstrates that pre-training can maximize performance when the datamodalities and organs of upstream and downstream tasks are consistent.</description>
      <author>example@mail.com (Shansong Wang, Mojtaba Safari, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang)</author>
      <guid isPermaLink="false">2502.14064v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data</title>
      <link>http://arxiv.org/abs/2502.14044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025. Code: https://github.com/sycny/SelfSynthX&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个新颖的视觉拒绝采样框架，利用自合成数据提升大型多模态模型（LMMs）的认知和可解释性。&lt;h4&gt;背景&lt;/h4&gt;大型多模态模型在广泛的任务中表现出色，但在细粒度视觉推理上存在困难，难以提供充分合理的预测解释。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来改进大型多模态模型的细粒度视觉推理能力及其对特定领域目标的理解和可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过合成易于解读的答案，这些答案包含基于专家定义的概念的人类可验证的视觉特征。在每一轮微调后使用无奖励模型过滤机制选出最高质量的易解答案以进行下一次微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法有效提高了特定视觉分类任务的准确性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架通过不断迭代的数据合成和微调，逐步提高大型多模态模型生成准确合理解释的能力。&lt;h4&gt;翻译&lt;/h4&gt;大规模多模态模型在一系列视觉任务中表现出色。然而，它们往往难以进行细粒度的视觉推理，并且无法提供合理的预测说明。为了解决这个问题，我们提出了一种新的基于自合成数据改进大模型认知能力和可解释性的视觉拒绝采样框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large multimodal models (LMMs) have shown impressive capabilities in a widerange of visual tasks. However, they often struggle with fine-grained visualreasoning, failing to identify domain-specific objectives and providejustifiable explanations for their predictions. To address this, we propose anovel visual rejection sampling framework to improve the cognition andexplainability of LMMs using self-synthesized data. Specifically, visualfine-tuning requires images, queries, and target answers. Our approach beginsby synthesizing interpretable answers that include human-verifiable visualfeatures. These features are based on expert-defined concepts, carefullyselected based on their alignment with the image content. After each round offine-tuning, we apply a reward model-free filtering mechanism to select thehighest-quality interpretable answers for the next round of tuning. Thisiterative process of data synthesis and fine-tuning progressively improves themodel's ability to generate accurate and reasonable explanations. Experimentalresults demonstrate the effectiveness of our method in improving both theaccuracy and explainability of specialized visual classification tasks.</description>
      <author>example@mail.com (Yucheng Shi, Quanzheng Li, Jin Sun, Xiang Li, Ninghao Liu)</author>
      <guid isPermaLink="false">2502.14044v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Method to Simultaneously Facilitate All Jet Physics Tasks</title>
      <link>http://arxiv.org/abs/2502.14652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在喷射物理中发挥着关键作用，特别是在处理高维数据的复杂性方面。通过专门设计的机器学习模型进行特定任务训练后，可以改进所有其他喷射物理学任务的准确度、精确性和速度。&lt;h4&gt;背景&lt;/h4&gt;由于喷射具有复杂的高维度性质，人工无法全面分析其特性，而神经网络能够从整体上探索这些特性。&lt;h4&gt;目的&lt;/h4&gt;展示专门构建的机器学习模型在特定喷射分类任务上的训练可以提高所有其他喷射物理学任务的表现，并介绍OmniLearn方法作为一个基础模型应用于喷射物理领域。&lt;h4&gt;方法&lt;/h4&gt;通过使用特定多类生成和分类任务进行训练，然后将学到的表示用于不同类型的生成和分类任务、具有不同的探测器模拟数据集的任务、来自不同碰撞系统的喷射任务（pp与ep）、似然比估计以及异常检测中。&lt;h4&gt;主要发现&lt;/h4&gt;专门构建的机器学习模型可以提高所有其他喷射物理任务的表现，且OmniLearn方法作为一个通用的基础模型适用于需要高精度分析的情况。&lt;h4&gt;结论&lt;/h4&gt;OmniLearn方法作为一种基础模型在任何需要顶尖精确度的涉及喷射及其结构分析的应用中公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has become an essential tool in jet physics. Due to theircomplex, high-dimensional nature, jets can be explored holistically by neuralnetworks in ways that are not possible manually. However, innovations in allareas of jet physics are proceeding in parallel. We show that speciallyconstructed machine learning models trained for a specific jet classificationtask can improve the accuracy, precision, or speed of all other jet physicstasks. This is demonstrated by training on a particular multiclass generationand classification task and then using the learned representation for differentgeneration and classification tasks, for datasets with a different (full)detector simulation, for jets from a different collision system (pp versus ep),for generative models, for likelihood ratio estimation, and for anomalydetection. We consider, our OmniLearn approach thus as a jet-physics foundationmodel. It is made publicly available for use in any area where state-of-the-artprecision is required for analyses involving jets and their substructure.</description>
      <author>example@mail.com (Vinicius Mikuni, Benjamin Nachman)</author>
      <guid isPermaLink="false">2502.14652v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>SelfAge: Personalized Facial Age Transformation Using Self-reference Images</title>
      <link>http://arxiv.org/abs/2502.13987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于扩散模型的个性化面部年龄变换方法，旨在生成更接近个人实际年龄变化特征的人脸图像。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习方法虽然能够产生自然的老化效果，但无法准确反映个人因生活经历而产生的独特老化特征。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以利用少量自参考图片进行个性化训练的扩散模型，以实现更加个性化的面部年龄变换。&lt;h4&gt;方法&lt;/h4&gt;通过引入自我参照图像作为额外监督信息，对预训练的扩散模型进行微调，并设计有效的提示来提高效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在定量和定性评估中均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够更好地保留个人身份的同时实现更加自然且个性化的面部年龄变化。&lt;h4&gt;翻译&lt;/h4&gt;面部图像的年龄转换是一种编辑与年龄相关的人脸外观的技术，在保持个人识别性的前提下进行。现有的基于深度学习的方法可以再现自然的衰老过程；然而，它们只能再现平均化的过渡效果，而无法考虑到由于生活经历影响的独特个体特征。在本文中，我们提出了第一个基于扩散模型的个性化年龄变换方法。我们的扩散模型以面部图像和目标年龄作为输入，并生成经过年龄编辑后的面部图像输出。为了反映个人特定特征，我们将使用自我参照图片（即同一人的不同年龄段的照片）作为额外监督信息来微调预训练的扩散模型。我们还设计了一种有效的提示来增强年龄编辑效果和身份保存能力。实验结果表明，在定量与定性评估中，我们的方法都优于现有方法。代码及预训练模型可在 https://github.com/shiiiijp/SelfAge 查找。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Age transformation of facial images is a technique that edits age-relatedperson's appearances while preserving the identity. Existing deeplearning-based methods can reproduce natural age transformations; however, theyonly reproduce averaged transitions and fail to account for individual-specificappearances influenced by their life histories. In this paper, we propose thefirst diffusion model-based method for personalized age transformation. Ourdiffusion model takes a facial image and a target age as input and generates anage-edited face image as output. To reflect individual-specific features, weincorporate additional supervision using self-reference images, which arefacial images of the same person at different ages. Specifically, we fine-tunea pretrained diffusion model for personalized adaptation using approximately 3to 5 self-reference images. Additionally, we design an effective prompt toenhance the performance of age editing and identity preservation. Experimentsdemonstrate that our method achieves superior performance both quantitativelyand qualitatively compared to existing methods. The code and the pretrainedmodel are available at https://github.com/shiiiijp/SelfAge.</description>
      <author>example@mail.com (Taishi Ito, Yuki Endo, Yoshihiro Kanamori)</author>
      <guid isPermaLink="false">2502.13987v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>VB-Com: Learning Vision-Blind Composite Humanoid Locomotion Against Deficient Perception</title>
      <link>http://arxiv.org/abs/2502.14814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种复合框架VB-Com，该框架使类人机器人能够在感知不足的情况下决定何时依赖视觉策略和何时切换到盲策略。&lt;h4&gt;背景&lt;/h4&gt;腿足运动性能与状态观察的准确性和全面性密切相关。仅依靠本体感觉的盲策略被认为高度可靠，但限制了行走速度，并且经常需要通过碰撞地形来适应。相比之下，视觉策略允许机器人提前规划动作并积极应对未结构化的地形，但由于真实环境中的噪音、传感器故障以及当前模拟中动态或可变形地形的局限性，感知常常受到影响。&lt;h4&gt;目的&lt;/h4&gt;为了利用视觉策略和盲策略的优势，该研究旨在开发一种能够帮助类人机器人在感知不足的情况下做出决策的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为VB-Com的新框架，使类人机器人能够在动态或不可预测地形中进行导航时决定何时依赖于视觉信息，以及何时切换到仅使用本体感觉的策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VB-Com能够帮助类人机器人克服由动态环境或感知噪声引起的障碍，成功穿越具有挑战性的地形和障碍物。&lt;h4&gt;结论&lt;/h4&gt;通过结合视觉策略与盲策略的优点，VB-Com框架提供了一种更鲁棒、高效的解决方案来应对真实世界中的复杂挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of legged locomotion is closely tied to the accuracy andcomprehensiveness of state observations. Blind policies, which rely solely onproprioception, are considered highly robust due to the reliability ofproprioceptive observations. However, these policies significantly limitlocomotion speed and often require collisions with the terrain to adapt. Incontrast, Vision policies allows the robot to plan motions in advance andrespond proactively to unstructured terrains with an online perception module.However, perception is often compromised by noisy real-world environments,potential sensor failures, and the limitations of current simulations inpresenting dynamic or deformable terrains. Humanoid robots, with high degreesof freedom and inherently unstable morphology, are particularly susceptible tomisguidance from deficient perception, which can result in falls or terminationon challenging dynamic terrains. To leverage the advantages of both vision andblind policies, we propose VB-Com, a composite framework that enables humanoidrobots to determine when to rely on the vision policy and when to switch to theblind policy under perceptual deficiency. We demonstrate that VB-Comeffectively enables humanoid robots to traverse challenging terrains andobstacles despite perception deficiencies caused by dynamic terrains orperceptual noise.</description>
      <author>example@mail.com (Junli Ren, Tao Huang, Huayi Wang, Zirui Wang, Qingwei Ben, Jiangmiao Pang, Ping Luo)</author>
      <guid isPermaLink="false">2502.14814v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Planning, scheduling, and execution on the Moon: the CADRE technology demonstration mission</title>
      <link>http://arxiv.org/abs/2502.14803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be presented at AAMAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;NASA的CADRE任务计划于2025/2026年飞往月球Reiner Gamma地区，旨在演示多代理自主探索月球表面和次表层。该团队包括三台机器人和一个基站，将自主地在着陆器附近的一个区域内进行探索。&lt;h4&gt;背景&lt;/h4&gt;NASA的CADRE任务的目标是展示多个自治机器人如何协同工作来收集数据并绘制月球表面及其地下部分的地图。&lt;h4&gt;目的&lt;/h4&gt;演示多代理自主探索技术和分布式规划、调度与执行系统的功能。该系统确保在没有人类输入的情况下，机器人能够高效且安全地执行各种任务。&lt;h4&gt;方法&lt;/h4&gt;CADRE的软件架构基于一个新颖的自治、分布式的计划、调度和执行（PS&amp;E）系统。此系统采用集中式规划和分布式执行的概念，并利用选举领导者机制来增强系统的鲁棒性，确保在个别代理失效时仍能继续正常运作。&lt;h4&gt;主要发现&lt;/h4&gt;论文描述了CADRE PS&amp;E系统的架构、设计理由以及该系统在硬件上的验证与测试情况。&lt;h4&gt;结论&lt;/h4&gt;准备将PS&amp;E系统部署到月球上进行实际操作，并通过此次任务展示其有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE)mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, isdesigned to demonstrate multi-agent autonomous exploration of the Lunar surfaceand sub-surface. A team of three robots and a base station will autonomouslyexplore a region near the lander, collecting the data required for 3Dreconstruction of the surface with no human input; and then autonomouslyperform distributed sensing with multi-static ground penetrating radars (GPR),driving in formation while performing coordinated radar soundings to create amap of the subsurface. At the core of CADRE's software architecture is a novelautonomous, distributed planning, scheduling, and execution (PS&amp;E) system. Thesystem coordinates the robots' activities, planning and executing tasks thatrequire multiple robots' participation while ensuring that each individualrobot's thermal and power resources stay within prescribed bounds, andrespecting ground-prescribed sleep-wake cycles. The system uses acentralized-planning, distributed-execution paradigm, and a leader electionmechanism ensures robustness to failures of individual agents. In this paper,we describe the architecture of CADRE's PS&amp;E system; discuss its designrationale; and report on verification and validation (V&amp;V) testing of thesystem on CADRE's hardware in preparation for deployment on the Moon.</description>
      <author>example@mail.com (Gregg Rabideau, Joseph Russino, Andrew Branch, Nihal Dhamani, Tiago Stegun Vaquero, Steve Chien, Jean-Pierre de la Croix, Federico Rossi)</author>
      <guid isPermaLink="false">2502.14803v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration</title>
      <link>http://arxiv.org/abs/2502.14795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Humanoid-VLA框架，用于解决现有类人机器人控制框架在自主交互能力和数据稀缺性方面的局限性。该框架结合了语言理解、第一视角场景感知和运动控制。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人控制框架主要依赖于反应机制，并且由于缺乏足够的数据而难以实现自主互动能力。&lt;h4&gt;目的&lt;/h4&gt;提出Humanoid-VLA框架，旨在通过整合多方面的能力来增强人形机器人的交互能力和环境适应性。&lt;h4&gt;方法&lt;/h4&gt;首先使用非第一视角的配有人类动作描述的数据集进行语言和运动的预对齐；然后引入参数高效的视频条件微调以结合第一视觉上下文；最后采用一种自监督数据增强策略生成伪注释，将原始运动序列转化为问题回答对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于全身控制架构的人形机器人VLA框架能够执行对象交互和环境探索任务，并且具备更强的语境感知能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合语言理解、场景感知及运动控制，Humanoid-VLA展示了更接近人类的表现，即能够进行适应性和智能性的互动，从而克服了当前人形机器人在自主性方面的限制。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其对应中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the limitations of current humanoid robot controlframeworks, which primarily rely on reactive mechanisms and lack autonomousinteraction capabilities due to data scarcity. We propose Humanoid-VLA, a novelframework that integrates language understanding, egocentric scene perception,and motion control, enabling universal humanoid control. Humanoid-VLA beginswith language-motion pre-alignment using non-egocentric human motion datasetspaired with textual descriptions, allowing the model to learn universal motionpatterns and action semantics. We then incorporate egocentric visual contextthrough a parameter efficient video-conditioned fine-tuning, enablingcontext-aware motion generation. Furthermore, we introduce a self-superviseddata augmentation strategy that automatically generates pseudoannotationsdirectly derived from motion data. This process converts raw motion sequencesinto informative question-answer pairs, facilitating the effective use oflarge-scale unlabeled video data. Built upon whole-body control architectures,extensive experiments show that Humanoid-VLA achieves object interaction andenvironment exploration tasks with enhanced contextual awareness, demonstratinga more human-like capacity for adaptive and intelligent engagement.</description>
      <author>example@mail.com (Pengxiang Ding, Jianfei Ma, Xinyang Tong, Binghong Zou, Xinxin Luo, Yiguo Fan, Ting Wang, Hongchao Lu, Panzhong Mo, Jinxin Liu, Yuefan Wang, Huaicheng Zhou, Wenshuo Feng, Jiacheng Liu, Siteng Huang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.14795v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Agent Coordination across Diverse Applications: A Survey</title>
      <link>http://arxiv.org/abs/2502.14743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了多智能体系统（MAS）中的协调研究现状，通过回答四个基本的协调问题来提供统一的理解。&lt;h4&gt;背景&lt;/h4&gt;随着新兴应用和快速的人工智能发展，对多代理系统中趋势传播的基本机制的研究受到了越来越多的关注。&lt;h4&gt;目的&lt;/h4&gt;探索现有的协调思想和技术，并指出不同应用程序之间的联系以及未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;首先识别并分析了在各种应用程序中都至关重要的一般性协调问题。其次，综述了一系列的MAS应用案例。最后，分析和讨论了关于可扩展性、异质性和学习机制等开放挑战。&lt;h4&gt;主要发现&lt;/h4&gt;指出了分层与去中心化协调结合、人机协作以及基于大语言模型（LLM）的多智能体系统作为未来的有前景的研究方向。&lt;h4&gt;结论&lt;/h4&gt;通过统一的理解，明确了当前MAS协调研究的状态，并为未来提出了具有潜力的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent coordination studies the underlying mechanism enabling thetrending spread of diverse multi-agent systems (MAS) and has receivedincreasing attention, driven by the expansion of emerging applications andrapid AI advances. This survey outlines the current state of coordinationresearch across applications through a unified understanding that answers fourfundamental coordination questions: (1) what is coordination; (2) whycoordination; (3) who to coordinate with; and (4) how to coordinate. Ourpurpose is to explore existing ideas and expertise in coordination and theirconnections across diverse applications, while identifying and highlightingemerging and promising research directions. First, general coordinationproblems that are essential to varied applications are identified and analyzed.Second, a number of MAS applications are surveyed, ranging from widely studieddomains, e.g., search and rescue, warehouse automation and logistics, andtransportation systems, to emerging fields including humanoid andanthropomorphic robots, satellite systems, and large language models (LLMs).Finally, open challenges about the scalability, heterogeneity, and learningmechanisms of MAS are analyzed and discussed. In particular, we identify thehybridization of hierarchical and decentralized coordination, human-MAScoordination, and LLM-based MAS as promising future directions.</description>
      <author>example@mail.com (Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen)</author>
      <guid isPermaLink="false">2502.14743v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Performance Scores: Directed Functional Connectivity as a Brain-Based Biomarker for Motor Skill Learning and Retention</title>
      <link>http://arxiv.org/abs/2502.14731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于脑电图（EEG）的定向功能连接性（dFC）作为新的生物标记物，用于评估运动技能学习和保持阶段。研究通过应用Fitts和Posner模型的不同阶段来展示dFC在神经机制中的作用，并展示了其在整个训练过程中及六周停训期后的稳定性和有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的性能指标如执行时间和错误率对捕捉复杂的任务序列学习过程中的神经机制提供了有限的见解。这些指标难以深入理解技能习得和保持背后的认知变化。&lt;h4&gt;目的&lt;/h4&gt;引入基于EEG的dFC作为新的生物标记物，用以更好地评估运动技能的学习与保留情况，并提供对神经机制的新视角。&lt;h4&gt;方法&lt;/h4&gt;应用定向功能连接性（dFC）来映射Fitts和Posner模型的不同阶段，同时对比对照组，确保观察到的变化是由于训练而非其他因素引起的。&lt;h4&gt;主要发现&lt;/h4&gt;1. dFC能够有效地识别并追踪通过Fitts和Posner模型各个学习阶段的进展。2. 与传统方法相比，dFC捕捉到了神经信息流动的方向性和强度，提供了更全面的理解。3. 在六周停训期内，观察到dFC具有较高的稳定性，表明其在长期保持中的监测作用。4. 对照组未显示出显著变化，进一步确认了训练引起的特定神经适应性。&lt;h4&gt;结论&lt;/h4&gt;dFC作为一种强有力的生物标记物补充了传统的性能指标，对运动技能学习和保留提供了更深入的理解。它有助于个性化、靶向的训练协议的发展，特别是在外科教育等领域中至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motor skill acquisition in fields like surgery, robotics, and sports involveslearning complex task sequences through extensive training. Traditionalperformance metrics, like execution time and error rates, offer limited insightas they fail to capture the neural mechanisms underlying skill learning andretention. This study introduces directed functional connectivity (dFC),derived from electroencephalography (EEG), as a novel brain-based biomarker forassessing motor skill learning and retention. For the first time, dFC isapplied as a biomarker to map the stages of the Fitts and Posner motor learningmodel, offering new insights into the neural mechanisms underlying skillacquisition and retention. Unlike traditional measures, it captures both thestrength and direction of neural information flow, providing a comprehensiveunderstanding of neural adaptations across different learning stages. Theanalysis demonstrates that dFC can effectively identify and track theprogression through various stages of the Fitts and Posner model. Furthermore,its stability over a six-week washout period highlights its utility inmonitoring long-term retention. No significant changes in dFC were observed ina control group, confirming that the observed neural adaptations were specificto training and not due to external factors. By offering a granular view of thelearning process at the group and individual levels, dFC facilitates thedevelopment of personalized, targeted training protocols aimed at enhancingoutcomes in fields where precision and long-term retention are critical, suchas surgical education. These findings underscore the value of dFC as a robustbiomarker that complements traditional performance metrics, providing a deeperunderstanding of motor skill learning and retention.</description>
      <author>example@mail.com (Anil Kamat, Rahul Rahul, Lora Cavuoto, Harry Burke, Matthew Hackett, Jack Norfleet, Steven Schwaitzberg, Suvranu De)</author>
      <guid isPermaLink="false">2502.14731v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>CDGS: Confidence-Aware Depth Regularization for 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.14684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;3D高斯点阵（3DGS）在新颖视图合成中表现出色，但其几何准确性受限于缺乏明确的几何约束。本文提出了一种新的方法CDGS来增强3DGS。&lt;h4&gt;背景&lt;/h4&gt;3DGS在渲染速度和图像质量方面具有优势，但在三维重建中的几何精度受到限制。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种基于深度正则化的信心感知方法（CDGS）以提高3DGS的几何细节保持能力和几何准确度。&lt;h4&gt;方法&lt;/h4&gt;使用多线索信心图来自单目深度估计和稀疏的结构从运动深度来适应性地调整优化过程中的深度监督。&lt;h4&gt;主要发现&lt;/h4&gt;在新颖视图合成的质量和几何精度方面都取得了竞争性的性能，特别是在训练早期阶段改善了细节保持能力，并且在Tanks and Temples基准数据集上的实验表明，该方法可以实现更稳定的收敛行为及更高的几何重建准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了3DGS的效率和准确度，还可能为数字孪生创建、文化遗产保护或林业应用等现实世界中的高效和精确三维重建系统的发展提供帮助。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D高斯点阵（3DGS）在新颖视图合成中表现出显著的优势，特别是在实现高速渲染和高质量结果方面。然而，由于优化过程中缺乏明确的几何约束，其在三维重建中的几何准确性仍然有限。本文介绍了一种新的方法CDGS来增强3DGS。我们利用单目深度估计的多线索信心图以及稀疏结构从运动深度，在优化过程中自适应地调整深度监督。我们的方法展示了在训练早期阶段改善了细节保持能力，并且实现了新颖视图合成质量和几何精度方面的竞争性性能。在公开可用的Tanks and Temples基准数据集上的实验表明，该方法可以实现更稳定的收敛行为及更高的几何重建准确性，在PSNR方面提升了最多2.31 dB，而M3C2距离度量中的几何误差更低。值得注意的是，我们的方法仅用50%的训练迭代次数就达到了与原始3DGS相当的F分数。我们预计这项工作将有助于开发高效的三维重建系统用于现实世界的应用，如数字孪生创建、文化遗产保护或林业应用等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has shown significant advantages in novel viewsynthesis (NVS), particularly in achieving high rendering speeds andhigh-quality results. However, its geometric accuracy in 3D reconstructionremains limited due to the lack of explicit geometric constraints duringoptimization. This paper introduces CDGS, a confidence-aware depthregularization approach developed to enhance 3DGS. We leverage multi-cueconfidence maps of monocular depth estimation and sparse Structure-from-Motiondepth to adaptively adjust depth supervision during the optimization process.Our method demonstrates improved geometric detail preservation in earlytraining stages and achieves competitive performance in both NVS quality andgeometric accuracy. Experiments on the publicly available Tanks and Templesbenchmark dataset show that our method achieves more stable convergencebehavior and more accurate geometric reconstruction results, with improvementsof up to 2.31 dB in PSNR for NVS and consistently lower geometric errors inM3C2 distance metrics. Notably, our method reaches comparable F-scores to theoriginal 3DGS with only 50% of the training iterations. We expect this workwill facilitate the development of efficient and accurate 3D reconstructionsystems for real-world applications such as digital twin creation, heritagepreservation, or forestry applications.</description>
      <author>example@mail.com (Qilin Zhang, Olaf Wysocki, Steffen Urban, Boris Jutzi)</author>
      <guid isPermaLink="false">2502.14684v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Structure-from-Sherds++: Robust Incremental 3D Reassembly of Axially Symmetric Pots from Unordered and Mixed Fragment Collections</title>
      <link>http://arxiv.org/abs/2502.13986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种用于重新组装多个轴对称陶器的高效方法，该方法基于逐片迭代注册技术，通过利用多图束搜索来探索多种注册路径，并过滤出无法区分的虚假匹配。&lt;h4&gt;背景&lt;/h4&gt;碎片化陶片重新组装对于文化遗产保护至关重要，但薄且锋利的断裂面导致大量错误匹配，使得大规模拼图解决变得困难。现有的全局方法在处理多重混杂时面临局部极小值和可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的重组成型方法，以克服现有技术挑战并提高轴对称陶器碎片重新组装的成功率。&lt;h4&gt;方法&lt;/h4&gt;受到基于多图像的三维重建结构从运动（SfM）方法启发，我们开发了一种基于逐片迭代注册的新方法Structure-from-Sherds++ (SfS++)。此方法通过探索多种可能的匹配路径来过滤错误匹配，并且不需要先验信息如底座或混合物体的数量。&lt;h4&gt;主要发现&lt;/h4&gt;在包含142个真实碎片和来自10种不同陶器的数据集上，我们的方法实现了87%的重新组装准确率，优于其他处理复杂裂纹图案和混杂数据的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的SfS++方法展示了其在文化遗产保护中的潜力，特别是在处理混合轴对称陶器碎片时。它克服了现有技术的局限性，并且无需任何先验信息即可有效重新组装多个物体。&lt;h4&gt;翻译&lt;/h4&gt;重新组装破碎的具有轴向对称性的陶器对于文化遗迹保存极为重要，但由于这些陶器碎片薄而尖锐，容易产生大量误匹配，使得大规模拼图解决成为一项巨大挑战。现有的全局方法和数据驱动模型在处理复杂情况时易陷入局部最小值，并且面对多重混杂的数据集时可扩展性较差。受结构从运动(SfM)技术的启发，我们提出了一种基于逐片迭代注册的重新组装方法Structure-from-Sherds++ (SfS++)，能够有效过滤出无法区分的误匹配并同时重构多个陶器而不需任何先验信息。在包含142个真实碎片和来自十种不同陶器的数据集上，我们的方法实现了87%的成功率，优于其他处理复杂裂纹图案与混合数据的方法，并且达到了当前的最佳水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reassembling multiple axially symmetric pots from fragmentary sherds iscrucial for cultural heritage preservation, yet it poses significant challengesdue to thin and sharp fracture surfaces that generate numerous false positivematches and hinder large-scale puzzle solving. Existing global approaches,which optimize all potential fragment pairs simultaneously or data-drivenmodels, are prone to local minima and face scalability issues when multiplepots are intermixed. Motivated by Structure-from-Motion (SfM) for 3Dreconstruction from multiple images, we propose an efficient reassembly methodfor axially symmetric pots based on iterative registration of one sherd at atime, called Structure-from-Sherds++ (SfS++). Our method extends beyond simplereplication of incremental SfM and leverages multi-graph beam search to exploremultiple registration paths. This allows us to effectively filter outindistinguishable false matches and simultaneously reconstruct multiple potswithout requiring prior information such as base or the number of mixedobjects. Our approach achieves 87% reassembly accuracy on a dataset of 142 realfragments from 10 different pots, outperforming other methods in handlingcomplex fracture patterns with mixed datasets and achieving state-of-the-artperformance. Code and results can be found in our project pagehttps://sj-yoo.info/sfs/.</description>
      <author>example@mail.com (Seong Jong Yoo, Sisung Liu, Muhammad Zeeshan Arshad, Jinhyeok Kim, Young Min Kim, Yiannis Aloimonos, Cornelia Fermuller, Kyungdon Joo, Jinwook Kim, Je Hyeong Hong)</author>
      <guid isPermaLink="false">2502.13986v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO</title>
      <link>http://arxiv.org/abs/2502.14669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的两阶段训练框架，旨在为标准的大型语言模型（LLMs）赋予空间视觉推理能力，特别是在迷宫导航任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;尽管大模型在语言处理方面表现出色，但在需要真实的空间视觉推理的任务上存在困难。&lt;h4&gt;目的&lt;/h4&gt;通过一种创新的方法来增强现有语言模型的空间推理能力，特别是用于解决迷宫导航问题。&lt;h4&gt;方法&lt;/h4&gt;{'第一阶段': '使用监督微调（SFT）在包含标记化迷宫表示的数据集上训练模型以预测步骤指令', '第二阶段': '应用集团相对策略优化（GRPO），通过精心设计的奖励函数进一步提高模型的序列决策能力'}&lt;h4&gt;主要发现&lt;/h4&gt;{'基准测试结果': '基础模型无法导航迷宫，而SFT微调后的模型达到了86%的准确性', '增强效果': '进一步应用GRPO后，模型准确率提升至93%，显示出更稳健且自我纠正的空间推理能力'}&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了将语言模型与视觉空间任务相结合的巨大潜力，并为机器人、自主导航等领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在处理自然语言方面表现出色，但在需要真实空间视觉推理的任务中却表现不佳。本论文提出了一种创新的两阶段训练框架，旨在增强标准LLMs的空间视觉推理能力，特别是在迷宫导航任务上。该方法包括使用监督微调（SFT）和集团相对策略优化（GRPO），并在合成生成的迷宫实验中取得了86%至93%的准确率提升。研究结果表明，通过适当的技术改进，可以显著提高语言模型处理视觉空间问题的能力，并为机器人技术、自主导航等领域的应用提供了新的可能路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated impressive capabilities inlanguage processing, yet they often struggle with tasks requiring genuinevisual spatial reasoning. In this paper, we introduce a novel two-stagetraining framework designed to equip standard LLMs with visual reasoningabilities for maze navigation. First, we leverage Supervised Fine Tuning (SFT)on a curated dataset of tokenized maze representations to teach the model topredict step-by-step movement commands. Next, we apply Group Relative PolicyOptimization (GRPO)-a technique used in DeepSeekR1-with a carefully craftedreward function to refine the model's sequential decision-making and encourageemergent chain-of-thought behaviors. Experimental results on syntheticallygenerated mazes show that while a baseline model fails to navigate the maze,the SFT-trained model achieves 86% accuracy, and further GRPO fine-tuningboosts accuracy to 93%. Qualitative analyses reveal that GRPO fosters morerobust and self-corrective reasoning, highlighting the potential of ourapproach to bridge the gap between language models and visual spatial tasks.These findings offer promising implications for applications in robotics,autonomous navigation, and other domains that require integrated visual andsequential reasoning.</description>
      <author>example@mail.com (Alan Dao, Dinh Bach Vu)</author>
      <guid isPermaLink="false">2502.14669v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Monocular Depth Estimation and Segmentation for Transparent Object with Iterative Semantic and Geometric Fusion</title>
      <link>http://arxiv.org/abs/2502.14616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA(2025). The code is accessible through:  https://github.com/L-J-Yuan/MODEST&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种用于透明物体分割和深度估计的单目框架，该框架利用单一图像输入，并通过语义与几何融合模块及迭代策略优化预测结果。&lt;h4&gt;背景&lt;/h4&gt;透明物体的感知对于许多机器人任务至关重要。然而，由于其复杂的光学特性，准确地对透明物体进行分割并估算深度仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在只使用单张图像输入的情况下，在透明对象的分割和深度估计方面表现卓越的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新颖的语义与几何融合模块，有效整合了任务之间的多尺度信息，并采用迭代策略逐步优化初始特征以获得更清晰的结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型在两个具有挑战性的合成数据集和真实世界数据集中超越了现有的单目、立体以及多视角方法，改进幅度达到了约38.8%-46.2%。&lt;h4&gt;结论&lt;/h4&gt;提出的框架是第一个能够在单一图像输入下同时优化透明物体分割与深度估计的方法，并且其效果显著优于现有技术。&lt;h4&gt;翻译&lt;/h4&gt;透明物体感知对于许多机器人任务来说至关重要。然而，由于复杂的光学特性，准确地对透明物体进行分割并估算其深度仍然具有挑战性。现有的方法主要专注于单独的任务，使用额外的输入或专用传感器，忽略了任务之间的有价值交互以及后续精炼过程，导致预测结果模糊且不理想。为了解决这些问题，我们提出了一种单目框架，这是第一个在仅用单张图像作为输入的情况下，在透明物体分割和深度估计方面表现出色的方法。具体来说，我们设计了一个新颖的语义与几何融合模块，有效整合了多尺度信息之间的任务，并受到人类感知对象方式的启发，进一步采用了迭代策略，逐步优化初始特征以获得更清晰的结果。在两个具有挑战性的合成数据集和真实世界数据集中进行的实验表明，我们的模型超越了现有的单目、立体以及多视角方法，在只有单一RGB输入的情况下，性能提高了约38.8%-46.2%。相关代码和模型可在https://github.com/L-J-Yuan/MODEST公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transparent object perception is indispensable for numerous robotic tasks.However, accurately segmenting and estimating the depth of transparent objectsremain challenging due to complex optical properties. Existing methodsprimarily delve into only one task using extra inputs or specialized sensors,neglecting the valuable interactions among tasks and the subsequent refinementprocess, leading to suboptimal and blurry predictions. To address these issues,we propose a monocular framework, which is the first to excel in bothsegmentation and depth estimation of transparent objects, with only asingle-image input. Specifically, we devise a novel semantic and geometricfusion module, effectively integrating the multi-scale information betweentasks. In addition, drawing inspiration from human perception of objects, wefurther incorporate an iterative strategy, which progressively refines initialfeatures for clearer results. Experiments on two challenging synthetic andreal-world datasets demonstrate that our model surpasses state-of-the-artmonocular, stereo, and multi-view methods by a large margin of about38.8%-46.2% with only a single RGB input. Codes and models are publiclyavailable at https://github.com/L-J-Yuan/MODEST.</description>
      <author>example@mail.com (Jiangyuan Liu, Hongxuan Ma, Yuxin Guo, Yuhao Zhao, Chi Zhang, Wei Sui, Wei Zou)</author>
      <guid isPermaLink="false">2502.14616v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Real-world Troublemaker: A Novel Track Testing Framework for Automated Driving Systems in Safety-critical Interaction Scenarios</title>
      <link>http://arxiv.org/abs/2502.14574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,14 figures,2tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为Real-world Troublemaker的新型测试框架，用于生成对抗性目标对象运动轨迹，并促进被测车辆与环境之间的智能交互。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶系统的轨道测试场景通常是固定的和有限的，这是由于物体控制方法缺乏灵活性以及缺乏智能化互动行为造成的。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够产生对抗性目标物运动轨迹并促进车辆与环境间智能互动的新框架，从而创建更加真实且动态的测试环境。&lt;h4&gt;方法&lt;/h4&gt;利用云控制系统远程动态地操控对象以模拟真实的交通场景，并引入游戏理论结构下的互动具体场景生成法来实现智能化交互。&lt;h4&gt;主要发现&lt;/h4&gt;在同济大学智能网联汽车测评基地成功实施了此框架，结果显示它能够准确有效地执行动态交互测试。与传统方法相比，Troublemaker提高了场景再现精度65.2%，增加了目标车辆互动策略的多样性大约9.2倍，并将无保护左转安全临界情景的曝光频率提高3.5倍。&lt;h4&gt;结论&lt;/h4&gt;Real-world Troublemaker框架克服了现有自动驾驶系统测试中物体控制和智能交互方面的局限性，提供了更准确、高效且多样的场景再现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Track testing plays a critical role in the safety evaluation of autonomousdriving systems (ADS), as it provides real-world object targets and asafety-controllable interaction environment. However, existing track testingscenarios are often pre-fixed and limited, primarily due to the inflexibilityof object target control methods and the lack of intelligent interactivebehaviors. To overcome this limitation, we propose a novel track testingframework, Real-world Troublemaker, which can generate adversarial objecttarget motion trajectories and facilitate intelligent interactions with thevehicle under test (VUT), creating a more realistic and dynamic testingenvironment. To enable flexible motion trajectories, cloud-controlledtechnology is utilized to remotely and dynamically control object targets tocreate a realistic traffic environment. To achieve intelligent interactions, aninteractive concrete scenario generation method is introduced within agame-theoretic structure. The proposed framework has been successfullyimplemented at the Tongji University Intelligent Connected Vehicle EvaluationBase. Field test results demonstrate that Troublemaker can perform dynamicinteractive testing of ADS accurately and effectively. Compared to traditionaltrack testing methods, Troublemaker improves scenario reproduction accuracy by65.2\%, increases the diversity of target vehicle interaction strategies byapproximately 9.2 times, and enhances exposure frequency of safety-criticalscenarios by 3.5 times in unprotected left-turn scenarios.</description>
      <author>example@mail.com (Xinrui Zhang, Lu Xiong, Peizhi Zhang, Junpeng Huang, Yining Ma)</author>
      <guid isPermaLink="false">2502.14574v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>A Mobile Robotic Approach to Autonomous Surface Scanning in Legal Medicine</title>
      <link>http://arxiv.org/abs/2502.14514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted and accepted for presentation at CARS 2025. This preprint  has not undergone peer review or post-submission revisions. The final version  of this work will appear in the official CARS 2025 proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了一种移动机器人系统在法医学领域中的应用，该系统能够进行全身体表RGB-D扫描。&lt;h4&gt;背景&lt;/h4&gt;目前的法医文档记录主要依赖于手动操作，时间成本高且主观误差大。采用固定安装的机器人系统则需要大量空间和专用房间。&lt;h4&gt;目的&lt;/h4&gt;研究开发一种移动机器人系统用于尸体外部损伤的数字化文档记录，并评估其在实际应用中的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计并实现了一种能够进行全身体表RGB-D扫描的移动机器人系统，通过实验室实验验证系统的环境配置参数及适用性。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在三个特定位置上使用该系统可以达到94.96%的身体覆盖范围，并且在模拟和实际尸体上的表面覆盖率分别为96.90%±3.16%和92.45%±1.43%，证明了系统的有效性。&lt;h4&gt;结论&lt;/h4&gt;移动机器人系统能够有效支持法医学中的RGB-D扫描，有助于提高文档记录的效率和自动化程度，并减少手动干预的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：目的包括尸体内外部检查在内的全面法律医学文件记录通常由手动常规解剖过程中完成。特别地，外部伤口的数字化文档记录对于法医分析越来越重要。为此，引入了RGB表面扫描技术。然而，手持相机进行全表面扫描耗时且依赖操作者；而固定安装的机器人系统则需要大量空间和专用房间。因此，我们探讨了一种移动机器人系统的可行性用于尸体外层文档记录的方法开发：我们设计并实现了一个可全身RGB-D扫描的移动机器人系统，并通过实验室实验验证了其环境配置参数及实际应用效果。结果表明，在三个特定位置上的全身体表覆盖率为94.96%；模拟和真实尸体表面覆盖率分别为96.90±3.16%和92.45±1.43%，证明系统有效。结论：移动机器人系统的RGB-D扫描在法医领域显示出了极大的潜力，可以支持更高效的自动文档记录过程，并减少手动干预的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Comprehensive legal medicine documentation includes both an internalbut also an external examination of the corpse. Typically, this documentationis conducted manually during conventional autopsy. A systematic digitaldocumentation would be desirable, especially for the external examination ofwounds, which is becoming more relevant for legal medicine analysis. For thispurpose, RGB surface scanning has been introduced. While a manual full surfacescan using a handheld camera is timeconsuming and operator dependent, floor orceiling mounted robotic systems require substantial space and a dedicated room.Hence, we consider whether a mobile robotic system can be used for externaldocumentation. Methods: We develop a mobile robotic system that enablesfull-body RGB-D surface scanning. Our work includes a detailed configurationspace analysis to identify the environmental parameters that need to beconsidered to successfully perform a surface scan. We validate our findingsthrough an experimental study in the lab and demonstrate the system'sapplication in a legal medicine environment. Results: Our configuration spaceanalysis shows that a good trade-off between coverage and time is reached withthree robot base positions, leading to a coverage of 94.96 %. Experimentsvalidate the effectiveness of the system in accurately capturing body surfacegeometry with an average surface coverage of 96.90 +- 3.16 % and 92.45 +- 1.43% for a body phantom and actual corpses, respectively. Conclusion: This workdemonstrates the potential of a mobile robotic system to automate RGB-D surfacescanning in legal medicine, complementing the use of post-mortem CT scans forinner documentation. Our results indicate that the proposed system cancontribute to more efficient and autonomous legal medicine documentation,reducing the need for manual intervention.</description>
      <author>example@mail.com (Sarah Grube, Sarah Latus, Martin Fischer, Vidas Raudonis, Axel Heinemann, Benjamin Ondruschka, Alexander Schlaefer)</author>
      <guid isPermaLink="false">2502.14514v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated Object Manipulation via Motion Adaptation and Impedance Control</title>
      <link>http://arxiv.org/abs/2502.14457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的基于强化学习的流水线，该流水线装备了可变阻抗控制和利用观测历史进行运动适应的方法，专门用于通用化的关节对象操纵。&lt;h4&gt;背景&lt;/h4&gt;关节物体操作相对于刚性物体操作具有独特的挑战，因为物体本身代表了一个动态环境。传统的视觉数据（RGBD/点云）通常作为策略输入直接使用，但这种做法会增加仿真到现实的差距。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的强化学习流水线，旨在实现零样本模拟到真实场景转换中的平滑且灵巧的动作操作。&lt;h4&gt;方法&lt;/h4&gt;[{'减少对视觉数据依赖': '通过现成模块提取有用的低维数据来间接使用视觉数据特征'}, {'利用观测历史': '推断物体运动及其内在属性以减轻仿真与现实的差距'}, {'阻抗控制': '在模拟和真实环境中均采用阻抗控制'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'训练设置': '设计了一个具有良好随机化和专门奖励系统的训练环境，使多阶段、端到端操作成为可能而无需启发式运动规划'}, {'实验结果': '通过广泛的未见过物体的实验，在真实世界中实现了84%的成功率，据我们所知这是首次报告的结果'}]&lt;h4&gt;结论&lt;/h4&gt;我们的策略是首个在广泛的真实对象上实现高效关节操纵的成功案例。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新颖的方法来解决关节物体操作的独特挑战，并通过广泛的实验验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Articulated object manipulation poses a unique challenge compared to rigidobject manipulation as the object itself represents a dynamic environment. Inthis work, we present a novel RL-based pipeline equipped with variableimpedance control and motion adaptation leveraging observation history forgeneralizable articulated object manipulation, focusing on smooth and dexterousmotion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap,our pipeline diminishes reliance on vision by not leveraging the vision datafeature (RGBD/pointcloud) directly as policy input but rather extracting usefullow-dimensional data first via off-the-shelf modules. Additionally, weexperience less sim-to-real gap by inferring object motion and its intrinsicproperties via observation history as well as utilizing impedance control bothin the simulation and in the real world. Furthermore, we develop awell-designed training setting with great randomization and a specializedreward system (task-aware and motion-aware) that enables multi-staged,end-to-end manipulation without heuristic motion planning. To the best of ourknowledge, our policy is the first to report 84\% success rate in the realworld via extensive experiments with various unseen objects.</description>
      <author>example@mail.com (Tan-Dzung Do, Nandiraju Gireesh, Jilong Wang, He Wang)</author>
      <guid isPermaLink="false">2502.14457v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Ground-aerial Transportation System for Pest Control Enabled by AI-based Autonomous Nano-UAVs</title>
      <link>http://arxiv.org/abs/2502.14455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;高效农作物生产需要早期检测害虫爆发并及时进行处理；本文提出了一种基于多架自主微型无人机（纳米UAV）的解决方案，用于视觉检测害虫，并由一辆较慢但功能强大的车辆运送处理物资。&lt;h4&gt;背景&lt;/h4&gt;农业生产中，及时发现和处理害虫爆发对于保证作物产量至关重要。然而，现有的方法在资源利用效率上存在不足。&lt;h4&gt;目的&lt;/h4&gt;设计一种基于纳米UAV的高效害虫监测与处理系统，以提高农作物生产的可持续性和经济效益。&lt;h4&gt;方法&lt;/h4&gt;['为应对纳米UAV上的极端限制（例如低分辨率传感器和计算能力），我们设计并优化了一个轻量级图像识别卷积神经网络(CNN)。该CNN在检测有害昆虫方面取得了0.79的平均精度(mAP)，同时减少了32倍的操作。', '为了处理田间意外障碍，采用了基于A*算法的全局+局部路径规划器。全局路径规划器确定纳米UAV的最佳飞行路线，而局部规划器可以达到50Hz的运行频率，通过调整近距离路径来防止碰撞。', '进行仿真实验，展示了一架25个纳米UAV组成的机队如何在200x200m的葡萄园中执行任务，并收集信息以优化拖拉机的最佳行进路线。']&lt;h4&gt;主要发现&lt;/h4&gt;['设计并实现了轻量级CNN，在低计算预算下，仍能实现高精度的害虫检测。', '提出了一种基于A*算法的路径规划方法，使纳米UAV能够避免障碍物，并高效完成飞行任务。', '实验表明，使用25架纳米UAV组成的机队可以比传统单一地面车辆节省高达20小时的工作时间。']&lt;h4&gt;结论&lt;/h4&gt;所提出的系统为农业生产提供了高效的害虫监测与处理方案，大幅提升了资源利用效率和作业速度。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3719210&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient crop production requires early detection of pest outbreaks andtimely treatments; we consider a solution based on a fleet of multipleautonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detectpests and a single slower heavy vehicle that visits the detected outbreaks todeliver treatments. To cope with the extreme limitations aboard nano-UAVs,e.g., low-resolution sensors and sub-100 mW computational power budget, wedesign, fine-tune, and optimize a tiny image-based convolutional neural network(CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58GOps/inference), on our dataset, it scores a mean average precision (mAP) of0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operationsthan the best-performing CNN in the literature. Our CNN runs in real-time at6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflienano-UAV. Then, to cope with in-field unexpected obstacles, we leverage aglobal+local path planner based on the A* algorithm. The global path plannerdetermines the best route for the nano-UAV to sweep the entire area, while thelocal one runs up to 50 Hz aboard our nano-UAV and prevents collision byadjusting the short-distance path. Finally, we demonstrate with in-simulatorexperiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard,collected information can be used to plan the best path for the tractor,visiting all and only required hotspots. In this scenario, our efficienttransportation system, compared to a traditional single-ground vehicleperforming both inspection and treatment, can save up to 20 h working time.</description>
      <author>example@mail.com (Luca Crupi, Luca Butera, Alberto Ferrante, Alessandro Giusti, Daniele Palossi)</author>
      <guid isPermaLink="false">2502.14455v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ChatVLA: Unified Multimodal Understanding and Robot Control with Vision-Language-Action Model</title>
      <link>http://arxiv.org/abs/2502.14420v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为ChatVLA的新框架，用于解决视觉-语言-行动模型(VLA)中的两项关键挑战：虚假遗忘和任务干扰。该框架通过分阶段对齐训练和专家混合架构来克服这些问题，并展示了在多模态理解和机器人操作方面的优越性能。&lt;h4&gt;背景&lt;/h4&gt;人类具有感知、理解并与物理世界互动的统一认知能力，而大型语言模型难以复制这种综合理解能力。&lt;h4&gt;目的&lt;/h4&gt;探讨现有视觉-语言-行动模型中的训练模式存在的问题并提出改进方案。&lt;h4&gt;方法&lt;/h4&gt;通过系统性地分析现有的VLA模型训练范式，识别了两个主要挑战：虚假遗忘和任务干扰。为解决这些问题，提出了一个称为ChatVLA的新框架，它包含分阶段对齐训练（Phased Alignment Training）以及专家混合架构(Mixture-of-Experts)。&lt;h4&gt;主要发现&lt;/h4&gt;ChatVLA在视觉问答数据集上表现出具有竞争力的性能，并且在多模态理解基准测试中显著超越了最先进的VLA方法。它以更加参数高效的架构设计，在MMMU和MMStar上的表现分别优于现有模型六倍和47.2%，并在25个实际机器人操作任务中超越了OpenVLA等现有的VLA方法。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了统一框架在实现强大的多模态理解和有效的机器人控制方面的潜力，这表明ChatVLA为这些目标提供了有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess a unified cognitive ability to perceive, comprehend, andinteract with the physical world. Why can't large language models replicatethis holistic understanding? Through a systematic analysis of existing trainingparadigms in vision-language-action models (VLA), we identify two keychallenges: spurious forgetting, where robot training overwrites crucialvisual-text alignments, and task interference, where competing control andunderstanding tasks degrade performance when trained jointly. To overcome theselimitations, we propose ChatVLA, a novel framework featuring Phased AlignmentTraining, which incrementally integrates multimodal data after initial controlmastery, and a Mixture-of-Experts architecture to minimize task interference.ChatVLA demonstrates competitive performance on visual question-answeringdatasets and significantly surpasses state-of-the-art vision-language-action(VLA) methods on multimodal understanding benchmarks. Notably, it achieves asix times higher performance on MMMU and scores 47.2% on MMStar with a moreparameter-efficient design than ECoT. Furthermore, ChatVLA demonstratessuperior performance on 25 real-world robot manipulation tasks compared toexisting VLA methods like OpenVLA. Our findings highlight the potential of ourunified framework for achieving both robust multimodal understanding andeffective robot control.</description>
      <author>example@mail.com (Zhongyi Zhou, Yichen Zhu, Minjie Zhu, Junjie Wen, Ning Liu, Zhiyuan Xu, Weibin Meng, Ran Cheng, Yaxin Peng, Chaomin Shen, Feifei Feng)</author>
      <guid isPermaLink="false">2502.14420v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>OrchardDepth: Precise Metric Depth Estimation of Orchard Scene from Monocular Camera Images</title>
      <link>http://arxiv.org/abs/2502.14279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, Australasian Conference on Robotics and  Automation, ACRA, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;单目深度估计是机器人感知的基础任务，近年来随着更准确和稳健的神经网络模型的发展以及不同类型数据集的应用，单目深度估计在性能和效率方面有了显著提升。然而，大多数相关研究集中在特定领域内，特别是在户外场景中的基准测试主要针对城市环境以改善自主驾驶设备，这与果园/葡萄园等农业环境差异巨大。&lt;h4&gt;背景&lt;/h4&gt;单目深度估计是机器人感知中的基础任务，并且该领域的进步依赖于更准确和稳健的神经网络模型的发展以及不同类型数据集的应用。然而，现有的研究大多集中在特定领域内（如城市环境），缺乏针对果园或葡萄园等农业环境的研究。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有单目深度估计方法在果园/葡萄园环境中性能不足的问题，提出一种填补该领域的空白的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的重训练方法，通过监控稠密深度图和稀疏点之间的连贯正则化来改进训练结果。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的 OrchardDepth 方法显著提高了单目相机在果园环境中的度量深度估计性能，将 RMSE 从 1.5337 减少到了 0.6738。&lt;h4&gt;结论&lt;/h4&gt;该研究通过提出一个新的方法和新的数据集填补了现有的单目深度估计模型中关于农业环境的空白，并证明了其有效性和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation is a rudimentary task in robotic perception.Recently, with the development of more accurate and robust neural networkmodels and different types of datasets, monocular depth estimation hassignificantly improved performance and efficiency. However, most of theresearch in this area focuses on very concentrated domains. In particular, mostof the benchmarks in outdoor scenarios belong to urban environments for theimprovement of autonomous driving devices, and these benchmarks have a massivedisparity with the orchard/vineyard environment, which is hardly helpful forresearch in the primary industry. Therefore, we propose OrchardDepth, whichfills the gap in the estimation of the metric depth of the monocular camera inthe orchard/vineyard environment. In addition, we present a new retrainingmethod to improve the training result by monitoring the consistentregularization between dense depth maps and sparse points. Our method improvesthe RMSE of depth estimation in the orchard environment from 1.5337 to 0.6738,proving our method's validation.</description>
      <author>example@mail.com (Zhichao Zheng, Henry Williams, Bruce A MacDonald)</author>
      <guid isPermaLink="false">2502.14279v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for Long-Horizon Embodied Navigation</title>
      <link>http://arxiv.org/abs/2502.14254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，在大型语言模型（LLMs）和视觉-语言模型（VLMs）方面的进展使它们成为具身导航的强大工具，使得代理能够利用常识和空间推理来在不熟悉的环境中高效探索。&lt;h4&gt;背景&lt;/h4&gt;现有的基于LLM的方法将全局记忆，如语义或拓扑地图转换为语言描述以指导导航。这种方法提高了效率并减少了冗余的探索，但是用语言表示方式丢失了几何信息，这阻碍了复杂的环境中的空间推理。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于视觉-语言模型（VLM）的导航框架来解决这些问题，该框架通过从全局记忆模块中自适应检索任务相关的线索，并将其与代理的第一人称观察相结合，从而增强长期任务中的空间推理和决策制定。&lt;h4&gt;方法&lt;/h4&gt;利用动态对齐全局上下文信息与局部感知的技术来提高空间推理和决策的效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在对象导航任务中超越了以前最先进的方法，并为具身导航提供了一个更有效和可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;新的VLM框架通过结合全局记忆信息与第一人称视觉输入的优点，在复杂的导航环境中实现了更加高效和精准的空间推理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) and Vision-LanguageModels (VLMs) have made them powerful tools in embodied navigation, enablingagents to leverage commonsense and spatial reasoning for efficient explorationin unfamiliar environments. Existing LLM-based approaches convert globalmemory, such as semantic or topological maps, into language descriptions toguide navigation. While this improves efficiency and reduces redundantexploration, the loss of geometric information in language-basedrepresentations hinders spatial reasoning, especially in intricateenvironments. To address this, VLM-based approaches directly processego-centric visual inputs to select optimal directions for exploration.However, relying solely on a first-person perspective makes navigation apartially observed decision-making problem, leading to suboptimal decisions incomplex environments. In this paper, we present a novel vision-language model(VLM)-based navigation framework that addresses these challenges by adaptivelyretrieving task-relevant cues from a global memory module and integrating themwith the agent's egocentric observations. By dynamically aligning globalcontextual information with local perception, our approach enhances spatialreasoning and decision-making in long-horizon tasks. Experimental resultsdemonstrate that the proposed method surpasses previous state-of-the-artapproaches in object navigation tasks, providing a more effective and scalablesolution for embodied navigation.</description>
      <author>example@mail.com (Lingfeng Zhang, Yuecheng Liu, Zhanguang Zhang, Matin Aghaei, Yaochen Hu, Hongjian Gu, Mohammad Ali Alomrani, David Gamaliel Arcos Bravo, Raika Karimi, Atia Hamidizadeh, Haoping Xu, Guowei Huang, Zhanpeng Zhang, Tongtong Cao, Weichao Qiu, Xingyue Quan, Jianye Hao, Yuzheng Zhuang, Yingxue Zhang)</author>
      <guid isPermaLink="false">2502.14254v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>No Minima, No Collisions: Combining Modulation and Control Barrier Function Strategies for Feasible Dynamical Collision Avoidance</title>
      <link>http://arxiv.org/abs/2502.14238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了控制栅栏函数二次规划（CBF-QP）和动力学系统调制（Mod-DS）在实时安全关键反应控制系统中的应用，提出了结合两者优点的新方法。&lt;h4&gt;背景&lt;/h4&gt;CBF-QP适用于一般性控制仿射系统但会产生局部极小值；而Mod-DS可以减少甚至避免局部最小值，但在某些约束下难以实现最优解，并且只适用于完全驱动的系统。&lt;h4&gt;目的&lt;/h4&gt;揭示CBF-QP和Mod-DS之间的理论联系并提出一种结合两者优势的新方法来提高实时障碍物规避系统的性能。&lt;h4&gt;方法&lt;/h4&gt;通过数学证明正常调制动力学系统是CBF-QP的一种特殊情况，参考Mod-DS与CBF-QP之间存在一个连接的方程。基于此理论基础，提出了基于Mod的CBF-QP控制器。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的基于Mod的CBF-QP方法能够为控制仿射系统实现局部极小值免费的反应障碍物规避，并在模拟和真实世界实验中表现出了优于传统方法的效果。&lt;h4&gt;结论&lt;/h4&gt;结合CBF-QP与Mod-DS的方法可以有效地解决现有技术的问题，提高系统的安全性和性能。&lt;h4&gt;翻译&lt;/h4&gt;作为重要的实时安全关键响应控制技术，控制屏障函数二次规划(CBF-QPs)适用于一般的控制仿射系统，但会产生局部极小值，并不能确保达到目标。与此相反，动力学系统调制(Mod-DS)，包括常规、参考和在流形上的Mod-DS，可以实现具有很少甚至没有局部最小值的障碍物规避，但在最优地减少受约束与不受约束控制器输出之间的差异方面遇到困难，其应用仅限于完全驱动的系统。我们深入探讨了CBF-QP和Mod-DS的基础理论，并证明尽管它们来自不同的起源，常规Mod-DS是CBF-QP的一种特殊情况，而参考Mod-DS的解决方案通过一个方程与CBF-QP中的解存在数学联系。基于揭示出的CBF-QP和Mod-DS之间的理论联系，我们提出了参考Mod基CBF-QP和在流形上的Mod基CBF-QP控制器来结合这两种方法的优势，并为控制仿射系统实现局部最小值免费的反应障碍物规避。我们在模拟医院环境和使用Ridgeback完全驱动系统的实际世界实验中验证了我们的方法，同时也在Fetch机器人的欠驱动系统中进行了实验。在所有实验中，基于Mod的CBF-QP都超过了传统的CBF-QPs以及我们提出的最优约束执行的Mod-DS方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As prominent real-time safety-critical reactive control techniques, ControlBarrier Function Quadratic Programs (CBF-QPs) work for control affine systemsin general but result in local minima in the generated trajectories andconsequently cannot ensure convergence to the goals. Contrarily, Modulation ofDynamical Systems (Mod-DSs), including normal, reference, and on-manifoldMod-DS, achieve obstacle avoidance with few and even no local minima but havetrouble optimally minimizing the difference between the constrained and theunconstrained controller outputs, and its applications are limited tofully-actuated systems. We dive into the theoretical foundations of CBF-QP andMod-DS, proving that despite their distinct origins, normal Mod-DS is a specialcase of CBF-QP, and reference Mod-DS's solutions are mathematically connectedto that of the CBF-QP through one equation. Building on top of the unveiledtheoretical connections between CBF-QP and Mod-DS, reference Mod-based CBF-QPand on-manifold Mod-based CBF-QP controllers are proposed to combine thestrength of CBF-QP and Mod-DS approaches and realize local-minimum-freereactive obstacle avoidance for control affine systems in general. We validateour methods in both simulated hospital environments and real-world experimentsusing Ridgeback for fully-actuated systems and Fetch robots for underactuatedsystems. Mod-based CBF-QPs outperform CBF-QPs as well as the optimallyconstrained-enforcing Mod-DS approaches we proposed in all experiments.</description>
      <author>example@mail.com (Yifan Xue, Nadia Figueroa)</author>
      <guid isPermaLink="false">2502.14238v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Sampling-based Online Planning for Drone Interception</title>
      <link>http://arxiv.org/abs/2502.14231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICRA 2025. Supplementary video:  https://youtu.be/dDdshfEAZpg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了动态环境中高速在线规划问题，提出了一种基于神经网络的采样式算法来解决时间最优轨迹生成、计算约束以及环境不确定性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中，需要找到符合系统动力学的时间最优路径，并满足实时适应性的计算限制。同时还要考虑来自环境变化带来的不确定性影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够快速探索多种可能的不确定情况下的轨迹选择方法，解决无人机拦截问题中目标预测不完善和碰撞避免的问题。&lt;h4&gt;方法&lt;/h4&gt;采用采样为基础的在线规划算法结合神经网络推理技术来替代耗时的非线性路径优化过程。该算法可以平行生成多个潜在目标位置的轨迹，并评估这些轨迹的时间可达性以选择最优解。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模拟和现实环境中的验证，证明了所提出方法具有高速率在线规划的能力以及在无结构场景中应对不可预测运动变化的良好适应性。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了利用神经网络辅助采样式算法的有效性和可行性，为动态环境中需要快速决策的任务提供了一种新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies high-speed online planning in dynamic environments. Theproblem requires finding time-optimal trajectories that conform to systemdynamics, meeting computational constraints for real-time adaptation, andaccounting for uncertainty from environmental changes. To address thesechallenges, we propose a sampling-based online planning algorithm thatleverages neural network inference to replace time-consuming nonlineartrajectory optimization, enabling rapid exploration of multiple trajectoryoptions under uncertainty. The proposed method is applied to the droneinterception problem, where a defense drone must intercept a target whileavoiding collisions and handling imperfect target predictions. The algorithmefficiently generates trajectories toward multiple potential target dronepositions in parallel. It then assesses trajectory reachability by comparingtraversal times with the target drone's predicted arrival time, ultimatelyselecting the minimum-time reachable trajectory. Through extensive validationin both simulated and real-world environments, we demonstrate our method'scapability for high-rate online planning and its adaptability to unpredictablemovements in unstructured settings.</description>
      <author>example@mail.com (Gilhyun Ryou, Lukas Lao Beyer, Sertac Karaman)</author>
      <guid isPermaLink="false">2502.14231v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Text and Vision: A Multi-View Text-Vision Registration Approach for Cross-Modal Place Recognition</title>
      <link>http://arxiv.org/abs/2502.14195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Text4VPR的方法，用于通过多视图（360度）文本-视觉注册来识别地点。这种方法首次完全利用了语言描述而非单一视角的图像信息。&lt;h4&gt;背景&lt;/h4&gt;移动机器人需要先进的自然语言理解能力以准确地识别位置并执行任务如包裹递送。然而传统的视觉地方识别方法依赖于单视图视觉信息，无法解读人类的语言描述。&lt;h4&gt;目的&lt;/h4&gt;目的是通过提出Text4VPR来克服现有方法的局限性，该方法将文本和图像结合起来，并使用冻结版T5语言模型以及Sinkhorn算法进行处理，以解决基于文本的地方识别任务中的挑战。&lt;h4&gt;方法&lt;/h4&gt;Text4VPR在训练阶段强调单个文本-图像对之间的精确描述。它还使用了级联交叉注意力余弦匹配（CCCA）来解决内部文本和图像组的不一致，并实现了通过语言描述与图像进行精准地点匹配。&lt;h4&gt;主要发现&lt;/h4&gt;Text4VPR方法首次建立了基于文字到图片地方识别任务的一个稳健基线，达到了57%的第一名精度以及92%的前十名精度（在测试集内半径为5米的情况下），这表明从文本描述定位至图像不仅是可行的，还有进一步发展的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;Text4VPR方法展示了将语言和视觉信息结合解决地方识别任务的有效性，并为未来研究提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nuozimiaowu/Text4VPR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots necessitate advanced natural language understandingcapabilities to accurately identify locations and perform tasks such as packagedelivery. However, traditional visual place recognition (VPR) methods relysolely on single-view visual information and cannot interpret human languagedescriptions. To overcome this challenge, we bridge text and vision byproposing a multiview (360{\deg} views of the surroundings) text-visionregistration approach called Text4VPR for place recognition task, which is thefirst method that exclusively utilizes textual descriptions to match a databaseof images. Text4VPR employs the frozen T5 language model to extract globaltextual embeddings. Additionally, it utilizes the Sinkhorn algorithm withtemperature coefficient to assign local tokens to their respective clusters,thereby aggregating visual descriptors from images. During the training stage,Text4VPR emphasizes the alignment between individual text-image pairs forprecise textual description. In the inference stage, Text4VPR uses the CascadedCross-Attention Cosine Alignment (CCCA) to address the internal mismatchbetween text and image groups. Subsequently, Text4VPR performs precisely placematch based on the descriptions of text-image groups. On Street360Loc, thefirst text to image VPR dataset we created, Text4VPR builds a robust baseline,achieving a leading top-1 accuracy of 57% and a leading top-10 accuracy of 92%within a 5-meter radius on the test set, which indicates that localization fromtextual descriptions to images is not only feasible but also holds significantpotential for further advancement, as shown in Figure 1.</description>
      <author>example@mail.com (Tianyi Shang, Zhenyu Li, Pengjie Xu, Jinwei Qiao, Gang Chen, Zihan Ruan, Weijun Hu)</author>
      <guid isPermaLink="false">2502.14195v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>REFLEX Dataset: A Multimodal Dataset of Human Reactions to Robot Failures and Explanations</title>
      <link>http://arxiv.org/abs/2502.14185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted and to appear in the IEEE/ACM Conference on Human Robot  Interaction 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为REFLEX的多模态数据集，该数据集记录了机器人在合作环境中因故障而向人类解释时引发的人类反应。&lt;h4&gt;背景&lt;/h4&gt;当前研究中缺乏对机器人出现故障及其后续解释过程中人类反应的系统性捕捉和分析。&lt;h4&gt;目的&lt;/h4&gt;为了促进对人机交互动态的研究，特别是针对初始失败、解释以及长期互动中的情感演变的探讨。&lt;h4&gt;方法&lt;/h4&gt;构建了一个丰富的数据集，包含了人类对于不同类型故障的反应，并且详细注释了不同的解释层次与策略变化。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集为开发更加稳健、适应性和用户满意的机器人系统提供了支持，这些系统能够在面对如重复性失败等挑战时维持积极的人机合作关系。&lt;h4&gt;结论&lt;/h4&gt;通过提供丰富的人类对不同故障类型的反应注释数据，REFLEX促进了更深入地理解和改善人机交互的机制。&lt;h4&gt;翻译&lt;/h4&gt;这项工作介绍了REFLEX（机器人解释给人类以应对失败和人类表达）：一个全面的多模态数据集，捕捉了合作环境中因机器人故障而引起的人类反应以及后续解释。它旨在促进对人机互动动态的研究，并解决需要研究初始失败、解释及长期互动中这些情感变化的需求。通过提供丰富的注释数据来描述人类对于不同类型的失败、不同的解释层次和策略的变化的响应，该数据集有助于开发更加稳健、适应性更强且满足用户需求的机器人系统，在面对如重复故障等挑战时仍能保持与人类合作者之间的积极关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents REFLEX: Robotic Explanations to FaiLures and HumanEXpressions, a comprehensive multimodal dataset capturing human reactions torobot failures and subsequent explanations in collaborative settings. It aimsto facilitate research into human-robot interaction dynamics, addressing theneed to study reactions to both initial failures and explanations, as well asthe evolution of these reactions in long-term interactions. By providing rich,annotated data on human responses to different types of failures, explanationlevels, and explanation varying strategies, the dataset contributes to thedevelopment of more robust, adaptive, and satisfying robotic systems capable ofmaintaining positive relationships with human collaborators, even duringchallenges like repeated failures.</description>
      <author>example@mail.com (Parag Khanna, Andreas Naoum, Elmira Yadollahi, Mårten Björkman, Christian Smith)</author>
      <guid isPermaLink="false">2502.14185v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>ModSkill: Physical Character Skill Modularization</title>
      <link>http://arxiv.org/abs/2502.14140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新型技能学习框架ModSkill，该框架将复杂的全身运动分解为独立的身体部位的模块化技能。&lt;h4&gt;背景&lt;/h4&gt;人类动作高度多样和动态变化，对模仿学习算法提出了挑战，这些算法旨在泛化控制模拟角色的运动技能。先前的方法通常依赖于全身体控制器来追踪参考动作或统一的全身心态嵌入空间，但难以在更大的运动数据集中进行泛化和扩展。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够处理大规模多样化人体动作并能有效学习模块化技能的新框架。&lt;h4&gt;方法&lt;/h4&gt;引入了ModSkill框架，该框架包括一个技能模块化注意层，将策略观察转换为引导各身体部位低级控制器的模块化技能嵌入。同时提出了一种带有生成适应性采样的主动技能学习方法，使用大规模动作生成模型在挑战性的追踪场景中增强策略学习。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在精确全身影子动作跟踪方面优于现有方法，并且能够为各种目标驱动的任务提供可重复使用的技能嵌入。&lt;h4&gt;结论&lt;/h4&gt;ModSkill框架通过分解复杂的身体运动技能，提高了模仿学习算法的泛化能力，在处理大规模人体动作数据集时表现出了优越性。&lt;h4&gt;翻译&lt;/h4&gt;人类的动作非常多样和动态变化，这对旨在将运动技能泛化到模拟角色控制中的模仿学习算法提出了挑战。先前的方法通常依赖于一个通用的全身体控制器来追踪参考动作或统一的全身心态嵌入空间。然而，在更大规模的数据集中这些方法往往难以实现泛化和扩展。在这项工作中，我们介绍了一种新的技能学习框架ModSkill，它将复杂的全身体运动分解为独立的身体部位模块化的技能。我们的框架包括一个技能模块化注意层，该层处理策略观察并将其转换为引导各身体部位低级控制器的模块化技能嵌入。此外，我们还提出了一种结合生成适应性采样（Generative Adaptive Sampling）的主动技能学习方法，使用大规模动作生成模型在挑战性的追踪场景中增强策略学习。我们的研究结果表明，该框架通过分解成模块化的技能学习并利用生成采样技术，在精确全身影子动作跟踪方面超过了现有的方法，并且能够为多样化目标驱动的任务提供可重复使用的技能嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human motion is highly diverse and dynamic, posing challenges for imitationlearning algorithms that aim to generalize motor skills for controllingsimulated characters. Previous methods typically rely on a universal full-bodycontroller for tracking reference motion (tracking-based model) or a unifiedfull-body skill embedding space (skill embedding). However, these approachesoften struggle to generalize and scale to larger motion datasets. In this work,we introduce a novel skill learning framework, ModSkill, that decouples complexfull-body skills into compositional, modular skills for independent body parts.Our framework features a skill modularization attention layer that processespolicy observations into modular skill embeddings that guide low-levelcontrollers for each body part. We also propose an Active Skill Learningapproach with Generative Adaptive Sampling, using large motion generationmodels to adaptively enhance policy learning in challenging tracking scenarios.Our results show that this modularized skill learning framework, enhanced bygenerative sampling, outperforms existing methods in precise full-body motiontracking and enables reusable skill embeddings for diverse goal-driven tasks.</description>
      <author>example@mail.com (Yiming Huang, Zhiyang Dou, Lingjie Liu)</author>
      <guid isPermaLink="false">2502.14140v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Visual Servoing of Tendon-driven Continuum Robots</title>
      <link>http://arxiv.org/abs/2502.14092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于控制肌腱驱动连续机器人（TDCR）的新型混合视觉伺服系统（HVS）。该方法结合了图像基视觉伺服(IBVS)和深度学习基视觉伺服(DLBVS)，以克服单一方法的局限性，提高整体性能。&lt;h4&gt;背景&lt;/h4&gt;在处理动态、无结构环境中的问题时，传统的IBVS和DLBVS各有优缺点。IBVS具有更高的精度和较快的收敛速度，而DLBVS则对干扰有更强的鲁棒性，并且工作空间更大。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够根据需要平滑过渡于IBVS与DLBVS之间控制方法，以提高处理复杂环境的能力。&lt;h4&gt;方法&lt;/h4&gt;混合视觉伺服系统(HVS)结合了IBVS和DLBVS的优点，通过模拟实验和真实世界测试验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;HVS相较于单独使用DLBVS，在迭代时间、收敛速度、最终误差和性能平滑性方面均有所改进。同时保留了DLBVS在诸如遮挡、光照变化等挑战条件下的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的混合视觉伺服系统能够有效应对复杂多变的环境，展示了比单独使用IBVS或DLBVS更好的综合性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文介绍了一种针对肌腱驱动连续机器人控制的新颖混合视觉伺服（HVS）方法。该HVS系统结合了基于图像的视觉伺服(IBVS)与基于深度学习的视觉伺服(DLBVS)，克服了各自方法的局限性，以提升整体性能。IBVS在特征丰富环境中提供了更高的精度和更快的收敛速度；而DLBVS则增强了对抗干扰的能力，并拥有更大的工作空间。通过使IBVS与DLBVS之间实现平滑转换，所提出的HVS确保了复杂、无结构环境中的有效控制。该方法的有效性已通过仿真及真实世界实验得到验证，展示了相较于单独使用DLBVS时，HVS在减少迭代时间、加快收敛速度、降低最终误差以及改善性能方面的优势，同时保持了DLBVS面对诸如遮挡、光照变化、驱动器噪声和物理冲击等挑战条件下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel Hybrid Visual Servoing (HVS) approach forcontrolling tendon-driven continuum robots (TDCRs). The HVS system combinesImage-Based Visual Servoing (IBVS) with Deep Learning-Based Visual Servoing(DLBVS) to overcome the limitations of each method and improve overallperformance. IBVS offers higher accuracy and faster convergence in feature-richenvironments, while DLBVS enhances robustness against disturbances and offers alarger workspace. By enabling smooth transitions between IBVS and DLBVS, theproposed HVS ensures effective control in dynamic, unstructured environments.The effectiveness of this approach is validated through simulations andreal-world experiments, demonstrating that HVS achieves reduced iteration time,faster convergence, lower final error, and smoother performance compared toDLBVS alone, while maintaining DLBVS's robustness in challenging conditionssuch as occlusions, lighting changes, actuator noise, and physical impacts.</description>
      <author>example@mail.com (Rana Danesh, Farrokh Janabi-Sharifi, Farhad Aghili)</author>
      <guid isPermaLink="false">2502.14092v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.14061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于GDRNPP的快速且可扩展的姿态估计器集合，旨在实现实时应用中速度与精度之间的良好平衡。&lt;h4&gt;背景&lt;/h4&gt;在工业实时反馈应用场景（如质量控制和机器人操作）中，高准确度的姿态估计算法需求仍然非常重要。尽管目前有一些算法提高了姿态估计的速度和准确性，但在动态环境中实现高效计算能力和精确性的平衡仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于GDRNPP的快速、可扩展姿势估计算法集合，以满足或超越当前基准在准确性和鲁棒性方面的表现，特别是在实时场景中的效率-精度权衡问题上进行改进。&lt;h4&gt;方法&lt;/h4&gt;提出了AMIS算法来根据特定应用场景中推理时间和准确性之间的应用特定位平衡选择合适的模型。该研究展示了基于AMIS的模型选择在四个著名的基准数据集（LM-O、YCB-V、T-LESS和ITODD）上的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的AMIS方法可以在不同应用场景之间灵活调整，从而实现实时应用中速度与精度之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;本文通过改进现有的姿态估计算法模型，并提出了新的AMIS方法来优化实时场景中的效率-准确性的权衡，为工业自动化和机器人技术等领域提供了更好的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In industrial applications requiring real-time feedback, such as qualitycontrol and robotic manipulation, the demand for high-speed and accurate poseestimation remains critical. Despite advances improving speed and accuracy inpose estimation, finding a balance between computational efficiency andaccuracy poses significant challenges in dynamic environments. Most currentalgorithms lack scalability in estimation time, especially for diversedatasets, and the state-of-the-art (SOTA) methods are often too slow. Thisstudy focuses on developing a fast and scalable set of pose estimators based onGDRNPP to meet or exceed current benchmarks in accuracy and robustness,particularly addressing the efficiency-accuracy trade-off essential inreal-time scenarios. We propose the AMIS algorithm to tailor the utilized modelaccording to an application-specific trade-off between inference time andaccuracy. We further show the effectiveness of the AMIS-based model choice onfour prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).</description>
      <author>example@mail.com (Zixuan Fang, Thomas Pöllabauer, Tristan Wirth, Sarah Berkei, Volker Knauthe, Arjan Kuijper)</author>
      <guid isPermaLink="false">2502.14061v1</guid>
      <pubDate>Fri, 21 Feb 2025 16:27:06 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Cadastral Boundary from Satellite Images Using U-Net model</title>
      <link>http://arxiv.org/abs/2502.11044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用深度学习方法，采用迁移学习训练具有ResNet34骨干网络的U-Net模型，通过三类语义分割（边界、农田和背景）来检测农地的土地权属界限。&lt;h4&gt;背景&lt;/h4&gt;土地管理中找到农地的土地权属界限是一个关键问题。使用卫星图像和无人机(UAV)图像进行该任务是必要的。&lt;h4&gt;目的&lt;/h4&gt;利用深度学习方法加速并简化从卫星和UAV图像中提取土地权属边界的流程。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习训练具有ResNet34骨干网络的U-Net模型，用于三类语义分割以检测土地权属边界。使用的类别包括“边界”，“农田”以及“背景”。&lt;h4&gt;主要发现&lt;/h4&gt;在伊朗农业地区的两张卫星图像上评估了模型性能，分别得到了88%，75%和81%的精确度、召回率及F值。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明该方法具有良好的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finding the cadastral boundaries of farmlands is a crucial concern for landadministration. Therefore, using deep learning methods to expedite and simplifythe extraction of cadastral boundaries from satellite and unmanned aerialvehicle (UAV) images is critical. In this paper, we employ transfer learning totrain a U-Net model with a ResNet34 backbone to detect cadastral boundariesthrough three-class semantic segmentation: "boundary", "field", and"background". We evaluate the performance on two satellite images fromfarmlands in Iran using "precision", "recall", and "F-score", achieving highvalues of 88%, 75%, and 81%, respectively, which indicate promising results.</description>
      <author>example@mail.com (Neda Rahimpour Anaraki, Maryam Tahmasbi, Saeed Reza Kheradpisheh)</author>
      <guid isPermaLink="false">2502.11044v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
  <item>
      <title>Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2502.12414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally as co-first authors. The  manuscript is 21 pages long and is a work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文探讨了大规模训练的语音基础模型在自动语音识别（ASR）任务中的性能评估挑战。&lt;h4&gt;背景&lt;/h4&gt;现有的传统评价指标如WER和CER无法有效反映转录质量，尤其是伪造输出检测方面的问题。这使得这些模型在诸如医疗、法律及航空等高风险领域中可能隐藏严重错误。&lt;h4&gt;目的&lt;/h4&gt;研究自动语音识别（ASR）模型中的hallucination现象，并引入HER来量化这一问题。&lt;h4&gt;方法&lt;/h4&gt;分析了20个不同的ASR模型，探究分布变化、模型大小和架构对HER的影响。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '高WER可能掩盖低HER，而低WER也可能隐藏危险的hallucinations。', '2': '对抗性合成噪声（如白噪音、音调偏移和时间拉伸）会增加HER。', '3': '分布变化与HER之间有强相关性（α = 0.91）。'}&lt;h4&gt;结论&lt;/h4&gt;建议在评估ASR模型时，不仅要考虑传统的WER等指标，还要结合新的HER指标来更全面地衡量性能，特别是在高风险领域中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech foundation models trained at a massive scale, both in terms of modeland data size, result in robust systems capable of performing multiple speechtasks, including automatic speech recognition (ASR). These models transcendlanguage and domain barriers, yet effectively measuring their performanceremains a challenge. Traditional metrics like word error rate (WER) andcharacter error rate (CER) are commonly used to evaluate ASR performance butoften fail to reflect transcription quality in critical contexts, particularlywhen detecting fabricated outputs. This phenomenon, known as hallucination, isespecially concerning in high-stakes domains such as healthcare, legal, andaviation, where errors can have severe consequences. In our work, we addressthis gap by investigating hallucination in ASR models. We examine how factorssuch as distribution shifts, model size, and model architecture influence thehallucination error rate (HER), a metric we introduce to quantifyhallucinations. Our analysis of 20 ASR models reveals \numinsights~keyinsights: (1) High WERs can mask low hallucination rates, while low WERs mayconceal dangerous hallucinations. (2) Synthetic noise, both adversarial andcommon perturbations like white noise, pitch shift, and time stretching,increase HER. (3) Distribution shift correlates strongly with HER ($\alpha =0.91$). Our findings highlight the importance of incorporating HER alongsidetraditional metrics like WER to better assess ASR model performance,particularly in high-stakes domains.</description>
      <author>example@mail.com (Hanin Atwany, Abdul Waheed, Rita Singh, Monojit Choudhury, Bhiksha Raj)</author>
      <guid isPermaLink="false">2502.12414v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised CP-UNet Framework for Denoising DAS Data with Decay Noise</title>
      <link>http://arxiv.org/abs/2502.13395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;分布式声学传感器(DAS)技术利用光纤电缆检测声信号，提供成本效益高且密集的监测能力。该技术具备多种优势，包括在极端条件下的耐受性、对电磁干扰的免疫性和精确探测能力。&lt;h4&gt;背景&lt;/h4&gt;DAS技术虽然具有诸多优点，但其信噪比(S/N)通常低于地震检波器，并且容易受到随机噪声、突发噪声、水平噪声和长周期噪声的影响。这些噪音可能会降低数据分析中反演和解释的质量。&lt;h4&gt;目的&lt;/h4&gt;为了改善DAS数据中的噪音问题，作者开发了一个基于上下文金字塔模块(Context-Pyramid-UNet, CP-UNet)的无监督学习(UL)网络模型，以抑制DAS数据中的突发噪声和随机噪声。&lt;h4&gt;方法&lt;/h4&gt;该CP-UNet模型利用了编码和解码过程中的Context Pyramid Module来提取特征并重构DAS数据。为了增强浅层与深层特征之间的连接性，在编码和解码部分加入了Connected Module(CM)。在训练过程中，用Layer Normalization(LN)代替常用的Batch Normalization(BN)，以加速模型的收敛速度，并防止梯度爆炸。&lt;h4&gt;主要发现&lt;/h4&gt;该研究提出的CP-UNet网络在二维合成数据和现场数据上都展示了出色的去噪性能，优于传统的去噪方法以及最新的无监督学习框架。&lt;h4&gt;结论&lt;/h4&gt;通过实验结果验证了基于上下文金字塔模块的无监督学习模型具有优秀的噪声抑制能力，能够有效提高DAS数据的质量。&lt;h4&gt;翻译&lt;/h4&gt;分布式声学传感器技术利用光纤电缆来检测声信号，并提供成本效益高、密度大的监测功能。虽然它具有许多优势，例如在极端条件下的抵抗力、对电磁干扰的免疫力以及准确的检测，但它通常表现出比地震检波器更低的信噪比(S/N)，并且容易受到各种噪声的影响，如随机噪声、不规则噪声、水平噪声和长周期噪声。这些减少的S/N可能会影响包含反演和解释的数据分析。虽然人工智能在去噪方面已经展示了出色的能力，但大多数现有方法依赖于监督学习并需要标签数据的支持。为了解决这一问题，我们开发了一个基于Context-Pyramid-UNet (CP-UNet)的无监督学习(UL)网络模型来抑制DAS数据中的不规则和随机噪声。该CP-UNet利用编码和解码过程中的上下文金字塔模块(Context Pyramid Module)提取特征并重构DAS数据。为了增强浅层与深层特征之间的连接性，我们在编码和解码部分加入了Connected Module (CM)。在训练过程中使用Layer Normalization (LN)替代常用的Batch Normalization (BN)，以加速模型的收敛速度，并防止梯度爆炸的发生。我们采用Huber损失作为我们的损失函数，其参数通过实验确定。该网络被应用于二维合成数据和现场数据上。与传统去噪方法以及最新无监督学习框架相比，所提出的去噪方法展示出了更好的噪声抑制性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed acoustic sensor (DAS) technology leverages optical fiber cablesto detect acoustic signals, providing cost-effective and dense monitoringcapabilities. It offers several advantages including resistance to extremeconditions, immunity to electromagnetic interference, and accurate detection.However, DAS typically exhibits a lower signal-to-noise ratio (S/N) compared togeophones and is susceptible to various noise types, such as random noise,erratic noise, level noise, and long-period noise. This reduced S/N cannegatively impact data analyses containing inversion and interpretation. Whileartificial intelligence has demonstrated excellent denoising capabilities, mostexisting methods rely on supervised learning with labeled data, which imposesstringent requirements on the quality of the labels. To address this issue, wedevelop a label-free unsupervised learning (UL) network model based onContext-Pyramid-UNet (CP-UNet) to suppress erratic and random noises in DASdata. The CP-UNet utilizes the Context Pyramid Module in the encoding anddecoding process to extract features and reconstruct the DAS data. To enhancethe connectivity between shallow and deep features, we add a Connected Module(CM) to both encoding and decoding section. Layer Normalization (LN) isutilized to replace the commonly employed Batch Normalization (BN),accelerating the convergence of the model and preventing gradient explosionduring training. Huber-loss is adopted as our loss function whose parametersare experimentally determined. We apply the network to both the 2-D syntheticand filed data. Comparing to traditional denoising methods and the latest ULframework, our proposed method demonstrates superior noise reductionperformance.</description>
      <author>example@mail.com (Tianye Huang, Aopeng Li, Xiang Li, Jing Zhang, Sijing Xian, Qi Zhang, Mingkong Lu, Guodong Chen, Liangming Xiong, Xiangyun Hu)</author>
      <guid isPermaLink="false">2502.13395v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Multi-view Video-Pose Pretraining for Operating Room Surgical Activity Recognition</title>
      <link>http://arxiv.org/abs/2502.13883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无校准多视角多模态预训练框架PreViPS，用于手术活动识别，该框架能够将不同摄像机视图下的2D姿态和视觉嵌入对齐。&lt;h4&gt;背景&lt;/h4&gt;理解复杂手术室中临床医生与环境的交互需要深入理解外科程序的工作流程。现有的手术活动识别（SAR）模型通常无法准确捕捉细微的动作变化或充分利用多视角信息，或者它们需要精确校准的多视图摄像机设置和高级点云处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需多相机标定即可有效进行视频姿态和视觉特征预训练的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PreViPS的新框架。该模型采用CLIP风格的双编码器架构，一个用于处理视觉特性，另一个则负责人类姿态嵌入的生成。为了处理连续2D人体姿势坐标数据，引入了分词后的离散表示法将这些坐标转换为离散姿态嵌入，从而可以在双编码器框架中高效集成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在两个不同手术室数据集上的表现优于强基线模型，并且展示了其在多视图和单视图设置下的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究为复杂手术环境中的SAR任务提供了一种高效、实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;理解复杂的外科手术工作流程需要深入了解临床医生与其操作环境之间的交互作用。手术活动识别（SAR）是一项关键的计算机视觉任务，它从多视角摄像机记录中检测动作或阶段。现有的SAR模型往往无法准确捕捉细微的临床医生动作变化或多视角知识，或者它们需要精确校准的多视角摄像机设置和高级点云处理以获得更好的结果。在这项工作中，我们提出了一种新的无校准多视图多模态预训练框架PreViPS，该框架将不同摄像机视图下的2D姿态与视觉嵌入对齐。我们的模型采用了CLIP风格的双编码器架构：一个编码器处理视觉特征，另一个则用于编码人类姿势嵌入。为了处理连续的2D人体姿态坐标，我们引入了一种分词后的离散表示法，将连续的2D姿态坐标转换为离散的姿态嵌入，从而可以在双编码器框架中高效集成。为了弥合这两种模式之间的差距，我们提出了一些跨模态和同模态几何约束下的预训练目标，并采用掩码姿势令牌预测策略来增强表征学习能力。广泛的实验和消融研究表明，与强大的基线相比有所改进，并且在两个不同的手术室数据集上的数据效率测试进一步突显了该方法的有效性。我们强调这种方法对于多视图和单视图设置中的外科活动识别的益处，展示了其在复杂手术环境中的实际适用性。代码将在以下地址发布：https://github.com/CAMMA-public/PreViPS。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the workflow of surgical procedures in complex operating roomsrequires a deep understanding of the interactions between clinicians and theirenvironment. Surgical activity recognition (SAR) is a key computer vision taskthat detects activities or phases from multi-view camera recordings. ExistingSAR models often fail to account for fine-grained clinician movements andmulti-view knowledge, or they require calibrated multi-view camera setups andadvanced point-cloud processing to obtain better results. In this work, wepropose a novel calibration-free multi-view multi-modal pretraining frameworkcalled Multiview Pretraining for Video-Pose Surgical Activity RecognitionPreViPS, which aligns 2D pose and vision embeddings across camera views. Ourmodel follows CLIP-style dual-encoder architecture: one encoder processesvisual features, while the other encodes human pose embeddings. To handle thecontinuous 2D human pose coordinates, we introduce a tokenized discreterepresentation to convert the continuous 2D pose coordinates into discrete poseembeddings, thereby enabling efficient integration within the dual-encoderframework. To bridge the gap between these two modalities, we propose severalpretraining objectives using cross- and in-modality geometric constraintswithin the embedding space and incorporating masked pose token predictionstrategy to enhance representation learning. Extensive experiments and ablationstudies demonstrate improvements over the strong baselines, whiledata-efficiency experiments on two distinct operating room datasets furtherhighlight the effectiveness of our approach. We highlight the benefits of ourapproach for surgical activity recognition in both multi-view and single-viewsettings, showcasing its practical applicability in complex surgicalenvironments. Code will be made available at:https://github.com/CAMMA-public/PreViPS.</description>
      <author>example@mail.com (Idris Hamoud, Vinkle Srivastav, Muhammad Abdullah Jamal, Didier Mutter, Omid Mohareri, Nicolas Padoy)</author>
      <guid isPermaLink="false">2502.13883v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Toward Robust Non-Transferable Learning: A Survey and Benchmark</title>
      <link>http://arxiv.org/abs/2502.13593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对非可传输学习（NTL）进行了首次全面的综述，并提出了评估NTL性能和鲁棒性的基准测试NLTBench。&lt;h4&gt;背景&lt;/h4&gt;过去几十年的研究主要集中在提高模型泛化能力上，较少关注调节这种泛化。然而，不良对手可以利用模型在未经授权或有害数据上的泛化能力，这可能违反了模型伦理。&lt;h4&gt;目的&lt;/h4&gt;解决现有NTL方法中缺乏全面综述和系统性分析的不足，并提出首个评估NTL性能及鲁棒性的统一框架NLTBench。&lt;h4&gt;方法&lt;/h4&gt;文章首先介绍了NTL的任务设置、通用框架以及评价标准。随后，总结现有的NTL方法并重点讨论了这些方法在面对破坏非可传输机制的各种攻击时所面临的鲁棒性问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用NLTBench进行实验验证，揭示现有NTL方法的局限性，尤其是在抵御不同攻击方面的鲁棒性不足。&lt;h4&gt;结论&lt;/h4&gt;本文还探讨了NTL的实际应用、未来研究方向及挑战，并强调了在实现NTL时需要注意的问题和面临的挑战。&lt;h4&gt;翻译&lt;/h4&gt;过去几十年的研究主要集中在提高模型泛化能力上。但是，这种泛化能力也可能被不良对手利用来造成未经授权或有害数据的使用，从而违背伦理原则。为了解决这个问题，研究人员提出了非可传输学习（NTL）任务，即重塑深度学习模型的泛化能力。尽管已经提出许多方法，但目前仍缺乏全面的综述和系统性分析。因此，本文填补了这一空白，并介绍了首个评估NTL性能及鲁棒性的基准NLTBench，在这个统一框架下进行了详细的实验验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past decades, researchers have primarily focused on improving thegeneralization abilities of models, with limited attention given to regulatingsuch generalization. However, the ability of models to generalize to unintendeddata (e.g., harmful or unauthorized data) can be exploited by maliciousadversaries in unforeseen ways, potentially resulting in violations of modelethics. Non-transferable learning (NTL), a task aimed at reshaping thegeneralization abilities of deep learning models, was proposed to address thesechallenges. While numerous methods have been proposed in this field, acomprehensive review of existing progress and a thorough analysis of currentlimitations remain lacking. In this paper, we bridge this gap by presenting thefirst comprehensive survey on NTL and introducing NTLBench, the first benchmarkto evaluate NTL performance and robustness within a unified framework.Specifically, we first introduce the task settings, general framework, andcriteria of NTL, followed by a summary of NTL approaches. Furthermore, weemphasize the often-overlooked issue of robustness against various attacks thatcan destroy the non-transferable mechanism established by NTL. Experimentsconducted via NTLBench verify the limitations of existing NTL methods inrobustness. Finally, we discuss the practical applications of NTL, along withits future directions and associated challenges.</description>
      <author>example@mail.com (Ziming Hong, Yongli Xiang, Tongliang Liu)</author>
      <guid isPermaLink="false">2502.13593v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Extending the RANGE of Graph Neural Networks: Relaying Attention Nodes for Global Encoding</title>
      <link>http://arxiv.org/abs/2502.13797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;介绍了一种名为RANGE的新框架，该框架旨在解决图神经网络在处理大型分子系统时遇到的信息流瓶颈问题。&lt;h4&gt;背景&lt;/h4&gt;图神经网络(GNNs)被广泛应用于建模物理、社会科学和经济学中的多体相互作用。然而，在模拟大型分子系统的分散力和局部电场变化导致的集体结构变化方面，GNN存在局限性，这使得现有的解决方案在计算成本和可扩展性上面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一种模型无关的方法RANGE框架，以有效地捕捉长距离交互并提高处理大规模分子系统的能力。&lt;h4&gt;方法&lt;/h4&gt;该框架采用了基于注意力的聚合-广播机制，通过引入虚拟节点消息传递来动态地扩大表示，并在计算成本低的情况下显著减少信息流瓶颈问题。&lt;h4&gt;主要发现&lt;/h4&gt;RANGE是第一个将注意和位置编码以及正则化整合到虚拟节点消息传递中的实现方案。这使它能够在捕捉长程相互作用方面表现出色，同时保持较低的计算开销。&lt;h4&gt;结论&lt;/h4&gt;这项工作为下一代机器学习力场奠定了基础，能够准确而有效地模拟大规模分子系统的长距离交互。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）被常规地用于建模分子物理学、社会科学和经济学中的图形系统多体相互作用。然而，由于其固有的局部性，它们在信息流方面可能遭受瓶颈问题，特别是在建模大型分子系统时，这会驱动集体结构变化的分散力和局部电场的变化尤为严重。现有的解决方案面临计算成本及可扩展性的挑战。我们介绍了RANGE模型无关框架，该框架采用基于注意力机制的聚合广播机制，大大减少了信息压缩效应，并以几乎可以忽略不计的计算开销实现了对长程相互作用的精确捕获。值得注意的是，RANGE是首个将注意力机制与位置编码及正则化结合来动态扩展虚拟表示的虚拟节点消息传递实现方案。这项工作为下一代机器学习力场奠定了基础，提供了准确而高效的建模方式以模拟大型分子系统的长程交互。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are routinely used in molecular physics, socialsciences, and economics to model many-body interactions in graph-like systems.However, GNNs are inherently local and can suffer from information flowbottlenecks. This is particularly problematic when modeling large molecularsystems, where dispersion forces and local electric field variations drivecollective structural changes. Existing solutions face challenges related tocomputational cost and scalability. We introduce RANGE, a model-agnosticframework that employs an attention-based aggregation-broadcast mechanism thatsignificantly reduces oversquashing effects, and achieves remarkable accuracyin capturing long-range interactions at a negligible computational cost.Notably, RANGE is the first virtual-node message-passing implementation tointegrate attention with positional encodings and regularization to dynamicallyexpand virtual representations. This work lays the foundation fornext-generation of machine-learned force fields, offering accurate andefficient modeling of long-range interactions for simulating large molecularsystems.</description>
      <author>example@mail.com (Alessandro Caruso, Jacopo Venturin, Lorenzo Giambagli, Edoardo Rolando, Frank Noé, Cecilia Clementi)</author>
      <guid isPermaLink="false">2502.13797v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Machine Learning Performance through Intelligent Data Quality Assessment: An Unsupervised Data-centric Framework</title>
      <link>http://arxiv.org/abs/2502.13198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个智能数据为中心的评估框架，该框架能够识别高质量的数据并提高机器学习系统的性能。&lt;h4&gt;背景&lt;/h4&gt;由于数据量和复杂性的增加，现代数据更容易受到质量低下的影响。这导致在将数据输入到ML管道之前需要进行大量繁琐且耗时的工作来准备和改进数据。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，提出了一种智能的数据为中心的评估框架，用于识别高质量数据并提高机器学习系统的性能。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了质量测量的整理和无监督学习技术，能够区分高质量和低质量的数据。此外，该框架设计为具有灵活性和通用性，可以应用于各种领域和应用。&lt;h4&gt;主要发现&lt;/h4&gt;在实际案例中验证了所提出的框架的有效性，在分析化学领域的实验中，通过三个反义寡核苷酸数据集进行了测试，并咨询了相关领域的专家以确定相关的质量测量并评估框架的结果。结果表明该框架能够识别高质量数据的特性，从而指导高效的实验室实验进行，并提高机器学习系统的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的质量为中心的数据评估框架能够在多种应用场景中有效提升数据质量和机器学习模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;低质量的数据限制了机器学习（ML）的优势并削弱了高性能的ML软件系统。由于数据量和复杂性的增加，现代数据更容易受到质量问题的影响。因此，在将数据输入到ML管道之前需要进行大量繁琐且耗时的工作来准备和改进数据。为了应对这一挑战，我们提出了一种智能的数据为中心的评估框架，该框架能够识别高质量数据并提高机器学习系统的性能。该框架结合了质量测量的整理和无监督学习技术以区分高质量和低质量的数据。此外，该框架设计为具有灵活性和通用性，可以应用于各种领域和应用。为了验证所提出的框架的效果，在分析化学领域的实验中进行了实际案例测试，并通过咨询相关专家评估结果。结果显示，基于数据质量的评估框架能够识别出高质量数据的特点，从而指导实验室高效的实验操作并提高机器学习系统的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Poor data quality limits the advantageous power of Machine Learning (ML) andweakens high-performing ML software systems. Nowadays, data are more prone tothe risk of poor quality due to their increasing volume and complexity.Therefore, tedious and time-consuming work goes into data preparation andimprovement before moving further in the ML pipeline. To address thischallenge, we propose an intelligent data-centric evaluation framework that canidentify high-quality data and improve the performance of an ML system. Theproposed framework combines the curation of quality measurements andunsupervised learning to distinguish high- and low-quality data. The frameworkis designed to integrate flexible and general-purpose methods so that it isdeployed in various domains and applications. To validate the outcomes of thedesigned framework, we implemented it in a real-world use case from the fieldof analytical chemistry, where it is tested on three datasets of anti-senseoligonucleotides. A domain expert is consulted to identify the relevant qualitymeasurements and evaluate the outcomes of the framework. The results show thatthe quality-centric data evaluation framework identifies the characteristics ofhigh-quality data that guide the conduct of efficient laboratory experimentsand consequently improve the performance of the ML system.</description>
      <author>example@mail.com (Manal Rahal, Bestoun S. Ahmed, Gergely Szabados, Torgny Fornstedt, Jorgen Samuelsson)</author>
      <guid isPermaLink="false">2502.13198v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Non-Euclidean Hierarchical Representational Learning using Hyperbolic Graph Neural Networks for Environmental Claim Detection</title>
      <link>http://arxiv.org/abs/2502.13628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络和双曲空间图神经网络作为环境声明检测任务中的轻量级替代方案，证明了这些基于结构化图的方法在保持高性能的同时具有更高的效率、可解释性和计算效率。&lt;h4&gt;背景&lt;/h4&gt;Transformer模型主导着自然语言处理领域的各项任务，但其巨大的计算需求和缺乏透明性给实际应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;探索轻量级且有效的Graph Neural Networks (GNNs) 和Hyperbolic Graph Neural Networks (HGNNs) 作为环境声明检测中的替代方案，并重新定义该问题为图分类问题。&lt;h4&gt;方法&lt;/h4&gt;构造了依赖句法解析图，使用简单的词向量（word2vec）表示节点特征，将依存关系编码到边缘特征中。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这些基于结构化的图模型能够在参数减少30倍的情况下达到与最先进的Transformer模型相当或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了在自然语言处理任务中使用结构化、可解释和计算效率高的图方法的潜力。&lt;h4&gt;翻译&lt;/h4&gt;变压器主导着如情感分析，机器翻译，声明验证等NLP任务，然而它们庞大的计算需求和缺乏透明性阻碍了对高效和透明度要求的应用。在这项工作中，我们探讨了图神经网络（GNNs）和双曲图神经网络（HGNNs）作为环境声明检测中轻量级且有效的替代方案，重新将其定义为一个图形分类问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based models dominate NLP tasks like sentiment analysis, machinetranslation, and claim verification. However, their massive computationaldemands and lack of interpretability pose challenges for real-worldapplications requiring efficiency and transparency. In this work, we exploreGraph Neural Networks (GNNs) and Hyperbolic Graph Neural Networks (HGNNs) aslightweight yet effective alternatives for Environmental Claim Detection,reframing it as a graph classification problem. We construct dependency parsinggraphs to explicitly model syntactic structures, using simple word embeddings(word2vec) for node features with dependency relations encoded as edgefeatures. Our results demonstrate that these graph-based models achievecomparable or superior performance to state-of-the-art transformers while using30x fewer parameters. This efficiency highlights the potential of structured,interpretable, and computationally efficient graph-based approaches.</description>
      <author>example@mail.com (Darpan Aswal, Manjira Sinha)</author>
      <guid isPermaLink="false">2502.13628v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Refining embeddings with fill-tuning: data-efficient generalised performance improvements for materials foundation models</title>
      <link>http://arxiv.org/abs/2502.13886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;预训练基础模型学习的嵌入可以用于广泛的任务，当在特定任务上表现不足时可以通过微调来改进。然而当前的方法会导致对所有分布外任务的表现下降。这项工作提出了一种新的方法'fill-tuning'，生成针对特定下游任务不合适的预训练数据集，并通过粗糙度分析技术改善模型的嵌入表示。&lt;h4&gt;背景&lt;/h4&gt;预训练基础模型在各种下游任务中表现出色，但是它们可能无法准确处理特定的任务而需要微调。传统的微调会导致对未见过的数据的表现下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法'fill-tuning'来生成针对不合适的下游任务的预训练数据集，并通过该方法提高模型在所有下游任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;'fill-tuning' 方法使用粗糙度分析技术识别并改善模型嵌入表示中质量较差的部分，从而有针对性地改进特定领域的性能。&lt;h4&gt;主要发现&lt;/h4&gt;应用 fill-tuning 到多个先进材料基础模型上，在添加仅仅 100 个数据点的情况下实现了所有下游任务表现平均提升接近 1% 的效果。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种在计算成本等于微调的情况下，对预训练基础模型进行整体改进的途径。&lt;h4&gt;翻译&lt;/h4&gt;预训练的基础模型学习到的嵌入可用于多种下游任务。这些嵌入优化了总体性能，如果在特定任务上不够准确，则可以通过微调来提升性能。然而，所有当前的方法都会导致其他未见过数据上的表现下降。在这项工作中我们提出了一种新的方法'fill-tuning'，用于生成针对不适合具体下游任务的预训练基础模型的数据集，而不是旨在纠正嵌入表示中的不良区域。我们展示了粗糙度分析如何应用于潜在空间拓扑结构，并说明了它可以用来推荐最有价值改进嵌入表示的数据点。我们将 fill-tuning 应用到一组最先进的材料基础模型上，这些模型是在 $O(10^9)$ 数据点的基础上训练的，在添加仅 100 条数据的情况下实现了所有下游任务中平均表现提高接近 1% 的效果。该方法提供了一种以与微调相当的计算成本来改进预训练基础模型的方法途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained foundation models learn embeddings that can be used for a widerange of downstream tasks. These embeddings optimise general performance, andif insufficiently accurate at a specific task the model can be fine-tuned toimprove performance. For all current methodologies this operation necessarilydegrades performance on all out-of-distribution tasks. In this work we present'fill-tuning', a novel methodology to generate datasets for continuedpretraining of foundation models that are not suited to a particular downstreamtask, but instead aim to correct poor regions of the embedding. We present theapplication of roughness analysis to latent space topologies and illustrate howit can be used to propose data that will be most valuable to improving theembedding. We apply fill-tuning to a set of state-of-the-art materialsfoundation models trained on $O(10^9)$ data points and show model improvementof almost 1% in all downstream tasks with the addition of only 100 data points.This method provides a route to the general improvement of foundation models atthe computational cost of fine-tuning.</description>
      <author>example@mail.com (Matthew P. Wilson, Edward O. Pyzer-Knapp, Nicolas Galichet, Luke Dicks)</author>
      <guid isPermaLink="false">2502.13886v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Machine Learning Potentials through Transfer Learning across Chemical Elements</title>
      <link>http://arxiv.org/abs/2502.13522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '机器学习势能（MLPs）可以在显著降低计算成本的情况下实现从头算精度的模拟，但其有效性依赖于具有足够化学空间和热力学条件覆盖的大规模数据集。本文提出了在元素之间转移训练潜在能量面的方法。', '背景': 'MLPs的有效性需要大量的数据集来确保在整个化学空间中的稳健泛化，而这些大规模的数据集生成可能非常耗时。', '目的': '探索如何利用较少的数据进行MLPs的训练，特别是在缺乏大量初始数据的情况下。', '方法': '提出了转移学习的方法，即使用已训练好的硅原子MLP模型初始化并加速锗原子MLP模型的训练。', '主要发现': '与从零开始的传统训练相比，转移学习在力预测方面表现更佳，提高了模拟的稳定性，并且温度传递性更好。随着训练数据集的减小，这些优势变得更加明显。', '结论': '跨化学元素的迁移学习是一种开发准确和数值稳定的MLPs的有效技术，尤其是在数据稀少的情况下。', '翻译': '机器学习势能可以以数量级降低的成本实现从头算精度的模拟，但其有效性依赖于具有足够化学空间覆盖的大规模数据集。为此，文章提出了在相似元素之间迁移训练潜在能量面的方法，并通过实验验证了转移学习能够提高力预测准确性和温度传递性，尤其适用于小数据集情况下的模型开发。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine Learning Potentials (MLPs) can enable simulations of ab initioaccuracy at orders of magnitude lower computational cost. However, theireffectiveness hinges on the availability of considerable datasets to ensurerobust generalization across chemical space and thermodynamic conditions. Thegeneration of such datasets can be labor-intensive, highlighting the need forinnovative methods to train MLPs in data-scarce scenarios. Here, we introducetransfer learning of potential energy surfaces between chemically similarelements. Specifically, we leverage the trained MLP for silicon to initializeand expedite the training of an MLP for germanium. Utilizing classical forcefield and ab initio datasets, we demonstrate that transfer learning surpassestraditional training from scratch in force prediction, leading to more stablesimulations and improved temperature transferability. These advantages becomeeven more pronounced as the training dataset size decreases. The out-of-targetproperty analysis shows that transfer learning leads to beneficial butsometimes adversarial effects. Our findings demonstrate that transfer learningacross chemical elements is a promising technique for developing accurate andnumerically stable MLPs, particularly in a data-scarce regime.</description>
      <author>example@mail.com (Sebastien Röcken, Julija Zavadlav)</author>
      <guid isPermaLink="false">2502.13522v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Chain-of-Thought Subspace Meta-Learning for Few-shot Image Captioning with Large Vision and Language Models</title>
      <link>http://arxiv.org/abs/2502.13942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态元学习框架，利用调优提示来连接两个预训练的大规模视觉和语言模型，以解决在少量数据训练时的领域差距问题。&lt;h4&gt;背景&lt;/h4&gt;大规模的视觉和语言预训练模型已经在大量的数据上编码了视觉和语言先验知识，使得生成更自然、更真实的图像和文本变得更加容易。然而，在小样本设置中（即只有非常有限的数据可用于训练），视觉和语言模态之间的领域差距仍然显著。&lt;h4&gt;目的&lt;/h4&gt;为了减轻这个领域差距问题，提出了一种多模态元学习框架来连接两个预训练的大规模视觉和语言模型，并引入一个可调的提示以促进两者的交互。&lt;h4&gt;方法&lt;/h4&gt;在少量样本图像描述任务中，现有的多模态元学习框架采用了一步式提示方案来积累输入图像的视觉特征并指导语言模型。然而，这种策略难以仅通过有限的训练样本生成准确的图像描述。因此，提出了一个链条思维（CoT）元学习方案作为多步骤图像描述程序，更有效地模仿人类如何描述图像，并进一步提出在每个CoT步骤中学习不同的子空间元参数以避免干扰。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在不同数据集上评估的方法优于基线方法，尤其是在少样本设置下的MSCOCO、Flickr8k和Flickr30k三个常用图像描述数据集中表现更为出色。&lt;h4&gt;结论&lt;/h4&gt;所提出的链条思维子空间元学习策略在性能方面超越了基准模型，并且能够更好地处理视觉和语言模态之间的领域差距问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A large-scale vision and language model that has been pretrained on massivedata encodes visual and linguistic prior, which makes it easier to generateimages and language that are more natural and realistic. Despite this, there isstill a significant domain gap between the modalities of vision and language,especially when training data is scarce in few-shot settings, where only verylimited data are available for training. In order to mitigate this issue, amulti-modal meta-learning framework has been proposed to bridge the gap betweentwo frozen pretrained large vision and language models by introducing a tunableprompt connecting these two large models. For few-shot image captioning, theexisting multi-model meta-learning framework utilizes a one-step promptingscheme to accumulate the visual features of input images to guide the languagemodel, which struggles to generate accurate image descriptions with only a fewtraining samples. Instead, we propose a chain-of-thought (CoT) meta-learningscheme as a multi-step image captioning procedure to better imitate how humansdescribe images. In addition, we further propose to learn differentmeta-parameters of the model corresponding to each CoT step in distinctsubspaces to avoid interference. We evaluated our method on three commonly usedimage captioning datasets, i.e., MSCOCO, Flickr8k, and Flickr30k, underfew-shot settings. The results of our experiments indicate that ourchain-of-thought subspace meta-learning strategy is superior to the baselinesin terms of performance across different datasets measured by differentmetrics.</description>
      <author>example@mail.com (Hao Huang, Shuaihang Yuan, Yu Hao, Congcong Wen, Yi Fang)</author>
      <guid isPermaLink="false">2502.13942v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MuDAF: Long-Context Multi-Document Attention Focusing through Contrastive Learning on Attention Heads</title>
      <link>http://arxiv.org/abs/2502.13963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了MuDAF方法来解决大型语言模型在长上下文问答任务中由于输入信息不相关而导致的注意力分散问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型常因输入中的无关信息而表现出注意力分散，严重损害了它们处理长上下文的能力。最近的研究表明检索头在长上下文事实性方面的有效性。&lt;h4&gt;目的&lt;/h4&gt;通过改进检索头直接解决这种分心问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多文档注意聚焦（MuDAF）的新颖方法，该方法通过对比学习显式优化头部级别的注意力分布。&lt;h4&gt;主要发现&lt;/h4&gt;根据实验结果，MuDAF可以显著提高大型语言模型在长上下文问答任务中的表现，特别是在多文档问答场景下。广泛的检索评分和注意可视化评估表明MuDAF具有使注意力头更专注于相关信息并减少注意力分散的潜力。&lt;h4&gt;结论&lt;/h4&gt;MuDAF通过优化头部级别的注意力分布来解决大型语言模型中存在的注意力分散问题，并在长上下文问答任务中显示出显著改善的表现，特别是在多文档问答方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) frequently show distracted attention due toirrelevant information in the input, which severely impairs their long-contextcapabilities. Inspired by recent studies on the effectiveness of retrievalheads in long-context factutality, we aim at addressing this distraction issuethrough improving such retrieval heads directly. We propose Multi-DocumentAttention Focusing (MuDAF), a novel method that explicitly optimizes theattention distribution at the head level through contrastive learning.According to the experimental results, MuDAF can significantly improve thelong-context question answering performance of LLMs, especially inmulti-document question answering. Extensive evaluations on retrieval scoresand attention visualizations show that MuDAF possesses great potential inmaking attention heads more focused on relevant information and reducingattention distractions.</description>
      <author>example@mail.com (Weihao Liu, Ning Wu, Shiping Yang, Wenbiao Ding, Shining Liang, Ming Gong, Dongmei Zhang)</author>
      <guid isPermaLink="false">2502.13963v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Graph Embeddings for Session-based Recommendation with Item Features</title>
      <link>http://arxiv.org/abs/2502.13763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;论文&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合图神经网络和基于会话相似性的推荐算法的新方法——Graph Convolutional Network Extension (GCNext)，该方法通过在图卷积网络中直接集成物品特征来增强现有的序列推荐系统。&lt;h4&gt;背景&lt;/h4&gt;现有最先进的顺序推荐算法主要采用图神经网络建模会话或利用物品特性之间的相似性进行推荐。这些方法要么使用复杂的计算模型，要么依赖于大量的用户行为数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的序列推荐方法GCNext，该方法结合了两种当前主流的推荐技术的优点，通过在图表示中直接整合物品特征来改进会话基线推荐系统。&lt;h4&gt;方法&lt;/h4&gt;GCNext创建一个丰富物品共现图并利用无监督学习方式获取对应的物品嵌入。此外，研究团队还将这种方法与最近邻算法和神经网络模型相结合以验证其效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在三个数据集上将GCNext融入序列推荐算法可以显著提升近似邻居方法以及神经网络模型的性能，并且提高了MRR@20指标值高达12.79%。此外，该技术对于最先进的推荐方法来说易于集成并且具有灵活性。&lt;h4&gt;结论&lt;/h4&gt;通过直接整合物品特征到图卷积网络中的创新性设计，GCNext不仅改进了现有推荐系统的性能还提供了一种新的研究方向和策略用于未来的研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;在基于会话的推荐系统中，预测是根据用户在此会话之前的行动进行的。最先进的顺序推荐算法要么使用图形神经网络来建模图中的会话，要么通过利用物品特征来挖掘会话之间的相似性。本文结合这两种方法并提出了一种新颖的方法Graph Convolutional Network Extension (GCNext)，它直接将项目特性纳入到图表示中。 GCNext创建了一个丰富的共现图，并在无监督的方式下学习对应的物品嵌入。我们在三个数据集上展示了将其融入顺序推荐算法可以显著提升最近邻方法和神经网络模型的性能，我们的灵活扩展易于在最先进的方法中集成并且可提高MRR@20达12.79%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In session-based recommender systems, predictions are based on the user'spreceding behavior in the session. State-of-the-art sequential recommendationalgorithms either use graph neural networks to model sessions in a graph orleverage the similarity of sessions by exploiting item features. In this paper,we combine these two approaches and propose a novel method, Graph ConvolutionalNetwork Extension (GCNext), which incorporates item features directly into thegraph representation via graph convolutional networks. GCNext creates afeature-rich item co-occurrence graph and learns the corresponding itemembeddings in an unsupervised manner. We show on three datasets thatintegrating GCNext into sequential recommendation algorithms significantlyboosts the performance of nearest-neighbor methods as well as neural networkmodels. Our flexible extension is easy to incorporate in state-of-the-artmethods and increases the MRR@20 by up to 12.79%.</description>
      <author>example@mail.com (Andreas Peintner, Marta Moscati, Emilia Parada-Cabaleiro, Markus Schedl, Eva Zangerle)</author>
      <guid isPermaLink="false">2502.13763v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Model Agnostic Social Influence Maximization in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2502.13571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了HIM，一种利用双曲表示学习来估计用户潜在影响力传播的新颖扩散模型无关方法。&lt;h4&gt;背景&lt;/h4&gt;传统影响最大化（IM）问题的方法依赖于具有已知参数的固定扩散模型，这限制了它们在现实场景中的应用。基于图表示的学习方法虽然能够克服这一局限性，但现有的研究建立在欧氏空间上，无法有效捕捉社会影响力分布的潜在层次特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的影响最大化（IM）问题解决方法，以更好地适应现实世界的社会网络。&lt;h4&gt;方法&lt;/h4&gt;HIM包括两个关键组成部分：一是双曲影响力表示模块，它从网络结构和历史影响力激活中编码出有表现力的双曲用户表示；二是自适应种子选择模块，该模块利用学习到的用户表示的位置信息灵活有效地选择种子用户。&lt;h4&gt;主要发现&lt;/h4&gt;在五个网络数据集上的广泛实验表明了HIM方法对于具有未知扩散模型参数的影响最大化问题的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;通过使用双曲空间中的几何属性来反映用户的影响力大小，以及自适应的种子选择模块，HIM能够更准确地预测用户潜在的影响力传播，并在大规模现实世界的社会网络中展现出巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;影响最大化（IM）问题旨在寻找一组具有影响力的用户，以最大限度地扩大他们在社交网络中的影响力。传统的解决方案依赖于固定扩散模型和已知参数，这限制了它们在真实场景中的应用。基于图表示学习的方法虽然能够克服这一局限性，但现有的研究建立在欧氏空间上，无法有效捕捉社会影响力分布的潜在层次特征。为解决这些问题，我们提出了HIM，一种新颖的扩散模型无关方法，利用双曲表示学习从社交传播数据中估计用户潜在的影响传播。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Influence Maximization (IM) problem aims to find a small set ofinfluential users to maximize their influence spread in a social network.Traditional methods rely on fixed diffusion models with known parameters,limiting their generalization to real-world scenarios. In contrast, graphrepresentation learning-based methods have gained wide attention for overcomingthis limitation by learning user representations to capture influencecharacteristics. However, existing studies are built on Euclidean space, whichfails to effectively capture the latent hierarchical features of socialinfluence distribution. As a result, users' influence spread cannot beeffectively measured through the learned representations. To alleviate theselimitations, we propose HIM, a novel diffusion model agnostic method thatleverages hyperbolic representation learning to estimate users' potentialinfluence spread from social propagation data. HIM consists of two keycomponents. First, a hyperbolic influence representation module encodesinfluence spread patterns from network structure and historical influenceactivations into expressive hyperbolic user representations. Hence, theinfluence magnitude of users can be reflected through the geometric propertiesof hyperbolic space, where highly influential users tend to cluster near thespace origin. Second, a novel adaptive seed selection module is developed toflexibly and effectively select seed users using the positional information oflearned user representations. Extensive experiments on five network datasetsdemonstrate the superior effectiveness and efficiency of our method for the IMproblem with unknown diffusion model parameters, highlighting its potential forlarge-scale real-world social networks.</description>
      <author>example@mail.com (Hongliang Qiao)</author>
      <guid isPermaLink="false">2502.13571v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Web Phishing Net (WPN): A scalable machine learning approach for real-time phishing campaign detection</title>
      <link>http://arxiv.org/abs/2502.13171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Intelligent Cybersecurity Conference (ICSC2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;钓鱼攻击是当今最常见的网络攻击类型，被认为是数据泄露的主要源头，并对个人和企业造成重大后果。&lt;h4&gt;背景&lt;/h4&gt;网页基础的钓鱼攻击最为频繁，通过社交媒体帖子或包含链接到钓鱼网站的电子邮件来实施。这些现有的检测方法依赖于监督学习技术，需要大量数据进行训练，具有高计算需求，并且侵犯用户隐私。此外，由于生成式人工智能技术的发展，现有系统对于日益演变的安全威胁缺乏抵抗力。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的学习方法，以解决现有钓鱼URL检测系统的不足，实现快速、可扩展的检测方案，同时保持用户的隐私。&lt;h4&gt;方法&lt;/h4&gt;采用了一种不涉及配对比较的新颖无监督学习方法，能够实时识别完整的钓鱼攻击活动，并且对于使用生成式AI技术创建的目标性更强的钓鱼URL也能有效防御。&lt;h4&gt;主要发现&lt;/h4&gt;该论文所提出的无监督学习方法能够在检测效率和准确性上超越现有解决方案。它可以在没有用户数据的前提下高效地工作，同时仍能提供高准确率的威胁识别。&lt;h4&gt;结论&lt;/h4&gt;这种新颖的方法为应对不断变化的安全环境提供了有力工具，并在保护用户隐私的同时增强了对抗生成式AI驱动钓鱼攻击的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了现今最常见且最具危害性的网络攻击——钓鱼攻击所带来的问题。当前基于监督学习技术的解决方案存在计算需求高、侵犯隐私及抵抗新兴威胁能力弱等问题。论文提出了一个新的无监督方法，旨在提高检测速度和准确性，同时保护用户隐私，并应对由生成式AI驱动的新一轮有针对性的钓鱼URL攻击浪潮。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Phishing is the most prevalent type of cyber-attack today and is recognizedas the leading source of data breaches with significant consequences for bothindividuals and corporations. Web-based phishing attacks are the most frequentwith vectors such as social media posts and emails containing links to phishingURLs that once clicked on render host systems vulnerable to more sinisterattacks. Research efforts to detect phishing URLs have involved the use ofsupervised learning techniques that use large amounts of data to train modelsand have high computational requirements. They also involve analysis offeatures derived from vectors including email contents thus affecting userprivacy. Additionally, they suffer from a lack of resilience against evolutionof threats especially with the advent of generative AI techniques to bypassthese systems as with AI-generated phishing URLs. Unsupervised methods such asclustering techniques have also been used in phishing detection in the past,however, they are at times unscalable due to the use of pair-wise comparisons.They also lack high detection rates while detecting phishing campaigns. In thispaper, we propose an unsupervised learning approach that is not only fast butscalable, as it does not involve pair-wise comparisons. It is able to detectentire campaigns at a time with a high detection rate while preserving userprivacy; this includes the recent surge of campaigns with targeted phishingURLs generated by malicious entities using generative AI techniques.</description>
      <author>example@mail.com (Muhammad Fahad Zia, Sri Harish Kalidass)</author>
      <guid isPermaLink="false">2502.13171v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Performance Evaluation of Sentiment Analysis on Text and Emoji Data Using End-to-End, Transfer Learning, Distributed and Explainable AI Models</title>
      <link>http://arxiv.org/abs/2502.13278v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了使用表情符号进行情感分析和基于文本的情感分类，并采用分布式训练方式提高了模型的效率。&lt;h4&gt;背景&lt;/h4&gt;当前，数字世界中频繁使用表情符号来表达从简单到复杂的思想。因此，在情感分析和定向营销活动中也越来越多地使用它们。&lt;h4&gt;目的&lt;/h4&gt;研究使用不同嵌入模型对推特及Kaggle上的情感数据进行情感分类，并探索分布式训练方法以提高效率。&lt;h4&gt;方法&lt;/h4&gt;{'模型选择': '采用Universal Sentence Encoder (USE) 和Sentence Bidirectional Encoder Representations from Transformers (SBERT)生成句子嵌入，用于训练标准全连接神经网络（NN）和LSTM NN模型。', '数据处理': '对推特文本使用上述嵌入模型进行情感分类。同时，利用表情符号数据集作为验证集来评估模型性能。', '分布式训练': '采用分布式训练方法替代传统单线程模型以提高可扩展性，减少了大约15%的运行时间而不会牺牲准确性。', '解释性AI': '使用Shap算法解释模型行为并检查给定特征集中的潜在偏见。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'情感分类准确度': '对于推特文本的情感分析，全连接NN和LSTM NN模型的分类准确率都在98%左右。', '表情符号验证数据集': '当使用训练集中没有的表情符号作为验证集时，两个模型的准确率都急剧下降到70%左右。'}&lt;h4&gt;结论&lt;/h4&gt;虽然表情符号在情感分析中的准确性存在局限性，但采用分布式训练方法可以提高计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，在当前数字世界中，表情符号被广泛用于表达各种思想，并且在情感分析和定向营销活动中也得到了应用。研究者对Twitter数据及Kaggle上的表情符号数据进行了情感分类，使用了Universal Sentence Encoder (USE) 和Sentence Bidirectional Encoder Representations from Transformers (SBERT)，生成句子嵌入并训练标准全连接神经网络（NN）和LSTM NN模型。对于推特文本的测试集，两种模型的情感分类准确率均约为98%；然而，当验证数据集中包含未出现在训练中的表情符号时，两个模型的准确度大幅下降至70%左右。此外，研究还使用了分布式训练方法来提高模型可扩展性，并通过Shap算法进行了解释性AI的应用，以检查给定特征集上的潜在偏见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.12720/jait.13.2.167-172&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emojis are being frequently used in todays digital world to express fromsimple to complex thoughts more than ever before. Hence, they are also beingused in sentiment analysis and targeted marketing campaigns. In this work, weperformed sentiment analysis of Tweets as well as on emoji dataset from theKaggle. Since tweets are sentences we have used Universal Sentence Encoder(USE) and Sentence Bidirectional Encoder Representations from Transformers(SBERT) end-to-end sentence embedding models to generate the embeddings whichare used to train the Standard fully connected Neural Networks (NN), and LSTMNN models. We observe the text classification accuracy was almost the same forboth the models around 98 percent. On the contrary, when the validation set wasbuilt using emojis that were not present in the training set then the accuracyof both the models reduced drastically to 70 percent. In addition, the modelswere also trained using the distributed training approach instead of atraditional singlethreaded model for better scalability. Using the distributedtraining approach, we were able to reduce the run-time by roughly 15% withoutcompromising on accuracy. Finally, as part of explainable AI the Shap algorithmwas used to explain the model behaviour and check for model biases for thegiven feature set.</description>
      <author>example@mail.com (Sirisha Velampalli, Chandrashekar Muniyappa, Ashutosh Saxena)</author>
      <guid isPermaLink="false">2502.13278v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Helix-mRNA: A Hybrid Foundation Model For Full Sequence mRNA Therapeutics</title>
      <link>http://arxiv.org/abs/2502.13785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Helix-mRNA，一种用于优化mRNA疫苗序列的深度学习模型。该模型通过结构化的状态空间和注意力机制的结合，在处理UTR（非编码区）和编码区域时表现出色。&lt;h4&gt;背景&lt;/h4&gt;基于mRNA的疫苗在制药行业受到高度重视，但mRNA序列中包括编码区和非翻译区在内的各种因素共同决定了疫苗的有效性。当前深度学习模型主要关注于优化编码区而忽略了非翻译区。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时优化mRNA序列中的UTR和编码区域，并且具备高效处理长序列能力的深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;引入了Helix-mRNA，一个结合结构化状态空间和注意力机制的混合模型。该模型使用单核苷酸标记化及密码子分离来保持原始mRNA序列中的生物和结构性信息，在初次预训练之后进行了第二次高质数据预训练以提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;Helix-mRNA在分析UTR和编码区域特性方面超越了现有方法，能够处理比当前技术长六倍的序列且仅使用其他基础模型10%的参数。此外，其预测能力覆盖所有mRNA区域。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种高效的深度学习框架Helix-mRNA用于优化mRNA疫苗序列，它在准确性、效率和数据利用方面都有显著改进，并将源代码与权重开放共享以供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;基于mRNA的疫苗已成为制药业的主要焦点。编码序列以及非翻译区（UTRs）可以强烈影响蛋白质合成的效率、稳定性和降解等特性，这些共同决定了疫苗的效果。然而，优化mRNA序列仍然是一项复杂的挑战。现有的深度学习模型通常仅关注于编码区域的优化，而忽略了UTR。我们提出了Helix-mRNA，这是一种基于结构化的状态空间和注意力机制相结合的方法来解决这些问题。除了初步预训练外，通过高质量数据的二次预训练使模型专业化。采用单核苷酸标记法对mRNA序列进行处理，并分离密码子以确保保留原始mRNA序列中的生物和结构信息。Helix-mRNA在分析UTR和编码区域性质方面超过了现有方法的表现，在仅使用当前基础模型10%参数的情况下，可以处理比目前技术长六倍的序列。该模型具有广泛的预测能力，适用于所有mRNA区段。我们将开放源代码（https://github.com/helicalAI/helical）及模型权重（https://huggingface.co/helical-ai/helix-mRNA）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; mRNA-based vaccines have become a major focus in the pharmaceutical industry.The coding sequence as well as the Untranslated Regions (UTRs) of an mRNA canstrongly influence translation efficiency, stability, degradation, and otherfactors that collectively determine a vaccine's effectiveness. However,optimizing mRNA sequences for those properties remains a complex challenge.Existing deep learning models often focus solely on coding region optimization,overlooking the UTRs. We present Helix-mRNA, a structured state-space-based andattention hybrid model to address these challenges. In addition to a firstpre-training, a second pre-training stage allows us to specialise the modelwith high-quality data. We employ single nucleotide tokenization of mRNAsequences with codon separation, ensuring prior biological and structuralinformation from the original mRNA sequence is not lost. Our model, Helix-mRNA,outperforms existing methods in analysing both UTRs and coding regionproperties. It can process sequences 6x longer than current approaches whileusing only 10% of the parameters of existing foundation models. Its predictivecapabilities extend to all mRNA regions. We open-source the model(https://github.com/helicalAI/helical) and model weights(https://huggingface.co/helical-ai/helix-mRNA).</description>
      <author>example@mail.com (Matthew Wood, Mathieu Klop, Maxime Allard)</author>
      <guid isPermaLink="false">2502.13785v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven Discovery of High Performance Polymer Electrodes for Next-Generation Batteries</title>
      <link>http://arxiv.org/abs/2502.13899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 10 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;使用过渡族金属在电动电池中的应用，面临着锂、钴和镍等关键元素大量消耗的挑战，这些元素对环境造成了显著的影响。为了减少这种影响，用具有氧化还原活性的有机材料替代这些金属是一种有希望的方法，可以将电池的碳足迹降低一个数量级。&lt;h4&gt;背景&lt;/h4&gt;过渡族金属在电动电池中的广泛应用导致了锂、钴和镍等关键元素资源的巨大消耗，这对环境构成了严重挑战。为了减轻这一问题，研究转向寻找新的材料来取代这些金属。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于机器学习的电池信息学框架，以加速并优化具有氧化还原活性的有机材料的选择、优化与设计过程，从而克服其电压和特定容量方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;建立了一个结合数据融合和元学习模型的机器学习框架，该框架能够预测各种有机负极材料和载流子（正极材料）组合下的电池性能参数，包括电压和特定容量。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用先进的机器学习技术和广泛的电池数据库，研究成功地识别并设计出了适合可持续储能技术的候选材料。&lt;h4&gt;结论&lt;/h4&gt;该研究成果为加速具有氧化还原活性有机材料的研究提供了重要的手段，有助于推动更环保、高效的能源存储解决方案的发展。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要是关于探索使用红ox活性有机材料替代过渡族金属在电池中的应用。通过机器学习驱动的方法，研究旨在克服现有材料的局限性，并推进可持续储能技术的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of transition group metals in electric batteries requires extensiveusage of critical elements like lithium, cobalt and nickel, which posessignificant environmental challenges. Replacing these metals with redox-activeorganic materials offers a promising alternative, thereby reducing the carbonfootprint of batteries by one order of magnitude. However, this approach facescritical obstacles, including the limited availability of suitable redox-activeorganic materials and issues such as lower electronic conductivity, voltage,specific capacity, and long-term stability. To overcome the limitations forlower voltage and specific capacity, a machine learning (ML) driven batteryinformatics framework is developed and implemented. This framework utilizes anextensive battery dataset and advanced ML techniques to accelerate and enhancethe identification, optimization, and design of redox-active organic materials.In this contribution, a data-fusion ML coupled meta learning model capable ofpredicting the battery properties, voltage and specific capacity, for variousorganic negative electrodes and charge carriers (positive electrode materials)combinations is presented. The ML models accelerate experimentation, facilitatethe inverse design of battery materials, and identify suitable candidates fromthree extensive material libraries to advance sustainable energy-storagetechnologies.</description>
      <author>example@mail.com (Subhash V. S. Ganti, Lukas Woelfel, Christopher Kuenneth)</author>
      <guid isPermaLink="false">2502.13899v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning-Based privacy metrics in Tabular Synthetic Datasets</title>
      <link>http://arxiv.org/abs/2502.13833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;合成数据作为一种隐私保护技术在医疗和金融等行业中受到关注。为了确保使用合成数据的实际应用中的隐私保障，本文提出了一种对比学习方法，该方法通过将数据嵌入到更具代表性的空间来改进对合成数据集的隐私评估。&lt;h4&gt;背景&lt;/h4&gt;利用合成数据提供保护保证是一个关键问题，尤其是在医疗和金融等敏感行业中。目前有两种主要的方法：基于相似度的方法以及基于攻击的方法。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的对比学习方法以提升合成数据集的隐私评估，并通过实验验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了将数据嵌入到更加代表性的空间中的对比学习方法，使其能够利用直观的距离测量指标来改进对隐私保护度的估计。同时，该研究还比较了基于相似性和攻击的方法在使用和不使用此嵌入技术时的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相对简单且易于实施的隐私评估指标可以与更复杂、专门针对GDPR条件设计的指标一样有效。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种改进合成数据集隐私保护度评估的新方法，并展示了其在多种公共可用数据集上的有效性。这种方法为实际应用中的合成数据分析提供了一个有效的工具。&lt;h4&gt;翻译&lt;/h4&gt;合成数据作为增强隐私的技术，在医疗和金融领域等得到了广泛应用。为了保障将合成数据应用于实践时的隐私安全，研究文献中提出了两种处理表格数据的方法：基于相似度的方法旨在寻找训练数据与合成数据之间的相似性程度；而基于攻击的方法则故意对合成数据集进行攻击，通过成功概率来评估其安全性。本文介绍了一种对比方法，该方法通过将数据嵌入到更具代表性的空间来改善对生成数据隐私保护的评价，从而克服了不同类型和属性的数据面临的障碍，并使得使用直观的距离度量指标成为可能。在一系列公开可用数据集上进行的实验中，我们比较了基于相似性和攻击的方法，在使用与不使用对比学习基嵌入的情况下两种方法的表现情况。我们的结果表明，相对简单且容易实现的隐私评估指标可以像更高级、专门针对GDPR条件设计的隐私模型一样有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthetic data has garnered attention as a Privacy Enhancing Technology (PET)in sectors such as healthcare and finance. When using synthetic data inpractical applications, it is important to provide protection guarantees. Inthe literature, two family of approaches are proposed for tabular data: on theone hand, Similarity-based methods aim at finding the level of similaritybetween training and synthetic data. Indeed, a privacy breach can occur if thegenerated data is consistently too similar or even identical to the train data.On the other hand, Attack-based methods conduce deliberate attacks on syntheticdatasets. The success rates of these attacks reveal how secure the syntheticdatasets are.  In this paper, we introduce a contrastive method that improves privacyassessment of synthetic datasets by embedding the data in a more representativespace. This overcomes obstacles surrounding the multitude of data types andattributes. It also makes the use of intuitive distance metrics possible forsimilarity measurements and as an attack vector. In a series of experimentswith publicly available datasets, we compare the performances ofsimilarity-based and attack-based methods, both with and without use of thecontrastive learning-based embeddings. Our results show that relativelyefficient, easy to implement privacy metrics can perform equally well as moreadvanced metrics explicitly modeling conditions for privacy referred to by theGDPR.</description>
      <author>example@mail.com (Milton Nicolás Plasencia Palacios, Sebastiano Saccani, Gabriele Sgroi, Alexander Boudewijn, Luca Bortolussi)</author>
      <guid isPermaLink="false">2502.13833v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Integrated Sensing and Communication for 6G Holographic Digital Twins</title>
      <link>http://arxiv.org/abs/2502.13352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文探讨了6G网络下全息通信的发展前景，特别是全息数字孪生（HDT）的应用。提出了一个基于感知与通信集成(ISAC)的四层架构来支持低成本、高精度环境数据收集以构建HDT。&lt;h4&gt;背景&lt;/h4&gt;随着6G网络的到来和终端设备分辨率的提升，全息通信逐渐成为可能。HDT是其关键应用之一，能够实时映射和预测物理实体状态，并进行空间信息三维再现。&lt;h4&gt;目的&lt;/h4&gt;提出一种集成感知与通信（ISAC）辅助架构以支持低成本、高精度环境数据收集用于构建HDT。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一个四层架构，通过探索超分辨率技术来增强感知解析度，同时研究多点协作感应在构建HDT中的应用，并详细回顾了四种关键技术：节点选择、多频带合作、协作波束形成和数据融合。&lt;h4&gt;主要发现&lt;/h4&gt;论文提出并分析了几种可以提高全息数字孪生性能的关键技术和方法。其中强调了超分辨率技术和多点协同感应的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文指出了几个未来研究的有趣方向，旨在指导和启发后续的工作。&lt;h4&gt;翻译&lt;/h4&gt;随着6G网络的到来，提供超高带宽和极低延迟，并且终端设备分辨率的提升，全息通信正逐渐成为现实。HDT被认为是全息通信中的关键应用之一，能够为物理实体的状态进行实时映射与预测，并实现空间信息的三维再现。在此背景下，感知与通信集成(ISAC)有望成为一个提供数据源给HDT的关键路径。本文提出了一种基于ISAC辅助四层架构的HDT方案，整合新兴范式和技术以实现低成本、高精度环境数据收集来构建HDT。具体而言，在提高感应分辨率方面，从参数估计和点云构造的角度探讨了超分辨率技术，并专注于多点协作感应在构建HDT中的应用，提供节点选择、多频带合作、协作波束形成和数据融合四种关键技术的全面回顾。最后指出了几个未来研究的方向以指导并启发后续工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of 6G networks, offering ultra-high bandwidth and ultra-lowlatency, coupled with the enhancement of terminal device resolutions,holographic communication is gradually becoming a reality. Holographic digitaltwin (HDT) is considered one of key applications of holographic communication,capable of creating virtual replicas for real-time mapping and prediction ofphysical entity states, and performing three-dimensional reproduction ofspatial information. In this context, integrated sensing and communication(ISAC) is expected to be a crucial pathway for providing data sources to HDT.This paper proposes a four-layer architecture assisted by ISAC for HDT,integrating emerging paradigms and key technologies to achieve low-cost,high-precision environmental data collection for constructing HDT.Specifically, to enhance sensing resolution, we explore super-resolutiontechniques from the perspectives of parameter estimation and point cloudconstruction. Additionally, we focus on multi-point collaborative sensing forconstructing HDT, and provide a comprehensive review of four key techniques:node selection, multi-band collaboration, cooperative beamforming, and datafusion. Finally, we highlight several interesting research directions to guideand inspire future work.</description>
      <author>example@mail.com (Haijun Zhang, Ziyang Zhang, Xiangnan Liu, Wei Li, Haojin Li, Chen Sun)</author>
      <guid isPermaLink="false">2502.13352v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.13656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的句子嵌入生成和精炼的方法，该方法通过控制大规模语言模型（LLMs）在潜在空间中的生成方向来确保语义差异，并结合排名信息对现有句子嵌入模型进行改进。&lt;h4&gt;背景&lt;/h4&gt;对比学习方法在使用如NLI等标注数据集的情况下为许多自然语言处理任务提供了强大的句嵌入，但依赖人工标签限制了可扩展性。最近的研究利用大规模语言模型生成句子对以减少注释需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的控制大规模语言模型生成方向的方法，并结合排名信息来改进现有句子嵌入模型的性能。&lt;h4&gt;方法&lt;/h4&gt;通过控制LLMs在潜在空间中的生成方向，确保语义差异，并引入排名和语义信息来精炼现有的句子嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在适度增加句对合成成本的情况下，该方法达到了新的SOTA（State-of-the-Art）性能水平。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在不显著增加计算成本的前提下提高了句子嵌入的精度和语义区分能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sentence embedding is essential for many NLP tasks, with contrastive learningmethods achieving strong performance using annotated datasets like NLI. Yet,the reliance on manual labels limits scalability. Recent studies leverage largelanguage models (LLMs) to generate sentence pairs, reducing annotationdependency. However, they overlook ranking information crucial for fine-grainedsemantic distinctions. To tackle this challenge, we propose a method forcontrolling the generation direction of LLMs in the latent space. Unlikeunconstrained generation, the controlled approach ensures meaningful semanticdivergence. Then, we refine exist sentence embedding model by integratingranking information and semantic information. Experiments on multiplebenchmarks demonstrate that our method achieves new SOTA performance with amodest cost in ranking sentence synthesis.</description>
      <author>example@mail.com (Liyang He, Chenglong Liu, Rui Li, Zhenya Huang, Shulan Ruan, Jun Zhou, Enhong Chen)</author>
      <guid isPermaLink="false">2502.13656v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Homophily Heterogeneity Matters in Graph Federated Learning: A Spectrum Sharing and Complementing Perspective</title>
      <link>http://arxiv.org/abs/2502.13732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的联邦学习方法FedGSP，该方法通过挖掘图的谱性质来解决图联邦学习中的同质性异质性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的许多方法主要关注于处理节点特征异质性和结构异质性，而忽视了同质性水平在不同客户端之间存在的显著变化，即同质性异质性。这个问题导致局部模型之间的合作效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦学习方法FedGSP，以有效地解决图数据中的同质性异质性问题，并提高各客户端间的协作效率和性能。&lt;h4&gt;方法&lt;/h4&gt;引入谱Graph神经网络(GNN)，并通过挖掘图的谱性质来实现跨客户端共享通用的谱属性(即低频信息)。此外，允许客户端通过获取其缺乏的谱特性（即高频信息）来互补非通用的谱特性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了FedGSP在处理同质性和异质性图数据时的表现优越性，并且在所有异质性数据集上比现有最佳方法平均高出3.28%。&lt;h4&gt;结论&lt;/h4&gt;通过挖掘和利用图形的谱性质，可以有效地解决联邦学习中的同质性异质性问题。FedGSP提供了一种有效的方法来提高各客户端间模型合作的效果。&lt;h4&gt;翻译&lt;/h4&gt;由于异质性是图联邦学习的基本挑战，许多现有方法主要关注于处理节点特征异质性和结构异质性。然而，它们忽视了关键的同质性异质性问题，即不同客户图数据中的同质水平存在显著变化。同质水平表示连接属于同一类别的节点之间的边的比例。由于适应各自的本地同质性，局部模型在不同的客户端之间捕获不一致的频谱特性，这大大减少了合作的有效性。具体来说，在高同质性的图上训练的局部模型倾向于捕捉低频信息，而那些在低同质性的图上训练的局部模型则倾向于捕捉高频信息。为了有效处理同质异质性问题，我们引入了谱Graph神经网络（GNN），并提出了一种通过挖掘图形谱特性进行联邦学习的新方法FedGSP。一方面，我们的提议FedGSP使客户端能够共享通用的频谱属性（即低频信息），从而使所有参与者都能从合作中受益。另一方面，受到理论发现的启发，我们提出的FedGSP允许客户端通过获取它们所缺乏的频谱特征来补充非通用的谱特性（即高频信息），从而获得额外的信息增益。在六种同质性和五种异质性图数据集上的广泛实验表明了我们的方法优于现有的11个最先进的方法。值得注意的是，我们的FedGSP在所有异质性数据集中比第二好的方法平均高出3.28%的性能差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Since heterogeneity presents a fundamental challenge in graph federatedlearning, many existing methods are proposed to deal with node featureheterogeneity and structure heterogeneity. However, they overlook the criticalhomophily heterogeneity, which refers to the substantial variation in homophilylevels across graph data from different clients. The homophily level representsthe proportion of edges connecting nodes that belong to the same class. Due toadapting to their local homophily, local models capture inconsistent spectralproperties across different clients, significantly reducing the effectivenessof collaboration. Specifically, local models trained on graphs with highhomophily tend to capture low-frequency information, whereas local modelstrained on graphs with low homophily tend to capture high-frequencyinformation. To effectively deal with homophily heterophily, we introduce thespectral Graph Neural Network (GNN) and propose a novel Federated learningmethod by mining Graph Spectral Properties (FedGSP). On one hand, our proposedFedGSP enables clients to share generic spectral properties (i.e.,low-frequency information), allowing all clients to benefit throughcollaboration. On the other hand, inspired by our theoretical findings, ourproposed FedGSP allows clients to complement non-generic spectral properties byacquiring the spectral properties they lack (i.e., high-frequency information),thereby obtaining additional information gain. Extensive experiments conductedon six homophilic and five heterophilic graph datasets, across bothnon-overlapping and overlapping settings, validate the superiority of ourmethod over eleven state-of-the-art methods. Notably, our FedGSP outperformsthe second-best method by an average margin of 3.28% on all heterophilicdatasets.</description>
      <author>example@mail.com (Wentao Yu)</author>
      <guid isPermaLink="false">2502.13732v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Democratizing Large Language Model-Based Graph Data Augmentation via Latent Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2502.13555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种黑盒上下文驱动的图数据增强方法，该方法利用大型语言模型（LLM）生成的知识图谱来丰富原始图数据。&lt;h4&gt;背景&lt;/h4&gt;图表示学习中由于图数据稀疏性和噪声问题，需要进行数据增强。现有的大多数增强方法忽视了来自数据集的上下文信息，并且依赖于图结构单一地进行数据增强。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于LLM指导的数据增强方法，以便更好地利用图数据中的上下文知识并提高预测性能和可解释性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用文本提示作为与上下文相关的信息来引导LLM生成知识图谱，并设计了一种动态合并策略以随机地将生成的知识图谱合并到原始图中。同时，提出了一种粒度感知的指令微调模块，根据数据集的不同粒度级别无缝生成文本提示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在各种图学习任务上都优于现有图数据增强方法，并且特别适用于电子健康记录（EHR）等场景。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够最大化地利用上下文知识，从而提升预测性能和可解释性。此方法可以克服现有LLM封闭源代码的问题，使之为更多人所用。&lt;h4&gt;翻译&lt;/h4&gt;为了克服这些限制，我们提出了一个黑盒上下文驱动的图数据增强方法——DemoGraph，在大型语言模型的指导下进行操作。通过使用文本提示作为与上下文相关的信息，我们让大模型生成知识图谱，这使我们可以捕捉到从文本输出中的结构交互。然后，我们在训练过程中设计了一个动态合并策略，随机地将这些由LLM生成的知识图谱整合进原始图中。为了控制增强后的图的稀疏性，我们还开发了一种粒度感知提示策略和指令微调模块，这可以根据数据集的不同粒度级别无缝生成文本提示。在各种图学习任务上的广泛实验验证了我们的方法优于现有的图数据增强方法。特别地，在涉及电子健康记录（EHR）的情境下，我们的方法表现出色，表明其能够充分运用上下文知识，从而提升预测性能和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation is necessary for graph representation learning due to thescarcity and noise present in graph data. Most of the existing augmentationmethods overlook the context information inherited from the dataset as theyrely solely on the graph structure for augmentation. Despite the success ofsome large language model-based (LLM) graph learning methods, they are mostlywhite-box which require access to the weights or latent features from theopen-access LLMs, making them difficult to be democratized for everyone asexisting LLMs are mostly closed-source for commercial considerations. Toovercome these limitations, we propose a black-box context-driven graph dataaugmentation approach, with the guidance of LLMs -- DemoGraph. Leveraging thetext prompt as context-related information, we task the LLM with generatingknowledge graphs (KGs), which allow us to capture the structural interactionsfrom the text outputs. We then design a dynamic merging schema tostochastically integrate the LLM-generated KGs into the original graph duringtraining. To control the sparsity of the augmented graph, we further devise agranularity-aware prompting strategy and an instruction fine-tuning module,which seamlessly generates text prompts according to different granularitylevels of the dataset. Extensive experiments on various graph learning tasksvalidate the effectiveness of our method over existing graph data augmentationmethods. Notably, our approach excels in scenarios involving electronic healthrecords (EHRs), which validates its maximal utilization of contextualknowledge, leading to enhanced predictive performance and interpretability.</description>
      <author>example@mail.com (Yushi Feng, Tsai Hor Chan, Guosheng Yin, Lequan Yu)</author>
      <guid isPermaLink="false">2502.13555v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Towards Invariance to Node Identifiers in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.13660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2411.02271&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的正则化方法，用于增强图神经网络（GNN）对于节点ID不变性的能力，提高了模型的泛化性能。&lt;h4&gt;背景&lt;/h4&gt;消息传递结构导致了图神经网络表达力受限的问题。添加唯一节点标识符可以打破限制表达力的基本对称性。&lt;h4&gt;目的&lt;/h4&gt;解决现有ID框架的关键局限，并提出一种新的方法来实现节点ID不变性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的正则化技术，该技术能有效增强GNN对于节点ID的不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在现实世界和合成任务上，所提出的模型改善了节点ID不变性，进而提高了泛化性能。&lt;h4&gt;结论&lt;/h4&gt;新的正则化方法增强了图神经网络模型对节点标识符变化的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;消息传递图神经网络（GNN）由于其消息传递结构而被认为具有有限的表达力。一种规避这种限制的方法是添加独特的节点标识符，这打破了导致表达力受限的基本对称性。在这项工作中，我们指出了ID框架的关键局限，并提出了解决方案。我们首先观察到最终输出不应依赖于特定的ID。然后显示在实践中这是不成立的，这意味着学习网络并不具备所需的结构属性。可以通过几种方式强制执行节点ID不变性，我们将讨论它们的理论性质。接着我们提出了一种新的正则化方法，有效地增强了对网络中的ID不变性的要求。大量的真实世界和合成任务评估表明，我们的方法显著提高了ID不变性，并且在实践中通常也提升了泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-Passing Graph Neural Networks (GNNs) are known to have limitedexpressive power, due to their message passing structure. One mechanism forcircumventing this limitation is to add unique node identifiers (IDs), whichbreak the symmetries that underlie the expressivity limitation. In this work,we highlight a key limitation of the ID framework, and propose an approach foraddressing it. We begin by observing that the final output of the GNN shouldclearly not depend on the specific IDs used. We then show that in practice thisdoes not hold, and thus the learned network does not possess this desiredstructural property. Such invariance to node IDs may be enforced in severalways, and we discuss their theoretical properties.  We then propose a novel regularization method that effectively enforces IDinvariance to the network. Extensive evaluations on both real-world andsynthetic tasks demonstrate that our approach significantly improves IDinvariance and, in turn, often boosts generalization performance.</description>
      <author>example@mail.com (Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Schonlieb, Ran Gilad-Bachrach, Amir Globerson)</author>
      <guid isPermaLink="false">2502.13660v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>CARE: Confidence-Aware Regression Estimation of building density fine-tuning EO Foundation Models</title>
      <link>http://arxiv.org/abs/2502.13734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Submitted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Confidence-Aware Regression Estimation (CARE)的新模型，用于解决像素级回归任务中的置信度量化和评估问题。&lt;h4&gt;背景&lt;/h4&gt;在深度神经网络的实际应用中，准确地量化和评估信心是非常重要的。然而，在像素级别的回归任务（如建筑密度估计）中，这一方面还没有得到充分的研究。&lt;h4&gt;目的&lt;/h4&gt;开发并验证一种用于解决像素级回归问题的新模型CARE，并展示其相对于其他方法的优势。&lt;h4&gt;方法&lt;/h4&gt;提出了名为Confidence-Aware Regression Estimation (CARE)的模型。该模型可以为回归输出结果计算和分配置信度，从而更好地处理像素级回归任务。&lt;h4&gt;主要发现&lt;/h4&gt;在使用Copernicus Sentinel-2卫星数据进行实验时，显示提出的CARE方法能够成功应用于回归问题，并且其性能优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在解决像素级回归任务的置信度量化和评估方面表现出色，为实际应用中深度神经网络模型的表现改进提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;执行准确的信心量化和评估对于深度神经网络预测故障、提高性能以及增强其在现实世界中的能力至关重要。然而，与分类任务（如语义分割）相比，在像素级回归任务上这方面的问题并没有得到很好的解决。为了应对这一挑战，我们提出并训练了名为Confidence-Aware Regression Estimation (CARE)的模型。该模型计算并分配给回归输出结果信心值，并聚焦于作为地球观测(AI Foundation Model for Earth Observation, EO)下游任务的回归问题。实验结果显示，在估计建筑密度的任务上，所提出的CARE方法可以成功应用于回归问题，并且在Copernicus Sentinel-2卫星数据集上的表现优于其他方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Performing accurate confidence quantification and assessment is important fordeep neural networks to predict their failures, improve their performance andenhance their capabilities in real-world applications, for their practicaldeployment in real life. For pixel-wise regression tasks, confidencequantification and assessment has not been well addressed in the literature, incontrast to classification tasks like semantic segmentation. The softmax outputlayer is not used in deep neural networks that solve pixel-wise regressionproblems. In this paper, to address these problems, we develop, train andevaluate the proposed model Confidence-Aware Regression Estimation (CARE). Ourmodel CARE computes and assigns confidence to regression output results. Wefocus on solving regression problems as downstream tasks of an AI FoundationModel for Earth Observation (EO). We evaluate the proposed model CARE andexperimental results on data from the Copernicus Sentinel-2 satelliteconstellation for estimating the density of buildings show that the proposedmethod can be successfully applied to regression problems. We also show thatour approach outperforms other methods.</description>
      <author>example@mail.com (Nikolaos Dionelis, Jente Bosmans, Nicolas Longépé)</author>
      <guid isPermaLink="false">2502.13734v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Random Forest Autoencoders for Guided Representation Learning</title>
      <link>http://arxiv.org/abs/2502.13257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Random Forest Autoencoders (RF-AE)的新框架，用于解决监督可视化中的扩展性问题。&lt;h4&gt;背景&lt;/h4&gt;长期以来，无监督数据可视化方法已经非常成熟，而基于专家标签指导表示的监督可视化研究相对较少。尽管最近一种基于扩散和随机森林的方法RF-PHATE取得了一些进展，但其缺乏显式映射函数限制了它在大规模数据集和标签稀疏场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效地将新样本纳入现有模型，并保持高准确性和可解释性的框架。&lt;h4&gt;方法&lt;/h4&gt;RF-AE结合了自编码器的灵活性、随机森林的监督学习优势以及RF-PHATE所捕捉到的信息几何特性，形成了一种新的神经网络基础架构。它解决了RF-PHATE在扩展性上的问题并改善了性能。&lt;h4&gt;主要发现&lt;/h4&gt;RF-AE不仅在准确性和可解释性方面优于现有方法和标准内核扩展的RF-PHATE，还具有对超参数选择的鲁棒性和通用性。&lt;h4&gt;结论&lt;/h4&gt;通过利用自编码器、随机森林以及信息几何的优势，RF-AE为监督数据可视化提供了一种新的强大工具。它不仅能解决现存的方法在大规模或标签稀疏场景下的局限性问题，还能提高可视化的质量和实用性。&lt;h4&gt;翻译&lt;/h4&gt;数十年的研究产生了稳健的无监督数据可视化方法，而以专家标签指导表示的监督可视化研究仍然较少，因为大多数监督方法优先考虑分类而非可视化。最近，RF-PHATE，一种利用随机森林和信息几何的基于扩散的流形学习方法，在监督可视化方面取得了显著进展。然而，其缺乏显式映射函数限制了可扩展性和应用于未见数据的能力，对大型数据集和标签稀少场景提出了挑战。为了克服这些局限性，我们引入了一种名为Random Forest Autoencoders (RF-AE)的框架，这是一种基于神经网络的方法，结合了自编码器的灵活性、随机森林的学习优势以及RF-PHATE所捕捉到的信息几何特性。RF-AE使高效的未见数据监督可视化成为可能，并在准确性和可解释性方面超越了包括RF-PHATE的标准内核扩展在内的现有方法。此外，RF-AE对超参数的选择具有鲁棒性，并可以推广应用于任何基于内核的降维方法中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decades of research have produced robust methods for unsupervised datavisualization, yet supervised visualization$\unicode{x2013}$where expert labelsguide representations$\unicode{x2013}$remains underexplored, as most supervisedapproaches prioritize classification over visualization. Recently, RF-PHATE, adiffusion-based manifold learning method leveraging random forests andinformation geometry, marked significant progress in supervised visualization.However, its lack of an explicit mapping function limits scalability andprevents application to unseen data, posing challenges for large datasets andlabel-scarce scenarios. To overcome these limitations, we introduce RandomForest Autoencoders (RF-AE), a neural network-based framework for out-of-samplekernel extension that combines the flexibility of autoencoders with thesupervised learning strengths of random forests and the geometry captured byRF-PHATE. RF-AE enables efficient out-of-sample supervised visualization andoutperforms existing methods, including RF-PHATE's standard kernel extension,in both accuracy and interpretability. Additionally, RF-AE is robust to thechoice of hyper-parameters and generalizes to any kernel-based dimensionalityreduction method.</description>
      <author>example@mail.com (Adrien Aumon, Shuang Ni, Myriam Lizotte, Guy Wolf, Kevin R. Moon, Jake S. Rhodes)</author>
      <guid isPermaLink="false">2502.13257v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Large Language Models for Time Series Modeling via a Novel Parameter-efficient Adaptation Method</title>
      <link>http://arxiv.org/abs/2502.13725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;时间序列建模在许多现实世界的应用中具有重要意义，并且已经被广泛研究。虽然预训练基础模型在自然语言处理和计算机视觉领域取得了显著进展，但在时间序列领域的开发受到数据稀疏性的限制。&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，大型语言模型（LLMs）具备识别复杂令牌序列模式的稳健能力和推理能力。&lt;h4&gt;目的&lt;/h4&gt;为了实现时间序列和自然语言模态之间的高质量平衡，并保持推断效率，本文提出了Time-LlaMA框架。&lt;h4&gt;方法&lt;/h4&gt;首先，通过线性标记机制将时间序列输入转换为令牌嵌入。其次，对齐时间序列令牌嵌入与文本提示。第三，开发了一种动态低秩适应技术（D-LoRA），该技术在Transformer骨干网络的每一层中根据每个时间序列输入动态选择最合适的LoRA模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Time-LlaMA框架提出的改进方法在一系列具有挑战性的现实世界时间序列任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;通过上述方法和创新技术的应用，该研究展示了预训练语言模型在时间序列建模中的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于时间序列建模的重要性和现状，并提出了一个新的框架Time-LlaMA来解决当前文献中存在的问题。该框架包括将时间序列输入转换为令牌嵌入、对齐文本提示和动态低秩适应技术等方法，从而实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series modeling holds significant importance in many real-worldapplications and has been extensively studied. While pre-trained foundationmodels have made impressive strides in the fields of natural languageprocessing (NLP) and computer vision (CV), their development in time seriesdomains has been constrained by data sparsity. A series of recent studies havedemonstrated that large language models (LLMs) possess robust patternrecognition and reasoning abilities over complex sequences of tokens. However,the current literature have yet striked a high-quality balance between (a)effectively aligning the time series and natural language modalities, and (b)keeping the inference efficiency. To address the above issues, we now proposethe Time-LlaMA framework. Time-LlaMA first converts the time series input intotoken embeddings through a linear tokenization mechanism. Second, the timeseries token embeddings are aligned with the text prompts. Third, to furtheradapt the LLM backbone for time series modeling, we have developed a dynamiclow-rank adaptation technique (D-LoRA). D-LoRA dynamically chooses the mostsuitable LoRA modules at each layer of the Transformer backbone for each timeseries input, enhancing the model's predictive capabilities. Our experimentalresults on an extensive collection of challenging real-world time series tasksconfirm that our proposed method achieves the state-of-the-art (SOTA)performance.</description>
      <author>example@mail.com (Juyuan Zhang, Wei Zhu, Jiechao Gao)</author>
      <guid isPermaLink="false">2502.13725v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Uncertain Multi-Objective Recommendation via Orthogonal Meta-Learning Enhanced Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2502.13180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新型推荐系统框架，该框架借鉴了自动驾驶汽车的分类方法，并将其应用于推荐系统的自主性水平上。这个框架旨在提升用户个性化体验的同时减少负面效应如回音室效应。&lt;h4&gt;背景&lt;/h4&gt;传统的推荐系统研究主要关注提高推荐准确率，这往往会带来诸如形成回音室等意外后果，限制用户的互动方式。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个动态的多目标优化方法来响应不同用户的多样化需求（例如准确性、多样性和平等性），促进更加智能和伦理化的个性化推荐体验。&lt;h4&gt;方法&lt;/h4&gt;开发了一个基于贝叶斯优化框架的方法来处理不确定性并捕捉用户在多个目标之间的个人偏好，同时利用正交元学习范式提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了一种有效的方式以根据个体用户的不确定多目标需求进行最优化。&lt;h4&gt;结论&lt;/h4&gt;研究表明新的推荐系统方法能够适应性和集中于用户体验的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RSs) play a crucial role in shaping our digitalinteractions, influencing how we access and engage with information acrossvarious domains. Traditional research has predominantly centered on maximizingrecommendation accuracy, often leading to unintended side effects such as echochambers and constrained user experiences. Drawing inspiration from autonomousdriving, we introduce a novel framework that categorizes RS autonomy into fivedistinct levels, ranging from basic rule-based accuracy-driven systems tobehavior-aware, uncertain multi-objective RSs - where users may have varyingneeds, such as accuracy, diversity, and fairness. In response, we propose anapproach that dynamically identifies and optimizes multiple objectives based onindividual user preferences, fostering more ethical and intelligentuser-centric recommendations. To navigate the uncertainty inherent inmulti-objective RSs, we develop a Bayesian optimization (BO) framework thatcaptures personalized trade-offs between different objectives while accountingfor their uncertain interdependencies. Furthermore, we introduce an orthogonalmeta-learning paradigm to enhance BO efficiency and effectiveness by leveragingshared knowledge across similar tasks and mitigating conflicts among objectivesthrough the discovery of orthogonal information. Finally, extensive empiricalevaluations demonstrate the effectiveness of our method in optimizing uncertainmulti-objectives for individual users, paving the way for more adaptive anduser-focused RSs.</description>
      <author>example@mail.com (Hongxu Wang, Zhu Sun, Yingpeng Du, Lu Zhang, Tiantian He, Yew-Soon Ong)</author>
      <guid isPermaLink="false">2502.13180v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>AS-GCL: Asymmetric Spectral Augmentation on Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.13525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TMM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;图对比学习（GCL）已经成为图结构数据自监督学习的主要方法。然而，现有的GCL方法通常依赖于一致的随机增强，这忽视了它们对谱域内固有结构的影响，从而限制了模型的有效泛化能力。&lt;h4&gt;背景&lt;/h4&gt;图对比学习是一种用于图结构数据的自监督学习方法，通过从各种增强视图中学习鲁棒表示来减少对标记数据的依赖。然而，现有的GCL方法忽视了它们对谱域内固有结构的影响。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的局限性，提出了一种新的范式——AS-GCL，它将不对称光谱增强引入到图对比学习中。&lt;h4&gt;方法&lt;/h4&gt;我们的方法在数据增强、视图编码和对比损失三个关键组成部分上都进行了显著改进。具体来说，在数据增强方面，我们采用了基于谱的增强来最小化谱变异性，并减少噪声；在编码过程中，使用具有不同扩散操作符的参数共享编码器生成多样且抗噪的图视图；对于对比损失，引入了上限损失函数以保持类内和类间距离分布的平衡。&lt;h4&gt;主要发现&lt;/h4&gt;我们是首次利用不对称编码器对谱域中的增强视图进行编码的方法。大量的实验在八种基准数据集上证明了所提出方法的优势。&lt;h4&gt;结论&lt;/h4&gt;所提出的AS-GCL范式通过引入不对称光谱增强和改进的对比损失函数，提高了模型的泛化能力，并在多个节点级任务上的表现优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Graph Contrastive Learning (GCL) has emerged as the foremost approach for self-supervised learning on graph-structured data. GCL reduces reliance on labeled data by learning robust representations from various augmented views. However, existing GCL methods typically depend on consistent stochastic augmentations, which overlook their impact on the intrinsic structure of the spectral domain, thereby limiting the model's ability to generalize effectively. To address these limitations, we propose a novel paradigm called AS-GCL that incorporates asymmetric spectral augmentation for graph contrastive learning. A typical GCL framework consists of three key components: graph data augmentation, view encoding, and contrastive loss. Our method introduces significant enhancements to each of these components. Specifically, for data augmentation, we apply spectral-based augmentation to minimize spectral variations, strengthen structural invariance, and reduce noise. With respect to encoding, we employ parameter-sharing encoders with distinct diffusion operators to generate diverse, noise-resistant graph views. For contrastive loss, we introduce an upper-bound loss function that promotes generalization by maintaining a balanced distribution of intra- and inter-class distance. To our knowledge, we are the first to encode augmentation views of the spectral domain using asymmetric encoders. Extensive experiments on eight benchmark datasets across various node-level tasks demonstrate the advantages of the proposed method.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has emerged as the foremost approach forself-supervised learning on graph-structured data. GCL reduces reliance onlabeled data by learning robust representations from various augmented views.However, existing GCL methods typically depend on consistent stochasticaugmentations, which overlook their impact on the intrinsic structure of thespectral domain, thereby limiting the model's ability to generalizeeffectively. To address these limitations, we propose a novel paradigm calledAS-GCL that incorporates asymmetric spectral augmentation for graph contrastivelearning. A typical GCL framework consists of three key components: graph dataaugmentation, view encoding, and contrastive loss. Our method introducessignificant enhancements to each of these components. Specifically, for dataaugmentation, we apply spectral-based augmentation to minimize spectralvariations, strengthen structural invariance, and reduce noise. With respect toencoding, we employ parameter-sharing encoders with distinct diffusionoperators to generate diverse, noise-resistant graph views. For contrastiveloss, we introduce an upper-bound loss function that promotes generalization bymaintaining a balanced distribution of intra- and inter-class distance. To ourknowledge, we are the first to encode augmentation views of the spectral domainusing asymmetric encoders. Extensive experiments on eight benchmark datasetsacross various node-level tasks demonstrate the advantages of the proposedmethod.</description>
      <author>example@mail.com (Ruyue Liu, Rong Yin, Yong Liu, Xiaoshuai Hao, Haichao Shi, Can Ma, Weiping Wang)</author>
      <guid isPermaLink="false">2502.13525v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable Hypergraph Views</title>
      <link>http://arxiv.org/abs/2502.13277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于超图视角的多模态对比学习框架HyperGCL，该框架通过自适应拓扑增强技术来改进图表示。&lt;h4&gt;背景&lt;/h4&gt;现有Graph Contrastive Learning（GCL）方法依赖于预定义的数据增强方式，在任务相关的信息保留和对不同输入数据的适应性方面存在不足。同时，负样本的选择问题也未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于超图视角的多模态GCL框架HyperGCL，以解决现有模型在图表示改进中的局限性。&lt;h4&gt;方法&lt;/h4&gt;HyperGCL通过联合利用输入图结构和属性信息构造三个不同的超图视图，并使用可学习的自适应拓扑增强技术来优化这些视图。引入特定于视图的编码器来捕捉每个视图的关键特征，同时采用网络感知对比损失定义正负样本。&lt;h4&gt;主要发现&lt;/h4&gt;HyperGCL在基准数据集上的实验结果表明，其在节点分类任务上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过创新地融合了超图和多模态学习策略，在改进图表示方面展示了显著的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Graph Contrastive Learning (GCL) have demonstratedremarkable effectiveness in improving graph representations. However, relyingon predefined augmentations (e.g., node dropping, edge perturbation, attributemasking) may result in the loss of task-relevant information and a lack ofadaptability to diverse input data. Furthermore, the selection of negativesamples remains rarely explored. In this paper, we introduce HyperGCL, a novelmultimodal GCL framework from a hypergraph perspective. HyperGCL constructsthree distinct hypergraph views by jointly utilizing the input graph'sstructure and attributes, enabling a comprehensive integration of multiplemodalities in contrastive learning. A learnable adaptive topology augmentationtechnique enhances these views by preserving important relations and filteringout noise. View-specific encoders capture essential characteristics from eachview, while a network-aware contrastive loss leverages the underlying topologyto define positive and negative samples effectively. Extensive experiments onbenchmark datasets demonstrate that HyperGCL achieves state-of-the-art nodeclassification performance.</description>
      <author>example@mail.com (Khaled Mohammed Saifuddin, Jonathan Shihao Ji, Esra Akbas)</author>
      <guid isPermaLink="false">2502.13277v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>The impact of conformer quality on learned representations of molecular conformer ensembles</title>
      <link>http://arxiv.org/abs/2502.13220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了机器学习模型预测分子构象集合性质时输入的3D构象质量对模型性能的影响。&lt;h4&gt;背景&lt;/h4&gt;训练机器学习模型来预测分子构象集合的性质已成为加速药物类似小分子、反应性有机底物和均相催化剂构象分析的一种流行策略。特别是对于高通量分析，经过训练的代理模型可以帮助规避依赖昂贵构象搜索和几何优化的传统方法。&lt;h4&gt;目的&lt;/h4&gt;研究较低质量的3D构象如何影响对高质量构象性质预测的效果；探讨随机构象的几何优化精度在编码中的重要性；探究包含引发目标属性活性构象的集合对于模型准确性的影响；比较代理模型预测与直接从便宜的构象集合估计性质的方法。&lt;h4&gt;方法&lt;/h4&gt;在基于密度泛函理论优化的构象集合中，研究了Sterimol参数的预测情况。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明3D表示学习模型的表现取决于输入数据的质量。较低质量的3D构象可能无法准确预测高质量构象的特性；随机构象的几何精度对于编码的效果至关重要；当活性构象存在时，能够提高模型的准确性；直接从便宜集合估计性质的方法有时可以与代理模型预测的结果相媲美。&lt;h4&gt;结论&lt;/h4&gt;虽然具体问题的答案会因情况而异，但研究提供了关于3D表示学习模型和构象质量重要性的宝贵见解，并提出了实际考虑因素。&lt;h4&gt;翻译&lt;/h4&gt;训练机器学习模型以预测分子构象集合的性质已成为加速药物类似小分子、反应性有机底物和均相催化剂构象分析的一种流行策略。尤其是高通量分析，经过训练的代理模型可以帮助规避依赖昂贵构象搜索和几何优化的传统方法。在这里，我们质疑所用3D构象质量对预测单一活性构象依赖性质的性能的影响。较低质量的构象能否准确反映高质量构象的性质？随机构象编码时，几何优化精度是否重要？对于将一系列构象作为输入的模型来说，目标属性引发活性构象的存在如何影响准确性？代理模型的预测与从便宜集合中估计性质的方法相比如何？我们在此背景下探讨了基于密度泛函理论优化的构象集合Sterimol参数的预测情况。虽然答案会因具体情况而异，但我们的分析提供了关于3D表示学习模型的重要视角，并提出了实际考虑因素，即何时构象质量很重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training machine learning models to predict properties of molecular conformerensembles is an increasingly popular strategy to accelerate the conformationalanalysis of drug-like small molecules, reactive organic substrates, andhomogeneous catalysts. For high-throughput analyses especially, trainedsurrogate models can help circumvent traditional approaches to conformationalanalysis that rely on expensive conformer searches and geometry optimizations.Here, we question how the performance of surrogate models for predicting 3Dconformer-dependent properties (of a single, active conformer) is affected bythe quality of the 3D conformers used as their input. How well do lower-qualityconformers inform the prediction of properties of higher-quality conformers?Does the fidelity of geometry optimization matter when encoding randomconformers? For models that encode sets of conformers, how does the presence ofthe active conformer that induces the target property affect model accuracy?How do predictions from a surrogate model compare to estimating the propertiesfrom cheap ensembles themselves? We explore these questions in the context ofpredicting Sterimol parameters of conformer ensembles optimized with densityfunctional theory. Although answers will be case-specific, our analyses providea valuable perspective on 3D representation learning models and raise practicalconsiderations regarding when conformer quality matters.</description>
      <author>example@mail.com (Keir Adams, Connor W. Coley)</author>
      <guid isPermaLink="false">2502.13220v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Integration of Agentic AI with 6G Networks for Mission-Critical Applications: Use-case and Challenges</title>
      <link>http://arxiv.org/abs/2502.13476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  FEMA  [https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2]  National Oceanic and Atmospheric Administration  [https://www.ncdc.noaa.gov/stormevents/details.jsp] packages Pytorch  [https://pytorch.org/] RLib [https://docs.ray.io/en/latest/rllib/index.html]  Neo4j [https://neo4j.com/] Apache Kafka [https://kafka.apache.org/]&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新型的代理人工智能（AAI）框架，用于关键任务的安全应用。该框架具有多层架构，并通过详细实现的AAI层将网络基础设施与关键任务应用程序连接起来。&lt;h4&gt;背景&lt;/h4&gt;随着AI技术的进步，特别是基础模型的发展，AI已经成为许多依赖自动化服务交付的应用程序的重要组成部分之一，其中包括对公共安全至关重要的使命级应用。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于代理的人工智能框架用于关键任务应用，以解决传统AI系统中人机交互的问题和在维持情境感知的同时缺乏适应动态条件的能力问题。&lt;h4&gt;方法&lt;/h4&gt;本研究设计了一个具有多层架构的新型AAI框架，并实现了一种新的AAI层，该层连接网络基础设施与关键任务应用程序，使其能够快速分析文本数据并迅速适应环境变化。&lt;h4&gt;主要发现&lt;/h4&gt;初步分析表明，所提出的AAI框架可以将初始响应时间平均减少5.6分钟，警报生成时间平均缩短15.6秒，并且资源分配提高了最多13.4%。此外，它还可以使并发操作数增加40个，从而最多可减少恢复时间至多5.2分钟。&lt;h4&gt;结论&lt;/h4&gt;本文展示了AAI框架在关键任务应用中的有效性及优势，但同时也指出了实施过程中需考虑的一些问题和挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们正处于一个变革的时代，人工智能（AI）的进步，尤其是基础模型的发展，一直在新闻中占据重要位置。AI已经成为许多依赖自动化服务交付的应用程序的重要组成部分之一，其中包括对公共安全至关重要的使命级应用。关键任务型AI应用程序的问题在于人机交互系统及在保持情境感知的同时缺乏适应动态条件的能力。由于代理人工智能（AAI）能够通过上下文分析文本数据并快速适应环境变化，因此最近它得到了广泛关注。在此背景下，本文提出了一种用于关键任务应用的AAI框架。我们提出了一个具有多层架构的新框架来实现AAI，并展示了一个详细的AAI实施，以弥合网络基础设施与关键任务应用程序之间的差距。我们的初步分析表明，AAI平均减少了5.6分钟的初始响应时间，警报生成时间平均缩短了15.6秒，资源分配最多提高了13.4%。我们还展示了AAI方法使并发操作数增加40个，从而最多可减少恢复时间至多5.2分钟。最后，我们强调了一些在实现AAI框架时需要考虑的问题和挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We are in a transformative era, and advances in Artificial Intelligence (AI),especially the foundational models, are constantly in the news. AI has been anintegral part of many applications that rely on automation for servicedelivery, and one of them is mission-critical public safety applications. Theproblem with AI-oriented mission-critical applications is the humanin-the-loopsystem and the lack of adaptability to dynamic conditions while maintainingsituational awareness. Agentic AI (AAI) has gained a lot of attention recentlydue to its ability to analyze textual data through a contextual lens whilequickly adapting to conditions. In this context, this paper proposes an AAIframework for mission-critical applications. We propose a novel framework witha multi-layer architecture to realize the AAI. We also present a detailedimplementation of AAI layer that bridges the gap between network infrastructureand missioncritical applications. Our preliminary analysis shows that the AAIreduces initial response time by 5.6 minutes on average, while alert generationtime is reduced by 15.6 seconds on average and resource allocation is improvedby up to 13.4%. We also show that the AAI methods improve the number ofconcurrent operations by 40, which reduces the recovery time by up to 5.2minutes. Finally, we highlight some of the issues and challenges that need tobe considered when implementing AAI frameworks.</description>
      <author>example@mail.com (Sunder Ali Khowaja, Kapal Dev, Muhammad Salman Pathan, Engin Zeydan, Merouane Debbah)</author>
      <guid isPermaLink="false">2502.13476v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization</title>
      <link>http://arxiv.org/abs/2502.12534v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: see https://theialab.github.io/noksr/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的大规模点云曲面重建方法，通过开发了一个高效的框架将不规则的点云转换为带符号的距离场（Signed Distance Field, SDF）。&lt;h4&gt;背景&lt;/h4&gt;当前基于Transformer架构的方法能够处理点云数据，但需要有效的序列化以保持局部性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的高效框架用于大规模点云曲面重建，并通过序列化方法将点云转换为SDF。&lt;h4&gt;方法&lt;/h4&gt;采用最近的基于Transformer的架构（如PointTransformerV3），该架构能够按保序的方式序列化点云。在预测某一点处的SDF值时，可以利用附近token的有效聚集来快速近似找到邻居。同时，在不同的层级/尺度下序列化点云，并通过非线性地聚合特征来预测SDF值。&lt;h4&gt;主要发现&lt;/h4&gt;跨多个尺度进行聚合对于克服序列化引入的近似误差（即局部邻域中的假阴性）至关重要，这有助于提高重建精度和效率。该框架在准确性和效率上均优于现有方法，在户外数据集上尤其表现出色，尤其是在稀疏网格方法表现不佳的情况下。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架通过结合序列化点云和多尺度特征聚合的方法，实现了前所未有的性能优势，并且具有更简单的实现方式。&lt;h4&gt;翻译&lt;/h4&gt;We present a novel approach to large-scale point cloud surface reconstruction by developing an efficient framework that converts an irregular point cloud into a signed distance field (SDF). Our backbone builds upon recent transformer-based architectures (i.e., PointTransformerV3), that serializes the point cloud into a locality-preserving sequence of tokens. We efficiently predict the SDF value at a point by aggregating nearby tokens, where fast approximate neighbors can be retrieved thanks to the serialization. We serialize the point cloud at different levels/scales, and non-linearly aggregate a feature to predict the SDF value. We show that aggregating across multiple scales is critical to overcome the approximations introduced by the serialization (i.e., false negatives in the neighborhood). Our framework sets the new state-of-the-art in terms of accuracy and efficiency (better or similar performance with half the latency of the best prior method, coupled with a simpler implementation), particularly on outdoor datasets where sparse-grid methods have shown limited performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach to large-scale point cloud surface reconstructionby developing an efficient framework that converts an irregular point cloudinto a signed distance field (SDF). Our backbone builds upon recenttransformer-based architectures (i.e., PointTransformerV3), that serializes thepoint cloud into a locality-preserving sequence of tokens. We efficientlypredict the SDF value at a point by aggregating nearby tokens, where fastapproximate neighbors can be retrieved thanks to the serialization. Weserialize the point cloud at different levels/scales, and non-linearlyaggregate a feature to predict the SDF value. We show that aggregating acrossmultiple scales is critical to overcome the approximations introduced by theserialization (i.e. false negatives in the neighborhood). Our frameworks setsthe new state-of-the-art in terms of accuracy and efficiency (better or similarperformance with half the latency of the best prior method, coupled with asimpler implementation), particularly on outdoor datasets where sparse-gridmethods have shown limited performance.</description>
      <author>example@mail.com (Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi)</author>
      <guid isPermaLink="false">2502.12534v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Are Large Language Models In-Context Graph Learners?</title>
      <link>http://arxiv.org/abs/2502.13562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '大型语言模型（LLMs）在处理各种任务中表现出了出色的上下文推理能力，尤其是在面对非结构化数据时。然而，在处理图形等结构化数据方面存在不足。', '背景': 'LLMs缺乏对非欧几里得结构的理解，导致它们无法有效处理图学习任务中的结构化数据，并且其性能远低于专门的图神经网络（GNNs）。', '目的': '提出一种基于检索增强生成（RAG）过程的概念框架来改进LLMs在图形学习任务中的上下文学习能力。', '方法': '将图形数据的学习过程视为一个查询和从图中检索出背景信息的过程，进而开发了一系列增强LLM性能的RAG框架。', '主要发现': '实验表明这些提出的RAG框架显著提升了LLM在基于图形的任务上的表现，特别是在需要使用预训练的LLM而无需修改或通过API访问的情况下。', '结论': '该方法为改进大型语言模型处理结构化数据的能力提供了一种有效途径。', '翻译': '大型语言模型（LLMs）在各种任务中展示了显著的上下文推理能力，尤其是对于非结构化的输入如语言和图像等。然而，在无额外微调的情况下，它们难以处理图形这样的结构化数据，并且其性能远低于专门用于图学习任务的图神经网络（GNNs）。本文展示了一种通过将基于图的数据的学习看作是检索增强生成（RAG）过程来提升LLM在图学习上的上下文学习能力的方法。一系列实验表明，这些提出的RAG框架能够显著改善LLMs处理图形相关任务的表现，尤其适用于无需修改的预训练LLM或API访问场景中。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated remarkable in-contextreasoning capabilities across a wide range of tasks, particularly withunstructured inputs such as language or images. However, LLMs struggle tohandle structured data, such as graphs, due to their lack of understanding ofnon-Euclidean structures. As a result, without additional fine-tuning, theirperformance significantly lags behind that of graph neural networks (GNNs) ingraph learning tasks. In this paper, we show that learning on graph data can beconceptualized as a retrieval-augmented generation (RAG) process, wherespecific instances (e.g., nodes or edges) act as queries, and the graph itselfserves as the retrieved context. Building on this insight, we propose a seriesof RAG frameworks to enhance the in-context learning capabilities of LLMs forgraph learning tasks. Comprehensive evaluations demonstrate that our proposedRAG frameworks significantly improve LLM performance on graph-based tasks,particularly in scenarios where a pretrained LLM must be used withoutmodification or accessed via an API.</description>
      <author>example@mail.com (Jintang Li, Ruofan Wu, Yuchang Zhu, Huizhe Zhang, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2502.13562v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Some Insights of Construction of Feature Graph to Learn Pairwise Feature Interactions with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.13471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the draft before submitting to any journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了特征交互在图神经网络（GNN）模型中的重要性，通过实验揭示了有效的特征交互建模需要保留相互作用的特征之间的边缘，并避免非交互边缘带来的噪音。&lt;h4&gt;背景&lt;/h4&gt;特征交互对于预测机器学习模型至关重要，因为它捕捉到了影响模型性能的特征之间关系。此工作关注成对交互并研究其在构建用于GNN的特征图中的重要性。&lt;h4&gt;目的&lt;/h4&gt;利用现有的GNN模型和工具来探索特征图结构与其建模交互有效性的关系，并提供稀疏特征选择的理论支持。&lt;h4&gt;方法&lt;/h4&gt;通过对合成数据集进行实验，研究了边缘对GNN在建模特征交互上的影响。使用MDL原理来证明保持必要相互作用边界的特征图比完全图更高效且可解释性更强。&lt;h4&gt;主要发现&lt;/h4&gt;1. 互作用特征之间的边对于有效建模特征交互是重要的。2. 包含非互动边缘会引入噪音，降低模型性能。3. 使用MDL原理可以有效地选择稀疏的特征图。&lt;h4&gt;结论&lt;/h4&gt;研究结果提供了有关设计能够提高GNN模型性能和可解释性的特征图的理论见解和实用指南。&lt;h4&gt;翻译&lt;/h4&gt;特性交互在预测机器学习模型中至关重要，因为它捕获了影响模型性能的特性之间的关系。在这项工作中，我们专注于成对互动，并探讨其在为图神经网络（GNN）构建特征图中的重要性。我们并没有提出新的方法，而是利用现有的GNN模型和工具来探索特征图结构及其建模交互的有效性的关系。通过合成数据集上的实验，我们发现相互作用的特性之间的边缘对于使GNN能够有效建模特性互动是重要的。我们也观察到包括非互动边可以作为噪音降低模型性能。此外，我们使用最小描述长度（MDL）原则提供了稀疏特征图选择的理论依据。我们证明了只保留必要交互边界的特征图比完整图更高效且可解释性更强，这与奥卡姆剃刀原理一致。我们的发现为设计改进GNN模型性能和可解释性的特征图提供理论见解和实用指南。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feature interaction is crucial in predictive machine learning models, as itcaptures the relationships between features that influence model performance.In this work, we focus on pairwise interactions and investigate theirimportance in constructing feature graphs for Graph Neural Networks (GNNs).Rather than proposing new methods, we leverage existing GNN models and tools toexplore the relationship between feature graph structures and theireffectiveness in modeling interactions. Through experiments on synthesizeddatasets, we uncover that edges between interacting features are important forenabling GNNs to model feature interactions effectively. We also observe thatincluding non-interaction edges can act as noise, degrading model performance.Furthermore, we provide theoretical support for sparse feature graph selectionusing the Minimum Description Length (MDL) principle. We prove that featuregraphs retaining only necessary interaction edges yield a more efficient andinterpretable representation than complete graphs, aligning with Occam's Razor.  Our findings offer both theoretical insights and practical guidelines fordesigning feature graphs that improve the performance and interpretability ofGNN models.</description>
      <author>example@mail.com (Phaphontee Yamchote, Saw Nay Htet Win, Chainarong Amornbunchornvej, Thanapon Noraset)</author>
      <guid isPermaLink="false">2502.13471v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>How Expressive are Knowledge Graph Foundation Models?</title>
      <link>http://arxiv.org/abs/2502.13339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文对知识图谱基础模型（KGFMs）的表达能力进行了严格的理论研究，揭示了其在处理不同关系词汇的新知识图谱时具有的泛化能力，并发现最典型的学习动机是二元性的，这限制了模型的表现力。设计并验证了使用更丰富的学习动机构建的KGFMs可以提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;知识图谱基础模型（KGFMs）在深度学习领域的知识图谱处理中具有前沿地位，能够对全新的、关系词汇不同的知识图谱进行泛化处理。然而尽管其实验效果良好，对其理论理解仍十分有限。&lt;h4&gt;目的&lt;/h4&gt;探讨并明确KGFMs的表达能力及其依赖的学习动机的关系，提出使用更丰富动机设计更具表现力的KGFMs，并通过实证研究验证这些理论发现。&lt;h4&gt;方法&lt;/h4&gt;首先分析现有文献中典型的学习动机（二元性），然后设计基于三元关系交互来学习关系表示的更加丰富的学习动机，并构建相应的KGFMs。进行广泛的实验，以测试和验证不同的模型在不同领域的数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;KGFMs的表现力直接依赖于用于学习关系表示的学习动机。二元性动机限制了表现力；基于三元关系交互的更丰富的动机可以提高模型的表现能力。&lt;h4&gt;结论&lt;/h4&gt;使用更丰富和复杂动机设计的知识图谱基础模型能够显著提升在各种领域数据集上的性能，这为KGFMs的设计提供了新的理论指导。&lt;h4&gt;翻译&lt;/h4&gt;Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep learning on knowledge graphs, as they can generalize to completely novel knowledge graphs with different relational vocabularies. Despite their empirical success, our theoretical understanding of KGFMs remains very limited. In this paper, we conduct a rigorous study of the expressive power of KGFMs. Specifically, we show that the expressive power of KGFMs directly depends on the motifs used for learning relation representations. We then observe that the most typical motifs used in existing literature are binary, as the representations are learned based on how pairs of relations interact, which limits model expressiveness. As part of our study, we design more expressive KGFMs using richer motifs, necessitating learning relation representations based on how triples of relations interact with each other. Finally, we empirically validate our theoretical findings, showing that the use of richer motifs results in better performance on a wide range of datasets drawn from different domains.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge Graph Foundation Models (KGFMs) are at the frontier for deeplearning on knowledge graphs (KGs), as they can generalize to completely novelknowledge graphs with different relational vocabularies. Despite theirempirical success, our theoretical understanding of KGFMs remains very limited.In this paper, we conduct a rigorous study of the expressive power of KGFMs.Specifically, we show that the expressive power of KGFMs directly depends onthe motifs that are used to learn the relation representations. We then observethat the most typical motifs used in the existing literature are binary, as therepresentations are learned based on how pairs of relations interact, whichlimits the model's expressiveness. As part of our study, we design moreexpressive KGFMs using richer motifs, which necessitate learning relationrepresentations based on, e.g., how triples of relations interact with eachother. Finally, we empirically validate our theoretical findings, showing thatthe use of richer motifs results in better performance on a wide range ofdatasets drawn from different domains.</description>
      <author>example@mail.com (Xingyue Huang, Pablo Barceló, Michael M. Bronstein, İsmail İlkan Ceylan, Mikhail Galkin, Juan L Reutter, Miguel Romero Orth)</author>
      <guid isPermaLink="false">2502.13339v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fusing Point Cloud and Visual Representations for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.12320v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的模仿学习方法FPV-Net，该方法能够有效地结合点云和RGB图像的优点，在复杂的RoboCasa基准测试中取得了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;手动操作的学习需要使用可以访问丰富的感官信息（如点云或RGB图象）的策略。点云在捕获几何结构方面非常有效，而RGB图像则提供了重要的纹理和语义信息。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法将2D图像特征映射到点云时丢失全局上下文信息的问题，提出了一种新的模仿学习方法FPV-Net。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用自适应层范数条件化使点云编码器依赖于全局和局部图象令牌，从而结合了两种模态的优点。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在复杂基准测试中，仅依靠单一模式存在局限性，并且FPV-Net在所有任务上都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过有效融合点云和RGB图像的优势解决了现有技术的不足，展示了其广泛的适用性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习需要使用具有丰富感觉信息（如点云或RGB图象）访问策略。点云有效地捕获几何结构，在模拟学习中的操作任务中至关重要。相比之下，RGB图象提供重要的纹理和语义信息，对于某些任务来说是必不可少的。现有融合两种模态的方法将2D图像特征分配给点云，但往往会丢失原始图像的整体上下文信息。在本文工作中，我们提出了FPV-Net，这是一种新的模仿学习方法，有效结合了点云和RGB模式的优点。我们的方法通过使用自适应层范数条件化使点云编码器依赖于全局和局部图象令牌来利用两种模式的有利特性。在具有挑战性的RoboCasa基准测试中进行广泛的实验表明，在复杂任务中仅依靠一种模态存在局限性，并且我们证明了该方法在整个任务上都达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning for manipulation requires using policies that have access to richsensory information such as point clouds or RGB images. Point cloudsefficiently capture geometric structures, making them essential formanipulation tasks in imitation learning. In contrast, RGB images provide richtexture and semantic information that can be crucial for certain tasks.Existing approaches for fusing both modalities assign 2D image features topoint clouds. However, such approaches often lose global contextual informationfrom the original images. In this work, we propose FPV-Net, a novel imitationlearning method that effectively combines the strengths of both point cloud andRGB modalities. Our method conditions the point-cloud encoder on global andlocal image tokens using adaptive layer norm conditioning, leveraging thebeneficial properties of both modalities. Through extensive experiments on thechallenging RoboCasa benchmark, we demonstrate the limitations of relying oneither modality alone and show that our method achieves state-of-the-artperformance across all tasks.</description>
      <author>example@mail.com (Atalay Donat, Xiaogang Jia, Xi Huang, Aleksandar Taranovic, Denis Blessing, Ge Li, Hongyi Zhou, Hanyi Zhang, Rudolf Lioutikov, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.12320v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>K-Paths: Reasoning over Graph Paths for Drug Repurposing and Drug Interaction Prediction</title>
      <link>http://arxiv.org/abs/2502.13344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;K-Paths 是一种从大规模生物医学知识图谱中提取结构化、多样性和生物学意义路径的检索框架，该框架可促进大语言模型和图神经网络有效预测未观察到的药物间及药物与疾病间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;药物发现是一个复杂且耗时的过程，需要识别和验证新的治疗候选者。利用大规模生物医学知识图谱（KGs）的计算方法为加速这一过程提供了可能的解决方案，但从中提取有意义的信息仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以与大语言模型和其他模型兼容的方法来从大规模 KGs 中提取结构化路径，并提高药物再定位和相互作用严重性预测的零样本性能。&lt;h4&gt;方法&lt;/h4&gt;K-Paths 框架利用 Yen 算法的一种多样性感知变体，检索查询中实体之间的 K 条最短无环路径，优先考虑生物学相关的多样关系。将这些路径转换为结构化格式以供大语言模型直接处理。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集上的实验表明，K-Paths 能够显著提高 Llama 8.1B 和 Llama 70B 的 F1 分数，在药物再定位和相互作用严重性预测中分别提高了12.45分和6.18分。此外，它还能有效降低知识图谱的规模并维持强大的预测性能。&lt;h4&gt;结论&lt;/h4&gt;K-Paths 提供了一种连接 KGs 和 LLM 的新方法，为药物发现提供了可解释的基础，并且在提高零样本性能的同时也提高了监督训练效率。&lt;h4&gt;翻译&lt;/h4&gt;药物发现是一个复杂和耗时的过程，需要识别和验证新的治疗候选者。计算方法利用大规模生物医学知识图谱（KGs）作为解决方案来加速这一过程显示出巨大潜力，但挑战在于如何从这些复杂的图结构中提取有意义的信息。现有的基于子图的方法主要针对图神经网络设计，导致它们与大语言模型等其他类型模型不兼容。为此，我们提出了一种名为 K-Paths 的检索框架，它可以从 KGs 中抽取结构化、多样化且生物上具有意义的路径，并让这些路径便于大语言模型和 GNN 用于预测未观察到的药物相互作用及药物与疾病之间的关系。与其他传统的基于路径排名的方法不同，K-Paths 检索并转换路径以一种大语言模型可以直接处理的形式呈现出来，从而实现可解释性推理。该方法利用了一种改进的 Yen 算法来优先考虑生物学相关的多样化的关联，并检索查询实体间 K 条最短无环路径。实验结果表明，在药物再定位和相互作用严重程度预测任务上，K-Paths 显著提升了零样本性能。此外，对于监督学习任务，它还能显著提高训练效率并保持强大的预测效果。这些特性表明 K-Paths 是一种高效的数据驱动药物发现工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery is a complex and time-intensive process that requiresidentifying and validating new therapeutic candidates. Computational approachesusing large-scale biomedical knowledge graphs (KGs) offer a promising solutionto accelerate this process. However, extracting meaningful insights fromlarge-scale KGs remains challenging due to the complexity of graph traversal.Existing subgraph-based methods are tailored to graph neural networks (GNNs),making them incompatible with other models, such as large language models(LLMs). We introduce K-Paths, a retrieval framework that extracts structured,diverse, and biologically meaningful paths from KGs. Integrating these pathsenables LLMs and GNNs to effectively predict unobserved drug-drug anddrug-disease interactions. Unlike traditional path-ranking approaches, K-Pathsretrieves and transforms paths into a structured format that LLMs can directlyprocess, facilitating explainable reasoning. K-Paths employs a diversity-awareadaptation of Yen's algorithm to retrieve the K shortest loopless paths betweenentities in an interaction query, prioritizing biologically relevant anddiverse relationships. Our experiments on benchmark datasets show that K-Pathsimproves the zero-shot performance of Llama 8.1B's F1-score by 12.45 points ondrug repurposing and 13.42 points on interaction severity prediction. We alsoshow that Llama 70B achieves F1-score gains of 6.18 and 8.46 points,respectively. K-Paths also improves the supervised training efficiency ofEmerGNN, a state-of-the-art GNN, by reducing KG size by 90% while maintainingstrong predictive performance. Beyond its scalability and efficiency, K-Pathsuniquely bridges the gap between KGs and LLMs, providing explainable rationalesfor predicted interactions. These capabilities show that K-Paths is a valuabletool for efficient data-driven drug discovery.</description>
      <author>example@mail.com (Tassallah Abdullahi, Ioanna Gemou, Nihal V. Nayak, Ghulam Murtaza, Stephen H. Bach, Carsten Eickhoff, Ritambhara Singh)</author>
      <guid isPermaLink="false">2502.13344v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations</title>
      <link>http://arxiv.org/abs/2502.13221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;在基础模型能力日益增强的时代，求职者开始利用生成式AI工具来提升他们的申请材料。然而，这种不平等的访问权限和知识水平可能导致招聘决策的准确性降低，并且给一些候选人带来不公平的优势。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型功能的提高，越来越多的人使用这些技术来改进简历等求职文件。但是，不同人之间获取生成式AI工具的能力存在差异，这可能会影响招聘过程中的公平性和准确度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略分类框架变体，以解决由于利用大规模语言模型而产生的操纵问题，并为此类操作制定相应规则。&lt;h4&gt;方法&lt;/h4&gt;引入了一个名为“双票制”的方案，在该方案中，招聘算法会对提交的每份简历进行额外的操作处理，并与原始版本一起考虑。此外还扩展了这一方法为更一般的n-票制度。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明表明，这种'双票制'方案能够提升招聘决策的准确性和公平性。并且，当正向预测率最大化并限制错误阳性发生时，最终的招聘结果将趋于稳定且不依赖于群体差异。&lt;h4&gt;结论&lt;/h4&gt;通过使用开源简历筛选工具对真实简历进行实验验证了该框架及其性能的有效性，这表明这种双票制方案能够在一定程度上缓解由于大型语言模型访问权的不同而引起的不公平现象。&lt;h4&gt;翻译&lt;/h4&gt;在技术不断进步的时代背景下，论文提出了一种新的策略分类方法来改善招聘过程中的公平性和准确性问题。通过引入一种名为‘双票制’的机制，并理论上证明了其有效性，最终通过实验验证表明这种方法能够解决由于大型语言模型使用差异带来的不公平现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In an era of increasingly capable foundation models, job seekers are turningto generative AI tools to enhance their application materials. However, unequalaccess to and knowledge about generative AI tools can harm both employers andcandidates by reducing the accuracy of hiring decisions and giving somecandidates an unfair advantage. To address these challenges, we introduce a newvariant of the strategic classification framework tailored to manipulationsperformed using large language models, accommodating varying levels ofmanipulations and stochastic outcomes. We propose a ``two-ticket'' scheme,where the hiring algorithm applies an additional manipulation to each submittedresume and considers this manipulated version together with the originalsubmitted resume. We establish theoretical guarantees for this scheme, showingimprovements for both the fairness and accuracy of hiring decisions when thetrue positive rate is maximized subject to a no false positives constraint. Wefurther generalize this approach to an $n$-ticket scheme and prove that hiringoutcomes converge to a fixed, group-independent decision, eliminatingdisparities arising from differential LLM access. Finally, we empiricallyvalidate our framework and the performance of our two-ticket scheme on realresumes using an open-source resume screening tool.</description>
      <author>example@mail.com (Lee Cohen, Jack Hsieh, Connie Hong, Judy Hanwen Shen)</author>
      <guid isPermaLink="false">2502.13221v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Myna: Masking-Based Contrastive Learning of Musical Representations</title>
      <link>http://arxiv.org/abs/2502.12511v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Myna 是一种简单的自监督音乐表示学习方法，基于对比学习框架，并引入了两个关键创新：使用 Vision Transformer (ViT) 处理频谱图和新颖的 token masking 数据增强策略。&lt;h4&gt;背景&lt;/h4&gt;音乐领域的自监督学习需要有效的数据表征方式以及高效的训练策略以提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法 Myna，能够通过对比学习框架提升音乐表示的学习效果，并且在有限资源下实现优秀的模型表现。&lt;h4&gt;方法&lt;/h4&gt;Myna 使用 ViT 作为主要架构并引入 token masking 数据增强技术。使用垂直补丁来捕捉关键特征，同时提高音高敏感性以改善任务性能。Myna-22M-Hybrid 版本同时处理不同大小的频谱图块，并且在单 GPU 上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;(i) Token masking 技术使每张 GPU 的批量大小从之前的 48 或者 120 增加到 4096，提高了效率。(ii) Myna 避免了传统增强方法，保持音高敏感性，从而在诸如关键检测的任务中表现更佳。(iii) 使用垂直补丁能更好地捕捉用于关键检测的特征。&lt;h4&gt;结论&lt;/h4&gt;Myna-22M-Hybrid 版本经过单 GPU 训练，在性能上超过了 MULE (62M)，并且与训练于 16 和 64 张 GPU 的 MERT-95M 相媲美，甚至在使用公开数据时表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Myna, a simple yet effective approach for self-supervised musicalrepresentation learning. Built on a contrastive learning framework, Mynaintroduces two key innovations: (1) the use of a Vision Transformer (ViT) onmel-spectrograms as the backbone and (2) a novel data augmentation strategy,token masking, that masks 90 percent of spectrogram tokens. These innovationsdeliver both effectiveness and efficiency: (i) Token masking enables asignificant increase in per-GPU batch size, from 48 or 120 in prior methods(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retainspitch sensitivity, enhancing performance in tasks like key detection. (iii) Theuse of vertical patches allows the model to better capture critical featuresfor key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and128x2 patches, achieving state-of-the-art results. Trained on a single GPU, itoutperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,establishing itself as the best-performing model trained on publicly availabledata. We release our code and models to promote reproducibility and facilitatefuture research.</description>
      <author>example@mail.com (Ori Yonay, Tracy Hammond, Tianbao Yang)</author>
      <guid isPermaLink="false">2502.12511v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Databases: A Survey</title>
      <link>http://arxiv.org/abs/2502.12908v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A survey focus on GNNs and databases. 9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了图神经网络（GNN）在数据库系统中的应用，提出了一个将现有方法分类为两类的新体系结构：关系型数据库和图形数据库。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图数据方面展示了强大的能力，并且在数据库社区中引起了越来越多的关注。然而，在如何通过基于GNN的方法改进数据库系统的全面理解和综述方面还存在空白。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补这一知识空白，提供一种结构化和深入的关于GNN在数据库系统中的应用的概述。&lt;h4&gt;方法&lt;/h4&gt;提出了一个分类体系结构，将现有方法分为两大类：（1）关系型数据库，包括性能预测、查询优化以及文本到SQL转换等任务；（2）图数据库，解决高效图形查询处理及相似性计算等问题。同时对各类关键方法进行了系统性的回顾。&lt;h4&gt;主要发现&lt;/h4&gt;概述了各种GNN在不同类型的数据库中应用的关键贡献和实际影响，并提出了将GNN进一步集成进数据库系统的潜在路径。&lt;h4&gt;结论&lt;/h4&gt;论文强调了图神经网络在改进数据库性能方面的潜力，同时也指出了一些未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful deep learning models forgraph-structured data, demonstrating remarkable success across diverse domains.Recently, the database (DB) community has increasingly recognized thepotentiality of GNNs, prompting a surge of researches focusing on improvingdatabase systems through GNN-based approaches. However, despite notableadvances, There is a lack of a comprehensive review and understanding of howGNNs could improve DB systems. Therefore, this survey aims to bridge this gapby providing a structured and in-depth overview of GNNs for DB systems.Specifically, we propose a new taxonomy that classifies existing methods intotwo key categories: (1) Relational Databases, which includes tasks likeperformance prediction, query optimization, and text-to-SQL, and (2) GraphDatabases, addressing challenges like efficient graph query processing andgraph similarity computation. We systematically review key methods in eachcategory, highlighting their contributions and practical implications. Finally,we suggest promising avenues for integrating GNNs into Database systems.</description>
      <author>example@mail.com (Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang)</author>
      <guid isPermaLink="false">2502.12908v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond</title>
      <link>http://arxiv.org/abs/2502.12048v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文综述了基于脑电图（EEG）的多模态生成技术的发展现状，重点关注通过生成对抗网络（GANs）、变分自编码器（VAEs）和扩散模型进行的EEG到图像生成，以及利用Transformer语言模型和对比学习方法实现的EEG到文本生成。&lt;h4&gt;背景&lt;/h4&gt;脑机接口（BCI）与生成人工智能（GenAI）的结合开启了大脑信号解码的新领域，实现了辅助通信、神经表示学习及多模态集成。特别是基于脑电图（EEG）的非侵入性方法，在将神经活动转化为有意义的输出方面发挥了重要作用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供基于EEG生成人工智能领域的结构化概述，为研究人员和从业者提供有关神经解码、增强辅助技术以及扩展人机交互边界的见解。&lt;h4&gt;方法&lt;/h4&gt;综述了通过GANs、VAEs和扩散模型实现的EEG到图像生成，以及借助Transformer语言模型和对比学习方法进行的EEG到文本生成。同时探讨了新兴领域——EEG到语音合成，并重点讨论关键数据集、使用案例、挑战及EEG特征编码方法。&lt;h4&gt;主要发现&lt;/h4&gt;近年来深度学习技术的进步显著改善了基于脑电图（EEG）产生图像、文本和语音的效果，特别是GANs和基于Transformer的大规模语言模型（LLMs）。&lt;h4&gt;结论&lt;/h4&gt;通过提供结构化概述，本文为推动神经解码的进展、增强辅助技术和拓展脑机交互领域提供了重要的研究视角。&lt;h4&gt;翻译&lt;/h4&gt;将脑电图（EEG）与生成人工智能结合的技术发展开辟了大脑信号解析的新方向。论文回顾了这些技术的应用现状，并指出了关键挑战和未来发展方向，强调其在神经解码、辅助通信及多模态数据融合方面的重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integration of Brain-Computer Interfaces (BCIs) and Generative ArtificialIntelligence (GenAI) has opened new frontiers in brain signal decoding,enabling assistive communication, neural representation learning, andmultimodal integration. BCIs, particularly those leveragingElectroencephalography (EEG), provide a non-invasive means of translatingneural activity into meaningful outputs. Recent advances in deep learning,including Generative Adversarial Networks (GANs) and Transformer-based LargeLanguage Models (LLMs), have significantly improved EEG-based generation ofimages, text, and speech. This paper provides a literature review of thestate-of-the-art in EEG-based multimodal generation, focusing on (i)EEG-to-image generation through GANs, Variational Autoencoders (VAEs), andDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer basedlanguage models and contrastive learning methods. Additionally, we discuss theemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. Wehighlight key datasets, use cases, challenges, and EEG feature encoding methodsthat underpin generative approaches. By providing a structured overview ofEEG-based generative AI, this survey aims to equip researchers andpractitioners with insights to advance neural decoding, enhance assistivetechnologies, and expand the frontiers of brain-computer interaction.</description>
      <author>example@mail.com (Shreya Shukla, Jose Torres, Abhijit Mishra, Jacek Gwizdka, Shounak Roychowdhury)</author>
      <guid isPermaLink="false">2502.12048v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Graph Structure Learning</title>
      <link>http://arxiv.org/abs/2502.12618v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'背景': '图神经网络（GNNs）已成为处理图结构数据学习的一种重要方法，但在图结构不理想时其效果会大打折扣。', '目的': '为了解决现有图结构学习（Graph Structure Learning, GSL）方法的两个关键局限性：一是忽视节点信息质量的重要性；二是构建的图结构通常受到对称性的限制，影响模型灵活性和有效性。', '方法': '提出了一种不确定性感知图结构学习（Uncertainty-aware Graph Structure Learning, UnGSL）策略。UnGSL通过估计节点信息的不确定性并利用它调整方向连接强度来减少具有高不确定性的节点的影响，并且可以无缝集成到现有的GSL方法中，几乎无需额外计算成本。', '主要发现': '实验显示，在将UnGSL应用于六种代表性GSL方法时，性能得到了一致的改进。', '结论': '通过引入不确定性感知机制和非对称连接调整策略，UnGSL能够提升现有图结构学习方法的有效性和灵活性。'}&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have become a prominent approach for learning from graph-structured data. However, their effectiveness can be significantly compromised when the graph structure is suboptimal. To address this issue, Graph Structure Learning (GSL) has emerged as a promising technique that refines node connections adaptively. Nevertheless, we identify two key limitations in existing GSL methods: 1) Most methods primarily focus on node similarity to construct relationships, while overlooking the quality of node information. Blindly connecting low-quality nodes and aggregating their ambiguous information can degrade the performance of other nodes. 2) The constructed graph structures are often constrained to be symmetric, which may limit the model's flexibility and effectiveness. To overcome these limitations, we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy. UnGSL estimates the uncertainty of node information and utilizes it to adjust the strength of directional connections, where the influence of nodes with high uncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-in module that can be seamlessly integrated into existing GSL methods with minimal additional computational cost. In our experiments, we implement UnGSL into six representative GSL methods, demonstrating consistent performance improvements.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become a prominent approach for learningfrom graph-structured data. However, their effectiveness can be significantlycompromised when the graph structure is suboptimal. To address this issue,Graph Structure Learning (GSL) has emerged as a promising technique thatrefines node connections adaptively. Nevertheless, we identify two keylimitations in existing GSL methods: 1) Most methods primarily focus on nodesimilarity to construct relationships, while overlooking the quality of nodeinformation. Blindly connecting low-quality nodes and aggregating theirambiguous information can degrade the performance of other nodes. 2) Theconstructed graph structures are often constrained to be symmetric, which maylimit the model's flexibility and effectiveness. To overcome these limitations,we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy.UnGSL estimates the uncertainty of node information and utilizes it to adjustthe strength of directional connections, where the influence of nodes with highuncertainty is adaptively reduced. Importantly, UnGSL serves as a plug-inmodule that can be seamlessly integrated into existing GSL methods with minimaladditional computational cost. In our experiments, we implement UnGSL into sixrepresentative GSL methods, demonstrating consistent performance improvements.</description>
      <author>example@mail.com (Shen Han, Zhiyao Zhou, Jiawei Chen, Zhezheng Hao, Sheng Zhou, Gang Wang, Yan Feng, Chun Chen, Can Wang)</author>
      <guid isPermaLink="false">2502.12618v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++是一种改进的深度学习模型，用于提高TESS（凌日系外行星巡天卫星）2分钟数据中的凌日信号分类准确性。&lt;h4&gt;背景&lt;/h4&gt;基于ExoMiner的成功经验，研究人员开发了ExoMiner++以更好地处理凌日信号，并区分出更多的假阳性源。&lt;h4&gt;目的&lt;/h4&gt;通过整合多种诊断输入和利用从开普勒太空望远镜中获得的高质量标签数据进行迁移学习来提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++引入了额外的诊断信息，包括周期图、通量趋势、差分图像、展开后的通量以及航天器姿态控制数据。&lt;h4&gt;主要发现&lt;/h4&gt;在147,568个未标记的凌日候选体中（TCE），ExoMiner++识别出了7330个为行星候选，其余则被分类为假阳性。这其中包括了与已知TESS目标对象相匹配的和新提出的社区TESS目标对象。&lt;h4&gt;结论&lt;/h4&gt;通过ExoMiner++的高准确性和优秀的排名质量，后续调查可以更加集中于最有希望的候选体上，从而提高发现行星的整体效率。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了ExoMiner++，这是一种改进型深度学习模型，在2分钟TESS数据中提升凌日信号分类。该模型利用周期图、通量趋势、差分图像等作为额外诊断输入，并通过从开普勒空间望远镜高质量标签数据进行迁移学习来优化性能。ExoMiner++在多种分类和排名指标上达到了高精度，显著缩小了后续调查的搜索范围以确认新的行星。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v3</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Sim-to-Real Methods in RL: Progress, Prospects and Challenges with Foundation Models</title>
      <link>http://arxiv.org/abs/2502.13187v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;深度强化学习（RL）在机器人、交通系统和推荐系统等多个领域被证明对于解决决策任务是有效且实用的。它通过与环境互动并根据收集到的经验更新策略来学习。&lt;h4&gt;背景&lt;/h4&gt;受限于真实世界的有限数据以及执行有害行为可能带来的不可接受后果，RL策略的学习主要局限于模拟器中进行。这确保了在学习过程中的安全性但带来了部署时的模拟现实差距（sim-to-real gap），导致性能下降和潜在风险。&lt;h4&gt;目的&lt;/h4&gt;这篇综述论文旨在首次为解决不同领域的模拟到真实问题的技术提供一个基于马尔可夫决策过程关键元素（状态、行动、转换和奖励）的形式框架。并涵盖了从经典方法到最近由大基础模型支持的高级方法在内的全面文献，同时讨论了各种领域中值得特别注意的特点。&lt;h4&gt;方法&lt;/h4&gt;根据提出的方法框架，对模拟现实性能进行了正式评估过程，并使用可访问代码或基准进行总结。&lt;h4&gt;主要发现&lt;/h4&gt;论文还概述了解决模拟到真实问题所面临的挑战以及未来研究的机会。&lt;h4&gt;结论&lt;/h4&gt;作者积极维护一个资源库以包含最新的模拟到真实的研究成果来帮助研究人员的工作。&lt;h4&gt;翻译&lt;/h4&gt;深度强化学习已被探索和验证为在机器人、运输系统和推荐系统等各个领域解决决策任务的有效方法。它通过与环境互动并根据收集的经验更新策略来进行学习。然而，由于现实世界数据的限制以及执行有害行为可能带来的不可接受后果，RL策略的学习主要局限于模拟器中进行。这虽然保证了学习过程中的安全性但带来了部署时的模拟现实差距（sim-to-real gap），导致性能下降和潜在风险。在不同领域中有各种技术尝试解决这个问题，特别是在大型基础模型或语言模型等新兴技术时代，这些问题得到了更多关注。&lt;h4&gt;关键词&lt;/h4&gt;['深度强化学习', '马尔可夫决策过程', '模拟到真实问题', '模拟器']&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Reinforcement Learning (RL) has been explored and verified to beeffective in solving decision-making tasks in various domains, such asrobotics, transportation, recommender systems, etc. It learns from theinteraction with environments and updates the policy using the collectedexperience. However, due to the limited real-world data and unbearableconsequences of taking detrimental actions, the learning of RL policy is mainlyrestricted within the simulators. This practice guarantees safety in learningbut introduces an inevitable sim-to-real gap in terms of deployment, thuscausing degraded performance and risks in execution. There are attempts tosolve the sim-to-real problems from different domains with various techniques,especially in the era with emerging techniques such as large foundations orlanguage models that have cast light on the sim-to-real. This survey paper, tothe best of our knowledge, is the first taxonomy that formally frames thesim-to-real techniques from key elements of the Markov Decision Process (State,Action, Transition, and Reward). Based on the framework, we cover comprehensiveliterature from the classic to the most advanced methods including thesim-to-real techniques empowered by foundation models, and we also discuss thespecialties that are worth attention in different domains of sim-to-realproblems. Then we summarize the formal evaluation process of sim-to-realperformance with accessible code or benchmarks. The challenges andopportunities are also presented to encourage future exploration of thisdirection. We are actively maintaining a to include the most up-to-datesim-to-real research outcomes to help the researchers in their work.</description>
      <author>example@mail.com (Longchao Da, Justin Turnau, Thirulogasankar Pranav Kutralingam, Alvaro Velasquez, Paulo Shakarian, Hua Wei)</author>
      <guid isPermaLink="false">2502.13187v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models</title>
      <link>http://arxiv.org/abs/2502.13179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为PTQ1.61的极低比特量化（Post-Training Quantization，简称PTQ）方法，首次实现将权重量化到1.61比特。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在面对极其低比特（小于2比特）量化时性能严重下降。现有的一些次2位后训练量化方法使用混合精度方案，并引入了额外的0.5或更多的比特以区分显著权重。&lt;h4&gt;目的&lt;/h4&gt;探索PTQ的真实极限，开发一种极低比特量化的方法。&lt;h4&gt;方法&lt;/h4&gt;引入了一维结构化掩码和基于输入激活降低量化误差上限的方法，使显著权重通道能分配到4位。对于非显著通道二值化，提出高效的块级缩放因子优化框架，考虑隐含的行相关性和角度偏差。此外，论文还提出了量化预处理的概念。&lt;h4&gt;主要发现&lt;/h4&gt;PTQ1.61在极低比特量化中实现了最先进的性能，并展示了代码库的位置。&lt;h4&gt;结论&lt;/h4&gt;通过新的结构化掩码和高效优化框架，首次实现了模型权重到1.61位的量化，在极端低比特环境下保持了良好的性能。同时强调了量化预处理对于提高低比特PTQ效果的重要性。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在面对极低比特（小于2比特）量化时表现出严重性能下降。现有的一些次2位后训练量化方法通过混合精度方案使用未结构化的细粒度掩码来区分显著权重，而这种方法会为每个权重引入额外的0.5个或更多的比特。为了探索PTQ的真实极限，我们提出了一种称为PTQ1.61的极低比特量化方法，首次实现了将权重量化到1.61比特的能力。具体而言，我们首先基于输入激活量从减少量化误差上限的角度引入了一个一维结构化掩码，每个权重仅增加几乎可以忽略不计的0.0002个比特，并允许相应的显著权重重分配至4位。对于非显著通道二值化，提出了一种高效的块级缩放因子优化框架来考虑隐含的行相关性和角度偏差。不同于以往的工作集中于调整量化方法论，我们进一步提出了量化预处理的新范式，即在量化前转换预先训练模型的权重分布可以缓解极低比特PTQ中的困难。广泛的实验表明我们的PTQ1.61在极低比特量化中达到了最先进的性能。代码可在https://github.com/zjq0455/PTQ1.61获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) suffer severe performance degradation whenfacing extremely low-bit (sub 2-bit) quantization. Several existing sub 2-bitpost-training quantization (PTQ) methods utilize a mix-precision scheme byleveraging an unstructured fine-grained mask to explicitly distinguish salientweights, while which introduces an extra 1-bit or more per weight. To explorethe real limit of PTQ, we propose an extremely low-bit PTQ method calledPTQ1.61, which enables weight quantization to 1.61-bit for the first time.Specifically, we first introduce a one-dimensional structured mask withnegligibly additional 0.0002-bit per weight based on input activations from theperspective of reducing the upper bound of quantization error to allocatecorresponding salient weight channels to 4-bit. For non-salient channelsbinarization, an efficient block-wise scaling factors optimization framework isthen presented to take implicit row-wise correlations and angular biases intoaccount. Different from prior works that concentrate on adjusting quantizationmethodologies, we further propose a novel paradigm called quantizationpreprocessing, where we argue that transforming the weight distribution of thepretrained model before quantization can alleviate the difficulty inper-channel extremely low-bit PTQ. Extensive experiments indicate our PTQ1.61achieves state-of-the-art performance in extremely low-bit quantization. Codesare available at https://github.com/zjq0455/PTQ1.61.</description>
      <author>example@mail.com (Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang)</author>
      <guid isPermaLink="false">2502.13179v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Training-Free Framework for Precise Mobile Manipulation of Small Everyday Objects</title>
      <link>http://arxiv.org/abs/2502.13964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project webpage: https://arjung128.github.io/svm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种称为视觉模型伺服控制（SVM）的新框架，用于移动机械臂在现实世界中处理需要精准操作小物体的任务。该方法无需训练，通过利用先进的视觉模型和腕部RGB-D相机实现目标的可靠检测与定位。&lt;h4&gt;背景&lt;/h4&gt;日常生活中许多任务都需要对小物件进行精确的操作，例如打开柜子或按下开关等。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需先期培训且适用于多种环境下的移动机械臂操作框架，以应对涉及小物体精准处理的任务。&lt;h4&gt;方法&lt;/h4&gt;使用RGB-D腕部相机和视觉伺服控制技术；采用先进的计算机视觉模型来计算3D目标位置；利用‘出画’（out-painting）技术减轻因末端执行器造成遮挡的影响，并提高目标定位的准确性；通过开放词汇的对象检测算法识别语义上的目标物体，用户点击确定交互点。&lt;h4&gt;主要发现&lt;/h4&gt;借助于‘出画’方法，无需训练的方法在处理未见过的对象时达到了85%的成功率，在真实世界环境中显著优于开环控制及基于模仿学习的基线模型（后者经过1000多次演示训练）。&lt;h4&gt;结论&lt;/h4&gt;SVM框架展示了其强大的泛化能力以及对未知环境和任务的有效适应，为移动机器人在实际应用中的操作提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many everyday mobile manipulation tasks require precise interaction withsmall objects, such as grasping a knob to open a cabinet or pressing a lightswitch. In this paper, we develop Servoing with Vision Models (SVM), aclosed-loop training-free framework that enables a mobile manipulator to tacklesuch precise tasks involving the manipulation of small objects. SVM employs anRGB-D wrist camera and uses visual servoing for control. Our novelty lies inthe use of state-of-the-art vision models to reliably compute 3D targets fromthe wrist image for diverse tasks and under occlusion due to the end-effector.To mitigate occlusion artifacts, we employ vision models to out-paint theend-effector thereby significantly enhancing target localization. Wedemonstrate that aided by out-painting methods, open-vocabulary objectdetectors can serve as a drop-in module to identify semantic targets (e.g.knobs) and point tracking methods can reliably track interaction sitesindicated by user clicks. This training-free method obtains an 85% zero-shotsuccess rate on manipulating unseen objects in novel environments in the realworld, outperforming an open-loop control method and an imitation learningbaseline trained on 1000+ demonstrations by an absolute success rate of 50%.</description>
      <author>example@mail.com (Arjun Gupta, Rishik Sathua, Saurabh Gupta)</author>
      <guid isPermaLink="false">2502.13964v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras</title>
      <link>http://arxiv.org/abs/2502.12545v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;我们提出了一种用于360°相机的新型3D重建流水线，旨在进行室内环境的3D映射和渲染。&lt;h4&gt;背景&lt;/h4&gt;传统的基于运动结构（SfM）的方法可能不适合大规模的室内场景，因为这些场景中存在无纹理和重复区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服传统SfM方法在处理大型室内场景中的不足。&lt;h4&gt;方法&lt;/h4&gt;{'IM360方法': '利用全景图像的广阔视野，并将球形相机模型集成到SfM流水线的核心组件中。引入神经隐式曲面重建技术，从稀疏输入数据生成高质量表面；使用基于网格的神经渲染技术来细化纹理图并准确捕捉依赖视点属性。', '评价': '在Matterport3D和Stanford2D3D数据集中的大规模室内场景上进行评估。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能提升': 'IM360在纹理网格重建方面优于现有最佳方法（SOTA）。', '改进的准确性': '观察到相机定位、注册以及渲染高频细节方面的准确度有所提高。'}&lt;h4&gt;结论&lt;/h4&gt;我们的研究为大型室内场景的高质量3D重建提供了一种有前景的方法，展示出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的360°摄像机3D重建流水线，用于大型室内环境的3D映射和渲染。传统的基于运动结构（SfM）方法在大规模无纹理且重复区域较多的场景中表现不佳。为了克服这些挑战，我们的IM360方法利用了全景图像的广阔视野，并将球形相机模型集成到了SfM流水线的核心组件中。此外，我们还整合了一个神经隐式表面重建技术来从稀疏输入数据生成高质量曲面，并且采用了一种基于网格的神经渲染方式来细化纹理图并准确捕捉依赖视点属性。我们在Matterport3D和Stanford2D3D数据集的大规模室内场景中评估了我们的流水线，IM360在纹理网格重建方面表现出比现有最佳方法（SOTA）更好的性能，同时我们还观察到了相机定位、注册以及渲染高频细节方面的准确度提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel 3D reconstruction pipeline for 360$^\circ$ cameras for 3Dmapping and rendering of indoor environments. Traditional Structure-from-Motion(SfM) methods may not work well in large-scale indoor scenes due to theprevalence of textureless and repetitive regions. To overcome these challenges,our approach (IM360) leverages the wide field of view of omnidirectional imagesand integrates the spherical camera model into every core component of the SfMpipeline. In order to develop a comprehensive 3D reconstruction solution, weintegrate a neural implicit surface reconstruction technique to generatehigh-quality surfaces from sparse input data. Additionally, we utilize amesh-based neural rendering approach to refine texture maps and accuratelycapture view-dependent properties by combining diffuse and specular components.We evaluate our pipeline on large-scale indoor scenes from the Matterport3D andStanford2D3D datasets. In practice, IM360 demonstrate superior performance interms of textured mesh reconstruction over SOTA. We observe accuracyimprovements in terms of camera localization and registration as well asrendering high frequency details.</description>
      <author>example@mail.com (Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha)</author>
      <guid isPermaLink="false">2502.12545v2</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>3D Gaussian Splatting aided Localization for Large and Complex Indoor-Environments</title>
      <link>http://arxiv.org/abs/2502.13803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了通过增加渲染图像来显著提高视觉定位精度和可靠性的新方法。&lt;h4&gt;背景&lt;/h4&gt;视觉定位领域经过几十年的研究，已经找到了许多实际应用。然而，在某些挑战性情况下，现有方法仍然表现不佳。&lt;h4&gt;目的&lt;/h4&gt;改进现有的视觉定位技术的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;首先使用现代视觉SLAM（Simultaneous Localization and Mapping）方法生成3D Gaussian Splatting (3DGS) 基于的地图作为参考数据；然后通过在随机采样的姿态下从3DGS渲染图像来丰富参考数据，以提升基于几何的视觉定位和Scene Coordinate Regression (SCR) 方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;增加渲染图像可以显著提高基于几何的方法和SCRe方法的性能，在工业环境中进行了全面评估，并分析了加入额外渲染视图对性能的影响。&lt;h4&gt;结论&lt;/h4&gt;通过添加渲染图像，能够有效提升视觉定位技术在复杂环境中的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;视觉定位领域经过几十年的研究，已经找到了许多实际应用。然而，尽管该领域取得了巨大进展，在某些挑战情况下，现有方法仍然表现出局限性。我们提出了一种改进传统视觉定位方法精度和可靠性的新途径，即通过添加渲染图像实现。具体而言，首先使用现代的视觉SLAM技术生成3D Gaussian Splatting (3DGS) 基的地图作为参考数据；然后通过从该地图随机采样的姿态下进行渲染来丰富这些参考数据，并证明这种做法可以显著提高基于几何的定位方法和Scene Coordinate Regression (SCR) 方法的表现。在大型工业环境中进行了全面评估，分析了添加额外渲染视图对性能的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of visual localization has been researched for several decades andhas meanwhile found many practical applications. Despite the strong progress inthis field, there are still challenging situations in which established methodsfail. We present an approach to significantly improve the accuracy andreliability of established visual localization methods by adding renderedimages. In detail, we first use a modern visual SLAM approach that provides a3D Gaussian Splatting (3DGS) based map to create reference data. We demonstratethat enriching reference data with images rendered from 3DGS at randomlysampled poses significantly improves the performance of both geometry-basedvisual localization and Scene Coordinate Regression (SCR) methods. Throughcomprehensive evaluation in a large industrial environment, we analyze theperformance impact of incorporating these additional rendered views.</description>
      <author>example@mail.com (Vincent Ress, Jonas Meyer, Wei Zhang, David Skuddis, Uwe Soergel, Norbert Haala)</author>
      <guid isPermaLink="false">2502.13803v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>The NavINST Dataset for Multi-Sensor Autonomous Navigation</title>
      <link>http://arxiv.org/abs/2502.13863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 20 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NavINST实验室开发了一套全面的多感官数据集，该数据集包含了城市环境中的各种道路测试轨迹，并涵盖了不同的照明条件，包括室内车库场景以及密集3D地图。&lt;h4&gt;背景&lt;/h4&gt;为了支持高精度定位、导航、制图、计算机视觉和多传感器融合等领域的高级研究，NavINST实验室创建了一个包含多个商用级IMU和高端战术级IMU的数据集。&lt;h4&gt;目的&lt;/h4&gt;该数据集旨在为自动驾驶车辆算法的开发和验证提供丰富的、多传感器信息。它包括了各种感知基础传感器以及准确后处理过的高精度GNSS/IMU数据，以提供精确的位置定位和导航信息。&lt;h4&gt;方法&lt;/h4&gt;NavINST实验室创建的数据集使用多种商用级惯性测量单元（IMUs）和高端战术级IMU，还包括固态激光雷达、机械式激光雷达、四个电子扫描雷达、单目摄像头以及两个立体摄像机。此外，该数据集还包含了从车辆里程表中提取的前向速度信息。&lt;h4&gt;主要发现&lt;/h4&gt;NavINST数据集是首个包含固态激光雷达的数据集之一，并且提供了精确的地面真实位置和导航信息，适用于开发和验证自主驾驶汽车的鲁棒算法。&lt;h4&gt;结论&lt;/h4&gt;该数据集已完全集成到ROS中，确保了对研究社区的易用性和可访问性。整个数据集及其开发工具可通过https://navinst.github.io获取。&lt;h4&gt;翻译&lt;/h4&gt;NavINST实验室在城市环境中通过各种道路测试轨迹创建了一个全面的多感官数据集，涵盖了不同的照明条件，包括带有密集3D地图的室内车库场景。该数据集包含多个商用级IMU和高端战术级IMU以及多种感知基础传感器（如固态激光雷达、机械式激光雷达、四个电子扫描雷达、单目摄像头及两个立体摄像机）。此外，还包括从车辆里程表中提取的前向速度信息，并提供高精度后处理后的GNSS/IMU数据。NavINST数据集用于支持高精度定位、导航、制图、计算机视觉和多传感器融合等领域的高级研究，为自动驾驶汽车算法的发展与验证提供了丰富的多传感器数据。整个数据集已完全集成到ROS中，确保了对研究社区的易用性和可访问性，并可通过https://navinst.github.io获取其全部内容及开发工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The NavINST Laboratory has developed a comprehensive multisensory datasetfrom various road-test trajectories in urban environments, featuring diverselighting conditions, including indoor garage scenarios with dense 3D maps. Thisdataset includes multiple commercial-grade IMUs and a high-end tactical-gradeIMU. Additionally, it contains a wide array of perception-based sensors, suchas a solid-state LiDAR - making it one of the first datasets to do so - amechanical LiDAR, four electronically scanning RADARs, a monocular camera, andtwo stereo cameras. The dataset also includes forward speed measurementsderived from the vehicle's odometer, along with accurately post-processedhigh-end GNSS/IMU data, providing precise ground truth positioning andnavigation information. The NavINST dataset is designed to support advancedresearch in high-precision positioning, navigation, mapping, computer vision,and multisensory fusion. It offers rich, multi-sensor data ideal for developingand validating robust algorithms for autonomous vehicles. Finally, it is fullyintegrated with the ROS, ensuring ease of use and accessibility for theresearch community. The complete dataset and development tools are available athttps://navinst.github.io.</description>
      <author>example@mail.com (Paulo Ricardo Marques de Araujo, Eslam Mounier, Qamar Bader, Emma Dawson, Shaza I. Kaoud Abdelaziz, Ahmed Zekry, Mohamed Elhabiby, Aboelmagd Noureldin)</author>
      <guid isPermaLink="false">2502.13863v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Minimally sufficient structures for information-feedback policies</title>
      <link>http://arxiv.org/abs/2502.13852v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 16th International Workshop on the Algorithmic Foundations of  Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文探讨了机器人在物理世界中的任务需求，这些任务需要通过有限感知、记忆和计算来实现。&lt;h4&gt;目的&lt;/h4&gt;设计一个过滤器来维持对物理世界的有用表示，并根据这个表示制定策略。&lt;h4&gt;方法&lt;/h4&gt;将过滤器看作机器人基于其感官信息的物理世界的视角。研究了内部系统（如过滤器）与外部物理世界如何通过传感器映射和信息反馈政策相互作用，以实现给定任务。&lt;h4&gt;主要发现&lt;/h4&gt;论文建立了使信息反馈政策存在的必要条件，并证明在轻微假设下存在唯一最小化内部系统来表示特定的规划/策略。&lt;h4&gt;结论&lt;/h4&gt;结果应用于确定距离最优导航所需的结构，在多边形环境中特别有效。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们考虑了机器人需要完成的任务，这些任务要求在一个物理世界中实现期望的结果。为了达到这一目标，我们需要设计一个过滤器来维持对这个物理世界的有用表示，并在此基础上制定策略。过滤器被视为机器人基于有限感官、记忆和计算的视角，并通过传感器映射和信息反馈政策将内部系统（如过滤器）与外部物理世界联系起来。论文确立了使这些结构存在的必要条件，以及在轻微假设下唯一最小化内部系统的存在性和独特性。最后，研究结果应用于确定多边形环境中的距离最优导航所需的足够结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider robotic tasks which require a desirable outcome tobe achieved in the physical world that the robot is embedded in and interactingwith. Accomplishing this objective requires designing a filter that maintains auseful representation of the physical world and a policy over the filterstates. A filter is seen as the robot's perspective of the physical world basedon limited sensing, memory, and computation and it is represented as atransition system over a space of information states. To this end, theinteractions result from the coupling of an internal and an external system, afilter, and the physical world, respectively, through a sensor mapping and aninformation-feedback policy. Within this setup, we look for sufficientstructures, that is, sufficient internal systems and sensors, for accomplishinga given task. We establish necessary and sufficient conditions for thesestructures to satisfy for information-feedback policies that can be definedover the states of an internal system to exist. We also show that under mildassumptions, minimal internal systems that can represent a particularplan/policy described over the action-observation histories exist and areunique. Finally, the results are applied to determine sufficient structures fordistance-optimal navigation in a polygonal environment.</description>
      <author>example@mail.com (Basak Sakcak, Vadim K. Weinstein, Kalle G. Timperi, Steven M. LaValle)</author>
      <guid isPermaLink="false">2502.13852v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>An Online Optimization-Based Trajectory Planning Approach for Cooperative Landing Tasks</title>
      <link>http://arxiv.org/abs/2502.13823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种针对由四旋翼和地面移动机器人组成的异构多机器人系统的实时轨迹规划方案，用于协作着陆任务。&lt;h4&gt;背景&lt;/h4&gt;现有系统缺乏对协同作业的灵活性和自主性的支持，特别是在需要动态调整以满足用户需求的情况下。&lt;h4&gt;目的&lt;/h4&gt;开发一种框架来实现基于可行性与用户规范的自动决定着陆位置、时间和机器人协调的任务。&lt;h4&gt;方法&lt;/h4&gt;利用互补性约束作为决策制定工具，并将其应用于协作降落场景中。该方案在模拟和实际应用中进行了验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过将地面移动机器人用作移动充电站并与需要充电的四旋翼进行实时协同，实现了安全有效的会合与着陆。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架展示了其实时能力，并为类似协作任务提供了潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已翻译成中文并进行了分点总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a real-time trajectory planning scheme for aheterogeneous multi-robot system (consisting of a quadrotor and a ground mobilerobot) for a cooperative landing task, where the landing position, landingtime, and coordination between the robots are determined autonomously under theconsideration of feasibility and user specifications. The proposed frameworkleverages the potential of the complementarity constraint as a decision-makerand an indicator for diverse cooperative tasks and extends it to thecollaborative landing scenario. In a potential application of the proposedmethodology, a ground mobile robot may serve as a mobile charging station andcoordinates in real-time with a quadrotor to be charged, facilitating a safeand efficient rendezvous and landing. We verified the generated trajectories insimulation and real-world applications, demonstrating the real-timecapabilities of the proposed landing planning framework.</description>
      <author>example@mail.com (Jingshan Chen, Lihan Xu, Henrik Ebel, Peter Eberhard)</author>
      <guid isPermaLink="false">2502.13823v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Embodied Emotional Communication: A Human-oriented Review of Mediated Social Touch</title>
      <link>http://arxiv.org/abs/2502.13816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is 41 pages long, including references and appendices, and  contains 8 figures. The manuscript has been accepted for publication in CCF  Transactions on Pervasive Computing and Interaction but has not yet been  officially published&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文通过回顾文献，为中介社会触摸（MST）提供了以人为主体的理解框架。&lt;h4&gt;研究背景&lt;/h4&gt;涵盖了触觉接口、情感信息、映射机制以及人际和人机交互的动态变化。&lt;h4&gt;研究目的&lt;/h4&gt;通过对37个选定的MST案例进行现有及探索性映射策略的研究，构建了容纳各种情绪的情感表达空间，并探讨了如何将情感线索转化为触觉信号。此外，还根据MST的表现力构建了一个设计空间。&lt;h4&gt;主要发现&lt;/h4&gt;建立了基于类别模型和效价-唤醒模型结合的情感表达空间；提出了包括工作流程、评估方法及伦理与文化考虑在内的多种MST设计方案；指出了未来的研究方向。&lt;h4&gt;结论&lt;/h4&gt;论文旨在为设计研究人员和从业者提供一个全面的参考，扩大情感交流范围，促进情感触觉应用探索，增强触觉交互的自然性和社交性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：This paper offers a structured understanding of mediated social touch (MST)using a human-oriented approach, through an extensive review of literaturespanning tactile interfaces, emotional information, mapping mechanisms, and thedynamics of human-human and human-robot interactions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper offers a structured understanding of mediated social touch (MST)using a human-oriented approach, through an extensive review of literaturespanning tactile interfaces, emotional information, mapping mechanisms, and thedynamics of human-human and human-robot interactions. By investigating theexisting and exploratory mapping strategies of the 37 selected MST cases, weestablished the emotional expression space of MSTs that accommodated a diversespectrum of emotions by integrating the categorical and Valence-arousal models,showcasing how emotional cues can be translated into tactile signals. Based onthe expressive capacity of MSTs, a practical design space was structuredencompassing factors such as the body locations, device form, tactilemodalities, and parameters. We also proposed various design strategies for MSTsincluding workflow, evaluation methods, and ethical and culturalconsiderations, as well as several future research directions. MSTs' potentialis reflected not only in conveying emotional information but also in fosteringempathy, comfort, and connection in both human-human and human-robotinteractions. This paper aims to serve as a comprehensive reference for designresearchers and practitioners, which helps expand the scope of emotionalcommunication of MSTs, facilitating the exploration of diverse applications ofaffective haptics, and enhancing the naturalness and sociability of hapticinteraction.</description>
      <author>example@mail.com (Liwen He, Zichun Guo, Yanru Mo, Yue Wen, Yun Wang)</author>
      <guid isPermaLink="false">2502.13816v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Muscle Activation Estimation by Optimzing the Musculoskeletal Model for Personalized Strength and Conditioning Training</title>
      <link>http://arxiv.org/abs/2502.13760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一个全身肌肉骨骼模型用于力量和体能训练，并通过基于表面肌电图的优化方法校准相关肌肉参数。&lt;h4&gt;背景&lt;/h4&gt;肌肉骨骼模型在康复与抗阻训练领域中对于分析肌肉状况至关重要。然而，个体间肌肉骨骼参数差异及一些内部生物力学变量无法直接测量的问题导致个性化建模非常困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的全身肌肉骨骼模型，并通过基于表面肌电图的优化方法校准相关的肌肉参数，以更准确地估计肌肉激活情况，从而分析训练表现。&lt;h4&gt;方法&lt;/h4&gt;使用基于表面肌电图（EMG）的优化方法来个性化调整全身肌肉骨骼模型中的相关肌肉参数。利用这个个性化的肌肉骨骼模型，研究者能够随后估算肌肉激活情况，进而分析运动表现。&lt;h4&gt;主要发现&lt;/h4&gt;通过选择杠铃卧推和硬拉作为实验验证的方法，证实了该方法的有效性，并展示了如何更准确地估计肌肉激活和性能。&lt;h4&gt;结论&lt;/h4&gt;开发的全身肌肉骨骼模型及其优化参数对于个性化训练方案设计具有重要意义。这些成果为未来康复医学和运动科学的研究提供了新的视角和工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Musculoskeletal models are pivotal in the domains of rehabilitation andresistance training to analyze muscle conditions. However, individualvariability in musculoskeletal parameters and the immeasurability of someinternal biomechanical variables pose significant obstacles to accuratepersonalized modelling. Furthermore, muscle activation estimation can bechallenging due to the inherent redundancy of the musculoskeletal system, wheremultiple muscles drive a single joint. This study develops a whole-bodymusculoskeletal model for strength and conditioning training and calibratesrelevant muscle parameters with an electromyography-based optimization method.By utilizing the personalized musculoskeletal model, muscle activation can besubsequently estimated to analyze the performance of exercises. Bench press anddeadlift are chosen for experimental verification to affirm the efficacy ofthis approach.</description>
      <author>example@mail.com (Xi Wu, Chenzui Li, Kehan Zou, Ning Xi, Fei Chen)</author>
      <guid isPermaLink="false">2502.13760v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Active Illumination for Visual Ego-Motion Estimation in the Dark</title>
      <link>http://arxiv.org/abs/2502.13708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉里程计（VO）和视觉同步定位与地图构建（V-SLAM）系统在低光或黑暗环境中表现不佳，因为缺乏稳健的视觉特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型主动照明框架，用于增强这些算法在挑战性条件下的性能。&lt;h4&gt;方法&lt;/h4&gt;{'主动照明框架': '动态控制移动光源以照亮具有高度纹理的区域', '探测器块': '结合深度学习增强网络来识别具有相关特征的区域', '云台控制器': '负责将光线引导至这些区域，提供富含信息的图像给自运动估计算法'}&lt;h4&gt;主要发现&lt;/h4&gt;在实际机器人平台上进行实验的结果显示，与传统的固定照明技术相比，所提出的方法可减少姿态估计误差高达75%。&lt;h4&gt;结论&lt;/h4&gt;该主动照明框架显著提高了VO和V-SLAM系统在低光条件下的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了视觉里程计（VO）和视觉同步定位与地图构建（V-SLAM）技术在低光或黑暗环境中存在的挑战，并提出了一种基于动态控制移动光源的主动照明框架来提高这些算法的表现，通过实验验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Odometry (VO) and Visual SLAM (V-SLAM) systems often struggle inlow-light and dark environments due to the lack of robust visual features. Inthis paper, we propose a novel active illumination framework to enhance theperformance of VO and V-SLAM algorithms in these challenging conditions. Thedeveloped approach dynamically controls a moving light source to illuminatehighly textured areas, thereby improving feature extraction and tracking.Specifically, a detector block, which incorporates a deep learning-basedenhancing network, identifies regions with relevant features. Then, a pan-tiltcontroller is responsible for guiding the light beam toward these areas, sothat to provide information-rich images to the ego-motion estimation algorithm.Experimental results on a real robotic platform demonstrate the effectivenessof the proposed method, showing a reduction in the pose estimation error up to75% with respect to a traditional fixed lighting technique.</description>
      <author>example@mail.com (Francesco Crocetti, Alberto Dionigi, Raffaele Brilli, Gabriele Costante, Paolo Valigi)</author>
      <guid isPermaLink="false">2502.13708v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Human-Like Robot Impedance Regulation Skill Learning from Human-Human Demonstrations</title>
      <link>http://arxiv.org/abs/2502.13707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种创新的阻抗调节技能学习框架，旨在实现多种物理协作任务中的人机合作（HRC）。该框架通过调整机器人与人类伙伴状态相适应的顺应性来工作，并根据人与人的示范提供的参考轨迹进行操作。&lt;h4&gt;背景&lt;/h4&gt;人类在基于对同伴状态和任务需求感知的基础上调节顺从行为方面擅长协作。让机器人掌握这种技能可以促进更高效的人机协作（HRC）。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架，通过调整机器人的顺应性来实现有效的人机物理合作。&lt;h4&gt;方法&lt;/h4&gt;收集并分析人类肌肉的肌电图(EMG)信号以提取肢体阻抗；采用概率学习方法捕捉和表示人体端点运动，并创建参考轨迹和相应的阻抗配置文件。使用LSTM模块开发任务导向型阻抗调节策略，同时提出一种针对类人机器人的全身阻抗控制器。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，在协作运输任务以及两个互动太极推手任务中，与恒定阻抗控制方法相比，本文所提出的框架从交互力的角度表现出更优性能。&lt;h4&gt;结论&lt;/h4&gt;该研究通过开发适应性更好的人机合作技能，促进了更加高效和自然的人机物理协作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans are experts in collaborating with others physically by regulatingcompliance behaviors based on the perception of their partner states and thetask requirements. Enabling robots to develop proficiency in humancollaboration skills can facilitate more efficient human-robot collaboration(HRC). This paper introduces an innovative impedance regulation skill learningframework for achieving HRC in multiple physical collaborative tasks. Theframework is designed to adjust the robot compliance to the human partnerstates while adhering to reference trajectories provided by human-humandemonstrations. Specifically, electromyography (EMG) signals from human musclesare collected and analyzed to extract limb impedance, representing compliancebehaviors during demonstrations. Human endpoint motions are captured andrepresented using a probabilistic learning method to create referencetrajectories and corresponding impedance profiles. Meanwhile, an LSTMbasedmodule is implemented to develop task-oriented impedance regulation policies bymapping the muscle synergistic contributions between two demonstrators.Finally, we propose a wholebody impedance controller for a human-like robot,coordinating joint outputs to achieve the desired impedance and referencetrajectory during task execution. Experimental validation was conducted througha collaborative transportation task and two interactive Tai Chi pushing handstasks, demonstrating superior performance from the perspective of interactiveforces compared to a constant impedance control method.</description>
      <author>example@mail.com (Chenzui Li, Xi Wu, Junjia Liu, Tao Teng, Yiming Chen, Sylvain Calinon, Darwin Caldwell, Fei Chen)</author>
      <guid isPermaLink="false">2502.13707v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>A Framework for Semantics-based Situational Awareness during Mobile Robot Deployments</title>
      <link>http://arxiv.org/abs/2502.13677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在危险环境中部署机器人时，人机团队合作中情景意识的高级语义信息理解和获取的方法。提出了一种可扩展框架，用于远程部署移动机器人的多模态语义级情景意识采集和整合，并通过灾难响应机器人中的搜索与救援应用来演示该框架。&lt;h4&gt;背景&lt;/h4&gt;在危险环境中部署机器人通常采用人机团队合作模式，其中人类监督者与远程操作的机器人协同工作。情景意识对于支持导航、规划和决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究不同自主程度下语义信息的重要性和差异，并提出一种获取和整合多模态语义级情景意识的通用框架。&lt;h4&gt;方法&lt;/h4&gt;提出了“环境语义指标”，这些指标可以反映风险指示或人类活动迹象等不同类型的语义信息。基于这些指标，设计了一种称为“情境语义丰富度（SSR）”的综合评估指标，该指标结合了多种语义指示来总结整体情况。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示提出的语义指标对不同场景中各种模态的语义信息变化敏感，且SSR度量能够反映遇到的情境的整体语义变化。这表明信息丰富和复杂的情况可能需要高级推理能力和专家人类操作员的关注。&lt;h4&gt;结论&lt;/h4&gt;该框架为远程部署移动机器人提供了强大的情景意识支持，有助于提高人机团队合作的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deployment of robots into hazardous environments typically involves a``Human-Robot Teaming'' (HRT) paradigm, in which a human supervisor interactswith a remotely operating robot inside the hazardous zone. SituationalAwareness (SA) is vital for enabling HRT, to support navigation, planning, anddecision-making. This paper explores issues of higher-level ``semantic''information and understanding in SA. In semi-autonomous, or variable-autonomyparadigms, different types of semantic information may be important, indifferent ways, for both the human operator and an autonomous agent controllingthe robot. We propose a generalizable framework for acquiring and combiningmultiple modalities of semantic-level SA during remote deployments of mobilerobots. We demonstrate the framework with an example application of search andrescue (SAR) in disaster response robotics. We propose a set of ``environmentsemantic indicators" that can reflect a variety of different types of semanticinformation, e.g. indicators of risk, or signs of human activity, as the robotencounters different scenes. Based on these indicators, we propose a metric todescribe the overall situation of the environment called ``Situational SemanticRichness (SSR)". This metric combines multiple semantic indicators to summarisethe overall situation. The SSR indicates if an information-rich and complexsituation has been encountered, which may require advanced reasoning for robotsand humans and hence the attention of the expert human operator. The frameworkis tested on a Jackal robot in a mock-up disaster response environment.Experimental results demonstrate that the proposed semantic indicators aresensitive to changes in different modalities of semantic information indifferent scenes, and the SSR metric reflects overall semantic changes in thesituations encountered.</description>
      <author>example@mail.com (Tianshu Ruan, Aniketh Ramesh, Hao Wang, Alix Johnstone-Morfoisse, Gokcenur Altindal, Paul Norman, Grigoris Nikolaou, Rustam Stolkin, Manolis Chiou)</author>
      <guid isPermaLink="false">2502.13677v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>An Adaptive Data-Enabled Policy Optimization Approach for Autonomous Bicycle Control</title>
      <link>http://arxiv.org/abs/2502.13676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一控制框架，该框架结合了内环的反馈线性化（FL）控制器和外环的自适应数据增强策略优化（DeePO）控制器来平衡自主自行车。&lt;h4&gt;背景&lt;/h4&gt;由于自主自行车系统本质上是不稳定且非线性的，因此使用FL控制器可以稳定并部分线性化系统。然而，性能会因未建模动态效应以及时间变化特性而受到影响。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，并增强系统的适应性和鲁棒性，引入了DeePO控制器来与FL控制器协同工作。&lt;h4&gt;方法&lt;/h4&gt;初始控制策略通过离线的持续激励输入和状态数据获得。利用一种促进鲁棒性的正则化器改进初始策略，同时增加一个遗忘因子以提升适应时间变化动态的能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟和实际实验验证了DeePO+FL方法的有效性，并表明其在跟踪参考倾斜角度和倾斜速率的精确度上优于仅使用FL的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的控制框架能够显著提高自主自行车系统的稳定性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要的内容描述了一种结合反馈线性化和自适应数据增强策略优化来平衡自主自行车的新方法，展示了该方法在模拟和实际实验中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a unified control framework that integrates a FeedbackLinearization (FL) controller in the inner loop with an adaptive Data-EnabledPolicy Optimization (DeePO) controller in the outer loop to balance anautonomous bicycle. While the FL controller stabilizes and partially linearizesthe inherently unstable and nonlinear system, its performance is compromised byunmodeled dynamics and time-varying characteristics. To overcome theselimitations, the DeePO controller is introduced to enhance adaptability androbustness. The initial control policy of DeePO is obtained from a finite setof offline, persistently exciting input and state data. To improve stabilityand compensate for system nonlinearities and disturbances, arobustness-promoting regularizer refines the initial policy, while the adaptivesection of the DeePO framework is enhanced with a forgetting factor to improveadaptation to time-varying dynamics. The proposed DeePO+FL approach isevaluated through simulations and real-world experiments on an instrumentedautonomous bicycle. Results demonstrate its superiority over the FL-onlyapproach, achieving more precise tracking of the reference lean angle and leanrate.</description>
      <author>example@mail.com (Niklas Persson, Feiran Zhao, Mojtaba Kaheni, Florian Dörfler, Alessandro V. Papadopoulos)</author>
      <guid isPermaLink="false">2502.13676v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>SLAMSpoof: Practical LiDAR Spoofing Attacks on Localization Systems Guided by Scan Matching Vulnerability Analysis</title>
      <link>http://arxiv.org/abs/2502.13641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7pages, 6figures, accepted at IEEE International Conference on  Robotics and Automation (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SLAMSpoof是一种针对自动驾驶车辆定位系统的LiDAR欺骗攻击，通过评估LiDAR在实际环境中的易受攻击性来检验其对自主驾驶的影响。&lt;h4&gt;背景&lt;/h4&gt;现代全自动驾驶服务依赖于地图交通信息进行精确的车道形状、交通灯位置和标志识别。为了实现这一点，需要厘米级的定位精度，而目前只有LiDAR传感器能够达到这一要求。然而，由于LiDAR容易受到激光欺骗攻击的影响，这种安全威胁引起了人们的关注。&lt;h4&gt;目的&lt;/h4&gt;设计SLAMSpoof来评估实际场景中对基于LiDAR的自动驾驶车辆定位系统进行欺骗攻击的安全性影响。&lt;h4&gt;方法&lt;/h4&gt;通过扫描匹配脆弱性评分（SMVS）找到有效的攻击位置，并在真实环境中测试了该攻击的有效性，证明其能够在所有流行的LiDAR定位算法上引入超过4.2米的位置误差。&lt;h4&gt;主要发现&lt;/h4&gt;SLAMSpoof能够有效利用基于LiDAR的定位系统中的漏洞，在现实世界场景中诱导出显著的位置错误。&lt;h4&gt;结论&lt;/h4&gt;论文指出了自动驾驶车辆在使用LiDAR时可能面临的安全威胁，并提出了评估该类攻击实际影响的方法。同时，讨论了对抗此类攻击的潜在对策。&lt;h4&gt;翻译&lt;/h4&gt;精确定位对于实现现代全自动驾驶服务至关重要。这些服务高度依赖于基于地图的交通信息来减少识别车道形状、交通信号灯位置和标志等不确定性的程度。为了达到这种对地图数据的高度信赖，需要厘米级精度的定位能力，目前只有激光雷达（LiDAR）传感器可以提供这样的精确度。然而，由于激光雷达容易受到恶意发射激光欺骗其读数的安全威胁，一旦定位系统被攻破，可能导致车辆偏离道路或忽视交通信号灯等严重后果。鉴于此类攻击所带来的安全问题，研究团队设计了SLAMSpoof，这是首个针对自动驾驶车辆定位系统的实际LiDAR欺骗攻击方法，用以评估这种攻击对自主驾驶汽车的实际影响。通过扫描匹配脆弱性评分（SMVS），该技术能够找到有效的攻击位置，并在实地测试中证明其能够在所有流行的基于激光雷达的定位算法上引入显著的位置误差。研究团队还讨论了针对此类攻击可能采取的安全措施。代码可在https://github.com/Keio-CSG/slamspoof获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate localization is essential for enabling modern full self-drivingservices. These services heavily rely on map-based traffic information toreduce uncertainties in recognizing lane shapes, traffic light locations, andtraffic signs. Achieving this level of reliance on map information requirescentimeter-level localization accuracy, which is currently only achievable withLiDAR sensors. However, LiDAR is known to be vulnerable to spoofing attacksthat emit malicious lasers against LiDAR to overwrite its measurements. Oncelocalization is compromised, the attack could lead the victim off roads or makethem ignore traffic lights. Motivated by these serious safety implications, wedesign SLAMSpoof, the first practical LiDAR spoofing attack on localizationsystems for self-driving to assess the actual attack significance on autonomousvehicles. SLAMSpoof can effectively find the effective attack location based onour scan matching vulnerability score (SMVS), a point-wise metric representingthe potential vulnerability to spoofing attacks. To evaluate the effectivenessof the attack, we conduct real-world experiments on ground vehicles and confirmits high capability in real-world scenarios, inducing position errors of$\geq$4.2 meters (more than typical lane width) for all 3 popular LiDAR-basedlocalization algorithms. We finally discuss the potential countermeasures ofthis attack. Code is available at https://github.com/Keio-CSG/slamspoof</description>
      <author>example@mail.com (Rokuto Nagata, Kenji Koide, Yuki Hayakawa, Ryo Suzuki, Kazuma Ikeda, Ozora Sako, Qi Alfred Chen, Takami Sato, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.13641v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Model Evolution Framework with Genetic Algorithm for Multi-Task Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.13569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于遗传算法的模型进化框架（MEGA），旨在通过调整模型结构以适应不同任务难度，从而提升多任务强化学习中单一策略的泛化能力和效率。&lt;h4&gt;背景&lt;/h4&gt;在多任务强化学习中，单个策略用于完成多个任务，并通过参数共享来提高代理的学习效率。现有的方法通常使用路由网络为每个任务生成特定路径，并将一组模块重组以同时完成多种任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够根据任务难度自动调整模型结构的框架，提升多任务强化学习中的资源分配和学习效率。&lt;h4&gt;方法&lt;/h4&gt;引入了基于遗传算法的模型进化框架（MEGA），该框架允许在训练过程中根据任务难度动态调整模型。具体而言，采用二进制序列作为基因型策略进行模型重建，并使用非梯度遗传算法优化这些基因型策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的MEGA框架通过自适应地添加模块和动态调整结构，在机器人抓取等多任务场景中实现了优越的性能表现。&lt;h4&gt;结论&lt;/h4&gt;论文证明了基于遗传算法的模型进化方法的有效性，并计划向公众开放源代码。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种新的研究方法，该方法通过采用遗传算法优化策略来改进强化学习中的多任务处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-task reinforcement learning employs a single policy to complete varioustasks, aiming to develop an agent with generalizability across differentscenarios. Given the shared characteristics of tasks, the agent's learningefficiency can be enhanced through parameter sharing. Existing approachestypically use a routing network to generate specific routes for each task andreconstruct a set of modules into diverse models to complete multiple taskssimultaneously. However, due to the inherent difference between tasks, it iscrucial to allocate resources based on task difficulty, which is constrained bythe model's structure. To this end, we propose a Model Evolution framework withGenetic Algorithm (MEGA), which enables the model to evolve during trainingaccording to the difficulty of the tasks. When the current model isinsufficient for certain tasks, the framework will automatically incorporateadditional modules, enhancing the model's capabilities. Moreover, to adapt toour model evolution framework, we introduce a genotype module-level model,using binary sequences as genotype policies for model reconstruction, whileleveraging a non-gradient genetic algorithm to optimize these genotypepolicies. Unlike routing networks with fixed output dimensions, our approachallows for the dynamic adjustment of the genotype policy length, enabling it toaccommodate models with a varying number of modules. We conducted experimentson various robotics manipulation tasks in the Meta-World benchmark. Ourstate-of-the-art performance demonstrated the effectiveness of the MEGAframework. We will release our source code to the public.</description>
      <author>example@mail.com (Yan Yu, Wengang Zhou, Yaodong Yang, Wanxuan Lu, Yingyan Hou, Houqiang Li)</author>
      <guid isPermaLink="false">2502.13569v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MILE: Model-based Intervention Learning</title>
      <link>http://arxiv.org/abs/2502.13519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Conference on Robotics and Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种模型，能够从少量专家干预中学习策略，并展示了如何在模拟环境和实际机器人任务中应用此方法。&lt;h4&gt;背景&lt;/h4&gt;模仿学习技术在现实世界的控制场景（例如机器人）中非常有效，但这些方法容易出现累积误差问题，且需要人类专家提供完整的轨迹数据。现有互动方法仅利用干预期间的数据，忽视了非干预时间步长中的反馈信号。&lt;h4&gt;目的&lt;/h4&gt;创建一种模型来描述在这种情况下如何发生干预，并展示可以通过少量的专家干预学习策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一个能够从专家反馈中获取关于当前状态质量和所选动作最优性的关键信息的方法，无论是否有干预都适用。该方法在离散和连续模拟环境、实际机器人操作任务以及人类主题研究中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;可以通过少量的专家干预学习出有效策略，并且可以利用非干预时间段中的反馈信号进行更有效的学习。&lt;h4&gt;结论&lt;/h4&gt;新的模型能够通过较少的数据实现更高效的模仿学习，为现实世界控制场景提供了改进的方法。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning techniques have been shown to be highly effective inreal-world control scenarios, such as robotics. However, these approaches notonly suffer from compounding error issues but also require human experts toprovide complete trajectories. Although there exist interactive methods wherean expert oversees the robot and intervenes if needed, these extensions usuallyonly utilize the data collected during intervention periods and ignore thefeedback signal hidden in non-intervention timesteps. In this work, we create amodel to formulate how the interventions occur in such cases, and show that itis possible to learn a policy with just a handful of expert interventions. Ourkey insight is that it is possible to get crucial information about the qualityof the current state and the optimality of the chosen action from expertfeedback, regardless of the presence or the absence of intervention. Weevaluate our method on various discrete and continuous simulation environments,a real-world robotic manipulation task, as well as a human subject study.Videos and the code can be found at https://liralab.usc.edu/mile .</description>
      <author>example@mail.com (Yigit Korkmaz, Erdem Bıyık)</author>
      <guid isPermaLink="false">2502.13519v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.13508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了VLAS，一种将语音识别直接集成到机器人策略模型中的新型端到端vision-language-action (VLA) 模型。&lt;h4&gt;背景&lt;/h4&gt;现有的VLA模型主要依赖于仅支持文本指令的视觉-语言模型(VLM)，忽略了更适合人机交互的自然语音模式。传统的语音融合方法通常涉及一个独立的语音识别系统，这会增加复杂性并引入错误传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有模型的问题，提出了一种新的端到端VLA模型（VLAS），它直接将语音识别集成到机器人策略模型中。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了VLAS，该模型可以直接理解口语指令并通过内部语音-文本对齐来生成相应的动作。2. 创建了两个新数据集SQA和CSI，支持针对语音命令的三阶段微调过程，使VLAS能够跨文本、图像、语音和机器人动作进行多模式交互。3. 设计了一个基于检索增强生成（RAG）的方法，让模型可以有效处理需要特定知识的任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VLAS能够在广泛的口语命令下有效地完成机器人操作任务，并提供无缝且个性化的交互体验。&lt;h4&gt;结论&lt;/h4&gt;提出了一种全新的VLA框架，直接在机器人策略中集成语音识别功能，显著提高了人机对话的自然性和效率。该模型能够处理多样化的语音指令并成功执行任务，开启了未来机器人和人类更紧密合作的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language-action 模型（VLAs）由于其端到端的设计和卓越性能，在机器人操作中越来越受欢迎。然而，现有的VLAs主要依赖于仅支持文本指令的视觉-语言模型（VLMs），忽略了更适合人机交互的自然语音模式。传统的语音融合方法通常涉及一个独立的语音识别系统，这会增加复杂性并引入错误传播。此外，转录过程可能会丢失原始语音中的非语义信息，例如声纹，在机器人完成定制任务时这些信息可能至关重要。为了解决上述挑战，我们提出了VLAS，一种新型端到端VLA模型，它直接将语音识别集成到机器人策略模型中。VLAS允许机器人通过内部的语音-文本对齐来理解口头命令，并生成相应动作以执行任务。我们还介绍了两个新数据集SQA和CSI，支持针对语音指令的三阶段微调过程，使VLAS能够跨文本、图像、语音和机器人操作进行多模式交互。更进一步地，设计了一种基于检索增强生成（RAG）的方法来使我们的模型可以有效处理需要特定知识的任务。广泛的实验表明，VLAS能够使用多样化的语音命令有效地完成机器人操作任务，并提供无缝且个性化的交互体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action models (VLAs) have become increasingly popular inrobot manipulation for their end-to-end design and remarkable performance.However, existing VLAs rely heavily on vision-language models (VLMs) that onlysupport text-based instructions, neglecting the more natural speech modalityfor human-robot interaction. Traditional speech integration methods usuallyinvolves a separate speech recognition system, which complicates the model andintroduces error propagation. Moreover, the transcription procedure would losenon-semantic information in the raw speech, such as voiceprint, which may becrucial for robots to successfully complete customized tasks. To overcome abovechallenges, we propose VLAS, a novel end-to-end VLA that integrates speechrecognition directly into the robot policy model. VLAS allows the robot tounderstand spoken commands through inner speech-text alignment and producescorresponding actions to fulfill the task. We also present two new datasets,SQA and CSI, to support a three-stage tuning process for speech instructions,which empowers VLAS with the ability of multimodal interaction across text,image, speech, and robot actions. Taking a step further, a voiceretrieval-augmented generation (RAG) paradigm is designed to enable our modelto effectively handle tasks that require individual-specific knowledge. Ourextensive experiments show that VLAS can effectively accomplish robotmanipulation tasks with diverse speech commands, offering a seamless andcustomized interaction experience.</description>
      <author>example@mail.com (Wei Zhao, Pengxiang Ding, Min Zhang, Zhefei Gong, Shuanghao Bai, Han Zhao, Donglin Wang)</author>
      <guid isPermaLink="false">2502.13508v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Improving Collision-Free Success Rate For Object Goal Visual Navigation Via Two-Stage Training With Collision Prediction</title>
      <link>http://arxiv.org/abs/2502.13498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了基于深度强化学习的端到端导航模型在目标物体导向视觉导航中的碰撞问题，并提出了一种两阶段训练方法来提高现有RGB观测下的导航模型的无碰撞成功率。&lt;h4&gt;背景&lt;/h4&gt;现有的深度强化学习导航模型虽然能较好地发现和到达目标对象，但在导航过程中的碰撞问题仍未解决。碰撞通常被忽略不计，在评估成功时不会对其施加负反馈，导致模型过于保守且难以有效避开障碍物。&lt;h4&gt;目的&lt;/h4&gt;引入无碰撞成功率的概念来衡量导航模型找到通往目标物体的无碰撞路径的能力，并提出一种新的两阶段训练方法以改善现有RGB观测下的导航模型的性能。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段训练策略：在第一阶段，通过监督代理人在探索过程中的碰撞状态学习预测可能发生的碰撞；在第二阶段，利用训练好的碰撞预测模块引导代理人学会在没有碰撞的情况下到达目标物体。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的两阶段训练方法能够显著提高现有导航模型的无碰撞成功率，并优于其他类似的方法。&lt;h4&gt;结论&lt;/h4&gt;新方法提高了基于深度强化学习的目标导向视觉导航系统的性能，在实际应用中可能具有更高的稳定性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;目标导向视觉导航任务是通过第一人称视角的视觉观察来定位特定目标物体。本文针对该任务中的碰撞问题提出了解决方案，即利用两阶段训练策略提高现有模型的无碰撞成功率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The object goal visual navigation is the task of navigating to a specifictarget object using egocentric visual observations. Recent end-to-endnavigation models based on deep reinforcement learning have achieved remarkableperformance in finding and reaching target objects. However, the collisionproblem of these models during navigation remains unresolved, since thecollision is typically neglected when evaluating the success. Althoughincorporating a negative reward for collision during training appearsstraightforward, it results in a more conservative policy, thereby limiting theagent's ability to reach targets. In addition, many of these models utilizeonly RGB observations, further increasing the difficulty of collision avoidancewithout depth information. To address these limitations, a new concept --collision-free success is introduced to evaluate the ability of navigationmodels to find a collision-free path towards the target object. A two-stagetraining method with collision prediction is proposed to improve thecollision-free success rate of the existing navigation models using RGBobservations. In the first training stage, the collision prediction modulesupervises the agent's collision states during exploration to learn to predictthe possible collision. In the second stage, leveraging the trained collisionprediction, the agent learns to navigate to the target without collision. Theexperimental results in the AI2-THOR environment demonstrate that the proposedmethod greatly improves the collision-free success rate of different navigationmodels and outperforms other comparable collision-avoidance methods.</description>
      <author>example@mail.com (Shiwei Lian, Feitian Zhang)</author>
      <guid isPermaLink="false">2502.13498v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Ephemerality meets LiDAR-based Lifelong Mapping</title>
      <link>http://arxiv.org/abs/2502.13452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6+2 pages, 11 figures, accepted at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ELite是一种基于LiDAR的终生地图构建框架，能够无缝地对多时段数据进行校准、移除动态物体并更新地图。&lt;h4&gt;背景&lt;/h4&gt;长期部署机器人在动态环境中的关键在于终身制图能力。常规的地图元素分类为静态或动态不能完全满足需求，例如停车的车辆需要更详细的类别划分。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够准确区分瞬时与持续性地图元素，并维护可靠、更新及时静态地图的方法。&lt;h4&gt;方法&lt;/h4&gt;通过将世界建模为两阶段$extit{ephemerality}$（瞬时性）的概率模型，该模型在两个不同的时间尺度内表示映射点的易逝性。利用瞬时性所编码的空间和时间上下文信息，ELite能够更精细地校准新数据并提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;ELite框架可以准确推断出瞬时地图元素，并维持可靠的更新静态地图。&lt;h4&gt;结论&lt;/h4&gt;该系统的有效性和鲁棒性已在长期的现实世界实验中得到了验证。开源代码可供机器人社区使用。&lt;h4&gt;翻译&lt;/h4&gt;终身制图对于在动态环境中长时间部署机器人至关重要。本文提出了ELite，一种基于LiDAR的终生映射框架，能够无缝地对多时段数据进行校准、移除动态物体并更新地图。地图元素通常被分类为静态或动态，但像停放车辆的情况表明需要比二元更详细类别的划分。我们的方法的核心是将世界建模为两阶段$extit{ephemerality}$的概率模型，它表示了映射点在两个不同时间尺度内的易逝性。通过利用瞬时性所编码的空间和时间上下文信息，ELite能够准确推断出瞬时地图元素，并维持可靠的更新静态地图，并且以更精细的方式提高新数据校准的鲁棒性。广泛的现实世界长期实验展示了我们系统的有效性和鲁棒性。开源代码可供机器人社区使用：https://github.com/dongjae0107/ELite&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifelong mapping is crucial for the long-term deployment of robots in dynamicenvironments. In this paper, we present ELite, an ephemerality-aidedLiDAR-based lifelong mapping framework which can seamlessly align multiplesession data, remove dynamic objects, and update maps in an end-to-end fashion.Map elements are typically classified as static or dynamic, but cases likeparked cars indicate the need for more detailed categories than binary. Centralto our approach is the probabilistic modeling of the world into two-stage$\textit{ephemerality}$, which represent the transiency of points in the mapwithin two different time scales. By leveraging the spatiotemporal contextencoded in ephemeralities, ELite can accurately infer transient map elements,maintain a reliable up-to-date static map, and improve robustness in aligningthe new data in a more fine-grained manner. Extensive real-world experiments onlong-term datasets demonstrate the robustness and effectiveness of our system.The source code is publicly available for the robotics community:https://github.com/dongjae0107/ELite.</description>
      <author>example@mail.com (Hyeonjae Gil, Dongjae Lee, Giseop Kim, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.13452v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.13451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为MapNav的新颖端到端视觉和语言导航模型，该模型在构建Annotated Semantic Map（ASM）时利用了语义地图来替代历史帧，并通过文本标签增强了结构化的导航信息。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉和语言导航方法依赖于大量的时空上下文存储以进行决策，导致显著的存储与计算开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型MapNav，旨在减轻传统方法中对大量历史观测数据的需求并改进性能。&lt;h4&gt;方法&lt;/h4&gt;在每次任务开始时构建一个基于顶视图的语义地图，并且随着每一步的时间步更新该地图。通过文本标签为关键区域添加明确的导航提示来生成ASM。利用VLM的强大端到端能力进行导航。&lt;h4&gt;主要发现&lt;/h4&gt;MapNav模型在模拟和真实世界环境中均表现出色，达到了最先进的性能水平。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效减少存储与计算资源需求，并且通过开放源代码和数据集进一步促进了研究的可重复性。&lt;h4&gt;贡献&lt;/h4&gt;为视觉语言导航提供了一种新的记忆表示方法，有望推动该领域未来的研究发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-and-language navigation (VLN) is a key task in Embodied AI, requiringagents to navigate diverse and unseen environments while following naturallanguage instructions. Traditional approaches rely heavily on historicalobservations as spatio-temporal contexts for decision making, leading tosignificant storage and computational overhead. In this paper, we introduceMapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map(ASM) to replace historical frames. Specifically, our approach constructs atop-down semantic map at the start of each episode and update it at eachtimestep, allowing for precise object mapping and structured navigationinformation. Then, we enhance this map with explicit textual labels for keyregions, transforming abstract semantics into clear navigation cues andgenerate our ASM. MapNav agent using the constructed ASM as input, and use thepowerful end-to-end capabilities of VLM to empower VLN. Extensive experimentsdemonstrate that MapNav achieves state-of-the-art (SOTA) performance in bothsimulated and real-world environments, validating the effectiveness of ourmethod. Moreover, we will release our ASM generation source code and dataset toensure reproducibility, contributing valuable resources to the field. Webelieve that our proposed MapNav can be used as a new memory representationmethod in VLN, paving the way for future research in this field.</description>
      <author>example@mail.com (Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu)</author>
      <guid isPermaLink="false">2502.13451v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Aware Robotic Palletization with Online Masking Inference</title>
      <link>http://arxiv.org/abs/2502.13443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种基于强化学习的方法来解决在线环境下的箱子堆放问题，这种方法考虑了盒子的物理属性，并在实际应用中证明其有效性。&lt;h4&gt;背景&lt;/h4&gt;现代仓储和物流管理中的物品堆叠计划是一个重要挑战。现有解决方案通常处理不同尺寸的盒子，但忽略它们的密度、刚度等内在和物理特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用强化学习并结合动作空间屏蔽的新方法来解决箱子堆放问题，使其更加适应实际场景的需求。&lt;h4&gt;方法&lt;/h4&gt;使用强化学习并通过动作空间掩码机制动态训练有效动作，不需要人为设计启发式规则。这种方法能够在线学习盒子的物理特性，并据此规划堆叠策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了新提出的方法在性能上超越现有的最先进算法；并且将该方法部署到一个实际应用中的机器人托盘装载机中进行测试。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于强化学习的方法有效地解决了在线环境下的箱子堆放问题，并展示了其在真实世界操作设置中的实用性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The efficient planning of stacking boxes, especially in the online settingwhere the sequence of item arrivals is unpredictable, remains a criticalchallenge in modern warehouse and logistics management. Existing solutionsoften address box size variations, but overlook their intrinsic and physicalproperties, such as density and rigidity, which are crucial for real-worldapplications. We use reinforcement learning (RL) to solve this problem byemploying action space masking to direct the RL policy toward valid actions.Unlike previous methods that rely on heuristic stability assessments which aredifficult to assess in physical scenarios, our framework utilizes onlinelearning to dynamically train the action space mask, eliminating the need formanual heuristic design. Extensive experiments demonstrate that our proposedmethod outperforms existing state-of-the-arts. Furthermore, we deploy ourlearned task planner in a real-world robotic palletizer, validating itspractical applicability in operational settings.</description>
      <author>example@mail.com (Tianqi Zhang, Zheng Wu, Yuxin Chen, Yixiao Wang, Boyuan Liang, Scott Moura, Masayoshi Tomizuka, Mingyu Ding, Wei Zhan)</author>
      <guid isPermaLink="false">2502.13443v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Generative Predictive Control: Flow Matching Policies for Dynamic and Difficult-to-Demonstrate Tasks</title>
      <link>http://arxiv.org/abs/2502.13406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新的机器人控制策略——生成式预测控制，旨在解决现有的基于行为克隆的生成政策方法在获取专家演示数据上的时间和成本问题以及处理快速动态任务时的局限性。&lt;h4&gt;背景&lt;/h4&gt;近年来，通过扩散或流匹配产生的行动序列的方法为机器人技术带来了重大进展。然而，这些方法存在两个主要限制：需要专家提供的大量时间与资金以获取高质量的演示数据，并且现有方法仅限于处理相对缓慢、准静态的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决当前生成策略局限性的新框架——生成式预测控制（Generative Predictive Control），用于处理快速动态任务，这类任务虽然难以展示但易于模拟。&lt;h4&gt;方法&lt;/h4&gt;利用采样基础的预测控制与生成模型之间的紧密联系。该论文介绍了如何在运行时通过流匹配政策进行热启动来保持时间一致性并实现快速反馈速率。&lt;h4&gt;主要发现&lt;/h4&gt;生成式预测控制能够提供一种不同于现有行为克隆方法的新途径，并有望为超越准静态任务领域的通才策略铺平道路。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种新的机器人控制框架，通过结合采样基础的预测控制和生成模型的方法来处理快速动态的任务。这种方法在理论上解决了基于演示数据的传统生成式政策的关键限制，从而开辟了未来研究的新方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成性控制策略最近为机器人技术带来了重大突破。这些方法通过扩散或流匹配产生行动序列，并利用演示数据进行训练。然而，在困难的操作问题上虽然取得了相当大的成功，但这种策略却存在两个主要限制：首先，行为克隆需要专家示范，获取起来耗时且昂贵；其次，现有方法仅限于相对缓慢、准静态的任务。在本文中，我们借助采样基础的预测控制与生成建模之间的紧密联系来解决这些问题。具体来说，我们引入了一种用于具有快速动态特性的任务的新框架——生成式预测控制（Generative Predictive Control），这些任务易于模拟但难以演示。接着展示了如何在运行时通过训练好的流匹配政策进行热启动以保持时间一致性并实现高速反馈率。我们认为，生成式预测控制为现有的行为克隆方法提供了一种互补的方法，并希望它能开启超越准静态展示导向型任务的通才策略之路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative control policies have recently unlocked major progress inrobotics. These methods produce action sequences via diffusion or flowmatching, with training data provided by demonstrations. But despite enjoyingconsiderable success on difficult manipulation problems, generative policiescome with two key limitations. First, behavior cloning requires expertdemonstrations, which can be time-consuming and expensive to obtain. Second,existing methods are limited to relatively slow, quasi-static tasks. In thispaper, we leverage a tight connection between sampling-based predictive controland generative modeling to address each of these issues. In particular, weintroduce generative predictive control, a supervised learning framework fortasks with fast dynamics that are easy to simulate but difficult todemonstrate. We then show how trained flow-matching policies can bewarm-started at run-time, maintaining temporal consistency and enabling fastfeedback rates. We believe that generative predictive control offers acomplementary approach to existing behavior cloning methods, and hope that itpaves the way toward generalist policies that extend beyond quasi-staticdemonstration-oriented tasks.</description>
      <author>example@mail.com (Vince Kurtz, Joel W. Burdick)</author>
      <guid isPermaLink="false">2502.13406v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Object-Pose Estimation With Neural Population Codes</title>
      <link>http://arxiv.org/abs/2502.13403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了机器人装配任务中物体姿态估计的问题，特别是对于避免昂贵机械约束的任务。提出了使用神经群体编码表示对象旋转的方法，克服了现有方法计算量大的问题。&lt;h4&gt;背景&lt;/h4&gt;在进行机器人的装配作业时，准确地对齐物体的姿势是必要的，特别是在需要减少机械限制成本的情况下。然而，当面对具有镜像或旋转对称性的物体时，这种对齐过程变得复杂且难以直接将感官输入映射到对象旋转上。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过引入神经网络群体编码来实现更为高效准确的物体姿态估计方法，并避免传统解决方法中大量计算开销的问题。&lt;h4&gt;方法&lt;/h4&gt;利用神经网络群体编码表示物体旋转，这使得可以直接对齐输入图像与目标旋转角度，从而能够端到端地训练模型。该方法通过概率分布预测多个假设的可能性来克服先前提出的解决方案所面临的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，在T-LESS数据集上采用灰度图像作为唯一输入的情况下，使用群体编码的模型能够在Apple M1 CPU上实现3.2毫秒内的推断速度，并达到84.7%的最大对称性感知表面距离精度。相比之下，直接映射到姿态的方法仅能达到69.7%的准确性。&lt;h4&gt;结论&lt;/h4&gt;神经网络群体编码为物体旋转提供了有效的表示方法，从而使得机器人装配任务中的对象姿态估计变得更快更准确。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经进行了中文翻译，并且上述所有项目均已根据原始英文摘要的内容进行填充。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic assembly tasks require object-pose estimation, particularly for tasksthat avoid costly mechanical constraints. Object symmetry complicates thedirect mapping of sensory input to object rotation, as the rotation becomesambiguous and lacks a unique training target. Some proposed solutions involveevaluating multiple pose hypotheses against the input or predicting aprobability distribution, but these approaches suffer from significantcomputational overhead. Here, we show that representing object rotation with aneural population code overcomes these limitations, enabling a direct mappingto rotation and end-to-end learning. As a result, population codes facilitatefast and accurate pose estimation. On the T-LESS dataset, we achieve inferencein 3.2 milliseconds on an Apple M1 CPU and a Maximum Symmetry-Aware SurfaceDistance accuracy of 84.7% using only gray-scale image input, compared to 69.7%accuracy when directly mapping to pose.</description>
      <author>example@mail.com (Heiko Hoffmann, Richard Hoffmann)</author>
      <guid isPermaLink="false">2502.13403v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Reflection of Episodes: Learning to Play Game from Expert and Self Experiences</title>
      <link>http://arxiv.org/abs/2502.13388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StarCraft II是一款复杂且动态的即时战略游戏环境，适用于人工智能和强化学习研究。为解决大型语言模型在复杂环境中通过自我反思进行学习的问题，提出了一种基于专家经验和自我经验的反射事件（ROE）框架。&lt;h4&gt;背景&lt;/h4&gt;StarCraft II是一个高度复杂的实时策略游戏环境，非常适合用于人工智能和强化学习的研究领域。&lt;h4&gt;目的&lt;/h4&gt;为了应对大型语言模型在复杂环境下通过自我反思来学习这一挑战，开发了一种新的框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于专家经验和自我经验的反射事件(ROE)框架。该框架首先通过关键帧选择法获取游戏中的关键信息，然后根据这些信息做出决策；每完成一局游戏后，进行回顾以获得新的自我经验。&lt;h4&gt;主要发现&lt;/h4&gt;实验中，我们的方法在TextStarCraft II的非常难难度下击败了机器人。&lt;h4&gt;结论&lt;/h4&gt;详细分析了大型语言模型在游戏中各个阶段的数据，验证了该方法的有效性&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; StarCraft II is a complex and dynamic real-time strategy (RTS) gameenvironment, which is very suitable for artificial intelligence andreinforcement learning research. To address the problem of Large LanguageModel(LLM) learning in complex environments through self-reflection, we proposea Reflection of Episodes(ROE) framework based on expert experience andself-experience. This framework first obtains key information in the gamethrough a keyframe selection method, then makes decisions based on expertexperience and self-experience. After a game is completed, it reflects on theprevious experience to obtain new self-experience. Finally, in the experiment,our method beat the robot under the Very Hard difficulty in TextStarCraft II.We analyze the data of the LLM in the process of the game in detail, verifiedits effectiveness.</description>
      <author>example@mail.com (Xiaojie Xu, Zongyuan Li, Chang Lu, Runnan Qi, Yanan Ni, Lumin Jiang, Xiangbei Liu, Xuebo Zhang, Yongchun Fang, Kuihua Huang, Xian Guo, Zhanghua Wu, Zhenya Li)</author>
      <guid isPermaLink="false">2502.13388v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Low-Complexity Cooperative Payload Transportation for Nonholonomic Mobile Robots Under Scalable Constraints</title>
      <link>http://arxiv.org/abs/2502.13366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;合作运输是物流网络中的一个关键环节，在这种情况下，通常使用分布式控制和基于优化的方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非完整移动机器人的合作运输方法来克服传统方法的缺点，该方法能够有效处理约束且具有可扩展性。&lt;h4&gt;方法&lt;/h4&gt;改进了传统的编队控制方式，提出了一个新型的合作运输方法。这个方法分为两个部分：机器人轨迹生成和轨迹跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的基于控制的方法不仅容易扩展到多个约束条件上，还降低了优化方法的时间复杂度，从多项式降至线性。&lt;h4&gt;结论&lt;/h4&gt;通过仿真实验验证了所提合作运输方法的可行性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种改进传统编队控制的合作运输方法的应用于非完整移动机器人领域。该方法具有分布式特性，时间复杂度低，并能适应可扩展约束条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cooperative transportation, a key aspect of logistics  cyber-physical systems (CPS), is typically approached using dis tributedcontrol and optimization-based methods. The distributed  control methods consume less time, but poorly handle and extend  to multiple constraints. Instead, optimization-based methods  handle constraints effectively, but they are usually centralized,  time-consuming and thus not easily scalable to numerous robots.  To overcome drawbacks of both, we propose a novel cooperative  transportation method for nonholonomic mobile robots by im provingconventional formation control, which is distributed, has  a low time-complexity and accommodates scalable constraints.  The proposed control-based method is testified on a cable suspended payloadand divided into two parts, including robot  trajectory generation and trajectory tracking. Unlike most time consumingtrajectory generation methods, ours can generate  trajectories with only constant time-complexity, needless of global  maps. As for trajectory tracking, our control-based method not  only scales easily to multiple constraints as those optimization basedmethods, but reduces their time-complexity from poly nomial to linear.Simulations and experiments can verify the  feasibility of our method.</description>
      <author>example@mail.com (Renhe Guan, Yuanzhe Wang, Tao Liu, Yan Wang)</author>
      <guid isPermaLink="false">2502.13366v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>BoundPlanner: A convex-set-based approach to bounded manipulator trajectory planning</title>
      <link>http://arxiv.org/abs/2502.13286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于凸集的在线轨迹规划框架，包括新的笛卡尔路径规划器BoundPlanner和扩展后的在线轨迹规划器BoundMPC。该框架能够在复杂环境中快速为机器人制定合适的轨迹，并考虑机器人的动力学限制和碰撞问题。&lt;h4&gt;背景&lt;/h4&gt;现有的许多机器人轨迹规划方法虽然适用于已知环境，但在实时计算方面效率较低，无法在具有挑战性的场景中找到满足机器人约束条件的路径。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的在线轨迹规划框架，能够为机器人制定合适的、符合其物理限制且考虑碰撞问题的路径。&lt;h4&gt;方法&lt;/h4&gt;{'BoundPlanner': '利用凸集探索和映射无障碍空间，并计算出具有边界的参考路径。', 'BoundMPC': '扩展了模型预测控制算法以处理路径偏移时的凸集合，使机器人能够在边界内最优地跟随路径并考虑其动力学特性。', '碰撞避免方法': '开发了一种独立于障碍物数量的新颖凸集基碰撞规避公式，来应对机器人连杆之间的碰撞问题。'}&lt;h4&gt;主要发现&lt;/h4&gt;在仿真和实验中验证了所提规划器的性能优于现有先进技术，并且该框架适用于具有7个自由度的机械臂。&lt;h4&gt;结论&lt;/h4&gt;新提出的轨迹规划方法能够有效解决在线环境中的挑战性问题，为机器人提供了快速反应能力和路径优化方案。源代码可在GitHub上获得，实验视频可通过提供的网站链接观看。&lt;h4&gt;翻译&lt;/h4&gt;在线轨迹规划使机器人能够迅速应对变化的工作环境或任务需求。许多现有的机器人轨迹规划器仅适用于已知环境，并且通常无法满足实时计算的要求。目前的方法在处理具有挑战性的场景时不能找到符合机器人类型限制并考虑碰撞的合适路径。本文提出了一种新的轨迹规划框架，包括基于凸集的新笛卡尔路径规划器BoundPlanner和在线轨迹规划器BoundMPC（扩展版）。BoundPlanner利用凸集合探索无障碍空间，并计算出具有边界的参考路径。BoundMPC被扩展来处理路径偏差时的凸集合问题，使机器人能够在其边界内最优地跟随路径同时考虑机器人的动力学特性。我们提出了一种新的基于凸集的碰撞规避公式独立于障碍物的数量，从而考虑到机器人连杆之间的碰撞问题。通过与最先进的方法进行比较，在一个具有7个自由度机械臂上的仿真和实验展示了所提出的规划器的表现能力。源代码可在GitHub（github.com/Thieso/BoundPlanner）上获得，并且在提供的网站链接www.acin.tuwien.ac.at/42d4可找到实验视频。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online trajectory planning enables robot manipulators to react quickly tochanging environments or tasks. Many robot trajectory planners exist for knownenvironments but are often too slow for online computations. Current methods inonline trajectory planning do not find suitable trajectories in challengingscenarios that respect the limits of the robot and account for collisions. Thiswork proposes a trajectory planning framework consisting of the novel Cartesianpath planner based on convex sets, called BoundPlanner, and the onlinetrajectory planner BoundMPC. BoundPlanner explores and maps the collision-freespace using convex sets to compute a reference path with bounds. BoundMPC isextended in this work to handle convex sets for path deviations, which allowsthe robot to optimally follow the path within the bounds while accounting forthe robot's kinematics. Collisions of the robot's kinematic chain areconsidered by a novel convex-set-based collision avoidance formulationindependent on the number of obstacles. Simulations and experiments with a7-DoF manipulator show the performance of the proposed planner compared tostate-of-the-art methods. The source code is available atgithub.com/Thieso/BoundPlanner and videos of the experiments can be found atwww.acin.tuwien.ac.at/42d4</description>
      <author>example@mail.com (Thies Oelerich, Christian Hartl-Nesic, Florian Beck, Andreas Kugi)</author>
      <guid isPermaLink="false">2502.13286v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>PCB Renewal: Iterative Reuse of PCB Substrates for Sustainable Electronic Making</title>
      <link>http://arxiv.org/abs/2502.13255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了PCB Renewal技术，该技术通过在旧PCB上选择性地沉积导电环氧树脂来擦除和重新配置电路路径，从而减少电子制造过程中的材料浪费。&lt;h4&gt;背景&lt;/h4&gt;印刷电路板（PCB）基材通常是一次性的，这导致了电子产品的材料浪费问题。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的技术——PCB Renewal，该技术能够通过沉积导电环氧树脂将旧的PCB进行改造和再利用。&lt;h4&gt;方法&lt;/h4&gt;展示了PCB Renewal的工作流程，并对其电气性能、机械耐久性进行了评估。还建立了一个软件插件来指导环氧树脂的沉积过程以及生成更新后的PCB配置文件。&lt;h4&gt;主要发现&lt;/h4&gt;通过四个设计迭代实例（包括相机滚轮、WiFi电台和ESPboy游戏控制台）展示了技术的有效性和多功能性，同时还展示了一块外包生产的双层PCB从LED手表转换为互动猫玩具的过程。&lt;h4&gt;结论&lt;/h4&gt;文章总结了该方法的局限性，并探讨了未来的研究方向。这项技术在减少材料浪费方面具有巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：PCB（印刷电路板）基材通常是一次性的，导致电子制造中的材料浪费问题。我们介绍了PCB Renewal这一新技术，它通过选择性沉积导电环氧树脂来擦除和重新配置PCB迹线，将孤立路径转变为支持新迹线的导电平面。文章展示了PCB Renewal的工作流程，并对其电气性能、机械耐久性和可持续性影响进行了评估，包括材料使用情况、成本、能源消耗和时间节省等方面。还开发了一个软件插件来指导环氧树脂沉积过程、生成更新后的PCB配置文件以及计算资源使用情况。为了证明该技术的有效性和多功能性，我们在三个项目中进行了一块PCB的四个设计迭代：相机滚轮、WiFi电台和ESPboy游戏控制台；此外，还展示了如何将一个外包生产的双层PCB从LED手表重新配置为互动猫玩具的过程。文章最后总结了限制条件并探讨了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3714276&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PCB (printed circuit board) substrates are often single-use, leading tomaterial waste in electronics making. We introduce PCB Renewal, a noveltechnique that "erases" and "reconfigures" PCB traces by selectively depositingconductive epoxy onto outdated areas, transforming isolated paths intoconductive planes that support new traces. We present the PCB Renewal workflow,evaluate its electrical performance and mechanical durability, and model itssustainability impact, including material usage, cost, energy consumption, andtime savings. We develop a software plug-in that guides epoxy deposition,generates updated PCB profiles, and calculates resource usage. To demonstratePCB Renewal's effectiveness and versatility, we repurpose a single PCB acrossfour design iterations spanning three projects: a camera roller, a WiFi radio,and an ESPboy game console. We also show how an outsourced double-layer PCB canbe reconfigured, transforming it from an LED watch to an interactive cat toy.The paper concludes with limitations and future directions.</description>
      <author>example@mail.com (Zeyu Yan, Advait Vartak, Jiasheng Li, Zining Zhang, Huaishu Peng)</author>
      <guid isPermaLink="false">2502.13255v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Soft Matter: Towards Embodied Intelligence</title>
      <link>http://arxiv.org/abs/2502.13224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;智能软物质位于材料科学、物理学和认知科学的交汇点，旨在改变我们设计与使用材料的方式。&lt;h4&gt;背景&lt;/h4&gt;传统材料通常执行静态或预定义的功能，而智能软物质能够动态地与其环境相互作用。它结合了多种感官输入，保留经验并作出决策以优化其反应。&lt;h4&gt;目的&lt;/h4&gt;通过借鉴生物系统，这些材料旨在利用柔软物质的固有属性（如灵活性、自演化和响应性）来执行模仿认知过程的功能，并展望智能软物质如何被构建。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种前瞻性的视角，讨论了设计传感、记忆与动作之间的集成以及内部低功耗操作的新途径，并探讨了具有“智能行为”的材料在实际应用中的挑战。&lt;h4&gt;结论&lt;/h4&gt;这些方法勾勒出一条通往更具鲁棒性、多功能性和可扩展性材料的道路，这种材料能够通过其固有的内在物质行为来行动、计算和“思考”，超越传统的需要外部控制的智能技术。&lt;h4&gt;翻译&lt;/h4&gt;智能软物质处于材料科学、物理学及认知科学的交汇点，承诺将改变我们设计与互动使用材料的方式。这一变革性的领域旨在创造具备生命特征能力（如感知、学习、记忆和适应性行为）的材料。与传统材料通常执行静态或预定义功能不同，智能软物质能与其环境动态交互。它融合了多种感官输入，保留经验并作出决策以优化其响应。受生物系统的启发，这些材料旨在利用柔软物质的固有属性（如灵活性、自演化及响应性）来实现模仿认知过程的功能。通过整合当前研究趋势和展望未来的发展方向，本文提供了一种前瞻性观点，即智能软物质如何构建，并意在激发包括生物医学设备和适应性机器人在内的领域的创新。文中还强调了将传感设计、记忆与动作的集成以及内部低功耗操作的新途径，并讨论了具有'智能行为'材料的实际应用挑战。这些方法描绘出了一条通往更为鲁棒、多功能及可扩展材料的道路，这种材料能够通过其内在固有的物质特性来行动、计算并“思考”，超越依赖外部控制的传统智能技术的范畴。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent soft matter stands at the intersection of materials science,physics, and cognitive science, promising to change how we design and interactwith materials. This transformative field seeks to create materials thatpossess life-like capabilities, such as perception, learning, memory, andadaptive behavior. Unlike traditional materials, which typically perform staticor predefined functions, intelligent soft matter dynamically interacts with itsenvironment. It integrates multiple sensory inputs, retains experiences, andmakes decisions to optimize its responses. Inspired by biological systems,these materials intend to leverage the inherent properties of soft matter:flexibility, self-evolving, and responsiveness to perform functions that mimiccognitive processes. By synthesizing current research trends and projectingtheir evolution, we present a forward-looking perspective on how intelligentsoft matter could be constructed, with the aim of inspiring innovations infields such as biomedical devices, adaptive robotics, and beyond. We highlightnew pathways for integrating design of sensing, memory and action with internallow-power operations and discuss challenges for practical implementation ofmaterials with "intelligent behavior". These approaches outline a path towardsto more robust, versatile and scalable materials that can potentially act,compute, and "think" by their inherent intrinsic material behaviour beyondtraditional smart technologies relying on external control.</description>
      <author>example@mail.com (Vladimir A. Baulin, Achille Giacometti, Dmitry Fedosov, Stephen Ebbens, Nydia R. Varela-Rosales, Neus Feliu, Mithun Chowdhury, Minghan Hu, Rudolf Füchslin, Marjolein Dijkstra, Matan Mussel, René van Roij, Dong Xie, Vassil Tzanov, Mengjie Zu, Samuel Hidalgo-Caballero, Ye Yuan, Luca Cocconi, Cheol-Min Ghim, Cécile Cottin-Bizonne, M. Carmen Miguel, Maria Jose Esplandiu, Juliane Simmchen, Wolfgang J. Parak, Marco Werner, Gerhard Gompper, Martin M. Hanczyc)</author>
      <guid isPermaLink="false">2502.13224v1</guid>
      <pubDate>Thu, 20 Feb 2025 16:54:09 +0800</pubDate>
    </item>
    <item>
      <title>ReStyle3D: Scene-Level Appearance Transfer with Semantic Correspondences</title>
      <link>http://arxiv.org/abs/2502.10377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://restyle3d.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种名为ReStyle3D的新框架，用于从单张风格图像到多视图表示的真实世界场景的场景级别外观转换。&lt;h4&gt;背景&lt;/h4&gt;现有的风格化方法通常以全局方式应用参考样式，这可能导致语义不匹配和多视角一致性问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架来实现更精确、一致且语义忠实的场景级风格转移。&lt;h4&gt;方法&lt;/h4&gt;{'开放词汇分割': '用于在风格图像和真实世界图像之间建立密集、实例级别的对应关系，确保每个对象都使用语义匹配的纹理进行样式化。', '训练自由机制': '首先在一个扩散模型中通过语义注意力机制将风格转移到单个视图上。', '学习网络': '然后通过一个受单眼深度和像素级对应信息指导的学习变形并细化网络，将风格提升到额外的视角。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'结构保存': 'ReStyle3D在结构保持、感知样式相似性和多视角一致性方面优于先前的方法。', '用户研究': '进一步验证了其生成逼真且语义忠实的结果的能力。'}&lt;h4&gt;结论&lt;/h4&gt;代码、预训练模型和数据集将公开发布，以支持室内设计、虚拟布景以及3D一致风格化的新应用。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为ReStyle3D的新型框架，用于从单张样式图像向由多视角表示的真实世界场景进行场景级外观转移。该方法结合了显式的语义对应与多视图一致性来实现精确且连贯的风格化。不同于传统的将参考样式全局应用的方法，ReStyle3D使用开放词汇分割在风格和真实世界图像之间建立了密集、实例级别的对应关系，确保每个对象都用语义匹配的纹理进行样式化。它首先在一个训练自由的语义注意力机制中通过扩散模型将样式转移到单个视图上，并随后通过受单眼深度和像素级对应信息指导的学习变形并细化网络提升到额外视图。实验表明，在结构保持、感知风格相似性和多视角一致性方面，ReStyle3D优于先前的方法。用户研究进一步验证了其生成逼真且语义忠实结果的能力。我们的代码、预训练模型以及数据集将公开发布以支持室内设计、虚拟布景及3D一致的样式化的新应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ReStyle3D, a novel framework for scene-level appearance transferfrom a single style image to a real-world scene represented by multiple views.The method combines explicit semantic correspondences with multi-viewconsistency to achieve precise and coherent stylization. Unlike conventionalstylization methods that apply a reference style globally, ReStyle3D usesopen-vocabulary segmentation to establish dense, instance-level correspondencesbetween the style and real-world images. This ensures that each object isstylized with semantically matched textures. It first transfers the style to asingle view using a training-free semantic-attention mechanism in a diffusionmodel. It then lifts the stylization to additional views via a learnedwarp-and-refine network guided by monocular depth and pixel-wisecorrespondences. Experiments show that ReStyle3D consistently outperforms priormethods in structure preservation, perceptual style similarity, and multi-viewcoherence. User studies further validate its ability to producephoto-realistic, semantically faithful results. Our code, pretrained models,and dataset will be publicly released, to support new applications in interiordesign, virtual staging, and 3D-consistent stylization.</description>
      <author>example@mail.com (Liyuan Zhu, Shengqu Cai, Shengyu Huang, Gordon Wetzstein, Naji Khosravan, Iro Armeni)</author>
      <guid isPermaLink="false">2502.10377v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
  <item>
      <title>Pre-training Auto-regressive Robotic Models with 4D Representations</title>
      <link>http://arxiv.org/abs/2502.13142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了一种新的自动回归机器人模型ARM4R，它利用从人类视频数据中学习到的低级4D表示来预训练更优的机器人模型。&lt;h4&gt;背景&lt;/h4&gt;大规模未标记的数据集预先训练的基石模型已经在自然语言和计算机视觉领域引发了革命性的变化，并展示了出色的泛化能力，这突显了预训练的重要性。然而，在机器人技术方面的努力却难以取得类似的成功，受到高昂的人工注释成本或缺乏有效建模物理世界的表示形式限制。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的自动回归机器人模型ARM4R，利用人类视频数据中的低级4D表示来改进机器人的预训练。&lt;h4&gt;方法&lt;/h4&gt;通过单目深度估计从时间上提升2D表示到3D空间中获取的点跟踪表示，这些4D表示在点和机器人状态之间保持了一致的几何结构。这种方法使人类视频数据的有效转移学习到低级机器人控制成为可能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明ARM4R能够有效地将从人类视频数据转移到机器人，并且能在各种环境和配置下的任务中持续提高性能。&lt;h4&gt;结论&lt;/h4&gt;ARM4R提供了一种新的途径来利用大规模的人类视频数据进行机器人的预训练，这有助于解决当前机器人技术面临的挑战。&lt;h4&gt;翻译&lt;/h4&gt;基石模型在大量未标记的数据集上预先训练，在自然语言处理和计算机视觉领域引发了革命性的变化，并展示了卓越的泛化能力。然而，机器人领域的研究努力却难以取得同样的成功，受限于昂贵的人工注释成本或无法有效建模物理世界的表示方法。本文提出了一种新的自动回归机器人模型ARM4R，它利用从人类视频数据中学习到的低级4D表示来预训练更优的机器人模型。实验表明，这种模型能够高效地将知识从人类视频转移到机器人的控制任务上，并在多种机器人环境和配置下持续提升性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models pre-trained on massive unlabeled datasets haverevolutionized natural language and computer vision, exhibiting remarkablegeneralization capabilities, thus highlighting the importance of pre-training.Yet, efforts in robotics have struggled to achieve similar success, limited byeither the need for costly robotic annotations or the lack of representationsthat effectively model the physical world. In this paper, we introduce ARM4R,an Auto-regressive Robotic Model that leverages low-level 4D Representationslearned from human video data to yield a better pre-trained robotic model.Specifically, we focus on utilizing 3D point tracking representations fromvideos derived by lifting 2D representations into 3D space via monocular depthestimation across time. These 4D representations maintain a shared geometricstructure between the points and robot state representations up to a lineartransformation, enabling efficient transfer learning from human video data tolow-level robotic control. Our experiments show that ARM4R can transferefficiently from human video data to robotics and consistently improvesperformance on tasks across various robot environments and configurations.</description>
      <author>example@mail.com (Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roei Herzig)</author>
      <guid isPermaLink="false">2502.13142v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Databases: A Survey</title>
      <link>http://arxiv.org/abs/2502.12908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A survey focus on GNNs and databases. 9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了图神经网络（GNN）在数据库系统中的应用，并提出了一个新的分类体系。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络因其处理图结构数据的强大能力，在各个领域展现了显著的成功。数据库社区也逐渐认识到GNN的潜力，并涌现出大量研究试图通过基于GNN的方法改进数据库系统。&lt;h4&gt;目的&lt;/h4&gt;为了填补现有研究中关于如何利用GNN提升数据库系统的全面理解和综述这一空白，本调查旨在提供一个结构化且深入的概览。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的分类体系将现有的方法分为两大类：关系型数据库和图形数据库，并对每一类别中的关键技术进行了系统性回顾。&lt;h4&gt;主要发现&lt;/h4&gt;分别总结了每种类型的方法及其贡献与实际应用，指出了在关系型数据库中包括性能预测、查询优化以及文本到SQL任务等，在图数据库中则涉及高效图查询处理及相似度计算等领域面临的挑战和解决方案。&lt;h4&gt;结论&lt;/h4&gt;本论文建议了一些有前景的途径，旨在将GNN更深入地集成到数据库系统当中。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）是用于图形结构数据的强大深度学习模型，在各个领域展示出了显著的成功。近年来，数据库社区逐渐认识到GNN的巨大潜力，因此越来越多的研究关注通过基于GNN的方法改进数据库系统。然而，尽管已经取得了可观的进步，关于如何利用GNN提升数据库系统的全面理解仍然不足。因此，本文旨在填补这一空白，提供一个结构化和深入的综述。具体而言，我们提出了一种新的分类体系，将现有的方法分为两类：关系型数据库（包括性能预测、查询优化和文本到SQL任务）以及图形数据库（解决高效图查询处理和相似性计算等挑战）。系统地回顾了每个类别中的关键方法，并强调了它们的贡献和实际意义。最后，我们建议了一些有前景的方法，以将GNN更好地融入到数据库系统中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful deep learning models forgraph-structured data, demonstrating remarkable success across diverse domains.Recently, the database (DB) community has increasingly recognized thepotentiality of GNNs, prompting a surge of researches focusing on improvingdatabase systems through GNN-based approaches. However, despite notableadvances, There is a lack of a comprehensive review and understanding of howGNNs could improve DB systems. Therefore, this survey aims to bridge this gapby providing a structured and in-depth overview of GNNs for DB systems.Specifically, we propose a new taxonomy that classifies existing methods intotwo key categories: (1) Relational Databases, which includes tasks likeperformance prediction, query optimization, and text-to-SQL, and (2) GraphDatabases, addressing challenges like efficient graph query processing andgraph similarity computation. We systematically review key methods in eachcategory, highlighting their contributions and practical implications. Finally,we suggest promising avenues for integrating GNNs into Database systems.</description>
      <author>example@mail.com (Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang)</author>
      <guid isPermaLink="false">2502.12908v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.13071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种鲁棒的雷达-相机3D目标检测模型，以应对环境和固有干扰。&lt;h4&gt;背景&lt;/h4&gt;低成本雷达-相机方法在多模态3D对象检测中表现出色，但这些传感器面临着来自环境（如光线或天气条件）以及内在因素（如噪声、位置模糊性）的挑战。为了实现鲁棒的雷达-相机3D目标检测，在各种条件下保持一致性能的要求尚未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;首次系统分析了雷达-相机在五种不同噪音下的稳健性，并提出了一个新颖的鲁棒对象检测模型RobuRCDet，该模型适用于基于鸟瞰图（BEV）中的3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;设计了一种3DGaussian Expansion (3DGE)模块来减少雷达点错误，包括位置、雷达截面(RCS)和速度。此外，引入了一个天气自适应融合模块，根据相机信号信心进行雷达与摄像头特征的动态融合。&lt;h4&gt;主要发现&lt;/h4&gt;RobuRCDet模型在常规条件和有噪声条件下均表现出竞争力的结果，在nuScenes基准测试中尤其有效。&lt;h4&gt;结论&lt;/h4&gt;该研究为克服环境干扰带来的挑战提供了新的视角，并通过3DGE模块和天气自适应融合机制，显著提高了雷达-相机目标检测的准确性与鲁棒性。未来工作可能继续探索更多稳健策略以进一步提高性能。&lt;h4&gt;翻译&lt;/h4&gt;最近低成本的雷达-相机方法在多模态三维物体检测中显示了令人鼓舞的结果，但是这些传感器都面临着环境和固有干扰的问题。不良照明或恶劣天气条件会降低摄像机的表现，而雷达则遭受噪声和位置模糊性的困扰。为了实现鲁棒的雷达-相机3D目标检测，在各种条件下保持一致性能的要求尚未被充分探索。在这项工作中，我们首先对五种不同噪音下的雷达-相机检测进行了系统分析，并提出了一种名为RobuRCDet的新鲁棒物体检测模型，该模型适用于基于鸟瞰图（BEV）中的3D物体检测。特别地，我们设计了一个三维高斯扩展模块（3DGaussian Expansion, 3DGE），用于减少雷达点的不准确性包括位置、雷达截面（RCS）、和速度方面的错误。这个3DGE使用了RCS和速度的先验知识来生成可变形核图并调整内核大小以进行值分布调节。此外，我们引入了一个天气适应性融合模块，能够根据相机信号信心动态地融合雷达与摄像头特征。在流行基准nuScenes上进行的大量实验表明，我们的模型即使在常规和有噪声条件下也能实现具有竞争力的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent low-cost radar-camera approaches have shown promising results inmulti-modal 3D object detection, both sensors face challenges fromenvironmental and intrinsic disturbances. Poor lighting or adverse weatherconditions degrade camera performance, while radar suffers from noise andpositional ambiguity. Achieving robust radar-camera 3D object detectionrequires consistent performance across varying conditions, a topic that has notyet been fully explored. In this work, we first conduct a systematic analysisof robustness in radar-camera detection on five kinds of noises and proposeRobuRCDet, a robust object detection model in BEV. Specifically, we design a 3DGaussian Expansion (3DGE) module to mitigate inaccuracies in radar points,including position, Radar Cross-Section (RCS), and velocity. The 3DGE uses RCSand velocity priors to generate a deformable kernel map and variance for kernelsize adjustment and value distribution. Additionally, we introduce aweather-adaptive fusion module, which adaptively fuses radar and camerafeatures based on camera signal confidence. Extensive experiments on thepopular benchmark, nuScenes, show that our model achieves competitive resultsin regular and noisy conditions.</description>
      <author>example@mail.com (Jingtong Yue, Zhiwei Lin, Xin Lin, Xiaoyu Zhou, Xiangtai Li, Lu Qi, Yongtao Wang, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2502.13071v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Circuit Representation Learning with Masked Gate Modeling and Verilog-AIG Alignment</title>
      <link>http://arxiv.org/abs/2502.12732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了MGVGA，一种新的约束掩码建模范式，旨在解决电路表示学习中的逻辑等价性问题，并促进从大语言模型中学习电路功能。&lt;h4&gt;背景&lt;/h4&gt;理解电路结构和功能对于电子设计自动化（EDA）至关重要。将电路作为And-Inverter图（AIG）进行建模有助于通过图神经网络（GNNs）实现高效的表示学习，而掩码建模方法已被证明在图表示学习中有效。&lt;h4&gt;目的&lt;/h4&gt;解决现有掩码建模范式破坏逻辑等价性和忽略抽象信息如电路功能的问题，并引入一种新的约束掩码建模方法，该方法能够从大语言模型获取电路的功能知识。&lt;h4&gt;方法&lt;/h4&gt;MGVGA结合了掩码门模型（MGM）和Verilog-AIG对齐（VGA）。MGM通过在隐空间而非原始电路中进行掩码来保持逻辑等价性，并随后重构这些被掩码的门的属性。而VGA则利用大语言模型理解Verilog代码功能的能力，执行原始电路中的掩码操作并在等效Verilog代码约束下重构被掩码的门。&lt;h4&gt;主要发现&lt;/h4&gt;MGVGA在各种逻辑综合任务上表现出优于现有最佳方法的性能。&lt;h4&gt;结论&lt;/h4&gt;通过将MGM和VGA结合使用，实现了更有效的电路表示学习，并证明了这种方法对EDA领域的影响。&lt;h4&gt;翻译&lt;/h4&gt;理解电路结构和功能对于电子设计自动化（EDA）至关重要。电路可以被表述为And-Inverter图（AIG），从而可以通过图神经网络（GNNs）实现高效的表示学习。掩码建模范式已被证明在图表示学习中有效，但是对原始电路进行掩码操作会破坏其逻辑等价性，这不适合用于电路表示学习。此外，现有的掩码建模方法往往优先考虑结构信息而牺牲了如电路功能的抽象信息。为了解决这些限制，我们引入了一种新的约束掩码建模范式MGVGA，它结合了掩码门模型（MGM）和Verilog-AIG对齐（VGA）。具体来说，MGM通过在隐空间中而不是原始电路里进行掩码操作来保持逻辑等价性，并随后重构被掩码的门属性。同时，大型语言模型已经展示了它们理解Verilog代码功能的良好能力。基于这种能力，VGA执行原始电路中的掩码操作，并根据等效Verilog代码约束条件重构掩码后的门，使得GNNs可以从大语言模型中学习到电路的功能。我们在各种逻辑综合任务上评估了MGVGA在EDA上的表现，并显示出其优于先前最先进的方法的性能优势。我们的代码可在https://github.com/wuhy68/MGVGA获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the structure and function of circuits is crucial forelectronic design automation (EDA). Circuits can be formulated as And-Invertergraphs (AIGs), enabling efficient implementation of representation learningthrough graph neural networks (GNNs). Masked modeling paradigms have beenproven effective in graph representation learning. However, maskingaugmentation to original circuits will destroy their logical equivalence, whichis unsuitable for circuit representation learning. Moreover, existing maskedmodeling paradigms often prioritize structural information at the expense ofabstract information such as circuit function. To address these limitations, weintroduce MGVGA, a novel constrained masked modeling paradigm incorporatingmasked gate modeling (MGM) and Verilog-AIG alignment (VGA). Specifically, MGMpreserves logical equivalence by masking gates in the latent space rather thanin the original circuits, subsequently reconstructing the attributes of thesemasked gates. Meanwhile, large language models (LLMs) have demonstrated anexcellent understanding of the Verilog code functionality. Building upon thiscapability, VGA performs masking operations on original circuits andreconstructs masked gates under the constraints of equivalent Verilog codes,enabling GNNs to learn circuit functions from LLMs. We evaluate MGVGA onvarious logic synthesis tasks for EDA and show the superior performance ofMGVGA compared to previous state-of-the-art methods. Our code is available athttps://github.com/wuhy68/MGVGA.</description>
      <author>example@mail.com (Haoyuan Wu, Haisheng Zheng, Yuan Pu, Bei Yu)</author>
      <guid isPermaLink="false">2502.12732v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>FedHC: A Hierarchical Clustered Federated Learning Framework for Satellite Networks</title>
      <link>http://arxiv.org/abs/2502.12783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种层级聚类联邦学习框架FedHC，旨在解决卫星网络中大数据处理的性能、能耗和时间效率问题。&lt;h4&gt;背景&lt;/h4&gt;随着数据驱动服务的增长，需要通过卫星网络处理的数据量显著增加。在分布式且资源受限的环境中，联邦学习非常适合于大型数据处理，但如何确保其收敛性的同时减少计算时间和能量消耗是挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架FedHC以优化卫星网络中的联邦学习过程，同时保持模型准确性。&lt;h4&gt;方法&lt;/h4&gt;采用卫星聚类参数服务器（PS）选择算法，在簇聚合阶段将附近卫星分为不同的簇，并指定每个簇的中心作为PS加速模型聚合。引入元学习驱动的卫星再聚类算法来增强对动态卫星集群变化的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与比较方法相比，FedHC框架可以显著减少处理时间（最多3倍）和能耗（最多2倍），同时保持模型准确性。&lt;h4&gt;结论&lt;/h4&gt;所提出的FedHC框架通过优化参数服务器的选择和增强对动态环境的适应性，在卫星网络中实现了更高效的联邦学习过程。&lt;h4&gt;翻译&lt;/h4&gt;随着数据驱动服务的增长，需要通过卫星网络处理的数据量显著增加。在分布式且资源受限的环境中，联邦学习非常适合于大型数据处理，但如何确保其收敛性的同时减少计算时间和能量消耗是挑战。为此，我们提出了一种层级聚类联邦学习框架FedHC。此框架使用了集群聚合阶段的卫星群集参数服务器（PS）选择算法，将附近的卫星分组为不同的簇，并指定一个簇中心作为PS来加速模型聚合。然后通过地面站选出几个能够通信的簇PS卫星以聚集全局参数，从而促进联邦学习过程。此外，还引入了一种基于元学习驱动的卫星再聚类算法，增强对动态卫星集群变化的适应性。在卫星网络实验平台上的大量试验表明，FedHC可以在保持模型准确性的前提下，与其它比较方法相比显著减少处理时间（最多3倍）和能耗（最多2倍）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the proliferation of data-driven services, the volume of data that needsto be processed by satellite networks has significantly increased. Federatedlearning (FL) is well-suited for big data processing in distributed,resource-constrained satellite environments. However, ensuring its convergenceperformance while minimizing processing time and energy consumption remains achallenge. To this end, we propose a hierarchical clustered federated learningframework, FedHC. This framework employs a satellite-clustered parameter server(PS) selection algorithm at the cluster aggregation stage, grouping nearbysatellites into distinct clusters and designating a cluster center as the PS toaccelerate model aggregation. Several communicable cluster PS satellites arethen selected through ground stations to aggregate global parameters,facilitating the FL process. Moreover, a meta-learning-driven satellitere-clustering algorithm is introduced to enhance adaptability to dynamicsatellite cluster changes. The extensive experiments on satellite networkstestbed demonstrate that FedHC can significantly reduce processing time (up to3x) and energy consumption (up to 2x) compared to other comparative methodswhile maintaining model accuracy.</description>
      <author>example@mail.com (Zhuocheng Liu, Zhishu Shen, Pan Zhou, Qiushi Zheng, Jiong Jin)</author>
      <guid isPermaLink="false">2502.12783v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Diverse Human Preference Learning through Principal Component Analysis</title>
      <link>http://arxiv.org/abs/2502.13131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;理解人类偏好对于改进基础模型和构建个性化AI系统至关重要。&lt;h4&gt;背景&lt;/h4&gt;由于偏好的多样性和复杂性，传统奖励模型难以捕捉其全部范围。收集精细粒度的偏好数据虽然有助于改善这一状况，但成本高昂且难以扩展。&lt;h4&gt;目的&lt;/h4&gt;介绍Decomposed Reward Models (DRMs)——一种新颖的方法，能够从二元比较中提取多样的人类偏好，无需细粒度标注。&lt;h4&gt;方法&lt;/h4&gt;将人类偏好表示为向量，并使用主成分分析（PCA）进行分析。通过构建首选和拒绝响应之间嵌入差异的数据集，DRM识别出能捕获不同偏好方面的正交基向量。&lt;h4&gt;主要发现&lt;/h4&gt;分解后的奖励可以灵活组合以适应不同的用户需求，并且能够提取有意义的偏好维度（如有用性、安全性、幽默等），并适应新用户而无需额外训练。&lt;h4&gt;结论&lt;/h4&gt;DRM为个性化和可解释的LLM对齐提供了一个强大的框架，展示出其在理解和应用人类偏好的潜力。&lt;h4&gt;翻译&lt;/h4&gt;理解人类偏好对于改进基础模型和构建个性化的AI系统至关重要。由于偏好具有多样性和复杂性，传统奖励模型难以完全捕捉这些特点。收集精细粒度的偏好数据虽然有所帮助，但成本高且扩展困难。为此，本文提出了一种新方法——Decomposed Reward Models (DRMs)，能够从二元比较中提取多样的人类偏好而无需细粒度标注。通过将偏好表示为向量并使用PCA分析来识别捕捉不同偏好的正交基向量。研究结果显示该模型可以灵活组合奖励以适应用户需求，并能有效提取有意义的偏好维度如有用性、安全性及幽默等，还能够适应新用户而不需要额外训练，表明DRM框架在个性化和可解释性的LLM对齐中有强大的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding human preferences is crucial for improving foundation modelsand building personalized AI systems. However, preferences are inherentlydiverse and complex, making it difficult for traditional reward models tocapture their full range. While fine-grained preference data can help,collecting it is expensive and hard to scale. In this paper, we introduceDecomposed Reward Models (DRMs), a novel approach that extracts diverse humanpreferences from binary comparisons without requiring fine-grained annotations.Our key insight is to represent human preferences as vectors and analyze themusing Principal Component Analysis (PCA). By constructing a dataset ofembedding differences between preferred and rejected responses, DRMs identifyorthogonal basis vectors that capture distinct aspects of preference. Thesedecomposed rewards can be flexibly combined to align with different user needs,offering an interpretable and scalable alternative to traditional rewardmodels. We demonstrate that DRMs effectively extract meaningful preferencedimensions (e.g., helpfulness, safety, humor) and adapt to new users withoutadditional training. Our results highlight DRMs as a powerful framework forpersonalized and interpretable LLM alignment.</description>
      <author>example@mail.com (Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen)</author>
      <guid isPermaLink="false">2502.13131v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Detection and Geographic Localization of Natural Objects in the Wild: A Case Study on Palms</title>
      <link>http://arxiv.org/abs/2502.13023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一种用于在密集热带森林中检测和定位棕榈的灵活管道，基于大尺度正射影像图，该系统通过集成最先进的对象检测器以及零样本SAM进行分割，并优化地理映射。&lt;h4&gt;背景&lt;/h4&gt;棕榈是衡量热带雨林健康、生物多样性和人类影响的重要指标，对地方经济和全球森林产品供应链有重要支持作用。但是，在密集的自然森林中检测棕榈仍然受限于重叠树冠、不均匀阴影和异质景观。&lt;h4&gt;目的&lt;/h4&gt;开发一种用于在复杂环境中准确检测和定位棕榈的技术方案，并建立一个大规模的数据集用于该技术方案的训练与评估。&lt;h4&gt;方法&lt;/h4&gt;1. 建立了一个基于无人机收集的大规模正射影像数据集，包含来自21个生态多样性地区共8,830个边界框以及5,026个棕榈中心点。2. 评价了多个最先进的对象检测器，并将零样本SAM集成作为分割骨干网。3. 应用校准方法来对齐置信分数和IoU，同时探索显著性地图以提高特征解释性。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM通过优化的管道可以更精确地在密集热带森林中定位棕榈，并且这种方法具有识别其他自然对象（如东部白松）的能力。此外，未来的工作将探索较低分辨率数据集（0.5到1米）上的迁移学习方法。&lt;h4&gt;结论&lt;/h4&gt;PRISM为解决密集森林中的复杂检测问题提供了一个有效的解决方案，不仅限于棕榈的检测，还可以应用于多种自然物体的识别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Palms are ecologically and economically indicators of tropical forest health,biodiversity, and human impact that support local economies and global forestproduct supply chains. While palm detection in plantations is well-studied,efforts to map naturally occurring palms in dense forests remain limited byoverlapping crowns, uneven shading, and heterogeneous landscapes. We developPRISM (Processing, Inference, Segmentation, and Mapping), a flexible pipelinefor detecting and localizing palms in dense tropical forests using largeorthomosaic images. Orthomosaics are created from thousands of aerial imagesand spanning several to hundreds of gigabytes. Our contributions are threefold.First, we construct a large UAV-derived orthomosaic dataset collected across 21ecologically diverse sites in western Ecuador, annotated with 8,830 boundingboxes and 5,026 palm center points. Second, we evaluate multiplestate-of-the-art object detectors based on efficiency and performance,integrating zero-shot SAM 2 as the segmentation backbone, and refining theresults for precise geographic mapping. Third, we apply calibration methods toalign confidence scores with IoU and explore saliency maps for featureexplainability. Though optimized for palms, PRISM is adaptable for identifyingother natural objects, such as eastern white pines. Future work will exploretransfer learning for lower-resolution datasets (0.5 to 1m).</description>
      <author>example@mail.com (Kangning Cui, Rongkun Zhu, Manqi Wang, Wei Tang, Gregory D. Larsen, Victor P. Pauca, Sarra Alqahtani, Fan Yang, David Segurado, David Lutz, Jean-Michel Morel, Miles R. Silman)</author>
      <guid isPermaLink="false">2502.13023v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Power Grid Inspections with Machine Learning</title>
      <link>http://arxiv.org/abs/2502.13037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用3D计算机视觉技术来自动化电力网络检查的方法，通过处理TS40K数据集中的点云信息，提高了对关键电网组件如电线和塔的检测准确率。&lt;h4&gt;背景&lt;/h4&gt;随着全球能源需求的增长，确保电力网的安全性和可靠性变得至关重要。传统的手动观察或直升机巡查方法资源消耗大且不具备扩展性。&lt;h4&gt;目的&lt;/h4&gt;探索使用3D计算机视觉技术来自动化电力网络检查的方法，提高电网维护工作的效率，并实现主动风险管理策略。&lt;h4&gt;方法&lt;/h4&gt;利用TS40K数据集进行研究，该数据集是一个高密度、标注完整的3D LiDAR点云集合。通过集中于3D语义分割，解决了类别不平衡和噪声数据的问题。&lt;h4&gt;主要发现&lt;/h4&gt;基准测试结果表明性能有了显著的提高，使用基于转换器的模型检测电线时交并比（IoU）得分达到了95.53%。&lt;h4&gt;结论&lt;/h4&gt;研究展示了将机器学习集成到电网维护工作流程中的巨大潜力，提高了效率，并支持了主动的风险管理策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety and reliability of power grids is critical as globalenergy demands continue to rise. Traditional inspection methods, such as manualobservations or helicopter surveys, are resource-intensive and lackscalability. This paper explores the use of 3D computer vision to automatepower grid inspections, utilizing the TS40K dataset -- a high-density,annotated collection of 3D LiDAR point clouds. By concentrating on 3D semanticsegmentation, our approach addresses challenges like class imbalance and noisydata to enhance the detection of critical grid components such as power linesand towers. The benchmark results indicate significant performanceimprovements, with IoU scores reaching 95.53% for the detection of power linesusing transformer-based models. Our findings illustrate the potential forintegrating ML into grid maintenance workflows, increasing efficiency andenabling proactive risk management strategies.</description>
      <author>example@mail.com (Diogo Lavado, Ricardo Santos, Andre Coelho, Joao Santos, Alessandra Micheletti, Claudia Soares)</author>
      <guid isPermaLink="false">2502.13037v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NTP-INT: Network Traffic Prediction-Driven In-band Network Telemetry for High-load Switches</title>
      <link>http://arxiv.org/abs/2502.12834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;入带网络遥测（INT）在网络管理中至关重要，因为它提供了实时可见性。然而，由于网络设备和服务的迅速增加，在动态网络环境中进行有针对性地访问详细网络信息已成为必要。本文提出了一种智能网络遥测系统NTP-INT，用于获取高负载交换机上的更细化的网络信息。具体而言，NTP-INT由三个模块组成：网络流量预测模块、网络修剪模块和探针路径规划模块。首先，网络流量预测模块采用多时间图神经网络（MTGNN）来预测未来的网络流量并识别出高负载交换机。然后，我们设计了一种网络修剪算法以生成一个覆盖所有高负载交换机的子网，从而降低探针路径规划的复杂度。最后，探针路径规划模块使用基于注意力机制的深度强化学习（DEL）模型在网络切片中规划有效的探针路径。实验结果表明，NTP-INT可以在减少控制开销50%的同时获取更精确的高负载交换机网络信息。&lt;h4&gt;背景&lt;/h4&gt;随着网络设备和服务的增长，需要在动态环境中访问详细的实时网络信息&lt;h4&gt;目的&lt;/h4&gt;提出一种智能网络遥测系统NTP-INT以获取高负载交换机上的详细和精确的信息并减少控制开销&lt;h4&gt;方法&lt;/h4&gt;{'模块组成': ['网络流量预测模块', '网络修剪模块', '探针路径规划模块'], '网络流量预测模块': '采用多时间图神经网络（MTGNN）进行未来的网络流量预测，并识别高负载交换机', '网络修剪算法': '设计用于生成一个覆盖所有高负载交换机的子网，以简化探针路径规划过程', '探针路径规划模块': '使用基于注意力机制的深度强化学习模型在网络切片中规划有效的探针路径'}&lt;h4&gt;主要发现&lt;/h4&gt;NTP-INT可以获取高负载交换机上的更精确网络信息，并将控制开销减少50%&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-band network telemetry (INT) is essential to network management due to itsreal-time visibility. However, because of the rapid increase in network devicesand services, it has become crucial to have targeted access to detailed networkinformation in a dynamic network environment. This paper proposes anintelligent network telemetry system called NTP-INT to obtain more fine-grainednetwork information on high-load switches. Specifically, NTP-INT consists ofthree modules: network traffic prediction module, network pruning module, andprobe path planning module. Firstly, the network traffic prediction moduleadopts a Multi-Temporal Graph Neural Network (MTGNN) to predict future networktraffic and identify high-load switches. Then, we design the network pruningalgorithm to generate a subnetwork covering all high-load switches to reducethe complexity of probe path planning. Finally, the probe path planning moduleuses an attention-mechanism-based deep reinforcement learning (DEL) model toplan efficient probe paths in the network slice. The experimental resultsdemonstrate that NTP-INT can acquire more precise network information onhigh-load switches while decreasing the control overhead by 50\%.</description>
      <author>example@mail.com (Penghui Zhang, Hua Zhang, Yuqi Dai, Cheng Zeng, Jingyu Wang, Jianxin Liao)</author>
      <guid isPermaLink="false">2502.12834v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image</title>
      <link>http://arxiv.org/abs/2502.12894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://sites.google.com/view/cast4&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CAST是一种从单张RGB图像中重建高质量3D场景的新方法，解决了现有方法在特定领域限制和低质量物体生成上的问题。&lt;h4&gt;背景&lt;/h4&gt;从单张RGB图像恢复高保真度的3D场景是计算机图形学中的一个挑战性任务。当前的方法往往受限于特定领域的局限性和低质量的对象生成。&lt;h4&gt;目的&lt;/h4&gt;提出CAST，以解决现有方法在重建高质量3D场景时遇到的问题，并提供一种更有效的解决方案。&lt;h4&gt;方法&lt;/h4&gt;{'步骤一': '提取输入图像中的对象级2D分割和相对深度信息', '步骤二': '使用基于GPT的模型分析物体间的空间关系', '步骤三': '利用一个感知遮挡的大规模3D生成模型独立生成每个物体的完整几何形状，通过MAE和点云条件来缓解遮挡和部分对象信息的影响', '步骤四': '计算必要的转换以将生成的网格精确放置并整合到场景的点云中', '步骤五': '利用一个基于物理感知的修正步骤来优化对象姿态，并确保它们在空间上的一致性和连贯性'}&lt;h4&gt;主要发现&lt;/h4&gt;通过使用符号距离场(SDF)，该模型有效解决了遮挡、物体穿透和漂浮物等问题，使生成的场景能够准确地反映现实世界中的物理相互作用。&lt;h4&gt;结论&lt;/h4&gt;CAST可以在机器人技术领域中得到应用，用于高效的从真实到模拟的工作流程，并提供给机器人系统一个现实且可扩展的仿真环境。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的内容已经用中文进行了总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering high-quality 3D scenes from a single RGB image is a challengingtask in computer graphics. Current methods often struggle with domain-specificlimitations or low-quality object generation. To address these, we propose CAST(Component-Aligned 3D Scene Reconstruction from a Single RGB Image), a novelmethod for 3D scene reconstruction and recovery. CAST starts by extractingobject-level 2D segmentation and relative depth information from the inputimage, followed by using a GPT-based model to analyze inter-object spatialrelationships. This enables the understanding of how objects relate to eachother within the scene, ensuring more coherent reconstruction. CAST thenemploys an occlusion-aware large-scale 3D generation model to independentlygenerate each object's full geometry, using MAE and point cloud conditioning tomitigate the effects of occlusions and partial object information, ensuringaccurate alignment with the source image's geometry and texture. To align eachobject with the scene, the alignment generation model computes the necessarytransformations, allowing the generated meshes to be accurately placed andintegrated into the scene's point cloud. Finally, CAST incorporates aphysics-aware correction step that leverages a fine-grained relation graph togenerate a constraint graph. This graph guides the optimization of objectposes, ensuring physical consistency and spatial coherence. By utilizing SignedDistance Fields (SDF), the model effectively addresses issues such asocclusions, object penetration, and floating objects, ensuring that thegenerated scene accurately reflects real-world physical interactions. CAST canbe leveraged in robotics, enabling efficient real-to-simulation workflows andproviding realistic, scalable simulation environments for robotic systems.</description>
      <author>example@mail.com (Kaixin Yao, Longwen Zhang, Xinhao Yan, Yan Zeng, Qixuan Zhang, Lan Xu, Wei Yang, Jiayuan Gu, Jingyi Yu)</author>
      <guid isPermaLink="false">2502.12894v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Task-Oriented Semantic Communication for Stereo-Vision 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.12735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于光学流的语义通信框架，旨在减少立体视觉3D物体检测任务中的数据传输开销。&lt;h4&gt;背景&lt;/h4&gt;随着计算机视觉的发展，3D物体检测在许多实际应用中变得越来越重要。然而，受限于传感器硬件的计算能力，复杂的算法需要部署到远程设备或云端执行，这带来了大量的数据传输负担。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架来减少立体视觉3D对象检测中的数据传输量，并确保检测精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一个光学流驱动模块联合提取和恢复左右图像中的语义信息以减少左-右光度对齐的语义信息损失，设计了一个2D语义提取模块识别并提取物体周围的语义意义，最后使用融合网络将恢复的语义进行融合，并重构立体视觉图像。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在检测精度上比传统方法提高了近70%，特别是在低信噪比的情况下表现更佳。&lt;h4&gt;结论&lt;/h4&gt;所提出的光学流驱动的语义通信框架能够有效减少数据传输量，同时保持或提高3D物体检测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;随着计算机视觉的发展，三维（3D）对象检测在许多现实世界应用中变得越来越重要。由于传感器侧硬件计算能力的限制，复杂的算法有时需要部署到远程设备或云上执行，这带来了大量的数据传输开销。为了应对这一问题，本文提出了一种基于光学流的语义通信框架来解决立体视觉3D对象检测任务中的挑战。该框架充分地利用了立体视觉3D检测对图像中语义信息的依赖，并优先传输这些语义信息以减少总的数据传输量同时确保检测准确性。特别地，我们开发了一个光学流驱动模块来联合提取和恢复左右图像中的语义信息，减少了左-右光度对齐的语义信息损失并改善了深度推断精度。然后设计了一种2D语义提取模块来识别并提取物体周围区域的语义意义，增强关键区域中语义信息的传输。最后使用融合网络将恢复的语义进行融合，并重构立体视觉图像以供3D检测。仿真结果表明该方法在检测准确性上提高了近70%，并且优于传统方法，尤其是在低信噪比的情况下表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the development of computer vision, 3D object detection has becomeincreasingly important in many real-world applications. Limited by thecomputing power of sensor-side hardware, the detection task is sometimesdeployed on remote computing devices or the cloud to execute complexalgorithms, which brings massive data transmission overhead. In response, thispaper proposes an optical flow-driven semantic communication framework for thestereo-vision 3D object detection task. The proposed framework fully exploitsthe dependence of stereo-vision 3D detection on semantic information in imagesand prioritizes the transmission of this semantic information to reduce totaltransmission data sizes while ensuring the detection accuracy. Specifically, wedevelop an optical flow-driven module to jointly extract and recover semanticsfrom the left and right images to reduce the loss of the left-right photometricalignment semantic information and improve the accuracy of depth inference.Then, we design a 2D semantic extraction module to identify and extractsemantic meaning around the objects to enhance the transmission of semanticinformation in the key areas. Finally, a fusion network is used to fuse therecovered semantics, and reconstruct the stereo-vision images for 3D detection.Simulation results show that the proposed method improves the detectionaccuracy by nearly 70% and outperforms the traditional method, especially forthe low signal-to-noise ratio regime.</description>
      <author>example@mail.com (Zijian Cao, Hua Zhang, Le Liang, Haotian Wang, Shi Jin, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2502.12735v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Semi-supervised Learning with Noisy Zero-shot Pseudolabels</title>
      <link>http://arxiv.org/abs/2502.12584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review for ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为ZMT的框架，该框架旨在通过结合零样本学习和无监督表示学习来改进半监督学习方法。&lt;h4&gt;背景&lt;/h4&gt;现有的半监督学习（SSL）方法依赖于有限标记数据和大量未标记数据。虽然基础模型可以通过零样本推断提供帮助，但尝试通过伪标签将其整合到SSL中的效果不稳定。&lt;h4&gt;目的&lt;/h4&gt;开发一种机制，该机制可以有效地利用零样本预测并结合当代SSL的无监督表示学习目标，以提高半监督学习的有效性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;ZMT框架采用多任务学习的方法，在生成伪标签的同时优化其质量，并确保对不同伪标签可靠性的适应能力。&lt;h4&gt;主要发现&lt;/h4&gt;在视觉、语言和音频领域的8个数据集上的实验结果表明，与传统的SSL方法相比，ZMT可以将错误率最多降低56%，特别是在伪标签不可靠的情况下表现尤为突出。&lt;h4&gt;结论&lt;/h4&gt;ZMT代表了半监督学习在资源受限环境中更有效和可访问性的重大进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning (SSL) leverages limited labeled data alongsideabundant unlabeled data to address labeling costs in machine learning. Whilerecent foundation models enable zero-shot inference, attempts to integratethese capabilities into SSL through pseudo-labeling have shown mixed resultsdue to unreliable zero-shot predictions. We present ZMT (Zero-Shot Multi-TaskLearning), a framework that jointly optimizes zero-shot pseudo-labels andunsupervised representation learning objectives from contemporary SSLapproaches. Our method introduces a multi-task learning-based mechanism thatincorporates pseudo-labels while ensuring robustness to varying pseudo-labelquality. Experiments across 8 datasets in vision, language, and audio domainsdemonstrate that ZMT reduces error by up to 56% compared to traditional SSLmethods, with particularly compelling results when pseudo-labels are noisy andunreliable. ZMT represents a significant step toward making semi-supervisedlearning more effective and accessible in resource-constrained environments.</description>
      <author>example@mail.com (Jichan Chung, Irene Y. Chen)</author>
      <guid isPermaLink="false">2502.12584v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection</title>
      <link>http://arxiv.org/abs/2502.13061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于检测仇恨表情包的新型两阶段微调框架LMM-RGCL，该框架在多个数据集上取得了最先进的性能，并展示了跨领域泛化的优越性。&lt;h4&gt;背景&lt;/h4&gt;互联网上的仇恨表情包成为了一个重要的问题，大模态模型虽然在多种任务中表现出色，但在检测仇恨表情包时表现不佳，因为表情包与新兴的社会趋势和突发事件紧密相关。传统的监督微调方法在这种情况下也显示出局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来提高大型多模态模型对仇恨表情包检测的准确性，并增强其跨领域泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL)，这是一种两阶段微调框架，旨在通过对比学习和基于检索的方法改进大模型在该任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LMM-RGCL不仅在六个广泛使用的表情包分类数据集上实现了最先进的性能，而且在资源有限的情况下能够有效地泛化到未见过的表情包。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法超越了现有的代理系统和其他模型，并为仇恨表情包检测提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;网络上的仇恨表情包已经成为一个重要问题。虽然大型多模态模型在很多任务中表现出色，但由于表情包和新兴的社会趋势及突发事件的联系密切，这些模型在仇恨表情包检测方面表现不佳。最近的研究进一步指出，在这种情况下常规监督微调方法的局限性。为了应对这一挑战，我们提出了一种名为Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL)的新框架，旨在提高大模态模型在该任务中的准确性及跨领域泛化能力。实验结果表明，在六个常用的表情包分类数据集上，LMM-RGCL达到了最先进的性能，并且在低资源条件下能够有效地泛化到未见过的表情包，超过了包括VPD-PALI-X-55B和GPT-4o在内的其他模型的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hateful memes have become a significant concern on the Internet,necessitating robust automated detection systems. While large multimodal modelshave shown strong generalization across various tasks, they exhibit poorgeneralization to hateful meme detection due to the dynamic nature of memestied to emerging social trends and breaking news. Recent work furtherhighlights the limitations of conventional supervised fine-tuning for largemultimodal models in this context. To address these challenges, we proposeLarge Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), anovel two-stage fine-tuning framework designed to improve both in-domainaccuracy and cross-domain generalization. Experimental results on six widelyused meme classification datasets demonstrate that LMM-RGCL achievesstate-of-the-art performance, outperforming agent-based systems such asVPD-PALI-X-55B. Furthermore, our method effectively generalizes toout-of-domain memes under low-resource settings, surpassing models like GPT-4o.</description>
      <author>example@mail.com (Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne)</author>
      <guid isPermaLink="false">2502.13061v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery</title>
      <link>http://arxiv.org/abs/2502.12453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted as ICLR 2025 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了Universal Matching Networks (UniMatch)模型，旨在解决药物发现过程中由于低成功率导致的数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;药物研发在寻找治疗各种疾病的候选药物中至关重要。然而，其低成功率往往会导致数据标注不足，形成少样本学习的问题。现有方法主要关注单一尺度的特征提取，忽略了决定分子不同性质的多层次分子结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多层次分子表示和任务级泛化的统一匹配框架UniMatch，以提高药物发现的成功率。&lt;h4&gt;方法&lt;/h4&gt;采用双层次匹配框架：显式的分层池化和匹配机制用于捕捉多尺度的结构性特征；隐式的元学习策略进行跨任务级别的匹配，帮助模型快速适应新任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UniMatch在MoleculeNet和FS-Mol基准测试中优于现有最佳方法，AUROC提升了2.87%，delta AUPRC提高了6.52%。同时，在Meta-MolNet基准上展现了优秀的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的方法通过结合显式的多层次分子匹配与隐式的任务级匹配，有效解决了药物发现中的少样本学习问题，并展示了优于现有方法的性能和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;药物发现对于识别治疗各种疾病的候选药物至关重要。然而，其低成功率往往导致数据标注不足，形成少样本学习的问题。现有的方法主要集中在单一尺度特征上，忽略了决定不同分子性质的多层次分子结构。为解决这些问题，我们引入了Universal Matching Networks (UniMatch)，这是一种双匹配框架，通过元学习将显式的层次化分子匹配与隐式的任务级匹配相结合，连接多层次分子表示和任务级别泛化。具体来说，我们的方法利用分层池化和匹配技术跨多个尺度（如原子、子结构和完整分子）捕捉结构性特征，促进精确的分子表达式和比较。此外，我们采用元学习策略进行隐式的任务级匹配，使模型能够捕获任务间的共享模式并快速适应新任务。这种统一的匹配框架确保了有效的分子对齐，并利用共享元知识实现快速适应。实验结果表明，在MoleculeNet和FS-Mol基准测试中，UniMatch优于现有最佳方法，分别在AUROC和delta AUPRC方面提高了2.87%和6.52%。此外，UniMatch在Meta-MolNet基准上的泛化能力也表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery is crucial for identifying candidate drugs for variousdiseases.However, its low success rate often results in a scarcity ofannotations, posing a few-shot learning problem. Existing methods primarilyfocus on single-scale features, overlooking the hierarchical molecularstructures that determine different molecular properties. To address theseissues, we introduce Universal Matching Networks (UniMatch), a dual matchingframework that integrates explicit hierarchical molecular matching withimplicit task-level matching via meta-learning, bridging multi-level molecularrepresentations and task-level generalization. Specifically, our approachexplicitly captures structural features across multiple levels, such as atoms,substructures, and molecules, via hierarchical pooling and matching,facilitating precise molecular representation and comparison. Additionally, weemploy a meta-learning strategy for implicit task-level matching, allowing themodel to capture shared patterns across tasks and quickly adapt to new ones.This unified matching framework ensures effective molecular alignment whileleveraging shared meta-knowledge for fast adaptation. Our experimental resultsdemonstrate that UniMatch outperforms state-of-the-art methods on theMoleculeNet and FS-Mol benchmarks, achieving improvements of 2.87% in AUROC and6.52% in delta AUPRC. UniMatch also shows excellent generalization ability onthe Meta-MolNet benchmark.</description>
      <author>example@mail.com (Ruifeng Li, Mingqian Li, Wei Liu, Yuhua Zhou, Xiangxin Zhou, Yuan Yao, Qiang Zhang, Hongyang Chen)</author>
      <guid isPermaLink="false">2502.12453v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Embedding Function for Traffic Classification via QUIC Domain Recognition Pretraining: A Transfer Learning Success</title>
      <link>http://arxiv.org/abs/2502.12930v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于迁移学习的加密流量分类方法，通过预训练模型来适应不断变化的网络协议和机器学习领域的发展。&lt;h4&gt;背景&lt;/h4&gt;随着TLS加密客户端Hello的广泛使用，QUIC流量中的SNI域名识别变得越来越困难。传统的加密流量分类技术难以应对新出现的网络协议及其扩展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于迁移学习的方法来改进加密流量分类的性能。&lt;h4&gt;方法&lt;/h4&gt;首先在一个复杂的任务上训练一个嵌入模型（识别QUIC流量中的SNI域名），然后将这个预训练模型转移到五个已知的TC数据集上。使用了独立类设置、ArcFace损失函数以及现代深度学习架构，旨在生成适用于各种任务的通用嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;基于最近邻搜索方法在四个数据集中超过了现有最优性能，并且与利用原始报文序列的基线方法相比有意外的发现，这可能对整个加密流量分类领域产生影响。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个有效的迁移学习方案来提升加密流量分类的效果，同时发布了模型架构、训练权重和实验结果以供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法利用预训练的嵌入模型，通过处理复杂任务（如识别QUIC中的SNI域名），然后将其应用到其他五个已知的数据集上。该方法在四个数据集中表现出超越现有最佳性能的结果，并且与基线方法相比有一些意外发现，可能会影响整个加密流量分类领域的发展方向和研究趋势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Encrypted traffic classification (TC) methods must adapt to new protocols andextensions as well as to advancements in other machine learning fields. In thispaper, we follow a transfer learning setup best known from computer vision. Wefirst pretrain an embedding model on a complex task with a large number ofclasses and then transfer it to five well-known TC datasets. The pretrainingtask is recognition of SNI domains in encrypted QUIC traffic, which in itselfis a problem for network monitoring due to the growing adoption of TLSEncrypted Client Hello. Our training pipeline -- featuring a disjoint classsetup, ArcFace loss function, and a modern deep learning architecture -- aimsto produce universal embeddings applicable across tasks. The proposed solution,based on nearest neighbors search in the embedding space, surpasses SOTAperformance on four of the five TC datasets. A comparison with a baselinemethod utilizing raw packet sequences revealed unexpected findings withpotential implications for the broader TC field. We published the modelarchitecture, trained weights, and transfer learning experiments.</description>
      <author>example@mail.com (Jan Luxemburk, Karel Hynek, Richard Plný, Tomáš Čejka)</author>
      <guid isPermaLink="false">2502.12930v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Magma: A Foundation Model for Multimodal AI Agents</title>
      <link>http://arxiv.org/abs/2502.13130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 16 figures, technical report from MSR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Magma的模型，该模型旨在支持多模态AI代理任务，不仅涵盖了视觉-语言的理解能力，还具备规划和执行实际世界中行动的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉-语言(VL)模型主要用于理解静态图像中的语义信息，而缺乏在动态环境中进行动作规划和执行的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够同时处理数字和物理世界的多模态AI代理任务的新模型Magma。&lt;h4&gt;方法&lt;/h4&gt;通过使用大量异构数据集（包括图片、视频到机器人数据）对Magma进行预训练，其中的可操作视觉对象在图像中标记为Set-of-Mark (SoM)，以实现动作定位；而在视频中，则使用Trace-of-Mark (ToM)标记物体运动轨迹来辅助行动规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SoM和ToM技术结合效果显著，并能够帮助Magma模型获取空间-时间智能，在UI导航和机器人操作等任务上达到了新的最佳性能。同时，它在图像和视频相关的多模态任务中也表现优越。&lt;h4&gt;结论&lt;/h4&gt;Magma展示出强大的跨领域适应性和高性能，特别是在UI导航和机器人操作方面超越了专为此类任务设计的其他模型，并且公开源代码以供重复研究。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了Magma，这是一种基础模型，能够服务于数字世界和物理世界的多模态AI代理任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Magma, a foundation model that serves multimodal AI agentic tasksin both the digital and physical worlds. Magma is a significant extension ofvision-language (VL) models in that it not only retains the VL understandingability (verbal intelligence) of the latter, but is also equipped with theability to plan and act in the visual-spatial world (spatial-temporalintelligence) and complete agentic tasks ranging from UI navigation to robotmanipulation. To endow the agentic capabilities, Magma is pretrained on largeamounts of heterogeneous datasets spanning from images, videos to roboticsdata, where the actionable visual objects (e.g., clickable buttons in GUI) inimages are labeled by Set-of-Mark (SoM) for action grounding, and the objectmovements (e.g., the trace of human hands or robotic arms) in videos arelabeled by Trace-of-Mark (ToM) for action planning. Extensive experiments showthat SoM and ToM reach great synergy and facilitate the acquisition ofspatial-temporal intelligence for our Magma model, which is fundamental to awide range of tasks as shown in Fig.1. In particular, Magma creates newstate-of-the-art results on UI navigation and robotic manipulation tasks,outperforming previous models that are specifically tailored to these tasks. Onimage and video-related multimodal tasks, Magma also compares favorably topopular large multimodal models that are trained on much larger datasets. Wemake our model and code public for reproducibility athttps://microsoft.github.io/Magma.</description>
      <author>example@mail.com (Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao)</author>
      <guid isPermaLink="false">2502.13130v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Transformation-Isomorphic Latent Space for Accurate Hand Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.12535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种名为TI-Net的视觉网络骨干，用于构建等变变换隐式空间，旨在解决现有表征学习方法在处理低层次信息和去除任务无关信息方面的不足。&lt;h4&gt;背景介绍&lt;/h4&gt;基于视觉的回归任务（如手部姿态估计）通过表示学习已经取得了更高的精度和更快的收敛速度。然而，现有的表示学习方法仍然面临特征提取问题：提取的高级语义特征不足以进行低级信息回归，并且包含的任务不相关信息会干扰回归任务。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种新的网络架构（TI-Net），解决当前表征学习中存在的问题，以提高手部姿态估计等回归任务的表现。&lt;h4&gt;创新方法&lt;/h4&gt;采用线性变换在隐式空间中建模几何变换，并确保这些变换与图像空间中的对应变换对齐。这种方法保证了提取的特征紧凑且有利于低层次信息（如姿态）的回归。&lt;h4&gt;实验验证&lt;/h4&gt;通过手部姿态估计任务评估TI-Net，在DexYCB数据集上，相比最先进的专门用于手部姿态估计的方法在PA-MPJPE指标上取得了10%的改进。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖且通用的视觉网络架构，能够有效地解决现有表示学习方法中存在的问题，并展示了其在特定任务上的优越性能。未来将开源代码以供研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;Vision-based regression tasks, such as hand pose estimation, have achieved higher accuracy and faster convergence through representation learning. However, existing representation learning methods often encounter issues: the high semantic level of features extracted from images is inadequate for regressing low-level information, and the extracted features include task-irrelevant information, reducing their compactness and interfering with regression tasks. To address these challenges, we propose TI-Net, a highly versatile visual Network backbone designed to construct a Transformation Isomorphic latent space. Specifically, we employ linear transformations to model geometric transformations in the latent space and ensure that TI-Net aligns them with those in the image space. This ensures that the latent features capture compact, low-level information beneficial for pose estimation tasks. We evaluated TI-Net on the hand pose estimation task to demonstrate the network's superiority. On the DexYCB dataset, TI-Net achieved a 10% improvement in the PA-MPJPE metric compared to specialized state-of-the-art (SOTA) hand pose estimation methods. Our code will be released in the future.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based regression tasks, such as hand pose estimation, have achievedhigher accuracy and faster convergence through representation learning.However, existing representation learning methods often encounter the followingissues: the high semantic level of features extracted from images is inadequatefor regressing low-level information, and the extracted features includetask-irrelevant information, reducing their compactness and interfering withregression tasks. To address these challenges, we propose TI-Net, a highlyversatile visual Network backbone designed to construct a TransformationIsomorphic latent space. Specifically, we employ linear transformations tomodel geometric transformations in the latent space and ensure that {\rmTI-Net} aligns them with those in the image space. This ensures that the latentfeatures capture compact, low-level information beneficial for pose estimationtasks. We evaluated TI-Net on the hand pose estimation task to demonstrate thenetwork's superiority. On the DexYCB dataset, TI-Net achieved a 10% improvementin the PA-MPJPE metric compared to specialized state-of-the-art (SOTA) handpose estimation methods. Our code will be released in the future.</description>
      <author>example@mail.com (Kaiwen Ren, Lei Hu, Zhiheng Zhang, Yongjing Ye, Shihong Xia)</author>
      <guid isPermaLink="false">2502.12535v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>An Experimental Study of SOTA LiDAR Segmentation Models</title>
      <link>http://arxiv.org/abs/2502.12860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  No comments&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;点云分割（PCS）是将每个点分类的任务，它使机器人能够解析其三维环境并自主运行。&lt;h4&gt;背景&lt;/h4&gt;现有PCP模型根据不同的点云表示方式大致可分为基于点、体素和范围图像的模型。然而，尚未有研究从应用角度对这些先进的点基、体素基和范围图像基模型进行全面比较。&lt;h4&gt;目的&lt;/h4&gt;提供关于不同模型在考虑LiDAR数据运动补偿以及模型参数、测试期间分配的最大GPU内存、推理延迟、每秒帧数、交并比（IoU）和平均交并比（mIoU）得分等方面的详尽对比。&lt;h4&gt;方法&lt;/h4&gt;实验结果有助于工程师根据应用场景选择合适的PCS模型，同时也启发了研究者在PCS领域设计更适合实际场景的模型。&lt;h4&gt;主要发现&lt;/h4&gt;提供了一套详细的数据，帮助工程师了解不同点云分割模型的优劣。&lt;h4&gt;结论&lt;/h4&gt;通过全面比较现有的点、体素和范围图像基模型，有助于提高机器人自主解析三维环境的能力，并促进更实用的PCS模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud segmentation (PCS) is to classify each point in point clouds. Thetask enables robots to parse their 3D surroundings and run autonomously.According to different point cloud representations, existing PCS models can beroughly divided into point-, voxel-, and range image-based models. However, nowork has been found to report comprehensive comparisons among thestate-of-the-art point-, voxel-, and range image-based models from anapplication perspective, bringing difficulty in utilizing these models forreal-world scenarios. In this paper, we provide thorough comparisons among themodels by considering the LiDAR data motion compensation and the metrics ofmodel parameters, max GPU memory allocated during testing, inference latency,frames per second, intersection-over-union (IoU) and mean IoU (mIoU) scores.The experimental results benefit engineers when choosing a reasonable PCS modelfor an application and inspire researchers in the PCS field to design morepractical models for a real-world scenario.</description>
      <author>example@mail.com (Bike Chen, Antti Tikanmäki, Juha Röning)</author>
      <guid isPermaLink="false">2502.12860v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Contrast-Unity for Partially-Supervised Temporal Sentence Grounding</title>
      <link>http://arxiv.org/abs/2502.12917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICASSP 2025.The first two authors share the same  contribution. arXiv admin note: text overlap with arXiv:2302.09850&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个中间的半监督设置，旨在通过只在训练期间提供短片段视频来降低标注成本，并同时保持高性能。为此设计了一种对比统一框架，采用隐式-显式的渐进式定位方法。&lt;h4&gt;背景&lt;/h4&gt;时间句子对齐的目标是从给定的未经修剪的视频中检测由自然语言查询描述的事件的时间戳。完全监督的方法虽然效果好但需要昂贵的标注成本；而弱监督的方法使用廉价标签但性能较差。&lt;h4&gt;目的&lt;/h4&gt;为了追求在减少标注成本的同时保持高性能，论文引入了一种中间部分监督设置，并设计了对比-统一框架来充分利用有限的标注信息。&lt;h4&gt;方法&lt;/h4&gt;提出了一种隐式阶段和显式阶段两阶段目标：在隐式阶段使用综合四元组对比学习对事件查询表示进行细粒度对齐；在显式阶段，利用获得的伪标签训练完全监督模型以实现定位细化和去噪。&lt;h4&gt;主要发现&lt;/h4&gt;部分监督的重要性及其框架的有效性得到了充分验证，在Charades-STA和ActivityNet Captions数据集上的大量实验也表明了这一点。&lt;h4&gt;结论&lt;/h4&gt;论文提出的半监督设置结合对比统一框架，为时间句子对齐问题提供了一种新的解决方案，实现了高精度定位的同时减少了标注成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal sentence grounding aims to detect event timestamps described by thenatural language query from given untrimmed videos. The existingfully-supervised setting achieves great results but requires expensiveannotation costs; while the weakly-supervised setting adopts cheap labels butperforms poorly. To pursue high performance with less annotation costs, thispaper introduces an intermediate partially-supervised setting, i.e., onlyshort-clip is available during training. To make full use of partial labels, wespecially design one contrast-unity framework, with the two-stage goal ofimplicit-explicit progressive grounding. In the implicit stage, we alignevent-query representations at fine granularity using comprehensive quadruplecontrastive learning: event-query gather, event-background separation,intra-cluster compactness and inter-cluster separability. Then, high-qualityrepresentations bring acceptable grounding pseudo-labels. In the explicitstage, to explicitly optimize grounding objectives, we train onefully-supervised model using obtained pseudo-labels for grounding refinementand denoising. Extensive experiments and thoroughly ablations on Charades-STAand ActivityNet Captions demonstrate the significance of partial supervision,as well as our superior performance.</description>
      <author>example@mail.com (Haicheng Wang, Chen Ju, Weixiong Lin, Chaofan Ma, Shuai Xiao, Ya Zhang, Yanfeng Wang)</author>
      <guid isPermaLink="false">2502.12917v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>tn4ml: Tensor Network Training and Customization for Machine Learning</title>
      <link>http://arxiv.org/abs/2502.13090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个新的名为tn4ml的库，旨在将张量网络集成到机器学习优化流程中。&lt;h4&gt;背景&lt;/h4&gt;张量网络作为一种新兴的技术在基础科学领域内的机器学习挑战中展现了其潜力，并开始应用于现实世界的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个易于使用的库（tn4ml），以支持基于张量网络的机器学习任务，并展示它的灵活性和应用范围。&lt;h4&gt;方法&lt;/h4&gt;该库提供了数据嵌入、目标函数定义以及使用多种优化策略进行模型训练的功能模块，演示了其在监督学习和无监督学习中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过两个实例展示了tn4ml库的灵活性：一个是表格数据上的有监督学习，另一个是图像数据集上的无监督学习。此外还分析了为张量网络定制机器学习管道的部分如何影响性能指标。&lt;h4&gt;结论&lt;/h4&gt;这个新的库能够促进张量网络在处理现实世界问题中的应用，并展示了其作为传统神经网络替代品的潜力。&lt;h4&gt;翻译&lt;/h4&gt;张量网络作为一种新兴的技术，已经成为解决基础科学领域内机器学习挑战的重要方案。本文介绍了一个名为tn4ml的新库，旨在将这些张量网络无缝集成到机器学习任务的优化流程中。受到现有机器学习框架的启发，该库提供了一个用户友好的结构，并包括用于数据嵌入、目标函数定义以及使用多种策略进行模型训练的功能模块。通过在表格数据上的有监督学习和图像数据集上的无监督学习中的应用实例展示了其灵活性，并分析了为张量网络定制化机器学习流程的各个部分如何影响性能指标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tensor Networks have emerged as a prominent alternative to neural networksfor addressing Machine Learning challenges in foundational sciences, paving theway for their applications to real-life problems. This paper introduces tn4ml,a novel library designed to seamlessly integrate Tensor Networks intooptimization pipelines for Machine Learning tasks. Inspired by existing MachineLearning frameworks, the library offers a user-friendly structure with modulesfor data embedding, objective function definition, and model training usingdiverse optimization strategies. We demonstrate its versatility through twoexamples: supervised learning on tabular data and unsupervised learning on animage dataset. Additionally, we analyze how customizing the parts of theMachine Learning pipeline for Tensor Networks influences performance metrics.</description>
      <author>example@mail.com (Ema Puljak, Sergio Sanchez-Ramirez, Sergi Masot-Llima, Jofre Vallès-Muns, Artur Garcia-Saez, Maurizio Pierini)</author>
      <guid isPermaLink="false">2502.13090v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>A deep learning framework for efficient pathology image analysis</title>
      <link>http://arxiv.org/abs/2502.13027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;人工智能通过从高分辨率全切片图像预测生物标志物，正在改变数字病理学。然而，当前的方法在计算上效率低下，处理每个全切片图像的数千个冗余切片，并且需要复杂的聚合模型。EAGLE（高效引导局部检查方法）是一个深度学习框架，模拟了病理学家通过选择性地分析信息区域来工作。&lt;h4&gt;背景&lt;/h4&gt;人工智能技术已经开始应用于数字病理学领域，其中最典型的应用是从全切片图像中预测生物标志物。但是现有的方法存在计算资源消耗大和处理效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且精确的深度学习框架EAGLE，通过选择性分析有信息量的区域来提高模型的表现，并减少所需的计算时间。&lt;h4&gt;方法&lt;/h4&gt;EAGLE使用两个基础模型：CHIEF用于有效切片选择，Virchow2用于提取高质量特征。此研究对包括31个任务在内的四种癌症类型进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;相比于现有的前沿滑动和切片级别基础模型，EAGLE在最高AUROC指标上表现出色，并且处理速度更快，耗时仅需2.27秒，而减少了超过99%的计算时间。&lt;h4&gt;结论&lt;/h4&gt;EAGLE不仅提高了数字病理学中的AI效率，还提供了更加可靠和可解释的结果。这使得实时工作流程成为可能，并消除了对高性能计算机的需求，使基于人工智能的病理诊断变得更加普及。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，AI已经通过从高分辨率全切片图像中预测生物标志物而彻底改变了数字病理学领域。然而，当前的方法在计算上存在低效的问题，需要处理大量冗余切片并使用复杂的聚合模型。为了解决这些问题，研究人员开发了EAGLE（Efficient Approach for Guided Local Examination），这是一种模仿病理学家工作方式的深度学习框架，通过选择性地分析有信息量的区域来提高效率和准确性。这项研究在四种癌症类型上进行了基准测试，涵盖了形态学、生物标志物预测以及预后任务，结果显示EAGLE相比现有的前沿模型表现出色，并且大大减少了处理时间，使其更适合实时工作流程，并且使得病理学家可以验证所有用于分析中的切片。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has transformed digital pathology by enablingbiomarker prediction from high-resolution whole slide images (WSIs). However,current methods are computationally inefficient, processing thousands ofredundant tiles per WSI and requiring complex aggregator models. We introduceEAGLE (Efficient Approach for Guided Local Examination), a deep learningframework that emulates pathologists by selectively analyzing informativeregions. EAGLE incorporates two foundation models: CHIEF for efficient tileselection and Virchow2 for extracting high-quality features. Benchmarking wasconducted against leading slide- and tile-level foundation models across 31tasks from four cancer types, spanning morphology, biomarker prediction andprognosis. EAGLE outperformed state-of-the-art foundation models by up to 23%and achieved the highest AUROC overall. It processed a slide in 2.27 seconds,reducing computational time by more than 99% compared to existing models. Thisefficiency enables real-time workflows, allows pathologists to validate alltiles which are used by the model during analysis, and eliminates dependence onhigh-performance computing, making AI-powered pathology more accessible. Byreliably identifying meaningful regions and minimizing artifacts, EAGLEprovides robust and interpretable outputs, supporting rapid slide searches,integration into multi-omics pipelines and emerging clinical foundation models.</description>
      <author>example@mail.com (Peter Neidlinger, Tim Lenz, Sebastian Foersch, Chiara M. L. Loeffler, Jan Clusmann, Marco Gustav, Lawrence A. Shaktah, Rupert Langer, Bastian Dislich, Lisa A. Boardman, Amy J. French, Ellen L. Goode, Andrea Gsur, Stefanie Brezina, Marc J. Gunter, Robert Steinfelder, Hans-Michael Behrens, Christoph Röcken, Tabitha Harrison, Ulrike Peters, Amanda I. Phipps, Giuseppe Curigliano, Nicola Fusco, Antonio Marra, Michael Hoffmeister, Hermann Brenner, Jakob Nikolas Kather)</author>
      <guid isPermaLink="false">2502.13027v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Machine Learning Potential X-MACE for Excited States using Integrated DeepSets</title>
      <link>http://arxiv.org/abs/2502.12870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了用于精确建模激发态并在关键非平滑区域提高准确性的深度学习架构，解决了量子化学计算中的锥形交叉问题。&lt;h4&gt;背景&lt;/h4&gt;在光化学反应中，锥形交叉是重要的通道，它们促进了潜在能级表面之间的快速无辐射跃迁。然而，使用量子化学计算这些交叉是非常计算密集的，并且由于其本质上非平滑和复杂的性质，利用机器学习进行建模也面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入深度学习架构来精确模拟激发态并在锥形交叉区域提高准确性，解决锥形交叉建模中的问题。&lt;h4&gt;方法&lt;/h4&gt;将Deep Sets集成到消息传递原子簇扩展（MACE）框架中，形成非光滑激发态势能表面的平滑表示。使用多种分子验证这种方法，并将其与传统激发态模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;开发的方法在准确模拟锥形交叉附近的能量景观方面显著优于常规激发态模型。此外，还展示了基于基态基础机器学习模型来构建激发态，这表明所发展的模型不仅可以在基态和激发态之间转移，还可以应用于超出训练数据集的分子系统。&lt;h4&gt;结论&lt;/h4&gt;这项研究增强了激发态建模的准确性，并为更复杂分子系统的调查奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conical intersections serve as critical gateways in photochemical reactions,enabling rapid nonradiative transitions between potential energy surfaces thatunderpin fundamental processes such as photosynthesis or vision. Theircalculation with quantum chemistry is, however, extremely computationallyintensive and their modeling with machine learning poses a significantchallenge due to their inherently non-smooth and complex nature. To addressthis challenge, we introduce a deep learning architecture designed to preciselymodel excited states and improve their accuracy around these critical,non-smooth regions. Our model integrates Deep Sets into the Message PassingAtomic Cluster Expansion (MACE) framework resulting in a smooth representationof the non-smooth excited-state potential energy surfaces. We validate ourmethod using numerous molecules, showcasing a significant improvement inaccurately modeling the energy landscape around conical intersections comparedto conventional excited-state models. Additionally, we apply ground-statefoundational machine learning models as a basis for excited states. By doingso, we showcase that the developed model is capable of transferring not onlyfrom the ground state to excited states, but also within chemical space tomolecular systems beyond those included in the training dataset. Thisadvancement not only enhances the fidelity of excited-state modeling, but alsolays the foundations for the investigation of more complex molecular systems.</description>
      <author>example@mail.com (Rhyan Barrett, Christoph Ortner, Julia Westermayr)</author>
      <guid isPermaLink="false">2502.12870v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm</title>
      <link>http://arxiv.org/abs/2502.12513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 12 figures, Webpage: https://garygutc.github.io/RealSyn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的数据集RealSyn，该数据集结合了真实和合成文本，并通过创新的方法有效利用了大量的非成对的多模态交织文档。&lt;h4&gt;背景&lt;/h4&gt;Contrastive Language-Image Pre-training (CLIP) 在经过广泛的图像文字配对预训练后，在多种基准测试中表现出色。然而，大量的非配对数据（例如，多模态交织文档）尚未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;充分利用未被使用的大量非配对的多模态交织文档，通过创建一个真实世界的视觉-语言表示学习的新数据集来提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;['建立了一个真实世界的数据提取管道以从多源中抽取高质量的图像和文本。', '设计了一种分层检索方法高效地将每张图片与多个语义相关的现实文本相匹配。', '提出了一个增强图像语义生成模块，用于合成文本生产，进一步提升细粒度视觉信息。', '采用一种语义平衡采样策略提高数据集的多样性，有助于学习长尾概念。']&lt;h4&gt;主要发现&lt;/h4&gt;['构建了包含真实和合成文本的数据集RealSyn，分别提供三种规模：15M、30M 和 100M。', '实验表明，基于 RealSyn 预训练的模型在多个下游任务上达到了最先进的性能。', 'RealSyn 数据集具有良好的可扩展性，为未来的研究提供了重要的资源。']&lt;h4&gt;结论&lt;/h4&gt;提出的创新方法和数据集有效提升了视觉-语言表示学习的能力，并通过多种基准测试验证了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;在大量的图像文字配对预训练后，对比语言图像预训练（CLIP）在众多标准评估中展示了显著的性能。然而，大量未配对的数据如多模态交织文档仍然没有得到充分利用。为了充分挖掘这些未配对文档的价值，我们首先构建了一个真实世界数据抽取管道，用于提取高质量的图像和文本。随后设计了一种层级检索方法来高效地将每张图片与多个语义相关的现实文本联系起来。为了进一步增强细粒度视觉信息，我们提出了一种基于图像语义增强生成模块合成文本的方法，并采用一种语义平衡采样策略提高数据集多样性，有利于长尾概念的学习。基于这些创新，我们构建了一个结合真实和合成文本的数据集RealSyn，在15M、30M 和 100M三个规模下可用。大量的实验验证了RealSyn在视觉语言表示学习中的有效性，并展示了其良好的可扩展性。在多个下游任务上预训练于RealSyn上的模型取得了最佳性能表现。为了促进未来研究，我们开放了数据集和预训练的权重访问：https://github.com/deepglint/RealSyn&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; After pre-training on extensive image-text pairs, Contrastive Language-ImagePre-training (CLIP) demonstrates promising performance on a wide variety ofbenchmarks. However, a substantial volume of non-paired data, such asmultimodal interleaved documents, remains underutilized for vision-languagerepresentation learning. To fully leverage these unpaired documents, weinitially establish a Real-World Data Extraction pipeline to extracthigh-quality images and texts. Then we design a hierarchical retrieval methodto efficiently associate each image with multiple semantically relevantrealistic texts. To further enhance fine-grained visual information, we proposean image semantic augmented generation module for synthetic text production.Furthermore, we employ a semantic balance sampling strategy to improve datasetdiversity, enabling better learning of long-tail concepts. Based on theseinnovations, we construct RealSyn, a dataset combining realistic and synthetictexts, available in three scales: 15M, 30M, and 100M. Extensive experimentsdemonstrate that RealSyn effectively advances vision-language representationlearning and exhibits strong scalability. Models pre-trained on RealSyn achievestate-of-the-art performance on multiple downstream tasks. To facilitate futureresearch, the RealSyn dataset and pre-trained model weights are released athttps://github.com/deepglint/RealSyn.</description>
      <author>example@mail.com (Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng)</author>
      <guid isPermaLink="false">2502.12513v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Graph Structure Learning</title>
      <link>http://arxiv.org/abs/2502.12618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by TheWebConf 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;图神经网络（GNNs）已成为处理图结构数据学习任务的主流方法，但其性能会因不理想的图结构而大幅下降。为解决这一问题，提出了图结构学习（Graph Structure Learning, GSL），该技术可以自适应地优化节点连接。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图结构数据方面表现卓越，但是当面对次优的图结构时，其性能会显著降低。现有的图结构学习方法主要关注于基于节点相似度来构建关系，但往往忽视了节点信息的质量问题，并且所生成的图结构通常是对称的。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有图结构学习技术中的不足，研究团队提出了一种不确定性感知的图结构学习（UnGSL）策略。该方法旨在通过估计节点信息的不确定性来调整方向连接的强度，从而减少高不确定性的节点的影响，并且可以作为插件模块集成到现有的图结构学习方法中。&lt;h4&gt;方法&lt;/h4&gt;所提出的UnGSL策略能够估算每个节点的信息质量并相应地调节其与其他节点之间的连接强度。此外，此策略设计为一种易于与现有模型结合的无创性解决方案，几乎不需要额外的计算资源。&lt;h4&gt;主要发现&lt;/h4&gt;通过将UnGSL应用到六种代表性图结构学习方法中进行实验验证后显示，所有情况下均实现了性能提升的效果。该工作表明了改进图数据的质量对于提升基于GNN的方法的有效性和灵活性的重要性。&lt;h4&gt;结论&lt;/h4&gt;研究团队提出了一种新颖的不确定性感知图结构学习（UnGSL）策略，有效地解决了现有图结构学习技术中的关键问题，并且展示出在多个基准测试中具有良好的性能表现。这项工作强调了通过提高数据质量来增强机器学习模型效果的一种新途径。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络（GNNs）已经成为处理图形结构化数据的主要方法，但其有效性可能会受到次优的图结构的重大影响。为解决这个问题，提出了图结构学习（GSL），这是一种能够自适应优化节点连接的技术。然而，我们发现现有GSL方法存在两个主要限制：1) 大多数方法侧重于通过相似性来构建关系，而忽视了信息质量的问题；2) 所构造的图形通常需要对称，这可能限制了模型的灵活性和效率。为克服这些局限，本研究提出了一种基于不确定性感知图结构学习（UnGSL）策略。该方法评估节点的信息不确定性，并利用它来调整有向连接的强度，在此过程中自适应地减少高不确定性的节点影响。值得注意的是，UnGSL可以作为插入式模块无缝集成到现有的GSL方法中，几乎不增加额外计算成本。在实验中，我们把UnGSL整合进了六种代表性GSL方法中，并展示了所有情况下性能都有提升的效果。代码可在https://github.com/UnHans/UnGSL上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become a prominent approach for learningfrom graph-structured data. However, their effectiveness can be significantlycompromised when the graph structure is suboptimal. To address this issue,Graph Structure Learning (GSL) has emerged as a promising technique thatrefines node connections adaptively. Nevertheless, we identify two keylimitations in existing GSL methods: 1) Most methods primarily focus on nodesimilarity to construct relationships, while overlooking the quality of nodeinformation. Blindly connecting low-quality nodes and aggregating theirambiguous information can degrade the performance of other nodes. 2) Theconstructed graph structures are often constrained to be symmetric, which maylimit the model's flexibility and effectiveness. To overcome these limitations,we propose an Uncertainty-aware Graph Structure Learning (UnGSL) strategy.UnGSL estimates the uncertainty of node information and utilizes it to adjustthe strength of directional connections, where the influence of nodes with highuncertainty is adaptively reduced.Importantly, UnGSL serves as a plug-in modulethat can be seamlessly integrated into existing GSL methods with minimaladditional computational cost. In our experiments, we implement UnGSL into sixrepresentative GSL methods, demonstrating consistent performance improvements.The code is available at https://github.com/UnHans/UnGSL.</description>
      <author>example@mail.com (Shen Han, Zhiyao Zhou, Jiawei Chen, Zhezheng Hao, Sheng Zhou, Gang Wang, Yan Feng, Chun Chen, Can Wang)</author>
      <guid isPermaLink="false">2502.12618v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Timesteps: A Novel Activation-wise Membrane Potential Propagation Mechanism for Spiking Neural Networks in 3D cloud</title>
      <link>http://arxiv.org/abs/2502.12791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的激活策略，用于解决基于脉冲神经网络（SNN）在处理视觉任务时的延迟和计算成本问题。&lt;h4&gt;背景&lt;/h4&gt;由于事件数据与点云有相似特性，一些研究开始将事件数据视作类似点云的数据进行分析。此外，从事件视觉角度出发的方法也采用异步性质的SNN来处理点云。然而这些方法通常局限于特定领域，难以在其他交叉领域应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统时间步长激活策略对脉冲神经元更新策略限制的问题，论文提出了一种新的激活策略，可以提升基于事件和点云数据的任务性能，并减少延迟。&lt;h4&gt;方法&lt;/h4&gt;提出了名为Activation-wise Membrane Potential Propagation (AMP2)的新激活策略。该策略将时间步骤的概念从手动设定的参数扩展到任何现有的网络结构中。&lt;h4&gt;主要发现&lt;/h4&gt;在常见点云任务（分类、对象和场景分割）以及事件云任务（动作识别）上的实验表明，相比传统的基于时间步长的方法，AMP2能够稳定SNN训练并保持竞争力的同时减少延迟。&lt;h4&gt;结论&lt;/h4&gt;所提出的AMP2激活策略可以作为一种通用的解决方案来改善SNN在各种视觉任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the similar characteristics between event-based visual data and pointclouds, recent studies have emerged that treat event data as event clouds tolearn based on point cloud analysis. Additionally, some works approach pointclouds from the perspective of event vision, employing Spiking Neural Network(SNN) due to their asynchronous nature. However, these contributions are oftendomain-specific, making it difficult to extend their applicability to otherintersecting fields. Moreover, while SNN-based visual tasks have seensignificant growth, the conventional timestep-wise iterative activationstrategy largely limits their real-world applications by large timesteps,resulting in significant delays and increased computational costs. Althoughsome innovative methods achieve good performance with short timesteps (&lt;10),few have fundamentally restructured the update strategy of spiking neurons tocompletely overcome the limitations of timesteps. In response to theseconcerns, we propose a novel and general activation strategy for spikingneurons called Activation-wise Membrane Potential Propagation (AMP2). Thisapproach extends the concept of timesteps from a manually crafted parameterwithin the activation function to any existing network structure. Inexperiments on common point cloud tasks (classification, object, and scenesegmentation) and event cloud tasks (action recognition), we found that AMP2stabilizes SNN training, maintains competitive performance, and reduces latencycompared to the traditional timestep-wise activation paradigm.</description>
      <author>example@mail.com (Jian Song, Boxuan Zheng, Xiangfei Yang, Donglin Wang)</author>
      <guid isPermaLink="false">2502.12791v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RadSplatter: Extending 3D Gaussian Splatting to Radio Frequencies for Wireless Radiomap Extrapolation</title>
      <link>http://arxiv.org/abs/2502.12686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RadSplatter是一个将3D高斯散射扩展到无线电频率的框架，旨在通过稀疏测量有效且准确地构建无线信号强度的空间分布图（即辐射图），适用于网络优化和自动驾驶等场景。&lt;h4&gt;背景&lt;/h4&gt;无线信号强度空间分布图对于网络优化、自动驾驶等领域至关重要。然而，在大型室外网络中，由于规模大，构造此类地图的成本很高。&lt;h4&gt;目的&lt;/h4&gt;提出RadSplatter框架，用于从稀疏测量中高效准确地推断出完整的辐射图。&lt;h4&gt;方法&lt;/h4&gt;利用3D高斯模型表示环境散射器和无线电路径，并通过放松均值方案重新参数化3D高斯的位置。此外，还开发了一种相机无关的3DGS投影技术来将3D高斯映射到2D无线电波束模式上。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RadSplatter在合成数据和真实世界场景中展示了最先进的外推准确性和执行速度。&lt;h4&gt;结论&lt;/h4&gt;通过结合环境散射器建模、优化的参数化方案以及高效的投影技术，RadSplatter能够从稀疏信号测量中生成高精度的辐射图，适用于大规模无线网络。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个新的框架RadSplatter，它将3D高斯散点扩展到无线电频率，旨在通过稀疏测量高效准确地推断出整个系统的无线信号强度分布地图（即辐射图）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A radiomap represents the spatial distribution of wireless signal strength,critical for applications like network optimization and autonomous driving.However, constructing radiomap relies on measuring radio signal power acrossthe entire system, which is costly in outdoor environments due to large networkscales. We present RadSplatter, a framework that extends 3D Gaussian Splatting(3DGS) to radio frequencies for efficient and accurate radiomap extrapolationfrom sparse measurements. RadSplatter models environmental scatterers and radiopaths using 3D Gaussians, capturing key factors of radio wave propagation. Itemploys a relaxed-mean (RM) scheme to reparameterize the positions of 3DGaussians from noisy and dense 3D point clouds. A camera-free 3DGS-basedprojection is proposed to map 3D Gaussians onto 2D radio beam patterns.Furthermore, a regularized loss function and recursive fine-tuning using highlystructured sparse measurements in real-world settings are applied to ensurerobust generalization. Experiments on synthetic and real-world data showstate-of-the-art extrapolation accuracy and execution speed.</description>
      <author>example@mail.com (Yiheng Wang, Ye Xue, Shutao Zhang, Tsung-Hui Chang)</author>
      <guid isPermaLink="false">2502.12686v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>S2C: Learning Noise-Resistant Differences for Unsupervised Change Detection in Multimodal Remote Sensing Images</title>
      <link>http://arxiv.org/abs/2502.12604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的无监督变化检测（UCD）框架，该框架适用于同质和异构的遥感图像。通过结合视觉基础模型（VFM）和对比学习方法论，引入了Semantic-to-Change (S2C) 学习框架。&lt;h4&gt;背景&lt;/h4&gt;多模态遥感影像中的无监督变化检测是一个具有挑战性的问题，由于其固有的时空复杂性和不同成像传感器导致的异质性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的对比学习方法论，将视觉基础模型中隐含的知识转化为变化表示，以消除显式监督的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的三元组学习策略，明确地建模时间差异，并引入随机空间和光谱扰动来增强对时间噪声的鲁棒性。定义了网格稀疏正则化以抑制不重要的变化，并开发了一个IoU匹配算法来优化变化检测结果。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准变化检测数据集上的实验表明，提出的S2C学习框架实现了显著的准确性改进，分别超过了当前最佳方法31%，9%，23%和15%。该方法还展示了良好的鲁棒性和样本效率，适用于各种视觉基础模型或骨干神经网络的训练和适应。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在无监督变化检测任务中具有优势，并且易于与其他视觉基础模型集成。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) images remains a difficult challenge due to the inherent spatio-temporal complexity within data, and the heterogeneity arising from different imaging sensors. Inspired by recent advancements in Visual Foundation Models (VFMs) and Contrastive Learning (CL) methodologies, this research aims to develop CL methodologies to translate implicit knowledge in VFM into change representations, thus eliminating the need for explicit supervision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Change Detection (UCD) in multimodal Remote Sensing (RS) imagesremains a difficult challenge due to the inherent spatio-temporal complexitywithin data, and the heterogeneity arising from different imaging sensors.Inspired by recent advancements in Visual Foundation Models (VFMs) andContrastive Learning (CL) methodologies, this research aims to develop CLmethodologies to translate implicit knowledge in VFM into changerepresentations, thus eliminating the need for explicit supervision. To thisend, we introduce a Semantic-to-Change (S2C) learning framework for UCD in bothhomogeneous and multimodal RS images. Differently from existing CLmethodologies that typically focus on learning multi-temporal similarities, weintroduce a novel triplet learning strategy that explicitly models temporaldifferences, which are crucial to the CD task. Furthermore, random spatial andspectral perturbations are introduced during the training to enhance robustnessto temporal noise. In addition, a grid sparsity regularization is defined tosuppress insignificant changes, and an IoU-matching algorithm is developed torefine the CD results. Experiments on four benchmark CD datasets demonstratethat the proposed S2C learning framework achieves significant improvements inaccuracy, surpassing current state-of-the-art by over 31\%, 9\%, 23\%, and15\%, respectively. It also demonstrates robustness and sample efficiency,suitable for training and adaptation of various Visual Foundation Models (VFMs)or backbone neural networks. The relevant code will be available at:github.com/DingLei14/S2C.</description>
      <author>example@mail.com (Lei Ding, Xibing Zuo, Danfeng Hong, Haitao Guo, Jun Lu, Zhihui Gong, Lorenzo Bruzzone)</author>
      <guid isPermaLink="false">2502.12604v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection</title>
      <link>http://arxiv.org/abs/2502.12948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Poster at Workshop on Large Language Models and Generative AI for  Health at AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种仅基于临床报告文本训练的模型，用于检测心脏LGE MRI图像中的疤痕。通过引入合成数据增强、标准化图像方向以及使用描述性损失来改进性能。&lt;h4&gt;背景&lt;/h4&gt;检测心脏LGE MRI图像中的高增强（hyperenhancement）是一个需要大量临床专业知识的任务。虽然基于深度学习的方法在该任务上取得了显著成果，但这些方法通常需要大量的带细粒度标注的数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种仅利用临床报告文本训练的模型来执行LGE检测，并通过各种策略提高其性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用合成数据增强技术创建疤痕图像及关联文本；2. 采用解剖学导向的方式标准化图像方向，以更好地对齐空间和文本特征；3. 利用描述性损失提供细粒度监督；4. 探索视觉编码器预训练对性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过上述方法的结合使用，模型在相对较小的临床队列（965名患者）上表现优异。此外，进行了消融实验以阐明每个设计组件对于整体性能的贡献。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的方法证明了仅依靠文本信息进行心脏病变检测的可能性，并展示了如何通过合成数据和描述性损失等技术提高模型性能。&lt;h4&gt;翻译&lt;/h4&gt;心脏LGE MRI图像中高增强（hyperenhancement）的检测是一项需要高水平临床知识的任务。尽管深度学习方法在该领域取得了进展，但这些方法通常依赖于大量带有详细标注的数据。研究团队利用来自心脏病理MRI检查报告中的丰富信息训练模型，并采用一系列策略提升性能，如通过合成数据扩展文本和图像对、解剖学导向标准化图像方向等。实验表明，在较小规模的患者样本中这种方法可以有效工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detection of hyperenhancement from cardiac LGE MRI images is a complex taskrequiring significant clinical expertise. Although deep learning-based modelshave shown promising results for the task, they require large amounts of datawith fine-grained annotations. Clinical reports generated for cardiac MRstudies contain rich, clinically relevant information, including the location,extent and etiology of any scars present. Although recently developedCLIP-based training enables pretraining models with image-text pairs, itrequires large amounts of data and further finetuning strategies on downstreamtasks. In this study, we use various strategies rooted in domain knowledge totrain a model for LGE detection solely using text from clinical reports, on arelatively small clinical cohort of 965 patients. We improve performancethrough the use of synthetic data augmentation, by systematically creating scarimages and associated text. In addition, we standardize the orientation of theimages in an anatomy-informed way to enable better alignment of spatial andtext features. We also use a captioning loss to enable fine-grained supervisionand explore the effect of pretraining of the vision encoder on performance.Finally, ablation studies are carried out to elucidate the contributions ofeach design component to the overall performance of the model.</description>
      <author>example@mail.com (Athira J Jacob, Puneet Sharma, Daniel Rueckert)</author>
      <guid isPermaLink="false">2502.12948v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Myna: Masking-Based Contrastive Learning of Musical Representations</title>
      <link>http://arxiv.org/abs/2502.12511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Myna是一种基于对比学习框架的简单而有效的自监督音乐表示学习方法。&lt;h4&gt;背景&lt;/h4&gt;之前的自监督学习方法在批处理大小、音高敏感性以及关键特征捕捉上存在一定的局限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据增强策略，即token masking，并采用视觉变换器（ViT）作为骨干网络，以提升模型性能和效率。&lt;h4&gt;方法&lt;/h4&gt;利用垂直补丁和masking 90%的光谱图标记来改进表示学习，同时避免了传统增广方式对音高敏感性的破坏。&lt;h4&gt;主要发现&lt;/h4&gt;{'批处理大小提升': 'token masking使得每个GPU上的批量尺寸显著增加到4096', '增强音高敏感性': '通过避免传统的数据增强方法，保留了音高的敏感性，在如音调检测等任务中表现更佳', '关键特征捕捉': '使用垂直补丁更好地捕获用于音调检测的关键特性'}&lt;h4&gt;结论&lt;/h4&gt;{'性能优越': '在单个GPU上训练的Myna-22M-Hybrid模型超越了之前的方法，包括62M参数量的MULE模型', '设置新记录': '在公开可用的数据上训练的Myna-22M-Hybrid模型超过了95M参数量的MERT-95M-public'}&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文已经给出，此处省略&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Myna, a simple yet effective approach for self-supervised musicalrepresentation learning. Built on a contrastive learning framework, Mynaintroduces two key innovations: (1) the use of a Vision Transformer (ViT) onmel-spectrograms as the backbone and (2) a novel data augmentation strategy,token masking, that masks 90 percent of spectrogram tokens. These innovationsdeliver both effectiveness and efficiency: (i) Token masking enables asignificant increase in per-GPU batch size, from 48 or 120 in prior methods(CLMR, MULE) to 4096. (ii) By avoiding traditional augmentations, Myna retainspitch sensitivity, enhancing performance in tasks like key detection. (iii) Theuse of vertical patches allows the model to better capture critical featuresfor key detection. Our hybrid model, Myna-22M-Hybrid, processes both 16x16 and128x2 patches, achieving state-of-the-art results. Trained on a single GPU, itoutperforms MULE (62M) on average and rivals MERT-95M, which was trained on 16and 64 GPUs, respectively. Additionally, it surpasses MERT-95M-public,establishing itself as the best-performing model trained on publicly availabledata. We release our code and models to promote reproducibility and facilitatefuture research.</description>
      <author>example@mail.com (Ori Yonay, Tracy Hammond, Tianbao Yang)</author>
      <guid isPermaLink="false">2502.12511v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Performance of Zero-Shot Time Series Foundation Models on Cloud Data</title>
      <link>http://arxiv.org/abs/2502.12944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了时间序列基础模型在云数据上的有效性，发现这些模型往往无法生成有意义或准确的零样本预测，并且其性能被简单的线性基线模型超越。&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型（FMs）作为跨多个不同领域的时间序列进行零样本预测的一种流行范式而出现。它们声称在包括云计算数据在内的多个领域中具有有效性。&lt;h4&gt;目的&lt;/h4&gt;探讨时间序列基础模型在云数据上的实际效果是否与其声称的一致。&lt;h4&gt;方法&lt;/h4&gt;通过实验评估了多种知名的基础模型在处理云数据时的性能，并将这些模型与简单的线性基线模型进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;许多流行的时间序列基础模型无法生成有意义或准确的零样本预测，其性能被简单的线性模型超越。此外，研究还揭示了一些有趣的病态现象，例如某些情况下，模型会突然输出看似随机的预测结果。&lt;h4&gt;结论&lt;/h4&gt;研究表明，时间序列基础模型在建模云数据方面存在广泛的问题和挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models (FMs) have emerged as a popular paradigm forzero-shot multi-domain forecasting. FMs are trained on numerous diversedatasets and claim to be effective forecasters across multiple different timeseries domains, including cloud data. In this work we investigate this claim,exploring the effectiveness of FMs on cloud data. We demonstrate that manywell-known FMs fail to generate meaningful or accurate zero-shot forecasts inthis setting. We support this claim empirically, showing that FMs areoutperformed consistently by simple linear baselines. We also illustrate anumber of interesting pathologies, including instances where FMs suddenlyoutput seemingly erratic, random-looking forecasts. Our results suggest awidespread failure of FMs to model cloud data.</description>
      <author>example@mail.com (William Toner, Thomas L. Lee, Artjom Joosen, Rajkarn Singh, Martin Asenov)</author>
      <guid isPermaLink="false">2502.12944v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation</title>
      <link>http://arxiv.org/abs/2502.12638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025, 10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个用于3D分子生成的模型NExT-Mol，结合了1D语言模型和3D扩散模型的优势。&lt;h4&gt;背景&lt;/h4&gt;当前在药物发现和材料设计中的3D分子生成中，大多数研究集中在使用3D扩散模型来建模连续的3D构象，但忽视了基于SELFIES的一维语言模型（LM）的优势。一维语言模型可以生成100%有效的分子，并利用大规模的一维分子数据集。&lt;h4&gt;目的&lt;/h4&gt;提出一个结合了一维SELFIES基语言模型和三维扩散模型优点的基础模型NExT-Mol以提高3D分子生成的性能。&lt;h4&gt;方法&lt;/h4&gt;NExT-Mol使用广泛预训练的分子LM进行一维分子生成，随后用3D扩散模型预测该分子的3D构象。通过增大LM模型尺寸、改进扩散神经网络架构和应用1D到3D迁移学习来提高其性能。&lt;h4&gt;主要发现&lt;/h4&gt;提出的1D分子LM在分布相似性上显著优于基线，并确保了有效性；3D扩散模型在构象预测方面取得了领先的成绩。基于这些改善，在GEOM-DRUGS的从头3D生成中，NExT-Mol实现了26%相对改进的3DFCD；在QM9-2014上的条件3D生成中平均获得13%相对收益。&lt;h4&gt;结论&lt;/h4&gt;通过结合SELFIES语言模型和扩散模型的优势，NExT-Mol为3D分子生成提供了一种新的方法。该方法提高了生成有效且高质量的3D分子的能力。&lt;h4&gt;翻译&lt;/h4&gt;3D分子生成对于药物发现及材料设计至关重要。先前的研究主要集中在利用三维扩散模型来建模连续的三维构象上，但忽略了基于SELFIES的一维语言模型的优势，后者可以完全生成有效的分子，并能利用大规模的一维分子数据集进行训练。为了结合这些优势，我们提出了一个基础模型NExT-Mol：将一维语言建模与三维扩散相结合以实现3D分子生成。NExT-Mol首先使用经过充分预训练的1D分子LM来生成分子，随后通过一个3D扩散模型预测该分子的3D构象，并在此基础上进行了一系列性能增强措施，包括增大LM模型尺寸、改进扩散神经网络架构以及应用从一维到三维的迁移学习。实验表明，我们的一维分子LM在分布相似性上显著优于基线模型并保证了生成的有效性；我们的三维扩散模型在构象预测方面取得了领先的成绩。基于这些提升，在GEOM-DRUGS上的从头3D生成中，NExT-Mol实现了26%相对改进的FCD分数，并且在QM9-2014数据集上进行条件生成时平均获得13%的相对收益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D molecule generation is crucial for drug discovery and material design.While prior efforts focus on 3D diffusion models for their benefits in modelingcontinuous 3D conformers, they overlook the advantages of 1D SELFIES-basedLanguage Models (LMs), which can generate 100% valid molecules and leverage thebillion-scale 1D molecule datasets. To combine these advantages for 3D moleculegeneration, we propose a foundation model -- NExT-Mol: 3D Diffusion Meets 1DLanguage Modeling for 3D Molecule Generation. NExT-Mol uses an extensivelypretrained molecule LM for 1D molecule generation, and subsequently predictsthe generated molecule's 3D conformers with a 3D diffusion model. We enhanceNExT-Mol's performance by scaling up the LM's model size, refining thediffusion neural architecture, and applying 1D to 3D transfer learning.Notably, our 1D molecule LM significantly outperforms baselines indistributional similarity while ensuring validity, and our 3D diffusion modelachieves leading performances in conformer prediction. Given these improvementsin 1D and 3D modeling, NExT-Mol achieves a 26% relative improvement in 3D FCDfor de novo 3D generation on GEOM-DRUGS, and a 13% average relative gain forconditional 3D generation on QM9-2014. Our codes and pretrained checkpoints areavailable at https://github.com/acharkq/NExT-Mol.</description>
      <author>example@mail.com (Zhiyuan Liu, Yanchen Luo, Han Huang, Enzhi Zhang, Sihang Li, Junfeng Fang, Yaorui Shi, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua)</author>
      <guid isPermaLink="false">2502.12638v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem</title>
      <link>http://arxiv.org/abs/2502.12617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper presents a novel deep reinforcement learning framework  combining graph neural networks with actor-critic architectures to address  the aircraft landing problem. The framework achieves a 99.95% reduction in  computational time compared to Mixed Integer Programming while maintaining  safety compliance, and 38% higher runway throughput over First Come First  Serve&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一种基于深度强化学习的新型框架，用于解决飞机着陆问题（ALP）。该方法结合了图神经网络和演员评论家架构，并展示了在标准基准数据集上优于传统操作研究算法的结果。&lt;h4&gt;背景&lt;/h4&gt;飞机着陆问题是航空运输管理中的一个挑战性难题。现有的解决方案大多基于运营研究算法和元启发式算法，但这些方法在处理实时再调度和计算可扩展性方面仍存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的深度强化学习框架来解决ALP，并展示其在不同因素上的改进效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一个图基状态表示法、用于多目标竞争着陆调度的专业演员评论家架构以及跑道平衡策略，后者确保资源利用效率同时满足安全约束条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该算法与操作研究算法相比计算时间减少了99.95%，并且在跑道吞吐量方面比先到先服务方法高38%。此外，它可以在1秒内生成解决方案，并且不需要重新训练，非常适用于工业部署。&lt;h4&gt;结论&lt;/h4&gt;所提出的解决方案具有显著的性能改进和实用性，在实时再调度方面特别有优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：飞机着陆问题是航空运输管理中的一个挑战性难题，其目标是通过优化成本和延迟来安排到达的飞机序列。尽管传统方法在某些因素上表现良好，但它们在处理实际时间重新调度和计算可扩展性方面仍存在问题。本文介绍了一种结合图神经网络与演员评论家架构的深度强化学习框架，用于解决ALP，并提出了三个关键贡献：一种有效的捕捉飞机之间时空关系的图基状态表示法；一种处理多目标竞争着陆调度的专业化演员评论家架构以及确保资源利用效率并保持安全约束条件的跑道平衡策略。实验结果表明，训练后的算法在不同的问题集上表现出竞争力，并且与混合整数规划相比，在标准基准数据集上的计算时间减少了99.95%，比先到先服务方法高38%的跑道吞吐量。因此，该方案对于传统方法具有竞争力并实现了显著进步。值得注意的是，它不需要重新训练，使其特别适合于工业部署。框架生成解决方案的能力在1秒内使其实现了实时再调度，满足了空中交通管理的关键需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Aircraft Landing Problem (ALP) is one of the challenging problems inaircraft transportation and management. The challenge is to schedule thearriving aircraft in a sequence so that the cost and delays are optimized.There are various solution approaches to solving this problem, most of whichare based on operations research algorithms and meta-heuristics. Althoughtraditional methods perform better on one or the other factors, there remains aproblem of solving real-time rescheduling and computational scalabilityaltogether. This paper presents a novel deep reinforcement learning (DRL)framework that combines graph neural networks with actor-critic architecturesto address the ALP. This paper introduces three key contributions: Agraph-based state representation that efficiently captures temporal and spatialrelationships between aircraft, a specialized actor-critic architecturedesigned to handle multiple competing objectives in landing scheduling, and arunway balance strategy that ensures efficient resource utilization whilemaintaining safety constraints. The results show that the trained algorithm canbe tested on different problem sets and the results are competitive tooperation research algorithms. The experimental results on standard benchmarkdata sets demonstrate a 99.95 reduction in computational time compared to MixedInteger Programming (MIP) and 38 higher runway throughput over First Come FirstServe (FCFS) approaches. Therefore, the proposed solution is competitive totraditional approaches and achieves substantial advancements. Notably, it doesnot require retraining, making it particularly suitable for industrialdeployment. The frameworks capability to generate solutions within 1 secondenables real-time rescheduling, addressing critical requirements of air trafficmanagement.</description>
      <author>example@mail.com (Vatsal Maru)</author>
      <guid isPermaLink="false">2502.12617v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>UniGenCoder: Merging Seq2Seq and Seq2Tree Paradigms for Unified Code Generation</title>
      <link>http://arxiv.org/abs/2502.12490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICSE2025 NIER track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于深度学习的代码生成已经彻底改变了当今开发者编写程序的方式。&lt;h4&gt;背景&lt;/h4&gt;现有的代码生成方法主要集中在序列到序列（Sequence-to-Sequence）或序列到树（Sequence-to-Tree）两个范式上，这两种范式虽然直观互补，但之前没有结合探索过。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一个统一这两个范式的框架，并探讨其在文本转代码和代码转代码任务上的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了名为UniGenCoder的模型，该模型包括一个共享编码器、带有少量额外参数的共享解码器以及一个动态选择最优范式的选择器。同时，在训练过程中采用了多任务学习和蒸馏策略来促进两种范式的知识转移，并利用对比学习训练选择器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过结合序列到序列和序列到树两个范式生成代码具有显著潜力。&lt;h4&gt;结论&lt;/h4&gt;提出的UniGenCoder模型在文本转代码和代码转代码任务上都显示出了有效性。该研究证明了集成这两个范式的可行性，并且为未来的相关研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;基于深度学习的代码生成已经彻底改变了当今开发者编写程序的方式。现有的方法主要集中在序列到序列（Sequence-to-Sequence）或序列到树（Sequence-to-Tree）两种模式上，这两种模式虽然直观互补，但之前没有结合探索过。我们提出了一种名为UniGenCoder的新框架，它包括一个共享编码器、带有少量额外参数的共享解码器以及一个动态选择最优范式的选择器，并且在训练过程中采用了多任务学习和蒸馏策略来促进两种模式之间的知识转移。此外，利用对比学习技术训练了选择器以提高模型性能。实验结果显示，在文本转代码及代码转代码的任务中，该模型表现出了良好的效果，证明了结合使用这两种方法的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based code generation has completely transformed the waydevelopers write programs today. Existing approaches to code generation havefocused either on the Sequence-to-Sequence paradigm, which generates targetcode as a sequence of tokens, or the Sequence-to-Tree paradigm, which outputscode as a sequence of actions. While these two paradigms are intuitivelycomplementary, their combination has not been previously explored. By comparingthe code generated under these two paradigms, we find that integrating themholds significant potential. In this paper, we propose UniGenCoder forcode-related generation tasks, which consists of a shared encoder, a shareddecoder with a minimal set of additional parameters to unify two paradigms, anda selector that dynamically chooses optimal paradigm for each instance. Also,during the model training, we first perform the multi-task learning anddistillation strategies to facilitate knowledge transfer between two paradigms,and then leverage contrastive learning to train the selector. Experimentalresults on the text-to-code and code-to-code generation tasks demonstrate theeffectiveness of our proposed model. We release our code athttps://github.com/DeepLearnXMU/UniGenCoder.</description>
      <author>example@mail.com (Liangying Shao, Yanfu Yan, Denys Poshyvanyk, Jinsong Su)</author>
      <guid isPermaLink="false">2502.12490v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>DivIL: Unveiling and Addressing Over-Invariance for Out-of- Distribution Generalization</title>
      <link>http://arxiv.org/abs/2502.12413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了机器学习模型在面对不同于训练数据分布的新环境时的表现问题，提出了一种新的方法来解决过度不变性导致的性能下降。&lt;h4&gt;背景&lt;/h4&gt;跨不同分布进行泛化的挑战。一种常见的策略是不变学习（IL），它试图使模型关注于不变特征而不是虚假相关特性。&lt;h4&gt;目的&lt;/h4&gt;减轻不变约束过强带来的不利影响，并探索如何通过添加额外机制来补偿这些限制，从而提高模型的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架Diverse Invariant Learning (DivIL)，结合了无监督对比学习和随机掩码机制来对抗过度不变性的问题。该方法适用于多种不变学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;在理论层面定义了过度不变性的概念，并观察到这种问题出现在不同的经典不变学习方法中。实验结果表明，DivIL框架有效减轻了过度不变性的影响。&lt;h4&gt;结论&lt;/h4&gt;通过引入无监督对比学习和随机掩码机制来补偿过强的不变约束，可以提高模型的泛化能力，特别是在多样化的环境和多模态数据集上表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;跨分布泛化是一个常见问题，期望模型在训练数据之外的不同分布中也能表现出色。一种流行的解决方法是不变学习（IL），通过在训练过程中添加强约束使模型专注于不变特征而非虚假相关特性。然而，这种方法可能存在过度不变性的问题，即由于有限的多样化环境和特征空间中的过正则化导致重要细节丢失。本文定义了过度不变性的概念，并观察到这种问题存在于各种经典IL方法中。为解决此问题，提出了一种简单的方法Diverse Invariant Learning (DivIL)，通过添加无监督对比学习和随机掩码机制来补偿强约束。该方法适用于多种IL方法。实验在多个模式的12个数据集和6种经典模型上进行，验证了过度不变性的见解以及DivIL框架的有效性。代码位于https://github.com/kokolerk/DivIL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution generalization is a common problem that expects the modelto perform well in the different distributions even far from the train data. Apopular approach to addressing this issue is invariant learning (IL), in whichthe model is compiled to focus on invariant features instead of spuriousfeatures by adding strong constraints during training. However, there are somepotential pitfalls of strong invariant constraints. Due to the limited numberof diverse environments and over-regularization in the feature space, it maylead to a loss of important details in the invariant features while alleviatingthe spurious correlations, namely the over-invariance, which can also degradethe generalization performance. We theoretically define the over-invariance andobserve that this issue occurs in various classic IL methods. To alleviate thisissue, we propose a simple approach Diverse Invariant Learning (DivIL) byadding the unsupervised contrastive learning and the random masking mechanismcompensatory for the invariant constraints, which can be applied to various ILmethods. Furthermore, we conduct experiments across multiple modalities across12 datasets and 6 classic models, verifying our over-invariance insight and theeffectiveness of our DivIL framework. Our code is available athttps://github.com/kokolerk/DivIL.</description>
      <author>example@mail.com (Jiaqi Wang, Yuhang Zhou, Zhixiong Zhang, Qiguang Chen, Yongqiang Chen, James Cheng)</author>
      <guid isPermaLink="false">2502.12413v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>NoKSR: Kernel-Free Neural Surface Reconstruction via Point Cloud Serialization</title>
      <link>http://arxiv.org/abs/2502.12534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: see /https://theialab.github.io/noksr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的大规模点云表面重构的方法，通过开发一个高效的框架将不规则的点云转换为符号距离场（SDF）。&lt;h4&gt;背景&lt;/h4&gt;现有的大规模点云处理方法存在效率和准确性之间的权衡问题，特别是在稀疏网格方法在室外数据集上的表现有限的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Transformer架构的方法来提高点云表面重构的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;{'框架基础': '该研究建立于最近的Transformer架构（PointTransformerV3）之上，将点云序列化为一个保持局部性的令牌序列。', 'SDF预测': '通过聚合附近令牌来高效地预测某一点上的SDF值，并且可以快速检索近似邻居以提高效率。', '多尺度处理': '在不同的层次/尺度上序列化点云，非线性聚合特征以预测SDF值。跨多个尺度的聚集对于克服由序列化引入的假阴性问题至关重要。', '框架特点': '该方法不仅性能优异（与现有最佳方法相比，在延迟减少一半的情况下保持了相似或更好的性能），而且实现更为简单。'}&lt;h4&gt;主要发现&lt;/h4&gt;跨多尺度处理是提高SDF预测准确性的重要因素，特别是在稀疏点云数据中。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在精度和效率方面均优于现有方法，并且特别适用于室外场景的处理。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach to large-scale point cloud surface reconstructionby developing an efficient framework that converts an irregular point cloudinto a signed distance field (SDF). Our backbone builds upon recenttransformer-based architectures (i.e., PointTransformerV3), that serializes thepoint cloud into a locality-preserving sequence of tokens. We efficientlypredict the SDF value at a point by aggregating nearby tokens, where fastapproximate neighbors can be retrieved thanks to the serialization. Weserialize the point cloud at different levels/scales, and non-linearlyaggregate a feature to predict the SDF value. We show that aggregating acrossmultiple scales is critical to overcome the approximations introduced by theserialization (i.e. false negatives in the neighborhood). Our frameworks setsthe new state-of-the-art in terms of accuracy and efficiency (better or similarperformance with half the latency of the best prior method, coupled with asimpler implementation), particularly on outdoor datasets where sparse-gridmethods have shown limited performance.</description>
      <author>example@mail.com (Zhen Li, Weiwei Sun, Shrisudhan Govindarajan, Shaobo Xia, Daniel Rebain, Kwang Moo Yi, Andrea Tagliasacchi)</author>
      <guid isPermaLink="false">2502.12534v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Time-series attribution maps with regularized contrastive learning</title>
      <link>http://arxiv.org/abs/2502.12977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at The 28th International Conference on Artificial  Intelligence and Statistics (AISTATS 2025). Code is available at  https://github.com/AdaptiveMotorControlLab/CEBRA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的时间序列数据可识别的归因图生成算法和方法（xCEBRA），通过对比学习和逆神经元梯度法，理论上证明其能更准确地标识生成过程中的雅克比矩阵，并在合成数据集上展示出对真实属性映射零与非零项的良好拟合。&lt;h4&gt;背景&lt;/h4&gt;现有的基于梯度的归因方法用于解释深度学习模型的决策但缺乏可识别性保证。当前，时间序列数据的归因图生成仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的对比学习算法以及逆神经元梯度法（Inverted Neuron Gradient），以生成具有理论保障的时间序列属性映射。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合正则化对比学习和新提出的逆神经元梯度法的框架，旨在生成可识别的归因图，并验证其在合成数据集上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了xCEBRA能有效标识时间序列数据中雅克比矩阵的零与非零项；实证上显示，在各种基于特征删除、Shapley值以及其他梯度方法前，展示了显著改进。&lt;h4&gt;结论&lt;/h4&gt;这项工作为可识别的时间序列归因图推断提供了首个实例，并为神经动态学和决策过程的理解开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gradient-based attribution methods aim to explain decisions of deep learningmodels but so far lack identifiability guarantees. Here, we propose a method togenerate attribution maps with identifiability guarantees by developing aregularized contrastive learning algorithm trained on time-series data plus anew attribution method called Inverted Neuron Gradient (collectively namedxCEBRA). We show theoretically that xCEBRA has favorable properties foridentifying the Jacobian matrix of the data generating process. Empirically, wedemonstrate robust approximation of zero vs. non-zero entries in theground-truth attribution map on synthetic datasets, and significantimprovements across previous attribution methods based on feature ablation,Shapley values, and other gradient-based methods. Our work constitutes a firstexample of identifiable inference of time-series attribution maps and opensavenues to a better understanding of time-series data, such as for neuraldynamics and decision-processes within neural networks.</description>
      <author>example@mail.com (Steffen Schneider, Rodrigo González Laiz, Anastasiia Filippova, Markus Frey, Mackenzie Weygandt Mathis)</author>
      <guid isPermaLink="false">2502.12977v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Healthcare cost prediction for heterogeneous patient profiles using deep learning models with administrative claims data</title>
      <link>http://arxiv.org/abs/2502.12277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于深度学习的框架，用于设计患者成本预测模型，以有效解决管理性索赔数据中的异质性和复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;准确且公平的患者成本预测对于制定健康管理制度和优化资源配置至关重要，这有助于在医疗支付方（包括政府机构和私人保险公司）中实现显著的成本节约。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够应对行政索赔数据中异质性的方法，并特别关注具有复杂慢性病的高需求患者的准确、公正及可推广的预测模型。&lt;h4&gt;方法&lt;/h4&gt;该研究基于社会技术考量，强调技术系统（如深度学习模型）与人文主义结果（例如医疗决策中的公平性）之间的相互作用。它采用表示学习和熵度量来处理数据异质性和复杂性，特别是对于高需求患者。提出了一种通道化深度学习框架，通过根据类型对管理索赔数据进行细分来缓解数据异质性。&lt;h4&gt;主要发现&lt;/h4&gt;与单通道模型相比，所提出的通道化模型将预测误差降低了23%，分别导致过度支付和不足支付减少16.4%和19.3%。对于高需求患者的预测偏差降低尤为显著，这表明该框架在处理数据和患者档案的异质性和复杂性方面有效。&lt;h4&gt;结论&lt;/h4&gt;这种通道化建模方法具有应用于类似异质性挑战领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;问题是如何设计能有效解决管理索赔（AC）数据异质性的患者成本预测模型，以确保准确、公平且可推广的预测，尤其是针对高需求（HN）患者的复杂慢性病。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Problem: How can we design patient cost prediction models that effectivelyaddress the challenges of heterogeneity in administrative claims (AC) data toensure accurate, fair, and generalizable predictions, especially for high-need(HN) patients with complex chronic conditions?  Relevance: Accurate and equitable patient cost predictions are vital fordeveloping health management policies and optimizing resource allocation, whichcan lead to significant cost savings for healthcare payers, includinggovernment agencies and private insurers. Addressing disparities in predictionoutcomes for HN patients ensures better economic and clinical decision-making,benefiting both patients and payers.  Methodology: This study is grounded in socio-technical considerations thatemphasize the interplay between technical systems (e.g., deep learning models)and humanistic outcomes (e.g., fairness in healthcare decisions). Itincorporates representation learning and entropy measurement to addressheterogeneity and complexity in data and patient profiles, particularly for HNpatients. We propose a channel-wise deep learning framework that mitigates dataheterogeneity by segmenting AC data into separate channels based on types ofcodes (e.g., diagnosis, procedures) and costs. This approach is paired with aflexible evaluation design that uses multi-channel entropy measurement toassess patient heterogeneity.  Results: The proposed channel-wise models reduce prediction errors by 23%compared to single-channel models, leading to 16.4% and 19.3% reductions inoverpayments and underpayments, respectively. Notably, the reduction inprediction bias is significantly higher for HN patients, demonstratingeffectiveness in handling heterogeneity and complexity in data and patientprofiles. This demonstrates the potential for applying channel-wise modeling todomains with similar heterogeneity challenges.</description>
      <author>example@mail.com (Mohammad Amin Morid, Olivia R. Liu Sheng)</author>
      <guid isPermaLink="false">2502.12277v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Transparent and Accurate Plasma State Monitoring at JET</title>
      <link>http://arxiv.org/abs/2502.12182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种透明且数据驱动的方法来监测托卡马克装置中的等离子体状态，该方法结合了监督学习和非监督学习技术，并通过多任务学习首次应用于等离子体状态监控。&lt;h4&gt;背景&lt;/h4&gt;控制和监控托卡马克设备中的等离子体是复杂而具有挑战性的。异常的等离子体事件（如中断）阻碍了稳定运行，并可能威胁大型装置的安全，这在未来的发电厂应用中是一个主要担忧。&lt;h4&gt;目的&lt;/h4&gt;提供一种可解释的等离子体状态表示方法来展示JET的操作空间，通过多任务学习首次应用于等离子体状态监控。&lt;h4&gt;方法&lt;/h4&gt;采用了一种结合监督和非监督机器学习技术的数据驱动方法。研究基于520个专家验证过的JET放电数据集进行。&lt;h4&gt;主要发现&lt;/h4&gt;序列基模型在预测中断方面显示出显著改进，特别是在结合物理指标并考虑邻近不稳定性的条件下取得了令人满意的交叉验证成功率。同时揭示了操作区域和破坏性区域以及学习的动力学模式的关联。&lt;h4&gt;结论&lt;/h4&gt;该方法为定义触发机制以切换不同的控制场景、数据分析和学习提供了新的可能性，并展示了在预测时间警告方面具有潜在的应用价值，且结果与已知物理机制相一致。&lt;h4&gt;翻译&lt;/h4&gt;控制和监测托卡马克装置中的等离子体是复杂而具有挑战性的。异常的等离子体事件（如中断）阻碍了稳定运行，并可能威胁大型装置的安全性，这在未来的发电厂应用中是一个主要担忧。为了更好地理解这些现象及其演变过程，有效监控等离子体状态至关重要。本文介绍了首次将多任务学习应用于JET操作空间的研究方法，结合监督和非监督机器学习技术来监测等离子体状态。序列基模型显示了预测中断方面的显著改进，并揭示了操作区域和破坏性模式的关联。此外，该研究展示了在定义触发机制、数据分析和探索潜在动力学方面的新可能性以及预警时间的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling and monitoring plasma within a tokamak device is complex andchallenging. Plasma off-normal events, such as disruptions, are hinderingsteady-state operation. For large devices, they can even endanger the machine'sintegrity and it represents in general one of the most serious concerns for theexploitation of the tokamak concept for future power plants. Effective plasmastate monitoring carries the potential to enable an understanding of suchphenomena and their evolution which is crucial for the successful operation oftokamaks. This paper presents the application of a transparent and data-drivenmethodology to monitor the plasma state in a tokamak. Compared to previousstudies in the field, supervised and unsupervised learning techniques arecombined. The dataset consisted of 520 expert-validated discharges from JET.The goal was to provide an interpretable plasma state representation for theJET operational space by leveraging multi-task learning for the first time inthe context of plasma state monitoring. When evaluated as disruptionpredictors, a sequence-based approach showed significant improvements comparedto the state-based models. The best resulting network achieved a promisingcross-validated success rate when combined with a physical indicator andaccounting for nearby instabilities. Qualitative evaluations of the learnedlatent space uncovered operational and disruptive regions as well as patternsrelated to learned dynamics and global feature importance. The appliedmethodology provides novel possibilities for the definition of triggers toswitch between different control scenarios, data analysis, and learning as wellas exploring latent dynamics for plasma state monitoring. It also showedpromising quantitative and qualitative results with warning times suitable foravoidance purposes and distributions that are consistent with known physicalmechanisms.</description>
      <author>example@mail.com (Andrin Bürli, Alessandro Pau, Thomas Koller, Olivier Sauter, JET Contributors)</author>
      <guid isPermaLink="false">2502.12182v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Keep what you need : extracting efficient subnetworks from large audio representation models</title>
      <link>http://arxiv.org/abs/2502.12925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了从大型基础模型中提取轻量级专业子网络的方法，通过引入可学习的二进制掩码和稀疏性诱导损失来实现。这种方法在保持原始权重不变的情况下训练得到一个专注于单一任务的小型化模型。&lt;h4&gt;背景&lt;/h4&gt;近年来音频基础模型的研究取得了显著进展，在复杂下游任务上不断取得改进结果。然而，这些模型的大小和复杂度大幅增加，导致无法部署到消费级设备或用于实时应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单有效的方法来解决大型音频基础模型在小型化和专门化方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;通过在网络层之间添加可学习的二进制掩码，并引入稀疏性损失函数，在下游任务上训练端到端模型，从而学到一个专精于单一任务的小型子网络。保持原始模型权重不变，降低额外训练成本。&lt;h4&gt;主要发现&lt;/h4&gt;评估了该方法在三种广泛使用的音频基础模型上的效果，表明这种方法能够显著提高性能，并且适用于语音、音乐和通用音频等多种场景。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为解决大型音频基础模型的小型化问题提供了一种有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, research on audio foundation models has witnessed notable advances,as illustrated by the ever improving results on complex downstream tasks.Subsequently, those pretrained networks have quickly been used for variousaudio applications. These improvements have however resulted in a considerableincrease both in size and complexity of these models. Along the environmentalconcerns this issue raises, this prevents the deployment of such networks onconsumer-level devices, and precludes their use for real-time applications.Moreover, this appears contradictory with the specificity of the tasks forwhich these models are used, which are often simpler compared to extracting arich, multi-purpose representation from any type of audio data. In this paper,we address this issue with a simple, yet effective method to extractlightweight specialist subnetworks from large foundation models. Specifically,we introduce learnable binary masks in-between the layers of a pretrainedrepresentation model. When training the end-to-end model on a downstream task,we add a sparsity-inducing loss to the overall objective, hence learning acompact subnetwork specialized on a single task. Importantly, the weights ofthe foundation model are kept frozen, resulting into low additional trainingcosts. Once trained, the masked computational units can then be removed fromthe network, implying significant performance gains. We assess our method onthree widespread audio foundation models, each based on a different backbonearchitecture, and illustrate its effectiveness on common audio representationevaluation tasks, as well as its versatility on both speech, music, and generalaudio. Code for reproducing the results and supporting webpage are available athttps://github.com/gnvIRCAM/Audio-representation-trimming</description>
      <author>example@mail.com (David Genova, Philippe Esling, Tom Hurlin)</author>
      <guid isPermaLink="false">2502.12925v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Mode Connectivity in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.12608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了图神经网络（GNNs）中的模式连接性，揭示了其独特的非线性特性，并与图结构的性质建立了联系。&lt;h4&gt;背景&lt;/h4&gt;理解GNN优化动态和损失景观几何对于提高模型可解释性和鲁棒性至关重要。虽然模式连接性已用于分析其他深度学习架构的几何属性，但其在GNN中的应用尚属空白。&lt;h4&gt;目的&lt;/h4&gt;首次探索GNNs中的模式连接性，并研究它对理论理解和实际应用的意义。&lt;h4&gt;方法&lt;/h4&gt;通过实验揭示了不同图结构和模型架构下的非线性模式连接特性。建立了模式连接与泛化的联系，提出了基于损失障碍的泛化界。&lt;h4&gt;主要发现&lt;/h4&gt;1. GNNs展示出不同于全连接网络或CNN的独特非线性模式连接。2. 图结构（如同质性）而非模型架构主导了这种行为。3. 模式连接与泛化能力之间存在联系，有助于作为诊断工具。&lt;h4&gt;结论&lt;/h4&gt;研究结果不仅为GNN理论提供了新的见解，还指出了在图学习领域中进行领域对齐策略和改进训练范式的方向。&lt;h4&gt;翻译&lt;/h4&gt;理解图神经网络（GNNs）的核心挑战在于表征其优化动态和损失景观几何，这对于提高可解释性和鲁棒性至关重要。虽然模式连接已经为其他深度学习架构提供了有价值的视角来分析损失景观的几何性质，但对于GNN的影响仍然未被探索。这项工作首次对GNN中的模式连接进行了调查，并揭示了与全连接网络或CNN所观察到的不同非线性模式连接特性。更重要的是，研究结果表明图结构而非模型架构决定了这种行为，其中同质性等图属性会关联于模式连接的模式。此外，该研究建立了模式连接和泛化之间的联系，并提出了基于损失障碍的泛化界，揭示了其作为诊断工具的作用。我们的发现将理论洞察与实际应用相结合：它们为图学习中的领域对齐策略提供了理据，并为改进GNN训练范式奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A fundamental challenge in understanding graph neural networks (GNNs) lies incharacterizing their optimization dynamics and loss landscape geometry,critical for improving interpretability and robustness. While modeconnectivity, a lens for analyzing geometric properties of loss landscapes hasproven insightful for other deep learning architectures, its implications forGNNs remain unexplored. This work presents the first investigation of modeconnectivity in GNNs. We uncover that GNNs exhibit distinct non-linear modeconnectivity, diverging from patterns observed in fully-connected networks orCNNs. Crucially, we demonstrate that graph structure, rather than modelarchitecture, dominates this behavior, with graph properties like homophilycorrelating with mode connectivity patterns. We further establish a linkbetween mode connectivity and generalization, proposing a generalization boundbased on loss barriers and revealing its utility as a diagnostic tool. Ourfindings further bridge theoretical insights with practical implications: theyrationalize domain alignment strategies in graph learning and provide afoundation for refining GNN training paradigms.</description>
      <author>example@mail.com (Bingheng Li, Zhikai Chen, Haoyu Han, Shenglai Zeng, Jingzhe Liu, Jiliang Tang)</author>
      <guid isPermaLink="false">2502.12608v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Robust Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning</title>
      <link>http://arxiv.org/abs/2502.12425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的鲁棒且分解化的反事实学习(RDCL)方法，用于物理视听常识推理。该方法旨在通过视频和音频输入来推断物体的物理常识，并针对缺失模态的情况模仿人类的推理能力。&lt;h4&gt;背景&lt;/h4&gt;当前大多数方法未能充分利用多模态数据的不同特征，而且模型缺乏因果推理能力，阻碍了隐含物理知识推理的进步。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够解耦视频中的静态和动态因素的方法，并引入反事实学习模块以增强模型的推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过变分自编码器（VAE）结合对比损失函数在潜在空间中将视频分解为静态和动态因子；引入一个反事实学习模块来建模不同物体之间的物理知识关系；提出一种鲁棒多模态学习方法，通过解耦共享特征和特定于模型的特征以恢复缺失数据。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的RDCL方法不仅提高了基线方法的推理准确性和鲁棒性，还取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了在物理视听常识推理任务中应用反事实学习模块的有效性，并展示了其在处理多模态输入时增强模型因果推理能力的能力。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新的稳健分解式反事实学习（RDCL）方法，用于物理视听常识推理。该任务旨在基于视频和音频输入推断物体的物理常识，主要挑战是如何在缺少模态的情况下模仿人类的推理能力。目前大多数的方法未能充分利用多模态数据的不同特征，并且模型缺乏因果推理能力阻碍了隐含物理知识推理的进步。为了解决这些问题，我们提出的RDCL方法通过分解式序列编码器将视频在潜在空间中解耦为静态（时间不变）和动态（时间变化）因子，该编码器采用变分自编码器（VAE），通过对比损失函数最大化互信息。此外，我们引入了一个反事实学习模块以增强模型的推理能力，通过模拟不同物体之间的物理知识关系在假设干预的情况下进行建模。为了缓解缺失模态数据的问题，我们提出了一种鲁棒多模态学习方法，通过解耦共享特征和特定于模型的特征来恢复缺失的数据。所提出的RDCL是一个即插即用模块，可以被集成到任何基线中包括视觉语言模型（VLM）。在实验中，我们展示了我们的方法提高了基线方法的推理准确性和鲁棒性，并且达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a new Robust Disentangled Counterfactual Learning(RDCL) approach for physical audiovisual commonsense reasoning. The task aimsto infer objects' physics commonsense based on both video and audio input, withthe main challenge being how to imitate the reasoning ability of humans, evenunder the scenario of missing modalities. Most of the current methods fail totake full advantage of different characteristics in multi-modal data, andlacking causal reasoning ability in models impedes the progress of implicitphysical knowledge inferring. To address these issues, our proposed RDCL methoddecouples videos into static (time-invariant) and dynamic (time-varying)factors in the latent space by the disentangled sequential encoder, whichadopts a variational autoencoder (VAE) to maximize the mutual information witha contrastive loss function. Furthermore, we introduce a counterfactuallearning module to augment the model's reasoning ability by modeling physicalknowledge relationships among different objects under counterfactualintervention. To alleviate the incomplete modality data issue, we introduce arobust multimodal learning method to recover the missing data by decomposingthe shared features and model-specific features. Our proposed method is aplug-and-play module that can be incorporated into any baseline including VLMs.In experiments, we show that our proposed method improves the reasoningaccuracy and robustness of baseline methods and achieves the state-of-the-artperformance.</description>
      <author>example@mail.com (Mengshi Qi, Changsheng Lv, Huadong Ma)</author>
      <guid isPermaLink="false">2502.12425v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Online Adaption for Time Series Foundation Model Forecasts</title>
      <link>http://arxiv.org/abs/2502.12920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AdapTS是一种轻量级机制，旨在通过利用在线反馈来增强基础模型（FMs）在时间序列预测中的性能。&lt;h4&gt;背景&lt;/h4&gt;随着计算成本高昂，基础模型通常在部署时保持固定不变，无法根据当前数据特征调整其预测。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过有效使用在线反馈来提高基础模型的性能。&lt;h4&gt;方法&lt;/h4&gt;AdapTS由两部分组成：1）AdapTS-Forecaster用于学习当前数据分布；2）AdapTS-Weighter用于结合基础模型和AdapTS-Forecaster的预测结果。&lt;h4&gt;主要发现&lt;/h4&gt;在使用多种最近的基础模型以及一系列标准时间序列数据集进行评估后，发现在所有实验中使用AdapTS都能提高性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了如何通过高效利用在线反馈来改进基础模型的时间序列预测能力。&lt;h4&gt;翻译&lt;/h4&gt;基础模型（FMs）作为时间序列预测的一种有前途的方法已经出现。虽然有效，但由于在线学习时的高计算成本，这些模型在部署后通常保持固定不变。因此，尽管有新数据到达时提供的在线反馈可用性，已部署的基础模型仍无法根据当前数据特征调整其预测。这引发了关于基础模型性能是否可以通过有效地使用这种反馈来提升的问题。我们提出了AdapTS来解答这个问题。AdapTS是一种轻量级机制，旨在让基础模型的预测能够响应在线反馈而进行在线适应。该系统包含两部分：a）AdapTS-Forecaster用于学习当前数据分布；b）AdapTS-Weighter用于结合基础模型和AdapTS-Forecaster的预测结果。我们评估了在多种最近的基础模型与一系列标准时间序列数据集相结合时，使用AdapTS的效果。实验结果显示，在所有情况下使用AdapTS都能提高性能。这项工作展示了如何通过有效利用在线反馈来改进基础模型的时间序列预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) have emerged as a promising approach for time seriesforecasting. While effective, FMs typically remain fixed during deployment dueto the high computational costs of learning them online. Consequently, deployedFMs fail to adapt their forecasts to current data characteristics, despite theavailability of online feedback from newly arriving data. This raises thequestion of whether FM performance can be enhanced by the efficient usage ofthis feedback. We propose AdapTS to answer this question.  AdapTS is a lightweight mechanism for the online adaption of FM forecasts inresponse to online feedback. AdapTS consists of two parts: a) theAdapTS-Forecaster which is used to learn the current data distribution; and b)the AdapTS-Weighter which is used to combine the forecasts of the FM and theAdapTS-Forecaster. We evaluate the performance of AdapTS in conjunction withseveral recent FMs across a suite of standard time series datasets. In all ofour experiments we find that using AdapTS improves performance. This workdemonstrates how efficient usage of online feedback can be used to improve FMforecasts.</description>
      <author>example@mail.com (Thomas L. Lee, William Toner, Rajkarn Singh, Artjom Joosem, Martin Asenov)</author>
      <guid isPermaLink="false">2502.12920v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models</title>
      <link>http://arxiv.org/abs/2502.12776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的微调原则，即可移植奖励微调（PRT），它通过将其视为奖励最大化来减少推理开销。&lt;h4&gt;背景&lt;/h4&gt;基础模型会因为知识过时或能力有限而变得过时，需要被更新的基础模型替换，这会导致反复对新模型进行微调的额外成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够降低推理时间调整开销的新方法——可移植奖励微调（PRT）。&lt;h4&gt;方法&lt;/h4&gt;基于将微调重新定义为最大化奖励的方法，PRT通过相同的损失函数显式地训练奖励模型。在推理阶段，可以使用该奖励模型与任何基础模型一起工作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在视觉和语言模型中，经过PRT训练的模型能够达到与其他方法（例如推理时间调整）相当的效果，但具有更低的推理成本。&lt;h4&gt;结论&lt;/h4&gt;可移植奖励微调是一种有效的技术，能够在减少计算开销的同时保持模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While foundation models have been exploited for various expert tasks throughfine-tuning, any foundation model will become outdated due to its old knowledgeor limited capability. Thus the underlying foundation model should beeventually replaced by new ones, which leads to repeated cost of fine-tuningthese new models. Existing work addresses this problem by inference-timetuning, i.e., modifying the output probabilities from the new foundation modelwith the outputs from the old foundation model and its fine-tuned model, whichinvolves an additional overhead in inference by the latter two models. In thispaper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),that reduces the inference overhead by its nature, based on the reformulationof fine-tuning as the reward maximization. Specifically, instead of fine-tuningparameters of the foundation models, PRT trains the reward model explicitlythrough the same loss function as in fine-tuning. During inference, the rewardmodel can be used with any foundation model (with the same set of vocabulariesor labels) through the formulation of reward maximization. Experimentalresults, covering both vision and language models, demonstrate that thePRT-trained model can achieve comparable accuracy to the existing work ofinference-time tuning, with less inference cost.</description>
      <author>example@mail.com (Daiki Chijiwa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Susumu Takeuchi)</author>
      <guid isPermaLink="false">2502.12776v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Not-So-Optimal Transport Flows for 3D Point Cloud Generation</title>
      <link>http://arxiv.org/abs/2502.12456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成3D点云的模型是三维生成学习中的一个基本问题。点云的一个关键特性是它们对置换不变性，即改变点云中点的顺序不会改变其所代表的形状。&lt;h4&gt;目的&lt;/h4&gt;分析最近提出的等变OT流，这类方法旨在为基于分子数据的学习置换不变性的生成模型，并指出这些模型在大规模点云上的扩展性较差。同时解决学习（等变）OT流的一般挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种不太优化的运输流量模型，通过离线预计算近似OT，使能够在训练中更高效地构建OT对。此外，在训练过程中可以通过结合我们的近似OT和独立耦合来构造混合耦合，从而使目标流模型更容易学习。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的实证研究中显示，所提出的模型在ShapeNet基准测试的无条件生成和形状完成上优于先前的扩散方法和基于流的方法。&lt;h4&gt;结论&lt;/h4&gt;新的不那么优化运输流量模型能够有效解决大规模点云问题，并且在各种任务上的性能表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning generative models of 3D point clouds is one of the fundamentalproblems in 3D generative learning. One of the key properties of point cloudsis their permutation invariance, i.e., changing the order of points in a pointcloud does not change the shape they represent. In this paper, we analyze therecently proposed equivariant OT flows that learn permutation invariantgenerative models for point-based molecular data and we show that these modelsscale poorly on large point clouds. Also, we observe learning (equivariant) OTflows is generally challenging since straightening flow trajectories makes thelearned flow model complex at the beginning of the trajectory. To remedy these,we propose not-so-optimal transport flow models that obtain an approximate OTby an offline OT precomputation, enabling an efficient construction of OT pairsfor training. During training, we can additionally construct a hybrid couplingby combining our approximate OT and independent coupling to make the targetflow models easier to learn. In an extensive empirical study, we show that ourproposed model outperforms prior diffusion- and flow-based approaches on a widerange of unconditional generation and shape completion on the ShapeNetbenchmark.</description>
      <author>example@mail.com (Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat)</author>
      <guid isPermaLink="false">2502.12456v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GeneralizeFormer: Layer-Adaptive Model Generation across Test-Time Distribution Shifts</title>
      <link>http://arxiv.org/abs/2502.12195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种在测试时实现领域泛化的轻量级元学习Transformer模型GeneralizeFormer，该模型通过生成多层参数来适应未知的目标域分布。&lt;h4&gt;背景&lt;/h4&gt;传统的领域泛化方法通常使用微调或在线调整分类器参数的方法，在新的目标域上进行适应。然而这些方法往往在处理多个目标分布时效果不佳，并且可能遗忘源领域的特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法，能够在测试阶段动态生成多层参数，以更好地适应领域泛化问题中不同和多变的目标分布。&lt;h4&gt;方法&lt;/h4&gt;利用一个轻量级的元学习Transformer，在推理过程中为每个目标批次实时生成多个层的参数。通过这种方式，模型能够避免微调或在线调整，并且能够在各种分布偏移下进行自我调节。为了减少计算成本，固定了卷积参数的同时只生成Batch Normalization层和线性分类器的参数。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在处理多种领域泛化数据集上展示了优越的表现能力，在动态场景中实现泛化，并且避免遗忘源域中的有价值特征。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，GeneralizeFormer模型能够有效地解决各种分布偏移问题，并在测试时通过实时生成参数的方式提升了对未知目标领域的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of test-time domain generalization, where a model istrained on several source domains and adjusted on target domains never seenduring training. Different from the common methods that fine-tune the model oradjust the classifier parameters online, we propose to generate multiple layerparameters on the fly during inference by a lightweight meta-learnedtransformer, which we call \textit{GeneralizeFormer}. The layer-wise parametersare generated per target batch without fine-tuning or online adjustment. Bydoing so, our method is more effective in dynamic scenarios with multipletarget distributions and also avoids forgetting valuable source distributioncharacteristics. Moreover, by considering layer-wise gradients, the proposedmethod adapts itself to various distribution shifts. To reduce thecomputational and time cost, we fix the convolutional parameters while onlygenerating parameters of the Batch Normalization layers and the linearclassifier. Experiments on six widely used domain generalization datasetsdemonstrate the benefits and abilities of the proposed method to efficientlyhandle various distribution shifts, generalize in dynamic scenarios, and avoidforgetting.</description>
      <author>example@mail.com (Sameer Ambekar, Zehao Xiao, Xiantong Zhen, Cees G. M. Snoek)</author>
      <guid isPermaLink="false">2502.12195v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Imbalanced Learning</title>
      <link>http://arxiv.org/abs/2502.10816v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文系统地分类了主流的多模态不平衡算法，并提出了BalanceBenchmark基准测试，以全面评估这些方法。&lt;h4&gt;背景&lt;/h4&gt;多模态学习因能整合不同模态的信息而受到关注，但常受制于模态失衡问题，即某一模态主导其他模态被忽略。尽管已有研究提出多种解决该问题的方法，但仍缺乏全面公平的比较。&lt;h4&gt;目的&lt;/h4&gt;系统地分类主流的多模态不平衡算法，并通过BalanceBenchmark基准测试来评估这些方法的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一个包括多个常用数据集和评价指标的BalanceBenchmark，从性能、失衡程度和复杂性三个视角进行综合评估。为确保公平比较，开发了一个模块化且可扩展的工具包，标准化了不同方法之间的实验流程。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用BalanceBenchmark的实验结果，发现了不同类型方法在性能、平衡度以及计算复杂性方面的特点和优势。&lt;h4&gt;结论&lt;/h4&gt;期望这样的分析能激发未来更有效的方法来解决多模态失衡问题，并有助于基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其集成不同模态信息的能力而受到关注。然而，它常常受限于模态不平衡的问题，即某些模态主导而其他模态未被充分利用。尽管近期有研究提出多种方法以减轻这一问题，但缺乏全面且公平的比较。本文系统地将各种主流多模态不平衡算法根据其减少失衡的策略分类为四组，并介绍了BalanceBenchmark基准测试，其中包括多个常用的多维数据集和从性能、失衡程度及复杂性三个角度评估的方法。为了确保公平对比，我们开发了一个模块化且可扩展的工具包，该工具包标准化了不同方法之间的实验流程。基于使用BalanceBenchmark的实验结果，我们在性能、平衡度以及计算复杂性方面发现了不同类型方法的特点和优势。我们期望这样的分析能够启发未来更有效的方法来解决多模态不平衡问题，并为基础模型提供帮助。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, DiHu)</author>
      <guid isPermaLink="false">2502.10816v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fusing Point Cloud and Visual Representations for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.12320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的模仿学习方法，该方法结合了点云和RGB图像的优点，在机器人操作任务中展示了优于现有技术的性能。&lt;h4&gt;背景&lt;/h4&gt;学习操纵通常需要使用能够访问丰富感官信息（如点云或RGB图像）的策略。点云可以有效地捕捉几何结构，对于基于模仿的学习中的操纵任务至关重要；而RGB图像提供了丰富的纹理和语义信息，在某些任务中必不可少。然而，现有的融合两种模态的方法往往会导致原始图像中的全局上下文信息丢失。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模仿学习方法，能够有效结合点云和RGB图像的强项。&lt;h4&gt;方法&lt;/h4&gt;通过使用自适应层归一化条件对点云编码器进行调整，将全局和局部图像标记应用于点云，从而融合两种模态的优点。&lt;h4&gt;主要发现&lt;/h4&gt;在RoboCasa基准测试上的广泛实验表明，单独依赖任一单一模态存在局限性；而所提出的方法在所有任务中均达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了有效结合点云和RGB图像的必要性和优势，在复杂的机器人操作任务上显著提高了模仿学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning for manipulation requires using policies that have access to richsensory information such as point clouds or RGB images. Point cloudsefficiently capture geometric structures, making them essential formanipulation tasks in imitation learning. In contrast, RGB images provide richtexture and semantic information that can be crucial for certain tasks.Existing approaches for fusing both modalities assign 2D image features topoint clouds. However, such approaches often lose global contextual informationfrom the original images. In this work, we propose a novel imitation learningmethod that effectively combines the strengths of both point cloud and RGBmodalities. Our method conditions the point-cloud encoder on global and localimage tokens using adaptive layer norm conditioning, leveraging the beneficialproperties of both modalities. Through extensive experiments on the challengingRoboCasa benchmark, we demonstrate the limitations of relying on eithermodality alone and show that our method achieves state-of-the-art performanceacross all tasks.</description>
      <author>example@mail.com (Atalay Donat, Xiaogang Jia, Xi Huang, Aleksandar Taranovic, Denis Blessing, Ge Li, Hongyi Zhou, Hanyi Zhang, Rudolf Lioutikov, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.12320v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</title>
      <link>http://arxiv.org/abs/2502.08826v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  GitHub repository:  https://github.com/llm-lab-org/Multimodal-RAG-Survey&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对检索增强生成(RAG)的多模态版本进行了全面分析，涵盖了数据集、评估指标、基准测试、评价方法以及在检索、融合、增广和生成方面的方法论创新。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型(LLMs)由于依赖静态训练数据而面临幻觉和知识过时的问题。RAG通过整合外部动态信息来减轻这些问题，并且最近的多模态学习进展促进了多模态RAG的发展，它结合了文本、图像、音频和视频等多种模式。&lt;h4&gt;目的&lt;/h4&gt;对多模态RAG系统进行结构化全面分析，审查训练策略，增强鲁棒性以及损失函数等，同时探索多样的多模态RAG场景，并讨论开放挑战及未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;论文综述了多种数据集、评估指标和基准测试，同时也探讨了在检索、融合、增广和生成方面的创新方法论。&lt;h4&gt;主要发现&lt;/h4&gt;跨模式对齐和推理为多模态RAG引入了独特的挑战，使其区别于传统的单一模式RAG。此外还讨论了在训练策略、增强鲁棒性和损失函数等方面的具体审查。&lt;h4&gt;结论&lt;/h4&gt;论文为开发更强大且可靠的AI系统提供了基础，这些系统能够有效利用多模态动态外部知识库。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型(LLMs)因依赖静态训练数据而面临幻觉和过时知识的问题。RAG通过整合外部动态信息来解决这些问题，并提高了事实的准确性和更新性。最近在跨模式学习领域的进展已经导致了多模态RAG的发展，它结合了文本、图像、音频和视频等多种模式以增强生成输出的效果。然而，跨模式对齐和推理为多模态RAG引入了独特的挑战，使其与传统的单一模式RAG区分开来。这项综述提供了一个关于多模态RAG系统的结构化且全面的分析，涵盖了数据集、评估指标、基准测试、评价方法以及在检索、融合、增广和生成方面的创新方法论。此外还详细审查了训练策略、增强鲁棒性及损失函数等，并探讨了多元化的多模态RAG应用场景。论文最后讨论了一些开放问题及未来的研究方向，支持这一领域的发展。这项综述为开发更强大且可靠的AI系统奠定了基础，这些系统能够有效地利用多模态动态外部知识库。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/llm-lab-org/multimodal-rag-survey&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) struggle with hallucinations and outdatedknowledge due to their reliance on static training data. Retrieval-AugmentedGeneration (RAG) mitigates these issues by integrating external dynamicinformation enhancing factual and updated grounding. Recent advances inmultimodal learning have led to the development of Multimodal RAG,incorporating multiple modalities such as text, images, audio, and video toenhance the generated outputs. However, cross-modal alignment and reasoningintroduce unique challenges to Multimodal RAG, distinguishing it fromtraditional unimodal RAG. This survey offers a structured and comprehensiveanalysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,evaluation, methodologies, and innovations in retrieval, fusion, augmentation,and generation. We precisely review training strategies, robustnessenhancements, and loss functions, while also exploring the diverse MultimodalRAG scenarios. Furthermore, we discuss open challenges and future researchdirections to support advancements in this evolving field. This survey lays thefoundation for developing more capable and reliable AI systems that effectivelyleverage multimodal dynamic external knowledge bases. Resources are availableat https://github.com/llm-lab-org/Multimodal-RAG-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2502.08826v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GVTNet: Graph Vision Transformer For Face Super-Resolution</title>
      <link>http://arxiv.org/abs/2502.12570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了基于图神经网络的Transformer架构，即Graph Vision Transformer Network（GVTNet），以解决现有超分辨率算法在处理人脸图像时面部组件关系不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;近年来，人脸识别增强领域利用了Transformer架构。然而，在对低分辨率图片进行超分辨率处理时，现有的算法无法很好地处理不同补丁之间的关系。&lt;h4&gt;目的&lt;/h4&gt;通过改进Transformer架构来提高低分辨率脸部图像的超分辨率质量。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）的方法，每个小块都被视为一个图形节点，并根据这些节点间的信息建立邻接矩阵。这使得每个块只与其相邻的块进行交互，从而更好地处理面部组件的关系。&lt;h4&gt;主要发现&lt;/h4&gt;定量和可视化实验表明，与现有的最先进的技术相比，该算法在增强脸部组件方面具有更先进的超分辨率能力。&lt;h4&gt;结论&lt;/h4&gt;通过详细的比较证明了所提出的GVTNet方法在人脸图像超分辨率任务中优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;近期在面部超分辨率研究领域利用Transformer架构的进展已经出现。然而，由于面部图像是高度相关的特性，在处理低分辨率图像时现有的算法不能很好地管理不同补丁之间的关系。这导致了面部组件失真问题。为了解决这些问题，我们提出了一种基于图神经网络的Transformer架构，名为Graph Vision Transformer Network（GVTNet）。我们把每个小块视为一个图形节点，并根据这些节点间的信息建立邻接矩阵。这样可以使得每个块只与其相邻的块进行交互，进一步处理面部组件的关系。通过定量和可视化实验证明了我们的算法优于现有的最先进的技术。与现有方法进行了详细比较后展示了该算法在增强面部组件方面的先进超分辨率能力。PyTorch代码可在https://github.com/continueyang/GVTNet获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in face super-resolution research have utilized theTransformer architecture. This method processes the input image into a seriesof small patches. However, because of the strong correlation between differentfacial components in facial images. When it comes to super-resolution oflow-resolution images, existing algorithms cannot handle the relationshipsbetween patches well, resulting in distorted facial components in thesuper-resolution results. To solve the problem, we propose a transformerarchitecture based on graph neural networks called graph vision transformernetwork. We treat each patch as a graph node and establish an adjacency matrixbased on the information between patches. In this way, the patch only interactsbetween neighboring patches, further processing the relationship of facialcomponents. Quantitative and visualization experiments have underscored thesuperiority of our algorithm over state-of-the-art techniques. Through detailedcomparisons, we have demonstrated that our algorithm possesses more advancedsuper-resolution capabilities, particularly in enhancing facial components. ThePyTorch code is available at https://github.com/continueyang/GVTNet</description>
      <author>example@mail.com (Chao Yang, Yong Fan, Cheng Lu, Minghao Yuan, Zhijing Yang)</author>
      <guid isPermaLink="false">2502.12570v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting</title>
      <link>http://arxiv.org/abs/2502.12213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;交通预测对于优化出行调度和提升公共安全至关重要，但交通数据中复杂的时空动态特性给准确预测带来了挑战。本文介绍了一种新的模型——时空间趋势-季节性分解网络（STDN），该模型通过构建动态图结构来表示交通流，并引入新颖的时空嵌入以共同捕捉全局交通动态。&lt;h4&gt;背景&lt;/h4&gt;交通预测在优化出行调度和提升公共安全方面具有重要作用，但现有的方法难以有效应对复杂的时空数据特性带来的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型STDN，旨在通过分解交通流量的时间趋势与季节性因素来提高交通预测的准确性，并降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;该模型首先构建动态图结构表示交通流，使用创新的空间时间嵌入共同捕捉全局交通动态。然后通过专门设计的趋势-季节性分解模块分离出每个交通节点在不同时间内的趋势循环和季节成分，最后这些成分经过编码器解码器网络处理生成最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验结果表明，在现实世界的交通数据集上，STDN模型能够以显著的计算成本实现更好的性能。此外，研究人员还发布了一个名为JiNan的新交通数据集，该数据集具有独特的城市内部动态特性。&lt;h4&gt;结论&lt;/h4&gt;提出的STDN模型通过分解时间趋势和季节性因素，提高了交通流量预测的准确性，并且新发布的JiNan数据集丰富了评估场景全面性的选项。&lt;h4&gt;翻译&lt;/h4&gt;交通预测对优化行程安排和提高公共安全至关重要，但是复杂的空间时间和动态特性在交通数据中给准确预测带来了挑战。本文介绍了新的模型——时空趋势-季节性分解网络（STDN），该模型开始通过构建表示流量的动态图结构，并结合新颖的时间空间嵌入共同捕捉全局交通动态。这些学习到的表示进一步由特别设计的趋势-季节性分解模块细化，该模块将每个时间点和节点的交通趋势循环和季节因素分离开来。然后这些组件通过编码器解码器网络处理生成最终预测结果。在现实世界交通数据集上的广泛实验表明，STDN实现了卓越性能，并且计算成本显著降低。此外，我们发布了名为JiNan的新交通数据集，该数据集包含独特的城市内部动态特性，因此丰富了交通预测评估的场景全面性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic prediction is critical for optimizing travel scheduling and enhancingpublic safety, yet the complex spatial and temporal dynamics within trafficdata present significant challenges for accurate forecasting. In this paper, weintroduce a novel model, the Spatiotemporal-aware Trend-SeasonalityDecomposition Network (STDN). This model begins by constructing a dynamic graphstructure to represent traffic flow and incorporates novel spatio-temporalembeddings to jointly capture global traffic dynamics. The representationslearned are further refined by a specially designed trend-seasonalitydecomposition module, which disentangles the trend-cyclical component andseasonal component for each traffic node at different times within the graph.These components are subsequently processed through an encoder-decoder networkto generate the final predictions. Extensive experiments conducted onreal-world traffic datasets demonstrate that STDN achieves superior performancewith remarkable computation cost. Furthermore, we have released a new trafficdataset named JiNan, which features unique inner-city dynamics, therebyenriching the scenario comprehensiveness in traffic prediction evaluation.</description>
      <author>example@mail.com (Lingxiao Cao, Bin Wang, Guiyuan Jiang, Yanwei Yu, Junyu Dong)</author>
      <guid isPermaLink="false">2502.12213v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Improving the Stability of GNN Force Field Models by Reducing Feature Correlation</title>
      <link>http://arxiv.org/abs/2502.12548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于特征相关性的方法，用于增强GNNFF模型在分子动力学模拟中的稳定性，并通过实验证明该方法可以显著提高模型的稳定性，尤其是在处理出界数据集时。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于图神经网络的力场(GNNFF)模型被广泛应用于半导体材料研究中成本效益最高的分子动力学(MD)仿真。然而，即使这些模型在训练过的(入样分布)数据集中提供高精度的能量和力的绝对误差（MAE），它们在长时间MD模拟时面对出界数据集经常变得不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强GNNFF模型稳定性的方法，以改善分子动力学仿真的稳定性。&lt;h4&gt;方法&lt;/h4&gt;揭示了特征相关性和GNNFF模型稳定性之间的负面关系，并设计了一个动态损失系数调度器的损失函数来减少边缘特征的相关性。此外，还提出了一个经验指标用于评估MD仿真中的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;基于特征相关性的新方法可以显著提高GNNFF模型在处理出界数据集时的稳定性，且计算开销不超过3%。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的损失函数和评估标准，该研究成功提高了GNNFF模型在分子动力学仿真中的稳定性和可靠性。这种方法为半导体材料的研究提供了更可靠的工具。&lt;h4&gt;翻译&lt;/h4&gt;最近，基于图神经网络的力场(GNNFF)模型广泛应用于分子动力学(MD)仿真中，这是半导体材料研究中最经济有效的手段之一。然而，尽管这些模型在训练过的(入样分布)数据集中提供高精度的能量和力的绝对误差（MAE），它们在长时间MD模拟时面对出界数据集经常变得不稳定。本文提出了一种基于特征相关性的方法来增强GNNFF模型中的MD仿真的稳定性，并揭示了特征相关性与GNNFF模型稳定性之间的负面关系，设计了一个带有动态损失系数调度器的损失函数以减少边缘特征的相关性，适用于一般GNNFF训练。我们还提出了一个经验指标用于评估MD仿真中的稳定性。实验表明，我们的方法可以显著提高GNNFF模型在处理出界数据集时的稳定性，计算开销不超过3%。例如，在Allegro模型中，我们可以确保从0.03ps到10ps的稳定的MD模拟时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Graph Neural Network based Force Field (GNNFF) models are widelyused in Molecular Dynamics (MD) simulation, which is one of the mostcost-effective means in semiconductor material research. However, even suchmodels provide high accuracy in energy and force Mean Absolute Error (MAE) overtrained (in-distribution) datasets, they often become unstable during long-timeMD simulation when used for out-of-distribution datasets. In this paper, wepropose a feature correlation based method for GNNFF models to enhance thestability of MD simulation. We reveal the negative relationship between featurecorrelation and the stability of GNNFF models, and design a loss function witha dynamic loss coefficient scheduler to reduce edge feature correlation thatcan be applied in general GNNFF training. We also propose an empirical metricto evaluate the stability in MD simulation. Experiments show our method cansignificantly improve stability for GNNFF models especially inout-of-distribution data with less than 3% computational overhead. For example,we can ensure the stable MD simulation time from 0.03ps to 10ps for Allegromodel.</description>
      <author>example@mail.com (Yujie Zeng, Wenlong He, Ihor Vasyltsov, Jiaxin Wei, Ying Zhang, Lin Chen, Yuehua Dai)</author>
      <guid isPermaLink="false">2502.12548v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>USPilot: An Embodied Robotic Assistant Ultrasound System with Large Language Model Enhanced Graph Planner</title>
      <link>http://arxiv.org/abs/2502.12498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于大型语言模型的机器人辅助超声系统USPilot，该系统能够自主进行超声检查。&lt;h4&gt;背景&lt;/h4&gt;随着大语言模型的发展，实体人工智能在机器人操控任务中提供了变革性的机遇。然而，在医疗诊断过程中广泛应用且成本效益高的超声成像面临着专业超声技师短缺的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于LLM的框架，使USPilot能够作为虚拟超声技师自主完成超声检查，并回答患者相关问题。&lt;h4&gt;方法&lt;/h4&gt;通过微调大语言模型以增强对特定于超声的操作和任务的理解；并结合改进后的图神经网络(GNN)来管理超声机器人API和服务于任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，基于LLM的GNN在公共数据集上的任务规划准确性达到了前所未有的水平。USPilot系统显示出显著地能够自主理解和执行超声检查程序的能力。&lt;h4&gt;结论&lt;/h4&gt;这一进展使我们更接近实现完全自主且可能无人值守的机器人超声系统，从而填补了医疗成像中的关键资源缺口。&lt;h4&gt;翻译&lt;/h4&gt;在大型语言模型的时代，实体人工智能为机器人操控任务提供了变革性的机会。超声成像作为一种广泛应用和成本效益高的医学诊断程序面临着专业技师短缺的问题。为此，我们提出了USPilot——一个基于LLM的框架支持的机器人辅助超声系统，旨在实现自主进行超声检查的能力。该系统能够响应患者的超声相关问题，并根据用户意图执行超声扫描。通过微调大语言模型，USPilot在特定于超声的问题和任务中展现出了深刻的理解力。此外，它整合了一个增强的图神经网络(GNN)，用于管理超声机器人API并作为任务规划器使用。实验结果显示，在公共数据集上的该GNN实现了前所未有的任务规划准确性。此外，该系统展示了自主理解和执行超声程序的巨大潜力。这些进步使我们更接近于实现完全自主且可能无人值守的机器人超声系统，从而解决医学成像中的关键资源缺口问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of Large Language Models (LLMs), embodied artificial intelligencepresents transformative opportunities for robotic manipulation tasks.Ultrasound imaging, a widely used and cost-effective medical diagnosticprocedure, faces challenges due to the global shortage of professionalsonographers. To address this issue, we propose USPilot, an embodied roboticassistant ultrasound system powered by an LLM-based framework to enableautonomous ultrasound acquisition. USPilot is designed to function as a virtualsonographer, capable of responding to patients' ultrasound-related queries andperforming ultrasound scans based on user intent. By fine-tuning the LLM,USPilot demonstrates a deep understanding of ultrasound-specific questions andtasks. Furthermore, USPilot incorporates an LLM-enhanced Graph Neural Network(GNN) to manage ultrasound robotic APIs and serve as a task planner.Experimental results show that the LLM-enhanced GNN achieves unprecedentedaccuracy in task planning on public datasets. Additionally, the systemdemonstrates significant potential in autonomously understanding and executingultrasound procedures. These advancements bring us closer to achievingautonomous and potentially unmanned robotic ultrasound systems, addressingcritical resource gaps in medical imaging.</description>
      <author>example@mail.com (Mingcong Chen, Siqi Fan, Guanglin Cao, Hongbin Liu)</author>
      <guid isPermaLink="false">2502.12498v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor Search in LiDAR Data</title>
      <link>http://arxiv.org/abs/2502.11602v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提供了一个关于各种数据结构与邻近搜索方法的全面比较分析，并引入了一种新颖的数据结构cheesemap来处理3D LiDAR点云。&lt;h4&gt;背景&lt;/h4&gt;点云数据是表示三维空间信息的基本形式，在索引和查询这些点云时，高效的操作对于物体识别、自主导航以及环境建模等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;比较分析不同类型的点云中各种数据结构及其邻近搜索方法，并提出一种新颖的数据结构cheesemap以处理3D LiDAR点云。&lt;h4&gt;方法&lt;/h4&gt;对不同的点云类型进行数据结构和相邻搜索策略的综合对比。提出了用于管理3D LiDAR点云的新颖数据结构，称为cheesemap，并根据点分布的不同特性设计了三种变体：稠密型、稀疏型以及混合型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相较于现有的先进数据结构，cheesemap在每个查询的执行时间方面有显著优势，尤其是在航空激光扫描（ALS）点云上。此外，在稀疏和混合表示中内存消耗也较低。&lt;h4&gt;结论&lt;/h4&gt;鉴于其优越性能以及低内存占用的特点，cheesemap成为涉及三维点云应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;点云数据作为三维空间信息的表示形式，在物体识别、自主导航及环境建模等领域具有重要的意义。本论文对各种数据结构与邻近搜索方法进行了全面比较，并提出了用于处理3D LiDAR点云的新颖数据结构cheesemap，实验结果表明这种新数据结构在执行效率上优于现有技术，特别是在ALS点云中表现出色，同时内存消耗较小，尤其是在稀疏和混合表示中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data, as the representation of three-dimensional spatialinformation, is a fundamental piece of information in various domains whereindexing and querying these point clouds efficiently is crucial for tasks suchas object recognition, autonomous navigation, and environmental modeling. Inthis paper, we present a comprehensive comparative analysis of various datastructures combined with neighboring search methods across different types ofpoint clouds. Additionally, we introduce a novel data structure, cheesemap, tohandle 3D LiDAR point clouds. Exploring the sparsity and irregularity in thedistribution of points, there are three flavors of the cheesemap: dense,sparse, and mixed. Results show that the cheesemap can outperformstate-of-the-art data structures in terms of execution time per query,particularly for ALS (Aerial Laser Scanning) point clouds. Memory consumptionis also minimal, especially in the sparse and mixed representations, making thecheesemap a suitable choice for applications involving three-dimensional pointclouds.</description>
      <author>example@mail.com (Ruben Laso, Miguel Yermo)</author>
      <guid isPermaLink="false">2502.11602v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer</title>
      <link>http://arxiv.org/abs/2502.07158v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer框架的PedCA-FT，用于早期预测儿科心脏骤停（CA），该方法融合了电子健康记录（EHR）的数据表视图和衍生的文本视图，以全面释放高维风险因素及其动态变化之间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;在高危重症监护环境中，儿童心脏骤停（CA）的早期预测对于及时干预至关重要。现有的人工智能模型难以充分捕捉复杂的时间序列数据中的模式以及各维度风险因素间的交互效应。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于Transformer的方法来融合电子健康记录的数据表视图和文本视图，以生成更为精确的心脏骤停风险评估。&lt;h4&gt;方法&lt;/h4&gt;PedCA-FT通过为每种模态视图（数据表或文本）设计特定的Transformer模块，捕捉复杂的时间序列模式以及上下文关系。这种方法可以更好地理解高维风险因素及其动态变化之间的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;在CHOA-CICU数据库中的一个经过精心选择的儿科群体上进行了评估，PedCA-FT模型在五个关键性能指标上的表现优于其他十种人工智能方法，并且能够识别出具有临床意义的风险因素。这些结果表明了多模态融合技术在提高早期心脏骤停检测和改善患者护理方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过使用PedCA-FT模型，可以有效地进行儿科心脏骤停的早期预测，该模型展示了其在真实世界数据集上的强大性能，并为未来的研究提供了重要的参考价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early prediction of pediatric cardiac arrest (CA) is critical for timelyintervention in high-risk intensive care settings. We introduce PedCA-FT, anovel transformer-based framework that fuses tabular view of EHR with thederived textual view of EHR to fully unleash the interactions ofhigh-dimensional risk factors and their dynamics. By employing dedicatedtransformer modules for each modality view, PedCA-FT captures complex temporaland contextual patterns to produce robust CA risk estimates. Evaluated on acurated pediatric cohort from the CHOA-CICU database, our approach outperformsten other artificial intelligence models across five key performance metricsand identifies clinically meaningful risk factors. These findings underscorethe potential of multimodal fusion techniques to enhance early CA detection andimprove patient care.</description>
      <author>example@mail.com (Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.07158v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>On the Robust Approximation of ASR Metrics</title>
      <link>http://arxiv.org/abs/2502.12408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 Pages. Work in Progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期语音基础模型的进步主要是通过扩大模型规模和数据来实现的，使其能够执行包括语音识别在内的各种任务。然而，受限于来自不同领域的有限标注数据以及测试条件，这些模型在标准基准之外的真实泛化能力仍然不明确。&lt;h4&gt;背景&lt;/h4&gt;传统上，自动语音识别（ASR）模型使用像词错误率（WER）和字符错误率（CER）这样的指标来评估性能。但是受限于多领域、多环境的标注数据不足以及标注成本高耗时长的问题，这些标准基准之外的真实性能仍不清楚。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统方法中的局限性，研究人员提出了一种无需真实标签的新颖无标签方法来估计ASR性能指标。&lt;h4&gt;方法&lt;/h4&gt;该方法利用统一空间内的多模态嵌入，结合高质量的代理模型计算出代理度量，并使用这些特征训练回归模型预测像WER和CER这样的关键ASR指标。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多种标准测试环境以及实际场景下进行超过40种不同模型的评估后，该方法在所有配置中能够将误差保持在一个很小范围内，并且比最近的最佳基线性能高出50%以上。&lt;h4&gt;结论&lt;/h4&gt;通过采用无标签的方法来估算自动语音识别模型的关键性能指标，可以有效减少数据标注的成本和时间消耗，同时提供更可靠的泛化能力评估。&lt;h4&gt;翻译&lt;/h4&gt;近期在语音基础模型上的进展主要依靠扩大模型的规模和训练数据，使得这些模型能够执行包括语音识别在内的广泛任务。然而，在受限于不同领域和测试条件下的有限标签数据之后，这些模型的真实性能超出标准基准的能力尚不明确。为了解决这个问题，提出了一种新颖的无标签方法来估计自动语音识别（ASR）性能指标，从而避免了对真实标签的需求。该方法利用统一空间内的多模态嵌入结合高质量代理模型计算出代理度量，并用于训练回归模型预测像WER和CER这样的关键ASR指标。实验结果表明，在超过40种模型和14个数据集（包括标准测试条件和现实世界环境）上，这种方法能够以单个数字的绝对差异估算这些度量，性能比最近的最佳基线高出50%以上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in speech foundation models are largely driven by scalingboth model size and data, enabling them to perform a wide range of tasks,including speech recognition. Traditionally, ASR models are evaluated usingmetrics like Word Error Rate (WER) and Character Error Rate (CER), which dependon ground truth labels. As a result of limited labeled data from diversedomains and testing conditions, the true generalization capabilities of thesemodels beyond standard benchmarks remain unclear. Moreover, labeling data isboth costly and time-consuming. To address this, we propose a novel label-freeapproach for approximating ASR performance metrics, eliminating the need forground truth labels. Our method utilizes multimodal embeddings in a unifiedspace for speech and transcription representations, combined with ahigh-quality proxy model to compute proxy metrics. These features are used totrain a regression model to predict key ASR metrics like Word Error Rate (WER)and Character Error Rate (CER). We experiment with over 40 models across 14datasets representing both standard and in-the-wild testing conditions. Ourresults show that we approximate the metrics within a single-digit absolutedifference across all experimental configurations, outperforming the mostrecent baseline by more than 50\%.</description>
      <author>example@mail.com (Abdul Waheed, Hanin Atwany, Rita Singh, Bhiksha Raj)</author>
      <guid isPermaLink="false">2502.12408v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Mechanistic Interpretability of Graph Transformers via Attention Graphs</title>
      <link>http://arxiv.org/abs/2502.12352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Attention Graphs，一种用于解释图神经网络(GNN)和图变换器的机制性可解释性的新工具。&lt;h4&gt;背景&lt;/h4&gt;基于GNN中的消息传递与Transformer中的自注意力机制之间的数学等价性。&lt;h4&gt;目的&lt;/h4&gt;通过在同质性和异质性节点分类任务上的实验，从网络科学的角度分析Attention Graphs。&lt;h4&gt;方法&lt;/h4&gt;聚合Transformer层和头的注意力矩阵以描述信息如何在网络输入节点之间流动。&lt;h4&gt;主要发现&lt;/h4&gt;{'(1)': '当图变换器被允许使用输入节点之间的全连接注意来学习最优图结构时，模型学到的Attention Graphs通常不会与输入/原始图结构相关联；(2)对于异质性图，不同的图变换器变体可以通过利用不同的信息流动模式获得相似的表现。', '(2)': '不同变种的Graph Transformer在性能相似的情况下会使用截然不同的信息流模式'}&lt;h4&gt;结论&lt;/h4&gt;提出了一个新的工具Attention Graphs，并通过实验展示了其在网络科学分析中的潜力和特性。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Attention Graphs，这是一种新的用于机制性解释图神经网络(GNN)和图变换器的工具。该工具基于GNN中消息传递与Transformer中自注意力机制之间的数学等价性。通过在同质性和异质性的节点分类任务上进行实验，并从网络科学的角度分析了Attention Graphs。我们发现：当Graph Transformers能够利用输入节点间的全连接注意来学习最优图结构时，所学到的Attention Graphs通常不会与原始/输入图的相关结构相匹配；对于异质性图而言，不同的Graph Transformer变体在性能相似的同时会采用截然不同的信息流动模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Attention Graphs, a new tool for mechanistic interpretability ofGraph Neural Networks (GNNs) and Graph Transformers based on the mathematicalequivalence between message passing in GNNs and the self-attention mechanism inTransformers. Attention Graphs aggregate attention matrices across Transformerlayers and heads to describe how information flows among input nodes. Throughexperiments on homophilous and heterophilous node classification tasks, weanalyze Attention Graphs from a network science perspective and find that: (1)When Graph Transformers are allowed to learn the optimal graph structure usingall-to-all attention among input nodes, the Attention Graphs learned by themodel do not tend to correlate with the input/original graph structure; and (2)For heterophilous graphs, different Graph Transformer variants can achievesimilar performance while utilising distinct information flow patterns. Opensource code: https://github.com/batu-el/understanding-inductive-biases-of-gnns</description>
      <author>example@mail.com (Batu El, Deepro Choudhury, Pietro Liò, Chaitanya K. Joshi)</author>
      <guid isPermaLink="false">2502.12352v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Achieving Upper Bound Accuracy of Joint Training in Continual Learning</title>
      <link>http://arxiv.org/abs/2502.12388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了连续学习领域的研究进展，重点介绍了如何通过理论和大模型的力量实现理想精度。&lt;h4&gt;背景&lt;/h4&gt;连续学习是机器学习中的一个活跃领域，主要关注于增量地学习一系列任务。该领域面临的主要挑战包括灾难性遗忘（CF）和任务间类别的分离（ICS）。&lt;h4&gt;目的&lt;/h4&gt;论文旨在探讨最新的研究进展，解释为什么通过利用理论与大型基础模型，可以使连续学习算法达到联合训练的理想精度。&lt;h4&gt;方法&lt;/h4&gt;最近的研究表明，可以通过充分利用大模型的潜力并结合有效的连续学习策略来克服传统挑战，并实现上界性能。这些发现已在文本和图像分类数据集上得到实验证明。&lt;h4&gt;主要发现&lt;/h4&gt;通过采用适当的理论框架和大型预训练模型，现在可以实现与一次性联合训练相媲美的精度水平，这标志着连续学习在实际应用中的成熟。&lt;h4&gt;结论&lt;/h4&gt;论文总结了使连续学习算法接近理想性能的研究进展，并强调了这种方法在现实世界应用场景中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;持续学习已经成为机器学习的一个活跃研究领域，重点在于增量地学习一系列任务序列。该领域的关键挑战是灾难性遗忘（CF），大多数研究努力集中在缓解这个问题上。然而，最先进的连续学习算法的准确性与所有任务联合训练时的理想或上限准确度之间仍存在显著差距。这种差距阻碍了持续学习在许多应用中的采用，因为精度往往至关重要。最近还发现了一个名为跨任务类别分离（ICS）的新挑战，这促使人们进行理论研究来寻找解决持续学习问题的原则性方法。进一步的研究表明，通过利用这些理论和大型基础模型的力量，现在可以达到理想性能水平，并且这个结论已经在文本分类和图像分类的数据集上得到了实验证明。因此，持续学习现在准备好用于实际应用中了。该论文回顾了实现这一成就的主要研究工作，并从直观理解和神经科学研究的角度解释这种方法的合理性，还讨论了一些见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning has been an active research area in machine learning,focusing on incrementally learning a sequence of tasks. A key challenge iscatastrophic forgetting (CF), and most research efforts have been directedtoward mitigating this issue. However, a significant gap remains between theaccuracy achieved by state-of-the-art continual learning algorithms and theideal or upper-bound accuracy achieved by training all tasks together jointly.This gap has hindered or even prevented the adoption of continual learning inapplications, as accuracy is often of paramount importance. Recently, anotherchallenge, termed inter-task class separation (ICS), was also identified, whichspurred a theoretical study into principled approaches for solving continuallearning. Further research has shown that by leveraging the theory and thepower of large foundation models, it is now possible to achieve upper-boundaccuracy, which has been empirically validated using both text and imageclassification datasets. Continual learning is now ready for real-lifeapplications. This paper surveys the main research leading to this achievement,justifies the approach both intuitively and from neuroscience research, anddiscusses insights gained.</description>
      <author>example@mail.com (Saleh Momeni, Bing Liu)</author>
      <guid isPermaLink="false">2502.12388v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Systematic Weaknesses in Vision Models along Predefined Human-Understandable Dimensions</title>
      <link>http://arxiv.org/abs/2502.12360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种结合现代基础模型和组合搜索算法的工作流程，用于在图像数据中寻找深度神经网络（DNN）的系统性弱点。&lt;h4&gt;背景&lt;/h4&gt;随着建立安全AI系统的关注增加，在过去几年里研究DNN的系统性弱点变得越来越重要。现有的方法通常难以直接使用这些发现，因为它们缺乏与人类理解相关的元数据。&lt;h4&gt;目的&lt;/h4&gt;提出一个工作流程来寻找基于图像数据中DNN错误和结构化数据的系统性弱点，并确保这些弱点能够与预定义的人类可理解维度相一致。&lt;h4&gt;方法&lt;/h4&gt;结合现代基础模型进行组合搜索算法，以识别具有低性能的数据切片或子集。同时考虑到元数据噪声的影响。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在四个流行的计算机视觉数据集中进行了评估，并使用多个最先进的DNN作为测试对象，这些数据集包括自动驾驶数据集如Cityscapes、BDD100k和RailSem19。&lt;h4&gt;结论&lt;/h4&gt;通过将基础模型与组合搜索算法相结合的工作流程可以有效地识别图像中的系统性弱点。这种方法为理解深度神经网络在现实世界应用中的行为提供了新的视角，特别是对于安全相关领域来说尤为重要。&lt;h4&gt;翻译&lt;/h4&gt;研究DNN系统的薄弱环节近年来受到越来越多的关注，尤其是在构建安全AI系统的背景下。切片发现方法（SDM）是寻找这些系统性弱性的算法方法之一，它们可以识别数据集的一部分，在这部分中，被测试的深度神经网络性能较低。为了使这些发现直接有用，例如作为安全性论证中的证据，切片需要与人类理解的安全相关维度对齐，这通常由安全和领域专家定义为操作设计领域的部分。尽管对于结构化数据来说这是显而易见的，但缺乏语义元数据使得在无结构数据中进行此类调查变得具有挑战性。因此，我们提出了一种结合现代基础模型以及考虑结构化数据和DNN错误以寻找图像中的系统性弱点的工作流程。与现有方法不同的是，我们的方法识别出与预定义的人类可理解维度一致的弱切片。由于该工作流包括基础模型，其中间和最终结果可能并不总是准确的。因此，在我们的工作流程中构建了一种解决元数据噪声影响的方法。我们在四个流行计算机视觉数据集（包括自动驾驶数据集如Cityscapes、BDD100k和RailSem19）上评估了我们的方法，并使用多个最先进的模型作为被测试的DNN进行实验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Studying systematic weaknesses of DNNs has gained prominence in the last fewyears with the rising focus on building safe AI systems. Slice discoverymethods (SDMs) are prominent algorithmic approaches for finding such systematicweaknesses. They identify top-k semantically coherent slices/subsets of datawhere a DNN-under-test has low performance. For being directly useful, e.g., asevidences in a safety argumentation, slices should be aligned withhuman-understandable (safety-relevant) dimensions, which, for example, aredefined by safety and domain experts as parts of the operational design domain(ODD). While straightforward for structured data, the lack of semantic metadatamakes these investigations challenging for unstructured data. Therefore, wepropose a complete workflow which combines contemporary foundation models withalgorithms for combinatorial search that consider structured data and DNNerrors for finding systematic weaknesses in images. In contrast to existingapproaches, ours identifies weak slices that are in line with predefinedhuman-understandable dimensions. As the workflow includes foundation models,its intermediate and final results may not always be exact. Therefore, we buildinto our workflow an approach to address the impact of noisy metadata. Weevaluate our approach w.r.t. its quality on four popular computer visiondatasets, including autonomous driving datasets like Cityscapes, BDD100k, andRailSem19, while using multiple state-of-the-art models as DNNs-under-test.</description>
      <author>example@mail.com (Sujan Sai Gannamaneni, Rohil Prakash Rao, Michael Mock, Maram Akila, Stefan Wrobel)</author>
      <guid isPermaLink="false">2502.12360v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++ 是一个改进的深度学习模型，用于提高对 TESS 数据中的过渡信号分类准确性。&lt;h4&gt;背景&lt;/h4&gt;在成功的 ExoMiner 模型基础上开发了 ExoMiner++，它使用额外的诊断输入来区分真实过渡信号和假阳性来源。&lt;h4&gt;目的&lt;/h4&gt;通过引入更多诊断性特征并利用从开普勒太空望远镜获取的数据进行迁移学习，提高过渡信号分类准确性。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++ 使用多种数据源作为输入（如周期图、通量趋势等），并在 Kepler 数据上进行了迁移学习以提升模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在 147,568 个未标记的 TCEs 中，ExoMiner++ 确定了 7,330 个作为潜在新行星候选者，并且与之前的分类相比减少了不必要假阳性的搜索范围。&lt;h4&gt;结论&lt;/h4&gt;通过提高过渡信号分类的质量和准确性，ExoMiner++ 大大缩小了后续调查的搜索空间，使得研究可以更专注于最有可能的新行星发现。此外，该模型为天文学家提供了新的 TESS 目录，包含每条过渡信号的分类结果及其置信度分数。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了 ExoMiner++，这是一个基于 ExoMiner 成功改进的深度学习模型，用于提高对 2 分钟 TESS 数据中的过渡信号分类准确性。ExoMiner++ 包括额外的诊断输入，包括周期图、通量趋势等关键特征，这些对于有效区分真实过渡信号和假阳性来源至关重要。为了进一步增强性能，我们利用了从高质量标签数据（来自开普勒空间望远镜）进行迁移学习，缓解了 TESS 数据噪声更大且更难以界定的问题。ExoMiner++ 在各种分类和排名指标上均达到了高准确性，显著缩小了后续调查以确认新行星的搜索范围。为了服务外星人社区，我们引入了包含每个过渡信号的 ExoMiner++ 分类和置信度分数的新 TESS 目录。在 147,568 个未标记的 TCEs 中，ExoMiner++ 确定了 7,330 个作为行星候选者，其余则被分类为假阳性来源。这些 7,330 个候选行星对应于 1,868 个现有的 TESS 目标物体 (TOIs)，69 个社区 TESS 目标物体 (CTOIs) 和新的 50 个 CTOIs。在先前被标记为潜在新行星候选者的 2,506 TOI 中，1,797 被 ExoMiner++ 分类为行星候选者。这种减少的可能候选者数量结合了 ExoMiner++ 的优秀排名质量，使得后续努力可以集中在最有可能的新行星发现上，从而提高了整体新行星产率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Motion planning for highly-dynamic unconditioned reflexes based on chained Signed Distance Functions</title>
      <link>http://arxiv.org/abs/2502.10734v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要原文&lt;/h4&gt;The unconditioned reflex (e.g., protective reflex), which is the innate reaction of the organism and usually performed through the spinal cord rather than the brain, can enable organisms to escape harms from environments. In this paper, we propose an online, highly-dynamic motion planning algorithm to endow manipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed Distance Functions (SDFs), which can be pre-computed and stored. Our proposed algorithm is divided into two stages. In the offline stage, we create 3 groups of local SDFs to store the geometric information of the manipulator and its working environment. In the online stage, the pre-computed local SDFs are chained together according the configuration of the manipulator, to provide global geometric information about the environment. While the point clouds of the dynamic objects serve as query points to look up these local SDFs for quickly generating escape velocity. Then we propose a modified geometric Jacobian matrix and use the Jacobian-pseudo-inverse method to generate real-time reflex behaviors to avoid the static and dynamic obstacles in the environment. The benefits of our method are validated in both static and dynamic scenarios. In the static scenario, our method identifies the path solutions with lower time consumption and shorter trajectory length compared to existing solutions. In the dynamic scenario, our method can reliably pursue the dynamic target point, avoid dynamic obstacles, and react to these obstacles within 1ms, which surpasses the unconditioned reflex reaction time of humans.&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于签名距离函数（SDF）的在线、高度动态的运动规划算法，为机械臂赋予类似于生物本能反应的能力，使其能快速避开静态和动态障碍物。&lt;h4&gt;背景&lt;/h4&gt;无条件反射是生物体的一种先天反应机制，通常通过脊髓而非大脑执行，用于帮助生物从环境中逃脱伤害。当前缺乏一种能够实时避免障碍物的高效运动规划算法。&lt;h4&gt;目的&lt;/h4&gt;设计并实现一种高效的在线、高度动态的运动规划算法，使机械臂能快速响应并避开静态和动态环境中的障碍物，模拟人类无条件反射反应机制。&lt;h4&gt;方法&lt;/h4&gt;{'离线阶段': '创建3组局部SDF存储机械臂及其工作环境的几何信息', '在线阶段': '根据机械臂配置将预先计算好的局部SDF链接起来提供全局几何信息；利用动态对象的点云数据作为查询点，快速生成避障速度向量'}&lt;h4&gt;主要发现&lt;/h4&gt;在静态场景中，提出的方法能够在较低的时间消耗下获得较短轨迹长度的路径解决方案；在动态场景中，该方法能可靠地追踪动态目标点、避开动态障碍物，并且对这些障碍物做出反应的时间小于1毫秒。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法能够有效地使机械臂模拟生物体的无条件反射行为，在静态和动态环境中都能快速避障并响应环境变化，性能优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unconditioned reflex (e.g., protective reflex), which is the innatereaction of the organism and usually performed through the spinal cord ratherthan the brain, can enable organisms to escape harms from environments. In thispaper, we propose an online, highly-dynamic motion planning algorithm to endowmanipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed DistanceFunctions (SDFs), which can be pre-computed and stored. Our proposed algorithmis divided into two stages. In the offline stage, we create 3 groups of localSDFs to store the geometric information of the manipulator and its workingenvironment. In the online stage, the pre-computed local SDFs are chainedtogether according the configuration of the manipulator, to provide globalgeometric information about the environment. While the point clouds of thedynamic objects serve as query points to look up these local SDFs for quicklygenerating escape velocity. Then we propose a modified geometric Jacobianmatrix and use the Jacobian-pseudo-inverse method to generate real-time reflexbehaviors to avoid the static and dynamic obstacles in the environment. Thebenefits of our method are validated in both static and dynamic scenarios. Inthe static scenario, our method identifies the path solutions with lower timeconsumption and shorter trajectory length compared to existing solutions. Inthe dynamic scenario, our method can reliably pursue the dynamic target point,avoid dynamic obstacles, and react to these obstacles within 1ms, whichsurpasses the unconditioned reflex reaction time of humans.</description>
      <author>example@mail.com (Ken Lin, Qi Ye, Tin Lun Lam, Zhibin Li, Jiming Chen, Gaofeng Li)</author>
      <guid isPermaLink="false">2502.10734v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis</title>
      <link>http://arxiv.org/abs/2502.12180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了ClusMFL框架，用于处理跨机构脑影像分析中的模态不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;多模式联邦学习（MFL）在分布式客户端上协同训练多模式模型方面显示出巨大潜力。特别是在脑成像领域，不同医疗机构可能由于隐私、设备限制或数据可用性等问题而缺少特定的成像模态。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的MFL框架ClusMFL，以应对跨机构脑影像分析中的模态不完整性问题。&lt;h4&gt;方法&lt;/h4&gt;利用FINCH算法构建每个模态标签对的特征嵌入簇中心池，并通过监督对比学习进行模内特征对齐。同时，这些簇中心作为缺失模态的代理来促进跨模式知识迁移。此外，该框架采用了基于模态的聚合策略以进一步增强模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI数据集上进行了实验评估，结果表明ClusMFL在各种程度的模态不完整性下均优于多种基线方法。&lt;h4&gt;结论&lt;/h4&gt;ClusMFL为跨机构脑影像分析提供了可扩展解决方案，并且其性能超越了现有的许多基准技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Federated Learning (MFL) has emerged as a promising approach forcollaboratively training multimodal models across distributed clients,particularly in healthcare domains. In the context of brain imaging analysis,modality incompleteness presents a significant challenge, where someinstitutions may lack specific imaging modalities (e.g., PET, MRI, or CT) dueto privacy concerns, device limitations, or data availability issues. Whileexisting work typically assumes modality completeness or oversimplifiesmissing-modality scenarios, we simulate a more realistic setting by consideringboth client-level and instance-level modality incompleteness in this study.Building on this realistic simulation, we propose ClusMFL, a novel MFLframework that leverages feature clustering for cross-institutional brainimaging analysis under modality incompleteness. Specifically, ClusMFL utilizesthe FINCH algorithm to construct a pool of cluster centers for the featureembeddings of each modality-label pair, effectively capturing fine-grained datadistributions. These cluster centers are then used for feature alignment withineach modality through supervised contrastive learning, while also acting asproxies for missing modalities, allowing cross-modal knowledge transfer.Furthermore, ClusMFL employs a modality-aware aggregation strategy, furtherenhancing the model's performance in scenarios with severe modalityincompleteness. We evaluate the proposed framework on the ADNI dataset,utilizing structural MRI and PET scans. Extensive experimental resultsdemonstrate that ClusMFL achieves state-of-the-art performance compared tovarious baseline methods across varying levels of modality incompleteness,providing a scalable solution for cross-institutional brain imaging analysis.</description>
      <author>example@mail.com (Xinpeng Wang, Rong Zhou, Han Xie, Xiaoying Tang, Lifang He, Carl Yang)</author>
      <guid isPermaLink="false">2502.12180v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>AnyTouch: Learning Unified Static-Dynamic Representation across Multiple Visuo-tactile Sensors</title>
      <link>http://arxiv.org/abs/2502.12191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文旨在通过统一的多传感器表示学习框架提高机器人触觉感知能力。&lt;h4&gt;背景&lt;/h4&gt;视触传感器用于模拟人类触觉感知，帮助机器人精确理解与操作物体。然而，低标准化特征阻碍了强大的触觉感知系统的发展。&lt;h4&gt;目的&lt;/h4&gt;提出一个解决方法来整合不同的触觉数据来源，并通过统一的多模态表示学习框架促进跨传感器知识转移。&lt;h4&gt;方法&lt;/h4&gt;{'TacQuad': '这是一个从四种不同视触传感器获取的数据集，旨在实现各种传感器之间的直接融合。', 'AnyTouch': '该框架集成静态和动态视角来学习统一体现多层次结构的多传感表示。通过掩码建模捕捉像素级细节并利用跨模式对齐与交叉感应匹配技术增强感知及传输能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;方法在各种数据集上表现优秀，并且能够有效应对真实世界的倾倒任务。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法克服了现有方法的局限性，展示了强大的静态和动态感知能力以及跨传感器转移的能力。&lt;h4&gt;翻译&lt;/h4&gt;视觉-触觉传感器旨在模拟人类触觉感知，使机器人能够精确理解并操作物体。随着时间推移，大量精心设计的视觉-触觉传感器被集成到机器人系统中，以帮助完成各种任务。然而，这些低标准化特征的感官数据特性阻碍了强大触觉感知系统的建立。我们认为解决这个问题的关键在于学习统一的多传感表示，从而整合传感器，并促进它们之间的触觉知识转移。为了实现这种性质的统一表示，我们介绍了TacQuad，这是一个来自四种不同视觉-触觉传感器的数据集，它使各种传感器能够明确融合。认识到人类通过获取包括纹理和压力变化在内的多样化触觉信息来感知物理环境，我们进一步提出从静态和动态角度学习统一多传感表示的方法。通过集成触觉图像和视频，我们提出了AnyTouch，这是一个多层次结构的统一体现静态-动态多传感表示学习框架，旨在增强综合感知能力并使有效的跨感应传输成为可能。这种多层次架构通过掩码建模捕捉触觉数据中的像素级细节，并通过多模式对齐和交叉传感器匹配学习语义级别的无感觉特征来提高感知和可转移性。我们提供了全面的多传感传输分析，并在各种数据集以及现实世界的倾倒任务中验证了我们的方法。实验结果显示，该方法优于现有方法，在多种传感器上展示出卓越的静态和动态感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuo-tactile sensors aim to emulate human tactile perception, enablingrobots to precisely understand and manipulate objects. Over time, numerousmeticulously designed visuo-tactile sensors have been integrated into roboticsystems, aiding in completing various tasks. However, the distinct datacharacteristics of these low-standardized visuo-tactile sensors hinder theestablishment of a powerful tactile perception system. We consider that the keyto addressing this issue lies in learning unified multi-sensor representations,thereby integrating the sensors and promoting tactile knowledge transferbetween them. To achieve unified representation of this nature, we introduceTacQuad, an aligned multi-modal multi-sensor tactile dataset from fourdifferent visuo-tactile sensors, which enables the explicit integration ofvarious sensors. Recognizing that humans perceive the physical environment byacquiring diverse tactile information such as texture and pressure changes, wefurther propose to learn unified multi-sensor representations from both staticand dynamic perspectives. By integrating tactile images and videos, we presentAnyTouch, a unified static-dynamic multi-sensor representation learningframework with a multi-level structure, aimed at both enhancing comprehensiveperceptual abilities and enabling effective cross-sensor transfer. Thismulti-level architecture captures pixel-level details from tactile data viamasked modeling and enhances perception and transferability by learningsemantic-level sensor-agnostic features through multi-modal alignment andcross-sensor matching. We provide a comprehensive analysis of multi-sensortransferability, and validate our method on various datasets and in thereal-world pouring task. Experimental results show that our method outperformsexisting methods, exhibits outstanding static and dynamic perceptioncapabilities across various sensors.</description>
      <author>example@mail.com (Ruoxuan Feng, Jiangyu Hu, Wenke Xia, Tianci Gao, Ao Shen, Yuhao Sun, Bin Fang, Di Hu)</author>
      <guid isPermaLink="false">2502.12191v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>On Creating a Causally Grounded Usable Rating Method for Assessing the Robustness of Foundation Models Supporting Time Series</title>
      <link>http://arxiv.org/abs/2502.12226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一个因果框架，用于评估基于基础模型的时间序列（FMTS）预测在输入扰动下的鲁棒性，并通过股票价格预测问题验证了该方法的有效性和实用性。&lt;h4&gt;背景&lt;/h4&gt;基础模型已经在金融等领域提高了时间序列预测的准确性，但它们对输入干扰的脆弱性阻碍了其广泛应用。因此需要一种新的评估工具来提高这些模型的可靠性和接受度。&lt;h4&gt;目的&lt;/h4&gt;提出一个因果框架用于评价FMTS在面对输入扰动时的鲁棒性，并为模型选择和部署提供实用建议。&lt;h4&gt;方法&lt;/h4&gt;以股票价格预测为例，研究了六个最先进的单模态及多模态FMTS模型对六种主要股票的时间序列数据进行评估。同时进行了用户测试来验证框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '多模态的FMTS比单一模态版本表现出更好的鲁棒性和准确性', '2': '专门针对时间序列预测任务预训练的模型在鲁棒性和预测准确度方面优于跨多种场景下通用目的预训练的模型'}&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效评估不同FMTS模型的性能，并通过用户测试证明了该框架可以降低比较各种系统鲁棒性的难度。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在金融等领域提高了时间序列预测，但其对输入扰动的脆弱性限制了其应用。为了应对这一挑战，我们提出了一种因果方法来评估FMTS面对输入干扰时的表现，并通过股票价格预测问题测试了六个最先进的时间序列模型的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) have improved time series forecasting in varioussectors, such as finance, but their vulnerability to input disturbances canhinder their adoption by stakeholders, such as investors and analysts. Toaddress this, we propose a causally grounded rating framework to study therobustness of Foundational Models for Time Series (FMTS) with respect to inputperturbations. We evaluate our approach to the stock price prediction problem,a well-studied problem with easily accessible public data, evaluating sixstate-of-the-art (some multi-modal) FMTS across six prominent stocks spanningthree industries. The ratings proposed by our framework effectively assess therobustness of FMTS and also offer actionable insights for model selection anddeployment. Within the scope of our study, we find that (1) multi-modal FMTSexhibit better robustness and accuracy compared to their uni-modal versionsand, (2) FMTS pre-trained on time series forecasting task exhibit betterrobustness and forecasting accuracy compared to general-purpose FMTSpre-trained across diverse settings. Further, to validate our framework'susability, we conduct a user study showcasing FMTS prediction errors along withour computed ratings. The study confirmed that our ratings reduced thedifficulty for users in comparing the robustness of different systems.</description>
      <author>example@mail.com (Kausik Lakkaraju, Rachneet Kaur, Parisa Zehtabi, Sunandita Patra, Siva Likitha Valluru, Zhen Zeng, Biplav Srivastava, Marco Valtorta)</author>
      <guid isPermaLink="false">2502.12226v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>iMOVE: Instance-Motion-Aware Video Understanding</title>
      <link>http://arxiv.org/abs/2502.11594v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种改进视频大型语言模型（Video Large Language Models）的方法，以提高其对细粒度实例时空运动感知的能力。&lt;h4&gt;背景&lt;/h4&gt;当前的视频理解和时间理解能力在处理复杂和细节丰富的实例运动时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;通过数据和模型两个方面进行改进，从而提升视频大型语言模型的时间感知能力和总体视频理解能力。&lt;h4&gt;方法&lt;/h4&gt;{'数据改进': '创建了iMOVE-IT，这是第一个大规模的以实例运动为意识的视频指令调优数据集，该数据集包含详尽的实例运动注释和时空相互监督任务。', '模型改进': '提出了iMOVE，这是一种基于实例运动感知的视频基础模型，它利用事件感知的空间时间高效建模来保留信息丰富的实例空间时间细节，并采用相对空间时间位置令牌确保对实例空间时间位置的认识。'}&lt;h4&gt;主要发现&lt;/h4&gt;iMOVE在视频时间和总体理解以及长期视频理解方面表现出显著优势。&lt;h4&gt;结论&lt;/h4&gt;该方法为提高视频大型语言模型的时间感知能力和总体视频理解能力提供了一种有效的途径。&lt;h4&gt;翻译&lt;/h4&gt;提升视频大型语言模型细粒度实例时空运动感知的能力，对于改善其时间理解和整体视频理解至关重要。然而，当前的模型在感知详细和复杂的实例运动方面存在困难。为了应对这些挑战，我们从数据和模型两方面进行了改进。在数据层面，我们精心策划了iMOVE-IT，这是第一个大规模以实例运动为意识的视频指令调优数据集，该数据集包含详尽的实例运动注释和时空相互监督任务，提供了广泛的训练来提升模型对实例运动的感知能力。在此基础上，我们引入了iMOVE，这是一种基于实例运动感知的视频基础模型，它利用事件感知的空间时间高效建模来保留信息丰富的实例空间时间细节，并采用相对空间时间位置令牌确保对实例空间时间位置的认识。评估表明，iMOVE不仅在视频时间和总体理解方面表现出色，在长期视频理解中也显示出显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enhancing the fine-grained instance spatiotemporal motion perceptioncapabilities of Video Large Language Models is crucial for improving theirtemporal and general video understanding. However, current models struggle toperceive detailed and complex instance motions. To address these challenges, wehave made improvements from both data and model perspectives. In terms of data,we have meticulously curated iMOVE-IT, the first large-scaleinstance-motion-aware video instruction-tuning dataset. This dataset isenriched with comprehensive instance motion annotations and spatiotemporalmutual-supervision tasks, providing extensive training for the model'sinstance-motion-awareness. Building on this foundation, we introduce iMOVE, aninstance-motion-aware video foundation model that utilizes Event-awareSpatiotemporal Efficient Modeling to retain informative instance spatiotemporalmotion details while maintaining computational efficiency. It also incorporatesRelative Spatiotemporal Position Tokens to ensure awareness of instancespatiotemporal positions. Evaluations indicate that iMOVE excels not only invideo temporal understanding and general video understanding but alsodemonstrates significant advantages in long-term video understanding.</description>
      <author>example@mail.com (Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di Zhang)</author>
      <guid isPermaLink="false">2502.11594v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.10157v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的下一会话预测范式（NSPP）SessionRec，用于生成式的序列推荐。&lt;h4&gt;背景&lt;/h4&gt;现有传统的下一个项目预测范式（NIPP）与实际的基于会话用户交互存在基本不匹配的问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入会话感知表示学习以及多项目推荐下一会话预测目标来更好地捕捉用户的多样化兴趣。&lt;h4&gt;方法&lt;/h4&gt;采用层次序列聚合进行会话意识表示学习，减少注意力计算复杂性，并在下一会话预测中使用排名损失函数改进生成式序列推荐模型的排序效果。&lt;h4&gt;主要发现&lt;/h4&gt;SessionRec展示了与大型语言模型类似的幂律标度规律，在美团应用中的在线A/B测试表明其有效性。&lt;h4&gt;结论&lt;/h4&gt;通过其无模型特定架构和计算效率，所提出的范式为开发工业规模的生成性推荐系统建立了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新型的下一会话预测范式（NSPP）SessionRec，用于解决传统的下一个项目预测范式与现实世界中的推荐场景之间的根本不匹配。我们的框架通过层次序列聚合引入了基于会话的表示学习，并在下一会话中采用了多项目的推荐目标，以更好地捕捉用户的多样化兴趣。此外，在下一会话预测范式下为会话内的物品加入排名损失可以显著提高生成式序列推荐模型的排序效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SessionRec, a novel next-session prediction paradigm (NSPP) forgenerative sequential recommendation, addressing the fundamental misalignmentbetween conventional next-item prediction paradigm (NIPP) and real-worldrecommendation scenarios. Unlike NIPP's item-level autoregressive generationthat contradicts actual session-based user interactions, our frameworkintroduces a session-aware representation learning through hierarchicalsequence aggregation (intra/inter-session), reducing attention computationcomplexity while enabling implicit modeling of massive negative interactions,and a session-based prediction objective that better captures users' diverseinterests through multi-item recommendation in next sessions. Moreover, wefound that incorporating a rank loss for items within the session under thenext session prediction paradigm can significantly improve the rankingeffectiveness of generative sequence recommendation models. We also verifiedthat SessionRec exhibits clear power-law scaling laws similar to those observedin LLMs. Extensive experiments conducted on public datasets and online A/B testin Meituan App demonstrate the effectiveness of SessionRec. The proposedparadigm establishes new foundations for developing industrial-scale generativerecommendation systems through its model-agnostic architecture andcomputational efficiency.</description>
      <author>example@mail.com (Lei Huang, Hao Guo, Linzhi Peng, Long Zhang, Xiaoteng Wang, Daoyuan Wang, Shichao Wang, Jinpeng Wang, Lei Wang, Sheng Chen)</author>
      <guid isPermaLink="false">2502.10157v2</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.13144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://hgao-cv.github.io/RAD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于3DGS的闭环强化学习训练范式，用于自动驾驶算法，以解决因果混淆和开环差距等问题。通过构建逼真的数字副本，使政策能够广泛探索状态空间并处理边缘情况。&lt;h4&gt;背景&lt;/h4&gt;现有端到端自主驾驶（AD）算法通常遵循模仿学习（IL）模式，但面临如因果混淆及开环间隙等挑战。&lt;h4&gt;目的&lt;/h4&gt;建立基于3DGS的闭环强化学习训练范式，以改进自动驾驶策略的学习和安全性。&lt;h4&gt;方法&lt;/h4&gt;利用3DGS技术创建逼真的数字世界，设计特殊奖励引导政策响应关键安全事件，并理解真实世界的因果关系。同时结合模仿学习作为正则化项以更好地与人类驾驶行为对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在各种闭合回路指标中，RAD相比基于IL的方法表现出更强的性能，特别是在碰撞率方面降低了3倍。&lt;h4&gt;结论&lt;/h4&gt;通过闭环评估基准测试和多样化的3DGS环境验证了所提出方法的有效性，并展示了其卓越的安全性和行为一致性。&lt;h4&gt;翻译&lt;/h4&gt;现有的端到端自动驾驶算法多采用模仿学习模式，面临因果混淆及开环差距等挑战。本研究建立了基于3DGS的闭环强化学习训练框架，利用逼真的数字副本实现广泛状态空间探索，有效处理边缘情况，并设计特殊奖励以提升安全性与政策响应能力。为了更好地模拟人类驾驶行为，在RL训练中引入了模仿学习作为正则化项。此外，还构建了一个包含多种未见3DGS环境的闭环评估基准测试集。实验结果表明，相比基于IL的方法，RAD在大多数闭合回路指标上表现更优，特别是在碰撞率方面下降了3倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing end-to-end autonomous driving (AD) algorithms typically follow theImitation Learning (IL) paradigm, which faces challenges such as causalconfusion and the open-loop gap. In this work, we establish a 3DGS-basedclosed-loop Reinforcement Learning (RL) training paradigm. By leveraging 3DGStechniques, we construct a photorealistic digital replica of the real physicalworld, enabling the AD policy to extensively explore the state space and learnto handle out-of-distribution scenarios through large-scale trial and error. Toenhance safety, we design specialized rewards that guide the policy toeffectively respond to safety-critical events and understand real-world causalrelationships. For better alignment with human driving behavior, IL isincorporated into RL training as a regularization term. We introduce aclosed-loop evaluation benchmark consisting of diverse, previously unseen 3DGSenvironments. Compared to IL-based methods, RAD achieves stronger performancein most closed-loop metrics, especially 3x lower collision rate. Abundantclosed-loop results are presented at https://hgao-cv.github.io/RAD.</description>
      <author>example@mail.com (Hao Gao, Shaoyu Chen, Bo Jiang, Bencheng Liao, Yiang Shi, Xiaoyang Guo, Yuechuan Pu, Haoran Yin, Xiangyu Li, Xinbang Zhang, Ying Zhang, Wenyu Liu, Qian Zhang, Xinggang Wang)</author>
      <guid isPermaLink="false">2502.13144v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation</title>
      <link>http://arxiv.org/abs/2502.13143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://qizekun.github.io/sofar/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了语义方向的概念，通过自然语言描述对象的方向（例如USB插口的方向或刀具手柄的方向），从而提升机器人理解并处理物体姿态的能力。&lt;h4&gt;背景&lt;/h4&gt;空间智能是具身AI的关键组成部分，它促进了机器人对环境的理解和互动。尽管最近的进步增强了视觉语言模型感知物体位置及位置关系的能力，但它们仍然缺乏精确理解和表达对象方向的能力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有系统中关于对象姿态理解的局限性，提出了一种利用自然语言表达语义方向的方法，并通过构建大规模数据集支持这一概念。&lt;h4&gt;方法&lt;/h4&gt;提出了基于自然语言描述物体位置的新概念——语义方向；构建了一个大型数据集OrienText300K，该数据集中包含有三维模型和与几何理解及功能语义相联系的语义方向注释。将语义方向融入视觉语言模型系统中。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过采用本文提出的方法，机器人在处理需要精确方向控制的任务时表现出显著提高的能力，例如在Open6DOR测试中的准确率为48.7%，在SIMPLER测试中的准确率高达74.9%。&lt;h4&gt;结论&lt;/h4&gt;利用自然语言来表示物体的方向可以为具身AI系统提供更灵活、更具表现力的解决方案，有助于提升机器人处理复杂任务的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial intelligence is a critical component of embodied AI, promoting robotsto understand and interact with their environments. While recent advances haveenhanced the ability of VLMs to perceive object locations and positionalrelationships, they still lack the capability to precisely understand objectorientations-a key requirement for tasks involving fine-grained manipulations.Addressing this limitation not only requires geometric reasoning but also anexpressive and intuitive way to represent orientation. In this context, wepropose that natural language offers a more flexible representation space thancanonical frames, making it particularly suitable for instruction-followingrobotic systems. In this paper, we introduce the concept of semanticorientation, which defines object orientations using natural language in areference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the''handle'' direction of a knife). To support this, we construct OrienText300K,a large-scale dataset of 3D models annotated with semantic orientations thatlink geometric understanding to functional semantics. By integrating semanticorientation into a VLM system, we enable robots to generate manipulationactions with both positional and orientational constraints. Extensiveexperiments in simulation and real world demonstrate that our approachsignificantly enhances robotic manipulation capabilities, e.g., 48.7% accuracyon Open6DOR and 74.9% accuracy on SIMPLER.</description>
      <author>example@mail.com (Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He, Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi)</author>
      <guid isPermaLink="false">2502.13143v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations</title>
      <link>http://arxiv.org/abs/2502.13134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://humanoid-interaction.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为RHINO的框架，旨在使类人机器人能够在多模态的人机交互信号中快速理解和响应人类指令，实现即时反馈和中断。&lt;h4&gt;背景&lt;/h4&gt;现有的研究大多关注于分阶段的任务执行，忽视了实时反馈的重要性。为了在日常生活中更好地辅助人类，类人机器人需要能够根据人类的互动信号迅速做出反应。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，使类人机器人能够在任何时间点响应并处理来自人类的不同指令，并确保它们的安全性、灵活性和即时性。&lt;h4&gt;方法&lt;/h4&gt;RHINO是一个分层学习框架，它允许类人机器人通过观察人类与物体的互动以及远程操作的数据来学习反应技能。该框架将交互过程分为两个层次：高层次计划者从实时的人类行为中推断意图；低级控制器基于预测的意图执行即时动作和物体操纵。&lt;h4&gt;主要发现&lt;/h4&gt;RHINO能够在多种场景下有效、灵活且安全地工作，特别是在处理人类指令和保证机器人与环境的安全互动方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;通过引入RHINO框架，类人机器人可以更有效地融入日常生活并提供实时帮助。该研究为未来的人机交互提供了新的视角，并证明了其在提高机器人实用性和用户体验方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;类人机器人已经在步行和操纵等方面展示了成功之处。尽管具备这些基本能力，为了更好地成为人类日常生活的有价值的助手，它们仍然需要快速理解并根据人的互动信号做出反应。然而，大多数现有的研究只关注于多阶段的互动过程，并且忽略了实时反馈的重要性。本文提出了一种框架（RHINO），使类人机器人能够进行即时反馈和中断处理的能力，允许人们随时打断机器人的任务执行，并使得机器人可以立即回应人类的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots have shown success in locomotion and manipulation. Despitethese basic abilities, humanoids are still required to quickly understand humaninstructions and react based on human interaction signals to become valuableassistants in human daily life. Unfortunately, most existing works only focuson multi-stage interactions, treating each task separately, and neglectingreal-time feedback. In this work, we aim to empower humanoid robots withreal-time reaction abilities to achieve various tasks, allowing human tointerrupt robots at any time, and making robots respond to humans immediately.To support such abilities, we propose a general humanoid-human-objectinteraction framework, named RHINO, i.e., Real-time Humanoid-human Interactionand Object manipulation. RHINO provides a unified view of reactive motion,instruction-based manipulation, and safety concerns, over multiple human signalmodalities, such as languages, images, and motions. RHINO is a hierarchicallearning framework, enabling humanoids to learn reaction skills fromhuman-human-object demonstrations and teleoperation data. In particular, itdecouples the interaction process into two levels: 1) a high-level plannerinferring human intentions from real-time human behaviors; and 2) a low-levelcontroller achieving reactive motion behaviors and object manipulation skillsbased on the predicted intentions. We evaluate the proposed framework on a realhumanoid robot and demonstrate its effectiveness, flexibility, and safety invarious scenarios.</description>
      <author>example@mail.com (Jingxiao Chen, Xinyao Li, Jiahang Cao, Zhengbang Zhu, Wentao Dong, Minghuan Liu, Ying Wen, Yong Yu, Liqing Zhang, Weinan Zhang)</author>
      <guid isPermaLink="false">2502.13134v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>IM360: Textured Mesh Reconstruction for Large-scale Indoor Mapping with 360$^\circ$ Cameras</title>
      <link>http://arxiv.org/abs/2502.12545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于室内环境3D映射和渲染的全新360度相机3D重建管道。针对大规模室内场景中存在的纹理缺失与重复区域的问题，IM360方法利用全景图像的宽视野特性，并将球形相机模型集成到SfM管线的核心组件中。&lt;h4&gt;背景&lt;/h4&gt;传统的从运动结构（Structure-from-Motion, SfM）方法在处理大规模室内环境时存在局限性，特别是在纹理不足和重复区域广泛存在的情况下表现不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够全面解决室内3D重建问题的解决方案。该方案结合了神经隐式表面重构技术和基于网格的神经渲染技术，以生成高质量的表面并精炼纹理图。&lt;h4&gt;方法&lt;/h4&gt;IM360方法利用球形相机模型，将全景图像的优势整合到SfM管线中的每个核心组件，并且集成了神经隐式表面重建技术和基于网格的神经渲染技术来提高质量。&lt;h4&gt;主要发现&lt;/h4&gt;在实际测试中，IM360方法相对于现有最优方法（State-of-the-Art, SOTA）显示出了更优越的表现。具体来说，在纹理网格重构、相机定位和注册精度以及高频细节捕捉方面均有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的IM360方法在大规模室内场景的3D重建上展示了出色的性能，为室内环境的精细建模提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一个用于从360度摄像头获取的数据进行三维映射和渲染的全新三维重建管道。传统基于运动结构的方法可能不适合处理大型室内场景中的纹理缺失及重复区域问题。为了克服这些挑战，我们的方法IM360利用了全景图像的大视野范围，并将球形相机模型整合到SfM流水线的核心组件中。为实现全面的3D重建解决方案，我们结合了一种基于神经隐式的表面重建技术来从稀疏输入数据生成高质量的表面，并采用了基于网格的神经渲染方法来优化纹理图和准确捕捉视角依赖属性，通过组合漫反射和镜面成分。我们在Matterport3D及Stanford2D3D大型室内场景上评估了该管道，并观察到在纹理网格重构、相机定位和注册精度以及高频细节捕捉方面的改进，证明IM360相对于现有最优方法具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel 3D reconstruction pipeline for 360$^\circ$ cameras for 3Dmapping and rendering of indoor environments. Traditional Structure-from-Motion(SfM) methods may not work well in large-scale indoor scenes due to theprevalence of textureless and repetitive regions. To overcome these challenges,our approach (IM360) leverages the wide field of view of omnidirectional imagesand integrates the spherical camera model into every core component of the SfMpipeline. In order to develop a comprehensive 3D reconstruction solution, weintegrate a neural implicit surface reconstruction technique to generatehigh-quality surfaces from sparse input data. Additionally, we utilize amesh-based neural rendering approach to refine texture maps and accuratelycapture view-dependent properties by combining diffuse and specular components.We evaluate our pipeline on large-scale indoor scenes from the Matterport3D andStanford2D3D datasets. In practice, IM360 demonstrate superior performance interms of textured mesh reconstruction over SOTA. We observe accuracyimprovements in terms of camera localization and registration as well asrendering high frequency details.</description>
      <author>example@mail.com (Dongki Jung, Jaehoon Choi, Yonghan Lee, Dinesh Manocha)</author>
      <guid isPermaLink="false">2502.12545v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit</title>
      <link>http://arxiv.org/abs/2502.13013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为HOMIE的新系统，该系统整合了一个用于人形机器人操作的政策和一个低成本的外骨骼硬件系统。此系统使得单个操作者能够通过简单设备操控整个机器人的运动。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人远程操作系统要么缺乏可靠的低级控制策略，要么难以获取准确的整体肢体控制命令，从而使人形机器人的移动与抓取任务变得困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型人形机器人远程操作舱——HOMIE，以解决现有系统的问题，并促进更加稳定、快速和精确的人形机器人移动和操控。&lt;h4&gt;方法&lt;/h4&gt;通过结合外骨骼双臂装置、动作感应手套及脚踏板的低成本硬件系统以及基于强化学习训练框架设计的新策略。此策略使机器人能够根据任意上身姿态进行行走与下蹲至特定高度，同时收集的数据可用于模仿学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该远程操作舱显著提高了人形机器人的移动和操控效率，加速任务完成并减少重定位错误，并验证了其硬件系统数据在模仿学习中的有效性。&lt;h4&gt;结论&lt;/h4&gt;HOMIE不仅解决了现有系统的问题，还提供了用于模仿学习的有效训练数据。项目开源，可访问https://homietele.github.io/获取更多演示及代码。&lt;h4&gt;翻译&lt;/h4&gt;目前的人形机器人遥操作系统要么缺乏可靠的低级控制策略，要么难以获得精确的整体身体操控命令，这使得远程操作人形机器人为移动操作任务变得困难。为了解决这些问题，我们提出了HOMIE，一种新的基于人形机器人运动策略和低成本外骨骼硬件系统的远程操作舱。该策略使人形机器人能够在任意上身姿态的情况下行走，并蹲下至特定高度。这是通过我们的新颖强化学习训练框架实现的，该框架结合了上半身姿势课程、高度跟踪奖励以及对称性利用，而不依赖任何运动先验知识。配合政策，硬件系统集成了同构外骨骼双臂、一对动作感应手套和一个脚踏板，允许单个操作员完全控制人形机器人。我们的实验表明我们的远程操作系统能够实现更稳定、快速且精确的人形机器人移动与操控任务，加速了任务完成，并消除了逆向动力学方法的重定位错误。我们还验证了由我们系统收集的数据对于模仿学习的有效性。项目全部开源，演示和代码可在此网址中找到: https://homietele.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current humanoid teleoperation systems either lack reliable low-level controlpolicies, or struggle to acquire accurate whole-body control commands, makingit difficult to teleoperate humanoids for loco-manipulation tasks. To solvethese issues, we propose HOMIE, a novel humanoid teleoperation cockpitintegrates a humanoid loco-manipulation policy and a low-cost exoskeleton-basedhardware system. The policy enables humanoid robots to walk and squat tospecific heights while accommodating arbitrary upper-body poses. This isachieved through our novel reinforcement learning-based training framework thatincorporates upper-body pose curriculum, height-tracking reward, and symmetryutilization, without relying on any motion priors. Complementing the policy,the hardware system integrates isomorphic exoskeleton arms, a pair ofmotion-sensing gloves, and a pedal, allowing a single operator to achieve fullcontrol of the humanoid robot. Our experiments show our cockpit facilitatesmore stable, rapid, and precise humanoid loco-manipulation teleoperation,accelerating task completion and eliminating retargeting errors compared toinverse kinematics-based methods. We also validate the effectiveness of thedata collected by our cockpit for imitation learning. Our project is fullyopen-sourced, demos and code can be found in https://homietele.github.io/.</description>
      <author>example@mail.com (Qingwei Ben, Feiyu Jia, Jia Zeng, Junting Dong, Dahua Lin, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.13013v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>D3-ARM: High-Dynamic, Dexterous and Fully Decoupled Cable-driven Robotic Arm</title>
      <link>http://arxiv.org/abs/2502.12963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的运动解耦机制，用于减轻电缆驱动的机械臂在远程操作中出现的移动耦合和电缆布线问题，并通过一个完全解耦且轻量化的D3-Arm机器人手臂验证了该方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;电缆传输使机械臂能够在各种环境中以轻量级、低惯性的关节运行，但同时也带来了运动耦合和电缆布线的问题，这些问题会降低手臂的控制精度和性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解耦机制来解决由电缆驱动引起的移动耦合问题，并开发出一款高效且稳定的机器人机械臂（D3-Arm）。&lt;h4&gt;方法&lt;/h4&gt;设计了一种低摩擦度的运动解耦机制，通过在关节处安装这些装置制造了一个完全解耦、轻量化的电缆驱动机器人手臂（D3-Arm），所有电气元件均位于底座上。此外，还集成了一个缆线预张紧机构来提高长距离电缆传输的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;这款776毫米长且拥有六自由度（DOF）、仅重1.6公斤的机械臂，在一系列全面测试中证明了其卓越的表现：平均定位误差为1.29毫米，载荷能力可达2.0千克。这表明所提出的解耦机制在电缆驱动机器人手臂中具有实用性。&lt;h4&gt;结论&lt;/h4&gt;通过D3-Arm的实验结果证实了解耦机制的有效性，并展示了该设计对于实现高性能和高精度电缆驱动机械臂的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的运动解耦机制，用于减轻电缆驱动的机械臂在远程操作中出现的移动耦合和电缆布线问题。通过一系列广泛的测试，表明了这种基于低摩擦度的设计可以提高动力传输效率，并且证明所提出的解耦方法对实现高性能和高精度的电缆驱动机器人手臂的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cable transmission enables motors of robotic arm to operate lightweight andlow-inertia joints remotely in various environments, but it also creates issueswith motion coupling and cable routing that can reduce arm's control precisionand performance. In this paper, we present a novel motion decoupling mechanismwith low-friction to align the cables and efficiently transmit the motor'spower. By arranging these mechanisms at the joints, we fabricate a fullydecoupled and lightweight cable-driven robotic arm called D3-Arm with all theelectrical components be placed at the base. Its 776 mm length moving partboasts six degrees of freedom (DOF) and only 1.6 kg weights. To address theissue of cable slack, a cable-pretension mechanism is integrated to enhance thestability of long-distance cable transmission. Through a series ofcomprehensive tests, D3-Arm demonstrated 1.29 mm average positioning error and2.0 kg payload capacity, proving the practicality of the proposed decouplingmechanisms in cable-driven robotic arm.</description>
      <author>example@mail.com (Hong Luo, Jianle Xu, Shoujie Li, Huayue Liang, Yanbo Chen, Chongkun Xia, Xueqian Wang)</author>
      <guid isPermaLink="false">2502.12963v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RobotIQ: Empowering Mobile Robots with Human-Level Planning for Real-World Execution</title>
      <link>http://arxiv.org/abs/2502.12862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一个名为RobotIQ的框架，该框架使移动机器人具备了类似人类级别的规划能力，并能够通过大型语言模型进行自然语言指令交流。此框架基于ROS架构设计，旨在弥合人与机器之间的差距，让机器人能够理解和执行用户输入的文字或语音命令。&lt;h4&gt;背景&lt;/h4&gt;当前机器人技术在理解复杂的人类指示和任务执行方面面临挑战，尤其是在需要高度智能规划能力的任务中。&lt;h4&gt;目的&lt;/h4&gt;提出一个集成大型语言模型的框架，使得移动机器人可以理解和响应自然语言指令，并能够在广泛的任务上实现人类级别的规划能力和行为适应性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个基于ROS架构的框架RobotIQ，该框架允许机器人理解并执行用户通过文本或语音输入的命令。此外，该系统在模拟和现实世界环境中均进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;RobotIQ成功地将大型语言模型整合到机器人控制系统中，使得机器人能够在导航、操作以及物体定位等任务上表现出色，并且能够从模拟环境中学得的行为迁移到真实场景应用中。&lt;h4&gt;结论&lt;/h4&gt;RobotIQ是一个开源的、易于使用和高度可适应性的机器人库套件，适用于各种类型的机器人。其有效性和实用性已在家庭服务场景中的协助老年人的应用程序中得到验证。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces RobotIQ, a framework that empowers mobile robots withhuman-level planning capabilities, enabling seamless communication via naturallanguage instructions through any Large Language Model. The proposed frameworkis designed in the ROS architecture and aims to bridge the gap between humansand robots, enabling robots to comprehend and execute user-expressed text orvoice commands. Our research encompasses a wide spectrum of robotic tasks,ranging from fundamental logical, mathematical, and learning reasoning fortransferring knowledge in domains like navigation, manipulation, and objectlocalization, enabling the application of learned behaviors from simulatedenvironments to real-world operations. All encapsulated within a modularcrafted robot library suite of API-wise control functions, RobotIQ offers afully functional AI-ROS-based toolset that allows researchers to design anddevelop their own robotic actions tailored to specific applications and robotconfigurations. The effectiveness of the proposed system was tested andvalidated both in simulated and real-world experiments focusing on a homeservice scenario that included an assistive application designed for elderlypeople. RobotIQ with an open-source, easy-to-use, and adaptable robotic librarysuite for any robot can be found at https://github.com/emmarapt/RobotIQ.</description>
      <author>example@mail.com (Emmanuel K. Raptis, Athanasios Ch. Kapoutsis, Elias B. Kosmatopoulos)</author>
      <guid isPermaLink="false">2502.12862v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>InstructRobot: A Model-Free Framework for Mapping Natural Language Instructions into Robot Motion</title>
      <link>http://arxiv.org/abs/2502.12861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种名为InstructRobot的框架，该框架能够将自然语言指令转换为机器人的物理动作，而无需构建大型数据集或预先了解机器人动力学模型。&lt;h4&gt;背景&lt;/h4&gt;人类与机器人的交互中使用自然语言交流是一个重要的进步。然而，准确地将口头命令转化为物理动作仍然面临挑战，现有的方法需要大量的训练数据且主要适用于最多具有6个自由度的机器人。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法所需的大规模数据集和对机器人动力学模型先验知识的需求问题。&lt;h4&gt;方法&lt;/h4&gt;InstructRobot框架利用强化学习算法，实现语言表示与逆向运动学模型的同时学习，简化整个学习过程。该框架已在具有26个旋转关节的复杂机器人的物体操作任务中得到验证。&lt;h4&gt;主要发现&lt;/h4&gt;通过在复杂的机器人环境中测试，证明了该框架的有效性、鲁棒性和适应性，特别适用于数据集稀缺且难以创建的任务或领域。&lt;h4&gt;结论&lt;/h4&gt;InstructRobot提供了一种直观且可访问的方法来解决使用语言交流训练机器人的挑战，并公开了源代码以供进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了如何利用自然语言命令指导机器人执行物理动作的框架，名为InstructRobot。它克服了传统方法中对大规模数据集及先验动力学模型的需求限制，展示了在复杂环境中的强大适应性和实用性，并提供了一个开源平台促进进一步的研究和发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to communicate with robots using natural language is asignificant step forward in human-robot interaction. However, accuratelytranslating verbal commands into physical actions is promising, but stillpresents challenges. Current approaches require large datasets to train themodels and are limited to robots with a maximum of 6 degrees of freedom. Toaddress these issues, we propose a framework called InstructRobot that mapsnatural language instructions into robot motion without requiring theconstruction of large datasets or prior knowledge of the robot's kinematicsmodel. InstructRobot employs a reinforcement learning algorithm that enablesjoint learning of language representations and inverse kinematics model,simplifying the entire learning process. The proposed framework is validatedusing a complex robot with 26 revolute joints in object manipulation tasks,demonstrating its robustness and adaptability in realistic environments. Theframework can be applied to any task or domain where datasets are scarce anddifficult to create, making it an intuitive and accessible solution to thechallenges of training robots using linguistic communication. Open source codefor the InstructRobot framework and experiments can be accessed athttps://github.com/icleveston/InstructRobot.</description>
      <author>example@mail.com (Iury Cleveston, Alana C. Santana, Paula D. P. Costa, Ricardo R. Gudwin, Alexandre S. Simões, Esther L. Colombini)</author>
      <guid isPermaLink="false">2502.12861v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Applications of Stretch Reflex for the Upper Limb of Musculoskeletal Humanoids: Protective Behavior, Postural Stability, and Active Induction</title>
      <link>http://arxiv.org/abs/2502.12811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在类人机器人上嵌入和评估人类反射行为的重要性，并具体分析了伸展反射（即牵张反射）在机器人的应用。&lt;h4&gt;背景&lt;/h4&gt;肌肉骨骼的仿生人体模型具有多种生物模仿的好处，将人类反射特性植入实际机器人中进行评估是研究的重点。目前虽然已经对下肢进行了类似的实验，但上肢的应用还未广泛探索。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过实施伸展反射在类人机器人的手臂部分来发现其潜在应用价值，并探讨参数差异如何影响行为表现。&lt;h4&gt;方法&lt;/h4&gt;文章讨论了实际机器人中伸张反射的实现方式及其主动和被动应用场景，同时分析了不同参数对机器人行为的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实施上肢的伸展反射不仅有助于提高仿人机器人的运动灵活性和反应能力，还能通过调整参数来改变其动作特性。&lt;h4&gt;结论&lt;/h4&gt;上肢伸张反射的应用为未来类人机器人的设计提供了新的思路和技术基础。这项研究强调了进一步探索人体反射机制与机器人集成之间关系的重要性。&lt;h4&gt;翻译&lt;/h4&gt;肌肉骨骼的人形机器人具有多种仿生学上的好处，嵌入并评估人类的反射行为对于实际机器人来说很重要。虽然已经在下肢实现了伸展反射（牵张反射），但本论文将其应用于上肢以发现其潜在的应用价值。本文考虑了在实际机器人中实现伸展反射的方式、主动和被动应用以及由于参数差异引起的行为变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS45743.2020.9341488&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The musculoskeletal humanoid has various biomimetic benefits, and it isimportant that we can embed and evaluate human reflexes in the actual robot.Although stretch reflex has been implemented in lower limbs of musculoskeletalhumanoids, we apply it to the upper limb to discover its useful applications.We consider the implementation of stretch reflex in the actual robot, itsactive/passive applications, and the change in behavior according to thedifference of parameters.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12811v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Exceeding the Maximum Speed Limit of the Joint Angle for the Redundant Tendon-driven Structures of Musculoskeletal Humanoids</title>
      <link>http://arxiv.org/abs/2502.12808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出并验证了两种克服冗余肌肉中速度限制的方法，使得多自由度人形机器人能够实现关节角度的最大角速度超越传统极限。&lt;h4&gt;背景&lt;/h4&gt;具有仿生特性的骨骼肌人体型机器人拥有冗余的肌肉结构，这种结构允许其在故障安全和变量刚度控制方面表现出色。然而，在实际应用中存在一个问题，即最大关节角度速度受限于冗余肌肉中最慢的一块。&lt;h4&gt;目的&lt;/h4&gt;提出并验证两种方法来克服由冗余肌肉带来的关节运动速度限制问题。&lt;h4&gt;方法&lt;/h4&gt;设计了能够超出传统速度极限的两种方案，并通过实体机器人实验验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的解决方案在实际应用中证明有效，成功超越了由于最慢冗余肌肉导致的速度上限。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来基于冗余肌肉结构的人形机器人的设计提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;多自由度人形机器人因其具有生物模仿特性而拥有诸多好处，其中最重要的特点之一就是其冗余的肌肉安排。这种冗余可以实现故障安全的冗余驱动以及变量刚度控制。然而，在实践中存在这样一个问题：最大关节角度速度受制于冗余肌肉中最慢的那一块。在这项研究中，我们提出了两种能够超越限制性最高速度的方法，并通过实际机器人的实验验证了这些方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS45743.2020.9341510&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The musculoskeletal humanoid has various biomimetic benefits, and theredundant muscle arrangement is one of its most important characteristics. Thisredundancy can achieve fail-safe redundant actuation and variable stiffnesscontrol. However, there is a problem that the maximum joint angle velocity islimited by the slowest muscle among the redundant muscles. In this study, wepropose two methods that can exceed the limited maximum joint angle velocity,and verify the effectiveness with actual robot experiments.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yuya Koga, Kei Tsuzuki, Moritaka Onitsuka, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12808v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture</title>
      <link>http://arxiv.org/abs/2502.12803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2021&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了肌肉冗余在类人机器人中的重要性，特别是当一个肌肉失效时仍然保持运动的能力。&lt;h4&gt;背景&lt;/h4&gt;骨骼肌型类人机器人的优势之一是可以通过调整肌肉的排列来控制关节的刚度。然而，许多研究并未关注单一肌肉损坏后系统仍能继续运作的问题。&lt;h4&gt;目的&lt;/h4&gt;优化肌肉排列设计以最大化在某一肌肉失效时仍可施加的最小可用扭矩。&lt;h4&gt;方法&lt;/h4&gt;采用仿真技术对类人机器人Musashi的手肘进行分析，并通过实际机器人的实验验证了该设计策略的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现了优化肌肉布置可以提高机器人在特定条件下（例如单一肌肉损坏）下的性能和稳定性。&lt;h4&gt;结论&lt;/h4&gt;通过对肌肉排列的设计优化，提高了类人机器人的鲁棒性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;骨骼肌型人类机器人具有多种仿生优势，其中允许可变刚度控制的冗余肌肉布置是最重要的特点之一。在这项研究中，我们专注于其中一个冗余特性，即即使一个肌肉损坏，该机器人仍然能够继续移动，这一点在许多研究中尚未被充分考虑。为了充分利用这一优点，通过最大化单一肌肉失效时仍可施加的最小可用扭矩来优化肌肉排列设计。该方法应用于具有骨骼肌结构的人形机器人Musashi的手肘，并从仿真结果中提取了设计策略，然后通过实际机器人的实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS51168.2021.9636845&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Musculoskeletal humanoids have various biomimetic advantages, and theredundant muscle arrangement allowing for variable stiffness control is one ofthe most important. In this study, we focus on one feature of the redundancy,which enables the humanoid to keep moving even if one of its muscles breaks, anadvantage that has not been dealt with in many studies. In order to make themost of this advantage, the design of muscle arrangement is optimized byconsidering the maximization of minimum available torque that can be exertedwhen one muscle breaks. This method is applied to the elbow of amusculoskeletal humanoid Musashi with simulations, the design policy isextracted from the optimization results, and its effectiveness is confirmedwith the actual robot.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yasunori Toshimitsu, Manabu Nishiura, Yuya Koga, Yusuke Omura, Yuki Asano, Kei Okada, Koji Kawasaki, Masayuki Inaba)</author>
      <guid isPermaLink="false">2502.12803v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>ExoKit: A Toolkit for Rapid Prototyping of Interactions for Arm-based Exoskeletons</title>
      <link>http://arxiv.org/abs/2502.12747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conditionally accepted to CHI '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;ExoKit是一款针对初学者的快速原型制作工具包，用于低精度、功能性的外骨骼原型开发。&lt;h4&gt;背景&lt;/h4&gt;人类与外骨骼之间的交互虽然具有潜力，但因缺乏易于使用的原型设计工具而未被充分探索。这阻碍了设计师轻松地开发定制化外骨骼设计和互动行为。&lt;h4&gt;目的&lt;/h4&gt;通过提供易于制作和重新配置的模块化硬件组件以及简化编程的高级功能抽象，ExoKit旨在降低早期交互设计阶段的门槛，并支持各种经验水平的设计者。&lt;h4&gt;方法&lt;/h4&gt;ExoKit包含用于感应和驱动肩部与肘部关节的模块化硬件组件。此外，它还提供了命令行接口、图形用户界面、Processing库以及微控制器固件等多种编程方式供不同技能水平的人使用。&lt;h4&gt;主要发现&lt;/h4&gt;通过实施的应用案例及两项使用研究证明了ExoKit在外骨骼原型设计中的多功能性和易用性。&lt;h4&gt;结论&lt;/h4&gt;ExoKit为外骨骼的早期互动设计提供了有力支持，展示了其在HCI（人机交互）领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;外骨骼开辟了一种独特的人体运动与机器人驱动无缝结合的交互空间。尽管有巨大潜力，但由于缺乏易于使用的原型制作工具，人类与外骨骼之间的交互一直是HCI领域的一个未被充分探索的研究方向。我们推出了ExoKit，这是一个针对初学者的DIY（自己动手做）快速原型开发套件，用于低精度、功能性的外骨骼设计，并能支持定制化的互动行为发展。ExoKit包括感应和驱动肩部及肘部关节的模块化硬件组件，这些组件易于制作且可重新配置以适应个性化需求与舒适度。为了简化交互行为的编程过程，我们提出了包含高层次人类-外骨骼互动的功能抽象概念。这些可以方便地通过ExoKit的命令行接口、图形用户界面（GUI）、Processing库或微控制器固件来访问，每种方式都针对不同的经验水平进行设计。实施的应用案例以及两项使用研究的结果表明了ExoKit在外骨骼早期交互设计中的灵活性和易用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713815&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Exoskeletons open up a unique interaction space that seamlessly integratesusers' body movements with robotic actuation. Despite its potential,human-exoskeleton interaction remains an underexplored area in HCI, largely dueto the lack of accessible prototyping tools that enable designers to easilydevelop exoskeleton designs and customized interactive behaviors. We presentExoKit, a do-it-yourself toolkit for rapid prototyping of low-fidelity,functional exoskeletons targeted at novice roboticists. ExoKit includes modularhardware components for sensing and actuating shoulder and elbow joints, whichare easy to fabricate and (re)configure for customized functionality andwearability. To simplify the programming of interactive behaviors, we proposefunctional abstractions that encapsulate high-level human-exoskeletoninteractions. These can be readily accessed either through ExoKit'scommand-line or graphical user interface, a Processing library, ormicrocontroller firmware, each targeted at different experience levels.Findings from implemented application cases and two usage studies demonstratethe versatility and accessibility of ExoKit for early-stage interaction design.</description>
      <author>example@mail.com (Marie Muehlhaus, Alexander Liggesmeyer, Jürgen Steimle)</author>
      <guid isPermaLink="false">2502.12747v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Form and function in biological filaments: A physicist's review</title>
      <link>http://arxiv.org/abs/2502.12731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然界利用延长的形状和丝状结构来构建稳定结构、产生运动，并允许复杂的几何相互作用。&lt;h4&gt;目的&lt;/h4&gt;在本次综述中，我们探讨了不同尺度下生物丝状体的作用。&lt;h4&gt;主要发现&lt;/h4&gt;{'分子水平': '细胞骨架丝提供了一个既牢固又动态的细胞支架', '细胞附属物水平': '类似纤毛和鞭毛等细胞附肢的功能', '微小微生物水平': '蓝藻等丝状微生物在地球上是最成功的种群之一', '长形动物水平': '如蠕虫和蛇等长形动物，其运动方式启发了机器人的类比'}&lt;h4&gt;结论&lt;/h4&gt;强调了一般机制将形式与功能联系起来的原理。物理原则（例如经典弹性及主动物质的非互易性）可以用于追踪跨越约六个数量级长度尺度这些系统的统一主题。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了生物丝状体在不同尺度下的作用，从分子水平到长形动物等不同尺度下探讨了它们的功能，并强调了一般机制将形式与功能联系起来的原理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nature uses elongated shapes and filaments to build stable structures,generate motion, and allow complex geometric interactions. In this Review, weexamine the role of biological filaments across different length scales. Fromthe molecular scale, where cytoskeletal filaments provides a robust but dynamiccellular scaffolding, over the scale of cellular appendages like cilia andflagella, to the scale of filamentous microorganisms like cyanobacteria whichare among the most successful genera on Earth, and even to the scale ofelongated animals like worms and snakes, whose motility modes inspire roboticanalogues. We highlight the general mechanisms that couple form and function.Physical principles, such as classical elasticity and the non-reciprocity ofactive matter can be used to trace unifying themes linking these systemsspanning about six orders of magnitude in length.</description>
      <author>example@mail.com (Jan Cammann, Hannah Laeverenz-Schlogelhofer, Kirsty Y. Wan, Marco G. Mazza)</author>
      <guid isPermaLink="false">2502.12731v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Responsive Noise-Relaying Diffusion Policy: Responsive and Efficient Visuomotor Control</title>
      <link>http://arxiv.org/abs/2502.12724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的机器人模仿学习策略，即响应式噪声中继扩散政策(RNR-DP)，解决了现有Diffusion Policy在处理需要即时反应的任务时的局限性。&lt;h4&gt;背景&lt;/h4&gt;模仿学习是一种高效的机器人任务教学方法。特别是基于条件去噪扩散过程生成动作的Diffusion Policy，在从多模态演示中学习方面表现出色，但依赖于执行多个动作以保持性能并防止模式跳跃。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略来解决现有Diffusion Policy响应性不足的问题，同时保留其在任务处理上的优势。&lt;h4&gt;方法&lt;/h4&gt;引入了RNR-DP，该政策通过维护一个噪声中继缓冲区和采用顺序去噪机制，生成基于最新观测的即时、无噪声动作，而将有噪音的动作添加到序列尾部。这种设计确保了动作响应性和运动一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在需要快速反应的任务上，RNR-DP相比Diffusion Policy提高了18%的成功率；而在常规任务中也超过了最佳加速方法6.9%，展示了其计算效率上的优势。&lt;h4&gt;结论&lt;/h4&gt;RNR-DP通过引入噪声中继缓冲区和顺序去噪机制解决了现有策略的响应性问题，并在需要快速反应的任务上表现出色，同时保持了良好的计算效率。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习是一种高效地教机器人执行各种任务的方法。Diffusion Policy利用条件去噪扩散过程生成动作，在从多模态演示中学习方面表现优异。然而，它依赖于执行多个动作来维持性能和防止模式跳跃，这限制了它的响应性，因为动作不是基于最新的观察。为了解决这个问题，我们提出了响应式噪声中继扩散政策(RNR-DP)，该策略维护一个噪声水平逐渐增加的噪声中继缓冲区，并采用顺序去噪机制生成即时、无噪音的动作序列头部和在序列尾部添加有噪音的动作。这确保了动作基于最新的观察并保持运动一致性。这种设计能够处理需要响应控制的任务，通过重用去噪步骤加速动作生成。在敏感于反应的任务上的实验表明，与Diffusion Policy相比，我们实现了18%的成功率提升。进一步对常规任务的评估显示，RNR-DP也超过了最佳加速方法6.9%，突显了其在响应性要求较低场景中的计算效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning is an efficient method for teaching robots a variety oftasks. Diffusion Policy, which uses a conditional denoising diffusion processto generate actions, has demonstrated superior performance, particularly inlearning from multi-modal demonstrates. However, it relies on executingmultiple actions to retain performance and prevent mode bouncing, which limitsits responsiveness, as actions are not conditioned on the most recentobservations. To address this, we introduce Responsive Noise-Relaying DiffusionPolicy (RNR-DP), which maintains a noise-relaying buffer with progressivelyincreasing noise levels and employs a sequential denoising mechanism thatgenerates immediate, noise-free actions at the head of the sequence, whileappending noisy actions at the tail. This ensures that actions are responsiveand conditioned on the latest observations, while maintaining motionconsistency through the noise-relaying buffer. This design enables the handlingof tasks requiring responsive control, and accelerates action generation byreusing denoising steps. Experiments on response-sensitive tasks demonstratethat, compared to Diffusion Policy, ours achieves 18% improvement in successrate. Further evaluation on regular tasks demonstrates that RNR-DP also exceedsthe best acceleration method by 6.9%, highlighting its computational efficiencyadvantage in scenarios where responsiveness is less critical.</description>
      <author>example@mail.com (Zhuoqun Chen, Xiu Yuan, Tongzhou Mu, Hao Su)</author>
      <guid isPermaLink="false">2502.12724v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Soft Arm-Motor Thrust Characterization for a Pneumatically Actuated Soft Morphing Quadrotor</title>
      <link>http://arxiv.org/abs/2502.12716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This extended abstract was accepted for RoboSoft Conference, 2025 but  later withdrawn&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文研究了一种软体、气动驱动变形四旋翼无人机的配置空间，并重点分析了其柔性臂在考虑下洗流影响下的精确推力特性。&lt;h4&gt;背景&lt;/h4&gt;传统的四旋翼无人机使用固定的刚性结构，而这种新型的软体无人机采用气动驱动的柔性臂。这种设计引入了电机推力与臂变形之间的复杂非线性相互作用，使得精密控制变得非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;对软体无人机配置空间进行实验表征，并特别关注其在考虑下洗流效应的情况下精确推进臂特性的分析。&lt;h4&gt;方法&lt;/h4&gt;通过采用不同的气动压力实现柔性臂的可变工作空间，并在整个飞行过程中监控和控制柔性臂在压缩和扩张时的偏转。实验中还研究了电机产生的下洗流对臂偏转角度的影响。&lt;h4&gt;主要发现&lt;/h4&gt;下洗流显著且随机地影响着软体无人机的稳定性及臂部期望偏转，这种干扰难以实时预测与补偿。&lt;h4&gt;结论&lt;/h4&gt;论文为软体、气动驱动变形四旋翼在实际飞行中可能遇到的问题提供了重要的实验表征和分析基础。这项工作有助于提升对柔性臂精确控制的理解，并为进一步优化该类无人机的设计提供了有价值的指导。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们展示了一种软体、气动驱动变形四旋翼无人机配置空间的实验表征，重点在于其柔性的推进臂在考虑到下洗流影响情况下的精确推力特性分析。不同于传统的刚性结构四旋翼无人机，该软体无人机使用了通过不同压力控制的硅胶柔性臂。这种设计带来了电机产生的推力与臂变形之间的复杂非线性相互作用，增加了实现精密控制的难度。在飞行过程中，安装于柔性臂末端的电机所产生的下洗流显著且随机地干扰着臂偏转角度及系统稳定性，对此进行了实验表征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, an experimental characterization of the configuration space ofa soft, pneumatically actuated morphing quadrotor is presented, with a focus onprecise thrust characterization of its flexible arms, considering the effect ofdownwash. Unlike traditional quadrotors, the soft drone has pneumaticallyactuated arms, introducing complex, nonlinear interactions between motor thrustand arm deformation, which make precise control challenging. The silicone armsare actuated using differential pressure to achieve flexibility and thus have avariable workspace compared to their fixed counter-parts. The deflection of thesoft arms during compression and expansion is controlled throughout the flight.However, in real time, the downwash from the motor attached at the tip of thesoft arm generates a significant and random disturbance on the arm. Thisdisturbance affects both the desired deflection of the arm and the overallstability of the system. To address this factor, an experimentalcharacterization of the effect of downwash on the deflection angle of the armis conducted.</description>
      <author>example@mail.com (Vidya Sumathy, Jakub Haluska, George Nikolokopoulos)</author>
      <guid isPermaLink="false">2502.12716v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Introducing ROADS: A Systematic Comparison of Remote Control Interaction Concepts for Automated Vehicles at Road Works</title>
      <link>http://arxiv.org/abs/2502.12680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be presented at CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着车辆自动化技术的成熟，远程监控和干预功能变得越来越重要。这项研究设计并评估了三种人机交互概念（路径规划、轨迹引导和航点引导），结果表明参与者更偏好路径规划方法。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶技术的发展，需要强大的远程监控与干预系统来确保车辆在出现故障或复杂路况时能够得到及时的人工介入。这要求人类操作员的角色从持续的驾驶员转变为间歇性的远程操控者。&lt;h4&gt;目的&lt;/h4&gt;评估三种不同的人机交互概念（路径规划、轨迹引导和航点引导）的有效性，为未来自动驾驶汽车的人机接口开发提供指导。&lt;h4&gt;方法&lt;/h4&gt;设计并实施了三个交互概念，并在包含23名参与者的受试内研究中进行了测试，每个参与者都面对着多达四个同时发生的自动化车辆请求。&lt;h4&gt;主要发现&lt;/h4&gt;路径规划的概念得到了最高的偏好度和最佳的可用性表现；轨迹引导解决了最少的问题，但没有具体说明满意度如何。这些结果有助于未来远程协助自动驾驶汽车的人机接口开发。&lt;h4&gt;结论&lt;/h4&gt;研究证明了不同人机交互概念的有效性和局限性，并建议在未来的发展中进一步优化这些系统。&lt;h4&gt;翻译&lt;/h4&gt;随着车辆自动化技术的成熟，需要强大的远程监控和干预功能来应对故障、恶劣驾驶条件或难以导航区域。这要求人类操作员的角色从持续驾驶员转变为间歇性的远程操控者，从而促使开发适合的人机接口。尽管提出了某些界面概念，但没有比较研究。这项工作设计并评估了三种交互模式（路径规划、轨迹引导和航点引导），每个参与者最多面对四个同时发生的自动化车辆请求。结果显示了对路径规划概念的明确偏好，并达到了最高的可用性水平，尽管满意度相对较低。使用轨迹引导时，解决了最少的问题。这些发现为未来专注于远程协助自动驾驶汽车的人机接口开发做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713476&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As vehicle automation technology continues to mature, there is a necessityfor robust remote monitoring and intervention features. These are essential forintervening during vehicle malfunctions, challenging road conditions, or inareas that are difficult to navigate. This evolution in the role of the humanoperator - from a constant driver to an intermittent teleoperator -necessitates the development of suitable interaction interfaces. While someinterfaces were suggested, a comparative study is missing. We designed,implemented, and evaluated three interaction concepts (path planning,trajectory guidance, and waypoint guidance) with up to four concurrent requestsof automated vehicles in a within-subjects study with N=23 participants. Theresults showed a clear preference for the path planning concept. It also led tothe highest usability but lower satisfaction. With trajectory guidance, thefewest requests were resolved. The study's findings contribute to the ongoingdevelopment of HMIs focused on the remote assistance of automated vehicles.</description>
      <author>example@mail.com (Mark Colley, Jonathan Westhauser, Jonas Andersson, Alexander G. Mirnig, Enrico Rukzio)</author>
      <guid isPermaLink="false">2502.12680v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>SATA: Safe and Adaptive Torque-Based Locomotion Policies Inspired by Animal Learning</title>
      <link>http://arxiv.org/abs/2502.12674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于生物力学原理的SATA框架，用于学习扭矩控制策略，以提高四足机器人在复杂环境中的适应性和安全性。&lt;h4&gt;背景&lt;/h4&gt;当前多数腿部机器人的控制方法采用位置控制，这种方法难以应对训练外的新环境或干扰。动物通过肌肉的伸缩实现平滑且适应性的运动，基于扭矩的方法可以更直接地控制执行器，但其推广受到非线性状态空间和探索效率低下的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种生物启发式的SATA框架以解决现有方法在复杂环境中的挑战，同时实现在模拟到现实场景中的零样本迁移能力。&lt;h4&gt;方法&lt;/h4&gt;通过模仿动物运动的机械结构和自适应学习机制来设计控制策略，提高早期探索效率，最终获得高性能策略，并实现从模拟环境到真实环境的有效迁移。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SATA能够在软滑地形、狭窄通道等复杂环境中表现出良好的顺应性和安全性，在面对重大外部干扰时也能保持稳定运行。这为机器人在人类中心场景中的实际部署提供了可能。&lt;h4&gt;结论&lt;/h4&gt;生物启发式的控制策略有助于提高腿部机器人的适应性，通过优化探索阶段的性能可以有效促进扭矩控制方法的学习过程，并具有现实应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in learning-based controllers for legged robots,deployments in human-centric environments remain limited by safety concerns.Most of these approaches use position-based control, where policies outputtarget joint angles that must be processed by a low-level controller (e.g., PDor impedance controllers) to compute joint torques. Although impressive resultshave been achieved in controlled real-world scenarios, these methods oftenstruggle with compliance and adaptability when encountering environments ordisturbances unseen during training, potentially resulting in extreme or unsafebehaviors. Inspired by how animals achieve smooth and adaptive movements bycontrolling muscle extension and contraction, torque-based policies offer apromising alternative by enabling precise and direct control of the actuatorsin torque space. In principle, this approach facilitates more effectiveinteractions with the environment, resulting in safer and more adaptablebehaviors. However, challenges such as a highly nonlinear state space andinefficient exploration during training have hindered their broader adoption.To address these limitations, we propose SATA, a bio-inspired framework thatmimics key biomechanical principles and adaptive learning mechanisms observedin animal locomotion. Our approach effectively addresses the inherentchallenges of learning torque-based policies by significantly improvingearly-stage exploration, leading to high-performance final policies.Remarkably, our method achieves zero-shot sim-to-real transfer. Ourexperimental results indicate that SATA demonstrates remarkable compliance andsafety, even in challenging environments such as soft/slippery terrain ornarrow passages, and under significant external disturbances, highlighting itspotential for practical deployments in human-centric and safety-criticalscenarios.</description>
      <author>example@mail.com (Peizhuo Li, Hongyi Li, Ge Sun, Jin Cheng, Xinrong Yang, Guillaume Bellegarda, Milad Shafiee, Yuhong Cao, Auke Ijspeert, Guillaume Sartoretti)</author>
      <guid isPermaLink="false">2502.12674v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>LiMo-Calib: On-Site Fast LiDAR-Motor Calibration for Quadruped Robot-Based Panoramic 3D Sensing System</title>
      <link>http://arxiv.org/abs/2502.12655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种高效的现场校准方法LiMo-Calib，用于解决四足机器人搭载的电机化激光雷达系统在高频振动下的校准难题。&lt;h4&gt;背景&lt;/h4&gt;传统的单个激光雷达系统受限于视野范围（FoV）较小的问题，在携带重量有限的移动平台上尤为明显。通过使用集成式可旋转激光雷达可以显著扩大其观测范围，但在四足机器人等动态平台上的应用面临由于高频率振动带来的校准问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需外部参考目标、仅依赖于原始激光雷达扫描几何特征的现场校准方法LiMo-Calib，以提高3D感知精度和效率。&lt;h4&gt;方法&lt;/h4&gt;通过利用点云数据中的正常分布优化特征选择过程，并引入重新加权机制来评估局部平面拟合质量，从而提升算法鲁棒性。同时在四足机器人上进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法LiMo-Calib显著提高了校准效率和3D感知准确性，在实际应用中表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法解决了现有校准方案的局限性，并证明了其适用于现实世界中的机器人应用。&lt;h4&gt;翻译&lt;/h4&gt;传统单一激光雷达系统由于视场范围（FoV）有限，导致盲点和环境认知不完整的问题尤为严重，尤其是在负载受限的移动平台上。将电机化激光雷达集成提供了一个实用解决方案，通过大幅扩展传感器的视野并实现适应性全景3D感知。然而，四足机器人上出现的高频振动带来了校准挑战，这种振动能改变激光雷达与电机间的转换关系从而影响感知准确性。现有依赖于人工目标或密集特征提取的传统校准方法在实地应用和实时处理中缺乏可行性。为解决这些局限，我们提出了一种名为LiMo-Calib的有效现场校准方法，它无需外部参考点即可通过直接从原始激光雷达扫描中获取几何特性实现高效校准。该算法通过基于正态分布的特征选择优化过程加快收敛速度的同时保持准确性，并引入重新加权机制评估局部平面拟合质量以提高鲁棒性。我们将此方法在四足机器人搭载的电机化激光雷达系统上进行集成和验证，证明了它显著提升了校准效率与3D感知精度，使之更适合实际中的机器人应用需求。相关演示视频可访问：https://youtu.be/FMINa-sap7g&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional single LiDAR systems are inherently constrained by their limitedfield of view (FoV), leading to blind spots and incomplete environmentalawareness, particularly on robotic platforms with strict payload limitations.Integrating a motorized LiDAR offers a practical solution by significantlyexpanding the sensor's FoV and enabling adaptive panoramic 3D sensing. However,the high-frequency vibrations of the quadruped robot introduce calibrationchallenges, causing variations in the LiDAR-motor transformation that degradesensing accuracy. Existing calibration methods that use artificial targets ordense feature extraction lack feasibility for on-site applications andreal-time implementation. To overcome these limitations, we propose LiMo-Calib,an efficient on-site calibration method that eliminates the need for externaltargets by leveraging geometric features directly from raw LiDAR scans.LiMo-Calib optimizes feature selection based on normal distribution toaccelerate convergence while maintaining accuracy and incorporates areweighting mechanism that evaluates local plane fitting quality to enhancerobustness. We integrate and validate the proposed method on a motorized LiDARsystem mounted on a quadruped robot, demonstrating significant improvements incalibration efficiency and 3D sensing accuracy, making LiMo-Calib well-suitedfor real-world robotic applications. The demo video is available at:https://youtu.be/FMINa-sap7g</description>
      <author>example@mail.com (Jianping Li, Zhongyuan Liu, Xinhang Xu, Jinxin Liu, Shenghai Yuan, Lihua Xie)</author>
      <guid isPermaLink="false">2502.12655v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning-based Dynamic Robot-to-Human Handover</title>
      <link>http://arxiv.org/abs/2502.12602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. For associated videos, see  https://zerotohero7886.github.io/dyn-r2h-handover&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的方法，用于动态的机器人向人类的手递送过程，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;当前大多数手递送方法假设接收者是静止的，而实际情况中的人类往往在移动。这种不匹配导致交互效率低下和用户体验不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种适应于动态环境下的机器人与人类之间的物体传递系统，以提高互动效率及舒适度。&lt;h4&gt;方法&lt;/h4&gt;使用非参数技术生成根据接收者动作连续调整的递送动作，并通过1000个真人之间手递送的数据集训练模型。引入了偏好学习和阻抗控制来优化性能并确保用户安全。&lt;h4&gt;主要发现&lt;/h4&gt;动态手递送比静态手递送在减少传递时间和提高用户体验方面有显著优势，这些优点已经在模拟环境以及实际测试中得到验证。&lt;h4&gt;结论&lt;/h4&gt;该研究为机器人与人类之间的更高效、舒适互动提供了可能的解决方案。视频演示和更多资料可在提供的网址上找到。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：本文提出了一种基于学习的方法用于动态的机器人向人类的手递送过程，解决了将物体传递给移动接收者时遇到的问题。假设在动态手递送中，当机器人根据接收者的动作做出调整时，相比静态手递送（即假定接收者是静止不动的），这样可以实现更高效和舒适的互动。为了验证这一点，我们开发了一种非参数方法来生成连续的手递送运动，这些运动基于接收者的动作，并使用了1000个真人之间手递送的数据集训练模型。我们还结合了偏好学习以提高手递送效果，并应用阻抗控制确保用户安全和适应性。该方案在模拟环境及真实场景中进行了评估，在用户研究中显示，动态手递送相比于静态方法大大减少了手递送时间并提高了用户的舒适度。我们的方法的视频演示和其他相关资料可在此网址上找到：https://zerotohero7886.github.io/dyn-r2h-handover 。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel learning-based approach to dynamic robot-to-humanhandover, addressing the challenges of delivering objects to a moving receiver.We hypothesize that dynamic handover, where the robot adjusts to the receiver'smovements, results in more efficient and comfortable interaction compared tostatic handover, where the receiver is assumed to be stationary. To validatethis, we developed a nonparametric method for generating continuous handovermotion, conditioned on the receiver's movements, and trained the model using adataset of 1,000 human-to-human handover demonstrations. We integratedpreference learning for improved handover effectiveness and applied impedancecontrol to ensure user safety and adaptiveness. The approach was evaluated inboth simulation and real-world settings, with user studies demonstrating thatdynamic handover significantly reduces handover time and improves user comfortcompared to static methods. Videos and demonstrations of our approach areavailable at https://zerotohero7886.github.io/dyn-r2h-handover .</description>
      <author>example@mail.com (Hyeonseong Kim, Chanwoo Kim, Matthew Pan, Kyungjae Lee, Sungjoon Choi)</author>
      <guid isPermaLink="false">2502.12602v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning a High-quality Robotic Wiping Policy Using Systematic Reward Analysis and Visual-Language Model Based Curriculum</title>
      <link>http://arxiv.org/abs/2502.12599v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度强化学习（Deep RL）的方法来解决自主机器人擦拭问题，并通过引入新的奖励机制和视觉-语言模型指导的学习过程来改善该方法。&lt;h4&gt;背景&lt;/h4&gt;自主机器人的擦拭任务在工业制造到医疗保健消毒等众多行业中都很重要。尽管深度强化学习表现出了极大的潜力，但是它往往需要大量的重复性奖励工程工作。&lt;h4&gt;目的&lt;/h4&gt;减少对人工调节的依赖，并提出一种新的有界奖励公式来提高问题可行性。&lt;h4&gt;方法&lt;/h4&gt;1. 分析质量关键性的机器人擦拭任务的收敛情况；2. 提出一个新的有界奖励公式；3. 引入视觉-语言模型（VLM）指导的学习过程，它能够主动监测进度并建议超参数调整。&lt;h4&gt;主要发现&lt;/h4&gt;结合上述方法可以在具有不同曲率、摩擦力和路径点的各种表面上找到合适的擦拭策略。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能有效解决高质量机器人擦拭任务的问题，并展示了一种新的深度强化学习应用途径。&lt;h4&gt;翻译&lt;/h4&gt;自主机器人的擦拭工作在各种行业中非常重要，从工业制造到医疗保健的消毒。尽管深度强化学习已经成为一个有前景的算法，但它经常面临着重复性奖励工程需求高的问题。为了减少对人工调整的依赖，我们首先分析了质量关键性的机器人擦拭任务（需要高质量的擦拭和快速的任务完成）的收敛情况，并指出该问题是难以收敛的，然后提出了一个新的有界奖励公式来解决这个问题。进一步地，通过提出一种新的视觉-语言模型（VLM）基于课程的学习方法，积极监测学习进度并建议超参数调整，从而改进了学习过程。我们证明结合这种新方法可以在具有各种曲率、摩擦力和路径点的表面上找到一个满意的擦拭策略，而基线公式则无法实现这一点。该项目演示可以在这里查看：https://sites.google.com/view/highqualitywiping&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robotic wiping is an important task in various industries, rangingfrom industrial manufacturing to sanitization in healthcare. Deep reinforcementlearning (Deep RL) has emerged as a promising algorithm, however, it oftensuffers from a high demand for repetitive reward engineering. Instead ofrelying on manual tuning, we first analyze the convergence of quality-criticalrobotic wiping, which requires both high-quality wiping and fast taskcompletion, to show the poor convergence of the problem and propose a newbounded reward formulation to make the problem feasible. Then, we furtherimprove the learning process by proposing a novel visual-language model (VLM)based curriculum, which actively monitors the progress and suggestshyperparameter tuning. We demonstrate that the combined method can find adesirable wiping policy on surfaces with various curvatures, frictions, andwaypoints, which cannot be learned with the baseline formulation. The demo ofthis project can be found at: https://sites.google.com/view/highqualitywiping.</description>
      <author>example@mail.com (Yihong Liu, Dongyeop Kang, Sehoon Ha)</author>
      <guid isPermaLink="false">2502.12599v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Design and Implementation of a Dual Uncrewed Surface Vessel Platform for Bathymetry Research under High-flow Conditions</title>
      <link>http://arxiv.org/abs/2502.12539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Corresponding author: Iman Soltani (isoltani@ucdavis.edu)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两个互补的无人水面船系统的设计与实现，旨在解决水下地形测量（测深学）中设备昂贵和操作风险高的问题。&lt;h4&gt;背景&lt;/h4&gt;测深学依赖于声纳技术对水下结构进行测绘。然而，现有的基于船只的操作方式成本高昂、存在人员安全威胁，并且在高流速条件下难以获得稳定的数据采集环境。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过设计并实现两个无人水面船系统来推进自主控制、导航和数据处理技术的研究，特别是针对测深学的应用。&lt;h4&gt;方法&lt;/h4&gt;提出了一个低成本的USV用于导航与控制研究（NAC-USV）和一个高端配置的USV配备高分辨率多波束声纳及后处理硬件（BEP-USV）。这两个系统可以分别用来测试自主避障、稳定性和数据评价技术，同时开放了设计源代码。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的实验验证，两个系统均展示了良好的性能，在多种操作环境中能够有效进行测深学研究，并且降低了设备和人员的风险。&lt;h4&gt;结论&lt;/h4&gt;本文提供的无人水面船平台为未来的测深学及相关领域提供了重要的工具和支持。这些系统的开放设计可以促进后续的研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文译文是：水下地形测量，即通过声纳测绘水下的地貌特征，通常是依赖于对淹没结构进行声纳扫描来完成的。这些数据对于基础设施健康监测至关重要，但通常需要昂贵的仪器设备支持。由于传感器损坏或船只损失导致的高昂财务风险使得无人水面船（USV）在执行测深任务时受到限制。然而，载人船队的水下地形测量操作成本高、人员安全风险大，并且经常无法达到采集高质量测深数据所需的稳定条件，尤其是在强水流条件下。因此，进一步的研究对于推进自主控制、导航和数据处理技术至关重要，特别是在测深领域的应用中更为重要。目前，缺乏能够同时支持测深领域自动控制和导航研究以及数据评估与后处理的可访问硬件平台。本文通过设计并实施两种互补的无人水面船系统来填补这一空白，一种是低成本USV用于导航与控制研究（NAC-USV），另一种则是配备了高分辨率多波束声纳及其相关硬件用于测深数据质量评估和后处理研究的高端USV（BEP-USV）。NAC-USV平台旨在促进自主、故障安全导航和控制的研究，强调了采集高质量测深数据所需的稳定性和减少设备风险。随后使用与NAC-USV硬件相似配置的BEP-USV进行额外的控制验证，并深入探讨水下地形数据评估和后处理的方法论。本文详细阐述了两个系统的设计实现过程并开源设计。此外，还展示了该系统的有效性在一系列操作场景中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bathymetry, the study of underwater topography, relies on sonar mapping ofsubmerged structures. These measurements, critical for infrastructure healthmonitoring, often require expensive instrumentation. The high financial riskassociated with sensor damage or vessel loss creates a reluctance to deployuncrewed surface vessels (USVs) for bathymetry. However, the crewed-boatbathymetry operations, are costly, pose hazards to personnel, and frequentlyfail to achieve the stable conditions necessary for bathymetry data collection,especially under high currents. Further research is essential to advanceautonomous control, navigation, and data processing technologies, with aparticular focus on bathymetry. There is a notable lack of accessible hardwareplatforms that allow for integrated research in both bathymetry-focusedautonomous control and navigation, as well as data evaluation and processing.This paper addresses this gap through the design and implementation of twocomplementary USV systems tailored for uncrewed bathymetry research. Thisincludes a low-cost USV for Navigation And Control research (NAC-USV) and asecond, high-end USV equipped with a high-resolution multi-beam sonar and theassociated hardware for Bathymetry data quality Evaluation and Post-processingresearch (BEP-USV). The NAC-USV facilitates the investigation of autonomous,fail-safe navigation and control, emphasizing the stability requirements forhigh-quality bathymetry data collection while minimizing the risk to equipment.The BEP-USV, which mirrors the NAC-USV hardware, is then used for additionalcontrol validation and in-depth exploration of bathymetry data evaluation andpost-processing methodologies. We detail the design and implementation of bothsystems, and open source the design. Furthermore, we demonstrate the system'seffectiveness in a range of operational scenarios.</description>
      <author>example@mail.com (Dinesh Kumar, Amin Ghorbanpour, Kin Yen, Iman Soltani)</author>
      <guid isPermaLink="false">2502.12539v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>GSCE: A Prompt Framework with Enhanced Reasoning for Reliable LLM-driven Drone Control</title>
      <link>http://arxiv.org/abs/2502.12531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种增强推理的提示框架GSCE，用于支持可靠的大规模语言模型驱动的无人机控制。&lt;h4&gt;背景&lt;/h4&gt;大规模语言模型（LLMs）在机器人控制中的集成有可能革新自主系统。研究证明了LLMs可以用来支持机器人的操作，但当面对复杂推理任务时，关于解决方案可靠性的担忧和挑战也随之而来。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强推理的提示框架GSCE，以实现可靠的LLM驱动无人机控制。&lt;h4&gt;方法&lt;/h4&gt;GSCE框架包括使用Guidelines（准则）、Skill APIs（技能API）、Constraints（约束）和Examples（示例）构建的新技术组件。该框架具有可靠且符合约束条件的代码生成特点。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，证明了GSCE可以显著提高不同复杂度任务的成功率和完整性，优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;GSCE展示出用于开发可靠的大规模语言模型驱动的自主无人机系统的潜力。&lt;h4&gt;翻译&lt;/h4&gt;将大型语言模型（LLMs）集成到机器人控制中，包括无人机，有可能革新自主系统。研究表明，可以利用LLMs支持机器人的操作，但当面临需要复杂推理的任务时，对LLM生成解决方案可靠性的担忧和挑战也随之产生。本文提出了一种增强推理的提示框架GSCE，以实现可靠的LLM驱动无人机控制。该框架由使用准则、技能APIs、约束条件和示例构建的新技术组件组成。通过广泛的实验测试了GSCE在不同复杂度任务中对无人机控制的效果，结果显示GSCE可以显著提高成功率和完整性，优于基线方法，展示了其开发可靠的大规模语言模型驱动的自主无人机系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of Large Language Models (LLMs) into robotic control,including drones, has the potential to revolutionize autonomous systems.Research studies have demonstrated that LLMs can be leveraged to supportrobotic operations. However, when facing tasks with complex reasoning, concernsand challenges are raised about the reliability of solutions produced by LLMs.In this paper, we propose a prompt framework with enhanced reasoning to enablereliable LLM-driven control for drones. Our framework consists of noveltechnical components designed using Guidelines, Skill APIs, Constraints, andExamples, namely GSCE. GSCE is featured by its reliable andconstraint-compliant code generation. We performed thorough experiments usingGSCE for the control of drones with a wide level of task complexities. Ourexperiment results demonstrate that GSCE can significantly improve task successrates and completeness compared to baseline approaches, highlighting itspotential for reliable LLM-driven autonomous drone systems.</description>
      <author>example@mail.com (Wenhao Wang, Yanyan Li, Long Jiao, Jiawei Yuan)</author>
      <guid isPermaLink="false">2502.12531v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Memory-updated-based Framework for 100% Reliable Flexible Flat Cables Insertion</title>
      <link>http://arxiv.org/abs/2502.12514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种模仿人类行为的新型框架，用于解决柔性扁平电缆（FFC）插入任务中的自动化挑战。&lt;h4&gt;背景&lt;/h4&gt;自动装配线已取代了许多手工劳动，但因反馈和动态操作需求高，FFC插入尚未实现自动化，影响了约11%的全球工业产能。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以精确感知、理解和控制FFC插入过程的框架，以提高插入的成功率并最终实现完全自动化的生产线。&lt;h4&gt;方法&lt;/h4&gt;该框架包括三个模块：感应模块用于收集三维力数据；感知模块将这些数据转换为有意义的物理信号；基于贝叶斯理论的记忆模块用于可靠性估计和控制。&lt;h4&gt;主要发现&lt;/h4&gt;使用此框架的机器人可以检测到0.5毫米的对准误差，并在几次迭代后达到100%的成功率，展示了可靠感知和复杂插入任务中精准控制的能力。&lt;h4&gt;结论&lt;/h4&gt;该工作解决了不稳定的感知和控制问题，为全自动生产线的发展指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic assembly lines have increasingly replaced human labor in varioustasks; however, the automation of Flexible Flat Cable (FFC) insertion remainsunrealized due to its high requirement for effective feedback and dynamicoperation, limiting approximately 11% of global industrial capacity. Despitelots of approaches, like vision-based tactile sensors and reinforcementlearning, having been proposed, the implementation of human-like high-reliableinsertion (i.e., with a 100% success rate in completed insertion) remains a bigchallenge. Drawing inspiration from human behavior in FFC insertion, whichinvolves sensing three-dimensional forces, translating them into physicalconcepts, and continuously improving estimates, we propose a novel framework.This framework includes a sensing module for collecting three-dimensionaltactile data, a perception module for interpreting this data into meaningfulphysical signals, and a memory module based on Bayesian theory for reliabilityestimation and control. This strategy enables the robot to accurately assessits physical state and generate reliable status estimations and correctiveactions. Experimental results demonstrate that the robot using this frameworkcan detect alignment errors of 0.5 mm with an accuracy of 97.92% and thenachieve a 100% success rate in all completed tests after a few iterations. Thiswork addresses the challenges of unreliable perception and control in complexinsertion tasks, highlighting the path toward the development of fullyautomated production lines.</description>
      <author>example@mail.com (Zhengrong Ling, Xiong Yang, Dong Guo, Hongyuan Chang, Tieshan Zhang, Ruijia Zhang, Yajing Shen)</author>
      <guid isPermaLink="false">2502.12514v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Predicate Hierarchies Improve Few-Shot State Classification</title>
      <link>http://arxiv.org/abs/2502.12481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025. First two authors contributed equally. Project page:  https://emilyzjin.github.io/projects/phier.html&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '介绍了一种名为PHIER的模型，该模型通过利用谓词层次结构，在少样本场景下有效推广，并在CALVIN和BEHAVIOR机器人环境中表现出色。', '背景': '对象状态分类及其关系对于许多长期任务至关重要，尤其是在机器人规划和操作中。但是，可能的对象-谓词组合的数量呈指数增长，加上适应新现实环境的需求，使得模型需要能够用少量示例推广到新的查询上。', '目的': '提出了一种名为PHIER的模型，该模型利用谓词层次结构来在少样本场景下有效地推广。', '方法': 'PHIER使用以对象为中心的场景编码器、自监督损失函数（用于推断谓词之间的语义关系）和双曲距离度量（捕捉层级结构），学习图像-谓词对的有结构的潜在空间，从而指导状态分类查询上的推理。', '主要发现': '在少样本、分布外的状态分类任务中显著优于现有方法，并展示了从模拟到真实世界任务的零样本和少量样本推广的强大能力。', '结论': '利用谓词层次结构可以改善在数据有限的情况下进行状态分类任务的表现。'}&lt;h4&gt;翻译&lt;/h4&gt;状态分类是许多长期任务的核心，尤其是在机器人规划和操作中。但是，对象-谓词组合的数量爆炸加上适应新现实环境的需求使得模型需要能够用少量示例推广到新的查询上。为此，我们提出了一种名为PHIER的模型，该模型利用谓词层次结构来在少样本场景下有效地推广。PHIER使用以对象为中心的场景编码器、自监督损失函数和双曲距离度量，捕捉层级结构；它学习图像-谓词对的有结构的潜在空间，从而指导状态分类查询上的推理。我们在CALVIN和BEHAVIOR机器人环境中评估了PHIER，并展示了该模型在少样本、分布外的状态分类中显著优于现有方法，并展示了从模拟到真实世界任务的强大零样本和少量样本推广能力。我们的结果表明，在数据有限的情况下利用谓词层次结构可以改善状态分类任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State classification of objects and their relations is core to manylong-horizon tasks, particularly in robot planning and manipulation. However,the combinatorial explosion of possible object-predicate combinations, coupledwith the need to adapt to novel real-world environments, makes it a desideratumfor state classification models to generalize to novel queries with fewexamples. To this end, we propose PHIER, which leverages predicate hierarchiesto generalize effectively in few-shot scenarios. PHIER uses an object-centricscene encoder, self-supervised losses that infer semantic relations betweenpredicates, and a hyperbolic distance metric that captures hierarchicalstructure; it learns a structured latent space of image-predicate pairs thatguides reasoning over state classification queries. We evaluate PHIER in theCALVIN and BEHAVIOR robotic environments and show that PHIER significantlyoutperforms existing methods in few-shot, out-of-distribution stateclassification, and demonstrates strong zero- and few-shot generalization fromsimulated to real-world tasks. Our results demonstrate that leveragingpredicate hierarchies improves performance on state classification tasks withlimited data.</description>
      <author>example@mail.com (Emily Jin, Joy Hsu, Jiajun Wu)</author>
      <guid isPermaLink="false">2502.12481v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>RTPD: Penetration Depth calculation using Hardware accelerated Ray-Tracing</title>
      <link>http://arxiv.org/abs/2502.12463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures, under review for a journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的利用RT-cores计算穿透深度的算法，该算法在不同类型和代次的RTX GPU上进行了测试，并显示出优于现有技术和传统GPU实现的巨大性能优势。&lt;h4&gt;背景&lt;/h4&gt;穿透深度计算对于模拟、元宇宙及机器人等领域至关重要。为了加速此计算过程，人们已经尝试使用并行计算资源如CPU和GPU来优化性能。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的基于RT-cores的算法用于提高穿透深度计算效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型算法，包括基于光线追踪技术提取穿透表面的方法以及计算Hausdorff距离的方法，旨在充分利用现代GPU中的RT-cores进行高效处理。&lt;h4&gt;主要发现&lt;/h4&gt;在不同代次和类型的RTX GPU上测试了所提出的算法，并且结果表明该方法相比最先进的穿透深度计算技术和传统的GPU实现分别快37.66倍和5.33倍。&lt;h4&gt;结论&lt;/h4&gt;研究表明基于RT-cores的方法非常高效，这暗示了RT-cores在广泛的计算任务中具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已经完成并以JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Penetration depth calculation quantifies the extent of overlap between twoobjects and is crucial in fields like simulations, the metaverse, and robotics.Recognizing its significance, efforts have been made to accelerate thiscomputation using parallel computing resources, such as CPUs and GPUs. Unliketraditional GPU cores, modern GPUs incorporate specialized ray-tracing cores(RT-cores) primarily used for rendering applications. We introduce a novelalgorithm for penetration depth calculation that leverages RT-cores. Ourapproach includes a ray-tracing based algorithm for penetration surfaceextraction and another for calculating Hausdorff distance, optimizing the useof RT-cores. We tested our method across various generations of RTX GPUs withdifferent benchmark scenes. The results demonstrated that our algorithmoutperformed a state-of-the-art penetration depth calculation method andconventional GPU implementations by up to 37.66 and 5.33 times, respectively.These findings demonstrate the efficiency of our RT core-based method andsuggest broad applicability for RT-cores in diverse computational tasks.</description>
      <author>example@mail.com (YoungWoo Kim, Sungmin Kwon, Duksu Kim)</author>
      <guid isPermaLink="false">2502.12463v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Multi-vision-based Picking Point Localisation of Target Fruit for Harvesting Robots</title>
      <link>http://arxiv.org/abs/2502.12406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于收获机器人的多视觉定位策略，旨在提高水果采摘的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确识别采收点对于机械采摘至关重要，因为不稳定的抓取可能导致经济损失和果实损坏。&lt;h4&gt;目的&lt;/h4&gt;研究提出并评估了两种基于多视觉的方法：解析法和模型驱动算法，以确定水果的实际几何中心。&lt;h4&gt;方法&lt;/h4&gt;{'数据收集': '使用动作捕捉系统（mocap）收集实际的水果几何中心点，并通过两个RGB-D相机提取不同的表面点Cfix和Ceih。', '检测技术': '首先用解析法探测目标水果的采收点，然后利用各种初级学习和集成学习方法预测水果的几何中心。', '算法比较': '对Adaboost回归等模型驱动定位算法进行了评估，并与单相机系统进行对比。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'效果对比': '多视觉系统的性能优于单摄像头系统，其中最成功的模型基于Adaboost回归方法，收获准确率为88.8%，平均欧氏距离（MED）为4.40mm。', '传统方法表现': '解析法的采摘成功率较低，为81.4%，MED为14.25mm。单相机系统的性能最差，采摘成功率为77.7%，MED为24.02mm。', '实验验证': '通过一系列机器人收获试验验证了多视觉系统对提高采收点定位准确性的重要作用，并展示了更高的采摘成功率'}&lt;h4&gt;结论&lt;/h4&gt;研究表明，基于多视觉的定位策略可以显著改善机械收割中的水果识别和采摘精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents multi-vision-based localisation strategies for harvestingrobots. Identifying picking points accurately is essential for roboticharvesting because insecure grasping can lead to economic loss through fruitdamage and dropping. In this study, two multi-vision-based localisationmethods, namely the analytical approach and model-based algorithms, wereemployed. The actual geometric centre points of fruits were collected using amotion capture system (mocap), and two different surface points Cfix and Ceihwere extracted using two Red-Green-Blue-Depth (RGB-D) cameras. First, thepicking points of the target fruit were detected using analytical methods.Second, various primary and ensemble learning methods were employed to predictthe geometric centre of target fruits by taking surface points as input.Adaboost regression, the most successful model-based localisation algorithm,achieved 88.8% harvesting accuracy with a Mean Euclidean Distance (MED) of 4.40mm, while the analytical approach reached 81.4% picking success with a MED of14.25 mm, both demonstrating better performance than the single-camera, whichhad a picking success rate of 77.7% with a MED of 24.02 mm. To evaluate theeffect of picking point accuracy in collecting fruits, a series of roboticharvesting experiments were performed utilising a collaborative robot (cobot).It is shown that multi-vision systems can improve picking point localisation,resulting in higher success rates of picking in robotic harvesting.</description>
      <author>example@mail.com (C. Beldek, A. Dunn, J. Cunningham, E. Sariyildiz, S. L. Phung, G. Alici)</author>
      <guid isPermaLink="false">2502.12406v1</guid>
      <pubDate>Wed, 19 Feb 2025 17:40:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization</title>
      <link>http://arxiv.org/abs/2501.14635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Wasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) 算法，该算法能够在$m$点网格上计算离散概率分布的精确barycenter。&lt;h4&gt;背景&lt;/h4&gt;最优传输重心（即Wasserstein barycenter）是欧氏空间到概率分布Wasserstein空间中平均的概念扩展。对于在$d&gt;1$维域上的点云上离散的概率分布，求解未正则化的barycenter是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的计算精确barycenter的方法，该方法基于$m$-点网格的输入概率密度函数，并且不依赖于传统的熵正则化技术。&lt;h4&gt;方法&lt;/h4&gt;提出了一个近似线性时间复杂度为$O(m \log{m})$和线性空间复杂度为$O(m)$的WDHA算法，该算法通过交替优化Wasserstein和Sobolev几何结构来求解原始barycenter问题及其对偶Kantorovich势能子问题。&lt;h4&gt;主要发现&lt;/h4&gt;证明了在适当选择步长的情况下，WDHA算法的收敛速率及迭代复杂度，并且实验结果表明相比于现有的Sinkhorn类算法，该方法具有更优的计算效率、可扩展性和准确性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个高效精确求解Wasserstein barycenter问题的新算法，为处理高分辨率二维合成和实际数据提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;最优传输重心（又称为Wasserstein重心）是将平均概念从欧氏空间扩展到概率分布的Wasserstein空间中的基本概念。计算离散在点云上的概率分布的无正则化的barycenter，当领域维度$d &gt; 1$时是一个具有挑战性的任务。大多数用于近似解barycenter问题的实际算法都是基于熵正则化技术的。本文引入了一种几乎线性时间复杂度为$O(m \log{m})$和线性空间复杂度为$O(m)$的原始-对偶算法WDHA（Wasserstein下降$\dot{\mathbb{H}}^1$上升）用于在$m$点网格上计算输入概率密度函数离散化时的确切barycenter。WDHA算法成功的关键在于交替使用两种不同的但密切相关于Wasserstein和Sobolev优化几何的原始barycenter问题及其对偶Kantorovich势能子问题。在合理的假设下，我们建立了当步长适当选择时的WDHA收敛速率与迭代复杂度，并通过高分辨率（例如$1024 \times 1024$图像）二维合成和真实数据证明了其相比现有Sinkhorn型算法具有更优的计算效率、可扩展性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimal transport barycenter (a.k.a. Wasserstein barycenter) is afundamental notion of averaging that extends from the Euclidean space to theWasserstein space of probability distributions. Computation of theunregularized barycenter for discretized probability distributions on pointclouds is a challenging task when the domain dimension $d &gt; 1$. Most practicalalgorithms for approximating the barycenter problem are based on entropicregularization. In this paper, we introduce a nearly linear time $O(m \log{m})$and linear space complexity $O(m)$ primal-dual algorithm, theWasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) algorithm, for computingthe exact barycenter when the input probability density functions arediscretized on an $m$-point grid. The key success of the WDHA algorithm hingeson alternating between two different yet closely related Wasserstein andSobolev optimization geometries for the primal barycenter and dual Kantorovichpotential subproblems. Under reasonable assumptions, we establish theconvergence rate and iteration complexity of WDHA to its stationary point whenthe step size is appropriately chosen. Superior computational efficacy,scalability, and accuracy over the existing Sinkhorn-type algorithms aredemonstrated on high-resolution (e.g., $1024 \times 1024$ images) 2D syntheticand real data.</description>
      <author>example@mail.com (Kaheon Kim, Rentian Yao, Changbo Zhu, Xiaohui Chen)</author>
      <guid isPermaLink="false">2501.14635v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
  <item>
      <title>Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency</title>
      <link>http://arxiv.org/abs/2502.05028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种新的算法（MA-OSMA）以及其改进版（MA-OSEA），旨在解决多代理系统在不确定环境中的子模函数最大化问题，这些问题是机器学习、机器人规划和控制等领域的关键挑战。&lt;h4&gt;背景&lt;/h4&gt;现有方法如OSG算法的近似保证较差且要求完全连接的通信图，在实际应用中存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法框架（MA-OSMA），通过多线性扩展将离散问题转化为连续优化，减少对完全网络的要求；同时引入避免次优解的新颖梯度方法，并进一步开发了无需投影操作的变种算法（MA-OSEA）以提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;- MA-OSMA算法：使用多线性扩展和共识技术来降低通信图完整性的要求，利用新提出的代理梯度避开次优稳定点；- MA-OSEA算法：通过混合均匀分布有效利用KL散度，减少计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明两种算法均能达到$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-eta}})$的遗憾界限，并且对子模目标函数提供了一个显著改善的近似比$(\frac{1-e^{-c}}{c})$，优于现有方法（OSG算法）提供的$(\frac{1}{1+c})$。&lt;h4&gt;结论&lt;/h4&gt;通过基于模拟的多目标跟踪实验验证了提出的MA-OSMA和MA-OSEA算法的有效性，在不确定性环境中协调多个代理协同最大化子模函数方面取得了进展。&lt;h4&gt;翻译&lt;/h4&gt;协调多个代理在不可预测环境下协作最大化子模函数是一个充满应用前景的重要任务，特别是在机器学习、机器人规划和控制领域。现有的解决方案（如OSG算法）因为近似保证不足及需要完全连通的通信图而受到限制。为解决这些问题，我们首先提出了一种MA-OSMA算法，它使用多线性扩展将离散子模最大化问题转换为连续优化问题，并通过共识技术减少了对完整图形结构的依赖要求。此外，MA-OSMA算法利用一种新颖的代理梯度方法来避免陷入次优解点。为了减少MA-OSMA中的计算密集型投影操作，我们还引入了一种无需投影的操作（MA-OSEA）算法，该算法通过混合均匀分布有效使用KL散度。理论上，我们证明了这两个算法在与最优后见比较器的$(\frac{1-e^{-c}}{c})$近似值时能够实现遗憾界限为$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-eta}})$的效果，其中$C_{T}$是最大化序列偏差、$\beta$是网络的谱隙以及$c$是子模目标函数的联合曲率。这一结果显著提升了现有最佳OSG算法提供的$(\frac{1}{1+c})$近似比。最后，我们通过基于模拟的多目标跟踪实验展示了所提出算法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coordinating multiple agents to collaboratively maximize submodular functionsin unpredictable environments is a critical task with numerous applications inmachine learning, robot planning and control. The existing approaches, such asthe OSG algorithm, are often hindered by their poor approximation guaranteesand the rigid requirement for a fully connected communication graph. To addressthese challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, whichemploys the multi-linear extension to transfer the discrete submodularmaximization problem into a continuous optimization, thereby allowing us toreduce the strict dependence on a complete graph through consensus techniques.Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoidsub-optimal stationary points. To eliminate the computationally intensiveprojection operations in $\textbf{MA-OSMA}$, we also introduce aprojection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KLdivergence by mixing a uniform distribution. Theoretically, we confirm thatboth algorithms achieve a regret bound of$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against a$(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where$C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap ofthe network and $c$ is the joint curvature of submodular objectives. Thisresult significantly improves the $(\frac{1}{1+c})$-approximation provided bythe state-of-the-art OSG algorithm. Finally, we demonstrate the effectivenessof our proposed algorithms through simulation-based multi-target tracking.</description>
      <author>example@mail.com (Qixin Zhang, Zongqi Wan, Yu Yang, Li Shen, Dacheng Tao)</author>
      <guid isPermaLink="false">2502.05028v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities</title>
      <link>http://arxiv.org/abs/2502.12128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://ml-jku.github.io/LaM-SLidE/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的生成模型LaM-SLidE，用于时空动力系统的轨迹采样。&lt;h4&gt;背景&lt;/h4&gt;生成模型在深度学习领域取得了显著进展，并显示出对动态系统轨迹采样的强大潜力。然而，与图像和视频生成相比，在大多数动态系统中应用潜在空间建模方法更为困难。&lt;h4&gt;目的&lt;/h4&gt;通过引入标识表示（IDs），使从潜在系统表示检索实体属性成为可能，从而实现追溯性，并结合图神经网络的优势以及最近在图像和视频生成中的效率和可扩展性，提高动力系统的轨迹采样性能。&lt;h4&gt;方法&lt;/h4&gt;LaM-SLidE方法结合了图神经网络的时效性和跟踪能力，与目前用于图像和视频生成模型中预训练编码器和解码器冻结后的潜在空间建模技术的高效性和可伸缩性。它引入标识表示（IDs）以允许从潜在系统表示检索实体属性，从而增强时间追踪。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在不同领域，LaM-SLidE在速度、准确度和泛化能力方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了通过将图神经网络的时效性和跟踪优势与图像及视频生成模型中潜在空间建模技术结合在一起可以提高动力系统的轨迹采样性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models are spearheading recent progress in deep learning, showingstrong promise for trajectory sampling in dynamical systems as well. However,while latent space modeling paradigms have transformed image and videogeneration, similar approaches are more difficult for most dynamical systems.Such systems -- from chemical molecule structures to collective human behavior-- are described by interactions of entities, making them inherently linked toconnectivity patterns and the traceability of entities over time. Our approach,LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via LinkedEntities), combines the advantages of graph neural networks, i.e., thetraceability of entities across time-steps, with the efficiency and scalabilityof recent advances in image and video generation, where pre-trained encoder anddecoder are frozen to enable generative modeling in the latent space. The coreidea of LaM-SLidE is to introduce identifier representations (IDs) to allow forretrieval of entity properties, e.g., entity coordinates, from latent systemrepresentations and thus enables traceability. Experimentally, across differentdomains, we show that LaM-SLidE performs favorably in terms of speed, accuracy,and generalizability. (Code is available athttps://github.com/ml-jku/LaM-SLidE)</description>
      <author>example@mail.com (Florian Sestak, Artur Toshev, Andreas Fürst, Günter Klambauer, Andreas Mayr, Johannes Brandstetter)</author>
      <guid isPermaLink="false">2502.12128v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>PreAdaptFWI: Pretrained-Based Adaptive Residual Learning for Full-Waveform Inversion Without Dataset Dependency</title>
      <link>http://arxiv.org/abs/2502.11913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合神经网络和全波形反演（FWI）的简单而有效的训练框架，该框架通过适配残差学习模块避免局部最优解。&lt;h4&gt;背景&lt;/h4&gt;全波形反演方法利用地震数据来最小化模拟波形与观测波形之间的差异，以反转地下介质的物理参数。然而由于其固有的病态性，FWI容易陷入局部极小值。&lt;h4&gt;目的&lt;/h4&gt;通过引入神经网络和残差学习模块改进FWI过程稳定性，并减少对特定数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一个独立于数据集依赖性的训练框架，在预训练阶段只需要在一个简单的初始模型上进行适度训练，随后在迁移学习阶段通过传统FWI梯度同时更新神经网络和残差学习模块。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能有效地将物理先验知识转化为地层分布的全局表示，并捕捉到相邻层速度变化的细微差异，从而避免局部最优解。实验表明，在不同条件下的两个基准模型上应用此方法均表现出色。&lt;h4&gt;结论&lt;/h4&gt;提出的算法在各种条件下均优于传统FWI及其他相关技术，能够更准确有效地进行全波形反演。&lt;h4&gt;翻译&lt;/h4&gt;摘要：全波形反演（FWI）是一种利用地震数据来反转地下介质物理参数的方法，通过最小化模拟和观测波形之间的差异。由于其病态性质，FWI容易陷入局部极小值。因此，各种研究尝试将神经网络与FWI结合以稳定反演过程。本文提出了一种简单且有效的训练框架，该框架独立于数据集依赖性，并仅需对一个简单的初始模型进行适度预训练即可稳定网络输出。在迁移学习阶段，传统的FWI梯度同时更新了神经网络和提出的自适应残差学习模块，后者学习的是网络输出中大规模分布特征的残差映射，而不是直接拟合目标映射。通过这种协同训练范式，所提算法将物理先验知识有效转化为地层分布的全局表示，并捕捉到相邻层速度变化中的局部细节差异，从而避免了局部极小值。在两个基准模型的各种条件下评估该方法，包括缺乏低频数据、噪声干扰和不同初始模型的情况下，以及相应的消融实验中，一致证明了所提方法的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-waveform inversion (FWI) is a method that utilizes seismic data toinvert the physical parameters of subsurface media by minimizing the differencebetween simulated and observed waveforms. Due to its ill-posed nature, FWI issusceptible to getting trapped in local minima. Consequently, various researchefforts have attempted to combine neural networks with FWI to stabilize theinversion process. This study presents a simple yet effective trainingframework that is independent of dataset reliance and requires only moderatepre-training on a simple initial model to stabilize network outputs. During thetransfer learning phase, the conventional FWI gradients will simultaneouslyupdate both the neural network and the proposed adaptive residual learningmodule, which learns the residual mapping of large-scale distribution featuresin the network's output, rather than directly fitting the target mapping.Through this synergistic training paradigm, the proposed algorithm effectivelyinfers the physically-informed prior knowledge into a global representation ofstratigraphic distribution, as well as capturing subtle variations ininter-layer velocities within local details, thereby escaping local optima.Evaluating the method on two benchmark models under various conditions,including absent low-frequency data, noise interference, and differing initialmodels, along with corresponding ablation experiments, consistentlydemonstrates the superiority of the proposed approach.</description>
      <author>example@mail.com (Xintong Dong, Zhengyi Yuan, Jun Lin, Shiqi Dong, Xunqian Tong, Yue Li)</author>
      <guid isPermaLink="false">2502.11913v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling the Power of Complex-Valued Transformers in Wireless Communications</title>
      <link>http://arxiv.org/abs/2502.11151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE for possible publications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了复值神经网络（CVNN）在无线通信中的应用，并提出了适用于该领域的复杂值转换器模型。&lt;h4&gt;背景&lt;/h4&gt;利用复数信号的自然表示，复值神经网络在处理无线通信任务中显示出优越性。然而，现有的研究大多集中在简单的复数版本的神经网络架构上，对现代深度学习技术的应用理解不足。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补复数神经网络在理论和实践上的空白，并提出一种用于无线通信的基本复杂值转换器范式。&lt;h4&gt;方法&lt;/h4&gt;详细描述了CVNN中的各种操作，并通过实验验证了CVNN相较于实数值网络所需的层数更少。此外，针对无线通信的三个代表性应用（信道估计、用户活动检测和预编码设计），开发了定制化的复数变换模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在这三个应用场景中，复杂值转换器的表现优于传统的实数值神经网络方法。&lt;h4&gt;结论&lt;/h4&gt;通过理论分析和实际验证，本文证明了CVNN在无线通信领域的优越性，并为未来的深度学习研究提供了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing complex-valued neural networks (CVNNs) in wireless communicationtasks has received growing attention for their ability to provide natural andeffective representation of complex-valued signals and data. However, existingstudies typically employ complex-valued versions of simple neural networkarchitectures. Not only they merely scratch the surface of the extensive rangeof modern deep learning techniques, theoretical understanding of the superiorperformance of CVNNs is missing. To this end, this paper aims to fill both thetheoretical and practice gap of employing CVNNs in wireless communications. Inparticular, we provide a comprehensive description on the various operations inCVNNs and theoretically prove that the CVNN requires fewer layers than thereal-valued counterpart to achieve a given approximation error of a continuousfunction. Furthermore, to advance CVNNs in the field of wirelesscommunications, this paper focuses on the transformer model, which represents amore sophisticated deep learning architecture and has been shown to haveexcellent performance in wireless communications but only in its real-valuedform. In this aspect, we propose a fundamental paradigm of complex-valuedtransformers for wireless communications. Leveraging this structure, we developcustomized complex-valued transformers for three representative applications inwireless communications: channel estimation, user activity detection, andprecoding design. These applications utilize transformers with varying levelsof sophistication and span a variety of tasks, ranging from regression toclassification, supervised to unsupervised learning, and specific module designto end-to-end design. Experimental results demonstrate the superior performanceof the complex-valued transformers for the above three applications compared toother traditional real-valued neural network-based methods.</description>
      <author>example@mail.com (Yang Leng, Qingfeng Lin, Long-Yin Yung, Jingreng Lei, Yang Li, Yik-Chung Wu)</author>
      <guid isPermaLink="false">2502.11151v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2502.11824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了面向多语言的方面基础情感分析（ABSA）任务，特别是M-ABSA数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的ABSA数据集主要以英语为中心，限制了多语种研究和评估的可能性。&lt;h4&gt;目的&lt;/h4&gt;创建一个涵盖7个领域及21种语言的数据集M-ABSA，以填补现有研究的空白。&lt;h4&gt;方法&lt;/h4&gt;通过自动翻译并结合人工审核的方式构建数据集，侧重于三元组抽取（包括方面术语、类别以及情感极性）。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该数据集适用于多语种和跨领域迁移学习，并且能够评估大规模语言模型的性能。&lt;h4&gt;结论&lt;/h4&gt;M-ABSA数据集因其广泛的覆盖范围和高质量的数据，有望推动多语言ABSA研究的发展。&lt;h4&gt;翻译&lt;/h4&gt;通过自动翻译结合人工审核的过程构建了一个包含7个领域21种语言的大规模平行语料库，为跨语言的情感分析提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aspect-based sentiment analysis (ABSA) is a crucial task in informationextraction and sentiment analysis, aiming to identify aspects with associatedsentiment elements in text. However, existing ABSA datasets are predominantlyEnglish-centric, limiting the scope for multilingual evaluation and research.To bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7domains and 21 languages, making it the most extensive multilingual paralleldataset for ABSA to date. Our primary focus is on triplet extraction, whichinvolves identifying aspect terms, aspect categories, and sentiment polarities.The dataset is constructed through an automatic translation process with humanreview to ensure quality. We perform extensive experiments using variousbaselines to assess performance and compatibility on M-ABSA. Our empiricalfindings highlight that the dataset enables diverse evaluation tasks, such asmultilingual and multi-domain transfer learning, and large language modelevaluation, underscoring its inclusivity and its potential to driveadvancements in multilingual ABSA research.</description>
      <author>example@mail.com (Chengyan Wu, Bolei Ma, Yihong Liu, Zheyu Zhang, Ningyuan Deng, Yanshu Li, Baolan Chen, Yi Zhang, Barbara Plank, Yun Xue)</author>
      <guid isPermaLink="false">2502.11824v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>Data assimilation performed with robust shape registration and graph neural networks: application to aortic coarctation</title>
      <link>http://arxiv.org/abs/2502.12097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于图像的、特定于患者的血流动力学建模可以提高诊断能力并提供互补见解，有助于更好地理解治疗结果。然而，在临床环境中计算流体动力学模拟仍然相对昂贵。&lt;h4&gt;目的&lt;/h4&gt;探索一种解决方案：形状配准技术，即从一系列可用几何形状中设计一个参考模板几何，并将其通过微分同胚映射到每个个体上，以减少解算器的复杂度并提高机器学习架构的效果。&lt;h4&gt;方法&lt;/h4&gt;比较了最新的图神经网络模型和数据同化策略，在主动脉狭窄背景下用于预测物理量和临床相关生物标志物的表现。&lt;h4&gt;主要发现&lt;/h4&gt;形状配准技术提供了一种自然编码，这种编码可以被机器学习架构利用，并且同时提供了参考计算域，在此域内可以执行高效的维数减少策略。这种方法在处理解剖结构形状的高度变化时具有优势。&lt;h4&gt;结论&lt;/h4&gt;本文的方法和策略为基于图像的、患者特异性血流动力学建模提供了一种有效的途径，有助于提高临床诊断能力和治疗结果理解。&lt;h4&gt;翻译&lt;/h4&gt;图片为基础的，以病人为中心的心血管血液动力模型可以增强诊断效果，并提供补充信息来更好地了解治疗结果。尽管计算流体动力模拟在临床上仍较为昂贵，形状配准技术（将参考模板几何从一系列可用几何中设计并映射到每个个体）为解决这个问题提供了可能的解决方案。研究比较了图神经网络和数据同化策略，在主动脉狭窄背景下用于预测物理量和临床相关生物标志物的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based, patient-specific modelling of hemodynamics can improvediagnostic capabilities and provide complementary insights to better understandthe hemodynamic treatment outcomes. However, computational fluid dynamicssimulations remain relatively costly in a clinical context. Moreover,projection-based reduced-order models and purely data-driven surrogate modelsstruggle due to the high variability of anatomical shapes in a population. Apossible solution is shape registration: a reference template geometry isdesigned from a cohort of available geometries, which can then bediffeomorphically mapped onto it. This provides a natural encoding that can beexploited by machine learning architectures and, at the same time, a referencecomputational domain in which efficient dimension-reduction strategies can beperformed. We compare state-of-the-art graph neural network models with recentdata assimilation strategies for the prediction of physical quantities andclinically relevant biomarkers in the context of aortic coarctation.</description>
      <author>example@mail.com (Francesco Romor, Felipe Galarce, Jan Brüning, Leonid Goubergrits, Alfonso Caiazzo)</author>
      <guid isPermaLink="false">2502.12097v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:55 +0800</pubDate>
    </item>
    <item>
      <title>UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs</title>
      <link>http://arxiv.org/abs/2502.11519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于建模意见演化的框架UniGO，该框架利用统一的意见动力学模型生成合成数据集，并通过图神经网络有效模拟了意见动态过程。&lt;h4&gt;背景&lt;/h4&gt;社交媒体中的极化和碎片化加剧了用户的偏见，理解意见演变变得越来越重要。虽然意见动力学为研究意见演变提供了可解释性，但将其见解融入预测模型仍具挑战。&lt;h4&gt;目的&lt;/h4&gt;构建统一的意见动力学模型来整合不同的意见融合规则，并生成相应的合成数据集；引入UniGO框架以建模图上的意见演化。&lt;h4&gt;方法&lt;/h4&gt;使用统一意见动态机制生成合成数据集并预训练模型。通过精细-粗糙化机制和图神经网络，有效模拟复杂的意见演进过程，并避免过平滑问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，UniGO在捕捉复杂的意见形成过程以及预测未来演变方面非常有效；使用合成数据预先训练的模型展示了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一种基于统一意见动力学的新框架，通过生成性地处理合成数据集来增强真实世界应用中的表现，并验证了这种方法的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何构建一个能够整合多种意见融合规则的统一模型，并提出了UniGO框架。该框架利用图神经网络有效模拟复杂的意见动态过程，并展示了在合成和实际数据上的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714636&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Polarization and fragmentation in social media amplify user biases, making itincreasingly important to understand the evolution of opinions. Opiniondynamics provide interpretability for studying opinion evolution, yetincorporating these insights into predictive models remains challenging. Thischallenge arises due to the inherent complexity of the diversity of opinionfusion rules and the difficulty in capturing equilibrium states while avoidingover-smoothing. This paper constructs a unified opinion dynamics model tointegrate different opinion fusion rules and generates corresponding syntheticdatasets. To fully leverage the advantages of unified opinion dynamics, weintroduces UniGO, a framework for modeling opinion evolution on graphs. Using acoarsen-refine mechanism, UniGO efficiently models opinion dynamics through agraph neural network, mitigating over-smoothing while preserving equilibriumphenomena. UniGO leverages pretraining on synthetic datasets, which enhancesits ability to generalize to real-world scenarios, providing a viable paradigmfor applications of opinion dynamics. Experimental results on both syntheticand real-world datasets demonstrate UniGO's effectiveness in capturing complexopinion formation processes and predicting future evolution. The pretrainedmodel also shows strong generalization capability, validating the benefits ofusing synthetic data to boost real-world performance.</description>
      <author>example@mail.com (Hao Li, Hao Jiang, Yuke Zheng, Hao Sun, Wenying Gong)</author>
      <guid isPermaLink="false">2502.11519v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy</title>
      <link>http://arxiv.org/abs/2502.10704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  [ICLR 2025] Project and code at: https://github.com/zikai1/OAReg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的无监督点云非刚性对齐方法——Occlusion-Aware Registration (OAR)，该方法利用自适应相关熵函数作为局部相似度测量，解决了现有技术在处理遮挡场景时的挑战。&lt;h4&gt;背景&lt;/h4&gt;点云的非刚性对准对于场景理解和重建以及计算机视觉和机器人任务至关重要。最新的隐式变形网络的发展大大减少了对大量标记训练数据的需求，但仍然面临处理遮挡情况的困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督方法来改进现有技术在处理点云遮挡问题时的表现。&lt;h4&gt;方法&lt;/h4&gt;利用自适应相关熵函数作为局部相似度测量，并结合非刚性隐式神经表示和最大相关熵准则优化未被遮挡区域的变形，同时引入局部线性重构以确保缺乏对应关系的区域经历物理上合理的形变。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在处理带有遮挡的几何结构时优于或与现有方法竞争，并展示了其在大规模形变、形状插值和存在遮挡干扰下的形状补全等挑战任务中的灵活性。同时，该方法理论上将最大相关熵准则与常用的查默斯距离建立了联系。&lt;h4&gt;结论&lt;/h4&gt;Occlusion-Aware Registration (OAR) 方法通过创新性地利用自适应相关熵函数解决了现有技术在处理点云遮挡问题时的不足，展示了出色的性能和广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;非刚性对齐点云对于场景理解和重建至关重要，并且影响着计算机视觉和机器人领域的多种任务。近年来，隐式变形网络的发展显著减少了非刚性注册对大量标记训练数据的需求。然而，现有的最先进的方法在处理遮挡情况时仍然面临挑战。为了解决这个问题，本文介绍了一种创新的无监督方法——Occlusion-Aware Registration (OAR)，用于非刚性地对齐点云。该方法的关键创新在于使用自适应相关熵函数作为局部相似度测量，使我们能够区分处理各个点。与以往的方法只最小化两个形状之间的总体偏差不同，我们将未标记的隐式神经表示与最大相关熵准则相结合来优化未被遮挡区域的变形，从而有效避免了折叠、撕裂和其他物理上不合理的结果。此外，我们还进行了理论分析，并建立了最大相关熵准则和常用查默斯距离之间的关系，强调了由相关熵诱导的度量可以用作点云分析中的通用标准。另外，我们引入局部线性重构以确保即使在缺乏形状对应区域的情况下也能进行物理上自然的变形。我们的方法相比现有技术取得了优越或竞争性的性能，在处理带有遮挡结构时尤为突出，并展示了其在大规模形变、形状插值和存在遮挡干扰下的形状补全等挑战任务中的多功能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-rigid alignment of point clouds is crucial for scene understanding,reconstruction, and various computer vision and robotics tasks. Recentadvancements in implicit deformation networks for non-rigid registration havesignificantly reduced the reliance on large amounts of annotated training data.However, existing state-of-the-art methods still face challenges in handlingocclusion scenarios. To address this issue, this paper introduces an innovativeunsupervised method called Occlusion-Aware Registration (OAR) for non-rigidlyaligning point clouds. The key innovation of our method lies in the utilizationof the adaptive correntropy function as a localized similarity measure,enabling us to treat individual points distinctly. In contrast to previousapproaches that solely minimize overall deviations between two shapes, wecombine unsupervised implicit neural representations with the maximumcorrentropy criterion to optimize the deformation of unoccluded regions. Thiseffectively avoids collapsed, tearing, and other physically implausibleresults. Moreover, we present a theoretical analysis and establish therelationship between the maximum correntropy criterion and the commonly usedChamfer distance, highlighting that the correntropy-induced metric can beserved as a more universal measure for point cloud analysis. Additionally, weintroduce locally linear reconstruction to ensure that regions lackingcorrespondences between shapes still undergo physically natural deformations.Our method achieves superior or competitive performance compared to existingapproaches, particularly when dealing with occluded geometries. We alsodemonstrate the versatility of our method in challenging tasks such as largedeformations, shape interpolation, and shape completion under occlusiondisturbances.</description>
      <author>example@mail.com (Mingyang Zhao, Gaofeng Meng, Dong-Ming Yan)</author>
      <guid isPermaLink="false">2502.10704v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning of CATE with Kernel Ridge Regression</title>
      <link>http://arxiv.org/abs/2502.11331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的适应性转移学习方法，用于估计条件平均处理效果（CATE），并使用数值研究验证了该方法的有效性和优越性。&lt;h4&gt;背景&lt;/h4&gt;数据的增多促使人们利用一个研究的结果来估算不同目标群体中的治疗效应，但这种迁移学习过程常受到显著协变量变化和有限重叠的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于核岭回归（KRR）的方法进行适应性的转移学习，以便在源与目标人群以及内部对照组之间的有限重叠情况下估计CATE。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将标记的来源数据划分为两部分来进行候选CATE模型的选择：一部分用于训练模型，另一部分和未标注的目标数据一起选择最优模型。&lt;h4&gt;主要发现&lt;/h4&gt;提供了一个理论依据，并通过尖锐的非渐近均方误差界限证明了其对弱重叠和复杂度适应性的有效性。数值研究证实该方法在有限样本中的效率和适应性都优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;通过使用401(k)资格数据集，展示了所提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of data has sparked significant interest in leveragingfindings from one study to estimate treatment effects in a different targetpopulation without direct outcome observations. However, the transfer learningprocess is frequently hindered by substantial covariate shift and limitedoverlap between (i) the source and target populations, as well as (ii) thetreatment and control groups within the source. We propose a novel method foroverlap-adaptive transfer learning of conditional average treatment effect(CATE) using kernel ridge regression (KRR). Our approach involves partitioningthe labeled source data into two subsets. The first one is used to traincandidate CATE models based on regression adjustment and pseudo-outcomes. Anoptimal model is then selected using the second subset and unlabeled targetdata, employing another pseudo-outcome-based strategy. We provide a theoreticaljustification for our method through sharp non-asymptotic MSE bounds,highlighting its adaptivity to both weak overlaps and the complexity of CATEfunction. Extensive numerical studies confirm that our method achieves superiorfinite-sample efficiency and adaptability. We conclude by demonstrating theeffectiveness of our approach using a 401(k) eligibility dataset.</description>
      <author>example@mail.com (Seok-Jin Kim, Hongjie Liu, Molei Liu, Kaizheng Wang)</author>
      <guid isPermaLink="false">2502.11331v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>REGNav: Room Expert Guided Image-Goal Navigation</title>
      <link>http://arxiv.org/abs/2502.10785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAAI 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的图像目标导航模型，该模型模仿人类行为以提高代理在不同房间环境中导航到目标位置的能力。&lt;h4&gt;背景&lt;/h4&gt;大多数先前的方法通过学习导航策略来解决从观察图像引导智能体到达由另一张图像指定的目标位置的任务。当代理处于与目标图像不同的房间时，识别相似性并推断可能的定位非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在模仿人类行为，设计一种新的模型，以帮助智能体确定当前观测和目标图像是不是位于同一房间里，并以此来改善导航性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种由房型专家指导的图像目标导航模型(REGNav)。首先对未标记的房间图像进行无监督学习预训练，生成一个能够提取隐藏的房间风格信息并预测两者是否属于同一个房间的关系的房型专家。然后探索了两种不同的融合方法来利用这种关系知识有效地引导代理导航。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的REGNav模型在三个流行基准上的性能优于先前最先进的作品。&lt;h4&gt;结论&lt;/h4&gt;通过模仿人类行为并采用房型专家指导的方法，可以显著提高图像目标导航任务中的智能体表现。&lt;h4&gt;翻译&lt;/h4&gt;图象-目标导航旨在引导代理到达由一张图指定的目标位置。大多数先前的方法是通过学习导航策略来解决这个问题的，该策略提取目标和观察图像的视觉特征、比较它们之间的相似性并预测行为。然而如果代理处于不同于目标图片的位置（例如不同的房间），识别其相似性和推断可能的目标位置变得极其具有挑战性，这可能导致代理迷失方向。从直观上看，当人类执行这个任务时，他们可能会粗略地将当前的观察与目标图像进行比较，并在采取行动之前大致了解自己是否在同一房间内。受到这种直觉的启发，我们试图模仿人的行为并提出了一种由房型专家指导的图象-目标导航模型（REGNav），以使代理能够分析目标和观察图片是否是在同一个房间拍摄的。具体来说，我们首先使用无监督学习技术在收集到未标记的房间图像上训练了一个房型专家。该专家可以提取目标和观察图像中隐藏的房间风格信息，并预测它们之间关于是否属于同一房间的关系。此外，还探讨了两种不同的融合方法来有效地指导代理导航，以利用关系知识。广泛的实验表明，我们的REGNav模型在三个流行的基准测试上超越了现有的最先进的工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-goal navigation aims to steer an agent towards the goal locationspecified by an image. Most prior methods tackle this task by learning anavigation policy, which extracts visual features of goal and observationimages, compares their similarity and predicts actions. However, if the agentis in a different room from the goal image, it's extremely challenging toidentify their similarity and infer the likely goal location, which may resultin the agent wandering around. Intuitively, when humans carry out this task,they may roughly compare the current observation with the goal image, having anapproximate concept of whether they are in the same room before executing theactions. Inspired by this intuition, we try to imitate human behaviour andpropose a Room Expert Guided Image-Goal Navigation model (REGNav) to equip theagent with the ability to analyze whether goal and observation images are takenin the same room. Specifically, we first pre-train a room expert with anunsupervised learning technique on the self-collected unlabelled room images.The expert can extract the hidden room style information of goal andobservation images and predict their relationship about whether they belong tothe same room. In addition, two different fusion approaches are explored toefficiently guide the agent navigation with the room relation knowledge.Extensive experiments show that our REGNav surpasses prior state-of-the-artworks on three popular benchmarks.</description>
      <author>example@mail.com (Pengna Li, Kangyi Wu, Jingwen Fu, Sanping Zhou)</author>
      <guid isPermaLink="false">2502.10785v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond</title>
      <link>http://arxiv.org/abs/2502.12048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文综述了基于EEG的多模态生成领域的最新进展，重点讨论了通过GAN、VAE和扩散模型实现的EEG到图像生成以及利用Transformer语言模型和对比学习方法进行的EEG到文本生成。&lt;h4&gt;背景&lt;/h4&gt;脑机接口（BCIs）与生成式人工智能（GenAI）的结合为大脑信号解码开辟了新的领域，使得辅助通信、神经表示学习及多模态融合成为可能。特别是采用EEG技术的非侵入性方法可以将神经活动转化为有意义的输出。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供基于EEG生成式人工智能领域的结构化概览，帮助研究人员和实践者深入了解如何推进大脑信号解码，增强辅助技术，并扩展脑机交互的边界。&lt;h4&gt;方法&lt;/h4&gt;综述了通过GAN、VAE以及扩散模型实现的EEG到图像生成；利用Transformer语言模型及对比学习方法进行的EEG到文本生成；新兴领域包括基于EEG的声音合成。&lt;h4&gt;主要发现&lt;/h4&gt;关键数据集、应用场景、挑战及EEG特征编码方法在生成式方法中起着基础作用。这些技术的应用范围广泛，从辅助通信到神经表示学习以及多模态融合。&lt;h4&gt;结论&lt;/h4&gt;该综述为研究人员和实践者提供了有关基于EEG的生成AI领域的深入见解，并展示了BCI与GenAI结合的可能性及其潜在影响。&lt;h4&gt;翻译&lt;/h4&gt;脑机接口（BCIs）与生成式人工智能（GenAI）的整合开辟了大脑信号解码的新领域，使辅助通信、神经表示学习和多模态融合成为可能。尤其是利用EEG技术的方法提供了将神经活动转化为有意义输出的非侵入性手段。近年来，包括GAN和基于Transformer的大规模语言模型在内的深度学习进步显著提高了基于EEG生成图像、文本和语音的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integration of Brain-Computer Interfaces (BCIs) and Generative ArtificialIntelligence (GenAI) has opened new frontiers in brain signal decoding,enabling assistive communication, neural representation learning, andmultimodal integration. BCIs, particularly those leveragingElectroencephalography (EEG), provide a non-invasive means of translatingneural activity into meaningful outputs. Recent advances in deep learning,including Generative Adversarial Networks (GANs) and Transformer-based LargeLanguage Models (LLMs), have significantly improved EEG-based generation ofimages, text, and speech. This paper provides a literature review of thestate-of-the-art in EEG-based multimodal generation, focusing on (i)EEG-to-image generation through GANs, Variational Autoencoders (VAEs), andDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer basedlanguage models and contrastive learning methods. Additionally, we discuss theemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. Wehighlight key datasets, use cases, challenges, and EEG feature encoding methodsthat underpin generative approaches. By providing a structured overview ofEEG-based generative AI, this survey aims to equip researchers andpractitioners with insights to advance neural decoding, enhance assistivetechnologies, and expand the frontiers of brain-computer interaction.</description>
      <author>example@mail.com (Shreya Shukla, Jose Torres, Abhijit Mishra, Jacek Gwizdka, Shounak Roychowdhury)</author>
      <guid isPermaLink="false">2502.12048v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>AudioSpa: Spatializing Sound Events with Text</title>
      <link>http://arxiv.org/abs/2502.11219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于文本的双耳音频生成技术，结合大型语言模型和声学信息，能够从单声道参考音频中生成具有空间感的双耳音频。&lt;h4&gt;背景&lt;/h4&gt;最近的文本文本到音频（TTA）系统在合成单声道音频方面表现出了强大的性能。然而，将文字转化为提供更沉浸式听觉体验的双耳空间音频的任务尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;提出了一种基于文本指导的双耳音频生成方法，并专注于给定单声道参考音频的情况下进行实验。&lt;h4&gt;方法&lt;/h4&gt;提出了AudioSpa模型，这是一个端到端的方法，使用大型语言模型处理声学和文本信息。同时引入了融合多头注意力（FMHA）机制来增强多模态学习的能力。还设计了一种数据增强策略以生成多样化且具有不同空间位置的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该模型能够将声音准确地定位在指定的位置，并在定位精度和信号失真方面表现出竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作为基于文本的双耳音频生成提供了一个初步但有前景的方法，利用大规模语言模型来处理复杂的声学描述。所提出的数据增强策略有助于提高空间化声音事件的能力。&lt;h4&gt;翻译&lt;/h4&gt;最近，文本文本到音频（TTA）系统在合成单声道音频方面表现出色。然而，从文本中生成双耳立体声音频的任务还未被探索。这项工作介绍了基于文本的双耳音频生成技术，并专注于同时给定单声道参考音频的情况。核心问题是如何将特定的声音事件与方向关联起来以创建具有空间感的双耳音频。挑战在于复杂的文本描述和单一来源声音事件数据集的稀缺性。为此，我们提出了AudioSpa模型，这是一个端到端的方法，结合大型语言模型处理声学和文本信息，并提出了一种双耳源定位模型来评估生成音频的质量。此外，还设计了数据增强策略以生成多样化且具有各种空间位置的数据集，使该模型能够将声音事件的空间化至多个位置。实验结果表明该模型在指定位置准确放置声音方面表现出色，在定位精度和信号失真两方面均达到了竞争水平的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-audio (TTA) systems have recently demonstrated strong performance insynthesizing monaural audio from text. However, the task of generating binauralspatial audio from text, which provides a more immersive auditory experience byincorporating the sense of spatiality, have not been explored yet. In thiswork, we introduce text-guided binaural audio generation. As an early effort,we focus on the scenario where a monaural reference audio is givenadditionally. The core problem is to associate specific sound events with theirdirections, thereby creating binaural spatial audio. The challenge lies in thecomplexity of textual descriptions and the limited availability ofsingle-source sound event datasets. To address this, we propose AudioSpa, anend-to-end model that applies large language models to process both acousticand textual information. We employ fusion multi-head attention (FMHA) tointegrate text tokens, which enhances the generation capability of themultimodal learning. Additionally, we propose a binaural source localizationmodel to assess the quality of the generated audio. Finally, we design a dataaugmentation strategy to generate diverse datasets, which enables the model tospatialize sound events across various spatial positions. Experimental resultsdemonstrate that our model is able to put sounds at the specified locationsaccurately. It achieves competitive performance in both localization accuracyand signal distortion. Our demonstrations are available athttps://linfeng-feng.github.io/AudioSpa-demo.</description>
      <author>example@mail.com (Linfeng Feng, Lei Zhao, Boyu Zhu, Xiao-Lei Zhang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.11219v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation</title>
      <link>http://arxiv.org/abs/2502.12148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Gen-Verse/HermesFlow&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究揭示了多模态大型语言模型（MLLMs）在理解和生成能力之间存在显著差距，提出了HermesFlow框架以缩小这一差距。&lt;h4&gt;背景&lt;/h4&gt;自回归范式的成功推动了多模态大型语言模型的发展，如Show-o、Transfusion和Emu3等模型在统一的图像理解和生成方面取得了重大进展。然而，研究发现这些模型的理解能力通常比其生成能力更强，两者之间存在显著差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架HermesFlow来弥合多模态大型语言模型中理解与生成之间的差距。&lt;h4&gt;方法&lt;/h4&gt;使用同源数据输入来创建理解和生成的偏好数据。通过Pair-DPO和自我对弈迭代优化，利用同源偏好数据有效对接多模态理解和生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HermesFlow在缩小多模态理解和生成之间的差距方面优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;研究表明，HermesFlow作为下一代多模态基础模型的一般对齐框架具有巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;自回归范式的成功使得多模态大型语言模型（MLLMs）取得了显著进展，强大的模型如Show-o、Transfusion和Emu3在统一的图像理解和生成方面实现了明显的进步。首次揭示了一个共同现象：这些模型的理解能力通常比其生成能力强得多，并且两者之间存在显著差距。基于这一发现，我们提出了HermesFlow框架，这是一个简单而通用的方法，旨在无缝对接多模态大型语言模型中的理解与生成之间的差距。通过使用同源数据作为输入来创建理解和生成的偏好数据集，并利用Pair-DPO和自我对弈迭代优化，该方法有效地将多模态理解和生成进行对齐。广泛的实验表明了我们的方法相对于先前的方法具有显著的优势，特别是在缩小多模态理解和生成之间差距方面。这些发现突显了HermesFlow作为下一代多模态基础模型通用对齐框架的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable success of the autoregressive paradigm has made significantadvancement in Multimodal Large Language Models (MLLMs), with powerful modelslike Show-o, Transfusion and Emu3 achieving notable progress in unified imageunderstanding and generation. For the first time, we uncover a commonphenomenon: the understanding capabilities of MLLMs are typically stronger thantheir generative capabilities, with a significant gap between the two. Buildingon this insight, we propose HermesFlow, a simple yet general framework designedto seamlessly bridge the gap between understanding and generation in MLLMs.Specifically, we take the homologous data as input to curate homologouspreference data of both understanding and generation. Through Pair-DPO andself-play iterative optimization, HermesFlow effectively aligns multimodalunderstanding and generation using homologous preference data. Extensiveexperiments demonstrate the significant superiority of our approach over priormethods, particularly in narrowing the gap between multimodal understanding andgeneration. These findings highlight the potential of HermesFlow as a generalalignment framework for next-generation multimodal foundation models. Code:https://github.com/Gen-Verse/HermesFlow</description>
      <author>example@mail.com (Ling Yang, Xinchen Zhang, Ye Tian, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui)</author>
      <guid isPermaLink="false">2502.12148v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition</title>
      <link>http://arxiv.org/abs/2502.11742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submmitted to IEEE IV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种创新的图像到点云跨模态视觉位置识别（VPR）方法，该方法结合了范围或RGB图像以及鸟瞰图（BEV）图像的信息，并采用全局描述符相似性搜索过程进行重新排序。&lt;h4&gt;背景&lt;/h4&gt;在跨模态VPR任务中，查询是RGB图像，数据库样本为LiDAR点云。这种方法利用了RGB相机的普及性和点云提供的准确空间几何和距离信息的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效结合范围（或RGB）图像与鸟瞰图（BEV）图像信息的方法，并通过全局描述符相似性搜索过程实现重新排序。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新颖的相似度标签监督技术，以最大限度地利用有限的训练数据。具体来说，采用点平均距离来近似外观相似度，并根据相似度差异将自适应边距融入标准三元组损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在KITTI数据集上显著优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过创新的初始检索与重新排序策略有效结合了范围或RGB图像和鸟瞰图信息，并且能够最大化利用有限训练数据中的信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-to-point cloud cross-modal Visual Place Recognition (VPR) is achallenging task where the query is an RGB image, and the database samples areLiDAR point clouds. Compared to single-modal VPR, this approach benefits fromthe widespread availability of RGB cameras and the robustness of point cloudsin providing accurate spatial geometry and distance information. However,current methods rely on intermediate modalities that capture either thevertical or horizontal field of view, limiting their ability to fully exploitthe complementary information from both sensors. In this work, we propose aninnovative initial retrieval + re-rank method that effectively combinesinformation from range (or RGB) images and Bird's Eye View (BEV) images. Ourapproach relies solely on a computationally efficient global descriptorsimilarity search process to achieve re-ranking. Additionally, we introduce anovel similarity label supervision technique to maximize the utility of limitedtraining data. Specifically, we employ points average distance to approximateappearance similarity and incorporate an adaptive margin, based on similaritydifferences, into the vanilla triplet loss. Experimental results on the KITTIdataset demonstrate that our method significantly outperforms state-of-the-artapproaches.</description>
      <author>example@mail.com (Jianyi Peng, Fan Lu, Bin Li, Yuan Huang, Sanqing Qu, Guang Chen)</author>
      <guid isPermaLink="false">2502.11742v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>PrivilegedDreamer: Explicit Imagination of Privileged Information for Rapid Adaptation of Learned Policies</title>
      <link>http://arxiv.org/abs/2502.11377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. Website:  https://morganbyrd03.github.io/icra25_privileged_dreamer/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;许多现实世界中的控制问题涉及不可观察的隐藏参数影响的动力学和目标，从自动驾驶到机器人操作等，这些问题在模拟到实际转移过程中会导致性能下降。为表示这类领域，我们采用了带隐含参数马尔可夫决策过程（HIP-MDP），它用于建模由隐藏变量参数化的转换函数和奖励函数的序列决策问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的控制问题通常涉及受不可观察隐藏参数影响的动力学和目标，这导致了从模拟环境到真实环境转移时性能下降的问题。这些问题在各种领域中普遍存在，例如自动驾驶汽车和机器人操作。&lt;h4&gt;目的&lt;/h4&gt;为了解决由未观测的隐藏变量引起的影响，在本文中提出了一种新的基于模型的强化学习框架——Privileged-Dreamer，旨在通过引入一个显式的参数估计模块来有效处理带有隐含参数马尔可夫决策过程（HIP-MDP）的问题。&lt;h4&gt;方法&lt;/h4&gt;该论文提出的Privileged-Dreamer模型利用其独特的双循环架构从有限的历史数据中明确地估计出隐藏的参数，并使我们能够将这些估计出来的参数作为条件作用于模型、行为者和评价器网络上。&lt;h4&gt;主要发现&lt;/h4&gt;对五种不同的HIP-MDP任务进行的经验分析表明，Privileged-Dreamer框架在性能上优于现有的基于模型的方法、无模型方法以及领域适应学习算法。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了通过显式地估计隐藏参数并在强化学习过程中考虑这些参数的有效性。实验结果表明，在处理受不可观测变量影响的复杂环境时，Privileged-Dreamer能够显著提高性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;许多现实世界中的控制问题涉及由未观察到的隐藏参数影响的动力学和目标，这些问题在从模拟转移到真实系统的过程中会引起性能下降。为了表示这些类型的问题领域，我们采用了带有隐含参数马尔可夫决策过程（HIP-MDP）。HIP-MDP建模了序列决策问题，在这些问题中，隐藏变量参数化转换函数和奖励函数。现有方法，如领域随机化、领域适应和元学习等，简单地将隐藏参数的影响视为额外的方差，并且经常难以有效处理带有隐含参数马尔可夫决策过程（HIP-MDP）的问题，特别是在奖励函数由隐藏变量参数化的情况下。我们提出了Privileged-Dreamer，这是一种基于模型的强化学习框架，它通过引入显式的参数估计模块扩展了现有的基于模型的方法。Privileged-Dreamer具有其新颖的双循环架构，从有限的历史数据中明确地估计出隐藏的参数，并允许我们将这些估计出来的参数作为条件作用于模型、行为者和评价器网络上。在五种不同的HIP-MDP任务上的经验分析表明，Privileged-Dreamer优于现有的基于模型的、无模型的和领域适应学习算法。此外，我们进行了消融研究以证明所提出架构中每个组件的必要性。&lt;h4&gt;实验验证&lt;/h4&gt;通过一系列实验，论文展示了提出的框架在五种不同的HIP-MDP任务上均表现出色，并且显著超越了现有技术方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous real-world control problems involve dynamics and objectives affectedby unobservable hidden pa- rameters, ranging from autonomous driving to roboticmanipu- lation, which cause performance degradation during sim-to-realtransfer. To represent these kinds of domains, we adopt hidden- parameterMarkov decision processes (HIP-MDPs), which model sequential decision problemswhere hidden variables parameterize transition and reward functions. Existingap- proaches, such as domain randomization, domain adaptation, andmeta-learning, simply treat the effect of hidden param- eters as additionalvariance and often struggle to effectively handle HIP-MDP problems, especiallywhen the rewards are parameterized by hidden variables. We introducePrivileged- Dreamer, a model-based reinforcement learning framework thatextends the existing model-based approach by incorporating an explicitparameter estimation module. PrivilegedDreamer features its novel dualrecurrent architecture that explicitly estimates hidden parameters from limitedhistorical data and enables us to condition the model, actor, and criticnetworks on these estimated parameters. Our empirical analysis on five diverseHIP-MDP tasks demonstrates that PrivilegedDreamer outperforms state-of-the-artmodel-based, model-free, and do- main adaptation learning algorithms.Additionally, we conduct ablation studies to justify the inclusion of eachcomponent in the proposed architecture.</description>
      <author>example@mail.com (Morgan Byrd, Jackson Crandell, Mili Das, Jessica Inman, Robert Wright, Sehoon Ha)</author>
      <guid isPermaLink="false">2502.11377v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency</title>
      <link>http://arxiv.org/abs/2502.11965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2025 ICMLCN accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于自我监督学习的多输入多输出（MIMO）无线信道基础模型CSI-CLIP。&lt;h4&gt;背景&lt;/h4&gt;在人工智能领域，自监督学习通过利用大规模未标记数据集进行预训练，在泛化能力方面表现出了优越性。这对于适应各种场景的无线通信模型尤为重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的MIMO无线信道基础模型，以提高跨场景的适应性和特征提取的能力。&lt;h4&gt;方法&lt;/h4&gt;该论文创新地将通道状态信息(CSI)和通道脉冲响应(CIR)视为自然对齐的多模态数据，并提出了CSI-CLIP模型。通过有效地捕捉CIR和CSI的联合表示，模型表现出卓越的跨场景适应性和稳健性特征提取能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在定位任务中，CSI-CLIP将平均误差距离减少了22%；在波束管理任务中，与传统的监督方法相比，准确率提高了1%，并在信道识别任务中也有所提升。这些改进不仅突显了CSI-CLIP在整合感知和通信方面的潜力和价值，还展示了其相对于现有技术的重大优势。&lt;h4&gt;结论&lt;/h4&gt;将CSI和CIR视为多模态对，并通过对比学习为无线通道基础模型开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文翻译是：在人工智能领域，自监督学习通过利用大规模未标记数据集进行预训练，在泛化能力方面表现出了优越性。这对于适应各种场景的无线通信模型尤为重要。该论文创新地将通道状态信息(CSI)和通道脉冲响应(CIR)视为自然对齐的多模态数据，并提出了CSI-CLIP模型。通过有效地捕捉CIR和CSI的联合表示，模型表现出卓越的跨场景适应性和稳健性特征提取能力。实验结果显示，在定位任务中，CSI-CLIP将平均误差距离减少了22%；在波束管理任务中，与传统的监督方法相比，准确率提高了1%，并在信道识别任务中也有所提升。这些改进不仅突显了CSI-CLIP在整合感知和通信方面的潜力和价值，还展示了其相对于现有技术的重大优势。将CSI和CIR视为多模态对，并通过对比学习为无线通道基础模型开辟了新的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of artificial intelligence, self-supervised learning hasdemonstrated superior generalization capabilities by leveraging large-scaleunlabeled datasets for pretraining, which is especially critical for wirelesscommunication models to adapt to a variety of scenarios. This paperinnovatively treats Channel State Information (CSI) and Channel ImpulseResponse (CIR) as naturally aligned multi-modal data and proposes the firstMIMO wireless channel foundation model, named CSI-CLIP. By effectivelycapturing the joint representations of both CIR and CSI, CSI-CLIP exhibitsremarkable adaptability across scenarios and robust feature extractioncapabilities. Experimental results show that in positioning task, CSI-CLIPreduces the mean error distance by 22%; in beam management task, it increasesaccuracy by 1% compared to traditional supervised methods, as well as in thechannel identification task. These improvements not only highlight thepotential and value of CSI-CLIP in integrating sensing and communication butalso demonstrate its significant advantages over existing techniques. Moreover,viewing CSI and CIR as multi-modal pairs and contrastive learning for wirelesschannel foundation model open up new research directions in the domain of MIMOwireless communications.</description>
      <author>example@mail.com (Jun Jiang, Wenjun Yu, Yunfan Li, Yuan Gao, Shugong Xu)</author>
      <guid isPermaLink="false">2502.11965v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A GNN-based Spectral Filtering Mechanism for Imbalance Classification in Network Digital Twin</title>
      <link>http://arxiv.org/abs/2502.11505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2406.06595&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络模型Class-Fourier Graph Neural Network (CF-GNN)，该模型通过引入类特定的谱滤波机制，解决了5G核心网络数字孪生中的多类别不平衡分类问题。&lt;h4&gt;背景&lt;/h4&gt;在第五代（5G）核心网络的数字孪生系统中，由于罕见故障类型的出现以及复杂的数据结构，传统的图神经网络难以准确地进行故障类型识别。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法在处理复杂且不均衡分布数据时的不足，本文旨在提出一种能够有效解决多类别不平衡问题的新模型，并探讨其在网络数字孪生系统中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;提出的CF-GNN引入了类特定的谱滤波机制，该机制通过估计每个类别的独特谱滤波器来确保精确分类。利用特征值和特征向量的谱滤波技术可以捕捉并适应少数类别数据的变化，从而实现精准的类特异性特征区分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CF-GNN能够有效提高数字孪生系统的多类别不平衡数据处理能力，并能为改进现有分类器技术和深入研究网络数字孪生系统中的多类别不平衡问题提供新思路。&lt;h4&gt;结论&lt;/h4&gt;提出的Class-Fourier Graph Neural Network (CF-GNN) 在处理5G核心网络的数字孪生中遇到的复杂和不均衡分布的数据时，表现出了卓越的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks are gaining attention in Fifth-Generation (5G) corenetwork digital twins, which are data-driven complex systems with numerouscomponents. Analyzing these data can be challenging due to rare failure types,leading to imbalanced classification in multiclass settings. Digital twins of5G networks increasingly employ graph classification as the main method foridentifying failure types. However, the skewed distribution of failureoccurrences is a major class imbalance issue that prevents effective graph datamining. Previous studies have not sufficiently tackled this complex problem. Inthis paper, we propose Class-Fourier Graph Neural Network (CF-GNN) introduces aclass-oriented spectral filtering mechanism that ensures precise classificationby estimating a unique spectral filter for each class. We employ eigenvalue andeigenvector spectral filtering to capture and adapt to variations in theminority classes, ensuring accurate class-specific feature discrimination, andadept at graph representation learning for complex local structures amongneighbors in an end-to-end setting. Extensive experiments have demonstratedthat the proposed CF-GNN could help with both the creation of new techniquesfor enhancing classifiers and the investigation of the characteristics of themulti-class imbalanced data in a network digital twin system.</description>
      <author>example@mail.com (Abubakar Isah, Ibrahim Aliyu, Sulaiman Muhammad Rashid, Jaehyung Park, Minsoo Hahn, Jinsul Kim)</author>
      <guid isPermaLink="false">2502.11505v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Masked Latent Prediction and Classification for Self-Supervised Audio Representation Learning</title>
      <link>http://arxiv.org/abs/2502.12031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Copyright 2025 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，基于遮蔽潜在预测的自我监督学习方法被证明能够将输入数据编码为强大的表示。然而，在训练过程中，可以进一步变换所学的潜在空间以提取更适于下游分类任务的高级信息。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习方法在通过遮蔽潜在预测的方式获取强大表示上表现出色，但它们可能没有充分利用潜在空间来实现更好的下游分类性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MATPAC（MAsked latenTPrediction And Classification），它通过解决两个预设任务联合训练，旨在进一步优化所学的潜在空间以适应更高级的信息提取和分类需求。&lt;h4&gt;方法&lt;/h4&gt;该方法包括两个预设任务：一个是遮蔽潜在预测任务，确保在潜在线性中的稳健输入表示；另一个是无监督分类任务，利用第一个预设任务生成的潜在线条来匹配教师模型和学生模型之间的概率分布。MATPAC通过与现有最先进的提议进行比较以及执行消融研究来进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;MATPAC在参考音频分类数据集（如OpenMIC、GTZAN、ESC-50和US8K）上实现了自监督学习的最新结果，并且在音乐自动标记任务Magna-tag-a-tune上的表现优于可比较的监督方法。&lt;h4&gt;结论&lt;/h4&gt;通过将遮蔽潜在预测与无监督分类相结合，MATPAC能够显著提高所学表示的有效性，在各种音频数据集上的性能优于其他自监督学习方法和一些监督方法。&lt;h4&gt;翻译&lt;/h4&gt;最近，基于遮蔽潜在预测的自我监督学习方法被证明能够将输入数据编码为强大的表示形式。然而，在训练过程中，可以进一步变换所学的潜在空间以提取更适于下游分类任务的信息。因此，我们提出了一种新方法：MAsked latenTPrediction And Classification (MATPAC)，它通过解决两个预设任务联合进行训练。如之前的工作所述，第一个预设任务是遮蔽潜在预测任务，确保在潜在线性中的稳健输入表示形式。第二个则是无监督分类任务，该任务利用第一个预设任务生成的潜在线条来匹配教师模型和学生模型之间的概率分布。我们通过与其他最先进的提议进行比较并执行消融研究验证了MATPAC方法的有效性。MATPAC在参考音频分类数据集（如OpenMIC、GTZAN、ESC-50和US8K）上实现了自监督学习的最新结果，并且在音乐自动标记任务Magna-tag-a-tune上的表现优于可比较的监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, self-supervised learning methods based on masked latent predictionhave proven to encode input data into powerful representations. However, duringtraining, the learned latent space can be further transformed to extracthigher-level information that could be more suited for downstreamclassification tasks. Therefore, we propose a new method: MAsked latenTPrediction And Classification (MATPAC), which is trained with two pretext taskssolved jointly. As in previous work, the first pretext task is a masked latentprediction task, ensuring a robust input representation in the latent space.The second one is unsupervised classification, which utilises the latentrepresentations of the first pretext task to match probability distributionsbetween a teacher and a student. We validate the MATPAC method by comparing itto other state-of-the-art proposals and conducting ablations studies. MATPACreaches state-of-the-art self-supervised learning results on reference audioclassification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperformscomparable supervised methods results for musical auto-tagging onMagna-tag-a-tune.</description>
      <author>example@mail.com (Aurian Quelennec, Pierre Chouteau, Geoffroy Peeters, Slim Essid)</author>
      <guid isPermaLink="false">2502.12031v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>BalanceBenchmark: A Survey for Imbalanced Learning</title>
      <link>http://arxiv.org/abs/2502.10816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态学习中的不平衡问题，并提出了一个基准测试框架BalanceBenchmark来评估不同方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;多模态学习通过融合来自不同模态的信息得到了广泛关注，但面临的一个主要问题是某些模态的数据量远远大于其他模态导致的不平衡现象。尽管已有研究提出了一些缓解措施，但缺乏系统的对比分析。&lt;h4&gt;目的&lt;/h4&gt;系统地分类主流的多模态不平衡算法，并引入一个新的基准测试框架来全面评估不同方法的效果。&lt;h4&gt;方法&lt;/h4&gt;根据所采用的不同策略将现有算法分为四类；设计了包括多个常用数据集和从三个维度（性能，不平衡程度及计算复杂度）进行评估的新基准测试；开发了一个模块化且可扩展的工具包以确保实验的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用BalanceBenchmark进行了详尽的实验，揭示了不同方法组在处理多模态不平衡问题时的特点和优势。研究结果为未来解决此类问题提供了有价值的见解，并可能对基础模型的设计产生影响。&lt;h4&gt;结论&lt;/h4&gt;本文的工作不仅有助于更好地理解现有的多模态不平衡算法，还期望能够激发更多高效的解决方案以应对未来的挑战，包括对基础模型的影响。&lt;h4&gt;翻译&lt;/h4&gt;多模态学习因其整合来自不同来源的信息的能力而备受关注。然而，在这种环境下一个常见的问题是数据的多模态不平衡问题，即某些类型的数据主导整个系统的同时其他类型的使用不足。尽管最近的研究提出了一些缓解策略，但缺乏全面和公平的比较研究。本文中，我们根据所用的不同方法将主流的解决不平衡的方法分为了四类。为使这些不同方法能有一个综合评估，我们引入了一个基准测试框架（BalanceBenchmark），包括多个广泛使用的多维数据集以及从三个维度进行评价的标准：性能、不平衡程度和复杂度。通过标准化整个实验流程以确保公平比较，开发了一种模块化且扩展性强的工具包。基于使用该框架进行的实验，我们得出了关于不同方法组在处理不平衡问题方面的特征及优势的关键见解，并期望此分析能够在未来启发更有效的解决多模态学习中不平衡问题的方法，以及对于基础模型的影响。平衡基准测试的相关代码可以在https://github.com/GeWu-Lab/BalanceBenchmark获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained attention for its capacity to integrateinformation from different modalities. However, it is often hindered by themultimodal imbalance problem, where certain modality dominates while othersremain underutilized. Although recent studies have proposed various methods toalleviate this problem, they lack comprehensive and fair comparisons. In thispaper, we systematically categorize various mainstream multimodal imbalancealgorithms into four groups based on the strategies they employ to mitigateimbalance. To facilitate a comprehensive evaluation of these methods, weintroduce BalanceBenchmark, a benchmark including multiple widely usedmultidimensional datasets and evaluation metrics from three perspectives:performance, imbalance degree, and complexity. To ensure fair comparisons, wehave developed a modular and extensible toolkit that standardizes theexperimental workflow across different methods. Based on the experiments usingBalanceBenchmark, we have identified several key insights into thecharacteristics and advantages of different method groups in terms ofperformance, balance degree and computational complexity. We expect suchanalysis could inspire more efficient approaches to address the imbalanceproblem in the future, as well as foundation models. The code of the toolkit isavailable at https://github.com/GeWu-Lab/BalanceBenchmark.</description>
      <author>example@mail.com (Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, DiHu)</author>
      <guid isPermaLink="false">2502.10816v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Structure based SAT dataset for analysing GNN generalisation</title>
      <link>http://arxiv.org/abs/2502.11410v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be published in 28th International Conference on Artificial  Intelligence and Statistics (AISTATS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了在SAT问题求解领域，CDCL（冲突驱动的子句学习）技术已经取得了显著成果。然而，针对GNN（图神经网络）方法在此领域的应用还存在一个被忽视的问题：结构属性与模型泛化能力之间的关系研究不足。&lt;h4&gt;背景&lt;/h4&gt;基于CDCL的技术已经在合成和实际工业问题中实现了卓越性能。但是，虽然这些CDCL求解器仅在特定问题上操作，GNN求解器通过利用已解决问题的知识来加速新SAT问题的解决带来了新的益处。&lt;h4&gt;目的&lt;/h4&gt;提出StructureSAT数据集及其生成代码，旨在研究结构属性（如模块性、自相似性）与基于图神经网络的SAT求解器泛化能力之间的关系，并揭示现有GNN SAT求解器中存在问题的原因。&lt;h4&gt;方法&lt;/h4&gt;利用了一种新的分割方法，该方法侧重于根据其结构性质将家族细化为更详细的层次结构。通过新数据集帮助解释现有GNN SAT求解器中的问题泛化难题。&lt;h4&gt;主要发现&lt;/h4&gt;文章未明确指出具体的研究结果或实验数据，但强调了研究的潜在贡献和未来发展方向。&lt;h4&gt;结论&lt;/h4&gt;为了促进基于图神经网络的SAT解决技术的发展，提出了多个未来研究方向，以帮助研究人员开发出更加有效且具有泛化能力的SAT求解器。&lt;h4&gt;翻译&lt;/h4&gt;可满足性（SAT）求解器基于冲突驱动子句学习等技术，在合成和现实世界工业问题上表现出色。然而，尽管CDCL求解器仅针对特定问题操作，图神经网络（GNN）求解器通过允许实践者利用已解决问题的知识来加速新SAT问题的解决带来了新的益处。但是，一个在CDCL求解器中经常研究但在GNN求解器中被忽视的问题是：SAT问题中的结构属性与GNN求解器泛化能力之间的关系。为了弥合结构性图特性（如模块性、自相似性）与基于图神经网络的SAT求解器泛化的差距，我们提出了StructureSAT：一个包含多样化来自知名问题领域SAT问题的数据集，并提供了生成新示例的代码。此外，我们利用了一种新的分割方法，该方法侧重于根据其结构性质将家族细化为更详细的层次结构。通过此数据集，我们旨在帮助解释现有GNN SAT求解器中的泛化难题，并利用对结构图属性的知识。最后，我们总结了可以帮助基于图神经网络的SAT解决技术发展的多个未来研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satisfiability (SAT) solvers based on techniques such as conflict drivenclause learning (CDCL) have produced excellent performance on both syntheticand real world industrial problems. While these CDCL solvers only operate on aper-problem basis, graph neural network (GNN) based solvers bring new benefitsto the field by allowing practitioners to exploit knowledge gained from solvedproblems to expedite solving of new SAT problems. However, one specific areathat is often studied in the context of CDCL solvers, but largely overlooked inGNN solvers, is the relationship between graph theoretic measure of structurein SAT problems and the generalisation ability of GNN solvers. To bridge thegap between structural graph properties (e.g., modularity, self-similarity) andthe generalisability (or lack thereof) of GNN based SAT solvers, we presentStructureSAT: a curated dataset, along with code to further generate novelexamples, containing a diverse set of SAT problems from well known problemdomains. Furthermore, we utilise a novel splitting method that focuses ondeconstructing the families into more detailed hierarchies based on theirstructural properties. With the new dataset, we aim to help explain problematicgeneralisation in existing GNN SAT solvers by exploiting knowledge ofstructural graph properties. We conclude with multiple future directions thatcan help researchers in GNN based SAT solving develop more effective andgeneralisable SAT solvers.</description>
      <author>example@mail.com (Yi Fu, Anthony Tompkins, Yang Song, Maurice Pagnucco)</author>
      <guid isPermaLink="false">2502.11410v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-aware contrastive heterogeneous molecular graph learning</title>
      <link>http://arxiv.org/abs/2502.11711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的框架，用于改善分子表示学习，特别是在药物设计中的应用。通过引入异构图结构和对比学习方法，该框架能够更好地整合外部知识并提升分子性质预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的分子性质预测方法主要依赖同质图编码，这种方法无法有效地融入外部知识，并且难以在不同粒度级别上表示分子结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的机器学习框架Knowledge-aware Contrastive Heterogeneous Molecular Graph Learning (KCHML)，以解决传统方法的局限性并提高分子性质预测能力。&lt;h4&gt;方法&lt;/h4&gt;该研究通过引入异构图编码和对比学习，创建了一个基于三种不同视角（分子、元素及药理）的新颖表示模型。此框架利用双层消息传递机制来增强分子图的表现力。&lt;h4&gt;主要发现&lt;/h4&gt;KCHML不仅在预测分子特性方面超越了现有最佳模型，在下游任务如药物相互作用预测上也表现出色，这表明该方法能有效捕捉到复杂分子特征。&lt;h4&gt;结论&lt;/h4&gt;通过引入异构图编码和对比学习技术，KCHML框架能够显著提升分子表示的学习效果及其应用价值。这一方法为未来的分子性质研究提供了新的视角和可能。&lt;h4&gt;翻译&lt;/h4&gt;分子表示学习在预测分子属性和推进药物设计方面至关重要。传统的依赖于同质图编码的方法由于无法整合外部知识以及难以跨不同粒度级别表示分子结构，而存在局限性。为了克服这些限制，我们提出了一种向异构图结构进行图编码的范式转变，并引入了一个新的框架：具有嵌入外部知识对比学习功能的知识感知异构分子图学习（KCHML）。该方法利用了三种不同的图视角——分子、元素和药理学，通过增强型的异构分子图以及双消息传递机制来丰富分子表示。这种设计为属性预测提供了全面的表征，并且对于下游任务如药物-药物相互作用预测同样适用。广泛的基准测试证明KCHML在最先进的分子属性预测模型中具有优越性，突显了其捕捉复杂分子特征的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular representation learning is pivotal in predicting molecularproperties and advancing drug design. Traditional methodologies, whichpredominantly rely on homogeneous graph encoding, are limited by theirinability to integrate external knowledge and represent molecular structuresacross different levels of granularity. To address these limitations, wepropose a paradigm shift by encoding molecular graphs into heterogeneousstructures, introducing a novel framework: Knowledge-aware ContrastiveHeterogeneous Molecular Graph Learning (KCHML). This approach leveragescontrastive learning to enrich molecular representations with embedded externalknowledge. KCHML conceptualizes molecules through three distinct graphviews-molecular, elemental, and pharmacological-enhanced by heterogeneousmolecular graphs and a dual message-passing mechanism. This design offers acomprehensive representation for property prediction, as well as for downstreamtasks such as drug-drug interaction (DDI) prediction. Extensive benchmarkingdemonstrates KCHML's superiority over state-of-the-art molecular propertyprediction models, underscoring its ability to capture intricate molecularfeatures.</description>
      <author>example@mail.com (Mukun Chen, Jia Wu, Shirui Pan, Fu Lin, Bo Du, Xiuwen Gong, Wenbin Hu)</author>
      <guid isPermaLink="false">2502.11711v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Oversmoothing as Loss of Sign: Towards Structural Balance in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.11394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的解决图神经网络过度平滑问题的方法，通过将抗过度平滑技术解释为在带有正负边的签名图上进行消息传递，从而提供了对这些方法内在机制的新见解。&lt;h4&gt;背景&lt;/h4&gt;在图神经网络中，随着层数增加节点表示变得过于同质化的问题很常见。现有解决该问题的技术主要基于直觉而非理论支持，缺乏统一的理解。&lt;h4&gt;目的&lt;/h4&gt;通过分析签名图传播的渐进行为，展示负边如何使节点相互排斥，并提出一种新的方法来减轻过度平滑现象。&lt;h4&gt;方法&lt;/h4&gt;引入了结构平衡传播（SBP），这种方法利用标签和特征信息创建一个结构上平衡的图用于消息传递。&lt;h4&gt;主要发现&lt;/h4&gt;负边可以将节点在某种程度上推开，这对于长期聚类表示非常重要。此外，正边存在于集群内部而负边出现在集群之间时，签名图中的结构均衡对于节点表示的长期聚类至关重要。&lt;h4&gt;结论&lt;/h4&gt;实验证明了我们的方法能够有效地缓解过度平滑问题，并展示了从签名图角度理解GNN的方法的价值。&lt;h4&gt;翻译&lt;/h4&gt;过度平滑是图神经网络中常见的一种现象，在层数增加时，节点表示变得过于同质化。本文通过将抗过度平滑技术解释为在带有正负边的签名图上进行消息传递，提供了对这些方法内在机制的新见解，并提出了一种新的理论上有保证的方法——结构平衡传播（SBP），该方法利用标签和特征信息创建一个结构上均衡的图用于消息传递。实验结果表明了我们方法的有效性，并强调了从签名图角度理解GNN的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oversmoothing is a common issue in graph neural networks (GNNs), where noderepresentations become excessively homogeneous as the number of layersincreases, resulting in degraded performance. Various strategies have beenproposed to combat oversmoothing in practice, yet they are based on differentheuristics and lack a unified understanding of their inherent mechanisms. Inthis paper, we show that three major classes of anti-oversmoothing techniquescan be mathematically interpreted as message passing over signed graphscomprising both positive and negative edges. By analyzing the asymptoticbehavior of signed graph propagation, we demonstrate that negative edges canrepel nodes to a certain extent, providing deeper insights into how thesemethods mitigate oversmoothing. Furthermore, our results suggest that thestructural balance of a signed graph-where positive edges exist only withinclusters and negative edges appear only between clusters-is crucial forclustering node representations in the long term through signed graphpropagation. Motivated by these observations, we propose a solution to mitigateoversmoothing with theoretical guarantees-Structural Balance Propagation (SBP),by incorporating label and feature information to create a structurallybalanced graph for message-passing. Experiments on nine datasets against twelvebaselines demonstrate the effectiveness of our method, highlighting the valueof our signed graph perspective.</description>
      <author>example@mail.com (Jiaqi Wang, Xinyi Wu, James Cheng, Yifei Wang)</author>
      <guid isPermaLink="false">2502.11394v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>No-reference geometry quality assessment for colorless point clouds via list-wise rank learning</title>
      <link>http://arxiv.org/abs/2502.11726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于列表排序学习的无参考几何质量评估（GQA）方法，名为LRL-GQA。此方法包括一个用于捕捉点云内在多尺度特征的质量评估网络（GQANet），以及用于训练和排名降级点云列表的学习网络（LRLNet）。实验表明该方法在性能上优于现有的全参考GQA指标。&lt;h4&gt;背景&lt;/h4&gt;目前，客观的几何质量评估对于评价基于点云的新解决方案（如水印、压缩和3D重建）的重要性日益增加。然而，现有方法要么是传统的全参考度量标准，要么针对的是颜色和几何失真的综合学习方法，这些都不适用于无参考的GQA任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无参考仅几何质量评估的方法，以解决当前方法中存在的局限性，并推动基于学习的质量评估指标的发展。&lt;h4&gt;方法&lt;/h4&gt;该研究构建了一个名为LRL数据集的大规模数据库，其中包含多种几何失真，并开发了两个网络：GQANet用于捕捉点云的多尺度特征并预测质量指数；LRLNet则利用可能性损失函数来训练GQANet并对降级点云列表进行排名。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的无参考LRL-GQA方法在评估几何质量和排序受损点云方面表现出色，优于现有的全参考GQA度量标准。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种有效的无参考仅几何质量评估的方法，并通过实验验证了其优越性。这种方法为基于学习的GQA指标的发展提供了新的方向和可能性。&lt;h4&gt;翻译&lt;/h4&gt;几何质量评估（GQA）对于评价新兴点云解决方案的重要性日益增加，但现有的客观方法要么是传统的全参考度量标准，要么针对的是颜色和几何失真的综合学习方法，这些都不适合无参考的质量评估任务。此外，由于缺乏大规模的具有主观评分的GQA数据集，这进一步阻碍了基于学习的方法的发展。该论文提出了一种新的基于列表排序学习的无参考仅几何质量评估方法LRL-GQA，包括一个捕捉多尺度特征的质量评估网络和用于训练和排名降级点云列表的学习网络。实验表明其性能优于现有的全参考GQA度量标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.cag.2025.104176&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometry quality assessment (GQA) of colorless point clouds is crucial forevaluating the performance of emerging point cloud-based solutions (e.g.,watermarking, compression, and 3-Dimensional (3D) reconstruction).Unfortunately, existing objective GQA approaches are traditional full-referencemetrics, whereas state-of-the-art learning-based point cloud quality assessment(PCQA) methods target both color and geometry distortions, neither of which arequalified for the no-reference GQA task. In addition, the lack of large-scaleGQA datasets with subjective scores, which are always imprecise, biased, andinconsistent, also hinders the development of learning-based GQA metrics.Driven by these limitations, this paper proposes a no-reference geometry-onlyquality assessment approach based on list-wise rank learning, termed LRL-GQA,which comprises of a geometry quality assessment network (GQANet) and alist-wise rank learning network (LRLNet). The proposed LRL-GQA formulates theno-reference GQA as a list-wise rank problem, with the objective of directlyoptimizing the entire quality ordering. Specifically, a large datasetcontaining a variety of geometry-only distortions is constructed first, namedLRL dataset, in which each sample is label-free but coupled with qualityranking information. Then, the GQANet is designed to capture intrinsicmulti-scale patch-wise geometric features in order to predict a quality indexfor each point cloud. After that, the LRLNet leverages the LRL dataset and alikelihood loss to train the GQANet and ranks the input list of degraded pointclouds according to their distortion levels. In addition, the pre-trainedGQANet can be fine-tuned further to obtain absolute quality scores.Experimental results demonstrate the superior performance of the proposedno-reference LRL-GQA method compared with existing full-reference GQA metrics.</description>
      <author>example@mail.com (Zheng Li, Bingxu Xie, Chao Chu, Weiqing Li, Zhiyong Su)</author>
      <guid isPermaLink="false">2502.11726v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable speech deepfake detection via meta-learned LoRA</title>
      <link>http://arxiv.org/abs/2502.10838v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了利用元学习和LoRA适配器结合的方法，以应对深度伪造检测中的分布变化问题。&lt;h4&gt;背景&lt;/h4&gt;深度伪造检测面临的问题是标签固定但深度伪造样本的生成方法会改变。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够泛化的深度伪造检测方法，该方法可以适应各种不同类型的攻击。&lt;h4&gt;方法&lt;/h4&gt;采用元学习和LoRA适配器来学习训练数据中所有攻击类型共有的结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入元学习技术，可以使模型更好地掌握不同攻击模式下的共享特性，从而提高泛化能力。&lt;h4&gt;结论&lt;/h4&gt;利用元学习结合LoRA的技术能够有效应对深度伪造样本的分布变化问题。&lt;h4&gt;翻译&lt;/h4&gt;通用的深度伪造检测可以被定义为一种标签固定但数据生成分布发生变化的问题。我们可以在训练时使用选定的攻击类型和真实数据集，但是攻击者可以通过改变种子重新训练生成器来制造新的攻击。一个合理的方法是将所有不同类型的攻击模式在训练阶段整合在一起。我们的方法利用了元学习结合LoRA适配器技术来从训练集中学习出适用于各种攻击类型的数据结构特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizable deepfake detection can be formulated as a detection problemwhere labels (bonafide and fake) are fixed but distributional drift affects thedeepfake set. We can always train our detector with one-selected attacks andbonafide data, but an attacker can generate new attacks by just retraining hisgenerator with a different seed. One reasonable approach is to simply pool alldifferent attack types available in training time. Our proposed approach is toutilize meta-learning in combination with LoRA adapters to learn the structurein the training data that is common to all attack types.</description>
      <author>example@mail.com (Janne Laakkonen, Ivan Kukanov, Ville Hautamäki)</author>
      <guid isPermaLink="false">2502.10838v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A-MEM: Agentic Memory for LLM Agents</title>
      <link>http://arxiv.org/abs/2502.12110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于大型语言模型代理的新型记忆系统，这种系统能动态地组织记忆，并根据Zettelkasten方法创建知识网络。&lt;h4&gt;背景&lt;/h4&gt;现有的记忆系统虽然能够存储和检索信息，但缺乏对复杂任务的适应性和灵活的记忆结构，限制了它们在不同任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以自动识别、链接相关记忆并随时间演化的动态记忆管理系统，以增强大型语言模型代理的能力。&lt;h4&gt;方法&lt;/h4&gt;结合Zettelkasten的知识组织原则和基于代理的决策灵活性，通过动态索引和关联构建互联知识网络。每个新记忆都被记录为包含多个结构化属性（如上下文描述、关键词和标签）的综合笔记，并与历史记忆进行比较以建立有意义的联系。&lt;h4&gt;主要发现&lt;/h4&gt;该系统的实验结果表明，在六个基础模型上相较于现有最先进的基准系统有显著改进，这表明动态组织的记忆方法可以有效提升大型语言模型代理在实际任务中的表现。&lt;h4&gt;结论&lt;/h4&gt;通过引入一种新颖的记忆管理系统，论文解决了当前记忆系统对于复杂现实世界任务适应性不足的问题，并为未来的大型语言模型研究提供了新的思路和方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新提出的用于大型语言模型（LLM）代理的记忆系统。该系统旨在解决现有记忆系统的局限性问题，这些系统虽然能够实现基本的存储和检索功能，但缺乏灵活的记忆组织结构。论文中的解决方案是通过引入一种基于Zettelkasten方法、具备动态索引和关联能力的知识网络，来增强大型语言模型在不同任务中应用的能力。这种方法允许新记忆被整合进现有的知识体系，并触发对已有信息的更新或重新评估，从而实现更智能的记忆管理方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While large language model (LLM) agents can effectively use external toolsfor complex real-world tasks, they require memory systems to leveragehistorical experiences. Current memory systems enable basic storage andretrieval but lack sophisticated memory organization, despite recent attemptsto incorporate graph databases. Moreover, these systems' fixed operations andstructures limit their adaptability across diverse tasks. To address thislimitation, this paper proposes a novel agentic memory system for LLM agentsthat can dynamically organize memories in an agentic way. Following the basicprinciples of the Zettelkasten method, we designed our memory system to createinterconnected knowledge networks through dynamic indexing and linking. When anew memory is added, we generate a comprehensive note containing multiplestructured attributes, including contextual descriptions, keywords, and tags.The system then analyzes historical memories to identify relevant connections,establishing links where meaningful similarities exist. Additionally, thisprocess enables memory evolution - as new memories are integrated, they cantrigger updates to the contextual representations and attributes of existinghistorical memories, allowing the memory network to continuously refine itsunderstanding. Our approach combines the structured organization principles ofZettelkasten with the flexibility of agent-driven decision making, allowing formore adaptive and context-aware memory management. Empirical experiments on sixfoundation models show superior improvement against existing SOTA baselines.The source code is available at https://github.com/WujiangXu/AgenticMemory.</description>
      <author>example@mail.com (Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang)</author>
      <guid isPermaLink="false">2502.12110v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Reinforcement Learning-Based User Scheduling for Collaborative Perception</title>
      <link>http://arxiv.org/abs/2502.10456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于深度强化学习的V2X用户调度算法，以优化协作感知中的通信资源利用。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶中独立感知系统由于传感范围有限和远距离遮挡问题而存在潜在风险。通过使用车辆到一切(V2X)通信来促进联网与自动驾驶汽车及路边单元间的合作可以提高感知精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够优化V2X通信资源调度的深度强化学习算法，以实现高效的协作感知。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于双层深度Q网络(DDQN)的用户调度框架SchedCP，该框架结合信道状态信息(CSI)和语义信息，将传统的依赖标签的目标重构为无标签的目标，以便于3D目标检测。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果验证了所提方法在协作感知中的有效性和鲁棒性。此外，通过案例研究展示了算法如何根据即时的CSI和感知语义动态调整调度决策。&lt;h4&gt;结论&lt;/h4&gt;SchedCP框架提供了一种改进V2X用户调度的新途径，它有效地解决了由于通信资源有限而无法传输所有传感数据的问题。&lt;h4&gt;翻译&lt;/h4&gt;独立运行的自动驾驶感知系统面临传感器检测范围有限及远距离遮挡导致的重大问题。为了解决这些问题，并通过车辆与路边单元之间的V2X通讯来提高感知精度，本研究提出了一个基于深度强化学习的方法来进行用户调度优化。在获取感知标签难度大的情况下，我们创新性地将传统的依赖于标签的目标转变为无需标签的准则，这主要是由于3D目标检测的特点所决定的。通过结合信道状态信息和语义信息，设计了一个名为SchedCP的基于双层深度Q网络(DDQN)的用户调度框架以支持协作感知，并且实验表明该方法相比传统V2X调度方式在效率和鲁棒性方面具有优势。最后，我们还提供了一项案例研究来展示如何根据即时信道状态信息和感知语义调整调度决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stand-alone perception systems in autonomous driving suffer from limitedsensing ranges and occlusions at extended distances, potentially resulting incatastrophic outcomes. To address this issue, collaborative perception isenvisioned to improve perceptual accuracy by using vehicle-to-everything (V2X)communication to enable collaboration among connected and autonomous vehiclesand roadside units. However, due to limited communication resources, it isimpractical for all units to transmit sensing data such as point clouds orhigh-definition video. As a result, it is essential to optimize the schedulingof communication links to ensure efficient spectrum utilization for theexchange of perceptual data. In this work, we propose a deep reinforcementlearning-based V2X user scheduling algorithm for collaborative perception.Given the challenges in acquiring perceptual labels, we reformulate theconventional label-dependent objective into a label-free goal, based oncharacteristics of 3D object detection. Incorporating both channel stateinformation (CSI) and semantic information, we develop a double deep Q-Network(DDQN)-based user scheduling framework for collaborative perception, namedSchedCP. Simulation results verify the effectiveness and robustness of SchedCPcompared with traditional V2X scheduling methods. Finally, we present a casestudy to illustrate how our proposed algorithm adaptively modifies thescheduling decisions by taking both instantaneous CSI and perceptual semanticsinto account.</description>
      <author>example@mail.com (Yandi Liu, Guowei Liu, Le Liang, Hao Ye, Chongtao Guo, Shi Jin)</author>
      <guid isPermaLink="false">2502.10456v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Graph Topic Modeling with Topic Tree-based Transformer</title>
      <link>http://arxiv.org/abs/2502.11345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个集成文本内部主题层次和文档间图结构的模型，以统一处理文档中的复杂信息。&lt;h4&gt;背景&lt;/h4&gt;现有的Hyperbolic Graph Neural Networks (HGNNs)在捕捉图层级结构方面表现出色，但无法很好地建模文档中的丰富语义。同时，大多数Hierarchical Topic Models (HTMs)专注于文本内容内的主题层次发现，而忽略了文档间链接的图邻接关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来整合话题层次和图层级到统一的Transformer模型中。&lt;h4&gt;方法&lt;/h4&gt;设计了一个主题树，并提出了Hyperbolic Doubly Recurrent Neural Network（双循环神经网络），利用双曲空间来建模祖先结构和同辈结构，同时在每层Transformer中嵌入两者以学习统一表示。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够有效地结合话题层次和图层级信息，在有监督和无监督实验中表现出色。&lt;h4&gt;结论&lt;/h4&gt;新的Hierarchical Graph Topic Modeling Transformer成功地整合了文本内部的主题层次与文档间的关系，展示了其在处理复杂结构化数据中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Textual documents are commonly connected in a hierarchical graph structurewhere a central document links to others with an exponentially growingconnectivity. Though Hyperbolic Graph Neural Networks (HGNNs) excel atcapturing such graph hierarchy, they cannot model the rich textual semanticswithin documents. Moreover, text contents in documents usually discuss topicsof different specificity. Hierarchical Topic Models (HTMs) discover such latenttopic hierarchy within text corpora. However, most of them focus on the textualcontent within documents, and ignore the graph adjacency across interlinkeddocuments. We thus propose a Hierarchical Graph Topic Modeling Transformer tointegrate both topic hierarchy within documents and graph hierarchy acrossdocuments into a unified Transformer. Specifically, to incorporate topichierarchy within documents, we design a topic tree and infer a hierarchicaltree embedding for hierarchical topic modeling. To preserve both topic andgraph hierarchies, we design our model in hyperbolic space and proposeHyperbolic Doubly Recurrent Neural Network, which models ancestral andfraternal tree structure. Both hierarchies are inserted into each Transformerlayer to learn unified representations. Both supervised and unsupervisedexperiments verify the effectiveness of our model.</description>
      <author>example@mail.com (Delvin Ce Zhang, Menglin Yang, Xiaobao Wu, Jiasheng Zhang, Hady W. Lauw)</author>
      <guid isPermaLink="false">2502.11345v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>The Worse The Better: Content-Aware Viewpoint Generation Network for Projection-related Point Cloud Quality Assessment</title>
      <link>http://arxiv.org/abs/2502.11710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in IEEE Transactions on Circuits and Systems for  Video Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于木桶理论的新视角生成网络(CAVGN)，该网络考虑降质点云的几何和属性特征分布，以学习更好的视点。&lt;h4&gt;背景&lt;/h4&gt;现有的投影相关PCQA方法在不同视图设置下预测的质量评分不稳定且变化显著。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新的内容感知视点生成网络(CAVGN)来解决现有问题，该网络能够更好地优化视角。&lt;h4&gt;方法&lt;/h4&gt;1. 提出的CAVGN分别提取整个输入点云的多尺度几何和纹理特征；2. 对每个默认独立于内容的视角，将提取到的几何和纹理特征进行细化，聚焦于对应部分的可见区域；3. 将精细化后的几何和纹理特性合并生成优化视角。&lt;h4&gt;主要发现&lt;/h4&gt;通过自监督视点排序网络(SSVRN)选择质量投影图像最差的视点来构建默认-优化视角数据集，实验表明使用所提出的CAVGN生成的视点可以提高基于投影的相关PCQA方法的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究成功开发了一种新的内容感知视角生成机制(CAVGN)，在多种情况下提高了PCQA的质量评分预测稳定性。&lt;h4&gt;翻译&lt;/h4&gt;通过实验证明现有的点云质量评估(PCQA)方法存在最终预测质量分数不稳定的问题。本文提出基于“木桶理论”的全新视角生成网络，该网络根据降质点云的几何及属性特性分布来学习更好的视图角度，并利用自监督训练技术提高投影相关PCQA方法性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2025.3541445&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Through experimental studies, however, we observed the instability of finalpredicted quality scores, which change significantly over different viewpointsettings. Inspired by the "wooden barrel theory", given the defaultcontent-independent viewpoints of existing projection-related PCQA approaches,this paper presents a novel content-aware viewpoint generation network (CAVGN)to learn better viewpoints by taking the distribution of geometric andattribute features of degraded point clouds into consideration. Firstly, theproposed CAVGN extracts multi-scale geometric and texture features of theentire input point cloud, respectively. Then, for each defaultcontent-independent viewpoint, the extracted geometric and texture features arerefined to focus on its corresponding visible part of the input point cloud.Finally, the refined geometric and texture features are concatenated togenerate an optimized viewpoint. To train the proposed CAVGN, we present aself-supervised viewpoint ranking network (SSVRN) to select the viewpoint withthe worst quality projected image to construct a default-optimized viewpointdataset, which consists of thousands of paired default viewpoints andcorresponding optimized viewpoints. Experimental results show that theprojection-related PCQA methods can achieve higher performance using theviewpoints generated by the proposed CAVGN.</description>
      <author>example@mail.com (Zhiyong Su, Bingxu Xie, Zheng Li, Jincan Wu, Weiqing Li)</author>
      <guid isPermaLink="false">2502.11710v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Fast Transmission Control Adaptation for URLLC via Channel Knowledge Map and Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.10777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures. This paper has been submitted to IEEE Internet  of Things Journal for possible publication (Second revision completed)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在无线环境中提供超高可靠低延迟通信（URLLC）的方法，以支持关键任务的物联网服务。&lt;h4&gt;背景&lt;/h4&gt;在未知信道分布的无线环境中，为实现超可靠和低延时通信(URLLC)，需要解决传输控制适应性问题。&lt;h4&gt;目的&lt;/h4&gt;提出两种解决方案来满足URLLC的要求，并验证它们的适应能力。&lt;h4&gt;方法&lt;/h4&gt;{'第一种方案': '功率缩放方案结合深度强化学习(DRL)算法，在不重新训练的情况下使用信道知识图(CKM)，该图利用历史信道增益样本中的空间相关性。', '第二种方案': '基于模型无关的元学习(MAML)的元强化学习算法，根据不同的信道分布进行训练，并能迅速适应新的环境。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'第一种方法': 'DRL算法在各种服务质量(QoS)约束下能够有效满足URLLC的要求。', '第二种方法': '功率缩放方案和元强化学习算法的适应能力得到了验证，能够在有限步骤内调整并快速适应新环境。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的两种解决方案都能有效地解决无线环境中未知信道分布下的超可靠低延迟通信问题，并满足关键任务物联网服务的需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文考虑了在具有未知信道分布的无线环境中为实现关键任务的物联网服务提供超高可靠低延时通信(URLLC)的方法。这些方法依赖于目标区域中少数几个位置的历史信道增益样本。我们根据URLLC约束，在整个目标区域内提出一个复杂的传输控制适应性问题，然后提出了两种解决方案来解决这个问题。第一个是功率缩放方案结合深度强化学习(DRL)算法，利用信道知识图(CKM)，无需重新训练就能使用该图的信道特征的空间相关性。第二个方案是一种基于模型无关元学习(MAML)的元强化学习算法，它根据已知的不同分布信道增益样本进行训练，并能在少量梯度更新后快速适应新环境。模拟结果表明，DRL基线算法在各种服务质量(QoS)约束下能有效满足URLLC的要求。然后验证了功率缩放方案和元强化学习算法的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper considers methods for delivering ultra reliable low latencycommunication (URLLC) to enable mission-critical Internet of Things (IoT)services in wireless environments with unknown channel distribution. Themethods rely upon the historical channel gain samples of a few locations in atarget area. We formulate a non-trivial transmission control adaptation problemacross the target area under the URLLC constraints. Then we propose twosolutions to solve this problem. The first is a power scaling scheme inconjunction with the deep reinforcement learning (DRL) algorithm with the helpof the channel knowledge map (CKM) without retraining, where the CKM employsthe spatial correlation of the channel characteristics from the historicalchannel gain samples. The second solution is model agnostic meta-learning(MAML) based metareinforcement learning algorithm that is trained from theknown channel gain samples following distinct channel distributions and canquickly adapt to the new environment within a few steps of gradient update.Simulation results indicate that the DRL-based algorithm can effectively meetthe reliability requirement of URLLC under various quality-of-service (QoS)constraints. Then the adaptation capabilities of the power scaling scheme andmeta-reinforcement learning algorithm are also validated.</description>
      <author>example@mail.com (Hongsen Peng, Tobias Kallehauge, Meixia Tao, Petar Popovski)</author>
      <guid isPermaLink="false">2502.10777v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Controlling Neural Collapse Enhances Out-of-Distribution Detection and Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.10691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度神经网络中的OOD检测和泛化之间的关系，并提出了通过控制神经崩溃（NC）来解决这两者之间权衡的方法。&lt;h4&gt;背景&lt;/h4&gt;在深度神经网络中，OO D检测和泛化的研究非常广泛，但它们之间的联系仍未被充分理解。&lt;h4&gt;目的&lt;/h4&gt;探讨神经崩溃与OOD检测及泛化的关系，提出一种可以同时改善这两种任务的新方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一个理论框架来连接神经崩溃到OOD检测和泛化的关联，并展示了熵正则化如何减少NC以提高泛化性能，而固定SIMPLEX等角紧致框架投影器如何强制执行NC以便于更好的检测。基于这些见解，提出了一种控制不同深度神经网络层中NC的方法。&lt;h4&gt;主要发现&lt;/h4&gt;神经崩溃的强度与OOD检测和泛化的权衡关系密切：更强的神经崩溃有助于OOD检测但损害了泛化能力；较弱的神经崩溃则有利于泛化而牺牲了一些检测性能。因此，单一特征空间无法同时完成这两项任务。&lt;h4&gt;结论&lt;/h4&gt;通过控制不同深度神经网络层中的神经崩溃程度，可以在OOD检测和泛化之间找到一种折衷方案，并且实验结果表明这种方法在不同的OOD数据集和DNN架构上表现优异。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection and OOD generalization are widely studiedin Deep Neural Networks (DNNs), yet their relationship remains poorlyunderstood. We empirically show that the degree of Neural Collapse (NC) in anetwork layer is inversely related with these objectives: stronger NC improvesOOD detection but degrades generalization, while weaker NC enhancesgeneralization at the cost of detection. This trade-off suggests that a singlefeature space cannot simultaneously achieve both tasks. To address this, wedevelop a theoretical framework linking NC to OOD detection and generalization.We show that entropy regularization mitigates NC to improve generalization,while a fixed Simplex Equiangular Tight Frame (ETF) projector enforces NC forbetter detection. Based on these insights, we propose a method to control NC atdifferent DNN layers. In experiments, our method excels at both tasks acrossOOD datasets and DNN architectures.</description>
      <author>example@mail.com (Md Yousuf Harun, Jhair Gallardo, Christopher Kanan)</author>
      <guid isPermaLink="false">2502.10691v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Following the Autoregressive Nature of LLM Embeddings via Compression and Alignment</title>
      <link>http://arxiv.org/abs/2502.11401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的对比学习方法AutoRegEmbed，该方法利用嵌入条件概率分布来解决大型语言模型(LLM)在作为密集文本编码器时遇到的问题。&lt;h4&gt;背景&lt;/h4&gt;当前趋势是将LLM用作通过对比学习实现的密集文本编码器。然而，由于LLM嵌入预测下一个令牌的概率分布，它们本质上具有生成性和分散性，这与需要捕获全文语义并通过余弦相似度对齐的对比学习相矛盾。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决这一问题，使得大型语言模型在作为密集文本编码器时能够更好地利用其预训练能力。&lt;h4&gt;方法&lt;/h4&gt;提出的方法AutoRegEmbed整合了信息压缩和条件分布对齐两个核心任务。其中，信息压缩任务将文本编码到嵌入空间中，确保嵌入向量捕获全局语义；而条件分布对齐任务则通过利用嵌入的条件分布来实现与正样本嵌入的对齐，并同时降低从文本嵌入生成负样本的概率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该方法在使用相同数据量的情况下显著优于传统的对比学习方法，且性能可与当前最先进的模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;通过利用嵌入条件概率分布的新对比学习方法AutoRegEmbed有效地解决了现有问题，并展示了其在文本编码任务中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A new trend uses LLMs as dense text encoders via contrastive learning.However, since LLM embeddings predict the probability distribution of the nexttoken, they are inherently generative and distributive, conflicting withcontrastive learning, which requires embeddings to capture full-text semanticsand align via cosine similarity. This discrepancy hinders the full utilizationof LLMs' pre-training capabilities, resulting in inefficient learning. Inresponse to this issue, we propose AutoRegEmbed, a new contrastive learningmethod built on embedding conditional probability distributions, whichintegrates two core tasks: information compression and conditional distributionalignment. The information compression task encodes text into the embeddingspace, ensuring that the embedding vectors capture global semantics. Theconditional distribution alignment task focuses on aligning text embeddingswith positive samples embeddings by leveraging the conditional distribution ofembeddings while simultaneously reducing the likelihood of generating negativesamples from text embeddings, thereby achieving embedding alignment anduniformity. Experimental results demonstrate that our method significantlyoutperforms traditional contrastive learning approaches and achievesperformance comparable to state-of-the-art models when using the same amount ofdata.</description>
      <author>example@mail.com (Jingcheng Deng, Zhongtao Jiang, Liang Pang, Liwei Chen, Kun Xu, Zihao Wei, Huawei Shen, Xueqi Cheng)</author>
      <guid isPermaLink="false">2502.11401v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</title>
      <link>http://arxiv.org/abs/2502.08279v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VISTA是一个专门用于科学领域视频到文本摘要的大型数据集，包含18,599个AI会议演讲及其对应的论文摘要。&lt;h4&gt;背景&lt;/h4&gt;将录制的视频转换为简洁准确的文字摘要在多模态学习中是一项日益增长的挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍VISTA数据集，并评估最先进的大规模模型在此任务上的表现以及使用基于计划框架的效果。&lt;h4&gt;方法&lt;/h4&gt;基准测试了当前最佳的大规模模型，同时采用了一种基于规划的方法来更好地捕捉摘要结构化的特性。&lt;h4&gt;主要发现&lt;/h4&gt;无论是人工还是自动评价都表明明确的规划能够提高总结的质量和事实的一致性，但与人类性能相比仍存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;科学视频摘要化任务仍然面临挑战，这表明模型在理解和生成高质量科学文本摘要方面仍有改进的空间。&lt;h4&gt;翻译&lt;/h4&gt;将录制的视频转换为简洁准确的文字摘要在多模态学习中是一项日益增长的挑战。本文介绍了一个专门用于科学研究领域的视频到文字总结的数据集VISTA。该数据集包含18,599个AI会议演讲及其对应的论文摘要。我们基准测试了最先进的大规模模型，并应用了一种基于规划的方法，以更好地捕捉摘要结构化的特性。无论是人工还是自动评价都确认明确的计划能够提高总结的质量和事实的一致性，但是与人类性能相比仍存在显著差距，这表明科学视频摘要化任务仍然面临挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transforming recorded videos into concise and accurate textual summaries is agrowing challenge in multimodal learning. This paper introduces VISTA, adataset specifically designed for video-to-text summarization in scientificdomains. VISTA contains 18,599 recorded AI conference presentations paired withtheir corresponding paper abstracts. We benchmark the performance ofstate-of-the-art large models and apply a plan-based framework to bettercapture the structured nature of abstracts. Both human and automatedevaluations confirm that explicit planning enhances summary quality and factualconsistency. However, a considerable gap remains between models and humanperformance, highlighting the challenges of scientific video summarization.</description>
      <author>example@mail.com (Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg)</author>
      <guid isPermaLink="false">2502.08279v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications</title>
      <link>http://arxiv.org/abs/2502.12096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在这篇文章中，我们介绍了token通信（TokCom），这是一种统一的框架，在生成式语义通信（GenSC）中利用跨模态上下文信息。TokCom是一个新的范式，受到最近生成基础模型和多模态大型语言模型(GFM/MLLMs)成功的启发，其中通信单位是token，这使得在发送方和接收方可以高效地进行基于transformer的token处理。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于生成的基础模型和多模态大规模语言模型（GFM/MLLMs）取得了显著的成功。这些模型能够有效地利用跨模态上下文信息，并且通过引入token通信(TokCom)，可以在无线通信系统中更好地整合这种能力。&lt;h4&gt;目的&lt;/h4&gt;文章旨在探讨在生成式语义通信(GenSC)中利用上下文的潜在机会和挑战，研究如何将基于GFM/MLLMs的token处理集成到语义通信系统中以有效利用跨模态上下文信息，并提出未来无线网络各层上高效TokenCom的关键原则。&lt;h4&gt;方法&lt;/h4&gt;文中探讨了TokCom在不同层级上的实现方式，特别是在图像传输场景下如何利用跨模态背景信息。通过这种方式，能够显著提升带宽效率并保持语义或感知质量的损失最小化。&lt;h4&gt;主要发现&lt;/h4&gt;文章展示了一个基于GenSC的实验实例，在该实验中使用跨模态上下文信息可以将带宽效率提高70.8%，同时确保语义/感知质量几乎不受影响。&lt;h4&gt;结论&lt;/h4&gt;研究确定了未来在无线网络中实现和采用TokCom的研究方向，以进一步增强其效果并推动相关技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce token communications (TokCom), a unifiedframework to leverage cross-modal context information in generative semanticcommunications (GenSC). TokCom is a new paradigm, motivated by the recentsuccess of generative foundation models and multimodal large language models(GFM/MLLMs), where the communication units are tokens, enabling efficienttransformer-based token processing at the transmitter and receiver. In thispaper, we introduce the potential opportunities and challenges of leveragingcontext in GenSC, explore how to integrate GFM/MLLMs-based token processinginto semantic communication systems to leverage cross-modal contexteffectively, present the key principles for efficient TokCom at various layersin future wireless networks. We demonstrate the corresponding TokCom benefitsin a GenSC setup for image, leveraging cross-modal context information, whichincreases the bandwidth efficiency by 70.8% with negligible loss ofsemantic/perceptual quality. Finally, the potential research directions areidentified to facilitate adoption of TokCom in future wireless networks.</description>
      <author>example@mail.com (Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Rahim Tafazolli, Mehdi Bennis, Dusit Niyato)</author>
      <guid isPermaLink="false">2502.12096v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Subspace Learning for Surface Anomaly Classification Based on 3D Point Cloud Data</title>
      <link>http://arxiv.org/abs/2502.11669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于深度子空间学习的3D异常分类模型，该模型通过轻量级编码器提取潜在表示，并将每个类视为一个子空间来处理类内变异和类间相似性。&lt;h4&gt;背景&lt;/h4&gt;表面异常分类对于制造系统的故障诊断和质量控制至关重要。然而，在实践中存在三个主要挑战：异常模式在类内的变化、不同类别之间的相似性和生产过程中可能出现的新类型异常，以及罕见的异常数据限制了模型的学习能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够同时解决上述挑战的方法。&lt;h4&gt;方法&lt;/h4&gt;基于深度子空间学习的3D异常分类模型。该模型利用轻量级编码器提取潜在表示，并将每个类视为一个子空间来处理类内变化，同时促进不同类别之间的区别以应对类间相似性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的模型能够更好地识别新类型的异常并达到比基准方法更好的异常分类结果。&lt;h4&gt;结论&lt;/h4&gt;该模型在广泛数值实验中展示了其优越的性能和有效性。&lt;h4&gt;翻译&lt;/h4&gt;表面异常分类对于制造系统的故障诊断和质量控制至关重要。然而，实践中存在三个挑战：一是异常模式在类内的变化以及不同类别之间的相似性；二是生产过程中可能出现的新类型异常需要准确检测；三是罕见的异常数据限制了模型的学习能力。为解决这些挑战，本文提出了一种基于深度子空间学习的3D异常分类模型，该模型能够更好地处理类内变异和类间相似性，并具备识别新类型异常的能力。实验结果表明该方法优于基准方法，在异常检测方面表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface anomaly classification is critical for manufacturing system faultdiagnosis and quality control. However, the following challenges always hinderaccurate anomaly classification in practice: (i) Anomaly patterns exhibitintra-class variation and inter-class similarity, presenting challenges in theaccurate classification of each sample. (ii) Despite the predefined classes,new types of anomalies can occur during production that require to be detectedaccurately. (iii) Anomalous data is rare in manufacturing processes, leading tolimited data for model learning. To tackle the above challenges simultaneously,this paper proposes a novel deep subspace learning-based 3D anomalyclassification model. Specifically, starting from a lightweight encoder toextract the latent representations, we model each class as a subspace toaccount for the intra-class variation, while promoting distinct subspaces ofdifferent classes to tackle the inter-class similarity. Moreover, the explicitmodeling of subspaces offers the capability to detect out-of-distributionsamples, i.e., new types of anomalies, and the regularization effect with muchfewer learnable parameters of our proposed subspace classifier, compared to thepopular Multi-Layer Perceptions (MLPs). Extensive numerical experimentsdemonstrate our method achieves better anomaly classification results thanbenchmark methods, and can effectively identify the new types of anomalies.</description>
      <author>example@mail.com (Xuanming Cao, Chengyu Tao, Juan Du)</author>
      <guid isPermaLink="false">2502.11669v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking the Potential of Generative AI through Neuro-Symbolic Architectures: Benefits and Limitations</title>
      <link>http://arxiv.org/abs/2502.11269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  54 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了神经符号人工智能（NSAI）的不同架构，探讨它们如何结合深度学习处理大规模和非结构化数据的能力与符号方法的结构化推理能力。研究评估了这些架构在泛化、推理能力、迁移能力和可解释性等标准下的表现。&lt;h4&gt;背景&lt;/h4&gt;神经符号人工智能通过整合深度学习和符号方法的优势，在人工智能领域代表了一种变革性的方法，解决了透明度和数据效率等问题。&lt;h4&gt;目的&lt;/h4&gt;系统地研究不同的NSAI架构及其与当前AI技术（如增强检索生成、图神经网络、强化学习和多智能体系统）的结合方式，并评估它们在各种标准下的性能表现。&lt;h4&gt;方法&lt;/h4&gt;论文详细分析了不同NSAI架构如何整合神经和符号组件，以及这些架构如何与现有AI技术相适应。然后对这些模型进行了全面的比较分析。&lt;h4&gt;主要发现&lt;/h4&gt;Neuro &gt; Symbolic &lt; Neural模型（即具有明确象征性和较强神经网络能力的模型）在所有评估标准中均表现出色，这表明了这种架构利用先进科技如多智能体系统的优势。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了不同NSAI架构之间的比较分析，并指出了每种架构的优点和局限性。特别强调的是，结合了象征性和神经网络特征的新架构在未来人工智能技术中的潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其中文翻译及总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuro-symbolic artificial intelligence (NSAI) represents a transformativeapproach in artificial intelligence (AI) by combining deep learning's abilityto handle large-scale and unstructured data with the structured reasoning ofsymbolic methods. By leveraging their complementary strengths, NSAI enhancesgeneralization, reasoning, and scalability while addressing key challenges suchas transparency and data efficiency. This paper systematically studies diverseNSAI architectures, highlighting their unique approaches to integrating neuraland symbolic components. It examines the alignment of contemporary AItechniques such as retrieval-augmented generation, graph neural networks,reinforcement learning, and multi-agent systems with NSAI paradigms. This studythen evaluates these architectures against comprehensive set of criteria,including generalization, reasoning capabilities, transferability, andinterpretability, therefore providing a comparative analysis of theirrespective strengths and limitations. Notably, the Neuro &gt; Symbolic &lt; Neuromodel consistently outperforms its counterparts across all evaluation metrics.This result aligns with state-of-the-art research that highlight the efficacyof such architectures in harnessing advanced technologies like multi-agentsystems.</description>
      <author>example@mail.com (Oualid Bougzime, Samir Jabbar, Christophe Cruz, Frédéric Demoly)</author>
      <guid isPermaLink="false">2502.11269v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Demographic Attributes Prediction from Speech Using WavLM Embeddings</title>
      <link>http://arxiv.org/abs/2502.12007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted by The Conference on Information Sciences and  Systems (CISS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文介绍了一种基于WavLM特征的通用分类器，用于从语音中推断人口统计学特征，如年龄、性别、母语、教育背景和国家。这种人口统计信息预测在语言学习、无障碍技术和数字取证等应用中扮演着关键角色，使技术更加个性化和包容性。&lt;h4&gt;研究背景&lt;/h4&gt;人口统计数据的预测对于开发个性化的和包容性的技术具有重要意义，特别是在语言学习、无障碍技术以及数字取证等领域。&lt;h4&gt;研究目的&lt;/h4&gt;利用预训练模型进行嵌入提取，提出了一种能够识别与人口统计特征相关的声学和语言关键特征的框架，并通过各种数据集验证了该方法的有效性。&lt;h4&gt;采用的方法&lt;/h4&gt;基于WavLM特征，提出了一个用于预测年龄、性别等人口统计信息的分类器。同时利用大量的预训练模型来确保系统的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;{'年龄预测误差': '提出的系统在年龄预测任务上的平均绝对误差（MAE）为4.94', '性别分类准确性': '性别分类准确率超过99.81%', '改进幅度': '相比于现有模型，本研究的系统在各个任务中的性能提高了最多30%（以相对MAE衡量），以及高达10%的精度和F1分数提升'}&lt;h4&gt;结论&lt;/h4&gt;这项研究表明了说话人多样性的新见解，并为基于语音的人口统计特征分析提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a general classifier based on WavLM features, to inferdemographic characteristics, such as age, gender, native language, education,and country, from speech. Demographic feature prediction plays a crucial rolein applications like language learning, accessibility, and digital forensics,enabling more personalized and inclusive technologies. Leveraging pretrainedmodels for embedding extraction, the proposed framework identifies key acousticand linguistic fea-tures associated with demographic attributes, achieving aMean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracyfor gender classification across various datasets. Our system improves uponexisting models by up to relative 30% in MAE and up to relative 10% in accuracyand F1 scores across tasks, leveraging a diverse range of datasets and largepretrained models to ensure robustness and generalizability. This study offersnew insights into speaker diversity and provides a strong foundation for futureresearch in speech-based demographic profiling.</description>
      <author>example@mail.com (Yuchen Yang, Thomas Thebaud, Najim Dehak)</author>
      <guid isPermaLink="false">2502.12007v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Real-time Neural Rendering of LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2502.11618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 1 table,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;静态LiDAR扫描仪可以生成准确、密集且彩色的点云数据，但由于包含明显的伪影（如遮挡导致的数据缺失），直接显示时效果较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法，用于从这些LiDAR扫描中渲染逼真的图像，并不涉及昂贵的预处理或特定场景模型的训练。&lt;h4&gt;方法&lt;/h4&gt;{'关键步骤1': '使用朴素投影法（1x1像素）将点云数据投影到输出视图上。该方法速度快且保留细节，但会导致背景点泄漏至前景像素区域形成难以理解的结果。', '关键步骤2': '利用U-Net深度卷积模型和基于深度的预处理算法来优化投影结果。', '具体问题解决': '提出的解决方案可以有效地应对LiDAR特有的问题如遮挡导致的数据缺失、颜色不一致性和点密度变化等。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过合成训练数据的方法解决了地面真实图像不完全对齐的问题，该方法在使用现成GPU时能够实现实时渲染速度，并且在速度和质量上都优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能在不需要昂贵预处理或特定场景模型训练的情况下生成逼真的LiDAR扫描图像，具有速度快、效果好的优点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Static LiDAR scanners produce accurate, dense, colored point clouds, butoften contain obtrusive artifacts which makes them ill-suited for directdisplay. We propose an efficient method to render photorealistic images of suchscans without any expensive preprocessing or training of a scene-specificmodel. A naive projection of the point cloud to the output view using 1x1pixels is fast and retains the available detail, but also results inunintelligible renderings as background points leak in between the foregroundpixels. The key insight is that these projections can be transformed into arealistic result using a deep convolutional model in the form of a U-Net, and adepth-based heuristic that prefilters the data. The U-Net also handlesLiDAR-specific problems such as missing parts due to occlusion, colorinconsistencies and varying point densities. We also describe a method togenerate synthetic training data to deal with imperfectly-aligned ground truthimages. Our method achieves real-time rendering rates using an off-the-shelfGPU and outperforms the state-of-the-art in both speed and quality.</description>
      <author>example@mail.com (Joni Vanherck, Brent Zoomers, Tom Mertens, Lode Jorissen, Nick Michiels)</author>
      <guid isPermaLink="false">2502.11618v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Large Language-Geometry Model: When LLM meets Equivariance</title>
      <link>http://arxiv.org/abs/2502.11149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的框架EquiLLM，它将几何感知提示、等变编码器、大语言模型和等变适配器结合在一起，用于表示三维物理系统。&lt;h4&gt;背景&lt;/h4&gt;现有的基于几何图神经网络（GNN）的方法在3D结构预测中表现出E(3)等变性，但它们难以利用广泛的外部信息。直接应用大型语言模型可以集成外部知识，但缺乏空间推理能力以及等变性保证。&lt;h4&gt;目的&lt;/h4&gt;开发一个新框架EquiLLM，它将大语言模型的能力与E(3)-等变性质结合在一起。&lt;h4&gt;方法&lt;/h4&gt;EquiLLM由四个关键组件组成：几何感知提示、等变编码器、大语言模型和等变适配器。该方法通过引导式提示指导的大语言模型处理不变特征，同时三维方向信息由等变编码器和适配器模块处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明EquiLLM在分子动力学模拟、人类运动模拟和抗体设计方面优于先前的方法，展示了其出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;EquiLLM框架成功地将大语言模型的外部知识集成能力和等变性质相结合，在多个领域表现出色，为准确预测3D物理系统的结构和动态提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;精确预测物理系统中的3D结构和动力学对于科学应用至关重要。现有的基于几何图神经网络（GNN）的方法虽然在E(3)等变性方面表现良好，但难以利用广泛的信息。直接使用大型语言模型可以整合外部知识，但缺乏空间推理能力以及确保的等变性。本文提出了一种新的框架EquiLLM，它将E(3)-等变性质与大语言模型的能力相结合。具体来说，EquiLLM由四个关键组件组成：几何感知提示、等变编码器、大语言模型和等变适配器。通过指导式提示引导的大语言模型作为高级不变特征处理器发挥作用，而三维方向信息则专门由等变编码器和适配器模块处理。实验结果表明，在分子动力学模拟、人类运动模拟和抗体设计方面，EquiLLM显著优于先前的方法，展示了其出色的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting 3D structures and dynamics of physical systems iscrucial in scientific applications. Existing approaches that rely on geometricGraph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,but they often fall in leveraging extensive broader information. While directapplication of Large Language Models (LLMs) can incorporate external knowledge,they lack the capability for spatial reasoning with guaranteed equivariance. Inthis paper, we propose EquiLLM, a novel framework for representing 3D physicalsystems that seamlessly integrates E(3)-equivariance with LLM capabilities.Specifically, EquiLLM comprises four key components: geometry-aware prompting,an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, theLLM guided by the instructive prompt serves as a sophisticated invariantfeature processor, while 3D directional information is exclusively handled bythe equivariant encoder and adaptor modules. Experimental results demonstratethat EquiLLM delivers significant improvements over previous methods acrossmolecular dynamics simulation, human motion simulation, and antibody design,highlighting its promising generalizability.</description>
      <author>example@mail.com (Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao)</author>
      <guid isPermaLink="false">2502.11149v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Without Paired Labeled Data: An End-to-End Self-Supervised Paradigm for UAV-View Geo-Localization</title>
      <link>http://arxiv.org/abs/2502.11381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级的端到端自监督框架DMNIL，用于无人机视图地理定位。该框架通过基于双路径聚类对比学习架构建模同一视图内的结构关系，并利用动态记忆驱动分层学习模块逐步挖掘局部和全局信息，提高了模型鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要依赖于需要标注成对数据进行训练的监督学习范式，这带来了高昂的数据注释成本，阻碍了大规模部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要配对训练数据的方法来克服上述限制，并提高无人机地理定位的准确性与鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种动态记忆驱动和邻域信息学习网络(DMNIL)，该框架利用基于双路径聚类的对比学习架构建模同一视图内的结构关系，同时引入了动态记忆驱动分层模块挖掘局部和全局特征。此外，还提出一种信息一致性进化学习机制来探索无人机与卫星图像之间的领域差距。&lt;h4&gt;主要发现&lt;/h4&gt;DMNIL框架在三个基准数据集上取得了接近现有最优监督方法的性能，并且无需配对训练数据的支持，证明了其计算效率及实用性。&lt;h4&gt;结论&lt;/h4&gt;提出的DMNIL网络不仅提高了地理定位精度和模型鲁棒性，而且由于不需要昂贵的数据标注过程而更加适合实际应用部署。代码即将发布。&lt;h4&gt;翻译&lt;/h4&gt;UAV-View Geo-Localization (UVGL)旨在通过检索最相似的带有GPS标签的卫星图像来确定无人机的确切位置。然而，现有的方法主要依赖于需要成对训练数据进行监督学习的方法，这带来了高昂的数据标注成本，并阻碍了大规模部署。为了克服这一限制，我们提出了一种轻量级的端到端自监督框架DMNIL（Dynamic Memory-Driven and Neighborhood Information Learning）。该框架通过基于双路径聚类对比学习架构建模同一视图内的结构关系，增强了特征的一致性和区分度。同时，提出了动态记忆驱动分层学习模块以逐步挖掘局部和全局信息，强化多级特征关联来提高模型鲁棒性。为了缩小无人机与卫星视图之间的领域差距，我们设计了一种信息一致性进化学习机制系统地探索同一视图内部的潜在关系以及跨视图领域的联系，最终构建统一的跨视图特征表示空间。在三个基准数据集上的广泛实验表明，DMNIL达到了接近最先进的监督方法的表现水平，同时保持了计算效率。值得注意的是，这种优越性是在没有依赖配对训练数据的情况下实现的，突显出该框架的实际部署潜力。代码将在近期发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAV-View Geo-Localization (UVGL) aims to ascertain the precise location of aUAV by retrieving the most similar GPS-tagged satellite image. However,existing methods predominantly rely on supervised learning paradigms thatnecessitate annotated paired data for training, which incurs substantialannotation costs and impedes large-scale deployment. To overcome thislimitation, we propose the Dynamic Memory-Driven and Neighborhood InformationLearning (DMNIL) network, a lightweight end-to-end self-supervised frameworkfor UAV-view geo-localization. The DMNIL framework utilizes a dual-pathclustering-based contrastive learning architecture as its baseline to modelintra-view structural relationships, enhancing feature consistency anddiscriminability. Additionally, a dynamic memory-driven hierarchical learningmodule is proposed to progressively mine local and global information,reinforcing multi-level feature associations to improve model robustness. Tobridge the domain gap between UAV and satellite views, we design aninformation-consistent evolutionary learning mechanism that systematicallyexplores latent correlations within intra-view neighborhoods and acrosscross-view domains, ultimately constructing a unified cross-view featurerepresentation space. Extensive experiments on three benchmarks(University-1652, SUES-200, and DenseUAV) demonstrate that DMNIL achievescompetitive performance against state-of-the-art supervised methods whilemaintaining computational efficiency. Notably, this superiority is attainedwithout relying on paired training data, underscoring the framework'spracticality for real-world deployment. Codes will be released soon.</description>
      <author>example@mail.com (Zhongwei Chen, Zhao-Xu Yang, Hai-Jun Rong)</author>
      <guid isPermaLink="false">2502.11381v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Personalized Ranking on Cascading Behavior Graphs for Accurate Multi-Behavior Recommendation</title>
      <link>http://arxiv.org/abs/2502.11335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了CascadingRank，一种用于多行为推荐的新颖图排名方法。&lt;h4&gt;背景&lt;/h4&gt;现有的多行为推荐方法分为表征学习和图排序两类。前者通过生成用户和项目的嵌入来捕捉潜在的交互模式，但常受过度平滑和频繁互动偏见的影响；后者直接计算个性化评分以更好地反映用户的偏好，但在多行为场景中的应用较少。&lt;h4&gt;目的&lt;/h4&gt;提出CascadingRank方法，利用级联行为图模型自然的行为序列，并通过迭代算法计算排名分数，确保其在平滑性、查询适应性和级联对齐方面的性能。&lt;h4&gt;方法&lt;/h4&gt;1. CascadingRank通过级联行为图来建模用户行为的自然顺序。2. 使用迭代算法计算评分以优化推荐结果。3. 提供理论分析以展示CascadingRank的有效性，收敛性和可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CascadingRank在三个真实世界数据集上优于现有技术方法，HR@10和NDCG@10分别提高了9.56%和7.16%。&lt;h4&gt;结论&lt;/h4&gt;研究表明，图排序方法适用于多行为推荐，能够显著提高推荐性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的直接中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-behavior recommendation predicts items a user may purchase by analyzingdiverse behaviors like viewing, adding to a cart, and purchasing. Existingmethods fall into two categories: representation learning and graph ranking.Representation learning generates user and item embeddings to capture latentinteraction patterns, leveraging multi-behavior properties for bettergeneralization. However, these methods often suffer from over-smoothing andbias toward frequent interactions, limiting their expressiveness. Graph rankingmethods, on the other hand, directly compute personalized ranking scores,capturing user preferences more effectively. Despite their potential, graphranking approaches have been primarily explored in single-behavior settings andremain underutilized for multi-behavior recommendation. In this paper, wepropose CascadingRank, a novel graph ranking method for multi-behaviorrecommendation. It models the natural sequence of user behaviors (e.g.,viewing, adding to cart, and purchasing) through a cascading behavior graph. Aniterative algorithm computes ranking scores, ensuring smoothness, queryfitting, and cascading alignment. Experiments on three real-world datasetsdemonstrate that CascadingRank outperforms state-of-the-art methods, with up to9.56% and 7.16% improvements in HR@10 and NDCG@10, respectively. Furthermore,we provide theoretical analysis highlighting its effectiveness, convergence,and scalability, showcasing the advantages of graph ranking in multi-behaviorrecommendation.</description>
      <author>example@mail.com (Geonwoo Ko, Minseo Jeon, Jinhong Jung)</author>
      <guid isPermaLink="false">2502.11335v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Cheesemap: A High-Performance Point-Indexing Data Structure for Neighbor~Search in LiDAR Data</title>
      <link>http://arxiv.org/abs/2502.11602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提供了一种针对点云数据的全面比较分析，引入了名为cheesemap的新数据结构来处理3D LiDAR点云，并展示了其在不同类型的点云（特别是ALS）中的性能优势。&lt;h4&gt;背景&lt;/h4&gt;点云数据作为三维空间信息的表示，在物体识别、自主导航和环境建模等任务中至关重要。高效的索引和查询对于提高这些应用的效果来说非常重要。&lt;h4&gt;目的&lt;/h4&gt;论文旨在通过比较分析各种数据结构及其邻域搜索方法，引入新的cheesemap数据结构来优化3D LiDAR点云的处理效率。&lt;h4&gt;方法&lt;/h4&gt;该研究采用了多种数据结构结合不同的邻域搜索方法对不同类型（密集、稀疏和混合）的点云进行了全面评估，并测试了新提出的cheesemap在这些情况下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，新的cheesemap数据结构在执行时间和内存消耗方面优于现有的先进技术，特别是在ALS点云中表现尤为突出。&lt;h4&gt;结论&lt;/h4&gt;cheesemap由于其高效的查询时间和较低的内存使用量，在处理三维点云的应用场景下表现出色，尤其适用于大规模稀疏和混合类型的点云数据集。&lt;h4&gt;翻译&lt;/h4&gt;点云数据作为三维空间信息的表现形式，在物体识别、自主导航以及环境建模等各个领域中扮演着重要角色。文中提出了一种新的数据结构——cheesemap，旨在更有效地索引和查询3D LiDAR点云，并针对不同的点分布情况设计了三种版本：密集型、稀疏型及混合型。实验证明，相比于现有方法，这种新型的数据结构在执行效率上具有明显的优势，尤其是在ALS（空中激光扫描）点云场景下性能尤为突出，同时其内存消耗较低，特别是在处理稀疏和混合类型数据时表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data, as the representation of three-dimensional spatialinformation, is a fundamental piece of information in various domains whereindexing and querying these point clouds efficiently is crucial for tasks suchas object recognition, autonomous navigation, and environmental modeling. Inthis paper, we present a comprehensive comparative analysis of various datastructures combined with neighboring search methods across different types ofpoint clouds. Additionally, we introduce a novel data structure, cheesemap, tohandle 3D LiDAR point clouds. Exploring the sparsity and irregularity in thedistribution of points, there are three flavors of the cheesemap: dense,sparse, and mixed. Results show that the cheesemap can outperformstate-of-the-art data structures in terms of execution time per query,particularly for ALS (Aerial Laser Scanning) point clouds. Memory consumptionis also minimal, especially in the sparse and mixed representations, making thecheesemap a suitable choice for applications involving three-dimensional pointclouds.</description>
      <author>example@mail.com (Ruben Laso, Miguel Yermo)</author>
      <guid isPermaLink="false">2502.11602v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>ILIAS: Instance-Level Image retrieval At Scale</title>
      <link>http://arxiv.org/abs/2502.11748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的测试数据集ILIAS，用于评估大规模实例级图像检索的能力。&lt;h4&gt;背景&lt;/h4&gt;当前的基准测试不足以全面评估大型基础模型和检索技术在识别特定对象时的表现。&lt;h4&gt;目的&lt;/h4&gt;创建一个大规模、跨领域多样性且带有准确真实性的测试数据集，以充分挑战现有的图像检索方法。&lt;h4&gt;方法&lt;/h4&gt;ILIAS包含了1000个物体实例的查询图片及其正样本图片，并与来自YFCC100M的数据集中的一亿张干扰图进行大规模检索。&lt;h4&gt;主要发现&lt;/h4&gt;{'模型性能差异': '特定领域微调的模型在它们擅长的领域表现优秀，但在ILIAS上却失效了；', '多域学习提升': '通过使用多个领域的类别监督来学习线性适配层可以提高性能，特别是对于视觉-语言模型来说；', '局部描述子作用': '检索重新排名中的局部描述子仍然是一个关键因素，在存在严重背景干扰的情况下尤其重要；', '文本到图像性能': '视觉-语言基础模型的文本到图像性能与对应的图像到图像情况非常接近。'}&lt;h4&gt;结论&lt;/h4&gt;ILIAS是一个评估大型基础模型和检索技术在大规模实例级图像检索中能力的有效工具。&lt;h4&gt;翻译&lt;/h4&gt;这项工作引入了ILIAS，这是一个新的测试数据集，用于评估当前和未来的基础模型以及检索方法识别特定对象的能力。相较于现有的数据集，它具有规模大、领域多样性和准确的真实标签等优势，并且其性能尚未饱和。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces ILIAS, a new test dataset for Instance-Level Imageretrieval At Scale. It is designed to evaluate the ability of current andfuture foundation models and retrieval techniques to recognize particularobjects. The key benefits over existing datasets include large scale, domaindiversity, accurate ground truth, and a performance that is far from saturated.ILIAS includes query and positive images for 1,000 object instances, manuallycollected to capture challenging conditions and diverse domains. Large-scaleretrieval is conducted against 100 million distractor images from YFCC100M. Toavoid false negatives without extra annotation effort, we include only queryobjects confirmed to have emerged after 2014, i.e. the compilation date ofYFCC100M. An extensive benchmarking is performed with the followingobservations: i) models fine-tuned on specific domains, such as landmarks orproducts, excel in that domain but fail on ILIAS ii) learning a linearadaptation layer using multi-domain class supervision results in performanceimprovements, especially for vision-language models iii) local descriptors inretrieval re-ranking are still a key ingredient, especially in the presence ofsevere background clutter iv) the text-to-image performance of thevision-language foundation models is surprisingly close to the correspondingimage-to-image case. website: https://vrg.fel.cvut.cz/ilias/</description>
      <author>example@mail.com (Giorgos Kordopatis-Zilos, Vladan Stojnić, Anna Manko, Pavel Šuma, Nikolaos-Antonios Ypsilantis, Nikos Efthymiadis, Zakaria Laskar, Jiří Matas, Ondřej Chum, Giorgos Tolias)</author>
      <guid isPermaLink="false">2502.11748v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Contrastive Learning for Feature Alignment: Insights from Housing-Household Relationship Inference</title>
      <link>http://arxiv.org/abs/2502.11205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于深度对比学习(DCL)的模型，用于分析美国社区调查(ACS)公共使用微数据样本(PUMS)中的住房与家庭之间的关系。&lt;h4&gt;背景&lt;/h4&gt;住房及住户特征是社会经济福祉的关键决定因素，但目前对它们之间相互影响的理解仍存在局限性。&lt;h4&gt;目的&lt;/h4&gt;填补知识空白，利用深度对比学习模型研究和理解住房与住户之间的联系，并提出适用于无明确标签数据问题的一般方法论框架。&lt;h4&gt;方法&lt;/h4&gt;采用双编码器的DCL架构，通过PUMS中的共现模式识别引入了一种二分K均值聚类技术来处理缺乏地面真实标签的问题。此外，模型设计考虑了住房与住户特征之间的语义差异，并且可以减少由聚类过程产生的噪声。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在特拉华州表现出比现有最佳方法更强的能力，在北卡罗莱纳州的可迁移性测试中也证明了其跨多种社会人口和地理背景的一般适用性。此外，通过SHAP值进行事后解释性人工智能分析表明：产权状态和按揭信息对于住房与住户匹配的影响大于传统重视的因素（如人员数量和房间数）。&lt;h4&gt;结论&lt;/h4&gt;研究提出的DCL模型在解决缺乏明确标签的数据问题方面表现出了优越性，并且为社会经济福祉相关领域的进一步研究提供了强有力的方法支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Housing and household characteristics are key determinants of social andeconomic well-being, yet our understanding of their interrelationships remainslimited. This study addresses this knowledge gap by developing a deepcontrastive learning (DCL) model to infer housing-household relationships usingthe American Community Survey (ACS) Public Use Microdata Sample (PUMS). Morebroadly, the proposed model is suitable for a class of problems where the goalis to learn joint relationships between two distinct entities withoutexplicitly labeled ground truth data. Our proposed dual-encoder DCL approachleverages co-occurrence patterns in PUMS and introduces a bisect K-meansclustering method to overcome the absence of ground truth labels. Thedual-encoder DCL architecture is designed to handle the semantic differencesbetween housing (building) and household (people) features while mitigatingnoise introduced by clustering. To validate the model, we generate a syntheticground truth dataset and conduct comprehensive evaluations. The model furtherdemonstrates its superior performance in capturing housing-householdrelationships in Delaware compared to state-of-the-art methods. Atransferability test in North Carolina confirms its generalizability acrossdiverse sociodemographic and geographic contexts. Finally, the post-hocexplainable AI analysis using SHAP values reveals that tenure status andmortgage information play a more significant role in housing-household matchingthan traditionally emphasized factors such as the number of persons and rooms.</description>
      <author>example@mail.com (Xiao Qian, Shangjia Dong, Rachel Davidson)</author>
      <guid isPermaLink="false">2502.11205v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs</title>
      <link>http://arxiv.org/abs/2502.11037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为多视角置换变分自编码器（MVP）的方法，用于处理缺失不规则的数据情况下的多视图表示学习。&lt;h4&gt;背景&lt;/h4&gt;当前的多视图表征学习技术在面对不规则数据缺失时会生成缺乏充分性和一致性的表征。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来解决由不完整数据引起的表示不足和一致性问题，该方法能够从不规则丢失的数据中挖掘出不同视图之间的不变关系。&lt;h4&gt;方法&lt;/h4&gt;引入了MVP模型，在变分自编码器的潜在空间内建立了跨视角对应，并通过随机排列变量来进行交叉视图生成。此外，使用循环后验置换来增强一致性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的MVP方法在具有不同缺失比率的七种多样数据集上进行了测试，证明了其在多视图聚类和生成任务中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;MVP成功地解决了由不规则丢失引起的表示不足和一致性问题，并展示了在处理缺失不规则的数据时的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：多视角表征学习（MVRL）旨在通过利用不同视图间的共享信息以及互补信息来从多视图数据中推导出统一的表征。然而，当视图以不规则方式丢失时，这种不完整数据会导致生成的表示不足和缺乏一致性。为了应对这一挑战，我们提出了一种名为多视角置换变分自编码器（MVP）的方法，该方法挖掘了在缺失数据中不同视图之间的不变关系。通过建立潜在空间中的跨视角对应，MVP能够推断出缺失的视图并汇总更多的充分信息。为学习时获得有效的证据下界（ELBO），我们应用置换来随机重新排列变量以进行交叉视图生成，并将其按视图分割以便在置换条件下保持不变的意义。此外，通过引入带有循环后验置换的信息先验，增强了表示的一致性，将正则化项转换为分布之间的相似度量。我们在具有不同缺失率的七个多样数据集上展示了我们方法的有效性，在多视角聚类和生成任务中取得了优越的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-View Representation Learning (MVRL) aims to derive a unifiedrepresentation from multi-view data by leveraging shared and complementaryinformation across views. However, when views are irregularly missing, theincomplete data can lead to representations that lack sufficiency andconsistency. To address this, we propose Multi-View Permutation of VariationalAuto-Encoders (MVP), which excavates invariant relationships between views inincomplete data. MVP establishes inter-view correspondences in the latent spaceof Variational Auto-Encoders, enabling the inference of missing views and theaggregation of more sufficient information. To derive a valid Evidence LowerBound (ELBO) for learning, we apply permutations to randomly reorder variablesfor cross-view generation and then partition them by views to maintaininvariant meanings under permutations. Additionally, we enhance consistency byintroducing an informational prior with cyclic permutations of posteriors,which turns the regularization term into a similarity measure acrossdistributions. We demonstrate the effectiveness of our approach on sevendiverse datasets with varying missing ratios, achieving superior performance inmulti-view clustering and generation tasks.</description>
      <author>example@mail.com (Xin Gao, Jian Pu)</author>
      <guid isPermaLink="false">2502.11037v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence</title>
      <link>http://arxiv.org/abs/2502.11461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在恶劣天气条件或重复几何图案等挑战性环境中，LiDAR测距性能会受到负面影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于多普勒速度的方法来改进4D LiDAR和雷达技术中的扫描匹配。&lt;h4&gt;方法&lt;/h4&gt;首次提出了一个简单且鲁棒的多普勒对应关系（Doppler Correspondence），该方法利用点云数据的时间、空间信息和速度信息，不依赖于迭代最近邻搜索算法。它能有效应对小角度旋转和平移变化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的非迭代直接匹配算法效率高，并且能够更准确地估计重复几何环境中点之间的对应关系。&lt;h4&gt;结论&lt;/h4&gt;基于多普勒速度的扫描匹配方法能够在不良条件下提高LiDAR测距系统的性能，具有重要的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;实现成功的扫描配准对于激光雷达里程计至关重要。然而，在恶劣天气条件或存在重复几何图案等挑战性环境中，由于不正确的扫描配准，会导致激光雷达测距性能下降。最近出现的调频连续波4D LiDAR和4D雷达技术提供了解决这些不利条件的可能性。所谓的“4D”是指在距离、方位角和高度的基础上增加了多普勒速度信息。尽管可以获取这种数据，但大多数现有的用于4D LiDAR和4D雷达扫描配准的方法仍然通过反复识别连续扫描之间的最近点来建立对应关系，忽略了多普勒信息的作用。本文首次引入了一种简单基于多普勒速度的对应方法——“多普勒对应”（Doppler Correspondence），该方法不受传感器平移或小旋转的影响，并且具有几何和运动学基础理论支持。广泛的实验表明所提出的直接匹配连续点云的方法不需要迭代过程，因此计算效率更高，并且在重复几何环境中提供了更加稳健的对应关系估计能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving successful scan matching is essential for LiDAR odometry. However,in challenging environments with adverse weather conditions or repetitivegeometric patterns, LiDAR odometry performance is degraded due to incorrectscan matching. Recently, the emergence of frequency-modulated continuous wave4D LiDAR and 4D radar technologies has provided the potential to address theseunfavorable conditions. The term 4D refers to point cloud data characterized byrange, azimuth, and elevation along with Doppler velocity. Although 4D data isavailable, most scan matching methods for 4D LiDAR and 4D radar still establishcorrespondence by repeatedly identifying the closest points between consecutivescans, overlooking the Doppler information. This paper introduces, for thefirst time, a simple Doppler velocity-based correspondence -- DopplerCorrespondence -- that is invariant to translation and small rotation of thesensor, with its geometric and kinematic foundations. Extensive experimentsdemonstrate that the proposed method enables the direct matching of consecutivepoint clouds without an iterative process, making it computationally efficient.Additionally, it provides a more robust correspondence estimation inenvironments with repetitive geometric patterns.</description>
      <author>example@mail.com (Jiwoo Kim, Geunsik Bae, Changseung Kim, Jinwoo Lee, Woojae Shin, Hyondong Oh)</author>
      <guid isPermaLink="false">2502.11461v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Hyperspherical Energy Transformer with Recurrent Depth</title>
      <link>http://arxiv.org/abs/2502.11646v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 13 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种新的Transformer架构，即Hyper-SET，旨在提高模型的可解释性和实际性能。&lt;h4&gt;背景&lt;/h4&gt;基于Transformer的基础模型已经取得了巨大的成功，但其核心构建块（Transformer层）的设计主要依赖于从下至上的工程方法和直觉驱动。这些设计缺乏高可解释性，并且难以扩展到更深的层次。&lt;h4&gt;目的&lt;/h4&gt;为了探索下一代架构，该研究旨在设计一种具有高可解释性和实际性能的基础模型。&lt;h4&gt;方法&lt;/h4&gt;该论文采用自顶向下视角，从能量最小化角度设计神经网络。通过在嵌入子空间的超球体上修改Hopfield能量函数，设计了具有对称结构的Transformer层作为能量函数迭代优化的一部分。整合具有相同参数设置的层数后提出了Hyper-SET架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在合成和现实世界任务（如解决数独和掩码图像建模）中，Hyper-SET能够利用更少的参数实现与标准Transformer相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;通过采用新的设计思路，该论文提出了一种新型的高效、可扩展且具有高解释性的模型架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based foundation models have achieved unprecedented success witha gigantic amount of parameters and computational resources. Yet, the corebuilding blocks of these models, the Transformer layers, and how they arearranged and configured are primarily engineered from the bottom up and drivenby heuristics. For advancing next-generation architectures, it demandsexploring a prototypical model that is amenable to high interpretability and ofpractical competence. To this end, we take a step from the top-down view anddesign neural networks from an energy minimization perspective. Specifically,to promote isotropic token distribution on the sphere, we formulate a modifiedHopfield energy function on the subspace-embedded hypersphere, based on whichTransformer layers with symmetric structures are designed as the iterativeoptimization for the energy function. By integrating layers with the sameparameters, we propose \textit{Hyper-Spherical Energy Transformer} (Hyper-SET),an alternative to the vanilla Transformer with recurrent depth. This designinherently provides greater interpretability and allows for scaling to deeperlayers without a significant increase in the number of parameters. We alsoempirically demonstrate that Hyper-SET achieves comparable or even superiorperformance on both synthetic and real-world tasks, such as solving Sudoku andmasked image modeling, while utilizing fewer parameters.</description>
      <author>example@mail.com (Yunzhe Hu, Difan Zou, Dong Xu)</author>
      <guid isPermaLink="false">2502.11646v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening</title>
      <link>http://arxiv.org/abs/2502.11001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Gen Zhou and Sugitha Janarthanan contributed equally; Accepted at  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;针对抗菌药物研发领域中抗微生物耐药性的挑战，研究人员利用机器学习技术来预测和开发具有抗生素潜力的新化合物。本文提出了CL-MFAP模型，这是一个基于对比学习的多模态基础模型，用于发现可能具有抗菌特性的小分子。&lt;h4&gt;背景&lt;/h4&gt;由于抗生素耐药性问题日益严重，寻找新型具有潜在抗菌作用的化合物变得至关重要。然而，传统药物开发方法成本高且效率低下。因此，研究人员转向机器学习技术以加速新抗生素化合物的研发进程。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于对比学习（CL）的多模态基础模型，该模型专门用于发现可能具有抗微生物特性的小分子，并通过利用三种类型的数据来提高抗菌特性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用了来自ChEMBL数据集中的160万种具有药物样性质的生物活性分子进行预训练，包括：（1）带有旋转位置嵌入的SMILES字符串处理变换器编码器；（2）用于处理分子图表示的新颖双层路由注意机制的变换器编码器；以及（3）使用多层感知机的Morgan指纹编码器。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在抗生素性质预测任务中优于基线模型，并且当针对与抗生素相关的特性预测任务进行微调时，表现出优异的专业领域性能。&lt;h4&gt;结论&lt;/h4&gt;CL-MFAP通过有效利用不同的分子模态，在抗菌剂开发的预训练和微调过程中展示了出色的性能。这表明，多模式数据在新型抗生素发现中的价值尚未被完全挖掘出来。&lt;h4&gt;翻译&lt;/h4&gt;鉴于全球公共卫生问题中抗微生物耐药性的增加，寻找具有潜在抗生素特性的新化合物至关重要。然而，传统的药物研发方式既昂贵又低效。研究人员已经转向使用机器学习技术来预测和开发新的抗菌化合物。虽然基础模型在抗生素发现方面显示出前景，但主流努力仍未能充分利用多模式分子数据的潜力。研究表明，利用对比学习框架进行跨领域表示学习时，结合多种模态的数据可以表现出卓越性能。基于此，我们推出了CL-MFAP，这是一种专门用于从三种类型的分子数据中识别潜在抗菌特性的新型小分子发现模型。该模型使用ChEMBL数据集中具有药物样性质的160万种生物活性分子进行预训练，包括：（1）带有旋转位置嵌入处理SMILES字符串的变换器编码器；（2）为处理分子图表示设计的一种新颖双层路由注意机制的变换器编码器；以及（3）使用多层感知机的Morgan指纹编码器。CL-MFAP在抗生素特性预测中优于基线模型，通过有效利用不同模态的数据，并且当针对与抗生素相关的特性预测任务进行微调时表现出优异的专业领域性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the rise in antimicrobial resistance, identifying novel compounds withantibiotic potential is crucial for combatting this global health issue.However, traditional drug development methods are costly and inefficient.Recognizing the pressing need for more effective solutions, researchers haveturned to machine learning techniques to streamline the prediction anddevelopment of novel antibiotic compounds. While foundation models have shownpromise in antibiotic discovery, current mainstream efforts still fall short offully leveraging the potential of multimodal molecular data. Recent studiessuggest that contrastive learning frameworks utilizing multimodal data exhibitexcellent performance in representation learning across various domains.Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning(CL)-based multimodal foundation (MF) model specifically tailored fordiscovering small molecules with potential antibiotic properties (AP) usingthree types of molecular data. This model employs 1.6 million bioactivemolecules with drug-like properties from the ChEMBL dataset to jointly pretrainthree encoders: (1) a transformer-based encoder with rotary position embeddingfor processing SMILES strings; (2) another transformer-based encoder,incorporating a novel bi-level routing attention mechanism to handle moleculargraph representations; and (3) a Morgan fingerprint encoder using a multilayerperceptron, to achieve the contrastive learning purpose. The CL-MFAPoutperforms baseline models in antibiotic property prediction by effectivelyutilizing different molecular modalities and demonstrates superiordomain-specific performance when fine-tuned for antibiotic-related propertyprediction tasks.</description>
      <author>example@mail.com (Gen Zhou, Sugitha Janarthanan, Yutong Lu, Pingzhao Hu)</author>
      <guid isPermaLink="false">2502.11001v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>iMOVE: Instance-Motion-Aware Video Understanding</title>
      <link>http://arxiv.org/abs/2502.11594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了iMOVE视频基础模型，该模型通过引入事件感知时空高效建模和相对时空位置令牌机制来增强对视频中细粒度实例时空运动的感知能力。&lt;h4&gt;背景&lt;/h4&gt;目前的视频大语言模型在理解和捕捉视频中的细粒度实例时空运动细节方面存在不足，这限制了它们的时间理解和泛化视频理解的能力。&lt;h4&gt;目的&lt;/h4&gt;通过数据和模型两方面的改进来增强视频中细粒度实例时空运动的理解能力。&lt;h4&gt;方法&lt;/h4&gt;{'数据层面': '精心制作iMOVE-IT，这是一个新的大规模视频指令微调数据集，该数据集包含丰富的实例运动注释及空间时间互监督任务。', '模型层面': '提出了iMOVE模型，它利用事件感知时空高效建模来保留信息丰富的实例时空运动细节，并通过相对时空位置令牌机制确保实例的时空位置意识。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，iMOVE在视频的时间理解、泛化视频理解和长期视频理解方面都表现出显著优势。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的数据集和改进模型结构，能够有效提高视频中细粒度实例时空运动的理解能力，从而提升视频分析的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enhancing the fine-grained instance spatiotemporal motion perceptioncapabilities of Video Large Language Models is crucial for improving theirtemporal and general video understanding. However, current models struggle toperceive detailed and complex instance motions. To address these challenges, wehave made improvements from both data and model perspectives. In terms of data,we have meticulously curated iMOVE-IT, the first large-scaleinstance-motion-aware video instruction-tuning dataset. This dataset isenriched with comprehensive instance motion annotations and spatiotemporalmutual-supervision tasks, providing extensive training for the model'sinstance-motion-awareness. Building on this foundation, we introduce iMOVE, aninstance-motion-aware video foundation model that utilizes Event-awareSpatiotemporal Efficient Modeling to retain informative instance spatiotemporalmotion details while maintaining computational efficiency. It also incorporatesRelative Spatiotemporal Position Tokens to ensure awareness of instancespatiotemporal positions. Evaluations indicate that iMOVE excels not only invideo temporal understanding and general video understanding but alsodemonstrates significant advantages in long-term video understanding.</description>
      <author>example@mail.com (Jiaze Li, Yaya Shi, Zongyang Ma, Haoran Xu, Feng Cheng, Huihui Xiao, Ruiwen Kang, Fan Yang, Tingting Gao, Di Zhang)</author>
      <guid isPermaLink="false">2502.11594v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model</title>
      <link>http://arxiv.org/abs/2502.10707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 8 figures, accepted by International Conference on Learning  Representations 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;心电图(ECG)在心律失常和其他心脏病的临床诊断中至关重要，但基于ECG的深度学习方法由于需要高质量注释而面临限制。尽管之前的心电图自监督学习(eSSL)方法从未标注的ECG数据中进行表示学习方面取得了显著进展，它们通常将ECG信号视为普通时间序列数据，并使用固定大小和步长的时间窗口分割信号，这往往忽略了心电信号的形式、节奏特征及其潜在语义关系。在这项工作中，我们引入了对ECG信号的新视角，将其心脏跳动视为单词，而节奏则被视为句子。基于这种观点，首先设计QRS-Tokenizer，从原始心电图数据中生成具有语义意义的心电图句子。在此基础上，提出HeartLang，一种新的自监督学习框架，用于处理ECG语言，在形式和节奏水平上进行通用表示的学习。此外，我们构建了迄今为止最大的基于心跳的ECG词汇表，这将进一步促进ECG语言处理的发展。我们在六个公开心电图数据集上对HeartLang进行了评估，它在与其他eSSL方法的竞争中表现出强大的竞争力。&lt;h4&gt;背景&lt;/h4&gt;目前基于ECG的心律失常和其他心脏疾病的诊断依赖深度学习方法，然而这些方法由于需要高质量的注释而受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的视角和自监督框架来改进ECG信号处理，并构建一个大型的ECG词汇表以促进该领域的发展。&lt;h4&gt;方法&lt;/h4&gt;设计QRS-Tokenizer从原始心电图数据中生成有意义的心电图句子，提出了HeartLang这一基于新观点的自监督学习框架，以及构建了迄今为止最大的心跳为基础的ECG词汇表。&lt;h4&gt;主要发现&lt;/h4&gt;HeartLang在形式和节奏水平上进行通用表示的学习，并通过六个公开的数据集验证其有效性与竞争力。&lt;h4&gt;结论&lt;/h4&gt;提出的QRS-Tokenizer和HeartLang方法展示了心电图处理的新方向，且HeartLang显示了优越的表现，在实际应用中具有潜在的临床价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已全部翻译成中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electrocardiogram (ECG) is essential for the clinical diagnosis ofarrhythmias and other heart diseases, but deep learning methods based on ECGoften face limitations due to the need for high-quality annotations. Althoughprevious ECG self-supervised learning (eSSL) methods have made significantprogress in representation learning from unannotated ECG data, they typicallytreat ECG signals as ordinary time-series data, segmenting the signals usingfixed-size and fixed-step time windows, which often ignore the form and rhythmcharacteristics and latent semantic relationships in ECG signals. In this work,we introduce a novel perspective on ECG signals, treating heartbeats as wordsand rhythms as sentences. Based on this perspective, we first designed theQRS-Tokenizer, which generates semantically meaningful ECG sentences from theraw ECG signals. Building on these, we then propose HeartLang, a novelself-supervised learning framework for ECG language processing, learninggeneral representations at form and rhythm levels. Additionally, we constructthe largest heartbeat-based ECG vocabulary to date, which will further advancethe development of ECG language processing. We evaluated HeartLang across sixpublic ECG datasets, where it demonstrated robust competitiveness against othereSSL methods. Our data and code are publicly available athttps://github.com/PKUDigitalHealth/HeartLang.</description>
      <author>example@mail.com (Jiarui Jin, Haoyu Wang, Hongyan Li, Jun Li, Jiahui Pan, Shenda Hong)</author>
      <guid isPermaLink="false">2502.10707v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems</title>
      <link>http://arxiv.org/abs/2502.11127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了G-Safeguard，一种旨在增强基于大型语言模型的多智能体系统（LLM-MAS）安全性的方法。&lt;h4&gt;背景&lt;/h4&gt;当前的LLM-MAS在复杂任务中表现出了非凡的能力，但同时面临对抗性攻击、虚假信息传播和意外行为等风险。&lt;h4&gt;目的&lt;/h4&gt;提出G-Safeguard以检测并缓解LLM-MAS中的异常行为，提高其鲁棒性和安全性。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络分析多智能体话语图来发现异常，并使用拓扑干预进行攻击修复。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，G-Safeguard在各种攻击策略下表现出显著的有效性；它能够适应不同LLM架构和大规模MAS；并且可以与主流MAS安全结合。&lt;h4&gt;结论&lt;/h4&gt;通过代码公开，展示了G-Safeguard对于提高LLM-MAS的安全性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;基于大型语言模型的多智能体系统（LLM-MAS）在各种复杂任务中表现出非凡的能力，但面临的安全问题促使研究人员提出了一种利用图神经网络进行异常检测和攻击缓解的方法。实验结果表明这种方法具有良好的适应性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Model (LLM)-based Multi-agent Systems (MAS) have demonstratedremarkable capabilities in various complex tasks, ranging from collaborativeproblem-solving to autonomous decision-making. However, as these systems becomeincreasingly integrated into critical applications, their vulnerability toadversarial attacks, misinformation propagation, and unintended behaviors haveraised significant concerns. To address this challenge, we introduceG-Safeguard, a topology-guided security lens and treatment for robust LLM-MAS,which leverages graph neural networks to detect anomalies on the multi-agentutterance graph and employ topological intervention for attack remediation.Extensive experiments demonstrate that G-Safeguard: (I) exhibits significanteffectiveness under various attack strategies, recovering over 40% of theperformance for prompt injection; (II) is highly adaptable to diverse LLMbackbones and large-scale MAS; (III) can seamlessly combine with mainstream MASwith security guarantees. The code is available athttps://github.com/wslong20/G-safeguard.</description>
      <author>example@mail.com (Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, Chongye Guo, Kun Wang, Yang Wang)</author>
      <guid isPermaLink="false">2502.11127v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-aware Text-Image-Point Cloud Pretraining for Open-World 3D Object Recognition</title>
      <link>http://arxiv.org/abs/2502.10674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近的开放世界表示学习方法利用CLIP实现了零样本3D物体识别。然而，由于预训练设置与实际情况不符，真实点云中的遮挡问题仍然影响性能，且这些方法在推理过程中计算成本高。&lt;h4&gt;背景&lt;/h4&gt;当前的方法依赖于CLIP进行零样本3D对象识别，但由于预训练环境与实际场景存在差距以及使用Transformer带来的高计算需求，它们的性能仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出新的预训练框架和模型来解决现有方法在处理真实世界点云时的遮挡问题，并降低推理成本。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种考虑遮挡情况下的文本-图像-点云联合预训练，生成大量模拟现实世界的不完整点云进行模型优化。2. 开发了DuoMamba模型，这是一种专为点云设计的两流线性状态空间模型，利用两个填充曲线和1维卷积来建模点之间的空间依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过提出的预训练框架生成的数据集显著提高了现有3D网络在实际环境中的识别性能；同时，新开发的DuoMamba模型不仅提升了性能，还降低了延迟和计算量。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法展示了在处理真实世界的点云数据时提高准确性和减少计算成本方面的巨大潜力，并计划发布相关资源以促进未来研究。&lt;h4&gt;翻译&lt;/h4&gt;最近的研究表明，通过CLIP进行零样本3D物体识别虽然有潜力，但在实际应用中仍然存在挑战。本文通过引入新的预训练方法和模型架构解决了这些问题，展示了在真实场景下的性能提升以及计算效率的改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent open-world representation learning approaches have leveraged CLIP toenable zero-shot 3D object recognition. However, performance on real pointclouds with occlusions still falls short due to the unrealistic pretrainingsettings. Additionally, these methods incur high inference costs because theyrely on Transformer's attention modules. In this paper, we make twocontributions to address these limitations. First, we propose occlusion-awaretext-image-point cloud pretraining to reduce the training-testing domain gap.From 52K synthetic 3D objects, our framework generates nearly 630K partialpoint clouds for pretraining, consistently improving real-world recognitionperformances of existing popular 3D networks. Second, to reduce computationalrequirements, we introduce DuoMamba, a two-stream linear state space modeltailored for point clouds. By integrating two space-filling curves with 1Dconvolutions, DuoMamba effectively models spatial dependencies between pointtokens, offering a powerful alternative to Transformer. When pretrained withour framework, DuoMamba surpasses current state-of-the-art methods whilereducing latency and FLOPs, highlighting the potential of our approach forreal-world applications. We will release our data and code to facilitate futureresearch.</description>
      <author>example@mail.com (Khanh Nguyen, Ghulam Mubashar Hassan, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.10674v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Open-Set Cross-Network Node Classification via Unknown-Excluded Adversarial Graph Domain Alignment</title>
      <link>http://arxiv.org/abs/2502.10967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的跨网络节点分类问题（开放集跨网络节点分类）以及解决此问题的未知排除对抗图领域对齐模型。&lt;h4&gt;背景&lt;/h4&gt;现有的跨网络节点分类方法主要针对封闭集设置，即源网络和目标网络共享完全相同的标签空间。然而，在实际应用中这种情况受到限制，因为目标网络可能包含源网络中不存在的新类别。&lt;h4&gt;目的&lt;/h4&gt;研究一个更贴近现实的开放集跨网络节点分类问题，并提出有效的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了未知排除对抗图领域对齐（UAGA）模型和分离适应训练策略。通过设计一种对抗框架，将已知类与未知类初步分开，然后定制了未知排除对抗领域对齐以仅对来自已知类别的目标节点进行源领域的对齐，并且远离源自未见过的类别。&lt;h4&gt;主要发现&lt;/h4&gt;UAGA模型在现实世界数据集上的实验结果表明其比现有的最佳方法显著更优。&lt;h4&gt;结论&lt;/h4&gt;提出的开放集跨网络节点分类问题更加贴近实际应用，而未知排除对抗图领域对齐（UAGA）模型是解决该类问题的有效途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文直接翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing cross-network node classification methods are mainly proposed forclosed-set setting, where the source network and the target network shareexactly the same label space. Such a setting is restricted in real-worldapplications, since the target network might contain additional classes thatare not present in the source. In this work, we study a more realistic open-setcross-network node classification (O-CNNC) problem, where the target networkcontains all the known classes in the source and further contains severaltarget-private classes unseen in the source. Borrowing the concept fromopen-set domain adaptation, all target-private classes are defined as anadditional unknown class. To address the challenging O-CNNC problem, we proposean unknown-excluded adversarial graph domain alignment (UAGA) model with aseparate-adapt training strategy. Firstly, UAGA roughly separates known classesfrom unknown class, by training a graph neural network encoder and aneighborhood-aggregation node classifier in an adversarial framework. Then,unknown-excluded adversarial domain alignment is customized to align onlytarget nodes from known classes with the source, while pushing target nodesfrom unknown class far away from the source, by assigning positive and negativedomain adaptation coefficient to known class nodes and unknown class nodes.Extensive experiments on real-world datasets demonstrate significantoutperformance of the proposed UAGA over state-of-the-art methods on O-CNNC.</description>
      <author>example@mail.com (Xiao Shen, Zhihao Chen, Shirui Pan, Shuang Zhou, Laurence T. Yang, Xi Zhou)</author>
      <guid isPermaLink="false">2502.10967v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Point-Language Models with Dual-Prompts for 3D Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.11307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为PLANE的点云异常检测新模型，它利用双模态提示扩展了预训练的Point-Language Models在3D点云领域的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;在工业应用中，特别是精密制造领域，三维点云异常检测至关重要。目前的方法大多需要为每个类别分别训练单独的模型，导致内存占用高且缺乏灵活性。&lt;h4&gt;目的&lt;/h4&gt;开发一个单一模型可以跨多个类别的3D点云异常检测方法，提高效率和性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双提示学习方法，结合了文本和点云提示。通过动态提示创建模块（DPCM）生成特定样本的动态提示，并与每个模式下的类别特异性静态提示相结合，以驱动预训练的语言模型实现高效的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在Anomaly-ShapeNet数据集上比现有的单类单模型方法提升了8.7%/17%在异常检测和定位性能；对于Real3D-AD数据集则分别提高了4.3%/4.1%。这些提升是在多类别单一模型框架下实现的。&lt;h4&gt;结论&lt;/h4&gt;PLANE模型通过结合双模态提示，成功地将预训练的语言模型应用于三维点云的异常检测中，展示了其在广泛工业应用中的潜力和有效性。&lt;h4&gt;翻译&lt;/h4&gt;3D点云异常检测在众多工业应用中至关重要，特别是在精密制造领域。为了满足行业需求，已经开发了几种方法。然而，大多数这些方法通常需要为每个类别分别训练单独的模型，这会导致内存使用量大且缺乏灵活性。本文提出了一种新的Point-Language模型，带双提示用于3D异常检测（PLANE）。该方法利用多模态提示将预训练的语言模型强大的泛化能力扩展到3D点云异常检测领域，在单一模型上实现了跨多个类别的出色检测性能。具体而言，提出了一个双提示学习法，结合了文本和点云提示，并使用动态提示创建模块（DPCM）来生成特定样本的动态提示，然后将这些与每个模式下的类别特异性静态提示相结合，有效地驱动预训练语言模型。基于点云数据的特点，提出了一种伪3D异常生成方法（Ano3D），以在无监督设置中提高模型的检测能力。实验结果显示，在多类单模框架下，所提方法相对于现有的一类一模型方法分别在Anomaly-ShapeNet数据集上提高了8.7%/17%，而在Real3D-AD数据集中则分别提高了4.3%/4.1%。代码发布后将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection (AD) in 3D point clouds is crucial in a wide range ofindustrial applications, especially in various forms of precisionmanufacturing. Considering the industrial demand for reliable 3D AD, severalmethods have been developed. However, most of these approaches typicallyrequire training separate models for each category, which is memory-intensiveand lacks flexibility. In this paper, we propose a novel Point-Language modelwith dual-prompts for 3D ANomaly dEtection (PLANE). The approach leveragesmulti-modal prompts to extend the strong generalization capabilities ofpre-trained Point-Language Models (PLMs) to the domain of 3D point cloud AD,achieving impressive detection performance across multiple categories using asingle model. Specifically, we propose a dual-prompt learning method,incorporating both text and point cloud prompts. The method utilizes a dynamicprompt creator module (DPCM) to produce sample-specific dynamic prompts, whichare then integrated with class-specific static prompts for each modality,effectively driving the PLMs. Additionally, based on the characteristics ofpoint cloud data, we propose a pseudo 3D anomaly generation method (Ano3D) toimprove the model's detection capabilities in an unsupervised setting.Experimental results demonstrate that the proposed method, which is under themulti-class-one-model paradigm, achieves a +8.7%/+17% gain on anomaly detectionand localization performance as compared to the state-of-the-artone-class-one-model methods for the Anomaly-ShapeNet dataset, and obtains+4.3%/+4.1% gain for the Real3D-AD dataset. Code will be available uponpublication.</description>
      <author>example@mail.com (Jiaxiang Wang, Haote Xu, Xiaolu Chen, Haodi Xu, Yue Huang, Xinghao Ding, Xiaotong Tu)</author>
      <guid isPermaLink="false">2502.11307v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Hierarchical Contrastive Self-supervising Learning for Time Series Classification via Importance-aware Resolution Selection</title>
      <link>http://arxiv.org/abs/2502.10567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appears in IEEEBigData-2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种新的训练方法，用于解决时间序列数据中层级对比学习自监督框架在处理长时序数据时计算成本过高的问题。&lt;h4&gt;背景&lt;/h4&gt;近期设计针对时间序列的自监督学习(SSM)框架有了显著进展。这些基于层级对比学习的方法通过多分辨率的数据嵌入对比来学习表示，能够收集更多信息并表现出更好的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了应对长时序数据计算成本高的挑战，提出了一种高效的训练方法来降低计算负担。&lt;h4&gt;方法&lt;/h4&gt;受每个分辨率间数据嵌入依赖关系的启发，引入了基于重要性感知的分辨率选择训练框架。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法显著提高了训练时间效率，并且在广泛的时间序列分类性能评估中保持原有模型结构完整性和准确性。&lt;h4&gt;结论&lt;/h4&gt;论文提出的解决方案有助于提升层级对比学习模型的训练效率和实用性，特别是在处理长时序数据场景下。&lt;h4&gt;翻译&lt;/h4&gt;最近，在设计针对时间序列的数据自监督学习(SSM)框架方面取得了显著进展，以减少对数据标签的依赖。这些基于层级对比学习的方法通过多分辨率下的数据嵌入对比来学习表示，并因其能够收集更多信息而表现出更好的泛化能力。然而，当时间序列长度较长时，其计算成本通常比其他SSM框架高得多。本文提出了一种高效的训练方法，旨在应对这一挑战：引入了基于重要性感知的分辨率选择训练框架以降低计算负担。实验表明该方法显著提高了训练效率，并在广泛的时间序列分类性能评估中保持了原有模型结构完整性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, there has been a significant advancement in designingSelf-Supervised Learning (SSL) frameworks for time series data to reduce thedependency on data labels. Among these works, hierarchical contrastivelearning-based SSL frameworks, which learn representations by contrasting dataembeddings at multiple resolutions, have gained considerable attention. Due totheir ability to gather more information, they exhibit better generalization invarious downstream tasks. However, when the time series data length issignificant long, the computational cost is often significantly higher thanthat of other SSL frameworks. In this paper, to address this challenge, wepropose an efficient way to train hierarchical contrastive learning models.Inspired by the fact that each resolution's data embedding is highly dependent,we introduce importance-aware resolution selection based training framework toreduce the computational cost. In the experiment, we demonstrate that theproposed method significantly improves training time while preserving theoriginal model's integrity in extensive time series classification performanceevaluations. Our code could be found here, https://github.com/KEEBVIN/IARS</description>
      <author>example@mail.com (Kevin Garcia, Juan Manuel Perez, Yifeng Gao)</author>
      <guid isPermaLink="false">2502.10567v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Implicit Neural Representations of Molecular Vector-Valued Functions</title>
      <link>http://arxiv.org/abs/2502.10848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is a tiny paper track submission to the LRML workshop at ICLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;分子有多种计算表示形式，包括数值描述符、字符串、图结构、点云和表面。为了补充现有的表示方法，本文引入了通过向量值函数或由神经网络参数化的$n$维矢量场来表示分子的新方法。&lt;h4&gt;背景&lt;/h4&gt;当前的分子表示方法涵盖了从线性回归到与大型语言模型结合使用的图神经网络等机器学习技术的应用。&lt;h4&gt;目的&lt;/h4&gt;为了改进现有分子表示，提出了使用向量值函数或称为分子神经场（molecular neural fields）的方法来更好地捕捉分子外部特征和疏水核心。&lt;h4&gt;方法&lt;/h4&gt;介绍了基于自动解码器架构的蛋白质-配体复合物参数化和超分辨率重构以及基于自编码器架构的分子体积嵌入到潜在空间中的框架。&lt;h4&gt;主要发现&lt;/h4&gt;与离散图或点表示相比，分子神经场具有紧凑性、分辨率独立性和在时空维度上内插的能力。这些特性使它们适合生成基于形状、结构和成分的分子，并能进行时间和空间维度上的分辨率无关插值。&lt;h4&gt;结论&lt;/h4&gt;本文提供了一个框架和概念验证示例来支持使用向量值函数表示分子的新方法，展示了其在分子科学中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecules have various computational representations, including numericaldescriptors, strings, graphs, point clouds, and surfaces. Each representationmethod enables the application of various machine learning methodologies fromlinear regression to graph neural networks paired with large language models.To complement existing representations, we introduce the representation ofmolecules through vector-valued functions, or $n$-dimensional vector fields,that are parameterized by neural networks, which we denote molecular neuralfields. Unlike surface representations, molecular neural fields captureexternal features and the hydrophobic core of macromolecules such as proteins.Compared to discrete graph or point representations, molecular neural fieldsare compact, resolution independent and inherently suited for interpolation inspatial and temporal dimensions. These properties inherited by molecular neuralfields lend themselves to tasks including the generation of molecules based ontheir desired shape, structure, and composition, and the resolution-independentinterpolation between molecular conformations in space and time. Here, weprovide a framework and proofs-of-concept for molecular neural fields, namely,the parametrization and superresolution reconstruction of a protein-ligandcomplex using an auto-decoder architecture and the embedding of molecularvolumes in latent space using an auto-encoder architecture.</description>
      <author>example@mail.com (Jirka Lhotka, Daniel Probst)</author>
      <guid isPermaLink="false">2502.10848v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages</title>
      <link>http://arxiv.org/abs/2502.10362v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;CLaMP 3是一个统一的框架，用于解决音乐信息检索中的跨模态和跨语言泛化挑战。&lt;h4&gt;背景&lt;/h4&gt;当前音乐信息检索系统在处理不同语言和模式之间的通用性上面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将包括乐谱、表演信号、音频记录在内的所有主要音乐模态与多语言文本统一在一个共享表示空间中的框架，从而实现跨不相关模式的检索，并且以文本作为桥梁。&lt;h4&gt;方法&lt;/h4&gt;使用对比学习技术，构建了一个可适应未见过的语言的多语言文本编码器，利用增强生成的检索技术创建了包含2.31万音乐-文本对的大规模网络级数据集M4-RAG，以及一个包含乐谱、音频和详细文字描述的WikiMT-X基准。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CLaMP 3在多项MIR任务上实现了最先进的性能，并且在多模态和多语言音乐场景中表现出色的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过发布具有挑战性的基准集，研究人员能够进一步推进跨语言、跨模式音乐信息检索领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;CLaMP 3是为了解决音乐信息检索中的跨模态与跨语言问题而开发的一个统一框架。它利用对比学习方法将不同的音乐形式（乐谱、表演信号和音频记录）及多语言文本整合到一个共享的表示空间中，使得不同模式之间可以通过文本作为桥梁进行检索。该系统具有适应未知语言的能力，并通过大规模数据集M4-RAG和基准测试集WikiMT-X展示了其在多种音乐信息检索任务中的优越性能和广泛的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLaMP 3 is a unified framework developed to address challenges of cross-modaland cross-lingual generalization in music information retrieval. Usingcontrastive learning, it aligns all major music modalities--including sheetmusic, performance signals, and audio recordings--with multilingual text in ashared representation space, enabling retrieval across unaligned modalitieswith text as a bridge. It features a multilingual text encoder adaptable tounseen languages, exhibiting strong cross-lingual generalization. Leveragingretrieval-augmented generation, we curated M4-RAG, a web-scale datasetconsisting of 2.31 million music-text pairs. This dataset is enriched withdetailed metadata that represents a wide array of global musical traditions. Toadvance future research, we release WikiMT-X, a benchmark comprising 1,000triplets of sheet music, audio, and richly varied text descriptions.Experiments show that CLaMP 3 achieves state-of-the-art performance on multipleMIR tasks, significantly surpassing previous strong baselines and demonstratingexcellent generalization in multimodal and multilingual music contexts.</description>
      <author>example@mail.com (Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun)</author>
      <guid isPermaLink="false">2502.10362v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Automatic Prompt Engineering: An Optimization Perspective</title>
      <link>http://arxiv.org/abs/2502.11560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了自动化提示工程的研究，提出了一种统一的优化理论视角来综合各种方法。&lt;h4&gt;背景&lt;/h4&gt;基础模型的发展使得研究从资源密集型的微调转向了通过输入设计引导模型行为的提示工程。然而，手动提示工程在可扩展性、适应性和跨模态一致性方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提供首个关于自动化提示工程的全面综述，涵盖多种方法和理论框架。&lt;h4&gt;方法&lt;/h4&gt;将提示优化问题形式化为在离散、连续以及混合提示空间中的最大化问题，并根据不同变量（指令、软提示、示例）、特定任务目标以及计算框架来系统地组织各种方法。&lt;h4&gt;主要发现&lt;/h4&gt;通过统一的优化视角，该综述连接了理论设计与实践实施，涵盖了文本、视觉和多模态领域。同时指出了在受限优化及代理导向型提示设计中的未探索前沿。&lt;h4&gt;结论&lt;/h4&gt;为研究者和从业者提供了一个基础框架，并强调了一些关键的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;随着基础模型的发展，注意力从资源密集的微调转向了通过输入设计来引导模型行为的提示工程。手动提示工程在可扩展性、适应性和跨模态一致性方面存在局限。自动化方法涵盖基于基础模型的优化、进化方法、梯度基优化和强化学习等，提供了有前景的解决方案。本文首次提出了一个关于自动化提示工程的全面综述，通过统一的优化理论视角进行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of foundation models has shifted focus from resource-intensivefine-tuning to prompt engineering, a paradigm that steers model behaviorthrough input design rather than weight updates. While manual promptengineering faces limitations in scalability, adaptability, and cross-modalalignment, automated methods, spanning foundation model (FM) basedoptimization, evolutionary methods, gradient-based optimization, andreinforcement learning, offer promising solutions. Existing surveys, however,remain fragmented across modalities and methodologies. This paper presents thefirst comprehensive survey on automated prompt engineering through a unifiedoptimization-theoretic lens. We formalize prompt optimization as a maximizationproblem over discrete, continuous, and hybrid prompt spaces, systematicallyorganizing methods by their optimization variables (instructions, soft prompts,exemplars), task-specific objectives, and computational frameworks. By bridgingtheoretical formulation with practical implementations across text, vision, andmultimodal domains, this survey establishes a foundational framework for bothresearchers and practitioners, while highlighting underexplored frontiers inconstrained optimization and agent-oriented prompt design.</description>
      <author>example@mail.com (Wenwu Li, Xiangfeng Wang, Wenhao Li, Bo Jin)</author>
      <guid isPermaLink="false">2502.11560v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Motion planning for highly-dynamic unconditioned reflexes based on chained Signed Distance Functions</title>
      <link>http://arxiv.org/abs/2502.10734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在线、高度动态的运动规划算法，旨在赋予机器人机械臂以类人的无条件反射能力，使其能够迅速避开环境中的静态和动态障碍。&lt;h4&gt;背景&lt;/h4&gt;无条件反射（如保护性反射）是生物体在遇到危险时自然发生的反应，通常是通过脊髓而不是大脑来执行的。此类反射帮助有机体避免来自环境的危害。&lt;h4&gt;目的&lt;/h4&gt;设计一种算法，使机器人机械臂能够具备高度动态的无条件反射能力，以避开人类和/或环境中的潜在危害。&lt;h4&gt;方法&lt;/h4&gt;{'离线阶段': '创建3组局部距离函数（SDFs）来存储机械臂及其工作环境的几何信息，并预先计算和存储这些数据。', '在线阶段': '根据机械臂的配置将预先计算好的局部SDF链式连接起来，提供全局几何信息。动态对象的点云作为查询点以快速生成逃逸速度。', '实时行为生成': '提出修改后的几何雅可比矩阵并使用雅可比伪逆方法，在遇到静态和动态障碍物时产生即时避障行为'}&lt;h4&gt;主要发现&lt;/h4&gt;{'静态场景': '在静态场景中，本文的方法相比现有解决方案耗时更少且轨迹长度更短。', '动态场景': '在动态场景下，该算法能够可靠地追踪动态目标点、避开动态障碍物，并能在1ms内对这些障碍作出反应，超越了人类的无条件反射时间。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过高效的运动规划和即时避障策略，在静态与动态环境中均表现出色，具有重要的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一个基于链式距离函数的在线、高度动态运动规划算法，赋予机械臂类似人类无条件反射的能力来避开环境中的障碍物。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The unconditioned reflex (e.g., protective reflex), which is the innatereaction of the organism and usually performed through the spinal cord ratherthan the brain, can enable organisms to escape harms from environments. In thispaper, we propose an online, highly-dynamic motion planning algorithm to endowmanipulators the highly-dynamic unconditioned reflexes to humans and/orenvironments. Our method is based on a chained version of Signed DistanceFunctions (SDFs), which can be pre-computed and stored. Our proposed algorithmis divided into two stages. In the offline stage, we create 3 groups of localSDFs to store the geometric information of the manipulator and its workingenvironment. In the online stage, the pre-computed local SDFs are chainedtogether according the configuration of the manipulator, to provide globalgeometric information about the environment. While the point clouds of thedynamic objects serve as query points to look up these local SDFs for quicklygenerating escape velocity. Then we propose a modified geometric Jacobianmatrix and use the Jacobian-pseudo-inverse method to generate real-time reflexbehaviors to avoid the static and dynamic obstacles in the environment. Thebenefits of our method are validated in both static and dynamic scenarios. Inthe static scenario, our method identifies the path solutions with lower timeconsumption and shorter trajectory length compared to existing solutions. Inthe dynamic scenario, our method can reliably pursue the dynamic target point,avoid dynamic obstacles, and react to these obstacles within 1ms, whichsurpasses the unconditioned reflex reaction time of humans.</description>
      <author>example@mail.com (Ken Lin, Qi Ye, Tin Lun Lam, Zhibin Li, Jiming Chen)</author>
      <guid isPermaLink="false">2502.10734v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>LLM-driven Knowledge Distillation for Dynamic Text-Attributed Graphs</title>
      <link>http://arxiv.org/abs/2502.10914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the AI4TS: AI for Time Series Analysis workshop, AAAI  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的模型LKD4DyTAG，该模型通过将LLM的知识蒸馏到动态文本属性图中，解决了在包含时间信息的动态图中的挑战。&lt;h4&gt;背景&lt;/h4&gt;Dynamic Text-Attributed Graphs (DyTAGs) 在社交媒体、合作网络等领域有广泛应用。这些网络中的节点和边经常包含描述性文本，并且图形结构会随着时间变化。&lt;h4&gt;目的&lt;/h4&gt;为未来链接预测，边缘分类等任务开发一种能够同时编码时间、结构信息的强大的表示方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通过知识蒸馏将大型语言模型（LLM）的能力注入到动态图中的方法，这种方法可以在轻量级GNN模型中利用邻域文本属性来生成时空表示。&lt;h4&gt;主要发现&lt;/h4&gt;在六个现实世界的数据集上进行了广泛的实验验证了该方法的有效性，并显示它比基线模型显著提高了下游任务的表现。&lt;h4&gt;结论&lt;/h4&gt;LKD4DyTAG通过结合时间编码和知识蒸馏，能够有效地解决动态文本属性图中的结构化信息、时间信息和文本信息的表示问题。&lt;h4&gt;翻译&lt;/h4&gt;动态文本属性图（Dynamic Text-Attributed Graphs, DyTAGs）在现实世界中有许多应用，例如社交网络、合作网络等。节点和边通常包含描述性文本，并且图形结构会随时间演变。为了处理未来链接预测等问题，需要强大的表示来编码结构化信息、时间信息和文本信息。本文提出了一种新的模型LKD4DyTAG，通过知识蒸馏将大型语言模型（LLM）的文本处理能力注入到动态图中，以生成更丰富的时空表示。实验表明该方法在六个现实世界的数据集上显著提升了未来链接预测等任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic Text-Attributed Graphs (DyTAGs) have numerous real-worldapplications, e.g. social, collaboration, citation, communication, and reviewnetworks. In these networks, nodes and edges often contain text descriptions,and the graph structure can evolve over time. Future link prediction, edgeclassification, relation generation, and other downstream tasks on DyTAGsrequire powerful representations that encode structural, temporal, and textualinformation. Although graph neural networks (GNNs) excel at handling structureddata, encoding temporal information within dynamic graphs remains a significantchallenge. In this work, we propose LLM-driven Knowledge Distillation forDynamic Text Attributed Graph (LKD4DyTAG) with temporal encoding to addressthese challenges. We use a simple, yet effective approach to encode temporalinformation in edges so that graph convolution can simultaneously capture bothtemporal and structural information in the hidden representations. To leverageLLM's text processing capabilities for learning richer representations onDyTAGs, we distill knowledge from LLM-driven edge representations (based on aneighborhood's text attributes) into saptio-temporal representations using alightweight GNN model that encodes temporal and structural information. Theobjective of knowledge distillation enables the GNN to learn representationsthat more effectively encode the available structural, temporal, and textualinformation in DyTAG. We conducted extensive experimentation on six real-worldDyTAG datasets to verify the effectiveness of our approach LKD4DyTAG for futurelink prediction and edge classification task. The results show that ourapproach significantly improves the performance of downstream tasks compared tothe baseline models.</description>
      <author>example@mail.com (Amit Roy, Ning Yan, Masood Mortazavi)</author>
      <guid isPermaLink="false">2502.10914v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>http://arxiv.org/abs/2502.10650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种改进的变分自动编码器（VAE）技术，即对抗性变分贝叶斯算法（AVB），用于项目因素分析（IFA）。这项工作通过结合生成对抗网络（GAN）的优势，提升了传统 VAE 的灵活性和准确性。&lt;h4&gt;背景&lt;/h4&gt;深度学习和表示学习的进步已经改变了项因子分析在项目响应理论文献中的面貌，使得更高效、更准确的参数估计成为可能。然而，基于传统变分自动编码器（VAE）的推断模型表达能力有限，仍然限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入 AVB 算法改进 IFA 中 VAE 的灵活性和准确性，并进一步提出了一种增强算法——重要加权对抗性变分贝叶斯（IWAVB），以应对更高维度的挑战。&lt;h4&gt;方法&lt;/h4&gt;将 GAN 和 VAE 结合形成 AVB，通过引入辅助判别网络重新定义估计过程为一个二人博弈问题。此算法还消除了标准正态分布假设的传统推断模型限制，并提出了重要加权对抗性变分贝叶斯（IWAVB）。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据的探索性分析中，IWAVB 通过实现更高的似然比展示出更好的表达能力，优于 IWAE。而在模拟数据的确证研究中，IWAVB 达到了与 IWAE 相同的平均平方误差结果，同时实现了更高的似然值，并且对于多模式分布的潜在变量情况，IWAVB 提供了更准确的参数估计。&lt;h4&gt;结论&lt;/h4&gt;鉴于其对 GAN 的创新使用，IWAVB 展示出在处理大规模数据方面扩展 IFA 的潜力，促进了心理测量学与多模态数据分析的融合可能性。&lt;h4&gt;翻译&lt;/h4&gt;在深度学习和表示学习的进步推动下，项目因子分析（IFA）得到了极大改进。然而，传统的变分自动编码器（VAE）表达能力不足限制了估计性能。此研究引入对抗性变分贝叶斯（AVB）算法提升 IFA 的灵活性与准确性，并提出重要加权对抗性变分贝叶斯（IWAVB），通过真实数据和模拟数据验证其优于传统方法，显示了在大规模数据处理中的潜力及心理测量学多模态数据分析的可能融合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in deep learning and representation learning have transformed itemfactor analysis (IFA) in the item response theory (IRT) literature by enablingmore efficient and accurate parameter estimation. Variational Autoencoders(VAEs) have been one of the most impactful techniques in modelinghigh-dimensional latent variables in this context. However, the limitedexpressiveness of the inference model based on traditional VAEs can stillhinder the estimation performance. This study introduces AdversarialVariational Bayes (AVB) algorithms as an improvement to VAEs for IFA withimproved flexibility and accuracy. By bridging the strengths of VAEs andGenerative Adversarial Networks (GANs), AVB incorporates an auxiliarydiscriminator network to reframe the estimation process as a two-playeradversarial game and removes the restrictive assumption of standard normaldistributions in the inference model. Theoretically, AVB can achieve similar orhigher likelihood compared to VAEs. A further enhanced algorithm,Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed andcompared with Importance-weighted Autoencoders (IWAE). In an exploratoryanalysis of real empirical data, IWAVB demonstrated superior expressiveness byachieving a higher likelihood compared to IWAE. In confirmatory studies withsimulated data, IWAVB achieved similar mean-square error results to IWAE whileconsistently achieving higher likelihoods. Moreover, in simulations wherelatent variables followed a multimodal distribution, IWAVB outperformed IWAE byproviding more accurate parameter estimates. With its innovative use of GANs,IWAVB is shown to have the potential to extend IFA to handle large-scale data,facilitating the potential integration of psychometrics and multimodal dataanalysis.</description>
      <author>example@mail.com (Nanyu Luo, Feng Ji)</author>
      <guid isPermaLink="false">2502.10650v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Robust Multidimensional Graph Neural Networks for Signal Processing in Wireless Communications with Edge-Graph Information Bottleneck</title>
      <link>http://arxiv.org/abs/2502.10869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的信号处理框架，结合了多维图神经网络（MDGNN）和边图信息瓶颈（EGIB），以应对未来第六代无线网络中的数据速率需求。&lt;h4&gt;背景&lt;/h4&gt;随着无线网络的快速增长，产生了大量的数据流量，传统优化理论算法的应用受到限制。同时，传统的图神经网络专注于将输入压缩到顶点上更新表示，这导致难以区分输入特征并削弱了性能。&lt;h4&gt;目的&lt;/h4&gt;设计高效的信号处理框架以解决当前面临的挑战，并在多径干扰和噪声的实际场景中提供鲁棒性解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过引入多维图神经网络（MDGNN）来替代顶点更新表示，同时利用边图信息瓶颈（EGIB）减少不相关的信息聚合，从而提高框架的性能和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的信号处理框架在多个任务中表现出色，在频谱效率（SE）和网络开销方面优于现有框架。尤其是当干扰噪声增加时，该框架的频谱效率逐渐稳定下来，显示出其在干扰环境中的优秀鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法为未来第六代无线网络中的信号处理提供了一种新颖且有效的解决方案，在多径干扰和高噪音环境中具有出色的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signal processing is crucial for satisfying the high data rate requirementsof future sixth-generation (6G) wireless networks. However, the rapid growth ofwireless networks has brought about massive data traffic, which hinders theapplication of traditional optimization theory-based algorithms. Meanwhile,traditional graph neural networks (GNNs) focus on compressing inputs ontovertices to update representations, which often leads to their inability toeffectively distinguish input features and severely weakens performance. Inthis context, designing efficient signal processing frameworks becomesimperative. Moreover, actual scenarios are susceptible to multipathinterference and noise, resulting in specific differences between the receivedand actual information. To address these challenges, this paper incorporatesmultidimensional graph neural networks (MDGNNs) with edge-graph informationbottleneck (EGIB) to design a robust framework for signal processing.Specifically, MDGNNs utilize hyper-edges instead of vertices to updaterepresentations to avoid indistinguishable features and reduce informationloss, while EGIB encourages providing minimal sufficient information aboutoutputs to avoid aggregation of irrelevant information. We numericallydemonstrate that compared with existing frameworks, the proposed frameworksachieve excellent performance in terms of spectrum efficiency (SE) and networkoverhead under multiple signal processing tasks. Remarkably, as theinterference noise increases, the SE performance of the proposed frameworksgradually stabilizes. This reveals the proposed frameworks have excellentrobustness in interference prone environments, especially in wireless policiesrelated to channel matrices.</description>
      <author>example@mail.com (Ziheng Liu, Jiayi Zhang, Yiyang Zhu, Enyu Shi, Bo Ai)</author>
      <guid isPermaLink="false">2502.10869v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SinSim: Sinkhorn-Regularized SimCLR</title>
      <link>http://arxiv.org/abs/2502.10478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SinSim是一种基于对比学习的自监督表示学习方法，通过引入Sinkhorn正则化来改进特征空间的结构。&lt;h4&gt;背景&lt;/h4&gt;自监督学习改变了无标签数据下的表示学习方式。然而，现有的对比学习方法如SimCLR虽然能够最大化图像增强视图间的相似度，但缺乏明确的正则化手段来确保全局结构化的潜在空间。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过结合最优传输理论中的Sinkhorn正则化，改进自监督对比学习的方法以克服现有技术的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的SimCLR扩展版本SinSim，该版本在训练过程中引入了熵正则化的Wasserstein距离（即Sinkhorn损失），以此鼓励特征空间的良好分散和几何感知能力，同时保持其判别力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与SimCLR相比，SinSim具有更好的性能。并且，在多个数据集上的评估显示，SinSim的表现优于其他著名的方法如VICReg和Barlow Twins；UMAP可视化进一步揭示了类别分离性得到提高以及特征分布变得更加结构化。&lt;h4&gt;结论&lt;/h4&gt;将最优传输正则化融入对比学习中提供了一种原则性和有效的机制来学习稳健且具有良好结构的表示。这为自监督框架中的运输约束的应用开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了通过引入Sinkhorn正则化的SinSim方法如何超越传统的SimCLR，展示了其在特征空间结构化和泛化能力上的改进，并强调了这种方法对未来研究的意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has revolutionized representation learning byeliminating the need for labeled data. Contrastive learning methods, such asSimCLR, maximize the agreement between augmented views of an image but lackexplicit regularization to enforce a globally structured latent space. Thislimitation often leads to suboptimal generalization. We propose SinSim, a novelextension of SimCLR that integrates Sinkhorn regularization from optimaltransport theory to enhance representation structure. The Sinkhorn loss, anentropy-regularized Wasserstein distance, encourages a well-dispersed andgeometry-aware feature space, preserving discriminative power. Empiricalevaluations on various datasets demonstrate that SinSim outperforms SimCLR andachieves competitive performance against prominent self-supervised methods suchas VICReg and Barlow Twins. UMAP visualizations further reveal improved classseparability and structured feature distributions. These results indicate thatintegrating optimal transport regularization into contrastive learning providesa principled and effective mechanism for learning robust, well-structuredrepresentations. Our findings open new directions for applying transport-basedconstraints in self-supervised learning frameworks.</description>
      <author>example@mail.com (M. Hadi Sepanj, Paul Fiegth)</author>
      <guid isPermaLink="false">2502.10478v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Generative Multi-Agent Collaboration in Embodied AI: A Systematic Review</title>
      <link>http://arxiv.org/abs/2502.11518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对具身多智能体系统（EMAS）如何利用生成模型的潜在能力进行了系统性综述，分析了这些系统的架构和实体表现形式，并探讨了集成基础模型对EMAS灵活性和鲁棒性的提升。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于复杂现实挑战的需求，尤其是物流和机器人领域，具身多智能体系统（EMAS）逐渐受到关注。随着基础模型的快速发展，生成型代理在丰富交流和适应性问题解决方面展现出了巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;本综述旨在探讨如何使EMAS从这些生成能力中受益，并提出一种分类法来根据系统的架构和实体表现形式对它们进行分类。&lt;h4&gt;方法&lt;/h4&gt;文章分析了构建模块（如感知、规划、通信和反馈）如何利用生成技术增强系统鲁棒性和灵活性，通过具体例子说明基础模型如何融入具身多代理框架带来的变革效应。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，集成基础模型到EMAS中可以显著提高其适应性、协作能力和解决问题的效率。&lt;h4&gt;结论&lt;/h4&gt;综述讨论了挑战和未来方向，强调了EMAS在重塑AI驱动合作领域的重大前景。&lt;h4&gt;翻译&lt;/h4&gt;具身多智能体系统（Embodied Multi-Agent Systems, EMAS）因其处理复杂现实世界挑战的能力而受到越来越多的关注。随着基础模型的最新进展，生成型代理具备更丰富的通信能力和适应性问题解决能力成为可能。本文提供了一个系统的EMAS如何从这些生成能力中受益的研究，并提出了一个分类法来根据系统架构和实体表现形式对它们进行分类。通过具体例子展示了将基础模型融入到具身多智能体框架中的变革效应，最终讨论了挑战与未来方向，强调了EMAS在重塑AI驱动合作领域的重大前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied multi-agent systems (EMAS) have attracted growing attention fortheir potential to address complex, real-world challenges in areas such aslogistics and robotics. Recent advances in foundation models pave the way forgenerative agents capable of richer communication and adaptive problem-solving.This survey provides a systematic examination of how EMAS can benefit fromthese generative capabilities. We propose a taxonomy that categorizes EMAS bysystem architectures and embodiment modalities, emphasizing how collaborationspans both physical and virtual contexts. Central building blocks, perception,planning, communication, and feedback, are then analyzed to illustrate howgenerative techniques bolster system robustness and flexibility. Throughconcrete examples, we demonstrate the transformative effects of integratingfoundation models into embodied, multi-agent frameworks. Finally, we discusschallenges and future directions, underlining the significant promise of EMASto reshape the landscape of AI-driven collaboration.</description>
      <author>example@mail.com (Di Wu, Xian Wei, Guang Chen, Hao Shen, Xiangfeng Wang, Wenhao Li, Bo Jin)</author>
      <guid isPermaLink="false">2502.11518v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>To Bin or not to Bin: Alternative Representations of Mass Spectra</title>
      <link>http://arxiv.org/abs/2502.10851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been submitted to the tiny paper track at the  LMRL workshop at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了如何通过不同的表示方法改进质谱数据在机器学习任务中的应用，特别是针对质量碎片光谱的处理。&lt;h4&gt;背景&lt;/h4&gt;质谱技术尤其是串联质谱被广泛用于评估样品的化学多样性。然而，这些技术产生的光谱往往需要进一步解析以确定分子结构或性质。&lt;h4&gt;目的&lt;/h4&gt;研究两种不依赖于光谱预处理（如分箱）的方法来直接表示质量碎片光谱：集合基和图基表示方法。&lt;h4&gt;方法&lt;/h4&gt;对比了基于这两种新表示法的机器学习模型，包括集变换器(Set Transformer) 和图神经网络(Graph Neural Network)，并将其与传统的多层感知机(MLP) 进行性能比较。&lt;h4&gt;主要发现&lt;/h4&gt;新的集合基和图基表示都显著优于用分箱数据训练的传统多层感知机。这表明直接处理原始光谱而不进行预处理可以提高模型的预测能力。&lt;h4&gt;结论&lt;/h4&gt;研究结果支持了采用新型表示法来直接使用原始质谱数据的有效性，为后续机器学习任务提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;质量谱分析，特别是所谓的串联质量谱分析，通常用于评估样品的化学多样性。生成的质量碎片光谱代表了可能未确定结构的分子。这给实验上确定或通过计算预测分子结构从质量光谱带来了挑战。一种替代方案是从光谱直接预测分子属性或相似性。已经提出了多种方法将质量光谱嵌入以供进一步用于机器学习任务。然而，这些方法通常需要对光谱进行预处理，例如分箱或子采样峰，主要原因是创造统一向量大小和去除噪声。在此研究中，我们探讨了两种在下游机器学习任务之前不使用分箱的替代方案：集合基表示法和图基表示法。对比这两种提议的方法分别训练一个集变换器（用于回归任务）和图神经网络，显示它们都比基于分箱数据的传统多层感知机模型表现出色得多。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mass spectrometry, especially so-called tandem mass spectrometry, is commonlyused to assess the chemical diversity of samples. The resulting massfragmentation spectra are representations of molecules of which the structuremay have not been determined. This poses the challenge of experimentallydetermining or computationally predicting molecular structures from massspectra. An alternative option is to predict molecular properties or molecularsimilarity directly from spectra. Various methodologies have been proposed toembed mass spectra for further use in machine learning tasks. However, thesemethodologies require preprocessing of the spectra, which often includesbinning or sub-sampling peaks with the main reasoning of creating uniformvector sizes and removing noise. Here, we investigate two alternatives to thebinning of mass spectra before down-stream machine learning tasks, namely,set-based and graph-based representations. Comparing the two proposedrepresentations to train a set transformer and a graph neural network on aregression task, respectively, we show that they both perform substantiallybetter than a multilayer perceptron trained on binned data.</description>
      <author>example@mail.com (Niek de Jonge, Justin J. J. van der Hooft, Daniel Probst)</author>
      <guid isPermaLink="false">2502.10851v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Medical Image Registration Meets Vision Foundation Model: Prototype Learning and Contour Awareness</title>
      <link>http://arxiv.org/abs/2502.11440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Information Processing in Medical Imaging (IPMI) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的医学图像配准框架，该框架利用Segment Anything Model (SAM) 生成的分割掩码来提供显式的解剖结构信息，并通过原型学习和边缘感知损失改进了传统方法仅依赖于强度相似度的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督可变形注册方法主要依靠基于强度的相似度指标，缺少明确的解剖学知识，导致其准确性和鲁棒性有限。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的限制，提出了一种新的SAM辅助配准框架，通过集成显式的解剖信息、原型学习和边缘感知损失来提高图像注册的准确性与鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;(1) 显式解剖信息注入：使用由SAM生成的分割掩码作为训练和测试过程中的辅助输入；(2) 原型学习：利用分割掩码提取原型特征，并对齐原型以优化图像间的语义对应关系；(3) 边缘感知损失：设计了一种基于分割掩码边缘信息的损失函数，用于改善模型在精细变形场上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，所提出的框架在多个数据集上显著优于现有方法，在具有复杂解剖结构和模糊边界的情况下尤其表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过引入显式的解剖知识和利用边缘感知损失，本文的工作提供了一种有效的方法来改善医学图像配准任务的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了医疗影像注册的基本任务，并提出了一个新的基于SAM辅助的配准框架，该框架包含三个主要部分：显式解剖信息注入、原型学习以及轮廓意识损耗。通过利用高质量的分割掩码和边缘信息来改进现有方法依赖强度相似度的局限性。实验表明所提出的方法在多个数据集上都表现优异，特别是在复杂结构下表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image registration is a fundamental task in medical image analysis,aiming to establish spatial correspondences between paired images. However,existing unsupervised deformable registration methods rely solely onintensity-based similarity metrics, lacking explicit anatomical knowledge,which limits their accuracy and robustness. Vision foundation models, such asthe Segment Anything Model (SAM), can generate high-quality segmentation masksthat provide explicit anatomical structure knowledge, addressing thelimitations of traditional methods that depend only on intensity similarity.Based on this, we propose a novel SAM-assisted registration frameworkincorporating prototype learning and contour awareness. The framework includes:(1) Explicit anatomical information injection, where SAM-generated segmentationmasks are used as auxiliary inputs throughout training and testing to ensurethe consistency of anatomical information; (2) Prototype learning, whichleverages segmentation masks to extract prototype features and alignsprototypes to optimize semantic correspondences between images; and (3)Contour-aware loss, a contour-aware loss is designed that leverages the edgesof segmentation masks to improve the model's performance in fine-graineddeformation fields. Extensive experiments demonstrate that the proposedframework significantly outperforms existing methods across multiple datasets,particularly in challenging scenarios with complex anatomical structures andambiguous boundaries. Our code is available athttps://github.com/HaoXu0507/IPMI25-SAM-Assisted-Registration.</description>
      <author>example@mail.com (Hao Xu, Tengfei Xue, Jianan Fan, Dongnan Liu, Yuqian Chen, Fan Zhang, Carl-Fredrik Westin, Ron Kikinis, Lauren J. O'Donnell, Weidong Cai)</author>
      <guid isPermaLink="false">2502.11440v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Row-Based Sparse Fine-Tuning</title>
      <link>http://arxiv.org/abs/2502.11439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的稀疏微调（Sparse Fine-tuning, SFT）框架，该框架基于神经网络修剪的原理。通过实验表明，在保持训练时间和实现复杂度不变的同时，可以显著提高SFT的记忆效率，并且在准确率上与最先进的方法如LoRA及其变体相当。&lt;h4&gt;背景&lt;/h4&gt;为了使具有有限计算预算的用户能够更便捷地适应大型语言模型到下游任务中，需要开发内存和计算效率更高的微调方法。稀疏微调（Sparse Fine-tuning, SFT）和低秩适应（Low-rank adaptation, LoRA）是为解决这一问题而出现并广泛应用的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于神经网络修剪原理的SFT框架，以提高其内存效率，并保持训练时间和实现复杂度不变的同时，在准确率上与最先进的方法如LoRA及其变体相当。&lt;h4&gt;方法&lt;/h4&gt;首先使用来自神经网络修剪中的结构化剪枝方法识别出'重要'的神经元/节点；然后在涉及这些神经元的权重范围内进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验，在常见语言任务上证明了该方法能够在不增加训练时间复杂度和实现复杂度的情况下，显著提高SFT的记忆效率，并且达到与最先进的方法（如LoRA及其变体）相媲美的准确率。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的基于修剪原理的稀疏微调框架，该框架在保持高准确性的同时提升了内存效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning is an important step in adapting foundation models such as largelanguage models to downstream tasks. To make this step more accessible to userswith limited computational budgets, it is crucial to develop fine-tuningmethods that are memory and computationally efficient. Sparse Fine-tuning (SFT)and Low-rank adaptation (LoRA) are two frameworks that have emerged foraddressing this problem and have been adopted widely in practice. In this work,we develop a new SFT framework, based on ideas from neural network pruning. Ata high level, we first identify "important" neurons/nodes using featureimportance metrics from network pruning (specifically, we use the structuralpruning method), and then perform fine-tuning by restricting to weightsinvolving these neurons. Using experiments on common language tasks, wedemonstrate that our method significantly improves the memory efficiency of SFTwithout increasing training time complexity and implementation complexity,while achieving accuracy comparable to state-of-the-art methods such as LoRAand its variants.</description>
      <author>example@mail.com (Cen-Jhih Li, Aditya Bhaskara)</author>
      <guid isPermaLink="false">2502.11439v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs: Bridging Recurrent and Graph Learning</title>
      <link>http://arxiv.org/abs/2502.10818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了通过线性控制理论的视角来统一理解图神经网络（GNN）中的过度平滑和过度压缩问题的方法。&lt;h4&gt;背景&lt;/h4&gt;GNN利用消息传递机制在节点之间传输信息，然而这种方法容易遭受过度平滑和过度压缩现象的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的理解和缓解这些问题的方法，并探讨如何设计更深层且高效的图神经网络。&lt;h4&gt;方法&lt;/h4&gt;通过将GNN视作递归模型并应用线性控制理论中的思想来分析问题。同时，通过简单的状态空间形式化有效减轻了过度平滑和过度压缩的问题。&lt;h4&gt;主要发现&lt;/h4&gt;(i) GNN由于设计原因在经过几层后容易出现极端梯度消失；(ii) 过度平滑直接与导致梯度消失的机制相关联；(iii) 过度压缩可以通过图重新布线和缓解梯度消失的方式最有效地减轻。&lt;h4&gt;结论&lt;/h4&gt;这项工作有助于弥合递归神经网络和图神经网络文献之间的差距，并为设计新的深度高效GNN打开了道路。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) 是利用图形结构通过消息传递机制在节点之间传输信息的模型。尽管取得了广泛的成功，这种做法已知会遭受过度平滑和过度压缩现象的影响，导致随着层数增加而代表性的崩溃，并且对于距离遥远及连接不良节点的信息不敏感。在这篇论文中，我们从消失梯度的角度提出了一种统一理解这些问题的方法，使用了线性控制理论的思想进行分析。我们提出了将GNN视作递归模型的解释，并通过实验证明，一个简单的状态空间形式化能够有效地缓解过度平滑和过度压缩的问题而无需额外可训练参数成本。此外，我们从理论上和实验上表明：(i) 由于设计原因，即使经过几层后GNN也容易出现极端梯度消失；(ii) 过度平滑直接与导致梯度消失的机制相关；(iii) 过度压缩可以通过图重新布线和缓解梯度消失的方式最有效地减轻。我们相信这项工作将有助于弥合递归和图神经网络文献之间的差距，并为设计新的深度且高效的GNN打开新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are models that leverage the graph structure totransmit information between nodes, typically through the message-passingoperation. While widely successful, this approach is well known to suffer fromthe over-smoothing and over-squashing phenomena, which result inrepresentational collapse as the number of layers increases and insensitivityto the information contained at distant and poorly connected nodes,respectively. In this paper, we present a unified view of these problemsthrough the lens of vanishing gradients, using ideas from linear control theoryfor our analysis. We propose an interpretation of GNNs as recurrent models andempirically demonstrate that a simple state-space formulation of a GNNeffectively alleviates over-smoothing and over-squashing at no extra trainableparameter cost. Further, we show theoretically and empirically that (i) GNNsare by design prone to extreme gradient vanishing even after a few layers; (ii)Over-smoothing is directly related to the mechanism causing vanishinggradients; (iii) Over-squashing is most easily alleviated by a combination ofgraph rewiring and vanishing gradient mitigation. We believe our work will helpbridge the gap between the recurrent and graph neural network literature andwill unlock the design of new deep and performant GNNs.</description>
      <author>example@mail.com (Álvaro Arroyo, Alessio Gravina, Benjamin Gutteridge, Federico Barbero, Claudio Gallicchio, Xiaowen Dong, Michael Bronstein, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2502.10818v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Small World of Word Embeddings: A Comparative Study on Conceptual Spaces from LLMs of Different Scales</title>
      <link>http://arxiv.org/abs/2502.11380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;概念空间表示概念为节点和语义相关性为边。词嵌入结合相似度指标提供了一种有效的方法来构建这种空间。&lt;h4&gt;目的&lt;/h4&gt;研究不同规模的大语言模型（LLMs）的词嵌入属性，探索它们在构建概念空间中的作用，并进行跨语言语义映射分析。&lt;h4&gt;方法&lt;/h4&gt;使用不同规模的LLM构造概念空间，基于语言类型学启发的连通性假设建立网络，分析全局统计性质和比较不同规模的LLMs。局部层面则探讨概念对、WordNet关系以及跨语言语义网络。&lt;h4&gt;主要发现&lt;/h4&gt;构建的空间具有小世界特性，表现为高聚类系数和短路径长度；更大规模的LLM生成更为复杂的空间，长路径反映了更丰富的关系结构和连接；网络作为高效的跨语言语义映射桥梁。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了不同规模的大语言模型在构造概念空间中的独特贡献以及它们如何促进有效的跨语言语义理解。&lt;h4&gt;翻译&lt;/h4&gt;A conceptual space represents concepts as nodes and semantic relatedness as edges. Word embeddings, combined with a similarity metric, provide an effective approach to constructing such a space. Typically, embeddings are derived from traditional distributed models or encoder-only pretrained models, whose objectives directly capture the meaning of the current token. In contrast, decoder-only models, including large language models (LLMs), predict the next token, making their embeddings less directly tied to the current token's semantics. Moreover, comparative studies on LLMs of different scales remain underexplored. In this paper, we construct a conceptual space using word embeddings from LLMs of varying scales and comparatively analyze their properties.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A conceptual space represents concepts as nodes and semantic relatedness asedges. Word embeddings, combined with a similarity metric, provide an effectiveapproach to constructing such a space. Typically, embeddings are derived fromtraditional distributed models or encoder-only pretrained models, whoseobjectives directly capture the meaning of the current token. In contrast,decoder-only models, including large language models (LLMs), predict the nexttoken, making their embeddings less directly tied to the current token'ssemantics. Moreover, comparative studies on LLMs of different scales remainunderexplored. In this paper, we construct a conceptual space using wordembeddings from LLMs of varying scales and comparatively analyze theirproperties. We establish a network based on a linguistic typology-inspiredconnectivity hypothesis, examine global statistical properties, and compareLLMs of varying scales. Locally, we analyze conceptual pairs, WordNetrelations, and a cross-lingual semantic network for qualitative words. Ourresults indicate that the constructed space exhibits small-world properties,characterized by a high clustering coefficient and short path lengths. LargerLLMs generate more intricate spaces, with longer paths reflecting richerrelational structures and connections. Furthermore, the network serves as anefficient bridge for cross-lingual semantic mapping.</description>
      <author>example@mail.com (Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun)</author>
      <guid isPermaLink="false">2502.11380v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction</title>
      <link>http://arxiv.org/abs/2502.10776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的基于蒸馏的未来感知图神经网络框架（DishFT-GNN），用于股票趋势预测。&lt;h4&gt;背景&lt;/h4&gt;股票趋势预测涉及通过分析历史数据和各种市场指标来预测未来的股价走势。随着机器学习的进步，由于其强大的能力能够捕捉股票的空间时间依赖关系，图神经网络(GNNs)在股市预测中得到了广泛的应用。&lt;h4&gt;目的&lt;/h4&gt;尽管已有多种GNN股票预测器尝试提高预测性能，但它们仅关注分析历史空间时间依赖性，忽视了历史和未来模式之间的相关性。因此，研究目的是提出一种能够同时捕捉历史和未来数据分布变化之间关系的模型。&lt;h4&gt;方法&lt;/h4&gt;DishFT-GNN通过迭代训练教师模型和学生模型来实现。教师模型学习到的历史和未来数据分布变化的相关信息被用作中间监督信号，引导学生模型学习对未来感知的空间时间嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;通过在两个真实世界的数据集上进行广泛的实验验证了DishFT-GNN的最先进的性能表现。&lt;h4&gt;结论&lt;/h4&gt;提出的基于蒸馏的未来感知图神经网络框架（DishFT-GNN）可以有效地捕捉历史和未来的相关性，从而提高股票趋势预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;股票趋势预测涉及通过分析历史数据和各种市场指标来预测未来的股价走势。随着机器学习的进步，由于其强大的能力能够捕捉股票的空间时间依赖关系，图神经网络(GNNs)在股市预测中得到了广泛的应用。然而，尽管已有多种GNN股票预测器尝试提高预测性能，但它们仅关注分析历史空间时间依赖性，忽视了历史和未来模式之间的相关性。本文提出了一种新的基于蒸馏的未来感知图神经网络框架（DishFT-GNN）。通过在两个真实世界的数据集上进行广泛的实验验证了该方法的先进性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stock trend prediction involves forecasting the future price movements byanalyzing historical data and various market indicators. With the advancementof machine learning, graph neural networks (GNNs) have been extensivelyemployed in stock prediction due to their powerful capability to capturespatiotemporal dependencies of stocks. However, despite the efforts of variousGNN stock predictors to enhance predictive performance, the improvements remainlimited, as they focus solely on analyzing historical spatiotemporaldependencies, overlooking the correlation between historical and futurepatterns. In this study, we propose a novel distillation-based future-aware GNNframework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNNtrains a teacher model and a student model, iteratively. The teacher modellearns to capture the correlation between distribution shifts of historical andfuture data, which is then utilized as intermediate supervision to guide thestudent model to learn future-aware spatiotemporal embeddings for accurateprediction. Through extensive experiments on two real-world datasets, we verifythe state-of-the-art performance of DishFT-GNN.</description>
      <author>example@mail.com (Zhipeng Liu, Peibo Duan, Mingyang Geng, Bin Zhang)</author>
      <guid isPermaLink="false">2502.10776v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>WRT-SAM: Foundation Model-Driven Segmentation for Generalized Weld Radiographic Testing</title>
      <link>http://arxiv.org/abs/2502.11338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Segment Anything Model (SAM)的新型焊缝射线检测缺陷分割模型WRT-SAM，通过适配器集成和专业化提示生成架构，提升了对灰度焊缝射线图像的适应性。此外，引入了频域提示生成模块来增强模型敏感性，并使用多尺度提示生成模块处理焊接缺陷的多层次特性。&lt;h4&gt;背景&lt;/h4&gt;放射检测是非破坏评估技术之一，用于识别焊接缺陷并评价工业应用中的质量。近年来，深度学习在焊缝缺陷识别中取得了显著进步。然而，传统的基于单一场景数据集训练的小规模模型泛化能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于SAM的焊缝射线缺陷分割方法，以提高跨领域泛化的性能，并在不同焊接检测场景中实现应用。&lt;h4&gt;方法&lt;/h4&gt;WRT-SAM通过adapter-based集成方式利用了预先训练好的视觉基础模型SAM。此外，为了增强适应性，引入了一个频率提示生成模块和一个多尺度提示生成模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，WRT-SAM在焊缝射线图像缺陷分割任务上取得了78.87%的召回率、84.04%的精确度以及0.9746的AUC值，刷新了该领域的最新基准。同时展示了优异的零样本泛化性能。&lt;h4&gt;结论&lt;/h4&gt;WRT-SAM模型展现了在焊缝射线图像缺陷分割中的卓越性能和广泛适用性，为实际部署提供了坚实基础。&lt;h4&gt;翻译&lt;/h4&gt;放射检测是一种基本的非破坏性评估技术，利用其高分辨率成像能力来识别焊接缺陷并评价工业应用中的质量。近年来，深度学习技术显著推进了焊接缺陷在射线图像中的识别进展。然而，依赖于单一场景数据集训练的小规模模型的传统方法，在跨领域泛化方面表现不佳。最近，Segment Anything Model (SAM)，一个基于大规模数据集预训练的视觉基础模型，展示了卓越的零样本泛化能力。利用有限的特定领域数据对SAM进行微调，在医学图像分割和异常检测等领域取得了显著成果。据我们所知，这项工作是首次将基于SAM的分割技术应用于通用焊接射线检测图像。我们提出了一种新的焊缝射线缺陷分割模型WRT-SAM，该模型利用了SAM并通过适配器集成与专业化提示生成架构结合。为了提高对灰度焊缝射线图像的适应性，引入了一个频率提示生成模块，增强了模型对频域信息的敏感性。此外，为了解决焊接缺陷多尺度问题，我们集成了一个多尺度提示生成模块，使模型能够有效地在不同尺度下提取和编码缺陷信息。广泛的实验评估表明，WRT-SAM实现了78.87%的召回率、84.04%的精确度以及AUC值为0.9746，设立了一个新的行业标准（SOTA）。此外，该模型展示了优秀的零样本泛化性能，突显了其在各种射线检测场景中实际部署的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radiographic testing is a fundamental non-destructive evaluation techniquefor identifying weld defects and assessing quality in industrial applicationsdue to its high-resolution imaging capabilities. Over the past decade, deeplearning techniques have significantly advanced weld defect identification inradiographic images. However, conventional approaches, which rely on trainingsmall-scale, task-specific models on single-scenario datasets, exhibit poorcross-scenario generalization. Recently, the Segment Anything Model (SAM), apre-trained visual foundation model trained on large-scale datasets, hasdemonstrated exceptional zero-shot generalization capabilities. Fine-tuning SAMwith limited domain-specific data has yielded promising results in fields suchas medical image segmentation and anomaly detection. To the best of ourknowledge, this work is the first to introduce SAM-based segmentation forgeneral weld radiographic testing images. We propose WRT-SAM, a novel weldradiographic defect segmentation model that leverages SAM through anadapter-based integration with a specialized prompt generator architecture. Toimprove adaptability to grayscale weld radiographic images, we introduce afrequency prompt generator module, which enhances the model's sensitivity tofrequency-domain information. Furthermore, to address the multi-scale nature ofweld defects, we incorporate a multi-scale prompt generator module, enablingthe model to effectively extract and encode defect information across varyingscales. Extensive experimental evaluations demonstrate that WRT-SAM achieves arecall of 78.87%, a precision of 84.04%, and an AUC of 0.9746, setting a newstate-of-the-art (SOTA) benchmark. Moreover, the model exhibits superiorzero-shot generalization performance, highlighting its potential for practicaldeployment in diverse radiographic testing scenarios.</description>
      <author>example@mail.com (Yunyi Zhou, Kun Shi, Gang Hao)</author>
      <guid isPermaLink="false">2502.11338v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities</title>
      <link>http://arxiv.org/abs/2502.10750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, Accepted for publication in the ACM WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究背景': '社区检测是社交网络分析中的重要问题，旨在识别内部联系紧密而外部链接较少的社团。然而，随着生成式AI和元宇宙的发展，出现了混合的人类-AI社交网络（HASN），这使得传统的社区检测方法在处理人类为中心的情境时效果不佳。', '研究目的': '提出一种新的MetaCD问题，即在HASN中增强人类连接的同时减少AI节点的存在。旨在解决排除某些AI节点与保持社团结构之间的微妙平衡问题。', '所提方案': '提出了CUSA框架，该框架使用了考虑AI的聚类技术来优化这种权衡，在保留对社区完整性有益的AI节点的同时，排除不适当的AI节点。', '数据策略': '鉴于现实世界中的HASN稀缺，设计了四种方法在各种假设场景下合成这些网络。', '实验结果': '实验证明了该方法与传统的非深度学习和图神经网络（GNN）技术相比，在重新配置为HASN的真实社交网络上的有效性及实用性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714679&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Community detection is a cornerstone problem in social network analysis(SNA), aimed at identifying cohesive communities with minimal external links.However, the rise of generative AI and Metaverse introduce complexities bycreating hybrid human-AI social networks (denoted by HASNs), where traditionalmethods fall short, especially in human-centric settings. This paper introducesa novel community detection problem in HASNs (denoted by MetaCD), which seeksto enhance human connectivity within communities while reducing the presence ofAI nodes. Effective processing of MetaCD poses challenges due to the delicatetrade-off between excluding certain AI nodes and maintaining communitystructure. To address this, we propose CUSA, an innovative frameworkincorporating AI-aware clustering techniques that navigate this trade-off byselectively retaining AI nodes that contribute to community integrity.Furthermore, given the scarcity of real-world HASNs, we devise four strategiesfor synthesizing these networks under various hypothetical scenarios. Empiricalevaluations on real social networks, reconfigured as HASNs, demonstrate theeffectiveness and practicality of our approach compared to traditional non-deeplearning and graph neural network (GNN)-based methods.</description>
      <author>example@mail.com (Shih-Hsuan Chiu, Ya-Wen Teng, De-Nian Yang, Ming-Syan Chen)</author>
      <guid isPermaLink="false">2502.10750v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Phantom: Subject-consistent video generation via cross-modal alignment</title>
      <link>http://arxiv.org/abs/2502.11079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Phantom是一个用于生成单个和多个参考主体的统一视频生成框架，通过跨模态对齐学习提高了文本和图像提示之间的平衡。&lt;h4&gt;背景&lt;/h4&gt;基础模型在视频生成领域的持续发展正在向各种应用拓展，而基于主题一致性的视频生成仍处于探索阶段。这个领域被称为Subject-to-Video。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决Subject-to-Video中的跨模态对齐问题，特别是针对人类主体的一致性生成。&lt;h4&gt;方法&lt;/h4&gt;构建了一个统一的框架Phantom，该框架基于现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据驱动其学习跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;强调人类生成中的主体一致性，覆盖现有的身份保持型视频生成同时提供增强的优势。&lt;h4&gt;结论&lt;/h4&gt;Phantom框架在Subject-to-Video问题上取得了显著进展，为未来的视频生成技术提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在视频生成领域的持续发展正在向各种应用拓展，而基于主题一致性的视频生成仍处于探索阶段。我们称之为Subject-to-Video，该方法从参考图像中提取主体元素，并通过文本指令生成主体一致性视频。我们认为，Subject-to-Video的核心在于平衡文本和图像双模态提示，从而同时深入对齐文本和视觉内容。为此，我们提出了Phantom框架，用于单个和多个参考主体的统一视频生成。该框架基于现有的文本到视频和图像到视频架构，重新设计了联合文本-图像注入模型，并通过文本-图像-视频三元组数据驱动其学习跨模态对齐。特别地，我们在人类生成中强调主体一致性，涵盖了现有身份保持型视频生成的同时提供了增强的优势。该项目主页在这里：https://phantom-video.github.io/Phantom/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The continuous development of foundational models for video generation isevolving into various applications, with subject-consistent video generationstill in the exploratory stage. We refer to this as Subject-to-Video, whichextracts subject elements from reference images and generatessubject-consistent video through textual instructions. We believe that theessence of subject-to-video lies in balancing the dual-modal prompts of textand image, thereby deeply and simultaneously aligning both text and visualcontent. To this end, we propose Phantom, a unified video generation frameworkfor both single and multi-subject references. Building on existingtext-to-video and image-to-video architectures, we redesign the jointtext-image injection model and drive it to learn cross-modal alignment viatext-image-video triplet data. In particular, we emphasize subject consistencyin human generation, covering existing ID-preserving video generation whileoffering enhanced advantages. The project homepage is herehttps://phantom-video.github.io/Phantom/.</description>
      <author>example@mail.com (Lijie Liu, Tianxiang Ma, Bingchuan Li, Zhuowei Chen, Jiawei Liu, Qian He, Xinglong Wu)</author>
      <guid isPermaLink="false">2502.11079v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Automated Data Quality Validation in an End-to-End GNN Framework</title>
      <link>http://arxiv.org/abs/2502.10667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于改进的图神经网络（GNN）和多任务学习的数据质量验证与修复框架DQuag。该方法采用双解码器设计，分别用于数据质量和数据修复，并且能够自动检测显式和隐藏的数据错误。&lt;h4&gt;背景&lt;/h4&gt;确保数据质量对于现代数据生态系统至关重要，尤其是在机器学习中的训练或测试数据集方面。现有验证方法依赖于计算数据质量指标和/或使用专家定义的约束条件。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需手动输入约束生成、能够自动检测复杂特征关系的数据质量验证与修复框架，以提高数据质量和解决传统系统难以发现的问题。&lt;h4&gt;方法&lt;/h4&gt;DQuag采用改进的图神经网络（GNN）架构和多任务学习技术来捕捉表格数据中的复杂特性关系，并通过双解码器设计实现数据质量验证和数据修复功能。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够自动检测传统系统经常忽略的隐藏错误，无需手动生成约束条件即可学习底层特征依赖关系。&lt;h4&gt;结论&lt;/h4&gt;实验结果证明了这种方法在识别和解决数据质量问题方面的有效性，并强调其不需要人工干预来定义约束条件的优势。&lt;h4&gt;翻译&lt;/h4&gt;确保数据质量是现代数据生态系统的关键要素，特别是在训练或测试机器学习模型的数据集中。现有验证方法通常依赖于计算数据质量指标以及专家定义的规则。尽管存在自动化的约束生成技术，但它们往往不完整且可能过于严格或宽松，导致误报或遗漏错误，从而需要人工调整。此外，这些方法在检测由复杂关系掩盖的细微数据差异时表现不佳。本文提出了一种基于改进图神经网络和多任务学习的端到端框架DQuag，用于数据质量验证与修复。该框架使用双解码器结构，一个用于数据质量验证，另一个用于数据修复。通过采用多层次图神经网络架构，我们的方法可以捕捉表格数据集中的复杂特性关系，并自动检测显性和隐性的数据错误。与以往的方法不同的是，我们这种方法不需要人为生成约束条件，而是学习到特征之间的依赖性，从而能够识别传统系统常会忽视的隐藏错误。此外，它还可以建议修复值，进一步提升整体的数据质量。实验结果证明了该方法的有效性，在识别和解决数据质量问题方面表现优异。本文发表于2025年EDBT会议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring data quality is crucial in modern data ecosystems, especially fortraining or testing datasets in machine learning. Existing validationapproaches rely on computing data quality metrics and/or using expert-definedconstraints. Although there are automated constraint generation methods, theyare often incomplete and may be too strict or too soft, causing false positivesor missed errors, thus requiring expert adjustment. These methods may also failto detect subtle data inconsistencies hidden by complex interdependencieswithin the data. In this paper, we propose DQuag, an end-to-end data qualityvalidation and repair framework based on an improved Graph Neural Network (GNN)and multi-task learning. The proposed method incorporates a dual-decoderdesign: one for data quality validation and the other for data repair. Ourapproach captures complex feature relationships within tabular datasets using amulti-layer GNN architecture to automatically detect explicit and hidden dataerrors. Unlike previous methods, our model does not require manual input forconstraint generation and learns the underlying feature dependencies, enablingit to identify complex hidden errors that traditional systems often miss.Moreover, it can recommend repair values, improving overall data quality.Experimental results validate the effectiveness of our approach in identifyingand resolving data quality issues. The paper appeared in EDBT 2025.</description>
      <author>example@mail.com (Sijie Dong, Soror Sahri, Themis Palpanas, Qitong Wang)</author>
      <guid isPermaLink="false">2502.10667v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>ClimateLLM: Efficient Weather Forecasting via Frequency-Aware Large Language Models</title>
      <link>http://arxiv.org/abs/2502.11059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;天气预报对于公共安全、灾害预防和缓解、农业生产以及能源管理至关重要。虽然深度学习在气象预测方面取得了显著进展，但目前的方法存在局限性：难以捕捉动态时间依赖性和短期突变变化，导致极端天气建模困难；计算成本高昂；对多尺度频率的适应能力有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，我们提出了ClimateLLM这一用于天气预报的基础模型。该模型旨在通过融合基于傅里叶的方法和大型语言模型来加强空间和时间建模，同时处理全球信号和局部极端事件。&lt;h4&gt;方法&lt;/h4&gt;ClimateLLM使用了一种混合专家机制（MoE），能够灵活处理不同的频率成分；还引入了跨时间和空间的动态提示机制，使大型语言模型能够有效地整合多尺度气象模式。此外，其框架集成了基于傅里叶的方法与大型语言模型来增强空间和时间建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在真实世界数据集上ClimateLLM比现有的最佳方法在准确性和效率方面表现更佳，是一个可扩展的全球天气预报解决方案。&lt;h4&gt;结论&lt;/h4&gt;该论文提出了一种新的基于深度学习的方法，用于改进极端气象事件预测及提高计算资源利用率。这种方法通过增强时间序列分析和频率分解能力，有望为未来的研究提供一个坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要的原始内容已经包含中文表述&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weather forecasting is crucial for public safety, disaster prevention andmitigation, agricultural production, and energy management, with globalrelevance. Although deep learning has significantly advanced weatherprediction, current methods face critical limitations: (i) they often struggleto capture both dynamic temporal dependencies and short-term abrupt changes,making extreme weather modeling difficult; (ii) they incur high computationalcosts due to extensive training and resource requirements; (iii) they havelimited adaptability to multi-scale frequencies, leading to challenges whenseparating global trends from local fluctuations. To address these issues, wepropose ClimateLLM, a foundation model for weather forecasting. It capturesspatiotemporal dependencies via a cross-temporal and cross-spatialcollaborative modeling framework that integrates Fourier-based frequencydecomposition with Large Language Models (LLMs) to strengthen spatial andtemporal modeling. Our framework uses a Mixture-of-Experts (MoE) mechanism thatadaptively processes different frequency components, enabling efficienthandling of both global signals and localized extreme events. In addition, weintroduce a cross-temporal and cross-spatial dynamic prompting mechanism,allowing LLMs to incorporate meteorological patterns across multiple scaleseffectively. Extensive experiments on real-world datasets show that ClimateLLMoutperforms state-of-the-art approaches in accuracy and efficiency, as ascalable solution for global weather forecasting.</description>
      <author>example@mail.com (Shixuan Li, Wei Yang, Peiyu Zhang, Xiongye Xiao, Defu Cao, Yuehan Qin, Xiaole Zhang, Yue Zhao, Paul Bogdan)</author>
      <guid isPermaLink="false">2502.11059v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Recent Advances in Malware Detection: Graph Learning and Explainability</title>
      <link>http://arxiv.org/abs/2502.10556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;该论文综述了恶意软件检测领域的最新进展，特别是图学习技术和可解释性技术之间的相互作用。&lt;h4&gt;背景&lt;/h4&gt;恶意软件的快速演变需要超越传统基于签名的方法的复杂检测手段。图学习技术利用图神经网络（GNN）和其他相关方法，成为了建模和分析恶意软件行为中固有复杂关系的强大工具。&lt;h4&gt;目的&lt;/h4&gt;综述旨在全面探索近期在恶意软件检测方面的进展，并强调图学习与可解释性之间的相互作用的重要性。&lt;h4&gt;研究范围&lt;/h4&gt;论文首先回顾了恶意软件分析技术和数据集的现状，这些是理解恶意软件行为和支持检测策略的基础。然后讨论了特征工程、图简化和图嵌入方法，以展示将原始数据转换为实用见解的重要意义，并确保系统可扩展性和效率。&lt;h4&gt;重点技术&lt;/h4&gt;强调了在恶意软件检测中应用可解释性技术的重要性，包括透明度和信任度的保证。&lt;h4&gt;综合贡献&lt;/h4&gt;通过整合这些组件，该综述展示了图学习与可解释性的结合如何有助于构建稳健、可解释且高效的恶意软件检测系统。&lt;h4&gt;未来方向&lt;/h4&gt;论文还概述了未来的研究方向，以解决当前挑战并开启新的机遇。&lt;h4&gt;翻译&lt;/h4&gt;摘要：恶意软件的快速演变促使发展出超越传统基于签名方法的复杂检测手段。图学习技术已作为建模和分析恶意行为中固有复杂关系的强大工具而出现，并利用图神经网络（GNNs）和其他相关方法的进步。这篇综述全面探讨了近期在恶意软件检测方面的进展，重点是图学习与可解释性的相互作用。它首先回顾了恶意软件分析技术和数据集，强调它们理解恶意行为和支撑检测策略的基础性角色。然后讨论了特征工程、图简化及图嵌入方法，突显这些技术将原始数据转化为实用见解的重要意义，并确保系统的可扩展性和效率。此外，综述重点在于解释性技术和其在恶意软件检测中的应用，以保证透明度与信任度。通过整合这些组件，该综述展示了如何利用图学习和解释性构建稳健、可解读且高效的恶意软件检测系统。它还概述了未来的研究方向，旨在应对现有挑战并解锁新的机遇，以解决这个网络安全关键领域的难题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of malware has necessitated the development ofsophisticated detection methods that go beyond traditional signature-basedapproaches. Graph learning techniques have emerged as powerful tools formodeling and analyzing the complex relationships inherent in malware behavior,leveraging advancements in Graph Neural Networks (GNNs) and related methods.This survey provides a comprehensive exploration of recent advances in malwaredetection, focusing on the interplay between graph learning and explainability.It begins by reviewing malware analysis techniques and datasets, emphasizingtheir foundational role in understanding malware behavior and supportingdetection strategies. The survey then discusses feature engineering, graphreduction, and graph embedding methods, highlighting their significance intransforming raw data into actionable insights, while ensuring scalability andefficiency. Furthermore, this survey focuses on explainability techniques andtheir applications in malware detection, ensuring transparency andtrustworthiness. By integrating these components, this survey demonstrates howgraph learning and explainability contribute to building robust, interpretable,and scalable malware detection systems. Future research directions are outlinedto address existing challenges and unlock new opportunities in this criticalarea of cybersecurity.</description>
      <author>example@mail.com (Hossein Shokouhinejad, Roozbeh Razavi-Far, Hesamodin Mohammadian, Mahdi Rabbani, Samuel Ansong, Griffin Higgins, Ali A Ghorbani)</author>
      <guid isPermaLink="false">2502.10556v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Accelerated co-design of robots through morphological pretraining</title>
      <link>http://arxiv.org/abs/2502.10862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了'零样本进化'的概念，即通过形态预训练来快速获得适用于多种机器人身体布局的通用控制器，并展示了这种方法可以比同时优化控制器和设计群体的方法产生更大的多样性。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人形态与神经控制共设计方法需要大量的训练数据来评估每种设计方案的表现。这通常涉及到使用强化学习来为每个身体计划近似一个唯一的控制策略梯度。&lt;h4&gt;目的&lt;/h4&gt;展示通过可微模拟的基于梯度优化可以直接快速获得适用于所有机器人体形的通用控制器，从而减少对大量训练数据的需求，并促进机器人设计探索。&lt;h4&gt;方法&lt;/h4&gt;采用形态预训练过程：首先使用可微分模拟进行优化得到一个通用控制器；然后在不改变控制器的前提下，通过非连续变化调整机器人的物理布局（例如添加、删除或重新组合离散的身体部件）来评估其性能。&lt;h4&gt;主要发现&lt;/h4&gt;零样本进化方法能够迅速产生多种高性能的设计方案，并且在整个进化过程中通过对当前设计群体进行微调来保持和增加多样性。相比之下，同时优化控制器与不断演化的设计方案会导致“多样性崩溃”，即群体（及其训练数据）会收敛到易于使用共享通用控制器控制的类似设计。&lt;h4&gt;结论&lt;/h4&gt;零样本进化方法不仅能够有效地探索机器人设计空间，还能够在不牺牲性能的前提下实现更广泛的多样性，从而避免了多样性的丧失。这种方法为快速高效的机器人形态和控制系统的设计提供了一个新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The co-design of robot morphology and neural control typically requires usingreinforcement learning to approximate a unique control policy gradient for eachbody plan, demanding massive amounts of training data to measure theperformance of each design. Here we show that a universal, morphology-agnosticcontroller can be rapidly and directly obtained by gradient-based optimizationthrough differentiable simulation. This process of morphological pretrainingallows the designer to explore non-differentiable changes to a robot's physicallayout (e.g. adding, removing and recombining discrete body parts) andimmediately determine which revisions are beneficial and which are deleterioususing the pretrained model. We term this process "zero-shot evolution" andcompare it with the simultaneous co-optimization of a universal controlleralongside an evolving design population. We find the latter results indiversity collapse, a previously unknown pathology whereby the population --and thus the controller's training data -- converges to similar designs thatare easier to steer with a shared universal controller. We show that zero-shotevolution with a pretrained controller quickly yields a diversity of highlyperformant designs, and by fine-tuning the pretrained controller on the currentpopulation throughout evolution, diversity is not only preserved butsignificantly increased as superior performance is achieved.</description>
      <author>example@mail.com (Luke Strgar, Sam Kriegman)</author>
      <guid isPermaLink="false">2502.10862v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Preconditioned Inexact Stochastic ADMM for Deep Model</title>
      <link>http://arxiv.org/abs/2502.10784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PISA的算法，该算法在训练基础模型时能够支持大规模并行计算，并且能够在仅假设梯度李普希兹连续性的条件下保证收敛。&lt;h4&gt;背景&lt;/h4&gt;近年来，基础模型（FMs）的发展带来了范式转变，在全球各个领域产生革命性影响。然而，基于随机梯度下降的常用优化算法在分布式设置下遇到数据异质性和理论及数值性能方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的优化算法PISA，以解决现有算法面对的数据异质性和并行计算规模问题，并提高训练基础模型时的数值表现和收敛效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PISA（预处理不精确随机交替方向乘子法）的新算法，该算法支持多种二阶矩方案，并在严格的理论保证下证明了其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估结果表明，在训练或微调不同类型的基础模型时，包括视觉模型、大型语言模型、强化学习模型等，PISA的数值性能优于现有的多种最先进优化器。&lt;h4&gt;结论&lt;/h4&gt;通过解决数据异质性问题和提高并行计算能力，PISA算法为大规模基础模型的有效训练提供了强大支持。&lt;h4&gt;翻译&lt;/h4&gt;最近基础模型的发展带来了范式转变，在全球各个领域产生了革命性的影响。本文提出了一个名为PISA的算法来应对这些问题，该算法能够支持大规模并行计算，并在理论上保证了即使存在数据异质性的条件下也具有良好的数值性能和收敛性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancement of foundation models (FMs) has brought about aparadigm shift, revolutionizing various sectors worldwide. The popularoptimizers used to train these models are stochastic gradient descent-basedalgorithms, which face inherent limitations, such as slow convergence andstringent assumptions for convergence. In particular, data heterogeneityarising from distributed settings poses significant challenges to theirtheoretical and numerical performance. This paper develops an algorithm, PISA({P}reconditioned {I}nexact {S}tochastic {A}lternating Direction Method ofMultipliers), which enables scalable parallel computing and supports varioussecond-moment schemes. Grounded in rigorous theoretical guarantees, thealgorithm converges under the sole assumption of Lipschitz continuity of thegradient, thereby removing the need for other conditions commonly imposed bystochastic methods. This capability enables PISA to tackle the challenge ofdata heterogeneity effectively. Comprehensive experimental evaluations fortraining or fine-tuning diverse FMs, including vision models, large languagemodels, reinforcement learning models, generative adversarial networks, andrecurrent neural networks, demonstrate its superior numerical performancecompared to various state-of-the-art optimizers.</description>
      <author>example@mail.com (Shenglong Zhou, Ouya Wang, Ziyan Luo, Yongxu Zhu, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2502.10784v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>HIPPo: Harnessing Image-to-3D Priors for Model-free Zero-shot 6D Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.10606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无需预处理CAD模型和参考图像的零样本6D物体姿态估计框架HIPPo。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在精确估算6D物体姿态时，严重依赖于精心准备的CAD模型或参考图像。然而，在实际场景中这些资源可能不可用，且准备过程耗时费力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架HIPPo，利用扩散模型中的图像到3D先验知识进行零样本6D姿态估计。&lt;h4&gt;方法&lt;/h4&gt;{'构建HIPPo Dreamer': '这是一个基于多视角扩散模型和三维重建基础模型的快速图象转网格模型。它可以仅凭一张图片生成任何未见过物体的三维网格。', '逐步优化': '通过测量引导方案，逐步用更可靠的在线观测替换初步的扩散先验，以实现持续优化。'}&lt;h4&gt;主要发现&lt;/h4&gt;HIPPo能够在瞬间估算和跟踪新颖对象的6D姿态，并保持一个完整的网格模型用于即时机器人应用。&lt;h4&gt;结论&lt;/h4&gt;在各种基准测试中，当先前参考图像有限时，HIPPo在6D物体姿态估计方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;这项工作关注的是无需预处理CAD模型和参考图像的零样本六自由度（6D）物体姿态估计技术。现有的方法虽然能够精确估算6D物体姿态，但它们严重依赖于精心准备的CAD模型或参考图像。这些资源在实际场景中可能不可用，并且准备工作耗时费力。本文提出了一种新框架HIPPo，它利用扩散模型中的图象到3D先验知识进行零样本6D姿态估计。通过一个快速的图像转网格模型HIPPo Dreamer，该框架能够在几秒钟内仅凭一张图片生成任何未见过物体的三维网格，并随着观察数据增加持续优化其性能。实验表明，在先前参考图像有限的情况下，HIPPo在六自由度（6D）物体姿态估计方面优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work focuses on model-free zero-shot 6D object pose estimation forrobotics applications. While existing methods can estimate the precise 6D poseof objects, they heavily rely on curated CAD models or reference images, thepreparation of which is a time-consuming and labor-intensive process. Moreover,in real-world scenarios, 3D models or reference images may not be available inadvance and instant robot reaction is desired. In this work, we propose a novelframework named HIPPo, which eliminates the need for curated CAD models andreference images by harnessing image-to-3D priors from Diffusion Models,enabling model-free zero-shot 6D pose estimation. Specifically, we constructHIPPo Dreamer, a rapid image-to-mesh model built on a multiview Diffusion Modeland a 3D reconstruction foundation model. Our HIPPo Dreamer can generate a 3Dmesh of any unseen objects from a single glance in just a few seconds. Then, asmore observations are acquired, we propose to continuously refine the diffusionprior mesh model by joint optimization of object geometry and appearance. Thisis achieved by a measurement-guided scheme that gradually replaces theplausible diffusion priors with more reliable online observations.Consequently, HIPPo can instantly estimate and track the 6D pose of a novelobject and maintain a complete mesh for immediate robotic applications.Thorough experiments on various benchmarks show that HIPPo outperformsstate-of-the-art methods in 6D object pose estimation when prior referenceimages are limited.</description>
      <author>example@mail.com (Yibo Liu, Zhaodong Jiang, Binbin Xu, Guile Wu, Yuan Ren, Tongtong Cao, Bingbing Liu, Rui Heng Yang, Amir Rasouli, Jinjun Shan)</author>
      <guid isPermaLink="false">2502.10606v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in 3D MRIs of the Knee Joint</title>
      <link>http://arxiv.org/abs/2502.10559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了一种用于从3D MRI图像中分割软骨和半月板的深度学习方法，该方法基于交互式的、具有记忆功能的视觉基础模型，并通过融合策略改进空间感知。&lt;h4&gt;背景&lt;/h4&gt;膝关节骨关节炎监测需要准确评估软骨厚度/体积等形态学参数。然而，当前的软骨分割技术依赖于大量专家标注的数据集，并且容易受到阅读者间差异的影响。&lt;h4&gt;目的&lt;/h4&gt;探索视觉基础模型（尤其是记忆型方法）在提高泛化能力和鲁棒性方面的机会，开发一种深度学习方法来改善膝关节MRI图像中软骨和半月板的分割准确性。&lt;h4&gt;方法&lt;/h4&gt;研究团队训练了四个AI模型：一个基于CNN的3D-VNet、两个自动变压器模型（SaMRI2D和SaMRI3D），以及一个记忆型视觉基础模型（SAMRI-2）。这些模型在包含来自270名患者的公共和内部数据集上进行训练，并在外部分为57例患者的数据集中进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;引入了混合洗牌策略（HSS）以提高空间感知能力和收敛性，使用分割掩码传播技术来提升注释效率。实验表明，SAMRI-2模型在所有其他模型中表现最佳，在Dice Score和交并比上平均提高了5分，对于胫骨软骨最高甚至提升了12分。&lt;h4&gt;结论&lt;/h4&gt;这种基于记忆的视觉基础模型提供了可靠的人工智能辅助膝关节MRI分割的新方法，并显著降低了软骨厚度误差。SAMRI-2模型仅需最少三个用户点击即可实现高精度解剖学注释，为肌骨骼成像领域的深度学习研究开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;Accurate morphometric assessment of cartilage such as thickness/volume via MRI is essential for monitoring knee osteoarthritis. Segmenting cartilage remains challenging and dependent on extensive expert-annotated datasets, which are heavily subjected to inter-reader variability. Recent advancements in Visual Foundational Models (VFM), especially memory-based approaches, offer opportunities for improving generalizability and robustness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate morphometric assessment of cartilage-such as thickness/volume-viaMRI is essential for monitoring knee osteoarthritis. Segmenting cartilageremains challenging and dependent on extensive expert-annotated datasets, whichare heavily subjected to inter-reader variability. Recent advancements inVisual Foundational Models (VFM), especially memory-based approaches, offeropportunities for improving generalizability and robustness. This studyintroduces a deep learning (DL) method for cartilage and meniscus segmentationfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awarenessand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) duringtraining and applied a segmentation mask propagation technique to enhanceannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, twoautomatic transformer-based models (SaMRI2D and SaMRI3D), and atransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from270 patients using public and internal datasets and evaluated on 57 externalcases, including multi-radiologist annotations and different data acquisitions.Model performance was assessed against reference standards using Dice Score(DSC) and Intersection over Union (IoU), with additional morphometricevaluations to further quantify segmentation accuracy. SAMRI-2 model, trainedwith HSS, outperformed all other models, achieving an average DSC improvementof 5 points, with a peak improvement of 12 points for tibial cartilage. It alsodemonstrated the lowest cartilage thickness errors, reducing discrepancies byup to threefold. Notably, SAMRI-2 maintained high performance with as few asthree user clicks per volume, reducing annotation effort while ensuringanatomical precision. This memory-based VFM with spatial awareness offers anovel approach for reliable AI-assisted knee MRI segmentation, advancing DL inmusculoskeletal imaging.</description>
      <author>example@mail.com (Danielle L. Ferreira, Bruno A. A. Nunes, Xuzhe Zhang, Laura Carretero Gomez, Maggie Fung, Ravi Soni)</author>
      <guid isPermaLink="false">2502.10559v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs</title>
      <link>http://arxiv.org/abs/2502.10522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种名为GraphiT的框架，用于将图数据编码成文本格式，并优化大语言模型（LLMs）在图预测任务中的提示语。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型应用于图形数据的研究受到了广泛关注。这些模型允许使用预先训练好的模型的深度上下文嵌入来处理带有文本属性的节点。然而，如何有效地将图结构和特征编码成序列形式以供LLMs使用仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法（GraphiT框架），以便更高效地利用图数据中的信息，并优化LLM提示语，使得它们在没有人工干预的情况下也能有效工作。&lt;h4&gt;方法&lt;/h4&gt;1. 将每个节点及其邻域的图数据编码成简洁的文本格式；2. 使用DSPy框架对LLM提示语进行程序化优化，以提高效率和可重复性。&lt;h4&gt;主要发现&lt;/h4&gt;GraphiT在三个数据集上的性能优于基于LLMs的基本模型，并且通过自动化的优化步骤可以在没有手动调整的情况下获得更好的结果。此外，该图编码方法的成本较低，因为它使用的令牌数量显著减少。&lt;h4&gt;结论&lt;/h4&gt;GraphiT提供了一种新的有效的方法来处理带有文本属性的节点分类问题，同时降低了计算成本和人工干预的需求。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在图形数据中的应用最近引起了广泛关注。这些模型允许我们使用预先训练好的深度上下文嵌入来进行具有文本属性图上的任务，在这种情况下，通常为节点的文本属性使用浅层嵌入。然而，如何有效地将图结构和特征编码成序列形式以供LLMs使用仍然是一个挑战。此外，单一LLM的表现高度依赖于输入提示语的结构，这限制了它们作为可靠方法的有效性，并且往往需要反复的手动调整，这种做法可能缓慢、繁琐并且难以编程地复制。在本文中，我们提出了一种名为GraphiT（文本中的图）的框架，该框架将图形编码为文本格式，并优化LLM提示语以用于图预测任务。在这里，我们专注于带有文本属性图的节点分类。我们将每个节点及其邻域的图数据编码成简洁文本，使LLMs能够更好地利用图中的信息。然后，我们进一步使用DSPy框架对LLM提示语进行程序化优化，以便自动化这一步骤并使其更高效和可重复。GraphiT在三个数据集上优于我们的基于LLMs的基本模型，并展示了GraphiT中优化步骤如何导致没有手动调整提示词的明显更好的结果。我们也证明了我们的图编码方法与其他图编码方法具有竞争力，但成本更低，因为它使用相同的任务显著较少的令牌。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of large language models (LLMs) to graph data has attracted alot of attention recently. LLMs allow us to use deep contextual embeddings frompretrained models in text-attributed graphs, where shallow embeddings are oftenused for the text at- tributes of nodes. However, it is still challenging toefficiently en- code the graph structure and features into a sequential formfor use by LLMs. In addition, the performance of an LLM alone, is highlydependent on the structure of the input prompt, which limits theireffectiveness as a reliable approach and often requires iterative man- ualadjustments that could be slow, tedious and difficult to replicateprogrammatically. In this paper, we propose GraphiT (Graphs in Text), aframework for encoding graphs into a textual format and optimizing LLM promptsfor graph prediction tasks. Here we focus on node classification fortext-attributed graphs. We encode the graph data for every node and itsneighborhood into a concise text to enable LLMs to better utilize theinformation in the graph. We then further programmatically optimize the LLMprompts us- ing the DSPy framework to automate this step and make it moreefficient and reproducible. GraphiT outperforms our LLM-based baselines onthree datasets and we show how the optimization step in GraphiT leads tomeasurably better results without manual prompt tweaking. We also demonstratedthat our graph encoding approach is competitive to other graph encoding methodswhile being less expensive because it uses significantly less tokens for thesame task.</description>
      <author>example@mail.com (Shima Khoshraftar, Niaz Abedini, Amir Hajian)</author>
      <guid isPermaLink="false">2502.10522v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Cluster and Predict Latent Patches for Improved Masked Image Modeling</title>
      <link>http://arxiv.org/abs/2502.08769v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 7 figures, submitted to TMLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的自我监督表示学习框架CAPI，该框架通过预测潜在聚类来改进现有的Masked Image Modeling (MIM) 方法。&lt;h4&gt;背景&lt;/h4&gt;当前的MIM模型虽然在自监督表征学习方面有前景，但性能仍落后于最先进的方法。研究者分析了目标表征、损失函数和架构，以期提升MIM的表现力。&lt;h4&gt;目的&lt;/h4&gt;通过设计一种全新的基于聚类的损失函数并采用纯MIM框架来改进现有模型的表现。&lt;h4&gt;方法&lt;/h4&gt;引入CAPI框架，利用稳定的聚类损失，并在ViT-L骨干网络上实现了这一创新。此外还展示了该方法在ImageNet和ADE20K数据集上的性能表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用简单的线性探测器，CAPI在ImageNet上达到了83.8%的准确率，在ADE20K上实现了32.1%mIoU，显著优于之前的MIM方法，并接近于DINOv2的最佳效果。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种新的纯MIM框架CAPI，通过预测潜在聚类来改进自监督学习表示。实验结果证明了其优越性，并且发布了所有代码和模型以供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;掩码图像建模（MIM）为自我监督表征学习提供了一个有前景的方法，然而现有MIM模型仍然落后于最先进的技术。在本文中，我们系统地分析了目标表示、损失函数和架构，引入了一种新的纯MIM框架CAPI，该框架依赖于潜在聚类的预测。我们的方法利用基于聚类的损失，训练稳定，并展示了有前景的扩展属性。使用ViT-L骨干网络，我们的模型在ImageNet上达到了83.8%的准确率，在ADE20K上实现了32.1%mIoU，显著优于以前的MIM方法并接近目前最先进的性能DINOv2。我们发布了所有代码和模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/facebookresearch/capi&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Image Modeling (MIM) offers a promising approach to self-supervisedrepresentation learning, however existing MIM models still lag behind thestate-of-the-art. In this paper, we systematically analyze targetrepresentations, loss functions, and architectures, to introduce CAPI - a novelpure-MIM framework that relies on the prediction of latent clusterings. Ourapproach leverages a clustering-based loss, which is stable to train, andexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,substantially outperforming previous MIM methods and approaching theperformance of the current state-of-the-art, DINOv2. We release all our codeand models.</description>
      <author>example@mail.com (Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski)</author>
      <guid isPermaLink="false">2502.08769v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Applying Deep Learning to Ads Conversion Prediction in Last Mile Delivery Marketplace</title>
      <link>http://arxiv.org/abs/2502.10514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, submitted to KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Deep神经网络（DNN）在大规模网页排名系统中实现了革命性的变革，通过捕捉复杂用户行为和驱动性能提升。DoorDash首次将主页广告排名系统从传统的树模型转变为前沿的多任务DNN，在此过程中推动了数据基础、模型设计、训练效率、评估严谨性和线上服务等方面的发展。&lt;h4&gt;背景&lt;/h4&gt;Deep神经网络（DNN）在大规模网页排序系统中实现了革命性的变革，特别是在捕捉复杂用户行为和驱动性能提升方面。在此之前，DoorDash使用传统的树基模型来管理其主页广告排名系统。&lt;h4&gt;目的&lt;/h4&gt;通过分享从识别正确问题到开发和扩展深度学习推荐系统的整个过程中所遇到的挑战和解决方案，为其他寻求类似机器学习系统改进的团队提供见解和实际指导。&lt;h4&gt;方法&lt;/h4&gt;详细介绍了将传统决策树模型转换为多任务DNN的过程，并探讨了这一转变所带来的数据基础、模型设计、训练效率等方面的进步。&lt;h4&gt;主要发现&lt;/h4&gt;此次转变为DoorDash带来了显著的业务影响，改善了其广告排名系统的性能，并且重塑了公司对机器学习应用的理解和方法论。&lt;h4&gt;结论&lt;/h4&gt;通过展示将传统系统转化为基于DNN的多任务排序系统的过程中的经验和教训，论文鼓励其他团队在追求类似技术改进时借鉴这些经验。&lt;h4&gt;翻译&lt;/h4&gt;深度神经网络（DNN）已经在大规模网页排名系统中引发了革命，使捕捉复杂用户行为和性能提升成为可能。DoorDash首次利用这一变革性力量，将主页广告排名系统从传统的树模型转换为最先进的多任务DNN。这种演变促进了数据基础、模型设计、训练效率、评估严谨性和在线服务等方面的发展，并带来了显著的业务影响，重新定义了公司在机器学习方面的做法。在本文中，我们讨论了问题驱动的研究旅程，从识别正确的挑战并制定针对性解决方案到克服开发和扩展深度学习推荐系统的复杂性。通过我们的成功经验和教训，我们旨在为寻求类似机器学习系统改进团队提供见解和实用指南。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have revolutionized web-scale ranking systems,enabling breakthroughs in capturing complex user behaviors and drivingperformance gains. At DoorDash, we first harnessed this transformative power bytransitioning our homepage Ads ranking system from traditional tree basedmodels to cutting edge multi task DNNs. This evolution sparked advancements indata foundations, model design, training efficiency, evaluation rigor, andonline serving, delivering substantial business impact and reshaping ourapproach to machine learning. In this paper, we talk about our problem drivenjourney, from identifying the right problems and crafting targeted solutions toovercoming the complexity of developing and scaling a deep learningrecommendation system. Through our successes and learned lessons, we aim toshare insights and practical guidance to teams pursuing similar advancements inmachine learning systems.</description>
      <author>example@mail.com (Di Li, Xiaochang Miao, Huiyu Song, Chao Chu, Hao Xu, Mandar Rahurkar)</author>
      <guid isPermaLink="false">2502.10514v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of World Models for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2501.11260v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Ongoing project&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统地回顾了自动驾驶领域世界模型的最新进展，并提出了一种三层次分类体系，包括未来物理世界的生成、智能代理的行为规划以及预测与规划之间的交互。&lt;h4&gt;背景&lt;/h4&gt;最近在自主驾驶方面的突破主要得益于稳健的世界建模技术的进步，这从根本上改变了车辆对动态场景的理解和安全决策执行的方式。世界模型已经成为关键技术，提供高保真度的驾驶环境表示，并整合了多传感器数据、语义线索和时间动力学。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在分析世界模型在自动驾驶中的应用进展，并提出未来的研究挑战，以推进复杂城市环境中自主驾驶解决方案的安全性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个三层次的世界模型分类体系：1) 生成未来的物理世界；2) 智能代理的行为规划；3) 预测与规划之间的交互。此外，还分析了包括自监督学习、多模态预训练和生成数据增强在内的培训范例。&lt;h4&gt;主要发现&lt;/h4&gt;文章强调了在场景理解和运动预测任务中评估世界模型性能的重要性，并指出未来研究需要解决关键挑战如自我监督表示学习、长尾场景生成以及多模态融合，以推动复杂城市环境中的实际部署。&lt;h4&gt;结论&lt;/h4&gt;通过全面分析，本文提供了利用世界模型的变革潜力来推进安全可靠的自主驾驶解决方案的理论框架和技术路线图。&lt;h4&gt;翻译&lt;/h4&gt;最近在自动驾驶方面的突破主要得益于稳健的世界建模技术的进步，这从根本上改变了车辆对动态场景的理解和安全决策执行的方式。研究提出了一种三层次分类体系：1) 生成未来的物理世界；2) 智能代理的行为规划；3) 预测与规划之间的交互。此外还分析了训练范例，包括自监督学习、多模态预训练以及生成数据增强，并评估了在场景理解和运动预测任务中世界模型的性能。未来研究必须解决关键挑战如自我监督表示学习、长尾场景生成及多模态融合来推进复杂城市环境中的实际部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in autonomous driving have been propelled by advances inrobust world modeling, fundamentally transforming how vehicles interpretdynamic scenes and execute safe decision-making. In particular, world modelshave emerged as a linchpin technology, offering high-fidelity representationsof the driving environment that integrate multi-sensor data, semantic cues, andtemporal dynamics. This paper systematically reviews recent advances in worldmodels for autonomous driving, proposing a three-tiered taxonomy: 1) Generationof Future Physical World, covering image-, BEV-, OG-, and PC-based generationmethods that enhance scene evolution modeling through diffusion models and 4Doccupancy forecasting; 2) Behavior Planning for Intelligent Agents, combiningrule-driven and learning-based paradigms with cost map optimization andreinforcement learning for trajectory generation in complex traffic conditions;3) Interaction Between Prediction and Planning, achieving multi-agentcollaborative decision-making through latent space diffusion andmemory-augmented architectures. The study further analyzes training paradigmsincluding self-supervised learning, multimodal pretraining, and generative dataaugmentation, while evaluating world models' performance in scene understandingand motion prediction tasks. Future research must address key challenges inself-supervised representation learning, long-tail scenario generation, andmultimodal fusion to advance the practical deployment of world models incomplex urban environments. Overall, our comprehensive analysis provides atheoretical framework and technical roadmap for harnessing the transformativepotential of world models in advancing safe and reliable autonomous drivingsolutions.</description>
      <author>example@mail.com (Tuo Feng, Wenguan Wang, Yi Yang)</author>
      <guid isPermaLink="false">2501.11260v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>http://arxiv.org/abs/2502.10248v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要要点总结&lt;/h4&gt;{'模型名称': 'Step-Video-T2V', '参数数量': '30B 参数', '视频生成能力': '最多可生成 204 帧的视频', '压缩技术': '设计了深度压缩Variational Autoencoder (Video-VAE)，空间压缩比为16x16，时间压缩比为8倍', '编码方式': '使用两种双语文本编码器处理英语和中文', '去噪方法': '采用DiT（具有3D全注意力机制）进行去噪输入噪声到潜在帧中', '质量改进技术': '应用视频基底DPO (Video-DPO) 方法减少伪影，提高生成视频的视觉质量', '训练策略和观察': '详细描述了训练策略，并分享关键观察结果和见解', '评估基准': '在Step-Video-T2V-Eval上进行性能评估，显示与开源及商业引擎相比具有先进的文本到视频质量', '未来方向': '讨论当前基于扩散模型的范式的局限性并提出未来研究的方向', '可用资源': '在 https://github.com/stepfun-ai/Step-Video-T2V 和 https://yuewen.cn/videos 上提供在线版本'}&lt;h4&gt;翻译&lt;/h4&gt;我们提出了Step-Video-T2V，这是一个拥有30B参数的最先进的文本到视频预训练模型，能够生成最长达到204帧的视频。为了视频生成任务设计了一种深度压缩的Variational Autoencoder (Video-VAE)，实现了16x16的空间和8倍的时间压缩率，并保持了卓越的视频重建质量。用户提示使用两种双语文本编码器进行处理，以支持英语和中文输入。通过流动匹配技术训练了一个具有3D全注意力机制的DiT用于将输入噪声去噪为潜在帧。采用了一种基于视频的DPO方法（Video-DPO）来减少伪影并提高生成视频的视觉质量。我们详细描述了我们的训练策略，并分享了关键观察结果和见解。Step-Video-T2V在一项新颖的视频生成基准测试，即Step-Video-T2V-Eval上进行了性能评估，在与开源及商业引擎比较时展示了先进的文本到视频质量。此外，我们还讨论了当前基于扩散模型范式的局限性，并提出了未来研究的方向。我们将Step-Video-T2V及其评估工具公开在https://github.com/stepfun-ai/Step-Video-T2V上，并且在线版本可以通过 https://yuewen.cn/videos 访问。我们的目标是加速视频基础模型的创新并支持视频内容创作者。&lt;h4&gt;背景&lt;/h4&gt;当前存在对高效、高质量文本到视频转换的需求，尤其是在人工智能和多媒体领域&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成高品质长视频序列的新一代预训练模型，并探索其在不同应用中的潜力&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术（包括压缩算法和去噪技术）以及双语支持来提高视频质量及通用性&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained modelwith 30B parameters and the ability to generate videos up to 204 frames inlength. A deep compression Variational Autoencoder, Video-VAE, is designed forvideo generation tasks, achieving 16x16 spatial and 8x temporal compressionratios, while maintaining exceptional video reconstruction quality. Userprompts are encoded using two bilingual text encoders to handle both Englishand Chinese. A DiT with 3D full attention is trained using Flow Matching and isemployed to denoise input noise into latent frames. A video-based DPO approach,Video-DPO, is applied to reduce artifacts and improve the visual quality of thegenerated videos. We also detail our training strategies and share keyobservations and insights. Step-Video-T2V's performance is evaluated on a novelvideo generation benchmark, Step-Video-T2V-Eval, demonstrating itsstate-of-the-art text-to-video quality when compared with both open-source andcommercial engines. Additionally, we discuss the limitations of currentdiffusion-based model paradigm and outline future directions for videofoundation models. We make both Step-Video-T2V and Step-Video-T2V-Evalavailable at https://github.com/stepfun-ai/Step-Video-T2V. The online versioncan be accessed from https://yuewen.cn/videos as well. Our goal is toaccelerate the innovation of video foundation models and empower video contentcreators.</description>
      <author>example@mail.com (Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua Cheng, Na Wang, Qiaohui Chen, Qinglin He, Qiuyan Liang, Quan Sun, Ran Sun, Rui Wang, Shaoliang Pang, Shiliang Yang, Sitong Liu, Siqi Liu, Shuli Gao, Tiancheng Cao, Tianyu Wang, Weipeng Ming, Wenqing He, Xu Zhao, Xuelin Zhang, Xianfang Zeng, Xiaojia Liu, Xuan Yang, Yaqi Dai, Yanbo Yu, Yang Li, Yineng Deng, Yingming Wang, Yilei Wang, Yuanwei Lu, Yu Chen, Yu Luo, Yuchu Luo, Yuhe Yin, Yuheng Feng, Yuxiang Yang, Zecheng Tang, Zekai Zhang, Zidong Yang, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang)</author>
      <guid isPermaLink="false">2502.10248v2</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning Getting-Up Policies for Real-World Humanoid Robots</title>
      <link>http://arxiv.org/abs/2502.12152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://humanoid-getup.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自动恢复站立是人形机器人可靠部署的一个关键前提。本文开发了一个学习框架来生成控制器，使人形机器人能够在不同地形和摔倒后各种姿态的情况下重新站起来。&lt;h4&gt;背景&lt;/h4&gt;手动设计用于帮助人形机器人从摔倒中恢复的控制器非常困难，因为机器人可能处于多种不同的姿势，并且需要在复杂的地面上工作。&lt;h4&gt;目的&lt;/h4&gt;通过一个学习框架开发能够让人形机器人从复杂情况下站立起来的控制策略。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段的方法来解决这一问题：第一阶段关注发现良好的重新站立轨迹，而第二阶段则将这种运动改进为可以在实际环境中稳定运行的动作。&lt;h4&gt;主要发现&lt;/h4&gt;新的创新使得一个真实的G1人形机器人能够在多种摔倒情况和地形下重新站起来。例如，无论是面部朝上还是面部朝下，机器人都能在平坦的、变形的、滑溜的地面上以及斜坡（如泥泞草地或雪地）中重新站立。&lt;h4&gt;结论&lt;/h4&gt;据我们所知，这是首次成功展示的人形机器人在真实世界环境中学习到的重新站立策略。&lt;h4&gt;翻译&lt;/h4&gt;自动恢复站立是人形机器人可靠部署的一个关键前提。手动设计用于帮助人形机器人从摔倒中恢复的控制器非常困难，因为机器人可能处于多种不同的姿势，并且需要在复杂的地面上工作。本论文开发了一种学习框架来生成控制器，使人形机器人能够在不同地形和摔倒后各种姿态的情况下重新站起来。与之前的人形行走学习成功案例不同的是，站立起来的任务涉及到复杂的接触模式，这需要准确地建模碰撞几何图形并使用更稀疏的奖励。我们通过一个遵循课程大纲的两阶段方法解决了这些挑战：第一阶段关注发现良好的重新站立轨迹，在此阶段不会对平滑度或速度/扭矩限制施加过多约束；第二阶段则将这种运动改进为可以在实际环境中稳定运行的动作，使其能够应对初始配置和地形的变化。实验结果表明，通过这种方法，一个真实的G1人形机器人能够在两种主要情况下重新站立：面部朝上或者面部朝下，并且这两种情况都是在平坦的、变形的、滑溜的地面上以及斜坡（如泥泞草地或雪地）中进行测试。据我们所知，这是首次成功展示的人形机器人在真实世界环境中学习到的重新站立策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic fall recovery is a crucial prerequisite before humanoid robots canbe reliably deployed. Hand-designing controllers for getting up is difficultbecause of the varied configurations a humanoid can end up in after a fall andthe challenging terrains humanoid robots are expected to operate on. This paperdevelops a learning framework to produce controllers that enable humanoidrobots to get up from varying configurations on varying terrains. Unlikeprevious successful applications of humanoid locomotion learning, thegetting-up task involves complex contact patterns, which necessitatesaccurately modeling the collision geometry and sparser rewards. We addressthese challenges through a two-phase approach that follows a curriculum. Thefirst stage focuses on discovering a good getting-up trajectory under minimalconstraints on smoothness or speed / torque limits. The second stage thenrefines the discovered motions into deployable (i.e. smooth and slow) motionsthat are robust to variations in initial configuration and terrains. We findthese innovations enable a real-world G1 humanoid robot to get up from two mainsituations that we considered: a) lying face up and b) lying face down, bothtested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grassand snowfield). To the best of our knowledge, this is the first successfuldemonstration of learned getting-up policies for human-sized humanoid robots inthe real world. Project page: https://humanoid-getup.github.io/</description>
      <author>example@mail.com (Xialin He, Runpei Dong, Zixuan Chen, Saurabh Gupta)</author>
      <guid isPermaLink="false">2502.12152v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>A Monocular Event-Camera Motion Capture System</title>
      <link>http://arxiv.org/abs/2502.12113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种基于单目事件相机的运动捕捉系统被开发出来，适用于狭窄空间中的物体跟踪。&lt;h4&gt;背景&lt;/h4&gt;传统的多视角运动捕捉系统依赖于多个摄像头和被动反射标记物来确定对象的位置，这使得它们不适合在狭窄的空间中使用。&lt;h4&gt;目的&lt;/h4&gt;提出一个适合在狭窄空间使用的单目事件相机运动捕捉系统，并克服现有系统的局限性。&lt;h4&gt;方法&lt;/h4&gt;该系统利用主动闪烁的LED标志物（每个标志物通过不同的闪烁频率进行唯一标识），并结合PnP问题解决技术来确定物体的位置和姿态。&lt;h4&gt;主要发现&lt;/h4&gt;开发的系统具有毫米级精度，毫秒级延迟，并且可以用于控制小型、灵活的四旋翼飞行器。&lt;h4&gt;结论&lt;/h4&gt;提出的单目事件相机运动捕捉系统为狭窄空间内的对象跟踪提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;动作捕捉系统在研究中广泛使用以记录物体的真实姿态。商用系统通过在物体上附加反射标记并从多个摄像机视角进行三角定位来确定物体的姿态。因此，该物体必须对多个摄像头可见，这使得多视图运动捕捉系统不适合狭窄、受限空间（例如船舶压载舱）的部署。在这份技术报告中，我们描述了一种单目事件相机动作捕捉系统，它克服了这一限制，并特别适合于狭小的空间使用。代替被动标记物，该系统依赖于主动闪烁的LED标志物，每个标志物通过不同的闪烁频率进行唯一标识。这些标志物被放置在跟踪物体上的已知位置。然后我们解决PnP（透视N点）问题以获得对象的位置和方向。开发的系统的精度为毫米级，延迟为毫秒级，并且我们可以证明其状态估计可以用于飞行小型、敏捷的四旋翼飞行器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion capture systems are a widespread tool in research to recordground-truth poses of objects. Commercial systems use reflective markersattached to the object and then triangulate pose of the object from multiplecamera views. Consequently, the object must be visible to multiple cameraswhich makes such multi-view motion capture systems unsuited for deployments innarrow, confined spaces (e.g. ballast tanks of ships). In this technical reportwe describe a monocular event-camera motion capture system which overcomes thislimitation and is ideally suited for narrow spaces. Instead of passive markersit relies on active, blinking LED markers such that each marker can be uniquelyidentified from the blinking frequency. The markers are placed at knownlocations on the tracking object. We then solve the PnP (perspective-n-points)problem to obtain the position and orientation of the object. The developedsystem has millimeter accuracy, millisecond latency and we demonstrate that itsstate estimate can be used to fly a small, agile quadrotor.</description>
      <author>example@mail.com (Leonard Bauersfeld, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2502.12113v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Bandwidth-Adaptive Spatiotemporal Correspondence Identification for Collaborative Perception</title>
      <link>http://arxiv.org/abs/2502.12098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种新的带宽自适应时空对应识别（CoID）方法，用于解决多机器人协作感知中的通信限制问题。&lt;h4&gt;背景&lt;/h4&gt;在现实世界的应用中，如互联自主驾驶车辆面临由于有限的通信带宽而无法直接共享原始观察数据的问题。这阻碍了多机器人系统在各自视野内一致地引用同一对象的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，该研究提出了一种新的方法来解决协作感知中的带宽适应性时空CoID问题。&lt;h4&gt;方法&lt;/h4&gt;所提出的方案允许机器人逐步选择部分时空观察并与他人共享这些信息，并且能够根据不断变化的通信限制进行调整。&lt;h4&gt;实验结果&lt;/h4&gt;通过连接自主驾驶模拟的各种场景对所提出的方法进行了评估，结果显示该方法能够在动态通信带宽下实现CoID并适应其变化。&lt;h4&gt;性能改进&lt;/h4&gt;与以前的技术相比，该方法在可看见对象检索方面实现了8%-56%的整体改进，并且在数据共享效率上达到了目前最先进的水平。&lt;h4&gt;翻译&lt;/h4&gt;对应识别（CoID）是多机器人协作感知中的关键能力之一，使一组机器人能够在各自的视野内一致地引用相同的目标。为了解决直接共享原始观察结果时面临的带宽限制问题，我们提出了一种新的基于带宽自适应时空CoID的协作感知方法。这种方法允许机器人逐步选择部分时空观察并与他人分享这些信息，并根据动态变化的时间通信约束进行调整。我们在连接自主驾驶模拟中的各种场景下对该方法进行了评估。实验结果显示该方法能够在动态通信带宽下实现CoID并适应其变化，同时在可看见对象检索方面实现了8%-56%的整体改进，在数据共享效率上达到了目前最先进的水平。更多详情请参见：https://gaopeng5.github.io/acoid.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correspondence identification (CoID) is an essential capability inmulti-robot collaborative perception, which enables a group of robots toconsistently refer to the same objects within their respective fields of view.In real-world applications, such as connected autonomous driving, vehicles facechallenges in directly sharing raw observations due to limited communicationbandwidth. In order to address this challenge, we propose a novel approach forbandwidth-adaptive spatiotemporal CoID in collaborative perception. Thisapproach allows robots to progressively select partial spatiotemporalobservations and share with others, while adapting to communication constraintsthat dynamically change over time. We evaluate our approach across variousscenarios in connected autonomous driving simulations. Experimental resultsvalidate that our approach enables CoID and adapts to dynamic communicationbandwidth changes. In addition, our approach achieves 8%-56% overallimprovements in terms of covisible object retrieval for CoID and data sharingefficiency, which outperforms previous techniques and achieves thestate-of-the-art performance. More information is available at:https://gaopeng5.github.io/acoid.</description>
      <author>example@mail.com (Peng Gao, Williard Joshua Jose, Hao Zhang)</author>
      <guid isPermaLink="false">2502.12098v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Multimodal-LLMs Assisted by Instance Segmentation for Intelligent Traffic Monitoring</title>
      <link>http://arxiv.org/abs/2502.11304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, submitted to 30th IEEE International Symposium on  Computers and Communications (ISCC) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个基于LLaVA多模态大语言模型的交通监控系统，用于在实时Quanser交互实验室平台上模拟城市中的各种交通场景。该系统利用部署于多个位置的摄像头收集数据，并通过LAVA模型进行分析。&lt;h4&gt;背景&lt;/h4&gt;智能城市和ITS需要一套强大的交通监测系统来优化交通流、减少拥堵并提高道路安全。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一个既能理解动态的城市条件，又能提供直观用户界面以实现有效管理的交通监控系统。&lt;h4&gt;方法&lt;/h4&gt;使用LLaVA视觉定位多模态大语言模型在实时Quanser交互实验室平台上进行交通监测任务。摄像头捕捉来自模拟场景的真实图像并将其输入到LLaVA模型中进行分析。集成到摄像机中的实例分割模型突出显示关键元素，如车辆和行人。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在识别车辆位置方面准确率达84.3%，确定转向方向的准确性为76.4%，优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;LLaVA多模态大语言模型应用于交通监控任务中显示出卓越的效果。此技术可以进一步优化并推广到实际应用中，提高城市的智能化管理水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已提供&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A robust and efficient traffic monitoring system is essential for smartcities and Intelligent Transportation Systems (ITS), using sensors and camerasto track vehicle movements, optimize traffic flow, reduce congestion, enhanceroad safety, and enable real-time adaptive traffic control. Traffic monitoringmodels must comprehensively understand dynamic urban conditions and provide anintuitive user interface for effective management. This research leverages theLLaVA visual grounding multimodal large language model (LLM) for trafficmonitoring tasks on the real-time Quanser Interactive Lab simulation platform,covering scenarios like intersections, congestion, and collisions. Camerasplaced at multiple urban locations collect real-time images from thesimulation, which are fed into the LLaVA model with queries for analysis. Aninstance segmentation model integrated into the cameras highlights key elementssuch as vehicles and pedestrians, enhancing training and throughput. The systemachieves 84.3% accuracy in recognizing vehicle locations and 76.4% indetermining steering direction, outperforming traditional models.</description>
      <author>example@mail.com (Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Aisha Syed, Matthew Andrews, Sean Kennedy)</author>
      <guid isPermaLink="false">2502.11304v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Transparent Object Pose Estimation: A Fusion of GDR-Net and Edge Detection</title>
      <link>http://arxiv.org/abs/2502.12027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at First Austrian Symposium on AI, Robotics, and Vision  (AIROV 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过在物体检测和姿态估计任务中引入边缘检测的预处理步骤，探讨了透明物体的物体姿态估计问题。&lt;h4&gt;背景&lt;/h4&gt;由于光照、背景和反射的影响，机器人视觉领域中的透明物体的姿态估计仍然是一个具有挑战性的课题。&lt;h4&gt;目的&lt;/h4&gt;利用透明物体边缘具有最高对比度的特点，通过实验研究不同边缘检测方法对6D物体姿态估计性能的影响。&lt;h4&gt;方法&lt;/h4&gt;使用GDR-Net进行6D物体姿态估计和YOLOX作为物体检测器，并应用不同的边缘检测预处理步骤（如Canny边缘检测，带或不带颜色信息，以及整体嵌套边缘HED）进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，在透明对象数据集Trans6D-32 K上使用基于物理渲染的数据集时，采用边缘检测作为预处理可以提高某些物体的性能。&lt;h4&gt;结论&lt;/h4&gt;引入边缘检测作为预处理步骤能够增强特定情况下的物体姿态估计效果。&lt;h4&gt;翻译&lt;/h4&gt;物体姿态估计是机器人视觉领域中的一项挑战性任务，特别是对于透明对象。此研究提出了一种新颖的方法，即在物体识别和姿态估计之前加入边缘检测步骤，来提高性能。实验结果表明这种方法对某些透明物体有显著的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object pose estimation of transparent objects remains a challenging task inthe field of robot vision due to the immense influence of lighting, background,and reflections. However, the edges of clear objects have the highest contrast,which leads to stable and prominent features. We propose a novel approach byincorporating edge detection in a pre-processing step for the tasks of objectdetection and object pose estimation. We conducted experiments to investigatethe effect of edge detectors on transparent objects. We examine the performanceof the state-of-the-art 6D object pose estimation pipeline GDR-Net and theobject detector YOLOX when applying different edge detectors as pre-processingsteps (i.e., Canny edge detection with and without color information, andholistically-nested edges (HED)). We evaluate the physically-based rendereddataset Trans6D-32 K of transparent objects with parameters proposed by the BOPChallenge. Our results indicate that applying edge detection as apre-processing enhances performance for certain objects.</description>
      <author>example@mail.com (Tessa Pulli, Peter Hönig, Stefan Thalhammer, Matthias Hirschmanner, Markus Vincze)</author>
      <guid isPermaLink="false">2502.12027v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Robotic CBCT Meets Robotic Ultrasound</title>
      <link>http://arxiv.org/abs/2502.12019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新的临床设置，其中通过预校准和动态共注册的机器人锥形束计算机断层扫描（CBCT）和超声波（US）系统实现了多模态成像。这种设置为无变形组织下的多模态引导程序提供了无需注册的刚性注册，并在验证实验中表现出显著改进。&lt;h4&gt;背景&lt;/h4&gt;传统的影像设备由于灵活性和移动性的限制，难以整合到标准化的工作流程中，这阻碍了全自主干预系统的进步。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新型临床配置，用于提高多模态引导操作效率、准确性和成功率。&lt;h4&gt;方法&lt;/h4&gt;通过一次性预校准两个系统，并利用SAM2算法从B模式图像中分割血管。然后将多普勒图像或分割出的血管掩码映射到CBCT上，以创建一个优化融合后的图像。&lt;h4&gt;主要发现&lt;/h4&gt;在使用含有病变和多个血管的特定设计的仿体进行验证实验后，US和CBCT之间的映射误差平均偏差为1.72±0.62毫米。用户研究显示，CBCT-US融合比传统超声引导的工作流程有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的机器人双模态成像系统在针插入指导方面相比传统的手动干预展示了明显的效果提升。&lt;h4&gt;翻译&lt;/h4&gt;多模式影像系统为现代临床实践中安全和精确的介入提供了最佳的融合图像，例如CT-US引导下的穿刺术。但是，当前影像设备的手动性质限制了它们整合到标准化工作流程中的能力，并阻碍向全自主操作系统的进步。本文介绍了一种新的临床设置，其中预先校准并动态共注册的机器人CBCT和超声波系统实现了这种可能性。该设置允许无注册刚性注册，在没有组织变形的情况下进行多模态引导程序。首先执行了两个系统之间的一次性预校准。为了通过在3D CBCT上突出关键血管来确保安全插入路径，SAM2利用B模式图像中的多普勒信号作为自主生成的提示来分割血管。基于共注册，将多普勒图像或分割后的血管掩码映射到CBCT上，创建了一个包含详细信息的最佳融合图像。为了验证该系统，我们使用了一种专门设计的仿体进行测试，该仿体具有肋骨覆盖的病变和多个模拟流动状态下的血管。US与CBCT之间的映射误差导致平均偏差为1.72±0.62毫米。用户研究证明了CBCT-US融合用于针插入指导的有效性，并显示出在时间效率、准确性和成功率方面的显著改进，相较于传统的超声引导工作流程提高了大约50%的性能表现。我们提出了首个专为临床应用设计的机器人双模态成像系统，其结果表明与传统手动干预相比有明显的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The multi-modality imaging system offers optimal fused images for safe andprecise interventions in modern clinical practices, such as computed tomography- ultrasound (CT-US) guidance for needle insertion. However, the limiteddexterity and mobility of current imaging devices hinder their integration intostandardized workflows and the advancement toward fully autonomous interventionsystems. In this paper, we present a novel clinical setup where robotic conebeam computed tomography (CBCT) and robotic US are pre-calibrated anddynamically co-registered, enabling new clinical applications. This setupallows registration-free rigid registration, facilitating multi-modal guidedprocedures in the absence of tissue deformation. First, a one-timepre-calibration is performed between the systems. To ensure a safe insertionpath by highlighting critical vasculature on the 3D CBCT, SAM2 segments vesselsfrom B-mode images, using the Doppler signal as an autonomously generatedprompt. Based on the registration, the Doppler image or segmented vessel masksare then mapped onto the CBCT, creating an optimally fused image withcomprehensive detail. To validate the system, we used a specially designedphantom, featuring lesions covered by ribs and multiple vessels with simulatedmoving flow. The mapping error between US and CBCT resulted in an averagedeviation of 1.72+-0.62 mm. A user study demonstrated the effectiveness ofCBCT-US fusion for needle insertion guidance, showing significant improvementsin time efficiency, accuracy, and success rate. Needle intervention performanceimproved by approximately 50% compared to the conventional US-guided workflow.We present the first robotic dual-modality imaging system designed to guideclinical applications. The results show significant performance improvementscompared to traditional manual interventions.</description>
      <author>example@mail.com (Feng Li, Yuan Bi, Dianye Huang, Zhongliang Jiang, Nassir Navab)</author>
      <guid isPermaLink="false">2502.12019v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM</title>
      <link>http://arxiv.org/abs/2502.11955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;pySLAM是一个开源的Python框架，用于视觉同时定位与地图构建（Visual SLAM），支持单目、立体和RGB-D相机。&lt;h4&gt;背景&lt;/h4&gt;当前的SLAM研究需要一个灵活且适应性强的平台来集成经典和现代局部特征以及深度预测模型等。&lt;h4&gt;目的&lt;/h4&gt;提供一个适用于初学者和资深研究人员的框架，促进视觉SLAM领域的社区合作与开发。&lt;h4&gt;方法&lt;/h4&gt;pySLAM框架包括不同的环路闭合技术、体素重建流水线，并支持多种视觉里程计和SLAM应用工具。&lt;h4&gt;主要发现&lt;/h4&gt;该框架为各种SLAM任务提供了灵活性，能够整合经典和现代局部特征以及深度预测模型。&lt;h4&gt;结论&lt;/h4&gt;通过鼓励社区贡献，pySLAM旨在成为Visual SLAM领域的标准平台之一，促进领域内的创新和发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：pySLAM是一个开源的Python框架，用于视觉同时定位与地图构建（Visual SLAM），支持单目、立体和RGB-D相机。它提供了集成经典和现代局部特征的灵活接口，使其能够适应各种SLAM任务。该框架包括不同的环路闭合方法，体素重建流水线，并支持深度预测模型。此外，它还提供了一系列用于视觉里程计和SLAM应用的工具。pySLAM旨在为初学者和经验丰富的研究人员设计，鼓励社区贡献，在Visual SLAM领域推动协作开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; pySLAM is an open-source Python framework for Visual SLAM, supportingmonocular, stereo, and RGB-D cameras. It provides a flexible interface forintegrating both classical and modern local features, making it adaptable tovarious SLAM tasks. The framework includes different loop closure methods, avolumetric reconstruction pipeline, and support for depth prediction models.Additionally, it offers a suite of tools for visual odometry and SLAMapplications. Designed for both beginners and experienced researchers, pySLAMencourages community contributions, fostering collaborative development in thefield of Visual SLAM.</description>
      <author>example@mail.com (Luigi Freda)</author>
      <guid isPermaLink="false">2502.11955v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>The Dynamic Model of the UR10 Robot and its ROS2 Integration</title>
      <link>http://arxiv.org/abs/2502.11940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures, 6 tables, IEEE Transactions on Industrial  Informatics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于UR10工业机器人的完整动态模型，并采用三级识别方法来估计操作臂的动态系数。&lt;h4&gt;背景&lt;/h4&gt;现有机器人动力学模型可能无法准确预测电流或调整电机增益，特别是在负载变化的情况下。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的动态模型和相应的软件工具，以便更好地用于控制和规划。&lt;h4&gt;方法&lt;/h4&gt;{'线性参数估计': '使用标准的线性回归算法计算', '非线性摩擦参数估计': '基于S形函数模型进行估算', '电机驱动增益设计': '将估计到的关节电流映射为扭矩'}&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，该模型在预测电流准确性上比现有最优模型提高了最多4.43倍，并且更精确地调整了电机增益。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法可以有效地提高机器人的动力学性能和控制精度。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TII.2025.3534415&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the full dynamic model of the UR10 industrial robot. Atriple-stage identification approach is adopted to estimate the manipulator'sdynamic coefficients. First, linear parameters are computed using a standardlinear regression algorithm. Subsequently, nonlinear friction parameters areestimated according to a sigmoidal model. Lastly, motor drive gains are devisedto map estimated joint currents to torques. The overall identified model can beused for both control and planning purposes, as the accompanied ROS2 softwarecan be easily reconfigured to account for a generic payload. The estimatedrobot model is experimentally validated against a set of exciting trajectoriesand compared to the state-of-the-art model for the same manipulator, achievinghigher current prediction accuracy (up to a factor of 4.43) and more precisemotor gains. The related software is available athttps://codeocean.com/capsule/8515919/tree/v2.</description>
      <author>example@mail.com (Vincenzo Petrone, Enrico Ferrentino, Pasquale Chiacchio)</author>
      <guid isPermaLink="false">2502.11940v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Continual Learning Should Move Beyond Incremental Classification</title>
      <link>http://arxiv.org/abs/2502.11927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了连续学习（CL）领域在面对超出标准分类任务时的局限性，通过具体案例分析指出当前CL方法在处理多目标分类、机器人技术中的受限输出空间、连续任务域中的学习以及高级概念记忆等问题上的不足。&lt;h4&gt;背景&lt;/h4&gt;连续学习是机器学习的一个子领域，专注于动态环境中知识积累。然而，目前的研究主要集中在增量分类任务上，即模型能够学习新的类别同时保留之前学过的知识。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过分析具体实例来拓宽CL研究的范围，并提出克服当前挑战的具体建议，以加强其理论基础和实际应用性。&lt;h4&gt;方法&lt;/h4&gt;通过对多目标分类、机器人技术中的受限输出空间问题、连续任务域的学习以及高级概念记忆等方面的详细案例分析，识别并讨论了三个根本性的挑战：学习问题的连续性本质（C1）、用于测量相似性的适当空间和度量的选择（C2），以及超出分类之外的学习目标的作用（C3）。&lt;h4&gt;主要发现&lt;/h4&gt;目前CL方法在解决上述提及的具体应用场景时往往表现不佳，表明现有理论和技术框架存在局限。识别了三个核心挑战并提出了相应的建议，如通过分布过程的形式化时间动态、为连续任务空间开发原理性的方法以及引入密度估计和生成目标等。&lt;h4&gt;结论&lt;/h4&gt;本文呼吁扩大CL研究的范围，强调其在解决现实世界问题中的重要性，并指出上述提出的策略可以帮助推进领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到连续学习（CL）是机器学习的一个子领域，处理的是动态环境下的知识积累。至今为止，CL的研究主要集中在增量分类任务上，在这类任务中模型能够学会对新的类别进行分类同时保留已经学到的知识。本文认为这种单一的焦点限制了理论的发展和实用性的应用范围。通过分析具体例子——包括多目标分类、受限输出空间中的机器人技术学习、连续任务域中的学习以及高级概念记忆，展示如何在超出标准分类的情况下，当前的方法经常失效。作者识别出了三个基本挑战：（C1）学习问题的连续性本质；（C2）选择用于测量相似性的适当的空间和度量；（C3）超越分类的学习目标的作用。针对每个挑战，提供了一些具体的建议以推动领域向前发展，包括通过分布过程的形式化时间动态、为连续任务空间开发原理性的方法以及引入密度估计和生成目标。通过这种方式，本文旨在扩大CL研究的范围并加强其理论基础，使其更适用于解决实际问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) is the sub-field of machine learning concerned withaccumulating knowledge in dynamic environments. So far, CL research has mainlyfocused on incremental classification tasks, where models learn to classify newcategories while retaining knowledge of previously learned ones. Here, we arguethat maintaining such a focus limits both theoretical development and practicalapplicability of CL methods. Through a detailed analysis of concrete examples -including multi-target classification, robotics with constrained output spaces,learning in continuous task domains, and higher-level concept memorization - wedemonstrate how current CL approaches often fail when applied beyond standardclassification. We identify three fundamental challenges: (C1) the nature ofcontinuity in learning problems, (C2) the choice of appropriate spaces andmetrics for measuring similarity, and (C3) the role of learning objectivesbeyond classification. For each challenge, we provide specific recommendationsto help move the field forward, including formalizing temporal dynamics throughdistribution processes, developing principled approaches for continuous taskspaces, and incorporating density estimation and generative objectives. In sodoing, this position paper aims to broaden the scope of CL research whilestrengthening its theoretical foundations, making it more applicable toreal-world problems.</description>
      <author>example@mail.com (Rupert Mitchell, Antonio Alliegro, Raffaello Camoriano, Dustin Carrión-Ojeda, Antonio Carta, Georgia Chalvatzaki, Nikhil Churamani, Carlo D'Eramo, Samin Hamidi, Robin Hesse, Fabian Hinder, Roshni Ramanna Kamath, Vincenzo Lomonaco, Subarnaduti Paul, Francesca Pistilli, Tinne Tuytelaars, Gido M van de Ven, Kristian Kersting, Simone Schaub-Meyer, Martin Mundt)</author>
      <guid isPermaLink="false">2502.11927v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>VLP: Vision-Language Preference Learning for Embodied Manipulation</title>
      <link>http://arxiv.org/abs/2502.11918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一个新颖的Vision-Language Preference (VLP)框架，旨在解决强化学习中的奖励工程问题。该框架通过构建无标注的视觉-语言偏好数据集来训练偏好模型。&lt;h4&gt;背景&lt;/h4&gt;强化学习中的奖励设计是一项关键挑战，传统的基于偏好的RL方法需要大量的人类反馈标签，这既耗时又昂贵。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需人工注释就可以提供有效反馈的方法，并提高在下游任务中的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;定义了三种语言条件下的偏好类型并构建了一个视觉-语言的无标注数据集。提出了VLP框架，该框架能够从文本描述中提取出相关的特征，为仿真环境中的机器人操作任务生成偏好标签。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在模拟的物理环境中进行的各种机器人抓取和操纵任务上，基于该方法训练出来的策略优于基线模型，并且可以泛化到未见过的任务以及语言指令。&lt;h4&gt;结论&lt;/h4&gt;VLP框架有效地解决了强化学习中奖励设计的问题，为无需人工干预的情况下提供有效的反馈提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;奖励工程是强化学习(RL)中的一个关键挑战。基于偏好的RL通过从人类反馈中学习来有效解决这一问题。然而，收集人类偏好标签既耗时又昂贵。本文提出了一种新颖的Vision-Language Preference (VLP)框架，该框架用于为机器人实体操作任务提供偏好反馈。为了实现这一点，我们定义了三种语言条件下的偏好类型，并构建了一个包含多种隐式偏好顺序而无需人工注释的视觉-语言偏好数据集。偏好模型学习提取与语言相关的特征，然后作为偏好标注器在各种下游任务中使用。策略可以通过奖励学习或直接策略优化根据这些标注偏好数据进行学习。广泛的实验证明了该方法提供了准确的偏好，并且能泛化到未见过的任务和语言指令上，大大优于基线模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward engineering is one of the key challenges in Reinforcement Learning(RL). Preference-based RL effectively addresses this issue by learning fromhuman feedback. However, it is both time-consuming and expensive to collecthuman preference labels. In this paper, we propose a novel\textbf{V}ision-\textbf{L}anguage \textbf{P}reference learning framework, named\textbf{VLP}, which learns a vision-language preference model to providepreference feedback for embodied manipulation tasks. To achieve this, we definethree types of language-conditioned preferences and construct a vision-languagepreference dataset, which contains versatile implicit preference orders withouthuman annotations. The preference model learns to extract language-relatedfeatures, and then serves as a preference annotator in various downstreamtasks. The policy can be learned according to the annotated preferences viareward learning or direct policy optimization. Extensive empirical results onsimulated embodied manipulation tasks demonstrate that our method providesaccurate preferences and generalizes to unseen tasks and unseen languageinstructions, outperforming the baselines by a large margin.</description>
      <author>example@mail.com (Runze Liu, Chenjia Bai, Jiafei Lyu, Shengjie Sun, Yali Du, Xiu Li)</author>
      <guid isPermaLink="false">2502.11918v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>1 A formal implementation of Behavior Trees to act in robotics</title>
      <link>http://arxiv.org/abs/2502.11904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了通过将行为树（BT）转换为形式语言来定义其正式语义的方法，以此进行程序验证和运行时验证。&lt;h4&gt;背景&lt;/h4&gt;行为树作为自主机器人系统中的行动组件越来越受欢迎。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以便于对使用行为树编写的程序进行正式验证，并支持运行时的动态验证。&lt;h4&gt;方法&lt;/h4&gt;采用形式框架Fiacre及其语言、TTS模型，利用Tina进行模型检查以及Hippo进行运行时验证。此外，还展示了将BT自动转换为Fiacre的过程，讨论了离线和在线可以验证的形式化属性（LTL和CTL）。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一个正式的框架来支持行为树程序的正确性验证，并且不需行为树程序员掌握形式语言；同时保留了模块化、灵活性及可重用性的特点。此外，展示了在机器人应用中如何利用Fiacre提供的其他特性（状态变量、时间等）。&lt;h4&gt;结论&lt;/h4&gt;通过这种方式可以使行为树的开发和使用更加高效和可靠，并为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;将行为树转换为形式语言以进行正式验证的方法，使程序验证更为便捷且不需要程序员掌握复杂的正式语言。这种方法保留了行为树的优点，如模块化、灵活性及重用性，同时也展示了在机器人应用中的实际效果和新特性利用的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavior Trees (BT) are becoming quite popular as an Acting component ofautonomous robotic systems. We propose to define a formal semantics to BT bytranslating them to a formal language which enables us to perform verificationof programs written with BT, as well as runtime verification while these BTexecute. This allows us to formally verify BT correctness without requiring BTprogrammers to master formal language and without compromising BT most valuablefeatures: modularity, flexibility and reusability. We present the formalframework we use: Fiacre, its langage and the produced TTS model; Tina, itsmodel checking tools and Hippo, its runtime verification engine. We then showhow the translation from BT to Fiacre is automatically done, the type of formalLTL and CTL properties we can check offline and how to execute the formal modelonline in place of a regular BT engine. We illustrate our approach on tworobotics applications, and show how BT could benefit of other featuresavailable in the Fiacre formal framework (state variables, time, etc).</description>
      <author>example@mail.com (Felix Ingrand)</author>
      <guid isPermaLink="false">2502.11904v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Stonefish: Supporting Machine Learning Research in Marine Robotics</title>
      <link>http://arxiv.org/abs/2502.11887v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as full paper at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Stonefish仿真器的最新改进，这是一个专为海洋机器人开发和测试设计的开源平台。这些更新包括新增传感器、支持缆绳操作、改进推进器建模、更灵活的水动力学以及增强声纳精度。&lt;h4&gt;背景&lt;/h4&gt;模拟技术在海洋机器人领域极其重要，能够提供一个成本效益高且可控的环境来应对复杂的海底作业条件。&lt;h4&gt;目的&lt;/h4&gt;鉴于真实世界测试中的高昂费用和后勤挑战，开发出可以捕捉海底环境操作条件的仿真器对于研发遥控和自主水下车辆算法至关重要。&lt;h4&gt;方法&lt;/h4&gt;文中概述了Stonefish平台的关键更新，涵盖了额外传感器（事件相机、热像仪、光学流相机）、可见光通信支持、更灵活的水动力学建模以及推进器模拟改进等。&lt;h4&gt;主要发现&lt;/h4&gt;这些开发成果和自动注释工具极大地增强了Stonefish在海洋机器人研究中的作用，特别是在机器学习领域，训练数据收集困难的情况下更为重要。&lt;h4&gt;结论&lt;/h4&gt;通过改善仿真环境，能够更好地支持海洋机器人系统的算法研发和性能测试，提高其在实际操作中的效率与可靠性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文描述了模拟技术如何为开发用于遥控及自主水下车辆的算法提供了成本效益高的测试平台，并重点介绍了Stonefish仿真器的新特性及其对海洋机器人研究尤其是机器学习领域的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulations are highly valuable in marine robotics, offering a cost-effectiveand controlled environment for testing in the challenging conditions ofunderwater and surface operations. Given the high costs and logisticaldifficulties of real-world trials, simulators capable of capturing theoperational conditions of subsea environments have become key in developing andrefining algorithms for remotely-operated and autonomous underwater vehicles.This paper highlights recent enhancements to the Stonefish simulator, anadvanced open-source platform supporting development and testing of marinerobotics solutions. Key updates include a suite of additional sensors, such asan event-based camera, a thermal camera, and an optical flow camera, as wellas, visual light communication, support for tethered operations, improvedthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.These developments and an automated annotation tool significantly bolsterStonefish's role in marine robotics research, especially in the field ofmachine learning, where training data with a known ground truth is hard orimpossible to collect.</description>
      <author>example@mail.com (Michele Grimaldi, Patryk Cieslak, Eduardo Ochoa, Vibhav Bharti, Hayat Rajani, Ignacio Carlucho, Maria Koskinopoulou, Yvan R. Petillot, Nuno Gracias)</author>
      <guid isPermaLink="false">2502.11887v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Does Knowledge About Perceptual Uncertainty Help an Agent in Automated Driving?</title>
      <link>http://arxiv.org/abs/2502.11864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了代理在感知不确定性的环境中的行为表现及其变化，特别是当代理接收到有关当前不确定性信息时的行为调整。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶等现实场景中存在感知不确定性问题，而强化学习算法通常不考虑这些环境的不确定性。目前，关于如何利用感知领域的不确定性来指导目标导向行动的研究很少。&lt;h4&gt;目的&lt;/h4&gt;探究不确定感知对代理行为的影响以及当有关这种不确定性的信息可用时其行为的变化情况。&lt;h4&gt;方法&lt;/h4&gt;通过设定一个代理任务，在该任务中，代理被奖励以最快的速度完成路线驾驶而不与其他道路使用者发生碰撞。实验引入了观察空间中的不确定性，通过扰动给定代理的感知并通知它来执行受控实验。&lt;h4&gt;主要发现&lt;/h4&gt;不准确的观测空间（由感知扰动建模）会导致防御性驾驶行为；当直接将当前不确定性的信息添加到观察空间时，代理会适应特定情况，并总体上更快地完成其任务同时考虑风险。&lt;h4&gt;结论&lt;/h4&gt;利用不确定性信息可以改善自动驾驶等场景中代理的行为表现和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Agents in real-world scenarios like automated driving deal with uncertaintyin their environment, in particular due to perceptual uncertainty. Although,reinforcement learning is dedicated to autonomous decision-making underuncertainty these algorithms are typically not informed about the uncertaintycurrently contained in their environment. On the other hand, uncertaintyestimation for perception itself is typically directly evaluated in theperception domain, e.g., in terms of false positive detection rates orcalibration errors based on camera images. Its use for deciding ongoal-oriented actions remains largely unstudied. In this paper, we investigatehow an agent's behavior is influenced by an uncertain perception and how thisbehavior changes if information about this uncertainty is available. Therefore,we consider a proxy task, where the agent is rewarded for driving a route asfast as possible without colliding with other road users. For controlledexperiments, we introduce uncertainty in the observation space by perturbingthe perception of the given agent while informing the latter. Our experimentsshow that an unreliable observation space modeled by a perturbed perceptionleads to a defensive driving behavior of the agent. Furthermore, when addingthe information about the current uncertainty directly to the observationspace, the agent adapts to the specific situation and in general accomplishesits task faster while, at the same time, accounting for risks.</description>
      <author>example@mail.com (Natalie Grabowsky, Annika Mütze, Joshua Wendland, Nils Jansen, Matthias Rottmann)</author>
      <guid isPermaLink="false">2502.11864v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Bi-invariant Geodesic Regression with Data from the Osteoarthritis Initiative</title>
      <link>http://arxiv.org/abs/2502.11826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at the Information Processing in Medical Imaging (IPMI) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了李群上的测地线回归方法，并提出了一种非度量估计器，该估计器在计算时保留数据的对称性。&lt;h4&gt;背景&lt;/h4&gt;许多现象自然地通过连续变换来表征，例如医学中的形状变化或机器人技术中的连杆系统。为了描述这些数据集的变化性，需要执行李群上的统计方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够尊重李群上对称性的非度量估计器，使其不敏感于参考坐标系统的改变等干扰因素。&lt;h4&gt;方法&lt;/h4&gt;基于黎曼流形上的线性回归发展了一种测地线回归方法。提出了一个利用仿射连接的设置来开发非度量估计器，并设计了一个高效的固定点算法来进行计算。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够捕捉到尊重李群中左、右平移对称性的测地线关系，且可以通过自动微分计算得出所需的基本导数表达式。实验结果证明了其有效性和适用性。&lt;h4&gt;结论&lt;/h4&gt;该非度量估计器在实际应用中有很大潜力，尤其是在医学图像分析和机器人技术等领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经全部被翻译成中文，并按照要求进行了分点总结&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many phenomena are naturally characterized by measuring continuoustransformations such as shape changes in medicine or articulated systems inrobotics. Modeling the variability in such datasets requires performingstatistics on Lie groups, that is, manifolds carrying an additional groupstructure. As the Lie group captures the symmetries in the data, it isessential from a theoretical and practical perspective to ask for statisticalmethods that respect these symmetries; this way they are insensitive toconfounding effects, e.g., due to the choice of reference coordinate systems.In this work, we investigate geodesic regression -- a generalization of linearregression originally derived for Riemannian manifolds. While Lie groups can beendowed with Riemannian metrics, these are generally incompatible with thegroup structure. We develop a non-metric estimator using an affine connectionsetting. It captures geodesic relationships respecting the symmetries given byleft and right translations. For its computation, we propose an efficient fixedpoint algorithm requiring simple differential expressions that can becalculated through automatic differentiation. We perform experiments on asynthetic example and evaluate our method on an open-access, clinical datasetstudying knee joint configurations under the progression of osteoarthritis.</description>
      <author>example@mail.com (Johannes Schade, Christoph von Tycowicz, Martin Hanik)</author>
      <guid isPermaLink="false">2502.11826v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Residual Learning towards High-fidelity Vehicle Dynamics Modeling with Transformer</title>
      <link>http://arxiv.org/abs/2502.11800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度神经网络的车辆动力学校正系统，该系统通过修正物理模型的状态残差而非直接估计状态来提高车辆动态预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;长期以来，研究人员致力于准确建模车辆的动力学特性。传统的基于物理学的方法使用数学公式进行建模，但因为简化处理而无法充分描述复杂车辆系统的动力学行为。近年来，基于深度学习的方法通过直接回归车辆动力学特征试图解决这一问题，但在性能和泛化能力方面仍有改进空间。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在提出一种新的方法来提升车辆动态预测的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;作者开发了一种新型的Transformer基的动力残差校正网络DyTR。该网络将状态残差隐式表示为高维查询，并通过与动力学状态特征交互迭代更新估计残差。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的系统在模拟环境中的表现优于传统物理模型。此外，作者的DyTR模型在动态状态残差校正任务中表现出最佳性能，在两个数据集上分别减少了简单3自由度车辆模型的状态预测误差92.3%和59.9%。&lt;h4&gt;结论&lt;/h4&gt;提出的车辆动力学校正系统通过使用深度神经网络修正物理模型的残差，大大降低了学习难度，并提高了估计准确性。这种创新方法为未来的自动驾驶研究提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：汽车动力学模型是自主驾驶系统的组成部分之一，它描述了车辆状态随时间的变化情况。长期以来，研究人员在准确建模车辆动态方面做出了巨大努力。传统的基于物理学的方法使用数学公式进行车辆动力学建模，但由于简化处理而无法充分描述复杂车辆系统。近年来，基于深度学习的方法通过直接回归车辆动力学解决了这一限制。然而，性能和泛化能力仍然需要进一步改进。在这封信中，我们提出了一种新的方法来解决这些问题，即利用深度神经网络修正物理模型的状态残差而非直接估计状态。这种方法大大降低了网络的学习难度，并提高了对车辆动态的预测准确性。此外，我们开发了一种新型Transformer基的动力学残差校正网络DyTR。该网络将高维查询隐式表示为状态残差，并通过与动力学状态特征交互迭代更新估计残差。在模拟实验中表明，所提出的系统表现优于传统物理模型，而我们的DyTR模型在动态状态残差校正任务中的性能最佳，在两个数据集上分别减少了简单3自由度车辆模型的状态预测误差92.3%和59.9%&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vehicle dynamics model serves as a vital component of autonomous drivingsystems, as it describes the temporal changes in vehicle state. In a longperiod, researchers have made significant endeavors to accurately model vehicledynamics. Traditional physics-based methods employ mathematical formulae tomodel vehicle dynamics, but they are unable to adequately describe complexvehicle systems due to the simplifications they entail. Recent advancements indeep learning-based methods have addressed this limitation by directlyregressing vehicle dynamics. However, the performance and generalizationcapabilities still require further enhancement. In this letter, we addressthese problems by proposing a vehicle dynamics correction system that leveragesdeep neural networks to correct the state residuals of a physical model insteadof directly estimating the states. This system greatly reduces the difficultyof network learning and thus improves the estimation accuracy of vehicledynamics. Furthermore, we have developed a novel Transformer-based dynamicsresidual correction network, DyTR. This network implicitly represents stateresiduals as high-dimensional queries, and iteratively updates the estimatedresiduals by interacting with dynamics state features. The experiments insimulations demonstrate the proposed system works much better than physicsmodel, and our proposed DyTR model achieves the best performances on dynamicsstate residual correction task, reducing the state prediction errors of asimple 3 DoF vehicle model by an average of 92.3% and 59.9% in two dataset,respectively.</description>
      <author>example@mail.com (Jinyu Miao, Rujun Yan, Bowei Zhang, Tuopu Wen, Kun Jiang, Mengmeng Yang, Jin Huang, Zhihua Zhong, Diange Yang)</author>
      <guid isPermaLink="false">2502.11800v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Deep Neural Networks for Accurate Depth Estimation with Latent Space Features</title>
      <link>http://arxiv.org/abs/2502.11777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了一种新的单目深度估计框架，通过利用深层卷积神经网络中的潜在空间特征来提升单目深度图的精度。&lt;h4&gt;背景&lt;/h4&gt;在室内环境中，准确的3D场景重建对导航和物体处理等任务至关重要。然而，传统的双目摄像头或激光雷达方法成本高昂，相比之下，基于单个RGB摄像头的单目深度估计更为经济且具有发展潜力。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有单目深度估计方法难以精确定义深度边界的问题，本研究旨在开发一种新的框架来改进这一技术。&lt;h4&gt;方法&lt;/h4&gt;该框架采用了一种双编码器-解码器结构，能够实现颜色到深度以及深度之间的转换。同时引入了一种结合潜在损失和梯度损失的新损失函数以进一步提高深度边界和局部特征的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在NYU Depth V2数据集上该方法达到了新的基准水平，并在复杂的室内场景中表现出色，有效地减少了深度模糊性。&lt;h4&gt;结论&lt;/h4&gt;这种方法为人类与机器人交互以及3D场景重建的应用提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/biomimetics9120747&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation plays a pivotal role in advancing human-robot interactions,especially in indoor environments where accurate 3D scene reconstruction isessential for tasks like navigation and object handling. Monocular depthestimation, which relies on a single RGB camera, offers a more affordablesolution compared to traditional methods that use stereo cameras or LiDAR.However, despite recent progress, many monocular approaches struggle withaccurately defining depth boundaries, leading to less precise reconstructions.In response to these challenges, this study introduces a novel depth estimationframework that leverages latent space features within a deep convolutionalneural network to enhance the precision of monocular depth maps. The proposedmodel features dual encoder-decoder architecture, enabling both color-to-depthand depth-to-depth transformations. This structure allows for refined depthestimation through latent space encoding. To further improve the accuracy ofdepth boundaries and local features, a new loss function is introduced. Thisfunction combines latent loss with gradient loss, helping the model maintainthe integrity of depth boundaries. The framework is thoroughly tested using theNYU Depth V2 dataset, where it sets a new benchmark, particularly excelling incomplex indoor scenarios. The results clearly show that this approacheffectively reduces depth ambiguities and blurring, making it a promisingsolution for applications in human-robot interaction and 3D scenereconstruction.</description>
      <author>example@mail.com (Siddiqui Muhammad Yasir, Hyunsik Ahn)</author>
      <guid isPermaLink="false">2502.11777v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Early Detection of Human Handover Intentions in Human-Robot Collaboration: Comparing EEG, Gaze, and Hand Motion</title>
      <link>http://arxiv.org/abs/2502.11752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In submission at Robotics and Autonomous Systems, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文研究了人类在物体交接过程中产生的非运动生理信号是否可以用于识别机器人协作中的人类意图。&lt;h4&gt;背景&lt;/h4&gt;现有的HRC任务主要是通过视觉检测运动轨迹来判断人机交互的意图，但这种方法容易产生延迟或误报，尤其是在动作重叠的情况下。&lt;h4&gt;目的&lt;/h4&gt;研究在物体交接过程中人类非运动生理信号是否可以用于识别手部动作是为物体交接还是其他行动。&lt;h4&gt;方法&lt;/h4&gt;进行了多模式分析，比较了三种数据模态：脑电波（EEG）、视线和手臂运动信号，以区分HRC场景中意图进行物体交接的人类动作与其他动作。&lt;h4&gt;主要发现&lt;/h4&gt;所有三个模态都可以检测到交接的意图，但视线信号在分类意图为交接或非交接动作时是最准确且最早的。&lt;h4&gt;结论&lt;/h4&gt;这是首次系统地开发和测试多个模态下的意向探测器的研究，在相同的实验环境下进行了验证。结果表明，基于多模式生理信号可以有效预测人类进行物体交接的动作意图。&lt;h4&gt;翻译&lt;/h4&gt;人机协作（HRC）依赖于对人类意图的准确及时识别以确保无缝交互。在常见的HRC任务中，从人类到机器人的物体传递已经广泛研究用于规划机器人接物时的行为。然而，在动作重叠的情况下，仅通过视觉检测运动轨迹的方法会导致延迟或误报。本文探讨了非运动生理信号是否可以反映人在交接物体时的意图，并进行了多模式分析比较三种数据模态：脑电波（EEG）、视线和手臂运动信号。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-robot collaboration (HRC) relies on accurate and timely recognition ofhuman intentions to ensure seamless interactions. Among common HRC tasks,human-to-robot object handovers have been studied extensively for planning therobot's actions during object reception, assuming the human intention forobject handover. However, distinguishing handover intentions from other actionshas received limited attention. Most research on handovers has focused onvisually detecting motion trajectories, which often results in delays or falsedetections when trajectories overlap. This paper investigates whether humanintentions for object handovers are reflected in non-movement-basedphysiological signals. We conduct a multimodal analysis comparing three datamodalities: electroencephalogram (EEG), gaze, and hand-motion signals. Ourstudy aims to distinguish between handover-intended human motions andnon-handover motions in an HRC setting, evaluating each modality's performancein predicting and classifying these actions before and after human movementinitiation. We develop and evaluate human intention detectors based on thesemodalities, comparing their accuracy and timing in identifying handoverintentions. To the best of our knowledge, this is the first study tosystematically develop and test intention detectors across multiple modalitieswithin the same experimental context of human-robot handovers. Our analysisreveals that handover intention can be detected from all three modalities.Nevertheless, gaze signals are the earliest as well as the most accurate toclassify the motion as intended for handover or non-handover.</description>
      <author>example@mail.com (Parag Khanna, Nona Rajabi, Sumeyra U. Demir Kanik, Danica Kragic, Mårten Björkman, Christian Smith)</author>
      <guid isPermaLink="false">2502.11752v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>FUNCTO: Function-Centric One-Shot Imitation Learning for Tool Manipulation</title>
      <link>http://arxiv.org/abs/2502.11744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为FUNCTO的新方法，该方法能够在仅通过单个人类演示视频的情况下，使机器人学会并推广使用不同几何形状但功能相同的工具的技能。&lt;h4&gt;背景&lt;/h4&gt;人类能够轻松地将观察到的一项动作技巧应用到支持相同功能的不同物体上。然而现有的一次性模仿学习（OSIL）方法在这种情况下效果不佳，因为它们难以处理具有相似功能但在外形上有很大差异的对象之间的对应关系问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在保持工具功能的同时，有效应对不同几何形状的同功能对象之间变化的新一代OSIL方法。&lt;h4&gt;方法&lt;/h4&gt;FUNCTO通过使用3D功能性关键点表示来建立功能中心的对应关系。该方法被细分为三个阶段：功能性关键点提取、功能中心的对应关系确定和基于功能性关键点的动作规划。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有的模块化OSIL方法和端到端行为克隆方法相比，FUNCTO在处理具有显著几何变化的不同工具时表现更优。&lt;h4&gt;结论&lt;/h4&gt;通过使用3D功能关键点表示来建立对应关系，FUNCTO成功地解决了现有OSIL方法难以应对的问题，并为机器人学习如何灵活应用不同但相似功能的工具提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;从单个人类演示视频中学习工具使用提供了一种直观且高效的机器人教学方式。尽管人类可以轻松将展示过的操作技能推广到支持相同功能的不同工具上，现有的一次性模仿学习方法却难以做到这一点。为了解决这个问题，提出了FUNCTO这一OSIL方法，该方法通过3D功能性关键点表示来建立对应关系，使得机器人能够从单个人类演示视频中推广出对具有相同功能但几何形状不同的新工具的操作技能。此方法分解为三个阶段：功能性关键点提取、基于功能的对应关系确定以及基于功能性关键点的动作规划。在多种工具操作任务上的真实机器人实验结果表明，与现有的模块化OSIL方法和端到端行为克隆方法相比，FUNCTO在处理具有显著几何变化的不同工具时更具优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning tool use from a single human demonstration video offers a highlyintuitive and efficient approach to robot teaching. While humans caneffortlessly generalize a demonstrated tool manipulation skill to diverse toolsthat support the same function (e.g., pouring with a mug versus a teapot),current one-shot imitation learning (OSIL) methods struggle to achieve this. Akey challenge lies in establishing functional correspondences betweendemonstration and test tools, considering significant geometric variationsamong tools with the same function (i.e., intra-function variations). Toaddress this challenge, we propose FUNCTO (Function-Centric OSIL for ToolManipulation), an OSIL method that establishes function-centric correspondenceswith a 3D functional keypoint representation, enabling robots to generalizetool manipulation skills from a single human demonstration video to novel toolswith the same function despite significant intra-function variations. With thisformulation, we factorize FUNCTO into three stages: (1) functional keypointextraction, (2) function-centric correspondence establishment, and (3)functional keypoint-based action planning. We evaluate FUNCTO against exitingmodular OSIL methods and end-to-end behavioral cloning methods throughreal-robot experiments on diverse tool manipulation tasks. The resultsdemonstrate the superiority of FUNCTO when generalizing to novel tools withintra-function geometric variations. More details are available athttps://sites.google.com/view/functo.</description>
      <author>example@mail.com (Chao Tang, Anxing Xiao, Yuhong Deng, Tianrun Hu, Wenlong Dong, Hanbo Zhang, David Hsu, Hong Zhang)</author>
      <guid isPermaLink="false">2502.11744v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration</title>
      <link>http://arxiv.org/abs/2502.11720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CHI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究探讨了间接言语行为（ISAs）在人机协作中的作用，表明具备理解ISAs的机器人能够显著提升人类对机器人的拟人化感知、团队表现和信任。然而，这种效果取决于任务和环境的具体情况。&lt;h4&gt;背景&lt;/h4&gt;间接言语行为是人类交流中的一种自然实用特性，允许通过含蓄的方式进行请求，同时保持微妙性和灵活性。尽管语音识别的进步使得机器人能够理解直接明确的命令，但大型语言模型的兴起为机器人理解ISAs提供了可能。&lt;h4&gt;目的&lt;/h4&gt;探讨在人机协作（HRC）中使用间接言语行为的效果，并评估其对合作体验和任务表现的影响。&lt;h4&gt;方法&lt;/h4&gt;通过一项巫师之奥兹实验（N=36），参与者与一个机器人共同完成物理任务，以此研究ISAs的效果。&lt;h4&gt;主要发现&lt;/h4&gt;能够理解ISAs的机器人显著提高了人类感知到的机器人的拟人化、团队绩效和信任。然而，这种效果取决于具体任务和环境的情境特征。&lt;h4&gt;结论&lt;/h4&gt;间接请求的有效性取决于具体的任务与环境背景，在设计人机交互系统时应谨慎使用直接和间接请求。&lt;h4&gt;翻译&lt;/h4&gt;间接言语行为是人类交流中的自然实用特性，允许通过含蓄的方式进行请求。尽管语音识别技术的进步使得机器人能够理解明确的命令，但大型语言模型的发展开启了机器人能理解ISAs的新可能。目前关于HRC中ISAs影响的研究尚不充分。研究者们进行了巫师之奥兹实验（N=36），结果显示具备理解ISAs能力的机器人显著提升了人类对机器人的拟人化感知、团队表现和信任，但这种效果受具体任务和环境的影响，因此需要谨慎使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713780&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indirect speech acts (ISAs) are a natural pragmatic feature of humancommunication, allowing requests to be conveyed implicitly while maintainingsubtlety and flexibility. Although advancements in speech recognition haveenabled natural language interactions with robots through direct, explicitcommands--providing clarity in communication--the rise of large language modelspresents the potential for robots to interpret ISAs. However, empiricalevidence on the effects of ISAs on human-robot collaboration (HRC) remainslimited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging aparticipant and a robot in collaborative physical tasks. Our findings indicatethat robots capable of understanding ISAs significantly improve human'sperceived robot anthropomorphism, team performance, and trust. However, theeffectiveness of ISAs is task- and context-dependent, thus requiring carefuluse. These results highlight the importance of appropriately integrating directand indirect requests in HRC to enhance collaborative experiences and taskperformance.</description>
      <author>example@mail.com (Yan Zhang, Tharaka Sachintha Ratnayake, Cherie Sew, Jarrod Knibbe, Jorge Goncalves, Wafa Johal)</author>
      <guid isPermaLink="false">2502.11720v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>An Innovative Brain-Computer Interface Interaction System Based on the Large Language Model</title>
      <link>http://arxiv.org/abs/2502.11659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages,3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于SSVEP拼写器与大型语言模型接口结合的脑机接口系统，提高了系统的多语言支持、智能化和功能多样性。&lt;h4&gt;背景&lt;/h4&gt;现有的BCI技术在日常应用场景中的广泛应用受到单一功能性、限制性的范式设计、弱化的多语言支持以及较低智能水平的影响。&lt;h4&gt;目的&lt;/h4&gt;通过引入大型语言模型来改进现有BCI的技术性能，提高用户体验并扩展其实际应用范围。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新的BCI系统，该系统结合了SSVEP拼写器和LLM接口，实现自然语言输入并通过动态调用大模型生成SSVEP范式。&lt;h4&gt;主要发现&lt;/h4&gt;提出的系统支持多种任务场景，包括家用电器控制、机器人手臂操作以及无人机管理等，并且可以通过用户的习惯、使用情景和设备特性进行个性化设置。&lt;h4&gt;结论&lt;/h4&gt;结合SSVEP拼写器与大型语言模型的BCI系统克服了当前BCI系统的许多挑战，在功能、智能和支持多语种方面取得了突破。同时，引入LLM提升了用户体验并扩大了BCI技术在现实世界中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近的大规模语言模型（LLMs）的进步为通过用户交互改进脑机接口（BCI）技术提供了一条更有效的路径。然而，由于其单一的功能性、受限的范式设计、弱多语言支持以及较低的智能水平等限制因素的存在，BCI在日常应用中的广泛采用仍然受到阻碍。在这篇文章中，我们提出了一种创新性的BCI系统，该系统将稳定态视觉诱发电位（SSVEP）拼写器与大型语言模型的应用程序接口(API)深度整合起来。这一方法允许通过SSVEP拼写器输入自然语言，并且能够根据用户在不同场景中的控制需求动态调用大规模模型来生成新的SSVEP范式。命令提示、闪烁频率和布局位置都是可调整的，同时该系统支持超过十种不同的语言。此创新技术为用户提供了一系列任务场景的选择，包括家用电器控制、机器人手臂操作以及无人机管理等选项，并且可以依据用户习惯、使用情景及设备特性进行个性化定制。通过将SSVEP拼写器与大型语言模型相结合，所提出的系统解决了当前BCI系统面临的主要挑战，在功能性、智能化和多语种支持方面实现了突破性的进展。同时，引入LLM不仅改善了用户体验，还扩大了BCI技术在现实世界中的潜在应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) provide a more effectivepathway for upgrading brain-computer interface (BCI) technology in terms ofuser interaction. The widespread adoption of BCIs in daily applicationscenarios is still limited by factors such as their single functionality,restricted paradigm design, weak multilingual support, and low levels ofintelligence. In this paper, we propose an innovative BCI system that deeplyintegrates a steady-state visual evoked potential (SSVEP) speller with an LLMapplication programming interface (API). It allows natural language inputthrough the SSVEP speller and dynamically calls large models to generate SSVEPparadigms. The command prompt, blinking frequency, and layout position areadjustable to meet the user's control requirements in various scenarios. Morethan ten languages are compatible with the multilingual support of LLM. Avariety of task scenarios, such as home appliance control, robotic armoperation, and unmanned aerial vehicle (UAV) management are provided. The taskinterfaces of the system can be personalized according to the user's habits,usage scenarios, and equipment characteristics. By combining the SSVEP spellerwith an LLM, the system solves numerous challenges faced by current BCI systemsand makes breakthroughs in functionality, intelligence, and multilingualsupport. The introduction of LLM not only enhances user experience but alsoexpands the potential applications of BCI technology in real-worldenvironments.</description>
      <author>example@mail.com (Jing Jina, Yutao Zhang, Ruitian Xu, Yixin Chen)</author>
      <guid isPermaLink="false">2502.11659v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Object-Centric Image to Video Generation with Language Guidance</title>
      <link>http://arxiv.org/abs/2502.11655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了TextOCVP，一个基于文本描述指导的图像到视频生成的对象中心模型。&lt;h4&gt;背景&lt;/h4&gt;准确且灵活的世界模型对于自主系统理解环境和预测未来事件至关重要。对象中心模型通过结构化的潜在空间在建模物体动态和交互方面展示了潜力，但往往难以扩展至复杂数据集并结合外部引导，限制了其在机器人技术中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，我们提出了一种新的方法来构建准确且可控制的预测模型。&lt;h4&gt;方法&lt;/h4&gt;TextOCVP将观察到的场景解析成对象表示（称为槽），并且使用文本条件变压器预测器来预测未来物体状态和视频帧。这种模型同时建模物体动态和交互，并结合了文本指导，增强了对预测过程的控制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过其结构化的潜在空间提供了更精细的过程控制，在与几种图像到视频生成基线相比时表现出色。此外，它展示了结构化对象中心表示提供了更好的可控性和可解释性，有助于精确和易理解的预测。&lt;h4&gt;结论&lt;/h4&gt;TextOCVP不仅能够提供准确且可控制的预测，还能增强模型对复杂环境的理解能力，为机器人技术中的自主系统应用提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;精确而灵活的世界模型对于自主系统的环境理解和未来事件预测至关重要。对象中心模型通过结构化潜在空间展示了建模物体动态和交互方面的潜力，但往往难以扩展至复杂数据集并结合外部引导，限制了其在机器人技术中的应用。为了解决这些局限性，我们提出了一种新的方法TextOCVP——一个基于文本描述指导的图像到视频生成的对象中心模型。该模型将观察场景解析成对象表示（称为槽），并且使用文本条件变压器预测器来预测未来物体状态和视频帧。这种模型同时建模物体动态和交互，并结合了文本引导，增强了对预测过程的控制。通过其结构化的潜在空间提供了更精细的过程控制，在与几种图像到视频生成基线相比时表现出色。此外，它展示了结构化对象中心表示提供了更好的可控性和可解释性，有助于精确和易理解的预测。TextOCVP不仅能够提供准确且可控制的预测，还能增强模型对复杂环境的理解能力，为机器人技术中的自主系统应用提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and flexible world models are crucial for autonomous systems tounderstand their environment and predict future events. Object-centric models,with structured latent spaces, have shown promise in modeling object dynamicsand interactions, but often face challenges in scaling to complex datasets andincorporating external guidance, limiting their applicability in robotics. Toaddress these limitations, we propose TextOCVP, an object-centric model forimage-to-video generation guided by textual descriptions. TextOCVP parses anobserved scene into object representations, called slots, and utilizes atext-conditioned transformer predictor to forecast future object states andvideo frames. Our approach jointly models object dynamics and interactionswhile incorporating textual guidance, thus leading to accurate and controllablepredictions. Our method's structured latent space offers enhanced control overthe prediction process, outperforming several image-to-video generativebaselines. Additionally, we demonstrate that structured object-centricrepresentations provide superior controllability and interpretability,facilitating the modeling of object dynamics and enabling more precise andunderstandable predictions. Videos and code are available athttps://play-slot.github.io/TextOCVP/.</description>
      <author>example@mail.com (Angel Villar-Corrales, Gjergj Plepi, Sven Behnke)</author>
      <guid isPermaLink="false">2502.11655v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Leader and Follower: Interactive Motion Generation under Trajectory Constraints</title>
      <link>http://arxiv.org/abs/2502.11563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;随着游戏和电影制作的快速发展，从文本生成交互式运动因具有革新内容创作流程的巨大潜力而备受关注。&lt;h4&gt;背景&lt;/h4&gt;在许多实际应用中，需要对虚拟角色的动作范围或轨迹施加严格限制。然而，仅依赖于文本输入的方法面临着捕捉用户意图的重大挑战，特别是在指定所需的轨迹时存在困难。因此，生成的运动通常缺乏真实性和准确性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在开发一种无需重新训练即可为定制化动作生成提供灵活性和适应性的方法。&lt;h4&gt;方法&lt;/h4&gt;基于两人舞蹈中的角色分配概念，本文将复杂运动分解为引导者-跟随者的动态结构，并提出了一种无需训练的方法，该方法整合了步速控制器和动力学同步适配器。通过控制领导者的行为并纠正追随者的动作以与领导者保持一致，框架提升了现有模型生成符合轨迹的动作的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的利用轨迹信息更有效的办法，在真实性和准确性方面都优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究为从文本生成交互式运动提供了新的方向，并展示了一种可以应用于不同类型数据集的灵活、适应性强的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of game and film production, generatinginteractive motion from texts has garnered significant attention due to itspotential to revolutionize content creation processes. In many practicalapplications, there is a need to impose strict constraints on the motion rangeor trajectory of virtual characters. However, existing methods that rely solelyon textual input face substantial challenges in accurately capturing the user'sintent, particularly in specifying the desired trajectory. As a result, thegenerated motions often lack plausibility and accuracy. Moreover, existingtrajectory - based methods for customized motion generation rely on retrainingfor single - actor scenarios, which limits flexibility and adaptability todifferent datasets, as well as interactivity in two-actor motions. To generateinteractive motion following specified trajectories, this paper decouplescomplex motion into a Leader - Follower dynamic, inspired by role allocation inpartner dancing. Based on this framework, this paper explores the motion rangerefinement process in interactive motion generation and proposes atraining-free approach, integrating a Pace Controller and a KinematicSynchronization Adapter. The framework enhances the ability of existing modelsto generate motion that adheres to trajectory by controlling the leader'smovement and correcting the follower's motion to align with the leader.Experimental results show that the proposed approach, by better leveragingtrajectory information, outperforms existing methods in both realism andaccuracy.</description>
      <author>example@mail.com (Runqi Wang, Caoyuan Ma, Jian Zhao, Hanrui Xu, Dongfang Sun, Haoyang Chen, Lin Xiong, Zheng Wang, Xuelong Li)</author>
      <guid isPermaLink="false">2502.11563v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Statistical and Deterministic RCS Characterization for ISAC Channel Modeling</title>
      <link>http://arxiv.org/abs/2502.11540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在这项研究中，我们对在室内工厂环境下25-28GHz频段的各种测试目标的雷达反射截面（RCS）进行了统计分析，旨在为未来无线系统的目标识别和其他传感应用制定参数。我们的分析基于单站和双站配置下的测量数据，在发射器-接收器（T-R）以及目标位置的函数下进行双站角度20°、40°和60°的测试。我们使用精确的3dB波束宽度为10°，在方位角和平面内进行测量。测试目标包括无人驾驶飞机、自主移动机器人和机械臂。我们利用参数统计分布拟合测得的RCS数据。分析表明，对数正态和伽玛分布模型适用于描述不同反射点上的目标运动情况下的RCS。此外，为评估矩形木板在双站配置中的确定性RCS提供了一个框架，并对其广泛应用于室内热点环境进行了探讨。我们还评估了新型的确定性和统计性的RCS模型，这些模型依赖于双站角度、T-R距离（2m-10m）和目标的不同特性。结果表明，一些提出的RCS模型准确地拟合了测得的数据，突出了它们在双站配置中的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究针对未来无线系统的目标识别和其他传感应用，在特定频段内对室内工厂环境下的测试目标的雷达反射截面进行了统计分析。&lt;h4&gt;目的&lt;/h4&gt;制定可用于未来无线系统的参数，这些参数可以用于目标识别及其他类型的传感器应用中。&lt;h4&gt;方法&lt;/h4&gt;使用单站和双站配置在不同发射器-接收器位置和特定角度下进行测量，并利用对数正态分布和伽玛分布来拟合测得的雷达反射截面数据。此外还开发了一个评估矩形木板在双站配置中的确定性RCS框架。&lt;h4&gt;主要发现&lt;/h4&gt;对数正态和伽玛分布有效模拟了测试目标运动时的不同点上的雷达反射截面；提出的某些RCS模型能够很好地拟合测得的数据，尤其适用于双站配置。&lt;h4&gt;结论&lt;/h4&gt;研究提供了一个用于评估矩形木板在室内环境中的双站雷达反射截面的框架，并且提出了有效的RCS统计分布模型和确定性模型。这些结果对理解未来无线通信系统中目标识别的重要性具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we perform a statistical analysis of the radar cross section(RCS) for various test targets in an indoor factory at \(25\)-\(28\) GHz, withthe goal of formulating parameters that may be used for target identificationand other sensing applications for future wireless systems. The analysis isconducted based on measurements in monostatic and bistatic configurations forbistatic angles of \(20^\circ\), \(40^\circ\), and \(60^\circ\), which arefunctions of transmitter-receiver (T-R) and target positions, via accurate\(3\)dB beamwidth of \(10^\circ\) in both azimuth and elevation planes. Thetest targets include unmanned aerial vehicles, an autonomous mobile robot, anda robotic arm. We utilize parametric statistical distributions to fit themeasured RCS data. The analysis reveals that the \textit{lognormal and gammadistributions} are effective in modeling the RCS of the test targets overdifferent reflecting points of the target itself, i.e. when target is inmotion. Additionally, we provide a framework for evaluating the deterministicbistatic RCS of a rectangular sheet of laminated wood, due to its widespreaduse in indoor hotspot environments. Novel deterministic and statistical RCSmodels are evaluated, incorporating dependencies on the bistatic angle, T-Rdistance (\(2\)m -\(10\)m) and the target. The results demonstrate that someproposed RCS models accurately fit the measured data, highlighting theirapplicability in bistatic configurations.</description>
      <author>example@mail.com (Ali Waqar Azim, Ahmad Bazzi, Roberto Bomfin, Nikolaos Giakoumidis, Theodore S. Rappaport, Marwa Chafii)</author>
      <guid isPermaLink="false">2502.11540v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Iterative Surface Fitting for Contact-stable Grasp Planning</title>
      <link>http://arxiv.org/abs/2502.11535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 6 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的表面拟合算法，旨在解决现有抓取规划算法忽略接触点稳定性的问题。新方法分为三个步骤：旋转优化以对齐接触法线、平移精炼以改善质心（CoM）对齐和夹爪开口调整来优化接触点分布。&lt;h4&gt;背景&lt;/h4&gt;当前基于表面拟合的抓取规划算法侧重于机械手与物体表面之间的几何对应关系，而忽略了接触稳定性的重要性。这导致了由于接触配置不足而导致的不稳定的抓取情况。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法中的局限性，论文提出了一种新的表面拟合算法，该算法在保持几何兼容性的基础上考虑到了接触点分布的稳定性。&lt;h4&gt;方法&lt;/h4&gt;受人类抓握行为启发，新方法将抓取姿态优化分解为三个步骤：旋转以对齐接触法线、平移以改进质心（CoM）对齐以及调整夹爪开口来优化接触点分布。&lt;h4&gt;主要发现&lt;/h4&gt;通过在YCB数据集的十个物体上进行仿真实验，所提出的方法相比忽视了接触稳定性的传统表面拟合方法，在抓取成功率方面提高了80%。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了考虑接触稳定性对提高抓取成功的有效性，并且证明了分步骤优化策略的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们解决了基于表面拟合的抓取规划算法的主要局限性，这种算法主要关注夹爪和物体表面之间的几何匹配，而忽略了接触点分布稳定性的考量。这往往导致由于接触配置不足而导致的不稳定抓取情况。为了克服这个限制，我们提出了一种新的表面拟合算法，在保持几何兼容性的同时考虑了接触稳定性。受人类抓握行为启发的方法将抓取姿态优化分解为三个连续步骤：（1）旋转优化以对齐接触法线；（2）平移精炼以改进质心（CoM）对齐；（3）夹爪开口调整以优化接触点分布。我们通过在YCB数据集的十个对象上的模拟验证了我们的方法，展示了比传统忽视接触稳定性的表面拟合方法高出80%的成功抓取率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we address the limitation of surface fitting-based graspplanning algorithm, which primarily focuses on geometric alignment between thegripper and object surface while overlooking the stability of contact pointdistribution, often resulting in unstable grasps due to inadequate contactconfigurations. To overcome this limitation, we propose a novel surface fittingalgorithm that integrates contact stability while preserving geometriccompatibility. Inspired by human grasping behavior, our method disentangles thegrasp pose optimization into three sequential steps: (1) rotation optimizationto align contact normals, (2) translation refinement to improve Center of Mass(CoM) alignment, and (3) gripper aperture adjustment to optimize contact pointdistribution. We validate our approach through simulations on ten YCB datasetobjects, demonstrating an 80% improvement in grasp success over conventionalsurface fitting methods that disregard contact stability. Further details canbe found on our project page:https://tomoya-yamanokuchi.github.io/disf-project-page/.</description>
      <author>example@mail.com (Tomoya Yamanokuchi, Alberto Bacchin, Emilio Olivastri, Takamitsu Matsubara, Emanuele Menegatti)</author>
      <guid isPermaLink="false">2502.11535v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>SurgPose: a Dataset for Articulated Robotic Surgical Tool Pose Estimation and Tracking</title>
      <link>http://arxiv.org/abs/2502.11534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为SurgPose的数据集，用于视觉外科工具姿态估计和跟踪。该数据集包括不同光照条件下收集的原始视频和关键点注释。&lt;h4&gt;背景&lt;/h4&gt;准确且高效的手术机器人工具姿态估计对于诸如增强现实（AR）等下游应用以及基于学习的自主操作至关重要。然而，在缺乏公开数据的情况下，这仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有数据集的限制并提高手术机器人工具姿态估计的质量，研究人员创建了一个包含实例感知语义关键点和骨架的新数据集SurgPose。&lt;h4&gt;方法&lt;/h4&gt;使用紫外线反应油漆在视频中进行标记，并在不同照明条件下执行相同的轨迹来收集原始视频和关键点注释。该数据集由6类外科器械的约120,000个实例组成，每个实例都标注了7个语义关键点。&lt;h4&gt;主要发现&lt;/h4&gt;SurgPose数据集中包含的数据可用于测试几种基于视觉的方法来进行手术工具跟踪。&lt;h4&gt;结论&lt;/h4&gt;通过发布SurgPose数据集以及展示几个基线方法的有效性，研究工作为未来的研究提供了重要的资源和参考。&lt;h4&gt;翻译&lt;/h4&gt;准确且高效的外科机器人工具姿态估计对于下游应用（例如增强现实(AR)在手术培训中的应用及基于学习的自主操作）具有基础性的意义。尽管人类和动物的姿态估计取得了显著进展，在外科手术机器人领域，由于公开数据的稀缺性，这一问题仍然是一个挑战。达芬奇末端执行器运动学的大绝对误差以及复杂的校准程序使得收集标定后的运动学数据十分昂贵。鉴于这些限制，我们创建了一个名为SurgPose的数据集，用于视觉外科工具姿态估计和跟踪。通过使用在白光下不可见但在紫外线照射下显形的紫外线反应油漆进行标记，我们在不同照明条件下执行相同轨迹以分别获取原始视频和关键点注释。SurgPose数据集中包含大约120,000个手术器械实例（用于训练80,000个，验证40,000个），包括6类。每种工具实例都被标注了7个语义关键点。由于视频以立体成对形式采集，因此可以基于立体匹配深度将二维姿态提升到三维。除了发布数据集之外，我们还测试了几种手术器械跟踪的基线方法来展示SurgPose的有效性。更多细节请访问surgpose.github.io网站。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient surgical robotic tool pose estimation is offundamental significance to downstream applications such as augmented reality(AR) in surgical training and learning-based autonomous manipulation. Whilesignificant advancements have been made in pose estimation for humans andanimals, it is still a challenge in surgical robotics due to the scarcity ofpublished data. The relatively large absolute error of the da Vinci endeffector kinematics and arduous calibration procedure make calibratedkinematics data collection expensive. Driven by this limitation, we collected adataset, dubbed SurgPose, providing instance-aware semantic keypoints andskeletons for visual surgical tool pose estimation and tracking. By markingkeypoints using ultraviolet (UV) reactive paint, which is invisible under whitelight and fluorescent under UV light, we execute the same trajectory underdifferent lighting conditions to collect raw videos and keypoint annotations,respectively. The SurgPose dataset consists of approximately 120k surgicalinstrument instances (80k for training and 40k for validation) of 6 categories.Each instrument instance is labeled with 7 semantic keypoints. Since the videosare collected in stereo pairs, the 2D pose can be lifted to 3D based onstereo-matching depth. In addition to releasing the dataset, we test a fewbaseline approaches to surgical instrument tracking to demonstrate the utilityof SurgPose. More details can be found at surgpose.github.io.</description>
      <author>example@mail.com (Zijian Wu, Adam Schmidt, Randy Moore, Haoying Zhou, Alexandre Banks, Peter Kazanzides, Septimiu E. Salcudean)</author>
      <guid isPermaLink="false">2502.11534v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Anti-Degeneracy Scheme for Lidar SLAM based on Particle Filter in Geometry Feature-Less Environments</title>
      <link>http://arxiv.org/abs/2502.11486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种基于深度学习的抗退化系统，以解决粒子滤波SLAM在缺乏几何特征场景中的精度问题。&lt;h4&gt;背景&lt;/h4&gt;粒子过滤SLAM方法因高效性被广泛应用于室内环境。然而，在缺少几何特征的环境中，该方法的准确性会大幅下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的抗退化系统来提升粒子过滤SLAM在不具备明显几何特征的环境下的性能和精度。&lt;h4&gt;方法&lt;/h4&gt;{'线性映射设计': '采用尺度不变的线性映射将连续空间坐标转换为离散索引，并通过基于高斯模型的数据增强方法确保模型性能不受粒子数量变化影响。', '退化检测模型开发': '使用残差神经网络和变换器来发展一个能够识别退化的模型，该模型能通过观察粒子分布的特征来判断是否出现退化。', '自适应抗退化策略设计': '在重采样过程中进行融合和扰动操作以提供更加丰富且准确的姿态初始值，并采用分层姿态优化方法结合粗匹配与细匹配，在不同程度的退化下能动态调整优化频率及传感器可信度，提升寻找全局最优位置的能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过消融实验验证了模型的有效性、改进图像矩阵法和GPU计算时间上的优势，并且通过模拟实验和真实环境中的测试证明了该抗退化系统在各种场景下的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的工作已被提交至IEEE发表，其旨在解决几何特征缺乏的环境中SLAM系统的精度问题，并展示了通过深度学习技术可以显著提升粒子滤波算法的表现。&lt;h4&gt;翻译&lt;/h4&gt;基于粒子过滤的定位与地图构建（SLAM）方法由于其高效率被广泛应用于室内场景。然而，在缺少几何特性的情况下，因为约束条件的缺失导致了准确性的严重下降。本文提出了一个基于深度学习的抗退化系统，旨在提高在缺乏明显特征环境中的性能和精度。该系统包括设计尺度不变的线性映射、开发残差神经网络与变换器结合的退化检测模型以及自适应抗退化策略的设计等三个主要部分，并通过实验验证了系统的有效性及优化方法的效果。这项工作已经被提交给IEEE进行发表。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) based on particle filtering hasbeen extensively employed in indoor scenarios due to its high efficiency.However, in geometry feature-less scenes, the accuracy is severely reduced dueto lack of constraints. In this article, we propose an anti-degeneracy systembased on deep learning. Firstly, we design a scale-invariant linear mapping toconvert coordinates in continuous space into discrete indexes, in which a dataaugmentation method based on Gaussian model is proposed to ensure the modelperformance by effectively mitigating the impact of changes in the number ofparticles on the feature distribution. Secondly, we develop a degeneracydetection model using residual neural networks (ResNet) and transformer whichis able to identify degeneracy by scrutinizing the distribution of the particlepopulation. Thirdly, an adaptive anti-degeneracy strategy is designed, whichfirst performs fusion and perturbation on the resample process to provide richand accurate initial values for the pose optimization, and use a hierarchicalpose optimization combining coarse and fine matching, which is able toadaptively adjust the optimization frequency and the sensor trustworthinessaccording to the degree of degeneracy, in order to enhance the ability ofsearching the global optimal pose. Finally, we demonstrate the optimality ofthe model, as well as the improvement of the image matrix method and GPU on thecomputation time through ablation experiments, and verify the performance ofthe anti-degeneracy system in different scenarios through simulationexperiments and real experiments. This work has been submitted to IEEE forpublication. Copyright may be transferred without notice, after which thisversion may no longer be available.</description>
      <author>example@mail.com (Yanbin Li, Wei Zhang, Zhiguo Zhang, Xiaogang Shi, Ziruo Li, Mingming Zhang, Hongping Xie, Wenzheng Chi)</author>
      <guid isPermaLink="false">2502.11486v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Learning Dexterous Bimanual Catch Skills through Adversarial-Cooperative Heterogeneous-Agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.11437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的异构代理强化学习框架，用于学习灵巧的双臂接球技能。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人接球研究主要集中在单手系统上，这种系统的处理能力有限，无法应对大型或复杂的物体。而双臂接球在灵活性和物体处理方面具有巨大潜力，但同时也带来了新的协调与控制挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种使用异构代理强化学习（HARL）框架的方法来解决这些问题，旨在提高机器人在复杂环境中的接球能力。&lt;h4&gt;方法&lt;/h4&gt;引入了一种对抗性奖励机制，其中投掷器和接球器分别作为两个不同的智能体进行互动：投掷器通过调整物体的抛出速度增加挑战难度；而接球器则学习如何协调两只手来接住这些变化条件下的物体。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟环境中使用15种不同物体进行了评估，显示了该方法在处理多样性和复杂性方面具有良好的鲁棒性和灵活性。实验结果表明，与单智能体基线相比，在所有测试条件下均实现了大约2倍的接球奖励提升。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为开发能够处理更大、更复杂的对象提供了可能，并展示了双臂机器人协调技术的新前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经作为中文进行了详细解释。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic catching has traditionally focused on single-handed systems, whichare limited in their ability to handle larger or more complex objects. Incontrast, bimanual catching offers significant potential for improved dexterityand object handling but introduces new challenges in coordination and control.In this paper, we propose a novel framework for learning dexterous bimanualcatching skills using Heterogeneous-Agent Reinforcement Learning (HARL). Ourapproach introduces an adversarial reward scheme, where a throw agent increasesthe difficulty of throws-adjusting speed-while a catch agent learns tocoordinate both hands to catch objects under these evolving conditions. Weevaluate the framework in simulated environments using 15 different objects,demonstrating robustness and versatility in handling diverse objects. Ourmethod achieved approximately a 2x increase in catching reward compared tosingle-agent baselines across 15 diverse objects.</description>
      <author>example@mail.com (Taewoo Kim, Youngwoo Yoon, Jaehong Kim)</author>
      <guid isPermaLink="false">2502.11437v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>Verti-Bench: A General and Scalable Off-Road Mobility Benchmark for Vertically Challenging Terrain</title>
      <link>http://arxiv.org/abs/2502.11426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Verti-Bench，一个专注于极崎岖、垂直挑战性越野环境的移动性能基准。它提供了100个独特的越野环境和1000项不同的导航任务，用于对自主移动机器人的移动系统进行标准化和客观评估。&lt;h4&gt;背景&lt;/h4&gt;近年来，自动驾驶技术在户外非公路环境中部署取得了显著进展，并从模拟和真实世界的实验中获得了令人鼓舞的结果。然而，在评估越野移动性时仍面临巨大挑战，主要是由于车辆平台和地形性质的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出Verti-Bench这一基准工具来解决现有越野环境评价中存在的问题，通过高保真多物理仿真提供标准化和客观的评价。&lt;h4&gt;方法&lt;/h4&gt;通过在极高精度的模拟环境中设置100种不同的越野条件和1000个独特的导航任务来进行评估。这些环境包括各种几何形状、语义信息以及刚性和可变形表面等特性，同时支持不同规模与驱动机制的车辆平台。&lt;h4&gt;主要发现&lt;/h4&gt;使用Verti-Bench对十个越野移动系统进行了基准测试，并基于结果提出了未来的研究方向。&lt;h4&gt;结论&lt;/h4&gt;Verti-Bench不仅为现有的越野自动驾驶研究提供了一个有价值的评估工具，还推动了该领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;近期，在户外非公路环境中的自主移动机器人的部署方面取得了重大进展。从模拟和实际世界实验中获得了令人鼓舞的结果。然而，与在静态数据集上评估越野感知任务不同，评价越野机动性仍然面临着许多挑战，如车辆平台和地形属性的多样性。此外，在进行机动性评估时需要展开不同的车地互动方式，这要求移动系统必须能够与其环境相互作用而不是与预收集的数据集比较。本文中，我们介绍了Verti-Bench，一个专注于极端崎岖、垂直挑战性越野环境的机动性基准工具。它包括100个独特的非公路环境和1000项不同的导航任务，并且包含了数百万种不同类型的地形属性，如各种几何形状与语义信息、刚性和变形表面以及大型自然障碍物，从而在高保真度多物理仿真中提供标准化和客观的评估。Verti-Bench还可扩展到不同规模及驱动机制的各种车辆平台。我们还提供了专家演示数据集、随机探索数据、失败案例（包括翻车和困住的情况）以及一个用于强化学习的gym-like接口。使用Verti-Bench对十个非公路机动系统进行了基准测试，并提出了我们的研究结果，指出了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancement in off-road autonomy has shown promises in deployingautonomous mobile robots in outdoor off-road environments. Encouraging resultshave been reported from both simulated and real-world experiments. However,unlike evaluating off-road perception tasks on static datasets, benchmarkingoff-road mobility still faces significant challenges due to a variety offactors, including variations in vehicle platforms and terrain properties.Furthermore, different vehicle-terrain interactions need to be unfolded duringmobility evaluation, which requires the mobility systems to interact with theenvironments instead of comparing against a pre-collected dataset. In thispaper, we present Verti-Bench, a mobility benchmark that focuses on extremelyrugged, vertically challenging off-road environments. 100 unique off-roadenvironments and 1000 distinct navigation tasks with millions of off-roadterrain properties, including a variety of geometry and semantics, rigid anddeformable surfaces, and large natural obstacles, provide standardized andobjective evaluation in high-fidelity multi-physics simulation. Verti-Bench isalso scalable to various vehicle platforms with different scales and actuationmechanisms. We also provide datasets from expert demonstration, randomexploration, failure cases (rolling over and getting stuck), as well as agym-like interface for reinforcement learning. We use Verti-Bench to benchmarkten off-road mobility systems, present our findings, and identify futureoff-road mobility research directions.</description>
      <author>example@mail.com (Tong Xu, Chenhui Pan, Madhan B. Rao, Aniket Datar, Anuj Pokhrel, Yuanjie Lu, Xuesu Xiao)</author>
      <guid isPermaLink="false">2502.11426v1</guid>
      <pubDate>Tue, 18 Feb 2025 18:11:56 +0800</pubDate>
    </item>
    <item>
      <title>DES to HSC: Detecting low surface brightness galaxies in the Abell 194 cluster using transfer learning</title>
      <link>http://arxiv.org/abs/2502.03142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究利用了两种基于Transformer模型的LSBG识别技术，并成功应用于更深观测数据，发现了171个低表面亮度星系（包括87个新发现）和28个超扩散星系。这些发现有助于理解星系演化及宇宙学模型。&lt;h4&gt;背景&lt;/h4&gt;低表面亮度星系(LSBGs)对于理解星系演化和宇宙学模型至关重要。未来的大规模调查预计将揭露大量LSBGs，需要准确的自动化或基于机器学习的方法进行检测。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习在识别LSBG中的作用，并提出一种新的方法来提高LSBG识别效率。&lt;h4&gt;方法&lt;/h4&gt;使用训练过的Transformer模型（LSBG DETR和LSBG ViT）对Abell 194星系团的专用Hyper Suprime-Cam (HSC)观测数据进行LSBG检测。这些数据比Dark Energy Survey (DES)的数据深两个星等。&lt;h4&gt;主要发现&lt;/h4&gt;[{'数量': '识别出171个低表面亮度星系，包括87个新发现'}, {'分类': '28个超扩散星系被归类为LSBGs'}, {'模型性能': 'Transformer模型在未经微调的情况下达到93%的真正例率(TPR)'}]&lt;h4&gt;结论&lt;/h4&gt;训练于较浅调查数据集的Transformer模型可以成功应用于更深的数据，但需要适当的数据标准化。&lt;h4&gt;翻译&lt;/h4&gt;Low表面亮度星系(LSBGs)对于理解galaxy演化和宇宙学模型至关重要。未来的大规模调查预计将揭露大量LSBGs，需要准确的自动化或基于机器学习的方法进行检测。本研究使用训练过的Transformer模型（LSBG DETR和LSBG ViT）对Abell 194星系团的专用Hyper Suprime-Cam (HSC)观测数据进行LSBG检测，并成功发现了171个低表面亮度星系，包括87个新发现。这些LSBGs中还包括28个被分类为超扩散星系(UDGs)，它们与矮星系共享类似的S'ersic参数，表明可能是一类扩展的矮星系群体。此外，在未经微调的情况下，Transformer模型在较深数据集上达到了93%的真正例率(TPR)。研究表明，训练于较浅调查数据集的Transformer模型可以成功应用于更深的数据，但需要适当的数据标准化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low surface brightness galaxies (LSBGs) are important for understandinggalaxy evolution and cosmological models. The upcoming large-scale surveys areexpected to uncover a large number of LSBGs, requiring accurate automated ormachine learning-based methods for their detection. We study the scope oftransfer learning for the identification of LSBGs. We use transformer modelsdivided into two categories: LSBG Detection Transformer (LSBG DETR) and LSBGVision Transformer (LSBG ViT), trained on Dark Energy Survey (DES) data, toidentify LSBGs from dedicated Hyper Suprime-Cam (HSC) observations of the Abell194 cluster, which are two magnitudes deeper than DES. The data from DES andHSC were standardized based on pixel-level surface brightness. We used twotransformer ensembles to detect LSBGs. This was followed by a single-componentS\'ersic model fit and a final visual inspection to filter out potential falsepositives and improve sample purity. We present a sample of 171 low surfacebrightness galaxies (LSBGs) in the Abell 194 cluster using HSC data, including87 new discoveries. Of these, 159 were identified using transformer models, and12 additional LSBGs were found through visual inspection. The transformer modelachieved a true positive rate (TPR) of 93% in HSC data without any fine-tuning.Among the LSBGs, 28 were classified as ultra-diffuse galaxies (UDGs). Thenumber of UDGs and the radial UDG number density suggest a linear relationshipbetween UDG numbers and cluster mass on a log scale. UDGs share similarS\'ersic parameters with dwarf galaxies and occupy the extended end of the$R_{\mathrm{eff}}-M_g$ plane, suggesting they might be an extendedsubpopulation of dwarf galaxies. We have demonstrated that transformer modelstrained on shallower surveys can be successfully applied to deeper surveys withappropriate data normalization.</description>
      <author>example@mail.com (H. Thuruthipilly, Junais, J. Koda, A. Pollo, M. Yagi, H. Yamanoi, Y. Komiyama, M. Romano, K. Małek, D. Donevski)</author>
      <guid isPermaLink="false">2502.03142v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
  <item>
      <title>AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.10235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;预训练基础模型（FMs）在单变量时间序列预测任务中表现出色，但仍然面临如何处理特征间的复杂依赖关系和量化不确定性等挑战。本文提出了一种名为适配器（adapters）的方法来解决这些问题，通过将多变量输入投影到适合的潜在空间并独立应用于每个维度，从而有效利用预训练单变量时间序列FMs进行多元任务预测。&lt;h4&gt;背景&lt;/h4&gt;预训练基础模型在处理单变量时间序列数据时展现出了强大的性能。然而，在实际应用中仍存在一些挑战：例如如何有效地管理多个特征之间的复杂依赖关系以及如何准确量化这些模型的预测不确定性。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入适配器来应对上述关键问题，该方法能够帮助预训练单变量时间序列FMs在多变量任务上更有效应用。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一种新的框架AdaPTS，它包括一系列适配器和优化/推理策略。这些适应器是特征空间变换，在灵感来自表示学习和部分随机贝叶斯神经网络的研究成果的基础上设计的。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成数据集及实际世界数据集上的实验验证了该方法的有效性，展示了与基线方法相比在预测准确性和不确定性量化方面的显著改进。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明AdaPTS框架作为利用时间序列FMs处理多元问题的一种模块化、可扩展且有效的解决方案，可以促进其在未来更广泛的实际应用中的采用。相关代码可在https://github.com/abenechehab/AdaPTS中获取。&lt;h4&gt;翻译&lt;/h4&gt;预训练基础模型在单变量时间序列预测任务中表现出色，但仍然面临如何处理特征间的复杂依赖关系和量化不确定性等挑战。本文提出了一种名为适配器的方法来解决这些问题，通过将多变量输入投影到适合的潜在空间并独立应用于每个维度，从而有效利用预训练单变量时间序列FMs进行多元任务预测。文章设计了一系列适应器，并通过实验验证了其有效性，在合成数据集及实际世界数据集中均显示出了相比基线方法而言在准确性与不确定性量化方面的显著改善。该研究为预训练基础模型在未来更广泛的应用中提供了一个模块化、可扩展且有效的解决方案，推动它们的进一步采用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained foundation models (FMs) have shown exceptional performance inunivariate time series forecasting tasks. However, several practical challengespersist, including managing intricate dependencies among features andquantifying uncertainty in predictions. This study aims to tackle thesecritical limitations by introducing adapters; feature-space transformationsthat facilitate the effective use of pre-trained univariate time series FMs formultivariate tasks. Adapters operate by projecting multivariate inputs into asuitable latent space and applying the FM independently to each dimension.Inspired by the literature on representation learning and partially stochasticBayesian neural networks, we present a range of adapters andoptimization/inference strategies. Experiments conducted on both synthetic andreal-world datasets confirm the efficacy of adapters, demonstrating substantialenhancements in forecasting accuracy and uncertainty quantification compared tobaseline methods. Our framework, AdaPTS, positions adapters as a modular,scalable, and effective solution for leveraging time series FMs in multivariatecontexts, thereby promoting their wider adoption in real-world applications. Werelease the code at https://github.com/abenechehab/AdaPTS.</description>
      <author>example@mail.com (Abdelhakim Benechehab, Vasilii Feofanov, Giuseppe Paolo, Albert Thomas, Maurizio Filippone, Balázs Kégl)</author>
      <guid isPermaLink="false">2502.10235v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SGS-GNN: A Supervised Graph Sparsification method for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.10208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在大型图上进行推理任务时，图形神经网络（GNNs）的计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的监督图稀疏化方法SGS-GNN，以减少GNNs执行推断任务所需的计算开销&lt;h4&gt;方法&lt;/h4&gt;{'1': '学习边采样概率分布并抽取特定大小的稀疏子图来降低计算成本。', '2': '在损失函数中使用正则化器增强异质图中的同质性，从而提高GNNs的准确性。', '3': '支持基于先验的概率分布学习模块的条件更新以缩小稀疏图搜索空间。', '4': '比采用固定分布（如随机采样）的方法更有效地学习子图搜索空间'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '在仅保留20%边的稀疏子图中，SGS-GNN相对于原始图改善F1评分几何平均值为4%，并在异质性图形上预测准确性提高最多30%', '2': '与最先进的方法相比，在相似度的采样子图稀疏度下，SGS-GNN在F1评分上的改进达到4-7%的几何平均值', '3': '相比采用固定分布的方法，SGS-GNN需要大约一半的时间来收敛'}&lt;h4&gt;结论&lt;/h4&gt;SGS-GNN有效降低了GNN执行推理任务时的计算成本，并提高了稀疏图上模型预测准确性。实验表明它比当前最佳方法更高效。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了SGS-GNN，这是一种新颖的监督图稀疏化方法，通过学习边采样概率分布并抽取特定大小的稀疏子图来减少大型图上执行GNNs推断任务时的计算成本。该方法在异质性图中提高了模型预测准确性，并且比使用固定分布的方法更有效地减少了收敛时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SGS-GNN, a novel supervised graph sparsifier that learns thesampling probability distribution of edges and samples sparse subgraphs of auser-specified size to reduce the computational costs required by GNNs forinference tasks on large graphs. SGS-GNN employs regularizers in the lossfunction to enhance homophily in sparse subgraphs, boosting the accuracy ofGNNs on heterophilic graphs, where a significant number of the neighbors of anode have dissimilar labels. SGS-GNN also supports conditional updates of theprobability distribution learning module based on a prior, which helps narrowthe search space for sparse graphs. SGS-GNN requires fewer epochs to obtainhigh accuracies since it learns the search space of subgraphs more effectivelythan methods using fixed distributions such as random sampling. Extensiveexperiments using 33 homophilic and heterophilic graphs demonstrate thefollowing: (i) with only 20% of edges retained in the sparse subgraphs, SGS-GNNimproves the F1-scores by a geometric mean of 4% relative to the originalgraph; on heterophilic graphs, the prediction accuracy is better up to 30%.(ii) SGS-GNN outperforms state-of-the-art methods with improvement in F1-scoresof 4-7% in geometric mean with similar sparsities in the sampled subgraphs, and(iii) compared to sparsifiers that employ fixed distributions, SGS-GNN requiresabout half the number of epochs to converge.</description>
      <author>example@mail.com (Siddhartha Shankar Das, Naheed Anjum Arafat, Muftiqur Rahman, S M Ferdous, Alex Pothen, Mahantesh M Halappanavar)</author>
      <guid isPermaLink="false">2502.10208v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages</title>
      <link>http://arxiv.org/abs/2502.10362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;CLaMP 3是一个统一的框架，旨在解决音乐信息检索中的跨模态和跨语言泛化挑战。&lt;h4&gt;背景&lt;/h4&gt;传统的音乐信息检索系统在处理不同模态（乐谱、表演信号、音频录音）以及多种语言时面临挑战，需要一个能够统一这些模式并促进其之间相互转换的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架CLaMP 3，它使用对比学习方法将所有主要的音乐模态与多语言文本在共享表示空间中对齐，使跨不匹配模态的信息检索成为可能。&lt;h4&gt;方法&lt;/h4&gt;{'1': '采用对比学习技术，让不同类型的音乐数据和多语言文本在一个共同的表示空间内对齐。', '2': '使用一种可适应未见过的语言的多语言文本编码器来增强系统的跨语言泛化能力。', '3': '通过检索增强生成方法创建了一个大规模的数据集M4-RAG，包含2.31万音乐-文本配对。', '4': '利用详细元数据丰富了数据集，使其涵盖了全球各种音乐传统。', '5': '为了推进未来的研究，发布了一项新的基准测试WikiMT-X，包含了1000个乐谱、音频和多样化文本描述的三元组。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'CLaMP 3在多个MIR任务上达到了最先进的性能。', '2': '该系统显著超越了以前的强大基准线，在多模态和多语言音乐环境中展示了优秀的泛化能力。'}&lt;h4&gt;结论&lt;/h4&gt;CLaMP 3框架提供了一个强大的解决方案，用于解决跨模态和跨语言挑战，并通过大规模数据集的创建为未来的研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;CLaMP 3是一个旨在应对音乐信息检索中跨模态与跨语种泛化难题的统一框架。它利用对比学习技术，实现了乐谱、表演信号及音频录音等主要音乐形态与多语言文本在共享表示空间内的对齐，从而通过文本作为桥梁实现不同不匹配模态之间的信息检索。此框架具备一种能适应未知语言的多语种文本编码器，展示了强大的跨语种泛化能力。借助于增强型生成的检索方法，我们构建了一个包含231万音乐-文本配对的大规模网络级数据集M4-RAG，并且该数据集通过详细的元数据信息代表了全球多样化的音乐传统风格。为了推进未来的相关研究工作，我们发布了WikiMT-X基准测试，包括了一千个乐谱、音频文件及丰富多样的文字描述三元组样本。实验结果表明，CLaMP 3在多项MIR任务上实现了卓越的性能表现，并显著超越了现有最强的基线模型，在多元模态与语言音乐场景中均展示了优秀的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLaMP 3 is a unified framework developed to address challenges of cross-modaland cross-lingual generalization in music information retrieval. Usingcontrastive learning, it aligns all major music modalities--including sheetmusic, performance signals, and audio recordings--with multilingual text in ashared representation space, enabling retrieval across unaligned modalitieswith text as a bridge. It features a multilingual text encoder adaptable tounseen languages, exhibiting strong cross-lingual generalization. Leveragingretrieval-augmented generation, we curated M4-RAG, a web-scale datasetconsisting of 2.31 million music-text pairs. This dataset is enriched withdetailed metadata that represents a wide array of global musical traditions. Toadvance future research, we release WikiMT-X, a benchmark comprising 1,000triplets of sheet music, audio, and richly varied text descriptions.Experiments show that CLaMP 3 achieves state-of-the-art performance on multipleMIR tasks, significantly surpassing previous strong baselines and demonstratingexcellent generalization in multimodal and multilingual music contexts.</description>
      <author>example@mail.com (Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun)</author>
      <guid isPermaLink="false">2502.10362v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models</title>
      <link>http://arxiv.org/abs/2502.10307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为SPIRIT的新模型，该模型利用基础模型进行太阳辐照度预测，适用于没有多年历史数据的新型光伏电站。&lt;h4&gt;背景&lt;/h4&gt;传统的太阳能预测模型依赖于特定地点多年的辐射数据，但新建光伏电站往往缺乏这些数据。可再生能源的高度间歇性使得建立准确的太阳能辐照度预测系统对于有效电网管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖于历史数据的新方法，以促进新型光伏发电系统的快速部署和全球范围内的太阳能能源整合。&lt;h4&gt;方法&lt;/h4&gt;提出了SPIRIT模型，在零样本迁移学习中表现出色，能够适应新地点而无需历史数据。随着更多特定位置的数据可用性提高，性能可通过微调进一步改进。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最佳模型相比，该模型在零样本迁移学习中的表现高出约70%，并在统计上显著改善了预测准确性。&lt;h4&gt;结论&lt;/h4&gt;SPIRIT代表了一种向快速、可扩展和适应性强的太阳能预报解决方案迈进的重要步骤，有助于加速全球电力系统中可再生能源的整合。&lt;h4&gt;翻译&lt;/h4&gt;传统的太阳能预测模型依赖于数年的特定地点的历史辐照度数据，但新建光伏电站往往缺乏这些数据。由于可再生能源的高度间歇性，建立准确的太阳辐射预测系统对于有效电网管理和促进太阳能能源的发展至关重要，这是实现联合国净零目标的关键因素。在本研究中，我们提出了一种基于基础模型进行太阳辐射预报的新方法SPIRIT，使其适用于新的光伏安装。我们的方法在零样本迁移学习中的表现比现有最佳模型高出约70%，使新地点的有效性能成为可能，而无需任何历史数据。随着更多特定位置的数据可用性提高，微调进一步提高了性能。这些发现得到了统计显著性的支持，进一步验证了我们的方法。SPIRIT代表了一种向快速、可扩展和适应性强的太阳预报解决方案迈进的重要步骤，有助于加速将可再生能源整合到全球电力系统中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional solar forecasting models are based on several years ofsite-specific historical irradiance data, often spanning five or more years,which are unavailable for newer photovoltaic farms. As renewable energy ishighly intermittent, building accurate solar irradiance forecasting systems isessential for efficient grid management and enabling the ongoing proliferationof solar energy, which is crucial to achieve the United Nations' net zerogoals. In this work, we propose SPIRIT, a novel approach leveraging foundationmodels for solar irradiance forecasting, making it applicable to newer solarinstallations. Our approach outperforms state-of-the-art models in zero-shottransfer learning by about 70%, enabling effective performance at new locationswithout relying on any historical data. Further improvements in performance areachieved through fine-tuning, as more location-specific data becomes available.These findings are supported by statistical significance, further validatingour approach. SPIRIT represents a pivotal step towards rapid, scalable, andadaptable solar forecasting solutions, advancing the integration of renewableenergy into global power systems.</description>
      <author>example@mail.com (Aditya Mishra, Ravindra T, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru)</author>
      <guid isPermaLink="false">2502.10307v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Robustness tests for biomedical foundation models should tailor to specification</title>
      <link>http://arxiv.org/abs/2502.10374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review, comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的生物医学AI监管框架中包括了鲁棒性作为关键组成部分，但缺乏详细的实施指导。随着生物医学基础模型的兴起，这些系统的能力范围广泛且容易受到复杂的数据分布变化的影响，这给测试和认证带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于优先级的任务导向方法，针对预定义规范来定制鲁棒性评估目标，以平衡测试可行性和有效性。&lt;h4&gt;方法&lt;/h4&gt;建议采用具体的政策来细化鲁棒性概念的分类，并推动风险评估与监控的标准制定。&lt;h4&gt;主要发现&lt;/h4&gt;该研究指出了一种标准化的风险评估和监控的方法可以指导技术发展及缓解措施的实施。&lt;h4&gt;结论&lt;/h4&gt;通过提出一种基于任务优先级的方法，结合具体的政策建议，在生物医学AI领域内促进鲁棒性概念的细化，并鼓励风险评估与监测的标准制定，从而提高整体系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;现有的生物医学人工智能（AI）监管框架虽然将稳健性作为关键要素之一，但缺乏详细的实施指导。近年来出现的生物医学基础模型因为其广泛的适用能力和对复杂数据分布变化的高度敏感性，为测试和认证带来了新的挑战。为了在保持测试可行性和有效性之间取得平衡，我们建议采取一种基于任务优先级的方法来根据预定义规范定制鲁棒性评估目标。此外，我们还呼吁采用具体政策细化鲁棒性概念的分类，并促进风险评估与监控的标准制定。这种方法有助于推动技术发展和缓解措施实施过程中的标准化，从而提升整体系统的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing regulatory frameworks for biomedical AI include robustness as a keycomponent but lack detailed implementational guidance. The recent rise ofbiomedical foundation models creates new hurdles in testing and certificationgiven their broad capabilities and susceptibility to complex distributionshifts. To balance test feasibility and effectiveness, we suggest apriority-based, task-oriented approach to tailor robustness evaluationobjectives to a predefined specification. We urge concrete policies to adopt agranular categorization of robustness concepts in the specification. Ourapproach promotes the standardization of risk assessment and monitoring, whichguides technical developments and mitigation efforts.</description>
      <author>example@mail.com (R. Patrick Xian, Noah R. Baker, Tom David, Qiming Cui, A. Jay Holmgren, Stefan Bauer, Madhumita Sushil, Reza Abbasi-Asl)</author>
      <guid isPermaLink="false">2502.10374v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Diverse Inference and Verification for Advanced Reasoning</title>
      <link>http://arxiv.org/abs/2502.09955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  165 pages. arXiv admin note: text overlap with arXiv:2001.04383 by  other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种结合多种模型和方法的推理大语言模型的方法，能够有效解决国际数学奥林匹克竞赛组合题、抽象与推理语料库（ARC）难题以及人类最后考试（HLE）问题。&lt;h4&gt;背景&lt;/h4&gt;现有的推理LLM在数学和编码领域取得了显著进步，但在处理像IMO组合题、ARC谜题及HLE这类高级任务时仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过多样化的推断方法来提高上述问题的解答准确度，并探索改进模型泛化能力的技术。&lt;h4&gt;方法&lt;/h4&gt;使用了一种在测试时间结合多个模型和方法的方法，包括自动验证数学和代码问题答案的正确性、对其他类型的问题进行拒绝抽样。另外还应用了最佳N策略来回答HLE问题。&lt;h4&gt;主要发现&lt;/h4&gt;该研究通过测试时模拟、强化学习以及元学习等技术提高了模型的泛化能力，并且在解决ARC难题上超越了人类的表现和o3高计算资源。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法可靠、稳健并且具有可扩展性，为未来的研究提供了有价值的方向，并计划在论文发表后公开源代码以促进复制研究。&lt;h4&gt;翻译&lt;/h4&gt;推理大语言模型（如OpenAI的o1、o3以及DeepSeek R1）在数学和编程方面取得了显著进步，但在解决国际数学奥林匹克竞赛组合题、抽象与推理语料库难题以及人类最后考试问题等高级任务时仍然面临挑战。我们采用了结合多种模型及方法进行推断的方法，在测试时间中利用这种方法来验证答案的正确性，并对其他类型的问题实施拒绝采样技术。通过Lean和代码自动检验IMO和ARC问题的答案，最佳N策略则被用来回答HLE问题。本研究将IMO组合题解题准确率从33.3%提升到了77.8%，提高了HLE问题的解答正确性至37%，并且能够解决80%人类无法完成以及o3高计算资源未能解决的ARC谜题。通过测试时模拟、强化学习及元学习技术的应用，模型泛化能力得到显著提高，并在处理复杂推理任务上表现出色。这项工作可靠、稳健且具备可扩展性，为了促进可重复研究的原则，在论文发表后将会公开源代码供进一步探索使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significantprogress in mathematics and coding, yet find challenging advanced tasks such asInternational Mathematical Olympiad (IMO) combinatorics problems, Abstractionand Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions.We use a diverse inference approach that combines multiple models and methodsat test time. We find that verifying mathematics and code problems, andrejection sampling on other problems is simple and effective. We automaticallyverify correctness of solutions to IMO problems by Lean, and ARC puzzles bycode, and find that best-of-N effectively answers HLE questions. Our approachincreases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%,accuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that948 humans could not and 26.5% of ARC puzzles that o3 high compute does not.Test-time simulations, reinforcement learning, and meta-learning with inferencefeedback improve generalization by adapting agent graph representations andvarying prompts, code, and datasets. Our approach is reliable, robust, andscalable, and in the spirit of reproducible research, we will make it publiclyavailable upon publication.</description>
      <author>example@mail.com (Iddo Drori, Gaston Longhitano, Mao Mao, Seunghwan Hyun, Yuke Zhang, Sungjun Park, Zachary Meeks, Xin-Yu Zhang, Ben Segev, Howard Yong, Nakul Verma, Avi Shporer, Alon Amit, Madeleine Udell)</author>
      <guid isPermaLink="false">2502.09955v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.10392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种高效的多级卷积架构用于3D视觉定位。&lt;h4&gt;背景&lt;/h4&gt;传统的两阶段或基于点的方法难以满足实时推理的需求。受三维物体检测中稀疏全卷积架构成功的启发，作者旨在构建一个新的三维视觉定位框架。&lt;h4&gt;目的&lt;/h4&gt;通过文本指导的剪枝（TGP）和完成基线加法（CBA），高效融合3D场景表示与文本特征，并在保持计算效率的同时避免过度裁减细节几何信息。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的3D视觉定位框架，包括基于文本引导的稀疏化以及通过目标区域补全进行有效融合的方法。这种方法能够在减少计算开销的前提下深度交互三维空间和文本描述的信息。&lt;h4&gt;主要发现&lt;/h4&gt;相比之前的单阶段方法，该方法在推断速度上达到了顶尖水平，并且超过了现有最快的100 FPS；与两阶段方法比较时，准确率也领先。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架不仅实现了实时性要求，在精度方面与其他先进方法相比也有显著提升。源代码可以在指定的GitHub仓库中找到。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种用于3D视觉定位的有效多级卷积架构。传统的两阶段或基于点的方法由于难以满足实时推理的需求而变得不实用。受三维物体检测领域稀疏全卷积架构成功的激励，我们的目标是建立一个跟随这一技术路线的新的3D视觉定位框架。然而，在3D视觉定位任务中，3D场景表示应该与文本特征深度交互，基于稀疏卷积的架构由于大量的体素特征而变得低效。因此，我们提出了基于文本引导的剪枝(TGP)和完成基线加法(CBA)，以通过逐区域裁减和目标补全的方式有效地融合3D场景表示与文本特征。具体来说，TGP迭代地稀疏化了三维场景表示，并且通过交叉注意力机制高效地将体素特征与文本特征相互作用。为了减轻剪枝对精细几何信息的影响，CBA适应性地修复过度裁减的区域，而计算开销可以忽略不计。相比于之前的单阶段方法，我们的方法实现了顶尖的推理速度，比最快的现有方法提高了100 FPS。在精度方面，与两阶段方法相比，即使与其他最先进的方法比较时也表现出领先的准确性，在ScanRefer上的Acc@0.5指标上领先了+1.13，在NR3D和SR3D上分别获得了2.6和3.2的提升。代码可在指定的GitHub仓库中找到（https://github.com/GWxuan/TSP3D）.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose an efficient multi-level convolution architecturefor 3D visual grounding. Conventional methods are difficult to meet therequirements of real-time inference due to the two-stage or point-basedarchitecture. Inspired by the success of multi-level fully sparse convolutionalarchitecture in 3D object detection, we aim to build a new 3D visual groundingframework following this technical route. However, as in 3D visual groundingtask the 3D scene representation should be deeply interacted with textfeatures, sparse convolution-based architecture is inefficient for thisinteraction due to the large amount of voxel features. To this end, we proposetext-guided pruning (TGP) and completion-based addition (CBA) to deeply fuse 3Dscene representation and text features in an efficient way by gradual regionpruning and target completion. Specifically, TGP iteratively sparsifies the 3Dscene representation and thus efficiently interacts the voxel features withtext features by cross-attention. To mitigate the affect of pruning on delicategeometric information, CBA adaptively fixes the over-pruned region by voxelcompletion with negligible computational overhead. Compared with previoussingle-stage methods, our method achieves top inference speed and surpassesprevious fastest method by 100\% FPS. Our method also achieves state-of-the-artaccuracy even compared with two-stage methods, with $+1.13$ lead of Acc@0.5 onScanRefer, and $+2.6$ and $+3.2$ leads on NR3D and SR3D respectively. The codeis available at\href{https://github.com/GWxuan/TSP3D}{https://github.com/GWxuan/TSP3D}.</description>
      <author>example@mail.com (Wenxuan Guo, Xiuwei Xu, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu)</author>
      <guid isPermaLink="false">2502.10392v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Looking around you: external information enhances representations for event sequences</title>
      <link>http://arxiv.org/abs/2502.10205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的表示学习方法，该方法通过聚合多个用户信息来增强特定用户的表示，尤其适用于处理具有多并发事件序列的场景。&lt;h4&gt;背景&lt;/h4&gt;传统的顺序数据模型通常只考虑单个序列的数据，忽略了其他相关序列提供的上下文信息。特别是在金融等外部环境变化迅速的领域，单一序列的信息不足以准确预测。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有表示学习中忽略上下文信息的问题，尤其是在处理多并发事件序列时的情况。&lt;h4&gt;方法&lt;/h4&gt;使用了多种聚合技术，从简单的池化方法到基于可训练注意力的方法（特别是Kernel注意机制），该机制能够突出显示来自其他用户的复杂信息流。这种方法可以建立在现有的编码器之上，并支持其有效的微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在金融交易数据集和下游任务上，Kernel注意力聚合改进了ROC AUC评分，无论是否进行微调；而平均池化也提供了一定程度的性能提升，尽管不如前者显著。&lt;h4&gt;结论&lt;/h4&gt;提出的聚合信息方法有效提升了模型对于多并发事件序列场景的表现能力。特别是Kernel注意机制在多种情况下都展示了比其他简单技术更好的效果。&lt;h4&gt;翻译&lt;/h4&gt;表示学习产生跨不同领域的模型，例如商店购买、客户交易和普通人的行为模式。然而，这些针对顺序数据的模型通常处理单个序列，忽略来自其他相关序列的信息上下文，甚至误导没有最近事件记录用户的预测。我们首次提出了一种方法，该方法通过聚合多个用户表示来增强特定用户的一个表示，适用于多并发事件序列的情景。我们的研究考虑了多样化的聚合方式，从简单的池化技术到可训练的基于注意力的方法（特别是内核注意聚合），这种机制可以强调来自其他用户的更复杂的信息流动。所提出的方法建立在现有的编码器之上，并支持其有效的微调。在考虑的金融交易数据集和下游任务中，内核注意改进了ROC AUC分数，在有无微调的情况下都有效果；而平均池化虽然效果较小但仍具有显著性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning produces models in different domains, such as storepurchases, client transactions, and general people's behaviour. However, suchmodels for sequential data usually process a single sequence, ignoring contextfrom other relevant ones, even in domains with rapidly changing externalenvironments like finance or misguiding the prediction for a user with norecent events.  We are the first to propose a method that aggregates information frommultiple user representations augmenting a specific user one for a scenario ofmultiple co-occurring event sequences. Our study considers diverse aggregationapproaches, ranging from simple pooling techniques to trainable attention-basedapproaches, especially Kernel attention aggregation, that can highlight morecomplex information flow from other users. The proposed method operates atop anexisting encoder and supports its efficient fine-tuning. Across considereddatasets of financial transactions and downstream tasks, Kernel attentionimproves ROC AUC scores, both with and without fine-tuning, while mean poolingyields a smaller but still significant gain.</description>
      <author>example@mail.com (Maria Kovaleva, Petr Sokerin, Sofia Krehova, Alexey Zaytsev)</author>
      <guid isPermaLink="false">2502.10205v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks via Node Feature and Structural Perturbations</title>
      <link>http://arxiv.org/abs/2502.10111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图神经网络解释器COMBINEX，该工具生成针对节点和图分类任务的反事实解释。通过统一的方法优化结构变化和特征扰动，确保预测翻转所需的最小且有效的改变。&lt;h4&gt;背景&lt;/h4&gt;当前技术主要关注边修改，而忽视了节点属性扰动在形成模型预测中的关键作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够平衡对边和节点属性的修改的新方法COMBINEX。&lt;h4&gt;方法&lt;/h4&gt;通过联合优化边缘和节点特征的变化来实现最优解，同时处理连续和离散的节点特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法在现实世界数据集上比现有的基线更有效且稳健。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的解释器COMBINEX，它提供了一个更为全面和有效的反事实解释框架，适用于各种图神经网络架构。&lt;h4&gt;翻译&lt;/h4&gt;反事实解释已成为揭开图神经网络决策过程不透明性的一个强大工具。然而现有的技术主要集中在边缘修改上，常常忽略了节点属性扰动在塑造模型预测中的关键作用。为了弥补这一局限，我们提出了一种新的GNN解释器COMBINEX，它为节点和图形分类任务生成反事实解释。不同于先前的方法仅独立处理结构变化和特征变化，COMBINEX通过联合优化这些修改来最佳平衡边缘和节点属性的变化。这种方法确保了翻转模型预测所需的最小且有效的改变，从而产生了现实而可解释的反事实结果。此外，COMBINEX可以无缝处理连续和离散的节点特性，增强了其在各种数据集和GNN架构中的适用性。对真实世界的数据集和不同GNN架构进行的广泛实验显示了我们方法相对于现有基线的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Counterfactual explanations have emerged as a powerful tool to unveil theopaque decision-making processes of graph neural networks (GNNs). However,existing techniques primarily focus on edge modifications, often overlookingthe crucial role of node feature perturbations in shaping model predictions. Toaddress this limitation, we propose COMBINEX, a novel GNN explainer thatgenerates counterfactual explanations for both node and graph classificationtasks. Unlike prior methods, which treat structural and feature-based changesindependently, COMBINEX optimally balances modifications to edges and nodefeatures by jointly optimizing these perturbations. This unified approachensures minimal yet effective changes required to flip a model's prediction,resulting in realistic and interpretable counterfactuals. Additionally,COMBINEX seamlessly handles both continuous and discrete node features,enhancing its versatility across diverse datasets and GNN architectures.Extensive experiments on real-world datasets and various GNN architecturesdemonstrate the effectiveness and robustness of our approach over existingbaselines.</description>
      <author>example@mail.com (Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei)</author>
      <guid isPermaLink="false">2502.10111v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Camera Bias of Person Re-identification</title>
      <link>http://arxiv.org/abs/2502.10195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实证研究了人员重新识别（ReID）模型中的相机偏差问题，并提出了一种简单有效的特征归一化方法来减少未知领域数据的偏见。&lt;h4&gt;背景&lt;/h4&gt;之前的研究提出了多种处理相机感知的方法，但这些方法主要局限于训练域。在新的、未见过的数据集上测量ReID模型时，发现相机偏置更加明显。&lt;h4&gt;目的&lt;/h4&gt;旨在研究和缓解人员重新识别（ReID）模型中的相机偏差问题，并探索特征归一化作为减轻这种偏差的有效性。&lt;h4&gt;方法&lt;/h4&gt;分析了嵌入向量上的特征规范化在减少相机偏差方面的有效性。此外，还探讨了解决无监督学习中ReID模型相机偏置的简单训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;1. 特征归一化可以有效降低多种详细偏见因素的影响，如图像低级属性和身体角度。2. 在各种模型和基准测试上的广泛适用性验证了其作为人员重新识别（ReID）时简明有效的测试后处理方法的潜力。3. 无监督学习中，即使是在已见过的数据域上，ReID模型仍然高度倾向于相机标签，表明存在显著改进空间。&lt;h4&gt;结论&lt;/h4&gt;通过简单的训练策略对现有无监督算法进行修改可以实现性能的显著提升。这些发现为解决人员重新识别中的相机偏差问题提供了新的视角和方法。&lt;h4&gt;翻译&lt;/h4&gt;我们通过实证研究了人员重识别（ReID）模型中相机偏见的问题，并测量了未见过的数据域上的相机偏差现象，揭示其在数据分布变化时更加突出的现象。作为针对未知领域数据的去偏方法，重新审视了嵌入向量上特征归一化的应用，分析其有效性并展示了它应用于多种细节偏置因素的能力。验证了该方法在不同模型和基准测试中的泛化能力，并指出无监督学习中ReID模型存在相机偏见的风险。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We empirically investigate the camera bias of person re-identification (ReID)models. Previously, camera-aware methods have been proposed to address thisissue, but they are largely confined to training domains of the models. Wemeasure the camera bias of ReID models on unseen domains and reveal that camerabias becomes more pronounced under data distribution shifts. As a debiasingmethod for unseen domain data, we revisit feature normalization on embeddingvectors. While the normalization has been used as a straightforward solution,its underlying causes and broader applicability remain unexplored. We analyzewhy this simple method is effective at reducing bias and show that it can beapplied to detailed bias factors such as low-level image properties and bodyangle. Furthermore, we validate its generalizability across various models andbenchmarks, highlighting its potential as a simple yet effective test-timepostprocessing method for ReID. In addition, we explore the inherent risk ofcamera bias in unsupervised learning of ReID models. The unsupervised modelsremain highly biased towards camera labels even for seen domain data,indicating substantial room for improvement. Based on observations of thenegative impact of camera-biased pseudo labels on training, we suggest simpletraining strategies to mitigate the bias. By applying these strategies toexisting unsupervised learning algorithms, we show that significant performanceimprovements can be achieved with minor modifications.</description>
      <author>example@mail.com (Myungseo Song, Jin-Woo Park, Jong-Seok Lee)</author>
      <guid isPermaLink="false">2502.10195v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>STAR: Spectral Truncation and Rescale for Model Merging</title>
      <link>http://arxiv.org/abs/2502.10339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Spectral Truncation And Rescale (STAR)的方法，用于解决模型合并时任务性能下降的问题。&lt;h4&gt;背景&lt;/h4&gt;模型融合是一种从多个预训练模型中获取多任务模型的有效方式，尽管这种方法高效，但在增加模型数量的过程中会出现不可避免的任务性能下降问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为STAR的技术来减轻“合并冲突”，并保持原始矩阵的核范数。&lt;h4&gt;方法&lt;/h4&gt;通过截断每个模型在相应频谱空间中的小分量，并随后采用自动参数调整方案以保留原始矩阵的核范数。&lt;h4&gt;主要发现&lt;/h4&gt;STAR技术在广泛的NLP任务中进行了多种模型融合案例验证，展示出了良好的效果。STAR能够稳健地处理不同规模的模型合并，并且在合并12个Flan-T5模型时可以超越基线4.2%的表现。&lt;h4&gt;结论&lt;/h4&gt;STAR方法不需要额外的原始训练数据推理，并对超参数选择具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模型融合是从多个预训练模型中获得多任务模型的一种有效方式，无需进一步微调，并且在自然语言处理（NLP）等多个领域获得了关注。尽管高效，但模型合并的关键挑战在于随着模型数量的增加似乎不可避免地导致任务性能下降。本文提出了一种名为Spectral Truncation And Rescale (STAR)的方法，旨在通过截断每个模型在相应频谱空间中的小分量来减轻“合并冲突”，随后采用自动参数调整方案以保留原始矩阵的核范数。STAR不需要额外的原始训练数据推理，并对超参数选择具有鲁棒性。我们通过对各种NLP任务进行了广泛的模型融合案例，展示了STAR的有效性。具体来说，STAR能够稳健地处理不同规模的模型合并，并且在合并12个Flan-T5模型时可以超越基线4.2%的表现。我们的代码可从https://github.com/IBM/STAR获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging is an efficient way of obtaining a multi-task model fromseveral pretrained models without further fine-tuning, and it has gainedattention in various domains, including natural language processing (NLP).Despite the efficiency, a key challenge in model merging is the seeminglyinevitable decrease in task performance as the number of models increases. Inthis paper, we propose $\mathbf{S}$pectral $\mathbf{T}$runcation $\mathbf{A}$nd$\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' bytruncating small components in the respective spectral spaces, which isfollowed by an automatic parameter rescaling scheme to retain the nuclear normof the original matrix. STAR requires no additional inference on originaltraining data and is robust to hyperparamater choice. We demonstrate theeffectiveness of STAR through extensive model merging cases on diverse NLPtasks. Specifically, STAR works robustly across varying model sizes, and canoutperform baselines by 4.2$\%$ when merging 12 models on Flan-T5. Our code ispublicly available at https://github.com/IBM/STAR.</description>
      <author>example@mail.com (Yu-Ang Lee, Ching-Yun Ko, Tejaswini Pedapati, I-Hsin Chung, Mi-Yen Yeh, Pin-Yu Chen)</author>
      <guid isPermaLink="false">2502.10339v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.09931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;提出了TransGUNet框架，结合了注意力跨尺度图神经网络(ACS-GNN)和基于熵驱动特征选择(EFS)的空间注意机制。&lt;h4&gt;背景&lt;/h4&gt;在医学图像分割中，跳跃连接主要用于解决编码器和解码器之间的语义间隙，并整合全局依赖性以理解复杂解剖结构的关系。尽管一些模型提出了使用变压器的跳过连接来包含全局依赖性的方法，但它们通常难以同时捕捉详细的局部特征并且计算复杂度高。&lt;h4&gt;目的&lt;/h4&gt;为了改进医学图像分割中的跳跃连接框架并解决深层学习模型产生无信息特征图的问题，引入了一种结合了注意力跨尺度图神经网络(ACS-GNN)和基于熵驱动特征选择(EFS)的空间注意机制的新方法。&lt;h4&gt;方法&lt;/h4&gt;提出了TransGUNet框架：1. ACS-GNN将跨尺度特征图转换为图形结构并通过节点关注捕捉复杂解剖结构。2. EFS与空间注意力相结合，计算每个通道的熵分数并过滤掉高熵特征图。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合实验和分析，TransGUNet在六种已见数据集和八种未见数据集中达到了优越的分割性能，并且其效率明显高于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;TransGUNet能够有效地增强跨不同模态的域泛化能力，通过利用图神经网络以及可靠的空间注意图确保跳跃连接中的更稳健特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skip connection engineering is primarily employed to address the semantic gapbetween the encoder and decoder, while also integrating global dependencies tounderstand the relationships among complex anatomical structures in medicalimage segmentation. Although several models have proposed transformer-basedapproaches to incorporate global dependencies within skip connections, theyoften face limitations in capturing detailed local features with highcomputational complexity. In contrast, graph neural networks (GNNs) exploitgraph structures to effectively capture local and global features. Leveragingthese properties, we introduce an attentional cross-scale graph neural network(ACS-GNN), which enhances the skip connection framework by convertingcross-scale feature maps into a graph structure and capturing complexanatomical structures through node attention. Additionally, we observed thatdeep learning models often produce uninformative feature maps, which degradesthe quality of spatial attention maps. To address this problem, we integratedentropy-driven feature selection (EFS) with spatial attention, calculating anentropy score for each channel and filtering out high-entropy feature maps. Ourinnovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatialattentio} to effectively enhance domain generalizability across variousmodalities by leveraging GNNs alongside a reliable spatial attention map,ensuring more robust features within the skip connection. Through comprehensiveexperiments and analysis, TransGUNet achieved superior segmentation performanceon six seen and eight unseen datasets, demonstrating significantly higherefficiency compared to previous methods.</description>
      <author>example@mail.com (Ju-Hyeon Nam, Nur Suriza Syazwany, Sang-Chul Lee)</author>
      <guid isPermaLink="false">2502.09931v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning on Out of Distribution in Tabular Data</title>
      <link>http://arxiv.org/abs/2502.10095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了TCL，一种轻量级且有效的解决方案，适用于标准CPU硬件处理开放世界假设下的数据。该方法通过对比学习原则适应表格数据结构，并引入全矩阵增强和简化损失计算。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在处理OOD（非分布）数据方面表现出色，但通常需要专用硬件支持，这限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轻量级解决方案TCL，以便于使用标准CPU硬件高效运行，并且在分类和回归任务中实现高性能。&lt;h4&gt;方法&lt;/h4&gt;采用对比学习原则适应表格数据结构，引入全矩阵增强和简化损失计算的方法来处理OOD问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过10种不同数据集的全面实验表明，TCL在分类任务上优于现有模型（如FT-Transformer和ResNet），同时保持了回归问题中的竞争力。此外，该方法减少了计算需求，使得资源受限用户也能使用。&lt;h4&gt;结论&lt;/h4&gt;TCL提供了一种性能与效率之间的良好平衡，对于处理OOD预测任务非常有益，并且为检测和评估OOD数据提供了实用指导。&lt;h4&gt;翻译&lt;/h4&gt;开放世界假设下的模型开发表明，模型可能缺乏足够的信息来有效应对完全不同的或非分布的数据。虽然深度学习方法通过泛化技术展示了对OOD数据的出色结果，但它们往往需要专用硬件的支持，这并非所有用户都能获得。我们提出了TCL，一种轻量级且高效的解决方案，在标准CPU硬件上运行。我们的方法采用对比学习原则适应表格数据结构，并引入了全矩阵增强和简化损失计算。通过在10种不同数据集上的全面实验，我们展示了TCL优于现有模型（包括FT-Transformer和ResNet），特别是在分类任务中，同时保持回归问题中的竞争性能。TCL以显著减少的计算需求实现了这些结果，使其成为硬件能力有限用户的理想选择。本研究还提供了通过简单实验和可视化来检测和评估OOD数据的实际指导。我们的发现表明，TCL为处理OOD预测任务提供了一种性能与效率之间的良好平衡，这特别有益于面对计算限制的一般机器学习从业者。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The open-world assumption in model development suggests that a model mightlack sufficient information to adequately handle data that is entirely distinctor out of distribution (OOD). While deep learning methods have shown promisingresults in handling OOD data through generalization techniques, they oftenrequire specialized hardware that may not be accessible to all users. Wepresent TCL, a lightweight yet effective solution that operates efficiently onstandard CPU hardware. Our approach adapts contrastive learning principlesspecifically for tabular data structures, incorporating full matrixaugmentation and simplified loss calculation. Through comprehensive experimentsacross 10 diverse datasets, we demonstrate that TCL outperforms existingmodels, including FT-Transformer and ResNet, particularly in classificationtasks, while maintaining competitive performance in regression problems. TCLachieves these results with significantly reduced computational requirements,making it accessible to users with limited hardware capabilities. This studyalso provides practical guidance for detecting and evaluating OOD data throughstraightforward experiments and visualizations. Our findings show that TCLoffers a promising balance between performance and efficiency in handling OODprediction tasks, which is particularly beneficial for general machine learningpractitioners working with computational constraints.</description>
      <author>example@mail.com (Achmad Ginanjar, Xue Li, Priyanka Singh, Wen Hua)</author>
      <guid isPermaLink="false">2502.10095v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++ 是一种改进的深度学习模型，旨在提高TESS 2分钟数据中过渡信号分类的准确性。&lt;h4&gt;背景&lt;/h4&gt;ExoMiner 是一个成功的过渡信号分类器，而 ExoMiner++ 在其基础上引入了更多诊断输入信息以进一步提升性能。&lt;h4&gt;目的&lt;/h4&gt;通过结合来自开普勒太空望远镜的高质量标记数据进行迁移学习，提高在TESS较为嘈杂和模糊标签下的表现，并为系外行星社区提供新的分类目录。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++ 采用了包括周期图、通量趋势、差异图像、未折叠通量以及航天器姿态控制数据在内的额外诊断输入信息。此外，模型利用了开普勒空间望远镜的高质量标签数据进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;在总计147,568个未标记的TESS候选事件（TCE）中，ExoMiner++ 将其中的7330个识别为系外行星候选者。这些候选者中有1,868个是已知的TOI，69个是社区关注的CTOI以及50个新的CTOI。&lt;h4&gt;结论&lt;/h4&gt;通过减少潜在的候选者的数量并提高排名质量，使得后续调查可以更加集中于最有潜力的系外行星候选人上，从而提高了整个系外行星产出效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning</title>
      <link>http://arxiv.org/abs/2502.10038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了一种用于改善POI表示学习的框架，即POI-Enhancer。该框架利用大型语言模型（LLMs）来提升由经典POI学习模型生成的POI表示。&lt;h4&gt;背景&lt;/h4&gt;POI表示学习在处理与用户移动性相关的任务中起着关键作用。现有方法通常只使用POI类别或签到内容等文本信息，导致弱化的文本特征。相比之下，训练于大量文本数据上的大型语言模型具备丰富的文本知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用LLMs知识来增强POI表示学习的方法，并解决从LLMs中提取和整合POI相关知识的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了三个特殊提示以高效地从LLMs中抽取语义信息。使用Dual Feature Alignment模块提升所提取的信息质量，Semantic Feature Fusion模块保持其完整性。通过Cross Attention Fusion模块将高质量信息充分融合进POI表示，并利用多视图对比学习进一步注入人类可理解的语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在三个真实世界数据集上均表现优异，相较于所有基线方法有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的新框架POI-Enhancer展现了利用大型语言模型增强POI表示学习的有效性，并为未来相关研究提供了新的思路和方向。&lt;h4&gt;翻译&lt;/h4&gt;POI表示学习在处理用户移动数据的任务中扮演着关键角色。最近的研究表明，通过多模态信息丰富POI表示可以显著提升任务性能。然而，传统的POI表示通常仅包含POI类别或签到内容等文本信息，导致现有方法中的文本特征相对薄弱。相比之下，大型语言模型（LLMs）训练于大量文本数据上，具备丰富的文本知识。但如何有效利用这些知识来增强POI表示学习，则面临两个主要挑战：一是如何从LLMs中提取POI相关知识；二是如何整合所提取的信息以改进POI表示。为此，我们提出了一种便携式框架POI-Enhancer，它利用大型语言模型来改善经典POI学习模型生成的POI表示。首先设计了三种专门提示，用于高效抽取LLMs中的语义信息。然后通过Dual Feature Alignment模块提升所提取的信息质量，并用Semantic Feature Fusion模块保持其完整性。最后通过Cross Attention Fusion模块将高质量信息充分融合进POI表示中，并利用多视图对比学习注入人类可理解的语义信息。在三个真实世界数据集上的大量实验结果表明，我们的框架表现出了显著效果，相较于所有基线方法均有大幅提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; POI representation learning plays a crucial role in handling tasks related touser mobility data. Recent studies have shown that enriching POIrepresentations with multimodal information can significantly enhance theirtask performance. Previously, the textual information incorporated into POIrepresentations typically involved only POI categories or check-in content,leading to relatively weak textual features in existing methods. In contrast,large language models (LLMs) trained on extensive text data have been found topossess rich textual knowledge. However leveraging such knowledge to enhancePOI representation learning presents two key challenges: first, how to extractPOI-related knowledge from LLMs effectively, and second, how to integrate theextracted information to enhance POI representations. To address thesechallenges, we propose POI-Enhancer, a portable framework that leverages LLMsto improve POI representations produced by classic POI learning models. Wefirst design three specialized prompts to extract semantic information fromLLMs efficiently. Then, the Dual Feature Alignment module enhances the qualityof the extracted information, while the Semantic Feature Fusion modulepreserves its integrity. The Cross Attention Fusion module then fullyadaptively integrates such high-quality information into POI representationsand Multi-View Contrastive Learning further injects human-understandablesemantic information into these representations. Extensive experiments on threereal-world datasets demonstrate the effectiveness of our framework, showingsignificant improvements across all baseline representations.</description>
      <author>example@mail.com (Jiawei Cheng, Jingyuan Wang, Yichuan Zhang, Jiahao Ji, Yuanshao Zhu, Zhibo Zhang, Xiangyu Zhao)</author>
      <guid isPermaLink="false">2502.10038v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating and Improving Graph-based Explanation Methods for Multi-Agent Coordination</title>
      <link>http://arxiv.org/abs/2502.09889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨并描述了现有的图神经网络解释方法在多智能体协调中的适用性，提出了一个注意力熵正则化项以提高现有图形解释器的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络（GNN）被用于机器人和代理人的学习，并取得了显著的成功。这些成功促使研究者探索将现有的GNN解释方法应用于多智能体协同作业的可能性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在调查和描述当前存在的GNN解释方法是否适用于解释多智能体协调问题，并提出一种改进现有图形解释器性能的方法。&lt;h4&gt;方法&lt;/h4&gt;通过分析现有方法在识别对团队行为有重大影响的通信渠道方面的潜力，研究者提出了一个注意力熵正则化项。该正则化项使得基于图注意网络（GAT）的策略更容易被现有的基于图的解释器所理解。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，减少注意力熵可以增加生成的子图与其补集之间的差异性，从而提高现有图形解释器的有效性，并且不会影响任务性能。在三个不同任务和三种团队规模上的评估表明，提出的正则化项能够显著提升解释质量。&lt;h4&gt;结论&lt;/h4&gt;本文证明了现有的GNN解释方法可以在多智能体协调领域发挥重要作用，通过引入注意力熵正则化可以提高这些方法的效能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）由图形学习社区开发，在多机器人和多代理人的学习中被采用并显示出高度有效性。受此成功跨学科合作的启发，我们调查和描述了现有GNN解释方法在解释多智能体协调中的适用性。研究发现这些方法有能力识别对团队行为影响最大的通信渠道。基于初步分析，我们提出了一项注意力熵正则化措施，使基于图注意网络（GAT）的方法更容易被现有的图形解释器理解和使用。从理论上讲，减少注意力熵可以激励代理限制其关注范围在最具有影响力或影响力的代理上，从而减轻解释者面临的挑战。通过三个任务和三种团队规模的评估，一方面提供了对现有解释方法有效性的见解，另一方面也展示了我们的正则化策略能够持续提高解释质量而不会牺牲任务性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs), developed by the graph learning community, havebeen adopted and shown to be highly effective in multi-robot and multi-agentlearning. Inspired by this successful cross-pollination, we investigate andcharacterize the suitability of existing GNN explanation methods for explainingmulti-agent coordination. We find that these methods have the potential toidentify the most-influential communication channels that impact the team'sbehavior. Informed by our initial analyses, we propose an attention entropyregularization term that renders GAT-based policies more amenable to existinggraph-based explainers. Intuitively, minimizing attention entropy incentivizesagents to limit their attention to the most influential or impactful agents,thereby easing the challenge faced by the explainer. We theoretically groundthis intuition by showing that minimizing attention entropy increases thedisparity between the explainer-generated subgraph and its complement.Evaluations across three tasks and three team sizes i) provides insights intothe effectiveness of existing explainers, and ii) demonstrates that ourproposed regularization consistently improves explanation quality withoutsacrificing task performance.</description>
      <author>example@mail.com (Siva Kailas, Shalin Jain, Harish Ravichandar)</author>
      <guid isPermaLink="false">2502.09889v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>http://arxiv.org/abs/2502.10248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Step-Video-T2V，这是一种先进的文本到视频的预训练模型，拥有30B参数的能力，并能够生成长达204帧的视频。&lt;h4&gt;背景&lt;/h4&gt;利用深度压缩变分自编码器（Video-VAE）进行视频生成任务，在保持高质量视频重建的同时实现了16x16空间和8x时间的压缩比率。&lt;h4&gt;目的&lt;/h4&gt;通过设计新的模型和技术，提高文本到视频转换的质量，并减少生成视频中的伪影。&lt;h4&gt;方法&lt;/h4&gt;使用两个双语文本编码器处理英文和中文提示；训练具有3D全注意力机制的DiT以去除输入噪声并转化为潜在帧；应用基于视频的DPO方法（Video-DPO）来改善视觉质量。此外，还详细介绍了培训策略、关键观察结果和见解。&lt;h4&gt;主要发现&lt;/h4&gt;通过新的基准测试Step-Video-T2V-Eval评估模型性能，显示出与开源及商用引擎相比，在文本到视频转换中的卓越表现。&lt;h4&gt;结论&lt;/h4&gt;讨论了基于扩散模型的当前范式的局限性，并提出了未来视频基础模型的发展方向。同时提供了模型和评价标准的访问方式以促进创新。&lt;h4&gt;翻译&lt;/h4&gt;论文介绍了一种名为Step-Video-T2V的前沿技术，能够将文本转换为高质量视频，同时提供详细的训练策略、观察结果以及对未来发展的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained modelwith 30B parameters and the ability to generate videos up to 204 frames inlength. A deep compression Variational Autoencoder, Video-VAE, is designed forvideo generation tasks, achieving 16x16 spatial and 8x temporal compressionratios, while maintaining exceptional video reconstruction quality. Userprompts are encoded using two bilingual text encoders to handle both Englishand Chinese. A DiT with 3D full attention is trained using Flow Matching and isemployed to denoise input noise into latent frames. A video-based DPO approach,Video-DPO, is applied to reduce artifacts and improve the visual quality of thegenerated videos. We also detail our training strategies and share keyobservations and insights. Step-Video-T2V's performance is evaluated on a novelvideo generation benchmark, Step-Video-T2V-Eval, demonstrating itsstate-of-the-art text-to-video quality when compared with both open-source andcommercial engines. Additionally, we discuss the limitations of currentdiffusion-based model paradigm and outline future directions for videofoundation models. We make both Step-Video-T2V and Step-Video-T2V-Evalavailable at https://github.com/stepfun-ai/Step-Video-T2V. The online versioncan be accessed from https://yuewen.cn/videos as well. Our goal is toaccelerate the innovation of video foundation models and empower video contentcreators.</description>
      <author>example@mail.com (Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua Cheng, Na Wang, Qiaohui Chen, Qinglin He, Qiuyan Liang, Quan Sun, Ran Sun, Rui Wang, Shaoliang Pang, Shiliang Yang, Sitong Liu, Siqi Liu, Shuli Gao, Tiancheng Cao, Tianyu Wang, Weipeng Ming, Wenqing He, Xu Zhao, Xuelin Zhang, Xianfang Zeng, Xiaojia Liu, Xuan Yang, Yaqi Dai, Yanbo Yu, Yang Li, Yineng Deng, Yingming Wang, Yilei Wang, Yuanwei Lu, Yu Chen, Yu Luo, Yuchu Luo, Yuhe Yin, Yuheng Feng, Yuxiang Yang, Zecheng Tang, Zekai Zhang, Zidong Yang, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang)</author>
      <guid isPermaLink="false">2502.10248v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.10157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了SessionRec框架，旨在解决传统下一项目预测范式与现实推荐场景之间的不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;传统的下一个项目预测范式在处理实际基于会话的用户交互时存在缺陷。新的范式通过层次序列聚合和会话感知表示学习来减少注意力计算复杂性，并能够隐式建模大量的负面交互。&lt;h4&gt;目的&lt;/h4&gt;开发一个新型的下一会话推荐范式，以更好地捕捉用户的多样性兴趣并通过多项目推荐改善下一会话中的推荐效果。&lt;h4&gt;方法&lt;/h4&gt;引入了基于会话的预测目标和会话内部项目的排序损失来改进模型性能。该框架还展示了类似大语言模型的幂律扩展规律，并且实验验证了其在实际应用中的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;SessionRec能够有效提升生成式序列推荐系统的排名效果，同时保持计算效率并展示良好的扩展性。&lt;h4&gt;结论&lt;/h4&gt;提出的会话感知范式为大规模工业级推荐系统的发展建立了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了SessionRec，这是一种新颖的下一会话预测范式（NSPP），用于生成式的顺序推荐。该框架通过层次序列聚合和会话感知表示学习解决了传统下一个项目预测范式与现实世界推荐场景之间的基本不一致问题，并展示了显著提升模型排名效果的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SessionRec, a novel next-session prediction paradigm (NSPP) forgenerative sequential recommendation, addressing the fundamental misalignmentbetween conventional next-item prediction paradigm (NIPP) and real-worldrecommendation scenarios. Unlike NIPP's item-level autoregressive generationthat contradicts actual session-based user interactions, our frameworkintroduces a session-aware representation learning through hierarchicalsequence aggregation (intra/inter-session), reducing attention computationcomplexity while enabling implicit modeling of massive negative interactions,and a session-based prediction objective that better captures users' diverseinterests through multi-item recommendation in next sessions. Moreover, wefound that incorporating a rank loss for items within the session under thenext session prediction paradigm can significantly improve the rankingeffectiveness of generative sequence recommendation models. We also verifiedthat SessionRec exhibits clear power-law scaling laws similar to those observedin LLMs. Extensive experiments conducted on public datasets and online A/B testin Meituan App demonstrate the effectiveness of SessionRec. The proposedparadigm establishes new foundations for developing industrial-scale generativerecommendation systems through its model-agnostic architecture andcomputational efficiency.</description>
      <author>example@mail.com (Lei Huang, Hao Guo, Linzhi Peng, Long Zhang, Xiaoteng Wang, Daoyuan Wang, Shichao Wang, Jinpeng Wang, Lei Wang, Sheng Chen)</author>
      <guid isPermaLink="false">2502.10157v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Resource Allocation with Multi-task Learning for Wireless Networks</title>
      <link>http://arxiv.org/abs/2502.10027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多任务学习的框架，该框架通过引入路由机制使单个深度神经网络能够解决具有不同维度、目标和约束条件的多种优化问题。&lt;h4&gt;背景&lt;/h4&gt;在无线网络环境中，由于存在多个且相互冲突的目标与限制条件，现有的深度神经网络（DNN）解决方案需要频繁调整或重新训练以适应变化。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入多任务学习框架来提高单个深度神经网络解决多样化优化问题的能力和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于条件计算的多任务学习方法，并设计了一个包含基础深度神经网络（bDNN）与路由深度神经网络（rDNN）两部分的模型，其中rDNN控制哪些节点和层在执行特定任务时被使用。通过这种方式，不同任务可以选择共享或独立使用参数。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够有效解决多种优化问题，并且实验结果表明其优于缺乏路由机制的标准深度神经网络。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于条件计算的多任务学习方法及其架构在处理具有多样化特性的无线网络中的优化问题是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：求解一个优化问题的最佳方案取决于该问题的目标函数、约束条件以及规模。尽管深度神经网络（DNN）已被证明能够有效地解决优化问题，但变化的问题大小或目标要求的调整通常需要对DNN架构进行更改才能保持其有效性，甚至可能需要从头开始重新训练新的DNN模型。鉴于无线网络动态特性涉及多个且多样化的目标及限制条件，本文提出了一种多任务学习（MTL）框架，该框架允许单个DNN同时解决各种不同的优化问题。在此框架下，具有不同维度值、目标和约束的优化问题是作为独立的任务来对待的。为了共同处理这些任务，我们提出了基于条件计算与路由的MTL方法。这个多任务DNN由两部分组成：基础深度神经网络（bDNN）用于提取所有考虑中的优化问题的解决方案；以及路由深度神经网络（rDNN），其管理着bDNN中哪些节点和层在每项任务向前传播时被使用。该架构支持监督学习与非监督学习场景，并且实验结果证明了所提出的MTL方法解决多样化优化问题的有效性。相比之下，没有rDNN机制的标准DNN模型无法达到同等性能水平，从而突显出提议架构的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimal solution to an optimization problem depends on the problem'sobjective function, constraints, and size. While deep neural networks (DNNs)have proven effective in solving optimization problems, changes in theproblem's size, objectives, or constraints often require adjustments to the DNNarchitecture to maintain effectiveness, or even retraining a new DNN fromscratch. Given the dynamic nature of wireless networks, which involve multipleand diverse objectives that can have conflicting requirements and constraints,we propose a multi-task learning (MTL) framework to enable a single DNN tojointly solve a range of diverse optimization problems. In this framework,optimization problems with varying dimensionality values, objectives, andconstraints are treated as distinct tasks. To jointly address these tasks, wepropose a conditional computation-based MTL approach with routing. Themulti-task DNN consists of two components, the base DNN (bDNN), which is thesingle DNN used to extract the solutions for all considered optimizationproblems, and the routing DNN (rDNN), which manages which nodes and layers ofthe bDNN to be used during the forward propagation of each task. The output ofthe rDNN is a binary vector which is multiplied with all bDNN's weights duringthe forward propagation, creating a unique computational path through the bDNNfor each task. This setup allows the tasks to either share parameters or useindependent ones, with the decision controlled by the rDNN. The proposedframework supports both supervised and unsupervised learning scenarios.Numerical results demonstrate the efficiency of the proposed MTL approach insolving diverse optimization problems. In contrast, benchmark DNNs lacking therDNN mechanism were unable to achieve similar levels of performance,highlighting the effectiveness of the proposed architecture.</description>
      <author>example@mail.com (Nikos A. Mitsiou, Pavlos S. Bouzinis, Panagiotis G. Sarigiannidis, George K. Karagiannidis)</author>
      <guid isPermaLink="false">2502.10027v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>IMM-MOT: A Novel 3D Multi-object Tracking Framework with Interacting Multiple Model Filter</title>
      <link>http://arxiv.org/abs/2502.09672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages,5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为IMM-MOT的3D多目标跟踪算法，该算法通过引入交互多重模型滤波器和基于距离的得分增强模块来提高复杂环境下的追踪精度。&lt;h4&gt;背景&lt;/h4&gt;现有的三维多物体跟踪方法通常采用单一运动模型进行物体全程追踪。然而，由于周围环境的变化，物体可能会改变其运动模式，导致现有方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D MOT算法IMM-MOT，通过更准确地捕捉单个目标的复杂运动模式来克服传统方法中单一运动模型跟踪的限制。&lt;h4&gt;方法&lt;/h4&gt;{'交互多重模型滤波器（IMM）': '用于适应不同环境下的物体动态变化，提高追踪精度。', '阻尼窗口机制': '用于管理和优化轨迹生命周期，减少漏检低置信度真目标的发生概率。', '基于距离的得分增强模块': '通过调整检测分数来区分假阳性和真实阳性，从而提升得分过滤器的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;在NuScenes Val数据集上，IMM-MOT算法超越了大多数其他使用3D点云的单一模型方法，在AMOTA指标上达到了73.8%。&lt;h4&gt;结论&lt;/h4&gt;通过引入交互多重模型滤波器、阻尼窗口机制以及基于距离的得分增强模块，IMM-MOT能够更准确地捕捉和追踪复杂环境下的物体运动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Multi-Object Tracking (MOT) provides the trajectories of surroundingobjects, assisting robots or vehicles in smarter path planning and obstacleavoidance. Existing 3D MOT methods based on the Tracking-by-Detection frameworktypically use a single motion model to track an object throughout its entiretracking process. However, objects may change their motion patterns due tovariations in the surrounding environment. In this paper, we introduce theInteracting Multiple Model filter in IMM-MOT, which accurately fits the complexmotion patterns of individual objects, overcoming the limitation ofsingle-model tracking in existing approaches. In addition, we incorporate aDamping Window mechanism into the trajectory lifecycle management, leveragingthe continuous association status of trajectories to control their creation andtermination, reducing the occurrence of overlooked low-confidence true targets.Furthermore, we propose the Distance-Based Score Enhancement module, whichenhances the differentiation between false positives and true positives byadjusting detection scores, thereby improving the effectiveness of the ScoreFilter. On the NuScenes Val dataset, IMM-MOT outperforms most othersingle-modal models using 3D point clouds, achieving an AMOTA of 73.8%. Ourproject is available at https://github.com/Ap01lo/IMM-MOT.</description>
      <author>example@mail.com (Xiaohong Liu, Xulong Zhao, Gang Liu, Zili Wu, Tao Wang, Lei Meng, Yuhan Wang)</author>
      <guid isPermaLink="false">2502.09672v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>KGGen: Extracting Knowledge Graphs from Plain Text with Language Models</title>
      <link>http://arxiv.org/abs/2502.09956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为KGGen的工具包，该工具包使用语言模型从纯文本生成高质量的知识图谱（KG），解决了知识图谱数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的最佳已知知识图谱主要是由人工标注、模式匹配或早期NLP技术提取出来的，自动提取的知识图谱质量存疑。这些方法产生的知识图谱要么资源有限，要么存在质量问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种名为KGGen的工具包，它使用语言模型从纯文本中生成高质量的知识图谱，以解决数据稀缺问题，并提供一个新的基准测试MINE来评估提取器的能力。&lt;h4&gt;方法&lt;/h4&gt;KGGen是一个Python库（pip install kg-gen），可以将相关实体聚类减少提取知识图谱中的稀疏性。同时发布了第一个测试提取器能力的基准测试MINE，用于从纯文本中生成有用的知识图谱。&lt;h4&gt;主要发现&lt;/h4&gt;通过与其他现有提取工具进行基准测试对比，KGGen表现出远超其他工具的能力。&lt;h4&gt;结论&lt;/h4&gt;KGGen提供了一种有效的方法来解决知识图谱数据稀缺的问题，并且可以通过Python库形式方便地获取和使用。&lt;h4&gt;翻译&lt;/h4&gt;最近对构建用于知识图谱（KG）的基础模型的兴趣突显了一个根本性挑战：即知识图谱的数据相对匮乏。最佳已知的知识图谱主要是通过人工标注、模式匹配或早期的NLP技术提取出来的，而由人类生成的知识图谱资源有限；自动提取的知识图谱质量存疑。我们提出了一种文本到KG生成器（KGGen），这是一个使用语言模型从纯文本创建高质量图的方法，并以Python库形式提供给所有人。与KGGen一起发布的还有第一个基准测试MINE，用于评估一个提取器从纯文本中生成有用知识图的能力。我们在现有提取工具上进行了基准测试并展示了其远超其他工具的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent interest in building foundation models for KGs has highlighted afundamental challenge: knowledge-graph data is relatively scarce. Thebest-known KGs are primarily human-labeled, created by pattern-matching, orextracted using early NLP techniques. While human-generated KGs are in shortsupply, automatically extracted KGs are of questionable quality. We present asolution to this data scarcity problem in the form of a text-to-KG generator(KGGen), a package that uses language models to create high-quality graphs fromplaintext. Unlike other KG extractors, KGGen clusters related entities toreduce sparsity in extracted KGs. KGGen is available as a Python library(\texttt{pip install kg-gen}), making it accessible to everyone. Along withKGGen, we release the first benchmark, Measure of of Information in Nodes andEdges (MINE), that tests an extractor's ability to produce a useful KG fromplain text. We benchmark our new tool against existing extractors anddemonstrate far superior performance.</description>
      <author>example@mail.com (Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, Sanmi Koyejo)</author>
      <guid isPermaLink="false">2502.09956v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>NeuralCFD: Deep Learning on High-Fidelity Automotive Aerodynamics Simulations</title>
      <link>http://arxiv.org/abs/2502.09692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近的神经算子学习进展为汽车空气动力学等领域带来了变革性的创新，但要实现工业级应用，仍需解决一些关键挑战。&lt;h4&gt;背景&lt;/h4&gt;当前基于神经网络的仿真代理技术在处理大规模表面和体积网格时面临可扩展性问题，并且需要大量的高保真数值模拟样本进行训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Geometry-preserving Universal Physics Transformer (GP-UPT)的新方法，旨在解决上述挑战并提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;GP-UPT通过分离几何编码和物理预测，确保了对不同几何表示的灵活性和支持独立的表面采样策略。这使得模型的不同部分可以根据实际需求进行扩展。&lt;h4&gt;主要发现&lt;/h4&gt;GP-UPT能够避免生成高质量的仿真网格，同时在2000万个网格单元上准确预测三维速度场，并且从低保真度数据集转移到高保真度数据集时表现出色，仅需不到一半的高保真度数据即可达到与从头训练模型相当的表现。&lt;h4&gt;结论&lt;/h4&gt;GP-UPT提供了一种灵活、可扩展的方法来解决基于神经网络的仿真代理在工业应用中的开放性挑战。&lt;h4&gt;翻译&lt;/h4&gt;最近在神经算子学习领域的进展为汽车空气动力学等领域的变革创新铺平了道路。但是，为了使基于神经网络的模拟替代品能够在工业规模上实施，需要克服几个关键问题。首先，这些替代品必须能够处理大规模表面和体积网格，尤其是在仅使用原始几何输入时（即不依赖于模拟网格）。其次，它们必须在有限数量的高保真数值模拟样本下进行训练，并达到所需性能水平。为此，我们引入了保留几何的通用物理变换器（Geometry-preserving Universal Physics Transformer, GP-UPT），该方法将几何编码和物理预测分离，确保对不同几何表示和支持独立表面采样策略的灵活性。GP-UPT使模型的不同部分可以根据实际需求进行扩展，并提供了针对开放性挑战的可扩展解决方案。此外，GP-UPT规避了高质量仿真网格的创建过程，在20百万个网格单元上实现准确的三维速度场预测，并在从低保真度向高保真度模拟数据集的学习中表现出色，需要少于一半的高保真度数据即可达到与从头训练模型相同的表现水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in neural operator learning are paving the way fortransformative innovations in fields such as automotive aerodynamics. However,key challenges must be overcome before neural network-based simulationsurrogates can be implemented at an industry scale. First, surrogates mustbecome scalable to large surface and volume meshes, especially when using rawgeometry inputs only, i.e., without relying on the simulation mesh. Second,surrogates must be trainable with a limited number of high-fidelity numericalsimulation samples while still reaching the required performance levels. Tothis end, we introduce Geometry-preserving Universal Physics Transformer(GP-UPT), which separates geometry encoding and physics predictions, ensuringflexibility with respect to geometry representations and surface samplingstrategies. GP-UPT enables independent scaling of the respective parts of themodel according to practical requirements, offering scalable solutions to openchallenges. GP-UPT circumvents the creation of high-quality simulation meshes,enables accurate 3D velocity field predictions at 20 million mesh cells, andexcels in transfer learning from low-fidelity to high-fidelity simulationdatasets, requiring less than half of the high-fidelity data to match theperformance of models trained from scratch.</description>
      <author>example@mail.com (Maurits Bleeker, Matthias Dorfer, Tobias Kronlachner, Reinhard Sonnleitner, Benedikt Alkin, Johannes Brandstetter)</author>
      <guid isPermaLink="false">2502.09692v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Neural Topic Models with Variance-Invariance-Covariance Regularization</title>
      <link>http://arxiv.org/abs/2502.09944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint accepted in Springer Knowledge and Information Systems  (KAIS), in press&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合神经主题模型（NTM）和正则化自监督学习方法的自我监督神经主题模型，以提高性能。&lt;h4&gt;背景&lt;/h4&gt;传统的主题模型使用有限的方式从文档中提取隐藏的主题，并且灵活性较低。而神经主题模型利用神经网络来挖掘文本中的潜在主题，提供了更大的灵活性和更好的主题一致性估计能力。同时，一些自监督学习方法通过双塔结构（即两个相同的网络）为同一输入的不同增强版本产生相似的表示，并通过正则化防止这些表征坍塌。&lt;h4&gt;目的&lt;/h4&gt;改进现有模型以提高主题质量并开发新的变体模型。&lt;h4&gt;方法&lt;/h4&gt;引入了基于NTM的新模型，该模型使用显式正则化来限制锚点和积极样本的主题潜在表示。同时，提出了一种对抗性数据增强技术来替代传统的启发式采样策略，并构建了几种对比学习模型以利用正负样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的模型在三个不同数据集上均超越了基线方法和其他最先进的模型，在主题质量和数量指标方面表现更佳。&lt;h4&gt;结论&lt;/h4&gt;该研究通过结合NTM与自监督学习技术来增强潜在表示的约束力，从而有效提升话题的质量。同时开发出基于对比学习的不同变体模型能够进一步改进性能。&lt;h4&gt;翻译&lt;/h4&gt;在我们的研究中，我们提出了一种自我监督神经主题模型（NTM），它结合了NTM和正则化自监督学习方法的力量来提高表现。 NTMs使用神经网络从文档中的单词背后挖掘隐藏的主题，从而使灵活性更高，并且比传统话题模型更好地估计更一致的话题。另一方面，一些自监督学习方法采用双塔架构，即两个相同的网络为同一输入的不同增强版本生成相似表示。通过正则化防止这些表征坍塌（否则会导致所有输入的输出是恒定或冗余表示）。我们的模型通过显式正则化锚点和积极样本的主题潜在表示来提升主题质量。我们还引入了一种对抗性数据增强方法，以取代启发式的采样方法。此外，我们开发了几个变体模型，包括在NTM基础上结合对比学习（使用正负样本）的模型。实验结果表明，在三个数据集上的定量和定性评估中，我们的模型均优于基线和其他最先进模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In our study, we propose a self-supervised neural topic model (NTM) thatcombines the power of NTMs and regularized self-supervised learning methods toimprove performance. NTMs use neural networks to learn latent topics hiddenbehind the words in documents, enabling greater flexibility and the ability toestimate more coherent topics compared to traditional topic models. On theother hand, some self-supervised learning methods use a joint embeddingarchitecture with two identical networks that produce similar representationsfor two augmented versions of the same input. Regularizations are applied tothese representations to prevent collapse, which would otherwise result in thenetworks outputting constant or redundant representations for all inputs. Ourmodel enhances topic quality by explicitly regularizing latent topicrepresentations of anchor and positive samples. We also introduced anadversarial data augmentation method to replace the heuristic sampling method.We further developed several variation models including those on the basis ofan NTM that incorporates contrastive learning with both positive and negativesamples. Experimental results on three datasets showed that our modelsoutperformed baselines and state-of-the-art models both quantitatively andqualitatively.</description>
      <author>example@mail.com (Weiran Xu, Kengo Hirami, Koji Eguchi)</author>
      <guid isPermaLink="false">2502.09944v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding</title>
      <link>http://arxiv.org/abs/2502.09906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态对话模型Insect-LLaVA，旨在提升在昆虫领域的视觉理解和知识。通过构建大规模的多模态昆虫数据集和开发用于捕捉昆虫细微特征的学习机制，该模型能够在视觉昆虫理解任务上取得卓越性能。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态对话模型虽然表现出强大的文本图像数据学习能力，但在专门的视觉昆虫知识方面仍显不足。精确农业中理解昆虫是促进可持续发展的基本问题之一。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有模型在视觉昆虫领域的知识空白，本文提出了Insect-LLaVA模型及其相关技术，旨在提升视觉昆虫的理解和认知。&lt;h4&gt;方法&lt;/h4&gt;首先构建了一个新的大规模多模态昆虫数据集，包含视觉昆虫指令数据。其次开发了具有微特征自监督学习机制的昆虫基础模型，并引入了一种基于Patch-wise Relevant Attention机制来捕捉昆虫图像中的细微差异。&lt;h4&gt;主要发现&lt;/h4&gt;提出的Insect-LLaVA模型在视觉昆虫理解任务上表现出色，在标准基准测试中达到了当前最佳性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的数据集和学习机制，本文成功提升了现有多模态对话模型在处理视觉昆虫知识方面的能力，为未来的研究提供了强有力的方法支持。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal conversational generative AI has demonstrated impressive capabilities in vision and language understanding through massive text-image data learning, but current models lack knowledge about visual insects. In precision agriculture, understanding insects is fundamental to promoting agricultural sustainability. This paper introduces Insect-LLaVA, a novel multimodal conversation model aimed at enhancing insect-domain knowledge visually. It includes a new large-scale dataset for multimodal foundation model learning and an insect feature enhancement mechanism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal conversational generative AI has shown impressive capabilities invarious vision and language understanding through learning massive text-imagedata. However, current conversational models still lack knowledge about visualinsects since they are often trained on the general knowledge ofvision-language data. Meanwhile, understanding insects is a fundamental problemin precision agriculture, helping to promote sustainable development inagriculture. Therefore, this paper proposes a novel multimodal conversationalmodel, Insect-LLaVA, to promote visual understanding in insect-domainknowledge. In particular, we first introduce a new large-scale MultimodalInsect Dataset with Visual Insect Instruction Data that enables the capabilityof learning the multimodal foundation models. Our proposed dataset enablesconversational models to comprehend the visual and semantic features of theinsects. Second, we propose a new Insect-LLaVA model, a new general LargeLanguage and Vision Assistant in Visual Insect Understanding. Then, to enhancethe capability of learning insect features, we develop an Insect FoundationModel by introducing a new micro-feature self-supervised learning with aPatch-wise Relevant Attention mechanism to capture the subtle differences amonginsect images. We also present Description Consistency loss to improvemicro-feature learning via text descriptions. The experimental resultsevaluated on our new Visual Insect Question Answering benchmarks illustrate theeffective performance of our proposed approach in visual insect understandingand achieve State-of-the-Art performance on standard benchmarks ofinsect-related tasks.</description>
      <author>example@mail.com (Thanh-Dat Truong, Hoang-Quan Nguyen, Xuan-Bac Nguyen, Ashley Dowling, Xin Li, Khoa Luu)</author>
      <guid isPermaLink="false">2502.09906v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Probabilistic Lexical Manifold Construction in Large Language Models via Hierarchical Vector Field Interpolation</title>
      <link>http://arxiv.org/abs/2502.10013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的词嵌入技术将单词映射到离散的令牌空间中，这种方法会导致表示上的不连续性。基于转换器的模型虽然有强大的语义捕获能力，但它们生成的嵌入表示仍然可能在某些情况下存在一致性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种层次化的向量场插值方法，通过构建一个具有概率结构的空间来改善词嵌入的一致性和连贯性。&lt;h4&gt;方法&lt;/h4&gt;构建了一个能够保证拓扑一致性的概率函数空间，在该空间中词表示遵循连续的流形分布，而非局限于离散令牌映射。使用发散最小化技术确保插值后的向量保持概率一致性的同时保留计算可行性。&lt;h4&gt;主要发现&lt;/h4&gt;{'改进词汇连贯性': '通过精炼上下文关系，概率约束可以增强词汇的一致性和稳定性', '减少表示不一致和异向性扭曲': '实验表明该方法能够减少语义分布中的非均匀变形，提高嵌入表示的密度对齐。', '更稳定的表征': '与标准转换器模型相比，在需要精细语义区分的任务中结构化插值能提供更加稳定的表现。', '计算效率': '虽然引入了轻微的处理开销，但这种方法对于大规模实施仍然具有可扩展性。'}&lt;h4&gt;结论&lt;/h4&gt;层次化的向量场插值技术通过概率方法解决了传统词嵌入表示中的连续性和一致性问题，并在多种语言分布中提高了语义稳定性。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译为：层次化向量场插值引入了一种结构化的概率框架来实现词汇表征，确保了单词嵌入能够在连续流形上平滑过渡而非受限于离散令牌映射。所提出的方法构建了一个概率函数空间，在此空间中词表示遵循拓扑一致性，减少了基于转换器的嵌入中常见代表不连续性。实证评估表明，通过概率约束增强词汇连贯性，并通过细化上下文关系来改善语义稳定性在多种语言分布中表现更好。利用发散最小化技术确保插值后的嵌入保持概率一致性的同时保留大范围实现中的计算可行性。实验结果表明，插值词流形提高了表示密度对齐度并减少了上下文嵌入分布中的非均匀变形。与基于转换器的标准模型进行对比分析发现，在需要精细语义区分的任务中结构化插值提供了更稳定的表征。统计评价的嵌入发散证明了概率词汇流形减少了一致性问题而保持不同抽象层次上的连贯性。计算效率评估表明，虽然插值得到了额外处理开销，但这种结构化的表示学习方法仍然适用于实际部署中的大规模实施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical vector field interpolation introduces a structured probabilisticframework for lexical representation, ensuring that word embeddings transitionsmoothly across a continuous manifold rather than being constrained to discretetoken mappings. The proposed methodology constructs a probabilistic functionspace where word representations adhere to topological consistency, mitigatingrepresentational discontinuities commonly observed in transformer-basedembeddings. Empirical evaluations reveal that probabilistic constraints enhancelexical coherence by refining contextual relationships, leading to improvementsin semantic stability across multiple linguistic distributions. The applicationof divergence minimization techniques ensures that interpolated embeddingsmaintain probabilistic consistency while preserving computational feasibilityfor large-scale implementations. Experimental findings demonstrate thatinterpolated lexical manifolds improve representation density alignment,reducing anisotropic distortions in contextual embedding distributions.Comparative analyses with standard transformer-based models highlight thatstructured interpolation yields more stable representations, particularly intasks requiring fine-grained semantic differentiation. The statisticalevaluation of embedding divergence confirms that probabilistic lexicalmanifolds reduce representational inconsistencies while maintaining coherenceacross varying scales of contextual abstraction. An assessment of computationalefficiency reveals that while interpolation introduces minor processingoverhead, the structured representation learning approach remains scalable forpractical deployment.</description>
      <author>example@mail.com (Clive Pendleton, Ewan Harrington, Giles Fairbrother, Jasper Arkwright, Nigel Fenwick, Richard Katrix)</author>
      <guid isPermaLink="false">2502.10013v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Meta-INR: Efficient Encoding of Volumetric Data via Meta-Learning Implicit Neural Representation</title>
      <link>http://arxiv.org/abs/2502.09669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by PVIS Short Paper Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;隐式神经表示（INR）作为一种编码体积数据的有前景的方法已经出现，它提供连续性表示并与体渲染流水线无缝兼容。&lt;h4&gt;背景&lt;/h4&gt;优化一个从随机初始化参数开始的新体积的INR网络在计算上是低效的，特别是在处理大型时变或集合体积数据集的情况下，尽管这些数据集中包含共享相似结构模式的数据块但仍然需要独立训练。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种基于元学习算法预训练策略Meta-INR，用于从体积数据集的部分观察中学习初始INR参数。&lt;h4&gt;方法&lt;/h4&gt;通过从部分观察的体积数据集中学习初始参数，使学习到的初始参数作为强大的先验知识来增强INR的泛化能力。当适应新体积时，只需要少数梯度更新就可以显著加快收敛速度，并且在分析自适应INRs的参数时具有更好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;Meta-INR能够有效提取高质量的通用特征，有助于编码不同数据集中未见过的相似体数据。此外，在模拟参数分析和代表性时间步选择等任务中也表现出实用性。&lt;h4&gt;结论&lt;/h4&gt;该策略展示了在处理大规模复杂体积数据集时的有效性和潜力，并通过代码开源来支持研究社区。&lt;h4&gt;翻译&lt;/h4&gt;隐式神经表示（INR）作为一种编码体积数据的有前景的方法已经出现，它提供连续性表示并与体渲染流水线无缝兼容。然而，从随机初始化参数开始优化一个全新的体积的INR网络在计算上是低效的，特别是在处理大型时变或集合体积数据集的情况下，尽管这些数据集中包含共享相似结构模式的数据块但仍然需要独立训练。为了解决上述问题，提出了一种基于元学习算法预训练策略Meta-INR，用于从体积数据集的部分观察中学习初始INR参数。与从零开始训练相比，通过部分观察获得的初始参数提供了一个强大的先验知识，这增强了INR泛化能力，并在适应新体数据时只需要少数梯度更新就能实现显著更快的收敛速度和更好的可解释性。实验结果表明Meta-INR可以提取高质量的通用特征来帮助编码不同数据集中未见过的相似体积数据。此外，在模拟参数分析以及代表性时间步选择等任务中也表现出实用性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit neural representation (INR) has emerged as a promising solution forencoding volumetric data, offering continuous representations and seamlesscompatibility with the volume rendering pipeline. However, optimizing an INRnetwork from randomly initialized parameters for each new volume iscomputationally inefficient, especially for large-scale time-varying orensemble volumetric datasets where volumes share similar structural patternsbut require independent training. To close this gap, we propose Meta-INR, apretraining strategy adapted from meta-learning algorithms to learn initial INRparameters from partial observation of a volumetric dataset. Compared totraining an INR from scratch, the learned initial parameters provide a strongprior that enhances INR generalizability, allowing significantly fasterconvergence with just a few gradient updates when adapting to a new volume andbetter interpretability when analyzing the parameters of the adapted INRs. Wedemonstrate that Meta-INR can effectively extract high-quality generalizablefeatures that help encode unseen similar volume data across diverse datasets.Furthermore, we highlight its utility in tasks such as simulation parameteranalysis and representative timestep selection. The code is available athttps://github.com/spacefarers/MetaINR.</description>
      <author>example@mail.com (Maizhe Yang, Kaiyuan Tang, Chaoli Wang)</author>
      <guid isPermaLink="false">2502.09669v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection</title>
      <link>http://arxiv.org/abs/2502.09271v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PAKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对图神经网络的新攻击策略，通过向系统中注入孤立子图来误导链路推荐器和节点分类器，从而降低节点分类精度。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络在处理具有图形结构的数据方面表现出色，但最近的研究揭示了它们对对抗性攻击的脆弱性。传统方法依赖于操纵原始图或向人工创建的节点添加链接，这些方法在实际环境中往往不切实际。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的对抗性场景，该场景涉及注入孤立子图以欺骗GNN系统中的链路推荐器和节点分类器。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LiSA的框架，利用双代理模型和两级优化来同时满足两个对抗目标：误导链路推荐器向目标受害者节点与子图之间提议链接，并降低节点分类精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提方法在真实世界数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;新的攻击策略通过注入孤立的子图，成功实现了对GNN系统的有效攻击。LiSA框架展示了对抗性场景中同时满足多个目标的能力。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）在处理具有图形结构的数据方面表现出了卓越的能力，然而最近的研究揭示了它们容易受到对抗性攻击的影响。传统的依赖于篡改原始图或向人工节点添加链接的攻击方法，在现实世界的应用中往往显得不切实际。本文介绍了一种新的对抗场景，即通过注入孤立子图来欺骗GNN系统中的链路推荐器和节点分类器。具体而言，该策略误导链路推荐器在目标受害者节点与子图之间提议链接，从而诱导用户建立意外且有害的连接，并降低节点分类精度，进而实现成功的攻击。为了应对这种威胁，我们提出了LiSA框架，它利用双代理模型和两级优化来同时满足两个对抗性目标。广泛的实验表明了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inmodeling data with graph structures, yet recent research reveals theirsusceptibility to adversarial attacks. Traditional attack methodologies, whichrely on manipulating the original graph or adding links to artificially creatednodes, often prove impractical in real-world settings. This paper introduces anovel adversarial scenario involving the injection of an isolated subgraph todeceive both the link recommender and the node classifier within a GNN system.Specifically, the link recommender is mislead to propose links between targetedvictim nodes and the subgraph, encouraging users to unintentionally establishconnections and that would degrade the node classification accuracy, therebyfacilitating a successful attack. To address this, we present the LiSAframework, which employs a dual surrogate model and bi-level optimization tosimultaneously meet two adversarial objectives. Extensive experiments onreal-world datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Wenlun Zhang, Enyan Dai, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.09271v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation</title>
      <link>http://arxiv.org/abs/2502.09268v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了一种新的闭环视觉语言动作（VLA）模型GEVRM，该模型结合了内部模型控制（IMC）原则来增强机器人视觉操作的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;随着具身人工智能的发展，用于通用机器人决策的视觉-语言-行动（VLA）模型取得了显著进展。然而，现有的大多数VLA模型未能考虑到在部署过程中遇到的不可避免的外部干扰。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的闭环VLA方法GEVRM来增强机器人视觉操作的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;GEVRM通过结合IMC原则，在文本引导的视频生成模型中产生高度表达性的未来视觉规划目标，并通过模拟响应评估扰动，这些模拟响应被称为内部嵌入并通过原型对比学习进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GEVRM在标准和受干扰的CALVIN基准测试上均达到最先进的性能，并且在现实中的机器人任务中显示出显著改进。&lt;h4&gt;结论&lt;/h4&gt;新模型通过结合IMC原则能够更准确地跟踪参考输入并有效抵消扰动，从而增强视觉操作的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;随着具身人工智能的发展，用于通用机器人决策的视觉-语言-行动（VLA）模型取得了显著进展。然而，现有的大多数VLA模型未能考虑到在部署过程中遇到的不可避免的外部干扰。这些干扰引入了不可预见的状态信息到VLA中，导致不准确的动作并因此降低了泛化性能。经典的内部模型控制原则表明，一个包含外部输入信号的闭环系统可以精确跟踪参考输入，并有效抵消扰动。我们提出了一种新的闭环VLA方法GEVRM，该方法结合了IMC原则来增强机器人视觉操作的鲁棒性。在GEVRM中，文本引导的视频生成模型能够产生高度表达性的未来视觉规划目标。同时，通过模拟响应评估干扰，并将其称为内部嵌入并通过原型对比学习进行优化。这使模型可以隐式地从外部环境中推断和区分扰动。提出的GEVRM在标准和受干扰的CALVIN基准测试上均达到最先进的性能，并且在现实中的机器人任务中显示出显著改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of embodied artificial intelligence, significantprogress has been made in vision-language-action (VLA) models for general robotdecision-making. However, the majority of existing VLAs fail to account for theinevitable external perturbations encountered during deployment. Theseperturbations introduce unforeseen state information to the VLA, resulting ininaccurate actions and consequently, a significant decline in generalizationperformance. The classic internal model control (IMC) principle demonstratesthat a closed-loop system with an internal model that includes external inputsignals can accurately track the reference input and effectively offset thedisturbance. We propose a novel closed-loop VLA method GEVRM that integratesthe IMC principle to enhance the robustness of robot visual manipulation. Thetext-guided video generation model in GEVRM can generate highly expressivefuture visual planning goals. Simultaneously, we evaluate perturbations bysimulating responses, which are called internal embeddings and optimizedthrough prototype contrastive learning. This allows the model to implicitlyinfer and distinguish perturbations from the external environment. The proposedGEVRM achieves state-of-the-art performance on both standard and perturbedCALVIN benchmarks and shows significant improvements in realistic robot tasks.</description>
      <author>example@mail.com (Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang)</author>
      <guid isPermaLink="false">2502.09268v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond</title>
      <link>http://arxiv.org/abs/2502.09897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了谱学机器学习（SpectraML）的发展，系统地分析了从分子到光谱预测和从光谱推断分子的现代方法。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习和人工智能在化学领域的迅速发展，基于光谱和质谱数据的应用（即谱学机器学习）仍相对较少探索。现代谱学技术产生的高维大数据量亟需超越传统专家工作流程的自动化智能分析。&lt;h4&gt;目的&lt;/h4&gt;提供关于SpectraML的统一综述，追溯机器学习在谱学中的历史演变，并介绍代表性神经网络架构分类，同时指出现有挑战和未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;回顾了从早期模式识别到最新基础模型的进步，总结了代表性的基于图和转换器的方法。还讨论了解决数据质量问题、多模态集成以及计算可扩展性问题的新兴趋势。&lt;h4&gt;主要发现&lt;/h4&gt;提出了合成数据生成、大规模预训练和少量或零样本学习等新方向，旨在促进谱学与人工智能领域的研究进展。&lt;h4&gt;结论&lt;/h4&gt;本综述为研究人员提供了在光谱学和AI交汇处指导进步的道路图。为了推动可重复的研究，还公开了一个包含最近论文及其相应筛选数据集的开源仓库（https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers）。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已全部翻译为中文并总结成上述要点&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advent of machine learning (ML) and artificial intelligence (AI)has catalyzed major transformations in chemistry, yet the application of thesemethods to spectroscopic and spectrometric data, referred to as SpectroscopyMachine Learning (SpectraML), remains relatively underexplored. Modernspectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growingvolume of high-dimensional data, creating a pressing need for automated andintelligent analysis beyond traditional expert-based workflows. In this survey,we provide a unified review of SpectraML, systematically examiningstate-of-the-art approaches for both forward tasks (molecule-to-spectrumprediction) and inverse tasks (spectrum-to-molecule inference). We trace thehistorical evolution of ML in spectroscopy, from early pattern recognition tothe latest foundation models capable of advanced reasoning, and offer ataxonomy of representative neural architectures, including graph-based andtransformer-based methods. Addressing key challenges such as data quality,multimodal integration, and computational scalability, we highlight emergingdirections such as synthetic data generation, large-scale pretraining, and few-or zero-shot learning. To foster reproducible research, we also release anopen-source repository containing recent papers and their corresponding curateddatasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our surveyserves as a roadmap for researchers, guiding progress at the intersection ofspectroscopy and AI.</description>
      <author>example@mail.com (Kehan Guo, Yili Shen, Gisela Abigail Gonzalez-Montiel, Yue Huang, Yujun Zhou, Mihir Surve, Zhichun Guo, Prayel Das, Nitesh V Chawla, Olaf Wiest, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2502.09897v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model</title>
      <link>http://arxiv.org/abs/2502.09947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 workshop Time Series in the Age of Large Models. arXiv  admin note: substantial text overlap with arXiv:2502.09173&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;远程医疗监控数据的时间序列表示学习在揭示患者行为深层次模式方面具有重要价值，特别是在面对精细时间粒度的数据时。&lt;h4&gt;目的&lt;/h4&gt;通过分析患有痴呆症人群的家庭活动记录，研究提出了一种两阶段的自监督学习方法，旨在量化评估参与者的行为模式并识别活动偏见。&lt;h4&gt;方法&lt;/h4&gt;{'第一阶段': '将时间序列活动转换为文本字符串，并用微调过的语言模型进行编码。', '第二阶段': '将时间序列向量双维度化以应用PageRank方法，分析潜在状态转换。'}&lt;h4&gt;主要发现&lt;/h4&gt;这些见解结合诊断数据，旨在支持个性化护理干预措施。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有助于从时间序列活动中提取有价值的患者行为模式，从而为痴呆症患者的日常活动监控和个性化护理提供依据。&lt;h4&gt;翻译&lt;/h4&gt;在对远程医疗监测数据进行分析时，时间序列表示学习对于揭示患者的行为模式具有重要价值。本研究关注了患有痴呆症人群的家庭活动记录，并提出了一种两阶段的自监督学习方法：第一阶段将时间序列活动转化为文本字符串并用微调过的语言模型进行编码；第二阶段则将时间序列向量双维度化，应用PageRank方法分析潜在状态转换，以量化评估参与者的活动模式和识别行为偏见。这些发现结合诊断数据可以支持个性化护理干预措施的实施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the analysis of remote healthcare monitoring data, time seriesrepresentation learning offers substantial value in uncovering deeper patternsof patient behavior, especially given the fine temporal granularity of thedata. In this study, we focus on a dataset of home activity records from peopleliving with Dementia. We propose a two-stage self-supervised learning approach.The first stage involves converting time-series activities into text strings,which are then encoded by a fine-tuned language model. In the second stage,these time-series vectors are bi-dimensionalized for applying PageRank method,to analyze latent state transitions to quantitatively assess participantsbehavioral patterns and identify activity biases. These insights, combined withdiagnostic data, aim to support personalized care interventions.</description>
      <author>example@mail.com (Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott)</author>
      <guid isPermaLink="false">2502.09947v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT System for the DASR Task of the CHiME-8 Challenge</title>
      <link>http://arxiv.org/abs/2502.09859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了为CHiME-8挑战赛的DASR任务1设计的一种多说话人远距离自动语音识别系统。&lt;h4&gt;背景&lt;/h4&gt;该系统处理各种录音条件，包括从晚餐聚会到专业会议以及从两个到八个说话人的场景。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法来改进传统的多人远距离自动语音识别系统的性能。&lt;h4&gt;方法&lt;/h4&gt;{'步骤1': '首先进行说话人定位（Diarization），接着是语音增强处理，最后执行自动语音识别。', '关键改进': [{'EEND-VC': '基于端到端的说话人定位与向量聚类'}, {'多通道说话人数计数': '使用来自EEND-VC的增强嵌入进行计数'}, {'目标说话人的声音活动检测': 'TS-VAD用于提高识别准确率'}], '语音增强': {'创新性麦克风选择规则': '为了更好地从分布式麦克风中选取最相关的麦克风', '波束成形改进': '研究了进一步的提升措施'}, '自动语音识别模型': [{'Whisper和WavLM基础模型': '利用这些模型开发了几种不同的ASR模型'}]}&lt;h4&gt;主要发现&lt;/h4&gt;最强系统在宏观TCP WER上的相对改善达到了63%，并且在NOTSOFAR-1会议评估数据中优于挑战最佳结果。&lt;h4&gt;结论&lt;/h4&gt;该论文展示了如何通过一系列创新性的方法和技术改进多说话人远距离自动语音识别系统的性能，特别是在处理复杂录音环境和多个说话人的场景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a multi-talker distant automatic speechrecognition (DASR) system we designed for the DASR task 1 of the CHiME-8challenge. Our system performs speaker counting, diarization, and ASR. Ithandles various recording conditions, from diner parties to professionalmeetings and from two to eight speakers. We perform diarization first, followedby speech enhancement, and then ASR as the challenge baseline. However, weintroduced several key refinements. First, we derived a powerful speakerdiarization relying on end-to-end speaker diarization with vector clustering(EEND-VC), multi-channel speaker counting using enhanced embeddings fromEEND-VC, and target-speaker voice activity detection (TS-VAD). For speechenhancement, we introduced a novel microphone selection rule to better selectthe most relevant microphones among the distributed microphones andinvestigated improvements to beamforming. Finally, for ASR, we developedseveral models exploiting Whisper and WavLM speech foundation models. Wepresent the results we submitted to the challenge and updated results weobtained afterward. Our strongest system achieves a 63% relative macro tcpWERimprovement over the baseline and outperforms the challenge best results on theNOTSOFAR-1 meeting evaluation data among geometry-independent systems.</description>
      <author>example@mail.com (Naoyuki Kamo, Naohiro Tawara, Atsushi Ando, Takatomo Kano, Hiroshi Sato, Rintaro Ikeshita, Takafumi Moriya, Shota Horiguch, Kohei Matsuura, Atsunori Ogawa, Alexis Plaquet, Takanori Ashihara, Tsubasa Ochiai, Masato Mimura, Marc Delcroix, Tomohiro Nakatani, Taichi Asami, Shoko Araki)</author>
      <guid isPermaLink="false">2502.09859v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Multifidelity Simulation-based Inference for Computationally Expensive Simulators</title>
      <link>http://arxiv.org/abs/2502.08416v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;在科学的多个领域中，随机模型是理解经验观察数据背后机制的重要工具。这些模型可以有不同的细节和精度水平，在研究现象时高保真度（即准确性高）的模型通常更受欢迎。然而，通过基于仿真的推理推断高保真度模型的参数具有挑战性，尤其是在仿真计算成本高昂的情况下。&lt;h4&gt;背景&lt;/h4&gt;在科学研究中，随机模型是理解实验观察数据背后的机制的重要工具。不同精度和细节水平的模型可以用于不同的情况，在许多情况下，更准确的高保真模型更为优选。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的方法——MF-NPE（多保真度神经后验估计），该方法利用低成本低保真模拟来推断在有限计算预算内的高保真仿真的参数。&lt;h4&gt;方法&lt;/h4&gt;通过转移学习，MF-NPE能够在有限的高保真资源下执行神经后验估计，并具备使用主动学习优先处理个别观察的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在一项统计任务（具有解析基础事实）和两项真实世界任务中，与现有方法相比，MF-NPE展示了相当的性能表现，同时需要高达两个数量级较少的高保真模拟次数。&lt;h4&gt;结论&lt;/h4&gt;总体而言，MF-NPE为昂贵计算仿真的高效贝叶斯推理提供了新的机会。&lt;h4&gt;翻译&lt;/h4&gt;在科学多个领域内，随机模型是理解观测数据背后机制的关键工具。这些模型有不同的精度和细节层次，在许多情况下，更高准确性的高保真度模型更为理想。然而，通过基于模拟的推断来估计这种高保真模型参数十分具有挑战性，尤其是在仿真的计算成本高昂时。我们提出了一种新的方法——MF-NPE（多保真神经后验估计），它利用低成本低保真度仿真来进行转移学习，在有限的模拟预算内推断出昂贵的高精度模拟器的参数，并且具备主动学习能力以优先处理个别观测。在具有解析地面事实的一项统计任务以及两项现实世界任务上，MF-NPE展示了与当前方法相当的表现水平，同时需要高达两个数量级更少次数的高保真度仿真。总的来说，MF-NPE为计算昂贵的模拟器上的高效贝叶斯推理提供了新的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Across many domains of science, stochastic models are an essential tool tounderstand the mechanisms underlying empirically observed data. Models can beof different levels of detail and accuracy, with models of high-fidelity (i.e.,high accuracy) to the phenomena under study being often preferable. However,inferring parameters of high-fidelity models via simulation-based inference ischallenging, especially when the simulator is computationally expensive. Weintroduce MF-NPE, a multifidelity approach to neural posterior estimation thatleverages inexpensive low-fidelity simulations to infer parameters ofhigh-fidelity simulators within a limited simulation budget. MF-NPE performsneural posterior estimation with limited high-fidelity resources by virtue oftransfer learning, with the ability to prioritize individual observations usingactive learning. On one statistical task with analytical ground-truth and tworeal-world tasks, MF-NPE shows comparable performance to current approacheswhile requiring up to two orders of magnitude fewer high-fidelity simulations.Overall, MF-NPE opens new opportunities to perform efficient Bayesian inferenceon computationally expensive simulators.</description>
      <author>example@mail.com (Anastasia N. Krouglova, Hayden R. Johnson, Basile Confavreux, Michael Deistler, Pedro J. Gonçalves)</author>
      <guid isPermaLink="false">2502.08416v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning</title>
      <link>http://arxiv.org/abs/2502.09863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型的成功在于它们能够从预训练语料库中隐式地学习结构化的潜在表示。&lt;h4&gt;目的&lt;/h4&gt;研究一类可解的对比自监督算法，这些算法类似于word2vec并且在下游任务中的表现相似。&lt;h4&gt;方法&lt;/h4&gt;提出二次词嵌入模型，并提供针对特定超参数选择下的训练动态以及最终词嵌入的解析解。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型学习正交线性子空间，每次增量地提高嵌入的有效秩直到模型容量饱和。在WikiText上训练后发现顶部子空间表示可解释的概念。&lt;h4&gt;结论&lt;/h4&gt;利用动力学理论预测模型何时何地获得完成类比任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型的成功在于它们能够从预训练语料库中隐式地学习结构化的潜在表示。本文研究了一类可解的对比自监督算法，这些算法类似于word2vec并且在下游任务中的表现相似。论文的主要贡献是提供了针对特定超参数选择下的训练动态以及最终词嵌入的解析解，并揭示了模型如何以增量方式提高嵌入的有效秩直到达到饱和状态。此外，在WikiText上进行实验后发现顶部子空间表示可解释的概念，同时利用动力学理论预测模型何时何地获得完成类比任务的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable success of large language models relies on their ability toimplicitly learn structured latent representations from the pretraining corpus.As a simpler surrogate for representation learning in language modeling, westudy a class of solvable contrastive self-supervised algorithms which we termquadratic word embedding models. These models resemble the word2vec algorithmand perform similarly on downstream tasks. Our main contributions areanalytical solutions for both the training dynamics (under certainhyperparameter choices) and the final word embeddings, given in terms of onlythe corpus statistics. Our solutions reveal that these models learn orthogonallinear subspaces one at a time, each one incrementing the effective rank of theembeddings until model capacity is saturated. Training on WikiText, we findthat the top subspaces represent interpretable concepts. Finally, we use ourdynamical theory to predict how and when models acquire the ability to completeanalogies.</description>
      <author>example@mail.com (Dhruva Karkada, James B. Simon, Yasaman Bahri, Michael R. DeWeese)</author>
      <guid isPermaLink="false">2502.09863v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving Medical Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.09744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE EMBC 2025; 7 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;联邦学习（FL）为机器学习提供了一种去中心化的策略，允许多个设备或服务器在不共享原始数据的情况下协作训练模型，从而保护了数据隐私。这种技术由于其保密性，在学术界和工业界引起了广泛的兴趣，尤其是在医疗领域，因为该领域的数据往往受到严格法规的保护。&lt;h4&gt;背景&lt;/h4&gt;联邦学习因其能够在保持数据私密性的前提下进行高效的数据利用而备受关注，特别是在受监管严格的医学研究中。然而，目前较少有文献探讨将联邦学习应用于基础模型（FMs）的时间序列预测任务中的可能性及其挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探索使用不同联邦学习技术对时间序列基础模型进行微调的可能性，并讨论在各种数据异质性配置下所面临的挑战和权衡。&lt;h4&gt;方法&lt;/h4&gt;研究团队采用了ECG与ICG等医疗领域的时间序列数据，尝试了不同的联邦学习策略来微调基础模型，用于时间序列预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在不同客户端的数据分布条件下，联邦学习对微调基础模型的有效性有显著影响。其优势在于能克服数据限制同时保持隐私保护，但该效果依赖于参与方（客户）之间的数据分布特性。&lt;h4&gt;结论&lt;/h4&gt;研究表明了在时间序列预测任务中使用联邦学习进行基础模型微调的潜力与局限，并指出了应用联邦学习技术时需要注意的数据分布差异等问题。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) provides a decentralized machine learning approach, where multiple devices or servers collaboratively train a model without sharing their raw data, thus enabling data privacy. This approach has gained significant interest in academia and industry due to its privacy-preserving properties, which are particularly valuable in the medical domain where data availability is often protected under strict regulations. A relatively unexplored area is the use of FL to fine-tune Foundation Models (FMs) for time series forecasting, potentially enhancing model efficacy by overcoming data limitation while maintaining privacy. In this paper, we fine-tuned time series FMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data using different FL techniques. We then examined various scenarios and discussed the challenges FL faces under different data heterogeneity configurations. Our empirical results demonstrated that while FL can be effective for fine-tuning FMs on time series forecasting tasks, its benefits depend on the data distribution across clients. We highlighted the trade-offs in applying FL to FM fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) provides a decentralized machine learning approach,where multiple devices or servers collaboratively train a model without sharingtheir raw data, thus enabling data privacy. This approach has gainedsignificant interest in academia and industry due to its privacy-preservingproperties, which are particularly valuable in the medical domain where dataavailability is often protected under strict regulations. A relativelyunexplored area is the use of FL to fine-tune Foundation Models (FMs) for timeseries forecasting, potentially enhancing model efficacy by overcoming datalimitation while maintaining privacy. In this paper, we fine-tuned time seriesFMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data usingdifferent FL techniques. We then examined various scenarios and discussed thechallenges FL faces under different data heterogeneity configurations. Ourempirical results demonstrated that while FL can be effective for fine-tuningFMs on time series forecasting tasks, its benefits depend on the datadistribution across clients. We highlighted the trade-offs in applying FL to FMfine-tuning.</description>
      <author>example@mail.com (Mahad Ali, Curtis Lisle, Patrick W. Moore, Tammer Barkouki, Brian J. Kirkwood, Laura J. Brattain)</author>
      <guid isPermaLink="false">2502.09744v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)</title>
      <link>http://arxiv.org/abs/2502.09376v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文分析了低秩适应（LoRA）的训练动态，并探讨了其损失函数景观，提出了两种场景：理想化的线性化假设成立的‘特殊场景’和更现实但线性化假设不适用的‘一般场景’。&lt;h4&gt;背景&lt;/h4&gt;低秩适应已成为微调大型基础模型的标准方法。然而，人们对LoRA的理论理解仍有限制。&lt;h4&gt;目的&lt;/h4&gt;分析没有限制假设的情况下的LoRA损失函数景观。&lt;h4&gt;方法&lt;/h4&gt;定义了两种不同的情况：一种是理想化设置下线性化论证适用的‘特殊场景’；另一种是在更现实但线性化假设不成立的‘一般场景’。在‘一般场景’中，展示了低秩适应训练可以收敛到具有较低秩和小幅度的全局最小值或高秩且幅度大的不同解。&lt;h4&gt;主要发现&lt;/h4&gt;零初始化以及权重衰减促使了向参数空间中的低秩、小幅度区域的隐式偏好，从而解释了为什么LoRA通常能够找到全局最优解的原因。&lt;h4&gt;结论&lt;/h4&gt;该工作通过分析没有假设的情况下LoRA训练的行为机制，为理解其理论基础提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has become a standard approach for fine-tuninglarge foundation models. However, our theoretical understanding of LoRA remainslimited as prior analyses of LoRA's training dynamics either rely onlinearization arguments or consider highly simplified setups. In this work, weanalyze the LoRA loss landscape without such restrictive assumptions. We definetwo regimes: a ``special regime'', which includes idealized setups wherelinearization arguments hold, and a ``generic regime'' representing morerealistic setups where linearization arguments do not hold. In the genericregime, we show that LoRA training converges to a global minimizer with lowrank and small magnitude, or a qualitatively distinct solution with high rankand large magnitude. Finally, we argue that the zero-initialization and weightdecay in LoRA training induce an implicit bias toward the low-rank,small-magnitude region of the parameter space -- where global minima lie --thus shedding light on why LoRA training usually succeeds in finding globalminima.</description>
      <author>example@mail.com (Junsu Kim, Jaeyeon Kim, Ernest K. Ryu)</author>
      <guid isPermaLink="false">2502.09376v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence</title>
      <link>http://arxiv.org/abs/2502.09815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统计一致性对齐的方法，通过张量场收敛来强制结构化的标记表示，并建立了量化一致性的数学框架。实验表明这种方法在提高困惑度、增强分类准确性和优化罕见词嵌入方面有效。&lt;h4&gt;背景&lt;/h4&gt;表示学习在构建语言的内部嵌入以捕捉统计数据特性中起着关键作用，影响生成文本的一致性和上下文连贯性。&lt;h4&gt;目的&lt;/h4&gt;引入统计一致性对齐方法来指导嵌入体反映语言数据中的固有统计依赖关系，优化整个训练过程中表示一致性的损失函数。&lt;h4&gt;方法&lt;/h4&gt;建立了一种量化一致性的数学框架，并通过实验评估了应用此约束后性能的改善情况。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提高了困惑度和分类准确性，改进了罕见词嵌入，使表示空间更加稳定。同时，它还避免了表征崩溃的问题，保持上下文依赖性。&lt;h4&gt;结论&lt;/h4&gt;统计一致性对齐增强了语义完整性，在需要更高上下文保真的应用中证明了其有效性，并提供了关于如何利用统计依存关系改进语言模型训练的见解。&lt;h4&gt;翻译&lt;/h4&gt;代表学习在构造内部嵌入以捕捉语言统计数据特性方面扮演着核心角色，这对生成文本的一致性和连贯性有影响。引入了一种通过张量场收敛来强制结构化标记表示的方法——统计一致性对齐，指导嵌入体反映语言数据中的固有统计依赖关系。建立了量化一致性的数学框架，并采用一种损失函数在训练迭代过程中优化表示一致性。实验证明应用这种约束可以改善困惑度和分类准确性，改进罕见词的嵌入体，从而提供一个更稳定的表征空间。与基准模型相比分析显示该方法促进了可解释性结构内部结构的发展，保证了上下文依赖性的保持并减轻了表示崩溃的风险。影响一致性得分分布的因素表明对齐机制增强了语义完整性，因此学习到的嵌入得到了更好的组织。计算评估表明尽管这种方法会增加额外的记忆和训练成本，但有结构化的优化流程来支持这种权衡，在需要更高上下文保真的应用中尤为如此。实验结果验证了统计一致性在最优化标记表示方面的有效性，并提供了关于如何利用统计数据依赖关系改进语言模型训练的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning plays a central role in structuring internalembeddings to capture the statistical properties of language, influencing thecoherence and contextual consistency of generated text. Statistical CoherenceAlignment is introduced as a method to enforce structured token representationsthrough tensor field convergence, guiding embeddings to reflect statisticaldependencies inherent in linguistic data. A mathematical framework isestablished to quantify coherence alignment, integrating a loss function thatoptimizes representational consistency across training iterations. Empiricalevaluations demonstrate that applying coherence constraints improvesperplexity, enhances classification accuracy, and refines rare word embeddings,contributing to a more stable representation space. Comparative analyses withbaseline models reveal that the proposed method fosters a more interpretableinternal structure, ensuring that embeddings retain contextual dependencieswhile mitigating representation collapse. The impact on coherence scoredistributions suggests that the alignment mechanism strengthens semanticintegrity across diverse linguistic constructs, leading to a more balancedorganization of learned embeddings. Computational assessments indicate thatwhile the method introduces additional memory and training costs, thestructured optimization process justifies the trade-offs in applicationsrequiring heightened contextual fidelity. Experimental results validate theeffectiveness of coherence alignment in optimizing token representations,providing insights into how statistical dependencies can be leveraged toimprove language model training.</description>
      <author>example@mail.com (Jonathan Gale, Godfrey Aldington, Harriet Thistlewood, Thomas Tattershall, Basil Wentworth, Vincent Enoasmo)</author>
      <guid isPermaLink="false">2502.09815v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin</title>
      <link>http://arxiv.org/abs/2502.04794v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MedMimic是一种多模态框架，用于诊断发热原因不明（FUO）疾病。该系统结合了预训练的视觉模型和临床数据来提高疾病的分类效果。&lt;h4&gt;背景&lt;/h4&gt;发热原因不明（FUO）是一个重要的医疗挑战，需要有效的诊断工具。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于多模态融合的框架，利用医学图像和临床信息，以改进对FUO疾病类型的分类准确性。&lt;h4&gt;方法&lt;/h4&gt;采用预训练模型如DINOv2、Vision Transformer和ResNet-18等将高维的18F-FDG PET/CT影像转换为低维且具有语义意义的特征，并通过一个可学习的自注意力融合网络整合这些影像数据与临床信息。&lt;h4&gt;主要发现&lt;/h4&gt;在四川大学华西医院2017年至2023年的416例FUO患者病例中，多模态融合分类网络MFCN实现了宏AUROC评分介于0.8654到0.9291之间，在七项任务中均优于传统机器学习和单一模式深度学习方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合大型预训练模型与深度学习的优势，MedMimic为疾病分类提供了一个有前景的解决方案，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;发热原因不明（FUO）一直是诊断上的挑战。 MedMimic作为一种受现实世界诊断过程启发的多模态框架被提出。它利用预训练模型如DINOv2、Vision Transformer和ResNet-18将高维的18F-FDG PET/CT成像转化为低维且具有语义意义的特征。然后，一个基于可学习自注意力机制的融合网络将这些影像特征与临床数据结合进行分类。在四川大学华西医院从2017年到2023年的416例FUO病例中，多模态融合分类网络（MFCN）实现了宏AUROC评分介于0.8654到0.9291之间，显著优于传统的机器学习和单模深度学习方法。通过删除实验以及五折交叉验证进一步证实了其有效性。结合大型预训练模型与深度学习的优势，MedMimic为疾病分类提供了一个有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fever of unknown origin FUO remains a diagnostic challenge. MedMimic isintroduced as a multimodal framework inspired by real-world diagnosticprocesses. It uses pretrained models such as DINOv2, Vision Transformer, andResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging intolow-dimensional, semantically meaningful features. A learnableself-attention-based fusion network then integrates these imaging features withclinical data for classification. Using 416 FUO patient cases from SichuanUniversity West China Hospital from 2017 to 2023, the multimodal fusionclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to0.9291 across seven tasks, outperforming conventional machine learning andsingle-modality deep learning methods. Ablation studies and five-foldcross-validation further validated its effectiveness. By combining thestrengths of pretrained large models and deep learning, MedMimic offers apromising solution for disease classification.</description>
      <author>example@mail.com (Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo)</author>
      <guid isPermaLink="false">2502.04794v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Graph Foundation Models for Recommendation: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2502.08346v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了基于图基础模型（GFMs）的推荐系统技术，介绍了当前方法的分类、详细方法论以及面临的挑战和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在在线信息导航中扮演关键角色，并通过深度学习的进步不断改进排名准确性。尤其是图神经网络（GNNs）擅长提取高级结构信息，而大型语言模型（LLMs）则专注于处理自然语言的理解，两者都因其高效性而在行业中广泛采用。&lt;h4&gt;目的&lt;/h4&gt;综述基于GFMs的推荐系统技术，提供该领域的方法分类、方法论细节以及关键挑战和未来研究方向的概述。&lt;h4&gt;方法&lt;/h4&gt;论文采用了文献回顾的方法，对当前使用图基础模型（GFMs）解决复杂推荐系统的各种方法进行了详细的分析。&lt;h4&gt;主要发现&lt;/h4&gt;最近的研究集中在整合GNNs和LLMs优点的GFMs上，这些模型能够更有效地处理用户-物品关系的图形结构以及文本理解。&lt;h4&gt;结论&lt;/h4&gt;综述通过综合最近的发展，提供了基于GFMs的推荐系统领域的重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) serve as a fundamental tool for navigating the vastexpanse of online information, with deep learning advancements playing anincreasingly important role in improving ranking accuracy. Among these, graphneural networks (GNNs) excel at extracting higher-order structural information,while large language models (LLMs) are designed to process and comprehendnatural language, making both approaches highly effective and widely adopted.Recent research has focused on graph foundation models (GFMs), which integratethe strengths of GNNs and LLMs to model complex RS problems more efficiently byleveraging the graph-based structure of user-item relationships alongsidetextual understanding. In this survey, we provide a comprehensive overview ofGFM-based RS technologies by introducing a clear taxonomy of currentapproaches, diving into methodological details, and highlighting key challengesand future directions. By synthesizing recent advancements, we aim to offervaluable insights into the evolving landscape of GFM-based recommender systems.</description>
      <author>example@mail.com (Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi)</author>
      <guid isPermaLink="false">2502.08346v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping</title>
      <link>http://arxiv.org/abs/2502.08054v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 11 figures, https://combo-grasp.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文解决了机器人抓取中物体被遮挡的问题，即由于环境约束如表面碰撞导致所需的抓取姿态在运动学上不可行的情况下的抓取。传统机器人操作方法难以处理在这种情况下人类常用的非握持或双臂策略的复杂性。最先进的强化学习（RL）方法由于任务本身固有的复杂性而不适合使用。而基于演示的学习需要收集大量的专家演示，这通常是不切实际的。因此，本文借鉴了人类在双手协调以稳定和重新定向物体时采用的方法，专注于一个双臂机器人设置来解决这个问题。具体来说，我们引入了一种基于约束的手动操作方法（COMBO-Grasp），这是一种学习驱动的方法，利用两个协同策略：一种是使用自监督数据集训练的约束策略生成稳定的姿态；另一种是通过强化学习训练的抓取策略重新定向和抓住目标物体。关键贡献在于价值函数引导下的策略协调。具体来说，在对抓取策略进行RL训练时，通过对联合训练的价值函数的梯度优化来精炼约束策略的输出，从而提高双臂协同操作的能力并提升任务性能。最后，COMBO-Grasp使用了教师-学生策略蒸馏方法将点云基策略有效部署到现实环境中。实证研究表明，与竞争基准方法相比，COMBO-Grasp在模拟和真实环境下的未见物体上显著提高了任务成功率。&lt;h4&gt;背景&lt;/h4&gt;机器人在处理遮挡抓取问题时面临挑战，传统的机器人操作方法无法有效解决这种复杂性的问题，同时最先进的强化学习方法也因为任务的固有复杂性而不适用。基于演示的学习策略难以获取足够的专家数据进行训练。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以模仿人类双臂协作技巧来处理遮挡抓取问题的方法，并验证其在模拟和真实环境中的性能。&lt;h4&gt;方法&lt;/h4&gt;{'COMBO-Grasp': '提出了一种学习驱动的解决方案，该方案利用两个协同策略：一个负责稳定物体姿态，另一个负责重新定向并抓取目标。这种方法通过价值函数引导下的策略协调来改进双臂协同操作的能力，并采用教师-学生策略蒸馏将点云基策略有效部署到现实环境中。', '关键创新': '在对抓取策略进行强化学习训练时，通过对联合训练的价值函数的梯度优化来精炼约束策略的输出'}&lt;h4&gt;主要发现&lt;/h4&gt;COMBO-Grasp方法相比传统方法和其它基准方法，在处理遮挡物体上的任务成功率显著提高。&lt;h4&gt;结论&lt;/h4&gt;通过模仿人类双臂协调技巧并采用价值函数引导下的策略协同，COMBO-Grasp能有效地解决被遮挡环境中的机器人抓取问题，并且在模拟与真实环境中均表现出良好的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of occluded robot grasping, i.e. graspingin situations where the desired grasp poses are kinematically infeasible due toenvironmental constraints such as surface collisions. Traditional robotmanipulation approaches struggle with the complexity of non-prehensile orbimanual strategies commonly used by humans in these circumstances.State-of-the-art reinforcement learning (RL) methods are unsuitable due to theinherent complexity of the task. In contrast, learning from demonstrationrequires collecting a significant number of expert demonstrations, which isoften infeasible. Instead, inspired by human bimanual manipulation strategies,where two hands coordinate to stabilise and reorient objects, we focus on abimanual robotic setup to tackle this challenge. In particular, we introduceConstraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), alearning-based approach which leverages two coordinated policies: a constraintpolicy trained using self-supervised datasets to generate stabilising poses anda grasping policy trained using RL that reorients and grasps the target object.A key contribution lies in value function-guided policy coordination.Specifically, during RL training for the grasping policy, the constraintpolicy's output is refined through gradients from a jointly trained valuefunction, improving bimanual coordination and task performance. Lastly,COMBO-Grasp employs teacher-student policy distillation to effectively deploypoint cloud-based policies in real-world environments. Empirical evaluationsdemonstrate that COMBO-Grasp significantly improves task success rates comparedto competitive baseline approaches, with successful generalisation to unseenobjects in both simulated and real-world environments.</description>
      <author>example@mail.com (Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner)</author>
      <guid isPermaLink="false">2502.08054v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>GraphCompNet: A Position-Aware Model for Predicting and Compensating Shape Deviations in 3D Printing</title>
      <link>http://arxiv.org/abs/2502.09652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于数据驱动的算法，用于建模和补偿增材制造中的形状偏差。该方法利用图神经网络与生成对抗网络相结合的方法来提高复杂几何结构的精度。&lt;h4&gt;背景&lt;/h4&gt;传统分析模型及测量技术在提升增材制造的几何精度方面存在局限性，尤其不适用于大规模生产；机器学习的进步改善了补偿精确度，但无法很好地处理复杂的几何形状和位置依赖的变化。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的数据驱动算法，以提高增材制造过程中的几何精度并适应于大规模生产需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为GraphCompNet的计算框架，该框架结合了基于图的神经网络以及生成对抗网络(GAN)启发式的训练流程。通过使用点云数据和动态图卷积神经网络(DGCNN)，GraphCompNet能够处理复杂形状并融入位置特定的热力学与机械因素。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，所提出的方法能显著提高补偿精度(35至65个百分点)且适应于打印空间内的位置依赖变化。此方法推进了增材制造中的数字孪生技术的发展，并能够实现大规模、实时监控和优化。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发高精度、自动化的工业规模设计与制造系统提供了支持，有助于解决当前增材制造过程控制中存在的关键问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a data-driven algorithm for modeling and compensatingshape deviations in additive manufacturing (AM), addressing challenges ingeometric accuracy and batch production. While traditional methods, such asanalytical models and metrology, laid the groundwork for geometric precision,they are often impractical for large-scale production. Recent advancements inmachine learning (ML) have improved compensation precision, but issues remainin generalizing across complex geometries and adapting to position-dependentvariations. We present a novel approach for powder bed fusion (PBF) processes,using GraphCompNet, which is a computational framework combining graph-basedneural networks with a generative adversarial network (GAN)-inspired trainingprocess. By leveraging point cloud data and dynamic graph convolutional neuralnetworks (DGCNNs), GraphCompNet models complex shapes and incorporatesposition-specific thermal and mechanical factors. A two-stage adversarialtraining procedure iteratively refines compensated designs via acompensator-predictor architecture, offering real-time feedback andoptimization. Experimental validation across diverse shapes and positions showsthe framework significantly improves compensation accuracy (35 to 65 percent)across the entire print space, adapting to position-dependent variations. Thiswork advances the development of Digital Twin technology for AM, enablingscalable, real-time monitoring and compensation, and addressing critical gapsin AM process control. The proposed method supports high-precision, automatedindustrial-scale design and manufacturing systems.</description>
      <author>example@mail.com (Lei, Chen, Juheon Lee, Juan Carlos Catana, Tsegai Yhdego, Nathan Moroney, Mohammad Amin Nabian, Hui Wang, Jun Zeng)</author>
      <guid isPermaLink="false">2502.09652v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>The Science of Evaluating Foundation Models</title>
      <link>http://arxiv.org/abs/2502.09670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大模型的评估面临诸多挑战，现有文献未能提供全面且一致的过程。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在自然语言处理领域带来了革命性的变化，但其规模、能力以及跨应用场景部署使得它们的评估变得复杂。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在解决大型语言模型（LLM）评估中的三个关键方面：正式化评估过程、提供实用工具和框架、综述最近的工作进展。&lt;h4&gt;方法&lt;/h4&gt;(1) 提供适用于具体使用场景上下文的结构化评估框架；(2) 开发清单和模板等操作性工具，确保评估的全面性和可重复性；(3) 针对LLM评估领域的最新进展进行有针对性的回顾，强调实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过提供定制化的评估流程和实用工具，可以更加系统地应对大型模型多样性的挑战，并考虑伦理和社会影响因素。&lt;h4&gt;结论&lt;/h4&gt;现有的评估方法需要改进以涵盖更广泛的使用场景并综合考量道德与运营问题。本研究提供的框架可为未来的研究者和实践者提供指导。&lt;h4&gt;翻译&lt;/h4&gt;大规模基础模型在自然语言处理领域引发了一系列新现象，但这些模型的复杂性及其广泛应用使得对其进行有效评估变得颇具挑战性。现有的学术文献通常关注于特定方面，比如基准性能或具体任务，而缺乏一个整合多样化使用场景并考虑更广泛伦理和操作问题的综合过程。本文重点关注三大关键领域：正式化评估流程、提供实用工具与框架以及综述近期相关工作进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergent phenomena of large foundation models have revolutionized naturallanguage processing. However, evaluating these models presents significantchallenges due to their size, capabilities, and deployment across diverseapplications. Existing literature often focuses on individual aspects, such asbenchmark performance or specific tasks, but fails to provide a cohesiveprocess that integrates the nuances of diverse use cases with broader ethicaland operational considerations. This work focuses on three key aspects: (1)Formalizing the Evaluation Process by providing a structured framework tailoredto specific use-case contexts, (2) Offering Actionable Tools and Frameworkssuch as checklists and templates to ensure thorough, reproducible, andpractical evaluations, and (3) Surveying Recent Work with a targeted review ofadvancements in LLM evaluation, emphasizing real-world applications.</description>
      <author>example@mail.com (Jiayi Yuan, Jiamu Zhang, Andrew Wen, Xia Hu)</author>
      <guid isPermaLink="false">2502.09670v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks</title>
      <link>http://arxiv.org/abs/2502.06153v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种低张量秩适应（LoTRA）技术，用于Kolmogorov-Arnold网络（KANs）的微调和参数更新。该方法基于张量分解理论，并通过实验证明了在解决偏微分方程和其他科学任务时的有效性。&lt;h4&gt;背景&lt;/h4&gt;KANs已经在多个领域展示出作为多层感知器（MLPs）替代方案的潜力，特别是在与科学相关的任务中。然而，对于KANs的迁移学习仍然是一个相对未探索的领域。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的适应方法LoTRA以改进KANs在迁移学习中的性能，并通过张量分解理论分析其表达能力。&lt;h4&gt;方法&lt;/h4&gt;基于Tucker张量分解和KAN参数更新的低张量秩结构，提出了洛特拉（LoTRA）技术。此外，还提供了一种选择合适的学习率来实现高效训练的方法论分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证明了所提出的适应性学习速率策略的有效性和对于迁移学习中使用KANs求解偏微分方程的效率提升。研究还表明，在函数表示和图像分类任务中，通过低张量秩分解可以减少参数数量而不损失性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为KANs的迁移学习提供了一种新的有效技术，并展示了降低模型大小以保持高性能的能力。&lt;h4&gt;翻译&lt;/h4&gt;Kolmogorov-Arnold网络（KAN）已经在不同领域中展示出了作为多层感知器（MLPs）替代方案的巨大潜力，特别是在科学相关的任务上。然而，对于KANs的迁移学习仍然是一个相对未探索的研究领域。本文受张量分解启发，并结合了KAN参数更新低张量秩结构的相关证据，开发了一种名为“Low Tensor Rank Adaptation” (LoTRA) 的技术用于KAN的微调。我们基于Tucker分解近似值研究了LoTRA的表现力，并提供了一个理论分析来选择每个LoTRA组件的学习率以实现高效训练。研究表明使用相同的跨所有组件的学习速率会导致训练效率低下，强调需要采用自适应学习速率策略。除了理论见解外，本文还探索了将LoTRA应用于通过微调KANs有效解决各种偏微分方程（PDE）的方法。此外，我们提出了一种“Slim KAN”，它利用了KAN参数张量的内在低张量秩属性以减少模型大小同时保持性能优越。实验结果验证了所提出的适应性学习率选择策略的有效性和使用LoTRA进行KAN迁移学习求解偏微分方程的有效性。此外，在函数表示和图像分类任务中的进一步评估凸显了LoTRA的表现力以及通过低张量秩分解实现参数减少的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov--Arnold networks (KANs) have demonstrated their potential as analternative to multi-layer perceptions (MLPs) in various domains, especiallyfor science-related tasks. However, transfer learning of KANs remains arelatively unexplored area. In this paper, inspired by Tucker decomposition oftensors and evidence on the low tensor-rank structure in KAN parameter updates,we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We studythe expressiveness of LoTRA based on Tucker decomposition approximations.Furthermore, we provide a theoretical analysis to select the learning rates foreach LoTRA component to enable efficient training. Our analysis also shows thatusing identical learning rates across all components leads to inefficienttraining, highlighting the need for an adaptive learning rate strategy. Beyondtheoretical insights, we explore the application of LoTRA for efficientlysolving various partial differential equations (PDEs) by fine-tuning KANs.Additionally, we propose Slim KANs that incorporate the inherentlow-tensor-rank properties of KAN parameter tensors to reduce model size whilemaintaining superior performance. Experimental results validate the efficacy ofthe proposed learning rate selection strategy and demonstrate the effectivenessof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations onSlim KANs for function representation and image classification tasks highlightthe expressiveness of LoTRA and the potential for parameter reduction throughlow tensor-rank decomposition.</description>
      <author>example@mail.com (Yihang Gao, Michael K. Ng, Vincent Y. F. Tan)</author>
      <guid isPermaLink="false">2502.06153v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning for cell stage classification of animal embryos</title>
      <link>http://arxiv.org/abs/2502.07360v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视频显微镜技术和机器学习结合为研究体外产生的胚胎早期发育提供了有前景的方法。但手动注释发育事件，尤其是细胞分裂过程非常耗时且难以扩展。&lt;h4&gt;背景&lt;/h4&gt;现有的手动生成的生物学家对胚胎发育阶段的手动标注在时间和效率上存在局限性，特别是在处理大量数据集和低质量图像的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动分类胚胎从2D时间推移显微镜视频中细胞阶段的方法，使用深度学习技术，针对牛胚胎发育进行分析，并创建了一个新的Bovine Embryos Cell Stages (ECS) 数据集。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的方法CLEmbryo，该方法结合监督对比学习和焦点损失训练，同时采用轻量级的3D神经网络CSN-50作为编码器。这种方法能够处理图像质量低、牛细胞暗化问题以及发育阶段边界的类别模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;CLEmbryo在Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中都优于现有的最先进的方法，表明其具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了自动分类牛胚胎细胞阶段的有效性，并为其他生物医学应用中的相似问题提供了可能解决方案。&lt;h4&gt;挑战&lt;/h4&gt;该研究面临三个主要挑战：图像质量差及暗色的牛细胞导致识别细胞阶段困难；发育阶段边界处类别模糊；数据分布不平衡。&lt;h4&gt;翻译&lt;/h4&gt;视频显微镜技术与机器学习结合为体外产生的胚胎早期发育的研究提供了一种有前景的方法。然而，手动标注生物学家的发育事件（尤其是细胞分裂）在时间和效率上都难以承受且无法扩展至实际应用中。我们旨在使用深度学习方法自动分类2D时间推移显微镜视频中的胚胎细胞阶段，并专注于牛胚胎发育分析的应用，因为我们主要关注畜牧业领域并创建了一个Bovine Embryos Cell Stages (ECS) 数据集。挑战包括：1. 低质量图像和暗色的牛细胞使得难以识别细胞阶段；2. 发育阶段边界处类别模糊性；3. 数据分布不平衡。为解决这些问题，我们提出了一种新的方法CLEmbryo，它结合了监督对比学习与焦点损失训练，并采用轻量级的3D神经网络CSN-50作为编码器。我们的方法表现出良好的泛化能力，在Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中均优于现有的最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video microscopy, when combined with machine learning, offers a promisingapproach for studying the early development of in vitro produced (IVP) embryos.However, manually annotating developmental events, and more specifically celldivisions, is time-consuming for a biologist and cannot scale up for practicalapplications. We aim to automatically classify the cell stages of embryos from2D time-lapse microscopy videos with a deep learning approach. We focus on theanalysis of bovine embryonic development using video microscopy, as we areprimarily interested in the application of cattle breeding, and we have createda Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)low-quality images and bovine dark cells that make the identification of cellstages difficult, (2) class ambiguity at the boundaries of developmentalstages, and (3) imbalanced data distribution. To address these challenges, weintroduce CLEmbryo, a novel method that leverages supervised contrastivelearning combined with focal loss for training, and the lightweight 3D neuralnetwork CSN-50 as an encoder. We also show that our method generalizes well.CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS datasetand the publicly available NYU Mouse Embryos dataset.</description>
      <author>example@mail.com (Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis)</author>
      <guid isPermaLink="false">2502.07360v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Image Super-Resolution with Guarantees via Conformal Generative Models</title>
      <link>http://arxiv.org/abs/2502.09664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于符合预测技术的新方法，用于生成图像超分辨率模型中的不确定性量化。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习基础模型在图像超分辨率领域使用越来越多，需要一种既稳健又可解释的不确定性量化方法。&lt;h4&gt;目的&lt;/h4&gt;通过开发适应性强、数据获取容易且可根据局部图像相似性度量自定义的方法来满足这一需求，并为生成模型提供可靠的“置信度掩模”。&lt;h4&gt;方法&lt;/h4&gt;该方法采用符合预测技术，能够应用于任何黑盒生成模型（包括那些被隐藏在不透明API后的），只需要易于获得的数据进行校准。&lt;h4&gt;主要发现&lt;/h4&gt;证明了该方法具有强大的理论保证，涵盖了根据所选局部图像相似性度量的保真度误差控制、重构质量以及数据泄露时的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过实证评估验证了该方法的有效性和性能。&lt;h4&gt;翻译&lt;/h4&gt;随着生成机器学习基础模型在图像超分辨率领域中的广泛应用，迫切需要一种既稳健又可解释的不确定性量化方法。本文提出了一种基于符合预测技术的新方法，用于任何黑盒生成模型（包括被隐藏于不透明API后的）创建“置信度掩模”，该掩模可以可靠且直观地显示生成图像中哪些部分是可信的。该方法只需要易于获取的数据进行校准，并通过选择局部图像相似性度量实现高度定制化，同时具备强大的理论保证，在保真度误差控制、重构质量和面对数据泄露时的鲁棒性方面均有表现。最终实证评估验证了这种方法的有效性和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of generative ML foundation models for imagesuper-resolution calls for robust and interpretable uncertainty quantificationmethods. We address this need by presenting a novel approach based on conformalprediction techniques to create a "confidence mask" capable of reliably andintuitively communicating where the generated image can be trusted. Our methodis adaptable to any black-box generative model, including those locked behindan opaque API, requires only easily attainable data for calibration, and ishighly customizable via the choice of a local image similarity metric. We provestrong theoretical guarantees for our method that span fidelity error control(according to our local image similarity metric), reconstruction quality, androbustness in the face of data leakage. Finally, we empirically evaluate theseresults and establish our method's solid performance.</description>
      <author>example@mail.com (Eduardo Adame, Daniel Csillag, Guilherme Tegoni Goedert)</author>
      <guid isPermaLink="false">2502.09664v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SASVi - Segment Any Surgical Video</title>
      <link>http://arxiv.org/abs/2502.09653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SASVi，一种基于帧级Mask R-CNN Overseer模型的重新提示机制，用于改善基础模型SAM2在手术视频分割中的时间一致性。&lt;h4&gt;背景&lt;/h4&gt;训练于大量公共数据集的基础模型往往需要额外的微调或重新提示机制才能应用于视觉差异显著的目标领域（如手术视频）。由于缺乏目标领域的专业知识，这些模型无法准确捕捉特定语义信息，特别是在对象离开场景或新对象进入时的表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高基础模型在手术视频分割中的时间一致性和表现力。&lt;h4&gt;方法&lt;/h4&gt;提出了SASVi机制，利用少量稀缺注释数据训练的帧级Mask R-CNN Overseer模型，在场景组合变化时自动重新提示SAM2基础模型。这使得能够对完整的手术视频进行平滑且完整的时间分割。&lt;h4&gt;主要发现&lt;/h4&gt;基于Overseer模型的重新提示显著提高了手术视频分割的时间一致性，相较于其他类似提示技术改进了至少1.5%。&lt;h4&gt;结论&lt;/h4&gt;SASVi可以作为一个新基准，在注释数据稀缺的情况下实现手术视频的平滑和时间一致性的分割。该方法允许我们利用有限的数据获取大规模数据集完整视频的完全注释，并公开提供这些注释，为未来手术数据分析模型的发展提供了丰富的数据支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经用中文进行总结、背景介绍、目的声明、方法描述、主要发现和结论阐述。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Foundation models, trained on multitudes of public datasets, oftenrequire additional fine-tuning or re-prompting mechanisms to be applied tovisually distinct target domains such as surgical videos. Further, withoutdomain knowledge, they cannot model the specific semantics of the targetdomain. Hence, when applied to surgical video segmentation, they fail togeneralise to sections where previously tracked objects leave the scene or newobjects enter. Methods: We propose SASVi, a novel re-prompting mechanism basedon a frame-wise Mask R-CNN Overseer model, which is trained on a minimal amountof scarcely available annotations for the target domain. This modelautomatically re-prompts the foundation model SAM2 when the scene constellationchanges, allowing for temporally smooth and complete segmentation of fullsurgical videos. Results: Re-prompting based on our Overseer modelsignificantly improves the temporal consistency of surgical video segmentationcompared to similar prompting techniques and especially frame-wisesegmentation, which neglects temporal information, by at least 1.5%. Ourproposed approach allows us to successfully deploy SAM2 to surgical videos,which we quantitatively and qualitatively demonstrate for three differentcholecystectomy and cataract surgery datasets. Conclusion: SASVi can serve as anew baseline for smooth and temporally consistent segmentation of surgicalvideos with scarcely available annotation data. Our method allows us toleverage scarce annotations and obtain complete annotations for full videos ofthe large-scale counterpart datasets. We make those annotations publiclyavailable, providing extensive annotation data for the future development ofsurgical data science models.</description>
      <author>example@mail.com (Ssharvien Kumar Sivakumar, Yannik Frisch, Amin Ranem, Anirban Mukhopadhyay)</author>
      <guid isPermaLink="false">2502.09653v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds</title>
      <link>http://arxiv.org/abs/2502.10363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://why618188.github.io/beamdojo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种名为BeamDojo的强化学习框架，该框架专为使类人机器人在稀疏支撑点的环境中实现敏捷行走而设计。&lt;h4&gt;背景&lt;/h4&gt;类人机器人在具有稀疏支撑点的风险地形中行走时面临挑战，需要精确的脚步放置和稳定移动。现有的面向四足机器人的方法通常无法推广到类人机器人上，因为两者在脚部几何形状和形态稳定性方面存在差异；基于学习的方法虽然能用于类人机器人，但在复杂地形上的性能较差。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的限制，设计了一种新的强化学习框架来促进类人机器人的敏捷行走并提高其适应稀疏支撑点环境的能力。&lt;h4&gt;方法&lt;/h4&gt;BeamDojo引入了针对多边形脚部设计的脚步采样奖励机制，并采用双批评家模型以平衡密集运动奖励和稀疏脚步放置奖励的学习过程。此外，通过两阶段强化学习方式来鼓励足够的探索：第一阶段在平坦地形上进行训练同时提供任务环境感知观察，第二阶段则是在实际环境中微调策略。&lt;h4&gt;主要发现&lt;/h4&gt;BeamDojo框架不仅能在模拟器中实现高效的学习，在现实世界应用时也能使类人机器人实现在稀疏支撑点的精准脚步放置，并且即使面对重大外部干扰仍能保持高成功率。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了BeamDojo在推动类人机器人在具有挑战性的地形上的运动能力方面的重要进展，为未来的研究开辟了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traversing risky terrains with sparse footholds poses a significant challengefor humanoid robots, requiring precise foot placements and stable locomotion.Existing approaches designed for quadrupedal robots often fail to generalize tohumanoid robots due to differences in foot geometry and unstable morphology,while learning-based approaches for humanoid locomotion still face greatchallenges on complex terrains due to sparse foothold reward signals andinefficient learning processes. To address these challenges, we introduceBeamDojo, a reinforcement learning (RL) framework designed for enabling agilehumanoid locomotion on sparse footholds. BeamDojo begins by introducing asampling-based foothold reward tailored for polygonal feet, along with a doublecritic to balancing the learning process between dense locomotion rewards andsparse foothold rewards. To encourage sufficient trail-and-error exploration,BeamDojo incorporates a two-stage RL approach: the first stage relaxes theterrain dynamics by training the humanoid on flat terrain while providing itwith task terrain perceptive observations, and the second stage fine-tunes thepolicy on the actual task terrain. Moreover, we implement a onboard LiDAR-basedelevation map to enable real-world deployment. Extensive simulation andreal-world experiments demonstrate that BeamDojo achieves efficient learning insimulation and enables agile locomotion with precise foot placement on sparsefootholds in the real world, maintaining a high success rate even undersignificant external disturbances.</description>
      <author>example@mail.com (Huayi Wang, Zirui Wang, Junli Ren, Qingwei Ben, Tao Huang, Weinan Zhang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.10363v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MITO: Enabling Non-Line-of-Sight Perception using Millimeter-waves through Real-World Datasets and Simulation Tools</title>
      <link>http://arxiv.org/abs/2502.10259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的多光谱毫米波图像数据集MITO。&lt;h4&gt;背景&lt;/h4&gt;毫米波信号能够穿透日常遮挡物，但由于公开的毫米波图像资料稀缺及跨学科挑战的存在，计算机视觉研究者在开发基于非视距感知算法和模型方面遇到困难。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出了一个真实世界的数据集和开源模拟工具用于毫米波成像。&lt;h4&gt;方法&lt;/h4&gt;{'数据收集': '使用UR5机器人手臂、两个不同频率的毫米波雷达及RGB-D相机采集超过76个YCB数据集中物体的真实世界3D毫米波图像（超过580幅）。', '信号处理': '通过信号处理管道捕捉并生成真实世界的3D毫米波图像。', '模拟工具': '开发了一个开源模拟工具，可以为任何三维三角网格生成合成的毫米波图像。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'数据集特性': '提供视距和非视距的真实世界毫米波图像、RGB-D图像及地面实况分割蒙版。', '模型性能': '使用segment anything model (SAM) 进行毫米波图像对象分割，达到92.6%的中位精度和64%的中位召回率；训练一个分类器，在非视距条件下可以识别物体（基于合成图像训练），可对真实世界图像进行85%准确度的分类。'}&lt;h4&gt;结论&lt;/h4&gt;相信MITO将成为开发非视距感知的重要资源，类似于早期相机数据集在塑造计算机视觉领域中的作用。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了MITO，这是第一个包含日常物体多光谱毫米波（mmWave）图像的数据集。不同于可见光，mmWave信号能够穿透日常生活中的遮挡物（例如纸板箱、布料和塑料）。然而，由于公开可用的mmWave图象稀缺以及收集和处理mmWave信号的跨学科挑战，在今天对于计算机视觉研究人员来说开发基于非视距感知算法和模型仍然很困难。为了解决这些挑战，我们引入了一个真实世界的数据集和开源模拟工具用于毫米波成像。该数据集使用UR5机器人手臂、两个不同频率的mmWave雷达及RGB-D相机采集超过76个YCB数据集中物体的真实世界3D mmWave图像（超过580幅）。通过信号处理管道，我们捕捉并生成这些图像，并提供了视距和非视距条件下的真实毫米波图象、RGB-D图象以及地面实况分割蒙版。我们还开发了一个开源模拟工具，可以为任何三维三角网格生成合成的毫米波图像，当与真实世界mmWave图像进行比较时，该工具达到了94%的中位F-Score。我们在多个非视距CV任务中展示了数据集和模拟工具的价值：首先，使用segment anything model (SAM) 对mmWave图像执行对象分割，并达到92.6%的中位精度和64%的中位召回率；其次，我们训练了一个分类器，在非视距条件下识别物体（基于合成图像进行训练），该分类器可以对真实世界图象做出85%准确度的分类。我们认为MITO将为计算机视觉研究人员开发非视距感知提供宝贵的资源，这与早期相机数据集在塑造领域中的作用相似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MITO, the first dataset of multi-spectral millimeter-wave (mmWave)images of everyday objects. Unlike visible light, mmWave signals can imagethrough everyday occlusions (e.g., cardboard boxes, fabric, plastic). However,due to the dearth of publicly-available mmWave images and the interdisciplinarychallenges in collecting and processing mmWave signals, it remains difficulttoday for computer vision researchers to develop mmWave-based non-line-of-sightperception algorithms and models.  To overcome these challenges, we introduce a real-world dataset andopen-source simulation tool for mmWave imaging. The dataset is acquired using aUR5 robotic arm with two mmWave radars operating at different frequencies andan RGB-D camera. Through a signal processing pipeline, we capture and createover 580 real-world 3D mmWave images from over 76 different objects in the YCBdataset, a standard dataset for robotics manipulation. We provide real-worldmmWave images in line-of-sight and non-line-of-sight, as well as RGB-D imagesand ground truth segmentation masks. We also develop an open-source simulationtool that can be used to generate synthetic mmWave images for any 3D trianglemesh, which achieves a median F-Score of 94% when compared to real-world mmWaveimages.  We show the usefulness of this dataset and simulation tool in multiple CVtasks in non-line-of-sight. First, we perform object segmentation for mmWaveimages using the segment anything model (SAM), and achieve a median precisionand recall of 92.6% and 64%. Second, we train a classifier that can recognizeobjects in non-line-of-sight. It is trained on synthetic images and canclassify real-world images with 85% accuracy.  We believe MITO will be a valuable resource for computer vision researchersin developing non-line-of-sight perception, similar to how early camera-baseddatasets shaped the field.</description>
      <author>example@mail.com (Laura Dodds, Tara Boroushaki, Fadel Adib)</author>
      <guid isPermaLink="false">2502.10259v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Integrated Multi-Simulation Environments for Aerial Robotics Research</title>
      <link>http://arxiv.org/abs/2502.10218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种解决方案，用于将Sphinx模拟器中的无人机集成到Gazebo仿真环境中。通过创建一个镜像实例来克服现有部分开源或闭源模拟器的限制，并展示了该方法在目标追踪任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人系统开发中，不同的组件可能需要使用不同环境或模拟器进行模拟。特别是在使用Sphinx和Gazebo这样的仿真工具时，如何将它们集成在一起是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;解决部分开源或闭源仿真器中的限制问题，并展示集成后的无人机在目标追踪任务上的表现优于默认的控制器。&lt;h4&gt;方法&lt;/h4&gt;通过创建一个镜像实例的方法将Parrot公司的Sphinx模拟器中的Anafi无人机融入到Gazebo环境中。利用模型预测控制（MPC）进行性能测试，对比传统PID控制器的表现。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的集成仿真环境在目标追踪任务中优于传统的PID控制器。&lt;h4&gt;结论&lt;/h4&gt;通过本研究提出的方法，可以有效解决不同模拟器之间的兼容性问题，并提高了无人机系统开发的安全性和效率。&lt;h4&gt;翻译&lt;/h4&gt;模拟框架在机器人应用程序的安全开发中扮演着重要角色。然而，不同的组件往往需要使用不同的环境/模拟器进行模拟，这给构建一个集成的机器人框架带来了挑战。特别是对于部分开源或闭源的模拟器来说，通常会出现两个核心限制：i) 场景中的其他物体（除了指定的机器人）在运行时无法通过如ROS之类的接口控制；ii) 无法实时获取场景中对象的状态信息（例如位置、速度等）。在这项工作中，我们解决了这些问题，并描述了将Parrot无人机提供的强大模拟器Sphinx中的无人机集成到Gazebo仿真器中的解决方案。为了实现这一点，我们在现有的基于Gazebo的环境中添加了一个镜像实例的无人机。我们的综合模拟环境的一个有希望的应用是目标追踪任务，在空中多机器人场景中很常见。因此，我们还通过严格的测试在模拟和现实世界的跟踪实验中实施并评估了一种模型预测控制器（MPC），其在各种动态追踪场景中的性能优于Parrot流行的Anafi无人机默认提供的基于PID的控制框架，从而增强了系统的整体效用。我们在一个现有的Gazebo环境中包含了一个Anafi无人机，并通过针对自定义的PID控制器基线进行模拟和实际世界跟踪实验来评估MPC的表现。源代码发布在https://github.com/robot-perception-group/anafi_sim上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation frameworks play a pivotal role in the safe development of roboticapplications. However, often different components of an envisioned roboticsystem are best simulated in different environments/simulators. This poses asignificant challenge in simulating the entire project into a single integratedrobotic framework. Specifically, for partially-open or closed-sourcesimulators, often two core limitations arise. i) Actors in the scene other thanthe designated robots cannot be controlled during runtime via interfaces suchas ROS and ii) retrieving real-time state information (such as pose, velocityetc.) of objects in the scene is prevented. In this work, we address theselimitations and describe our solution for the use case of integrating aerialdrones simulated by the powerful simulator Sphinx (provided by Parrot Drone)into the Gazebo simulator. We achieve this by means of a mirrored instance of adrone that is included into existing Gazebo-based environments. A promisingapplication of our integrated simulation environment is the task of targettracking that is common in aerial multi-robot scenarios. Therefore, todemonstrate the effectiveness our our integrated simulation, we also implementa model predictive controller (MPC) that outperforms the default PID-basedcontroller framework provided with the Parrot's popular Anafi drone in variousdynamic tracking scenarios thus enhancing the utility of the overall system. Wetest our solution by including the Anafi drone in an existing Gazebo-basedsimulation and evaluate the performance of the MPC through rigorous testing insimulated and real-world tracking experiments against a customized PIDcontroller baseline. Source code is published onhttps://github.com/robot-perception-group/anafi_sim.</description>
      <author>example@mail.com (Pascal Goldschmid, Aamir Ahmad)</author>
      <guid isPermaLink="false">2502.10218v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MonoForce: Learnable Image-conditioned Physics Engine</title>
      <link>http://arxiv.org/abs/2502.10156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Robotics (T-RO), 2025. Code:  https://github.com/ctu-vras/monoforce&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合物理感知神经符号层的新型模型，用于从车载摄像头图像预测机器人在崎岖越野地形上的轨迹。&lt;h4&gt;背景&lt;/h4&gt;当前机器人系统在现实世界中的性能差距依然显著，特别是在复杂和不可预知的地面上。现有模型通常缺乏对经典力学定律的遵守，同时难以大规模数据学习。&lt;h4&gt;目的&lt;/h4&gt;开发一种结合物理知识与神经网络优势的混合架构，用于提高机器人的轨迹预测精度，并缩小仿真与真实环境之间的差距。&lt;h4&gt;方法&lt;/h4&gt;模型包括一个黑盒组件，它根据地形条件预测机器人-地面交互力；一个可微分物理引擎将这些力应用于计算机器人运动路径。整个体系结构为端到端的可微性设计。&lt;h4&gt;主要发现&lt;/h4&gt;该架构能够显著减少仿真与实际环境之间的差距，并且由于其快速模拟速度和可微特性，适用于多种应用如模型预测控制、轨迹规划、监督学习及强化学习等。&lt;h4&gt;结论&lt;/h4&gt;通过结合物理原理与数据驱动的神经网络方法，新模型在处理复杂地形时表现出卓越性能。开源代码和实验数据也已公开分享。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新型模型，用于从车载摄像头图像预测机器人在崎岖越野地形上的轨迹。该模型利用了一个具有物理学意识的神经符号层来执行经典力学定律，并保持了通过大规模数据学习的能力，因为它是一个端到端可微分架构。所提出的混合模型结合了一个黑盒组件和一个神经符号层，前者用于预测与地面交互的力量，后者包括一个可微分物理引擎，该引擎通过查询接触点处的这些力量来计算机器人的轨迹。由于该架构包含了大量的几何和物理先验知识，因此可以将结果模型视为基于真实图像的学习型物理引擎，每秒能产生10,000条轨迹。我们论证并实验证明了这种架构减少了仿真与现实之间的差距，并缓解了分布外敏感性问题。通过结合快速模拟速度和可微特性，该模型非常适合各种应用如模型预测控制、轨迹规划、监督学习或强化学习及SLAM等使用。代码和数据已公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel model for the prediction of robot trajectories on roughoffroad terrain from the onboard camera images. This model enforces the laws ofclassical mechanics through a physics-aware neural symbolic layer whilepreserving the ability to learn from large-scale data as it is end-to-enddifferentiable. The proposed hybrid model integrates a black-box component thatpredicts robot-terrain interaction forces with a neural-symbolic layer. Thislayer includes a differentiable physics engine that computes the robot'strajectory by querying these forces at the points of contact with the terrain.As the proposed architecture comprises substantial geometrical and physicspriors, the resulting model can also be seen as a learnable physics engineconditioned on real images that delivers $10^4$ trajectories per second. Weargue and empirically demonstrate that this architecture reduces thesim-to-real gap and mitigates out-of-distribution sensitivity. Thedifferentiability, in conjunction with the rapid simulation speed, makes themodel well-suited for various applications including model predictive control,trajectory shooting, supervised and reinforcement learning or SLAM. The codesand data are publicly available.</description>
      <author>example@mail.com (Ruslan Agishev, Karel Zimmermann)</author>
      <guid isPermaLink="false">2502.10156v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models</title>
      <link>http://arxiv.org/abs/2502.10090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Manual2Skill框架，这是一个使机器人能够通过高级手册指令执行复杂装配任务的系统。&lt;h4&gt;背景&lt;/h4&gt;人类可以理解并根据抽象的手册指南完成复杂的操作任务，而机器人在这方面面临巨大挑战，因为它们无法解读这些指令并将之转化为可执行的动作。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够让机器人利用视觉语言模型从指导图片中提取结构化信息，并使用此信息构建层次装配图的框架，以便于执行复杂装配任务。&lt;h4&gt;方法&lt;/h4&gt;采用视觉语言模型（VLM）来解析手册中的图像，建立零件、子装配件及其关系之间的层次结构。同时运用姿态估计预测各组件在装配过程中的相对6D姿态，并生成可供机器人实施的动作序列。&lt;h4&gt;主要发现&lt;/h4&gt;通过成功组装多件真实世界的IKEA家具证明了Manual2Skill的有效性，显示其能够高效精确地管理长期操作任务，显著提升了从手册学习的实用性。&lt;h4&gt;结论&lt;/h4&gt;这项研究标志着一个突破，使得机器人系统更接近于像人类那样理解和执行复杂的操控任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个框架——Manual2Skill，它使机器人能通过高级指令文档来进行复杂装配工作。该框架利用视觉语言模型解析手册中的结构化信息，并构建装配图，帮助机器人实现精准的长时操作任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess an extraordinary ability to understand and execute complexmanipulation tasks by interpreting abstract instruction manuals. For robots,however, this capability remains a substantial challenge, as they cannotinterpret abstract instructions and translate them into executable actions. Inthis paper, we present Manual2Skill, a novel framework that enables robots toperform complex assembly tasks guided by high-level manual instructions. Ourapproach leverages a Vision-Language Model (VLM) to extract structuredinformation from instructional images and then uses this information toconstruct hierarchical assembly graphs. These graphs represent parts,subassemblies, and the relationships between them. To facilitate taskexecution, a pose estimation model predicts the relative 6D poses of componentsat each assembly step. At the same time, a motion planning module generatesactionable sequences for real-world robotic implementation. We demonstrate theeffectiveness of Manual2Skill by successfully assembling several real-worldIKEA furniture items. This application highlights its ability to managelong-horizon manipulation tasks with both efficiency and precision,significantly enhancing the practicality of robot learning from instructionmanuals. This work marks a step forward in advancing robotic systems capable ofunderstanding and executing complex manipulation tasks in a manner akin tohuman capabilities.</description>
      <author>example@mail.com (Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao)</author>
      <guid isPermaLink="false">2502.10090v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Imit Diff: Semantics Guided Diffusion Transformer with Dual Resolution Fusion for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.09649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了Imit Diff，这是一种用于模仿学习的语义引导扩散变换器，并引入了双分辨率融合来提高复杂场景下的操作技能获取能力。&lt;h4&gt;背景&lt;/h4&gt;视觉运动模仿学习允许实体智能体通过视频演示和机器人本体感觉有效获得操作技巧。然而，在场景复杂度增加且存在视觉干扰的情况下，现有的方法在简单场景中表现良好的性能会下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在复杂场景下性能下降的问题，论文提出了一种新的模仿学习方法——Imit Diff。&lt;h4&gt;方法&lt;/h4&gt;该方法利用了视觉语言基础模型的先验知识，将高层次语义指令翻译成像素级视觉定位信息，并将其显式地集成到一个多尺度增强框架中。此外，还引入了一致性策略来提高实体智能体控制的实际性能和运动流畅度。&lt;h4&gt;主要发现&lt;/h4&gt;在几个具有挑战性的现实任务上评估了Imit Diff，由于其目标导向的视觉定位能力和细粒度场景感知能力，在复杂且存在视觉干扰的场景中，它显著优于现有的最先进方法，特别是在零样本实验（专注于视觉干扰和类别泛化）中的表现。&lt;h4&gt;结论&lt;/h4&gt;论文提出了新的模仿学习方法——Imit Diff，并展示了在处理具有挑战性的操作任务时该方法的有效性。未来的研究将公开提供代码供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor imitation learning enables embodied agents to effectively acquiremanipulation skills from video demonstrations and robot proprioception.However, as scene complexity and visual distractions increase, existing methodsthat perform well in simple scenes tend to degrade in performance. To addressthis challenge, we introduce Imit Diff, a semanstic guided diffusiontransformer with dual resolution fusion for imitation learning. Our approachleverages prior knowledge from vision language foundation models to translatehigh-level semantic instruction into pixel-level visual localization. Thisinformation is explicitly integrated into a multi-scale visual enhancementframework, constructed with a dual resolution encoder. Additionally, weintroduce an implementation of Consistency Policy within the diffusiontransformer architecture to improve both real-time performance and motionsmoothness in embodied agent control.We evaluate Imit Diff on severalchallenging real-world tasks. Due to its task-oriented visual localization andfine-grained scene perception, it significantly outperforms state-of-the-artmethods, especially in complex scenes with visual distractions, includingzero-shot experiments focused on visual distraction and categorygeneralization. The code will be made publicly available.</description>
      <author>example@mail.com (Yuhang Dong, Haizhou Ge, Yupei Zeng, Jiangning Zhang, Beiwen Tian, Guanzhong Tian, Hongrui Zhu, Yufei Jia, Ruixiang Wang, Ran Yi, Guyue Zhou, Longhua Ma)</author>
      <guid isPermaLink="false">2502.09649v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Patient Acceptance of Robotic Ultrasound through Conversational Virtual Agent and Immersive Visualizations</title>
      <link>http://arxiv.org/abs/2502.10088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures, to be published in IEEE Transactions on  Visualization and Computer Graphics (TVCG) and 2025 IEEE conference on  virtual reality and 3D user interfaces (VR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了结合AI驱动的对话虚拟代理和三种混合现实可视化技术的系统，旨在提高患者对机器人超声系统的信任感与舒适度。&lt;h4&gt;背景&lt;/h4&gt;机器人超声波系统在医疗诊断中有潜在的应用价值，但患者的接受程度较低。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个由大型语言模型支持的虚拟对话代理以及多种混合现实视图来增强患者对机器人的信任和使用体验。&lt;h4&gt;方法&lt;/h4&gt;设计了一种结合AI驱动的虚拟助手与三种不同类型的混合现实视觉技术（增强现实、增强虚拟性和全沉浸式虚拟现实）的系统，旨在改善用户交互可靠性和提升用户体验。&lt;h4&gt;主要发现&lt;/h4&gt;通过用户研究证明了该方案能够显著提高患者的信任感和接受度，为自主医疗程序中的混合现实技术和虚拟代理设计提供了宝贵的见解。&lt;h4&gt;结论&lt;/h4&gt;这项创新性方法可以有效促进患者对机器人超声系统的接受，并改善其体验。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic ultrasound systems can enhance medical diagnostics, but patientacceptance is a challenge. We propose a system combining an AI-poweredconversational virtual agent with three mixed reality visualizations to improvetrust and comfort. The virtual agent, powered by a large language model,engages in natural conversations and guides the ultrasound robot, enhancinginteraction reliability. The visualizations include augmented reality,augmented virtuality, and fully immersive virtual reality, each designed tocreate patient-friendly experiences. A user study demonstrated significantimprovements in trust and acceptance, offering valuable insights for designingmixed reality and virtual agents in autonomous medical procedures.</description>
      <author>example@mail.com (Tianyu Song, Felix Pabst, Ulrich Eck, Nassir Navab)</author>
      <guid isPermaLink="false">2502.10088v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Coordinated control of multiple autonomous surface vehicles: challenges and advances - a systematic review</title>
      <link>http://arxiv.org/abs/2502.10080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了自主水面船舶（ASV）协调控制领域的最新进展，并探讨了这一领域的重要缺口。&lt;h4&gt;背景&lt;/h4&gt;随着ASVs在各种海事活动中的使用和实施增加，对它们的控制研究和发展也日益增多。特别是多个ASVs之间的协作带来了新的挑战和机遇，需要来自机器人学、控制理论、通信系统以及海洋科学等领域的跨学科研究努力。&lt;h4&gt;目的&lt;/h4&gt;探讨利用不同控制技术组合来实现各种任务或目标的可能性，并引入机器学习以考虑以往认为难以实施的方面。&lt;h4&gt;方法&lt;/h4&gt;采用系统的文献筛选方法来确保文章选择的一致性和减少偏见，重点讨论了定制化控制策略和集成机器学习技术以提高自主性的次执行ASVs的问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文对最新的协调ASV控制进行了全面探索，并指出了以前综述中未涵盖的关键缺口。同时概述了目前的技术状态并为未来的研究工作提供了指导。&lt;h4&gt;结论&lt;/h4&gt;通过综合最近的进展和识别新兴趋势，文章提出了促进该领域发展的见解，为未来的科研努力提供了一个全面的视角和技术指南。&lt;h4&gt;翻译&lt;/h4&gt;随着自主水面船舶（ASVs）在海事环境中的各种活动中的应用增加，预计这将推动对其控制的研究和发展。特别是多个ASVs之间的协调带来了新的挑战和机遇，需要来自机器人学、控制理论、通信系统以及海洋科学等领域的跨学科研究努力。这些船只可以集体用于多种任务或目标，因此可以结合使用不同的控制技术，包括探索机器学习来考虑以前认为不可行的方面。本文提供了对协同ASV控制的全面探讨，并解决了先前综述中留下的关键缺口。与之前的工作不同的是，我们采取了系统的方法以确保文章选择的一致性和减少偏见。我们将深入探讨次执行ASVs的世界，并重点讨论定制化控制策略以及集成机器学习技术以提高自主性的问题。通过综合最近的进展并识别新兴趋势，本文提供了促进该领域发展的见解，为未来的科研工作提供了一个全面的技术和指导视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.oceaneng.2024.119160&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use and implementation of Autonomous Surface Vessels (ASVs)for various activities in maritime environments is expected to drive a rise indevelopments and research on their control. Particularly, the coordination ofmultiple ASVs presents novel challenges and opportunities, requiringinterdisciplinary research efforts at the intersection of robotics, controltheory, communication systems, and marine sciences. The wide variety ofmissions or objectives for which these vessels can be collectively used allowsfor the application and combination of different control techniques. Thisincludes the exploration of machine learning to consider aspects previouslydeemed infeasible. This review provides a comprehensive exploration ofcoordinated ASV control while addressing critical gaps left by previousreviews. Unlike previous works, we adopt a systematic approach to ensureintegrity and minimize bias in article selection. We delve into the complexworld of sub-actuated ASVs with a focus on customized control strategies andthe integration of machine learning techniques for increased autonomy. Bysynthesizing recent advances and identifying emerging trends, we offer insightsthat drive this field forward, providing both a comprehensive overview ofstate-of-the-art techniques and guidance for future research efforts.</description>
      <author>example@mail.com (Manuel Gantiva Osorioa, Carmelina Ierardia, Isabel Jurado Floresa, Mario Pereira Martína, Pablo Millán Gata)</author>
      <guid isPermaLink="false">2502.10080v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints</title>
      <link>http://arxiv.org/abs/2502.10062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a full paper at AAMAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了在未知机器人转换模型的情况下多机器人协作的问题，确保由时间窗口时态逻辑指定的任务能够在用户定义的概率阈值下得到满足。&lt;h4&gt;背景&lt;/h4&gt;当前的多机器人系统面临着如何在不完全了解机器人动态变化（即转换模型）的情况下进行有效任务分配和执行的问题。现有的方法通常依赖于详细的机器人模型来进行优化，这限制了它们的应用范围。&lt;h4&gt;目的&lt;/h4&gt;提出一种分层框架来解决上述问题，使机器人能够在不确定环境下有效地协作完成指定任务，并且达到用户定义的成功概率阈值。&lt;h4&gt;方法&lt;/h4&gt;1. 高层次的任务分配：基于对每个机器人的估计任务完成概率和预期奖励来进行任务分配。2. 低层次的分布式策略学习与执行：允许机器人独立优化辅助奖励，同时满足其分配到的任务要求。3. 利用实时任务执行数据来迭代细化任务完成的概率以及预期奖励，无需显式的机器人转换模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过理论验证和广泛的模拟实验，证明了所提出的算法能够有效地在不确定环境中进行多机器人协调，并且可以达到用户定义的成功概率阈值。&lt;h4&gt;结论&lt;/h4&gt;提出了一种基于实时数据的自适应任务分配方法，使得多机器人系统能够在没有精确模型的情况下高效工作。这种方法提高了系统的鲁棒性和灵活性，为未来的智能协作提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;此研究处理了在未知机器人转换模式下进行多机器人协调的问题，确保根据时间窗口时态逻辑指定的任务能够达到用户定义的概率阈值要求。通过介绍一种结合高层次任务分配和低层次分布式策略学习与执行的分层框架来解决这个问题，并且展示了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the problem of multi-robot coordination under unknownrobot transition models, ensuring that tasks specified by Time Window TemporalLogic are satisfied with user-defined probability thresholds. We present abi-level framework that integrates (i) high-level task allocation, where tasksare assigned based on the robots' estimated task completion probabilities andexpected rewards, and (ii) low-level distributed policy learning and execution,where robots independently optimize auxiliary rewards while fulfilling theirassigned tasks. To handle uncertainty in robot dynamics, our approach leveragesreal-time task execution data to iteratively refine expected task completionprobabilities and rewards, enabling adaptive task allocation without explicitrobot transition models. We theoretically validate the proposed algorithm,demonstrating that the task assignments meet the desired probability thresholdswith high confidence. Finally, we demonstrate the effectiveness of ourframework through comprehensive simulations.</description>
      <author>example@mail.com (Xiaoshan Lin, Roberto Tron)</author>
      <guid isPermaLink="false">2502.10062v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>A Generalized Modeling Approach to Liquid-driven Ballooning Membranes</title>
      <link>http://arxiv.org/abs/2502.10057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;软机器人技术正在利用柔性材料推进适应性强的机器人系统的开发。膜驱动的软机器人通过使用加压、可延展的薄膜来克服传统软机器人的局限，实现稳定的大变形，但复杂的形变动态使得控制和状态估计仍然具有挑战性。&lt;h4&gt;背景&lt;/h4&gt;传统的软机器人在形状改变和动力学方面存在限制，特别是在需要精确控制的应用中。膜驱动软机器人使用加压、可伸展的薄膜来克服这些限制，实现了较大的变形范围。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新颖的建模方法，用于液驱膨胀膜，该模型采用椭球近似法来描述在平面形变下的形状和拉伸情况。目的是利用这种方法实现精确的膜状态估计。&lt;h4&gt;方法&lt;/h4&gt;使用液体驱动膨胀膜的实验验证了所提出的模型的有效性，并通过压力数据和控制液体体积来进行内部反馈，从而实现了对膜状态的准确估算。&lt;h4&gt;主要发现&lt;/h4&gt;在基于膨胀膜执行器的实验中获得了0.80毫米的压入深度误差（$RMSE_{h_2}$），这个值占总压入范围的23%，以及未被压入时执行器高度范围的6.67%。对于力估计，误差范围为0.15牛顿（$RMSE_{F}$），该数值是测得力范围的10%。&lt;h4&gt;结论&lt;/h4&gt;所提出的液驱膨胀膜建模方法能够准确地进行膜状态和力的估算，展示了其在软机器人领域中的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robotics is advancing the use of flexible materials for adaptablerobotic systems. Membrane-actuated soft robots address the limitations oftraditional soft robots by using pressurized, extensible membranes to achievestable, large deformations, yet control and state estimation remain challengingdue to their complex deformation dynamics. This paper presents a novel modelingapproach for liquid-driven ballooning membranes, employing an ellipsoidapproximation to model shape and stretch under planar deformation. Relyingsolely on intrinsic feedback from pressure data and controlled liquid volume,this approach enables accurate membrane state estimation. We demonstrate theeffectiveness of the proposed model for ballooning membrane-based actuators byexperimental validation, obtaining the indentation depth error of$RMSE_{h_2}=0.80\;$mm, which is $23\%$ of the indentation range and $6.67\%$ ofthe unindented actuator height range. For the force estimation, the error rangeis obtained to be $RMSE_{F}=0.15\;$N which is $10\%$ of the measured forcerange.</description>
      <author>example@mail.com (Mirroyal Ismayilov, Jeref Merlin, Christos Bergeles, Lukas Lindenroth)</author>
      <guid isPermaLink="false">2502.10057v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Trajectory-guided Policy for Long-horizon Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.10040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近，Vision-Language-Action（VLA）模型在机器人模仿学习中取得了进展，但高昂的数据收集成本和有限的演示数据限制了泛化能力，并且现有的模仿学习方法在外分布场景下表现不佳，尤其是对于长时间任务。&lt;h4&gt;背景&lt;/h4&gt;当前的机器人模仿学习面临高数据采集成本、有限演示数据及外分布场景下的挑战。尤其是在处理长时间任务时，模仿学习中累积误差导致的问题尤为突出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架（Diffusion Trajectory-guided Policy, DTP）来减少长时序任务中的累积错误，并提高机器人在现实世界中的性能。&lt;h4&gt;方法&lt;/h4&gt;该研究采用两阶段方法：首先训练一个生成式视觉语言模型，通过扩散模型产生2D轨迹；然后利用这些轨迹指导政策学习，以改善模仿策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在CALVIN基准测试中，DTP框架在成功率方面比现有最佳基线高出25%，且无需外部预训练。此外，DTP显著提高了实际机器人系统的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的Diffusion Trajectory-guided Policy（DTP）方法为解决长时间任务的机器人模仿学习中的误差累积问题提供了一种有效途径，并展示了在现实世界应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近，Vision-Language-Action模型已推动了机器人模仿学习的发展，但高昂的数据采集成本和有限演示限制了泛化能力。当前的方法在外分布场景下尤其难以处理长时间任务。为解决这些问题，本文提出了Diffusion Trajectory-guided Policy（DTP）框架，该框架通过生成2D轨迹来指导长时序任务中的策略学习，减少了错误累积。实验结果表明，在CALVIN基准测试中，DTP比现有最佳方法高出25%的成功率，并且显著改善了真实机器人系统的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Vision-Language-Action models (VLA) have advanced robot imitationlearning, but high data collection costs and limited demonstrations hindergeneralization and current imitation learning methods struggle inout-of-distribution scenarios, especially for long-horizon tasks. A keychallenge is how to mitigate compounding errors in imitation learning, whichlead to cascading failures over extended trajectories. To address thesechallenges, we propose the Diffusion Trajectory-guided Policy (DTP) framework,which generates 2D trajectories through a diffusion model to guide policylearning for long-horizon tasks. By leveraging task-relevant trajectories, DTPprovides trajectory-level guidance to reduce error accumulation. Our two-stageapproach first trains a generative vision-language model to creatediffusion-based trajectories, then refines the imitation policy using them.Experiments on the CALVIN benchmark show that DTP outperforms state-of-the-artbaselines by 25% in success rate, starting from scratch without externalpretraining. Moreover, DTP significantly improves real-world robot performance.</description>
      <author>example@mail.com (Shichao Fan, Quantao Yang, Yajie Liu, Kun Wu, Zhengping Che, Qingjie Liu, Min Wan)</author>
      <guid isPermaLink="false">2502.10040v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.10028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ManiTrend的统一框架，该框架利用3D流作为语言驱动未来图像生成和精细化动作预测之间的桥梁。通过因果Transformer模型对三维粒子动态、视觉观察和操作行为进行建模。&lt;h4&gt;背景&lt;/h4&gt;基于自然语言的目标表示是解决语言条件操纵任务的关键挑战之一，而三维流动则被认为是一个有效的连接点。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用3D流信息的统一框架ManiTrend，以改善基于语言的动作预测任务的表现。&lt;h4&gt;方法&lt;/h4&gt;开发了名为ManiTrend的新模型，该模型采用因果Transformer架构，并将三维流动作为未来图像生成和动作预测中的额外条件。&lt;h4&gt;主要发现&lt;/h4&gt;1. 三维流动可以替代缺失或异质性操作标签，在大规模预训练中使用跨身体演示。2. 实验显示本文方法在两个全面基准上的性能优于现有技术，且效率更高。&lt;h4&gt;结论&lt;/h4&gt;ManiTrend框架通过引入3D流作为中间表示，提高了语言驱动的未来图像生成和精细化动作预测任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;语言条件操纵是一项重要但具挑战性的机器人任务，因为自然语言的高度抽象性。为了解决这个问题，研究人员正在寻求改进源自自然语言的目标表示。本文中，我们强调了3D流动——代表场景内三维粒子的运动趋势——作为基于语言未来图像生成与精细动作预测之间的有效桥梁。为此，我们开发了一种称为ManiTrend的统一框架，该框架利用因果Transformer对三维粒子动态、视觉观察和操作行为进行建模。在此框架中，用于3D流动预测的功能作为未来图像生成和动作预测中的额外条件，减轻了像素级时空模型化复杂性，并提供无缝的动作指导。此外，在大规模预训练过程中，3D流动可以替代缺失或异质性的动作标签，使用跨身体演示。在两个全面基准上的实验表明，我们的方法实现了最先进的性能，具有高效率。我们的代码和模型检查点将在接受后可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language-conditioned manipulation is a vital but challenging robotic task dueto the high-level abstraction of language. To address this, researchers havesought improved goal representations derived from natural language. In thispaper, we highlight 3D flow - representing the motion trend of 3D particleswithin a scene - as an effective bridge between language-based future imagegeneration and fine-grained action prediction. To this end, we developManiTrend, a unified framework that models the dynamics of 3D particles, visionobservations and manipulation actions with a causal transformer. Within thisframework, features for 3D flow prediction serve as additional conditions forfuture image generation and action prediction, alleviating the complexity ofpixel-wise spatiotemporal modeling and providing seamless action guidance.Furthermore, 3D flow can substitute missing or heterogeneous action labelsduring large-scale pretraining on cross-embodiment demonstrations. Experimentson two comprehensive benchmarks demonstrate that our method achievesstate-of-the-art performance with high efficiency. Our code and modelcheckpoints will be available upon acceptance.</description>
      <author>example@mail.com (Yuxin He, Qiang Nie)</author>
      <guid isPermaLink="false">2502.10028v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Dream to Drive: Model-Based Vehicle Control Using Analytic World Models</title>
      <link>http://arxiv.org/abs/2502.10012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了可微模拟器在训练自动驾驶车辆控制器方面的应用，并首次尝试使用它们来训练世界模型。&lt;h4&gt;背景&lt;/h4&gt;可微模拟器允许通过它们进行反向传播，从而将已知的动力学作为策略学习的先验知识。然而，这些系统仅被用于训练政策。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法——Analytic World Models (AWMs)，利用可微模拟器来训练世界模型，并展示了其在规划任务中的应用。&lt;h4&gt;方法&lt;/h4&gt;提出了三种新任务设置，允许学习下一个状态预测器、最优规划者和最优逆向状态。与传统的分析策略梯度（APG）相比，该方法依赖于当前状态到下一个状态的梯度。&lt;h4&gt;主要发现&lt;/h4&gt;AWM 方法在 Waymo Open Motion 数据集上的性能比基线提高了多达12%，同时几乎不增加额外成本。&lt;h4&gt;结论&lt;/h4&gt;通过使用可微模拟器训练世界模型，可以极大地提升自动驾驶车辆控制器的性能和效率。&lt;h4&gt;翻译&lt;/h4&gt;最近，可微分仿真器被证明对训练自主车辆控制器有很大潜力。由于它们支持反向传播，因此可以在端到端训练循环中使用，从而将已知的动力学转化为策略学习的有效先验知识，消除了环境的黑盒假设。迄今为止，这些系统仅用于培训政策。然而，在提供可能性方面，这还远未结束。在这里，我们首次利用它们来训练世界模型。具体而言，我们介绍了三种新的任务设置，使我们能够学习下一个状态预测器、最优规划者和最佳逆状态。与需要当前行动对下一仿真状态的梯度的传统分析策略梯度（APG）不同，我们提出的设置依赖于当前状态到下一状态的梯度。我们称这种方法为解析世界模型（AWM），并展示了它的应用，包括如何在Waymax模拟器中使用它进行规划。除了推动此类模拟器的可能性之外，还提供了一种改进的训练方法，在大规模Waymo开放运动数据集上的性能提高了高达12％，与基线相比几乎不增加额外成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentiable simulators have recently shown great promise for trainingautonomous vehicle controllers. Being able to backpropagate through them, theycan be placed into an end-to-end training loop where their known dynamics turninto useful priors for the policy to learn, removing the typical black boxassumption of the environment. So far, these systems have only been used totrain policies. However, this is not the end of the story in terms of what theycan offer. Here, for the first time, we use them to train world models.Specifically, we present three new task setups that allow us to learn nextstate predictors, optimal planners, and optimal inverse states. Unlike analyticpolicy gradients (APG), which requires the gradient of the next simulator statewith respect to the current actions, our proposed setups rely on the gradientof the next state with respect to the current state. We call this approachAnalytic World Models (AWMs) and showcase its applications, including how touse it for planning in the Waymax simulator. Apart from pushing the limits ofwhat is possible with such simulators, we offer an improved training recipethat increases performance on the large-scale Waymo Open Motion dataset by upto 12% compared to baselines at essentially no additional cost.</description>
      <author>example@mail.com (Asen Nachkov, Danda Pani Paudel, Jan-Nico Zaech, Davide Scaramuzza, Luc Van Gool)</author>
      <guid isPermaLink="false">2502.10012v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models</title>
      <link>http://arxiv.org/abs/2502.09980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的问题设置，将大型语言模型（LLM）集成到基于车辆间通信的自动驾驶系统中，并引入了Vehicle-to-Vehicle Question-Answering (V2V-QA)数据集和基准。&lt;h4&gt;背景&lt;/h4&gt;现有的自主驾驶汽车主要依赖自身传感器来感知周围环境并规划未来路径，在传感器故障或遮挡时可靠性较低。通过车辆间通信进行协作感知的方法已被提出，但这些方法多集中在检测和跟踪上，而它们对整体合作规划性能的贡献尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;基于最近利用大型语言模型构建自主驾驶系统的进展，论文旨在研究如何将LLM用于自动驾驶汽车中的信息融合，并探讨其在解决不同任务方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了Vehicle-to-Vehicle Large Language Model (V2V-LLM)基线方法，该方法使用LLM来融合多个连接的自主车辆（CAVs）提供的感知信息并回答与驾驶相关的提问：定位、识别显著对象及规划路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的V2V-LLM模型在执行各种协作自动驾驶任务时表现良好，并优于其他采用不同融合方法的基线模型。&lt;h4&gt;结论&lt;/h4&gt;本文工作开创了一种新的研究方向，可以提高未来自主驾驶系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;当前自主车辆主要依赖自身传感器理解周围环境并规划路径，在传感器故障或遮挡时可能会不可靠。为解决此问题，通过车对车（V2V）通信进行协作感知的方法已被提出，但这些方法大多集中在检测和跟踪上。目前对于如何利用上述方法提升整体合作规划性能还存在不足研究。受最近使用大型语言模型构建自主驾驶系统进展的启发，我们提出了一个将LLM融入到合作自动驾驶中的新颖问题设置，并引入了Vehicle-to-Vehicle Question-Answering (V2V-QA)数据集和基准。同时提出我们的基线方法Vehicle-to-Vehicle Large Language Model (V2V-LLM)，它使用LLM融合多个连接的自主车辆提供的感知信息并回答与驾驶相关的提问：定位、识别显著对象及规划路径。实验结果表明，我们提出的V2V-LLM可以作为执行各种合作自动驾驶任务的有前景的统一模型架构，并优于其他采用不同融合方法的基线模型。我们的工作开创了一种新的研究方向，以提高未来自主驾驶系统的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current autonomous driving vehicles rely mainly on their individual sensorsto understand surrounding scenes and plan for future trajectories, which can beunreliable when the sensors are malfunctioning or occluded. To address thisproblem, cooperative perception methods via vehicle-to-vehicle (V2V)communication have been proposed, but they have tended to focus on detectionand tracking. How those approaches contribute to overall cooperative planningperformance is still under-explored. Inspired by recent progress using LargeLanguage Models (LLMs) to build autonomous driving systems, we propose a novelproblem setting that integrates an LLM into cooperative autonomous driving,with the proposed Vehicle-to-Vehicle Question-Answering (V2V-QA) dataset andbenchmark. We also propose our baseline method Vehicle-to-Vehicle LargeLanguage Model (V2V-LLM), which uses an LLM to fuse perception information frommultiple connected autonomous vehicles (CAVs) and answer driving-relatedquestions: grounding, notable object identification, and planning. Experimentalresults show that our proposed V2V-LLM can be a promising unified modelarchitecture for performing various tasks in cooperative autonomous driving,and outperforms other baseline methods that use different fusion approaches.Our work also creates a new research direction that can improve the safety offuture autonomous driving systems. Our project website:https://eddyhkchiu.github.io/v2vllm.github.io/ .</description>
      <author>example@mail.com (Hsu-kuang Chiu, Ryo Hachiuma, Chien-Yi Wang, Stephen F. Smith, Yu-Chiang Frank Wang, Min-Hung Chen)</author>
      <guid isPermaLink="false">2502.09980v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Global-Local Interface for On-Demand Teleoperation</title>
      <link>http://arxiv.org/abs/2502.09960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章介绍了全球-局部（G-L）遥控界面，这是一种用于机器人遥控行为的新型接口，它能够同时处理全局运动和精确操作。&lt;h4&gt;背景&lt;/h4&gt;当前存在的遥控方法在灵活性、工作范围和精度方面有各自的优缺点。为了融合这些优势，作者提出了一种新的解决方案。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入G-L界面来提供一种既能保证机器人动作范围和直观性，又能提升人类操作者执行精细任务的能力的方法。&lt;h4&gt;方法&lt;/h4&gt;基于G-L界面构建了单臂和双臂遥控系统，并使用不同的远程控制设备进行了演示。这些实验涉及需要大运动范围、精确操纵或灵巧末端执行器控制的任务。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明，所提出的界面具有用户友好性、准确性以及广泛适用性。&lt;h4&gt;结论&lt;/h4&gt;G-L遥操作接口提供了一种有效的方法来增强机器人在各种任务中的表现，包括传统的拾取放置任务和复杂的精细操作。&lt;h4&gt;翻译&lt;/h4&gt;远程操作是人机交互的关键方法，在工业和非结构化环境中具有重要的应用潜力。现有远程操作方法在灵活性、工作范围和精度方面各有优缺点。为了融合这些优点，我们引入了全球-局部（G-L）远程操作界面。该接口将机器人的遥控分解为全局行为，确保机器人运动范围的直观性，并增强人类操作者进行精细任务的能力。基于G-L界面构建了一个单臂和双臂遥操作系统并使用不同的远程控制设备进行了演示，这些实验涉及需要大动作范围、精确操纵或灵巧末端执行器控制的任务。广泛的实验证明了所提出接口的用户友好性、准确性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Teleoperation is a critical method for human-robot interface, holdssignificant potential for enabling robotic applications in industrial andunstructured environments. Existing teleoperation methods have distinctstrengths and limitations in flexibility, range of workspace and precision. Tofuse these advantages, we introduce the Global-Local (G-L) TeleoperationInterface. This interface decouples robotic teleoperation into global behavior,which ensures the robot motion range and intuitiveness, and local behavior,which enhances human operator's dexterity and capability for performing finetasks. The G-L interface enables efficient teleoperation not only forconventional tasks like pick-and-place, but also for challenging finemanipulation and large-scale movements. Based on the G-L interface, weconstructed a single-arm and a dual-arm teleoperation system with differentremote control devices, then demonstrated tasks requiring large motion range,precise manipulation or dexterous end-effector control. Extensive experimentsvalidated the user-friendliness, accuracy, and generalizability of the proposedinterface.</description>
      <author>example@mail.com (Jianshu Zhou, Boyuan Liang, Junda Huang, Ian Zhang, Pieter Abbeel, Masayoshi Tomizuka)</author>
      <guid isPermaLink="false">2502.09960v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Self-Consistent Model-based Adaptation for Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.09923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的自我一致模型自适应（SCMA）方法，该方法通过将嘈杂的观察结果转换为干净的观察结果来提高视觉强化学习代理在实际应用中的性能，而无需修改策略。&lt;h4&gt;背景&lt;/h4&gt;现有的方法依赖于使用手工制作的数据增强技术对策略表示进行微调，以应对现实世界中由视觉干扰引起的性能下降问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种不修改现有策略的自适应方法，能够通过插件方式提高在各种复杂环境下的表现。&lt;h4&gt;方法&lt;/h4&gt;利用去噪模型将杂乱无章的观测值转换为清晰的观测值；推导出了一种无监督分布匹配目标以优化该去噪模型，并提出一种算法来估计干净观察数据的概率分布，使用预训练的世界模型进行。&lt;h4&gt;主要发现&lt;/h4&gt;SCMA能够有效缓解各种策略在面对不同干扰时的表现下降问题，并且具有更好的样本效率。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，无论是在多个视觉泛化基准测试还是真实的机器人数据上，SCMA都能显著提升性能表现。&lt;h4&gt;翻译&lt;/h4&gt;视觉强化学习代理通常会在实际应用中由于视觉干扰而导致严重的性能下降。现有的方法依赖于利用手工制作的数据增强技术来微调策略表示。在这项工作中，我们提出了自我一致模型自适应（Self-Consistent Model-based Adaptation, SCMA），这是一种新的无需修改现有策略即可实现稳健自适应的方法。通过使用去噪模型将嘈杂的观测值转换为干净的观测值，SCMA能够缓解各种干扰对不同策略的影响，并作为一个插件增强功能来应用。为了在无监督的情况下优化该去噪模型，我们推导出了一种分布匹配的目标函数，并对其最优性进行了理论分析。进一步地，我们提出一种实用算法以估计清洁观察数据的分布并以此为目标进行优化，使用的是预先训练好的世界模型。广泛的实验表明，在多种视觉泛化基准测试和实际机器人数据上，SCMA都能显著提高性能表现，并且具有更好的样本效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual reinforcement learning agents typically face serious performancedeclines in real-world applications caused by visual distractions. Existingmethods rely on fine-tuning the policy's representations with hand-craftedaugmentations. In this work, we propose Self-Consistent Model-based Adaptation(SCMA), a novel method that fosters robust adaptation without modifying thepolicy. By transferring cluttered observations to clean ones with a denoisingmodel, SCMA can mitigate distractions for various policies as a plug-and-playenhancement. To optimize the denoising model in an unsupervised manner, wederive an unsupervised distribution matching objective with a theoreticalanalysis of its optimality. We further present a practical algorithm tooptimize the objective by estimating the distribution of clean observationswith a pre-trained world model. Extensive experiments on multiple visualgeneralization benchmarks and real robot data demonstrate that SCMA effectivelyboosts performance across various distractions and exhibits better sampleefficiency.</description>
      <author>example@mail.com (Xinning Zhou, Chengyang Ying, Yao Feng, Hang Su, Jun Zhu)</author>
      <guid isPermaLink="false">2502.09923v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Dual Control for Interactive Autonomous Merging with Model Predictive Diffusion</title>
      <link>http://arxiv.org/abs/2502.09918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶等应用中，交互式决策至关重要。传统的预测-行动框架往往不够充分或低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种主动学习框架及在线滚动地平线控制问题的基于模型的扩散求解器。&lt;h4&gt;方法&lt;/h4&gt;提出了一个严格的预测信念分布推导和一个为在线滚动地平线控制问题设计的新建模扩散解决者。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在实际硬件实验中验证了行为推理，并展示了改进的不确定性下的自适应规划能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作推进了交互式决策领域的进展，特别是在现实世界的应用中的不确定性和适应性规划方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种针对自动驾驶等场景开发的新方法和框架，通过引入基于模型的扩散求解器及主动学习框架来改进不确定性条件下的自适应规划能力。研究包括理论推导、仿真验证以及实际硬件实验展示，表明了该技术的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interactive decision-making is essential in applications such as autonomousdriving, where the agent must infer the behavior of nearby human drivers whileplanning in real-time. Traditional predict-then-act frameworks are ofteninsufficient or inefficient because accurate inference of human behaviorrequires a continuous interaction rather than isolated prediction. To addressthis, we propose an active learning framework in which we rigorously derivepredicted belief distributions. Additionally, we introduce a novel model-baseddiffusion solver tailored for online receding horizon control problems,demonstrated through a complex, non-convex highway merging scenario. Ourapproach extends previous high-fidelity dual control simulations to hardwareexperiments, which may be viewed at https://youtu.be/Q_JdZuopGL4, and verifiesbehavior inference in human-driven traffic scenarios, moving beyond idealizedmodels. The results show improvements in adaptive planning under uncertainty,advancing the field of interactive decision-making for real-world applications.</description>
      <author>example@mail.com (Jacob Knaup, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Panagiotis Tsiotras)</author>
      <guid isPermaLink="false">2502.09918v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos</title>
      <link>http://arxiv.org/abs/2502.09886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Video2Policy是一个基于互联网上RGB视频的框架，通过模仿日常人类行为来生成模拟任务，并利用大型语言模型生成奖励函数进行强化学习。&lt;h4&gt;背景&lt;/h4&gt;现有的方法要么依赖于可能产生不适用于机器人领域的大型语言模型，要么使用难以扩展且需要真实世界与模拟精确对齐的数字双胞胎。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架Video2Policy，以解决现有数据生成问题，并成功训练复杂的机器人任务策略。&lt;h4&gt;方法&lt;/h4&gt;该方法包含两个阶段：（1）从视频中在模拟环境中生成任务；（2）利用大型语言模型迭代地产生奖励函数进行强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;使用SSv2数据集中的100多个视频，成功训练了9个不同复杂度的机器人任务策略，包括投掷等挑战性任务。&lt;h4&gt;结论&lt;/h4&gt;Video2Policy框架不仅可以生成大规模模拟数据来培训通用策略，还可以通过Real2Sim2Real的方式将其应用于实际机器人上。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了一种新的基于互联网视频的数据生成方法，旨在通过模仿人类行为训练复杂和多样化的机器学习任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation offers a promising approach for cheaply scaling training data forgeneralist policies. To scalably generate data from diverse and realistictasks, existing algorithms either rely on large language models (LLMs) that mayhallucinate tasks not interesting for robotics; or digital twins, which requirecareful real-to-sim alignment and are hard to scale. To address thesechallenges, we introduce Video2Policy, a novel framework that leveragesinternet RGB videos to reconstruct tasks based on everyday human behavior. Ourapproach comprises two phases: (1) task generation in simulation from videos;and (2) reinforcement learning utilizing in-context LLM-generated rewardfunctions iteratively. We demonstrate the efficacy of Video2Policy byreconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,which depicts diverse and complex human behaviors on 9 different tasks. Ourmethod can successfully train RL policies on such tasks, including complex andchallenging tasks such as throwing. Finally, we show that the generatedsimulation data can be scaled up for training a general policy, and it can betransferred back to the real robot in a Real2Sim2Real way.</description>
      <author>example@mail.com (Weirui Ye, Fangchen Liu, Zheng Ding, Yang Gao, Oleh Rybkin, Pieter Abbeel)</author>
      <guid isPermaLink="false">2502.09886v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Determining angle of arrival of radio frequency fields using subwavelength, amplitude-only measurements of standing waves in a Rydberg atom sensor</title>
      <link>http://arxiv.org/abs/2502.09835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深亚波长射频成像技术使用原子里德堡传感器克服了传统天线的基本限制，并实现了超宽带全向时间变化场检测，且结构紧凑。&lt;h4&gt;目的&lt;/h4&gt;展示一种新型的里德堡传感器用于角度到达（AoA）测量，该方法利用亚波长驻波场成像，无需额外的强射频相位参考场即可确定入射角。&lt;h4&gt;方法&lt;/h4&gt;通过在里德堡单元内放置一块金属板来实现独立于传入RF场强度的角度定位，并进行精密角度到达（AoA）测量。使用机器人天线定位系统对4.2GHz、5.0GHz和5.7GHz信号进行了测量。&lt;h4&gt;主要发现&lt;/h4&gt;实现了1.7度的极角分辨率从0到60度AoA，以及在整个可能的角度范围内4.1度的分辨率。&lt;h4&gt;结论&lt;/h4&gt;这种方法为高精度角度到达（AoA）测量提供了一种新的途径，且在无需额外RF相位参考场的情况下具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;深亚波长射频成像技术通过原子里德堡传感器克服了传统天线的基本限制，并实现了超宽带全向时间变化场检测，结构紧凑。在此基础上，我们展示了一种用于角度到达（AoA）测量的新型里德堡传感器，该方法利用亚波长驻波场成像，并且无需额外的强射频相位参考场即可确定入射角。通过在里德堡单元内放置一块金属板来实现独立于传入RF场强度的角度定位，并进行精密角度到达（AoA）测量，使用机器人天线定位系统对4.2GHz、5.0GHz和5.7GHz信号进行了测试。实现了1.7度的极角分辨率从0到60度AoA，以及在整个可能的角度范围内4.1度的分辨率。这种方法为高精度角度到达（AoA）测量提供了一种新的途径，且在无需额外RF相位参考场的情况下具有鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep subwavelength RF imaging with atomic Rydberg sensors has overcomefundamental limitations of traditional antennas and enabled ultra-widebanddetection of omni-directional time varying fields all in a compact form factor.However, in most applications, Rydberg sensors require the use of a secondarystrong RF reference field to serve as a phase reference. Here, we demonstrate anew type of Rydberg sensor for angle-of-arrival (AoA) sensing which utilizessubwavelength imaging of standing wave fields. By placing a metallic platewithin the Rydberg cell, we can determine the AoA independent of the strengthof incoming RF field and without requiring a secondary strong RF phasereference field. We perform precision AoA measurements with a robotic antennapositioning system for 4.2, 5.0, and 5.7 GHz signals and demonstrate a 1.7 degpolar angular resolution from 0 deg to 60 deg AoA and 4.1 deg over all possibleangles.</description>
      <author>example@mail.com (Rajavardhan Talashila, William J. Watterson, Benjamin L. Moser, Joshua A. Gordon, Alexandra B. Artusio-Glimpse, Nikunjkumar Prajapati, Noah Schlossberger, Matthew T. Simons, Christopher L. Holloway)</author>
      <guid isPermaLink="false">2502.09835v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection</title>
      <link>http://arxiv.org/abs/2502.09829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估机器人控制策略性能的新框架，通过建模所有任务和策略上的机器人表现分布来减少实验成本，并使用自然语言作为先验知识提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;评估机器人的控制政策需要花费大量的人力物力资源。随着任务数量的增加以及新的控制政策的不断产生，传统方法变得越来越难以执行。&lt;h4&gt;目的&lt;/h4&gt;通过将机器人评估问题看作主动测试问题来减少实验者的工作量，并提供准确可靠的评价结果。&lt;h4&gt;方法&lt;/h4&gt;利用连续执行试验的方式建模机器人性能在所有任务和策略上的分布。提出了一种基于成本意识的期望信息增益启发式算法，以选择最具有信息价值的试验。&lt;h4&gt;主要发现&lt;/h4&gt;该框架可以有效地减少评估多个任务上机器人控制政策的成本，并且能够处理连续或离散性的表现结果。&lt;h4&gt;结论&lt;/h4&gt;通过优先考虑有信息量的试验来优化机器人性能评价的过程，从而节省了计算成本。实验表明这种方法在真实机器人的数据和模拟环境中都具有较高的有效性。&lt;h4&gt;翻译&lt;/h4&gt;评估已学习到的机器人控制策略以确定其物理任务级别能力的成本很高，因为这需要花费大量的人力物力资源。随着政策数量和任务数量的增长，这个问题变得越来越严重。盲目选择随机的任务子集进行测试是一种高成本且结果不可靠的方法。在此研究中，我们提出将机器人评估作为主动测试问题来解决这一挑战。我们将所有任务和策略上的机器人表现分布建模为一系列试验执行的结果，并利用自然语言中的先验知识揭示任务间的潜在关系以提高模型效率。通过使用基于成本意识的期望信息增益启发式算法选择最具有信息价值的试验，我们能够显著降低实验者的工作量。在真实机器人的数据和模拟环境中进行的实验证明了该框架的有效性，并且其可以适用于连续或离散性的表现结果评价任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Evaluating learned robot control policies to determine their physicaltask-level capabilities costs experimenter time and effort. The growing numberof policies and tasks exacerbates this issue. It is impractical to test everypolicy on every task multiple times; each trial requires a manual environmentreset, and each task change involves re-arranging objects or even changingrobots. Naively selecting a random subset of tasks and policies to evaluate isa high-cost solution with unreliable, incomplete results. In this work, weformulate robot evaluation as an active testing problem. We propose to modelthe distribution of robot performance across all tasks and policies as wesequentially execute experiments. Tasks often share similarities that canreveal potential relationships in policy behavior, and we show that naturallanguage is a useful prior in modeling these relationships between tasks. Wethen leverage this formulation to reduce the experimenter effort by using acost-aware expected information gain heuristic to efficiently selectinformative trials. Our framework accommodates both continuous and discreteperformance outcomes. We conduct experiments on existing evaluation data fromreal robots and simulations. By prioritizing informative trials, our frameworkreduces the cost of calculating evaluation metrics for robot policies acrossmany tasks.</description>
      <author>example@mail.com (Abrar Anwar, Rohan Gupta, Zain Merchant, Sayan Ghosh, Willie Neiswanger, Jesse Thomason)</author>
      <guid isPermaLink="false">2502.09829v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>PUGS: Perceptual Uncertainty for Grasp Selection in Underwater Environments</title>
      <link>http://arxiv.org/abs/2502.09824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures Accepted to International Conference on Robotics  and Automation (ICRA) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的方法来量化和表示三维重建中的感知不确定性，并将其应用于水下环境下的自主抓取选择。&lt;h4&gt;背景&lt;/h4&gt;在感官信息不完善且不完整的环境中，机器人必须做出考虑这些缺点的决策。&lt;h4&gt;目的&lt;/h4&gt;开发一种框架将这种感知不确定性纳入到水下环境中自动抓取的选择中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通过占用不确定估计来量化和表示三维重建中的感知不确定性的方法，并将其传播到了多视图重建过程中的抓取选择过程中，而不是在决定从何处抓取时平等对待每个测量值。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，考虑不确定性后，抓取选择对于部分信息和噪声更加鲁棒。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以提高机器人在复杂环境下的感知精度和操作性能。&lt;h4&gt;翻译&lt;/h4&gt;当处理感官信息不完善且不完整的挑战性环境时，机器人必须做出决策以应对这些缺点。本文提出了一种新的方法来量化并表示这种三维重建中的感知不确定性，并开发了一个框架将其应用于水下环境中自动抓取选择。我们的研究不仅在模拟数据上，在真实世界的数据中也得到了验证：通过考虑不确定性的因素，使得抓取的选择面对部分信息和噪声时更加稳健有效。相关代码将在https://onurbagoren.github.io/PUGS/提供访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When navigating and interacting in challenging environments where sensoryinformation is imperfect and incomplete, robots must make decisions thataccount for these shortcomings. We propose a novel method for quantifying andrepresenting such perceptual uncertainty in 3D reconstruction through occupancyuncertainty estimation. We develop a framework to incorporate it into graspselection for autonomous manipulation in underwater environments. Instead oftreating each measurement equally when deciding which location to grasp from,we present a framework that propagates uncertainty inherent in the multi-viewreconstruction process into the grasp selection. We evaluate our method withboth simulated and the real world data, showing that by accounting foruncertainty, the grasp selection becomes robust against partial and noisymeasurements. Code will be made available athttps://onurbagoren.github.io/PUGS/</description>
      <author>example@mail.com (Onur Bagoren, Marc Micatka, Katherine A. Skinner, Aaron Marburg)</author>
      <guid isPermaLink="false">2502.09824v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Suture Thread Modeling Using Control Barrier Functions for Autonomous Surgery</title>
      <link>http://arxiv.org/abs/2502.09813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for 2025 IEEE International Conference on Robotics and  Automation (ICRA). Supplementary video:  https://www.youtube.com/watch?v=qO-nroi4Faw&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种使用控制屏障函数（CBFs）的新方法，用于模拟缝合线的动态特性，实现了现实性和计算效率的结合。&lt;h4&gt;背景&lt;/h4&gt;自动化的外科系统能提高手术精度和安全性，减少高风险环境中的人员参与。然而，在像缝合这样的自动化手术程序中准确建模缝合线是一个挑战，因为现有的模型要么缺乏安全关键过程所需的准确性，要么过于复杂而无法实时执行。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来模拟缝合线的动态特性，这种方法既真实又计算效率高，适用于自动化的外科系统和虚拟现实手术训练系统。&lt;h4&gt;方法&lt;/h4&gt;使用控制屏障函数（CBFs）和控制李雅普诺夫函数（CLF）框架统一建模类似丝状的行为、碰撞避免、刚度和阻尼。&lt;h4&gt;主要发现&lt;/h4&gt;该模型简化了复杂力的计算或微分方程的求解，大大减少了计算负担，并且保持了一种适合自动化系统和虚拟现实训练系统的现实模型。此外，通过提供基于缝合线与环境交互产生的视觉提示来增强用户体验。&lt;h4&gt;结论&lt;/h4&gt;提出的模型在微创磁性缝合手术系统中进行了测试，该系统使用磁场操纵缝合针，为外科手术提供了一个更少侵入性的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;自动化外科系统的应用提高了精度和安全性，并减少了高风险环境中的人员参与。然而，在像缝合这样的自动化的手术程序中准确建模缝合线是一个挑战，因为现有的模型要么缺乏安全关键过程所需的准确性，要么过于复杂而无法实时执行。在这项研究中，我们提出了一种使用控制屏障函数（CBFs）的新方法来模拟缝合线的动态特性，实现了现实性和计算效率的结合。这种新方法不需要复杂的力或微分方程求解，在保持真实模型的同时显著降低了计算负担，并适用于自动化系统和虚拟现实手术训练系统。此外，该框架还允许根据缝合线与环境的交互提供视觉提示，增强用户体验进行缝合或结扎任务时的体验。提出的模型已在微创磁性缝合平台中进行了测试，这是一个使用磁场操纵缝合针进行外科操作的非侵入性解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automating surgical systems enhances precision and safety while reducinghuman involvement in high-risk environments. A major challenge in automatingsurgical procedures like suturing is accurately modeling the suture thread, ahighly flexible and compliant component. Existing models either lack theaccuracy needed for safety critical procedures or are too computationallyintensive for real time execution. In this work, we introduce a novel approachfor modeling suture thread dynamics using control barrier functions (CBFs),achieving both realism and computational efficiency. Thread like behavior,collision avoidance, stiffness, and damping are all modeled within a unifiedCBF and control Lyapunov function (CLF) framework. Our approach eliminates theneed to calculate complex forces or solve differential equations, significantlyreducing computational overhead while maintaining a realistic model suitablefor both automation and virtual reality surgical training systems. Theframework also allows visual cues to be provided based on the thread'sinteraction with the environment, enhancing user experience when performingsuture or ligation tasks. The proposed model is tested on the MagnetoSuturesystem, a minimally invasive robotic surgical platform that uses magneticfields to manipulate suture needles, offering a less invasive solution forsurgical procedures.</description>
      <author>example@mail.com (Kimia Forghani, Suraj Raval, Lamar Mair, Axel Krieger, Yancy Diaz-Mercado)</author>
      <guid isPermaLink="false">2502.09813v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Vision-based Geo-Localization of Future Mars Rotorcraft in Challenging Illumination Conditions</title>
      <link>http://arxiv.org/abs/2502.09795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;行星探索利用空中资产有可能在火星上实现前所未有的科学发现。&lt;h4&gt;背景&lt;/h4&gt;NASA的火星直升机'机智号'证明了在火星大气中飞行是可能的，但未来的火星旋翼飞机需要先进的导航能力来完成长距离飞行。其中一个重要能力就是基于地图定位（MbL），它通过将机载图像与参考地图进行匹配以减少视觉里程计带来的累积漂移。&lt;h4&gt;目的&lt;/h4&gt;研究一个新的基于地图定位系统并提出Geo-LoFTR，这是一种在光照差异显著的情况下更具鲁棒性的图像配准深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;该系统由一个自定义的模拟框架支持，使用真实的轨道图来生成大量现实的火星地形图像。这些图像被用来测试和评估新的MbL系统的性能。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的系统在光照变化和尺度差异显著的情况下定位准确性超过了以前的方法。&lt;h4&gt;结论&lt;/h4&gt;通过在一个仿真的火星日中验证了该方法的有效性，证明了Geo-LoFTR能够为未来的火星旋翼飞机提供更可靠的导航支持。&lt;h4&gt;翻译&lt;/h4&gt;行星探索使用空中资产有潜力在火星上带来前所未有的科学发现。尽管NASA的火星直升机'机智号'证实了火星大气层中的飞行是可行的，但未来火星旋翼飞机将需要先进的导航能力来完成长距离飞行。其中一种重要能力是基于地图定位（MbL），该方法通过在飞行中将机载图像与参考地图进行匹配以减少视觉里程计带来的累积漂移。然而，传统基于地图定位系统受到旋翼飞机观测和参考图之间光照差异的影响，限制了车辆的运行窗口。本文调查了一种新的基于地图定位系统，并提出了一种Geo-LoFTR模型，这是一种通过几何辅助实现图像配准的深度学习方法，在显著照明变化下比之前的方法更具鲁棒性。该系统支持自定义模拟框架，使用真实轨道图生成大量现实火星地形图像。全面评估表明我们的新系统在光照和尺度变化中超过了以前的基于地图定位工作，同时展示了其在仿真的火星日中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Planetary exploration using aerial assets has the potential for unprecedentedscientific discoveries on Mars. While NASA's Mars helicopter Ingenuity provedflight in Martian atmosphere is possible, future Mars rotocrafts will requireadvanced navigation capabilities for long-range flights. One such criticalcapability is Map-based Localization (MbL) which registers an onboard image toa reference map during flight in order to mitigate cumulative drift from visualodometry. However, significant illumination differences between rotocraftobservations and a reference map prove challenging for traditional MbL systems,restricting the operational window of the vehicle. In this work, we investigatea new MbL system and propose Geo-LoFTR, a geometry-aided deep learning modelfor image registration that is more robust under large illumination differencesthan prior models. The system is supported by a custom simulation frameworkthat uses real orbital maps to produce large amounts of realistic images of theMartian terrain. Comprehensive evaluations show that our proposed systemoutperforms prior MbL efforts in terms of localization accuracy undersignificant lighting and scale variations. Furthermore, we demonstrate thevalidity of our approach across a simulated Martian day.</description>
      <author>example@mail.com (Dario Pisanti, Robert Hewitt, Roland Brockers, Georgios Georgakis)</author>
      <guid isPermaLink="false">2502.09795v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Teaming in Multi-Drone Pursuit: Simulation, Training, and Deployment</title>
      <link>http://arxiv.org/abs/2502.09762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AT-MDP框架，该框架旨在解决多无人机协同追捕任务中的自适应团队合作问题。&lt;h4&gt;背景&lt;/h4&gt;当前关于机器人在未预先协调的情况下与未知队友协作的能力（即自适应团队合作）的研究还较为不足。特别是在边境监控、搜索救援和反恐等领域中需要实时调整策略以应对环境变化的场景，这种能力尤为重要。&lt;h4&gt;目的&lt;/h4&gt;定义并正式化了自适应多无人机追捕问题，并开发了一套包括仿真、算法训练与现实世界部署在内的综合框架AT-MDP。&lt;h4&gt;方法&lt;/h4&gt;构建了一个灵活的实验配置器和仿真接口；提供了一个分布式的算法培训框架，其中包括两个新提出的基线方法以及一个用于评估自适应团队合作能力的未见过无人机集合；并且实现了一套利用边缘计算和Crazyflie无人机的真实世界部署系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过四个不同难度级别的多无人机追捕环境中的广泛实验验证了AT-MDP框架的有效性，且在实际物理系统的部署进一步证明其可行性。&lt;h4&gt;结论&lt;/h4&gt;AT-MDP框架是首个针对复杂现实环境中连续动作决策问题的自适应框架，它使多个无人机能够与未知队友有效协调。这为解决实际应用中多机器人协作挑战提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;自适应团队合作能力是指无需预先协调的情况下能够与其他未知队员进行协同工作的能力，在多机器人协作领域内仍是一个有待探索的问题。本文专注于研究在如边境监控、搜索救援及反恐等现实任务中的多无人机协同追捕情境下的这种自适应能力，并提出了AT-MDP框架，它集成了仿真、算法训练以及实际部署三个部分，旨在提升无人机的协调能力和应对复杂环境变化的能力。实验结果表明该框架不仅在模拟环境中表现良好，在真实世界的应用中也具有可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptive teaming, the ability to collaborate with unseen teammates withoutprior coordination, remains an underexplored challenge in multi-robotcollaboration. This paper focuses on adaptive teaming in multi-dronecooperative pursuit, a critical task with real-world applications such asborder surveillance, search-and-rescue, and counter-terrorism. We first defineand formalize the \textbf{A}daptive Teaming in \textbf{M}ulti-\textbf{D}rone\textbf{P}ursuit (AT-MDP) problem and introduce AT-MDP framework, acomprehensive framework that integrates simulation, algorithm training andreal-world deployment. AT-MDP framework provides a flexible experimentconfigurator and interface for simulation, a distributed training frameworkwith an extensive algorithm zoo (including two newly proposed baseline methods)and an unseen drone zoo for evaluating adaptive teaming, as well as areal-world deployment system that utilizes edge computing and Crazyflie drones.To the best of our knowledge, AT-MDP framework is the first adaptive frameworkfor continuous-action decision-making in complex real-world drone tasks,enabling multiple drones to coordinate effectively with unseen teammates.Extensive experiments in four multi-drone pursuit environments of increasingdifficulty confirm the effectiveness of AT-MDP framework, while real-worlddeployments further validate its feasibility in physical systems. Videos andcode are available at https://sites.google.com/view/at-mdp.</description>
      <author>example@mail.com (Yang Li, Junfan Chen, Feng Xue, Jiabin Qiu, Wenbin Li, Qingrui Zhang, Ying Wen, Wei Pan)</author>
      <guid isPermaLink="false">2502.09762v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning Pipeline via Voting</title>
      <link>http://arxiv.org/abs/2502.09749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to RSS24-W: TaskSpec&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文提出了一种新的投票树规划器(Vote-Tree-Planner)，该策略通过在决策过程中使用投票来指导计划遍历，以此减少LLM的重复查询，提高任务规划系统的执行效率和可靠性。&lt;h4&gt;背景&lt;/h4&gt;目前将大型语言模型（LLMs）集成到闭环机器人任务规划中越来越流行。然而，之前的尝试主要集中在利用LLMs强大的推理能力上，而忽视了由于反复向LLMs进行查询而导致的任务规划效率低下。&lt;h4&gt;目的&lt;/h4&gt;论文旨在通过最小化冗余并提高规划有效性来促进LLM和任务规划系统之间的协同作用。&lt;h4&gt;方法&lt;/h4&gt;基于Prog-Prompt和高级概念的Tree-Planner，研究提出了Vote-Tree-Planner这一采样策略，利用投票机制在决策过程中引导计划遍历。该方法通过给代理分配权重来进行路径评估，以提高成功率并减少LLM查询次数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在未见过的数据集中，与基线方法相比，新的Vote-Tree-Planner表现出更高的稳定性和成功平均率以及目标条件召回率。&lt;h4&gt;结论&lt;/h4&gt;论文的研究结果强调了投票树规划器在基于大型语言模型的计划系统中提高计划准确性、可靠性和效率方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;将大语言模型（LLMs）整合到闭环机器人任务规划中，通过利用这些模型的强大推理能力来改进任务规划性能变得越来越流行。然而，在此过程中往往忽略了由于频繁查询LLM而导致的任务执行效率和可操作性问题。本文探讨了LLM与任务规划系统之间的协同作用，旨在减少冗余并提高计划有效性。基于Prog-Prompt和高级概念的Tree-Planner，我们提出了Vote-Tree-Planner这一采样策略，在决策过程中利用投票机制指导路径遍历。这种方法允许在执行前评估关键路径，并通过简单的投票树构造进一步提高了成功率并减少了LLM查询次数。实验结果表明，我们的Vote-Tree-Planner表现出更好的稳定性，在未见过的数据集中展示了更高的平均成功和目标条件召回率，这比之前的基线方法更为优越。这些发现强调了Vote-Tree-Planner在提高基于大型语言模型的规划系统准确度、可靠性和效率方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating large language models (LLMs) into closed-loop robotic taskplanning has become increasingly popular within embodied artificialintelligence. Previous efforts mainly focused on leveraging the strongreasoning abilities of LLMs to enhance task planning performance while oftenoverlooking task planning efficiency and executability due to repetitivequeries to LLMs. This paper addresses the synergy between LLMs and taskplanning systems, aiming to minimize redundancy while enhancing planningeffectiveness. Specifically, building upon Prog-Prompt and the high-levelconcept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategyutilizes votes to guide plan traversal during the decision-making process. Ourapproach is motivated by a straightforward observation: assigning weights toagents during decision-making enables the evaluation of critical paths beforeexecution. With this simple vote-tree construction, our method further improvesthe success rate and reduces the number of queries to LLMs. The experimentalresults highlight that our Vote-Tree-Planner demonstrates greater stability andshows a higher average success rate and goal condition recall on the unseendataset compared with previous baseline methods. These findings underscore thepotential of the Vote-Tree-Planner to enhance planning accuracy, reliability,and efficiency in LLM-based planning systems.</description>
      <author>example@mail.com (Chaoyuan Zhang, Zhaowei Li, Wentao Yuan)</author>
      <guid isPermaLink="false">2502.09749v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Perch like a bird: bio-inspired optimal maneuvers and nonlinear control for Flapping-Wing Unmanned Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2502.09728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究旨在设计扑翼机器人（ornithopter）的着陆动作和控制系统，通过分析飞行动态、反馈回路及环境约束之间的相互作用，以期提升对鸟类着陆机制的理解，并开发出一种模仿鸟类优美控制策略的最佳操作方式及其控制器。&lt;h4&gt;背景&lt;/h4&gt;现有的扑翼机器人的研究需要更好的理解和优化其在复杂环境中的着陆能力，尤其关注如何模仿自然界中鸟类的精确和优雅的飞行控制。&lt;h4&gt;目的&lt;/h4&gt;通过分析飞行动力学、反馈回路以及环境约束之间的动态交互作用，旨在设计出一种能够实现稳定着陆的最佳操作方式及其控制器，并探讨这种适应性行为在控制系统中的体现。&lt;h4&gt;方法&lt;/h4&gt;采用解析优化问题的方法来最小化着陆时的速度，在给定的运动和动态约束条件下求解。开发了非线性的、自适应的扑翼频率及尾部对称偏转的控制策略，确保稳定着陆的同时具备较强的抗扰能力。&lt;h4&gt;主要发现&lt;/h4&gt;所设计的操作方式包含减速以及快速的垂直转向动作；验证并确认这些自主式的着陆操作能够与文献中报告的真实鸟类着陆轨迹高度一致。&lt;h4&gt;结论&lt;/h4&gt;研究为未来模仿鸟类高效着陆机制的扑翼机器人原型开发奠定了坚实的理论基础，其控制策略在复杂环境下的稳定性和适应性得到了显著提升。&lt;h4&gt;翻译&lt;/h4&gt;这项研究致力于设计仿鸟飞行器（ornithopter）的栖息动作和控制系统。通过分析飞行动态、反馈回路与环境约束之间的相互作用，本研究旨在深化对鸟类着陆机制的理解，并开发出能够实现稳定着陆的最佳操作方式及其控制器。控制策略是根据最小化速度的优化问题，在给定的动力学限制下求解得出，并且具有非线性和自适应性以确保在复杂情况下的稳定性。这种基于家系统原理的适应性行为增强了机器人对未预料干扰的抵抗能力，同时能保持着陆过程中的稳定姿态。所提出的自主式着陆操作——闭环下降和转向动作，在验证中显示出与文献报道的真实鸟类着陆轨迹高度一致。本研究结果为开发未来的仿鸟飞行器原型提供了理论基础，其将能够更加精准地模仿鸟类的栖息技巧。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research endeavors to design the perching maneuver and control inornithopter robots. By analyzing the dynamic interplay between the robot'sflight dynamics, feedback loops, and the environmental constraints, we aim toadvance our understanding of the perching maneuver, drawing parallels tobiological systems. Inspired by the elegant control strategies observed inavian flight, we develop an optimal maneuver and a corresponding controller toachieve stable perching. The maneuver consists of a deceleration and a rapidpitch-up (vertical turn), which arises from analytically solving theoptimization problem of minimal velocity at perch, subject to kinematic anddynamic constraints. The controller for the flapping frequency and tailsymmetric deflection is nonlinear and adaptive, ensuring robustly stableperching. Indeed, such adaptive behavior in a sense incorporates homeostaticprinciples of cybernetics into the control system, enhancing the robot'sability to adapt to unexpected disturbances and maintain a stable postureduring the perching maneuver. The resulting autonomous perching maneuvers --closed-loop descent and turn -- , have been verified and validated,demonstrating excellent agreement with real bird perching trajectories reportedin the literature. These findings lay the theoretical groundwork for thedevelopment of future prototypes that better imitate the skillful perchingmaneuvers of birds.</description>
      <author>example@mail.com (C. Ruiz, J. Á. Acosta)</author>
      <guid isPermaLink="false">2502.09728v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Contrastive Block Disentanglement</title>
      <link>http://arxiv.org/abs/2502.07281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据集通常结合了在不同实验条件下收集的数据，这虽然增加了数据量，但也引入了虚假关联，使得难以建模感兴趣的变量。&lt;h4&gt;目的&lt;/h4&gt;提出一种算法来分离现象和虚假关联，并确保模型对环境变化具有不变性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种称为监督对比阻塞解耦（SCBD）的算法，该算法基于纯粹的监督对比学习，能够有效实现这种不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了SCBD在域泛化和批次校正问题上的有效性。通过引入一个超参数α来控制对环境变量e的不变性的程度，并且当增加α以增强不变性时，模型的分布外性能会有所提升但可能会损害其分布内性能。&lt;h4&gt;结论&lt;/h4&gt;提出的SCBD算法优于现有方法，在合成数据集和实际问题（如Camelyon17-WILDS）上均表现出色。该方法可以用于保持生物信号并去除单细胞扰动中的批次效应。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的机器学习方法，旨在解决现实中数据集中存在的虚假关联问题，并提出了一种通过分离现象和虚假关联来提高模型鲁棒性的算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world datasets often combine data collected under different experimentalconditions. This yields larger datasets, but also introduces spuriouscorrelations that make it difficult to model the phenomena of interest. Weaddress this by learning two embeddings to independently represent thephenomena of interest and the spurious correlations. The embedding representingthe phenomena of interest is correlated with the target variable $y$, and isinvariant to the environment variable $e$. In contrast, the embeddingrepresenting the spurious correlations is correlated with $e$. The invarianceto $e$ is difficult to achieve on real-world datasets. Our primary contributionis an algorithm called Supervised Contrastive Block Disentanglement (SCBD) thateffectively enforces this invariance. It is based purely on SupervisedContrastive Learning, and applies to real-world data better than existingapproaches. We empirically validate SCBD on two challenging problems. The firstproblem is domain generalization, where we achieve strong performance on asynthetic dataset, as well as on Camelyon17-WILDS. We introduce a singlehyperparameter $\alpha$ to control the degree of invariance to $e$. When weincrease $\alpha$ to strengthen the degree of invariance, out-of-distributionperformance improves at the expense of in-distribution performance. The secondproblem is batch correction, in which we apply SCBD to preserve biologicalsignal and remove inter-well batch effects when modeling single-cellperturbations from 26 million Optical Pooled Screening images.</description>
      <author>example@mail.com (Taro Makino, Ji Won Park, Natasa Tagasovska, Takamasa Kudo, Paula Coelho, Jan-Christian Huetter, Heming Yao, Burkhard Hoeckendorf, Ana Carolina Leote, Stephen Ra, David Richmond, Kyunghyun Cho, Aviv Regev, Romain Lopez)</author>
      <guid isPermaLink="false">2502.07281v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
  <item>
      <title>Foundation Neural-Network Quantum States</title>
      <link>http://arxiv.org/abs/2502.09488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型是高度灵活的神经网络架构，能够处理不同类型的输入数据（如文本和图像），并且在多种任务上具有泛化能力（例如分类和生成）。&lt;h4&gt;目的&lt;/h4&gt;受此成功启发，提出了Foundation Neural-Network Quantum States (FNQS)，这是一个用于研究量子多体系统的集成范式。&lt;h4&gt;方法&lt;/h4&gt;FNQS利用基础模型的关键原则来定义基于单一、灵活架构的变分波函数，该架构能够处理包括自旋配置和哈密顿量物理耦合在内的多种输入模式。与为特定哈密顿量定制的专业架构不同，FNQS可以泛化到训练过程中未曾遇到的其他物理系统。&lt;h4&gt;主要发现&lt;/h4&gt;FNQS使传统方法难以计算或计算成本高昂的一些量（如无序平均可观测值）的有效估计成为可能，并且易于获得保真度易感性以揭示量子相变，而无需事先了解顺序参数。&lt;h4&gt;结论&lt;/h4&gt;这些预训练模型可以高效地针对特定的量子系统进行微调。论文中所使用的架构可以在Hugging Face上公开访问：https://huggingface.co/nqs-models，并附有使用NetKet实现这些神经网络的例子。&lt;h4&gt;翻译&lt;/h4&gt;基础模型是能够处理多种数据类型（如文本和图像）并能跨多个任务泛化的灵活的神经网络结构。受此启发，我们提出了Foundation Neural-Network Quantum States (FNQS)，这是一种用于研究量子多体系统的一体化方法。FNQS利用基础模型的关键原则来定义基于单一、多功能架构的变分波函数，该架构可以处理包括自旋配置和哈密顿量物理耦合在内的多模态输入。与针对特定哈密顿量定制的专业结构不同，FNQS能够泛化到训练过程中未曾遇到的新物理系统，提供了一种适用于各种量子系统的统一框架。此外，FNQS可以高效地估计传统方法难以计算或成本高昂的某些量（如无序平均观测值），并且很容易获得保真度易感性来揭示量子相变，而无需事先了解顺序参数。这些预训练模型可以针对特定量子系统进行高效的微调。本文使用的架构可以在https://huggingface.co/nqs-models公开获取，并附有使用NetKet实现该神经网络的示例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are highly versatile neural-network architectures capableof processing different data types, such as text and images, and generalizingacross various tasks like classification and generation. Inspired by thissuccess, we propose Foundation Neural-Network Quantum States (FNQS) as anintegrated paradigm for studying quantum many-body systems. FNQS leverage keyprinciples of foundation models to define variational wave functions based on asingle, versatile architecture that processes multimodal inputs, including spinconfigurations and Hamiltonian physical couplings. Unlike specializedarchitectures tailored for individual Hamiltonians, FNQS can generalize tophysical Hamiltonians beyond those encountered during training, offering aunified framework adaptable to various quantum systems and tasks. FNQS enablethe efficient estimation of quantities that are traditionally challenging orcomputationally intensive to calculate using conventional methods, particularlydisorder-averaged observables. Furthermore, the fidelity susceptibility can beeasily obtained to uncover quantum phase transitions without prior knowledge oforder parameters. These pretrained models can be efficiently fine-tuned forspecific quantum systems. The architectures trained in this paper are publiclyavailable at https://huggingface.co/nqs-models, along with examples forimplementing these neural networks in NetKet.</description>
      <author>example@mail.com (Riccardo Rende, Luciano Loris Viteritti, Federico Becca, Antonello Scardicchio, Alessandro Laio, Giuseppe Carleo)</author>
      <guid isPermaLink="false">2502.09488v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Reinforcement Learning for Optimization in Automation</title>
      <link>http://arxiv.org/abs/2502.09417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 tables, and 1 figure. Accepted at IEEE 20th International  Conference on Automation Science and Engineering (CASE) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇综述文章探讨了强化学习在自动化领域中的当前应用及未来发展方向。&lt;h4&gt;背景&lt;/h4&gt;强化学习作为解决复杂优化挑战的重要工具，在自动化的多个方面已经取得了显著进展。本文集中于制造业、能源系统和机器人技术三大领域的研究现状，同时讨论了各个领域内的前沿方法以及存在的重大挑战。&lt;h4&gt;目的&lt;/h4&gt;本论文旨在分析自动化中强化学习驱动的优化方法的优势与限制，并指出现有挑战，为未来的研究提供方向。&lt;h4&gt;方法&lt;/h4&gt;文章首先回顾强化学习在制造、能源系统和机器人技术中的应用情况，然后探讨了这些领域内存在的问题以及未来的研究趋势。&lt;h4&gt;主要发现&lt;/h4&gt;文中指出了一些普遍遇到的问题，例如样本效率与可扩展性；安全性及鲁棒性；可解释性和可信度；迁移学习与元学习；真实场景部署等。此外，文章还展望了解决这些问题的潜在策略和未来的研究途径。&lt;h4&gt;结论&lt;/h4&gt;该综述总结了强化学习在自动化优化中的重要角色，并为研究人员提供了相关文献资源列表，有助于探索这一研究领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已提供翻译内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CASE59546.2024.10711718&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) has become a critical tool for optimizationchallenges within automation, leading to significant advancements in severalareas. This review article examines the current landscape of RL withinautomation, with a particular focus on its roles in manufacturing, energysystems, and robotics. It discusses state-of-the-art methods, major challenges,and upcoming avenues of research within each sector, highlighting RL's capacityto solve intricate optimization challenges. The paper reviews the advantagesand constraints of RL-driven optimization methods in automation. It points outprevalent challenges encountered in RL optimization, including issues relatedto sample efficiency and scalability; safety and robustness; interpretabilityand trustworthiness; transfer learning and meta-learning; and real-worlddeployment and integration. It further explores prospective strategies andfuture research pathways to navigate these challenges. Additionally, the surveyincludes a comprehensive list of relevant research papers, making it anindispensable guide for scholars and practitioners keen on exploring thisdomain.</description>
      <author>example@mail.com (Ahmad Farooq, Kamran Iqbal)</author>
      <guid isPermaLink="false">2502.09417v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Potential of Encoder-free Architectures in 3D LMMs</title>
      <link>http://arxiv.org/abs/2502.09620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is released at https://github.com/Ivan-Tang-3D/ENEL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次全面研究了无编码器架构在三维理解场景中的应用潜力，提出了一种新颖的Encoder-free 3D LMM（ENEL），该模型在不使用传统编码器的情况下，在分类、描述和视觉问答任务上取得了与现有最佳模型相当的表现。&lt;h4&gt;背景&lt;/h4&gt;虽然无编码器架构已在二维视觉领域得到初步探索，但它们是否能有效应用于三维理解场景仍然是一个未解的问题。&lt;h4&gt;目的&lt;/h4&gt;探讨无编码器架构在3D Large Multimodal Models（LMMs）中的应用潜力，并克服现有基于编码器模型的挑战。&lt;h4&gt;方法&lt;/h4&gt;{'LLM-embedded Semantic Encoding策略': '提出了语义嵌入自监督损失，探索不同点云自监督损失的效果，并引入混合语义损失以提取高级语义信息。', 'Hierarchical Geometry Aggregation策略': '在指令调优阶段加入层次几何聚合策略，将归纳偏置融入LLM的早期层，使其专注于点云的局部细节。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种名为ENEL的新模型，在7B参数规模下与当前最先进的ShapeLLM-13B模型相比，分别在分类、描述和视觉问答任务上达到了55.0%、50.92%和42.7%的成绩。&lt;h4&gt;结论&lt;/h4&gt;无编码器架构在三维理解领域具有很高的潜力，并可能成为替代现有基于编码器架构的有效方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Encoder-free architectures have been preliminarily explored in the 2D visualdomain, yet it remains an open question whether they can be effectively appliedto 3D understanding scenarios. In this paper, we present the firstcomprehensive investigation into the potential of encoder-free architectures toovercome the challenges of encoder-based 3D Large Multimodal Models (LMMs).These challenges include the failure to adapt to varying point cloudresolutions and the point features from the encoder not meeting the semanticneeds of Large Language Models (LLMs). We identify key aspects for 3D LMMs toremove the encoder and enable the LLM to assume the role of the 3D encoder: 1)We propose the LLM-embedded Semantic Encoding strategy in the pre-trainingstage, exploring the effects of various point cloud self-supervised losses. Andwe present the Hybrid Semantic Loss to extract high-level semantics. 2) Weintroduce the Hierarchical Geometry Aggregation strategy in the instructiontuning stage. This incorporates inductive bias into the LLM early layers tofocus on the local details of the point clouds. To the end, we present thefirst Encoder-free 3D LMM, ENEL. Our 7B model rivals the currentstate-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on theclassification, captioning, and VQA tasks, respectively. Our resultsdemonstrate that the encoder-free architecture is highly promising forreplacing encoder-based architectures in the field of 3D understanding. Thecode is released at https://github.com/Ivan-Tang-3D/ENEL</description>
      <author>example@mail.com (Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao)</author>
      <guid isPermaLink="false">2502.09620v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>FARM: Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation</title>
      <link>http://arxiv.org/abs/2502.09375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种频率感知模型（FARM）用于跨域直播推荐，解决了用户行为稀疏和短视频曝光量远大于直播导致的用户偏好建模困难的问题。&lt;h4&gt;背景&lt;/h4&gt;由于实时互动性和娱乐价值，直播服务吸引了广泛的关注。用户的参与方式包括留言、点赞或发送虚拟礼物等，但这些有价值的行为是零散且难以捕捉的。平台上的主要曝光内容为短视频，其占比远高于直播，这使得直播内容无法充分反映用户偏好。&lt;h4&gt;目的&lt;/h4&gt;提出一种频率感知模型（FARM）解决数据稀疏性问题，并优化跨域推荐系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一个频域内关注模块以及跨领域偏好转换与融合策略。通过离散傅里叶变换，该模型能够捕捉高频率用户行为信息；同时使用对比学习技术进行偏好对齐，并设计一系列定制的注意力机制来融合来自不同领域的用户偏好。&lt;h4&gt;主要发现&lt;/h4&gt;FARM模型在广泛的离线实验和线上A/B测试中均表现出有效性和优越性。它已经在快手直播服务上部署，为数亿用户提供个性化推荐。&lt;h4&gt;结论&lt;/h4&gt;通过频率感知方法和跨域偏好的优化处理，FARM能够更有效地利用稀疏用户行为数据进行精准的直播推荐，并显著提高用户体验。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Live-streaming services have attracted widespread popularity due to theirreal-time interactivity and entertainment value. Users can engage withlive-streaming authors by participating in live chats, posting likes, orsending virtual gifts to convey their preferences and support. However, thelive-streaming services faces serious data-sparsity problem, which can beattributed to the following two points: (1) User's valuable behaviors areusually sparse, e.g., like, comment and gift, which are easily overlooked bythe model, making it difficult to describe user's personalized preference. (2)The main exposure content on our platform is short-video, which is 9 timeshigher than the exposed live-streaming, leading to the inability oflive-streaming content to fully model user preference. To this end, we proposea Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation, termedas FARM. Specifically, we first present the intra-domain frequency aware moduleto enable our model to perceive user's sparse yet valuable behaviors, i.e.,high-frequency information, supported by the Discrete Fourier Transform (DFT).To transfer user preference across the short-video and live-streaming domains,we propose a novel preference align before fuse strategy, which consists of twoparts: the cross-domain preference align module to align user preference inboth domains with contrastive learning, and the cross-domain preference fusemodule to further fuse user preference in both domains using a serious oftailor-designed attention mechanisms. Extensive offline experiments and onlineA/B testing on Kuaishou live-streaming services demonstrate the effectivenessand superiority of FARM. Our FARM has been deployed in online live-streamingservices and currently serves hundreds of millions of users on Kuaishou.</description>
      <author>example@mail.com (Xiaodong Li, Ruochen Yang, Shuang Wen, Shen Wang, Yueyang Liu, Guoquan Wang, Weisong Hu, Qiang Luo, Jiawei Sheng, Tingwen Liu, Jiangxia Cao, Shuang Yang, Zhaojie Liu)</author>
      <guid isPermaLink="false">2502.09375v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures</title>
      <link>http://arxiv.org/abs/2502.09623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种可以处理具有不同架构的NeRF的框架，并展示了如何通过训练图元网络来实现这一目标，从而在未见过的新架构上进行推断。&lt;h4&gt;背景&lt;/h4&gt;Neural Radiance Fields (NeRFs) 已成为表示3D对象和场景的一种突破性范式。现有方法只能处理具有特定预定义架构的NeRF。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以接受多种架构的NeRF并能在训练时未见过的新架构上执行推断的框架。&lt;h4&gt;方法&lt;/h4&gt;通过在表征学习框架中使用图元网络进行训练，并展示了对比目标如何有助于获得不受架构限制的潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基于多层感知机（MLP）和三平面NeRF上的分类和检索任务上表现出色，性能至少与针对单一架构设计的方法相当或更好。&lt;h4&gt;结论&lt;/h4&gt;提出了首个能处理任意架构的NeRF并执行相关任务的方法，通过处理它们的权重来实现这一点。&lt;h4&gt;翻译&lt;/h4&gt;神经辐射场（Neural Radiance Fields, NeRFs）已成为表示3D对象和场景的一种突破性范式，将形状和外观信息编码到神经网络的权重中。最近的研究表明这些权重可以作为输入框架用于解决深度学习任务。然而，现有框架只能处理具有特定预定义架构的NeRF。本文介绍了一种首个能够接受多种架构的NeRF并能在训练时未见过的新架构上执行推断的框架。我们通过在表征学习框架中训练图元网络来实现这一目标，并展示了对比目标如何有助于获得不受架构限制的潜在空间。实验表明，在基于多层感知机（MLP）和三平面NeRF上的分类和检索任务中，我们的方法表现出与现有针对单一架构设计的方法相当或更好的性能，从而提供了一种首个处理任意架构的NeRF并执行相关任务的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm forrepresenting 3D objects and scenes by encoding shape and appearance informationinto the weights of a neural network. Recent works have shown how such weightscan be used as input to frameworks processing them to solve deep learningtasks. Yet, these frameworks can only process NeRFs with a specific, predefinedarchitecture. In this paper, we present the first framework that can ingestNeRFs with multiple architectures and perform inference on architectures unseenat training time. We achieve this goal by training a Graph Meta-Network in arepresentation learning framework. Moreover, we show how a contrastiveobjective is conducive to obtaining an architecture-agnostic latent space. Inexperiments on both MLP-based and tri-planar NeRFs, our approach demonstratesrobust performance in classification and retrieval tasks that either matches orexceeds that of existing frameworks constrained to single architectures, thusproviding the first architecture-agnostic method to perform tasks on NeRFs byprocessing their weights.</description>
      <author>example@mail.com (Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano)</author>
      <guid isPermaLink="false">2502.09623v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Utility of Higher-Order Information in Relational Learning</title>
      <link>http://arxiv.org/abs/2502.09570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文系统评估了若干超图级和图级架构在关系学习中利用高阶信息的有效性，发现将图级模型应用于超图扩展通常优于专门的超图级架构，并提出了一种基于经典超图特征的编码方法以增强图神经网络的表现力。&lt;h4&gt;背景&lt;/h4&gt;许多领域的关系推理需要超越成对交互的信息。超图作为一种自然框架来建模这些关系已经被提出，这促使了图神经网络架构向超图的扩展研究。&lt;h4&gt;目的&lt;/h4&gt;系统评估几种基于超图级和图级别的架构在利用高阶信息方面的效果，并探索新的方法来提高表现力。&lt;h4&gt;方法&lt;/h4&gt;选取了几种超图级别和图级别的模型进行了实验对比，引入了一种依赖于经典超图特性的编码策略以进一步提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;将图级架构应用于超图扩展通常在关系学习中效果更佳；基于经典特性设计的超图级编码虽未显著改善专用的超图形构，但与图模型结合使用时表现良好。理论分析表明这种编码方法可以增加消息传递式图神经网络的表现力。&lt;h4&gt;结论&lt;/h4&gt;对于许多应用而言，利用超图扩展上的图架构可能比专门的超图模型更加有效；同时，基于经典特性的超图级编码能提高图神经网络的学习能力。&lt;h4&gt;翻译&lt;/h4&gt;高阶信息在许多领域的关系学习中至关重要，这些领域的关系超越了成对交互。超图提供了一种自然框架来建模这种关系，这激发了最近将图神经网络架构扩展到超图的研究。然而，超图架构与标准图级别模型之间的比较仍然有限。在这项工作中，我们系统地评估了几种基于超图和图级别的架构的有效性，以确定它们在利用高阶信息进行关系学习中的有效性。我们的结果显示，在处理自然参数化为超图的输入时，将图级架构应用于超图扩展通常优于专用的超图级模型。作为另一种方法来利用高阶信息，我们提出了基于经典超图特征特性的超图级编码方案。尽管这些编码方式并未显著改善专用的超图形构，但与图级别模型结合使用时表现良好。我们的理论分析表明，这种基于超图级的编码可以确凿地提升消息传递式图神经网络的表现力，超越其对应的图级别模型的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Higher-order information is crucial for relational learning in many domainswhere relationships extend beyond pairwise interactions. Hypergraphs provide anatural framework for modeling such relationships, which has motivated recentextensions of graph neural net- work architectures to hypergraphs. However,comparisons between hypergraph architectures and standard graph-level modelsremain limited. In this work, we systematically evaluate a selection ofhypergraph-level and graph-level architectures, to determine theireffectiveness in leveraging higher-order information in relational learning.Our results show that graph-level architectures applied to hypergraphexpansions often outperform hypergraph- level ones, even on inputs that arenaturally parametrized as hypergraphs. As an alternative approach forleveraging higher-order information, we propose hypergraph-level encodingsbased on classical hypergraph characteristics. While these encodings do notsignificantly improve hypergraph architectures, they yield substantialperformance gains when combined with graph-level models. Our theoreticalanalysis shows that hypergraph-level encodings provably increase therepresentational power of message-passing graph neural networks beyond that oftheir graph-level counterparts.</description>
      <author>example@mail.com (Raphael Pellegrin, Lukas Fesser, Melanie Weber)</author>
      <guid isPermaLink="false">2502.09570v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Euclidean Alignment for Transfer Learning in EEG-Based Brain-Computer Interfaces</title>
      <link>http://arxiv.org/abs/2502.09203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文回顾了欧氏对齐(EA)技术，该技术在2020年被提出用于改进基于脑电图(EEG)的脑机接口(BCI)系统的校准过程。&lt;h4&gt;背景&lt;/h4&gt;由于EEG信号具有非平稳性和较大的个体差异性，基于EEG的BCI系统通常需要针对每个新用户进行特定主体的校准。这种校准过程耗时且不友好，阻碍了其在现实世界中的应用。转移学习(TL)被广泛用于加快这一过程。&lt;h4&gt;目的&lt;/h4&gt;通过减少不同受试者/会话之间的数据分布差异来避免负向迁移，并介绍EA的有效性、使用方法及其扩展应用，同时指出潜在的新研究方向。&lt;h4&gt;方法&lt;/h4&gt;文章解释了欧氏对齐(EA)的程序和正确使用方式，并展示了其在10种不同BCI范式中的众多实验结果。&lt;h4&gt;主要发现&lt;/h4&gt;EA技术通过减少数据分布差异显著提高了基于EEG信号的解码效率，减少了新的用户校准时间。&lt;h4&gt;结论&lt;/h4&gt;对于研究基于EEG信号的BCI系统的研究人员来说，该论文提供了有关EA技术的全面概述，并为未来的研究方向提出了建议。&lt;h4&gt;翻译&lt;/h4&gt;由于EEG信号的非平稳性和个体差异性较大，基于EEG的脑机接口(BCI)通常需要针对每个新用户进行特定主体校准。这种过程耗时且不友好，限制了其实用价值。转移学习(TL)已被广泛用于通过利用其他受试者/会话的数据来加速此过程。对于TL在EEG-BCI中的应用而言，减少不同受试者或会话间数据分布差异以避免负向迁移是一个重要考虑因素。2020年提出了一种欧氏对齐(EA)方法来解决这一挑战。该技术通过大量的实验验证了其有效性和效率，涵盖了10种不同的BCI范式。本文重新审视EA技术，解释其实现流程和正确使用方式，并介绍其应用及扩展方向，同时指出了可能的新研究领域。这对EEG信号解码研究人员来说极具价值，尤其是那些致力于解决基于EEG的BCI系统问题的研究者们。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the non-stationarity and large individual differences of EEG signals,EEG-based brain-computer interfaces (BCIs) usually need subject-specificcalibration to tailor the decoding algorithm for each new subject, which istime-consuming and user-unfriendly, hindering their real-world applications.Transfer learning (TL) has been extensively used to expedite the calibration,by making use of EEG data from other subjects/sessions. An importantconsideration in TL for EEG-based BCIs is to reduce the data distributiondiscrepancies among different subjects/session, to avoid negative transfer.Euclidean alignment (EA) was proposed in 2020 to address this challenge.Numerous experiments from 10 different BCI paradigms demonstrated itseffectiveness and efficiency. This paper revisits the EA, explaining itsprocedure and correct usage, introducing its applications and extensions, andpointing out potential new research directions. It should be very helpful toBCI researchers, especially those who are working on EEG signal decoding.</description>
      <author>example@mail.com (Dongrui Wu)</author>
      <guid isPermaLink="false">2502.09203v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)</title>
      <link>http://arxiv.org/abs/2502.09376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了低秩适应（LoRA）在训练大型基础模型时的理论性质，提出了两种不同的场景，并探讨了零初始化和权重衰减如何影响参数空间中的解决方案。&lt;h4&gt;背景&lt;/h4&gt;目前对LoRA的理论理解尚不充分，大多数先前的研究依赖于线性化假设或考虑过于简化的设定。本文旨在解决这一局限。&lt;h4&gt;目的&lt;/h4&gt;分析在没有简化假设的情况下，LoRA训练损失函数的特性，并探讨零初始化和权重衰减如何影响模型参数空间中的解决方案。&lt;h4&gt;方法&lt;/h4&gt;定义了两个不同的训练场景：特殊模式（线性化假设适用的理想情况）和通用模式（非理想、更现实的情况）。并在这两个背景下分析了LoRA的收敛性质。&lt;h4&gt;主要发现&lt;/h4&gt;在通用情况下，LoRA训练可以收敛到低秩且小幅度的全局最小值或高秩且大幅度的独特解决方案。零初始化和权重衰减促使模型倾向于低秩且小幅度参数空间内的全局极小值区。&lt;h4&gt;结论&lt;/h4&gt;通过分析揭示了为什么LoRA通常能够在大型基础模型中找到全局最小值，为未来研究提供了理论依据。&lt;h4&gt;翻译&lt;/h4&gt;低秩适应（LoRA）已经成为微调大尺度基础模型的标准方法。然而，关于LoRA的理论理解仍然有限，先前对LoRA训练动态的研究要么依赖于线性化论证，要么考虑了高度简化的设置。在本工作中，我们分析了在没有这些限制假设的情况下LoRA损失函数的变化情况。我们将这种变化定义为两种情形：一种是'特殊模式'，包括理想化的设置，在那里可以使用线性化论证；另一种是更现实的场景下的‘通用模式’，在这种模式下线性化论证并不适用。在通用模式中，我们展示了LoRA训练会收敛到一个具有低秩且小幅度或高度且大幅度的独特全局最小值解决方案上。最后，我们指出零初始化和权重衰减在LoRA训练中的作用促使模型倾向于参数空间中的低秩、小幅度的区域——也就是全局最小值所在的区域——从而解释了为什么LoRA通常能找到全局极小值的原因所在。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has become a standard approach for fine-tuninglarge foundation models. However, our theoretical understanding of LoRA remainslimited as prior analyses of LoRA's training dynamics either rely onlinearization arguments or consider highly simplified setups. In this work, weanalyze the LoRA loss landscape without such restrictive assumptions. We definetwo regimes: a ``special regime'', which includes idealized setups wherelinearization arguments hold, and a ``generic regime'' representing morerealistic setups where linearization arguments do not hold. In the genericregime, we show that LoRA training converges to a global minimizer with lowrank and small magnitude, or a qualitatively distinct solution with high rankand large magnitude. Finally, we argue that the zero-initialization and weightdecay in LoRA training induce an implicit bias toward the low-rank,small-magnitude region of the parameter space -- where global minima lie --thus shedding light on why LoRA training usually succeeds in finding globalminima.</description>
      <author>example@mail.com (Junsu Kim, Jaeyeon Kim, Ernest K. Ryu)</author>
      <guid isPermaLink="false">2502.09376v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Machine learning for modelling unstructured grid data in computational physics: a review</title>
      <link>http://arxiv.org/abs/2502.09346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了处理高维动态系统中不规则网格数据的先进机器学习（ML）方法，特别关注计算物理学领域。&lt;h4&gt;背景&lt;/h4&gt;在计算物理中，不结构化的网格数据对于建模复杂的几何形状和动力学至关重要。然而，这些数据本身的不规则性给传统的机器学习技术带来了显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提供一份关于处理高维动态系统中的不规则网格数据的先进ML方法的全面综述，为计算科学家和ML研究人员提供指导。&lt;h4&gt;方法&lt;/h4&gt;讨论的关键方法包括图神经网络、具有空间注意力机制的变压器模型、插值集成机器学习方法以及如物理信息神经网络之类的无网格技术。&lt;h4&gt;主要发现&lt;/h4&gt;这些方法已在流体动力学和环境模拟等各个领域证明了其有效性，展示了ML在克服传统数值技术局限性方面的潜力，并反过来利用计算物理学中的见解来促进ML的发展。&lt;h4&gt;结论&lt;/h4&gt;该综述不仅概述了开放访问的不规则网格数据集以支持基准测试，还讨论了一些新兴方向如无结构数据生成模型、强化学习用于网格式样生成以及混合物理-数据驱动范式等，旨在激发未来在这一不断发展的领域中的创新和进步。&lt;h4&gt;翻译&lt;/h4&gt;未直接作为摘要内容的一部分，这里表示整个摘要的内容已经被翻译成了中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unstructured grid data are essential for modelling complex geometries anddynamics in computational physics. Yet, their inherent irregularity presentssignificant challenges for conventional machine learning (ML) techniques. Thispaper provides a comprehensive review of advanced ML methodologies designed tohandle unstructured grid data in high-dimensional dynamical systems. Keyapproaches discussed include graph neural networks, transformer models withspatial attention mechanisms, interpolation-integrated ML methods, and meshlesstechniques such as physics-informed neural networks. These methodologies haveproven effective across diverse fields, including fluid dynamics andenvironmental simulations. This review is intended as a guidebook forcomputational scientists seeking to apply ML approaches to unstructured griddata in their domains, as well as for ML researchers looking to addresschallenges in computational physics. It places special focus on how ML methodscan overcome the inherent limitations of traditional numerical techniques and,conversely, how insights from computational physics can inform ML development.To support benchmarking, this review also provides a summary of open-accessdatasets of unstructured grid data in computational physics. Finally, emergingdirections such as generative models with unstructured data, reinforcementlearning for mesh generation, and hybrid physics-data-driven paradigms arediscussed to inspire future advancements in this evolving field.</description>
      <author>example@mail.com (Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci)</author>
      <guid isPermaLink="false">2502.09346v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</title>
      <link>http://arxiv.org/abs/2502.08826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模语言模型（LLM）由于依赖静态训练数据，在幻觉和过时知识方面存在挑战。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题。&lt;h4&gt;目的&lt;/h4&gt;该综述提供了一个结构化且全面的多模态RAG系统的分析，涵盖了数据集、度量标准、基准测试、评估方法论及创新等各个方面。&lt;h4&gt;方法&lt;/h4&gt;详细回顾了训练策略、鲁棒性增强和损失函数，并探讨了多样化的多模态RAG场景。还讨论了开放性挑战和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;跨模态对齐与推理给多模态RAG带来了独特的挑战，使其区别于传统的单模态RAG。&lt;h4&gt;结论&lt;/h4&gt;该综述为开发更强大、可靠的AI系统奠定了基础，这些系统能有效利用多模态动态外部知识库。&lt;h4&gt;翻译&lt;/h4&gt;大规模语言模型（LLM）由于依赖静态训练数据，在幻觉和过时知识方面存在挑战。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题。近年来，随着多模态学习的进步，开发出了将文本、图像、音频和视频等多种模式结合的多模态RAG系统以提高生成输出的质量。然而，跨模态对齐与推理给多模态RAG带来了独特的挑战，使其区别于传统的单模态RAG。本综述提供了一个结构化且全面的分析，涵盖了数据集、度量标准、基准测试、评估方法论及创新等各个方面。详细回顾了训练策略、鲁棒性增强和损失函数，并探讨了多样化的多模态RAG场景。还讨论了开放性挑战和未来研究方向，以支持该领域的发展进步。本综述为开发更强大、可靠的AI系统奠定了基础，这些系统能有效利用多模态动态外部知识库。资源详见：https://github.com/llm-lab-org/Multimodal-RAG-Survey。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) struggle with hallucinations and outdatedknowledge due to their reliance on static training data. Retrieval-AugmentedGeneration (RAG) mitigates these issues by integrating external dynamicinformation enhancing factual and updated grounding. Recent advances inmultimodal learning have led to the development of Multimodal RAG,incorporating multiple modalities such as text, images, audio, and video toenhance the generated outputs. However, cross-modal alignment and reasoningintroduce unique challenges to Multimodal RAG, distinguishing it fromtraditional unimodal RAG. This survey offers a structured and comprehensiveanalysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,evaluation, methodologies, and innovations in retrieval, fusion, augmentation,and generation. We precisely review training strategies, robustnessenhancements, and loss functions, while also exploring the diverse MultimodalRAG scenarios. Furthermore, we discuss open challenges and future researchdirections to support advancements in this evolving field. This survey lays thefoundation for developing more capable and reliable AI systems that effectivelyleverage multimodal dynamic external knowledge bases. Resources are availableat https://github.com/llm-lab-org/Multimodal-RAG-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2502.08826v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2502.09274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种改进的基于范围视图的工作流程，用于激光雷达语义分割，旨在克服现有方法在数据稀疏性和计算需求方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;三维场景理解是自动驾驶中的关键任务之一，但由于激光雷达数据的不规则和稀疏性以及处理大规模点云所需的大量计算资源，这一任务极具挑战性。现有的方法利用范围视图表示来提高处理效率。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过重新设计工作流程来解决由于将多个3D点映射到相同的2D网格而导致的信息丢失问题，并证明降低分辨率可以在准确性和效率上提供更佳的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种综合性的重新设计方案，包括数据表示、增强和后处理方法改进。通过在两个公开数据集上的广泛实验验证了所提出的管道能够显著提升多种网络架构的表现。&lt;h4&gt;主要发现&lt;/h4&gt;降低分辨率而非增加分辨率更有助于提高效率和准确性；重新设计的流程可以改善各种网络架构的表现。&lt;h4&gt;结论&lt;/h4&gt;这项工作为基于激光雷达的有效感知提供了更好的途径，表明了在自动驾驶系统中采用该方法的可能性。&lt;h4&gt;翻译&lt;/h4&gt;3D场景理解是自主驾驶中的关键但具有挑战性的任务，主要原因是激光雷达数据的不规则性和稀疏性以及处理大规模点云所需的大量计算资源。最近的方法利用范围视图表示来提高处理效率。为了解决由“多对一”问题导致的信息丢失所引起的性能下降，“多对一”中多个附近的3D点映射到相同的2D网格并且只保留最接近的点，先前的工作倾向于选择更高的俯仰分辨率进行范围视图投影。然而，这会带来减少携带信息像素比例和网络内部计算量加重的问题。我们认为这不是最优解决方案，并展示降低分辨率在效率和准确性上更具优势。在此工作中，我们提出了基于范围视图的LiDAR语义分割工作流程的全面重新设计。我们的方法解决了数据表示、增强及后处理方法改进的问题。通过两个公开数据集上的广泛实验，我们证明了相对于基线，该管道可以显著提升各种网络架构的表现，为自主系统中的有效激光雷达感知铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene understanding is a critical yet challenging task in autonomousdriving, primarily due to the irregularity and sparsity of LiDAR data, as wellas the computational demands of processing large-scale point clouds. Recentmethods leverage the range-view representation to improve processingefficiency. To mitigate the performance drop caused by information lossinherent to the "many-to-one" problem, where multiple nearby 3D points aremapped to the same 2D grids and only the closest is retained, prior works tendto choose a higher azimuth resolution for range-view projection. However, thiscan bring the drawback of reducing the proportion of pixels that carryinformation and heavier computation within the network. We argue that it is notthe optimal solution and show that, in contrast, decreasing the resolution ismore advantageous in both efficiency and accuracy. In this work, we present acomprehensive re-design of the workflow for range-view-based LiDAR semanticsegmentation. Our approach addresses data representation, augmentation, andpost-processing methods for improvements. Through extensive experiments on twopublic datasets, we demonstrate that our pipeline significantly enhances theperformance of various network architectures over their baselines, paving theway for more effective LiDAR-based perception in autonomous systems.</description>
      <author>example@mail.com (Bin Yang, Alexandru Paul Condurache)</author>
      <guid isPermaLink="false">2502.09274v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Graph Diffusion Network for Drug-Gene Prediction</title>
      <link>http://arxiv.org/abs/2502.09335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/ACM TCBB. 14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GDNDGP的图扩散网络框架，用于预测药物-基因关联。此框架通过两项创新解决了数据稀疏性和高效对比学习实施的问题：一是采用基于元路径的同质图学习方法捕捉药物与药物、基因与基因之间的关系；二是引入并行扩散网络生成训练期间的硬负样本。&lt;h4&gt;背景&lt;/h4&gt;药物-基因关联预测对于药物开发和疾病治疗至关重要，而图形神经网络（GNN）在解决这个问题时遇到了数据稀疏性和高效对比性学习实现的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图扩散网络框架GDNDGP，以改进现有方法在药物-基因预测任务中的表现，特别是在处理复杂的异构关系方面。&lt;h4&gt;方法&lt;/h4&gt;该模型通过采用基于元路径的同质图学习捕捉药物与药物、基因与基因之间的关系，并引入并行扩散网络生成硬负样本来改善训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;在DGIdb 4.0数据集上，所提出的GDNDGP框架实现了优于现有方法的表现。此外，在三元组的药物-基因-疾病网络中也展示了较强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该模型通过创新的方法显著提升了药物-基因预测任务中的性能，并且开源了源代码供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;预测药物-基因关联对于药物开发和治疗疾病至关重要。虽然图神经网络（GNN）在这一领域表现出有效性，但它们面临着数据稀疏性和高效对比学习实现的挑战。我们引入了一种用于药物-基因预测的图扩散网络（GDNDGP），该框架通过两项关键创新解决了这些限制：第一，它使用基于元路径的同质图学习方法捕捉药物-药物和基因-基因关系，确保相似实体共享嵌入空间；第二，它包括一个并行扩散网络，在训练期间生成硬负样本，消除了对穷举式负样本检索的需求。我们的模型在DGIdb 4.0数据集上实现了优于现有方法的表现，并且在三元组的药物-基因-疾病网络中展示了强大的泛化能力。结果表明，该方法显著改进了现有的药物-基因预测任务中的表现，特别是在处理复杂的异构关系方面。源代码可在https://github.com/csjywu1/GDNDGP上公开获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting drug-gene associations is crucial for drug development and diseasetreatment. While graph neural networks (GNN) have shown effectiveness in thistask, they face challenges with data sparsity and efficient contrastivelearning implementation. We introduce a graph diffusion network for drug-geneprediction (GDNDGP), a framework that addresses these limitations through twokey innovations. First, it employs meta-path-based homogeneous graph learningto capture drug-drug and gene-gene relationships, ensuring similar entitiesshare embedding spaces. Second, it incorporates a parallel diffusion networkthat generates hard negative samples during training, eliminating the need forexhaustive negative sample retrieval. Our model achieves superior performanceon the DGIdb 4.0 dataset and demonstrates strong generalization capability ontripartite drug-gene-disease networks. Results show significant improvementsover existing methods in drug-gene prediction tasks, particularly in handlingcomplex heterogeneous relationships. The source code is publicly available athttps://github.com/csjywu1/GDNDGP.</description>
      <author>example@mail.com (Jiayang Wu, Wensheng Gan, Philip S. Yu)</author>
      <guid isPermaLink="false">2502.09335v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Memristor-Based Meta-Learning for Fast mmWave Beam Prediction in Non-Stationary Environments</title>
      <link>http://arxiv.org/abs/2502.09244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于忆阻器的元学习（M-ML）框架，用于实时预测毫米波通信中的波束成形向量。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习技术已经在提高毫米波通信的数据传输率和减少延迟方面取得了显著成功。然而，这些方法仍然面临两个主要挑战：一是依赖大规模配对数据进行模型训练与调优；二是基于元学习的波束形成解决方案在有限任务集上容易过拟合。&lt;h4&gt;目的&lt;/h4&gt;为了克服上述问题，本文提出了一个基于忆阻器的元学习框架M-ML来预测毫米波通信中的实时波束。该方法旨在提高模型适应未知环境的能力和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;通过利用存储能力保存关键数据，M-ML框架在训练阶段生成最优初始化参数，在测试阶段适应不同环境时可以提供良好的起点。此外，这种方法能够在不依赖大型数据集的情况下实现高精度预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在新环境中能够达到很高的波束预测准确性，并且增强了模型的泛化能力和适应性。&lt;h4&gt;结论&lt;/h4&gt;基于忆阻器的元学习框架可以有效解决毫米波通信中实时波束成形面临的挑战，其不仅提高了预测精度和环境适应能力，还通过优化参数初始化避免了过拟合问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional machine learning techniques have achieved great success inimproving data-rate performance and reducing latency in millimeter wave(mmWave) communications. However, these methods still face two key challenges:(i) their reliance on large-scale paired data for model training and tuningwhich limits performance gains and makes beam predictions outdated, especiallyin multi-user mmWave systems with large antenna arrays, and (ii) meta-learning(ML)-based beamforming solutions are prone to overfitting when trained on alimited number of tasks. To address these issues, we propose a memristorbasedmeta-learning (M-ML) framework for predicting mmWave beam in real time. TheM-ML framework generates optimal initialization parameters during the trainingphase, providing a strong starting point for adapting to unknown environmentsduring the testing phase. By leveraging memory to store key data, M-ML ensuresthe predicted beamforming vectors are wellsuited to episodically dynamicchannel distributions, even when testing and training environments do notalign. Simulation results show that our approach delivers high predictionaccuracy in new environments, without relying on large datasets. Moreover, MMLenhances the model's generalization ability and adaptability.</description>
      <author>example@mail.com (Yuwen Cao, Wenqin Lu, Tomoaki Ohtsuki, Setareh Maghsudi, Xue-Qin Jiang, Charalampos C. Tsimenidis)</author>
      <guid isPermaLink="false">2502.09244v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2502.09501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于先验约束的关联学习方法，用于解决广义类别发现任务中的问题。这项研究改进了传统的半监督学习方法，并特别关注未标记数据可能来自未知类别的挑战。&lt;h4&gt;背景&lt;/h4&gt;广义类别发现（GCD）的任务是在已知类别标签数据的帮助下对潜在的已知或未知类别的无标签数据进行聚类，区别于传统半监督学习，由于未标注的数据可能是全新的类别而更加具有挑战性。目前的方法倾向于使用自蒸馏来辅助参数化分类器的学习。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入先验约束关联学习方法改进广义类别发现任务中的性能，该方法利用来自已知类别的标记数据提供的独特先验信息对无标签数据进行处理，并结合非参数原型对比增强表示学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于先验的关联学习（Prior-constrained Association Learning）方法，通过将先验完全融入到关联过程中来约束关联结果。利用估计出的语义组与非参数原型对比法相结合以提高表示学习的效果。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的算法在多项广义类别发现基准测试中表现出色，并显著优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;该论文通过引入先验约束并改进了半监督学习框架，展示了一种有效的解决未知类别问题的方法。实验结果验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文针对广义类别发现任务提出了一种基于先验约束的关联学习方法，利用已知类别的标签数据提供独特先验信息来处理未标注的数据，并通过非参数原型对比法增强表示学习效果，从而在多项基准测试中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses generalized category discovery (GCD), the task ofclustering unlabeled data from potentially known or unknown categories with thehelp of labeled instances from each known category. Compared to traditionalsemi-supervised learning, GCD is more challenging because unlabeled data couldbe from novel categories not appearing in labeled data. Currentstate-of-the-art methods typically learn a parametric classifier assisted byself-distillation. While being effective, these methods do not make use ofcross-instance similarity to discover class-specific semantics which areessential for representation learning and category discovery. In this paper, werevisit the association-based paradigm and propose a Prior-constrainedAssociation Learning method to capture and learn the semantic relations withindata. In particular, the labeled data from known categories provides a uniqueprior for the association of unlabeled data. Unlike previous methods that onlyadopts the prior as a pre or post-clustering refinement, we fully incorporatethe prior into the association process, and let it constrain the associationtowards a reliable grouping outcome. The estimated semantic groups are utilizedthrough non-parametric prototypical contrast to enhance the representationlearning. A further combination of both parametric and non-parametricclassification complements each other and leads to a model that outperformsexisting methods by a significant margin. On multiple GCD benchmarks, weperform extensive experiments and validate the effectiveness of our proposedmethod.</description>
      <author>example@mail.com (Menglin Wang, Zhun Zhong, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.09501v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.09254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对图异常检测（GAD）任务的图基础模型AnomalyGFM，该模型支持零样本推理和少量提示调整。通过预训练来对齐数据无关性的正常和异常类原型，并使用节点表示残差来识别不同图形中的异常节点。&lt;h4&gt;背景&lt;/h4&gt;现有的通用图模型在各种图任务中取得了显著成功，但难以泛化到GAD任务，因为这些模型难以学习捕捉不同领域图中固有的罕见、不规则和异构的异常模式的一般性知识。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一挑战，提出了一种专门针对GAD任务的图基础模型AnomalyGFM。&lt;h4&gt;方法&lt;/h4&gt;该模型在预训练阶段使用节点表示残差来对齐数据无关性的正常和异常类原型。它支持零样本推理，并且如果新的图形中有少量标记为正常的节点，则可以进行提示调整以更好地适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在11个广泛使用的具有真实异常的GAD数据集上，AnomalyGFM在零样本和少量样本的GAD设置下均显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AnomalyGFM是一种强大的图基础模型，能够有效地支持各种图形中的异常节点检测任务，并且可以在没有大量训练数据的情况下进行有效的泛化和适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图异常检测（GAD）旨在识别与图中大多数节点不同的异常节点，在最近几年引起了广泛关注。现有的通用图模型在不同图任务中取得了显著成功，但在GAD任务上难以泛化。这种局限性源于它们难以学习捕捉来自不同领域的图形中的固有的罕见、不规则和异构的异常模式的一般性知识。为了解决这一挑战，我们提出了一种专门针对GAD任务的图基础模型AnomalyGFM，该模型支持零样本推理和少量提示调整以在各种图数据集上进行GAD。一个关键见解是，在不同的图形中有效支持零/少量样本GAD需要正常和异常类的数据无关表示。受此启发，AnomalyGFM被预训练为对齐数据无关、可学习的正常和异常类原型与节点表示残差（即，节点与其邻居之间的表示偏差）。这些残留特性本质上将节点信息映射到一个统一的特征空间中，在这个空间中我们可以一致地有效测量来自不同图的节点的异常性。这为学习针对图形不可知、区分性的正常和异常类原型提供了推动力，这种模型可以用于在新图（包括非常大规模图）上实现零样本GAD。如果新的图中有少量标记为正常的节点，则AnomalyGFM还可以进一步支持提示调整以利用这些节点进行更好的适应性改进。综合广泛的11个具有真实异常的GAD数据集上的实验表明，AnomalyGFM在零样本和少量样本设置下均显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph anomaly detection (GAD) aims to identify abnormal nodes that differfrom the majority of the nodes in a graph, which has been attractingsignificant attention in recent years. Existing generalist graph models haveachieved remarkable success in different graph tasks but struggle to generalizeto the GAD task. This limitation arises from their difficulty in learninggeneralized knowledge for capturing the inherently infrequent, irregular andheterogeneous abnormality patterns in graphs from different domains. To addressthis challenge, we propose AnomalyGFM, a GAD-oriented graph foundation modelthat supports zero-shot inference and few-shot prompt tuning for GAD in diversegraph datasets. One key insight is that graph-agnostic representations fornormal and abnormal classes are required to support effective zero/few-shot GADacross different graphs. Motivated by this, AnomalyGFM is pre-trained to aligndata-independent, learnable normal and abnormal class prototypes with noderepresentation residuals (i.e., representation deviation of a node from itsneighbors). The residual features essentially project the node information intoa unified feature space where we can effectively measure the abnormality ofnodes from different graphs in a consistent way. This provides a driving forcefor the learning of graph-agnostic, discriminative prototypes for the normaland abnormal classes, which can be used to enable zero-shot GAD on new graphs,including very large-scale graphs. If there are few-shot labeled normal nodesavailable in the new graphs, AnomalyGFM can further support prompt tuning toleverage these nodes for better adaptation. Comprehensive experiments on 11widely-used GAD datasets with real anomalies, demonstrate that AnomalyGFMsignificantly outperforms state-of-the-art competing methods under both zero-and few-shot GAD settings.</description>
      <author>example@mail.com (Hezhe Qiao, Chaoxi Niu, Ling Chen, Guansong Pang)</author>
      <guid isPermaLink="false">2502.09254v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Topological Interference Management: A Learning-to-Code on Graphs Perspective</title>
      <link>http://arxiv.org/abs/2502.09344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2305.07186&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的拓扑干扰管理框架，旨在自动生成适用于无线通信系统的编码方案。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的拓扑干扰管理模式（TIM）通常为特定网络拓扑设计，并依赖专家知识和复杂处理方法，缺乏系统性和自动化手段限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习导向的编码方式，以解决现有TIM编码方案的一般化问题并促进其在无线通信中的应用。&lt;h4&gt;方法&lt;/h4&gt;通过将图神经网络（GNN）与强化学习相结合，创建了一个统一的学习到编码框架（LCG），能够自动生成适合任意网络拓扑结构的编码方案。&lt;h4&gt;主要发现&lt;/h4&gt;该LCG框架不仅能够恢复已知的一对一标量/矢量干扰对齐解决方案，并且能够为多天线情况下的子空间干扰对齐编码方案生成新的解决方案，这些新方案难以通过手动设计获得。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LCG框架能有效自动产生系统性编码方案以解决具有任意网络拓扑的TIM实例问题，并且其学习算法在在线推理时间、泛化性和可转移性方面表现出色，适用于实际部署。&lt;h4&gt;翻译&lt;/h4&gt;拓扑干扰管理（TIM）的发展是近年来网络信息理论发展的主要推动力之一。然而，最先进的TIM编码方案通常为特定网络拓扑设计，严重依赖专家知识和复杂处理手段。缺乏系统化与自动化的解决方案生成方法限制了其在无线通信系统中的广泛应用。为了应对这一挑战，本文首次尝试从新的学习导向编码视角重新审视拓扑干扰对齐（IA）问题。具体而言，我们将一对一和子空间IA条件重铸为向量分配策略，并通过利用图神经网络（GNNs）捕捉拓扑结构以及强化学习（RL）进行IA波束赋形向量分配决策提出了一个统一的学习到编码框架（LCG）。有趣的是，所提出的LCG框架能够恢复已知的一对一标量/矢量IA解决方案，适用于更广泛的网络拓扑，并且更为显著地发现了一种新的多天线情况下的子空间IA编码方案，这些新方案难以通过手动设计获得。大量的实验表明，LCG框架是一种有效的方式以自动产生系统性编码方案来应对具有任意网络拓扑的TIM实例问题，并且其背后的算法在在线推理时间方面高效，同时具备优秀的泛化性和可转移性，适用于实际部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advance of topological interference management (TIM) has been one of thedriving forces of recent developments in network information theory. However,state-of-the-art coding schemes for TIM are usually handcrafted for specificfamilies of network topologies, relying critically on experts' domain knowledgeand sophisticated treatments. The lack of systematic and automatic generationof solutions inevitably restricts their potential wider applications towireless communication systems, due to the limited generalizability of codingschemes to wider network configurations. To address such an issue, this workmakes the first attempt to advocate revisiting topological interferencealignment (IA) from a novel learning-to-code perspective. Specifically, werecast the one-to-one and subspace IA conditions as vector assignment policiesand propose a unifying learning-to-code on graphs (LCG) framework by leveraginggraph neural networks (GNNs) for capturing topological structures andreinforcement learning (RL) for decision-making of IA beamforming vectorassignment. Interestingly, the proposed LCG framework is capable of recoveringknown one-to-one scalar/vector IA solutions for a significantly wider range ofnetwork topologies, and more remarkably of discovering new subspace IA codingschemes for multiple-antenna cases that are challenging to be handcrafted. Theextensive experiments demonstrate that the LCG framework is an effective way toautomatically produce systematic coding solutions to the TIM instances witharbitrary network topologies, and at the same time, the underlying learningalgorithm is efficient with respect to online inference time and possessesexcellent generalizability and transferability for practical deployment.</description>
      <author>example@mail.com (Zhiwei Shan, Xinping Yi, Han Yu, Chung-Shou Liao, Shi Jin)</author>
      <guid isPermaLink="false">2502.09344v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.09086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于迁移学习和元学习的少量样本文本分类模型，通过预训练模型的知识转移和元学习机制优化了模型在小样本任务中的快速适应性。实验结果表明，在少样本和中等样本条件下，该模型显著优于传统机器学习和深度学习方法。&lt;h4&gt;背景&lt;/h4&gt;随着自然语言处理技术的发展，文本分类任务被广泛应用于多个领域。然而，获取标注数据通常是昂贵且困难的，尤其是在少量样本场景下。&lt;h4&gt;目的&lt;/h4&gt;为了解决在少量样本情况下获得标注数据的问题，提出了一种基于迁移学习和元学习的文本分类模型。&lt;h4&gt;方法&lt;/h4&gt;该模型利用预训练模型的知识进行迁移，并通过元学习机制优化模型在小样本任务中的快速适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在少样本和中等样本条件下，基于迁移学习和元学习的模型显著优于传统机器学习和深度学习方法。此外，消融试验进一步分析了各组件对模型性能的贡献，并确认了迁移学习和元学习在提高模型准确性中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了未来的研究方向，并展望了该方法在未来实际应用中的潜力&lt;h4&gt;翻译&lt;/h4&gt;随着自然语言处理技术的发展，文本分类任务被广泛应用于多个领域。然而，在获取标注数据方面通常是昂贵且困难的，尤其是在少量样本场景下。为了解决这一问题，本文提出了一种基于迁移学习和元学习的文本分类模型，该模型利用预训练模型的知识进行知识转移，并通过元学习机制来优化模型在小样本任务中的快速适应性。通过一系列对比实验和消融试验验证了所提方法的有效性。实验结果显示，在少样本与中等样本条件下，基于迁移学习和元学习的模型显著优于传统机器学习和深度学习的方法。此外，消融试验进一步分析了各个组件对模型性能的影响，并确认了迁移学习和元学习在提高模型准确性方面的重要作用。最后，本文讨论了未来的研究方向并展望了该方法在未来实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the continuous development of natural language processing (NLP)technology, text classification tasks have been widely used in multipleapplication fields. However, obtaining labeled data is often expensive anddifficult, especially in few-shot learning scenarios. To solve this problem,this paper proposes a few-shot text classification model based on transferlearning and meta-learning. The model uses the knowledge of the pre-trainedmodel for transfer and optimizes the model's rapid adaptability in few-sampletasks through a meta-learning mechanism. Through a series of comparativeexperiments and ablation experiments, we verified the effectiveness of theproposed method. The experimental results show that under the conditions of fewsamples and medium samples, the model based on transfer learning andmeta-learning significantly outperforms traditional machine learning and deeplearning methods. In addition, ablation experiments further analyzed thecontribution of each component to the model performance and confirmed the keyrole of transfer learning and meta-learning in improving model accuracy.Finally, this paper discusses future research directions and looks forward tothe potential of this method in practical applications.</description>
      <author>example@mail.com (Jia Gao, Shuangquan Lyu, Guiran Liu, Binrong Zhu, Hongye Zheng, Xiaoxuan Liao)</author>
      <guid isPermaLink="false">2502.09086v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Bilevel gradient methods and Morse parametric qualification</title>
      <link>http://arxiv.org/abs/2502.09074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Morse参数化条件，这种新条件扩展了均匀强凸性的概念，并展示了半代数函数在分段意义上的这一性质如何使双层问题简化为混合整数规划问题。&lt;h4&gt;背景&lt;/h4&gt;Morse参数化条件是一个新的数学条件，它推广了均匀强凸性。研究表明，大多数的半代数函数在这种条件下是分段意义下的Morse参数化的。&lt;h4&gt;目的&lt;/h4&gt;研究在这一新框架内双层梯度算法的不同策略及其特性。&lt;h4&gt;方法&lt;/h4&gt;两种策略：一种是一步多步骤策略（先处理一系列下层问题然后进行一次上层问题的处理），另一种是受元学习应用启发的可微编程策略，该策略优化了双层问题的平滑近似。&lt;h4&gt;主要发现&lt;/h4&gt;单步多步法显示为具有丰富特性的有偏梯度方法；而可微编程法虽然不如前者稳定但因其简洁性和易于实现获得了研究者的青睐。&lt;h4&gt;结论&lt;/h4&gt;新的Morse参数化条件提供了一种理解双层优化问题的新视角，其中的两种策略在处理这些问题时各有利弊。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Morse parametric qualification condition is a new condition that generalizesuniform strong convexity. Generic semi-algebraic functions are Morse parametricin a piecewise sense, implying that generic semi-algebraic bilevel problemsreduce to mixed-integer programming. In this new framework, we study bilevelgradient algorithms with two strategies: the single-step multi-step strategy,which involves a sequence of steps on the lower-level problems followed by onestep on the upper-level problem, and a differentiable programming strategy thatoptimizes a smooth approximation of the bilevel problem. While the first isshown to be a biased gradient method on the problem with rich properties, thesecond, inspired by meta-learning applications, is less stable but offerssimplicity and ease of implementation.</description>
      <author>example@mail.com (Jérôme Bolte, Quoc-Tung Le, Edouard Pauwels, Samuel Vaiter)</author>
      <guid isPermaLink="false">2502.09074v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>OpenBench: A New Benchmark and Baseline for Semantic Navigation in Smart Logistics</title>
      <link>http://arxiv.org/abs/2502.09238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个结合基础模型和经典算法的开放式户外语义导航系统（OPEN），用于提高智能物流中的最后一公里配送效率。&lt;h4&gt;背景&lt;/h4&gt;随着对高效最后一公里配送的需求增加，自主机器人在提升运营效率和降低成本方面的作用日益显著。然而，传统的依赖高精度地图的导航方法资源密集型，而基于学习的方法通常难以实现在现实场景中的泛化。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，该研究旨在开发一种能够结合基础模型和经典算法进行规模化户外导航的系统。&lt;h4&gt;方法&lt;/h4&gt;OPEN系统利用现成的OpenStreetMap（OSM）提供灵活的地图表示，并使用大型语言模型理解交付指令以及视觉-语言模型实现全球定位、地图更新和门牌号识别。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，该系统在模拟和现实环境中的导航效率和可靠性方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;为了进一步促进研究，研究人员公开了代码和基准测试数据集。&lt;h4&gt;翻译&lt;/h4&gt;随着对智能物流中高效最后一公里配送的需求增加，自主机器人在提升运营效率和降低成本方面的作用日益显著。传统的依赖高精度地图的导航方法资源密集型，而基于学习的方法通常难以实现在现实场景中的泛化。为了解决这些挑战，该研究开发了一种结合基础模型和经典算法进行规模化户外导航的系统（OPEN）。实验结果表明，在模拟和真实环境中，该系统的导航效率和可靠性均表现出色。为了进一步促进研究，代码和基准测试数据集已被公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing demand for efficient last-mile delivery in smart logisticsunderscores the role of autonomous robots in enhancing operational efficiencyand reducing costs. Traditional navigation methods, which depend onhigh-precision maps, are resource-intensive, while learning-based approachesoften struggle with generalization in real-world scenarios. To address thesechallenges, this work proposes the Openstreetmap-enhanced oPen-air sEmanticNavigation (OPEN) system that combines foundation models with classicalgorithms for scalable outdoor navigation. The system uses off-the-shelfOpenStreetMap (OSM) for flexible map representation, thereby eliminating theneed for extensive pre-mapping efforts. It also employs Large Language Models(LLMs) to comprehend delivery instructions and Vision-Language Models (VLMs)for global localization, map updates, and house number recognition. Tocompensate the limitations of existing benchmarks that are inadequate forassessing last-mile delivery, this work introduces a new benchmark specificallydesigned for outdoor navigation in residential areas, reflecting the real-worldchallenges faced by autonomous delivery systems. Extensive experiments insimulated and real-world environments demonstrate the proposed system'sefficacy in enhancing navigation efficiency and reliability. To facilitatefurther research, our code and benchmark are publicly available.</description>
      <author>example@mail.com (Junhui Wang, Dongjie Huo, Zehui Xu, Yongliang Shi, Yimin Yan, Yuanxin Wang, Chao Gao, Yan Qiao, Guyue Zhou)</author>
      <guid isPermaLink="false">2502.09238v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>3D-Grounded Vision-Language Framework for Robotic Task Planning: Automated Prompt Synthesis and Supervised Reasoning</title>
      <link>http://arxiv.org/abs/2502.08903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于改进视觉-语言模型在3D场景定位和机器人任务执行中的表现。&lt;h4&gt;背景&lt;/h4&gt;当前多模态大型语言模型虽然在场景理解和感知方面取得显著成果，但在精细的机器人操作中受限于低识别精度、效率低下、转移性差和可靠性不足等挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新颖框架来增强视觉-语言模型处理3D场景的能力，并解决其在复杂环境下的表现问题。&lt;h4&gt;方法&lt;/h4&gt;该框架包括一个2D提示合成模块，用于将图像映射到点云并从中提取精确的3D空间信息；同时采用小型语言模型（SLM）监督VLM输出以减少幻觉现象，并确保生成可靠、可执行的任务控制代码。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在任务成功率为96.0%时超越了其他方法。消融研究表明，移除2D提示合成模块或监督输出模块会导致成功率下降67%，这证明了所提框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过增强3D场景理解、改进任务规划和提升机器人任务执行的可靠性，有效提高了视觉-语言模型在复杂环境中的性能。此外，该方法还消除了对新环境中重新训练的需求，提升了成本效率及运行稳定性。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language models (VLMs) have achieved remarkable success in scene understanding and perception tasks, but lack robust 3D scene localization capabilities. To address this issue, a novel framework integrating a 2D prompt synthesis module and a small language model (SLM) is proposed, enabling autonomous extraction of precise 3D spatial information and ensuring reliable robotic control code generation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) have achieved remarkable success in sceneunderstanding and perception tasks, enabling robots to plan and execute actionsadaptively in dynamic environments. However, most multimodal large languagemodels lack robust 3D scene localization capabilities, limiting theireffectiveness in fine-grained robotic operations. Additionally, challenges suchas low recognition accuracy, inefficiency, poor transferability, andreliability hinder their use in precision tasks. To address these limitations,we propose a novel framework that integrates a 2D prompt synthesis module bymapping 2D images to point clouds, and incorporates a small language model(SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs,trained on 2D images and text, to autonomously extract precise 3D spatialinformation without manual intervention, significantly enhancing 3D sceneunderstanding. Meanwhile, the SLM supervises VLM outputs, mitigatinghallucinations and ensuring reliable, executable robotic control codegeneration. Our framework eliminates the need for retraining in newenvironments, thereby improving cost efficiency and operational robustness.Experimental results that the proposed framework achieved a 96.0\% Task SuccessRate (TSR), outperforming other methods. Ablation studies demonstrated thecritical role of both the 2D prompt synthesis module and the output supervisionmodule (which, when removed, caused a 67\% TSR drop). These findings validatethe framework's effectiveness in improving 3D recognition, task planning, androbotic task execution.</description>
      <author>example@mail.com (Guoqin Tang, Qingxuan Jia, Zeyuan Huang, Gang Chen, Ning Ji, Zhipeng Yao)</author>
      <guid isPermaLink="false">2502.08903v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Low-Complexity Plug-and-Play Deep Learning Model for Massive MIMO Precoding Across Sites</title>
      <link>http://arxiv.org/abs/2502.08757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This preprint comprises 6 pages and features 2 figures. It has been  accepted to the IEEE International Conference on Machine Learning and  Computer Networking (ICMLCN) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;毫米波大规模多输入多输出（mMIMO）技术通过提升频谱效率和网络容量彻底改变了无线通信。本文提出了一种基于深度学习的mMIMO预编码方案，以解决现有方法如加权最小均方误差（WMMSE）所面临的复杂性挑战，并利用元学习领域的泛化能力和教师-学生架构来提高在各种通信环境中的适应能力。&lt;h4&gt;背景&lt;/h4&gt;毫米波大规模多输入多输出技术极大地提高了频谱效率和网络容量，但现有的解决方案由于其复杂的计算需求，在实际应用中存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于深度学习的mMIMO预编码方案，以减少现有方法的复杂性，并在不同的通信环境中实现良好的性能泛化能力。&lt;h4&gt;方法&lt;/h4&gt;利用元学习领域的泛化能力和教师-学生架构来开发新型预编码器。模型通过避免矩阵求逆和使用更简单的神经网络结构，在未见过的实际地点部署时能够保持低计算复杂度，同时保证较高的总速率性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法能够在保持高效计算效率的同时提供高总数据率性能，并在不熟悉的环境中展示出强大的泛化能力。此外，通过微调，所提出的模型在所有测试站点和信号噪声比（SNR）条件下均优于WMMSE方法，并且复杂度至少减少了73倍。&lt;h4&gt;结论&lt;/h4&gt;基于深度学习的mMIMO预编码器提供了一种有效的方法来解决现有的计算复杂性问题，同时保持高效的总数据率性能。这表明在不同的通信环境下，该模型具有良好的适应性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Massive multiple-input multiple-output (mMIMO) technology has transformedwireless communication by enhancing spectral efficiency and network capacity.This paper proposes a novel deep learning-based mMIMO precoder to tackle thecomplexity challenges of existing approaches, such as weighted minimum meansquare error (WMMSE), while leveraging meta-learning domain generalization anda teacher-student architecture to improve generalization across diversecommunication environments. When deployed to a previously unseen site, theproposed model achieves excellent sum-rate performance while maintaining lowcomputational complexity by avoiding matrix inversions and by using a simplerneural network structure. The model is trained and tested on a customray-tracing dataset composed of several base station locations. Theexperimental results indicate that our method effectively balancescomputational efficiency with high sum-rate performance while showcasing stronggeneralization performance in unseen environments. Furthermore, withfine-tuning, the proposed model outperforms WMMSE across all tested sites andSNR conditions while reducing complexity by at least 73$\times$.</description>
      <author>example@mail.com (Ali Hasanzadeh Karkan, Ahmed Ibrahim, Jean-François Frigon, François Leduc-Primeau)</author>
      <guid isPermaLink="false">2502.08757v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Visual Graph Question Answering with ASP and LLMs for Language Parsing</title>
      <link>http://arxiv.org/abs/2502.09211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings ICLP 2024, arXiv:2502.08453. This work was partially  funded from the Bosch Center for AI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了如何将回答集编程（ASP）与视觉和自然语言处理模块结合，以解决图像中图结构的视觉问答(VQA)问题。&lt;h4&gt;背景&lt;/h4&gt;VQA是需要处理多模态输入的挑战性问题。ASP在为模块化VQA架构增加可解释性和透明度方面显示出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的方法来集成回答集编程与视觉和自然语言处理模块，以解决基于图像图结构的新颖且复杂的VQA变体问题。&lt;h4&gt;方法&lt;/h4&gt;提出的解决方案采用了一种模块化神经符号方法，结合光学图形识别进行图形解析、预训练的OCR神经网络进行标签解析、大型语言模型(LLM)用于语言处理以及ASP用于推理。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法作为第一个基准，在数据集上的整体平均准确率为73%。此外，评估证明了模块化神经符号系统（尤其是不涉及进一步训练和逻辑编程）解决复杂VQA任务的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过提出的方法，展示了在图结构图像中的VQA问题上采用模块化神经符号方法的有效性，并为进一步的研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;视觉问答(VQA)是一个需要处理多模态输入的挑战性问题。回答集编程(ASP)在为模块化的VQA架构增加可解释性和透明度方面显示出巨大潜力。本文提出了一种结合光学图形识别、预训练OCR神经网络、大型语言模型(LLM)和ASP进行推理的新方法，以解决图像中图结构的独特且复杂的VQA变体问题，并在一个新数据集上达到了73%的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.4204/EPTCS.416.2&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Question Answering (VQA) is a challenging problem that requires toprocess multimodal input. Answer-Set Programming (ASP) has shown greatpotential in this regard to add interpretability and explainability to modularVQA architectures. In this work, we address the problem of how to integrate ASPwith modules for vision and natural language processing to solve a new anddemanding VQA variant that is concerned with images of graphs (not graphs insymbolic form). Images containing graph-based structures are an ubiquitous andpopular form of visualisation. Here, we deal with the particular problem ofgraphs inspired by transit networks, and we introduce a novel dataset thatamends an existing one by adding images of graphs that resemble metro lines.Our modular neuro-symbolic approach combines optical graph recognition forgraph parsing, a pretrained optical character recognition neural network forparsing labels, Large Language Models (LLMs) for language processing, and ASPfor reasoning. This method serves as a first baseline and achieves an overallaverage accuracy of 73% on the dataset. Our evaluation provides furtherevidence of the potential of modular neuro-symbolic systems, in particular withpretrained models that do not involve any further training and logicprogramming for reasoning, to solve complex VQA tasks.</description>
      <author>example@mail.com (Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch)</author>
      <guid isPermaLink="false">2502.09211v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation</title>
      <link>http://arxiv.org/abs/2502.09268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着嵌入式人工智能的快速发展，通用机器人决策中的视觉-语言-行动（VLA）模型取得了显著进展。然而，大多数现有的VLAs未能考虑部署过程中不可避免遇到的外部干扰，导致性能下降。&lt;h4&gt;背景&lt;/h4&gt;当前VLA模型在面对实际应用场景时难以处理未知或未预见的状态信息变化，影响了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于内部模型控制（IMC）原则的新闭环视觉-语言-行动方法GEVRM，以增强机器人视觉操作的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;在GEVRM中引入文本引导视频生成模型，用于生成未来视觉规划目标；同时通过原型对比学习优化模拟响应，使模型能够隐式区分外部环境中的干扰因素。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的GEVRM在标准和受扰的CALVIN基准测试上均达到最新技术水平，并且在现实世界的机器人任务中显示出显著改进。&lt;h4&gt;结论&lt;/h4&gt;通过整合IMC原则，新方法能够有效提高VLA模型面对未知状态时的表现，进而提升机器人的适应性和执行能力。&lt;h4&gt;翻译&lt;/h4&gt;随着嵌入式人工智能的发展，视觉-语言-行动模型（VLA）在通用机器人决策方面取得了显著进步。然而，大多数现有的VLAs未能处理部署过程中遇到的外部干扰，导致性能下降。我们提出了一种新的闭环VLA方法GEVRM，该方法整合了内部模型控制原则，以增强机器人视觉操作的鲁棒性。此外，通过文本引导视频生成和原型对比学习优化模拟响应，使模型能够区分并适应外部环境中的扰动。实验表明，在标准和受扰CALVIN基准测试中，以及在现实世界任务中，GEVRM均表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of embodied artificial intelligence, significantprogress has been made in vision-language-action (VLA) models for general robotdecision-making. However, the majority of existing VLAs fail to account for theinevitable external perturbations encountered during deployment. Theseperturbations introduce unforeseen state information to the VLA, resulting ininaccurate actions and consequently, a significant decline in generalizationperformance. The classic internal model control (IMC) principle demonstratesthat a closed-loop system with an internal model that includes external inputsignals can accurately track the reference input and effectively offset thedisturbance. We propose a novel closed-loop VLA method GEVRM that integratesthe IMC principle to enhance the robustness of robot visual manipulation. Thetext-guided video generation model in GEVRM can generate highly expressivefuture visual planning goals. Simultaneously, we evaluate perturbations bysimulating responses, which are called internal embeddings and optimizedthrough prototype contrastive learning. This allows the model to implicitlyinfer and distinguish perturbations from the external environment. The proposedGEVRM achieves state-of-the-art performance on both standard and perturbedCALVIN benchmarks and shows significant improvements in realistic robot tasks.</description>
      <author>example@mail.com (Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang)</author>
      <guid isPermaLink="false">2502.09268v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Inverse-Mapping Model for a Flapping Robotic Wing</title>
      <link>http://arxiv.org/abs/2502.09378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. 10 Pages 5 figures + 2 figures in appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种针对拍翅机器人系统的机器学习解决方案，旨在解决复杂的输入输出映射问题。&lt;h4&gt;背景&lt;/h4&gt;在复杂系统中（例如拍翅机器人），将输入动作（翅膀的运动）与输出结果（空气动力学力）进行准确映射非常困难，并且为了实时控制而逆向求解该映射是计算上不可行的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种机器学习模型，用于解决拍翅机器人系统中的复杂动力学问题，通过从实验数据中学习输入翅膀运动以生成期望的空气动力学力输出。&lt;h4&gt;方法&lt;/h4&gt;使用了为时间序列数据定制的序列到序列（Sequence-to-Sequence）模型，并引入了一种新颖的自适应频谱层来实现频率领域的表示学习。同时开发了一个能够同时测量翅膀3D运动和空气动力学力的拍翅系统，用于训练机器学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法在测试数据集上的中间损失上比最先进的基于变压器（Transformer）的模型提高了11%，并且推理时间更短，使得其实时控制成为可能。&lt;h4&gt;结论&lt;/h4&gt;这种开源的数据和框架有望改善由复杂动力学系统所支配的各种设备中的建模与实时控制问题，从仿生机器人到生物医学装置。&lt;h4&gt;翻译&lt;/h4&gt;在控制系统中，通过调整输入来调控系统的动态行为以达到预期的结果。然而，在复杂的拍翅机器人等涉及精细流体运动的系统中，将输入动作映射到输出结果非常困难，并且逆向求解这种映射用于实时控制是计算上不可行的。本文提出了一种基于机器学习的方法，通过实验数据训练模型来解决拍翅系统中的逆问题。该方法在测试集上的性能优于先进的Transformer模型，同时具备更短的推理时间，使得其实时应用成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In systems control, the dynamics of a system are governed by modulating itsinputs to achieve a desired outcome. For example, to control the thrust of aquad-copter propeller the controller modulates its rotation rate, relying on astraightforward mapping between the input rotation rate and the resultingthrust. This mapping can be inverted to determine the rotation rate needed togenerate a desired thrust. However, in complex systems, such as flapping-wingrobots where intricate fluid motions are involved, mapping inputs (wingkinematics) to outcomes (aerodynamic forces) is nontrivial and inverting thismapping for real-time control is computationally impractical. Here, we report amachine-learning solution for the inverse mapping of a flapping-wing systembased on data from an experimental system we have developed. Our model learnsthe input wing motion required to generate a desired aerodynamic force outcome.We used a sequence-to-sequence model tailored for time-series data andaugmented it with a novel adaptive-spectrum layer that implementsrepresentation learning in the frequency domain. To train our model, wedeveloped a flapping wing system that simultaneously measures the wing'saerodynamic force and its 3D motion using high-speed cameras. We demonstratethe performance of our system on an additional open-source dataset of aflapping wing in a different flow regime. Results show superior performancecompared with more complex state-of-the-art transformer-based models, with 11%improvement on the test datasets median loss. Moreover, our model showssuperior inference time, making it practical for onboard robotic control. Ouropen-source data and framework may improve modeling and real-time control ofsystems governed by complex dynamics, from biomimetic robots to biomedicaldevices.</description>
      <author>example@mail.com (Hadar Sharvit, Raz Karl, Tsevi Beatus)</author>
      <guid isPermaLink="false">2502.09378v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>CoL3D: Collaborative Learning of Single-view Depth and Camera Intrinsics for Metric 3D Shape Recovery</title>
      <link>http://arxiv.org/abs/2502.08902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;从单张图像恢复三维形状的度量在机器人和具身智能应用中特别相关，准确的空间理解对于导航和与环境互动至关重要。通常，主流方法通过单目深度估计实现这一目标，但没有相机内参的情况下无法仅凭深度信息恢复3D度量形状。&lt;h4&gt;背景&lt;/h4&gt;从单张图像恢复三维形状的度量在机器人和具身智能应用中特别相关，准确的空间理解对于导航和与环境互动至关重要。然而，没有相机内参的情况下无法仅凭深度信息恢复3D度量形状。&lt;h4&gt;目的&lt;/h4&gt;提出一种协作学习框架（CoL3D），用于同时估计单张图像中的深度和相机内参，以从单张图像中学习三维形状的度量。&lt;h4&gt;方法&lt;/h4&gt;该研究采用统一网络，并在三个层次上进行协同优化：深度、相机内参以及点云。对于相机内参估计，设计了一种规范入射场机制作为先验知识，使模型能够学习残差入射场以增强校准能力。同时，在点云空间中引入形状相似性测量损失，以提高机器人应用所需的3D形状质量。&lt;h4&gt;主要发现&lt;/h4&gt;深度信息和相机内参之间存在相互关系，通过协同优化可以更准确地估计深度并计算出度量三维形状所必需的相机参数。&lt;h4&gt;结论&lt;/h4&gt;CoL3D框架在多个室内外基准数据集上表现优异，在单个数据集中进行训练和测试时，无论是深度估计还是相机校准性能都显著优于现有方法。该研究为机器人感知能力提供了高质量的3D形状信息。&lt;h4&gt;翻译&lt;/h4&gt;从单张图像恢复三维形状度量对机器人技术及具身智能应用尤为重要，准确的空间理解对于导航与环境互动至关重要。通常，主流方法通过单目深度估计实现这一目标，但没有相机内参的情况下仅凭深度无法恢复3D度量形状。研究证明了深度信息作为三维先验约束的作用，并揭示了其与相机参数之间的相互关系。基于此，提出了一种协同学习框架（CoL3D），用于同时估计单张图像中的深度和相机内参，以从单张图像中获取3D形状的度量。该方法采用了统一网络，并在三个层次上进行优化：深度、相机内参及点云。此外，在点云空间引入了形状相似性测量损失来提升三维形状质量。实验结果表明，CoL3D在多个室内外基准数据集中均表现出色，无论是在单张图像的深度估计还是相机校准性能方面都远超现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering the metric 3D shape from a single image is particularly relevantfor robotics and embodied intelligence applications, where accurate spatialunderstanding is crucial for navigation and interaction with environments.Usually, the mainstream approaches achieve it through monocular depthestimation. However, without camera intrinsics, the 3D metric shape can not berecovered from depth alone. In this study, we theoretically demonstrate thatdepth serves as a 3D prior constraint for estimating camera intrinsics anduncover the reciprocal relations between these two elements. Motivated by this,we propose a collaborative learning framework for jointly estimating depth andcamera intrinsics, named CoL3D, to learn metric 3D shapes from single images.Specifically, CoL3D adopts a unified network and performs collaborativeoptimization at three levels: depth, camera intrinsics, and 3D point clouds.For camera intrinsics, we design a canonical incidence field mechanism as aprior that enables the model to learn the residual incident field for enhancedcalibration. Additionally, we incorporate a shape similarity measurement lossin the point cloud space, which improves the quality of 3D shapes essential forrobotic applications. As a result, when training and testing on a singledataset with in-domain settings, CoL3D delivers outstanding performance in bothdepth estimation and camera calibration across several indoor and outdoorbenchmark datasets, which leads to remarkable 3D shape quality for theperception capabilities of robots.</description>
      <author>example@mail.com (Chenghao Zhang, Lubin Fan, Shen Cao, Bojian Wu, Jieping Ye)</author>
      <guid isPermaLink="false">2502.08902v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>If Multi-Agent Debate is the Answer, What is the Question?</title>
      <link>http://arxiv.org/abs/2502.08788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This position paper takes a critical view of the status quo of MAD  research, and outline multiple potential directions to improve MAD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多智能体辩论（MAD）作为一种通过在推理过程中让多个代理进行迭代讨论来提高大型语言模型（LLMs）事实准确性和推理质量的方法，已经显示出潜力。然而，当前的MAD研究存在评估实践中的关键不足。&lt;h4&gt;背景&lt;/h4&gt;现有的MAD研究受限于有限的数据集重叠和不一致的基准测试，这引发了对其泛化能力的重大担忧。&lt;h4&gt;目的&lt;/h4&gt;本文系统地评估了五种代表性的MAD方法在九个基准上使用四个基础模型的表现。&lt;h4&gt;方法&lt;/h4&gt;采用四种基础模型对五个具有代表性多代理辩论（MAD）的方法进行了全面的性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，尽管消耗额外的推理时间计算量，但MAD方法未能可靠地超越简单的单代理基线如链式思维和自洽性。此外，作者还发现了模态异质性的显著影响，并提出了Heter-MAD框架以增强当前MAD框架的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究指出了多智能体辩论在提高大型语言模型性能方面的局限性和改进方向，旨在激发这一领域更广泛的对话与未来工作。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文描述了多代理辩论（MAD）技术的现状、评估方法及其发现和建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent debate (MAD) has emerged as a promising approach to enhance thefactual accuracy and reasoning quality of large language models (LLMs) byengaging multiple agents in iterative discussions during inference. Despite itspotential, we argue that current MAD research suffers from criticalshortcomings in evaluation practices, including limited dataset overlap andinconsistent baselines, raising significant concerns about generalizability.Correspondingly, this paper presents a systematic evaluation of fiverepresentative MAD methods across nine benchmarks using four foundationalmodels. Surprisingly, our findings reveal that MAD methods fail to reliablyoutperform simple single-agent baselines such as Chain-of-Thought andSelf-Consistency, even when consuming additional inference-time computation.From our analysis, we found that model heterogeneity can significantly improveMAD frameworks. We propose Heter-MAD enabling a single LLM agent to access theoutput from heterogeneous foundation models, which boosts the performance ofcurrent MAD frameworks. Finally, we outline potential directions for advancingMAD, aiming to spark a broader conversation and inspire future work in thisarea.</description>
      <author>example@mail.com (Hangfan Zhang, Zhiyao Cui, Xinrun Wang, Qiaosheng Zhang, Zhen Wang, Dinghao Wu, Shuyue Hu)</author>
      <guid isPermaLink="false">2502.08788v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia</title>
      <link>http://arxiv.org/abs/2502.09173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 Workshop on Large Language Models and Generative AI for  Health&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种针对认知障碍患者家庭活动数据的时间序列表征学习框架，通过将时间序列活动转化为文本序列并利用PageRank向量进行低秩表示来揭示关键行为模式。&lt;h4&gt;背景&lt;/h4&gt;远程医疗监测中，从高频数据中提取重要的病人行为模式是至关重要的。本研究关注于阿尔茨海默病患者的家庭活动数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督学习的两阶段方法，用以挖掘认知障碍患者的低秩结构和关键行为特征。&lt;h4&gt;方法&lt;/h4&gt;第一阶段将时间序列活动转化为文本序列，并使用预训练的语言模型进行编码；第二阶段采用基于PageRank的方法生成向量表示，捕捉潜在状态转换，提高数据可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了所提框架在支持认知状态预测、个性化护理干预和大规模健康监测方面的潜力。这种低秩表示不仅增强了模型的可解释性，还促进了聚类分析和过渡分析，揭示了与临床指标如MMSE（简易精神状态检查）和ADAS-COG评分相关的关键行为模式。&lt;h4&gt;结论&lt;/h4&gt;该研究提供的自监督学习框架能够有效地从家庭活动数据中提取关键信息，为远程医疗监测提供了有价值的见解和支持。&lt;h4&gt;翻译&lt;/h4&gt;在远程医疗服务监控领域，时间序列表示的学习能够揭示来自高频数据中的重要患者行为模式。这项研究分析了患有痴呆症的个体的家庭生活活动数据，并提出了一种两阶段自监督学习方法，旨在揭露低秩结构。第一阶段将时间序列活动转变为文本序列，这些序列由预训练的语言模型编码，提供了一个基于PageRank的方法生成的高度丰富的高维潜在状态空间。这种PageRank向量捕捉到潜在的状态转换，有效地压缩了复杂的行为数据，使之更简明易懂。该低秩表示不仅增强了模型的可解释性，并且有助于聚类和过渡分析，揭示与MMSE（简易精神状况检查）及ADAS-COG评分等临床指标密切相关的关键行为模式。我们的发现展示了这种框架在支持认知状态预测、个性化护理干预以及大规模健康监控方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In remote healthcare monitoring, time series representation learning revealscritical patient behavior patterns from high-frequency data. This studyanalyzes home activity data from individuals living with dementia by proposinga two-stage, self-supervised learning approach tailored to uncover low-rankstructures. The first stage converts time-series activities into text sequencesencoded by a pre-trained language model, providing a rich, high-dimensionallatent state space using a PageRank-based method. This PageRank vector captureslatent state transitions, effectively compressing complex behaviour data into asuccinct form that enhances interpretability. This low-rank representation notonly enhances model interpretability but also facilitates clustering andtransition analysis, revealing key behavioral patterns correlated withclinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate theframework's potential in supporting cognitive status prediction, personalizedcare interventions, and large-scale health monitoring.</description>
      <author>example@mail.com (Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott)</author>
      <guid isPermaLink="false">2502.09173v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>$\mathsf{CSMAE~}$:~Cataract Surgical Masked Autoencoder (MAE) based Pre-training</title>
      <link>http://arxiv.org/abs/2502.08822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, Accepted to IEEE International Symposium on Biomedical  Imaging (ISBI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Masked Autoencoder (MAE)的预训练方法CSMAE，用于白内障手术视频分析。这种方法通过考虑空间和时间的重要性来选择掩码令牌而非随机选择，并使用大量白内障手术视频数据集提高了模型的学习效率。&lt;h4&gt;背景&lt;/h4&gt;自动分析外科手术视频对于提高外科培训、工作流程优化及术后评估至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门用于白内障手术视频分析的预训练方法，以改善模型在低数据环境下的学习能力和鲁棒性，并为下游任务提供强大的基础。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于Masked Autoencoder (MAE)的新颖预训练策略CSMAE，该策略根据令牌的空间和时间重要性来选择掩码。利用大量的白内障手术视频数据集进行模型训练，并通过微调适应特定的下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;在两个不同数据集（D99 和 Cataract-101）上的步骤识别任务测试中，该方法超越了当前最先进的自监督预训练和适配器基转移学习方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了MAE基础预训练在手术视频分析领域的潜力，并为未来的研究设定了新的标准。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated analysis of surgical videos is crucial for improving surgicaltraining, workflow optimization, and postoperative assessment. We introduce aCSMAE, Masked Autoencoder (MAE)-based pretraining approach, specificallydeveloped for Cataract Surgery video analysis, where instead of randomlyselecting tokens for masking, they are selected based on the spatiotemporalimportance of the token. We created a large dataset of cataract surgery videosto improve the model's learning efficiency and expand its robustness inlow-data regimes. Our pre-trained model can be easily adapted for specificdownstream tasks via fine-tuning, serving as a robust backbone for furtheranalysis. Through rigorous testing on a downstream step-recognition task on twoCataract Surgery video datasets, D99 and Cataract-101, our approach surpassescurrent state-of-the-art self-supervised pretraining and adapter-based transferlearning methods by a significant margin. This advancement not onlydemonstrates the potential of our MAE-based pretraining in the field ofsurgical video analysis but also sets a new benchmark for future research.</description>
      <author>example@mail.com (Nisarg A. Shah, Wele Gedara Chaminda Bandara, Shameema Skider, S. Swaroop Vedula, Vishal M. Patel)</author>
      <guid isPermaLink="false">2502.08822v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound</title>
      <link>http://arxiv.org/abs/2502.08774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了如何利用测试时间自适应(TTA)技术来改进胎儿大脑亚皮层区域自动分割的准确性，特别关注在不同领域偏移条件下的模型性能。&lt;h4&gt;背景&lt;/h4&gt;手动标注胎儿超声图像中的亚皮层脑区是一个挑战性问题。虽然基于深度学习的方法可以实现自动化分割，但在面对新的数据集时（特别是自由手操作的超声图像），预训练模型的表现通常会下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合正常解剖图谱作为先验知识的新TTA方法，以提高胎儿大脑亚皮层区域自动分割在不同领域偏移下的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用测试时间自适应技术来应对真实和模拟的领域偏移。2. 提出了一种新的TTA方法，该方法通过整合正常解剖图谱作为先验知识，改进了模型对不同类型领域变化的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在不同类型的领域偏移条件下，所提出的方法相对于其他TTA技术显示出显著性能提升。这表明结合先验知识可以有效地提高胎儿大脑亚皮层区域分割任务中的模型泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过引入一种新的TTA方法和解剖图谱作为先验知识，大大改善了胎儿超声图像中特定脑区的自动分割效果，在未来的临床应用中有很大潜力。&lt;h4&gt;翻译&lt;/h4&gt;监测胎儿大脑皮层下的区域在超声（US）图像中的生长有助于识别发育异常。手动标注这些区域是一项具有挑战性的任务，但最近的研究表明可以使用深度学习实现自动化。然而，将预训练模型应用于新的自由手US体积数据时，由于获取和对齐方式的巨大差异，通常会导致性能下降。在这项工作中，我们首先展示了测试时间适应(TTA)可以在存在真实和模拟领域偏移的情况下改善模型性能。此外，我们提出了一种新颖的TTA方法，通过将规范图集作为解剖学的先验知识来改进它。在不同类型领域的偏移情况下，我们对不同TTA方法的性能进行了基准测试，并展示了我们的提议方法带来的改进。这些改进可能有助于进一步推动胎儿大脑发育的自动监测。我们的代码可在https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring the growth of subcortical regions of the fetal brain in ultrasound(US) images can help identify the presence of abnormal development. Manuallysegmenting these regions is a challenging task, but recent work has shown thatit can be automated using deep learning. However, applying pretrained models tounseen freehand US volumes often leads to a degradation of performance due tothe vast differences in acquisition and alignment. In this work, we firstdemonstrate that test time adaptation (TTA) can be used to improve modelperformance in the presence of both real and simulated domain shifts. Wefurther propose a novel TTA method by incorporating a normative atlas as aprior for anatomy. In the presence of various types of domain shifts, webenchmark the performance of different TTA methods and demonstrate theimprovements brought by our proposed approach, which may further facilitateautomated monitoring of fetal brain development. Our code is available athttps://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation.</description>
      <author>example@mail.com (Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale)</author>
      <guid isPermaLink="false">2502.08774v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Graph Contrastive Pretraining for Device-level Integrated Circuits</title>
      <link>http://arxiv.org/abs/2502.08949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;自我监督的图表示学习在社交网络分析、分子设计和电子设计自动化（EDA）等领域取得了重大进展。然而，以往关于EDA的研究主要集中在门级数字电路的表示上，忽略了模拟和混合信号电路。&lt;h4&gt;背景&lt;/h4&gt;自我监督的图表示学习已在多个领域取得显著进步，但在EDA中主要集中于门级数字电路，未充分考虑模拟及混合信号电路。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究未能涵盖模拟与混合信号电路表示的学习方法空白。&lt;h4&gt;方法&lt;/h4&gt;提出DICE模型：一种面向任何在设备级别表达的电路的第一种自我监督预训练图神经网络（GNN），采用消息传递神经网络(MPNN)并通过图对比学习进行训练。DICE的预训练过程无需仿真，引入了两种新颖的数据增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，DICE模型在三种下游任务中取得了显著性能提升，表明其对于模拟和数字电路都具有有效性。&lt;h4&gt;结论&lt;/h4&gt;DICE是一个突破性的工具，它不仅填补了EDA领域自我监督学习方法的空白，还为未来的电子设计提供了强大的预训练图神经网络模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容由英文翻译成中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised graph representation learning has driven significantadvancements in domains such as social network analysis, molecular design, andelectronics design automation (EDA). However, prior works in EDA have mainlyfocused on the representation of gate-level digital circuits, failing tocapture analog and mixed-signal circuits. To address this gap, we introduceDICE: Device-level Integrated Circuits Encoder, the first self-supervisedpretrained graph neural network (GNN) model for any circuit expressed at thedevice level. DICE is a message-passing neural network (MPNN) trained throughgraph contrastive learning, and its pretraining process is simulation-free,incorporating two novel data augmentation techniques. Experimental resultsdemonstrate that DICE achieves substantial performance gains across threedownstream tasks, underscoring its effectiveness for both analog and digitalcircuits.</description>
      <author>example@mail.com (Sungyoung Lee, Ziyi Wang, Seunggeun Kim, Taekyun Lee, David Z. Pan)</author>
      <guid isPermaLink="false">2502.08949v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Neuro-Symbolic Contrastive Learning for Cross-domain Inference</title>
      <link>http://arxiv.org/abs/2502.09213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings ICLP 2024, arXiv:2502.08453&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;预训练语言模型（PLMs）在自然语言推理任务中取得了重大进展，但它们对文本扰动的敏感性和对大规模数据集的依赖表明了过度依赖浅层启发式方法。相比之下，归纳逻辑编程（ILP）擅长于从多样、稀疏且有限的数据集中推导出逻辑关系，但由于其离散特性需要输入精确指定，从而限制了应用范围。&lt;h4&gt;背景&lt;/h4&gt;预训练语言模型在自然语言推理任务中的表现尽管优秀，但存在对文本扰动敏感和依赖大规模数据集的问题。归纳逻辑编程能够处理多样且稀疏的数据，但因为其离散性质而难以广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合神经符号对比学习的方法来弥合预训练语言模型和归纳逻辑编程之间的差距，以改善在复杂、嘈杂且稀疏的逻辑函数空间中的推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过将数据表示为逻辑程序和一组逻辑规则，在神经符号框架中嵌入抽象逻辑关系。这种方法利用连续和可微优化来提高逻辑准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，这种新方法能够显著改善模型在泛化能力和推理方面的性能。&lt;h4&gt;结论&lt;/h4&gt;提出了神经符号对比学习的方法，成功地将预训练语言模型的深度学习能力与归纳逻辑编程的精确推理相结合，在处理稀疏和嘈杂数据时表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.4204/EPTCS.416.6&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained language models (PLMs) have made significant advances in naturallanguage inference (NLI) tasks, however their sensitivity to textualperturbations and dependence on large datasets indicate an over-reliance onshallow heuristics. In contrast, inductive logic programming (ILP) excels atinferring logical relationships across diverse, sparse and limited datasets,but its discrete nature requires the inputs to be precisely specified, whichlimits their application. This paper proposes a bridge between the twoapproaches: neuro-symbolic contrastive learning. This allows for smooth anddifferentiable optimisation that improves logical accuracy across an otherwisediscrete, noisy, and sparse topological space of logical functions. We showthat abstract logical relationships can be effectively embedded within aneuro-symbolic paradigm, by representing data as logic programs and sets oflogic rules. The embedding space captures highly varied textual informationwith similar semantic logical relations, but can also separate similar textualrelations that have dissimilar logical relations. Experimental resultsdemonstrate that our approach significantly improves the inference capabilitiesof the models in terms of generalisation and reasoning.</description>
      <author>example@mail.com (Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks)</author>
      <guid isPermaLink="false">2502.09213v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.08884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为ShapeLib的方法，该方法利用前沿大型语言模型的先验知识来设计一个包含3D形状抽象函数库。ShapeLib能够根据文本描述和示例形状集合发现可重复使用的程序化表示。&lt;h4&gt;背景&lt;/h4&gt;程序化表示是三维形状编码的一种理想、多功能且流行的形式，但手动或数据驱动的设计过程具有挑战性。现有的研究尝试通过探索如何识别一个可以解释整个形状家族的程序化函数库来解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于前沿大型语言模型先验知识的方法（ShapeLib），用于设计可扩展和易于修改的3D形状抽象函数库，以满足特定的设计意图，并能从不同的视觉模态中推断出相应的形状程序。&lt;h4&gt;方法&lt;/h4&gt;用户可以提供包含所需功能的文字描述或示例形状集。ShapeLib通过提出并验证这些可能的功能应用和实现来探索符合设计意图的程序化抽象。此外，训练了一个识别网络，该网络能够基于ShapeLib库从不同视觉模态中推断出形状程序。&lt;h4&gt;主要发现&lt;/h4&gt;生成的形状函数不仅具有表达性，并且能够超越种子集合之外推广到整个形状家族。这些参数具有语义可解释性和灵活性，可以修改以产生合理的形状变化。&lt;h4&gt;结论&lt;/h4&gt;ShapeLib方法在不同数据集上进行了评估，展示出明显优于现有方法和替代方案的优势，表明这种方法对于三维形状的设计和编辑具有重要的实用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法旨在通过利用大型语言模型的先验知识来设计程序化函数库，这些函数库能够根据给定的设计意图（如文本描述或示例形状）发现并实现可重复使用的程序化表示。生成的功能不仅表达能力强且具有良好的泛化能力，并能从不同的视觉输入中推断出相应的程序。这种方法在评估中表现出显著的优势，为三维形状的创建和编辑提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Procedural representations are desirable, versatile, and popular shapeencodings. Authoring them, either manually or using data-driven procedures,remains challenging, as a well-designed procedural representation should becompact, intuitive, and easy to manipulate. A long-standing problem in shapeanalysis studies how to discover a reusable library of procedural functions,with semantically aligned exposed parameters, that can explain an entire shapefamily. We present ShapeLib as the first method that leverages the priors offrontier LLMs to design a library of 3D shape abstraction functions. Our systemaccepts two forms of design intent: text descriptions of functions to includein the library and a seed set of exemplar shapes. We discover proceduralabstractions that match this design intent by proposing, and then validating,function applications and implementations. The discovered shape functions inthe library are not only expressive but also generalize beyond the seed set toa full family of shapes. We train a recognition network that learns to infershape programs based on our library from different visual modalities(primitives, voxels, point clouds). Our shape functions have parameters thatare semantically interpretable and can be modified to produce plausible shapevariations. We show that this allows inferred programs to be successfullymanipulated by an LLM given a text prompt. We evaluate ShapeLib on differentdatasets and show clear advantages over existing methods and alternativeformulations.</description>
      <author>example@mail.com (R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie)</author>
      <guid isPermaLink="false">2502.08884v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection</title>
      <link>http://arxiv.org/abs/2502.09271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的针对图神经网络（GNN）的攻击方式，即通过注入孤立子图来欺骗链接推荐器和节点分类器，并展示了LiSA框架的有效性。&lt;h4&gt;背景&lt;/h4&gt;近年来的研究发现，尽管图神经网络在处理具有图结构的数据时表现出色，但它们对对抗性攻击非常敏感。传统的攻击方法通常不适用于实际场景。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一问题，论文提出了一个新的对抗性场景，并引入了LiSA框架来同时满足两个对抗目标：欺骗链接推荐器和降低节点分类准确性。&lt;h4&gt;方法&lt;/h4&gt;该研究采用了双代理模型和两级优化技术以实现其攻击策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过注入孤立子图可以成功地误导GNN系统中的链接推荐器，并且这种攻击方式会对节点分类的准确性产生负面影响。&lt;h4&gt;结论&lt;/h4&gt;提出的LiSA框架在真实世界的数据集上展示了有效的性能和潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）在处理具有图结构的数据时表现出色，但最近的研究揭示了它们对对抗性攻击的高度敏感性。传统的依赖于修改原始图或向人工创建的节点添加链接的方法通常在实际环境中不可行。本文提出了一种新的涉及注入孤立子图以欺骗GNN系统中链接推荐器和节点分类器的对抗场景。具体而言，该方法误导链接推荐器建议目标受害节点与子图之间的链接，从而鼓励用户无意间建立连接并降低节点分类准确性。为了解决这一问题，我们提出了LiSA框架，它采用双代理模型和两级优化以同时满足两个对抗性目标。大量的实验在真实世界的数据集上验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inmodeling data with graph structures, yet recent research reveals theirsusceptibility to adversarial attacks. Traditional attack methodologies, whichrely on manipulating the original graph or adding links to artificially creatednodes, often prove impractical in real-world settings. This paper introduces anovel adversarial scenario involving the injection of an isolated subgraph todeceive both the link recommender and the node classifier within a GNN system.Specifically, the link recommender is mislead to propose links between targetedvictim nodes and the subgraph, encouraging users to unintentionally establishconnections and that would degrade the node classification accuracy, therebyfacilitating a successful attack. To address this, we present the LiSAframework, which employs a dual surrogate model and bi-level optimization tosimultaneously meet two adversarial objectives. Extensive experiments onreal-world datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Wenlun Zhang, Enyan Dai, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.09271v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation</title>
      <link>http://arxiv.org/abs/2502.08818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种通过连续几何变换动态重构词嵌入的方法，旨在提高语言模型在处理复杂句子结构和领域特定术语时的灵活性与性能。&lt;h4&gt;背景&lt;/h4&gt;静态词嵌入限制了词汇的灵活性，在面对复杂的句法或领域变化时表现不佳。这可能导致语义关系维持不充分，影响语言模型的一致性和流畅性。&lt;h4&gt;目的&lt;/h4&gt;开发一种动态重构词嵌入的方法，以解决静态词嵌入在复杂文本中的局限性问题，并提高语言模型处理结构化和领域适应性任务的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于流形的转换机制来调节词汇位置，在保证语义关系连续的同时允许词嵌入发生可控的变化。该机制通过连续几何变换实现动态重构，从而增强语义一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，通过重新配置词嵌入可以降低困惑度（perplexity），提高词汇连贯性和句级别的连续性。特别是在结构化和领域适应性的文本生成任务中效果显著。同时，动态调节的词嵌入表现出更广泛的词汇多样性，并减少重复的标记模式。&lt;h4&gt;结论&lt;/h4&gt;尽管训练过程因迭代优化词嵌入而导致复杂度增加，但推理效率保持较高水平，确保了实际应用中的可行性。此外，在多个数据集上的评估表明，动态调整后的词嵌入在处理领域特定的任务中表现出更强的语言模型一致性与流畅性。&lt;h4&gt;翻译&lt;/h4&gt;上下文适应性的词嵌入调整是语言模型维持文本连贯性和语义关系的关键因素。静态词嵌入通常限制了词汇的灵活性，在面对复杂句子结构或领域术语转变时会导致性能下降。为了克服这一局限，研究者开发了一种基于连续几何变换动态重构词嵌入的方法，使表示能够随话语结构的变化而演化。采用一种流形为基础的转换机制来调控词汇位置，确保在不同文本上下文中保持语言关系的同时允许词嵌入进行可控变化。实证研究表明，通过调整词嵌入可以减少困惑度、提高词汇连贯性和句级别的连续性，特别是在复杂和领域适应性的文本生成任务中表现尤为出色。比较分析结果显示，在动态重新配置表示后，尽管训练的复杂性增加，但推理阶段依然保持高效，并且上下文一致性更强，减少了标记依赖关系的错位，同时保持了语言模型输出的流畅性。此外，评估还表明在处理多样数据集时，该方法使词嵌入表现出更加丰富的词汇多样性，并减少重复模式的发生，从而支持更灵活的表示学习过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contextual adaptation in token embeddings plays a central role in determininghow well language models maintain coherence and retain semantic relationshipsover extended text sequences. Static embeddings often impose constraints onlexical flexibility, leading to suboptimal performance when faced with complexsentence structures or domain-specific terminology shifts. To address thislimitation, a structured approach was developed for dynamically reconfiguringtoken embeddings through continuous geometric transformations, ensuring thatrepresentations evolved in response to evolving discourse structures. Amanifold-based transformation mechanism was integrated to regulate lexicalpositioning, allowing embeddings to undergo controlled shifts while preservinglinguistic relationships across varying textual contexts. Empirical evaluationsdemonstrated that embedding reconfiguration contributed to reductions inperplexity, improved lexical coherence, and enhanced sentence-level continuity,particularly in structured and domain-adaptive text generation tasks.Comparative analyses of embedding drift indicated that dynamically restructuredrepresentations maintained stronger contextual consistency, reducingmisalignment in token dependencies while preserving fluency in languagemodeling outputs. Computational overhead assessments confirmed that whiletraining complexity increased due to the iterative refinement of embeddings,inference remained efficient, ensuring practical feasibility for real-timegeneration. Evaluations across multiple datasets further demonstrated thatdynamically modulated embeddings exhibited broader lexical diversity, reducingrepetitive token patterns and enabling a more adaptable representation learningprocess.</description>
      <author>example@mail.com (Koinis Vassilis, Godfrey Milbourne, Harriet Featherstone, Xanthe Peverell, Yorick Bletchley, Zachary Montford)</author>
      <guid isPermaLink="false">2502.08818v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Advancing machine fault diagnosis: A detailed examination of convolutional neural networks</title>
      <link>http://arxiv.org/abs/2502.08689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;综述了卷积神经网络(CNN)在机器故障诊断中的应用，包括其理论基础、架构变化和实际应用。分析了CNN在此领域的优缺点，并探讨了数据增强、迁移学习和混合架构等最近的进展。&lt;h4&gt;背景&lt;/h4&gt;随着机械设备复杂性和操作效率及安全性的需求增加，先进的故障诊断技术变得越来越重要。卷积神经网络因其在故障检测与分类中的强大能力和准确性而脱颖而出。&lt;h4&gt;目的&lt;/h4&gt;全面回顾CNN在机器故障诊断中的应用，分析其优势和局限性，并探讨未来的研究方向和潜在挑战。&lt;h4&gt;方法&lt;/h4&gt;综述了CNN的理论基础、架构变化以及在不同故障类型、数据复杂度和操作环境下的实际实施情况。&lt;h4&gt;主要发现&lt;/h4&gt;CNN能够有效处理各种类型的故障，适用于不同的数据复杂性和运行环境。最近的发展包括利用数据增强技术、迁移学习策略和混合架构来改进故障诊断。&lt;h4&gt;结论&lt;/h4&gt;展望了未来的研究方向，强调通过解决潜在挑战进一步提升CNN在机器故障诊断中的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;机械设备复杂性日益增加以及对操作效率及安全性的需求不断增长推动了先进故障诊断技术的发展。卷积神经网络(CNN)作为一种强大的工具，在提供鲁棒且准确的故障检测和分类能力方面表现出色。这篇综述深入探讨了CNN在机器故障诊断中的应用，涵盖了其理论基础、架构变化以及实际实施情况。文中分析了CNN在此领域的优势与局限性，并讨论了它们处理各种类型故障、数据复杂度及操作环境的有效性。此外，我们还研究了基于CNN的故障诊断领域的发展趋势，考察了最近在数据增强、迁移学习和混合架构方面的进步。最后，我们指出了未来的研究方向以及为了进一步提升CNN应用效果而可能面临的潜在挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing complexity of machinery and the increasing demand for operationalefficiency and safety have driven the development of advanced fault diagnosistechniques. Among these, convolutional neural networks (CNNs) have emerged as apowerful tool, offering robust and accurate fault detection and classificationcapabilities. This comprehensive review delves into the application of CNNs inmachine fault diagnosis, covering its theoretical foundation, architecturalvariations, and practical implementations. The strengths and limitations ofCNNs are analyzed in this domain, discussing their effectiveness in handlingvarious fault types, data complexities, and operational environments.Furthermore, we explore the evolving landscape of CNN-based fault diagnosis,examining recent advancements in data augmentation, transfer learning, andhybrid architectures. Finally, we highlight future research directions andpotential challenges to further enhance the application of CNNs for reliableand proactive machine fault diagnosis.</description>
      <author>example@mail.com (Govind Vashishtha, Sumika Chauhan, Mert Sehri, Justyna Hebda-Sobkowicz, Radoslaw Zimroz, Patrick Dumond, Rajesh Kumar)</author>
      <guid isPermaLink="false">2502.08689v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple Architectures Meet Excellence</title>
      <link>http://arxiv.org/abs/2502.09263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了通过增强框架GNN+改进经典图神经网络（GNNs）在处理图形级别任务时的表现，证明了传统GNNs在许多情况下可以优于图形变换器（GTs）。&lt;h4&gt;背景&lt;/h4&gt;消息传递的GNNs由于表达力不足、过度平滑和过度挤压等问题受到批评。相比之下，基于全局注意力机制的Graph Transformers被认为更强大。&lt;h4&gt;目的&lt;/h4&gt;探索经典图神经网络通过增强框架改善其性能的潜力，并重新评估它们在图形级别任务中的有效性。&lt;h4&gt;方法&lt;/h4&gt;研究者提出了GNN+框架，整合了六种常用技术：边特征集成、归一化、dropout、残差连接、前馈网络和位置编码。在此基础上，对GCN、GIN和GatedGCN三种经典图神经网络进行增强，并在14个著名图形级别数据集上进行了系统性评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在所有测试的数据集中，经典的图神经网络通过GNN+框架的改进后，在大多数任务中都表现出色且排名前三，其中八项任务取得了第一的位置。此外还显示了经典图神经网络在效率方面优于GTs的优势。&lt;h4&gt;结论&lt;/h4&gt;研究挑战了复杂机制是实现卓越图形级别性能的关键这一观念，并强调简单架构的GNNs具有巨大潜力，能够通过适当的优化技术超越更复杂的模型。&lt;h4&gt;翻译&lt;/h4&gt;消息传递图神经网络(GNNs)由于其表现力受限、过度平滑和过度挤压等问题受到批评，在捕捉长距离依赖方面也存在挑战。而Graph Transformers (GTs)，因其全局注意力机制被认为更为优越。文献普遍认为，特别是在图分类和回归等图形级别任务中，GTs优于GNNs。在本研究中，我们通过增强框架GNN+探索了经典GNNs的未开发潜力，该框架整合了六种常用技术：边特征集成、归一化、dropout、残差连接、前馈网络和位置编码，以有效处理图形级别任务。我们在三个经典GNN（GCN，GIN和GatedGCN）上进行了系统的评估，这些模型通过GNN+框架增强了14个著名图形级别数据集上的表现。我们的结果表明，与普遍看法相反的是，经典的图神经网络在图形级别的任务中表现出色，在所有数据集中排名前三，并且在八个数据集中排名第一，同时也显示了比GTs更高的效率。这突显了简单GNN架构的潜力，并挑战了复杂机制是实现卓越图形级别性能的关键这一观念。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LUOyk1999/tunedGNN-G&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-passing Graph Neural Networks (GNNs) are often criticized for theirlimited expressiveness, issues like over-smoothing and over-squashing, andchallenges in capturing long-range dependencies, while Graph Transformers (GTs)are considered superior due to their global attention mechanisms. Literaturefrequently suggests that GTs outperform GNNs, particularly in graph-level taskssuch as graph classification and regression. In this study, we explore theuntapped potential of GNNs through an enhanced framework, GNN+, whichintegrates six widely used techniques: edge feature integration, normalization,dropout, residual connections, feed-forward networks, and positional encoding,to effectively tackle graph-level tasks. We conduct a systematic evaluation ofthree classic GNNs, namely GCN, GIN, and GatedGCN, enhanced by the GNN+framework across 14 well-known graph-level datasets. Our results show that,contrary to the prevailing belief, classic GNNs excel in graph-level tasks,securing top three rankings across all datasets and achieving first place ineight, while also demonstrating greater efficiency than GTs. This highlightsthe potential of simple GNN architectures, challenging the belief that complexmechanisms in GTs are essential for superior graph-level performance.</description>
      <author>example@mail.com (Yuankai Luo, Lei Shi, Xiao-Ming Wu)</author>
      <guid isPermaLink="false">2502.09263v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Cluster and Predict Latents Patches for Improved Masked Image Modeling</title>
      <link>http://arxiv.org/abs/2502.08769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 7 figures, submitted to TMLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CAPI的新型纯Masked Image Modeling (MIM) 框架，该框架通过预测潜在聚类来改进自我监督表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的MIM模型在性能上仍落后于当前的技术前沿。&lt;h4&gt;目的&lt;/h4&gt;系统地分析目标表示、损失函数和架构，以提出一种新的纯MIM框架CAPI。&lt;h4&gt;方法&lt;/h4&gt;采用了基于聚类的损失函数，该损失函数训练稳定且具有良好的扩展性。使用了ViT-L骨干网络，并通过简单的线性探针在ImageNet上实现83.8% 的准确率，在ADE20K数据集上的mIoU值为32.1%。&lt;h4&gt;主要发现&lt;/h4&gt;CAPI框架的性能显著优于以前的MIM方法，接近于当前最先进的DINOv2模型的表现。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖的方法来改进自我监督表示学习，并且该方法在多个数据集上达到了优越的结果。&lt;h4&gt;翻译&lt;/h4&gt;Masked Image Modeling (MIM)为自我监督表示学习提供了一种有前途的途径，然而现有的MIM模型仍落后于当前的技术前沿。在这项研究中，我们系统地分析了目标表示、损失函数和架构，并引入了一种新颖的纯MIM框架CAPI，该框架依赖于预测潜在聚类。我们的方法采用基于聚类的损失函数，训练稳定且具有良好的扩展性。使用ViT-L骨干网络进行实验，在ImageNet上实现了83.8% 的准确率，在ADE20K数据集上的mIoU值为32.1%，显著优于先前的方法，并接近于当前最先进的DINOv2模型的表现。我们将所有代码和模型公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Image Modeling (MIM) offers a promising approach to self-supervisedrepresentation learning, however existing MIM models still lag behind thestate-of-the-art. In this paper, we systematically analyze targetrepresentations, loss functions, and architectures, to introduce CAPI - a novelpure-MIM framework that relies on the prediction of latent clusterings. Ourapproach leverages a clustering-based loss, which is stable to train, andexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,substantially outperforming previous MIM methods and approaching theperformance of the current state-of-the-art, DINOv2. We release all our codeand models.</description>
      <author>example@mail.com (Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski)</author>
      <guid isPermaLink="false">2502.08769v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Self-Evaluation for Job-Shop Scheduling</title>
      <link>http://arxiv.org/abs/2502.08684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的神经组合优化框架，用于解决调度和路径规划等NP难问题。&lt;h4&gt;背景&lt;/h4&gt;组合优化问题是许多行业中的关键挑战，但由于其计算复杂性，这些问题难以直接通过算法解决。现有的神经组合优化方法通常依赖于顺序决策过程，该过程容易累积错误。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来克服传统序贯方法的缺点，并提高解决组合优化问题的能力。&lt;h4&gt;方法&lt;/h4&gt;借鉴大型语言模型中的自我评估技术，本文提出了一个生成和评估任务分配子集的新框架。具体应用于作业车间调度问题（Job-Shop Scheduling Problem），该框架结合了异构图神经网络和Transformer来构建策略模型及自评估函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验在具有挑战性的基准测试数据集上验证了所提出方法的有效性，超过了现有的最先进水平。&lt;h4&gt;结论&lt;/h4&gt;新框架能够有效解决组合优化问题，并在未来的研究中有着潜在的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;组合优化问题是诸如调度和路径规划等领域的关键问题，这些问题由于其NP难特性而难以计算求解。神经组合优化方法利用机器学习技术来应对这些挑战，但通常依赖于顺序决策过程，这种过程容易累积错误，因为小的失误在整个过程中会逐渐扩大。受大型语言模型中自我评估技术的启发，本文提出了一种新框架，该框架生成并评估任务分配子集，超越了传统的逐步骤方法。应用于作业车间调度问题（Job-Shop Scheduling Problem），该方法融合了异构图神经网络与Transformer以构建策略模型和自评估函数。在具有挑战性的、知名基准测试上的实验验证表明，我们的方法比现有的最佳技术更有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combinatorial optimization problems, such as scheduling and route planning,are crucial in various industries but are computationally intractable due totheir NP-hard nature. Neural Combinatorial Optimization methods leveragemachine learning to address these challenges but often depend on sequentialdecision-making, which is prone to error accumulation as small mistakespropagate throughout the process. Inspired by self-evaluation techniques inLarge Language Models, we propose a novel framework that generates andevaluates subsets of assignments, moving beyond traditional stepwiseapproaches. Applied to the Job-Shop Scheduling Problem, our method integrates aheterogeneous graph neural network with a Transformer to build a policy modeland a self-evaluation function. Experimental validation on challenging,well-known benchmarks demonstrates the effectiveness of our approach,surpassing state-of-the-art methods.</description>
      <author>example@mail.com (Imanol Echeverria, Maialen Murua, Roberto Santana)</author>
      <guid isPermaLink="false">2502.08684v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LIR-LIVO: A Lightweight,Robust LiDAR/Vision/Inertial Odometry with Illumination-Resilient Deep Features</title>
      <link>http://arxiv.org/abs/2502.08676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级且鲁棒的LiDAR-惯性-视觉里程计系统LIR-LIVO，用于挑战性的照明和退化环境。&lt;h4&gt;背景&lt;/h4&gt;在复杂的环境中（如光照变化大、条件差），传统的LiDAR-Inertial-Visual Odometry (LIVO) 系统可能无法保持准确性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的LIVO系统，能够利用深度学习技术抵抗照明变化，并适用于各种环境。&lt;h4&gt;方法&lt;/h4&gt;1. 利用基于深度学习的抗光特性；            2. 使用LiDAR点云进行特征均匀分布深度分配；            3. 结合Superpoint和LightGlue实现自适应特征匹配。&lt;h4&gt;主要发现&lt;/h4&gt;通过NTU-VIRAL、Hilti'22及R3LIVE-Dataset等基准数据集的实验，证明了所提出的方法在标准和挑战性条件下均优于现有的SOTA方法。特别是在Hilti'22数据集中，在低光照环境下具有优越的姿态估计能力。&lt;h4&gt;结论&lt;/h4&gt;该工作通过公开代码的方式分享给机器人技术社区，以促进相关领域的进步。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了LIR-LIVO系统，这是一种轻量级且鲁棒的LiDAR-惯性-视觉里程计系统，旨在应对挑战性的照明和退化环境。该方法结合了基于深度学习的技术来实现抗光特性，并利用深度关联技术将特征分布均匀到LiDAR点云上，同时采用Superpoint和LightGlue进行自适应匹配。实验结果表明，在NTU-VIRAL、Hilti'22及R3LIVE-Dataset等基准数据集上的表现优于现有的SOTA方法，并且在低光照环境下具有优越的姿态估计能力。该工作的代码可在GitHub上公开获取，以促进机器人技术社区的发展进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose LIR-LIVO, a lightweight and robustLiDAR-inertial-visual odometry system designed for challenging illumination anddegraded environments. The proposed method leverages deep learning-basedillumination-resilient features and LiDAR-Inertial-Visual Odometry (LIVO). Byincorporating advanced techniques such as uniform depth distribution offeatures enabled by depth association with LiDAR point clouds and adaptivefeature matching utilizing Superpoint and LightGlue, LIR-LIVO achievesstate-of-the-art (SOTA) accuracy and robustness with low computational cost.Experiments are conducted on benchmark datasets, including NTU-VIRAL, Hilti'22,and R3LIVE-Dataset. The corresponding results demonstrate that our proposedmethod outperforms other SOTA methods on both standard and challengingdatasets. Particularly, the proposed method demonstrates robust pose estimationunder poor ambient lighting conditions in the Hilti'22 dataset. The code ofthis work is publicly accessible on GitHub to facilitate advancements in therobotics community.</description>
      <author>example@mail.com (Shujie Zhou, Zihao Wang, Xinye Dai, Weiwei Song, Shengfeng Gu)</author>
      <guid isPermaLink="false">2502.08676v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units</title>
      <link>http://arxiv.org/abs/2502.06921v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文介绍了GraNNite，一个针对商业现货(COTS)最先进深度神经网络加速器优化图神经网络(GNN)执行的硬件感知框架。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）对于从结构化数据中学习至关重要，在网络分析、推荐系统和语音分析等领域有着广泛应用。将其部署在边缘设备上可以增强实时处理能力，保护隐私，并且不受云计算依赖的影响。然而，不规则内存访问、稀疏性和动态结构导致资源受限设备上的延迟和能耗过高。&lt;h4&gt;目的&lt;/h4&gt;提出一个优化GNN执行的框架，以解决现有硬件加速器（如NPU）在不规则图计算中的挑战。&lt;h4&gt;方法&lt;/h4&gt;采用了一个分三步的方法来优化COTS最先进DNN加速器上的GNN执行：(1)启用NPU执行；(2)提升性能；(3)通过牺牲精度换取效率。每个步骤使用特定的技术或工具，如GraphSplit、StaGr、EffOp等。&lt;h4&gt;主要发现&lt;/h4&gt;在Intel Core Ultra AI PC上测试时，GraNNite相比默认的NPU映射提供了2.6倍至7.6倍的速度提升，并且比CPU和GPU最多能节省8.6倍的能量消耗。与单独使用CPU和GPU相比，在不同的GNN模型中分别实现了10.8倍和6.7倍的性能增强。&lt;h4&gt;结论&lt;/h4&gt;通过专门的方法，可以有效地优化图神经网络在COTS最先进DNN加速器上的执行效率，实现更高的计算速度和更低的能量消耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are vital for learning from graph-structureddata, enabling applications in network analysis, recommendation systems, andspeech analytics. Deploying them on edge devices like client PCs and laptopsenhances real-time processing, privacy, and cloud independence. GNNs aidRetrieval-Augmented Generation (RAG) for Large Language Models (LLMs) andenable event-based vision tasks. However, irregular memory access, sparsity,and dynamic structures cause high latency and energy overhead onresource-constrained devices. While modern edge processors integrate CPUs,GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregularGNN computations. We introduce GraNNite, the first hardware-aware frameworkoptimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNNaccelerators via a structured three-step methodology: (1) enabling NPUexecution, (2) optimizing performance, and (3) trading accuracy for efficiencygains. Step 1 employs GraphSplit for workload distribution and StaGr for staticaggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boostsperformance using EffOp for control-heavy tasks and GraSp for sparsityexploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduceredundancy and memory transfers. Step 3 balances quality versus efficiency,where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerateattention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higherperformance than CPUs and GPUs, respectively, across GNN models.</description>
      <author>example@mail.com (Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan)</author>
      <guid isPermaLink="false">2502.06921v2</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Meta-learning of shared linear representations beyond well-specified linear regression</title>
      <link>http://arxiv.org/abs/2501.18975v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于多任务学习和元学习的方法，考虑如何从任务或用户中学习共享的结构，如低秩表示或集群结构。不同于以往的研究集中在指定线性回归上，该研究针对更一般的凸目标函数，在这种情况下，结构化假设在每个函数的最优解处表达。&lt;h4&gt;背景&lt;/h4&gt;多任务和元学习的方法旨在通过从多个相关任务中提取共享信息来提高模型性能，特别是在低秩表示或集群结构的情况下。然而，大多数现有方法集中在特定线性回归框架下。&lt;h4&gt;目的&lt;/h4&gt;研究更一般的凸目标函数中的共享结构，并探讨在较少样本条件下如何恢复这些结构。&lt;h4&gt;方法&lt;/h4&gt;该研究假设了Hessian集中和最优解处的噪声集中等条件，使用秩约束估计器来实现这一目标。此外还提出了一种通过核范数限制进行多项式时间算法的方法，用于在凸学习目标中学习共享线性表示。&lt;h4&gt;主要发现&lt;/h4&gt;当样本数量足够大时，可以恢复低秩和集群结构；仅有一个任务样本的情况下可以通过秩约束估计器来恢复子空间，并且需要任务的数量随子空间维度呈指数级增长。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在理论上证明了从凸目标函数中学习共享结构的可能性，并提供了一种实用的多项式时间算法。这为未来多任务和元学习研究提供了新的方向和方法论支持。&lt;h4&gt;翻译&lt;/h4&gt;受多任务及元学习方法启发，我们考虑从任务或用户中学习共享结构的问题，如低秩表示或者集群结构。尽管之前的全部工作都集中在指定线性回归上，我们则专注于更一般的凸目标函数，在这种情况下，结构性的假设以每个函数最优解的形式表达出来。在温和条件，比如Hessian集中以及噪声在最优解处集中的条件下，我们展示了当样本数量和任务数量足够大的时候，可以恢复低秩和集群结构。之后，我们在只有单一样本的任务环境中探讨了如何恢复所有解决方案所在的子空间的问题：在这种情况下，通过秩约束估计器可以恢复出这个子空间，但是需要的任务数量随着子空间维度呈指数级增长。最后，我们还提供了一种使用核范数限制的多项式时间算法，在凸学习目标中用于学习共享线性表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by multi-task and meta-learning approaches, we consider the problemof learning structure shared by tasks or users, such as shared low-rankrepresentations or clustered structures. While all previous works focus onwell-specified linear regression, we consider more general convex objectives,where the structural low-rank and cluster assumptions are expressed on theoptima of each function. We show that under mild assumptions such as\textit{Hessian concentration} and \textit{noise concentration at the optimum},rank and clustered regularized estimators recover such structure, provided thenumber of samples per task and the number of tasks are large enough. We thenstudy the problem of recovering the subspace in which all the solutions lie, inthe setting where there is only a single sample per task: we show that in thatcase, the rank-constrained estimator can recover the subspace, but that thenumber of tasks needs to scale exponentially large with the dimension of thesubspace. Finally, we provide a polynomial-time algorithm via nuclear normconstraints for learning a shared linear representation in the context ofconvex learning objectives.</description>
      <author>example@mail.com (Mathieu Even, Laurent Massoulié)</author>
      <guid isPermaLink="false">2501.18975v2</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References</title>
      <link>http://arxiv.org/abs/2502.09614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. Website: https://meowuu7.github.io/DexTrack/  Code: https://github.com/Meowuu7/DexTrack/ Video:  https://youtu.be/zru1Z-DaiWE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种用于灵巧机器人手操作的通用神经控制器的方法，通过收集大规模的人机交互数据进行训练，并利用强化学习和模仿学习相结合的方式来提高控制器在动态环境中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常依赖于任务特定奖励或精确系统模型，因此难以适应复杂的接触动力学和广泛的泛化需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够管理灵巧机器人手以操纵多种对象并适用于不同应用场景的神经跟踪控制器。&lt;h4&gt;方法&lt;/h4&gt;{'数据驱动': '收集大规模的成功机器人跟踪演示，包含人类参考与机器人动作对，用于训练神经控制器。', '迭代优化': '利用数据飞轮机制不断改进控制器性能和高质量跟踪演示的数量及质量。', '强化学习和模仿学习结合': '在动态环境中通过集成强化学习和模仿学习来增强控制器的表现。', '轨迹优化': '单独针对每条轨迹进行优化，使用已学得的跟踪控制器在一个同伦优化方法中工作以提高表现并增加演示多样性。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法相比于领先基线方法在成功率上提高了超过10%。&lt;h4&gt;结论&lt;/h4&gt;通过结合大规模数据、强化学习和模仿学习以及轨迹单独优化，成功训练出一个在模拟和真实世界环境中都能表现出色的通用神经控制器。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了从人类参考中开发灵巧操作的手部机器人泛化神经跟踪控制器的问题。此控制器旨在管理灵巧机器人手来操纵各种由运动学人机交互定义的不同目的的物体。由于复杂接触动力学和对适应性、泛化能力和鲁棒性的需求，这样的控制器很难发展出来。现有的强化学习和轨迹优化方法通常因依赖任务特定奖励或精确系统模型而表现不佳。我们介绍了一种收集大规模成功机器人跟踪演示的方法（包括人类参考和机器人动作），以此来训练神经控制器。通过数据飞轮机制，我们不断改进控制器性能以及高质量的跟踪演示的数量和质量。在动态环境中，我们利用现有的跟踪演示并仔细集成强化学习和模仿学习以提高控制器的表现。同时为了获得高质量的跟踪演示，我们使用学到的跟踪控制器在一个同伦优化方法中单独针对每条轨迹进行优化，从而解决困难的轨迹跟踪问题来增加演示多样性。我们在模拟和真实世界环境中训练了一个通用神经控制器，并与最先进的基线进行了比较。我们的方法在成功率上比领先基线方法提高了超过10%。项目网站https://meowuu7.github.io/DexTrack/提供了带有动画结果的信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of developing a generalizable neural trackingcontroller for dexterous manipulation from human references. This controlleraims to manage a dexterous robot hand to manipulate diverse objects for variouspurposes defined by kinematic human-object interactions. Developing such acontroller is complicated by the intricate contact dynamics of dexterousmanipulation and the need for adaptivity, generalizability, and robustness.Current reinforcement learning and trajectory optimization methods often fallshort due to their dependence on task-specific rewards or precise systemmodels. We introduce an approach that curates large-scale successful robottracking demonstrations, comprising pairs of human references and robotactions, to train a neural controller. Utilizing a data flywheel, weiteratively enhance the controller's performance, as well as the number andquality of successful tracking demonstrations. We exploit available trackingdemonstrations and carefully integrate reinforcement learning and imitationlearning to boost the controller's performance in dynamic environments. At thesame time, to obtain high-quality tracking demonstrations, we individuallyoptimize per-trajectory tracking by leveraging the learned tracking controllerin a homotopy optimization method. The homotopy optimization, mimickingchain-of-thought, aids in solving challenging trajectory tracking problems toincrease demonstration diversity. We showcase our success by training ageneralizable neural controller and evaluating it in both simulation and realworld. Our method achieves over a 10% improvement in success rates compared toleading baselines. The project website with animated results is available athttps://meowuu7.github.io/DexTrack/.</description>
      <author>example@mail.com (Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi)</author>
      <guid isPermaLink="false">2502.09614v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Rolling Ahead Diffusion for Traffic Scene Simulation</title>
      <link>http://arxiv.org/abs/2502.09587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Workshop on Machine Learning for Autonomous Driving at  AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于滚动扩散的交通场景生成模型，结合了自回归（AR）预测即时未来和差分方程模型再生场景的优点。&lt;h4&gt;背景&lt;/h4&gt;现实驾驶仿真需要NPC不仅要模仿自然驾驶行为，还要对其它仿真人行为做出反应。最近的发展集中在利用基于扩散的方法生成多样的、真实的交通场景，但这种方法在面对模拟代理动作偏离预定轨迹时缺乏响应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够同时预测下一时刻未来并部分预测进一步未来的扰动模型的滚动扩散方法，以此提升仿真场景的实时性和计算效率。&lt;h4&gt;方法&lt;/h4&gt;利用自回归（AR）模型来预测所有NPC的即时下一步行动，并结合差分方程模型的再生成能力，在每个时间步长上同时进行下一时刻和后续部分扰动步骤的预测。&lt;h4&gt;主要发现&lt;/h4&gt;提出的滚动扩散交通场景生成模型在响应性和计算效率之间取得了有益的折衷，相较于基于自回归（AR）的扩散模型更为高效。&lt;h4&gt;结论&lt;/h4&gt;通过结合自回归模型的即时性与差分方程再生模型的长期规划能力，新的方法提供了一种更高效的解决方案来实现真实驾驶模拟中的场景生成。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在现实驾驶仿真中NPC需要模仿自然驾驶行为并对其它仿真人做出反应的需求。基于扩散的方法虽然能创造多样且真实的交通场景，但在面对代理动作偏离模型轨迹时缺乏响应性。为解决这一问题，提出了一种结合自回归预测和差分方程再生的滚动扩散方法，实现了在实时性和计算效率之间的平衡，以提高驾驶模拟的真实感和动态适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Realistic driving simulation requires that NPCs not only mimic naturaldriving behaviors but also react to the behavior of other simulated agents.Recent developments in diffusion-based scenario generation focus on creatingdiverse and realistic traffic scenarios by jointly modelling the motion of allthe agents in the scene. However, these traffic scenarios do not react when themotion of agents deviates from their modelled trajectories. For example, theego-agent can be controlled by a stand along motion planner. To producereactive scenarios with joint scenario models, the model must regenerate thescenario at each timestep based on new observations in a Model PredictiveControl (MPC) fashion. Although reactive, this method is time-consuming, as onecomplete possible future for all NPCs is generated per simulation step.Alternatively, one can utilize an autoregressive model (AR) to predict only theimmediate next-step future for all NPCs. Although faster, this method lacks thecapability for advanced planning. We present a rolling diffusion based trafficscene generation model which mixes the benefits of both methods by predictingthe next step future and simultaneously predicting partially noised furtherfuture steps at the same time. We show that such model is efficient compared todiffusion model based AR, achieving a beneficial compromise between reactivityand computational efficiency.</description>
      <author>example@mail.com (Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood)</author>
      <guid isPermaLink="false">2502.09587v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2502.09556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the preprint version of the paper published in 2023 IEEE  International Conference on Robotics and Automation (ICRA). The final version  is available at IEEE Xplore: https://doi.org/10.1109/ICRA48891.2023.10160595&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Real-Time Fast Marching Tree (RT-FMT)的实时规划算法，该算法能够在搜索过程中快速寻找全局解决方案，并同时生成局部路径，使得机器人可以更快地开始执行任务。此外，此算法还具有动态障碍物避让功能。&lt;h4&gt;背景&lt;/h4&gt;Fast Marching Tree（FMT*）和Real-time Rapidly-Exploring Random Tree (RT-RRT*)是现有规划算法的基础。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的实时路径规划算法以解决局部与全局路径生成、多重查询规划以及动态障碍物避让的问题，同时提高执行成本和到达时间的性能。&lt;h4&gt;方法&lt;/h4&gt;基于FMT*和RT-RRT*两种算法，引入了RT-FMT算法，它能够快速寻找全局解，并在搜索过程中产生可用的局部路径。通过不断调整树形结构来避免形成动态障碍物内部分支，同时保持根节点靠近机器人位置，使得该算法可以被多次重复使用。&lt;h4&gt;主要发现&lt;/h4&gt;RT-FMT算法相较于RT-RRT*而言，在大多数情况下都能降低执行成本和到达时间。此外，尽管存在采取次优路径的可能性较小，但在全局路径可用之前采用局部路径以减少到达时间是值得的。&lt;h4&gt;结论&lt;/h4&gt;RT-FMT作为一种实时路径规划方法，具有高效的性能表现和适用性，能够快速响应动态环境变化并生成合理的行驶路线。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的算法——实时光速树（Real-Time Fast Marching Tree, RT-FMT），该算法能够在搜索过程中迅速找到全局解决方案，并同时产生局部路径。这种算法能在短时间内启动执行任务以节省时间，同时还具备处理动态障碍物的能力。通过与RT-RRT*进行对比模拟实验发现，在大多数情况下，RT-FMT在执行成本和到达时间方面优于后者。此外还证明了即使有较小的可能性会采取较差的路线，提前采用局部路径也能降低到达时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICRA48891.2023.10160595&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-timeplanning algorithm that features local and global path generation,multiple-query planning, and dynamic obstacle avoidance. During the search,RT-FMT quickly looks for the global solution and, in the meantime, generateslocal paths that can be used by the robot to start execution faster. Inaddition, our algorithm constantly rewires the tree to keep branches fromforming inside the dynamic obstacles and to maintain the tree root near therobot, which allows the tree to be reused multiple times for different goals.Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-timeRapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMToutperforms RT- RRT* in both execution cost and arrival time, in most cases.Moreover, we also demonstrate via simulation that it is worthwhile taking thelocal path before the global path is available in order to reduce arrival time,even though there is a small possibility of taking an inferior path.</description>
      <author>example@mail.com (Jefferson Silveira, Kleber Cabral, Sidney Givigi, Joshua A. Marshall)</author>
      <guid isPermaLink="false">2502.09556v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>SpeechCompass: Enhancing Mobile Captioning with Diarization and Directional Guidance via Multi-Microphone Localization</title>
      <link>http://arxiv.org/abs/2502.08848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;移动设备上的语音转文字功能在听力和口语辅助、语言翻译、记笔记和会议记录方面发挥了重要作用。然而，基础的大规模调查表明，在多人对话中无法区分说话人的方向使这些技术面临挑战。&lt;h4&gt;背景&lt;/h4&gt;语音转文本技术已经在多种场景下证明了其价值，但目前的语音识别系统难以处理多讲话者的方向信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入高效的音频定位算法和特定硬件来解决当前移动设备上语音转文字功能在多人对话中的局限性问题。&lt;h4&gt;方法&lt;/h4&gt;使用低功耗微控制器及四个集成麦克风实现实时、多麦克风语音定位。通过大规模调查（n=494）进行小组会议的现场研究，收集八名常用手机语音识别用户的反馈，并评估五种可视化风格。&lt;h4&gt;主要发现&lt;/h4&gt;参与者普遍认为身份区分和视觉化定位的价值和潜力对于多人对话非常重要。所有参与者都认同方向指导在小组对话中的价值与可能性。&lt;h4&gt;结论&lt;/h4&gt;SpeechCompass通过提供实时的多麦克风语音定位解决方案，增强了移动设备上语音转文字的功能，特别是在处理多个说话者的场景中提供了更好的用户体验。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要提及了现有的语音转文本技术虽然有用但存在局限性，并提出了改进方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech-to-text capabilities on mobile devices have proven helpful for hearingand speech accessibility, language translation, note-taking, and meetingtranscripts. However, our foundational large-scale survey (n=263) shows thatthe inability to distinguish and indicate speaker direction makes themchallenging in group conversations. SpeechCompass addresses this limitationthrough real-time, multi-microphone speech localization, where the direction ofspeech allows visual separation and guidance (e.g., arrows) in the userinterface. We introduce efficient real-time audio localization algorithms andcustom sound perception hardware running on a low-power microcontroller andfour integrated microphones, which we characterize in technical evaluations.Informed by a large-scale survey (n=494), we conducted an in-person study ofgroup conversations with eight frequent users of mobile speech-to-text, whoprovided feedback on five visualization styles. The value of diarization andvisualizing localization was consistent across participants, with everyoneagreeing on the value and potential of directional guidance for groupconversations.</description>
      <author>example@mail.com (Artem Dementyev, Dimitri Kavensky, Samuel J. Yang, Mathieu Parvaix, Chiong Lai, Alex Olwal)</author>
      <guid isPermaLink="false">2502.08848v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Variable Stiffness for Robust Locomotion through Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.09436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IFAC Joint Symposia on Mechatronics &amp; Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的控制范式，将可变刚度集成到动作空间中，并与关节位置结合在一起，实现了不同级别的刚度控制策略。通过这种方法，机器人在速度跟踪和推力恢复方面的表现优于单纯的位置控制，在能量效率方面，混合关节-腿刚度策略表现出色。&lt;h4&gt;背景&lt;/h4&gt;强化学习方法虽然可以使腿部机器人执行动态运动，但通常需要手动调整关节刚度，这很耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的控制范式来简化设计过程并提高性能。&lt;h4&gt;方法&lt;/h4&gt;将可变刚度纳入动作空间，并采用分组刚度控制策略（如每关节刚度、每腿刚度和混合关节-腿刚度）进行试验。&lt;h4&gt;主要发现&lt;/h4&gt;使用分组的每腿刚度策略在速度跟踪和推力恢复方面超越了位置控制，而混合关节-腿刚度策略则表现出了更高的能量效率。此外，该方法通过模拟到现实环境转移展示了鲁棒行走能力。&lt;h4&gt;结论&lt;/h4&gt;新的控制范式简化设计过程同时保持了多种性能指标的竞争性结果。&lt;h4&gt;翻译&lt;/h4&gt;强化学习的步态使腿部机器人能够执行动态动作，但通常伴随有耗时的手动调节关节刚度。本文介绍了一种新的控制模式，该模式将可变刚度与关节位置一起整合到动作空间中，支持分组刚度控制（如每关节刚度、每腿刚度和混合关节-腿刚度）。我们表明，在速度跟踪和推力恢复方面，采用分组的每腿刚度策略优于仅基于位置的控制。相比之下，混合关节-腿刚度策略在能量效率上更胜一筹。此外，通过从平地训练的策略实现模拟到现实环境转移，该方法展示了在各种户外地形上的鲁棒步行行为。我们的方法简化了设计流程，消除了对每关节刚度的手动调节，并且在多种性能指标下保持了竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement-learned locomotion enables legged robots to perform highlydynamic motions but often accompanies time-consuming manual tuning of jointstiffness. This paper introduces a novel control paradigm that integratesvariable stiffness into the action space alongside joint positions, enablinggrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffnesspolicies, with grouping in per-leg stiffness (PLS), outperform position-basedcontrol in velocity tracking and push recovery. In contrast, HJLS excels inenergy efficiency. Furthermore, our method showcases robust walking behaviouron diverse outdoor terrains by sim-to-real transfer, although the policy issorely trained on a flat floor. Our approach simplifies design by eliminatingper-joint stiffness tuning while keeping competitive results with variousmetrics.</description>
      <author>example@mail.com (Dario Spoljaric, Yashuai Yan, Dongheui Lee)</author>
      <guid isPermaLink="false">2502.09436v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework</title>
      <link>http://arxiv.org/abs/2502.08756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;开发基于Web的地理信息系统（GIS）应用程序，通常被称为CyberGIS仪表板，在环境研究中查询和可视化GIS数据往往需要重复且资源密集型的努力。虽然生成式人工智能提供了代码生成自动化的潜力，但由于在整合领域知识、软件工程原则以及UI设计最佳实践方面的挑战，它难以处理复杂的科学应用。&lt;h4&gt;背景&lt;/h4&gt;开发Web GIS应用程序的需求很高，但目前的自动化技术存在局限性，特别是在结合领域知识和用户体验设计方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强生成式预训练Transformer（GPT）用于前端开发的知识增益代码生成框架。该框架旨在从用户绘制的界面草图中自动生成GIS基于Web的应用程序。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种新颖的方法，即上下文感知视觉提示技术，使用Python实现从草图中提取布局和界面特性，并将其应用于指导代码生成。采用大规模语言模型（LLMs），结合结构化推理、软件工程原则以及领域知识，生成前端代码。&lt;h4&gt;主要发现&lt;/h4&gt;案例研究展示了框架能够根据用户绘制的草图自动生成一个模块化的、可维护的Web平台来托管多个仪表板，用于展示环境和能源数据。通过采用以知识驱动的方法，该框架使用诸如Model-View-ViewModel（MVVM）等设计模式和React之类的前端框架生成大规模的标准代码。&lt;h4&gt;结论&lt;/h4&gt;这种方法大大减少了手动设计和编码的工作量，并为智慧城市软件开发开创了一种自动化且高效的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing web-based GIS applications, commonly known as CyberGIS dashboards,for querying and visualizing GIS data in environmental research often demandsrepetitive and resource-intensive efforts. While Generative AI offersautomation potential for code generation, it struggles with complex scientificapplications due to challenges in integrating domain knowledge, softwareengineering principles, and UI design best practices. This paper introduces aknowledge-augmented code generation framework that retrieves softwareengineering best practices, domain expertise, and advanced technology stacksfrom a specialized knowledge base to enhance Generative Pre-trainedTransformers (GPT) for front-end development. The framework automates thecreation of GIS-based web applications (e.g., dashboards, interfaces) fromuser-defined UI wireframes sketched in tools like PowerPoint or AdobeIllustrator. A novel Context-Aware Visual Prompting method, implemented inPython, extracts layouts and interface features from these wireframes to guidecode generation. Our approach leverages Large Language Models (LLMs) togenerate front-end code by integrating structured reasoning, softwareengineering principles, and domain knowledge, drawing inspiration fromChain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). Acase study demonstrates the framework's capability to generate a modular,maintainable web platform hosting multiple dashboards for visualizingenvironmental and energy data (e.g., time-series, shapefiles, rasters) fromuser-sketched wireframes. By employing a knowledge-driven approach, theframework produces scalable, industry-standard front-end code using designpatterns such as Model-View-ViewModel (MVVM) and frameworks like React. Thissignificantly reduces manual effort in design and coding, pioneering anautomated and efficient method for developing smart city software.</description>
      <author>example@mail.com (Haowen Xu, Xiao-Ying Yu)</author>
      <guid isPermaLink="false">2502.08756v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation</title>
      <link>http://arxiv.org/abs/2502.09395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了使用概率实际因果关系来确定导致观察到的不良结果的因素，并展示了如何利用这种因果概率找到替代行动以改变结果。研究应用此分析于机器人倒水任务中，当出现洒漏时，通过分析可以识别出导致这一问题的具体参数以及应如何调整这些参数。&lt;h4&gt;背景&lt;/h4&gt;在日常生活或工作中，我们执行各种任务（如烹饪、清洁）并会遇到意外或不希望的结果。面对这种情况时，我们会采取补救措施直到达成预期目标。&lt;h4&gt;目的&lt;/h4&gt;通过研究概率因果关系的应用来确定导致不良结果的因素，并提出如何找到替代行动以改变这些结果的方法。&lt;h4&gt;方法&lt;/h4&gt;论文采用了一个完整的因果建模过程（包括任务分析、变量定义、因果图结构的决定以及条件概率分布的估计），利用机器人倒水任务的真实模拟数据，涵盖了大量组合的任务参数。基于这些要求和数据进行研究分析。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析可以识别出导致不良结果的具体因素，并能够建议调整方法来避免这些问题；同时展示了实际因果分析在选择替代行动参数中的实用价值。&lt;h4&gt;结论&lt;/h4&gt;论文证明了概率因果关系分析的有效性，不仅可以帮助确定问题原因，还能指导采取适当的补救措施。这表明该技术有潜力用于更广泛的自动化任务中以提高效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了使用概率实际因果推理来判断一个因素是否是导致观察到的不良结果的原因，并展示了如何利用这种因果性概率找到替代行动以改变结果。通过在机器人倒水任务中的应用，当出现洒漏时，该分析能够识别出特定的任务参数作为原因并提出应采取何种调整措施。研究需要构建任务的因果图和相应的条件概率分布，为此进行了全面的因果建模过程，包括使用真实模拟数据进行任务分析、变量定义、决定因果结构以及估计条件概率分布等步骤。基于这些结果，讨论了变量表示的意义，并比较了实际因果性分析提出的替代解决方案与人类观察者可能提出的不同之处。此外，还展示了选择替代行动参数的实际因果性分析的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In everyday life, we perform tasks (e.g., cooking or cleaning) that involve alarge variety of objects and goals. When confronted with an unexpected orunwanted outcome, we take corrective actions and try again until achieving thedesired result. The reasoning performed to identify a cause of the observedoutcome and to select an appropriate corrective action is a crucial aspect ofhuman reasoning for successful task execution. Central to this reasoning is theassumption that a factor is responsible for producing the observed outcome. Inthis paper, we investigate the use of probabilistic actual causation todetermine whether a factor is the cause of an observed undesired outcome.Furthermore, we show how the actual causation probabilities can be used to findalternative actions to change the outcome. We apply the probabilistic actualcausation analysis to a robot pouring task. When spillage occurs, the analysisindicates whether a task parameter is the cause and how it should be changed toavoid spillage. The analysis requires a causal graph of the task and thecorresponding conditional probability distributions. To fulfill theserequirements, we perform a complete causal modeling procedure (i.e., taskanalysis, definition of variables, determination of the causal graph structure,and estimation of conditional probability distributions) using data from arealistic simulation of the robot pouring task, covering a large combinatorialspace of task parameters. Based on the results, we discuss the implications ofthe variables' representation and how the alternative actions suggested by theactual causation analysis would compare to the alternative solutions proposedby a human observer. The practical use of the analysis of probabilistic actualcausation to select alternative action parameters is demonstrated.</description>
      <author>example@mail.com (Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill)</author>
      <guid isPermaLink="false">2502.09395v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable Reinforcement Learning with Biologically Inspired Hyperdimensional Occupancy Grid Maps for Exploration and Goal-Directed Path Planning</title>
      <link>http://arxiv.org/abs/2502.09393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;实时自主系统采用多层次计算框架来执行感知、目标寻找和路径规划等关键任务。本文研究了一种基于向量符号架构（VSA）的超维度空间中的概率占域网格映射方法，将其与传统的贝叶斯希尔伯特图谱（BHM）进行比较，并在强化学习环境下的目标寻找及路径规划中测试其性能。&lt;h4&gt;背景&lt;/h4&gt;实时自主系统利用多层次计算框架执行任务。传统方法使用占域网格映射（OGM），通过概率信息将环境分割为离散单元格，而最近的方法采用基于生物灵感的向量符号架构（VSA）来实现超维度空间中的概率OGM。&lt;h4&gt;目的&lt;/h4&gt;评估VSA-OGM在下游任务上的表现，并将其与传统的OGM方法进行比较。研究旨在确定VSA-OGM是否可以作为神经形态替代方案用于大规模集成中。&lt;h4&gt;方法&lt;/h4&gt;该研究在一个受控探索环境中和一个F1-Tenth挑战启发的自动驾驶场景中，将VSA-OGM的方法与传统OGM方法（贝叶斯希尔伯特图谱BHM）进行比较。评估了它们在强化学习框架下的目标寻找和路径规划中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，在单个及多情景训练配置下，VSA-OGM保持了与BHM相当的学习性能，并且在未见环境中性能提高了大约47%，这表明使用VSA-OGM进行政策网络培训具有更高的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究表明VSA-OGM方法不仅能够提供类似于传统占域网格映射的方法的性能，而且还能提高系统对于新环境的适应性。该研究强调了在各种环境下部署神经形态计算的可能性和价值。&lt;h4&gt;翻译&lt;/h4&gt;实时自主系统采用多层次计算框架来执行任务如感知、目标寻找和路径规划等关键操作。传统方法使用占域网格映射（OGM）通过概率信息分割环境为离散单元格，而最近的方法则利用基于生物灵感的数学模型向量符号架构（VSA），在超维度空间中进行概率OGM的操作。尽管这一新方法与突触神经网络天然兼容并显示出了作为现有OGM方法替代品的应用潜力，但在大规模集成中需要评估其对下游任务的影响。研究旨在通过强化学习框架下目标寻找和路径规划的性能测试，比较VSA-OGM方法在受控探索环境及F1-Tenth挑战启发的自动驾驶场景中的表现与传统的贝叶斯希尔伯特图谱（BHM）的表现。结果显示，在单个和多情景训练配置下，VSA-OGM保持了类似的学习效果，且在未见环境中性能提高了大约47%，这表明使用VSA-OGM进行策略网络培训的泛化能力更强，增强了其实际应用中部署的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time autonomous systems utilize multi-layer computational frameworks toperform critical tasks such as perception, goal finding, and path planning.Traditional methods implement perception using occupancy grid mapping (OGM),segmenting the environment into discretized cells with probabilisticinformation. This classical approach is well-established and provides astructured input for downstream processes like goal finding and path planningalgorithms. Recent approaches leverage a biologically inspired mathematicalframework known as vector symbolic architectures (VSA), commonly known ashyperdimensional computing, to perform probabilistic OGM in hyperdimensionalspace. This approach, VSA-OGM, provides native compatibility with spikingneural networks, positioning VSA-OGM as a potential neuromorphic alternative toconventional OGM. However, for large-scale integration, it is essential toassess the performance implications of VSA-OGM on downstream tasks compared toestablished OGM methods. This study examines the efficacy of VSA-OGM against atraditional OGM approach, Bayesian Hilbert Maps (BHM), within reinforcementlearning based goal finding and path planning frameworks, across a controlledexploration environment and an autonomous driving scenario inspired by theF1-Tenth challenge. Our results demonstrate that VSA-OGM maintains comparablelearning performance across single and multi-scenario training configurationswhile improving performance on unseen environments by approximately 47%. Thesefindings highlight the increased generalizability of policy networks trainedwith VSA-OGM over BHM, reinforcing its potential for real-world deployment indiverse environments.</description>
      <author>example@mail.com (Shay Snyder, Ryan Shea, Andrew Capodieci, David Gorsich, Maryam Parsa)</author>
      <guid isPermaLink="false">2502.09393v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.09389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了S$^2$-Diffusion，一种开放词汇的技能学习策略，能够使机器人从实例级别的训练数据中泛化到类别级别，从而实现在同一类别的不同实例间转移技能。&lt;h4&gt;背景&lt;/h4&gt;最近在技能学习领域的进展使得机器人操纵技术得以实现复杂任务的学习。然而，这些技能通常局限于特定的动作、物体和环境实例，并且难以迁移到相同类别但未展示的实例上。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法S$^2$-Diffusion来解决现有技能学习中跨同类不同实例迁移的问题，使机器人能够在更多场景下应用其学到的技能。&lt;h4&gt;方法&lt;/h4&gt;通过结合可提示语义模块与空间表示功能，S$^2$-Diffusion能够捕捉到技能的功能特性，并利用深度估计网络仅用单个RGB摄像头实现这些技能的应用。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在模拟环境和真实世界中多样化的机器人操纵任务上进行了评估和比较。结果显示，S$^2$-Diffusion对类别无关因素的变化具有不变性，并且即使没有针对特定实例进行训练也能在相同类别的其他实例上实现令人满意的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了机器人技能学习领域的一个重要进步，使得机器人能够更好地适应新的操作场景和物体类型。这表明使用开放词汇模型可以显著提高机器人的任务灵活性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;最近的技能学习进展推动了机器人操纵技术的发展，使其能够在展示一定数量演示的情况下学会复杂的操纵任务。然而，这些技能往往局限于训练数据中显示的具体行动、对象和环境实例，并且很难转移到同一类别的其他实例上。在这项工作中，我们提出了一种开放词汇的空间语义扩散策略S$^2$-Diffusion，它使得机器人可以从实例级别的训练数据泛化到类别级别，从而使技能能够在同一类别的不同实例间转移。研究显示，通过可提示的语义模块和空间表示结合的功能可以捕捉技能的功能方面，并且我们还提出利用深度估计网络以允许仅使用单个RGB相机实现这些功能。该方法在模拟环境和真实世界的多种机器人操纵任务上进行了评估和比较。结果显示S$^2$-Diffusion对于类别无关因素的变化具有不变性，同时能够在同一类别的其他实例中实现令人满意的表现，即使没有针对特定实例进行训练。所有实际世界实验的完整视频可在补充材料中获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in skill learning has propelled robot manipulation to newheights by enabling it to learn complex manipulation tasks from a practicalnumber of demonstrations. However, these skills are often limited to theparticular action, object, and environment \textit{instances} that are shown inthe training data, and have trouble transferring to other instances of the samecategory. In this work we present an open-vocabulary Spatial-Semantic Diffusionpolicy (S$^2$-Diffusion) which enables generalization from instance-leveltraining data to category-level, enabling skills to be transferable betweeninstances of the same category. We show that functional aspects of skills canbe captured via a promptable semantic module combined with a spatialrepresentation. We further propose leveraging depth estimation networks toallow the use of only a single RGB camera. Our approach is evaluated andcompared on a diverse number of robot manipulation tasks, both in simulationand in the real world. Our results show that S$^2$-Diffusion is invariant tochanges in category-irrelevant factors as well as enables satisfyingperformance on other instances within the same category, even if it was nottrained on that specific instance. Full videos of all real-world experimentsare available in the supplementary material.</description>
      <author>example@mail.com (Quantao Yang, Michael C. Welle, Danica Kragic, Olov Andersson)</author>
      <guid isPermaLink="false">2502.09389v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>TRIFFID: Autonomous Robotic Aid For Increasing First Responders Efficiency</title>
      <link>http://arxiv.org/abs/2502.09379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TRIFFID系统是一个综合技术框架，旨在利用无人驾驶地面和空中车辆以及先进的AI功能来提升灾难应对能力。&lt;h4&gt;背景&lt;/h4&gt;自然灾害事故的复杂性增加需要创新的技术解决方案以支持救援人员的工作。&lt;h4&gt;目的&lt;/h4&gt;引入TRIFFID系统，该系统通过整合无人车、无人机、先进的人工智能技术等功能增强在森林火灾、城市洪水和地震后的搜救任务中的响应能力。&lt;h4&gt;方法&lt;/h4&gt;利用先进的自主导航、语义感知和技术，并结合智能手机应用、中央地面站和定制通信基础设施等组件来开发TRIFFID系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过深度神经网络，知识图谱以及多模态信息融合技术使机器人能够自动导航并分析灾难环境，减少了人员风险，加快了响应时间。&lt;h4&gt;结论&lt;/h4&gt;该系统增强了应急团队的高级任务规划、安全监控和自适应任务执行能力，并确保在复杂且危险的情况下提供实时情况感知和支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个旨在通过整合无人驾驶车辆与先进人工智能技术来提高自然灾害应对能力的技术框架——TRIFFID系统的介绍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing complexity of natural disaster incidents demands innovativetechnological solutions to support first responders in their efforts. Thispaper introduces the TRIFFID system, a comprehensive technical framework thatintegrates unmanned ground and aerial vehicles with advanced artificialintelligence functionalities to enhance disaster response capabilities acrosswildfires, urban floods, and post-earthquake search and rescue missions. Byleveraging state-of-the-art autonomous navigation, semantic perception, andhuman-robot interaction technologies, TRIFFID provides a sophisticated systemcom- posed of the following key components: hybrid robotic platform,centralized ground station, custom communication infrastructure, and smartphoneapplication. The defined research and development activities demonstrate howdeep neural networks, knowledge graphs, and multimodal information fusion canenable robots to autonomously navigate and analyze disaster environ- ments,reducing personnel risks and accelerating response times. The proposed systemenhances emergency response teams by providing advanced mission planning,safety monitoring, and adaptive task execution capabilities. Moreover, itensures real- time situational awareness and operational support in complex andrisky situations, facilitating rapid and precise information collection andcoordinated actions.</description>
      <author>example@mail.com (Jorgen Cani, Panagiotis Koletsis, Konstantinos Foteinos, Ioannis Kefaloukos, Lampros Argyriou, Manolis Falelakis, Iván Del Pino, Angel Santamaria-Navarro, Martin Čech, Ondřej Severa, Alessandro Umbrico, Francesca Fracasso, AndreA Orlandini, Dimitrios Drakoulis, Evangelos Markakis, Georgios Th. Papadopoulos)</author>
      <guid isPermaLink="false">2502.09379v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Moving Matter: Efficient Reconfiguration of Tile Arrangements by a Single Active Robot</title>
      <link>http://arxiv.org/abs/2502.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用一个单一的主动机器人重新配置二维连通网格上的被动建筑模块的问题，目标是在保证瓷砖布局始终连通的情况下找到最小化总体完成时间（makespan）的重新配置方案。&lt;h4&gt;背景&lt;/h4&gt;在二维空间中，通过移动和转移单个瓷砖来重新配置由被动组件构成的连通网格布局是一个挑战性问题。&lt;h4&gt;目的&lt;/h4&gt;确定一种能够最小化总工时并确保结构始终连通的再配置策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一个参数化的通用版本，该版本引入了根据携带或不携带瓷砖移动的成本加权的问题，证明其为NP完全问题；同时提供了一种针对起始和目标边界框互斥情况下的近似算法，并且对于2倍缩放实例给出了最优搬运距离。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '提出了具有移动成本的通用化版本并证明其NP完全性', '2': '提供了针对分离起始及目标边界的多项式时间近似算法'}&lt;h4&gt;结论&lt;/h4&gt;虽然问题本身非常困难（NP完全），但对于特定条件下的场景，可以找到有效的解决策略。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑了从初始布局到目标布局重新配置二维连通网格排列的被动构建块的问题，使用单个可以在瓷砖上移动、在给定位置移除个别瓷砖并将其物理地转移到新位置上的主动机器人。目的是确定一个最小化总体完成时间（makespan）的同时确保瓷砖布置保持连接的再配置计划。我们提供了既包括否定性也包含积极的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of reconfiguring a two-dimensional connected gridarrangement of passive building blocks from a start configuration to a goalconfiguration, using a single active robot that can move on the tiles, removeindividual tiles from a given location and physically move them to a newposition by walking on the remaining configuration. The objective is todetermine a reconfiguration schedule that minimizes the overall makespan, whileensuring that the tile configuration remains connected. We provide bothnegative and positive results. (1) We present a generalized version of theproblem, parameterized by weighted costs for moving with or without tiles, andshow that this is NP-complete. (2) We give a polynomial-time constant-factorapproximation algorithm for the case of disjoint start and target boundingboxes. In addition, our approach yields optimal carry distance for 2-scaledinstances.</description>
      <author>example@mail.com (Aaron T. Becker, Sándor P. Fekete, Jonas Friemel, Ramin Kosfeld, Peter Kramer, Harm Kube, Christian Rieck, Christian Scheffer, Arne Schmidt)</author>
      <guid isPermaLink="false">2502.09299v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Safety Evaluation of Human Arm Operations Using IMU Sensors with a Spring-Damper-Mass Predictive Model</title>
      <link>http://arxiv.org/abs/2502.09241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的实时安全监测方法，用于人机协作制造环境，通过在手腕上安装惯性测量单元（IMU）系统并集成预测安全性模型（PSM）。该系统基于弹簧-阻尼-质量模型进行优化，适用于手腕运动，并采用基于阻抗的概率安全性评估。&lt;h4&gt;背景&lt;/h4&gt;现有的预测安全性模型无法完全适应人机协作制造环境中复杂的手腕动作。传统的安全方法可能不够灵活和精确。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的实时监测系统，以提高人机协作环境中的安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于阻抗的安全性评估方法，并使用频域分析方法进行定量化的安全阈值的建立。通过三个制造任务（工具操作、视觉检查以及抓取放置）进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在各种制造场景中表现出强大的性能，同时通过优化参数选择保持了计算效率。&lt;h4&gt;结论&lt;/h4&gt;这项工作为未来实时适应性风险评估的发展奠定了基础，在人机协作制造环境中具有重要应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的完整中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to real-time safety monitoring inhuman-robot collaborative manufacturing environments through a wrist-mountedInertial Measurement Unit (IMU) system integrated with a Predictive SafetyModel (PSM). The proposed system extends previous PSM implementations throughthe adaptation of a spring-damper-mass model specifically optimized for wristmotions, employing probabilistic safety assessment through impedance-basedcomputations. We analyze our proposed impedance-based safety approach withfrequency domain methods, establishing quantitative safety thresholds throughcomprehensive comparative analysis. Experimental validation across threemanufacturing tasks - tool manipulation, visual inspection, and pick-and-placeoperations. Results show robust performance across diverse manufacturingscenarios while maintaining computational efficiency through optimizedparameter selection. This work establishes a foundation for future developmentsin adaptive risk assessment in real-time for human-robot collaborativemanufacturing environments.</description>
      <author>example@mail.com (Musab Zubair Inamdar, Seyed Amir Tafrishi)</author>
      <guid isPermaLink="false">2502.09241v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Machine Learning Approach to Sensor Substitution for Non-Prehensile Manipulation</title>
      <link>http://arxiv.org/abs/2502.09180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, submitted to IEEE Robotics and Automation  Letters, for associated video, see https://youtu.be/Cl6nTBtCaGU&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于机器学习的框架，该框架允许配备有限传感器集（如激光雷达或RGB-D相机）的机器人有效地执行原本依赖更丰富传感器套件（如触觉皮肤）的任务。&lt;h4&gt;背景&lt;/h4&gt;移动机械臂被部署在复杂环境中时需要各种各样的传感器进行感知和交互。然而，并非每个机器人都可以装备所有类型的传感器，因为成本和技术限制的存在使得这变得不切实际。&lt;h4&gt;目的&lt;/h4&gt;解决不同传感器能力的机器人之间协作或执行类似任务的问题。具体来说，当拥有高分辨率触觉皮肤的移动机械臂需要被没有此类触觉感应功能的机器人替换时，学习到的操作策略将不再适用。&lt;h4&gt;方法&lt;/h4&gt;提出了一种机器学习框架，该框架可以学习可用传感器数据和被替代传感器提供的信息之间的映射关系，从而有效地合成缺失的感官输入。通过训练模型来用激光雷达或RGB-D相机代替触觉皮肤的数据来进行非抓取操作任务（如推动）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在经过训练后，配备仅使用激光雷达或RGB-D相机的机械臂在执行非抓取式推动任务时可以达到与直接利用触觉反馈进行操作的移动基础相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;本研究证明了一种有效的传感器替代方法，并为未来基于机器人的多传感器协作应用提供了可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile manipulators are increasingly deployed in complex environments,requiring diverse sensors to perceive and interact with their surroundings.However, equipping every robot with every possible sensor is often impracticaldue to cost and physical constraints. A critical challenge arises when robotswith differing sensor capabilities need to collaborate or perform similartasks. For example, consider a scenario where a mobile manipulator equippedwith high-resolution tactile skin is skilled at non-prehensile manipulationtasks like pushing. If this robot needs to be replaced or augmented by a robotlacking such tactile sensing, the learned manipulation policies becomeinapplicable. This paper addresses the problem of sensor substitution innon-prehensile manipulation. We propose a novel machine learning-basedframework that enables a robot with a limited sensor set (e.g., LiDAR or RGB-Dcamera) to effectively perform tasks previously reliant on a richer sensorsuite (e.g., tactile skin). Our approach learns a mapping between the availablesensor data and the information provided by the substituted sensor, effectivelysynthesizing the missing sensory input. Specifically, we demonstrate theefficacy of our framework by training a model to substitute tactile skin datafor the task of non-prehensile pushing using a mobile manipulator. We show thata manipulator equipped only with LiDAR or RGB-D can, after training, achievecomparable and sometimes even better pushing performance to a mobile baseutilizing direct tactile feedback.</description>
      <author>example@mail.com (Idil Ozdamar, Doganay Sirintuna, Arash Ajoudani)</author>
      <guid isPermaLink="false">2502.09180v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement</title>
      <link>http://arxiv.org/abs/2502.09170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为LimSim Series的综合模拟平台，旨在解决自动驾驶系统（ADS）验证和改进中的挑战。&lt;h4&gt;背景&lt;/h4&gt;闭合回路模拟环境在验证和增强自动驾驶系统的性能方面扮演着关键角色。然而，在准确性与持续时间平衡、功能与实用性协调以及全面评估机制建立等方面存在一些挑战。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，本文提出了LimSim Series平台，该平台支持ADS的快速部署和有效迭代。&lt;h4&gt;方法&lt;/h4&gt;LimSim Series整合了道路网络中的多类型信息，采用了类似人类决策规划算法以增强背景车辆的行为，并引入了“兴趣区域”（AoI）的概念来优化计算资源。此外，它还提供了一系列基准算法和用户友好的界面，使多个技术流程的灵活验证成为可能。&lt;h4&gt;主要发现&lt;/h4&gt;LimSim Series支持模块化、端到端以及基于视觉语言模型的知识驱动系统，并能够评估不同场景下的性能表现。&lt;h4&gt;结论&lt;/h4&gt;实验表明，LimSim Series可以辅助自动驾驶系统的迭代和更新。该平台的代码已在GitHub上公开发布。&lt;h4&gt;翻译&lt;/h4&gt;封闭循环模拟环境在验证和增强自动车辆驾驶（ADS）系统的有效性方面发挥着至关重要的作用。但是，在确保模拟准确性的同时缩短持续时间、平衡功能与实用性以及建立全面评估机制等方面存在一些挑战。本文通过介绍LimSim系列，一个全面的仿真平台来解决这些问题，该平台旨在支持快速部署和有效迭代自动驾驶系统，并集成了多种类型的道路网络信息，采用了类似人类决策规划算法增强背景车辆的行为，并引入了兴趣区域（AoI）的概念以优化计算资源。此外，它还提供了一系列基准算法和用户友好的界面，使灵活验证各种技术流程成为可能，同时提供了多维度的评估指标来全面了解系统的性能表现，从而帮助研究人员快速发现并改进问题。实验结果表明LimSim系列能够兼容模块化、端到端以及基于视觉语言模型的知识驱动系统，并在不同场景下进行性能评价以支持自动驾驶系统的迭代和更新。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Closed-loop simulation environments play a crucial role in the validation andenhancement of autonomous driving systems (ADS). However, certain challengeswarrant significant attention, including balancing simulation accuracy withduration, reconciling functionality with practicality, and establishingcomprehensive evaluation mechanisms. This paper addresses these challenges byintroducing the LimSim Series, a comprehensive simulation platform designed tosupport the rapid deployment and efficient iteration of ADS. The LimSim Seriesintegrates multi-type information from road networks, employs human-likedecision-making and planning algorithms for background vehicles, and introducesthe concept of the Area of Interest (AoI) to optimize computational resources.The platform offers a variety of baseline algorithms and user-friendlyinterfaces, facilitating flexible validation of multiple technical pipelines.Additionally, the LimSim Series incorporates multi-dimensional evaluationmetrics, delivering thorough insights into system performance, thus enablingresearchers to promptly identify issues for further improvements. Experimentsdemonstrate that the LimSim Series is compatible with modular, end-to-end, andVLM-based knowledge-driven systems. It can assist in the iteration and updatingof ADS by evaluating performance across various scenarios. The code of theLimSim Series is released at: https://github.com/PJLab-ADG/LimSim.</description>
      <author>example@mail.com (Daocheng Fu, Naiting Zhong, Xu Han, Pinlong Cai, Licheng Wen, Song Mao, Botian Shi, Yu Qiao)</author>
      <guid isPermaLink="false">2502.09170v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation</title>
      <link>http://arxiv.org/abs/2502.09142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as conference proceeding in International Conference on  Human-Computer Interaction 2025 (HCI International 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人技术和增强现实（AR）的结合为提升人机交互（HRI）提供了变革性的机会，通过改善可用性、直观性和可访问性。&lt;h4&gt;目的&lt;/h4&gt;介绍一种无需控制器、基于大型语言模型驱动的声音指令型AR操控系统，使用户能够实时操作机器人的虚拟版本以远程控制实体机器人。&lt;h4&gt;方法&lt;/h4&gt;利用自然语言处理（NLP）技术和AR技术构建了一个原型系统，使用Meta Quest 3设备进行开发。此系统通过语音命令实现对虚拟机器人的直接操纵，并省去了物理控制器的需求，从而提升了用户体验并减少了潜在的安全风险。&lt;h4&gt;主要发现&lt;/h4&gt;初步用户演示成功验证了系统的功能，展示了其在提供更安全、更具直观性及沉浸式的机器人控制方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该工作表明无需实体控制器的基于语音命令和AR技术的人机交互系统具有实际应用价值，并为未来的HRI研究提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将机器人技术和增强现实（AR）相结合，通过改善可用性、直观性和可访问性，可以推动人机交互（HRI）的发展。本工作介绍了一种无需控制器的大型语言模型驱动的声音指令型AR操控系统，用户可以通过实时操作虚拟机器人的方式远程控制实体机器人。利用自然语言处理（NLP）技术和增强现实技术，我们的系统——使用Meta Quest 3原型构建——消除了物理控制器的需求，提高了易用性并减少了直接操作机器人时的潜在安全风险。初步用户演示成功地验证了系统的功能，展示了其在提供更安全、更具直观性和沉浸感的机器人控制方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of robotics and augmented reality (AR) presentstransformative opportunities for advancing human-robot interaction (HRI) byimproving usability, intuitiveness, and accessibility. This work introduces acontroller-free, LLM-driven voice-commanded AR puppeteering system, enablingusers to teleoperate a robot by manipulating its virtual counterpart in realtime. By leveraging natural language processing (NLP) and AR technologies, oursystem -- prototyped using Meta Quest 3 -- eliminates the need for physicalcontrollers, enhancing ease of use while minimizing potential safety risksassociated with direct robot operation. A preliminary user demonstrationsuccessfully validated the system's functionality, demonstrating its potentialfor safer, more intuitive, and immersive robotic control.</description>
      <author>example@mail.com (Yuchong Zhang, Bastian Orthmann, Michael C. Welle, Jonne Van Haastregt, Danica Kragic)</author>
      <guid isPermaLink="false">2502.09142v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior</title>
      <link>http://arxiv.org/abs/2502.09111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的SLAM系统DenseSplat，该系统结合了NeRF和3DGS的优点，在稀疏视图条件下能够有效填充地图中的空白区域。&lt;h4&gt;背景&lt;/h4&gt;高斯SLAM系统在实时渲染和精细化重建方面优于基于NeRF的系统。然而，其依赖于大量关键帧的问题使其难以部署到实际机器人中，因为实际情况通常需要处理稀疏视角条件下的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以高效利用稀疏关键帧并填充地图空白区域的SLAM系统，以提高其实用性和性能。&lt;h4&gt;方法&lt;/h4&gt;DenseSplat使用了NeRF先验知识来初始化可以在地图中密集填充的原始体，并实现了感知几何的采样和修剪策略。此外，该系统还集成了闭环检测和捆绑调整功能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个大规模数据集上，DenseSplat在跟踪和建图方面的表现优于当前最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;DenseSplat克服了传统SLAM系统的局限性，提供了一种新的解决方案来解决稀疏视图条件下地图重建的问题。&lt;h4&gt;翻译&lt;/h4&gt;Gaussian SLAM系统在实时渲染和精细化重建方面比基于NeRF的系统更优。然而，在实际机器人应用中，它们对大量关键帧的需求是不切实际的，因为通常情况下，这些场景需要处理的是稀疏视角条件下的问题。为了解决这些问题，我们引入了DenseSplat，这是第一个有效结合NeRF和3DGS优势的SLAM系统。它使用稀疏的关键帧和NeRF先验知识来初始化填充地图的原始体，并实施感知几何学采样和修剪策略以管理粒度并提高渲染效率。此外，该系统还集成了闭环检测和捆绑调整功能，显著提高了帧间跟踪的准确性。在多个大规模数据集上的广泛实验表明，与当前最先进的方法相比，DenseSplat在跟踪和映射方面取得了更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian SLAM systems excel in real-time rendering and fine-grainedreconstruction compared to NeRF-based systems. However, their reliance onextensive keyframes is impractical for deployment in real-world roboticsystems, which typically operate under sparse-view conditions that can resultin substantial holes in the map. To address these challenges, we introduceDenseSplat, the first SLAM system that effectively combines the advantages ofNeRF and 3DGS. DenseSplat utilizes sparse keyframes and NeRF priors forinitializing primitives that densely populate maps and seamlessly fill gaps. Italso implements geometry-aware primitive sampling and pruning strategies tomanage granularity and enhance rendering efficiency. Moreover, DenseSplatintegrates loop closure and bundle adjustment, significantly enhancingframe-to-frame tracking accuracy. Extensive experiments on multiple large-scaledatasets demonstrate that DenseSplat achieves superior performance in trackingand mapping compared to current state-of-the-art methods.</description>
      <author>example@mail.com (Mingrui Li, Shuhong Liu, Tianchen Deng, Hongyu Wang)</author>
      <guid isPermaLink="false">2502.09111v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>MTDP: Modulated Transformer Diffusion Policy Model</title>
      <link>http://arxiv.org/abs/2502.09029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Transformer架构——调制化Transformer扩散策略（MTDP）模型，用于提高机器人基于行为克隆的任务学习效率。&lt;h4&gt;背景&lt;/h4&gt;近期研究通过将扩散模型与行为克隆结合提出了扩散策略，显著提高了机器人的任务成功率。但是，高容量Transformer在整合引导条件时存在困难，导致使用此类架构的模型在操纵任务中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的调制化注意力模块来改进传统Transformer结构，以有效解决指导条件的集成问题，并提高生成模型输出质量。&lt;h4&gt;方法&lt;/h4&gt;引入了Modulated Transformer Diffusion Policy（MTDP）和Modulated UNet Diffusion Policy（MUDP）两种模型。其中核心是通过提出的调制化注意力模块来更有效地将引导条件与主要输入结合，同时探索使用Denoising Diffusion Implicit Models (DDIM)作为扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示MTDP在六项任务中表现优于现有Transformer架构，在Toolhang实验中的成功率提高了12%。而MUDP则普遍超越了现有的UNet架构的性能。另外，采用DDIM作为扩散模型的MTDP-I和MUDP-I几乎将生成速度翻倍。&lt;h4&gt;结论&lt;/h4&gt;通过提出调制化注意力模块改进Transformer结构，显著提升了机器人操作任务的成功率，并且提高了生成效率。&lt;h4&gt;翻译&lt;/h4&gt;近期关于基于行为克隆（BC）的机器人操纵研究已经取得了重大进展。通过结合扩散模型与BC提出了扩散策略，使机器人能够快速学习高成功率的操作任务。然而，在将扩散政策与大型变压器整合时遇到了挑战，传统的Transformer架构难以有效融合引导条件，在使用Transformer基模型进行操作任务时表现不佳。本文探讨了Transformer的关键架构设计，并通过提出调制化注意力模块改进传统Transformer结构，以提升生成模型的输出质量及机器人任务成功率。在六项实验中，MTDP优于现有Transformer架构，尤其是在Toolhang实验中成功率为12%的增幅。为验证调制化注意的有效性，将其应用于UNet架构构建Modulated UNet Diffusion Policy（MUDP），该模型也超越了所有六个实验中的现有UNet架构的成功率。扩散政策使用去噪扩散概率模型作为扩散模型，并基于此探索了DDIM，以创建MTDP-I和MUDP-I模型，几乎使生成速度翻倍同时保持性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research on robot manipulation based on Behavior Cloning (BC) has madesignificant progress. By combining diffusion models with BC, diffusion policiyhas been proposed, enabling robots to quickly learn manipulation tasks withhigh success rates. However, integrating diffusion policy with high-capacityTransformer presents challenges, traditional Transformer architectures struggleto effectively integrate guiding conditions, resulting in poor performance inmanipulation tasks when using Transformer-based models. In this paper, weinvestigate key architectural designs of Transformers and improve thetraditional Transformer architecture by proposing the Modulated TransformerDiffusion Policy (MTDP) model for diffusion policy. The core of this model isthe Modulated Attention module we proposed, which more effectively integratesthe guiding conditions with the main input, improving the generative model'soutput quality and, consequently, increasing the robot's task success rate. Insix experimental tasks, MTDP outperformed existing Transformer modelarchitectures, particularly in the Toolhang experiment, where the success rateincreased by 12\%. To verify the generality of Modulated Attention, we appliedit to the UNet architecture to construct Modulated UNet Diffusion Policy model(MUDP), which also achieved higher success rates than existing UNetarchitectures across all six experiments. The Diffusion Policy uses DenoisingDiffusion Probabilistic Models (DDPM) as the diffusion model. Building on this,we also explored Denoising Diffusion Implicit Models (DDIM) as the diffusionmodel, constructing the MTDP-I and MUDP-I model, which nearly doubled thegeneration speed while maintaining performance.</description>
      <author>example@mail.com (Qianhao Wang, Yinqian Sun, Enmeng Lu, Qian Zhang, Yi Zeng)</author>
      <guid isPermaLink="false">2502.09029v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>SkyRover: A Modular Simulator for Cross-Domain Pathfinding</title>
      <link>http://arxiv.org/abs/2502.08969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SkyRover的模块化模拟器，用于研究无人飞行器（UAV）和自动导引车（AGV）在多智能体路径查找中的协作。&lt;h4&gt;背景&lt;/h4&gt;现有的模拟器通常专注于单一领域，限制了跨领域的研究。为了克服这一问题，提出了SkyRover以支持更全面的多域算法设计、测试和基准测试。&lt;h4&gt;目的&lt;/h4&gt;提供一种可以用于UAV-AGV多智能体路径查找（MAPF）的通用仿真平台。&lt;h4&gt;方法&lt;/h4&gt;SkyRover具有真实的代理动态，可配置的3D环境以及方便外部求解器和学习方法使用的API接口。该模拟器统一了地面和空中的操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SkyRover能够实现高效的路径查找，并且在UAV-AGV协调中提供高保真的仿真。&lt;h4&gt;结论&lt;/h4&gt;SkyRover是一个强大的工具，用于跨域算法的设计、测试以及基准性能的比较。&lt;h4&gt;翻译&lt;/h4&gt;无人驾驶飞行器（无人机）和自动引导车（AGV）在物流、监视、检查等任务中的合作越来越紧密。然而，现有的模拟器通常专注于单一领域，限制了跨领域的研究。本文提出了一种名为SkyRover的模块化模拟器，用于UAV-AGV多智能体路径查找（MAPF）。SkyRover支持真实的代理动态，可配置的3D环境以及方便外部求解器和学习方法使用的API接口。通过统一地面和空中的操作，它促进了跨领域的算法设计、测试及基准比较。实验表明，SkyRover在UAV-AGV协调中具有高效路径查找和高保真仿真的能力。该项目可以在https://sites.google.com/view/mapf3d/home上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned Aerial Vehicles (UAVs) and Automated Guided Vehicles (AGVs)increasingly collaborate in logistics, surveillance, inspection tasks and etc.However, existing simulators often focus on a single domain, limitingcross-domain study. This paper presents the SkyRover, a modular simulator forUAV-AGV multi-agent pathfinding (MAPF). SkyRover supports realistic agentdynamics, configurable 3D environments, and convenient APIs for externalsolvers and learning methods. By unifying ground and aerial operations, itfacilitates cross-domain algorithm design, testing, and benchmarking.Experiments highlight SkyRover's capacity for efficient pathfinding andhigh-fidelity simulations in UAV-AGV coordination. Project is available athttps://sites.google.com/view/mapf3d/home.</description>
      <author>example@mail.com (Wenhui Ma, Wenhao Li, Bo Jin, Changhong Lu, Xiangfeng Wang)</author>
      <guid isPermaLink="false">2502.08969v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Training Trajectory Predictors Without Ground-Truth Data</title>
      <link>http://arxiv.org/abs/2502.08957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种能够准确平滑地估计位置、航向和速度的框架。基于此高质量输入，我们提出了一个基于Trajectron++系统的模型，能够持续生成精确的轨迹预测。&lt;h4&gt;背景&lt;/h4&gt;传统的轨迹预测模型依赖于地面真实数据进行训练，而这些数据可能难以获取或质量不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖地面真实数据即可有效训练轨迹预测模型的方法，并评估输入数据质量和模型输出之间的关系。&lt;h4&gt;方法&lt;/h4&gt;提出了一个高质量的估计系统框架和基于Trajectron++的预测系统，该系统能够仅依靠自身的估计结果进行学习和改进。&lt;h4&gt;主要发现&lt;/h4&gt;低质量的输入会导致噪声大的和不可靠的预测，这对导航模块不利。同时证明了在缺乏大量训练数据的情况下也能有效训练轨迹预测模型，并产生跨不同环境有效的预测结果。&lt;h4&gt;结论&lt;/h4&gt;准确的估计对于在真实世界场景中部署轨迹预测模型至关重要，而本文提出的方法能够确保无论应用上下文如何都提供有意义和可靠的结果。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种能精确且平滑地估算位置、航向及速度的框架，并基于高质量输入数据开发了一个利用Trajectron++系统的精准轨迹预测系统。不同于需要地面真实数据进行训练的传统模型，本文的方法摆脱了这种依赖性。研究表明低质量输入会导致噪声和不可靠的结果，这对导航模块具有破坏性影响。通过对输入数据质量和模型输出的评估来展示输入噪音的影响，并展示了即使在缺乏大量数据的情况下也能有效训练轨迹预测模型，产生跨不同环境的有效预测结果。精确估计对实际场景中部署这些模型至关重要，该系统能确保无论应用背景如何都能提供有意义且可靠的成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework capable of accurately and smoothly estimatingposition, heading, and velocity. Using this high-quality input, we propose asystem based on Trajectron++, able to consistently generate precise trajectorypredictions. Unlike conventional models that require ground-truth data fortraining, our approach eliminates this dependency. Our analysis demonstratesthat poor quality input leads to noisy and unreliable predictions, which can bedetrimental to navigation modules. We evaluate both input data quality andmodel output to illustrate the impact of input noise. Furthermore, we show thatour estimation system enables effective training of trajectory predictionmodels even with limited data, producing robust predictions across differentenvironments. Accurate estimations are crucial for deploying trajectoryprediction models in real-world scenarios, and our system ensures meaningfuland reliable results across various application contexts.</description>
      <author>example@mail.com (Mikolaj Kliniewski, Jesse Morris, Ian R. Manchester, Viorela Ila)</author>
      <guid isPermaLink="false">2502.08957v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>WanderGuide: Indoor Map-less Robotic Guide for Exploration by Blind People</title>
      <link>http://arxiv.org/abs/2502.08906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;盲人探索环境的机会有限。现有的导航系统虽然可以提供周围信息，但需要预先构建地图，因此可扩展性较差。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需预建地图的机器人辅助系统，让盲人能够根据兴趣自由地探索环境。&lt;h4&gt;方法&lt;/h4&gt;首先在购物商城和科学博物馆进行了一项包含十位盲人的研究以调查系统需求。之后研发了WanderGuide，该系统能让用户调整描述细节的程度，并通过口头互动询问关于环境的信息或前往感兴趣的地方。&lt;h4&gt;主要发现&lt;/h4&gt;通过五名盲人参与的研究表明，WanderGuide能够提供给盲人在心中没有明确目的地的情况下自由漫步的愉快体验。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了用户需要以不同层次详细程度描述周围环境的需求。新研发的系统满足这些需求，并为用户提供了一种更有趣和更有用的方式来探索他们所处的空间。&lt;h4&gt;翻译&lt;/h4&gt;盲人面临着较少机会根据个人兴趣来探索周围环境的问题。虽然现有的导航技术可以在导航过程中提供一些基本信息，但它们依赖于预构建的地图，难以大规模应用。为了开发一种不需要地图的机器人辅助系统以帮助盲人更好地探索环境，研究团队首先进行了包含十名盲人的实地调查，在购物商城和科学博物馆内收集了他们的需求。调查表明用户需要根据自身的喜好对周围环境进行层次化的描述。基于这些信息，他们研发出了WanderGuide。该导航工具能够提供三个不同的详细程度供用户选择，并且可以与系统以语音的方式互动，如询问关于当前位置的细节或前往感兴趣的地点等。五名盲人参与了进一步的研究测试，结果显示WanderGuide能够让使用者享受到没有目的地约束情况下的漫游乐趣。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713788&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blind people have limited opportunities to explore an environment based ontheir interests. While existing navigation systems could provide them withsurrounding information while navigating, they have limited scalability as theyrequire preparing prebuilt maps. Thus, to develop a map-less robot that assistsblind people in exploring, we first conducted a study with ten blindparticipants at a shopping mall and science museum to investigate therequirements of the system, which revealed the need for three levels of detailto describe the surroundings based on users' preferences. Then, we developedWanderGuide, with functionalities that allow users to adjust the level ofdetail in descriptions and verbally interact with the system to ask questionsabout the environment or to go to points of interest. The study with five blindparticipants revealed that WanderGuide could provide blind people with theenjoyable experience of wandering around without a specific destination intheir minds.</description>
      <author>example@mail.com (Masaki Kuribayashi, Kohei Uehara, Allan Wang, Shigeo Morishima, Chieko Asakawa)</author>
      <guid isPermaLink="false">2502.08906v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Data Sensor Fusion In Digital Twin Technology For Enhanced Capabilities In A Home Environment</title>
      <link>http://arxiv.org/abs/2502.08874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了数据传感器融合在数字孪生技术中的应用，以增强家庭环境的功能，并特别关注新冠肺炎疫情带来的挑战及其经济影响。&lt;h4&gt;背景&lt;/h4&gt;研究强调数字化转型不仅有助于适应第四次工业革命的变革，还能缓解其带来的中断。使用Wit Motion传感器收集步行、工作、坐立和躺卧等活动的数据。&lt;h4&gt;目的&lt;/h4&gt;目的是通过结合赛博物理系统、物联网(IoT)、人工智能(AI)和机器人技术来增强数字孪生的能力。&lt;h4&gt;方法&lt;/h4&gt;研究比较了多种传感器融合方法，包括特征级融合、决策级融合以及卡尔曼滤波器融合，并使用支持向量机(SVM)、梯度提升(GBDT)及随机森林(RF)等机器学习模型进行效果评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，传感器融合显著提高了这些模型的准确性和可靠性，尤其能弥补单一传感器在磁力计上的弱点。尽管理想条件下精度更高，但多传感器数据整合确保了现实场景下的稳定和可靠结果。&lt;h4&gt;结论&lt;/h4&gt;因此建立了一个稳健的应用系统，可以在实际情景中被信任地采用。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译版本&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the integration of data sensor fusion in digital twintechnology to bolster home environment capabilities, particularly in thecontext of challenges brought on by the coronavirus pandemic and its economiceffects. The study underscores the crucial role of digital transformation innot just adapting to, but also mitigating disruptions during the fourthindustrial revolution. Using the Wit Motion sensor, data was collected foractivities such as walking, working, sitting, and lying, with sensors measuringaccelerometers, gyroscopes, and magnetometers. The research integratesCyber-physical systems, IoT, AI, and robotics to fortify digital twincapabilities.  The paper compares sensor fusion methods, including feature-level fusion,decision-level fusion, and Kalman filter fusion, alongside machine learningmodels like SVM, GBoost, and Random Forest to assess model effectiveness.Results show that sensor fusion significantly improves the accuracy andreliability of these models, as it compensates for individual sensorweaknesses, particularly with magnetometers. Despite higher accuracy in idealconditions, integrating data from multiple sensors ensures more consistent andreliable results in real-world settings, thereby establishing a robust systemthat can be confidently applied in practical scenarios.</description>
      <author>example@mail.com (Benjamin Momoh, Salisu Yahaya)</author>
      <guid isPermaLink="false">2502.08874v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>MuJoCo Playground</title>
      <link>http://arxiv.org/abs/2502.08844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了MuJoCo Playground，这是一个开源的机器人学习框架，旨在简化模拟、训练以及从模拟到现实机器人的迁移。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人学习方法往往需要复杂的设置和长时间的调试才能在实际硬件上运行。&lt;h4&gt;目的&lt;/h4&gt;通过提供一个完全开放源代码的框架来促进研究者快速进行模拟环境下的策略训练，并实现无监督的从模拟环境向真实机器人转移的技术。&lt;h4&gt;方法&lt;/h4&gt;利用MJX技术创建了MuJoCo Playground，该平台支持多种机器人平台（包括四足、人形、灵巧手和机械臂），并整合了一个包含物理引擎、批处理渲染器及训练环境的集成栈。&lt;h4&gt;主要发现&lt;/h4&gt;通过安装pip install playground命令，研究者可以在单个GPU上几分钟内完成策略训练，并且可以从状态输入或像素输入进行零样本模拟到现实机器人的迁移。&lt;h4&gt;结论&lt;/h4&gt;MuJoCo Playground为机器人学习领域提供了新的可能性，使得在真实硬件上的实验变得更加便捷和高效。整个框架及其视频结果都可以免费获取。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了MuJoCo游乐场，这是一个基于MJX完全开源的机器人学习框架，其目的是简化模拟、训练以及从模拟到现实机器人的迁移。通过简单的pip install playground命令安装后，研究人员可以在单个GPU上几分钟内完成策略训练。游乐场支持多种机器人平台（包括四足、人形、灵巧手和机械臂），实现无监督的从状态输入或像素输入进行零样本模拟到真实机器人的迁移。这得益于一个包含物理引擎、批处理渲染器及训练环境的集成栈的支持。除了视频结果，整个框架都免费提供在playground.mujoco.org上&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce MuJoCo Playground, a fully open-source framework for robotlearning built with MJX, with the express goal of streamlining simulation,training, and sim-to-real transfer onto robots. With a simple "pip installplayground", researchers can train policies in minutes on a single GPU.Playground supports diverse robotic platforms, including quadrupeds, humanoids,dexterous hands, and robotic arms, enabling zero-shot sim-to-real transfer fromboth state and pixel inputs. This is achieved through an integrated stackcomprising a physics engine, batch renderer, and training environments. Alongwith video results, the entire framework is freely available atplayground.mujoco.org</description>
      <author>example@mail.com (Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder A. Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel)</author>
      <guid isPermaLink="false">2502.08844v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>ClipRover: Zero-shot Vision-Language Exploration and Target Discovery by Mobile Robots</title>
      <link>http://arxiv.org/abs/2502.08791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  V1, 21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型导航管道ClipRover，用于未知环境中的同时探索和目标发现。&lt;h4&gt;背景&lt;/h4&gt;当前的视觉-语言导航系统通常将地图探索与路径规划分开，并依赖于低效算法由于有限的（部分观察到的）环境信息。这些系统在执行零样本推理任务时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型导航管道，用于未知环境中的同时探索和目标发现。&lt;h4&gt;方法&lt;/h4&gt;使用视觉-语言模型CLIP的能力，结合单目视觉和功能原型UGV系统Rover Master进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ClipRover在吞吐量、障碍物规避能力和轨迹性能方面均优于传统地图遍历算法，并且其表现与依赖于先前地图和目标知识的路径规划方法相当。特别是，ClipRover能够在没有预先捕获候选图像或预建节点图的情况下进行实时主动导航。&lt;h4&gt;结论&lt;/h4&gt;提出的新型导航管道在未知环境中表现出优越的性能，展示了视觉-语言模型用于自主导航任务的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language navigation (VLN)技术作为移动机器人执行零样本推理和执行任务的一种有前途的方法已出现。然而，现有的系统通常将地图探索与路径规划分开进行，并且由于有限的信息（部分观察到的环境信息），这些系统的探索依赖于低效算法。在这篇论文中，我们提出了一种名为“ClipRover”的新型导航管道，在未知环境中同时实现探索和目标发现，利用视觉-语言模型CLIP的能力。我们的方法仅需要单目视觉，并且不需要任何先前的地图或对目标的知识。为了进行全面评估，我们设计了一个名为“Rover Master”的无人地面车辆系统功能原型，这是一个专为通用VLN任务定制的平台。我们将ClipRover管道集成并部署到Rover Master上，在各种真实场景中对其吞吐量、障碍物规避能力和轨迹性能进行评估。实验结果显示，ClipRover在吞吐量和轨迹性能方面优于传统的地图遍历算法，并且其表现与依赖于先前地图和目标知识的路径规划方法相当。值得注意的是，ClipRover可以在没有预先捕获候选图像或预建节点图的情况下实现实时主动导航，解决了现有VLN管道的关键限制问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language navigation (VLN) has emerged as a promising paradigm,enabling mobile robots to perform zero-shot inference and execute tasks withoutspecific pre-programming. However, current systems often separate mapexploration and path planning, with exploration relying on inefficientalgorithms due to limited (partially observed) environmental information. Inthis paper, we present a novel navigation pipeline named ''ClipRover'' forsimultaneous exploration and target discovery in unknown environments,leveraging the capabilities of a vision-language model named CLIP. Our approachrequires only monocular vision and operates without any prior map or knowledgeabout the target. For comprehensive evaluations, we design the functionalprototype of a UGV (unmanned ground vehicle) system named ''Rover Master'', acustomized platform for general-purpose VLN tasks. We integrate and deploy theClipRover pipeline on Rover Master to evaluate its throughput, obstacleavoidance capability, and trajectory performance across various real-worldscenarios. Experimental results demonstrate that ClipRover consistentlyoutperforms traditional map traversal algorithms and achieves performancecomparable to path-planning methods that depend on prior map and targetknowledge. Notably, ClipRover offers real-time active navigation withoutrequiring pre-captured candidate images or pre-built node graphs, addressingkey limitations of existing VLN pipelines.</description>
      <author>example@mail.com (Yuxuan Zhang, Adnan Abdullah, Sanjeev J. Koppal, Md Jahidul Islam)</author>
      <guid isPermaLink="false">2502.08791v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Acoustic Wave Manipulation Through Sparse Robotic Actuation</title>
      <link>http://arxiv.org/abs/2502.08784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，机器人、控制和机器学习的进步推动了物体操纵领域的进展。本文探索了一项更具挑战性的问题：通过部分被机器人传感器观测到的声波进行操作，并使用空间稀疏驱动器影响这些声波。&lt;h4&gt;背景&lt;/h4&gt;当前研究中利用深度神经网络表示由机器人传感器部分观察到的动力学模型，以及采用稀疏控制信号的有效控制方法已经取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的基于数据的方法，使得机器人能够聚焦或抑制在指定区域散射的声能，根据具体任务的需求进行调整。&lt;h4&gt;方法&lt;/h4&gt;提出了一种适用于通过偏微分方程描述的动力系统操作的数据驱动学习法，并与现有最佳机器学习方法和经典半解析方法进行了比较，该方法在解决方案质量和计算复杂度方面表现更优。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在聚焦或抑制声能的效率和精确性上优于现有的机器学习方法，并且在某些应用场景中可以媲美经典的半解析方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法具有设计新型人工材料、超声切割工具以及能量采集等领域的应用潜力，同时也展示了机器人技术在复杂物理现象操控中的强大能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文译文为：近年来，在机器人学、控制理论和机器学习方面的进步促进了物体操纵这一挑战性领域的发展。这些进展包括利用深度神经网络来表示部分由机器人传感器观测到的动力学，以及采用稀疏控制信号的有效控制方法。在本文中，我们探讨了一个更具普遍性的问题：即通过空间上稀疏的驱动器影响声波，并且这些声波仅能被一个特定类型的机器人部分感知的问题。这一领域具有巨大的潜力，适用于新型人工材料设计、超声切割工具制造以及能量采集等应用。我们开发了一种高效的基于数据的方法用于机器学习，该方法能够应用于聚焦或者抑制在指定区域的散射声能，具体取决于任务需求。相比于目前最先进的利用偏微分方程描述的动力系统操作的机器学习方法，我们的方法在解决方案质量和计算复杂度方面表现出色；此外，在实际演示的任务中，我们提出的方法与经典的半解析法相竞争。项目代码及相关视频展示已公开：https://gladisor.github.io/waves/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in robotics, control, and machine learning havefacilitated progress in the challenging area of object manipulation. Theseadvancements include, among others, the use of deep neural networks torepresent dynamics that are partially observed by robot sensors, as well aseffective control using sparse control signals. In this work, we explore a moregeneral problem: the manipulation of acoustic waves, which are partiallyobserved by a robot capable of influencing the waves through spatially sparseactuators. This problem holds great potential for the design of new artificialmaterials, ultrasonic cutting tools, energy harvesting, and other applications.We develop an efficient data-driven method for robot learning that isapplicable to either focusing scattered acoustic energy in a designated regionor suppressing it, depending on the desired task. The proposed method is betterin terms of a solution quality and computational complexity as compared to astate-of-the-art learning based method for manipulation of dynamical systemsgoverned by partial differential equations. Furthermore our proposed method iscompetitive with a classical semi-analytical method in acoustics research onthe demonstrated tasks. We have made the project code publicly available, alongwith a web page featuring video demonstrations:https://gladisor.github.io/waves/.</description>
      <author>example@mail.com (Tristan Shah, Noam Smilovich, Samer Gerges, Feruza Amirkulova, Stas Tiomkin)</author>
      <guid isPermaLink="false">2502.08784v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Europe's AI Imperative -- A Pragmatic Blueprint for Global Tech Leadership</title>
      <link>http://arxiv.org/abs/2502.08781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;欧洲在与美国的大型风险资本和技术巨头以及中国的规模导向型、自上而下的发展模式的竞争中处于关键时刻。&lt;h4&gt;目的&lt;/h4&gt;鉴于人工智能与量子计算、生物科技、虚拟现实/增强现实（VR/AR）、5G/6G、机器人技术、先进材料和高性能计算等互补性技术和协同技术的融合可能会颠覆地缘政治平衡，欧洲需要重新思考其在人工智能领域的策略。&lt;h4&gt;总结&lt;/h4&gt;论文提出了一项基于欧洲优势并弥补差距的战略方案。&lt;h4&gt;方法&lt;/h4&gt;该战略是在巴黎2025年的人工智能行动峰会上提出的，并且具有实际可操作性。&lt;h4&gt;主要发现&lt;/h4&gt;&lt;h4&gt;结论&lt;/h4&gt;通过重新思考其人工智能策略，欧洲有可能在国际竞争中取得成功。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于欧洲如何在全球AI竞赛中的关键时刻制定可行的战略以弥补与美国和中国的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Europe is at a make-or-break moment in the global AI race, squeezed betweenthe massive venture capital and tech giants in the US and China'sscale-oriented, top-down drive. At this tipping point, where the convergence ofAI with complementary and synergistic technologies, like quantum computing,biotech, VR/AR, 5G/6G, robotics, advanced materials, and high-performancecomputing, could upend geopolitical balances, Europe needs to rethink itsAI-related strategy. On the heels of the AI Action Summit 2025 in Paris, wepresent a sharp, doable strategy that builds upon Europe's strengths and closesgaps.</description>
      <author>example@mail.com (Gjergji Kasneci, Urs Gasser, Thomas F. Hofmann, Gerhard Kramer, Gerhard Müller, Claudia Peus, Helmut Schönenberger, Enkelejda Kasneci)</author>
      <guid isPermaLink="false">2502.08781v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Bilevel Learning for Bilevel Planning</title>
      <link>http://arxiv.org/abs/2502.08697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的双层规划方法IVNTR，该方法能够从演示中直接学习神经谓词。这种方法结合了符号和神经网络的学习机制，在多种机器人任务上表现出卓越的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;当前的双层规划方法依赖于手动设计或非常简单的谓词表示，这限制了它们在复杂高维状态空间中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动从演示中学习复杂神经网络谓词的双层规划框架。&lt;h4&gt;方法&lt;/h4&gt;提出了IVNTR方法，该方法通过交替进行符号学习和神经网络学习来实现对复杂任务的理解和泛化。符号学习处理谓词的效果，而神经网络学习则关注谓词的功能。&lt;h4&gt;主要发现&lt;/h4&gt;在六种不同的机器人领域中，IVNTR展示了显著的抽象能力，并且在未见过的任务上达到了77%的成功率，远高于现有方法（小于35%成功率）。此外，在移动操作器场景中的测试也证明了它的泛化能力和实用性。&lt;h4&gt;结论&lt;/h4&gt;通过学习和规划与抽象的关系，IVNTR为实现高层次的泛化提供了新的途径，并且展示了在实际机器人任务中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;一个从演示中学习的机器人不应仅仅模仿它看到的东西——应该理解被展示的高层概念并将它们推广到新任务上。双层规划是一种层次化的基于模型的方法，其中谓词（关系状态抽象）可以用来实现组合泛化。然而，先前的双层规划方法依赖于要么手动工程设计或仅限于非常简单形式的谓词表示，这限制了其在复杂高维状态空间中的扩展性。为了克服这一限制，我们提出了一种名为IVNTR的新方法——第一个能够直接从演示中学习神经谓词的双层规划方法。我们的主要创新是一种镜像双层规划结构的神经符号双层学习框架，在该框架下，谓词“效果”的符号学习和谓词“功能”的神经网络学习交替进行，相互指导。我们在六个不同的机器人规划领域评估了IVNTR的表现力，证明它能够抽象各种连续且高维的状态。尽管大多数现有的方法在泛化时表现不佳（成功率小于35%），我们的IVNTR则在未见过的任务上实现了77%的成功率。此外，我们还展示了IVNTR在一个移动操作器上的应用，它可以学习执行现实世界中的移动操控任务，并推广到包含新对象、新的状态以及更长任务时间的测试场景中去。我们的研究结果强调了通过抽象进行学习和规划作为实现高层次泛化的路径的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A robot that learns from demonstrations should not just imitate what it sees-- it should understand the high-level concepts that are being demonstrated andgeneralize them to new tasks. Bilevel planning is a hierarchical model-basedapproach where predicates (relational state abstractions) can be leveraged toachieve compositional generalization. However, previous bilevel planningapproaches depend on predicates that are either hand-engineered or restrictedto very simple forms, limiting their scalability to sophisticated,high-dimensional state spaces. To address this limitation, we present IVNTR,the first bilevel planning approach capable of learning neural predicatesdirectly from demonstrations. Our key innovation is a neuro-symbolic bilevellearning framework that mirrors the structure of bilevel planning. In IVNTR,symbolic learning of the predicate "effects" and neural learning of thepredicate "functions" alternate, with each providing guidance for the other. Weevaluate IVNTR in six diverse robot planning domains, demonstrating itseffectiveness in abstracting various continuous and high-dimensional states.While most existing approaches struggle to generalize (with &lt;35% success rate),our IVNTR achieves an average of 77% success rate on unseen tasks.Additionally, we showcase IVNTR on a mobile manipulator, where it learns toperform real-world mobile manipulation tasks and generalizes to unseen testscenarios that feature new objects, new states, and longer task horizons. Ourfindings underscore the promise of learning and planning with abstractions as apath towards high-level generalization.</description>
      <author>example@mail.com (Bowen Li, Tom Silver, Sebastian Scherer, Alexander Gray)</author>
      <guid isPermaLink="false">2502.08697v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Uniform Kernel Prober</title>
      <link>http://arxiv.org/abs/2502.07369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uniform Kernel Prober (UKP)的伪度量，用于评估不同统计模型（如神经网络）学习到的不同特征或表示在下游预测任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;多任务学习的成功在于能够基于训练数据识别出对多种预测任务都有低预测误差的有用特征或表示。然而，在实践中选择合适的预测任务以及获得这些任务的相关测试数据是一个挑战，这使得比较不同特征的表现变得困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种伪度量方法来评估和比较不同的特征或表示在下游预测任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Uniform Kernel Prober (UKP)的伪度量方法。这种伪度量可以在没有测试数据的情况下，基于给定的核函数提供一个统一的、对所有类型的核岭回归任务有效的衡量标准。&lt;h4&gt;主要发现&lt;/h4&gt;提出的伪度量能够有效地估计输入数据样本的数量，并通过选择合适的核函数捕捉表示中的所需不变性；此外，实验结果表明UKP能够在下游核岭回归任务中根据一般化性能区分不同类型的特征或表示。&lt;h4&gt;结论&lt;/h4&gt;Uniform Kernel Prober (UKP)作为一种新方法，在评估和比较多任务学习模型的性能方面具有重要的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;识别基于训练数据能够实现低预测误差的有效特征或表示是多任务学习成功的关键。然而，实践中的挑战在于选择适当的预测任务以及获取这些任务相关的测试数据，这使得比较不同特征的表现变得复杂。本文提出了一种名为Uniform Kernel Prober (UKP)的伪度量方法用于评估和比较统计模型如神经网络所学的不同特征或表示在涉及核岭回归的下游预测任务中的表现。该伪度量可以在没有测试数据的情况下提供统一衡量标准，并通过选择合适的核函数捕捉表示中的所需不变性。实验结果表明，UKP能够在多任务学习中根据一般化性能区分不同类型的特征或表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to identify useful features or representations of the input databased on training data that achieves low prediction error on test data acrossmultiple prediction tasks is considered the key to multitask learning success.In practice, however, one faces the issue of the choice of prediction tasks andthe availability of test data from the chosen tasks while comparing therelative performance of different features. In this work, we develop a class ofpseudometrics called Uniform Kernel Prober (UKP) for comparing features orrepresentations learned by different statistical models such as neural networkswhen the downstream prediction tasks involve kernel ridge regression. Theproposed pseudometric, UKP, between any two representations, provides a uniformmeasure of prediction error on test data corresponding to a general class ofkernel ridge regression tasks for a given choice of a kernel without access totest data. Additionally, desired invariances in representations can besuccessfully captured by UKP only through the choice of the kernel function andthe pseudometric can be efficiently estimated from $n$ input data samples with$O(\frac{1}{\sqrt{n}})$ estimation error. We also experimentally demonstratethe ability of UKP to discriminate between different types of features orrepresentations based on their generalization performance on downstream kernelridge regression tasks.</description>
      <author>example@mail.com (Soumya Mukherjee, Bharath K. Sriperumbudur)</author>
      <guid isPermaLink="false">2502.07369v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
  <item>
      <title>A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion</title>
      <link>http://arxiv.org/abs/2502.08573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于对比学习和视觉序列压缩的新型多模态情感识别方法DeepMSI-MER。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能与计算机视觉技术的进步，多模态情绪识别已成为研究热点。然而，现有方法在异构数据融合及模式间相关性的有效利用方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态情感识别方法，旨在改进跨模式特征融合并减少冗余，从而提高情绪识别的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的DeepMSI-MER方法通过对比学习增强了跨模态特征融合，并利用视觉序列压缩减少了视觉模式中的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;在IEMOCAP和MELD两个公开数据集上的实验结果表明，DeepMSI-MER显著提高了情感识别的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的多模态特征融合方法及其具体实现验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;随着人工智能和计算机视觉技术的发展，多模式情绪识别已成为一个重要研究领域。然而，现有的方法在异构数据融合以及充分利用不同模式之间的相关性方面面临挑战。本文提出了一种新的基于对比学习和视觉序列压缩的多模态情感识别方法DeepMSI-MER。该方法通过对比学习改进跨模式特征融合，并利用视觉序列压缩减少视觉模式中的冗余。实验结果表明，在两个公开数据集上，即IEMOCAP和MELD，DeepMSI-MER显著提高了情绪识别的准确性和鲁棒性，验证了多模态特征融合的有效性和所提出方法的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of artificial intelligence and computer visiontechnologies, multimodal emotion recognition has become a prominent researchtopic. However, existing methods face challenges such as heterogeneous datafusion and the effective utilization of modality correlations. This paperproposes a novel multimodal emotion recognition approach, DeepMSI-MER, based onthe integration of contrastive learning and visual sequence compression. Theproposed method enhances cross-modal feature fusion through contrastivelearning and reduces redundancy in the visual modality by leveraging visualsequence compression. Experimental results on two public datasets, IEMOCAP andMELD, demonstrate that DeepMSI-MER significantly improves the accuracy androbustness of emotion recognition, validating the effectiveness of multimodalfeature fusion and the proposed approach.</description>
      <author>example@mail.com (Wei Dai, Dequan Zheng, Feng Yu, Yanrong Zhang, Yaohui Hou)</author>
      <guid isPermaLink="false">2502.08573v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions</title>
      <link>http://arxiv.org/abs/2502.08438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at AAAI 2024, 9 pages. Project Website:  https://vl2g.github.io/projects/cstbir&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;非母语使用者由于词汇量有限，经常难以命名特定对象，尽管他们能够想象这些对象。例如，在澳大利亚以外地区寻找袋食蚁兽的人可能会遇到这种问题。此外，用户可能希望搜索那些难以草图绘制但容易用语言描述的对象或场景交互的情况。在这样常见却复杂的环境中，用户需要一个支持复合多模态查询的搜索界面，该界面可以接受难以命名但易于手绘对象的手绘草图和描述难以描绘但是能口头表达出来的对象属性或者与场景互动的文字信息。这种新的问题陈述明显区别于之前研究较多的基于文本（TBIR）和基于草图（SBIR）的图像检索问题。&lt;h4&gt;背景&lt;/h4&gt;非母语使用者或在搜索难以命名但容易想象的对象时，尤其是那些难以通过草图描绘但是可以用语言描述互动的复杂场景。现有技术如基于文本或者基于草图的方法无法很好地满足这些需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种全新的复合多模态查询方法，并为此创建了一个包含约200万个查询和10.8万张自然场景图像的数据集，以研究如何使用手绘草图和文字描述相结合的方式来进行更加有效的图像检索。&lt;h4&gt;方法&lt;/h4&gt;首先建立了CSTBIR（复合素描+文本基础的图像检索）数据集。然后开发了一个基于预训练多模态变换器模型的基线系统——STNET（素描+文本网络），该模型使用手绘草图来定位自然场景中的相关对象，并且编码文本和图像进行图像检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的复合查询方法在仅基于文本、仅基于草图以及复合模式查询方面均优于现有的最佳图像检索技术。此外，我们还提出了多种训练目标以进一步提高模型性能。&lt;h4&gt;结论&lt;/h4&gt;这项研究不仅为非母语使用者提供了一种有效的图像搜索方式，同时也展示了如何利用复合多模态信息进行更准确的图像检索。所使用的数据集和代码将公开发布于项目官方网站上供研究人员参考使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-native speakers with limited vocabulary often struggle to name specificobjects despite being able to visualize them, e.g., people outside Australiasearching for numbats. Further, users may want to search for such elusiveobjects with difficult-to-sketch interactions, e.g., numbat digging in theground. In such common but complex situations, users desire a search interfacethat accepts composite multimodal queries comprising hand-drawn sketches ofdifficult-to-name but easy-to-draw objects and text describingdifficult-to-sketch but easy-to-verbalize object attributes or interaction withthe scene. This novel problem statement distinctly differs from the previouslywell-researched TBIR (text-based image retrieval) and SBIR (sketch-based imageretrieval) problems. To study this under-explored task, we curate a dataset,CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2Mqueries and 108K natural scene images. Further, as a solution to this problem,we propose a pretrained multimodal transformer-based baseline, STNET(Sketch+Text Network), that uses a hand-drawn sketch to localize relevantobjects in the natural scene image, and encodes the text and image to performimage retrieval. In addition to contrastive learning, we propose multipletraining objectives that improve the performance of our model. Extensiveexperiments show that our proposed method outperforms several state-of-the-artretrieval methods for text-only, sketch-only, and composite query modalities.We make the dataset and code available at our project website.</description>
      <author>example@mail.com (Prajwal Gatti, Kshitij Parikh, Dhriti Prasanna Paul, Manish Gupta, Anand Mishra)</author>
      <guid isPermaLink="false">2502.08438v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Closer through commonality: Enhancing hypergraph contrastive learning with shared groups</title>
      <link>http://arxiv.org/abs/2502.08432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11page, 5 figures, 6 tables, 2024 IEEE International Conference on  Big Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Hypergraph Fine-grained对比学习（HyFi）方法，利用超图中的复杂高维信息进行对比学习。&lt;h4&gt;背景&lt;/h4&gt;传统同质化图表在表示现实世界中复杂的多维度关系时存在局限性。而基于超图的对比学习研究较少，现有图谱对比学习方法未能充分利用超图中的高级关联信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于超图的对比学习方法HyFi，以克服现有方法的问题，并提高节点分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;通过向节点特征添加噪声来实现简单高效的增广函数，同时避免了破坏超图表结构的传统图谱增强方法。引入弱正样本的概念，超越传统的正负样本二元关系。&lt;h4&gt;主要发现&lt;/h4&gt;HyFi能够产生高质量的嵌入，并在10个数据集上的节点分类任务中优于监督和非监督基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法有效利用了高维超图信息，在对比学习方面显著改善了现有基于图的方法的表现，同时具有较高的训练效率和较低的GPU内存开销。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已被准确地用中文进行了总结，并转化为易于理解的JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypergraphs provide a superior modeling framework for representing complexmultidimensional relationships in the context of real-world interactions thatoften occur in groups, overcoming the limitations of traditional homogeneousgraphs. However, there have been few studies on hypergraphbased contrastivelearning, and existing graph-based contrastive learning methods have not beenable to fully exploit the highorder correlation information in hypergraphs.Here, we propose a Hypergraph Fine-grained contrastive learning (HyFi) methoddesigned to exploit the complex high-dimensional information inherent inhypergraphs. While avoiding traditional graph augmentation methods that corruptthe hypergraph topology, the proposed method provides a simple and efficientlearning augmentation function by adding noise to node features. Furthermore,we expands beyond the traditional dichotomous relationship between positive andnegative samples in contrastive learning by introducing a new relationship ofweak positives. It demonstrates the importance of fine-graining positivesamples in contrastive learning. Therefore, HyFi is able to produce highqualityembeddings, and outperforms both supervised and unsupervised baselines inaverage rank on node classification across 10 datasets. Our approacheffectively exploits high-dimensional hypergraph information, shows significantimprovement over existing graph-based contrastive learning methods, and isefficient in terms of training speed and GPU memory cost. The source code isavailable at https://github.com/Noverse0/HyFi.git.</description>
      <author>example@mail.com (Daeyoung Roh, Donghee Han, Daehee Kim, Keejun Han, Mun Yi)</author>
      <guid isPermaLink="false">2502.08432v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Fully-Geometric Cross-Attention for Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2502.08285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer架构的新型交叉注意机制，旨在解决点云配准在低重叠情况下由于噪声导致的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云注册方法在点云重叠较低的情况下往往失败，因为这种情况下会出现大量的噪声点对应关系。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的跨注意力机制来克服传统方法的局限性，并提高点云配准的效果和精度。&lt;h4&gt;方法&lt;/h4&gt;{'1': '提出了一种融合了坐标与特征信息的新交叉注意机制，该机制在超点级别上工作，将不同点云之间的几何结构考虑进去。', '2': '引入Gromov-Wasserstein距离到跨注意力机制中以计算不同点云之间点的距离，并考虑到它们的几何结构。', '3': '提出了一种自我注意机制，在点级别上聚合局部几何信息至点特征，以便于精细匹配。'}&lt;h4&gt;主要发现&lt;/h4&gt;新的交叉注意机制能够保证旋转和平移不变性，使来自两个不同点云中的点在任意刚体变换下仍可相互响应。&lt;h4&gt;结论&lt;/h4&gt;通过引入新方法，文中所提模型可以增加内点对应关系的数量，从而比现有最佳的方法获得更精确的配准结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法已经在3DMatch、3DLoMatch、KITTI和3DCSR数据集上进行了广泛的评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration approaches often fail when the overlap between pointclouds is low due to noisy point correspondences. This work introduces a novelcross-attention mechanism tailored for Transformer-based architectures thattackles this problem, by fusing information from coordinates and features atthe super-point level between point clouds. This formulation has remainedunexplored primarily because it must guarantee rotation and translationinvariance since point clouds reside in different and independent referenceframes. We integrate the Gromov-Wasserstein distance into the cross-attentionformulation to jointly compute distances between points across different pointclouds and account for their geometric structure. By doing so, points from twodistinct point clouds can attend to each other under arbitrary rigidtransformations. At the point level, we also devise a self-attention mechanismthat aggregates the local geometric structure information into point featuresfor fine matching. Our formulation boosts the number of inlier correspondences,thereby yielding more precise registration results compared to state-of-the-artapproaches. We have conducted an extensive evaluation on 3DMatch, 3DLoMatch,KITTI, and 3DCSR datasets.</description>
      <author>example@mail.com (Weijie Wang, Guofeng Mei, Jian Zhang, Nicu Sebe, Bruno Lepri, Fabio Poiesi)</author>
      <guid isPermaLink="false">2502.08285v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Class Discovery in Instance Segmentation</title>
      <link>http://arxiv.org/abs/2502.08149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个用于实例分割中的广义类别的发现任务的方法，该方法旨在通过已知数据和未知数据来识别新的类别并实现对所有已知和新类别的实例进行分割。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，物体种类繁多且分布呈长尾状，每个类别的实例数量不平衡。&lt;h4&gt;目的&lt;/h4&gt;解决由于实例分布不平衡导致的广义类别发现的问题，并提出解决方案来改善这一状况。&lt;h4&gt;方法&lt;/h4&gt;{'instance-wise temperature assignment (ITA) 方法': '通过为来自头类别的样本放松实例区分来提高GCD的表现，从而应对长尾分布。', 'class-wise reliability criteria': '在使用从GCD获得的伪标签训练实例分割网络时避免忽略长尾类别大部分伪标签的标准。', '动态调整标准': '根据训练阶段的不同灵活地利用多样化或可靠样本的方法。', '软注意力模块': '一种高效的编码对象特定表示以支持广义类别的发现的方法'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的ITAT方法在COCO半 + LVIS和LVIS + Visual Genome两个设定上表现优于先前的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入有效的实例级温度分配、类别级可靠性标准以及动态调整伪标签使用策略，该工作为解决实例分割中的长尾分布问题提供了新的解决方案，并且实验结果显示其性能优越。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the task of generalized class discovery (GCD) in instancesegmentation. The goal is to discover novel classes and obtain a model capableof segmenting instances of both known and novel categories, given labeled andunlabeled data. Since the real world contains numerous objects with long-taileddistributions, the instance distribution for each class is inherentlyimbalanced. To address the imbalanced distributions, we propose aninstance-wise temperature assignment (ITA) method for contrastive learning andclass-wise reliability criteria for pseudo-labels. The ITA method relaxesinstance discrimination for samples belonging to head classes to enhance GCD.The reliability criteria are to avoid excluding most pseudo-labels for tailclasses when training an instance segmentation network using pseudo-labels fromGCD. Additionally, we propose dynamically adjusting the criteria to leveragediverse samples in the early stages while relying only on reliablepseudo-labels in the later stages. We also introduce an efficient softattention module to encode object-specific representations for GCD. Finally, weevaluate our proposed method by conducting experiments on two settings:COCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental resultsdemonstrate that the proposed method outperforms previous state-of-the-artmethods.</description>
      <author>example@mail.com (Cuong Manh Hoang, Yeejin Lee, Byeongkeun Kang)</author>
      <guid isPermaLink="false">2502.08149v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Checkerboard Target Measurement in Unordered Point Clouds with Coloured ICP</title>
      <link>http://arxiv.org/abs/2502.08525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究探讨了在3D点云中测量中心棋盘格目标的问题。这个问题在注册、长期监测以及与其他传感器系统关联方面有着重要的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于彩色ICP算法的三维模板匹配方法来解决这一问题，并且能够在处理无结构的3D数据的情况下工作，以适应新的低成本激光雷达传感器产生的未排序点云数据。&lt;h4&gt;方法&lt;/h4&gt;采用了一种基于彩色ICP算法的三维模板匹配方法。该方法特别适用于处理没有结构约束的3D数据（即无序点云）的情况，并且能够处理新型低成本LIDAR传感器生成的数据，这类传感器在距离和反射率测量中增加了噪声。&lt;h4&gt;主要发现&lt;/h4&gt;提供了使用合成数据进行广泛仿真结果的研究成果，以展示这种方法的应用潜力。此外还详细描述了处理实际传感器数据的具体步骤。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种解决3D点云中心棋盘格目标测量问题的有效方法，并且能够适应新型低成本LIDAR传感器的数据特性。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们研究了在三维点云中度量中心棋盘格目标的问题。这是一个重要的问题，在注册、长期监测及与其他传感系统关联中有应用。我们利用了一种基于彩色ICP算法的3D模板匹配方法来解决问题，并且我们在处理无结构的3D数据（即未排序点云）的情况下解决了这个问题，这使我们能够处理新一代低成本LIDAR传感器生成的数据。这类传感器在范围和反射率测量中也增加了噪声。我们使用合成数据进行了广泛的仿真结果研究以捕捉这种方法的应用潜力。然后给出了处理真实传感器数据的具体步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we investigate the problem of measuring a the centrecheckerboard target in an 3D point cloud. This is an important problem whichhas applications in registration, long term monitoring and linking to othersensor systems. We use a 3D template matching approach based on the colouredICP algorithm to solve the problem. We tackle the problem under the additionalconstraints that we assume no structure in the 3D data in order to be able tohandle unordered point clouds. This gives us the capability to process datafrom the new generation of low-cost LIDAR sensors. This category of sensorsalso suffers from increased noise in range and reflectivity measurement. Weprovide extensive simulation results using synthetic data to capture thepotential of the approach. We then give the detailed steps for handling realsensor data.</description>
      <author>example@mail.com (June Moh Goo, Jialun Li, Darmawan Wicaksono, Jan Boehm)</author>
      <guid isPermaLink="false">2502.08525v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?</title>
      <link>http://arxiv.org/abs/2502.08503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文指出了在3D大型语言模型评估中存在的一种称为'2D-Cheating'的问题，并提出了评估3D理解能力的新原则。&lt;h4&gt;背景&lt;/h4&gt;当前的3D LLM评估任务可能存在被视觉语言模型利用通过渲染点云图像轻易解决的情况，从而无法有效评价3D LLM的独特三维能力。&lt;h4&gt;目的&lt;/h4&gt;测试不同视觉语言模型在多个3D LLM基准上的表现，并提出更有效的评估原则以准确衡量真正的3D理解能力。&lt;h4&gt;方法&lt;/h4&gt;比较VLM在多个人工智能基准测试中的性能，以此作为参考。&lt;h4&gt;主要发现&lt;/h4&gt;提出了用于更好评估真实三维理解的指导原则，并建议在评估3D LLM时明确区分其三维能力与其他维度的能力。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以更准确地评价3D大型语言模型的实际三维理解水平。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们识别出3D LLM评估中的“2D-Cheating”问题，并提出改进评估原则以确保能够有效评测3D LLM的真正三维能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we identify the "2D-Cheating" problem in 3D LLM evaluation,where these tasks might be easily solved by VLMs with rendered images of pointclouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. Wetest VLM performance across multiple 3D LLM benchmarks and, using this as areference, propose principles for better assessing genuine 3D understanding. Wealso advocate explicitly separating 3D abilities from 1D or 2D aspects whenevaluating 3D LLMs.</description>
      <author>example@mail.com (Jiahe Jin, Yanheng He, Mingyan Yang)</author>
      <guid isPermaLink="false">2502.08503v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World</title>
      <link>http://arxiv.org/abs/2502.08449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CordViP框架，利用物体的6D姿态估计和机器人本体感觉来建立交互感知点云之间的对应关系。该方法在四个现实世界的任务中表现出卓越的操作能力。&lt;h4&gt;背景&lt;/h4&gt;实现类人级别的灵巧性是机械臂操作领域的关键目标。近年来基于3D模仿学习的进步取得了显著成果，但高质量的3D表示受到摄像机分辨率、位置和遮挡的影响，以及缺乏接触信息和空间对应关系。&lt;h4&gt;目的&lt;/h4&gt;提出CordViP框架以克服现有技术中的限制，并提高机械臂的操作能力。&lt;h4&gt;方法&lt;/h4&gt;通过利用物体6D姿态估计和机器人本体感觉，建立交互感知点云之间的对应关系。使用这些点云进行预训练策略，其中还包括对象中心接触图和手-臂协调信息。&lt;h4&gt;主要发现&lt;/h4&gt;CordViP在四个现实世界的任务中表现出平均90%的成功率，并且比其他基准方法有更好的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该框架通过有效利用物体的6D姿态估计和机器人本体感觉，提供了一种新的途径来提高机械臂的操作性能。&lt;h4&gt;翻译&lt;/h4&gt;实现人类级别的灵巧性是机器人操作领域的一个关键目标。最近基于3D模仿学习的进步已显示出有希望的结果，为达成这一目标提供了有效的路径。然而，获取高质量的3D表示存在两个主要问题：（1）单视图摄像机捕获的点云质量显著受到相机分辨率、定位和灵巧手引起的遮挡的影响；（2）全局点云缺乏必要的接触信息和空间对应关系以执行精细操作任务。为消除这些限制，我们提出了CordViP框架，利用物体的6D姿态估计和机器人本体感觉来建立交互感知点云之间的对应关系。该方法在四个现实世界任务中展示了卓越的操作能力，并且其泛化能力和鲁棒性都比其他基准表现优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving human-level dexterity in robots is a key objective in the field ofrobotic manipulation. Recent advancements in 3D-based imitation learning haveshown promising results, providing an effective pathway to achieve this goal.However, obtaining high-quality 3D representations presents two key problems:(1) the quality of point clouds captured by a single-view camera issignificantly affected by factors such as camera resolution, positioning, andocclusions caused by the dexterous hand; (2) the global point clouds lackcrucial contact information and spatial correspondences, which are necessaryfor fine-grained dexterous manipulation tasks. To eliminate these limitations,we propose CordViP, a novel framework that constructs and learnscorrespondences by leveraging the robust 6D pose estimation of objects androbot proprioception. Specifically, we first introduce the interaction-awarepoint clouds, which establish correspondences between the object and the hand.These point clouds are then used for our pre-training policy, where we alsoincorporate object-centric contact maps and hand-arm coordination information,effectively capturing both spatial and temporal dynamics. Our methoddemonstrates exceptional dexterous manipulation capabilities with an averagesuccess rate of 90\% in four real-world tasks, surpassing other baselines by alarge margin. Experimental results also highlight the superior generalizationand robustness of CordViP to different objects, viewpoints, and scenarios. Codeand videos are available on https://aureleopku.github.io/CordViP.</description>
      <author>example@mail.com (Yankai Fu, Qiuxuan Feng, Ning Chen, Zichen Zhou, Mengzhen Liu, Mingdong Wu, Tianxing Chen, Shanyu Rong, Jiaming Liu, Hao Dong, Shanghang Zhang)</author>
      <guid isPermaLink="false">2502.08449v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Data Curation for Visual Contrastive Learning: Why Crafting Effective Positive and Negative Pairs Matters</title>
      <link>http://arxiv.org/abs/2502.08134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉对比学习通过对比相同（正样本）和不相似（负样本）的数据对来学习表示。这些数据对的设计极大地影响了表示质量、训练效率以及计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了优化对比预训练的效果，特别是在解决下游任务时，数据整理变得至关重要。这项调查尝试为现有对比学习中用于正样本与负样本配对的方法建立分类学。&lt;h4&gt;方法&lt;/h4&gt;详细描述了现有的技术手段来管理和筛选这些正负样例的策略和模型。&lt;h4&gt;主要发现&lt;/h4&gt;良好的正负样例选择能够提升表示的质量，加速收敛速度。&lt;h4&gt;结论&lt;/h4&gt;通过分析对比学习中的不同数据整理技术，为未来研究提供了理论基础，并指出其对于实际应用的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual contrastive learning aims to learn representations by contrastingsimilar (positive) and dissimilar (negative) pairs of data samples. The designof these pairs significantly impacts representation quality, trainingefficiency, and computational cost. A well-curated set of pairs leads tostronger representations and faster convergence. As contrastive pre-trainingsees wider adoption for solving downstream tasks, data curation becomesessential for optimizing its effectiveness. In this survey, we attempt tocreate a taxonomy of existing techniques for positive and negative paircuration in contrastive learning, and describe them in detail.</description>
      <author>example@mail.com (Shasvat Desai, Debasmita Ghose, Deep Chakraborty)</author>
      <guid isPermaLink="false">2502.08134v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data</title>
      <link>http://arxiv.org/abs/2502.08547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一种名为GAME的算法，用于处理不同医疗机构之间的电子健康记录（EHR）数据异质性问题。&lt;h4&gt;背景&lt;/h4&gt;随着EHR系统的采用，基于数据驱动的临床护理和研究机会增加。然而，多机构间进行有效的EHR研究存在数据异质性和隐私保护方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;解决上述挑战，提供一种能够处理不同机构之间代码差异的方法，并同时保持患者数据的隐私性。&lt;h4&gt;方法&lt;/h4&gt;GAME算法通过在知识图谱中建立编码之间的关系以及利用语言模型确定特定于每个机构的代码与标准化代码的关系来工作。此外，使用图注意力网络量化代码间关系强度并采用转移和联邦学习技术创建联合训练嵌入以保护数据隐私。&lt;h4&gt;主要发现&lt;/h4&gt;该方法已经在7个不同医疗机构进行了测试和验证，并展示了其在各种疾病条件下的应用效果，如心力衰竭、类风湿性关节炎等。另外，在不共享患者级别数据的情况下，在精神健康障碍患者的阿尔茨海默病预后和自杀风险研究中也显示了它的有效性。&lt;h4&gt;结论&lt;/h4&gt;GAME算法能够有效整合多机构EHR数据，并在不同条件下为AI驱动的算法选择相关特征输入，同时保持严格的隐私保护标准。&lt;h4&gt;翻译&lt;/h4&gt;EHR系统的广泛采用为基于数据驱动的临床护理和研究提供了机会。然而，在多个医疗机构之间进行有效的EHR研究存在很大的障碍——即系统之间的数据异质性问题以及由于需要保护患者隐私而导致多机构间共享患者级别数据难度大。为了应对这些挑战，我们开发了GAME算法，该算法已经在7个不同机构进行了测试并验证其有效性，并且可以支持两种语言的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The adoption of EHRs has expanded opportunities to leverage data-drivenalgorithms in clinical care and research. A major bottleneck in effectivelyconducting multi-institutional EHR studies is the data heterogeneity acrosssystems with numerous codes that either do not exist or represent differentclinical concepts across institutions. The need for data privacy further limitsthe feasibility of including multi-institutional patient-level data required tostudy similarities and differences across patient subgroups. To address thesechallenges, we developed the GAME algorithm. Tested and validated across 7institutions and 2 languages, GAME integrates data in several levels: (1) atthe institutional level with knowledge graphs to establish relationshipsbetween codes and existing knowledge sources, providing the medical context forstandard codes and their relationship to each other; (2) between institutions,leveraging language models to determine the relationships betweeninstitution-specific codes with established standard codes; and (3) quantifyingthe strength of the relationships between codes using a graph attentionnetwork. Jointly trained embeddings are created using transfer and federatedlearning to preserve data privacy. In this study, we demonstrate theapplicability of GAME in selecting relevant features as inputs for AI-drivenalgorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.We then highlight the application of GAME harmonized multi-institutional EHRdata in a study of Alzheimer's disease outcomes and suicide risk among patientswith mental health disorders, without sharing patient-level data outsideindividual institutions.</description>
      <author>example@mail.com (Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai)</author>
      <guid isPermaLink="false">2502.08547v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Multifidelity Simulation-based Inference for Computationally Expensive Simulators</title>
      <link>http://arxiv.org/abs/2502.08416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MF-NPE是一种多保真度的神经后验估计方法，利用低成本低精度仿真来推断高保真仿真的参数。&lt;h4&gt;背景&lt;/h4&gt;在科学研究中，随机模型是理解经验数据背后的机制的重要工具。然而，通过基于模拟的推理来推断高保真模型的参数是一个挑战，尤其是当模拟器计算成本高昂时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MF-NPE，可以在有限的仿真预算内利用低精度仿真有效地推断高保真仿真的参数。&lt;h4&gt;方法&lt;/h4&gt;MF-NPE通过迁移学习，在资源受限的情况下执行神经后验估计，并能使用主动学习来优先考虑个别观察结果。&lt;h4&gt;主要发现&lt;/h4&gt;在一项统计任务和两项实际应用中，MF-NPE展示了与当前方法相当的性能，但需要的高保真模拟次数减少了两个数量级。&lt;h4&gt;结论&lt;/h4&gt;总体而言，MF-NPE为在计算成本高的模拟器上进行高效的贝叶斯推理提供了新的机会。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨科学领域的多个领域，随机模型是理解经验观察数据背后机制的重要工具。这些模型可以有不同的细节和准确性水平，高保真度（即高度准确）的模型通常更受欢迎。然而，通过基于模拟的推断来推断高保真模型参数具有挑战性，尤其是在仿真器计算成本高昂的情况下。我们介绍了MF-NPE，这是一种多保真神经后验估计方法，利用低成本低精度仿真在有限的仿真预算内推断高精度仿真的参数。通过迁移学习，MF-NPE能够在资源受限的情况下执行神经后验估计，并能使用主动学习来优先考虑个别观察结果。在一个具有解析真实值的统计任务和两个现实世界任务上，MF-NPE展示了与当前方法相当的表现，但需要的高保真模拟次数减少了两个数量级。总体而言，MF-NPE为在计算成本高的仿真器上进行高效的贝叶斯推理提供了新的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Across many domains of science, stochastic models are an essential tool tounderstand the mechanisms underlying empirically observed data. Models can beof different levels of detail and accuracy, with models of high-fidelity (i.e.,high accuracy) to the phenomena under study being often preferable. However,inferring parameters of high-fidelity models via simulation-based inference ischallenging, especially when the simulator is computationally expensive. Weintroduce MF-NPE, a multifidelity approach to neural posterior estimation thatleverages inexpensive low-fidelity simulations to infer parameters ofhigh-fidelity simulators within a limited simulation budget. MF-NPE performsneural posterior estimation with limited high-fidelity resources by virtue oftransfer learning, with the ability to prioritize individual observations usingactive learning. On one statistical task with analytical ground-truth and tworeal-world tasks, MF-NPE shows comparable performance to current approacheswhile requiring up to two orders of magnitude fewer high-fidelity simulations.Overall, MF-NPE opens new opportunities to perform efficient Bayesian inferenceon computationally expensive simulators.</description>
      <author>example@mail.com (Anastasia N. Krouglova, Hayden R. Johnson, Basile Confavreux, Michael Deistler, Pedro J. Gonçalves)</author>
      <guid isPermaLink="false">2502.08416v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping</title>
      <link>http://arxiv.org/abs/2502.08054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种解决机器人在受环境约束（如表面碰撞）情况下抓取物体的挑战的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人操作方法难以处理非预设或人体常用的双手动策略。最先进的强化学习方法由于任务复杂性而不适用，而基于演示的学习需要收集大量专家演示数据，这往往是不可行的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法来解决受遮挡下的机器人抓取问题，特别是在环境约束导致所需抓取姿态在运动学上无法实现的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了COMBO-Grasp（基于限制的手动双臂抓取），这是一种学习型方法，利用了两个协调策略：一个是通过自我监督数据集训练的限制策略，用于生成稳定姿势；另一个是通过强化学习训练的抓取策略，重新定向和抓取目标物体。关键贡献在于价值函数引导的策略协调。&lt;h4&gt;主要发现&lt;/h4&gt;COMBO-Grasp显著提高了任务成功率，并且在模拟环境和现实环境中都可以成功应用于未见过的对象。&lt;h4&gt;结论&lt;/h4&gt;提出的COMBO-Grasp方法通过改进双臂机器人操作中的协调性和任务性能，展示了其相较于竞争基准方法的优势。该方法还采用了教师-学生策略蒸馏技术以有效部署基于点云的策略到实际环境中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文解决的是遮挡下的机器人抓取问题，即在环境约束（如表面碰撞）导致所需抓取姿态在运动学上无法实现的情况下进行抓取。传统的方法难以应对这种复杂的任务，而最新的强化学习方法由于任务复杂性而不适用；基于演示的学习则需要收集大量的专家示教数据，这往往是不可行的。本文提出了一种双臂机器人操作策略COMBO-Grasp，该策略通过两个协调的政策（限制策略和抓取策略）来解决这一挑战，并且该方法利用价值函数引导策略协调，提高任务性能并成功部署到现实环境中。实验表明，与竞争基线相比，COMBO-Grasp显著提高了任务成功率，并能在模拟环境和真实环境中对未见过的对象进行有效操作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of occluded robot grasping, i.e. graspingin situations where the desired grasp poses are kinematically infeasible due toenvironmental constraints such as surface collisions. Traditional robotmanipulation approaches struggle with the complexity of non-prehensile orbimanual strategies commonly used by humans in these circumstances.State-of-the-art reinforcement learning (RL) methods are unsuitable due to theinherent complexity of the task. In contrast, learning from demonstrationrequires collecting a significant number of expert demonstrations, which isoften infeasible. Instead, inspired by human bimanual manipulation strategies,where two hands coordinate to stabilise and reorient objects, we focus on abimanual robotic setup to tackle this challenge. In particular, we introduceConstraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), alearning-based approach which leverages two coordinated policies: a constraintpolicy trained using self-supervised datasets to generate stabilising poses anda grasping policy trained using RL that reorients and grasps the target object.A key contribution lies in value function-guided policy coordination.Specifically, during RL training for the grasping policy, the constraintpolicy's output is refined through gradients from a jointly trained valuefunction, improving bimanual coordination and task performance. Lastly,COMBO-Grasp employs teacher-student policy distillation to effectively deploypoint cloud-based policies in real-world environments. Empirical evaluationsdemonstrate that COMBO-Grasp significantly improves task success rates comparedto competitive baseline approaches, with successful generalisation to unseenobjects in both simulated and real-world environments.</description>
      <author>example@mail.com (Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner)</author>
      <guid isPermaLink="false">2502.08054v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation</title>
      <link>http://arxiv.org/abs/2502.08642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://swiftsketch.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;近年来，大型视觉-语言模型在向量草图生成方面取得了显著进展。然而，这些最先进的方法需要通过预训练模型反复反馈来确定笔画位置，从而导致耗时的优化过程。&lt;h4&gt;背景&lt;/h4&gt;现有的最佳方法尽管能产生令人印象深刻的草图，但由于其长时间的优化过程，在实际应用中受到限制。&lt;h4&gt;目的&lt;/h4&gt;介绍SwiftSketch，这是一种基于图像条件生成向量草图的扩散模型，能够在不到一秒的时间内生成高质量草图。&lt;h4&gt;方法&lt;/h4&gt;SwiftSketch通过逐步清除从高斯分布采样的笔画控制点噪声来工作。其变压器解码器架构被设计为有效地处理矢量表示的离散性质，并捕捉笔画之间的固有全局依赖关系。为了训练SwiftSketch，构建了一个合成图像-草图配对数据集。&lt;h4&gt;主要发现&lt;/h4&gt;提出的ControlSketch方法通过引入深度感知ControlNet来增强SDS技术，从而在生成这些合成草图时能够进行精确的空间控制。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明SwiftSketch能够在多种概念上泛化，并能高效地产生结合高保真度和自然、视觉吸引力的风格的草图。&lt;h4&gt;翻译&lt;/h4&gt;最近，在大型视觉-语言模型方面的发展已经使高度表达且多样的向量草图生成成为可能。然而，最先进的方法依赖于耗时的优化过程，涉及预训练模型的重复反馈来确定笔画位置。因此，尽管这些方法能产生令人印象深刻的草图，但在实际应用中受到限制。本工作介绍了SwiftSketch，这是一种基于图像条件的向量草图扩散生成模型，能够在不到一秒钟的时间内生产高质量草图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large vision-language models have enabled highlyexpressive and diverse vector sketch generation. However, state-of-the-artmethods rely on a time-consuming optimization process involving repeatedfeedback from a pretrained model to determine stroke placement. Consequently,despite producing impressive sketches, these methods are limited in practicalapplications. In this work, we introduce SwiftSketch, a diffusion model forimage-conditioned vector sketch generation that can produce high-qualitysketches in less than a second. SwiftSketch operates by progressively denoisingstroke control points sampled from a Gaussian distribution. Itstransformer-decoder architecture is designed to effectively handle the discretenature of vector representation and capture the inherent global dependenciesbetween strokes. To train SwiftSketch, we construct a synthetic dataset ofimage-sketch pairs, addressing the limitations of existing sketch datasets,which are often created by non-artists and lack professional quality. Forgenerating these synthetic sketches, we introduce ControlSketch, a method thatenhances SDS-based techniques by incorporating precise spatial control througha depth-aware ControlNet. We demonstrate that SwiftSketch generalizes acrossdiverse concepts, efficiently producing sketches that combine high fidelitywith a natural and visually appealing style.</description>
      <author>example@mail.com (Ellie Arar, Yarden Frenkel, Daniel Cohen-Or, Ariel Shamir, Yael Vinker)</author>
      <guid isPermaLink="false">2502.08642v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar</title>
      <link>http://arxiv.org/abs/2502.06114v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Arxiv preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个新颖的知识蒸馏框架，用于处理4D雷达点云的稀疏性问题，并通过在潜在空间中模仿多个教师模型来使学生模型能够稠密化其输入。&lt;h4&gt;背景&lt;/h4&gt;准确的3D物体检测对于自动驾驶的安全导航至关重要。然而，在恶劣天气条件下，LiDAR性能会下降，而雷达系统保持可靠性能。传统的雷达由于缺乏高度数据存在局限性，但新的4D雷达通过测量范围、方位角和多普勒速度来克服这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达稠密张量解决点云稀疏性的方法，并提高自动驾驶车辆在各种天气条件下的检测性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个知识蒸馏框架，使学生模型能够模仿多个教师模型的行为，在潜在空间中使输入点云变得稠密。该框架主要依赖于4D雷达的密集雷达张量，利用其包含的空间和多普勒维度上的功率测量数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与目前最先进的RTNH模型相比，所提出的模型在K-Radar数据集上性能提高了25%，同时保持了实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;通过引入知识蒸馏框架，该研究为如何利用4D雷达的密集张量来克服其点云稀疏性问题提供了一种有效的方法。这种方法可以进一步提高自动驾驶汽车的安全性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;准确的三维物体检测对于安全自主导航至关重要，在各种天气条件下都需要可靠的性能表现。虽然激光雷达在恶劣天气条件下的性能会下降，但雷达系统能够保持可靠的表现。传统的雷达由于缺乏高度数据而存在局限性，但是新的4D雷达通过测量范围、方位角和多普勒速度来解决这一问题，从而成为自动驾驶汽车中的宝贵工具。然而，在使用4D雷达时的主要挑战是其点云的稀疏性。先前的研究主要依赖于开发能更好地捕捉稀疏点云语义和上下文信息的架构，并且大多数借鉴了基于激光雷达的方法。但是这些方法往往忽略了4D雷达的一个独特优势：密集的雷达张量，该张量包含了三个空间维度以及多普勒维度上的功率测量数据。我们的论文利用这种张量来解决稀疏性问题。我们提出了一种新颖的知识蒸馏框架，使学生模型能够在潜在空间中模仿多个教师模型的行为从而稠密化其输入点云。&lt;h4&gt;性能提升&lt;/h4&gt;在K-Radar数据集上，与当前最先进的RTNH模型相比，论文所提方法的性能提高了25%，并且仍保持了实时推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D object detection is crucial for safe autonomous navigation,requiring reliable performance across diverse weather conditions. While LiDARperformance deteriorates in challenging weather, Radar systems maintain theirreliability. Traditional Radars have limitations due to their lack of elevationdata, but the recent 4D Radars overcome this by measuring elevation alongsiderange, azimuth, and Doppler velocity, making them invaluable for autonomousvehicles. The primary challenge in utilizing 4D Radars is the sparsity of theirpoint clouds. Previous works address this by developing architectures thatbetter capture semantics and context in sparse point cloud, largely drawingfrom LiDAR-based approaches. However, these methods often overlook a uniqueadvantage of 4D Radars: the dense Radar tensor, which encapsulates powermeasurements across three spatial dimensions and the Doppler dimension. Ourpaper leverages this tensor to tackle the sparsity issue. We introduce a novelknowledge distillation framework that enables a student model to densify itssparse input in the latent space by emulating an ensemble of teacher models.Our experiments demonstrate a 25% performance improvement over thestate-of-the-art RTNH model on the K-Radar dataset. Notably, this improvementis achieved while still maintaining a real-time inference speed.</description>
      <author>example@mail.com (Seung-Hyun Song, Dong-Hee Paek, Minh-Quan Dao, Ezio Malis, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.06114v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation</title>
      <link>http://arxiv.org/abs/2502.08505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Label-Propagation Tensor Graph Neural Network (LP-TGNN)框架，用于解决图神经网络在单一领域内训练导致的标签需求量大和表示能力较差的问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Networks（GNN）已经成为研究图数据的主要工具，并且在图形分类任务上表现出色。然而，它们主要是在监督学习中进行单域训练，这需要大量的标注数据并且产生的表示不能很好地迁移到其他领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来解决GNN的标签需求量大和表示能力较差的问题，使GNN能够在不同领域的图数据之间更好地迁移。&lt;h4&gt;方法&lt;/h4&gt;LP-TGNN通过张量架构提取图的整体拓扑信息，并通过标签传播减少域之间的差异。该框架可以与通用GNN和领域适应技术兼容并进行伪标签调整。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的LP-TGNN在各种现实世界基准测试中优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;通过消融研究验证了每个组件的有效性，并分析了它们的作用机制。&lt;h4&gt;翻译&lt;/h4&gt;最近，图神经网络（Graph Neural Networks, GNNs）已经成为处理图数据的主要工具。尽管在图分类任务上表现出色，但GNN主要是在单一领域内进行监督学习训练，因此需要大量的标注数据并且产生的表示不能很好地迁移到其他领域。为了解决这个问题，我们提出了Label-Propagation Tensor Graph Neural Network（LP-TGNN）框架来连接图数据与传统的域适应方法之间的差距。该框架使用张量架构整体提取图的拓扑信息，并通过标签传播减少不同领域的差异。此外，它能够轻松地与其他通用GNN和领域适应技术兼容并进行最小化调整以实现伪标记。在各种现实世界基准上的实验表明，我们的LP-TGNN显著优于基线方法。我们还通过对每个组件的消融研究验证了其有效性及分析作用机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently become the predominant tools forstudying graph data. Despite state-of-the-art performance on graphclassification tasks, GNNs are overwhelmingly trained in a single domain undersupervision, thus necessitating a prohibitively high demand for labels andresulting in poorly transferable representations. To address this challenge, wepropose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) frameworkto bridge the gap between graph data and traditional domain adaptation methods.It extracts graph topological information holistically with a tensorarchitecture and then reduces domain discrepancy through label propagation. Itis readily compatible with general GNNs and domain adaptation techniques withminimal adjustment through pseudo-labeling. Experiments on various real-worldbenchmarks show that our LP-TGNN outperforms baselines by a notable margin. Wealso validate and analyze each component of the proposed framework in theablation study.</description>
      <author>example@mail.com (Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei)</author>
      <guid isPermaLink="false">2502.08505v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model</title>
      <link>http://arxiv.org/abs/2502.08612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究提出了一种用于预测住院心脏骤停(IHCA)的两阶段模型Feature Extractor-Aggregator Network (FEAN)，仅使用单通道指尖光电容积描记(PPG)信号。该模型利用预训练的PPG基础模型与序列分类模型结合，展示了在重症监护病房(ICU)患者中只用连续PPG信号进行预测的心脏骤停结果。&lt;h4&gt;背景&lt;/h4&gt;非侵入性病人监测在跟踪和预测急性不良健康事件方面的研究是一个新兴领域。特别是心脏骤停(IHCA)的早期预警具有重大临床意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于单通道PPG信号的新方法，用于预测住院患者心脏骤停的发生，提高对心脏骤停风险的识别能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Feature Extractor-Aggregator Network (FEAN)，该模型使用预训练的大规模PPG基础模型（如PPG-GPT），结合序列分类器，以1小时或24小时历史数据为基础进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;在心脏骤停前24小时内平均获得0.79的AUROC值；在一小时前达到最高性能，为0.82。此外，通过架构调优和PaCMAP可视化技术提供了模型全面分析。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了利用单模态PPG信号进行心脏骤停预测的有效性，并且可能成为未来非侵入式监测系统的一部分。&lt;h4&gt;翻译&lt;/h4&gt;无创患者监控在跟踪和预测急性不良健康事件方面的研究正在成为一个新兴领域。我们使用单一通道的指尖光电容积描记(PPG)信号来探索住院心脏骤停(IHCA)的预测。所提出的两阶段模型Feature Extractor-Aggregator Network (FEAN)，结合了预训练的大规模PPG基础模型（如PPG-GPT）和序列分类器。我们提出了两种FEAN变体('1H', 'FH')，分别使用最新一小时和最多24小时的历史数据来做出决策。本研究首次展示了仅用连续单模态(PPG信号)波形的深度表示，在ICU患者中预测IHCA的结果。通过我们的最佳模型，在心脏骤停事件发生前24~h的时间窗口内获得0.79的平均AUROC值，其中在事件发生一小时前达到峰值性能为0.82。我们还通过架构调整和PaCMAP技术对患者的健康轨迹进行了潜空间可视化分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-invasive patient monitoring for tracking and predicting adverse acutehealth events is an emerging area of research. We pursue in-hospital cardiacarrest (IHCA) prediction using only single-channel finger photoplethysmography(PPG) signals. Our proposed two-stage model Feature Extractor-AggregatorNetwork (FEAN) leverages powerful representations from pre-trained PPGfoundation models (PPG-GPT of size up to 1 Billion) stacked with sequentialclassification models. We propose two FEAN variants ("1H", "FH") which use thelatest one-hour and (max) 24-hour history to make decisions respectively. Ourstudy is the first to present IHCA prediction results in ICU patients usingonly unimodal (continuous PPG signal) waveform deep representations. With ourbest model, we obtain an average of 0.79 AUROC over 24~h prediction windowbefore CA event onset with our model peaking performance at 0.82 one hourbefore CA. We also provide a comprehensive analysis of our model througharchitectural tuning and PaCMAP visualization of patient health trajectory inlatent space.</description>
      <author>example@mail.com (Saurabh Kataria, Ran Xiao, Timothy Ruchti, Matthew Clark, Jiaying Lu, Randall J. Lee, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.08612v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Keep your distance: learning dispersed embeddings on $\mathbb{S}_d$</title>
      <link>http://arxiv.org/abs/2502.08231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在高维空间中学习分离特征的重要性，并提出了一种新的角度来促进这种分离，即使用最大均值差异(MMD)重新解释成对分散。&lt;h4&gt;背景&lt;/h4&gt;在处理文本或图像嵌入等高维度数据时，有效的特征分离对于机器学习应用至关重要。通过限制特征在一个超球面上进行散布可以解决这一问题，并且已有理论和数值解法适用于低维情况，但这些方法难以直接应用于实际的表示学习任务。&lt;h4&gt;目的&lt;/h4&gt;探索新的分散方法以改进高维度空间中的表示学习以及提高不同领域的性能。&lt;h4&gt;方法&lt;/h4&gt;重新诠释成对散度使用最大均值差异(MMD)动机，并提出了一种在线K-Means算法变体作为通用域上的有效替代正则化器，此外还提出了直接利用超球面特性的新分散技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示了分散在图像分类和自然语言处理任务中的重要性以及不同算法的权衡表现。&lt;h4&gt;结论&lt;/h4&gt;新的散度方法能够有效地促进高维度特征分离，并提高了各种领域的机器学习性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中描述的学习良好分离的特征在处理文本或图片等高维数据时非常重要，这可以通过散布嵌入来实现。然而，在表示学习领域通常需要面对大规模和高维度的数据挑战，现有的理论和数值解决方案难以直接适用。因此，人们常常依赖于基于梯度的方法鼓励分散，并通过最小化某些成对距离函数来达成目标。本文首先介绍了现有方法并指出了它们之间的联系与相似性，然后提出了一些新的角度以及利用超球面特性的新散度技术。实验表明了分散对于图像分类和自然语言处理的重要性，同时展示了不同算法在不同类型任务中的性能权衡情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning well-separated features in high-dimensional spaces, such as text orimage embeddings, is crucial for many machine learning applications. Achievingsuch separation can be effectively accomplished through the dispersion ofembeddings, where unrelated vectors are pushed apart as much as possible. Byconstraining features to be on a hypersphere, we can connect dispersion towell-studied problems in mathematics and physics, where optimal solutions areknown for limited low-dimensional cases. However, in representation learning wetypically deal with a large number of features in high-dimensional space, andmoreover, dispersion is usually traded off with some other task-orientedtraining objective, making existing theoretical and numerical solutionsinapplicable. Therefore, it is common to rely on gradient-based methods toencourage dispersion, usually by minimizing some function of the pairwisedistances. In this work, we first give an overview of existing methods fromdisconnected literature, making new connections and highlighting similarities.Next, we introduce some new angles. We propose to reinterpret pairwisedispersion using a maximum mean discrepancy (MMD) motivation. We then proposean online variant of the celebrated Lloyd's algorithm, of K-Means fame, as aneffective alternative regularizer for dispersion on generic domains. Finally,we derive a novel dispersion method that directly exploits properties of thehypersphere. Our experiments show the importance of dispersion in imageclassification and natural language processing tasks, and how algorithmsexhibit different trade-offs in different regimes.</description>
      <author>example@mail.com (Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae)</author>
      <guid isPermaLink="false">2502.08231v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Causal Analysis of ASR Errors for Children: Quantifying the Impact of Physiological, Cognitive, and Extrinsic Factors</title>
      <link>http://arxiv.org/abs/2502.08587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Computer Speech &amp; Language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;近年来，随着儿童自动语音识别（ASR）系统的广泛应用，研究者们致力于提高专为儿童设计的模型准确度。该研究旨在填补现有研究中对于基于开放源代码或针对儿童进行微调后的基础语音模型在性能下降原因分析上的空白。&lt;h4&gt;背景&lt;/h4&gt;当前的方法要么直接使用开源语音基础模型（SFM），要么用儿童语音数据对其进行微调，然而这些模型通常表现出高于成人言语的单词错误率（WER）。&lt;h4&gt;目的&lt;/h4&gt;理解并解决这种性能差距的原因对于改善针对儿童语音的基础模型准确性至关重要。本研究通过调查准确度下降的原因以及造成WER的主要因素来填补这一空白。&lt;h4&gt;方法&lt;/h4&gt;首先，在两个自我监督SFM（Wav2Vec2.0和Hubert）及两种弱监督SFM（Whisper和MMS）的不同年龄段上的儿童语音语料库上进行了全面基准测试，建立了因果推理分析第二部分的原始数据。然后使用因果推断技术来评估生理因素、认知因素和外部因素对儿童言语SFM准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，生理因素（年龄）以及特定的外部因素（音频中的单词数量）对准确度影响最大，其次是背景噪音和发音能力。针对儿童语音微调基础模型可以减少其对生理和认知因素的敏感性，但依然存在对于音频中单词数目的敏感。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了影响儿童ASR系统准确性的重要因素，并提供了如何通过针对性改进这些因素来提高SFM性能的方法。&lt;h4&gt;翻译&lt;/h4&gt;近年来，随着用于儿童自动语音识别（ASR）系统的增加，研究人员一直在努力改进针对儿童语言设计的模型准确度。当前的研究方法涉及到直接使用开源基础语音模型或者用儿童的数据微调这些模型，然而无论开源还是经过孩子数据微调的基础语音模型通常都会表现出比成人言语更高的单词错误率(WER)。目前尚缺乏系统地分析导致这种性能下降的原因。了解并解决这些差距对于提高SFM的准确性至关重要。研究通过评估基础语音模型在各种年龄段上两个儿童语言语料库中的表现，建立了因果推断分析的基础，并深入探讨了影响儿童ASR系统的准确性的生理、认知和外部因素的影响程度。研究表明年龄、音频单词数量是最重要的决定因素，其次是背景噪音以及发音能力。针对儿童语言数据微调SFM可以减少其对生理与认知特征的敏感性，但仍然保持对于音频中单词数目的敏感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of children's automatic speech recognition (ASR) systemshas spurred research efforts to improve the accuracy of models designed forchildren's speech in recent years. The current approach utilizes eitheropen-source speech foundation models (SFMs) directly or fine-tuning them withchildren's speech data. These SFMs, whether open-source or fine-tuned forchildren, often exhibit higher word error rates (WERs) compared to adultspeech. However, there is a lack of systemic analysis of the cause of thisdegraded performance of SFMs. Understanding and addressing the reasons behindthis performance disparity is crucial for improving the accuracy of SFMs forchildren's speech. Our study addresses this gap by investigating the causes ofaccuracy degradation and the primary contributors to WER in children's speech.In the first part of the study, we conduct a comprehensive benchmarking studyon two self-supervised SFMs (Wav2Vec2.0 and Hubert) and two weakly supervisedSFMs (Whisper and MMS) across various age groups on two children speechcorpora, establishing the raw data for the causal inference analysis in thesecond part. In the second part of the study, we analyze the impact ofphysiological factors (age, gender), cognitive factors (pronunciation ability),and external factors (vocabulary difficulty, background noise, and word count)on SFM accuracy in children's speech using causal inference. The resultsindicate that physiology (age) and particular external factor (number of wordsin audio) have the highest impact on accuracy, followed by background noise andpronunciation ability. Fine-tuning SFMs on children's speech reducessensitivity to physiological and cognitive factors, while sensitivity to thenumber of words in audio persists.  Keywords: Children's ASR, Speech Foundational Models, Causal Inference,Physiology, Cognition, Pronunciation</description>
      <author>example@mail.com (Vishwanath Pratap Singh, Md. Sahidullah, Tomi Kinnunen)</author>
      <guid isPermaLink="false">2502.08587v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation</title>
      <link>http://arxiv.org/abs/2502.08347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, Code: https://github.com/FengheTan9/Hi-End-MAE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Hi-End-MAE的新颖的预训练框架，用于提高Vision Transformer在医疗图像分割任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割由于标签稀疏而面临挑战。通过未标记的大规模数据集进行掩码图像建模（MIM）预训练可以解决这个问题，并且ViT具有计算效率和模型泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于Transformer的简单有效的预训练解决方案，以提高其在医学影像分割任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了两个创新点：编码器驱动重建和分层密集解码。前者使编码器能够学习更丰富的特征；后者通过实现层次化解码结构来捕捉不同层级之间的丰富表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Hi-End-MAE在多个医学图像分割基准测试中具有优越的迁移学习能力。&lt;h4&gt;结论&lt;/h4&gt;证明了ViT模型在医疗成像应用中的巨大潜力。该框架为未来的研究提供了一个良好的起点。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种新的预训练方法，通过改进Vision Transformer架构来提升其在医学图像分割任务上的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation remains a formidable challenge due to the labelscarcity. Pre-training Vision Transformer (ViT) through masked image modeling(MIM) on large-scale unlabeled medical datasets presents a promising solution,providing both computational efficiency and model generalization for variousdownstream tasks. However, current ViT-based MIM pre-training frameworkspredominantly emphasize local aggregation representations in output layers andfail to exploit the rich representations across different ViT layers thatbetter capture fine-grained semantic information needed for more precisemedical downstream tasks. To fill the above gap, we hereby present HierarchicalEncoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-trainingsolution, which centers on two key innovations: (1) Encoder-drivenreconstruction, which encourages the encoder to learn more informative featuresto guide the reconstruction of masked patches; and (2) Hierarchical densedecoding, which implements a hierarchical decoding structure to capture richrepresentations across different layers. We pre-train Hi-End-MAE on alarge-scale dataset of 10K CT scans and evaluated its performance across sevenpublic medical image segmentation benchmarks. Extensive experiments demonstratethat Hi-End-MAE achieves superior transfer learning capabilities across variousdownstream tasks, revealing the potential of ViT in medical imagingapplications. The code is available at:https://github.com/FengheTan9/Hi-End-MAE</description>
      <author>example@mail.com (Fenghe Tang, Qingsong Yao, Wenxin Ma, Chenxu Wu, Zihang Jiang, S. Kevin Zhou)</author>
      <guid isPermaLink="false">2502.08347v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Tokenized Graph Transformers for Node Classification</title>
      <link>http://arxiv.org/abs/2502.08101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图变换器(SwapGT)方法，用于改进节点分类任务中令牌序列的生成。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图变换器的方法在节点分类任务中展示了良好的性能。这些模型依赖于将输入图转换为令牌序列的关键模块来促进节点表示学习。&lt;h4&gt;目的&lt;/h4&gt;解决现有图变换器只关注构造相似性图的一阶邻居的问题，通过改进令牌生成策略提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的令牌交换操作，以充分利用节点之间的语义相关性，从而生成更多样的令牌序列。然后使用基于Transformer的骨干网络从这些序列中学习节点表示，并开发一种中心对齐损失来约束来自多个令牌序列的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验结果表明SwapGT在多种数据集上的性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够更有效地利用图中的信息，从而提高节点分类任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;节点标记化图变换器（GTs）在节点分类中表现出良好的性能。现有的令牌序列生成策略仅关注构造的相似性图的一阶邻居，限制了模型从更多节点获取多样令牌序列的能力。为了解决这个问题，我们提出了SwapGT方法，它通过引入基于令牌特性的交换操作来改进这一过程，并结合中心对齐损失进一步优化表示学习。实验结果表明，与现有技术相比，该方法在节点分类任务中表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node tokenized graph Transformers (GTs) have shown promising performance innode classification. The generation of token sequences is the key module inexisting tokenized GTs which transforms the input graph into token sequences,facilitating the node representation learning via Transformer. In this paper,we observe that the generations of token sequences in existing GTs only focuson the first-order neighbors on the constructed similarity graphs, which leadsto the limited usage of nodes to generate diverse token sequences, furtherrestricting the potential of tokenized GTs for node classification. To thisend, we propose a new method termed SwapGT. SwapGT first introduces a noveltoken swapping operation based on the characteristics of token sequences thatfully leverages the semantic relevance of nodes to generate more informativetoken sequences. Then, SwapGT leverages a Transformer-based backbone to learnnode representations from the generated token sequences. Moreover, SwapGTdevelops a center alignment loss to constrain the representation learning frommultiple token sequences, further enhancing the model performance. Extensiveempirical results on various datasets showcase the superiority of SwapGT fornode classification.</description>
      <author>example@mail.com (Jinsong Chen, Chenyang Li, GaiChao Li, John E. Hopcroft, Kun He)</author>
      <guid isPermaLink="false">2502.08101v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport Plans</title>
      <link>http://arxiv.org/abs/2502.07962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于切片最优传输的新型完全并行化双重随机注意机制，该方法在不使用迭代Sinkhorn归一化的前提下实现了注意力分布的平衡和结构优化。&lt;h4&gt;背景&lt;/h4&gt;自注意力机制虽然对Transformer模型的成功至关重要，但可能导致训练过程中某些令牌过度集中，从而影响信息流动。现有的双随机性约束方法依赖于计算成本高昂的迭代Sinkhorn标准化过程。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的、完全并行化的双重随机注意机制，以提高效率和性能，同时确保可以无缝集成到深度学习模型中。&lt;h4&gt;方法&lt;/h4&gt;引入了基于切片最优传输的新注意力机制，利用期望切片传输计划（ESP）来实现双随机性约束。通过温度基软排序技术保证可微分性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个基准数据集上（包括图像分类、点云分类、情感分析和神经机器翻译等任务），该增强注意力正则化机制在各种应用场景中都能显著提升性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法提供了一种更有效且计算成本更低的方式来优化Transformer模型中的自注意力机制，从而提高不同领域的深度学习应用的效率与准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然自我注意对于Transformer的成功至关重要，但它可能会导致在训练过程中某些令牌过度集中，影响信息流动。强制执行双随机约束已经被证明可以改善注意力分布的结构和平衡性。然而，现有的方法依赖于迭代Sinkhorn归一化过程，这计算成本高昂。本文介绍了一种基于切片最优传输的新型完全并行化的双重随机注意机制，利用期望切片传输计划（ESP）。与以往的方法不同，该方法在不使用迭代Sinkhorn标准化的情况下实现了双随机性约束，显著提高了效率。为了确保可微分性，我们引入了基于温度的软排序技术，使得能够无缝集成到深度学习模型中。实验结果显示，在包括图像分类、点云分类、情感分析和神经机器翻译在内的多个基准数据集上，增强注意力正则化机制在各种应用场景中的性能都有所提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While self-attention has been instrumental in the success of Transformers, itcan lead to over-concentration on a few tokens during training, resulting insuboptimal information flow. Enforcing doubly-stochastic constraints inattention matrices has been shown to improve structure and balance in attentiondistributions. However, existing methods rely on iterative Sinkhornnormalization, which is computationally costly. In this paper, we introduce anovel, fully parallelizable doubly-stochastic attention mechanism based onsliced optimal transport, leveraging Expected Sliced Transport Plans (ESP).Unlike prior approaches, our method enforces double stochasticity withoutiterative Sinkhorn normalization, significantly enhancing efficiency. To ensuredifferentiability, we incorporate a temperature-based soft sorting technique,enabling seamless integration into deep learning models. Experiments acrossmultiple benchmark datasets, including image classification, point cloudclassification, sentiment analysis, and neural machine translation, demonstratethat our enhanced attention regularization consistently improves performanceacross diverse applications.</description>
      <author>example@mail.com (Ashkan Shahbazi, Elaheh Akbari, Darian Salehi, Xinran Liu, Navid Naderializadeh, Soheil Kolouri)</author>
      <guid isPermaLink="false">2502.07962v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised categorization of similarity measures</title>
      <link>http://arxiv.org/abs/2502.08098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2306.00239&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了人工神经网络系统通过表示学习自主分类度量空间的能力，这些空间对应于物体特征，并且探讨了如何独立评估特征之间的差异和相似性。&lt;h4&gt;背景&lt;/h4&gt;现有的方法往往限制潜在空间的轴线相互独立或正交。然而，这种相互独立的轴线不适合对度量空间进行分类。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服现有方法中关于高维度量空间分类的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一种只约束空间之间互相独立而不强制轴线单独独立的方法。&lt;h4&gt;主要发现&lt;/h4&gt;提出了满足代数独立性的理论条件，这为无监督的独立度量空间分类提供了通用条件，并推动了神经网络功能分化数学理论的发展。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，人工神经网络可以更好地处理和分类不同特征空间（如颜色空间和形状空间）之间的关系。&lt;h4&gt;翻译&lt;/h4&gt;通常情况下，物体可以根据其特性和属性进行区分，例如颜色或形状。特别是假设这些特性在不同的度量空间中可以独立地进行相似性判断。然而，与对象特征对应的度量空间的无监督分类机制尚不清楚。本研究展示了人工神经网络系统通过表示学习自主对度量空间进行分类以满足神经网络之间的代数独立性，并将感觉信息投射到多个高维度量空间中来独立评估特性之间的差异和相似性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In general, objects can be distinguished on the basis of their features, suchas color or shape. In particular, it is assumed that similarity judgments aboutsuch features can be processed independently in different metric spaces.However, the unsupervised categorization mechanism of metric spacescorresponding to object features remains unknown. Here, we show that theartificial neural network system can autonomously categorize metric spacesthrough representation learning to satisfy the algebraic independence betweenneural networks, and project sensory information onto multiple high-dimensionalmetric spaces to independently evaluate the differences and similaritiesbetween features. Conventional methods often constrain the axes of the latentspace to be mutually independent or orthogonal. However, the independent axesare not suitable for categorizing metric spaces. High-dimensional metric spacesthat are independent of each other are not uniquely determined by the mutuallyindependent axes, because any combination of independent axes can form mutuallyindependent spaces. In other words, the mutually independent axes cannot beused to naturally categorize different feature spaces, such as color space andshape space. Therefore, constraining the axes to be mutually independent makesit difficult to categorize high-dimensional metric spaces. To overcome thisproblem, we developed a method to constrain only the spaces to be mutuallyindependent and not the composed axes to be independent. Our theory providesgeneral conditions for the unsupervised categorization of independent metricspaces, thus advancing the mathematical theory of functional differentiation ofneural networks.</description>
      <author>example@mail.com (Yoshiyuki Ohmura, Wataru Shimaya, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2502.08098v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy</title>
      <link>http://arxiv.org/abs/2502.08353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了图神经网络（GNN）与大型语言模型（LLM）结合的现状，提出了一个分类框架来帮助研究人员理解不同方法的原则和应用场景，并系统地回顾了代表性方法，指出了这些方法在集成过程中的适用场景、潜在优势及限制。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络在各个领域的广泛应用，其可信度问题成为研究重点。一些现有研究表明，将大型语言模型与GNN结合可以提高其语义理解和生成能力，从而从多方面提升GNN的可信度。&lt;h4&gt;目的&lt;/h4&gt;介绍一种分类框架以帮助研究人员理解不同方法之间的联系和区别，并总结代表性方法在四个类别中的表现情况。&lt;h4&gt;方法&lt;/h4&gt;提出了一种关于如何将大型语言模型（LLM）与图神经网络（GNN）集成的方法分类体系，系统地对具有代表性的方法进行了回顾。&lt;h4&gt;主要发现&lt;/h4&gt;通过所提出的分类体系，研究人员可以理解每种方法在可信集成功能中的适用场景、潜在优势和局限性。此外还指出了未来研究的方向和趋势。&lt;h4&gt;结论&lt;/h4&gt;提出了一个明确的框架来帮助研究人员了解不同方法之间的关系及其应用场景，并展望了LLM与GNN结合以提高模型可靠性的未来发展方向。&lt;h4&gt;翻译&lt;/h4&gt;随着图神经网络（GNN）在各个领域的广泛应用，其可信度问题成为研究重点。一些现有研究表明，将大型语言模型（LLM）集成到GNN中可以提升其语义理解和生成能力，从而从多个角度增强GNN的可靠性。该论文综述介绍了这种分类框架，并系统地总结了代表性方法，旨在为未来的研究方向提供指南和趋势预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the extensive application of Graph Neural Networks (GNNs) across variousdomains, their trustworthiness has emerged as a focal point of research. Someexisting studies have shown that the integration of large language models(LLMs) can improve the semantic understanding and generation capabilities ofGNNs, which in turn improves the trustworthiness of GNNs from various aspects.Our review introduces a taxonomy that offers researchers a clear framework forcomprehending the principles and applications of different methods and helpsclarify the connections and differences among various approaches. Then wesystematically survey representative approaches along the four categories ofour taxonomy. Through our taxonomy, researchers can understand the applicablescenarios, potential advantages, and limitations of each approach for the thetrusted integration of GNNs with LLMs. Finally, we present some promisingdirections of work and future trends for the integration of LLMs and GNNs toimprove model trustworthiness.</description>
      <author>example@mail.com (Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang)</author>
      <guid isPermaLink="false">2502.08353v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</title>
      <link>http://arxiv.org/abs/2502.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2306.02873 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VISTA是一个专门用于科学领域视频到文本摘要的数据库，旨在解决将记录的视频转化为简洁准确的文字摘要这一多模态学习中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在多模态学习中，从记录的视频生成简洁且准确的文本摘要是一项日益增长的挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍VISTA数据集，并评估最先进的大型模型在其上的性能。同时应用基于计划的框架以更好地捕捉摘要结构化特性。&lt;h4&gt;方法&lt;/h4&gt;将18,599个AI会议演讲录音与其对应的论文摘要配对，使用计划基础框架来生成总结并进行人类和自动化的评价。&lt;h4&gt;主要发现&lt;/h4&gt;显式的规划提高了摘要质量和事实一致性。然而，模型性能与人类表现之间仍存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;尽管基于计划的方法改进了科学视频摘要的准确性，但该领域仍然面临挑战。&lt;h4&gt;翻译&lt;/h4&gt;将记录的视频转换为简洁准确的文字总结是多模态学习中的一个日益增长的挑战。本文介绍了一个专门用于科学领域的视频到文本总结的数据集VISTA，它包含了18,599个AI会议演讲录音及其对应的论文摘要。我们对最先进的大型模型进行了基准测试，并应用了基于计划框架来更好地捕捉摘要结构化特性。无论是人工还是自动化评估都证实了显式规划提升了摘要质量和事实一致性。然而，模型与人类表现之间的差距依然存在，这突显了科学视频总结中的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transforming recorded videos into concise and accurate textual summaries is agrowing challenge in multimodal learning. This paper introduces VISTA, adataset specifically designed for video-to-text summarization in scientificdomains. VISTA contains 18,599 recorded AI conference presentations paired withtheir corresponding paper abstracts. We benchmark the performance ofstate-of-the-art large models and apply a plan-based framework to bettercapture the structured nature of abstracts. Both human and automatedevaluations confirm that explicit planning enhances summary quality and factualconsistency. However, a considerable gap remains between models and humanperformance, highlighting the challenges of scientific video summarization.</description>
      <author>example@mail.com (Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg)</author>
      <guid isPermaLink="false">2502.08279v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Mixture of Decoupled Message Passing Experts with Entropy Constraint for General Node Classification</title>
      <link>http://arxiv.org/abs/2502.08083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2412.08193&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于混合专家(MoE)机制的通用节点分类框架GNNMoE，用于解决图神经网络(GNNs)在处理同质性和异质性不同的现实世界图形时面临的问题。&lt;h4&gt;背景&lt;/h4&gt;现实中图的数据结构中存在着不同程度的同质性和异质性，这使得现有的图神经网络难以实现普遍适用性。从数据为中心的角度来看，不同的图对不同信息传播编码方案有着固有的偏好：同质图倾向于局部传播，而异质图则更喜欢传播和转换的灵活组合。&lt;h4&gt;目的&lt;/h4&gt;为了提高GNN在处理不同类型图形时的表现力和适应性，设计了一种通用节点分类框架。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于Mixture-of-Experts (MoE)机制的节点分类框架GNNMoE。该框架首先通过细粒度编码操作重构出多样化的消息传递专家网络，然后设计了软硬门控层以分配最适合每个节点表示学习的专家网络，并引入熵约束来指导软门控的硬化过程。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GNNMoE框架在节点分类性能和跨多种图数据集的通用性方面显著优于主流图神经网络、异质图神经网络以及图变换器。&lt;h4&gt;结论&lt;/h4&gt;通过实验证明，所提出的GNNMoE框架能够有效解决现有图神经网络处理不同类型图形时面临的挑战，并提高模型的表现力和适应性。&lt;h4&gt;翻译&lt;/h4&gt;现实世界中的图数据结构存在不同程度的同质性和异质性，这限制了图神经网络(GNNs)在节点分类任务上的普遍适用性。本研究采用数据为中心的方法揭示了不同类型的图对不同的消息编码方案有着固有的偏好：同质图倾向于局部传播，而异质图则更喜欢灵活组合的消息传递和转换。为解决这一问题，提出了一种基于混合专家机制的通用节点分类框架GNNMoE。该框架通过构建多样化的消息传递专家网络，并设计软硬门控层来选择最适合每个节点表示学习的网络，从而提高模型的表现力和适应性。此外，在同质场景中引入熵约束以减少编码噪声的影响。实验结果表明，GNNMoE在节点分类性能以及对不同类型图数据集的通用性方面均优于主流图神经网络、异质图神经网络及图变换器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The varying degrees of homophily and heterophily in real-world graphspersistently constrain the universality of graph neural networks (GNNs) fornode classification. Adopting a data-centric perspective, this work reveals aninherent preference of different graphs towards distinct message encodingschemes: homophilous graphs favor local propagation, while heterophilous graphsexhibit preference for flexible combinations of propagation and transformation.To address this, we propose GNNMoE, a universal node classification frameworkbased on the Mixture-of-Experts (MoE) mechanism. The framework first constructsdiverse message-passing experts through recombination of fine-grained encodingoperators, then designs soft and hard gating layers to allocate the mostsuitable expert networks for each node's representation learning, therebyenhancing both model expressiveness and adaptability to diverse graphs.Furthermore, considering that soft gating might introduce encoding noise inhomophilous scenarios, we introduce an entropy constraint to guide sharpeningof soft gates, achieving organic integration of weighted combination and Top-Kselection. Extensive experiments demonstrate that GNNMoE significantlyoutperforms mainstream GNNs, heterophilous GNNs, and graph transformers in bothnode classification performance and universality across diverse graph datasets.</description>
      <author>example@mail.com (Xuanze Chen, Jiajun Zhou, Jinsong Chen, Shanqing Yu, Qi Xuan)</author>
      <guid isPermaLink="false">2502.08083v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Graph Foundation Models for Recommendation: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2502.08346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;基于图基础模型的推荐系统技术综述&lt;h4&gt;背景&lt;/h4&gt;推荐系统（RS）是导航海量在线信息的基本工具，深度学习的进步在提高排序准确性方面发挥着越来越重要的作用。其中，图形神经网络（GNNs）擅长提取高级结构化信息，而大型语言模型（LLMs）则旨在处理和理解自然语言，使两者都成为高度有效且广泛采用的方法。&lt;h4&gt;目的&lt;/h4&gt;本文提供了一种基于图基础模型的推荐系统技术的全面概述，介绍当前方法的分类、深入分析方法细节，并强调关键挑战和未来方向。&lt;h4&gt;方法&lt;/h4&gt;通过综合最近的进步，我们旨在为基于GFM（图基础模型）的推荐系统的演变格局提供有价值的见解。&lt;h4&gt;主要发现&lt;/h4&gt;最近的研究集中在将GNNs和LLMs的优点结合在一起的方法上，这些方法利用用户-项目关系的图形结构以及文本理解来更有效地建模复杂的RS问题。&lt;h4&gt;结论&lt;/h4&gt;通过合成近期进展，本文旨在为基于图基础模型（GFMs）的推荐系统提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：Recommender systems (RS) serve as a fundamental tool for navigating the vast expanse of online information, with deep learning advancements playing an increasingly important role in improving ranking accuracy. Among these, graph neural networks (GNNs) excel at extracting higher-order structural information, while large language models (LLMs) are designed to process and comprehend natural language, making both approaches highly effective and widely adopted. Recent research has focused on graph foundation models (GFMs), which integrate the strengths of GNNs and LLMs to model complex RS problems more efficiently by leveraging the graph-based structure of user-item relationships alongside textual understanding. In this survey, we provide a comprehensive overview of GFM-based RS technologies by introducing a clear taxonomy of current approaches, diving into methodological details, and highlighting key challenges and future directions. By synthesizing recent advancements, we aim to offer valuable insights into the evolving landscape of GFM-based recommender systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) serve as a fundamental tool for navigating the vastexpanse of online information, with deep learning advancements playing anincreasingly important role in improving ranking accuracy. Among these, graphneural networks (GNNs) excel at extracting higher-order structural information,while large language models (LLMs) are designed to process and comprehendnatural language, making both approaches highly effective and widely adopted.Recent research has focused on graph foundation models (GFMs), which integratethe strengths of GNNs and LLMs to model complex RS problems more efficiently byleveraging the graph-based structure of user-item relationships alongsidetextual understanding. In this survey, we provide a comprehensive overview ofGFM-based RS technologies by introducing a clear taxonomy of currentapproaches, diving into methodological details, and highlighting key challengesand future directions. By synthesizing recent advancements, we aim to offervaluable insights into the evolving landscape of GFM-based recommender systems.</description>
      <author>example@mail.com (Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi)</author>
      <guid isPermaLink="false">2502.08346v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Foundation Models: Perception, Generation and Agentic Modeling</title>
      <link>http://arxiv.org/abs/2502.08556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了Human-centric Foundation Models (HcFMs)，提出了一个分类体系，将当前的方法分为四类：人类感知基础模型、人类AIGC基础模型、统一的感知和生成模型以及人类代理基础模型。&lt;h4&gt;背景&lt;/h4&gt;人机交互理解与生成是数字人建模的关键。受到大型语言和视觉模型成功的启发，HcFMs旨在将各种以人为中心的任务整合到一个框架中，超越了传统的特定任务方法。&lt;h4&gt;目的&lt;/h4&gt;综述提供了一个全面的视角来审视现有的HcFMs，并讨论最新的技术、存在的挑战以及未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种分类体系，该体系将HcFMs分为四个主要类别：人类感知基础模型、人类AIGC基础模型、统一的感知和生成模型、以及人类代理基础模型。每个类别都包含了不同的任务和能力。&lt;h4&gt;主要发现&lt;/h4&gt;四种类型的HcFMs分别在不同方面展现出了独特的优势，从捕捉多模态的理解到高保真度内容的生成再到模拟交互行为等方面均有所贡献。&lt;h4&gt;结论&lt;/h4&gt;综述旨在为研究者提供一个路线图，推动更加坚固、多样化和智能的数字人建模的发展。&lt;h4&gt;翻译&lt;/h4&gt;人类理解和生成对于建模数字人和拟人化实体至关重要。最近，受到大型语言模型和视觉模型成功的启发，以人为中心的基础模型(HcFMs)应运而生，旨在将各种以人为中心的任务整合到一个框架中，并超越传统的特定任务方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human understanding and generation are critical for modeling digital humansand humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)inspired by the success of generalist models, such as large language and visionmodels, have emerged to unify diverse human-centric tasks into a singleframework, surpassing traditional task-specific approaches. In this survey, wepresent a comprehensive overview of HcFMs by proposing a taxonomy thatcategorizes current approaches into four groups: (1) Human-centric PerceptionFoundation Models that capture fine-grained features for multi-modal 2D and 3Dunderstanding. (2) Human-centric AIGC Foundation Models that generatehigh-fidelity, diverse human-related content. (3) Unified Perception andGeneration Models that integrate these capabilities to enhance both humanunderstanding and synthesis. (4) Human-centric Agentic Foundation Models thatextend beyond perception and generation to learn human-like intelligence andinteractive behaviors for humanoid embodied tasks. We review state-of-the-arttechniques, discuss emerging challenges and future research directions. Thissurvey aims to serve as a roadmap for researchers and practitioners workingtowards more robust, versatile, and intelligent digital human and embodimentsmodeling.</description>
      <author>example@mail.com (Shixiang Tang, Yizhou Wang, Lu Chen, Yuan Wang, Sida Peng, Dan Xu, Wanli Ouyang)</author>
      <guid isPermaLink="false">2502.08556v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-Guided Wasserstein Distributionally Robust Optimization</title>
      <link>http://arxiv.org/abs/2502.08146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新型的知识引导的Wasserstein分布鲁棒优化（KG-WDRO）框架，通过适应性地利用多源外部知识来改进统计效率。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是一种流行的策略，旨在利用外部知识提高有限样本目标数据集上的统计效率。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法来克服传统WDRO的保守性，该保守性往往导致过度悲观化的向零收缩。&lt;h4&gt;方法&lt;/h4&gt;通过控制运输方向以源知识为指导，构建更小的Wasserstein模糊集合，从而减轻协变量预测投影上的扰动，并防止信息损失。理论证明了KG-WDRO的形式与基于共线相似性的知识引导收缩估计之间的等价性，确保了可行集的可操作性和几何化。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够调整源和目标之间回归模型中的比例差异，并适应诸如lasso和ridge等通用类型的正则化。广泛的模拟表明KG-WDRO在增强小样本迁移学习方面的优越性能和适应性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个新型的基于分布鲁棒性的迁移学习方法，证明了其理论上的有效性和实际应用中的优越性。&lt;h4&gt;翻译&lt;/h4&gt;转移学习是一种流行的策略，利用外部知识提高有限目标数据集的统计效率。本文提出了一种新的知识引导Wasserstein分布鲁棒优化（KG-WDRO）框架，该框架通过适应地结合多源外部知识克服了传统WDRO过于保守的问题，并减轻了预测方向上的扰动和信息损失。该方法建立了WDRO公式与基于共线相似性的知识引导收缩估计之间的等价性，证明其可行性并从分布鲁棒性角度解释最近的收缩迁移学习方法。此外，KG-WDRO能够调整源和目标模型的比例差异，并处理lasso和ridge等通用正则化类型。实验结果表明，该框架在小样本迁移学习中具有优越性能与适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a popular strategy to leverage external knowledge andimprove statistical efficiency, particularly with a limited target sample. Wepropose a novel knowledge-guided Wasserstein Distributionally RobustOptimization (KG-WDRO) framework that adaptively incorporates multiple sourcesof external knowledge to overcome the conservativeness of vanilla WDRO, whichoften results in overly pessimistic shrinkage toward zero. Our methodconstructs smaller Wasserstein ambiguity sets by controlling the transportationalong directions informed by the source knowledge. This strategy can alleviateperturbations on the predictive projection of the covariates and protectagainst information loss. Theoretically, we establish the equivalence betweenour WDRO formulation and the knowledge-guided shrinkage estimation based oncollinear similarity, ensuring tractability and geometrizing the feasible set.This also reveals a novel and general interpretation for recent shrinkage-basedtransfer learning approaches from the perspective of distributional robustness.In addition, our framework can adjust for scaling differences in the regressionmodels between the source and target and accommodates general types ofregularization such as lasso and ridge. Extensive simulations demonstrate thesuperior performance and adaptivity of KG-WDRO in enhancing small-sampletransfer learning.</description>
      <author>example@mail.com (Zitao Wang, Ziyuan Wang, Molei Liu, Nian Si)</author>
      <guid isPermaLink="false">2502.08146v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Data Pricing for Graph Neural Networks without Pre-purchased Inspection</title>
      <link>http://arxiv.org/abs/2502.08284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAMAS-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在各种场景中已成为不可或缺的工具。然而，它们的有效性依赖于大量的数据才能达到满意的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于结构重要性的模型交易机制（SIMT），该机制可以在不公开数据的情况下评估数据的重要性并补偿数据所有者。&lt;h4&gt;方法&lt;/h4&gt;SIMT 从数据所有者处获取特征和标签数据，根据它们的结构重要性进行采购，并使用图神经网络为模型消费者训练一个模型。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明 SIMT 确保了激励兼容、个体理性且预算可行。实验结果在五个流行的数据集上验证了 SIMT 在 MacroF1 和 MicroF1 两个指标上均优于基本方案，性能提高可达40%。&lt;h4&gt;结论&lt;/h4&gt;SIMT 是一种有效解决数据交易中数据所有者不愿无偿分享其有价值信息的机制。&lt;h4&gt;翻译&lt;/h4&gt;机器学习模型已成为各种场景中的重要工具。然而，为了达到满意的表现，这些模型需要大量数据的支持。为了解决这个问题，市场平台应运而生，连接寻求机器学习解决方案的模型消费者和拥有宝贵数据的数据所有者。现有的交易机制通常假设在被支付之前数据所有者愿意分享他们的数据，在现实世界中这是不合理的。因此，我们提出了基于结构重要性的模型交易（SIMT）机制，该机制可以评估数据的重要性，并且不需要透露数据就能补偿数据所有者。具体来说，SIMT 根据它们的结构重要性从数据所有者那里获取特征和标签数据，然后为模型消费者训练一个图神经网络。理论上，SIMT 确保激励兼容、个体理性且预算可行。在五个流行的数据集上进行的实验验证了 SIMT 在 MacroF1 和 MicroF1 两个指标上的性能优于基本方案，最高可达40%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) models have become essential tools in variousscenarios. Their effectiveness, however, hinges on a substantial volume of datafor satisfactory performance. Model marketplaces have thus emerged as crucialplatforms bridging model consumers seeking ML solutions and data ownerspossessing valuable data. These marketplaces leverage model trading mechanismsto properly incentive data owners to contribute their data, and return a wellperforming ML model to the model consumers. However, existing model tradingmechanisms often assume the data owners are willing to share their data beforebeing paid, which is not reasonable in real world. Given that, we propose anovel mechanism, named Structural Importance based Model Trading (SIMT)mechanism, that assesses the data importance and compensates data ownersaccordingly without disclosing the data. Specifically, SIMT procures featureand label data from data owners according to their structural importance, andthen trains a graph neural network for model consumers. Theoretically, SIMTensures incentive compatible, individual rational and budget feasible. Theexperiments on five popular datasets validate that SIMT consistentlyoutperforms vanilla baselines by up to $40\%$ in both MacroF1 and MicroF1.</description>
      <author>example@mail.com (Yiping Liu, Mengxiao Zhang, Jiamou Liu, Song Yang)</author>
      <guid isPermaLink="false">2502.08284v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>O1 Embedder: Let Retrievers Think Before Action</title>
      <link>http://arxiv.org/abs/2502.07555v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;大型语言模型(LLMs)在信息检索和利用方面的能力显著提升，尤其擅长细粒度数据表示和基于外部引用的高质量答案生成。最近推出的推理模型进一步增强了LLMs解决问题前进行逐步思考的能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型通过优秀的数据表征能力改善了信息获取方式，并且可以生成基于外部参考的高质量答案。新型推理模型如OpenAI O1 和 DeepSeek R1 进一步提升了这一技术，使其能够解决更加复杂的任务（例如编码和数学证明）。&lt;h4&gt;目的&lt;/h4&gt;受这些进展启发，我们旨在为检索模型开发类似的逐步思考能力，以便更好地处理多任务检索、零样本学习等难题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为O1 Embedder的新方法，用于生成关于输入查询的有用思维以进行目标文档检索。通过设计数据合成工作流和优化训练过程来实现这一目的。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的实验中，该方法取得了显著改进，在跨域场景下的多个流行数据集中表现出色。这表明O1 Embedder具有极高的准确性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项研究为下一代信息检索基础模型的发展铺平了道路，展示了其在未来处理复杂任务中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在人们获取和使用信息的方式上发生了革命性的变化。它们擅长进行细粒度的数据表示，这有助于精确的信息检索，并基于外部参考生成高质量的答案，从而产生有用的见解。最近推出的推理模型，如OpenAI O1 和 DeepSeek R1，进一步展示了LLM的逐步思考能力，在交付最终答案之前进行有条理地推演，显著提高了处理复杂任务（例如编码和数学证明）的能力。受这些进步启发，我们旨在为检索模型开发类似的功能，以解决该领域中的关键挑战，包括多任务检索、零样本检索以及需要对复杂关系进行深度推理的任务。为此，我们提出了一种名为O1 Embedder的新方法，在生成目标文档的检索思维之前，先为输入查询生成有用的想法。为了实现这一目标，我们解决了两个技术难题：首先，设计了数据合成工作流，通过LLM专家生成初步想法，并利用检索委员会对其进行改进；其次，优化训练过程，使预训练模型能够联合微调以产生检索思想并通过行为克隆进行密集检索和对比学习。我们的方法经过全面的实验验证，在12个流行的数据集（涵盖域内和域外场景）中实现了显著改善。这些结果表明O1 Embedder具有出色的准确性和泛化能力，为下一代信息检索基础模型的发展铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing power of large language models (LLMs) has revolutionized howpeople access and utilize information. Notably, the LLMs excel at performingfine-grained data representation, which facilitates precise retrieval ofinformation. They also generate high-quality answers based on externalreferences, enabling the production of useful knowledge. The recentintroduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks anotherleap forward, highlighting LLMs' ability to think progressively beforedelivering final answers. This breakthrough significantly improves the abilityto address complex tasks, e.g., coding and math proofs.  Inspired by this progress, we aim to develop similar capabilities forretrieval models, which hold great promise for tackling critical challenges inthe field, including multi-task retrieval, zero-shot retrieval, and tasksrequiring intensive reasoning of complex relationships. With this motivation,we propose a novel approach called O1 Embedder, which generates useful thoughtsfor the input query before making retrieval for the target documents. Torealize this objective, we conquer two technical difficulties. First, we designa data synthesis workflow, creating training signals for O1 Embedder bygenerating initial thoughts from an LLM-expert and subsequently refining themusing a retrieval committee. Second, we optimize the training process, enablinga pre-trained model to be jointly fine-tuned to generate retrieval thoughts viabehavior cloning and perform dense retrieval through contrastive learning. Ourapproach is evaluated by comprehensive experiments, where substantialimprovements are achieved across 12 popular datasets, spanning both in-domainand out-of-domain scenarios. These results highlight O1 Embedder's remarkableaccuracy and generalizability, paving the way for the development ofnext-generation IR foundation models.</description>
      <author>example@mail.com (Ruiran Yan, Zheng Liu, Defu Lian)</author>
      <guid isPermaLink="false">2502.07555v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Equivariant Masked Position Prediction for Efficient Molecular Representation</title>
      <link>http://arxiv.org/abs/2502.08209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的自监督方法Equivariant Masked Position Prediction (EMPP)，用于改进图神经网络在计算化学中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNNs）在计算化学领域展现出巨大潜力，但分子数据的稀缺性限制了它们捕捉物理和化学基本原理的能力，从而影响其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习方法EMPP以解决现有图神经网络由于缺乏大量训练数据而面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;EMPP基于分子内位势和力理论，通过预测位置的细化任务来改进量子力学特征的学习过程。该方法不同于传统的属性掩码技术，并且在获取物理特性时绕过了常用高斯混合分布近似的限制。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，EMPP显著提高了复杂分子架构的性能，超越了现有的最先进的自监督学习方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法可以更好地利用有限的数据资源来提升图神经网络在计算化学领域的表现。&lt;h4&gt;翻译&lt;/h4&gt;Graph 神经网络（GNNs）在计算化学领域显示出巨大的前景。然而，分子数据的稀缺性引发了人们对于 GNNs 能否有效捕捉物理和化学基本原理能力的担忧，从而限制了它们的泛化能力。为了应对这一挑战，我们引入了一种名为等变掩码位置预测（EMPP）的新颖自监督方法，该方法基于分子内位势和力理论。不同于传统的属性掩码技术，EMPP定义了一个更加精细的位置预测任务，这有助于更好地学习量子力学特征，并绕过了常用的高斯混合分布的近似限制，从而能够更准确地获取物理特性。实验结果表明，EMPP显著提升了复杂分子架构的表现，超越了现有的最先进的自监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown considerable promise in computationalchemistry. However, the limited availability of molecular data raises concernsregarding GNNs' ability to effectively capture the fundamental principles ofphysics and chemistry, which constrains their generalization capabilities. Toaddress this challenge, we introduce a novel self-supervised approach termedEquivariant Masked Position Prediction (EMPP), grounded in intramolecularpotential and force theory. Unlike conventional attribute masking techniques,EMPP formulates a nuanced position prediction task that is more well-definedand enhances the learning of quantum mechanical features. EMPP also bypassesthe approximation of the Gaussian mixture distribution commonly used indenoising methods, allowing for more accurate acquisition of physicalproperties. Experimental results indicate that EMPP significantly enhancesperformance of advanced molecular architectures, surpassing state-of-the-artself-supervised approaches. Our code is released inhttps://github.com/ajy112/EMPP.</description>
      <author>example@mail.com (Junyi An, Chao Qu, Yun-Fei Shi, XinHao Liu, Qianwei Tang, Fenglei Cao, Yuan Qi)</author>
      <guid isPermaLink="false">2502.08209v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Music for All: Exploring Multicultural Representations in Music Generation Models</title>
      <link>http://arxiv.org/abs/2502.07328v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, accepted to NAACL'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了音乐生成领域的数据集和研究文献中存在的偏见，并提出了一种减轻这种偏见的方法。&lt;h4&gt;背景&lt;/h4&gt;音乐语言模型虽然极大地提高了AI系统自动生成音乐的能力，但它们在涵盖世界音乐类型和文化方面存在局限性。现有音乐数据集中只有5.7%来自非西方流派。&lt;h4&gt;目的&lt;/h4&gt;量化这些数据集中的偏见，并评估参数高效微调（PEFT）技术是否能减轻这种偏见，使模型更好地适应不同类型的音乐。&lt;h4&gt;方法&lt;/h4&gt;研究了两个流行模型MusicGen和Mustango在两种代表性不足的非西方音乐传统——印度斯坦古典音乐和土耳其马卡姆音乐上的表现，使用小数据集进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;PEFT技术展示出潜力，但跨流派适应仍然是一个复杂的问题。现有的基线音乐语言模型需要更公平地设计，以支持跨文化迁移学习。&lt;h4&gt;结论&lt;/h4&gt;需要更多研究来创建更加多元化的音乐数据集和更适合全球音乐文化的AI系统。&lt;h4&gt;翻译&lt;/h4&gt;音乐语言模型的出现极大地增强了人工智能系统的自动音乐生成能力，但它们在涵盖世界各地的音乐流派和文化方面存在局限性。本研究分析了用于音乐生成的数据集和研究论文，并量化了这些流派中的偏见和代表性不足问题。实验表明参数高效微调技术对缓解这种偏见有潜在作用，但也暗示需要设计更公平的基础模型来支持跨文化的迁移学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Music-Language Models has greatly enhanced the automatic musicgeneration capability of AI systems, but they are also limited in theircoverage of the musical genres and cultures of the world. We present a study ofthe datasets and research papers for music generation and quantify the bias andunder-representation of genres. We find that only 5.7% of the total hours ofexisting music datasets come from non-Western genres, which naturally leads todisparate performance of the models across genres. We then investigate theefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigatingthis bias. Our experiments with two popular models -- MusicGen and Mustango,for two underrepresented non-Western music traditions -- Hindustani Classicaland Turkish Makam music, highlight the promises as well as the non-trivialityof cross-genre adaptation of music through small datasets, implying the needfor more equitable baseline music-language models that are designed forcross-cultural transfer learning.</description>
      <author>example@mail.com (Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury)</author>
      <guid isPermaLink="false">2502.07328v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation</title>
      <link>http://arxiv.org/abs/2502.08161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在最近的推荐系统中广泛应用，负采样在此过程中扮演着重要角色。现有的负采样方法将节点之间的关系严格限制为硬正样本或硬负样本。&lt;h4&gt;问题&lt;/h4&gt;这种限制导致了结构信息的丢失，并且缺乏生成稀疏邻居节点正面配对机制。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些局限性，提出了基于软链接的新颖采样方法，即MixDec Sampling。&lt;h4&gt;方法&lt;/h4&gt;{'Mixup Sampling模块': '通过合成新的节点和软连接来增强节点特征，为具有少量邻居的节点提供足够的样本。', 'Decay Sampling模块': '通过生成用于节点嵌入学习的软连接来加强图结构信息的理解。'}&lt;h4&gt;主要发现&lt;/h4&gt;据我们所知，这是首次在基于GNN的推荐系统中使用软链接建模采样关系的方法。广泛的实验表明，提出的MixDec Sampling可以显著且一致地提升几种代表性GNN模型在不同推荐基准上的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的基于软连接的负采样方法可以有效地增强图神经网络在推荐系统的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络近年来广泛应用于推荐系统中，并且负样本抽取在这个过程中发挥着关键作用。现有的负样本抽取策略要么采用硬正样本，要么是硬负样本，在这种情况下，节点之间的关系被严格限定，导致结构信息的丢失以及缺乏生成稀疏邻居节点的正向配对机制。为了解决这些问题，我们提出了一种基于软链接的新颖采样方法——MixDec Sampling，该方法由混合抽样模块和衰减抽样模块组成。其中，混合抽样通过合成新的节点及软连接来增强节点特征，并且可以解决稀疏邻居问题中样本数量不足的问题；而衰减抽样则是通过生成用于嵌入学习的软链接强化图结构信息的理解能力。据我们所知，这是首次尝试在基于GNN推荐系统中采用这种利用软链接建模采样关系的方法。大量的实验结果表明，在各种推荐基准下使用该方法可以有效提升多种代表性GNN模型的表现力，并且能够保持稳定的性能改进效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICDM54844.2022.00070&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been widely used in recent recommender systems,where negative sampling plays an important role. Existing negative samplingmethods restrict the relationship between nodes as either hard positive pairsor hard negative pairs. This leads to the loss of structural information, andlacks the mechanism to generate positive pairs for nodes with few neighbors. Toovercome limitations, we propose a novel soft link-based sampling method,namely MixDec Sampling, which consists of Mixup Sampling module and DecaySampling module. The Mixup Sampling augments node features by synthesizing newnodes and soft links, which provides sufficient number of samples for nodeswith few neighbors. The Decay Sampling strengthens the digestion of graphstructure information by generating soft links for node embedding learning. Tothe best of our knowledge, we are the first to model sampling relationshipsbetween nodes by soft links in GNN-based recommender systems. Extensiveexperiments demonstrate that the proposed MixDec Sampling can significantly andconsistently improve the recommendation performance of several representativeGNN-based models on various recommendation benchmarks.</description>
      <author>example@mail.com (Xiangjin Xie, Yuxin Chen, Ruipeng Wang, Kai Ouyang, Zihan Zhang, Hai-Tao Zheng, Buyue Qian, Hansen Zheng, Bo Hu, Chengxiang Zhuo, Zang Li)</author>
      <guid isPermaLink="false">2502.08161v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>One-Shot Federated Learning with Classifier-Free Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.08488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;联邦学习（FL）通过实现去中心化的协作学习减少数据集中化，但引入了显著的通信成本，因为客户端和服务器之间需要进行多轮通信。一次性联邦学习（OSFL）通过仅使用一轮通信形成全局模型来解决这一问题，并通常依赖于服务器端的模型蒸馏或辅助数据集生成——经常利用预训练扩散模型（DM）。然而，现有的基于DM的OSFL方法通常采用分类器引导的DM，这需要在每个客户端上训练辅助分类模型，从而引入额外的计算开销。这项工作介绍了一种称为OSCAR的新的一次性联邦学习方法，该方法消除了对辅助模型的需求。&lt;h4&gt;背景&lt;/h4&gt;传统的联邦学习由于多轮通信导致了显著的通信成本，而一次性联邦学习通过仅使用一轮通信来缓解这一问题，但现有的基于扩散模型的方法仍需要在客户端训练分类器，引入额外开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外辅助模型的一次性联邦学习方法，以减少计算和通信成本。&lt;h4&gt;方法&lt;/h4&gt;OSCAR利用基础模型为客户端生成类别特定的数据表示，并将其无缝集成到服务器侧的无分类器扩散模型管道中进行数据生成。&lt;h4&gt;主要发现&lt;/h4&gt;OSCAR是一种简单且成本效益高的一次性联邦学习方法，在四个基准数据集上超越了现有最佳性能，同时减少了至少99%的通信负载。&lt;h4&gt;结论&lt;/h4&gt;通过消除对辅助模型的需求，OSCAR提供了一种更高效的一次性联邦学习解决方案，具有重要的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) enables collaborative learning without datacentralization but introduces significant communication costs due to multiplecommunication rounds between clients and the server. One-shot federatedlearning (OSFL) addresses this by forming a global model with a singlecommunication round, often relying on the server's model distillation orauxiliary dataset generation - often through pre-trained diffusion models(DMs). Existing DM-assisted OSFL methods, however, typically employclassifier-guided DMs, which require training auxiliary classifier models ateach client, introducing additional computation overhead. This work introducesOSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), anovel OSFL approach that eliminates the need for auxiliary models. OSCAR usesfoundation models to devise category-specific data representations at eachclient, seamlessly integrated into a classifier-free diffusion model pipelinefor server-side data generation. OSCAR is a simple yet cost-effective OSFLapproach that outperforms the state-of-the-art on four benchmarking datasetswhile reducing the communication load by at least 99%.</description>
      <author>example@mail.com (Obaidullah Zaland, Shutong Jin, Florian T. Pokorny, Monowar Bhuyan)</author>
      <guid isPermaLink="false">2502.08488v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models in Computational Pathology: A Review of Challenges, Opportunities, and Impact</title>
      <link>http://arxiv.org/abs/2502.08333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  63 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;计算病理学近年来从自我监督的视觉模型发展到对比性视觉语言框架，迅速进步。&lt;h4&gt;背景&lt;/h4&gt;随着数据规模急剧增长以及模型参数量增加至数十亿级别，自动生成的人工智能‘副驾驶’展示了挖掘细微组织线索的能力，并能生成全面报告和回应复杂用户查询。&lt;h4&gt;目的&lt;/h4&gt;探讨这一波新的生成性和多用途AI如何改变临床诊断，并评估基础模型在病理学中的应用及意义。&lt;h4&gt;方法&lt;/h4&gt;回顾了计算病理学中基础模型的快速进展，定义并分析这些模型成为基础、通用或多功能的原因及其对领域的影响。&lt;h4&gt;主要发现&lt;/h4&gt;虽然这些模型展示了卓越的预测和生成能力，但建立全球基准是提高评估标准和促进临床广泛应用的关键。&lt;h4&gt;结论&lt;/h4&gt;前沿AI在计算病理学中的更广泛影响取决于其被接受度和社会认可度。公共曝光虽非必要，但在消除误解、构建信任和支持监管方面依然至关重要。&lt;h4&gt;翻译&lt;/h4&gt;从自我监督的视觉模型到对比性视觉语言框架，计算病理学近年来迅速发展。生成式人工智能‘副驾驶’现在能够挖掘细胞至组织层面微妙且难以察觉的线索，自动生成全面报告并回应复杂用户查询。数据量和可训练参数数量急剧增长的同时，提出了这样一个关键问题：这一波新的生成性和多用途AI将如何改变临床诊断？本文探讨了这些创新的真实潜力及其在临床实践中的应用，并回顾基础模型在病理学领域快速进展的背景，明确其应用及意义。此外，我们仔细研究了基础模型定义，分析使其成为基础、通用或多功能的因素，并评估它们对计算病理学的影响。同时讨论了开发和评价这些模型的独特挑战。尽管已展示出卓越预测和生成能力，但建立全球基准是提高评估标准以及推进临床广泛应用的关键所在。在计算病理学中，前沿AI的更广泛影响最终取决于其被接受度及社会认可度。虽然直接公共接触并非严格必要，但在消除误解、构建信任和支持监管方面依然是强有力的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From self-supervised, vision-only models to contrastive visual-languageframeworks, computational pathology has rapidly evolved in recent years.Generative AI "co-pilots" now demonstrate the ability to mine subtle,sub-visual tissue cues across the cellular-to-pathology spectrum, generatecomprehensive reports, and respond to complex user queries. The scale of datahas surged dramatically, growing from tens to millions of multi-gigapixeltissue images, while the number of trainable parameters in these models hasrisen to several billion. The critical question remains: how will this new waveof generative and multi-purpose AI transform clinical diagnostics? In thisarticle, we explore the true potential of these innovations and theirintegration into clinical practice. We review the rapid progress of foundationmodels in pathology, clarify their applications and significance. Moreprecisely, we examine the very definition of foundational models, identifyingwhat makes them foundational, general, or multipurpose, and assess their impacton computational pathology. Additionally, we address the unique challengesassociated with their development and evaluation. These models havedemonstrated exceptional predictive and generative capabilities, butestablishing global benchmarks is crucial to enhancing evaluation standards andfostering their widespread clinical adoption. In computational pathology, thebroader impact of frontier AI ultimately depends on widespread adoption andsocietal acceptance. While direct public exposure is not strictly necessary, itremains a powerful tool for dispelling misconceptions, building trust, andsecuring regulatory support.</description>
      <author>example@mail.com (Mohsin Bilal, Aadam, Manahil Raza, Youssef Altherwy, Anas Alsuhaibani, Abdulrahman Abduljabbar, Fahdah Almarshad, Paul Golding, Nasir Rajpoot)</author>
      <guid isPermaLink="false">2502.08333v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge Swapping via Learning and Unlearning</title>
      <link>http://arxiv.org/abs/2502.08075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为“知识交换”的新任务，该任务旨在通过选择性地调节预训练模型的知识来实现指定信息的遗忘、保留重要知识并获取新知识。&lt;h4&gt;背景&lt;/h4&gt;增量学习通常从低级表示向高级语义推进，而忘记则往往相反，即从高级语义开始并向低级特征方向进行。&lt;h4&gt;目的&lt;/h4&gt;通过基准测试“先学后忘”的策略来验证在各种任务上的有效性，如图像分类、目标检测和语义分割等。&lt;h4&gt;方法&lt;/h4&gt;基于敲入特征层次分析提出了一种新的知识交换任务，并引入了“学习之前遗忘”（Learning Before Forgetting）的策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了所提出的策略在多个任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;源代码可在https://github.com/xingmingyu123456/KnowledgeSwapping获得，该研究为预训练模型的知识调节提供了一种新的视角和方法。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了知识交换这一新任务，旨在通过选择性地调节预训练模型的知识来实现指定信息的遗忘、保留重要知识并获取新知识。通过对敲入特征层次进行分析，我们发现增量学习通常从低级表示向高级语义推进，而忘记则往往相反，即从高级语义开始并向低级特征方向进行。基于此，我们提出了一种基准测试“先学后忘”的策略来验证在各种任务上的有效性，如图像分类、目标检测和语义分割等。广泛的实验验证了所提出的策略的有效性。源代码可在https://github.com/xingmingyu123456/KnowledgeSwapping获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce \textbf{Knowledge Swapping}, a novel task designed toselectively regulate knowledge of a pretrained model by enabling the forgettingof user\-specified information, retaining essential knowledge, and acquiringnew knowledge simultaneously. By delving into the analysis of knock-on featurehierarchy, we find that incremental learning typically progresses fromlow\-level representations to higher\-level semantics, whereas forgetting tendsto occur in the opposite direction\-starting from high-level semantics andmoving down to low-level features. Building upon this, we propose to benchmarkthe knowledge swapping task with the strategy of \textit{Learning BeforeForgetting}. Comprehensive experiments on various tasks like imageclassification, object detection, and semantic segmentation validate theeffectiveness of the proposed strategy. The source code is available at\href{https://github.com/xingmingyu123456/KnowledgeSwapping}{https://github.com/xingmingyu123456/KnowledgeSwapping}.</description>
      <author>example@mail.com (Mingyu Xing, Lechao Cheng, Shenggeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang)</author>
      <guid isPermaLink="false">2502.08075v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>DOGR: Leveraging Document-Oriented Contrastive Learning in Generative Retrieval</title>
      <link>http://arxiv.org/abs/2502.07219v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'创新性方法': '生成式检索是一种信息检索领域的创新方法，利用生成语言模型（LM）为给定查询生成文档标识符（docid）的排名列表。', '简化流程': '它通过用模型参数替换大型外部索引来简化检索流程。', '现有工作局限': '现有的研究仅学习了查询和文档标识符之间的关系，无法直接表示查询和文档的相关性。', '提出的新框架': '为了克服这个问题，我们提出了一个新颖且通用的生成式检索框架——基于文档导向对比学习的生成式检索（DOGR），利用对比学习改进生成式检索任务。', '两阶段策略': '它采用了一种双阶段学习策略，通过直接交互全面捕捉查询和文档之间的关系。', '增强语义表示': '实现负样本采样方法及相应的对比学习目标以加强语义表示的学习过程，从而促进对查询与文档间关系的深入理解。', '实验结果': '实验结果显示，在两个公开基准数据集上，DOGR的性能优于现有的生成式检索方法。', '通用有效性': '进一步的实验证明我们的框架对于常见的标识符构建技术也具有普遍的有效性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval constitutes an innovative approach in informationretrieval, leveraging generative language models (LM) to generate a ranked listof document identifiers (docid) for a given query. It simplifies the retrievalpipeline by replacing the large external index with model parameters. However,existing works merely learned the relationship between queries and documentidentifiers, which is unable to directly represent the relevance betweenqueries and documents. To address the above problem, we propose a novel andgeneral generative retrieval framework, namely Leveraging Document-OrientedContrastive Learning in Generative Retrieval (DOGR), which leveragescontrastive learning to improve generative retrieval tasks. It adopts atwo-stage learning strategy that captures the relationship between queries anddocuments comprehensively through direct interactions. Furthermore, negativesampling methods and corresponding contrastive learning objectives areimplemented to enhance the learning of semantic representations, therebypromoting a thorough comprehension of the relationship between queries anddocuments. Experimental results demonstrate that DOGR achieves state-of-the-artperformance compared to existing generative retrieval methods on two publicbenchmark datasets. Further experiments have shown that our framework isgenerally effective for common identifier construction techniques.</description>
      <author>example@mail.com (Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo)</author>
      <guid isPermaLink="false">2502.07219v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Filtering Meets Spectrum Shift: Connecting User-Item Interaction with Graph-Structured Side Information</title>
      <link>http://arxiv.org/abs/2502.08071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了在图神经网络（GNN）应用于协同过滤时，当将结构化的侧面信息（如多模态相似性图或社交网络）整合到用户-物品二分图中时，现有方法未能达到令人满意的性能。作者从谱分析的角度定量地解释了这种现象，并提出了一种新的修正方案。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Network (GNN)在协同过滤领域展现了其优越性，而在此过程中使用的用户-物品交互的二部图作为基础的数据格式。然而当加入结构化的侧面信息时，现有方法无法取得理想效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的谱修正方案Spectrum Shift Correction（SSC），以解决上述问题，并提高模型在集成多种侧信源下的表现。&lt;h4&gt;方法&lt;/h4&gt;通过分析频谱的偏移现象，设计了一种新的方法来调整和缩放因子，使GNN能够适应由于引入侧面信息而导致的频谱变化。此方法不需要针对不同类型的结构化数据进行特别的设计。&lt;h4&gt;主要发现&lt;/h4&gt;随着更多侧信源被纳入U-I二部图中，扩展后的邻接矩阵最高频率会逐渐向右移动，导致原有方法分配的重要性与实际情况不匹配。通过引入SSC方案可以有效地解决这一问题。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，在社交推荐和多模态推荐任务上应用SSC可以获得显著的性能提升（高达23%），同时没有增加额外的计算负担。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络在协同过滤中展现了其优越性，其中用户-物品交互的二部图为基本数据格式。然而当引入结构化的侧面信息时，现有方法的表现不尽如人意。通过谱分析可以解释这一现象，并提出了一种新的频谱修正方案Spectrum Shift Correction（SSC），该方案不需要针对特定的数据类型进行特殊设计。实验结果表明在社交和多模态推荐任务中应用SSC可以获得显著的性能提升，且无需增加额外计算负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN) has demonstrated their superiority incollaborative filtering, where the user-item (U-I) interaction bipartite graphserves as the fundamental data format. However, when graph-structured sideinformation (e.g., multimodal similarity graphs or social networks) isintegrated into the U-I bipartite graph, existing graph collaborative filteringmethods fall short of achieving satisfactory performance. We quantitativelyanalyze this problem from a spectral perspective. Recall that a bipartite graphpossesses a full spectrum within the range of [-1, 1], with the highestfrequency exactly achievable at -1 and the lowest frequency at 1; however, weobserve as more side information is incorporated, the highest frequency of theaugmented adjacency matrix progressively shifts rightward. This spectrum shiftphenomenon has caused previous approaches built for the full spectrum [-1, 1]to assign mismatched importance to different frequencies. To this end, wepropose Spectrum Shift Correction (dubbed SSC), incorporating shifting andscaling factors to enable spectral GNNs to adapt to the shifted spectrum.Unlike previous paradigms of leveraging side information, which necessitatetailored designs for diverse data types, SSC directly connects traditionalgraph collaborative filtering with any graph-structured side information.Experiments on social and multimodal recommendation demonstrate theeffectiveness of SSC, achieving relative improvements of up to 23% withoutincurring any additional computational overhead.</description>
      <author>example@mail.com (Yunhang He, Cong Xu, Jun Wang, Wei Zhang)</author>
      <guid isPermaLink="false">2502.08071v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning Effective Dynamics across Spatio-Temporal Scales of Complex Flows</title>
      <link>http://arxiv.org/abs/2502.07990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Parsimony and Learning (CPAL)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Graph-based Learning of Effective Dynamics (Graph-LED)框架，该框架结合图神经网络和基于注意力的自回归模型来从少量仿真数据中提取有效动力学。&lt;h4&gt;背景&lt;/h4&gt;复杂流体流动建模与仿真在科学及工程领域面临挑战。完全尺度解析模拟对于如高度湍流系统而言在未来可预见的时间内不可行，因此需要降阶模型捕捉涉及多时空尺度交互的动力学现象。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于图的深度学习框架来解决复杂流体流动建模与仿真的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了图神经网络（GNN）进行可变大小非结构化网格上的降维以及一个自回归时间注意力模型，以自动学习时间依赖性。GNN能够有效处理复杂的几何形状和非均匀网格。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列流体动力学问题的测试，包括圆柱绕流和后向台阶上流动，在不同雷诺数下显示了对时空物理的有效预测能力。特别是在圆柱绕流的情况下，既准确捕捉到了靠近圆柱的小尺度效应，也准确地捕获了其尾迹。&lt;h4&gt;结论&lt;/h4&gt;Graph-LED框架展示了强大的仿真复杂流体动力学的能力，并且在处理具有挑战性的多尺度问题时显示出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;对复杂流体流动进行建模和仿真是许多科学与工程领域中的基本挑战。对于高度湍流系统等系统的全分辨率模拟，在可预见的未来是不可行的，必须降低阶数模型来捕捉跨多个空间-时间尺度交互的动力学现象。在此工作中，我们提出了一种新的框架——基于图的学习有效动力学（Graph-LED），利用图神经网络（GNN）以及基于注意力的自回归模型，从少量仿真数据中提取有效动力学。GNN在非结构化网格上表示流场作为图形，并且能够有效地处理复杂的几何形状和非均匀格网。所提出的方法结合了可变大小的非结构化网格上的降维（使用GNN）与一个可以自动学习时间依赖性的自回归时序注意力模型。我们在一系列流体动力学问题上评估了该方法，包括在不同雷诺数下的绕圆柱流动和后向台阶流动。结果展示了对时空物理的稳健且有效的预测能力；特别是，在绕圆柱流动的情况下，既准确地捕捉到了靠近圆柱的小尺度效应，也准确地捕获了其尾迹。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling and simulation of complex fluid flows with dynamics that spanmultiple spatio-temporal scales is a fundamental challenge in many scientificand engineering domains. Full-scale resolving simulations for systems such ashighly turbulent flows are not feasible in the foreseeable future, andreduced-order models must capture dynamics that involve interactions acrossscales. In the present work, we propose a novel framework, Graph-based Learningof Effective Dynamics (Graph-LED), that leverages graph neural networks (GNNs),as well as an attention-based autoregressive model, to extract the effectivedynamics from a small amount of simulation data. GNNs represent flow fields onunstructured meshes as graphs and effectively handle complex geometries andnon-uniform grids. The proposed method combines a GNN based, dimensionalityreduction for variable-size unstructured meshes with an autoregressive temporalattention model that can learn temporal dependencies automatically. Weevaluated the proposed approach on a suite of fluid dynamics problems,including flow past a cylinder and flow over a backward-facing step over arange of Reynolds numbers. The results demonstrate robust and effectiveforecasting of spatio-temporal physics; in the case of the flow past acylinder, both small-scale effects that occur close to the cylinder as well asits wake are accurately captured.</description>
      <author>example@mail.com (Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos)</author>
      <guid isPermaLink="false">2502.07990v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing</title>
      <link>http://arxiv.org/abs/2502.07608v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Time2Lang是一个将时间序列基础模型（TFM）的输出直接映射到大型语言模型（LLM）表示的方法，无需中间文本转换。该方法首先使用周期性预测作为预设任务在合成数据上进行训练，并通过心理健康分类任务进行评估。&lt;h4&gt;背景&lt;/h4&gt;当大型语言模型与行为感知数据结合时，在健康应用方面显示出巨大潜力。传统的做法是将传感器数据转换为提示文本，但这种方法容易出错、计算成本高且需要领域专业知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有挑战，并实现TFM和LLM的有效集成。&lt;h4&gt;方法&lt;/h4&gt;Time2Lang框架在合成数据上使用周期性预测作为预设任务进行训练。然后，在两个纵向可穿戴设备和移动感知的数据集上进行了评估：每日抑郁预测（基于步数，17,251天来自256名参与者）；积极生活状态分类（基于对话持续时间，46名参与者10周数据）。&lt;h4&gt;主要发现&lt;/h4&gt;Time2Lang保持了近似恒定的推理时间，不受输入长度影响。生成的嵌入保留了时间序列的基本特征，如自相关性。&lt;h4&gt;结论&lt;/h4&gt;研究表明，可以有效整合TFM和LLM，在减少信息损失的同时，实现性能跨不同模型范式的转移。这是首次将TFM与LLM结合用于健康应用的研究，为未来的复杂医疗任务研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在与行为感知数据结合时对健康应用有巨大潜力。传统方法将传感器数据转换成提示文本，但这种方法容易出错、计算成本高且需要领域专业知识。这里提出Time2Lang框架直接映射TFM输出到LLM表示而无需中间文本转换。该研究使用周期性预测作为预设任务在合成数据上训练模型，并评估其在心理健康分类任务上的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) show promise for health applications whencombined with behavioral sensing data. Traditional approaches convert sensordata into text prompts, but this process is prone to errors, computationallyexpensive, and requires domain expertise. These challenges are particularlyacute when processing extended time series data. While time series foundationmodels (TFMs) have recently emerged as powerful tools for learningrepresentations from temporal data, bridging TFMs and LLMs remains challenging.Here, we present Time2Lang, a framework that directly maps TFM outputs to LLMrepresentations without intermediate text conversion. Our approach first trainson synthetic data using periodicity prediction as a pretext task, followed byevaluation on mental health classification tasks. We validate Time2Lang on twolongitudinal wearable and mobile sensing datasets: daily depression predictionusing step count data (17,251 days from 256 participants) and flourishingclassification based on conversation duration (46 participants over 10 weeks).Time2Lang maintains near constant inference times regardless of input length,unlike traditional prompting methods. The generated embeddings preserveessential time-series characteristics such as auto-correlation. Our resultsdemonstrate that TFMs and LLMs can be effectively integrated while minimizinginformation loss and enabling performance transfer across these distinctmodeling paradigms. To our knowledge, we are the first to integrate a TFM andan LLM for health, thus establishing a foundation for future research combininggeneral-purpose large models for complex healthcare tasks.</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell)</author>
      <guid isPermaLink="false">2502.07608v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Automated Capability Discovery via Model Self-Exploration</title>
      <link>http://arxiv.org/abs/2502.07577v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了自动化能力发现（ACD）框架，该框架利用一个基础模型作为科学家来系统地提出开放性任务以探索另一个主题模型的能力和潜在问题。通过结合前沿模型与开放性的概念，ACD能够自动且全面地揭示出模型的惊人能力和缺陷。&lt;h4&gt;背景&lt;/h4&gt;当前的基础模型已经展示出了跨多个领域的广泛能力，并且存在对这些新模型进行精确定量分析的巨大挑战。现有的评估方法通常需要大量的劳动力和难以设计合适的测试案例来应对更为强大的模型。&lt;h4&gt;目的&lt;/h4&gt;旨在通过自动化的方法，有效发现基础模型的全面能力和潜在风险，降低人工参与的需求。&lt;h4&gt;方法&lt;/h4&gt;提出并实现了ACD框架，该框架利用一个或多个前沿的基础模型作为“科学家”，为被评估的主题模型设计开放性任务，并对其进行自我评价以揭示其能力范围和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;展示ACD在GPT、Claude及Llama系列等不同基础模型上的应用，能够自动识别出成千上万种人工团队难以全面发掘的能力和问题。通过大规模的人工调查验证了机器自评与人类评价之间的一致性。&lt;h4&gt;结论&lt;/h4&gt;利用基础模型自身的任务创建能力和自我评估能力，ACD为新型AI系统的可扩展自动化评估提供了一条重要的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要中介绍的论文内容包括开发了一个名为自动能力发现（Automated Capability Discovery, ACD）的新框架。该框架通过指定一个基础模型作为“科学家”，系统性地提议开放性的任务，以探测另一个主体模型的能力与潜在风险。ACD结合了前沿的基础模型和关于开放式探索的想法，能够自动且全面揭示主题模型的惊人能力和失败点。研究成果涵盖多个系列的基础模型（包括GPT、Claude以及Llama等），展示出成千上万种人工团队难以发现的能力，并通过大规模的人类调查验证了机器自评与人类评估的一致性。该框架为新型AI系统的可扩展和自动化评价提供了重要的途径。所有代码及评估日志均开源在GitHub上：https://github.com/conglu1997/ACD&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have become general-purpose assistants, exhibiting diversecapabilities across numerous domains through training on web-scale data. Itremains challenging to precisely characterize even a fraction of the fullspectrum of capabilities and potential risks in any new model. Existingevaluation approaches often require significant human effort, and it is takingincreasing effort to design ever harder challenges for more capable models. Weintroduce Automated Capability Discovery (ACD), a framework that designates onefoundation model as a scientist to systematically propose open-ended tasksprobing the abilities of a subject model (potentially itself). By combiningfrontier models with ideas from the field of open-endedness, ACD automaticallyand systematically uncovers both surprising capabilities and failures in thesubject model. We demonstrate ACD across a range of foundation models(including the GPT, Claude, and Llama series), showing that it automaticallyreveals thousands of capabilities that would be challenging for any single teamto uncover. We further validate our method's automated scoring with extensivehuman surveys, observing high agreement between model-generated and humanevaluations. By leveraging foundation models' ability to both create tasks andself-evaluate, ACD is a significant step toward scalable, automated evaluationof novel AI systems. All code and evaluation logs are open-sourced athttps://github.com/conglu1997/ACD.</description>
      <author>example@mail.com (Cong Lu, Shengran Hu, Jeff Clune)</author>
      <guid isPermaLink="false">2502.07577v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</title>
      <link>http://arxiv.org/abs/2502.00568v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为PathGen的新模型，该模型基于扩散生成AI技术，能够从数字病理图像合成基因表达信息，并利用这些信息准确预测癌症分级和患者生存风险。&lt;h4&gt;背景&lt;/h4&gt;现有的研究显示，通过结合数字病理学和转录组特征的人工智能多模态融合方法可以改善癌症诊断（分级/亚型）和预后（存活率）的预测。然而，在实际临床环境中直接使用这种融合技术进行联合决策是不现实的。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于扩散生成AI的新模型PathGen，该模型能够从数字病理图像合成基因表达信息，并利用这些合成的信息来准确预测癌症分级和患者生存风险。&lt;h4&gt;方法&lt;/h4&gt;采用了一种新的扩散基跨模态生成AI模型PathGen。通过此模型可以将来自数字病理学的模式转换为对应的转录组特征，进而进行癌症诊断和预后分析。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够利用合成的基因表达信息准确预测癌症分级和患者生存风险，并且其性能达到了当前领域的最高标准；同时，它还提供了确定性（通过符合保证覆盖）和可解释性（通过分布注意力图）。&lt;h4&gt;结论&lt;/h4&gt;PathGen提供了一种实用的方法来从数字病理学图像合成转录组信息，这对于提高癌症诊断的准确性和预后的预测具有重要的意义。&lt;h4&gt;翻译&lt;/h4&gt;新兴的研究表明，基于人工智能的多模态融合方法能够改善利用数字病理学和转录组特征进行癌症诊断（分级/亚型）及预后（存活率）预测。然而，在实际临床环境中直接使用这种联合决策的方法是不现实的，因为组织病理学仍然是诊断的金标准，并且转录组测试在公共医疗系统中很少被要求。借助我们新的基于扩散的跨模态生成AI模型PathGen，我们证明了从数字组织病理学合成的基因表达信息能够准确预测癌症分级和患者生存风险（性能达到当前领域的最高标准），并提供了确定性和可解释性。PathGen代码在GitHub上开放使用，网址为https://github.com/Samiran-Dey/PathGen。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Samiran-Dey/PathoGen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging research has highlighted that artificial intelligence basedmultimodal fusion of digital pathology and transcriptomic features can improvecancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.However, such direct fusion for joint decision is impractical in real clinicalsettings, where histopathology is still the gold standard for diagnosis andtranscriptomic tests are rarely requested, at least in the public healthcaresystem. With our novel diffusion based crossmodal generative AI model PathGen,we show that genomic expressions synthesized from digital histopathologyjointly predicts cancer grading and patient survival risk with high accuracy(state-of-the-art performance), certainty (through conformal coverageguarantee) and interpretability (through distributed attention maps). PathGencode is available for open use by the research community through GitHub athttps://github.com/Samiran-Dey/PathGen.</description>
      <author>example@mail.com (Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2502.00568v3</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Technical note on calibrating vision-language models under covariate shift</title>
      <link>http://arxiv.org/abs/2502.07847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于缓解低样本视觉分类任务中的协变量偏移和置信度错配问题的统一框架$C3SC$。&lt;h4&gt;背景&lt;/h4&gt;虽然视觉-语言基础模型在低样本视觉分类中取得了成功，但由于样本不足，它们对数据分布的变化敏感。常用的方法是通过多个数据集进行微调，但这在实践中成本高昂。&lt;h4&gt;目的&lt;/h4&gt;研究如何同时解决预训练数据和目标数据之间的协变量偏移以及由于数据稀缺导致的置信度错配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了$C3SC$框架，该框架利用Fisher信息罚分来纠正协变量偏移，并使用置信度误分类惩罚(CMP)来降低对错误分类样本的信心。&lt;h4&gt;主要发现&lt;/h4&gt;$C3SC$在各种视觉和协变量偏移数据集上的实验结果表明，它显著改善了校准（ECE）最多提高了5.82%，并且由于在具有挑战性的协变量偏移数据集上准确率提高3.5%而表现出更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;$C3SC$是解决分布变化下视觉-语言低样本应用场景可靠性问题的有希望的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：尽管作为新兴能力的成功案例，用于低样本视觉分类的视觉-语言基础模型由于样本不足而对数据的变化敏感。常用的方法是在多个数据集上进行微调以解决领域泛化的问题，但这在实践中成本高昂。这项工作同时研究了预训练数据和未具体说明的目标数据之间的协变量偏移以及置信度错配问题（即有限的数据可用性导致模型预测信心的放大）。我们提出了$C3SC$框架，用于缓解协变量偏移和置信度错配。$C3SC$利用Fisher信息罚分来纠正协变量偏移，并使用置信度误分类惩罚(CMP)来降低对错误分类样本的信心。在各种视觉和协变量偏移数据集上的实验结果表明，$C3SC$显著改善了校准（ECE）最多提高了5.82%，并且由于在具有挑战性的协变量偏移数据集上准确率提高3.5%而表现出更好的鲁棒性。这使得$C3SC$成为解决分布变化下视觉-语言低样本应用场景可靠性问题的有希望的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite being a successful example of emerging capability, vision-languagefoundation models for low-shot vision classification have a limited ability tosufficiently generalize to the target data distribution due to sample poverty,leading to sensitivity to variations in the data. A popular mitigation strategyis finetuning over multiple datasets, but domain generalization is expensivewhen practiced in this manner. This work examines both covariate shift betweenpre-training data and the underspecified target data, and \textit{confidencemisalignment}, where the model's prediction confidence amplified by the limiteddata availability. We propose \textit{Confidence-Calibrated Covariate ShiftCorrection ($C3SC$)}, a unified framework to mitigate both covariate shift andconfidence misalignment. $C3SC$ leverages Fisher information penalty forcovariate shift correction and confidence misalignment penalty (CMP) to lowerconfidence on misclassified examples. Experimental results across variousvision and covariate shift datasets demonstrates that $C3SC$ significantlyimproves in calibration (ECE) by $5.82\%$ at maximum. $C3SC$ shows betterrobustness as well by showing $3.5\%$ improvement in accuracy metric onchallenging covariate shift datasets, making $C3SC$ a promising solution forreliable real-world vision-language low-shot applications under distributionshift.</description>
      <author>example@mail.com (Behraj Khan, Rizwan Qureshi, Tahir Syed)</author>
      <guid isPermaLink="false">2502.07847v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Unpaired Image Dehazing via Kolmogorov-Arnold Transformation of Latent Features</title>
      <link>http://arxiv.org/abs/2502.07812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于Kolmogorov-Arnold变换的无监督图像去雾框架UID-KAT，该框架利用了对抗训练和对比学习来提高性能。&lt;h4&gt;背景&lt;/h4&gt;图像去雾被看作是一个具有挑战性的视觉任务，并且需要复杂的变换和解释。最近引入的Kolmogorov-Arnold网络（KANs）由于其高效的多项式基础，为复杂函数提供了一种比多层感知机更有效的逼近方法。&lt;h4&gt;目的&lt;/h4&gt;探索结合使用对抗训练、对比学习以及KAN来建立图像去雾模型，以利用无监督设置中的大量真实世界数据进行去雾任务。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的UID-KAT框架：在该框架中，Kolmogorov-Arnold网络（KANs）被用作基础神经网络，并通过对抗训练和对比学习来增强其模型的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的UID-KAT框架在多个数据集和场景上达到了最先进的去雾性能，在减少模型复杂性的同时超越了现有的无配对方法。&lt;h4&gt;结论&lt;/h4&gt;该工作展示了KAN结合对抗训练和对比学习的有效性，并且提供了一种新颖的图像去雾方法。代码可在GitHub上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an innovative framework for Unsupervised Image Dehazingvia Kolmogorov-Arnold Transformation, termed UID-KAT. Image dehazing isrecognized as a challenging and ill-posed vision task that requires complextransformations and interpretations in the feature space. Recent advancementshave introduced Kolmogorov-Arnold Networks (KANs), inspired by theKolmogorov-Arnold representation theorem, as promising alternatives toMulti-Layer Perceptrons (MLPs) since KANs can leverage their polynomialfoundation to more efficiently approximate complex functions while requiringfewer layers than MLPs. Motivated by this potential, this paper explores theuse of KANs combined with adversarial training and contrastive learning tomodel the intricate relationship between hazy and clear images. Adversarialtraining is employed due to its capacity in producing high-fidelity images, andcontrastive learning promotes the model's emphasis on significant featureswhile suppressing the influence of irrelevant information. The proposed UID-KATframework is trained in an unsupervised setting to take advantage of theabundance of real-world data and address the challenge of preparing pairedhazy/clean images. Experimental results show that UID-KAT achievesstate-of-the-art dehazing performance across multiple datasets and scenarios,outperforming existing unpaired methods while reducing model complexity. Thesource code for this work is publicly available athttps://github.com/tranleanh/uid-kat.</description>
      <author>example@mail.com (Le-Anh Tran)</author>
      <guid isPermaLink="false">2502.07812v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>CrossVideoMAE: Self-Supervised Image-Video Representation Learning with Masked Autoencoders</title>
      <link>http://arxiv.org/abs/2502.07811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的视频自监督学习模型CrossVideoMAE，旨在同时从视频级别和帧级别有效学习空间时间表示和语义属性。&lt;h4&gt;背景&lt;/h4&gt;当前的基于视频的Masked Autoencoders (MAEs) 主要关注于从视觉角度学习有效的时空表示，可能会优先考虑一般的时空模式而忽视特定交互或序列等细微的语义属性。此外，现有的视频MAE与静态图像MAE使用独立的数据集，这可能缺乏理解所学概念所需的丰富语义属性。&lt;h4&gt;目的&lt;/h4&gt;为了更好地利用视频和对应采样帧图片中的信息，本文提出了CrossVideoMAE模型，该模型旨在整合视频中相互的空间时间信息以及从采样帧中获得的空间信息，并鼓励在视频域内的增强不变性。&lt;h4&gt;方法&lt;/h4&gt;CrossVideoMAE通过联合嵌入可见令牌的特征并结合跨模态和同模态内部的特征对应关系，在自监督学习方式下，可以从视频和帧图像模式中获取丰富的无标签引导信号。此模型是在一种特性不变的空间内进行工作的。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在多个基准数据集上超越了当前最先进的技术，并且消融研究表明该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;CrossVideoMAE通过集成视频和帧图像中的信息，在自监督学习框架下实现了有效的空间时间表示和语义属性的学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current video-based Masked Autoencoders (MAEs) primarily focus on learningeffective spatiotemporal representations from a visual perspective, which maylead the model to prioritize general spatial-temporal patterns but oftenoverlook nuanced semantic attributes like specific interactions or sequencesthat define actions - such as action-specific features that align more closelywith human cognition for space-time correspondence. This can limit the model'sability to capture the essence of certain actions that are contextually richand continuous. Humans are capable of mapping visual concepts, object viewinvariance, and semantic attributes available in static instances to comprehendnatural dynamic scenes or videos. Existing MAEs for videos and static imagesrely on separate datasets for videos and images, which may lack the richsemantic attributes necessary for fully understanding the learned concepts,especially when compared to using video and corresponding sampled frame imagestogether. To this end, we propose CrossVideoMAE an end-to-end self-supervisedcross-modal contrastive learning MAE that effectively learns both video-leveland frame-level rich spatiotemporal representations and semantic attributes.Our method integrates mutual spatiotemporal information from videos withspatial information from sampled frames within a feature-invariant space, whileencouraging invariance to augmentations within the video domain. This objectiveis achieved through jointly embedding features of visible tokens and combiningfeature correspondence within and across modalities, which is critical foracquiring rich, label-free guiding signals from both video and frame imagemodalities in a self-supervised manner. Extensive experiments demonstrate thatour approach surpasses previous state-of-the-art methods and ablation studiesvalidate the effectiveness of our approach.</description>
      <author>example@mail.com (Shihab Aaqil Ahamed, Malitha Gunawardhana, Liel David, Michael Sidorov, Daniel Harari, Muhammad Haris Khan)</author>
      <guid isPermaLink="false">2502.07811v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Re$^3$Sim: Generating High-Fidelity Simulation Data via 3D-Photorealistic Real-to-Sim for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.08645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RE$^3$SIM是一个从真实世界到仿真环境的系统，旨在通过先进的三维重建和神经渲染技术解决现实与模拟之间的几何差异和视觉差距问题。&lt;h4&gt;背景&lt;/h4&gt;真实的机器人数据收集非常昂贵且资源密集型，需要熟练的操作员和昂贵的硬件。虽然仿真提供了一种可扩展的替代方案，但通常因为几何和视觉上的差异难以实现从模拟到真实的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出一个3D-逼真的现实到仿真系统RE$^3$SIM来解决几何和视觉差距问题，并在各种操作任务场景中验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;RE$^3$SIM利用先进的三维重建技术将真实世界环境精准还原，并通过神经渲染实现在基于物理的模拟器中的实时交叉视角摄像机渲染。系统还利用专家示范数据高效地进行模仿学习训练。&lt;h4&gt;主要发现&lt;/h4&gt;仅使用仿真数据，该系统可以实现超过58%平均成功率的零样本从模拟到现实的迁移。此外，生成了一个大规模的仿真数据集来展示如何通过仿真数据建立稳健的策略并在不同对象上泛化。&lt;h4&gt;结论&lt;/h4&gt;RE$^3$SIM提供了一种有效的途径解决机器人领域中的模拟到真实问题，并展示了在多种操作任务场景下的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;现实世界中，机器人数据收集成本高昂且资源密集型。仿真作为一种替代方案虽然具备可扩展性，但常常因为几何和视觉差距而无法达到从模拟到真实的泛化效果。为了解决这些问题，我们提出了一个名为RE$^3$SIM的3D-逼真从真实环境转到仿真的系统，专门解决几何和视觉上的差异问题。该系统采用先进的三维重建技术和神经渲染技术来重现现实场景，并在基于物理的模拟器中实现交叉视角摄像机的实时渲染。通过利用专家示范数据有效地收集仿真中的演示并使用模仿学习训练机器人策略，我们在各种操作任务场景验证了从真实到仿真的管线的有效性。值得注意的是，在没有实际数据的情况下，我们仅用仿真数据就能达到超过58%平均成功率的零样本迁移效果。为了进一步推动现实到模拟技术的应用边界，我们还生成了一个大规模的仿真数据集来展示如何通过仿真数据建立稳健策略并在不同物体上进行泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world data collection for robotics is costly and resource-intensive,requiring skilled operators and expensive hardware. Simulations offer ascalable alternative but often fail to achieve sim-to-real generalization dueto geometric and visual gaps. To address these challenges, we propose a3D-photorealistic real-to-sim system, namely, RE$^3$SIM, addressing geometricand visual sim-to-real gaps. RE$^3$SIM employs advanced 3D reconstruction andneural rendering techniques to faithfully recreate real-world scenarios,enabling real-time rendering of simulated cross-view cameras within aphysics-based simulator. By utilizing privileged information to collect expertdemonstrations efficiently in simulation, and train robot policies withimitation learning, we validate the effectiveness of the real-to-sim-to-realpipeline across various manipulation task scenarios. Notably, with onlysimulated data, we can achieve zero-shot sim-to-real transfer with an averagesuccess rate exceeding 58%. To push the limit of real-to-sim, we furthergenerate a large-scale simulation dataset, demonstrating how a robust policycan be built from simulation data that generalizes across various objects.Codes and demos are available at: http://xshenhan.github.io/Re3Sim/.</description>
      <author>example@mail.com (Xiaoshen Han, Minghuan Liu, Yilun Chen, Junqiu Yu, Xiaoyang Lyu, Yang Tian, Bolun Wang, Weinan Zhang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.08645v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems</title>
      <link>http://arxiv.org/abs/2502.06581v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了云边端协同（CETC）系统在分布式视频分析中的应用，包括架构组件、边缘计算平台和资源管理机制，并探讨了面向边缘的方法与基于云端的方法，以及混合视频分析技术。&lt;h4&gt;背景&lt;/h4&gt;随着视频数据的爆炸性增长，云边端协作系统的分布式视频分析得到了快速发展，推动了视频处理效率、实时推断及隐私保护方面的突破。CETC系统能够分布视频处理任务，并在云、边缘和终端设备间进行自适应分析。&lt;h4&gt;目的&lt;/h4&gt;本文综述了CETC系统中的基本架构组件，包括分层式、分布式和混合框架，以及边缘计算平台和资源管理机制。文章还探讨了面向边缘的方法和基于云端的方法，以及混合视频分析技术的最新进展，并讨论了这些技术所带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;本文首先分析了基础架构组件，如分层、分布和混合框架，以及边缘计算平台和资源配置机制；接着介绍了以边缘为中心的方法（包括本地处理、边缘辅助卸载等）和基于云端的方法（利用强大的算力进行复杂的视频理解和模型训练）。此外还探讨了结合自适应任务卸载和资源感知调度技术的混合视频分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究涵盖了面向边缘的方法，强调设备上的处理、边缘辅助卸载和智能。同时，也介绍了基于云的方法，通过强大的计算能力支持复杂视频理解与模型训练。此外，还探讨了结合自适应任务卸载及资源感知调度技术的混合视频分析。&lt;h4&gt;结论&lt;/h4&gt;未来的研究方向包括可解释系统、高效处理机制以及高级视频分析，为该领域提供了宝贵的见解。然而，大型语言模型和多模态集成的发展也揭示了平台扩展性、数据保护与系统可靠性方面的挑战。&lt;h4&gt;翻译&lt;/h4&gt;随着视频数据的爆炸性增长，云边端协同（CETC）系统在分布式视频分析中的作用越来越重要，这不仅推动了高效的视频处理和实时推断，而且还促进了隐私保护技术的发展。本文综述了该领域的架构组件、边缘计算平台及资源管理机制，并探讨了面向边缘的方法与基于云端的方法以及混合视频分析技术的最新进展及其带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of video data has driven the development of distributedvideo analytics in cloud-edge-terminal collaborative (CETC) systems, enablingefficient video processing, real-time inference, and privacy-preservinganalysis. Among multiple advantages, CETC systems can distribute videoprocessing tasks and enable adaptive analytics across cloud, edge, and terminaldevices, leading to breakthroughs in video surveillance, autonomous driving,and smart cities. In this survey, we first analyze fundamental architecturalcomponents, including hierarchical, distributed, and hybrid frameworks,alongside edge computing platforms and resource management mechanisms. Buildingupon these foundations, edge-centric approaches emphasize on-device processing,edge-assisted offloading, and edge intelligence, while cloud-centric methodsleverage powerful computational capabilities for complex video understandingand model training. Our investigation also covers hybrid video analyticsincorporating adaptive task offloading and resource-aware scheduling techniquesthat optimize performance across the entire system. Beyond conventionalapproaches, recent advances in large language models and multimodal integrationreveal both opportunities and challenges in platform scalability, dataprotection, and system reliability. Future directions also encompassexplainable systems, efficient processing mechanisms, and advanced videoanalytics, offering valuable insights for researchers and practitioners in thisdynamic field.</description>
      <author>example@mail.com (Linxiao Gong, Hao Yang, Gaoyun Fang, Bobo Ju, Juncen Guo, Xiaoguang Zhu, Yan Wang, Xiping Hu, Peng Sun, Azzedine Boukerche)</author>
      <guid isPermaLink="false">2502.06581v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards</title>
      <link>http://arxiv.org/abs/2502.08643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025, Project Page: https://iker-robot.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了IKER（迭代关键点奖励）这一视觉基础的Python奖励函数，用于动态任务定义，并展示了在仿真和真实环境中的应用。&lt;h4&gt;背景&lt;/h4&gt;机器人操纵任务规范在开放世界环境中具有挑战性，需要灵活适应的人类意图导向的目标，在迭代反馈中进化。&lt;h4&gt;目的&lt;/h4&gt;通过引入IKER框架解决多步骤操作任务的视觉奖励函数生成与优化问题。&lt;h4&gt;方法&lt;/h4&gt;使用VLM（视觉语言模型）根据RGB-D观察和自由形式的语言指令生成关键点，并据此构建和细化奖励函数。这些奖励在仿真环境中训练强化学习策略，然后部署到真实世界中，形成从现实到模拟再到现实的循环。&lt;h4&gt;主要发现&lt;/h4&gt;IKER展示出在多种场景中的显著能力，包括灵巧与非灵巧任务执行、自发错误恢复以及即时策略调整。&lt;h4&gt;结论&lt;/h4&gt;结果证明了通过迭代奖励优化使得机器人能够完成动态环境下的多步骤任务的有效性。&lt;h4&gt;翻译&lt;/h4&gt;任务规范对于开放世界的机器人操作来说具有挑战性，需要灵活适应的人类意图导向的目标，并且能够在迭代反馈中进化。我们引入IKER（迭代关键点奖励），这是一种以视觉为基础的Python奖励函数，用作动态任务规范。我们的框架利用VLM生成并优化这些用于多步骤操作任务的奖励函数。通过RGB-D观察和自由形式的语言指令，在场景中采样关键点，并以此构建条件化的奖励函数。IKER基于关键点的空间关系运作，利用关于期望行为的常识先验知识，并实现精确的SE(3)控制。我们重建现实世界的场景并在仿真环境中使用生成的奖励训练强化学习策略，然后将其部署到真实世界——形成从现实到模拟再到现实的循环。我们的方法在各种场景中展示了显著的能力，包括灵巧和非灵巧任务，展示出多步骤任务执行、自发错误恢复及即时策略调整。结果突显了IKER通过迭代奖励优化使机器人能够完成动态环境下的多步骤操作的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Task specification for robotic manipulation in open-world environments ischallenging, requiring flexible and adaptive objectives that align with humanintentions and can evolve through iterative feedback. We introduce IterativeKeypoint Reward (IKER), a visually grounded, Python-based reward function thatserves as a dynamic task specification. Our framework leverages VLMs togenerate and refine these reward functions for multi-step manipulation tasks.Given RGB-D observations and free-form language instructions, we samplekeypoints in the scene and generate a reward function conditioned on thesekeypoints. IKER operates on the spatial relationships between keypoints,leveraging commonsense priors about the desired behaviors, and enabling preciseSE(3) control. We reconstruct real-world scenes in simulation and use thegenerated rewards to train reinforcement learning (RL) policies, which are thendeployed into the real world-forming a real-to-sim-to-real loop. Our approachdemonstrates notable capabilities across diverse scenarios, including bothprehensile and non-prehensile tasks, showcasing multi-step task execution,spontaneous error recovery, and on-the-fly strategy adjustments. The resultshighlight IKER's effectiveness in enabling robots to perform multi-step tasksin dynamic environments through iterative reward shaping.</description>
      <author>example@mail.com (Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li)</author>
      <guid isPermaLink="false">2502.08643v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Robot Data Curation with Mutual Information Estimators</title>
      <link>http://arxiv.org/abs/2502.08623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Videos and code at https://jhejna.github.io/demonstration-info&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估机器人模仿学习数据质量的新技术，该技术基于k-近邻估计和简单的VAE嵌入来衡量状态多样性和动作预测性。&lt;h4&gt;背景&lt;/h4&gt;随着机器人领域对模仿学习的重视增加，用于训练机器人的示范数据集也在不断扩充。然而，尽管收集的数据量显著增大，对其质量评估的研究却相对较少。&lt;h4&gt;目的&lt;/h4&gt;研究旨在估计单个示例在整体数据集中所贡献的状态多样性和动作预测性的相对质量，并据此提升机器人模仿学习的表现。&lt;h4&gt;方法&lt;/h4&gt;通过计算整个数据集内状态和动作之间的互信息来衡量每条轨迹的平均贡献。使用基于k-近邻估计的新技术结合简单的VAE嵌入，解决了传统互信息估算器对大数据量的需求问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，本研究的方法能够根据人类专家评分准确地将示范数据集按质量分类，并且基于该方法过滤后的训练策略在RoboMimic、真实环境下的ALOHA和Franka设置中表现更好。&lt;h4&gt;结论&lt;/h4&gt;提出的新技术为评估机器人模仿学习的数据质量提供了有力的工具，有助于提高机器人的学习性能。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习策略的表现往往依赖于它们训练所用的数据集。因此，在工业界和学术实验室中，用于机器人数据收集的投资正在增加。然而，尽管收集到的示范数量显著增加，很少有工作试图评估这些数据的质量，尤其是在视觉和语言领域，越来越多证据表明其重要性。在这项工作中，我们朝着解决机器人领域的数据质量这一问题迈出了重要的一步。对于给定的一组演示集，我们的目标是估计单个演示在状态多样性和动作预测性方面相对质量。为此，我们估算了一条轨迹对整个数据集中状态与动作之间互信息的平均贡献，这可以精确捕捉状态分布的熵以及基于状态的动作条件熵。虽然常用的互信息估计器需要大量数据，这些数据通常超出机器人领域的规模，但我们提出了一种新颖的技术，该技术基于k-近邻的互信息估计和简单的VAE嵌入的状态与动作。从经验上讲，我们展示了我们的方法能够根据人类专家评分将示范数据集按质量划分，并且在一系列跨越模拟环境的真实世界环境中都有很好的表现。此外，使用通过我们方法过滤后的数据训练策略，在RoboMimic中导致了5-10%的性能提升，并在真实世界的ALOHA和Franka设置中的表现更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of imitation learning policies often hinges on the datasetswith which they are trained. Consequently, investment in data collection forrobotics has grown across both industrial and academic labs. However, despitethe marked increase in the quantity of demonstrations collected, little workhas sought to assess the quality of said data despite mounting evidence of itsimportance in other areas such as vision and language. In this work, we take acritical step towards addressing the data quality in robotics. Given a datasetof demonstrations, we aim to estimate the relative quality of individualdemonstrations in terms of both state diversity and action predictability. Todo so, we estimate the average contribution of a trajectory towards the mutualinformation between states and actions in the entire dataset, which preciselycaptures both the entropy of the state distribution and the state-conditionedentropy of actions. Though commonly used mutual information estimators requirevast amounts of data often beyond the scale available in robotics, we introducea novel technique based on k-nearest neighbor estimates of mutual informationon top of simple VAE embeddings of states and actions. Empirically, wedemonstrate that our approach is able to partition demonstration datasets byquality according to human expert scores across a diverse set of benchmarksspanning simulation and real world environments. Moreover, training policiesbased on data filtered by our method leads to a 5-10% improvement in RoboMimicand better performance on real ALOHA and Franka setups.</description>
      <author>example@mail.com (Joey Hejna, Suvir Mirchandani, Ashwin Balakrishna, Annie Xie, Ayzaan Wahid, Jonathan Tompson, Pannag Sanketi, Dhruv Shah, Coline Devin, Dorsa Sadigh)</author>
      <guid isPermaLink="false">2502.08623v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Direction Finding for Software Defined Radios with Switched Uniform Circular Arrays</title>
      <link>http://arxiv.org/abs/2502.08592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 8 figures, IEEE IMS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种成本效益高的连续波信号方向估计系统，适用于2.4GHz ISM频段。&lt;h4&gt;背景&lt;/h4&gt;精确的方向到达（DoA）估计对于机器人技术和通信应用至关重要，但一致多通道接收机的高成本和复杂性阻碍了其普及。&lt;h4&gt;目的&lt;/h4&gt;开发一种低成本且硬件复杂度低的连续波信号方向到达估计系统。&lt;h4&gt;方法&lt;/h4&gt;使用带有时间分割复用功能的两通道软件定义无线电（SDR）以及中央参考天线来模拟相干采样，从而减少相位抖动和采样误差。采用增强型MUSIC算法结合空间平滑处理以解决轻度多路径干扰问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验在消声室中验证了理想条件下的准确性，在现实环境中的测试确认系统具备优秀的抗多径干扰性能。&lt;h4&gt;结论&lt;/h4&gt;该系统提供了实时和可靠的DoA估计解决方案，每秒5次更新，并通过后期处理进一步增强追踪能力。&lt;h4&gt;翻译&lt;/h4&gt;准确的方向到达（DoA）估计对于机器人技术及通信应用至关重要，然而一致性的多通道接收机因成本高昂与复杂性而难以普及。本研究提出了一种在2.4GHz ISM频段对连续波信号进行方向估计的经济型系统。此方案采用带有时间分割复用功能的两通道软件定义无线电（SDR）结合八单元圆形阵列实现伪相干采样，同时利用中央参考天线来减少相位抖动与采样误差问题。该系统引入了增强MUSIC算法并结合空间平滑处理以应对室内及室外环境中的轻微多径干扰情况。在消声室内的实验验证了理想条件下的准确性，而真实世界测试则证明了其具备强大的抗多路径干扰能力。通过每秒5次DoA更新率和后期优化处理进一步增强了追踪性能，从而为实际应用提供了可行且可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate Direction of Arrival (DoA) estimation is critical for applicationsin robotics and communication, but high costs and complexity of coherentmulti-channel receivers hinder accessibility. This work proposes acost-effective DoA estimation system for continuous wave (CW) signals in the2.4 GHz ISM band. A two-channel software-defined radio (SDR) with time-divisionmultiplexing (TDM) enables pseudo-coherent sampling of an eight-element uniformcircular array (UCA) with low hardware complexity. A central reference antennamitigates phase jitter and sampling errors. The system applies an enhancedMUSIC algorithm with spatial smoothing to handle light multipath interferencein indoor and outdoor environments. Experiments in an anechoic chamber validateaccuracy under ideal conditions, while real-world tests confirm robustperformance in multipath-prone scenarios. With 5 Hz DoA updates andpost-processing to enhance tracking, the system provides an accessible andreliable solution for DoA estimation in real-world environments.</description>
      <author>example@mail.com (Lennart Werner, Markus Gardill, Marco Hutter)</author>
      <guid isPermaLink="false">2502.08592v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Group and Grasp Multiple Objects</title>
      <link>http://arxiv.org/abs/2502.08452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于模仿学习的方法，用于解决机器人同时抓取和运输多个物体时的问题，通过收集专家操作的数据来训练扩散策略网络，使机器人能够自动生成推动、分组和抓取的行动序列。&lt;h4&gt;背景&lt;/h4&gt;同时抓取并运输多个物体可以显著提高机器人的工作效率，并且已经成为了几十年来的关键研究焦点。主要挑战在于如何在考虑物体分布和机器人硬件限制的情况下执行推动、分组及同步抓取操作。&lt;h4&gt;目的&lt;/h4&gt;解决现有基于规则的方法难以灵活适应不同场景的问题，提出一种新的模仿学习方法来优化多对象的抓取与运输策略。&lt;h4&gt;方法&lt;/h4&gt;通过远程控制收集一系列专家演示数据，并训练一个扩散策略网络。该网络能够使机器人动态生成推动、分组和抓取的动作序列，以促进高效的多物体抓取和搬运。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的方法可以在不同规模的训练集大小、变化的对象数量以及真实世界对象场景下有效地自适应地生成多物体分组与抓取策略。随着更多训练数据的支持，模仿学习有望成为解决多对象抓取问题的有效方法。&lt;h4&gt;结论&lt;/h4&gt;基于模仿学习的机器人操作策略展示出了处理复杂多物体系统的强大能力，并预示着在实际应用中的潜力和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneously grasping and transporting multiple objects can significantlyenhance robotic work efficiency and has been a key research focus for decades.The primary challenge lies in determining how to push objects, group them, andexecute simultaneous grasping for respective groups while considering objectdistribution and the hardware constraints of the robot. Traditional rule-basedmethods struggle to flexibly adapt to diverse scenarios. To address thischallenge, this paper proposes an imitation learning-based approach. We collecta series of expert demonstrations through teleoperation and train a diffusionpolicy network, enabling the robot to dynamically generate action sequences forpushing, grouping, and grasping, thereby facilitating efficient multi-objectgrasping and transportation. We conducted experiments to evaluate the methodunder different training dataset sizes, varying object quantities, andreal-world object scenarios. The results demonstrate that the proposed approachcan effectively and adaptively generate multi-object grouping and graspingstrategies. With the support of more training data, imitation learning isexpected to be an effective approach for solving the multi-object graspingproblem.</description>
      <author>example@mail.com (Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada)</author>
      <guid isPermaLink="false">2502.08452v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Robot-Initiated Social Control of Sedentary Behavior: Comparing the Impact of Relationship- and Target-Focused Strategies</title>
      <link>http://arxiv.org/abs/2502.08428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to HRI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了社交机器人使用人际关系导向策略和目标导向策略来鼓励人们减少久坐行为的有效性。&lt;h4&gt;背景&lt;/h4&gt;为了设计有效的社会机器人以促进健康行为的改变，了解人们如何对这些机器人的不同健康沟通策略做出反应至关重要。&lt;h4&gt;目的&lt;/h4&gt;探究来自社会机器人的两种类型的社会控制策略（关系聚焦策略和目标聚焦策略）在鼓励人们减少久坐行为方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;进行了一项两阶段实验室实验(n = 135)，参与者先与机器人玩一个游戏，然后由机器人使用其中一种策略说服他们站起来活动。一半的参与者参加了第二阶段以重复与机器人的互动。&lt;h4&gt;主要发现&lt;/h4&gt;关系聚焦策略激励参与者保持活跃的时间更长；重复会话并没有增强参与者对机器人的依恋感，但那些感到更加依附于机器人的参与者对目标聚焦策略有更为积极的回应。&lt;h4&gt;结论&lt;/h4&gt;研究结果为设计用于健康沟通环境中的社交机器人说服策略提供了宝贵的见解。&lt;h4&gt;翻译&lt;/h4&gt;为了设计能够有效促进健康行为改变的社会机器人，了解人们如何响应这些机器人所采用的各种健康传播策略至关重要。这项研究探讨了两种类型的社会控制策略——关系导向策略（强调人际关系后果）和目标导向策略（强调健康后果），在鼓励减少久坐行为方面的有效性。一项两阶段实验室实验(n = 135)被开展，其中参与者首先与一个机器人玩游戏，然后让该机器人使用一种策略说服他们站起来活动。一半的参与者参加了第二阶段以重复互动。结果显示，关系导向策略激励了参与者更长时间地保持活跃状态；然而，多次会话并没有加深参与者的对机器人的依恋感，但那些更加依附于机器人的个体对于目标导向策略产生了更为积极的回应。这些发现为设计用于健康传播环境中的社会机器人说服策略提供了宝贵的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To design social robots to effectively promote health behavior change, it isessential to understand how people respond to various health communicationstrategies employed by these robots. This study examines the effectiveness oftwo types of social control strategies from a social robot,relationship-focused strategies (emphasizing relational consequences) andtarget-focused strategies (emphasizing health consequences), in encouragingpeople to reduce sedentary behavior. A two-session lab experiment was conducted(n = 135), where participants first played a game with a robot, followed by therobot persuading them to stand up and move using one of the strategies. Half ofthe participants joined a second session to have a repeated interaction withthe robot. Results showed that relationship-focused strategies motivatedparticipants to stay active longer. Repeated sessions did not strengthenparticipants' relationship with the robot, but those who felt more attached tothe robot responded more actively to the target-focused strategies. Thesefindings offer valuable insights for designing persuasive strategies for socialrobots in health communication contexts.</description>
      <author>example@mail.com (Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn)</author>
      <guid isPermaLink="false">2502.08428v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Conveyor Line Color Object Sorting using A Monochrome Camera, Colored Light and RGB Filters</title>
      <link>http://arxiv.org/abs/2502.08419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 26 figures, 23rd Annual Hawaii International Conference on  Education, Ja n. 4-7, 2025, Honolulu, Hawa ii&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文测试了一种使用单色相机的机器视觉系统区分彩色物体的能力。该系统的目的是自主和连续地分类用户指定颜色的对象。&lt;h4&gt;背景&lt;/h4&gt;利用带有颜色滤镜的相机和RGB LED灯，帮助机器视觉系统识别零件对比度。&lt;h4&gt;目的&lt;/h4&gt;开发一种由可编程逻辑控制器（PLC）控制，并与机器人集成的系统来自动去除待分类的零件。&lt;h4&gt;方法&lt;/h4&gt;通过传送带将零件输送到工作单元中，该传送带也受PLC控制。用户可以通过人机界面和物理按钮选择期望的颜色。&lt;h4&gt;主要发现&lt;/h4&gt;&lt;h4&gt;结论&lt;/h4&gt;&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文测试了一种使用单色相机的机器视觉系统区分彩色物体的能力。该系统的目的是自主和连续地分类用户指定颜色的对象。该系统利用带有颜色滤镜的相机和RGB LED灯，帮助机器视觉系统识别零件对比度。此外，该系统由可编程逻辑控制器（PLC）控制，并与机器人集成用于去除零件。通过传送带将零件输送到工作单元中，该传送带也受PLC控制。用户可以通过人机界面和物理按钮选择期望的颜色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tests the ability of a machine vision system with a monochromecamera to differentiate colored objects. The system is designed to autonomouslyand continuously sort colored objects of which the user specifies the desiredcolor(s). The system uses camera color light filters and red-green-blue (RGB)color light emitting diode (LED) lights to aid the machine vision system inrecognizing part contrast. Additionally the system is controlled by aProgrammable Logic Controller (PLC) which is integrated with a Robot that isused to remove parts. The parts are fed into the workcell via a conveyor beltthat is controlled by the PLC. The user has the ability to select the desiredacceptable colors on both the HMI and the physical pushbuttons.</description>
      <author>example@mail.com (Mason Petersen, Brendon Lakenen, Krishna Chavan, Pratik Waghmare, Aleksandr Sergeyev, Nathir A. Rawashdeh)</author>
      <guid isPermaLink="false">2502.08419v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning Humanoid Standing-up Control across Diverse Postures</title>
      <link>http://arxiv.org/abs/2502.08378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Humanoid Standing-up Control, 12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的机器人站立控制框架HoST，该框架通过强化学习从零开始训练站立动作，并能够在不同场景和姿态下实现稳定且鲁棒的起身控制。&lt;h4&gt;背景&lt;/h4&gt;当前人形机器人的站立控制系统存在局限性，要么仅限于模拟环境，要么依赖特定地面的动作轨迹。这些方法无法适应现实世界的多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够跨不同姿势进行稳健模拟到现实转移的人形机器人站立控制系统。&lt;h4&gt;方法&lt;/h4&gt;提出了HoST框架，使用强化学习从头开始训练站立动作，并在多样化地形上利用多批评分器架构和基于课程的培训。引入平滑度正则化和隐含运动速度限制以确保实际部署的成功。&lt;h4&gt;主要发现&lt;/h4&gt;HoST能够学习适应不同姿态的动作，并且可以直接将学到的控制策略应用于Unitree G1人形机器人，实验结果表明控制器在各种实验室内外环境中表现平稳、稳定和鲁棒。&lt;h4&gt;结论&lt;/h4&gt;提出的HoST框架成功地解决了现有的站立控制系统的问题，实现了从模拟到现实环境中的稳健转移。&lt;h4&gt;翻译&lt;/h4&gt;立起控制对于人形机器人至关重要，可以整合入当前的运动和动控系统中，如跌倒恢复。现有方法要么仅限于忽视硬件限制的仿真中，要么依赖于预定义的地面特定动作轨迹，无法实现在真实场景跨姿态站起。为了弥补这一差距，我们提出了HoST（人形立起控制），这是一种从头开始学习站立控制的强化学习框架，能够实现稳健的模拟到现实跨不同姿态转移。HoST通过使用多批评分器架构和基于课程的多样化地形训练有效地学习适应姿势的动作，并施加平滑度正则化以确保实际部署的成功。在模拟训练后，所学的控制策略可以直接应用到Unitree G1人形机器人上。实验结果表明控制器实现了从实验室内外环境的平稳、稳定和鲁棒站立动作。视频可在https://taohuang13.github.io/humanoid-standingup.github.io/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Standing-up control is crucial for humanoid robots, with the potential forintegration into current locomotion and loco-manipulation systems, such as fallrecovery. Existing approaches are either limited to simulations that overlookhardware constraints or rely on predefined ground-specific motion trajectories,failing to enable standing up across postures in real-world scenes. To bridgethis gap, we present HoST (Humanoid Standing-up Control), a reinforcementlearning framework that learns standing-up control from scratch, enablingrobust sim-to-real transfer across diverse postures. HoST effectively learnsposture-adaptive motions by leveraging a multi-critic architecture andcurriculum-based training on diverse simulated terrains. To ensure successfulreal-world deployment, we constrain the motion with smoothness regularizationand implicit motion speed bound to alleviate oscillatory and violent motions onphysical hardware, respectively. After simulation-based training, the learnedcontrol policies are directly deployed on the Unitree G1 humanoid robot. Ourexperimental results demonstrate that the controllers achieve smooth, stable,and robust standing-up motions across a wide range of laboratory and outdoorenvironments. Videos are available athttps://taohuang13.github.io/humanoid-standingup.github.io/.</description>
      <author>example@mail.com (Tao Huang, Junli Ren, Huayi Wang, Zirui Wang, Qingwei Ben, Muning Wen, Xiao Chen, Jianan Li, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.08378v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.08336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Salience-Invariant Consistent Policy Learning (SCPL)的算法，旨在解决视觉强化学习中从训练环境过度拟合到测试环境中未见场景的问题。&lt;h4&gt;背景&lt;/h4&gt;在视觉强化学习领域，智能体容易过度拟合并提取与任务无关的信息，导致无法在未曾见过的环境下保持最优行为。&lt;h4&gt;目的&lt;/h4&gt;提出SCPL算法以提高零样本泛化性能，并解决智能体由于注意力分散而导致的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;{'Salience-Invariant Consistent Policy Learning (SCPL)算法': '该算法通过引入价值一致性模块和动态模块，结合增强数据集帮助编码器捕捉任务相关的表示。其中，价值一致性模块确保智能体在原始观察与扰动后的观察中关注于相关像素。', '政策一致性模块': '使用KL散度约束来维护原始观察与扰动后观察的一致性策略'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SCPL算法在DMC-GB、机器人操作和CARLA基准测试上显著优于现有的方法，分别提高了14%，39%和69%的性能。&lt;h4&gt;结论&lt;/h4&gt;理论分析证明了政策一致性对于泛化的重要性，并且SCPL算法通过引入价值一致性和动态模块有效地提升了智能体在未见场景中的表现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizing policies to unseen scenarios remains a critical challenge invisual reinforcement learning, where agents often overfit to the specificvisual observations of the training environment. In unseen environments,distracting pixels may lead agents to extract representations containingtask-irrelevant information. As a result, agents may deviate from the optimalbehaviors learned during training, thereby hindering visual generalization.Toaddress this issue, we propose the Salience-Invariant Consistent PolicyLearning (SCPL) algorithm, an efficient framework for zero-shot generalization.Our approach introduces a novel value consistency module alongside a dynamicsmodule to effectively capture task-relevant representations. The valueconsistency module, guided by saliency, ensures the agent focuses ontask-relevant pixels in both original and perturbed observations, while thedynamics module uses augmented data to help the encoder capture dynamic- andreward-relevant representations. Additionally, our theoretical analysishighlights the importance of policy consistency for generalization. Tostrengthen this, we introduce a policy consistency module with a KL divergenceconstraint to maintain consistent policies across original and perturbedobservations.Extensive experiments on the DMC-GB, Robotic Manipulation, andCARLA benchmarks demonstrate that SCPL significantly outperformsstate-of-the-art methods in terms of generalization. Notably, SCPL achievesaverage performance improvements of 14\%, 39\%, and 69\% in the challenging DMCvideo hard setting, the Robotic hard setting, and the CARLA benchmark,respectively.Project Page: https://sites.google.com/view/scpl-rl.</description>
      <author>example@mail.com (Sun Jingbo, Tu Songjun, Zhang Qichao, Chen Ke, Zhao Dongbin)</author>
      <guid isPermaLink="false">2502.08336v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Open-Source Factor Graph Optimization Package for GNSS: Examples and Applications</title>
      <link>http://arxiv.org/abs/2502.08158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 2025 IEEE/ION Position, Location and Navigation  Symposium (PLANS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为gtsam_gnss的开源GNSS因子图优化(FGO)包，该包通过分离GNSS观测数据预处理和因子优化，简化了结构并提高了灵活性。&lt;h4&gt;背景&lt;/h4&gt;因子图优化方法在卫星导航系统研究中引起了广泛关注，并且相对于传统的基于最小二乘或卡尔曼滤波的状态估计方法具有更优的精度。&lt;h4&gt;目的&lt;/h4&gt;提出一个开源软件包gtsam_gnss以促进GNSS研究和开发，同时支持用户特定的研究需求。&lt;h4&gt;方法&lt;/h4&gt;该软件包将GNSS观测数据预处理与因子优化分离，并直接描述了GNSS因素的误差函数，以便于一般的输入使用。此外，它还包括实际城市环境中各种因素的分析示例。&lt;h4&gt;主要发现&lt;/h4&gt;gtsam_gnss在不同的应用场景中表现出良好的状态估计性能，包括鲁棒误差模型的应用、载波相位整周模糊度的估计以及GNSS和智能手机惯性测量单元(IMU)数据的融合。&lt;h4&gt;结论&lt;/h4&gt;该框架为从基于最小二乘的位置定位过渡到FGO提供了一种途径，并且支持用户特定的GNSS研究，展示了良好的状态估计性能。&lt;h4&gt;翻译&lt;/h4&gt;使用因子图优化（FGO）的状态估算方法在卫星导航系统（GNSS）的研究中获得了大量关注。与依赖于最小二乘或卡尔曼滤波的传统状态估算方法相比，FGO显示出优越的估算精度。然而，专门针对GNSS观测值的FGO库很少见。本文介绍了名为gtsam_gnss的一个开源GNSS FGO包，它具有简单结构，并且可以轻松应用于GNSS研究和开发中。该软件包将GNSS观测数据预处理与因子优化分离，同时以直接方式描述了GNSS因素的误差函数，支持一般的输入使用。这种设计便于从基于最小二乘的位置定位过渡到FGO，并且支持用户特定的GNSS研究。此外，gtsam_gnss包括实际城市环境中各种因素使用的分析示例。本文提出了三个应用实例：鲁棒误差模型的应用、载波相位整周模糊度的估计以及GNSS和智能手机惯性测量单元（IMU）数据融合。所提出的框架在所有使用案例中均表现出卓越的状态估算性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State estimation methods using factor graph optimization (FGO) have garneredsignificant attention in global navigation satellite system (GNSS) research.FGO exhibits superior estimation accuracy compared with traditional stateestimation methods that rely on least-squares or Kalman filters. However, onlya few FGO libraries are specialized for GNSS observations. This paperintroduces an open-source GNSS FGO package named gtsam\_gnss, which has asimple structure and can be easily applied to GNSS research and development.This package separates the preprocessing of GNSS observations from factoroptimization. Moreover, it describes the error function of the GNSS factor in astraightforward manner, allowing for general-purpose inputs. This designfacilitates the transition from ordinary least-squares-based positioning to FGOand supports user-specific GNSS research. In addition, gtsam\_gnss includesanalytical examples involving various factors using GNSS data in real urbanenvironments. This paper presents three application examples: the use of arobust error model, estimation of integer ambiguity in the carrier phase, andcombination of GNSS and inertial measurements from smartphones. The proposedframework demonstrates excellent state estimation performance across all usecases.</description>
      <author>example@mail.com (Taro Suzuki)</author>
      <guid isPermaLink="false">2502.08158v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles</title>
      <link>http://arxiv.org/abs/2502.08119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于无人机和地面站的鲁棒多接入边缘计算框架，用于协助无人水面艇完成复杂任务。&lt;h4&gt;背景&lt;/h4&gt;随着无人水面艇（USVs）在海上搜索与救援等应用中的部署增加，需要计算支持和覆盖。然而，由于任务不确定性、无人水面艇轨迹不确定性、异质性和有限的计算资源，无人机（UAVs）和地面站（GSs）之间的协作面临挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种优化算法来解决联合任务卸载和无人机轨迹的问题，以最小化总执行时间，并提高复杂环境下的预测不确定性和动态适应能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成式人工智能增强的异构代理近端策略优化（GAI-HAPPO）算法，该算法集成GAI模型以增强代理网络在建模复杂环境和提取高层次特征方面的能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的模拟实验表明，所提出的算法优于现有的基准方法，在解决跨域复杂问题上显示出巨大的潜力。&lt;h4&gt;结论&lt;/h4&gt;新提出的方法为无人水面艇应用中的协作计算提供了一种有效且高效的新途径，并展示了其在处理复杂和动态环境中任务分配方面的优越性。&lt;h4&gt;翻译&lt;/h4&gt;随着无人驾驶表面车辆（USVs）的部署增加，海上搜索与救援等应用需要计算支持。无人机可以提供低成本、灵活的服务，地面站可以提供强大支持，三者可合作帮助USV应对复杂场景中的挑战。然而，UAV和GS在USV任务协作中面临多项挑战，包括任务不确定性、无人水面艇轨迹不确定性以及异质性和有限的计算资源问题。为解决这些问题，提出了一种基于无人机和地面站的合作鲁棒多接入边缘计算框架来协助USVs完成计算任务。研究采用生成式人工智能增强的异构代理近端策略优化算法（GAI-HAPPO），该算法在复杂的环境建模、高阶特征提取方面表现优异，并能预测不确定性，适应动态条件变化。实验表明，所提方法显著优于现有基准，在复杂场景下表现出巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing deployment of unmanned surface vehicles (USVs) requirecomputational support and coverage in applications such as maritime search andrescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerialservices, and ground stations (GSs) can provide powerful supports, which cancooperate to help the USVs in complex scenarios. However, the collaborationbetween UAVs and GSs for USVs faces challenges of task uncertainties, USVstrajectory uncertainties, heterogeneities, and limited computational resources.To address these issues, we propose a cooperative UAV and GS based robustmulti-access edge computing framework to assist USVs in completingcomputational tasks. Specifically, we formulate the optimization problem ofjoint task offloading and UAV trajectory to minimize the total execution time,which is in the form of mixed integer nonlinear programming and NP-hard totackle. Therefore, we propose the algorithm of generative artificialintelligence-enhanced heterogeneous agent proximal policy optimization(GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actornetwork ability to model complex environments and extract high-level features,thereby allowing the algorithm to predict uncertainties and adapt to dynamicconditions. Additionally, GAI stabilizes the critic network, addressing theinstability of multi-agent reinforcement learning approaches. Finally,extensive simulations demonstrate that the proposed algorithm outperforms theexisting benchmark methods, thus highlighting the potentials in tacklingintricate, cross-domain issues in the considered scenarios.</description>
      <author>example@mail.com (Jiahao You, Ziye Jia, Chao Dong, Qihui Wu, Zhu Han)</author>
      <guid isPermaLink="false">2502.08119v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Ground-Optimized 4D Radar-Inertial Odometry via Continuous Velocity Integration using Gaussian Process</title>
      <link>http://arxiv.org/abs/2502.08093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;雷达在恶劣天气条件下提供强大的感知能力，但高本征噪声水平带来的挑战仍然存在。现有的雷达里程计通过过滤虚假点、利用多普勒速度或集成惯性测量来克服这些挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍两项超越现有雷达-惯性里程计的新改进：地面优化的噪声滤波和连续速度预积分。&lt;h4&gt;方法&lt;/h4&gt;{'第一项改进': '鉴于在激光雷达里程计中广泛使用地平面，但雷达测量的地面点分布不准确导致简单的平面拟合失效，我们引入了基于区域的不确定性感知地面建模，专门针对雷达设计。', '第二项改进': '注意到可以通过更好地结合雷达速度测量和IMU来提高雷达-惯性里程计的速度预积分准确性。现有方法往往通过离散化传播模型简化不同步数据流的时间差异来忽略这些时间差异，我们利用高斯过程（GP）构建连续的预积分方法以紧密结合3自由度线性速度与IMU。', '结果': '我们的方法在公共数据集中表现出色，在仔细的条件下垂直漂移小于1%，显著提高了高度精度。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过新颖的方法显著改进了雷达-惯性里程计性能，特别是在减少垂直漂移和提高高程精度方面取得了重大进展。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法在公共数据集上展示了卓越的性能，并将代码开源给社区：https://github.com/wooseongY/Go-RIO。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种改进雷达-惯性里程计的方法，通过优化噪声滤波和速度预积分技术来提高其在恶劣天气条件下的感知能力。这项工作引入了基于区域的不确定性感知地面建模和连续的速度预积分方法，显著减少了垂直漂移并提高了高度精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar ensures robust sensing capabilities in adverse weather conditions, yetchallenges remain due to its high inherent noise level. Existing radar odometryhas overcome these challenges with strategies such as filtering spuriouspoints, exploiting Doppler velocity, or integrating with inertial measurements.This paper presents two novel improvements beyond the existing radar-inertialodometry: ground-optimized noise filtering and continuous velocitypreintegration. Despite the widespread use of ground planes in LiDAR odometry,imprecise ground point distributions of radar measurements cause naive planefitting to fail. Unlike plane fitting in LiDAR, we introduce a zone-baseduncertainty-aware ground modeling specifically designed for radar. Secondly, wenote that radar velocity measurements can be better combined with IMU for amore accurate preintegration in radar-inertial odometry. Existing methods oftenignore temporal discrepancies between radar and IMU by simplifying thecomplexities of asynchronous data streams with discretized propagation models.Tackling this issue, we leverage GP and formulate a continuous preintegrationmethod for tightly integrating 3-DOF linear velocity with IMU, facilitatingfull 6-DOF motion directly from the raw measurements. Our approach demonstratesremarkable performance (less than 1% vertical drift) in public datasets withmeticulous conditions, illustrating substantial improvement in elevationaccuracy. The code will be released as open source for the community:https://github.com/wooseongY/Go-RIO.</description>
      <author>example@mail.com (Wooseong Yang, Hyesu Jang, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.08093v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Cooperative Bearing-Rate Approach for Observability-Enhanced Target Motion Estimation</title>
      <link>http://arxiv.org/abs/2502.08089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by icra 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了基于视觉的目标运动估计问题，并提出了一种新的协同估算器STT-R，旨在解决现有方法在追踪高度机动目标时的低可观测性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉的目标运动估计算法面对高速度、高机动性的目标时存在观测性差的问题，难以有效跟踪这些目标。&lt;h4&gt;目的&lt;/h4&gt;针对无人机空中追击任务中的三维空间目标机动性难题，提出一种新的估算方法以提高可观测性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于分布式递归最小二乘法的新型协同估计算法STT-R（带有角度变化率信息的空间-时间三角测量），该算法在理论和实际实验中得到了验证。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的STT-R算法能更准确地进行目标运动估算，并有效减少了速度估计中的滞后现象，使得追踪更为机动的目标成为可能。&lt;h4&gt;结论&lt;/h4&gt;通过数值模拟和真实世界的实验验证了STT-R的有效性，该方法为解决高度机动目标的追踪问题提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;基于视觉的目标运动估算是许多机器人任务中的一个基本问题。现有的方法在观测性和跟踪高度机动的目标时存在限制。受无人机空中追击任务中需要追踪三维空间内可自由移动目标这一挑战的启发，本文研究如何通过引入未被充分探索的角度变化率信息来进一步增强可观测性。论文的主要贡献在于提出了一个新的协同估计算法STT-R（带有角度变化率的空间-时间三角测量），该算法是在分布式递归最小二乘框架下设计的。理论结果通过数值模拟和真实实验得到了验证，显示了所提出的STT-R算法能有效提高估计精度，并显著减少了速度估算中的滞后现象，使得追踪更为机动的目标成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based target motion estimation is a fundamental problem in manyrobotic tasks. The existing methods have the limitation of low observabilityand, hence, face challenges in tracking highly maneuverable targets. Motivatedby the aerial target pursuit task where a target may maneuver in 3D space, thispaper studies how to further enhance observability by incorporating the\emph{bearing rate} information that has not been well explored in theliterature. The main contribution of this paper is to propose a new cooperativeestimator called STT-R (Spatial-Temporal Triangulation with bearing Rate),which is designed under the framework of distributed recursive least squares.This theoretical result is further verified by numerical simulation andreal-world experiments. It is shown that the proposed STT-R algorithm caneffectively generate more accurate estimations and effectively reduce the lagin velocity estimation, enabling tracking of more maneuverable targets.</description>
      <author>example@mail.com (Canlun Zheng, Hanqing Guo, Shiyu Zhao)</author>
      <guid isPermaLink="false">2502.08089v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Innovations in Nanotechnology: A Comprehensive Review of Applications Beyond Space Exploration</title>
      <link>http://arxiv.org/abs/2502.08036v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, a review paper about the use of nanotechnology in  space exploration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;纳米技术在多个行业中展现出变革力量，通过改善材料、提高仪器精度以及开发智能系统来促进工业进步。&lt;h4&gt;背景&lt;/h4&gt;纳米技术在材料科学、医疗健康、能源存储、环境监测和机器人学等多个领域都有广泛应用。例如碳纳米管和石墨烯等纳米材料，在能量生成和医药等领域提供了显著的改进，而纳米传感器则革新了环境和工业监测手段。&lt;h4&gt;目的&lt;/h4&gt;综述文章旨在探讨各种纳米技术应用，包括在不同领域的先进技术和创新方法，并强调跨学科合作的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;微/纳机器人提供自动化解决方案，进一步扩展到空间探索之外的其他领域，展示了纳米技术在未来重塑行业的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;通过跨学科协作和持续创新，纳米技术将对工业界产生深远影响，开启新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;纳米技术作为一种变革力量，在多个行业中崭露头角。它提升了材料性能、提高了仪器的精度，并开发了智能系统。此综述探讨了纳米技术在诸如材料科学、医疗健康、能源存储、环境监测及机器人学等领域的应用。特别地，碳纳米管和石墨烯等纳米材料显著改善了能量生成和医学领域的发展，而纳米传感器则革新了环境与工业的监测方式。微/纳机器人提供了跨行业的自动化解决方案，并且其影响力已从太空探索延伸到其他重要方面，展示了纳米技术在未来重塑各行业中的巨大潜力。综述强调了通过跨学科合作及持续创新来实现这一潜力的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nanotechnology has emerged as a transformative force across multipleindustries, enhancing materials, improving instrumentation precision, anddeveloping intelligent systems. This review explores various nanotechnologyapplications, including advancements in materials science, healthcare, energystorage, environmental monitoring, and robotics. Nanomaterials, such as carbonnanotubes and graphene, offer significant improvements in fields like energygeneration and medicine, while nanosensors revolutionize environmental andindustrial monitoring. Micro and nano robots provide automation solutionsacross industries. By expanding beyond space exploration, this reviewhighlights the far-reaching potential of nanotechnology to reshape industriesthrough interdisciplinary collaboration and innovation.</description>
      <author>example@mail.com (Syed Muhammad Muslim Hussain, Batool Zehra Ladha, Muhammad Hasan Khan)</author>
      <guid isPermaLink="false">2502.08036v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Predictive Planner for Autonomous Driving with Consistency Models</title>
      <link>http://arxiv.org/abs/2502.08033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的统一数据驱动框架，将轨迹预测和规划结合在一个一致性模型中。该框架通过端到端的预测性规划解决了传统模块化方法中的交互式规划问题，并且更适用于多代理场景。&lt;h4&gt;背景&lt;/h4&gt;传统的自动驾驶车辆导航组件如轨迹预测和规划常常被视为独立模块处理，限制了互动规划能力并导致在多代理环境下的计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架以整合轨迹预测与规划过程，通过使用单一的一致性模型来提高交互式行为的生成能力和实际应用中的实时性能。&lt;h4&gt;方法&lt;/h4&gt;利用现实世界的人类驾驶数据集训练一致性模型，该模型能够从自我车辆及周围代理的高维多模态联合轨迹分布中生成样本，并提出了一种交替方向法以在线指导采样并加入对自我车辆的额外规划约束。&lt;h4&gt;主要发现&lt;/h4&gt;对比扩散模型，该一致性的模型在更少的抽样步骤下实现了更好的性能，在Waymo开放运动数据集(WOMD)上的实验结果表明其轨迹质量、约束满足度和交互行为优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出的新框架展示了改进自动驾驶车辆导航决策能力的巨大潜力，并为未来研究提供了有效的途径，特别是在多代理场景中的实时交互性规划方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory prediction and planning are fundamental components for autonomousvehicles to navigate safely and efficiently in dynamic environments.Traditionally, these components have often been treated as separate modules,limiting the ability to perform interactive planning and leading tocomputational inefficiency in multi-agent scenarios. In this paper, we presenta novel unified and data-driven framework that integrates prediction andplanning with a single consistency model. Trained on real-world human drivingdatasets, our consistency model generates samples from high-dimensional,multimodal joint trajectory distributions of the ego and multiple surroundingagents, enabling end-to-end predictive planning. It effectively producesinteractive behaviors, such as proactive nudging and yielding to ensure bothsafe and efficient interactions with other road users. To incorporateadditional planning constraints on the ego vehicle, we propose an alternatingdirection method for multi-objective guidance in online guided sampling.Compared to diffusion models, our consistency model achieves better performancewith fewer sampling steps, making it more suitable for real-time deployment.Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate ourmethod's superiority in trajectory quality, constraint satisfaction, andinteractive behavior compared to various existing approaches.</description>
      <author>example@mail.com (Anjian Li, Sangjae Bae, David Isele, Ryne Beeson, Faizan M. Tariq)</author>
      <guid isPermaLink="false">2502.08033v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Visual-Haptic Model Mediated Teleoperation for Remote Ultrasound</title>
      <link>http://arxiv.org/abs/2502.07922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Supplementary video: https://youtu.be/fDLBah7bPeo . This work has  been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种远程超声系统的原型，该系统结合了视觉和触觉反馈模型，可以有效减少时间延迟带来的影响。&lt;h4&gt;背景&lt;/h4&gt;远程超声波技术有助于改善偏远地区的医疗公平性，但实际应用中存在的时间延迟问题导致传统的遥操作方式表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过引入本地环境的视觉-触觉模型来补偿长时间延迟，提高远程机器人超声系统的稳定性和准确性。&lt;h4&gt;方法&lt;/h4&gt;设计并测试了一种原型系统，在该系统中使用预先获取的超声扫描实时重切片和渲染技术为操作员提供延迟图像的预览。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，视觉-触觉模型中介遥操作（MMT）能够完全补偿1000毫秒往返时间延迟对操作者努力和完成时间的影响。对于更长时间延迟，视觉-触觉MMT在运动准确性和力控制方面也显著优于传统MMT。&lt;h4&gt;结论&lt;/h4&gt;本概念验证研究证明了视觉-触觉模型中介遥操作可能有助于远程机器人超声的应用。&lt;h4&gt;翻译&lt;/h4&gt;该摘要描述了一种利用本地环境的视觉和触觉反馈来改善时间延迟影响的方法，通过在实验中应用原型系统并收集数据，证实了所提出技术的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tele-ultrasound has the potential greatly to improve health equity forcountless remote communities. However, practical scenarios involve potentiallylarge time delays which cause current implementations of telerobotic ultrasound(US) to fail. Using a local model of the remote environment to provide hapticsto the expert operator can decrease teleoperation instability, but the delayedvisual feedback remains problematic. This paper introduces a robotic tele-USsystem in which the local model is not only haptic, but also visual, byre-slicing and rendering a pre-acquired US sweep in real time to provide theoperator a preview of what the delayed image will resemble. A prototype systemis presented and tested with 15 volunteer operators. It is found thatvisual-haptic model-mediated teleoperation (MMT) compensates completely fortime delays up to 1000 ms round trip in terms of operator effort and completiontime while conventional MMT does not. Visual-haptic MMT also significantlyoutperforms MMT for longer time delays in terms of motion accuracy and forcecontrol. This proof-of-concept study suggests that visual-haptic MMT mayfacilitate remote robotic tele-US.</description>
      <author>example@mail.com (David Black, Maria Tirindelli, Septimiu Salcudean, Wolfgang Wein, Marco Esposito)</author>
      <guid isPermaLink="false">2502.07922v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Safe Scheduling of Robots</title>
      <link>http://arxiv.org/abs/2502.07851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种快速启发式算法，用于在路径图上为一组机器人生成无碰撞调度方案的实验分析。&lt;h4&gt;背景&lt;/h4&gt;现有的方法可能无法有效地解决多机器人系统中的无碰撞调度问题。&lt;h4&gt;目的&lt;/h4&gt;评估该启发式算法的有效性，并通过整数线性规划验证其性能和最优解能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一种快速生成无碰撞调度方案的启发式算法，同时提供了一个保证任何输入图上最优解的整数线性规划模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在所有任务时长相等的情况下，该启发式算法能够产生最优解；对比两种算法的解决方案和运行时间后发现，尽管整数线性规划可以找到全局最优解，但其计算资源消耗较大，而启发式算法则在几乎所有情况下都接近或达到最优，并且具有更快的运行速度。&lt;h4&gt;结论&lt;/h4&gt;该快速启发式算法是解决多机器人无碰撞调度问题的有效工具，在大多数实际应用场景中优于整数线性规划方法。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们展示了对一种快速启发式算法进行实验分析的结果。这种算法旨在为路径图上的机器人生成快速且无碰撞的调度方案。实验验证了该算法在产生无碰撞调度方案方面的有效性，并表明当所有分配给机器人的任务时长相等时，它可以达到最优解。此外，我们还提供了一个整数线性规划模型来保证对任何输入图上此调度问题的最佳解决方案，尽管这会消耗显著更多的计算资源。通过对比这两种算法的解决方案和运行时间，我们证明了启发式算法在几乎所有情况下都接近或达到了最佳性能，并且其执行速度远快于整数线性规划方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an experimental analysis of a fast heuristicalgorithm that was designed to generate a fast, collision-free schedule for aset of robots on a path graph. The experiments confirm the algorithm'seffectiveness in producing collision-free schedules as well as achieving theoptimal solution when all tasks assigned to the robots are of equal duration.Additionally, we provide an integer linear programming formulation thatguarantees an optimal solution for this scheduling problem on any input graph,at the expense of significantly greater computational resources. We prove thecorrectness of our integer linear program. By comparing the solutions of thesetwo algorithms, including the time required by the schedule itself, and the runtime of each algorithm, we show that the heuristic algorithm is optimal or nearoptimal in nearly all cases, with a far faster run time than the integer linearprogram.</description>
      <author>example@mail.com (Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul G. Spirakis)</author>
      <guid isPermaLink="false">2502.07851v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Factor Modelling for Biclustering Large-dimensional Matrix-valued Time Series</title>
      <link>http://arxiv.org/abs/2502.06397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于全新潜在双向因子结构的无监督学习方法，用于大规模矩阵值时间序列的聚类。该方法通过估计全局加载空间和特定于集群的因素加载空间来实现。&lt;h4&gt;背景&lt;/h4&gt;处理高维矩阵值时间序列的数据在许多领域变得越来越重要，然而传统的聚类算法难以有效处理这种复杂类型的数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督学习方法，能够有效地对大规模的矩阵值时间序列进行聚类，并同时识别潜在的行/列集群。&lt;h4&gt;方法&lt;/h4&gt;通过将观测矩阵投影到对应的公共因素行或列加载空间上来估计全局加载空间；然后通过向已估计出的全局加载空间的正交补空间投影来进一步恢复特定于集群的因素加载空间。提供了一个基于估计出的行/列因素负载的$K$-means算法，用于同时识别矩阵值时间序列的潜在行/列集群。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在温和条件下获得了比现有文献中的最佳方法更快收敛率的全局加载矩阵，并提出了一种单次特征比率方法来估计全球和特定于集群的因素数量。建立了局部加载矩阵、因素数以及潜伏群成员身份的估计器的一致性和显式收敛速率。&lt;h4&gt;结论&lt;/h4&gt;通过数值实验（包括模拟数据和真实数据示例）验证了所提方法的有效性，展示了该新方法在处理大规模高维矩阵值时间序列聚类任务中的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的内容被翻译成中文，并根据论文主要关注点进行了分段总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A novel unsupervised learning method is proposed in this paper forbiclustering large-dimensional matrix-valued time series based on an entirelynew latent two-way factor structure. Each block cluster is characterized by itsown row and column cluster-specific factors in addition to some common matrixfactors which impact on all the matrix time series. We first estimate theglobal loading spaces by projecting the observation matrices onto the row orcolumn loading space corresponding to common factors. The loading spaces forcluster-specific factors are then further recovered by projecting theobservation matrices onto the orthogonal complement space of the estimatedglobal loading spaces. To identify the latent row/column clusterssimultaneously for matrix-valued time series, we provide a $K$-means algorithmbased on the estimated row/column factor loadings of the cluster-specific weakfactors. Theoretically, we derive faster convergence rates for global loadingmatrices than those of the state-of-the-art methods available in the literatureunder mild conditions. We also propose an one-pass eigenvalue-ratio method toestimate the numbers of global and cluster-specific factors. The consistencywith explicit convergence rates is also established for the estimators of thelocal loading matrices, the factor numbers and the latent cluster memberships.Numerical experiments with both simulated data as well as a real data exampleare also reported to illustrate the usefulness of our proposed method.</description>
      <author>example@mail.com (Yong He, Xiaoyang Ma, Xingheng Wang, Yalin Wang)</author>
      <guid isPermaLink="false">2502.06397v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
  <item>
      <title>Block Graph Neural Networks for tumor heterogeneity prediction</title>
      <link>http://arxiv.org/abs/2502.05458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于模拟肿瘤演化的数学模型生成人工数据集的方法，用于提高肿瘤分类的准确性。通过这种方法和Block Graph Neural Networks（BGNN）网络，研究者在人工生成的数据上实现了89.67%的测试精度。&lt;h4&gt;背景&lt;/h4&gt;现有的肿瘤分级方法存在局限性，单一细胞测序可以提供深入见解但成本高昂且操作复杂，统计机器学习方法需要复杂的预处理步骤。因此需要更有效的方法来克服这些挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于数学模型和BGNN网络的框架，用于生成人工数据集以改进肿瘤分类准确性，并探索结合传统分级方法与细胞增殖指数（如Ki-67）等生化指标的可能性。&lt;h4&gt;方法&lt;/h4&gt;(1) 从人工数据中提取切片和图生成过程；(2) 设计肿瘤特征；(3) 构建基于Graph Neural Network的Block Graph Neural Networks (BGNN)，用于预测肿瘤异质性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的组合特征和模型在人工生成的数据集上取得了优秀的分类性能，显示出结合传统病理学方法与分子标记能够显著提高肿瘤异质性的预测准确性和总体分类效率。&lt;h4&gt;结论&lt;/h4&gt;这种方法不仅展示了其在提高肿瘤分类准确性方面的潜力，而且为未来的AI辅助分级和空间转录组学研究提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate tumor classification is essential for selecting effectivetreatments, but current methods have limitations. Standard tumor grading, whichcategorizes tumors based on cell differentiation, is not recommended as astand-alone procedure, as some well-differentiated tumors can be malignant.Tumor heterogeneity assessment via single-cell sequencing offers profoundinsights but can be costly and may still require significant manualintervention. Many existing statistical machine learning methods for tumor datastill require complex pre-processing of MRI and histopathological data.  In this paper, we propose to build on a mathematical model that simulatestumor evolution (O\.{z}a\'{n}ski (2017)) and generate artificial datasets fortumor classification. Tumor heterogeneity is estimated using normalizedentropy, with a threshold to classify tumors as having high or lowheterogeneity. Our contributions are threefold: (1) the cut and graphgeneration processes from the artificial data, (2) the design of tumorfeatures, and (3) the construction of Block Graph Neural Networks (BGNN), aGraph Neural Network-based approach to predict tumor heterogeneity. Theexperimental results reveal that the combination of the proposed features andmodels yields excellent results on artificially generated data ($89.67\%$accuracy on the test data). In particular, in alignment with the emergingtrends in AI-assisted grading and spatial transcriptomics, our results suggestthat enriching traditional grading methods with birth (e.g., Ki-67proliferation index) and death markers can improve heterogeneity prediction andenhance tumor classification.</description>
      <author>example@mail.com (Marianne Abémgnigni Njifon, Tobias Weber, Viktor Bezborodov, Tyll Krueger, Dominic Schuhmacher)</author>
      <guid isPermaLink="false">2502.05458v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Allegro-FM: Towards Equivariant Foundation Model for Exascale Molecular Dynamics Simulations</title>
      <link>http://arxiv.org/abs/2502.06073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种基于E(3)等变网络架构（Allegro）和通过Total Energy Alignment (TEA)框架整合的大规模有机及无机材料数据集构建的用于百亿亿次级分子动力学模拟的基础模型。此模型在描述结构、力学和热力学性质方面与高级量子化学理论有很好的一致性，并展现出对未训练任务（如结构相关性、反应动力学等）的新能力。&lt;h4&gt;背景&lt;/h4&gt;当前分子动力学模拟需要处理大规模的材料系统，而传统的计算方法难以满足其需求。利用深度学习技术可以提高模型性能和预测准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理大量原子系统的百亿亿次级分子动力学基础模型，并展示该模型在不同下游任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用E(3)等变网络架构（Allegro）和Total Energy Alignment (TEA)框架整合的大规模材料数据集，训练一个通用的材料模拟基础模型（Allegro-FM）。测试其在化学反应、机械强度等方面的表现，并评估其在百亿亿次超级计算机上的并行效率。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的Allegro-FM模型在未经过专门训练的情况下，能够准确预测结构相关性、反应动力学等特性。该模型对9.1百万个过渡态数据集和钙硅酸盐水合物的化学反应具有强大的预测能力和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究展示了基于大规模原子级模拟的基础模型在新型材料设计与发现方面的巨大潜力，为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种利用E(3)等变网络架构（Allegro）和Total Energy Alignment (TEA)框架合并的大规模有机及无机材料数据集构建的用于百亿亿次分子动力学模拟的基础模型。由于大规模训练数据集的支持，获得的模型（Allegro-FM）适用于各种材料模拟任务，涵盖周期表中89种元素的下游任务。Allegro-FM在描述结构、力学和热力学性质方面与高级量子化学理论有很好的一致性，并且展示了未经过训练的任务上的新能力，如结构相关性、反应动力学等。此外，我们还通过包含9.1百万过渡态数据集及钙硅酸盐水合物测试床的实验验证了Allegro-FM在化学反应预测中的鲁棒性和泛化性。凭借其计算效率高和严格局部化的网络架构，Allegro-FM可以扩展到数十亿原子系统，并且在美国阿贡国家实验室领导力计算设施上的Aurora超级计算机上实现了0.964的并行效率。本工作提出的方法展示了基于大规模原子级模拟的基础模型在新型材料设计与发现方面的潜在价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a foundation model for exascale molecular dynamics simulations byleveraging an E(3) equivariant network architecture (Allegro) and a set oflarge-scale organic and inorganic materials datasets merged by Total EnergyAlignment (TEA) framework. Thanks to the large-scale training sets, theobtained model (Allegro-FM) is versatile for various materials simulations fordiverse downstream tasks covering 89 elements in the periodic table. Allegro-FMexhibits excellent agreements with high-level quantum chemistry theories indescribing structural, mechanical, and thermodynamic properties, whileexhibiting emergent capabilities for structural correlations, reactionkinetics, mechanical strengths, fracture, and solid/liquid dissolution, forwhich the model has not been trained. Furthermore, we demonstrate the robustpredictability and generalizability of Allegro-FM for chemical reactions usingthe transition1x that consists of 9.1 million transition state data, as well ascalcium silicate hydrates as a testbed. With its computationally efficient,strictly-local network architecture, Allegro-FM scales up to multi-billion-atomsystems with a parallel efficiency of 0.964 on the exaflop/s Aurorasupercomputer at Argonne Leadership Computing Facility. The approach presentedin this work demonstrates the potential of the foundation model for a novelmaterials design and discovery based on large-scale atomistic simulations.</description>
      <author>example@mail.com (Ken-ichi Nomura, Shinnosuke Hattori, Satoshi Ohmura, Ikumi Kanemasu, Kohei Shimamura, Nabankur Dasgupta, Aiichiro Nakano, Rajiv K. Kalia, Priya Vashishta)</author>
      <guid isPermaLink="false">2502.06073v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning</title>
      <link>http://arxiv.org/abs/2502.07721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了一种新的可转移元学习者TMLC-Net，旨在解决现实世界数据集中噪音标签对深度学习模型有效部署的阻碍问题。&lt;h4&gt;背景&lt;/h4&gt;在实际的数据集中，噪声标签广泛存在并对深度学习模型的有效应用构成了显著障碍。尽管元学习策略作为应对这一挑战的一种有前景的方法已经出现，但现有的方法往往因为有限的转移性和任务特定设计而受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的可迁移的元学习者TMLC-Net来克服这些限制，并解决噪声标签的问题。&lt;h4&gt;方法&lt;/h4&gt;TMLC-Net包含三个核心组件：(1)归一化噪声感知，捕捉并归一化训练动态以处理分布偏移；(2)时间序列编码，使用递归神经网络建模样本统计的时态演变；(3)子类解码，根据学习到的表示预测一个修正标签分布。&lt;h4&gt;主要发现&lt;/h4&gt;在具有不同噪声类型和水平的基准数据集上进行了广泛的实验，结果表明TMLC-Net在准确性和对标签噪声的鲁棒性方面均优于最先进的方法。此外，分析了TMLC-Net的可转移性，并展示了其适应新数据集和噪声条件的能力。&lt;h4&gt;结论&lt;/h4&gt;研究确立了TMLC-Net作为一种广泛适用解决方案在嘈杂环境中进行稳健深度学习的潜力。&lt;h4&gt;翻译&lt;/h4&gt;现实世界数据集中噪声标签的普遍存在对深度学习模型的有效应用构成了显著障碍。虽然元学习策略作为应对这一挑战的一种有前景的方法已经出现，但现有的方法往往因为有限的转移性和任务特定设计而受限。本研究提出了一种新的可迁移的元学习者TMLC-Net来克服这些限制，并解决了噪声标签的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of noisy labels in real-world datasets poses a significantimpediment to the effective deployment of deep learning models. Whilemeta-learning strategies have emerged as a promising approach for addressingthis challenge, existing methods often suffer from limited transferability andtask-specific designs. This paper introduces TMLC-Net, a novel TransferableMeta-Learner for Correcting Noisy Labels, designed to overcome theselimitations. TMLC-Net learns a general-purpose label correction strategy thatcan be readily applied across diverse datasets and model architectures withoutrequiring extensive retraining or fine-tuning. Our approach integrates threecore components: (1) Normalized Noise Perception, which captures and normalizestraining dynamics to handle distribution shifts; (2) Time-Series Encoding,which models the temporal evolution of sample statistics using a recurrentneural network; and (3) Subclass Decoding, which predicts a corrected labeldistribution based on the learned representations. We conduct extensiveexperiments on benchmark datasets with various noise types and levels,demonstrating that TMLC-Net consistently outperforms state-of-the-art methodsin terms of both accuracy and robustness to label noise. Furthermore, weanalyze the transferability of TMLC-Net, showcasing its adaptability to newdatasets and noise conditions, and establishing its potential as a broadlyapplicable solution for robust deep learning in noisy environments.</description>
      <author>example@mail.com (Mengyang Li)</author>
      <guid isPermaLink="false">2502.07721v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement</title>
      <link>http://arxiv.org/abs/2502.07680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于最小势能（MPE）的全局配准方法，用于解决工业测量中由于3D采集系统缺陷导致的点云数据噪声和不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;在自由形式叶片重建过程中，点云注册是关键步骤。然而，由于3D获取系统的测量缺陷，不可避免地会导致包含噪声和缺失的数据点云，使得精确高效的配准变得具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全局配准方法，该方法基于最小势能（MPE）的方法来解决上述问题，并提高精度与抗噪能力。&lt;h4&gt;方法&lt;/h4&gt;1. 定义目标函数为物理注册系统的最小势能优化函数，通过这种方法可以更重视大部分内部点的权重，减少噪声和异常值的影响。2. 将解决方案分解为全局最优逼近过程和使用修剪迭代最近点算法的精细配准过程以加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;1. 提出了一种新理论来寻找MPE点，该理论采用两个标志来监测注册过程的状态。2. 在四种类型的叶片上展示了所提出方法的效果，在精度和抗噪能力方面优于其他全局方法。&lt;h4&gt;结论&lt;/h4&gt;提出的基于最小势能（MPE）的配准算法在工业测量中的噪声点云数据处理中表现出色，为提高自由形式叶片重建的效率与准确性提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云注册是工业测量中自由形式叶片重建的关键步骤。然而，由于3D获取系统的测量缺陷，不可避免地会导致包含噪声和缺失的数据点云，这使得精确高效的配准变得具有挑战性。本文提出了一种新的全局配准方法，基于最小势能（MPE）的方法来解决这些问题。基本策略是目标函数被定义为物理注册系统中的最小势能优化函数。此函数对内部大多数点分配更多权重，并且对噪声和异常值的权重较少，这本质上减少了数学公式化中扰动的影响。我们将解决方案分解为全局最优逼近过程以及使用修剪迭代最近点算法的精细配准过程以加速收敛。近似程序包含两个主要步骤：根据力牵引算子构造，可以简单地计算潜在能量最小的位置；为了找到MPE点，我们提出了一种新理论，即采用两个标志来观察注册过程的状态。我们在四种类型的叶片上展示了所提出的算法的性能，在精度和抗噪能力方面优于其他全局方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIM.2022.3169559&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration is an essential step for free-form bladereconstruction in industrial measurement. Nonetheless, measuring defects of the3D acquisition system unavoidably result in noisy and incomplete point clouddata, which renders efficient and accurate registration challenging. In thispaper, we propose a novel global registration method that is based on theminimum potential energy (MPE) method to address these problems. The basicstrategy is that the objective function is defined as the minimum potentialenergy optimization function of the physical registration system. The functiondistributes more weight to the majority of inlier points and less weight to thenoise and outliers, which essentially reduces the influence of perturbations inthe mathematical formulation. We decompose the solution into a globally optimalapproximation procedure and a fine registration process with the trimmediterative closest point algorithm to boost convergence. The approximationprocedure consists of two main steps. First, according to the construction ofthe force traction operator, we can simply compute the position of thepotential energy minimum. Second, to find the MPE point, we propose a newtheory that employs two flags to observe the status of the registrationprocedure. We demonstrate the performance of the proposed algorithm on fourtypes of blades. The proposed method outperforms the other global methods interms of both accuracy and noise resistance.</description>
      <author>example@mail.com (Zijie Wu, Yaonan Wang, Yang Mo, Qing Zhu, He Xie, Haotian Wu, Mingtao Feng, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.07680v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Analytic Personalized Federated Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.06915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两种框架，分别是FedACnnL和pFedACnnL，前者是用于深度神经网络训练的分析联邦学习（AFL）框架，后者是对前者的扩展，可以处理异质数据分布问题。这两个框架都能显著减少模型训练时间，并且在大多数情况下能够达到或超越现有最佳性能。&lt;h4&gt;背景&lt;/h4&gt;当前的AFL框架不支持DNN训练，且未解决异质数据分布问题，这限制了其应用范围和效果。&lt;h4&gt;目的&lt;/h4&gt;提出新的分析联邦学习方法以克服现有AFL框架对DNN的支持不足以及忽视异质数据的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了FedACnnL框架，使用一种新颖的局部分析学习方法ACnnL，并将每一层训练建模为一个分布式最小二乘问题。进一步扩展该框架形成pFedACnnL，允许具有相似数据分布的客户端共享一个健壮的全局模型以快速适应其本地任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与传统零阶（即无梯度）FL框架相比，FedACnnL训练时间减少了98%。而在大多数凸和非凸设置中，pFedACnnL达到了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;新提出的FedACnnL和pFedACnnL框架不仅大大缩短了深度神经网络的训练时间，而且在处理异质数据分布方面也显示出了优越性。&lt;h4&gt;翻译&lt;/h4&gt;分析联邦学习（AFL）通过使用封闭形式的最小二乘（LS）解决方案仅更新一次模型权重来减少大量无梯度联邦学习（FL）中的训练时间。当前的AFL框架无法支持深度神经网络（DNN）训练，这阻碍了其在复杂机器学习任务上的实施。同时，它忽略了限制单一全局模型在其执行每个客户端的任务时表现不佳的异构数据分布问题。为克服第一个挑战，我们提出了一种新的AFL框架FedACnnL，在该框架中，我们求助于一种新颖的本地分析学习方法（ACnnL），并将其每一层的训练建模为一个分布式LS问题。针对第二个挑战，我们提出了一个基于FedACnnL的分析个性化联邦元学习框架pFedACnnL。在pFedACnnL中，具有相似数据分布的客户端共享一个健壮的全局模型，并以分析方式快速适应其本地任务。理论上证明了FedACnnL比传统的零阶（即无梯度）FL框架在DNN训练中的所需时间显著缩短，在实验中减少了98%。同时，pFedACnnL在大多数凸和非凸设置下达到了最佳性能，优于之前的最优框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analytic federated learning (AFL) which updates model weights only once byusing closed-form least-square (LS) solutions can reduce abundant training timein gradient-free federated learning (FL). The current AFL framework cannotsupport deep neural network (DNN) training, which hinders its implementation oncomplex machine learning tasks. Meanwhile, it overlooks the heterogeneous datadistribution problem that restricts the single global model from performingwell on each client's task. To overcome the first challenge, we propose an AFLframework, namely FedACnnL, in which we resort to a novel local analyticlearning method (ACnnL) and model the training of each layer as a distributedLS problem. For the second challenge, we propose an analytic personalizedfederated meta-learning framework, namely pFedACnnL, which is inherited fromFedACnnL. In pFedACnnL, clients with similar data distribution share a commonrobust global model for fast adapting it to local tasks in an analytic manner.FedACnnL is theoretically proven to require significantly shorter training timethan the conventional zeroth-order (i.e. gradient-free) FL frameworks on DNNtraining while the reduction ratio is $98\%$ in the experiment. Meanwhile,pFedACnnL achieves state-of-the-art (SOTA) model performance in most cases ofconvex and non-convex settings, compared with the previous SOTA frameworks.</description>
      <author>example@mail.com (Shunxian Gu, Chaoqun You, Deke Guo, Zhihao Qu, Bangbang Ren, Zaipeng Xie, Lailong Luo)</author>
      <guid isPermaLink="false">2502.06915v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Stereograph: Stereoscopic event reconstruction using graph neural networks applied to CTAO</title>
      <link>http://arxiv.org/abs/2502.07421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CTAO是一个正在建设中的国际天文台，计划拥有超过六十个望远镜，将成为世界上最大的和最敏感的地面伽马射线观测站。论文探讨了使用图神经网络（GNN）来改进事件重建的方法，并展示了该方法在提高能量分辨率、角分辨率以及区分伽马光子与质子方面优于传统的随机森林算法。&lt;h4&gt;背景&lt;/h4&gt;CTAO通过观察由宇宙中的剧烈现象产生的高能伽马射线，研究宇宙的高能特性。这些伽马射线进入大气层后会产生切伦科夫辐射，被CTAO的高度敏感相机捕捉到。&lt;h4&gt;目的&lt;/h4&gt;探索使用图神经网络（GNN）来优化多台望远镜观测数据的整合和事件重建过程。&lt;h4&gt;方法&lt;/h4&gt;利用模拟的数据集，采用图神经网络模型进行立体重建，并与传统随机森林算法的结果对比。&lt;h4&gt;主要发现&lt;/h4&gt;相比于传统的随机森林方法，基于GNN的方法在能量分辨率、角分辨率上表现更好，同时在区分伽马光子和质子方面也有明显优势。&lt;h4&gt;结论&lt;/h4&gt;图神经网络为提高CTAO事件重建的准确性和性能提供了一种有前景的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The CTAO (Cherenkov Telescope Array Observatory) is an internationalobservatory currently under construction. With more than sixty telescopes, itwill eventually be the largest and most sensitive ground-based gamma-rayobservatory. CTAO studies the high-energy universe by observing gamma raysemitted by violent phenomena (supernovae, black hole environments, etc.). Thesegamma rays produce an atmospheric shower when entering the atmosphere, whichemits faint blue light, observed by CTAO's highly sensitive cameras. The eventreconstruction consists of analyzing the images produced by the telescopes toretrieve the physical properties of the incident particle (mainly direction,energy, and type). A standard method for performing this reconstructionconsists of combining traditional image parameter calculations with machinelearning algorithms, such as random forests, to estimate the particle's energyand class probability for each telescope. A second step, called stereoscopy,combines these monoscopic reconstructions into a global one using weightedaverages. In this work, we explore the possibility of using Graph NeuralNetworks (GNNs) as a suitable solution for combining information from eachtelescope. The "graph" approach aims to link observations from differenttelescopes, allowing analysis of the shower from multiple angles and producinga stereoscopic reconstruction of the events. We apply GNNs to CTAO-simulateddata from the Northern Hemisphere and show that they are a very promisingapproach to improving event reconstruction, providing a more performantstereoscopic reconstruction. In particular, we observe better energy andangular resolutions(before event selection) and better separation between gammaphotons and protons compared to the Random Forest method.</description>
      <author>example@mail.com (Hana Ali Messaoud, Thomas Vuillaume, Tom François)</author>
      <guid isPermaLink="false">2502.07421v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Robust Representations of Neutrino Data</title>
      <link>http://arxiv.org/abs/2502.07724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了对比学习在中微子物理学中的应用，旨在通过结合经验评估和理论见解展示对比学习如何提升模型性能及适应性。&lt;h4&gt;背景&lt;/h4&gt;中微子物理分析依赖于大规模模拟数据集，因此模型需有效泛化至真实世界探测器数据。对比学习作为一种成熟的深度学习技术，为这一挑战提供了有前景的解决方案。&lt;h4&gt;目的&lt;/h4&gt;探究对比学习方法在中微子物理学中的应用，展示其如何提升模型性能和适应性，并将其与其他领域适应技术进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过结合经验评估和理论见解来研究对比学习的方法和技术优势。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习能够通过控制数据增强从模拟数据中提取出稳健且可迁移的特征，从而提升了基于模拟训练模型对真实实验数据分布的适应能力。&lt;h4&gt;结论&lt;/h4&gt;对比学习在解决中微子物理学中的领域适配问题上具有独特的优势，并能显著提高模型性能和适应性。&lt;h4&gt;翻译&lt;/h4&gt;在中微子物理研究中，数据分析通常依赖于大量模拟数据集。为了使基于这些模拟训练得到的模型能够有效地应用于实际探测器的数据中，需要确保模型具备良好的泛化能力。对比学习作为一种成熟的深度学习技术，在这里展现出了它的独特优势：通过应用控制的数据增强技术到模拟数据上，可以提取出更加稳定和可转移的特征，从而使得在模拟数据基础上训练出来的模型更能适应真实实验中的数据分布特性。本论文研究了对比学习方法如何被应用于中微子物理领域，并通过一系列实证评估及理论分析展示其优势所在；同时与其他领域的适配技术进行了比较，突显出对比学习在此特定应用背景下的独特优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In neutrino physics, analyses often depend on large simulated datasets,making it essential for models to generalise effectively to real-world detectordata. Contrastive learning, a well-established technique in deep learning,offers a promising solution to this challenge. By applying controlled dataaugmentations to simulated data, contrastive learning enables the extraction ofrobust and transferable features. This improves the ability of models trainedon simulations to adapt to real experimental data distributions. In this paper,we investigate the application of contrastive learning methods in the contextof neutrino physics. Through a combination of empirical evaluations andtheoretical insights, we demonstrate how contrastive learning enhances modelperformance and adaptability. Additionally, we compare it to other domainadaptation techniques, highlighting the unique advantages of contrastivelearning for this field.</description>
      <author>example@mail.com (Alex Wilkinson, Radi Radev, Saul Alonso-Monsalve)</author>
      <guid isPermaLink="false">2502.07724v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data</title>
      <link>http://arxiv.org/abs/2502.07746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;论文摘要&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HiPoNet的端到端可微神经网络，适用于高维点云数据上的回归、分类和表示学习。该模型特别针对单细胞数据分析进行了优化。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理具有极高维度的单细胞数据时存在局限性，并且现代实验生成了大量的多患者数据集，这需要能够有效处理大规模高维点云的方法。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的问题并提供一种有效的解决方案来处理这些复杂的数据集，HiPoNet被开发出来以利用更高的几何信息进行更复杂的表示学习。&lt;h4&gt;方法&lt;/h4&gt;通过可学习的特征重新加权形成高级单纯复形，生成多个数据视图，并采用基于单纯复形的小波变换提取多尺度特性。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，该模型能够保持拓扑信息并超过现有的点云和图形基线，在单细胞数据分析中表现尤为出色。此外，HiPoNet在空间转录组学中的应用也取得了成功。&lt;h4&gt;结论&lt;/h4&gt;HiPoNet为高维数据的分析提供了一种稳健且可扩展的方法，并具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一个端到端可微神经网络——HiPoNet，用于处理高维度点云上的回归、分类和表示学习。对于单细胞数据分析而言，其复杂性和高度的维度超过了现有方法的能力范围。此外，现代单细胞和空间实验现在产生整个队列的数据集（即每个病人的一个），这需要能够以规模方式处理大量高维点云的模型。大多数当前的方法仅构建单一最近邻图，丢失了重要的几何信息。相比之下，HiPoNet通过可学习的特征重新加权生成更高阶单纯复形，从而产生多个数据视图，将不同的生物过程解耦，并使用基于单纯复形的小波变换来提取多尺度特性——捕捉局部和全局拓扑结构。我们实验证明了这些组件在所学表示中保持拓扑信息的能力，并且HiPoNet显著优于单细胞数据集上的最先进点云和图基线模型。我们也展示了HiPoNet在使用空间坐标作为视图之一的空间转录组数据的应用案例。总的来说，HiPoNet为高维数据分析提供了一种稳健、可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose HiPoNet, an end-to-end differentiable neuralnetwork for regression, classification, and representation learning onhigh-dimensional point clouds. Single-cell data can have high dimensionalityexceeding the capabilities of existing methods point cloud tailored for 3Ddata. Moreover, modern single-cell and spatial experiments now yield entirecohorts of datasets (i.e. one on every patient), necessitating models that canprocess large, high-dimensional point clouds at scale. Most current approachesbuild a single nearest-neighbor graph, discarding important geometricinformation. In contrast, HiPoNet forms higher-order simplicial complexesthrough learnable feature reweighting, generating multiple data views thatdisentangle distinct biological processes. It then employs simplicial wavelettransforms to extract multi-scale features - capturing both local and globaltopology. We empirically show that these components preserve topologicalinformation in the learned representations, and that HiPoNet significantlyoutperforms state-of-the-art point-cloud and graph-based models on single cell.We also show an application of HiPoNet on spatial transcriptomics datasetsusing spatial co-ordinates as one of the views. Overall, HiPoNet offers arobust and scalable solution for high-dimensional data analysis.</description>
      <author>example@mail.com (Siddharth Viswanath, Hiren Madhu, Dhananjay Bhaskar, Jake Kovalic, Dave Johnson, Rex Ying, Christopher Tape, Ian Adelstein, Michael Perlmutter, Smita Krishnaswamy)</author>
      <guid isPermaLink="false">2502.07746v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata</title>
      <link>http://arxiv.org/abs/2502.07461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要介绍&lt;/h4&gt;JamendoMaxCaps是一个大型音乐字幕数据集，包含超过20万首来自知名平台Jamendo的免费许可乐器曲目。&lt;h4&gt;数据集特点&lt;/h4&gt;该数据集包括由最先进的字幕生成模型创建并增强有推断元数据的字幕。&lt;h4&gt;检索系统&lt;/h4&gt;介绍了一种检索系统，利用音乐特征和元数据来识别相似歌曲，并使用本地大型语言模型填补缺失元数据。&lt;h4&gt;目标受众&lt;/h4&gt;此方法为从事音乐-语言理解任务的研究人员提供了一个更全面和信息丰富的数据集。&lt;h4&gt;验证方式&lt;/h4&gt;通过五种不同的度量标准进行定量验证。&lt;h4&gt;公开资源&lt;/h4&gt;将JamendoMaxCaps数据集公开发布，以便于推进包括音乐检索、多模态表示学习以及生成式音乐模型在内的音乐-语言理解任务研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce JamendoMaxCaps, a large-scale music-caption dataset featuringover 200,000 freely licensed instrumental tracks from the renowned Jamendoplatform. The dataset includes captions generated by a state-of-the-artcaptioning model, enhanced with imputed metadata. We also introduce a retrievalsystem that leverages both musical features and metadata to identify similarsongs, which are then used to fill in missing metadata using a local largelanguage model (LLLM). This approach allows us to provide a more comprehensiveand informative dataset for researchers working on music-language understandingtasks. We validate this approach quantitatively with five differentmeasurements. By making the JamendoMaxCaps dataset publicly available, weprovide a high-quality resource to advance research in music-languageunderstanding tasks such as music retrieval, multimodal representationlearning, and generative music models.</description>
      <author>example@mail.com (Abhinaba Roy, Renhang Liu, Tongyu Lu, Dorien Herremans)</author>
      <guid isPermaLink="false">2502.07461v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</title>
      <link>http://arxiv.org/abs/2502.07783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的模型微调技术，称为曲率调整（CT），这种方法基于最近发展的样条算子理论框架。通过单个参数调节模型决策边界的曲率，使得无需训练即可进行模型引导。&lt;h4&gt;背景&lt;/h4&gt;随着大规模模型和数据集的发展，微调成为了利用最新模型的主要方法之一。然而，现有的微调方法如全量或低秩适配器存在大量超参数且缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于样条算子理论的新颖、可解释的微调后处理解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了名为曲率调整（Curvature Tuning, CT）的技术，该技术通过单个参数调节模型决策边界的曲率来实现无训练引导。这种方法相比传统的微调更加高效且具有更好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了CT在提高预训练模型泛化能力和鲁棒性方面的有效性。例如，在十七个下游数据集上，CT使ResNet-18/50的分布外传输性能分别提高了2.57%/1.74%，并在RobustBench上提升了11.76%/348.44%的鲁棒准确性。&lt;h4&gt;结论&lt;/h4&gt;曲率调整（CT）是一种新颖且有效的模型微调方法，能够通过单个参数调节来改善预训练模型在多个任务上的性能，并展示了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;随着模型和数据规模的增长，AI范式已经改变。作为结果，利用最新模型的通用协议是通过微调将其导向特定下游任务。尽管这种方法的重要性，但主要的微调方法仍然局限于全量或低秩适配器——包含无数超参数且缺乏可解释性。本文回顾了从深网络的一个丰富数学框架样条算子理论中推导出新颖和可解释的后训练引导解决方案的可能性。我们的方法——被命名为曲率调整（CT）——具有一个可以证明调节模型决策边界曲率的单一参数，从而可以在无需训练的情况下进行引导。这使得CT比传统的微调方法更加高效且更具可解释性。我们在改善预训练模型的泛化能力和鲁棒性的有效性方面进行了实证验证。例如，在十七个下游数据集上，CT提高了ResNet-18/50分布外传输性能2.57%/1.74%，并且在RobustBench上的鲁棒准确性提升了11.76%/348.44%。此外，我们将CT应用于基于ReLU的Swin-T/S，在九个下游数据集上提高了泛化能力2.43%/3.33%。我们的代码可在https://github.com/Leon-Leyang/curvature-tuning获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scaling of model size and data size has reshaped the paradigm of AI. As aresult, the common protocol to leverage the latest models is to steer themtowards a specific downstream task of interest through {\em fine-tuning}.Despite its importance, the main methods for fine-tuning remain limited to fullor low-rank adapters--containing countless hyper-parameters and lackinginterpretability. In this paper, we take a step back and demonstrate how noveland explainable post-training steering solutions can be derived theoreticallyfrom {\em spline operators}, a rich mathematical framing of Deep Networks thatwas recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--hasa single parameter that provably modulates the curvature of the model'sdecision boundary henceforth allowing training-free steering. This makes CTboth more efficient and interpretable than conventional fine-tuning methods. Weempirically validate its effectiveness in improving generalization androbustness of pretrained models. For example, CT improves out-of-distributiontransfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeendownstream datasets, and improves RobustBench robust accuracy by11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improvingtheir generalization on nine downstream datasets by 2.43\%/3.33\%. Our code isavailable at\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.</description>
      <author>example@mail.com (Leyang Hu, Randall Balestriero)</author>
      <guid isPermaLink="false">2502.07783v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Effects of Random Edge-Dropping on Over-Squashing in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.07364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 7 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了消息传递神经网络（MPNN）在图神经网络中的挑战，特别是过度平滑和过度压缩问题，并分析了几种用于解决过度平滑问题的算法对过度压缩的影响。&lt;h4&gt;背景&lt;/h4&gt;Message Passing Neural Networks (MPNNs) 利用图拓扑结构在网络中传播信息。然而，这种消息传递机制导致了过度平滑和过度压缩两个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;研究针对过度平滑设计的各种算法（如DropEdge及其变体）在解决过度压缩问题方面的效果，填补文献中的这一空白。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和实验评估来探讨这些算法如何影响过度压缩，并使用真实数据集进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;DropEdge和其他类似技术虽然可以改善短距离任务的性能，但在长距离任务中会导致模型过拟合训练集中短距离特征，从而损害了泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文强调需要重新评估用于深度GNN训练的各种方法，并重视建模长程相互作用的重要性。&lt;h4&gt;翻译&lt;/h4&gt;消息传递神经网络（MPNNs）是一种图神经网络类算法，它们利用图的拓扑结构在网络中传播信息。这种消息传递机制引发了过度平滑和过度压缩两个主要挑战。尽管有一些算法如DropEdge及其变体在解决过度平滑问题上取得了成功，但它们对过度压缩的影响尚未被充分研究。这是一个重要的文献空白，因为无法缓解过度压缩会使这些方法不适合长距离任务。在这项工作中，我们首次尝试通过研究上述算法在过度压缩背景下的表现来填补这一空白，并提出了一种新的理论结果，该结果显示DropEdge会降低图神经网络的有效感受野，从而对远距离节点间的敏感度产生负面影响，这表明它不适用于长程任务。我们的发现可以很容易地扩展到其变体中，使我们能够全面理解它们如何影响过度压缩。我们在真实世界数据集上评估了这些方法，并展示了它们的负面效果：虽然DropEdge变种在短距离任务中的测试性能得到改善，但在长距离任务中则表现不佳。我们的理论解释说，随机边缘删除降低了GNN的有效感受野，这虽然是有益于短程任务的优点，但使模型与远程任务不一致，迫使模型过度拟合训练集中的短程特征，从而导致泛化能力差。我们的结论强调了重新评估用于深度图神经网络训练的各种方法的必要性，并着重关注建模长距离相互作用的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks(GNNs) that leverage the graph topology to propagate messages acrossincreasingly larger neighborhoods. The message-passing scheme leads to twodistinct challenges: over-smoothing and over-squashing. While severalalgorithms, e.g. DropEdge and its variants -- DropNode, DropAgg and DropGNN --have successfully addressed the over-smoothing problem, their impact onover-squashing remains largely unexplored. This represents a critical gap inthe literature as failure to mitigate over-squashing would make these methodsunsuitable for long-range tasks. In this work, we take the first step towardsclosing this gap by studying the aforementioned algorithms in the context ofover-squashing. We present novel theoretical results that characterize thenegative effects of DropEdge on sensitivity between distant nodes, suggestingits unsuitability for long-range tasks. Our findings are easily extended to itsvariants, allowing us to build a comprehensive understanding of how they affectover-squashing. We evaluate these methods using real-world datasets,demonstrating their detrimental effects. Specifically, we show that whileDropEdge-variants improve test-time performance in short range tasks, theydeteriorate performance in long-range ones. Our theory explains these resultsas follows: random edge-dropping lowers the effective receptive field of GNNs,which although beneficial for short-range tasks, misaligns the models onlong-range ones. This forces the models to overfit to short-range artefacts inthe training set, resulting in poor generalization. Our conclusions highlightthe need to re-evaluate various methods designed for training deep GNNs, with arenewed focus on modelling long-range interactions.</description>
      <author>example@mail.com (Jasraj Singh, Keyue Jiang, Brooks Paige, Laura Toni)</author>
      <guid isPermaLink="false">2502.07364v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.07645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的交互式模仿学习框架，将行为克隆扩展为一个迭代过程，以估计和优化最优动作集，并通过人类纠正提供理论保证。&lt;h4&gt;背景&lt;/h4&gt;传统的行为克隆方法依赖于演示数据，假设展示的动作是最优的。然而，在存在噪声的数据情况下，这可能导致过度拟合问题，特别是在使用表达能力强的模型（如基于能量的模型）时。&lt;h4&gt;目的&lt;/h4&gt;解决行为克隆在面对噪声数据和多样反馈类型时的问题，并提出一种新的交互式模仿学习方法来优化动作选择策略。&lt;h4&gt;方法&lt;/h4&gt;引入对比政策学习从互动校正中受益的方法（CLIC），它使用人类纠正来估计一组期望的动作并优化策略以从该集合中选择动作。&lt;h4&gt;主要发现&lt;/h4&gt;CLIC在模拟和真实机器人实验中优于现有的最先进方法，展示了稳定的基于能量模型的训练、对反馈噪声的鲁棒性以及适应多种反馈类型的能力。&lt;h4&gt;结论&lt;/h4&gt;通过互动校正来估计最优动作集并优化策略能够有效地解决行为克隆中的过度拟合问题，并且具有良好的泛化能力和稳健性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavior cloning (BC) traditionally relies on demonstration data, assumingthe demonstrated actions are optimal. This can lead to overfitting under noisydata, particularly when expressive models are used (e.g., the energy-basedmodel in Implicit BC). To address this, we extend behavior cloning into aniterative process of optimal action estimation within the Interactive ImitationLearning framework. Specifically, we introduce Contrastive policy Learning fromInteractive Corrections (CLIC). CLIC leverages human corrections to estimate aset of desired actions and optimizes the policy to select actions from thisset. We provide theoretical guarantees for the convergence of the desiredaction set to optimal actions in both single and multiple optimal action cases.Extensive simulation and real-robot experiments validate CLIC's advantages overexisting state-of-the-art methods, including stable training of energy-basedmodels, robustness to feedback noise, and adaptability to diverse feedbacktypes beyond demonstrations. Our code will be publicly available soon.</description>
      <author>example@mail.com (Zhaoting Li, Rodrigo Pérez-Dattari, Robert Babuska, Cosimo Della Santina, Jens Kober)</author>
      <guid isPermaLink="false">2502.07645v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GaRLIO: Gravity enhanced Radar-LiDAR-Inertial Odometry</title>
      <link>http://arxiv.org/abs/2502.07703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GaRLIO是一种结合雷达和LiDAR惯性里程计的改进方法，利用雷达直接测速数据来提高重力估计准确性，并减少垂直漂移。&lt;h4&gt;背景&lt;/h4&gt;目前在线重力估计主要依赖于姿态估计与IMU测量，而未充分利用提供直接速度信息的雷达传感器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法GaRLIO以利用雷达提供的直接速度测量数据，改进现有的重力估计和状态估计技术。&lt;h4&gt;方法&lt;/h4&gt;通过融合雷达点云的速度信息预测重力，并同时在动态环境中移除动态对象来增强鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在多种容易出现垂直漂移的环境下，GaRLIO的表现优于传统LiDAR-Inertial Odometry（LIO）方法。&lt;h4&gt;结论&lt;/h4&gt;通过利用雷达传感器直接测速数据改进了重力估计准确性，并提高了状态估计性能。该方法已经在公开源代码中提供以促进进一步研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;最近，重力被强调为缓解潜在垂直漂移的状态估计中的关键约束条件。现有的在线重力估计技术主要依赖于姿态估计结合IMU测量数据，在没有直接速度测量的情况下被视为最佳实践。然而，利用雷达传感器提供的直接速度信息进行重力估算的潜力尚未得到充分利用，这为我们提供了提高重力估算准确性的重大机会。GaRLIO（基于增强雷达-激光雷达惯性里程计的重力改进）能够稳健地预测重力以减少垂直漂移，并通过使用点对点的速度测量数据来提升状态估计性能。此外，该方法在动态环境中确保了鲁棒性，利用雷达去除LiDAR点云中的动态物体。我们的方法已在各种易发生垂直漂移的环境下通过实验验证，结果显示优于传统LiDAR-Inertial Odometry（LIO）技术的表现。我们公开发布了源代码以鼓励进一步的研究和开发。（https://github.com/ChiyunNoh/GaRLIO）&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, gravity has been highlighted as a crucial constraint for stateestimation to alleviate potential vertical drift. Existing online gravityestimation methods rely on pose estimation combined with IMU measurements,which is considered best practice when direct velocity measurements areunavailable. However, with radar sensors providing direct velocity data-ameasurement not yet utilized for gravity estimation-we found a significantopportunity to improve gravity estimation accuracy substantially. GaRLIO, theproposed gravity-enhanced Radar-LiDAR-Inertial Odometry, can robustly predictgravity to reduce vertical drift while simultaneously enhancing stateestimation performance using pointwise velocity measurements. Furthermore,GaRLIO ensures robustness in dynamic environments by utilizing radar to removedynamic objects from LiDAR point clouds. Our method is validated throughexperiments in various environments prone to vertical drift, demonstratingsuperior performance compared to traditional LiDAR-Inertial Odometry methods.We make our source code publicly available to encourage further research anddevelopment. https://github.com/ChiyunNoh/GaRLIO</description>
      <author>example@mail.com (Chiyun Noh, Wooseong Yang, Minwoo Jung, Sangwoo Jung, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.07703v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Instance-dependent Early Stopping</title>
      <link>http://arxiv.org/abs/2502.07547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在机器学习实践中，提前停止技术已被广泛用于正则化模型，并且通过在验证集上的性能不再提升时终止训练过程来节省计算成本。然而，传统的提前停止方法对所有样本采用相同的停止标准，没有考虑它们各自的训练状态，导致那些已经学得很好的样本进行冗余的计算。为了进一步提高效率，我们提出了一种基于实例的提前停止（IES）方法，该方法将提前停止机制从整个训练集调整为实例级别，并且根据核心原则，在模型掌握一个实例后应立即停止对该实例的训练。IES认为如果某个实例损失值的二阶差值在零附近保持在一个很小的范围内，则这个实例就被视为已经掌握了。这提供了一种比直接使用损失值更一致的方式来衡量一个实例的学习状态，因此允许设置统一的标准来确定何时可以将某个实例排除出后续的反向传播过程。我们还表明，从反向传播中移除已掌握的样本可以增加梯度幅度，从而加速训练损失下降的速度，并加快整个训练进程。大量的基准实验显示IES方法能够减少10%-50%的反向传播实例数量，同时保持或略微提高模型在测试集上的准确率和迁移学习性能。&lt;h4&gt;背景&lt;/h4&gt;传统提前停止技术存在对所有样本采用相同标准的问题，可能导致已学得较好的样本进行不必要的计算。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于实例的提前停止（IES）方法以提高机器学习训练效率。&lt;h4&gt;方法&lt;/h4&gt;将提前停止机制从整个训练集调整到每个具体实例上。使用损失值的二阶差值得出是否已经掌握一个特定实例的标准，并在此基础上决定何时排除这个实例，从而加快模型训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;IES能够通过减少不必要的反向传播过程提高计算效率并保持或改善测试准确率及迁移学习性能。&lt;h4&gt;结论&lt;/h4&gt;基于实例的提前停止技术（IES）在不牺牲精度的情况下显著提高了机器学习算法的训练效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In machine learning practice, early stopping has been widely used toregularize models and can save computational costs by halting the trainingprocess when the model's performance on a validation set stops improving.However, conventional early stopping applies the same stopping criterion to allinstances without considering their individual learning statuses, which leadsto redundant computations on instances that are already well-learned. Tofurther improve the efficiency, we propose an Instance-dependent Early Stopping(IES) method that adapts the early stopping mechanism from the entire trainingset to the instance level, based on the core principle that once the model hasmastered an instance, the training on it should stop. IES considers an instanceas mastered if the second-order differences of its loss value remain within asmall range around zero. This offers a more consistent measure of an instance'slearning status compared with directly using the loss value, and thus allowsfor a unified threshold to determine when an instance can be excluded fromfurther backpropagation. We show that excluding mastered instances frombackpropagation can increase the gradient norms, thereby accelerating thedecrease of the training loss and speeding up the training process. Extensiveexperiments on benchmarks demonstrate that IES method can reducebackpropagation instances by 10%-50% while maintaining or even slightlyimproving the test accuracy and transfer learning performance of a model.</description>
      <author>example@mail.com (Suqin Yuan, Runqi Lin, Lei Feng, Bo Han, Tongliang Liu)</author>
      <guid isPermaLink="false">2502.07547v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer</title>
      <link>http://arxiv.org/abs/2502.07158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了PedCA-FT框架，该框架结合了EHR的表格视图和衍生文本视图来预测儿童心脏骤停。&lt;h4&gt;背景&lt;/h4&gt;早期识别儿科心脏骤停对于高风险重症监护环境中的及时干预至关重要。&lt;h4&gt;目的&lt;/h4&gt;利用融合多模态数据的方法提高早期检测心脏骤停的能力并改善患者护理。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于Transformer的框架PedCA-FT，该框架分别使用专用模块处理EHR的表格和文本视图，并捕捉复杂的时间序列模式。&lt;h4&gt;主要发现&lt;/h4&gt;在CHOA-CICU数据库中选取的研究队列上进行了评估，结果显示模型性能优于其他十个人工智能模型，同时识别出有意义的风险因素。&lt;h4&gt;结论&lt;/h4&gt;多模态融合技术在提高早期心脏骤停检测的准确性方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：儿童期心脏骤停（CA）的早期预测对于重症监护环境中高风险患者及时干预至关重要。我们提出了一种基于Transformer的新框架PedCA-FT，该框架结合了EHR表格视图与衍生文本视图，全面释放出高维风险因素及其动态变化之间的相互作用。通过为每种模态视图应用专用的Transformer模块，PedCA-FT捕捉复杂的时间序列和上下文模式，从而产生稳健的心脏骤停风险评估。在CHOA-CICU数据库中的一个儿科队列上进行评估，我们的方法在五个关键性能指标中优于其他十个人工智能模型，并识别出具有临床意义的风险因素。这些发现强调了多模态融合技术增强早期心脏骤停检测的潜力以及改善患者护理的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early prediction of pediatric cardiac arrest (CA) is critical for timelyintervention in high-risk intensive care settings. We introduce PedCA-FT, anovel transformer-based framework that fuses tabular view of EHR with thederived textual view of EHR to fully unleash the interactions ofhigh-dimensional risk factors and their dynamics. By employing dedicatedtransformer modules for each modality view, PedCA-FT captures complex temporaland contextual patterns to produce robust CA risk estimates. Evaluated on acurated pediatric cohort from the CHOA-CICU database, our approach outperformsten other artificial intelligence models across five key performance metricsand identifies clinically meaningful risk factors. These findings underscorethe potential of multimodal fusion techniques to enhance early CA detection andimprove patient care.</description>
      <author>example@mail.com (Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.07158v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Music for All: Exploring Multicultural Representations in Music Generation Models (Camera Ready)</title>
      <link>http://arxiv.org/abs/2502.07328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, accepted to NAACL'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文研究了音乐生成领域的数据集和文献，量化了不同音乐流派的偏差与代表性不足问题，并探讨了解决这一问题的方法。&lt;h4&gt;背景&lt;/h4&gt;音乐语言模型在自动音乐生成方面取得了显著进展，但它们对于世界各种音乐类型和文化的覆盖范围有限。&lt;h4&gt;目的&lt;/h4&gt;研究现有的音乐数据集和相关论文，评估这些模型在不同音乐流派上的性能偏差，并探索减轻这种偏差的技术方法。&lt;h4&gt;方法&lt;/h4&gt;分析现有音乐数据集中非西方音乐的占比；应用参数高效微调（PEFT）技术测试两个流行模型（MusicGen和Mustang）对于两种代表性不足的非西方音乐传统（印度斯坦古典音乐与土耳其马卡姆音乐）的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;现有的音乐数据集中，只有5.7%的时间属于非西方音乐；通过小规模数据集在不同流派之间进行微调以提高模型性能存在一定的挑战和潜力。&lt;h4&gt;结论&lt;/h4&gt;需要设计更加公平的基础音乐语言模型，这些模型更适合跨文化的转移学习。&lt;h4&gt;翻译&lt;/h4&gt;音乐语言模型的出现极大地提升了AI系统自动创作音乐的能力，但它们对世界各种音乐类型和文化的覆盖仍然有限。我们研究了用于音乐生成的数据集和相关文献，并量化了其中不同流派的偏见与代表性不足问题。研究表明，现有的音乐数据集中只有5.7%的时间属于非西方音乐，这导致模型在处理不同音乐风格时的表现差距显著。接着，我们考察了参数高效微调（PEFT）技术减轻此类偏差的可能性，通过两种流行模型（MusicGen和Mustang）对两个代表性不足的非西方音乐传统——印度斯坦古典音乐与土耳其马卡姆音乐进行实验，证明了解决跨流派适应问题的小规模数据集的有效性及其挑战。这表明需要设计更加公平的基础音乐语言模型，这些模型更适合跨文化的转移学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Music-Language Models has greatly enhanced the automatic musicgeneration capability of AI systems, but they are also limited in theircoverage of the musical genres and cultures of the world. We present a study ofthe datasets and research papers for music generation and quantify the bias andunder-representation of genres. We find that only 5.7% of the total hours ofexisting music datasets come from non-Western genres, which naturally leads todisparate performance of the models across genres. We then investigate theefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigatingthis bias. Our experiments with two popular models -- MusicGen and Mustango,for two underrepresented non-Western music traditions -- Hindustani Classicaland Turkish Makam music, highlight the promises as well as the non-trivialityof cross-genre adaptation of music through small datasets, implying the needfor more equitable baseline music-language models that are designed forcross-cultural transfer learning.</description>
      <author>example@mail.com (Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury)</author>
      <guid isPermaLink="false">2502.07328v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes</title>
      <link>http://arxiv.org/abs/2502.07145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本论文提出了一种新的统计形状建模（SSM）方法Mesh2SSM++，用于改进解剖评估。&lt;h4&gt;背景&lt;/h4&gt;统计形状模型在解剖学评价中至关重要，它们从MRI和CT扫描中提取定量形态描述符，全面地描述了一个群体中的解剖变异。然而，这些模型的有效性依赖于高质量且鲁棒的形状模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需监督的方法来估计对应关系，并通过无偏的概率模板学习方式改进现有的SSM方法。&lt;h4&gt;方法&lt;/h4&gt;Mesh2SSM++能够从网格中直接学习对齐关系，从而不需要预设的形状模型。它采用概率形式化并量化不确定性以提高决策可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示Mesh2SSM++在各种解剖结构、评估指标和下游任务上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Mesh2SSM++通过其计算效率和解释性提供了传统及基于深度学习的SSM方法的一个有吸引力的选择，特别是在具有挑战性的成像条件下表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;解剖学评价对于理解生理状态、诊断异常以及指导医疗干预至关重要。统计形状模型（SSM）在此过程中起着关键作用，通过从MRI和CT扫描中提取定量形态描述符来提供一个群体中的解剖变异的全面描述。然而，SSM的有效性依赖于高质量且鲁棒的形状模型，而现有方法在这一方面仍存在限制，并往往需要预设的形状模型进行训练。为了克服这些挑战，我们提出了一种新的方法Mesh2SSM++，它能够以无监督方式学习从网格中估计对应关系的方式。该方法利用无偏、排列不变性表示学习来推断如何将一个模板点云变形为受试者的特定网格，形成基于对应的形状模型。此外，其概率形式化允许学习出适应于不同群体的模板，减少与模板选择相关的潜在偏差。Mesh2SSM++的一个关键特征是能够量化固有的数据变异性（即不确定性），这对于确保可靠的模型预测和在临床任务中的稳健决策至关重要，特别是在具有挑战性的成像条件下。通过在各种解剖结构、评估指标及下游任务上的广泛验证，我们证明了Mesh2SSM++优于现有方法。该方法由于其直接处理网格的能力，以及概率框架提供的计算效率与可解释性，在传统的和基于深度学习的SSM方法中具有竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anatomy evaluation is crucial for understanding the physiological state,diagnosing abnormalities, and guiding medical interventions. Statistical shapemodeling (SSM) is vital in this process. By enabling the extraction ofquantitative morphological shape descriptors from MRI and CT scans, SSMprovides comprehensive descriptions of anatomical variations within apopulation. However, the effectiveness of SSM in anatomy evaluation hinges onthe quality and robustness of the shape models. While deep learning techniquesshow promise in addressing these challenges by learning complex nonlinearrepresentations of shapes, existing models still have limitations and oftenrequire pre-established shape models for training. To overcome these issues, wepropose Mesh2SSM++, a novel approach that learns to estimate correspondencesfrom meshes in an unsupervised manner. This method leverages unsupervised,permutation-invariant representation learning to estimate how to deform atemplate point cloud into subject-specific meshes, forming acorrespondence-based shape model. Additionally, our probabilistic formulationallows learning a population-specific template, reducing potential biasesassociated with template selection. A key feature of Mesh2SSM++ is its abilityto quantify aleatoric uncertainty, which captures inherent data variability andis essential for ensuring reliable model predictions and robust decision-makingin clinical tasks, especially under challenging imaging conditions. Throughextensive validation across diverse anatomies, evaluation metrics, anddownstream tasks, we demonstrate that Mesh2SSM++ outperforms existing methods.Its ability to operate directly on meshes, combined with computationalefficiency and interpretability through its probabilistic framework, makes itan attractive alternative to traditional and deep learning-based SSMapproaches.</description>
      <author>example@mail.com (Krithika Iyer, Mokshagna Sai Teja Karanam, Shireen Elhabian)</author>
      <guid isPermaLink="false">2502.07145v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative Distribution Prediction: A Unified Approach to Multimodal Learning</title>
      <link>http://arxiv.org/abs/2502.07090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了Generative Distribution Prediction (GDP)框架，该框架利用多模态合成数据生成技术来提高预测性能。&lt;h4&gt;背景&lt;/h4&gt;在处理包含表格、文本和视觉输入或输出的多元异构数据类型时，传统的预测方法往往难以保持高精度。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够集成不同类型的多模态数据，并通过增强合成数据生成能力来提升预测准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;利用条件扩散模型作为生成技术的核心，GDP是一种与任何高质量生成模型兼容的框架，支持迁移学习以适应不同的领域需求。该研究还为GDP提供了统计保证的基础理论。&lt;h4&gt;主要发现&lt;/h4&gt;通过估计数据生成分布并针对多种损失函数进行风险最小化调整，GDP能够实现跨多模态环境下的准确点预测。&lt;h4&gt;结论&lt;/h4&gt;实验验证表明，GDP在表格数据预测、问答系统、图像描述和自适应分位数回归等四个监督学习任务上表现出色，展示了其在不同领域的通用性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;精确的多模式数据（包括表格数据、文本和视觉输入或输出）预测对于推动各种应用领域中的数据分析至关重要。传统的预测方法往往难以同时处理不同的数据类型，并保持高准确性。我们提出了生成分布预测（GDP），这是一个新颖框架，它利用条件扩散模型等多模式合成数据生成技术来增强结构化和非结构化模态下的预测性能。GDP是模型无关的，可以与任何高质量生成模型配合使用，并支持领域适应性迁移学习。我们为GDP建立了严格的理论基础，提供了当使用扩散模型作为核心生成器时，其准确性的统计保证。通过估计数据生成分布并根据不同的风险最小化损失函数进行调整，GDP能够在多模态设置中实现精确的点预测。我们在表格数据预测、问答系统、图像描述和自适应分位数回归等四个监督学习任务上验证了GDP的表现，显示了它在不同领域的通用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction with multimodal data-encompassing tabular, textual, andvisual inputs or outputs-is fundamental to advancing analytics in diverseapplication domains. Traditional approaches often struggle to integrateheterogeneous data types while maintaining high predictive accuracy. Weintroduce Generative Distribution Prediction (GDP), a novel framework thatleverages multimodal synthetic data generation-such as conditional diffusionmodels-to enhance predictive performance across structured and unstructuredmodalities. GDP is model-agnostic, compatible with any high-fidelity generativemodel, and supports transfer learning for domain adaptation. We establish arigorous theoretical foundation for GDP, providing statistical guarantees onits predictive accuracy when using diffusion models as the generative backbone.By estimating the data-generating distribution and adapting to various lossfunctions for risk minimization, GDP enables accurate point predictions acrossmultimodal settings. We empirically validate GDP on four supervised learningtasks-tabular data prediction, question answering, image captioning, andadaptive quantile regression-demonstrating its versatility and effectivenessacross diverse domains.</description>
      <author>example@mail.com (Xinyu Tian, Xiaotong Shen)</author>
      <guid isPermaLink="false">2502.07090v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title>
      <link>http://arxiv.org/abs/2502.07701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Magic 1-For-1 (Magic141) 是一种高效的视频生成模型，通过优化内存消耗和推理延迟来提高效率。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到视频生成任务在训练和推断过程中存在计算成本高、收敛速度慢的问题。为解决这些问题，该研究提出了一种新的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种更有效率的视频生成模型，并通过一系列优化技术减少其计算成本和推理延迟。&lt;h4&gt;方法&lt;/h4&gt;{'分解任务': '将文本到视频的任务分解成两个更容易处理的任务：文字到图像生成和图像到视频生成。', '模型收敛加速': '使用多模态先验条件注入来加快模型的收敛速度。', '推断延迟优化': '通过对抗性步骤蒸馏，减少推理延迟。', '内存成本优化': '采用参数稀疏化技术进行推理内存开销的优化。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'任务分解的有效性': '验证了将文本到视频的任务拆分为图像到视频的任务可以更快地收敛。', '计算成本降低': '通过一系列方法成功降低了训练和推断阶段的成本，实现了5秒视频生成在3秒内完成。', '长视频生成优化': '利用测试时间滑动窗口技术，在一分钟内能够生成一分钟时长的高质量视频，平均花费不到一秒的时间来生成每秒钟的视频片段。'}&lt;h4&gt;结论&lt;/h4&gt;Magic 1-For-1 在计算成本和视频质量之间找到了最佳平衡点，为开源探索提供了坚实的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;在这份技术报告中，我们介绍了Magic 1-For-1 (Magic141)，这是一种高效地生成视频的模型，在内存消耗和推理延迟上都有优化。该方法的核心思想很简单：将文本到视频的任务分解成两个单独且更容易处理的任务进行扩散步骤蒸馏，即文字到图像生成和图像到视频生成。我们验证了在相同的优化算法下，图像到视频任务的确比文本到视频任务更易于收敛。此外，还探索了一套优化技巧来降低训练图像到视频(I2V)模型的计算成本，并从三个方面实现了这个目标：1）通过使用多模态先验条件注入加快模型的收敛速度；2）应用对抗性步骤蒸馏减少推理延迟；3）采用参数稀疏化技术进行推理内存开销优化。利用这些技术，我们可以实现在3秒内生成5秒钟的视频片段。通过在测试时间滑动窗口中应用这种方法，我们能够在一分钟内生成一整分钟时长的高质量视频，并且显著提升了视觉质量和运动动态性，在平均意义上花费不到一秒的时间来生成每秒钟的视频片段。我们进行了一系列初步探索以找到扩散步骤蒸馏过程中计算成本和视频质量之间的最佳折衷点，希望这可以成为一个很好的开源探索基础模型。相关代码与权重可在https://github.com/DA-Group-PKU/Magic-1-For-1 上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this technical report, we present Magic 1-For-1 (Magic141), an efficientvideo generation model with optimized memory consumption and inference latency.The key idea is simple: factorize the text-to-video generation task into twoseparate easier tasks for diffusion step distillation, namely text-to-imagegeneration and image-to-video generation. We verify that with the sameoptimization algorithm, the image-to-video task is indeed easier to convergeover the text-to-video task. We also explore a bag of optimization tricks toreduce the computational cost of training the image-to-video (I2V) models fromthree aspects: 1) model convergence speedup by using a multi-modal priorcondition injection; 2) inference latency speed up by applying an adversarialstep distillation, and 3) inference memory cost optimization with parametersparsification. With those techniques, we are able to generate 5-second videoclips within 3 seconds. By applying a test time sliding window, we are able togenerate a minute-long video within one minute with significantly improvedvisual quality and motion dynamics, spending less than 1 second for generating1 second video clips on average. We conduct a series of preliminaryexplorations to find out the optimal tradeoff between computational cost andvideo quality during diffusion step distillation and hope this could be a goodfoundation model for open-source explorations. The code and the model weightsare available at https://github.com/DA-Group-PKU/Magic-1-For-1.</description>
      <author>example@mail.com (Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou)</author>
      <guid isPermaLink="false">2502.07701v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2502.07505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种高效、连续且局部SE(3)等变的卷积层，用于点云处理。该方法基于通用群卷积和本地参考框架。&lt;h4&gt;背景&lt;/h4&gt;将卷积神经网络的翻译等变性扩展到更大的对称组可以减少样本复杂度并促进更具区分力的特征学习。进一步利用额外的对称性比标准卷积共享更多权重，从而在不增加参数数量的情况下提高网络表达能力。&lt;h4&gt;目的&lt;/h4&gt;为点云处理开发一种计算成本低、连续且局部SE(3)等变的卷积层。&lt;h4&gt;方法&lt;/h4&gt;采用通用群卷积和本地参考框架技术来构建高效的SE(3)等变卷积层，以应对3D数据扩展至SE(3)对称性的6维卷积操作挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该工作提出的方法在多种数据集和任务上（包括对象分类和语义分割）达到了竞争或更好的性能，并且计算开销可以忽略不计。&lt;h4&gt;结论&lt;/h4&gt;所提出的连续、局部SE(3)等变卷积层为处理由多个物体组成的场景提供了有效的解决方案，同时保持了较低的计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extending the translation equivariance property of convolutional neuralnetworks to larger symmetry groups has been shown to reduce sample complexityand enable more discriminative feature learning. Further, exploiting additionalsymmetries facilitates greater weight sharing than standard convolutions,leading to an enhanced network expressivity without an increase in parametercount. However, extending the equivariant properties of a convolution layercomes at a computational cost. In particular, for 3D data, expandingequivariance to the SE(3) group (rotation and translation) results in a 6Dconvolution operation, which is not tractable for larger data samples such as3D scene scans. While efforts have been made to develop efficient SE(3)equivariant networks, existing approaches rely on discretization or onlyintroduce global rotation equivariance. This limits their applicability topoint clouds representing a scene composed of multiple objects. This workpresents an efficient, continuous, and local SE(3) equivariant convolutionlayer for point cloud processing based on general group convolution and localreference frames. Our experiments show that our approach achieves competitiveor superior performance across a range of datasets and tasks, including objectclassification and semantic segmentation, with negligible computationaloverhead.</description>
      <author>example@mail.com (Lisa Weijler, Pedro Hermosilla)</author>
      <guid isPermaLink="false">2502.07505v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks</title>
      <link>http://arxiv.org/abs/2502.07325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文提出了一种基于课程迁移学习的物理信息神经网络（CTL-PINN）用于长时间模拟物理和机械行为。该方法的主要创新在于将长期问题分解为一系列短期子问题，通过课程学习方法结合先前步骤的信息来解决后续的时间域问题，并且引入了转移学习技术以有效利用之前训练的数据。&lt;h4&gt;背景&lt;/h4&gt;标准的物理信息神经网络（PINN）在处理长时间模拟时遇到了局部优化和时间域扩展不准确等问题。基于此，研究者提出了将课程学习和迁移学习相结合的方法来解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CTL-PINN方法以克服标准PINN模型的问题，并提高长期计算挑战的解决能力。&lt;h4&gt;方法&lt;/h4&gt;1. 将长时间问题分解成短期子问题；2. 初始使用标准PINN处理第一个子问题；3. 在后续时间域问题中应用课程学习方法，整合之前步骤的信息；4. 使用转移学习技术有效利用先前训练数据；5. 综合运用课程学习和迁移学习的优势。&lt;h4&gt;主要发现&lt;/h4&gt;CTL-PINN能有效地解决长时间计算中的局部优化问题，并提高了在非线性波传播、Kirchhoff板动态响应以及三峡水库区域水动力学模型等场景下的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过将课程学习和转移学习相结合，CTL-PINN能够更好地处理长期物理行为的模拟挑战，显示出了优于其他方法的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a Curriculum-Transfer-Learning based physics-informedneural network (CTL-PINN) for long-term simulation of physical and mechanicalbehaviors. The main innovation of CTL-PINN lies in decomposing long-termproblems into a sequence of short-term subproblems. Initially, the standardPINN is employed to solve the first sub-problem. As the simulation progresses,subsequent time-domain problems are addressed using a curriculum learningapproach that integrates information from previous steps. Furthermore, transferlearning techniques are incorporated, allowing the model to effectively utilizeprior training data and solve sequential time domain transfer problems.CTL-PINN combines the strengths of curriculum learning and transfer learning,overcoming the limitations of standard PINNs, such as local optimizationissues, and addressing the inaccuracies over extended time domains encounteredin CL-PINN and the low computational efficiency of TL-PINN. The efficacy androbustness of CTL-PINN are demonstrated through applications to nonlinear wavepropagation, Kirchhoff plate dynamic response, and the hydrodynamic model ofthe Three Gorges Reservoir Area, showcasing its superior capability inaddressing long-term computational challenges.</description>
      <author>example@mail.com (Yuan Guo, Zhuojia Fu, Jian Min, Shiyu Lin, Xiaoting Liu, Youssef F. Rashed, Xiaoying Zhuang)</author>
      <guid isPermaLink="false">2502.07325v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift</title>
      <link>http://arxiv.org/abs/2502.07620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了大规模对比预训练模型在概念漂移环境下的挑战，提出了一种基于因果推理的方法来减轻这种影响。&lt;h4&gt;背景&lt;/h4&gt;随着顶级数据集的推动，大型对比预训练的发展达到了一个转变点。当前，在变化的数据分布下保持和提升模型的预训练能力成为一个显著挑战。&lt;h4&gt;目的&lt;/h4&gt;通过深入分析对比预训练方法在概念漂移环境下的表现，并提出一种新的预训练策略来增强模型应对动态数据的能力。&lt;h4&gt;方法&lt;/h4&gt;利用因果推理构建了结构因果图，系统性地分析了概念漂移对对比预训练的影响。提出了因果干预对比目标，并设计了一种能够适应概念漂移动态数据流的鲁棒对比预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;对比预训练模型受到概念漂移显著影响，导致特征空间出现偏差。所提出的因果介入式对比目标和鲁棒预训练策略能有效减轻这一偏见。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，在不同的下游任务上，该鲁棒对比预训练方法可以有效缓解来自概念漂移数据流的偏见问题。&lt;h4&gt;翻译&lt;/h4&gt;大规模对比预训练模型的发展已经达到了一个转变点。然而在不断变化的数据分布下保持和提升这些模型的能力成为了新的挑战。本文发现对比预训练方法受到不确定变动数据分布的影响，导致特征空间出现偏差。基于因果推理，构造了结构因果图来分析概念漂移对对比预训练系统性影响，并提出了一种新的目标函数——因果干预式对比目标。此外还设计了一个能够适应动态变化的鲁棒预训练方案，在一系列下游任务上的实验表明该方法可以有效减轻来自概念漂移动态数据流的偏见问题。代码可在https://anonymous.4open.science/r/ResilientCL/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of large-scale contrastive pre-training propelled by top-tierdatasets has reached a transition point in the scaling law. Consequently,sustaining and enhancing a model's pre-training capabilities in driftenvironments have surfaced as a notable challenge. In this paper, we initiallyuncover that contrastive pre-training methods are significantly impacted byconcept drift wherein distributions change unpredictably, resulting in notablebiases in the feature space of the pre-trained model. Empowered by causalinference, we construct a structural causal graph to analyze the impact ofconcept drift to contrastive pre-training systemically, and propose the causalinterventional contrastive objective. Upon achieving this, we devise aresilient contrastive pre-training approach to accommodate the data stream ofconcept drift, with simple and scalable implementation. Extensive experimentson various downstream tasks demonstrate our resilient contrastive pre-trainingeffectively mitigates the bias stemming from the concept drift data stream.Codes are available at https://anonymous.4open.science/r/ResilientCL/.</description>
      <author>example@mail.com (Xiaoyu Yang, Jie Lu, En Yu)</author>
      <guid isPermaLink="false">2502.07620v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing</title>
      <link>http://arxiv.org/abs/2502.07608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review at CHIL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Time2Lang框架，该框架直接将时间序列基础模型（TFM）的输出映射到大型语言模型（LLMs）表示中，无需中间文本转换。&lt;h4&gt;背景&lt;/h4&gt;在健康应用领域，大型语言模型与行为感应数据结合显示出潜力。然而，传统方法通过将传感器数据转成文本提示存在误差大、计算成本高和需要领域专业知识的问题。特别是在处理长时间序列数据时问题更加突出。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的框架Time2Lang来直接连接TFMs和LLMs，并对其有效性进行了验证。&lt;h4&gt;方法&lt;/h4&gt;该研究首先在合成数据上使用周期性预测作为预训练任务进行训练，然后通过每日抑郁症预测（基于步数）以及个人繁荣度分类（基于对话时长）的纵向可穿戴设备及移动感应数据集进行评估。Time2Lang框架能够在不考虑输入长度的情况下保持几乎恒定的推理时间，并且生成的嵌入保留了诸如自相关的时间序列特征。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了TFMs和LLMs可以被有效集成，同时最小化信息损失并使这些不同建模范式之间的性能转移成为可能。这是首次将TFM与LLM结合用于健康领域的尝试。&lt;h4&gt;结论&lt;/h4&gt;Time2Lang框架成功地解决了传统方法的限制，并为未来的复杂医疗任务研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在结合行为感应数据时对健康应用展现出潜力，但现有技术如文本提示存在显著挑战。本文提出了一种新的直接映射方法（Time2Lang），有效地将时间序列基础模型与大型语言模型相结合，并通过实际案例证明了其有效性及优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) show promise for health applications whencombined with behavioral sensing data. Traditional approaches convert sensordata into text prompts, but this process is prone to errors, computationallyexpensive, and requires domain expertise. These challenges are particularlyacute when processing extended time series data. While time series foundationmodels (TFMs) have recently emerged as powerful tools for learningrepresentations from temporal data, bridging TFMs and LLMs remains challenging.Here, we present Time2Lang, a framework that directly maps TFM outputs to LLMrepresentations without intermediate text conversion. Our approach first trainson synthetic data using periodicity prediction as a pretext task, followed byevaluation on mental health classification tasks. We validate Time2Lang on twolongitudinal wearable and mobile sensing datasets: daily depression predictionusing step count data (17,251 days from 256 participants) and flourishingclassification based on conversation duration (46 participants over 10 weeks).Time2Lang maintains near constant inference times regardless of input length,unlike traditional prompting methods. The generated embeddings preserveessential time-series characteristics such as auto-correlation. Our resultsdemonstrate that TFMs and LLMs can be effectively integrated while minimizinginformation loss and enabling performance transfer across these distinctmodeling paradigms. To our knowledge, we are the first to integrate a TFM andan LLM for health, thus establishing a foundation for future research combininggeneral-purpose large models for complex healthcare tasks.</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell)</author>
      <guid isPermaLink="false">2502.07608v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2502.07486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures, accepted in DICTA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR数据的从顶部视角提取道路信息的方法，该方法通过减少对特定路缘石设计的依赖来提高不同城市区域的道路提取精度。&lt;h4&gt;背景&lt;/h4&gt;现有的道路信息提取技术主要依赖于局部特征和激光反射角度，这使得它们在面对不同的路缘石设计或高密度地区时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于LiDAR数据的新方法，该方法使用从顶部视角的3D点云来减少对特定路缘石设计的依赖，并提高道路提取的质量。&lt;h4&gt;方法&lt;/h4&gt;首先进行统计异常值去除和基于密度的聚类以降低噪声。接下来使用网格分割法过滤地面点，适应不同的道路场景和地形特性。然后将过滤后的点投影到2D平面上，使用骨架化算法来抽取道路信息。最终的道路中心线通过Savitzky-Golay滤波进行平滑。&lt;h4&gt;主要发现&lt;/h4&gt;提出的初步方法在珀斯CBD数据集上实现了67%的IoU值，而经过后处理优化的方法提高了提取精度至73%，同时减少了23%的计算时间。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种结合3D和2D技术的一般化且计算效率高的解决方案，为未来的道路重建和点云对齐提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;从三维点云中提取道路信息对于城市规划和交通管理非常有用。现有方法往往依赖于局部特征和来自路缘石的激光反射角度，这使得它们在面对不同的路缘石设计或高密度地区时变得敏感且表现不佳。我们提出了一种基于LiDAR数据顶部视角的方法来提取道路点并拟合中心线，这种视角减少了对特定路缘石设计的依赖，并提高了道路提取的效果。首先进行统计异常值去除和基于密度的聚类以降低噪声；接下来使用网格分割法过滤地面点，适应不同的道路场景和地形特性；然后将过滤后的点投影到2D平面上，通过骨架化算法抽取道路信息；最后的道路中心线通过Savitzky-Golay滤波进行平滑。初步方法在珀斯CBD数据集上实现了67%的IoU值，而经过后处理优化的方法提高了提取精度至73%，同时减少了23%的计算时间。该方法提供了一种结合3D和2D技术的一般化且计算效率高的解决方案，为未来的道路重建和点云对齐提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road information extraction from 3D point clouds is useful for urban planningand traffic management. Existing methods often rely on local features and therefraction angle of lasers from kerbs, which makes them sensitive to variablekerb designs and issues in high-density areas due to data homogeneity. Wepropose an approach for extracting road points and fitting centrelines using atop-down view of LiDAR based ground-collected point clouds. This prospectiveview reduces reliance on specific kerb design and results in better roadextraction. We first perform statistical outlier removal and density-basedclustering to reduce noise from 3D point cloud data. Next, we perform groundpoint filtering using a grid-based segmentation method that adapts to diverseroad scenarios and terrain characteristics. The filtered points are thenprojected onto a 2D plane, and the road is extracted by a skeletonisationalgorithm. The skeleton is back-projected onto the 3D point cloud withcalculated normals, which guide a region growing algorithm to find nearby roadpoints. The extracted road points are then smoothed with the Savitzky-Golayfilter to produce the final centreline. Our initial approach withoutpost-processing of road skeleton achieved 67% in IoU by testing on the PerthCBD dataset with different road types. Incorporating the post-processing of theroad skeleton improved the extraction of road points around the smoothedskeleton. The refined approach achieved a higher IoU value of 73% and with 23%reduction in the processing time. Our approach offers a generalised andcomputationally efficient solution that combines 3D and 2D processingtechniques, laying the groundwork for future road reconstruction and 3D-to-2Dpoint cloud alignment.</description>
      <author>example@mail.com (Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Hasnein Tareque, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.07486v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework</title>
      <link>http://arxiv.org/abs/2502.07246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DF-Loc是一种基于多源无监督领域适应（MUDA）的端到端动态指纹定位系统，旨在提高室内环境中的稳健性和适应性。&lt;h4&gt;背景&lt;/h4&gt;传统的指纹定位方法在静态数据上有效，但在数据分布和特征空间不断变化的动态环境中表现不佳。动态环境下的挑战包括数据随时间变化导致的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出DF-Loc以解决动态环境下指纹定位系统的稳健性和适应性问题。&lt;h4&gt;方法&lt;/h4&gt;1. DF-Loc利用多源历史数据进行知识迁移。2. 系统包含一个质量控制模块用于CSI数据预处理，并使用图像处理技术重构CSI指纹特征。3. 设计一个多尺度注意力基网络以提取多层次可转移的指纹特征。4. 采用两阶段对齐模型使多个源-目标领域的分布一致，从而提高目标域中的回归特性。&lt;h4&gt;主要发现&lt;/h4&gt;DF-Loc在办公室和教室环境中进行了广泛的实验，并且相比于比较方法，该系统在定位准确性和鲁棒性方面表现更佳。使用60%参考点进行训练时，在“同测试”场景下，平均定位误差为0.79m和3.72m；而在“不同测试”场景下分别为0.94m和4.39m。&lt;h4&gt;结论&lt;/h4&gt;DF-Loc开创了一种端到端的多源迁移学习方法来处理指纹定位问题，并为动态环境下的未来研究提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fingerprint localization has gained significant attention due to itscost-effective deployment, low complexity, and high efficacy. However,traditional methods, while effective for static data, often struggle in dynamicenvironments where data distributions and feature spaces evolve-a commonoccurrence in real-world scenarios. To address the challenges of robustness andadaptability in fingerprint localization for dynamic indoor environments, thispaper proposes DF-Loc, an end-to-end dynamic fingerprint localization systembased on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverageshistorical data from multiple time scales to facilitate knowledge transfer inspecific feature spaces, thereby enhancing generalization capabilities in thetarget domain and reducing reliance on labeled data. Specifically, the systemincorporates a Quality Control (QC) module for CSI data preprocessing andemploys image processing techniques for CSI fingerprint feature reconstruction.Additionally, a multi-scale attention-based feature fusion backbone network isdesigned to extract multi-level transferable fingerprint features. Finally, adual-stage alignment model aligns the distributions of multiple source-targetdomain pairs, improving regression characteristics in the target domain.Extensive experiments conducted in office and classroom environmentsdemonstrate that DF-Loc outperforms comparative methods in terms of bothlocalization accuracy and robustness. With 60% of reference points used fortraining, DF-Loc achieves average localization errors of 0.79m and 3.72m in"same-test" scenarios, and 0.94m and 4.39m in "different-test" scenarios,respectively. This work pioneers an end-to-end multi-source transfer learningapproach for fingerprint localization, providing valuable insights for futureresearch in dynamic environments.</description>
      <author>example@mail.com (Jiyu Jiao, Xiaojun Wang, Chengpei Han)</author>
      <guid isPermaLink="false">2502.07246v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>O1 Embedder: Let Retrievers Think Before Action</title>
      <link>http://arxiv.org/abs/2502.07555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要描述了大语言模型（LLMs）在信息获取和利用方面的革命性进步，特别是它们在精细数据表示、高质量答案生成以及推理能力方面的优势。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型通过其强大的细粒度数据表示能力和基于外部引用的高质量回答能力改变了人们访问和使用信息的方式。最近推出的推理模型进一步展示了LLMs的逐步思考能力。&lt;h4&gt;目的&lt;/h4&gt;受这一进展启发，研究者希望为检索模型开发类似的渐进思考能力，以解决领域内的重大挑战，包括多任务检索、零样本检索以及需要复杂关系推理的任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为O1 Embedder的新颖方法，该方法在进行文档检索之前，先生成输入查询的有用思想。为了实现这一目标，研究者克服了两项技术难题：设计数据合成工作流程和优化训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，O1 Embedder在广泛的应用场景中表现出了显著的优势，包括跨域任务在内的多项流行数据集中均取得了性能提升。&lt;h4&gt;结论&lt;/h4&gt;该方法为下一代信息检索基础模型的发展铺平了道路，并展示了其卓越的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;随着大型语言模型（LLMs）力量的增长，它们已经革新了人们访问和利用信息的方式。特别是，这些模型在进行精细数据表示方面表现出色，这有助于精确的信息检索，并能生成基于外部参考的高质量答案，从而产生有用的知识。最近引入的推理模型，如OpenAI O1和DeepSeek R1，标志着又一进步，突显了LLMs能够在提供最终答案之前逐步思考的能力。这一突破显著提高了处理复杂任务（例如编码和数学证明）的能力。受到这些进展的启发，我们旨在为检索模型开发类似能力，以应对领域中的关键挑战，包括多任务检索、零样本检索以及需要密集推理的任务。基于此动机，我们提出了一种名为O1 Embedder的新方法，该方法在针对目标文档进行检索之前生成输入查询的有用思想。为了实现这一目标，我们解决了两项技术难题：设计数据合成工作流程和优化训练过程。我们在广泛的实验中评估了我们的方法，并在涵盖领域内和跨域场景中的12个流行数据集中取得了显著改进，这突显了O1 Embedder卓越的准确性和泛化能力，为开发下一代信息检索基础模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing power of large language models (LLMs) has revolutionized howpeople access and utilize information. Notably, the LLMs excel at performingfine-grained data representation, which facilitates precise retrieval ofinformation. They also generate high-quality answers based on externalreferences, enabling the production of useful knowledge. The recentintroduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks anotherleap forward, highlighting LLMs' ability to think progressively beforedelivering final answers. This breakthrough significantly improves the abilityto address complex tasks, e.g., coding and math proofs.  Inspired by this progress, we aim to develop similar capabilities forretrieval models, which hold great promise for tackling critical challenges inthe field, including multi-task retrieval, zero-shot retrieval, and tasksrequiring intensive reasoning of complex relationships. With this motivation,we propose a novel approach called O1 Embedder, which generates useful thoughtsfor the input query before making retrieval for the target documents. Torealize this objective, we conquer two technical difficulties. First, we designa data synthesis workflow, creating training signals for O1 Embedder bygenerating initial thoughts from an LLM-expert and subsequently refining themusing a retrieval committee. Second, we optimize the training process, enablinga pre-trained model to be jointly fine-tuned to generate retrieval thoughts viabehavior cloning and perform dense retrieval through contrastive learning. Ourapproach is evaluated by comprehensive experiments, where substantialimprovements are achieved across 12 popular datasets, spanning both in-domainand out-of-domain scenarios. These results highlight O1 Embedder's remarkableaccuracy and generalizability, paving the way for the development ofnext-generation IR foundation models.</description>
      <author>example@mail.com (Ruin Yan, Zheng Liu, Defu Lian)</author>
      <guid isPermaLink="false">2502.07555v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>From Image to Video: An Empirical Study of Diffusion Representations</title>
      <link>http://arxiv.org/abs/2502.07001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文探讨了扩散模型在视觉理解任务中的潜力，特别是视频扩散模型。&lt;h4&gt;背景&lt;/h4&gt;扩散模型已经在图像和视频合成中取得了革命性的成功，并激发了人们探索其在视觉理解任务中的应用。尽管最近的研究已经研究了图像生成的潜在用途，但视频扩散模型的视觉理解能力尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，作者系统地比较了相同架构下训练用于视频和图像生成的效果，分析它们在下游任务上的性能表现。&lt;h4&gt;方法&lt;/h4&gt;实验中使用相同的模型结构分别进行视频和图像生成的训练，并评估其潜在表示在诸如图像分类、动作识别、深度估计以及跟踪等不同下游任务中的效果。进一步探讨了从不同层次抽取的特征以及噪声水平不同的影响，同时也分析了模型大小及训练预算对表现和生成质量的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明视频扩散模型在多种下游任务上始终优于其图像对应的模型，尽管这种优越性程度在不同任务中有所差异。此外，还发现了提取自不同层次的特征以及噪声水平的变化对于性能有着显著影响。&lt;h4&gt;结论&lt;/h4&gt;这是首次直接比较视频和图像扩散目标用于视觉理解的研究工作，为时间信息在表示学习中的作用提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;扩散模型已经在生成建模领域取得革命性进展，使得图像和视频合成的逼真度达到了前所未有的水平。这一成功引发了人们对利用其表示进行视觉理解和任务的兴趣。尽管最近的工作已经探索了这种潜在应用以实现图像生成，但关于视频扩散模型的视觉理解能力的研究依然非常有限。为了填补这一空白，我们系统地比较了相同架构在训练用于视频和图像生成时的效果，并分析它们在包括图像分类、动作识别、深度估计以及跟踪在内的多种下游任务中的表现。结果显示，在这些任务中，视频扩散模型始终优于其对应的图像模型，尽管这种优越性的程度有所不同。此外，我们也研究了从不同层次抽取的特征以及噪声水平对性能的影响，还探讨了模型大小和训练预算对表示质量和生成质量的作用。这项工作首次直接比较了用于视觉理解的视频和图像扩散目标，为时间信息在表示学习中的作用提供了重要的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have revolutionized generative modeling, enablingunprecedented realism in image and video synthesis. This success has sparkedinterest in leveraging their representations for visual understanding tasks.While recent works have explored this potential for image generation, thevisual understanding capabilities of video diffusion models remain largelyuncharted. To address this gap, we systematically compare the same modelarchitecture trained for video versus image generation, analyzing theperformance of their latent representations on various downstream tasksincluding image classification, action recognition, depth estimation, andtracking. Results show that video diffusion models consistently outperformtheir image counterparts, though we find a striking range in the extent of thissuperiority. We further analyze features extracted from different layers andwith varying noise levels, as well as the effect of model size and trainingbudget on representation and generation quality. This work marks the firstdirect comparison of video and image diffusion objectives for visualunderstanding, offering insights into the role of temporal information inrepresentation learning.</description>
      <author>example@mail.com (Pedro Vélez, Luisa F. Polanía, Yi Yang, Chuhan Zhang, Rishab Kabra, Anurag Arnab, Mehdi S. M. Sajjadi)</author>
      <guid isPermaLink="false">2502.07001v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Neighborhood-Order Learning Graph Attention Network for Fake News Detection</title>
      <link>http://arxiv.org/abs/2502.06927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的模型NOL-GAT，用于检测假新闻。该模型通过学习每个节点的最佳邻域顺序来改进信息提取。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体和在线通信网络的普及，虚假新闻的识别成为了一个重要挑战。基于图神经网络的方法显示出分析图结构数据的强大潜力。&lt;h4&gt;目的&lt;/h4&gt;解决传统GNN架构在利用多层以外邻居信息时的局限性，提高模型精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的NOL-GAT模型，该模型包括一个Hop Network和一个Embedding Network来确定最佳邻域顺序并更新节点嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，NOL-GAT在多个假新闻数据集上表现优异，并且在标签数据有限的情况下也能显著优于基准模型。&lt;h4&gt;结论&lt;/h4&gt;提出的模型能够缓解过度压扁问题，改善信息流动和减少计算复杂性，显示出了明显的优势。&lt;h4&gt;翻译&lt;/h4&gt;虚假新闻检测是数字时代的一个重大挑战，随着社交媒体和在线通信网络的普及变得越来越重要。基于图神经网络（GNN）的方法在解决这个问题时显示出分析图形结构数据的巨大潜力。然而，传统GNN架构的主要限制在于它们无法有效利用多层外邻居的信息，这会降低模型的准确性和效果。本文提出了一种名为Neighborhood-Order Learning Graph Attention Network (NOL-GAT)的新模型用于虚假新闻检测。该模型允许每层中的每个节点独立学习其最佳邻域顺序。通过这样做，模型可以有针对性且有效地从远距离邻居中提取关键信息。NOL-GAT架构由两个主要部分组成：一个决定最佳邻域顺序的Hop Network和使用这些最优邻域更新节点嵌入的Embedding Network。为了评估该模型的性能，在各种虚假新闻数据集上进行了实验。结果表明，NOL-GAT在准确性、F1分数等指标上显著优于基线模型，特别是在标签数据有限的情况下。其他优势包括缓解过度压扁问题，改进信息流动以及减少计算复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fake news detection is a significant challenge in the digital age, which hasbecome increasingly important with the proliferation of social media and onlinecommunication networks. Graph Neural Networks (GNN)-based methods have shownhigh potential in analyzing graph-structured data for this problem. However, amajor limitation in conventional GNN architectures is their inability toeffectively utilize information from neighbors beyond the network's layerdepth, which can reduce the model's accuracy and effectiveness. In this paper,we propose a novel model called Neighborhood-Order Learning Graph AttentionNetwork (NOL-GAT) for fake news detection. This model allows each node in eachlayer to independently learn its optimal neighborhood order. By doing so, themodel can purposefully and efficiently extract critical information fromdistant neighbors. The NOL-GAT architecture consists of two main components: aHop Network that determines the optimal neighborhood order and an EmbeddingNetwork that updates node embeddings using these optimal neighborhoods. Toevaluate the model's performance, experiments are conducted on various fakenews datasets. Results demonstrate that NOL-GAT significantly outperformsbaseline models in metrics such as accuracy and F1-score, particularly inscenarios with limited labeled data. Features such as mitigating theover-squashing problem, improving information flow, and reducing computationalcomplexity further highlight the advantages of the proposed model.</description>
      <author>example@mail.com (Batool Lakzaei, Mostafa Haghir Chehreghani, Alireza Bagheri)</author>
      <guid isPermaLink="false">2502.06927v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>SEMU: Singular Value Decomposition for Efficient Machine Unlearning</title>
      <link>http://arxiv.org/abs/2502.07587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于奇异值分解的高效机器遗忘（SEMU）方法，以优化模型在特定数据点上的选择性遗忘过程。该方法解决了现有机器遗忘技术中的高计算成本和训练不稳定性问题，并减少了对原始训练数据集的需求。&lt;h4&gt;背景&lt;/h4&gt;生成基础模型的能力近年来迅速提升，但防止有害行为的方法仍不成熟。其中，机器遗忘（MU）成为应对即将到来的安全法规的关键挑战之一。现有的大多数MU方法侧重于改变模型中最显著的参数，但这往往需要大量的模型微调，导致计算成本高和训练不稳定。&lt;h4&gt;目的&lt;/h4&gt;通过利用奇异值分解来创建紧凑、低维投影，从而实现特定数据点的选择性遗忘，同时减少对原始训练数据集的需求。本文旨在优化机器遗忘过程中的效率问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法——基于奇异值分解的高效机器遗忘（SEMU），该方法通过最小化需要修改的模型参数数量来有效移除不需要的知识，并且仅需少量改变权重即可实现特定数据点的选择性遗忘。同时，SEMU消除了对原始训练数据集的需求。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，SEMU在保持性能的同时，在数据使用和被修改参数的数量上显著提高了效率。&lt;h4&gt;结论&lt;/h4&gt;通过引入奇异值分解技术来优化机器遗忘过程，有效地解决了现有方法的局限性，并展示了其实际应用中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the capabilities of generative foundational models have advancedrapidly in recent years, methods to prevent harmful and unsafe behaviors remainunderdeveloped. Among the pressing challenges in AI safety, machine unlearning(MU) has become increasingly critical to meet upcoming safety regulations. Mostexisting MU approaches focus on altering the most significant parameters of themodel. However, these methods often require fine-tuning substantial portions ofthe model, resulting in high computational costs and training instabilities,which are typically mitigated by access to the original training dataset.  In this work, we address these limitations by leveraging Singular ValueDecomposition (SVD) to create a compact, low-dimensional projection thatenables the selective forgetting of specific data points. We propose SingularValue Decomposition for Efficient Machine Unlearning (SEMU), a novel approachdesigned to optimize MU in two key aspects. First, SEMU minimizes the number ofmodel parameters that need to be modified, effectively removing unwantedknowledge while making only minimal changes to the model's weights. Second,SEMU eliminates the dependency on the original training dataset, preserving themodel's previously acquired knowledge without additional data requirements.  Extensive experiments demonstrate that SEMU achieves competitive performancewhile significantly improving efficiency in terms of both data usage and thenumber of modified parameters.</description>
      <author>example@mail.com (Marcin Sendera, Łukasz Struski, Kamil Książek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk)</author>
      <guid isPermaLink="false">2502.07587v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Extended monocular 3D imaging</title>
      <link>http://arxiv.org/abs/2502.07403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的单目3D成像框架EM3D，利用光的波矢量性质实现高精度和高分辨率的三维点云捕获。&lt;h4&gt;背景&lt;/h4&gt;尽管在3D视觉领域已有许多进展，现有的3D成像硬件依然笨重且复杂，并且图像分辨率远低于2D成像系统。此外，在低纹理、强反射或透明场景中，现有解决方案常常失效。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型单目3D成像框架EM3D，用于捕获高精度和高质量的三维点云，特别是在传统难以处理的情境下。&lt;h4&gt;方法&lt;/h4&gt;通过使用配备有衍射-折射混合镜头的小型单目相机，结合多个阶段的光波衍射与偏振深度线索融合技术，实现了快速且准确地获取百万像素级别的3D图像。&lt;h4&gt;主要发现&lt;/h4&gt;1. 该框架能够在低纹理、强反射或透明物体等传统难以处理的场景中成功捕获高精度和高质量的三维点云；2. 结合了深度信息与偏振信息后，能够解锁新材料识别的独特机会，这将扩展机器智能在目标识别及面部防伪等方面的应用。&lt;h4&gt;结论&lt;/h4&gt;EM3D框架提供了一种高效且简洁的方法，在最小硬件规模下实现高维视觉系统的发展，为单目相机的广泛应用铺平了道路。这种结构开辟了一个全新的路径，以最少的形式因素进行更高维度机器视觉研究。&lt;h4&gt;翻译&lt;/h4&gt;三维视觉对于包括机器智能和精密计量在内的许多应用至关重要。尽管在最近几年取得了很多进展，但大多数3D成像硬件仍然笨重且复杂，并提供了远低于其2D对应物的图像分辨率。此外，现有3D成像解决方案在很多众所周知的情况下经常失败。在这里，我们引入了一个扩展单目3D成像（EM3D）框架，充分利用了光的矢量波性质。通过衍射和偏振深度线索的多阶段融合，使用配备有衍射折射混合镜头的小型单目相机，我们在实验中展示了对包括低纹理、高度反射或接近透明在内的传统挑战性场景中的百万像素级准确3D点云的一次性捕获。此外，我们发现深度信息与偏振信息结合可以解锁独特的材料识别机会，这可能会进一步扩展机器智能在目标识别和面部防伪等应用中。因此，这种简单而强大的架构为最小化尺寸形式的更高维度机器视觉开辟了一条新道路，促进单目相机在更多样化的场景中的部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D vision is of paramount importance for numerous applications ranging frommachine intelligence to precision metrology. Despite much recent progress, themajority of 3D imaging hardware remains bulky and complicated and provides muchlower image resolution compared to their 2D counterparts. Moreover, there aremany well-known scenarios that existing 3D imaging solutions frequently fail.Here, we introduce an extended monocular 3D imaging (EM3D) framework that fullyexploits the vectorial wave nature of light. Via the multi-stage fusion ofdiffraction- and polarization-based depth cues, using a compact monocularcamera equipped with a diffractive-refractive hybrid lens, we experimentallydemonstrate the snapshot acquisition of a million-pixel and accurate 3D pointcloud for extended scenes that are traditionally challenging, including thosewith low texture, being highly reflective, or nearly transparent, without adata prior. Furthermore, we discover that the combination of depth andpolarization information can unlock unique new opportunities in materialidentification, which may further expand machine intelligence for applicationslike target recognition and face anti-spoofing. The straightforward yetpowerful architecture thus opens up a new path for a higher-dimensional machinevision in a minimal form factor, facilitating the deployment of monocularcameras for applications in much more diverse scenarios.</description>
      <author>example@mail.com (Zicheng Shen, Feng Zhao, Yibo Ni, Yuanmu Yang)</author>
      <guid isPermaLink="false">2502.07403v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification</title>
      <link>http://arxiv.org/abs/2502.07409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  first version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种基于提示学习的方法，用于通过少量样本进行病理图像分类。&lt;h4&gt;背景&lt;/h4&gt;全切片病理图像分类由于其巨大的图像尺寸和有限的标注标签而面临挑战。现有的模型泛化能力受限。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种适应大规模视觉语言模型的新方法来解决上述问题，并提高病理性分类任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;{'1': '扩展了Prov-GigaPath视觉基础模型，通过加入适配器并利用923K图像-文本对进行对比学习将其转化为一个视觉-语言模型。', '2': '提出了一种多粒度注意力机制，该机制将可学习提示与单个图像补丁和这些补丁组之间的相互作用进行比较，以改进模型识别复杂模式的能力。', '3': '利用基于最优传输的可视化文本距离来提高模型鲁棒性，并减轻数据增强过程中可能出现的扰动影响。'}&lt;h4&gt;主要发现&lt;/h4&gt;该方法在肺、肾和乳腺病理图像模态上的实验验证了其有效性，超越了几种最新的竞争对手，在各种架构（包括CLIP、PLIP以及Prov-GigaPath集成的PLIP）中持续提高了性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入多粒度注意力机制和基于最优传输的视觉文本距离，该模型在病理图像分类任务上表现出色。作者公开了其实现代码和预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;全切片病理图像分类面临挑战的原因是其巨大的图像尺寸和有限的标注标签，这限制了现有模型的泛化能力。本文介绍了一种提示学习方法来适应大规模视觉语言模型，以解决少量样本下的病理性分类问题。通过扩展预先训练在1.3亿个病理图像切片上的Prov-GigaPath视觉基础模型，并引入适配器和基于923K图像-文本对的对比学习，将其转换为一个视觉-语言模型。该方法采用多粒度注意力机制改进了模型捕捉细粒度细节与整体上下文的能力。为了进一步提高准确率，采用了基于最优传输的可视化文本距离来确保模型鲁棒性，并减少数据增强过程中可能出现的扰动影响。实验证明，在肺、肾和乳腺病理图像模态上，该方法超越了几种最新的竞争对手，并在各种架构中持续提高了性能。作者公开了其实现代码和预训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whole slide pathology image classification presents challenges due togigapixel image sizes and limited annotation labels, hindering modelgeneralization. This paper introduces a prompt learning method to adapt largevision-language models for few-shot pathology classification. We first extendthe Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathologyimage tiles, into a vision-language model by adding adaptors and aligning itwith medical text encoders via contrastive learning on 923K image-text pairs.The model is then used to extract visual features and text embeddings fromfew-shot annotations and fine-tunes with learnable prompt embeddings. Unlikeprior methods that combine prompts with frozen features using prefix embeddingsor self-attention, we propose multi-granular attention that comparesinteractions between learnable prompts with individual image patches and groupsof them. This approach improves the model's ability to capture bothfine-grained details and broader context, enhancing its recognition of complexpatterns across sub-regions. To further improve accuracy, we leverage(unbalanced) optimal transport-based visual-text distance to secure modelrobustness by mitigating perturbations that might occur during the dataaugmentation process. Empirical experiments on lung, kidney, and breastpathology modalities validate the effectiveness of our approach; thereby, wesurpass several of the latest competitors and consistently improve performanceacross diverse architectures, including CLIP, PLIP, and Prov-GigaPathintegrated PLIP. We release our implementations and pre-trained models at thisMGPATH.</description>
      <author>example@mail.com (Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag, Hanibal Bohnenberger, Anne-Christin Hauschild)</author>
      <guid isPermaLink="false">2502.07409v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units</title>
      <link>http://arxiv.org/abs/2502.06921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Graph Neural Networks (GNNs) 在处理网络分析、推荐系统和语音分析等任务时非常重要，部署在边缘设备上可以提高实时性、隐私保护和云独立性。然而，在资源受限的设备上执行 GNN 会导致高延迟和能量开销。&lt;h4&gt;背景&lt;/h4&gt;当前边缘处理器集成了 CPU、GPU 和 NPU，但专为数据并行任务设计的 NPU 难以处理不规则的 GNN 计算。&lt;h4&gt;目的&lt;/h4&gt;引入 GraNNite，这是一种基于商用货架上的 SOTA DNN 加速器的硬件感知框架，旨在优化 GNN 的执行。&lt;h4&gt;方法&lt;/h4&gt;GraNNite 通过三个步骤的方法论来优化：1) 使 NPU 能够执行任务；2) 提高性能；3) 在质量与效率之间进行权衡。每个步骤包含多个子步骤和工具。&lt;h4&gt;主要发现&lt;/h4&gt;在 Intel Core Ultra AI PC 上，GraNNite 达到了 2.6 倍到 7.6 倍的速度提升，并且实现了高达 8.6 倍的能量节省。相对于 CPU 和 GPU 分别达到了 10.8 倍和 6.7 倍的性能提升。&lt;h4&gt;结论&lt;/h4&gt;GraNNite 提供了一种有效的优化框架，可以在资源受限设备上高效执行 GNN 计算，并具有显著的速度和能量效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are vital for learning from graph-structureddata, enabling applications in network analysis, recommendation systems, andspeech analytics. Deploying them on edge devices like client PCs and laptopsenhances real-time processing, privacy, and cloud independence. GNNs aidRetrieval-Augmented Generation (RAG) for Large Language Models (LLMs) andenable event-based vision tasks. However, irregular memory access, sparsity,and dynamic structures cause high latency and energy overhead onresource-constrained devices. While modern edge processors integrate CPUs,GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregularGNN computations. We introduce GraNNite, the first hardware-aware frameworkoptimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNNaccelerators via a structured three-step methodology: (1) enabling NPUexecution, (2) optimizing performance, and (3) trading accuracy for efficiencygains. Step 1 employs GraphSplit for workload distribution and StaGr for staticaggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boostsperformance using EffOp for control-heavy tasks and GraSp for sparsityexploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduceredundancy and memory transfers. Step 3 balances quality versus efficiency,where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerateattention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higherperformance than CPUs and GPUs, respectively, across GNN models.</description>
      <author>example@mail.com (Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan)</author>
      <guid isPermaLink="false">2502.06921v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automated Capability Discovery via Model Self-Exploration</title>
      <link>http://arxiv.org/abs/2502.07577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种自动能力发现(ACD)框架，该框架利用一个基础模型作为科学家，系统地提出开放性任务以探测目标模型的能力。&lt;h4&gt;背景&lt;/h4&gt;大语言模型已成为通用助手，在广泛领域表现出不同能力。然而，难以精确描述新模型的全部能力和潜在风险。&lt;h4&gt;目的&lt;/h4&gt;介绍一种能够自动和系统化地发现基础模型意外能力和失败的方法——自动能力发现（ACD）框架。&lt;h4&gt;方法&lt;/h4&gt;结合前沿模型与开放性领域的理念，设计了一个利用一个模型作为科学家来探测另一个模型的能力的系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过跨多个基础模型系列（包括GPT、Claude和Llama等），展示该方法能自动揭示出目标模型数千种能力，超越了任何单个团队的探查范围。并且通过广泛的问卷调查验证了其评分系统的准确性。&lt;h4&gt;结论&lt;/h4&gt;利用大模型创造任务和自我评估的能力，ACD是向可扩展、自动化的人工智能系统评价迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;基础模型已经成为多领域中的通用助手，在大规模网络数据训练下展示了广泛的能力。然而，精确表征任何新模型的全部能力及潜在风险仍然是一个挑战。现有的评估方法通常需要大量的手工劳动，并且为更强大的模型设计新的挑战也越来越困难。我们引入了一个名为自动能力发现(ACD)的框架，该框架利用基础模型作为科学家来系统地提出开放性任务以探测目标模型的能力（可能是自身）。通过结合前沿模型与开放性领域的理念，ACD能自动和系统化地揭示出目标模型意外能力和失败。我们在不同的基础模型系列上展示了这种方法的效果，包括GPT、Claude及Llama等，并发现它可以自动揭示数千种难以由单一团队探查到的能力。此外，我们通过广泛的问卷调查验证了该方法自动化评分的有效性，观察到了机器生成的评价与人工评价之间的高度一致性。利用基础模型创造任务和自我评估的功能，ACD向大规模、自动化的AI系统评价迈进了一大步。所有代码和评测日志开源于https://github.com/conglu1997/ACD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have become general-purpose assistants, exhibiting diversecapabilities across numerous domains through training on web-scale data. Itremains challenging to precisely characterize even a fraction of the fullspectrum of capabilities and potential risks in any new model. Existingevaluation approaches often require significant human effort, and it is takingincreasing effort to design ever harder challenges for more capable models. Weintroduce Automated Capability Discovery (ACD), a framework that designates onefoundation model as a scientist to systematically propose open-ended tasksprobing the abilities of a subject model (potentially itself). By combiningfrontier models with ideas from the field of open-endedness, ACD automaticallyand systematically uncovers both surprising capabilities and failures in thesubject model. We demonstrate ACD across a range of foundation models(including the GPT, Claude, and Llama series), showing that it automaticallyreveals thousands of capabilities that would be challenging for any single teamto uncover. We further validate our method's automated scoring with extensivehuman surveys, observing high agreement between model-generated and humanevaluations. By leveraging foundation models' ability to both create tasks andself-evaluate, ACD is a significant step toward scalable, automated evaluationof novel AI systems. All code and evaluation logs are open-sourced athttps://github.com/conglu1997/ACD.</description>
      <author>example@mail.com (Cong Lu, Shengran Hu, Jeff Clune)</author>
      <guid isPermaLink="false">2502.07577v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Suction Grasping with Large-Scale Parcel Dataset</title>
      <link>http://arxiv.org/abs/2502.07238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文针对物体吸盘抓取技术在处理复杂包裹场景中的挑战，提出了一个大规模合成数据集Parcel-Suction-Dataset和一种创新的Diffusion-Suction框架。&lt;h4&gt;背景&lt;/h4&gt;尽管最近在物体吸盘抓取方面取得了显著进展，但在混乱且复杂的包裹处理环境中仍然存在重大挑战。目前的方法受到两个根本限制：缺乏针对包裹操作任务量身定制的全面吸盘抓取数据集以及对不同对象特性（如大小、几何复杂性和纹理多样性）适应性的不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本文提出了一种大规模合成数据集Parcel-Suction-Dataset和一种创新的方法Diffusion-Suction框架。&lt;h4&gt;方法&lt;/h4&gt;1. Parcel-Suction-Dataset：包含25000个混乱场景及4亿多个高精度标注的吸盘抓取姿态的数据集。该数据集通过新颖的几何采样算法生成，能够有效生成基于物理约束和材料属性的最优吸盘抓取。2. Diffusion-Suction框架：将吸盘抓取预测重新定义为条件生成任务，并使用去噪扩散概率模型进行实现。此方法通过从点云观察中获得视觉条件引导逐步细化随机噪声，以学习合成数据集中的空间点特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，简单而高效的Diffusion-Suction在Parcel-Suction-Dataset和公共SuctionNet-1Billion基准测试上实现了新的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;本文通过提出大规模合成数据集和创新性方法来解决现有吸盘抓取技术的局限性，并展示了优越的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent advances in object suction grasping have shown remarkableprogress, significant challenges persist particularly in cluttered and complexparcel handling scenarios. Two fundamental limitations hinder currentapproaches: (1) the lack of a comprehensive suction grasp dataset tailored forparcel manipulation tasks, and (2) insufficient adaptability to diverse objectcharacteristics including size variations, geometric complexity, and texturaldiversity. To address these challenges, we present Parcel-Suction-Dataset, alarge-scale synthetic dataset containing 25 thousand cluttered scenes with 410million precision-annotated suction grasp poses. This dataset is generatedthrough our novel geometric sampling algorithm that enables efficientgeneration of optimal suction grasps incorporating both physical constraintsand material properties. We further propose Diffusion-Suction, an innovativeframework that reformulates suction grasp prediction as a conditionalgeneration task through denoising diffusion probabilistic models. Our methoditeratively refines random noise into suction grasp score maps throughvisual-conditioned guidance from point cloud observations, effectively learningspatial point-wise affordances from our synthetic dataset. Extensiveexperiments demonstrate that the simple yet efficient Diffusion-Suctionachieves new state-of-the-art performance compared to previous models on bothParcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.</description>
      <author>example@mail.com (Ding-Tao Huang, Xinyi He, Debei Hua, Dongfang Yu, En-Te Lin, Long Zeng)</author>
      <guid isPermaLink="false">2502.07238v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning for cell stage classification of animal embryos</title>
      <link>http://arxiv.org/abs/2502.07360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视频显微镜技术结合机器学习为研究体外生产胚胎早期发育提供了一种有前景的方法。然而，手动标注生物发育事件特别是细胞分裂是耗时的，并且无法扩展到实际应用中。&lt;h4&gt;背景&lt;/h4&gt;目前对于体外产生的（IVP）胚胎的早期发育阶段的手动标记工作非常耗时且难以大规模实施，尤其是在结合视频显微镜技术和机器学习的研究中存在显著挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于深度学习的方法自动分类牛胚胎发育过程中的细胞阶段，并针对低质量图像、暗色细胞和不平衡数据分布等挑战提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了CLEmbryo方法，该方法结合监督对比学习与焦损函数进行训练，并采用轻量级3D神经网络CSN-50作为编码器。同时开发了用于牛胚胎分析的Bovine Embryos Cell Stages (ECS) 数据集。&lt;h4&gt;主要发现&lt;/h4&gt;CLEmbryo在自建的Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中均超越现有最佳方法，显示出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合深度学习与视频显微镜技术能够有效解决牛胚胎发育阶段分类的问题，并且证明了所提出的方法在不同类型的生物实验数据中具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video microscopy, when combined with machine learning, offers a promisingapproach for studying the early development of in vitro produced (IVP) embryos.However, manually annotating developmental events, and more specifically celldivisions, is time-consuming for a biologist and cannot scale up for practicalapplications. We aim to automatically classify the cell stages of embryos from2D time-lapse microscopy videos with a deep learning approach. We focus on theanalysis of bovine embryonic development using video microscopy, as we areprimarily interested in the application of cattle breeding, and we have createda Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)low-quality images and bovine dark cells that make the identification of cellstages difficult, (2) class ambiguity at the boundaries of developmentalstages, and (3) imbalanced data distribution. To address these challenges, weintroduce CLEmbryo, a novel method that leverages supervised contrastivelearning combined with focal loss for training, and the lightweight 3D neuralnetwork CSN-50 as an encoder. We also show that our method generalizes well.CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS datasetand the publicly available NYU Mouse Embryos dataset.</description>
      <author>example@mail.com (Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis)</author>
      <guid isPermaLink="false">2502.07360v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution</title>
      <link>http://arxiv.org/abs/2502.06894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 Pages, 22 figures, 20 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;高光谱成像(HSI)技术捕捉空间和光谱数据，能够分析传统系统无法看到的特征，在天气监测、食品质量控制、防伪检测、医疗诊断以及国防、农业和工业自动化等领域发挥重要作用。&lt;h4&gt;背景&lt;/h4&gt;HSI技术随着光谱分辨率提高、设备小型化及计算方法的进步而不断发展。该研究概述了HSI及其应用，探讨数据融合面临的挑战，并强调深度学习模型在处理HSI数据中的作用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在为技术和非技术人员提供关于HSI图像、趋势和未来方向的见解，同时提供有关HSI数据集及软件库的有价值信息。&lt;h4&gt;方法&lt;/h4&gt;介绍了多模态HSI与AI特别是深度学习技术的集成如何提高分类准确性和操作效率。文章还详细说明了深度学习在特征提取、变化检测、降噪分解、降维、土地覆盖制图、数据增强、光谱构建和超分辨率分析方面的提升。&lt;h4&gt;主要发现&lt;/h4&gt;最新的研究焦点在于将高光谱相机与大型语言模型(LLMs)结合，开发出如低能见度碰撞预警及反欺骗面部识别等高级应用。该融合被称为“大脑型”LLM。&lt;h4&gt;结论&lt;/h4&gt;文章还强调了HSI工业中的关键参与者及其复合年增长率，并探讨了其不断增长的产业重要性。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral imaging (HSI) captures spatial and spectral data, enabling analysis of features invisible to conventional systems. The technology is vital in fields such as weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, and extending into defense, agriculture, and industrial automation at the same time. HSI has advanced with improvements in spectral resolution, miniaturization, and computational methods. This study provides an overview of the HSI, its applications, challenges in data fusion and the role of deep learning models in processing HSI data. We discuss how integration of multimodal HSI with AI, particularly with deep learning, improves classification accuracy and operational efficiency. Deep learning enhances HSI analysis in areas like feature extraction, change detection, denoising unmixing, dimensionality reduction, landcover mapping, data augmentation, spectral construction and super resolution. An emerging focus is the fusion of hyperspectral cameras with large language models (LLMs), referred as highbrain LLMs, enabling the development of advanced applications such as low visibility crash detection and face antispoofing. We also highlight key players in HSI industry, its compound annual growth rate and the growing industrial significance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral imaging (HSI) captures spatial and spectral data, enablinganalysis of features invisible to conventional systems. The technology is vitalin fields such as weather monitoring, food quality control, counterfeitdetection, healthcare diagnostics, and extending into defense, agriculture, andindustrial automation at the same time. HSI has advanced with improvements inspectral resolution, miniaturization, and computational methods. This studyprovides an overview of the HSI, its applications, challenges in data fusionand the role of deep learning models in processing HSI data. We discuss howintegration of multimodal HSI with AI, particularly with deep learning,improves classification accuracy and operational efficiency. Deep learningenhances HSI analysis in areas like feature extraction, change detection,denoising unmixing, dimensionality reduction, landcover mapping, dataaugmentation, spectral construction and super resolution. An emerging focus isthe fusion of hyperspectral cameras with large language models (LLMs), referredas highbrain LLMs, enabling the development of advanced applications such aslow visibility crash detection and face antispoofing. We also highlight keyplayers in HSI industry, its compound annual growth rate and the growingindustrial significance. The purpose is to offer insight to both technical andnon-technical audience, covering HSI's images, trends, and future directions,while providing valuable information on HSI datasets and software libraries.</description>
      <author>example@mail.com (David S. Bhatti, Yougin Choi, Rahman S M Wahidur, Maleeka Bakhtawar, Sumin Kim, Surin Lee, Yongtae Lee, Heung-No Lee)</author>
      <guid isPermaLink="false">2502.06894v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations</title>
      <link>http://arxiv.org/abs/2502.07181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种名为Tab2Visual的新颖方法，该方法将异构表格数据转换为视觉表示形式，从而可以应用强大的深度学习模型。这种技术特别针对数据量有限的领域（如医疗健康），通过引入新颖的图像增强技术和促进迁移学习来有效解决数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;在医疗等受限制领域的表格分类中，面临的主要挑战是数据量的不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的方法来处理表格数据分类中的数据短缺问题，特别是在医疗保健等领域。通过将异构表格数据转换为视觉表示形式，使得可以使用强大的深度学习模型进行分析和分类。&lt;h4&gt;方法&lt;/h4&gt;提出了Tab2Visual方法，该方法能够将各种类型的表格数据转换成图像，结合新的图像增强技术来改善数据的多样性，并且支持迁移学习以利用现有的知识。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在有限的数据条件下，Tab2Visual在表格分类问题中超越了传统机器学习算法、基于树的方法以及专为表格设计的深度学习模型的表现。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了Tab2Visual作为一种有潜力解决数据稀缺性的方法的有效性，并且通过广泛的评估证明了其性能优越于其他现有技术。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已直接作为中文描述，无需额外翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research addresses the challenge of limited data in tabular dataclassification, particularly prevalent in domains with constraints likehealthcare. We propose Tab2Visual, a novel approach that transformsheterogeneous tabular data into visual representations, enabling theapplication of powerful deep learning models. Tab2Visual effectively addressesdata scarcity by incorporating novel image augmentation techniques andfacilitating transfer learning. We extensively evaluate the proposed approachon diverse tabular datasets, comparing its performance against a wide range ofmachine learning algorithms, including classical methods, tree-based ensembles,and state-of-the-art deep learning models specifically designed for tabulardata. We also perform an in-depth analysis of factors influencing Tab2Visual'sperformance. Our experimental results demonstrate that Tab2Visual outperformsother methods in classification problems with limited tabular data.</description>
      <author>example@mail.com (Ahmed Mamdouh, Moumen El-Melegy, Samia Ali, Ron Kikinis)</author>
      <guid isPermaLink="false">2502.07181v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos</title>
      <link>http://arxiv.org/abs/2502.07327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了AI生成视频在视频检索任务中的影响，并构建了一个包含真实和AI生成视频的基准数据集，以评估模型对AI生成视频的偏好。&lt;h4&gt;背景&lt;/h4&gt;随着AI生成内容（AIGC）的发展，高质量AI生成视频的创造变得更加迅速和容易，导致互联网上充斥着各种视频内容。然而，这些视频对内容生态系统的影响仍未被充分研究。&lt;h4&gt;目的&lt;/h4&gt;探讨在具有挑战性的视频检索任务中是否存在类似于图像检索中的模型偏见，并评估将AI生成视频纳入训练集的效果。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含13,000个由两个先进开源视频生成模型产生的视频的基准数据集。设计了一套严格的度量标准来准确测量这种偏好，同时考虑了AIGC视频由于帧率有限和质量不佳带来的潜在偏差。应用了三种现成的视频检索模型进行检索任务。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，在检索任务中存在明显的对AI生成视频的偏爱。将AI生成视频纳入训练集会加剧这种偏好，而视频检索中的偏好来源于未见视觉信息和时间信息的复杂互动。&lt;h4&gt;结论&lt;/h4&gt;该研究表明了AI生成视频在检索系统中的潜在影响，并提出了一种使用对比学习方法来减轻模型对AI生成视频偏好的技术。&lt;h4&gt;翻译&lt;/h4&gt;随着AI生成内容的发展，研究者们构建了一个包含真实和AI生成视频的数据集，以评估现有视频检索模型中存在的偏好。结果揭示了显著的偏向于AI生成视频的现象，并探讨了解决这种问题的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of AI-generated content (AIGC), the creation ofhigh-quality AI-generated videos has become faster and easier, resulting in theInternet being flooded with all kinds of video content. However, the impact ofthese videos on the content ecosystem remains largely unexplored. Videoinformation retrieval remains a fundamental approach for accessing videocontent. Building on the observation that retrieval models often favorAI-generated content in ad-hoc and image retrieval tasks, we investigatewhether similar biases emerge in the context of challenging video retrieval,where temporal and visual factors may further influence model behavior. Toexplore this, we first construct a comprehensive benchmark dataset containingboth real and AI-generated videos, along with a set of fair and rigorousmetrics to assess bias. This benchmark consists of 13,000 videos generated bytwo state-of-the-art open-source video generation models. We meticulouslydesign a suite of rigorous metrics to accurately measure this preference,accounting for potential biases arising from the limited frame rate andsuboptimal quality of AIGC videos. We then applied three off-the-shelf videoretrieval models to perform retrieval tasks on this hybrid dataset. Ourfindings reveal a clear preference for AI-generated videos in retrieval.Further investigation shows that incorporating AI-generated videos into thetraining set of retrieval models exacerbates this bias. Unlike the preferenceobserved in image modalities, we find that video retrieval bias arises fromboth unseen visual and temporal information, making the root causes of videobias a complex interplay of these two factors. To mitigate this bias, wefine-tune the retrieval models using a contrastive learning approach. Theresults of this study highlight the potential implications of AI-generatedvideos on retrieval systems.</description>
      <author>example@mail.com (Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng)</author>
      <guid isPermaLink="false">2502.07327v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>NatureLM: Deciphering the Language of Nature for Scientific Discovery</title>
      <link>http://arxiv.org/abs/2502.07527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  81 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了NatureLM，一种基于序列的科学基础模型，旨在促进跨领域的科学研究和应用。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在自然语言处理和人工智能领域取得了巨大成功，推动了针对特定科学领域的模型的发展。然而这些模型通常独立训练，缺乏跨域整合能力。&lt;h4&gt;目的&lt;/h4&gt;提出NatureLM以克服现有科学领域模型的局限性，并促进多学科之间的交叉应用。&lt;h4&gt;方法&lt;/h4&gt;通过使用来自多个科学领域的数据对NatureLM进行预训练，使其具备统一性和灵活性，适用于多种应用场景。&lt;h4&gt;主要发现&lt;/h4&gt;NatureLM在生成和优化小分子、蛋白质、RNA及材料方面的表现优异；实现了跨域的生成与设计，并展示了在任务如SMILES到IUPAC翻译和逆合成等方面的领先性能。随着模型规模的增大，性能显著提升。&lt;h4&gt;结论&lt;/h4&gt;NatureLM为包括药物发现、新材料开发以及治疗性蛋白或核酸的设计在内的多种科学任务提供了通用且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在自然语言处理和人工智能领域已经革命化了机器理解和生成人类语言的方式。受到这些基础模型成功的启发，研究人员针对特定的科学领域（如小分子、材料、蛋白质、DNA以及RNA）开发了相应的基础模型。然而，这些模型通常独立训练，缺乏跨不同科学领域的整合能力。认识到这些领域中的实体都可以表示为序列，并共同构成了“自然语言”，我们引入了基于序列的科学基础模型NatureLM。预训练时使用来自多个科学领域的数据，NatureLM提供了一种统一且多用途的模型，能够支持多种应用，包括：（i）利用文本指令生成和优化小分子、蛋白质、RNA及材料；（ii）跨域生成/设计，例如从蛋白质到分子或蛋白质到RNA的生成；（iii）在诸如SMILES至IUPAC转换以及逆合成等任务上达到最先进的性能水平。我们开发了不同规模的NatureLM模型（包括10亿参数、80亿参数和467亿参数版本），并观察到了随着模型尺寸增加，性能明显改善的现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized natural language processing andartificial intelligence, significantly enhancing how machines comprehend andgenerate human languages. Inspired by the success of these foundation models,researchers have developed foundation models for individual scientific domains,including small molecules, materials, proteins, DNA, and RNA. However, thesemodels are typically trained in isolation, lacking the ability to integrateacross different scientific domains. Recognizing that entities within thesedomains can all be represented as sequences, which together form the "languageof nature", we introduce Nature Language Model (briefly, NatureLM), asequence-based science foundation model designed for scientific discovery.Pre-trained with data from multiple scientific domains, NatureLM offers aunified, versatile model that enables various applications including: (i)generating and optimizing small molecules, proteins, RNA, and materials usingtext instructions; (ii) cross-domain generation/design, such asprotein-to-molecule and protein-to-RNA generation; and (iii) achievingstate-of-the-art performance in tasks like SMILES-to-IUPAC translation andretrosynthesis on USPTO-50k. NatureLM offers a promising generalist approachfor various scientific tasks, including drug discovery (hitgeneration/optimization, ADMET optimization, synthesis), novel material design,and the development of therapeutic proteins or nucleotides. We have developedNatureLM models in different sizes (1 billion, 8 billion, and 46.7 billionparameters) and observed a clear improvement in performance as the model sizeincreases.</description>
      <author>example@mail.com (Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin)</author>
      <guid isPermaLink="false">2502.07527v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Cross-platform Learning-based Fault Tolerant Surfacing Controller for Underwater Robots</title>
      <link>http://arxiv.org/abs/2502.07133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 international Conference on Robotics &amp; Automation  (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于强化学习（RL）的新型跨平台容错浮起控制器，用于水下机器人。&lt;h4&gt;背景&lt;/h4&gt;传统的故障容错方法需要明确识别出故障执行器，而本文的方法则允许机器人在不需确定故障的情况下使用剩余正常工作的执行器进行浮起。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理不同执行器配置下各种故障场景的鲁棒策略，并引入跨学习机制以提高多个具有不同类型执行器的水下机器人的控制效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的基于强化学习的方法，该方法通过模拟三种类型的水下机器人（包括悬浮型AUV、鱼雷形状的AUV以及海龟形状的U-CAT）来验证其有效性，并在物理环境中进行真实世界实验。&lt;h4&gt;主要发现&lt;/h4&gt;提出的RL控制器相比基线控制器，在稳定性和成功率方面表现更好，实测中达到了85.7%的成功率，而基线控制器仅为57.1%&lt;h4&gt;结论&lt;/h4&gt;该研究为不同水下平台提供了可扩展且高效的故障容错解决方案，并可能在现实世界中的水域任务中有潜在应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中，我们提出了一种基于强化学习（RL）的新型跨平台容错浮起控制器，用于水下机器人。与传统的需要明确识别故障执行器的方法不同，我们的方法使机器人能够在不需确定具体失败位置的情况下仅使用剩余正常工作的执行器进行浮起操作。所提出的控制器能够为不同的执行器配置学习出处理各种故障场景的鲁棒策略，并引入了跨平台共享控制策略的学习机制以提高水下机器人的学习效率和适应性。为了验证我们的方法，我们在三种不同类型的水下机器人（包括悬浮型AUV、鱼雷形AUV以及海龟形U-CAT）上进行了模拟实验，并且在受控环境中对物理设备中的U-CAT进行了实际测试。通过与基线控制器进行对比，基于RL的控制器表现出了更高的稳定性和成功率，在真实世界测试中成功率达到85.7%，而基线控制器仅为57.1%。这项研究为多样化的水下平台提供了一种可扩展且高效的故障容错解决方案，并具有在现实世界的水域任务中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel cross-platform fault-tolerant surfacingcontroller for underwater robots, based on reinforcement learning (RL). Unlikeconventional approaches, which require explicit identification ofmalfunctioning actuators, our method allows the robot to surface using only theremaining operational actuators without needing to pinpoint the failures. Theproposed controller learns a robust policy capable of handling diverse failurescenarios across different actuator configurations. Moreover, we introduce atransfer learning mechanism that shares a part of the control policy acrossvarious underwater robots with different actuators, thus improving learningefficiency and generalization across platforms. To validate our approach, weconduct simulations on three different types of underwater robots: ahovering-type AUV, a torpedo shaped AUV, and a turtle-shaped robot (U-CAT).Additionally, real-world experiments are performed, successfully transferringthe learned policy from simulation to a physical U-CAT in a controlledenvironment. Our RL-based controller demonstrates superior performance in termsof stability and success rate compared to a baseline controller, achieving an85.7 percent success rate in real-world tests compared to 57.1 percent with abaseline controller. This research provides a scalable and efficient solutionfor fault-tolerant control for diverse underwater platforms, with potentialapplications in real-world aquatic missions.</description>
      <author>example@mail.com (Yuya Hamamatsu, Walid Remmas, Jaan Rebane, Maarja Kruusmaa, Asko Ristolainen)</author>
      <guid isPermaLink="false">2502.07133v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation</title>
      <link>http://arxiv.org/abs/2502.07302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于共识矩阵的自我纠正AI代理，用于高分辨率全片扫描图像中多类细胞分割任务。&lt;h4&gt;背景&lt;/h4&gt;在高分辨率的全片扫描图像（WSI）中进行多类别细胞分割对于临床应用至关重要。然而，训练此类模型通常需要领域专家手动标注像素级别的数据，这是一项耗时且劳动密集型的任务。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统非代理方法难以适应标签噪声的问题，本文提出了一个共识矩阵引导的自我纠正AI代理。&lt;h4&gt;方法&lt;/h4&gt;该方法使用共识矩阵定义了AI和注释者都同意标记为细胞或非细胞的区域，并对这些区域施加更强的监督。同时，在特征相似性方面，对于与高置信度一致区域更接近的不一致区域赋予更高的权重。&lt;h4&gt;主要发现&lt;/h4&gt;采用对比学习技术来区分噪声区域与可靠一致性区域之间的特征差异，从而提高模型在处理错误标注数据时的表现。&lt;h4&gt;结论&lt;/h4&gt;这种方法通过迭代修正标签中的噪音增强了模型鲁棒性，在真实世界和模拟噪声数据集上进行了验证，并展示了其训练抗噪数据集中强大模型的潜力。&lt;h4&gt;翻译&lt;/h4&gt;多类细胞分割在高分辨率的全片扫描图像（WSI）中至关重要，尤其是在各种临床应用中。然而，这样的模型通常需要领域专家进行劳动密集型像素级别标注。最近的努力通过引入没有医学专业知识的普通注释者来民主化此过程。但是，传统的非代理方法难以适应性地处理注释噪声，因为它们缺乏机制来降低假阳性（FP）和假阴性（FN）。本文提出了一种共识矩阵感知的自我纠正AI代理，它利用共识矩阵指导其学习过程。该模型展示了在真实世界和模拟噪声数据集上提高分割性能的能力，并且可以纠正FP和FN错误。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-class cell segmentation in high-resolution gigapixel whole slide images(WSI) is crucial for various clinical applications. However, training suchmodels typically requires labor-intensive, pixel-wise annotations by domainexperts. Recent efforts have democratized this process by involving layannotators without medical expertise. However, conventional non-agent-basedapproaches struggle to handle annotation noise adaptively, as they lackmechanisms to mitigate false positives (FP) and false negatives (FN) at boththe image-feature and pixel levels. In this paper, we propose a consensus-awareself-corrective AI agent that leverages the Consensus Matrix to guide itslearning process. The Consensus Matrix defines regions where both the AI andannotators agree on cell and non-cell annotations, which are prioritized withstronger supervision. Conversely, areas of disagreement are adaptively weightedbased on their feature similarity to high-confidence agreement regions, withmore similar regions receiving greater attention. Additionally, contrastivelearning is employed to separate features of noisy regions from those ofreliable agreement regions by maximizing their dissimilarity. This paradigmenables the AI to iteratively refine noisy labels, enhancing its robustness.Validated on one real-world lay-annotated cell dataset and two simulated noisydatasets, our method demonstrates improved segmentation performance,effectively correcting FP and FN errors and showcasing its potential fortraining robust models on noisy datasets. The official implementation and cellannotations are publicly available at https://github.com/ddrrnn123/CASC-AI.</description>
      <author>example@mail.com (Ruining Deng, Yihe Yang, David J. Pisapia, Benjamin Liechty, Junchao Zhu, Juming Xiong, Junlin Guo, Zhengyi Lu, Jiacheng Wang, Xing Yao, Runxuan Yu, Rendong Zhang, Gaurav Rudravaram, Mengmeng Yin, Pinaki Sarder, Haichun Yang, Yuankai Huo, Mert R. Sabuncu)</author>
      <guid isPermaLink="false">2502.07302v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling</title>
      <link>http://arxiv.org/abs/2502.07425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多PDE物理信息神经网络模型的有效性，并通过主动学习策略提高了样本效率。&lt;h4&gt;背景&lt;/h4&gt;传统的PINN模型主要用于单一PDE，限制了其在不同物理系统中的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;探索基于统一架构的多PDE PINN模型的能力及其与主动学习相结合的方法。&lt;h4&gt;方法&lt;/h4&gt;使用一个单一的PINN框架训练四个不同的PDE，并采用Monte Carlo Dropout不确定性估计来实施主动学习策略，以提高样本效率。&lt;h4&gt;主要发现&lt;/h4&gt;目标不确定度采样能够显著提升性能并减少所需的训练样本数量，从而实现跨多个PDE的有效学习。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了基于PINN的泛化模型在处理不同物理问题时无需重新设计网络架构的可能性，并提出了使用多PDE PINN和主动学习的方法来降低计算成本同时保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;物理学信息神经网络(PINNs)作为一种通过将物理定律嵌入到神经网络训练中来解决偏微分方程(PDEs)的强大框架已经出现。然而，传统的PINN模型通常是为单一PDE设计的，限制了其在不同物理系统中的泛化能力。在这项工作中，我们探讨了一个能够解决多个PDE并在统一架构下工作的基础PINN模型的可能性。通过训练一个单一的PINN框架来处理四种不同的PDE——简单谐振子(SHO)、一维热方程、一维波动方程和二维拉普拉斯方程，证明了它学习多样物理动态的能力。为了提高样本效率，我们引入主动学习(Active Learning AL)，采用基于Monte Carlo Dropout的不确定性估计方法选择最具有信息量的训练样本进行迭代式选取。我们评估了不同的主动学习策略，并比较了在10%、20%、30%、40%和50%完整数据集上训练得到模型的准确性影响。我们的结果表明，目标不确定度采样能显著提高性能并减少所需训练样本数量，从而实现了跨多个PDE的有效学习。这项工作强调了一个泛化的PINN基础模型在适应不同的基于物理的问题时无需重新设计网络架构的可能性。我们发现多PDE PINN结合主动学习可以在保持高精度的同时降低物理学基深度学习应用中的计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-Informed Neural Networks (PINNs) have emerged as a powerful frameworkfor solving partial differential equations (PDEs) by embedding physical lawsinto neural network training. However, traditional PINN models are typicallydesigned for single PDEs, limiting their generalizability across differentphysical systems. In this work, we explore the potential of a foundation PINNmodel capable of solving multiple PDEs within a unified architecture. Weinvestigate the efficacy of a single PINN framework trained on four distinctPDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D WaveEquation, and the 2D Laplace Equation, demonstrating its ability to learndiverse physical dynamics.  To enhance sample efficiency, we incorporate Active Learning (AL) using MonteCarlo (MC) Dropout-based uncertainty estimation, selecting the most informativetraining samples iteratively. We evaluate different active learning strategies,comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset,and analyze their impact on solution accuracy. Our results indicate thattargeted uncertainty sampling significantly improves performance with fewertraining samples, leading to efficient learning across multiple PDEs.  This work highlights the feasibility of a generalizable PINN-based foundationmodel, capable of adapting to different physics-based problems withoutredesigning network architectures. Our findings suggest that multi-PDE PINNswith active learning can serve as an effective approach for reducingcomputational costs while maintaining high accuracy in physics-based deeplearning applications.</description>
      <author>example@mail.com (Keon Vin Park)</author>
      <guid isPermaLink="false">2502.07425v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification</title>
      <link>http://arxiv.org/abs/2502.06619v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于增强领域泛化重识别（DG Re-ID）的新方法，名为DCAC。&lt;h4&gt;背景&lt;/h4&gt;域泛化重识别任务由于其实用性吸引了越来越多的关注。然而，现有大多数依赖判别式或对比学习框架的方法往往未能有效避免捷径学习问题，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了改进这一现状，提出了一种基于扩散模型的辅助表示学习方法，结合了关联感知条件化方案（DCAC）。&lt;h4&gt;方法&lt;/h4&gt;该方法通过引入一种关联感知条件化方案，将判别式和对比性的重识别模型与预训练的扩散模型集成在一起。此方案利用生成自重识别模型的身份分类概率以及一组可学身份提示来注入暗知识，并引导扩散过程以捕获身份相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在单源域及多源域DG Re-ID任务中均表现出优越性能，并通过全面的消融研究验证了其有效性与鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DCAC框架不仅提高了重识别特征的泛化能力，还为解决捷径学习问题提供了一个有效的解决方案。代码可在https://github.com/RikoLi/DCAC获得。&lt;h4&gt;翻译&lt;/h4&gt;领域通用化的重新识别（DG Re-ID）旨在通过一个或多个源域训练模型，并在未见目标域上评估其性能，这一任务由于其实用性吸引了越来越多的关注。虽然已经提出了许多方法，但大多数依赖于判别式或对比学习框架来学习泛化表示特征。然而，这些方法往往无法避免捷径学习问题，导致次优的性能表现。在这项工作中，我们提出了一种名为扩散模型辅助表示学习及其关联感知条件方案（DCAC）的新方法，以增强DG Re-ID。我们的方法通过一种关联感知条件方案将判别式和对比性的重识别模型与预训练的扩散模型集成在一起。该方案结合了来自重识别模型的身份分类概率以及一组可学身份提示来注入暗知识，捕捉身份相关性，并引导扩散过程。同时，反馈从扩散模型中传播到重识别模型，有效提高了重识别特征的泛化能力。在单源和多源DG Re-ID任务上的广泛实验表明了我们方法实现了最先进的性能表现。全面消融研究进一步验证了所提出方案的有效性和鲁棒性，并提供了关于其工作原理的见解。代码可在https://github.com/RikoLi/DCAC获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25020552&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/RikoLi/DCAC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain-generalizable re-identification (DG Re-ID) aims to train a model onone or more source domains and evaluate its performance on unseen targetdomains, a task that has attracted growing attention due to its practicalrelevance. While numerous methods have been proposed, most rely ondiscriminative or contrastive learning frameworks to learn generalizablefeature representations. However, these approaches often fail to mitigateshortcut learning, leading to suboptimal performance. In this work, we proposea novel method called diffusion model-assisted representation learning with acorrelation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our methodintegrates a discriminative and contrastive Re-ID model with a pre-traineddiffusion model through a correlation-aware conditioning scheme. Byincorporating ID classification probabilities generated from the Re-ID modelwith a set of learnable ID-wise prompts, the conditioning scheme injects darkknowledge that captures ID correlations to guide the diffusion process.Simultaneously, feedback from the diffusion model is back-propagated throughthe conditioning scheme to the Re-ID model, effectively improving thegeneralization capability of Re-ID features. Extensive experiments on bothsingle-source and multi-source DG Re-ID tasks demonstrate that our methodachieves state-of-the-art performance. Comprehensive ablation studies furthervalidate the effectiveness of the proposed approach, providing insights intoits robustness. Codes will be available at https://github.com/RikoLi/DCAC.</description>
      <author>example@mail.com (Jiachen Li, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.06619v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Data Warehouse Design for Multiple Source Forest Inventory Management and Image Processing</title>
      <link>http://arxiv.org/abs/2502.07015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一个原型数据仓库，旨在整合来自多个来源的林业数据进行长期监测、管理和可持续性分析。此数据仓库能够处理不同类型的数据集，并将其转换为机器学习和深度学习分类及分割模型。&lt;h4&gt;背景&lt;/h4&gt;当前需要一个全面的数据管理系统来整合多源的林业数据，以便于后续的研究与管理需求。&lt;h4&gt;目的&lt;/h4&gt;建立并优化一个用于存储、管理和利用各类林业数据的数据仓库。通过集成先进的数据处理管道，该系统可以为YOLO对象识别模型提供高质量的数据支持，并有助于资源利用率的提升和扩展性。&lt;h4&gt;方法&lt;/h4&gt;研究采用了无人机(UAV)拍摄的照片和纸质文档记录进行实验，在此基础上使用YOLOv11模型测试了合并后的数据集。此外，还探讨了如何利用历史与当前数据比较来理解树木生长或衰退的趋势。&lt;h4&gt;主要发现&lt;/h4&gt;通过整合纸质文档提升了地面真值信息的质量，并且初步结果显示性能有显著改进。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了在林业领域中使用数据仓库进行长时间数据分析的潜力。同时，还指出了未来需要进一步优化资源利用率以及扩展性的可能方向。&lt;h4&gt;翻译&lt;/h4&gt;此摘要为对该论文主要内容的中文译文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research developed a prototype data warehouse to integrate multi-sourceforestry data for long-term monitoring, management, and sustainability. Thedata warehouse is intended to accommodate all types of imagery from variousplatforms, LiDAR point clouds, survey records, and paper documents, with thecapability to transform these datasets into machine learning (ML) and deeplearning classification and segmentation models. In this study, we pioneeredthe integration of unmanned aerial vehicle (UAV) imagery and paper records,testing the merged data on the YOLOv11 model. Paper records improved groundtruth, and preliminary results demonstrated notable performance improvements.  This research aims to implement a data warehouse (DW) to manage data for aYOLO (You Only Look Once) model, which identifies objects in images. It doesthis by integrating advanced data processing pipelines. Data are also storedand easily accessible for future use, including comparing current andhistorical data to understand growth or declining patterns. In addition, thedesign is used to optimize resource usage. It also scales easily, not affectingother parts of the data warehouse when adding dimension tables or other fieldsto the fact table. DW performance and estimations for growing workloads arealso explored in this paper.</description>
      <author>example@mail.com (Kristina Cormier, Kongwen, Zhang, Joshua Padron-Uy, Albert Wong, Keona Gagnier, Ajitesh Parihar)</author>
      <guid isPermaLink="false">2502.07015v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Dataset Ownership Verification in Contrastive Pre-trained Models</title>
      <link>http://arxiv.org/abs/2502.07276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;高质量的开源数据集推动了深度学习领域的快速发展，但保护这些数据集对于数据所有者来说至关重要。本文提出了一种针对自监督预训练模型的所有权验证方法。&lt;h4&gt;背景&lt;/h4&gt;高质开放数据集在深度学习领域中具有重要作用，然而现有所有权验证技术主要面向有监督模型，并不适用于无监督的预训练模型。&lt;h4&gt;目的&lt;/h4&gt;为解决上述问题，本研究旨在开发一种专门针对自监督预训练模型的所有权验证方法。此法有助于确认可疑的黑盒骨干网络是否使用了特定未标注的数据集进行预训练，从而帮助数据所有者维护其权益。&lt;h4&gt;方法&lt;/h4&gt;该方法基于对比学习原理，通过观察在目标数据集中训练的模型与不在其中训练的模型之间的嵌入空间中单个和二元实例关系的变化来验证所有权。研究团队使用了多个对比自监督预训练模型（如SimCLR、BYOL等）进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够显著降低误判率（$p$值低于0.05），优于所有现有方法。&lt;h4&gt;结论&lt;/h4&gt;我们的工作为验证数据集所有权提供了一个新的视角和工具，尤其在无监督预训练模型领域具有重要的应用价值。我们的代码开源可访问于GitHub：https://github.com/xieyc99/DOV4CL。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经用中文进行总结，并按要求转换成了JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality open-source datasets, which necessitate substantial efforts forcuration, has become the primary catalyst for the swift progress of deeplearning. Concurrently, protecting these datasets is paramount for thewell-being of the data owner. Dataset ownership verification emerges as acrucial method in this domain, but existing approaches are often limited tosupervised models and cannot be directly extended to increasingly popularunsupervised pre-trained models. In this work, we propose the first datasetownership verification method tailored specifically for self-supervisedpre-trained models by contrastive learning. Its primary objective is toascertain whether a suspicious black-box backbone has been pre-trained on aspecific unlabeled dataset, aiding dataset owners in upholding their rights.The proposed approach is motivated by our empirical insights that when modelsare trained with the target dataset, the unary and binary instancerelationships within the embedding space exhibit significant variationscompared to models trained without the target dataset. We validate the efficacyof this approach across multiple contrastive pre-trained models includingSimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that ourmethod rejects the null hypothesis with a $p$-value markedly below $0.05$,surpassing all previous methodologies. Our code is available athttps://github.com/xieyc99/DOV4CL.</description>
      <author>example@mail.com (Yuechen Xie, Jie Song, Mengqi Xue, Haofei Zhang, Xingen Wang, Bingde Hu, Genlang Chen, Mingli Song)</author>
      <guid isPermaLink="false">2502.07276v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DOGR: Leveraging Document-Oriented Contrastive Learning in Generative Retrieval</title>
      <link>http://arxiv.org/abs/2502.07219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的通用生成检索框架DOGR，通过对比学习改进了生成式检索任务。&lt;h4&gt;背景&lt;/h4&gt;生成检索是一种新颖的信息检索方法，利用生成语言模型为给定查询生成文档标识符的排名列表。这种方法简化了检索管道，用模型参数取代了庞大的外部索引。&lt;h4&gt;目的&lt;/h4&gt;解决现有研究仅关注查询与文档标识符之间关系的学习问题，无法直接表示查询和文档之间的相关性。&lt;h4&gt;方法&lt;/h4&gt;提出DOGR框架，采用两阶段学习策略，通过直接交互全面捕捉查询和文档间的关系，并使用负采样方法及对应的对比学习目标来增强语义表征的习得。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在两个公共基准数据集上，DOGR相比现有生成式检索方法达到了最先进的性能。进一步实验显示该框架对于常见的标识符构建技术具有普遍有效性。&lt;h4&gt;结论&lt;/h4&gt;通过引入文档导向对比学习来增强生成式检索任务，能够更全面地理解查询和文档之间的关系，并取得优异的检索效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在信息检索领域提出的一种创新方法——DOGR框架，该方法利用对比学习技术改进生成式检索任务。与现有研究相比，它不仅简化了检索管道，还解决了相关性表示的问题，并且在实验中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval constitutes an innovative approach in in- formationretrieval, leveraging generative language models (LM) to generate a ranked listof document identifiers (do- cid) for a given query. It simplifies theretrieval pipeline by replacing the large external index with model parameters.However, existing works merely learned the relationship be- tween queries anddocument identifiers, which is unable to directly represent the relevancebetween queries and docu- ments. To address the above problem, we propose anovel and general generative retrieval framework, namely Leverag- ingDocument-Oriented Contrastive Learning in Generative Retrieval (DOGR), whichleverages contrastive learning to improve generative retrieval tasks. It adoptsa two-stage learn- ing strategy that captures the relationship between queriesand documents comprehensively through direct interactions. Furthermore,negative sampling methods and correspond- ing contrastive learning objectivesare implemented to en- hance the learning of semantic representations, therebypro- moting a thorough comprehension of the relationship be- tween queries anddocuments. Experimental results demon- strate that DOGR achievesstate-of-the-art performance com- pared to existing generative retrievalmethods on two public benchmark datasets. Further experiments have shown thatour framework is generally effective for common identifier con- structiontechniques.</description>
      <author>example@mail.com (Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo)</author>
      <guid isPermaLink="false">2502.07219v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Refine Knowledge of Large Language Models via Adaptive Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.07184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种通过模仿人类学习过程来减少大型语言模型（LLM）幻觉的方法。&lt;h4&gt;背景&lt;/h4&gt;减轻LLMs的幻觉一直是研究社区的根本目标。现有的主流方法是通过优化知识表示来降低幻觉，这些工作主要关注模型获取的知识。&lt;h4&gt;目的&lt;/h4&gt;借鉴人类学习知识的方式，设计了一种适应性对比学习策略，以提高LLM处理知识的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Adaptive Contrastive Learning策略，该策略根据LLMs的实际掌握情况灵活构建正负样本进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，我们的方法有助于模型巩固已有的正确知识、加深对尚未完全理解的知识的理解、遗忘不正确的知识，并承认自己缺乏的知识。&lt;h4&gt;结论&lt;/h4&gt;广泛的数据集上的实验和详细分析验证了所提出的方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;如何减轻大型语言模型（LLMs）的幻觉一直是研究社区追求的基本目标。通过回顾大量与幻觉相关的研究，发现主流方法是通过优化LLMs的知识表示来减少幻觉。考虑到这些工作的核心关注点在于模型获得的知识，并且知识长期以来一直是人类社会进步的核心主题，我们认为模仿人类学习过程可以极大地提高模型完善知识的过程。在我们的工作中，我们设计了一种适应性对比学习策略。该方法根据LLMs对知识的实际掌握情况灵活构建正负样本进行对比学习。这一策略帮助LLMs巩固已有的正确知识、加深对尚未完全理解的知识的理解、遗忘不正确的知识，并承认自己缺乏的知识。广泛的数据集上的实验和详细分析验证了我们方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How to alleviate the hallucinations of Large Language Models (LLMs) hasalways been the fundamental goal pursued by the LLMs research community.Looking through numerous hallucination-related studies, a mainstream categoryof methods is to reduce hallucinations by optimizing the knowledgerepresentation of LLMs to change their output. Considering that the core focusof these works is the knowledge acquired by models, and knowledge has long beena central theme in human societal progress, we believe that the process ofmodels refining knowledge can greatly benefit from the way humans learn. In ourwork, by imitating the human learning process, we design an AdaptiveContrastive Learning strategy. Our method flexibly constructs differentpositive and negative samples for contrastive learning based on LLMs' actualmastery of knowledge. This strategy helps LLMs consolidate the correctknowledge they already possess, deepen their understanding of the correctknowledge they have encountered but not fully grasped, forget the incorrectknowledge they previously learned, and honestly acknowledge the knowledge theylack. Extensive experiments and detailed analyses on widely used datasetsdemonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-Yu Guo, Chao Qu, Xiaoyu Tan, Hai-Tao Zheng, Ying Shen, Philip S. Yu)</author>
      <guid isPermaLink="false">2502.07184v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>From Pixels to Components: Eigenvector Masking for Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06314v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图像掩码策略，该策略在主成分分析的基础上进行随机掩码操作，而非直接对原始像素进行处理。这种方法利用了图像的全局信息，通过预测被遮挡的部分从可见部分重建来提高视觉表示学习的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的图像自我监督方法通常采用随机遮蔽像素块的方式，这存在一定的局限性，可能导致无法有效学习到用于下游任务所需的高层次特征。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的限制，提出了一种新的掩码策略，以期能够通过预测被遮挡的部分从可见部分重建来提取更有用的视觉表示。&lt;h4&gt;方法&lt;/h4&gt;首先对数据进行主成分分析（PCA），然后随机掩码一部分分量，并确保这些被掩码的分量占据整个数据方差的一个固定比例。学习任务是基于未被掩码的分量预测和重构被掩码的部分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与直接对像素进行掩码相比，这种方法能够显著提高图像分类性能，证明了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法是一种简单且鲁棒的数据驱动替代方案，可以作为传统遮挡图像建模方法的有力补充或替代。&lt;h4&gt;翻译&lt;/h4&gt;从预测图像中被掩盖部分来学习视觉表示是自我监督的一种强大方式。然而，随机掩码像素块的做法存在一定的局限性，可能导致无法有效学习到高层次特征。我们提出了一种在数据转换基础上进行的操作策略，即对主成分分析后的结果进行随机掩码，并重构未被遮挡的部分。这种方法利用了图像的全局信息，能够提取更多有用表示。实验表明，在图像分类任务上，该方法优于传统的像素掩码方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting masked from visible parts of an image is a powerfulself-supervised approach for visual representation learning. However, thecommon practice of masking random patches of pixels exhibits certain failuremodes, which can prevent learning meaningful high-level features, as requiredfor downstream tasks. We propose an alternative masking strategy that operateson a suitable transformation of the data rather than on the raw pixels.Specifically, we perform principal component analysis and then randomly mask asubset of components, which accounts for a fixed ratio of the data variance.The learning task then amounts to reconstructing the masked components from thevisible ones. Compared to local patches of pixels, the principal components ofimages carry more global information. We thus posit that predicting masked fromvisible components involves more high-level features, allowing our maskingstrategy to extract more useful representations. This is corroborated by ourempirical findings which demonstrate improved image classification performancefor component over pixel masking. Our method thus constitutes a simple androbust data-driven alternative to traditional masked image modeling approaches.</description>
      <author>example@mail.com (Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt)</author>
      <guid isPermaLink="false">2502.06314v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Model Diffusion for Certifiable Few-shot Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.06970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在现代大规模深度学习中，解决低数据问题的一种流行且有效的工作流程是通过参数高效微调（PEFT）将强大的预训练基础模型（FMs）适应到新的任务上。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在为下游任务开发一种新型的转移学习方法，以提供非空泛化的理论保证，在低样本场景下也能确保模型的有效性和准确性。&lt;h4&gt;方法&lt;/h4&gt;研究人员首先利用上游任务来训练PEFT参数分布。然后通过抽样和评估过程来进行下游任务的学习——从训练好的扩散模型中抽取可能的PEFT并选择在下游数据上可能性最高的那个。这种方法将模型假设限制在一个有限数量的PEFT样本集中，从而相较于神经网络权重中的连续假设空间提供了更紧的风险保证。&lt;h4&gt;主要发现&lt;/h4&gt;该方法相比现有学习方法，在低样本场景下能提供非空泛化保证，并且与现有的会导致无意义界限的学习方式不同，这种方法可以避免泛化性能无法验证的问题。&lt;h4&gt;结论&lt;/h4&gt;新的转移学习方法能够为低数据量环境下的模型部署和应用提供理论上的泛化保证，有助于提高这些应用场景中的模型可靠性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;在现代大规模深度学习中，解决低数据问题的一种流行且有效的工作流程是通过参数高效微调（PEFT）将强大的预训练基础模型（FMs）适应到新的任务上。然而，尽管这种方法从经验上看很有效，但由于缺乏泛化保证来证明其准确性，可能导致对于某些应用场景部署前的伦理或法律要求无法满足。在这篇论文中，我们开发了一种新型转移学习方法，旨在为下游任务提供非空理论上的泛化保证，即使在低样本环境中也能实现这一目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern large-scale deep learning, a prevalent and effective workflow forsolving low-data problems is adapting powerful pre-trained foundation models(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, whileempirically effective, the resulting solutions lack generalisation guaranteesto certify their accuracy - which may be required for ethical or legal reasonsprior to deployment in high-importance applications. In this paper we develop anovel transfer learning approach that is designed to facilitate non-vacuouslearning theoretic generalisation guarantees for downstream tasks, even in thelow-shot regime. Specifically, we first use upstream tasks to train adistribution over PEFT parameters. We then learn the downstream task by asample-and-evaluate procedure -- sampling plausible PEFTs from the traineddiffusion model and selecting the one with the highest likelihood on thedownstream data. Crucially, this confines our model hypothesis to a finite setof PEFT samples. In contrast to learning in the typical continuous hypothesisspaces of neural network weights, this facilitates tighter risk certificates.We instantiate our bound and show non-trivial generalization guaranteescompared to existing learning approaches which lead to vacuous bounds in thelow-shot regime.</description>
      <author>example@mail.com (Fady Rezk, Royson Lee, Henry Gouk, Timothy Hospedales, Minyoung Kim)</author>
      <guid isPermaLink="false">2502.06970v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Cost-Efficient Continual Learning with Sufficient Exemplar Memory</title>
      <link>http://arxiv.org/abs/2502.07274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一个在充足示例存储资源下的持续学习（CL）新方法，通过结合权重重置和平均技术直接操作模型的权重空间来减少计算成本。&lt;h4&gt;背景&lt;/h4&gt;当前持续学习研究通常假设记忆资源受到严格限制。然而，在许多现实场景中，尤其是在大型基础模型时代，内存是充足的，而GPU计算成本成为主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;调查在示例存储资源丰富的条件下进行持续学习的方法，并提出一种减少现有方法计算成本的新型技术方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种直接操作模型权重空间的新方法，通过结合权重重置和平均技术，在充足的示例存储环境中工作。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了与现有最佳性能相当的结果，同时将计算成本降低到四分之一或三分之一。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了传统的持续学习假设，并为计算效率高的持续学习应用提供了实用基准。&lt;h4&gt;翻译&lt;/h4&gt;持续学习（CL）研究通常假定高度受限的示例内存资源。然而，在许多现实世界场景中——尤其是在大型基础模型时代，内存充足，而GPU计算成本是主要瓶颈。在这项工作中，我们探讨了在示例记忆充足的条件下进行持续学习的新设置。与为严格的示例内存限制设计的方法不同，我们提出了一种简单但有效的方法，直接通过结合权重重置和平均技术操作模型的权重空间。我们的方法实现了最先进的性能，同时将计算成本降低到现有方法的四分之一或三分之一。这些发现挑战了传统的持续学习假设，并提供了计算效率高的持续学习应用的实际基准线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) research typically assumes highly constrainedexemplar memory resources. However, in many real-world scenarios-especially inthe era of large foundation models-memory is abundant, while GPU computationalcosts are the primary bottleneck. In this work, we investigate CL in a novelsetting where exemplar memory is ample (i.e., sufficient exemplar memory).Unlike prior methods designed for strict exemplar memory constraints, wepropose a simple yet effective approach that directly operates in the model'sweight space through a combination of weight resetting and averagingtechniques. Our method achieves state-of-the-art performance while reducing thecomputational cost to a quarter or third of existing methods. These findingschallenge conventional CL assumptions and provide a practical baseline forcomputationally efficient CL applications.</description>
      <author>example@mail.com (Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha)</author>
      <guid isPermaLink="false">2502.07274v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks at a Fraction</title>
      <link>http://arxiv.org/abs/2502.06136v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, accepted at PAKKD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Quaternion Message Passing Neural Networks (QMPNNs)框架，该框架利用四元数空间计算节点表示，从而在减少模型大小的同时保持与原始尺寸GNN相当的准确性。&lt;h4&gt;背景&lt;/h4&gt;图形神经网络（GNN）已被证明是学习图结构数据表示的强大工具。除了实值GNN之外，四元数GNN也在处理图任务时表现出色。然而，在保持高精度的情况下减小模型规模仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;通过减少模型尺寸同时维持与原始大小的GNN相当的准确性来降低能量足迹。&lt;h4&gt;方法&lt;/h4&gt;论文提出了QMPNN框架，并提出了一种新的视角——Graph Lottery Tickets，旨在从子网络中找到初始化彩票，即能够训练出与原始GNN相当性能的小型子网。此外，该研究评估了所提出的QMPNN框架和LTH在三种基础图任务上的表现：节点分类、链路预测以及图分类。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了QMPNN框架的有效性，在减少参数数量的同时保持了与原始GNN相当的性能；还发现了可以进一步降低可训练模型参数的方法，即从GNN子网络中找到初始化彩票。这些方法在三个实际数据集上的评估显示出良好的效果。&lt;h4&gt;结论&lt;/h4&gt;所提出的Quaternion Message Passing Neural Networks (QMPNNs)框架和Graph Lottery Tickets视角提供了一种通用化的方法，可以在减少四倍原始参数数量的情况下将四元数表示整合到GNN架构中，并保持与原模型相当的性能。这种方法不仅能够显著减小模型大小，而且还能节省计算资源。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实值GNN之外，四元数GNN在处理图形任务时也表现出色。为了减少能源消耗，我们在保持与原始尺寸的GNN相当精度的同时减少了模型大小。本文介绍了Quaternion Message Passing Neural Networks (QMPNNs)，这是一个框架，利用四元空间计算节点表示。我们的方法提供了一种通用的方法，在只使用原参数数量四分之一的情况下将四元表示整合到GNN架构中。此外，我们还提出了一种新颖的视角——Graph Lottery Tickets，并重新定义了其在GNN和QMPNN上下文中的适用性。具体目标是找到一个能够实现与原始GNN相当性能的子网初始化彩票，以此进一步减少可训练模型参数的数量。为了验证所提出的QMPNN框架和LTH的有效性，我们在三种基本图任务——节点分类、链路预测以及图分类上使用真实数据集进行了评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for learningrepresentations of graph-structured data. In addition to real-valued GNNs,quaternion GNNs also perform well on tasks on graph-structured data. With theaim of reducing the energy footprint, we reduce the model size whilemaintaining accuracy comparable to that of the original-sized GNNs. This paperintroduces Quaternion Message Passing Neural Networks (QMPNNs), a frameworkthat leverages quaternion space to compute node representations. Our approachoffers a generalizable method for incorporating quaternion representations intoGNN architectures at one-fourth of the original parameter count. Furthermore,we present a novel perspective on Graph Lottery Tickets, redefining theirapplicability within the context of GNNs and QMPNNs. We specifically aim tofind the initialization lottery from the subnetwork of the GNNs that canachieve comparable performance to the original GNN upon training. Therebyreducing the trainable model parameters even further. To validate theeffectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,we evaluate their performance on real-world datasets across three fundamentalgraph-based tasks: node classification, link prediction, and graphclassification.</description>
      <author>example@mail.com (Rucha Bhalchandra Joshi, Sagar Prakash Barad, Nidhi Tiwari, Subhankar Mishra)</author>
      <guid isPermaLink="false">2502.06136v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2502.01216v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;工业缺陷分割对于制造业的质量控制至关重要。由于训练样本的稀缺性，少样本语义分割（FSS）在该领域具有重要价值。&lt;h4&gt;背景&lt;/h4&gt;现有的研究大多将FSS应用于简单纹理上的缺陷处理，而忽略了更多样化场景的需求。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过探索基于更广泛工业产品和各种类型缺陷的FSS来弥补这一空白。&lt;h4&gt;贡献1&lt;/h4&gt;我们提供了一个新的真实世界数据集，并重新组织了一些现有的数据集以构建一个更为全面的少样本缺陷分割（FDS）基准。&lt;h4&gt;方法&lt;/h4&gt;在该基准上，我们深入研究了基于度量学习的FSS方法，包括基于元学习和视觉基础模型（VFMs）的方法。&lt;h4&gt;主要发现1&lt;/h4&gt;现有基于元学习的方法一般不太适合这一任务，而VFMs则具有很大的潜力。&lt;h4&gt;贡献2&lt;/h4&gt;进一步系统地研究了各种VFMs在该任务中的适用性，涉及两种范式：特征匹配以及使用Segment Anything (SAM)模型的方案。&lt;h4&gt;主要发现2&lt;/h4&gt;我们提出了一种基于特征匹配的新颖高效的FDS方法，并且发现通过其视频跟踪模式，SAM2特别有效于解决FDS问题。&lt;h4&gt;数据集和代码&lt;/h4&gt;贡献的数据集和代码将在https://github.com/liutongkun/GFDS上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial defect segmentation is critical for manufacturing quality control.Due to the scarcity of training defect samples, few-shot semantic segmentation(FSS) holds significant value in this field. However, existing studies mostlyapply FSS to tackle defects on simple textures, without considering morediverse scenarios. This paper aims to address this gap by exploring FSS inbroader industrial products with various defect types. To this end, wecontribute a new real-world dataset and reorganize some existing datasets tobuild a more comprehensive few-shot defect segmentation (FDS) benchmark. Onthis benchmark, we thoroughly investigate metric learning-based FSS methods,including those based on meta-learning and those based on Vision FoundationModels (VFMs). We observe that existing meta-learning-based methods aregenerally not well-suited for this task, while VFMs hold great potential. Wefurther systematically study the applicability of various VFMs in this task,involving two paradigms: feature matching and the use of Segment Anything (SAM)models. We propose a novel efficient FDS method based on feature matching.Meanwhile, we find that SAM2 is particularly effective for addressing FDSthrough its video track mode. The contributed dataset and code will beavailable at: https://github.com/liutongkun/GFDS.</description>
      <author>example@mail.com (Tongkun Liu, Bing Li, Xiao Jin, Yupeng Shi, Qiuying Li, Xiang Wei)</author>
      <guid isPermaLink="false">2502.01216v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction</title>
      <link>http://arxiv.org/abs/2502.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期人工智能的进步革新了材料科学中的属性预测，并加速了新材料的发现。图神经网络（GNN）因其能将晶体结构表示为图的能力而脱颖而出，有效捕捉局部交互并提供优秀的预测结果。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常会丢失关键的全局信息，如晶系和重复单元连接性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于跨注意力机制的多模态融合模型CAST，该模型结合了图和文本模态以保留重要的材料信息。&lt;h4&gt;方法&lt;/h4&gt;CAST通过使用交叉注意力机制在节点级和标记级别上组合特征，并且通过掩码节点预测预训练策略进一步增强原子级别的信息整合。此方法超越了依赖于材料级别的嵌入（如均值汇集或[CLS]令牌）的方法。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在四个晶体属性（包括带隙）的性质预测方面比CrysMMNet和MultiMat等方法高出高达22.9%的改进。&lt;h4&gt;结论&lt;/h4&gt;预训练是关键，以使节点和文本嵌入对齐。注意力图证实了其捕捉节点与令牌之间关系的有效性。该研究突显了多模态学习在材料科学中的潜力，并为更加强大的预测模型铺平道路，这些模型能够整合局部和全局信息。&lt;h4&gt;翻译&lt;/h4&gt;最近人工智能的进步革新了材料科学领域中物质属性的预测方法，并加速了新材料的发现过程。图神经网络（GNN）由于其将晶体结构表示成图的能力而脱颖而出，可以有效地捕捉到本地交互并提供更好的预测结果。然而，这些方法往往会丢失重要的全局信息，例如晶系和重复单元连接性等。为了解决这个问题，我们提出了一种基于跨注意力机制的多模态融合模型CAST，该模型结合了图形和文本模式以保留关键材料信息。通过使用交叉注意机制在节点级别和标记级别的特征之间进行组合，并且通过掩码节点预测预训练策略进一步增强原子级别的信息整合，我们的方法超越了依赖于材料级别的嵌入（例如图均值汇集或[CLS]令牌）的方法。我们的方法在四个晶体属性的性质预测上比CrysMMNet和MultiMat等方法提高了高达22.9%的表现。预训练是关键以使节点和文本嵌入对齐，并且注意力地图确认其捕捉到节点与标记之间关系的有效性。这项研究展示了多模态学习在材料科学中的潜力，为更加强大的预测模型打开了大门，这些模型能够整合局部和全局信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in AI have revolutionized property prediction inmaterials science and accelerating material discovery. Graph neural networks(GNNs) stand out due to their ability to represent crystal structures asgraphs, effectively capturing local interactions and delivering superiorpredictions. However, these methods often lose critical global information,such as crystal systems and repetitive unit connectivity. To address this, wepropose CAST, a cross-attention-based multimodal fusion model that integratesgraph and text modalities to preserve essential material information. CASTcombines node- and token-level features using cross-attention mechanisms,surpassing previous approaches reliant on material-level embeddings like graphmean-pooling or [CLS] tokens. A masked node prediction pretraining strategyfurther enhances atomic-level information integration. Our method achieved upto 22.9\% improvement in property prediction across four crystal propertiesincluding band gap compared to methods like CrysMMNet and MultiMat. Pretrainingwas key to aligning node and text embeddings, with attention maps confirmingits effectiveness in capturing relationships between nodes and tokens. Thisstudy highlights the potential of multimodal learning in materials science,paving the way for more robust predictive models that incorporate both localand global information.</description>
      <author>example@mail.com (Jaewan Lee, Changyoung Park, Hongjun Yang, Sungbin Lim, Sehui Han)</author>
      <guid isPermaLink="false">2502.06836v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GENERator: A Long-Context Generative Genomic Foundation Model</title>
      <link>http://arxiv.org/abs/2502.07272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GENERator的新型基因组基础模型，该模型使用大型语言模型技术来解析DNA序列，并展示了在多个基准测试中的领先性能。&lt;h4&gt;背景&lt;/h4&gt;随着DNA测序技术的进步，解码基因组序列的能力得到了显著提高。然而，由于遗传材料的复杂性，对这些序列进行预测和解释仍然具有挑战性。尽管大型语言模型为生物序列分析引入了新的机会，但现有模型在鲁棒性和应用范围方面仍面临限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为GENERator的新基因组基础模型，以克服现有模型面临的局限性，并提升其在复杂生物系统中的预测和解释能力。&lt;h4&gt;方法&lt;/h4&gt;开发了一个具有98k碱基对上下文长度和12亿参数的生成型基因组基础模型。该模型基于3860亿个真核DNA碱基组成的庞大数据集进行训练，能够准确地生成蛋白质编码序列，并响应性地生成具有特定活性谱的启动子序列。&lt;h4&gt;主要发现&lt;/h4&gt;GENERator在多个基准测试中表现出色，在基因序列优化方面显示出显著潜力。该模型还能产生与已知蛋白质家族结构类似的新蛋白质编码序列。&lt;h4&gt;结论&lt;/h4&gt;作为重要的工具，GENERator能够推动基因组研究和生物技术的进步，增强我们对复杂生物系统的理解和预测能力，并为精准的基因组干预提供可能。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：随着DNA测序技术的进步，解码基因组序列的能力显著提高。然而，由于遗传材料的复杂性，这些序列的预测和解释仍然具有挑战性。大型语言模型（LLMs）为生物序列分析带来了新的机会。最近在基因组语言模型方面的进展突显了LLMs解读DNA序列的潜力。尽管如此，现有模型往往面临鲁棒性和应用范围上的限制，主要由于模型结构和训练数据规模的局限。为了克服这些限制，我们提出了一种名为GENERator的新生成型基因组基础模型，该模型具有98k碱基对(bp)的上下文长度和12亿个参数。该模型基于一个包含3860亿个真核DNA碱基的大规模数据集进行训练，并在现有及新提出的基准测试中表现出色。GENERator遵循分子生物学的基本定律，能够准确地生成蛋白质编码序列，翻译出与已知家族结构相似的蛋白质。此外，在序列优化方面，特别是通过响应性启动子序列生成（具有特定活性谱）展现出显著潜力。这些能力使GENERator成为基因组研究和生物技术进步的关键工具，增强我们对复杂生物系统进行解读和预测的能力，并为精准的基因组干预提供可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in DNA sequencing technologies have significantly improved ourability to decode genomic sequences. However, the prediction and interpretationof these sequences remain challenging due to the intricate nature of geneticmaterial. Large language models (LLMs) have introduced new opportunities forbiological sequence analysis. Recent developments in genomic language modelshave underscored the potential of LLMs in deciphering DNA sequences.Nonetheless, existing models often face limitations in robustness andapplication scope, primarily due to constraints in model structure and trainingdata scale. To address these limitations, we present GENERator, a generativegenomic foundation model featuring a context length of 98k base pairs (bp) and1.2B parameters. Trained on an expansive dataset comprising 386B bp ofeukaryotic DNA, the GENERator demonstrates state-of-the-art performance acrossboth established and newly proposed benchmarks. The model adheres to thecentral dogma of molecular biology, accurately generating protein-codingsequences that translate into proteins structurally analogous to knownfamilies. It also shows significant promise in sequence optimization,particularly through the prompt-responsive generation of promoter sequenceswith specific activity profiles. These capabilities position the GENERator as apivotal tool for genomic research and biotechnological advancement, enhancingour ability to interpret and predict complex biological systems and enablingprecise genomic interventions.</description>
      <author>example@mail.com (Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang)</author>
      <guid isPermaLink="false">2502.07272v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2502.07221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;病理学在诊断多种疾病中起着关键作用，但现有方法依赖于专门针对特定任务训练的模型，并且需要大量标记的数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的病理诊断技术主要依靠为具体任务设计的机器学习模型。这些模型通常需要大量的数据来保证准确性，这使得它们难以适应不同类型的病理性状并导致了可持续性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用多模态嵌入的方法以支持多种下游任务，并引入一个评估病理学中多模态嵌入质量的标准基准。&lt;h4&gt;方法&lt;/h4&gt;提出了MLLM4PUE框架，该框架利用多模态大型语言模型生成病理学通用嵌入。同时开发了病理学多模态嵌入基准（PMEB）来全面评估病理数据集中的多模态关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于MLLM的方法能够有效地支持各种下游任务，并且为基础模型在病理学研究方向上统一了研究路径。&lt;h4&gt;结论&lt;/h4&gt;通过引入通用的多模态嵌入以及统一基准，能够更好地解决现有技术面临的可持续性问题和多样性挑战，推动医学图像和文本处理的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely on task-specific models trained on extensive well-labeled datasets. This creates sustainability challenges due to the diversity of pathologies and labor-intensive data collection. To address these limitations, we propose MLLM4PUE framework using multimodal large language models for generating universal pathology embeddings. Additionally, a comprehensive benchmark PMEB is introduced for evaluating the quality of multimodal embeddings in pathology tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology plays a critical role in diagnosing a wide range of diseases, yetexisting approaches often rely heavily on task-specific models trained onextensive, well-labeled datasets. These methods face sustainability challengesdue to the diversity of pathologies and the labor-intensive nature of datacollection. To address these limitations, we highlight the need for universalmultimodal embeddings that can support multiple downstream tasks. Previousapproaches often involve fine-tuning CLIP-based models, which handle images andtext separately, limiting their ability to capture complex multimodalrelationships. Additionally, these models are evaluated across diverse datasetswithout a unified benchmark for assessing multimodal embeddings in pathology.To address these challenges, we propose MLLM4PUE, a novel framework thatleverages Multimodal Large Language Models (MLLMs) to generate PathologyUniversal Embeddings. The MLLM4PUE framework not only facilitates robustintegration of images and text but also enhances understanding and fusioncapabilities across various tasks. We further introduce the PathologyMultimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed toassess the quality of pathology multimodal embeddings. PMEB comprises 15original tasks drawn from 14 datasets, organized into three meta-tasks:retrieval, classification, and composed retrieval. Experimental resultsdemonstrate the superiority of MLLM4PUE, illustrating MLLM-based models caneffectively support a wide range of downstream tasks and unify the researchdirection for foundation models in pathology.</description>
      <author>example@mail.com (Qifeng Zhou, Thao M. Dang, Wenliang Zhong, Yuzhi Guo, Hehuan Ma, Saiyang Na, Junzhou Huang)</author>
      <guid isPermaLink="false">2502.07221v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MPFBench: A Large Scale Dataset for SciML of Multi-Phase-Flows: Droplet and Bubble Dynamics</title>
      <link>http://arxiv.org/abs/2502.07080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了科学机器学习在模拟多相流体动力学（如滴落的液滴和上升的气泡）中的应用，展示了利用神经算子和基础模型进行高效建模的可能性。&lt;h4&gt;背景&lt;/h4&gt;工业应用中遇到的多相流体力学现象，比如滴落的液滴和上升的气泡，由于其复杂的不稳定性、波形图案和气泡破裂等特性，使得对其进行有效模拟极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;探索科学机器学习（SciML）在基于神经算子和基础模型下建模多相流体动力学现象中的应用潜力，并提高这类问题的计算效率与准确性。&lt;h4&gt;方法&lt;/h4&gt;研究团队通过序列到序列技术对一个包含11,000次模拟结果的数据集进行分析，该数据集中包含了由经过验证的格子玻尔兹曼方法（LBM）框架生成的一百万个时间快照。&lt;h4&gt;主要发现&lt;/h4&gt;机器学习模型能够捕捉瞬态动态和复杂的流体相互作用，为基于SciML的求解器在未来实现更加准确且计算效率更高的多相应用铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;利用神经算子和基础模型进行科学机器学习的方法展示出显著潜力，可以有效解决复杂多相现象模拟问题，并有望推动相关工业领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多相流体力学（如滴落的液滴和上升的气泡）对于许多工业应用至关重要。然而，由于不稳定性、波形图案及气泡破裂等特性，对其进行有效的模拟极具挑战性。本文探讨了科学机器学习（SciML）在使用神经算子与基础模型建模这些现象方面的潜力。我们对11,000次仿真生成的全面数据集进行了序列到序列技术的应用，该数据集包含一百万个时间快照，并由一种经过验证的格子玻尔兹曼方法（LBM）框架产生。结果表明机器学习模型能够捕捉瞬态动态与复杂的流体交互作用，为基于SciML的求解器在未来实现更加准确且计算效率更高的多相应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiphase fluid dynamics, such as falling droplets and rising bubbles, arecritical to many industrial applications. However, simulating these phenomenaefficiently is challenging due to the complexity of instabilities, wavepatterns, and bubble breakup. This paper investigates the potential ofscientific machine learning (SciML) to model these dynamics using neuraloperators and foundation models. We apply sequence-to-sequence techniques on acomprehensive dataset generated from 11,000 simulations, comprising 1 milliontime snapshots, produced with a well-validated Lattice Boltzmann method (LBM)framework. The results demonstrate the ability of machine learning models tocapture transient dynamics and intricate fluid interactions, paving the way formore accurate and computationally efficient SciML-based solvers for multiphaseapplications.</description>
      <author>example@mail.com (Mehdi Shadkhah, Ronak Tali, Ali Rabeh, Ethan Herron, Cheng-Hau Yang, Abhisek Upadhyaya, Adarsh Krishnamurthy, Chinmay Hegde, Aditya Balu, Baskar Ganapathysubramanian)</author>
      <guid isPermaLink="false">2502.07080v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.06910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种基于Kolmogorov-Arnold网络（KAN）的频率分解学习架构TimeKAN，用于解决混合多频时间序列预测问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界的时间序列通常包含多种相互交织的频率成分，这使得准确预测变得具有挑战性。单一频率模式在不同频率下的信息密度各不相同，统一建模方法可能导致特征描述不准。&lt;h4&gt;目的&lt;/h4&gt;提出一种灵活且高效的架构来解决由多频混合导致的复杂时间序列预测问题。&lt;h4&gt;方法&lt;/h4&gt;TimeKAN主要包含三个组件：级联频率分解（CFD）块、多阶KAN表征学习（M-KAN）块以及频率混合块。通过底部向上递进的方式获取每个频率带的序列表示，利用高灵活性的KAN设计了一种新的M-KAN模块用于学习特定时间模式，并且通过频率混合块重新组合不同的频段。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明TimeKAN在多个实际时间序列数据集上实现了最先进的性能，并且作为一种轻量级架构具有优越性。&lt;h4&gt;结论&lt;/h4&gt;TimeKAN提供了一种有效的解决方案，解决了由多频成分复杂交织导致的时间序列预测问题。其源代码已在GitHub上公开。&lt;h4&gt;翻译&lt;/h4&gt;真实世界中的时间序列通常包含多个频率成分，这些成分相互交织在一起，使得准确的时间序列预测变得具有挑战性。将混合的频率成分分解为多个单一频率成分是一种自然的选择。然而，不同频率下的模式信息密度各不相同，使用统一建模方法会导致特征描述不准。为了应对这一挑战，受最近Kolmogorov-Arnold网络（KAN）灵活性的启发，我们提出了一种基于KAN的时间分解学习架构TimeKAN来解决由多个频率混合造成的复杂预测问题。具体来说，TimeKAN主要包含三个组件：级联频率分解(CFD)块、多阶KAN表征学习(M-KAN)块和频率混合块。CFD块采用自底向上递进的方法获得每个频带的序列表示。得益于KAN的高度灵活性，我们设计了一种新的M-KAN模块来在每个频带内学习特定的时间模式并进行表征。最后，通过频率混合块将不同的频段重新组合为原始格式。广泛的实验结果表明，在多个现实世界时间序列数据集上，TimeKAN作为一个极其轻量级的架构实现了最先进的性能。源代码可在https://github.com/huangst21/TimeKAN获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world time series often have multiple frequency components that areintertwined with each other, making accurate time series forecastingchallenging. Decomposing the mixed frequency components into multiple singlefrequency components is a natural choice. However, the information density ofpatterns varies across different frequencies, and employing a uniform modelingapproach for different frequency components can lead to inaccuratecharacterization. To address this challenges, inspired by the flexibility ofthe recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based FrequencyDecomposition Learning architecture (TimeKAN) to address the complexforecasting challenges caused by multiple frequency mixtures. Specifically,TimeKAN mainly consists of three components: Cascaded Frequency Decomposition(CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks andFrequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach toobtain series representations for each frequency band. Benefiting from the highflexibility of KAN, we design a novel M-KAN block to learn and representspecific temporal patterns within each frequency band. Finally, FrequencyMixing blocks is used to recombine the frequency bands into the originalformat. Extensive experimental results across multiple real-world time seriesdatasets demonstrate that TimeKAN achieves state-of-the-art performance as anextremely lightweight architecture. Code is available athttps://github.com/huangst21/TimeKAN.</description>
      <author>example@mail.com (Songtao Huang, Zhen Zhao, Can Li, Lei Bai)</author>
      <guid isPermaLink="false">2502.06910v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06101v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf'25 (WWW'25) as a Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;大语言模型（LLMs）已应用于推荐系统以提高对用户行为的理解。检索增强生成（RAG）技术被进一步整合到这些系统中，以获取更相关项目并提升系统性能。&lt;h4&gt;背景&lt;/h4&gt;现有的RAG方法主要依赖于文本语义，并且通常未能整合最相关的项目，这限制了系统的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的推荐系统方法——用于检索增强的大语言模型推荐（RALLRec）。&lt;h4&gt;方法&lt;/h4&gt;通过提示大语言模型生成更详细的项目描述来增强文本语义；采用联合表示学习技术将提取的文本和协同语义结合起来。考虑到用户兴趣可能随时间变化，引入了一种简单的重新排序方法以捕捉用户偏好的动态性。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界的数据集上进行了广泛的实验，并且评估结果验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;代码已公开发布于https://github.com/JianXu95/RALLRec。&lt;h4&gt;翻译&lt;/h4&gt;大语言模型（LLMs）已经被融入到推荐系统中，以增强对用户行为的理解。检索增强生成（RAG）技术被进一步纳入这些系统，以便获取更相关的项目并提高系统的性能。然而，现有的RAG方法主要依赖于文本语义，并且常常无法整合最相关的内容，从而限制了系统的效果。在这篇论文中，我们提出了用于检索增强的大语言模型推荐的表示学习（RALLRec）。具体来说，通过提示大语言模型生成更详细的项目描述来增强文本语义；接着进行文本和协同语义的联合表示学习，这些分别由大语言模型和推荐模型提取。考虑到用户兴趣可能随时间变化的特点，我们还引入了一种简单但有效的重新排序方法以捕捉用户偏好的动态性。我们在三个真实数据集上进行了广泛的实验，并且评估结果验证了该方法的有效性。代码已公开发布于https://github.com/JianXu95/RALLRec。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been integrated into recommendation systemsto enhance user behavior comprehension. The Retrieval Augmented Generation(RAG) technique is further incorporated into these systems to retrieve morerelevant items and improve system performance. However, existing RAG methodsrely primarily on textual semantics and often fail to incorporate the mostrelevant items, limiting the effectiveness of the systems.  In this paper, we propose Representation learning for retrieval-AugmentedLarge Language model Recommendation (RALLRec). Specifically, we enhance textualsemantics by prompting LLMs to generate more detailed item descriptions,followed by joint representation learning of textual and collaborativesemantics, which are extracted by the LLM and recommendation models,respectively. Considering the potential time-varying characteristics of userinterest, a simple yet effective reranking method is further introduced tocapture the dynamics of user preference. We conducted extensive experiments onthree real-world datasets, and the evaluation results validated theeffectiveness of our method. Code is made public athttps://github.com/JianXu95/RALLRec.</description>
      <author>example@mail.com (Jian Xu, Sichun Luo, Xiangyu Chen, Haoming Huang, Hanxu Hou, Linqi Song)</author>
      <guid isPermaLink="false">2502.06101v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Topological derivative approach for deep neural network architecture adaptation</title>
      <link>http://arxiv.org/abs/2502.06885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新颖的算法，用于在网络深度增加的过程中逐步调整神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;在进行神经网络训练时，如何有效地添加新的层次（容量）以及初始化这些新层次是一个重要的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过数学原理解决两个关键问题：何时、何地增加新层及如何初始化新增加的层次。&lt;h4&gt;方法&lt;/h4&gt;引入了'形状泛函'概念，并定义了相对于神经网络拓扑结构的形变导数。从最优控制的角度出发，探讨在一定条件下网络拓扑导数的存在性及其封闭形式表达式。&lt;h4&gt;主要发现&lt;/h4&gt;首次探索了形变导数与最优控制理论中的哈密顿量之间的联系，将形状泛函优化问题转化为深度神经架构适应过程中的特征值问题。提出了一种基于最优传输观点的插入新层策略，即在$p$-Wasserstein空间中最大化形变导数值。&lt;h4&gt;结论&lt;/h4&gt;通过全连接网络、卷积神经网络和视觉变换器在不同回归与分类任务上的实验表明，该方法可以超越基准网络及其他架构适应策略。此外还展示了拓扑导数在迁移学习等领域的其他应用。&lt;h4&gt;翻译&lt;/h4&gt;这项工作介绍了一种新颖的算法，用于在网络深度增加的过程中逐步调整神经网络结构。特别地，我们尝试以数学原理的方式解决以下问题：i) 在训练过程中何处添加新的容量（层）？ ii) 如何初始化新加入的能力？我们的方法的核心是两个关键成分：i) 引入'形状泛函'来最小化，并且它依赖于神经网络的拓扑结构，ii) 引入相对于神经网络拓扑结构的'形变导数'。从最优控制的角度出发，我们展示了在网络拓扑导数存在条件下的存在性及其封闭形式表达式被推导出来。特别地，首次探索了来自拓扑优化框架中的形变导数与最优控制理论中哈密顿量之间的联系。进一步的，展示出形状泛函的最佳条件导致深度神经架构适应过程中的特征值问题。因此该方法确定在训练期间沿深度需要插入新层的最敏感位置以及关联的新添加层次的参数初始化。还展示了我们的层次插入策略可以基于最优传输观点导出为$p$-Wasserstein空间中最大化形变导数值的解决方案。使用全连接网络、卷积神经网络和视觉变换器在各种回归与分类问题上的数值调查表明，所提出的方法可以超越基准网络及其他架构适应策略。此外还展示了拓扑导数在迁移学习等领域的其他应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a novel algorithm for progressively adapting neuralnetwork architecture along the depth. In particular, we attempt to address thefollowing questions in a mathematically principled way: i) Where to add a newcapacity (layer) during the training process? ii) How to initialize the newcapacity? At the heart of our approach are two key ingredients: i) theintroduction of a ``shape functional" to be minimized, which depends on neuralnetwork topology, and ii) the introduction of a topological derivative of theshape functional with respect to the neural network topology. Using an optimalcontrol viewpoint, we show that the network topological derivative exists undercertain conditions, and its closed-form expression is derived. In particular,we explore, for the first time, the connection between the topologicalderivative from a topology optimization framework with the Hamiltonian fromoptimal control theory. Further, we show that the optimality condition for theshape functional leads to an eigenvalue problem for deep neural architectureadaptation. Our approach thus determines the most sensitive location along thedepth where a new layer needs to be inserted during the training phase and theassociated parametric initialization for the newly added layer. We alsodemonstrate that our layer insertion strategy can be derived from an optimaltransport viewpoint as a solution to maximizing a topological derivative in$p$-Wasserstein space, where $p&gt;= 1$. Numerical investigations with fullyconnected network, convolutional neural network, and vision transformer onvarious regression and classification problems demonstrate that our proposedapproach can outperform an ad-hoc baseline network and other architectureadaptation strategies. Further, we also demonstrate other applications oftopological derivative in fields such as transfer learning.</description>
      <author>example@mail.com (C G Krishnanunni, Tan Bui-Thanh, Clint Dawson)</author>
      <guid isPermaLink="false">2502.06885v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Group Reasoning Emission Estimation Networks</title>
      <link>http://arxiv.org/abs/2502.06874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种基于人工智能的碳排放核算框架——Group Reasoning Emission Estimation Networks (GREEN)，旨在解决中小企业在温室气体排放报告中的挑战。&lt;h4&gt;背景&lt;/h4&gt;准确的温室气体（GHG）排放报告对政府、企业和投资者至关重要，但由于高昂的成本和缺乏标准化的方法，特别是在中小型企业中，实施仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的碳核算框架——Group Reasoning Emission Estimation Networks (GREEN)，以解决中小企业在温室气体排放报告中的实际问题。&lt;h4&gt;方法&lt;/h4&gt;构建了一个基于人工智能的碳会计框架（GREEN），通过编译具有验证过的北美行业分类系统标签的企业文本描述，使用对比学习损失对Sentence-BERT模型进行微调，并引入一种新的分组推理方法来处理大量的层级类别。&lt;h4&gt;主要发现&lt;/h4&gt;在1,114个NAICS类别的实验中，该框架达到了最先进的性能（Top-1准确率为83.68%，Top-10准确率为91.47%），并且20家公司的案例研究显示平均绝对百分比误差为45.88%。&lt;h4&gt;结论&lt;/h4&gt;GREEN框架提供了一种有效的方法来提高企业级温室气体排放报告的准确性，并有助于推动中小企业的可持续发展。&lt;h4&gt;翻译&lt;/h4&gt;精确的温室气体（GHG）排放报告对于政府、企业和投资者来说至关重要。然而，由于高昂的成本和缺乏标准化方法等问题，在中小企业中实施仍然有限。本文提出一种基于人工智能的碳会计框架——Group Reasoning Emission Estimation Networks (GREEN)，通过标准的企业级排放估算、大规模基准数据集以及与大型语言模型（LLMs）结合的新推理方法来解决这些问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate greenhouse gas (GHG) emission reporting is critical for governments,businesses, and investors. However, adoption remains limited particularly amongsmall and medium enterprises due to high implementation costs, fragmentedemission factor databases, and a lack of robust sector classification methods.To address these challenges, we introduce Group Reasoning Emission EstimationNetworks (GREEN), an AI-driven carbon accounting framework that standardizesenterprise-level emission estimation, constructs a large-scale benchmarkdataset, and leverages a novel reasoning approach with large language models(LLMs). Specifically, we compile textual descriptions for 20,850 companies withvalidated North American Industry Classification System (NAICS) labels andalign these with an economic model of carbon intensity factors. By reframingsector classification as an information retrieval task, we fine-tuneSentence-BERT models using a contrastive learning loss. To overcome thelimitations of single-stage models in handling thousands of hierarchicalcategories, we propose a Group Reasoning method that ensembles LLM classifiersbased on the natural NAICS ontology, decomposing the task into multiplesub-classification steps. We theoretically prove that this approach reducesclassification uncertainty and computational complexity. Experiments on 1,114NAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47%Top-10 accuracy), and case studies on 20 companies report a mean absolutepercentage error (MAPE) of 45.88%. The project is available at:https://huggingface.co/datasets/Yvnminc/ExioNAICS.</description>
      <author>example@mail.com (Yanming Guo, Xiao Qian, Kevin Credit, Jin Ma)</author>
      <guid isPermaLink="false">2502.06874v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的框架TRACK，用于动态道路网络和轨迹表示学习，以改善城市交通管理。&lt;h4&gt;背景&lt;/h4&gt;有效的城市交通管理对可持续城市发展至关重要。当前方法通常关注静态道路网络的特性以及路线表示的学习，忽略了交通状态和轨迹的动态性，这对下游任务来说是至关重要的。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架来填补传统方法忽视交通状态和轨迹动态性的空白。&lt;h4&gt;方法&lt;/h4&gt;{'TRACK框架': '利用图注意力网络（GAT）编码静态和空间道路分段特征，并引入基于变换器的模型进行路线表示学习。通过将转移概率从路线数据中纳入到GAT注意权重，捕捉道路分段的空间特性。同时设计了一个交通变换器编码器来从交通状态数据中捕捉道路分段的空间-时间动态。', '增强动态表示': '提出了一种共注意力转换器编码器和轨迹-交通状态匹配任务以进一步增强动态表示。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过在真实城市交通数据集上的大量实验，TRACK展示了其相对于最新基线的优越性，并且案例研究证实了其有效捕捉空间时间动态的能力。&lt;h4&gt;结论&lt;/h4&gt;TRACK框架为动态道路网络和轨迹表示学习提供了一种新的方法，能够更好地适应城市的实际需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective urban traffic management is vital for sustainable city development,relying on intelligent systems with machine learning tasks such as traffic flowprediction and travel time estimation. Traditional approaches usually focus onstatic road network and trajectory representation learning, and overlook thedynamic nature of traffic states and trajectories, which is crucial fordownstream tasks. To address this gap, we propose TRACK, a novel framework tobridge traffic state and trajectory data for dynamic road network andtrajectory representation learning. TRACK leverages graph attention networks(GAT) to encode static and spatial road segment features, and introduces atransformer-based model for trajectory representation learning. Byincorporating transition probabilities from trajectory data into GAT attentionweights, TRACK captures dynamic spatial features of road segments. Meanwhile,TRACK designs a traffic transformer encoder to capture the spatial-temporaldynamics of road segments from traffic state data. To further enhance dynamicrepresentations, TRACK proposes a co-attentional transformer encoder and atrajectory-traffic state matching task. Extensive experiments on real-lifeurban traffic datasets demonstrate the superiority of TRACK overstate-of-the-art baselines. Case studies confirm TRACK's ability to capturespatial-temporal dynamics effectively.</description>
      <author>example@mail.com (Chengkai Han, Jingyuan Wang, Yongyao Wang, Xie Yu, Hao Lin, Chao Li, Junjie Wu)</author>
      <guid isPermaLink="false">2502.06870v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation</title>
      <link>http://arxiv.org/abs/2502.06848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的预训练和迁移学习框架用于图网络物理模拟器，通过引入可扩展的图U-Net（SGUNET）模型，并结合自定义映射函数以及额外规范化项来实现不同配置下的模型参数对齐。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于图神经网络（GNN）的方法在复杂系统物理建模中取得了显著成效。然而，这些方法通常需要大量由传统物理模拟器生成的数据进行完全监督训练。&lt;h4&gt;目的&lt;/h4&gt;探讨迁移学习如何改善模型性能和训练效率，并提出一种适用于不同网格大小和分辨率的可扩展图U-Net（SGUNET）模型及其预训练策略。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了适应多种规模与细节需求的SGUNET架构，包含创新性的深度优先搜索（DFS）池化技术。           2. 设计了一套映射函数来实现不同配置下的模型参数对齐，并在损失中加入额外规范化项以约束预训练权重和目标模型间差异。           3. 利用大型物理模拟数据集，包含来自开源A Big CAD (ABC)数据库的20,000个随机选择三维物体的物理仿真。&lt;h4&gt;主要发现&lt;/h4&gt;提出的迁移学习方法使SGUNET在仅使用少量标记训练数据的情况下也能显著优于从头开始训练的方法。具体地，在二维变形板基准测试中，使用1/16的数据进行微调后，模型的位置均方根误差（RMSE）相较于完整数据集的模型提高了11.05％。&lt;h4&gt;结论&lt;/h4&gt;通过引入预训练和迁移学习技术到图网络物理模拟器框架中，可以显著提高模型性能并减少所需训练数据量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Graph Neural Network (GNN) based models have shown promisingresults in simulating physics of complex systems. However, training dedicatedgraph network based physics simulators can be costly, as most models areconfined to fully supervised training, which requires extensive data generatedfrom traditional physics simulators. To date, how transfer learning couldimprove the model performance and training efficiency has remained unexplored.In this work, we introduce a pre-training and transfer learning paradigm forgraph network simulators. We propose the scalable graph U-net (SGUNET).Incorporating an innovative depth-first search (DFS) pooling, the SGUNET isadaptable to different mesh sizes and resolutions for various simulation tasks.To enable the transfer learning between differently configured SGUNETs, wepropose a set of mapping functions to align the parameters between thepre-trained model and the target model. An extra normalization term is alsoadded into the loss to constrain the difference between the pre-trained weightsand target model weights for better generalization performance. To pre-trainour physics simulator we created a dataset which includes 20,000 physicalsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)dataset. We show that our proposed transfer learning methods allow the model toperform even better when fine-tuned with small amounts of training data thanwhen it is trained from scratch with full extensive dataset. On the 2DDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 ofthe training data achieved an 11.05\% improvement in position RMSE compared tothe model trained from scratch.</description>
      <author>example@mail.com (Siqi Shen, Yu Liu, Daniel Biggs, Omar Hafez, Jiandong Yu, Wentao Zhang, Bin Cui, Jiulong Shan)</author>
      <guid isPermaLink="false">2502.06848v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters</title>
      <link>http://arxiv.org/abs/2502.06916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种受量子机器学习文献中哈明权重保持的量子电路启发的参数高效微调方法Quantum-Inspired Adapters，旨在解决大规模预训练模型在特定任务上微调时由于计算和存储需求而带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;传统的全参数更新方法在处理大规模预训练语言和视觉模型时因计算和存储需求问题变得日益困难。为此，参数高效微调（PEFT）方法通过仅对一小部分模型参数进行更新来解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种受量子机器学习中哈明权重保持的量子电路启发的新PEFT方法Quantum-Inspired Adapters，并在基准数据集上验证其效果和效率。&lt;h4&gt;方法&lt;/h4&gt;利用量子机学习文献中的哈明权保存量子电路原理，开发了一种新的微调方法Quantum-Inspired Adapters。该方法允许模型同时操作在组合空间中运行并保持权重参数的正交性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有的LoRA等其他微调方法相比，在语言理解和视觉任务上，所提出的Quantum-Inspired Adapters可以达到98%以上的性能，同时实现44倍和25倍的参数压缩。通过消融研究确定了结合多个哈明权重顺序、正交性以及矩阵组合对于高效微调至关重要。&lt;h4&gt;结论&lt;/h4&gt;研究表明，Quantum-Inspired Adapters为语言和视觉模型在资源受限环境中的有效适应提供了一种有前景的方向，并且该方法同时提供了与现有最佳性能相当的精度，但参数更少。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large foundation models for specific tasks has becomeincreasingly challenging due to the computational and storage demandsassociated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT)methods address this issue by updating only a small subset of model parametersusing adapter modules. In this work, we propose \emph{Quantum-InspiredAdapters}, a PEFT approach inspired by Hamming-weight preserving quantumcircuits from quantum machine learning literature. These models can be bothexpressive and parameter-efficient by operating in a combinatorially largespace while simultaneously preserving orthogonality in weight parameters. Wetest our proposed adapters by adapting large language models and large visiontransformers on benchmark datasets. Our method can achieve 99.2\% of theperformance of existing fine-tuning methods such LoRA with a 44x parametercompression on language understanding datasets like GLUE and VTAB. Compared toexisting orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\%relative performance with 25x fewer parameters. This demonstrates competitiveperformance paired with a significant reduction in trainable parameters.Through ablation studies, we determine that combining multiple Hamming-weightorders with orthogonality and matrix compounding are essential for performantfine-tuning. Our findings suggest that Quantum-Inspired Adapters offer apromising direction for efficient adaptation of language and vision models inresource-constrained environments.</description>
      <author>example@mail.com (Snehal Raj, Brian Coyle)</author>
      <guid isPermaLink="false">2502.06916v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Anomaly Detection: Vision and Challenges</title>
      <link>http://arxiv.org/abs/2502.06911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;论文综述了基于基础模型（FMs）的异常检测领域的最新进展，提出了一个新颖的分类体系，并系统分析了当前最佳实践和面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;在金融、制造、医疗等各个领域中，数据量和复杂性持续增长。有效的异常检测对于识别可能预示着关键问题的不规则模式至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出首个基于基础模型（FMs）进行异常检测的研究综述，分析先进方法并探讨未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;将基础模型分类为编码器、检测器或解释器三类，并对这些角色进行了系统的状态评估和挑战讨论。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在增强异常识别能力、生成详细数据描述及提供可视化解释方面显示出了前所未有的潜力。&lt;h4&gt;结论&lt;/h4&gt;概述了利用基础模型进行改进异常检测的关键挑战以及未来研究方向，特别是在快速发展的该领域中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As data continues to grow in volume and complexity across domains such asfinance, manufacturing, and healthcare, effective anomaly detection isessential for identifying irregular patterns that may signal critical issues.Recently, foundation models (FMs) have emerged as a powerful tool for advancinganomaly detection. They have demonstrated unprecedented capabilities inenhancing anomaly identification, generating detailed data descriptions, andproviding visual explanations. This survey presents the first comprehensivereview of recent advancements in FM-based anomaly detection. We propose a noveltaxonomy that classifies FMs into three categories based on their roles inanomaly detection tasks, i.e., as encoders, detectors, or interpreters. Weprovide a systematic analysis of state-of-the-art methods and discuss keychallenges in leveraging FMs for improved anomaly detection. We also outlinefuture research directions in this rapidly evolving field.</description>
      <author>example@mail.com (Jing Ren, Tao Tang, Hong Jia, Haytham Fayek, Xiaodong Li, Suyu Ma, Xiwei Xu, Feng Xia)</author>
      <guid isPermaLink="false">2502.06911v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming</title>
      <link>http://arxiv.org/abs/2502.07772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LLM-GP-BT技术，利用大型语言模型和遗传编程自动化生成和配置行为树（BT），以提高机器人任务规划的准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;精确的任务规划对自主系统的控制至关重要。行为树框架因其模块化、灵活性和可重用性在任务规划中被广泛认为是最重要的控制策略定义框架之一，但基于BT的控制政策生成仍然具有挑战性，需要领域专业知识。&lt;h4&gt;目的&lt;/h4&gt;通过利用大型语言模型（LLM）和遗传编程（GP），自动地将机器人任务命令从人类自然语言转换为准确可靠的基于行为树的任务计划。&lt;h4&gt;方法&lt;/h4&gt;提出了LLM-GP-BT技术，该技术处理用自然语言表达的机器人任务指令，并以计算高效且用户友好的方式将其转化为基于行为树的任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟实验系统地开发和验证了提出的LLM-GP-BT技术，证明其在简化自主系统的任务规划方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;LLM-GP-BT技术为自动化生成准确的基于行为树的任务计划提供了可能，这将有助于减少对领域专业知识的需求，并提高机器人等自治系统任务规划的效率和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;准确的任务规划对于控制诸如机器人、无人机和自动驾驶车辆之类的自主系统至关重要。行为树（BT）因其模块化、灵活性和可重用性而被视为任务规划中最突出的控制策略定义框架之一。然而，生成可靠的基于BT的控制政策仍然具有挑战性，并通常需要领域专业知识。在本文中，我们提出了一种LLM-GP-BT技术，该技术利用大型语言模型（LLM）和遗传编程（GP）来自动化生成和配置行为树。LLM-GP-BT技术处理用人类自然语言表达的机器人任务命令，并以计算高效且用户友好的方式将其转化为准确可靠的基于行为树的任务计划。所提出的这项技术通过模拟实验系统地开发并验证，展示了其在简化自主系统的任务规划方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate task planning is critical for controlling autonomous systems, suchas robots, drones, and self-driving vehicles. Behavior Trees (BTs) areconsidered one of the most prominent control-policy-defining frameworks in taskplanning, due to their modularity, flexibility, and reusability. Generatingreliable and accurate BT-based control policies for robotic systems remainschallenging and often requires domain expertise. In this paper, we present theLLM-GP-BT technique that leverages the Large Language Model (LLM) and GeneticProgramming (GP) to automate the generation and configuration of BTs. TheLLM-GP-BT technique processes robot task commands expressed in human naturallanguage and converts them into accurate and reliable BT-based task plans in acomputationally efficient and user-friendly manner. The proposed technique issystematically developed and validated through simulation experiments,demonstrating its potential to streamline task planning for autonomous systems.</description>
      <author>example@mail.com (Azizjon Kobilov, Jianglin Lan)</author>
      <guid isPermaLink="false">2502.07772v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove</title>
      <link>http://arxiv.org/abs/2502.07730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了一种名为DOGlove的低成本、精密且具有触觉力反馈的手套系统，旨在改进远程操作和机器人抓取任务。该系统可以快速组装并在经济实惠的价格范围内提供精确的动作捕捉和多方向的力反馈。&lt;h4&gt;背景&lt;/h4&gt;灵巧手遥操作系统在实现机器人的人类级别抓握技巧方面发挥着关键作用，但当前系统往往依赖昂贵设备且缺乏多模态感官反馈，限制了操作员感知物体特性和执行复杂任务的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种低成本、精确且具有触觉力反馈的远程手套系统，以改进现有的遥操作系统并提高操作灵活性和精度。&lt;h4&gt;方法&lt;/h4&gt;DOGlove采用定制化的关节结构实现21自由度动作捕捉，使用紧凑型缆绳驱动扭矩传输机制提供5自由度多方向力反馈，并利用线性共振执行器为指尖触觉反馈提供支持。此外还探讨了无视觉反馈情况下的操作性能和模仿学习策略训练。&lt;h4&gt;主要发现&lt;/h4&gt;DOGlove系统能够实现精确且沉浸式的灵巧手远程操作，成功完成复杂、接触密集的任务。研究显示在缺乏视觉反馈的情况下触觉力反馈对任务表现至关重要。&lt;h4&gt;结论&lt;/h4&gt;通过开源硬件和软件系统，DOGlove展示了其潜力和有效性，在改进人类与机器人交互的方式方面具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;灵巧手遥操作对于实现机器人的高级抓握技巧至关重要。然而，现有的远程操作系统往往依赖于昂贵的设备，并且缺乏多模态感官反馈，限制了人类操作员感知物体属性并执行复杂任务的能力。为了克服这些局限性，我们提出了一种名为DOGlove的手套系统，这是一种低成本、精确且具备触觉力反馈的解决方案，适用于遥操作和抓取应用。该手套可在数小时内组装完成，并且成本低于600美元。它具有21自由度动作捕捉所需的定制关节结构，使用紧凑型缆绳驱动扭矩传输机制实现5自由度多方向力反馈，并通过线性共振执行器提供指尖的5自由度触觉反馈。利用行动和力反馈重定向技术，DOGlove实现了灵巧机器人手精确且沉浸式的远程操作，在复杂、接触密集的任务中取得了高成功率。我们进一步在无视觉反馈的情况下评估了DOGlove的表现，展示了触觉力反馈对任务性能的关键作用。此外，我们还收集演示以训练模仿学习策略，突显了DOGlove的潜力和效果。DOGlove的硬件与软件系统将在https://do-glove.github.io/上完全开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous hand teleoperation plays a pivotal role in enabling robots toachieve human-level manipulation dexterity. However, current teleoperationsystems often rely on expensive equipment and lack multi-modal sensoryfeedback, restricting human operators' ability to perceive object propertiesand perform complex manipulation tasks. To address these limitations, wepresent DOGlove, a low-cost, precise, and haptic force feedback glove systemfor teleoperation and manipulation. DoGlove can be assembled in hours at a costunder 600 USD. It features a customized joint structure for 21-DoF motioncapture, a compact cable-driven torque transmission mechanism for 5-DoFmultidirectional force feedback, and a linear resonate actuator for 5-DoFfingertip haptic feedback. Leveraging action and haptic force retargeting,DOGlove enables precise and immersive teleoperation of dexterous robotic hands,achieving high success rates in complex, contact-rich tasks. We furtherevaluate DOGlove in scenarios without visual feedback, demonstrating thecritical role of haptic force feedback in task performance. In addition, weutilize the collected demonstrations to train imitation learning policies,highlighting the potential and effectiveness of DOGlove. DOGlove's hardware andsoftware system will be fully open-sourced at https://do-glove.github.io/.</description>
      <author>example@mail.com (Han Zhang, Songbo Hu, Zhecheng Yuan, Huazhe Xu)</author>
      <guid isPermaLink="false">2502.07730v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Ultrafast 4D scanning transmission electron microscopy for imaging of localized optical fields</title>
      <link>http://arxiv.org/abs/2502.07338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1: preprint; licence: CC BY 4.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的超快4D扫描透射电子显微镜技术，该技术能够在避免使用电子光谱过滤的情况下成像光学近场的横向分量。&lt;h4&gt;背景&lt;/h4&gt;超高频电子显微术的目标是成像纳米尺度上的瞬变现象，并可视化由相干激发在各种类型的纳米结构附近产生的局部光学和等离子体模式。这种成像能力是由基于通过非弹性散射的光谱筛选电子与近场相互作用所激发的光子诱导近场光学显微镜实现。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的超快4D扫描透射电子显微镜技术，该技术能够避免使用电子光谱筛选来成像光学近场的横向分量，并展示这种方法的能力。&lt;h4&gt;方法&lt;/h4&gt;采用新发展的超快4D扫描传输电子显微镜技术对钨纳米尖端和光学驻波的ponderomotive势进行成像。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够以21 nm的空间分辨率对钨纳米尖端和光学驻波的ponderomotive势的光学近场进行成像。&lt;h4&gt;结论&lt;/h4&gt;新开发的技术提供了一种新的方法，可以在不使用电子光谱筛选的情况下成像光学近场的横向分量，并展示了这种方法的实用性与高效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的英文原文内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultrafast electron microscopy aims for imaging transient phenomena occurringon nanoscale. One of its goals is to visualize localized optical and plasmonicmodes generated by coherent excitation in the vicinity of various types ofnanostructures. Such imaging capability was enabled by photon-inducednear-field optical microscopy, which is based on spectral filtering ofelectrons inelastically scattered due to the stimulated interaction with thenear-field. Here we report on the development of ultrafast 4D scanningtransmission electron microscopy, which allows us to image the transversecomponents of the optical near-field while avoiding the need of electronspectral filtering. We demonstrate that this method is capable of imagingoptical near-fields of a tungsten nanotip and ponderomotive potential of anoptical standing wave with a spatial resolution of 21 nm.</description>
      <author>example@mail.com (Petr Koutenský, Neli Laštovičková Streshkova, Kamila Moriová, Marius Constantin Chirita Mihaila, Daniel Burda, Alexandr Knápek, Martin Kozák)</author>
      <guid isPermaLink="false">2502.07338v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DeepVL: Dynamics and Inertial Measurements-based Deep Velocity Learning for Underwater Odometry</title>
      <link>http://arxiv.org/abs/2502.07726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the 2025 IEEE International Conference  on Robotics &amp; Automation (ICRA 2025), Atlanta, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种通过动力学感知本体感觉预测水下机器人中心速度的模型。该方法利用递归神经网络，以惯性线索、电机命令和电池电压读数以及前一时间步的隐藏状态作为输入，输出稳健的速度估计及其相关不确定性。&lt;h4&gt;背景&lt;/h4&gt;现有的水下导航技术通常依赖于外部感知来提供长期定位。然而，在视觉信息不可用的情况下，这些方法可能无法提供准确的位置估计。&lt;h4&gt;目的&lt;/h4&gt;开发一种通过结合内部传感器数据和神经网络预测速度的方法，以实现无需额外外部感知的长期水下载具定位。&lt;h4&gt;方法&lt;/h4&gt;利用递归神经网络模型处理惯性线索、电机命令和电池电压读数等信息，并融合网络输出到扩展卡尔曼滤波器中。该模型使用少量特征进行增强型视觉惯性里程估计，减少对完整视觉数据的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在完全没有视觉信息的情况下，所提出的方法仍能提供小于4%相对位置误差的定位精度；即使在单目相机仅跟踪最多2个视觉特征时，相对误差也保持在约2%左右。测试中模型的推断速度低于5ms。&lt;h4&gt;结论&lt;/h4&gt;通过利用动力学感知本体感觉预测技术，可以显著提升水下机器人的自主导航能力，在完全缺乏外部感知信息的情况下仍能实现高精度定位。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种学习型模型，用于通过动力学感知的本体感受来预测水下机器人以机器人为中心的速度。这种方法利用递归神经网络作为输入，使用惯性提示、电机命令和电池电压读数以及前一个时间步的隐藏状态输出稳健的速度估计及其相关不确定性。使用一组网络增强了速度和不确定性的预测能力。将网络输出与惯性预测和气压更新融合到扩展卡尔曼滤波器中，该方法允许在没有进一步外部感知的情况下实现长期水下载具里程计定位。此外，在集成视觉惯性里程计时，该方法有助于增强估计的鲁棒性，当跟踪的总特征数量（低至1个）比传统视觉惯性系统少一个数量级时。实验是在一台部署于实验室游泳池和特隆赫姆峡湾的水下机器人上进行的，模型在NVIDIA Orin AGX的CPU或GPU上的推理时间不到5ms，在完全黑视情况下新轨迹中的相对位置误差小于4%，当单目相机最多跟踪2个视觉特征时，相对误差约为2%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a learned model to predict the robot-centric velocity ofan underwater robot through dynamics-aware proprioception. The method exploitsa recurrent neural network using as inputs inertial cues, motor commands, andbattery voltage readings alongside the hidden state of the previous time-stepto output robust velocity estimates and their associated uncertainty. Anensemble of networks is utilized to enhance the velocity and uncertaintypredictions. Fusing the network's outputs into an Extended Kalman Filter,alongside inertial predictions and barometer updates, the method enableslong-term underwater odometry without further exteroception. Furthermore, whenintegrated into visual-inertial odometry, the method assists in enhancedestimation resilience when dealing with an order of magnitude fewer totalfeatures tracked (as few as 1) as compared to conventional visual-inertialsystems. Tested onboard an underwater robot deployed both in a laboratory pooland the Trondheim Fjord, the method takes less than 5ms for inference either onthe CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than 4% relativeposition error in novel trajectories during complete visual blackout, andapproximately 2% relative error when a maximum of 2 visual features from amonocular camera are available.</description>
      <author>example@mail.com (Mohit Singh, Kostas Alexis)</author>
      <guid isPermaLink="false">2502.07726v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning</title>
      <link>http://arxiv.org/abs/2502.07600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PlaySlot是一个用于预测未来场景表示的物体中心视频预测模型，它能够从无标注视频数据中推断出物体状态和潜在动作，并根据这些信息生成未来的可能情况。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数方法依赖于带有精确动作注释的视频序列或模拟环境来进行场景表示的预测。这种方式限制了对大量未标记视频数据的有效利用。&lt;h4&gt;目的&lt;/h4&gt;提出PlaySlot模型，以解决现有方法不能充分利用无标签视频数据的问题，并实现机器人对未来场景的理解和互动能力。&lt;h4&gt;方法&lt;/h4&gt;PlaySlot通过推断物体在无标注视频序列中的表示以及潜在动作来预测未来的物体状态和帧。它可以生成基于学习的行动策略、用户提供的或者从视频动态中推导出的多个可能的未来情况。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PlaySlot模型不仅能够超越传统随机和以对象为中心的基准线进行视频预测，在各种环境中也表现出色；同时，它的潜在动作可以用来高效地学习机器人行为，仅基于未标记的视频演示。&lt;h4&gt;结论&lt;/h4&gt;通过从无标注视频数据中推断出的物体表示与潜在动作，PlaySlot提供了一种灵活且可解释的方法来建模世界，并能有效提升机器人的交互性能。&lt;h4&gt;翻译&lt;/h4&gt;预测未来场景表示是使机器人能够理解和互动环境的关键任务。然而，现有的大多数方法依赖于带有精确动作注释的视频序列和模拟，这限制了它们利用大量可用无标签视频数据的能力。为了解决这一挑战，我们提出了PlaySlot模型，这是一种基于物体中心视角的视频预测模型，可以从无标注视频序列中推断出物体表示和潜在动作，并使用这些表示来预测未来物体状态和帧。PlaySlot可以生成多个基于学习策略、用户提供的或从视频动态中推测出的动作条件下的可能未来情况，从而实现灵活且可解释的世界建模。我们的实验结果表明，PlaySlot在视频预测方面超越了随机及以对象为中心的基准线，在不同环境中表现优异；此外，我们证明了可以使用推断出的潜在动作来有效学习机器人行为，仅基于无标签视频演示数据即可。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting future scene representations is a crucial task for enabling robotsto understand and interact with the environment. However, most existing methodsrely on video sequences and simulations with precise action annotations,limiting their ability to leverage the large amount of available unlabeledvideo data. To address this challenge, we propose PlaySlot, an object-centricvideo prediction model that infers object representations and latent actionsfrom unlabeled video sequences. It then uses these representations to forecastfuture object states and video frames. PlaySlot allows to generate multiplepossible futures conditioned on latent actions, which can be inferred fromvideo dynamics, provided by a user, or generated by a learned action policy,thus enabling versatile and interpretable world modeling. Our results show thatPlaySlot outperforms both stochastic and object-centric baselines for videoprediction across different environments. Furthermore, we show that ourinferred latent actions can be used to learn robot behaviors sample-efficientlyfrom unlabeled video demonstrations. Videos and code are available athttps://play-slot.github.io/PlaySlot/.</description>
      <author>example@mail.com (Angel Villar-Corrales, Sven Behnke)</author>
      <guid isPermaLink="false">2502.07600v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Coverage Control for Time-Varying Spatial Processes</title>
      <link>http://arxiv.org/abs/2502.07595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种分布式控制策略，该策略利用高斯过程建模空间场，并平衡学习空间场与优化覆盖之间的权衡。此方法适用于时间变化的空间领域。&lt;h4&gt;背景&lt;/h4&gt;多机器人系统在环境监测中起着关键作用，尤其是在跟踪污染、土壤矿物质和水盐度等空间现象方面。然而，在分布密度未知且随时间变化的环境中部署多机器人团队存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种有效的方法来应对上述挑战，特别是在时空变化的领域内实现最优覆盖的问题。&lt;h4&gt;方法&lt;/h4&gt;采用高斯过程建模技术，并结合分布式控制策略，每个机器人仅使用其自身收集的数据及邻居机器人的信息进行操作。同时利用算法高效处理数据量问题，只选择最相关的样本用于估计。&lt;h4&gt;主要发现&lt;/h4&gt;通过多种模拟和实验评估了所提算法的性能，这些实验包括实际现象，验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究提供了一种新颖的方法来解决时空变化环境下的多机器人覆盖优化问题。这种方法在时间和空间上都动态调整探索与利用之间的权衡，并且具有分布式特性和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多机器人系统对于环境监测至关重要，尤其是在跟踪污染、土壤矿物质和水盐度等空间现象方面更为重要。这项研究解决了在分布密度未知并且随时间变化的环境中部署多机器人团队以实现最优覆盖的问题。我们提出了一种完全分散的控制策略，利用高斯过程（GPs）来建模空间场，并平衡学习该领域与优化覆盖之间的权衡。不同于现有方法，我们在更具现实性的场景下处理时间变化的空间域，在此场景中探索与开发之间的折衷会随时间动态调整。每个机器人仅使用其自身收集的数据和邻近机器人的信息操作。为了应对高斯过程的计算限制，该算法通过选择最相关的样本进行流程估计来有效管理数据量。通过多个模拟和实验评估了所提议算法的表现，并结合实际世界现象数据证明了它的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TRO.2025.3539168&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot systems are essential for environmental monitoring, particularlyfor tracking spatial phenomena like pollution, soil minerals, and watersalinity, and more. This study addresses the challenge of deploying amulti-robot team for optimal coverage in environments where the densitydistribution, describing areas of interest, is unknown and changes over time.We propose a fully distributed control strategy that uses Gaussian Processes(GPs) to model the spatial field and balance the trade-off between learning thefield and optimally covering it. Unlike existing approaches, we address a morerealistic scenario by handling time-varying spatial fields, where theexploration-exploitation trade-off is dynamically adjusted over time. Eachrobot operates locally, using only its own collected data and the informationshared by the neighboring robots. To address the computational limits of GPs,the algorithm efficiently manages the volume of data by selecting only the mostrelevant samples for the process estimation. The performance of the proposedalgorithm is evaluated through several simulations and experiments,incorporating real-world data phenomena to validate its effectiveness.</description>
      <author>example@mail.com (Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini)</author>
      <guid isPermaLink="false">2502.07595v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Dual Arm Steering of Deformable Linear Objects in 2-D and 3-D Environments Using Euler's Elastica Solutions</title>
      <link>http://arxiv.org/abs/2502.07509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种使用两个机械手操纵变形线性物体的方法，特别是在存在稀疏障碍物的环境中。&lt;h4&gt;背景&lt;/h4&gt;在环境中有稀疏分布的障碍物时，需要一种方法来引导和控制柔性的、不可伸长的线性对象。现有技术可能不完全适用于这种场景。&lt;h4&gt;目的&lt;/h4&gt;开发一套理论框架和技术方案，确保使用两个机械手操纵柔性线性物体时能够避免自我碰撞，并保证稳定性和避开环境中的障碍物。&lt;h4&gt;方法&lt;/h4&gt;该论文采用闭合形式解来描述二维环境中可变形的线性对象形状（欧拉弹性曲线），并根据这些解决方案制定了非自交、稳定性及避障标准。所有安全准则被整合进一个方案中，用于引导柔性线性物体在二维和三维环境中的移动。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新颖的标准以确保柔韧物件的稳定性，并成功将该方法应用于双臂机械手实验验证。&lt;h4&gt;结论&lt;/h4&gt;通过理论推导和实际操作展示了这种方法的有效性和可行性。未来的研究可以探讨更复杂的障碍物环境及更加灵活的控制策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes a method for steering deformable linear objects usingtwo robot hands in environments populated by sparsely spaced obstacles. Theapproach involves manipulating an elastic inextensible rod by varying thegripping endpoint positions and tangents. Closed form solutions that describethe flexible linear object shape in planar environments, Euler's elastica, aredescribed. The paper uses these solutions to formulate criteria for nonself-intersection, stability and obstacle avoidance. These criteria areformulated as constraints in the flexible object six-dimensional configurationspace that represents the robot gripping endpoint positions and tangents. Inparticular, this paper introduces a novel criterion that ensures the flexibleobject stability during steering. All safety criteria are integrated into ascheme for steering flexible linear objects in planar environments, which islifted into a steering scheme in three-dimensional environments populated bysparsely spaced obstacles. Experiments with a dual-arm robot demonstrate themethod.</description>
      <author>example@mail.com (Aharon Levin, Itay Grinberg, Elon Rimon, Amir Shapiro)</author>
      <guid isPermaLink="false">2502.07509v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Blind Eye: Motion and Obstacle Detection Leveraging Wi-Fi</title>
      <link>http://arxiv.org/abs/2502.07493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Wi-Fi技术通过提供平滑的网络连接，彻底改变了无线网络环境。本文研究了设备与接入点之间的信号接收差异，并探索这些差异在特定应用场景中的潜在价值。&lt;h4&gt;背景&lt;/h4&gt;Wi-Fi利用无线电通讯，在接近接入点时可以有效工作。但设备接收到的Wi-Fi信号强度会因障碍物或移动而变化。&lt;h4&gt;目的&lt;/h4&gt;创造性地使用Wi-Fi信号差异来开发能够检测封闭区域内运动的应用程序。&lt;h4&gt;方法&lt;/h4&gt;研究当前无线基础设施，利用现有的Wi-Fi技术而不需额外硬件进行应用开发。&lt;h4&gt;主要发现&lt;/h4&gt;可以将这些信号强度的变化应用于改进安全系统或为复杂机器人提供支持。&lt;h4&gt;结论&lt;/h4&gt;通过挖掘现有Wi-Fi信号的不一致性，可以在无需增加新硬件的情况下实现新的功能和用途。&lt;h4&gt;翻译&lt;/h4&gt;无线保真技术（即Wi-Fi）已经彻底改变了无线网络环境，特别是在封闭空间内提供了平滑的互联网和网络连接。与大多数无线技术一样，它依赖于无线电通讯来工作。这意味着，设备靠近接入点时可以有效接收信号，但根据障碍物或移动的不同，这种接收效果会有较大差异。研究团队利用这些变化作为机会开发出用于检测封闭区域内运动的应用程序。该方法不需要额外的硬件支持，因为它仅使用现有的无线基础设施。此类应用可以在增强安全系统、提高机器人复杂性等方面发挥重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wireless Fidelity or Wi-Fi, has completely transfigured wireless networkingby offering a smooth connection to the internet and networks, particularly whendealing with enclosed environments. As with the majority of wirelesstechnology, it functions through radio communication. This makes it possiblefor Wi-Fi to operate effectively close to an Access Point. However, a device'sability to receive Wi-Fi signals can vary greatly. These discrepancies arisebecause of impediments or motions between the device and the access point. Wehave creatively used these variances as unique opportunities for applicationsthat can be used to detect movement in confined areas. As this approach makesuse of the current wireless infrastructure, no additional hardware is required.These applications could potentially be leveraged to enable sophisticatedrobots or enhance security systems.</description>
      <author>example@mail.com (Aditya Mitra, Anisha Ghosh, Sibi Chakkaravarthy S, Devi Priya VS)</author>
      <guid isPermaLink="false">2502.07493v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Robotic In-Hand Manipulation for Large-Range Precise Object Movement: The RGMC Champion Solution</title>
      <link>http://arxiv.org/abs/2502.07472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to RA-L. Project website:  https://rgmc-xl-team.github.io/ingrasp_manipulation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用手指运动在稳定抓握下实现高精度和大范围物体移动的方法，这种方法不依赖于预训练或物体几何信息，并且适用于真实场景中的新对象。&lt;h4&gt;背景&lt;/h4&gt;手内操作是一项关键的机器人技能，它可以通过多指灵巧操作减少对大型臂部动作的需求，从而节省空间和能量。在稳定抓握下进行物体移动是该领域的重点问题之一。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单实用的方法来解决手内对象运动中精度与范围同时实现的问题，并展示其在真实场景中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;采用基于动力学轨迹优化的方案，无需预训练或物体几何信息的支持。&lt;h4&gt;主要发现&lt;/h4&gt;通过参加ICRA 2024举办的第九届机器人抓取和操作竞赛（RGMC）的手内操作项目并获得冠军，验证了该方法的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;论文详细介绍了实施方案、讨论及进一步的实验结果，以全面评估提出的方法，并分享在比赛中取得的关键经验。补充材料包括视频和代码可从指定链接获取。&lt;h4&gt;翻译&lt;/h4&gt;手内操作利用多指灵巧性是减少对大型臂部动作依赖的一项关键机器人技能，可以节省空间和能量。本文重点在于抓握内的物体移动，即通过手指运动将物体调整到期望姿态，并且在稳定抓握状态下实现这一点。挑战在于同时达到高精度与大范围的动作的同时保持稳定的抓握状态。为解决这一问题，我们提出了一种简单实用的方法，基于动力学轨迹优化，无需预训练或物体几何信息的参与，易于应用于真实场景中的新对象。采用这种方法，在ICRA 2024举办的第九届机器人抓取和操作竞赛的手内操作项目中获得了冠军。论文详细介绍了实施方案、讨论及进一步的实验结果，以全面评估提出的方法，并分享在比赛中取得的关键经验。补充材料包括视频和代码可从https://rgmc-xl-team.github.io/ingrasp_manipulation获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-hand manipulation using multiple dexterous fingers is a critical roboticskill that can reduce the reliance on large arm motions, thereby saving spaceand energy. This letter focuses on in-grasp object movement, which refers tomanipulating an object to a desired pose through only finger motions within astable grasp. The key challenge lies in simultaneously achieving high precisionand large-range movements while maintaining a constant stable grasp. To addressthis problem, we propose a simple and practical approach based on kinematictrajectory optimization with no need for pretraining or object geometries,which can be easily applied to novel objects in real-world scenarios. Adoptingthis approach, we won the championship for the in-hand manipulation track atthe 9th Robotic Grasping and Manipulation Competition (RGMC) held at ICRA 2024.Implementation details, discussion, and further quantitative experimentalresults are presented in this letter, which aims to comprehensively evaluateour approach and share our key takeaways from the competition. Supplementarymaterials including video and code are available athttps://rgmc-xl-team.github.io/ingrasp_manipulation .</description>
      <author>example@mail.com (Mingrui Yu, Yongpeng Jiang, Chen Chen, Yongyi Jia, Xiang Li)</author>
      <guid isPermaLink="false">2502.07472v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Demonstrating Wheeled Lab: Modern Sim2Real for Low-cost, Open-source Wheeled Robotics</title>
      <link>http://arxiv.org/abs/2502.07380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Wheeled Lab是一个低成本、开源的轮式机器人平台框架，旨在促进先进仿真到现实技术的应用。&lt;h4&gt;背景&lt;/h4&gt;近年来机器人领域的重大进展依赖于昂贵和高维护成本的平台，限制了更广泛的受众接触这些先进技术的机会。&lt;h4&gt;目的&lt;/h4&gt;介绍一个名为Wheeled Lab的框架，该框架使用低成本、开源轮式平台，并结合Isaac Lab进行Sim2Real技术的应用。&lt;h4&gt;方法&lt;/h4&gt;通过集成现代Sim2Real技术（如领域随机化、传感器仿真和端到端学习）进入新的用户社区。为启动教育并展示框架的能力，开发了三项针对小型遥控车的先进策略：控制漂移、攀爬斜坡和视觉导航。&lt;h4&gt;主要发现&lt;/h4&gt;Wheeled Lab通过整合先进的Sim2Real技术和低成本、易获取的机器人平台，缩小了技术差距，并促进了更广泛范围内的创新与教育。&lt;h4&gt;结论&lt;/h4&gt;该框架从硬件到软件都是低价格且开源，致力于使先进工具更加普及，促进更大范围内机器人的创新和教育。&lt;h4&gt;翻译&lt;/h4&gt;仿真在最近的机器人里程碑中至关重要，并将在未来领域发挥重要作用。然而，最新的机器人进展往往依赖于昂贵、维护成本高的平台，这限制了更广泛受众接触这些技术的机会。本工作介绍了Wheeled Lab框架，这是一个面向低成本、开源轮式平台（这些平台已经在教育和研究中广泛应用）的框架。通过与Isaac Lab集成，Wheeled Lab引入了现代Sim2Real技术，如领域随机化、传感器仿真及端到端学习，为新的用户社区提供服务。为了启动教育并展示框架的能力，我们为小型遥控车开发了三种最先进的策略：控制漂移、攀爬斜坡和视觉导航，这些策略在仿真中训练并在现实世界部署。通过结合先进的Sim2Real技术和低成本可获取的机器人平台，Wheeled Lab旨在普及先进工具，并促进更广泛范围内的创新与教育。从硬件到软件的整体架构都是低价格且开源的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation has been pivotal in recent robotics milestones and is poised toplay a prominent role in the field's future. However, recent robotic advancesoften rely on expensive and high-maintenance platforms, limiting access tobroader robotics audiences. This work introduces Wheeled Lab, a framework forthe low-cost, open-source wheeled platforms that are already widely establishedin education and research. Through integration with Isaac Lab, Wheeled Labintroduces modern techniques in Sim2Real, such as domain randomization, sensorsimulation, and end-to-end learning, to new user communities. To kickstarteducation and demonstrate the framework's capabilities, we develop threestate-of-the-art policies for small-scale RC cars: controlled drifting,elevation traversal, and visual navigation, each trained in simulation anddeployed in the real world. By bridging the gap between advanced Sim2Realmethods and affordable, available robotics, Wheeled Lab aims to democratizeaccess to cutting-edge tools, fostering innovation and education in a broaderrobotics context. The full stack, from hardware to software, is low cost andopen-source.</description>
      <author>example@mail.com (Tyler Han, Preet Shah, Sidharth Rajagopal, Yanda Bao, Sanghun Jung, Sidharth Talia, Gabriel Guo, Bryan Xu, Bhaumik Mehta, Emma Romig, Rosario Scalise, Byron Boots)</author>
      <guid isPermaLink="false">2502.07380v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>SymbioSim: Human-in-the-loop Simulation Platform for Bidirectional Continuing Learning in Human-Robot Interaction</title>
      <link>http://arxiv.org/abs/2502.07358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为SymbioSim的新平台，旨在促进人类与机器人之间安全、高效且自然的互动学习。&lt;h4&gt;背景&lt;/h4&gt;智能机器人的发展目标是实现人机共生。然而，在真实环境中直接训练和测试算法成本高且有风险，并且现有的机器人模拟器无法支持真人参与，影响了实际交互体验和获取有价值的反馈。&lt;h4&gt;目的&lt;/h4&gt;开发SymbioSim平台以解决现有问题，促进人类与机器人之间的持续互动、学习和适应。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含细致架构和模块的系统，提供自然且现实的人机交互体验，支持双向的学习和优化过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验和用户研究证明了SymbioSim平台的有效性，并展示了它在促进人类与机器人共生领域的潜在重大贡献。&lt;h4&gt;结论&lt;/h4&gt;SymbioSim为研发人员提供了一种创新工具，以实现人机协作的自然交互，从而推动相关研究的进步。&lt;h4&gt;翻译&lt;/h4&gt;智能机器人的开发目标是无缝地将其融入到人类世界中，在日常生活中提供帮助和陪伴。要实现这一愿景，机器人必须通过与人类持续互动和合作来不断学习和发展，而人类则需要逐步建立对机器人的理解和信任。然而，直接在物理机器人上进行训练和测试涉及高额成本及安全风险；此外，现有的机器人模拟器无法支持真人参与，限制了它们提供真实交互体验和收集有价值的用户反馈的能力。本文介绍了一种新的“SymbioSim”人机共融式仿真平台，旨在使人类与机器人的互动发展、评估和优化变得既安全又高效，并通过精心设计的系统架构和模块提供了自然且真实的互动体验，促进了双向持续学习及适应过程。广泛的实验和用户研究展示了该平台的优异性能及其在推动人机共生领域的潜在重大贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of intelligent robots seeks to seamlessly integrate them intothe human world, providing assistance and companionship in daily life and work,with the ultimate goal of achieving human-robot symbiosis. To realize thisvision, robots must continuously learn and evolve through consistentinteraction and collaboration with humans, while humans need to graduallydevelop an understanding of and trust in robots through shared experiences.However, training and testing algorithms directly on physical robots involvesubstantial costs and safety risks. Moreover, current robotic simulators failto support real human participation, limiting their ability to provideauthentic interaction experiences and gather valuable human feedback. In thispaper, we introduce SymbioSim, a novel human-in-the-loop robotic simulationplatform designed to enable the safe and efficient development, evaluation, andoptimization of human-robot interactions. By leveraging a carefully designedsystem architecture and modules, SymbioSim delivers a natural and realisticinteraction experience, facilitating bidirectional continuous learning andadaptation for both humans and robots. Extensive experiments and user studiesdemonstrate the platform's promising performance and highlight its potential tosignificantly advance research on human-robot symbiosis.</description>
      <author>example@mail.com (Haoran Chen, Yiteng Xu, Yiming Ren, Yaoqin Ye, Xinran Li, Ning Ding, Peishan Cong, Ziyi Wang, Bushi Liu, Yuhan Chen, Zhiyang Dou, Xiaokun Leng, Manyi Li, Yuexin Ma, Changhe Tu)</author>
      <guid isPermaLink="false">2502.07358v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>The Combined Problem of Online Task Assignment and Lifelong Path Finding in Logistics Warehouses: A Case Study</title>
      <link>http://arxiv.org/abs/2502.07332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在线任务分配和终身路径规划的结合问题，这对物流行业至关重要。&lt;h4&gt;背景&lt;/h4&gt;现有文献大多数集中于假设给定任务分配器的情况下的终生路径规划或已知所有任务的离线版本的问题。&lt;h4&gt;目的&lt;/h4&gt;为了最大化系统的吞吐量，直接解决将这两者集成在一起的在线版本问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个正式框架和解决方案概念，并设计了一个基于规则的终身计划程序，在实践中即使在存在严重局部拥堵的情况下也能很好地工作。随后自动化搜索任务分配器与底层路径规划器的关系。&lt;h4&gt;主要发现&lt;/h4&gt;(1) 在时间效率方面，系统只需要目前美团使用的执行时间的83.77%，优于其他最先进的算法8.09%；(2) 经济效率上，可以使用当前仅60%的代理实现相同的吞吐量。&lt;h4&gt;结论&lt;/h4&gt;该方法在实际应用中展示了高效的时间和经济效益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the combined problem of online task assignment and lifelong pathfinding, which is crucial for the logistics industries. However, mostliterature either (1) focuses on lifelong path finding assuming a given taskassigner, or (2) studies the offline version of this problem where tasks areknown in advance. We argue that, to maximize the system throughput, the onlineversion that integrates these two components should be tackled directly. Tothis end, we introduce a formal framework of the combined problem and itssolution concept. Then, we design a rule-based lifelong planner under apractical robot model that works well even in environments with severe localcongestion. Upon that, we automate the search for the task assigner withrespect to the underlying path planner. Simulation experiments conducted inwarehouse scenarios at \textit{Meituan}, one of the largest shopping platformsin China, demonstrate that (a)~\textit{in terms of time efficiency}, our systemrequires only 83.77\% of the execution time needed for the currently deployedsystem at Meituan, outperforming other SOTA algorithms by 8.09\%;(b)~\textit{in terms of economic efficiency}, ours can achieve the samethroughput with only 60\% of the agents currently in use.</description>
      <author>example@mail.com (Fengming Zhu, Fangzhen Lin, Weijia Xu, Yifei Guo)</author>
      <guid isPermaLink="false">2502.07332v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.07306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种模块化的方法来解决视觉-语言导航（VLN）任务，通过将问题分解为四个子模块，并在零样本设置中使用最先进的大语言模型和视觉-语言模型。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言导航(VLN)任务需要结合自然语言指令、环境感知以及路径规划能力。现有的方法大多依赖于联合语义地图进行导航性能的评估。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的模块化框架来提高VLN任务的表现，特别是在复杂的R2R-Habitat数据集上，并详细量化视觉定位对导航表现的影响。&lt;h4&gt;方法&lt;/h4&gt;1. 使用大语言模型(Large Language Models, LLMs)从自然语言指令中提取地标及其访问顺序；2. 假设已知环境模型，使用最短路径算法在环境的拓扑地图上生成从起始地点到最后一个地标的k条路径假设；3. 采用动态规划计算路径序列与地标名称序列之间的对齐得分，并通过视觉语言模型(Vision-Language Models, VLMs)获取匹配分数；4. 计算最高对齐得分的假设路径的nDTW度量，以评估路径准确性。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在复杂R2R-Habitat指令数据集上展示出优于使用联合语义地图(如VLMaps)的方法的表现，并详细量化了视觉定位对导航性能的影响。&lt;h4&gt;结论&lt;/h4&gt;提出的模块化方法为解决视觉-语言导航问题提供了一种有效途径，特别是在零样本设置中利用先进的大语言模型和视觉语言模型进行自然语言指令的处理。该研究还强调了视觉定位在提高导航精度方面的重要性。&lt;h4&gt;翻译&lt;/h4&gt;在此工作中，我们提出了一种通过将任务分解成四个子模块来解决视觉-语言导航（VLN）问题的方法，在零样本设置中使用最先进的大型语言模型和视觉-语言模型。给定自然语言的导航指令后，我们首先提示大型语言模型提取地标以及它们访问的顺序。假设已知环境模型，我们检索出最接近最后地标的k个位置，并从起始地点到最后一个地标生成k条路径假说，使用环境中拓扑地图上的最短路径算法进行生成。每个路径假说由一系列全景图表示。然后，我们利用动态规划计算序列间对齐得分，即将这些序列中的全景图与地标名称序列匹配的分数通过视觉-语言模型获取。最后，我们将最高对齐得分支对应的假设求nDTW度量来评估路径的一致性。我们在复杂的R2R-Habitat指令数据集上展示出优于使用联合语义地图（如VLMaps）的方法的表现，并详细量化了视觉定位对导航性能的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a modular approach for the Vision-LanguageNavigation (VLN) task by decomposing the problem into four sub-modules that usestate-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)in a zero-shot setting. Given navigation instruction in natural language, wefirst prompt LLM to extract the landmarks and the order in which they arevisited. Assuming the known model of the environment, we retrieve the top-klocations of the last landmark and generate $k$ path hypotheses from thestarting location to the last landmark using the shortest path algorithm on thetopological map of the environment. Each path hypothesis is represented by asequence of panoramas. We then use dynamic programming to compute the alignmentscore between the sequence of panoramas and the sequence of landmark names,which match scores obtained from VLM. Finally, we compute the nDTW metricbetween the hypothesis that yields the highest alignment score to evaluate thepath fidelity. We demonstrate superior performance compared to other approachesthat use joint semantic maps like VLMaps \cite{vlmaps} on the complexR2R-Habitat \cite{r2r} instruction dataset and quantify in detail the effect ofvisual grounding on navigation performance.</description>
      <author>example@mail.com (Navid Rajabi, Jana Kosecka)</author>
      <guid isPermaLink="false">2502.07306v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Leader-follower formation enabled by pressure sensing in free-swimming undulatory robotic fish</title>
      <link>http://arxiv.org/abs/2502.07282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 10 figures. Accepted for 2025 IEEE International Conference  on Robotics and Automation (ICRA). Supplementary video:  https://youtu.be/DIDYGi9Td0I&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种模仿鱼类侧线系统用于感知水流和压力梯度的仿生机器人，该机器人能够通过压力传感器实现领导-跟随模式下的群组游泳。&lt;h4&gt;背景&lt;/h4&gt;鱼利用其侧线系统来感测水流和压力变化，进而发现周围物体及生物。这项研究旨在复制这一能力，使用具有双边压感触觉传感器的仿生鱼类进行实验。&lt;h4&gt;目的&lt;/h4&gt;展示基于流体压力感应技术在机器人中实现领导-跟随游泳模式的有效性，并通过机器学习方法优化控制策略。&lt;h4&gt;方法&lt;/h4&gt;['首先进行了静态排列试验，在固定不动的追随者和摆动的领导者之间建立了能产生强烈压力变化的理想排布方式。', '接着，采用长短期记忆神经网络作为控制系统的核心算法，该模型将从传感器采集的压力信号、机器人电机命令以及IMU测量的角度值映射为转向指令。', '控制策略通过行为克隆法和DAgger（数据聚合）技术进行训练以模仿专家策略。']&lt;h4&gt;主要发现&lt;/h4&gt;['实验表明，在仅有两个双边压力传感器且仅基于不到一小时的训练数据的情况下，追随者能够在游泳速度达到155毫米/秒时成功跟随领导者至最远200毫米（约一个鱼体长度）的距离。', '该研究证明了利用流体压力反馈机制来实现鱼类模仿机器人在复杂水域环境中有效导航和群组游泳的能力。']&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了基于生物灵感设计的鱼类仿生机器人的潜力，它们能够有效地应对流动环境，并通过使用流体压力回馈系统实现群组游泳。&lt;h4&gt;翻译&lt;/h4&gt;鱼利用侧线来感知水流及周围的压力变化，以此检测附近的物体和生命体。为了复制这种能力，研究者展示了一种名为'微小机器人鱼（$\mu$Bot/MUBot）的仿生机器人能够通过流体压力感应实现领导-跟随游泳模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fish use their lateral lines to sense flows and pressure gradients, enablingthem to detect nearby objects and organisms. Towards replicating thiscapability, we demonstrated successful leader-follower formation swimming usingflow pressure sensing in our undulatory robotic fish ($\mu$Bot/MUBot). Thefollower $\mu$Bot is equipped at its head with bilateral pressure sensors todetect signals excited by both its own and the leader's movements. First, usingexperiments with static formations between an undulating leader and astationary follower, we determined the formation that resulted in strongpressure variations measured by the follower. This formation was then selectedas the desired formation in free swimming for obtaining an expert policy. Next,a long short-term memory neural network was used as the control policy thatmaps the pressure signals along with the robot motor commands and the Eulerangles (measured by the onboard IMU) to the steering command. The policy wastrained to imitate the expert policy using behavior cloning and DatasetAggregation (DAgger). The results show that with merely two bilateral pressuresensors and less than one hour of training data, the follower effectivelytracked the leader within distances of up to 200 mm (= 1 body length) whileswimming at speeds of 155 mm/s (= 0.8 body lengths/s). This work highlights thepotential of fish-inspired robots to effectively navigate fluid environmentsand achieve formation swimming through the use of flow pressure feedback.</description>
      <author>example@mail.com (Kundan Panta, Hankun Deng, Micah DeLattre, Bo Cheng)</author>
      <guid isPermaLink="false">2502.07282v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Confidence: Adaptive Abstention in Dual-Threshold Conformal Prediction for Autonomous System Perception</title>
      <link>http://arxiv.org/abs/2502.07255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的双阈值校准框架，该框架能够为安全关键性的感知系统提供统计保证下的不确定性估计，并在高风险场景中启用选择性预测。此方法结合了有效预测集的校准阈值和通过ROC分析优化的弃权阈值，在各种环境条件下都能保持稳健的表现。&lt;h4&gt;背景&lt;/h4&gt;安全关键性的感知系统需要可靠的不确定性量化机制以及基于原则的放弃预测策略，以在多样的操作环境中维持安全性。&lt;h4&gt;目的&lt;/h4&gt;提供一个既能保证统计学上的不确定度估计又能支持选择性预测的方法框架，特别是在高风险场景中能可靠地弃权而不做出可能不准确或危险的预测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双阈值校准化框架，结合了确保有效预测集的校准阈值和通过ROC分析优化的放弃阈值。该框架在CIFAR-100、ImageNet1K和ModelNet40数据集中进行了全面评估，展示了其跨摄像头与LiDAR模态下的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架在恶劣条件下表现出卓越的检测性能（AUC：0.993至0.995），同时保持高覆盖率（&gt;90.0%）并实现自适应弃权（13.5%至63.4%±0.5）。特别是在LiDAR感知中，该框架展示了特别强的表现，在重大环境干扰下依然能维持稳健的覆盖度（&gt;84.5%），同时适当地放弃不可靠预测。值得注意的是，所提出的体系在重大力干扰下表现出色且稳定。&lt;h4&gt;结论&lt;/h4&gt;本文的方法通过理论保障与实际部署需求之间的桥梁提供了可靠的安全关键性自主系统的解决方案，并能在具有挑战性的现实世界环境中有效运行。&lt;h4&gt;翻译&lt;/h4&gt;原文为英文摘要的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safety-critical perception systems require both reliable uncertaintyquantification and principled abstention mechanisms to maintain safety underdiverse operational conditions. We present a novel dual-thresholdconformalization framework that provides statistically-guaranteed uncertaintyestimates while enabling selective prediction in high-risk scenarios. Ourapproach uniquely combines a conformal threshold ensuring valid prediction setswith an abstention threshold optimized through ROC analysis, providingdistribution-free coverage guarantees (\ge 1 - \alpha) while identifyingunreliable predictions. Through comprehensive evaluation on CIFAR-100,ImageNet1K, and ModelNet40 datasets, we demonstrate superior robustness acrosscamera and LiDAR modalities under varying environmental perturbations. Theframework achieves exceptional detection performance (AUC: 0.993\to0.995) undersevere conditions while maintaining high coverage (&gt;90.0\%) and enablingadaptive abstention (13.5\%\to63.4\%\pm0.5) as environmental severityincreases. For LiDAR-based perception, our approach demonstrates particularlystrong performance, maintaining robust coverage (&gt;84.5\%) while appropriatelyabstaining from unreliable predictions. Notably, the framework shows remarkablestability under heavy perturbations, with detection performance (AUC:0.995\pm0.001) significantly outperforming existing methods across allmodalities. Our unified approach bridges the gap between theoretical guaranteesand practical deployment needs, offering a robust solution for safety-criticalautonomous systems operating in challenging real-world conditions.</description>
      <author>example@mail.com (Divake Kumar, Nastaran Darabi, Sina Tayebati, Amit Ranjan Trivedi)</author>
      <guid isPermaLink="false">2502.07255v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Parameter Optimization of Optical Six-Axis Force/Torque Sensor for Legged Robots</title>
      <link>http://arxiv.org/abs/2502.07196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种专为轻型腿足机器人设计的新型六轴力/扭矩传感器。该传感器采用非接触式光耦合器设计，相比传统的应变计式传感器在耐物理冲击、降低损坏风险等方面具有优势。&lt;h4&gt;背景&lt;/h4&gt;现有腿足机器人的力/扭矩传感器存在体积大、重量重及易受物理损伤等问题，限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非接触式六轴力/扭矩传感器设计，旨在解决传统力传感器的缺点，并满足小型化和轻量化的需要。&lt;h4&gt;方法&lt;/h4&gt;采用光耦合器而非传统的应变计来制造新型传感器，并通过优化参数的方法提高传感器灵敏度并减少误差。利用精确建模和分析目标函数的方式推导出最优设计方案。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该传感器的有效性，其性能与理论模型吻合良好。此外，它还能应用于多种机器人环境，特别是用于研究机器人足部与地面之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;这项创新不仅解决了现有传感器的局限性，还促进了传感技术以及机器人的进一步发展，并为未来在机器人系统中的应用铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要介绍了针对轻型腿足机器人设计的新六轴力/扭矩传感器。这种新型非接触式光耦合器设计方案相较于传统应变计类型传感器，在耐冲击和减少物理损伤风险方面具有显著优势，简化制造过程并降低成本。优化参数的方法被提出以实现高灵敏度与低误差，并通过精确建模和分析目标函数确定最优设计参数。此传感器已在四足机器人中得到验证，展现了其良好的性能表现，适用于多样化机器人环境，尤其是对研究机器人脚部与地面交互具有重要意义。这一创新不仅克服了现有传感器的限制，而且推动了传感技术和机器人的进步，并为未来的机器人系统应用打开了大门。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel six-axis force/torque sensor tailored forcompact and lightweight legged robots. Unlike traditional strain gauge-basedsensors, the proposed non-contact design employs photocouplers, enhancingresistance to physical impacts and reducing damage risk. This approachsimplifies manufacturing, lowers costs, and meets the demands of legged robotsby combining small size, light weight, and a wide force measurement range. Amethodology for optimizing sensor parameters is also presented, focusing onmaximizing sensitivity and minimizing error. Precise modeling and analysis ofobjective functions enabled the derivation of optimal design parameters. Thesensor's performance was validated through extensive testing and integrationinto quadruped robots, demonstrating alignment with theoretical modeling. Thesensor's precise measurement capabilities make it suitable for diverse roboticenvironments, particularly in analyzing interactions between robot feet and theground. This innovation addresses existing sensor limitations whilecontributing to advancements in robotics and sensor technology, paving the wayfor future applications in robotic systems.</description>
      <author>example@mail.com (Hyun-Bin Kim, Byeong-Il Ham, Keun-Ha Choi, Kyung-Soo Kim)</author>
      <guid isPermaLink="false">2502.07196v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Space-Aware Instruction Tuning: Dataset and Benchmark for Guide Dog Robots Assisting the Visually Impaired</title>
      <link>http://arxiv.org/abs/2502.07183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个用于提升视觉障碍人士导航能力的机器人指导解决方案，强调了在复杂环境中的空间感知和沟通的重要性。&lt;h4&gt;背景&lt;/h4&gt;导盲犬机器人为视力受损者提供了更好的移动性和安全性。现有视觉-语言模型（VLMs）虽然能够生成周围环境的自然语言描述以辅助决策，但它们在解释和传达空间关系方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;通过引入Space-Aware Instruction Tuning (SAIT) 数据集和Space-Aware Benchmark (SA-Bench)，解决现有VLMs理解物理环境的能力不足问题，并评估其提供行走指导的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自动化的数据生成流水线，专注于三维空间中虚拟路径到目的地的构建及周围环境的理解。此外，还设计了一个评价协议以衡量VLM在导航中的效果。&lt;h4&gt;主要发现&lt;/h4&gt;与现有算法相比，该研究的空间感知指令调优模型能更准确地提供导航指导。&lt;h4&gt;结论&lt;/h4&gt;论文通过开放共享SAIT数据集、SA-Bench及其相关代码来促进导盲机器人技术的发展和应用。&lt;h4&gt;翻译&lt;/h4&gt;向导机器人为视力受损者提供了增强移动性和安全性的有希望的解决方案，弥补了传统导盲犬在感知智能和沟通方面的局限性。随着视觉-语言模型（VLMs）的出现，机器人现在能够生成周围环境的自然语言描述，有助于更安全的决策制定。然而，现有的VLM通常难以准确解释和传达空间关系，在如过街等复杂环境中尤为重要。我们提出了Space-Aware Instruction Tuning (SAIT) 数据集和Space-Aware Benchmark (SA-Bench)，以解决现有VLM理解物理环境的能力不足问题，并评估其提供行走指导的有效性。我们的自动化数据生成流水线专注于三维空间中虚拟路径到目的地的构建及周围环境的理解，增强对环境的认知能力并使VLM能够为视力受损者提供更准确的指引。我们还提出了一个评估协议来衡量VLM在导航中的效果。比较实验表明，我们的空间感知指令调优模型超越了现有最佳算法。我们在https://github.com/byungokhan/Space-awareVLM上完全开放共享SAIT数据集、SA-Bench及其相关代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Guide dog robots offer promising solutions to enhance mobility and safety forvisually impaired individuals, addressing the limitations of traditional guidedogs, particularly in perceptual intelligence and communication. With theemergence of Vision-Language Models (VLMs), robots are now capable ofgenerating natural language descriptions of their surroundings, aiding in saferdecision-making. However, existing VLMs often struggle to accurately interpretand convey spatial relationships, which is crucial for navigation in complexenvironments such as street crossings. We introduce the Space-Aware InstructionTuning (SAIT) dataset and the Space-Aware Benchmark (SA-Bench) to address thelimitations of current VLMs in understanding physical environments. Ourautomated data generation pipeline focuses on the virtual path to thedestination in 3D space and the surroundings, enhancing environmentalcomprehension and enabling VLMs to provide more accurate guidance to visuallyimpaired individuals. We also propose an evaluation protocol to assess VLMeffectiveness in delivering walking guidance. Comparative experimentsdemonstrate that our space-aware instruction-tuned model outperformsstate-of-the-art algorithms. We have fully open-sourced the SAIT dataset andSA-Bench, along with the related code, athttps://github.com/byungokhan/Space-awareVLM</description>
      <author>example@mail.com (ByungOk Han, Woo-han Yun, Beom-Su Seo, Jaehong Kim)</author>
      <guid isPermaLink="false">2502.07183v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Online Aggregation of Trajectory Predictors</title>
      <link>http://arxiv.org/abs/2502.07178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种轻量级且模型无关的方法，用于在线聚合不同轨迹预测器的输出。&lt;h4&gt;背景&lt;/h4&gt;轨迹预测是自动驾驶安全性和效率的关键任务。不同的方法（例如基于规则或通过各种架构和数据集学习）已经被提出来解决这一问题，但这些方法往往对部署环境敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轻量级且模型无关的方法来聚合不同轨迹预测器的输出，使得即使在分布外的数据上也能保持性能。&lt;h4&gt;方法&lt;/h4&gt;基于在线凸优化理论，每个单独的轨迹预测器被视为一个'专家'，并通过维护概率向量混合不同专家的输出。利用真实世界中逐步揭示的真实行为数据形成损失函数，并通过梯度引导概率向量选择最佳的专家组合。&lt;h4&gt;主要发现&lt;/h4&gt;当将训练在不同城市的NUSCENES数据集上得到的不同轨迹预测器进行聚合时，该方法显示了出色的性能，甚至在分布外的LYFT数据集中也表现得和单一模型一样好或更好。&lt;h4&gt;结论&lt;/h4&gt;这种方法提供了一种有效的方式，在各种环境条件下实现更稳健、更准确的轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提及的是一种基于在线凸优化理论但又超越了凸性和静态性的轻量级、模型无关的方法，用于聚合不同轨迹预测器的输出。该方法旨在解决现有轨迹预测技术对特定部署环境敏感的问题，通过将每个单独训练的轨迹预测器视为一个'专家'来工作，并使用真实数据动态调整这些'专家'的权重。实验结果表明，在不同的城市和分布外的数据集上，这种方法能够实现与单一模型一样好或更好的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory prediction, the task of forecasting future agent behavior frompast data, is central to safe and efficient autonomous driving. A diverse setof methods (e.g., rule-based or learned with different architectures anddatasets) have been proposed, yet it is often the case that the performance ofthese methods is sensitive to the deployment environment (e.g., how well thedesign rules model the environment, or how accurately the test data match thetraining data). Building upon the principled theory of online convexoptimization but also going beyond convexity and stationarity, we present alightweight and model-agnostic method to aggregate different trajectorypredictors online. We propose treating each individual trajectory predictor asan "expert" and maintaining a probability vector to mix the outputs ofdifferent experts. Then, the key technical approach lies in leveraging onlinedata -the true agent behavior to be revealed at the next timestep- to form aconvex-or-nonconvex, stationary-or-dynamic loss function whose gradient steersthe probability vector towards choosing the best mixture of experts. Weinstantiate this method to aggregate trajectory predictors trained on differentcities in the NUSCENES dataset and show that it performs just as well, if notbetter than, any singular model, even when deployed on the out-of-distributionLYFT dataset.</description>
      <author>example@mail.com (Alex Tong, Apoorva Sharma, Sushant Veer, Marco Pavone, Heng Yang)</author>
      <guid isPermaLink="false">2502.07178v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>A Safe Hybrid Control Framework for Car-like Robot with Guaranteed Global Path-Invariance using a Control Barrier Function</title>
      <link>http://arxiv.org/abs/2502.07136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, initial submission to CCTA25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的混合框架，用于带有避障、全局收敛和安全性的车轮式机器人。&lt;h4&gt;背景&lt;/h4&gt;对于车轮式机器人而言，在存在潜在障碍物的环境中沿着预设路径行驶并保持安全性是一个重要的挑战。安全在此被解释为路径不变性：一旦机器人进入路径，则不会离开该路径。&lt;h4&gt;目的&lt;/h4&gt;设计一种既能够避开障碍物，又能够在到达预定路径后稳定地沿该路径行进而不偏离的控制系统。&lt;h4&gt;方法&lt;/h4&gt;首先定义了一条沿着给定路径的安全区域，并设计了局部控制器来保证收敛到路径并保持路径不变性。引入控制屏障函数技术以避免奇点问题；其次设计了一个混合控制框架，将本地路径不变控制器与现有的全局跟踪控制器相结合，从而实现从任意位置向期望路径的全局收敛。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方案通过结合局部和全局控制策略确保了路径不变性和对传感器噪声的鲁棒性，并且模拟结果验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为车轮式机器人在存在障碍物的情况下提供了有效的导航解决方案，保证了系统的安全性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;这项工作提出了一个具有避障、全局收敛和安全性特征的混合框架。其中安全性被定义为路径不变性：一旦机器人接近预定路径，则不会离开该路径。给定一条无碰撞且可行性的预设路径，在此路径周围可能存在障碍物，任务是避开这些障碍物并到达目标路径后保持在该路径上而不会偏离。问题分为两个阶段解决。首先，我们定义了沿着给定路径的无障碍区域，并设计了一个局部控制器以确保向路径的收敛性以及路径不变性。其次，我们创建了一个混合控制框架，它将这个本地路径不变控件与现有的全局跟踪控制器（这些控制器没有提供路径不变性的保证）相结合，从而确保从任何位置到预期路径的全球汇聚能力。该方法通过保持路径不变性和对传感器噪声的鲁棒性来保障系统的稳定性和安全性。详细的模拟结果证实了所提出方案的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a hybrid framework for car-like robots with obstacleavoidance, global convergence, and safety, where safety is interpreted as pathinvariance, namely, once the robot converges to the path, it never leaves thepath. Given a priori obstacle-free feasible path where obstacles can be aroundthe path, the task is to avoid obstacles while reaching the path and thenstaying on the path without leaving it. The problem is solved in two stages.Firstly, we define a ``tight'' obstacle-free neighborhood along the path anddesign a local controller to ensure convergence to the path and pathinvariance. The control barrier function technology is involved in the controldesign to steer the system away from its singularity points, where the localpath invariant controller is not defined. Secondly, we design a hybrid controlframework that integrates this local path-invariant controller with any globaltracking controller from the existing literature without path invarianceguarantee, ensuring convergence from any position to the desired path, namely,global convergence. This framework guarantees path invariance and robustness tosensor noise. Detailed simulation results affirm the effectiveness of theproposed scheme.</description>
      <author>example@mail.com (Nan Wang, Adeel Akhtar, Ricardo G. Sanfelice)</author>
      <guid isPermaLink="false">2502.07136v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Smell of Source: Learning-Based Odor Source Localization with Molecular Communication</title>
      <link>http://arxiv.org/abs/2502.07112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分子通信、环境监测等领域中单源单分子情况下气味源定位的三种主要方法：贝叶斯过滤、机器学习模型和物理信息神经网络(PINNs)。通过生成合成数据集来评估这些方法在不同条件下的性能。&lt;h4&gt;背景&lt;/h4&gt;气味源定位是分子通讯、环境监控、灾害响应及工业安全等领域的基础挑战之一。&lt;h4&gt;目的&lt;/h4&gt;旨在比较和评估贝叶斯过滤、机器学习模型以及物理信息神经网络(PINNs)在单一来源单个分子的气味源定位中的性能。&lt;h4&gt;方法&lt;/h4&gt;使用二维对流扩散偏微分方程求解器生成合成数据集，以模拟不同环境条件（如传感器噪声和稀疏测量）下的实验。&lt;h4&gt;主要发现&lt;/h4&gt;物理信息神经网络(PINNs)在所有测试条件下均表现出最低的定位误差(0.89×10^-6米)，优于机器学习反演(1.48×10^-6米)和卡尔曼滤波器(1.62×10^-6米)；强化学习方法虽然误差较大（3.01×10^-6米），但在推断时间上仅需0.147秒。&lt;h4&gt;结论&lt;/h4&gt;物理信息神经网络(PINNs)在气味源定位方面表现最佳，但其计算效率不如使用强化学习的方法。这表明了准确性和计算效率之间的权衡关系。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：气味源定位是分子通讯、环境监测、灾害响应和工业安全等领域的一个基础挑战。本文研究三种主要方法：贝叶斯过滤、机器学习模型以及物理信息神经网络(PINNs)，目的是在单源单一分子的情况下实现气味源的定位。通过将源传感器架构视为发射器-接收器模型，我们从分子通讯的角度探讨了源定位问题。使用二维对流扩散偏微分方程求解器生成合成数据集以评估不同条件下（包括传感器噪声和稀疏测量）的各种方法性能。实验结果表明，物理信息神经网络(PINNs)实现了最低的定位误差0.89×10^-6米，优于机器学习反演(1.48×10^-6米)和卡尔曼滤波器(1.62×10^-6米)；而强化学习方法虽然实现3.01×10^-6米的定位误差，但其推断时间仅为0.147秒，这表明了不同方法之间准确性与计算效率之间的权衡关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Odor source localization is a fundamental challenge in molecularcommunication, environmental monitoring, disaster response, industrial safety,and robotics. In this study, we investigate three major approaches: Bayesianfiltering, machine learning (ML) models, and physics-informed neural networks(PINNs) with the aim of odor source localization in a single-source,single-molecule case. By considering the source-sensor architecture as atransmitter-receiver model we explore source localization under the scope ofmolecular communication. Synthetic datasets are generated using a 2Dadvection-diffusion PDE solver to evaluate each method under varyingconditions, including sensor noise and sparse measurements. Our experimentsdemonstrate that \textbf{Physics-Informed Neural Networks (PINNs)} achieve thelowest localization error of \(\mathbf{0.89 \times 10^{-6}}\) m, outperforming\textbf{machine learning (ML) inversion} (\(\mathbf{1.48 \times 10^{-6}}\) m)and \textbf{Kalman filtering} (\(\mathbf{1.62 \times 10^{-6}}\) m). The\textbf{reinforcement learning (RL)} approach, while achieving a localizationerror of \(\mathbf{3.01 \times 10^{-6}}\) m, offers an inference time of\(\mathbf{0.147}\) s, highlighting the trade-off between accuracy andcomputational efficiency among different methodologies.</description>
      <author>example@mail.com (Ayse Sila Okcu, Ozgur B. Akan)</author>
      <guid isPermaLink="false">2502.07112v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects</title>
      <link>http://arxiv.org/abs/2502.07005v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages main text, 30 pages all included&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于异构图的策略模型HEPi，以解决机器人操作中涉及不同几何形状和可变形物体的任务。该方法采用$SE(3)$等变消息传递网络，并引入了显式的异质性建模。&lt;h4&gt;背景&lt;/h4&gt;操纵具有各种几何形状的对象以及处理可变形物体是机器人领域中的一个重要挑战。例如，插入不同类型的对象或悬挂衣物需要精确的控制和复杂的动态模型。&lt;h4&gt;目的&lt;/h4&gt;通过构建一种统一的图表示形式来解决此类问题，并提出了一种新的强化学习基准测试方法以评估该框架的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个异构图表示模型HEPi，利用$SE(3)$等变消息传递网络作为主要架构，并引入了显式的异质性建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，相较于基于Transformer的方法以及非异质的等变策略，HEPi在平均回报、样本效率和对未见过物体的泛化能力方面表现更优。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新的机器人任务处理框架，并展示了其对于复杂动态模型的有效性和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;操控具有不同几何形状的对象以及可变形对象是机器人技术中的一个主要挑战。例如，插入不同类型对象或悬挂衣物需要精确控制和有效的复杂动力学建模。在这项工作中，我们通过异构图的视角来解决这个问题，该图包含较小的子图（如致动器和物体），并且有不同类型的边描述它们之间的交互作用。这种图表示既适用于刚性物体任务也适用于可变形对象任务，并且可以进一步扩展到多致动器的任务中。为了评估这一设置，我们提出了一种新的具有挑战性的强化学习基准测试，包括插入不同类型物体的刚性插入和使用多个末端执行器进行绳索及布料操作。这些任务由于初始配置和目标配置在3D空间中的均匀采样而呈现出较大的搜索空间。为了解决这个问题，我们提出了一个新颖的基于图策略模型HEPi，利用$SE(3)$等变消息传递网络作为主要架构来利用几何对称性。此外，通过显式地建模异质性，HEPi在平均回报、样本效率以及未见过对象上的泛化能力方面优于Transformer基线和非异构等变策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manipulating objects with varying geometries and deformable objects is amajor challenge in robotics. Tasks such as insertion with different objects orcloth hanging require precise control and effective modelling of complexdynamics. In this work, we frame this problem through the lens of aheterogeneous graph that comprises smaller sub-graphs, such as actuators andobjects, accompanied by different edge types describing their interactions.This graph representation serves as a unified structure for both rigid anddeformable objects tasks, and can be extended further to tasks comprisingmultiple actuators. To evaluate this setup, we present a novel and challengingreinforcement learning benchmark, including rigid insertion of diverse objects,as well as rope and cloth manipulation with multiple end-effectors. These taskspresent a large search space, as both the initial and target configurations areuniformly sampled in 3D space. To address this issue, we propose a novelgraph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi),utilizing $SE(3)$  equivariant message passing networks as the main backbone to exploit thegeometric symmetry. In addition, by modeling explicit heterogeneity, HEPi canoutperform Transformer-based and non-heterogeneous equivariant policies interms of average returns, sample efficiency, and generalization to unseenobjects.</description>
      <author>example@mail.com (Tai Hoang, Huy Le, Philipp Becker, Vien Anh Ngo, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.07005v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Select before Act: Spatially Decoupled Action Repetition for Continuous Control</title>
      <link>http://arxiv.org/abs/2502.06919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的重复框架SDAR，通过独立执行每个动作维度的闭环选择来实现空间解耦的动作重复。&lt;h4&gt;背景&lt;/h4&gt;强化学习在连续控制任务中取得了显著成功，如机器人操作和行走。最近的研究将动作重复集成到RL中，提高了样本效率并增强了性能。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法忽视各动作维度差异的问题，提高决策灵活性，并改进策略的敏捷性和效果。&lt;h4&gt;方法&lt;/h4&gt;引入SDAR框架，通过执行每个动作维度的闭环选择来实现空间解耦的动作重复，从而获得更灵活的重复策略。&lt;h4&gt;主要发现&lt;/h4&gt;相比现有的重复框架，SDAR在样本效率、策略性能和减少行动波动方面表现更好，并在多种连续控制场景中进行了实验验证其有效性。&lt;h4&gt;结论&lt;/h4&gt;通过将动作维度分离进行独立决策的方式提高了强化学习中的动作持久性和多样性之间的平衡，改进了现有方法的局限性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：强化学习（RL）已经在各种连续控制任务中取得了显著的成功，例如机器人操作和行走。与主流RL在每个步骤做出决策不同的是，最近的研究将行动重复集成到RL中，通过增强行为持久性和提高样本效率来获得更好的性能。然而，现有方法在重复期间将所有动作维度视为整体，忽略了它们之间的差异。这种限制导致了决策的不灵活性，从而降低了策略的敏捷性并影响了效果。在这项工作中，我们提出了一种称为SDAR的新颖重复框架，它通过为每个动作维度单独执行闭环行动或重复选择来实现空间解耦的动作重复。SDAR实现了更灵活的重复策略，提高了行为持久性和多样性的平衡。与现有的重复框架相比，SDAR在样本效率、更高的策略性能和减少的行为波动方面表现更好。我们在各种连续控制场景中进行了实验，展示了本文提出的空间解耦重复设计的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) has achieved remarkable success in variouscontinuous control tasks, such as robot manipulation and locomotion. Differentto mainstream RL which makes decisions at individual steps, recent studies haveincorporated action repetition into RL, achieving enhanced action persistencewith improved sample efficiency and superior performance. However, existingmethods treat all action dimensions as a whole during repetition, ignoringvariations among them. This constraint leads to inflexibility in decisions,which reduces policy agility with inferior effectiveness. In this work, wepropose a novel repetition framework called SDAR, which implements SpatiallyDecoupled Action Repetition through performing closed-loop act-or-repeatselection for each action dimension individually. SDAR achieves more flexiblerepetition strategies, leading to an improved balance between actionpersistence and diversity. Compared to existing repetition frameworks, SDAR ismore sample efficient with higher policy performance and reduced actionfluctuation. Experiments are conducted on various continuous control scenarios,demonstrating the effectiveness of spatially decoupled repetition designproposed in this work.</description>
      <author>example@mail.com (Buqing Nie, Yangqing Fu, Yue Gao)</author>
      <guid isPermaLink="false">2502.06919v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Learning Efficient Flocking Control based on Gibbs Random Fields</title>
      <link>http://arxiv.org/abs/2502.02984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于Gibbs随机场的多智能体强化学习框架，用于解决多机器人系统在拥挤环境下的群集控制问题。&lt;h4&gt;背景&lt;/h4&gt;群集控制对于多机器人系统的各种应用至关重要，但在拥挤环境中实现高效的群集控制面临着计算负担、性能最优性和运动安全性的挑战。&lt;h4&gt;目的&lt;/h4&gt;该论文通过构建基于Gibbs随机场的多智能体强化学习框架来应对这些挑战。&lt;h4&gt;方法&lt;/h4&gt;[{'方法1': '利用Gibbs随机场表示一个多机器人系统，将其视为一组符合联合概率分布的随机变量，为群集奖励设计提供新的视角'}, {'方法2': '通过基于GRF的信用分配方法实现去中心化的训练和执行机制，增强多智能体强化学习对于机器人数量的可扩展性'}, {'方法3': '引入动作注意模块以隐式预测邻近机器人的运动意图，从而减轻MARL中的潜在非平稳问题'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'发现1': '提出框架能够在具有挑战性的环境中通过与最新的解决方案进行详细的模拟和实验比较证明学习高效的分布式控制策略的成功率为99%左右'}, {'发现2': '进行了消融研究以验证不同框架模块的效率'}]&lt;h4&gt;结论&lt;/h4&gt;所提出的基于Gibbs随机场的方法为解决多机器人系统在复杂环境下的群集控制问题提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Flocking control is essential for multi-robot systems in diverseapplications, yet achieving efficient flocking in congested environments poseschallenges regarding computation burdens, performance optimality, and motionsafety. This paper addresses these challenges through a multi-agentreinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs).With GRFs, a multi-robot system is represented by a set of random variablesconforming to a joint probability distribution, thus offering a freshperspective on flocking reward design. A decentralized training and executionmechanism, which enhances the scalability of MARL concerning robot quantity, isrealized using a GRF-based credit assignment method. An action attention moduleis introduced to implicitly anticipate the motion intentions of neighboringrobots, consequently mitigating potential non-stationarity issues in MARL. Theproposed framework enables learning an efficient distributed control policy formulti-robot systems in challenging environments with success rate around$99\%$, as demonstrated through thorough comparisons with state-of-the-artsolutions in simulations and experiments. Ablation studies are also performedto validate the efficiency of different framework modules.</description>
      <author>example@mail.com (Dengyu Zhang, Chenghao, Feng Xue, Qingrui Zhang)</author>
      <guid isPermaLink="false">2502.02984v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
  <item>
      <title>Discovering Physics Laws of Dynamical Systems via Invariant Function Learning</title>
      <link>http://arxiv.org/abs/2502.04495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了学习由常微分方程（ODE）支配的动力系统的内在规律的问题，特别是在不同环境中发现基本动力学而非特定环境机制的方法。&lt;h4&gt;背景&lt;/h4&gt;研究对象是在多种环境下探索和识别动力系统的基本动态规律，而不是针对某个具体环境的特殊机制。挑战在于如何在功能系数变化甚至完全不同的函数形式变化的情况下进行学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于因果分析的新方法DIF（Invariant Function Disentanglement），以解决复杂环境中发现不变函数的问题，并展示其有效性和效率。&lt;h4&gt;方法&lt;/h4&gt;该研究通过因果图的构建和编码-解码超网络的设计，明确地将环境特有的动力学与不变函数分离。这种方法依赖于信息基础原则来保证从提取的不变函数中独立出环境影响。&lt;h4&gt;主要发现&lt;/h4&gt;在三个ODE系统上的定量对比表明了该方法的有效性和效率；此外，符号回归解释结果强调了框架揭示基本规律的能力。&lt;h4&gt;结论&lt;/h4&gt;通过提出DIF方法，研究解决了复杂环境下发现动力学基本规律的问题，并展示了其在不同环境下的应用价值和潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑学习由普通微分方程（ODE）支配的动力系统的基本规律。主要挑战在于如何跨多个环境发现内在动态，同时避免特定于环境的机制。不同于以往的工作，本文解决的是更加复杂的情况，在这种情况下变化不仅限于功能系数的变化，还包括完全不同的函数形式的变化...我们通过因果图和编码-解码超网络的设计来明确分离不变函数与特定于环境的动力学，并保证它们之间的独立性...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider learning underlying laws of dynamical systems governed byordinary differential equations (ODE). A key challenge is how to discoverintrinsic dynamics across multiple environments while circumventingenvironment-specific mechanisms. Unlike prior work, we tackle more complexenvironments where changes extend beyond function coefficients to entirelydifferent function forms. For example, we demonstrate the discovery of idealpendulum's natural motion $\alpha^2 \sin{\theta_t}$ by observing pendulumdynamics in different environments, such as the damped environment $\alpha^2\sin(\theta_t) - \rho \omega_t$ and powered environment $\alpha^2\sin(\theta_t) + \rho \frac{\omega_t}{\left|\omega_t\right|}$. Here, weformulate this problem as an \emph{invariant function learning} task andpropose a new method, known as \textbf{D}isentanglement of \textbf{I}nvariant\textbf{F}unctions (DIF), that is grounded in causal analysis. We propose acausal graph and design an encoder-decoder hypernetwork that explicitlydisentangles invariant functions from environment-specific dynamics. Thediscovery of invariant functions is guaranteed by our information-basedprinciple that enforces the independence between extracted invariant functionsand environments. Quantitative comparisons with meta-learning and invariantlearning baselines on three ODE systems demonstrate the effectiveness andefficiency of our method. Furthermore, symbolic regression explanation resultshighlight the ability of our framework to uncover intrinsic laws.</description>
      <author>example@mail.com (Shurui Gui, Xiner Li, Shuiwang Ji)</author>
      <guid isPermaLink="false">2502.04495v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>AnyPlace: Learning Generalized Object Placement for Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.04531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AnyPlace 是一种基于合成数据训练的两阶段方法，用于预测真实世界任务中的可行放置姿态。&lt;h4&gt;背景&lt;/h4&gt;机器人在处理对象放置时面临挑战，由于物体几何形状和放置配置的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出 AnyPlace 方法来解决由对象多样化带来的放置问题。&lt;h4&gt;方法&lt;/h4&gt;利用视觉-语言模型（VLM）识别大致放置位置，并专注于局部放置区域以训练低级别放置姿态预测模型。通过生成包含随机生成对象的不同放置配置（插入、堆叠、悬挂）的完全合成数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在成功率、可能放置模式的覆盖率和精度方面优于基线模型，并且能够直接将仅基于合成数据训练的模型应用于真实世界场景中。&lt;h4&gt;结论&lt;/h4&gt;AnyPlace 方法成功地展示了如何利用合成数据来解决实际对象放置任务中的复杂问题，包括处理不同几何形状的对象以及实现精细放置的高精度。&lt;h4&gt;翻译&lt;/h4&gt;物体在机器人任务中的放置本质上具有挑战性，因为对象几何形状和放置配置的多样性。为了解决这个问题，我们提出了 AnyPlace 方法，这是一种完全基于合成数据训练的两阶段方法，能够预测真实世界任务中的一系列可行放置姿态。我们的关键见解是利用视觉-语言模型（VLM）识别大致放置位置，并专注于局部放置区域进行训练。在评估过程中，在模拟环境中展示了该方法优于基线模型的表现，尤其是在成功率、可能放置模式覆盖率和精度方面。在现实世界的实验中证明了，该方法能够直接将仅基于合成数据的模型应用于真实场景，即使是在对象几何形状变化多样且需要高精度精细放置的情况下也能成功执行任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object placement in robotic tasks is inherently challenging due to thediversity of object geometries and placement configurations. To address this,we propose AnyPlace, a two-stage method trained entirely on synthetic data,capable of predicting a wide range of feasible placement poses for real-worldtasks. Our key insight is that by leveraging a Vision-Language Model (VLM) toidentify rough placement locations, we focus only on the relevant regions forlocal placement, which enables us to train the low-levelplacement-pose-prediction model to capture diverse placements efficiently. Fortraining, we generate a fully synthetic dataset of randomly generated objectsin different placement configurations (insertion, stacking, hanging) and trainlocal placement-prediction models. We conduct extensive evaluations insimulation, demonstrating that our method outperforms baselines in terms ofsuccess rate, coverage of possible placement modes, and precision. Inreal-world experiments, we show how our approach directly transfers modelstrained purely on synthetic data to the real world, where it successfullyperforms placements in scenarios where other models struggle -- such as withvarying object geometries, diverse placement modes, and achieving highprecision for fine placement. More at: https://any-place.github.io.</description>
      <author>example@mail.com (Yuchi Zhao, Miroslav Bogdanovic, Chengyuan Luo, Steven Tohme, Kourosh Darvish, Alán Aspuru-Guzik, Florian Shkurti, Animesh Garg)</author>
      <guid isPermaLink="false">2502.04531v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Data Processing and Benchmarking of AI Models for Pathology</title>
      <link>http://arxiv.org/abs/2502.06750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在计算病理学领域取得了重大进展。&lt;h4&gt;目的&lt;/h4&gt;解决可用模型数量增加及缺乏标准化基准的问题，评估模型的优缺点以及进一步发展的潜力。&lt;h4&gt;方法&lt;/h4&gt;开发了一套新的软件工具，用于全切片图像处理、基础模型评测和公开任务管理。&lt;h4&gt;主要发现&lt;/h4&gt;这些资源有望促进透明度、可重复性和该领域的持续进步。&lt;h4&gt;翻译&lt;/h4&gt;在基础建模方面取得的进展已经重塑了计算病理学领域。然而，可用模型数量增加以及缺乏标准化基准评估其优缺点及进一步发展的潜力使得这些问题更加复杂化。为了解决这一挑战，我们引入了一套新的软件工具，用于全切片图像处理、基础模型评测和公开任务管理。我们期待这些资源能够促进该领域的透明度、可重复性以及持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in foundation modeling have reshaped computational pathology.However, the increasing number of available models and lack of standardizedbenchmarks make it increasingly complex to assess their strengths, limitations,and potential for further development. To address these challenges, weintroduce a new suite of software tools for whole-slide image processing,foundation model benchmarking, and curated publicly available tasks. Weanticipate that these resources will promote transparency, reproducibility, andcontinued progress in the field.</description>
      <author>example@mail.com (Andrew Zhang, Guillaume Jaume, Anurag Vaidya, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2502.06750v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar</title>
      <link>http://arxiv.org/abs/2502.06114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文探讨了在恶劣天气条件下3D物体检测的重要性，以及雷达系统如何弥补激光雷达的不足。提出了一个基于知识蒸馏框架的方法来处理4D雷达点云稀疏性问题。&lt;h4&gt;背景&lt;/h4&gt;准确的3D物体检测对于自主导航的安全至关重要，在不同天气条件下的表现可靠性要求极高。尽管LiDAR在恶劣天气中的性能下降，但雷达系统保持了其稳定性。然而，传统雷达缺乏高度信息，最近出现的4D雷达通过测量范围、方位角和多普勒速度同时捕捉高度数据来克服这一限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达特有的密集雷达成像（Radar Tensor）解决点云稀疏性问题的新方法。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新颖的知识蒸馏框架，该框架使学生模型能够通过模仿一组教师模型在潜在空间中对稀疏输入进行稠密化处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在K-Radar数据集上与当前最先进的RTNH模型相比，性能提升了25%，同时保持了实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了4D雷达特有的密集雷达成像的潜在价值，并展示了通过知识蒸馏框架增强其在3D物体检测中的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D object detection is crucial for safe autonomous navigation,requiring reliable performance across diverse weather conditions. While LiDARperformance deteriorates in challenging weather, Radar systems maintain theirreliability. Traditional Radars have limitations due to their lack of elevationdata, but the recent 4D Radars overcome this by measuring elevation alongsiderange, azimuth, and Doppler velocity, making them invaluable for autonomousvehicles. The primary challenge in utilizing 4D Radars is the sparsity of theirpoint clouds. Previous works address this by developing architectures thatbetter capture semantics and context in sparse point cloud, largely drawingfrom LiDAR-based approaches. However, these methods often overlook a uniqueadvantage of 4D Radars: the dense Radar tensor, which encapsulates powermeasurements across three spatial dimensions and the Doppler dimension. Ourpaper leverages this tensor to tackle the sparsity issue. We introduce a novelknowledge distillation framework that enables a student model to densify itssparse input in the latent space by emulating an ensemble of teacher models.Our experiments demonstrate a 25% performance improvement over thestate-of-the-art RTNH model on the K-Radar dataset. Notably, this improvementis achieved while still maintaining a real-time inference speed.</description>
      <author>example@mail.com (Seung-Hyun Song, Dong-Hee Paek, Minh-Quan Dao, Ezio Malis, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.06114v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation</title>
      <link>http://arxiv.org/abs/2502.06336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了DefTransNet，一种用于非刚性点云注册的端到端Transformer架构。它能够处理大变形、异常值、噪声和部分数据等问题。&lt;h4&gt;背景&lt;/h4&gt;软组织手术由于组织变形可能导致组织位置和形状变得不清晰，影响手术准确性。现有的基于特征的方法难以应对噪音、异常值等挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的非刚性点云注册方法（DefTransNet），增强在具有挑战性的场景中的鲁棒性和精度。&lt;h4&gt;方法&lt;/h4&gt;设计了一种端到端的Transformer架构，输入源和目标点云数据，并输出位移矢量场。该模型通过学习变换矩阵来提高对仿射变换的鲁棒性，并集成了全局与局部几何信息以及使用Transformer捕捉点之间的长程依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ModelNet、SynBench、4DMatch和DeformedTissue四个数据集上的实验表明，DefTransNet在各种困难条件下优于现有的最先进的注册网络。&lt;h4&gt;结论&lt;/h4&gt;通过利用Transformer的注意力机制并综合全局与局部信息，DefTransNet成功地提高了非刚性点云注册任务中的鲁棒性和精度，并为软组织手术提供了一个有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;软组织外科手术如肿瘤切除术因其难以预测的组织变形而复杂化。将这些组织表面表示为点云并通过应用非刚性点云配准（PCR）方法，外科医生可以在术前、术中和术后更好地了解组织变形情况。然而，现有的非刚性PCR方法在面对噪声、异常值等挑战时鲁棒性较差。尽管基于学习的方法尤其是Transformer方法由于其注意力机制在捕捉交互方面显示出巨大潜力，但它们在复杂场景中的适应性仍有待提高。本文提出了一种新颖的端到端Transformer架构DefTransNet用于非刚性PCR，旨在解决大变形、异常值等问题，并且通过实验验证了该方法的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft-tissue surgeries, such as tumor resections, are complicated by tissuedeformations that can obscure the accurate location and shape of tissues. Byrepresenting tissue surfaces as point clouds and applying non-rigid point cloudregistration (PCR) methods, surgeons can better understand tissue deformationsbefore, during, and after surgery. Existing non-rigid PCR methods, such asfeature-based approaches, struggle with robustness against challenges likenoise, outliers, partial data, and large deformations, making accurate pointcorrespondence difficult. Although learning-based PCR methods, particularlyTransformer-based approaches, have recently shown promise due to theirattention mechanisms for capturing interactions, their robustness remainslimited in challenging scenarios. In this paper, we present DefTransNet, anovel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNetis designed to address the key challenges of deformable registration, includinglarge deformations, outliers, noise, and partial data, by inputting source andtarget point clouds and outputting displacement vector fields. The proposedmethod incorporates a learnable transformation matrix to enhance robustness toaffine transformations, integrates global and local geometric information, andcaptures long-range dependencies among points using Transformers. We validateour approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue,using both synthetic and real-world data to demonstrate the generalization ofour proposed method. Experimental results demonstrate that DefTransNetoutperforms current state-of-the-art registration networks across variouschallenging conditions. Our code and data are publicly available.</description>
      <author>example@mail.com (Sara Monji-Azad, Marvin Kinz, Siddharth Kothari, Robin Khanna, Amrei Carla Mihan, David Maennel, Claudia Scherl, Juergen Hesser)</author>
      <guid isPermaLink="false">2502.06336v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks</title>
      <link>http://arxiv.org/abs/2502.06684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近用于处理表格数据的基础模型在通过上下文学习适应新任务方面表现出色，但这些模型忽视了一个关键的等变性属性：目标维度的任意排序不应影响模型预测。&lt;h4&gt;背景&lt;/h4&gt;TabPFN和其他基础模型已经在各种表格数据任务中展示了强大的表现能力。然而，这类模型存在一个严重的不足，即它们未能考虑到输出维度上的等变性问题，这会导致不稳定性和不可压缩误差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有模型中存在的等变性问题，并通过实验验证该新方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种能够保持输出维度间等变性的新型模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的模型不仅有效地解决了原有模型的不足，还取得了与基准性能相竞争的结果。&lt;h4&gt;结论&lt;/h4&gt;新的模型通过确保目标维度排序对预测结果没有影响，显著提高了模型的稳定性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent foundational models for tabular data, such as TabPFN, havedemonstrated remarkable effectiveness in adapting to new tasks throughin-context learning. However, these models overlook a crucial equivarianceproperty: the arbitrary ordering of target dimensions should not influencemodel predictions. In this study, we identify this oversight as a source ofincompressible error, termed the equivariance gap, which introduces instabilityin predictions. To mitigate these issues, we propose a novel model designed topreserve equivariance across output dimensions. Our experimental resultsindicate that our proposed model not only addresses these pitfalls effectivelybut also achieves competitive benchmark performance.</description>
      <author>example@mail.com (Michael Arbel, David Salinas, Frank Hutter)</author>
      <guid isPermaLink="false">2502.06684v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Prototype Contrastive Consistency Learning for Semi-Supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.06650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为原型对比一致性分割（PCCS）的新方法，用于半监督医学图像分割。&lt;h4&gt;背景&lt;/h4&gt;医疗影像分割在医疗图像分析中至关重要，但在缺乏标注数据而有大量未标记数据的情况下尤其具有挑战性。对比学习通过从部分像素构建对比样本已被证明可用于改进这种情况下的医学影像分割。&lt;h4&gt;目的&lt;/h4&gt;解决现有对比学习方法忽视了未标记图像的整体上下文信息的问题，以提高精确分割效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种原型对比一致性分割（PCCS）新方法。该方法通过构造带有标志距离图和不确定性图的未标注图像来强制相同语义类别的原型彼此接近，并使不同类别之间的原型远离。此外，还设计了学生-教师架构下的原型更新机制来优化对比学习中的原型。&lt;h4&gt;主要发现&lt;/h4&gt;PCCS方法能够从大量未标记数据中挖掘出更可靠的信息，并通过不确定性一致性损失函数进行增强。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，与现有最先进的方法相比，PCCS在医学图像分割方面取得了更好的表现。代码公开于GitHub（https://github.com/comphsh/PCCS）。&lt;h4&gt;翻译&lt;/h4&gt;医疗影像分割是医疗图像分析中的关键任务，但在较少标记数据和大量未标记数据的情况下尤其具有挑战性。对比学习通过从部分像素构建对比样本已被证明对半监督医学影像分割非常有效。然而，尽管先前的对比学习方法可以从图内部分像素中挖掘语义信息，但它们忽略了整个未标记图像的上下文信息，这对于精确分割至关重要。为了解决这个问题，我们提出了一种新颖的原型对比学习方法，称为原型对比一致性分割（PCCS），用于半监督医学影像分割。核心思想是强制相同语义类别的原型彼此接近，并使不同类别之间的原型远离。具体而言，我们从未标记图像中构建了标志距离图和不确定性图。使用标志距离图来构造对比学习中的原型，然后根据不确定性地图估计原型不确定性作为权衡。为了获得更好的原型，在学生-教师架构的基础上设计了一种新的机制——原型更新机制，用于辅助对比学习中的原型更新。此外，我们提出了一种不确定性一致性损失函数，以挖掘未标记数据中的更多可靠信息。广泛的医学图像分割实验表明，PCCS方法在分割性能上优于现有最先进的方法。代码可在GitHub（https://github.com/comphsh/PCCS）获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation is a crucial task in medical image analysis, butit can be very challenging especially when there are less labeled data but withlarge unlabeled data. Contrastive learning has proven to be effective formedical image segmentation in semi-supervised learning by constructingcontrastive samples from partial pixels. However, although previous contrastivelearning methods can mine semantic information from partial pixels withinimages, they ignore the whole context information of unlabeled images, which isvery important to precise segmentation. In order to solve this problem, wepropose a novel prototype contrastive learning method called PrototypeContrastive Consistency Segmentation (PCCS) for semi-supervised medical imagesegmentation. The core idea is to enforce the prototypes of the same semanticclass to be closer and push the prototypes in different semantic classes faraway from each other. Specifically, we construct a signed distance map and anuncertainty map from unlabeled images. The signed distance map is used toconstruct prototypes for contrastive learning, and then we estimate theprototype uncertainty from the uncertainty map as trade-off among prototypes.In order to obtain better prototypes, based on the student-teacherarchitecture, a new mechanism named prototype updating prototype is designed toassist in updating the prototypes for contrastive learning. In addition, wepropose an uncertainty-consistency loss to mine more reliable information fromunlabeled data. Extensive experiments on medical image segmentation demonstratethat PCCS achieves better segmentation performance than the state-of-the-artmethods. The code is available at https://github.com/comphsh/PCCS.</description>
      <author>example@mail.com (Shihuan He, Zhihui Lai, Ruxin Wang, Heng Kong)</author>
      <guid isPermaLink="false">2502.06650v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundational Models for Dynamical System Reconstruction: Hierarchical Meta-Learning via Mixture of Experts</title>
      <link>http://arxiv.org/abs/2502.05335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 11 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;随着基础模型重塑科学研究，动力系统重构（DSR）中仍存在一个瓶颈：跨层次学习的能力。虽然许多元学习方法已经成功地应用于单一系统，但当面对稀疏且松散相关数据集时，这些方法就显得力不从心了。&lt;h4&gt;背景&lt;/h4&gt;在进行科学发现的过程中，基础模型正在重塑动力系统的重构（DSR），然而其主要瓶颈在于跨越不同层次的学习能力。现有的元学习方法虽然对单个系统有效，但在面对稀疏且松散相关数据集时效果不佳，尤其是在需要同时处理多个层次的情况下。&lt;h4&gt;目的&lt;/h4&gt;引入一种基于混合专家（Mixture of Experts, MoE）的新框架来克服现有模型在跨层次动力学重构中的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MixER的方法：混合专家重构器。这种方法采用稀疏的Top-1 Mixture of Expert层，并使用基于K-means和最小二乘法的自定义门控更新算法，以解决传统MoE方法在训练过程中由于梯度下降基线机制导致的学习效率低以及路由冲突问题。&lt;h4&gt;主要发现&lt;/h4&gt;混合专家重构器（MixER）通过定制化的门控更新机制实现了更高效的训练过程，并能够处理多达十个参数化常微分方程的系统。然而，在数据量非常大且每个专家只能处理一小部分高度相关的数据集时，其性能不如现有的元学习者。&lt;h4&gt;结论&lt;/h4&gt;通过合成和神经科学时间序列的数据分析表明，MixER生成上下文表示的质量与数据中层次结构的存在紧密相关。这项研究为未来解决复杂系统中的跨层次学习问题提供了新的思路和方向。&lt;h4&gt;其他要点&lt;/h4&gt;混合专家（MoE）方法具有处理多个层级系统的自然范式优势，但由于其基于梯度下降的门控更新机制，在训练过程中面临效率低下及路由冲突的问题。通过引入MixER解决了这些问题，并展示了该框架在不同领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As foundational models reshape scientific discovery, a bottleneck persists indynamical system reconstruction (DSR): the ability to learn across systemhierarchies. Many meta-learning approaches have been applied successfully tosingle systems, but falter when confronted with sparse, loosely relateddatasets requiring multiple hierarchies to be learned. Mixture of Experts (MoE)offers a natural paradigm to address these challenges. Despite their potential,we demonstrate that naive MoEs are inadequate for the nuanced demands ofhierarchical DSR, largely due to their gradient descent-based gating updatemechanism which leads to slow updates and conflicted routing during training.To overcome this limitation, we introduce MixER: Mixture of ExpertReconstructors, a novel sparse top-1 MoE layer employing a custom gating updatealgorithm based on $K$-means and least squares. Extensive experiments validateMixER's capabilities, demonstrating efficient training and scalability tosystems of up to ten parametric ordinary differential equations. However, ourlayer underperforms state-of-the-art meta-learners in high-data regimes,particularly when each expert is constrained to process only a fraction of adataset composed of highly related data points. Further analysis with syntheticand neuroscientific time series suggests that the quality of the contextualrepresentations generated by MixER is closely linked to the presence ofhierarchical structure in the data.</description>
      <author>example@mail.com (Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin)</author>
      <guid isPermaLink="false">2502.05335v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Evaluation of Deep Audio Representations for Hearables</title>
      <link>http://arxiv.org/abs/2502.06664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference on Acoustics, Speech, and Signal  Processing (ICASSP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍并发布了DEAR，这是一个用于评估基础模型在捕捉对hearables（可听设备）至关重要的声学属性的有效性的数据集和基准。&lt;h4&gt;背景&lt;/h4&gt;理解用户周围的声环境对于有效地引导可听设备至关重要。在声音场景的计算分析中，基于大模型产生了高质量、鲁棒性和多用途的声音表示。&lt;h4&gt;目的&lt;/h4&gt;为了评估基础模型捕捉对hearables至关重要的声学属性的有效性，引入并发布了DEAR数据集和基准。&lt;h4&gt;方法&lt;/h4&gt;该数据集包含1,158段30秒长的音频片段，这些音频片段通过将专有的独白与商业高品质的日常声音场景录音进行空间混合生成。评估基准涵盖了八个任务，用于评价音频场景的一般背景、语音来源及技术声学特性。&lt;h4&gt;主要发现&lt;/h4&gt;通过对四个通用音频表示模型的评估，展示了BEATs模型比其他模型表现得更好，这突显了在多样化的音频集合上训练的大模型的优势，并确认它们适用于广泛的听觉任务，包括编码hearables所需的环境属性。&lt;h4&gt;结论&lt;/h4&gt;DEAR数据集及其相关代码可用于进一步的研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;有效引导可听设备需要了解用户周围的声音环境。在声音场景的计算分析中，基础大模型已成为生成高性能、鲁棒且多功能音频表示的最佳状态方法。我们介绍了并发布了深度评估音频表示（DEAR），这是首个用于评价基础模型捕捉对hearables至关重要的声学属性的数据集和基准。该数据集包括1,158段30秒长的音频片段，这些音频片段通过将专有的独白与商业高品质的日常声音场景录音进行空间混合生成。我们的评估基准涵盖了八个任务，用于评价音频场景的一般背景、语音来源及技术声学特性。通过对四个通用音频表示模型的评估，我们展示了BEATs模型比其他模型表现得更好。这突显了在多样化的音频集合上训练的大模型的优势，并确认它们适用于广泛的听觉任务，包括编码hearables所需的环境属性。DEAR数据集及其相关代码可在https://dear-dataset.github.io获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively steering hearable devices requires understanding the acousticenvironment around the user. In the computational analysis of sound scenes,foundation models have emerged as the state of the art to producehigh-performance, robust, multi-purpose audio representations. We introduce andrelease Deep Evaluation of Audio Representations (DEAR), the first dataset andbenchmark to evaluate the efficacy of foundation models in capturing essentialacoustic properties for hearables. The dataset includes 1,158 audio tracks,each 30 seconds long, created by spatially mixing proprietary monologues withcommercial, high-quality recordings of everyday acoustic scenes. Our benchmarkencompasses eight tasks that assess the general context, speech sources, andtechnical acoustic properties of the audio scenes. Through our evaluation offour general-purpose audio representation models, we demonstrate that the BEATsmodel significantly surpasses its counterparts. This superiority underscoresthe advantage of models trained on diverse audio collections, confirming theirapplicability to a wide array of auditory tasks, including encoding theenvironment properties necessary for hearable steering. The DEAR dataset andassociated code are available at https://dear-dataset.github.io.</description>
      <author>example@mail.com (Fabian Gröger, Pascal Baumann, Ludovic Amruthalingam, Laurent Simon, Ruksana Giurda, Simone Lionetti)</author>
      <guid isPermaLink="false">2502.06664v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>RelGNN: Composite Message Passing for Relational Deep Learning</title>
      <link>http://arxiv.org/abs/2502.06784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了RelGNN，这是一种专门为捕捉关系数据库独特特性设计的新颖图神经网络框架。&lt;h4&gt;背景&lt;/h4&gt;在电子商务、医疗保健和社会媒体等现实世界应用中，基于关系数据库的预测任务至关重要。为了有效应对这些任务，关系深度学习将关系数据编码为图形，使图神经网络能够利用关系结构进行改进的预测。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的GNN框架RelGNN，旨在解决现有异构GNN在建模效率上的不足，更好地捕捉关系数据库的独特特性。&lt;h4&gt;方法&lt;/h4&gt;引入原子路线的概念，并在此基础上设计了新颖的复合消息传递机制，使不同类型的节点之间可以直接进行单跳交互。这避免了冗余聚合和信息纠缠的问题。&lt;h4&gt;主要发现&lt;/h4&gt;RelGNN在来自RelBench的30个不同的现实世界任务上进行了评估，并且始终达到了最先进的精度，最多提高了25%。&lt;h4&gt;结论&lt;/h4&gt;通过利用关系数据库的独特特性以及创新的消息传递机制，RelGNN能够更高效、准确地进行预测。&lt;h4&gt;翻译&lt;/h4&gt;基于关系数据库的预测任务在电子商务、医疗保健和社会媒体等现实世界应用中至关重要。为了有效应对这些任务，现有的图神经网络方法往往忽视了关系数据库固有的结构性质，导致建模效率低下。我们提出了一种新的框架RelGNN，它专门设计来捕捉关系数据库的独特特性，并通过引入原子路线和新颖的消息传递机制提高了预测的准确性和效率。在30个不同现实世界任务上的评估显示，RelGNN能够实现最先进的精度提升，最多提高25%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predictive tasks on relational databases are critical in real-worldapplications spanning e-commerce, healthcare, and social media. To addressthese tasks effectively, Relational Deep Learning (RDL) encodes relational dataas graphs, enabling Graph Neural Networks (GNNs) to exploit relationalstructures for improved predictions. However, existing heterogeneous GNNs oftenoverlook the intrinsic structural properties of relational databases, leadingto modeling inefficiencies. Here we introduce RelGNN, a novel GNN frameworkspecifically designed to capture the unique characteristics of relationaldatabases. At the core of our approach is the introduction of atomic routes,which are sequences of nodes forming high-order tripartite structures. Buildingupon these atomic routes, RelGNN designs new composite message passingmechanisms between heterogeneous nodes, allowing direct single-hop interactionsbetween them. This approach avoids redundant aggregations and mitigatesinformation entanglement, ultimately leading to more efficient and accuratepredictive modeling. RelGNN is evaluated on 30 diverse real-world tasks fromRelBench (Fey et al., 2024), and consistently achieves state-of-the-artaccuracy with up to 25% improvement.</description>
      <author>example@mail.com (Tianlang Chen, Charilaos Kanatsoulis, Jure Leskovec)</author>
      <guid isPermaLink="false">2502.06784v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Institutional Preferences in the Laboratory</title>
      <link>http://arxiv.org/abs/2502.06748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文研究了在社会互动中，个体如何通过改变游戏规则来促进合作。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，个人不仅被动接受静态环境，还会积极地影响和塑造自己所处的社会系统。这引发了关于动态环境下个体行为对合作的影响的讨论：是阻碍还是推动合作？&lt;h4&gt;目的&lt;/h4&gt;研究团队是否能够通过改变环境参数引导自身达到协作结果。&lt;h4&gt;方法&lt;/h4&gt;设计了一种实验室场景来测试经济游戏中不同社会困境下群体的合作情况，这些游戏在制度特征（稳定性、效率和公平性）方面有所不同。实验提供给参与者一定的行为选择自由以及对规则的二次操控权。&lt;h4&gt;主要发现&lt;/h4&gt;研究关注于自然环境中动态且可选的游戏规则如何影响合作过程，探讨了跨场景转移学习中特性间相互作用的重要性及其对于促进或阻碍协作学习的影响。&lt;h4&gt;结论&lt;/h4&gt;研究表明在具有灵活性和可调性的游戏规则下，群体可以通过改变环境参数来引导自身达到更有效率、公平的合作状态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Getting a group to adopt cooperative norms is an enduring challenge. But inreal-world settings, individuals don't just passively accept staticenvironments, they act both within and upon the social systems that structuretheir interactions. Should we expect the dynamism of player-driven changes tothe "rules of the game" to hinder cooperation -- because of the substantialadded complexity -- or help it, as prosocial agents tweak their environmenttoward non-zero-sum games? We introduce a laboratory setting to test whethergroups can guide themselves to cooperative outcomes by manipulating theenvironmental parameters that shape their emergent cooperation process. We testfor cooperation in a set of economic games that impose different socialdilemmas. These games vary independently in the institutional features ofstability, efficiency, and fairness. By offering agency over behavior alongwith second-order agency over the rules of the game, we understand emergentcooperation in naturalistic settings in which the rules of the game arethemselves dynamic and subject to choice. The literature on transfer learningin games suggests that interactions between features are important and mightaid or hinder the transfer of cooperative learning to new settings.</description>
      <author>example@mail.com (Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey)</author>
      <guid isPermaLink="false">2502.06748v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Particle Tracking with Neuromorphic Computing</title>
      <link>http://arxiv.org/abs/2502.06771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 21 figures, submitted to MDPI Particles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了神经网络架构在无监督学习条件下，通过延迟和突触权重的学习来识别带电粒子轨迹的应用。&lt;h4&gt;背景&lt;/h4&gt;利用脉冲时间依赖性可塑性规则（spike-time-dependent plasticity rule）进行学习。模型中的神经元接收有关粒子碰撞检测器中粒子击中位置的时间编码信息，该检测器基于紧凑型μ介子螺线管第二阶段探测器的几何形状。&lt;h4&gt;目的&lt;/h4&gt;展示一种尖峰神经网络如何能够完全无监督地成功识别带电粒子留下的信号，并且在存在明显噪声的情况下也能有效区分随机或组合撞击产生的假象信号。&lt;h4&gt;方法&lt;/h4&gt;使用模拟数据进行研究，该数据反映了紧凑型μ介子螺线管第二阶段探测器的几何结构和运作模式。利用神经网络模型来学习识别带电粒子轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明尖峰神经网络能够成功地在无监督条件下从背景噪声中区分出带电粒子信号。&lt;h4&gt;结论&lt;/h4&gt;这些研究开启了脉冲神经形态计算应用于粒子追踪的可能性，为进一步探索其在未来高能物理实验中的实时、低能耗的粒子跟踪应用潜力提供了动力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the application of a neural network architecture for identifyingcharged particle trajectories via unsupervised learning of delays and synapticweights using a spike-time-dependent plasticity rule. In the considered model,the neurons receive time-encoded information on the position of particle hitsin a tracking detector for a particle collider, modeled according to thegeometry of the Compact Muon Solenoid Phase II detector. We show how a spikingneural network is capable of successfully identifying in a completelyunsupervised way the signal left by charged particles in the presence ofconspicuous noise from accidental or combinatorial hits. These results open theway to applications of neuromorphic computing to particle tracking, motivatingfurther studies into its potential for real-time, low-power particle trackingin future high-energy physics experiments.</description>
      <author>example@mail.com (Emanuele Coradin, Fabio Cufino, Muhammad Awais, Tommaso Dorigo, Enrico Lupi, Eleonora Porcu, Jinu Raj, Fredrik Sandin, Mia Tosi)</author>
      <guid isPermaLink="false">2502.06771v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups</title>
      <link>http://arxiv.org/abs/2502.06695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;深度学习模型常利用训练数据中的虚假特征来达到低训练误差，这通常导致在测试分布发生变化时泛化能力差。本文提出了一种名为FairDropout的方法，通过调整记忆机制以减少对虚假相关性的依赖，并提高了对抗虚假关联的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型经常利用训练数据中的虚假特征来达到低训练误差，这使得它们在面对测试分布变化时泛化能力较差。已有多种方法被提出增强深度神经网络的稳健性，但这些方法往往无法很好地处理多数群体和少数群体之间的记忆问题。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过调整模型的记忆机制，减少对虚假相关性的依赖，并提高深度学习模型在不同子群间的公平性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;基于最近的研究发现，即记忆可以被限制为有限数量的神经元中，作者提出了名为FairDropout的方法。这种方法通过对特定神经元应用示例绑定dropout，在推理过程中删除这些神经元，从而重新定向了模型的记忆过程到特定的神经元上。&lt;h4&gt;主要发现&lt;/h4&gt;通过在包含视觉、语言和医疗任务的子群体基准套件上的实验评估，作者证明该方法显著减少了对虚假相关性的依赖，并且优于现有的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;FairDropout作为一种新颖的方法，在减少深度学习模型中虚假特征的影响方面显示出了巨大潜力。这种方法不仅提高了模型在不同环境下的鲁棒性，也增强了模型的公平性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models frequently exploit spurious features in training data toachieve low training error, often resulting in poor generalization when facedwith shifted testing distributions. To address this issue, various methods fromimbalanced learning, representation learning, and classifier recalibration havebeen proposed to enhance the robustness of deep neural networks againstspurious correlations. In this paper, we observe that models trained withempirical risk minimization tend to generalize well for examples from themajority groups while memorizing instances from minority groups. Building onrecent findings that show memorization can be localized to a limited number ofneurons, we apply example-tied dropout as a method we term FairDropout, aimedat redirecting this memorization to specific neurons that we subsequently dropout during inference. We empirically evaluate FairDropout using thesubpopulation benchmark suite encompassing vision, language, and healthcaretasks, demonstrating that it significantly reduces reliance on spuriouscorrelations, and outperforms state-of-the-art methods.</description>
      <author>example@mail.com (Geraldin Nanfack, Eugene Belilovsky)</author>
      <guid isPermaLink="false">2502.06695v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Driven Continual Graph Learning</title>
      <link>http://arxiv.org/abs/2502.06327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为PROMPTCGL的新型提示驱动的连续图学习框架，该框架旨在解决传统记忆回放方法在处理不断演化的图数据时遇到的可扩展性和隐私问题。&lt;h4&gt;背景&lt;/h4&gt;连续图学习(CGL)的目标是在不忘记先前知识的情况下适应新的任务和不断变化的图数据。主流解决方案采用基于记忆重播的思想，但这种方法面对大规模持续进化的图数据时存在可扩展性问题，并且在处理用户敏感信息时可能引发隐私担忧。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的提示驱动连续图学习(PROMPTCGL)框架，旨在解决传统方法的局限性，同时保持模型固定不变以避免先前任务知识的灾难性遗忘。&lt;h4&gt;方法&lt;/h4&gt;提出层次化提示机制，从特征和拓扑层面指导模型处理动态环境中任务图的变化。开发个性化提示生成器为每个节点生成定制化的提示，并尽量减少使用的提示数量，从而实现与图规模无关的记忆消耗量。&lt;h4&gt;主要发现&lt;/h4&gt;PROMPTCGL框架在四个基准测试中展示了比现有连续图学习方法更优越的性能和显著降低的内存占用。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的提示机制解决了持续演化图数据处理中的知识遗忘问题，并且有效减少了内存使用，证明了该方法的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：连续图学习（CGL）旨在无需忘记先前的知识的情况下适应不断演变的图形数据中新出现的任务。主流解决方案采用基于记忆回放的思想，即通过存储早期任务中的代表性数据重新训练图形模型。然而，这种策略在面对持续进化的图形时面临可扩展性问题，并且引发关于数据隐私的关注。本文受最近提示学习范式的进展启发，提出了一种新的提示驱动连续图学习（PROMPTCGL）框架，该框架为每个新任务学习一个单独的提示并保持底层图神经网络模型不变。以此方式，PROMPTCGL自然避免了先前任务知识的灾难性遗忘。具体而言，我们提出了分层提示机制，在特征和拓扑级别上引导模型以全面应对动态连续学习中任务图形的变化多样性。此外，我们开发了一个个性化提示生成器为每个图节点生成定制化提示，并尽量减少所需提示的数量，从而实现了与图形规模无关的恒定内存消耗。在四个基准测试上的广泛实验表明，PROMPTCGL相比现有的CGL方法表现出更优越的性能并显著减少了内存使用量。我们的代码可在https://github.com/QiWang98/PromptCGL获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual Graph Learning (CGL), which aims to accommodate new tasks overevolving graph data without forgetting prior knowledge, is garneringsignificant research interest. Mainstream solutions adopt the memoryreplay-based idea, ie, caching representative data from earlier tasks forretraining the graph model. However, this strategy struggles with scalabilityissues for constantly evolving graphs and raises concerns regarding dataprivacy. Inspired by recent advancements in the prompt-based learning paradigm,this paper introduces a novel prompt-driven continual graph learning(PROMPTCGL) framework, which learns a separate prompt for each incoming taskand maintains the underlying graph neural network model fixed. In this way,PROMPTCGL naturally avoids catastrophic forgetting of knowledge from previoustasks. More specifically, we propose hierarchical prompting to instruct themodel from both feature- and topology-level to fully address the variability oftask graphs in dynamic continual learning. Additionally, we develop apersonalized prompt generator to generate tailored prompts for each graph nodewhile minimizing the number of prompts needed, leading to constant memoryconsumption regardless of the graph scale. Extensive experiments on fourbenchmarks show that PROMPTCGL achieves superior performance against existingCGL approaches while significantly reducing memory consumption. Our code isavailable at https://github.com/QiWang98/PromptCGL.</description>
      <author>example@mail.com (Qi Wang, Tianfei Zhou, Ye Yuan, Rui Mao)</author>
      <guid isPermaLink="false">2502.06327v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification</title>
      <link>http://arxiv.org/abs/2502.06619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的用于增强域通用再识别（DG Re-ID）的方法，通过结合辨别式和对比性重识别模型与预训练的扩散模型，并引入一种感知相关性的条件化方案来提高特征泛化能力。&lt;h4&gt;背景&lt;/h4&gt;领域可迁移的重识别任务旨在在一个或多个源领域上训练模型，并在未见的目标领域上评估其性能。由于其实用价值，这个任务越来越受到研究者的关注。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法DCAC（扩散模型辅助表示学习和感知相关性的条件化方案），以提高域通用重识别的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法将辨别式和对比性重识别模型与预训练的扩散模型通过一种感知相关性的条件化方案相结合。该方案利用了来自重识别模型的身份分类概率，并结合一组可学习的身份提示，从而注入暗知识来捕捉身份之间的关联以指导扩散过程。同时，从扩散模型反馈的信息也通过此条件化方案反向传播到重识别模型。&lt;h4&gt;主要发现&lt;/h4&gt;在单一源域和多源域的DG Re-ID任务上进行了广泛的实验，结果表明该方法实现了最先进的性能。并且，全面消融研究表明了所提出的方法的有效性，并提供了关于其鲁棒性的见解。&lt;h4&gt;结论&lt;/h4&gt;通过利用预训练扩散模型与重识别模型之间的交互，可以显著提高特征的泛化能力，在DG Re-ID任务中取得了很好的效果。&lt;h4&gt;翻译&lt;/h4&gt;领域可迁移的重识别（DG Re-ID）旨在在一个或多个源领域上训练一个模型，并在未见的目标域上评估其性能。虽然已经提出了许多方法，但大多数依赖于辨别式或对比性学习框架来学习通用特征表示。然而，这些方法通常无法缓解捷径学习问题，导致性能不佳。本文提出了一种新的名为扩散模型辅助表示学习与感知相关性的条件化方案（DCAC）的方法来增强DG Re-ID任务的处理能力。该方法将一个辨别式和对比性重识别模型与预训练的扩散模型通过一种感知相关性的条件化方案结合在一起，从而提高特征的泛化性能。大量的实验显示，在单一源域和多源域上，我们的方法达到了最先进的性能水平，并且全面消融研究进一步验证了所提出的方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25020552&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain-generalizable re-identification (DG Re-ID) aims to train a model onone or more source domains and evaluate its performance on unseen targetdomains, a task that has attracted growing attention due to its practicalrelevance. While numerous methods have been proposed, most rely ondiscriminative or contrastive learning frameworks to learn generalizablefeature representations. However, these approaches often fail to mitigateshortcut learning, leading to suboptimal performance. In this work, we proposea novel method called diffusion model-assisted representation learning with acorrelation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our methodintegrates a discriminative and contrastive Re-ID model with a pre-traineddiffusion model through a correlation-aware conditioning scheme. Byincorporating ID classification probabilities generated from the Re-ID modelwith a set of learnable ID-wise prompts, the conditioning scheme injects darkknowledge that captures ID correlations to guide the diffusion process.Simultaneously, feedback from the diffusion model is back-propagated throughthe conditioning scheme to the Re-ID model, effectively improving thegeneralization capability of Re-ID features. Extensive experiments on bothsingle-source and multi-source DG Re-ID tasks demonstrate that our methodachieves state-of-the-art performance. Comprehensive ablation studies furthervalidate the effectiveness of the proposed approach, providing insights intoits robustness. Codes will be available at https://github.com/RikoLi/DCAC.</description>
      <author>example@mail.com (Jiachen Li, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.06619v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>IceBerg: Debiased Self-Training for Class-Imbalanced Node Classification</title>
      <link>http://arxiv.org/abs/2502.06280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IceBerg的去偏自训练框架，用于解决图神经网络在处理类别不平衡和少量样本情况时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）虽然在处理非欧几里得图结构数据方面取得了巨大成功，并被广泛应用于现实世界的应用中，但在类别不平衡的数据集中其效果往往会受到威胁。现有的大多数研究从监督学习的角度分析了类别不平衡的节点分类问题，但并未充分利用半监督场景下的大量未标记节点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自训练框架IceBerg来同时解决图神经网络在类别不平衡和少量样本情况下的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了Double Balancing策略以解决自我训练中的马太效应和标签分布偏移问题，以及通过分离传播与转换操作提升GNN的长距离传播能力。&lt;h4&gt;主要发现&lt;/h4&gt;利用未标记节点可以显著增强图神经网络在类别不平衡和少量样本场景下的性能，并且即使进行微小、手术性的修改也能带来显著的性能改进。&lt;h4&gt;结论&lt;/h4&gt;IceBerg框架在基准数据集上的系统实验表明，它能大大超越现有的类别不平衡节点分类基线。同时由于其卓越的利用无监督信号的能力，在少量样本节点分类场景中也取得了最先进的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）已在处理非欧几里得图结构数据方面取得巨大成功，并被广泛应用于许多现实世界的应用程序中。然而，它们的效果往往在类别不平衡的训练集下受到威胁。大多数现有研究从监督学习的角度分析了类别不平衡的节点分类问题，但并未充分利用半监督场景下的大量未标记节点。我们主张监督信号只是冰山一角，大量的未标记节点尚未被有效利用。在这项工作中，我们提出了一种名为IceBerg的去偏自训练框架，以同时解决图神经网络在处理类别不平衡和少量样本情况时面临的挑战。具体而言，为了解决自我训练中的马太效应和标签分布偏移问题，我们提出了双平衡策略，只需几行代码就可以作为简单的即插即用模块极大地改进现有基线的性能。其次，为了增强GNNs的长距离传播能力，我们将传播与转换操作分开。因此，弱监督信号可以更有效地传播到未标记节点中以解决少量样本问题。总之，我们发现利用未标记节点可以在类别不平衡和少量样本场景下显著提高图神经网络的性能，并且即使是微小、手术性的修改也可以带来可观的性能改进。基准数据集上的系统实验表明我们的方法能大大超越现有的类别不平衡节点分类基线。此外，由于IceBerg卓越地利用无监督信号的能力，在少量样本节点分类场景中也取得了最先进的结果。IceBerg代码可在https://github.com/ZhixunLEE/IceBerg获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved great success in dealing withnon-Euclidean graph-structured data and have been widely deployed in manyreal-world applications. However, their effectiveness is often jeopardizedunder class-imbalanced training sets. Most existing studies have analyzedclass-imbalanced node classification from a supervised learning perspective,but they do not fully utilize the large number of unlabeled nodes insemi-supervised scenarios. We claim that the supervised signal is just the tipof the iceberg and a large number of unlabeled nodes have not yet beeneffectively utilized. In this work, we propose IceBerg, a debiasedself-training framework to address the class-imbalanced and few-shot challengesfor GNNs at the same time. Specifically, to figure out the Matthew effect andlabel distribution shift in self-training, we propose Double Balancing, whichcan largely improve the performance of existing baselines with just a few linesof code as a simple plug-and-play module. Secondly, to enhance the long-rangepropagation capability of GNNs, we disentangle the propagation andtransformation operations of GNNs. Therefore, the weak supervision signals canpropagate more effectively to address the few-shot issue. In summary, we findthat leveraging unlabeled nodes can significantly enhance the performance ofGNNs in class-imbalanced and few-shot scenarios, and even small, surgicalmodifications can lead to substantial performance improvements. Systematicexperiments on benchmark datasets show that our method can deliver considerableperformance gain over existing class-imbalanced node classification baselines.Additionally, due to IceBerg's outstanding ability to leverage unsupervisedsignals, it also achieves state-of-the-art results in few-shot nodeclassification scenarios. The code of IceBerg is available at:https://github.com/ZhixunLEE/IceBerg.</description>
      <author>example@mail.com (Zhixun Li, Dingshuo Chen, Tong Zhao, Daixin Wang, Hongrui Liu, Zhiqiang Zhang, Jun Zhou, Jeffrey Xu Yu)</author>
      <guid isPermaLink="false">2502.06280v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Clustering-based Prototypes for Compositional Zero-shot Learning</title>
      <link>http://arxiv.org/abs/2502.06501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025; Project page:  https://github.com/quhongyu/ClusPro&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ClusPro的框架，该框架旨在解决组成零样本学习（CZSL）中的挑战，通过开发一个基于聚类的原型挖掘框架来应对现有解决方案中过度简化的数据假设问题。&lt;h4&gt;背景&lt;/h4&gt;在构成性零样本学习（Compositional Zero-Shot Learning, CZSL）领域，从已知组合中学习基本概念是主要的挑战。现有的CZSL解决方案往往依赖于过于简单的数据假设，并忽视了属性或对象在与其他实体结合时的自然多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的原型挖掘框架来解决现有CZSL方法中的局限性问题。&lt;h4&gt;方法&lt;/h4&gt;ClusPro通过聚类技术自动发现和动态更新嵌入空间中的原型，进而构建出一个结构良好且独立的基本概念（属性或对象）表示空间。这些原型用于进行基于对比学习的去相关化学习，确保了同类内部分离和不同类型之间的去相关。&lt;h4&gt;主要发现&lt;/h4&gt;ClusPro框架在多个基准测试中表现出色，在闭集世界和开放世界的设置下均超越了许多领先的CZSL解决方案。&lt;h4&gt;结论&lt;/h4&gt;ClusPro提供了一种无需引入额外可学习参数或计算预算即可进行原型聚类的有效方法，从而为解决构成性零样本学习问题开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning primitive (i.e., attribute and object) concepts from seencompositions is the primary challenge of Compositional Zero-Shot Learning(CZSL). Existing CZSL solutions typically rely on oversimplified dataassumptions, e.g., modeling each primitive with a single centroid primitiverepresentation, ignoring the natural diversities of the attribute (resp.object) when coupled with different objects (resp. attribute). In this work, wedevelop ClusPro, a robust clustering-based prototype mining framework for CZSLthat defines the conceptual boundaries of primitives through a set ofdiversified prototypes. Specifically, ClusPro conducts within-primitiveclustering on the embedding space for automatically discovering and dynamicallyupdating prototypes. These representative prototypes are subsequently used torepaint a well-structured and independent primitive embedding space, ensuringintra-primitive separation and inter-primitive decorrelation throughprototype-based contrastive learning and decorrelation learning. Moreover,ClusPro efficiently performs prototype clustering in a non-parametric fashionwithout the introduction of additional learnable parameters or computationalbudget during testing. Experiments on three benchmarks demonstrate ClusProoutperforms various top-leading CZSL solutions under both closed-world andopen-world settings.</description>
      <author>example@mail.com (Hongyu Qu, Jianan Wei, Xiangbo Shu, Wenguan Wang)</author>
      <guid isPermaLink="false">2502.06501v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos</title>
      <link>http://arxiv.org/abs/2502.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种无需人工标注的自动对齐斑马鱼胚胎发育阶段的方法。&lt;h4&gt;背景&lt;/h4&gt;斑马鱼在生物医学研究中被广泛使用，其胚胎发育阶段需要同步以进行进一步分析。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来从3D+t点云数据提取描述性特征，并将相应的发展阶段时间上对齐。&lt;h4&gt;方法&lt;/h4&gt;设计了一种自编码器架构用于学习点云的描述表示，并采用深度回归网络实现它们的时间对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实现了高达98.14%的对齐准确度，平均偏差仅为3.83分钟，在整个实验持续时间5.3小时的情况下表现优异。&lt;h4&gt;结论&lt;/h4&gt;作为一种完全无监督的方法，无需手动标记和主观偏见影响，易于扩展且避免了人工分析的限制。&lt;h4&gt;翻译&lt;/h4&gt;斑马鱼在生物医学研究中广泛用于胚胎发育阶段的研究。为了对这些阶段进行同步分析，研究人员提出了一种新的方法，该方法通过自动编码器架构学习点云数据，并使用深度回归网络将不同时间点的数据进行精确的时间对齐，平均偏差仅为3.83分钟，整个实验过程中无须人工干预或标签输入。这种方法不仅提高了研究效率，而且减少了主观偏见的影响，并且能够适应大规模数据分析的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-43993-3_58&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zebrafish are widely used in biomedical research and developmental stages oftheir embryos often need to be synchronized for further analysis. We present anunsupervised approach to extract descriptive features from 3D+t point clouds ofzebrafish embryos and subsequently use those features to temporally aligncorresponding developmental stages. An autoencoder architecture is proposed tolearn a descriptive representation of the point clouds and we designed a deepregression network for their temporal alignment. We achieve a high alignmentaccuracy with an average mismatch of only 3.83 minutes over an experimentalduration of 5.3 hours. As a fully-unsupervised approach, there is no manuallabeling effort required and unlike manual analyses the method easily scales.Besides, the alignment without human annotation of the data also avoids anyinfluence caused by subjective bias.</description>
      <author>example@mail.com (Zhu Chen, Ina Laube, Johannes Stegmaier)</author>
      <guid isPermaLink="false">2502.06543v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images</title>
      <link>http://arxiv.org/abs/2502.06615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于DINOv2和UNet的框架，用于从心脏MRI图像中自动分割左心房（LA），以提高心血管疾病诊断和管理的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确地从延迟钆增强磁共振成像中分割出左心房对可视化病变的心脏结构至关重要，特别是在使用消融疗法治疗心房颤动时。然而，手动分割耗时且容易出现观察者间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的解决方案来提高心脏MRI图像中左心房的分割精度。&lt;h4&gt;方法&lt;/h4&gt;将类不可知基础模型DINOv2作为编码器，与UNet风格解码器结合，并加入多尺度特征融合和输入图像集成以增强分割准确性。引入了可学习加权机制以及在解码阶段重新引入原始输入图象来保持高分辨率空间细节。&lt;h4&gt;主要发现&lt;/h4&gt;通过LAScarQS 2022数据集验证，该方法比nnUNet基线模型的性能有所提高，在大型架构下Dice分数为92.3%，IoU得分为84.1%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明了所提出的方法在自动左心房分割领域的有效性。&lt;h4&gt;翻译&lt;/h4&gt;准确地从延迟钆增强磁共振成像中分割出左心房对于可视化病变的心脏结构至关重要，特别是在使用消融疗法治疗心房颤动时。然而，手动分割耗时且容易出现观察者间差异。为了应对这一挑战，研究团队提出了一种结合DINOv2作为编码器和UNet风格解码器的框架，并通过多尺度特征融合和输入图像集成来增强分割准确性。实验结果表明，在LAScarQS 2022数据集上的Dice分数达到92.3%，IoU得分为84.1%。这突显了该方法在自动左心房分割领域的有效性，有望推动相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate segmentation of the left atrium (LA) from late gadolinium-enhancedmagnetic resonance imaging plays a vital role in visualizing diseased atrialstructures, enabling the diagnosis and management of cardiovascular diseases.It is particularly essential for planning treatment with ablation therapy, akey intervention for atrial fibrillation (AF). However, manual segmentation istime-intensive and prone to inter-observer variability, underscoring the needfor automated solutions. Class-agnostic foundation models like DINOv2 havedemonstrated remarkable feature extraction capabilities in vision tasks.However, their lack of domain specificity and task-specific adaptation canreduce spatial resolution during feature extraction, impacting the capture offine anatomical detail in medical imaging. To address this limitation, wepropose a segmentation framework that integrates DINOv2 as an encoder with aUNet-style decoder, incorporating multi-scale feature fusion and input imageintegration to enhance segmentation accuracy. The learnable weighting mechanismdynamically prioritizes hierarchical features from different encoder blocks ofthe foundation model, optimizing feature selection for task relevance.Additionally, the input image is reintroduced during the decoding stage topreserve high-resolution spatial details, addressing limitations ofdownsampling in the encoder. We validate our approach on the LAScarQS 2022dataset and demonstrate improved performance with a 92.3% Dice and 84.1% IoUscore for giant architecture compared to the nnUNet baseline model. Thesefindings emphasize the efficacy of our approach in advancing the field ofautomated left atrium segmentation from cardiac MRI.</description>
      <author>example@mail.com (Bipasha Kundu, Zixin Yang, Richard Simon, Cristian Linte)</author>
      <guid isPermaLink="false">2502.06615v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Structure-preserving contrastive learning for spatial time series</title>
      <link>http://arxiv.org/abs/2502.06380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TL;DR: Preserving certain structures of similarity relations in  spatio-temporal data can improve downstream task performance via contrastive  learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的自监督学习方法，通过引入两个结构保持正则化器来增强时空序列（如交通互动）的信息表示，并展示了该方法在多变量时间序列分类、宏观和微观交通预测中的有效性。&lt;h4&gt;背景&lt;/h4&gt;时空序列数据的表示学习面临挑战，尤其是在维护隐藏空间中细粒度相似性关系时。自监督学习需要有效的方法来保持结构信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入两个新的正则化器改进对比学习方法，并提出动态机制以适应性调整权衡，从而提高模型在时空序列任务中的表现和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;论文提出了两个用于对比学习的结构保持正则化器：一个保持实例间的相似性的拓扑结构，另一个保持跨空间和时间维度的图几何结构。此外，还提出了一种动态机制来平衡对比学习与结构保存之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法在多变量时间序列分类、宏观及微观交通预测任务中显著提高了现有最佳性能，并展示了更高相似性结构保留意味着更具有信息量和有用性的表示。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种通用且有效的自监督学习框架，对于时空或地理特征的时间序列特别有益。这一方法有助于理解神经网络在模式识别中的表征学习贡献，并公开了相关代码和数据。&lt;h4&gt;翻译&lt;/h4&gt;本文通过引入两个结构保持正则化器改进对比学习的方法来增强时空序列的数据表示，从而提高自监督模型的性能及泛化能力。该研究显示所提出的方法能更有效地保留相似性关系的结构，并在多变量时间序列分类以及宏观和微观交通预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Informative representations enhance model performance and generalisability indownstream tasks. However, learning self-supervised representations forspatially characterised time series, like traffic interactions, poseschallenges as it requires maintaining fine-grained similarity relations in thelatent space. In this study, we incorporate two structure-preservingregularisers for the contrastive learning of spatial time series: oneregulariser preserves the topology of similarities between instances, and theother preserves the graph geometry of similarities across spatial and temporaldimensions. To balance contrastive learning and structure preservation, wepropose a dynamic mechanism that adaptively weighs the trade-off and stabilisestraining. We conduct experiments on multivariate time series classification, aswell as macroscopic and microscopic traffic prediction. For all three tasks,our approach preserves the structures of similarity relations more effectivelyand improves state-of-the-art task performances. The proposed approach can beapplied to an arbitrary encoder and is particularly beneficial for time serieswith spatial or geographical features. Furthermore, this study suggests thathigher similarity structure preservation indicates more informative and usefulrepresentations. This may help to understand the contribution of representationlearning in pattern recognition with neural networks. Our code is made openlyaccessible with all resulting data at https://github.com/yiru-jiao/spclt.</description>
      <author>example@mail.com (Yiru Jiao, Sander van Cranenburgh, Simeon Calvert, Hans van Lint)</author>
      <guid isPermaLink="false">2502.06380v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Physically-Based Mesh Generation for Confined 3D Point Clouds Using Flexible Foil Models</title>
      <link>http://arxiv.org/abs/2502.06541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个通过模拟空间约束下的柔性箔片来从受限的3D点云构造高质量封闭表面网格的方法。&lt;h4&gt;背景&lt;/h4&gt;在计算机图形学和计算几何领域，需要一种能够生成物理上准确且现实的网格结构的技术方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于物理的模拟技术，用于从3D点云数据中创建高真实性和物理准确性要求的闭合表面网格。&lt;h4&gt;方法&lt;/h4&gt;采用动态弹性、压力驱动变形以及自适应固定顶点捕获等机制来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法可以有效地构建高质量且封闭的表面网格，适用于各种计算机图形学和计算几何的应用场景。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为从受限3D点云构造物理上准确的闭合表面网格提供了一个稳健框架，并展示了其在计算机图形学和计算几何领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种通过模拟空间约束下的柔性箔片来从限制性3D点云中构建高质量封闭表面网格的方法。该方法结合了动态弹性、压力驱动变形以及固定顶点的自适应捕捉，提供了一个用于创建现实且物理准确网格的强大框架。讨论了这种方法在计算机图形学和计算几何中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a method for constructing high-quality, closed-surface meshes fromconfined 3D point clouds via a physically-based simulation of flexible foilsunder spatial constraints. The approach integrates dynamic elasticity,pressure-driven deformation, and adaptive snapping to fixed vertices, providinga robust framework for realistic and physically accurate mesh creation.Applications in computer graphics and computational geometry are discussed.</description>
      <author>example@mail.com (Netzer Moriya)</author>
      <guid isPermaLink="false">2502.06541v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?</title>
      <link>http://arxiv.org/abs/2502.06555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;差分隐私（DP）合成数据是一种使私人数据分析成为可能的多功能工具。近年来，在大型语言模型（LLMs）方面的进展激发了许多改进DP合成数据生成的技术。&lt;h4&gt;目的&lt;/h4&gt;提出两种仅需访问基础模型API就能进行DP合成表格数据算法的方法，并探讨这些方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;{'私有演化算法扩展': '将适用于图像和文本数据的Private Evolution算法（Lin et al., 2023; Xie et al., 2024）适应到表格数据领域，定义基于查询工作负载的距离度量。', '一次性API访问算法': '提出一系列使用一次性的LLM API访问，而不是对LLM进行自适应查询的算法家族。'}&lt;h4&gt;主要发现&lt;/h4&gt;强大的LLMs通过API访问并不总是能提高DP合成数据的质量，这与不使用此类访问的传统基线方法相比。&lt;h4&gt;结论&lt;/h4&gt;提供关于为何这种现象发生的原因，并提出改进LLMs的具体建议，使它们更加适用于此类应用。&lt;h4&gt;翻译&lt;/h4&gt;差分隐私（DP）合成数据是处理私人数据分析的一种多功能工具。大型语言模型的最新进展激发了一系列旨在改善DP合成数据生成技术的方法。一种方法通过在基础模型权重上进行差分私有微调来实现；然而，最先进的模型的权重可能不会公开共享。本研究提出两种仅需API访问到基础模型就能执行DP合成表格数据算法。我们适应了适用于图像和文本数据的Private Evolution算法（Lin et al., 2023; Xie et al., 2024），并将它应用于表格数据领域，定义了一种基于查询工作负载的距离度量。此外，提出了一系列使用单次API访问到LLM的方法而非多次自适应查询到LLM的算法家族。我们的研究结果表明，通过API访问强大的LLMs并不总是能够提高DP合成数据的质量，与传统基线方法相比，并提供了导致这一现象的根本原因以及改进LLMs以使其在这个应用中更有效的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentially private (DP) synthetic data is a versatile tool for enablingthe analysis of private data. Recent advancements in large language models(LLMs) have inspired a number of algorithm techniques for improving DPsynthetic data generation. One family of approaches uses DP finetuning on thefoundation model weights; however, the model weights for state-of-the-artmodels may not be public. In this work we propose two DP synthetic tabular dataalgorithms that only require API access to the foundation model. We adapt thePrivate Evolution algorithm (Lin et al., 2023; Xie et al., 2024) -- which wasdesigned for image and text data -- to the tabular data domain. In ourextension of Private Evolution, we define a query workload-based distancemeasure, which may be of independent interest. We propose a family ofalgorithms that use one-shot API access to LLMs, rather than adaptive queriesto the LLM. Our findings reveal that API-access to powerful LLMs does notalways improve the quality of DP synthetic data compared to establishedbaselines that operate without such access. We provide insights into theunderlying reasons and propose improvements to LLMs that could make them moreeffective for this application.</description>
      <author>example@mail.com (Marika Swanberg, Ryan McKenna, Edo Roth, Albert Cheu, Peter Kairouz)</author>
      <guid isPermaLink="false">2502.06555v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Koopman-Equivariant Gaussian Processes</title>
      <link>http://arxiv.org/abs/2502.06645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 28th International Conference on Artificial  Intelligence and Statistics (AISTATS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了针对线性时不变响应的动力系统的一系列高斯过程（GP）模型，该类模型仅在初始条件上是非线性的。这种线性特性允许同时可追踪地量化预测和表示不确定性，并简化了从基于GP的动力学系统中计算轨迹分布的挑战。&lt;h4&gt;背景&lt;/h4&gt;可靠的决策制定需要对动力系统的可信预测及表征学习的能力不断提高。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的高斯过程（GP）模型家族，用于解决线性时不变响应的动力系统中的可预测性和表示不确定性问题，并采用基于诱导点的变分推理方法支持大规模回归。&lt;h4&gt;方法&lt;/h4&gt;使用了轨迹等价性的概念——称为“Koopman等价性”——来提高GP模型的一般化能力。同时采用了基于适当诱导点的变分推断，以应对大规模回归的任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示所提出的模型在预测性能上与基于核的方法学习动力系统时相比，至少相当且有时更好。&lt;h4&gt;结论&lt;/h4&gt;通过利用线性响应特性及Koopman等价性的概念，能够有效地解决从高斯过程驱动的动力学系统中推断轨迹分布的问题，并展示了该方法的有效性和潜在优势。&lt;h4&gt;翻译&lt;/h4&gt;可信的预测和表示学习对于动力系统的可靠决策至关重要。为此，我们提出了针对线性时不变响应的动力系统的一系列高斯过程（GP）模型，这些模型仅在初始条件上是非线性的。这种线性特性使我们可以同时可追踪地量化预测和表示不确定性，并简化了从基于GP的动力学系统中计算轨迹分布的挑战。利用一种被称为“Koopman等价性”的轨迹等价性概念，我们得到了一个具有增强泛化能力的GP模型。为了支持大规模回归，我们在框架中引入了基于适当诱导点的变分推理方法。实验结果表明，与用于学习动力系统的基于核的方法相比，我们的预测性能至少相当且通常更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Credible forecasting and representation learning of dynamical systems are ofever-increasing importance for reliable decision-making. To that end, wepropose a family of Gaussian processes (GP) for dynamical systems with lineartime-invariant responses, which are nonlinear only in initial conditions. Thislinearity allows us to tractably quantify forecasting and representationaluncertainty, simultaneously alleviating the challenge of computing thedistribution of trajectories from a GP-based dynamical system and enabling anew probabilistic treatment of learning Koopman operator representations. Usinga trajectory-based equivariance -- which we refer to as \textit{Koopmanequivariance} -- we obtain a GP model with enhanced generalizationcapabilities. To allow for large-scale regression, we equip our framework withvariational inference based on suitable inducing points. Experimentsdemonstrate on-par and often better forecasting performance compared tokernel-based methods for learning dynamical systems.</description>
      <author>example@mail.com (Petar Bevanda, Max Beier, Armin Lederer, Alexandre Capone, Stefan Sosnowski, Sandra Hirche)</author>
      <guid isPermaLink="false">2502.06645v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Hyperparameters in Score-Based Membership Inference Attacks</title>
      <link>http://arxiv.org/abs/2502.06374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted for publication in the 3rd IEEE  Conference on Secure and Trustworthy Machine Learning (SaTML'25). The final  version will be available on IEEE Xplore&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Membership Inference Attacks (MIA) 方法，展示了在转移学习环境中进行MIA时，攻击者不需要知道目标模型的超参数。通过匹配目标和影子模型的输出分布来选择合适的超参数。&lt;h4&gt;背景&lt;/h4&gt;现有的基于分数的MIA方法假设攻击者了解目标模型的超参数，这些信息可用于训练用于攻击的影子模型。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法，在不知道目标模型超参数的情况下，为影子模型选择适当的超参数以进行有效的MIA。&lt;h4&gt;方法&lt;/h4&gt;通过匹配输出分布来选择适合的超参数。这种方法在性能上与使用实际目标模型超参数训练得到的结果相近。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，提出的基于输出分布的方法能够找到近似的目标模型的超参数，并且这种新方法不会因为进行超参数优化而增加MIA攻击的风险。&lt;h4&gt;结论&lt;/h4&gt;新的MIA方法不需要了解目标模型的具体信息就能有效地执行。此外，在使用训练数据进行超参数优化时，不同隐私保护机制下的隐私风险差异不大。&lt;h4&gt;翻译&lt;/h4&gt;成员推断攻击（MIAs）已成为评估机器学习模型隐私泄漏的有价值的框架。基于分数的MIAs尤其因为能够利用模型为特定输入生成的信心得分而著称。现有的基于分数的MIA方法隐含地假设攻击者可以访问目标模型的超参数，这些信息可用于训练影子模型进行攻击。在这项工作中，我们证明了在转移学习环境中执行MIA并不需要知道目标模型的超参数知识。基于此，当攻击者没有关于其先前的知识时，我们提出了一个新方法来选择用于训练影子模型以进行MIA的超参数，通过匹配目标和影子模型的输出分布实现。我们展示了使用这种方法可以得到几乎与利用实际目标超参数训练出来的影子模型效果相当的超参数集合。此外，我们研究了在不同的隐私保护机制下，未考虑到的用于训练数据进行超参数优化（HPO）的实践隐私风险，并没有发现显著统计证据表明使用训练数据执行超参数优化会增加对MIA攻击的脆弱性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Membership Inference Attacks (MIAs) have emerged as a valuable framework forevaluating privacy leakage by machine learning models. Score-based MIAs aredistinguished, in particular, by their ability to exploit the confidence scoresthat the model generates for particular inputs. Existing score-based MIAsimplicitly assume that the adversary has access to the target model'shyperparameters, which can be used to train the shadow models for the attack.In this work, we demonstrate that the knowledge of target hyperparameters isnot a prerequisite for MIA in the transfer learning setting. Based on this, wepropose a novel approach to select the hyperparameters for training the shadowmodels for MIA when the attacker has no prior knowledge about them by matchingthe output distributions of target and shadow models. We demonstrate that usingthe new approach yields hyperparameters that lead to an attack nearindistinguishable in performance from an attack that uses targethyperparameters to train the shadow models. Furthermore, we study the empiricalprivacy risk of unaccounted use of training data for hyperparameteroptimization (HPO) in differentially private (DP) transfer learning. We find nostatistically significant evidence that performing HPO using training datawould increase vulnerability to MIA.</description>
      <author>example@mail.com (Gauri Pradhan, Joonas Jälkö, Marlon Tobaben, Antti Honkela)</author>
      <guid isPermaLink="false">2502.06374v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model</title>
      <link>http://arxiv.org/abs/2502.06438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures, 5 tables, pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为FEMBA的新型自我监督框架，用于高效和准确地分析长时间EEG记录。该模型通过双向状态空间建模，在资源受限环境中表现出色。&lt;h4&gt;背景&lt;/h4&gt;精确且高效的脑电图（EEG）分析对于检测长期监测中的癫痫发作和伪迹至关重要，并广泛应用于医院诊断到可穿戴健康设备等领域。&lt;h4&gt;目的&lt;/h4&gt;提出FEMBA框架，以解决传统深度学习模型在处理长时间EEG数据时的计算资源限制问题。&lt;h4&gt;方法&lt;/h4&gt;使用超过21000小时未标记的EEG数据训练FEMBA，并对三个下游任务进行微调。与基于Transformer的模型相比，FEMBA通过线性扩展序列长度实现更高效的处理。&lt;h4&gt;主要发现&lt;/h4&gt;在TUAB任务上达到81.82%的平衡准确率（AUROC为0.8921），在TUAR任务上的AUROC为0.949；一种只有7.8M参数的小型变体也表现出良好的性能，适用于资源受限设备。&lt;h4&gt;结论&lt;/h4&gt;FEMBA框架不仅能够提供高效的EEG分析，在临床应用和可穿戴技术方面也有巨大潜力。这项工作证明了其在处理大规模长时间记录中的优越性，并且为未来的研究铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;精确而高效的脑电图（EEG）分析对于检测长期监测中的癫痫发作和伪迹至关重要，应用场景包括医院诊断到可穿戴健康设备等。强大的EEG分析有潜力极大地改善患者的护理质量。然而，传统的深度学习模型，特别是基于Transformer的架构，在时间和内存复杂性上具有二次特性，使得它们在资源受限环境下不太适用。为了解决这些问题，我们提出了FEMBA（基础EEG曼巴+双向架构），这是一个新颖的自我监督框架，通过双向状态空间建模建立了新的效率基准。与基于Transformer的模型不同，后者由于时间和内存复杂性而具有二次特性，FEMBA随着序列长度线性扩展，能够更有效地处理延长的EEG记录。在超过21,000小时未标记的EEG数据和三个下游任务上的微调之后，FEMBA与转换器模型相比实现了竞争力的表现，并且计算成本显著降低。具体而言，在TUAB上实现81.82%的平衡准确率（AUROC为0.8921），在TUAR上达到0.949 AUROC；一个只有7.8M参数的小型变体显示了在资源受限设备上的适用性。这些结果为临床EEG分析提供了可扩展、通用的方法，并强调FEMBA是可穿戴应用的有希望的候选者。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient electroencephalography (EEG) analysis is essential fordetecting seizures and artifacts in long-term monitoring, with applicationsspanning hospital diagnostics to wearable health devices. Robust EEG analyticshave the potential to greatly improve patient care. However, traditional deeplearning models, especially Transformer-based architectures, are hindered bytheir quadratic time and memory complexity, making them less suitable forresource-constrained environments. To address these challenges, we presentFEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novelself-supervised framework that establishes new efficiency benchmarks for EEGanalysis through bidirectional state-space modeling. Unlike Transformer-basedmodels, which incur quadratic time and memory complexity, FEMBA scales linearlywith sequence length, enabling more scalable and efficient processing ofextended EEG recordings. Trained on over 21,000 hours of unlabeled EEG andfine-tuned on three downstream tasks, FEMBA achieves competitive performance incomparison with transformer models, with significantly lower computationalcost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUABand 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstratesviability for resource-constrained devices. These results pave the way forscalable, general-purpose EEG analytics in both clinical and highlight FEMBA asa promising candidate for wearable applications.</description>
      <author>example@mail.com (Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li)</author>
      <guid isPermaLink="false">2502.06438v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>A Data-Efficient Pan-Tumor Foundation Model for Oncology CT Interpretation</title>
      <link>http://arxiv.org/abs/2502.06171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  57 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;人工智能辅助影像分析在肿瘤诊断和管理方面取得了显著进展。本文介绍了PASTA，这是一种全肿瘤CT基础模型，在46个代表性肿瘤学任务中的45项上实现了最先进的性能——包括病灶分割、平扫CT中肿瘤检测、肿瘤分期、生存预测、结构化报告生成以及跨模态迁移学习等，并在其中35个任务中显著优于次佳模型。&lt;h4&gt;背景&lt;/h4&gt;人工智能辅助影像分析已经在肿瘤诊断和管理领域取得了重要进展。然而，缺乏高质量的公开标注数据集已成为CT基础模型开发的重要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;介绍PASTA，一个在多项代表性肿瘤学任务上表现出色的全肿瘤CT基础模型，并展示其通过合成数据生成框架PASTA-Gen来解决数据稀缺问题的方法和性能。&lt;h4&gt;方法&lt;/h4&gt;研发了创新性的合成肿瘤生成框架PASTA-Gen，生产出包含来自十种器官的恶性病变及五类良性病变在内的30,000张CT扫描图像及其像素级标注病灶和配对的结构化报告。通过这种高质量、丰富的合成数据集解决了公开可用且高质量的数据稀缺问题。&lt;h4&gt;主要发现&lt;/h4&gt;PASTA在多个任务上超越了现有最佳模型，尤其是在生存预测及跨模态迁移学习方面表现突出；该模型具有出色的数据效率，在仅少量真实世界数据的支持下，其性能得到了显著提升。&lt;h4&gt;结论&lt;/h4&gt;通过公开发布合成数据集和PASTA基础模型，有效解决了数据稀缺问题，并促进了肿瘤学研究与临床应用的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence-assisted imaging analysis has made substantialstrides in tumor diagnosis and management. Here we present PASTA, a pan-tumorCT foundation model that achieves state-of-the-art performance on 45 of 46representative oncology tasks -- including lesion segmentation, tumor detectionin plain CT, tumor staging, survival prediction, structured report generation,and cross-modality transfer learning, significantly outperforming thesecond-best models on 35 tasks. This remarkable advancement is driven by ourdevelopment of PASTA-Gen, an innovative synthetic tumor generation frameworkthat produces a comprehensive dataset of 30,000 CT scans with pixel-levelannotated lesions and paired structured reports, encompassing malignanciesacross ten organs and five benign lesion types. By leveraging this rich,high-quality synthetic data, we overcome a longstanding bottleneck in thedevelopment of CT foundation models -- specifically, the scarcity of publiclyavailable, high-quality annotated datasets due to privacy constraints and thesubstantial labor required for scaling precise data annotation. Encouragingly,PASTA demonstrates exceptional data efficiency with promising practical value,markedly improving performance on various tasks with only a small amount ofreal-world data. The open release of both the synthetic dataset and PASTAfoundation model effectively addresses the challenge of data scarcity, therebyadvancing oncological research and clinical translation.</description>
      <author>example@mail.com (Wenhui Lei, Hanyu Chen, Zitian Zhang, Luyang Luo, Qiong Xiao, Yannian Gu, Peng Gao, Yankai Jiang, Ci Wang, Guangtao Wu, Tongjia Xu, Yingjie Zhang, Xiaofan Zhang, Pranav Rajpurkar, Shaoting Zhang, Zhenning Wang)</author>
      <guid isPermaLink="false">2502.06171v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>AppVLM: A Lightweight Vision Language Model for Online App Control</title>
      <link>http://arxiv.org/abs/2502.06395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了一种名为AppVLM的轻量级Vision-Language Model (VLM)，用于解决智能手机助手（appagents）面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;当前的方法在使用大型专有模型时计算成本高昂，而采用小型微调模型则难以适应分布外任务。这些限制阻碍了智能助手的有效利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级且高效的解决方案来克服现有方法的局限性，以便更好地执行人类指令。&lt;h4&gt;方法&lt;/h4&gt;1. 在AndroidControl数据集上离线微调AppVLM；2. 收集来自AndroidWorld环境的数据，并进行额外的训练迭代以优化策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相比于所有评估的基础模型，在离线评测时AppVLM具有最高的动作预测准确率。在线任务完成成功率与GPT-4o相当，但速度提高了10倍。&lt;h4&gt;结论&lt;/h4&gt;AppVLM作为一种实用且高效的解决方案，非常适合现实世界的部署应用。&lt;h4&gt;翻译&lt;/h4&gt;基础模型作为智能手机助手（统称为appagents）的应用是一个重要的研究挑战。这些助手旨在通过解析文本指令并通过设备界面执行操作来完成人类命令。尽管有前景，但现有方法面临着重大限制：使用大型专有模型如GPT-4o的方法计算成本高昂；而采用小型微调模型的方法则往往无法适应分布外任务。本工作引入了一种轻量级的Vision-Language Model (VLM)，名为AppVLM。首先，在AndroidControl数据集上离线对其进行微调，然后通过在AndroidWorld环境中收集数据并进行额外训练迭代来优化其策略。实验结果表明，与所有评估的基础模型相比，AppVLM在离线评估时实现了最高的动作预测准确率，并且在线任务完成成功率与GPT-4o相当，在AndroidWorld环境中的速度提高了10倍。因此，AppVLM为现实世界的部署提供了一个实用且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The utilisation of foundation models as smartphone assistants, termed appagents, is a critical research challenge. These agents aim to execute humaninstructions on smartphones by interpreting textual instructions and performingactions via the device's interface. While promising, current approaches facesignificant limitations. Methods that use large proprietary models, such asGPT-4o, are computationally expensive, while those that use smaller fine-tunedmodels often lack adaptability to out-of-distribution tasks. In this work, weintroduce AppVLM, a lightweight Vision-Language Model (VLM). First, wefine-tune it offline on the AndroidControl dataset. Then, we refine its policyby collecting data from the AndroidWorld environment and performing furthertraining iterations. Our results indicate that AppVLM achieves the highestaction prediction accuracy in offline evaluation on the AndroidControl dataset,compared to all evaluated baselines, and matches GPT-4o in online taskcompletion success rate in the AndroidWorld environment, while being up to tentimes faster. This makes AppVLM a practical and efficient solution forreal-world deployment.</description>
      <author>example@mail.com (Georgios Papoudakis, Thomas Coste, Zhihao Wu, Jianye Hao, Jun Wang, Kun Shao)</author>
      <guid isPermaLink="false">2502.06395v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks at a Fraction</title>
      <link>http://arxiv.org/abs/2502.06136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, accepted at PAKKD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了Quaternion Message Passing Neural Networks (QMPNNs)，这是一种通过利用四元数空间来计算节点表示的框架，旨在减少模型大小的同时保持与原始尺寸GNN相当的准确性。&lt;h4&gt;背景&lt;/h4&gt;图形神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实数值GNN外，四元数GNN在处理图结构数据的任务中也表现出色。&lt;h4&gt;目的&lt;/h4&gt;为了降低能源消耗，该研究旨在减少模型大小，同时保持与原始尺寸的GNN相当的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出Quaternion Message Passing Neural Networks (QMPNNs)框架，并采用四元数表示以减少参数量。同时重新定义了Graph Lottery Tickets的概念，应用于GNN和QMPNN中寻找可训练模型参数更少的初始化方案。&lt;h4&gt;主要发现&lt;/h4&gt;提出的QMPNN框架以及用于GNN和QMPNN中的LTH方法在三个基本图任务（节点分类、链接预测和图形分类）上验证了其有效性，并在实际数据集上的表现良好。&lt;h4&gt;结论&lt;/h4&gt;通过使用四元数表示的QMPNN框架可以显著减少模型参数，同时保持与传统GNN相似的表现。此外，在GNN和QMPNN中应用Graph Lottery Tickets的概念有助于进一步优化可训练模型参数的数量。&lt;h4&gt;翻译&lt;/h4&gt;图形神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实数值的GNN外，四元数GNN在处理图结构数据的任务中也表现出色。为了减少能耗，我们在保持相当精度的同时缩小了模型大小。本文介绍了Quaternion Message Passing Neural Networks (QMPNNs)框架，该框架利用四元数空间来计算节点表示，并以原始参数量的1/4提供了通用方法将四元数表示融入GNN架构中。此外，我们提出了Graph Lottery Tickets的新视角，在GNN和QMPNN背景下重新定义了其适用性，旨在从GNN子网络找到一个初始化方案，该方案在训练后能达到与原始GNN相当的表现，并进一步减少可训练模型参数的数量。为了验证所提出的QMPNN框架及LTH对GNN和QMPNN的有效性，我们在节点分类、链接预测以及图分类这三个基本的基于图的任务上评估了它们在实际数据集上的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for learningrepresentations of graph-structured data. In addition to real-valued GNNs,quaternion GNNs also perform well on tasks on graph-structured data. With theaim of reducing the energy footprint, we reduce the model size whilemaintaining accuracy comparable to that of the original-sized GNNs. This paperintroduces Quaternion Message Passing Neural Networks (QMPNNs), a frameworkthat leverages quaternion space to compute node representations. Our approachoffers a generalizable method for incorporating quaternion representations intoGNN architectures at one-fourth of the original parameter count. Furthermore,we present a novel perspective on Graph Lottery Tickets, redefining theirapplicability within the context of GNNs and QMPNNs. We specifically aim tofind the initialization lottery from the subnetwork of the GNNs that canachieve comparable performance to the original GNN upon training. Therebyreducing the trainable model parameters even further. To validate theeffectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,we evaluate their performance on real-world datasets across three fundamentalgraph-based tasks: node classification, link prediction, and graphclassification.</description>
      <author>example@mail.com (Rucha Bhalchandra Joshi, Sagar Prakash Barad, Nidhi Tiwari, Subhankar Mishra)</author>
      <guid isPermaLink="false">2502.06136v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Transformers versus the EM Algorithm in Multi-class Clustering</title>
      <link>http://arxiv.org/abs/2502.06007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了Transformer模型在无监督学习任务中多类高斯混合聚类问题上的理论保证，建立了Softmax注意力层与EM算法之间的联系，并证明了其逼近能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）通过使用变换器模型作为骨干，在复杂的机器学习任务中展示了强大的推理能力。然而，对于这些模型在无监督学习问题中的理解还很有限。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer在执行高斯混合聚类的多分类聚类时的学习保证，并建立Softmax注意力层与EM算法之间的理论联系。&lt;h4&gt;方法&lt;/h4&gt;通过证明多变量映射由softmax函数实现的通用逼近能力，为期望和最大化步骤提供了近似界限。同时表明，在有足够的预训练样本和初始化的情况下，Transformer可以达到问题考虑的最小最大最优率。&lt;h4&gt;主要发现&lt;/h4&gt;论文发展了一种理论框架，将Softmax注意力层与EM算法的工作流程联系起来，并展示了Transformers在多类高斯混合聚类中的强大学习能力。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了该理论，表明Transformer即使在超出理论假设的情况下也具有强大的推理能力。这为LLMs的推断能力提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）展示了在复杂机器学习任务中进行推理的能力，这些任务以变换器模型作为其核心架构。为了进一步理解这类模型在无监督学习问题上的表现，我们研究了Transformer执行多类高斯混合聚类时的学习保证，并建立了一个将Softmax注意力层与EM算法的工作流程联系起来的理论框架。通过证明softmax函数在实现多变量映射中的通用逼近能力，我们的理论为期望和最大化步骤提供了近似界限。此外，在给定足够的预训练样本和初始化的情况下，我们还展示了Transformer可以达到考虑问题的最小最大最优率。广泛的模拟实验从经验上验证了我们的理论，并揭示了Transformer即使超出假设条件也具备强大的学习能力，这强调了LLMs的强大推理潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs demonstrate significant inference capacities in complicated machinelearning tasks, using the Transformer model as its backbone. Motivated by thelimited understanding of such models on the unsupervised learning problems, westudy the learning guarantees of Transformers in performing multi-classclustering of the Gaussian Mixture Models. We develop a theory drawing strongconnections between the Softmax Attention layers and the workflow of the EMalgorithm on clustering the mixture of Gaussians. Our theory providesapproximation bounds for the Expectation and Maximization steps by proving theuniversal approximation abilities of multivariate mappings by Softmaxfunctions. In addition to the approximation guarantees, we also show that witha sufficient number of pre-training samples and an initialization, Transformerscan achieve the minimax optimal rate for the problem considered. Our extensivesimulations empirically verified our theory by revealing the strong learningcapacities of Transformers even beyond the assumptions in the theory, sheddinglight on the powerful inference capacities of LLMs.</description>
      <author>example@mail.com (Yihan He, Hong-Yu Chen, Yuan Cao, Jianqing Fan, Han Liu)</author>
      <guid isPermaLink="false">2502.06007v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Musical Representations for Music Performance Question Answering</title>
      <link>http://arxiv.org/abs/2502.06710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;音乐表演为音频-视觉建模提供了典型的应用场景，与常见稀疏声音的场景不同，音乐表演中持续存在密集的声音信号。&lt;h4&gt;背景问题&lt;/h4&gt;现有的多模式学习方法在通用场景中的表现令人印象深刻，但在处理音乐表演的基本问题时却显得不足：它们未能深入探索多种感官信号之间的交互，并未考虑到乐器和音乐的独特特性。&lt;h4&gt;研究目的&lt;/h4&gt;为了解决上述研究差距，该论文旨在提出一种能够更好地理解和分析音乐表演的方法。&lt;h4&gt;方法介绍&lt;/h4&gt;{'(i) 多模态互动设计': '鉴于音乐数据中固有的复杂多模式互连性，本研究主要采用了一种结合了音频和视频信号在音乐上下文中的交互作用的设计方案;', '(ii) 学习音乐特性': '为了使模型能够学习音乐的特性，作者对当前音乐数据集进行了节奏和音乐来源的注释并开放;', '(iii) 时间感知建模': '为实现时间感知音频-视觉建模，该方法将模型预测与时间维度进行对齐'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在Music AVQA 数据集中实现了最先进的效果。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法在音乐表演场景中表现出色，并通过公开源代码促进相关领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;音乐表演代表了音频-视觉建模的典型应用场景。与普通稀疏声音场景不同，音乐表演中持续存在密集的声音信号。虽然现有的多模式学习方法在通用情景下展示了出色的能力，但在处理音乐表演的基本问题时却显得不足：它们未能深入探索多种感官信号之间的交互，并未考虑到乐器和音乐的独特特性。因此，现有方法倾向于不准确地回答关于音乐表演的问题。为了弥补上述研究差距，(i) 由于音乐数据中固有的复杂多模式互连性，我们的主干设计旨在结合音频和视频信号在音乐上下文中的互动；(ii) 为了让模型学习到音乐的特点，我们对现有的音乐数据集进行节奏和音乐来源的注释并开放给公众；(iii) 对于时间感知的音频-视觉建模，我们将模型预测与时间维度进行对齐。实验显示，在Music AVQA 数据集中我们的方法取得了最先进的效果。代码可在https://github.com/xid32/Amuse获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Music performances are representative scenarios for audio-visual modeling.Unlike common scenarios with sparse audio, music performances continuouslyinvolve dense audio signals throughout. While existing multimodal learningmethods on the audio-video QA demonstrate impressive capabilities in generalscenarios, they are incapable of dealing with fundamental problems within themusic performances: they underexplore the interaction between the multimodalsignals in performance and fail to consider the distinctive characteristics ofinstruments and music. Therefore, existing methods tend to answer questionsregarding musical performances inaccurately. To bridge the above research gaps,(i) given the intricate multimodal interconnectivity inherent to music data,our primary backbone is designed to incorporate multimodal interactions withinthe context of music; (ii) to enable the model to learn music characteristics,we annotate and release rhythmic and music sources in the current musicdatasets; (iii) for time-aware audio-visual modeling, we align the model'smusic predictions with the temporal dimension. Our experiments showstate-of-the-art effects on the Music AVQA datasets. Our code is available athttps://github.com/xid32/Amuse.</description>
      <author>example@mail.com (Xingjian Diao, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui)</author>
      <guid isPermaLink="false">2502.06710v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.06301v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于新颖性的NS-ES和NSR-ES算法在强化学习问题上训练复杂Transformer架构的有效性，并探讨了通过预训练模型加速这些大型模型的训练的可能性。&lt;h4&gt;背景&lt;/h4&gt;进化策略（如OpenAI-ES）已被用于训练决策变压器等复杂架构，但需要评估其性能是否适用于基于新颖性的变体和更大规模的问题。&lt;h4&gt;目的&lt;/h4&gt;测试NS-ES和NSR-ES算法在大规模Transformer架构上的有效性，并研究预训练模型能否加速这些算法的训练过程。&lt;h4&gt;方法&lt;/h4&gt;实验使用了新颖性为基础的OpenAI-ES变种（NS-ES和NSR-ES），并评估其对复杂强化学习问题中使用的变压器型架构的有效性。同时测试是否可以通过一个预训练模型来加速基于新颖性的大规模模型的训练。&lt;h4&gt;主要发现&lt;/h4&gt;虽然NS-ES显示出了一定的进步，但仍需要更多的迭代才能获得有趣的结果；而NSR-ES在更大规模模型上的表现与先前工作的Feed-forward模型和决策变压器之间的性能相似，并且证明了其能够直接应用于更大的模型上。此外，在大型模型中引入预训练种子加速新颖性搜索的潜力也被探讨。&lt;h4&gt;结论&lt;/h4&gt;基于新颖性的进化策略变种（NSR-ES）显示出在大规模Transformer架构上的强大能力，通过进一步的研究可以为这一领域提供新的见解和可能的应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们实验了OpenAI-ES的新颖性变体——NS-ES和NSR-ES算法，并评估它们训练复杂、基于变压器的强化学习问题（如决策变压器）架构的有效性。我们还测试是否可以通过预训练模型来加速这些大型模型的新颖性训练。通过这种方法，我们在以前的工作基础上进一步研究了进化策略（特别是OpenAI-ES）对Decision Transformer架构的培训能力。结果是混合的。NS-ES显示出了进步，但显然还需要更多的迭代才能产生有趣的结果。而另一方面，NSR-ES证明可以直接用在更大的模型上，因为其性能在前馈网络模型和决策变压器之间似乎与我们在先前工作中使用OpenAI-ES时的表现相似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we experiment with novelty-based variants of OpenAI-ES, theNS-ES and NSR-ES algorithms, and evaluate their effectiveness in trainingcomplex, transformer-based architectures designed for the problem ofreinforcement learning such as Decision Transformers. We also test if we canaccelerate the novelty-based training of these larger models by seeding thetraining by a pretrained models. By this, we build on our previous work, wherewe tested the ability of evolution strategies - specifically the aforementionedOpenAI-ES - to train the Decision Transformer architecture. The results weremixed. NS-ES showed progress, but it would clearly need many more iterationsfor it to yield interesting results. NSR-ES, on the other hand, proved quitecapable of being straightforwardly used on larger models, since its performanceappears as similar between the feed-forward model and Decision Transformer, asit was for the OpenAI-ES in our previous work.</description>
      <author>example@mail.com (Matyáš Lorenc)</author>
      <guid isPermaLink="false">2502.06301v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting in Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.06194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于无监督连续异常检测（UCAD）的多模态任务表示记忆库方法(MTRMB)，该方法通过两个关键技术创新来解决现有的代表性学习和灾难性遗忘的问题。&lt;h4&gt;背景&lt;/h4&gt;在多任务表征学习中，现有无监督模型缺乏先验信息，难以有效区分冗余和互补的多模态特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解决方案以改进无监督连续异常检测中的表示学习和防止灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;提出了两个关键技术：1. 使用简洁的关键提示来指导BERT和ViT之间的跨模式特征交互的Key-Prompt-Multimodal Knowledge (KPMK)机制；2. 基于结构化的对比学习（RSCL），利用Grounding DINO和SAM生成精确的分割掩码，将同一结构区域的特性拉近，而不同结构区域的特性推开。&lt;h4&gt;主要发现&lt;/h4&gt;在MVtec AD和VisA数据集上的实验表明，MTRMB方法具有优越性，在最低遗忘率下达到了0.921的平均检测准确度，显著优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;计划在未来将此工作开源到GitHub上。&lt;h4&gt;翻译&lt;/h4&gt;无监督连续异常检测（UCAD）在多任务表征学习中面临重大挑战。现有方法由于表示不完整和灾难性遗忘而表现不佳。与监督模型不同的是，无监督场景缺乏先验信息，难以有效区分冗余和互补的多模态特征。为了解决这一问题，我们通过两个关键技术创新提出了Multimodal Task Representation Memory Bank (MTRMB)方法：一种Key-Prompt-Multimodal Knowledge (KPMK)机制，利用简洁的关键提示来指导BERT与ViT之间的跨模式特性交互；以及基于结构化的对比学习（RSCL），它使用Grounding DINO和SAM生成精确的分割掩码，将同一结构区域中的特性拉近，同时推开不同的结构区域。在MVtec AD和VisA数据集上的实验表明MTRMB方法具有优越性，在最低遗忘率下达到了0.921的平均检测准确度，显著优于最先进的方法。我们计划在未来将此工作开源到GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Continuous Anomaly Detection (UCAD) faces significant challengesin multi-task representation learning, with existing methods suffering fromincomplete representation and catastrophic forgetting. Unlike supervisedmodels, unsupervised scenarios lack prior information, making it difficult toeffectively distinguish redundant and complementary multimodal features. Toaddress this, we propose the Multimodal Task Representation Memory Bank (MTRMB)method through two key technical innovations: A Key-Prompt-Multimodal Knowledge(KPMK) mechanism that uses concise key prompts to guide cross-modal featureinteraction between BERT and ViT. Refined Structure-based Contrastive Learning(RSCL) leveraging Grounding DINO and SAM to generate precise segmentationmasks, pulling features of the same structural region closer while pushingdifferent structural regions apart. Experiments on MVtec AD and VisA datasetsdemonstrate MTRMB's superiority, achieving an average detection accuracy of0.921 at the lowest forgetting rate, significantly outperformingstate-of-the-art methods. We plan to open source on GitHub.</description>
      <author>example@mail.com (You Zhou, Jiangshan Zhao, Deyu Zeng, Zuo Zuo, Weixiang Liu, Zongze Wu)</author>
      <guid isPermaLink="false">2502.06194v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?</title>
      <link>http://arxiv.org/abs/2502.06289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了通用视觉基础模型DINOv2和特定于眼科的基础模型RETFound在眼科疾病检测和系统性疾病预测任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型（FMs）的出现，医学领域正在发生变革。在眼科中，专门针对视网膜的RETFound表现出了较高的适应性，而通用视觉基础模型DINOv2则可能适用于非医疗领域但其临床应用尚未充分研究。&lt;h4&gt;目的&lt;/h4&gt;为了评估不同大小的DINOv2模型与RETFound在眼部疾病检测和系统性疾病预测任务中的性能差异。&lt;h4&gt;方法&lt;/h4&gt;通过在八组标准化开源眼科数据集以及Moorfields AlzEye和UK Biobank数据集上进行微调，对RETFound和三个DINOv2模型（大、中、小）进行了头对头的评估。&lt;h4&gt;主要发现&lt;/h4&gt;{'糖尿病性视网膜病变检测': '在三种数据集中，DINOv2-large模型的表现优于RETFound（AUROC=0.850-0.952 vs 0.823-0.944）', '多类眼疾分类': 'DINOv2-large模型也表现得比RETFound更好（AUROC=0.892 vs 0.846）', '青光眼检测': '在青光眼的检测中，DINOv2-base模型优于RETFound（AUROC=0.958 vs 0.940）', '系统性疾病预测': '在心力衰竭、心肌梗死和缺血性卒中的预测任务上，RETFound表现出色，优于所有大小的DINOv2模型'}&lt;h4&gt;结论&lt;/h4&gt;该研究展示了通用视觉基础模型与领域特定基础模型各自的优势场景，并强调了根据具体任务需求选择适当的基础模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;随着基础模型（FMs）在医学领域的引入，它们正在改变眼科等专业领域。虽然专门针对视网膜的RETFound模型在临床应用中表现出色，但通用视觉基础模型DINOv2在非医疗场景中的潜力尚未被充分研究。通过在标准化眼科数据集和Moorfields AlzEye及UK Biobank上的测试对比分析，我们发现不同大小的DINOv2模型在某些特定的眼科疾病检测任务中优于RETFound；同时，在系统性疾病预测方面，RETFound的表现则超过所有版本的DINOv2。这些发现表明了通用与领域专用基础模型各自的优势场景，并强调应根据具体任务需求选择最合适的模型以优化临床效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of foundation models (FMs) is transforming medical domain. Inophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4million natural images and 1.6 million retinal images, has demonstrated highadaptability across clinical applications. Conversely, DINOv2, ageneral-purpose vision FM pre-trained on 142 million natural images, has shownpromise in non-medical domains. However, its applicability to clinical tasksremains underexplored. To address this, we conducted head-to-head evaluationsby fine-tuning RETFound and three DINOv2 models (large, base, small) for oculardisease detection and systemic disease prediction tasks, across eightstandardized open-source ocular datasets, as well as the Moorfields AlzEye andthe UK Biobank datasets. DINOv2-large model outperformed RETFound in detectingdiabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,all P&lt;=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P&lt;0.001). Inglaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,P&lt;0.001). Conversely, RETFound achieved superior performance over all DINOv2models in predicting heart failure, myocardial infarction, and ischaemic stroke(AUROC=0.732-0.796 vs 0.663-0.771, all P&lt;0.001). These trends persisted evenwith 10% of the fine-tuning data. These findings showcase the distinctscenarios where general-purpose and domain-specific FMs excel, highlighting theimportance of aligning FM selection with task-specific requirements to optimiseclinical performance.</description>
      <author>example@mail.com (Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K. Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, AnRan Ran, Rui Santos, Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Yim-Lui Cheung, Pearse A. Keane, Yih Chung Tham)</author>
      <guid isPermaLink="false">2502.06289v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised deep learning for semantic segmentation of multispectral LiDAR forest point clouds</title>
      <link>http://arxiv.org/abs/2502.06227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为GrowSP-ForMS的全无人工监督深度学习模型，专门用于高密度多光谱ALS点云数据中的叶木分离。&lt;h4&gt;背景&lt;/h4&gt;激光扫描系统捕捉到的森林环境点云可以应用于树木属性估计、叶片角度分布和地上生物量等多个领域。有效的利用这些数据需要对木材和树叶点进行语义分割（即叶木分离）。传统的方法依赖于几何和辐射度测量的无监督算法，但其在高密度ALS数据上表现不佳。虽然最近的一些机器学习方法在这方面取得了显著成果，但他们通常需要大量的手工标注训练数据。&lt;h4&gt;目的&lt;/h4&gt;提出一个不需要人工标签、基于深度学习的新方法来提高叶木分离的准确性。&lt;h4&gt;方法&lt;/h4&gt;GrowSP-ForMS模型是基于GrowSP架构并专为多光谱ALS点云设计的方法。该方法利用了多光谱信息以改进叶木分离精度。&lt;h4&gt;主要发现&lt;/h4&gt;在测试集上，该模型达到了84.3%的平均准确率和69.6%的平均交并比（mIoU），超过了参考无监督方法，并且使用多光谱数据可以将mIoU从单光谱情况下的5.6个百分点提高。&lt;h4&gt;结论&lt;/h4&gt;虽然与最新的监督深度学习方法相比，GrowSP-ForMS的表现稍逊一筹，但它仍然是一种无需人工标签的非常有效的叶木分离工具。&lt;h4&gt;翻译&lt;/h4&gt;点云捕获自森林环境的激光扫描系统数据在林业和植物生态学应用中广泛使用。有效利用这些数据需要将木材和树叶点进行语义分割（即叶木分离）。传统的方法基于几何和辐射度测量，但在高密度ALS数据上表现不佳。尽管最近一些机器学习方法在这类问题上取得了显著成果，但它们通常要求手动标注的训练集。多光谱信息被证明可以提高叶木分离精度，但是其效果至今缺乏定量评估。本研究提出了一种基于GrowSP架构设计的完全无人工监督深度学习模型（名为GrowSP-ForMS），专门针对高密度多光谱ALS点云数据中的叶木分离问题。在我们的测试集中，该模型实现了84.3%的平均准确率和69.6%的平均交并比（mIoU），显著优于无监督参考方法。相较于有监督深度学习方法，该模型的表现与略早一些的PointNet架构相似，并被更近的方法超越。最后进行两组消融实验表明，相比原始GrowSP模型，我们提出的改进将GrowSP-ForMS在测试集上的mIoU提高了29.4个百分点；同时利用多光谱数据相较于单光谱情况可以提高5.6个百分点的mIoU。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point clouds captured with laser scanning systems from forest environmentscan be utilized in a wide variety of applications within forestry and plantecology, such as the estimation of tree stem attributes, leaf angledistribution, and above-ground biomass. However, effectively utilizing the datain such tasks requires the semantic segmentation of the data into wood andfoliage points, also known as leaf-wood separation. The traditional approach toleaf-wood separation has been geometry- and radiometry-based unsupervisedalgorithms, which tend to perform poorly on data captured with airborne laserscanning (ALS) systems, even with a high point density. While recent machineand deep learning approaches achieve great results even on sparse point clouds,they require manually labeled training data, which is often extremely laboriousto produce. Multispectral (MS) information has been demonstrated to havepotential for improving the accuracy of leaf-wood separation, but quantitativeassessment of its effects has been lacking. This study proposes a fullyunsupervised deep learning method, GrowSP-ForMS, which is specifically designedfor leaf-wood separation of high-density MS ALS point clouds and based on theGrowSP architecture. GrowSP-ForMS achieved a mean accuracy of 84.3% and a meanintersection over union (mIoU) of 69.6% on our MS test set, outperforming theunsupervised reference methods by a significant margin. When compared tosupervised deep learning methods, our model performed similarly to the slightlyolder PointNet architecture but was outclassed by more recent approaches.Finally, two ablation studies were conducted, which demonstrated that ourproposed changes increased the test set mIoU of GrowSP-ForMS by 29.4 percentagepoints (pp) in comparison to the original GrowSP model and that utilizing MSdata improved the mIoU by 5.6 pp from the monospectral case.</description>
      <author>example@mail.com (Lassi Ruoppa, Oona Oinonen, Josef Taher, Matti Lehtomäki, Narges Takhtkeshha, Antero Kukko, Harri Kaartinen, Juha Hyyppä)</author>
      <guid isPermaLink="false">2502.06227v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>ARISE: Iterative Rule Induction and Synthetic Data Generation for Text Classification</title>
      <link>http://arxiv.org/abs/2502.05923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Findings of NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在文本分类任务中，合成数据生成和自动规则归纳是非常重要的技术。&lt;h4&gt;目的&lt;/h4&gt;提出ARISE框架，旨在通过迭代地诱导规则并生成合成数据来提高文本分类的性能。&lt;h4&gt;方法&lt;/h4&gt;结合了基于引导的数据生成与自动规则诱导技术，以迭代方式过滤产生的规则和数据。通过语法n-grams的归纳概括诱导规则。&lt;h4&gt;主要发现&lt;/h4&gt;{'单独使用规则': '在上下文学习（ICL）和微调（FT）设置中都能带来性能提升。', '单独使用增强的数据': '模型性能提高，优于依赖复杂方法如对比学习的配置。', '实验结果': '在三个全量样本、八个少量样本及七个跨语言变体设置上进行广泛的实验，证明生成的规则和数据能跨越这些多样化的领域和语言带来性能改进。'}&lt;h4&gt;结论&lt;/h4&gt;ARISE框架通过迭代地过滤合成数据和规则来提高文本分类任务中的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为ARISE的框架，该框架用于迭代诱导规则并生成合成数据以进行文本分类。我们结合了基于引导的数据生成与自动规则归纳技术，以迭代方式过滤产生的规则和数据。通过语法n-grams的归纳概括诱导规则，并且这些规则单独使用就能在上下文学习（ICL）和微调（FT）设置中带来性能提升。同样地，仅使用ARISE生成的增强数据也能提高模型性能，在对比其他复杂方法如对比学习的配置时表现出色。我们还在覆盖三个全量样本、八个少量样本及七个跨语言变体设置的各种数据集上进行了广泛的实验，结果表明我们生成的规则和数据在这些多样化的领域和语言中都有所改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose ARISE, a framework that iteratively induces rules and generatessynthetic data for text classification. We combine synthetic data generationand automatic rule induction, via bootstrapping, to iteratively filter thegenerated rules and data. We induce rules via inductive generalisation ofsyntactic n-grams, enabling us to capture a complementary source ofsupervision. These rules alone lead to performance gains in both, in-contextlearning (ICL) and fine-tuning (FT) settings. Similarly, use of augmented datafrom ARISE alone improves the performance for a model, outperformingconfigurations that rely on complex methods like contrastive learning. Further,our extensive experiments on various datasets covering three full-shot, eightfew-shot and seven multilingual variant settings demonstrate that the rules anddata we generate lead to performance improvements across these diverse domainsand languages.</description>
      <author>example@mail.com (Yashwanth M., Vaibhav Singh, Ayush Maheshwari, Amrith Krishna, Ganesh Ramakrishnan)</author>
      <guid isPermaLink="false">2502.05923v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time LiDAR Point Cloud Compression and Transmission for Resource-constrained Robots</title>
      <link>http://arxiv.org/abs/2502.06123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种针对资源受限的机器人应用的新颖点云压缩和传输框架，名为RCPCC。&lt;h4&gt;背景&lt;/h4&gt;激光雷达（LiDAR）在自主机器人中广泛应用，因为它能够提供准确的环境结构信息。然而，大量的点云数据带来了存储和传输方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;为资源受限的机器人应用设计一种新的点云压缩和传输框架。&lt;h4&gt;方法&lt;/h4&gt;迭代拟合具有类似范围值的点云表面并消除冗余；使用形状自适应离散余弦变换（SA-DCT）转换未拟合的点，通过量化变换系数减少数据量；基于QoE（用户体验质量）设计了自适应比特率控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架在保持下游应用高精度的同时实现了40到80倍的数据压缩。当压缩比超过70倍时，方法的准确性明显优于其他基准方法。此外，在通信带宽降低的情况下，自适应比特率控制策略显示出显著的质量提升。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效地解决点云数据存储和传输的问题，并且在各种资源限制条件下表现出色。&lt;h4&gt;翻译&lt;/h4&gt;激光雷达由于其提供准确环境结构信息的能力而在自主机器人中广泛应用。然而，大量的点云数据给存储和传输带来了挑战。本文提出了一种新的适用于资源受限的机器人应用的点云压缩和传输框架RCPCC。通过迭代拟合具有相似范围值的点云表面并消除冗余，并使用形状自适应离散余弦变换（SA-DCT）处理未拟合的点，减少数据量。设计了一个基于用户体验质量（QoE）的自适应比特率控制策略来优化传输点云的质量。实验结果表明，在保持下游应用高精度的同时实现了40到80倍的数据压缩。当压缩比超过70倍时，该方法明显优于其他基准方法。此外，在通信带宽减少的情况下，自适应比特率控制策略能够显著提升用户体验质量。代码可以在 https://github.com/HITSZ-NRSL/RCPCC.git 上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDARs are widely used in autonomous robots due to their ability to provideaccurate environment structural information. However, the large size of pointclouds poses challenges in terms of data storage and transmission. In thispaper, we propose a novel point cloud compression and transmission frameworkfor resource-constrained robotic applications, called RCPCC. We iteratively fitthe surface of point clouds with a similar range value and eliminate redundancythrough their spatial relationships. Then, we use Shape-adaptive DCT (SA-DCT)to transform the unfit points and reduce the data volume by quantizing thetransformed coefficients. We design an adaptive bitrate control strategy basedon QoE as the optimization goal to control the quality of the transmitted pointcloud. Experiments show that our framework achieves compression rates of40$\times$ to 80$\times$ while maintaining high accuracy for downstreamapplications. our method significantly outperforms other baselines in terms ofaccuracy when the compression rate exceeds 70$\times$. Furthermore, insituations of reduced communication bandwidth, our adaptive bitrate controlstrategy demonstrates significant QoE improvements. The code will be availableat https://github.com/HITSZ-NRSL/RCPCC.git.</description>
      <author>example@mail.com (Yuhao Cao, Yu Wang, Haoyao Chen)</author>
      <guid isPermaLink="false">2502.06123v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions</title>
      <link>http://arxiv.org/abs/2502.06536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  47 pages, 16 figures, 9 Tables, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在现实世界中应用广泛，但黑盒AI系统缺乏解释性和鲁棒性等问题仍然存在。概念模型（CBM）通过从高维数据如图像中学习可解释的概念来解决这些问题，然而这些模型中存在的概念泄漏问题会影响预测准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管概念模型能够帮助理解机器学习系统中的决策过程，但是它们经常包含不相关的信息或"错误"概念的误导信息。现有的缓解策略需要强烈假设或大量的手动干预。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于因果表示学习（CRL）的新框架，该框架在不需要任何干预的情况下提供关于所学概念正确性的理论保证，并且降低了所需标签的数量。&lt;h4&gt;方法&lt;/h4&gt;利用因果表示学习从低级数据中提取高层因果变量，并试图将这些变量与可解释的概念对齐。针对这种映射提出了线性估计器和非参数估计器，分别在有限样本下给出高概率结果，在无限样本的情况下则得到一致性结果。&lt;h4&gt;主要发现&lt;/h4&gt;新框架实现了概念模型的准确性和鲁棒性的提升，通过合成数据集和图像基准测试验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架提供了一种无需人工干预即可学习正确且可解释的概念的方法，这对于提高机器学习系统的透明度至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含在问题描述中&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning is a vital part of many real-world systems, but severalconcerns remain about the lack of interpretability, explainability androbustness of black-box AI systems. Concept-based models (CBM) address some ofthese challenges by learning interpretable concepts from high-dimensional data,e.g. images, which are used to predict labels. An important issue in CBMs isconcept leakage, i.e., spurious information in the learned concepts, whicheffectively leads to learning "wrong" concepts. Current mitigating strategiesare heuristic, have strong assumptions, e.g., they assume that the concepts arestatistically independent of each other, or require substantial humaninteraction in terms of both interventions and labels provided by annotators.In this paper, we describe a framework that provides theoretical guarantees onthe correctness of the learned concepts and on the number of required labels,without requiring any interventions. Our framework leverages causalrepresentation learning (CRL) to learn high-level causal variables fromlow-level data, and learns to align these variables with interpretableconcepts. We propose a linear and a non-parametric estimator for this mapping,providing a finite-sample high probability result in the linear case and anasymptotic consistency result for the non-parametric estimator. We implementour framework with state-of-the-art CRL methods, and show its efficacy inlearning the correct concepts in synthetic and image benchmarks.</description>
      <author>example@mail.com (Hidde Fokkema, Tim van Erven, Sara Magliacane)</author>
      <guid isPermaLink="false">2502.06536v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Norm Augmented Graph AutoEncoders for Link Prediction</title>
      <link>http://arxiv.org/abs/2502.05868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图自编码器（GAE）在链路预测任务中性能不佳的问题，并提出了一种通过增加低度节点嵌入向量的范数来提高其表现的方法。&lt;h4&gt;背景&lt;/h4&gt;链路预测是图结构数据中的重要问题，而图神经网络（尤其是图自编码器）已被广泛用于解决这一问题。然而，实验证明GAE在处理长尾节点分布时性能较差，即低度节点的表现通常不如高度节点。&lt;h4&gt;目的&lt;/h4&gt;研究造成这种与节点度数相关偏差的原因，并提出一种减轻该偏差的方法。&lt;h4&gt;方法&lt;/h4&gt;本文发现GAE学习到的节点嵌入向量范数在其不同度节点之间存在差异，这影响了链路预测最终结果。通过为低度节点引入额外的自环来增加其嵌入向量的范数，从而提高其性能。&lt;h4&gt;主要发现&lt;/h4&gt;嵌入向量具有较大范数的节点更倾向于引导解码器对正链接赋予更高的评分，并对负链接赋予更低的评分，这导致了更好的链路预测表现。通过为低度节点增加嵌入向量的范数可以提升其在链路预测中的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于增范策略改进的GAE方法能在保持较低计算成本的同时显著提高链路预测任务中低度节点的表现，实验结果验证了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：链路预测是图结构数据中一个关键问题。图神经网络（包括图自编码器）已成为链路预测领域的重要工具，但我们的实证研究发现图自编码器在处理长尾节点度分布时性能显著下降，即低度节点的链路预测表现通常不如高度节点的表现好。这种与节点度数相关的偏差是什么原因造成的？如何减轻这一问题？本研究表明GAE学习到的不同节点间嵌入向量范数的变化是影响最终链路预测结果的关键因素之一。具体来说，具有较大范数的嵌入更倾向于引导解码器对正链接赋予更高的评分，并且降低负链接的分数，从而有助于提高性能。这一发现促使我们通过增加低度节点的嵌入向量范数来改善其链路预测表现，这可以通过在训练目标中为这些节点引入额外自环轻松实现并有效执行。该增范策略可无缝集成到现有GAE方法中，并且计算成本较小。在各种数据集和GAE方法上的广泛实验结果表明了基于增范策略的图自编码器优越的表现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link Prediction (LP) is a crucial problem in graph-structured data. GraphNeural Networks (GNNs) have gained prominence in LP, with Graph AutoEncoders(GAEs) being a notable representation. However, our empirical findings revealthat GAEs' LP performance suffers heavily from the long-tailed node degreedistribution, i.e., low-degree nodes tend to exhibit inferior LP performancecompared to high-degree nodes. \emph{What causes this degree-related bias, andhow can it be mitigated?} In this study, we demonstrate that the norm of nodeembeddings learned by GAEs exhibits variation among nodes with differentdegrees, underscoring its central significance in influencing the finalperformance of LP. Specifically, embeddings with larger norms tend to guide thedecoder towards predicting higher scores for positive links and lower scoresfor negative links, thereby contributing to superior performance. Thisobservation motivates us to improve GAEs' LP performance on low-degree nodes byincreasing their embedding norms, which can be implemented simply yeteffectively by introducing additional self-loops into the training objectivefor low-degree nodes. This norm augmentation strategy can be seamlesslyintegrated into existing GAE methods with light computational cost. Extensiveexperiments on various datasets and GAE methods show the superior performanceof norm-augmented GAEs.</description>
      <author>example@mail.com (Yunhui Liu, Huaisong Zhang, Xinyi Gao, Liuye Guo, Zhen Tao, Tieke He)</author>
      <guid isPermaLink="false">2502.05868v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks</title>
      <link>http://arxiv.org/abs/2502.06153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Kolmogorov-Arnold网络（KAN）微调方法——低张量秩自适应（LoTRA），该方法通过借鉴Tucker分解技术，使KAN在网络转移学习中的性能得到提升，并且在解决偏微分方程和函数表示等方面表现出色。&lt;h4&gt;背景&lt;/h4&gt;虽然Kolmogorov-Arnold网络展示了其作为多层感知机的替代方案的巨大潜力，但关于KANs的迁移学习尚未充分探索。作者通过Tucker张量分解理论以及观察到的KAN参数更新具有低张量秩结构的特点来开发了一种新颖的方法。&lt;h4&gt;目的&lt;/h4&gt;旨在研究LoTRA的表达能力，并提供一种高效的训练策略选择学习率的方法，同时证明这种方法在解决偏微分方程和功能表示任务中的有效性。&lt;h4&gt;方法&lt;/h4&gt;基于Tucker分解近似理论，提出低张量秩自适应（LoTRA）算法；分析如何根据各个组件的特点设置合适的学习率以实现有效的训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明了所提出的LoTRA可以有效地利用KAN的迁移学习能力解决各种偏微分方程问题。此外，作者还提出了Slim KANs，该模型在保持高性能的同时减少了参数数量。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，采用低张量秩自适应策略（LoTRA）能够有效提高基于Kolmogorov-Arnold网络的迁移学习性能，并且对于偏微分方程求解具有很大的潜力。此外，Slim KANs在函数表示和图像分类任务中展示了其表达力以及通过张量分解减少参数的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到Kolmogorov-Arnold网络（KAN）展示出作为多层感知机的替代方案的巨大潜力，特别是在科学相关领域。然而，关于KANs的迁移学习仍是一个相对未探索的领域。本文受张量Tucker分解以及KAN参数更新中低张量秩结构证据启发，开发了一种用于微调KAN的新方法——低张量秩自适应（LoTRA）。研究基于Tucker分解近似理论探讨了LoTRA的表现力，并提供了一个理论分析来为每个LoTRA组件选择合适的学习率以实现高效的训练。此外还发现使用相同学习率在所有组件之间会导致效率低下，强调了采用自适应学习率策略的重要性。除了理论见解外，本文还探索了通过微调KAN高效解决各种偏微分方程（PDE）的应用。另外，提出了包含KAN参数张量固有的低张量秩性质的Slim KANs来减少模型大小同时保持优异性能。实验结果验证了所提议的学习率选择策略的有效性，并展示了LoTRA在基于KAN的迁移学习中解决偏微分方程的能力。关于Slim KANs在功能表示和图像分类任务中的进一步评估突显了LoTRA的表现力以及通过低张量秩分解减少参数的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov--Arnold networks (KANs) have demonstrated their potential as analternative to multi-layer perceptions (MLPs) in various domains, especiallyfor science-related tasks. However, transfer learning of KANs remains arelatively unexplored area. In this paper, inspired by Tucker decomposition oftensors and evidence on the low tensor-rank structure in KAN parameter updates,we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We studythe expressiveness of LoTRA based on Tucker decomposition approximations.Furthermore, we provide a theoretical analysis to select the learning rates foreach LoTRA component to enable efficient training. Our analysis also shows thatusing identical learning rates across all components leads to inefficienttraining, highlighting the need for an adaptive learning rate strategy. Beyondtheoretical insights, we explore the application of LoTRA for efficientlysolving various partial differential equations (PDEs) by fine-tuning KANs.Additionally, we propose Slim KANs that incorporate the inherentlow-tensor-rank properties of KAN parameter tensors to reduce model size whilemaintaining superior performance. Experimental results validate the efficacy ofthe proposed learning rate selection strategy and demonstrate the effectivenessof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations onSlim KANs for function representation and image classification tasks highlightthe expressiveness of LoTRA and the potential for parameter reduction throughlow tensor-rank decomposition.</description>
      <author>example@mail.com (Yihang Gao, Michael K. Ng, Vincent Y. F. Tan)</author>
      <guid isPermaLink="false">2502.06153v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Accurate, Efficient, and Interpretable MLPs on Multiplex Graphs via Node-wise Multi-View Ensemble Distillation</title>
      <link>http://arxiv.org/abs/2502.05864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的知识蒸馏框架Multiplex Graph-Free Neural Networks (MGFNN)及其改进版本MGFNN+，旨在结合多路图神经网络(MGNNs)的高级性能和MLP模型高效的推断能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多路图（带有多种边类型的图）提供更丰富的结构语义，并且对于某些下游任务中的表现优于单一路径。然而，基于邻居聚合的方法在低延迟应用场景中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;结合MGNNs的性能和MLP模型推断效率，通过知识蒸馏框架进行融合。&lt;h4&gt;方法&lt;/h4&gt;直接训练学生MLP模型使用节点特征作为输入，并用教师MGNN生成的软标签作为目标。MGFNN+进一步采用基于低秩近似的重参数化学习节点级系数，使不同的视图GNN在不同节点上贡献不一。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与普通的MLPs相比，MGFNN模型实现了约10%平均准确率的提升；其性能与教师MGNN相当或更好；推断速度比MGNN快35.40到89.14倍；并且可以为不同的节点分配不同系数以实现多视图融合蒸馏（解释性）。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型不仅提高了准确率，还保证了推理效率，并且具有较好的可解释性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiplex graphs, with multiple edge types (graph views) among common nodes,provide richer structural semantics and better modeling capabilities. MultiplexGraph Neural Networks (MGNNs), typically comprising view-specific GNNs and amulti-view integration layer, have achieved advanced performance in variousdownstream tasks. However, their reliance on neighborhood aggregation poseschallenges for deployment in latency-sensitive applications. Motivated byrecent GNN-to-MLP knowledge distillation frameworks, we propose MultiplexGraph-Free Neural Networks (MGFNN and MGFNN+) to combine MGNNs' superiorperformance and MLPs' efficient inference via knowledge distillation. MGFNNdirectly trains student MLPs with node features as input and soft labels fromteacher MGNNs as targets. MGFNN+ further employs a low-rank approximation-basedreparameterization to learn node-wise coefficients, enabling adaptive knowledgeensemble from each view-specific GNN. This node-wise multi-view ensembledistillation strategy allows student MLPs to learn more informative multiplexsemantic knowledge for different nodes. Experiments show that MGFNNs achieveaverage accuracy improvements of about 10% over vanilla MLPs and performcomparably or even better to teacher MGNNs (accurate); MGFNNs achieve a35.40$\times$-89.14$\times$ speedup in inference over MGNNs (efficient); MGFNN+adaptively assigns different coefficients for multi-view ensemble distillationregarding different nodes (interpretable).</description>
      <author>example@mail.com (Yunhui Liu, Zhen Tao, Xiang Zhao, Jianhua Zhao, Tao Zheng, Tieke He)</author>
      <guid isPermaLink="false">2502.05864v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Neural Shortest Path for Surface Reconstruction from Point Clouds</title>
      <link>http://arxiv.org/abs/2502.06047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的神经最短路径（NSP）模型，该模型通过向量值隐式神经表示来近似距离函数及其梯度。&lt;h4&gt;背景&lt;/h4&gt;现有方法通常单独学习距离函数本身，而无法同时恢复距离函数和其梯度。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时恢复距离函数及其梯度的新方法，并证明NSP分解表示在$H^1$范数下的收敛性。&lt;h4&gt;方法&lt;/h4&gt;将NSP分解为幅度和方向两部分，每个分解组件分别近似于一个距离函数及其梯度；设计了一个新的损失函数以强制执行最短路径的属性。&lt;h4&gt;主要发现&lt;/h4&gt;数学证明了NSP的分解表示保证了$H^1$范数下NSP幅度的收敛性。实验验证了NSP在多种数据集上的性能，显示其能够重建高质量表面，并具有较强的噪声和数据稀疏鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过学习最短路径（ESP），即距离函数及其梯度的乘积，可以有效表示各种复杂表面。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种神经最短路径（NSP）模型，这是一种向量值隐式神经表征，用于逼近一个距离函数及它的梯度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose the neural shortest path (NSP), a vector-valuedimplicit neural representation (INR) that approximates a distance function andits gradient. The key feature of NSP is to learn the exact shortest path (ESP),which directs an arbitrary point to its nearest point on the target surface.The NSP is decomposed into its magnitude and direction, and a variablesplitting method is used that each decomposed component approximates a distancefunction and its gradient, respectively. Unlike to existing methods of learningthe distance function itself, the NSP ensures the simultaneous recovery of thedistance function and its gradient. We mathematically prove that the decomposedrepresentation of NSP guarantees the convergence of the magnitude of NSP in the$H^1$ norm. Furthermore, we devise a novel loss function that enforces theproperty of ESP, demonstrating that its global minimum is the ESP. We evaluatethe performance of the NSP through comprehensive experiments on diversedatasets, validating its capacity to reconstruct high-quality surfaces with therobustness to noise and data sparsity. The numerical results show substantialimprovements over state-of-the-art methods, highlighting the importance oflearning the ESP, the product of distance function and its gradient, forrepresenting a wide variety of complex surfaces.</description>
      <author>example@mail.com (Yesom Park, Imseong Park, Jooyoung Hahn, Myungjoo Kang)</author>
      <guid isPermaLink="false">2502.06047v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>PiKE: Adaptive Data Mixing for Multi-Task Learning Under Low Gradient Conflicts</title>
      <link>http://arxiv.org/abs/2502.06244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;现代机器学习模型通过多任务学习在多样化的数据集和任务上进行训练，以提高泛化能力。PiKE算法适应性地调整训练过程中各任务的贡献，动态优化任务采样策略。&lt;h4&gt;背景&lt;/h4&gt;传统多任务学习研究主要集中在减少任务间的梯度冲突，然而许多现实场景中的任务交互是正向且无显著冲突的。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于积极梯度交互的任务权重估计算法PiKE，以适应不同数据源下的多任务训练需求。&lt;h4&gt;方法&lt;/h4&gt;PiKE通过调整各任务贡献来最小化总体损失，在几乎不增加计算开销的情况下充分利用正面的梯度交互作用。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析证明了PiKE的有效性，并展示了其在大规模语言模型预训练中的优越表现，比静态混合策略更快收敛且提升下游任务性能。&lt;h4&gt;结论&lt;/h4&gt;实验证明，与现有启发式和固定混合策略相比，PiKE能更公平地促进多任务间的平衡学习，防止任务被忽视。它适用于跨领域、跨语言等多样化数据集的预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;现代机器学习模型在多样化的数据集上进行多任务训练以提高泛化能力。当前研究主要集中在减少多任务学习中的梯度冲突问题。然而，许多真实世界的场景显示出积极的任务交互且几乎没有或没有明显的梯度冲突。基于这一观察，我们提出了PiKE（基于正向梯度交互的K任务权重估计器），这是一种适应性数据混合算法，能够在训练过程中动态调整各任务贡献以最小化总体损失。此外，我们扩展了PiKE的方法来促进多任务间的公平学习，确保各个任务能取得均衡的进步，并防止被低估的任务出现。大规模语言模型预训练的实际评估表明，PiKE在现有启发式和固定策略中均表现出色，能够更快地收敛并提升下游任务性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern machine learning models are trained on diverse datasets and tasks toimprove generalization. A key challenge in multitask learning is determiningthe optimal data mixing and sampling strategy across different data sources.Prior research in this multi-task learning setting has primarily focused onmitigating gradient conflicts between tasks. However, we observe that manyreal-world multitask learning scenarios-such as multilingual training andmulti-domain learning in large foundation models-exhibit predominantly positivetask interactions with minimal or no gradient conflict. Building on thisinsight, we introduce PiKE (Positive gradient interaction-based K-task weightsEstimator), an adaptive data mixing algorithm that dynamically adjusts taskcontributions throughout training. PiKE optimizes task sampling to minimizeoverall loss, effectively leveraging positive gradient interactions with almostno additional computational overhead. We establish theoretical convergenceguarantees for PiKE and demonstrate its superiority over static andnon-adaptive mixing strategies. Additionally, we extend PiKE to promote fairlearning across tasks, ensuring balanced progress and preventing taskunderrepresentation. Empirical evaluations on large-scale language modelpretraining show that PiKE consistently outperforms existing heuristic andstatic mixing strategies, leading to faster convergence and improved downstreamtask performance.</description>
      <author>example@mail.com (Zeman Li, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni)</author>
      <guid isPermaLink="false">2502.06244v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>From Pixels to Components: Eigenvector Masking for Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了在图像表示学习中的一种新的自监督方法，通过随机遮蔽主成分而非原始像素来改进现有的随机打乱像素的方法。&lt;h4&gt;背景&lt;/h4&gt;当前预测被掩码区域从可见部分进行视觉表征学习的主流方式是随机遮蔽一些像素块。然而这种方法存在一定的缺陷，可能导致无法学到高层有意义的特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略以克服现有方法的局限性，并通过更为有效的遮蔽操作来改进图像表示的学习。&lt;h4&gt;方法&lt;/h4&gt;采用主成分分析（PCA）作为数据变换方式，在此基础上随机掩码一些主成分而非原始像素，重建任务为从可见部分恢复被隐藏的部分。&lt;h4&gt;主要发现&lt;/h4&gt;对比局部像素块的处理，图片中的主成分包含了更多的全局信息。因此，预测被遮蔽的主成分能够更好地使用高层特征进行学习，并且实验结果验证了这种方法可以提高图像分类性能。&lt;h4&gt;结论&lt;/h4&gt;提出的基于主成分分析的方法为传统的掩码图像建模提供了一种简单而稳健的数据驱动替代方案。&lt;h4&gt;翻译&lt;/h4&gt;预测图片中被掩盖部分，以从可见部分获取视觉表征的学习是一种强大的自监督方法。然而，随机遮蔽像素块的常见做法显示出某些失败模式，这可能会阻止学习到下游任务所需的有意义的高级特征。我们提出了一种基于数据变换而非原始像素的替代掩码策略。具体来说，在进行主成分分析后，我们随机掩盖一定数量的分量，这些分量占整个数据方差的比例固定不变。接下来的任务则是从可见部分重建被掩盖的分量。相较于局部像素块，图像中的主成分包含了更多的全局信息。因此，预测被遮蔽的主成分涉及更多高级特征，允许我们的掩码策略提取出更有用的表示形式。通过实验证明了相比于像素掩码，使用成分掩码可以提高图像分类性能。我们提出的方法为传统的基于掩膜的图像建模方法提供了一种简单而稳健的数据驱动替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting masked from visible parts of an image is a powerfulself-supervised approach for visual representation learning. However, thecommon practice of masking random patches of pixels exhibits certain failuremodes, which can prevent learning meaningful high-level features, as requiredfor downstream tasks. We propose an alternative masking strategy that operateson a suitable transformation of the data rather than on the raw pixels.Specifically, we perform principal component analysis and then randomly mask asubset of components, which accounts for a fixed ratio of the data variance.The learning task then amounts to reconstructing the masked components from thevisible ones. Compared to local patches of pixels, the principal components ofimages carry more global information. We thus posit that predicting masked fromvisible components involves more high-level features, allowing our maskingstrategy to extract more useful representations. This is corroborated by ourempirical findings which demonstrate improved image classification performancefor component over pixel masking. Our method thus constitutes a simple androbust data-driven alternative to traditional masked image modeling approaches.</description>
      <author>example@mail.com (Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt)</author>
      <guid isPermaLink="false">2502.06314v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification</title>
      <link>http://arxiv.org/abs/2502.05836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted on NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的任务，即通过修辞角色分类来对法律文件进行语义分割，并且介绍了LegalSeg数据集作为该任务的最大标注数据集。&lt;h4&gt;背景&lt;/h4&gt;目前缺乏针对印度法律判决的大型语料库和有效的评估基准，这阻碍了相关研究的发展。&lt;h4&gt;目的&lt;/h4&gt;开发一个大规模的数据集并评价多种最先进的模型在法律文件修辞角色分类中的表现。&lt;h4&gt;方法&lt;/h4&gt;引入LegalSeg数据集，并评测包括Hierarchical BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)等在内的多个模型，同时还探索了RhetoricLLaMA语言模型的应用。&lt;h4&gt;主要发现&lt;/h4&gt;整合更广泛的上下文信息和结构关系的模型优于仅依赖句子级别特征的模型。此外，周边文本和标签对分类准确性的改善也被研究。&lt;h4&gt;结论&lt;/h4&gt;尽管在区分相似角色及处理类别不平衡方面仍存在挑战，但这项工作展示了高级技术对于提高法律文件理解的巨大潜力，并为未来的研究奠定了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们通过修辞角色分类的任务来解决对法律文件进行语义分割的问题，重点是印度的法律判决。我们介绍了LegalSeg，这是目前最大的针对该任务的数据集，包含超过7,000份文档和140万句句子，并用七种修辞角色进行了标注。为了评估性能，我们评测了多个最先进的模型，包括Hierarchical BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)、图神经网络(GNNs)以及Role-Aware Transformers，同时探索了一个经过指令微调的大型语言模型RhetoricLLaMA的应用情况。我们的结果表明，整合更广泛的上下文信息、结构关系和连续句子信息的模型优于仅依赖于句子级别特征的模型。此外，我们通过实验研究了使用周围文本和预测或实际标签的影响来评估它们对分类准确性的改善作用。尽管这些进展已经取得了一定成果，但在区分密切相关角色以及处理类别不平衡方面仍然存在挑战。我们的工作强调了高级技术在提高法律文件理解方面的巨大潜力，并为未来的研究奠定了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the task of semantic segmentation of legaldocuments through rhetorical role classification, with a focus on Indian legaljudgments. We introduce LegalSeg, the largest annotated dataset for this task,comprising over 7,000 documents and 1.4 million sentences, labeled with 7rhetorical roles. To benchmark performance, we evaluate multiplestate-of-the-art models, including Hierarchical BiLSTM-CRF,TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), andRole-Aware Transformers, alongside an exploratory RhetoricLLaMA, aninstruction-tuned large language model. Our results demonstrate that modelsincorporating broader context, structural relationships, and sequentialsentence information outperform those relying solely on sentence-levelfeatures. Additionally, we conducted experiments using surrounding context andpredicted or actual labels of neighboring sentences to assess their impact onclassification accuracy. Despite these advancements, challenges persist indistinguishing between closely related roles and addressing class imbalance.Our work underscores the potential of advanced techniques for improving legaldocument understanding and sets a strong foundation for future research inlegal NLP.</description>
      <author>example@mail.com (Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya)</author>
      <guid isPermaLink="false">2502.05836v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Representation Distillation via Multi-Scale Feature Decoupling</title>
      <link>http://arxiv.org/abs/2502.05835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;知识蒸馏是一种技术，旨在通过从预训练的大模型（教师网络）向较小的模型（学生网络）转移知识来提升小模型的表现，而不增加其参数量。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的方法，在特征传递过程中引入多尺度解耦，以处理不同区域嵌入的不同类型的信息，并提高学生网络的学习效率和性能。&lt;h4&gt;方法&lt;/h4&gt;该研究首次在特征传输中采用了多尺度解耦策略，其中解耦的局部特征被单独处理并使用对比学习进行整合。相比之前基于对比学习的方法，这种方法减少了计算成本并提高了效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在CIFAR-100和ImageNet数据集上的评估显示了该方法的优势；某些学生网络在蒸馏后甚至超过了教师网络的表现。&lt;h4&gt;结论&lt;/h4&gt;研究表明我们的方法使得学生模型能够充分吸收教师网络的知识，从而表现出色。&lt;h4&gt;翻译&lt;/h4&gt;知识蒸馏是一种通过将预训练的大型教师模型中的知识转移到较小的学生模型中以提高其性能的技术。现有的研究主要集中在全局特征信息上，而忽略了不同区域嵌入的不同类型的信息的重要性。本文首次在特征传输过程中引入了多尺度解耦策略，并使用对比学习来处理解耦后的局部特征。该方法不仅减少了计算成本和提升了效率，还能够通过仅用单批样本使学生网络的表现得到改进。广泛的实验证明了我们的方法的有效性，在某些情况下，蒸馏后的学生模型甚至超过了教师模型的性能，这表明学生模型可以充分吸收教师模型的知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge distillation is a technique aimed at enhancing the performance of asmaller student network without increasing its parameter size by transferringknowledge from a larger, pre-trained teacher network. Previous approaches havepredominantly focused on distilling global feature information whileoverlooking the importance of disentangling the diverse types of informationembedded within different regions of the feature. In this work, we introducemulti-scale decoupling in the feature transfer process for the first time,where the decoupled local features are individually processed and integratedwith contrastive learning. Moreover, compared to previous contrastivelearning-based distillation methods, our approach not only reducescomputational costs but also enhances efficiency, enabling performanceimprovements for the student network using only single-batch samples. Extensiveevaluations on CIFAR-100 and ImageNet demonstrate our method's superiority,with some student networks distilled using our method even surpassing theperformance of their pre-trained teacher networks. These results underscore theeffectiveness of our approach in enabling student networks to thoroughly absorbknowledge from teacher networks.</description>
      <author>example@mail.com (Cuipeng Wang, Tieyuan Chen, Haipeng Wang)</author>
      <guid isPermaLink="false">2502.05835v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing</title>
      <link>http://arxiv.org/abs/2502.06219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的异构特征集成变换器(HFIT)，用于RGB-深度驾驶场景解析，该方法利用了视觉基础模型(VFM)的潜力，并在Cityscapes和KITTI Semantics数据集上展示了其优越性能。&lt;h4&gt;背景&lt;/h4&gt;虽然基于Vision Transformer (ViT)的视觉基础模型(VFMs)已经在仅关注RGB图像的任务中取得了成功，但它们在RGB-深度驾驶场景解析中的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;探索一种可行的技术来充分利用VFMs进行通用化的RGB-深度驾驶场景解析。&lt;h4&gt;方法&lt;/h4&gt;研究了RGB和深度数据的内在特性，并提出了一种异构特征集成变换器(HFIT)，该网络可以在不重新训练ViT的情况下高效提取和整合全面的异质特征。&lt;h4&gt;主要发现&lt;/h4&gt;HFIT克服了依赖于深度图的限制，利用VFM生成的相关深度预测结果作为输入。在Cityscapes和KITTI Semantics数据集上，提出的HFIT比所有传统的单模态、数据融合场景解析网络以及预训练VFMs和ViT适配器表现更佳。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为基于视觉基础模型的数据融合技术未来的发展开辟了道路，并且源代码已经公开分享。&lt;h4&gt;翻译&lt;/h4&gt;最近的视觉基础模型(VFMs)，通常是基于Vision Transformer (ViT)构建的，已经在许多计算机视觉任务中取得了显著进展。尽管它们在仅关注RGB图像的任务上取得成功，但在RGB-深度驾驶场景解析中的潜力仍然未被充分开发。本文通过研究一种可行的技术来充分利用VFMs进行通用化的RGB-深度驾驶场景解析，迈向了这个新兴的研究领域。具体而言，我们探讨了RGB和深度数据的内在特性，并提出了一种异构特征集成变换器(HFIT)。该网络能够高效提取并整合全面的异质特征而无需重新训练ViTs。VFM生成的相关深度预测结果作为输入给HFIT侧面适配器，克服了依赖于深度图的限制。与所有传统的单模态和数据融合场景解析网络、预训练VFMs以及ViT适配器相比，我们提出的HFIT在Cityscapes和KITTI Semantics数据集上展示了更优越的表现。我们认为这一创新策略为基于视觉基础模型的数据融合技术未来的发展铺平了道路，并且源代码已经公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent vision foundation models (VFMs), typically based on Vision Transformer(ViT), have significantly advanced numerous computer vision tasks. Despitetheir success in tasks focused solely on RGB images, the potential of VFMs inRGB-depth driving scene parsing remains largely under-explored. In thisarticle, we take one step toward this emerging research area by investigating afeasible technique to fully exploit VFMs for generalizable RGB-depth drivingscene parsing. Specifically, we explore the inherent characteristics of RGB anddepth data, thereby presenting a Heterogeneous Feature Integration Transformer(HFIT). This network enables the efficient extraction and integration ofcomprehensive heterogeneous features without re-training ViTs. Relative depthprediction results from VFMs, used as inputs to the HFIT side adapter, overcomethe limitations of the dependence on depth maps. Our proposed HFIT demonstratessuperior performance compared to all other traditional single-modal anddata-fusion scene parsing networks, pre-trained VFMs, and ViT adapters on theCityscapes and KITTI Semantics datasets. We believe this novel strategy pavesthe way for future innovations in VFM-based data-fusion techniques for drivingscene parsing. Our source code is publicly available athttps://mias.group/HFIT.</description>
      <author>example@mail.com (Sicen Guo, Tianyou Wen, Chuang-Wei Liu, Qijun Chen, Rui Fan)</author>
      <guid isPermaLink="false">2502.06219v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A 3D Multimodal Feature for Infrastructure Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.05779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的三维多模态特征3DMulti-FPFHI，用于提高老化结构点云中的裂缝检测质量。&lt;h4&gt;背景&lt;/h4&gt;老旧结构需要定期检查以识别结构缺陷。之前的工作使用了几何变形来定位合成砌体桥的点云中的裂缝，但难以发现小裂缝。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的三维多模态特征3DMulti-FPFHI，结合定制化的快速点特征直方图（FPFH）和强度特征，以增强检测小型裂缝的能力。&lt;h4&gt;方法&lt;/h4&gt;该新特征被集成到PatchCore异常检测算法中，并通过统计和参数分析进行评估。使用真实砌体拱桥的点云数据和全尺寸混凝土隧道实验模型进行了进一步验证。&lt;h4&gt;主要发现&lt;/h4&gt;3D强度特征提高了检查质量，增强了裂缝检测能力；还能够识别水分入侵产生的强度异常现象。与FPFH及最先进的多模态异常检测方法相比，3DMulti-FPFHI表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法在处理基础设施的多种异常检测场景中显示出潜在价值，尤其是在需要的数据量方面远少于基于学习的方法。&lt;h4&gt;翻译&lt;/h4&gt;老化结构需定期检查以识别结构缺陷。此前研究采用几何畸变来定位合成砌体桥点云中的裂缝，但难以探测小裂缝。为解决这一限制，本文提出一种新的3D多模态特征——3DMulti-FPFHI，结合定制的快速点特征直方图（FPFH）与强度特征。该特征被纳入PatchCore异常检测算法，并通过统计和参数分析进行评估。采用真实砌体拱桥及全尺寸混凝土隧道实验模型的点云数据进一步验证方法效果。结果显示，3D强度特性提高了检查质量并增强了裂缝检测能力；此外，它还能够识别水分入侵造成的强度异常现象。与FPFH及最先进的多模态异常检测方法相比，3DMulti-FPFHI表现更佳。该方法在处理基础设施多种异常检测场景时显示出了潜在价值，尤其是在数据需求方面低于基于学习的方法。相关代码和点云数据集可在GitHub上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ageing structures require periodic inspections to identify structuraldefects. Previous work has used geometric distortions to locate cracks insynthetic masonry bridge point clouds but has struggled to detect small cracks.To address this limitation, this study proposes a novel 3D multimodal feature,3DMulti-FPFHI, that combines a customized Fast Point Feature Histogram (FPFH)with an intensity feature. This feature is integrated into the PatchCoreanomaly detection algorithm and evaluated through statistical and parametricanalyses. The method is further evaluated using point clouds of a real masonryarch bridge and a full-scale experimental model of a concrete tunnel. Resultsshow that the 3D intensity feature enhances inspection quality by improvingcrack detection; it also enables the identification of water ingress whichintroduces intensity anomalies. The 3DMulti-FPFHI outperforms FPFH and astate-of-the-art multimodal anomaly detection method. The potential of themethod to address diverse infrastructure anomaly detection scenarios ishighlighted by the minimal requirements for data compared to learning-basedmethods. The code and related point cloud dataset are available athttps://github.com/Jingyixiong/3D-Multi-FPFHI.</description>
      <author>example@mail.com (Yixiong Jing, Wei Lin, Brian Sheil, Sinan Acikgoz)</author>
      <guid isPermaLink="false">2502.05779v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>K-ON: Stacking Knowledge On the Head Layer of Large Language Model</title>
      <link>http://arxiv.org/abs/2502.06257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期的大规模语言模型在各种自然语言处理任务中取得了显著进步，但这些模型与知识图谱场景存在粒度不匹配的问题。为此提出了一种名为K-ON的方法，通过引入多头层进行下一k步预测来整合知识图谱的知识。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在许多自然语言处理任务中表现出色，因为它们通常被训练来进行下一个标记的预测。然而，在知识图谱场景下，实体是基本单元，并且识别一个实体需要多个令牌，这导致了知识图谱和自然语言之间的粒度不匹配。&lt;h4&gt;目的&lt;/h4&gt;为了解决LLMs与知识图谱之间存在的粒度不匹配问题，提出了一种新的方法K-ON来整合知识图谱的知识。&lt;h4&gt;方法&lt;/h4&gt;通过在大型语言模型中引入多个头层进行下一k步预测，以适应实体识别任务的需求。这种方法不仅能够在一步内生成实体级别的结果，还可以使用与实体对比的损失函数作为最强大的工具进行知识图谱表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示K-ON方法优于现有文本和多模态融合的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;提出的K-ON模型能够有效地将知识图谱的知识整合到大型语言模型中，从而提高实体识别任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) have significantlyimproved various natural language processing (NLP) tasks. Typically, LLMs aretrained to predict the next token, aligning well with many NLP tasks. However,in knowledge graph (KG) scenarios, entities are the fundamental units andidentifying an entity requires at least several tokens. This leads to agranularity mismatch between KGs and natural languages. To address this issue,we propose K-ON, which integrates KG knowledge into the LLM by employingmultiple head layers for next k-step prediction. K-ON can not only generateentity-level results in one step, but also enables contrastive loss againstentities, which is the most powerful tool in KG representation learning.Experimental results show that K-ON outperforms state-of-the-art methods thatincorporate text and even the other modalities.</description>
      <author>example@mail.com (Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen)</author>
      <guid isPermaLink="false">2502.06257v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation</title>
      <link>http://arxiv.org/abs/2502.05780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了GOLD框架，用于图数据的OOD检测。&lt;h4&gt;背景&lt;/h4&gt;当前的图神经网络在处理图结构数据时面临OOD实例识别挑战，特别是缺乏额外的OOD样本。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需预训练生成模型的数据合成方法来解决图数据中的OOD问题。&lt;h4&gt;方法&lt;/h4&gt;GOLD框架采用隐式对抗学习管道，在没有预训练模型的情况下使用合成OOD数据进行检测。通过交替优化框架，训练一个潜在生成器模仿当前的ID嵌入，并同时训练图神经网络编码器和OOD探测器以区分ID和OOD数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了GOLD在五个基准图数据集上的优越性能，无需使用真实的OOD数据即可超越最先进的OOD暴露和非暴露基线方法。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种创新的方法来模拟没有额外数据的OOD场景，并证明了其在处理图结构数据中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;尽管图神经网络（GNN）在建模图结构数据方面取得了巨大成功，但当前GNN仍然面临着识别OOD测试实例的巨大挑战。一种最有效的技术是通过暴露检测器模型与额外的OOD节点集来实现，然而，在实践中获取这些额外的OOD样本非常困难。最近的方法通过使用OOD数据合成解决了图像数据中的这一问题，通常依赖于像StableDiffusion这样的预训练生成模型。但是，对于图数据而言，这种方法需要大量额外的数据以及一个通用的预训练生成模型，这是不可用的。因此，我们提出了用于图OOD检测的GOLD框架，这是一种无需预训练模型但具有合成OOD暴露的隐式对抗性学习管道。该隐式对抗训练过程采用了新颖的交替优化框架：（1）通过训练潜在生成器来定期模仿来自演进中的GNN的ID嵌入；（2）同时训练图神经网络编码器和OOD探测器以准确分类ID数据，增加ID嵌入与生成模型合成嵌入之间的能量差异。这种新颖的方法隐式地将合成嵌入转化为相对于ID数据的伪OOD实例，有效地模拟了没有辅助数据的情况下暴露于OOD场景的过程。在五个基准图数据集上进行了广泛的OOD检测实验，验证了GOLD相比于最先进的OOD曝光和非曝光基线方法，在不使用真实OOD数据时具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite graph neural networks' (GNNs) great success in modellinggraph-structured data, out-of-distribution (OOD) test instances still pose agreat challenge for current GNNs. One of the most effective techniques todetect OOD nodes is to expose the detector model with an additional OODnode-set, yet the extra OOD instances are often difficult to obtain inpractice. Recent methods for image data address this problem using OOD datasynthesis, typically relying on pre-trained generative models like StableDiffusion. However, these approaches require vast amounts of additional data,as well as one-for-all pre-trained generative models, which are not availablefor graph data. Therefore, we propose the GOLD framework for graph OODdetection, an implicit adversarial learning pipeline with synthetic OODexposure without pre-trained models. The implicit adversarial training processemploys a novel alternating optimisation framework by training: (1) a latentgenerative model to regularly imitate the in-distribution (ID) embeddings froman evolving GNN, and (2) a GNN encoder and an OOD detector to accuratelyclassify ID data while increasing the energy divergence between the IDembeddings and the generative model's synthetic embeddings. This novel approachimplicitly transforms the synthetic embeddings into pseudo-OOD instancesrelative to the ID data, effectively simulating exposure to OOD scenarioswithout auxiliary data. Extensive OOD detection experiments are conducted onfive benchmark graph datasets, verifying the superior performance of GOLDwithout using real OOD data compared with the state-of-the-art OOD exposure andnon-exposure baselines.</description>
      <author>example@mail.com (Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang)</author>
      <guid isPermaLink="false">2502.05780v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis</title>
      <link>http://arxiv.org/abs/2502.05556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的知识增强认知诊断(KCD)框架，旨在利用大型语言模型(LLM)的优势来改进现有的认知诊断模型(CDM)，以更全面和精细地评估学生的认知状态。&lt;h4&gt;背景&lt;/h4&gt;现有的认知诊断模型在缺乏丰富先验知识的情况下难以对不频繁出现的学生和练习进行有效诊断。随着大型语言模型的发展，这些模型因其广泛的领域知识而被引入到认知诊断中来。&lt;h4&gt;目的&lt;/h4&gt;通过结合大型语言模型与认知诊断模型的优点，提出一种适用于多种CDM架构的知识增强框架，以解决现有CDM在处理稀疏数据时的局限性，并提高其对学习者和练习的认知诊断能力。&lt;h4&gt;方法&lt;/h4&gt;KCD框架包括两个阶段：LLM诊断和认知水平对齐。在第一个阶段中，利用大型语言模型对学生和练习进行综合详细的诊断；第二个阶段则是通过对比学习和掩码重建方法将CDMs的行为空间与LLMs的语义空间连接起来。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的KCD框架能够在多个真实数据集上有效提高认知诊断的效果。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了一种新颖的方法来利用大型语言模型的知识增强现有的认知诊断，为未来结合不同领域的知识和人工智能技术在教育评估中的应用开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitivestates by analyzing their performance across a series of exercises. However,existing CDMs often struggle with diagnosing infrequent students and exercisesdue to a lack of rich prior knowledge. With the advancement in large languagemodels (LLMs), which possess extensive domain knowledge, their integration intocognitive diagnosis presents a promising opportunity. Despite this potential,integrating LLMs with CDMs poses significant challenges. LLMs are notwell-suited for capturing the fine-grained collaborative interactions betweenstudents and exercises, and the disparity between the semantic space of LLMsand the behavioral space of CDMs hinders effective integration. To addressthese issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD)framework, which is a model-agnostic framework utilizing LLMs to enhance CDMsand compatible with various CDM architectures. The KCD framework operates intwo stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosisstage, both students and exercises are diagnosed to achieve comprehensive anddetailed modeling. In the Cognitive Level Alignment stage, we bridge the gapbetween the CDMs' behavioral space and the LLMs' semantic space usingcontrastive learning and mask-reconstruction approaches. Experiments on severalreal-world datasets demonstrate the effectiveness of our proposed framework.</description>
      <author>example@mail.com (Zhiang Dong, Jingyuan Chen, Fei Wu)</author>
      <guid isPermaLink="false">2502.05556v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Estimation with missing not at random binary outcomes via exponential tilts</title>
      <link>http://arxiv.org/abs/2502.06046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了二元结果缺失非随机（MNAR）数据集的问题，并提出了一种基于指数倾斜的方法，这种方法不需要通常进行统计估计所需的'非响应工具变量'或'影子变量'。我们建立了足够的条件来确定倾斜参数的可识别性，并提出了一个用于估算这些参数的算法。根据这些倾斜参数估计值，我们提出了重要权加权和双重稳健估计器，以估计感兴趣的任何平均函数，并通过合成数据集验证了其性能。&lt;h4&gt;背景&lt;/h4&gt;在处理缺失非随机（MNAR）的数据时，传统的统计方法往往需要额外的信息如'非响应工具变量'或'影子变量'来提高估计的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于指数倾斜的方法用于处理二元结果缺失非随机数据集的问题，并验证该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种基于指数倾斜的新方法，以避开传统的需要额外信息（如'非响应工具变量'或'影子变量'）的要求；2. 确定了确定倾斜参数的可识别性的充分条件；3. 开发了一个算法来估计这些倾斜参数。&lt;h4&gt;主要发现&lt;/h4&gt;1. 提供了一种无需依赖特殊外部变量的新方法来处理MNAR数据集中的二元结果问题。 2. 基于提出的框架，实现了重要的加权和双重稳健的估计器用于任何感兴趣的平均函数，并且在合成数据集中验证了其性能。&lt;h4&gt;结论&lt;/h4&gt;利用所提的指数倾斜框架，在Waterbirds数据集上执行无监督迁移学习实验时，当响应变量来自目标域的数据缺失时，能够达到与黄金标准相媲美的预测表现。这表明该方法在处理MNAR问题上的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了具有二元结果的'非随机缺少（MNAR）数据集的问题，并提出了一种基于指数倾斜的方法，这种方法不需要通常进行统计估计所需的“非响应工具变量”或“影子变量”。我们建立了足够的条件来确定倾斜参数的可识别性，并提出了一个用于估算这些参数的算法。根据这些倾斜参数估计值，我们提出了重要权加权和双重稳健估计器以估计感兴趣的任何平均函数，并通过合成数据集验证了其性能。在Waterbirds数据集上的实验中，我们利用我们的倾斜框架执行无监督迁移学习，在响应变量来自目标域的数据缺失时，达到了与黄金标准相媲美的预测表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of missing not at random (MNAR) datasets with binaryoutcomes. We propose an exponential tilt based approach that bypasses anyknowledge on 'nonresponse instruments' or 'shadow variables' that are usuallyrequired for statistical estimation. We establish a sufficient condition foridentifiability of tilt parameters and propose an algorithm to estimate them.Based on these tilt parameter estimates, we propose importance weighted anddoubly robust estimators for any mean functions of interest, and validate theirperformances in a synthetic dataset. In an experiment with the Waterbirdsdataset, we utilize our tilt framework to perform unsupervised transferlearning, when the responses are missing from a target domain of interest, andachieve a prediction performance that is comparable to a gold standard.</description>
      <author>example@mail.com (Subha Maity)</author>
      <guid isPermaLink="false">2502.06046v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset</title>
      <link>http://arxiv.org/abs/2502.06180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in WASSA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了在Twitter上使用低资源语言数据进行情感和情绪分类的挑战，并评估了几种最先进的基于Transformer的预训练模型。&lt;h4&gt;背景&lt;/h4&gt;社交媒体已成为个人表达观点、分享经验的重要开放平台，但在推特上利用低资源语言的数据面临诸多困难，如内容稀缺、质量低下以及语言使用的巨大差异（包括俚语和代码混合）。&lt;h4&gt;目的&lt;/h4&gt;评估几种最先进的基于Transformer的预训练模型在肯尼亚使用代码混合数据的情感分析与情绪分类任务中的性能表现，并详细介绍了数据收集及标注的方法论及其遇到的数据整理阶段挑战。&lt;h4&gt;方法&lt;/h4&gt;使用监督学习和半监督学习两种方式，对四种最先进（SOTA）的Transformer预训练模型进行评估：XLM-R、mBERT、DistilBERT以及Afri-BERTa。具体描述了数据采集与注释的方法论及其在数据整理阶段遇到的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，对于情感分析任务，XLM-R模型（无论是监督学习还是半监督学习）都达到了最高的准确率和F1分数；而对于情绪分类，DistilBERT的监督模型表现最好，mBERT的半监督模型次之。Afri-BERTa模型在这两个任务中的准确性及F1得分均为最低值。&lt;h4&gt;结论&lt;/h4&gt;所有测试模型在预测中性情感方面存在倾向性，特别是Afri-BERTa模型对于共情情绪显示出最高的偏差和独特的敏感度。XLM-R在代码混合语言的情感分析与情绪分类任务上表现出色，尽管面临诸多挑战依然具有较高的准确性和F1分数。&lt;h4&gt;翻译&lt;/h4&gt;社交媒体已成为个人表达观点、分享经验的重要开放平台。然而，在Twitter这样的平台上利用低资源语言的数据面临着诸如内容稀缺和质量低下等巨大挑战，尤其是当出现俚语或代码混合使用时更是如此。该研究分析了肯尼亚的代码混合数据，并评估了几种最先进的（SOTA）基于Transformer预训练模型的情感和情绪分类能力，包括监督学习和半监督学习方法。文章详细描述了数据收集、注释的方法以及在数据整理阶段所遇到的挑战。实验结果显示，在情感分析任务中，XLM-R模型无论是通过监督学习还是半监督学习都达到了最高的准确率和F1分数；而在情绪分类方面，DistilBERT监督模型表现出色，其次为mBERT半监督模型。Afri-BERTa模型在这两项任务中的表现最弱。所有测试的模型倾向于预测中性情感，而Afri-BERTa模型对于共情情绪显示出最高的偏差和独特的敏感度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.18653/v1/2024.wassa-1.19&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social media has become a crucial open-access platform for individuals toexpress opinions and share experiences. However, leveraging low-resourcelanguage data from Twitter is challenging due to scarce, poor-quality contentand the major variations in language use, such as slang and code-switching.Identifying tweets in these languages can be difficult as Twitter primarilysupports high-resource languages. We analyze Kenyan code-switched data andevaluate four state-of-the-art (SOTA) transformer-based pretrained models forsentiment and emotion classification, using supervised and semi-supervisedmethods. We detail the methodology behind data collection and annotation, andthe challenges encountered during the data curation phase. Our results showthat XLM-R outperforms other models; for sentiment analysis, XLM-R supervisedmodel achieves the highest accuracy (69.2\%) and F1 score (66.1\%), XLM-Rsemi-supervised (67.2\% accuracy, 64.1\% F1 score). In emotion analysis,DistilBERT supervised leads in accuracy (59.8\%) and F1 score (31\%), mBERTsemi-supervised (accuracy (59\% and F1 score 26.5\%). AfriBERTa models show thelowest accuracy and F1 scores. All models tend to predict neutral sentiment,with Afri-BERT showing the highest bias and unique sensitivity to empathyemotion. https://github.com/NEtori21/Ride_hailing</description>
      <author>example@mail.com (Naome A. Etori, Maria L. Gini)</author>
      <guid isPermaLink="false">2502.06180v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>4DR P2T: 4D Radar Tensor Synthesis with Point Clouds</title>
      <link>http://arxiv.org/abs/2502.05550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了4D雷达点云到张量生成模型(4DR P2T)，利用条件生成对抗网络(cGAN)处理4D雷达数据，减少测量损失并优化深度学习应用。&lt;h4&gt;背景&lt;/h4&gt;在四维雷达点云生成中，使用恒虚警率(CFAR)算法去除杂波，但CFAR可能无法完全捕捉到目标的空间特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型来克服传统方法的局限性，同时提高数据的质量和减少测量损失以适应深度学习应用。&lt;h4&gt;方法&lt;/h4&gt;采用条件生成对抗网络(cGAN)，对其进行了修改以便有效处理4D雷达点云数据并生成张量数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的4DR P2T模型在K-Radar数据集上实现了平均PSNR为30.39dB和SSIM为0.96的效果。此外，分析显示5%分位数方法提供了最佳的整体性能，而1%分位数方法则在数据量减少与性能之间取得了良好的平衡。&lt;h4&gt;结论&lt;/h4&gt;4DR P2T模型有效解决了传统CFAR算法存在的问题，并且是用于深度学习应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种四维雷达点云生成模型的研究，该模型通过改进的条件生成对抗网络来处理四维雷达数据并减少测量损失。实验结果表明其在特定数据集上的优越性能和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In four-dimensional (4D) Radar-based point cloud generation, clutter removalis commonly performed using the constant false alarm rate (CFAR) algorithm.However, CFAR may not fully capture the spatial characteristics of objects. Toaddress limitation, this paper proposes the 4D Radar Point-to-Tensor (4DR P2T)model, which generates tensor data suitable for deep learning applicationswhile minimizing measurement loss. Our method employs a conditional generativeadversarial network (cGAN), modified to effectively process 4D Radar pointcloud data and generate tensor data. Experimental results on the K-Radardataset validate the effectiveness of the 4DR P2T model, achieving an averagePSNR of 30.39dB and SSIM of 0.96. Additionally, our analysis of different pointcloud generation methods highlights that the 5% percentile method provides thebest overall performance, while the 1% percentile method optimally balancesdata volume reduction and performance, making it well-suited for deep learningapplications.</description>
      <author>example@mail.com (Woo-Jin Jung, Dong-Hee Paek, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.05550v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Link Prediction for Directed Graphs</title>
      <link>http://arxiv.org/abs/2502.05724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;有向图链接预测及其在现实世界中的应用，以及改进现有评估基准的需求。&lt;h4&gt;背景&lt;/h4&gt;目前有多种方法用于有向图的链路预测任务，包括嵌入方法和图形神经网络（GNNs）。然而这些方法往往缺乏对表示能力的深入分析，并且使用的评价基准不足以进行公平评估。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架来评估现有方法的表达力，同时介绍一个新的基准测试DirLinkBench以应对当前实验设置中的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了新的有向图链路预测基准DirLinkBench，并且理论重新审视DiGAE，还提出了新的谱系定向图形自动编码器SDGAE。&lt;h4&gt;主要发现&lt;/h4&gt;目前的方法在新基准上难以取得强性能，而DiGAE总体表现最好。此外，研究展示了DiGAE的图卷积与无向二分图上的GCN一致，并提出了新颖的谱系有向图自编码器SDGAE，在DirLinkBench中取得了当前最佳结果。&lt;h4&gt;结论&lt;/h4&gt;分析了影响有向图链接预测的关键因素，并指出了开放性挑战。新的基准测试和研究方法为该领域提供了前进方向，有助于改进未来的研究成果。&lt;h4&gt;翻译&lt;/h4&gt;针对有向图的链路预测任务，本文提出了一种评估现有方法表示能力的统一框架，并且为了克服当前实验设置中的局限性，引入了新基准DirLinkBench。结果显示目前的方法在新的基准测试中难以取得强性能，而DiGAE总体表现最佳。此外还提出了谱系有向图自编码器SDGAE，在新基准中取得了最新成果。最后分析了一些关键因素，并强调了开放性的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction for directed graphs is a crucial task with diverse real-worldapplications. Recent advances in embedding methods and Graph Neural Networks(GNNs) have shown promising improvements. However, these methods often lack athorough analysis of embedding expressiveness and suffer from ineffectivebenchmarks for a fair evaluation. In this paper, we propose a unified frameworkto assess the expressiveness of existing methods, highlighting the impact ofdual embeddings and decoder design on performance. To address limitations incurrent experimental setups, we introduce DirLinkBench, a robust new benchmarkwith comprehensive coverage and standardized evaluation. The results show thatcurrent methods struggle to achieve strong performance on the new benchmark,while DiGAE outperforms others overall. We further revisit DiGAE theoretically,showing its graph convolution aligns with GCN on an undirected bipartite graph.Inspired by these insights, we propose a novel spectral directed graphauto-encoder SDGAE that achieves SOTA results on DirLinkBench. Finally, weanalyze key factors influencing directed link prediction and highlight openchallenges.</description>
      <author>example@mail.com (Mingguo He, Yuhe Guo, Yanping Zheng, Zhewei Wei, Stephan Günnemann, Xiaokui Xiao)</author>
      <guid isPermaLink="false">2502.05724v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Protecting Intellectual Property of EEG-based Neural Networks with Watermarking</title>
      <link>http://arxiv.org/abs/2502.05931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 13 figures, and 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于加密奇偶校验过滤器的水印框架，专门针对EEG（脑电图）基神经网络进行知识产权保护。&lt;h4&gt;背景&lt;/h4&gt;基于EEG的神经网络在医学诊断和脑机接口中发挥着关键作用，但由于依赖于敏感的神经生理数据且开发资源密集，面临重大的IP风险。当前的水印方法不能有效应对这些挑战。&lt;h4&gt;目的&lt;/h4&gt;通过提供一种专门针对EEG模型的独特水印框架来增强知识产权保护措施。&lt;h4&gt;方法&lt;/h4&gt;采用抗碰撞性散列和公钥加密技术，在训练过程中嵌入水印，确保最小失真（精度下降不超过5%）及高可靠性（100%的水印检测率）。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在对抗攻击下表现出持久性：即便经过严苛的神经元修剪后，带水印状态的分类准确度仍保持高于90%，而未被有效去除。此外，无法嵌入第二层水印而不会导致严重的准确性损失。&lt;h4&gt;结论&lt;/h4&gt;该方法通过DEAP数据集进行验证，在各种模型上实现超过99.4%的虚设嵌入精度，展示了其在保护敏感EEG模型方面的有效性，并保持了诊断实用性。&lt;h4&gt;翻译&lt;/h4&gt;基于脑电图（EEG）的神经网络在医疗诊断和脑机接口领域至关重要，但由于依赖于敏感的神经生理数据以及资源密集型开发过程，它们面临着重大的知识产权风险。现有的水印方法，尤其是使用抽象触发集的方法，在提供强大的身份验证方面效果不佳，并未能解决EEG模型特有的挑战。本文提出了一种基于加密奇偶校验过滤器的水印框架，专门用于保护基于EEG的神经网络。通过利用抗碰撞性散列和公钥加密技术，该框架在训练过程中嵌入水印，确保最少的失真（不超过5%的精度下降）并实现高可靠性（100%的水印检测率）。此方法经过了对抗攻击的严格评估，包括微调、迁移学习以及神经元修剪。结果表明，在极端修剪下，带水印的状态依然保持超过90%的分类准确度，而主任务性能则下降更快，从而有效阻止非法去除尝试。验证该方法对盗版行为的有效性时发现，无法嵌入第二层水印不会造成严重的精度损失（EEGNet和CCNN模型中的精度降低超过10%）。通过使用加密散列进行身份验证可以降低暴力破解攻击的成功概率。在DEAP数据集上，该方法实现了大于99.4%的虚设嵌入准确率，在各种模型中有效消除了假阳性问题（包括CCNN、EEGNet和TSception模型）。通过将奇偶校验过滤器与特定于EEG的适应性相结合，这项工作填补了神经生理学模型知识产权保护方面的关键空白，并为医疗保健和生物识别应用提供了安全且不可篡改的解决方案。该框架对对抗修改的鲁棒性彰显出其在保护敏感的EEG模型同时保持诊断实用性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; EEG-based neural networks, pivotal in medical diagnosis and brain-computerinterfaces, face significant intellectual property (IP) risks due to theirreliance on sensitive neurophysiological data and resource-intensivedevelopment. Current watermarking methods, particularly those using abstracttrigger sets, lack robust authentication and fail to address the uniquechallenges of EEG models. This paper introduces a cryptographic wonderfilter-based watermarking framework tailored for EEG-based neural networks.Leveraging collision-resistant hashing and public-key encryption, the wonderfilter embeds the watermark during training, ensuring minimal distortion ($\leq5\%$ drop in EEG task accuracy) and high reliability (100\% watermarkdetection). The framework is rigorously evaluated against adversarial attacks,including fine-tuning, transfer learning, and neuron pruning. Resultsdemonstrate persistent watermark retention, with classification accuracy forwatermarked states remaining above 90\% even after aggressive pruning, whileprimary task performance degrades faster, deterring removal attempts. Piracyresistance is validated by the inability to embed secondary watermarks withoutsevere accuracy loss ( $&gt;10\%$ in EEGNet and CCNN models). Cryptographichashing ensures authentication, reducing brute-force attack successprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,TSception), the method achieves $&gt;99.4\%$ null-embedding accuracy, effectivelyeliminating false positives. By integrating wonder filters with EEG-specificadaptations, this work bridges a critical gap in IP protection forneurophysiological models, offering a secure, tamper-proof solution forhealthcare and biometric applications. The framework's robustness againstadversarial modifications underscores its potential to safeguard sensitive EEGmodels while maintaining diagnostic utility.</description>
      <author>example@mail.com (Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares)</author>
      <guid isPermaLink="false">2502.05931v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf'25 (WWW'25) as a Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法RALLRec，用于增强基于大型语言模型的推荐系统。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型已被集成到推荐系统中以提高用户行为理解。然而现有Retrieval Augmented Generation (RAG) 方法主要依赖文本语义，并且常常无法有效整合最相关的项目。&lt;h4&gt;目的&lt;/h4&gt;通过引入联合表示学习方法，增强基于大语言模型的推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的方法RALLRec，该方法首先通过提示大型语言模型生成更详细的项目描述来增强文本语义，然后结合由LLM和推荐模型提取的文本与协同语义进行共同表示学习。考虑到用户兴趣的时间变化特性，引入了一种简单有效的重排序方法以捕捉用户的偏好动态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该方法的有效性，并通过公开代码供其他研究者参考。&lt;h4&gt;结论&lt;/h4&gt;RALLRec为基于大型语言模型的推荐系统提供了一个新的解决方案，提高了系统的准确性和相关性的性能。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型已被整合到推荐系统中以增强对用户行为的理解。进一步将检索增强生成（Retrieval Augmented Generation, RAG）技术融入这些系统，以便检索更多相关的项目并提高系统性能。但是现有RAG方法主要依赖于文本语义，并经常无法有效整合最相关的内容，这限制了系统的有效性。在这篇论文中，我们提出了表示学习用于检索增强大型语言模型推荐（RALLRec）。具体而言，通过提示大模型生成更详细的描述来增强文本语义，随后进行文本和协同语义的联合表示学习，这些分别由LLM 和推荐模型提取。考虑到用户兴趣的时间变化特性，我们进一步引入了一种简单而有效的重排序方法以捕捉用户的偏好动态变化。我们在三个真实数据集上进行了广泛的实验，并通过评估结果验证了该方法的有效性。代码在https://github.com/JianXu95/RALLRec 公开发布供参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been integrated into recommendation systemsto enhance user behavior comprehension. The Retrieval Augmented Generation(RAG) technique is further incorporated into these systems to retrieve morerelevant items and improve system performance. However, existing RAG methodsrely primarily on textual semantics and often fail to incorporate the mostrelevant items, limiting the effectiveness of the systems.  In this paper, we propose Representation learning for retrieval-AugmentedLarge Language model Recommendation (RALLRec). Specifically, we enhance textualsemantics by prompting LLMs to generate more detailed item descriptions,followed by joint representation learning of textual and collaborativesemantics, which are extracted by the LLM and recommendation models,respectively. Considering the potential time-varying characteristics of userinterest, a simple yet effective reranking method is further introduced tocapture the dynamics of user preference. We conducted extensive experiments onthree real-world datasets, and the evaluation results validated theeffectiveness of our method. Code is made public athttps://github.com/JianXu95/RALLRec.</description>
      <author>example@mail.com (Jian Xu, Sichun Luo, Xiangyu Chen, Haoming Huang, Hanxu Hou, Linqi Song)</author>
      <guid isPermaLink="false">2502.06101v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Efficient AC Power Flow Prediction in Power Grids</title>
      <link>http://arxiv.org/abs/2502.05702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, NeurIPS 2025,  https://github.com/Amirtalebi83/GNN-OptimalPowerFlow&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用图神经网络（GNN）解决电力系统交流潮流问题的创新方法。&lt;h4&gt;背景&lt;/h4&gt;交流最优潮流问题在降低发电成本的同时满足电网运营约束至关重要。传统的求解器难以处理大型系统的可扩展性，特别是在存在大量可再生能源源的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的方法来预测电力系统中的AC潮流解决方案，以应对传统方法在大规模复杂系统中面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;将电力网建模为一个图结构，其中节点代表电网的母线，边表示输电线路。研究了不同类型的GNN架构（包括GCN、GAT、SAGEConv和GraphConv），以实现高效的AC潮流预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于GNN的方法可以准确地预测交流功率流动解决方案，并且能够扩展到更大的系统，在计算时间上优于传统求解器。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了图神经网络在实时电网管理中的潜力，未来计划将模型应用于更大规模的电网系统中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文提出了一种新颖的方法，利用图神经网络（GNN）来解决电力网中的交流潮流问题。AC最优潮流对于降低发电成本同时满足电网操作约束至关重要。传统求解器在大型系统的可扩展性方面面临挑战，尤其是在存在大量可再生能源的情况下。我们的方法将电力系统建模为图形，其中母线是节点，输电线路是边。我们探索了不同类型的GNN架构，包括GCN、GAT、SAGEConv和GraphConv，以高效地预测交流潮流解决方案。我们在IEEE测试系统上的实验表明，GNN可以准确预测功率流解决方案，并能够扩展到更大的系统，在计算时间上优于传统求解器。这项工作强调了图神经网络在实时电网管理中的潜力，未来计划将模型应用于更大规模的电网中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel approach using Graph Neural Networks (GNNs) tosolve the AC Power Flow problem in power grids. AC OPF is essential forminimizing generation costs while meeting the operational constraints of thegrid. Traditional solvers struggle with scalability, especially in largesystems with renewable energy sources. Our approach models the power grid as agraph, where buses are nodes and transmission lines are edges. We exploredifferent GNN architectures, including GCN, GAT, SAGEConv, and GraphConv topredict AC power flow solutions efficiently. Our experiments on IEEE testsystems show that GNNs can accurately predict power flow solutions and scale tolarger systems, outperforming traditional solvers in terms of computation time.This work highlights the potential of GNNs for real-time power grid management,with future plans to apply the model to even larger grid systems.</description>
      <author>example@mail.com (Seyedamirhossein Talebi, Kaixiong Zhou)</author>
      <guid isPermaLink="false">2502.05702v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Target Speaker Lipreading by Audio-Visual Self-Distillation Pretraining and Speaker Adaptation</title>
      <link>http://arxiv.org/abs/2502.05758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to ESWA journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的唇读技术，旨在解决现有模型在跨语言应用和特定说话人适应方面的问题，并通过结合唇部区域兴趣（ROI）和面部输入来提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;基于多模态自蒸馏的自监督学习方法AV2vec在英语LRS3数据集上显示出了令人鼓舞的表现，但其训练成本高且非英语语言如中文缺乏足够的视听数据。此外，现有研究主要集中在说话者无关的唇读模型，难以处理不同说话者的风格差异。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文提出了一种综合方法，包括跨语言迁移学习、说话人适应策略和结合唇部ROI与面部输入的集成模型策略。&lt;h4&gt;方法&lt;/h4&gt;首先，研究了从源语言到目标语言的跨语言迁移学习；其次，提出了增强特定说话人的唇读准确性的说话人适应策略；最后，通过引入一种新的模型集成策略，将唇部ROI与面部输入相结合，大大提高了模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ChatCLR数据集的评估集中，该方法实现了77.3%的字符错误率（CER），比2024年中文唇读挑战赛的顶级结果更低。&lt;h4&gt;结论&lt;/h4&gt;所提出的改进方案有效提升了跨语言和特定说话人的唇读模型性能，并通过引入新的模型集成策略进一步优化了整体表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lipreading is an important technique for facilitating human-computerinteraction in noisy environments. Our previously developed self-supervisedlearning method, AV2vec, which leverages multimodal self-distillation, hasdemonstrated promising performance in speaker-independent lipreading on theEnglish LRS3 dataset. However, AV2vec faces challenges such as high trainingcosts and a potential scarcity of audio-visual data for lipreading in languagesother than English, such as Chinese. Additionally, most studies concentrate onspeakerindependent lipreading models, which struggle to account for thesubstantial variation in speaking styles across di?erent speakers. To addressthese issues, we propose a comprehensive approach. First, we investigatecross-lingual transfer learning, adapting a pre-trained AV2vec model from asource language and optimizing it for the lipreading task in a target language.Second, we enhance the accuracy of lipreading for specific target speakersthrough a speaker adaptation strategy, which is not extensively explored inprevious research. Third, after analyzing the complementary performance oflipreading with lip region-of-interest (ROI) and face inputs, we introduce amodel ensembling strategy that integrates both, signi?cantly boosting modelperformance. Our method achieved a character error rate (CER) of 77.3% on theevaluation set of the ChatCLR dataset, which is lower than the top result fromthe 2024 Chat-scenario Chinese Lipreading Challenge.</description>
      <author>example@mail.com (Jing-Xuan Zhang, Tingzhi Mao, Longjiang Guo, Jin Li, Lichen Zhang)</author>
      <guid isPermaLink="false">2502.05758v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Approximation of Visual Autoregressive Transformers</title>
      <link>http://arxiv.org/abs/2502.06167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了基于变压器的基础模型的理论极限，特别探讨了视觉自回归（VAR）变压器在图像生成中的作用和潜力。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的方法包括Diffusion Transformers。新的VAR Transformer框架通过一种新颖、可扩展且从粗到细的'下一尺度预测'方法，在图像合成任务中表现出卓越性能，并超过了所有先前的方法。&lt;h4&gt;目的&lt;/h4&gt;探讨单头VAR变压器在自注意力层和插值层上的通用性，证明它们可以作为任意图像到图像Lipschitz函数的泛化逼近器。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和验证VAR Transformer在单一头部设置下的性能，并进一步展示流基自动回归Transformer继承了相似的近似能力。&lt;h4&gt;主要发现&lt;/h4&gt;证明简单的单头VAR变压器具有通用性，可以用于任意图像到图像Lipschitz函数的泛化逼近。此外还表明基于流动的自回归变压器也具备类似的近似能力。&lt;h4&gt;结论&lt;/h4&gt;研究成果为有效且计算效率高的VAR Transformer策略提供了重要的设计原则，并能进一步应用于更复杂的VAR模型在图像生成和相关领域的应用。&lt;h4&gt;翻译&lt;/h4&gt;我们探讨了基于变压器的基础模型的基本限制，扩展分析包括视觉自回归（VAR）变压器。VAR是使用新颖、可扩展的从粗到细“下一尺度预测”框架生成图像的重要步骤。这些模型设立了新的质量标准，在所有先前的方法中表现最佳，包括扩散变换器，并在图像合成任务中保持了最先进的性能。我们的主要贡献在于证明对于单头VAR变压器具有单一自注意力层和单一插值层的情况而言，VAR Transformer是通用的。从统计学的角度来看，我们证明了这样的简单VAR变压器可以作为任何图像到图像Lipschitz函数的泛化逼近器。此外，我们展示了流基自动回归变换器继承相似的近似能力。我们的结果为有效和计算效率高的VAR Transformer策略提供了重要的设计原则，这些策略可以用于扩展其在更复杂的VAR模型中的应用价值，在图像生成和其他相关领域中具有实用意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the fundamental limits of transformer-based foundation models,extending our analysis to include Visual Autoregressive (VAR) transformers. VARrepresents a big step toward generating images using a novel, scalable,coarse-to-fine ``next-scale prediction'' framework. These models set a newquality bar, outperforming all previous methods, including DiffusionTransformers, while having state-of-the-art performance for image synthesistasks. Our primary contributions establish that, for single-head VARtransformers with a single self-attention layer and single interpolation layer,the VAR Transformer is universal. From the statistical perspective, we provethat such simple VAR transformers are universal approximators for anyimage-to-image Lipschitz functions. Furthermore, we demonstrate that flow-basedautoregressive transformers inherit similar approximation capabilities. Ourresults provide important design principles for effective and computationallyefficient VAR Transformer strategies that can be used to extend their utilityto more sophisticated VAR models in image generation and other related areas.</description>
      <author>example@mail.com (Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song)</author>
      <guid isPermaLink="false">2502.06167v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Visual Representation Learning via Knowledge Distillation from Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2502.05766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to Pattern Recognition&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个基于语音基础模型（SFM）的跨模态知识蒸馏的方法，用于提升音频-视觉表示学习的能力。&lt;h4&gt;背景&lt;/h4&gt;多模态语音处理任务中，如唇读和音频-视觉语音识别，需要有效的音频-视觉表示学习。最近的研究表明，语音基础模型在各种与语音相关的任务中展现了强大的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;利用跨模态知识蒸馏方法从SFM中提取信息以增强多模态语音处理的能力。&lt;h4&gt;方法&lt;/h4&gt;将SFM作为教师模型，通过清洁音频输入获取其多层次的隐藏表示，并引入多教师集成方法对接收音频-视觉数据的学生模型进行训练。采用了新的表征知识蒸馏损失函数在预训练阶段和微调阶段均加以应用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在自动语音识别、视觉语音识别和音频-视觉语音识别任务上均取得了优于或至少可与现有最先进的基准方法相媲美的性能。同时进行了详尽的消融研究及学习表示图可视化以评估所提方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过跨模态知识蒸馏，从SFM中提取的知识能够显著提升音频-视觉表示模型在多模态语音任务上的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual representation learning is crucial for advancing multimodalspeech processing tasks, such as lipreading and audio-visual speechrecognition. Recently, speech foundation models (SFMs) have shown remarkablegeneralization capabilities across various speech-related tasks. Building onthis progress, we propose an audio-visual representation learning model thatleverages cross-modal knowledge distillation from SFMs. In our method, SFMsserve as teachers, from which multi-layer hidden representations are extractedusing clean audio inputs. We also introduce a multi-teacher ensemble method todistill the student, which receives audio-visual data as inputs. A novelrepresentational knowledge distillation loss is employed to train the studentduring pretraining, which is also applied during finetuning to further enhancethe performance on downstream tasks. Our experiments utilized both aself-supervised SFM, WavLM, and a supervised SFM, iFLYTEK-speech. The resultsdemonstrated that our proposed method achieved superior or at least comparableperformance to previous state-of-the-art baselines across automatic speechrecognition, visual speech recognition, and audio-visual speech recognitiontasks. Additionally, comprehensive ablation studies and the visualization oflearned representations were conducted to evaluate the effectiveness of ourproposed method.</description>
      <author>example@mail.com (Jing-Xuan Zhang, Genshun Wan, Jianqing Gao, Zhen-Hua Ling)</author>
      <guid isPermaLink="false">2502.05766v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>NOMANet: A Graph Neural Network Enabled Power Allocation Scheme for NOMA</title>
      <link>http://arxiv.org/abs/2502.05592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的非正交多址接入（NOMA）网络功率分配方案。&lt;h4&gt;背景&lt;/h4&gt;在下行场景中，一个基站为多个用户通过多个子信道进行服务。由于可用子信道的数量少于用户的数量，因此一些用户必须共享同一个子信道。&lt;h4&gt;目的&lt;/h4&gt;旨在最大化系统的能源效率，并确保每个用户的速率要求和总体预算得以满足。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度学习的方法NOMA net（NOMANet）来解决上述问题。该网络采用图神经网络，将信道状态信息映射到所有子信道的功率分配方案上。通过多头注意机制和残差/密集连接增强了特征提取能力。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明，未经过监督训练的NOMANet实现了与连续凸逼近方法相近的表现，但其推理速度提高了约700倍。此外，NOMANet具有用户数量和子信道数量可扩展性的特点。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在性能和计算效率方面均表现优越，并且具备良好的可扩展性，能够应对不同规模的网络需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a graph neural network (GNN) enabled power allocationscheme for non-orthogonal multiple access (NOMA) networks. In particular, adownlink scenario with one base station serving multiple users over severalsubchannels is considered, where the number of subchannels is less than thenumber of users, and thus, some users have to share a subchannel via NOMA. Ourgoal is to maximize the system energy efficiency subject to the raterequirement of each user and the overall budget. We propose a deep learningbased approach termed NOMA net (NOMANet) to address the considered problem.Particularly, NOMANet is GNN-based, which maps channel state information to thedesired power allocation scheme for all subchannels. The multi-head attentionand the residual/dense connection are adopted to enhance the featureextraction. The output of NOMANet is guaranteed to be feasible via thecustomized activation function and the penalty method. Numerical results showthat NOMANet trained unsupervised achieves performance close to that of thesuccessive convex approximation method but with a faster inference speed byabout $700$ times. Besides, NOMANet is featured by its scalability to bothusers and subchannels.</description>
      <author>example@mail.com (Yipu Hou, Yang Lu, Wei Chen, Bo Ai, Dusit Niyato, Zhiguo Ding)</author>
      <guid isPermaLink="false">2502.05592v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Coalition Formation for Heterogeneous Federated Learning Enabled Channel Estimation in RIS-assisted Cell-free MIMO</title>
      <link>http://arxiv.org/abs/2502.05538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于联盟形成的异构联邦学习框架，用于解决重配置智能表面辅助的非蜂窝多输入多输出通信系统中的下行链路信道估计问题。&lt;h4&gt;背景&lt;/h4&gt;传统的信道估计算法主要依赖于集中式的深度学习方法来处理高维和复杂的级联信道。这些算法需要所有用户的数据进行集中式模型训练，导致了过高的通信开销和显著的隐私问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架以解决上述挑战，该框架通过利用联盟形成来指导异构联邦学习用户组的形成，从而实现有效的信道估计。&lt;h4&gt;方法&lt;/h4&gt;引入了一种分布式深度强化学习（DRL）方法，使每个联邦学习用户能够智能地独立决定是否加入或离开一个联盟。此外，为加速DRL-FL收敛过程和减轻终端用户的计算负担，还提出了一种转移学习方法。&lt;h4&gt;主要发现&lt;/h4&gt;与基准相比，所提出的框架在减少终端用户的计算开销方面表现出16%的显著改善，并提高了数据隐私性和20%的信道估计准确性。&lt;h4&gt;结论&lt;/h4&gt;通过使用基于联盟形成的异构联邦学习框架，在保持或提高信道估计精度的同时，可以有效降低通信开销和保护用户隐私。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Downlink channel estimation remains a significant bottleneck inreconfigurable intelligent surface-assisted cell-free multiple-inputmultiple-output communication systems. Conventional approaches primarily relyon centralized deep learning methods to estimate the high-dimensional andcomplex cascaded channels. These methods require data aggregation from allusers for centralized model training, leading to excessive communicationoverhead and significant data privacy concerns. Additionally, the large size oflocal learning models imposes heavy computational demands on end users,necessitating strong computational capabilities that most commercial deviceslack. To address the aforementioned challenges, a coalition-formation-guidedheterogeneous federated learning (FL) framework is proposed. This frameworkleverages coalition formation to guide the formation of heterogeneous FL usergroups for efficient channel estimation. Specifically, by utilizing adistributed deep reinforcement learning (DRL) approach, each FL userintelligently and independently decides whether to join or leave a coalition,aiming at improving channel estimation accuracy, while reducing local modelsize and computational costs for end users. Moreover, to accelerate the DRL-FLconvergence process and reduce computational burdens on end users, a transferlearning method is introduced. This method incorporates both received referencesignal power and distance similarity metrics, by considering that nodes withsimilar distances to the base station and comparable received signal power havea strong likelihood of experiencing similar channel fading. Massive experimentsperformed that reveal that, compared with the benchmarks, the proposedframework significantly reduces the computational overhead of end users by 16%,improves data privacy, and improves channel estimation accuracy by 20%.</description>
      <author>example@mail.com (Nan Qi, Haoxuan Liu, Theodoros A. Tsiftsis, Alexandros-Apostolos A. Boulogeorgos, Fuhui Zhou, Shi Jin, Qihui Wu)</author>
      <guid isPermaLink="false">2502.05538v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model of Electronic Medical Records for Adaptive Risk Estimation</title>
      <link>http://arxiv.org/abs/2502.06124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ETHOS是一种基于Transformer架构的AI模型，用于预测患者健康时间线（PHT）。ARES系统利用ETHOS来计算个性化和动态的风险概率，并且提供了个人解释模块以识别影响风险评估的关键临床因素。&lt;h4&gt;背景&lt;/h4&gt;传统的预警系统在预测医院入院、重症监护病房（ICU）入院和住院延长等方面存在局限性，需要一种能够提供实时、个性化的风险估计的模型来改进这些系统的性能。&lt;h4&gt;目的&lt;/h4&gt;开发ETHOS模型以改善患者健康时间线的预测，并通过ARES系统将该模型应用于临床决策支持，提高对患者的诊断信任度。&lt;h4&gt;方法&lt;/h4&gt;利用MIMIC-IV v2.2数据集，在急诊科环境中评估了ETHOS和ARES系统的性能。处理后的数据包括来自超过299,721名独特患者的数据，转换为285,622条PHT记录。&lt;h4&gt;主要发现&lt;/h4&gt;ETHOS在预测医院入院、ICU入院和住院延长方面优于基准模型，并且其风险估计的个性化解释模块能提供有助于临床决策的支持信息。&lt;h4&gt;结论&lt;/h4&gt;ARES系统，基于ETHOS模型，为实时个性化风险评估提供了强大工具，增强了医生对模型的信任。该系统的灵活性和准确性使其成为临床上具有变革性的工具。&lt;h4&gt;翻译&lt;/h4&gt;我们开发了增强型变换器健康结果模拟（ETHOS），这是一个AI模型，它从电子病历中获取患者健康时间线(PHT)并通过转换架构来预测未来的PHT。ARES利用ETHOS计算个性化且动态的风险概率，并包括一个解释模块以识别影响个人风险评估的关键临床因素。在MIMIC-IV v2.2数据集的急诊科环境中，评价了该系统的性能并将其与传统的早期预警系统和机器学习模型进行了比较。我们处理了超过299,721个独特患者的数据为PHTs，其中60%包括住院记录，并包含3亿5千多万个标记。ETHOS在预测医院入院、ICU入院以及长时间住院方面优于基准模型，并实现了优异的AUC分数。基于ETHOS的风险评估显示了良好的鲁棒性，并通过校准曲线得到了验证。个性化解释模块提供了有助于临床决策的支持信息，表明其为患者特定风险因素提供见解。ARES系统提高了预测健康AI在动态、实时和个性化风险估计方面的功能，通过提供个性化的解释来增强医生的信任度。该系统的灵活性及其准确性使其成为临床决策支持中具有变革性的工具，有可能改善急诊科和住院患者的治疗结果及资源分配。我们将在github.com/ipolharvard/ethos-ares公开完整代码以促进未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOSpredicts future PHTs using transformer-based architectures. The Adaptive RiskEstimation System (ARES) employs ETHOS to compute dynamic and personalized riskprobabilities for clinician-defined critical events. ARES incorporates apersonalized explainability module that identifies key clinical factorsinfluencing risk estimates for individual patients. ARES was evaluated on theMIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking itsperformance against traditional early warning systems and machine learningmodels. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,with 60% including hospital admissions. The dataset contained over 357 milliontokens. ETHOS outperformed benchmark models in predicting hospital admissions,ICU admissions, and prolonged hospital stays, achieving superior AUC scores.ETHOS-based risk estimates demonstrated robustness across demographic subgroupswith strong model reliability, confirmed via calibration curves. Thepersonalized explainability module provides insights into patient-specificfactors contributing to risk. ARES, powered by ETHOS, advances predictivehealthcare AI by providing dynamic, real-time, and personalized risk estimationwith patient-specific explainability to enhance clinician trust. Itsadaptability and superior accuracy position it as a transformative tool forclinical decision-making, potentially improving patient outcomes and resourceallocation in emergency and inpatient settings. We release the full code atgithub.com/ipolharvard/ethos-ares to facilitate future research.</description>
      <author>example@mail.com (Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek)</author>
      <guid isPermaLink="false">2502.06124v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Robust Deep Signed Graph Clustering via Weak Balance Theory</title>
      <link>http://arxiv.org/abs/2502.05472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by WWW25 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为DSGC的深度正负图聚类框架，旨在解决现有技术在噪声处理和社区结构边界划分方面的不足。&lt;h4&gt;背景&lt;/h4&gt;签名图聚类用于探索既有积极关系也有消极关系的社会网络中的社区结构。当前面临的主要挑战是现有的光谱方法对噪声非常敏感以及主流签名图神经网络中受Social Balance Theory影响的‘敌人的敌人就是我的朋友’原则导致群组边界狭窄或中断。&lt;h4&gt;目的&lt;/h4&gt;通过引入Weak Balance理论，提高预处理和编码过程以实现更稳健的表现学习。&lt;h4&gt;方法&lt;/h4&gt;DSGC框架包括Violation Sign-Refine（用高阶邻居信息纠正噪声边）和Density-based Augmentation（根据弱平衡原则在群内添加正边，在群间添加负边），并开发了签名神经网络来强调负面连接节点之间的区别，最后通过最小化正则聚类损失优化聚类分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明DSGC框架在合成和真实数据集上均显著优于所有基线方法，确立了新的性能基准。&lt;h4&gt;结论&lt;/h4&gt;本文提出的DSGC框架有效解决了现有签名图聚类算法中的噪声问题，并且更好地保持了社区结构的边界，从而提高了聚类质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：正负图聚类是发现同时具有积极和消极关系的社会网络中社区结构的关键技术。我们识别出该领域面临的两个主要挑战：i) 当前的光谱方法在实际场景中的噪声普遍存在时非常脆弱；ii) 由Social Balance Theory衍生的‘敌人的敌人就是我的朋友’原则往往限制或打断主流签名图神经网络中的群边界划分。为解决这些挑战，我们提出了一种名为DSGC（Deep Signed Graph Clustering）的框架，该框架利用Weak Balance理论增强预处理和编码过程以实现稳健的表现学习。首先，DSGC引入Violation Sign-Refine算法通过使用高阶邻居信息来纠正噪声边对正负网络进行去噪。随后，基于密度的增强技术通过在群内添加正边以及在不同群之间添加负边来加强语义结构，并遵循弱平衡原则。框架利用弱平衡原则开发了以聚类为导向的签名神经网络，通过强调负面连接节点之间的区别来拓宽群边界。最后，DSGC通过最小化一个正则化的聚类损失来进行最佳分配优化。合成和真实数据集上的综合实验显示DSGC始终优于所有基线方法，确立了一项新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714915&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signed graph clustering is a critical technique for discovering communitystructures in graphs that exhibit both positive and negative relationships. Wehave identified two significant challenges in this domain: i) existing signedspectral methods are highly vulnerable to noise, which is prevalent inreal-world scenarios; ii) the guiding principle ``an enemy of my enemy is myfriend'', rooted in \textit{Social Balance Theory}, often narrows or disruptscluster boundaries in mainstream signed graph neural networks. Addressing thesechallenges, we propose the \underline{D}eep \underline{S}igned\underline{G}raph \underline{C}lustering framework (DSGC), which leverages\textit{Weak Balance Theory} to enhance preprocessing and encoding for robustrepresentation learning. First, DSGC introduces Violation Sign-Refine todenoise the signed network by correcting noisy edges with high-order neighborinformation. Subsequently, Density-based Augmentation enhances semanticstructures by adding positive edges within clusters and negative edges acrossclusters, following \textit{Weak Balance} principles. The framework thenutilizes \textit{Weak Balance} principles to develop clustering-oriented signedneural networks to broaden cluster boundaries by emphasizing distinctionsbetween negatively linked nodes. Finally, DSGC optimizes clustering assignmentsby minimizing a regularized clustering loss. Comprehensive experiments onsynthetic and real-world datasets demonstrate DSGC consistently outperforms allbaselines, establishing a new benchmark in signed graph clustering.</description>
      <author>example@mail.com (Peiyao Zhao, Xin Li, Zeyu Zhang, Mingzhong Wang, Xueying Zhu, Lejian Liao)</author>
      <guid isPermaLink="false">2502.05472v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Calibrated Unsupervised Anomaly Detection in Multivariate Time-series using Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.03245v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication and presentation at the  2025 IEEE International systems Conference (SysCon)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用强化学习在自编码器潜在空间中的无监督异常检测方法，特别是在多变量时间序列数据中。提出了一种利用小波分析增强异常检测的新策略。&lt;h4&gt;背景&lt;/h4&gt;对于无监督异常检测的一个重要挑战在于缺乏足够的异常样本数据，这导致模型难以区分正常事件与异常事件，并产生大量的假阴性错误。&lt;h4&gt;目的&lt;/h4&gt;通过强化学习在训练过程中促进探索和开发的平衡，防止过拟合并提高模型性能。同时利用小波分析来捕捉不同时间分辨率下的细微变化，提升检测精度。&lt;h4&gt;方法&lt;/h4&gt;引入了自编码器潜在空间中的强化学习机制，并结合生成合成异常数据的方法调整决策边界。此外还嵌入了一套监督框架以辅助无监督学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过小波系数捕捉到的数据突变与细微变化可以显著提高检测精度，而采用合成异常样本校准模型的决策边界，则有助于进一步明确正常模式和异常模式之间的界限。&lt;h4&gt;结论&lt;/h4&gt;利用强化学习与小波分析结合的方法能够有效克服无监督异常检测中的难题，提高算法在实际应用中的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;该论文研究了使用自编码器潜在空间中强化学习（RL）的多变量时间序列数据无监督异常检测方法。一个显著挑战是缺乏异常样本数据，这可能导致将异常误判为正常事件，从而增加假阴性的数量。RL可以通过促进探索和在训练过程中平衡利用来克服这一限制，并有效防止过拟合。此外还采用了小波分析以增强异常检测能力，通过将其时间序列分解成时间和频率域，能够捕捉到多个分辨率下的异常情况，提取的小波系数可用于检测数据中的突然变化及微小波动，从而优化异常检测过程。最后，我们通过生成合成异常样本并嵌入监督框架来校准决策边界，这种监督组件有助于无监督学习过程中细化决策边界，并提高模型区分正常模式和异常模式的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates unsupervised anomaly detection in multivariatetime-series data using reinforcement learning (RL) in the latent space of anautoencoder. A significant challenge is the limited availability of anomalousdata, often leading to misclassifying anomalies as normal events, thus raisingfalse negatives. RL can help overcome this limitation by promoting explorationand balancing exploitation during training, effectively preventing overfitting.Wavelet analysis is also utilized to enhance anomaly detection, enablingtime-series data decomposition into both time and frequency domains. Thisapproach captures anomalies at multiple resolutions, with wavelet coefficientsextracted to detect both sudden and subtle shifts in the data, thereby refiningthe anomaly detection process. We calibrate the decision boundary by generatingsynthetic anomalies and embedding a supervised framework within the model. Thissupervised element aids the unsupervised learning process by fine-tuning thedecision boundary and increasing the model's capacity to distinguish betweennormal and anomalous patterns effectively.</description>
      <author>example@mail.com (Saba Sanami, Amir G. Aghdam)</author>
      <guid isPermaLink="false">2502.03245v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science</title>
      <link>http://arxiv.org/abs/2502.06084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合预训练机器学习模型和基于物理的模型的新型框架，旨在提高复杂系统中多个耦合过程建模的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的物理引导型机器学习方法主要适用于孤立且相对简单的任务，难以应对包含多个相互作用进程及大量影响特征的复杂科学体系。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时利用预训练ML模型和基于物理模型优势的新框架，以增强在多耦合过程中的建模能力。&lt;h4&gt;方法&lt;/h4&gt;构建了一个模拟环境系统，并采用基于物理的模型生成各种影响因素和变量。在此基础上进行预训练，之后使用真实观测数据对特定任务进行微调，同时保持与已知物理学原理（如质量守恒和能量守恒原则）的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的PGFM框架在现实湖泊中的水温及溶解氧动态建模中表现出有效性，并且具有广泛的应用前景，尤其是在那些使用基于物理模型的科学领域内。&lt;h4&gt;结论&lt;/h4&gt;通过将预训练ML模型与基于物理的模型相结合的方式可以有效改善复杂系统中多个耦合过程的建模精度和效率。&lt;h4&gt;翻译&lt;/h4&gt;物理学指导型机器学习(PGML)方法因其能够整合科学理论以增强机器学习模型而被用于科学研究。然而，大多数PGML方法仅适用于孤立且简单的任务，限制了它们在包含多进程互作及大量影响因子复杂体系中的应用能力。本文提出了一种物理引导型基础模型(PGFM)，它结合预训练的机器学习模型和基于物理学的模型，并利用这些模型的优势来改进多个耦合过程建模效果。为了有效进行预训练，我们构建了一个包含各种影响因素和变量(由基于物理的模型生成)模拟环境体系。该模型在这一系统中通过多任务目标引导下适应性选择重要的特征交互完成预训练，在特定的任务中使用真实观察值对模型微调，并保持与质量守恒及能量守恒等已确立的物理学原理的一致性。我们展示了这种建模方法在现实世界湖泊中的水温及溶解氧动态预测中的有效性，所提出的PGFM同样适用于广泛采用基于物理模型的研究领域内。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-guided machine learning (PGML) has become a prevalent approach instudying scientific systems due to its ability to integrate scientific theoriesfor enhancing machine learning (ML) models. However, most PGML approaches aretailored to isolated and relatively simple tasks, which limits theirapplicability to complex systems involving multiple interacting processes andnumerous influencing features. In this paper, we propose a\textit{\textbf{P}hysics-\textbf{G}uided \textbf{F}oundation \textbf{M}odel(\textbf{PGFM})} that combines pre-trained ML models and physics-based modelsand leverages their complementary strengths to improve the modeling of multiplecoupled processes. To effectively conduct pre-training, we construct asimulated environmental system that encompasses a wide range of influencingfeatures and various simulated variables generated by physics-based models. Themodel is pre-trained in this system to adaptively select important featureinteractions guided by multi-task objectives. We then fine-tune the model foreach specific task using true observations, while maintaining consistency withestablished physical theories, such as the principles of mass and energyconservation. We demonstrate the effectiveness of this methodology in modelingwater temperature and dissolved oxygen dynamics in real-world lakes. Theproposed PGFM is also broadly applicable to a range of scientific fields wherephysics-based models are being used.</description>
      <author>example@mail.com (Runlong Yu, Chonghao Qiu, Robert Ladwig, Paul Hanson, Yiqun Xie, Xiaowei Jia)</author>
      <guid isPermaLink="false">2502.06084v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Enabled Pinching Antennas</title>
      <link>http://arxiv.org/abs/2502.05447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了图神经网络（GNN）在夹钳天线系统中用于同时优化天线布局和功率分配的传输设计。通过将配备有夹钳天线的下行通信系统建模为一个二分图，并提出了一种基于图注意力网络（GAT）的方法，称为BGAT模型来解决能效最大化的优化问题。&lt;h4&gt;背景&lt;/h4&gt;夹钳天线技术是一种新型柔性天线技术，它不仅能够对抗大规模路径损耗，还能灵活地重新配置天线阵列。该技术通过在任意长度的波导上应用小尺寸介电粒子，在靠近用户的位置布置天线以避免显著的大规模路径损耗。&lt;h4&gt;目的&lt;/h4&gt;研究基于图神经网络（GNN）的方法来同时优化夹钳天线系统的布局和功率分配，从而提高能量效率（EE）。&lt;h4&gt;方法&lt;/h4&gt;将装有夹钳天线的下行通信系统建模为二分图，并提出了一个称为BGAT（双图注意力网络）的新模型，该模型基于图注意力网络，以解决能效最大化问题。利用定制化的读取过程确保了可行解并促进无监督训练。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明夹钳天线系统在提高能源效率方面和所提出的BGAT模型的优越性、可扩展性和计算效率方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究通过引入基于图神经网络的方法，为夹钳天线系统的优化提供了一种新的有效途径，并验证了其潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pinching-antenna system is a novel flexible-antenna technology, which hasthe capabilities not only to combat large-scale path loss, but also toreconfigure the antenna array in a flexible manner. The key idea of pinchingantennas is to apply small dielectric particles on a waveguide of arbitrarylength, so that they can be positioned close to users to avoid significantlarge-scale path loss. This paper investigates the graph neural network (GNN)enabled transmit design for the joint optimization of antenna placement andpower allocation in pinching-antenna systems. We formulate the downlinkcommunication system equipped with pinching antennas as a bipartite graph, andpropose a graph attention network (GAT) based model, termed bipartite GAT(BGAT), to solve an energy efficiency (EE) maximization problem. With thetailored readout processes, the BGAT guarantees a feasible solution, which alsofacilitates the unsupervised training. Numerical results demonstrate theeffectiveness of pinching antennas in enhancing the system EE as well as theproposed BGAT in terms of optimality, scalability and computational efficiency.</description>
      <author>example@mail.com (Xinke Xie, Yang Lu, Zhiguo Ding)</author>
      <guid isPermaLink="false">2502.05447v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions</title>
      <link>http://arxiv.org/abs/2502.05553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于概率机制动态调整词元表示的框架，用于改进语言模型在推理阶段的表现。&lt;h4&gt;背景&lt;/h4&gt;静态或确定性的词嵌入限制了模型处理复杂语境的能力。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的转换框架，通过概率更新使每个词元嵌入能够适应性地改变，同时保持其意义的一致性和完整性。&lt;h4&gt;方法&lt;/h4&gt;在提出的框架中，词元的表示根据上下文进行动态的概率调整。实验表明这种方法提高了模型词汇多样性、生成一致性和低频词汇保留能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过统计分析显示，基于概率机制的方法能够更灵活地改变嵌入表示且不会丧失连贯性；同时，这种框架在文本完成准确性、对话一致性以及结构复杂度上有显著改进。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，引入的概率机制虽带来轻微的计算开销，但在保持生成效率的同时提高了表达能力。此外，概率更新保留了语义分组并支持上下文驱动的变化，进一步验证了该转换机制的有效性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;随机嵌入转移通过动态调整词元表示来引入一种概率机制，以此缓解静态或确定性嵌入施加的限制。提出的转换框架中每个词元嵌入通过概率更新演变，确保适应性的同时保持语义完整性。实证评估表明，包含随机过渡的模型词汇多样性更高、生成一致性更好以及低频词汇保留能力更强，这导致了更丰富的句法结构和减少对高概率选择的依赖。跨变压器层的嵌入漂移统计分析显示表示演化更加灵活且不失连贯性，支持受控随机性有助于上下文敏感表示学习的观点。实验结果表明，引入的概率嵌入带来了轻微计算开销但保持生成效率，进一步证实其在大规模应用中的可行性。与传统嵌入方法进行比较的研究强调了文本完成准确性、对话一致性和结构复杂度的可测量改进，确认了随机过渡增强表达能力的有效性。聚类模式显示概率更新保留有意义的语义组同时支持上下文驱动的变化，进一步验证转换机制的稳定性。性能指标表明，随机过渡平衡适应性与控制，确保生成输出在无过度随机化的前提下保持语言连贯性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stochastic embedding transitions introduce a probabilistic mechanism foradjusting token representations dynamically during inference, mitigating theconstraints imposed through static or deterministic embeddings. A transitionframework was proposed in which each token embedding evolved throughprobabilistic updates, ensuring adaptability while preserving semanticintegrity across linguistic contexts. Empirical evaluations demonstrated thatmodels incorporating stochastic transitions exhibited greater lexicaldiversity, improved generative coherence, and enhanced retention oflow-frequency vocabulary, contributing to more varied sentence structures andreduced reliance on high-probability token selections. Statistical analyses ofembedding drift across transformer layers indicated that representationsevolved more flexibly without losing coherence, supporting the hypothesis thatcontrolled stochasticity facilitated context-sensitive representation learning.Experimental results revealed that probabilistic embeddings introduced minorcomputational overhead while maintaining generative efficiency, reinforcingtheir feasibility in large-scale applications. A comparative study withtraditional embedding approaches highlighted measurable gains in textcompletion accuracy, dialogue coherence, and structural complexity, confirmingthe effectiveness of stochastic transitions in enhancing representationexpressiveness. Clustering patterns in the embedding space suggested thatprobabilistic updates preserved meaningful semantic groupings while enablingcontext-driven shifts, further validating the stability of the transitionmechanism. Performance metrics indicated that stochastic transitions balancedadaptability and control, ensuring that generative outputs remainedlinguistically coherent without excessive randomness.</description>
      <author>example@mail.com (Stefan Whitaker, Colin Sisate, Marcel Windsor, Nikolai Fairweather, Tarquin Goldborough, Oskar Lindenfeld)</author>
      <guid isPermaLink="false">2502.05553v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Forgetting during Finetuning with Pretraining Data Injection</title>
      <link>http://arxiv.org/abs/2502.06042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 15 figures, preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了通过微调预训练模型来提升特定领域性能的方法，并研究了在目标数据有限和模型规模变化时，如何量化过度拟合和知识遗忘的现象。&lt;h4&gt;背景&lt;/h4&gt;为了使语言模型更好地适应特定领域的任务，通常的做法是使用从该领域获取的数据对预训练模型进行微调。然而，在实践中由于目标数据量的限制，这种策略往往会导致模型快速过拟合或忘记之前学到的知识。&lt;h4&gt;目的&lt;/h4&gt;量化在不同规模的目标域、可用目标数据数量和模型大小下，过度拟合与知识遗忘的现象，并研究将少量预训练数据注入微调数据集中的方法以防止知识遗忘并减轻过拟合问题。&lt;h4&gt;方法&lt;/h4&gt;通过测量向微调数据集中加入一定比例的预训练数据对避免遗忘和减少过拟合的效果来推导出相应的缩放法则。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，即使在目标数据混合物中只包含1%的预训练数据，也足以防止模型忘记原预训练数据集中的知识。&lt;h4&gt;结论&lt;/h4&gt;通过加入少量的预训练数据到微调过程中，可以有效解决过度拟合和知识遗忘问题，从而提高模型在特定领域任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;一种广泛采用的方法是通过对目标领域的无监督下文预测进行微调以获得适用于该领域的语言模型。然而，这种方法面临两个挑战：一是当目标数据量有限时会导致快速过拟合；二是模型会偏离原始的预训练状态，忘记预训练过程中获取的知识和通用知识。本文旨在为不同规模的目标域、可用目标数据数量以及不同的模型大小推导出量化这两类现象的缩放法则，并研究将少量预训练数据注入微调数据中的效果。实验表明，向微调数据集中加入1%的预训练数据可以有效防止遗忘原预训练集的知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A widespread strategy to obtain a language model that performs well on atarget domain is to finetune a pretrained model to perform unsupervisednext-token prediction on data from that target domain. Finetuning presents twochallenges: (i) if the amount of target data is limited, as in most practicalapplications, the model will quickly overfit, and (ii) the model will driftaway from the original model, forgetting the pretraining data and the genericknowledge that comes with it. We aim to derive scaling laws that quantify thesetwo phenomena for various target domains, amounts of available target data, andmodel scales. We measure the efficiency of injecting pretraining data into thefinetuning data mixture to avoid forgetting and mitigate overfitting. A keypractical takeaway from our study is that injecting as little as 1% ofpretraining data in the finetuning data mixture prevents the model fromforgetting the pretraining set.</description>
      <author>example@mail.com (Louis Bethune, David Grangier, Dan Busbridge, Eleonora Gualdoni, Marco Cuturi, Pierre Ablin)</author>
      <guid isPermaLink="false">2502.06042v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation</title>
      <link>http://arxiv.org/abs/2502.05423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于图神经网络的方法，用于人脸的综合表示和年龄估计。&lt;h4&gt;背景&lt;/h4&gt;脸部信息集中在面部关键点上，前沿研究开始使用图神经网络将面部分割成节点来建模复杂的面部表示。但是这些方法构建节点与节点之间的关系时依赖于相似性阈值，从而导致一些潜在的关系被忽略。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的带有初始和动态残差的潜在线条感知图神经网络（LRA-GNN），以实现稳健且综合的人脸表示。&lt;h4&gt;方法&lt;/h4&gt;首先使用面部关键点作为先验知识构建一个初始图，并通过随机游走策略获取全局结构，这些步骤共同指导后续的有效探索和全面表达。然后利用多注意机制捕捉潜在的关系并基于上述指导生成包含丰富面部信息和完整结构的全连接图。为了避免在全连接图上提取深层特征时过度平滑问题，精心设计了深度残差图卷积网络以融合自适应初始残差和动态发展残差。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够避免深度学习模型中常见的过度平滑问题，并通过逐步强化学习优化集成分类回归器来提高年龄估计的精度和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在几个年龄估计基准上超过了最先进的基线，展示了其力量和有效性。&lt;h4&gt;翻译&lt;/h4&gt;面部信息主要集中在面部关键点上。前沿研究开始使用图神经网络将面部分割成节点以建模复杂的面部表示。然而这些方法基于相似性阈值构建节点与节点之间的关系，因此一些潜在的关系被忽略了。这些潜在的关系对于深度语义的人脸老化表示至关重要。我们提出了一种新的带有初始和动态残差的潜在线条感知图神经网络（LRA-GNN）以实现稳健且综合的人脸表示。具体来说，首先使用面部关键点作为先验知识构建一个初始图，并通过随机游走策略获取全局结构，这些步骤共同指导后续的有效探索和全面表达。然后 LRA-GNN 利用多注意机制捕捉潜在的关系并基于上述指导生成包含丰富面部信息和完整结构的全连接图。为了防止在全连接图上提取深层特征时过度平滑问题，精心设计了深度残差图卷积网络以融合自适应初始残差和动态发展残差确保信息的一致性和多样性。最后，为提高年龄估计精度和泛化能力，提出逐步强化学习来优化集成分类回归器。我们所提出的框架在几个年龄估计基准上超过了最先进的基线，展示了其力量和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face information is mainly concentrated among facial key points, and frontierresearch has begun to use graph neural networks to segment faces into patchesas nodes to model complex face representations. However, these methodsconstruct node-to-node relations based on similarity thresholds, so there is aproblem that some latent relations are missing. These latent relations arecrucial for deep semantic representation of face aging. In this novel, wepropose a new Latent Relation-Aware Graph Neural Network with Initial andDynamic Residual (LRA-GNN) to achieve robust and comprehensive facialrepresentation. Specifically, we first construct an initial graph utilizingfacial key points as prior knowledge, and then a random walk strategy isemployed to the initial graph for obtaining the global structure, both of whichtogether guide the subsequent effective exploration and comprehensiverepresentation. Then LRA-GNN leverages the multi-attention mechanism to capturethe latent relations and generates a set of fully connected graphs containingrich facial information and complete structure based on the aforementionedguidance. To avoid over-smoothing issues for deep feature extraction on thefully connected graphs, the deep residual graph convolutional networks arecarefully designed, which fuse adaptive initial residuals and dynamicdevelopmental residuals to ensure the consistency and diversity of information.Finally, to improve the estimation accuracy and generalization ability,progressive reinforcement learning is proposed to optimize the ensembleclassification regressor. Our proposed framework surpasses the state-of-the-artbaselines on several age estimation benchmarks, demonstrating its strength andeffectiveness.</description>
      <author>example@mail.com (Yiping Zhang, Yuntao Shou, Wei Ai, Tao Meng, Keqin Li)</author>
      <guid isPermaLink="false">2502.05423v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models</title>
      <link>http://arxiv.org/abs/2502.06039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 2025 IEEE/ACM Second International Conference on AI  Foundation Models and Software Engineering (Forge 2025). 10 pages, 7 figures,  5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了提示工程在减少大型语言模型生成代码中的安全漏洞方面的有效性，并通过基准测试评估不同提示策略的效果。&lt;h4&gt;背景&lt;/h4&gt;当前，虽然提示工程技术被用于改善大语言模型的推理错误，但其对减轻这些模型生成代码的安全性脆弱性的效果尚未充分探究。&lt;h4&gt;目的&lt;/h4&gt;填补这一研究空白，建立一个自动化评估系统来衡量不同的提示工程策略对于提高代码安全性的效果。&lt;h4&gt;方法&lt;/h4&gt;该基准测试利用了两个经过同行评审的提示数据集，并使用静态扫描器在大规模范围内评估代码安全性。此外，还在GPT-3.5-turbo、GPT-4o和GPT-4o-mini上测试了多种提示工程技巧。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在GPT-4o和GPT-4o-mini模型中，采用安全导向的提示前缀可以将代码中的安全漏洞减少多达56%。同时，使用迭代提示技术时，所有被测模型都能检测并修复先前生成代码中41.9%-68.7%的安全问题。&lt;h4&gt;结论&lt;/h4&gt;提出了一种“提示代理”的概念，展示了如何在实际开发工作流程中应用最有效的技巧来提高代码安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了研究背景、目的、方法和主要发现，并提出了‘提示代理’的概念。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompt engineering reduces reasoning mistakes in Large Language Models(LLMs). However, its effectiveness in mitigating vulnerabilities inLLM-generated code remains underexplored. To address this gap, we implemented abenchmark to automatically assess the impact of various prompt engineeringstrategies on code security. Our benchmark leverages two peer-reviewed promptdatasets and employs static scanners to evaluate code security at scale. Wetested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, andGPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, asecurity-focused prompt prefix can reduce the occurrence of securityvulnerabilities by up to 56%. Additionally, all tested models demonstrated theability to detect and repair between 41.9% and 68.7% of vulnerabilities inpreviously generated code when using iterative prompting techniques. Finally,we introduce a "prompt agent" that demonstrates how the most effectivetechniques can be applied in real-world development workflows.</description>
      <author>example@mail.com (Marc Bruni, Fabio Gabrielli, Mohammad Ghafari, Martin Kropp)</author>
      <guid isPermaLink="false">2502.06039v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints</title>
      <link>http://arxiv.org/abs/2502.05414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了GAMIC技术，该技术结合了图神经网络和分子描述符，以优化大规模语言模型在分子任务中的上下文学习性能。&lt;h4&gt;背景&lt;/h4&gt;目前的提示检索方法主要依赖于局部特征相似性，如Morgan指纹，这无法充分捕捉到全局分子结构及其原子键合关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习技术GAMIC，以更好地表示和理解分子复杂结构，并优化小至中等规模的语言模型在特定任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络表示的全局分子结构与文本描述进行对齐，并通过Morgan指纹实现局部特征相似性检索；引入了基于最大边际相关性的多样性启发法以优化提示样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GAMIC在所有任务上均超越了简单的基于Morgan指纹的上下文学习方法，性能提升最高可达45%。&lt;h4&gt;结论&lt;/h4&gt;GAMIC为分子领域的上下文学习提供了一种有效的方法，特别是在小至中等规模的语言模型中的应用展示了潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何通过引入GAMIC技术来改善大规模语言模型在处理分子任务时的表现，特别是通过结合图神经网络和文本描述，以及利用Morgan指纹来检索特征相似性。该方法提高了输入提示样本的多样性，并且实验结果表明其性能显著优于现有的基于局部特征的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context learning (ICL) effectively conditions large language models (LLMs)for molecular tasks, such as property prediction and molecule captioning, byembedding carefully selected demonstration examples into the input prompt. Thisapproach avoids the computational overhead of extensive pertaining andfine-tuning. However, current prompt retrieval methods for molecular tasks haverelied on molecule feature similarity, such as Morgan fingerprints, which donot adequately capture the global molecular and atom-binding relationships. Asa result, these methods fail to represent the full complexity of molecularstructures during inference. Moreover, small-to-medium-sized LLMs, which offersimpler deployment requirements in specialized systems, have remained largelyunexplored in the molecular ICL literature. To address these gaps, we propose aself-supervised learning technique, GAMIC (Graph-Aligned Molecular In-Contextlearning, which aligns global molecular structures, represented by graph neuralnetworks (GNNs), with textual captions (descriptions) while leveraging localfeature similarity through Morgan fingerprints. In addition, we introduce aMaximum Marginal Relevance (MMR) based diversity heuristic during retrieval tooptimize input prompt demonstration samples. Our experimental findings usingdiverse benchmark datasets show GAMIC outperforms simple Morgan-based ICLretrieval methods across all tasks by up to 45%.</description>
      <author>example@mail.com (Ali Al-Lawati, Jason Lucas, Zhiwei Zhang, Prasenjit Mitra, Suhang Wang)</author>
      <guid isPermaLink="false">2502.05414v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2502.05282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by T-PAMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种新的学习方法GEMINI，用于解决医学图像在密集对比表示学习（DCRL）中的虚假正负对问题。&lt;h4&gt;背景&lt;/h4&gt;Dense contrastive representation learning (DCRL) 提高了图像密集预测任务的学习效率，并显示出减少医疗影像收集和密集标注成本的巨大潜力。但是，医学影像的特性导致不可靠的对应关系发现，从而在大规模数据中引入了大量的虚假正负样本对（FP&amp;N）。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合同胚先验的DCRL学习方法，以实现可靠的对应关系发现并有效减少密集对比中的错误配对。&lt;h4&gt;方法&lt;/h4&gt;提出了可变形同胚学习(DHL)模型来描述医学图像之间的同胚性质，并通过保持拓扑结构的方式预测像素间的对应关系；同时引入了几何语义相似性(GSS)，用于从特征中提取语义信息，以衡量对应关系的学习程度。这些创新有助于减少配对搜索空间，并促进变形和正样本对的有效学习。&lt;h4&gt;主要发现&lt;/h4&gt;GEMINI通过有效利用同胚先验减少了错误配对，并提高了密集对比表示学习的效率与性能；在两个典型的表示学习任务上的实验变体证明了其优越性，且在七个数据集上超越了现有的方法。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了GEMINI在解决大规模医学影像中虚假正负样本问题的有效性和潜力。代码将在GitHub上公开。&lt;h4&gt;翻译&lt;/h4&gt;密集对比表示学习（DCRL）极大提高了图像密集预测任务的学习效率，显示出减少医疗影像收集和密集标注成本的巨大潜力。然而，医学影像的特性导致不可靠的对应关系发现，在大规模数据中引入了虚假正负样本对的问题。为了克服这一挑战，我们提出了GEoMetricvIsual deNse sImilarity（GEMINI）学习方法，该方法将同胚先验嵌入到DCRL中，实现了可靠的对应关系发现，并为有效的密集对比奠定了基础。具体而言，我们提出了一种可变形同胚学习(DHL)，用于模型医学图像之间的同胚性质，并通过保持拓扑结构的方式预测像素间的对应关系；同时引入了几何语义相似性(GSS)，提取特征中的语义信息来衡量对应关系的学习程度。此外，在两个典型的表示学习任务上的实验变体中，我们的研究展示了GEMINI在七个数据集上超越现有方法的优越表现，并将在GitHub上公开代码以供进一步开发和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense contrastive representation learning (DCRL) has greatly improved thelearning efficiency for image-dense prediction tasks, showing its greatpotential to reduce the large costs of medical image collection and denseannotation. However, the properties of medical images make unreliablecorrespondence discovery, bringing an open problem of large-scale falsepositive and negative (FP&amp;N) pairs in DCRL. In this paper, we propose GEoMetricvIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism priorto DCRL and enables a reliable correspondence discovery for effective densecontrast. We propose a deformable homeomorphism learning (DHL) which models thehomeomorphism of medical images and learns to estimate a deformable mapping topredict the pixels' correspondence under topological preservation. Iteffectively reduces the searching space of pairing and drives an implicit andsoft learning of negative pairs via a gradient. We also propose a geometricsemantic similarity (GSS) which extracts semantic information in features tomeasure the alignment degree for the correspondence learning. It will promotethe learning efficiency and performance of deformation, constructing positivepairs reliably. We implement two practical variants on two typicalrepresentation learning tasks in our experiments. Our promising results onseven datasets which outperform the existing methods show our greatsuperiority. We will release our code on a companion link:https://github.com/YutingHe-list/GEMINI.</description>
      <author>example@mail.com (Yuting He, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li)</author>
      <guid isPermaLink="false">2502.05282v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</title>
      <link>http://arxiv.org/abs/2502.00568v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的跨模态生成AI模型PathoGen，该模型可以从数字病理图像中合成基因表达数据，并且这种合成的数据能够准确预测癌症分级和患者生存风险。&lt;h4&gt;背景&lt;/h4&gt;现有的研究显示了结合数字病理学与转录组特征的人工智能多模式融合技术可以提高癌症诊断（分级/亚型）和预后（存活风险）的准确性，然而在实际临床环境中直接应用这种联合决策方式并不现实。由于组织病理学仍然是诊断的金标准，并且转录组测试很少被要求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从数字病理图像中合成基因表达数据的新模型PathoGen，并验证该模型预测癌症分级和患者生存风险的能力。&lt;h4&gt;方法&lt;/h4&gt;利用扩散过程为基础的跨模态生成AI模型PathoGen，将数字病理学与转录组特征进行结合，以提高癌症诊断及预后的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用PathoGen模型合成基因表达数据，能够高精度地预测癌症分级和患者生存风险，并且具有确定性（通过一致性覆盖保证）和可解释性（通过分布式注意图）。&lt;h4&gt;结论&lt;/h4&gt;PathoGen模型在数字病理图像与转录组特征的融合上表现出色，为临床诊断提供了一种新的途径。&lt;h4&gt;翻译&lt;/h4&gt;新兴的研究表明基于人工智能的多模态融合技术可以提高癌症诊断（分级/亚型）和预后（生存风险）预测的准确性。然而，在实际临床环境中直接应用这种联合决策方式并不现实。病理学仍然是诊断的金标准，而转录组测试很少被要求。通过我们的新扩散跨模式生成AI模型PathoGen，我们展示了从数字病理图像合成基因表达数据可以高精度地预测癌症分级和患者生存风险（达到最新技术水平），并且具有确定性和可解释性。PathoGen代码可在GitHub上公开使用，地址为https://github.com/Samiran-Dey/PathoGen。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Samiran-Dey/PathoGen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging research has highlighted that artificial intelligence basedmultimodal fusion of digital pathology and transcriptomic features can improvecancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.However, such direct fusion for joint decision is impractical in real clinicalsettings, where histopathology is still the gold standard for diagnosis andtranscriptomic tests are rarely requested, at least in the public healthcaresystem. With our novel diffusion based crossmodal generative AI model PathoGen,we show that genomic expressions synthesized from digital histopathologyjointly predicts cancer grading and patient survival risk with high accuracy(state-of-the-art performance), certainty (through conformal coverageguarantee) and interpretability (through distributed attention maps). PathoGencode is available for open use by the research community through GitHub athttps://github.com/Samiran-Dey/PathoGen.</description>
      <author>example@mail.com (Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2502.00568v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Compositional Reasoning in Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2502.06037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了大型预训练时间序列基础模型(TSFMs)在各种领域的零样本性能，并研究它们是通过记忆训练模式还是具备推理能力来实现成功的。&lt;h4&gt;背景&lt;/h4&gt;尽管大规模语言模型(LLM)的推理能力受到了广泛关注，但在时间序列基础模型(TSFMs)中，这一概念尚未被明确界定和探索。&lt;h4&gt;目的&lt;/h4&gt;受语言建模文献启发，本文正式定义了组合式推理在预测中的作用，并将其与分布内泛化区分开来。通过评估23种流行深度学习预测模型的推理和泛化能力，研究探讨TSFM架构设计对组合式推理和泛化的影响力。&lt;h4&gt;方法&lt;/h4&gt;使用多个合成和现实世界数据集评估了23个流行的深度学习预测模型，并进行了有控制的研究以系统地检查TSFMs的设计选择如何影响它们的推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现基于补丁的Transformer在推理性能方面表现最佳，其次是残差化MLP架构。后者在计算复杂性和可训练参数数量上更为简洁（分别减少97%和86%）。此外，在某些零样本分布外场景中，这些模型可以超越在分布内数据上训练的统计基准（如移动平均值和平滑指数）。&lt;h4&gt;结论&lt;/h4&gt;只有少数设计选择（例如标记化方法）对Transformer模型性能有显著影响。这项研究揭示了TSFM架构设计对组合式推理和泛化的关键见解，并指出基于补丁的Transformers是目前的最佳选择，尽管残差MLP架构可能更易于实现且计算成本更低。&lt;h4&gt;翻译&lt;/h4&gt;大型预训练时间序列基础模型(TSFMs)在各种领域的零样本性能中展现出了潜力。然而，一个问题是：TSFMs的成功是否仅限于记忆训练模式，还是它们具备推理能力？虽然语言建模文献中有关推理的研究引起了大量关注，在TSFMs中的定义和探索仍然不足。在此研究中，我们受语言模型文献启发，正式定义了组合式推理在预测中的作用，并将其与分布内泛化区分开来。通过评估23种流行的深度学习预测模型的推理和泛化能力，我们在多个合成数据集和现实世界的数据集上进行了评价。此外，通过有控制的研究，我们系统地检查了TSFMs的设计选择如何影响它们的推理能力。我们的研究揭示了TSFM架构设计对组合式推理和泛化的关键见解：基于补丁的Transformers在推理性能方面表现最佳，其次是残差化MLP架构（后者更为简洁），同时，在某些零样本分布外场景中，这些模型可以超越传统的统计基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large pre-trained time series foundation models (TSFMs) have demonstratedpromising zero-shot performance across a wide range of domains. However, aquestion remains: Do TSFMs succeed solely by memorizing training patterns, ordo they possess the ability to reason? While reasoning is a topic of greatinterest in the study of Large Language Models (LLMs), it is undefined andlargely unexplored in the context of TSFMs. In this work, inspired by languagemodeling literature, we formally define compositional reasoning in forecastingand distinguish it from in-distribution generalization. We evaluate thereasoning and generalization capabilities of 23 popular deep learningforecasting models on multiple synthetic and real-world datasets. Additionally,through controlled studies, we systematically examine which design choices inTSFMs contribute to improved reasoning abilities. Our study yields key insightsinto the impact of TSFM architecture design on compositional reasoning andgeneralization. We find that patch-based Transformers have the best reasoningperformance, closely followed by residualized MLP-based architectures, whichare 97\% less computationally complex in terms of FLOPs and 86\% smaller interms of the number of trainable parameters. Interestingly, in some zero-shotout-of-distribution scenarios, these models can outperform moving average andexponential smoothing statistical baselines trained on in-distribution data.Only a few design choices, such as the tokenization method, had a significant(negative) impact on Transformer model performance.</description>
      <author>example@mail.com (Willa Potosnak, Cristian Challu, Mononito Goswami, Kin G. Olivares, Michał Wiliński, Nina Żukowska, Artur Dubrawski)</author>
      <guid isPermaLink="false">2502.06037v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Voltage Drop: Models, Features and Data Representation Towards a Neural Surrogate</title>
      <link>http://arxiv.org/abs/2502.05345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了机器学习技术在现代ASIC电压降（IR下降）估算中的应用，旨在减少计算时间和资源需求。&lt;h4&gt;背景&lt;/h4&gt;随着集成电路复杂性和晶体管密度的增加，准确估计现代ASIC的电压降变得越来越耗时和耗费资源。&lt;h4&gt;目的&lt;/h4&gt;通过研究包括XGBoost、CNN和GNN在内的机器学习技术如何帮助降低IC中IR下降估算所需的计算努力及时间需求。&lt;h4&gt;方法&lt;/h4&gt;利用ASIC的电气特性、定时信息和物理参数训练机器学习模型，确保在不同的设计上具有较小调整即可实现适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，机器学习模型比商业工具更优越，在预测速度方面有显著提升。特别是GNNs在电压降估算中表现出色且误差极小。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了ML算法在精确估计IR下降和优化ASIC签署工作中的有效性。使用ML模型能够加快预测时间，减少计算时间和改善能源效率，从而通过优化的功率电路降低环境影响。&lt;h4&gt;翻译&lt;/h4&gt;准确估计现代应用特定集成电路（ASIC）中的电压降是极具挑战性的，因为这需要大量的时间和资源来处理日益复杂的晶体管密度问题。本文探究了机器学习技术（如XGBoost、CNN和GNN）如何帮助减少估算集成电路中IR下降所需的计算努力以及所需时间。传统方法，包括商业工具，在产生准确近似值时需要相当长的时间，尤其是在包含大量晶体管的复杂设计中。相比之下，作为快速且精确估计IR下降的一种替代解决方案，本文探索了机器学习算法的应用，并发现其能在明显较少时间内提供有效的估算结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate estimation of voltage drop (IR drop) in modern Application-SpecificIntegrated Circuits (ASICs) is highly time and resource demanding, due to thegrowing complexity and the transistor density in recent technology nodes. Tomitigate this challenge, we investigate how Machine Learning (ML) techniques,including Extreme Gradient Boosting (XGBoost), Convolutional Neural Network(CNN), and Graph Neural Network (GNN) can aid in reducing the computationaleffort and implicitly the time required to estimate the IR drop in IntegratedCircuits (ICs). Traditional methods, including commercial tools, requireconsiderable time to produce accurate approximations, especially forcomplicated designs with numerous transistors. ML algorithms, on the otherhand, are explored as an alternative solution to offer quick and precise IRdrop estimation, but in considerably less time. Our approach leverages ASICs'electrical, timing, and physical to train ML models, ensuring adaptabilityacross diverse designs with minimal adjustments. Experimental resultsunderscore the superiority of ML models over commercial tools, greatlyenhancing prediction speed. Particularly, GNNs exhibit promising performancewith minimal prediction errors in voltage drop estimation. The incorporation ofGNNs marks a groundbreaking advancement in accurate IR drop prediction. Thisstudy illustrates the effectiveness of ML algorithms in precisely estimating IRdrop and optimizing ASIC sign-off. Utilizing ML models leads to expeditedpredictions, reducing calculation time and improving energy efficiency, therebyreducing environmental impact through optimized power circuits.</description>
      <author>example@mail.com (Yifei Jin, Dimitrios Koutlis, Hector Bandala, Marios Daoutis)</author>
      <guid isPermaLink="false">2502.05345v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions</title>
      <link>http://arxiv.org/abs/2502.06026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer的多模态深度学习方法，用于近似求解各种ODE和PDE。该模型结合了数值输入（如方程参数和初始条件）与物理过程或系统动态的文字描述。&lt;h4&gt;背景&lt;/h4&gt;神经网络是科学计算任务中一种常用的工具，用来逼近非线性微分方程。现有的偏微分方程基础模型集中于学习通用求解器操作符或者控制方程本身，并且只处理数值或符号模态的数据。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有方法的局限性，提出了一种能够同时处理文本分析和描述输出等更灵活数据模式的新方法。&lt;h4&gt;方法&lt;/h4&gt;采用Transformer架构来逼近广泛的ODE和PDE求解操作符。模型整合了数值输入和物理过程或系统动态的文字描述。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该模型对于分布内和分布外的数据都能提供准确的解决方案（平均相对误差分别为小于3.3%和7.8%），并能够生成精确的文字描述（100%情况下正确）；在某些测试中还展示了时间上的外推能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为解决涉及复杂物理过程的任务提供了强大的工具，不仅准确地解决了数值问题，还能提供关于基本动力学和解性质的深入解释。&lt;h4&gt;翻译&lt;/h4&gt;神经网络是科学计算任务（如替代建模、实时预测及最优控制）中逼近非线性微分方程的一种工具。PDE基础模型利用神经网络同时训练多个微分方程的近似值，因此是一个可以适应下游任务的一般求解器。当前的PDE基础模型集中于学习通用解算子和/或支配系统方程，并且只处理数值或符号模态的数据。然而，在实际应用中可能需要更灵活的数据模式，例如文本分析或描述性输出。为了解决这一缺口，我们提出了一种基于Transformer架构的新颖多模态深度学习方法，该方法用于逼近各种ODE和PDE的解算子。我们的方法结合了数值输入（如方程参数和初始条件）与物理过程或系统动力学的文字描述。这使模型能够处理符号表示可能不完整或不可用的情况。除了提供准确的数值预测之外，我们的方法还生成可解释的科学文本描述，为底层动态和解属性提供了更深层次的理解。数值实验表明，对于分布内数据（平均相对误差小于3.3%）及分布外数据（平均相对误差小于7.8%），模型均能提供精确解决方案，并且每次都能产生正确的文字描述。在某些测试中，该模型也显示出了时间上的外推能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural networks are one tool for approximating non-linear differentialequations used in scientific computing tasks such as surrogate modeling,real-time predictions, and optimal control. PDE foundation models utilizeneural networks to train approximations to multiple differential equationssimultaneously and are thus a general purpose solver that can be adapted todownstream tasks. Current PDE foundation models focus on either learninggeneral solution operators and/or the governing system of equations, and thusonly handle numerical or symbolic modalities. However, real-world applicationsmay require more flexible data modalities, e.g. text analysis or descriptiveoutputs. To address this gap, we propose a novel multimodal deep learningapproach that leverages a transformer-based architecture to approximatesolution operators for a wide variety of ODEs and PDEs. Our method integratesnumerical inputs, such as equation parameters and initial conditions, with textdescriptions of physical processes or system dynamics. This enables our modelto handle settings where symbolic representations may be incomplete orunavailable. In addition to providing accurate numerical predictions, ourapproach generates interpretable scientific text descriptions, offering deeperinsights into the underlying dynamics and solution properties. The numericalexperiments show that our model provides accurate solutions for in-distributiondata (with average relative error less than 3.3%) and out-of-distribution data(average relative error less than 7.8%) together with precise text descriptions(with correct descriptions generated 100% of times). In certain tests, themodel is also shown to be capable of extrapolating solutions in time.</description>
      <author>example@mail.com (Elisa Negrini, Yuxuan Liu, Liu Yang, Stanley J. Osher, Hayden Schaeffer)</author>
      <guid isPermaLink="false">2502.06026v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Working Memory: Query-Guided Segment Refinement for Enhanced Multimodal Understanding</title>
      <link>http://arxiv.org/abs/2502.06020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种增强多模态基础模型（MFMs）处理时间序列能力的专用认知模块——时序工作记忆（TWM）。通过保留任务相关的信息，该模块优化了有限容量内的信息处理，使MFM在视频和音频分析中表现得更为出色。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在图像字幕、问答和图像-文本检索等任务上表现出色，但它们在处理长时间序列时存在固有局限性。这些局限限制了它们对复杂时间敏感数据的处理能力。&lt;h4&gt;目的&lt;/h4&gt;通过引入TWM模块来提高MFMs的时间建模能力，并优化其有限容量内的信息保留机制，使其能够更好地应对视频和音频内容分析中的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于查询引导注意的方法，以在时序序列中聚焦于最具有信息量的多模态片段。TWM模块可以容易地集成到现有的MFMs中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，通过使用TWM插件式模块，九个最先进的模型在视频字幕、问答和视频-文本检索任务上都取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;TWM通过增强多模态基础模型的时间建模能力，扩展了它们处理复杂时间敏感数据的能力。我们的代码可在此处获取：https://github.com/xid32/NAACL_2025_TWM。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，尽管多模态基础模型（MFMs）在诸如视觉字幕、问答和图像-文本检索任务中取得了显著的成功，但它们由于内部容量有限而难以处理长时间序列数据。因此，研究者们设计了一种特殊认知模块——时序工作记忆（TWM），用来增强这些模型的时间建模能力，并通过只保留最关键的信息来优化其使用效率。这种模块可以轻易地加入现有的MFMs中，并且实验结果显示，它使得九个最先进的模型在视频字幕、问答和视频-文本检索等任务上的性能有了显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models (MFMs) have demonstrated significant success intasks such as visual captioning, question answering, and image-text retrieval.However, these models face inherent limitations due to their finite internalcapacity, which restricts their ability to process extended temporal sequences,a crucial requirement for comprehensive video and audio analysis. To overcomethese challenges, we introduce a specialized cognitive module, temporal workingmemory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.It selectively retains task-relevant information across temporal dimensions,ensuring that critical details are preserved throughout the processing of videoand audio content. The TWM uses a query-guided attention approach to focus onthe most informative multimodal segments within temporal sequences. Byretaining only the most relevant content, TWM optimizes the use of the model'slimited capacity, enhancing its temporal modeling ability. This plug-and-playmodule can be easily integrated into existing MFMs. With our TWM, ninestate-of-the-art models exhibit significant performance improvements acrosstasks such as video captioning, question answering, and video-text retrieval.By enhancing temporal modeling, TWM extends the capability of MFMs to handlecomplex, time-sensitive data effectively. Our code is available athttps://github.com/xid32/NAACL_2025_TWM.</description>
      <author>example@mail.com (Xingjian Diao, Chunhui Zhang, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui)</author>
      <guid isPermaLink="false">2502.06020v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Redefining Robot Generalization Through Interactive Intelligence</title>
      <link>http://arxiv.org/abs/2502.05963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文讨论了机器人基础模型如何需要从单一代理视角转向交互式的多代理视角，以应对实时的人机协作的复杂性。&lt;h4&gt;背景&lt;/h4&gt;虽然大规模机器学习的发展产生了能够适应各种下游任务的强大基础模型，但在机器人领域中仍普遍认为机器人是独立执行如抓取和导航等任务的单一决策者，与人类互动较少。然而，在现实世界中，许多类型的半自主系统（例如穿戴式设备、远程操作以及神经接口）需要持续的人机交互协作。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨基础模型在处理人机实时协同适应时所面临的挑战，并提出一种新的框架来支持这种多代理视角的需求。&lt;h4&gt;方法&lt;/h4&gt;作者提出了一个基于神经科学启发的通用架构，包括四个模块：（1）一种受感觉运动整合原则影响的多模式感知模块；（2）类似认知科学研究中联合行动框架的工作小组模型；（3）以内部模型理论为基础的动作控制预测世界信念模型；以及（4）类似于海布定律和强化学习机制的记忆/反馈系统。&lt;h4&gt;主要发现&lt;/h4&gt;提出的架构不仅适用于仿生系统的场景，而且还可以应用于任何需要半自主或交互操作的机器人。通过超越单一代理设计的理念，基础模型可以达到更强大、个性化及更具预见性的性能水平。&lt;h4&gt;结论&lt;/h4&gt;为了更好地支持实时的人机协作，未来的基础模型发展应当采纳一个多代理视角，并采用作者提议的方法和架构来实现这一目标。&lt;h4&gt;翻译&lt;/h4&gt;最近的大规模机器学习进展产生了能够适应广泛下游任务的强大基础模型。然而，在机器人领域中，传统的观点仍然将机器人视为执行如抓取、导航等单一任务的独立决策者，与人类互动有限。本文提出一个基于神经科学启发的通用架构来支持半自主或交互式操作场景中的多代理视角需求，以应对人机实时协同适应的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large-scale machine learning have produced high-capacityfoundation models capable of adapting to a broad array of downstream tasks.While such models hold great promise for robotics, the prevailing paradigmstill portrays robots as single, autonomous decision-makers, performing taskslike manipulation and navigation, with limited human involvement. However, alarge class of real-world robotic systems, including wearable robotics (e.g.,prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, aresemiautonomous, and require ongoing interactive coordination with humanpartners, challenging single-agent assumptions. In this position paper, weargue that robot foundation models must evolve to an interactive multi-agentperspective in order to handle the complexities of real-time human-robotco-adaptation. We propose a generalizable, neuroscience-inspired architectureencompassing four modules: (1) a multimodal sensing module informed bysensorimotor integration principles, (2) an ad-hoc teamwork model reminiscentof joint-action frameworks in cognitive science, (3) a predictive world beliefmodel grounded in internal model theories of motor control, and (4) amemory/feedback mechanism that echoes concepts of Hebbian andreinforcement-based plasticity. Although illustrated through the lens of cyborgsystems, where wearable devices and human physiology are inseparablyintertwined, the proposed framework is broadly applicable to robots operatingin semi-autonomous or interactive contexts. By moving beyond single-agentdesigns, our position emphasizes how foundation models in robotics can achievea more robust, personalized, and anticipatory level of performance.</description>
      <author>example@mail.com (Sharmita Dey)</author>
      <guid isPermaLink="false">2502.05963v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction</title>
      <link>http://arxiv.org/abs/2502.05218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于超图的因子模型（FactorGCL），该模型利用时间残差对比学习方法，旨在改进传统线性因素模型，并通过挖掘隐藏因素来预测股票收益。&lt;h4&gt;背景&lt;/h4&gt;因子模型是经济学和金融学中的基本方法，在量化投资中被广泛使用。近年来，从传统的专家设计的因素的线性模型转向更灵活的数据驱动非线性机器学习模型已成为趋势，但市场数据中信号与噪声的比例低使得挖掘有效因素变得困难。&lt;h4&gt;目的&lt;/h4&gt;为了提高因子模型的有效性并解决当前问题，本文旨在通过结合超图结构和时间残差对比学习方法来改进因子模型，以便更好地捕捉股票收益之间的高阶非线性关系，并提取有效的隐藏因素以补充专家设计的先验因素。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于超图的因素模型（FactorGCL），其中采用了一个级联残差超图架构，该架构可以从去除先验因素影响后的剩余信息中提取隐藏因素。此外，还提出了时间残差对比学习方法来指导有效和全面的隐藏因素的提取。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明了FactorGCL不仅能超越现有的最先进方法，而且还能挖掘出有效的隐藏因素用于预测股票收益。&lt;h4&gt;结论&lt;/h4&gt;通过引入超图结构和时间残差对比学习方法，本文提出的模型在预测股票收益方面表现出色，并且可以作为进一步研究的有前途的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a fundamental method in economics and finance, the factor model has beenextensively utilized in quantitative investment. In recent years, there hasbeen a paradigm shift from traditional linear models with expert-designedfactors to more flexible nonlinear machine learning-based models withdata-driven factors, aiming to enhance the effectiveness of these factormodels. However, due to the low signal-to-noise ratio in market data, miningeffective factors in data-driven models remains challenging. In this work, wepropose a hypergraph-based factor model with temporal residual contrastivelearning (FactorGCL) that employs a hypergraph structure to better capturehigh-order nonlinear relationships among stock returns and factors. To minehidden factors that supplement human-designed prior factors for predictingstock returns, we design a cascading residual hypergraph architecture, in whichthe hidden factors are extracted from the residual information after removingthe influence of prior factors. Additionally, we propose a temporal residualcontrastive learning method to guide the extraction of effective andcomprehensive hidden factors by contrasting stock-specific residual informationover different time periods. Our extensive experiments on real stock marketdata demonstrate that FactorGCL not only outperforms existing state-of-the-artmethods but also mines effective hidden factors for predicting stock returns.</description>
      <author>example@mail.com (Yitong Duan, Weiran Wang, Jian Li)</author>
      <guid isPermaLink="false">2502.05218v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>TabICL: A Tabular Foundation Model for In-Context Learning on Large Data</title>
      <link>http://arxiv.org/abs/2502.05564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为TabICL的新模型，该模型利用两阶段架构处理大规模表格数据，并在分类任务上表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的梯度增强决策树在表格数据上的主导地位正受到使用上下文学习（ICL）的新型基础模型的挑战。最近提出的TabPFNv2虽然适用于小规模数据集，但在处理大规模训练集时计算成本过高。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效扩展并在大型数据集上提供优势的新模型，以克服现有模型在大表格上的局限性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的两阶段架构的TabICL模型：首先是列然后是行注意机制来构建固定维度的行嵌入，随后使用变压器进行高效的上下文学习。该模型预训练于包含多达60K样本的合成数据集，并能在可负担资源上处理50万样本。&lt;h4&gt;主要发现&lt;/h4&gt;在200个分类任务的数据集中，TabICL的表现与TabPFNv2相当，但在速度上快至10倍；对于超过10K样本的56个数据集，它超越了TabPFNv2和CatBoost，显示了上下文学习对大规模数据的有效性。&lt;h4&gt;结论&lt;/h4&gt;TabICL模型在处理大型表格分类任务方面展示出卓越的能力，并且表明上下文学习技术有潜力为未来的大规模数据分析提供强大的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The long-standing dominance of gradient-boosted decision trees on tabulardata is currently challenged by tabular foundation models using In-ContextLearning (ICL): setting the training data as context for the test data andpredicting in a single forward pass without parameter updates. While the veryrecent TabPFNv2 foundation model (2025) excels on tables with up to 10Ksamples, its alternating column- and row-wise attentions make handling largetraining sets computationally prohibitive. So, can ICL be effectively scaledand deliver a benefit for larger tables? We introduce TabICL, a tabularfoundation model for classification, pretrained on synthetic datasets with upto 60K samples and capable of handling 500K samples on affordable resources.This is enabled by a novel two-stage architecture: a column-then-row attentionmechanism to build fixed-dimensional embeddings of rows, followed by atransformer for efficient ICL. Across 200 classification datasets from theTALENT benchmark, TabICL is on par with TabPFNv2 while being systematicallyfaster (up to 10 times), and significantly outperforms all other approaches. On56 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost,demonstrating the potential of ICL for large data.</description>
      <author>example@mail.com (Jingang Qu, David Holzmüller, Gaël Varoquaux, Marine Le Morvan)</author>
      <guid isPermaLink="false">2502.05564v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SSH: Sparse Spectrum Adaptation via Discrete Hartley Transformation</title>
      <link>http://arxiv.org/abs/2502.05539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新的参数高效微调方法SSH通过选择最有信息量的频谱分量，显著减少了训练参数的数量，并在计算成本和内存需求方面实现了重大节省。&lt;h4&gt;背景&lt;/h4&gt;低秩适应(LoRA)已经证明，在微调大型基础模型时能够减少可训练参数的数量。然而，当扩展到更大规模的模型或处理更复杂的任务自适应时，它仍然面临计算资源和内存方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法SSH，通过稀疏频谱选择来增强大语言模型在复杂任务上的适应性，并降低其计算和存储要求。&lt;h4&gt;方法&lt;/h4&gt;利用离散哈特利变换(DHT)，根据初始权重指导选择最具信息量的频谱分量。再使用轻量级逆DHT将频谱投影回空间域以进行更新。&lt;h4&gt;主要发现&lt;/h4&gt;SSH在单模态任务如语言理解和生成，以及跨模态任务如视频-文本理解上均表现出色，并超过了现有的参数高效微调方法，在计算成本和内存需求方面都有显著的减少。&lt;h4&gt;结论&lt;/h4&gt;提出的方法不仅提高了模型性能，还通过选择性地更新最具信息量的部分实现了对现有资源使用的优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has been demonstrated effective in reducing thetrainable parameter number when fine-tuning a large foundation model (LLM).However, it still encounters computational and memory challenges when scalingto larger models or addressing more complex task adaptation.  In this work, we introduce Sparse Spectrum Adaptation via Discrete HartleyTransformation (SSH), a novel approach that significantly reduces the number oftrainable parameters while enhancing model performance. It selects the mostinformative spectral components across all layers, under the guidance of theinitial weights after a discrete Hartley transformation (DHT). The lightweightinverse DHT then projects the spectrum back into the spatial domain forupdates.  Extensive experiments across both single-modality tasks such as languageunderstanding and generation and multi-modality tasks such as video-textunderstanding demonstrate that SSH outperforms existing parameter-efficientfine-tuning (PEFT) methods while achieving substantial reductions incomputational cost and memory requirements.</description>
      <author>example@mail.com (Yixian Shen, Qi Bi, Jia-Hong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania)</author>
      <guid isPermaLink="false">2502.05539v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model</title>
      <link>http://arxiv.org/abs/2502.05505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为Sim-PE的新方法，它扩展了Private Evolution (PE)框架，使其能够利用各种领域特定的仿真器进行差分隐私(DP)数据合成。&lt;h4&gt;背景&lt;/h4&gt;差分隐私合成数据是一种既能保护隐私又能提供高质量数据的重要技术。近期提出的Private Evolution（PE）方法通过仅使用基础模型的推理API来生成DP合成数据，显示出其潜力。&lt;h4&gt;目的&lt;/h4&gt;探索利用领域特定仿真器作为PE框架中推理API的可能性，并评估这种方法在图像合成中的性能和效果。&lt;h4&gt;方法&lt;/h4&gt;发现并验证了PE框架可以接受除基础模型之外的其他类型推理API。具体来说，使用如计算机图形学为基础的图像合成工具等模拟器作为有效API的方法被提出。该研究探讨了利用多种仿真器进行DP数据合成的可能性，并在多个不同的仿真器上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;Sim-PE方法在图像合成中表现出色，在提高下游分类准确性和降低FID评分方面优于传统的PE方法，最高可提升至3倍和减少80%。此外，基础模型与领域特定模拟器可以结合使用以进一步改进性能。&lt;h4&gt;结论&lt;/h4&gt;本文证明了利用仿真器作为推理API的可行性，并展示了Sim-PE在多个场景中的有效性。这为DP合成数据的应用提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;差分隐私(DP)合成数据已成为一种重要工具，能够在不损害隐私的情况下释放私有数据的价值。最近提出的Private Evolution（PE）方法作为一种生成DP合成数据的前景技术出现。不同于基于训练的方法，PE仅需要访问基础模型的推理API来利用最先进的模型能力。然而，并不是所有领域都有适当的基础模型可用。本文发现PE框架足够通用，可以接受超出基础模型范围的推理API，包括如计算机图形学为基础的图像生成工具等模拟器作为有效API使用。这一发现大大扩展了PE的应用范围，使其能够利用广泛的特定领域的仿真器进行DP数据合成。我们在图像合成领域探索了这种方法（名为Sim-PE）的潜力，并在三个不同的模拟器上进行了测试。结果显示，在提高下游分类准确性和降低FID评分方面，Sim-PE表现优异，最高可提升至3倍和减少80%。此外，基础模型与特定领域的仿真器可以结合使用以进一步改进性能。代码开源于Private Evolution Python库：https://github.com/microsoft/DPSDA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentially private (DP) synthetic data, which closely resembles theoriginal private data while maintaining strong privacy guarantees, has become akey tool for unlocking the value of private data without compromising privacy.Recently, Private Evolution (PE) has emerged as a promising method forgenerating DP synthetic data. Unlike other training-based approaches, PE onlyrequires access to inference APIs from foundation models, enabling it toharness the power of state-of-the-art models. However, a suitable foundationmodel for a specific private data domain is not always available. In thispaper, we discover that the PE framework is sufficiently general to allowinference APIs beyond foundation models. Specifically, we show that simulators-- such as computer graphics-based image synthesis tools -- can also serve aseffective APIs within the PE framework. This insight greatly expands theapplicability of PE, enabling the use of a wide variety of domain-specificsimulators for DP data synthesis. We explore the potential of this approach,named Sim-PE, in the context of image synthesis. Across three diversesimulators, Sim-PE performs well, improving the downstream classificationaccuracy of PE by up to 3x and reducing the FID score by up to 80%. We alsoshow that simulators and foundation models can be easily leveraged togetherwithin the PE framework to achieve further improvements. The code isopen-sourced in the Private Evolution Python library:https://github.com/microsoft/DPSDA.</description>
      <author>example@mail.com (Zinan Lin, Tadas Baltrusaitis, Sergey Yekhanin)</author>
      <guid isPermaLink="false">2502.05505v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>L2GNet: Optimal Local-to-Global Representation of Anatomical Structures for Generalized Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.05229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为L2GNet的新模型，该模型旨在改进医疗图像分割中连续和离散潜在空间（CDLS）方法的性能。&lt;h4&gt;背景&lt;/h4&gt;CLoS和DLS模型在医学图像分割任务上表现出色。然而，处理长程依赖关系时存在困难，尤其是冗余区域特征聚合的问题，这影响了解剖结构的理解及分类内部依赖性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架L2GNet来解决现有CDLS方法的缺点，特别是关于如何更好地建模全局依赖性和避免计算开销。&lt;h4&gt;方法&lt;/h4&gt;L2GNet通过利用最优传输将离散代码从DLS中获得，并在可训练参考上对齐这些代码，从而学习全局依赖关系。它不使用额外的权重矩阵进行自我注意模型中的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与包括SynergyNet在内的当前最佳方法相比，L2GNet在多器官分割和心脏数据集上的性能更为优越。&lt;h4&gt;结论&lt;/h4&gt;所提出的L2GNet为提高医学图像分析中深度学习模型的性能提供了一种新思路。&lt;h4&gt;翻译&lt;/h4&gt;连续潜在空间（CLS）和离散潜在空间（DLS）模型在医疗图像分割任务上表现出色。然而，处理长程依赖关系时存在困难，尤其是冗余区域特征聚合的问题，这影响了解剖结构的理解及分类内部依赖性。为此，我们提出了L2GNet，通过最优传输获取离散代码，并在可训练参考中对齐这些代码来学习全局依赖关系。实验结果表明，在多器官分割和心脏数据集上，与包括SynergyNet在内的当前最佳方法相比，L2GNet的性能更优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous Latent Space (CLS) and Discrete Latent Space (DLS) models, likeAttnUNet and VQUNet, have excelled in medical image segmentation. In contrast,Synergistic Continuous and Discrete Latent Space (CDLS) models show promise inhandling fine and coarse-grained information. However, they struggle withmodeling long-range dependencies. CLS or CDLS-based models, such as TransUNetor SynergyNet are adept at capturing long-range dependencies. Since they relyheavily on feature pooling or aggregation using self-attention, they maycapture dependencies among redundant regions. This hinders comprehension ofanatomical structure content, poses challenges in modeling intra-class andinter-class dependencies, increases false negatives and compromisesgeneralization. Addressing these issues, we propose L2GNet, which learns globaldependencies by relating discrete codes obtained from DLS using optimaltransport and aligning codes on a trainable reference. L2GNet achievesdiscriminative on-the-fly representation learning without an additional weightmatrix in self-attention models, making it computationally efficient formedical applications. Extensive experiments on multi-organ segmentation andcardiac datasets demonstrate L2GNet's superiority over state-of-the-artmethods, including the CDLS method SynergyNet, offering an novel approach toenhance deep learning models' performance in medical image analysis.</description>
      <author>example@mail.com (Vandan Gorade, Sparsh Mittal, Neethi Dasu, Rekha Singhal, KC Santosh, Debesh Jha)</author>
      <guid isPermaLink="false">2502.05229v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.05485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be published in ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种分层的视觉-语言-动作(VLA)模型，用于解决在机器人领域中利用非目标域数据进行有效训练的问题，并展示了其在真实机器人的实验中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在视觉和语言领域的开放世界泛化能力较强，但在机器人领域尚未达到同等水平的泛化效果。主要挑战在于获取昂贵且有限的目标域机器人数据，一种可能的解决策略是利用更便宜、非目标域的数据如无动作视频或手绘草图。&lt;h4&gt;目的&lt;/h4&gt;探讨分层VLA模型在处理非目标域数据方面相较于标准单体VLA模型（直接将视觉-语言模型微调为预测动作）更为有效的假设，以及其如何实现在机器人任务中的泛化能力提升。&lt;h4&gt;方法&lt;/h4&gt;通过研究一类特定的分层VLA模型，在该模型中高层视觉-语言模型被微调以产生粗略2D路径指示期望机器人的末端执行器轨迹；基于此2D预测路径指导低层次、3D感知控制策略进行精确操作。这种设计减少了高层模型对细粒度动作预测的需求，同时减轻了低层政策的复杂任务级推理负担。&lt;h4&gt;主要发现&lt;/h4&gt;利用分层VLA模型架构，高层视觉-语言模型能够跨越显著的目标域与现实机器人测试场景间的差距（包括物理外观、动力学和语义差异等），在真实机器人实验中观察到相比于基准方法OpenVLA成功率提升20%的平均值。&lt;h4&gt;结论&lt;/h4&gt;该研究通过创新性的分层设计展示了一条利用非目标域数据有效训练机器人系统的路径，从而提高了模型在实际环境中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;大型基础模型已经在视觉和语言领域展现了对复杂问题的强大开放世界泛化能力，但在机器人领域的同等水平的泛化效果尚未实现。一个基本挑战是缺乏昂贵且难以获得的目标域机器人数据。一种有前景的方法是在视觉-语言动作(VLA)模型中引入层次结构来更有效地利用便宜、非目标域的数据，如无动作视频或手绘草图等。本文提出了一种分层VLA模型，其中高层视觉-语言模型被微调以生成指示期望机器人末端执行器轨迹的粗略2D路径。基于此路径预测作为低层次控制策略进行精确操作的指导。这种方法减轻了高层模型对细粒度动作预测的需求，并减轻了低层策略在复杂任务级推理上的负担，从而使得该方法能够跨越显著的目标域与现实机器人测试场景间的差距（包括物理外观、动力学和语义差异等）。在实际机器人的实验中，我们观察到相比于基准OpenVLA模型，在七种不同泛化轴向上有平均20%的成功率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models have shown strong open-world generalization tocomplex problems in vision and language, but similar levels of generalizationhave yet to be achieved in robotics. One fundamental challenge is the lack ofrobotic data, which are typically obtained through expensive on-robotoperation. A promising remedy is to leverage cheaper, off-domain data such asaction-free videos, hand-drawn sketches or simulation data. In this work, weposit that hierarchical vision-language-action (VLA) models can be moreeffective in utilizing off-domain data than standard monolithic VLA models thatdirectly finetune vision-language models (VLMs) to predict actions. Inparticular, we study a class of hierarchical VLA models, where the high-levelVLM is finetuned to produce a coarse 2D path indicating the desired robotend-effector trajectory given an RGB image and a task description. Theintermediate 2D path prediction is then served as guidance to the low-level,3D-aware control policy capable of precise manipulation. Doing so alleviatesthe high-level VLM from fine-grained action prediction, while reducing thelow-level policy's burden on complex task-level reasoning. We show that, withthe hierarchical design, the high-level VLM can transfer across significantdomain gaps between the off-domain finetuning data and real-robot testingscenarios, including differences on embodiments, dynamics, visual appearancesand task semantics, etc. In the real-robot experiments, we observe an averageof 20% improvement in success rate across seven different axes ofgeneralization over OpenVLA, representing a 50% relative gain. Visual resultsare provided at: https://hamster-robot.github.io/</description>
      <author>example@mail.com (Yi Li, Yuquan Deng, Jesse Zhang, Joel Jang, Marius Memme, Raymond Yu, Caelan Reed Garrett, Fabio Ramos, Dieter Fox, Anqi Li, Abhishek Gupta, Ankit Goyal)</author>
      <guid isPermaLink="false">2502.05485v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Addressing Out-of-Label Hazard Detection in Dashcam Videos: Insights from the COOOL Challenge</title>
      <link>http://arxiv.org/abs/2501.16037v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025, 5 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的方法，用于行车记录仪视频中的危险分析，包括驾驶员对危险的反应检测、危险物体识别以及生成描述性说明。&lt;h4&gt;背景&lt;/h4&gt;当前对于自动驾驶系统来说，在缺乏标记数据的情况下如何有效进行危险分析是一个挑战。现有的方法通常依赖于标签数据来训练模型，但这种情况在实际应用中并不总是可行。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入新的检测和识别技术来改进这一过程，这些技术可以在不完全依赖标注数据的前提下提高系统的性能。&lt;h4&gt;方法&lt;/h4&gt;{'驾驶员反应检测': '利用速度和声音异常检测的方法，并采用无监督学习技术。', '危险物检测': '使用一组启发式规则作为弱分类器，并通过集成学习方法结合这些分类器，同时引入差分隐私以进一步优化模型的稳健性。', '危险描述生成': '使用最新的视觉-语言模型为识别出的危险物体或场景生成描述性的标签。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在自动驾驶领域的无标签挑战中获得了最高分数，在驾驶员反应检测、危险物识别和生成描述性说明这三个任务上均表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文介绍的新方法通过集成学习与差分隐私技术的结合，成功地提高了行车记录仪视频中的危险分析能力，并证明了其在实际应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已直接用中文呈现&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ffyyytt/coool_2025&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach for hazard analysis in dashcam footage,addressing the detection of driver reactions to hazards, the identification ofhazardous objects, and the generation of descriptive captions. We firstintroduce a method for detecting driver reactions through speed and soundanomaly detection, leveraging unsupervised learning techniques. For hazarddetection, we employ a set of heuristic rules as weak classifiers, which arecombined using an ensemble method. This ensemble approach is further refinedwith differential privacy to mitigate overconfidence, ensuring robustnessdespite the lack of labeled data. Lastly, we use state-of-the-artvision-language models for hazard captioning, generating descriptive labels forthe detected hazards. Our method achieved the highest scores in the Challengeon Out-of-Label in Autonomous Driving, demonstrating its effectiveness acrossall three tasks. Source codes are publicly available athttps://github.com/ffyyytt/COOOL_2025.</description>
      <author>example@mail.com (Anh-Kiet Duong, Petra Gomez-Krämer)</author>
      <guid isPermaLink="false">2501.16037v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>MoFM: A Large-Scale Human Motion Foundation Model</title>
      <link>http://arxiv.org/abs/2502.05432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FM）由于其在不同任务中的可扩展性和泛化能力而越来越受到研究者的关注。&lt;h4&gt;目的&lt;/h4&gt;受基础模型和大型语言模型进展原则的启发，本文介绍了一种新型的基础运动模型MoFM，旨在实现复杂人体运动的时间和空间语义理解。&lt;h4&gt;方法&lt;/h4&gt;为支持大规模训练，设计并采用MotionBook作为综合的人体动作词典。MotionBook利用热立方体捕捉时空运动热图，并应用离散变分模型的原则将人类运动编码成离散单元以实现更高效、可扩展的表示。&lt;h4&gt;主要发现&lt;/h4&gt;经过大量运动数据集训练后的MoFM提供了一个适应各种下游任务的基础骨干，支持如一次学习、无监督和有监督的任务范式。这种多功能性使MoFM非常适合广泛的基于动作的应用程序。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了基础运动模型在处理复杂人体运动中的时间和空间语义理解方面的潜力，并且通过有效的训练方法和创新的表示技术提高了模型的可扩展性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含中文，无需额外翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AFoundation Models (FM) have increasingly drawn the attention of researchersdue to their scalability and generalization across diverse tasks. Inspired bythe success of FMs and the principles that have driven advancements in LargeLanguage Models (LLMs), we introduce MoFM as a novel Motion Foundation Model.MoFM is designed for the semantic understanding of complex human motions inboth time and space. To facilitate large-scale training, MotionBook, acomprehensive human motion dictionary of discretized motions is designed andemployed. MotionBook utilizes Thermal Cubes to capture spatio-temporal motionheatmaps, applying principles from discrete variational models to encode humanmovements into discrete units for a more efficient and scalable representation.MoFM, trained on a large corpus of motion data, provides a foundationalbackbone adaptable to diverse downstream tasks, supporting paradigms such asone-shot, unsupervised, and supervised tasks. This versatility makes MoFMwell-suited for a wide range of motion-based applications.</description>
      <author>example@mail.com (Mohammadreza Baharani, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Gabriel Maldonado, Hamed Tabkhi)</author>
      <guid isPermaLink="false">2502.05432v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation</title>
      <link>http://arxiv.org/abs/2502.05424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WWW2025 Main Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个用于多域图预训练和跨领域适应的结构对齐框架（SAMGPT），该框架能够从多个来源领域中的图形中学习到多领域的知识，并将其应用于未知的目标领域。&lt;h4&gt;背景&lt;/h4&gt;在线服务使用图形来表示相互关联的实体，支持了网络上的广泛应用。然而，来自不同域的图常常表现出不同的特性，这给跨域适应带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从多个来源领域中学习并适应到未知目标领域的模型框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结构对齐框架（SAMGPT），该框架在预训练阶段引入了结构令牌来协调多源域中的基于结构的聚合，并设计了用于跨域适应的整体提示和特定提示。&lt;h4&gt;主要发现&lt;/h4&gt;通过全面实验评估了提出的SAMGPT的有效性。&lt;h4&gt;结论&lt;/h4&gt;SAMGPT为解决图的基础模型如何从多个来源领域进行训练并适应到未知目标领域的挑战提供了一个创新的方法。&lt;h4&gt;翻译&lt;/h4&gt;图能够建模许多在线服务中的互连实体，支持网络上广泛的应用。这提出了一个问题：我们如何在多源域中训练图基础模型，并将其调整为一个未见的目标域？主要障碍是来自不同域的图经常表现出不同的特性。一些研究利用大型语言模型基于与图形关联的文字描述来对齐多个领域，限制了它们仅适用于附有文字属性的图。对于无文本图而言，最近的一些工作试图跨领域对齐不同的特征分布，但通常忽视了结构差异。在本文中，我们提出了一个新颖的结构对齐框架用于无文本多域图预训练和跨域适应（SAMGPT），该框架旨在从多个来源领域的图形中学得多领域知识，并将其应用于未见的目标领域。具体来说，在预训练阶段，我们引入了一组结构令牌以协调基于结构的聚合。然后对于跨域适应，我们设计了双提示，即整体提示和特定提示，分别用于将统一的多域结构性知识以及细粒度的、特定领域的信息调整到目标域。最后，我们在七个公开数据集上进行了全面实验，评估并分析了SAMGPT的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are able to model interconnected entities in many online services,supporting a wide range of applications on the Web. This raises an importantquestion: How can we train a graph foundational model on multiple sourcedomains and adapt to an unseen target domain? A major obstacle is that graphsfrom different domains often exhibit divergent characteristics. Some studiesleverage large language models to align multiple domains based on textualdescriptions associated with the graphs, limiting their applicability totext-attributed graphs. For text-free graphs, a few recent works attempt toalign different feature distributions across domains, while generallyneglecting structural differences. In this work, we propose a novel StructureAlignment framework for text-free Multi-domain Graph Pre-Training andcross-domain adaptation (SAMGPT). It is designed to learn multi-domainknowledge from graphs originating in multiple source domains, which can then beadapted to address applications in an unseen target domain. Specifically, weintroduce a set of structure tokens to harmonize structure-based aggregationacross source domains during the pre-training phase. Next, for cross-domainadaptation, we design dual prompts, namely, holistic prompts and specificprompts, which adapt unified multi-domain structural knowledge andfine-grained, domain-specific information, respectively, to a target domain.Finally, we conduct comprehensive experiments on seven public datasets toevaluate and analyze the effectiveness of SAMGPT.</description>
      <author>example@mail.com (Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang)</author>
      <guid isPermaLink="false">2502.05424v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Particle Trajectory Representation Learning with Masked Point Modeling</title>
      <link>http://arxiv.org/abs/2502.02558v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. 24 pages, 15 figures. Project page at  https://youngsm.com/polarmae/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于3D粒子轨迹分析的自监督学习框架PoLAr-MAE。&lt;h4&gt;背景&lt;/h4&gt;虽然许多在线语料库和带注释照片的方法已经得到发展，但在科学领域中应用这些方法仍处于初期阶段。&lt;h4&gt;目的&lt;/h4&gt;开发一种针对时间投影室（TPCs）中的3D粒子轨迹分析的自监督学习框架。&lt;h4&gt;方法&lt;/h4&gt;基于PointMAE，提出体积分词以将稀疏的离子化点分类为分辨率无关的补丁，并增加了一个辅助能量填充任务来改进轨迹语义。&lt;h4&gt;主要发现&lt;/h4&gt;PoLAr-MAE模型在不使用任何标记数据的情况下达到了与监督基线相当的表现水平（轨迹和淋浴分类F分数分别为99.4%和97.7%）。&lt;h4&gt;问题&lt;/h4&gt;尽管该模型学习了丰富的粒子轨迹表示，但它在处理子令牌现象（如重叠或短寿命的粒子轨迹）时存在困难。&lt;h4&gt;贡献&lt;/h4&gt;发布了一个大型公开LArTPC数据集PILArNet-M（超过100万个事件和52亿个标记点），以推进高能物理中的自监督学习。&lt;h4&gt;翻译&lt;/h4&gt;有效的自我监督学习技术在解锁大规模数据集用于表示学习方面发挥了关键作用。尽管许多具有前景的方法已经使用在线语料库和带注释的照片开发出来，但在包含高度专业化知识的科学领域中应用这些方法仍处于初期阶段。我们提出了一种针对时间投影室（TPCs）中的3D粒子轨迹分析的自监督屏蔽建模框架。这些探测器生成全局稀疏但局部密集的点云，以毫米分辨率捕获米尺度的粒子轨迹。基于PointMAE的工作提出了体积分词来将稀疏的离子化点分类为分辨率无关的补丁，并增加了一个辅助能量填充任务来改进轨迹语义。这一方法——我们称之为PoLAr-MAE——在不使用任何标记数据的情况下，实现了与监督基线相当的表现水平（轨迹和淋浴分类F分数分别为99.4%和97.7%）。虽然该模型学习了丰富的粒子轨迹表示，但在处理子令牌现象如重叠或短寿命的粒子轨迹时存在困难。为了支持进一步的研究，我们发布了PILArNet-M——最大的公开LArTPC数据集（超过100万个事件和52亿个标记点）以推动高能物理中的自监督学习的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective self-supervised learning (SSL) techniques have been key tounlocking large datasets for representation learning. While many promisingmethods have been developed using online corpora and captioned photographs,their application to scientific domains, where data encodes highly specializedknowledge, remains in its early stages. We present a self-supervised maskedmodeling framework for 3D particle trajectory analysis in Time ProjectionChambers (TPCs). These detectors produce globally sparse (&lt;1% occupancy) butlocally dense point clouds, capturing meter-scale particle trajectories atmillimeter resolution. Starting with PointMAE, this work proposes volumetrictokenization to group sparse ionization points into resolution-agnosticpatches, as well as an auxiliary energy infilling task to improve trajectorysemantics. This approach -- which we call Point-based Liquid Argon MaskedAutoencoder (PoLAr-MAE) -- achieves 99.4% track and 97.7% shower classificationF-scores, matching that of supervised baselines without any labeled data. Whilethe model learns rich particle trajectory representations, it struggles withsub-token phenomena like overlapping or short-lived particle trajectories. Tosupport further research, we release PILArNet-M -- the largest open LArTPCdataset (1M+ events, 5.2B labeled points) -- to advance SSL in high energyphysics (HEP). Project site: https://youngsm.com/polarmae/</description>
      <author>example@mail.com (Sam Young, Yeon-jae Jwa, Kazuhiro Terao)</author>
      <guid isPermaLink="false">2502.02558v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Infinite-Horizon Value Function Approximation for Model Predictive Control</title>
      <link>http://arxiv.org/abs/2502.06760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何使用神经网络和价值迭代以及轨迹优化来近似约束最优控制问题的无限时间价值函数，并展示了将这种价值函数作为终端成本用于模型预测控制器中的全局稳定性。该方法通过两个玩具问题和一个在线避障的真实世界场景得到了验证。&lt;h4&gt;背景&lt;/h4&gt;模型预测控制（MPC）已成为机器人生成复杂运动的一种流行工具，但由于实时要求限制了硬约束和大预览时间窗口的使用，这影响了系统的安全性和稳定性。实践中，设计人员必须仔细设计成本函数以模仿无限时间框架，这是一个繁琐且容易陷入局部最优解的过程。&lt;h4&gt;目的&lt;/h4&gt;研究如何近似约束最优控制问题的无限时间价值函数，并展示这种价值函数作为终端成本在模型预测控制器中提供的全局稳定性。&lt;h4&gt;方法&lt;/h4&gt;通过使用神经网络和价值迭代以及轨迹优化来近似无限时间价值函数。将这种方法应用于两个玩具问题和在线避障的真实世界场景验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法成功地展示了如何利用价值函数的近似作为终端成本，提供模型预测控制器中的全局稳定性，并通过实验表明这种技术的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为解决机器人在实时环境下的复杂运动控制问题提供了有效的解决方案，特别是在确保系统安全性和稳定性的前提下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model Predictive Control has emerged as a popular tool for robots to generatecomplex motions. However, the real-time requirement has limited the use of hardconstraints and large preview horizons, which are necessary to ensure safetyand stability. In practice, practitioners have to carefully design costfunctions that can imitate an infinite horizon formulation, which is tediousand often results in local minima. In this work, we study how to approximatethe infinite horizon value function of constrained optimal control problemswith neural networks using value iteration and trajectory optimization.Furthermore, we demonstrate how using this value function approximation as aterminal cost provides global stability to the model predictive controller. Theapproach is validated on two toy problems and a real-world scenario with onlineobstacle avoidance on an industrial manipulator where the value function isconditioned to the goal and obstacle.</description>
      <author>example@mail.com (Armand Jordana, Sébastien Kleff, Arthur Haffemayer, Joaquim Ortiz-Haro, Justin Carpentier, Nicolas Mansard, Ludovic Righetti)</author>
      <guid isPermaLink="false">2502.06760v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>FOCUS - Multi-View Foot Reconstruction From Synthetically Trained Dense Correspondences</title>
      <link>http://arxiv.org/abs/2502.06367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从多个校准图像重建表面是一个具有挑战性的任务，通常需要大量重叠显著的收集到的图像。&lt;h4&gt;目的&lt;/h4&gt;旨在解决人类脚部重建的具体问题，通过多视角RGB图像提取丰富的像素级几何线索，并将这些线索融合成最终的3D对象。&lt;h4&gt;方法&lt;/h4&gt;{'贡献一': 'SynFoot2，现有合成足数据集的扩展，包括新的数据类型：与参数化足模型FIND的密集对应关系。', '贡献二': '基于我们的合成数据集训练出一个感知不确定性的密集对应预测器。', '贡献三': '两种从密集对应的预测重建3D表面的方法：一种受结构从运动启发的方法；另一种使用FIND模型的优化方法。'}&lt;h4&gt;主要发现&lt;/h4&gt;在少视角设置下，重建的质量达到了最先进的水平，在多视角可用时性能也与最先进方法相当，并且运行速度显著更快。&lt;h4&gt;结论&lt;/h4&gt;我们发布我们的合成数据集供研究界使用。代码可在https://github.com/OllieBoyne/FOCUS获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种名为FOCUS的方法，用于从多视角RGB图像中重建人类脚部的3D表面，并提出了该方法在少视角设置下的优越性能及运行速度的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface reconstruction from multiple, calibrated images is a challenging task- often requiring a large number of collected images with significant overlap.We look at the specific case of human foot reconstruction. As with previoussuccessful foot reconstruction work, we seek to extract rich per-pixel geometrycues from multi-view RGB images, and fuse these into a final 3D object. Ourmethod, FOCUS, tackles this problem with 3 main contributions: (i) SynFoot2, anextension of an existing synthetic foot dataset to include a new data type:dense correspondence with the parameterized foot model FIND; (ii) anuncertainty-aware dense correspondence predictor trained on our syntheticdataset; (iii) two methods for reconstructing a 3D surface from densecorrespondence predictions: one inspired by Structure-from-Motion, and oneoptimization-based using the FIND model. We show that our reconstructionachieves state-of-the-art reconstruction quality in a few-view setting,performing comparably to state-of-the-art when many views are available, andruns substantially faster. We release our synthetic dataset to the researchcommunity. Code is available at: https://github.com/OllieBoyne/FOCUS</description>
      <author>example@mail.com (Oliver Boyne, Roberto Cipolla)</author>
      <guid isPermaLink="false">2502.06367v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Wandering around: A bioinspired approach to visual attention through object motion sensitivity</title>
      <link>http://arxiv.org/abs/2502.06747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种受生物启发的注意系统，该系统利用脉冲卷积神经网络和动态视觉传感器进行对象运动敏感性选择性关注。&lt;h4&gt;背景&lt;/h4&gt;主动视觉允许动态视觉感知，为依赖大规模数据集和高计算资源的传统前馈架构提供了替代方案。基于哺乳动物视网膜设计的事件相机通过捕获异步场景变化增强了这种能力，从而实现高效低延迟处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种结合事件传感器与神经形态算法的新颖系统，以提高在动态环境中的实时响应能力和计算效率。&lt;h4&gt;方法&lt;/h4&gt;使用Speck神经形态硬件集成的动态视觉传感器（DVS）和倾斜-平移单元组成一个系统，通过固定眼球运动生成事件来识别ROI，并对目标进行中心化处理。该系统利用理想光栅进行了表征，并在Event Camera Motion Segmentation Dataset上进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;系统在多对象运动分割中达到了平均IoU为82.2%和SSIM为96%，办公室场景中显著物体检测精度达到88.8%，低光照条件下达到89.8%。该系统的实时演示显示，其对动态场景的响应时间为0.12秒。&lt;h4&gt;结论&lt;/h4&gt;一种无需学习的设计确保了系统在感知场景中的鲁棒性，并为实时机器人应用提供了可靠基础，也为更复杂架构的发展奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;主动视觉通过使用脉冲卷积神经网络和动态视觉传感器（DVS）进行选择性注意，在对象运动敏感性的基础上实现。该方法使系统能够高效地在低光照等复杂条件下操作，并为实时机器人应用提供了坚实的基础，同时为更复杂的架构发展开辟了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active vision enables dynamic visual perception, offering an alternative tostatic feedforward architectures in computer vision, which rely on largedatasets and high computational resources. Biological selective attentionmechanisms allow agents to focus on salient Regions of Interest (ROIs),reducing computational demand while maintaining real-time responsiveness.Event-based cameras, inspired by the mammalian retina, enhance this capabilityby capturing asynchronous scene changes enabling efficient low-latencyprocessing. To distinguish moving objects while the event-based camera is inmotion the agent requires an object motion segmentation mechanism to accuratelydetect targets and center them in the visual field (fovea). Integratingevent-based sensors with neuromorphic algorithms represents a paradigm shift,using Spiking Neural Networks to parallelize computation and adapt to dynamicenvironments. This work presents a Spiking Convolutional Neural Networkbioinspired attention system for selective attention through object motionsensitivity. The system generates events via fixational eye movements using aDynamic Vision Sensor integrated into the Speck neuromorphic hardware, mountedon a Pan-Tilt unit, to identify the ROI and saccade toward it. The system,characterized using ideal gratings and benchmarked against the Event CameraMotion Segmentation Dataset, reaches a mean IoU of 82.2% and a mean SSIM of 96%in multi-object motion segmentation. The detection of salient objects reaches88.8% accuracy in office scenarios and 89.8% in low-light conditions on theEvent-Assisted Low-Light Video Object Segmentation Dataset. A real-timedemonstrator shows the system's 0.12 s response to dynamic scenes. Itslearning-free design ensures robustness across perceptual scenes, making it areliable foundation for real-time robotic applications serving as a basis formore complex architectures.</description>
      <author>example@mail.com (Giulia D Angelo, Victoria Clerico, Chiara Bartolozzi, Matej Hoffmann, P. Michael Furlong, Alexander Hadjiivanov)</author>
      <guid isPermaLink="false">2502.06747v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Rough Stochastic Pontryagin Maximum Principle and an Indirect Shooting Method</title>
      <link>http://arxiv.org/abs/2502.06726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究推导了确定性控制下的随机最优控制的一阶Pontryagin最优条件。&lt;h4&gt;背景&lt;/h4&gt;系统由粗糙微分方程（RDE）驱动，并且这些方程是高斯粗糙路径的一部分。这种方法可以应用于遵循布朗运动驱动的随机微分方程(SDE)的系统，但不依赖于前向-后向SDE，并使用与确定性PMP相同的哈密顿量。&lt;h4&gt;目的&lt;/h4&gt;目的是推导出一种适用于RDE系统的Pontryagin最大原理（PMP），并提出了一种间接射击法来解决非线性的随机最优控制问题，这种方法比直接方法快10倍。&lt;h4&gt;方法&lt;/h4&gt;首先通过利用高斯粗糙路径的最新结果，推导了非线性及线性RDE解的各种可积误差界限。然后使用基于针状变化的标准技术得出了PMP。&lt;h4&gt;主要发现&lt;/h4&gt;首次提出了间接射击法来解决非线性的随机最优控制问题，并且该方法在稳定性任务上比直接方法收敛速度快10倍。&lt;h4&gt;结论&lt;/h4&gt;所提出的Pontryagin最大原理（PMP）及其应用于非线性随机最优控制的间接射击法，为研究和应用提供了一种新的工具。&lt;h4&gt;翻译&lt;/h4&gt;我们针对由高斯粗糙路径驱动的粗糙微分方程系统，推导了确定性控制下的随机最优控制的一阶Pontryagin最优条件。这种Pontryagin最大原理（PMP）可以应用于布朗运动驱动的随机微分方程(SDE)的系统，但它不依赖于前向-后向SDE，并使用与确定性PMP相同的哈密顿量。证明过程包括首先通过利用高斯粗糙路径的最新结果推导出非线性和线性RDE解的各种可积误差界限。然后，使用基于针状变化的标准技术得出PMP。作为应用，我们首次提出了间接射击法来解决非线性的随机最优控制问题，并显示该方法比直接方法在稳定性任务上收敛速度快10倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We derive first-order Pontryagin optimality conditions for stochastic optimalcontrol with deterministic controls for systems modeled by rough differentialequations (RDE) driven by Gaussian rough paths. This Pontryagin MaximumPrinciple (PMP) applies to systems following stochastic differential equations(SDE) driven by Brownian motion, yet it does not rely on forward-backward SDEsand involves the same Hamiltonian as the deterministic PMP. The proof consistsof first deriving various integrable error bounds for solutions to nonlinearand linear RDEs by leveraging recent results on Gaussian rough paths. The PMPthen follows using standard techniques based on needle-like variations. As anapplication, we propose the first indirect shooting method for nonlinearstochastic optimal control and show that it converges 10x faster than a directmethod on a stabilization task.</description>
      <author>example@mail.com (Thomas Lew)</author>
      <guid isPermaLink="false">2502.06726v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems</title>
      <link>http://arxiv.org/abs/2502.06581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;综述了云边端协同（CETC）系统在视频数据分析中的应用，探讨了其架构、边缘计算平台和资源管理机制。&lt;h4&gt;背景&lt;/h4&gt;视频数据的爆炸性增长推动了分布式视频分析的发展，尤其是基于CETC系统的高效视频处理、实时推理以及隐私保护分析。&lt;h4&gt;目的&lt;/h4&gt;分析CETC系统的根本组成要素，包括分层框架、分布式框架及混合架构，并探讨边缘计算平台和资源管理机制。&lt;h4&gt;方法&lt;/h4&gt;研究分为两部分：一部分侧重于以设备为中心的边缘处理方式；另一部分则聚焦云中心的方法，利用强大的计算能力进行复杂的视频理解和模型训练。此外还介绍了结合自适应任务卸载和资源感知调度技术的混合视频分析。&lt;h4&gt;主要发现&lt;/h4&gt;当前研究涵盖传统方法以及大型语言模型和多模态集成带来的新机会与挑战，在平台可扩展性、数据保护及系统可靠性方面均有体现。&lt;h4&gt;结论&lt;/h4&gt;未来的研究方向包括解释性的系统设计、高效的处理机制，以及高级视频分析技术的开发，这些都将为研究人员和从业者提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了分布式视频数据分析在云边端协同（CETC）系统中的应用情况，该领域的研究涵盖了系统的架构组成要素、边缘计算平台与资源管理机制，并探讨了多种处理方法及其面临的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of video data has driven the development of distributedvideo analytics in cloud-edge-terminal collaborative (CETC) systems, enablingefficient video processing, real-time inference, and privacy-preservinganalysis. Among multiple advantages, CETC systems can distribute videoprocessing tasks and enable adaptive analytics across cloud, edge, and terminaldevices, leading to breakthroughs in video surveillance, autonomous driving,and smart cities. In this survey, we first analyze fundamental architecturalcomponents, including hierarchical, distributed, and hybrid frameworks,alongside edge computing platforms and resource management mechanisms. Buildingupon these foundations, edge-centric approaches emphasize on-device processing,edge-assisted offloading, and edge intelligence, while cloud-centric methodsleverage powerful computational capabilities for complex video understandingand model training. Our investigation also covers hybrid video analyticsincorporating adaptive task offloading and resource-aware scheduling techniquesthat optimize performance across the entire system. Beyond conventionalapproaches, recent advances in large language models and multimodal integrationreveal both opportunities and challenges in platform scalability, dataprotection, and system reliability. Future directions also encompassexplainable systems, efficient processing mechanisms, and advanced videoanalytics, offering valuable insights for researchers and practitioners in thisdynamic field.</description>
      <author>example@mail.com (Linxiao Gong, Hao Yang, Gaoyun Fang, Bobo Ju, Juncen Guo, Xiaoguang Zhu, Yan Wang, Xiping Hu, Peng Sun, Azzedine Boukerche)</author>
      <guid isPermaLink="false">2502.06581v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Building Rome with Convex Optimization</title>
      <link>http://arxiv.org/abs/2502.04640v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过深度预测和凸优化使全局束调整变得更简单。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来简化全局束调整，并提高结构从运动（SfM）管道的性能。&lt;h4&gt;方法&lt;/h4&gt;{'(i)': '提出了一个缩放的全局束调整(SBA)公式，该公式通过学习到的深度将2D关键点测量提升至3D空间。', '(ii)': '设计了一种经验上紧致的凸半定规划(SDP)松弛方案，用于以可证明的全局最优性解决SBA问题。', '(iii)': '使用Burder-Monteiro因子化和基于CUDA的信任区域黎曼优化器(XM)来在极端规模下求解SDP松弛。', '(iv)': '构建了一个结构从运动(SfM)管道，其中XM作为优化引擎，并展示了该方法相较于现有SfM管道具有更好的重建质量和更快的速度、可扩展性以及无需初始化的特点。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的XM-SfM在图像重建质量上优于或至少与现有的SfM管道相当，同时提高了速度和规模的灵活性。&lt;h4&gt;结论&lt;/h4&gt;通过结合深度学习和凸优化技术，解决了全局束调整问题，并开发了一个性能优越、无需初始化且更高效的结构从运动(SfM)系统。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已转化为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global bundle adjustment is made easy by depth prediction and convexoptimization. We (i) propose a scaled bundle adjustment (SBA) formulation thatlifts 2D keypoint measurements to 3D with learned depth, (ii) design anempirically tight convex semidfinite program (SDP) relaxation that solves SBAto certfiable global optimality, (iii) solve the SDP relaxations at extremescale with Burer-Monteiro factorization and a CUDA-based trust-regionRiemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM)pipeline with XM as the optimization engine and show that XM-SfM dominates orcompares favorably with existing SfM pipelines in terms of reconstructionquality while being faster, more scalable, and initialization-free.</description>
      <author>example@mail.com (Haoyu Han, Heng Yang)</author>
      <guid isPermaLink="false">2502.04640v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in Dynamic Environments by Leveraging Object Detection</title>
      <link>http://arxiv.org/abs/2502.06725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript has been submitted to 2025 INTERNATIONAL CONFERENCE ON  UNMANNED AIRCRAFT SYSTEMS (ICUAS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于深度强化学习的自主无人机导航方案，以解决动态环境中快速移动物体导致的目标位置变化问题。&lt;h4&gt;背景&lt;/h4&gt;现有的传统规划方法和经典优化算法在面对实时、不可预测的变化时表现不佳，适应性和实时决策能力受限。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的运动规划器AgilePilot，利用深度强化学习技术结合实时计算机视觉进行对象检测，以提高无人机在动态环境中的导航性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度强化学习的运动规划器AgilePilot，并通过训练-部署框架来缩小仿真与真实世界的差距。该系统采用先进的奖励结构促进安全性及灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;新的运动规划器相比传统的人工势场法等算法，在性能和动态目标跟踪精度方面提高3倍，实验成功率高达90%。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了深度强化学习在解决实时动态导航挑战方面的有效性，并为智能安全与灵活的无人机导航提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;自主无人机构建在动态环境中的导航仍然是一个关键挑战，特别是在处理快速移动物体以及目标位置迅速变化的情况下。传统规划方法和经典优化技术虽然广泛使用，但面对实时不可预测的变化时适应性和实时决策能力不足，导致性能不佳。本文提出了一种新的基于深度强化学习的运动规划器AgilePilot，并结合飞行中实时计算机视觉进行对象检测，以提高无人机在动态环境中的导航效果。该系统能够快速适应变化环境，并实现最大速度为3.0米/秒的实际应用场景表现。相比传统的势场法等算法，在性能和跟踪精度方面提高了三倍，并且在75次实验中的成功率高达90%。这项工作强调了深度强化学习技术解决实时动态导航挑战的有效性，提供了智能安全性和灵活度的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous drone navigation in dynamic environments remains a criticalchallenge, especially when dealing with unpredictable scenarios includingfast-moving objects with rapidly changing goal positions. While traditionalplanners and classical optimisation methods have been extensively used toaddress this dynamic problem, they often face real-time, unpredictable changesthat ultimately leads to sub-optimal performance in terms of adaptiveness andreal-time decision making. In this work, we propose a novel motion planner,AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained indynamic conditions, coupled with real-time Computer Vision (CV) for objectdetections during flight. The training-to-deployment framework bridges theSim2Real gap, leveraging sophisticated reward structures that promotes bothsafety and agility depending upon environment conditions. The system canrapidly adapt to changing environments, while achieving a maximum speed of 3.0m/s in real-world scenarios. In comparison, our approach outperforms classicalalgorithms such as Artificial Potential Field (APF) based motion planner by 3times, both in performance and tracking accuracy of dynamic targets by usingvelocity predictions while exhibiting 90% success rate in 75 conductedexperiments. This work highlights the effectiveness of DRL in tacklingreal-time dynamic navigation challenges, offering intelligent safety andagility.</description>
      <author>example@mail.com (Roohan Ahmed Khan, Valerii Serpiva, Demetros Aschalew, Aleksey Fedoseev, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.06725v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Resilient and Energy-Efficient Smart Metering Infrastructure Utilizing a Self-Organizing UAV Swarm</title>
      <link>http://arxiv.org/abs/2502.06508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于无人机群的智能计量架构，旨在解决传统人工抄表方式带来的成本高、安全性差和准确性低的问题。&lt;h4&gt;背景&lt;/h4&gt;智能电表基础设施可能成为智慧城市中有效管理能源的关键因素之一。目前，传统的测量记录收集主要通过手动方式进行，这带来了成本、安全性和准确性的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种基于无人机群的自动数据采集架构，用于智能计量基础设施，并确保其可扩展性、低成本和风险最小化。&lt;h4&gt;方法&lt;/h4&gt;开发了一个综合系统，包括多种操作阶段、通信协议以及可靠的故障处理机制。进行了广泛的仿真，以维护精确飞行编队、高效收集智能电表的数据以及适应各种故障场景。另外分析了无人机群的能量消耗，并提出了电池尺寸策略及无人机群的运行寿命估计。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，基于无人机群的方案在数据采集效率和可靠性方面具有显著优势，能够有效支持绿色智慧城市的发展。&lt;h4&gt;结论&lt;/h4&gt;UAV（无人飞行器）群有潜力彻底改变智能计量领域，推动更环保、更具弹性的智慧城市建设。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The smart metering infrastructure may become one of the key elements inefficiently managing energy in smart cities. At the same time, traditionalmeasurement record collection is performed by manual methods, which raisescost, safety, and accuracy issues. This paper proposes an innovative SMIarchitecture based on an unmanned aerial vehicle swarm organizing itself forthe autonomous data collection in smart metering infrastructure withscalability and cost-effectiveness while minimizing risks. We design anarchitecture-based comprehensive system with various phases of operation,communication protocols, and robust failure-handling mechanisms to ensurereliable operations. We further perform extensive simulations in maintenance ofprecise formations during flight, efficient data collection from smart meters,and adaptation to various failure scenarios. Importantly, we analyze the energyconsumption of the proposed system in both drone flight operations and networkcommunication. We now propose a battery sizing strategy and provide an estimateof the operational lifetime of the swarm, underlining the feasibility andpracticality of our approach. Our results show that UAV swarms have greatpotential to revolutionize smart metering and to bring a further brick togreener and more resilient smart cities.</description>
      <author>example@mail.com (Mustafa Siham, Qutaiba I. Ali)</author>
      <guid isPermaLink="false">2502.06508v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>HetSwarm: Cooperative Navigation of Heterogeneous Swarm in Dynamic and Dense Environments through Impedance-based Guidance</title>
      <link>http://arxiv.org/abs/2502.06722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript has been submitted to ICUAS-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HetSwarm是一种结合了无人机和地面移动机器人的异构多机器人系统，旨在解决物流和仓库管理中的高效性需求。&lt;h4&gt;背景&lt;/h4&gt;随着对高效物流和仓储管理系统的需求增加，无人飞行器（UAV）作为自动引导车（AGV）的补充正在变得越来越重要。然而，无人机受到有限飞行时间、电池寿命以及载荷能力的限制。&lt;h4&gt;目的&lt;/h4&gt;提出HetSwarm系统以应对上述挑战，该系统结合了无人机和地面移动机器人进行协作导航。&lt;h4&gt;方法&lt;/h4&gt;采用人工势场（APF）路径规划器用于无人机，并使用阻抗链接保持地面上机器人的连接稳定性。地面机器人还建立了与低高度障碍物的临时阻抗链路，避免局部碰撞。&lt;h4&gt;主要发现&lt;/h4&gt;在各种环境条件下对HetSwarm进行了实验验证，在30个测试案例中取得了90%的成功率；地面机器人表现出平均45厘米的偏离距离，有效避开了障碍物。模拟也证实了系统的鲁棒性及其实际应用潜力。&lt;h4&gt;结论&lt;/h4&gt;HetSwarm系统通过协作导航展示了其在拥挤且动态环境中的高效性和适应能力，并为未来的实时任务执行提供了可能的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;随着对物流和仓储管理效率需求的增长，无人飞行器（UAV）作为自动引导车（AGV）的有效补充正在变得越来越重要。无人机提高效率的能力在于它们可以导航密集环境并在不同高度上操作。然而，由于其有限的飞行时间、电池寿命以及载荷能力限制，需要地面站的支持来协助工作。为了应对这些挑战，我们提出了HetSwarm系统，这是一种结合了UAV和移动地面机器人的异构多机器人系统，用于在混乱和动态条件下进行协作导航。我们的方法采用人工势场（APF）路径规划器为无人机提供实时调整轨迹的能力。地面上的机器人跟随这条路径并保持通过阻抗链接建立的连接稳定性，确保协调一致。此外，地面机器人还会与低高度障碍物建立临时阻抗链路以避免局部碰撞，因为这些障碍物不会影响无人机飞行。在各种环境条件下对HetSwarm进行了实验验证，在30个测试案例中取得了90%的成功率；同时，地面上的机器人在遇到障碍物时表现出平均45厘米的偏离距离，证实了有效的避碰能力。通过Gym PyBullet环境中的广泛模拟进一步验证了我们系统的鲁棒性以适应实际应用，并证明其在混乱环境中进行动态实时任务执行方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing demand for efficient logistics and warehouse management,unmanned aerial vehicles (UAVs) are emerging as a valuable complement toautomated guided vehicles (AGVs). UAVs enhance efficiency by navigating denseenvironments and operating at varying altitudes. However, their limited flighttime, battery life, and payload capacity necessitate a supporting groundstation. To address these challenges, we propose HetSwarm, a heterogeneousmulti-robot system that combines a UAV and a mobile ground robot forcollaborative navigation in cluttered and dynamic conditions. Our approachemploys an artificial potential field (APF)-based path planner for the UAV,allowing it to dynamically adjust its trajectory in real time. The ground robotfollows this path while maintaining connectivity through impedance links,ensuring stable coordination. Additionally, the ground robot establishestemporal impedance links with low-height ground obstacles to avoid localcollisions, as these obstacles do not interfere with the UAV's flight.Experimental validation of HetSwarm in diverse environmental conditionsdemonstrated a 90% success rate across 30 test cases. The ground robotexhibited an average deviation of 45 cm near obstacles, confirming effectivecollision avoidance. Extensive simulations in the Gym PyBullet environmentfurther validated the robustness of our system for real-world applications,demonstrating its potential for dynamic, real-time task execution in clutteredenvironments.</description>
      <author>example@mail.com (Malaika Zafar, Roohan Ahmed Khan, Aleksey Fedoseev, Kumar Katyayan Jaiswal, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.06722v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimization under Attack: Resilience, Vulnerability, and the Path to Collapse</title>
      <link>http://arxiv.org/abs/2502.05954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了分布式敌对攻击下多智能体离散选择组合优化的性能轨迹，从弹性到脆弱性再到崩溃。&lt;h4&gt;背景&lt;/h4&gt;对于智慧城市的大型社会技术基础设施（如能源和交通系统），优化是提高运营效率的重要手段。尤其在多智能体系统的分布式对抗攻击下的表现尚缺乏研究。&lt;h4&gt;目的&lt;/h4&gt;探索不同敌对强度及网络位置的代理数量如何影响分布式优化性能，包括帕累托最优解点。&lt;h4&gt;方法&lt;/h4&gt;利用真实世界数据模拟超过28亿个情景来评估优化性能。创建了一个开放的大规模数据集作为基准。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了从弹性到脆弱性再到崩溃的不同敌对攻击强度下的优化轨迹，并明确了哪些条件会使系统变得脆弱或崩溃。&lt;h4&gt;结论&lt;/h4&gt;这些新发现为设计对抗分布式优化的故障容忍和故障纠正策略提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;本文首次解析了在不同的敌对影响下，从弹性到脆弱性再到最终崩溃的分布式优化路径。通过模拟超过28亿个情景，并利用真实世界数据进行评估，展示了不同数量的不同类型代理如何影响分布式优化性能和帕累托最优解点的存在情况。此研究为设计新的故障容忍及修复策略提供了宝贵见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimization is instrumental for improving operations of large-scalesocio-technical infrastructures of Smart Cities, for instance, energy andtraffic systems. In particular, understanding the performance of multi-agentdiscrete-choice combinatorial optimization under distributed adversary attacksis a compelling and underexplored problem, since multi-agent systems exhibit alarge number of remote control variables that can influence in an unprecedentedway the cost-effectiveness of distributed optimization heuristics. This paperunravels for the first time the trajectories of distributed optimization fromresilience to vulnerability, and finally to collapse under varying adversaryinfluence. Using real-world data to emulate over 28 billion multi-agentoptimization scenarios, we exhaustively assess how the number of agents withdifferent adversarial severity and network positioning influences optimizationperformance, including the influence on Pareto optimal points. With this novellarge-scale dataset, made openly available as a benchmark, we disentangle howoptimization remains resilient to adversaries and which adversary conditionsare required to make optimization vulnerable or collapsed. These new findingscan provide new insights for designing self-healing strategies forfault-tolerance and fault-correction in adversarial distributed optimizationthat have been missing so far.</description>
      <author>example@mail.com (Amal Aldawsari, Evangelos Pournaras)</author>
      <guid isPermaLink="false">2502.05954v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Discovery of skill switching criteria for learning agile quadruped locomotion</title>
      <link>http://arxiv.org/abs/2502.06676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一种分层学习和优化框架，用于实现多种技能的协调运动。&lt;h4&gt;背景&lt;/h4&gt;现有的多技能行走策略往往需要人为设定规则来切换不同的步行模式，并且在遇到意外失败时恢复能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够自动自然地进行不同技能间转换并在遭遇故障后迅速恢复的学习和优化框架，适用于追踪任意位置目标的场景。&lt;h4&gt;方法&lt;/h4&gt;{'包含接触模式': '将接触模式整合到奖励项中以学习不同类型的步伐作为独立策略，无需其他参考。', '高层政策生成': '通过深度强化学习过程与优化过程组合来学习高层策略，该策略能够为个体策略生成权重并组合成多技能运动。', '自然切换规则': '根据目标距离自动调整和自然转换技能，并在奖励计算中包含适当的切换距离以适应高阶策略的学习，并通过外层优化循环更新这些距离。', '实验验证': '首先在一个模拟的Unitree A1四足机器人上展示了全面任务中的多技能行走能力，随后将学习到的策略应用于现实世界场景，包括小跑步、跳跃和全速奔跑等动作及其自然过渡。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架能够成功地在广泛的运动技能中进行平滑且连续的转换，而不需要人为设定规则来切换不同的步行模式。&lt;h4&gt;结论&lt;/h4&gt;相较于离散单技能之间的切换（如未能在现实中从慢跑直接过渡到全速奔跑），该方法实现了所有学习到的敏捷技能，并展示了更流畅、连续的技能转换能力。&lt;h4&gt;翻译&lt;/h4&gt;本文开发了一种分层学习和优化框架，可以学习并实现协调良好的多技能步行。所学的多技能策略可以在追踪任意位置的目标时自动且自然地在不同的技能之间进行切换，并能迅速从故障中恢复过来。提出的框架由深度强化学习过程和一个优化过程组成。首先将接触模式整合到奖励项中以分别学习不同类型的步伐作为独立策略，无需其他参考。接着通过一个高级别的政策来生成个体策略的权重，以便在追踪目标的任务设置中组合多技能步行。技能会根据到目标的距离自动且自然地切换，而适当的切换距离则被包含在高阶策略的学习奖励计算中，并由外部优化循环更新。首先，在模拟的Unitree A1四足机器人上证明了成功实现多技能运动的能力。然后在现实世界场景部署学习到的政策，展示了包括慢跑、跳跃和全速奔跑在内的多种步行模式及其自然过渡能力。此外，所学策略能够及时应对意外故障，进行快速恢复，并重新开始行走任务。相比于离散切换单一技能（未能从现实中转换至全速奔跑），所提出的方法实现了所有学习到的敏捷技能，且具有更平滑和连续的技能转换特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper develops a hierarchical learning and optimization framework thatcan learn and achieve well-coordinated multi-skill locomotion. The learnedmulti-skill policy can switch between skills automatically and naturally intracking arbitrarily positioned goals and recover from failures promptly. Theproposed framework is composed of a deep reinforcement learning process and anoptimization process. First, the contact pattern is incorporated into thereward terms for learning different types of gaits as separate policies withoutthe need for any other references. Then, a higher level policy is learned togenerate weights for individual policies to compose multi-skill locomotion in agoal-tracking task setting. Skills are automatically and naturally switchedaccording to the distance to the goal. The proper distances for skill switchingare incorporated in reward calculation for learning the high level policy andupdated by an outer optimization loop as learning progresses. We firstdemonstrated successful multi-skill locomotion in comprehensive tasks on asimulated Unitree A1 quadruped robot. We also deployed the learned policy inthe real world showcasing trotting, bounding, galloping, and their naturaltransitions as the goal position changes. Moreover, the learned policy canreact to unexpected failures at any time, perform prompt recovery, and resumelocomotion successfully. Compared to discrete switch between single skillswhich failed to transition to galloping in the real world, our proposedapproach achieves all the learned agile skills, with smoother and morecontinuous skill transitions.</description>
      <author>example@mail.com (Wanming Yu, Fernando Acero, Vassil Atanassov, Chuanyu Yang, Ioannis Havoutis, Dimitrios Kanoulas, Zhibin Li)</author>
      <guid isPermaLink="false">2502.06676v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Red Teaming: Breaking Policies Without Breaking Robots</title>
      <link>http://arxiv.org/abs/2502.06575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的问题：预测性红队策略，用于在非正常场景中评估和预测视觉运动策略的性能下降。作者开发了RoboART系统，使用生成式图像编辑技术修改常规观察，并用特定于政策的异常检测器来预测各种环境变化下的性能。&lt;h4&gt;背景&lt;/h4&gt;基于模仿学习训练出的视动策略能够执行复杂的操作任务，但在不同的光照、视觉干扰和物体位置等环境下表现出极高的脆弱性。这种脆弱性的表现方式难以预料且需要昂贵和耗时的实际硬件评估才能发现。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化红队策略（ART）管道RoboART，用于在不进行实际硬件测试的情况下预测特定策略的性能下降，并基于这些预测指导目标数据收集。&lt;h4&gt;方法&lt;/h4&gt;通过使用生成式图像编辑技术修改常规观察来改变不同的环境因素，并利用特定于政策的异常检测器根据修改后的观测值预测每种情况下的表现。此外，该系统还展示了如何在条件不利时进行有针对性的数据采集以改善基线性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在500多个硬件测试中以及12个不同的非正常条件下，RoboART能够准确地预测视觉运动策略的性能下降（真实成功率与预测之间的平均差异小于0.19）。此外，通过在条件不佳的情况下有针对性的数据收集进行微调后，基线性能得到了2-7倍的提升。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种自动化评估和提高机器学习模型鲁棒性的有效方法，并且展示了如何通过这种方法改进现有系统的实际性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor policies trained via imitation learning are capable of performingchallenging manipulation tasks, but are often extremely brittle to lighting,visual distractors, and object locations. These vulnerabilities can dependunpredictably on the specifics of training, and are challenging to exposewithout time-consuming and expensive hardware evaluations. We propose theproblem of predictive red teaming: discovering vulnerabilities of a policy withrespect to environmental factors, and predicting the corresponding performancedegradation without hardware evaluations in off-nominal scenarios. In order toachieve this, we develop RoboART: an automated red teaming (ART) pipeline that(1) modifies nominal observations using generative image editing to varydifferent environmental factors, and (2) predicts performance under eachvariation using a policy-specific anomaly detector executed on editedobservations. Experiments across 500+ hardware trials in twelve off-nominalconditions for visuomotor diffusion policies demonstrate that RoboART predictsperformance degradation with high accuracy (less than 0.19 average differencebetween predicted and real success rates). We also demonstrate how predictivered teaming enables targeted data collection: fine-tuning with data collectedunder conditions predicted to be adverse boosts baseline performance by 2-7x.</description>
      <author>example@mail.com (Anirudha Majumdar, Mohit Sharma, Dmitry Kalashnikov, Sumeet Singh, Pierre Sermanet, Vikas Sindhwani)</author>
      <guid isPermaLink="false">2502.06575v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SIREN: Semantic, Initialization-Free Registration of Multi-Robot Gaussian Splatting Maps</title>
      <link>http://arxiv.org/abs/2502.06519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了用于多机器人高斯点云地图（GSplat）注册的SIREN方法，无需使用相机姿态、图像或初始子图转换进行初始化或融合。&lt;h4&gt;背景&lt;/h4&gt;现有的多机器人地图融合技术通常依赖于精确的相机位置信息和图像数据作为初始化步骤的一部分。然而，在缺乏这些先决条件的情况下，实现有效的地图融合是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;通过利用语义信息来增强GSplat地图注册过程的能力，以提高地图融合的质量和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;{'第一点': 'SIREN使用语义识别特征丰富的本地地图区域，在这些地方可以更好地解决问题，不需要任何初始化。这克服了之前工作中通常需要的初始步骤的问题。', '第二点': 'SIREN通过使用稳健的语义特征来确定局部地图中高斯分布之间的候选对应关系，从而建立了稳健几何优化的基础，并粗略对齐3D高斯元从局部地图中提取出的数据。', '第三点': '利用新视角合成和基于语义的图像滤波器计算子图之间具有较高精度的非刚性变换，实现后续光度校准。该步骤使生成高保真的融合地图成为可能。'}&lt;h4&gt;主要发现&lt;/h4&gt;SIREN方法在真实世界数据集上优于竞争基线，在包括机械臂、无人机和四足机器人在内的广泛使用的机器人硬件平台上表现突出。&lt;h4&gt;结论&lt;/h4&gt;实验表明，与现有方法相比，特别是在最具挑战性的场景中，SIREN能够显著减少旋转误差（约90倍）、平移误差（约300倍）和缩放误差（约44倍）。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种用于在多机器人环境中融合GSplat地图的新技术——SIREN。这种方法利用语义信息来实现无需相机姿态、图像等先验知识的地图注册，展示了比现有方法更好的性能，并将在评审结束后公开源代码和项目页面链接。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SIREN for registration of multi-robot Gaussian Splatting (GSplat)maps, with zero access to camera poses, images, and inter-map transforms forinitialization or fusion of local submaps. To realize these capabilities, SIRENharnesses the versatility and robustness of semantics in three critical ways toderive a rigorous registration pipeline for multi-robot GSplat maps. First,SIREN utilizes semantics to identify feature-rich regions of the local mapswhere the registration problem is better posed, eliminating the need for anyinitialization which is generally required in prior work. Second, SIRENidentifies candidate correspondences between Gaussians in the local maps usingrobust semantic features, constituting the foundation for robust geometricoptimization, coarsely aligning 3D Gaussian primitives extracted from the localmaps. Third, this key step enables subsequent photometric refinement of thetransformation between the submaps, where SIREN leverages novel-view synthesisin GSplat maps along with a semantics-based image filter to compute ahigh-accuracy non-rigid transformation for the generation of a high-fidelityfused map. We demonstrate the superior performance of SIREN compared tocompeting baselines across a range of real-world datasets, and in particular,across the most widely-used robot hardware platforms, including a manipulator,drone, and quadruped. In our experiments, SIREN achieves about 90x smallerrotation errors, 300x smaller translation errors, and 44x smaller scale errorsin the most challenging scenes, where competing methods struggle. We willrelease the code and provide a link to the project page after the reviewprocess.</description>
      <author>example@mail.com (Ola Shorinwa, Jiankai Sun, Mac Schwager, Anirudha Majumdar)</author>
      <guid isPermaLink="false">2502.06519v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Inflatable Kirigami Crawlers</title>
      <link>http://arxiv.org/abs/2502.06466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了通过在热密封纺织品中引入折纸图案，创造出的充气式折纸爬行器。这种设计利用了切割模式来指导形态变化，使得充气后能产生非对称变形并触发局部旋转。&lt;h4&gt;背景&lt;/h4&gt;传统的空气囊膨胀时会形成对称的凸起和收缩。这项工作通过引入折叠与剪切图案（kirigami）解决了这一局限性。&lt;h4&gt;目的&lt;/h4&gt;创造一种新的充气式爬行器，利用折纸技术实现非对称变形并增强压缩能力。&lt;h4&gt;方法&lt;/h4&gt;在热密封纺织品上设计特殊的切割模式，并研究其膨胀时的非线性和几何特性。通过实验测试了这种结构在摩擦力和运动方向上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;充气式kirigami驱动器展示了一致且受控的收缩，伴随着不对称的局部变形；并且显示出对不同粗糙度表面的方向性摩擦属性。&lt;h4&gt;结论&lt;/h4&gt;引入多个通道和分段的设计增强了这些软体机器人的功能性，使其具有多样化的移动能力。这项研究证明了通过几何设计可以实现预测性的行走功能。&lt;h4&gt;翻译&lt;/h4&gt;折纸技术提供了一种通过利用切割模式的几何特性来引导形态变化的独特机会。本文介绍了一种可充气式折纸爬行器的设计方法，它在热密封纺织品中引入特定的切割图案，以实现在周期性气动驱动下的运动功能。传统气囊膨胀时会产生对称性的膨胀和收缩，而这种新的设计通过积累压缩力打破了这一对称性，提高了压缩比，并且当封闭边缘重叠自组装成一个具有新尺度特征的结构时，还会触发局部旋转动作。这使得充气式折纸驱动器能够表现出一致、受控的收缩以及不对称的离面变形现象。研究通过利用几何和材料非线性的特点赋予了基于纺织品的可充气式折纸驱动器可预测的行走功能，并详细描述了这些驱动器编程变形的特性和它们对摩擦力的影响，发现当被膨胀时，这种折叠结构展现出方向性异质摩擦特性：在运动方向上的摩擦系数更高，从而能够适应不同粗糙度表面的移动。此外，通过增加多个气道和分段设计进一步提升了充气式折纸驱动器的功能，创造了具有多种行走能力的软体机器人原型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kirigami offers unique opportunities for guided morphing by leveraging thegeometry of the cuts. This work presents inflatable kirigami crawlers createdby introducing cut patterns into heat-sealable textiles to achieve locomotionupon cyclic pneumatic actuation. Inflating traditional air pouches results insymmetric bulging and contraction. In inflated kirigami actuators, theaccumulated compressive forces uniformly break the symmetry, enhancecontraction compared to simple air pouches by two folds, and trigger localrotation of the sealed edges that overlap and self-assemble into an architectedsurface with emerging scale-like features. As a result, the inflatable kirigamiactuators exhibit a uniform, controlled contraction with asymmetric localizedout-of-plane deformations. This process allows us to harness the geometric andmaterial nonlinearities to imbue inflatable textile-based kirigami actuatorswith predictable locomotive functionalities. We thoroughly characterized theprogrammed deformations of these actuators and their impact on friction. Wefound that the kirigami actuators exhibit directional anisotropic frictionproperties when inflated, having higher friction coefficients against thedirection of the movement, enabling them to move across surfaces with varyingroughness. We further enhanced the functionality of inflatable kirigamiactuators by introducing multiple channels and segments to create functionalsoft robotic prototypes with versatile locomotion capabilities.</description>
      <author>example@mail.com (Burcu Seyidoğlu, Aida Parvaresh, Bahman Taherkhani, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06466v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding</title>
      <link>http://arxiv.org/abs/2502.06440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the 2025 IEEE International Conference  on Robotics and Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于纱夫理论的去中心化深度强化学习框架，旨在解决多智能体路径规划问题中的合作决策难题。&lt;h4&gt;背景&lt;/h4&gt;在已知环境下的多智能体路径规划（MAPF）问题是机器人大规模物流和运输部署的核心挑战。现有基于学习的方法依赖于有限视野下做出的短视决策，导致复杂场景中效率低下且难以实现有效协作。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过应用纱夫理论来促进分散式深度强化学习中的智能体之间的几何交叉依赖性学习，并进行紧密合作性的决策制定。&lt;h4&gt;方法&lt;/h4&gt;利用纱夫理论提供的局部观察达成全局共识的数学条件，论文将神经网络应用于近似模型中以在潜在空间内基于纱夫理论建模共识，并通过自我监督学习对其进行训练。在此过程中，除了正常的MAPF特征外，每个智能体还分布式地考虑了一种学习到的共识特性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在大规模且复杂的情境下显示出相对于现有最佳学习型MAPF规划器的重大改进，表现出了其优越性。&lt;h4&gt;结论&lt;/h4&gt;提出的基于纱夫理论的新框架能够有效提升多智能体路径规划问题中智能体之间的合作效率和全局共识达成能力，在各种模拟实验与真实世界机器人实验中均展现了卓越性能。&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要讨论了一种新的解决MAPF问题的方法，采用去中心化的深度强化学习框架，并利用纱夫理论来改进智能体间的协作机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Multi-Agent Path Finding (MAPF) problem aims to determine the shortestand collision-free paths for multiple agents in a known, potentiallyobstacle-ridden environment. It is the core challenge for robotic deploymentsin large-scale logistics and transportation. Decentralized learning-basedapproaches have shown great potential for addressing the MAPF problems,offering more reactive and scalable solutions. However, existing learning-basedMAPF methods usually rely on agents making decisions based on a limited fieldof view (FOV), resulting in short-sighted policies and inefficient cooperationin complex scenarios. There, a critical challenge is to achieve consensus onpotential movements between agents based on limited observations andcommunications. To tackle this challenge, we introduce a new framework thatapplies sheaf theory to decentralized deep reinforcement learning, enablingagents to learn geometric cross-dependencies between each other through localconsensus and utilize them for tightly cooperative decision-making. Inparticular, sheaf theory provides a mathematical proof of conditions forachieving global consensus through local observation. Inspired by this, weincorporate a neural network to approximately model the consensus in latentspace based on sheaf theory and train it through self-supervised learning.During the task, in addition to normal features for MAPF as in previous works,each agent distributedly reasons about a learned consensus feature, leading toefficient cooperation on pathfinding and collision avoidance. As a result, ourproposed method demonstrates significant improvements over state-of-the-artlearning-based MAPF planners, especially in relatively large and complexscenarios, demonstrating its superiority over baselines in various simulationsand real-world robot experiments.</description>
      <author>example@mail.com (Shuhao Liao, Weihang Xia, Yuhong Cao, Weiheng Dai, Chengyang He, Wenjun Wu, Guillaume Sartoretti)</author>
      <guid isPermaLink="false">2502.06440v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large Language Models</title>
      <link>http://arxiv.org/abs/2502.06419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE International Conference on Robotics and  Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了基于占用的大型语言模型(Occ-LLM)，这是将大型语言模型与重要表示方式集成的第一个尝试。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在机器人和自动驾驶领域取得了显著进展。然而，如何有效地利用这些模型处理动态场景中的物体是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过开发一种新的方法来解决这个问题，并展示这种创新方法在关键任务上的有效性。&lt;h4&gt;方法&lt;/h4&gt;{'Motion Separation Variational Autoencoder (MS-VAE)': '为了解决输入中动态对象和静态背景的分类不平衡问题，研究提出了一种基于先验知识的方法，可以区分移动物体与静止场景，并利用定制化的变分自编码器进行有效的信息处理。', 'Occ-LLM': '该方法通过将占用情况作为大型语言模型的有效输入来提高模型在动态轨迹识别和静态背景重建方面的性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;研究证明了Occ-LLM在4D占用预测、自我规划和基于占用的场景问答等关键任务上的有效性，其性能优于现有的最佳方法，在交并比(IoU)和平均交并比(mIoU)上分别提高了约6%和4%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明Occ-LLM具有变革性潜力，能够重塑机器人和自动驾驶领域的现有范式。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在机器人技术和自主驾驶领域取得了显著进步。这项研究首次提出了一种基于占用的大型语言模型(Occ-LLM)，这是将大型语言模型与重要表示方式集成的第一个尝试。为有效地将占用情况作为输入传递给大型语言模型并解决与之相关的分类不平衡问题，我们提出了运动分离变分自编码器(MS-VAE)。这种方法利用先验知识在将数据输入定制化变分自编码器之前区分动态对象和静态场景。这种分割增强了模型集中于动态轨迹的同时有效地重建静态场景的能力。Occ-LLM的有效性已经在包括4D占用预测、自我规划和基于占用的场景问答在内的关键任务上得到了验证。全面评估表明，Occ-LLM显著超越了现有最先进方法，在4D占用预测任务中分别实现了约6%交并比(IoU)和4%平均交并比(mIoU)的增长。这些发现强调了Occ-LLM在重塑机器人技术与自主驾驶领域当前范式方面的变革潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have made substantial advancements in the fieldof robotic and autonomous driving. This study presents the firstOccupancy-based Large Language Model (Occ-LLM), which represents a pioneeringeffort to integrate LLMs with an important representation. To effectivelyencode occupancy as input for the LLM and address the category imbalancesassociated with occupancy, we propose Motion Separation Variational Autoencoder(MS-VAE). This innovative approach utilizes prior knowledge to distinguishdynamic objects from static scenes before inputting them into a tailoredVariational Autoencoder (VAE). This separation enhances the model's capacity toconcentrate on dynamic trajectories while effectively reconstructing staticscenes. The efficacy of Occ-LLM has been validated across key tasks, including4D occupancy forecasting, self-ego planning, and occupancy-based scene questionanswering. Comprehensive evaluations demonstrate that Occ-LLM significantlysurpasses existing state-of-the-art methodologies, achieving gains of about 6\%in Intersection over Union (IoU) and 4\% in mean Intersection over Union (mIoU)for the task of 4D occupancy forecasting. These findings highlight thetransformative potential of Occ-LLM in reshaping current paradigms withinrobotic and autonomous driving.</description>
      <author>example@mail.com (Tianshuo Xu, Hao Lu, Xu Yan, Yingjie Cai, Bingbing Liu, Yingcong Chen)</author>
      <guid isPermaLink="false">2502.06419v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>An Automated Machine Learning Framework for Surgical Suturing Action Detection under Class Imbalance</title>
      <link>http://arxiv.org/abs/2502.06407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于自动化机器学习的方法，用于腹腔镜手术训练中的实时手术动作检测，并提供了可解释的输出。&lt;h4&gt;背景&lt;/h4&gt;在腹腔镜手术培训和评估中，实时检测外科操作及其可解释性对于自动化的即时反馈和技能发展至关重要。这需要能够处理不同技术水平外科医生的数据不平衡问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种快速部署的方法来实现基于机器学习技术的手术动作识别系统，该方法可以提供实时、可靠的反馈并促进技能培训。&lt;h4&gt;方法&lt;/h4&gt;使用自动化机器学习方法，通过收集经验丰富和培训中的外科医生的操作数据进行分析。该方法部分地考虑了模型透明度的需求，以满足医疗应用中可靠性的要求。&lt;h4&gt;主要发现&lt;/h4&gt;与深度学习方法相比，传统机器学习模型不仅有助于高效快速部署，并且在解释性方面具有明显优势。实验结果表明这种方法有潜力提供实时手术训练环境中的快速、可靠的检测。&lt;h4&gt;结论&lt;/h4&gt;通过自动化机器学习的方法，可以实现腹腔镜手术训练中准确的实时动作识别，同时保持良好的可解释性和预测稳定性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在腹腔镜外科手术培训和评估过程中，实时检测外科操作并提供可解释性输出对于自动化的即时反馈和技能发展至关重要。这种能力将能够推动机器引导的培训系统的开发。本文提出了一种快速部署方法，该方法基于从经验丰富的外科医生和受训人员处收集的外科动作数据，并利用自动化机器学习技术。所提出的这种方法有效地解决了高度不平衡类别分布的问题，确保了在不同水平外科医生中的稳健预测。此外，我们的方法部分地包含了模型透明度，满足了医疗应用中的可靠性要求。与深度学习的方法相比，传统的机器学习模型不仅促进了高效的快速部署，还提供了显著的解释性优势。通过实验，本研究展示了该方法具有提供手术训练环境中的即时、可靠和有效检测的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In laparoscopy surgical training and evaluation, real-time detection ofsurgical actions with interpretable outputs is crucial for automated andreal-time instructional feedback and skill development. Such capability wouldenable development of machine guided training systems. This paper presents arapid deployment approach utilizing automated machine learning methods, basedon surgical action data collected from both experienced and trainee surgeons.The proposed approach effectively tackles the challenge of highly imbalancedclass distributions, ensuring robust predictions across varying skill levels ofsurgeons. Additionally, our method partially incorporates model transparency,addressing the reliability requirements in medical applications. Compared todeep learning approaches, traditional machine learning models not onlyfacilitate efficient rapid deployment but also offer significant advantages ininterpretability. Through experiments, this study demonstrates the potential ofthis approach to provide quick, reliable and effective real-time detection insurgical training environments</description>
      <author>example@mail.com (Baobing Zhang, Paul Sullivan, Benjie Tang, Ghulam Nabi, Mustafa Suphi Erden)</author>
      <guid isPermaLink="false">2502.06407v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs</title>
      <link>http://arxiv.org/abs/2502.06390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了针对Vision-Language Models (VLMs)的攻击策略，按照目标将这些攻击分为越狱、伪装和利用三类，并详细介绍了数据操纵的方法。同时概述了相应的防御机制以减轻脆弱性。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型（VLMs）因其能够有效整合和处理文本与图像信息而在近年来得到了广泛应用，并且显著提高了场景感知和机器人等领域的性能。但这些应用也带来了安全和隐私方面的重要问题，需要深入研究来评估潜在的漏洞。&lt;h4&gt;目的&lt;/h4&gt;系统地调查针对VLM系统的攻击策略及其防御措施，并提出一个有力的分类体系以更好地理解不同类型的攻击之间的联系与区别&lt;h4&gt;方法&lt;/h4&gt;对现有文献进行总结性分析，根据不同的攻击目标将攻击方式分类为越狱、伪装和利用三类。同时详细描述了各种用于操纵VLM数据的方法。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的针对视觉语言模型（VLMs）的攻击分类法，并且概述了一系列评价指标来全面地刻画不同类型的攻击在VLM中的特征和影响&lt;h4&gt;结论&lt;/h4&gt;展望未来的研究方向，强调持续探索以进一步增强VLM的安全性和鲁棒性的重要性。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言模型由于其出色的能力整合并处理文本与图像信息，在最近几年中获得了极大的关注。这种能力的融合显著提升了多种应用领域的表现，比如场景理解和机器人技术。然而，部署这些模型也带来了重要的安全和隐私问题，需要进行广泛的研究来评估它们潜在的安全漏洞。在这项工作中，我们提供了一种深入的针对VLM系统的攻击策略综述。基于不同的目标将这些攻击分为“越狱”、“伪装”和“利用”，同时详细描述了用于数据操纵的各种方法。此外还概述了一些被提出的防御机制，以减轻这些脆弱性带来的影响。通过辨别各种类型的攻击之间的重要关联与差异，我们提出了一个有力的分类体系来总结VLM系统的安全威胁。另外也概括了一套评价指标，全面地刻画不同类型的攻击在视觉语言模型中的特征和潜在影响。最后讨论了未来可能的研究方向以进一步提高VLM的安全性和鲁棒性，并强调这一研究领域的持续重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have gained considerable prominence in recentyears due to their remarkable capability to effectively integrate and processboth textual and visual information. This integration has significantlyenhanced performance across a diverse spectrum of applications, such as sceneperception and robotics. However, the deployment of VLMs has also given rise tocritical safety and security concerns, necessitating extensive research toassess the potential vulnerabilities these VLM systems may harbor. In thiswork, we present an in-depth survey of the attack strategies tailored for VLMs.We categorize these attacks based on their underlying objectives - namelyjailbreak, camouflage, and exploitation - while also detailing the variousmethodologies employed for data manipulation of VLMs. Meanwhile, we outlinecorresponding defense mechanisms that have been proposed to mitigate thesevulnerabilities. By discerning key connections and distinctions among thediverse types of attacks, we propose a compelling taxonomy for VLM attacks.Moreover, we summarize the evaluation metrics that comprehensively describe thecharacteristics and impact of different attacks on VLMs. Finally, we concludewith a discussion of promising future research directions that could furtherenhance the robustness and safety of VLMs, emphasizing the importance ofongoing exploration in this critical area of study. To facilitate communityengagement, we maintain an up-to-date project page, accessible at:https://github.com/AobtDai/VLM_Attack_Paper_List.</description>
      <author>example@mail.com (Aobotao Dai, Xinyu Ma, Lei Chen, Songze Li, Lin Wang)</author>
      <guid isPermaLink="false">2502.06390v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Proprioceptive Origami Manipulator</title>
      <link>http://arxiv.org/abs/2502.06362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型的自感式腱驱动折纸操作器，该操作器通过使用导电线作为执行机构，并将其与本体感觉传感功能多路复用，以实现对连续管状结构的良好控制。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉系统的柔性机械臂在复杂和杂乱环境中的应用受到限制。为了克服这一局限性，研究人员开始探索一种无需外部传感器的帮助就能精确感知自身状态的方案。&lt;h4&gt;目的&lt;/h4&gt;开发出一个具有本体感觉能力的折纸操作器，旨在为连续管状结构提供闭合回路控制的基础，并保留其固有的灵活性。&lt;h4&gt;方法&lt;/h4&gt;使用导电线作为执行机构和传感器。通过测量导电线长度变化引起的电阻变化来实现对操纵器姿态的感知。该信息被输入到前向动力学模型中，以重建操作器配置和末端效应器位置。&lt;h4&gt;主要发现&lt;/h4&gt;将导电丝用作既可驱动又可感知的手动肌腱，并将其应用于管状折纸结构作为连续性机械臂的原型设计，通过电阻变化来实现对其状态的有效监控。&lt;h4&gt;结论&lt;/h4&gt;这种新型的操作方式不仅为复杂环境下的机器人操作提供了新的可能性，同时也展示了如何在保证灵活性的同时提高对软体机器人的控制精度。&lt;h4&gt;翻译&lt;/h4&gt;折纸提供了一个多功能框架，用于设计可变结构和软机器人，通过利用折叠的几何形状。管状折纸结构可以充当连续操纵器，平衡柔韧性和强度。然而，精确控制这种操作器通常需要依赖基于视觉的系统，这限制了它们在复杂且杂乱环境中的应用。在这里，我们提出了一种本体感觉腱驱动折纸操作器，无需牺牲其灵活性。使用导电线作为执行机构，我们将它们与本体感知传感功能多路复用。活化长度的变化在线的有效电阻中反映出来，可以简单电路测量。我们把这种变化的电阻与肌腱长度相关联。输入此信息到前向动力学模型来重建操作器配置和末端效应器位置。这个平台为连续折纸操纵器的闭合回路控制提供了基础，并保留了其固有的灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Origami offers a versatile framework for designing morphable structures andsoft robots by exploiting the geometry of folds. Tubular origami structures canact as continuum manipulators that balance flexibility and strength. However,precise control of such manipulators often requires reliance on vision-basedsystems that limit their application in complex and cluttered environments.Here, we propose a proprioceptive tendon-driven origami manipulator withoutcompromising its flexibility. Using conductive threads as actuating tendons, wemultiplex them with proprioceptive sensing capabilities. The change in theactive length of the tendons is reflected in their effective resistance, whichcan be measured with a simple circuit. We correlated the change in theresistance to the lengths of the tendons. We input this information into aforward kinematic model to reconstruct the manipulator configuration andend-effector position. This platform provides a foundation for the closed-loopcontrol of continuum origami manipulators while preserving their inherentflexibility.</description>
      <author>example@mail.com (Aida Parvaresh, Arman Goshtasbi, Jonathan Andres Tirado Rosero, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06362v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>DATCloud: A Model-Driven Framework for Multi-Layered Data-Intensive Architectures</title>
      <link>http://arxiv.org/abs/2501.18257v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DATCloud是一个框架，用于多层架构的建模、验证和改进，旨在解决数据密集型系统的需求。&lt;h4&gt;背景&lt;/h4&gt;复杂的数据密集型系统的灵活性、可扩展性和效率要求促使了像DATCloud这样的模型驱动框架的发展。&lt;h4&gt;目的&lt;/h4&gt;通过遵循ISO/IEC/IEEE 42010标准，DATCloud利用结构化和行为元模型以及特定领域的图形语言（DSL）来增强重用性和利益相关者之间的沟通。&lt;h4&gt;方法&lt;/h4&gt;DATCloud采用模型驱动的方法，并使用结构化和行为元模型及特定领域的图形语言进行架构设计。&lt;h4&gt;主要发现&lt;/h4&gt;在Uffizi画廊的VASARI系统中的初步验证显示，与手动方法相比，建模时间减少了40%，灵活性提高了32%。&lt;h4&gt;结论&lt;/h4&gt;虽然DATCloud已经展示了其有效性，但它仍是一个正在进行的工作，在未来将计划集成先进的代码生成工具、仿真工具和特定领域的扩展功能来进一步增强其实用性。&lt;h4&gt;翻译&lt;/h4&gt;多层数据密集型系统的复杂性要求确保灵活性、可扩展性和效率的框架。DATCloud是一种模型驱动框架，旨在促进多层架构的建模、验证和改进，解决可扩展性、模块化及现实世界需求的问题。通过遵循ISO/IEC/IEEE 42010标准，DATCloud利用结构和行为元模型以及图形特定领域语言（DSL）来提高重用性和利益相关者之间的沟通。初步在Uffizi画廊的VASARI系统中的验证表明，与手动方法相比，建模时间减少了40%，灵活性提高了32%。尽管有效，但DATCloud仍是一个正在进行的工作，在未来计划集成先进的代码生成工具、仿真工具和特定领域的扩展功能，以进一步增强其在医疗保健、智慧城市和其他数据密集型领域应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity of multi-layered, data-intensive systems demands frameworksthat ensure flexibility, scalability, and efficiency. DATCloud is amodel-driven framework designed to facilitate the modeling, validation, andrefinement of multi-layered architectures, addressing scalability, modularity,and real-world requirements. By adhering to ISO/IEC/IEEE 42010 standards,DATCloud leverages structural and behavioral meta-models and graphicaldomain-specific languages (DSLs) to enhance reusability and stakeholdercommunication. Initial validation through the VASARI system at the UffiziGallery demonstrates a 40% reduction in modeling time and a 32% improvement inflexibility compared to manual methods. While effective, DATCloud is a work inprogress, with plans to integrate advanced code generation, simulation tools,and domain-specific extensions to further enhance its capabilities forapplications in healthcare, smart cities, and other data-intensive domains.</description>
      <author>example@mail.com (Moamin Abughazala, Henry Muccini)</author>
      <guid isPermaLink="false">2501.18257v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Weld n'Cut: Automated fabrication of inflatable fabric actuators</title>
      <link>http://arxiv.org/abs/2502.06361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于制造纺织基轻质耐用充气软执行器的自动化平台Weld n'Cut，该平台结合了超声波焊接和振荡刀具技术。&lt;h4&gt;背景&lt;/h4&gt;现有的纺织品基充气软执行器在康复机器人和个人性能增强设备中广泛使用。然而，这些执行器的制造过程通常涉及多步且容易出错。&lt;h4&gt;目的&lt;/h4&gt;为了提高充气软执行器的生产精度和性能，引入了一种自动化制造流程Weld n'Cut平台。&lt;h4&gt;方法&lt;/h4&gt;该平台采用超声波焊接技术将纺织层融合在一起，并使用振荡刀具进行精确切割。这样可以创建具有任意复杂几何形状的充气结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，无论材料和设计如何，该制造流程都能有效地生产复杂的充气软执行器。&lt;h4&gt;结论&lt;/h4&gt;Weld n'Cut平台提供了一种准确、高效的自动化方法来制造复杂的纺织基充气软执行器。&lt;h4&gt;翻译&lt;/h4&gt;轻质耐用的基于纺织品的可充气软执行器在软机器人领域，特别是在康复辅助和提高高要求工作的人类性能方面得到广泛应用。这些执行器的传统制造过程通常包括多个步骤：使用热压机将热熔性织物层融合在一起，并用防粘隔离层定义内部腔室。这些隔离层必须在制造后小心去除，这使得过程既耗时又容易出错。为了解决这些问题并提高可充气执行器的精度和性能，我们引入了Weld n'Cut平台——一个开源、自动化制造流程，结合了超声波焊接技术用于融合纺织层，并使用振荡刀具进行精确切割，从而能够创造出具有复杂几何形状的充气结构。我们在各种材料和设计中展示了该机器的表现力及其处理任意复杂几何形状的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lightweight, durable textile-based inflatable soft actuators are widely usedin soft robotics, particularly for wearable robots in rehabilitation and inenhancing human performance in demanding jobs. Fabricating these actuatorstypically involves multiple steps: heat-sealable fabrics are fused with a heatpress, and non-stick masking layers define internal chambers. These layers mustbe carefully removed post-fabrication, often making the process labor-intensiveand prone to errors. To address these challenges and improve the accuracy andperformance of inflatable actuators, we introduce the Weld n'Cut platform-anopen-source, automated manufacturing process that combines ultrasonic weldingfor fusing textile layers with an oscillating knife for precise cuts, enablingthe creation of complex inflatable structures. We demonstrate the machine'sperformance across various materials and designs with arbitrarily complexgeometries.</description>
      <author>example@mail.com (Arman Goshtasbi, Burcu Seyidoğlu, Saravana Prashanth Murali Babu, Aida Parvaresh, Cao Danh Do, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06361v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-Aware Contingency Safety-Critical Planning for Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2502.06359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种针对动态和遮挡环境下的自动驾驶车辆实时安全规划的新方法。&lt;h4&gt;背景&lt;/h4&gt;在动态且被遮挡的环境中，确保自动驾驶汽车的安全驾驶同时保持出行效率是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一个基于风险评估的可实现性分析的方法，该方法能够计算出被遮挡车辆的速度边界，并将其整合到非线性规划框架中，以实现实时安全路径生成。&lt;h4&gt;方法&lt;/h4&gt;通过可达性分析进行风险评估，计算被遮挡车辆的前进可达集来量化动态速度界限。这些速度界限被纳入双凸非线性编程（NLP）形式化过程中，以便在退步时间窗口规划框架内同时优化探索和回退路径。为了促进实时优化并确保轨迹之间的协调，采用共识交替方向乘子法（ADMM）将双凸NLP问题分解为低维凸子问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究和现实世界实验验证了所提出方法的有效性，在被遮挡的交叉路口下展示了增强的安全性和提高的出行效率，能够在不同障碍物条件下实现实时安全路径生成。&lt;h4&gt;结论&lt;/h4&gt;该方法在动态遮挡环境中能够有效提升自动驾驶车辆的安全性能并改善其出行效率。&lt;h4&gt;翻译&lt;/h4&gt;确保自主驾驶车辆在动态且被遮挡的环境中的安全行驶同时保持旅行效率是一项关键挑战。本文提出了一种实时感知遮挡情况下的应急安全规划策略，利用可达性分析进行风险评估，并计算出遮挡物的速度边界以优化路径决策。通过实验验证了该方法的有效性和实用性，在保证安全性的同时提升了出行效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safe driving while maintaining travel efficiency for autonomousvehicles in dynamic and occluded environments is a critical challenge. Thispaper proposes an occlusion-aware contingency safety-critical planning approachfor real-time autonomous driving in such environments. Leveraging reachabilityanalysis for risk assessment, forward reachable sets of occluded phantomvehicles are computed to quantify dynamic velocity boundaries. These velocityboundaries are incorporated into a biconvex nonlinear programming (NLP)formulation, enabling simultaneous optimization of exploration and fallbacktrajectories within a receding horizon planning framework. To facilitatereal-time optimization and ensure coordination between trajectories, we employthe consensus alternating direction method of multipliers (ADMM) to decomposethe biconvex NLP problem into low-dimensional convex subproblems. Theeffectiveness of the proposed approach is validated through simulation studiesand real-world experiments in occluded intersections. Experimental resultsdemonstrate enhanced safety and improved travel efficiency, enabling real-timesafe trajectory generation in dynamic occluded intersections under varyingobstacle conditions. A video showcasing the experimental results is availableat https://youtu.be/CHayG7NChqM.</description>
      <author>example@mail.com (Lei Zheng, Rui Yang, Minzhe Zheng, Zengqi Peng, Michael Yu Wang, Jun Ma)</author>
      <guid isPermaLink="false">2502.06359v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Outlier-robust Rotation Estimation by Stereographic Projection</title>
      <link>http://arxiv.org/abs/2502.06337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;旋转估计在计算机视觉和机器人任务中起着基础性作用，但面对大量包含众多异常值（即不匹配）和噪声的数据集时，高效地进行旋转估计是一大挑战。本文提出了一种有效且鲁棒的旋转估计算法。&lt;h4&gt;背景&lt;/h4&gt;当前许多针对这一问题设计的方法由于计算时间长及陷入局部最优的风险而难以实际应用。&lt;h4&gt;目的&lt;/h4&gt;研发一种能够快速、准确解决大规模数据集上旋转估计任务的新方法。&lt;h4&gt;方法&lt;/h4&gt;{'步骤1': '首先研究仅涉及旋转轴的几何约束条件', '步骤2': '然后采用立体投影和空间投票技术确定旋转轴与角度'}&lt;h4&gt;主要发现&lt;/h4&gt;该算法能够高效地获得最优旋转估计，并且可以同时估计多个旋转，实验证明其在准确性和效率上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过使用GPU辅助计算，在处理大量数据（例如10^6个点）和高异常比率（90%的异常值率）的情况下，该算法能在0.07秒内完成任务，且角误差仅为0.01度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rotation estimation plays a fundamental role in many computer vision androbot tasks. However, efficiently estimating rotation in large inputscontaining numerous outliers (i.e., mismatches) and noise is a recognizedchallenge. Many robust rotation estimation methods have been designed toaddress this challenge. Unfortunately, existing methods are often inapplicabledue to their long computation time and the risk of local optima. In this paper,we propose an efficient and robust rotation estimation method. Specifically,our method first investigates geometric constraints involving only the rotationaxis. Then, it uses stereographic projection and spatial voting techniques toidentify the rotation axis and angle. Furthermore, our method efficientlyobtains the optimal rotation estimation and can estimate multiple rotationssimultaneously. To verify the feasibility of our method, we conduct comparativeexperiments using both synthetic and real-world data. The results show that,with GPU assistance, our method can solve large-scale ($10^6$ points) andseverely corrupted (90\% outlier rate) rotation estimation problems within 0.07seconds, with an angular error of only 0.01 degrees, which is superior toexisting methods in terms of accuracy and efficiency.</description>
      <author>example@mail.com (Taosi Xu, Yinlong Liu, Xianbo Wang, Zhi-Xin Yang)</author>
      <guid isPermaLink="false">2502.06337v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map</title>
      <link>http://arxiv.org/abs/2502.06292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于优化的SLAM方法Occupancy-SLAM，该方法能够同时联合优化机器人的轨迹和占用地图。通过参数化的地图表示，它实现了机器人姿态与不同单元顶点处占据值的同时优化。&lt;h4&gt;背景&lt;/h4&gt;在特征基础的SLAM问题中，姿势和特征的同时优化已经被广泛研究并证明可以产生更准确的结果。然而，在非特征基础上的地图和机器人的轨迹联合优化的研究较少。占用图因其能够有效地区分障碍物、自由空间以及未知区域而被广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于参数化地图表示的方法，通过同时对机器人姿态与占据值进行优化来改善机器人在环境中的定位问题。&lt;h4&gt;方法&lt;/h4&gt;提出Occupancy-SLAM方法，在该方法中，机器人轨迹和占用图可以通过参数化的地图表示一起被联合优化。这种方法的关键创新在于能够同时处理机器人位置的确定以及空间单元上的占据值计算。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真数据和实际2D激光雷达数据集进行评估后发现，所提出的方法在计算时间接近的情况下比现有技术获得了更准确的机器人轨迹和占用图结果。初步研究还表明，在3D场景下该方法同样具有更高的准确性。&lt;h4&gt;结论&lt;/h4&gt;Occupancy-SLAM是一种创新性地联合优化机器人姿态与非特征地图的新方法，并且已经在2D及3D环境中显示出了强大的性能，未来有望在实际应用中得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;共同优化姿势和基于特征的地图已广泛研究并证明可以产生更准确的结果。然而，同时优化姿势和非特征基础地图的研究仍然有限。因为它们能够有效地将空间划分为障碍物、自由区域以及未知区域，所以占用图被用作环境表示的常见方法。本文提出了一种新的SLAM方法Occupancy-SLAM，它通过参数化地图表示实现了机器人的轨迹与占用图的同时优化。这种方法的关键创新在于可以在同一过程中进行机器人姿势和占据值的不同单元顶点上的同时优化。使用模拟数据及实际2D激光雷达数据集的评估显示，在计算时间相近的情况下所提出的该方法比现有的技术能够产生更准确的结果，这在三维场景中的初步研究中也得到了验证，进一步证明了其在未来3D应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint optimization of poses and features has been extensively studied anddemonstrated to yield more accurate results in feature-based SLAM problems.However, research on jointly optimizing poses and non-feature-based mapsremains limited. Occupancy maps are widely used non-feature-based environmentrepresentations because they effectively classify spaces into obstacles, freeareas, and unknown regions, providing robots with spatial information forvarious tasks. In this paper, we propose Occupancy-SLAM, a noveloptimization-based SLAM method that enables the joint optimization of robottrajectory and the occupancy map through a parameterized map representation.The key novelty lies in optimizing both robot poses and occupancy values atdifferent cell vertices simultaneously, a significant departure from existingmethods where the robot poses need to be optimized first before the map can beestimated. Evaluations using simulations and practical 2D laser datasetsdemonstrate that the proposed approach can robustly obtain more accurate robottrajectories and occupancy maps than state-of-the-art techniques withcomparable computational time. Preliminary results in the 3D case furtherconfirm the potential of the proposed method in practical 3D applications,achieving more accurate results than existing methods.</description>
      <author>example@mail.com (Yingyu Wang, Liang Zhao, Shoudong Huang)</author>
      <guid isPermaLink="false">2502.06292v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors</title>
      <link>http://arxiv.org/abs/2502.06287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The codebase and datasets will be open-sourced at  https://github.com/JasonSun623/CT-UIO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于非均匀B样条框架的高效UWB-惯性里程计定位系统，适用于能量受限条件下使用较少基站的情况。&lt;h4&gt;背景&lt;/h4&gt;近年来，在能量限制条件下利用少量锚点进行超宽带（UWB）定位引起了广泛的研究兴趣。然而，大多数现有方法依赖于离散时间表示和光滑先验来推断机器人的运动状态，并且在保证多传感器数据同步方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的UWB-惯性里程计定位系统，能够在能量受限条件下使用较少的基站，同时确保高精度和鲁棒性能。&lt;h4&gt;方法&lt;/h4&gt;{'非均匀B样条框架': '引入了基于自适应结点跨度调整策略的非均匀连续时间轨迹表示方法，能够根据运动速度动态调整控制点。', '改进的EKF滤波器': '提出了一种基于创新性的自适应估计改进的扩展卡尔曼滤波器（EKF），以提供短期准确的运动先验。', '虚拟锚生成法': '针对少量基站条件下实现完全可观测UWB定位系统的挑战，提出了基于多假设的虚拟锚生成方法。', 'CT-UIO因子图': '在系统后端采用了一种带有自适应滑动窗口的CT-UIO因子图进行全局轨迹估计。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的系统具有高精度和稳健性，在走廊和展览厅数据集上的表现尤为出色。&lt;h4&gt;结论&lt;/h4&gt;该研究为能量受限条件下使用较少基站实现UWB定位提供了一种有效的方法，并将公开源代码和数据集供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到，近年来在能量限制条件下的超宽带（UWB）定位引起了广泛的研究兴趣，特别是在使用少量锚点的情况下。然而，大多数现有方法依赖于离散时间表示和光滑先验来推断机器人的运动状态，并且通常难以确保多传感器数据的同步。本文提出了一种利用非均匀B样条框架实现高效UWB-惯性里程计定位系统的方案，在能量受限条件下可以使用较少基站进行定位。为了适应连续时间轨迹的表现，我们引入了一个基于移动速度调整控制点的自适应结点跨度调整策略。此外，为了解决在少量锚点条件下难以构建完全可观测的UWB定位系统的问题，提出了基于多假设生成虚拟锚的方法。通过提出一种采用CT-UIO因子图和自适应滑动窗口进行全局轨迹估计后端方法来实现高效的传感器数据融合。实验结果表明所提出的系统的准确性和鲁棒性非常高，并且开源代码库与数据集将会在 https://github.com/JasonSun623/CT-UIO 上发布供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultra-wideband (UWB) based positioning with fewer anchors has attractedsignificant research interest in recent years, especially underenergy-constrained conditions. However, most existing methods rely ondiscrete-time representations and smoothness priors to infer a robot's motionstates, which often struggle with ensuring multi-sensor data synchronization.In this paper, we present an efficient UWB-Inertial-odometer localizationsystem, utilizing a non-uniform B-spline framework with fewer anchors. Unliketraditional uniform B-spline-based continuous-time methods, we introduce anadaptive knot-span adjustment strategy for non-uniform continuous-timetrajectory representation. This is accomplished by adjusting control pointsdynamically based on movement speed. To enable efficient fusion of IMU andodometer data, we propose an improved Extended Kalman Filter (EKF) withinnovation-based adaptive estimation to provide short-term accurate motionprior. Furthermore, to address the challenge of achieving a fully observableUWB localization system under few-anchor conditions, the Virtual Anchor (VA)generation method based on multiple hypotheses is proposed. At the backend, wepropose a CT-UIO factor graph with an adaptive sliding window for globaltrajectory estimation. Comprehensive experiments conducted on corridor andexhibition hall datasets validate the proposed system's high precision androbust performance. The codebase and datasets of this work will be open-sourcedat https://github.com/JasonSun623/CT-UIO.</description>
      <author>example@mail.com (Jian Sun, Wei Sun, Genwei Zhang, Kailun Yang, Song Li, Xiangqi Meng, Na Deng, Chongbin Tan)</author>
      <guid isPermaLink="false">2502.06287v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Interaction-aware Conformal Prediction for Crowd Navigation</title>
      <link>http://arxiv.org/abs/2502.06221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WAFR 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '介绍了一种名为交互感知符合预测（ICP）的方法，用于交替进行不确定性感知的机器人运动规划和基于决策的人类运动不确定量化。通过实验验证了ICP在导航效率、社交意识和不确定性量化之间取得了良好的平衡，并展示了其在不同人群密度下的泛化能力。', '背景': '在群体导航中，机器人的运动计划需要考虑人类移动的不确定性，而这种不确定性又依赖于机器人的运动规划方案。', '目的': '提出一种方法来解决机器人与人类交互中的不确定性和决策相关性问题。', '方法': 'ICP由轨迹预测器、模型预测控制器、人类模拟器和符合预测模块组成。通过加入概率安全性的时间间隔半径，使用计划的机器人移动条件下的校准数据集收集人行轨迹，量化轨迹预测误差。', '主要发现': '实验表明ICP在导航效率、社交意识以及不确定性量化方面表现优越，并能很好地适应各种人群密度的任务。', '结论': 'ICP具备快速运行时间和高效内存使用的特点，使其适用于现实世界的应用。代码可在GitHub上获取（https://github.com/tedhuang96/icp）', '翻译': '在群体导航过程中，机器人的运动计划需要考虑人类移动的不确定性，并且这种不确定性又依赖于机器人自身的运动规划方案。为解决此问题引入了交互感知符合预测ICP方法，用于交替进行不确定性感知的机器人运动规划和基于决策的人类运动不确定量化。经过实验验证，ICP在导航效率、社交意识以及不确定性量化方面表现卓越，适应各种人群密度的任务，并且具有快速运行时间和高效内存使用的特点，使其适用于现实世界的应用。该研究已开源（https://github.com/tedhuang96/icp）'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; During crowd navigation, robot motion plan needs to consider human motionuncertainty, and the human motion uncertainty is dependent on the robot motionplan. We introduce Interaction-aware Conformal Prediction (ICP) to alternateuncertainty-aware robot motion planning and decision-dependent human motionuncertainty quantification. ICP is composed of a trajectory predictor topredict human trajectories, a model predictive controller to plan robot motionwith confidence interval radii added for probabilistic safety, a humansimulator to collect human trajectory calibration dataset conditioned on theplanned robot motion, and a conformal prediction module to quantify trajectoryprediction error on the decision-dependent calibration dataset. Crowdnavigation simulation experiments show that ICP strikes a good balance ofperformance among navigation efficiency, social awareness, and uncertaintyquantification compared to previous works. ICP generalizes well to navigationtasks under various crowd densities. The fast runtime and efficient memoryusage make ICP practical for real-world applications. Code is available athttps://github.com/tedhuang96/icp.</description>
      <author>example@mail.com (Zhe Huang, Tianchen Ji, Heling Zhang, Fatemeh Cheraghi Pouria, Katherine Driggs-Campbell, Roy Dong)</author>
      <guid isPermaLink="false">2502.06221v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Improved Extrinsic Calibration of Acoustic Cameras via Batch Optimization</title>
      <link>http://arxiv.org/abs/2502.06196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and is going to be presented at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个用于声学摄像机的自动标定技术，该技术使用同时包含视觉和听觉标记的校准板来确定麦克风阵列中每个麦克风的位置。&lt;h4&gt;背景&lt;/h4&gt;声学摄像机在实践中有着广泛的应用。为了融合视觉与听觉测量数据，准确且可靠的麦克风阵列与视觉传感器之间的外参标定至关重要。现有的方法要么需要已知麦克风阵列的几何结构信息，要么依赖于网格搜索策略，这导致迭代速度慢或收敛性差。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要先验知识并且能够快速、准确地进行外参标定的方法。&lt;h4&gt;方法&lt;/h4&gt;使用同时包含视觉和听觉标记的校准板来自动识别每个麦克风的位置，并将外参标定问题形式化为一个非线性最小二乘问题，采用批量优化策略求解。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法提高了声学摄像机外参数标定的准确性和鲁棒性，在精度和稳定性上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的数值模拟和实际实验验证了该技术的有效性，并将相关代码与数据开源以供社区使用（https://github.com/AISLAB-sustech/AcousticCamera）。&lt;h4&gt;翻译&lt;/h4&gt;声学摄像机在实践中有着广泛的应用。为了融合视觉与听觉测量数据，准确且可靠的麦克风阵列与视觉传感器之间的外参标定至关重要。现有的方法要么需要已知麦克风阵列的几何结构信息，要么依赖于网格搜索策略，这导致迭代速度慢或收敛性差。为了解决这些问题，在本文中我们提出了一种使用同时包含视觉和听觉标记校准板的自动标定技术来确定每个麦克风的位置。我们将外参标定问题（即麦克风与视觉传感器之间）形式化为非线性最小二乘问题，并采用批量优化策略求解相关问题。广泛的数值模拟以及实际实验表明，所提出的方法提高了声学摄像机外参数标定的准确性和鲁棒性，在精度和稳定性上优于现有方法。为了使社区受益，我们开源了所有代码与数据（https://github.com/AISLAB-sustech/AcousticCamera）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Acoustic cameras have found many applications in practice. Accurate andreliable extrinsic calibration of the microphone array and visual sensorswithin acoustic cameras is crucial for fusing visual and auditory measurements.Existing calibration methods either require prior knowledge of the microphonearray geometry or rely on grid search which suffers from slow iteration speedor poor convergence. To overcome these limitations, in this paper, we proposean automatic calibration technique using a calibration board with both visualand acoustic markers to identify each microphone position in the camera frame.We formulate the extrinsic calibration problem (between microphones and thevisual sensor) as a nonlinear least squares problem and employ a batchoptimization strategy to solve the associated problem. Extensive numericalsimulations and realworld experiments show that the proposed method improvesboth the accuracy and robustness of extrinsic parameter calibration foracoustic cameras, in comparison to existing methods. To benefit the community,we open-source all the codes and data athttps://github.com/AISLAB-sustech/AcousticCamera.</description>
      <author>example@mail.com (Zhi Li, Jiang Wang, Xiaoyang Li, He Kong)</author>
      <guid isPermaLink="false">2502.06196v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Calibration of Multiple Asynchronous Microphone Arrays using Hybrid TDOA</title>
      <link>http://arxiv.org/abs/2502.06195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and is going to be presented at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的声学传感系统校准方法，该方法结合了相邻声音事件之间的时间差测量（TDOAS），以提高多麦克风阵列系统的定位和追踪性能。&lt;h4&gt;背景&lt;/h4&gt;准确校准由多个异步麦克风组成的声学传感系统对于实现满意的音源定位和跟踪至关重要。当前最先进的校准技术依赖于时间到达差异(TDOA)和方向到达(DOA)的测量。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入TDOAS来提高系统的校准精度，以改进现有的声学传感器阵列校准方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段校准方案：首先利用混合时间差（包括TDOAM和TDOA-S）、车轮里程计数据、方向到达(DOA)等信息进行初始值估计(IVE)，然后通过迭代最近点算法来确定麦克风阵列的方向。在最终的联合优化步骤中，同时估算多个麦克风阵列的位置、方向、时间偏移、时钟漂移率和声源位置。&lt;h4&gt;主要发现&lt;/h4&gt;无论是模拟还是实验结果都表明，在低或中等TDOA噪声水平的情况下，该方法在准确性方面优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入相邻声音事件之间的时间差测量并结合其他校准技术，可以显著提高多麦克风阵列系统的校准精度。所有代码和数据可在https://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib获取。&lt;h4&gt;翻译&lt;/h4&gt;精确校准由多个异步麦克风组成的声学传感系统对于实现满意的音源定位和跟踪至关重要。当前的校准方法依赖于时间到达差异（TDOA）和方向到达（DOA）测量值来确定麦克风阵列之间的相对位置。本文提出了将相邻声音事件之间的时间差测量（TDOAS）加入现有技术的方法，以增强系统的准确性。我们提出了一种两阶段的校准流程：首先是初始值估算(IVE)过程，使用混合时间到达差异、车轮里程计数据以及方向到达(DOA)来初始化参数；接着通过迭代最近点方法估计麦克风阵列的方向。最终的联合优化步骤同时对多个麦克风阵列的位置、方向、时钟偏移和漂移率以及声源位置进行了估算。仿真和实验结果表明，在低至中等水平的时间到达差异噪声下，本方法在精度上优于现有技术。所有代码和数据可在https://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate calibration of acoustic sensing systems made of multipleasynchronous microphone arrays is essential for satisfactory performance insound source localization and tracking. State-of-the-art calibration methodsfor this type of system rely on the time difference of arrival and direction ofarrival measurements among the microphone arrays (denoted as TDOA-M and DOA,respectively). In this paper, to enhance calibration accuracy, we propose toincorporate the time difference of arrival measurements between adjacent soundevents (TDOAS) with respect to the microphone arrays. More specifically, wepropose a two-stage calibration approach, including an initial value estimation(IVE) procedure and the final joint optimization step. The IVE stage firstinitializes all parameters except for microphone array orientations, usinghybrid TDOA (i.e., TDOAM and TDOA-S), odometer data from a moving robotcarrying a speaker, and DOA. Subsequently, microphone orientations areestimated through the iterative closest point method. The final jointoptimization step estimates multiple microphone array locations, orientations,time offsets, clock drift rates, and sound source locations simultaneously.Both simulation and experiment results show that for scenarios with low ormoderate TDOA noise levels, our approach outperforms existing methods in termsof accuracy. All code and data are available athttps://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib.</description>
      <author>example@mail.com (Chengjie Zhang, Wenda Pan, Xinyang Han, He Kong)</author>
      <guid isPermaLink="false">2502.06195v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Portable, High-Frequency, and High-Voltage Control Circuits for Untethered Miniature Robots Driven by Dielectric Elastomer Actuators</title>
      <link>http://arxiv.org/abs/2502.06166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 10 figures, accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无绳应用的介电弹性体执行器(DEA)的高压、高频控制电路。&lt;h4&gt;背景&lt;/h4&gt;现有的DEA驱动系统通常体积较大且需要连接电源线，这限制了其在便携式和穿戴设备中的使用。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于无绳应用的小型化高电压、高频率控制电路。&lt;h4&gt;方法&lt;/h4&gt;利用低电压电阻元件串联以实现高达1.8kV的电压控制，并测试该控制电路的不同负载条件和电源下的性能。基于此电路，结合商用小型高压电源转换器，构建了一种由圆柱形DEA驱动的无绳爬行机器人。&lt;h4&gt;主要发现&lt;/h4&gt;42克重的无绳机器人能够在15Hz的驱动频率下，在桌面上及管道内成功实现爬行运动，并通过机载摄像机和天线实时传输视频数据。&lt;h4&gt;结论&lt;/h4&gt;该研究为使用低电压控制电子设备来实现DEA的无绳驱动提供了一种实用的方法，从而促进了便携式和穿戴设备的发展。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种用于无绳应用的介电弹性体执行器(DEA)的高压、高频控制电路。该电路板利用低电压电阻元件串联以在紧凑尺寸内实现高达1.8kV的电压控制，适用于0至1kHz范围内的频率变化。单通道控制板仅重2.5克。我们测试了该控制电路在不同负载条件和电源下的性能表现。基于此控制电路，并结合商用小型高压电源转换器，我们构建了一种由圆柱形DEA驱动的无绳爬行机器人。42克重的无绳机器人能够在15Hz的驱动频率下，在桌面上及管道内成功实现爬行运动，并通过机载摄像机和天线实时传输视频数据。我们的工作提供了一种使用低电压控制电子设备来实现DEA的无绳驱动的实际方法，从而促进了便携式和穿戴设备的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a high-voltage, high-frequency control circuit forthe untethered applications of dielectric elastomer actuators (DEAs). Thecircuit board leverages low-voltage resistive components connected in series tocontrol voltages of up to 1.8 kV within a compact size, suitable forfrequencies ranging from 0 to 1 kHz. A single-channel control board weighs only2.5 g. We tested the performance of the control circuit under different loadconditions and power supplies. Based on this control circuit, along with acommercial miniature high-voltage power converter, we construct an untetheredcrawling robot driven by a cylindrical DEA. The 42-g untethered robotssuccessfully obtained crawling locomotion on a bench and within a pipeline at adriving frequency of 15 Hz, while simultaneously transmitting real-time videodata via an onboard camera and antenna. Our work provides a practical way touse low-voltage control electronics to achieve the untethered driving of DEAs,and therefore portable and wearable devices.</description>
      <author>example@mail.com (Qi Shao, Xin-Jun Liu, Huichan Zhao)</author>
      <guid isPermaLink="false">2502.06166v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Reward-Based Collision-Free Algorithm for Trajectory Planning of Autonomous Robots</title>
      <link>http://arxiv.org/abs/2502.06149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的自主机器人任务规划算法，该算法能够从预定义的路点集中选择出最优路径序列，并基于此优化机器人的奖励值。&lt;h4&gt;背景&lt;/h4&gt;当前的任务规划问题通常涉及到如何最大化效益同时避免障碍物、满足约束条件等挑战。现有的方法往往无法很好地解决这一复杂性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够高效地处理奖赏收集旅行商问题的新算法，通过遗传算法寻找最佳路径序列，并优化机器人的导航性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的基于惩罚函数和交叉操作的遗传算法；利用微分平坦性和Clothoid曲线特性进行轨迹规划与评估；采用动态时间规整法进行高效的解空间搜索。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能够在保证路径可行性的前提下，有效地寻找最优路点序列，并对高奖励目标给予优先权。此外，在仿真和实际试验中展示出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的任务规划算法成功解决了奖赏收集旅行商问题，能够有效避免不可行的路点并优化机器人的导航策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要：该论文介绍了一种新的自主机器人任务规划算法，通过奖励导向的选择机制来确定从预定义集合中获得最优路径序列。该算法计算了机器人在遵循状态、输入及其导数约束的情况下，在避开障碍物的同时行进于路点之间的可行轨迹和相应的控制指令，并最大化总收益以及符合任务时间窗口和最大距离的限制。这也解决了广义的奖赏收集旅行商问题。提议的方法利用了一种新颖的遗传算法，该算法通过基于适应度函数及交叉操作演化的候选解决方案来趋近最优解。在适应度评估期间，使用惩罚方法强制执行约束条件，并通过微分平坦性与Clothoid曲线高效地惩罚不可行轨迹。与最小瞬时和加速度多项式相比，欧拉螺旋法显示出更优的轨迹参数化结果。由于探索空间是离散性的，采用基于动态时间规整的方法及扩展凸组合与投影来进行交叉操作，并通过突变步骤来增强探索能力。实验结果显示该算法能够发现最优路点序列、满足约束条件、避免不可行路径以及优先选择高收益目标点。同时提供了一系列涉及地面车辆、四旋翼和四足机器人的仿真及试验结果，辅以基准测试与时间复杂性分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a new mission planning algorithm for autonomous robotsthat enables the reward-based selection of an optimal waypoint sequence from apredefined set. The algorithm computes a feasible trajectory and correspondingcontrol inputs for a robot to navigate between waypoints while avoidingobstacles, maximizing the total reward, and adhering to constraints on state,input and its derivatives, mission time window, and maximum distance. This alsosolves a generalized prize-collecting traveling salesman problem. The proposedalgorithm employs a new genetic algorithm that evolves solution candidatestoward the optimal solution based on a fitness function and crossover. Duringfitness evaluation, a penalty method enforces constraints, and the differentialflatness property with clothoid curves efficiently penalizes infeasibletrajectories. The Euler spiral method showed promising results for trajectoryparameterization compared to minimum snap and jerk polynomials. Due to thediscrete exploration space, crossover is performed using a dynamictime-warping-based method and extended convex combination with projection. Amutation step enhances exploration. Results demonstrate the algorithm's abilityto find the optimal waypoint sequence, fulfill constraints, avoid infeasiblewaypoints, and prioritize high-reward ones. Simulations and experiments with aground vehicle, quadrotor, and quadruped are presented, complemented bybenchmarking and a time-complexity analysis.</description>
      <author>example@mail.com (Jose D. Hoyos, Tianyu Zhou, Zehui Lu, Shaoshuai Mou)</author>
      <guid isPermaLink="false">2502.06149v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Mixed Reality Outperforms Virtual Reality for Remote Error Resolution in Pick-and-Place Tasks</title>
      <link>http://arxiv.org/abs/2502.06141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究评估了混合现实（MR）、虚拟现实（VR）和摄像头流接口在远程错误解决任务中的性能和可用性，特别是对于仓库包装错误的纠正。&lt;h4&gt;背景&lt;/h4&gt;当前情况下，机器人手臂检测到错误后停止运行，需要远程操作员通过抓取放置动作介入并解决问题。这些任务通常由不同的技术界面支持进行操作。&lt;h4&gt;目的&lt;/h4&gt;评估混合现实（MR）、虚拟现实（VR）和摄像头流接口在执行远程错误解决任务时的性能和可用性。&lt;h4&gt;方法&lt;/h4&gt;21名参与者进行了模拟抓取和放置任务，分别使用三种不同类型的接口。通过线性混合模型（LMM）分析了任务解决时间、可用性得分（SUS）和心理工作量评分（NASA-TLX）。&lt;h4&gt;主要发现&lt;/h4&gt;{'MR性能优势': '混合现实界面在任务完成速度上显著优于VR和摄像头流接口，且在可用性和认知负荷方面也表现出色。', '空间理解能力': 'MR通过将虚拟机器人投影到物理桌面上提供了更好的空间理解和实际参考线索。'}&lt;h4&gt;结论&lt;/h4&gt;混合现实（MR）界面因其较高的性能、可用性以及较低的认知负担而被参与者偏好，表明MR在远程错误解决任务中具有明显优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已完成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study evaluates the performance and usability of Mixed Reality (MR),Virtual Reality (VR), and camera stream interfaces for remote error resolutiontasks, such as correcting warehouse packaging errors. Specifically, we considera scenario where a robotic arm halts after detecting an error, requiring aremote operator to intervene and resolve it via pick-and-place actions.Twenty-one participants performed simulated pick-and-place tasks using eachinterface. A linear mixed model (LMM) analysis of task resolution time,usability scores (SUS), and mental workload scores (NASA-TLX) showed that theMR interface outperformed both VR and camera interfaces. MR enabledsignificantly faster task completion, was rated higher in usability, and wasperceived to be less cognitively demanding. Notably, the MR interface, whichprojected a virtual robot onto a physical table, provided superior spatialunderstanding and physical reference cues. Post-study surveys further confirmedparticipants' preference for MR over other interfaces.</description>
      <author>example@mail.com (Advay Kumar, Stephanie Simangunsong, Pamela Carreno-Medrano, Akansel Cosgun)</author>
      <guid isPermaLink="false">2502.06141v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Bio-inspired Heuristically Accelerated Reinforcement Learning for Adaptive Underwater Multi-Agents Behaviour</title>
      <link>http://arxiv.org/abs/2502.06113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  i-SAIRAS 2024 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文讨论了在复杂环境中协调自主多智能体系统（MAS）的问题，特别是用于检测和识别感兴趣物体的覆盖规划问题。这些任务对于太空应用至关重要，并且同样适用于包括水下环境在内的多个领域。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种新的策略来解决由于学习时间长而限制当前大多数MARL算法在实际应用场景中的应用这一问题。&lt;h4&gt;方法&lt;/h4&gt;通过引入生物启发式算法（如粒子群优化PSO）作为引导智能体训练过程的启发法，加速了MAS在水下环境覆盖规划任务中的收敛速度。具体来说，该策略应用于MSAC算法，并在一个连续控制环境中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;新的方法让智能体能够更快地达到最优性能，减少了训练中所需的交互次数。&lt;h4&gt;结论&lt;/h4&gt;通过结合生物启发式算法和MARL技术，研究提供了一种有效的方法来加速MAS在复杂且动态的水下环境中的学习过程。这种方法有助于解决覆盖规划问题中的不确定性、通信限制等问题，并展示了在实际应用（如探索水下区域）中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes the problem of coordination of an autonomous Multi-AgentSystem which aims to solve the coverage planning problem in a complexenvironment. The considered applications are the detection and identificationof objects of interest while covering an area. These tasks, which are highlyrelevant for space applications, are also of interest among various domainsincluding the underwater context, which is the focus of this study. In thiscontext, coverage planning is traditionally modelled as a Markov DecisionProcess where a coordinated MAS, a swarm of heterogeneous autonomous underwatervehicles, is required to survey an area and search for objects. This MDP isassociated with several challenges: environment uncertainties, communicationconstraints, and an ensemble of hazards, including time-varying andunpredictable changes in the underwater environment. MARL algorithms can solvehighly non-linear problems using deep neural networks and display greatscalability against an increased number of agents. Nevertheless, most of thecurrent results in the underwater domain are limited to simulation due to thehigh learning time of MARL algorithms. For this reason, a novel strategy isintroduced to accelerate this convergence rate by incorporating biologicallyinspired heuristics to guide the policy during training. The PSO method, whichis inspired by the behaviour of a group of animals, is selected as a heuristic.It allows the policy to explore the highest quality regions of the action andstate spaces, from the beginning of the training, optimizing theexploration/exploitation trade-off. The resulting agent requires fewerinteractions to reach optimal performance. The method is applied to the MSACalgorithm and evaluated for a 2D covering area mission in a continuous controlenvironment.</description>
      <author>example@mail.com (Antoine Vivien, Thomas Chaffre, Matthew Stephenson, Eva Artusi, Paulo Santos, Benoit Clement, Karl Sammut)</author>
      <guid isPermaLink="false">2502.06113v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>CDM: Contact Diffusion Model for Multi-Contact Point Localization</title>
      <link>http://arxiv.org/abs/2502.06109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication at the 2025 IEEE  International Conference on Robotics and Automation (ICRA), Atlanta, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于学习的方法，即接触扩散模型(CDM)，用于多接触点定位。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理多个接触点和力对传感器测量值产生相同结果的情况时存在问题。&lt;h4&gt;目的&lt;/h4&gt;通过利用扩散模型解决上述问题，并提高机器人表面任意位置的接触点定位准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种条件化的扩散模型(CDM)，该模型基于过去的输出并考虑到多接触场景的时间特性。此外，为了有效处理复杂形状的机器人表面，在去噪过程中引入了符号距离场。&lt;h4&gt;主要发现&lt;/h4&gt;CDM能够以高精度在任意位置定位接触点，并且实验结果表明该方法的有效性。具体而言，CDM运行时间为15.97毫秒，在单次接触和双重接触场景中分别实现了0.44厘米和1.24厘米的误差。&lt;h4&gt;结论&lt;/h4&gt;提出的扩散模型（CDM）是一种有效的解决多点接触定位问题的方法，并且在真实世界的应用中显示出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a Contact Diffusion Model (CDM), a novellearning-based approach for multi-contact point localization. We consider arobot equipped with joint torque sensors and a force/torque sensor at the base.By leveraging a diffusion model, CDM addresses the singularity where multiplepairs of contact points and forces produce identical sensor measurements. Weformulate CDM to be conditioned on past model outputs to account for thetime-dependent characteristics of the multi-contact scenarios. Moreover, toeffectively address the complex shape of the robot surfaces, we incorporate thesigned distance field in the denoising process. Consequently, CDM can localizecontacts at arbitrary locations with high accuracy. Simulation and real-worldexperiments demonstrate the effectiveness of the proposed method. Inparticular, CDM operates at 15.97ms and, in the real world, achieves an errorof 0.44cm in single-contact scenarios and 1.24cm in dual-contact scenarios.</description>
      <author>example@mail.com (Seo Wook Han, Min Jun Kim)</author>
      <guid isPermaLink="false">2502.06109v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.05996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度强化学习（DRL）在无人机添加剂制造中的运动控制挑战的应用。&lt;h4&gt;背景&lt;/h4&gt;基于无人机的添加剂制造能够在大型或危险环境中实现灵活和自主的材料沉积。然而，多旋翼空中机器人在不同负载和潜在干扰下的实时控制仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种深度强化学习框架，该框架能够为执行路径导航任务的多旋翼无人机学习适应性的控制策略。&lt;h4&gt;方法&lt;/h4&gt;比较了DDPG（Deep Deterministic Policy Gradient）和TD3（Twin Delayed Deep Deterministic Policy Gradient），并在处理不断增加复杂度的学习课程方案中进行了测试。实验表明，当引入质量变化时，TD3在训练稳定性、精度和成功率方面表现更佳。&lt;h4&gt;主要发现&lt;/h4&gt;结果证明了使用DRL方法能够实现稳健且自主的无人机控制，并为添加剂制造提供了可扩展路径。&lt;h4&gt;结论&lt;/h4&gt;通过深度强化学习技术，特别是在处理动态场景中的参数调节问题时，可以提高多旋翼无人机在添加剂制造任务中的适应性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文探讨了将深度强化（DRL）学习应用于解决无人机添加剂制造的运动控制挑战。基于无人机的添加剂制造能够在大型或危险环境中实现灵活和自主的材料沉积。然而，多旋翼空中机器人在不同负载和潜在干扰下的实时控制仍然具有挑战性。传统的控制器如PID经常需要频繁调节参数，在动态场景中限制了它们的应用。我们提出了一种DRL框架，该框架能够为执行路径导航任务的多旋翼无人机学习适应性的控制策略。我们在处理不断增加复杂度的学习课程方案中比较了DDPG和TD3，并在实验中展示了TD3能够平衡训练稳定性、精度和成功率，尤其是在引入质量变化时。这些发现提供了一条向添加剂制造中稳健且自主的无人机控制扩展的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the application of Deep Reinforcement (DRL) Learningto address motion control challenges in drones for additive manufacturing (AM).Drone-based additive manufacturing promises flexible and autonomous materialdeposition in large-scale or hazardous environments. However, achieving robustreal-time control of a multi-rotor aerial robot under varying payloads andpotential disturbances remains challenging. Traditional controllers like PIDoften require frequent parameter re-tuning, limiting their applicability indynamic scenarios. We propose a DRL framework that learns adaptable controlpolicies for multi-rotor drones performing waypoint navigation in AM tasks. Wecompare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed DeepDeterministic Policy Gradient (TD3) within a curriculum learning schemedesigned to handle increasing complexity. Our experiments show TD3 consistentlybalances training stability, accuracy, and success, particularly when massvariability is introduced. These findings provide a scalable path towardrobust, autonomous drone control in additive manufacturing.</description>
      <author>example@mail.com (Gaurav Shetty, Mahya Ramezani, Hamed Habibi, Holger Voos, Jose Luis Sanchez-Lopez)</author>
      <guid isPermaLink="false">2502.05996v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Mechanic Modeling and Nonlinear Optimal Control of Actively Articulated Suspension of Mobile Heavy-Duty Manipulators</title>
      <link>http://arxiv.org/abs/2502.05972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对移动重型机械臂的分析建模及其最优控制，以最大化其静态和动态稳定性的方法。&lt;h4&gt;背景&lt;/h4&gt;研究采用螺旋理论形式化方法，将悬架机制视为由两个闭合运动链组成的刚体多体系统。&lt;h4&gt;目的&lt;/h4&gt;通过这种方法来提高计算车轮反作用力的准确性，并提供机械臂质心及惯性张量的确切解。&lt;h4&gt;方法&lt;/h4&gt;利用铰接体惯性法，根据悬架的线性执行器计算整个平台的空间惯性参数。这些惯性参数和正向力用于定义静态和动态稳定性的指标，并建立一个非线性规划问题以优化这些指标来生成防止平台翻倒的最佳稳定性运动。&lt;h4&gt;主要发现&lt;/h4&gt;通过在C++中模拟具有主动铰接悬架的7自由度重型并联-串联移动机械臂，证明了该方法在计算速度、精度和性能改进方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究展示了一种提高移动重型机械臂稳定性的新途径，并证实了所提出的方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文提出了对装备有主动铰接悬架的移动重型机械臂进行分析建模及其最优控制，以最大化其静态和动态稳定性。通过采用螺旋理论形式化方法，将悬架机制视为由两个闭合运动链组成的刚体多体系统。该机械模型使我们能够根据悬架的线性执行器计算整个平台的空间惯性参数，并利用铰接体惯性法提供精确的质量中心及惯性张量解。这些惯性参数和正向力用于定义移动机械臂静态和动态稳定性的指标，并构建一个非线性规划问题以优化这些指标，生成防止平台翻倒的最佳稳定性运动。最优执行器位置通过状态反馈液压阀控制跟踪实现。通过在C++中模拟具有主动铰接悬架的7自由度重型并联-串联移动机械臂，验证了该方法的有效性，具体体现在计算速度、精度和性能改进方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the analytic modeling of mobile heavy-duty manipulatorswith actively articulated suspension and its optimal control to maximize itsstatic and dynamic stabilization. By adopting the screw theory formalism, weconsider the suspension mechanism as a rigid multibody composed of two closedkinematic chains. This mechanical modeling allows us to compute the spatialinertial parameters of the whole platform as a function of the suspension'slinear actuators through the articulated-body inertia method. Our solutionenhances the computation accuracy of the wheels' reaction normal forces byproviding an exact solution for the center of mass and inertia tensor of themobile manipulator. Moreover, these inertial parameters and the normal forcesare used to define metrics of both static and dynamic stability of the mobilemanipulator and formulate a nonlinear programming problem that optimizes suchmetrics to generate an optimal stability motion that prevents the platform'soverturning, such optimal position of the actuator is tracked with astate-feedback hydraulic valve control. We demonstrate our method's efficiencyin terms of C++ computational speed, accuracy and performance improvement bysimulating a 7 degrees-of-freedom heavy-duty parallel-serial mobile manipulatorwith four wheels and actively articulated suspension.</description>
      <author>example@mail.com (Alvaro Paz, Jouni Mattila)</author>
      <guid isPermaLink="false">2502.05972v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    </channel>
</rss>