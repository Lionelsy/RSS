<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 17 Feb 2025 16:54:23 +0800</lastBuildDate>
    <item>
      <title>DES to HSC: Detecting low surface brightness galaxies in the Abell 194 cluster using transfer learning</title>
      <link>http://arxiv.org/abs/2502.03142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究利用了两种基于Transformer模型的LSBG识别技术，并成功应用于更深观测数据，发现了171个低表面亮度星系（包括87个新发现）和28个超扩散星系。这些发现有助于理解星系演化及宇宙学模型。&lt;h4&gt;背景&lt;/h4&gt;低表面亮度星系(LSBGs)对于理解星系演化和宇宙学模型至关重要。未来的大规模调查预计将揭露大量LSBGs，需要准确的自动化或基于机器学习的方法进行检测。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习在识别LSBG中的作用，并提出一种新的方法来提高LSBG识别效率。&lt;h4&gt;方法&lt;/h4&gt;使用训练过的Transformer模型（LSBG DETR和LSBG ViT）对Abell 194星系团的专用Hyper Suprime-Cam (HSC)观测数据进行LSBG检测。这些数据比Dark Energy Survey (DES)的数据深两个星等。&lt;h4&gt;主要发现&lt;/h4&gt;[{'数量': '识别出171个低表面亮度星系，包括87个新发现'}, {'分类': '28个超扩散星系被归类为LSBGs'}, {'模型性能': 'Transformer模型在未经微调的情况下达到93%的真正例率(TPR)'}]&lt;h4&gt;结论&lt;/h4&gt;训练于较浅调查数据集的Transformer模型可以成功应用于更深的数据，但需要适当的数据标准化。&lt;h4&gt;翻译&lt;/h4&gt;Low表面亮度星系(LSBGs)对于理解galaxy演化和宇宙学模型至关重要。未来的大规模调查预计将揭露大量LSBGs，需要准确的自动化或基于机器学习的方法进行检测。本研究使用训练过的Transformer模型（LSBG DETR和LSBG ViT）对Abell 194星系团的专用Hyper Suprime-Cam (HSC)观测数据进行LSBG检测，并成功发现了171个低表面亮度星系，包括87个新发现。这些LSBGs中还包括28个被分类为超扩散星系(UDGs)，它们与矮星系共享类似的S'ersic参数，表明可能是一类扩展的矮星系群体。此外，在未经微调的情况下，Transformer模型在较深数据集上达到了93%的真正例率(TPR)。研究表明，训练于较浅调查数据集的Transformer模型可以成功应用于更深的数据，但需要适当的数据标准化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low surface brightness galaxies (LSBGs) are important for understandinggalaxy evolution and cosmological models. The upcoming large-scale surveys areexpected to uncover a large number of LSBGs, requiring accurate automated ormachine learning-based methods for their detection. We study the scope oftransfer learning for the identification of LSBGs. We use transformer modelsdivided into two categories: LSBG Detection Transformer (LSBG DETR) and LSBGVision Transformer (LSBG ViT), trained on Dark Energy Survey (DES) data, toidentify LSBGs from dedicated Hyper Suprime-Cam (HSC) observations of the Abell194 cluster, which are two magnitudes deeper than DES. The data from DES andHSC were standardized based on pixel-level surface brightness. We used twotransformer ensembles to detect LSBGs. This was followed by a single-componentS\'ersic model fit and a final visual inspection to filter out potential falsepositives and improve sample purity. We present a sample of 171 low surfacebrightness galaxies (LSBGs) in the Abell 194 cluster using HSC data, including87 new discoveries. Of these, 159 were identified using transformer models, and12 additional LSBGs were found through visual inspection. The transformer modelachieved a true positive rate (TPR) of 93% in HSC data without any fine-tuning.Among the LSBGs, 28 were classified as ultra-diffuse galaxies (UDGs). Thenumber of UDGs and the radial UDG number density suggest a linear relationshipbetween UDG numbers and cluster mass on a log scale. UDGs share similarS\'ersic parameters with dwarf galaxies and occupy the extended end of the$R_{\mathrm{eff}}-M_g$ plane, suggesting they might be an extendedsubpopulation of dwarf galaxies. We have demonstrated that transformer modelstrained on shallower surveys can be successfully applied to deeper surveys withappropriate data normalization.</description>
      <author>example@mail.com (H. Thuruthipilly, Junais, J. Koda, A. Pollo, M. Yagi, H. Yamanoi, Y. Komiyama, M. Romano, K. Małek, D. Donevski)</author>
      <guid isPermaLink="false">2502.03142v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
  <item>
      <title>AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.10235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;预训练基础模型（FMs）在单变量时间序列预测任务中表现出色，但仍然面临如何处理特征间的复杂依赖关系和量化不确定性等挑战。本文提出了一种名为适配器（adapters）的方法来解决这些问题，通过将多变量输入投影到适合的潜在空间并独立应用于每个维度，从而有效利用预训练单变量时间序列FMs进行多元任务预测。&lt;h4&gt;背景&lt;/h4&gt;预训练基础模型在处理单变量时间序列数据时展现出了强大的性能。然而，在实际应用中仍存在一些挑战：例如如何有效地管理多个特征之间的复杂依赖关系以及如何准确量化这些模型的预测不确定性。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入适配器来应对上述关键问题，该方法能够帮助预训练单变量时间序列FMs在多变量任务上更有效应用。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一种新的框架AdaPTS，它包括一系列适配器和优化/推理策略。这些适应器是特征空间变换，在灵感来自表示学习和部分随机贝叶斯神经网络的研究成果的基础上设计的。&lt;h4&gt;主要发现&lt;/h4&gt;通过在合成数据集及实际世界数据集上的实验验证了该方法的有效性，展示了与基线方法相比在预测准确性和不确定性量化方面的显著改进。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明AdaPTS框架作为利用时间序列FMs处理多元问题的一种模块化、可扩展且有效的解决方案，可以促进其在未来更广泛的实际应用中的采用。相关代码可在https://github.com/abenechehab/AdaPTS中获取。&lt;h4&gt;翻译&lt;/h4&gt;预训练基础模型在单变量时间序列预测任务中表现出色，但仍然面临如何处理特征间的复杂依赖关系和量化不确定性等挑战。本文提出了一种名为适配器的方法来解决这些问题，通过将多变量输入投影到适合的潜在空间并独立应用于每个维度，从而有效利用预训练单变量时间序列FMs进行多元任务预测。文章设计了一系列适应器，并通过实验验证了其有效性，在合成数据集及实际世界数据集中均显示出了相比基线方法而言在准确性与不确定性量化方面的显著改善。该研究为预训练基础模型在未来更广泛的应用中提供了一个模块化、可扩展且有效的解决方案，推动它们的进一步采用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained foundation models (FMs) have shown exceptional performance inunivariate time series forecasting tasks. However, several practical challengespersist, including managing intricate dependencies among features andquantifying uncertainty in predictions. This study aims to tackle thesecritical limitations by introducing adapters; feature-space transformationsthat facilitate the effective use of pre-trained univariate time series FMs formultivariate tasks. Adapters operate by projecting multivariate inputs into asuitable latent space and applying the FM independently to each dimension.Inspired by the literature on representation learning and partially stochasticBayesian neural networks, we present a range of adapters andoptimization/inference strategies. Experiments conducted on both synthetic andreal-world datasets confirm the efficacy of adapters, demonstrating substantialenhancements in forecasting accuracy and uncertainty quantification compared tobaseline methods. Our framework, AdaPTS, positions adapters as a modular,scalable, and effective solution for leveraging time series FMs in multivariatecontexts, thereby promoting their wider adoption in real-world applications. Werelease the code at https://github.com/abenechehab/AdaPTS.</description>
      <author>example@mail.com (Abdelhakim Benechehab, Vasilii Feofanov, Giuseppe Paolo, Albert Thomas, Maurizio Filippone, Balázs Kégl)</author>
      <guid isPermaLink="false">2502.10235v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SGS-GNN: A Supervised Graph Sparsification method for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.10208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在大型图上进行推理任务时，图形神经网络（GNNs）的计算成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的监督图稀疏化方法SGS-GNN，以减少GNNs执行推断任务所需的计算开销&lt;h4&gt;方法&lt;/h4&gt;{'1': '学习边采样概率分布并抽取特定大小的稀疏子图来降低计算成本。', '2': '在损失函数中使用正则化器增强异质图中的同质性，从而提高GNNs的准确性。', '3': '支持基于先验的概率分布学习模块的条件更新以缩小稀疏图搜索空间。', '4': '比采用固定分布（如随机采样）的方法更有效地学习子图搜索空间'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '在仅保留20%边的稀疏子图中，SGS-GNN相对于原始图改善F1评分几何平均值为4%，并在异质性图形上预测准确性提高最多30%', '2': '与最先进的方法相比，在相似度的采样子图稀疏度下，SGS-GNN在F1评分上的改进达到4-7%的几何平均值', '3': '相比采用固定分布的方法，SGS-GNN需要大约一半的时间来收敛'}&lt;h4&gt;结论&lt;/h4&gt;SGS-GNN有效降低了GNN执行推理任务时的计算成本，并提高了稀疏图上模型预测准确性。实验表明它比当前最佳方法更高效。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了SGS-GNN，这是一种新颖的监督图稀疏化方法，通过学习边采样概率分布并抽取特定大小的稀疏子图来减少大型图上执行GNNs推断任务时的计算成本。该方法在异质性图中提高了模型预测准确性，并且比使用固定分布的方法更有效地减少了收敛时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SGS-GNN, a novel supervised graph sparsifier that learns thesampling probability distribution of edges and samples sparse subgraphs of auser-specified size to reduce the computational costs required by GNNs forinference tasks on large graphs. SGS-GNN employs regularizers in the lossfunction to enhance homophily in sparse subgraphs, boosting the accuracy ofGNNs on heterophilic graphs, where a significant number of the neighbors of anode have dissimilar labels. SGS-GNN also supports conditional updates of theprobability distribution learning module based on a prior, which helps narrowthe search space for sparse graphs. SGS-GNN requires fewer epochs to obtainhigh accuracies since it learns the search space of subgraphs more effectivelythan methods using fixed distributions such as random sampling. Extensiveexperiments using 33 homophilic and heterophilic graphs demonstrate thefollowing: (i) with only 20% of edges retained in the sparse subgraphs, SGS-GNNimproves the F1-scores by a geometric mean of 4% relative to the originalgraph; on heterophilic graphs, the prediction accuracy is better up to 30%.(ii) SGS-GNN outperforms state-of-the-art methods with improvement in F1-scoresof 4-7% in geometric mean with similar sparsities in the sampled subgraphs, and(iii) compared to sparsifiers that employ fixed distributions, SGS-GNN requiresabout half the number of epochs to converge.</description>
      <author>example@mail.com (Siddhartha Shankar Das, Naheed Anjum Arafat, Muftiqur Rahman, S M Ferdous, Alex Pothen, Mahantesh M Halappanavar)</author>
      <guid isPermaLink="false">2502.10208v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>CLaMP 3: Universal Music Information Retrieval Across Unaligned Modalities and Unseen Languages</title>
      <link>http://arxiv.org/abs/2502.10362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures, 12 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;CLaMP 3是一个统一的框架，旨在解决音乐信息检索中的跨模态和跨语言泛化挑战。&lt;h4&gt;背景&lt;/h4&gt;传统的音乐信息检索系统在处理不同模态（乐谱、表演信号、音频录音）以及多种语言时面临挑战，需要一个能够统一这些模式并促进其之间相互转换的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架CLaMP 3，它使用对比学习方法将所有主要的音乐模态与多语言文本在共享表示空间中对齐，使跨不匹配模态的信息检索成为可能。&lt;h4&gt;方法&lt;/h4&gt;{'1': '采用对比学习技术，让不同类型的音乐数据和多语言文本在一个共同的表示空间内对齐。', '2': '使用一种可适应未见过的语言的多语言文本编码器来增强系统的跨语言泛化能力。', '3': '通过检索增强生成方法创建了一个大规模的数据集M4-RAG，包含2.31万音乐-文本配对。', '4': '利用详细元数据丰富了数据集，使其涵盖了全球各种音乐传统。', '5': '为了推进未来的研究，发布了一项新的基准测试WikiMT-X，包含了1000个乐谱、音频和多样化文本描述的三元组。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'CLaMP 3在多个MIR任务上达到了最先进的性能。', '2': '该系统显著超越了以前的强大基准线，在多模态和多语言音乐环境中展示了优秀的泛化能力。'}&lt;h4&gt;结论&lt;/h4&gt;CLaMP 3框架提供了一个强大的解决方案，用于解决跨模态和跨语言挑战，并通过大规模数据集的创建为未来的研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;CLaMP 3是一个旨在应对音乐信息检索中跨模态与跨语种泛化难题的统一框架。它利用对比学习技术，实现了乐谱、表演信号及音频录音等主要音乐形态与多语言文本在共享表示空间内的对齐，从而通过文本作为桥梁实现不同不匹配模态之间的信息检索。此框架具备一种能适应未知语言的多语种文本编码器，展示了强大的跨语种泛化能力。借助于增强型生成的检索方法，我们构建了一个包含231万音乐-文本配对的大规模网络级数据集M4-RAG，并且该数据集通过详细的元数据信息代表了全球多样化的音乐传统风格。为了推进未来的相关研究工作，我们发布了WikiMT-X基准测试，包括了一千个乐谱、音频文件及丰富多样的文字描述三元组样本。实验结果表明，CLaMP 3在多项MIR任务上实现了卓越的性能表现，并显著超越了现有最强的基线模型，在多元模态与语言音乐场景中均展示了优秀的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLaMP 3 is a unified framework developed to address challenges of cross-modaland cross-lingual generalization in music information retrieval. Usingcontrastive learning, it aligns all major music modalities--including sheetmusic, performance signals, and audio recordings--with multilingual text in ashared representation space, enabling retrieval across unaligned modalitieswith text as a bridge. It features a multilingual text encoder adaptable tounseen languages, exhibiting strong cross-lingual generalization. Leveragingretrieval-augmented generation, we curated M4-RAG, a web-scale datasetconsisting of 2.31 million music-text pairs. This dataset is enriched withdetailed metadata that represents a wide array of global musical traditions. Toadvance future research, we release WikiMT-X, a benchmark comprising 1,000triplets of sheet music, audio, and richly varied text descriptions.Experiments show that CLaMP 3 achieves state-of-the-art performance on multipleMIR tasks, significantly surpassing previous strong baselines and demonstratingexcellent generalization in multimodal and multilingual music contexts.</description>
      <author>example@mail.com (Shangda Wu, Zhancheng Guo, Ruibin Yuan, Junyan Jiang, Seungheon Doh, Gus Xia, Juhan Nam, Xiaobing Li, Feng Yu, Maosong Sun)</author>
      <guid isPermaLink="false">2502.10362v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models</title>
      <link>http://arxiv.org/abs/2502.10307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为SPIRIT的新模型，该模型利用基础模型进行太阳辐照度预测，适用于没有多年历史数据的新型光伏电站。&lt;h4&gt;背景&lt;/h4&gt;传统的太阳能预测模型依赖于特定地点多年的辐射数据，但新建光伏电站往往缺乏这些数据。可再生能源的高度间歇性使得建立准确的太阳能辐照度预测系统对于有效电网管理至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖于历史数据的新方法，以促进新型光伏发电系统的快速部署和全球范围内的太阳能能源整合。&lt;h4&gt;方法&lt;/h4&gt;提出了SPIRIT模型，在零样本迁移学习中表现出色，能够适应新地点而无需历史数据。随着更多特定位置的数据可用性提高，性能可通过微调进一步改进。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最佳模型相比，该模型在零样本迁移学习中的表现高出约70%，并在统计上显著改善了预测准确性。&lt;h4&gt;结论&lt;/h4&gt;SPIRIT代表了一种向快速、可扩展和适应性强的太阳能预报解决方案迈进的重要步骤，有助于加速全球电力系统中可再生能源的整合。&lt;h4&gt;翻译&lt;/h4&gt;传统的太阳能预测模型依赖于数年的特定地点的历史辐照度数据，但新建光伏电站往往缺乏这些数据。由于可再生能源的高度间歇性，建立准确的太阳辐射预测系统对于有效电网管理和促进太阳能能源的发展至关重要，这是实现联合国净零目标的关键因素。在本研究中，我们提出了一种基于基础模型进行太阳辐射预报的新方法SPIRIT，使其适用于新的光伏安装。我们的方法在零样本迁移学习中的表现比现有最佳模型高出约70%，使新地点的有效性能成为可能，而无需任何历史数据。随着更多特定位置的数据可用性提高，微调进一步提高了性能。这些发现得到了统计显著性的支持，进一步验证了我们的方法。SPIRIT代表了一种向快速、可扩展和适应性强的太阳预报解决方案迈进的重要步骤，有助于加速将可再生能源整合到全球电力系统中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional solar forecasting models are based on several years ofsite-specific historical irradiance data, often spanning five or more years,which are unavailable for newer photovoltaic farms. As renewable energy ishighly intermittent, building accurate solar irradiance forecasting systems isessential for efficient grid management and enabling the ongoing proliferationof solar energy, which is crucial to achieve the United Nations' net zerogoals. In this work, we propose SPIRIT, a novel approach leveraging foundationmodels for solar irradiance forecasting, making it applicable to newer solarinstallations. Our approach outperforms state-of-the-art models in zero-shottransfer learning by about 70%, enabling effective performance at new locationswithout relying on any historical data. Further improvements in performance areachieved through fine-tuning, as more location-specific data becomes available.These findings are supported by statistical significance, further validatingour approach. SPIRIT represents a pivotal step towards rapid, scalable, andadaptable solar forecasting solutions, advancing the integration of renewableenergy into global power systems.</description>
      <author>example@mail.com (Aditya Mishra, Ravindra T, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru)</author>
      <guid isPermaLink="false">2502.10307v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Robustness tests for biomedical foundation models should tailor to specification</title>
      <link>http://arxiv.org/abs/2502.10374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review, comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的生物医学AI监管框架中包括了鲁棒性作为关键组成部分，但缺乏详细的实施指导。随着生物医学基础模型的兴起，这些系统的能力范围广泛且容易受到复杂的数据分布变化的影响，这给测试和认证带来了新的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于优先级的任务导向方法，针对预定义规范来定制鲁棒性评估目标，以平衡测试可行性和有效性。&lt;h4&gt;方法&lt;/h4&gt;建议采用具体的政策来细化鲁棒性概念的分类，并推动风险评估与监控的标准制定。&lt;h4&gt;主要发现&lt;/h4&gt;该研究指出了一种标准化的风险评估和监控的方法可以指导技术发展及缓解措施的实施。&lt;h4&gt;结论&lt;/h4&gt;通过提出一种基于任务优先级的方法，结合具体的政策建议，在生物医学AI领域内促进鲁棒性概念的细化，并鼓励风险评估与监测的标准制定，从而提高整体系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;现有的生物医学人工智能（AI）监管框架虽然将稳健性作为关键要素之一，但缺乏详细的实施指导。近年来出现的生物医学基础模型因为其广泛的适用能力和对复杂数据分布变化的高度敏感性，为测试和认证带来了新的挑战。为了在保持测试可行性和有效性之间取得平衡，我们建议采取一种基于任务优先级的方法来根据预定义规范定制鲁棒性评估目标。此外，我们还呼吁采用具体政策细化鲁棒性概念的分类，并促进风险评估与监控的标准制定。这种方法有助于推动技术发展和缓解措施实施过程中的标准化，从而提升整体系统的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing regulatory frameworks for biomedical AI include robustness as a keycomponent but lack detailed implementational guidance. The recent rise ofbiomedical foundation models creates new hurdles in testing and certificationgiven their broad capabilities and susceptibility to complex distributionshifts. To balance test feasibility and effectiveness, we suggest apriority-based, task-oriented approach to tailor robustness evaluationobjectives to a predefined specification. We urge concrete policies to adopt agranular categorization of robustness concepts in the specification. Ourapproach promotes the standardization of risk assessment and monitoring, whichguides technical developments and mitigation efforts.</description>
      <author>example@mail.com (R. Patrick Xian, Noah R. Baker, Tom David, Qiming Cui, A. Jay Holmgren, Stefan Bauer, Madhumita Sushil, Reza Abbasi-Asl)</author>
      <guid isPermaLink="false">2502.10374v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Diverse Inference and Verification for Advanced Reasoning</title>
      <link>http://arxiv.org/abs/2502.09955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  165 pages. arXiv admin note: text overlap with arXiv:2001.04383 by  other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种结合多种模型和方法的推理大语言模型的方法，能够有效解决国际数学奥林匹克竞赛组合题、抽象与推理语料库（ARC）难题以及人类最后考试（HLE）问题。&lt;h4&gt;背景&lt;/h4&gt;现有的推理LLM在数学和编码领域取得了显著进步，但在处理像IMO组合题、ARC谜题及HLE这类高级任务时仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过多样化的推断方法来提高上述问题的解答准确度，并探索改进模型泛化能力的技术。&lt;h4&gt;方法&lt;/h4&gt;使用了一种在测试时间结合多个模型和方法的方法，包括自动验证数学和代码问题答案的正确性、对其他类型的问题进行拒绝抽样。另外还应用了最佳N策略来回答HLE问题。&lt;h4&gt;主要发现&lt;/h4&gt;该研究通过测试时模拟、强化学习以及元学习等技术提高了模型的泛化能力，并且在解决ARC难题上超越了人类的表现和o3高计算资源。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法可靠、稳健并且具有可扩展性，为未来的研究提供了有价值的方向，并计划在论文发表后公开源代码以促进复制研究。&lt;h4&gt;翻译&lt;/h4&gt;推理大语言模型（如OpenAI的o1、o3以及DeepSeek R1）在数学和编程方面取得了显著进步，但在解决国际数学奥林匹克竞赛组合题、抽象与推理语料库难题以及人类最后考试问题等高级任务时仍然面临挑战。我们采用了结合多种模型及方法进行推断的方法，在测试时间中利用这种方法来验证答案的正确性，并对其他类型的问题实施拒绝采样技术。通过Lean和代码自动检验IMO和ARC问题的答案，最佳N策略则被用来回答HLE问题。本研究将IMO组合题解题准确率从33.3%提升到了77.8%，提高了HLE问题的解答正确性至37%，并且能够解决80%人类无法完成以及o3高计算资源未能解决的ARC谜题。通过测试时模拟、强化学习及元学习技术的应用，模型泛化能力得到显著提高，并在处理复杂推理任务上表现出色。这项工作可靠、稳健且具备可扩展性，为了促进可重复研究的原则，在论文发表后将会公开源代码供进一步探索使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significantprogress in mathematics and coding, yet find challenging advanced tasks such asInternational Mathematical Olympiad (IMO) combinatorics problems, Abstractionand Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions.We use a diverse inference approach that combines multiple models and methodsat test time. We find that verifying mathematics and code problems, andrejection sampling on other problems is simple and effective. We automaticallyverify correctness of solutions to IMO problems by Lean, and ARC puzzles bycode, and find that best-of-N effectively answers HLE questions. Our approachincreases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%,accuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that948 humans could not and 26.5% of ARC puzzles that o3 high compute does not.Test-time simulations, reinforcement learning, and meta-learning with inferencefeedback improve generalization by adapting agent graph representations andvarying prompts, code, and datasets. Our approach is reliable, robust, andscalable, and in the spirit of reproducible research, we will make it publiclyavailable upon publication.</description>
      <author>example@mail.com (Iddo Drori, Gaston Longhitano, Mao Mao, Seunghwan Hyun, Yuke Zhang, Sungjun Park, Zachary Meeks, Xin-Yu Zhang, Ben Segev, Howard Yong, Nakul Verma, Avi Shporer, Alon Amit, Madeleine Udell)</author>
      <guid isPermaLink="false">2502.09955v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2502.10392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种高效的多级卷积架构用于3D视觉定位。&lt;h4&gt;背景&lt;/h4&gt;传统的两阶段或基于点的方法难以满足实时推理的需求。受三维物体检测中稀疏全卷积架构成功的启发，作者旨在构建一个新的三维视觉定位框架。&lt;h4&gt;目的&lt;/h4&gt;通过文本指导的剪枝（TGP）和完成基线加法（CBA），高效融合3D场景表示与文本特征，并在保持计算效率的同时避免过度裁减细节几何信息。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的3D视觉定位框架，包括基于文本引导的稀疏化以及通过目标区域补全进行有效融合的方法。这种方法能够在减少计算开销的前提下深度交互三维空间和文本描述的信息。&lt;h4&gt;主要发现&lt;/h4&gt;相比之前的单阶段方法，该方法在推断速度上达到了顶尖水平，并且超过了现有最快的100 FPS；与两阶段方法比较时，准确率也领先。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架不仅实现了实时性要求，在精度方面与其他先进方法相比也有显著提升。源代码可以在指定的GitHub仓库中找到。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种用于3D视觉定位的有效多级卷积架构。传统的两阶段或基于点的方法由于难以满足实时推理的需求而变得不实用。受三维物体检测领域稀疏全卷积架构成功的激励，我们的目标是建立一个跟随这一技术路线的新的3D视觉定位框架。然而，在3D视觉定位任务中，3D场景表示应该与文本特征深度交互，基于稀疏卷积的架构由于大量的体素特征而变得低效。因此，我们提出了基于文本引导的剪枝(TGP)和完成基线加法(CBA)，以通过逐区域裁减和目标补全的方式有效地融合3D场景表示与文本特征。具体来说，TGP迭代地稀疏化了三维场景表示，并且通过交叉注意力机制高效地将体素特征与文本特征相互作用。为了减轻剪枝对精细几何信息的影响，CBA适应性地修复过度裁减的区域，而计算开销可以忽略不计。相比于之前的单阶段方法，我们的方法实现了顶尖的推理速度，比最快的现有方法提高了100 FPS。在精度方面，与两阶段方法相比，即使与其他最先进的方法比较时也表现出领先的准确性，在ScanRefer上的Acc@0.5指标上领先了+1.13，在NR3D和SR3D上分别获得了2.6和3.2的提升。代码可在指定的GitHub仓库中找到（https://github.com/GWxuan/TSP3D）.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose an efficient multi-level convolution architecturefor 3D visual grounding. Conventional methods are difficult to meet therequirements of real-time inference due to the two-stage or point-basedarchitecture. Inspired by the success of multi-level fully sparse convolutionalarchitecture in 3D object detection, we aim to build a new 3D visual groundingframework following this technical route. However, as in 3D visual groundingtask the 3D scene representation should be deeply interacted with textfeatures, sparse convolution-based architecture is inefficient for thisinteraction due to the large amount of voxel features. To this end, we proposetext-guided pruning (TGP) and completion-based addition (CBA) to deeply fuse 3Dscene representation and text features in an efficient way by gradual regionpruning and target completion. Specifically, TGP iteratively sparsifies the 3Dscene representation and thus efficiently interacts the voxel features withtext features by cross-attention. To mitigate the affect of pruning on delicategeometric information, CBA adaptively fixes the over-pruned region by voxelcompletion with negligible computational overhead. Compared with previoussingle-stage methods, our method achieves top inference speed and surpassesprevious fastest method by 100\% FPS. Our method also achieves state-of-the-artaccuracy even compared with two-stage methods, with $+1.13$ lead of Acc@0.5 onScanRefer, and $+2.6$ and $+3.2$ leads on NR3D and SR3D respectively. The codeis available at\href{https://github.com/GWxuan/TSP3D}{https://github.com/GWxuan/TSP3D}.</description>
      <author>example@mail.com (Wenxuan Guo, Xiuwei Xu, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu)</author>
      <guid isPermaLink="false">2502.10392v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Looking around you: external information enhances representations for event sequences</title>
      <link>http://arxiv.org/abs/2502.10205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的表示学习方法，该方法通过聚合多个用户信息来增强特定用户的表示，尤其适用于处理具有多并发事件序列的场景。&lt;h4&gt;背景&lt;/h4&gt;传统的顺序数据模型通常只考虑单个序列的数据，忽略了其他相关序列提供的上下文信息。特别是在金融等外部环境变化迅速的领域，单一序列的信息不足以准确预测。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有表示学习中忽略上下文信息的问题，尤其是在处理多并发事件序列时的情况。&lt;h4&gt;方法&lt;/h4&gt;使用了多种聚合技术，从简单的池化方法到基于可训练注意力的方法（特别是Kernel注意机制），该机制能够突出显示来自其他用户的复杂信息流。这种方法可以建立在现有的编码器之上，并支持其有效的微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在金融交易数据集和下游任务上，Kernel注意力聚合改进了ROC AUC评分，无论是否进行微调；而平均池化也提供了一定程度的性能提升，尽管不如前者显著。&lt;h4&gt;结论&lt;/h4&gt;提出的聚合信息方法有效提升了模型对于多并发事件序列场景的表现能力。特别是Kernel注意机制在多种情况下都展示了比其他简单技术更好的效果。&lt;h4&gt;翻译&lt;/h4&gt;表示学习产生跨不同领域的模型，例如商店购买、客户交易和普通人的行为模式。然而，这些针对顺序数据的模型通常处理单个序列，忽略来自其他相关序列的信息上下文，甚至误导没有最近事件记录用户的预测。我们首次提出了一种方法，该方法通过聚合多个用户表示来增强特定用户的一个表示，适用于多并发事件序列的情景。我们的研究考虑了多样化的聚合方式，从简单的池化技术到可训练的基于注意力的方法（特别是内核注意聚合），这种机制可以强调来自其他用户的更复杂的信息流动。所提出的方法建立在现有的编码器之上，并支持其有效的微调。在考虑的金融交易数据集和下游任务中，内核注意改进了ROC AUC分数，在有无微调的情况下都有效果；而平均池化虽然效果较小但仍具有显著性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning produces models in different domains, such as storepurchases, client transactions, and general people's behaviour. However, suchmodels for sequential data usually process a single sequence, ignoring contextfrom other relevant ones, even in domains with rapidly changing externalenvironments like finance or misguiding the prediction for a user with norecent events.  We are the first to propose a method that aggregates information frommultiple user representations augmenting a specific user one for a scenario ofmultiple co-occurring event sequences. Our study considers diverse aggregationapproaches, ranging from simple pooling techniques to trainable attention-basedapproaches, especially Kernel attention aggregation, that can highlight morecomplex information flow from other users. The proposed method operates atop anexisting encoder and supports its efficient fine-tuning. Across considereddatasets of financial transactions and downstream tasks, Kernel attentionimproves ROC AUC scores, both with and without fine-tuning, while mean poolingyields a smaller but still significant gain.</description>
      <author>example@mail.com (Maria Kovaleva, Petr Sokerin, Sofia Krehova, Alexey Zaytsev)</author>
      <guid isPermaLink="false">2502.10205v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks via Node Feature and Structural Perturbations</title>
      <link>http://arxiv.org/abs/2502.10111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图神经网络解释器COMBINEX，该工具生成针对节点和图分类任务的反事实解释。通过统一的方法优化结构变化和特征扰动，确保预测翻转所需的最小且有效的改变。&lt;h4&gt;背景&lt;/h4&gt;当前技术主要关注边修改，而忽视了节点属性扰动在形成模型预测中的关键作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够平衡对边和节点属性的修改的新方法COMBINEX。&lt;h4&gt;方法&lt;/h4&gt;通过联合优化边缘和节点特征的变化来实现最优解，同时处理连续和离散的节点特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法在现实世界数据集上比现有的基线更有效且稳健。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的解释器COMBINEX，它提供了一个更为全面和有效的反事实解释框架，适用于各种图神经网络架构。&lt;h4&gt;翻译&lt;/h4&gt;反事实解释已成为揭开图神经网络决策过程不透明性的一个强大工具。然而现有的技术主要集中在边缘修改上，常常忽略了节点属性扰动在塑造模型预测中的关键作用。为了弥补这一局限，我们提出了一种新的GNN解释器COMBINEX，它为节点和图形分类任务生成反事实解释。不同于先前的方法仅独立处理结构变化和特征变化，COMBINEX通过联合优化这些修改来最佳平衡边缘和节点属性的变化。这种方法确保了翻转模型预测所需的最小且有效的改变，从而产生了现实而可解释的反事实结果。此外，COMBINEX可以无缝处理连续和离散的节点特性，增强了其在各种数据集和GNN架构中的适用性。对真实世界的数据集和不同GNN架构进行的广泛实验显示了我们方法相对于现有基线的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Counterfactual explanations have emerged as a powerful tool to unveil theopaque decision-making processes of graph neural networks (GNNs). However,existing techniques primarily focus on edge modifications, often overlookingthe crucial role of node feature perturbations in shaping model predictions. Toaddress this limitation, we propose COMBINEX, a novel GNN explainer thatgenerates counterfactual explanations for both node and graph classificationtasks. Unlike prior methods, which treat structural and feature-based changesindependently, COMBINEX optimally balances modifications to edges and nodefeatures by jointly optimizing these perturbations. This unified approachensures minimal yet effective changes required to flip a model's prediction,resulting in realistic and interpretable counterfactuals. Additionally,COMBINEX seamlessly handles both continuous and discrete node features,enhancing its versatility across diverse datasets and GNN architectures.Extensive experiments on real-world datasets and various GNN architecturesdemonstrate the effectiveness and robustness of our approach over existingbaselines.</description>
      <author>example@mail.com (Flavio Giorgi, Fabrizio Silvestri, Gabriele Tolomei)</author>
      <guid isPermaLink="false">2502.10111v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Camera Bias of Person Re-identification</title>
      <link>http://arxiv.org/abs/2502.10195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实证研究了人员重新识别（ReID）模型中的相机偏差问题，并提出了一种简单有效的特征归一化方法来减少未知领域数据的偏见。&lt;h4&gt;背景&lt;/h4&gt;之前的研究提出了多种处理相机感知的方法，但这些方法主要局限于训练域。在新的、未见过的数据集上测量ReID模型时，发现相机偏置更加明显。&lt;h4&gt;目的&lt;/h4&gt;旨在研究和缓解人员重新识别（ReID）模型中的相机偏差问题，并探索特征归一化作为减轻这种偏差的有效性。&lt;h4&gt;方法&lt;/h4&gt;分析了嵌入向量上的特征规范化在减少相机偏差方面的有效性。此外，还探讨了解决无监督学习中ReID模型相机偏置的简单训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;1. 特征归一化可以有效降低多种详细偏见因素的影响，如图像低级属性和身体角度。2. 在各种模型和基准测试上的广泛适用性验证了其作为人员重新识别（ReID）时简明有效的测试后处理方法的潜力。3. 无监督学习中，即使是在已见过的数据域上，ReID模型仍然高度倾向于相机标签，表明存在显著改进空间。&lt;h4&gt;结论&lt;/h4&gt;通过简单的训练策略对现有无监督算法进行修改可以实现性能的显著提升。这些发现为解决人员重新识别中的相机偏差问题提供了新的视角和方法。&lt;h4&gt;翻译&lt;/h4&gt;我们通过实证研究了人员重识别（ReID）模型中相机偏见的问题，并测量了未见过的数据域上的相机偏差现象，揭示其在数据分布变化时更加突出的现象。作为针对未知领域数据的去偏方法，重新审视了嵌入向量上特征归一化的应用，分析其有效性并展示了它应用于多种细节偏置因素的能力。验证了该方法在不同模型和基准测试中的泛化能力，并指出无监督学习中ReID模型存在相机偏见的风险。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We empirically investigate the camera bias of person re-identification (ReID)models. Previously, camera-aware methods have been proposed to address thisissue, but they are largely confined to training domains of the models. Wemeasure the camera bias of ReID models on unseen domains and reveal that camerabias becomes more pronounced under data distribution shifts. As a debiasingmethod for unseen domain data, we revisit feature normalization on embeddingvectors. While the normalization has been used as a straightforward solution,its underlying causes and broader applicability remain unexplored. We analyzewhy this simple method is effective at reducing bias and show that it can beapplied to detailed bias factors such as low-level image properties and bodyangle. Furthermore, we validate its generalizability across various models andbenchmarks, highlighting its potential as a simple yet effective test-timepostprocessing method for ReID. In addition, we explore the inherent risk ofcamera bias in unsupervised learning of ReID models. The unsupervised modelsremain highly biased towards camera labels even for seen domain data,indicating substantial room for improvement. Based on observations of thenegative impact of camera-biased pseudo labels on training, we suggest simpletraining strategies to mitigate the bias. By applying these strategies toexisting unsupervised learning algorithms, we show that significant performanceimprovements can be achieved with minor modifications.</description>
      <author>example@mail.com (Myungseo Song, Jin-Woo Park, Jong-Seok Lee)</author>
      <guid isPermaLink="false">2502.10195v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>STAR: Spectral Truncation and Rescale for Model Merging</title>
      <link>http://arxiv.org/abs/2502.10339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Spectral Truncation And Rescale (STAR)的方法，用于解决模型合并时任务性能下降的问题。&lt;h4&gt;背景&lt;/h4&gt;模型融合是一种从多个预训练模型中获取多任务模型的有效方式，尽管这种方法高效，但在增加模型数量的过程中会出现不可避免的任务性能下降问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为STAR的技术来减轻“合并冲突”，并保持原始矩阵的核范数。&lt;h4&gt;方法&lt;/h4&gt;通过截断每个模型在相应频谱空间中的小分量，并随后采用自动参数调整方案以保留原始矩阵的核范数。&lt;h4&gt;主要发现&lt;/h4&gt;STAR技术在广泛的NLP任务中进行了多种模型融合案例验证，展示出了良好的效果。STAR能够稳健地处理不同规模的模型合并，并且在合并12个Flan-T5模型时可以超越基线4.2%的表现。&lt;h4&gt;结论&lt;/h4&gt;STAR方法不需要额外的原始训练数据推理，并对超参数选择具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：模型融合是从多个预训练模型中获得多任务模型的一种有效方式，无需进一步微调，并且在自然语言处理（NLP）等多个领域获得了关注。尽管高效，但模型合并的关键挑战在于随着模型数量的增加似乎不可避免地导致任务性能下降。本文提出了一种名为Spectral Truncation And Rescale (STAR)的方法，旨在通过截断每个模型在相应频谱空间中的小分量来减轻“合并冲突”，随后采用自动参数调整方案以保留原始矩阵的核范数。STAR不需要额外的原始训练数据推理，并对超参数选择具有鲁棒性。我们通过对各种NLP任务进行了广泛的模型融合案例，展示了STAR的有效性。具体来说，STAR能够稳健地处理不同规模的模型合并，并且在合并12个Flan-T5模型时可以超越基线4.2%的表现。我们的代码可从https://github.com/IBM/STAR获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging is an efficient way of obtaining a multi-task model fromseveral pretrained models without further fine-tuning, and it has gainedattention in various domains, including natural language processing (NLP).Despite the efficiency, a key challenge in model merging is the seeminglyinevitable decrease in task performance as the number of models increases. Inthis paper, we propose $\mathbf{S}$pectral $\mathbf{T}$runcation $\mathbf{A}$nd$\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' bytruncating small components in the respective spectral spaces, which isfollowed by an automatic parameter rescaling scheme to retain the nuclear normof the original matrix. STAR requires no additional inference on originaltraining data and is robust to hyperparamater choice. We demonstrate theeffectiveness of STAR through extensive model merging cases on diverse NLPtasks. Specifically, STAR works robustly across varying model sizes, and canoutperform baselines by 4.2$\%$ when merging 12 models on Flan-T5. Our code ispublicly available at https://github.com/IBM/STAR.</description>
      <author>example@mail.com (Yu-Ang Lee, Ching-Yun Ko, Tejaswini Pedapati, I-Hsin Chung, Mi-Yen Yeh, Pin-Yu Chen)</author>
      <guid isPermaLink="false">2502.10339v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.09931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;提出了TransGUNet框架，结合了注意力跨尺度图神经网络(ACS-GNN)和基于熵驱动特征选择(EFS)的空间注意机制。&lt;h4&gt;背景&lt;/h4&gt;在医学图像分割中，跳跃连接主要用于解决编码器和解码器之间的语义间隙，并整合全局依赖性以理解复杂解剖结构的关系。尽管一些模型提出了使用变压器的跳过连接来包含全局依赖性的方法，但它们通常难以同时捕捉详细的局部特征并且计算复杂度高。&lt;h4&gt;目的&lt;/h4&gt;为了改进医学图像分割中的跳跃连接框架并解决深层学习模型产生无信息特征图的问题，引入了一种结合了注意力跨尺度图神经网络(ACS-GNN)和基于熵驱动特征选择(EFS)的空间注意机制的新方法。&lt;h4&gt;方法&lt;/h4&gt;提出了TransGUNet框架：1. ACS-GNN将跨尺度特征图转换为图形结构并通过节点关注捕捉复杂解剖结构。2. EFS与空间注意力相结合，计算每个通道的熵分数并过滤掉高熵特征图。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合实验和分析，TransGUNet在六种已见数据集和八种未见数据集中达到了优越的分割性能，并且其效率明显高于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;TransGUNet能够有效地增强跨不同模态的域泛化能力，通过利用图神经网络以及可靠的空间注意图确保跳跃连接中的更稳健特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Skip connection engineering is primarily employed to address the semantic gapbetween the encoder and decoder, while also integrating global dependencies tounderstand the relationships among complex anatomical structures in medicalimage segmentation. Although several models have proposed transformer-basedapproaches to incorporate global dependencies within skip connections, theyoften face limitations in capturing detailed local features with highcomputational complexity. In contrast, graph neural networks (GNNs) exploitgraph structures to effectively capture local and global features. Leveragingthese properties, we introduce an attentional cross-scale graph neural network(ACS-GNN), which enhances the skip connection framework by convertingcross-scale feature maps into a graph structure and capturing complexanatomical structures through node attention. Additionally, we observed thatdeep learning models often produce uninformative feature maps, which degradesthe quality of spatial attention maps. To address this problem, we integratedentropy-driven feature selection (EFS) with spatial attention, calculating anentropy score for each channel and filtering out high-entropy feature maps. Ourinnovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatialattentio} to effectively enhance domain generalizability across variousmodalities by leveraging GNNs alongside a reliable spatial attention map,ensuring more robust features within the skip connection. Through comprehensiveexperiments and analysis, TransGUNet achieved superior segmentation performanceon six seen and eight unseen datasets, demonstrating significantly higherefficiency compared to previous methods.</description>
      <author>example@mail.com (Ju-Hyeon Nam, Nur Suriza Syazwany, Sang-Chul Lee)</author>
      <guid isPermaLink="false">2502.09931v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning on Out of Distribution in Tabular Data</title>
      <link>http://arxiv.org/abs/2502.10095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了TCL，一种轻量级且有效的解决方案，适用于标准CPU硬件处理开放世界假设下的数据。该方法通过对比学习原则适应表格数据结构，并引入全矩阵增强和简化损失计算。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在处理OOD（非分布）数据方面表现出色，但通常需要专用硬件支持，这限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轻量级解决方案TCL，以便于使用标准CPU硬件高效运行，并且在分类和回归任务中实现高性能。&lt;h4&gt;方法&lt;/h4&gt;采用对比学习原则适应表格数据结构，引入全矩阵增强和简化损失计算的方法来处理OOD问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过10种不同数据集的全面实验表明，TCL在分类任务上优于现有模型（如FT-Transformer和ResNet），同时保持了回归问题中的竞争力。此外，该方法减少了计算需求，使得资源受限用户也能使用。&lt;h4&gt;结论&lt;/h4&gt;TCL提供了一种性能与效率之间的良好平衡，对于处理OOD预测任务非常有益，并且为检测和评估OOD数据提供了实用指导。&lt;h4&gt;翻译&lt;/h4&gt;开放世界假设下的模型开发表明，模型可能缺乏足够的信息来有效应对完全不同的或非分布的数据。虽然深度学习方法通过泛化技术展示了对OOD数据的出色结果，但它们往往需要专用硬件的支持，这并非所有用户都能获得。我们提出了TCL，一种轻量级且高效的解决方案，在标准CPU硬件上运行。我们的方法采用对比学习原则适应表格数据结构，并引入了全矩阵增强和简化损失计算。通过在10种不同数据集上的全面实验，我们展示了TCL优于现有模型（包括FT-Transformer和ResNet），特别是在分类任务中，同时保持回归问题中的竞争性能。TCL以显著减少的计算需求实现了这些结果，使其成为硬件能力有限用户的理想选择。本研究还提供了通过简单实验和可视化来检测和评估OOD数据的实际指导。我们的发现表明，TCL为处理OOD预测任务提供了一种性能与效率之间的良好平衡，这特别有益于面对计算限制的一般机器学习从业者。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The open-world assumption in model development suggests that a model mightlack sufficient information to adequately handle data that is entirely distinctor out of distribution (OOD). While deep learning methods have shown promisingresults in handling OOD data through generalization techniques, they oftenrequire specialized hardware that may not be accessible to all users. Wepresent TCL, a lightweight yet effective solution that operates efficiently onstandard CPU hardware. Our approach adapts contrastive learning principlesspecifically for tabular data structures, incorporating full matrixaugmentation and simplified loss calculation. Through comprehensive experimentsacross 10 diverse datasets, we demonstrate that TCL outperforms existingmodels, including FT-Transformer and ResNet, particularly in classificationtasks, while maintaining competitive performance in regression problems. TCLachieves these results with significantly reduced computational requirements,making it accessible to users with limited hardware capabilities. This studyalso provides practical guidance for detecting and evaluating OOD data throughstraightforward experiments and visualizations. Our findings show that TCLoffers a promising balance between performance and efficiency in handling OODprediction tasks, which is particularly beneficial for general machine learningpractitioners working with computational constraints.</description>
      <author>example@mail.com (Achmad Ginanjar, Xue Li, Priyanka Singh, Wen Hua)</author>
      <guid isPermaLink="false">2502.10095v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>ExoMiner++ on TESS with Transfer Learning from Kepler: Transit Classification and Vetting Catalog for 2-min Data</title>
      <link>http://arxiv.org/abs/2502.09790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ExoMiner++ 是一种改进的深度学习模型，旨在提高TESS 2分钟数据中过渡信号分类的准确性。&lt;h4&gt;背景&lt;/h4&gt;ExoMiner 是一个成功的过渡信号分类器，而 ExoMiner++ 在其基础上引入了更多诊断输入信息以进一步提升性能。&lt;h4&gt;目的&lt;/h4&gt;通过结合来自开普勒太空望远镜的高质量标记数据进行迁移学习，提高在TESS较为嘈杂和模糊标签下的表现，并为系外行星社区提供新的分类目录。&lt;h4&gt;方法&lt;/h4&gt;ExoMiner++ 采用了包括周期图、通量趋势、差异图像、未折叠通量以及航天器姿态控制数据在内的额外诊断输入信息。此外，模型利用了开普勒空间望远镜的高质量标签数据进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;在总计147,568个未标记的TESS候选事件（TCE）中，ExoMiner++ 将其中的7330个识别为系外行星候选者。这些候选者中有1,868个是已知的TOI，69个是社区关注的CTOI以及50个新的CTOI。&lt;h4&gt;结论&lt;/h4&gt;通过减少潜在的候选者的数量并提高排名质量，使得后续调查可以更加集中于最有潜力的系外行星候选人上，从而提高了整个系外行星产出效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present ExoMiner++, an enhanced deep learning model that builds on thesuccess of ExoMiner to improve transit signal classification in 2-minute TESSdata. ExoMiner++ incorporates additional diagnostic inputs, includingperiodogram, flux trend, difference image, unfolded flux, and spacecraftattitude control data, all of which are crucial for effectively distinguishingtransit signals from more challenging sources of false positives. To furtherenhance performance, we leverage transfer learning from high-quality labeleddata from the Kepler space telescope, mitigating the impact of TESS's noisierand more ambiguous labels. ExoMiner++ achieves high accuracy across variousclassification and ranking metrics, significantly narrowing the search spacefor follow-up investigations to confirm new planets. To serve the exoplanetcommunity, we introduce new TESS catalogs containing ExoMiner++ classificationsand confidence scores for each transit signal. Among the 147,568 unlabeledTCEs, ExoMiner++ identifies 7,330 as planet candidates, with the remainderclassified as false positives. These 7,330 planet candidates correspond to1,868 existing TESS Objects of Interest (TOIs), 69 Community TESS Objects ofInterest (CTOIs), and 50 newly introduced CTOIs. 1,797 out of the 2,506 TOIspreviously labeled as planet candidates in ExoFOP are classified as planetcandidates by ExoMiner++. This reduction in plausible candidates combined withthe excellent ranking quality of ExoMiner++ allows the follow-up efforts to befocused on the most likely candidates, increasing the overall planet yield.</description>
      <author>example@mail.com (Hamed Valizadegan, Miguel J. S. Martinho, Jon M. Jenkins, Joseph D. Twicken, Douglas A. Caldwell, Patrick Maynard, Hongbo Wei, William Zhong, Charles Yates, Sam Donald, Karen A. Collins, David Latham, Khalid Barkaoui, Perry Berlind, Michael L. Calkins, Kylee Carden, Nikita Chazov, Gilbert A. Esquerdo, Tristan Guillot, Vadim Krushinsky, Grzegorz Nowak, Benjamin V. Rackham, Amaury Triaud, Richard P. Schwarz, Denise Stephens, Chris Stockdale, Jiaqi Wang, Cristilyn N. Watkins, Francis P. Wilkin)</author>
      <guid isPermaLink="false">2502.09790v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning</title>
      <link>http://arxiv.org/abs/2502.10038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了一种用于改善POI表示学习的框架，即POI-Enhancer。该框架利用大型语言模型（LLMs）来提升由经典POI学习模型生成的POI表示。&lt;h4&gt;背景&lt;/h4&gt;POI表示学习在处理与用户移动性相关的任务中起着关键作用。现有方法通常只使用POI类别或签到内容等文本信息，导致弱化的文本特征。相比之下，训练于大量文本数据上的大型语言模型具备丰富的文本知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用LLMs知识来增强POI表示学习的方法，并解决从LLMs中提取和整合POI相关知识的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了三个特殊提示以高效地从LLMs中抽取语义信息。使用Dual Feature Alignment模块提升所提取的信息质量，Semantic Feature Fusion模块保持其完整性。通过Cross Attention Fusion模块将高质量信息充分融合进POI表示，并利用多视图对比学习进一步注入人类可理解的语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在三个真实世界数据集上均表现优异，相较于所有基线方法有显著改进。&lt;h4&gt;结论&lt;/h4&gt;提出的新框架POI-Enhancer展现了利用大型语言模型增强POI表示学习的有效性，并为未来相关研究提供了新的思路和方向。&lt;h4&gt;翻译&lt;/h4&gt;POI表示学习在处理用户移动数据的任务中扮演着关键角色。最近的研究表明，通过多模态信息丰富POI表示可以显著提升任务性能。然而，传统的POI表示通常仅包含POI类别或签到内容等文本信息，导致现有方法中的文本特征相对薄弱。相比之下，大型语言模型（LLMs）训练于大量文本数据上，具备丰富的文本知识。但如何有效利用这些知识来增强POI表示学习，则面临两个主要挑战：一是如何从LLMs中提取POI相关知识；二是如何整合所提取的信息以改进POI表示。为此，我们提出了一种便携式框架POI-Enhancer，它利用大型语言模型来改善经典POI学习模型生成的POI表示。首先设计了三种专门提示，用于高效抽取LLMs中的语义信息。然后通过Dual Feature Alignment模块提升所提取的信息质量，并用Semantic Feature Fusion模块保持其完整性。最后通过Cross Attention Fusion模块将高质量信息充分融合进POI表示中，并利用多视图对比学习注入人类可理解的语义信息。在三个真实世界数据集上的大量实验结果表明，我们的框架表现出了显著效果，相较于所有基线方法均有大幅提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; POI representation learning plays a crucial role in handling tasks related touser mobility data. Recent studies have shown that enriching POIrepresentations with multimodal information can significantly enhance theirtask performance. Previously, the textual information incorporated into POIrepresentations typically involved only POI categories or check-in content,leading to relatively weak textual features in existing methods. In contrast,large language models (LLMs) trained on extensive text data have been found topossess rich textual knowledge. However leveraging such knowledge to enhancePOI representation learning presents two key challenges: first, how to extractPOI-related knowledge from LLMs effectively, and second, how to integrate theextracted information to enhance POI representations. To address thesechallenges, we propose POI-Enhancer, a portable framework that leverages LLMsto improve POI representations produced by classic POI learning models. Wefirst design three specialized prompts to extract semantic information fromLLMs efficiently. Then, the Dual Feature Alignment module enhances the qualityof the extracted information, while the Semantic Feature Fusion modulepreserves its integrity. The Cross Attention Fusion module then fullyadaptively integrates such high-quality information into POI representationsand Multi-View Contrastive Learning further injects human-understandablesemantic information into these representations. Extensive experiments on threereal-world datasets demonstrate the effectiveness of our framework, showingsignificant improvements across all baseline representations.</description>
      <author>example@mail.com (Jiawei Cheng, Jingyuan Wang, Yichuan Zhang, Jiahao Ji, Yuanshao Zhu, Zhibo Zhang, Xiangyu Zhao)</author>
      <guid isPermaLink="false">2502.10038v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating and Improving Graph-based Explanation Methods for Multi-Agent Coordination</title>
      <link>http://arxiv.org/abs/2502.09889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨并描述了现有的图神经网络解释方法在多智能体协调中的适用性，提出了一个注意力熵正则化项以提高现有图形解释器的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，图神经网络（GNN）被用于机器人和代理人的学习，并取得了显著的成功。这些成功促使研究者探索将现有的GNN解释方法应用于多智能体协同作业的可能性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在调查和描述当前存在的GNN解释方法是否适用于解释多智能体协调问题，并提出一种改进现有图形解释器性能的方法。&lt;h4&gt;方法&lt;/h4&gt;通过分析现有方法在识别对团队行为有重大影响的通信渠道方面的潜力，研究者提出了一个注意力熵正则化项。该正则化项使得基于图注意网络（GAT）的策略更容易被现有的基于图的解释器所理解。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，减少注意力熵可以增加生成的子图与其补集之间的差异性，从而提高现有图形解释器的有效性，并且不会影响任务性能。在三个不同任务和三种团队规模上的评估表明，提出的正则化项能够显著提升解释质量。&lt;h4&gt;结论&lt;/h4&gt;本文证明了现有的GNN解释方法可以在多智能体协调领域发挥重要作用，通过引入注意力熵正则化可以提高这些方法的效能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）由图形学习社区开发，在多机器人和多代理人的学习中被采用并显示出高度有效性。受此成功跨学科合作的启发，我们调查和描述了现有GNN解释方法在解释多智能体协调中的适用性。研究发现这些方法有能力识别对团队行为影响最大的通信渠道。基于初步分析，我们提出了一项注意力熵正则化措施，使基于图注意网络（GAT）的方法更容易被现有的图形解释器理解和使用。从理论上讲，减少注意力熵可以激励代理限制其关注范围在最具有影响力或影响力的代理上，从而减轻解释者面临的挑战。通过三个任务和三种团队规模的评估，一方面提供了对现有解释方法有效性的见解，另一方面也展示了我们的正则化策略能够持续提高解释质量而不会牺牲任务性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs), developed by the graph learning community, havebeen adopted and shown to be highly effective in multi-robot and multi-agentlearning. Inspired by this successful cross-pollination, we investigate andcharacterize the suitability of existing GNN explanation methods for explainingmulti-agent coordination. We find that these methods have the potential toidentify the most-influential communication channels that impact the team'sbehavior. Informed by our initial analyses, we propose an attention entropyregularization term that renders GAT-based policies more amenable to existinggraph-based explainers. Intuitively, minimizing attention entropy incentivizesagents to limit their attention to the most influential or impactful agents,thereby easing the challenge faced by the explainer. We theoretically groundthis intuition by showing that minimizing attention entropy increases thedisparity between the explainer-generated subgraph and its complement.Evaluations across three tasks and three team sizes i) provides insights intothe effectiveness of existing explainers, and ii) demonstrates that ourproposed regularization consistently improves explanation quality withoutsacrificing task performance.</description>
      <author>example@mail.com (Siva Kailas, Shalin Jain, Harish Ravichandar)</author>
      <guid isPermaLink="false">2502.09889v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</title>
      <link>http://arxiv.org/abs/2502.10248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Step-Video-T2V，这是一种先进的文本到视频的预训练模型，拥有30B参数的能力，并能够生成长达204帧的视频。&lt;h4&gt;背景&lt;/h4&gt;利用深度压缩变分自编码器（Video-VAE）进行视频生成任务，在保持高质量视频重建的同时实现了16x16空间和8x时间的压缩比率。&lt;h4&gt;目的&lt;/h4&gt;通过设计新的模型和技术，提高文本到视频转换的质量，并减少生成视频中的伪影。&lt;h4&gt;方法&lt;/h4&gt;使用两个双语文本编码器处理英文和中文提示；训练具有3D全注意力机制的DiT以去除输入噪声并转化为潜在帧；应用基于视频的DPO方法（Video-DPO）来改善视觉质量。此外，还详细介绍了培训策略、关键观察结果和见解。&lt;h4&gt;主要发现&lt;/h4&gt;通过新的基准测试Step-Video-T2V-Eval评估模型性能，显示出与开源及商用引擎相比，在文本到视频转换中的卓越表现。&lt;h4&gt;结论&lt;/h4&gt;讨论了基于扩散模型的当前范式的局限性，并提出了未来视频基础模型的发展方向。同时提供了模型和评价标准的访问方式以促进创新。&lt;h4&gt;翻译&lt;/h4&gt;论文介绍了一种名为Step-Video-T2V的前沿技术，能够将文本转换为高质量视频，同时提供详细的训练策略、观察结果以及对未来发展的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Step-Video-T2V, a state-of-the-art text-to-video pre-trained modelwith 30B parameters and the ability to generate videos up to 204 frames inlength. A deep compression Variational Autoencoder, Video-VAE, is designed forvideo generation tasks, achieving 16x16 spatial and 8x temporal compressionratios, while maintaining exceptional video reconstruction quality. Userprompts are encoded using two bilingual text encoders to handle both Englishand Chinese. A DiT with 3D full attention is trained using Flow Matching and isemployed to denoise input noise into latent frames. A video-based DPO approach,Video-DPO, is applied to reduce artifacts and improve the visual quality of thegenerated videos. We also detail our training strategies and share keyobservations and insights. Step-Video-T2V's performance is evaluated on a novelvideo generation benchmark, Step-Video-T2V-Eval, demonstrating itsstate-of-the-art text-to-video quality when compared with both open-source andcommercial engines. Additionally, we discuss the limitations of currentdiffusion-based model paradigm and outline future directions for videofoundation models. We make both Step-Video-T2V and Step-Video-T2V-Evalavailable at https://github.com/stepfun-ai/Step-Video-T2V. The online versioncan be accessed from https://yuewen.cn/videos as well. Our goal is toaccelerate the innovation of video foundation models and empower video contentcreators.</description>
      <author>example@mail.com (Guoqing Ma, Haoyang Huang, Kun Yan, Liangyu Chen, Nan Duan, Shengming Yin, Changyi Wan, Ranchen Ming, Xiaoniu Song, Xing Chen, Yu Zhou, Deshan Sun, Deyu Zhou, Jian Zhou, Kaijun Tan, Kang An, Mei Chen, Wei Ji, Qiling Wu, Wen Sun, Xin Han, Yanan Wei, Zheng Ge, Aojie Li, Bin Wang, Bizhu Huang, Bo Wang, Brian Li, Changxing Miao, Chen Xu, Chenfei Wu, Chenguang Yu, Dapeng Shi, Dingyuan Hu, Enle Liu, Gang Yu, Ge Yang, Guanzhe Huang, Gulin Yan, Haiyang Feng, Hao Nie, Haonan Jia, Hanpeng Hu, Hanqi Chen, Haolong Yan, Heng Wang, Hongcheng Guo, Huilin Xiong, Huixin Xiong, Jiahao Gong, Jianchang Wu, Jiaoren Wu, Jie Wu, Jie Yang, Jiashuai Liu, Jiashuo Li, Jingyang Zhang, Junjing Guo, Junzhe Lin, Kaixiang Li, Lei Liu, Lei Xia, Liang Zhao, Liguo Tan, Liwen Huang, Liying Shi, Ming Li, Mingliang Li, Muhua Cheng, Na Wang, Qiaohui Chen, Qinglin He, Qiuyan Liang, Quan Sun, Ran Sun, Rui Wang, Shaoliang Pang, Shiliang Yang, Sitong Liu, Siqi Liu, Shuli Gao, Tiancheng Cao, Tianyu Wang, Weipeng Ming, Wenqing He, Xu Zhao, Xuelin Zhang, Xianfang Zeng, Xiaojia Liu, Xuan Yang, Yaqi Dai, Yanbo Yu, Yang Li, Yineng Deng, Yingming Wang, Yilei Wang, Yuanwei Lu, Yu Chen, Yu Luo, Yuchu Luo, Yuhe Yin, Yuheng Feng, Yuxiang Yang, Zecheng Tang, Zekai Zhang, Zidong Yang, Binxing Jiao, Jiansheng Chen, Jing Li, Shuchang Zhou, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Heung-Yeung Shum, Daxin Jiang)</author>
      <guid isPermaLink="false">2502.10248v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.10157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了SessionRec框架，旨在解决传统下一项目预测范式与现实推荐场景之间的不匹配问题。&lt;h4&gt;背景&lt;/h4&gt;传统的下一个项目预测范式在处理实际基于会话的用户交互时存在缺陷。新的范式通过层次序列聚合和会话感知表示学习来减少注意力计算复杂性，并能够隐式建模大量的负面交互。&lt;h4&gt;目的&lt;/h4&gt;开发一个新型的下一会话推荐范式，以更好地捕捉用户的多样性兴趣并通过多项目推荐改善下一会话中的推荐效果。&lt;h4&gt;方法&lt;/h4&gt;引入了基于会话的预测目标和会话内部项目的排序损失来改进模型性能。该框架还展示了类似大语言模型的幂律扩展规律，并且实验验证了其在实际应用中的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;SessionRec能够有效提升生成式序列推荐系统的排名效果，同时保持计算效率并展示良好的扩展性。&lt;h4&gt;结论&lt;/h4&gt;提出的会话感知范式为大规模工业级推荐系统的发展建立了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了SessionRec，这是一种新颖的下一会话预测范式（NSPP），用于生成式的顺序推荐。该框架通过层次序列聚合和会话感知表示学习解决了传统下一个项目预测范式与现实世界推荐场景之间的基本不一致问题，并展示了显著提升模型排名效果的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce SessionRec, a novel next-session prediction paradigm (NSPP) forgenerative sequential recommendation, addressing the fundamental misalignmentbetween conventional next-item prediction paradigm (NIPP) and real-worldrecommendation scenarios. Unlike NIPP's item-level autoregressive generationthat contradicts actual session-based user interactions, our frameworkintroduces a session-aware representation learning through hierarchicalsequence aggregation (intra/inter-session), reducing attention computationcomplexity while enabling implicit modeling of massive negative interactions,and a session-based prediction objective that better captures users' diverseinterests through multi-item recommendation in next sessions. Moreover, wefound that incorporating a rank loss for items within the session under thenext session prediction paradigm can significantly improve the rankingeffectiveness of generative sequence recommendation models. We also verifiedthat SessionRec exhibits clear power-law scaling laws similar to those observedin LLMs. Extensive experiments conducted on public datasets and online A/B testin Meituan App demonstrate the effectiveness of SessionRec. The proposedparadigm establishes new foundations for developing industrial-scale generativerecommendation systems through its model-agnostic architecture andcomputational efficiency.</description>
      <author>example@mail.com (Lei Huang, Hao Guo, Linzhi Peng, Long Zhang, Xiaoteng Wang, Daoyuan Wang, Shichao Wang, Jinpeng Wang, Lei Wang, Sheng Chen)</author>
      <guid isPermaLink="false">2502.10157v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Resource Allocation with Multi-task Learning for Wireless Networks</title>
      <link>http://arxiv.org/abs/2502.10027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多任务学习的框架，该框架通过引入路由机制使单个深度神经网络能够解决具有不同维度、目标和约束条件的多种优化问题。&lt;h4&gt;背景&lt;/h4&gt;在无线网络环境中，由于存在多个且相互冲突的目标与限制条件，现有的深度神经网络（DNN）解决方案需要频繁调整或重新训练以适应变化。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入多任务学习框架来提高单个深度神经网络解决多样化优化问题的能力和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于条件计算的多任务学习方法，并设计了一个包含基础深度神经网络（bDNN）与路由深度神经网络（rDNN）两部分的模型，其中rDNN控制哪些节点和层在执行特定任务时被使用。通过这种方式，不同任务可以选择共享或独立使用参数。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够有效解决多种优化问题，并且实验结果表明其优于缺乏路由机制的标准深度神经网络。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于条件计算的多任务学习方法及其架构在处理具有多样化特性的无线网络中的优化问题是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：求解一个优化问题的最佳方案取决于该问题的目标函数、约束条件以及规模。尽管深度神经网络（DNN）已被证明能够有效地解决优化问题，但变化的问题大小或目标要求的调整通常需要对DNN架构进行更改才能保持其有效性，甚至可能需要从头开始重新训练新的DNN模型。鉴于无线网络动态特性涉及多个且多样化的目标及限制条件，本文提出了一种多任务学习（MTL）框架，该框架允许单个DNN同时解决各种不同的优化问题。在此框架下，具有不同维度值、目标和约束的优化问题是作为独立的任务来对待的。为了共同处理这些任务，我们提出了基于条件计算与路由的MTL方法。这个多任务DNN由两部分组成：基础深度神经网络（bDNN）用于提取所有考虑中的优化问题的解决方案；以及路由深度神经网络（rDNN），其管理着bDNN中哪些节点和层在每项任务向前传播时被使用。该架构支持监督学习与非监督学习场景，并且实验结果证明了所提出的MTL方法解决多样化优化问题的有效性。相比之下，没有rDNN机制的标准DNN模型无法达到同等性能水平，从而突显出提议架构的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The optimal solution to an optimization problem depends on the problem'sobjective function, constraints, and size. While deep neural networks (DNNs)have proven effective in solving optimization problems, changes in theproblem's size, objectives, or constraints often require adjustments to the DNNarchitecture to maintain effectiveness, or even retraining a new DNN fromscratch. Given the dynamic nature of wireless networks, which involve multipleand diverse objectives that can have conflicting requirements and constraints,we propose a multi-task learning (MTL) framework to enable a single DNN tojointly solve a range of diverse optimization problems. In this framework,optimization problems with varying dimensionality values, objectives, andconstraints are treated as distinct tasks. To jointly address these tasks, wepropose a conditional computation-based MTL approach with routing. Themulti-task DNN consists of two components, the base DNN (bDNN), which is thesingle DNN used to extract the solutions for all considered optimizationproblems, and the routing DNN (rDNN), which manages which nodes and layers ofthe bDNN to be used during the forward propagation of each task. The output ofthe rDNN is a binary vector which is multiplied with all bDNN's weights duringthe forward propagation, creating a unique computational path through the bDNNfor each task. This setup allows the tasks to either share parameters or useindependent ones, with the decision controlled by the rDNN. The proposedframework supports both supervised and unsupervised learning scenarios.Numerical results demonstrate the efficiency of the proposed MTL approach insolving diverse optimization problems. In contrast, benchmark DNNs lacking therDNN mechanism were unable to achieve similar levels of performance,highlighting the effectiveness of the proposed architecture.</description>
      <author>example@mail.com (Nikos A. Mitsiou, Pavlos S. Bouzinis, Panagiotis G. Sarigiannidis, George K. Karagiannidis)</author>
      <guid isPermaLink="false">2502.10027v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>IMM-MOT: A Novel 3D Multi-object Tracking Framework with Interacting Multiple Model Filter</title>
      <link>http://arxiv.org/abs/2502.09672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages,5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为IMM-MOT的3D多目标跟踪算法，该算法通过引入交互多重模型滤波器和基于距离的得分增强模块来提高复杂环境下的追踪精度。&lt;h4&gt;背景&lt;/h4&gt;现有的三维多物体跟踪方法通常采用单一运动模型进行物体全程追踪。然而，由于周围环境的变化，物体可能会改变其运动模式，导致现有方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D MOT算法IMM-MOT，通过更准确地捕捉单个目标的复杂运动模式来克服传统方法中单一运动模型跟踪的限制。&lt;h4&gt;方法&lt;/h4&gt;{'交互多重模型滤波器（IMM）': '用于适应不同环境下的物体动态变化，提高追踪精度。', '阻尼窗口机制': '用于管理和优化轨迹生命周期，减少漏检低置信度真目标的发生概率。', '基于距离的得分增强模块': '通过调整检测分数来区分假阳性和真实阳性，从而提升得分过滤器的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;在NuScenes Val数据集上，IMM-MOT算法超越了大多数其他使用3D点云的单一模型方法，在AMOTA指标上达到了73.8%。&lt;h4&gt;结论&lt;/h4&gt;通过引入交互多重模型滤波器、阻尼窗口机制以及基于距离的得分增强模块，IMM-MOT能够更准确地捕捉和追踪复杂环境下的物体运动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Multi-Object Tracking (MOT) provides the trajectories of surroundingobjects, assisting robots or vehicles in smarter path planning and obstacleavoidance. Existing 3D MOT methods based on the Tracking-by-Detection frameworktypically use a single motion model to track an object throughout its entiretracking process. However, objects may change their motion patterns due tovariations in the surrounding environment. In this paper, we introduce theInteracting Multiple Model filter in IMM-MOT, which accurately fits the complexmotion patterns of individual objects, overcoming the limitation ofsingle-model tracking in existing approaches. In addition, we incorporate aDamping Window mechanism into the trajectory lifecycle management, leveragingthe continuous association status of trajectories to control their creation andtermination, reducing the occurrence of overlooked low-confidence true targets.Furthermore, we propose the Distance-Based Score Enhancement module, whichenhances the differentiation between false positives and true positives byadjusting detection scores, thereby improving the effectiveness of the ScoreFilter. On the NuScenes Val dataset, IMM-MOT outperforms most othersingle-modal models using 3D point clouds, achieving an AMOTA of 73.8%. Ourproject is available at https://github.com/Ap01lo/IMM-MOT.</description>
      <author>example@mail.com (Xiaohong Liu, Xulong Zhao, Gang Liu, Zili Wu, Tao Wang, Lei Meng, Yuhan Wang)</author>
      <guid isPermaLink="false">2502.09672v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>KGGen: Extracting Knowledge Graphs from Plain Text with Language Models</title>
      <link>http://arxiv.org/abs/2502.09956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为KGGen的工具包，该工具包使用语言模型从纯文本生成高质量的知识图谱（KG），解决了知识图谱数据稀缺的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的最佳已知知识图谱主要是由人工标注、模式匹配或早期NLP技术提取出来的，自动提取的知识图谱质量存疑。这些方法产生的知识图谱要么资源有限，要么存在质量问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种名为KGGen的工具包，它使用语言模型从纯文本中生成高质量的知识图谱，以解决数据稀缺问题，并提供一个新的基准测试MINE来评估提取器的能力。&lt;h4&gt;方法&lt;/h4&gt;KGGen是一个Python库（pip install kg-gen），可以将相关实体聚类减少提取知识图谱中的稀疏性。同时发布了第一个测试提取器能力的基准测试MINE，用于从纯文本中生成有用的知识图谱。&lt;h4&gt;主要发现&lt;/h4&gt;通过与其他现有提取工具进行基准测试对比，KGGen表现出远超其他工具的能力。&lt;h4&gt;结论&lt;/h4&gt;KGGen提供了一种有效的方法来解决知识图谱数据稀缺的问题，并且可以通过Python库形式方便地获取和使用。&lt;h4&gt;翻译&lt;/h4&gt;最近对构建用于知识图谱（KG）的基础模型的兴趣突显了一个根本性挑战：即知识图谱的数据相对匮乏。最佳已知的知识图谱主要是通过人工标注、模式匹配或早期的NLP技术提取出来的，而由人类生成的知识图谱资源有限；自动提取的知识图谱质量存疑。我们提出了一种文本到KG生成器（KGGen），这是一个使用语言模型从纯文本创建高质量图的方法，并以Python库形式提供给所有人。与KGGen一起发布的还有第一个基准测试MINE，用于评估一个提取器从纯文本中生成有用知识图的能力。我们在现有提取工具上进行了基准测试并展示了其远超其他工具的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent interest in building foundation models for KGs has highlighted afundamental challenge: knowledge-graph data is relatively scarce. Thebest-known KGs are primarily human-labeled, created by pattern-matching, orextracted using early NLP techniques. While human-generated KGs are in shortsupply, automatically extracted KGs are of questionable quality. We present asolution to this data scarcity problem in the form of a text-to-KG generator(KGGen), a package that uses language models to create high-quality graphs fromplaintext. Unlike other KG extractors, KGGen clusters related entities toreduce sparsity in extracted KGs. KGGen is available as a Python library(\texttt{pip install kg-gen}), making it accessible to everyone. Along withKGGen, we release the first benchmark, Measure of of Information in Nodes andEdges (MINE), that tests an extractor's ability to produce a useful KG fromplain text. We benchmark our new tool against existing extractors anddemonstrate far superior performance.</description>
      <author>example@mail.com (Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, Sanmi Koyejo)</author>
      <guid isPermaLink="false">2502.09956v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>NeuralCFD: Deep Learning on High-Fidelity Automotive Aerodynamics Simulations</title>
      <link>http://arxiv.org/abs/2502.09692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近的神经算子学习进展为汽车空气动力学等领域带来了变革性的创新，但要实现工业级应用，仍需解决一些关键挑战。&lt;h4&gt;背景&lt;/h4&gt;当前基于神经网络的仿真代理技术在处理大规模表面和体积网格时面临可扩展性问题，并且需要大量的高保真数值模拟样本进行训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Geometry-preserving Universal Physics Transformer (GP-UPT)的新方法，旨在解决上述挑战并提高模型性能。&lt;h4&gt;方法&lt;/h4&gt;GP-UPT通过分离几何编码和物理预测，确保了对不同几何表示的灵活性和支持独立的表面采样策略。这使得模型的不同部分可以根据实际需求进行扩展。&lt;h4&gt;主要发现&lt;/h4&gt;GP-UPT能够避免生成高质量的仿真网格，同时在2000万个网格单元上准确预测三维速度场，并且从低保真度数据集转移到高保真度数据集时表现出色，仅需不到一半的高保真度数据即可达到与从头训练模型相当的表现。&lt;h4&gt;结论&lt;/h4&gt;GP-UPT提供了一种灵活、可扩展的方法来解决基于神经网络的仿真代理在工业应用中的开放性挑战。&lt;h4&gt;翻译&lt;/h4&gt;最近在神经算子学习领域的进展为汽车空气动力学等领域的变革创新铺平了道路。但是，为了使基于神经网络的模拟替代品能够在工业规模上实施，需要克服几个关键问题。首先，这些替代品必须能够处理大规模表面和体积网格，尤其是在仅使用原始几何输入时（即不依赖于模拟网格）。其次，它们必须在有限数量的高保真数值模拟样本下进行训练，并达到所需性能水平。为此，我们引入了保留几何的通用物理变换器（Geometry-preserving Universal Physics Transformer, GP-UPT），该方法将几何编码和物理预测分离，确保对不同几何表示和支持独立表面采样策略的灵活性。GP-UPT使模型的不同部分可以根据实际需求进行扩展，并提供了针对开放性挑战的可扩展解决方案。此外，GP-UPT规避了高质量仿真网格的创建过程，在20百万个网格单元上实现准确的三维速度场预测，并在从低保真度向高保真度模拟数据集的学习中表现出色，需要少于一半的高保真度数据即可达到与从头训练模型相同的表现水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in neural operator learning are paving the way fortransformative innovations in fields such as automotive aerodynamics. However,key challenges must be overcome before neural network-based simulationsurrogates can be implemented at an industry scale. First, surrogates mustbecome scalable to large surface and volume meshes, especially when using rawgeometry inputs only, i.e., without relying on the simulation mesh. Second,surrogates must be trainable with a limited number of high-fidelity numericalsimulation samples while still reaching the required performance levels. Tothis end, we introduce Geometry-preserving Universal Physics Transformer(GP-UPT), which separates geometry encoding and physics predictions, ensuringflexibility with respect to geometry representations and surface samplingstrategies. GP-UPT enables independent scaling of the respective parts of themodel according to practical requirements, offering scalable solutions to openchallenges. GP-UPT circumvents the creation of high-quality simulation meshes,enables accurate 3D velocity field predictions at 20 million mesh cells, andexcels in transfer learning from low-fidelity to high-fidelity simulationdatasets, requiring less than half of the high-fidelity data to match theperformance of models trained from scratch.</description>
      <author>example@mail.com (Maurits Bleeker, Matthias Dorfer, Tobias Kronlachner, Reinhard Sonnleitner, Benedikt Alkin, Johannes Brandstetter)</author>
      <guid isPermaLink="false">2502.09692v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Neural Topic Models with Variance-Invariance-Covariance Regularization</title>
      <link>http://arxiv.org/abs/2502.09944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint accepted in Springer Knowledge and Information Systems  (KAIS), in press&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合神经主题模型（NTM）和正则化自监督学习方法的自我监督神经主题模型，以提高性能。&lt;h4&gt;背景&lt;/h4&gt;传统的主题模型使用有限的方式从文档中提取隐藏的主题，并且灵活性较低。而神经主题模型利用神经网络来挖掘文本中的潜在主题，提供了更大的灵活性和更好的主题一致性估计能力。同时，一些自监督学习方法通过双塔结构（即两个相同的网络）为同一输入的不同增强版本产生相似的表示，并通过正则化防止这些表征坍塌。&lt;h4&gt;目的&lt;/h4&gt;改进现有模型以提高主题质量并开发新的变体模型。&lt;h4&gt;方法&lt;/h4&gt;引入了基于NTM的新模型，该模型使用显式正则化来限制锚点和积极样本的主题潜在表示。同时，提出了一种对抗性数据增强技术来替代传统的启发式采样策略，并构建了几种对比学习模型以利用正负样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的模型在三个不同数据集上均超越了基线方法和其他最先进的模型，在主题质量和数量指标方面表现更佳。&lt;h4&gt;结论&lt;/h4&gt;该研究通过结合NTM与自监督学习技术来增强潜在表示的约束力，从而有效提升话题的质量。同时开发出基于对比学习的不同变体模型能够进一步改进性能。&lt;h4&gt;翻译&lt;/h4&gt;在我们的研究中，我们提出了一种自我监督神经主题模型（NTM），它结合了NTM和正则化自监督学习方法的力量来提高表现。 NTMs使用神经网络从文档中的单词背后挖掘隐藏的主题，从而使灵活性更高，并且比传统话题模型更好地估计更一致的话题。另一方面，一些自监督学习方法采用双塔架构，即两个相同的网络为同一输入的不同增强版本生成相似表示。通过正则化防止这些表征坍塌（否则会导致所有输入的输出是恒定或冗余表示）。我们的模型通过显式正则化锚点和积极样本的主题潜在表示来提升主题质量。我们还引入了一种对抗性数据增强方法，以取代启发式的采样方法。此外，我们开发了几个变体模型，包括在NTM基础上结合对比学习（使用正负样本）的模型。实验结果表明，在三个数据集上的定量和定性评估中，我们的模型均优于基线和其他最先进模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In our study, we propose a self-supervised neural topic model (NTM) thatcombines the power of NTMs and regularized self-supervised learning methods toimprove performance. NTMs use neural networks to learn latent topics hiddenbehind the words in documents, enabling greater flexibility and the ability toestimate more coherent topics compared to traditional topic models. On theother hand, some self-supervised learning methods use a joint embeddingarchitecture with two identical networks that produce similar representationsfor two augmented versions of the same input. Regularizations are applied tothese representations to prevent collapse, which would otherwise result in thenetworks outputting constant or redundant representations for all inputs. Ourmodel enhances topic quality by explicitly regularizing latent topicrepresentations of anchor and positive samples. We also introduced anadversarial data augmentation method to replace the heuristic sampling method.We further developed several variation models including those on the basis ofan NTM that incorporates contrastive learning with both positive and negativesamples. Experimental results on three datasets showed that our modelsoutperformed baselines and state-of-the-art models both quantitatively andqualitatively.</description>
      <author>example@mail.com (Weiran Xu, Kengo Hirami, Koji Eguchi)</author>
      <guid isPermaLink="false">2502.09944v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Insect-Foundation: A Foundation Model and Large Multimodal Dataset for Vision-Language Insect Understanding</title>
      <link>http://arxiv.org/abs/2502.09906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多模态对话模型Insect-LLaVA，旨在提升在昆虫领域的视觉理解和知识。通过构建大规模的多模态昆虫数据集和开发用于捕捉昆虫细微特征的学习机制，该模型能够在视觉昆虫理解任务上取得卓越性能。&lt;h4&gt;背景&lt;/h4&gt;当前的多模态对话模型虽然表现出强大的文本图像数据学习能力，但在专门的视觉昆虫知识方面仍显不足。精确农业中理解昆虫是促进可持续发展的基本问题之一。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有模型在视觉昆虫领域的知识空白，本文提出了Insect-LLaVA模型及其相关技术，旨在提升视觉昆虫的理解和认知。&lt;h4&gt;方法&lt;/h4&gt;首先构建了一个新的大规模多模态昆虫数据集，包含视觉昆虫指令数据。其次开发了具有微特征自监督学习机制的昆虫基础模型，并引入了一种基于Patch-wise Relevant Attention机制来捕捉昆虫图像中的细微差异。&lt;h4&gt;主要发现&lt;/h4&gt;提出的Insect-LLaVA模型在视觉昆虫理解任务上表现出色，在标准基准测试中达到了当前最佳性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的数据集和学习机制，本文成功提升了现有多模态对话模型在处理视觉昆虫知识方面的能力，为未来的研究提供了强有力的方法支持。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal conversational generative AI has demonstrated impressive capabilities in vision and language understanding through massive text-image data learning, but current models lack knowledge about visual insects. In precision agriculture, understanding insects is fundamental to promoting agricultural sustainability. This paper introduces Insect-LLaVA, a novel multimodal conversation model aimed at enhancing insect-domain knowledge visually. It includes a new large-scale dataset for multimodal foundation model learning and an insect feature enhancement mechanism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal conversational generative AI has shown impressive capabilities invarious vision and language understanding through learning massive text-imagedata. However, current conversational models still lack knowledge about visualinsects since they are often trained on the general knowledge ofvision-language data. Meanwhile, understanding insects is a fundamental problemin precision agriculture, helping to promote sustainable development inagriculture. Therefore, this paper proposes a novel multimodal conversationalmodel, Insect-LLaVA, to promote visual understanding in insect-domainknowledge. In particular, we first introduce a new large-scale MultimodalInsect Dataset with Visual Insect Instruction Data that enables the capabilityof learning the multimodal foundation models. Our proposed dataset enablesconversational models to comprehend the visual and semantic features of theinsects. Second, we propose a new Insect-LLaVA model, a new general LargeLanguage and Vision Assistant in Visual Insect Understanding. Then, to enhancethe capability of learning insect features, we develop an Insect FoundationModel by introducing a new micro-feature self-supervised learning with aPatch-wise Relevant Attention mechanism to capture the subtle differences amonginsect images. We also present Description Consistency loss to improvemicro-feature learning via text descriptions. The experimental resultsevaluated on our new Visual Insect Question Answering benchmarks illustrate theeffective performance of our proposed approach in visual insect understandingand achieve State-of-the-Art performance on standard benchmarks ofinsect-related tasks.</description>
      <author>example@mail.com (Thanh-Dat Truong, Hoang-Quan Nguyen, Xuan-Bac Nguyen, Ashley Dowling, Xin Li, Khoa Luu)</author>
      <guid isPermaLink="false">2502.09906v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Probabilistic Lexical Manifold Construction in Large Language Models via Hierarchical Vector Field Interpolation</title>
      <link>http://arxiv.org/abs/2502.10013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的词嵌入技术将单词映射到离散的令牌空间中，这种方法会导致表示上的不连续性。基于转换器的模型虽然有强大的语义捕获能力，但它们生成的嵌入表示仍然可能在某些情况下存在一致性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种层次化的向量场插值方法，通过构建一个具有概率结构的空间来改善词嵌入的一致性和连贯性。&lt;h4&gt;方法&lt;/h4&gt;构建了一个能够保证拓扑一致性的概率函数空间，在该空间中词表示遵循连续的流形分布，而非局限于离散令牌映射。使用发散最小化技术确保插值后的向量保持概率一致性的同时保留计算可行性。&lt;h4&gt;主要发现&lt;/h4&gt;{'改进词汇连贯性': '通过精炼上下文关系，概率约束可以增强词汇的一致性和稳定性', '减少表示不一致和异向性扭曲': '实验表明该方法能够减少语义分布中的非均匀变形，提高嵌入表示的密度对齐。', '更稳定的表征': '与标准转换器模型相比，在需要精细语义区分的任务中结构化插值能提供更加稳定的表现。', '计算效率': '虽然引入了轻微的处理开销，但这种方法对于大规模实施仍然具有可扩展性。'}&lt;h4&gt;结论&lt;/h4&gt;层次化的向量场插值技术通过概率方法解决了传统词嵌入表示中的连续性和一致性问题，并在多种语言分布中提高了语义稳定性。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译为：层次化向量场插值引入了一种结构化的概率框架来实现词汇表征，确保了单词嵌入能够在连续流形上平滑过渡而非受限于离散令牌映射。所提出的方法构建了一个概率函数空间，在此空间中词表示遵循拓扑一致性，减少了基于转换器的嵌入中常见代表不连续性。实证评估表明，通过概率约束增强词汇连贯性，并通过细化上下文关系来改善语义稳定性在多种语言分布中表现更好。利用发散最小化技术确保插值后的嵌入保持概率一致性的同时保留大范围实现中的计算可行性。实验结果表明，插值词流形提高了表示密度对齐度并减少了上下文嵌入分布中的非均匀变形。与基于转换器的标准模型进行对比分析发现，在需要精细语义区分的任务中结构化插值提供了更稳定的表征。统计评价的嵌入发散证明了概率词汇流形减少了一致性问题而保持不同抽象层次上的连贯性。计算效率评估表明，虽然插值得到了额外处理开销，但这种结构化的表示学习方法仍然适用于实际部署中的大规模实施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical vector field interpolation introduces a structured probabilisticframework for lexical representation, ensuring that word embeddings transitionsmoothly across a continuous manifold rather than being constrained to discretetoken mappings. The proposed methodology constructs a probabilistic functionspace where word representations adhere to topological consistency, mitigatingrepresentational discontinuities commonly observed in transformer-basedembeddings. Empirical evaluations reveal that probabilistic constraints enhancelexical coherence by refining contextual relationships, leading to improvementsin semantic stability across multiple linguistic distributions. The applicationof divergence minimization techniques ensures that interpolated embeddingsmaintain probabilistic consistency while preserving computational feasibilityfor large-scale implementations. Experimental findings demonstrate thatinterpolated lexical manifolds improve representation density alignment,reducing anisotropic distortions in contextual embedding distributions.Comparative analyses with standard transformer-based models highlight thatstructured interpolation yields more stable representations, particularly intasks requiring fine-grained semantic differentiation. The statisticalevaluation of embedding divergence confirms that probabilistic lexicalmanifolds reduce representational inconsistencies while maintaining coherenceacross varying scales of contextual abstraction. An assessment of computationalefficiency reveals that while interpolation introduces minor processingoverhead, the structured representation learning approach remains scalable forpractical deployment.</description>
      <author>example@mail.com (Clive Pendleton, Ewan Harrington, Giles Fairbrother, Jasper Arkwright, Nigel Fenwick, Richard Katrix)</author>
      <guid isPermaLink="false">2502.10013v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Meta-INR: Efficient Encoding of Volumetric Data via Meta-Learning Implicit Neural Representation</title>
      <link>http://arxiv.org/abs/2502.09669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by PVIS Short Paper Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;隐式神经表示（INR）作为一种编码体积数据的有前景的方法已经出现，它提供连续性表示并与体渲染流水线无缝兼容。&lt;h4&gt;背景&lt;/h4&gt;优化一个从随机初始化参数开始的新体积的INR网络在计算上是低效的，特别是在处理大型时变或集合体积数据集的情况下，尽管这些数据集中包含共享相似结构模式的数据块但仍然需要独立训练。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种基于元学习算法预训练策略Meta-INR，用于从体积数据集的部分观察中学习初始INR参数。&lt;h4&gt;方法&lt;/h4&gt;通过从部分观察的体积数据集中学习初始参数，使学习到的初始参数作为强大的先验知识来增强INR的泛化能力。当适应新体积时，只需要少数梯度更新就可以显著加快收敛速度，并且在分析自适应INRs的参数时具有更好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;Meta-INR能够有效提取高质量的通用特征，有助于编码不同数据集中未见过的相似体数据。此外，在模拟参数分析和代表性时间步选择等任务中也表现出实用性。&lt;h4&gt;结论&lt;/h4&gt;该策略展示了在处理大规模复杂体积数据集时的有效性和潜力，并通过代码开源来支持研究社区。&lt;h4&gt;翻译&lt;/h4&gt;隐式神经表示（INR）作为一种编码体积数据的有前景的方法已经出现，它提供连续性表示并与体渲染流水线无缝兼容。然而，从随机初始化参数开始优化一个全新的体积的INR网络在计算上是低效的，特别是在处理大型时变或集合体积数据集的情况下，尽管这些数据集中包含共享相似结构模式的数据块但仍然需要独立训练。为了解决上述问题，提出了一种基于元学习算法预训练策略Meta-INR，用于从体积数据集的部分观察中学习初始INR参数。与从零开始训练相比，通过部分观察获得的初始参数提供了一个强大的先验知识，这增强了INR泛化能力，并在适应新体数据时只需要少数梯度更新就能实现显著更快的收敛速度和更好的可解释性。实验结果表明Meta-INR可以提取高质量的通用特征来帮助编码不同数据集中未见过的相似体积数据。此外，在模拟参数分析以及代表性时间步选择等任务中也表现出实用性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit neural representation (INR) has emerged as a promising solution forencoding volumetric data, offering continuous representations and seamlesscompatibility with the volume rendering pipeline. However, optimizing an INRnetwork from randomly initialized parameters for each new volume iscomputationally inefficient, especially for large-scale time-varying orensemble volumetric datasets where volumes share similar structural patternsbut require independent training. To close this gap, we propose Meta-INR, apretraining strategy adapted from meta-learning algorithms to learn initial INRparameters from partial observation of a volumetric dataset. Compared totraining an INR from scratch, the learned initial parameters provide a strongprior that enhances INR generalizability, allowing significantly fasterconvergence with just a few gradient updates when adapting to a new volume andbetter interpretability when analyzing the parameters of the adapted INRs. Wedemonstrate that Meta-INR can effectively extract high-quality generalizablefeatures that help encode unseen similar volume data across diverse datasets.Furthermore, we highlight its utility in tasks such as simulation parameteranalysis and representative timestep selection. The code is available athttps://github.com/spacefarers/MetaINR.</description>
      <author>example@mail.com (Maizhe Yang, Kaiyuan Tang, Chaoli Wang)</author>
      <guid isPermaLink="false">2502.09669v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection</title>
      <link>http://arxiv.org/abs/2502.09271v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PAKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对图神经网络的新攻击策略，通过向系统中注入孤立子图来误导链路推荐器和节点分类器，从而降低节点分类精度。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络在处理具有图形结构的数据方面表现出色，但最近的研究揭示了它们对对抗性攻击的脆弱性。传统方法依赖于操纵原始图或向人工创建的节点添加链接，这些方法在实际环境中往往不切实际。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的对抗性场景，该场景涉及注入孤立子图以欺骗GNN系统中的链路推荐器和节点分类器。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为LiSA的框架，利用双代理模型和两级优化来同时满足两个对抗目标：误导链路推荐器向目标受害者节点与子图之间提议链接，并降低节点分类精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提方法在真实世界数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;新的攻击策略通过注入孤立的子图，成功实现了对GNN系统的有效攻击。LiSA框架展示了对抗性场景中同时满足多个目标的能力。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）在处理具有图形结构的数据方面表现出了卓越的能力，然而最近的研究揭示了它们容易受到对抗性攻击的影响。传统的依赖于篡改原始图或向人工节点添加链接的攻击方法，在现实世界的应用中往往显得不切实际。本文介绍了一种新的对抗场景，即通过注入孤立子图来欺骗GNN系统中的链路推荐器和节点分类器。具体而言，该策略误导链路推荐器在目标受害者节点与子图之间提议链接，从而诱导用户建立意外且有害的连接，并降低节点分类精度，进而实现成功的攻击。为了应对这种威胁，我们提出了LiSA框架，它利用双代理模型和两级优化来同时满足两个对抗性目标。广泛的实验表明了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inmodeling data with graph structures, yet recent research reveals theirsusceptibility to adversarial attacks. Traditional attack methodologies, whichrely on manipulating the original graph or adding links to artificially creatednodes, often prove impractical in real-world settings. This paper introduces anovel adversarial scenario involving the injection of an isolated subgraph todeceive both the link recommender and the node classifier within a GNN system.Specifically, the link recommender is mislead to propose links between targetedvictim nodes and the subgraph, encouraging users to unintentionally establishconnections and that would degrade the node classification accuracy, therebyfacilitating a successful attack. To address this, we present the LiSAframework, which employs a dual surrogate model and bi-level optimization tosimultaneously meet two adversarial objectives. Extensive experiments onreal-world datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Wenlun Zhang, Enyan Dai, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.09271v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation</title>
      <link>http://arxiv.org/abs/2502.09268v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了一种新的闭环视觉语言动作（VLA）模型GEVRM，该模型结合了内部模型控制（IMC）原则来增强机器人视觉操作的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;随着具身人工智能的发展，用于通用机器人决策的视觉-语言-行动（VLA）模型取得了显著进展。然而，现有的大多数VLA模型未能考虑到在部署过程中遇到的不可避免的外部干扰。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的闭环VLA方法GEVRM来增强机器人视觉操作的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;GEVRM通过结合IMC原则，在文本引导的视频生成模型中产生高度表达性的未来视觉规划目标，并通过模拟响应评估扰动，这些模拟响应被称为内部嵌入并通过原型对比学习进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GEVRM在标准和受干扰的CALVIN基准测试上均达到最先进的性能，并且在现实中的机器人任务中显示出显著改进。&lt;h4&gt;结论&lt;/h4&gt;新模型通过结合IMC原则能够更准确地跟踪参考输入并有效抵消扰动，从而增强视觉操作的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;随着具身人工智能的发展，用于通用机器人决策的视觉-语言-行动（VLA）模型取得了显著进展。然而，现有的大多数VLA模型未能考虑到在部署过程中遇到的不可避免的外部干扰。这些干扰引入了不可预见的状态信息到VLA中，导致不准确的动作并因此降低了泛化性能。经典的内部模型控制原则表明，一个包含外部输入信号的闭环系统可以精确跟踪参考输入，并有效抵消扰动。我们提出了一种新的闭环VLA方法GEVRM，该方法结合了IMC原则来增强机器人视觉操作的鲁棒性。在GEVRM中，文本引导的视频生成模型能够产生高度表达性的未来视觉规划目标。同时，通过模拟响应评估干扰，并将其称为内部嵌入并通过原型对比学习进行优化。这使模型可以隐式地从外部环境中推断和区分扰动。提出的GEVRM在标准和受干扰的CALVIN基准测试上均达到最先进的性能，并且在现实中的机器人任务中显示出显著改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of embodied artificial intelligence, significantprogress has been made in vision-language-action (VLA) models for general robotdecision-making. However, the majority of existing VLAs fail to account for theinevitable external perturbations encountered during deployment. Theseperturbations introduce unforeseen state information to the VLA, resulting ininaccurate actions and consequently, a significant decline in generalizationperformance. The classic internal model control (IMC) principle demonstratesthat a closed-loop system with an internal model that includes external inputsignals can accurately track the reference input and effectively offset thedisturbance. We propose a novel closed-loop VLA method GEVRM that integratesthe IMC principle to enhance the robustness of robot visual manipulation. Thetext-guided video generation model in GEVRM can generate highly expressivefuture visual planning goals. Simultaneously, we evaluate perturbations bysimulating responses, which are called internal embeddings and optimizedthrough prototype contrastive learning. This allows the model to implicitlyinfer and distinguish perturbations from the external environment. The proposedGEVRM achieves state-of-the-art performance on both standard and perturbedCALVIN benchmarks and shows significant improvements in realistic robot tasks.</description>
      <author>example@mail.com (Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang)</author>
      <guid isPermaLink="false">2502.09268v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond</title>
      <link>http://arxiv.org/abs/2502.09897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了谱学机器学习（SpectraML）的发展，系统地分析了从分子到光谱预测和从光谱推断分子的现代方法。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习和人工智能在化学领域的迅速发展，基于光谱和质谱数据的应用（即谱学机器学习）仍相对较少探索。现代谱学技术产生的高维大数据量亟需超越传统专家工作流程的自动化智能分析。&lt;h4&gt;目的&lt;/h4&gt;提供关于SpectraML的统一综述，追溯机器学习在谱学中的历史演变，并介绍代表性神经网络架构分类，同时指出现有挑战和未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;回顾了从早期模式识别到最新基础模型的进步，总结了代表性的基于图和转换器的方法。还讨论了解决数据质量问题、多模态集成以及计算可扩展性问题的新兴趋势。&lt;h4&gt;主要发现&lt;/h4&gt;提出了合成数据生成、大规模预训练和少量或零样本学习等新方向，旨在促进谱学与人工智能领域的研究进展。&lt;h4&gt;结论&lt;/h4&gt;本综述为研究人员提供了在光谱学和AI交汇处指导进步的道路图。为了推动可重复的研究，还公开了一个包含最近论文及其相应筛选数据集的开源仓库（https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers）。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已全部翻译为中文并总结成上述要点&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advent of machine learning (ML) and artificial intelligence (AI)has catalyzed major transformations in chemistry, yet the application of thesemethods to spectroscopic and spectrometric data, referred to as SpectroscopyMachine Learning (SpectraML), remains relatively underexplored. Modernspectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growingvolume of high-dimensional data, creating a pressing need for automated andintelligent analysis beyond traditional expert-based workflows. In this survey,we provide a unified review of SpectraML, systematically examiningstate-of-the-art approaches for both forward tasks (molecule-to-spectrumprediction) and inverse tasks (spectrum-to-molecule inference). We trace thehistorical evolution of ML in spectroscopy, from early pattern recognition tothe latest foundation models capable of advanced reasoning, and offer ataxonomy of representative neural architectures, including graph-based andtransformer-based methods. Addressing key challenges such as data quality,multimodal integration, and computational scalability, we highlight emergingdirections such as synthetic data generation, large-scale pretraining, and few-or zero-shot learning. To foster reproducible research, we also release anopen-source repository containing recent papers and their corresponding curateddatasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our surveyserves as a roadmap for researchers, guiding progress at the intersection ofspectroscopy and AI.</description>
      <author>example@mail.com (Kehan Guo, Yili Shen, Gisela Abigail Gonzalez-Montiel, Yue Huang, Yujun Zhou, Mihir Surve, Zhichun Guo, Prayel Das, Nitesh V Chawla, Olaf Wiest, Xiangliang Zhang)</author>
      <guid isPermaLink="false">2502.09897v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model</title>
      <link>http://arxiv.org/abs/2502.09947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 workshop Time Series in the Age of Large Models. arXiv  admin note: substantial text overlap with arXiv:2502.09173&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;远程医疗监控数据的时间序列表示学习在揭示患者行为深层次模式方面具有重要价值，特别是在面对精细时间粒度的数据时。&lt;h4&gt;目的&lt;/h4&gt;通过分析患有痴呆症人群的家庭活动记录，研究提出了一种两阶段的自监督学习方法，旨在量化评估参与者的行为模式并识别活动偏见。&lt;h4&gt;方法&lt;/h4&gt;{'第一阶段': '将时间序列活动转换为文本字符串，并用微调过的语言模型进行编码。', '第二阶段': '将时间序列向量双维度化以应用PageRank方法，分析潜在状态转换。'}&lt;h4&gt;主要发现&lt;/h4&gt;这些见解结合诊断数据，旨在支持个性化护理干预措施。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有助于从时间序列活动中提取有价值的患者行为模式，从而为痴呆症患者的日常活动监控和个性化护理提供依据。&lt;h4&gt;翻译&lt;/h4&gt;在对远程医疗监测数据进行分析时，时间序列表示学习对于揭示患者的行为模式具有重要价值。本研究关注了患有痴呆症人群的家庭活动记录，并提出了一种两阶段的自监督学习方法：第一阶段将时间序列活动转化为文本字符串并用微调过的语言模型进行编码；第二阶段则将时间序列向量双维度化，应用PageRank方法分析潜在状态转换，以量化评估参与者的活动模式和识别行为偏见。这些发现结合诊断数据可以支持个性化护理干预措施的实施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the analysis of remote healthcare monitoring data, time seriesrepresentation learning offers substantial value in uncovering deeper patternsof patient behavior, especially given the fine temporal granularity of thedata. In this study, we focus on a dataset of home activity records from peopleliving with Dementia. We propose a two-stage self-supervised learning approach.The first stage involves converting time-series activities into text strings,which are then encoded by a fine-tuned language model. In the second stage,these time-series vectors are bi-dimensionalized for applying PageRank method,to analyze latent state transitions to quantitatively assess participantsbehavioral patterns and identify activity biases. These insights, combined withdiagnostic data, aim to support personalized care interventions.</description>
      <author>example@mail.com (Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott)</author>
      <guid isPermaLink="false">2502.09947v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT System for the DASR Task of the CHiME-8 Challenge</title>
      <link>http://arxiv.org/abs/2502.09859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了为CHiME-8挑战赛的DASR任务1设计的一种多说话人远距离自动语音识别系统。&lt;h4&gt;背景&lt;/h4&gt;该系统处理各种录音条件，包括从晚餐聚会到专业会议以及从两个到八个说话人的场景。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法来改进传统的多人远距离自动语音识别系统的性能。&lt;h4&gt;方法&lt;/h4&gt;{'步骤1': '首先进行说话人定位（Diarization），接着是语音增强处理，最后执行自动语音识别。', '关键改进': [{'EEND-VC': '基于端到端的说话人定位与向量聚类'}, {'多通道说话人数计数': '使用来自EEND-VC的增强嵌入进行计数'}, {'目标说话人的声音活动检测': 'TS-VAD用于提高识别准确率'}], '语音增强': {'创新性麦克风选择规则': '为了更好地从分布式麦克风中选取最相关的麦克风', '波束成形改进': '研究了进一步的提升措施'}, '自动语音识别模型': [{'Whisper和WavLM基础模型': '利用这些模型开发了几种不同的ASR模型'}]}&lt;h4&gt;主要发现&lt;/h4&gt;最强系统在宏观TCP WER上的相对改善达到了63%，并且在NOTSOFAR-1会议评估数据中优于挑战最佳结果。&lt;h4&gt;结论&lt;/h4&gt;该论文展示了如何通过一系列创新性的方法和技术改进多说话人远距离自动语音识别系统的性能，特别是在处理复杂录音环境和多个说话人的场景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a multi-talker distant automatic speechrecognition (DASR) system we designed for the DASR task 1 of the CHiME-8challenge. Our system performs speaker counting, diarization, and ASR. Ithandles various recording conditions, from diner parties to professionalmeetings and from two to eight speakers. We perform diarization first, followedby speech enhancement, and then ASR as the challenge baseline. However, weintroduced several key refinements. First, we derived a powerful speakerdiarization relying on end-to-end speaker diarization with vector clustering(EEND-VC), multi-channel speaker counting using enhanced embeddings fromEEND-VC, and target-speaker voice activity detection (TS-VAD). For speechenhancement, we introduced a novel microphone selection rule to better selectthe most relevant microphones among the distributed microphones andinvestigated improvements to beamforming. Finally, for ASR, we developedseveral models exploiting Whisper and WavLM speech foundation models. Wepresent the results we submitted to the challenge and updated results weobtained afterward. Our strongest system achieves a 63% relative macro tcpWERimprovement over the baseline and outperforms the challenge best results on theNOTSOFAR-1 meeting evaluation data among geometry-independent systems.</description>
      <author>example@mail.com (Naoyuki Kamo, Naohiro Tawara, Atsushi Ando, Takatomo Kano, Hiroshi Sato, Rintaro Ikeshita, Takafumi Moriya, Shota Horiguch, Kohei Matsuura, Atsunori Ogawa, Alexis Plaquet, Takanori Ashihara, Tsubasa Ochiai, Masato Mimura, Marc Delcroix, Tomohiro Nakatani, Taichi Asami, Shoko Araki)</author>
      <guid isPermaLink="false">2502.09859v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Multifidelity Simulation-based Inference for Computationally Expensive Simulators</title>
      <link>http://arxiv.org/abs/2502.08416v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;在科学的多个领域中，随机模型是理解经验观察数据背后机制的重要工具。这些模型可以有不同的细节和精度水平，在研究现象时高保真度（即准确性高）的模型通常更受欢迎。然而，通过基于仿真的推理推断高保真度模型的参数具有挑战性，尤其是在仿真计算成本高昂的情况下。&lt;h4&gt;背景&lt;/h4&gt;在科学研究中，随机模型是理解实验观察数据背后的机制的重要工具。不同精度和细节水平的模型可以用于不同的情况，在许多情况下，更准确的高保真模型更为优选。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的方法——MF-NPE（多保真度神经后验估计），该方法利用低成本低保真模拟来推断在有限计算预算内的高保真仿真的参数。&lt;h4&gt;方法&lt;/h4&gt;通过转移学习，MF-NPE能够在有限的高保真资源下执行神经后验估计，并具备使用主动学习优先处理个别观察的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在一项统计任务（具有解析基础事实）和两项真实世界任务中，与现有方法相比，MF-NPE展示了相当的性能表现，同时需要高达两个数量级较少的高保真模拟次数。&lt;h4&gt;结论&lt;/h4&gt;总体而言，MF-NPE为昂贵计算仿真的高效贝叶斯推理提供了新的机会。&lt;h4&gt;翻译&lt;/h4&gt;在科学多个领域内，随机模型是理解观测数据背后机制的关键工具。这些模型有不同的精度和细节层次，在许多情况下，更高准确性的高保真度模型更为理想。然而，通过基于模拟的推断来估计这种高保真模型参数十分具有挑战性，尤其是在仿真的计算成本高昂时。我们提出了一种新的方法——MF-NPE（多保真神经后验估计），它利用低成本低保真度仿真来进行转移学习，在有限的模拟预算内推断出昂贵的高精度模拟器的参数，并且具备主动学习能力以优先处理个别观测。在具有解析地面事实的一项统计任务以及两项现实世界任务上，MF-NPE展示了与当前方法相当的表现水平，同时需要高达两个数量级更少次数的高保真度仿真。总的来说，MF-NPE为计算昂贵的模拟器上的高效贝叶斯推理提供了新的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Across many domains of science, stochastic models are an essential tool tounderstand the mechanisms underlying empirically observed data. Models can beof different levels of detail and accuracy, with models of high-fidelity (i.e.,high accuracy) to the phenomena under study being often preferable. However,inferring parameters of high-fidelity models via simulation-based inference ischallenging, especially when the simulator is computationally expensive. Weintroduce MF-NPE, a multifidelity approach to neural posterior estimation thatleverages inexpensive low-fidelity simulations to infer parameters ofhigh-fidelity simulators within a limited simulation budget. MF-NPE performsneural posterior estimation with limited high-fidelity resources by virtue oftransfer learning, with the ability to prioritize individual observations usingactive learning. On one statistical task with analytical ground-truth and tworeal-world tasks, MF-NPE shows comparable performance to current approacheswhile requiring up to two orders of magnitude fewer high-fidelity simulations.Overall, MF-NPE opens new opportunities to perform efficient Bayesian inferenceon computationally expensive simulators.</description>
      <author>example@mail.com (Anastasia N. Krouglova, Hayden R. Johnson, Basile Confavreux, Michael Deistler, Pedro J. Gonçalves)</author>
      <guid isPermaLink="false">2502.08416v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning</title>
      <link>http://arxiv.org/abs/2502.09863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型的成功在于它们能够从预训练语料库中隐式地学习结构化的潜在表示。&lt;h4&gt;目的&lt;/h4&gt;研究一类可解的对比自监督算法，这些算法类似于word2vec并且在下游任务中的表现相似。&lt;h4&gt;方法&lt;/h4&gt;提出二次词嵌入模型，并提供针对特定超参数选择下的训练动态以及最终词嵌入的解析解。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型学习正交线性子空间，每次增量地提高嵌入的有效秩直到模型容量饱和。在WikiText上训练后发现顶部子空间表示可解释的概念。&lt;h4&gt;结论&lt;/h4&gt;利用动力学理论预测模型何时何地获得完成类比任务的能力。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型的成功在于它们能够从预训练语料库中隐式地学习结构化的潜在表示。本文研究了一类可解的对比自监督算法，这些算法类似于word2vec并且在下游任务中的表现相似。论文的主要贡献是提供了针对特定超参数选择下的训练动态以及最终词嵌入的解析解，并揭示了模型如何以增量方式提高嵌入的有效秩直到达到饱和状态。此外，在WikiText上进行实验后发现顶部子空间表示可解释的概念，同时利用动力学理论预测模型何时何地获得完成类比任务的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable success of large language models relies on their ability toimplicitly learn structured latent representations from the pretraining corpus.As a simpler surrogate for representation learning in language modeling, westudy a class of solvable contrastive self-supervised algorithms which we termquadratic word embedding models. These models resemble the word2vec algorithmand perform similarly on downstream tasks. Our main contributions areanalytical solutions for both the training dynamics (under certainhyperparameter choices) and the final word embeddings, given in terms of onlythe corpus statistics. Our solutions reveal that these models learn orthogonallinear subspaces one at a time, each one incrementing the effective rank of theembeddings until model capacity is saturated. Training on WikiText, we findthat the top subspaces represent interpretable concepts. Finally, we use ourdynamical theory to predict how and when models acquire the ability to completeanalogies.</description>
      <author>example@mail.com (Dhruva Karkada, James B. Simon, Yasaman Bahri, Michael R. DeWeese)</author>
      <guid isPermaLink="false">2502.09863v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving Medical Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.09744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE EMBC 2025; 7 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;联邦学习（FL）为机器学习提供了一种去中心化的策略，允许多个设备或服务器在不共享原始数据的情况下协作训练模型，从而保护了数据隐私。这种技术由于其保密性，在学术界和工业界引起了广泛的兴趣，尤其是在医疗领域，因为该领域的数据往往受到严格法规的保护。&lt;h4&gt;背景&lt;/h4&gt;联邦学习因其能够在保持数据私密性的前提下进行高效的数据利用而备受关注，特别是在受监管严格的医学研究中。然而，目前较少有文献探讨将联邦学习应用于基础模型（FMs）的时间序列预测任务中的可能性及其挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探索使用不同联邦学习技术对时间序列基础模型进行微调的可能性，并讨论在各种数据异质性配置下所面临的挑战和权衡。&lt;h4&gt;方法&lt;/h4&gt;研究团队采用了ECG与ICG等医疗领域的时间序列数据，尝试了不同的联邦学习策略来微调基础模型，用于时间序列预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在不同客户端的数据分布条件下，联邦学习对微调基础模型的有效性有显著影响。其优势在于能克服数据限制同时保持隐私保护，但该效果依赖于参与方（客户）之间的数据分布特性。&lt;h4&gt;结论&lt;/h4&gt;研究表明了在时间序列预测任务中使用联邦学习进行基础模型微调的潜力与局限，并指出了应用联邦学习技术时需要注意的数据分布差异等问题。&lt;h4&gt;翻译&lt;/h4&gt;Federated Learning (FL) provides a decentralized machine learning approach, where multiple devices or servers collaboratively train a model without sharing their raw data, thus enabling data privacy. This approach has gained significant interest in academia and industry due to its privacy-preserving properties, which are particularly valuable in the medical domain where data availability is often protected under strict regulations. A relatively unexplored area is the use of FL to fine-tune Foundation Models (FMs) for time series forecasting, potentially enhancing model efficacy by overcoming data limitation while maintaining privacy. In this paper, we fine-tuned time series FMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data using different FL techniques. We then examined various scenarios and discussed the challenges FL faces under different data heterogeneity configurations. Our empirical results demonstrated that while FL can be effective for fine-tuning FMs on time series forecasting tasks, its benefits depend on the data distribution across clients. We highlighted the trade-offs in applying FL to FM fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) provides a decentralized machine learning approach,where multiple devices or servers collaboratively train a model without sharingtheir raw data, thus enabling data privacy. This approach has gainedsignificant interest in academia and industry due to its privacy-preservingproperties, which are particularly valuable in the medical domain where dataavailability is often protected under strict regulations. A relativelyunexplored area is the use of FL to fine-tune Foundation Models (FMs) for timeseries forecasting, potentially enhancing model efficacy by overcoming datalimitation while maintaining privacy. In this paper, we fine-tuned time seriesFMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data usingdifferent FL techniques. We then examined various scenarios and discussed thechallenges FL faces under different data heterogeneity configurations. Ourempirical results demonstrated that while FL can be effective for fine-tuningFMs on time series forecasting tasks, its benefits depend on the datadistribution across clients. We highlighted the trade-offs in applying FL to FMfine-tuning.</description>
      <author>example@mail.com (Mahad Ali, Curtis Lisle, Patrick W. Moore, Tammer Barkouki, Brian J. Kirkwood, Laura J. Brattain)</author>
      <guid isPermaLink="false">2502.09744v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)</title>
      <link>http://arxiv.org/abs/2502.09376v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文分析了低秩适应（LoRA）的训练动态，并探讨了其损失函数景观，提出了两种场景：理想化的线性化假设成立的‘特殊场景’和更现实但线性化假设不适用的‘一般场景’。&lt;h4&gt;背景&lt;/h4&gt;低秩适应已成为微调大型基础模型的标准方法。然而，人们对LoRA的理论理解仍有限制。&lt;h4&gt;目的&lt;/h4&gt;分析没有限制假设的情况下的LoRA损失函数景观。&lt;h4&gt;方法&lt;/h4&gt;定义了两种不同的情况：一种是理想化设置下线性化论证适用的‘特殊场景’；另一种是在更现实但线性化假设不成立的‘一般场景’。在‘一般场景’中，展示了低秩适应训练可以收敛到具有较低秩和小幅度的全局最小值或高秩且幅度大的不同解。&lt;h4&gt;主要发现&lt;/h4&gt;零初始化以及权重衰减促使了向参数空间中的低秩、小幅度区域的隐式偏好，从而解释了为什么LoRA通常能够找到全局最优解的原因。&lt;h4&gt;结论&lt;/h4&gt;该工作通过分析没有假设的情况下LoRA训练的行为机制，为理解其理论基础提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has become a standard approach for fine-tuninglarge foundation models. However, our theoretical understanding of LoRA remainslimited as prior analyses of LoRA's training dynamics either rely onlinearization arguments or consider highly simplified setups. In this work, weanalyze the LoRA loss landscape without such restrictive assumptions. We definetwo regimes: a ``special regime'', which includes idealized setups wherelinearization arguments hold, and a ``generic regime'' representing morerealistic setups where linearization arguments do not hold. In the genericregime, we show that LoRA training converges to a global minimizer with lowrank and small magnitude, or a qualitatively distinct solution with high rankand large magnitude. Finally, we argue that the zero-initialization and weightdecay in LoRA training induce an implicit bias toward the low-rank,small-magnitude region of the parameter space -- where global minima lie --thus shedding light on why LoRA training usually succeeds in finding globalminima.</description>
      <author>example@mail.com (Junsu Kim, Jaeyeon Kim, Ernest K. Ryu)</author>
      <guid isPermaLink="false">2502.09376v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence</title>
      <link>http://arxiv.org/abs/2502.09815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统计一致性对齐的方法，通过张量场收敛来强制结构化的标记表示，并建立了量化一致性的数学框架。实验表明这种方法在提高困惑度、增强分类准确性和优化罕见词嵌入方面有效。&lt;h4&gt;背景&lt;/h4&gt;表示学习在构建语言的内部嵌入以捕捉统计数据特性中起着关键作用，影响生成文本的一致性和上下文连贯性。&lt;h4&gt;目的&lt;/h4&gt;引入统计一致性对齐方法来指导嵌入体反映语言数据中的固有统计依赖关系，优化整个训练过程中表示一致性的损失函数。&lt;h4&gt;方法&lt;/h4&gt;建立了一种量化一致性的数学框架，并通过实验评估了应用此约束后性能的改善情况。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提高了困惑度和分类准确性，改进了罕见词嵌入，使表示空间更加稳定。同时，它还避免了表征崩溃的问题，保持上下文依赖性。&lt;h4&gt;结论&lt;/h4&gt;统计一致性对齐增强了语义完整性，在需要更高上下文保真的应用中证明了其有效性，并提供了关于如何利用统计依存关系改进语言模型训练的见解。&lt;h4&gt;翻译&lt;/h4&gt;代表学习在构造内部嵌入以捕捉语言统计数据特性方面扮演着核心角色，这对生成文本的一致性和连贯性有影响。引入了一种通过张量场收敛来强制结构化标记表示的方法——统计一致性对齐，指导嵌入体反映语言数据中的固有统计依赖关系。建立了量化一致性的数学框架，并采用一种损失函数在训练迭代过程中优化表示一致性。实验证明应用这种约束可以改善困惑度和分类准确性，改进罕见词的嵌入体，从而提供一个更稳定的表征空间。与基准模型相比分析显示该方法促进了可解释性结构内部结构的发展，保证了上下文依赖性的保持并减轻了表示崩溃的风险。影响一致性得分分布的因素表明对齐机制增强了语义完整性，因此学习到的嵌入得到了更好的组织。计算评估表明尽管这种方法会增加额外的记忆和训练成本，但有结构化的优化流程来支持这种权衡，在需要更高上下文保真的应用中尤为如此。实验结果验证了统计一致性在最优化标记表示方面的有效性，并提供了关于如何利用统计数据依赖关系改进语言模型训练的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning plays a central role in structuring internalembeddings to capture the statistical properties of language, influencing thecoherence and contextual consistency of generated text. Statistical CoherenceAlignment is introduced as a method to enforce structured token representationsthrough tensor field convergence, guiding embeddings to reflect statisticaldependencies inherent in linguistic data. A mathematical framework isestablished to quantify coherence alignment, integrating a loss function thatoptimizes representational consistency across training iterations. Empiricalevaluations demonstrate that applying coherence constraints improvesperplexity, enhances classification accuracy, and refines rare word embeddings,contributing to a more stable representation space. Comparative analyses withbaseline models reveal that the proposed method fosters a more interpretableinternal structure, ensuring that embeddings retain contextual dependencieswhile mitigating representation collapse. The impact on coherence scoredistributions suggests that the alignment mechanism strengthens semanticintegrity across diverse linguistic constructs, leading to a more balancedorganization of learned embeddings. Computational assessments indicate thatwhile the method introduces additional memory and training costs, thestructured optimization process justifies the trade-offs in applicationsrequiring heightened contextual fidelity. Experimental results validate theeffectiveness of coherence alignment in optimizing token representations,providing insights into how statistical dependencies can be leveraged toimprove language model training.</description>
      <author>example@mail.com (Jonathan Gale, Godfrey Aldington, Harriet Thistlewood, Thomas Tattershall, Basil Wentworth, Vincent Enoasmo)</author>
      <guid isPermaLink="false">2502.09815v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin</title>
      <link>http://arxiv.org/abs/2502.04794v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MedMimic是一种多模态框架，用于诊断发热原因不明（FUO）疾病。该系统结合了预训练的视觉模型和临床数据来提高疾病的分类效果。&lt;h4&gt;背景&lt;/h4&gt;发热原因不明（FUO）是一个重要的医疗挑战，需要有效的诊断工具。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于多模态融合的框架，利用医学图像和临床信息，以改进对FUO疾病类型的分类准确性。&lt;h4&gt;方法&lt;/h4&gt;采用预训练模型如DINOv2、Vision Transformer和ResNet-18等将高维的18F-FDG PET/CT影像转换为低维且具有语义意义的特征，并通过一个可学习的自注意力融合网络整合这些影像数据与临床信息。&lt;h4&gt;主要发现&lt;/h4&gt;在四川大学华西医院2017年至2023年的416例FUO患者病例中，多模态融合分类网络MFCN实现了宏AUROC评分介于0.8654到0.9291之间，在七项任务中均优于传统机器学习和单一模式深度学习方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合大型预训练模型与深度学习的优势，MedMimic为疾病分类提供了一个有前景的解决方案，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;发热原因不明（FUO）一直是诊断上的挑战。 MedMimic作为一种受现实世界诊断过程启发的多模态框架被提出。它利用预训练模型如DINOv2、Vision Transformer和ResNet-18将高维的18F-FDG PET/CT成像转化为低维且具有语义意义的特征。然后，一个基于可学习自注意力机制的融合网络将这些影像特征与临床数据结合进行分类。在四川大学华西医院从2017年到2023年的416例FUO病例中，多模态融合分类网络（MFCN）实现了宏AUROC评分介于0.8654到0.9291之间，显著优于传统的机器学习和单模深度学习方法。通过删除实验以及五折交叉验证进一步证实了其有效性。结合大型预训练模型与深度学习的优势，MedMimic为疾病分类提供了一个有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fever of unknown origin FUO remains a diagnostic challenge. MedMimic isintroduced as a multimodal framework inspired by real-world diagnosticprocesses. It uses pretrained models such as DINOv2, Vision Transformer, andResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging intolow-dimensional, semantically meaningful features. A learnableself-attention-based fusion network then integrates these imaging features withclinical data for classification. Using 416 FUO patient cases from SichuanUniversity West China Hospital from 2017 to 2023, the multimodal fusionclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to0.9291 across seven tasks, outperforming conventional machine learning andsingle-modality deep learning methods. Ablation studies and five-foldcross-validation further validated its effectiveness. By combining thestrengths of pretrained large models and deep learning, MedMimic offers apromising solution for disease classification.</description>
      <author>example@mail.com (Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo)</author>
      <guid isPermaLink="false">2502.04794v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Graph Foundation Models for Recommendation: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2502.08346v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了基于图基础模型（GFMs）的推荐系统技术，介绍了当前方法的分类、详细方法论以及面临的挑战和未来研究方向。&lt;h4&gt;背景&lt;/h4&gt;推荐系统在在线信息导航中扮演关键角色，并通过深度学习的进步不断改进排名准确性。尤其是图神经网络（GNNs）擅长提取高级结构信息，而大型语言模型（LLMs）则专注于处理自然语言的理解，两者都因其高效性而在行业中广泛采用。&lt;h4&gt;目的&lt;/h4&gt;综述基于GFMs的推荐系统技术，提供该领域的方法分类、方法论细节以及关键挑战和未来研究方向的概述。&lt;h4&gt;方法&lt;/h4&gt;论文采用了文献回顾的方法，对当前使用图基础模型（GFMs）解决复杂推荐系统的各种方法进行了详细的分析。&lt;h4&gt;主要发现&lt;/h4&gt;最近的研究集中在整合GNNs和LLMs优点的GFMs上，这些模型能够更有效地处理用户-物品关系的图形结构以及文本理解。&lt;h4&gt;结论&lt;/h4&gt;综述通过综合最近的发展，提供了基于GFMs的推荐系统领域的重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) serve as a fundamental tool for navigating the vastexpanse of online information, with deep learning advancements playing anincreasingly important role in improving ranking accuracy. Among these, graphneural networks (GNNs) excel at extracting higher-order structural information,while large language models (LLMs) are designed to process and comprehendnatural language, making both approaches highly effective and widely adopted.Recent research has focused on graph foundation models (GFMs), which integratethe strengths of GNNs and LLMs to model complex RS problems more efficiently byleveraging the graph-based structure of user-item relationships alongsidetextual understanding. In this survey, we provide a comprehensive overview ofGFM-based RS technologies by introducing a clear taxonomy of currentapproaches, diving into methodological details, and highlighting key challengesand future directions. By synthesizing recent advancements, we aim to offervaluable insights into the evolving landscape of GFM-based recommender systems.</description>
      <author>example@mail.com (Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi)</author>
      <guid isPermaLink="false">2502.08346v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping</title>
      <link>http://arxiv.org/abs/2502.08054v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 11 figures, https://combo-grasp.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文解决了机器人抓取中物体被遮挡的问题，即由于环境约束如表面碰撞导致所需的抓取姿态在运动学上不可行的情况下的抓取。传统机器人操作方法难以处理在这种情况下人类常用的非握持或双臂策略的复杂性。最先进的强化学习（RL）方法由于任务本身固有的复杂性而不适合使用。而基于演示的学习需要收集大量的专家演示，这通常是不切实际的。因此，本文借鉴了人类在双手协调以稳定和重新定向物体时采用的方法，专注于一个双臂机器人设置来解决这个问题。具体来说，我们引入了一种基于约束的手动操作方法（COMBO-Grasp），这是一种学习驱动的方法，利用两个协同策略：一种是使用自监督数据集训练的约束策略生成稳定的姿态；另一种是通过强化学习训练的抓取策略重新定向和抓住目标物体。关键贡献在于价值函数引导下的策略协调。具体来说，在对抓取策略进行RL训练时，通过对联合训练的价值函数的梯度优化来精炼约束策略的输出，从而提高双臂协同操作的能力并提升任务性能。最后，COMBO-Grasp使用了教师-学生策略蒸馏方法将点云基策略有效部署到现实环境中。实证研究表明，与竞争基准方法相比，COMBO-Grasp在模拟和真实环境下的未见物体上显著提高了任务成功率。&lt;h4&gt;背景&lt;/h4&gt;机器人在处理遮挡抓取问题时面临挑战，传统的机器人操作方法无法有效解决这种复杂性的问题，同时最先进的强化学习方法也因为任务的固有复杂性而不适用。基于演示的学习策略难以获取足够的专家数据进行训练。&lt;h4&gt;目的&lt;/h4&gt;设计一种可以模仿人类双臂协作技巧来处理遮挡抓取问题的方法，并验证其在模拟和真实环境中的性能。&lt;h4&gt;方法&lt;/h4&gt;{'COMBO-Grasp': '提出了一种学习驱动的解决方案，该方案利用两个协同策略：一个负责稳定物体姿态，另一个负责重新定向并抓取目标。这种方法通过价值函数引导下的策略协调来改进双臂协同操作的能力，并采用教师-学生策略蒸馏将点云基策略有效部署到现实环境中。', '关键创新': '在对抓取策略进行强化学习训练时，通过对联合训练的价值函数的梯度优化来精炼约束策略的输出'}&lt;h4&gt;主要发现&lt;/h4&gt;COMBO-Grasp方法相比传统方法和其它基准方法，在处理遮挡物体上的任务成功率显著提高。&lt;h4&gt;结论&lt;/h4&gt;通过模仿人类双臂协调技巧并采用价值函数引导下的策略协同，COMBO-Grasp能有效地解决被遮挡环境中的机器人抓取问题，并且在模拟与真实环境中均表现出良好的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of occluded robot grasping, i.e. graspingin situations where the desired grasp poses are kinematically infeasible due toenvironmental constraints such as surface collisions. Traditional robotmanipulation approaches struggle with the complexity of non-prehensile orbimanual strategies commonly used by humans in these circumstances.State-of-the-art reinforcement learning (RL) methods are unsuitable due to theinherent complexity of the task. In contrast, learning from demonstrationrequires collecting a significant number of expert demonstrations, which isoften infeasible. Instead, inspired by human bimanual manipulation strategies,where two hands coordinate to stabilise and reorient objects, we focus on abimanual robotic setup to tackle this challenge. In particular, we introduceConstraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), alearning-based approach which leverages two coordinated policies: a constraintpolicy trained using self-supervised datasets to generate stabilising poses anda grasping policy trained using RL that reorients and grasps the target object.A key contribution lies in value function-guided policy coordination.Specifically, during RL training for the grasping policy, the constraintpolicy's output is refined through gradients from a jointly trained valuefunction, improving bimanual coordination and task performance. Lastly,COMBO-Grasp employs teacher-student policy distillation to effectively deploypoint cloud-based policies in real-world environments. Empirical evaluationsdemonstrate that COMBO-Grasp significantly improves task success rates comparedto competitive baseline approaches, with successful generalisation to unseenobjects in both simulated and real-world environments.</description>
      <author>example@mail.com (Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner)</author>
      <guid isPermaLink="false">2502.08054v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>GraphCompNet: A Position-Aware Model for Predicting and Compensating Shape Deviations in 3D Printing</title>
      <link>http://arxiv.org/abs/2502.09652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于数据驱动的算法，用于建模和补偿增材制造中的形状偏差。该方法利用图神经网络与生成对抗网络相结合的方法来提高复杂几何结构的精度。&lt;h4&gt;背景&lt;/h4&gt;传统分析模型及测量技术在提升增材制造的几何精度方面存在局限性，尤其不适用于大规模生产；机器学习的进步改善了补偿精确度，但无法很好地处理复杂的几何形状和位置依赖的变化。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的数据驱动算法，以提高增材制造过程中的几何精度并适应于大规模生产需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为GraphCompNet的计算框架，该框架结合了基于图的神经网络以及生成对抗网络(GAN)启发式的训练流程。通过使用点云数据和动态图卷积神经网络(DGCNN)，GraphCompNet能够处理复杂形状并融入位置特定的热力学与机械因素。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，所提出的方法能显著提高补偿精度(35至65个百分点)且适应于打印空间内的位置依赖变化。此方法推进了增材制造中的数字孪生技术的发展，并能够实现大规模、实时监控和优化。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发高精度、自动化的工业规模设计与制造系统提供了支持，有助于解决当前增材制造过程控制中存在的关键问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a data-driven algorithm for modeling and compensatingshape deviations in additive manufacturing (AM), addressing challenges ingeometric accuracy and batch production. While traditional methods, such asanalytical models and metrology, laid the groundwork for geometric precision,they are often impractical for large-scale production. Recent advancements inmachine learning (ML) have improved compensation precision, but issues remainin generalizing across complex geometries and adapting to position-dependentvariations. We present a novel approach for powder bed fusion (PBF) processes,using GraphCompNet, which is a computational framework combining graph-basedneural networks with a generative adversarial network (GAN)-inspired trainingprocess. By leveraging point cloud data and dynamic graph convolutional neuralnetworks (DGCNNs), GraphCompNet models complex shapes and incorporatesposition-specific thermal and mechanical factors. A two-stage adversarialtraining procedure iteratively refines compensated designs via acompensator-predictor architecture, offering real-time feedback andoptimization. Experimental validation across diverse shapes and positions showsthe framework significantly improves compensation accuracy (35 to 65 percent)across the entire print space, adapting to position-dependent variations. Thiswork advances the development of Digital Twin technology for AM, enablingscalable, real-time monitoring and compensation, and addressing critical gapsin AM process control. The proposed method supports high-precision, automatedindustrial-scale design and manufacturing systems.</description>
      <author>example@mail.com (Lei, Chen, Juheon Lee, Juan Carlos Catana, Tsegai Yhdego, Nathan Moroney, Mohammad Amin Nabian, Hui Wang, Jun Zeng)</author>
      <guid isPermaLink="false">2502.09652v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>The Science of Evaluating Foundation Models</title>
      <link>http://arxiv.org/abs/2502.09670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大模型的评估面临诸多挑战，现有文献未能提供全面且一致的过程。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在自然语言处理领域带来了革命性的变化，但其规模、能力以及跨应用场景部署使得它们的评估变得复杂。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在解决大型语言模型（LLM）评估中的三个关键方面：正式化评估过程、提供实用工具和框架、综述最近的工作进展。&lt;h4&gt;方法&lt;/h4&gt;(1) 提供适用于具体使用场景上下文的结构化评估框架；(2) 开发清单和模板等操作性工具，确保评估的全面性和可重复性；(3) 针对LLM评估领域的最新进展进行有针对性的回顾，强调实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;通过提供定制化的评估流程和实用工具，可以更加系统地应对大型模型多样性的挑战，并考虑伦理和社会影响因素。&lt;h4&gt;结论&lt;/h4&gt;现有的评估方法需要改进以涵盖更广泛的使用场景并综合考量道德与运营问题。本研究提供的框架可为未来的研究者和实践者提供指导。&lt;h4&gt;翻译&lt;/h4&gt;大规模基础模型在自然语言处理领域引发了一系列新现象，但这些模型的复杂性及其广泛应用使得对其进行有效评估变得颇具挑战性。现有的学术文献通常关注于特定方面，比如基准性能或具体任务，而缺乏一个整合多样化使用场景并考虑更广泛伦理和操作问题的综合过程。本文重点关注三大关键领域：正式化评估流程、提供实用工具与框架以及综述近期相关工作进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergent phenomena of large foundation models have revolutionized naturallanguage processing. However, evaluating these models presents significantchallenges due to their size, capabilities, and deployment across diverseapplications. Existing literature often focuses on individual aspects, such asbenchmark performance or specific tasks, but fails to provide a cohesiveprocess that integrates the nuances of diverse use cases with broader ethicaland operational considerations. This work focuses on three key aspects: (1)Formalizing the Evaluation Process by providing a structured framework tailoredto specific use-case contexts, (2) Offering Actionable Tools and Frameworkssuch as checklists and templates to ensure thorough, reproducible, andpractical evaluations, and (3) Surveying Recent Work with a targeted review ofadvancements in LLM evaluation, emphasizing real-world applications.</description>
      <author>example@mail.com (Jiayi Yuan, Jiamu Zhang, Andrew Wen, Xia Hu)</author>
      <guid isPermaLink="false">2502.09670v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks</title>
      <link>http://arxiv.org/abs/2502.06153v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种低张量秩适应（LoTRA）技术，用于Kolmogorov-Arnold网络（KANs）的微调和参数更新。该方法基于张量分解理论，并通过实验证明了在解决偏微分方程和其他科学任务时的有效性。&lt;h4&gt;背景&lt;/h4&gt;KANs已经在多个领域展示出作为多层感知器（MLPs）替代方案的潜力，特别是在与科学相关的任务中。然而，对于KANs的迁移学习仍然是一个相对未探索的领域。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的适应方法LoTRA以改进KANs在迁移学习中的性能，并通过张量分解理论分析其表达能力。&lt;h4&gt;方法&lt;/h4&gt;基于Tucker张量分解和KAN参数更新的低张量秩结构，提出了洛特拉（LoTRA）技术。此外，还提供了一种选择合适的学习率来实现高效训练的方法论分析。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证明了所提出的适应性学习速率策略的有效性和对于迁移学习中使用KANs求解偏微分方程的效率提升。研究还表明，在函数表示和图像分类任务中，通过低张量秩分解可以减少参数数量而不损失性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为KANs的迁移学习提供了一种新的有效技术，并展示了降低模型大小以保持高性能的能力。&lt;h4&gt;翻译&lt;/h4&gt;Kolmogorov-Arnold网络（KAN）已经在不同领域中展示出了作为多层感知器（MLPs）替代方案的巨大潜力，特别是在科学相关的任务上。然而，对于KANs的迁移学习仍然是一个相对未探索的研究领域。本文受张量分解启发，并结合了KAN参数更新低张量秩结构的相关证据，开发了一种名为“Low Tensor Rank Adaptation” (LoTRA) 的技术用于KAN的微调。我们基于Tucker分解近似值研究了LoTRA的表现力，并提供了一个理论分析来选择每个LoTRA组件的学习率以实现高效训练。研究表明使用相同的跨所有组件的学习速率会导致训练效率低下，强调需要采用自适应学习速率策略。除了理论见解外，本文还探索了将LoTRA应用于通过微调KANs有效解决各种偏微分方程（PDE）的方法。此外，我们提出了一种“Slim KAN”，它利用了KAN参数张量的内在低张量秩属性以减少模型大小同时保持性能优越。实验结果验证了所提出的适应性学习率选择策略的有效性和使用LoTRA进行KAN迁移学习求解偏微分方程的有效性。此外，在函数表示和图像分类任务中的进一步评估凸显了LoTRA的表现力以及通过低张量秩分解实现参数减少的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov--Arnold networks (KANs) have demonstrated their potential as analternative to multi-layer perceptions (MLPs) in various domains, especiallyfor science-related tasks. However, transfer learning of KANs remains arelatively unexplored area. In this paper, inspired by Tucker decomposition oftensors and evidence on the low tensor-rank structure in KAN parameter updates,we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We studythe expressiveness of LoTRA based on Tucker decomposition approximations.Furthermore, we provide a theoretical analysis to select the learning rates foreach LoTRA component to enable efficient training. Our analysis also shows thatusing identical learning rates across all components leads to inefficienttraining, highlighting the need for an adaptive learning rate strategy. Beyondtheoretical insights, we explore the application of LoTRA for efficientlysolving various partial differential equations (PDEs) by fine-tuning KANs.Additionally, we propose Slim KANs that incorporate the inherentlow-tensor-rank properties of KAN parameter tensors to reduce model size whilemaintaining superior performance. Experimental results validate the efficacy ofthe proposed learning rate selection strategy and demonstrate the effectivenessof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations onSlim KANs for function representation and image classification tasks highlightthe expressiveness of LoTRA and the potential for parameter reduction throughlow tensor-rank decomposition.</description>
      <author>example@mail.com (Yihang Gao, Michael K. Ng, Vincent Y. F. Tan)</author>
      <guid isPermaLink="false">2502.06153v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning for cell stage classification of animal embryos</title>
      <link>http://arxiv.org/abs/2502.07360v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视频显微镜技术和机器学习结合为研究体外产生的胚胎早期发育提供了有前景的方法。但手动注释发育事件，尤其是细胞分裂过程非常耗时且难以扩展。&lt;h4&gt;背景&lt;/h4&gt;现有的手动生成的生物学家对胚胎发育阶段的手动标注在时间和效率上存在局限性，特别是在处理大量数据集和低质量图像的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动分类胚胎从2D时间推移显微镜视频中细胞阶段的方法，使用深度学习技术，针对牛胚胎发育进行分析，并创建了一个新的Bovine Embryos Cell Stages (ECS) 数据集。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的方法CLEmbryo，该方法结合监督对比学习和焦点损失训练，同时采用轻量级的3D神经网络CSN-50作为编码器。这种方法能够处理图像质量低、牛细胞暗化问题以及发育阶段边界的类别模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;CLEmbryo在Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中都优于现有的最先进的方法，表明其具有良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了自动分类牛胚胎细胞阶段的有效性，并为其他生物医学应用中的相似问题提供了可能解决方案。&lt;h4&gt;挑战&lt;/h4&gt;该研究面临三个主要挑战：图像质量差及暗色的牛细胞导致识别细胞阶段困难；发育阶段边界处类别模糊；数据分布不平衡。&lt;h4&gt;翻译&lt;/h4&gt;视频显微镜技术与机器学习结合为体外产生的胚胎早期发育的研究提供了一种有前景的方法。然而，手动标注生物学家的发育事件（尤其是细胞分裂）在时间和效率上都难以承受且无法扩展至实际应用中。我们旨在使用深度学习方法自动分类2D时间推移显微镜视频中的胚胎细胞阶段，并专注于牛胚胎发育分析的应用，因为我们主要关注畜牧业领域并创建了一个Bovine Embryos Cell Stages (ECS) 数据集。挑战包括：1. 低质量图像和暗色的牛细胞使得难以识别细胞阶段；2. 发育阶段边界处类别模糊性；3. 数据分布不平衡。为解决这些问题，我们提出了一种新的方法CLEmbryo，它结合了监督对比学习与焦点损失训练，并采用轻量级的3D神经网络CSN-50作为编码器。我们的方法表现出良好的泛化能力，在Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中均优于现有的最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video microscopy, when combined with machine learning, offers a promisingapproach for studying the early development of in vitro produced (IVP) embryos.However, manually annotating developmental events, and more specifically celldivisions, is time-consuming for a biologist and cannot scale up for practicalapplications. We aim to automatically classify the cell stages of embryos from2D time-lapse microscopy videos with a deep learning approach. We focus on theanalysis of bovine embryonic development using video microscopy, as we areprimarily interested in the application of cattle breeding, and we have createda Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)low-quality images and bovine dark cells that make the identification of cellstages difficult, (2) class ambiguity at the boundaries of developmentalstages, and (3) imbalanced data distribution. To address these challenges, weintroduce CLEmbryo, a novel method that leverages supervised contrastivelearning combined with focal loss for training, and the lightweight 3D neuralnetwork CSN-50 as an encoder. We also show that our method generalizes well.CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS datasetand the publicly available NYU Mouse Embryos dataset.</description>
      <author>example@mail.com (Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis)</author>
      <guid isPermaLink="false">2502.07360v2</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Image Super-Resolution with Guarantees via Conformal Generative Models</title>
      <link>http://arxiv.org/abs/2502.09664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于符合预测技术的新方法，用于生成图像超分辨率模型中的不确定性量化。&lt;h4&gt;背景&lt;/h4&gt;随着机器学习基础模型在图像超分辨率领域使用越来越多，需要一种既稳健又可解释的不确定性量化方法。&lt;h4&gt;目的&lt;/h4&gt;通过开发适应性强、数据获取容易且可根据局部图像相似性度量自定义的方法来满足这一需求，并为生成模型提供可靠的“置信度掩模”。&lt;h4&gt;方法&lt;/h4&gt;该方法采用符合预测技术，能够应用于任何黑盒生成模型（包括那些被隐藏在不透明API后的），只需要易于获得的数据进行校准。&lt;h4&gt;主要发现&lt;/h4&gt;证明了该方法具有强大的理论保证，涵盖了根据所选局部图像相似性度量的保真度误差控制、重构质量以及数据泄露时的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过实证评估验证了该方法的有效性和性能。&lt;h4&gt;翻译&lt;/h4&gt;随着生成机器学习基础模型在图像超分辨率领域中的广泛应用，迫切需要一种既稳健又可解释的不确定性量化方法。本文提出了一种基于符合预测技术的新方法，用于任何黑盒生成模型（包括被隐藏于不透明API后的）创建“置信度掩模”，该掩模可以可靠且直观地显示生成图像中哪些部分是可信的。该方法只需要易于获取的数据进行校准，并通过选择局部图像相似性度量实现高度定制化，同时具备强大的理论保证，在保真度误差控制、重构质量和面对数据泄露时的鲁棒性方面均有表现。最终实证评估验证了这种方法的有效性和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of generative ML foundation models for imagesuper-resolution calls for robust and interpretable uncertainty quantificationmethods. We address this need by presenting a novel approach based on conformalprediction techniques to create a "confidence mask" capable of reliably andintuitively communicating where the generated image can be trusted. Our methodis adaptable to any black-box generative model, including those locked behindan opaque API, requires only easily attainable data for calibration, and ishighly customizable via the choice of a local image similarity metric. We provestrong theoretical guarantees for our method that span fidelity error control(according to our local image similarity metric), reconstruction quality, androbustness in the face of data leakage. Finally, we empirically evaluate theseresults and establish our method's solid performance.</description>
      <author>example@mail.com (Eduardo Adame, Daniel Csillag, Guilherme Tegoni Goedert)</author>
      <guid isPermaLink="false">2502.09664v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>SASVi - Segment Any Surgical Video</title>
      <link>http://arxiv.org/abs/2502.09653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SASVi，一种基于帧级Mask R-CNN Overseer模型的重新提示机制，用于改善基础模型SAM2在手术视频分割中的时间一致性。&lt;h4&gt;背景&lt;/h4&gt;训练于大量公共数据集的基础模型往往需要额外的微调或重新提示机制才能应用于视觉差异显著的目标领域（如手术视频）。由于缺乏目标领域的专业知识，这些模型无法准确捕捉特定语义信息，特别是在对象离开场景或新对象进入时的表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高基础模型在手术视频分割中的时间一致性和表现力。&lt;h4&gt;方法&lt;/h4&gt;提出了SASVi机制，利用少量稀缺注释数据训练的帧级Mask R-CNN Overseer模型，在场景组合变化时自动重新提示SAM2基础模型。这使得能够对完整的手术视频进行平滑且完整的时间分割。&lt;h4&gt;主要发现&lt;/h4&gt;基于Overseer模型的重新提示显著提高了手术视频分割的时间一致性，相较于其他类似提示技术改进了至少1.5%。&lt;h4&gt;结论&lt;/h4&gt;SASVi可以作为一个新基准，在注释数据稀缺的情况下实现手术视频的平滑和时间一致性的分割。该方法允许我们利用有限的数据获取大规模数据集完整视频的完全注释，并公开提供这些注释，为未来手术数据分析模型的发展提供了丰富的数据支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已经用中文进行总结、背景介绍、目的声明、方法描述、主要发现和结论阐述。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Foundation models, trained on multitudes of public datasets, oftenrequire additional fine-tuning or re-prompting mechanisms to be applied tovisually distinct target domains such as surgical videos. Further, withoutdomain knowledge, they cannot model the specific semantics of the targetdomain. Hence, when applied to surgical video segmentation, they fail togeneralise to sections where previously tracked objects leave the scene or newobjects enter. Methods: We propose SASVi, a novel re-prompting mechanism basedon a frame-wise Mask R-CNN Overseer model, which is trained on a minimal amountof scarcely available annotations for the target domain. This modelautomatically re-prompts the foundation model SAM2 when the scene constellationchanges, allowing for temporally smooth and complete segmentation of fullsurgical videos. Results: Re-prompting based on our Overseer modelsignificantly improves the temporal consistency of surgical video segmentationcompared to similar prompting techniques and especially frame-wisesegmentation, which neglects temporal information, by at least 1.5%. Ourproposed approach allows us to successfully deploy SAM2 to surgical videos,which we quantitatively and qualitatively demonstrate for three differentcholecystectomy and cataract surgery datasets. Conclusion: SASVi can serve as anew baseline for smooth and temporally consistent segmentation of surgicalvideos with scarcely available annotation data. Our method allows us toleverage scarce annotations and obtain complete annotations for full videos ofthe large-scale counterpart datasets. We make those annotations publiclyavailable, providing extensive annotation data for the future development ofsurgical data science models.</description>
      <author>example@mail.com (Ssharvien Kumar Sivakumar, Yannik Frisch, Amin Ranem, Anirban Mukhopadhyay)</author>
      <guid isPermaLink="false">2502.09653v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds</title>
      <link>http://arxiv.org/abs/2502.10363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://why618188.github.io/beamdojo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种名为BeamDojo的强化学习框架，该框架专为使类人机器人在稀疏支撑点的环境中实现敏捷行走而设计。&lt;h4&gt;背景&lt;/h4&gt;类人机器人在具有稀疏支撑点的风险地形中行走时面临挑战，需要精确的脚步放置和稳定移动。现有的面向四足机器人的方法通常无法推广到类人机器人上，因为两者在脚部几何形状和形态稳定性方面存在差异；基于学习的方法虽然能用于类人机器人，但在复杂地形上的性能较差。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的限制，设计了一种新的强化学习框架来促进类人机器人的敏捷行走并提高其适应稀疏支撑点环境的能力。&lt;h4&gt;方法&lt;/h4&gt;BeamDojo引入了针对多边形脚部设计的脚步采样奖励机制，并采用双批评家模型以平衡密集运动奖励和稀疏脚步放置奖励的学习过程。此外，通过两阶段强化学习方式来鼓励足够的探索：第一阶段在平坦地形上进行训练同时提供任务环境感知观察，第二阶段则是在实际环境中微调策略。&lt;h4&gt;主要发现&lt;/h4&gt;BeamDojo框架不仅能在模拟器中实现高效的学习，在现实世界应用时也能使类人机器人实现在稀疏支撑点的精准脚步放置，并且即使面对重大外部干扰仍能保持高成功率。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了BeamDojo在推动类人机器人在具有挑战性的地形上的运动能力方面的重要进展，为未来的研究开辟了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traversing risky terrains with sparse footholds poses a significant challengefor humanoid robots, requiring precise foot placements and stable locomotion.Existing approaches designed for quadrupedal robots often fail to generalize tohumanoid robots due to differences in foot geometry and unstable morphology,while learning-based approaches for humanoid locomotion still face greatchallenges on complex terrains due to sparse foothold reward signals andinefficient learning processes. To address these challenges, we introduceBeamDojo, a reinforcement learning (RL) framework designed for enabling agilehumanoid locomotion on sparse footholds. BeamDojo begins by introducing asampling-based foothold reward tailored for polygonal feet, along with a doublecritic to balancing the learning process between dense locomotion rewards andsparse foothold rewards. To encourage sufficient trail-and-error exploration,BeamDojo incorporates a two-stage RL approach: the first stage relaxes theterrain dynamics by training the humanoid on flat terrain while providing itwith task terrain perceptive observations, and the second stage fine-tunes thepolicy on the actual task terrain. Moreover, we implement a onboard LiDAR-basedelevation map to enable real-world deployment. Extensive simulation andreal-world experiments demonstrate that BeamDojo achieves efficient learning insimulation and enables agile locomotion with precise foot placement on sparsefootholds in the real world, maintaining a high success rate even undersignificant external disturbances.</description>
      <author>example@mail.com (Huayi Wang, Zirui Wang, Junli Ren, Qingwei Ben, Tao Huang, Weinan Zhang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.10363v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MITO: Enabling Non-Line-of-Sight Perception using Millimeter-waves through Real-World Datasets and Simulation Tools</title>
      <link>http://arxiv.org/abs/2502.10259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的多光谱毫米波图像数据集MITO。&lt;h4&gt;背景&lt;/h4&gt;毫米波信号能够穿透日常遮挡物，但由于公开的毫米波图像资料稀缺及跨学科挑战的存在，计算机视觉研究者在开发基于非视距感知算法和模型方面遇到困难。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出了一个真实世界的数据集和开源模拟工具用于毫米波成像。&lt;h4&gt;方法&lt;/h4&gt;{'数据收集': '使用UR5机器人手臂、两个不同频率的毫米波雷达及RGB-D相机采集超过76个YCB数据集中物体的真实世界3D毫米波图像（超过580幅）。', '信号处理': '通过信号处理管道捕捉并生成真实世界的3D毫米波图像。', '模拟工具': '开发了一个开源模拟工具，可以为任何三维三角网格生成合成的毫米波图像。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'数据集特性': '提供视距和非视距的真实世界毫米波图像、RGB-D图像及地面实况分割蒙版。', '模型性能': '使用segment anything model (SAM) 进行毫米波图像对象分割，达到92.6%的中位精度和64%的中位召回率；训练一个分类器，在非视距条件下可以识别物体（基于合成图像训练），可对真实世界图像进行85%准确度的分类。'}&lt;h4&gt;结论&lt;/h4&gt;相信MITO将成为开发非视距感知的重要资源，类似于早期相机数据集在塑造计算机视觉领域中的作用。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了MITO，这是第一个包含日常物体多光谱毫米波（mmWave）图像的数据集。不同于可见光，mmWave信号能够穿透日常生活中的遮挡物（例如纸板箱、布料和塑料）。然而，由于公开可用的mmWave图象稀缺以及收集和处理mmWave信号的跨学科挑战，在今天对于计算机视觉研究人员来说开发基于非视距感知算法和模型仍然很困难。为了解决这些挑战，我们引入了一个真实世界的数据集和开源模拟工具用于毫米波成像。该数据集使用UR5机器人手臂、两个不同频率的mmWave雷达及RGB-D相机采集超过76个YCB数据集中物体的真实世界3D mmWave图像（超过580幅）。通过信号处理管道，我们捕捉并生成这些图像，并提供了视距和非视距条件下的真实毫米波图象、RGB-D图象以及地面实况分割蒙版。我们还开发了一个开源模拟工具，可以为任何三维三角网格生成合成的毫米波图像，当与真实世界mmWave图像进行比较时，该工具达到了94%的中位F-Score。我们在多个非视距CV任务中展示了数据集和模拟工具的价值：首先，使用segment anything model (SAM) 对mmWave图像执行对象分割，并达到92.6%的中位精度和64%的中位召回率；其次，我们训练了一个分类器，在非视距条件下识别物体（基于合成图像进行训练），该分类器可以对真实世界图象做出85%准确度的分类。我们认为MITO将为计算机视觉研究人员开发非视距感知提供宝贵的资源，这与早期相机数据集在塑造领域中的作用相似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MITO, the first dataset of multi-spectral millimeter-wave (mmWave)images of everyday objects. Unlike visible light, mmWave signals can imagethrough everyday occlusions (e.g., cardboard boxes, fabric, plastic). However,due to the dearth of publicly-available mmWave images and the interdisciplinarychallenges in collecting and processing mmWave signals, it remains difficulttoday for computer vision researchers to develop mmWave-based non-line-of-sightperception algorithms and models.  To overcome these challenges, we introduce a real-world dataset andopen-source simulation tool for mmWave imaging. The dataset is acquired using aUR5 robotic arm with two mmWave radars operating at different frequencies andan RGB-D camera. Through a signal processing pipeline, we capture and createover 580 real-world 3D mmWave images from over 76 different objects in the YCBdataset, a standard dataset for robotics manipulation. We provide real-worldmmWave images in line-of-sight and non-line-of-sight, as well as RGB-D imagesand ground truth segmentation masks. We also develop an open-source simulationtool that can be used to generate synthetic mmWave images for any 3D trianglemesh, which achieves a median F-Score of 94% when compared to real-world mmWaveimages.  We show the usefulness of this dataset and simulation tool in multiple CVtasks in non-line-of-sight. First, we perform object segmentation for mmWaveimages using the segment anything model (SAM), and achieve a median precisionand recall of 92.6% and 64%. Second, we train a classifier that can recognizeobjects in non-line-of-sight. It is trained on synthetic images and canclassify real-world images with 85% accuracy.  We believe MITO will be a valuable resource for computer vision researchersin developing non-line-of-sight perception, similar to how early camera-baseddatasets shaped the field.</description>
      <author>example@mail.com (Laura Dodds, Tara Boroushaki, Fadel Adib)</author>
      <guid isPermaLink="false">2502.10259v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Integrated Multi-Simulation Environments for Aerial Robotics Research</title>
      <link>http://arxiv.org/abs/2502.10218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种解决方案，用于将Sphinx模拟器中的无人机集成到Gazebo仿真环境中。通过创建一个镜像实例来克服现有部分开源或闭源模拟器的限制，并展示了该方法在目标追踪任务上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人系统开发中，不同的组件可能需要使用不同环境或模拟器进行模拟。特别是在使用Sphinx和Gazebo这样的仿真工具时，如何将它们集成在一起是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;解决部分开源或闭源仿真器中的限制问题，并展示集成后的无人机在目标追踪任务上的表现优于默认的控制器。&lt;h4&gt;方法&lt;/h4&gt;通过创建一个镜像实例的方法将Parrot公司的Sphinx模拟器中的Anafi无人机融入到Gazebo环境中。利用模型预测控制（MPC）进行性能测试，对比传统PID控制器的表现。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的集成仿真环境在目标追踪任务中优于传统的PID控制器。&lt;h4&gt;结论&lt;/h4&gt;通过本研究提出的方法，可以有效解决不同模拟器之间的兼容性问题，并提高了无人机系统开发的安全性和效率。&lt;h4&gt;翻译&lt;/h4&gt;模拟框架在机器人应用程序的安全开发中扮演着重要角色。然而，不同的组件往往需要使用不同的环境/模拟器进行模拟，这给构建一个集成的机器人框架带来了挑战。特别是对于部分开源或闭源的模拟器来说，通常会出现两个核心限制：i) 场景中的其他物体（除了指定的机器人）在运行时无法通过如ROS之类的接口控制；ii) 无法实时获取场景中对象的状态信息（例如位置、速度等）。在这项工作中，我们解决了这些问题，并描述了将Parrot无人机提供的强大模拟器Sphinx中的无人机集成到Gazebo仿真器中的解决方案。为了实现这一点，我们在现有的基于Gazebo的环境中添加了一个镜像实例的无人机。我们的综合模拟环境的一个有希望的应用是目标追踪任务，在空中多机器人场景中很常见。因此，我们还通过严格的测试在模拟和现实世界的跟踪实验中实施并评估了一种模型预测控制器（MPC），其在各种动态追踪场景中的性能优于Parrot流行的Anafi无人机默认提供的基于PID的控制框架，从而增强了系统的整体效用。我们在一个现有的Gazebo环境中包含了一个Anafi无人机，并通过针对自定义的PID控制器基线进行模拟和实际世界跟踪实验来评估MPC的表现。源代码发布在https://github.com/robot-perception-group/anafi_sim上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation frameworks play a pivotal role in the safe development of roboticapplications. However, often different components of an envisioned roboticsystem are best simulated in different environments/simulators. This poses asignificant challenge in simulating the entire project into a single integratedrobotic framework. Specifically, for partially-open or closed-sourcesimulators, often two core limitations arise. i) Actors in the scene other thanthe designated robots cannot be controlled during runtime via interfaces suchas ROS and ii) retrieving real-time state information (such as pose, velocityetc.) of objects in the scene is prevented. In this work, we address theselimitations and describe our solution for the use case of integrating aerialdrones simulated by the powerful simulator Sphinx (provided by Parrot Drone)into the Gazebo simulator. We achieve this by means of a mirrored instance of adrone that is included into existing Gazebo-based environments. A promisingapplication of our integrated simulation environment is the task of targettracking that is common in aerial multi-robot scenarios. Therefore, todemonstrate the effectiveness our our integrated simulation, we also implementa model predictive controller (MPC) that outperforms the default PID-basedcontroller framework provided with the Parrot's popular Anafi drone in variousdynamic tracking scenarios thus enhancing the utility of the overall system. Wetest our solution by including the Anafi drone in an existing Gazebo-basedsimulation and evaluate the performance of the MPC through rigorous testing insimulated and real-world tracking experiments against a customized PIDcontroller baseline. Source code is published onhttps://github.com/robot-perception-group/anafi_sim.</description>
      <author>example@mail.com (Pascal Goldschmid, Aamir Ahmad)</author>
      <guid isPermaLink="false">2502.10218v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>MonoForce: Learnable Image-conditioned Physics Engine</title>
      <link>http://arxiv.org/abs/2502.10156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Robotics (T-RO), 2025. Code:  https://github.com/ctu-vras/monoforce&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合物理感知神经符号层的新型模型，用于从车载摄像头图像预测机器人在崎岖越野地形上的轨迹。&lt;h4&gt;背景&lt;/h4&gt;当前机器人系统在现实世界中的性能差距依然显著，特别是在复杂和不可预知的地面上。现有模型通常缺乏对经典力学定律的遵守，同时难以大规模数据学习。&lt;h4&gt;目的&lt;/h4&gt;开发一种结合物理知识与神经网络优势的混合架构，用于提高机器人的轨迹预测精度，并缩小仿真与真实环境之间的差距。&lt;h4&gt;方法&lt;/h4&gt;模型包括一个黑盒组件，它根据地形条件预测机器人-地面交互力；一个可微分物理引擎将这些力应用于计算机器人运动路径。整个体系结构为端到端的可微性设计。&lt;h4&gt;主要发现&lt;/h4&gt;该架构能够显著减少仿真与实际环境之间的差距，并且由于其快速模拟速度和可微特性，适用于多种应用如模型预测控制、轨迹规划、监督学习及强化学习等。&lt;h4&gt;结论&lt;/h4&gt;通过结合物理原理与数据驱动的神经网络方法，新模型在处理复杂地形时表现出卓越性能。开源代码和实验数据也已公开分享。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新型模型，用于从车载摄像头图像预测机器人在崎岖越野地形上的轨迹。该模型利用了一个具有物理学意识的神经符号层来执行经典力学定律，并保持了通过大规模数据学习的能力，因为它是一个端到端可微分架构。所提出的混合模型结合了一个黑盒组件和一个神经符号层，前者用于预测与地面交互的力量，后者包括一个可微分物理引擎，该引擎通过查询接触点处的这些力量来计算机器人的轨迹。由于该架构包含了大量的几何和物理先验知识，因此可以将结果模型视为基于真实图像的学习型物理引擎，每秒能产生10,000条轨迹。我们论证并实验证明了这种架构减少了仿真与现实之间的差距，并缓解了分布外敏感性问题。通过结合快速模拟速度和可微特性，该模型非常适合各种应用如模型预测控制、轨迹规划、监督学习或强化学习及SLAM等使用。代码和数据已公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel model for the prediction of robot trajectories on roughoffroad terrain from the onboard camera images. This model enforces the laws ofclassical mechanics through a physics-aware neural symbolic layer whilepreserving the ability to learn from large-scale data as it is end-to-enddifferentiable. The proposed hybrid model integrates a black-box component thatpredicts robot-terrain interaction forces with a neural-symbolic layer. Thislayer includes a differentiable physics engine that computes the robot'strajectory by querying these forces at the points of contact with the terrain.As the proposed architecture comprises substantial geometrical and physicspriors, the resulting model can also be seen as a learnable physics engineconditioned on real images that delivers $10^4$ trajectories per second. Weargue and empirically demonstrate that this architecture reduces thesim-to-real gap and mitigates out-of-distribution sensitivity. Thedifferentiability, in conjunction with the rapid simulation speed, makes themodel well-suited for various applications including model predictive control,trajectory shooting, supervised and reinforcement learning or SLAM. The codesand data are publicly available.</description>
      <author>example@mail.com (Ruslan Agishev, Karel Zimmermann)</author>
      <guid isPermaLink="false">2502.10156v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models</title>
      <link>http://arxiv.org/abs/2502.10090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Manual2Skill框架，这是一个使机器人能够通过高级手册指令执行复杂装配任务的系统。&lt;h4&gt;背景&lt;/h4&gt;人类可以理解并根据抽象的手册指南完成复杂的操作任务，而机器人在这方面面临巨大挑战，因为它们无法解读这些指令并将之转化为可执行的动作。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够让机器人利用视觉语言模型从指导图片中提取结构化信息，并使用此信息构建层次装配图的框架，以便于执行复杂装配任务。&lt;h4&gt;方法&lt;/h4&gt;采用视觉语言模型（VLM）来解析手册中的图像，建立零件、子装配件及其关系之间的层次结构。同时运用姿态估计预测各组件在装配过程中的相对6D姿态，并生成可供机器人实施的动作序列。&lt;h4&gt;主要发现&lt;/h4&gt;通过成功组装多件真实世界的IKEA家具证明了Manual2Skill的有效性，显示其能够高效精确地管理长期操作任务，显著提升了从手册学习的实用性。&lt;h4&gt;结论&lt;/h4&gt;这项研究标志着一个突破，使得机器人系统更接近于像人类那样理解和执行复杂的操控任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个框架——Manual2Skill，它使机器人能通过高级指令文档来进行复杂装配工作。该框架利用视觉语言模型解析手册中的结构化信息，并构建装配图，帮助机器人实现精准的长时操作任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans possess an extraordinary ability to understand and execute complexmanipulation tasks by interpreting abstract instruction manuals. For robots,however, this capability remains a substantial challenge, as they cannotinterpret abstract instructions and translate them into executable actions. Inthis paper, we present Manual2Skill, a novel framework that enables robots toperform complex assembly tasks guided by high-level manual instructions. Ourapproach leverages a Vision-Language Model (VLM) to extract structuredinformation from instructional images and then uses this information toconstruct hierarchical assembly graphs. These graphs represent parts,subassemblies, and the relationships between them. To facilitate taskexecution, a pose estimation model predicts the relative 6D poses of componentsat each assembly step. At the same time, a motion planning module generatesactionable sequences for real-world robotic implementation. We demonstrate theeffectiveness of Manual2Skill by successfully assembling several real-worldIKEA furniture items. This application highlights its ability to managelong-horizon manipulation tasks with both efficiency and precision,significantly enhancing the practicality of robot learning from instructionmanuals. This work marks a step forward in advancing robotic systems capable ofunderstanding and executing complex manipulation tasks in a manner akin tohuman capabilities.</description>
      <author>example@mail.com (Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao)</author>
      <guid isPermaLink="false">2502.10090v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Imit Diff: Semantics Guided Diffusion Transformer with Dual Resolution Fusion for Imitation Learning</title>
      <link>http://arxiv.org/abs/2502.09649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了Imit Diff，这是一种用于模仿学习的语义引导扩散变换器，并引入了双分辨率融合来提高复杂场景下的操作技能获取能力。&lt;h4&gt;背景&lt;/h4&gt;视觉运动模仿学习允许实体智能体通过视频演示和机器人本体感觉有效获得操作技巧。然而，在场景复杂度增加且存在视觉干扰的情况下，现有的方法在简单场景中表现良好的性能会下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在复杂场景下性能下降的问题，论文提出了一种新的模仿学习方法——Imit Diff。&lt;h4&gt;方法&lt;/h4&gt;该方法利用了视觉语言基础模型的先验知识，将高层次语义指令翻译成像素级视觉定位信息，并将其显式地集成到一个多尺度增强框架中。此外，还引入了一致性策略来提高实体智能体控制的实际性能和运动流畅度。&lt;h4&gt;主要发现&lt;/h4&gt;在几个具有挑战性的现实任务上评估了Imit Diff，由于其目标导向的视觉定位能力和细粒度场景感知能力，在复杂且存在视觉干扰的场景中，它显著优于现有的最先进方法，特别是在零样本实验（专注于视觉干扰和类别泛化）中的表现。&lt;h4&gt;结论&lt;/h4&gt;论文提出了新的模仿学习方法——Imit Diff，并展示了在处理具有挑战性的操作任务时该方法的有效性。未来的研究将公开提供代码供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor imitation learning enables embodied agents to effectively acquiremanipulation skills from video demonstrations and robot proprioception.However, as scene complexity and visual distractions increase, existing methodsthat perform well in simple scenes tend to degrade in performance. To addressthis challenge, we introduce Imit Diff, a semanstic guided diffusiontransformer with dual resolution fusion for imitation learning. Our approachleverages prior knowledge from vision language foundation models to translatehigh-level semantic instruction into pixel-level visual localization. Thisinformation is explicitly integrated into a multi-scale visual enhancementframework, constructed with a dual resolution encoder. Additionally, weintroduce an implementation of Consistency Policy within the diffusiontransformer architecture to improve both real-time performance and motionsmoothness in embodied agent control.We evaluate Imit Diff on severalchallenging real-world tasks. Due to its task-oriented visual localization andfine-grained scene perception, it significantly outperforms state-of-the-artmethods, especially in complex scenes with visual distractions, includingzero-shot experiments focused on visual distraction and categorygeneralization. The code will be made publicly available.</description>
      <author>example@mail.com (Yuhang Dong, Haizhou Ge, Yupei Zeng, Jiangning Zhang, Beiwen Tian, Guanzhong Tian, Hongrui Zhu, Yufei Jia, Ruixiang Wang, Ran Yi, Guyue Zhou, Longhua Ma)</author>
      <guid isPermaLink="false">2502.09649v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Patient Acceptance of Robotic Ultrasound through Conversational Virtual Agent and Immersive Visualizations</title>
      <link>http://arxiv.org/abs/2502.10088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures, to be published in IEEE Transactions on  Visualization and Computer Graphics (TVCG) and 2025 IEEE conference on  virtual reality and 3D user interfaces (VR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了结合AI驱动的对话虚拟代理和三种混合现实可视化技术的系统，旨在提高患者对机器人超声系统的信任感与舒适度。&lt;h4&gt;背景&lt;/h4&gt;机器人超声波系统在医疗诊断中有潜在的应用价值，但患者的接受程度较低。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个由大型语言模型支持的虚拟对话代理以及多种混合现实视图来增强患者对机器人的信任和使用体验。&lt;h4&gt;方法&lt;/h4&gt;设计了一种结合AI驱动的虚拟助手与三种不同类型的混合现实视觉技术（增强现实、增强虚拟性和全沉浸式虚拟现实）的系统，旨在改善用户交互可靠性和提升用户体验。&lt;h4&gt;主要发现&lt;/h4&gt;通过用户研究证明了该方案能够显著提高患者的信任感和接受度，为自主医疗程序中的混合现实技术和虚拟代理设计提供了宝贵的见解。&lt;h4&gt;结论&lt;/h4&gt;这项创新性方法可以有效促进患者对机器人超声系统的接受，并改善其体验。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic ultrasound systems can enhance medical diagnostics, but patientacceptance is a challenge. We propose a system combining an AI-poweredconversational virtual agent with three mixed reality visualizations to improvetrust and comfort. The virtual agent, powered by a large language model,engages in natural conversations and guides the ultrasound robot, enhancinginteraction reliability. The visualizations include augmented reality,augmented virtuality, and fully immersive virtual reality, each designed tocreate patient-friendly experiences. A user study demonstrated significantimprovements in trust and acceptance, offering valuable insights for designingmixed reality and virtual agents in autonomous medical procedures.</description>
      <author>example@mail.com (Tianyu Song, Felix Pabst, Ulrich Eck, Nassir Navab)</author>
      <guid isPermaLink="false">2502.10088v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Coordinated control of multiple autonomous surface vehicles: challenges and advances - a systematic review</title>
      <link>http://arxiv.org/abs/2502.10080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了自主水面船舶（ASV）协调控制领域的最新进展，并探讨了这一领域的重要缺口。&lt;h4&gt;背景&lt;/h4&gt;随着ASVs在各种海事活动中的使用和实施增加，对它们的控制研究和发展也日益增多。特别是多个ASVs之间的协作带来了新的挑战和机遇，需要来自机器人学、控制理论、通信系统以及海洋科学等领域的跨学科研究努力。&lt;h4&gt;目的&lt;/h4&gt;探讨利用不同控制技术组合来实现各种任务或目标的可能性，并引入机器学习以考虑以往认为难以实施的方面。&lt;h4&gt;方法&lt;/h4&gt;采用系统的文献筛选方法来确保文章选择的一致性和减少偏见，重点讨论了定制化控制策略和集成机器学习技术以提高自主性的次执行ASVs的问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文对最新的协调ASV控制进行了全面探索，并指出了以前综述中未涵盖的关键缺口。同时概述了目前的技术状态并为未来的研究工作提供了指导。&lt;h4&gt;结论&lt;/h4&gt;通过综合最近的进展和识别新兴趋势，文章提出了促进该领域发展的见解，为未来的科研努力提供了一个全面的视角和技术指南。&lt;h4&gt;翻译&lt;/h4&gt;随着自主水面船舶（ASVs）在海事环境中的各种活动中的应用增加，预计这将推动对其控制的研究和发展。特别是多个ASVs之间的协调带来了新的挑战和机遇，需要来自机器人学、控制理论、通信系统以及海洋科学等领域的跨学科研究努力。这些船只可以集体用于多种任务或目标，因此可以结合使用不同的控制技术，包括探索机器学习来考虑以前认为不可行的方面。本文提供了对协同ASV控制的全面探讨，并解决了先前综述中留下的关键缺口。与之前的工作不同的是，我们采取了系统的方法以确保文章选择的一致性和减少偏见。我们将深入探讨次执行ASVs的世界，并重点讨论定制化控制策略以及集成机器学习技术以提高自主性的问题。通过综合最近的进展并识别新兴趋势，本文提供了促进该领域发展的见解，为未来的科研工作提供了一个全面的技术和指导视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.oceaneng.2024.119160&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use and implementation of Autonomous Surface Vessels (ASVs)for various activities in maritime environments is expected to drive a rise indevelopments and research on their control. Particularly, the coordination ofmultiple ASVs presents novel challenges and opportunities, requiringinterdisciplinary research efforts at the intersection of robotics, controltheory, communication systems, and marine sciences. The wide variety ofmissions or objectives for which these vessels can be collectively used allowsfor the application and combination of different control techniques. Thisincludes the exploration of machine learning to consider aspects previouslydeemed infeasible. This review provides a comprehensive exploration ofcoordinated ASV control while addressing critical gaps left by previousreviews. Unlike previous works, we adopt a systematic approach to ensureintegrity and minimize bias in article selection. We delve into the complexworld of sub-actuated ASVs with a focus on customized control strategies andthe integration of machine learning techniques for increased autonomy. Bysynthesizing recent advances and identifying emerging trends, we offer insightsthat drive this field forward, providing both a comprehensive overview ofstate-of-the-art techniques and guidance for future research efforts.</description>
      <author>example@mail.com (Manuel Gantiva Osorioa, Carmelina Ierardia, Isabel Jurado Floresa, Mario Pereira Martína, Pablo Millán Gata)</author>
      <guid isPermaLink="false">2502.10080v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints</title>
      <link>http://arxiv.org/abs/2502.10062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a full paper at AAMAS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了在未知机器人转换模型的情况下多机器人协作的问题，确保由时间窗口时态逻辑指定的任务能够在用户定义的概率阈值下得到满足。&lt;h4&gt;背景&lt;/h4&gt;当前的多机器人系统面临着如何在不完全了解机器人动态变化（即转换模型）的情况下进行有效任务分配和执行的问题。现有的方法通常依赖于详细的机器人模型来进行优化，这限制了它们的应用范围。&lt;h4&gt;目的&lt;/h4&gt;提出一种分层框架来解决上述问题，使机器人能够在不确定环境下有效地协作完成指定任务，并且达到用户定义的成功概率阈值。&lt;h4&gt;方法&lt;/h4&gt;1. 高层次的任务分配：基于对每个机器人的估计任务完成概率和预期奖励来进行任务分配。2. 低层次的分布式策略学习与执行：允许机器人独立优化辅助奖励，同时满足其分配到的任务要求。3. 利用实时任务执行数据来迭代细化任务完成的概率以及预期奖励，无需显式的机器人转换模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过理论验证和广泛的模拟实验，证明了所提出的算法能够有效地在不确定环境中进行多机器人协调，并且可以达到用户定义的成功概率阈值。&lt;h4&gt;结论&lt;/h4&gt;提出了一种基于实时数据的自适应任务分配方法，使得多机器人系统能够在没有精确模型的情况下高效工作。这种方法提高了系统的鲁棒性和灵活性，为未来的智能协作提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;此研究处理了在未知机器人转换模式下进行多机器人协调的问题，确保根据时间窗口时态逻辑指定的任务能够达到用户定义的概率阈值要求。通过介绍一种结合高层次任务分配和低层次分布式策略学习与执行的分层框架来解决这个问题，并且展示了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the problem of multi-robot coordination under unknownrobot transition models, ensuring that tasks specified by Time Window TemporalLogic are satisfied with user-defined probability thresholds. We present abi-level framework that integrates (i) high-level task allocation, where tasksare assigned based on the robots' estimated task completion probabilities andexpected rewards, and (ii) low-level distributed policy learning and execution,where robots independently optimize auxiliary rewards while fulfilling theirassigned tasks. To handle uncertainty in robot dynamics, our approach leveragesreal-time task execution data to iteratively refine expected task completionprobabilities and rewards, enabling adaptive task allocation without explicitrobot transition models. We theoretically validate the proposed algorithm,demonstrating that the task assignments meet the desired probability thresholdswith high confidence. Finally, we demonstrate the effectiveness of ourframework through comprehensive simulations.</description>
      <author>example@mail.com (Xiaoshan Lin, Roberto Tron)</author>
      <guid isPermaLink="false">2502.10062v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>A Generalized Modeling Approach to Liquid-driven Ballooning Membranes</title>
      <link>http://arxiv.org/abs/2502.10057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;软机器人技术正在利用柔性材料推进适应性强的机器人系统的开发。膜驱动的软机器人通过使用加压、可延展的薄膜来克服传统软机器人的局限，实现稳定的大变形，但复杂的形变动态使得控制和状态估计仍然具有挑战性。&lt;h4&gt;背景&lt;/h4&gt;传统的软机器人在形状改变和动力学方面存在限制，特别是在需要精确控制的应用中。膜驱动软机器人使用加压、可伸展的薄膜来克服这些限制，实现了较大的变形范围。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新颖的建模方法，用于液驱膨胀膜，该模型采用椭球近似法来描述在平面形变下的形状和拉伸情况。目的是利用这种方法实现精确的膜状态估计。&lt;h4&gt;方法&lt;/h4&gt;使用液体驱动膨胀膜的实验验证了所提出的模型的有效性，并通过压力数据和控制液体体积来进行内部反馈，从而实现了对膜状态的准确估算。&lt;h4&gt;主要发现&lt;/h4&gt;在基于膨胀膜执行器的实验中获得了0.80毫米的压入深度误差（$RMSE_{h_2}$），这个值占总压入范围的23%，以及未被压入时执行器高度范围的6.67%。对于力估计，误差范围为0.15牛顿（$RMSE_{F}$），该数值是测得力范围的10%。&lt;h4&gt;结论&lt;/h4&gt;所提出的液驱膨胀膜建模方法能够准确地进行膜状态和力的估算，展示了其在软机器人领域中的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robotics is advancing the use of flexible materials for adaptablerobotic systems. Membrane-actuated soft robots address the limitations oftraditional soft robots by using pressurized, extensible membranes to achievestable, large deformations, yet control and state estimation remain challengingdue to their complex deformation dynamics. This paper presents a novel modelingapproach for liquid-driven ballooning membranes, employing an ellipsoidapproximation to model shape and stretch under planar deformation. Relyingsolely on intrinsic feedback from pressure data and controlled liquid volume,this approach enables accurate membrane state estimation. We demonstrate theeffectiveness of the proposed model for ballooning membrane-based actuators byexperimental validation, obtaining the indentation depth error of$RMSE_{h_2}=0.80\;$mm, which is $23\%$ of the indentation range and $6.67\%$ ofthe unindented actuator height range. For the force estimation, the error rangeis obtained to be $RMSE_{F}=0.15\;$N which is $10\%$ of the measured forcerange.</description>
      <author>example@mail.com (Mirroyal Ismayilov, Jeref Merlin, Christos Bergeles, Lukas Lindenroth)</author>
      <guid isPermaLink="false">2502.10057v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Trajectory-guided Policy for Long-horizon Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.10040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近，Vision-Language-Action（VLA）模型在机器人模仿学习中取得了进展，但高昂的数据收集成本和有限的演示数据限制了泛化能力，并且现有的模仿学习方法在外分布场景下表现不佳，尤其是对于长时间任务。&lt;h4&gt;背景&lt;/h4&gt;当前的机器人模仿学习面临高数据采集成本、有限演示数据及外分布场景下的挑战。尤其是在处理长时间任务时，模仿学习中累积误差导致的问题尤为突出。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架（Diffusion Trajectory-guided Policy, DTP）来减少长时序任务中的累积错误，并提高机器人在现实世界中的性能。&lt;h4&gt;方法&lt;/h4&gt;该研究采用两阶段方法：首先训练一个生成式视觉语言模型，通过扩散模型产生2D轨迹；然后利用这些轨迹指导政策学习，以改善模仿策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在CALVIN基准测试中，DTP框架在成功率方面比现有最佳基线高出25%，且无需外部预训练。此外，DTP显著提高了实际机器人系统的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的Diffusion Trajectory-guided Policy（DTP）方法为解决长时间任务的机器人模仿学习中的误差累积问题提供了一种有效途径，并展示了在现实世界应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近，Vision-Language-Action模型已推动了机器人模仿学习的发展，但高昂的数据采集成本和有限演示限制了泛化能力。当前的方法在外分布场景下尤其难以处理长时间任务。为解决这些问题，本文提出了Diffusion Trajectory-guided Policy（DTP）框架，该框架通过生成2D轨迹来指导长时序任务中的策略学习，减少了错误累积。实验结果表明，在CALVIN基准测试中，DTP比现有最佳方法高出25%的成功率，并且显著改善了真实机器人系统的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Vision-Language-Action models (VLA) have advanced robot imitationlearning, but high data collection costs and limited demonstrations hindergeneralization and current imitation learning methods struggle inout-of-distribution scenarios, especially for long-horizon tasks. A keychallenge is how to mitigate compounding errors in imitation learning, whichlead to cascading failures over extended trajectories. To address thesechallenges, we propose the Diffusion Trajectory-guided Policy (DTP) framework,which generates 2D trajectories through a diffusion model to guide policylearning for long-horizon tasks. By leveraging task-relevant trajectories, DTPprovides trajectory-level guidance to reduce error accumulation. Our two-stageapproach first trains a generative vision-language model to creatediffusion-based trajectories, then refines the imitation policy using them.Experiments on the CALVIN benchmark show that DTP outperforms state-of-the-artbaselines by 25% in success rate, starting from scratch without externalpretraining. Moreover, DTP significantly improves real-world robot performance.</description>
      <author>example@mail.com (Shichao Fan, Quantao Yang, Yajie Liu, Kun Wu, Zhengping Che, Qingjie Liu, Min Wan)</author>
      <guid isPermaLink="false">2502.10040v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.10028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ManiTrend的统一框架，该框架利用3D流作为语言驱动未来图像生成和精细化动作预测之间的桥梁。通过因果Transformer模型对三维粒子动态、视觉观察和操作行为进行建模。&lt;h4&gt;背景&lt;/h4&gt;基于自然语言的目标表示是解决语言条件操纵任务的关键挑战之一，而三维流动则被认为是一个有效的连接点。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用3D流信息的统一框架ManiTrend，以改善基于语言的动作预测任务的表现。&lt;h4&gt;方法&lt;/h4&gt;开发了名为ManiTrend的新模型，该模型采用因果Transformer架构，并将三维流动作为未来图像生成和动作预测中的额外条件。&lt;h4&gt;主要发现&lt;/h4&gt;1. 三维流动可以替代缺失或异质性操作标签，在大规模预训练中使用跨身体演示。2. 实验显示本文方法在两个全面基准上的性能优于现有技术，且效率更高。&lt;h4&gt;结论&lt;/h4&gt;ManiTrend框架通过引入3D流作为中间表示，提高了语言驱动的未来图像生成和精细化动作预测任务中的表现。&lt;h4&gt;翻译&lt;/h4&gt;语言条件操纵是一项重要但具挑战性的机器人任务，因为自然语言的高度抽象性。为了解决这个问题，研究人员正在寻求改进源自自然语言的目标表示。本文中，我们强调了3D流动——代表场景内三维粒子的运动趋势——作为基于语言未来图像生成与精细动作预测之间的有效桥梁。为此，我们开发了一种称为ManiTrend的统一框架，该框架利用因果Transformer对三维粒子动态、视觉观察和操作行为进行建模。在此框架中，用于3D流动预测的功能作为未来图像生成和动作预测中的额外条件，减轻了像素级时空模型化复杂性，并提供无缝的动作指导。此外，在大规模预训练过程中，3D流动可以替代缺失或异质性的动作标签，使用跨身体演示。在两个全面基准上的实验表明，我们的方法实现了最先进的性能，具有高效率。我们的代码和模型检查点将在接受后可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language-conditioned manipulation is a vital but challenging robotic task dueto the high-level abstraction of language. To address this, researchers havesought improved goal representations derived from natural language. In thispaper, we highlight 3D flow - representing the motion trend of 3D particleswithin a scene - as an effective bridge between language-based future imagegeneration and fine-grained action prediction. To this end, we developManiTrend, a unified framework that models the dynamics of 3D particles, visionobservations and manipulation actions with a causal transformer. Within thisframework, features for 3D flow prediction serve as additional conditions forfuture image generation and action prediction, alleviating the complexity ofpixel-wise spatiotemporal modeling and providing seamless action guidance.Furthermore, 3D flow can substitute missing or heterogeneous action labelsduring large-scale pretraining on cross-embodiment demonstrations. Experimentson two comprehensive benchmarks demonstrate that our method achievesstate-of-the-art performance with high efficiency. Our code and modelcheckpoints will be available upon acceptance.</description>
      <author>example@mail.com (Yuxin He, Qiang Nie)</author>
      <guid isPermaLink="false">2502.10028v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Dream to Drive: Model-Based Vehicle Control Using Analytic World Models</title>
      <link>http://arxiv.org/abs/2502.10012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了可微模拟器在训练自动驾驶车辆控制器方面的应用，并首次尝试使用它们来训练世界模型。&lt;h4&gt;背景&lt;/h4&gt;可微模拟器允许通过它们进行反向传播，从而将已知的动力学作为策略学习的先验知识。然而，这些系统仅被用于训练政策。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法——Analytic World Models (AWMs)，利用可微模拟器来训练世界模型，并展示了其在规划任务中的应用。&lt;h4&gt;方法&lt;/h4&gt;提出了三种新任务设置，允许学习下一个状态预测器、最优规划者和最优逆向状态。与传统的分析策略梯度（APG）相比，该方法依赖于当前状态到下一个状态的梯度。&lt;h4&gt;主要发现&lt;/h4&gt;AWM 方法在 Waymo Open Motion 数据集上的性能比基线提高了多达12%，同时几乎不增加额外成本。&lt;h4&gt;结论&lt;/h4&gt;通过使用可微模拟器训练世界模型，可以极大地提升自动驾驶车辆控制器的性能和效率。&lt;h4&gt;翻译&lt;/h4&gt;最近，可微分仿真器被证明对训练自主车辆控制器有很大潜力。由于它们支持反向传播，因此可以在端到端训练循环中使用，从而将已知的动力学转化为策略学习的有效先验知识，消除了环境的黑盒假设。迄今为止，这些系统仅用于培训政策。然而，在提供可能性方面，这还远未结束。在这里，我们首次利用它们来训练世界模型。具体而言，我们介绍了三种新的任务设置，使我们能够学习下一个状态预测器、最优规划者和最佳逆状态。与需要当前行动对下一仿真状态的梯度的传统分析策略梯度（APG）不同，我们提出的设置依赖于当前状态到下一状态的梯度。我们称这种方法为解析世界模型（AWM），并展示了它的应用，包括如何在Waymax模拟器中使用它进行规划。除了推动此类模拟器的可能性之外，还提供了一种改进的训练方法，在大规模Waymo开放运动数据集上的性能提高了高达12％，与基线相比几乎不增加额外成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentiable simulators have recently shown great promise for trainingautonomous vehicle controllers. Being able to backpropagate through them, theycan be placed into an end-to-end training loop where their known dynamics turninto useful priors for the policy to learn, removing the typical black boxassumption of the environment. So far, these systems have only been used totrain policies. However, this is not the end of the story in terms of what theycan offer. Here, for the first time, we use them to train world models.Specifically, we present three new task setups that allow us to learn nextstate predictors, optimal planners, and optimal inverse states. Unlike analyticpolicy gradients (APG), which requires the gradient of the next simulator statewith respect to the current actions, our proposed setups rely on the gradientof the next state with respect to the current state. We call this approachAnalytic World Models (AWMs) and showcase its applications, including how touse it for planning in the Waymax simulator. Apart from pushing the limits ofwhat is possible with such simulators, we offer an improved training recipethat increases performance on the large-scale Waymo Open Motion dataset by upto 12% compared to baselines at essentially no additional cost.</description>
      <author>example@mail.com (Asen Nachkov, Danda Pani Paudel, Jan-Nico Zaech, Davide Scaramuzza, Luc Van Gool)</author>
      <guid isPermaLink="false">2502.10012v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models</title>
      <link>http://arxiv.org/abs/2502.09980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的问题设置，将大型语言模型（LLM）集成到基于车辆间通信的自动驾驶系统中，并引入了Vehicle-to-Vehicle Question-Answering (V2V-QA)数据集和基准。&lt;h4&gt;背景&lt;/h4&gt;现有的自主驾驶汽车主要依赖自身传感器来感知周围环境并规划未来路径，在传感器故障或遮挡时可靠性较低。通过车辆间通信进行协作感知的方法已被提出，但这些方法多集中在检测和跟踪上，而它们对整体合作规划性能的贡献尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;基于最近利用大型语言模型构建自主驾驶系统的进展，论文旨在研究如何将LLM用于自动驾驶汽车中的信息融合，并探讨其在解决不同任务方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了Vehicle-to-Vehicle Large Language Model (V2V-LLM)基线方法，该方法使用LLM来融合多个连接的自主车辆（CAVs）提供的感知信息并回答与驾驶相关的提问：定位、识别显著对象及规划路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的V2V-LLM模型在执行各种协作自动驾驶任务时表现良好，并优于其他采用不同融合方法的基线模型。&lt;h4&gt;结论&lt;/h4&gt;本文工作开创了一种新的研究方向，可以提高未来自主驾驶系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;当前自主车辆主要依赖自身传感器理解周围环境并规划路径，在传感器故障或遮挡时可能会不可靠。为解决此问题，通过车对车（V2V）通信进行协作感知的方法已被提出，但这些方法大多集中在检测和跟踪上。目前对于如何利用上述方法提升整体合作规划性能还存在不足研究。受最近使用大型语言模型构建自主驾驶系统进展的启发，我们提出了一个将LLM融入到合作自动驾驶中的新颖问题设置，并引入了Vehicle-to-Vehicle Question-Answering (V2V-QA)数据集和基准。同时提出我们的基线方法Vehicle-to-Vehicle Large Language Model (V2V-LLM)，它使用LLM融合多个连接的自主车辆提供的感知信息并回答与驾驶相关的提问：定位、识别显著对象及规划路径。实验结果表明，我们提出的V2V-LLM可以作为执行各种合作自动驾驶任务的有前景的统一模型架构，并优于其他采用不同融合方法的基线模型。我们的工作开创了一种新的研究方向，以提高未来自主驾驶系统的安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current autonomous driving vehicles rely mainly on their individual sensorsto understand surrounding scenes and plan for future trajectories, which can beunreliable when the sensors are malfunctioning or occluded. To address thisproblem, cooperative perception methods via vehicle-to-vehicle (V2V)communication have been proposed, but they have tended to focus on detectionand tracking. How those approaches contribute to overall cooperative planningperformance is still under-explored. Inspired by recent progress using LargeLanguage Models (LLMs) to build autonomous driving systems, we propose a novelproblem setting that integrates an LLM into cooperative autonomous driving,with the proposed Vehicle-to-Vehicle Question-Answering (V2V-QA) dataset andbenchmark. We also propose our baseline method Vehicle-to-Vehicle LargeLanguage Model (V2V-LLM), which uses an LLM to fuse perception information frommultiple connected autonomous vehicles (CAVs) and answer driving-relatedquestions: grounding, notable object identification, and planning. Experimentalresults show that our proposed V2V-LLM can be a promising unified modelarchitecture for performing various tasks in cooperative autonomous driving,and outperforms other baseline methods that use different fusion approaches.Our work also creates a new research direction that can improve the safety offuture autonomous driving systems. Our project website:https://eddyhkchiu.github.io/v2vllm.github.io/ .</description>
      <author>example@mail.com (Hsu-kuang Chiu, Ryo Hachiuma, Chien-Yi Wang, Stephen F. Smith, Yu-Chiang Frank Wang, Min-Hung Chen)</author>
      <guid isPermaLink="false">2502.09980v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Global-Local Interface for On-Demand Teleoperation</title>
      <link>http://arxiv.org/abs/2502.09960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章介绍了全球-局部（G-L）遥控界面，这是一种用于机器人遥控行为的新型接口，它能够同时处理全局运动和精确操作。&lt;h4&gt;背景&lt;/h4&gt;当前存在的遥控方法在灵活性、工作范围和精度方面有各自的优缺点。为了融合这些优势，作者提出了一种新的解决方案。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入G-L界面来提供一种既能保证机器人动作范围和直观性，又能提升人类操作者执行精细任务的能力的方法。&lt;h4&gt;方法&lt;/h4&gt;基于G-L界面构建了单臂和双臂遥控系统，并使用不同的远程控制设备进行了演示。这些实验涉及需要大运动范围、精确操纵或灵巧末端执行器控制的任务。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明，所提出的界面具有用户友好性、准确性以及广泛适用性。&lt;h4&gt;结论&lt;/h4&gt;G-L遥操作接口提供了一种有效的方法来增强机器人在各种任务中的表现，包括传统的拾取放置任务和复杂的精细操作。&lt;h4&gt;翻译&lt;/h4&gt;远程操作是人机交互的关键方法，在工业和非结构化环境中具有重要的应用潜力。现有远程操作方法在灵活性、工作范围和精度方面各有优缺点。为了融合这些优点，我们引入了全球-局部（G-L）远程操作界面。该接口将机器人的遥控分解为全局行为，确保机器人运动范围的直观性，并增强人类操作者进行精细任务的能力。基于G-L界面构建了一个单臂和双臂遥操作系统并使用不同的远程控制设备进行了演示，这些实验涉及需要大动作范围、精确操纵或灵巧末端执行器控制的任务。广泛的实验证明了所提出接口的用户友好性、准确性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Teleoperation is a critical method for human-robot interface, holdssignificant potential for enabling robotic applications in industrial andunstructured environments. Existing teleoperation methods have distinctstrengths and limitations in flexibility, range of workspace and precision. Tofuse these advantages, we introduce the Global-Local (G-L) TeleoperationInterface. This interface decouples robotic teleoperation into global behavior,which ensures the robot motion range and intuitiveness, and local behavior,which enhances human operator's dexterity and capability for performing finetasks. The G-L interface enables efficient teleoperation not only forconventional tasks like pick-and-place, but also for challenging finemanipulation and large-scale movements. Based on the G-L interface, weconstructed a single-arm and a dual-arm teleoperation system with differentremote control devices, then demonstrated tasks requiring large motion range,precise manipulation or dexterous end-effector control. Extensive experimentsvalidated the user-friendliness, accuracy, and generalizability of the proposedinterface.</description>
      <author>example@mail.com (Jianshu Zhou, Boyuan Liang, Junda Huang, Ian Zhang, Pieter Abbeel, Masayoshi Tomizuka)</author>
      <guid isPermaLink="false">2502.09960v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Self-Consistent Model-based Adaptation for Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.09923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的自我一致模型自适应（SCMA）方法，该方法通过将嘈杂的观察结果转换为干净的观察结果来提高视觉强化学习代理在实际应用中的性能，而无需修改策略。&lt;h4&gt;背景&lt;/h4&gt;现有的方法依赖于使用手工制作的数据增强技术对策略表示进行微调，以应对现实世界中由视觉干扰引起的性能下降问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种不修改现有策略的自适应方法，能够通过插件方式提高在各种复杂环境下的表现。&lt;h4&gt;方法&lt;/h4&gt;利用去噪模型将杂乱无章的观测值转换为清晰的观测值；推导出了一种无监督分布匹配目标以优化该去噪模型，并提出一种算法来估计干净观察数据的概率分布，使用预训练的世界模型进行。&lt;h4&gt;主要发现&lt;/h4&gt;SCMA能够有效缓解各种策略在面对不同干扰时的表现下降问题，并且具有更好的样本效率。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，无论是在多个视觉泛化基准测试还是真实的机器人数据上，SCMA都能显著提升性能表现。&lt;h4&gt;翻译&lt;/h4&gt;视觉强化学习代理通常会在实际应用中由于视觉干扰而导致严重的性能下降。现有的方法依赖于利用手工制作的数据增强技术来微调策略表示。在这项工作中，我们提出了自我一致模型自适应（Self-Consistent Model-based Adaptation, SCMA），这是一种新的无需修改现有策略即可实现稳健自适应的方法。通过使用去噪模型将嘈杂的观测值转换为干净的观测值，SCMA能够缓解各种干扰对不同策略的影响，并作为一个插件增强功能来应用。为了在无监督的情况下优化该去噪模型，我们推导出了一种分布匹配的目标函数，并对其最优性进行了理论分析。进一步地，我们提出一种实用算法以估计清洁观察数据的分布并以此为目标进行优化，使用的是预先训练好的世界模型。广泛的实验表明，在多种视觉泛化基准测试和实际机器人数据上，SCMA都能显著提高性能表现，并且具有更好的样本效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual reinforcement learning agents typically face serious performancedeclines in real-world applications caused by visual distractions. Existingmethods rely on fine-tuning the policy's representations with hand-craftedaugmentations. In this work, we propose Self-Consistent Model-based Adaptation(SCMA), a novel method that fosters robust adaptation without modifying thepolicy. By transferring cluttered observations to clean ones with a denoisingmodel, SCMA can mitigate distractions for various policies as a plug-and-playenhancement. To optimize the denoising model in an unsupervised manner, wederive an unsupervised distribution matching objective with a theoreticalanalysis of its optimality. We further present a practical algorithm tooptimize the objective by estimating the distribution of clean observationswith a pre-trained world model. Extensive experiments on multiple visualgeneralization benchmarks and real robot data demonstrate that SCMA effectivelyboosts performance across various distractions and exhibits better sampleefficiency.</description>
      <author>example@mail.com (Xinning Zhou, Chengyang Ying, Yao Feng, Hang Su, Jun Zhu)</author>
      <guid isPermaLink="false">2502.09923v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Dual Control for Interactive Autonomous Merging with Model Predictive Diffusion</title>
      <link>http://arxiv.org/abs/2502.09918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶等应用中，交互式决策至关重要。传统的预测-行动框架往往不够充分或低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种主动学习框架及在线滚动地平线控制问题的基于模型的扩散求解器。&lt;h4&gt;方法&lt;/h4&gt;提出了一个严格的预测信念分布推导和一个为在线滚动地平线控制问题设计的新建模扩散解决者。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在实际硬件实验中验证了行为推理，并展示了改进的不确定性下的自适应规划能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作推进了交互式决策领域的进展，特别是在现实世界的应用中的不确定性和适应性规划方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种针对自动驾驶等场景开发的新方法和框架，通过引入基于模型的扩散求解器及主动学习框架来改进不确定性条件下的自适应规划能力。研究包括理论推导、仿真验证以及实际硬件实验展示，表明了该技术的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interactive decision-making is essential in applications such as autonomousdriving, where the agent must infer the behavior of nearby human drivers whileplanning in real-time. Traditional predict-then-act frameworks are ofteninsufficient or inefficient because accurate inference of human behaviorrequires a continuous interaction rather than isolated prediction. To addressthis, we propose an active learning framework in which we rigorously derivepredicted belief distributions. Additionally, we introduce a novel model-baseddiffusion solver tailored for online receding horizon control problems,demonstrated through a complex, non-convex highway merging scenario. Ourapproach extends previous high-fidelity dual control simulations to hardwareexperiments, which may be viewed at https://youtu.be/Q_JdZuopGL4, and verifiesbehavior inference in human-driven traffic scenarios, moving beyond idealizedmodels. The results show improvements in adaptive planning under uncertainty,advancing the field of interactive decision-making for real-world applications.</description>
      <author>example@mail.com (Jacob Knaup, Jovin D'sa, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Ehsan Moradi-Pari, Panagiotis Tsiotras)</author>
      <guid isPermaLink="false">2502.09918v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos</title>
      <link>http://arxiv.org/abs/2502.09886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Video2Policy是一个基于互联网上RGB视频的框架，通过模仿日常人类行为来生成模拟任务，并利用大型语言模型生成奖励函数进行强化学习。&lt;h4&gt;背景&lt;/h4&gt;现有的方法要么依赖于可能产生不适用于机器人领域的大型语言模型，要么使用难以扩展且需要真实世界与模拟精确对齐的数字双胞胎。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架Video2Policy，以解决现有数据生成问题，并成功训练复杂的机器人任务策略。&lt;h4&gt;方法&lt;/h4&gt;该方法包含两个阶段：（1）从视频中在模拟环境中生成任务；（2）利用大型语言模型迭代地产生奖励函数进行强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;使用SSv2数据集中的100多个视频，成功训练了9个不同复杂度的机器人任务策略，包括投掷等挑战性任务。&lt;h4&gt;结论&lt;/h4&gt;Video2Policy框架不仅可以生成大规模模拟数据来培训通用策略，还可以通过Real2Sim2Real的方式将其应用于实际机器人上。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了一种新的基于互联网视频的数据生成方法，旨在通过模仿人类行为训练复杂和多样化的机器学习任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation offers a promising approach for cheaply scaling training data forgeneralist policies. To scalably generate data from diverse and realistictasks, existing algorithms either rely on large language models (LLMs) that mayhallucinate tasks not interesting for robotics; or digital twins, which requirecareful real-to-sim alignment and are hard to scale. To address thesechallenges, we introduce Video2Policy, a novel framework that leveragesinternet RGB videos to reconstruct tasks based on everyday human behavior. Ourapproach comprises two phases: (1) task generation in simulation from videos;and (2) reinforcement learning utilizing in-context LLM-generated rewardfunctions iteratively. We demonstrate the efficacy of Video2Policy byreconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,which depicts diverse and complex human behaviors on 9 different tasks. Ourmethod can successfully train RL policies on such tasks, including complex andchallenging tasks such as throwing. Finally, we show that the generatedsimulation data can be scaled up for training a general policy, and it can betransferred back to the real robot in a Real2Sim2Real way.</description>
      <author>example@mail.com (Weirui Ye, Fangchen Liu, Zheng Ding, Yang Gao, Oleh Rybkin, Pieter Abbeel)</author>
      <guid isPermaLink="false">2502.09886v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Determining angle of arrival of radio frequency fields using subwavelength, amplitude-only measurements of standing waves in a Rydberg atom sensor</title>
      <link>http://arxiv.org/abs/2502.09835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深亚波长射频成像技术使用原子里德堡传感器克服了传统天线的基本限制，并实现了超宽带全向时间变化场检测，且结构紧凑。&lt;h4&gt;目的&lt;/h4&gt;展示一种新型的里德堡传感器用于角度到达（AoA）测量，该方法利用亚波长驻波场成像，无需额外的强射频相位参考场即可确定入射角。&lt;h4&gt;方法&lt;/h4&gt;通过在里德堡单元内放置一块金属板来实现独立于传入RF场强度的角度定位，并进行精密角度到达（AoA）测量。使用机器人天线定位系统对4.2GHz、5.0GHz和5.7GHz信号进行了测量。&lt;h4&gt;主要发现&lt;/h4&gt;实现了1.7度的极角分辨率从0到60度AoA，以及在整个可能的角度范围内4.1度的分辨率。&lt;h4&gt;结论&lt;/h4&gt;这种方法为高精度角度到达（AoA）测量提供了一种新的途径，且在无需额外RF相位参考场的情况下具有鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;深亚波长射频成像技术通过原子里德堡传感器克服了传统天线的基本限制，并实现了超宽带全向时间变化场检测，结构紧凑。在此基础上，我们展示了一种用于角度到达（AoA）测量的新型里德堡传感器，该方法利用亚波长驻波场成像，并且无需额外的强射频相位参考场即可确定入射角。通过在里德堡单元内放置一块金属板来实现独立于传入RF场强度的角度定位，并进行精密角度到达（AoA）测量，使用机器人天线定位系统对4.2GHz、5.0GHz和5.7GHz信号进行了测试。实现了1.7度的极角分辨率从0到60度AoA，以及在整个可能的角度范围内4.1度的分辨率。这种方法为高精度角度到达（AoA）测量提供了一种新的途径，且在无需额外RF相位参考场的情况下具有鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep subwavelength RF imaging with atomic Rydberg sensors has overcomefundamental limitations of traditional antennas and enabled ultra-widebanddetection of omni-directional time varying fields all in a compact form factor.However, in most applications, Rydberg sensors require the use of a secondarystrong RF reference field to serve as a phase reference. Here, we demonstrate anew type of Rydberg sensor for angle-of-arrival (AoA) sensing which utilizessubwavelength imaging of standing wave fields. By placing a metallic platewithin the Rydberg cell, we can determine the AoA independent of the strengthof incoming RF field and without requiring a secondary strong RF phasereference field. We perform precision AoA measurements with a robotic antennapositioning system for 4.2, 5.0, and 5.7 GHz signals and demonstrate a 1.7 degpolar angular resolution from 0 deg to 60 deg AoA and 4.1 deg over all possibleangles.</description>
      <author>example@mail.com (Rajavardhan Talashila, William J. Watterson, Benjamin L. Moser, Joshua A. Gordon, Alexandra B. Artusio-Glimpse, Nikunjkumar Prajapati, Noah Schlossberger, Matthew T. Simons, Christopher L. Holloway)</author>
      <guid isPermaLink="false">2502.09835v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection</title>
      <link>http://arxiv.org/abs/2502.09829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估机器人控制策略性能的新框架，通过建模所有任务和策略上的机器人表现分布来减少实验成本，并使用自然语言作为先验知识提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;评估机器人的控制政策需要花费大量的人力物力资源。随着任务数量的增加以及新的控制政策的不断产生，传统方法变得越来越难以执行。&lt;h4&gt;目的&lt;/h4&gt;通过将机器人评估问题看作主动测试问题来减少实验者的工作量，并提供准确可靠的评价结果。&lt;h4&gt;方法&lt;/h4&gt;利用连续执行试验的方式建模机器人性能在所有任务和策略上的分布。提出了一种基于成本意识的期望信息增益启发式算法，以选择最具有信息价值的试验。&lt;h4&gt;主要发现&lt;/h4&gt;该框架可以有效地减少评估多个任务上机器人控制政策的成本，并且能够处理连续或离散性的表现结果。&lt;h4&gt;结论&lt;/h4&gt;通过优先考虑有信息量的试验来优化机器人性能评价的过程，从而节省了计算成本。实验表明这种方法在真实机器人的数据和模拟环境中都具有较高的有效性。&lt;h4&gt;翻译&lt;/h4&gt;评估已学习到的机器人控制策略以确定其物理任务级别能力的成本很高，因为这需要花费大量的人力物力资源。随着政策数量和任务数量的增长，这个问题变得越来越严重。盲目选择随机的任务子集进行测试是一种高成本且结果不可靠的方法。在此研究中，我们提出将机器人评估作为主动测试问题来解决这一挑战。我们将所有任务和策略上的机器人表现分布建模为一系列试验执行的结果，并利用自然语言中的先验知识揭示任务间的潜在关系以提高模型效率。通过使用基于成本意识的期望信息增益启发式算法选择最具有信息价值的试验，我们能够显著降低实验者的工作量。在真实机器人的数据和模拟环境中进行的实验证明了该框架的有效性，并且其可以适用于连续或离散性的表现结果评价任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Evaluating learned robot control policies to determine their physicaltask-level capabilities costs experimenter time and effort. The growing numberof policies and tasks exacerbates this issue. It is impractical to test everypolicy on every task multiple times; each trial requires a manual environmentreset, and each task change involves re-arranging objects or even changingrobots. Naively selecting a random subset of tasks and policies to evaluate isa high-cost solution with unreliable, incomplete results. In this work, weformulate robot evaluation as an active testing problem. We propose to modelthe distribution of robot performance across all tasks and policies as wesequentially execute experiments. Tasks often share similarities that canreveal potential relationships in policy behavior, and we show that naturallanguage is a useful prior in modeling these relationships between tasks. Wethen leverage this formulation to reduce the experimenter effort by using acost-aware expected information gain heuristic to efficiently selectinformative trials. Our framework accommodates both continuous and discreteperformance outcomes. We conduct experiments on existing evaluation data fromreal robots and simulations. By prioritizing informative trials, our frameworkreduces the cost of calculating evaluation metrics for robot policies acrossmany tasks.</description>
      <author>example@mail.com (Abrar Anwar, Rohan Gupta, Zain Merchant, Sayan Ghosh, Willie Neiswanger, Jesse Thomason)</author>
      <guid isPermaLink="false">2502.09829v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>PUGS: Perceptual Uncertainty for Grasp Selection in Underwater Environments</title>
      <link>http://arxiv.org/abs/2502.09824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures Accepted to International Conference on Robotics  and Automation (ICRA) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的方法来量化和表示三维重建中的感知不确定性，并将其应用于水下环境下的自主抓取选择。&lt;h4&gt;背景&lt;/h4&gt;在感官信息不完善且不完整的环境中，机器人必须做出考虑这些缺点的决策。&lt;h4&gt;目的&lt;/h4&gt;开发一种框架将这种感知不确定性纳入到水下环境中自动抓取的选择中。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通过占用不确定估计来量化和表示三维重建中的感知不确定性的方法，并将其传播到了多视图重建过程中的抓取选择过程中，而不是在决定从何处抓取时平等对待每个测量值。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，考虑不确定性后，抓取选择对于部分信息和噪声更加鲁棒。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以提高机器人在复杂环境下的感知精度和操作性能。&lt;h4&gt;翻译&lt;/h4&gt;当处理感官信息不完善且不完整的挑战性环境时，机器人必须做出决策以应对这些缺点。本文提出了一种新的方法来量化并表示这种三维重建中的感知不确定性，并开发了一个框架将其应用于水下环境中自动抓取选择。我们的研究不仅在模拟数据上，在真实世界的数据中也得到了验证：通过考虑不确定性的因素，使得抓取的选择面对部分信息和噪声时更加稳健有效。相关代码将在https://onurbagoren.github.io/PUGS/提供访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When navigating and interacting in challenging environments where sensoryinformation is imperfect and incomplete, robots must make decisions thataccount for these shortcomings. We propose a novel method for quantifying andrepresenting such perceptual uncertainty in 3D reconstruction through occupancyuncertainty estimation. We develop a framework to incorporate it into graspselection for autonomous manipulation in underwater environments. Instead oftreating each measurement equally when deciding which location to grasp from,we present a framework that propagates uncertainty inherent in the multi-viewreconstruction process into the grasp selection. We evaluate our method withboth simulated and the real world data, showing that by accounting foruncertainty, the grasp selection becomes robust against partial and noisymeasurements. Code will be made available athttps://onurbagoren.github.io/PUGS/</description>
      <author>example@mail.com (Onur Bagoren, Marc Micatka, Katherine A. Skinner, Aaron Marburg)</author>
      <guid isPermaLink="false">2502.09824v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Suture Thread Modeling Using Control Barrier Functions for Autonomous Surgery</title>
      <link>http://arxiv.org/abs/2502.09813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for 2025 IEEE International Conference on Robotics and  Automation (ICRA). Supplementary video:  https://www.youtube.com/watch?v=qO-nroi4Faw&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种使用控制屏障函数（CBFs）的新方法，用于模拟缝合线的动态特性，实现了现实性和计算效率的结合。&lt;h4&gt;背景&lt;/h4&gt;自动化的外科系统能提高手术精度和安全性，减少高风险环境中的人员参与。然而，在像缝合这样的自动化手术程序中准确建模缝合线是一个挑战，因为现有的模型要么缺乏安全关键过程所需的准确性，要么过于复杂而无法实时执行。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来模拟缝合线的动态特性，这种方法既真实又计算效率高，适用于自动化的外科系统和虚拟现实手术训练系统。&lt;h4&gt;方法&lt;/h4&gt;使用控制屏障函数（CBFs）和控制李雅普诺夫函数（CLF）框架统一建模类似丝状的行为、碰撞避免、刚度和阻尼。&lt;h4&gt;主要发现&lt;/h4&gt;该模型简化了复杂力的计算或微分方程的求解，大大减少了计算负担，并且保持了一种适合自动化系统和虚拟现实训练系统的现实模型。此外，通过提供基于缝合线与环境交互产生的视觉提示来增强用户体验。&lt;h4&gt;结论&lt;/h4&gt;提出的模型在微创磁性缝合手术系统中进行了测试，该系统使用磁场操纵缝合针，为外科手术提供了一个更少侵入性的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;自动化外科系统的应用提高了精度和安全性，并减少了高风险环境中的人员参与。然而，在像缝合这样的自动化的手术程序中准确建模缝合线是一个挑战，因为现有的模型要么缺乏安全关键过程所需的准确性，要么过于复杂而无法实时执行。在这项研究中，我们提出了一种使用控制屏障函数（CBFs）的新方法来模拟缝合线的动态特性，实现了现实性和计算效率的结合。这种新方法不需要复杂的力或微分方程求解，在保持真实模型的同时显著降低了计算负担，并适用于自动化系统和虚拟现实手术训练系统。此外，该框架还允许根据缝合线与环境的交互提供视觉提示，增强用户体验进行缝合或结扎任务时的体验。提出的模型已在微创磁性缝合平台中进行了测试，这是一个使用磁场操纵缝合针进行外科操作的非侵入性解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automating surgical systems enhances precision and safety while reducinghuman involvement in high-risk environments. A major challenge in automatingsurgical procedures like suturing is accurately modeling the suture thread, ahighly flexible and compliant component. Existing models either lack theaccuracy needed for safety critical procedures or are too computationallyintensive for real time execution. In this work, we introduce a novel approachfor modeling suture thread dynamics using control barrier functions (CBFs),achieving both realism and computational efficiency. Thread like behavior,collision avoidance, stiffness, and damping are all modeled within a unifiedCBF and control Lyapunov function (CLF) framework. Our approach eliminates theneed to calculate complex forces or solve differential equations, significantlyreducing computational overhead while maintaining a realistic model suitablefor both automation and virtual reality surgical training systems. Theframework also allows visual cues to be provided based on the thread'sinteraction with the environment, enhancing user experience when performingsuture or ligation tasks. The proposed model is tested on the MagnetoSuturesystem, a minimally invasive robotic surgical platform that uses magneticfields to manipulate suture needles, offering a less invasive solution forsurgical procedures.</description>
      <author>example@mail.com (Kimia Forghani, Suraj Raval, Lamar Mair, Axel Krieger, Yancy Diaz-Mercado)</author>
      <guid isPermaLink="false">2502.09813v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Vision-based Geo-Localization of Future Mars Rotorcraft in Challenging Illumination Conditions</title>
      <link>http://arxiv.org/abs/2502.09795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;行星探索利用空中资产有可能在火星上实现前所未有的科学发现。&lt;h4&gt;背景&lt;/h4&gt;NASA的火星直升机'机智号'证明了在火星大气中飞行是可能的，但未来的火星旋翼飞机需要先进的导航能力来完成长距离飞行。其中一个重要能力就是基于地图定位（MbL），它通过将机载图像与参考地图进行匹配以减少视觉里程计带来的累积漂移。&lt;h4&gt;目的&lt;/h4&gt;研究一个新的基于地图定位系统并提出Geo-LoFTR，这是一种在光照差异显著的情况下更具鲁棒性的图像配准深度学习模型。&lt;h4&gt;方法&lt;/h4&gt;该系统由一个自定义的模拟框架支持，使用真实的轨道图来生成大量现实的火星地形图像。这些图像被用来测试和评估新的MbL系统的性能。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的系统在光照变化和尺度差异显著的情况下定位准确性超过了以前的方法。&lt;h4&gt;结论&lt;/h4&gt;通过在一个仿真的火星日中验证了该方法的有效性，证明了Geo-LoFTR能够为未来的火星旋翼飞机提供更可靠的导航支持。&lt;h4&gt;翻译&lt;/h4&gt;行星探索使用空中资产有潜力在火星上带来前所未有的科学发现。尽管NASA的火星直升机'机智号'证实了火星大气层中的飞行是可行的，但未来火星旋翼飞机将需要先进的导航能力来完成长距离飞行。其中一种重要能力是基于地图定位（MbL），该方法通过在飞行中将机载图像与参考地图进行匹配以减少视觉里程计带来的累积漂移。然而，传统基于地图定位系统受到旋翼飞机观测和参考图之间光照差异的影响，限制了车辆的运行窗口。本文调查了一种新的基于地图定位系统，并提出了一种Geo-LoFTR模型，这是一种通过几何辅助实现图像配准的深度学习方法，在显著照明变化下比之前的方法更具鲁棒性。该系统支持自定义模拟框架，使用真实轨道图生成大量现实火星地形图像。全面评估表明我们的新系统在光照和尺度变化中超过了以前的基于地图定位工作，同时展示了其在仿真的火星日中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Planetary exploration using aerial assets has the potential for unprecedentedscientific discoveries on Mars. While NASA's Mars helicopter Ingenuity provedflight in Martian atmosphere is possible, future Mars rotocrafts will requireadvanced navigation capabilities for long-range flights. One such criticalcapability is Map-based Localization (MbL) which registers an onboard image toa reference map during flight in order to mitigate cumulative drift from visualodometry. However, significant illumination differences between rotocraftobservations and a reference map prove challenging for traditional MbL systems,restricting the operational window of the vehicle. In this work, we investigatea new MbL system and propose Geo-LoFTR, a geometry-aided deep learning modelfor image registration that is more robust under large illumination differencesthan prior models. The system is supported by a custom simulation frameworkthat uses real orbital maps to produce large amounts of realistic images of theMartian terrain. Comprehensive evaluations show that our proposed systemoutperforms prior MbL efforts in terms of localization accuracy undersignificant lighting and scale variations. Furthermore, we demonstrate thevalidity of our approach across a simulated Martian day.</description>
      <author>example@mail.com (Dario Pisanti, Robert Hewitt, Roland Brockers, Georgios Georgakis)</author>
      <guid isPermaLink="false">2502.09795v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Teaming in Multi-Drone Pursuit: Simulation, Training, and Deployment</title>
      <link>http://arxiv.org/abs/2502.09762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AT-MDP框架，该框架旨在解决多无人机协同追捕任务中的自适应团队合作问题。&lt;h4&gt;背景&lt;/h4&gt;当前关于机器人在未预先协调的情况下与未知队友协作的能力（即自适应团队合作）的研究还较为不足。特别是在边境监控、搜索救援和反恐等领域中需要实时调整策略以应对环境变化的场景，这种能力尤为重要。&lt;h4&gt;目的&lt;/h4&gt;定义并正式化了自适应多无人机追捕问题，并开发了一套包括仿真、算法训练与现实世界部署在内的综合框架AT-MDP。&lt;h4&gt;方法&lt;/h4&gt;构建了一个灵活的实验配置器和仿真接口；提供了一个分布式的算法培训框架，其中包括两个新提出的基线方法以及一个用于评估自适应团队合作能力的未见过无人机集合；并且实现了一套利用边缘计算和Crazyflie无人机的真实世界部署系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过四个不同难度级别的多无人机追捕环境中的广泛实验验证了AT-MDP框架的有效性，且在实际物理系统的部署进一步证明其可行性。&lt;h4&gt;结论&lt;/h4&gt;AT-MDP框架是首个针对复杂现实环境中连续动作决策问题的自适应框架，它使多个无人机能够与未知队友有效协调。这为解决实际应用中多机器人协作挑战提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;自适应团队合作能力是指无需预先协调的情况下能够与其他未知队员进行协同工作的能力，在多机器人协作领域内仍是一个有待探索的问题。本文专注于研究在如边境监控、搜索救援及反恐等现实任务中的多无人机协同追捕情境下的这种自适应能力，并提出了AT-MDP框架，它集成了仿真、算法训练以及实际部署三个部分，旨在提升无人机的协调能力和应对复杂环境变化的能力。实验结果表明该框架不仅在模拟环境中表现良好，在真实世界的应用中也具有可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptive teaming, the ability to collaborate with unseen teammates withoutprior coordination, remains an underexplored challenge in multi-robotcollaboration. This paper focuses on adaptive teaming in multi-dronecooperative pursuit, a critical task with real-world applications such asborder surveillance, search-and-rescue, and counter-terrorism. We first defineand formalize the \textbf{A}daptive Teaming in \textbf{M}ulti-\textbf{D}rone\textbf{P}ursuit (AT-MDP) problem and introduce AT-MDP framework, acomprehensive framework that integrates simulation, algorithm training andreal-world deployment. AT-MDP framework provides a flexible experimentconfigurator and interface for simulation, a distributed training frameworkwith an extensive algorithm zoo (including two newly proposed baseline methods)and an unseen drone zoo for evaluating adaptive teaming, as well as areal-world deployment system that utilizes edge computing and Crazyflie drones.To the best of our knowledge, AT-MDP framework is the first adaptive frameworkfor continuous-action decision-making in complex real-world drone tasks,enabling multiple drones to coordinate effectively with unseen teammates.Extensive experiments in four multi-drone pursuit environments of increasingdifficulty confirm the effectiveness of AT-MDP framework, while real-worlddeployments further validate its feasibility in physical systems. Videos andcode are available at https://sites.google.com/view/at-mdp.</description>
      <author>example@mail.com (Yang Li, Junfan Chen, Feng Xue, Jiabin Qiu, Wenbin Li, Qingrui Zhang, Ying Wen, Wei Pan)</author>
      <guid isPermaLink="false">2502.09762v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning Pipeline via Voting</title>
      <link>http://arxiv.org/abs/2502.09749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to RSS24-W: TaskSpec&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文提出了一种新的投票树规划器(Vote-Tree-Planner)，该策略通过在决策过程中使用投票来指导计划遍历，以此减少LLM的重复查询，提高任务规划系统的执行效率和可靠性。&lt;h4&gt;背景&lt;/h4&gt;目前将大型语言模型（LLMs）集成到闭环机器人任务规划中越来越流行。然而，之前的尝试主要集中在利用LLMs强大的推理能力上，而忽视了由于反复向LLMs进行查询而导致的任务规划效率低下。&lt;h4&gt;目的&lt;/h4&gt;论文旨在通过最小化冗余并提高规划有效性来促进LLM和任务规划系统之间的协同作用。&lt;h4&gt;方法&lt;/h4&gt;基于Prog-Prompt和高级概念的Tree-Planner，研究提出了Vote-Tree-Planner这一采样策略，利用投票机制在决策过程中引导计划遍历。该方法通过给代理分配权重来进行路径评估，以提高成功率并减少LLM查询次数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在未见过的数据集中，与基线方法相比，新的Vote-Tree-Planner表现出更高的稳定性和成功平均率以及目标条件召回率。&lt;h4&gt;结论&lt;/h4&gt;论文的研究结果强调了投票树规划器在基于大型语言模型的计划系统中提高计划准确性、可靠性和效率方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;将大语言模型（LLMs）整合到闭环机器人任务规划中，通过利用这些模型的强大推理能力来改进任务规划性能变得越来越流行。然而，在此过程中往往忽略了由于频繁查询LLM而导致的任务执行效率和可操作性问题。本文探讨了LLM与任务规划系统之间的协同作用，旨在减少冗余并提高计划有效性。基于Prog-Prompt和高级概念的Tree-Planner，我们提出了Vote-Tree-Planner这一采样策略，在决策过程中利用投票机制指导路径遍历。这种方法允许在执行前评估关键路径，并通过简单的投票树构造进一步提高了成功率并减少了LLM查询次数。实验结果表明，我们的Vote-Tree-Planner表现出更好的稳定性，在未见过的数据集中展示了更高的平均成功和目标条件召回率，这比之前的基线方法更为优越。这些发现强调了Vote-Tree-Planner在提高基于大型语言模型的规划系统准确度、可靠性和效率方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating large language models (LLMs) into closed-loop robotic taskplanning has become increasingly popular within embodied artificialintelligence. Previous efforts mainly focused on leveraging the strongreasoning abilities of LLMs to enhance task planning performance while oftenoverlooking task planning efficiency and executability due to repetitivequeries to LLMs. This paper addresses the synergy between LLMs and taskplanning systems, aiming to minimize redundancy while enhancing planningeffectiveness. Specifically, building upon Prog-Prompt and the high-levelconcept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategyutilizes votes to guide plan traversal during the decision-making process. Ourapproach is motivated by a straightforward observation: assigning weights toagents during decision-making enables the evaluation of critical paths beforeexecution. With this simple vote-tree construction, our method further improvesthe success rate and reduces the number of queries to LLMs. The experimentalresults highlight that our Vote-Tree-Planner demonstrates greater stability andshows a higher average success rate and goal condition recall on the unseendataset compared with previous baseline methods. These findings underscore thepotential of the Vote-Tree-Planner to enhance planning accuracy, reliability,and efficiency in LLM-based planning systems.</description>
      <author>example@mail.com (Chaoyuan Zhang, Zhaowei Li, Wentao Yuan)</author>
      <guid isPermaLink="false">2502.09749v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Perch like a bird: bio-inspired optimal maneuvers and nonlinear control for Flapping-Wing Unmanned Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2502.09728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究旨在设计扑翼机器人（ornithopter）的着陆动作和控制系统，通过分析飞行动态、反馈回路及环境约束之间的相互作用，以期提升对鸟类着陆机制的理解，并开发出一种模仿鸟类优美控制策略的最佳操作方式及其控制器。&lt;h4&gt;背景&lt;/h4&gt;现有的扑翼机器人的研究需要更好的理解和优化其在复杂环境中的着陆能力，尤其关注如何模仿自然界中鸟类的精确和优雅的飞行控制。&lt;h4&gt;目的&lt;/h4&gt;通过分析飞行动力学、反馈回路以及环境约束之间的动态交互作用，旨在设计出一种能够实现稳定着陆的最佳操作方式及其控制器，并探讨这种适应性行为在控制系统中的体现。&lt;h4&gt;方法&lt;/h4&gt;采用解析优化问题的方法来最小化着陆时的速度，在给定的运动和动态约束条件下求解。开发了非线性的、自适应的扑翼频率及尾部对称偏转的控制策略，确保稳定着陆的同时具备较强的抗扰能力。&lt;h4&gt;主要发现&lt;/h4&gt;所设计的操作方式包含减速以及快速的垂直转向动作；验证并确认这些自主式的着陆操作能够与文献中报告的真实鸟类着陆轨迹高度一致。&lt;h4&gt;结论&lt;/h4&gt;研究为未来模仿鸟类高效着陆机制的扑翼机器人原型开发奠定了坚实的理论基础，其控制策略在复杂环境下的稳定性和适应性得到了显著提升。&lt;h4&gt;翻译&lt;/h4&gt;这项研究致力于设计仿鸟飞行器（ornithopter）的栖息动作和控制系统。通过分析飞行动态、反馈回路与环境约束之间的相互作用，本研究旨在深化对鸟类着陆机制的理解，并开发出能够实现稳定着陆的最佳操作方式及其控制器。控制策略是根据最小化速度的优化问题，在给定的动力学限制下求解得出，并且具有非线性和自适应性以确保在复杂情况下的稳定性。这种基于家系统原理的适应性行为增强了机器人对未预料干扰的抵抗能力，同时能保持着陆过程中的稳定姿态。所提出的自主式着陆操作——闭环下降和转向动作，在验证中显示出与文献报道的真实鸟类着陆轨迹高度一致。本研究结果为开发未来的仿鸟飞行器原型提供了理论基础，其将能够更加精准地模仿鸟类的栖息技巧。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research endeavors to design the perching maneuver and control inornithopter robots. By analyzing the dynamic interplay between the robot'sflight dynamics, feedback loops, and the environmental constraints, we aim toadvance our understanding of the perching maneuver, drawing parallels tobiological systems. Inspired by the elegant control strategies observed inavian flight, we develop an optimal maneuver and a corresponding controller toachieve stable perching. The maneuver consists of a deceleration and a rapidpitch-up (vertical turn), which arises from analytically solving theoptimization problem of minimal velocity at perch, subject to kinematic anddynamic constraints. The controller for the flapping frequency and tailsymmetric deflection is nonlinear and adaptive, ensuring robustly stableperching. Indeed, such adaptive behavior in a sense incorporates homeostaticprinciples of cybernetics into the control system, enhancing the robot'sability to adapt to unexpected disturbances and maintain a stable postureduring the perching maneuver. The resulting autonomous perching maneuvers --closed-loop descent and turn -- , have been verified and validated,demonstrating excellent agreement with real bird perching trajectories reportedin the literature. These findings lay the theoretical groundwork for thedevelopment of future prototypes that better imitate the skillful perchingmaneuvers of birds.</description>
      <author>example@mail.com (C. Ruiz, J. Á. Acosta)</author>
      <guid isPermaLink="false">2502.09728v1</guid>
      <pubDate>Mon, 17 Feb 2025 16:54:23 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Contrastive Block Disentanglement</title>
      <link>http://arxiv.org/abs/2502.07281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实世界的数据集通常结合了在不同实验条件下收集的数据，这虽然增加了数据量，但也引入了虚假关联，使得难以建模感兴趣的变量。&lt;h4&gt;目的&lt;/h4&gt;提出一种算法来分离现象和虚假关联，并确保模型对环境变化具有不变性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种称为监督对比阻塞解耦（SCBD）的算法，该算法基于纯粹的监督对比学习，能够有效实现这种不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了SCBD在域泛化和批次校正问题上的有效性。通过引入一个超参数α来控制对环境变量e的不变性的程度，并且当增加α以增强不变性时，模型的分布外性能会有所提升但可能会损害其分布内性能。&lt;h4&gt;结论&lt;/h4&gt;提出的SCBD算法优于现有方法，在合成数据集和实际问题（如Camelyon17-WILDS）上均表现出色。该方法可以用于保持生物信号并去除单细胞扰动中的批次效应。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的机器学习方法，旨在解决现实中数据集中存在的虚假关联问题，并提出了一种通过分离现象和虚假关联来提高模型鲁棒性的算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world datasets often combine data collected under different experimentalconditions. This yields larger datasets, but also introduces spuriouscorrelations that make it difficult to model the phenomena of interest. Weaddress this by learning two embeddings to independently represent thephenomena of interest and the spurious correlations. The embedding representingthe phenomena of interest is correlated with the target variable $y$, and isinvariant to the environment variable $e$. In contrast, the embeddingrepresenting the spurious correlations is correlated with $e$. The invarianceto $e$ is difficult to achieve on real-world datasets. Our primary contributionis an algorithm called Supervised Contrastive Block Disentanglement (SCBD) thateffectively enforces this invariance. It is based purely on SupervisedContrastive Learning, and applies to real-world data better than existingapproaches. We empirically validate SCBD on two challenging problems. The firstproblem is domain generalization, where we achieve strong performance on asynthetic dataset, as well as on Camelyon17-WILDS. We introduce a singlehyperparameter $\alpha$ to control the degree of invariance to $e$. When weincrease $\alpha$ to strengthen the degree of invariance, out-of-distributionperformance improves at the expense of in-distribution performance. The secondproblem is batch correction, in which we apply SCBD to preserve biologicalsignal and remove inter-well batch effects when modeling single-cellperturbations from 26 million Optical Pooled Screening images.</description>
      <author>example@mail.com (Taro Makino, Ji Won Park, Natasa Tagasovska, Takamasa Kudo, Paula Coelho, Jan-Christian Huetter, Heming Yao, Burkhard Hoeckendorf, Ana Carolina Leote, Stephen Ra, David Richmond, Kyunghyun Cho, Aviv Regev, Romain Lopez)</author>
      <guid isPermaLink="false">2502.07281v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
  <item>
      <title>Foundation Neural-Network Quantum States</title>
      <link>http://arxiv.org/abs/2502.09488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型是高度灵活的神经网络架构，能够处理不同类型的输入数据（如文本和图像），并且在多种任务上具有泛化能力（例如分类和生成）。&lt;h4&gt;目的&lt;/h4&gt;受此成功启发，提出了Foundation Neural-Network Quantum States (FNQS)，这是一个用于研究量子多体系统的集成范式。&lt;h4&gt;方法&lt;/h4&gt;FNQS利用基础模型的关键原则来定义基于单一、灵活架构的变分波函数，该架构能够处理包括自旋配置和哈密顿量物理耦合在内的多种输入模式。与为特定哈密顿量定制的专业架构不同，FNQS可以泛化到训练过程中未曾遇到的其他物理系统。&lt;h4&gt;主要发现&lt;/h4&gt;FNQS使传统方法难以计算或计算成本高昂的一些量（如无序平均可观测值）的有效估计成为可能，并且易于获得保真度易感性以揭示量子相变，而无需事先了解顺序参数。&lt;h4&gt;结论&lt;/h4&gt;这些预训练模型可以高效地针对特定的量子系统进行微调。论文中所使用的架构可以在Hugging Face上公开访问：https://huggingface.co/nqs-models，并附有使用NetKet实现这些神经网络的例子。&lt;h4&gt;翻译&lt;/h4&gt;基础模型是能够处理多种数据类型（如文本和图像）并能跨多个任务泛化的灵活的神经网络结构。受此启发，我们提出了Foundation Neural-Network Quantum States (FNQS)，这是一种用于研究量子多体系统的一体化方法。FNQS利用基础模型的关键原则来定义基于单一、多功能架构的变分波函数，该架构可以处理包括自旋配置和哈密顿量物理耦合在内的多模态输入。与针对特定哈密顿量定制的专业结构不同，FNQS能够泛化到训练过程中未曾遇到的新物理系统，提供了一种适用于各种量子系统的统一框架。此外，FNQS可以高效地估计传统方法难以计算或成本高昂的某些量（如无序平均观测值），并且很容易获得保真度易感性来揭示量子相变，而无需事先了解顺序参数。这些预训练模型可以针对特定量子系统进行高效的微调。本文使用的架构可以在https://huggingface.co/nqs-models公开获取，并附有使用NetKet实现该神经网络的示例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are highly versatile neural-network architectures capableof processing different data types, such as text and images, and generalizingacross various tasks like classification and generation. Inspired by thissuccess, we propose Foundation Neural-Network Quantum States (FNQS) as anintegrated paradigm for studying quantum many-body systems. FNQS leverage keyprinciples of foundation models to define variational wave functions based on asingle, versatile architecture that processes multimodal inputs, including spinconfigurations and Hamiltonian physical couplings. Unlike specializedarchitectures tailored for individual Hamiltonians, FNQS can generalize tophysical Hamiltonians beyond those encountered during training, offering aunified framework adaptable to various quantum systems and tasks. FNQS enablethe efficient estimation of quantities that are traditionally challenging orcomputationally intensive to calculate using conventional methods, particularlydisorder-averaged observables. Furthermore, the fidelity susceptibility can beeasily obtained to uncover quantum phase transitions without prior knowledge oforder parameters. These pretrained models can be efficiently fine-tuned forspecific quantum systems. The architectures trained in this paper are publiclyavailable at https://huggingface.co/nqs-models, along with examples forimplementing these neural networks in NetKet.</description>
      <author>example@mail.com (Riccardo Rende, Luciano Loris Viteritti, Federico Becca, Antonello Scardicchio, Alessandro Laio, Giuseppe Carleo)</author>
      <guid isPermaLink="false">2502.09488v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Reinforcement Learning for Optimization in Automation</title>
      <link>http://arxiv.org/abs/2502.09417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 tables, and 1 figure. Accepted at IEEE 20th International  Conference on Automation Science and Engineering (CASE) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇综述文章探讨了强化学习在自动化领域中的当前应用及未来发展方向。&lt;h4&gt;背景&lt;/h4&gt;强化学习作为解决复杂优化挑战的重要工具，在自动化的多个方面已经取得了显著进展。本文集中于制造业、能源系统和机器人技术三大领域的研究现状，同时讨论了各个领域内的前沿方法以及存在的重大挑战。&lt;h4&gt;目的&lt;/h4&gt;本论文旨在分析自动化中强化学习驱动的优化方法的优势与限制，并指出现有挑战，为未来的研究提供方向。&lt;h4&gt;方法&lt;/h4&gt;文章首先回顾强化学习在制造、能源系统和机器人技术中的应用情况，然后探讨了这些领域内存在的问题以及未来的研究趋势。&lt;h4&gt;主要发现&lt;/h4&gt;文中指出了一些普遍遇到的问题，例如样本效率与可扩展性；安全性及鲁棒性；可解释性和可信度；迁移学习与元学习；真实场景部署等。此外，文章还展望了解决这些问题的潜在策略和未来的研究途径。&lt;h4&gt;结论&lt;/h4&gt;该综述总结了强化学习在自动化优化中的重要角色，并为研究人员提供了相关文献资源列表，有助于探索这一研究领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已提供翻译内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CASE59546.2024.10711718&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) has become a critical tool for optimizationchallenges within automation, leading to significant advancements in severalareas. This review article examines the current landscape of RL withinautomation, with a particular focus on its roles in manufacturing, energysystems, and robotics. It discusses state-of-the-art methods, major challenges,and upcoming avenues of research within each sector, highlighting RL's capacityto solve intricate optimization challenges. The paper reviews the advantagesand constraints of RL-driven optimization methods in automation. It points outprevalent challenges encountered in RL optimization, including issues relatedto sample efficiency and scalability; safety and robustness; interpretabilityand trustworthiness; transfer learning and meta-learning; and real-worlddeployment and integration. It further explores prospective strategies andfuture research pathways to navigate these challenges. Additionally, the surveyincludes a comprehensive list of relevant research papers, making it anindispensable guide for scholars and practitioners keen on exploring thisdomain.</description>
      <author>example@mail.com (Ahmad Farooq, Kamran Iqbal)</author>
      <guid isPermaLink="false">2502.09417v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Potential of Encoder-free Architectures in 3D LMMs</title>
      <link>http://arxiv.org/abs/2502.09620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is released at https://github.com/Ivan-Tang-3D/ENEL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文首次全面研究了无编码器架构在三维理解场景中的应用潜力，提出了一种新颖的Encoder-free 3D LMM（ENEL），该模型在不使用传统编码器的情况下，在分类、描述和视觉问答任务上取得了与现有最佳模型相当的表现。&lt;h4&gt;背景&lt;/h4&gt;虽然无编码器架构已在二维视觉领域得到初步探索，但它们是否能有效应用于三维理解场景仍然是一个未解的问题。&lt;h4&gt;目的&lt;/h4&gt;探讨无编码器架构在3D Large Multimodal Models（LMMs）中的应用潜力，并克服现有基于编码器模型的挑战。&lt;h4&gt;方法&lt;/h4&gt;{'LLM-embedded Semantic Encoding策略': '提出了语义嵌入自监督损失，探索不同点云自监督损失的效果，并引入混合语义损失以提取高级语义信息。', 'Hierarchical Geometry Aggregation策略': '在指令调优阶段加入层次几何聚合策略，将归纳偏置融入LLM的早期层，使其专注于点云的局部细节。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种名为ENEL的新模型，在7B参数规模下与当前最先进的ShapeLLM-13B模型相比，分别在分类、描述和视觉问答任务上达到了55.0%、50.92%和42.7%的成绩。&lt;h4&gt;结论&lt;/h4&gt;无编码器架构在三维理解领域具有很高的潜力，并可能成为替代现有基于编码器架构的有效方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Encoder-free architectures have been preliminarily explored in the 2D visualdomain, yet it remains an open question whether they can be effectively appliedto 3D understanding scenarios. In this paper, we present the firstcomprehensive investigation into the potential of encoder-free architectures toovercome the challenges of encoder-based 3D Large Multimodal Models (LMMs).These challenges include the failure to adapt to varying point cloudresolutions and the point features from the encoder not meeting the semanticneeds of Large Language Models (LLMs). We identify key aspects for 3D LMMs toremove the encoder and enable the LLM to assume the role of the 3D encoder: 1)We propose the LLM-embedded Semantic Encoding strategy in the pre-trainingstage, exploring the effects of various point cloud self-supervised losses. Andwe present the Hybrid Semantic Loss to extract high-level semantics. 2) Weintroduce the Hierarchical Geometry Aggregation strategy in the instructiontuning stage. This incorporates inductive bias into the LLM early layers tofocus on the local details of the point clouds. To the end, we present thefirst Encoder-free 3D LMM, ENEL. Our 7B model rivals the currentstate-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on theclassification, captioning, and VQA tasks, respectively. Our resultsdemonstrate that the encoder-free architecture is highly promising forreplacing encoder-based architectures in the field of 3D understanding. Thecode is released at https://github.com/Ivan-Tang-3D/ENEL</description>
      <author>example@mail.com (Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao)</author>
      <guid isPermaLink="false">2502.09620v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>FARM: Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation</title>
      <link>http://arxiv.org/abs/2502.09375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种频率感知模型（FARM）用于跨域直播推荐，解决了用户行为稀疏和短视频曝光量远大于直播导致的用户偏好建模困难的问题。&lt;h4&gt;背景&lt;/h4&gt;由于实时互动性和娱乐价值，直播服务吸引了广泛的关注。用户的参与方式包括留言、点赞或发送虚拟礼物等，但这些有价值的行为是零散且难以捕捉的。平台上的主要曝光内容为短视频，其占比远高于直播，这使得直播内容无法充分反映用户偏好。&lt;h4&gt;目的&lt;/h4&gt;提出一种频率感知模型（FARM）解决数据稀疏性问题，并优化跨域推荐系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一个频域内关注模块以及跨领域偏好转换与融合策略。通过离散傅里叶变换，该模型能够捕捉高频率用户行为信息；同时使用对比学习技术进行偏好对齐，并设计一系列定制的注意力机制来融合来自不同领域的用户偏好。&lt;h4&gt;主要发现&lt;/h4&gt;FARM模型在广泛的离线实验和线上A/B测试中均表现出有效性和优越性。它已经在快手直播服务上部署，为数亿用户提供个性化推荐。&lt;h4&gt;结论&lt;/h4&gt;通过频率感知方法和跨域偏好的优化处理，FARM能够更有效地利用稀疏用户行为数据进行精准的直播推荐，并显著提高用户体验。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Live-streaming services have attracted widespread popularity due to theirreal-time interactivity and entertainment value. Users can engage withlive-streaming authors by participating in live chats, posting likes, orsending virtual gifts to convey their preferences and support. However, thelive-streaming services faces serious data-sparsity problem, which can beattributed to the following two points: (1) User's valuable behaviors areusually sparse, e.g., like, comment and gift, which are easily overlooked bythe model, making it difficult to describe user's personalized preference. (2)The main exposure content on our platform is short-video, which is 9 timeshigher than the exposed live-streaming, leading to the inability oflive-streaming content to fully model user preference. To this end, we proposea Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation, termedas FARM. Specifically, we first present the intra-domain frequency aware moduleto enable our model to perceive user's sparse yet valuable behaviors, i.e.,high-frequency information, supported by the Discrete Fourier Transform (DFT).To transfer user preference across the short-video and live-streaming domains,we propose a novel preference align before fuse strategy, which consists of twoparts: the cross-domain preference align module to align user preference inboth domains with contrastive learning, and the cross-domain preference fusemodule to further fuse user preference in both domains using a serious oftailor-designed attention mechanisms. Extensive offline experiments and onlineA/B testing on Kuaishou live-streaming services demonstrate the effectivenessand superiority of FARM. Our FARM has been deployed in online live-streamingservices and currently serves hundreds of millions of users on Kuaishou.</description>
      <author>example@mail.com (Xiaodong Li, Ruochen Yang, Shuang Wen, Shen Wang, Yueyang Liu, Guoquan Wang, Weisong Hu, Qiang Luo, Jiawei Sheng, Tingwen Liu, Jiangxia Cao, Shuang Yang, Zhaojie Liu)</author>
      <guid isPermaLink="false">2502.09375v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures</title>
      <link>http://arxiv.org/abs/2502.09623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种可以处理具有不同架构的NeRF的框架，并展示了如何通过训练图元网络来实现这一目标，从而在未见过的新架构上进行推断。&lt;h4&gt;背景&lt;/h4&gt;Neural Radiance Fields (NeRFs) 已成为表示3D对象和场景的一种突破性范式。现有方法只能处理具有特定预定义架构的NeRF。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以接受多种架构的NeRF并能在训练时未见过的新架构上执行推断的框架。&lt;h4&gt;方法&lt;/h4&gt;通过在表征学习框架中使用图元网络进行训练，并展示了对比目标如何有助于获得不受架构限制的潜在空间。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基于多层感知机（MLP）和三平面NeRF上的分类和检索任务上表现出色，性能至少与针对单一架构设计的方法相当或更好。&lt;h4&gt;结论&lt;/h4&gt;提出了首个能处理任意架构的NeRF并执行相关任务的方法，通过处理它们的权重来实现这一点。&lt;h4&gt;翻译&lt;/h4&gt;神经辐射场（Neural Radiance Fields, NeRFs）已成为表示3D对象和场景的一种突破性范式，将形状和外观信息编码到神经网络的权重中。最近的研究表明这些权重可以作为输入框架用于解决深度学习任务。然而，现有框架只能处理具有特定预定义架构的NeRF。本文介绍了一种首个能够接受多种架构的NeRF并能在训练时未见过的新架构上执行推断的框架。我们通过在表征学习框架中训练图元网络来实现这一目标，并展示了对比目标如何有助于获得不受架构限制的潜在空间。实验表明，在基于多层感知机（MLP）和三平面NeRF上的分类和检索任务中，我们的方法表现出与现有针对单一架构设计的方法相当或更好的性能，从而提供了一种首个处理任意架构的NeRF并执行相关任务的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm forrepresenting 3D objects and scenes by encoding shape and appearance informationinto the weights of a neural network. Recent works have shown how such weightscan be used as input to frameworks processing them to solve deep learningtasks. Yet, these frameworks can only process NeRFs with a specific, predefinedarchitecture. In this paper, we present the first framework that can ingestNeRFs with multiple architectures and perform inference on architectures unseenat training time. We achieve this goal by training a Graph Meta-Network in arepresentation learning framework. Moreover, we show how a contrastiveobjective is conducive to obtaining an architecture-agnostic latent space. Inexperiments on both MLP-based and tri-planar NeRFs, our approach demonstratesrobust performance in classification and retrieval tasks that either matches orexceeds that of existing frameworks constrained to single architectures, thusproviding the first architecture-agnostic method to perform tasks on NeRFs byprocessing their weights.</description>
      <author>example@mail.com (Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano)</author>
      <guid isPermaLink="false">2502.09623v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Utility of Higher-Order Information in Relational Learning</title>
      <link>http://arxiv.org/abs/2502.09570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文系统评估了若干超图级和图级架构在关系学习中利用高阶信息的有效性，发现将图级模型应用于超图扩展通常优于专门的超图级架构，并提出了一种基于经典超图特征的编码方法以增强图神经网络的表现力。&lt;h4&gt;背景&lt;/h4&gt;许多领域的关系推理需要超越成对交互的信息。超图作为一种自然框架来建模这些关系已经被提出，这促使了图神经网络架构向超图的扩展研究。&lt;h4&gt;目的&lt;/h4&gt;系统评估几种基于超图级和图级别的架构在利用高阶信息方面的效果，并探索新的方法来提高表现力。&lt;h4&gt;方法&lt;/h4&gt;选取了几种超图级别和图级别的模型进行了实验对比，引入了一种依赖于经典超图特性的编码策略以进一步提升性能。&lt;h4&gt;主要发现&lt;/h4&gt;将图级架构应用于超图扩展通常在关系学习中效果更佳；基于经典特性设计的超图级编码虽未显著改善专用的超图形构，但与图模型结合使用时表现良好。理论分析表明这种编码方法可以增加消息传递式图神经网络的表现力。&lt;h4&gt;结论&lt;/h4&gt;对于许多应用而言，利用超图扩展上的图架构可能比专门的超图模型更加有效；同时，基于经典特性的超图级编码能提高图神经网络的学习能力。&lt;h4&gt;翻译&lt;/h4&gt;高阶信息在许多领域的关系学习中至关重要，这些领域的关系超越了成对交互。超图提供了一种自然框架来建模这种关系，这激发了最近将图神经网络架构扩展到超图的研究。然而，超图架构与标准图级别模型之间的比较仍然有限。在这项工作中，我们系统地评估了几种基于超图和图级别的架构的有效性，以确定它们在利用高阶信息进行关系学习中的有效性。我们的结果显示，在处理自然参数化为超图的输入时，将图级架构应用于超图扩展通常优于专用的超图级模型。作为另一种方法来利用高阶信息，我们提出了基于经典超图特征特性的超图级编码方案。尽管这些编码方式并未显著改善专用的超图形构，但与图级别模型结合使用时表现良好。我们的理论分析表明，这种基于超图级的编码可以确凿地提升消息传递式图神经网络的表现力，超越其对应的图级别模型的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Higher-order information is crucial for relational learning in many domainswhere relationships extend beyond pairwise interactions. Hypergraphs provide anatural framework for modeling such relationships, which has motivated recentextensions of graph neural net- work architectures to hypergraphs. However,comparisons between hypergraph architectures and standard graph-level modelsremain limited. In this work, we systematically evaluate a selection ofhypergraph-level and graph-level architectures, to determine theireffectiveness in leveraging higher-order information in relational learning.Our results show that graph-level architectures applied to hypergraphexpansions often outperform hypergraph- level ones, even on inputs that arenaturally parametrized as hypergraphs. As an alternative approach forleveraging higher-order information, we propose hypergraph-level encodingsbased on classical hypergraph characteristics. While these encodings do notsignificantly improve hypergraph architectures, they yield substantialperformance gains when combined with graph-level models. Our theoreticalanalysis shows that hypergraph-level encodings provably increase therepresentational power of message-passing graph neural networks beyond that oftheir graph-level counterparts.</description>
      <author>example@mail.com (Raphael Pellegrin, Lukas Fesser, Melanie Weber)</author>
      <guid isPermaLink="false">2502.09570v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Euclidean Alignment for Transfer Learning in EEG-Based Brain-Computer Interfaces</title>
      <link>http://arxiv.org/abs/2502.09203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文回顾了欧氏对齐(EA)技术，该技术在2020年被提出用于改进基于脑电图(EEG)的脑机接口(BCI)系统的校准过程。&lt;h4&gt;背景&lt;/h4&gt;由于EEG信号具有非平稳性和较大的个体差异性，基于EEG的BCI系统通常需要针对每个新用户进行特定主体的校准。这种校准过程耗时且不友好，阻碍了其在现实世界中的应用。转移学习(TL)被广泛用于加快这一过程。&lt;h4&gt;目的&lt;/h4&gt;通过减少不同受试者/会话之间的数据分布差异来避免负向迁移，并介绍EA的有效性、使用方法及其扩展应用，同时指出潜在的新研究方向。&lt;h4&gt;方法&lt;/h4&gt;文章解释了欧氏对齐(EA)的程序和正确使用方式，并展示了其在10种不同BCI范式中的众多实验结果。&lt;h4&gt;主要发现&lt;/h4&gt;EA技术通过减少数据分布差异显著提高了基于EEG信号的解码效率，减少了新的用户校准时间。&lt;h4&gt;结论&lt;/h4&gt;对于研究基于EEG信号的BCI系统的研究人员来说，该论文提供了有关EA技术的全面概述，并为未来的研究方向提出了建议。&lt;h4&gt;翻译&lt;/h4&gt;由于EEG信号的非平稳性和个体差异性较大，基于EEG的脑机接口(BCI)通常需要针对每个新用户进行特定主体校准。这种过程耗时且不友好，限制了其实用价值。转移学习(TL)已被广泛用于通过利用其他受试者/会话的数据来加速此过程。对于TL在EEG-BCI中的应用而言，减少不同受试者或会话间数据分布差异以避免负向迁移是一个重要考虑因素。2020年提出了一种欧氏对齐(EA)方法来解决这一挑战。该技术通过大量的实验验证了其有效性和效率，涵盖了10种不同的BCI范式。本文重新审视EA技术，解释其实现流程和正确使用方式，并介绍其应用及扩展方向，同时指出了可能的新研究领域。这对EEG信号解码研究人员来说极具价值，尤其是那些致力于解决基于EEG的BCI系统问题的研究者们。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the non-stationarity and large individual differences of EEG signals,EEG-based brain-computer interfaces (BCIs) usually need subject-specificcalibration to tailor the decoding algorithm for each new subject, which istime-consuming and user-unfriendly, hindering their real-world applications.Transfer learning (TL) has been extensively used to expedite the calibration,by making use of EEG data from other subjects/sessions. An importantconsideration in TL for EEG-based BCIs is to reduce the data distributiondiscrepancies among different subjects/session, to avoid negative transfer.Euclidean alignment (EA) was proposed in 2020 to address this challenge.Numerous experiments from 10 different BCI paradigms demonstrated itseffectiveness and efficiency. This paper revisits the EA, explaining itsprocedure and correct usage, introducing its applications and extensions, andpointing out potential new research directions. It should be very helpful toBCI researchers, especially those who are working on EEG signal decoding.</description>
      <author>example@mail.com (Dongrui Wu)</author>
      <guid isPermaLink="false">2502.09203v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)</title>
      <link>http://arxiv.org/abs/2502.09376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了低秩适应（LoRA）在训练大型基础模型时的理论性质，提出了两种不同的场景，并探讨了零初始化和权重衰减如何影响参数空间中的解决方案。&lt;h4&gt;背景&lt;/h4&gt;目前对LoRA的理论理解尚不充分，大多数先前的研究依赖于线性化假设或考虑过于简化的设定。本文旨在解决这一局限。&lt;h4&gt;目的&lt;/h4&gt;分析在没有简化假设的情况下，LoRA训练损失函数的特性，并探讨零初始化和权重衰减如何影响模型参数空间中的解决方案。&lt;h4&gt;方法&lt;/h4&gt;定义了两个不同的训练场景：特殊模式（线性化假设适用的理想情况）和通用模式（非理想、更现实的情况）。并在这两个背景下分析了LoRA的收敛性质。&lt;h4&gt;主要发现&lt;/h4&gt;在通用情况下，LoRA训练可以收敛到低秩且小幅度的全局最小值或高秩且大幅度的独特解决方案。零初始化和权重衰减促使模型倾向于低秩且小幅度参数空间内的全局极小值区。&lt;h4&gt;结论&lt;/h4&gt;通过分析揭示了为什么LoRA通常能够在大型基础模型中找到全局最小值，为未来研究提供了理论依据。&lt;h4&gt;翻译&lt;/h4&gt;低秩适应（LoRA）已经成为微调大尺度基础模型的标准方法。然而，关于LoRA的理论理解仍然有限，先前对LoRA训练动态的研究要么依赖于线性化论证，要么考虑了高度简化的设置。在本工作中，我们分析了在没有这些限制假设的情况下LoRA损失函数的变化情况。我们将这种变化定义为两种情形：一种是'特殊模式'，包括理想化的设置，在那里可以使用线性化论证；另一种是更现实的场景下的‘通用模式’，在这种模式下线性化论证并不适用。在通用模式中，我们展示了LoRA训练会收敛到一个具有低秩且小幅度或高度且大幅度的独特全局最小值解决方案上。最后，我们指出零初始化和权重衰减在LoRA训练中的作用促使模型倾向于参数空间中的低秩、小幅度的区域——也就是全局最小值所在的区域——从而解释了为什么LoRA通常能找到全局极小值的原因所在。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has become a standard approach for fine-tuninglarge foundation models. However, our theoretical understanding of LoRA remainslimited as prior analyses of LoRA's training dynamics either rely onlinearization arguments or consider highly simplified setups. In this work, weanalyze the LoRA loss landscape without such restrictive assumptions. We definetwo regimes: a ``special regime'', which includes idealized setups wherelinearization arguments hold, and a ``generic regime'' representing morerealistic setups where linearization arguments do not hold. In the genericregime, we show that LoRA training converges to a global minimizer with lowrank and small magnitude, or a qualitatively distinct solution with high rankand large magnitude. Finally, we argue that the zero-initialization and weightdecay in LoRA training induce an implicit bias toward the low-rank,small-magnitude region of the parameter space -- where global minima lie --thus shedding light on why LoRA training usually succeeds in finding globalminima.</description>
      <author>example@mail.com (Junsu Kim, Jaeyeon Kim, Ernest K. Ryu)</author>
      <guid isPermaLink="false">2502.09376v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Machine learning for modelling unstructured grid data in computational physics: a review</title>
      <link>http://arxiv.org/abs/2502.09346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了处理高维动态系统中不规则网格数据的先进机器学习（ML）方法，特别关注计算物理学领域。&lt;h4&gt;背景&lt;/h4&gt;在计算物理中，不结构化的网格数据对于建模复杂的几何形状和动力学至关重要。然而，这些数据本身的不规则性给传统的机器学习技术带来了显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提供一份关于处理高维动态系统中的不规则网格数据的先进ML方法的全面综述，为计算科学家和ML研究人员提供指导。&lt;h4&gt;方法&lt;/h4&gt;讨论的关键方法包括图神经网络、具有空间注意力机制的变压器模型、插值集成机器学习方法以及如物理信息神经网络之类的无网格技术。&lt;h4&gt;主要发现&lt;/h4&gt;这些方法已在流体动力学和环境模拟等各个领域证明了其有效性，展示了ML在克服传统数值技术局限性方面的潜力，并反过来利用计算物理学中的见解来促进ML的发展。&lt;h4&gt;结论&lt;/h4&gt;该综述不仅概述了开放访问的不规则网格数据集以支持基准测试，还讨论了一些新兴方向如无结构数据生成模型、强化学习用于网格式样生成以及混合物理-数据驱动范式等，旨在激发未来在这一不断发展的领域中的创新和进步。&lt;h4&gt;翻译&lt;/h4&gt;未直接作为摘要内容的一部分，这里表示整个摘要的内容已经被翻译成了中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unstructured grid data are essential for modelling complex geometries anddynamics in computational physics. Yet, their inherent irregularity presentssignificant challenges for conventional machine learning (ML) techniques. Thispaper provides a comprehensive review of advanced ML methodologies designed tohandle unstructured grid data in high-dimensional dynamical systems. Keyapproaches discussed include graph neural networks, transformer models withspatial attention mechanisms, interpolation-integrated ML methods, and meshlesstechniques such as physics-informed neural networks. These methodologies haveproven effective across diverse fields, including fluid dynamics andenvironmental simulations. This review is intended as a guidebook forcomputational scientists seeking to apply ML approaches to unstructured griddata in their domains, as well as for ML researchers looking to addresschallenges in computational physics. It places special focus on how ML methodscan overcome the inherent limitations of traditional numerical techniques and,conversely, how insights from computational physics can inform ML development.To support benchmarking, this review also provides a summary of open-accessdatasets of unstructured grid data in computational physics. Finally, emergingdirections such as generative models with unstructured data, reinforcementlearning for mesh generation, and hybrid physics-data-driven paradigms arediscussed to inspire future advancements in this evolving field.</description>
      <author>example@mail.com (Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci)</author>
      <guid isPermaLink="false">2502.09346v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation</title>
      <link>http://arxiv.org/abs/2502.08826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模语言模型（LLM）由于依赖静态训练数据，在幻觉和过时知识方面存在挑战。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题。&lt;h4&gt;目的&lt;/h4&gt;该综述提供了一个结构化且全面的多模态RAG系统的分析，涵盖了数据集、度量标准、基准测试、评估方法论及创新等各个方面。&lt;h4&gt;方法&lt;/h4&gt;详细回顾了训练策略、鲁棒性增强和损失函数，并探讨了多样化的多模态RAG场景。还讨论了开放性挑战和未来研究方向。&lt;h4&gt;主要发现&lt;/h4&gt;跨模态对齐与推理给多模态RAG带来了独特的挑战，使其区别于传统的单模态RAG。&lt;h4&gt;结论&lt;/h4&gt;该综述为开发更强大、可靠的AI系统奠定了基础，这些系统能有效利用多模态动态外部知识库。&lt;h4&gt;翻译&lt;/h4&gt;大规模语言模型（LLM）由于依赖静态训练数据，在幻觉和过时知识方面存在挑战。检索增强生成（RAG）通过整合外部动态信息来缓解这些问题。近年来，随着多模态学习的进步，开发出了将文本、图像、音频和视频等多种模式结合的多模态RAG系统以提高生成输出的质量。然而，跨模态对齐与推理给多模态RAG带来了独特的挑战，使其区别于传统的单模态RAG。本综述提供了一个结构化且全面的分析，涵盖了数据集、度量标准、基准测试、评估方法论及创新等各个方面。详细回顾了训练策略、鲁棒性增强和损失函数，并探讨了多样化的多模态RAG场景。还讨论了开放性挑战和未来研究方向，以支持该领域的发展进步。本综述为开发更强大、可靠的AI系统奠定了基础，这些系统能有效利用多模态动态外部知识库。资源详见：https://github.com/llm-lab-org/Multimodal-RAG-Survey。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) struggle with hallucinations and outdatedknowledge due to their reliance on static training data. Retrieval-AugmentedGeneration (RAG) mitigates these issues by integrating external dynamicinformation enhancing factual and updated grounding. Recent advances inmultimodal learning have led to the development of Multimodal RAG,incorporating multiple modalities such as text, images, audio, and video toenhance the generated outputs. However, cross-modal alignment and reasoningintroduce unique challenges to Multimodal RAG, distinguishing it fromtraditional unimodal RAG. This survey offers a structured and comprehensiveanalysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,evaluation, methodologies, and innovations in retrieval, fusion, augmentation,and generation. We precisely review training strategies, robustnessenhancements, and loss functions, while also exploring the diverse MultimodalRAG scenarios. Furthermore, we discuss open challenges and future researchdirections to support advancements in this evolving field. This survey lays thefoundation for developing more capable and reliable AI systems that effectivelyleverage multimodal dynamic external knowledge bases. Resources are availableat https://github.com/llm-lab-org/Multimodal-RAG-Survey.</description>
      <author>example@mail.com (Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari)</author>
      <guid isPermaLink="false">2502.08826v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>FLARES: Fast and Accurate LiDAR Multi-Range Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2502.09274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种改进的基于范围视图的工作流程，用于激光雷达语义分割，旨在克服现有方法在数据稀疏性和计算需求方面的挑战。&lt;h4&gt;背景&lt;/h4&gt;三维场景理解是自动驾驶中的关键任务之一，但由于激光雷达数据的不规则和稀疏性以及处理大规模点云所需的大量计算资源，这一任务极具挑战性。现有的方法利用范围视图表示来提高处理效率。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过重新设计工作流程来解决由于将多个3D点映射到相同的2D网格而导致的信息丢失问题，并证明降低分辨率可以在准确性和效率上提供更佳的解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种综合性的重新设计方案，包括数据表示、增强和后处理方法改进。通过在两个公开数据集上的广泛实验验证了所提出的管道能够显著提升多种网络架构的表现。&lt;h4&gt;主要发现&lt;/h4&gt;降低分辨率而非增加分辨率更有助于提高效率和准确性；重新设计的流程可以改善各种网络架构的表现。&lt;h4&gt;结论&lt;/h4&gt;这项工作为基于激光雷达的有效感知提供了更好的途径，表明了在自动驾驶系统中采用该方法的可能性。&lt;h4&gt;翻译&lt;/h4&gt;3D场景理解是自主驾驶中的关键但具有挑战性的任务，主要原因是激光雷达数据的不规则性和稀疏性以及处理大规模点云所需的大量计算资源。最近的方法利用范围视图表示来提高处理效率。为了解决由“多对一”问题导致的信息丢失所引起的性能下降，“多对一”中多个附近的3D点映射到相同的2D网格并且只保留最接近的点，先前的工作倾向于选择更高的俯仰分辨率进行范围视图投影。然而，这会带来减少携带信息像素比例和网络内部计算量加重的问题。我们认为这不是最优解决方案，并展示降低分辨率在效率和准确性上更具优势。在此工作中，我们提出了基于范围视图的LiDAR语义分割工作流程的全面重新设计。我们的方法解决了数据表示、增强及后处理方法改进的问题。通过两个公开数据集上的广泛实验，我们证明了相对于基线，该管道可以显著提升各种网络架构的表现，为自主系统中的有效激光雷达感知铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene understanding is a critical yet challenging task in autonomousdriving, primarily due to the irregularity and sparsity of LiDAR data, as wellas the computational demands of processing large-scale point clouds. Recentmethods leverage the range-view representation to improve processingefficiency. To mitigate the performance drop caused by information lossinherent to the "many-to-one" problem, where multiple nearby 3D points aremapped to the same 2D grids and only the closest is retained, prior works tendto choose a higher azimuth resolution for range-view projection. However, thiscan bring the drawback of reducing the proportion of pixels that carryinformation and heavier computation within the network. We argue that it is notthe optimal solution and show that, in contrast, decreasing the resolution ismore advantageous in both efficiency and accuracy. In this work, we present acomprehensive re-design of the workflow for range-view-based LiDAR semanticsegmentation. Our approach addresses data representation, augmentation, andpost-processing methods for improvements. Through extensive experiments on twopublic datasets, we demonstrate that our pipeline significantly enhances theperformance of various network architectures over their baselines, paving theway for more effective LiDAR-based perception in autonomous systems.</description>
      <author>example@mail.com (Bin Yang, Alexandru Paul Condurache)</author>
      <guid isPermaLink="false">2502.09274v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Graph Diffusion Network for Drug-Gene Prediction</title>
      <link>http://arxiv.org/abs/2502.09335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/ACM TCBB. 14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为GDNDGP的图扩散网络框架，用于预测药物-基因关联。此框架通过两项创新解决了数据稀疏性和高效对比学习实施的问题：一是采用基于元路径的同质图学习方法捕捉药物与药物、基因与基因之间的关系；二是引入并行扩散网络生成训练期间的硬负样本。&lt;h4&gt;背景&lt;/h4&gt;药物-基因关联预测对于药物开发和疾病治疗至关重要，而图形神经网络（GNN）在解决这个问题时遇到了数据稀疏性和高效对比性学习实现的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图扩散网络框架GDNDGP，以改进现有方法在药物-基因预测任务中的表现，特别是在处理复杂的异构关系方面。&lt;h4&gt;方法&lt;/h4&gt;该模型通过采用基于元路径的同质图学习捕捉药物与药物、基因与基因之间的关系，并引入并行扩散网络生成硬负样本来改善训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;在DGIdb 4.0数据集上，所提出的GDNDGP框架实现了优于现有方法的表现。此外，在三元组的药物-基因-疾病网络中也展示了较强的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该模型通过创新的方法显著提升了药物-基因预测任务中的性能，并且开源了源代码供社区使用。&lt;h4&gt;翻译&lt;/h4&gt;预测药物-基因关联对于药物开发和治疗疾病至关重要。虽然图神经网络（GNN）在这一领域表现出有效性，但它们面临着数据稀疏性和高效对比学习实现的挑战。我们引入了一种用于药物-基因预测的图扩散网络（GDNDGP），该框架通过两项关键创新解决了这些限制：第一，它使用基于元路径的同质图学习方法捕捉药物-药物和基因-基因关系，确保相似实体共享嵌入空间；第二，它包括一个并行扩散网络，在训练期间生成硬负样本，消除了对穷举式负样本检索的需求。我们的模型在DGIdb 4.0数据集上实现了优于现有方法的表现，并且在三元组的药物-基因-疾病网络中展示了强大的泛化能力。结果表明，该方法显著改进了现有的药物-基因预测任务中的表现，特别是在处理复杂的异构关系方面。源代码可在https://github.com/csjywu1/GDNDGP上公开获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting drug-gene associations is crucial for drug development and diseasetreatment. While graph neural networks (GNN) have shown effectiveness in thistask, they face challenges with data sparsity and efficient contrastivelearning implementation. We introduce a graph diffusion network for drug-geneprediction (GDNDGP), a framework that addresses these limitations through twokey innovations. First, it employs meta-path-based homogeneous graph learningto capture drug-drug and gene-gene relationships, ensuring similar entitiesshare embedding spaces. Second, it incorporates a parallel diffusion networkthat generates hard negative samples during training, eliminating the need forexhaustive negative sample retrieval. Our model achieves superior performanceon the DGIdb 4.0 dataset and demonstrates strong generalization capability ontripartite drug-gene-disease networks. Results show significant improvementsover existing methods in drug-gene prediction tasks, particularly in handlingcomplex heterogeneous relationships. The source code is publicly available athttps://github.com/csjywu1/GDNDGP.</description>
      <author>example@mail.com (Jiayang Wu, Wensheng Gan, Philip S. Yu)</author>
      <guid isPermaLink="false">2502.09335v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Memristor-Based Meta-Learning for Fast mmWave Beam Prediction in Non-Stationary Environments</title>
      <link>http://arxiv.org/abs/2502.09244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于忆阻器的元学习（M-ML）框架，用于实时预测毫米波通信中的波束成形向量。&lt;h4&gt;背景&lt;/h4&gt;传统的机器学习技术已经在提高毫米波通信的数据传输率和减少延迟方面取得了显著成功。然而，这些方法仍然面临两个主要挑战：一是依赖大规模配对数据进行模型训练与调优；二是基于元学习的波束形成解决方案在有限任务集上容易过拟合。&lt;h4&gt;目的&lt;/h4&gt;为了克服上述问题，本文提出了一个基于忆阻器的元学习框架M-ML来预测毫米波通信中的实时波束。该方法旨在提高模型适应未知环境的能力和泛化性能。&lt;h4&gt;方法&lt;/h4&gt;通过利用存储能力保存关键数据，M-ML框架在训练阶段生成最优初始化参数，在测试阶段适应不同环境时可以提供良好的起点。此外，这种方法能够在不依赖大型数据集的情况下实现高精度预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在新环境中能够达到很高的波束预测准确性，并且增强了模型的泛化能力和适应性。&lt;h4&gt;结论&lt;/h4&gt;基于忆阻器的元学习框架可以有效解决毫米波通信中实时波束成形面临的挑战，其不仅提高了预测精度和环境适应能力，还通过优化参数初始化避免了过拟合问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional machine learning techniques have achieved great success inimproving data-rate performance and reducing latency in millimeter wave(mmWave) communications. However, these methods still face two key challenges:(i) their reliance on large-scale paired data for model training and tuningwhich limits performance gains and makes beam predictions outdated, especiallyin multi-user mmWave systems with large antenna arrays, and (ii) meta-learning(ML)-based beamforming solutions are prone to overfitting when trained on alimited number of tasks. To address these issues, we propose a memristorbasedmeta-learning (M-ML) framework for predicting mmWave beam in real time. TheM-ML framework generates optimal initialization parameters during the trainingphase, providing a strong starting point for adapting to unknown environmentsduring the testing phase. By leveraging memory to store key data, M-ML ensuresthe predicted beamforming vectors are wellsuited to episodically dynamicchannel distributions, even when testing and training environments do notalign. Simulation results show that our approach delivers high predictionaccuracy in new environments, without relying on large datasets. Moreover, MMLenhances the model's generalization ability and adaptability.</description>
      <author>example@mail.com (Yuwen Cao, Wenqin Lu, Tomoaki Ohtsuki, Setareh Maghsudi, Xue-Qin Jiang, Charalampos C. Tsimenidis)</author>
      <guid isPermaLink="false">2502.09244v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2502.09501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于先验约束的关联学习方法，用于解决广义类别发现任务中的问题。这项研究改进了传统的半监督学习方法，并特别关注未标记数据可能来自未知类别的挑战。&lt;h4&gt;背景&lt;/h4&gt;广义类别发现（GCD）的任务是在已知类别标签数据的帮助下对潜在的已知或未知类别的无标签数据进行聚类，区别于传统半监督学习，由于未标注的数据可能是全新的类别而更加具有挑战性。目前的方法倾向于使用自蒸馏来辅助参数化分类器的学习。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入先验约束关联学习方法改进广义类别发现任务中的性能，该方法利用来自已知类别的标记数据提供的独特先验信息对无标签数据进行处理，并结合非参数原型对比增强表示学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于先验的关联学习（Prior-constrained Association Learning）方法，通过将先验完全融入到关联过程中来约束关联结果。利用估计出的语义组与非参数原型对比法相结合以提高表示学习的效果。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的算法在多项广义类别发现基准测试中表现出色，并显著优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;该论文通过引入先验约束并改进了半监督学习框架，展示了一种有效的解决未知类别问题的方法。实验结果验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文针对广义类别发现任务提出了一种基于先验约束的关联学习方法，利用已知类别的标签数据提供独特先验信息来处理未标注的数据，并通过非参数原型对比法增强表示学习效果，从而在多项基准测试中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses generalized category discovery (GCD), the task ofclustering unlabeled data from potentially known or unknown categories with thehelp of labeled instances from each known category. Compared to traditionalsemi-supervised learning, GCD is more challenging because unlabeled data couldbe from novel categories not appearing in labeled data. Currentstate-of-the-art methods typically learn a parametric classifier assisted byself-distillation. While being effective, these methods do not make use ofcross-instance similarity to discover class-specific semantics which areessential for representation learning and category discovery. In this paper, werevisit the association-based paradigm and propose a Prior-constrainedAssociation Learning method to capture and learn the semantic relations withindata. In particular, the labeled data from known categories provides a uniqueprior for the association of unlabeled data. Unlike previous methods that onlyadopts the prior as a pre or post-clustering refinement, we fully incorporatethe prior into the association process, and let it constrain the associationtowards a reliable grouping outcome. The estimated semantic groups are utilizedthrough non-parametric prototypical contrast to enhance the representationlearning. A further combination of both parametric and non-parametricclassification complements each other and leads to a model that outperformsexisting methods by a significant margin. On multiple GCD benchmarks, weperform extensive experiments and validate the effectiveness of our proposedmethod.</description>
      <author>example@mail.com (Menglin Wang, Zhun Zhong, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.09501v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.09254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对图异常检测（GAD）任务的图基础模型AnomalyGFM，该模型支持零样本推理和少量提示调整。通过预训练来对齐数据无关性的正常和异常类原型，并使用节点表示残差来识别不同图形中的异常节点。&lt;h4&gt;背景&lt;/h4&gt;现有的通用图模型在各种图任务中取得了显著成功，但难以泛化到GAD任务，因为这些模型难以学习捕捉不同领域图中固有的罕见、不规则和异构的异常模式的一般性知识。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一挑战，提出了一种专门针对GAD任务的图基础模型AnomalyGFM。&lt;h4&gt;方法&lt;/h4&gt;该模型在预训练阶段使用节点表示残差来对齐数据无关性的正常和异常类原型。它支持零样本推理，并且如果新的图形中有少量标记为正常的节点，则可以进行提示调整以更好地适应。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在11个广泛使用的具有真实异常的GAD数据集上，AnomalyGFM在零样本和少量样本的GAD设置下均显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;AnomalyGFM是一种强大的图基础模型，能够有效地支持各种图形中的异常节点检测任务，并且可以在没有大量训练数据的情况下进行有效的泛化和适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图异常检测（GAD）旨在识别与图中大多数节点不同的异常节点，在最近几年引起了广泛关注。现有的通用图模型在不同图任务中取得了显著成功，但在GAD任务上难以泛化。这种局限性源于它们难以学习捕捉来自不同领域的图形中的固有的罕见、不规则和异构的异常模式的一般性知识。为了解决这一挑战，我们提出了一种专门针对GAD任务的图基础模型AnomalyGFM，该模型支持零样本推理和少量提示调整以在各种图数据集上进行GAD。一个关键见解是，在不同的图形中有效支持零/少量样本GAD需要正常和异常类的数据无关表示。受此启发，AnomalyGFM被预训练为对齐数据无关、可学习的正常和异常类原型与节点表示残差（即，节点与其邻居之间的表示偏差）。这些残留特性本质上将节点信息映射到一个统一的特征空间中，在这个空间中我们可以一致地有效测量来自不同图的节点的异常性。这为学习针对图形不可知、区分性的正常和异常类原型提供了推动力，这种模型可以用于在新图（包括非常大规模图）上实现零样本GAD。如果新的图中有少量标记为正常的节点，则AnomalyGFM还可以进一步支持提示调整以利用这些节点进行更好的适应性改进。综合广泛的11个具有真实异常的GAD数据集上的实验表明，AnomalyGFM在零样本和少量样本设置下均显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph anomaly detection (GAD) aims to identify abnormal nodes that differfrom the majority of the nodes in a graph, which has been attractingsignificant attention in recent years. Existing generalist graph models haveachieved remarkable success in different graph tasks but struggle to generalizeto the GAD task. This limitation arises from their difficulty in learninggeneralized knowledge for capturing the inherently infrequent, irregular andheterogeneous abnormality patterns in graphs from different domains. To addressthis challenge, we propose AnomalyGFM, a GAD-oriented graph foundation modelthat supports zero-shot inference and few-shot prompt tuning for GAD in diversegraph datasets. One key insight is that graph-agnostic representations fornormal and abnormal classes are required to support effective zero/few-shot GADacross different graphs. Motivated by this, AnomalyGFM is pre-trained to aligndata-independent, learnable normal and abnormal class prototypes with noderepresentation residuals (i.e., representation deviation of a node from itsneighbors). The residual features essentially project the node information intoa unified feature space where we can effectively measure the abnormality ofnodes from different graphs in a consistent way. This provides a driving forcefor the learning of graph-agnostic, discriminative prototypes for the normaland abnormal classes, which can be used to enable zero-shot GAD on new graphs,including very large-scale graphs. If there are few-shot labeled normal nodesavailable in the new graphs, AnomalyGFM can further support prompt tuning toleverage these nodes for better adaptation. Comprehensive experiments on 11widely-used GAD datasets with real anomalies, demonstrate that AnomalyGFMsignificantly outperforms state-of-the-art competing methods under both zero-and few-shot GAD settings.</description>
      <author>example@mail.com (Hezhe Qiao, Chaoxi Niu, Ling Chen, Guansong Pang)</author>
      <guid isPermaLink="false">2502.09254v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Topological Interference Management: A Learning-to-Code on Graphs Perspective</title>
      <link>http://arxiv.org/abs/2502.09344v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2305.07186&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习的拓扑干扰管理框架，旨在自动生成适用于无线通信系统的编码方案。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的拓扑干扰管理模式（TIM）通常为特定网络拓扑设计，并依赖专家知识和复杂处理方法，缺乏系统性和自动化手段限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习导向的编码方式，以解决现有TIM编码方案的一般化问题并促进其在无线通信中的应用。&lt;h4&gt;方法&lt;/h4&gt;通过将图神经网络（GNN）与强化学习相结合，创建了一个统一的学习到编码框架（LCG），能够自动生成适合任意网络拓扑结构的编码方案。&lt;h4&gt;主要发现&lt;/h4&gt;该LCG框架不仅能够恢复已知的一对一标量/矢量干扰对齐解决方案，并且能够为多天线情况下的子空间干扰对齐编码方案生成新的解决方案，这些新方案难以通过手动设计获得。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LCG框架能有效自动产生系统性编码方案以解决具有任意网络拓扑的TIM实例问题，并且其学习算法在在线推理时间、泛化性和可转移性方面表现出色，适用于实际部署。&lt;h4&gt;翻译&lt;/h4&gt;拓扑干扰管理（TIM）的发展是近年来网络信息理论发展的主要推动力之一。然而，最先进的TIM编码方案通常为特定网络拓扑设计，严重依赖专家知识和复杂处理手段。缺乏系统化与自动化的解决方案生成方法限制了其在无线通信系统中的广泛应用。为了应对这一挑战，本文首次尝试从新的学习导向编码视角重新审视拓扑干扰对齐（IA）问题。具体而言，我们将一对一和子空间IA条件重铸为向量分配策略，并通过利用图神经网络（GNNs）捕捉拓扑结构以及强化学习（RL）进行IA波束赋形向量分配决策提出了一个统一的学习到编码框架（LCG）。有趣的是，所提出的LCG框架能够恢复已知的一对一标量/矢量IA解决方案，适用于更广泛的网络拓扑，并且更为显著地发现了一种新的多天线情况下的子空间IA编码方案，这些新方案难以通过手动设计获得。大量的实验表明，LCG框架是一种有效的方式以自动产生系统性编码方案来应对具有任意网络拓扑的TIM实例问题，并且其背后的算法在在线推理时间方面高效，同时具备优秀的泛化性和可转移性，适用于实际部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advance of topological interference management (TIM) has been one of thedriving forces of recent developments in network information theory. However,state-of-the-art coding schemes for TIM are usually handcrafted for specificfamilies of network topologies, relying critically on experts' domain knowledgeand sophisticated treatments. The lack of systematic and automatic generationof solutions inevitably restricts their potential wider applications towireless communication systems, due to the limited generalizability of codingschemes to wider network configurations. To address such an issue, this workmakes the first attempt to advocate revisiting topological interferencealignment (IA) from a novel learning-to-code perspective. Specifically, werecast the one-to-one and subspace IA conditions as vector assignment policiesand propose a unifying learning-to-code on graphs (LCG) framework by leveraginggraph neural networks (GNNs) for capturing topological structures andreinforcement learning (RL) for decision-making of IA beamforming vectorassignment. Interestingly, the proposed LCG framework is capable of recoveringknown one-to-one scalar/vector IA solutions for a significantly wider range ofnetwork topologies, and more remarkably of discovering new subspace IA codingschemes for multiple-antenna cases that are challenging to be handcrafted. Theextensive experiments demonstrate that the LCG framework is an effective way toautomatically produce systematic coding solutions to the TIM instances witharbitrary network topologies, and at the same time, the underlying learningalgorithm is efficient with respect to online inference time and possessesexcellent generalizability and transferability for practical deployment.</description>
      <author>example@mail.com (Zhiwei Shan, Xinping Yi, Han Yu, Chung-Shou Liao, Shi Jin)</author>
      <guid isPermaLink="false">2502.09344v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Hybrid Model for Few-Shot Text Classification Using Transfer and Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.09086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于迁移学习和元学习的少量样本文本分类模型，通过预训练模型的知识转移和元学习机制优化了模型在小样本任务中的快速适应性。实验结果表明，在少样本和中等样本条件下，该模型显著优于传统机器学习和深度学习方法。&lt;h4&gt;背景&lt;/h4&gt;随着自然语言处理技术的发展，文本分类任务被广泛应用于多个领域。然而，获取标注数据通常是昂贵且困难的，尤其是在少量样本场景下。&lt;h4&gt;目的&lt;/h4&gt;为了解决在少量样本情况下获得标注数据的问题，提出了一种基于迁移学习和元学习的文本分类模型。&lt;h4&gt;方法&lt;/h4&gt;该模型利用预训练模型的知识进行迁移，并通过元学习机制优化模型在小样本任务中的快速适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在少样本和中等样本条件下，基于迁移学习和元学习的模型显著优于传统机器学习和深度学习方法。此外，消融试验进一步分析了各组件对模型性能的贡献，并确认了迁移学习和元学习在提高模型准确性中的关键作用。&lt;h4&gt;结论&lt;/h4&gt;本文讨论了未来的研究方向，并展望了该方法在未来实际应用中的潜力&lt;h4&gt;翻译&lt;/h4&gt;随着自然语言处理技术的发展，文本分类任务被广泛应用于多个领域。然而，在获取标注数据方面通常是昂贵且困难的，尤其是在少量样本场景下。为了解决这一问题，本文提出了一种基于迁移学习和元学习的文本分类模型，该模型利用预训练模型的知识进行知识转移，并通过元学习机制来优化模型在小样本任务中的快速适应性。通过一系列对比实验和消融试验验证了所提方法的有效性。实验结果显示，在少样本与中等样本条件下，基于迁移学习和元学习的模型显著优于传统机器学习和深度学习的方法。此外，消融试验进一步分析了各个组件对模型性能的影响，并确认了迁移学习和元学习在提高模型准确性方面的重要作用。最后，本文讨论了未来的研究方向并展望了该方法在未来实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the continuous development of natural language processing (NLP)technology, text classification tasks have been widely used in multipleapplication fields. However, obtaining labeled data is often expensive anddifficult, especially in few-shot learning scenarios. To solve this problem,this paper proposes a few-shot text classification model based on transferlearning and meta-learning. The model uses the knowledge of the pre-trainedmodel for transfer and optimizes the model's rapid adaptability in few-sampletasks through a meta-learning mechanism. Through a series of comparativeexperiments and ablation experiments, we verified the effectiveness of theproposed method. The experimental results show that under the conditions of fewsamples and medium samples, the model based on transfer learning andmeta-learning significantly outperforms traditional machine learning and deeplearning methods. In addition, ablation experiments further analyzed thecontribution of each component to the model performance and confirmed the keyrole of transfer learning and meta-learning in improving model accuracy.Finally, this paper discusses future research directions and looks forward tothe potential of this method in practical applications.</description>
      <author>example@mail.com (Jia Gao, Shuangquan Lyu, Guiran Liu, Binrong Zhu, Hongye Zheng, Xiaoxuan Liao)</author>
      <guid isPermaLink="false">2502.09086v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Bilevel gradient methods and Morse parametric qualification</title>
      <link>http://arxiv.org/abs/2502.09074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Morse参数化条件，这种新条件扩展了均匀强凸性的概念，并展示了半代数函数在分段意义上的这一性质如何使双层问题简化为混合整数规划问题。&lt;h4&gt;背景&lt;/h4&gt;Morse参数化条件是一个新的数学条件，它推广了均匀强凸性。研究表明，大多数的半代数函数在这种条件下是分段意义下的Morse参数化的。&lt;h4&gt;目的&lt;/h4&gt;研究在这一新框架内双层梯度算法的不同策略及其特性。&lt;h4&gt;方法&lt;/h4&gt;两种策略：一种是一步多步骤策略（先处理一系列下层问题然后进行一次上层问题的处理），另一种是受元学习应用启发的可微编程策略，该策略优化了双层问题的平滑近似。&lt;h4&gt;主要发现&lt;/h4&gt;单步多步法显示为具有丰富特性的有偏梯度方法；而可微编程法虽然不如前者稳定但因其简洁性和易于实现获得了研究者的青睐。&lt;h4&gt;结论&lt;/h4&gt;新的Morse参数化条件提供了一种理解双层优化问题的新视角，其中的两种策略在处理这些问题时各有利弊。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Morse parametric qualification condition is a new condition that generalizesuniform strong convexity. Generic semi-algebraic functions are Morse parametricin a piecewise sense, implying that generic semi-algebraic bilevel problemsreduce to mixed-integer programming. In this new framework, we study bilevelgradient algorithms with two strategies: the single-step multi-step strategy,which involves a sequence of steps on the lower-level problems followed by onestep on the upper-level problem, and a differentiable programming strategy thatoptimizes a smooth approximation of the bilevel problem. While the first isshown to be a biased gradient method on the problem with rich properties, thesecond, inspired by meta-learning applications, is less stable but offerssimplicity and ease of implementation.</description>
      <author>example@mail.com (Jérôme Bolte, Quoc-Tung Le, Edouard Pauwels, Samuel Vaiter)</author>
      <guid isPermaLink="false">2502.09074v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>OpenBench: A New Benchmark and Baseline for Semantic Navigation in Smart Logistics</title>
      <link>http://arxiv.org/abs/2502.09238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个结合基础模型和经典算法的开放式户外语义导航系统（OPEN），用于提高智能物流中的最后一公里配送效率。&lt;h4&gt;背景&lt;/h4&gt;随着对高效最后一公里配送的需求增加，自主机器人在提升运营效率和降低成本方面的作用日益显著。然而，传统的依赖高精度地图的导航方法资源密集型，而基于学习的方法通常难以实现在现实场景中的泛化。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，该研究旨在开发一种能够结合基础模型和经典算法进行规模化户外导航的系统。&lt;h4&gt;方法&lt;/h4&gt;OPEN系统利用现成的OpenStreetMap（OSM）提供灵活的地图表示，并使用大型语言模型理解交付指令以及视觉-语言模型实现全球定位、地图更新和门牌号识别。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，该系统在模拟和现实环境中的导航效率和可靠性方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;为了进一步促进研究，研究人员公开了代码和基准测试数据集。&lt;h4&gt;翻译&lt;/h4&gt;随着对智能物流中高效最后一公里配送的需求增加，自主机器人在提升运营效率和降低成本方面的作用日益显著。传统的依赖高精度地图的导航方法资源密集型，而基于学习的方法通常难以实现在现实场景中的泛化。为了解决这些挑战，该研究开发了一种结合基础模型和经典算法进行规模化户外导航的系统（OPEN）。实验结果表明，在模拟和真实环境中，该系统的导航效率和可靠性均表现出色。为了进一步促进研究，代码和基准测试数据集已被公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing demand for efficient last-mile delivery in smart logisticsunderscores the role of autonomous robots in enhancing operational efficiencyand reducing costs. Traditional navigation methods, which depend onhigh-precision maps, are resource-intensive, while learning-based approachesoften struggle with generalization in real-world scenarios. To address thesechallenges, this work proposes the Openstreetmap-enhanced oPen-air sEmanticNavigation (OPEN) system that combines foundation models with classicalgorithms for scalable outdoor navigation. The system uses off-the-shelfOpenStreetMap (OSM) for flexible map representation, thereby eliminating theneed for extensive pre-mapping efforts. It also employs Large Language Models(LLMs) to comprehend delivery instructions and Vision-Language Models (VLMs)for global localization, map updates, and house number recognition. Tocompensate the limitations of existing benchmarks that are inadequate forassessing last-mile delivery, this work introduces a new benchmark specificallydesigned for outdoor navigation in residential areas, reflecting the real-worldchallenges faced by autonomous delivery systems. Extensive experiments insimulated and real-world environments demonstrate the proposed system'sefficacy in enhancing navigation efficiency and reliability. To facilitatefurther research, our code and benchmark are publicly available.</description>
      <author>example@mail.com (Junhui Wang, Dongjie Huo, Zehui Xu, Yongliang Shi, Yimin Yan, Yuanxin Wang, Chao Gao, Yan Qiao, Guyue Zhou)</author>
      <guid isPermaLink="false">2502.09238v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>3D-Grounded Vision-Language Framework for Robotic Task Planning: Automated Prompt Synthesis and Supervised Reasoning</title>
      <link>http://arxiv.org/abs/2502.08903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于改进视觉-语言模型在3D场景定位和机器人任务执行中的表现。&lt;h4&gt;背景&lt;/h4&gt;当前多模态大型语言模型虽然在场景理解和感知方面取得显著成果，但在精细的机器人操作中受限于低识别精度、效率低下、转移性差和可靠性不足等挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新颖框架来增强视觉-语言模型处理3D场景的能力，并解决其在复杂环境下的表现问题。&lt;h4&gt;方法&lt;/h4&gt;该框架包括一个2D提示合成模块，用于将图像映射到点云并从中提取精确的3D空间信息；同时采用小型语言模型（SLM）监督VLM输出以减少幻觉现象，并确保生成可靠、可执行的任务控制代码。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在任务成功率为96.0%时超越了其他方法。消融研究表明，移除2D提示合成模块或监督输出模块会导致成功率下降67%，这证明了所提框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的框架通过增强3D场景理解、改进任务规划和提升机器人任务执行的可靠性，有效提高了视觉-语言模型在复杂环境中的性能。此外，该方法还消除了对新环境中重新训练的需求，提升了成本效率及运行稳定性。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language models (VLMs) have achieved remarkable success in scene understanding and perception tasks, but lack robust 3D scene localization capabilities. To address this issue, a novel framework integrating a 2D prompt synthesis module and a small language model (SLM) is proposed, enabling autonomous extraction of precise 3D spatial information and ensuring reliable robotic control code generation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) have achieved remarkable success in sceneunderstanding and perception tasks, enabling robots to plan and execute actionsadaptively in dynamic environments. However, most multimodal large languagemodels lack robust 3D scene localization capabilities, limiting theireffectiveness in fine-grained robotic operations. Additionally, challenges suchas low recognition accuracy, inefficiency, poor transferability, andreliability hinder their use in precision tasks. To address these limitations,we propose a novel framework that integrates a 2D prompt synthesis module bymapping 2D images to point clouds, and incorporates a small language model(SLM) for supervising VLM outputs. The 2D prompt synthesis module enables VLMs,trained on 2D images and text, to autonomously extract precise 3D spatialinformation without manual intervention, significantly enhancing 3D sceneunderstanding. Meanwhile, the SLM supervises VLM outputs, mitigatinghallucinations and ensuring reliable, executable robotic control codegeneration. Our framework eliminates the need for retraining in newenvironments, thereby improving cost efficiency and operational robustness.Experimental results that the proposed framework achieved a 96.0\% Task SuccessRate (TSR), outperforming other methods. Ablation studies demonstrated thecritical role of both the 2D prompt synthesis module and the output supervisionmodule (which, when removed, caused a 67\% TSR drop). These findings validatethe framework's effectiveness in improving 3D recognition, task planning, androbotic task execution.</description>
      <author>example@mail.com (Guoqin Tang, Qingxuan Jia, Zeyuan Huang, Gang Chen, Ning Ji, Zhipeng Yao)</author>
      <guid isPermaLink="false">2502.08903v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Low-Complexity Plug-and-Play Deep Learning Model for Massive MIMO Precoding Across Sites</title>
      <link>http://arxiv.org/abs/2502.08757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This preprint comprises 6 pages and features 2 figures. It has been  accepted to the IEEE International Conference on Machine Learning and  Computer Networking (ICMLCN) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;毫米波大规模多输入多输出（mMIMO）技术通过提升频谱效率和网络容量彻底改变了无线通信。本文提出了一种基于深度学习的mMIMO预编码方案，以解决现有方法如加权最小均方误差（WMMSE）所面临的复杂性挑战，并利用元学习领域的泛化能力和教师-学生架构来提高在各种通信环境中的适应能力。&lt;h4&gt;背景&lt;/h4&gt;毫米波大规模多输入多输出技术极大地提高了频谱效率和网络容量，但现有的解决方案由于其复杂的计算需求，在实际应用中存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于深度学习的mMIMO预编码方案，以减少现有方法的复杂性，并在不同的通信环境中实现良好的性能泛化能力。&lt;h4&gt;方法&lt;/h4&gt;利用元学习领域的泛化能力和教师-学生架构来开发新型预编码器。模型通过避免矩阵求逆和使用更简单的神经网络结构，在未见过的实际地点部署时能够保持低计算复杂度，同时保证较高的总速率性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法能够在保持高效计算效率的同时提供高总数据率性能，并在不熟悉的环境中展示出强大的泛化能力。此外，通过微调，所提出的模型在所有测试站点和信号噪声比（SNR）条件下均优于WMMSE方法，并且复杂度至少减少了73倍。&lt;h4&gt;结论&lt;/h4&gt;基于深度学习的mMIMO预编码器提供了一种有效的方法来解决现有的计算复杂性问题，同时保持高效的总数据率性能。这表明在不同的通信环境下，该模型具有良好的适应性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Massive multiple-input multiple-output (mMIMO) technology has transformedwireless communication by enhancing spectral efficiency and network capacity.This paper proposes a novel deep learning-based mMIMO precoder to tackle thecomplexity challenges of existing approaches, such as weighted minimum meansquare error (WMMSE), while leveraging meta-learning domain generalization anda teacher-student architecture to improve generalization across diversecommunication environments. When deployed to a previously unseen site, theproposed model achieves excellent sum-rate performance while maintaining lowcomputational complexity by avoiding matrix inversions and by using a simplerneural network structure. The model is trained and tested on a customray-tracing dataset composed of several base station locations. Theexperimental results indicate that our method effectively balancescomputational efficiency with high sum-rate performance while showcasing stronggeneralization performance in unseen environments. Furthermore, withfine-tuning, the proposed model outperforms WMMSE across all tested sites andSNR conditions while reducing complexity by at least 73$\times$.</description>
      <author>example@mail.com (Ali Hasanzadeh Karkan, Ahmed Ibrahim, Jean-François Frigon, François Leduc-Primeau)</author>
      <guid isPermaLink="false">2502.08757v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Visual Graph Question Answering with ASP and LLMs for Language Parsing</title>
      <link>http://arxiv.org/abs/2502.09211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings ICLP 2024, arXiv:2502.08453. This work was partially  funded from the Bosch Center for AI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了如何将回答集编程（ASP）与视觉和自然语言处理模块结合，以解决图像中图结构的视觉问答(VQA)问题。&lt;h4&gt;背景&lt;/h4&gt;VQA是需要处理多模态输入的挑战性问题。ASP在为模块化VQA架构增加可解释性和透明度方面显示出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的方法来集成回答集编程与视觉和自然语言处理模块，以解决基于图像图结构的新颖且复杂的VQA变体问题。&lt;h4&gt;方法&lt;/h4&gt;提出的解决方案采用了一种模块化神经符号方法，结合光学图形识别进行图形解析、预训练的OCR神经网络进行标签解析、大型语言模型(LLM)用于语言处理以及ASP用于推理。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法作为第一个基准，在数据集上的整体平均准确率为73%。此外，评估证明了模块化神经符号系统（尤其是不涉及进一步训练和逻辑编程）解决复杂VQA任务的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过提出的方法，展示了在图结构图像中的VQA问题上采用模块化神经符号方法的有效性，并为进一步的研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;视觉问答(VQA)是一个需要处理多模态输入的挑战性问题。回答集编程(ASP)在为模块化的VQA架构增加可解释性和透明度方面显示出巨大潜力。本文提出了一种结合光学图形识别、预训练OCR神经网络、大型语言模型(LLM)和ASP进行推理的新方法，以解决图像中图结构的独特且复杂的VQA变体问题，并在一个新数据集上达到了73%的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.4204/EPTCS.416.2&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Question Answering (VQA) is a challenging problem that requires toprocess multimodal input. Answer-Set Programming (ASP) has shown greatpotential in this regard to add interpretability and explainability to modularVQA architectures. In this work, we address the problem of how to integrate ASPwith modules for vision and natural language processing to solve a new anddemanding VQA variant that is concerned with images of graphs (not graphs insymbolic form). Images containing graph-based structures are an ubiquitous andpopular form of visualisation. Here, we deal with the particular problem ofgraphs inspired by transit networks, and we introduce a novel dataset thatamends an existing one by adding images of graphs that resemble metro lines.Our modular neuro-symbolic approach combines optical graph recognition forgraph parsing, a pretrained optical character recognition neural network forparsing labels, Large Language Models (LLMs) for language processing, and ASPfor reasoning. This method serves as a first baseline and achieves an overallaverage accuracy of 73% on the dataset. Our evaluation provides furtherevidence of the potential of modular neuro-symbolic systems, in particular withpretrained models that do not involve any further training and logicprogramming for reasoning, to solve complex VQA tasks.</description>
      <author>example@mail.com (Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch)</author>
      <guid isPermaLink="false">2502.09211v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation</title>
      <link>http://arxiv.org/abs/2502.09268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;随着嵌入式人工智能的快速发展，通用机器人决策中的视觉-语言-行动（VLA）模型取得了显著进展。然而，大多数现有的VLAs未能考虑部署过程中不可避免遇到的外部干扰，导致性能下降。&lt;h4&gt;背景&lt;/h4&gt;当前VLA模型在面对实际应用场景时难以处理未知或未预见的状态信息变化，影响了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于内部模型控制（IMC）原则的新闭环视觉-语言-行动方法GEVRM，以增强机器人视觉操作的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;在GEVRM中引入文本引导视频生成模型，用于生成未来视觉规划目标；同时通过原型对比学习优化模拟响应，使模型能够隐式区分外部环境中的干扰因素。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的GEVRM在标准和受扰的CALVIN基准测试上均达到最新技术水平，并且在现实世界的机器人任务中显示出显著改进。&lt;h4&gt;结论&lt;/h4&gt;通过整合IMC原则，新方法能够有效提高VLA模型面对未知状态时的表现，进而提升机器人的适应性和执行能力。&lt;h4&gt;翻译&lt;/h4&gt;随着嵌入式人工智能的发展，视觉-语言-行动模型（VLA）在通用机器人决策方面取得了显著进步。然而，大多数现有的VLAs未能处理部署过程中遇到的外部干扰，导致性能下降。我们提出了一种新的闭环VLA方法GEVRM，该方法整合了内部模型控制原则，以增强机器人视觉操作的鲁棒性。此外，通过文本引导视频生成和原型对比学习优化模拟响应，使模型能够区分并适应外部环境中的扰动。实验表明，在标准和受扰CALVIN基准测试中，以及在现实世界任务中，GEVRM均表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of embodied artificial intelligence, significantprogress has been made in vision-language-action (VLA) models for general robotdecision-making. However, the majority of existing VLAs fail to account for theinevitable external perturbations encountered during deployment. Theseperturbations introduce unforeseen state information to the VLA, resulting ininaccurate actions and consequently, a significant decline in generalizationperformance. The classic internal model control (IMC) principle demonstratesthat a closed-loop system with an internal model that includes external inputsignals can accurately track the reference input and effectively offset thedisturbance. We propose a novel closed-loop VLA method GEVRM that integratesthe IMC principle to enhance the robustness of robot visual manipulation. Thetext-guided video generation model in GEVRM can generate highly expressivefuture visual planning goals. Simultaneously, we evaluate perturbations bysimulating responses, which are called internal embeddings and optimizedthrough prototype contrastive learning. This allows the model to implicitlyinfer and distinguish perturbations from the external environment. The proposedGEVRM achieves state-of-the-art performance on both standard and perturbedCALVIN benchmarks and shows significant improvements in realistic robot tasks.</description>
      <author>example@mail.com (Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang)</author>
      <guid isPermaLink="false">2502.09268v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Inverse-Mapping Model for a Flapping Robotic Wing</title>
      <link>http://arxiv.org/abs/2502.09378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. 10 Pages 5 figures + 2 figures in appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种针对拍翅机器人系统的机器学习解决方案，旨在解决复杂的输入输出映射问题。&lt;h4&gt;背景&lt;/h4&gt;在复杂系统中（例如拍翅机器人），将输入动作（翅膀的运动）与输出结果（空气动力学力）进行准确映射非常困难，并且为了实时控制而逆向求解该映射是计算上不可行的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种机器学习模型，用于解决拍翅机器人系统中的复杂动力学问题，通过从实验数据中学习输入翅膀运动以生成期望的空气动力学力输出。&lt;h4&gt;方法&lt;/h4&gt;使用了为时间序列数据定制的序列到序列（Sequence-to-Sequence）模型，并引入了一种新颖的自适应频谱层来实现频率领域的表示学习。同时开发了一个能够同时测量翅膀3D运动和空气动力学力的拍翅系统，用于训练机器学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法在测试数据集上的中间损失上比最先进的基于变压器（Transformer）的模型提高了11%，并且推理时间更短，使得其实时控制成为可能。&lt;h4&gt;结论&lt;/h4&gt;这种开源的数据和框架有望改善由复杂动力学系统所支配的各种设备中的建模与实时控制问题，从仿生机器人到生物医学装置。&lt;h4&gt;翻译&lt;/h4&gt;在控制系统中，通过调整输入来调控系统的动态行为以达到预期的结果。然而，在复杂的拍翅机器人等涉及精细流体运动的系统中，将输入动作映射到输出结果非常困难，并且逆向求解这种映射用于实时控制是计算上不可行的。本文提出了一种基于机器学习的方法，通过实验数据训练模型来解决拍翅系统中的逆问题。该方法在测试集上的性能优于先进的Transformer模型，同时具备更短的推理时间，使得其实时应用成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In systems control, the dynamics of a system are governed by modulating itsinputs to achieve a desired outcome. For example, to control the thrust of aquad-copter propeller the controller modulates its rotation rate, relying on astraightforward mapping between the input rotation rate and the resultingthrust. This mapping can be inverted to determine the rotation rate needed togenerate a desired thrust. However, in complex systems, such as flapping-wingrobots where intricate fluid motions are involved, mapping inputs (wingkinematics) to outcomes (aerodynamic forces) is nontrivial and inverting thismapping for real-time control is computationally impractical. Here, we report amachine-learning solution for the inverse mapping of a flapping-wing systembased on data from an experimental system we have developed. Our model learnsthe input wing motion required to generate a desired aerodynamic force outcome.We used a sequence-to-sequence model tailored for time-series data andaugmented it with a novel adaptive-spectrum layer that implementsrepresentation learning in the frequency domain. To train our model, wedeveloped a flapping wing system that simultaneously measures the wing'saerodynamic force and its 3D motion using high-speed cameras. We demonstratethe performance of our system on an additional open-source dataset of aflapping wing in a different flow regime. Results show superior performancecompared with more complex state-of-the-art transformer-based models, with 11%improvement on the test datasets median loss. Moreover, our model showssuperior inference time, making it practical for onboard robotic control. Ouropen-source data and framework may improve modeling and real-time control ofsystems governed by complex dynamics, from biomimetic robots to biomedicaldevices.</description>
      <author>example@mail.com (Hadar Sharvit, Raz Karl, Tsevi Beatus)</author>
      <guid isPermaLink="false">2502.09378v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>CoL3D: Collaborative Learning of Single-view Depth and Camera Intrinsics for Metric 3D Shape Recovery</title>
      <link>http://arxiv.org/abs/2502.08902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;从单张图像恢复三维形状的度量在机器人和具身智能应用中特别相关，准确的空间理解对于导航和与环境互动至关重要。通常，主流方法通过单目深度估计实现这一目标，但没有相机内参的情况下无法仅凭深度信息恢复3D度量形状。&lt;h4&gt;背景&lt;/h4&gt;从单张图像恢复三维形状的度量在机器人和具身智能应用中特别相关，准确的空间理解对于导航和与环境互动至关重要。然而，没有相机内参的情况下无法仅凭深度信息恢复3D度量形状。&lt;h4&gt;目的&lt;/h4&gt;提出一种协作学习框架（CoL3D），用于同时估计单张图像中的深度和相机内参，以从单张图像中学习三维形状的度量。&lt;h4&gt;方法&lt;/h4&gt;该研究采用统一网络，并在三个层次上进行协同优化：深度、相机内参以及点云。对于相机内参估计，设计了一种规范入射场机制作为先验知识，使模型能够学习残差入射场以增强校准能力。同时，在点云空间中引入形状相似性测量损失，以提高机器人应用所需的3D形状质量。&lt;h4&gt;主要发现&lt;/h4&gt;深度信息和相机内参之间存在相互关系，通过协同优化可以更准确地估计深度并计算出度量三维形状所必需的相机参数。&lt;h4&gt;结论&lt;/h4&gt;CoL3D框架在多个室内外基准数据集上表现优异，在单个数据集中进行训练和测试时，无论是深度估计还是相机校准性能都显著优于现有方法。该研究为机器人感知能力提供了高质量的3D形状信息。&lt;h4&gt;翻译&lt;/h4&gt;从单张图像恢复三维形状度量对机器人技术及具身智能应用尤为重要，准确的空间理解对于导航与环境互动至关重要。通常，主流方法通过单目深度估计实现这一目标，但没有相机内参的情况下仅凭深度无法恢复3D度量形状。研究证明了深度信息作为三维先验约束的作用，并揭示了其与相机参数之间的相互关系。基于此，提出了一种协同学习框架（CoL3D），用于同时估计单张图像中的深度和相机内参，以从单张图像中获取3D形状的度量。该方法采用了统一网络，并在三个层次上进行优化：深度、相机内参及点云。此外，在点云空间引入了形状相似性测量损失来提升三维形状质量。实验结果表明，CoL3D在多个室内外基准数据集中均表现出色，无论是在单张图像的深度估计还是相机校准性能方面都远超现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering the metric 3D shape from a single image is particularly relevantfor robotics and embodied intelligence applications, where accurate spatialunderstanding is crucial for navigation and interaction with environments.Usually, the mainstream approaches achieve it through monocular depthestimation. However, without camera intrinsics, the 3D metric shape can not berecovered from depth alone. In this study, we theoretically demonstrate thatdepth serves as a 3D prior constraint for estimating camera intrinsics anduncover the reciprocal relations between these two elements. Motivated by this,we propose a collaborative learning framework for jointly estimating depth andcamera intrinsics, named CoL3D, to learn metric 3D shapes from single images.Specifically, CoL3D adopts a unified network and performs collaborativeoptimization at three levels: depth, camera intrinsics, and 3D point clouds.For camera intrinsics, we design a canonical incidence field mechanism as aprior that enables the model to learn the residual incident field for enhancedcalibration. Additionally, we incorporate a shape similarity measurement lossin the point cloud space, which improves the quality of 3D shapes essential forrobotic applications. As a result, when training and testing on a singledataset with in-domain settings, CoL3D delivers outstanding performance in bothdepth estimation and camera calibration across several indoor and outdoorbenchmark datasets, which leads to remarkable 3D shape quality for theperception capabilities of robots.</description>
      <author>example@mail.com (Chenghao Zhang, Lubin Fan, Shen Cao, Bojian Wu, Jieping Ye)</author>
      <guid isPermaLink="false">2502.08902v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>If Multi-Agent Debate is the Answer, What is the Question?</title>
      <link>http://arxiv.org/abs/2502.08788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This position paper takes a critical view of the status quo of MAD  research, and outline multiple potential directions to improve MAD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多智能体辩论（MAD）作为一种通过在推理过程中让多个代理进行迭代讨论来提高大型语言模型（LLMs）事实准确性和推理质量的方法，已经显示出潜力。然而，当前的MAD研究存在评估实践中的关键不足。&lt;h4&gt;背景&lt;/h4&gt;现有的MAD研究受限于有限的数据集重叠和不一致的基准测试，这引发了对其泛化能力的重大担忧。&lt;h4&gt;目的&lt;/h4&gt;本文系统地评估了五种代表性的MAD方法在九个基准上使用四个基础模型的表现。&lt;h4&gt;方法&lt;/h4&gt;采用四种基础模型对五个具有代表性多代理辩论（MAD）的方法进行了全面的性能评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，尽管消耗额外的推理时间计算量，但MAD方法未能可靠地超越简单的单代理基线如链式思维和自洽性。此外，作者还发现了模态异质性的显著影响，并提出了Heter-MAD框架以增强当前MAD框架的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究指出了多智能体辩论在提高大型语言模型性能方面的局限性和改进方向，旨在激发这一领域更广泛的对话与未来工作。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文描述了多代理辩论（MAD）技术的现状、评估方法及其发现和建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent debate (MAD) has emerged as a promising approach to enhance thefactual accuracy and reasoning quality of large language models (LLMs) byengaging multiple agents in iterative discussions during inference. Despite itspotential, we argue that current MAD research suffers from criticalshortcomings in evaluation practices, including limited dataset overlap andinconsistent baselines, raising significant concerns about generalizability.Correspondingly, this paper presents a systematic evaluation of fiverepresentative MAD methods across nine benchmarks using four foundationalmodels. Surprisingly, our findings reveal that MAD methods fail to reliablyoutperform simple single-agent baselines such as Chain-of-Thought andSelf-Consistency, even when consuming additional inference-time computation.From our analysis, we found that model heterogeneity can significantly improveMAD frameworks. We propose Heter-MAD enabling a single LLM agent to access theoutput from heterogeneous foundation models, which boosts the performance ofcurrent MAD frameworks. Finally, we outline potential directions for advancingMAD, aiming to spark a broader conversation and inspire future work in thisarea.</description>
      <author>example@mail.com (Hangfan Zhang, Zhiyao Cui, Xinrun Wang, Qiaosheng Zhang, Zhen Wang, Dinghao Wu, Shuyue Hu)</author>
      <guid isPermaLink="false">2502.08788v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia</title>
      <link>http://arxiv.org/abs/2502.09173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 Workshop on Large Language Models and Generative AI for  Health&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种针对认知障碍患者家庭活动数据的时间序列表征学习框架，通过将时间序列活动转化为文本序列并利用PageRank向量进行低秩表示来揭示关键行为模式。&lt;h4&gt;背景&lt;/h4&gt;远程医疗监测中，从高频数据中提取重要的病人行为模式是至关重要的。本研究关注于阿尔茨海默病患者的家庭活动数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督学习的两阶段方法，用以挖掘认知障碍患者的低秩结构和关键行为特征。&lt;h4&gt;方法&lt;/h4&gt;第一阶段将时间序列活动转化为文本序列，并使用预训练的语言模型进行编码；第二阶段采用基于PageRank的方法生成向量表示，捕捉潜在状态转换，提高数据可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了所提框架在支持认知状态预测、个性化护理干预和大规模健康监测方面的潜力。这种低秩表示不仅增强了模型的可解释性，还促进了聚类分析和过渡分析，揭示了与临床指标如MMSE（简易精神状态检查）和ADAS-COG评分相关的关键行为模式。&lt;h4&gt;结论&lt;/h4&gt;该研究提供的自监督学习框架能够有效地从家庭活动数据中提取关键信息，为远程医疗监测提供了有价值的见解和支持。&lt;h4&gt;翻译&lt;/h4&gt;在远程医疗服务监控领域，时间序列表示的学习能够揭示来自高频数据中的重要患者行为模式。这项研究分析了患有痴呆症的个体的家庭生活活动数据，并提出了一种两阶段自监督学习方法，旨在揭露低秩结构。第一阶段将时间序列活动转变为文本序列，这些序列由预训练的语言模型编码，提供了一个基于PageRank的方法生成的高度丰富的高维潜在状态空间。这种PageRank向量捕捉到潜在的状态转换，有效地压缩了复杂的行为数据，使之更简明易懂。该低秩表示不仅增强了模型的可解释性，并且有助于聚类和过渡分析，揭示与MMSE（简易精神状况检查）及ADAS-COG评分等临床指标密切相关的关键行为模式。我们的发现展示了这种框架在支持认知状态预测、个性化护理干预以及大规模健康监控方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In remote healthcare monitoring, time series representation learning revealscritical patient behavior patterns from high-frequency data. This studyanalyzes home activity data from individuals living with dementia by proposinga two-stage, self-supervised learning approach tailored to uncover low-rankstructures. The first stage converts time-series activities into text sequencesencoded by a pre-trained language model, providing a rich, high-dimensionallatent state space using a PageRank-based method. This PageRank vector captureslatent state transitions, effectively compressing complex behaviour data into asuccinct form that enhances interpretability. This low-rank representation notonly enhances model interpretability but also facilitates clustering andtransition analysis, revealing key behavioral patterns correlated withclinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate theframework's potential in supporting cognitive status prediction, personalizedcare interventions, and large-scale health monitoring.</description>
      <author>example@mail.com (Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott)</author>
      <guid isPermaLink="false">2502.09173v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>$\mathsf{CSMAE~}$:~Cataract Surgical Masked Autoencoder (MAE) based Pre-training</title>
      <link>http://arxiv.org/abs/2502.08822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, Accepted to IEEE International Symposium on Biomedical  Imaging (ISBI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Masked Autoencoder (MAE)的预训练方法CSMAE，用于白内障手术视频分析。这种方法通过考虑空间和时间的重要性来选择掩码令牌而非随机选择，并使用大量白内障手术视频数据集提高了模型的学习效率。&lt;h4&gt;背景&lt;/h4&gt;自动分析外科手术视频对于提高外科培训、工作流程优化及术后评估至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门用于白内障手术视频分析的预训练方法，以改善模型在低数据环境下的学习能力和鲁棒性，并为下游任务提供强大的基础。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于Masked Autoencoder (MAE)的新颖预训练策略CSMAE，该策略根据令牌的空间和时间重要性来选择掩码。利用大量的白内障手术视频数据集进行模型训练，并通过微调适应特定的下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;在两个不同数据集（D99 和 Cataract-101）上的步骤识别任务测试中，该方法超越了当前最先进的自监督预训练和适配器基转移学习方法。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了MAE基础预训练在手术视频分析领域的潜力，并为未来的研究设定了新的标准。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated analysis of surgical videos is crucial for improving surgicaltraining, workflow optimization, and postoperative assessment. We introduce aCSMAE, Masked Autoencoder (MAE)-based pretraining approach, specificallydeveloped for Cataract Surgery video analysis, where instead of randomlyselecting tokens for masking, they are selected based on the spatiotemporalimportance of the token. We created a large dataset of cataract surgery videosto improve the model's learning efficiency and expand its robustness inlow-data regimes. Our pre-trained model can be easily adapted for specificdownstream tasks via fine-tuning, serving as a robust backbone for furtheranalysis. Through rigorous testing on a downstream step-recognition task on twoCataract Surgery video datasets, D99 and Cataract-101, our approach surpassescurrent state-of-the-art self-supervised pretraining and adapter-based transferlearning methods by a significant margin. This advancement not onlydemonstrates the potential of our MAE-based pretraining in the field ofsurgical video analysis but also sets a new benchmark for future research.</description>
      <author>example@mail.com (Nisarg A. Shah, Wele Gedara Chaminda Bandara, Shameema Skider, S. Swaroop Vedula, Vishal M. Patel)</author>
      <guid isPermaLink="false">2502.08822v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound</title>
      <link>http://arxiv.org/abs/2502.08774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了如何利用测试时间自适应(TTA)技术来改进胎儿大脑亚皮层区域自动分割的准确性，特别关注在不同领域偏移条件下的模型性能。&lt;h4&gt;背景&lt;/h4&gt;手动标注胎儿超声图像中的亚皮层脑区是一个挑战性问题。虽然基于深度学习的方法可以实现自动化分割，但在面对新的数据集时（特别是自由手操作的超声图像），预训练模型的表现通常会下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合正常解剖图谱作为先验知识的新TTA方法，以提高胎儿大脑亚皮层区域自动分割在不同领域偏移下的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用测试时间自适应技术来应对真实和模拟的领域偏移。2. 提出了一种新的TTA方法，该方法通过整合正常解剖图谱作为先验知识，改进了模型对不同类型领域变化的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在不同类型的领域偏移条件下，所提出的方法相对于其他TTA技术显示出显著性能提升。这表明结合先验知识可以有效地提高胎儿大脑亚皮层区域分割任务中的模型泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过引入一种新的TTA方法和解剖图谱作为先验知识，大大改善了胎儿超声图像中特定脑区的自动分割效果，在未来的临床应用中有很大潜力。&lt;h4&gt;翻译&lt;/h4&gt;监测胎儿大脑皮层下的区域在超声（US）图像中的生长有助于识别发育异常。手动标注这些区域是一项具有挑战性的任务，但最近的研究表明可以使用深度学习实现自动化。然而，将预训练模型应用于新的自由手US体积数据时，由于获取和对齐方式的巨大差异，通常会导致性能下降。在这项工作中，我们首先展示了测试时间适应(TTA)可以在存在真实和模拟领域偏移的情况下改善模型性能。此外，我们提出了一种新颖的TTA方法，通过将规范图集作为解剖学的先验知识来改进它。在不同类型领域的偏移情况下，我们对不同TTA方法的性能进行了基准测试，并展示了我们的提议方法带来的改进。这些改进可能有助于进一步推动胎儿大脑发育的自动监测。我们的代码可在https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring the growth of subcortical regions of the fetal brain in ultrasound(US) images can help identify the presence of abnormal development. Manuallysegmenting these regions is a challenging task, but recent work has shown thatit can be automated using deep learning. However, applying pretrained models tounseen freehand US volumes often leads to a degradation of performance due tothe vast differences in acquisition and alignment. In this work, we firstdemonstrate that test time adaptation (TTA) can be used to improve modelperformance in the presence of both real and simulated domain shifts. Wefurther propose a novel TTA method by incorporating a normative atlas as aprior for anatomy. In the presence of various types of domain shifts, webenchmark the performance of different TTA methods and demonstrate theimprovements brought by our proposed approach, which may further facilitateautomated monitoring of fetal brain development. Our code is available athttps://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation.</description>
      <author>example@mail.com (Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale)</author>
      <guid isPermaLink="false">2502.08774v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Graph Contrastive Pretraining for Device-level Integrated Circuits</title>
      <link>http://arxiv.org/abs/2502.08949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;自我监督的图表示学习在社交网络分析、分子设计和电子设计自动化（EDA）等领域取得了重大进展。然而，以往关于EDA的研究主要集中在门级数字电路的表示上，忽略了模拟和混合信号电路。&lt;h4&gt;背景&lt;/h4&gt;自我监督的图表示学习已在多个领域取得显著进步，但在EDA中主要集中于门级数字电路，未充分考虑模拟及混合信号电路。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究未能涵盖模拟与混合信号电路表示的学习方法空白。&lt;h4&gt;方法&lt;/h4&gt;提出DICE模型：一种面向任何在设备级别表达的电路的第一种自我监督预训练图神经网络（GNN），采用消息传递神经网络(MPNN)并通过图对比学习进行训练。DICE的预训练过程无需仿真，引入了两种新颖的数据增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，DICE模型在三种下游任务中取得了显著性能提升，表明其对于模拟和数字电路都具有有效性。&lt;h4&gt;结论&lt;/h4&gt;DICE是一个突破性的工具，它不仅填补了EDA领域自我监督学习方法的空白，还为未来的电子设计提供了强大的预训练图神经网络模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容由英文翻译成中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised graph representation learning has driven significantadvancements in domains such as social network analysis, molecular design, andelectronics design automation (EDA). However, prior works in EDA have mainlyfocused on the representation of gate-level digital circuits, failing tocapture analog and mixed-signal circuits. To address this gap, we introduceDICE: Device-level Integrated Circuits Encoder, the first self-supervisedpretrained graph neural network (GNN) model for any circuit expressed at thedevice level. DICE is a message-passing neural network (MPNN) trained throughgraph contrastive learning, and its pretraining process is simulation-free,incorporating two novel data augmentation techniques. Experimental resultsdemonstrate that DICE achieves substantial performance gains across threedownstream tasks, underscoring its effectiveness for both analog and digitalcircuits.</description>
      <author>example@mail.com (Sungyoung Lee, Ziyi Wang, Seunggeun Kim, Taekyun Lee, David Z. Pan)</author>
      <guid isPermaLink="false">2502.08949v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Neuro-Symbolic Contrastive Learning for Cross-domain Inference</title>
      <link>http://arxiv.org/abs/2502.09213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings ICLP 2024, arXiv:2502.08453&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;预训练语言模型（PLMs）在自然语言推理任务中取得了重大进展，但它们对文本扰动的敏感性和对大规模数据集的依赖表明了过度依赖浅层启发式方法。相比之下，归纳逻辑编程（ILP）擅长于从多样、稀疏且有限的数据集中推导出逻辑关系，但由于其离散特性需要输入精确指定，从而限制了应用范围。&lt;h4&gt;背景&lt;/h4&gt;预训练语言模型在自然语言推理任务中的表现尽管优秀，但存在对文本扰动敏感和依赖大规模数据集的问题。归纳逻辑编程能够处理多样且稀疏的数据，但因为其离散性质而难以广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合神经符号对比学习的方法来弥合预训练语言模型和归纳逻辑编程之间的差距，以改善在复杂、嘈杂且稀疏的逻辑函数空间中的推理能力。&lt;h4&gt;方法&lt;/h4&gt;通过将数据表示为逻辑程序和一组逻辑规则，在神经符号框架中嵌入抽象逻辑关系。这种方法利用连续和可微优化来提高逻辑准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，这种新方法能够显著改善模型在泛化能力和推理方面的性能。&lt;h4&gt;结论&lt;/h4&gt;提出了神经符号对比学习的方法，成功地将预训练语言模型的深度学习能力与归纳逻辑编程的精确推理相结合，在处理稀疏和嘈杂数据时表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.4204/EPTCS.416.6&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained language models (PLMs) have made significant advances in naturallanguage inference (NLI) tasks, however their sensitivity to textualperturbations and dependence on large datasets indicate an over-reliance onshallow heuristics. In contrast, inductive logic programming (ILP) excels atinferring logical relationships across diverse, sparse and limited datasets,but its discrete nature requires the inputs to be precisely specified, whichlimits their application. This paper proposes a bridge between the twoapproaches: neuro-symbolic contrastive learning. This allows for smooth anddifferentiable optimisation that improves logical accuracy across an otherwisediscrete, noisy, and sparse topological space of logical functions. We showthat abstract logical relationships can be effectively embedded within aneuro-symbolic paradigm, by representing data as logic programs and sets oflogic rules. The embedding space captures highly varied textual informationwith similar semantic logical relations, but can also separate similar textualrelations that have dissimilar logical relations. Experimental resultsdemonstrate that our approach significantly improves the inference capabilitiesof the models in terms of generalisation and reasoning.</description>
      <author>example@mail.com (Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks)</author>
      <guid isPermaLink="false">2502.09213v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>ShapeLib: designing a library of procedural 3D shape abstractions with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.08884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为ShapeLib的方法，该方法利用前沿大型语言模型的先验知识来设计一个包含3D形状抽象函数库。ShapeLib能够根据文本描述和示例形状集合发现可重复使用的程序化表示。&lt;h4&gt;背景&lt;/h4&gt;程序化表示是三维形状编码的一种理想、多功能且流行的形式，但手动或数据驱动的设计过程具有挑战性。现有的研究尝试通过探索如何识别一个可以解释整个形状家族的程序化函数库来解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于前沿大型语言模型先验知识的方法（ShapeLib），用于设计可扩展和易于修改的3D形状抽象函数库，以满足特定的设计意图，并能从不同的视觉模态中推断出相应的形状程序。&lt;h4&gt;方法&lt;/h4&gt;用户可以提供包含所需功能的文字描述或示例形状集。ShapeLib通过提出并验证这些可能的功能应用和实现来探索符合设计意图的程序化抽象。此外，训练了一个识别网络，该网络能够基于ShapeLib库从不同视觉模态中推断出形状程序。&lt;h4&gt;主要发现&lt;/h4&gt;生成的形状函数不仅具有表达性，并且能够超越种子集合之外推广到整个形状家族。这些参数具有语义可解释性和灵活性，可以修改以产生合理的形状变化。&lt;h4&gt;结论&lt;/h4&gt;ShapeLib方法在不同数据集上进行了评估，展示出明显优于现有方法和替代方案的优势，表明这种方法对于三维形状的设计和编辑具有重要的实用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法旨在通过利用大型语言模型的先验知识来设计程序化函数库，这些函数库能够根据给定的设计意图（如文本描述或示例形状）发现并实现可重复使用的程序化表示。生成的功能不仅表达能力强且具有良好的泛化能力，并能从不同的视觉输入中推断出相应的程序。这种方法在评估中表现出显著的优势，为三维形状的创建和编辑提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Procedural representations are desirable, versatile, and popular shapeencodings. Authoring them, either manually or using data-driven procedures,remains challenging, as a well-designed procedural representation should becompact, intuitive, and easy to manipulate. A long-standing problem in shapeanalysis studies how to discover a reusable library of procedural functions,with semantically aligned exposed parameters, that can explain an entire shapefamily. We present ShapeLib as the first method that leverages the priors offrontier LLMs to design a library of 3D shape abstraction functions. Our systemaccepts two forms of design intent: text descriptions of functions to includein the library and a seed set of exemplar shapes. We discover proceduralabstractions that match this design intent by proposing, and then validating,function applications and implementations. The discovered shape functions inthe library are not only expressive but also generalize beyond the seed set toa full family of shapes. We train a recognition network that learns to infershape programs based on our library from different visual modalities(primitives, voxels, point clouds). Our shape functions have parameters thatare semantically interpretable and can be modified to produce plausible shapevariations. We show that this allows inferred programs to be successfullymanipulated by an LLM given a text prompt. We evaluate ShapeLib on differentdatasets and show clear advantages over existing methods and alternativeformulations.</description>
      <author>example@mail.com (R. Kenny Jones, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie)</author>
      <guid isPermaLink="false">2502.08884v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection</title>
      <link>http://arxiv.org/abs/2502.09271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的针对图神经网络（GNN）的攻击方式，即通过注入孤立子图来欺骗链接推荐器和节点分类器，并展示了LiSA框架的有效性。&lt;h4&gt;背景&lt;/h4&gt;近年来的研究发现，尽管图神经网络在处理具有图结构的数据时表现出色，但它们对对抗性攻击非常敏感。传统的攻击方法通常不适用于实际场景。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一问题，论文提出了一个新的对抗性场景，并引入了LiSA框架来同时满足两个对抗目标：欺骗链接推荐器和降低节点分类准确性。&lt;h4&gt;方法&lt;/h4&gt;该研究采用了双代理模型和两级优化技术以实现其攻击策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，通过注入孤立子图可以成功地误导GNN系统中的链接推荐器，并且这种攻击方式会对节点分类的准确性产生负面影响。&lt;h4&gt;结论&lt;/h4&gt;提出的LiSA框架在真实世界的数据集上展示了有效的性能和潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）在处理具有图结构的数据时表现出色，但最近的研究揭示了它们对对抗性攻击的高度敏感性。传统的依赖于修改原始图或向人工创建的节点添加链接的方法通常在实际环境中不可行。本文提出了一种新的涉及注入孤立子图以欺骗GNN系统中链接推荐器和节点分类器的对抗场景。具体而言，该方法误导链接推荐器建议目标受害节点与子图之间的链接，从而鼓励用户无意间建立连接并降低节点分类准确性。为了解决这一问题，我们提出了LiSA框架，它采用双代理模型和两级优化以同时满足两个对抗性目标。大量的实验在真实世界的数据集上验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inmodeling data with graph structures, yet recent research reveals theirsusceptibility to adversarial attacks. Traditional attack methodologies, whichrely on manipulating the original graph or adding links to artificially creatednodes, often prove impractical in real-world settings. This paper introduces anovel adversarial scenario involving the injection of an isolated subgraph todeceive both the link recommender and the node classifier within a GNN system.Specifically, the link recommender is mislead to propose links between targetedvictim nodes and the subgraph, encouraging users to unintentionally establishconnections and that would degrade the node classification accuracy, therebyfacilitating a successful attack. To address this, we present the LiSAframework, which employs a dual surrogate model and bi-level optimization tosimultaneously meet two adversarial objectives. Extensive experiments onreal-world datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Wenlun Zhang, Enyan Dai, Kentaro Yoshioka)</author>
      <guid isPermaLink="false">2502.09271v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Lexical Manifold Reconfiguration in Large Language Models: A Novel Architectural Approach for Contextual Modulation</title>
      <link>http://arxiv.org/abs/2502.08818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种通过连续几何变换动态重构词嵌入的方法，旨在提高语言模型在处理复杂句子结构和领域特定术语时的灵活性与性能。&lt;h4&gt;背景&lt;/h4&gt;静态词嵌入限制了词汇的灵活性，在面对复杂的句法或领域变化时表现不佳。这可能导致语义关系维持不充分，影响语言模型的一致性和流畅性。&lt;h4&gt;目的&lt;/h4&gt;开发一种动态重构词嵌入的方法，以解决静态词嵌入在复杂文本中的局限性问题，并提高语言模型处理结构化和领域适应性任务的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于流形的转换机制来调节词汇位置，在保证语义关系连续的同时允许词嵌入发生可控的变化。该机制通过连续几何变换实现动态重构，从而增强语义一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，通过重新配置词嵌入可以降低困惑度（perplexity），提高词汇连贯性和句级别的连续性。特别是在结构化和领域适应性的文本生成任务中效果显著。同时，动态调节的词嵌入表现出更广泛的词汇多样性，并减少重复的标记模式。&lt;h4&gt;结论&lt;/h4&gt;尽管训练过程因迭代优化词嵌入而导致复杂度增加，但推理效率保持较高水平，确保了实际应用中的可行性。此外，在多个数据集上的评估表明，动态调整后的词嵌入在处理领域特定的任务中表现出更强的语言模型一致性与流畅性。&lt;h4&gt;翻译&lt;/h4&gt;上下文适应性的词嵌入调整是语言模型维持文本连贯性和语义关系的关键因素。静态词嵌入通常限制了词汇的灵活性，在面对复杂句子结构或领域术语转变时会导致性能下降。为了克服这一局限，研究者开发了一种基于连续几何变换动态重构词嵌入的方法，使表示能够随话语结构的变化而演化。采用一种流形为基础的转换机制来调控词汇位置，确保在不同文本上下文中保持语言关系的同时允许词嵌入进行可控变化。实证研究表明，通过调整词嵌入可以减少困惑度、提高词汇连贯性和句级别的连续性，特别是在复杂和领域适应性的文本生成任务中表现尤为出色。比较分析结果显示，在动态重新配置表示后，尽管训练的复杂性增加，但推理阶段依然保持高效，并且上下文一致性更强，减少了标记依赖关系的错位，同时保持了语言模型输出的流畅性。此外，评估还表明在处理多样数据集时，该方法使词嵌入表现出更加丰富的词汇多样性，并减少重复模式的发生，从而支持更灵活的表示学习过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contextual adaptation in token embeddings plays a central role in determininghow well language models maintain coherence and retain semantic relationshipsover extended text sequences. Static embeddings often impose constraints onlexical flexibility, leading to suboptimal performance when faced with complexsentence structures or domain-specific terminology shifts. To address thislimitation, a structured approach was developed for dynamically reconfiguringtoken embeddings through continuous geometric transformations, ensuring thatrepresentations evolved in response to evolving discourse structures. Amanifold-based transformation mechanism was integrated to regulate lexicalpositioning, allowing embeddings to undergo controlled shifts while preservinglinguistic relationships across varying textual contexts. Empirical evaluationsdemonstrated that embedding reconfiguration contributed to reductions inperplexity, improved lexical coherence, and enhanced sentence-level continuity,particularly in structured and domain-adaptive text generation tasks.Comparative analyses of embedding drift indicated that dynamically restructuredrepresentations maintained stronger contextual consistency, reducingmisalignment in token dependencies while preserving fluency in languagemodeling outputs. Computational overhead assessments confirmed that whiletraining complexity increased due to the iterative refinement of embeddings,inference remained efficient, ensuring practical feasibility for real-timegeneration. Evaluations across multiple datasets further demonstrated thatdynamically modulated embeddings exhibited broader lexical diversity, reducingrepetitive token patterns and enabling a more adaptable representation learningprocess.</description>
      <author>example@mail.com (Koinis Vassilis, Godfrey Milbourne, Harriet Featherstone, Xanthe Peverell, Yorick Bletchley, Zachary Montford)</author>
      <guid isPermaLink="false">2502.08818v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Advancing machine fault diagnosis: A detailed examination of convolutional neural networks</title>
      <link>http://arxiv.org/abs/2502.08689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;综述了卷积神经网络(CNN)在机器故障诊断中的应用，包括其理论基础、架构变化和实际应用。分析了CNN在此领域的优缺点，并探讨了数据增强、迁移学习和混合架构等最近的进展。&lt;h4&gt;背景&lt;/h4&gt;随着机械设备复杂性和操作效率及安全性的需求增加，先进的故障诊断技术变得越来越重要。卷积神经网络因其在故障检测与分类中的强大能力和准确性而脱颖而出。&lt;h4&gt;目的&lt;/h4&gt;全面回顾CNN在机器故障诊断中的应用，分析其优势和局限性，并探讨未来的研究方向和潜在挑战。&lt;h4&gt;方法&lt;/h4&gt;综述了CNN的理论基础、架构变化以及在不同故障类型、数据复杂度和操作环境下的实际实施情况。&lt;h4&gt;主要发现&lt;/h4&gt;CNN能够有效处理各种类型的故障，适用于不同的数据复杂性和运行环境。最近的发展包括利用数据增强技术、迁移学习策略和混合架构来改进故障诊断。&lt;h4&gt;结论&lt;/h4&gt;展望了未来的研究方向，强调通过解决潜在挑战进一步提升CNN在机器故障诊断中的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;机械设备复杂性日益增加以及对操作效率及安全性的需求不断增长推动了先进故障诊断技术的发展。卷积神经网络(CNN)作为一种强大的工具，在提供鲁棒且准确的故障检测和分类能力方面表现出色。这篇综述深入探讨了CNN在机器故障诊断中的应用，涵盖了其理论基础、架构变化以及实际实施情况。文中分析了CNN在此领域的优势与局限性，并讨论了它们处理各种类型故障、数据复杂度及操作环境的有效性。此外，我们还研究了基于CNN的故障诊断领域的发展趋势，考察了最近在数据增强、迁移学习和混合架构方面的进步。最后，我们指出了未来的研究方向以及为了进一步提升CNN应用效果而可能面临的潜在挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing complexity of machinery and the increasing demand for operationalefficiency and safety have driven the development of advanced fault diagnosistechniques. Among these, convolutional neural networks (CNNs) have emerged as apowerful tool, offering robust and accurate fault detection and classificationcapabilities. This comprehensive review delves into the application of CNNs inmachine fault diagnosis, covering its theoretical foundation, architecturalvariations, and practical implementations. The strengths and limitations ofCNNs are analyzed in this domain, discussing their effectiveness in handlingvarious fault types, data complexities, and operational environments.Furthermore, we explore the evolving landscape of CNN-based fault diagnosis,examining recent advancements in data augmentation, transfer learning, andhybrid architectures. Finally, we highlight future research directions andpotential challenges to further enhance the application of CNNs for reliableand proactive machine fault diagnosis.</description>
      <author>example@mail.com (Govind Vashishtha, Sumika Chauhan, Mert Sehri, Justyna Hebda-Sobkowicz, Radoslaw Zimroz, Patrick Dumond, Rajesh Kumar)</author>
      <guid isPermaLink="false">2502.08689v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple Architectures Meet Excellence</title>
      <link>http://arxiv.org/abs/2502.09263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了通过增强框架GNN+改进经典图神经网络（GNNs）在处理图形级别任务时的表现，证明了传统GNNs在许多情况下可以优于图形变换器（GTs）。&lt;h4&gt;背景&lt;/h4&gt;消息传递的GNNs由于表达力不足、过度平滑和过度挤压等问题受到批评。相比之下，基于全局注意力机制的Graph Transformers被认为更强大。&lt;h4&gt;目的&lt;/h4&gt;探索经典图神经网络通过增强框架改善其性能的潜力，并重新评估它们在图形级别任务中的有效性。&lt;h4&gt;方法&lt;/h4&gt;研究者提出了GNN+框架，整合了六种常用技术：边特征集成、归一化、dropout、残差连接、前馈网络和位置编码。在此基础上，对GCN、GIN和GatedGCN三种经典图神经网络进行增强，并在14个著名图形级别数据集上进行了系统性评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在所有测试的数据集中，经典的图神经网络通过GNN+框架的改进后，在大多数任务中都表现出色且排名前三，其中八项任务取得了第一的位置。此外还显示了经典图神经网络在效率方面优于GTs的优势。&lt;h4&gt;结论&lt;/h4&gt;研究挑战了复杂机制是实现卓越图形级别性能的关键这一观念，并强调简单架构的GNNs具有巨大潜力，能够通过适当的优化技术超越更复杂的模型。&lt;h4&gt;翻译&lt;/h4&gt;消息传递图神经网络(GNNs)由于其表现力受限、过度平滑和过度挤压等问题受到批评，在捕捉长距离依赖方面也存在挑战。而Graph Transformers (GTs)，因其全局注意力机制被认为更为优越。文献普遍认为，特别是在图分类和回归等图形级别任务中，GTs优于GNNs。在本研究中，我们通过增强框架GNN+探索了经典GNNs的未开发潜力，该框架整合了六种常用技术：边特征集成、归一化、dropout、残差连接、前馈网络和位置编码，以有效处理图形级别任务。我们在三个经典GNN（GCN，GIN和GatedGCN）上进行了系统的评估，这些模型通过GNN+框架增强了14个著名图形级别数据集上的表现。我们的结果表明，与普遍看法相反的是，经典的图神经网络在图形级别的任务中表现出色，在所有数据集中排名前三，并且在八个数据集中排名第一，同时也显示了比GTs更高的效率。这突显了简单GNN架构的潜力，并挑战了复杂机制是实现卓越图形级别性能的关键这一观念。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/LUOyk1999/tunedGNN-G&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message-passing Graph Neural Networks (GNNs) are often criticized for theirlimited expressiveness, issues like over-smoothing and over-squashing, andchallenges in capturing long-range dependencies, while Graph Transformers (GTs)are considered superior due to their global attention mechanisms. Literaturefrequently suggests that GTs outperform GNNs, particularly in graph-level taskssuch as graph classification and regression. In this study, we explore theuntapped potential of GNNs through an enhanced framework, GNN+, whichintegrates six widely used techniques: edge feature integration, normalization,dropout, residual connections, feed-forward networks, and positional encoding,to effectively tackle graph-level tasks. We conduct a systematic evaluation ofthree classic GNNs, namely GCN, GIN, and GatedGCN, enhanced by the GNN+framework across 14 well-known graph-level datasets. Our results show that,contrary to the prevailing belief, classic GNNs excel in graph-level tasks,securing top three rankings across all datasets and achieving first place ineight, while also demonstrating greater efficiency than GTs. This highlightsthe potential of simple GNN architectures, challenging the belief that complexmechanisms in GTs are essential for superior graph-level performance.</description>
      <author>example@mail.com (Yuankai Luo, Lei Shi, Xiao-Ming Wu)</author>
      <guid isPermaLink="false">2502.09263v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Cluster and Predict Latents Patches for Improved Masked Image Modeling</title>
      <link>http://arxiv.org/abs/2502.08769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 7 figures, submitted to TMLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CAPI的新型纯Masked Image Modeling (MIM) 框架，该框架通过预测潜在聚类来改进自我监督表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的MIM模型在性能上仍落后于当前的技术前沿。&lt;h4&gt;目的&lt;/h4&gt;系统地分析目标表示、损失函数和架构，以提出一种新的纯MIM框架CAPI。&lt;h4&gt;方法&lt;/h4&gt;采用了基于聚类的损失函数，该损失函数训练稳定且具有良好的扩展性。使用了ViT-L骨干网络，并通过简单的线性探针在ImageNet上实现83.8% 的准确率，在ADE20K数据集上的mIoU值为32.1%。&lt;h4&gt;主要发现&lt;/h4&gt;CAPI框架的性能显著优于以前的MIM方法，接近于当前最先进的DINOv2模型的表现。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖的方法来改进自我监督表示学习，并且该方法在多个数据集上达到了优越的结果。&lt;h4&gt;翻译&lt;/h4&gt;Masked Image Modeling (MIM)为自我监督表示学习提供了一种有前途的途径，然而现有的MIM模型仍落后于当前的技术前沿。在这项研究中，我们系统地分析了目标表示、损失函数和架构，并引入了一种新颖的纯MIM框架CAPI，该框架依赖于预测潜在聚类。我们的方法采用基于聚类的损失函数，训练稳定且具有良好的扩展性。使用ViT-L骨干网络进行实验，在ImageNet上实现了83.8% 的准确率，在ADE20K数据集上的mIoU值为32.1%，显著优于先前的方法，并接近于当前最先进的DINOv2模型的表现。我们将所有代码和模型公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Image Modeling (MIM) offers a promising approach to self-supervisedrepresentation learning, however existing MIM models still lag behind thestate-of-the-art. In this paper, we systematically analyze targetrepresentations, loss functions, and architectures, to introduce CAPI - a novelpure-MIM framework that relies on the prediction of latent clusterings. Ourapproach leverages a clustering-based loss, which is stable to train, andexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,substantially outperforming previous MIM methods and approaching theperformance of the current state-of-the-art, DINOv2. We release all our codeand models.</description>
      <author>example@mail.com (Timothée Darcet, Federico Baldassarre, Maxime Oquab, Julien Mairal, Piotr Bojanowski)</author>
      <guid isPermaLink="false">2502.08769v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Self-Evaluation for Job-Shop Scheduling</title>
      <link>http://arxiv.org/abs/2502.08684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的神经组合优化框架，用于解决调度和路径规划等NP难问题。&lt;h4&gt;背景&lt;/h4&gt;组合优化问题是许多行业中的关键挑战，但由于其计算复杂性，这些问题难以直接通过算法解决。现有的神经组合优化方法通常依赖于顺序决策过程，该过程容易累积错误。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来克服传统序贯方法的缺点，并提高解决组合优化问题的能力。&lt;h4&gt;方法&lt;/h4&gt;借鉴大型语言模型中的自我评估技术，本文提出了一个生成和评估任务分配子集的新框架。具体应用于作业车间调度问题（Job-Shop Scheduling Problem），该框架结合了异构图神经网络和Transformer来构建策略模型及自评估函数。&lt;h4&gt;主要发现&lt;/h4&gt;实验在具有挑战性的基准测试数据集上验证了所提出方法的有效性，超过了现有的最先进水平。&lt;h4&gt;结论&lt;/h4&gt;新框架能够有效解决组合优化问题，并在未来的研究中有着潜在的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;组合优化问题是诸如调度和路径规划等领域的关键问题，这些问题由于其NP难特性而难以计算求解。神经组合优化方法利用机器学习技术来应对这些挑战，但通常依赖于顺序决策过程，这种过程容易累积错误，因为小的失误在整个过程中会逐渐扩大。受大型语言模型中自我评估技术的启发，本文提出了一种新框架，该框架生成并评估任务分配子集，超越了传统的逐步骤方法。应用于作业车间调度问题（Job-Shop Scheduling Problem），该方法融合了异构图神经网络与Transformer以构建策略模型和自评估函数。在具有挑战性的、知名基准测试上的实验验证表明，我们的方法比现有的最佳技术更有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combinatorial optimization problems, such as scheduling and route planning,are crucial in various industries but are computationally intractable due totheir NP-hard nature. Neural Combinatorial Optimization methods leveragemachine learning to address these challenges but often depend on sequentialdecision-making, which is prone to error accumulation as small mistakespropagate throughout the process. Inspired by self-evaluation techniques inLarge Language Models, we propose a novel framework that generates andevaluates subsets of assignments, moving beyond traditional stepwiseapproaches. Applied to the Job-Shop Scheduling Problem, our method integrates aheterogeneous graph neural network with a Transformer to build a policy modeland a self-evaluation function. Experimental validation on challenging,well-known benchmarks demonstrates the effectiveness of our approach,surpassing state-of-the-art methods.</description>
      <author>example@mail.com (Imanol Echeverria, Maialen Murua, Roberto Santana)</author>
      <guid isPermaLink="false">2502.08684v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LIR-LIVO: A Lightweight,Robust LiDAR/Vision/Inertial Odometry with Illumination-Resilient Deep Features</title>
      <link>http://arxiv.org/abs/2502.08676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种轻量级且鲁棒的LiDAR-惯性-视觉里程计系统LIR-LIVO，用于挑战性的照明和退化环境。&lt;h4&gt;背景&lt;/h4&gt;在复杂的环境中（如光照变化大、条件差），传统的LiDAR-Inertial-Visual Odometry (LIVO) 系统可能无法保持准确性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的LIVO系统，能够利用深度学习技术抵抗照明变化，并适用于各种环境。&lt;h4&gt;方法&lt;/h4&gt;1. 利用基于深度学习的抗光特性；            2. 使用LiDAR点云进行特征均匀分布深度分配；            3. 结合Superpoint和LightGlue实现自适应特征匹配。&lt;h4&gt;主要发现&lt;/h4&gt;通过NTU-VIRAL、Hilti'22及R3LIVE-Dataset等基准数据集的实验，证明了所提出的方法在标准和挑战性条件下均优于现有的SOTA方法。特别是在Hilti'22数据集中，在低光照环境下具有优越的姿态估计能力。&lt;h4&gt;结论&lt;/h4&gt;该工作通过公开代码的方式分享给机器人技术社区，以促进相关领域的进步。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了LIR-LIVO系统，这是一种轻量级且鲁棒的LiDAR-惯性-视觉里程计系统，旨在应对挑战性的照明和退化环境。该方法结合了基于深度学习的技术来实现抗光特性，并利用深度关联技术将特征分布均匀到LiDAR点云上，同时采用Superpoint和LightGlue进行自适应匹配。实验结果表明，在NTU-VIRAL、Hilti'22及R3LIVE-Dataset等基准数据集上的表现优于现有的SOTA方法，并且在低光照环境下具有优越的姿态估计能力。该工作的代码可在GitHub上公开获取，以促进机器人技术社区的发展进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose LIR-LIVO, a lightweight and robustLiDAR-inertial-visual odometry system designed for challenging illumination anddegraded environments. The proposed method leverages deep learning-basedillumination-resilient features and LiDAR-Inertial-Visual Odometry (LIVO). Byincorporating advanced techniques such as uniform depth distribution offeatures enabled by depth association with LiDAR point clouds and adaptivefeature matching utilizing Superpoint and LightGlue, LIR-LIVO achievesstate-of-the-art (SOTA) accuracy and robustness with low computational cost.Experiments are conducted on benchmark datasets, including NTU-VIRAL, Hilti'22,and R3LIVE-Dataset. The corresponding results demonstrate that our proposedmethod outperforms other SOTA methods on both standard and challengingdatasets. Particularly, the proposed method demonstrates robust pose estimationunder poor ambient lighting conditions in the Hilti'22 dataset. The code ofthis work is publicly accessible on GitHub to facilitate advancements in therobotics community.</description>
      <author>example@mail.com (Shujie Zhou, Zihao Wang, Xinye Dai, Weiwei Song, Shengfeng Gu)</author>
      <guid isPermaLink="false">2502.08676v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units</title>
      <link>http://arxiv.org/abs/2502.06921v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文介绍了GraNNite，一个针对商业现货(COTS)最先进深度神经网络加速器优化图神经网络(GNN)执行的硬件感知框架。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）对于从结构化数据中学习至关重要，在网络分析、推荐系统和语音分析等领域有着广泛应用。将其部署在边缘设备上可以增强实时处理能力，保护隐私，并且不受云计算依赖的影响。然而，不规则内存访问、稀疏性和动态结构导致资源受限设备上的延迟和能耗过高。&lt;h4&gt;目的&lt;/h4&gt;提出一个优化GNN执行的框架，以解决现有硬件加速器（如NPU）在不规则图计算中的挑战。&lt;h4&gt;方法&lt;/h4&gt;采用了一个分三步的方法来优化COTS最先进DNN加速器上的GNN执行：(1)启用NPU执行；(2)提升性能；(3)通过牺牲精度换取效率。每个步骤使用特定的技术或工具，如GraphSplit、StaGr、EffOp等。&lt;h4&gt;主要发现&lt;/h4&gt;在Intel Core Ultra AI PC上测试时，GraNNite相比默认的NPU映射提供了2.6倍至7.6倍的速度提升，并且比CPU和GPU最多能节省8.6倍的能量消耗。与单独使用CPU和GPU相比，在不同的GNN模型中分别实现了10.8倍和6.7倍的性能增强。&lt;h4&gt;结论&lt;/h4&gt;通过专门的方法，可以有效地优化图神经网络在COTS最先进DNN加速器上的执行效率，实现更高的计算速度和更低的能量消耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are vital for learning from graph-structureddata, enabling applications in network analysis, recommendation systems, andspeech analytics. Deploying them on edge devices like client PCs and laptopsenhances real-time processing, privacy, and cloud independence. GNNs aidRetrieval-Augmented Generation (RAG) for Large Language Models (LLMs) andenable event-based vision tasks. However, irregular memory access, sparsity,and dynamic structures cause high latency and energy overhead onresource-constrained devices. While modern edge processors integrate CPUs,GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregularGNN computations. We introduce GraNNite, the first hardware-aware frameworkoptimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNNaccelerators via a structured three-step methodology: (1) enabling NPUexecution, (2) optimizing performance, and (3) trading accuracy for efficiencygains. Step 1 employs GraphSplit for workload distribution and StaGr for staticaggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boostsperformance using EffOp for control-heavy tasks and GraSp for sparsityexploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduceredundancy and memory transfers. Step 3 balances quality versus efficiency,where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerateattention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higherperformance than CPUs and GPUs, respectively, across GNN models.</description>
      <author>example@mail.com (Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan)</author>
      <guid isPermaLink="false">2502.06921v2</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Meta-learning of shared linear representations beyond well-specified linear regression</title>
      <link>http://arxiv.org/abs/2501.18975v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于多任务学习和元学习的方法，考虑如何从任务或用户中学习共享的结构，如低秩表示或集群结构。不同于以往的研究集中在指定线性回归上，该研究针对更一般的凸目标函数，在这种情况下，结构化假设在每个函数的最优解处表达。&lt;h4&gt;背景&lt;/h4&gt;多任务和元学习的方法旨在通过从多个相关任务中提取共享信息来提高模型性能，特别是在低秩表示或集群结构的情况下。然而，大多数现有方法集中在特定线性回归框架下。&lt;h4&gt;目的&lt;/h4&gt;研究更一般的凸目标函数中的共享结构，并探讨在较少样本条件下如何恢复这些结构。&lt;h4&gt;方法&lt;/h4&gt;该研究假设了Hessian集中和最优解处的噪声集中等条件，使用秩约束估计器来实现这一目标。此外还提出了一种通过核范数限制进行多项式时间算法的方法，用于在凸学习目标中学习共享线性表示。&lt;h4&gt;主要发现&lt;/h4&gt;当样本数量足够大时，可以恢复低秩和集群结构；仅有一个任务样本的情况下可以通过秩约束估计器来恢复子空间，并且需要任务的数量随子空间维度呈指数级增长。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在理论上证明了从凸目标函数中学习共享结构的可能性，并提供了一种实用的多项式时间算法。这为未来多任务和元学习研究提供了新的方向和方法论支持。&lt;h4&gt;翻译&lt;/h4&gt;受多任务及元学习方法启发，我们考虑从任务或用户中学习共享结构的问题，如低秩表示或者集群结构。尽管之前的全部工作都集中在指定线性回归上，我们则专注于更一般的凸目标函数，在这种情况下，结构性的假设以每个函数最优解的形式表达出来。在温和条件，比如Hessian集中以及噪声在最优解处集中的条件下，我们展示了当样本数量和任务数量足够大的时候，可以恢复低秩和集群结构。之后，我们在只有单一样本的任务环境中探讨了如何恢复所有解决方案所在的子空间的问题：在这种情况下，通过秩约束估计器可以恢复出这个子空间，但是需要的任务数量随着子空间维度呈指数级增长。最后，我们还提供了一种使用核范数限制的多项式时间算法，在凸学习目标中用于学习共享线性表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by multi-task and meta-learning approaches, we consider the problemof learning structure shared by tasks or users, such as shared low-rankrepresentations or clustered structures. While all previous works focus onwell-specified linear regression, we consider more general convex objectives,where the structural low-rank and cluster assumptions are expressed on theoptima of each function. We show that under mild assumptions such as\textit{Hessian concentration} and \textit{noise concentration at the optimum},rank and clustered regularized estimators recover such structure, provided thenumber of samples per task and the number of tasks are large enough. We thenstudy the problem of recovering the subspace in which all the solutions lie, inthe setting where there is only a single sample per task: we show that in thatcase, the rank-constrained estimator can recover the subspace, but that thenumber of tasks needs to scale exponentially large with the dimension of thesubspace. Finally, we provide a polynomial-time algorithm via nuclear normconstraints for learning a shared linear representation in the context ofconvex learning objectives.</description>
      <author>example@mail.com (Mathieu Even, Laurent Massoulié)</author>
      <guid isPermaLink="false">2501.18975v2</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References</title>
      <link>http://arxiv.org/abs/2502.09614v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025. Website: https://meowuu7.github.io/DexTrack/  Code: https://github.com/Meowuu7/DexTrack/ Video:  https://youtu.be/zru1Z-DaiWE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种用于灵巧机器人手操作的通用神经控制器的方法，通过收集大规模的人机交互数据进行训练，并利用强化学习和模仿学习相结合的方式来提高控制器在动态环境中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常依赖于任务特定奖励或精确系统模型，因此难以适应复杂的接触动力学和广泛的泛化需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够管理灵巧机器人手以操纵多种对象并适用于不同应用场景的神经跟踪控制器。&lt;h4&gt;方法&lt;/h4&gt;{'数据驱动': '收集大规模的成功机器人跟踪演示，包含人类参考与机器人动作对，用于训练神经控制器。', '迭代优化': '利用数据飞轮机制不断改进控制器性能和高质量跟踪演示的数量及质量。', '强化学习和模仿学习结合': '在动态环境中通过集成强化学习和模仿学习来增强控制器的表现。', '轨迹优化': '单独针对每条轨迹进行优化，使用已学得的跟踪控制器在一个同伦优化方法中工作以提高表现并增加演示多样性。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法相比于领先基线方法在成功率上提高了超过10%。&lt;h4&gt;结论&lt;/h4&gt;通过结合大规模数据、强化学习和模仿学习以及轨迹单独优化，成功训练出一个在模拟和真实世界环境中都能表现出色的通用神经控制器。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了从人类参考中开发灵巧操作的手部机器人泛化神经跟踪控制器的问题。此控制器旨在管理灵巧机器人手来操纵各种由运动学人机交互定义的不同目的的物体。由于复杂接触动力学和对适应性、泛化能力和鲁棒性的需求，这样的控制器很难发展出来。现有的强化学习和轨迹优化方法通常因依赖任务特定奖励或精确系统模型而表现不佳。我们介绍了一种收集大规模成功机器人跟踪演示的方法（包括人类参考和机器人动作），以此来训练神经控制器。通过数据飞轮机制，我们不断改进控制器性能以及高质量的跟踪演示的数量和质量。在动态环境中，我们利用现有的跟踪演示并仔细集成强化学习和模仿学习以提高控制器的表现。同时为了获得高质量的跟踪演示，我们使用学到的跟踪控制器在一个同伦优化方法中单独针对每条轨迹进行优化，从而解决困难的轨迹跟踪问题来增加演示多样性。我们在模拟和真实世界环境中训练了一个通用神经控制器，并与最先进的基线进行了比较。我们的方法在成功率上比领先基线方法提高了超过10%。项目网站https://meowuu7.github.io/DexTrack/提供了带有动画结果的信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of developing a generalizable neural trackingcontroller for dexterous manipulation from human references. This controlleraims to manage a dexterous robot hand to manipulate diverse objects for variouspurposes defined by kinematic human-object interactions. Developing such acontroller is complicated by the intricate contact dynamics of dexterousmanipulation and the need for adaptivity, generalizability, and robustness.Current reinforcement learning and trajectory optimization methods often fallshort due to their dependence on task-specific rewards or precise systemmodels. We introduce an approach that curates large-scale successful robottracking demonstrations, comprising pairs of human references and robotactions, to train a neural controller. Utilizing a data flywheel, weiteratively enhance the controller's performance, as well as the number andquality of successful tracking demonstrations. We exploit available trackingdemonstrations and carefully integrate reinforcement learning and imitationlearning to boost the controller's performance in dynamic environments. At thesame time, to obtain high-quality tracking demonstrations, we individuallyoptimize per-trajectory tracking by leveraging the learned tracking controllerin a homotopy optimization method. The homotopy optimization, mimickingchain-of-thought, aids in solving challenging trajectory tracking problems toincrease demonstration diversity. We showcase our success by training ageneralizable neural controller and evaluating it in both simulation and realworld. Our method achieves over a 10% improvement in success rates compared toleading baselines. The project website with animated results is available athttps://meowuu7.github.io/DexTrack/.</description>
      <author>example@mail.com (Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi)</author>
      <guid isPermaLink="false">2502.09614v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Rolling Ahead Diffusion for Traffic Scene Simulation</title>
      <link>http://arxiv.org/abs/2502.09587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Workshop on Machine Learning for Autonomous Driving at  AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于滚动扩散的交通场景生成模型，结合了自回归（AR）预测即时未来和差分方程模型再生场景的优点。&lt;h4&gt;背景&lt;/h4&gt;现实驾驶仿真需要NPC不仅要模仿自然驾驶行为，还要对其它仿真人行为做出反应。最近的发展集中在利用基于扩散的方法生成多样的、真实的交通场景，但这种方法在面对模拟代理动作偏离预定轨迹时缺乏响应性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够同时预测下一时刻未来并部分预测进一步未来的扰动模型的滚动扩散方法，以此提升仿真场景的实时性和计算效率。&lt;h4&gt;方法&lt;/h4&gt;利用自回归（AR）模型来预测所有NPC的即时下一步行动，并结合差分方程模型的再生成能力，在每个时间步长上同时进行下一时刻和后续部分扰动步骤的预测。&lt;h4&gt;主要发现&lt;/h4&gt;提出的滚动扩散交通场景生成模型在响应性和计算效率之间取得了有益的折衷，相较于基于自回归（AR）的扩散模型更为高效。&lt;h4&gt;结论&lt;/h4&gt;通过结合自回归模型的即时性与差分方程再生模型的长期规划能力，新的方法提供了一种更高效的解决方案来实现真实驾驶模拟中的场景生成。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在现实驾驶仿真中NPC需要模仿自然驾驶行为并对其它仿真人做出反应的需求。基于扩散的方法虽然能创造多样且真实的交通场景，但在面对代理动作偏离模型轨迹时缺乏响应性。为解决这一问题，提出了一种结合自回归预测和差分方程再生的滚动扩散方法，实现了在实时性和计算效率之间的平衡，以提高驾驶模拟的真实感和动态适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Realistic driving simulation requires that NPCs not only mimic naturaldriving behaviors but also react to the behavior of other simulated agents.Recent developments in diffusion-based scenario generation focus on creatingdiverse and realistic traffic scenarios by jointly modelling the motion of allthe agents in the scene. However, these traffic scenarios do not react when themotion of agents deviates from their modelled trajectories. For example, theego-agent can be controlled by a stand along motion planner. To producereactive scenarios with joint scenario models, the model must regenerate thescenario at each timestep based on new observations in a Model PredictiveControl (MPC) fashion. Although reactive, this method is time-consuming, as onecomplete possible future for all NPCs is generated per simulation step.Alternatively, one can utilize an autoregressive model (AR) to predict only theimmediate next-step future for all NPCs. Although faster, this method lacks thecapability for advanced planning. We present a rolling diffusion based trafficscene generation model which mixes the benefits of both methods by predictingthe next step future and simultaneously predicting partially noised furtherfuture steps at the same time. We show that such model is efficient compared todiffusion model based AR, achieving a beneficial compromise between reactivityand computational efficiency.</description>
      <author>example@mail.com (Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood)</author>
      <guid isPermaLink="false">2502.09587v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2502.09556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the preprint version of the paper published in 2023 IEEE  International Conference on Robotics and Automation (ICRA). The final version  is available at IEEE Xplore: https://doi.org/10.1109/ICRA48891.2023.10160595&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Real-Time Fast Marching Tree (RT-FMT)的实时规划算法，该算法能够在搜索过程中快速寻找全局解决方案，并同时生成局部路径，使得机器人可以更快地开始执行任务。此外，此算法还具有动态障碍物避让功能。&lt;h4&gt;背景&lt;/h4&gt;Fast Marching Tree（FMT*）和Real-time Rapidly-Exploring Random Tree (RT-RRT*)是现有规划算法的基础。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的实时路径规划算法以解决局部与全局路径生成、多重查询规划以及动态障碍物避让的问题，同时提高执行成本和到达时间的性能。&lt;h4&gt;方法&lt;/h4&gt;基于FMT*和RT-RRT*两种算法，引入了RT-FMT算法，它能够快速寻找全局解，并在搜索过程中产生可用的局部路径。通过不断调整树形结构来避免形成动态障碍物内部分支，同时保持根节点靠近机器人位置，使得该算法可以被多次重复使用。&lt;h4&gt;主要发现&lt;/h4&gt;RT-FMT算法相较于RT-RRT*而言，在大多数情况下都能降低执行成本和到达时间。此外，尽管存在采取次优路径的可能性较小，但在全局路径可用之前采用局部路径以减少到达时间是值得的。&lt;h4&gt;结论&lt;/h4&gt;RT-FMT作为一种实时路径规划方法，具有高效的性能表现和适用性，能够快速响应动态环境变化并生成合理的行驶路线。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种新的算法——实时光速树（Real-Time Fast Marching Tree, RT-FMT），该算法能够在搜索过程中迅速找到全局解决方案，并同时产生局部路径。这种算法能在短时间内启动执行任务以节省时间，同时还具备处理动态障碍物的能力。通过与RT-RRT*进行对比模拟实验发现，在大多数情况下，RT-FMT在执行成本和到达时间方面优于后者。此外还证明了即使有较小的可能性会采取较差的路线，提前采用局部路径也能降低到达时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICRA48891.2023.10160595&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-timeplanning algorithm that features local and global path generation,multiple-query planning, and dynamic obstacle avoidance. During the search,RT-FMT quickly looks for the global solution and, in the meantime, generateslocal paths that can be used by the robot to start execution faster. Inaddition, our algorithm constantly rewires the tree to keep branches fromforming inside the dynamic obstacles and to maintain the tree root near therobot, which allows the tree to be reused multiple times for different goals.Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-timeRapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMToutperforms RT- RRT* in both execution cost and arrival time, in most cases.Moreover, we also demonstrate via simulation that it is worthwhile taking thelocal path before the global path is available in order to reduce arrival time,even though there is a small possibility of taking an inferior path.</description>
      <author>example@mail.com (Jefferson Silveira, Kleber Cabral, Sidney Givigi, Joshua A. Marshall)</author>
      <guid isPermaLink="false">2502.09556v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>SpeechCompass: Enhancing Mobile Captioning with Diarization and Directional Guidance via Multi-Microphone Localization</title>
      <link>http://arxiv.org/abs/2502.08848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;移动设备上的语音转文字功能在听力和口语辅助、语言翻译、记笔记和会议记录方面发挥了重要作用。然而，基础的大规模调查表明，在多人对话中无法区分说话人的方向使这些技术面临挑战。&lt;h4&gt;背景&lt;/h4&gt;语音转文本技术已经在多种场景下证明了其价值，但目前的语音识别系统难以处理多讲话者的方向信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入高效的音频定位算法和特定硬件来解决当前移动设备上语音转文字功能在多人对话中的局限性问题。&lt;h4&gt;方法&lt;/h4&gt;使用低功耗微控制器及四个集成麦克风实现实时、多麦克风语音定位。通过大规模调查（n=494）进行小组会议的现场研究，收集八名常用手机语音识别用户的反馈，并评估五种可视化风格。&lt;h4&gt;主要发现&lt;/h4&gt;参与者普遍认为身份区分和视觉化定位的价值和潜力对于多人对话非常重要。所有参与者都认同方向指导在小组对话中的价值与可能性。&lt;h4&gt;结论&lt;/h4&gt;SpeechCompass通过提供实时的多麦克风语音定位解决方案，增强了移动设备上语音转文字的功能，特别是在处理多个说话者的场景中提供了更好的用户体验。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要提及了现有的语音转文本技术虽然有用但存在局限性，并提出了改进方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech-to-text capabilities on mobile devices have proven helpful for hearingand speech accessibility, language translation, note-taking, and meetingtranscripts. However, our foundational large-scale survey (n=263) shows thatthe inability to distinguish and indicate speaker direction makes themchallenging in group conversations. SpeechCompass addresses this limitationthrough real-time, multi-microphone speech localization, where the direction ofspeech allows visual separation and guidance (e.g., arrows) in the userinterface. We introduce efficient real-time audio localization algorithms andcustom sound perception hardware running on a low-power microcontroller andfour integrated microphones, which we characterize in technical evaluations.Informed by a large-scale survey (n=494), we conducted an in-person study ofgroup conversations with eight frequent users of mobile speech-to-text, whoprovided feedback on five visualization styles. The value of diarization andvisualizing localization was consistent across participants, with everyoneagreeing on the value and potential of directional guidance for groupconversations.</description>
      <author>example@mail.com (Artem Dementyev, Dimitri Kavensky, Samuel J. Yang, Mathieu Parvaix, Chiong Lai, Alex Olwal)</author>
      <guid isPermaLink="false">2502.08848v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Variable Stiffness for Robust Locomotion through Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.09436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IFAC Joint Symposia on Mechatronics &amp; Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的控制范式，将可变刚度集成到动作空间中，并与关节位置结合在一起，实现了不同级别的刚度控制策略。通过这种方法，机器人在速度跟踪和推力恢复方面的表现优于单纯的位置控制，在能量效率方面，混合关节-腿刚度策略表现出色。&lt;h4&gt;背景&lt;/h4&gt;强化学习方法虽然可以使腿部机器人执行动态运动，但通常需要手动调整关节刚度，这很耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的控制范式来简化设计过程并提高性能。&lt;h4&gt;方法&lt;/h4&gt;将可变刚度纳入动作空间，并采用分组刚度控制策略（如每关节刚度、每腿刚度和混合关节-腿刚度）进行试验。&lt;h4&gt;主要发现&lt;/h4&gt;使用分组的每腿刚度策略在速度跟踪和推力恢复方面超越了位置控制，而混合关节-腿刚度策略则表现出了更高的能量效率。此外，该方法通过模拟到现实环境转移展示了鲁棒行走能力。&lt;h4&gt;结论&lt;/h4&gt;新的控制范式简化设计过程同时保持了多种性能指标的竞争性结果。&lt;h4&gt;翻译&lt;/h4&gt;强化学习的步态使腿部机器人能够执行动态动作，但通常伴随有耗时的手动调节关节刚度。本文介绍了一种新的控制模式，该模式将可变刚度与关节位置一起整合到动作空间中，支持分组刚度控制（如每关节刚度、每腿刚度和混合关节-腿刚度）。我们表明，在速度跟踪和推力恢复方面，采用分组的每腿刚度策略优于仅基于位置的控制。相比之下，混合关节-腿刚度策略在能量效率上更胜一筹。此外，通过从平地训练的策略实现模拟到现实环境转移，该方法展示了在各种户外地形上的鲁棒步行行为。我们的方法简化了设计流程，消除了对每关节刚度的手动调节，并且在多种性能指标下保持了竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement-learned locomotion enables legged robots to perform highlydynamic motions but often accompanies time-consuming manual tuning of jointstiffness. This paper introduces a novel control paradigm that integratesvariable stiffness into the action space alongside joint positions, enablinggrouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness(PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffnesspolicies, with grouping in per-leg stiffness (PLS), outperform position-basedcontrol in velocity tracking and push recovery. In contrast, HJLS excels inenergy efficiency. Furthermore, our method showcases robust walking behaviouron diverse outdoor terrains by sim-to-real transfer, although the policy issorely trained on a flat floor. Our approach simplifies design by eliminatingper-joint stiffness tuning while keeping competitive results with variousmetrics.</description>
      <author>example@mail.com (Dario Spoljaric, Yashuai Yan, Dongheui Lee)</author>
      <guid isPermaLink="false">2502.09436v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework</title>
      <link>http://arxiv.org/abs/2502.08756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;开发基于Web的地理信息系统（GIS）应用程序，通常被称为CyberGIS仪表板，在环境研究中查询和可视化GIS数据往往需要重复且资源密集型的努力。虽然生成式人工智能提供了代码生成自动化的潜力，但由于在整合领域知识、软件工程原则以及UI设计最佳实践方面的挑战，它难以处理复杂的科学应用。&lt;h4&gt;背景&lt;/h4&gt;开发Web GIS应用程序的需求很高，但目前的自动化技术存在局限性，特别是在结合领域知识和用户体验设计方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强生成式预训练Transformer（GPT）用于前端开发的知识增益代码生成框架。该框架旨在从用户绘制的界面草图中自动生成GIS基于Web的应用程序。&lt;h4&gt;方法&lt;/h4&gt;介绍了一种新颖的方法，即上下文感知视觉提示技术，使用Python实现从草图中提取布局和界面特性，并将其应用于指导代码生成。采用大规模语言模型（LLMs），结合结构化推理、软件工程原则以及领域知识，生成前端代码。&lt;h4&gt;主要发现&lt;/h4&gt;案例研究展示了框架能够根据用户绘制的草图自动生成一个模块化的、可维护的Web平台来托管多个仪表板，用于展示环境和能源数据。通过采用以知识驱动的方法，该框架使用诸如Model-View-ViewModel（MVVM）等设计模式和React之类的前端框架生成大规模的标准代码。&lt;h4&gt;结论&lt;/h4&gt;这种方法大大减少了手动设计和编码的工作量，并为智慧城市软件开发开创了一种自动化且高效的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing web-based GIS applications, commonly known as CyberGIS dashboards,for querying and visualizing GIS data in environmental research often demandsrepetitive and resource-intensive efforts. While Generative AI offersautomation potential for code generation, it struggles with complex scientificapplications due to challenges in integrating domain knowledge, softwareengineering principles, and UI design best practices. This paper introduces aknowledge-augmented code generation framework that retrieves softwareengineering best practices, domain expertise, and advanced technology stacksfrom a specialized knowledge base to enhance Generative Pre-trainedTransformers (GPT) for front-end development. The framework automates thecreation of GIS-based web applications (e.g., dashboards, interfaces) fromuser-defined UI wireframes sketched in tools like PowerPoint or AdobeIllustrator. A novel Context-Aware Visual Prompting method, implemented inPython, extracts layouts and interface features from these wireframes to guidecode generation. Our approach leverages Large Language Models (LLMs) togenerate front-end code by integrating structured reasoning, softwareengineering principles, and domain knowledge, drawing inspiration fromChain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). Acase study demonstrates the framework's capability to generate a modular,maintainable web platform hosting multiple dashboards for visualizingenvironmental and energy data (e.g., time-series, shapefiles, rasters) fromuser-sketched wireframes. By employing a knowledge-driven approach, theframework produces scalable, industry-standard front-end code using designpatterns such as Model-View-ViewModel (MVVM) and frameworks like React. Thissignificantly reduces manual effort in design and coding, pioneering anautomated and efficient method for developing smart city software.</description>
      <author>example@mail.com (Haowen Xu, Xiao-Ying Yu)</author>
      <guid isPermaLink="false">2502.08756v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Robot Pouring: Identifying Causes of Spillage and Selecting Alternative Action Parameters Using Probabilistic Actual Causation</title>
      <link>http://arxiv.org/abs/2502.09395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了使用概率实际因果关系来确定导致观察到的不良结果的因素，并展示了如何利用这种因果概率找到替代行动以改变结果。研究应用此分析于机器人倒水任务中，当出现洒漏时，通过分析可以识别出导致这一问题的具体参数以及应如何调整这些参数。&lt;h4&gt;背景&lt;/h4&gt;在日常生活或工作中，我们执行各种任务（如烹饪、清洁）并会遇到意外或不希望的结果。面对这种情况时，我们会采取补救措施直到达成预期目标。&lt;h4&gt;目的&lt;/h4&gt;通过研究概率因果关系的应用来确定导致不良结果的因素，并提出如何找到替代行动以改变这些结果的方法。&lt;h4&gt;方法&lt;/h4&gt;论文采用了一个完整的因果建模过程（包括任务分析、变量定义、因果图结构的决定以及条件概率分布的估计），利用机器人倒水任务的真实模拟数据，涵盖了大量组合的任务参数。基于这些要求和数据进行研究分析。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析可以识别出导致不良结果的具体因素，并能够建议调整方法来避免这些问题；同时展示了实际因果分析在选择替代行动参数中的实用价值。&lt;h4&gt;结论&lt;/h4&gt;论文证明了概率因果关系分析的有效性，不仅可以帮助确定问题原因，还能指导采取适当的补救措施。这表明该技术有潜力用于更广泛的自动化任务中以提高效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了使用概率实际因果推理来判断一个因素是否是导致观察到的不良结果的原因，并展示了如何利用这种因果性概率找到替代行动以改变结果。通过在机器人倒水任务中的应用，当出现洒漏时，该分析能够识别出特定的任务参数作为原因并提出应采取何种调整措施。研究需要构建任务的因果图和相应的条件概率分布，为此进行了全面的因果建模过程，包括使用真实模拟数据进行任务分析、变量定义、决定因果结构以及估计条件概率分布等步骤。基于这些结果，讨论了变量表示的意义，并比较了实际因果性分析提出的替代解决方案与人类观察者可能提出的不同之处。此外，还展示了选择替代行动参数的实际因果性分析的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In everyday life, we perform tasks (e.g., cooking or cleaning) that involve alarge variety of objects and goals. When confronted with an unexpected orunwanted outcome, we take corrective actions and try again until achieving thedesired result. The reasoning performed to identify a cause of the observedoutcome and to select an appropriate corrective action is a crucial aspect ofhuman reasoning for successful task execution. Central to this reasoning is theassumption that a factor is responsible for producing the observed outcome. Inthis paper, we investigate the use of probabilistic actual causation todetermine whether a factor is the cause of an observed undesired outcome.Furthermore, we show how the actual causation probabilities can be used to findalternative actions to change the outcome. We apply the probabilistic actualcausation analysis to a robot pouring task. When spillage occurs, the analysisindicates whether a task parameter is the cause and how it should be changed toavoid spillage. The analysis requires a causal graph of the task and thecorresponding conditional probability distributions. To fulfill theserequirements, we perform a complete causal modeling procedure (i.e., taskanalysis, definition of variables, determination of the causal graph structure,and estimation of conditional probability distributions) using data from arealistic simulation of the robot pouring task, covering a large combinatorialspace of task parameters. Based on the results, we discuss the implications ofthe variables' representation and how the alternative actions suggested by theactual causation analysis would compare to the alternative solutions proposedby a human observer. The practical use of the analysis of probabilistic actualcausation to select alternative action parameters is demonstrated.</description>
      <author>example@mail.com (Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill)</author>
      <guid isPermaLink="false">2502.09395v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable Reinforcement Learning with Biologically Inspired Hyperdimensional Occupancy Grid Maps for Exploration and Goal-Directed Path Planning</title>
      <link>http://arxiv.org/abs/2502.09393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;实时自主系统采用多层次计算框架来执行感知、目标寻找和路径规划等关键任务。本文研究了一种基于向量符号架构（VSA）的超维度空间中的概率占域网格映射方法，将其与传统的贝叶斯希尔伯特图谱（BHM）进行比较，并在强化学习环境下的目标寻找及路径规划中测试其性能。&lt;h4&gt;背景&lt;/h4&gt;实时自主系统利用多层次计算框架执行任务。传统方法使用占域网格映射（OGM），通过概率信息将环境分割为离散单元格，而最近的方法采用基于生物灵感的向量符号架构（VSA）来实现超维度空间中的概率OGM。&lt;h4&gt;目的&lt;/h4&gt;评估VSA-OGM在下游任务上的表现，并将其与传统的OGM方法进行比较。研究旨在确定VSA-OGM是否可以作为神经形态替代方案用于大规模集成中。&lt;h4&gt;方法&lt;/h4&gt;该研究在一个受控探索环境中和一个F1-Tenth挑战启发的自动驾驶场景中，将VSA-OGM的方法与传统OGM方法（贝叶斯希尔伯特图谱BHM）进行比较。评估了它们在强化学习框架下的目标寻找和路径规划中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，在单个及多情景训练配置下，VSA-OGM保持了与BHM相当的学习性能，并且在未见环境中性能提高了大约47%，这表明使用VSA-OGM进行政策网络培训具有更高的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究表明VSA-OGM方法不仅能够提供类似于传统占域网格映射的方法的性能，而且还能提高系统对于新环境的适应性。该研究强调了在各种环境下部署神经形态计算的可能性和价值。&lt;h4&gt;翻译&lt;/h4&gt;实时自主系统采用多层次计算框架来执行任务如感知、目标寻找和路径规划等关键操作。传统方法使用占域网格映射（OGM）通过概率信息分割环境为离散单元格，而最近的方法则利用基于生物灵感的数学模型向量符号架构（VSA），在超维度空间中进行概率OGM的操作。尽管这一新方法与突触神经网络天然兼容并显示出了作为现有OGM方法替代品的应用潜力，但在大规模集成中需要评估其对下游任务的影响。研究旨在通过强化学习框架下目标寻找和路径规划的性能测试，比较VSA-OGM方法在受控探索环境及F1-Tenth挑战启发的自动驾驶场景中的表现与传统的贝叶斯希尔伯特图谱（BHM）的表现。结果显示，在单个和多情景训练配置下，VSA-OGM保持了类似的学习效果，且在未见环境中性能提高了大约47%，这表明使用VSA-OGM进行策略网络培训的泛化能力更强，增强了其实际应用中部署的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time autonomous systems utilize multi-layer computational frameworks toperform critical tasks such as perception, goal finding, and path planning.Traditional methods implement perception using occupancy grid mapping (OGM),segmenting the environment into discretized cells with probabilisticinformation. This classical approach is well-established and provides astructured input for downstream processes like goal finding and path planningalgorithms. Recent approaches leverage a biologically inspired mathematicalframework known as vector symbolic architectures (VSA), commonly known ashyperdimensional computing, to perform probabilistic OGM in hyperdimensionalspace. This approach, VSA-OGM, provides native compatibility with spikingneural networks, positioning VSA-OGM as a potential neuromorphic alternative toconventional OGM. However, for large-scale integration, it is essential toassess the performance implications of VSA-OGM on downstream tasks compared toestablished OGM methods. This study examines the efficacy of VSA-OGM against atraditional OGM approach, Bayesian Hilbert Maps (BHM), within reinforcementlearning based goal finding and path planning frameworks, across a controlledexploration environment and an autonomous driving scenario inspired by theF1-Tenth challenge. Our results demonstrate that VSA-OGM maintains comparablelearning performance across single and multi-scenario training configurationswhile improving performance on unseen environments by approximately 47%. Thesefindings highlight the increased generalizability of policy networks trainedwith VSA-OGM over BHM, reinforcing its potential for real-world deployment indiverse environments.</description>
      <author>example@mail.com (Shay Snyder, Ryan Shea, Andrew Capodieci, David Gorsich, Maryam Parsa)</author>
      <guid isPermaLink="false">2502.09393v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.09389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了S$^2$-Diffusion，一种开放词汇的技能学习策略，能够使机器人从实例级别的训练数据中泛化到类别级别，从而实现在同一类别的不同实例间转移技能。&lt;h4&gt;背景&lt;/h4&gt;最近在技能学习领域的进展使得机器人操纵技术得以实现复杂任务的学习。然而，这些技能通常局限于特定的动作、物体和环境实例，并且难以迁移到相同类别但未展示的实例上。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法S$^2$-Diffusion来解决现有技能学习中跨同类不同实例迁移的问题，使机器人能够在更多场景下应用其学到的技能。&lt;h4&gt;方法&lt;/h4&gt;通过结合可提示语义模块与空间表示功能，S$^2$-Diffusion能够捕捉到技能的功能特性，并利用深度估计网络仅用单个RGB摄像头实现这些技能的应用。&lt;h4&gt;主要发现&lt;/h4&gt;该研究在模拟环境和真实世界中多样化的机器人操纵任务上进行了评估和比较。结果显示，S$^2$-Diffusion对类别无关因素的变化具有不变性，并且即使没有针对特定实例进行训练也能在相同类别的其他实例上实现令人满意的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了机器人技能学习领域的一个重要进步，使得机器人能够更好地适应新的操作场景和物体类型。这表明使用开放词汇模型可以显著提高机器人的任务灵活性和适应性。&lt;h4&gt;翻译&lt;/h4&gt;最近的技能学习进展推动了机器人操纵技术的发展，使其能够在展示一定数量演示的情况下学会复杂的操纵任务。然而，这些技能往往局限于训练数据中显示的具体行动、对象和环境实例，并且很难转移到同一类别的其他实例上。在这项工作中，我们提出了一种开放词汇的空间语义扩散策略S$^2$-Diffusion，它使得机器人可以从实例级别的训练数据泛化到类别级别，从而使技能能够在同一类别的不同实例间转移。研究显示，通过可提示的语义模块和空间表示结合的功能可以捕捉技能的功能方面，并且我们还提出利用深度估计网络以允许仅使用单个RGB相机实现这些功能。该方法在模拟环境和真实世界的多种机器人操纵任务上进行了评估和比较。结果显示S$^2$-Diffusion对于类别无关因素的变化具有不变性，同时能够在同一类别的其他实例中实现令人满意的表现，即使没有针对特定实例进行训练。所有实际世界实验的完整视频可在补充材料中获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in skill learning has propelled robot manipulation to newheights by enabling it to learn complex manipulation tasks from a practicalnumber of demonstrations. However, these skills are often limited to theparticular action, object, and environment \textit{instances} that are shown inthe training data, and have trouble transferring to other instances of the samecategory. In this work we present an open-vocabulary Spatial-Semantic Diffusionpolicy (S$^2$-Diffusion) which enables generalization from instance-leveltraining data to category-level, enabling skills to be transferable betweeninstances of the same category. We show that functional aspects of skills canbe captured via a promptable semantic module combined with a spatialrepresentation. We further propose leveraging depth estimation networks toallow the use of only a single RGB camera. Our approach is evaluated andcompared on a diverse number of robot manipulation tasks, both in simulationand in the real world. Our results show that S$^2$-Diffusion is invariant tochanges in category-irrelevant factors as well as enables satisfyingperformance on other instances within the same category, even if it was nottrained on that specific instance. Full videos of all real-world experimentsare available in the supplementary material.</description>
      <author>example@mail.com (Quantao Yang, Michael C. Welle, Danica Kragic, Olov Andersson)</author>
      <guid isPermaLink="false">2502.09389v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>TRIFFID: Autonomous Robotic Aid For Increasing First Responders Efficiency</title>
      <link>http://arxiv.org/abs/2502.09379v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TRIFFID系统是一个综合技术框架，旨在利用无人驾驶地面和空中车辆以及先进的AI功能来提升灾难应对能力。&lt;h4&gt;背景&lt;/h4&gt;自然灾害事故的复杂性增加需要创新的技术解决方案以支持救援人员的工作。&lt;h4&gt;目的&lt;/h4&gt;引入TRIFFID系统，该系统通过整合无人车、无人机、先进的人工智能技术等功能增强在森林火灾、城市洪水和地震后的搜救任务中的响应能力。&lt;h4&gt;方法&lt;/h4&gt;利用先进的自主导航、语义感知和技术，并结合智能手机应用、中央地面站和定制通信基础设施等组件来开发TRIFFID系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过深度神经网络，知识图谱以及多模态信息融合技术使机器人能够自动导航并分析灾难环境，减少了人员风险，加快了响应时间。&lt;h4&gt;结论&lt;/h4&gt;该系统增强了应急团队的高级任务规划、安全监控和自适应任务执行能力，并确保在复杂且危险的情况下提供实时情况感知和支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个旨在通过整合无人驾驶车辆与先进人工智能技术来提高自然灾害应对能力的技术框架——TRIFFID系统的介绍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing complexity of natural disaster incidents demands innovativetechnological solutions to support first responders in their efforts. Thispaper introduces the TRIFFID system, a comprehensive technical framework thatintegrates unmanned ground and aerial vehicles with advanced artificialintelligence functionalities to enhance disaster response capabilities acrosswildfires, urban floods, and post-earthquake search and rescue missions. Byleveraging state-of-the-art autonomous navigation, semantic perception, andhuman-robot interaction technologies, TRIFFID provides a sophisticated systemcom- posed of the following key components: hybrid robotic platform,centralized ground station, custom communication infrastructure, and smartphoneapplication. The defined research and development activities demonstrate howdeep neural networks, knowledge graphs, and multimodal information fusion canenable robots to autonomously navigate and analyze disaster environ- ments,reducing personnel risks and accelerating response times. The proposed systemenhances emergency response teams by providing advanced mission planning,safety monitoring, and adaptive task execution capabilities. Moreover, itensures real- time situational awareness and operational support in complex andrisky situations, facilitating rapid and precise information collection andcoordinated actions.</description>
      <author>example@mail.com (Jorgen Cani, Panagiotis Koletsis, Konstantinos Foteinos, Ioannis Kefaloukos, Lampros Argyriou, Manolis Falelakis, Iván Del Pino, Angel Santamaria-Navarro, Martin Čech, Ondřej Severa, Alessandro Umbrico, Francesca Fracasso, AndreA Orlandini, Dimitrios Drakoulis, Evangelos Markakis, Georgios Th. Papadopoulos)</author>
      <guid isPermaLink="false">2502.09379v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Moving Matter: Efficient Reconfiguration of Tile Arrangements by a Single Active Robot</title>
      <link>http://arxiv.org/abs/2502.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用一个单一的主动机器人重新配置二维连通网格上的被动建筑模块的问题，目标是在保证瓷砖布局始终连通的情况下找到最小化总体完成时间（makespan）的重新配置方案。&lt;h4&gt;背景&lt;/h4&gt;在二维空间中，通过移动和转移单个瓷砖来重新配置由被动组件构成的连通网格布局是一个挑战性问题。&lt;h4&gt;目的&lt;/h4&gt;确定一种能够最小化总工时并确保结构始终连通的再配置策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一个参数化的通用版本，该版本引入了根据携带或不携带瓷砖移动的成本加权的问题，证明其为NP完全问题；同时提供了一种针对起始和目标边界框互斥情况下的近似算法，并且对于2倍缩放实例给出了最优搬运距离。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '提出了具有移动成本的通用化版本并证明其NP完全性', '2': '提供了针对分离起始及目标边界的多项式时间近似算法'}&lt;h4&gt;结论&lt;/h4&gt;虽然问题本身非常困难（NP完全），但对于特定条件下的场景，可以找到有效的解决策略。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑了从初始布局到目标布局重新配置二维连通网格排列的被动构建块的问题，使用单个可以在瓷砖上移动、在给定位置移除个别瓷砖并将其物理地转移到新位置上的主动机器人。目的是确定一个最小化总体完成时间（makespan）的同时确保瓷砖布置保持连接的再配置计划。我们提供了既包括否定性也包含积极的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of reconfiguring a two-dimensional connected gridarrangement of passive building blocks from a start configuration to a goalconfiguration, using a single active robot that can move on the tiles, removeindividual tiles from a given location and physically move them to a newposition by walking on the remaining configuration. The objective is todetermine a reconfiguration schedule that minimizes the overall makespan, whileensuring that the tile configuration remains connected. We provide bothnegative and positive results. (1) We present a generalized version of theproblem, parameterized by weighted costs for moving with or without tiles, andshow that this is NP-complete. (2) We give a polynomial-time constant-factorapproximation algorithm for the case of disjoint start and target boundingboxes. In addition, our approach yields optimal carry distance for 2-scaledinstances.</description>
      <author>example@mail.com (Aaron T. Becker, Sándor P. Fekete, Jonas Friemel, Ramin Kosfeld, Peter Kramer, Harm Kube, Christian Rieck, Christian Scheffer, Arne Schmidt)</author>
      <guid isPermaLink="false">2502.09299v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Safety Evaluation of Human Arm Operations Using IMU Sensors with a Spring-Damper-Mass Predictive Model</title>
      <link>http://arxiv.org/abs/2502.09241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的实时安全监测方法，用于人机协作制造环境，通过在手腕上安装惯性测量单元（IMU）系统并集成预测安全性模型（PSM）。该系统基于弹簧-阻尼-质量模型进行优化，适用于手腕运动，并采用基于阻抗的概率安全性评估。&lt;h4&gt;背景&lt;/h4&gt;现有的预测安全性模型无法完全适应人机协作制造环境中复杂的手腕动作。传统的安全方法可能不够灵活和精确。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的实时监测系统，以提高人机协作环境中的安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于阻抗的安全性评估方法，并使用频域分析方法进行定量化的安全阈值的建立。通过三个制造任务（工具操作、视觉检查以及抓取放置）进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在各种制造场景中表现出强大的性能，同时通过优化参数选择保持了计算效率。&lt;h4&gt;结论&lt;/h4&gt;这项工作为未来实时适应性风险评估的发展奠定了基础，在人机协作制造环境中具有重要应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的完整中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to real-time safety monitoring inhuman-robot collaborative manufacturing environments through a wrist-mountedInertial Measurement Unit (IMU) system integrated with a Predictive SafetyModel (PSM). The proposed system extends previous PSM implementations throughthe adaptation of a spring-damper-mass model specifically optimized for wristmotions, employing probabilistic safety assessment through impedance-basedcomputations. We analyze our proposed impedance-based safety approach withfrequency domain methods, establishing quantitative safety thresholds throughcomprehensive comparative analysis. Experimental validation across threemanufacturing tasks - tool manipulation, visual inspection, and pick-and-placeoperations. Results show robust performance across diverse manufacturingscenarios while maintaining computational efficiency through optimizedparameter selection. This work establishes a foundation for future developmentsin adaptive risk assessment in real-time for human-robot collaborativemanufacturing environments.</description>
      <author>example@mail.com (Musab Zubair Inamdar, Seyed Amir Tafrishi)</author>
      <guid isPermaLink="false">2502.09241v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>A Machine Learning Approach to Sensor Substitution for Non-Prehensile Manipulation</title>
      <link>http://arxiv.org/abs/2502.09180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, submitted to IEEE Robotics and Automation  Letters, for associated video, see https://youtu.be/Cl6nTBtCaGU&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于机器学习的框架，该框架允许配备有限传感器集（如激光雷达或RGB-D相机）的机器人有效地执行原本依赖更丰富传感器套件（如触觉皮肤）的任务。&lt;h4&gt;背景&lt;/h4&gt;移动机械臂被部署在复杂环境中时需要各种各样的传感器进行感知和交互。然而，并非每个机器人都可以装备所有类型的传感器，因为成本和技术限制的存在使得这变得不切实际。&lt;h4&gt;目的&lt;/h4&gt;解决不同传感器能力的机器人之间协作或执行类似任务的问题。具体来说，当拥有高分辨率触觉皮肤的移动机械臂需要被没有此类触觉感应功能的机器人替换时，学习到的操作策略将不再适用。&lt;h4&gt;方法&lt;/h4&gt;提出了一种机器学习框架，该框架可以学习可用传感器数据和被替代传感器提供的信息之间的映射关系，从而有效地合成缺失的感官输入。通过训练模型来用激光雷达或RGB-D相机代替触觉皮肤的数据来进行非抓取操作任务（如推动）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在经过训练后，配备仅使用激光雷达或RGB-D相机的机械臂在执行非抓取式推动任务时可以达到与直接利用触觉反馈进行操作的移动基础相当甚至更好的性能。&lt;h4&gt;结论&lt;/h4&gt;本研究证明了一种有效的传感器替代方法，并为未来基于机器人的多传感器协作应用提供了可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile manipulators are increasingly deployed in complex environments,requiring diverse sensors to perceive and interact with their surroundings.However, equipping every robot with every possible sensor is often impracticaldue to cost and physical constraints. A critical challenge arises when robotswith differing sensor capabilities need to collaborate or perform similartasks. For example, consider a scenario where a mobile manipulator equippedwith high-resolution tactile skin is skilled at non-prehensile manipulationtasks like pushing. If this robot needs to be replaced or augmented by a robotlacking such tactile sensing, the learned manipulation policies becomeinapplicable. This paper addresses the problem of sensor substitution innon-prehensile manipulation. We propose a novel machine learning-basedframework that enables a robot with a limited sensor set (e.g., LiDAR or RGB-Dcamera) to effectively perform tasks previously reliant on a richer sensorsuite (e.g., tactile skin). Our approach learns a mapping between the availablesensor data and the information provided by the substituted sensor, effectivelysynthesizing the missing sensory input. Specifically, we demonstrate theefficacy of our framework by training a model to substitute tactile skin datafor the task of non-prehensile pushing using a mobile manipulator. We show thata manipulator equipped only with LiDAR or RGB-D can, after training, achievecomparable and sometimes even better pushing performance to a mobile baseutilizing direct tactile feedback.</description>
      <author>example@mail.com (Idil Ozdamar, Doganay Sirintuna, Arash Ajoudani)</author>
      <guid isPermaLink="false">2502.09180v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement</title>
      <link>http://arxiv.org/abs/2502.09170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为LimSim Series的综合模拟平台，旨在解决自动驾驶系统（ADS）验证和改进中的挑战。&lt;h4&gt;背景&lt;/h4&gt;闭合回路模拟环境在验证和增强自动驾驶系统的性能方面扮演着关键角色。然而，在准确性与持续时间平衡、功能与实用性协调以及全面评估机制建立等方面存在一些挑战。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，本文提出了LimSim Series平台，该平台支持ADS的快速部署和有效迭代。&lt;h4&gt;方法&lt;/h4&gt;LimSim Series整合了道路网络中的多类型信息，采用了类似人类决策规划算法以增强背景车辆的行为，并引入了“兴趣区域”（AoI）的概念来优化计算资源。此外，它还提供了一系列基准算法和用户友好的界面，使多个技术流程的灵活验证成为可能。&lt;h4&gt;主要发现&lt;/h4&gt;LimSim Series支持模块化、端到端以及基于视觉语言模型的知识驱动系统，并能够评估不同场景下的性能表现。&lt;h4&gt;结论&lt;/h4&gt;实验表明，LimSim Series可以辅助自动驾驶系统的迭代和更新。该平台的代码已在GitHub上公开发布。&lt;h4&gt;翻译&lt;/h4&gt;封闭循环模拟环境在验证和增强自动车辆驾驶（ADS）系统的有效性方面发挥着至关重要的作用。但是，在确保模拟准确性的同时缩短持续时间、平衡功能与实用性以及建立全面评估机制等方面存在一些挑战。本文通过介绍LimSim系列，一个全面的仿真平台来解决这些问题，该平台旨在支持快速部署和有效迭代自动驾驶系统，并集成了多种类型的道路网络信息，采用了类似人类决策规划算法增强背景车辆的行为，并引入了兴趣区域（AoI）的概念以优化计算资源。此外，它还提供了一系列基准算法和用户友好的界面，使灵活验证各种技术流程成为可能，同时提供了多维度的评估指标来全面了解系统的性能表现，从而帮助研究人员快速发现并改进问题。实验结果表明LimSim系列能够兼容模块化、端到端以及基于视觉语言模型的知识驱动系统，并在不同场景下进行性能评价以支持自动驾驶系统的迭代和更新。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Closed-loop simulation environments play a crucial role in the validation andenhancement of autonomous driving systems (ADS). However, certain challengeswarrant significant attention, including balancing simulation accuracy withduration, reconciling functionality with practicality, and establishingcomprehensive evaluation mechanisms. This paper addresses these challenges byintroducing the LimSim Series, a comprehensive simulation platform designed tosupport the rapid deployment and efficient iteration of ADS. The LimSim Seriesintegrates multi-type information from road networks, employs human-likedecision-making and planning algorithms for background vehicles, and introducesthe concept of the Area of Interest (AoI) to optimize computational resources.The platform offers a variety of baseline algorithms and user-friendlyinterfaces, facilitating flexible validation of multiple technical pipelines.Additionally, the LimSim Series incorporates multi-dimensional evaluationmetrics, delivering thorough insights into system performance, thus enablingresearchers to promptly identify issues for further improvements. Experimentsdemonstrate that the LimSim Series is compatible with modular, end-to-end, andVLM-based knowledge-driven systems. It can assist in the iteration and updatingof ADS by evaluating performance across various scenarios. The code of theLimSim Series is released at: https://github.com/PJLab-ADG/LimSim.</description>
      <author>example@mail.com (Daocheng Fu, Naiting Zhong, Xu Han, Pinlong Cai, Licheng Wen, Song Mao, Botian Shi, Yu Qiao)</author>
      <guid isPermaLink="false">2502.09170v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation</title>
      <link>http://arxiv.org/abs/2502.09142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as conference proceeding in International Conference on  Human-Computer Interaction 2025 (HCI International 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人技术和增强现实（AR）的结合为提升人机交互（HRI）提供了变革性的机会，通过改善可用性、直观性和可访问性。&lt;h4&gt;目的&lt;/h4&gt;介绍一种无需控制器、基于大型语言模型驱动的声音指令型AR操控系统，使用户能够实时操作机器人的虚拟版本以远程控制实体机器人。&lt;h4&gt;方法&lt;/h4&gt;利用自然语言处理（NLP）技术和AR技术构建了一个原型系统，使用Meta Quest 3设备进行开发。此系统通过语音命令实现对虚拟机器人的直接操纵，并省去了物理控制器的需求，从而提升了用户体验并减少了潜在的安全风险。&lt;h4&gt;主要发现&lt;/h4&gt;初步用户演示成功验证了系统的功能，展示了其在提供更安全、更具直观性及沉浸式的机器人控制方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;该工作表明无需实体控制器的基于语音命令和AR技术的人机交互系统具有实际应用价值，并为未来的HRI研究提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将机器人技术和增强现实（AR）相结合，通过改善可用性、直观性和可访问性，可以推动人机交互（HRI）的发展。本工作介绍了一种无需控制器的大型语言模型驱动的声音指令型AR操控系统，用户可以通过实时操作虚拟机器人的方式远程控制实体机器人。利用自然语言处理（NLP）技术和增强现实技术，我们的系统——使用Meta Quest 3原型构建——消除了物理控制器的需求，提高了易用性并减少了直接操作机器人时的潜在安全风险。初步用户演示成功地验证了系统的功能，展示了其在提供更安全、更具直观性和沉浸感的机器人控制方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of robotics and augmented reality (AR) presentstransformative opportunities for advancing human-robot interaction (HRI) byimproving usability, intuitiveness, and accessibility. This work introduces acontroller-free, LLM-driven voice-commanded AR puppeteering system, enablingusers to teleoperate a robot by manipulating its virtual counterpart in realtime. By leveraging natural language processing (NLP) and AR technologies, oursystem -- prototyped using Meta Quest 3 -- eliminates the need for physicalcontrollers, enhancing ease of use while minimizing potential safety risksassociated with direct robot operation. A preliminary user demonstrationsuccessfully validated the system's functionality, demonstrating its potentialfor safer, more intuitive, and immersive robotic control.</description>
      <author>example@mail.com (Yuchong Zhang, Bastian Orthmann, Michael C. Welle, Jonne Van Haastregt, Danica Kragic)</author>
      <guid isPermaLink="false">2502.09142v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>DenseSplat: Densifying Gaussian Splatting SLAM with Neural Radiance Prior</title>
      <link>http://arxiv.org/abs/2502.09111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的SLAM系统DenseSplat，该系统结合了NeRF和3DGS的优点，在稀疏视图条件下能够有效填充地图中的空白区域。&lt;h4&gt;背景&lt;/h4&gt;高斯SLAM系统在实时渲染和精细化重建方面优于基于NeRF的系统。然而，其依赖于大量关键帧的问题使其难以部署到实际机器人中，因为实际情况通常需要处理稀疏视角条件下的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以高效利用稀疏关键帧并填充地图空白区域的SLAM系统，以提高其实用性和性能。&lt;h4&gt;方法&lt;/h4&gt;DenseSplat使用了NeRF先验知识来初始化可以在地图中密集填充的原始体，并实现了感知几何的采样和修剪策略。此外，该系统还集成了闭环检测和捆绑调整功能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个大规模数据集上，DenseSplat在跟踪和建图方面的表现优于当前最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;DenseSplat克服了传统SLAM系统的局限性，提供了一种新的解决方案来解决稀疏视图条件下地图重建的问题。&lt;h4&gt;翻译&lt;/h4&gt;Gaussian SLAM系统在实时渲染和精细化重建方面比基于NeRF的系统更优。然而，在实际机器人应用中，它们对大量关键帧的需求是不切实际的，因为通常情况下，这些场景需要处理的是稀疏视角条件下的问题。为了解决这些问题，我们引入了DenseSplat，这是第一个有效结合NeRF和3DGS优势的SLAM系统。它使用稀疏的关键帧和NeRF先验知识来初始化填充地图的原始体，并实施感知几何学采样和修剪策略以管理粒度并提高渲染效率。此外，该系统还集成了闭环检测和捆绑调整功能，显著提高了帧间跟踪的准确性。在多个大规模数据集上的广泛实验表明，与当前最先进的方法相比，DenseSplat在跟踪和映射方面取得了更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gaussian SLAM systems excel in real-time rendering and fine-grainedreconstruction compared to NeRF-based systems. However, their reliance onextensive keyframes is impractical for deployment in real-world roboticsystems, which typically operate under sparse-view conditions that can resultin substantial holes in the map. To address these challenges, we introduceDenseSplat, the first SLAM system that effectively combines the advantages ofNeRF and 3DGS. DenseSplat utilizes sparse keyframes and NeRF priors forinitializing primitives that densely populate maps and seamlessly fill gaps. Italso implements geometry-aware primitive sampling and pruning strategies tomanage granularity and enhance rendering efficiency. Moreover, DenseSplatintegrates loop closure and bundle adjustment, significantly enhancingframe-to-frame tracking accuracy. Extensive experiments on multiple large-scaledatasets demonstrate that DenseSplat achieves superior performance in trackingand mapping compared to current state-of-the-art methods.</description>
      <author>example@mail.com (Mingrui Li, Shuhong Liu, Tianchen Deng, Hongyu Wang)</author>
      <guid isPermaLink="false">2502.09111v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>MTDP: Modulated Transformer Diffusion Policy Model</title>
      <link>http://arxiv.org/abs/2502.09029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的Transformer架构——调制化Transformer扩散策略（MTDP）模型，用于提高机器人基于行为克隆的任务学习效率。&lt;h4&gt;背景&lt;/h4&gt;近期研究通过将扩散模型与行为克隆结合提出了扩散策略，显著提高了机器人的任务成功率。但是，高容量Transformer在整合引导条件时存在困难，导致使用此类架构的模型在操纵任务中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的调制化注意力模块来改进传统Transformer结构，以有效解决指导条件的集成问题，并提高生成模型输出质量。&lt;h4&gt;方法&lt;/h4&gt;引入了Modulated Transformer Diffusion Policy（MTDP）和Modulated UNet Diffusion Policy（MUDP）两种模型。其中核心是通过提出的调制化注意力模块来更有效地将引导条件与主要输入结合，同时探索使用Denoising Diffusion Implicit Models (DDIM)作为扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示MTDP在六项任务中表现优于现有Transformer架构，在Toolhang实验中的成功率提高了12%。而MUDP则普遍超越了现有的UNet架构的性能。另外，采用DDIM作为扩散模型的MTDP-I和MUDP-I几乎将生成速度翻倍。&lt;h4&gt;结论&lt;/h4&gt;通过提出调制化注意力模块改进Transformer结构，显著提升了机器人操作任务的成功率，并且提高了生成效率。&lt;h4&gt;翻译&lt;/h4&gt;近期关于基于行为克隆（BC）的机器人操纵研究已经取得了重大进展。通过结合扩散模型与BC提出了扩散策略，使机器人能够快速学习高成功率的操作任务。然而，在将扩散政策与大型变压器整合时遇到了挑战，传统的Transformer架构难以有效融合引导条件，在使用Transformer基模型进行操作任务时表现不佳。本文探讨了Transformer的关键架构设计，并通过提出调制化注意力模块改进传统Transformer结构，以提升生成模型的输出质量及机器人任务成功率。在六项实验中，MTDP优于现有Transformer架构，尤其是在Toolhang实验中成功率为12%的增幅。为验证调制化注意的有效性，将其应用于UNet架构构建Modulated UNet Diffusion Policy（MUDP），该模型也超越了所有六个实验中的现有UNet架构的成功率。扩散政策使用去噪扩散概率模型作为扩散模型，并基于此探索了DDIM，以创建MTDP-I和MUDP-I模型，几乎使生成速度翻倍同时保持性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research on robot manipulation based on Behavior Cloning (BC) has madesignificant progress. By combining diffusion models with BC, diffusion policiyhas been proposed, enabling robots to quickly learn manipulation tasks withhigh success rates. However, integrating diffusion policy with high-capacityTransformer presents challenges, traditional Transformer architectures struggleto effectively integrate guiding conditions, resulting in poor performance inmanipulation tasks when using Transformer-based models. In this paper, weinvestigate key architectural designs of Transformers and improve thetraditional Transformer architecture by proposing the Modulated TransformerDiffusion Policy (MTDP) model for diffusion policy. The core of this model isthe Modulated Attention module we proposed, which more effectively integratesthe guiding conditions with the main input, improving the generative model'soutput quality and, consequently, increasing the robot's task success rate. Insix experimental tasks, MTDP outperformed existing Transformer modelarchitectures, particularly in the Toolhang experiment, where the success rateincreased by 12\%. To verify the generality of Modulated Attention, we appliedit to the UNet architecture to construct Modulated UNet Diffusion Policy model(MUDP), which also achieved higher success rates than existing UNetarchitectures across all six experiments. The Diffusion Policy uses DenoisingDiffusion Probabilistic Models (DDPM) as the diffusion model. Building on this,we also explored Denoising Diffusion Implicit Models (DDIM) as the diffusionmodel, constructing the MTDP-I and MUDP-I model, which nearly doubled thegeneration speed while maintaining performance.</description>
      <author>example@mail.com (Qianhao Wang, Yinqian Sun, Enmeng Lu, Qian Zhang, Yi Zeng)</author>
      <guid isPermaLink="false">2502.09029v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>SkyRover: A Modular Simulator for Cross-Domain Pathfinding</title>
      <link>http://arxiv.org/abs/2502.08969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SkyRover的模块化模拟器，用于研究无人飞行器（UAV）和自动导引车（AGV）在多智能体路径查找中的协作。&lt;h4&gt;背景&lt;/h4&gt;现有的模拟器通常专注于单一领域，限制了跨领域的研究。为了克服这一问题，提出了SkyRover以支持更全面的多域算法设计、测试和基准测试。&lt;h4&gt;目的&lt;/h4&gt;提供一种可以用于UAV-AGV多智能体路径查找（MAPF）的通用仿真平台。&lt;h4&gt;方法&lt;/h4&gt;SkyRover具有真实的代理动态，可配置的3D环境以及方便外部求解器和学习方法使用的API接口。该模拟器统一了地面和空中的操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SkyRover能够实现高效的路径查找，并且在UAV-AGV协调中提供高保真的仿真。&lt;h4&gt;结论&lt;/h4&gt;SkyRover是一个强大的工具，用于跨域算法的设计、测试以及基准性能的比较。&lt;h4&gt;翻译&lt;/h4&gt;无人驾驶飞行器（无人机）和自动引导车（AGV）在物流、监视、检查等任务中的合作越来越紧密。然而，现有的模拟器通常专注于单一领域，限制了跨领域的研究。本文提出了一种名为SkyRover的模块化模拟器，用于UAV-AGV多智能体路径查找（MAPF）。SkyRover支持真实的代理动态，可配置的3D环境以及方便外部求解器和学习方法使用的API接口。通过统一地面和空中的操作，它促进了跨领域的算法设计、测试及基准比较。实验表明，SkyRover在UAV-AGV协调中具有高效路径查找和高保真仿真的能力。该项目可以在https://sites.google.com/view/mapf3d/home上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned Aerial Vehicles (UAVs) and Automated Guided Vehicles (AGVs)increasingly collaborate in logistics, surveillance, inspection tasks and etc.However, existing simulators often focus on a single domain, limitingcross-domain study. This paper presents the SkyRover, a modular simulator forUAV-AGV multi-agent pathfinding (MAPF). SkyRover supports realistic agentdynamics, configurable 3D environments, and convenient APIs for externalsolvers and learning methods. By unifying ground and aerial operations, itfacilitates cross-domain algorithm design, testing, and benchmarking.Experiments highlight SkyRover's capacity for efficient pathfinding andhigh-fidelity simulations in UAV-AGV coordination. Project is available athttps://sites.google.com/view/mapf3d/home.</description>
      <author>example@mail.com (Wenhui Ma, Wenhao Li, Bo Jin, Changhong Lu, Xiangfeng Wang)</author>
      <guid isPermaLink="false">2502.08969v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Training Trajectory Predictors Without Ground-Truth Data</title>
      <link>http://arxiv.org/abs/2502.08957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种能够准确平滑地估计位置、航向和速度的框架。基于此高质量输入，我们提出了一个基于Trajectron++系统的模型，能够持续生成精确的轨迹预测。&lt;h4&gt;背景&lt;/h4&gt;传统的轨迹预测模型依赖于地面真实数据进行训练，而这些数据可能难以获取或质量不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖地面真实数据即可有效训练轨迹预测模型的方法，并评估输入数据质量和模型输出之间的关系。&lt;h4&gt;方法&lt;/h4&gt;提出了一个高质量的估计系统框架和基于Trajectron++的预测系统，该系统能够仅依靠自身的估计结果进行学习和改进。&lt;h4&gt;主要发现&lt;/h4&gt;低质量的输入会导致噪声大的和不可靠的预测，这对导航模块不利。同时证明了在缺乏大量训练数据的情况下也能有效训练轨迹预测模型，并产生跨不同环境有效的预测结果。&lt;h4&gt;结论&lt;/h4&gt;准确的估计对于在真实世界场景中部署轨迹预测模型至关重要，而本文提出的方法能够确保无论应用上下文如何都提供有意义和可靠的结果。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种能精确且平滑地估算位置、航向及速度的框架，并基于高质量输入数据开发了一个利用Trajectron++系统的精准轨迹预测系统。不同于需要地面真实数据进行训练的传统模型，本文的方法摆脱了这种依赖性。研究表明低质量输入会导致噪声和不可靠的结果，这对导航模块具有破坏性影响。通过对输入数据质量和模型输出的评估来展示输入噪音的影响，并展示了即使在缺乏大量数据的情况下也能有效训练轨迹预测模型，产生跨不同环境的有效预测结果。精确估计对实际场景中部署这些模型至关重要，该系统能确保无论应用背景如何都能提供有意义且可靠的成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework capable of accurately and smoothly estimatingposition, heading, and velocity. Using this high-quality input, we propose asystem based on Trajectron++, able to consistently generate precise trajectorypredictions. Unlike conventional models that require ground-truth data fortraining, our approach eliminates this dependency. Our analysis demonstratesthat poor quality input leads to noisy and unreliable predictions, which can bedetrimental to navigation modules. We evaluate both input data quality andmodel output to illustrate the impact of input noise. Furthermore, we show thatour estimation system enables effective training of trajectory predictionmodels even with limited data, producing robust predictions across differentenvironments. Accurate estimations are crucial for deploying trajectoryprediction models in real-world scenarios, and our system ensures meaningfuland reliable results across various application contexts.</description>
      <author>example@mail.com (Mikolaj Kliniewski, Jesse Morris, Ian R. Manchester, Viorela Ila)</author>
      <guid isPermaLink="false">2502.08957v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>WanderGuide: Indoor Map-less Robotic Guide for Exploration by Blind People</title>
      <link>http://arxiv.org/abs/2502.08906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;盲人探索环境的机会有限。现有的导航系统虽然可以提供周围信息，但需要预先构建地图，因此可扩展性较差。&lt;h4&gt;目的&lt;/h4&gt;开发一个无需预建地图的机器人辅助系统，让盲人能够根据兴趣自由地探索环境。&lt;h4&gt;方法&lt;/h4&gt;首先在购物商城和科学博物馆进行了一项包含十位盲人的研究以调查系统需求。之后研发了WanderGuide，该系统能让用户调整描述细节的程度，并通过口头互动询问关于环境的信息或前往感兴趣的地方。&lt;h4&gt;主要发现&lt;/h4&gt;通过五名盲人参与的研究表明，WanderGuide能够提供给盲人在心中没有明确目的地的情况下自由漫步的愉快体验。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了用户需要以不同层次详细程度描述周围环境的需求。新研发的系统满足这些需求，并为用户提供了一种更有趣和更有用的方式来探索他们所处的空间。&lt;h4&gt;翻译&lt;/h4&gt;盲人面临着较少机会根据个人兴趣来探索周围环境的问题。虽然现有的导航技术可以在导航过程中提供一些基本信息，但它们依赖于预构建的地图，难以大规模应用。为了开发一种不需要地图的机器人辅助系统以帮助盲人更好地探索环境，研究团队首先进行了包含十名盲人的实地调查，在购物商城和科学博物馆内收集了他们的需求。调查表明用户需要根据自身的喜好对周围环境进行层次化的描述。基于这些信息，他们研发出了WanderGuide。该导航工具能够提供三个不同的详细程度供用户选择，并且可以与系统以语音的方式互动，如询问关于当前位置的细节或前往感兴趣的地点等。五名盲人参与了进一步的研究测试，结果显示WanderGuide能够让使用者享受到没有目的地约束情况下的漫游乐趣。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713788&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blind people have limited opportunities to explore an environment based ontheir interests. While existing navigation systems could provide them withsurrounding information while navigating, they have limited scalability as theyrequire preparing prebuilt maps. Thus, to develop a map-less robot that assistsblind people in exploring, we first conducted a study with ten blindparticipants at a shopping mall and science museum to investigate therequirements of the system, which revealed the need for three levels of detailto describe the surroundings based on users' preferences. Then, we developedWanderGuide, with functionalities that allow users to adjust the level ofdetail in descriptions and verbally interact with the system to ask questionsabout the environment or to go to points of interest. The study with five blindparticipants revealed that WanderGuide could provide blind people with theenjoyable experience of wandering around without a specific destination intheir minds.</description>
      <author>example@mail.com (Masaki Kuribayashi, Kohei Uehara, Allan Wang, Shigeo Morishima, Chieko Asakawa)</author>
      <guid isPermaLink="false">2502.08906v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Data Sensor Fusion In Digital Twin Technology For Enhanced Capabilities In A Home Environment</title>
      <link>http://arxiv.org/abs/2502.08874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了数据传感器融合在数字孪生技术中的应用，以增强家庭环境的功能，并特别关注新冠肺炎疫情带来的挑战及其经济影响。&lt;h4&gt;背景&lt;/h4&gt;研究强调数字化转型不仅有助于适应第四次工业革命的变革，还能缓解其带来的中断。使用Wit Motion传感器收集步行、工作、坐立和躺卧等活动的数据。&lt;h4&gt;目的&lt;/h4&gt;目的是通过结合赛博物理系统、物联网(IoT)、人工智能(AI)和机器人技术来增强数字孪生的能力。&lt;h4&gt;方法&lt;/h4&gt;研究比较了多种传感器融合方法，包括特征级融合、决策级融合以及卡尔曼滤波器融合，并使用支持向量机(SVM)、梯度提升(GBDT)及随机森林(RF)等机器学习模型进行效果评估。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，传感器融合显著提高了这些模型的准确性和可靠性，尤其能弥补单一传感器在磁力计上的弱点。尽管理想条件下精度更高，但多传感器数据整合确保了现实场景下的稳定和可靠结果。&lt;h4&gt;结论&lt;/h4&gt;因此建立了一个稳健的应用系统，可以在实际情景中被信任地采用。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译版本&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the integration of data sensor fusion in digital twintechnology to bolster home environment capabilities, particularly in thecontext of challenges brought on by the coronavirus pandemic and its economiceffects. The study underscores the crucial role of digital transformation innot just adapting to, but also mitigating disruptions during the fourthindustrial revolution. Using the Wit Motion sensor, data was collected foractivities such as walking, working, sitting, and lying, with sensors measuringaccelerometers, gyroscopes, and magnetometers. The research integratesCyber-physical systems, IoT, AI, and robotics to fortify digital twincapabilities.  The paper compares sensor fusion methods, including feature-level fusion,decision-level fusion, and Kalman filter fusion, alongside machine learningmodels like SVM, GBoost, and Random Forest to assess model effectiveness.Results show that sensor fusion significantly improves the accuracy andreliability of these models, as it compensates for individual sensorweaknesses, particularly with magnetometers. Despite higher accuracy in idealconditions, integrating data from multiple sensors ensures more consistent andreliable results in real-world settings, thereby establishing a robust systemthat can be confidently applied in practical scenarios.</description>
      <author>example@mail.com (Benjamin Momoh, Salisu Yahaya)</author>
      <guid isPermaLink="false">2502.08874v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>MuJoCo Playground</title>
      <link>http://arxiv.org/abs/2502.08844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了MuJoCo Playground，这是一个开源的机器人学习框架，旨在简化模拟、训练以及从模拟到现实机器人的迁移。&lt;h4&gt;背景&lt;/h4&gt;现有的机器人学习方法往往需要复杂的设置和长时间的调试才能在实际硬件上运行。&lt;h4&gt;目的&lt;/h4&gt;通过提供一个完全开放源代码的框架来促进研究者快速进行模拟环境下的策略训练，并实现无监督的从模拟环境向真实机器人转移的技术。&lt;h4&gt;方法&lt;/h4&gt;利用MJX技术创建了MuJoCo Playground，该平台支持多种机器人平台（包括四足、人形、灵巧手和机械臂），并整合了一个包含物理引擎、批处理渲染器及训练环境的集成栈。&lt;h4&gt;主要发现&lt;/h4&gt;通过安装pip install playground命令，研究者可以在单个GPU上几分钟内完成策略训练，并且可以从状态输入或像素输入进行零样本模拟到现实机器人的迁移。&lt;h4&gt;结论&lt;/h4&gt;MuJoCo Playground为机器人学习领域提供了新的可能性，使得在真实硬件上的实验变得更加便捷和高效。整个框架及其视频结果都可以免费获取。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了MuJoCo游乐场，这是一个基于MJX完全开源的机器人学习框架，其目的是简化模拟、训练以及从模拟到现实机器人的迁移。通过简单的pip install playground命令安装后，研究人员可以在单个GPU上几分钟内完成策略训练。游乐场支持多种机器人平台（包括四足、人形、灵巧手和机械臂），实现无监督的从状态输入或像素输入进行零样本模拟到真实机器人的迁移。这得益于一个包含物理引擎、批处理渲染器及训练环境的集成栈的支持。除了视频结果，整个框架都免费提供在playground.mujoco.org上&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce MuJoCo Playground, a fully open-source framework for robotlearning built with MJX, with the express goal of streamlining simulation,training, and sim-to-real transfer onto robots. With a simple "pip installplayground", researchers can train policies in minutes on a single GPU.Playground supports diverse robotic platforms, including quadrupeds, humanoids,dexterous hands, and robotic arms, enabling zero-shot sim-to-real transfer fromboth state and pixel inputs. This is achieved through an integrated stackcomprising a physics engine, batch renderer, and training environments. Alongwith video results, the entire framework is freely available atplayground.mujoco.org</description>
      <author>example@mail.com (Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder A. Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel)</author>
      <guid isPermaLink="false">2502.08844v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>ClipRover: Zero-shot Vision-Language Exploration and Target Discovery by Mobile Robots</title>
      <link>http://arxiv.org/abs/2502.08791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  V1, 21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型导航管道ClipRover，用于未知环境中的同时探索和目标发现。&lt;h4&gt;背景&lt;/h4&gt;当前的视觉-语言导航系统通常将地图探索与路径规划分开，并依赖于低效算法由于有限的（部分观察到的）环境信息。这些系统在执行零样本推理任务时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型导航管道，用于未知环境中的同时探索和目标发现。&lt;h4&gt;方法&lt;/h4&gt;使用视觉-语言模型CLIP的能力，结合单目视觉和功能原型UGV系统Rover Master进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ClipRover在吞吐量、障碍物规避能力和轨迹性能方面均优于传统地图遍历算法，并且其表现与依赖于先前地图和目标知识的路径规划方法相当。特别是，ClipRover能够在没有预先捕获候选图像或预建节点图的情况下进行实时主动导航。&lt;h4&gt;结论&lt;/h4&gt;提出的新型导航管道在未知环境中表现出优越的性能，展示了视觉-语言模型用于自主导航任务的强大潜力。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language navigation (VLN)技术作为移动机器人执行零样本推理和执行任务的一种有前途的方法已出现。然而，现有的系统通常将地图探索与路径规划分开进行，并且由于有限的信息（部分观察到的环境信息），这些系统的探索依赖于低效算法。在这篇论文中，我们提出了一种名为“ClipRover”的新型导航管道，在未知环境中同时实现探索和目标发现，利用视觉-语言模型CLIP的能力。我们的方法仅需要单目视觉，并且不需要任何先前的地图或对目标的知识。为了进行全面评估，我们设计了一个名为“Rover Master”的无人地面车辆系统功能原型，这是一个专为通用VLN任务定制的平台。我们将ClipRover管道集成并部署到Rover Master上，在各种真实场景中对其吞吐量、障碍物规避能力和轨迹性能进行评估。实验结果显示，ClipRover在吞吐量和轨迹性能方面优于传统的地图遍历算法，并且其表现与依赖于先前地图和目标知识的路径规划方法相当。值得注意的是，ClipRover可以在没有预先捕获候选图像或预建节点图的情况下实现实时主动导航，解决了现有VLN管道的关键限制问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language navigation (VLN) has emerged as a promising paradigm,enabling mobile robots to perform zero-shot inference and execute tasks withoutspecific pre-programming. However, current systems often separate mapexploration and path planning, with exploration relying on inefficientalgorithms due to limited (partially observed) environmental information. Inthis paper, we present a novel navigation pipeline named ''ClipRover'' forsimultaneous exploration and target discovery in unknown environments,leveraging the capabilities of a vision-language model named CLIP. Our approachrequires only monocular vision and operates without any prior map or knowledgeabout the target. For comprehensive evaluations, we design the functionalprototype of a UGV (unmanned ground vehicle) system named ''Rover Master'', acustomized platform for general-purpose VLN tasks. We integrate and deploy theClipRover pipeline on Rover Master to evaluate its throughput, obstacleavoidance capability, and trajectory performance across various real-worldscenarios. Experimental results demonstrate that ClipRover consistentlyoutperforms traditional map traversal algorithms and achieves performancecomparable to path-planning methods that depend on prior map and targetknowledge. Notably, ClipRover offers real-time active navigation withoutrequiring pre-captured candidate images or pre-built node graphs, addressingkey limitations of existing VLN pipelines.</description>
      <author>example@mail.com (Yuxuan Zhang, Adnan Abdullah, Sanjeev J. Koppal, Md Jahidul Islam)</author>
      <guid isPermaLink="false">2502.08791v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Acoustic Wave Manipulation Through Sparse Robotic Actuation</title>
      <link>http://arxiv.org/abs/2502.08784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，机器人、控制和机器学习的进步推动了物体操纵领域的进展。本文探索了一项更具挑战性的问题：通过部分被机器人传感器观测到的声波进行操作，并使用空间稀疏驱动器影响这些声波。&lt;h4&gt;背景&lt;/h4&gt;当前研究中利用深度神经网络表示由机器人传感器部分观察到的动力学模型，以及采用稀疏控制信号的有效控制方法已经取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的基于数据的方法，使得机器人能够聚焦或抑制在指定区域散射的声能，根据具体任务的需求进行调整。&lt;h4&gt;方法&lt;/h4&gt;提出了一种适用于通过偏微分方程描述的动力系统操作的数据驱动学习法，并与现有最佳机器学习方法和经典半解析方法进行了比较，该方法在解决方案质量和计算复杂度方面表现更优。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在聚焦或抑制声能的效率和精确性上优于现有的机器学习方法，并且在某些应用场景中可以媲美经典的半解析方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法具有设计新型人工材料、超声切割工具以及能量采集等领域的应用潜力，同时也展示了机器人技术在复杂物理现象操控中的强大能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文译文为：近年来，在机器人学、控制理论和机器学习方面的进步促进了物体操纵这一挑战性领域的发展。这些进展包括利用深度神经网络来表示部分由机器人传感器观测到的动力学，以及采用稀疏控制信号的有效控制方法。在本文中，我们探讨了一个更具普遍性的问题：即通过空间上稀疏的驱动器影响声波，并且这些声波仅能被一个特定类型的机器人部分感知的问题。这一领域具有巨大的潜力，适用于新型人工材料设计、超声切割工具制造以及能量采集等应用。我们开发了一种高效的基于数据的方法用于机器学习，该方法能够应用于聚焦或者抑制在指定区域的散射声能，具体取决于任务需求。相比于目前最先进的利用偏微分方程描述的动力系统操作的机器学习方法，我们的方法在解决方案质量和计算复杂度方面表现出色；此外，在实际演示的任务中，我们提出的方法与经典的半解析法相竞争。项目代码及相关视频展示已公开：https://gladisor.github.io/waves/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in robotics, control, and machine learning havefacilitated progress in the challenging area of object manipulation. Theseadvancements include, among others, the use of deep neural networks torepresent dynamics that are partially observed by robot sensors, as well aseffective control using sparse control signals. In this work, we explore a moregeneral problem: the manipulation of acoustic waves, which are partiallyobserved by a robot capable of influencing the waves through spatially sparseactuators. This problem holds great potential for the design of new artificialmaterials, ultrasonic cutting tools, energy harvesting, and other applications.We develop an efficient data-driven method for robot learning that isapplicable to either focusing scattered acoustic energy in a designated regionor suppressing it, depending on the desired task. The proposed method is betterin terms of a solution quality and computational complexity as compared to astate-of-the-art learning based method for manipulation of dynamical systemsgoverned by partial differential equations. Furthermore our proposed method iscompetitive with a classical semi-analytical method in acoustics research onthe demonstrated tasks. We have made the project code publicly available, alongwith a web page featuring video demonstrations:https://gladisor.github.io/waves/.</description>
      <author>example@mail.com (Tristan Shah, Noam Smilovich, Samer Gerges, Feruza Amirkulova, Stas Tiomkin)</author>
      <guid isPermaLink="false">2502.08784v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Europe's AI Imperative -- A Pragmatic Blueprint for Global Tech Leadership</title>
      <link>http://arxiv.org/abs/2502.08781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;欧洲在与美国的大型风险资本和技术巨头以及中国的规模导向型、自上而下的发展模式的竞争中处于关键时刻。&lt;h4&gt;目的&lt;/h4&gt;鉴于人工智能与量子计算、生物科技、虚拟现实/增强现实（VR/AR）、5G/6G、机器人技术、先进材料和高性能计算等互补性技术和协同技术的融合可能会颠覆地缘政治平衡，欧洲需要重新思考其在人工智能领域的策略。&lt;h4&gt;总结&lt;/h4&gt;论文提出了一项基于欧洲优势并弥补差距的战略方案。&lt;h4&gt;方法&lt;/h4&gt;该战略是在巴黎2025年的人工智能行动峰会上提出的，并且具有实际可操作性。&lt;h4&gt;主要发现&lt;/h4&gt;&lt;h4&gt;结论&lt;/h4&gt;通过重新思考其人工智能策略，欧洲有可能在国际竞争中取得成功。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于欧洲如何在全球AI竞赛中的关键时刻制定可行的战略以弥补与美国和中国的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Europe is at a make-or-break moment in the global AI race, squeezed betweenthe massive venture capital and tech giants in the US and China'sscale-oriented, top-down drive. At this tipping point, where the convergence ofAI with complementary and synergistic technologies, like quantum computing,biotech, VR/AR, 5G/6G, robotics, advanced materials, and high-performancecomputing, could upend geopolitical balances, Europe needs to rethink itsAI-related strategy. On the heels of the AI Action Summit 2025 in Paris, wepresent a sharp, doable strategy that builds upon Europe's strengths and closesgaps.</description>
      <author>example@mail.com (Gjergji Kasneci, Urs Gasser, Thomas F. Hofmann, Gerhard Kramer, Gerhard Müller, Claudia Peus, Helmut Schönenberger, Enkelejda Kasneci)</author>
      <guid isPermaLink="false">2502.08781v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Bilevel Learning for Bilevel Planning</title>
      <link>http://arxiv.org/abs/2502.08697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的双层规划方法IVNTR，该方法能够从演示中直接学习神经谓词。这种方法结合了符号和神经网络的学习机制，在多种机器人任务上表现出卓越的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;当前的双层规划方法依赖于手动设计或非常简单的谓词表示，这限制了它们在复杂高维状态空间中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动从演示中学习复杂神经网络谓词的双层规划框架。&lt;h4&gt;方法&lt;/h4&gt;提出了IVNTR方法，该方法通过交替进行符号学习和神经网络学习来实现对复杂任务的理解和泛化。符号学习处理谓词的效果，而神经网络学习则关注谓词的功能。&lt;h4&gt;主要发现&lt;/h4&gt;在六种不同的机器人领域中，IVNTR展示了显著的抽象能力，并且在未见过的任务上达到了77%的成功率，远高于现有方法（小于35%成功率）。此外，在移动操作器场景中的测试也证明了它的泛化能力和实用性。&lt;h4&gt;结论&lt;/h4&gt;通过学习和规划与抽象的关系，IVNTR为实现高层次的泛化提供了新的途径，并且展示了在实际机器人任务中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;一个从演示中学习的机器人不应仅仅模仿它看到的东西——应该理解被展示的高层概念并将它们推广到新任务上。双层规划是一种层次化的基于模型的方法，其中谓词（关系状态抽象）可以用来实现组合泛化。然而，先前的双层规划方法依赖于要么手动工程设计或仅限于非常简单形式的谓词表示，这限制了其在复杂高维状态空间中的扩展性。为了克服这一限制，我们提出了一种名为IVNTR的新方法——第一个能够直接从演示中学习神经谓词的双层规划方法。我们的主要创新是一种镜像双层规划结构的神经符号双层学习框架，在该框架下，谓词“效果”的符号学习和谓词“功能”的神经网络学习交替进行，相互指导。我们在六个不同的机器人规划领域评估了IVNTR的表现力，证明它能够抽象各种连续且高维的状态。尽管大多数现有的方法在泛化时表现不佳（成功率小于35%），我们的IVNTR则在未见过的任务上实现了77%的成功率。此外，我们还展示了IVNTR在一个移动操作器上的应用，它可以学习执行现实世界中的移动操控任务，并推广到包含新对象、新的状态以及更长任务时间的测试场景中去。我们的研究结果强调了通过抽象进行学习和规划作为实现高层次泛化的路径的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A robot that learns from demonstrations should not just imitate what it sees-- it should understand the high-level concepts that are being demonstrated andgeneralize them to new tasks. Bilevel planning is a hierarchical model-basedapproach where predicates (relational state abstractions) can be leveraged toachieve compositional generalization. However, previous bilevel planningapproaches depend on predicates that are either hand-engineered or restrictedto very simple forms, limiting their scalability to sophisticated,high-dimensional state spaces. To address this limitation, we present IVNTR,the first bilevel planning approach capable of learning neural predicatesdirectly from demonstrations. Our key innovation is a neuro-symbolic bilevellearning framework that mirrors the structure of bilevel planning. In IVNTR,symbolic learning of the predicate "effects" and neural learning of thepredicate "functions" alternate, with each providing guidance for the other. Weevaluate IVNTR in six diverse robot planning domains, demonstrating itseffectiveness in abstracting various continuous and high-dimensional states.While most existing approaches struggle to generalize (with &lt;35% success rate),our IVNTR achieves an average of 77% success rate on unseen tasks.Additionally, we showcase IVNTR on a mobile manipulator, where it learns toperform real-world mobile manipulation tasks and generalizes to unseen testscenarios that feature new objects, new states, and longer task horizons. Ourfindings underscore the promise of learning and planning with abstractions as apath towards high-level generalization.</description>
      <author>example@mail.com (Bowen Li, Tom Silver, Sebastian Scherer, Alexander Gray)</author>
      <guid isPermaLink="false">2502.08697v1</guid>
      <pubDate>Fri, 14 Feb 2025 16:37:32 +0800</pubDate>
    </item>
    <item>
      <title>Uniform Kernel Prober</title>
      <link>http://arxiv.org/abs/2502.07369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Uniform Kernel Prober (UKP)的伪度量，用于评估不同统计模型（如神经网络）学习到的不同特征或表示在下游预测任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;多任务学习的成功在于能够基于训练数据识别出对多种预测任务都有低预测误差的有用特征或表示。然而，在实践中选择合适的预测任务以及获得这些任务的相关测试数据是一个挑战，这使得比较不同特征的表现变得困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种伪度量方法来评估和比较不同的特征或表示在下游预测任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Uniform Kernel Prober (UKP)的伪度量方法。这种伪度量可以在没有测试数据的情况下，基于给定的核函数提供一个统一的、对所有类型的核岭回归任务有效的衡量标准。&lt;h4&gt;主要发现&lt;/h4&gt;提出的伪度量能够有效地估计输入数据样本的数量，并通过选择合适的核函数捕捉表示中的所需不变性；此外，实验结果表明UKP能够在下游核岭回归任务中根据一般化性能区分不同类型的特征或表示。&lt;h4&gt;结论&lt;/h4&gt;Uniform Kernel Prober (UKP)作为一种新方法，在评估和比较多任务学习模型的性能方面具有重要的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;识别基于训练数据能够实现低预测误差的有效特征或表示是多任务学习成功的关键。然而，实践中的挑战在于选择适当的预测任务以及获取这些任务相关的测试数据，这使得比较不同特征的表现变得复杂。本文提出了一种名为Uniform Kernel Prober (UKP)的伪度量方法用于评估和比较统计模型如神经网络所学的不同特征或表示在涉及核岭回归的下游预测任务中的表现。该伪度量可以在没有测试数据的情况下提供统一衡量标准，并通过选择合适的核函数捕捉表示中的所需不变性。实验结果表明，UKP能够在多任务学习中根据一般化性能区分不同类型的特征或表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to identify useful features or representations of the input databased on training data that achieves low prediction error on test data acrossmultiple prediction tasks is considered the key to multitask learning success.In practice, however, one faces the issue of the choice of prediction tasks andthe availability of test data from the chosen tasks while comparing therelative performance of different features. In this work, we develop a class ofpseudometrics called Uniform Kernel Prober (UKP) for comparing features orrepresentations learned by different statistical models such as neural networkswhen the downstream prediction tasks involve kernel ridge regression. Theproposed pseudometric, UKP, between any two representations, provides a uniformmeasure of prediction error on test data corresponding to a general class ofkernel ridge regression tasks for a given choice of a kernel without access totest data. Additionally, desired invariances in representations can besuccessfully captured by UKP only through the choice of the kernel function andthe pseudometric can be efficiently estimated from $n$ input data samples with$O(\frac{1}{\sqrt{n}})$ estimation error. We also experimentally demonstratethe ability of UKP to discriminate between different types of features orrepresentations based on their generalization performance on downstream kernelridge regression tasks.</description>
      <author>example@mail.com (Soumya Mukherjee, Bharath K. Sriperumbudur)</author>
      <guid isPermaLink="false">2502.07369v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
  <item>
      <title>A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion</title>
      <link>http://arxiv.org/abs/2502.08573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于对比学习和视觉序列压缩的新型多模态情感识别方法DeepMSI-MER。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能与计算机视觉技术的进步，多模态情绪识别已成为研究热点。然而，现有方法在异构数据融合及模式间相关性的有效利用方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态情感识别方法，旨在改进跨模式特征融合并减少冗余，从而提高情绪识别的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出的DeepMSI-MER方法通过对比学习增强了跨模态特征融合，并利用视觉序列压缩减少了视觉模式中的冗余。&lt;h4&gt;主要发现&lt;/h4&gt;在IEMOCAP和MELD两个公开数据集上的实验结果表明，DeepMSI-MER显著提高了情感识别的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的多模态特征融合方法及其具体实现验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;随着人工智能和计算机视觉技术的发展，多模式情绪识别已成为一个重要研究领域。然而，现有的方法在异构数据融合以及充分利用不同模式之间的相关性方面面临挑战。本文提出了一种新的基于对比学习和视觉序列压缩的多模态情感识别方法DeepMSI-MER。该方法通过对比学习改进跨模式特征融合，并利用视觉序列压缩减少视觉模式中的冗余。实验结果表明，在两个公开数据集上，即IEMOCAP和MELD，DeepMSI-MER显著提高了情绪识别的准确性和鲁棒性，验证了多模态特征融合的有效性和所提出方法的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancement of artificial intelligence and computer visiontechnologies, multimodal emotion recognition has become a prominent researchtopic. However, existing methods face challenges such as heterogeneous datafusion and the effective utilization of modality correlations. This paperproposes a novel multimodal emotion recognition approach, DeepMSI-MER, based onthe integration of contrastive learning and visual sequence compression. Theproposed method enhances cross-modal feature fusion through contrastivelearning and reduces redundancy in the visual modality by leveraging visualsequence compression. Experimental results on two public datasets, IEMOCAP andMELD, demonstrate that DeepMSI-MER significantly improves the accuracy androbustness of emotion recognition, validating the effectiveness of multimodalfeature fusion and the proposed approach.</description>
      <author>example@mail.com (Wei Dai, Dequan Zheng, Feng Yu, Yanrong Zhang, Yaohui Hou)</author>
      <guid isPermaLink="false">2502.08573v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions</title>
      <link>http://arxiv.org/abs/2502.08438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at AAAI 2024, 9 pages. Project Website:  https://vl2g.github.io/projects/cstbir&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;非母语使用者由于词汇量有限，经常难以命名特定对象，尽管他们能够想象这些对象。例如，在澳大利亚以外地区寻找袋食蚁兽的人可能会遇到这种问题。此外，用户可能希望搜索那些难以草图绘制但容易用语言描述的对象或场景交互的情况。在这样常见却复杂的环境中，用户需要一个支持复合多模态查询的搜索界面，该界面可以接受难以命名但易于手绘对象的手绘草图和描述难以描绘但是能口头表达出来的对象属性或者与场景互动的文字信息。这种新的问题陈述明显区别于之前研究较多的基于文本（TBIR）和基于草图（SBIR）的图像检索问题。&lt;h4&gt;背景&lt;/h4&gt;非母语使用者或在搜索难以命名但容易想象的对象时，尤其是那些难以通过草图描绘但是可以用语言描述互动的复杂场景。现有技术如基于文本或者基于草图的方法无法很好地满足这些需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种全新的复合多模态查询方法，并为此创建了一个包含约200万个查询和10.8万张自然场景图像的数据集，以研究如何使用手绘草图和文字描述相结合的方式来进行更加有效的图像检索。&lt;h4&gt;方法&lt;/h4&gt;首先建立了CSTBIR（复合素描+文本基础的图像检索）数据集。然后开发了一个基于预训练多模态变换器模型的基线系统——STNET（素描+文本网络），该模型使用手绘草图来定位自然场景中的相关对象，并且编码文本和图像进行图像检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的复合查询方法在仅基于文本、仅基于草图以及复合模式查询方面均优于现有的最佳图像检索技术。此外，我们还提出了多种训练目标以进一步提高模型性能。&lt;h4&gt;结论&lt;/h4&gt;这项研究不仅为非母语使用者提供了一种有效的图像搜索方式，同时也展示了如何利用复合多模态信息进行更准确的图像检索。所使用的数据集和代码将公开发布于项目官方网站上供研究人员参考使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-native speakers with limited vocabulary often struggle to name specificobjects despite being able to visualize them, e.g., people outside Australiasearching for numbats. Further, users may want to search for such elusiveobjects with difficult-to-sketch interactions, e.g., numbat digging in theground. In such common but complex situations, users desire a search interfacethat accepts composite multimodal queries comprising hand-drawn sketches ofdifficult-to-name but easy-to-draw objects and text describingdifficult-to-sketch but easy-to-verbalize object attributes or interaction withthe scene. This novel problem statement distinctly differs from the previouslywell-researched TBIR (text-based image retrieval) and SBIR (sketch-based imageretrieval) problems. To study this under-explored task, we curate a dataset,CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2Mqueries and 108K natural scene images. Further, as a solution to this problem,we propose a pretrained multimodal transformer-based baseline, STNET(Sketch+Text Network), that uses a hand-drawn sketch to localize relevantobjects in the natural scene image, and encodes the text and image to performimage retrieval. In addition to contrastive learning, we propose multipletraining objectives that improve the performance of our model. Extensiveexperiments show that our proposed method outperforms several state-of-the-artretrieval methods for text-only, sketch-only, and composite query modalities.We make the dataset and code available at our project website.</description>
      <author>example@mail.com (Prajwal Gatti, Kshitij Parikh, Dhriti Prasanna Paul, Manish Gupta, Anand Mishra)</author>
      <guid isPermaLink="false">2502.08438v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Closer through commonality: Enhancing hypergraph contrastive learning with shared groups</title>
      <link>http://arxiv.org/abs/2502.08432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11page, 5 figures, 6 tables, 2024 IEEE International Conference on  Big Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Hypergraph Fine-grained对比学习（HyFi）方法，利用超图中的复杂高维信息进行对比学习。&lt;h4&gt;背景&lt;/h4&gt;传统同质化图表在表示现实世界中复杂的多维度关系时存在局限性。而基于超图的对比学习研究较少，现有图谱对比学习方法未能充分利用超图中的高级关联信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于超图的对比学习方法HyFi，以克服现有方法的问题，并提高节点分类任务的表现。&lt;h4&gt;方法&lt;/h4&gt;通过向节点特征添加噪声来实现简单高效的增广函数，同时避免了破坏超图表结构的传统图谱增强方法。引入弱正样本的概念，超越传统的正负样本二元关系。&lt;h4&gt;主要发现&lt;/h4&gt;HyFi能够产生高质量的嵌入，并在10个数据集上的节点分类任务中优于监督和非监督基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法有效利用了高维超图信息，在对比学习方面显著改善了现有基于图的方法的表现，同时具有较高的训练效率和较低的GPU内存开销。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已被准确地用中文进行了总结，并转化为易于理解的JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypergraphs provide a superior modeling framework for representing complexmultidimensional relationships in the context of real-world interactions thatoften occur in groups, overcoming the limitations of traditional homogeneousgraphs. However, there have been few studies on hypergraphbased contrastivelearning, and existing graph-based contrastive learning methods have not beenable to fully exploit the highorder correlation information in hypergraphs.Here, we propose a Hypergraph Fine-grained contrastive learning (HyFi) methoddesigned to exploit the complex high-dimensional information inherent inhypergraphs. While avoiding traditional graph augmentation methods that corruptthe hypergraph topology, the proposed method provides a simple and efficientlearning augmentation function by adding noise to node features. Furthermore,we expands beyond the traditional dichotomous relationship between positive andnegative samples in contrastive learning by introducing a new relationship ofweak positives. It demonstrates the importance of fine-graining positivesamples in contrastive learning. Therefore, HyFi is able to produce highqualityembeddings, and outperforms both supervised and unsupervised baselines inaverage rank on node classification across 10 datasets. Our approacheffectively exploits high-dimensional hypergraph information, shows significantimprovement over existing graph-based contrastive learning methods, and isefficient in terms of training speed and GPU memory cost. The source code isavailable at https://github.com/Noverse0/HyFi.git.</description>
      <author>example@mail.com (Daeyoung Roh, Donghee Han, Daehee Kim, Keejun Han, Mun Yi)</author>
      <guid isPermaLink="false">2502.08432v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Fully-Geometric Cross-Attention for Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2502.08285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer架构的新型交叉注意机制，旨在解决点云配准在低重叠情况下由于噪声导致的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云注册方法在点云重叠较低的情况下往往失败，因为这种情况下会出现大量的噪声点对应关系。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新的跨注意力机制来克服传统方法的局限性，并提高点云配准的效果和精度。&lt;h4&gt;方法&lt;/h4&gt;{'1': '提出了一种融合了坐标与特征信息的新交叉注意机制，该机制在超点级别上工作，将不同点云之间的几何结构考虑进去。', '2': '引入Gromov-Wasserstein距离到跨注意力机制中以计算不同点云之间点的距离，并考虑到它们的几何结构。', '3': '提出了一种自我注意机制，在点级别上聚合局部几何信息至点特征，以便于精细匹配。'}&lt;h4&gt;主要发现&lt;/h4&gt;新的交叉注意机制能够保证旋转和平移不变性，使来自两个不同点云中的点在任意刚体变换下仍可相互响应。&lt;h4&gt;结论&lt;/h4&gt;通过引入新方法，文中所提模型可以增加内点对应关系的数量，从而比现有最佳的方法获得更精确的配准结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的方法已经在3DMatch、3DLoMatch、KITTI和3DCSR数据集上进行了广泛的评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration approaches often fail when the overlap between pointclouds is low due to noisy point correspondences. This work introduces a novelcross-attention mechanism tailored for Transformer-based architectures thattackles this problem, by fusing information from coordinates and features atthe super-point level between point clouds. This formulation has remainedunexplored primarily because it must guarantee rotation and translationinvariance since point clouds reside in different and independent referenceframes. We integrate the Gromov-Wasserstein distance into the cross-attentionformulation to jointly compute distances between points across different pointclouds and account for their geometric structure. By doing so, points from twodistinct point clouds can attend to each other under arbitrary rigidtransformations. At the point level, we also devise a self-attention mechanismthat aggregates the local geometric structure information into point featuresfor fine matching. Our formulation boosts the number of inlier correspondences,thereby yielding more precise registration results compared to state-of-the-artapproaches. We have conducted an extensive evaluation on 3DMatch, 3DLoMatch,KITTI, and 3DCSR datasets.</description>
      <author>example@mail.com (Weijie Wang, Guofeng Mei, Jian Zhang, Nicu Sebe, Bruno Lepri, Fabio Poiesi)</author>
      <guid isPermaLink="false">2502.08285v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Class Discovery in Instance Segmentation</title>
      <link>http://arxiv.org/abs/2502.08149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个用于实例分割中的广义类别的发现任务的方法，该方法旨在通过已知数据和未知数据来识别新的类别并实现对所有已知和新类别的实例进行分割。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，物体种类繁多且分布呈长尾状，每个类别的实例数量不平衡。&lt;h4&gt;目的&lt;/h4&gt;解决由于实例分布不平衡导致的广义类别发现的问题，并提出解决方案来改善这一状况。&lt;h4&gt;方法&lt;/h4&gt;{'instance-wise temperature assignment (ITA) 方法': '通过为来自头类别的样本放松实例区分来提高GCD的表现，从而应对长尾分布。', 'class-wise reliability criteria': '在使用从GCD获得的伪标签训练实例分割网络时避免忽略长尾类别大部分伪标签的标准。', '动态调整标准': '根据训练阶段的不同灵活地利用多样化或可靠样本的方法。', '软注意力模块': '一种高效的编码对象特定表示以支持广义类别的发现的方法'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的ITAT方法在COCO半 + LVIS和LVIS + Visual Genome两个设定上表现优于先前的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入有效的实例级温度分配、类别级可靠性标准以及动态调整伪标签使用策略，该工作为解决实例分割中的长尾分布问题提供了新的解决方案，并且实验结果显示其性能优越。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work addresses the task of generalized class discovery (GCD) in instancesegmentation. The goal is to discover novel classes and obtain a model capableof segmenting instances of both known and novel categories, given labeled andunlabeled data. Since the real world contains numerous objects with long-taileddistributions, the instance distribution for each class is inherentlyimbalanced. To address the imbalanced distributions, we propose aninstance-wise temperature assignment (ITA) method for contrastive learning andclass-wise reliability criteria for pseudo-labels. The ITA method relaxesinstance discrimination for samples belonging to head classes to enhance GCD.The reliability criteria are to avoid excluding most pseudo-labels for tailclasses when training an instance segmentation network using pseudo-labels fromGCD. Additionally, we propose dynamically adjusting the criteria to leveragediverse samples in the early stages while relying only on reliablepseudo-labels in the later stages. We also introduce an efficient softattention module to encode object-specific representations for GCD. Finally, weevaluate our proposed method by conducting experiments on two settings:COCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental resultsdemonstrate that the proposed method outperforms previous state-of-the-artmethods.</description>
      <author>example@mail.com (Cuong Manh Hoang, Yeejin Lee, Byeongkeun Kang)</author>
      <guid isPermaLink="false">2502.08149v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Checkerboard Target Measurement in Unordered Point Clouds with Coloured ICP</title>
      <link>http://arxiv.org/abs/2502.08525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究探讨了在3D点云中测量中心棋盘格目标的问题。这个问题在注册、长期监测以及与其他传感器系统关联方面有着重要的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于彩色ICP算法的三维模板匹配方法来解决这一问题，并且能够在处理无结构的3D数据的情况下工作，以适应新的低成本激光雷达传感器产生的未排序点云数据。&lt;h4&gt;方法&lt;/h4&gt;采用了一种基于彩色ICP算法的三维模板匹配方法。该方法特别适用于处理没有结构约束的3D数据（即无序点云）的情况，并且能够处理新型低成本LIDAR传感器生成的数据，这类传感器在距离和反射率测量中增加了噪声。&lt;h4&gt;主要发现&lt;/h4&gt;提供了使用合成数据进行广泛仿真结果的研究成果，以展示这种方法的应用潜力。此外还详细描述了处理实际传感器数据的具体步骤。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种解决3D点云中心棋盘格目标测量问题的有效方法，并且能够适应新型低成本LIDAR传感器的数据特性。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们研究了在三维点云中度量中心棋盘格目标的问题。这是一个重要的问题，在注册、长期监测及与其他传感系统关联中有应用。我们利用了一种基于彩色ICP算法的3D模板匹配方法来解决问题，并且我们在处理无结构的3D数据（即未排序点云）的情况下解决了这个问题，这使我们能够处理新一代低成本LIDAR传感器生成的数据。这类传感器在范围和反射率测量中也增加了噪声。我们使用合成数据进行了广泛的仿真结果研究以捕捉这种方法的应用潜力。然后给出了处理真实传感器数据的具体步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we investigate the problem of measuring a the centrecheckerboard target in an 3D point cloud. This is an important problem whichhas applications in registration, long term monitoring and linking to othersensor systems. We use a 3D template matching approach based on the colouredICP algorithm to solve the problem. We tackle the problem under the additionalconstraints that we assume no structure in the 3D data in order to be able tohandle unordered point clouds. This gives us the capability to process datafrom the new generation of low-cost LIDAR sensors. This category of sensorsalso suffers from increased noise in range and reflectivity measurement. Weprovide extensive simulation results using synthetic data to capture thepotential of the approach. We then give the detailed steps for handling realsensor data.</description>
      <author>example@mail.com (June Moh Goo, Jialun Li, Darmawan Wicaksono, Jan Boehm)</author>
      <guid isPermaLink="false">2502.08525v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?</title>
      <link>http://arxiv.org/abs/2502.08503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文指出了在3D大型语言模型评估中存在的一种称为'2D-Cheating'的问题，并提出了评估3D理解能力的新原则。&lt;h4&gt;背景&lt;/h4&gt;当前的3D LLM评估任务可能存在被视觉语言模型利用通过渲染点云图像轻易解决的情况，从而无法有效评价3D LLM的独特三维能力。&lt;h4&gt;目的&lt;/h4&gt;测试不同视觉语言模型在多个3D LLM基准上的表现，并提出更有效的评估原则以准确衡量真正的3D理解能力。&lt;h4&gt;方法&lt;/h4&gt;比较VLM在多个人工智能基准测试中的性能，以此作为参考。&lt;h4&gt;主要发现&lt;/h4&gt;提出了用于更好评估真实三维理解的指导原则，并建议在评估3D LLM时明确区分其三维能力与其他维度的能力。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法可以更准确地评价3D大型语言模型的实际三维理解水平。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们识别出3D LLM评估中的“2D-Cheating”问题，并提出改进评估原则以确保能够有效评测3D LLM的真正三维能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we identify the "2D-Cheating" problem in 3D LLM evaluation,where these tasks might be easily solved by VLMs with rendered images of pointclouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. Wetest VLM performance across multiple 3D LLM benchmarks and, using this as areference, propose principles for better assessing genuine 3D understanding. Wealso advocate explicitly separating 3D abilities from 1D or 2D aspects whenevaluating 3D LLMs.</description>
      <author>example@mail.com (Jiahe Jin, Yanheng He, Mingyan Yang)</author>
      <guid isPermaLink="false">2502.08503v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World</title>
      <link>http://arxiv.org/abs/2502.08449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CordViP框架，利用物体的6D姿态估计和机器人本体感觉来建立交互感知点云之间的对应关系。该方法在四个现实世界的任务中表现出卓越的操作能力。&lt;h4&gt;背景&lt;/h4&gt;实现类人级别的灵巧性是机械臂操作领域的关键目标。近年来基于3D模仿学习的进步取得了显著成果，但高质量的3D表示受到摄像机分辨率、位置和遮挡的影响，以及缺乏接触信息和空间对应关系。&lt;h4&gt;目的&lt;/h4&gt;提出CordViP框架以克服现有技术中的限制，并提高机械臂的操作能力。&lt;h4&gt;方法&lt;/h4&gt;通过利用物体6D姿态估计和机器人本体感觉，建立交互感知点云之间的对应关系。使用这些点云进行预训练策略，其中还包括对象中心接触图和手-臂协调信息。&lt;h4&gt;主要发现&lt;/h4&gt;CordViP在四个现实世界的任务中表现出平均90%的成功率，并且比其他基准方法有更好的泛化能力和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该框架通过有效利用物体的6D姿态估计和机器人本体感觉，提供了一种新的途径来提高机械臂的操作性能。&lt;h4&gt;翻译&lt;/h4&gt;实现人类级别的灵巧性是机器人操作领域的一个关键目标。最近基于3D模仿学习的进步已显示出有希望的结果，为达成这一目标提供了有效的路径。然而，获取高质量的3D表示存在两个主要问题：（1）单视图摄像机捕获的点云质量显著受到相机分辨率、定位和灵巧手引起的遮挡的影响；（2）全局点云缺乏必要的接触信息和空间对应关系以执行精细操作任务。为消除这些限制，我们提出了CordViP框架，利用物体的6D姿态估计和机器人本体感觉来建立交互感知点云之间的对应关系。该方法在四个现实世界任务中展示了卓越的操作能力，并且其泛化能力和鲁棒性都比其他基准表现优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving human-level dexterity in robots is a key objective in the field ofrobotic manipulation. Recent advancements in 3D-based imitation learning haveshown promising results, providing an effective pathway to achieve this goal.However, obtaining high-quality 3D representations presents two key problems:(1) the quality of point clouds captured by a single-view camera issignificantly affected by factors such as camera resolution, positioning, andocclusions caused by the dexterous hand; (2) the global point clouds lackcrucial contact information and spatial correspondences, which are necessaryfor fine-grained dexterous manipulation tasks. To eliminate these limitations,we propose CordViP, a novel framework that constructs and learnscorrespondences by leveraging the robust 6D pose estimation of objects androbot proprioception. Specifically, we first introduce the interaction-awarepoint clouds, which establish correspondences between the object and the hand.These point clouds are then used for our pre-training policy, where we alsoincorporate object-centric contact maps and hand-arm coordination information,effectively capturing both spatial and temporal dynamics. Our methoddemonstrates exceptional dexterous manipulation capabilities with an averagesuccess rate of 90\% in four real-world tasks, surpassing other baselines by alarge margin. Experimental results also highlight the superior generalizationand robustness of CordViP to different objects, viewpoints, and scenarios. Codeand videos are available on https://aureleopku.github.io/CordViP.</description>
      <author>example@mail.com (Yankai Fu, Qiuxuan Feng, Ning Chen, Zichen Zhou, Mengzhen Liu, Mingdong Wu, Tianxing Chen, Shanyu Rong, Jiaming Liu, Hao Dong, Shanghang Zhang)</author>
      <guid isPermaLink="false">2502.08449v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Data Curation for Visual Contrastive Learning: Why Crafting Effective Positive and Negative Pairs Matters</title>
      <link>http://arxiv.org/abs/2502.08134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉对比学习通过对比相同（正样本）和不相似（负样本）的数据对来学习表示。这些数据对的设计极大地影响了表示质量、训练效率以及计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了优化对比预训练的效果，特别是在解决下游任务时，数据整理变得至关重要。这项调查尝试为现有对比学习中用于正样本与负样本配对的方法建立分类学。&lt;h4&gt;方法&lt;/h4&gt;详细描述了现有的技术手段来管理和筛选这些正负样例的策略和模型。&lt;h4&gt;主要发现&lt;/h4&gt;良好的正负样例选择能够提升表示的质量，加速收敛速度。&lt;h4&gt;结论&lt;/h4&gt;通过分析对比学习中的不同数据整理技术，为未来研究提供了理论基础，并指出其对于实际应用的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual contrastive learning aims to learn representations by contrastingsimilar (positive) and dissimilar (negative) pairs of data samples. The designof these pairs significantly impacts representation quality, trainingefficiency, and computational cost. A well-curated set of pairs leads tostronger representations and faster convergence. As contrastive pre-trainingsees wider adoption for solving downstream tasks, data curation becomesessential for optimizing its effectiveness. In this survey, we attempt tocreate a taxonomy of existing techniques for positive and negative paircuration in contrastive learning, and describe them in detail.</description>
      <author>example@mail.com (Shasvat Desai, Debasmita Ghose, Deep Chakraborty)</author>
      <guid isPermaLink="false">2502.08134v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data</title>
      <link>http://arxiv.org/abs/2502.08547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一种名为GAME的算法，用于处理不同医疗机构之间的电子健康记录（EHR）数据异质性问题。&lt;h4&gt;背景&lt;/h4&gt;随着EHR系统的采用，基于数据驱动的临床护理和研究机会增加。然而，多机构间进行有效的EHR研究存在数据异质性和隐私保护方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;解决上述挑战，提供一种能够处理不同机构之间代码差异的方法，并同时保持患者数据的隐私性。&lt;h4&gt;方法&lt;/h4&gt;GAME算法通过在知识图谱中建立编码之间的关系以及利用语言模型确定特定于每个机构的代码与标准化代码的关系来工作。此外，使用图注意力网络量化代码间关系强度并采用转移和联邦学习技术创建联合训练嵌入以保护数据隐私。&lt;h4&gt;主要发现&lt;/h4&gt;该方法已经在7个不同医疗机构进行了测试和验证，并展示了其在各种疾病条件下的应用效果，如心力衰竭、类风湿性关节炎等。另外，在不共享患者级别数据的情况下，在精神健康障碍患者的阿尔茨海默病预后和自杀风险研究中也显示了它的有效性。&lt;h4&gt;结论&lt;/h4&gt;GAME算法能够有效整合多机构EHR数据，并在不同条件下为AI驱动的算法选择相关特征输入，同时保持严格的隐私保护标准。&lt;h4&gt;翻译&lt;/h4&gt;EHR系统的广泛采用为基于数据驱动的临床护理和研究提供了机会。然而，在多个医疗机构之间进行有效的EHR研究存在很大的障碍——即系统之间的数据异质性问题以及由于需要保护患者隐私而导致多机构间共享患者级别数据难度大。为了应对这些挑战，我们开发了GAME算法，该算法已经在7个不同机构进行了测试并验证其有效性，并且可以支持两种语言的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The adoption of EHRs has expanded opportunities to leverage data-drivenalgorithms in clinical care and research. A major bottleneck in effectivelyconducting multi-institutional EHR studies is the data heterogeneity acrosssystems with numerous codes that either do not exist or represent differentclinical concepts across institutions. The need for data privacy further limitsthe feasibility of including multi-institutional patient-level data required tostudy similarities and differences across patient subgroups. To address thesechallenges, we developed the GAME algorithm. Tested and validated across 7institutions and 2 languages, GAME integrates data in several levels: (1) atthe institutional level with knowledge graphs to establish relationshipsbetween codes and existing knowledge sources, providing the medical context forstandard codes and their relationship to each other; (2) between institutions,leveraging language models to determine the relationships betweeninstitution-specific codes with established standard codes; and (3) quantifyingthe strength of the relationships between codes using a graph attentionnetwork. Jointly trained embeddings are created using transfer and federatedlearning to preserve data privacy. In this study, we demonstrate theapplicability of GAME in selecting relevant features as inputs for AI-drivenalgorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.We then highlight the application of GAME harmonized multi-institutional EHRdata in a study of Alzheimer's disease outcomes and suicide risk among patientswith mental health disorders, without sharing patient-level data outsideindividual institutions.</description>
      <author>example@mail.com (Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai)</author>
      <guid isPermaLink="false">2502.08547v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Multifidelity Simulation-based Inference for Computationally Expensive Simulators</title>
      <link>http://arxiv.org/abs/2502.08416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MF-NPE是一种多保真度的神经后验估计方法，利用低成本低精度仿真来推断高保真仿真的参数。&lt;h4&gt;背景&lt;/h4&gt;在科学研究中，随机模型是理解经验数据背后的机制的重要工具。然而，通过基于模拟的推理来推断高保真模型的参数是一个挑战，尤其是当模拟器计算成本高昂时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MF-NPE，可以在有限的仿真预算内利用低精度仿真有效地推断高保真仿真的参数。&lt;h4&gt;方法&lt;/h4&gt;MF-NPE通过迁移学习，在资源受限的情况下执行神经后验估计，并能使用主动学习来优先考虑个别观察结果。&lt;h4&gt;主要发现&lt;/h4&gt;在一项统计任务和两项实际应用中，MF-NPE展示了与当前方法相当的性能，但需要的高保真模拟次数减少了两个数量级。&lt;h4&gt;结论&lt;/h4&gt;总体而言，MF-NPE为在计算成本高的模拟器上进行高效的贝叶斯推理提供了新的机会。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨科学领域的多个领域，随机模型是理解经验观察数据背后机制的重要工具。这些模型可以有不同的细节和准确性水平，高保真度（即高度准确）的模型通常更受欢迎。然而，通过基于模拟的推断来推断高保真模型参数具有挑战性，尤其是在仿真器计算成本高昂的情况下。我们介绍了MF-NPE，这是一种多保真神经后验估计方法，利用低成本低精度仿真在有限的仿真预算内推断高精度仿真的参数。通过迁移学习，MF-NPE能够在资源受限的情况下执行神经后验估计，并能使用主动学习来优先考虑个别观察结果。在一个具有解析真实值的统计任务和两个现实世界任务上，MF-NPE展示了与当前方法相当的表现，但需要的高保真模拟次数减少了两个数量级。总体而言，MF-NPE为在计算成本高的仿真器上进行高效的贝叶斯推理提供了新的机会。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Across many domains of science, stochastic models are an essential tool tounderstand the mechanisms underlying empirically observed data. Models can beof different levels of detail and accuracy, with models of high-fidelity (i.e.,high accuracy) to the phenomena under study being often preferable. However,inferring parameters of high-fidelity models via simulation-based inference ischallenging, especially when the simulator is computationally expensive. Weintroduce MF-NPE, a multifidelity approach to neural posterior estimation thatleverages inexpensive low-fidelity simulations to infer parameters ofhigh-fidelity simulators within a limited simulation budget. MF-NPE performsneural posterior estimation with limited high-fidelity resources by virtue oftransfer learning, with the ability to prioritize individual observations usingactive learning. On one statistical task with analytical ground-truth and tworeal-world tasks, MF-NPE shows comparable performance to current approacheswhile requiring up to two orders of magnitude fewer high-fidelity simulations.Overall, MF-NPE opens new opportunities to perform efficient Bayesian inferenceon computationally expensive simulators.</description>
      <author>example@mail.com (Anastasia N. Krouglova, Hayden R. Johnson, Basile Confavreux, Michael Deistler, Pedro J. Gonçalves)</author>
      <guid isPermaLink="false">2502.08416v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping</title>
      <link>http://arxiv.org/abs/2502.08054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种解决机器人在受环境约束（如表面碰撞）情况下抓取物体的挑战的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的机器人操作方法难以处理非预设或人体常用的双手动策略。最先进的强化学习方法由于任务复杂性而不适用，而基于演示的学习需要收集大量专家演示数据，这往往是不可行的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法来解决受遮挡下的机器人抓取问题，特别是在环境约束导致所需抓取姿态在运动学上无法实现的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了COMBO-Grasp（基于限制的手动双臂抓取），这是一种学习型方法，利用了两个协调策略：一个是通过自我监督数据集训练的限制策略，用于生成稳定姿势；另一个是通过强化学习训练的抓取策略，重新定向和抓取目标物体。关键贡献在于价值函数引导的策略协调。&lt;h4&gt;主要发现&lt;/h4&gt;COMBO-Grasp显著提高了任务成功率，并且在模拟环境和现实环境中都可以成功应用于未见过的对象。&lt;h4&gt;结论&lt;/h4&gt;提出的COMBO-Grasp方法通过改进双臂机器人操作中的协调性和任务性能，展示了其相较于竞争基准方法的优势。该方法还采用了教师-学生策略蒸馏技术以有效部署基于点云的策略到实际环境中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文解决的是遮挡下的机器人抓取问题，即在环境约束（如表面碰撞）导致所需抓取姿态在运动学上无法实现的情况下进行抓取。传统的方法难以应对这种复杂的任务，而最新的强化学习方法由于任务复杂性而不适用；基于演示的学习则需要收集大量的专家示教数据，这往往是不可行的。本文提出了一种双臂机器人操作策略COMBO-Grasp，该策略通过两个协调的政策（限制策略和抓取策略）来解决这一挑战，并且该方法利用价值函数引导策略协调，提高任务性能并成功部署到现实环境中。实验表明，与竞争基线相比，COMBO-Grasp显著提高了任务成功率，并能在模拟环境和真实环境中对未见过的对象进行有效操作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of occluded robot grasping, i.e. graspingin situations where the desired grasp poses are kinematically infeasible due toenvironmental constraints such as surface collisions. Traditional robotmanipulation approaches struggle with the complexity of non-prehensile orbimanual strategies commonly used by humans in these circumstances.State-of-the-art reinforcement learning (RL) methods are unsuitable due to theinherent complexity of the task. In contrast, learning from demonstrationrequires collecting a significant number of expert demonstrations, which isoften infeasible. Instead, inspired by human bimanual manipulation strategies,where two hands coordinate to stabilise and reorient objects, we focus on abimanual robotic setup to tackle this challenge. In particular, we introduceConstraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), alearning-based approach which leverages two coordinated policies: a constraintpolicy trained using self-supervised datasets to generate stabilising poses anda grasping policy trained using RL that reorients and grasps the target object.A key contribution lies in value function-guided policy coordination.Specifically, during RL training for the grasping policy, the constraintpolicy's output is refined through gradients from a jointly trained valuefunction, improving bimanual coordination and task performance. Lastly,COMBO-Grasp employs teacher-student policy distillation to effectively deploypoint cloud-based policies in real-world environments. Empirical evaluationsdemonstrate that COMBO-Grasp significantly improves task success rates comparedto competitive baseline approaches, with successful generalisation to unseenobjects in both simulated and real-world environments.</description>
      <author>example@mail.com (Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner)</author>
      <guid isPermaLink="false">2502.08054v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation</title>
      <link>http://arxiv.org/abs/2502.08642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://swiftsketch.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;近年来，大型视觉-语言模型在向量草图生成方面取得了显著进展。然而，这些最先进的方法需要通过预训练模型反复反馈来确定笔画位置，从而导致耗时的优化过程。&lt;h4&gt;背景&lt;/h4&gt;现有的最佳方法尽管能产生令人印象深刻的草图，但由于其长时间的优化过程，在实际应用中受到限制。&lt;h4&gt;目的&lt;/h4&gt;介绍SwiftSketch，这是一种基于图像条件生成向量草图的扩散模型，能够在不到一秒的时间内生成高质量草图。&lt;h4&gt;方法&lt;/h4&gt;SwiftSketch通过逐步清除从高斯分布采样的笔画控制点噪声来工作。其变压器解码器架构被设计为有效地处理矢量表示的离散性质，并捕捉笔画之间的固有全局依赖关系。为了训练SwiftSketch，构建了一个合成图像-草图配对数据集。&lt;h4&gt;主要发现&lt;/h4&gt;提出的ControlSketch方法通过引入深度感知ControlNet来增强SDS技术，从而在生成这些合成草图时能够进行精确的空间控制。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明SwiftSketch能够在多种概念上泛化，并能高效地产生结合高保真度和自然、视觉吸引力的风格的草图。&lt;h4&gt;翻译&lt;/h4&gt;最近，在大型视觉-语言模型方面的发展已经使高度表达且多样的向量草图生成成为可能。然而，最先进的方法依赖于耗时的优化过程，涉及预训练模型的重复反馈来确定笔画位置。因此，尽管这些方法能产生令人印象深刻的草图，但在实际应用中受到限制。本工作介绍了SwiftSketch，这是一种基于图像条件的向量草图扩散生成模型，能够在不到一秒钟的时间内生产高质量草图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large vision-language models have enabled highlyexpressive and diverse vector sketch generation. However, state-of-the-artmethods rely on a time-consuming optimization process involving repeatedfeedback from a pretrained model to determine stroke placement. Consequently,despite producing impressive sketches, these methods are limited in practicalapplications. In this work, we introduce SwiftSketch, a diffusion model forimage-conditioned vector sketch generation that can produce high-qualitysketches in less than a second. SwiftSketch operates by progressively denoisingstroke control points sampled from a Gaussian distribution. Itstransformer-decoder architecture is designed to effectively handle the discretenature of vector representation and capture the inherent global dependenciesbetween strokes. To train SwiftSketch, we construct a synthetic dataset ofimage-sketch pairs, addressing the limitations of existing sketch datasets,which are often created by non-artists and lack professional quality. Forgenerating these synthetic sketches, we introduce ControlSketch, a method thatenhances SDS-based techniques by incorporating precise spatial control througha depth-aware ControlNet. We demonstrate that SwiftSketch generalizes acrossdiverse concepts, efficiently producing sketches that combine high fidelitywith a natural and visually appealing style.</description>
      <author>example@mail.com (Ellie Arar, Yarden Frenkel, Daniel Cohen-Or, Ariel Shamir, Yael Vinker)</author>
      <guid isPermaLink="false">2502.08642v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar</title>
      <link>http://arxiv.org/abs/2502.06114v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Arxiv preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个新颖的知识蒸馏框架，用于处理4D雷达点云的稀疏性问题，并通过在潜在空间中模仿多个教师模型来使学生模型能够稠密化其输入。&lt;h4&gt;背景&lt;/h4&gt;准确的3D物体检测对于自动驾驶的安全导航至关重要。然而，在恶劣天气条件下，LiDAR性能会下降，而雷达系统保持可靠性能。传统的雷达由于缺乏高度数据存在局限性，但新的4D雷达通过测量范围、方位角和多普勒速度来克服这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达稠密张量解决点云稀疏性的方法，并提高自动驾驶车辆在各种天气条件下的检测性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个知识蒸馏框架，使学生模型能够模仿多个教师模型的行为，在潜在空间中使输入点云变得稠密。该框架主要依赖于4D雷达的密集雷达张量，利用其包含的空间和多普勒维度上的功率测量数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与目前最先进的RTNH模型相比，所提出的模型在K-Radar数据集上性能提高了25%，同时保持了实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;通过引入知识蒸馏框架，该研究为如何利用4D雷达的密集张量来克服其点云稀疏性问题提供了一种有效的方法。这种方法可以进一步提高自动驾驶汽车的安全性和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;准确的三维物体检测对于安全自主导航至关重要，在各种天气条件下都需要可靠的性能表现。虽然激光雷达在恶劣天气条件下的性能会下降，但雷达系统能够保持可靠的表现。传统的雷达由于缺乏高度数据而存在局限性，但是新的4D雷达通过测量范围、方位角和多普勒速度来解决这一问题，从而成为自动驾驶汽车中的宝贵工具。然而，在使用4D雷达时的主要挑战是其点云的稀疏性。先前的研究主要依赖于开发能更好地捕捉稀疏点云语义和上下文信息的架构，并且大多数借鉴了基于激光雷达的方法。但是这些方法往往忽略了4D雷达的一个独特优势：密集的雷达张量，该张量包含了三个空间维度以及多普勒维度上的功率测量数据。我们的论文利用这种张量来解决稀疏性问题。我们提出了一种新颖的知识蒸馏框架，使学生模型能够在潜在空间中模仿多个教师模型的行为从而稠密化其输入点云。&lt;h4&gt;性能提升&lt;/h4&gt;在K-Radar数据集上，与当前最先进的RTNH模型相比，论文所提方法的性能提高了25%，并且仍保持了实时推理速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D object detection is crucial for safe autonomous navigation,requiring reliable performance across diverse weather conditions. While LiDARperformance deteriorates in challenging weather, Radar systems maintain theirreliability. Traditional Radars have limitations due to their lack of elevationdata, but the recent 4D Radars overcome this by measuring elevation alongsiderange, azimuth, and Doppler velocity, making them invaluable for autonomousvehicles. The primary challenge in utilizing 4D Radars is the sparsity of theirpoint clouds. Previous works address this by developing architectures thatbetter capture semantics and context in sparse point cloud, largely drawingfrom LiDAR-based approaches. However, these methods often overlook a uniqueadvantage of 4D Radars: the dense Radar tensor, which encapsulates powermeasurements across three spatial dimensions and the Doppler dimension. Ourpaper leverages this tensor to tackle the sparsity issue. We introduce a novelknowledge distillation framework that enables a student model to densify itssparse input in the latent space by emulating an ensemble of teacher models.Our experiments demonstrate a 25% performance improvement over thestate-of-the-art RTNH model on the K-Radar dataset. Notably, this improvementis achieved while still maintaining a real-time inference speed.</description>
      <author>example@mail.com (Seung-Hyun Song, Dong-Hee Paek, Minh-Quan Dao, Ezio Malis, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.06114v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Domain Adaptation and Graph Neural Networks: A Tensor-Based Framework for Effective Label Propagation</title>
      <link>http://arxiv.org/abs/2502.08505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Label-Propagation Tensor Graph Neural Network (LP-TGNN)框架，用于解决图神经网络在单一领域内训练导致的标签需求量大和表示能力较差的问题。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Networks（GNN）已经成为研究图数据的主要工具，并且在图形分类任务上表现出色。然而，它们主要是在监督学习中进行单域训练，这需要大量的标注数据并且产生的表示不能很好地迁移到其他领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来解决GNN的标签需求量大和表示能力较差的问题，使GNN能够在不同领域的图数据之间更好地迁移。&lt;h4&gt;方法&lt;/h4&gt;LP-TGNN通过张量架构提取图的整体拓扑信息，并通过标签传播减少域之间的差异。该框架可以与通用GNN和领域适应技术兼容并进行伪标签调整。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的LP-TGNN在各种现实世界基准测试中优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;通过消融研究验证了每个组件的有效性，并分析了它们的作用机制。&lt;h4&gt;翻译&lt;/h4&gt;最近，图神经网络（Graph Neural Networks, GNNs）已经成为处理图数据的主要工具。尽管在图分类任务上表现出色，但GNN主要是在单一领域内进行监督学习训练，因此需要大量的标注数据并且产生的表示不能很好地迁移到其他领域。为了解决这个问题，我们提出了Label-Propagation Tensor Graph Neural Network（LP-TGNN）框架来连接图数据与传统的域适应方法之间的差距。该框架使用张量架构整体提取图的拓扑信息，并通过标签传播减少不同领域的差异。此外，它能够轻松地与其他通用GNN和领域适应技术兼容并进行最小化调整以实现伪标记。在各种现实世界基准上的实验表明，我们的LP-TGNN显著优于基线方法。我们还通过对每个组件的消融研究验证了其有效性及分析作用机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently become the predominant tools forstudying graph data. Despite state-of-the-art performance on graphclassification tasks, GNNs are overwhelmingly trained in a single domain undersupervision, thus necessitating a prohibitively high demand for labels andresulting in poorly transferable representations. To address this challenge, wepropose the Label-Propagation Tensor Graph Neural Network (LP-TGNN) frameworkto bridge the gap between graph data and traditional domain adaptation methods.It extracts graph topological information holistically with a tensorarchitecture and then reduces domain discrepancy through label propagation. Itis readily compatible with general GNNs and domain adaptation techniques withminimal adjustment through pseudo-labeling. Experiments on various real-worldbenchmarks show that our LP-TGNN outperforms baselines by a notable margin. Wealso validate and analyze each component of the proposed framework in theablation study.</description>
      <author>example@mail.com (Tao Wen, Elynn Chen, Yuzhou Chen, Qi Lei)</author>
      <guid isPermaLink="false">2502.08505v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Cardiac Arrest Prediction in ICU using PPG Foundation Model</title>
      <link>http://arxiv.org/abs/2502.08612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究提出了一种用于预测住院心脏骤停(IHCA)的两阶段模型Feature Extractor-Aggregator Network (FEAN)，仅使用单通道指尖光电容积描记(PPG)信号。该模型利用预训练的PPG基础模型与序列分类模型结合，展示了在重症监护病房(ICU)患者中只用连续PPG信号进行预测的心脏骤停结果。&lt;h4&gt;背景&lt;/h4&gt;非侵入性病人监测在跟踪和预测急性不良健康事件方面的研究是一个新兴领域。特别是心脏骤停(IHCA)的早期预警具有重大临床意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于单通道PPG信号的新方法，用于预测住院患者心脏骤停的发生，提高对心脏骤停风险的识别能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Feature Extractor-Aggregator Network (FEAN)，该模型使用预训练的大规模PPG基础模型（如PPG-GPT），结合序列分类器，以1小时或24小时历史数据为基础进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;在心脏骤停前24小时内平均获得0.79的AUROC值；在一小时前达到最高性能，为0.82。此外，通过架构调优和PaCMAP可视化技术提供了模型全面分析。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了利用单模态PPG信号进行心脏骤停预测的有效性，并且可能成为未来非侵入式监测系统的一部分。&lt;h4&gt;翻译&lt;/h4&gt;无创患者监控在跟踪和预测急性不良健康事件方面的研究正在成为一个新兴领域。我们使用单一通道的指尖光电容积描记(PPG)信号来探索住院心脏骤停(IHCA)的预测。所提出的两阶段模型Feature Extractor-Aggregator Network (FEAN)，结合了预训练的大规模PPG基础模型（如PPG-GPT）和序列分类器。我们提出了两种FEAN变体('1H', 'FH')，分别使用最新一小时和最多24小时的历史数据来做出决策。本研究首次展示了仅用连续单模态(PPG信号)波形的深度表示，在ICU患者中预测IHCA的结果。通过我们的最佳模型，在心脏骤停事件发生前24~h的时间窗口内获得0.79的平均AUROC值，其中在事件发生一小时前达到峰值性能为0.82。我们还通过架构调整和PaCMAP技术对患者的健康轨迹进行了潜空间可视化分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-invasive patient monitoring for tracking and predicting adverse acutehealth events is an emerging area of research. We pursue in-hospital cardiacarrest (IHCA) prediction using only single-channel finger photoplethysmography(PPG) signals. Our proposed two-stage model Feature Extractor-AggregatorNetwork (FEAN) leverages powerful representations from pre-trained PPGfoundation models (PPG-GPT of size up to 1 Billion) stacked with sequentialclassification models. We propose two FEAN variants ("1H", "FH") which use thelatest one-hour and (max) 24-hour history to make decisions respectively. Ourstudy is the first to present IHCA prediction results in ICU patients usingonly unimodal (continuous PPG signal) waveform deep representations. With ourbest model, we obtain an average of 0.79 AUROC over 24~h prediction windowbefore CA event onset with our model peaking performance at 0.82 one hourbefore CA. We also provide a comprehensive analysis of our model througharchitectural tuning and PaCMAP visualization of patient health trajectory inlatent space.</description>
      <author>example@mail.com (Saurabh Kataria, Ran Xiao, Timothy Ruchti, Matthew Clark, Jiaying Lu, Randall J. Lee, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.08612v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Keep your distance: learning dispersed embeddings on $\mathbb{S}_d$</title>
      <link>http://arxiv.org/abs/2502.08231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在高维空间中学习分离特征的重要性，并提出了一种新的角度来促进这种分离，即使用最大均值差异(MMD)重新解释成对分散。&lt;h4&gt;背景&lt;/h4&gt;在处理文本或图像嵌入等高维度数据时，有效的特征分离对于机器学习应用至关重要。通过限制特征在一个超球面上进行散布可以解决这一问题，并且已有理论和数值解法适用于低维情况，但这些方法难以直接应用于实际的表示学习任务。&lt;h4&gt;目的&lt;/h4&gt;探索新的分散方法以改进高维度空间中的表示学习以及提高不同领域的性能。&lt;h4&gt;方法&lt;/h4&gt;重新诠释成对散度使用最大均值差异(MMD)动机，并提出了一种在线K-Means算法变体作为通用域上的有效替代正则化器，此外还提出了直接利用超球面特性的新分散技术。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示了分散在图像分类和自然语言处理任务中的重要性以及不同算法的权衡表现。&lt;h4&gt;结论&lt;/h4&gt;新的散度方法能够有效地促进高维度特征分离，并提高了各种领域的机器学习性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中描述的学习良好分离的特征在处理文本或图片等高维数据时非常重要，这可以通过散布嵌入来实现。然而，在表示学习领域通常需要面对大规模和高维度的数据挑战，现有的理论和数值解决方案难以直接适用。因此，人们常常依赖于基于梯度的方法鼓励分散，并通过最小化某些成对距离函数来达成目标。本文首先介绍了现有方法并指出了它们之间的联系与相似性，然后提出了一些新的角度以及利用超球面特性的新散度技术。实验表明了分散对于图像分类和自然语言处理的重要性，同时展示了不同算法在不同类型任务中的性能权衡情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning well-separated features in high-dimensional spaces, such as text orimage embeddings, is crucial for many machine learning applications. Achievingsuch separation can be effectively accomplished through the dispersion ofembeddings, where unrelated vectors are pushed apart as much as possible. Byconstraining features to be on a hypersphere, we can connect dispersion towell-studied problems in mathematics and physics, where optimal solutions areknown for limited low-dimensional cases. However, in representation learning wetypically deal with a large number of features in high-dimensional space, andmoreover, dispersion is usually traded off with some other task-orientedtraining objective, making existing theoretical and numerical solutionsinapplicable. Therefore, it is common to rely on gradient-based methods toencourage dispersion, usually by minimizing some function of the pairwisedistances. In this work, we first give an overview of existing methods fromdisconnected literature, making new connections and highlighting similarities.Next, we introduce some new angles. We propose to reinterpret pairwisedispersion using a maximum mean discrepancy (MMD) motivation. We then proposean online variant of the celebrated Lloyd's algorithm, of K-Means fame, as aneffective alternative regularizer for dispersion on generic domains. Finally,we derive a novel dispersion method that directly exploits properties of thehypersphere. Our experiments show the importance of dispersion in imageclassification and natural language processing tasks, and how algorithmsexhibit different trade-offs in different regimes.</description>
      <author>example@mail.com (Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae)</author>
      <guid isPermaLink="false">2502.08231v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Causal Analysis of ASR Errors for Children: Quantifying the Impact of Physiological, Cognitive, and Extrinsic Factors</title>
      <link>http://arxiv.org/abs/2502.08587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Computer Speech &amp; Language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;近年来，随着儿童自动语音识别（ASR）系统的广泛应用，研究者们致力于提高专为儿童设计的模型准确度。该研究旨在填补现有研究中对于基于开放源代码或针对儿童进行微调后的基础语音模型在性能下降原因分析上的空白。&lt;h4&gt;背景&lt;/h4&gt;当前的方法要么直接使用开源语音基础模型（SFM），要么用儿童语音数据对其进行微调，然而这些模型通常表现出高于成人言语的单词错误率（WER）。&lt;h4&gt;目的&lt;/h4&gt;理解并解决这种性能差距的原因对于改善针对儿童语音的基础模型准确性至关重要。本研究通过调查准确度下降的原因以及造成WER的主要因素来填补这一空白。&lt;h4&gt;方法&lt;/h4&gt;首先，在两个自我监督SFM（Wav2Vec2.0和Hubert）及两种弱监督SFM（Whisper和MMS）的不同年龄段上的儿童语音语料库上进行了全面基准测试，建立了因果推理分析第二部分的原始数据。然后使用因果推断技术来评估生理因素、认知因素和外部因素对儿童言语SFM准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，生理因素（年龄）以及特定的外部因素（音频中的单词数量）对准确度影响最大，其次是背景噪音和发音能力。针对儿童语音微调基础模型可以减少其对生理和认知因素的敏感性，但依然存在对于音频中单词数目的敏感。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了影响儿童ASR系统准确性的重要因素，并提供了如何通过针对性改进这些因素来提高SFM性能的方法。&lt;h4&gt;翻译&lt;/h4&gt;近年来，随着用于儿童自动语音识别（ASR）系统的增加，研究人员一直在努力改进针对儿童语言设计的模型准确度。当前的研究方法涉及到直接使用开源基础语音模型或者用儿童的数据微调这些模型，然而无论开源还是经过孩子数据微调的基础语音模型通常都会表现出比成人言语更高的单词错误率(WER)。目前尚缺乏系统地分析导致这种性能下降的原因。了解并解决这些差距对于提高SFM的准确性至关重要。研究通过评估基础语音模型在各种年龄段上两个儿童语言语料库中的表现，建立了因果推断分析的基础，并深入探讨了影响儿童ASR系统的准确性的生理、认知和外部因素的影响程度。研究表明年龄、音频单词数量是最重要的决定因素，其次是背景噪音以及发音能力。针对儿童语言数据微调SFM可以减少其对生理与认知特征的敏感性，但仍然保持对于音频中单词数目的敏感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing use of children's automatic speech recognition (ASR) systemshas spurred research efforts to improve the accuracy of models designed forchildren's speech in recent years. The current approach utilizes eitheropen-source speech foundation models (SFMs) directly or fine-tuning them withchildren's speech data. These SFMs, whether open-source or fine-tuned forchildren, often exhibit higher word error rates (WERs) compared to adultspeech. However, there is a lack of systemic analysis of the cause of thisdegraded performance of SFMs. Understanding and addressing the reasons behindthis performance disparity is crucial for improving the accuracy of SFMs forchildren's speech. Our study addresses this gap by investigating the causes ofaccuracy degradation and the primary contributors to WER in children's speech.In the first part of the study, we conduct a comprehensive benchmarking studyon two self-supervised SFMs (Wav2Vec2.0 and Hubert) and two weakly supervisedSFMs (Whisper and MMS) across various age groups on two children speechcorpora, establishing the raw data for the causal inference analysis in thesecond part. In the second part of the study, we analyze the impact ofphysiological factors (age, gender), cognitive factors (pronunciation ability),and external factors (vocabulary difficulty, background noise, and word count)on SFM accuracy in children's speech using causal inference. The resultsindicate that physiology (age) and particular external factor (number of wordsin audio) have the highest impact on accuracy, followed by background noise andpronunciation ability. Fine-tuning SFMs on children's speech reducessensitivity to physiological and cognitive factors, while sensitivity to thenumber of words in audio persists.  Keywords: Children's ASR, Speech Foundational Models, Causal Inference,Physiology, Cognition, Pronunciation</description>
      <author>example@mail.com (Vishwanath Pratap Singh, Md. Sahidullah, Tomi Kinnunen)</author>
      <guid isPermaLink="false">2502.08587v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Hi-End-MAE: Hierarchical encoder-driven masked autoencoders are stronger vision learners for medical image segmentation</title>
      <link>http://arxiv.org/abs/2502.08347v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, Code: https://github.com/FengheTan9/Hi-End-MAE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Hi-End-MAE的新颖的预训练框架，用于提高Vision Transformer在医疗图像分割任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割由于标签稀疏而面临挑战。通过未标记的大规模数据集进行掩码图像建模（MIM）预训练可以解决这个问题，并且ViT具有计算效率和模型泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于Transformer的简单有效的预训练解决方案，以提高其在医学影像分割任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了两个创新点：编码器驱动重建和分层密集解码。前者使编码器能够学习更丰富的特征；后者通过实现层次化解码结构来捕捉不同层级之间的丰富表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Hi-End-MAE在多个医学图像分割基准测试中具有优越的迁移学习能力。&lt;h4&gt;结论&lt;/h4&gt;证明了ViT模型在医疗成像应用中的巨大潜力。该框架为未来的研究提供了一个良好的起点。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种新的预训练方法，通过改进Vision Transformer架构来提升其在医学图像分割任务上的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation remains a formidable challenge due to the labelscarcity. Pre-training Vision Transformer (ViT) through masked image modeling(MIM) on large-scale unlabeled medical datasets presents a promising solution,providing both computational efficiency and model generalization for variousdownstream tasks. However, current ViT-based MIM pre-training frameworkspredominantly emphasize local aggregation representations in output layers andfail to exploit the rich representations across different ViT layers thatbetter capture fine-grained semantic information needed for more precisemedical downstream tasks. To fill the above gap, we hereby present HierarchicalEncoder-driven MAE (Hi-End-MAE), a simple yet effective ViT-based pre-trainingsolution, which centers on two key innovations: (1) Encoder-drivenreconstruction, which encourages the encoder to learn more informative featuresto guide the reconstruction of masked patches; and (2) Hierarchical densedecoding, which implements a hierarchical decoding structure to capture richrepresentations across different layers. We pre-train Hi-End-MAE on alarge-scale dataset of 10K CT scans and evaluated its performance across sevenpublic medical image segmentation benchmarks. Extensive experiments demonstratethat Hi-End-MAE achieves superior transfer learning capabilities across variousdownstream tasks, revealing the potential of ViT in medical imagingapplications. The code is available at:https://github.com/FengheTan9/Hi-End-MAE</description>
      <author>example@mail.com (Fenghe Tang, Qingsong Yao, Wenxin Ma, Chenxu Wu, Zihang Jiang, S. Kevin Zhou)</author>
      <guid isPermaLink="false">2502.08347v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Tokenized Graph Transformers for Node Classification</title>
      <link>http://arxiv.org/abs/2502.08101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图变换器(SwapGT)方法，用于改进节点分类任务中令牌序列的生成。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图变换器的方法在节点分类任务中展示了良好的性能。这些模型依赖于将输入图转换为令牌序列的关键模块来促进节点表示学习。&lt;h4&gt;目的&lt;/h4&gt;解决现有图变换器只关注构造相似性图的一阶邻居的问题，通过改进令牌生成策略提高模型的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的令牌交换操作，以充分利用节点之间的语义相关性，从而生成更多样的令牌序列。然后使用基于Transformer的骨干网络从这些序列中学习节点表示，并开发一种中心对齐损失来约束来自多个令牌序列的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验结果表明SwapGT在多种数据集上的性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够更有效地利用图中的信息，从而提高节点分类任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;节点标记化图变换器（GTs）在节点分类中表现出良好的性能。现有的令牌序列生成策略仅关注构造的相似性图的一阶邻居，限制了模型从更多节点获取多样令牌序列的能力。为了解决这个问题，我们提出了SwapGT方法，它通过引入基于令牌特性的交换操作来改进这一过程，并结合中心对齐损失进一步优化表示学习。实验结果表明，与现有技术相比，该方法在节点分类任务中表现更优。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node tokenized graph Transformers (GTs) have shown promising performance innode classification. The generation of token sequences is the key module inexisting tokenized GTs which transforms the input graph into token sequences,facilitating the node representation learning via Transformer. In this paper,we observe that the generations of token sequences in existing GTs only focuson the first-order neighbors on the constructed similarity graphs, which leadsto the limited usage of nodes to generate diverse token sequences, furtherrestricting the potential of tokenized GTs for node classification. To thisend, we propose a new method termed SwapGT. SwapGT first introduces a noveltoken swapping operation based on the characteristics of token sequences thatfully leverages the semantic relevance of nodes to generate more informativetoken sequences. Then, SwapGT leverages a Transformer-based backbone to learnnode representations from the generated token sequences. Moreover, SwapGTdevelops a center alignment loss to constrain the representation learning frommultiple token sequences, further enhancing the model performance. Extensiveempirical results on various datasets showcase the superiority of SwapGT fornode classification.</description>
      <author>example@mail.com (Jinsong Chen, Chenyang Li, GaiChao Li, John E. Hopcroft, Kun He)</author>
      <guid isPermaLink="false">2502.08101v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>ESPFormer: Doubly-Stochastic Attention with Expected Sliced Transport Plans</title>
      <link>http://arxiv.org/abs/2502.07962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于切片最优传输的新型完全并行化双重随机注意机制，该方法在不使用迭代Sinkhorn归一化的前提下实现了注意力分布的平衡和结构优化。&lt;h4&gt;背景&lt;/h4&gt;自注意力机制虽然对Transformer模型的成功至关重要，但可能导致训练过程中某些令牌过度集中，从而影响信息流动。现有的双随机性约束方法依赖于计算成本高昂的迭代Sinkhorn标准化过程。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的、完全并行化的双重随机注意机制，以提高效率和性能，同时确保可以无缝集成到深度学习模型中。&lt;h4&gt;方法&lt;/h4&gt;引入了基于切片最优传输的新注意力机制，利用期望切片传输计划（ESP）来实现双随机性约束。通过温度基软排序技术保证可微分性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个基准数据集上（包括图像分类、点云分类、情感分析和神经机器翻译等任务），该增强注意力正则化机制在各种应用场景中都能显著提升性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法提供了一种更有效且计算成本更低的方式来优化Transformer模型中的自注意力机制，从而提高不同领域的深度学习应用的效率与准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：虽然自我注意对于Transformer的成功至关重要，但它可能会导致在训练过程中某些令牌过度集中，影响信息流动。强制执行双随机约束已经被证明可以改善注意力分布的结构和平衡性。然而，现有的方法依赖于迭代Sinkhorn归一化过程，这计算成本高昂。本文介绍了一种基于切片最优传输的新型完全并行化的双重随机注意机制，利用期望切片传输计划（ESP）。与以往的方法不同，该方法在不使用迭代Sinkhorn标准化的情况下实现了双随机性约束，显著提高了效率。为了确保可微分性，我们引入了基于温度的软排序技术，使得能够无缝集成到深度学习模型中。实验结果显示，在包括图像分类、点云分类、情感分析和神经机器翻译在内的多个基准数据集上，增强注意力正则化机制在各种应用场景中的性能都有所提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While self-attention has been instrumental in the success of Transformers, itcan lead to over-concentration on a few tokens during training, resulting insuboptimal information flow. Enforcing doubly-stochastic constraints inattention matrices has been shown to improve structure and balance in attentiondistributions. However, existing methods rely on iterative Sinkhornnormalization, which is computationally costly. In this paper, we introduce anovel, fully parallelizable doubly-stochastic attention mechanism based onsliced optimal transport, leveraging Expected Sliced Transport Plans (ESP).Unlike prior approaches, our method enforces double stochasticity withoutiterative Sinkhorn normalization, significantly enhancing efficiency. To ensuredifferentiability, we incorporate a temperature-based soft sorting technique,enabling seamless integration into deep learning models. Experiments acrossmultiple benchmark datasets, including image classification, point cloudclassification, sentiment analysis, and neural machine translation, demonstratethat our enhanced attention regularization consistently improves performanceacross diverse applications.</description>
      <author>example@mail.com (Ashkan Shahbazi, Elaheh Akbari, Darian Salehi, Xinran Liu, Navid Naderializadeh, Soheil Kolouri)</author>
      <guid isPermaLink="false">2502.07962v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised categorization of similarity measures</title>
      <link>http://arxiv.org/abs/2502.08098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2306.00239&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了人工神经网络系统通过表示学习自主分类度量空间的能力，这些空间对应于物体特征，并且探讨了如何独立评估特征之间的差异和相似性。&lt;h4&gt;背景&lt;/h4&gt;现有的方法往往限制潜在空间的轴线相互独立或正交。然而，这种相互独立的轴线不适合对度量空间进行分类。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服现有方法中关于高维度量空间分类的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一种只约束空间之间互相独立而不强制轴线单独独立的方法。&lt;h4&gt;主要发现&lt;/h4&gt;提出了满足代数独立性的理论条件，这为无监督的独立度量空间分类提供了通用条件，并推动了神经网络功能分化数学理论的发展。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，人工神经网络可以更好地处理和分类不同特征空间（如颜色空间和形状空间）之间的关系。&lt;h4&gt;翻译&lt;/h4&gt;通常情况下，物体可以根据其特性和属性进行区分，例如颜色或形状。特别是假设这些特性在不同的度量空间中可以独立地进行相似性判断。然而，与对象特征对应的度量空间的无监督分类机制尚不清楚。本研究展示了人工神经网络系统通过表示学习自主对度量空间进行分类以满足神经网络之间的代数独立性，并将感觉信息投射到多个高维度量空间中来独立评估特性之间的差异和相似性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In general, objects can be distinguished on the basis of their features, suchas color or shape. In particular, it is assumed that similarity judgments aboutsuch features can be processed independently in different metric spaces.However, the unsupervised categorization mechanism of metric spacescorresponding to object features remains unknown. Here, we show that theartificial neural network system can autonomously categorize metric spacesthrough representation learning to satisfy the algebraic independence betweenneural networks, and project sensory information onto multiple high-dimensionalmetric spaces to independently evaluate the differences and similaritiesbetween features. Conventional methods often constrain the axes of the latentspace to be mutually independent or orthogonal. However, the independent axesare not suitable for categorizing metric spaces. High-dimensional metric spacesthat are independent of each other are not uniquely determined by the mutuallyindependent axes, because any combination of independent axes can form mutuallyindependent spaces. In other words, the mutually independent axes cannot beused to naturally categorize different feature spaces, such as color space andshape space. Therefore, constraining the axes to be mutually independent makesit difficult to categorize high-dimensional metric spaces. To overcome thisproblem, we developed a method to constrain only the spaces to be mutuallyindependent and not the composed axes to be independent. Our theory providesgeneral conditions for the unsupervised categorization of independent metricspaces, thus advancing the mathematical theory of functional differentiation ofneural networks.</description>
      <author>example@mail.com (Yoshiyuki Ohmura, Wataru Shimaya, Yasuo Kuniyoshi)</author>
      <guid isPermaLink="false">2502.08098v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy</title>
      <link>http://arxiv.org/abs/2502.08353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了图神经网络（GNN）与大型语言模型（LLM）结合的现状，提出了一个分类框架来帮助研究人员理解不同方法的原则和应用场景，并系统地回顾了代表性方法，指出了这些方法在集成过程中的适用场景、潜在优势及限制。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络在各个领域的广泛应用，其可信度问题成为研究重点。一些现有研究表明，将大型语言模型与GNN结合可以提高其语义理解和生成能力，从而从多方面提升GNN的可信度。&lt;h4&gt;目的&lt;/h4&gt;介绍一种分类框架以帮助研究人员理解不同方法之间的联系和区别，并总结代表性方法在四个类别中的表现情况。&lt;h4&gt;方法&lt;/h4&gt;提出了一种关于如何将大型语言模型（LLM）与图神经网络（GNN）集成的方法分类体系，系统地对具有代表性的方法进行了回顾。&lt;h4&gt;主要发现&lt;/h4&gt;通过所提出的分类体系，研究人员可以理解每种方法在可信集成功能中的适用场景、潜在优势和局限性。此外还指出了未来研究的方向和趋势。&lt;h4&gt;结论&lt;/h4&gt;提出了一个明确的框架来帮助研究人员了解不同方法之间的关系及其应用场景，并展望了LLM与GNN结合以提高模型可靠性的未来发展方向。&lt;h4&gt;翻译&lt;/h4&gt;随着图神经网络（GNN）在各个领域的广泛应用，其可信度问题成为研究重点。一些现有研究表明，将大型语言模型（LLM）集成到GNN中可以提升其语义理解和生成能力，从而从多个角度增强GNN的可靠性。该论文综述介绍了这种分类框架，并系统地总结了代表性方法，旨在为未来的研究方向提供指南和趋势预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the extensive application of Graph Neural Networks (GNNs) across variousdomains, their trustworthiness has emerged as a focal point of research. Someexisting studies have shown that the integration of large language models(LLMs) can improve the semantic understanding and generation capabilities ofGNNs, which in turn improves the trustworthiness of GNNs from various aspects.Our review introduces a taxonomy that offers researchers a clear framework forcomprehending the principles and applications of different methods and helpsclarify the connections and differences among various approaches. Then wesystematically survey representative approaches along the four categories ofour taxonomy. Through our taxonomy, researchers can understand the applicablescenarios, potential advantages, and limitations of each approach for the thetrusted integration of GNNs with LLMs. Finally, we present some promisingdirections of work and future trends for the integration of LLMs and GNNs toimprove model trustworthiness.</description>
      <author>example@mail.com (Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang)</author>
      <guid isPermaLink="false">2502.08353v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</title>
      <link>http://arxiv.org/abs/2502.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2306.02873 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VISTA是一个专门用于科学领域视频到文本摘要的数据库，旨在解决将记录的视频转化为简洁准确的文字摘要这一多模态学习中的挑战。&lt;h4&gt;背景&lt;/h4&gt;在多模态学习中，从记录的视频生成简洁且准确的文本摘要是一项日益增长的挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍VISTA数据集，并评估最先进的大型模型在其上的性能。同时应用基于计划的框架以更好地捕捉摘要结构化特性。&lt;h4&gt;方法&lt;/h4&gt;将18,599个AI会议演讲录音与其对应的论文摘要配对，使用计划基础框架来生成总结并进行人类和自动化的评价。&lt;h4&gt;主要发现&lt;/h4&gt;显式的规划提高了摘要质量和事实一致性。然而，模型性能与人类表现之间仍存在显著差距。&lt;h4&gt;结论&lt;/h4&gt;尽管基于计划的方法改进了科学视频摘要的准确性，但该领域仍然面临挑战。&lt;h4&gt;翻译&lt;/h4&gt;将记录的视频转换为简洁准确的文字总结是多模态学习中的一个日益增长的挑战。本文介绍了一个专门用于科学领域的视频到文本总结的数据集VISTA，它包含了18,599个AI会议演讲录音及其对应的论文摘要。我们对最先进的大型模型进行了基准测试，并应用了基于计划框架来更好地捕捉摘要结构化特性。无论是人工还是自动化评估都证实了显式规划提升了摘要质量和事实一致性。然而，模型与人类表现之间的差距依然存在，这突显了科学视频总结中的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transforming recorded videos into concise and accurate textual summaries is agrowing challenge in multimodal learning. This paper introduces VISTA, adataset specifically designed for video-to-text summarization in scientificdomains. VISTA contains 18,599 recorded AI conference presentations paired withtheir corresponding paper abstracts. We benchmark the performance ofstate-of-the-art large models and apply a plan-based framework to bettercapture the structured nature of abstracts. Both human and automatedevaluations confirm that explicit planning enhances summary quality and factualconsistency. However, a considerable gap remains between models and humanperformance, highlighting the challenges of scientific video summarization.</description>
      <author>example@mail.com (Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg)</author>
      <guid isPermaLink="false">2502.08279v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Mixture of Decoupled Message Passing Experts with Entropy Constraint for General Node Classification</title>
      <link>http://arxiv.org/abs/2502.08083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2412.08193&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于混合专家(MoE)机制的通用节点分类框架GNNMoE，用于解决图神经网络(GNNs)在处理同质性和异质性不同的现实世界图形时面临的问题。&lt;h4&gt;背景&lt;/h4&gt;现实中图的数据结构中存在着不同程度的同质性和异质性，这使得现有的图神经网络难以实现普遍适用性。从数据为中心的角度来看，不同的图对不同信息传播编码方案有着固有的偏好：同质图倾向于局部传播，而异质图则更喜欢传播和转换的灵活组合。&lt;h4&gt;目的&lt;/h4&gt;为了提高GNN在处理不同类型图形时的表现力和适应性，设计了一种通用节点分类框架。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于Mixture-of-Experts (MoE)机制的节点分类框架GNNMoE。该框架首先通过细粒度编码操作重构出多样化的消息传递专家网络，然后设计了软硬门控层以分配最适合每个节点表示学习的专家网络，并引入熵约束来指导软门控的硬化过程。&lt;h4&gt;主要发现&lt;/h4&gt;提出的GNNMoE框架在节点分类性能和跨多种图数据集的通用性方面显著优于主流图神经网络、异质图神经网络以及图变换器。&lt;h4&gt;结论&lt;/h4&gt;通过实验证明，所提出的GNNMoE框架能够有效解决现有图神经网络处理不同类型图形时面临的挑战，并提高模型的表现力和适应性。&lt;h4&gt;翻译&lt;/h4&gt;现实世界中的图数据结构存在不同程度的同质性和异质性，这限制了图神经网络(GNNs)在节点分类任务上的普遍适用性。本研究采用数据为中心的方法揭示了不同类型的图对不同的消息编码方案有着固有的偏好：同质图倾向于局部传播，而异质图则更喜欢灵活组合的消息传递和转换。为解决这一问题，提出了一种基于混合专家机制的通用节点分类框架GNNMoE。该框架通过构建多样化的消息传递专家网络，并设计软硬门控层来选择最适合每个节点表示学习的网络，从而提高模型的表现力和适应性。此外，在同质场景中引入熵约束以减少编码噪声的影响。实验结果表明，GNNMoE在节点分类性能以及对不同类型图数据集的通用性方面均优于主流图神经网络、异质图神经网络及图变换器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The varying degrees of homophily and heterophily in real-world graphspersistently constrain the universality of graph neural networks (GNNs) fornode classification. Adopting a data-centric perspective, this work reveals aninherent preference of different graphs towards distinct message encodingschemes: homophilous graphs favor local propagation, while heterophilous graphsexhibit preference for flexible combinations of propagation and transformation.To address this, we propose GNNMoE, a universal node classification frameworkbased on the Mixture-of-Experts (MoE) mechanism. The framework first constructsdiverse message-passing experts through recombination of fine-grained encodingoperators, then designs soft and hard gating layers to allocate the mostsuitable expert networks for each node's representation learning, therebyenhancing both model expressiveness and adaptability to diverse graphs.Furthermore, considering that soft gating might introduce encoding noise inhomophilous scenarios, we introduce an entropy constraint to guide sharpeningof soft gates, achieving organic integration of weighted combination and Top-Kselection. Extensive experiments demonstrate that GNNMoE significantlyoutperforms mainstream GNNs, heterophilous GNNs, and graph transformers in bothnode classification performance and universality across diverse graph datasets.</description>
      <author>example@mail.com (Xuanze Chen, Jiajun Zhou, Jinsong Chen, Shanqing Yu, Qi Xuan)</author>
      <guid isPermaLink="false">2502.08083v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Graph Foundation Models for Recommendation: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2502.08346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;基于图基础模型的推荐系统技术综述&lt;h4&gt;背景&lt;/h4&gt;推荐系统（RS）是导航海量在线信息的基本工具，深度学习的进步在提高排序准确性方面发挥着越来越重要的作用。其中，图形神经网络（GNNs）擅长提取高级结构化信息，而大型语言模型（LLMs）则旨在处理和理解自然语言，使两者都成为高度有效且广泛采用的方法。&lt;h4&gt;目的&lt;/h4&gt;本文提供了一种基于图基础模型的推荐系统技术的全面概述，介绍当前方法的分类、深入分析方法细节，并强调关键挑战和未来方向。&lt;h4&gt;方法&lt;/h4&gt;通过综合最近的进步，我们旨在为基于GFM（图基础模型）的推荐系统的演变格局提供有价值的见解。&lt;h4&gt;主要发现&lt;/h4&gt;最近的研究集中在将GNNs和LLMs的优点结合在一起的方法上，这些方法利用用户-项目关系的图形结构以及文本理解来更有效地建模复杂的RS问题。&lt;h4&gt;结论&lt;/h4&gt;通过合成近期进展，本文旨在为基于图基础模型（GFMs）的推荐系统提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：Recommender systems (RS) serve as a fundamental tool for navigating the vast expanse of online information, with deep learning advancements playing an increasingly important role in improving ranking accuracy. Among these, graph neural networks (GNNs) excel at extracting higher-order structural information, while large language models (LLMs) are designed to process and comprehend natural language, making both approaches highly effective and widely adopted. Recent research has focused on graph foundation models (GFMs), which integrate the strengths of GNNs and LLMs to model complex RS problems more efficiently by leveraging the graph-based structure of user-item relationships alongside textual understanding. In this survey, we provide a comprehensive overview of GFM-based RS technologies by introducing a clear taxonomy of current approaches, diving into methodological details, and highlighting key challenges and future directions. By synthesizing recent advancements, we aim to offer valuable insights into the evolving landscape of GFM-based recommender systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) serve as a fundamental tool for navigating the vastexpanse of online information, with deep learning advancements playing anincreasingly important role in improving ranking accuracy. Among these, graphneural networks (GNNs) excel at extracting higher-order structural information,while large language models (LLMs) are designed to process and comprehendnatural language, making both approaches highly effective and widely adopted.Recent research has focused on graph foundation models (GFMs), which integratethe strengths of GNNs and LLMs to model complex RS problems more efficiently byleveraging the graph-based structure of user-item relationships alongsidetextual understanding. In this survey, we provide a comprehensive overview ofGFM-based RS technologies by introducing a clear taxonomy of currentapproaches, diving into methodological details, and highlighting key challengesand future directions. By synthesizing recent advancements, we aim to offervaluable insights into the evolving landscape of GFM-based recommender systems.</description>
      <author>example@mail.com (Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi)</author>
      <guid isPermaLink="false">2502.08346v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Human-Centric Foundation Models: Perception, Generation and Agentic Modeling</title>
      <link>http://arxiv.org/abs/2502.08556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了Human-centric Foundation Models (HcFMs)，提出了一个分类体系，将当前的方法分为四类：人类感知基础模型、人类AIGC基础模型、统一的感知和生成模型以及人类代理基础模型。&lt;h4&gt;背景&lt;/h4&gt;人机交互理解与生成是数字人建模的关键。受到大型语言和视觉模型成功的启发，HcFMs旨在将各种以人为中心的任务整合到一个框架中，超越了传统的特定任务方法。&lt;h4&gt;目的&lt;/h4&gt;综述提供了一个全面的视角来审视现有的HcFMs，并讨论最新的技术、存在的挑战以及未来的研究方向。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种分类体系，该体系将HcFMs分为四个主要类别：人类感知基础模型、人类AIGC基础模型、统一的感知和生成模型、以及人类代理基础模型。每个类别都包含了不同的任务和能力。&lt;h4&gt;主要发现&lt;/h4&gt;四种类型的HcFMs分别在不同方面展现出了独特的优势，从捕捉多模态的理解到高保真度内容的生成再到模拟交互行为等方面均有所贡献。&lt;h4&gt;结论&lt;/h4&gt;综述旨在为研究者提供一个路线图，推动更加坚固、多样化和智能的数字人建模的发展。&lt;h4&gt;翻译&lt;/h4&gt;人类理解和生成对于建模数字人和拟人化实体至关重要。最近，受到大型语言模型和视觉模型成功的启发，以人为中心的基础模型(HcFMs)应运而生，旨在将各种以人为中心的任务整合到一个框架中，并超越传统的特定任务方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human understanding and generation are critical for modeling digital humansand humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)inspired by the success of generalist models, such as large language and visionmodels, have emerged to unify diverse human-centric tasks into a singleframework, surpassing traditional task-specific approaches. In this survey, wepresent a comprehensive overview of HcFMs by proposing a taxonomy thatcategorizes current approaches into four groups: (1) Human-centric PerceptionFoundation Models that capture fine-grained features for multi-modal 2D and 3Dunderstanding. (2) Human-centric AIGC Foundation Models that generatehigh-fidelity, diverse human-related content. (3) Unified Perception andGeneration Models that integrate these capabilities to enhance both humanunderstanding and synthesis. (4) Human-centric Agentic Foundation Models thatextend beyond perception and generation to learn human-like intelligence andinteractive behaviors for humanoid embodied tasks. We review state-of-the-arttechniques, discuss emerging challenges and future research directions. Thissurvey aims to serve as a roadmap for researchers and practitioners workingtowards more robust, versatile, and intelligent digital human and embodimentsmodeling.</description>
      <author>example@mail.com (Shixiang Tang, Yizhou Wang, Lu Chen, Yuan Wang, Sida Peng, Dan Xu, Wanli Ouyang)</author>
      <guid isPermaLink="false">2502.08556v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-Guided Wasserstein Distributionally Robust Optimization</title>
      <link>http://arxiv.org/abs/2502.08146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新型的知识引导的Wasserstein分布鲁棒优化（KG-WDRO）框架，通过适应性地利用多源外部知识来改进统计效率。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是一种流行的策略，旨在利用外部知识提高有限样本目标数据集上的统计效率。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法来克服传统WDRO的保守性，该保守性往往导致过度悲观化的向零收缩。&lt;h4&gt;方法&lt;/h4&gt;通过控制运输方向以源知识为指导，构建更小的Wasserstein模糊集合，从而减轻协变量预测投影上的扰动，并防止信息损失。理论证明了KG-WDRO的形式与基于共线相似性的知识引导收缩估计之间的等价性，确保了可行集的可操作性和几何化。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够调整源和目标之间回归模型中的比例差异，并适应诸如lasso和ridge等通用类型的正则化。广泛的模拟表明KG-WDRO在增强小样本迁移学习方面的优越性能和适应性。&lt;h4&gt;结论&lt;/h4&gt;提出了一个新型的基于分布鲁棒性的迁移学习方法，证明了其理论上的有效性和实际应用中的优越性。&lt;h4&gt;翻译&lt;/h4&gt;转移学习是一种流行的策略，利用外部知识提高有限目标数据集的统计效率。本文提出了一种新的知识引导Wasserstein分布鲁棒优化（KG-WDRO）框架，该框架通过适应地结合多源外部知识克服了传统WDRO过于保守的问题，并减轻了预测方向上的扰动和信息损失。该方法建立了WDRO公式与基于共线相似性的知识引导收缩估计之间的等价性，证明其可行性并从分布鲁棒性角度解释最近的收缩迁移学习方法。此外，KG-WDRO能够调整源和目标模型的比例差异，并处理lasso和ridge等通用正则化类型。实验结果表明，该框架在小样本迁移学习中具有优越性能与适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a popular strategy to leverage external knowledge andimprove statistical efficiency, particularly with a limited target sample. Wepropose a novel knowledge-guided Wasserstein Distributionally RobustOptimization (KG-WDRO) framework that adaptively incorporates multiple sourcesof external knowledge to overcome the conservativeness of vanilla WDRO, whichoften results in overly pessimistic shrinkage toward zero. Our methodconstructs smaller Wasserstein ambiguity sets by controlling the transportationalong directions informed by the source knowledge. This strategy can alleviateperturbations on the predictive projection of the covariates and protectagainst information loss. Theoretically, we establish the equivalence betweenour WDRO formulation and the knowledge-guided shrinkage estimation based oncollinear similarity, ensuring tractability and geometrizing the feasible set.This also reveals a novel and general interpretation for recent shrinkage-basedtransfer learning approaches from the perspective of distributional robustness.In addition, our framework can adjust for scaling differences in the regressionmodels between the source and target and accommodates general types ofregularization such as lasso and ridge. Extensive simulations demonstrate thesuperior performance and adaptivity of KG-WDRO in enhancing small-sampletransfer learning.</description>
      <author>example@mail.com (Zitao Wang, Ziyuan Wang, Molei Liu, Nian Si)</author>
      <guid isPermaLink="false">2502.08146v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Data Pricing for Graph Neural Networks without Pre-purchased Inspection</title>
      <link>http://arxiv.org/abs/2502.08284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by AAMAS-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在各种场景中已成为不可或缺的工具。然而，它们的有效性依赖于大量的数据才能达到满意的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于结构重要性的模型交易机制（SIMT），该机制可以在不公开数据的情况下评估数据的重要性并补偿数据所有者。&lt;h4&gt;方法&lt;/h4&gt;SIMT 从数据所有者处获取特征和标签数据，根据它们的结构重要性进行采购，并使用图神经网络为模型消费者训练一个模型。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明 SIMT 确保了激励兼容、个体理性且预算可行。实验结果在五个流行的数据集上验证了 SIMT 在 MacroF1 和 MicroF1 两个指标上均优于基本方案，性能提高可达40%。&lt;h4&gt;结论&lt;/h4&gt;SIMT 是一种有效解决数据交易中数据所有者不愿无偿分享其有价值信息的机制。&lt;h4&gt;翻译&lt;/h4&gt;机器学习模型已成为各种场景中的重要工具。然而，为了达到满意的表现，这些模型需要大量数据的支持。为了解决这个问题，市场平台应运而生，连接寻求机器学习解决方案的模型消费者和拥有宝贵数据的数据所有者。现有的交易机制通常假设在被支付之前数据所有者愿意分享他们的数据，在现实世界中这是不合理的。因此，我们提出了基于结构重要性的模型交易（SIMT）机制，该机制可以评估数据的重要性，并且不需要透露数据就能补偿数据所有者。具体来说，SIMT 根据它们的结构重要性从数据所有者那里获取特征和标签数据，然后为模型消费者训练一个图神经网络。理论上，SIMT 确保激励兼容、个体理性且预算可行。在五个流行的数据集上进行的实验验证了 SIMT 在 MacroF1 和 MicroF1 两个指标上的性能优于基本方案，最高可达40%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) models have become essential tools in variousscenarios. Their effectiveness, however, hinges on a substantial volume of datafor satisfactory performance. Model marketplaces have thus emerged as crucialplatforms bridging model consumers seeking ML solutions and data ownerspossessing valuable data. These marketplaces leverage model trading mechanismsto properly incentive data owners to contribute their data, and return a wellperforming ML model to the model consumers. However, existing model tradingmechanisms often assume the data owners are willing to share their data beforebeing paid, which is not reasonable in real world. Given that, we propose anovel mechanism, named Structural Importance based Model Trading (SIMT)mechanism, that assesses the data importance and compensates data ownersaccordingly without disclosing the data. Specifically, SIMT procures featureand label data from data owners according to their structural importance, andthen trains a graph neural network for model consumers. Theoretically, SIMTensures incentive compatible, individual rational and budget feasible. Theexperiments on five popular datasets validate that SIMT consistentlyoutperforms vanilla baselines by up to $40\%$ in both MacroF1 and MicroF1.</description>
      <author>example@mail.com (Yiping Liu, Mengxiao Zhang, Jiamou Liu, Song Yang)</author>
      <guid isPermaLink="false">2502.08284v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>O1 Embedder: Let Retrievers Think Before Action</title>
      <link>http://arxiv.org/abs/2502.07555v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;大型语言模型(LLMs)在信息检索和利用方面的能力显著提升，尤其擅长细粒度数据表示和基于外部引用的高质量答案生成。最近推出的推理模型进一步增强了LLMs解决问题前进行逐步思考的能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型通过优秀的数据表征能力改善了信息获取方式，并且可以生成基于外部参考的高质量答案。新型推理模型如OpenAI O1 和 DeepSeek R1 进一步提升了这一技术，使其能够解决更加复杂的任务（例如编码和数学证明）。&lt;h4&gt;目的&lt;/h4&gt;受这些进展启发，我们旨在为检索模型开发类似的逐步思考能力，以便更好地处理多任务检索、零样本学习等难题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为O1 Embedder的新方法，用于生成关于输入查询的有用思维以进行目标文档检索。通过设计数据合成工作流和优化训练过程来实现这一目的。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的实验中，该方法取得了显著改进，在跨域场景下的多个流行数据集中表现出色。这表明O1 Embedder具有极高的准确性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;这项研究为下一代信息检索基础模型的发展铺平了道路，展示了其在未来处理复杂任务中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在人们获取和使用信息的方式上发生了革命性的变化。它们擅长进行细粒度的数据表示，这有助于精确的信息检索，并基于外部参考生成高质量的答案，从而产生有用的见解。最近推出的推理模型，如OpenAI O1 和 DeepSeek R1，进一步展示了LLM的逐步思考能力，在交付最终答案之前进行有条理地推演，显著提高了处理复杂任务（例如编码和数学证明）的能力。受这些进步启发，我们旨在为检索模型开发类似的功能，以解决该领域中的关键挑战，包括多任务检索、零样本检索以及需要对复杂关系进行深度推理的任务。为此，我们提出了一种名为O1 Embedder的新方法，在生成目标文档的检索思维之前，先为输入查询生成有用的想法。为了实现这一目标，我们解决了两个技术难题：首先，设计了数据合成工作流，通过LLM专家生成初步想法，并利用检索委员会对其进行改进；其次，优化训练过程，使预训练模型能够联合微调以产生检索思想并通过行为克隆进行密集检索和对比学习。我们的方法经过全面的实验验证，在12个流行的数据集（涵盖域内和域外场景）中实现了显著改善。这些结果表明O1 Embedder具有出色的准确性和泛化能力，为下一代信息检索基础模型的发展铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing power of large language models (LLMs) has revolutionized howpeople access and utilize information. Notably, the LLMs excel at performingfine-grained data representation, which facilitates precise retrieval ofinformation. They also generate high-quality answers based on externalreferences, enabling the production of useful knowledge. The recentintroduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks anotherleap forward, highlighting LLMs' ability to think progressively beforedelivering final answers. This breakthrough significantly improves the abilityto address complex tasks, e.g., coding and math proofs.  Inspired by this progress, we aim to develop similar capabilities forretrieval models, which hold great promise for tackling critical challenges inthe field, including multi-task retrieval, zero-shot retrieval, and tasksrequiring intensive reasoning of complex relationships. With this motivation,we propose a novel approach called O1 Embedder, which generates useful thoughtsfor the input query before making retrieval for the target documents. Torealize this objective, we conquer two technical difficulties. First, we designa data synthesis workflow, creating training signals for O1 Embedder bygenerating initial thoughts from an LLM-expert and subsequently refining themusing a retrieval committee. Second, we optimize the training process, enablinga pre-trained model to be jointly fine-tuned to generate retrieval thoughts viabehavior cloning and perform dense retrieval through contrastive learning. Ourapproach is evaluated by comprehensive experiments, where substantialimprovements are achieved across 12 popular datasets, spanning both in-domainand out-of-domain scenarios. These results highlight O1 Embedder's remarkableaccuracy and generalizability, paving the way for the development ofnext-generation IR foundation models.</description>
      <author>example@mail.com (Ruiran Yan, Zheng Liu, Defu Lian)</author>
      <guid isPermaLink="false">2502.07555v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Equivariant Masked Position Prediction for Efficient Molecular Representation</title>
      <link>http://arxiv.org/abs/2502.08209v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的自监督方法Equivariant Masked Position Prediction (EMPP)，用于改进图神经网络在计算化学中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNNs）在计算化学领域展现出巨大潜力，但分子数据的稀缺性限制了它们捕捉物理和化学基本原理的能力，从而影响其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习方法EMPP以解决现有图神经网络由于缺乏大量训练数据而面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;EMPP基于分子内位势和力理论，通过预测位置的细化任务来改进量子力学特征的学习过程。该方法不同于传统的属性掩码技术，并且在获取物理特性时绕过了常用高斯混合分布近似的限制。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，EMPP显著提高了复杂分子架构的性能，超越了现有的最先进的自监督学习方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法可以更好地利用有限的数据资源来提升图神经网络在计算化学领域的表现。&lt;h4&gt;翻译&lt;/h4&gt;Graph 神经网络（GNNs）在计算化学领域显示出巨大的前景。然而，分子数据的稀缺性引发了人们对于 GNNs 能否有效捕捉物理和化学基本原理能力的担忧，从而限制了它们的泛化能力。为了应对这一挑战，我们引入了一种名为等变掩码位置预测（EMPP）的新颖自监督方法，该方法基于分子内位势和力理论。不同于传统的属性掩码技术，EMPP定义了一个更加精细的位置预测任务，这有助于更好地学习量子力学特征，并绕过了常用的高斯混合分布的近似限制，从而能够更准确地获取物理特性。实验结果表明，EMPP显著提升了复杂分子架构的表现，超越了现有的最先进的自监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown considerable promise in computationalchemistry. However, the limited availability of molecular data raises concernsregarding GNNs' ability to effectively capture the fundamental principles ofphysics and chemistry, which constrains their generalization capabilities. Toaddress this challenge, we introduce a novel self-supervised approach termedEquivariant Masked Position Prediction (EMPP), grounded in intramolecularpotential and force theory. Unlike conventional attribute masking techniques,EMPP formulates a nuanced position prediction task that is more well-definedand enhances the learning of quantum mechanical features. EMPP also bypassesthe approximation of the Gaussian mixture distribution commonly used indenoising methods, allowing for more accurate acquisition of physicalproperties. Experimental results indicate that EMPP significantly enhancesperformance of advanced molecular architectures, surpassing state-of-the-artself-supervised approaches. Our code is released inhttps://github.com/ajy112/EMPP.</description>
      <author>example@mail.com (Junyi An, Chao Qu, Yun-Fei Shi, XinHao Liu, Qianwei Tang, Fenglei Cao, Yuan Qi)</author>
      <guid isPermaLink="false">2502.08209v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Music for All: Exploring Multicultural Representations in Music Generation Models</title>
      <link>http://arxiv.org/abs/2502.07328v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, accepted to NAACL'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了音乐生成领域的数据集和研究文献中存在的偏见，并提出了一种减轻这种偏见的方法。&lt;h4&gt;背景&lt;/h4&gt;音乐语言模型虽然极大地提高了AI系统自动生成音乐的能力，但它们在涵盖世界音乐类型和文化方面存在局限性。现有音乐数据集中只有5.7%来自非西方流派。&lt;h4&gt;目的&lt;/h4&gt;量化这些数据集中的偏见，并评估参数高效微调（PEFT）技术是否能减轻这种偏见，使模型更好地适应不同类型的音乐。&lt;h4&gt;方法&lt;/h4&gt;研究了两个流行模型MusicGen和Mustango在两种代表性不足的非西方音乐传统——印度斯坦古典音乐和土耳其马卡姆音乐上的表现，使用小数据集进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;PEFT技术展示出潜力，但跨流派适应仍然是一个复杂的问题。现有的基线音乐语言模型需要更公平地设计，以支持跨文化迁移学习。&lt;h4&gt;结论&lt;/h4&gt;需要更多研究来创建更加多元化的音乐数据集和更适合全球音乐文化的AI系统。&lt;h4&gt;翻译&lt;/h4&gt;音乐语言模型的出现极大地增强了人工智能系统的自动音乐生成能力，但它们在涵盖世界各地的音乐流派和文化方面存在局限性。本研究分析了用于音乐生成的数据集和研究论文，并量化了这些流派中的偏见和代表性不足问题。实验表明参数高效微调技术对缓解这种偏见有潜在作用，但也暗示需要设计更公平的基础模型来支持跨文化的迁移学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Music-Language Models has greatly enhanced the automatic musicgeneration capability of AI systems, but they are also limited in theircoverage of the musical genres and cultures of the world. We present a study ofthe datasets and research papers for music generation and quantify the bias andunder-representation of genres. We find that only 5.7% of the total hours ofexisting music datasets come from non-Western genres, which naturally leads todisparate performance of the models across genres. We then investigate theefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigatingthis bias. Our experiments with two popular models -- MusicGen and Mustango,for two underrepresented non-Western music traditions -- Hindustani Classicaland Turkish Makam music, highlight the promises as well as the non-trivialityof cross-genre adaptation of music through small datasets, implying the needfor more equitable baseline music-language models that are designed forcross-cultural transfer learning.</description>
      <author>example@mail.com (Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury)</author>
      <guid isPermaLink="false">2502.07328v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation</title>
      <link>http://arxiv.org/abs/2502.08161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在最近的推荐系统中广泛应用，负采样在此过程中扮演着重要角色。现有的负采样方法将节点之间的关系严格限制为硬正样本或硬负样本。&lt;h4&gt;问题&lt;/h4&gt;这种限制导致了结构信息的丢失，并且缺乏生成稀疏邻居节点正面配对机制。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些局限性，提出了基于软链接的新颖采样方法，即MixDec Sampling。&lt;h4&gt;方法&lt;/h4&gt;{'Mixup Sampling模块': '通过合成新的节点和软连接来增强节点特征，为具有少量邻居的节点提供足够的样本。', 'Decay Sampling模块': '通过生成用于节点嵌入学习的软连接来加强图结构信息的理解。'}&lt;h4&gt;主要发现&lt;/h4&gt;据我们所知，这是首次在基于GNN的推荐系统中使用软链接建模采样关系的方法。广泛的实验表明，提出的MixDec Sampling可以显著且一致地提升几种代表性GNN模型在不同推荐基准上的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的基于软连接的负采样方法可以有效地增强图神经网络在推荐系统的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络近年来广泛应用于推荐系统中，并且负样本抽取在这个过程中发挥着关键作用。现有的负样本抽取策略要么采用硬正样本，要么是硬负样本，在这种情况下，节点之间的关系被严格限定，导致结构信息的丢失以及缺乏生成稀疏邻居节点的正向配对机制。为了解决这些问题，我们提出了一种基于软链接的新颖采样方法——MixDec Sampling，该方法由混合抽样模块和衰减抽样模块组成。其中，混合抽样通过合成新的节点及软连接来增强节点特征，并且可以解决稀疏邻居问题中样本数量不足的问题；而衰减抽样则是通过生成用于嵌入学习的软链接强化图结构信息的理解能力。据我们所知，这是首次尝试在基于GNN推荐系统中采用这种利用软链接建模采样关系的方法。大量的实验结果表明，在各种推荐基准下使用该方法可以有效提升多种代表性GNN模型的表现力，并且能够保持稳定的性能改进效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICDM54844.2022.00070&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been widely used in recent recommender systems,where negative sampling plays an important role. Existing negative samplingmethods restrict the relationship between nodes as either hard positive pairsor hard negative pairs. This leads to the loss of structural information, andlacks the mechanism to generate positive pairs for nodes with few neighbors. Toovercome limitations, we propose a novel soft link-based sampling method,namely MixDec Sampling, which consists of Mixup Sampling module and DecaySampling module. The Mixup Sampling augments node features by synthesizing newnodes and soft links, which provides sufficient number of samples for nodeswith few neighbors. The Decay Sampling strengthens the digestion of graphstructure information by generating soft links for node embedding learning. Tothe best of our knowledge, we are the first to model sampling relationshipsbetween nodes by soft links in GNN-based recommender systems. Extensiveexperiments demonstrate that the proposed MixDec Sampling can significantly andconsistently improve the recommendation performance of several representativeGNN-based models on various recommendation benchmarks.</description>
      <author>example@mail.com (Xiangjin Xie, Yuxin Chen, Ruipeng Wang, Kai Ouyang, Zihan Zhang, Hai-Tao Zheng, Buyue Qian, Hansen Zheng, Bo Hu, Chengxiang Zhuo, Zang Li)</author>
      <guid isPermaLink="false">2502.08161v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>One-Shot Federated Learning with Classifier-Free Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.08488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;联邦学习（FL）通过实现去中心化的协作学习减少数据集中化，但引入了显著的通信成本，因为客户端和服务器之间需要进行多轮通信。一次性联邦学习（OSFL）通过仅使用一轮通信形成全局模型来解决这一问题，并通常依赖于服务器端的模型蒸馏或辅助数据集生成——经常利用预训练扩散模型（DM）。然而，现有的基于DM的OSFL方法通常采用分类器引导的DM，这需要在每个客户端上训练辅助分类模型，从而引入额外的计算开销。这项工作介绍了一种称为OSCAR的新的一次性联邦学习方法，该方法消除了对辅助模型的需求。&lt;h4&gt;背景&lt;/h4&gt;传统的联邦学习由于多轮通信导致了显著的通信成本，而一次性联邦学习通过仅使用一轮通信来缓解这一问题，但现有的基于扩散模型的方法仍需要在客户端训练分类器，引入额外开销。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外辅助模型的一次性联邦学习方法，以减少计算和通信成本。&lt;h4&gt;方法&lt;/h4&gt;OSCAR利用基础模型为客户端生成类别特定的数据表示，并将其无缝集成到服务器侧的无分类器扩散模型管道中进行数据生成。&lt;h4&gt;主要发现&lt;/h4&gt;OSCAR是一种简单且成本效益高的一次性联邦学习方法，在四个基准数据集上超越了现有最佳性能，同时减少了至少99%的通信负载。&lt;h4&gt;结论&lt;/h4&gt;通过消除对辅助模型的需求，OSCAR提供了一种更高效的一次性联邦学习解决方案，具有重要的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) enables collaborative learning without datacentralization but introduces significant communication costs due to multiplecommunication rounds between clients and the server. One-shot federatedlearning (OSFL) addresses this by forming a global model with a singlecommunication round, often relying on the server's model distillation orauxiliary dataset generation - often through pre-trained diffusion models(DMs). Existing DM-assisted OSFL methods, however, typically employclassifier-guided DMs, which require training auxiliary classifier models ateach client, introducing additional computation overhead. This work introducesOSCAR (One-Shot Federated Learning with Classifier-Free Diffusion Models), anovel OSFL approach that eliminates the need for auxiliary models. OSCAR usesfoundation models to devise category-specific data representations at eachclient, seamlessly integrated into a classifier-free diffusion model pipelinefor server-side data generation. OSCAR is a simple yet cost-effective OSFLapproach that outperforms the state-of-the-art on four benchmarking datasetswhile reducing the communication load by at least 99%.</description>
      <author>example@mail.com (Obaidullah Zaland, Shutong Jin, Florian T. Pokorny, Monowar Bhuyan)</author>
      <guid isPermaLink="false">2502.08488v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models in Computational Pathology: A Review of Challenges, Opportunities, and Impact</title>
      <link>http://arxiv.org/abs/2502.08333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  63 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;计算病理学近年来从自我监督的视觉模型发展到对比性视觉语言框架，迅速进步。&lt;h4&gt;背景&lt;/h4&gt;随着数据规模急剧增长以及模型参数量增加至数十亿级别，自动生成的人工智能‘副驾驶’展示了挖掘细微组织线索的能力，并能生成全面报告和回应复杂用户查询。&lt;h4&gt;目的&lt;/h4&gt;探讨这一波新的生成性和多用途AI如何改变临床诊断，并评估基础模型在病理学中的应用及意义。&lt;h4&gt;方法&lt;/h4&gt;回顾了计算病理学中基础模型的快速进展，定义并分析这些模型成为基础、通用或多功能的原因及其对领域的影响。&lt;h4&gt;主要发现&lt;/h4&gt;虽然这些模型展示了卓越的预测和生成能力，但建立全球基准是提高评估标准和促进临床广泛应用的关键。&lt;h4&gt;结论&lt;/h4&gt;前沿AI在计算病理学中的更广泛影响取决于其被接受度和社会认可度。公共曝光虽非必要，但在消除误解、构建信任和支持监管方面依然至关重要。&lt;h4&gt;翻译&lt;/h4&gt;从自我监督的视觉模型到对比性视觉语言框架，计算病理学近年来迅速发展。生成式人工智能‘副驾驶’现在能够挖掘细胞至组织层面微妙且难以察觉的线索，自动生成全面报告并回应复杂用户查询。数据量和可训练参数数量急剧增长的同时，提出了这样一个关键问题：这一波新的生成性和多用途AI将如何改变临床诊断？本文探讨了这些创新的真实潜力及其在临床实践中的应用，并回顾基础模型在病理学领域快速进展的背景，明确其应用及意义。此外，我们仔细研究了基础模型定义，分析使其成为基础、通用或多功能的因素，并评估它们对计算病理学的影响。同时讨论了开发和评价这些模型的独特挑战。尽管已展示出卓越预测和生成能力，但建立全球基准是提高评估标准以及推进临床广泛应用的关键所在。在计算病理学中，前沿AI的更广泛影响最终取决于其被接受度及社会认可度。虽然直接公共接触并非严格必要，但在消除误解、构建信任和支持监管方面依然是强有力的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From self-supervised, vision-only models to contrastive visual-languageframeworks, computational pathology has rapidly evolved in recent years.Generative AI "co-pilots" now demonstrate the ability to mine subtle,sub-visual tissue cues across the cellular-to-pathology spectrum, generatecomprehensive reports, and respond to complex user queries. The scale of datahas surged dramatically, growing from tens to millions of multi-gigapixeltissue images, while the number of trainable parameters in these models hasrisen to several billion. The critical question remains: how will this new waveof generative and multi-purpose AI transform clinical diagnostics? In thisarticle, we explore the true potential of these innovations and theirintegration into clinical practice. We review the rapid progress of foundationmodels in pathology, clarify their applications and significance. Moreprecisely, we examine the very definition of foundational models, identifyingwhat makes them foundational, general, or multipurpose, and assess their impacton computational pathology. Additionally, we address the unique challengesassociated with their development and evaluation. These models havedemonstrated exceptional predictive and generative capabilities, butestablishing global benchmarks is crucial to enhancing evaluation standards andfostering their widespread clinical adoption. In computational pathology, thebroader impact of frontier AI ultimately depends on widespread adoption andsocietal acceptance. While direct public exposure is not strictly necessary, itremains a powerful tool for dispelling misconceptions, building trust, andsecuring regulatory support.</description>
      <author>example@mail.com (Mohsin Bilal, Aadam, Manahil Raza, Youssef Altherwy, Anas Alsuhaibani, Abdulrahman Abduljabbar, Fahdah Almarshad, Paul Golding, Nasir Rajpoot)</author>
      <guid isPermaLink="false">2502.08333v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge Swapping via Learning and Unlearning</title>
      <link>http://arxiv.org/abs/2502.08075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为“知识交换”的新任务，该任务旨在通过选择性地调节预训练模型的知识来实现指定信息的遗忘、保留重要知识并获取新知识。&lt;h4&gt;背景&lt;/h4&gt;增量学习通常从低级表示向高级语义推进，而忘记则往往相反，即从高级语义开始并向低级特征方向进行。&lt;h4&gt;目的&lt;/h4&gt;通过基准测试“先学后忘”的策略来验证在各种任务上的有效性，如图像分类、目标检测和语义分割等。&lt;h4&gt;方法&lt;/h4&gt;基于敲入特征层次分析提出了一种新的知识交换任务，并引入了“学习之前遗忘”（Learning Before Forgetting）的策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了所提出的策略在多个任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;源代码可在https://github.com/xingmingyu123456/KnowledgeSwapping获得，该研究为预训练模型的知识调节提供了一种新的视角和方法。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了知识交换这一新任务，旨在通过选择性地调节预训练模型的知识来实现指定信息的遗忘、保留重要知识并获取新知识。通过对敲入特征层次进行分析，我们发现增量学习通常从低级表示向高级语义推进，而忘记则往往相反，即从高级语义开始并向低级特征方向进行。基于此，我们提出了一种基准测试“先学后忘”的策略来验证在各种任务上的有效性，如图像分类、目标检测和语义分割等。广泛的实验验证了所提出的策略的有效性。源代码可在https://github.com/xingmingyu123456/KnowledgeSwapping获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce \textbf{Knowledge Swapping}, a novel task designed toselectively regulate knowledge of a pretrained model by enabling the forgettingof user\-specified information, retaining essential knowledge, and acquiringnew knowledge simultaneously. By delving into the analysis of knock-on featurehierarchy, we find that incremental learning typically progresses fromlow\-level representations to higher\-level semantics, whereas forgetting tendsto occur in the opposite direction\-starting from high-level semantics andmoving down to low-level features. Building upon this, we propose to benchmarkthe knowledge swapping task with the strategy of \textit{Learning BeforeForgetting}. Comprehensive experiments on various tasks like imageclassification, object detection, and semantic segmentation validate theeffectiveness of the proposed strategy. The source code is available at\href{https://github.com/xingmingyu123456/KnowledgeSwapping}{https://github.com/xingmingyu123456/KnowledgeSwapping}.</description>
      <author>example@mail.com (Mingyu Xing, Lechao Cheng, Shenggeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang)</author>
      <guid isPermaLink="false">2502.08075v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>DOGR: Leveraging Document-Oriented Contrastive Learning in Generative Retrieval</title>
      <link>http://arxiv.org/abs/2502.07219v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'创新性方法': '生成式检索是一种信息检索领域的创新方法，利用生成语言模型（LM）为给定查询生成文档标识符（docid）的排名列表。', '简化流程': '它通过用模型参数替换大型外部索引来简化检索流程。', '现有工作局限': '现有的研究仅学习了查询和文档标识符之间的关系，无法直接表示查询和文档的相关性。', '提出的新框架': '为了克服这个问题，我们提出了一个新颖且通用的生成式检索框架——基于文档导向对比学习的生成式检索（DOGR），利用对比学习改进生成式检索任务。', '两阶段策略': '它采用了一种双阶段学习策略，通过直接交互全面捕捉查询和文档之间的关系。', '增强语义表示': '实现负样本采样方法及相应的对比学习目标以加强语义表示的学习过程，从而促进对查询与文档间关系的深入理解。', '实验结果': '实验结果显示，在两个公开基准数据集上，DOGR的性能优于现有的生成式检索方法。', '通用有效性': '进一步的实验证明我们的框架对于常见的标识符构建技术也具有普遍的有效性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval constitutes an innovative approach in informationretrieval, leveraging generative language models (LM) to generate a ranked listof document identifiers (docid) for a given query. It simplifies the retrievalpipeline by replacing the large external index with model parameters. However,existing works merely learned the relationship between queries and documentidentifiers, which is unable to directly represent the relevance betweenqueries and documents. To address the above problem, we propose a novel andgeneral generative retrieval framework, namely Leveraging Document-OrientedContrastive Learning in Generative Retrieval (DOGR), which leveragescontrastive learning to improve generative retrieval tasks. It adopts atwo-stage learning strategy that captures the relationship between queries anddocuments comprehensively through direct interactions. Furthermore, negativesampling methods and corresponding contrastive learning objectives areimplemented to enhance the learning of semantic representations, therebypromoting a thorough comprehension of the relationship between queries anddocuments. Experimental results demonstrate that DOGR achieves state-of-the-artperformance compared to existing generative retrieval methods on two publicbenchmark datasets. Further experiments have shown that our framework isgenerally effective for common identifier construction techniques.</description>
      <author>example@mail.com (Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo)</author>
      <guid isPermaLink="false">2502.07219v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Filtering Meets Spectrum Shift: Connecting User-Item Interaction with Graph-Structured Side Information</title>
      <link>http://arxiv.org/abs/2502.08071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文探讨了在图神经网络（GNN）应用于协同过滤时，当将结构化的侧面信息（如多模态相似性图或社交网络）整合到用户-物品二分图中时，现有方法未能达到令人满意的性能。作者从谱分析的角度定量地解释了这种现象，并提出了一种新的修正方案。&lt;h4&gt;背景&lt;/h4&gt;Graph Neural Network (GNN)在协同过滤领域展现了其优越性，而在此过程中使用的用户-物品交互的二部图作为基础的数据格式。然而当加入结构化的侧面信息时，现有方法无法取得理想效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的谱修正方案Spectrum Shift Correction（SSC），以解决上述问题，并提高模型在集成多种侧信源下的表现。&lt;h4&gt;方法&lt;/h4&gt;通过分析频谱的偏移现象，设计了一种新的方法来调整和缩放因子，使GNN能够适应由于引入侧面信息而导致的频谱变化。此方法不需要针对不同类型的结构化数据进行特别的设计。&lt;h4&gt;主要发现&lt;/h4&gt;随着更多侧信源被纳入U-I二部图中，扩展后的邻接矩阵最高频率会逐渐向右移动，导致原有方法分配的重要性与实际情况不匹配。通过引入SSC方案可以有效地解决这一问题。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，在社交推荐和多模态推荐任务上应用SSC可以获得显著的性能提升（高达23%），同时没有增加额外的计算负担。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络在协同过滤中展现了其优越性，其中用户-物品交互的二部图为基本数据格式。然而当引入结构化的侧面信息时，现有方法的表现不尽如人意。通过谱分析可以解释这一现象，并提出了一种新的频谱修正方案Spectrum Shift Correction（SSC），该方案不需要针对特定的数据类型进行特殊设计。实验结果表明在社交和多模态推荐任务中应用SSC可以获得显著的性能提升，且无需增加额外计算负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN) has demonstrated their superiority incollaborative filtering, where the user-item (U-I) interaction bipartite graphserves as the fundamental data format. However, when graph-structured sideinformation (e.g., multimodal similarity graphs or social networks) isintegrated into the U-I bipartite graph, existing graph collaborative filteringmethods fall short of achieving satisfactory performance. We quantitativelyanalyze this problem from a spectral perspective. Recall that a bipartite graphpossesses a full spectrum within the range of [-1, 1], with the highestfrequency exactly achievable at -1 and the lowest frequency at 1; however, weobserve as more side information is incorporated, the highest frequency of theaugmented adjacency matrix progressively shifts rightward. This spectrum shiftphenomenon has caused previous approaches built for the full spectrum [-1, 1]to assign mismatched importance to different frequencies. To this end, wepropose Spectrum Shift Correction (dubbed SSC), incorporating shifting andscaling factors to enable spectral GNNs to adapt to the shifted spectrum.Unlike previous paradigms of leveraging side information, which necessitatetailored designs for diverse data types, SSC directly connects traditionalgraph collaborative filtering with any graph-structured side information.Experiments on social and multimodal recommendation demonstrate theeffectiveness of SSC, achieving relative improvements of up to 23% withoutincurring any additional computational overhead.</description>
      <author>example@mail.com (Yunhang He, Cong Xu, Jun Wang, Wei Zhang)</author>
      <guid isPermaLink="false">2502.08071v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning Effective Dynamics across Spatio-Temporal Scales of Complex Flows</title>
      <link>http://arxiv.org/abs/2502.07990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Parsimony and Learning (CPAL)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Graph-based Learning of Effective Dynamics (Graph-LED)框架，该框架结合图神经网络和基于注意力的自回归模型来从少量仿真数据中提取有效动力学。&lt;h4&gt;背景&lt;/h4&gt;复杂流体流动建模与仿真在科学及工程领域面临挑战。完全尺度解析模拟对于如高度湍流系统而言在未来可预见的时间内不可行，因此需要降阶模型捕捉涉及多时空尺度交互的动力学现象。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于图的深度学习框架来解决复杂流体流动建模与仿真的问题。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了图神经网络（GNN）进行可变大小非结构化网格上的降维以及一个自回归时间注意力模型，以自动学习时间依赖性。GNN能够有效处理复杂的几何形状和非均匀网格。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列流体动力学问题的测试，包括圆柱绕流和后向台阶上流动，在不同雷诺数下显示了对时空物理的有效预测能力。特别是在圆柱绕流的情况下，既准确捕捉到了靠近圆柱的小尺度效应，也准确地捕获了其尾迹。&lt;h4&gt;结论&lt;/h4&gt;Graph-LED框架展示了强大的仿真复杂流体动力学的能力，并且在处理具有挑战性的多尺度问题时显示出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;对复杂流体流动进行建模和仿真是许多科学与工程领域中的基本挑战。对于高度湍流系统等系统的全分辨率模拟，在可预见的未来是不可行的，必须降低阶数模型来捕捉跨多个空间-时间尺度交互的动力学现象。在此工作中，我们提出了一种新的框架——基于图的学习有效动力学（Graph-LED），利用图神经网络（GNN）以及基于注意力的自回归模型，从少量仿真数据中提取有效动力学。GNN在非结构化网格上表示流场作为图形，并且能够有效地处理复杂的几何形状和非均匀格网。所提出的方法结合了可变大小的非结构化网格上的降维（使用GNN）与一个可以自动学习时间依赖性的自回归时序注意力模型。我们在一系列流体动力学问题上评估了该方法，包括在不同雷诺数下的绕圆柱流动和后向台阶流动。结果展示了对时空物理的稳健且有效的预测能力；特别是，在绕圆柱流动的情况下，既准确地捕捉到了靠近圆柱的小尺度效应，也准确地捕获了其尾迹。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling and simulation of complex fluid flows with dynamics that spanmultiple spatio-temporal scales is a fundamental challenge in many scientificand engineering domains. Full-scale resolving simulations for systems such ashighly turbulent flows are not feasible in the foreseeable future, andreduced-order models must capture dynamics that involve interactions acrossscales. In the present work, we propose a novel framework, Graph-based Learningof Effective Dynamics (Graph-LED), that leverages graph neural networks (GNNs),as well as an attention-based autoregressive model, to extract the effectivedynamics from a small amount of simulation data. GNNs represent flow fields onunstructured meshes as graphs and effectively handle complex geometries andnon-uniform grids. The proposed method combines a GNN based, dimensionalityreduction for variable-size unstructured meshes with an autoregressive temporalattention model that can learn temporal dependencies automatically. Weevaluated the proposed approach on a suite of fluid dynamics problems,including flow past a cylinder and flow over a backward-facing step over arange of Reynolds numbers. The results demonstrate robust and effectiveforecasting of spatio-temporal physics; in the case of the flow past acylinder, both small-scale effects that occur close to the cylinder as well asits wake are accurately captured.</description>
      <author>example@mail.com (Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos)</author>
      <guid isPermaLink="false">2502.07990v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing</title>
      <link>http://arxiv.org/abs/2502.07608v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Time2Lang是一个将时间序列基础模型（TFM）的输出直接映射到大型语言模型（LLM）表示的方法，无需中间文本转换。该方法首先使用周期性预测作为预设任务在合成数据上进行训练，并通过心理健康分类任务进行评估。&lt;h4&gt;背景&lt;/h4&gt;当大型语言模型与行为感知数据结合时，在健康应用方面显示出巨大潜力。传统的做法是将传感器数据转换为提示文本，但这种方法容易出错、计算成本高且需要领域专业知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有挑战，并实现TFM和LLM的有效集成。&lt;h4&gt;方法&lt;/h4&gt;Time2Lang框架在合成数据上使用周期性预测作为预设任务进行训练。然后，在两个纵向可穿戴设备和移动感知的数据集上进行了评估：每日抑郁预测（基于步数，17,251天来自256名参与者）；积极生活状态分类（基于对话持续时间，46名参与者10周数据）。&lt;h4&gt;主要发现&lt;/h4&gt;Time2Lang保持了近似恒定的推理时间，不受输入长度影响。生成的嵌入保留了时间序列的基本特征，如自相关性。&lt;h4&gt;结论&lt;/h4&gt;研究表明，可以有效整合TFM和LLM，在减少信息损失的同时，实现性能跨不同模型范式的转移。这是首次将TFM与LLM结合用于健康应用的研究，为未来的复杂医疗任务研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在与行为感知数据结合时对健康应用有巨大潜力。传统方法将传感器数据转换成提示文本，但这种方法容易出错、计算成本高且需要领域专业知识。这里提出Time2Lang框架直接映射TFM输出到LLM表示而无需中间文本转换。该研究使用周期性预测作为预设任务在合成数据上训练模型，并评估其在心理健康分类任务上的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) show promise for health applications whencombined with behavioral sensing data. Traditional approaches convert sensordata into text prompts, but this process is prone to errors, computationallyexpensive, and requires domain expertise. These challenges are particularlyacute when processing extended time series data. While time series foundationmodels (TFMs) have recently emerged as powerful tools for learningrepresentations from temporal data, bridging TFMs and LLMs remains challenging.Here, we present Time2Lang, a framework that directly maps TFM outputs to LLMrepresentations without intermediate text conversion. Our approach first trainson synthetic data using periodicity prediction as a pretext task, followed byevaluation on mental health classification tasks. We validate Time2Lang on twolongitudinal wearable and mobile sensing datasets: daily depression predictionusing step count data (17,251 days from 256 participants) and flourishingclassification based on conversation duration (46 participants over 10 weeks).Time2Lang maintains near constant inference times regardless of input length,unlike traditional prompting methods. The generated embeddings preserveessential time-series characteristics such as auto-correlation. Our resultsdemonstrate that TFMs and LLMs can be effectively integrated while minimizinginformation loss and enabling performance transfer across these distinctmodeling paradigms. To our knowledge, we are the first to integrate a TFM andan LLM for health, thus establishing a foundation for future research combininggeneral-purpose large models for complex healthcare tasks.</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell)</author>
      <guid isPermaLink="false">2502.07608v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Automated Capability Discovery via Model Self-Exploration</title>
      <link>http://arxiv.org/abs/2502.07577v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了自动化能力发现（ACD）框架，该框架利用一个基础模型作为科学家来系统地提出开放性任务以探索另一个主题模型的能力和潜在问题。通过结合前沿模型与开放性的概念，ACD能够自动且全面地揭示出模型的惊人能力和缺陷。&lt;h4&gt;背景&lt;/h4&gt;当前的基础模型已经展示出了跨多个领域的广泛能力，并且存在对这些新模型进行精确定量分析的巨大挑战。现有的评估方法通常需要大量的劳动力和难以设计合适的测试案例来应对更为强大的模型。&lt;h4&gt;目的&lt;/h4&gt;旨在通过自动化的方法，有效发现基础模型的全面能力和潜在风险，降低人工参与的需求。&lt;h4&gt;方法&lt;/h4&gt;提出并实现了ACD框架，该框架利用一个或多个前沿的基础模型作为“科学家”，为被评估的主题模型设计开放性任务，并对其进行自我评价以揭示其能力范围和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;展示ACD在GPT、Claude及Llama系列等不同基础模型上的应用，能够自动识别出成千上万种人工团队难以全面发掘的能力和问题。通过大规模的人工调查验证了机器自评与人类评价之间的一致性。&lt;h4&gt;结论&lt;/h4&gt;利用基础模型自身的任务创建能力和自我评估能力，ACD为新型AI系统的可扩展自动化评估提供了一条重要的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要中介绍的论文内容包括开发了一个名为自动能力发现（Automated Capability Discovery, ACD）的新框架。该框架通过指定一个基础模型作为“科学家”，系统性地提议开放性的任务，以探测另一个主体模型的能力与潜在风险。ACD结合了前沿的基础模型和关于开放式探索的想法，能够自动且全面揭示主题模型的惊人能力和失败点。研究成果涵盖多个系列的基础模型（包括GPT、Claude以及Llama等），展示出成千上万种人工团队难以发现的能力，并通过大规模的人类调查验证了机器自评与人类评估的一致性。该框架为新型AI系统的可扩展和自动化评价提供了重要的途径。所有代码及评估日志均开源在GitHub上：https://github.com/conglu1997/ACD&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have become general-purpose assistants, exhibiting diversecapabilities across numerous domains through training on web-scale data. Itremains challenging to precisely characterize even a fraction of the fullspectrum of capabilities and potential risks in any new model. Existingevaluation approaches often require significant human effort, and it is takingincreasing effort to design ever harder challenges for more capable models. Weintroduce Automated Capability Discovery (ACD), a framework that designates onefoundation model as a scientist to systematically propose open-ended tasksprobing the abilities of a subject model (potentially itself). By combiningfrontier models with ideas from the field of open-endedness, ACD automaticallyand systematically uncovers both surprising capabilities and failures in thesubject model. We demonstrate ACD across a range of foundation models(including the GPT, Claude, and Llama series), showing that it automaticallyreveals thousands of capabilities that would be challenging for any single teamto uncover. We further validate our method's automated scoring with extensivehuman surveys, observing high agreement between model-generated and humanevaluations. By leveraging foundation models' ability to both create tasks andself-evaluate, ACD is a significant step toward scalable, automated evaluationof novel AI systems. All code and evaluation logs are open-sourced athttps://github.com/conglu1997/ACD.</description>
      <author>example@mail.com (Cong Lu, Shengran Hu, Jeff Clune)</author>
      <guid isPermaLink="false">2502.07577v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</title>
      <link>http://arxiv.org/abs/2502.00568v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为PathGen的新模型，该模型基于扩散生成AI技术，能够从数字病理图像合成基因表达信息，并利用这些信息准确预测癌症分级和患者生存风险。&lt;h4&gt;背景&lt;/h4&gt;现有的研究显示，通过结合数字病理学和转录组特征的人工智能多模态融合方法可以改善癌症诊断（分级/亚型）和预后（存活率）的预测。然而，在实际临床环境中直接使用这种融合技术进行联合决策是不现实的。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于扩散生成AI的新模型PathGen，该模型能够从数字病理图像合成基因表达信息，并利用这些合成的信息来准确预测癌症分级和患者生存风险。&lt;h4&gt;方法&lt;/h4&gt;采用了一种新的扩散基跨模态生成AI模型PathGen。通过此模型可以将来自数字病理学的模式转换为对应的转录组特征，进而进行癌症诊断和预后分析。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够利用合成的基因表达信息准确预测癌症分级和患者生存风险，并且其性能达到了当前领域的最高标准；同时，它还提供了确定性（通过符合保证覆盖）和可解释性（通过分布注意力图）。&lt;h4&gt;结论&lt;/h4&gt;PathGen提供了一种实用的方法来从数字病理学图像合成转录组信息，这对于提高癌症诊断的准确性和预后的预测具有重要的意义。&lt;h4&gt;翻译&lt;/h4&gt;新兴的研究表明，基于人工智能的多模态融合方法能够改善利用数字病理学和转录组特征进行癌症诊断（分级/亚型）及预后（存活率）预测。然而，在实际临床环境中直接使用这种联合决策的方法是不现实的，因为组织病理学仍然是诊断的金标准，并且转录组测试在公共医疗系统中很少被要求。借助我们新的基于扩散的跨模态生成AI模型PathGen，我们证明了从数字组织病理学合成的基因表达信息能够准确预测癌症分级和患者生存风险（性能达到当前领域的最高标准），并提供了确定性和可解释性。PathGen代码在GitHub上开放使用，网址为https://github.com/Samiran-Dey/PathGen。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Samiran-Dey/PathoGen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging research has highlighted that artificial intelligence basedmultimodal fusion of digital pathology and transcriptomic features can improvecancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.However, such direct fusion for joint decision is impractical in real clinicalsettings, where histopathology is still the gold standard for diagnosis andtranscriptomic tests are rarely requested, at least in the public healthcaresystem. With our novel diffusion based crossmodal generative AI model PathGen,we show that genomic expressions synthesized from digital histopathologyjointly predicts cancer grading and patient survival risk with high accuracy(state-of-the-art performance), certainty (through conformal coverageguarantee) and interpretability (through distributed attention maps). PathGencode is available for open use by the research community through GitHub athttps://github.com/Samiran-Dey/PathGen.</description>
      <author>example@mail.com (Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2502.00568v3</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Technical note on calibrating vision-language models under covariate shift</title>
      <link>http://arxiv.org/abs/2502.07847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种用于缓解低样本视觉分类任务中的协变量偏移和置信度错配问题的统一框架$C3SC$。&lt;h4&gt;背景&lt;/h4&gt;虽然视觉-语言基础模型在低样本视觉分类中取得了成功，但由于样本不足，它们对数据分布的变化敏感。常用的方法是通过多个数据集进行微调，但这在实践中成本高昂。&lt;h4&gt;目的&lt;/h4&gt;研究如何同时解决预训练数据和目标数据之间的协变量偏移以及由于数据稀缺导致的置信度错配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了$C3SC$框架，该框架利用Fisher信息罚分来纠正协变量偏移，并使用置信度误分类惩罚(CMP)来降低对错误分类样本的信心。&lt;h4&gt;主要发现&lt;/h4&gt;$C3SC$在各种视觉和协变量偏移数据集上的实验结果表明，它显著改善了校准（ECE）最多提高了5.82%，并且由于在具有挑战性的协变量偏移数据集上准确率提高3.5%而表现出更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;$C3SC$是解决分布变化下视觉-语言低样本应用场景可靠性问题的有希望的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：尽管作为新兴能力的成功案例，用于低样本视觉分类的视觉-语言基础模型由于样本不足而对数据的变化敏感。常用的方法是在多个数据集上进行微调以解决领域泛化的问题，但这在实践中成本高昂。这项工作同时研究了预训练数据和未具体说明的目标数据之间的协变量偏移以及置信度错配问题（即有限的数据可用性导致模型预测信心的放大）。我们提出了$C3SC$框架，用于缓解协变量偏移和置信度错配。$C3SC$利用Fisher信息罚分来纠正协变量偏移，并使用置信度误分类惩罚(CMP)来降低对错误分类样本的信心。在各种视觉和协变量偏移数据集上的实验结果表明，$C3SC$显著改善了校准（ECE）最多提高了5.82%，并且由于在具有挑战性的协变量偏移数据集上准确率提高3.5%而表现出更好的鲁棒性。这使得$C3SC$成为解决分布变化下视觉-语言低样本应用场景可靠性问题的有希望的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite being a successful example of emerging capability, vision-languagefoundation models for low-shot vision classification have a limited ability tosufficiently generalize to the target data distribution due to sample poverty,leading to sensitivity to variations in the data. A popular mitigation strategyis finetuning over multiple datasets, but domain generalization is expensivewhen practiced in this manner. This work examines both covariate shift betweenpre-training data and the underspecified target data, and \textit{confidencemisalignment}, where the model's prediction confidence amplified by the limiteddata availability. We propose \textit{Confidence-Calibrated Covariate ShiftCorrection ($C3SC$)}, a unified framework to mitigate both covariate shift andconfidence misalignment. $C3SC$ leverages Fisher information penalty forcovariate shift correction and confidence misalignment penalty (CMP) to lowerconfidence on misclassified examples. Experimental results across variousvision and covariate shift datasets demonstrates that $C3SC$ significantlyimproves in calibration (ECE) by $5.82\%$ at maximum. $C3SC$ shows betterrobustness as well by showing $3.5\%$ improvement in accuracy metric onchallenging covariate shift datasets, making $C3SC$ a promising solution forreliable real-world vision-language low-shot applications under distributionshift.</description>
      <author>example@mail.com (Behraj Khan, Rizwan Qureshi, Tahir Syed)</author>
      <guid isPermaLink="false">2502.07847v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Unpaired Image Dehazing via Kolmogorov-Arnold Transformation of Latent Features</title>
      <link>http://arxiv.org/abs/2502.07812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于Kolmogorov-Arnold变换的无监督图像去雾框架UID-KAT，该框架利用了对抗训练和对比学习来提高性能。&lt;h4&gt;背景&lt;/h4&gt;图像去雾被看作是一个具有挑战性的视觉任务，并且需要复杂的变换和解释。最近引入的Kolmogorov-Arnold网络（KANs）由于其高效的多项式基础，为复杂函数提供了一种比多层感知机更有效的逼近方法。&lt;h4&gt;目的&lt;/h4&gt;探索结合使用对抗训练、对比学习以及KAN来建立图像去雾模型，以利用无监督设置中的大量真实世界数据进行去雾任务。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的UID-KAT框架：在该框架中，Kolmogorov-Arnold网络（KANs）被用作基础神经网络，并通过对抗训练和对比学习来增强其模型的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的UID-KAT框架在多个数据集和场景上达到了最先进的去雾性能，在减少模型复杂性的同时超越了现有的无配对方法。&lt;h4&gt;结论&lt;/h4&gt;该工作展示了KAN结合对抗训练和对比学习的有效性，并且提供了一种新颖的图像去雾方法。代码可在GitHub上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an innovative framework for Unsupervised Image Dehazingvia Kolmogorov-Arnold Transformation, termed UID-KAT. Image dehazing isrecognized as a challenging and ill-posed vision task that requires complextransformations and interpretations in the feature space. Recent advancementshave introduced Kolmogorov-Arnold Networks (KANs), inspired by theKolmogorov-Arnold representation theorem, as promising alternatives toMulti-Layer Perceptrons (MLPs) since KANs can leverage their polynomialfoundation to more efficiently approximate complex functions while requiringfewer layers than MLPs. Motivated by this potential, this paper explores theuse of KANs combined with adversarial training and contrastive learning tomodel the intricate relationship between hazy and clear images. Adversarialtraining is employed due to its capacity in producing high-fidelity images, andcontrastive learning promotes the model's emphasis on significant featureswhile suppressing the influence of irrelevant information. The proposed UID-KATframework is trained in an unsupervised setting to take advantage of theabundance of real-world data and address the challenge of preparing pairedhazy/clean images. Experimental results show that UID-KAT achievesstate-of-the-art dehazing performance across multiple datasets and scenarios,outperforming existing unpaired methods while reducing model complexity. Thesource code for this work is publicly available athttps://github.com/tranleanh/uid-kat.</description>
      <author>example@mail.com (Le-Anh Tran)</author>
      <guid isPermaLink="false">2502.07812v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>CrossVideoMAE: Self-Supervised Image-Video Representation Learning with Masked Autoencoders</title>
      <link>http://arxiv.org/abs/2502.07811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的视频自监督学习模型CrossVideoMAE，旨在同时从视频级别和帧级别有效学习空间时间表示和语义属性。&lt;h4&gt;背景&lt;/h4&gt;当前的基于视频的Masked Autoencoders (MAEs) 主要关注于从视觉角度学习有效的时空表示，可能会优先考虑一般的时空模式而忽视特定交互或序列等细微的语义属性。此外，现有的视频MAE与静态图像MAE使用独立的数据集，这可能缺乏理解所学概念所需的丰富语义属性。&lt;h4&gt;目的&lt;/h4&gt;为了更好地利用视频和对应采样帧图片中的信息，本文提出了CrossVideoMAE模型，该模型旨在整合视频中相互的空间时间信息以及从采样帧中获得的空间信息，并鼓励在视频域内的增强不变性。&lt;h4&gt;方法&lt;/h4&gt;CrossVideoMAE通过联合嵌入可见令牌的特征并结合跨模态和同模态内部的特征对应关系，在自监督学习方式下，可以从视频和帧图像模式中获取丰富的无标签引导信号。此模型是在一种特性不变的空间内进行工作的。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在多个基准数据集上超越了当前最先进的技术，并且消融研究表明该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;CrossVideoMAE通过集成视频和帧图像中的信息，在自监督学习框架下实现了有效的空间时间表示和语义属性的学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current video-based Masked Autoencoders (MAEs) primarily focus on learningeffective spatiotemporal representations from a visual perspective, which maylead the model to prioritize general spatial-temporal patterns but oftenoverlook nuanced semantic attributes like specific interactions or sequencesthat define actions - such as action-specific features that align more closelywith human cognition for space-time correspondence. This can limit the model'sability to capture the essence of certain actions that are contextually richand continuous. Humans are capable of mapping visual concepts, object viewinvariance, and semantic attributes available in static instances to comprehendnatural dynamic scenes or videos. Existing MAEs for videos and static imagesrely on separate datasets for videos and images, which may lack the richsemantic attributes necessary for fully understanding the learned concepts,especially when compared to using video and corresponding sampled frame imagestogether. To this end, we propose CrossVideoMAE an end-to-end self-supervisedcross-modal contrastive learning MAE that effectively learns both video-leveland frame-level rich spatiotemporal representations and semantic attributes.Our method integrates mutual spatiotemporal information from videos withspatial information from sampled frames within a feature-invariant space, whileencouraging invariance to augmentations within the video domain. This objectiveis achieved through jointly embedding features of visible tokens and combiningfeature correspondence within and across modalities, which is critical foracquiring rich, label-free guiding signals from both video and frame imagemodalities in a self-supervised manner. Extensive experiments demonstrate thatour approach surpasses previous state-of-the-art methods and ablation studiesvalidate the effectiveness of our approach.</description>
      <author>example@mail.com (Shihab Aaqil Ahamed, Malitha Gunawardhana, Liel David, Michael Sidorov, Daniel Harari, Muhammad Haris Khan)</author>
      <guid isPermaLink="false">2502.07811v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Re$^3$Sim: Generating High-Fidelity Simulation Data via 3D-Photorealistic Real-to-Sim for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.08645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RE$^3$SIM是一个从真实世界到仿真环境的系统，旨在通过先进的三维重建和神经渲染技术解决现实与模拟之间的几何差异和视觉差距问题。&lt;h4&gt;背景&lt;/h4&gt;真实的机器人数据收集非常昂贵且资源密集型，需要熟练的操作员和昂贵的硬件。虽然仿真提供了一种可扩展的替代方案，但通常因为几何和视觉上的差异难以实现从模拟到真实的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出一个3D-逼真的现实到仿真系统RE$^3$SIM来解决几何和视觉差距问题，并在各种操作任务场景中验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;RE$^3$SIM利用先进的三维重建技术将真实世界环境精准还原，并通过神经渲染实现在基于物理的模拟器中的实时交叉视角摄像机渲染。系统还利用专家示范数据高效地进行模仿学习训练。&lt;h4&gt;主要发现&lt;/h4&gt;仅使用仿真数据，该系统可以实现超过58%平均成功率的零样本从模拟到现实的迁移。此外，生成了一个大规模的仿真数据集来展示如何通过仿真数据建立稳健的策略并在不同对象上泛化。&lt;h4&gt;结论&lt;/h4&gt;RE$^3$SIM提供了一种有效的途径解决机器人领域中的模拟到真实问题，并展示了在多种操作任务场景下的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;现实世界中，机器人数据收集成本高昂且资源密集型。仿真作为一种替代方案虽然具备可扩展性，但常常因为几何和视觉差距而无法达到从模拟到真实的泛化效果。为了解决这些问题，我们提出了一个名为RE$^3$SIM的3D-逼真从真实环境转到仿真的系统，专门解决几何和视觉上的差异问题。该系统采用先进的三维重建技术和神经渲染技术来重现现实场景，并在基于物理的模拟器中实现交叉视角摄像机的实时渲染。通过利用专家示范数据有效地收集仿真中的演示并使用模仿学习训练机器人策略，我们在各种操作任务场景验证了从真实到仿真的管线的有效性。值得注意的是，在没有实际数据的情况下，我们仅用仿真数据就能达到超过58%平均成功率的零样本迁移效果。为了进一步推动现实到模拟技术的应用边界，我们还生成了一个大规模的仿真数据集来展示如何通过仿真数据建立稳健策略并在不同物体上进行泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world data collection for robotics is costly and resource-intensive,requiring skilled operators and expensive hardware. Simulations offer ascalable alternative but often fail to achieve sim-to-real generalization dueto geometric and visual gaps. To address these challenges, we propose a3D-photorealistic real-to-sim system, namely, RE$^3$SIM, addressing geometricand visual sim-to-real gaps. RE$^3$SIM employs advanced 3D reconstruction andneural rendering techniques to faithfully recreate real-world scenarios,enabling real-time rendering of simulated cross-view cameras within aphysics-based simulator. By utilizing privileged information to collect expertdemonstrations efficiently in simulation, and train robot policies withimitation learning, we validate the effectiveness of the real-to-sim-to-realpipeline across various manipulation task scenarios. Notably, with onlysimulated data, we can achieve zero-shot sim-to-real transfer with an averagesuccess rate exceeding 58%. To push the limit of real-to-sim, we furthergenerate a large-scale simulation dataset, demonstrating how a robust policycan be built from simulation data that generalizes across various objects.Codes and demos are available at: http://xshenhan.github.io/Re3Sim/.</description>
      <author>example@mail.com (Xiaoshen Han, Minghuan Liu, Yilun Chen, Junqiu Yu, Xiaoyang Lyu, Yang Tian, Bolun Wang, Weinan Zhang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.08645v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems</title>
      <link>http://arxiv.org/abs/2502.06581v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文综述了云边端协同（CETC）系统在分布式视频分析中的应用，包括架构组件、边缘计算平台和资源管理机制，并探讨了面向边缘的方法与基于云端的方法，以及混合视频分析技术。&lt;h4&gt;背景&lt;/h4&gt;随着视频数据的爆炸性增长，云边端协作系统的分布式视频分析得到了快速发展，推动了视频处理效率、实时推断及隐私保护方面的突破。CETC系统能够分布视频处理任务，并在云、边缘和终端设备间进行自适应分析。&lt;h4&gt;目的&lt;/h4&gt;本文综述了CETC系统中的基本架构组件，包括分层式、分布式和混合框架，以及边缘计算平台和资源管理机制。文章还探讨了面向边缘的方法和基于云端的方法，以及混合视频分析技术的最新进展，并讨论了这些技术所带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;本文首先分析了基础架构组件，如分层、分布和混合框架，以及边缘计算平台和资源配置机制；接着介绍了以边缘为中心的方法（包括本地处理、边缘辅助卸载等）和基于云端的方法（利用强大的算力进行复杂的视频理解和模型训练）。此外还探讨了结合自适应任务卸载和资源感知调度技术的混合视频分析。&lt;h4&gt;主要发现&lt;/h4&gt;研究涵盖了面向边缘的方法，强调设备上的处理、边缘辅助卸载和智能。同时，也介绍了基于云的方法，通过强大的计算能力支持复杂视频理解与模型训练。此外，还探讨了结合自适应任务卸载及资源感知调度技术的混合视频分析。&lt;h4&gt;结论&lt;/h4&gt;未来的研究方向包括可解释系统、高效处理机制以及高级视频分析，为该领域提供了宝贵的见解。然而，大型语言模型和多模态集成的发展也揭示了平台扩展性、数据保护与系统可靠性方面的挑战。&lt;h4&gt;翻译&lt;/h4&gt;随着视频数据的爆炸性增长，云边端协同（CETC）系统在分布式视频分析中的作用越来越重要，这不仅推动了高效的视频处理和实时推断，而且还促进了隐私保护技术的发展。本文综述了该领域的架构组件、边缘计算平台及资源管理机制，并探讨了面向边缘的方法与基于云端的方法以及混合视频分析技术的最新进展及其带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of video data has driven the development of distributedvideo analytics in cloud-edge-terminal collaborative (CETC) systems, enablingefficient video processing, real-time inference, and privacy-preservinganalysis. Among multiple advantages, CETC systems can distribute videoprocessing tasks and enable adaptive analytics across cloud, edge, and terminaldevices, leading to breakthroughs in video surveillance, autonomous driving,and smart cities. In this survey, we first analyze fundamental architecturalcomponents, including hierarchical, distributed, and hybrid frameworks,alongside edge computing platforms and resource management mechanisms. Buildingupon these foundations, edge-centric approaches emphasize on-device processing,edge-assisted offloading, and edge intelligence, while cloud-centric methodsleverage powerful computational capabilities for complex video understandingand model training. Our investigation also covers hybrid video analyticsincorporating adaptive task offloading and resource-aware scheduling techniquesthat optimize performance across the entire system. Beyond conventionalapproaches, recent advances in large language models and multimodal integrationreveal both opportunities and challenges in platform scalability, dataprotection, and system reliability. Future directions also encompassexplainable systems, efficient processing mechanisms, and advanced videoanalytics, offering valuable insights for researchers and practitioners in thisdynamic field.</description>
      <author>example@mail.com (Linxiao Gong, Hao Yang, Gaoyun Fang, Bobo Ju, Juncen Guo, Xiaoguang Zhu, Yan Wang, Xiping Hu, Peng Sun, Azzedine Boukerche)</author>
      <guid isPermaLink="false">2502.06581v2</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards</title>
      <link>http://arxiv.org/abs/2502.08643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025, Project Page: https://iker-robot.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了IKER（迭代关键点奖励）这一视觉基础的Python奖励函数，用于动态任务定义，并展示了在仿真和真实环境中的应用。&lt;h4&gt;背景&lt;/h4&gt;机器人操纵任务规范在开放世界环境中具有挑战性，需要灵活适应的人类意图导向的目标，在迭代反馈中进化。&lt;h4&gt;目的&lt;/h4&gt;通过引入IKER框架解决多步骤操作任务的视觉奖励函数生成与优化问题。&lt;h4&gt;方法&lt;/h4&gt;使用VLM（视觉语言模型）根据RGB-D观察和自由形式的语言指令生成关键点，并据此构建和细化奖励函数。这些奖励在仿真环境中训练强化学习策略，然后部署到真实世界中，形成从现实到模拟再到现实的循环。&lt;h4&gt;主要发现&lt;/h4&gt;IKER展示出在多种场景中的显著能力，包括灵巧与非灵巧任务执行、自发错误恢复以及即时策略调整。&lt;h4&gt;结论&lt;/h4&gt;结果证明了通过迭代奖励优化使得机器人能够完成动态环境下的多步骤任务的有效性。&lt;h4&gt;翻译&lt;/h4&gt;任务规范对于开放世界的机器人操作来说具有挑战性，需要灵活适应的人类意图导向的目标，并且能够在迭代反馈中进化。我们引入IKER（迭代关键点奖励），这是一种以视觉为基础的Python奖励函数，用作动态任务规范。我们的框架利用VLM生成并优化这些用于多步骤操作任务的奖励函数。通过RGB-D观察和自由形式的语言指令，在场景中采样关键点，并以此构建条件化的奖励函数。IKER基于关键点的空间关系运作，利用关于期望行为的常识先验知识，并实现精确的SE(3)控制。我们重建现实世界的场景并在仿真环境中使用生成的奖励训练强化学习策略，然后将其部署到真实世界——形成从现实到模拟再到现实的循环。我们的方法在各种场景中展示了显著的能力，包括灵巧和非灵巧任务，展示出多步骤任务执行、自发错误恢复及即时策略调整。结果突显了IKER通过迭代奖励优化使机器人能够完成动态环境下的多步骤操作的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Task specification for robotic manipulation in open-world environments ischallenging, requiring flexible and adaptive objectives that align with humanintentions and can evolve through iterative feedback. We introduce IterativeKeypoint Reward (IKER), a visually grounded, Python-based reward function thatserves as a dynamic task specification. Our framework leverages VLMs togenerate and refine these reward functions for multi-step manipulation tasks.Given RGB-D observations and free-form language instructions, we samplekeypoints in the scene and generate a reward function conditioned on thesekeypoints. IKER operates on the spatial relationships between keypoints,leveraging commonsense priors about the desired behaviors, and enabling preciseSE(3) control. We reconstruct real-world scenes in simulation and use thegenerated rewards to train reinforcement learning (RL) policies, which are thendeployed into the real world-forming a real-to-sim-to-real loop. Our approachdemonstrates notable capabilities across diverse scenarios, including bothprehensile and non-prehensile tasks, showcasing multi-step task execution,spontaneous error recovery, and on-the-fly strategy adjustments. The resultshighlight IKER's effectiveness in enabling robots to perform multi-step tasksin dynamic environments through iterative reward shaping.</description>
      <author>example@mail.com (Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li)</author>
      <guid isPermaLink="false">2502.08643v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Robot Data Curation with Mutual Information Estimators</title>
      <link>http://arxiv.org/abs/2502.08623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Videos and code at https://jhejna.github.io/demonstration-info&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种评估机器人模仿学习数据质量的新技术，该技术基于k-近邻估计和简单的VAE嵌入来衡量状态多样性和动作预测性。&lt;h4&gt;背景&lt;/h4&gt;随着机器人领域对模仿学习的重视增加，用于训练机器人的示范数据集也在不断扩充。然而，尽管收集的数据量显著增大，对其质量评估的研究却相对较少。&lt;h4&gt;目的&lt;/h4&gt;研究旨在估计单个示例在整体数据集中所贡献的状态多样性和动作预测性的相对质量，并据此提升机器人模仿学习的表现。&lt;h4&gt;方法&lt;/h4&gt;通过计算整个数据集内状态和动作之间的互信息来衡量每条轨迹的平均贡献。使用基于k-近邻估计的新技术结合简单的VAE嵌入，解决了传统互信息估算器对大数据量的需求问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，本研究的方法能够根据人类专家评分准确地将示范数据集按质量分类，并且基于该方法过滤后的训练策略在RoboMimic、真实环境下的ALOHA和Franka设置中表现更好。&lt;h4&gt;结论&lt;/h4&gt;提出的新技术为评估机器人模仿学习的数据质量提供了有力的工具，有助于提高机器人的学习性能。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习策略的表现往往依赖于它们训练所用的数据集。因此，在工业界和学术实验室中，用于机器人数据收集的投资正在增加。然而，尽管收集到的示范数量显著增加，很少有工作试图评估这些数据的质量，尤其是在视觉和语言领域，越来越多证据表明其重要性。在这项工作中，我们朝着解决机器人领域的数据质量这一问题迈出了重要的一步。对于给定的一组演示集，我们的目标是估计单个演示在状态多样性和动作预测性方面相对质量。为此，我们估算了一条轨迹对整个数据集中状态与动作之间互信息的平均贡献，这可以精确捕捉状态分布的熵以及基于状态的动作条件熵。虽然常用的互信息估计器需要大量数据，这些数据通常超出机器人领域的规模，但我们提出了一种新颖的技术，该技术基于k-近邻的互信息估计和简单的VAE嵌入的状态与动作。从经验上讲，我们展示了我们的方法能够根据人类专家评分将示范数据集按质量划分，并且在一系列跨越模拟环境的真实世界环境中都有很好的表现。此外，使用通过我们方法过滤后的数据训练策略，在RoboMimic中导致了5-10%的性能提升，并在真实世界的ALOHA和Franka设置中的表现更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of imitation learning policies often hinges on the datasetswith which they are trained. Consequently, investment in data collection forrobotics has grown across both industrial and academic labs. However, despitethe marked increase in the quantity of demonstrations collected, little workhas sought to assess the quality of said data despite mounting evidence of itsimportance in other areas such as vision and language. In this work, we take acritical step towards addressing the data quality in robotics. Given a datasetof demonstrations, we aim to estimate the relative quality of individualdemonstrations in terms of both state diversity and action predictability. Todo so, we estimate the average contribution of a trajectory towards the mutualinformation between states and actions in the entire dataset, which preciselycaptures both the entropy of the state distribution and the state-conditionedentropy of actions. Though commonly used mutual information estimators requirevast amounts of data often beyond the scale available in robotics, we introducea novel technique based on k-nearest neighbor estimates of mutual informationon top of simple VAE embeddings of states and actions. Empirically, wedemonstrate that our approach is able to partition demonstration datasets byquality according to human expert scores across a diverse set of benchmarksspanning simulation and real world environments. Moreover, training policiesbased on data filtered by our method leads to a 5-10% improvement in RoboMimicand better performance on real ALOHA and Franka setups.</description>
      <author>example@mail.com (Joey Hejna, Suvir Mirchandani, Ashwin Balakrishna, Annie Xie, Ayzaan Wahid, Jonathan Tompson, Pannag Sanketi, Dhruv Shah, Coline Devin, Dorsa Sadigh)</author>
      <guid isPermaLink="false">2502.08623v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Direction Finding for Software Defined Radios with Switched Uniform Circular Arrays</title>
      <link>http://arxiv.org/abs/2502.08592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 8 figures, IEEE IMS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种成本效益高的连续波信号方向估计系统，适用于2.4GHz ISM频段。&lt;h4&gt;背景&lt;/h4&gt;精确的方向到达（DoA）估计对于机器人技术和通信应用至关重要，但一致多通道接收机的高成本和复杂性阻碍了其普及。&lt;h4&gt;目的&lt;/h4&gt;开发一种低成本且硬件复杂度低的连续波信号方向到达估计系统。&lt;h4&gt;方法&lt;/h4&gt;使用带有时间分割复用功能的两通道软件定义无线电（SDR）以及中央参考天线来模拟相干采样，从而减少相位抖动和采样误差。采用增强型MUSIC算法结合空间平滑处理以解决轻度多路径干扰问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验在消声室中验证了理想条件下的准确性，在现实环境中的测试确认系统具备优秀的抗多径干扰性能。&lt;h4&gt;结论&lt;/h4&gt;该系统提供了实时和可靠的DoA估计解决方案，每秒5次更新，并通过后期处理进一步增强追踪能力。&lt;h4&gt;翻译&lt;/h4&gt;准确的方向到达（DoA）估计对于机器人技术及通信应用至关重要，然而一致性的多通道接收机因成本高昂与复杂性而难以普及。本研究提出了一种在2.4GHz ISM频段对连续波信号进行方向估计的经济型系统。此方案采用带有时间分割复用功能的两通道软件定义无线电（SDR）结合八单元圆形阵列实现伪相干采样，同时利用中央参考天线来减少相位抖动与采样误差问题。该系统引入了增强MUSIC算法并结合空间平滑处理以应对室内及室外环境中的轻微多径干扰情况。在消声室内的实验验证了理想条件下的准确性，而真实世界测试则证明了其具备强大的抗多路径干扰能力。通过每秒5次DoA更新率和后期优化处理进一步增强了追踪性能，从而为实际应用提供了可行且可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate Direction of Arrival (DoA) estimation is critical for applicationsin robotics and communication, but high costs and complexity of coherentmulti-channel receivers hinder accessibility. This work proposes acost-effective DoA estimation system for continuous wave (CW) signals in the2.4 GHz ISM band. A two-channel software-defined radio (SDR) with time-divisionmultiplexing (TDM) enables pseudo-coherent sampling of an eight-element uniformcircular array (UCA) with low hardware complexity. A central reference antennamitigates phase jitter and sampling errors. The system applies an enhancedMUSIC algorithm with spatial smoothing to handle light multipath interferencein indoor and outdoor environments. Experiments in an anechoic chamber validateaccuracy under ideal conditions, while real-world tests confirm robustperformance in multipath-prone scenarios. With 5 Hz DoA updates andpost-processing to enhance tracking, the system provides an accessible andreliable solution for DoA estimation in real-world environments.</description>
      <author>example@mail.com (Lennart Werner, Markus Gardill, Marco Hutter)</author>
      <guid isPermaLink="false">2502.08592v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Group and Grasp Multiple Objects</title>
      <link>http://arxiv.org/abs/2502.08452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于模仿学习的方法，用于解决机器人同时抓取和运输多个物体时的问题，通过收集专家操作的数据来训练扩散策略网络，使机器人能够自动生成推动、分组和抓取的行动序列。&lt;h4&gt;背景&lt;/h4&gt;同时抓取并运输多个物体可以显著提高机器人的工作效率，并且已经成为了几十年来的关键研究焦点。主要挑战在于如何在考虑物体分布和机器人硬件限制的情况下执行推动、分组及同步抓取操作。&lt;h4&gt;目的&lt;/h4&gt;解决现有基于规则的方法难以灵活适应不同场景的问题，提出一种新的模仿学习方法来优化多对象的抓取与运输策略。&lt;h4&gt;方法&lt;/h4&gt;通过远程控制收集一系列专家演示数据，并训练一个扩散策略网络。该网络能够使机器人动态生成推动、分组和抓取的动作序列，以促进高效的多物体抓取和搬运。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的方法可以在不同规模的训练集大小、变化的对象数量以及真实世界对象场景下有效地自适应地生成多物体分组与抓取策略。随着更多训练数据的支持，模仿学习有望成为解决多对象抓取问题的有效方法。&lt;h4&gt;结论&lt;/h4&gt;基于模仿学习的机器人操作策略展示出了处理复杂多物体系统的强大能力，并预示着在实际应用中的潜力和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneously grasping and transporting multiple objects can significantlyenhance robotic work efficiency and has been a key research focus for decades.The primary challenge lies in determining how to push objects, group them, andexecute simultaneous grasping for respective groups while considering objectdistribution and the hardware constraints of the robot. Traditional rule-basedmethods struggle to flexibly adapt to diverse scenarios. To address thischallenge, this paper proposes an imitation learning-based approach. We collecta series of expert demonstrations through teleoperation and train a diffusionpolicy network, enabling the robot to dynamically generate action sequences forpushing, grouping, and grasping, thereby facilitating efficient multi-objectgrasping and transportation. We conducted experiments to evaluate the methodunder different training dataset sizes, varying object quantities, andreal-world object scenarios. The results demonstrate that the proposed approachcan effectively and adaptively generate multi-object grouping and graspingstrategies. With the support of more training data, imitation learning isexpected to be an effective approach for solving the multi-object graspingproblem.</description>
      <author>example@mail.com (Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada)</author>
      <guid isPermaLink="false">2502.08452v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Robot-Initiated Social Control of Sedentary Behavior: Comparing the Impact of Relationship- and Target-Focused Strategies</title>
      <link>http://arxiv.org/abs/2502.08428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to HRI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了社交机器人使用人际关系导向策略和目标导向策略来鼓励人们减少久坐行为的有效性。&lt;h4&gt;背景&lt;/h4&gt;为了设计有效的社会机器人以促进健康行为的改变，了解人们如何对这些机器人的不同健康沟通策略做出反应至关重要。&lt;h4&gt;目的&lt;/h4&gt;探究来自社会机器人的两种类型的社会控制策略（关系聚焦策略和目标聚焦策略）在鼓励人们减少久坐行为方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;进行了一项两阶段实验室实验(n = 135)，参与者先与机器人玩一个游戏，然后由机器人使用其中一种策略说服他们站起来活动。一半的参与者参加了第二阶段以重复与机器人的互动。&lt;h4&gt;主要发现&lt;/h4&gt;关系聚焦策略激励参与者保持活跃的时间更长；重复会话并没有增强参与者对机器人的依恋感，但那些感到更加依附于机器人的参与者对目标聚焦策略有更为积极的回应。&lt;h4&gt;结论&lt;/h4&gt;研究结果为设计用于健康沟通环境中的社交机器人说服策略提供了宝贵的见解。&lt;h4&gt;翻译&lt;/h4&gt;为了设计能够有效促进健康行为改变的社会机器人，了解人们如何响应这些机器人所采用的各种健康传播策略至关重要。这项研究探讨了两种类型的社会控制策略——关系导向策略（强调人际关系后果）和目标导向策略（强调健康后果），在鼓励减少久坐行为方面的有效性。一项两阶段实验室实验(n = 135)被开展，其中参与者首先与一个机器人玩游戏，然后让该机器人使用一种策略说服他们站起来活动。一半的参与者参加了第二阶段以重复互动。结果显示，关系导向策略激励了参与者更长时间地保持活跃状态；然而，多次会话并没有加深参与者的对机器人的依恋感，但那些更加依附于机器人的个体对于目标导向策略产生了更为积极的回应。这些发现为设计用于健康传播环境中的社会机器人说服策略提供了宝贵的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To design social robots to effectively promote health behavior change, it isessential to understand how people respond to various health communicationstrategies employed by these robots. This study examines the effectiveness oftwo types of social control strategies from a social robot,relationship-focused strategies (emphasizing relational consequences) andtarget-focused strategies (emphasizing health consequences), in encouragingpeople to reduce sedentary behavior. A two-session lab experiment was conducted(n = 135), where participants first played a game with a robot, followed by therobot persuading them to stand up and move using one of the strategies. Half ofthe participants joined a second session to have a repeated interaction withthe robot. Results showed that relationship-focused strategies motivatedparticipants to stay active longer. Repeated sessions did not strengthenparticipants' relationship with the robot, but those who felt more attached tothe robot responded more actively to the target-focused strategies. Thesefindings offer valuable insights for designing persuasive strategies for socialrobots in health communication contexts.</description>
      <author>example@mail.com (Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn)</author>
      <guid isPermaLink="false">2502.08428v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Conveyor Line Color Object Sorting using A Monochrome Camera, Colored Light and RGB Filters</title>
      <link>http://arxiv.org/abs/2502.08419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 26 figures, 23rd Annual Hawaii International Conference on  Education, Ja n. 4-7, 2025, Honolulu, Hawa ii&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文测试了一种使用单色相机的机器视觉系统区分彩色物体的能力。该系统的目的是自主和连续地分类用户指定颜色的对象。&lt;h4&gt;背景&lt;/h4&gt;利用带有颜色滤镜的相机和RGB LED灯，帮助机器视觉系统识别零件对比度。&lt;h4&gt;目的&lt;/h4&gt;开发一种由可编程逻辑控制器（PLC）控制，并与机器人集成的系统来自动去除待分类的零件。&lt;h4&gt;方法&lt;/h4&gt;通过传送带将零件输送到工作单元中，该传送带也受PLC控制。用户可以通过人机界面和物理按钮选择期望的颜色。&lt;h4&gt;主要发现&lt;/h4&gt;&lt;h4&gt;结论&lt;/h4&gt;&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文测试了一种使用单色相机的机器视觉系统区分彩色物体的能力。该系统的目的是自主和连续地分类用户指定颜色的对象。该系统利用带有颜色滤镜的相机和RGB LED灯，帮助机器视觉系统识别零件对比度。此外，该系统由可编程逻辑控制器（PLC）控制，并与机器人集成用于去除零件。通过传送带将零件输送到工作单元中，该传送带也受PLC控制。用户可以通过人机界面和物理按钮选择期望的颜色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tests the ability of a machine vision system with a monochromecamera to differentiate colored objects. The system is designed to autonomouslyand continuously sort colored objects of which the user specifies the desiredcolor(s). The system uses camera color light filters and red-green-blue (RGB)color light emitting diode (LED) lights to aid the machine vision system inrecognizing part contrast. Additionally the system is controlled by aProgrammable Logic Controller (PLC) which is integrated with a Robot that isused to remove parts. The parts are fed into the workcell via a conveyor beltthat is controlled by the PLC. The user has the ability to select the desiredacceptable colors on both the HMI and the physical pushbuttons.</description>
      <author>example@mail.com (Mason Petersen, Brendon Lakenen, Krishna Chavan, Pratik Waghmare, Aleksandr Sergeyev, Nathir A. Rawashdeh)</author>
      <guid isPermaLink="false">2502.08419v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Learning Humanoid Standing-up Control across Diverse Postures</title>
      <link>http://arxiv.org/abs/2502.08378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Humanoid Standing-up Control, 12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的机器人站立控制框架HoST，该框架通过强化学习从零开始训练站立动作，并能够在不同场景和姿态下实现稳定且鲁棒的起身控制。&lt;h4&gt;背景&lt;/h4&gt;当前人形机器人的站立控制系统存在局限性，要么仅限于模拟环境，要么依赖特定地面的动作轨迹。这些方法无法适应现实世界的多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够跨不同姿势进行稳健模拟到现实转移的人形机器人站立控制系统。&lt;h4&gt;方法&lt;/h4&gt;提出了HoST框架，使用强化学习从头开始训练站立动作，并在多样化地形上利用多批评分器架构和基于课程的培训。引入平滑度正则化和隐含运动速度限制以确保实际部署的成功。&lt;h4&gt;主要发现&lt;/h4&gt;HoST能够学习适应不同姿态的动作，并且可以直接将学到的控制策略应用于Unitree G1人形机器人，实验结果表明控制器在各种实验室内外环境中表现平稳、稳定和鲁棒。&lt;h4&gt;结论&lt;/h4&gt;提出的HoST框架成功地解决了现有的站立控制系统的问题，实现了从模拟到现实环境中的稳健转移。&lt;h4&gt;翻译&lt;/h4&gt;立起控制对于人形机器人至关重要，可以整合入当前的运动和动控系统中，如跌倒恢复。现有方法要么仅限于忽视硬件限制的仿真中，要么依赖于预定义的地面特定动作轨迹，无法实现在真实场景跨姿态站起。为了弥补这一差距，我们提出了HoST（人形立起控制），这是一种从头开始学习站立控制的强化学习框架，能够实现稳健的模拟到现实跨不同姿态转移。HoST通过使用多批评分器架构和基于课程的多样化地形训练有效地学习适应姿势的动作，并施加平滑度正则化以确保实际部署的成功。在模拟训练后，所学的控制策略可以直接应用到Unitree G1人形机器人上。实验结果表明控制器实现了从实验室内外环境的平稳、稳定和鲁棒站立动作。视频可在https://taohuang13.github.io/humanoid-standingup.github.io/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Standing-up control is crucial for humanoid robots, with the potential forintegration into current locomotion and loco-manipulation systems, such as fallrecovery. Existing approaches are either limited to simulations that overlookhardware constraints or rely on predefined ground-specific motion trajectories,failing to enable standing up across postures in real-world scenes. To bridgethis gap, we present HoST (Humanoid Standing-up Control), a reinforcementlearning framework that learns standing-up control from scratch, enablingrobust sim-to-real transfer across diverse postures. HoST effectively learnsposture-adaptive motions by leveraging a multi-critic architecture andcurriculum-based training on diverse simulated terrains. To ensure successfulreal-world deployment, we constrain the motion with smoothness regularizationand implicit motion speed bound to alleviate oscillatory and violent motions onphysical hardware, respectively. After simulation-based training, the learnedcontrol policies are directly deployed on the Unitree G1 humanoid robot. Ourexperimental results demonstrate that the controllers achieve smooth, stable,and robust standing-up motions across a wide range of laboratory and outdoorenvironments. Videos are available athttps://taohuang13.github.io/humanoid-standingup.github.io/.</description>
      <author>example@mail.com (Tao Huang, Junli Ren, Huayi Wang, Zirui Wang, Qingwei Ben, Muning Wen, Xiao Chen, Jianan Li, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.08378v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.08336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Salience-Invariant Consistent Policy Learning (SCPL)的算法，旨在解决视觉强化学习中从训练环境过度拟合到测试环境中未见场景的问题。&lt;h4&gt;背景&lt;/h4&gt;在视觉强化学习领域，智能体容易过度拟合并提取与任务无关的信息，导致无法在未曾见过的环境下保持最优行为。&lt;h4&gt;目的&lt;/h4&gt;提出SCPL算法以提高零样本泛化性能，并解决智能体由于注意力分散而导致的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;{'Salience-Invariant Consistent Policy Learning (SCPL)算法': '该算法通过引入价值一致性模块和动态模块，结合增强数据集帮助编码器捕捉任务相关的表示。其中，价值一致性模块确保智能体在原始观察与扰动后的观察中关注于相关像素。', '政策一致性模块': '使用KL散度约束来维护原始观察与扰动后观察的一致性策略'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明SCPL算法在DMC-GB、机器人操作和CARLA基准测试上显著优于现有的方法，分别提高了14%，39%和69%的性能。&lt;h4&gt;结论&lt;/h4&gt;理论分析证明了政策一致性对于泛化的重要性，并且SCPL算法通过引入价值一致性和动态模块有效地提升了智能体在未见场景中的表现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizing policies to unseen scenarios remains a critical challenge invisual reinforcement learning, where agents often overfit to the specificvisual observations of the training environment. In unseen environments,distracting pixels may lead agents to extract representations containingtask-irrelevant information. As a result, agents may deviate from the optimalbehaviors learned during training, thereby hindering visual generalization.Toaddress this issue, we propose the Salience-Invariant Consistent PolicyLearning (SCPL) algorithm, an efficient framework for zero-shot generalization.Our approach introduces a novel value consistency module alongside a dynamicsmodule to effectively capture task-relevant representations. The valueconsistency module, guided by saliency, ensures the agent focuses ontask-relevant pixels in both original and perturbed observations, while thedynamics module uses augmented data to help the encoder capture dynamic- andreward-relevant representations. Additionally, our theoretical analysishighlights the importance of policy consistency for generalization. Tostrengthen this, we introduce a policy consistency module with a KL divergenceconstraint to maintain consistent policies across original and perturbedobservations.Extensive experiments on the DMC-GB, Robotic Manipulation, andCARLA benchmarks demonstrate that SCPL significantly outperformsstate-of-the-art methods in terms of generalization. Notably, SCPL achievesaverage performance improvements of 14\%, 39\%, and 69\% in the challenging DMCvideo hard setting, the Robotic hard setting, and the CARLA benchmark,respectively.Project Page: https://sites.google.com/view/scpl-rl.</description>
      <author>example@mail.com (Sun Jingbo, Tu Songjun, Zhang Qichao, Chen Ke, Zhao Dongbin)</author>
      <guid isPermaLink="false">2502.08336v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Open-Source Factor Graph Optimization Package for GNSS: Examples and Applications</title>
      <link>http://arxiv.org/abs/2502.08158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 2025 IEEE/ION Position, Location and Navigation  Symposium (PLANS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为gtsam_gnss的开源GNSS因子图优化(FGO)包，该包通过分离GNSS观测数据预处理和因子优化，简化了结构并提高了灵活性。&lt;h4&gt;背景&lt;/h4&gt;因子图优化方法在卫星导航系统研究中引起了广泛关注，并且相对于传统的基于最小二乘或卡尔曼滤波的状态估计方法具有更优的精度。&lt;h4&gt;目的&lt;/h4&gt;提出一个开源软件包gtsam_gnss以促进GNSS研究和开发，同时支持用户特定的研究需求。&lt;h4&gt;方法&lt;/h4&gt;该软件包将GNSS观测数据预处理与因子优化分离，并直接描述了GNSS因素的误差函数，以便于一般的输入使用。此外，它还包括实际城市环境中各种因素的分析示例。&lt;h4&gt;主要发现&lt;/h4&gt;gtsam_gnss在不同的应用场景中表现出良好的状态估计性能，包括鲁棒误差模型的应用、载波相位整周模糊度的估计以及GNSS和智能手机惯性测量单元(IMU)数据的融合。&lt;h4&gt;结论&lt;/h4&gt;该框架为从基于最小二乘的位置定位过渡到FGO提供了一种途径，并且支持用户特定的GNSS研究，展示了良好的状态估计性能。&lt;h4&gt;翻译&lt;/h4&gt;使用因子图优化（FGO）的状态估算方法在卫星导航系统（GNSS）的研究中获得了大量关注。与依赖于最小二乘或卡尔曼滤波的传统状态估算方法相比，FGO显示出优越的估算精度。然而，专门针对GNSS观测值的FGO库很少见。本文介绍了名为gtsam_gnss的一个开源GNSS FGO包，它具有简单结构，并且可以轻松应用于GNSS研究和开发中。该软件包将GNSS观测数据预处理与因子优化分离，同时以直接方式描述了GNSS因素的误差函数，支持一般的输入使用。这种设计便于从基于最小二乘的位置定位过渡到FGO，并且支持用户特定的GNSS研究。此外，gtsam_gnss包括实际城市环境中各种因素使用的分析示例。本文提出了三个应用实例：鲁棒误差模型的应用、载波相位整周模糊度的估计以及GNSS和智能手机惯性测量单元（IMU）数据融合。所提出的框架在所有使用案例中均表现出卓越的状态估算性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State estimation methods using factor graph optimization (FGO) have garneredsignificant attention in global navigation satellite system (GNSS) research.FGO exhibits superior estimation accuracy compared with traditional stateestimation methods that rely on least-squares or Kalman filters. However, onlya few FGO libraries are specialized for GNSS observations. This paperintroduces an open-source GNSS FGO package named gtsam\_gnss, which has asimple structure and can be easily applied to GNSS research and development.This package separates the preprocessing of GNSS observations from factoroptimization. Moreover, it describes the error function of the GNSS factor in astraightforward manner, allowing for general-purpose inputs. This designfacilitates the transition from ordinary least-squares-based positioning to FGOand supports user-specific GNSS research. In addition, gtsam\_gnss includesanalytical examples involving various factors using GNSS data in real urbanenvironments. This paper presents three application examples: the use of arobust error model, estimation of integer ambiguity in the carrier phase, andcombination of GNSS and inertial measurements from smartphones. The proposedframework demonstrates excellent state estimation performance across all usecases.</description>
      <author>example@mail.com (Taro Suzuki)</author>
      <guid isPermaLink="false">2502.08158v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles</title>
      <link>http://arxiv.org/abs/2502.08119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于无人机和地面站的鲁棒多接入边缘计算框架，用于协助无人水面艇完成复杂任务。&lt;h4&gt;背景&lt;/h4&gt;随着无人水面艇（USVs）在海上搜索与救援等应用中的部署增加，需要计算支持和覆盖。然而，由于任务不确定性、无人水面艇轨迹不确定性、异质性和有限的计算资源，无人机（UAVs）和地面站（GSs）之间的协作面临挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种优化算法来解决联合任务卸载和无人机轨迹的问题，以最小化总执行时间，并提高复杂环境下的预测不确定性和动态适应能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成式人工智能增强的异构代理近端策略优化（GAI-HAPPO）算法，该算法集成GAI模型以增强代理网络在建模复杂环境和提取高层次特征方面的能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的模拟实验表明，所提出的算法优于现有的基准方法，在解决跨域复杂问题上显示出巨大的潜力。&lt;h4&gt;结论&lt;/h4&gt;新提出的方法为无人水面艇应用中的协作计算提供了一种有效且高效的新途径，并展示了其在处理复杂和动态环境中任务分配方面的优越性。&lt;h4&gt;翻译&lt;/h4&gt;随着无人驾驶表面车辆（USVs）的部署增加，海上搜索与救援等应用需要计算支持。无人机可以提供低成本、灵活的服务，地面站可以提供强大支持，三者可合作帮助USV应对复杂场景中的挑战。然而，UAV和GS在USV任务协作中面临多项挑战，包括任务不确定性、无人水面艇轨迹不确定性以及异质性和有限的计算资源问题。为解决这些问题，提出了一种基于无人机和地面站的合作鲁棒多接入边缘计算框架来协助USVs完成计算任务。研究采用生成式人工智能增强的异构代理近端策略优化算法（GAI-HAPPO），该算法在复杂的环境建模、高阶特征提取方面表现优异，并能预测不确定性，适应动态条件变化。实验表明，所提方法显著优于现有基准，在复杂场景下表现出巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing deployment of unmanned surface vehicles (USVs) requirecomputational support and coverage in applications such as maritime search andrescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerialservices, and ground stations (GSs) can provide powerful supports, which cancooperate to help the USVs in complex scenarios. However, the collaborationbetween UAVs and GSs for USVs faces challenges of task uncertainties, USVstrajectory uncertainties, heterogeneities, and limited computational resources.To address these issues, we propose a cooperative UAV and GS based robustmulti-access edge computing framework to assist USVs in completingcomputational tasks. Specifically, we formulate the optimization problem ofjoint task offloading and UAV trajectory to minimize the total execution time,which is in the form of mixed integer nonlinear programming and NP-hard totackle. Therefore, we propose the algorithm of generative artificialintelligence-enhanced heterogeneous agent proximal policy optimization(GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actornetwork ability to model complex environments and extract high-level features,thereby allowing the algorithm to predict uncertainties and adapt to dynamicconditions. Additionally, GAI stabilizes the critic network, addressing theinstability of multi-agent reinforcement learning approaches. Finally,extensive simulations demonstrate that the proposed algorithm outperforms theexisting benchmark methods, thus highlighting the potentials in tacklingintricate, cross-domain issues in the considered scenarios.</description>
      <author>example@mail.com (Jiahao You, Ziye Jia, Chao Dong, Qihui Wu, Zhu Han)</author>
      <guid isPermaLink="false">2502.08119v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Ground-Optimized 4D Radar-Inertial Odometry via Continuous Velocity Integration using Gaussian Process</title>
      <link>http://arxiv.org/abs/2502.08093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;雷达在恶劣天气条件下提供强大的感知能力，但高本征噪声水平带来的挑战仍然存在。现有的雷达里程计通过过滤虚假点、利用多普勒速度或集成惯性测量来克服这些挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍两项超越现有雷达-惯性里程计的新改进：地面优化的噪声滤波和连续速度预积分。&lt;h4&gt;方法&lt;/h4&gt;{'第一项改进': '鉴于在激光雷达里程计中广泛使用地平面，但雷达测量的地面点分布不准确导致简单的平面拟合失效，我们引入了基于区域的不确定性感知地面建模，专门针对雷达设计。', '第二项改进': '注意到可以通过更好地结合雷达速度测量和IMU来提高雷达-惯性里程计的速度预积分准确性。现有方法往往通过离散化传播模型简化不同步数据流的时间差异来忽略这些时间差异，我们利用高斯过程（GP）构建连续的预积分方法以紧密结合3自由度线性速度与IMU。', '结果': '我们的方法在公共数据集中表现出色，在仔细的条件下垂直漂移小于1%，显著提高了高度精度。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过新颖的方法显著改进了雷达-惯性里程计性能，特别是在减少垂直漂移和提高高程精度方面取得了重大进展。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法在公共数据集上展示了卓越的性能，并将代码开源给社区：https://github.com/wooseongY/Go-RIO。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种改进雷达-惯性里程计的方法，通过优化噪声滤波和速度预积分技术来提高其在恶劣天气条件下的感知能力。这项工作引入了基于区域的不确定性感知地面建模和连续的速度预积分方法，显著减少了垂直漂移并提高了高度精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radar ensures robust sensing capabilities in adverse weather conditions, yetchallenges remain due to its high inherent noise level. Existing radar odometryhas overcome these challenges with strategies such as filtering spuriouspoints, exploiting Doppler velocity, or integrating with inertial measurements.This paper presents two novel improvements beyond the existing radar-inertialodometry: ground-optimized noise filtering and continuous velocitypreintegration. Despite the widespread use of ground planes in LiDAR odometry,imprecise ground point distributions of radar measurements cause naive planefitting to fail. Unlike plane fitting in LiDAR, we introduce a zone-baseduncertainty-aware ground modeling specifically designed for radar. Secondly, wenote that radar velocity measurements can be better combined with IMU for amore accurate preintegration in radar-inertial odometry. Existing methods oftenignore temporal discrepancies between radar and IMU by simplifying thecomplexities of asynchronous data streams with discretized propagation models.Tackling this issue, we leverage GP and formulate a continuous preintegrationmethod for tightly integrating 3-DOF linear velocity with IMU, facilitatingfull 6-DOF motion directly from the raw measurements. Our approach demonstratesremarkable performance (less than 1% vertical drift) in public datasets withmeticulous conditions, illustrating substantial improvement in elevationaccuracy. The code will be released as open source for the community:https://github.com/wooseongY/Go-RIO.</description>
      <author>example@mail.com (Wooseong Yang, Hyesu Jang, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.08093v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>A Cooperative Bearing-Rate Approach for Observability-Enhanced Target Motion Estimation</title>
      <link>http://arxiv.org/abs/2502.08089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by icra 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了基于视觉的目标运动估计问题，并提出了一种新的协同估算器STT-R，旨在解决现有方法在追踪高度机动目标时的低可观测性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉的目标运动估计算法面对高速度、高机动性的目标时存在观测性差的问题，难以有效跟踪这些目标。&lt;h4&gt;目的&lt;/h4&gt;针对无人机空中追击任务中的三维空间目标机动性难题，提出一种新的估算方法以提高可观测性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于分布式递归最小二乘法的新型协同估计算法STT-R（带有角度变化率信息的空间-时间三角测量），该算法在理论和实际实验中得到了验证。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的STT-R算法能更准确地进行目标运动估算，并有效减少了速度估计中的滞后现象，使得追踪更为机动的目标成为可能。&lt;h4&gt;结论&lt;/h4&gt;通过数值模拟和真实世界的实验验证了STT-R的有效性，该方法为解决高度机动目标的追踪问题提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;基于视觉的目标运动估算是许多机器人任务中的一个基本问题。现有的方法在观测性和跟踪高度机动的目标时存在限制。受无人机空中追击任务中需要追踪三维空间内可自由移动目标这一挑战的启发，本文研究如何通过引入未被充分探索的角度变化率信息来进一步增强可观测性。论文的主要贡献在于提出了一个新的协同估计算法STT-R（带有角度变化率的空间-时间三角测量），该算法是在分布式递归最小二乘框架下设计的。理论结果通过数值模拟和真实实验得到了验证，显示了所提出的STT-R算法能有效提高估计精度，并显著减少了速度估算中的滞后现象，使得追踪更为机动的目标成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based target motion estimation is a fundamental problem in manyrobotic tasks. The existing methods have the limitation of low observabilityand, hence, face challenges in tracking highly maneuverable targets. Motivatedby the aerial target pursuit task where a target may maneuver in 3D space, thispaper studies how to further enhance observability by incorporating the\emph{bearing rate} information that has not been well explored in theliterature. The main contribution of this paper is to propose a new cooperativeestimator called STT-R (Spatial-Temporal Triangulation with bearing Rate),which is designed under the framework of distributed recursive least squares.This theoretical result is further verified by numerical simulation andreal-world experiments. It is shown that the proposed STT-R algorithm caneffectively generate more accurate estimations and effectively reduce the lagin velocity estimation, enabling tracking of more maneuverable targets.</description>
      <author>example@mail.com (Canlun Zheng, Hanqing Guo, Shiyu Zhao)</author>
      <guid isPermaLink="false">2502.08089v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Innovations in Nanotechnology: A Comprehensive Review of Applications Beyond Space Exploration</title>
      <link>http://arxiv.org/abs/2502.08036v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures, a review paper about the use of nanotechnology in  space exploration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;纳米技术在多个行业中展现出变革力量，通过改善材料、提高仪器精度以及开发智能系统来促进工业进步。&lt;h4&gt;背景&lt;/h4&gt;纳米技术在材料科学、医疗健康、能源存储、环境监测和机器人学等多个领域都有广泛应用。例如碳纳米管和石墨烯等纳米材料，在能量生成和医药等领域提供了显著的改进，而纳米传感器则革新了环境和工业监测手段。&lt;h4&gt;目的&lt;/h4&gt;综述文章旨在探讨各种纳米技术应用，包括在不同领域的先进技术和创新方法，并强调跨学科合作的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;微/纳机器人提供自动化解决方案，进一步扩展到空间探索之外的其他领域，展示了纳米技术在未来重塑行业的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;通过跨学科协作和持续创新，纳米技术将对工业界产生深远影响，开启新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;纳米技术作为一种变革力量，在多个行业中崭露头角。它提升了材料性能、提高了仪器的精度，并开发了智能系统。此综述探讨了纳米技术在诸如材料科学、医疗健康、能源存储、环境监测及机器人学等领域的应用。特别地，碳纳米管和石墨烯等纳米材料显著改善了能量生成和医学领域的发展，而纳米传感器则革新了环境与工业的监测方式。微/纳机器人提供了跨行业的自动化解决方案，并且其影响力已从太空探索延伸到其他重要方面，展示了纳米技术在未来重塑各行业中的巨大潜力。综述强调了通过跨学科合作及持续创新来实现这一潜力的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nanotechnology has emerged as a transformative force across multipleindustries, enhancing materials, improving instrumentation precision, anddeveloping intelligent systems. This review explores various nanotechnologyapplications, including advancements in materials science, healthcare, energystorage, environmental monitoring, and robotics. Nanomaterials, such as carbonnanotubes and graphene, offer significant improvements in fields like energygeneration and medicine, while nanosensors revolutionize environmental andindustrial monitoring. Micro and nano robots provide automation solutionsacross industries. By expanding beyond space exploration, this reviewhighlights the far-reaching potential of nanotechnology to reshape industriesthrough interdisciplinary collaboration and innovation.</description>
      <author>example@mail.com (Syed Muhammad Muslim Hussain, Batool Zehra Ladha, Muhammad Hasan Khan)</author>
      <guid isPermaLink="false">2502.08036v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Predictive Planner for Autonomous Driving with Consistency Models</title>
      <link>http://arxiv.org/abs/2502.08033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的统一数据驱动框架，将轨迹预测和规划结合在一个一致性模型中。该框架通过端到端的预测性规划解决了传统模块化方法中的交互式规划问题，并且更适用于多代理场景。&lt;h4&gt;背景&lt;/h4&gt;传统的自动驾驶车辆导航组件如轨迹预测和规划常常被视为独立模块处理，限制了互动规划能力并导致在多代理环境下的计算效率低下。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的框架以整合轨迹预测与规划过程，通过使用单一的一致性模型来提高交互式行为的生成能力和实际应用中的实时性能。&lt;h4&gt;方法&lt;/h4&gt;利用现实世界的人类驾驶数据集训练一致性模型，该模型能够从自我车辆及周围代理的高维多模态联合轨迹分布中生成样本，并提出了一种交替方向法以在线指导采样并加入对自我车辆的额外规划约束。&lt;h4&gt;主要发现&lt;/h4&gt;对比扩散模型，该一致性的模型在更少的抽样步骤下实现了更好的性能，在Waymo开放运动数据集(WOMD)上的实验结果表明其轨迹质量、约束满足度和交互行为优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;论文提出的新框架展示了改进自动驾驶车辆导航决策能力的巨大潜力，并为未来研究提供了有效的途径，特别是在多代理场景中的实时交互性规划方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory prediction and planning are fundamental components for autonomousvehicles to navigate safely and efficiently in dynamic environments.Traditionally, these components have often been treated as separate modules,limiting the ability to perform interactive planning and leading tocomputational inefficiency in multi-agent scenarios. In this paper, we presenta novel unified and data-driven framework that integrates prediction andplanning with a single consistency model. Trained on real-world human drivingdatasets, our consistency model generates samples from high-dimensional,multimodal joint trajectory distributions of the ego and multiple surroundingagents, enabling end-to-end predictive planning. It effectively producesinteractive behaviors, such as proactive nudging and yielding to ensure bothsafe and efficient interactions with other road users. To incorporateadditional planning constraints on the ego vehicle, we propose an alternatingdirection method for multi-objective guidance in online guided sampling.Compared to diffusion models, our consistency model achieves better performancewith fewer sampling steps, making it more suitable for real-time deployment.Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate ourmethod's superiority in trajectory quality, constraint satisfaction, andinteractive behavior compared to various existing approaches.</description>
      <author>example@mail.com (Anjian Li, Sangjae Bae, David Isele, Ryne Beeson, Faizan M. Tariq)</author>
      <guid isPermaLink="false">2502.08033v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Visual-Haptic Model Mediated Teleoperation for Remote Ultrasound</title>
      <link>http://arxiv.org/abs/2502.07922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Supplementary video: https://youtu.be/fDLBah7bPeo . This work has  been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种远程超声系统的原型，该系统结合了视觉和触觉反馈模型，可以有效减少时间延迟带来的影响。&lt;h4&gt;背景&lt;/h4&gt;远程超声波技术有助于改善偏远地区的医疗公平性，但实际应用中存在的时间延迟问题导致传统的遥操作方式表现不佳。&lt;h4&gt;目的&lt;/h4&gt;通过引入本地环境的视觉-触觉模型来补偿长时间延迟，提高远程机器人超声系统的稳定性和准确性。&lt;h4&gt;方法&lt;/h4&gt;设计并测试了一种原型系统，在该系统中使用预先获取的超声扫描实时重切片和渲染技术为操作员提供延迟图像的预览。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，视觉-触觉模型中介遥操作（MMT）能够完全补偿1000毫秒往返时间延迟对操作者努力和完成时间的影响。对于更长时间延迟，视觉-触觉MMT在运动准确性和力控制方面也显著优于传统MMT。&lt;h4&gt;结论&lt;/h4&gt;本概念验证研究证明了视觉-触觉模型中介遥操作可能有助于远程机器人超声的应用。&lt;h4&gt;翻译&lt;/h4&gt;该摘要描述了一种利用本地环境的视觉和触觉反馈来改善时间延迟影响的方法，通过在实验中应用原型系统并收集数据，证实了所提出技术的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tele-ultrasound has the potential greatly to improve health equity forcountless remote communities. However, practical scenarios involve potentiallylarge time delays which cause current implementations of telerobotic ultrasound(US) to fail. Using a local model of the remote environment to provide hapticsto the expert operator can decrease teleoperation instability, but the delayedvisual feedback remains problematic. This paper introduces a robotic tele-USsystem in which the local model is not only haptic, but also visual, byre-slicing and rendering a pre-acquired US sweep in real time to provide theoperator a preview of what the delayed image will resemble. A prototype systemis presented and tested with 15 volunteer operators. It is found thatvisual-haptic model-mediated teleoperation (MMT) compensates completely fortime delays up to 1000 ms round trip in terms of operator effort and completiontime while conventional MMT does not. Visual-haptic MMT also significantlyoutperforms MMT for longer time delays in terms of motion accuracy and forcecontrol. This proof-of-concept study suggests that visual-haptic MMT mayfacilitate remote robotic tele-US.</description>
      <author>example@mail.com (David Black, Maria Tirindelli, Septimiu Salcudean, Wolfgang Wein, Marco Esposito)</author>
      <guid isPermaLink="false">2502.07922v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Safe Scheduling of Robots</title>
      <link>http://arxiv.org/abs/2502.07851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种快速启发式算法，用于在路径图上为一组机器人生成无碰撞调度方案的实验分析。&lt;h4&gt;背景&lt;/h4&gt;现有的方法可能无法有效地解决多机器人系统中的无碰撞调度问题。&lt;h4&gt;目的&lt;/h4&gt;评估该启发式算法的有效性，并通过整数线性规划验证其性能和最优解能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一种快速生成无碰撞调度方案的启发式算法，同时提供了一个保证任何输入图上最优解的整数线性规划模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在所有任务时长相等的情况下，该启发式算法能够产生最优解；对比两种算法的解决方案和运行时间后发现，尽管整数线性规划可以找到全局最优解，但其计算资源消耗较大，而启发式算法则在几乎所有情况下都接近或达到最优，并且具有更快的运行速度。&lt;h4&gt;结论&lt;/h4&gt;该快速启发式算法是解决多机器人无碰撞调度问题的有效工具，在大多数实际应用场景中优于整数线性规划方法。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们展示了对一种快速启发式算法进行实验分析的结果。这种算法旨在为路径图上的机器人生成快速且无碰撞的调度方案。实验验证了该算法在产生无碰撞调度方案方面的有效性，并表明当所有分配给机器人的任务时长相等时，它可以达到最优解。此外，我们还提供了一个整数线性规划模型来保证对任何输入图上此调度问题的最佳解决方案，尽管这会消耗显著更多的计算资源。通过对比这两种算法的解决方案和运行时间，我们证明了启发式算法在几乎所有情况下都接近或达到了最佳性能，并且其执行速度远快于整数线性规划方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an experimental analysis of a fast heuristicalgorithm that was designed to generate a fast, collision-free schedule for aset of robots on a path graph. The experiments confirm the algorithm'seffectiveness in producing collision-free schedules as well as achieving theoptimal solution when all tasks assigned to the robots are of equal duration.Additionally, we provide an integer linear programming formulation thatguarantees an optimal solution for this scheduling problem on any input graph,at the expense of significantly greater computational resources. We prove thecorrectness of our integer linear program. By comparing the solutions of thesetwo algorithms, including the time required by the schedule itself, and the runtime of each algorithm, we show that the heuristic algorithm is optimal or nearoptimal in nearly all cases, with a far faster run time than the integer linearprogram.</description>
      <author>example@mail.com (Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul G. Spirakis)</author>
      <guid isPermaLink="false">2502.07851v1</guid>
      <pubDate>Thu, 13 Feb 2025 16:37:06 +0800</pubDate>
    </item>
    <item>
      <title>Factor Modelling for Biclustering Large-dimensional Matrix-valued Time Series</title>
      <link>http://arxiv.org/abs/2502.06397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于全新潜在双向因子结构的无监督学习方法，用于大规模矩阵值时间序列的聚类。该方法通过估计全局加载空间和特定于集群的因素加载空间来实现。&lt;h4&gt;背景&lt;/h4&gt;处理高维矩阵值时间序列的数据在许多领域变得越来越重要，然而传统的聚类算法难以有效处理这种复杂类型的数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督学习方法，能够有效地对大规模的矩阵值时间序列进行聚类，并同时识别潜在的行/列集群。&lt;h4&gt;方法&lt;/h4&gt;通过将观测矩阵投影到对应的公共因素行或列加载空间上来估计全局加载空间；然后通过向已估计出的全局加载空间的正交补空间投影来进一步恢复特定于集群的因素加载空间。提供了一个基于估计出的行/列因素负载的$K$-means算法，用于同时识别矩阵值时间序列的潜在行/列集群。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在温和条件下获得了比现有文献中的最佳方法更快收敛率的全局加载矩阵，并提出了一种单次特征比率方法来估计全球和特定于集群的因素数量。建立了局部加载矩阵、因素数以及潜伏群成员身份的估计器的一致性和显式收敛速率。&lt;h4&gt;结论&lt;/h4&gt;通过数值实验（包括模拟数据和真实数据示例）验证了所提方法的有效性，展示了该新方法在处理大规模高维矩阵值时间序列聚类任务中的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的内容被翻译成中文，并根据论文主要关注点进行了分段总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A novel unsupervised learning method is proposed in this paper forbiclustering large-dimensional matrix-valued time series based on an entirelynew latent two-way factor structure. Each block cluster is characterized by itsown row and column cluster-specific factors in addition to some common matrixfactors which impact on all the matrix time series. We first estimate theglobal loading spaces by projecting the observation matrices onto the row orcolumn loading space corresponding to common factors. The loading spaces forcluster-specific factors are then further recovered by projecting theobservation matrices onto the orthogonal complement space of the estimatedglobal loading spaces. To identify the latent row/column clusterssimultaneously for matrix-valued time series, we provide a $K$-means algorithmbased on the estimated row/column factor loadings of the cluster-specific weakfactors. Theoretically, we derive faster convergence rates for global loadingmatrices than those of the state-of-the-art methods available in the literatureunder mild conditions. We also propose an one-pass eigenvalue-ratio method toestimate the numbers of global and cluster-specific factors. The consistencywith explicit convergence rates is also established for the estimators of thelocal loading matrices, the factor numbers and the latent cluster memberships.Numerical experiments with both simulated data as well as a real data exampleare also reported to illustrate the usefulness of our proposed method.</description>
      <author>example@mail.com (Yong He, Xiaoyang Ma, Xingheng Wang, Yalin Wang)</author>
      <guid isPermaLink="false">2502.06397v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
  <item>
      <title>Block Graph Neural Networks for tumor heterogeneity prediction</title>
      <link>http://arxiv.org/abs/2502.05458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于模拟肿瘤演化的数学模型生成人工数据集的方法，用于提高肿瘤分类的准确性。通过这种方法和Block Graph Neural Networks（BGNN）网络，研究者在人工生成的数据上实现了89.67%的测试精度。&lt;h4&gt;背景&lt;/h4&gt;现有的肿瘤分级方法存在局限性，单一细胞测序可以提供深入见解但成本高昂且操作复杂，统计机器学习方法需要复杂的预处理步骤。因此需要更有效的方法来克服这些挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于数学模型和BGNN网络的框架，用于生成人工数据集以改进肿瘤分类准确性，并探索结合传统分级方法与细胞增殖指数（如Ki-67）等生化指标的可能性。&lt;h4&gt;方法&lt;/h4&gt;(1) 从人工数据中提取切片和图生成过程；(2) 设计肿瘤特征；(3) 构建基于Graph Neural Network的Block Graph Neural Networks (BGNN)，用于预测肿瘤异质性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的组合特征和模型在人工生成的数据集上取得了优秀的分类性能，显示出结合传统病理学方法与分子标记能够显著提高肿瘤异质性的预测准确性和总体分类效率。&lt;h4&gt;结论&lt;/h4&gt;这种方法不仅展示了其在提高肿瘤分类准确性方面的潜力，而且为未来的AI辅助分级和空间转录组学研究提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate tumor classification is essential for selecting effectivetreatments, but current methods have limitations. Standard tumor grading, whichcategorizes tumors based on cell differentiation, is not recommended as astand-alone procedure, as some well-differentiated tumors can be malignant.Tumor heterogeneity assessment via single-cell sequencing offers profoundinsights but can be costly and may still require significant manualintervention. Many existing statistical machine learning methods for tumor datastill require complex pre-processing of MRI and histopathological data.  In this paper, we propose to build on a mathematical model that simulatestumor evolution (O\.{z}a\'{n}ski (2017)) and generate artificial datasets fortumor classification. Tumor heterogeneity is estimated using normalizedentropy, with a threshold to classify tumors as having high or lowheterogeneity. Our contributions are threefold: (1) the cut and graphgeneration processes from the artificial data, (2) the design of tumorfeatures, and (3) the construction of Block Graph Neural Networks (BGNN), aGraph Neural Network-based approach to predict tumor heterogeneity. Theexperimental results reveal that the combination of the proposed features andmodels yields excellent results on artificially generated data ($89.67\%$accuracy on the test data). In particular, in alignment with the emergingtrends in AI-assisted grading and spatial transcriptomics, our results suggestthat enriching traditional grading methods with birth (e.g., Ki-67proliferation index) and death markers can improve heterogeneity prediction andenhance tumor classification.</description>
      <author>example@mail.com (Marianne Abémgnigni Njifon, Tobias Weber, Viktor Bezborodov, Tyll Krueger, Dominic Schuhmacher)</author>
      <guid isPermaLink="false">2502.05458v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Allegro-FM: Towards Equivariant Foundation Model for Exascale Molecular Dynamics Simulations</title>
      <link>http://arxiv.org/abs/2502.06073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种基于E(3)等变网络架构（Allegro）和通过Total Energy Alignment (TEA)框架整合的大规模有机及无机材料数据集构建的用于百亿亿次级分子动力学模拟的基础模型。此模型在描述结构、力学和热力学性质方面与高级量子化学理论有很好的一致性，并展现出对未训练任务（如结构相关性、反应动力学等）的新能力。&lt;h4&gt;背景&lt;/h4&gt;当前分子动力学模拟需要处理大规模的材料系统，而传统的计算方法难以满足其需求。利用深度学习技术可以提高模型性能和预测准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效处理大量原子系统的百亿亿次级分子动力学基础模型，并展示该模型在不同下游任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用E(3)等变网络架构（Allegro）和Total Energy Alignment (TEA)框架整合的大规模材料数据集，训练一个通用的材料模拟基础模型（Allegro-FM）。测试其在化学反应、机械强度等方面的表现，并评估其在百亿亿次超级计算机上的并行效率。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的Allegro-FM模型在未经过专门训练的情况下，能够准确预测结构相关性、反应动力学等特性。该模型对9.1百万个过渡态数据集和钙硅酸盐水合物的化学反应具有强大的预测能力和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究展示了基于大规模原子级模拟的基础模型在新型材料设计与发现方面的巨大潜力，为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种利用E(3)等变网络架构（Allegro）和Total Energy Alignment (TEA)框架合并的大规模有机及无机材料数据集构建的用于百亿亿次分子动力学模拟的基础模型。由于大规模训练数据集的支持，获得的模型（Allegro-FM）适用于各种材料模拟任务，涵盖周期表中89种元素的下游任务。Allegro-FM在描述结构、力学和热力学性质方面与高级量子化学理论有很好的一致性，并且展示了未经过训练的任务上的新能力，如结构相关性、反应动力学等。此外，我们还通过包含9.1百万过渡态数据集及钙硅酸盐水合物测试床的实验验证了Allegro-FM在化学反应预测中的鲁棒性和泛化性。凭借其计算效率高和严格局部化的网络架构，Allegro-FM可以扩展到数十亿原子系统，并且在美国阿贡国家实验室领导力计算设施上的Aurora超级计算机上实现了0.964的并行效率。本工作提出的方法展示了基于大规模原子级模拟的基础模型在新型材料设计与发现方面的潜在价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a foundation model for exascale molecular dynamics simulations byleveraging an E(3) equivariant network architecture (Allegro) and a set oflarge-scale organic and inorganic materials datasets merged by Total EnergyAlignment (TEA) framework. Thanks to the large-scale training sets, theobtained model (Allegro-FM) is versatile for various materials simulations fordiverse downstream tasks covering 89 elements in the periodic table. Allegro-FMexhibits excellent agreements with high-level quantum chemistry theories indescribing structural, mechanical, and thermodynamic properties, whileexhibiting emergent capabilities for structural correlations, reactionkinetics, mechanical strengths, fracture, and solid/liquid dissolution, forwhich the model has not been trained. Furthermore, we demonstrate the robustpredictability and generalizability of Allegro-FM for chemical reactions usingthe transition1x that consists of 9.1 million transition state data, as well ascalcium silicate hydrates as a testbed. With its computationally efficient,strictly-local network architecture, Allegro-FM scales up to multi-billion-atomsystems with a parallel efficiency of 0.964 on the exaflop/s Aurorasupercomputer at Argonne Leadership Computing Facility. The approach presentedin this work demonstrates the potential of the foundation model for a novelmaterials design and discovery based on large-scale atomistic simulations.</description>
      <author>example@mail.com (Ken-ichi Nomura, Shinnosuke Hattori, Satoshi Ohmura, Ikumi Kanemasu, Kohei Shimamura, Nabankur Dasgupta, Aiichiro Nakano, Rajiv K. Kalia, Priya Vashishta)</author>
      <guid isPermaLink="false">2502.06073v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning</title>
      <link>http://arxiv.org/abs/2502.07721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了一种新的可转移元学习者TMLC-Net，旨在解决现实世界数据集中噪音标签对深度学习模型有效部署的阻碍问题。&lt;h4&gt;背景&lt;/h4&gt;在实际的数据集中，噪声标签广泛存在并对深度学习模型的有效应用构成了显著障碍。尽管元学习策略作为应对这一挑战的一种有前景的方法已经出现，但现有的方法往往因为有限的转移性和任务特定设计而受限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的可迁移的元学习者TMLC-Net来克服这些限制，并解决噪声标签的问题。&lt;h4&gt;方法&lt;/h4&gt;TMLC-Net包含三个核心组件：(1)归一化噪声感知，捕捉并归一化训练动态以处理分布偏移；(2)时间序列编码，使用递归神经网络建模样本统计的时态演变；(3)子类解码，根据学习到的表示预测一个修正标签分布。&lt;h4&gt;主要发现&lt;/h4&gt;在具有不同噪声类型和水平的基准数据集上进行了广泛的实验，结果表明TMLC-Net在准确性和对标签噪声的鲁棒性方面均优于最先进的方法。此外，分析了TMLC-Net的可转移性，并展示了其适应新数据集和噪声条件的能力。&lt;h4&gt;结论&lt;/h4&gt;研究确立了TMLC-Net作为一种广泛适用解决方案在嘈杂环境中进行稳健深度学习的潜力。&lt;h4&gt;翻译&lt;/h4&gt;现实世界数据集中噪声标签的普遍存在对深度学习模型的有效应用构成了显著障碍。虽然元学习策略作为应对这一挑战的一种有前景的方法已经出现，但现有的方法往往因为有限的转移性和任务特定设计而受限。本研究提出了一种新的可迁移的元学习者TMLC-Net来克服这些限制，并解决了噪声标签的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prevalence of noisy labels in real-world datasets poses a significantimpediment to the effective deployment of deep learning models. Whilemeta-learning strategies have emerged as a promising approach for addressingthis challenge, existing methods often suffer from limited transferability andtask-specific designs. This paper introduces TMLC-Net, a novel TransferableMeta-Learner for Correcting Noisy Labels, designed to overcome theselimitations. TMLC-Net learns a general-purpose label correction strategy thatcan be readily applied across diverse datasets and model architectures withoutrequiring extensive retraining or fine-tuning. Our approach integrates threecore components: (1) Normalized Noise Perception, which captures and normalizestraining dynamics to handle distribution shifts; (2) Time-Series Encoding,which models the temporal evolution of sample statistics using a recurrentneural network; and (3) Subclass Decoding, which predicts a corrected labeldistribution based on the learned representations. We conduct extensiveexperiments on benchmark datasets with various noise types and levels,demonstrating that TMLC-Net consistently outperforms state-of-the-art methodsin terms of both accuracy and robustness to label noise. Furthermore, weanalyze the transferability of TMLC-Net, showcasing its adaptability to newdatasets and noise conditions, and establishing its potential as a broadlyapplicable solution for robust deep learning in noisy environments.</description>
      <author>example@mail.com (Mengyang Li)</author>
      <guid isPermaLink="false">2502.07721v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement</title>
      <link>http://arxiv.org/abs/2502.07680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于最小势能（MPE）的全局配准方法，用于解决工业测量中由于3D采集系统缺陷导致的点云数据噪声和不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;在自由形式叶片重建过程中，点云注册是关键步骤。然而，由于3D获取系统的测量缺陷，不可避免地会导致包含噪声和缺失的数据点云，使得精确高效的配准变得具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全局配准方法，该方法基于最小势能（MPE）的方法来解决上述问题，并提高精度与抗噪能力。&lt;h4&gt;方法&lt;/h4&gt;1. 定义目标函数为物理注册系统的最小势能优化函数，通过这种方法可以更重视大部分内部点的权重，减少噪声和异常值的影响。2. 将解决方案分解为全局最优逼近过程和使用修剪迭代最近点算法的精细配准过程以加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;1. 提出了一种新理论来寻找MPE点，该理论采用两个标志来监测注册过程的状态。2. 在四种类型的叶片上展示了所提出方法的效果，在精度和抗噪能力方面优于其他全局方法。&lt;h4&gt;结论&lt;/h4&gt;提出的基于最小势能（MPE）的配准算法在工业测量中的噪声点云数据处理中表现出色，为提高自由形式叶片重建的效率与准确性提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云注册是工业测量中自由形式叶片重建的关键步骤。然而，由于3D获取系统的测量缺陷，不可避免地会导致包含噪声和缺失的数据点云，这使得精确高效的配准变得具有挑战性。本文提出了一种新的全局配准方法，基于最小势能（MPE）的方法来解决这些问题。基本策略是目标函数被定义为物理注册系统中的最小势能优化函数。此函数对内部大多数点分配更多权重，并且对噪声和异常值的权重较少，这本质上减少了数学公式化中扰动的影响。我们将解决方案分解为全局最优逼近过程以及使用修剪迭代最近点算法的精细配准过程以加速收敛。近似程序包含两个主要步骤：根据力牵引算子构造，可以简单地计算潜在能量最小的位置；为了找到MPE点，我们提出了一种新理论，即采用两个标志来观察注册过程的状态。我们在四种类型的叶片上展示了所提出的算法的性能，在精度和抗噪能力方面优于其他全局方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIM.2022.3169559&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration is an essential step for free-form bladereconstruction in industrial measurement. Nonetheless, measuring defects of the3D acquisition system unavoidably result in noisy and incomplete point clouddata, which renders efficient and accurate registration challenging. In thispaper, we propose a novel global registration method that is based on theminimum potential energy (MPE) method to address these problems. The basicstrategy is that the objective function is defined as the minimum potentialenergy optimization function of the physical registration system. The functiondistributes more weight to the majority of inlier points and less weight to thenoise and outliers, which essentially reduces the influence of perturbations inthe mathematical formulation. We decompose the solution into a globally optimalapproximation procedure and a fine registration process with the trimmediterative closest point algorithm to boost convergence. The approximationprocedure consists of two main steps. First, according to the construction ofthe force traction operator, we can simply compute the position of thepotential energy minimum. Second, to find the MPE point, we propose a newtheory that employs two flags to observe the status of the registrationprocedure. We demonstrate the performance of the proposed algorithm on fourtypes of blades. The proposed method outperforms the other global methods interms of both accuracy and noise resistance.</description>
      <author>example@mail.com (Zijie Wu, Yaonan Wang, Yang Mo, Qing Zhu, He Xie, Haotian Wu, Mingtao Feng, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.07680v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Analytic Personalized Federated Meta-Learning</title>
      <link>http://arxiv.org/abs/2502.06915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两种框架，分别是FedACnnL和pFedACnnL，前者是用于深度神经网络训练的分析联邦学习（AFL）框架，后者是对前者的扩展，可以处理异质数据分布问题。这两个框架都能显著减少模型训练时间，并且在大多数情况下能够达到或超越现有最佳性能。&lt;h4&gt;背景&lt;/h4&gt;当前的AFL框架不支持DNN训练，且未解决异质数据分布问题，这限制了其应用范围和效果。&lt;h4&gt;目的&lt;/h4&gt;提出新的分析联邦学习方法以克服现有AFL框架对DNN的支持不足以及忽视异质数据的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了FedACnnL框架，使用一种新颖的局部分析学习方法ACnnL，并将每一层训练建模为一个分布式最小二乘问题。进一步扩展该框架形成pFedACnnL，允许具有相似数据分布的客户端共享一个健壮的全局模型以快速适应其本地任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与传统零阶（即无梯度）FL框架相比，FedACnnL训练时间减少了98%。而在大多数凸和非凸设置中，pFedACnnL达到了最佳性能。&lt;h4&gt;结论&lt;/h4&gt;新提出的FedACnnL和pFedACnnL框架不仅大大缩短了深度神经网络的训练时间，而且在处理异质数据分布方面也显示出了优越性。&lt;h4&gt;翻译&lt;/h4&gt;分析联邦学习（AFL）通过使用封闭形式的最小二乘（LS）解决方案仅更新一次模型权重来减少大量无梯度联邦学习（FL）中的训练时间。当前的AFL框架无法支持深度神经网络（DNN）训练，这阻碍了其在复杂机器学习任务上的实施。同时，它忽略了限制单一全局模型在其执行每个客户端的任务时表现不佳的异构数据分布问题。为克服第一个挑战，我们提出了一种新的AFL框架FedACnnL，在该框架中，我们求助于一种新颖的本地分析学习方法（ACnnL），并将其每一层的训练建模为一个分布式LS问题。针对第二个挑战，我们提出了一个基于FedACnnL的分析个性化联邦元学习框架pFedACnnL。在pFedACnnL中，具有相似数据分布的客户端共享一个健壮的全局模型，并以分析方式快速适应其本地任务。理论上证明了FedACnnL比传统的零阶（即无梯度）FL框架在DNN训练中的所需时间显著缩短，在实验中减少了98%。同时，pFedACnnL在大多数凸和非凸设置下达到了最佳性能，优于之前的最优框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analytic federated learning (AFL) which updates model weights only once byusing closed-form least-square (LS) solutions can reduce abundant training timein gradient-free federated learning (FL). The current AFL framework cannotsupport deep neural network (DNN) training, which hinders its implementation oncomplex machine learning tasks. Meanwhile, it overlooks the heterogeneous datadistribution problem that restricts the single global model from performingwell on each client's task. To overcome the first challenge, we propose an AFLframework, namely FedACnnL, in which we resort to a novel local analyticlearning method (ACnnL) and model the training of each layer as a distributedLS problem. For the second challenge, we propose an analytic personalizedfederated meta-learning framework, namely pFedACnnL, which is inherited fromFedACnnL. In pFedACnnL, clients with similar data distribution share a commonrobust global model for fast adapting it to local tasks in an analytic manner.FedACnnL is theoretically proven to require significantly shorter training timethan the conventional zeroth-order (i.e. gradient-free) FL frameworks on DNNtraining while the reduction ratio is $98\%$ in the experiment. Meanwhile,pFedACnnL achieves state-of-the-art (SOTA) model performance in most cases ofconvex and non-convex settings, compared with the previous SOTA frameworks.</description>
      <author>example@mail.com (Shunxian Gu, Chaoqun You, Deke Guo, Zhihao Qu, Bangbang Ren, Zaipeng Xie, Lailong Luo)</author>
      <guid isPermaLink="false">2502.06915v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Stereograph: Stereoscopic event reconstruction using graph neural networks applied to CTAO</title>
      <link>http://arxiv.org/abs/2502.07421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CTAO是一个正在建设中的国际天文台，计划拥有超过六十个望远镜，将成为世界上最大的和最敏感的地面伽马射线观测站。论文探讨了使用图神经网络（GNN）来改进事件重建的方法，并展示了该方法在提高能量分辨率、角分辨率以及区分伽马光子与质子方面优于传统的随机森林算法。&lt;h4&gt;背景&lt;/h4&gt;CTAO通过观察由宇宙中的剧烈现象产生的高能伽马射线，研究宇宙的高能特性。这些伽马射线进入大气层后会产生切伦科夫辐射，被CTAO的高度敏感相机捕捉到。&lt;h4&gt;目的&lt;/h4&gt;探索使用图神经网络（GNN）来优化多台望远镜观测数据的整合和事件重建过程。&lt;h4&gt;方法&lt;/h4&gt;利用模拟的数据集，采用图神经网络模型进行立体重建，并与传统随机森林算法的结果对比。&lt;h4&gt;主要发现&lt;/h4&gt;相比于传统的随机森林方法，基于GNN的方法在能量分辨率、角分辨率上表现更好，同时在区分伽马光子和质子方面也有明显优势。&lt;h4&gt;结论&lt;/h4&gt;图神经网络为提高CTAO事件重建的准确性和性能提供了一种有前景的新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The CTAO (Cherenkov Telescope Array Observatory) is an internationalobservatory currently under construction. With more than sixty telescopes, itwill eventually be the largest and most sensitive ground-based gamma-rayobservatory. CTAO studies the high-energy universe by observing gamma raysemitted by violent phenomena (supernovae, black hole environments, etc.). Thesegamma rays produce an atmospheric shower when entering the atmosphere, whichemits faint blue light, observed by CTAO's highly sensitive cameras. The eventreconstruction consists of analyzing the images produced by the telescopes toretrieve the physical properties of the incident particle (mainly direction,energy, and type). A standard method for performing this reconstructionconsists of combining traditional image parameter calculations with machinelearning algorithms, such as random forests, to estimate the particle's energyand class probability for each telescope. A second step, called stereoscopy,combines these monoscopic reconstructions into a global one using weightedaverages. In this work, we explore the possibility of using Graph NeuralNetworks (GNNs) as a suitable solution for combining information from eachtelescope. The "graph" approach aims to link observations from differenttelescopes, allowing analysis of the shower from multiple angles and producinga stereoscopic reconstruction of the events. We apply GNNs to CTAO-simulateddata from the Northern Hemisphere and show that they are a very promisingapproach to improving event reconstruction, providing a more performantstereoscopic reconstruction. In particular, we observe better energy andangular resolutions(before event selection) and better separation between gammaphotons and protons compared to the Random Forest method.</description>
      <author>example@mail.com (Hana Ali Messaoud, Thomas Vuillaume, Tom François)</author>
      <guid isPermaLink="false">2502.07421v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Robust Representations of Neutrino Data</title>
      <link>http://arxiv.org/abs/2502.07724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了对比学习在中微子物理学中的应用，旨在通过结合经验评估和理论见解展示对比学习如何提升模型性能及适应性。&lt;h4&gt;背景&lt;/h4&gt;中微子物理分析依赖于大规模模拟数据集，因此模型需有效泛化至真实世界探测器数据。对比学习作为一种成熟的深度学习技术，为这一挑战提供了有前景的解决方案。&lt;h4&gt;目的&lt;/h4&gt;探究对比学习方法在中微子物理学中的应用，展示其如何提升模型性能和适应性，并将其与其他领域适应技术进行比较。&lt;h4&gt;方法&lt;/h4&gt;通过结合经验评估和理论见解来研究对比学习的方法和技术优势。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习能够通过控制数据增强从模拟数据中提取出稳健且可迁移的特征，从而提升了基于模拟训练模型对真实实验数据分布的适应能力。&lt;h4&gt;结论&lt;/h4&gt;对比学习在解决中微子物理学中的领域适配问题上具有独特的优势，并能显著提高模型性能和适应性。&lt;h4&gt;翻译&lt;/h4&gt;在中微子物理研究中，数据分析通常依赖于大量模拟数据集。为了使基于这些模拟训练得到的模型能够有效地应用于实际探测器的数据中，需要确保模型具备良好的泛化能力。对比学习作为一种成熟的深度学习技术，在这里展现出了它的独特优势：通过应用控制的数据增强技术到模拟数据上，可以提取出更加稳定和可转移的特征，从而使得在模拟数据基础上训练出来的模型更能适应真实实验中的数据分布特性。本论文研究了对比学习方法如何被应用于中微子物理领域，并通过一系列实证评估及理论分析展示其优势所在；同时与其他领域的适配技术进行了比较，突显出对比学习在此特定应用背景下的独特优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In neutrino physics, analyses often depend on large simulated datasets,making it essential for models to generalise effectively to real-world detectordata. Contrastive learning, a well-established technique in deep learning,offers a promising solution to this challenge. By applying controlled dataaugmentations to simulated data, contrastive learning enables the extraction ofrobust and transferable features. This improves the ability of models trainedon simulations to adapt to real experimental data distributions. In this paper,we investigate the application of contrastive learning methods in the contextof neutrino physics. Through a combination of empirical evaluations andtheoretical insights, we demonstrate how contrastive learning enhances modelperformance and adaptability. Additionally, we compare it to other domainadaptation techniques, highlighting the unique advantages of contrastivelearning for this field.</description>
      <author>example@mail.com (Alex Wilkinson, Radi Radev, Saul Alonso-Monsalve)</author>
      <guid isPermaLink="false">2502.07724v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data</title>
      <link>http://arxiv.org/abs/2502.07746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;论文摘要&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为HiPoNet的端到端可微神经网络，适用于高维点云数据上的回归、分类和表示学习。该模型特别针对单细胞数据分析进行了优化。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理具有极高维度的单细胞数据时存在局限性，并且现代实验生成了大量的多患者数据集，这需要能够有效处理大规模高维点云的方法。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术的问题并提供一种有效的解决方案来处理这些复杂的数据集，HiPoNet被开发出来以利用更高的几何信息进行更复杂的表示学习。&lt;h4&gt;方法&lt;/h4&gt;通过可学习的特征重新加权形成高级单纯复形，生成多个数据视图，并采用基于单纯复形的小波变换提取多尺度特性。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，该模型能够保持拓扑信息并超过现有的点云和图形基线，在单细胞数据分析中表现尤为出色。此外，HiPoNet在空间转录组学中的应用也取得了成功。&lt;h4&gt;结论&lt;/h4&gt;HiPoNet为高维数据的分析提供了一种稳健且可扩展的方法，并具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一个端到端可微神经网络——HiPoNet，用于处理高维度点云上的回归、分类和表示学习。对于单细胞数据分析而言，其复杂性和高度的维度超过了现有方法的能力范围。此外，现代单细胞和空间实验现在产生整个队列的数据集（即每个病人的一个），这需要能够以规模方式处理大量高维点云的模型。大多数当前的方法仅构建单一最近邻图，丢失了重要的几何信息。相比之下，HiPoNet通过可学习的特征重新加权生成更高阶单纯复形，从而产生多个数据视图，将不同的生物过程解耦，并使用基于单纯复形的小波变换来提取多尺度特性——捕捉局部和全局拓扑结构。我们实验证明了这些组件在所学表示中保持拓扑信息的能力，并且HiPoNet显著优于单细胞数据集上的最先进点云和图基线模型。我们也展示了HiPoNet在使用空间坐标作为视图之一的空间转录组数据的应用案例。总的来说，HiPoNet为高维数据分析提供了一种稳健、可扩展的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose HiPoNet, an end-to-end differentiable neuralnetwork for regression, classification, and representation learning onhigh-dimensional point clouds. Single-cell data can have high dimensionalityexceeding the capabilities of existing methods point cloud tailored for 3Ddata. Moreover, modern single-cell and spatial experiments now yield entirecohorts of datasets (i.e. one on every patient), necessitating models that canprocess large, high-dimensional point clouds at scale. Most current approachesbuild a single nearest-neighbor graph, discarding important geometricinformation. In contrast, HiPoNet forms higher-order simplicial complexesthrough learnable feature reweighting, generating multiple data views thatdisentangle distinct biological processes. It then employs simplicial wavelettransforms to extract multi-scale features - capturing both local and globaltopology. We empirically show that these components preserve topologicalinformation in the learned representations, and that HiPoNet significantlyoutperforms state-of-the-art point-cloud and graph-based models on single cell.We also show an application of HiPoNet on spatial transcriptomics datasetsusing spatial co-ordinates as one of the views. Overall, HiPoNet offers arobust and scalable solution for high-dimensional data analysis.</description>
      <author>example@mail.com (Siddharth Viswanath, Hiren Madhu, Dhananjay Bhaskar, Jake Kovalic, Dave Johnson, Rex Ying, Christopher Tape, Ian Adelstein, Michael Perlmutter, Smita Krishnaswamy)</author>
      <guid isPermaLink="false">2502.07746v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata</title>
      <link>http://arxiv.org/abs/2502.07461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要介绍&lt;/h4&gt;JamendoMaxCaps是一个大型音乐字幕数据集，包含超过20万首来自知名平台Jamendo的免费许可乐器曲目。&lt;h4&gt;数据集特点&lt;/h4&gt;该数据集包括由最先进的字幕生成模型创建并增强有推断元数据的字幕。&lt;h4&gt;检索系统&lt;/h4&gt;介绍了一种检索系统，利用音乐特征和元数据来识别相似歌曲，并使用本地大型语言模型填补缺失元数据。&lt;h4&gt;目标受众&lt;/h4&gt;此方法为从事音乐-语言理解任务的研究人员提供了一个更全面和信息丰富的数据集。&lt;h4&gt;验证方式&lt;/h4&gt;通过五种不同的度量标准进行定量验证。&lt;h4&gt;公开资源&lt;/h4&gt;将JamendoMaxCaps数据集公开发布，以便于推进包括音乐检索、多模态表示学习以及生成式音乐模型在内的音乐-语言理解任务研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce JamendoMaxCaps, a large-scale music-caption dataset featuringover 200,000 freely licensed instrumental tracks from the renowned Jamendoplatform. The dataset includes captions generated by a state-of-the-artcaptioning model, enhanced with imputed metadata. We also introduce a retrievalsystem that leverages both musical features and metadata to identify similarsongs, which are then used to fill in missing metadata using a local largelanguage model (LLLM). This approach allows us to provide a more comprehensiveand informative dataset for researchers working on music-language understandingtasks. We validate this approach quantitatively with five differentmeasurements. By making the JamendoMaxCaps dataset publicly available, weprovide a high-quality resource to advance research in music-languageunderstanding tasks such as music retrieval, multimodal representationlearning, and generative music models.</description>
      <author>example@mail.com (Abhinaba Roy, Renhang Liu, Tongyu Lu, Dorien Herremans)</author>
      <guid isPermaLink="false">2502.07461v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</title>
      <link>http://arxiv.org/abs/2502.07783v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的模型微调技术，称为曲率调整（CT），这种方法基于最近发展的样条算子理论框架。通过单个参数调节模型决策边界的曲率，使得无需训练即可进行模型引导。&lt;h4&gt;背景&lt;/h4&gt;随着大规模模型和数据集的发展，微调成为了利用最新模型的主要方法之一。然而，现有的微调方法如全量或低秩适配器存在大量超参数且缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于样条算子理论的新颖、可解释的微调后处理解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了名为曲率调整（Curvature Tuning, CT）的技术，该技术通过单个参数调节模型决策边界的曲率来实现无训练引导。这种方法相比传统的微调更加高效且具有更好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了CT在提高预训练模型泛化能力和鲁棒性方面的有效性。例如，在十七个下游数据集上，CT使ResNet-18/50的分布外传输性能分别提高了2.57%/1.74%，并在RobustBench上提升了11.76%/348.44%的鲁棒准确性。&lt;h4&gt;结论&lt;/h4&gt;曲率调整（CT）是一种新颖且有效的模型微调方法，能够通过单个参数调节来改善预训练模型在多个任务上的性能，并展示了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;随着模型和数据规模的增长，AI范式已经改变。作为结果，利用最新模型的通用协议是通过微调将其导向特定下游任务。尽管这种方法的重要性，但主要的微调方法仍然局限于全量或低秩适配器——包含无数超参数且缺乏可解释性。本文回顾了从深网络的一个丰富数学框架样条算子理论中推导出新颖和可解释的后训练引导解决方案的可能性。我们的方法——被命名为曲率调整（CT）——具有一个可以证明调节模型决策边界曲率的单一参数，从而可以在无需训练的情况下进行引导。这使得CT比传统的微调方法更加高效且更具可解释性。我们在改善预训练模型的泛化能力和鲁棒性的有效性方面进行了实证验证。例如，在十七个下游数据集上，CT提高了ResNet-18/50分布外传输性能2.57%/1.74%，并且在RobustBench上的鲁棒准确性提升了11.76%/348.44%。此外，我们将CT应用于基于ReLU的Swin-T/S，在九个下游数据集上提高了泛化能力2.43%/3.33%。我们的代码可在https://github.com/Leon-Leyang/curvature-tuning获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scaling of model size and data size has reshaped the paradigm of AI. As aresult, the common protocol to leverage the latest models is to steer themtowards a specific downstream task of interest through {\em fine-tuning}.Despite its importance, the main methods for fine-tuning remain limited to fullor low-rank adapters--containing countless hyper-parameters and lackinginterpretability. In this paper, we take a step back and demonstrate how noveland explainable post-training steering solutions can be derived theoreticallyfrom {\em spline operators}, a rich mathematical framing of Deep Networks thatwas recently developed. Our method--coined \textbf{Curvature Tuning (CT)}--hasa single parameter that provably modulates the curvature of the model'sdecision boundary henceforth allowing training-free steering. This makes CTboth more efficient and interpretable than conventional fine-tuning methods. Weempirically validate its effectiveness in improving generalization androbustness of pretrained models. For example, CT improves out-of-distributiontransfer performances of ResNet-18/50 by 2.57\%/1.74\% across seventeendownstream datasets, and improves RobustBench robust accuracy by11.76\%/348.44\%. Additionally, we apply CT to ReLU-based Swin-T/S, improvingtheir generalization on nine downstream datasets by 2.43\%/3.33\%. Our code isavailable at\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.</description>
      <author>example@mail.com (Leyang Hu, Randall Balestriero)</author>
      <guid isPermaLink="false">2502.07783v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Effects of Random Edge-Dropping on Over-Squashing in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.07364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 7 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了消息传递神经网络（MPNN）在图神经网络中的挑战，特别是过度平滑和过度压缩问题，并分析了几种用于解决过度平滑问题的算法对过度压缩的影响。&lt;h4&gt;背景&lt;/h4&gt;Message Passing Neural Networks (MPNNs) 利用图拓扑结构在网络中传播信息。然而，这种消息传递机制导致了过度平滑和过度压缩两个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;研究针对过度平滑设计的各种算法（如DropEdge及其变体）在解决过度压缩问题方面的效果，填补文献中的这一空白。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和实验评估来探讨这些算法如何影响过度压缩，并使用真实数据集进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;DropEdge和其他类似技术虽然可以改善短距离任务的性能，但在长距离任务中会导致模型过拟合训练集中短距离特征，从而损害了泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文强调需要重新评估用于深度GNN训练的各种方法，并重视建模长程相互作用的重要性。&lt;h4&gt;翻译&lt;/h4&gt;消息传递神经网络（MPNNs）是一种图神经网络类算法，它们利用图的拓扑结构在网络中传播信息。这种消息传递机制引发了过度平滑和过度压缩两个主要挑战。尽管有一些算法如DropEdge及其变体在解决过度平滑问题上取得了成功，但它们对过度压缩的影响尚未被充分研究。这是一个重要的文献空白，因为无法缓解过度压缩会使这些方法不适合长距离任务。在这项工作中，我们首次尝试通过研究上述算法在过度压缩背景下的表现来填补这一空白，并提出了一种新的理论结果，该结果显示DropEdge会降低图神经网络的有效感受野，从而对远距离节点间的敏感度产生负面影响，这表明它不适用于长程任务。我们的发现可以很容易地扩展到其变体中，使我们能够全面理解它们如何影响过度压缩。我们在真实世界数据集上评估了这些方法，并展示了它们的负面效果：虽然DropEdge变种在短距离任务中的测试性能得到改善，但在长距离任务中则表现不佳。我们的理论解释说，随机边缘删除降低了GNN的有效感受野，这虽然是有益于短程任务的优点，但使模型与远程任务不一致，迫使模型过度拟合训练集中的短程特征，从而导致泛化能力差。我们的结论强调了重新评估用于深度图神经网络训练的各种方法的必要性，并着重关注建模长距离相互作用的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Message Passing Neural Networks (MPNNs) are a class of Graph Neural Networks(GNNs) that leverage the graph topology to propagate messages acrossincreasingly larger neighborhoods. The message-passing scheme leads to twodistinct challenges: over-smoothing and over-squashing. While severalalgorithms, e.g. DropEdge and its variants -- DropNode, DropAgg and DropGNN --have successfully addressed the over-smoothing problem, their impact onover-squashing remains largely unexplored. This represents a critical gap inthe literature as failure to mitigate over-squashing would make these methodsunsuitable for long-range tasks. In this work, we take the first step towardsclosing this gap by studying the aforementioned algorithms in the context ofover-squashing. We present novel theoretical results that characterize thenegative effects of DropEdge on sensitivity between distant nodes, suggestingits unsuitability for long-range tasks. Our findings are easily extended to itsvariants, allowing us to build a comprehensive understanding of how they affectover-squashing. We evaluate these methods using real-world datasets,demonstrating their detrimental effects. Specifically, we show that whileDropEdge-variants improve test-time performance in short range tasks, theydeteriorate performance in long-range ones. Our theory explains these resultsas follows: random edge-dropping lowers the effective receptive field of GNNs,which although beneficial for short-range tasks, misaligns the models onlong-range ones. This forces the models to overfit to short-range artefacts inthe training set, resulting in poor generalization. Our conclusions highlightthe need to re-evaluate various methods designed for training deep GNNs, with arenewed focus on modelling long-range interactions.</description>
      <author>example@mail.com (Jasraj Singh, Keyue Jiang, Brooks Paige, Laura Toni)</author>
      <guid isPermaLink="false">2502.07364v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.07645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的交互式模仿学习框架，将行为克隆扩展为一个迭代过程，以估计和优化最优动作集，并通过人类纠正提供理论保证。&lt;h4&gt;背景&lt;/h4&gt;传统的行为克隆方法依赖于演示数据，假设展示的动作是最优的。然而，在存在噪声的数据情况下，这可能导致过度拟合问题，特别是在使用表达能力强的模型（如基于能量的模型）时。&lt;h4&gt;目的&lt;/h4&gt;解决行为克隆在面对噪声数据和多样反馈类型时的问题，并提出一种新的交互式模仿学习方法来优化动作选择策略。&lt;h4&gt;方法&lt;/h4&gt;引入对比政策学习从互动校正中受益的方法（CLIC），它使用人类纠正来估计一组期望的动作并优化策略以从该集合中选择动作。&lt;h4&gt;主要发现&lt;/h4&gt;CLIC在模拟和真实机器人实验中优于现有的最先进方法，展示了稳定的基于能量模型的训练、对反馈噪声的鲁棒性以及适应多种反馈类型的能力。&lt;h4&gt;结论&lt;/h4&gt;通过互动校正来估计最优动作集并优化策略能够有效地解决行为克隆中的过度拟合问题，并且具有良好的泛化能力和稳健性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavior cloning (BC) traditionally relies on demonstration data, assumingthe demonstrated actions are optimal. This can lead to overfitting under noisydata, particularly when expressive models are used (e.g., the energy-basedmodel in Implicit BC). To address this, we extend behavior cloning into aniterative process of optimal action estimation within the Interactive ImitationLearning framework. Specifically, we introduce Contrastive policy Learning fromInteractive Corrections (CLIC). CLIC leverages human corrections to estimate aset of desired actions and optimizes the policy to select actions from thisset. We provide theoretical guarantees for the convergence of the desiredaction set to optimal actions in both single and multiple optimal action cases.Extensive simulation and real-robot experiments validate CLIC's advantages overexisting state-of-the-art methods, including stable training of energy-basedmodels, robustness to feedback noise, and adaptability to diverse feedbacktypes beyond demonstrations. Our code will be publicly available soon.</description>
      <author>example@mail.com (Zhaoting Li, Rodrigo Pérez-Dattari, Robert Babuska, Cosimo Della Santina, Jens Kober)</author>
      <guid isPermaLink="false">2502.07645v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GaRLIO: Gravity enhanced Radar-LiDAR-Inertial Odometry</title>
      <link>http://arxiv.org/abs/2502.07703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GaRLIO是一种结合雷达和LiDAR惯性里程计的改进方法，利用雷达直接测速数据来提高重力估计准确性，并减少垂直漂移。&lt;h4&gt;背景&lt;/h4&gt;目前在线重力估计主要依赖于姿态估计与IMU测量，而未充分利用提供直接速度信息的雷达传感器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法GaRLIO以利用雷达提供的直接速度测量数据，改进现有的重力估计和状态估计技术。&lt;h4&gt;方法&lt;/h4&gt;通过融合雷达点云的速度信息预测重力，并同时在动态环境中移除动态对象来增强鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在多种容易出现垂直漂移的环境下，GaRLIO的表现优于传统LiDAR-Inertial Odometry（LIO）方法。&lt;h4&gt;结论&lt;/h4&gt;通过利用雷达传感器直接测速数据改进了重力估计准确性，并提高了状态估计性能。该方法已经在公开源代码中提供以促进进一步研究和发展。&lt;h4&gt;翻译&lt;/h4&gt;最近，重力被强调为缓解潜在垂直漂移的状态估计中的关键约束条件。现有的在线重力估计技术主要依赖于姿态估计结合IMU测量数据，在没有直接速度测量的情况下被视为最佳实践。然而，利用雷达传感器提供的直接速度信息进行重力估算的潜力尚未得到充分利用，这为我们提供了提高重力估算准确性的重大机会。GaRLIO（基于增强雷达-激光雷达惯性里程计的重力改进）能够稳健地预测重力以减少垂直漂移，并通过使用点对点的速度测量数据来提升状态估计性能。此外，该方法在动态环境中确保了鲁棒性，利用雷达去除LiDAR点云中的动态物体。我们的方法已在各种易发生垂直漂移的环境下通过实验验证，结果显示优于传统LiDAR-Inertial Odometry（LIO）技术的表现。我们公开发布了源代码以鼓励进一步的研究和开发。（https://github.com/ChiyunNoh/GaRLIO）&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, gravity has been highlighted as a crucial constraint for stateestimation to alleviate potential vertical drift. Existing online gravityestimation methods rely on pose estimation combined with IMU measurements,which is considered best practice when direct velocity measurements areunavailable. However, with radar sensors providing direct velocity data-ameasurement not yet utilized for gravity estimation-we found a significantopportunity to improve gravity estimation accuracy substantially. GaRLIO, theproposed gravity-enhanced Radar-LiDAR-Inertial Odometry, can robustly predictgravity to reduce vertical drift while simultaneously enhancing stateestimation performance using pointwise velocity measurements. Furthermore,GaRLIO ensures robustness in dynamic environments by utilizing radar to removedynamic objects from LiDAR point clouds. Our method is validated throughexperiments in various environments prone to vertical drift, demonstratingsuperior performance compared to traditional LiDAR-Inertial Odometry methods.We make our source code publicly available to encourage further research anddevelopment. https://github.com/ChiyunNoh/GaRLIO</description>
      <author>example@mail.com (Chiyun Noh, Wooseong Yang, Minwoo Jung, Sangwoo Jung, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.07703v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Instance-dependent Early Stopping</title>
      <link>http://arxiv.org/abs/2502.07547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025 (Spotlight)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;在机器学习实践中，提前停止技术已被广泛用于正则化模型，并且通过在验证集上的性能不再提升时终止训练过程来节省计算成本。然而，传统的提前停止方法对所有样本采用相同的停止标准，没有考虑它们各自的训练状态，导致那些已经学得很好的样本进行冗余的计算。为了进一步提高效率，我们提出了一种基于实例的提前停止（IES）方法，该方法将提前停止机制从整个训练集调整为实例级别，并且根据核心原则，在模型掌握一个实例后应立即停止对该实例的训练。IES认为如果某个实例损失值的二阶差值在零附近保持在一个很小的范围内，则这个实例就被视为已经掌握了。这提供了一种比直接使用损失值更一致的方式来衡量一个实例的学习状态，因此允许设置统一的标准来确定何时可以将某个实例排除出后续的反向传播过程。我们还表明，从反向传播中移除已掌握的样本可以增加梯度幅度，从而加速训练损失下降的速度，并加快整个训练进程。大量的基准实验显示IES方法能够减少10%-50%的反向传播实例数量，同时保持或略微提高模型在测试集上的准确率和迁移学习性能。&lt;h4&gt;背景&lt;/h4&gt;传统提前停止技术存在对所有样本采用相同标准的问题，可能导致已学得较好的样本进行不必要的计算。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于实例的提前停止（IES）方法以提高机器学习训练效率。&lt;h4&gt;方法&lt;/h4&gt;将提前停止机制从整个训练集调整到每个具体实例上。使用损失值的二阶差值得出是否已经掌握一个特定实例的标准，并在此基础上决定何时排除这个实例，从而加快模型训练速度。&lt;h4&gt;主要发现&lt;/h4&gt;IES能够通过减少不必要的反向传播过程提高计算效率并保持或改善测试准确率及迁移学习性能。&lt;h4&gt;结论&lt;/h4&gt;基于实例的提前停止技术（IES）在不牺牲精度的情况下显著提高了机器学习算法的训练效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In machine learning practice, early stopping has been widely used toregularize models and can save computational costs by halting the trainingprocess when the model's performance on a validation set stops improving.However, conventional early stopping applies the same stopping criterion to allinstances without considering their individual learning statuses, which leadsto redundant computations on instances that are already well-learned. Tofurther improve the efficiency, we propose an Instance-dependent Early Stopping(IES) method that adapts the early stopping mechanism from the entire trainingset to the instance level, based on the core principle that once the model hasmastered an instance, the training on it should stop. IES considers an instanceas mastered if the second-order differences of its loss value remain within asmall range around zero. This offers a more consistent measure of an instance'slearning status compared with directly using the loss value, and thus allowsfor a unified threshold to determine when an instance can be excluded fromfurther backpropagation. We show that excluding mastered instances frombackpropagation can increase the gradient norms, thereby accelerating thedecrease of the training loss and speeding up the training process. Extensiveexperiments on benchmarks demonstrate that IES method can reducebackpropagation instances by 10%-50% while maintaining or even slightlyimproving the test accuracy and transfer learning performance of a model.</description>
      <author>example@mail.com (Suqin Yuan, Runqi Lin, Lei Feng, Bo Han, Tongliang Liu)</author>
      <guid isPermaLink="false">2502.07547v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer</title>
      <link>http://arxiv.org/abs/2502.07158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了PedCA-FT框架，该框架结合了EHR的表格视图和衍生文本视图来预测儿童心脏骤停。&lt;h4&gt;背景&lt;/h4&gt;早期识别儿科心脏骤停对于高风险重症监护环境中的及时干预至关重要。&lt;h4&gt;目的&lt;/h4&gt;利用融合多模态数据的方法提高早期检测心脏骤停的能力并改善患者护理。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于Transformer的框架PedCA-FT，该框架分别使用专用模块处理EHR的表格和文本视图，并捕捉复杂的时间序列模式。&lt;h4&gt;主要发现&lt;/h4&gt;在CHOA-CICU数据库中选取的研究队列上进行了评估，结果显示模型性能优于其他十个人工智能模型，同时识别出有意义的风险因素。&lt;h4&gt;结论&lt;/h4&gt;多模态融合技术在提高早期心脏骤停检测的准确性方面具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：儿童期心脏骤停（CA）的早期预测对于重症监护环境中高风险患者及时干预至关重要。我们提出了一种基于Transformer的新框架PedCA-FT，该框架结合了EHR表格视图与衍生文本视图，全面释放出高维风险因素及其动态变化之间的相互作用。通过为每种模态视图应用专用的Transformer模块，PedCA-FT捕捉复杂的时间序列和上下文模式，从而产生稳健的心脏骤停风险评估。在CHOA-CICU数据库中的一个儿科队列上进行评估，我们的方法在五个关键性能指标中优于其他十个人工智能模型，并识别出具有临床意义的风险因素。这些发现强调了多模态融合技术增强早期心脏骤停检测的潜力以及改善患者护理的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early prediction of pediatric cardiac arrest (CA) is critical for timelyintervention in high-risk intensive care settings. We introduce PedCA-FT, anovel transformer-based framework that fuses tabular view of EHR with thederived textual view of EHR to fully unleash the interactions ofhigh-dimensional risk factors and their dynamics. By employing dedicatedtransformer modules for each modality view, PedCA-FT captures complex temporaland contextual patterns to produce robust CA risk estimates. Evaluated on acurated pediatric cohort from the CHOA-CICU database, our approach outperformsten other artificial intelligence models across five key performance metricsand identifies clinically meaningful risk factors. These findings underscorethe potential of multimodal fusion techniques to enhance early CA detection andimprove patient care.</description>
      <author>example@mail.com (Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu)</author>
      <guid isPermaLink="false">2502.07158v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Music for All: Exploring Multicultural Representations in Music Generation Models (Camera Ready)</title>
      <link>http://arxiv.org/abs/2502.07328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, accepted to NAACL'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文研究了音乐生成领域的数据集和文献，量化了不同音乐流派的偏差与代表性不足问题，并探讨了解决这一问题的方法。&lt;h4&gt;背景&lt;/h4&gt;音乐语言模型在自动音乐生成方面取得了显著进展，但它们对于世界各种音乐类型和文化的覆盖范围有限。&lt;h4&gt;目的&lt;/h4&gt;研究现有的音乐数据集和相关论文，评估这些模型在不同音乐流派上的性能偏差，并探索减轻这种偏差的技术方法。&lt;h4&gt;方法&lt;/h4&gt;分析现有音乐数据集中非西方音乐的占比；应用参数高效微调（PEFT）技术测试两个流行模型（MusicGen和Mustang）对于两种代表性不足的非西方音乐传统（印度斯坦古典音乐与土耳其马卡姆音乐）的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;现有的音乐数据集中，只有5.7%的时间属于非西方音乐；通过小规模数据集在不同流派之间进行微调以提高模型性能存在一定的挑战和潜力。&lt;h4&gt;结论&lt;/h4&gt;需要设计更加公平的基础音乐语言模型，这些模型更适合跨文化的转移学习。&lt;h4&gt;翻译&lt;/h4&gt;音乐语言模型的出现极大地提升了AI系统自动创作音乐的能力，但它们对世界各种音乐类型和文化的覆盖仍然有限。我们研究了用于音乐生成的数据集和相关文献，并量化了其中不同流派的偏见与代表性不足问题。研究表明，现有的音乐数据集中只有5.7%的时间属于非西方音乐，这导致模型在处理不同音乐风格时的表现差距显著。接着，我们考察了参数高效微调（PEFT）技术减轻此类偏差的可能性，通过两种流行模型（MusicGen和Mustang）对两个代表性不足的非西方音乐传统——印度斯坦古典音乐与土耳其马卡姆音乐进行实验，证明了解决跨流派适应问题的小规模数据集的有效性及其挑战。这表明需要设计更加公平的基础音乐语言模型，这些模型更适合跨文化的转移学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Music-Language Models has greatly enhanced the automatic musicgeneration capability of AI systems, but they are also limited in theircoverage of the musical genres and cultures of the world. We present a study ofthe datasets and research papers for music generation and quantify the bias andunder-representation of genres. We find that only 5.7% of the total hours ofexisting music datasets come from non-Western genres, which naturally leads todisparate performance of the models across genres. We then investigate theefficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigatingthis bias. Our experiments with two popular models -- MusicGen and Mustango,for two underrepresented non-Western music traditions -- Hindustani Classicaland Turkish Makam music, highlight the promises as well as the non-trivialityof cross-genre adaptation of music through small datasets, implying the needfor more equitable baseline music-language models that are designed forcross-cultural transfer learning.</description>
      <author>example@mail.com (Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury)</author>
      <guid isPermaLink="false">2502.07328v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Mesh2SSM++: A Probabilistic Framework for Unsupervised Learning of Statistical Shape Model of Anatomies from Surface Meshes</title>
      <link>http://arxiv.org/abs/2502.07145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本论文提出了一种新的统计形状建模（SSM）方法Mesh2SSM++，用于改进解剖评估。&lt;h4&gt;背景&lt;/h4&gt;统计形状模型在解剖学评价中至关重要，它们从MRI和CT扫描中提取定量形态描述符，全面地描述了一个群体中的解剖变异。然而，这些模型的有效性依赖于高质量且鲁棒的形状模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需监督的方法来估计对应关系，并通过无偏的概率模板学习方式改进现有的SSM方法。&lt;h4&gt;方法&lt;/h4&gt;Mesh2SSM++能够从网格中直接学习对齐关系，从而不需要预设的形状模型。它采用概率形式化并量化不确定性以提高决策可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示Mesh2SSM++在各种解剖结构、评估指标和下游任务上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Mesh2SSM++通过其计算效率和解释性提供了传统及基于深度学习的SSM方法的一个有吸引力的选择，特别是在具有挑战性的成像条件下表现更佳。&lt;h4&gt;翻译&lt;/h4&gt;解剖学评价对于理解生理状态、诊断异常以及指导医疗干预至关重要。统计形状模型（SSM）在此过程中起着关键作用，通过从MRI和CT扫描中提取定量形态描述符来提供一个群体中的解剖变异的全面描述。然而，SSM的有效性依赖于高质量且鲁棒的形状模型，而现有方法在这一方面仍存在限制，并往往需要预设的形状模型进行训练。为了克服这些挑战，我们提出了一种新的方法Mesh2SSM++，它能够以无监督方式学习从网格中估计对应关系的方式。该方法利用无偏、排列不变性表示学习来推断如何将一个模板点云变形为受试者的特定网格，形成基于对应的形状模型。此外，其概率形式化允许学习出适应于不同群体的模板，减少与模板选择相关的潜在偏差。Mesh2SSM++的一个关键特征是能够量化固有的数据变异性（即不确定性），这对于确保可靠的模型预测和在临床任务中的稳健决策至关重要，特别是在具有挑战性的成像条件下。通过在各种解剖结构、评估指标及下游任务上的广泛验证，我们证明了Mesh2SSM++优于现有方法。该方法由于其直接处理网格的能力，以及概率框架提供的计算效率与可解释性，在传统的和基于深度学习的SSM方法中具有竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anatomy evaluation is crucial for understanding the physiological state,diagnosing abnormalities, and guiding medical interventions. Statistical shapemodeling (SSM) is vital in this process. By enabling the extraction ofquantitative morphological shape descriptors from MRI and CT scans, SSMprovides comprehensive descriptions of anatomical variations within apopulation. However, the effectiveness of SSM in anatomy evaluation hinges onthe quality and robustness of the shape models. While deep learning techniquesshow promise in addressing these challenges by learning complex nonlinearrepresentations of shapes, existing models still have limitations and oftenrequire pre-established shape models for training. To overcome these issues, wepropose Mesh2SSM++, a novel approach that learns to estimate correspondencesfrom meshes in an unsupervised manner. This method leverages unsupervised,permutation-invariant representation learning to estimate how to deform atemplate point cloud into subject-specific meshes, forming acorrespondence-based shape model. Additionally, our probabilistic formulationallows learning a population-specific template, reducing potential biasesassociated with template selection. A key feature of Mesh2SSM++ is its abilityto quantify aleatoric uncertainty, which captures inherent data variability andis essential for ensuring reliable model predictions and robust decision-makingin clinical tasks, especially under challenging imaging conditions. Throughextensive validation across diverse anatomies, evaluation metrics, anddownstream tasks, we demonstrate that Mesh2SSM++ outperforms existing methods.Its ability to operate directly on meshes, combined with computationalefficiency and interpretability through its probabilistic framework, makes itan attractive alternative to traditional and deep learning-based SSMapproaches.</description>
      <author>example@mail.com (Krithika Iyer, Mokshagna Sai Teja Karanam, Shireen Elhabian)</author>
      <guid isPermaLink="false">2502.07145v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative Distribution Prediction: A Unified Approach to Multimodal Learning</title>
      <link>http://arxiv.org/abs/2502.07090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了Generative Distribution Prediction (GDP)框架，该框架利用多模态合成数据生成技术来提高预测性能。&lt;h4&gt;背景&lt;/h4&gt;在处理包含表格、文本和视觉输入或输出的多元异构数据类型时，传统的预测方法往往难以保持高精度。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够集成不同类型的多模态数据，并通过增强合成数据生成能力来提升预测准确性的框架。&lt;h4&gt;方法&lt;/h4&gt;利用条件扩散模型作为生成技术的核心，GDP是一种与任何高质量生成模型兼容的框架，支持迁移学习以适应不同的领域需求。该研究还为GDP提供了统计保证的基础理论。&lt;h4&gt;主要发现&lt;/h4&gt;通过估计数据生成分布并针对多种损失函数进行风险最小化调整，GDP能够实现跨多模态环境下的准确点预测。&lt;h4&gt;结论&lt;/h4&gt;实验验证表明，GDP在表格数据预测、问答系统、图像描述和自适应分位数回归等四个监督学习任务上表现出色，展示了其在不同领域的通用性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;精确的多模式数据（包括表格数据、文本和视觉输入或输出）预测对于推动各种应用领域中的数据分析至关重要。传统的预测方法往往难以同时处理不同的数据类型，并保持高准确性。我们提出了生成分布预测（GDP），这是一个新颖框架，它利用条件扩散模型等多模式合成数据生成技术来增强结构化和非结构化模态下的预测性能。GDP是模型无关的，可以与任何高质量生成模型配合使用，并支持领域适应性迁移学习。我们为GDP建立了严格的理论基础，提供了当使用扩散模型作为核心生成器时，其准确性的统计保证。通过估计数据生成分布并根据不同的风险最小化损失函数进行调整，GDP能够在多模态设置中实现精确的点预测。我们在表格数据预测、问答系统、图像描述和自适应分位数回归等四个监督学习任务上验证了GDP的表现，显示了它在不同领域的通用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction with multimodal data-encompassing tabular, textual, andvisual inputs or outputs-is fundamental to advancing analytics in diverseapplication domains. Traditional approaches often struggle to integrateheterogeneous data types while maintaining high predictive accuracy. Weintroduce Generative Distribution Prediction (GDP), a novel framework thatleverages multimodal synthetic data generation-such as conditional diffusionmodels-to enhance predictive performance across structured and unstructuredmodalities. GDP is model-agnostic, compatible with any high-fidelity generativemodel, and supports transfer learning for domain adaptation. We establish arigorous theoretical foundation for GDP, providing statistical guarantees onits predictive accuracy when using diffusion models as the generative backbone.By estimating the data-generating distribution and adapting to various lossfunctions for risk minimization, GDP enables accurate point predictions acrossmultimodal settings. We empirically validate GDP on four supervised learningtasks-tabular data prediction, question answering, image captioning, andadaptive quantile regression-demonstrating its versatility and effectivenessacross diverse domains.</description>
      <author>example@mail.com (Xinyu Tian, Xiaotong Shen)</author>
      <guid isPermaLink="false">2502.07090v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Magic 1-For-1: Generating One Minute Video Clips within One Minute</title>
      <link>http://arxiv.org/abs/2502.07701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Magic 1-For-1 (Magic141) 是一种高效的视频生成模型，通过优化内存消耗和推理延迟来提高效率。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到视频生成任务在训练和推断过程中存在计算成本高、收敛速度慢的问题。为解决这些问题，该研究提出了一种新的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种更有效率的视频生成模型，并通过一系列优化技术减少其计算成本和推理延迟。&lt;h4&gt;方法&lt;/h4&gt;{'分解任务': '将文本到视频的任务分解成两个更容易处理的任务：文字到图像生成和图像到视频生成。', '模型收敛加速': '使用多模态先验条件注入来加快模型的收敛速度。', '推断延迟优化': '通过对抗性步骤蒸馏，减少推理延迟。', '内存成本优化': '采用参数稀疏化技术进行推理内存开销的优化。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'任务分解的有效性': '验证了将文本到视频的任务拆分为图像到视频的任务可以更快地收敛。', '计算成本降低': '通过一系列方法成功降低了训练和推断阶段的成本，实现了5秒视频生成在3秒内完成。', '长视频生成优化': '利用测试时间滑动窗口技术，在一分钟内能够生成一分钟时长的高质量视频，平均花费不到一秒的时间来生成每秒钟的视频片段。'}&lt;h4&gt;结论&lt;/h4&gt;Magic 1-For-1 在计算成本和视频质量之间找到了最佳平衡点，为开源探索提供了坚实的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;在这份技术报告中，我们介绍了Magic 1-For-1 (Magic141)，这是一种高效地生成视频的模型，在内存消耗和推理延迟上都有优化。该方法的核心思想很简单：将文本到视频的任务分解成两个单独且更容易处理的任务进行扩散步骤蒸馏，即文字到图像生成和图像到视频生成。我们验证了在相同的优化算法下，图像到视频任务的确比文本到视频任务更易于收敛。此外，还探索了一套优化技巧来降低训练图像到视频(I2V)模型的计算成本，并从三个方面实现了这个目标：1）通过使用多模态先验条件注入加快模型的收敛速度；2）应用对抗性步骤蒸馏减少推理延迟；3）采用参数稀疏化技术进行推理内存开销优化。利用这些技术，我们可以实现在3秒内生成5秒钟的视频片段。通过在测试时间滑动窗口中应用这种方法，我们能够在一分钟内生成一整分钟时长的高质量视频，并且显著提升了视觉质量和运动动态性，在平均意义上花费不到一秒的时间来生成每秒钟的视频片段。我们进行了一系列初步探索以找到扩散步骤蒸馏过程中计算成本和视频质量之间的最佳折衷点，希望这可以成为一个很好的开源探索基础模型。相关代码与权重可在https://github.com/DA-Group-PKU/Magic-1-For-1 上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this technical report, we present Magic 1-For-1 (Magic141), an efficientvideo generation model with optimized memory consumption and inference latency.The key idea is simple: factorize the text-to-video generation task into twoseparate easier tasks for diffusion step distillation, namely text-to-imagegeneration and image-to-video generation. We verify that with the sameoptimization algorithm, the image-to-video task is indeed easier to convergeover the text-to-video task. We also explore a bag of optimization tricks toreduce the computational cost of training the image-to-video (I2V) models fromthree aspects: 1) model convergence speedup by using a multi-modal priorcondition injection; 2) inference latency speed up by applying an adversarialstep distillation, and 3) inference memory cost optimization with parametersparsification. With those techniques, we are able to generate 5-second videoclips within 3 seconds. By applying a test time sliding window, we are able togenerate a minute-long video within one minute with significantly improvedvisual quality and motion dynamics, spending less than 1 second for generating1 second video clips on average. We conduct a series of preliminaryexplorations to find out the optimal tradeoff between computational cost andvideo quality during diffusion step distillation and hope this could be a goodfoundation model for open-source explorations. The code and the model weightsare available at https://github.com/DA-Group-PKU/Magic-1-For-1.</description>
      <author>example@mail.com (Hongwei Yi, Shitong Shao, Tian Ye, Jiantong Zhao, Qingyu Yin, Michael Lingelbach, Li Yuan, Yonghong Tian, Enze Xie, Daquan Zhou)</author>
      <guid isPermaLink="false">2502.07701v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Continuous Group Convolutions for Local SE(3) Equivariance in 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2502.07505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种高效、连续且局部SE(3)等变的卷积层，用于点云处理。该方法基于通用群卷积和本地参考框架。&lt;h4&gt;背景&lt;/h4&gt;将卷积神经网络的翻译等变性扩展到更大的对称组可以减少样本复杂度并促进更具区分力的特征学习。进一步利用额外的对称性比标准卷积共享更多权重，从而在不增加参数数量的情况下提高网络表达能力。&lt;h4&gt;目的&lt;/h4&gt;为点云处理开发一种计算成本低、连续且局部SE(3)等变的卷积层。&lt;h4&gt;方法&lt;/h4&gt;采用通用群卷积和本地参考框架技术来构建高效的SE(3)等变卷积层，以应对3D数据扩展至SE(3)对称性的6维卷积操作挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该工作提出的方法在多种数据集和任务上（包括对象分类和语义分割）达到了竞争或更好的性能，并且计算开销可以忽略不计。&lt;h4&gt;结论&lt;/h4&gt;所提出的连续、局部SE(3)等变卷积层为处理由多个物体组成的场景提供了有效的解决方案，同时保持了较低的计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extending the translation equivariance property of convolutional neuralnetworks to larger symmetry groups has been shown to reduce sample complexityand enable more discriminative feature learning. Further, exploiting additionalsymmetries facilitates greater weight sharing than standard convolutions,leading to an enhanced network expressivity without an increase in parametercount. However, extending the equivariant properties of a convolution layercomes at a computational cost. In particular, for 3D data, expandingequivariance to the SE(3) group (rotation and translation) results in a 6Dconvolution operation, which is not tractable for larger data samples such as3D scene scans. While efforts have been made to develop efficient SE(3)equivariant networks, existing approaches rely on discretization or onlyintroduce global rotation equivariance. This limits their applicability topoint clouds representing a scene composed of multiple objects. This workpresents an efficient, continuous, and local SE(3) equivariant convolutionlayer for point cloud processing based on general group convolution and localreference frames. Our experiments show that our approach achieves competitiveor superior performance across a range of datasets and tasks, including objectclassification and semantic segmentation, with negligible computationaloverhead.</description>
      <author>example@mail.com (Lisa Weijler, Pedro Hermosilla)</author>
      <guid isPermaLink="false">2502.07505v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks</title>
      <link>http://arxiv.org/abs/2502.07325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文提出了一种基于课程迁移学习的物理信息神经网络（CTL-PINN）用于长时间模拟物理和机械行为。该方法的主要创新在于将长期问题分解为一系列短期子问题，通过课程学习方法结合先前步骤的信息来解决后续的时间域问题，并且引入了转移学习技术以有效利用之前训练的数据。&lt;h4&gt;背景&lt;/h4&gt;标准的物理信息神经网络（PINN）在处理长时间模拟时遇到了局部优化和时间域扩展不准确等问题。基于此，研究者提出了将课程学习和迁移学习相结合的方法来解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的CTL-PINN方法以克服标准PINN模型的问题，并提高长期计算挑战的解决能力。&lt;h4&gt;方法&lt;/h4&gt;1. 将长时间问题分解成短期子问题；2. 初始使用标准PINN处理第一个子问题；3. 在后续时间域问题中应用课程学习方法，整合之前步骤的信息；4. 使用转移学习技术有效利用先前训练数据；5. 综合运用课程学习和迁移学习的优势。&lt;h4&gt;主要发现&lt;/h4&gt;CTL-PINN能有效地解决长时间计算中的局部优化问题，并提高了在非线性波传播、Kirchhoff板动态响应以及三峡水库区域水动力学模型等场景下的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过将课程学习和转移学习相结合，CTL-PINN能够更好地处理长期物理行为的模拟挑战，显示出了优于其他方法的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a Curriculum-Transfer-Learning based physics-informedneural network (CTL-PINN) for long-term simulation of physical and mechanicalbehaviors. The main innovation of CTL-PINN lies in decomposing long-termproblems into a sequence of short-term subproblems. Initially, the standardPINN is employed to solve the first sub-problem. As the simulation progresses,subsequent time-domain problems are addressed using a curriculum learningapproach that integrates information from previous steps. Furthermore, transferlearning techniques are incorporated, allowing the model to effectively utilizeprior training data and solve sequential time domain transfer problems.CTL-PINN combines the strengths of curriculum learning and transfer learning,overcoming the limitations of standard PINNs, such as local optimizationissues, and addressing the inaccuracies over extended time domains encounteredin CL-PINN and the low computational efficiency of TL-PINN. The efficacy androbustness of CTL-PINN are demonstrated through applications to nonlinear wavepropagation, Kirchhoff plate dynamic response, and the hydrodynamic model ofthe Three Gorges Reservoir Area, showcasing its superior capability inaddressing long-term computational challenges.</description>
      <author>example@mail.com (Yuan Guo, Zhuojia Fu, Jian Min, Shiyu Lin, Xiaoting Liu, Youssef F. Rashed, Xiaoying Zhuang)</author>
      <guid isPermaLink="false">2502.07325v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift</title>
      <link>http://arxiv.org/abs/2502.07620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了大规模对比预训练模型在概念漂移环境下的挑战，提出了一种基于因果推理的方法来减轻这种影响。&lt;h4&gt;背景&lt;/h4&gt;随着顶级数据集的推动，大型对比预训练的发展达到了一个转变点。当前，在变化的数据分布下保持和提升模型的预训练能力成为一个显著挑战。&lt;h4&gt;目的&lt;/h4&gt;通过深入分析对比预训练方法在概念漂移环境下的表现，并提出一种新的预训练策略来增强模型应对动态数据的能力。&lt;h4&gt;方法&lt;/h4&gt;利用因果推理构建了结构因果图，系统性地分析了概念漂移对对比预训练的影响。提出了因果干预对比目标，并设计了一种能够适应概念漂移动态数据流的鲁棒对比预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;对比预训练模型受到概念漂移显著影响，导致特征空间出现偏差。所提出的因果介入式对比目标和鲁棒预训练策略能有效减轻这一偏见。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，在不同的下游任务上，该鲁棒对比预训练方法可以有效缓解来自概念漂移数据流的偏见问题。&lt;h4&gt;翻译&lt;/h4&gt;大规模对比预训练模型的发展已经达到了一个转变点。然而在不断变化的数据分布下保持和提升这些模型的能力成为了新的挑战。本文发现对比预训练方法受到不确定变动数据分布的影响，导致特征空间出现偏差。基于因果推理，构造了结构因果图来分析概念漂移对对比预训练系统性影响，并提出了一种新的目标函数——因果干预式对比目标。此外还设计了一个能够适应动态变化的鲁棒预训练方案，在一系列下游任务上的实验表明该方法可以有效减轻来自概念漂移动态数据流的偏见问题。代码可在https://anonymous.4open.science/r/ResilientCL/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of large-scale contrastive pre-training propelled by top-tierdatasets has reached a transition point in the scaling law. Consequently,sustaining and enhancing a model's pre-training capabilities in driftenvironments have surfaced as a notable challenge. In this paper, we initiallyuncover that contrastive pre-training methods are significantly impacted byconcept drift wherein distributions change unpredictably, resulting in notablebiases in the feature space of the pre-trained model. Empowered by causalinference, we construct a structural causal graph to analyze the impact ofconcept drift to contrastive pre-training systemically, and propose the causalinterventional contrastive objective. Upon achieving this, we devise aresilient contrastive pre-training approach to accommodate the data stream ofconcept drift, with simple and scalable implementation. Extensive experimentson various downstream tasks demonstrate our resilient contrastive pre-trainingeffectively mitigates the bias stemming from the concept drift data stream.Codes are available at https://anonymous.4open.science/r/ResilientCL/.</description>
      <author>example@mail.com (Xiaoyu Yang, Jie Lu, En Yu)</author>
      <guid isPermaLink="false">2502.07620v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing</title>
      <link>http://arxiv.org/abs/2502.07608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review at CHIL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Time2Lang框架，该框架直接将时间序列基础模型（TFM）的输出映射到大型语言模型（LLMs）表示中，无需中间文本转换。&lt;h4&gt;背景&lt;/h4&gt;在健康应用领域，大型语言模型与行为感应数据结合显示出潜力。然而，传统方法通过将传感器数据转成文本提示存在误差大、计算成本高和需要领域专业知识的问题。特别是在处理长时间序列数据时问题更加突出。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的框架Time2Lang来直接连接TFMs和LLMs，并对其有效性进行了验证。&lt;h4&gt;方法&lt;/h4&gt;该研究首先在合成数据上使用周期性预测作为预训练任务进行训练，然后通过每日抑郁症预测（基于步数）以及个人繁荣度分类（基于对话时长）的纵向可穿戴设备及移动感应数据集进行评估。Time2Lang框架能够在不考虑输入长度的情况下保持几乎恒定的推理时间，并且生成的嵌入保留了诸如自相关的时间序列特征。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了TFMs和LLMs可以被有效集成，同时最小化信息损失并使这些不同建模范式之间的性能转移成为可能。这是首次将TFM与LLM结合用于健康领域的尝试。&lt;h4&gt;结论&lt;/h4&gt;Time2Lang框架成功地解决了传统方法的限制，并为未来的复杂医疗任务研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在结合行为感应数据时对健康应用展现出潜力，但现有技术如文本提示存在显著挑战。本文提出了一种新的直接映射方法（Time2Lang），有效地将时间序列基础模型与大型语言模型相结合，并通过实际案例证明了其有效性及优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) show promise for health applications whencombined with behavioral sensing data. Traditional approaches convert sensordata into text prompts, but this process is prone to errors, computationallyexpensive, and requires domain expertise. These challenges are particularlyacute when processing extended time series data. While time series foundationmodels (TFMs) have recently emerged as powerful tools for learningrepresentations from temporal data, bridging TFMs and LLMs remains challenging.Here, we present Time2Lang, a framework that directly maps TFM outputs to LLMrepresentations without intermediate text conversion. Our approach first trainson synthetic data using periodicity prediction as a pretext task, followed byevaluation on mental health classification tasks. We validate Time2Lang on twolongitudinal wearable and mobile sensing datasets: daily depression predictionusing step count data (17,251 days from 256 participants) and flourishingclassification based on conversation duration (46 participants over 10 weeks).Time2Lang maintains near constant inference times regardless of input length,unlike traditional prompting methods. The generated embeddings preserveessential time-series characteristics such as auto-correlation. Our resultsdemonstrate that TFMs and LLMs can be effectively integrated while minimizinginformation loss and enabling performance transfer across these distinctmodeling paradigms. To our knowledge, we are the first to integrate a TFM andan LLM for health, thus establishing a foundation for future research combininggeneral-purpose large models for complex healthcare tasks.</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell)</author>
      <guid isPermaLink="false">2502.07608v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automated Road Extraction and Centreline Fitting in LiDAR Point Clouds</title>
      <link>http://arxiv.org/abs/2502.07486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures, accepted in DICTA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR数据的从顶部视角提取道路信息的方法，该方法通过减少对特定路缘石设计的依赖来提高不同城市区域的道路提取精度。&lt;h4&gt;背景&lt;/h4&gt;现有的道路信息提取技术主要依赖于局部特征和激光反射角度，这使得它们在面对不同的路缘石设计或高密度地区时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于LiDAR数据的新方法，该方法使用从顶部视角的3D点云来减少对特定路缘石设计的依赖，并提高道路提取的质量。&lt;h4&gt;方法&lt;/h4&gt;首先进行统计异常值去除和基于密度的聚类以降低噪声。接下来使用网格分割法过滤地面点，适应不同的道路场景和地形特性。然后将过滤后的点投影到2D平面上，使用骨架化算法来抽取道路信息。最终的道路中心线通过Savitzky-Golay滤波进行平滑。&lt;h4&gt;主要发现&lt;/h4&gt;提出的初步方法在珀斯CBD数据集上实现了67%的IoU值，而经过后处理优化的方法提高了提取精度至73%，同时减少了23%的计算时间。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种结合3D和2D技术的一般化且计算效率高的解决方案，为未来的道路重建和点云对齐提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;从三维点云中提取道路信息对于城市规划和交通管理非常有用。现有方法往往依赖于局部特征和来自路缘石的激光反射角度，这使得它们在面对不同的路缘石设计或高密度地区时变得敏感且表现不佳。我们提出了一种基于LiDAR数据顶部视角的方法来提取道路点并拟合中心线，这种视角减少了对特定路缘石设计的依赖，并提高了道路提取的效果。首先进行统计异常值去除和基于密度的聚类以降低噪声；接下来使用网格分割法过滤地面点，适应不同的道路场景和地形特性；然后将过滤后的点投影到2D平面上，通过骨架化算法抽取道路信息；最后的道路中心线通过Savitzky-Golay滤波进行平滑。初步方法在珀斯CBD数据集上实现了67%的IoU值，而经过后处理优化的方法提高了提取精度至73%，同时减少了23%的计算时间。该方法提供了一种结合3D和2D技术的一般化且计算效率高的解决方案，为未来的道路重建和点云对齐提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road information extraction from 3D point clouds is useful for urban planningand traffic management. Existing methods often rely on local features and therefraction angle of lasers from kerbs, which makes them sensitive to variablekerb designs and issues in high-density areas due to data homogeneity. Wepropose an approach for extracting road points and fitting centrelines using atop-down view of LiDAR based ground-collected point clouds. This prospectiveview reduces reliance on specific kerb design and results in better roadextraction. We first perform statistical outlier removal and density-basedclustering to reduce noise from 3D point cloud data. Next, we perform groundpoint filtering using a grid-based segmentation method that adapts to diverseroad scenarios and terrain characteristics. The filtered points are thenprojected onto a 2D plane, and the road is extracted by a skeletonisationalgorithm. The skeleton is back-projected onto the 3D point cloud withcalculated normals, which guide a region growing algorithm to find nearby roadpoints. The extracted road points are then smoothed with the Savitzky-Golayfilter to produce the final centreline. Our initial approach withoutpost-processing of road skeleton achieved 67% in IoU by testing on the PerthCBD dataset with different road types. Incorporating the post-processing of theroad skeleton improved the extraction of road points around the smoothedskeleton. The refined approach achieved a higher IoU value of 73% and with 23%reduction in the processing time. Our approach offers a generalised andcomputationally efficient solution that combines 3D and 2D processingtechniques, laying the groundwork for future road reconstruction and 3D-to-2Dpoint cloud alignment.</description>
      <author>example@mail.com (Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Hasnein Tareque, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.07486v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Robust Indoor Localization in Dynamic Environments: A Multi-source Unsupervised Domain Adaptation Framework</title>
      <link>http://arxiv.org/abs/2502.07246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DF-Loc是一种基于多源无监督领域适应（MUDA）的端到端动态指纹定位系统，旨在提高室内环境中的稳健性和适应性。&lt;h4&gt;背景&lt;/h4&gt;传统的指纹定位方法在静态数据上有效，但在数据分布和特征空间不断变化的动态环境中表现不佳。动态环境下的挑战包括数据随时间变化导致的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出DF-Loc以解决动态环境下指纹定位系统的稳健性和适应性问题。&lt;h4&gt;方法&lt;/h4&gt;1. DF-Loc利用多源历史数据进行知识迁移。2. 系统包含一个质量控制模块用于CSI数据预处理，并使用图像处理技术重构CSI指纹特征。3. 设计一个多尺度注意力基网络以提取多层次可转移的指纹特征。4. 采用两阶段对齐模型使多个源-目标领域的分布一致，从而提高目标域中的回归特性。&lt;h4&gt;主要发现&lt;/h4&gt;DF-Loc在办公室和教室环境中进行了广泛的实验，并且相比于比较方法，该系统在定位准确性和鲁棒性方面表现更佳。使用60%参考点进行训练时，在“同测试”场景下，平均定位误差为0.79m和3.72m；而在“不同测试”场景下分别为0.94m和4.39m。&lt;h4&gt;结论&lt;/h4&gt;DF-Loc开创了一种端到端的多源迁移学习方法来处理指纹定位问题，并为动态环境下的未来研究提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fingerprint localization has gained significant attention due to itscost-effective deployment, low complexity, and high efficacy. However,traditional methods, while effective for static data, often struggle in dynamicenvironments where data distributions and feature spaces evolve-a commonoccurrence in real-world scenarios. To address the challenges of robustness andadaptability in fingerprint localization for dynamic indoor environments, thispaper proposes DF-Loc, an end-to-end dynamic fingerprint localization systembased on multi-source unsupervised domain adaptation (MUDA). DF-Loc leverageshistorical data from multiple time scales to facilitate knowledge transfer inspecific feature spaces, thereby enhancing generalization capabilities in thetarget domain and reducing reliance on labeled data. Specifically, the systemincorporates a Quality Control (QC) module for CSI data preprocessing andemploys image processing techniques for CSI fingerprint feature reconstruction.Additionally, a multi-scale attention-based feature fusion backbone network isdesigned to extract multi-level transferable fingerprint features. Finally, adual-stage alignment model aligns the distributions of multiple source-targetdomain pairs, improving regression characteristics in the target domain.Extensive experiments conducted in office and classroom environmentsdemonstrate that DF-Loc outperforms comparative methods in terms of bothlocalization accuracy and robustness. With 60% of reference points used fortraining, DF-Loc achieves average localization errors of 0.79m and 3.72m in"same-test" scenarios, and 0.94m and 4.39m in "different-test" scenarios,respectively. This work pioneers an end-to-end multi-source transfer learningapproach for fingerprint localization, providing valuable insights for futureresearch in dynamic environments.</description>
      <author>example@mail.com (Jiyu Jiao, Xiaojun Wang, Chengpei Han)</author>
      <guid isPermaLink="false">2502.07246v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>O1 Embedder: Let Retrievers Think Before Action</title>
      <link>http://arxiv.org/abs/2502.07555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要描述了大语言模型（LLMs）在信息获取和利用方面的革命性进步，特别是它们在精细数据表示、高质量答案生成以及推理能力方面的优势。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型通过其强大的细粒度数据表示能力和基于外部引用的高质量回答能力改变了人们访问和使用信息的方式。最近推出的推理模型进一步展示了LLMs的逐步思考能力。&lt;h4&gt;目的&lt;/h4&gt;受这一进展启发，研究者希望为检索模型开发类似的渐进思考能力，以解决领域内的重大挑战，包括多任务检索、零样本检索以及需要复杂关系推理的任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为O1 Embedder的新颖方法，该方法在进行文档检索之前，先生成输入查询的有用思想。为了实现这一目标，研究者克服了两项技术难题：设计数据合成工作流程和优化训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，O1 Embedder在广泛的应用场景中表现出了显著的优势，包括跨域任务在内的多项流行数据集中均取得了性能提升。&lt;h4&gt;结论&lt;/h4&gt;该方法为下一代信息检索基础模型的发展铺平了道路，并展示了其卓越的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;随着大型语言模型（LLMs）力量的增长，它们已经革新了人们访问和利用信息的方式。特别是，这些模型在进行精细数据表示方面表现出色，这有助于精确的信息检索，并能生成基于外部参考的高质量答案，从而产生有用的知识。最近引入的推理模型，如OpenAI O1和DeepSeek R1，标志着又一进步，突显了LLMs能够在提供最终答案之前逐步思考的能力。这一突破显著提高了处理复杂任务（例如编码和数学证明）的能力。受到这些进展的启发，我们旨在为检索模型开发类似能力，以应对领域中的关键挑战，包括多任务检索、零样本检索以及需要密集推理的任务。基于此动机，我们提出了一种名为O1 Embedder的新方法，该方法在针对目标文档进行检索之前生成输入查询的有用思想。为了实现这一目标，我们解决了两项技术难题：设计数据合成工作流程和优化训练过程。我们在广泛的实验中评估了我们的方法，并在涵盖领域内和跨域场景中的12个流行数据集中取得了显著改进，这突显了O1 Embedder卓越的准确性和泛化能力，为开发下一代信息检索基础模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing power of large language models (LLMs) has revolutionized howpeople access and utilize information. Notably, the LLMs excel at performingfine-grained data representation, which facilitates precise retrieval ofinformation. They also generate high-quality answers based on externalreferences, enabling the production of useful knowledge. The recentintroduction of reasoning models, like OpenAI O1 and DeepSeek R1, marks anotherleap forward, highlighting LLMs' ability to think progressively beforedelivering final answers. This breakthrough significantly improves the abilityto address complex tasks, e.g., coding and math proofs.  Inspired by this progress, we aim to develop similar capabilities forretrieval models, which hold great promise for tackling critical challenges inthe field, including multi-task retrieval, zero-shot retrieval, and tasksrequiring intensive reasoning of complex relationships. With this motivation,we propose a novel approach called O1 Embedder, which generates useful thoughtsfor the input query before making retrieval for the target documents. Torealize this objective, we conquer two technical difficulties. First, we designa data synthesis workflow, creating training signals for O1 Embedder bygenerating initial thoughts from an LLM-expert and subsequently refining themusing a retrieval committee. Second, we optimize the training process, enablinga pre-trained model to be jointly fine-tuned to generate retrieval thoughts viabehavior cloning and perform dense retrieval through contrastive learning. Ourapproach is evaluated by comprehensive experiments, where substantialimprovements are achieved across 12 popular datasets, spanning both in-domainand out-of-domain scenarios. These results highlight O1 Embedder's remarkableaccuracy and generalizability, paving the way for the development ofnext-generation IR foundation models.</description>
      <author>example@mail.com (Ruin Yan, Zheng Liu, Defu Lian)</author>
      <guid isPermaLink="false">2502.07555v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>From Image to Video: An Empirical Study of Diffusion Representations</title>
      <link>http://arxiv.org/abs/2502.07001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文探讨了扩散模型在视觉理解任务中的潜力，特别是视频扩散模型。&lt;h4&gt;背景&lt;/h4&gt;扩散模型已经在图像和视频合成中取得了革命性的成功，并激发了人们探索其在视觉理解任务中的应用。尽管最近的研究已经研究了图像生成的潜在用途，但视频扩散模型的视觉理解能力尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，作者系统地比较了相同架构下训练用于视频和图像生成的效果，分析它们在下游任务上的性能表现。&lt;h4&gt;方法&lt;/h4&gt;实验中使用相同的模型结构分别进行视频和图像生成的训练，并评估其潜在表示在诸如图像分类、动作识别、深度估计以及跟踪等不同下游任务中的效果。进一步探讨了从不同层次抽取的特征以及噪声水平不同的影响，同时也分析了模型大小及训练预算对表现和生成质量的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明视频扩散模型在多种下游任务上始终优于其图像对应的模型，尽管这种优越性程度在不同任务中有所差异。此外，还发现了提取自不同层次的特征以及噪声水平的变化对于性能有着显著影响。&lt;h4&gt;结论&lt;/h4&gt;这是首次直接比较视频和图像扩散目标用于视觉理解的研究工作，为时间信息在表示学习中的作用提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;扩散模型已经在生成建模领域取得革命性进展，使得图像和视频合成的逼真度达到了前所未有的水平。这一成功引发了人们对利用其表示进行视觉理解和任务的兴趣。尽管最近的工作已经探索了这种潜在应用以实现图像生成，但关于视频扩散模型的视觉理解能力的研究依然非常有限。为了填补这一空白，我们系统地比较了相同架构在训练用于视频和图像生成时的效果，并分析它们在包括图像分类、动作识别、深度估计以及跟踪在内的多种下游任务中的表现。结果显示，在这些任务中，视频扩散模型始终优于其对应的图像模型，尽管这种优越性的程度有所不同。此外，我们也研究了从不同层次抽取的特征以及噪声水平对性能的影响，还探讨了模型大小和训练预算对表示质量和生成质量的作用。这项工作首次直接比较了用于视觉理解的视频和图像扩散目标，为时间信息在表示学习中的作用提供了重要的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have revolutionized generative modeling, enablingunprecedented realism in image and video synthesis. This success has sparkedinterest in leveraging their representations for visual understanding tasks.While recent works have explored this potential for image generation, thevisual understanding capabilities of video diffusion models remain largelyuncharted. To address this gap, we systematically compare the same modelarchitecture trained for video versus image generation, analyzing theperformance of their latent representations on various downstream tasksincluding image classification, action recognition, depth estimation, andtracking. Results show that video diffusion models consistently outperformtheir image counterparts, though we find a striking range in the extent of thissuperiority. We further analyze features extracted from different layers andwith varying noise levels, as well as the effect of model size and trainingbudget on representation and generation quality. This work marks the firstdirect comparison of video and image diffusion objectives for visualunderstanding, offering insights into the role of temporal information inrepresentation learning.</description>
      <author>example@mail.com (Pedro Vélez, Luisa F. Polanía, Yi Yang, Chuhan Zhang, Rishab Kabra, Anurag Arnab, Mehdi S. M. Sajjadi)</author>
      <guid isPermaLink="false">2502.07001v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Neighborhood-Order Learning Graph Attention Network for Fake News Detection</title>
      <link>http://arxiv.org/abs/2502.06927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的模型NOL-GAT，用于检测假新闻。该模型通过学习每个节点的最佳邻域顺序来改进信息提取。&lt;h4&gt;背景&lt;/h4&gt;随着社交媒体和在线通信网络的普及，虚假新闻的识别成为了一个重要挑战。基于图神经网络的方法显示出分析图结构数据的强大潜力。&lt;h4&gt;目的&lt;/h4&gt;解决传统GNN架构在利用多层以外邻居信息时的局限性，提高模型精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的NOL-GAT模型，该模型包括一个Hop Network和一个Embedding Network来确定最佳邻域顺序并更新节点嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，NOL-GAT在多个假新闻数据集上表现优异，并且在标签数据有限的情况下也能显著优于基准模型。&lt;h4&gt;结论&lt;/h4&gt;提出的模型能够缓解过度压扁问题，改善信息流动和减少计算复杂性，显示出了明显的优势。&lt;h4&gt;翻译&lt;/h4&gt;虚假新闻检测是数字时代的一个重大挑战，随着社交媒体和在线通信网络的普及变得越来越重要。基于图神经网络（GNN）的方法在解决这个问题时显示出分析图形结构数据的巨大潜力。然而，传统GNN架构的主要限制在于它们无法有效利用多层外邻居的信息，这会降低模型的准确性和效果。本文提出了一种名为Neighborhood-Order Learning Graph Attention Network (NOL-GAT)的新模型用于虚假新闻检测。该模型允许每层中的每个节点独立学习其最佳邻域顺序。通过这样做，模型可以有针对性且有效地从远距离邻居中提取关键信息。NOL-GAT架构由两个主要部分组成：一个决定最佳邻域顺序的Hop Network和使用这些最优邻域更新节点嵌入的Embedding Network。为了评估该模型的性能，在各种虚假新闻数据集上进行了实验。结果表明，NOL-GAT在准确性、F1分数等指标上显著优于基线模型，特别是在标签数据有限的情况下。其他优势包括缓解过度压扁问题，改进信息流动以及减少计算复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fake news detection is a significant challenge in the digital age, which hasbecome increasingly important with the proliferation of social media and onlinecommunication networks. Graph Neural Networks (GNN)-based methods have shownhigh potential in analyzing graph-structured data for this problem. However, amajor limitation in conventional GNN architectures is their inability toeffectively utilize information from neighbors beyond the network's layerdepth, which can reduce the model's accuracy and effectiveness. In this paper,we propose a novel model called Neighborhood-Order Learning Graph AttentionNetwork (NOL-GAT) for fake news detection. This model allows each node in eachlayer to independently learn its optimal neighborhood order. By doing so, themodel can purposefully and efficiently extract critical information fromdistant neighbors. The NOL-GAT architecture consists of two main components: aHop Network that determines the optimal neighborhood order and an EmbeddingNetwork that updates node embeddings using these optimal neighborhoods. Toevaluate the model's performance, experiments are conducted on various fakenews datasets. Results demonstrate that NOL-GAT significantly outperformsbaseline models in metrics such as accuracy and F1-score, particularly inscenarios with limited labeled data. Features such as mitigating theover-squashing problem, improving information flow, and reducing computationalcomplexity further highlight the advantages of the proposed model.</description>
      <author>example@mail.com (Batool Lakzaei, Mostafa Haghir Chehreghani, Alireza Bagheri)</author>
      <guid isPermaLink="false">2502.06927v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>SEMU: Singular Value Decomposition for Efficient Machine Unlearning</title>
      <link>http://arxiv.org/abs/2502.07587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于奇异值分解的高效机器遗忘（SEMU）方法，以优化模型在特定数据点上的选择性遗忘过程。该方法解决了现有机器遗忘技术中的高计算成本和训练不稳定性问题，并减少了对原始训练数据集的需求。&lt;h4&gt;背景&lt;/h4&gt;生成基础模型的能力近年来迅速提升，但防止有害行为的方法仍不成熟。其中，机器遗忘（MU）成为应对即将到来的安全法规的关键挑战之一。现有的大多数MU方法侧重于改变模型中最显著的参数，但这往往需要大量的模型微调，导致计算成本高和训练不稳定。&lt;h4&gt;目的&lt;/h4&gt;通过利用奇异值分解来创建紧凑、低维投影，从而实现特定数据点的选择性遗忘，同时减少对原始训练数据集的需求。本文旨在优化机器遗忘过程中的效率问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法——基于奇异值分解的高效机器遗忘（SEMU），该方法通过最小化需要修改的模型参数数量来有效移除不需要的知识，并且仅需少量改变权重即可实现特定数据点的选择性遗忘。同时，SEMU消除了对原始训练数据集的需求。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，SEMU在保持性能的同时，在数据使用和被修改参数的数量上显著提高了效率。&lt;h4&gt;结论&lt;/h4&gt;通过引入奇异值分解技术来优化机器遗忘过程，有效地解决了现有方法的局限性，并展示了其实际应用中的优越表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the capabilities of generative foundational models have advancedrapidly in recent years, methods to prevent harmful and unsafe behaviors remainunderdeveloped. Among the pressing challenges in AI safety, machine unlearning(MU) has become increasingly critical to meet upcoming safety regulations. Mostexisting MU approaches focus on altering the most significant parameters of themodel. However, these methods often require fine-tuning substantial portions ofthe model, resulting in high computational costs and training instabilities,which are typically mitigated by access to the original training dataset.  In this work, we address these limitations by leveraging Singular ValueDecomposition (SVD) to create a compact, low-dimensional projection thatenables the selective forgetting of specific data points. We propose SingularValue Decomposition for Efficient Machine Unlearning (SEMU), a novel approachdesigned to optimize MU in two key aspects. First, SEMU minimizes the number ofmodel parameters that need to be modified, effectively removing unwantedknowledge while making only minimal changes to the model's weights. Second,SEMU eliminates the dependency on the original training dataset, preserving themodel's previously acquired knowledge without additional data requirements.  Extensive experiments demonstrate that SEMU achieves competitive performancewhile significantly improving efficiency in terms of both data usage and thenumber of modified parameters.</description>
      <author>example@mail.com (Marcin Sendera, Łukasz Struski, Kamil Książek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk)</author>
      <guid isPermaLink="false">2502.07587v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Extended monocular 3D imaging</title>
      <link>http://arxiv.org/abs/2502.07403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的单目3D成像框架EM3D，利用光的波矢量性质实现高精度和高分辨率的三维点云捕获。&lt;h4&gt;背景&lt;/h4&gt;尽管在3D视觉领域已有许多进展，现有的3D成像硬件依然笨重且复杂，并且图像分辨率远低于2D成像系统。此外，在低纹理、强反射或透明场景中，现有解决方案常常失效。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型单目3D成像框架EM3D，用于捕获高精度和高质量的三维点云，特别是在传统难以处理的情境下。&lt;h4&gt;方法&lt;/h4&gt;通过使用配备有衍射-折射混合镜头的小型单目相机，结合多个阶段的光波衍射与偏振深度线索融合技术，实现了快速且准确地获取百万像素级别的3D图像。&lt;h4&gt;主要发现&lt;/h4&gt;1. 该框架能够在低纹理、强反射或透明物体等传统难以处理的场景中成功捕获高精度和高质量的三维点云；2. 结合了深度信息与偏振信息后，能够解锁新材料识别的独特机会，这将扩展机器智能在目标识别及面部防伪等方面的应用。&lt;h4&gt;结论&lt;/h4&gt;EM3D框架提供了一种高效且简洁的方法，在最小硬件规模下实现高维视觉系统的发展，为单目相机的广泛应用铺平了道路。这种结构开辟了一个全新的路径，以最少的形式因素进行更高维度机器视觉研究。&lt;h4&gt;翻译&lt;/h4&gt;三维视觉对于包括机器智能和精密计量在内的许多应用至关重要。尽管在最近几年取得了很多进展，但大多数3D成像硬件仍然笨重且复杂，并提供了远低于其2D对应物的图像分辨率。此外，现有3D成像解决方案在很多众所周知的情况下经常失败。在这里，我们引入了一个扩展单目3D成像（EM3D）框架，充分利用了光的矢量波性质。通过衍射和偏振深度线索的多阶段融合，使用配备有衍射折射混合镜头的小型单目相机，我们在实验中展示了对包括低纹理、高度反射或接近透明在内的传统挑战性场景中的百万像素级准确3D点云的一次性捕获。此外，我们发现深度信息与偏振信息结合可以解锁独特的材料识别机会，这可能会进一步扩展机器智能在目标识别和面部防伪等应用中。因此，这种简单而强大的架构为最小化尺寸形式的更高维度机器视觉开辟了一条新道路，促进单目相机在更多样化的场景中的部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D vision is of paramount importance for numerous applications ranging frommachine intelligence to precision metrology. Despite much recent progress, themajority of 3D imaging hardware remains bulky and complicated and provides muchlower image resolution compared to their 2D counterparts. Moreover, there aremany well-known scenarios that existing 3D imaging solutions frequently fail.Here, we introduce an extended monocular 3D imaging (EM3D) framework that fullyexploits the vectorial wave nature of light. Via the multi-stage fusion ofdiffraction- and polarization-based depth cues, using a compact monocularcamera equipped with a diffractive-refractive hybrid lens, we experimentallydemonstrate the snapshot acquisition of a million-pixel and accurate 3D pointcloud for extended scenes that are traditionally challenging, including thosewith low texture, being highly reflective, or nearly transparent, without adata prior. Furthermore, we discover that the combination of depth andpolarization information can unlock unique new opportunities in materialidentification, which may further expand machine intelligence for applicationslike target recognition and face anti-spoofing. The straightforward yetpowerful architecture thus opens up a new path for a higher-dimensional machinevision in a minimal form factor, facilitating the deployment of monocularcameras for applications in much more diverse scenarios.</description>
      <author>example@mail.com (Zicheng Shen, Feng Zhao, Yibo Ni, Yuanmu Yang)</author>
      <guid isPermaLink="false">2502.07403v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MGPATH: Vision-Language Model with Multi-Granular Prompt Learning for Few-Shot WSI Classification</title>
      <link>http://arxiv.org/abs/2502.07409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  first version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种基于提示学习的方法，用于通过少量样本进行病理图像分类。&lt;h4&gt;背景&lt;/h4&gt;全切片病理图像分类由于其巨大的图像尺寸和有限的标注标签而面临挑战。现有的模型泛化能力受限。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种适应大规模视觉语言模型的新方法来解决上述问题，并提高病理性分类任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;{'1': '扩展了Prov-GigaPath视觉基础模型，通过加入适配器并利用923K图像-文本对进行对比学习将其转化为一个视觉-语言模型。', '2': '提出了一种多粒度注意力机制，该机制将可学习提示与单个图像补丁和这些补丁组之间的相互作用进行比较，以改进模型识别复杂模式的能力。', '3': '利用基于最优传输的可视化文本距离来提高模型鲁棒性，并减轻数据增强过程中可能出现的扰动影响。'}&lt;h4&gt;主要发现&lt;/h4&gt;该方法在肺、肾和乳腺病理图像模态上的实验验证了其有效性，超越了几种最新的竞争对手，在各种架构（包括CLIP、PLIP以及Prov-GigaPath集成的PLIP）中持续提高了性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入多粒度注意力机制和基于最优传输的视觉文本距离，该模型在病理图像分类任务上表现出色。作者公开了其实现代码和预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;全切片病理图像分类面临挑战的原因是其巨大的图像尺寸和有限的标注标签，这限制了现有模型的泛化能力。本文介绍了一种提示学习方法来适应大规模视觉语言模型，以解决少量样本下的病理性分类问题。通过扩展预先训练在1.3亿个病理图像切片上的Prov-GigaPath视觉基础模型，并引入适配器和基于923K图像-文本对的对比学习，将其转换为一个视觉-语言模型。该方法采用多粒度注意力机制改进了模型捕捉细粒度细节与整体上下文的能力。为了进一步提高准确率，采用了基于最优传输的可视化文本距离来确保模型鲁棒性，并减少数据增强过程中可能出现的扰动影响。实验证明，在肺、肾和乳腺病理图像模态上，该方法超越了几种最新的竞争对手，并在各种架构中持续提高了性能。作者公开了其实现代码和预训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whole slide pathology image classification presents challenges due togigapixel image sizes and limited annotation labels, hindering modelgeneralization. This paper introduces a prompt learning method to adapt largevision-language models for few-shot pathology classification. We first extendthe Prov-GigaPath vision foundation model, pre-trained on 1.3 billion pathologyimage tiles, into a vision-language model by adding adaptors and aligning itwith medical text encoders via contrastive learning on 923K image-text pairs.The model is then used to extract visual features and text embeddings fromfew-shot annotations and fine-tunes with learnable prompt embeddings. Unlikeprior methods that combine prompts with frozen features using prefix embeddingsor self-attention, we propose multi-granular attention that comparesinteractions between learnable prompts with individual image patches and groupsof them. This approach improves the model's ability to capture bothfine-grained details and broader context, enhancing its recognition of complexpatterns across sub-regions. To further improve accuracy, we leverage(unbalanced) optimal transport-based visual-text distance to secure modelrobustness by mitigating perturbations that might occur during the dataaugmentation process. Empirical experiments on lung, kidney, and breastpathology modalities validate the effectiveness of our approach; thereby, wesurpass several of the latest competitors and consistently improve performanceacross diverse architectures, including CLIP, PLIP, and Prov-GigaPathintegrated PLIP. We release our implementations and pre-trained models at thisMGPATH.</description>
      <author>example@mail.com (Anh-Tien Nguyen, Duy Minh Ho Nguyen, Nghiem Tuong Diep, Trung Quoc Nguyen, Nhat Ho, Jacqueline Michelle Metsch, Miriam Cindy Maurer, Daniel Sonntag, Hanibal Bohnenberger, Anne-Christin Hauschild)</author>
      <guid isPermaLink="false">2502.07409v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units</title>
      <link>http://arxiv.org/abs/2502.06921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Graph Neural Networks (GNNs) 在处理网络分析、推荐系统和语音分析等任务时非常重要，部署在边缘设备上可以提高实时性、隐私保护和云独立性。然而，在资源受限的设备上执行 GNN 会导致高延迟和能量开销。&lt;h4&gt;背景&lt;/h4&gt;当前边缘处理器集成了 CPU、GPU 和 NPU，但专为数据并行任务设计的 NPU 难以处理不规则的 GNN 计算。&lt;h4&gt;目的&lt;/h4&gt;引入 GraNNite，这是一种基于商用货架上的 SOTA DNN 加速器的硬件感知框架，旨在优化 GNN 的执行。&lt;h4&gt;方法&lt;/h4&gt;GraNNite 通过三个步骤的方法论来优化：1) 使 NPU 能够执行任务；2) 提高性能；3) 在质量与效率之间进行权衡。每个步骤包含多个子步骤和工具。&lt;h4&gt;主要发现&lt;/h4&gt;在 Intel Core Ultra AI PC 上，GraNNite 达到了 2.6 倍到 7.6 倍的速度提升，并且实现了高达 8.6 倍的能量节省。相对于 CPU 和 GPU 分别达到了 10.8 倍和 6.7 倍的性能提升。&lt;h4&gt;结论&lt;/h4&gt;GraNNite 提供了一种有效的优化框架，可以在资源受限设备上高效执行 GNN 计算，并具有显著的速度和能量效率优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are vital for learning from graph-structureddata, enabling applications in network analysis, recommendation systems, andspeech analytics. Deploying them on edge devices like client PCs and laptopsenhances real-time processing, privacy, and cloud independence. GNNs aidRetrieval-Augmented Generation (RAG) for Large Language Models (LLMs) andenable event-based vision tasks. However, irregular memory access, sparsity,and dynamic structures cause high latency and energy overhead onresource-constrained devices. While modern edge processors integrate CPUs,GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregularGNN computations. We introduce GraNNite, the first hardware-aware frameworkoptimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNNaccelerators via a structured three-step methodology: (1) enabling NPUexecution, (2) optimizing performance, and (3) trading accuracy for efficiencygains. Step 1 employs GraphSplit for workload distribution and StaGr for staticaggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boostsperformance using EffOp for control-heavy tasks and GraSp for sparsityexploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduceredundancy and memory transfers. Step 3 balances quality versus efficiency,where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerateattention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higherperformance than CPUs and GPUs, respectively, across GNN models.</description>
      <author>example@mail.com (Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan)</author>
      <guid isPermaLink="false">2502.06921v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automated Capability Discovery via Model Self-Exploration</title>
      <link>http://arxiv.org/abs/2502.07577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种自动能力发现(ACD)框架，该框架利用一个基础模型作为科学家，系统地提出开放性任务以探测目标模型的能力。&lt;h4&gt;背景&lt;/h4&gt;大语言模型已成为通用助手，在广泛领域表现出不同能力。然而，难以精确描述新模型的全部能力和潜在风险。&lt;h4&gt;目的&lt;/h4&gt;介绍一种能够自动和系统化地发现基础模型意外能力和失败的方法——自动能力发现（ACD）框架。&lt;h4&gt;方法&lt;/h4&gt;结合前沿模型与开放性领域的理念，设计了一个利用一个模型作为科学家来探测另一个模型的能力的系统。&lt;h4&gt;主要发现&lt;/h4&gt;通过跨多个基础模型系列（包括GPT、Claude和Llama等），展示该方法能自动揭示出目标模型数千种能力，超越了任何单个团队的探查范围。并且通过广泛的问卷调查验证了其评分系统的准确性。&lt;h4&gt;结论&lt;/h4&gt;利用大模型创造任务和自我评估的能力，ACD是向可扩展、自动化的人工智能系统评价迈出的重要一步。&lt;h4&gt;翻译&lt;/h4&gt;基础模型已经成为多领域中的通用助手，在大规模网络数据训练下展示了广泛的能力。然而，精确表征任何新模型的全部能力及潜在风险仍然是一个挑战。现有的评估方法通常需要大量的手工劳动，并且为更强大的模型设计新的挑战也越来越困难。我们引入了一个名为自动能力发现(ACD)的框架，该框架利用基础模型作为科学家来系统地提出开放性任务以探测目标模型的能力（可能是自身）。通过结合前沿模型与开放性领域的理念，ACD能自动和系统化地揭示出目标模型意外能力和失败。我们在不同的基础模型系列上展示了这种方法的效果，包括GPT、Claude及Llama等，并发现它可以自动揭示数千种难以由单一团队探查到的能力。此外，我们通过广泛的问卷调查验证了该方法自动化评分的有效性，观察到了机器生成的评价与人工评价之间的高度一致性。利用基础模型创造任务和自我评估的功能，ACD向大规模、自动化的AI系统评价迈进了一大步。所有代码和评测日志开源于https://github.com/conglu1997/ACD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have become general-purpose assistants, exhibiting diversecapabilities across numerous domains through training on web-scale data. Itremains challenging to precisely characterize even a fraction of the fullspectrum of capabilities and potential risks in any new model. Existingevaluation approaches often require significant human effort, and it is takingincreasing effort to design ever harder challenges for more capable models. Weintroduce Automated Capability Discovery (ACD), a framework that designates onefoundation model as a scientist to systematically propose open-ended tasksprobing the abilities of a subject model (potentially itself). By combiningfrontier models with ideas from the field of open-endedness, ACD automaticallyand systematically uncovers both surprising capabilities and failures in thesubject model. We demonstrate ACD across a range of foundation models(including the GPT, Claude, and Llama series), showing that it automaticallyreveals thousands of capabilities that would be challenging for any single teamto uncover. We further validate our method's automated scoring with extensivehuman surveys, observing high agreement between model-generated and humanevaluations. By leveraging foundation models' ability to both create tasks andself-evaluate, ACD is a significant step toward scalable, automated evaluationof novel AI systems. All code and evaluation logs are open-sourced athttps://github.com/conglu1997/ACD.</description>
      <author>example@mail.com (Cong Lu, Shengran Hu, Jeff Clune)</author>
      <guid isPermaLink="false">2502.07577v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Suction Grasping with Large-Scale Parcel Dataset</title>
      <link>http://arxiv.org/abs/2502.07238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文针对物体吸盘抓取技术在处理复杂包裹场景中的挑战，提出了一个大规模合成数据集Parcel-Suction-Dataset和一种创新的Diffusion-Suction框架。&lt;h4&gt;背景&lt;/h4&gt;尽管最近在物体吸盘抓取方面取得了显著进展，但在混乱且复杂的包裹处理环境中仍然存在重大挑战。目前的方法受到两个根本限制：缺乏针对包裹操作任务量身定制的全面吸盘抓取数据集以及对不同对象特性（如大小、几何复杂性和纹理多样性）适应性的不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，本文提出了一种大规模合成数据集Parcel-Suction-Dataset和一种创新的方法Diffusion-Suction框架。&lt;h4&gt;方法&lt;/h4&gt;1. Parcel-Suction-Dataset：包含25000个混乱场景及4亿多个高精度标注的吸盘抓取姿态的数据集。该数据集通过新颖的几何采样算法生成，能够有效生成基于物理约束和材料属性的最优吸盘抓取。2. Diffusion-Suction框架：将吸盘抓取预测重新定义为条件生成任务，并使用去噪扩散概率模型进行实现。此方法通过从点云观察中获得视觉条件引导逐步细化随机噪声，以学习合成数据集中的空间点特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，简单而高效的Diffusion-Suction在Parcel-Suction-Dataset和公共SuctionNet-1Billion基准测试上实现了新的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;本文通过提出大规模合成数据集和创新性方法来解决现有吸盘抓取技术的局限性，并展示了优越的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While recent advances in object suction grasping have shown remarkableprogress, significant challenges persist particularly in cluttered and complexparcel handling scenarios. Two fundamental limitations hinder currentapproaches: (1) the lack of a comprehensive suction grasp dataset tailored forparcel manipulation tasks, and (2) insufficient adaptability to diverse objectcharacteristics including size variations, geometric complexity, and texturaldiversity. To address these challenges, we present Parcel-Suction-Dataset, alarge-scale synthetic dataset containing 25 thousand cluttered scenes with 410million precision-annotated suction grasp poses. This dataset is generatedthrough our novel geometric sampling algorithm that enables efficientgeneration of optimal suction grasps incorporating both physical constraintsand material properties. We further propose Diffusion-Suction, an innovativeframework that reformulates suction grasp prediction as a conditionalgeneration task through denoising diffusion probabilistic models. Our methoditeratively refines random noise into suction grasp score maps throughvisual-conditioned guidance from point cloud observations, effectively learningspatial point-wise affordances from our synthetic dataset. Extensiveexperiments demonstrate that the simple yet efficient Diffusion-Suctionachieves new state-of-the-art performance compared to previous models on bothParcel-Suction-Dataset and the public SuctionNet-1Billion benchmark.</description>
      <author>example@mail.com (Ding-Tao Huang, Xinyi He, Debei Hua, Dongfang Yu, En-Te Lin, Long Zeng)</author>
      <guid isPermaLink="false">2502.07238v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Supervised contrastive learning for cell stage classification of animal embryos</title>
      <link>http://arxiv.org/abs/2502.07360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视频显微镜技术结合机器学习为研究体外生产胚胎早期发育提供了一种有前景的方法。然而，手动标注生物发育事件特别是细胞分裂是耗时的，并且无法扩展到实际应用中。&lt;h4&gt;背景&lt;/h4&gt;目前对于体外产生的（IVP）胚胎的早期发育阶段的手动标记工作非常耗时且难以大规模实施，尤其是在结合视频显微镜技术和机器学习的研究中存在显著挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于深度学习的方法自动分类牛胚胎发育过程中的细胞阶段，并针对低质量图像、暗色细胞和不平衡数据分布等挑战提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了CLEmbryo方法，该方法结合监督对比学习与焦损函数进行训练，并采用轻量级3D神经网络CSN-50作为编码器。同时开发了用于牛胚胎分析的Bovine Embryos Cell Stages (ECS) 数据集。&lt;h4&gt;主要发现&lt;/h4&gt;CLEmbryo在自建的Bovine ECS数据集和公开可用的NYU Mouse Embryos数据集中均超越现有最佳方法，显示出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过结合深度学习与视频显微镜技术能够有效解决牛胚胎发育阶段分类的问题，并且证明了所提出的方法在不同类型的生物实验数据中具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video microscopy, when combined with machine learning, offers a promisingapproach for studying the early development of in vitro produced (IVP) embryos.However, manually annotating developmental events, and more specifically celldivisions, is time-consuming for a biologist and cannot scale up for practicalapplications. We aim to automatically classify the cell stages of embryos from2D time-lapse microscopy videos with a deep learning approach. We focus on theanalysis of bovine embryonic development using video microscopy, as we areprimarily interested in the application of cattle breeding, and we have createda Bovine Embryos Cell Stages (ECS) dataset. The challenges are three-fold: (1)low-quality images and bovine dark cells that make the identification of cellstages difficult, (2) class ambiguity at the boundaries of developmentalstages, and (3) imbalanced data distribution. To address these challenges, weintroduce CLEmbryo, a novel method that leverages supervised contrastivelearning combined with focal loss for training, and the lightweight 3D neuralnetwork CSN-50 as an encoder. We also show that our method generalizes well.CLEmbryo outperforms state-of-the-art methods on both our Bovine ECS datasetand the publicly available NYU Mouse Embryos dataset.</description>
      <author>example@mail.com (Yasmine Hachani, Patrick Bouthemy, Elisa Fromont, Sylvie Ruffini, Ludivine Laffont, Alline de Paula Reis)</author>
      <guid isPermaLink="false">2502.07360v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>AI-Driven HSI: Multimodality, Fusion, Challenges, and the Deep Learning Revolution</title>
      <link>http://arxiv.org/abs/2502.06894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 Pages, 22 figures, 20 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概述&lt;/h4&gt;高光谱成像(HSI)技术捕捉空间和光谱数据，能够分析传统系统无法看到的特征，在天气监测、食品质量控制、防伪检测、医疗诊断以及国防、农业和工业自动化等领域发挥重要作用。&lt;h4&gt;背景&lt;/h4&gt;HSI技术随着光谱分辨率提高、设备小型化及计算方法的进步而不断发展。该研究概述了HSI及其应用，探讨数据融合面临的挑战，并强调深度学习模型在处理HSI数据中的作用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在为技术和非技术人员提供关于HSI图像、趋势和未来方向的见解，同时提供有关HSI数据集及软件库的有价值信息。&lt;h4&gt;方法&lt;/h4&gt;介绍了多模态HSI与AI特别是深度学习技术的集成如何提高分类准确性和操作效率。文章还详细说明了深度学习在特征提取、变化检测、降噪分解、降维、土地覆盖制图、数据增强、光谱构建和超分辨率分析方面的提升。&lt;h4&gt;主要发现&lt;/h4&gt;最新的研究焦点在于将高光谱相机与大型语言模型(LLMs)结合，开发出如低能见度碰撞预警及反欺骗面部识别等高级应用。该融合被称为“大脑型”LLM。&lt;h4&gt;结论&lt;/h4&gt;文章还强调了HSI工业中的关键参与者及其复合年增长率，并探讨了其不断增长的产业重要性。&lt;h4&gt;翻译&lt;/h4&gt;Hyperspectral imaging (HSI) captures spatial and spectral data, enabling analysis of features invisible to conventional systems. The technology is vital in fields such as weather monitoring, food quality control, counterfeit detection, healthcare diagnostics, and extending into defense, agriculture, and industrial automation at the same time. HSI has advanced with improvements in spectral resolution, miniaturization, and computational methods. This study provides an overview of the HSI, its applications, challenges in data fusion and the role of deep learning models in processing HSI data. We discuss how integration of multimodal HSI with AI, particularly with deep learning, improves classification accuracy and operational efficiency. Deep learning enhances HSI analysis in areas like feature extraction, change detection, denoising unmixing, dimensionality reduction, landcover mapping, data augmentation, spectral construction and super resolution. An emerging focus is the fusion of hyperspectral cameras with large language models (LLMs), referred as highbrain LLMs, enabling the development of advanced applications such as low visibility crash detection and face antispoofing. We also highlight key players in HSI industry, its compound annual growth rate and the growing industrial significance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperspectral imaging (HSI) captures spatial and spectral data, enablinganalysis of features invisible to conventional systems. The technology is vitalin fields such as weather monitoring, food quality control, counterfeitdetection, healthcare diagnostics, and extending into defense, agriculture, andindustrial automation at the same time. HSI has advanced with improvements inspectral resolution, miniaturization, and computational methods. This studyprovides an overview of the HSI, its applications, challenges in data fusionand the role of deep learning models in processing HSI data. We discuss howintegration of multimodal HSI with AI, particularly with deep learning,improves classification accuracy and operational efficiency. Deep learningenhances HSI analysis in areas like feature extraction, change detection,denoising unmixing, dimensionality reduction, landcover mapping, dataaugmentation, spectral construction and super resolution. An emerging focus isthe fusion of hyperspectral cameras with large language models (LLMs), referredas highbrain LLMs, enabling the development of advanced applications such aslow visibility crash detection and face antispoofing. We also highlight keyplayers in HSI industry, its compound annual growth rate and the growingindustrial significance. The purpose is to offer insight to both technical andnon-technical audience, covering HSI's images, trends, and future directions,while providing valuable information on HSI datasets and software libraries.</description>
      <author>example@mail.com (David S. Bhatti, Yougin Choi, Rahman S M Wahidur, Maleeka Bakhtawar, Sumin Kim, Surin Lee, Yongtae Lee, Heung-No Lee)</author>
      <guid isPermaLink="false">2502.06894v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Tab2Visual: Overcoming Limited Data in Tabular Data Classification Using Deep Learning with Visual Representations</title>
      <link>http://arxiv.org/abs/2502.07181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种名为Tab2Visual的新颖方法，该方法将异构表格数据转换为视觉表示形式，从而可以应用强大的深度学习模型。这种技术特别针对数据量有限的领域（如医疗健康），通过引入新颖的图像增强技术和促进迁移学习来有效解决数据稀缺问题。&lt;h4&gt;背景&lt;/h4&gt;在医疗等受限制领域的表格分类中，面临的主要挑战是数据量的不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的方法来处理表格数据分类中的数据短缺问题，特别是在医疗保健等领域。通过将异构表格数据转换为视觉表示形式，使得可以使用强大的深度学习模型进行分析和分类。&lt;h4&gt;方法&lt;/h4&gt;提出了Tab2Visual方法，该方法能够将各种类型的表格数据转换成图像，结合新的图像增强技术来改善数据的多样性，并且支持迁移学习以利用现有的知识。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在有限的数据条件下，Tab2Visual在表格分类问题中超越了传统机器学习算法、基于树的方法以及专为表格设计的深度学习模型的表现。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了Tab2Visual作为一种有潜力解决数据稀缺性的方法的有效性，并且通过广泛的评估证明了其性能优越于其他现有技术。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已直接作为中文描述，无需额外翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research addresses the challenge of limited data in tabular dataclassification, particularly prevalent in domains with constraints likehealthcare. We propose Tab2Visual, a novel approach that transformsheterogeneous tabular data into visual representations, enabling theapplication of powerful deep learning models. Tab2Visual effectively addressesdata scarcity by incorporating novel image augmentation techniques andfacilitating transfer learning. We extensively evaluate the proposed approachon diverse tabular datasets, comparing its performance against a wide range ofmachine learning algorithms, including classical methods, tree-based ensembles,and state-of-the-art deep learning models specifically designed for tabulardata. We also perform an in-depth analysis of factors influencing Tab2Visual'sperformance. Our experimental results demonstrate that Tab2Visual outperformsother methods in classification problems with limited tabular data.</description>
      <author>example@mail.com (Ahmed Mamdouh, Moumen El-Melegy, Samia Ali, Ron Kikinis)</author>
      <guid isPermaLink="false">2502.07181v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos</title>
      <link>http://arxiv.org/abs/2502.07327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了AI生成视频在视频检索任务中的影响，并构建了一个包含真实和AI生成视频的基准数据集，以评估模型对AI生成视频的偏好。&lt;h4&gt;背景&lt;/h4&gt;随着AI生成内容（AIGC）的发展，高质量AI生成视频的创造变得更加迅速和容易，导致互联网上充斥着各种视频内容。然而，这些视频对内容生态系统的影响仍未被充分研究。&lt;h4&gt;目的&lt;/h4&gt;探讨在具有挑战性的视频检索任务中是否存在类似于图像检索中的模型偏见，并评估将AI生成视频纳入训练集的效果。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含13,000个由两个先进开源视频生成模型产生的视频的基准数据集。设计了一套严格的度量标准来准确测量这种偏好，同时考虑了AIGC视频由于帧率有限和质量不佳带来的潜在偏差。应用了三种现成的视频检索模型进行检索任务。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，在检索任务中存在明显的对AI生成视频的偏爱。将AI生成视频纳入训练集会加剧这种偏好，而视频检索中的偏好来源于未见视觉信息和时间信息的复杂互动。&lt;h4&gt;结论&lt;/h4&gt;该研究表明了AI生成视频在检索系统中的潜在影响，并提出了一种使用对比学习方法来减轻模型对AI生成视频偏好的技术。&lt;h4&gt;翻译&lt;/h4&gt;随着AI生成内容的发展，研究者们构建了一个包含真实和AI生成视频的数据集，以评估现有视频检索模型中存在的偏好。结果揭示了显著的偏向于AI生成视频的现象，并探讨了解决这种问题的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of AI-generated content (AIGC), the creation ofhigh-quality AI-generated videos has become faster and easier, resulting in theInternet being flooded with all kinds of video content. However, the impact ofthese videos on the content ecosystem remains largely unexplored. Videoinformation retrieval remains a fundamental approach for accessing videocontent. Building on the observation that retrieval models often favorAI-generated content in ad-hoc and image retrieval tasks, we investigatewhether similar biases emerge in the context of challenging video retrieval,where temporal and visual factors may further influence model behavior. Toexplore this, we first construct a comprehensive benchmark dataset containingboth real and AI-generated videos, along with a set of fair and rigorousmetrics to assess bias. This benchmark consists of 13,000 videos generated bytwo state-of-the-art open-source video generation models. We meticulouslydesign a suite of rigorous metrics to accurately measure this preference,accounting for potential biases arising from the limited frame rate andsuboptimal quality of AIGC videos. We then applied three off-the-shelf videoretrieval models to perform retrieval tasks on this hybrid dataset. Ourfindings reveal a clear preference for AI-generated videos in retrieval.Further investigation shows that incorporating AI-generated videos into thetraining set of retrieval models exacerbates this bias. Unlike the preferenceobserved in image modalities, we find that video retrieval bias arises fromboth unseen visual and temporal information, making the root causes of videobias a complex interplay of these two factors. To mitigate this bias, wefine-tune the retrieval models using a contrastive learning approach. Theresults of this study highlight the potential implications of AI-generatedvideos on retrieval systems.</description>
      <author>example@mail.com (Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng)</author>
      <guid isPermaLink="false">2502.07327v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>NatureLM: Deciphering the Language of Nature for Scientific Discovery</title>
      <link>http://arxiv.org/abs/2502.07527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  81 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了NatureLM，一种基于序列的科学基础模型，旨在促进跨领域的科学研究和应用。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在自然语言处理和人工智能领域取得了巨大成功，推动了针对特定科学领域的模型的发展。然而这些模型通常独立训练，缺乏跨域整合能力。&lt;h4&gt;目的&lt;/h4&gt;提出NatureLM以克服现有科学领域模型的局限性，并促进多学科之间的交叉应用。&lt;h4&gt;方法&lt;/h4&gt;通过使用来自多个科学领域的数据对NatureLM进行预训练，使其具备统一性和灵活性，适用于多种应用场景。&lt;h4&gt;主要发现&lt;/h4&gt;NatureLM在生成和优化小分子、蛋白质、RNA及材料方面的表现优异；实现了跨域的生成与设计，并展示了在任务如SMILES到IUPAC翻译和逆合成等方面的领先性能。随着模型规模的增大，性能显著提升。&lt;h4&gt;结论&lt;/h4&gt;NatureLM为包括药物发现、新材料开发以及治疗性蛋白或核酸的设计在内的多种科学任务提供了通用且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在自然语言处理和人工智能领域已经革命化了机器理解和生成人类语言的方式。受到这些基础模型成功的启发，研究人员针对特定的科学领域（如小分子、材料、蛋白质、DNA以及RNA）开发了相应的基础模型。然而，这些模型通常独立训练，缺乏跨不同科学领域的整合能力。认识到这些领域中的实体都可以表示为序列，并共同构成了“自然语言”，我们引入了基于序列的科学基础模型NatureLM。预训练时使用来自多个科学领域的数据，NatureLM提供了一种统一且多用途的模型，能够支持多种应用，包括：（i）利用文本指令生成和优化小分子、蛋白质、RNA及材料；（ii）跨域生成/设计，例如从蛋白质到分子或蛋白质到RNA的生成；（iii）在诸如SMILES至IUPAC转换以及逆合成等任务上达到最先进的性能水平。我们开发了不同规模的NatureLM模型（包括10亿参数、80亿参数和467亿参数版本），并观察到了随着模型尺寸增加，性能明显改善的现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized natural language processing andartificial intelligence, significantly enhancing how machines comprehend andgenerate human languages. Inspired by the success of these foundation models,researchers have developed foundation models for individual scientific domains,including small molecules, materials, proteins, DNA, and RNA. However, thesemodels are typically trained in isolation, lacking the ability to integrateacross different scientific domains. Recognizing that entities within thesedomains can all be represented as sequences, which together form the "languageof nature", we introduce Nature Language Model (briefly, NatureLM), asequence-based science foundation model designed for scientific discovery.Pre-trained with data from multiple scientific domains, NatureLM offers aunified, versatile model that enables various applications including: (i)generating and optimizing small molecules, proteins, RNA, and materials usingtext instructions; (ii) cross-domain generation/design, such asprotein-to-molecule and protein-to-RNA generation; and (iii) achievingstate-of-the-art performance in tasks like SMILES-to-IUPAC translation andretrosynthesis on USPTO-50k. NatureLM offers a promising generalist approachfor various scientific tasks, including drug discovery (hitgeneration/optimization, ADMET optimization, synthesis), novel material design,and the development of therapeutic proteins or nucleotides. We have developedNatureLM models in different sizes (1 billion, 8 billion, and 46.7 billionparameters) and observed a clear improvement in performance as the model sizeincreases.</description>
      <author>example@mail.com (Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Kehan Wu, Wei Zhang, Kaiyuan Gao, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin)</author>
      <guid isPermaLink="false">2502.07527v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Cross-platform Learning-based Fault Tolerant Surfacing Controller for Underwater Robots</title>
      <link>http://arxiv.org/abs/2502.07133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 international Conference on Robotics &amp; Automation  (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于强化学习（RL）的新型跨平台容错浮起控制器，用于水下机器人。&lt;h4&gt;背景&lt;/h4&gt;传统的故障容错方法需要明确识别出故障执行器，而本文的方法则允许机器人在不需确定故障的情况下使用剩余正常工作的执行器进行浮起。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理不同执行器配置下各种故障场景的鲁棒策略，并引入跨学习机制以提高多个具有不同类型执行器的水下机器人的控制效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的基于强化学习的方法，该方法通过模拟三种类型的水下机器人（包括悬浮型AUV、鱼雷形状的AUV以及海龟形状的U-CAT）来验证其有效性，并在物理环境中进行真实世界实验。&lt;h4&gt;主要发现&lt;/h4&gt;提出的RL控制器相比基线控制器，在稳定性和成功率方面表现更好，实测中达到了85.7%的成功率，而基线控制器仅为57.1%&lt;h4&gt;结论&lt;/h4&gt;该研究为不同水下平台提供了可扩展且高效的故障容错解决方案，并可能在现实世界中的水域任务中有潜在应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中，我们提出了一种基于强化学习（RL）的新型跨平台容错浮起控制器，用于水下机器人。与传统的需要明确识别故障执行器的方法不同，我们的方法使机器人能够在不需确定具体失败位置的情况下仅使用剩余正常工作的执行器进行浮起操作。所提出的控制器能够为不同的执行器配置学习出处理各种故障场景的鲁棒策略，并引入了跨平台共享控制策略的学习机制以提高水下机器人的学习效率和适应性。为了验证我们的方法，我们在三种不同类型的水下机器人（包括悬浮型AUV、鱼雷形AUV以及海龟形U-CAT）上进行了模拟实验，并且在受控环境中对物理设备中的U-CAT进行了实际测试。通过与基线控制器进行对比，基于RL的控制器表现出了更高的稳定性和成功率，在真实世界测试中成功率达到85.7%，而基线控制器仅为57.1%。这项研究为多样化的水下平台提供了一种可扩展且高效的故障容错解决方案，并具有在现实世界的水域任务中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel cross-platform fault-tolerant surfacingcontroller for underwater robots, based on reinforcement learning (RL). Unlikeconventional approaches, which require explicit identification ofmalfunctioning actuators, our method allows the robot to surface using only theremaining operational actuators without needing to pinpoint the failures. Theproposed controller learns a robust policy capable of handling diverse failurescenarios across different actuator configurations. Moreover, we introduce atransfer learning mechanism that shares a part of the control policy acrossvarious underwater robots with different actuators, thus improving learningefficiency and generalization across platforms. To validate our approach, weconduct simulations on three different types of underwater robots: ahovering-type AUV, a torpedo shaped AUV, and a turtle-shaped robot (U-CAT).Additionally, real-world experiments are performed, successfully transferringthe learned policy from simulation to a physical U-CAT in a controlledenvironment. Our RL-based controller demonstrates superior performance in termsof stability and success rate compared to a baseline controller, achieving an85.7 percent success rate in real-world tests compared to 57.1 percent with abaseline controller. This research provides a scalable and efficient solutionfor fault-tolerant control for diverse underwater platforms, with potentialapplications in real-world aquatic missions.</description>
      <author>example@mail.com (Yuya Hamamatsu, Walid Remmas, Jaan Rebane, Maarja Kruusmaa, Asko Ristolainen)</author>
      <guid isPermaLink="false">2502.07133v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>CASC-AI: Consensus-aware Self-corrective AI Agents for Noise Cell Segmentation</title>
      <link>http://arxiv.org/abs/2502.07302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于共识矩阵的自我纠正AI代理，用于高分辨率全片扫描图像中多类细胞分割任务。&lt;h4&gt;背景&lt;/h4&gt;在高分辨率的全片扫描图像（WSI）中进行多类别细胞分割对于临床应用至关重要。然而，训练此类模型通常需要领域专家手动标注像素级别的数据，这是一项耗时且劳动密集型的任务。&lt;h4&gt;目的&lt;/h4&gt;为了解决传统非代理方法难以适应标签噪声的问题，本文提出了一个共识矩阵引导的自我纠正AI代理。&lt;h4&gt;方法&lt;/h4&gt;该方法使用共识矩阵定义了AI和注释者都同意标记为细胞或非细胞的区域，并对这些区域施加更强的监督。同时，在特征相似性方面，对于与高置信度一致区域更接近的不一致区域赋予更高的权重。&lt;h4&gt;主要发现&lt;/h4&gt;采用对比学习技术来区分噪声区域与可靠一致性区域之间的特征差异，从而提高模型在处理错误标注数据时的表现。&lt;h4&gt;结论&lt;/h4&gt;这种方法通过迭代修正标签中的噪音增强了模型鲁棒性，在真实世界和模拟噪声数据集上进行了验证，并展示了其训练抗噪数据集中强大模型的潜力。&lt;h4&gt;翻译&lt;/h4&gt;多类细胞分割在高分辨率的全片扫描图像（WSI）中至关重要，尤其是在各种临床应用中。然而，这样的模型通常需要领域专家进行劳动密集型像素级别标注。最近的努力通过引入没有医学专业知识的普通注释者来民主化此过程。但是，传统的非代理方法难以适应性地处理注释噪声，因为它们缺乏机制来降低假阳性（FP）和假阴性（FN）。本文提出了一种共识矩阵感知的自我纠正AI代理，它利用共识矩阵指导其学习过程。该模型展示了在真实世界和模拟噪声数据集上提高分割性能的能力，并且可以纠正FP和FN错误。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-class cell segmentation in high-resolution gigapixel whole slide images(WSI) is crucial for various clinical applications. However, training suchmodels typically requires labor-intensive, pixel-wise annotations by domainexperts. Recent efforts have democratized this process by involving layannotators without medical expertise. However, conventional non-agent-basedapproaches struggle to handle annotation noise adaptively, as they lackmechanisms to mitigate false positives (FP) and false negatives (FN) at boththe image-feature and pixel levels. In this paper, we propose a consensus-awareself-corrective AI agent that leverages the Consensus Matrix to guide itslearning process. The Consensus Matrix defines regions where both the AI andannotators agree on cell and non-cell annotations, which are prioritized withstronger supervision. Conversely, areas of disagreement are adaptively weightedbased on their feature similarity to high-confidence agreement regions, withmore similar regions receiving greater attention. Additionally, contrastivelearning is employed to separate features of noisy regions from those ofreliable agreement regions by maximizing their dissimilarity. This paradigmenables the AI to iteratively refine noisy labels, enhancing its robustness.Validated on one real-world lay-annotated cell dataset and two simulated noisydatasets, our method demonstrates improved segmentation performance,effectively correcting FP and FN errors and showcasing its potential fortraining robust models on noisy datasets. The official implementation and cellannotations are publicly available at https://github.com/ddrrnn123/CASC-AI.</description>
      <author>example@mail.com (Ruining Deng, Yihe Yang, David J. Pisapia, Benjamin Liechty, Junchao Zhu, Juming Xiong, Junlin Guo, Zhengyi Lu, Jiacheng Wang, Xing Yao, Runxuan Yu, Rendong Zhang, Gaurav Rudravaram, Mengmeng Yin, Pinaki Sarder, Haichun Yang, Yuankai Huo, Mert R. Sabuncu)</author>
      <guid isPermaLink="false">2502.07302v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling</title>
      <link>http://arxiv.org/abs/2502.07425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了多PDE物理信息神经网络模型的有效性，并通过主动学习策略提高了样本效率。&lt;h4&gt;背景&lt;/h4&gt;传统的PINN模型主要用于单一PDE，限制了其在不同物理系统中的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;探索基于统一架构的多PDE PINN模型的能力及其与主动学习相结合的方法。&lt;h4&gt;方法&lt;/h4&gt;使用一个单一的PINN框架训练四个不同的PDE，并采用Monte Carlo Dropout不确定性估计来实施主动学习策略，以提高样本效率。&lt;h4&gt;主要发现&lt;/h4&gt;目标不确定度采样能够显著提升性能并减少所需的训练样本数量，从而实现跨多个PDE的有效学习。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了基于PINN的泛化模型在处理不同物理问题时无需重新设计网络架构的可能性，并提出了使用多PDE PINN和主动学习的方法来降低计算成本同时保持高精度。&lt;h4&gt;翻译&lt;/h4&gt;物理学信息神经网络(PINNs)作为一种通过将物理定律嵌入到神经网络训练中来解决偏微分方程(PDEs)的强大框架已经出现。然而，传统的PINN模型通常是为单一PDE设计的，限制了其在不同物理系统中的泛化能力。在这项工作中，我们探讨了一个能够解决多个PDE并在统一架构下工作的基础PINN模型的可能性。通过训练一个单一的PINN框架来处理四种不同的PDE——简单谐振子(SHO)、一维热方程、一维波动方程和二维拉普拉斯方程，证明了它学习多样物理动态的能力。为了提高样本效率，我们引入主动学习(Active Learning AL)，采用基于Monte Carlo Dropout的不确定性估计方法选择最具有信息量的训练样本进行迭代式选取。我们评估了不同的主动学习策略，并比较了在10%、20%、30%、40%和50%完整数据集上训练得到模型的准确性影响。我们的结果表明，目标不确定度采样能显著提高性能并减少所需训练样本数量，从而实现了跨多个PDE的有效学习。这项工作强调了一个泛化的PINN基础模型在适应不同的基于物理的问题时无需重新设计网络架构的可能性。我们发现多PDE PINN结合主动学习可以在保持高精度的同时降低物理学基深度学习应用中的计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-Informed Neural Networks (PINNs) have emerged as a powerful frameworkfor solving partial differential equations (PDEs) by embedding physical lawsinto neural network training. However, traditional PINN models are typicallydesigned for single PDEs, limiting their generalizability across differentphysical systems. In this work, we explore the potential of a foundation PINNmodel capable of solving multiple PDEs within a unified architecture. Weinvestigate the efficacy of a single PINN framework trained on four distinctPDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D WaveEquation, and the 2D Laplace Equation, demonstrating its ability to learndiverse physical dynamics.  To enhance sample efficiency, we incorporate Active Learning (AL) using MonteCarlo (MC) Dropout-based uncertainty estimation, selecting the most informativetraining samples iteratively. We evaluate different active learning strategies,comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset,and analyze their impact on solution accuracy. Our results indicate thattargeted uncertainty sampling significantly improves performance with fewertraining samples, leading to efficient learning across multiple PDEs.  This work highlights the feasibility of a generalizable PINN-based foundationmodel, capable of adapting to different physics-based problems withoutredesigning network architectures. Our findings suggest that multi-PDE PINNswith active learning can serve as an effective approach for reducingcomputational costs while maintaining high accuracy in physics-based deeplearning applications.</description>
      <author>example@mail.com (Keon Vin Park)</author>
      <guid isPermaLink="false">2502.07425v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification</title>
      <link>http://arxiv.org/abs/2502.06619v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于增强领域泛化重识别（DG Re-ID）的新方法，名为DCAC。&lt;h4&gt;背景&lt;/h4&gt;域泛化重识别任务由于其实用性吸引了越来越多的关注。然而，现有大多数依赖判别式或对比学习框架的方法往往未能有效避免捷径学习问题，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了改进这一现状，提出了一种基于扩散模型的辅助表示学习方法，结合了关联感知条件化方案（DCAC）。&lt;h4&gt;方法&lt;/h4&gt;该方法通过引入一种关联感知条件化方案，将判别式和对比性的重识别模型与预训练的扩散模型集成在一起。此方案利用生成自重识别模型的身份分类概率以及一组可学身份提示来注入暗知识，并引导扩散过程以捕获身份相关性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在单源域及多源域DG Re-ID任务中均表现出优越性能，并通过全面的消融研究验证了其有效性与鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DCAC框架不仅提高了重识别特征的泛化能力，还为解决捷径学习问题提供了一个有效的解决方案。代码可在https://github.com/RikoLi/DCAC获得。&lt;h4&gt;翻译&lt;/h4&gt;领域通用化的重新识别（DG Re-ID）旨在通过一个或多个源域训练模型，并在未见目标域上评估其性能，这一任务由于其实用性吸引了越来越多的关注。虽然已经提出了许多方法，但大多数依赖于判别式或对比学习框架来学习泛化表示特征。然而，这些方法往往无法避免捷径学习问题，导致次优的性能表现。在这项工作中，我们提出了一种名为扩散模型辅助表示学习及其关联感知条件方案（DCAC）的新方法，以增强DG Re-ID。我们的方法通过一种关联感知条件方案将判别式和对比性的重识别模型与预训练的扩散模型集成在一起。该方案结合了来自重识别模型的身份分类概率以及一组可学身份提示来注入暗知识，捕捉身份相关性，并引导扩散过程。同时，反馈从扩散模型中传播到重识别模型，有效提高了重识别特征的泛化能力。在单源和多源DG Re-ID任务上的广泛实验表明了我们方法实现了最先进的性能表现。全面消融研究进一步验证了所提出方案的有效性和鲁棒性，并提供了关于其工作原理的见解。代码可在https://github.com/RikoLi/DCAC获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25020552&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/RikoLi/DCAC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain-generalizable re-identification (DG Re-ID) aims to train a model onone or more source domains and evaluate its performance on unseen targetdomains, a task that has attracted growing attention due to its practicalrelevance. While numerous methods have been proposed, most rely ondiscriminative or contrastive learning frameworks to learn generalizablefeature representations. However, these approaches often fail to mitigateshortcut learning, leading to suboptimal performance. In this work, we proposea novel method called diffusion model-assisted representation learning with acorrelation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our methodintegrates a discriminative and contrastive Re-ID model with a pre-traineddiffusion model through a correlation-aware conditioning scheme. Byincorporating ID classification probabilities generated from the Re-ID modelwith a set of learnable ID-wise prompts, the conditioning scheme injects darkknowledge that captures ID correlations to guide the diffusion process.Simultaneously, feedback from the diffusion model is back-propagated throughthe conditioning scheme to the Re-ID model, effectively improving thegeneralization capability of Re-ID features. Extensive experiments on bothsingle-source and multi-source DG Re-ID tasks demonstrate that our methodachieves state-of-the-art performance. Comprehensive ablation studies furthervalidate the effectiveness of the proposed approach, providing insights intoits robustness. Codes will be available at https://github.com/RikoLi/DCAC.</description>
      <author>example@mail.com (Jiachen Li, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.06619v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Data Warehouse Design for Multiple Source Forest Inventory Management and Image Processing</title>
      <link>http://arxiv.org/abs/2502.07015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一个原型数据仓库，旨在整合来自多个来源的林业数据进行长期监测、管理和可持续性分析。此数据仓库能够处理不同类型的数据集，并将其转换为机器学习和深度学习分类及分割模型。&lt;h4&gt;背景&lt;/h4&gt;当前需要一个全面的数据管理系统来整合多源的林业数据，以便于后续的研究与管理需求。&lt;h4&gt;目的&lt;/h4&gt;建立并优化一个用于存储、管理和利用各类林业数据的数据仓库。通过集成先进的数据处理管道，该系统可以为YOLO对象识别模型提供高质量的数据支持，并有助于资源利用率的提升和扩展性。&lt;h4&gt;方法&lt;/h4&gt;研究采用了无人机(UAV)拍摄的照片和纸质文档记录进行实验，在此基础上使用YOLOv11模型测试了合并后的数据集。此外，还探讨了如何利用历史与当前数据比较来理解树木生长或衰退的趋势。&lt;h4&gt;主要发现&lt;/h4&gt;通过整合纸质文档提升了地面真值信息的质量，并且初步结果显示性能有显著改进。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了在林业领域中使用数据仓库进行长时间数据分析的潜力。同时，还指出了未来需要进一步优化资源利用率以及扩展性的可能方向。&lt;h4&gt;翻译&lt;/h4&gt;此摘要为对该论文主要内容的中文译文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research developed a prototype data warehouse to integrate multi-sourceforestry data for long-term monitoring, management, and sustainability. Thedata warehouse is intended to accommodate all types of imagery from variousplatforms, LiDAR point clouds, survey records, and paper documents, with thecapability to transform these datasets into machine learning (ML) and deeplearning classification and segmentation models. In this study, we pioneeredthe integration of unmanned aerial vehicle (UAV) imagery and paper records,testing the merged data on the YOLOv11 model. Paper records improved groundtruth, and preliminary results demonstrated notable performance improvements.  This research aims to implement a data warehouse (DW) to manage data for aYOLO (You Only Look Once) model, which identifies objects in images. It doesthis by integrating advanced data processing pipelines. Data are also storedand easily accessible for future use, including comparing current andhistorical data to understand growth or declining patterns. In addition, thedesign is used to optimize resource usage. It also scales easily, not affectingother parts of the data warehouse when adding dimension tables or other fieldsto the fact table. DW performance and estimations for growing workloads arealso explored in this paper.</description>
      <author>example@mail.com (Kristina Cormier, Kongwen, Zhang, Joshua Padron-Uy, Albert Wong, Keona Gagnier, Ajitesh Parihar)</author>
      <guid isPermaLink="false">2502.07015v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Dataset Ownership Verification in Contrastive Pre-trained Models</title>
      <link>http://arxiv.org/abs/2502.07276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;高质量的开源数据集推动了深度学习领域的快速发展，但保护这些数据集对于数据所有者来说至关重要。本文提出了一种针对自监督预训练模型的所有权验证方法。&lt;h4&gt;背景&lt;/h4&gt;高质开放数据集在深度学习领域中具有重要作用，然而现有所有权验证技术主要面向有监督模型，并不适用于无监督的预训练模型。&lt;h4&gt;目的&lt;/h4&gt;为解决上述问题，本研究旨在开发一种专门针对自监督预训练模型的所有权验证方法。此法有助于确认可疑的黑盒骨干网络是否使用了特定未标注的数据集进行预训练，从而帮助数据所有者维护其权益。&lt;h4&gt;方法&lt;/h4&gt;该方法基于对比学习原理，通过观察在目标数据集中训练的模型与不在其中训练的模型之间的嵌入空间中单个和二元实例关系的变化来验证所有权。研究团队使用了多个对比自监督预训练模型（如SimCLR、BYOL等）进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法能够显著降低误判率（$p$值低于0.05），优于所有现有方法。&lt;h4&gt;结论&lt;/h4&gt;我们的工作为验证数据集所有权提供了一个新的视角和工具，尤其在无监督预训练模型领域具有重要的应用价值。我们的代码开源可访问于GitHub：https://github.com/xieyc99/DOV4CL。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经用中文进行总结，并按要求转换成了JSON格式输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-quality open-source datasets, which necessitate substantial efforts forcuration, has become the primary catalyst for the swift progress of deeplearning. Concurrently, protecting these datasets is paramount for thewell-being of the data owner. Dataset ownership verification emerges as acrucial method in this domain, but existing approaches are often limited tosupervised models and cannot be directly extended to increasingly popularunsupervised pre-trained models. In this work, we propose the first datasetownership verification method tailored specifically for self-supervisedpre-trained models by contrastive learning. Its primary objective is toascertain whether a suspicious black-box backbone has been pre-trained on aspecific unlabeled dataset, aiding dataset owners in upholding their rights.The proposed approach is motivated by our empirical insights that when modelsare trained with the target dataset, the unary and binary instancerelationships within the embedding space exhibit significant variationscompared to models trained without the target dataset. We validate the efficacyof this approach across multiple contrastive pre-trained models includingSimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that ourmethod rejects the null hypothesis with a $p$-value markedly below $0.05$,surpassing all previous methodologies. Our code is available athttps://github.com/xieyc99/DOV4CL.</description>
      <author>example@mail.com (Yuechen Xie, Jie Song, Mengqi Xue, Haofei Zhang, Xingen Wang, Bingde Hu, Genlang Chen, Mingli Song)</author>
      <guid isPermaLink="false">2502.07276v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DOGR: Leveraging Document-Oriented Contrastive Learning in Generative Retrieval</title>
      <link>http://arxiv.org/abs/2502.07219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的通用生成检索框架DOGR，通过对比学习改进了生成式检索任务。&lt;h4&gt;背景&lt;/h4&gt;生成检索是一种新颖的信息检索方法，利用生成语言模型为给定查询生成文档标识符的排名列表。这种方法简化了检索管道，用模型参数取代了庞大的外部索引。&lt;h4&gt;目的&lt;/h4&gt;解决现有研究仅关注查询与文档标识符之间关系的学习问题，无法直接表示查询和文档之间的相关性。&lt;h4&gt;方法&lt;/h4&gt;提出DOGR框架，采用两阶段学习策略，通过直接交互全面捕捉查询和文档间的关系，并使用负采样方法及对应的对比学习目标来增强语义表征的习得。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在两个公共基准数据集上，DOGR相比现有生成式检索方法达到了最先进的性能。进一步实验显示该框架对于常见的标识符构建技术具有普遍有效性。&lt;h4&gt;结论&lt;/h4&gt;通过引入文档导向对比学习来增强生成式检索任务，能够更全面地理解查询和文档之间的关系，并取得优异的检索效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了在信息检索领域提出的一种创新方法——DOGR框架，该方法利用对比学习技术改进生成式检索任务。与现有研究相比，它不仅简化了检索管道，还解决了相关性表示的问题，并且在实验中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval constitutes an innovative approach in in- formationretrieval, leveraging generative language models (LM) to generate a ranked listof document identifiers (do- cid) for a given query. It simplifies theretrieval pipeline by replacing the large external index with model parameters.However, existing works merely learned the relationship be- tween queries anddocument identifiers, which is unable to directly represent the relevancebetween queries and docu- ments. To address the above problem, we propose anovel and general generative retrieval framework, namely Leverag- ingDocument-Oriented Contrastive Learning in Generative Retrieval (DOGR), whichleverages contrastive learning to improve generative retrieval tasks. It adoptsa two-stage learn- ing strategy that captures the relationship between queriesand documents comprehensively through direct interactions. Furthermore,negative sampling methods and correspond- ing contrastive learning objectivesare implemented to en- hance the learning of semantic representations, therebypro- moting a thorough comprehension of the relationship be- tween queries anddocuments. Experimental results demon- strate that DOGR achievesstate-of-the-art performance com- pared to existing generative retrievalmethods on two public benchmark datasets. Further experiments have shown thatour framework is generally effective for common identifier con- structiontechniques.</description>
      <author>example@mail.com (Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo)</author>
      <guid isPermaLink="false">2502.07219v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Refine Knowledge of Large Language Models via Adaptive Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.07184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种通过模仿人类学习过程来减少大型语言模型（LLM）幻觉的方法。&lt;h4&gt;背景&lt;/h4&gt;减轻LLMs的幻觉一直是研究社区的根本目标。现有的主流方法是通过优化知识表示来降低幻觉，这些工作主要关注模型获取的知识。&lt;h4&gt;目的&lt;/h4&gt;借鉴人类学习知识的方式，设计了一种适应性对比学习策略，以提高LLM处理知识的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Adaptive Contrastive Learning策略，该策略根据LLMs的实际掌握情况灵活构建正负样本进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，我们的方法有助于模型巩固已有的正确知识、加深对尚未完全理解的知识的理解、遗忘不正确的知识，并承认自己缺乏的知识。&lt;h4&gt;结论&lt;/h4&gt;广泛的数据集上的实验和详细分析验证了所提出的方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;如何减轻大型语言模型（LLMs）的幻觉一直是研究社区追求的基本目标。通过回顾大量与幻觉相关的研究，发现主流方法是通过优化LLMs的知识表示来减少幻觉。考虑到这些工作的核心关注点在于模型获得的知识，并且知识长期以来一直是人类社会进步的核心主题，我们认为模仿人类学习过程可以极大地提高模型完善知识的过程。在我们的工作中，我们设计了一种适应性对比学习策略。该方法根据LLMs对知识的实际掌握情况灵活构建正负样本进行对比学习。这一策略帮助LLMs巩固已有的正确知识、加深对尚未完全理解的知识的理解、遗忘不正确的知识，并承认自己缺乏的知识。广泛的数据集上的实验和详细分析验证了我们方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How to alleviate the hallucinations of Large Language Models (LLMs) hasalways been the fundamental goal pursued by the LLMs research community.Looking through numerous hallucination-related studies, a mainstream categoryof methods is to reduce hallucinations by optimizing the knowledgerepresentation of LLMs to change their output. Considering that the core focusof these works is the knowledge acquired by models, and knowledge has long beena central theme in human societal progress, we believe that the process ofmodels refining knowledge can greatly benefit from the way humans learn. In ourwork, by imitating the human learning process, we design an AdaptiveContrastive Learning strategy. Our method flexibly constructs differentpositive and negative samples for contrastive learning based on LLMs' actualmastery of knowledge. This strategy helps LLMs consolidate the correctknowledge they already possess, deepen their understanding of the correctknowledge they have encountered but not fully grasped, forget the incorrectknowledge they previously learned, and honestly acknowledge the knowledge theylack. Extensive experiments and detailed analyses on widely used datasetsdemonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Yinghui Li, Haojing Huang, Jiayi Kuang, Yangning Li, Shu-Yu Guo, Chao Qu, Xiaoyu Tan, Hai-Tao Zheng, Ying Shen, Philip S. Yu)</author>
      <guid isPermaLink="false">2502.07184v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>From Pixels to Components: Eigenvector Masking for Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06314v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的图像掩码策略，该策略在主成分分析的基础上进行随机掩码操作，而非直接对原始像素进行处理。这种方法利用了图像的全局信息，通过预测被遮挡的部分从可见部分重建来提高视觉表示学习的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的图像自我监督方法通常采用随机遮蔽像素块的方式，这存在一定的局限性，可能导致无法有效学习到用于下游任务所需的高层次特征。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有方法的限制，提出了一种新的掩码策略，以期能够通过预测被遮挡的部分从可见部分重建来提取更有用的视觉表示。&lt;h4&gt;方法&lt;/h4&gt;首先对数据进行主成分分析（PCA），然后随机掩码一部分分量，并确保这些被掩码的分量占据整个数据方差的一个固定比例。学习任务是基于未被掩码的分量预测和重构被掩码的部分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与直接对像素进行掩码相比，这种方法能够显著提高图像分类性能，证明了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法是一种简单且鲁棒的数据驱动替代方案，可以作为传统遮挡图像建模方法的有力补充或替代。&lt;h4&gt;翻译&lt;/h4&gt;从预测图像中被掩盖部分来学习视觉表示是自我监督的一种强大方式。然而，随机掩码像素块的做法存在一定的局限性，可能导致无法有效学习到高层次特征。我们提出了一种在数据转换基础上进行的操作策略，即对主成分分析后的结果进行随机掩码，并重构未被遮挡的部分。这种方法利用了图像的全局信息，能够提取更多有用表示。实验表明，在图像分类任务上，该方法优于传统的像素掩码方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting masked from visible parts of an image is a powerfulself-supervised approach for visual representation learning. However, thecommon practice of masking random patches of pixels exhibits certain failuremodes, which can prevent learning meaningful high-level features, as requiredfor downstream tasks. We propose an alternative masking strategy that operateson a suitable transformation of the data rather than on the raw pixels.Specifically, we perform principal component analysis and then randomly mask asubset of components, which accounts for a fixed ratio of the data variance.The learning task then amounts to reconstructing the masked components from thevisible ones. Compared to local patches of pixels, the principal components ofimages carry more global information. We thus posit that predicting masked fromvisible components involves more high-level features, allowing our maskingstrategy to extract more useful representations. This is corroborated by ourempirical findings which demonstrate improved image classification performancefor component over pixel masking. Our method thus constitutes a simple androbust data-driven alternative to traditional masked image modeling approaches.</description>
      <author>example@mail.com (Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt)</author>
      <guid isPermaLink="false">2502.06314v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Model Diffusion for Certifiable Few-shot Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.06970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在现代大规模深度学习中，解决低数据问题的一种流行且有效的工作流程是通过参数高效微调（PEFT）将强大的预训练基础模型（FMs）适应到新的任务上。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在为下游任务开发一种新型的转移学习方法，以提供非空泛化的理论保证，在低样本场景下也能确保模型的有效性和准确性。&lt;h4&gt;方法&lt;/h4&gt;研究人员首先利用上游任务来训练PEFT参数分布。然后通过抽样和评估过程来进行下游任务的学习——从训练好的扩散模型中抽取可能的PEFT并选择在下游数据上可能性最高的那个。这种方法将模型假设限制在一个有限数量的PEFT样本集中，从而相较于神经网络权重中的连续假设空间提供了更紧的风险保证。&lt;h4&gt;主要发现&lt;/h4&gt;该方法相比现有学习方法，在低样本场景下能提供非空泛化保证，并且与现有的会导致无意义界限的学习方式不同，这种方法可以避免泛化性能无法验证的问题。&lt;h4&gt;结论&lt;/h4&gt;新的转移学习方法能够为低数据量环境下的模型部署和应用提供理论上的泛化保证，有助于提高这些应用场景中的模型可靠性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;在现代大规模深度学习中，解决低数据问题的一种流行且有效的工作流程是通过参数高效微调（PEFT）将强大的预训练基础模型（FMs）适应到新的任务上。然而，尽管这种方法从经验上看很有效，但由于缺乏泛化保证来证明其准确性，可能导致对于某些应用场景部署前的伦理或法律要求无法满足。在这篇论文中，我们开发了一种新型转移学习方法，旨在为下游任务提供非空理论上的泛化保证，即使在低样本环境中也能实现这一目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern large-scale deep learning, a prevalent and effective workflow forsolving low-data problems is adapting powerful pre-trained foundation models(FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, whileempirically effective, the resulting solutions lack generalisation guaranteesto certify their accuracy - which may be required for ethical or legal reasonsprior to deployment in high-importance applications. In this paper we develop anovel transfer learning approach that is designed to facilitate non-vacuouslearning theoretic generalisation guarantees for downstream tasks, even in thelow-shot regime. Specifically, we first use upstream tasks to train adistribution over PEFT parameters. We then learn the downstream task by asample-and-evaluate procedure -- sampling plausible PEFTs from the traineddiffusion model and selecting the one with the highest likelihood on thedownstream data. Crucially, this confines our model hypothesis to a finite setof PEFT samples. In contrast to learning in the typical continuous hypothesisspaces of neural network weights, this facilitates tighter risk certificates.We instantiate our bound and show non-trivial generalization guaranteescompared to existing learning approaches which lead to vacuous bounds in thelow-shot regime.</description>
      <author>example@mail.com (Fady Rezk, Royson Lee, Henry Gouk, Timothy Hospedales, Minyoung Kim)</author>
      <guid isPermaLink="false">2502.06970v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Cost-Efficient Continual Learning with Sufficient Exemplar Memory</title>
      <link>http://arxiv.org/abs/2502.07274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一个在充足示例存储资源下的持续学习（CL）新方法，通过结合权重重置和平均技术直接操作模型的权重空间来减少计算成本。&lt;h4&gt;背景&lt;/h4&gt;当前持续学习研究通常假设记忆资源受到严格限制。然而，在许多现实场景中，尤其是在大型基础模型时代，内存是充足的，而GPU计算成本成为主要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;调查在示例存储资源丰富的条件下进行持续学习的方法，并提出一种减少现有方法计算成本的新型技术方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种直接操作模型权重空间的新方法，通过结合权重重置和平均技术，在充足的示例存储环境中工作。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了与现有最佳性能相当的结果，同时将计算成本降低到四分之一或三分之一。&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了传统的持续学习假设，并为计算效率高的持续学习应用提供了实用基准。&lt;h4&gt;翻译&lt;/h4&gt;持续学习（CL）研究通常假定高度受限的示例内存资源。然而，在许多现实世界场景中——尤其是在大型基础模型时代，内存充足，而GPU计算成本是主要瓶颈。在这项工作中，我们探讨了在示例记忆充足的条件下进行持续学习的新设置。与为严格的示例内存限制设计的方法不同，我们提出了一种简单但有效的方法，直接通过结合权重重置和平均技术操作模型的权重空间。我们的方法实现了最先进的性能，同时将计算成本降低到现有方法的四分之一或三分之一。这些发现挑战了传统的持续学习假设，并提供了计算效率高的持续学习应用的实际基准线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) research typically assumes highly constrainedexemplar memory resources. However, in many real-world scenarios-especially inthe era of large foundation models-memory is abundant, while GPU computationalcosts are the primary bottleneck. In this work, we investigate CL in a novelsetting where exemplar memory is ample (i.e., sufficient exemplar memory).Unlike prior methods designed for strict exemplar memory constraints, wepropose a simple yet effective approach that directly operates in the model'sweight space through a combination of weight resetting and averagingtechniques. Our method achieves state-of-the-art performance while reducing thecomputational cost to a quarter or third of existing methods. These findingschallenge conventional CL assumptions and provide a practical baseline forcomputationally efficient CL applications.</description>
      <author>example@mail.com (Dongkyu Cho, Taesup Moon, Rumi Chunara, Kyunghyun Cho, Sungmin Cha)</author>
      <guid isPermaLink="false">2502.07274v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks at a Fraction</title>
      <link>http://arxiv.org/abs/2502.06136v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, accepted at PAKKD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Quaternion Message Passing Neural Networks (QMPNNs)框架，该框架利用四元数空间计算节点表示，从而在减少模型大小的同时保持与原始尺寸GNN相当的准确性。&lt;h4&gt;背景&lt;/h4&gt;图形神经网络（GNN）已被证明是学习图结构数据表示的强大工具。除了实值GNN之外，四元数GNN也在处理图任务时表现出色。然而，在保持高精度的情况下减小模型规模仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;通过减少模型尺寸同时维持与原始大小的GNN相当的准确性来降低能量足迹。&lt;h4&gt;方法&lt;/h4&gt;论文提出了QMPNN框架，并提出了一种新的视角——Graph Lottery Tickets，旨在从子网络中找到初始化彩票，即能够训练出与原始GNN相当性能的小型子网。此外，该研究评估了所提出的QMPNN框架和LTH在三种基础图任务上的表现：节点分类、链路预测以及图分类。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了QMPNN框架的有效性，在减少参数数量的同时保持了与原始GNN相当的性能；还发现了可以进一步降低可训练模型参数的方法，即从GNN子网络中找到初始化彩票。这些方法在三个实际数据集上的评估显示出良好的效果。&lt;h4&gt;结论&lt;/h4&gt;所提出的Quaternion Message Passing Neural Networks (QMPNNs)框架和Graph Lottery Tickets视角提供了一种通用化的方法，可以在减少四倍原始参数数量的情况下将四元数表示整合到GNN架构中，并保持与原模型相当的性能。这种方法不仅能够显著减小模型大小，而且还能节省计算资源。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实值GNN之外，四元数GNN在处理图形任务时也表现出色。为了减少能源消耗，我们在保持与原始尺寸的GNN相当精度的同时减少了模型大小。本文介绍了Quaternion Message Passing Neural Networks (QMPNNs)，这是一个框架，利用四元空间计算节点表示。我们的方法提供了一种通用的方法，在只使用原参数数量四分之一的情况下将四元表示整合到GNN架构中。此外，我们还提出了一种新颖的视角——Graph Lottery Tickets，并重新定义了其在GNN和QMPNN上下文中的适用性。具体目标是找到一个能够实现与原始GNN相当性能的子网初始化彩票，以此进一步减少可训练模型参数的数量。为了验证所提出的QMPNN框架和LTH的有效性，我们在三种基本图任务——节点分类、链路预测以及图分类上使用真实数据集进行了评估。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for learningrepresentations of graph-structured data. In addition to real-valued GNNs,quaternion GNNs also perform well on tasks on graph-structured data. With theaim of reducing the energy footprint, we reduce the model size whilemaintaining accuracy comparable to that of the original-sized GNNs. This paperintroduces Quaternion Message Passing Neural Networks (QMPNNs), a frameworkthat leverages quaternion space to compute node representations. Our approachoffers a generalizable method for incorporating quaternion representations intoGNN architectures at one-fourth of the original parameter count. Furthermore,we present a novel perspective on Graph Lottery Tickets, redefining theirapplicability within the context of GNNs and QMPNNs. We specifically aim tofind the initialization lottery from the subnetwork of the GNNs that canachieve comparable performance to the original GNN upon training. Therebyreducing the trainable model parameters even further. To validate theeffectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,we evaluate their performance on real-world datasets across three fundamentalgraph-based tasks: node classification, link prediction, and graphclassification.</description>
      <author>example@mail.com (Rucha Bhalchandra Joshi, Sagar Prakash Barad, Nidhi Tiwari, Subhankar Mishra)</author>
      <guid isPermaLink="false">2502.06136v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2502.01216v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;工业缺陷分割对于制造业的质量控制至关重要。由于训练样本的稀缺性，少样本语义分割（FSS）在该领域具有重要价值。&lt;h4&gt;背景&lt;/h4&gt;现有的研究大多将FSS应用于简单纹理上的缺陷处理，而忽略了更多样化场景的需求。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过探索基于更广泛工业产品和各种类型缺陷的FSS来弥补这一空白。&lt;h4&gt;贡献1&lt;/h4&gt;我们提供了一个新的真实世界数据集，并重新组织了一些现有的数据集以构建一个更为全面的少样本缺陷分割（FDS）基准。&lt;h4&gt;方法&lt;/h4&gt;在该基准上，我们深入研究了基于度量学习的FSS方法，包括基于元学习和视觉基础模型（VFMs）的方法。&lt;h4&gt;主要发现1&lt;/h4&gt;现有基于元学习的方法一般不太适合这一任务，而VFMs则具有很大的潜力。&lt;h4&gt;贡献2&lt;/h4&gt;进一步系统地研究了各种VFMs在该任务中的适用性，涉及两种范式：特征匹配以及使用Segment Anything (SAM)模型的方案。&lt;h4&gt;主要发现2&lt;/h4&gt;我们提出了一种基于特征匹配的新颖高效的FDS方法，并且发现通过其视频跟踪模式，SAM2特别有效于解决FDS问题。&lt;h4&gt;数据集和代码&lt;/h4&gt;贡献的数据集和代码将在https://github.com/liutongkun/GFDS上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial defect segmentation is critical for manufacturing quality control.Due to the scarcity of training defect samples, few-shot semantic segmentation(FSS) holds significant value in this field. However, existing studies mostlyapply FSS to tackle defects on simple textures, without considering morediverse scenarios. This paper aims to address this gap by exploring FSS inbroader industrial products with various defect types. To this end, wecontribute a new real-world dataset and reorganize some existing datasets tobuild a more comprehensive few-shot defect segmentation (FDS) benchmark. Onthis benchmark, we thoroughly investigate metric learning-based FSS methods,including those based on meta-learning and those based on Vision FoundationModels (VFMs). We observe that existing meta-learning-based methods aregenerally not well-suited for this task, while VFMs hold great potential. Wefurther systematically study the applicability of various VFMs in this task,involving two paradigms: feature matching and the use of Segment Anything (SAM)models. We propose a novel efficient FDS method based on feature matching.Meanwhile, we find that SAM2 is particularly effective for addressing FDSthrough its video track mode. The contributed dataset and code will beavailable at: https://github.com/liutongkun/GFDS.</description>
      <author>example@mail.com (Tongkun Liu, Bing Li, Xiao Jin, Yupeng Shi, Qiuying Li, Xiang Wei)</author>
      <guid isPermaLink="false">2502.01216v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction</title>
      <link>http://arxiv.org/abs/2502.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期人工智能的进步革新了材料科学中的属性预测，并加速了新材料的发现。图神经网络（GNN）因其能将晶体结构表示为图的能力而脱颖而出，有效捕捉局部交互并提供优秀的预测结果。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常会丢失关键的全局信息，如晶系和重复单元连接性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于跨注意力机制的多模态融合模型CAST，该模型结合了图和文本模态以保留重要的材料信息。&lt;h4&gt;方法&lt;/h4&gt;CAST通过使用交叉注意力机制在节点级和标记级别上组合特征，并且通过掩码节点预测预训练策略进一步增强原子级别的信息整合。此方法超越了依赖于材料级别的嵌入（如均值汇集或[CLS]令牌）的方法。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在四个晶体属性（包括带隙）的性质预测方面比CrysMMNet和MultiMat等方法高出高达22.9%的改进。&lt;h4&gt;结论&lt;/h4&gt;预训练是关键，以使节点和文本嵌入对齐。注意力图证实了其捕捉节点与令牌之间关系的有效性。该研究突显了多模态学习在材料科学中的潜力，并为更加强大的预测模型铺平道路，这些模型能够整合局部和全局信息。&lt;h4&gt;翻译&lt;/h4&gt;最近人工智能的进步革新了材料科学领域中物质属性的预测方法，并加速了新材料的发现过程。图神经网络（GNN）由于其将晶体结构表示成图的能力而脱颖而出，可以有效地捕捉到本地交互并提供更好的预测结果。然而，这些方法往往会丢失重要的全局信息，例如晶系和重复单元连接性等。为了解决这个问题，我们提出了一种基于跨注意力机制的多模态融合模型CAST，该模型结合了图形和文本模式以保留关键材料信息。通过使用交叉注意机制在节点级别和标记级别的特征之间进行组合，并且通过掩码节点预测预训练策略进一步增强原子级别的信息整合，我们的方法超越了依赖于材料级别的嵌入（例如图均值汇集或[CLS]令牌）的方法。我们的方法在四个晶体属性的性质预测上比CrysMMNet和MultiMat等方法提高了高达22.9%的表现。预训练是关键以使节点和文本嵌入对齐，并且注意力地图确认其捕捉到节点与标记之间关系的有效性。这项研究展示了多模态学习在材料科学中的潜力，为更加强大的预测模型打开了大门，这些模型能够整合局部和全局信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in AI have revolutionized property prediction inmaterials science and accelerating material discovery. Graph neural networks(GNNs) stand out due to their ability to represent crystal structures asgraphs, effectively capturing local interactions and delivering superiorpredictions. However, these methods often lose critical global information,such as crystal systems and repetitive unit connectivity. To address this, wepropose CAST, a cross-attention-based multimodal fusion model that integratesgraph and text modalities to preserve essential material information. CASTcombines node- and token-level features using cross-attention mechanisms,surpassing previous approaches reliant on material-level embeddings like graphmean-pooling or [CLS] tokens. A masked node prediction pretraining strategyfurther enhances atomic-level information integration. Our method achieved upto 22.9\% improvement in property prediction across four crystal propertiesincluding band gap compared to methods like CrysMMNet and MultiMat. Pretrainingwas key to aligning node and text embeddings, with attention maps confirmingits effectiveness in capturing relationships between nodes and tokens. Thisstudy highlights the potential of multimodal learning in materials science,paving the way for more robust predictive models that incorporate both localand global information.</description>
      <author>example@mail.com (Jaewan Lee, Changyoung Park, Hongjun Yang, Sungbin Lim, Sehui Han)</author>
      <guid isPermaLink="false">2502.06836v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>GENERator: A Long-Context Generative Genomic Foundation Model</title>
      <link>http://arxiv.org/abs/2502.07272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GENERator的新型基因组基础模型，该模型使用大型语言模型技术来解析DNA序列，并展示了在多个基准测试中的领先性能。&lt;h4&gt;背景&lt;/h4&gt;随着DNA测序技术的进步，解码基因组序列的能力得到了显著提高。然而，由于遗传材料的复杂性，对这些序列进行预测和解释仍然具有挑战性。尽管大型语言模型为生物序列分析引入了新的机会，但现有模型在鲁棒性和应用范围方面仍面临限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为GENERator的新基因组基础模型，以克服现有模型面临的局限性，并提升其在复杂生物系统中的预测和解释能力。&lt;h4&gt;方法&lt;/h4&gt;开发了一个具有98k碱基对上下文长度和12亿参数的生成型基因组基础模型。该模型基于3860亿个真核DNA碱基组成的庞大数据集进行训练，能够准确地生成蛋白质编码序列，并响应性地生成具有特定活性谱的启动子序列。&lt;h4&gt;主要发现&lt;/h4&gt;GENERator在多个基准测试中表现出色，在基因序列优化方面显示出显著潜力。该模型还能产生与已知蛋白质家族结构类似的新蛋白质编码序列。&lt;h4&gt;结论&lt;/h4&gt;作为重要的工具，GENERator能够推动基因组研究和生物技术的进步，增强我们对复杂生物系统的理解和预测能力，并为精准的基因组干预提供可能。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：随着DNA测序技术的进步，解码基因组序列的能力显著提高。然而，由于遗传材料的复杂性，这些序列的预测和解释仍然具有挑战性。大型语言模型（LLMs）为生物序列分析带来了新的机会。最近在基因组语言模型方面的进展突显了LLMs解读DNA序列的潜力。尽管如此，现有模型往往面临鲁棒性和应用范围上的限制，主要由于模型结构和训练数据规模的局限。为了克服这些限制，我们提出了一种名为GENERator的新生成型基因组基础模型，该模型具有98k碱基对(bp)的上下文长度和12亿个参数。该模型基于一个包含3860亿个真核DNA碱基的大规模数据集进行训练，并在现有及新提出的基准测试中表现出色。GENERator遵循分子生物学的基本定律，能够准确地生成蛋白质编码序列，翻译出与已知家族结构相似的蛋白质。此外，在序列优化方面，特别是通过响应性启动子序列生成（具有特定活性谱）展现出显著潜力。这些能力使GENERator成为基因组研究和生物技术进步的关键工具，增强我们对复杂生物系统进行解读和预测的能力，并为精准的基因组干预提供可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in DNA sequencing technologies have significantly improved ourability to decode genomic sequences. However, the prediction and interpretationof these sequences remain challenging due to the intricate nature of geneticmaterial. Large language models (LLMs) have introduced new opportunities forbiological sequence analysis. Recent developments in genomic language modelshave underscored the potential of LLMs in deciphering DNA sequences.Nonetheless, existing models often face limitations in robustness andapplication scope, primarily due to constraints in model structure and trainingdata scale. To address these limitations, we present GENERator, a generativegenomic foundation model featuring a context length of 98k base pairs (bp) and1.2B parameters. Trained on an expansive dataset comprising 386B bp ofeukaryotic DNA, the GENERator demonstrates state-of-the-art performance acrossboth established and newly proposed benchmarks. The model adheres to thecentral dogma of molecular biology, accurately generating protein-codingsequences that translate into proteins structurally analogous to knownfamilies. It also shows significant promise in sequence optimization,particularly through the prompt-responsive generation of promoter sequenceswith specific activity profiles. These capabilities position the GENERator as apivotal tool for genomic research and biotechnological advancement, enhancingour ability to interpret and predict complex biological systems and enablingprecise genomic interventions.</description>
      <author>example@mail.com (Wei Wu, Qiuyi Li, Mingyang Li, Kun Fu, Fuli Feng, Jieping Ye, Hui Xiong, Zheng Wang)</author>
      <guid isPermaLink="false">2502.07272v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MLLM4PUE: Toward Universal Embeddings in Computational Pathology through Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2502.07221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;病理学在诊断多种疾病中起着关键作用，但现有方法依赖于专门针对特定任务训练的模型，并且需要大量标记的数据集。&lt;h4&gt;背景&lt;/h4&gt;现有的病理诊断技术主要依靠为具体任务设计的机器学习模型。这些模型通常需要大量的数据来保证准确性，这使得它们难以适应不同类型的病理性状并导致了可持续性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用多模态嵌入的方法以支持多种下游任务，并引入一个评估病理学中多模态嵌入质量的标准基准。&lt;h4&gt;方法&lt;/h4&gt;提出了MLLM4PUE框架，该框架利用多模态大型语言模型生成病理学通用嵌入。同时开发了病理学多模态嵌入基准（PMEB）来全面评估病理数据集中的多模态关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于MLLM的方法能够有效地支持各种下游任务，并且为基础模型在病理学研究方向上统一了研究路径。&lt;h4&gt;结论&lt;/h4&gt;通过引入通用的多模态嵌入以及统一基准，能够更好地解决现有技术面临的可持续性问题和多样性挑战，推动医学图像和文本处理的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;Pathology plays a critical role in diagnosing a wide range of diseases, yet existing approaches often rely on task-specific models trained on extensive well-labeled datasets. This creates sustainability challenges due to the diversity of pathologies and labor-intensive data collection. To address these limitations, we propose MLLM4PUE framework using multimodal large language models for generating universal pathology embeddings. Additionally, a comprehensive benchmark PMEB is introduced for evaluating the quality of multimodal embeddings in pathology tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology plays a critical role in diagnosing a wide range of diseases, yetexisting approaches often rely heavily on task-specific models trained onextensive, well-labeled datasets. These methods face sustainability challengesdue to the diversity of pathologies and the labor-intensive nature of datacollection. To address these limitations, we highlight the need for universalmultimodal embeddings that can support multiple downstream tasks. Previousapproaches often involve fine-tuning CLIP-based models, which handle images andtext separately, limiting their ability to capture complex multimodalrelationships. Additionally, these models are evaluated across diverse datasetswithout a unified benchmark for assessing multimodal embeddings in pathology.To address these challenges, we propose MLLM4PUE, a novel framework thatleverages Multimodal Large Language Models (MLLMs) to generate PathologyUniversal Embeddings. The MLLM4PUE framework not only facilitates robustintegration of images and text but also enhances understanding and fusioncapabilities across various tasks. We further introduce the PathologyMultimodal Embedding Benchmark (PMEB), a comprehensive benchmark designed toassess the quality of pathology multimodal embeddings. PMEB comprises 15original tasks drawn from 14 datasets, organized into three meta-tasks:retrieval, classification, and composed retrieval. Experimental resultsdemonstrate the superiority of MLLM4PUE, illustrating MLLM-based models caneffectively support a wide range of downstream tasks and unify the researchdirection for foundation models in pathology.</description>
      <author>example@mail.com (Qifeng Zhou, Thao M. Dang, Wenliang Zhong, Yuzhi Guo, Hehuan Ma, Saiyang Na, Junzhou Huang)</author>
      <guid isPermaLink="false">2502.07221v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>MPFBench: A Large Scale Dataset for SciML of Multi-Phase-Flows: Droplet and Bubble Dynamics</title>
      <link>http://arxiv.org/abs/2502.07080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了科学机器学习在模拟多相流体动力学（如滴落的液滴和上升的气泡）中的应用，展示了利用神经算子和基础模型进行高效建模的可能性。&lt;h4&gt;背景&lt;/h4&gt;工业应用中遇到的多相流体力学现象，比如滴落的液滴和上升的气泡，由于其复杂的不稳定性、波形图案和气泡破裂等特性，使得对其进行有效模拟极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;探索科学机器学习（SciML）在基于神经算子和基础模型下建模多相流体动力学现象中的应用潜力，并提高这类问题的计算效率与准确性。&lt;h4&gt;方法&lt;/h4&gt;研究团队通过序列到序列技术对一个包含11,000次模拟结果的数据集进行分析，该数据集中包含了由经过验证的格子玻尔兹曼方法（LBM）框架生成的一百万个时间快照。&lt;h4&gt;主要发现&lt;/h4&gt;机器学习模型能够捕捉瞬态动态和复杂的流体相互作用，为基于SciML的求解器在未来实现更加准确且计算效率更高的多相应用铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;利用神经算子和基础模型进行科学机器学习的方法展示出显著潜力，可以有效解决复杂多相现象模拟问题，并有望推动相关工业领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多相流体力学（如滴落的液滴和上升的气泡）对于许多工业应用至关重要。然而，由于不稳定性、波形图案及气泡破裂等特性，对其进行有效的模拟极具挑战性。本文探讨了科学机器学习（SciML）在使用神经算子与基础模型建模这些现象方面的潜力。我们对11,000次仿真生成的全面数据集进行了序列到序列技术的应用，该数据集包含一百万个时间快照，并由一种经过验证的格子玻尔兹曼方法（LBM）框架产生。结果表明机器学习模型能够捕捉瞬态动态与复杂的流体交互作用，为基于SciML的求解器在未来实现更加准确且计算效率更高的多相应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiphase fluid dynamics, such as falling droplets and rising bubbles, arecritical to many industrial applications. However, simulating these phenomenaefficiently is challenging due to the complexity of instabilities, wavepatterns, and bubble breakup. This paper investigates the potential ofscientific machine learning (SciML) to model these dynamics using neuraloperators and foundation models. We apply sequence-to-sequence techniques on acomprehensive dataset generated from 11,000 simulations, comprising 1 milliontime snapshots, produced with a well-validated Lattice Boltzmann method (LBM)framework. The results demonstrate the ability of machine learning models tocapture transient dynamics and intricate fluid interactions, paving the way formore accurate and computationally efficient SciML-based solvers for multiphaseapplications.</description>
      <author>example@mail.com (Mehdi Shadkhah, Ronak Tali, Ali Rabeh, Ethan Herron, Cheng-Hau Yang, Abhisek Upadhyaya, Adarsh Krishnamurthy, Chinmay Hegde, Aditya Balu, Baskar Ganapathysubramanian)</author>
      <guid isPermaLink="false">2502.07080v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2502.06910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种基于Kolmogorov-Arnold网络（KAN）的频率分解学习架构TimeKAN，用于解决混合多频时间序列预测问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界的时间序列通常包含多种相互交织的频率成分，这使得准确预测变得具有挑战性。单一频率模式在不同频率下的信息密度各不相同，统一建模方法可能导致特征描述不准。&lt;h4&gt;目的&lt;/h4&gt;提出一种灵活且高效的架构来解决由多频混合导致的复杂时间序列预测问题。&lt;h4&gt;方法&lt;/h4&gt;TimeKAN主要包含三个组件：级联频率分解（CFD）块、多阶KAN表征学习（M-KAN）块以及频率混合块。通过底部向上递进的方式获取每个频率带的序列表示，利用高灵活性的KAN设计了一种新的M-KAN模块用于学习特定时间模式，并且通过频率混合块重新组合不同的频段。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明TimeKAN在多个实际时间序列数据集上实现了最先进的性能，并且作为一种轻量级架构具有优越性。&lt;h4&gt;结论&lt;/h4&gt;TimeKAN提供了一种有效的解决方案，解决了由多频成分复杂交织导致的时间序列预测问题。其源代码已在GitHub上公开。&lt;h4&gt;翻译&lt;/h4&gt;真实世界中的时间序列通常包含多个频率成分，这些成分相互交织在一起，使得准确的时间序列预测变得具有挑战性。将混合的频率成分分解为多个单一频率成分是一种自然的选择。然而，不同频率下的模式信息密度各不相同，使用统一建模方法会导致特征描述不准。为了应对这一挑战，受最近Kolmogorov-Arnold网络（KAN）灵活性的启发，我们提出了一种基于KAN的时间分解学习架构TimeKAN来解决由多个频率混合造成的复杂预测问题。具体来说，TimeKAN主要包含三个组件：级联频率分解(CFD)块、多阶KAN表征学习(M-KAN)块和频率混合块。CFD块采用自底向上递进的方法获得每个频带的序列表示。得益于KAN的高度灵活性，我们设计了一种新的M-KAN模块来在每个频带内学习特定的时间模式并进行表征。最后，通过频率混合块将不同的频段重新组合为原始格式。广泛的实验结果表明，在多个现实世界时间序列数据集上，TimeKAN作为一个极其轻量级的架构实现了最先进的性能。源代码可在https://github.com/huangst21/TimeKAN获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world time series often have multiple frequency components that areintertwined with each other, making accurate time series forecastingchallenging. Decomposing the mixed frequency components into multiple singlefrequency components is a natural choice. However, the information density ofpatterns varies across different frequencies, and employing a uniform modelingapproach for different frequency components can lead to inaccuratecharacterization. To address this challenges, inspired by the flexibility ofthe recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based FrequencyDecomposition Learning architecture (TimeKAN) to address the complexforecasting challenges caused by multiple frequency mixtures. Specifically,TimeKAN mainly consists of three components: Cascaded Frequency Decomposition(CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks andFrequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach toobtain series representations for each frequency band. Benefiting from the highflexibility of KAN, we design a novel M-KAN block to learn and representspecific temporal patterns within each frequency band. Finally, FrequencyMixing blocks is used to recombine the frequency bands into the originalformat. Extensive experimental results across multiple real-world time seriesdatasets demonstrate that TimeKAN achieves state-of-the-art performance as anextremely lightweight architecture. Code is available athttps://github.com/huangst21/TimeKAN.</description>
      <author>example@mail.com (Songtao Huang, Zhen Zhao, Can Li, Lei Bai)</author>
      <guid isPermaLink="false">2502.06910v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06101v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf'25 (WWW'25) as a Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;大语言模型（LLMs）已应用于推荐系统以提高对用户行为的理解。检索增强生成（RAG）技术被进一步整合到这些系统中，以获取更相关项目并提升系统性能。&lt;h4&gt;背景&lt;/h4&gt;现有的RAG方法主要依赖于文本语义，并且通常未能整合最相关的项目，这限制了系统的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的推荐系统方法——用于检索增强的大语言模型推荐（RALLRec）。&lt;h4&gt;方法&lt;/h4&gt;通过提示大语言模型生成更详细的项目描述来增强文本语义；采用联合表示学习技术将提取的文本和协同语义结合起来。考虑到用户兴趣可能随时间变化，引入了一种简单的重新排序方法以捕捉用户偏好的动态性。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界的数据集上进行了广泛的实验，并且评估结果验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;代码已公开发布于https://github.com/JianXu95/RALLRec。&lt;h4&gt;翻译&lt;/h4&gt;大语言模型（LLMs）已经被融入到推荐系统中，以增强对用户行为的理解。检索增强生成（RAG）技术被进一步纳入这些系统，以便获取更相关的项目并提高系统的性能。然而，现有的RAG方法主要依赖于文本语义，并且常常无法整合最相关的内容，从而限制了系统的效果。在这篇论文中，我们提出了用于检索增强的大语言模型推荐的表示学习（RALLRec）。具体来说，通过提示大语言模型生成更详细的项目描述来增强文本语义；接着进行文本和协同语义的联合表示学习，这些分别由大语言模型和推荐模型提取。考虑到用户兴趣可能随时间变化的特点，我们还引入了一种简单但有效的重新排序方法以捕捉用户偏好的动态性。我们在三个真实数据集上进行了广泛的实验，并且评估结果验证了该方法的有效性。代码已公开发布于https://github.com/JianXu95/RALLRec。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been integrated into recommendation systemsto enhance user behavior comprehension. The Retrieval Augmented Generation(RAG) technique is further incorporated into these systems to retrieve morerelevant items and improve system performance. However, existing RAG methodsrely primarily on textual semantics and often fail to incorporate the mostrelevant items, limiting the effectiveness of the systems.  In this paper, we propose Representation learning for retrieval-AugmentedLarge Language model Recommendation (RALLRec). Specifically, we enhance textualsemantics by prompting LLMs to generate more detailed item descriptions,followed by joint representation learning of textual and collaborativesemantics, which are extracted by the LLM and recommendation models,respectively. Considering the potential time-varying characteristics of userinterest, a simple yet effective reranking method is further introduced tocapture the dynamics of user preference. We conducted extensive experiments onthree real-world datasets, and the evaluation results validated theeffectiveness of our method. Code is made public athttps://github.com/JianXu95/RALLRec.</description>
      <author>example@mail.com (Jian Xu, Sichun Luo, Xiangyu Chen, Haoming Huang, Hanxu Hou, Linqi Song)</author>
      <guid isPermaLink="false">2502.06101v2</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Topological derivative approach for deep neural network architecture adaptation</title>
      <link>http://arxiv.org/abs/2502.06885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新颖的算法，用于在网络深度增加的过程中逐步调整神经网络架构。&lt;h4&gt;背景&lt;/h4&gt;在进行神经网络训练时，如何有效地添加新的层次（容量）以及初始化这些新层次是一个重要的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在通过数学原理解决两个关键问题：何时、何地增加新层及如何初始化新增加的层次。&lt;h4&gt;方法&lt;/h4&gt;引入了'形状泛函'概念，并定义了相对于神经网络拓扑结构的形变导数。从最优控制的角度出发，探讨在一定条件下网络拓扑导数的存在性及其封闭形式表达式。&lt;h4&gt;主要发现&lt;/h4&gt;首次探索了形变导数与最优控制理论中的哈密顿量之间的联系，将形状泛函优化问题转化为深度神经架构适应过程中的特征值问题。提出了一种基于最优传输观点的插入新层策略，即在$p$-Wasserstein空间中最大化形变导数值。&lt;h4&gt;结论&lt;/h4&gt;通过全连接网络、卷积神经网络和视觉变换器在不同回归与分类任务上的实验表明，该方法可以超越基准网络及其他架构适应策略。此外还展示了拓扑导数在迁移学习等领域的其他应用。&lt;h4&gt;翻译&lt;/h4&gt;这项工作介绍了一种新颖的算法，用于在网络深度增加的过程中逐步调整神经网络结构。特别地，我们尝试以数学原理的方式解决以下问题：i) 在训练过程中何处添加新的容量（层）？ ii) 如何初始化新加入的能力？我们的方法的核心是两个关键成分：i) 引入'形状泛函'来最小化，并且它依赖于神经网络的拓扑结构，ii) 引入相对于神经网络拓扑结构的'形变导数'。从最优控制的角度出发，我们展示了在网络拓扑导数存在条件下的存在性及其封闭形式表达式被推导出来。特别地，首次探索了来自拓扑优化框架中的形变导数与最优控制理论中哈密顿量之间的联系。进一步的，展示出形状泛函的最佳条件导致深度神经架构适应过程中的特征值问题。因此该方法确定在训练期间沿深度需要插入新层的最敏感位置以及关联的新添加层次的参数初始化。还展示了我们的层次插入策略可以基于最优传输观点导出为$p$-Wasserstein空间中最大化形变导数值的解决方案。使用全连接网络、卷积神经网络和视觉变换器在各种回归与分类问题上的数值调查表明，所提出的方法可以超越基准网络及其他架构适应策略。此外还展示了拓扑导数在迁移学习等领域的其他应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a novel algorithm for progressively adapting neuralnetwork architecture along the depth. In particular, we attempt to address thefollowing questions in a mathematically principled way: i) Where to add a newcapacity (layer) during the training process? ii) How to initialize the newcapacity? At the heart of our approach are two key ingredients: i) theintroduction of a ``shape functional" to be minimized, which depends on neuralnetwork topology, and ii) the introduction of a topological derivative of theshape functional with respect to the neural network topology. Using an optimalcontrol viewpoint, we show that the network topological derivative exists undercertain conditions, and its closed-form expression is derived. In particular,we explore, for the first time, the connection between the topologicalderivative from a topology optimization framework with the Hamiltonian fromoptimal control theory. Further, we show that the optimality condition for theshape functional leads to an eigenvalue problem for deep neural architectureadaptation. Our approach thus determines the most sensitive location along thedepth where a new layer needs to be inserted during the training phase and theassociated parametric initialization for the newly added layer. We alsodemonstrate that our layer insertion strategy can be derived from an optimaltransport viewpoint as a solution to maximizing a topological derivative in$p$-Wasserstein space, where $p&gt;= 1$. Numerical investigations with fullyconnected network, convolutional neural network, and vision transformer onvarious regression and classification problems demonstrate that our proposedapproach can outperform an ad-hoc baseline network and other architectureadaptation strategies. Further, we also demonstrate other applications oftopological derivative in fields such as transfer learning.</description>
      <author>example@mail.com (C G Krishnanunni, Tan Bui-Thanh, Clint Dawson)</author>
      <guid isPermaLink="false">2502.06885v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Group Reasoning Emission Estimation Networks</title>
      <link>http://arxiv.org/abs/2502.06874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种基于人工智能的碳排放核算框架——Group Reasoning Emission Estimation Networks (GREEN)，旨在解决中小企业在温室气体排放报告中的挑战。&lt;h4&gt;背景&lt;/h4&gt;准确的温室气体（GHG）排放报告对政府、企业和投资者至关重要，但由于高昂的成本和缺乏标准化的方法，特别是在中小型企业中，实施仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的碳核算框架——Group Reasoning Emission Estimation Networks (GREEN)，以解决中小企业在温室气体排放报告中的实际问题。&lt;h4&gt;方法&lt;/h4&gt;构建了一个基于人工智能的碳会计框架（GREEN），通过编译具有验证过的北美行业分类系统标签的企业文本描述，使用对比学习损失对Sentence-BERT模型进行微调，并引入一种新的分组推理方法来处理大量的层级类别。&lt;h4&gt;主要发现&lt;/h4&gt;在1,114个NAICS类别的实验中，该框架达到了最先进的性能（Top-1准确率为83.68%，Top-10准确率为91.47%），并且20家公司的案例研究显示平均绝对百分比误差为45.88%。&lt;h4&gt;结论&lt;/h4&gt;GREEN框架提供了一种有效的方法来提高企业级温室气体排放报告的准确性，并有助于推动中小企业的可持续发展。&lt;h4&gt;翻译&lt;/h4&gt;精确的温室气体（GHG）排放报告对于政府、企业和投资者来说至关重要。然而，由于高昂的成本和缺乏标准化方法等问题，在中小企业中实施仍然有限。本文提出一种基于人工智能的碳会计框架——Group Reasoning Emission Estimation Networks (GREEN)，通过标准的企业级排放估算、大规模基准数据集以及与大型语言模型（LLMs）结合的新推理方法来解决这些问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate greenhouse gas (GHG) emission reporting is critical for governments,businesses, and investors. However, adoption remains limited particularly amongsmall and medium enterprises due to high implementation costs, fragmentedemission factor databases, and a lack of robust sector classification methods.To address these challenges, we introduce Group Reasoning Emission EstimationNetworks (GREEN), an AI-driven carbon accounting framework that standardizesenterprise-level emission estimation, constructs a large-scale benchmarkdataset, and leverages a novel reasoning approach with large language models(LLMs). Specifically, we compile textual descriptions for 20,850 companies withvalidated North American Industry Classification System (NAICS) labels andalign these with an economic model of carbon intensity factors. By reframingsector classification as an information retrieval task, we fine-tuneSentence-BERT models using a contrastive learning loss. To overcome thelimitations of single-stage models in handling thousands of hierarchicalcategories, we propose a Group Reasoning method that ensembles LLM classifiersbased on the natural NAICS ontology, decomposing the task into multiplesub-classification steps. We theoretically prove that this approach reducesclassification uncertainty and computational complexity. Experiments on 1,114NAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47%Top-10 accuracy), and case studies on 20 companies report a mean absolutepercentage error (MAPE) of 45.88%. The project is available at:https://huggingface.co/datasets/Yvnminc/ExioNAICS.</description>
      <author>example@mail.com (Yanming Guo, Xiao Qian, Kevin Credit, Jin Ma)</author>
      <guid isPermaLink="false">2502.06874v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的框架TRACK，用于动态道路网络和轨迹表示学习，以改善城市交通管理。&lt;h4&gt;背景&lt;/h4&gt;有效的城市交通管理对可持续城市发展至关重要。当前方法通常关注静态道路网络的特性以及路线表示的学习，忽略了交通状态和轨迹的动态性，这对下游任务来说是至关重要的。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架来填补传统方法忽视交通状态和轨迹动态性的空白。&lt;h4&gt;方法&lt;/h4&gt;{'TRACK框架': '利用图注意力网络（GAT）编码静态和空间道路分段特征，并引入基于变换器的模型进行路线表示学习。通过将转移概率从路线数据中纳入到GAT注意权重，捕捉道路分段的空间特性。同时设计了一个交通变换器编码器来从交通状态数据中捕捉道路分段的空间-时间动态。', '增强动态表示': '提出了一种共注意力转换器编码器和轨迹-交通状态匹配任务以进一步增强动态表示。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过在真实城市交通数据集上的大量实验，TRACK展示了其相对于最新基线的优越性，并且案例研究证实了其有效捕捉空间时间动态的能力。&lt;h4&gt;结论&lt;/h4&gt;TRACK框架为动态道路网络和轨迹表示学习提供了一种新的方法，能够更好地适应城市的实际需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective urban traffic management is vital for sustainable city development,relying on intelligent systems with machine learning tasks such as traffic flowprediction and travel time estimation. Traditional approaches usually focus onstatic road network and trajectory representation learning, and overlook thedynamic nature of traffic states and trajectories, which is crucial fordownstream tasks. To address this gap, we propose TRACK, a novel framework tobridge traffic state and trajectory data for dynamic road network andtrajectory representation learning. TRACK leverages graph attention networks(GAT) to encode static and spatial road segment features, and introduces atransformer-based model for trajectory representation learning. Byincorporating transition probabilities from trajectory data into GAT attentionweights, TRACK captures dynamic spatial features of road segments. Meanwhile,TRACK designs a traffic transformer encoder to capture the spatial-temporaldynamics of road segments from traffic state data. To further enhance dynamicrepresentations, TRACK proposes a co-attentional transformer encoder and atrajectory-traffic state matching task. Extensive experiments on real-lifeurban traffic datasets demonstrate the superiority of TRACK overstate-of-the-art baselines. Case studies confirm TRACK's ability to capturespatial-temporal dynamics effectively.</description>
      <author>example@mail.com (Chengkai Han, Jingyuan Wang, Yongyao Wang, Xie Yu, Hao Lin, Chao Li, Junjie Wu)</author>
      <guid isPermaLink="false">2502.06870v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation</title>
      <link>http://arxiv.org/abs/2502.06848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的预训练和迁移学习框架用于图网络物理模拟器，通过引入可扩展的图U-Net（SGUNET）模型，并结合自定义映射函数以及额外规范化项来实现不同配置下的模型参数对齐。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于图神经网络（GNN）的方法在复杂系统物理建模中取得了显著成效。然而，这些方法通常需要大量由传统物理模拟器生成的数据进行完全监督训练。&lt;h4&gt;目的&lt;/h4&gt;探讨迁移学习如何改善模型性能和训练效率，并提出一种适用于不同网格大小和分辨率的可扩展图U-Net（SGUNET）模型及其预训练策略。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了适应多种规模与细节需求的SGUNET架构，包含创新性的深度优先搜索（DFS）池化技术。           2. 设计了一套映射函数来实现不同配置下的模型参数对齐，并在损失中加入额外规范化项以约束预训练权重和目标模型间差异。           3. 利用大型物理模拟数据集，包含来自开源A Big CAD (ABC)数据库的20,000个随机选择三维物体的物理仿真。&lt;h4&gt;主要发现&lt;/h4&gt;提出的迁移学习方法使SGUNET在仅使用少量标记训练数据的情况下也能显著优于从头开始训练的方法。具体地，在二维变形板基准测试中，使用1/16的数据进行微调后，模型的位置均方根误差（RMSE）相较于完整数据集的模型提高了11.05％。&lt;h4&gt;结论&lt;/h4&gt;通过引入预训练和迁移学习技术到图网络物理模拟器框架中，可以显著提高模型性能并减少所需训练数据量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Graph Neural Network (GNN) based models have shown promisingresults in simulating physics of complex systems. However, training dedicatedgraph network based physics simulators can be costly, as most models areconfined to fully supervised training, which requires extensive data generatedfrom traditional physics simulators. To date, how transfer learning couldimprove the model performance and training efficiency has remained unexplored.In this work, we introduce a pre-training and transfer learning paradigm forgraph network simulators. We propose the scalable graph U-net (SGUNET).Incorporating an innovative depth-first search (DFS) pooling, the SGUNET isadaptable to different mesh sizes and resolutions for various simulation tasks.To enable the transfer learning between differently configured SGUNETs, wepropose a set of mapping functions to align the parameters between thepre-trained model and the target model. An extra normalization term is alsoadded into the loss to constrain the difference between the pre-trained weightsand target model weights for better generalization performance. To pre-trainour physics simulator we created a dataset which includes 20,000 physicalsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)dataset. We show that our proposed transfer learning methods allow the model toperform even better when fine-tuned with small amounts of training data thanwhen it is trained from scratch with full extensive dataset. On the 2DDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 ofthe training data achieved an 11.05\% improvement in position RMSE compared tothe model trained from scratch.</description>
      <author>example@mail.com (Siqi Shen, Yu Liu, Daniel Biggs, Omar Hafez, Jiandong Yu, Wentao Zhang, Bin Cui, Jiulong Shan)</author>
      <guid isPermaLink="false">2502.06848v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Hyper Compressed Fine-Tuning of Large Foundation Models with Quantum Inspired Adapters</title>
      <link>http://arxiv.org/abs/2502.06916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种受量子机器学习文献中哈明权重保持的量子电路启发的参数高效微调方法Quantum-Inspired Adapters，旨在解决大规模预训练模型在特定任务上微调时由于计算和存储需求而带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;传统的全参数更新方法在处理大规模预训练语言和视觉模型时因计算和存储需求问题变得日益困难。为此，参数高效微调（PEFT）方法通过仅对一小部分模型参数进行更新来解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种受量子机器学习中哈明权重保持的量子电路启发的新PEFT方法Quantum-Inspired Adapters，并在基准数据集上验证其效果和效率。&lt;h4&gt;方法&lt;/h4&gt;利用量子机学习文献中的哈明权保存量子电路原理，开发了一种新的微调方法Quantum-Inspired Adapters。该方法允许模型同时操作在组合空间中运行并保持权重参数的正交性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有的LoRA等其他微调方法相比，在语言理解和视觉任务上，所提出的Quantum-Inspired Adapters可以达到98%以上的性能，同时实现44倍和25倍的参数压缩。通过消融研究确定了结合多个哈明权重顺序、正交性以及矩阵组合对于高效微调至关重要。&lt;h4&gt;结论&lt;/h4&gt;研究表明，Quantum-Inspired Adapters为语言和视觉模型在资源受限环境中的有效适应提供了一种有前景的方向，并且该方法同时提供了与现有最佳性能相当的精度，但参数更少。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large foundation models for specific tasks has becomeincreasingly challenging due to the computational and storage demandsassociated with full parameter updates. Parameter-Efficient Fine-Tuning (PEFT)methods address this issue by updating only a small subset of model parametersusing adapter modules. In this work, we propose \emph{Quantum-InspiredAdapters}, a PEFT approach inspired by Hamming-weight preserving quantumcircuits from quantum machine learning literature. These models can be bothexpressive and parameter-efficient by operating in a combinatorially largespace while simultaneously preserving orthogonality in weight parameters. Wetest our proposed adapters by adapting large language models and large visiontransformers on benchmark datasets. Our method can achieve 99.2\% of theperformance of existing fine-tuning methods such LoRA with a 44x parametercompression on language understanding datasets like GLUE and VTAB. Compared toexisting orthogonal fine-tuning methods such as OFT or BOFT, we achieve 98\%relative performance with 25x fewer parameters. This demonstrates competitiveperformance paired with a significant reduction in trainable parameters.Through ablation studies, we determine that combining multiple Hamming-weightorders with orthogonality and matrix compounding are essential for performantfine-tuning. Our findings suggest that Quantum-Inspired Adapters offer apromising direction for efficient adaptation of language and vision models inresource-constrained environments.</description>
      <author>example@mail.com (Snehal Raj, Brian Coyle)</author>
      <guid isPermaLink="false">2502.06916v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Anomaly Detection: Vision and Challenges</title>
      <link>http://arxiv.org/abs/2502.06911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;论文综述了基于基础模型（FMs）的异常检测领域的最新进展，提出了一个新颖的分类体系，并系统分析了当前最佳实践和面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;在金融、制造、医疗等各个领域中，数据量和复杂性持续增长。有效的异常检测对于识别可能预示着关键问题的不规则模式至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出首个基于基础模型（FMs）进行异常检测的研究综述，分析先进方法并探讨未来研究方向。&lt;h4&gt;方法&lt;/h4&gt;将基础模型分类为编码器、检测器或解释器三类，并对这些角色进行了系统的状态评估和挑战讨论。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在增强异常识别能力、生成详细数据描述及提供可视化解释方面显示出了前所未有的潜力。&lt;h4&gt;结论&lt;/h4&gt;概述了利用基础模型进行改进异常检测的关键挑战以及未来研究方向，特别是在快速发展的该领域中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As data continues to grow in volume and complexity across domains such asfinance, manufacturing, and healthcare, effective anomaly detection isessential for identifying irregular patterns that may signal critical issues.Recently, foundation models (FMs) have emerged as a powerful tool for advancinganomaly detection. They have demonstrated unprecedented capabilities inenhancing anomaly identification, generating detailed data descriptions, andproviding visual explanations. This survey presents the first comprehensivereview of recent advancements in FM-based anomaly detection. We propose a noveltaxonomy that classifies FMs into three categories based on their roles inanomaly detection tasks, i.e., as encoders, detectors, or interpreters. Weprovide a systematic analysis of state-of-the-art methods and discuss keychallenges in leveraging FMs for improved anomaly detection. We also outlinefuture research directions in this rapidly evolving field.</description>
      <author>example@mail.com (Jing Ren, Tao Tang, Hong Jia, Haytham Fayek, Xiaodong Li, Suyu Ma, Xiwei Xu, Feng Xia)</author>
      <guid isPermaLink="false">2502.06911v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming</title>
      <link>http://arxiv.org/abs/2502.07772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LLM-GP-BT技术，利用大型语言模型和遗传编程自动化生成和配置行为树（BT），以提高机器人任务规划的准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;精确的任务规划对自主系统的控制至关重要。行为树框架因其模块化、灵活性和可重用性在任务规划中被广泛认为是最重要的控制策略定义框架之一，但基于BT的控制政策生成仍然具有挑战性，需要领域专业知识。&lt;h4&gt;目的&lt;/h4&gt;通过利用大型语言模型（LLM）和遗传编程（GP），自动地将机器人任务命令从人类自然语言转换为准确可靠的基于行为树的任务计划。&lt;h4&gt;方法&lt;/h4&gt;提出了LLM-GP-BT技术，该技术处理用自然语言表达的机器人任务指令，并以计算高效且用户友好的方式将其转化为基于行为树的任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟实验系统地开发和验证了提出的LLM-GP-BT技术，证明其在简化自主系统的任务规划方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;LLM-GP-BT技术为自动化生成准确的基于行为树的任务计划提供了可能，这将有助于减少对领域专业知识的需求，并提高机器人等自治系统任务规划的效率和可靠性。&lt;h4&gt;翻译&lt;/h4&gt;准确的任务规划对于控制诸如机器人、无人机和自动驾驶车辆之类的自主系统至关重要。行为树（BT）因其模块化、灵活性和可重用性而被视为任务规划中最突出的控制策略定义框架之一。然而，生成可靠的基于BT的控制政策仍然具有挑战性，并通常需要领域专业知识。在本文中，我们提出了一种LLM-GP-BT技术，该技术利用大型语言模型（LLM）和遗传编程（GP）来自动化生成和配置行为树。LLM-GP-BT技术处理用人类自然语言表达的机器人任务命令，并以计算高效且用户友好的方式将其转化为准确可靠的基于行为树的任务计划。所提出的这项技术通过模拟实验系统地开发并验证，展示了其在简化自主系统的任务规划方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate task planning is critical for controlling autonomous systems, suchas robots, drones, and self-driving vehicles. Behavior Trees (BTs) areconsidered one of the most prominent control-policy-defining frameworks in taskplanning, due to their modularity, flexibility, and reusability. Generatingreliable and accurate BT-based control policies for robotic systems remainschallenging and often requires domain expertise. In this paper, we present theLLM-GP-BT technique that leverages the Large Language Model (LLM) and GeneticProgramming (GP) to automate the generation and configuration of BTs. TheLLM-GP-BT technique processes robot task commands expressed in human naturallanguage and converts them into accurate and reliable BT-based task plans in acomputationally efficient and user-friendly manner. The proposed technique issystematically developed and validated through simulation experiments,demonstrating its potential to streamline task planning for autonomous systems.</description>
      <author>example@mail.com (Azizjon Kobilov, Jianglin Lan)</author>
      <guid isPermaLink="false">2502.07772v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove</title>
      <link>http://arxiv.org/abs/2502.07730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了一种名为DOGlove的低成本、精密且具有触觉力反馈的手套系统，旨在改进远程操作和机器人抓取任务。该系统可以快速组装并在经济实惠的价格范围内提供精确的动作捕捉和多方向的力反馈。&lt;h4&gt;背景&lt;/h4&gt;灵巧手遥操作系统在实现机器人的人类级别抓握技巧方面发挥着关键作用，但当前系统往往依赖昂贵设备且缺乏多模态感官反馈，限制了操作员感知物体特性和执行复杂任务的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种低成本、精确且具有触觉力反馈的远程手套系统，以改进现有的遥操作系统并提高操作灵活性和精度。&lt;h4&gt;方法&lt;/h4&gt;DOGlove采用定制化的关节结构实现21自由度动作捕捉，使用紧凑型缆绳驱动扭矩传输机制提供5自由度多方向力反馈，并利用线性共振执行器为指尖触觉反馈提供支持。此外还探讨了无视觉反馈情况下的操作性能和模仿学习策略训练。&lt;h4&gt;主要发现&lt;/h4&gt;DOGlove系统能够实现精确且沉浸式的灵巧手远程操作，成功完成复杂、接触密集的任务。研究显示在缺乏视觉反馈的情况下触觉力反馈对任务表现至关重要。&lt;h4&gt;结论&lt;/h4&gt;通过开源硬件和软件系统，DOGlove展示了其潜力和有效性，在改进人类与机器人交互的方式方面具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;灵巧手遥操作对于实现机器人的高级抓握技巧至关重要。然而，现有的远程操作系统往往依赖于昂贵的设备，并且缺乏多模态感官反馈，限制了人类操作员感知物体属性并执行复杂任务的能力。为了克服这些局限性，我们提出了一种名为DOGlove的手套系统，这是一种低成本、精确且具备触觉力反馈的解决方案，适用于遥操作和抓取应用。该手套可在数小时内组装完成，并且成本低于600美元。它具有21自由度动作捕捉所需的定制关节结构，使用紧凑型缆绳驱动扭矩传输机制实现5自由度多方向力反馈，并通过线性共振执行器提供指尖的5自由度触觉反馈。利用行动和力反馈重定向技术，DOGlove实现了灵巧机器人手精确且沉浸式的远程操作，在复杂、接触密集的任务中取得了高成功率。我们进一步在无视觉反馈的情况下评估了DOGlove的表现，展示了触觉力反馈对任务性能的关键作用。此外，我们还收集演示以训练模仿学习策略，突显了DOGlove的潜力和效果。DOGlove的硬件与软件系统将在https://do-glove.github.io/上完全开源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous hand teleoperation plays a pivotal role in enabling robots toachieve human-level manipulation dexterity. However, current teleoperationsystems often rely on expensive equipment and lack multi-modal sensoryfeedback, restricting human operators' ability to perceive object propertiesand perform complex manipulation tasks. To address these limitations, wepresent DOGlove, a low-cost, precise, and haptic force feedback glove systemfor teleoperation and manipulation. DoGlove can be assembled in hours at a costunder 600 USD. It features a customized joint structure for 21-DoF motioncapture, a compact cable-driven torque transmission mechanism for 5-DoFmultidirectional force feedback, and a linear resonate actuator for 5-DoFfingertip haptic feedback. Leveraging action and haptic force retargeting,DOGlove enables precise and immersive teleoperation of dexterous robotic hands,achieving high success rates in complex, contact-rich tasks. We furtherevaluate DOGlove in scenarios without visual feedback, demonstrating thecritical role of haptic force feedback in task performance. In addition, weutilize the collected demonstrations to train imitation learning policies,highlighting the potential and effectiveness of DOGlove. DOGlove's hardware andsoftware system will be fully open-sourced at https://do-glove.github.io/.</description>
      <author>example@mail.com (Han Zhang, Songbo Hu, Zhecheng Yuan, Huazhe Xu)</author>
      <guid isPermaLink="false">2502.07730v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Ultrafast 4D scanning transmission electron microscopy for imaging of localized optical fields</title>
      <link>http://arxiv.org/abs/2502.07338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v1: preprint; licence: CC BY 4.0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的超快4D扫描透射电子显微镜技术，该技术能够在避免使用电子光谱过滤的情况下成像光学近场的横向分量。&lt;h4&gt;背景&lt;/h4&gt;超高频电子显微术的目标是成像纳米尺度上的瞬变现象，并可视化由相干激发在各种类型的纳米结构附近产生的局部光学和等离子体模式。这种成像能力是由基于通过非弹性散射的光谱筛选电子与近场相互作用所激发的光子诱导近场光学显微镜实现。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的超快4D扫描透射电子显微镜技术，该技术能够避免使用电子光谱筛选来成像光学近场的横向分量，并展示这种方法的能力。&lt;h4&gt;方法&lt;/h4&gt;采用新发展的超快4D扫描传输电子显微镜技术对钨纳米尖端和光学驻波的ponderomotive势进行成像。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够以21 nm的空间分辨率对钨纳米尖端和光学驻波的ponderomotive势的光学近场进行成像。&lt;h4&gt;结论&lt;/h4&gt;新开发的技术提供了一种新的方法，可以在不使用电子光谱筛选的情况下成像光学近场的横向分量，并展示了这种方法的实用性与高效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的英文原文内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultrafast electron microscopy aims for imaging transient phenomena occurringon nanoscale. One of its goals is to visualize localized optical and plasmonicmodes generated by coherent excitation in the vicinity of various types ofnanostructures. Such imaging capability was enabled by photon-inducednear-field optical microscopy, which is based on spectral filtering ofelectrons inelastically scattered due to the stimulated interaction with thenear-field. Here we report on the development of ultrafast 4D scanningtransmission electron microscopy, which allows us to image the transversecomponents of the optical near-field while avoiding the need of electronspectral filtering. We demonstrate that this method is capable of imagingoptical near-fields of a tungsten nanotip and ponderomotive potential of anoptical standing wave with a spatial resolution of 21 nm.</description>
      <author>example@mail.com (Petr Koutenský, Neli Laštovičková Streshkova, Kamila Moriová, Marius Constantin Chirita Mihaila, Daniel Burda, Alexandr Knápek, Martin Kozák)</author>
      <guid isPermaLink="false">2502.07338v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>DeepVL: Dynamics and Inertial Measurements-based Deep Velocity Learning for Underwater Odometry</title>
      <link>http://arxiv.org/abs/2502.07726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the 2025 IEEE International Conference  on Robotics &amp; Automation (ICRA 2025), Atlanta, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种通过动力学感知本体感觉预测水下机器人中心速度的模型。该方法利用递归神经网络，以惯性线索、电机命令和电池电压读数以及前一时间步的隐藏状态作为输入，输出稳健的速度估计及其相关不确定性。&lt;h4&gt;背景&lt;/h4&gt;现有的水下导航技术通常依赖于外部感知来提供长期定位。然而，在视觉信息不可用的情况下，这些方法可能无法提供准确的位置估计。&lt;h4&gt;目的&lt;/h4&gt;开发一种通过结合内部传感器数据和神经网络预测速度的方法，以实现无需额外外部感知的长期水下载具定位。&lt;h4&gt;方法&lt;/h4&gt;利用递归神经网络模型处理惯性线索、电机命令和电池电压读数等信息，并融合网络输出到扩展卡尔曼滤波器中。该模型使用少量特征进行增强型视觉惯性里程估计，减少对完整视觉数据的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在完全没有视觉信息的情况下，所提出的方法仍能提供小于4%相对位置误差的定位精度；即使在单目相机仅跟踪最多2个视觉特征时，相对误差也保持在约2%左右。测试中模型的推断速度低于5ms。&lt;h4&gt;结论&lt;/h4&gt;通过利用动力学感知本体感觉预测技术，可以显著提升水下机器人的自主导航能力，在完全缺乏外部感知信息的情况下仍能实现高精度定位。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种学习型模型，用于通过动力学感知的本体感受来预测水下机器人以机器人为中心的速度。这种方法利用递归神经网络作为输入，使用惯性提示、电机命令和电池电压读数以及前一个时间步的隐藏状态输出稳健的速度估计及其相关不确定性。使用一组网络增强了速度和不确定性的预测能力。将网络输出与惯性预测和气压更新融合到扩展卡尔曼滤波器中，该方法允许在没有进一步外部感知的情况下实现长期水下载具里程计定位。此外，在集成视觉惯性里程计时，该方法有助于增强估计的鲁棒性，当跟踪的总特征数量（低至1个）比传统视觉惯性系统少一个数量级时。实验是在一台部署于实验室游泳池和特隆赫姆峡湾的水下机器人上进行的，模型在NVIDIA Orin AGX的CPU或GPU上的推理时间不到5ms，在完全黑视情况下新轨迹中的相对位置误差小于4%，当单目相机最多跟踪2个视觉特征时，相对误差约为2%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a learned model to predict the robot-centric velocity ofan underwater robot through dynamics-aware proprioception. The method exploitsa recurrent neural network using as inputs inertial cues, motor commands, andbattery voltage readings alongside the hidden state of the previous time-stepto output robust velocity estimates and their associated uncertainty. Anensemble of networks is utilized to enhance the velocity and uncertaintypredictions. Fusing the network's outputs into an Extended Kalman Filter,alongside inertial predictions and barometer updates, the method enableslong-term underwater odometry without further exteroception. Furthermore, whenintegrated into visual-inertial odometry, the method assists in enhancedestimation resilience when dealing with an order of magnitude fewer totalfeatures tracked (as few as 1) as compared to conventional visual-inertialsystems. Tested onboard an underwater robot deployed both in a laboratory pooland the Trondheim Fjord, the method takes less than 5ms for inference either onthe CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than 4% relativeposition error in novel trajectories during complete visual blackout, andapproximately 2% relative error when a maximum of 2 visual features from amonocular camera are available.</description>
      <author>example@mail.com (Mohit Singh, Kostas Alexis)</author>
      <guid isPermaLink="false">2502.07726v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning</title>
      <link>http://arxiv.org/abs/2502.07600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PlaySlot是一个用于预测未来场景表示的物体中心视频预测模型，它能够从无标注视频数据中推断出物体状态和潜在动作，并根据这些信息生成未来的可能情况。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数方法依赖于带有精确动作注释的视频序列或模拟环境来进行场景表示的预测。这种方式限制了对大量未标记视频数据的有效利用。&lt;h4&gt;目的&lt;/h4&gt;提出PlaySlot模型，以解决现有方法不能充分利用无标签视频数据的问题，并实现机器人对未来场景的理解和互动能力。&lt;h4&gt;方法&lt;/h4&gt;PlaySlot通过推断物体在无标注视频序列中的表示以及潜在动作来预测未来的物体状态和帧。它可以生成基于学习的行动策略、用户提供的或者从视频动态中推导出的多个可能的未来情况。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PlaySlot模型不仅能够超越传统随机和以对象为中心的基准线进行视频预测，在各种环境中也表现出色；同时，它的潜在动作可以用来高效地学习机器人行为，仅基于未标记的视频演示。&lt;h4&gt;结论&lt;/h4&gt;通过从无标注视频数据中推断出的物体表示与潜在动作，PlaySlot提供了一种灵活且可解释的方法来建模世界，并能有效提升机器人的交互性能。&lt;h4&gt;翻译&lt;/h4&gt;预测未来场景表示是使机器人能够理解和互动环境的关键任务。然而，现有的大多数方法依赖于带有精确动作注释的视频序列和模拟，这限制了它们利用大量可用无标签视频数据的能力。为了解决这一挑战，我们提出了PlaySlot模型，这是一种基于物体中心视角的视频预测模型，可以从无标注视频序列中推断出物体表示和潜在动作，并使用这些表示来预测未来物体状态和帧。PlaySlot可以生成多个基于学习策略、用户提供的或从视频动态中推测出的动作条件下的可能未来情况，从而实现灵活且可解释的世界建模。我们的实验结果表明，PlaySlot在视频预测方面超越了随机及以对象为中心的基准线，在不同环境中表现优异；此外，我们证明了可以使用推断出的潜在动作来有效学习机器人行为，仅基于无标签视频演示数据即可。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting future scene representations is a crucial task for enabling robotsto understand and interact with the environment. However, most existing methodsrely on video sequences and simulations with precise action annotations,limiting their ability to leverage the large amount of available unlabeledvideo data. To address this challenge, we propose PlaySlot, an object-centricvideo prediction model that infers object representations and latent actionsfrom unlabeled video sequences. It then uses these representations to forecastfuture object states and video frames. PlaySlot allows to generate multiplepossible futures conditioned on latent actions, which can be inferred fromvideo dynamics, provided by a user, or generated by a learned action policy,thus enabling versatile and interpretable world modeling. Our results show thatPlaySlot outperforms both stochastic and object-centric baselines for videoprediction across different environments. Furthermore, we show that ourinferred latent actions can be used to learn robot behaviors sample-efficientlyfrom unlabeled video demonstrations. Videos and code are available athttps://play-slot.github.io/PlaySlot/.</description>
      <author>example@mail.com (Angel Villar-Corrales, Sven Behnke)</author>
      <guid isPermaLink="false">2502.07600v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Coverage Control for Time-Varying Spatial Processes</title>
      <link>http://arxiv.org/abs/2502.07595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种分布式控制策略，该策略利用高斯过程建模空间场，并平衡学习空间场与优化覆盖之间的权衡。此方法适用于时间变化的空间领域。&lt;h4&gt;背景&lt;/h4&gt;多机器人系统在环境监测中起着关键作用，尤其是在跟踪污染、土壤矿物质和水盐度等空间现象方面。然而，在分布密度未知且随时间变化的环境中部署多机器人团队存在挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种有效的方法来应对上述挑战，特别是在时空变化的领域内实现最优覆盖的问题。&lt;h4&gt;方法&lt;/h4&gt;采用高斯过程建模技术，并结合分布式控制策略，每个机器人仅使用其自身收集的数据及邻居机器人的信息进行操作。同时利用算法高效处理数据量问题，只选择最相关的样本用于估计。&lt;h4&gt;主要发现&lt;/h4&gt;通过多种模拟和实验评估了所提算法的性能，这些实验包括实际现象，验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究提供了一种新颖的方法来解决时空变化环境下的多机器人覆盖优化问题。这种方法在时间和空间上都动态调整探索与利用之间的权衡，并且具有分布式特性和计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多机器人系统对于环境监测至关重要，尤其是在跟踪污染、土壤矿物质和水盐度等空间现象方面更为重要。这项研究解决了在分布密度未知并且随时间变化的环境中部署多机器人团队以实现最优覆盖的问题。我们提出了一种完全分散的控制策略，利用高斯过程（GPs）来建模空间场，并平衡学习该领域与优化覆盖之间的权衡。不同于现有方法，我们在更具现实性的场景下处理时间变化的空间域，在此场景中探索与开发之间的折衷会随时间动态调整。每个机器人仅使用其自身收集的数据和邻近机器人的信息操作。为了应对高斯过程的计算限制，该算法通过选择最相关的样本进行流程估计来有效管理数据量。通过多个模拟和实验评估了所提议算法的表现，并结合实际世界现象数据证明了它的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TRO.2025.3539168&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot systems are essential for environmental monitoring, particularlyfor tracking spatial phenomena like pollution, soil minerals, and watersalinity, and more. This study addresses the challenge of deploying amulti-robot team for optimal coverage in environments where the densitydistribution, describing areas of interest, is unknown and changes over time.We propose a fully distributed control strategy that uses Gaussian Processes(GPs) to model the spatial field and balance the trade-off between learning thefield and optimally covering it. Unlike existing approaches, we address a morerealistic scenario by handling time-varying spatial fields, where theexploration-exploitation trade-off is dynamically adjusted over time. Eachrobot operates locally, using only its own collected data and the informationshared by the neighboring robots. To address the computational limits of GPs,the algorithm efficiently manages the volume of data by selecting only the mostrelevant samples for the process estimation. The performance of the proposedalgorithm is evaluated through several simulations and experiments,incorporating real-world data phenomena to validate its effectiveness.</description>
      <author>example@mail.com (Federico Pratissoli, Mattia Mantovani, Amanda Prorok, Lorenzo Sabattini)</author>
      <guid isPermaLink="false">2502.07595v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Dual Arm Steering of Deformable Linear Objects in 2-D and 3-D Environments Using Euler's Elastica Solutions</title>
      <link>http://arxiv.org/abs/2502.07509v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种使用两个机械手操纵变形线性物体的方法，特别是在存在稀疏障碍物的环境中。&lt;h4&gt;背景&lt;/h4&gt;在环境中有稀疏分布的障碍物时，需要一种方法来引导和控制柔性的、不可伸长的线性对象。现有技术可能不完全适用于这种场景。&lt;h4&gt;目的&lt;/h4&gt;开发一套理论框架和技术方案，确保使用两个机械手操纵柔性线性物体时能够避免自我碰撞，并保证稳定性和避开环境中的障碍物。&lt;h4&gt;方法&lt;/h4&gt;该论文采用闭合形式解来描述二维环境中可变形的线性对象形状（欧拉弹性曲线），并根据这些解决方案制定了非自交、稳定性及避障标准。所有安全准则被整合进一个方案中，用于引导柔性线性物体在二维和三维环境中的移动。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新颖的标准以确保柔韧物件的稳定性，并成功将该方法应用于双臂机械手实验验证。&lt;h4&gt;结论&lt;/h4&gt;通过理论推导和实际操作展示了这种方法的有效性和可行性。未来的研究可以探讨更复杂的障碍物环境及更加灵活的控制策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes a method for steering deformable linear objects usingtwo robot hands in environments populated by sparsely spaced obstacles. Theapproach involves manipulating an elastic inextensible rod by varying thegripping endpoint positions and tangents. Closed form solutions that describethe flexible linear object shape in planar environments, Euler's elastica, aredescribed. The paper uses these solutions to formulate criteria for nonself-intersection, stability and obstacle avoidance. These criteria areformulated as constraints in the flexible object six-dimensional configurationspace that represents the robot gripping endpoint positions and tangents. Inparticular, this paper introduces a novel criterion that ensures the flexibleobject stability during steering. All safety criteria are integrated into ascheme for steering flexible linear objects in planar environments, which islifted into a steering scheme in three-dimensional environments populated bysparsely spaced obstacles. Experiments with a dual-arm robot demonstrate themethod.</description>
      <author>example@mail.com (Aharon Levin, Itay Grinberg, Elon Rimon, Amir Shapiro)</author>
      <guid isPermaLink="false">2502.07509v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Blind Eye: Motion and Obstacle Detection Leveraging Wi-Fi</title>
      <link>http://arxiv.org/abs/2502.07493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Wi-Fi技术通过提供平滑的网络连接，彻底改变了无线网络环境。本文研究了设备与接入点之间的信号接收差异，并探索这些差异在特定应用场景中的潜在价值。&lt;h4&gt;背景&lt;/h4&gt;Wi-Fi利用无线电通讯，在接近接入点时可以有效工作。但设备接收到的Wi-Fi信号强度会因障碍物或移动而变化。&lt;h4&gt;目的&lt;/h4&gt;创造性地使用Wi-Fi信号差异来开发能够检测封闭区域内运动的应用程序。&lt;h4&gt;方法&lt;/h4&gt;研究当前无线基础设施，利用现有的Wi-Fi技术而不需额外硬件进行应用开发。&lt;h4&gt;主要发现&lt;/h4&gt;可以将这些信号强度的变化应用于改进安全系统或为复杂机器人提供支持。&lt;h4&gt;结论&lt;/h4&gt;通过挖掘现有Wi-Fi信号的不一致性，可以在无需增加新硬件的情况下实现新的功能和用途。&lt;h4&gt;翻译&lt;/h4&gt;无线保真技术（即Wi-Fi）已经彻底改变了无线网络环境，特别是在封闭空间内提供了平滑的互联网和网络连接。与大多数无线技术一样，它依赖于无线电通讯来工作。这意味着，设备靠近接入点时可以有效接收信号，但根据障碍物或移动的不同，这种接收效果会有较大差异。研究团队利用这些变化作为机会开发出用于检测封闭区域内运动的应用程序。该方法不需要额外的硬件支持，因为它仅使用现有的无线基础设施。此类应用可以在增强安全系统、提高机器人复杂性等方面发挥重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wireless Fidelity or Wi-Fi, has completely transfigured wireless networkingby offering a smooth connection to the internet and networks, particularly whendealing with enclosed environments. As with the majority of wirelesstechnology, it functions through radio communication. This makes it possiblefor Wi-Fi to operate effectively close to an Access Point. However, a device'sability to receive Wi-Fi signals can vary greatly. These discrepancies arisebecause of impediments or motions between the device and the access point. Wehave creatively used these variances as unique opportunities for applicationsthat can be used to detect movement in confined areas. As this approach makesuse of the current wireless infrastructure, no additional hardware is required.These applications could potentially be leveraged to enable sophisticatedrobots or enhance security systems.</description>
      <author>example@mail.com (Aditya Mitra, Anisha Ghosh, Sibi Chakkaravarthy S, Devi Priya VS)</author>
      <guid isPermaLink="false">2502.07493v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Robotic In-Hand Manipulation for Large-Range Precise Object Movement: The RGMC Champion Solution</title>
      <link>http://arxiv.org/abs/2502.07472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to RA-L. Project website:  https://rgmc-xl-team.github.io/ingrasp_manipulation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用手指运动在稳定抓握下实现高精度和大范围物体移动的方法，这种方法不依赖于预训练或物体几何信息，并且适用于真实场景中的新对象。&lt;h4&gt;背景&lt;/h4&gt;手内操作是一项关键的机器人技能，它可以通过多指灵巧操作减少对大型臂部动作的需求，从而节省空间和能量。在稳定抓握下进行物体移动是该领域的重点问题之一。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单实用的方法来解决手内对象运动中精度与范围同时实现的问题，并展示其在真实场景中的应用效果。&lt;h4&gt;方法&lt;/h4&gt;采用基于动力学轨迹优化的方案，无需预训练或物体几何信息的支持。&lt;h4&gt;主要发现&lt;/h4&gt;通过参加ICRA 2024举办的第九届机器人抓取和操作竞赛（RGMC）的手内操作项目并获得冠军，验证了该方法的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;论文详细介绍了实施方案、讨论及进一步的实验结果，以全面评估提出的方法，并分享在比赛中取得的关键经验。补充材料包括视频和代码可从指定链接获取。&lt;h4&gt;翻译&lt;/h4&gt;手内操作利用多指灵巧性是减少对大型臂部动作依赖的一项关键机器人技能，可以节省空间和能量。本文重点在于抓握内的物体移动，即通过手指运动将物体调整到期望姿态，并且在稳定抓握状态下实现这一点。挑战在于同时达到高精度与大范围的动作的同时保持稳定的抓握状态。为解决这一问题，我们提出了一种简单实用的方法，基于动力学轨迹优化，无需预训练或物体几何信息的参与，易于应用于真实场景中的新对象。采用这种方法，在ICRA 2024举办的第九届机器人抓取和操作竞赛的手内操作项目中获得了冠军。论文详细介绍了实施方案、讨论及进一步的实验结果，以全面评估提出的方法，并分享在比赛中取得的关键经验。补充材料包括视频和代码可从https://rgmc-xl-team.github.io/ingrasp_manipulation获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-hand manipulation using multiple dexterous fingers is a critical roboticskill that can reduce the reliance on large arm motions, thereby saving spaceand energy. This letter focuses on in-grasp object movement, which refers tomanipulating an object to a desired pose through only finger motions within astable grasp. The key challenge lies in simultaneously achieving high precisionand large-range movements while maintaining a constant stable grasp. To addressthis problem, we propose a simple and practical approach based on kinematictrajectory optimization with no need for pretraining or object geometries,which can be easily applied to novel objects in real-world scenarios. Adoptingthis approach, we won the championship for the in-hand manipulation track atthe 9th Robotic Grasping and Manipulation Competition (RGMC) held at ICRA 2024.Implementation details, discussion, and further quantitative experimentalresults are presented in this letter, which aims to comprehensively evaluateour approach and share our key takeaways from the competition. Supplementarymaterials including video and code are available athttps://rgmc-xl-team.github.io/ingrasp_manipulation .</description>
      <author>example@mail.com (Mingrui Yu, Yongpeng Jiang, Chen Chen, Yongyi Jia, Xiang Li)</author>
      <guid isPermaLink="false">2502.07472v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Demonstrating Wheeled Lab: Modern Sim2Real for Low-cost, Open-source Wheeled Robotics</title>
      <link>http://arxiv.org/abs/2502.07380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Wheeled Lab是一个低成本、开源的轮式机器人平台框架，旨在促进先进仿真到现实技术的应用。&lt;h4&gt;背景&lt;/h4&gt;近年来机器人领域的重大进展依赖于昂贵和高维护成本的平台，限制了更广泛的受众接触这些先进技术的机会。&lt;h4&gt;目的&lt;/h4&gt;介绍一个名为Wheeled Lab的框架，该框架使用低成本、开源轮式平台，并结合Isaac Lab进行Sim2Real技术的应用。&lt;h4&gt;方法&lt;/h4&gt;通过集成现代Sim2Real技术（如领域随机化、传感器仿真和端到端学习）进入新的用户社区。为启动教育并展示框架的能力，开发了三项针对小型遥控车的先进策略：控制漂移、攀爬斜坡和视觉导航。&lt;h4&gt;主要发现&lt;/h4&gt;Wheeled Lab通过整合先进的Sim2Real技术和低成本、易获取的机器人平台，缩小了技术差距，并促进了更广泛范围内的创新与教育。&lt;h4&gt;结论&lt;/h4&gt;该框架从硬件到软件都是低价格且开源，致力于使先进工具更加普及，促进更大范围内机器人的创新和教育。&lt;h4&gt;翻译&lt;/h4&gt;仿真在最近的机器人里程碑中至关重要，并将在未来领域发挥重要作用。然而，最新的机器人进展往往依赖于昂贵、维护成本高的平台，这限制了更广泛受众接触这些技术的机会。本工作介绍了Wheeled Lab框架，这是一个面向低成本、开源轮式平台（这些平台已经在教育和研究中广泛应用）的框架。通过与Isaac Lab集成，Wheeled Lab引入了现代Sim2Real技术，如领域随机化、传感器仿真及端到端学习，为新的用户社区提供服务。为了启动教育并展示框架的能力，我们为小型遥控车开发了三种最先进的策略：控制漂移、攀爬斜坡和视觉导航，这些策略在仿真中训练并在现实世界部署。通过结合先进的Sim2Real技术和低成本可获取的机器人平台，Wheeled Lab旨在普及先进工具，并促进更广泛范围内的创新与教育。从硬件到软件的整体架构都是低价格且开源的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation has been pivotal in recent robotics milestones and is poised toplay a prominent role in the field's future. However, recent robotic advancesoften rely on expensive and high-maintenance platforms, limiting access tobroader robotics audiences. This work introduces Wheeled Lab, a framework forthe low-cost, open-source wheeled platforms that are already widely establishedin education and research. Through integration with Isaac Lab, Wheeled Labintroduces modern techniques in Sim2Real, such as domain randomization, sensorsimulation, and end-to-end learning, to new user communities. To kickstarteducation and demonstrate the framework's capabilities, we develop threestate-of-the-art policies for small-scale RC cars: controlled drifting,elevation traversal, and visual navigation, each trained in simulation anddeployed in the real world. By bridging the gap between advanced Sim2Realmethods and affordable, available robotics, Wheeled Lab aims to democratizeaccess to cutting-edge tools, fostering innovation and education in a broaderrobotics context. The full stack, from hardware to software, is low cost andopen-source.</description>
      <author>example@mail.com (Tyler Han, Preet Shah, Sidharth Rajagopal, Yanda Bao, Sanghun Jung, Sidharth Talia, Gabriel Guo, Bryan Xu, Bhaumik Mehta, Emma Romig, Rosario Scalise, Byron Boots)</author>
      <guid isPermaLink="false">2502.07380v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>SymbioSim: Human-in-the-loop Simulation Platform for Bidirectional Continuing Learning in Human-Robot Interaction</title>
      <link>http://arxiv.org/abs/2502.07358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为SymbioSim的新平台，旨在促进人类与机器人之间安全、高效且自然的互动学习。&lt;h4&gt;背景&lt;/h4&gt;智能机器人的发展目标是实现人机共生。然而，在真实环境中直接训练和测试算法成本高且有风险，并且现有的机器人模拟器无法支持真人参与，影响了实际交互体验和获取有价值的反馈。&lt;h4&gt;目的&lt;/h4&gt;开发SymbioSim平台以解决现有问题，促进人类与机器人之间的持续互动、学习和适应。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含细致架构和模块的系统，提供自然且现实的人机交互体验，支持双向的学习和优化过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验和用户研究证明了SymbioSim平台的有效性，并展示了它在促进人类与机器人共生领域的潜在重大贡献。&lt;h4&gt;结论&lt;/h4&gt;SymbioSim为研发人员提供了一种创新工具，以实现人机协作的自然交互，从而推动相关研究的进步。&lt;h4&gt;翻译&lt;/h4&gt;智能机器人的开发目标是无缝地将其融入到人类世界中，在日常生活中提供帮助和陪伴。要实现这一愿景，机器人必须通过与人类持续互动和合作来不断学习和发展，而人类则需要逐步建立对机器人的理解和信任。然而，直接在物理机器人上进行训练和测试涉及高额成本及安全风险；此外，现有的机器人模拟器无法支持真人参与，限制了它们提供真实交互体验和收集有价值的用户反馈的能力。本文介绍了一种新的“SymbioSim”人机共融式仿真平台，旨在使人类与机器人的互动发展、评估和优化变得既安全又高效，并通过精心设计的系统架构和模块提供了自然且真实的互动体验，促进了双向持续学习及适应过程。广泛的实验和用户研究展示了该平台的优异性能及其在推动人机共生领域的潜在重大贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of intelligent robots seeks to seamlessly integrate them intothe human world, providing assistance and companionship in daily life and work,with the ultimate goal of achieving human-robot symbiosis. To realize thisvision, robots must continuously learn and evolve through consistentinteraction and collaboration with humans, while humans need to graduallydevelop an understanding of and trust in robots through shared experiences.However, training and testing algorithms directly on physical robots involvesubstantial costs and safety risks. Moreover, current robotic simulators failto support real human participation, limiting their ability to provideauthentic interaction experiences and gather valuable human feedback. In thispaper, we introduce SymbioSim, a novel human-in-the-loop robotic simulationplatform designed to enable the safe and efficient development, evaluation, andoptimization of human-robot interactions. By leveraging a carefully designedsystem architecture and modules, SymbioSim delivers a natural and realisticinteraction experience, facilitating bidirectional continuous learning andadaptation for both humans and robots. Extensive experiments and user studiesdemonstrate the platform's promising performance and highlight its potential tosignificantly advance research on human-robot symbiosis.</description>
      <author>example@mail.com (Haoran Chen, Yiteng Xu, Yiming Ren, Yaoqin Ye, Xinran Li, Ning Ding, Peishan Cong, Ziyi Wang, Bushi Liu, Yuhan Chen, Zhiyang Dou, Xiaokun Leng, Manyi Li, Yuexin Ma, Changhe Tu)</author>
      <guid isPermaLink="false">2502.07358v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>The Combined Problem of Online Task Assignment and Lifelong Path Finding in Logistics Warehouses: A Case Study</title>
      <link>http://arxiv.org/abs/2502.07332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在线任务分配和终身路径规划的结合问题，这对物流行业至关重要。&lt;h4&gt;背景&lt;/h4&gt;现有文献大多数集中于假设给定任务分配器的情况下的终生路径规划或已知所有任务的离线版本的问题。&lt;h4&gt;目的&lt;/h4&gt;为了最大化系统的吞吐量，直接解决将这两者集成在一起的在线版本问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个正式框架和解决方案概念，并设计了一个基于规则的终身计划程序，在实践中即使在存在严重局部拥堵的情况下也能很好地工作。随后自动化搜索任务分配器与底层路径规划器的关系。&lt;h4&gt;主要发现&lt;/h4&gt;(1) 在时间效率方面，系统只需要目前美团使用的执行时间的83.77%，优于其他最先进的算法8.09%；(2) 经济效率上，可以使用当前仅60%的代理实现相同的吞吐量。&lt;h4&gt;结论&lt;/h4&gt;该方法在实际应用中展示了高效的时间和经济效益。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the combined problem of online task assignment and lifelong pathfinding, which is crucial for the logistics industries. However, mostliterature either (1) focuses on lifelong path finding assuming a given taskassigner, or (2) studies the offline version of this problem where tasks areknown in advance. We argue that, to maximize the system throughput, the onlineversion that integrates these two components should be tackled directly. Tothis end, we introduce a formal framework of the combined problem and itssolution concept. Then, we design a rule-based lifelong planner under apractical robot model that works well even in environments with severe localcongestion. Upon that, we automate the search for the task assigner withrespect to the underlying path planner. Simulation experiments conducted inwarehouse scenarios at \textit{Meituan}, one of the largest shopping platformsin China, demonstrate that (a)~\textit{in terms of time efficiency}, our systemrequires only 83.77\% of the execution time needed for the currently deployedsystem at Meituan, outperforming other SOTA algorithms by 8.09\%;(b)~\textit{in terms of economic efficiency}, ours can achieve the samethroughput with only 60\% of the agents currently in use.</description>
      <author>example@mail.com (Fengming Zhu, Fangzhen Lin, Weijia Xu, Yifei Guo)</author>
      <guid isPermaLink="false">2502.07332v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation</title>
      <link>http://arxiv.org/abs/2502.07306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种模块化的方法来解决视觉-语言导航（VLN）任务，通过将问题分解为四个子模块，并在零样本设置中使用最先进的大语言模型和视觉-语言模型。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言导航(VLN)任务需要结合自然语言指令、环境感知以及路径规划能力。现有的方法大多依赖于联合语义地图进行导航性能的评估。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的模块化框架来提高VLN任务的表现，特别是在复杂的R2R-Habitat数据集上，并详细量化视觉定位对导航表现的影响。&lt;h4&gt;方法&lt;/h4&gt;1. 使用大语言模型(Large Language Models, LLMs)从自然语言指令中提取地标及其访问顺序；2. 假设已知环境模型，使用最短路径算法在环境的拓扑地图上生成从起始地点到最后一个地标的k条路径假设；3. 采用动态规划计算路径序列与地标名称序列之间的对齐得分，并通过视觉语言模型(Vision-Language Models, VLMs)获取匹配分数；4. 计算最高对齐得分的假设路径的nDTW度量，以评估路径准确性。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在复杂R2R-Habitat指令数据集上展示出优于使用联合语义地图(如VLMaps)的方法的表现，并详细量化了视觉定位对导航性能的影响。&lt;h4&gt;结论&lt;/h4&gt;提出的模块化方法为解决视觉-语言导航问题提供了一种有效途径，特别是在零样本设置中利用先进的大语言模型和视觉语言模型进行自然语言指令的处理。该研究还强调了视觉定位在提高导航精度方面的重要性。&lt;h4&gt;翻译&lt;/h4&gt;在此工作中，我们提出了一种通过将任务分解成四个子模块来解决视觉-语言导航（VLN）问题的方法，在零样本设置中使用最先进的大型语言模型和视觉-语言模型。给定自然语言的导航指令后，我们首先提示大型语言模型提取地标以及它们访问的顺序。假设已知环境模型，我们检索出最接近最后地标的k个位置，并从起始地点到最后一个地标生成k条路径假说，使用环境中拓扑地图上的最短路径算法进行生成。每个路径假说由一系列全景图表示。然后，我们利用动态规划计算序列间对齐得分，即将这些序列中的全景图与地标名称序列匹配的分数通过视觉-语言模型获取。最后，我们将最高对齐得分支对应的假设求nDTW度量来评估路径的一致性。我们在复杂的R2R-Habitat指令数据集上展示出优于使用联合语义地图（如VLMaps）的方法的表现，并详细量化了视觉定位对导航性能的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a modular approach for the Vision-LanguageNavigation (VLN) task by decomposing the problem into four sub-modules that usestate-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs)in a zero-shot setting. Given navigation instruction in natural language, wefirst prompt LLM to extract the landmarks and the order in which they arevisited. Assuming the known model of the environment, we retrieve the top-klocations of the last landmark and generate $k$ path hypotheses from thestarting location to the last landmark using the shortest path algorithm on thetopological map of the environment. Each path hypothesis is represented by asequence of panoramas. We then use dynamic programming to compute the alignmentscore between the sequence of panoramas and the sequence of landmark names,which match scores obtained from VLM. Finally, we compute the nDTW metricbetween the hypothesis that yields the highest alignment score to evaluate thepath fidelity. We demonstrate superior performance compared to other approachesthat use joint semantic maps like VLMaps \cite{vlmaps} on the complexR2R-Habitat \cite{r2r} instruction dataset and quantify in detail the effect ofvisual grounding on navigation performance.</description>
      <author>example@mail.com (Navid Rajabi, Jana Kosecka)</author>
      <guid isPermaLink="false">2502.07306v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Leader-follower formation enabled by pressure sensing in free-swimming undulatory robotic fish</title>
      <link>http://arxiv.org/abs/2502.07282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 10 figures. Accepted for 2025 IEEE International Conference  on Robotics and Automation (ICRA). Supplementary video:  https://youtu.be/DIDYGi9Td0I&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种模仿鱼类侧线系统用于感知水流和压力梯度的仿生机器人，该机器人能够通过压力传感器实现领导-跟随模式下的群组游泳。&lt;h4&gt;背景&lt;/h4&gt;鱼利用其侧线系统来感测水流和压力变化，进而发现周围物体及生物。这项研究旨在复制这一能力，使用具有双边压感触觉传感器的仿生鱼类进行实验。&lt;h4&gt;目的&lt;/h4&gt;展示基于流体压力感应技术在机器人中实现领导-跟随游泳模式的有效性，并通过机器学习方法优化控制策略。&lt;h4&gt;方法&lt;/h4&gt;['首先进行了静态排列试验，在固定不动的追随者和摆动的领导者之间建立了能产生强烈压力变化的理想排布方式。', '接着，采用长短期记忆神经网络作为控制系统的核心算法，该模型将从传感器采集的压力信号、机器人电机命令以及IMU测量的角度值映射为转向指令。', '控制策略通过行为克隆法和DAgger（数据聚合）技术进行训练以模仿专家策略。']&lt;h4&gt;主要发现&lt;/h4&gt;['实验表明，在仅有两个双边压力传感器且仅基于不到一小时的训练数据的情况下，追随者能够在游泳速度达到155毫米/秒时成功跟随领导者至最远200毫米（约一个鱼体长度）的距离。', '该研究证明了利用流体压力反馈机制来实现鱼类模仿机器人在复杂水域环境中有效导航和群组游泳的能力。']&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了基于生物灵感设计的鱼类仿生机器人的潜力，它们能够有效地应对流动环境，并通过使用流体压力回馈系统实现群组游泳。&lt;h4&gt;翻译&lt;/h4&gt;鱼利用侧线来感知水流及周围的压力变化，以此检测附近的物体和生命体。为了复制这种能力，研究者展示了一种名为'微小机器人鱼（$\mu$Bot/MUBot）的仿生机器人能够通过流体压力感应实现领导-跟随游泳模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fish use their lateral lines to sense flows and pressure gradients, enablingthem to detect nearby objects and organisms. Towards replicating thiscapability, we demonstrated successful leader-follower formation swimming usingflow pressure sensing in our undulatory robotic fish ($\mu$Bot/MUBot). Thefollower $\mu$Bot is equipped at its head with bilateral pressure sensors todetect signals excited by both its own and the leader's movements. First, usingexperiments with static formations between an undulating leader and astationary follower, we determined the formation that resulted in strongpressure variations measured by the follower. This formation was then selectedas the desired formation in free swimming for obtaining an expert policy. Next,a long short-term memory neural network was used as the control policy thatmaps the pressure signals along with the robot motor commands and the Eulerangles (measured by the onboard IMU) to the steering command. The policy wastrained to imitate the expert policy using behavior cloning and DatasetAggregation (DAgger). The results show that with merely two bilateral pressuresensors and less than one hour of training data, the follower effectivelytracked the leader within distances of up to 200 mm (= 1 body length) whileswimming at speeds of 155 mm/s (= 0.8 body lengths/s). This work highlights thepotential of fish-inspired robots to effectively navigate fluid environmentsand achieve formation swimming through the use of flow pressure feedback.</description>
      <author>example@mail.com (Kundan Panta, Hankun Deng, Micah DeLattre, Bo Cheng)</author>
      <guid isPermaLink="false">2502.07282v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Confidence: Adaptive Abstention in Dual-Threshold Conformal Prediction for Autonomous System Perception</title>
      <link>http://arxiv.org/abs/2502.07255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的双阈值校准框架，该框架能够为安全关键性的感知系统提供统计保证下的不确定性估计，并在高风险场景中启用选择性预测。此方法结合了有效预测集的校准阈值和通过ROC分析优化的弃权阈值，在各种环境条件下都能保持稳健的表现。&lt;h4&gt;背景&lt;/h4&gt;安全关键性的感知系统需要可靠的不确定性量化机制以及基于原则的放弃预测策略，以在多样的操作环境中维持安全性。&lt;h4&gt;目的&lt;/h4&gt;提供一个既能保证统计学上的不确定度估计又能支持选择性预测的方法框架，特别是在高风险场景中能可靠地弃权而不做出可能不准确或危险的预测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双阈值校准化框架，结合了确保有效预测集的校准阈值和通过ROC分析优化的放弃阈值。该框架在CIFAR-100、ImageNet1K和ModelNet40数据集中进行了全面评估，展示了其跨摄像头与LiDAR模态下的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架在恶劣条件下表现出卓越的检测性能（AUC：0.993至0.995），同时保持高覆盖率（&gt;90.0%）并实现自适应弃权（13.5%至63.4%±0.5）。特别是在LiDAR感知中，该框架展示了特别强的表现，在重大环境干扰下依然能维持稳健的覆盖度（&gt;84.5%），同时适当地放弃不可靠预测。值得注意的是，所提出的体系在重大力干扰下表现出色且稳定。&lt;h4&gt;结论&lt;/h4&gt;本文的方法通过理论保障与实际部署需求之间的桥梁提供了可靠的安全关键性自主系统的解决方案，并能在具有挑战性的现实世界环境中有效运行。&lt;h4&gt;翻译&lt;/h4&gt;原文为英文摘要的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safety-critical perception systems require both reliable uncertaintyquantification and principled abstention mechanisms to maintain safety underdiverse operational conditions. We present a novel dual-thresholdconformalization framework that provides statistically-guaranteed uncertaintyestimates while enabling selective prediction in high-risk scenarios. Ourapproach uniquely combines a conformal threshold ensuring valid prediction setswith an abstention threshold optimized through ROC analysis, providingdistribution-free coverage guarantees (\ge 1 - \alpha) while identifyingunreliable predictions. Through comprehensive evaluation on CIFAR-100,ImageNet1K, and ModelNet40 datasets, we demonstrate superior robustness acrosscamera and LiDAR modalities under varying environmental perturbations. Theframework achieves exceptional detection performance (AUC: 0.993\to0.995) undersevere conditions while maintaining high coverage (&gt;90.0\%) and enablingadaptive abstention (13.5\%\to63.4\%\pm0.5) as environmental severityincreases. For LiDAR-based perception, our approach demonstrates particularlystrong performance, maintaining robust coverage (&gt;84.5\%) while appropriatelyabstaining from unreliable predictions. Notably, the framework shows remarkablestability under heavy perturbations, with detection performance (AUC:0.995\pm0.001) significantly outperforming existing methods across allmodalities. Our unified approach bridges the gap between theoretical guaranteesand practical deployment needs, offering a robust solution for safety-criticalautonomous systems operating in challenging real-world conditions.</description>
      <author>example@mail.com (Divake Kumar, Nastaran Darabi, Sina Tayebati, Amit Ranjan Trivedi)</author>
      <guid isPermaLink="false">2502.07255v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Parameter Optimization of Optical Six-Axis Force/Torque Sensor for Legged Robots</title>
      <link>http://arxiv.org/abs/2502.07196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种专为轻型腿足机器人设计的新型六轴力/扭矩传感器。该传感器采用非接触式光耦合器设计，相比传统的应变计式传感器在耐物理冲击、降低损坏风险等方面具有优势。&lt;h4&gt;背景&lt;/h4&gt;现有腿足机器人的力/扭矩传感器存在体积大、重量重及易受物理损伤等问题，限制了其广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的非接触式六轴力/扭矩传感器设计，旨在解决传统力传感器的缺点，并满足小型化和轻量化的需要。&lt;h4&gt;方法&lt;/h4&gt;采用光耦合器而非传统的应变计来制造新型传感器，并通过优化参数的方法提高传感器灵敏度并减少误差。利用精确建模和分析目标函数的方式推导出最优设计方案。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该传感器的有效性，其性能与理论模型吻合良好。此外，它还能应用于多种机器人环境，特别是用于研究机器人足部与地面之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;这项创新不仅解决了现有传感器的局限性，还促进了传感技术以及机器人的进一步发展，并为未来在机器人系统中的应用铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要介绍了针对轻型腿足机器人设计的新六轴力/扭矩传感器。这种新型非接触式光耦合器设计方案相较于传统应变计类型传感器，在耐冲击和减少物理损伤风险方面具有显著优势，简化制造过程并降低成本。优化参数的方法被提出以实现高灵敏度与低误差，并通过精确建模和分析目标函数确定最优设计参数。此传感器已在四足机器人中得到验证，展现了其良好的性能表现，适用于多样化机器人环境，尤其是对研究机器人脚部与地面交互具有重要意义。这一创新不仅克服了现有传感器的限制，而且推动了传感技术和机器人的进步，并为未来的机器人系统应用打开了大门。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel six-axis force/torque sensor tailored forcompact and lightweight legged robots. Unlike traditional strain gauge-basedsensors, the proposed non-contact design employs photocouplers, enhancingresistance to physical impacts and reducing damage risk. This approachsimplifies manufacturing, lowers costs, and meets the demands of legged robotsby combining small size, light weight, and a wide force measurement range. Amethodology for optimizing sensor parameters is also presented, focusing onmaximizing sensitivity and minimizing error. Precise modeling and analysis ofobjective functions enabled the derivation of optimal design parameters. Thesensor's performance was validated through extensive testing and integrationinto quadruped robots, demonstrating alignment with theoretical modeling. Thesensor's precise measurement capabilities make it suitable for diverse roboticenvironments, particularly in analyzing interactions between robot feet and theground. This innovation addresses existing sensor limitations whilecontributing to advancements in robotics and sensor technology, paving the wayfor future applications in robotic systems.</description>
      <author>example@mail.com (Hyun-Bin Kim, Byeong-Il Ham, Keun-Ha Choi, Kyung-Soo Kim)</author>
      <guid isPermaLink="false">2502.07196v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Space-Aware Instruction Tuning: Dataset and Benchmark for Guide Dog Robots Assisting the Visually Impaired</title>
      <link>http://arxiv.org/abs/2502.07183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个用于提升视觉障碍人士导航能力的机器人指导解决方案，强调了在复杂环境中的空间感知和沟通的重要性。&lt;h4&gt;背景&lt;/h4&gt;导盲犬机器人为视力受损者提供了更好的移动性和安全性。现有视觉-语言模型（VLMs）虽然能够生成周围环境的自然语言描述以辅助决策，但它们在解释和传达空间关系方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;通过引入Space-Aware Instruction Tuning (SAIT) 数据集和Space-Aware Benchmark (SA-Bench)，解决现有VLMs理解物理环境的能力不足问题，并评估其提供行走指导的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自动化的数据生成流水线，专注于三维空间中虚拟路径到目的地的构建及周围环境的理解。此外，还设计了一个评价协议以衡量VLM在导航中的效果。&lt;h4&gt;主要发现&lt;/h4&gt;与现有算法相比，该研究的空间感知指令调优模型能更准确地提供导航指导。&lt;h4&gt;结论&lt;/h4&gt;论文通过开放共享SAIT数据集、SA-Bench及其相关代码来促进导盲机器人技术的发展和应用。&lt;h4&gt;翻译&lt;/h4&gt;向导机器人为视力受损者提供了增强移动性和安全性的有希望的解决方案，弥补了传统导盲犬在感知智能和沟通方面的局限性。随着视觉-语言模型（VLMs）的出现，机器人现在能够生成周围环境的自然语言描述，有助于更安全的决策制定。然而，现有的VLM通常难以准确解释和传达空间关系，在如过街等复杂环境中尤为重要。我们提出了Space-Aware Instruction Tuning (SAIT) 数据集和Space-Aware Benchmark (SA-Bench)，以解决现有VLM理解物理环境的能力不足问题，并评估其提供行走指导的有效性。我们的自动化数据生成流水线专注于三维空间中虚拟路径到目的地的构建及周围环境的理解，增强对环境的认知能力并使VLM能够为视力受损者提供更准确的指引。我们还提出了一个评估协议来衡量VLM在导航中的效果。比较实验表明，我们的空间感知指令调优模型超越了现有最佳算法。我们在https://github.com/byungokhan/Space-awareVLM上完全开放共享SAIT数据集、SA-Bench及其相关代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Guide dog robots offer promising solutions to enhance mobility and safety forvisually impaired individuals, addressing the limitations of traditional guidedogs, particularly in perceptual intelligence and communication. With theemergence of Vision-Language Models (VLMs), robots are now capable ofgenerating natural language descriptions of their surroundings, aiding in saferdecision-making. However, existing VLMs often struggle to accurately interpretand convey spatial relationships, which is crucial for navigation in complexenvironments such as street crossings. We introduce the Space-Aware InstructionTuning (SAIT) dataset and the Space-Aware Benchmark (SA-Bench) to address thelimitations of current VLMs in understanding physical environments. Ourautomated data generation pipeline focuses on the virtual path to thedestination in 3D space and the surroundings, enhancing environmentalcomprehension and enabling VLMs to provide more accurate guidance to visuallyimpaired individuals. We also propose an evaluation protocol to assess VLMeffectiveness in delivering walking guidance. Comparative experimentsdemonstrate that our space-aware instruction-tuned model outperformsstate-of-the-art algorithms. We have fully open-sourced the SAIT dataset andSA-Bench, along with the related code, athttps://github.com/byungokhan/Space-awareVLM</description>
      <author>example@mail.com (ByungOk Han, Woo-han Yun, Beom-Su Seo, Jaehong Kim)</author>
      <guid isPermaLink="false">2502.07183v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Online Aggregation of Trajectory Predictors</title>
      <link>http://arxiv.org/abs/2502.07178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种轻量级且模型无关的方法，用于在线聚合不同轨迹预测器的输出。&lt;h4&gt;背景&lt;/h4&gt;轨迹预测是自动驾驶安全性和效率的关键任务。不同的方法（例如基于规则或通过各种架构和数据集学习）已经被提出来解决这一问题，但这些方法往往对部署环境敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轻量级且模型无关的方法来聚合不同轨迹预测器的输出，使得即使在分布外的数据上也能保持性能。&lt;h4&gt;方法&lt;/h4&gt;基于在线凸优化理论，每个单独的轨迹预测器被视为一个'专家'，并通过维护概率向量混合不同专家的输出。利用真实世界中逐步揭示的真实行为数据形成损失函数，并通过梯度引导概率向量选择最佳的专家组合。&lt;h4&gt;主要发现&lt;/h4&gt;当将训练在不同城市的NUSCENES数据集上得到的不同轨迹预测器进行聚合时，该方法显示了出色的性能，甚至在分布外的LYFT数据集中也表现得和单一模型一样好或更好。&lt;h4&gt;结论&lt;/h4&gt;这种方法提供了一种有效的方式，在各种环境条件下实现更稳健、更准确的轨迹预测。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提及的是一种基于在线凸优化理论但又超越了凸性和静态性的轻量级、模型无关的方法，用于聚合不同轨迹预测器的输出。该方法旨在解决现有轨迹预测技术对特定部署环境敏感的问题，通过将每个单独训练的轨迹预测器视为一个'专家'来工作，并使用真实数据动态调整这些'专家'的权重。实验结果表明，在不同的城市和分布外的数据集上，这种方法能够实现与单一模型一样好或更好的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory prediction, the task of forecasting future agent behavior frompast data, is central to safe and efficient autonomous driving. A diverse setof methods (e.g., rule-based or learned with different architectures anddatasets) have been proposed, yet it is often the case that the performance ofthese methods is sensitive to the deployment environment (e.g., how well thedesign rules model the environment, or how accurately the test data match thetraining data). Building upon the principled theory of online convexoptimization but also going beyond convexity and stationarity, we present alightweight and model-agnostic method to aggregate different trajectorypredictors online. We propose treating each individual trajectory predictor asan "expert" and maintaining a probability vector to mix the outputs ofdifferent experts. Then, the key technical approach lies in leveraging onlinedata -the true agent behavior to be revealed at the next timestep- to form aconvex-or-nonconvex, stationary-or-dynamic loss function whose gradient steersthe probability vector towards choosing the best mixture of experts. Weinstantiate this method to aggregate trajectory predictors trained on differentcities in the NUSCENES dataset and show that it performs just as well, if notbetter than, any singular model, even when deployed on the out-of-distributionLYFT dataset.</description>
      <author>example@mail.com (Alex Tong, Apoorva Sharma, Sushant Veer, Marco Pavone, Heng Yang)</author>
      <guid isPermaLink="false">2502.07178v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>A Safe Hybrid Control Framework for Car-like Robot with Guaranteed Global Path-Invariance using a Control Barrier Function</title>
      <link>http://arxiv.org/abs/2502.07136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures, initial submission to CCTA25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的混合框架，用于带有避障、全局收敛和安全性的车轮式机器人。&lt;h4&gt;背景&lt;/h4&gt;对于车轮式机器人而言，在存在潜在障碍物的环境中沿着预设路径行驶并保持安全性是一个重要的挑战。安全在此被解释为路径不变性：一旦机器人进入路径，则不会离开该路径。&lt;h4&gt;目的&lt;/h4&gt;设计一种既能够避开障碍物，又能够在到达预定路径后稳定地沿该路径行进而不偏离的控制系统。&lt;h4&gt;方法&lt;/h4&gt;首先定义了一条沿着给定路径的安全区域，并设计了局部控制器来保证收敛到路径并保持路径不变性。引入控制屏障函数技术以避免奇点问题；其次设计了一个混合控制框架，将本地路径不变控制器与现有的全局跟踪控制器相结合，从而实现从任意位置向期望路径的全局收敛。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方案通过结合局部和全局控制策略确保了路径不变性和对传感器噪声的鲁棒性，并且模拟结果验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为车轮式机器人在存在障碍物的情况下提供了有效的导航解决方案，保证了系统的安全性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;这项工作提出了一个具有避障、全局收敛和安全性特征的混合框架。其中安全性被定义为路径不变性：一旦机器人接近预定路径，则不会离开该路径。给定一条无碰撞且可行性的预设路径，在此路径周围可能存在障碍物，任务是避开这些障碍物并到达目标路径后保持在该路径上而不会偏离。问题分为两个阶段解决。首先，我们定义了沿着给定路径的无障碍区域，并设计了一个局部控制器以确保向路径的收敛性以及路径不变性。其次，我们创建了一个混合控制框架，它将这个本地路径不变控件与现有的全局跟踪控制器（这些控制器没有提供路径不变性的保证）相结合，从而确保从任何位置到预期路径的全球汇聚能力。该方法通过保持路径不变性和对传感器噪声的鲁棒性来保障系统的稳定性和安全性。详细的模拟结果证实了所提出方案的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a hybrid framework for car-like robots with obstacleavoidance, global convergence, and safety, where safety is interpreted as pathinvariance, namely, once the robot converges to the path, it never leaves thepath. Given a priori obstacle-free feasible path where obstacles can be aroundthe path, the task is to avoid obstacles while reaching the path and thenstaying on the path without leaving it. The problem is solved in two stages.Firstly, we define a ``tight'' obstacle-free neighborhood along the path anddesign a local controller to ensure convergence to the path and pathinvariance. The control barrier function technology is involved in the controldesign to steer the system away from its singularity points, where the localpath invariant controller is not defined. Secondly, we design a hybrid controlframework that integrates this local path-invariant controller with any globaltracking controller from the existing literature without path invarianceguarantee, ensuring convergence from any position to the desired path, namely,global convergence. This framework guarantees path invariance and robustness tosensor noise. Detailed simulation results affirm the effectiveness of theproposed scheme.</description>
      <author>example@mail.com (Nan Wang, Adeel Akhtar, Ricardo G. Sanfelice)</author>
      <guid isPermaLink="false">2502.07136v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Smell of Source: Learning-Based Odor Source Localization with Molecular Communication</title>
      <link>http://arxiv.org/abs/2502.07112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分子通信、环境监测等领域中单源单分子情况下气味源定位的三种主要方法：贝叶斯过滤、机器学习模型和物理信息神经网络(PINNs)。通过生成合成数据集来评估这些方法在不同条件下的性能。&lt;h4&gt;背景&lt;/h4&gt;气味源定位是分子通讯、环境监控、灾害响应及工业安全等领域的基础挑战之一。&lt;h4&gt;目的&lt;/h4&gt;旨在比较和评估贝叶斯过滤、机器学习模型以及物理信息神经网络(PINNs)在单一来源单个分子的气味源定位中的性能。&lt;h4&gt;方法&lt;/h4&gt;使用二维对流扩散偏微分方程求解器生成合成数据集，以模拟不同环境条件（如传感器噪声和稀疏测量）下的实验。&lt;h4&gt;主要发现&lt;/h4&gt;物理信息神经网络(PINNs)在所有测试条件下均表现出最低的定位误差(0.89×10^-6米)，优于机器学习反演(1.48×10^-6米)和卡尔曼滤波器(1.62×10^-6米)；强化学习方法虽然误差较大（3.01×10^-6米），但在推断时间上仅需0.147秒。&lt;h4&gt;结论&lt;/h4&gt;物理信息神经网络(PINNs)在气味源定位方面表现最佳，但其计算效率不如使用强化学习的方法。这表明了准确性和计算效率之间的权衡关系。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：气味源定位是分子通讯、环境监测、灾害响应和工业安全等领域的一个基础挑战。本文研究三种主要方法：贝叶斯过滤、机器学习模型以及物理信息神经网络(PINNs)，目的是在单源单一分子的情况下实现气味源的定位。通过将源传感器架构视为发射器-接收器模型，我们从分子通讯的角度探讨了源定位问题。使用二维对流扩散偏微分方程求解器生成合成数据集以评估不同条件下（包括传感器噪声和稀疏测量）的各种方法性能。实验结果表明，物理信息神经网络(PINNs)实现了最低的定位误差0.89×10^-6米，优于机器学习反演(1.48×10^-6米)和卡尔曼滤波器(1.62×10^-6米)；而强化学习方法虽然实现3.01×10^-6米的定位误差，但其推断时间仅为0.147秒，这表明了不同方法之间准确性与计算效率之间的权衡关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Odor source localization is a fundamental challenge in molecularcommunication, environmental monitoring, disaster response, industrial safety,and robotics. In this study, we investigate three major approaches: Bayesianfiltering, machine learning (ML) models, and physics-informed neural networks(PINNs) with the aim of odor source localization in a single-source,single-molecule case. By considering the source-sensor architecture as atransmitter-receiver model we explore source localization under the scope ofmolecular communication. Synthetic datasets are generated using a 2Dadvection-diffusion PDE solver to evaluate each method under varyingconditions, including sensor noise and sparse measurements. Our experimentsdemonstrate that \textbf{Physics-Informed Neural Networks (PINNs)} achieve thelowest localization error of \(\mathbf{0.89 \times 10^{-6}}\) m, outperforming\textbf{machine learning (ML) inversion} (\(\mathbf{1.48 \times 10^{-6}}\) m)and \textbf{Kalman filtering} (\(\mathbf{1.62 \times 10^{-6}}\) m). The\textbf{reinforcement learning (RL)} approach, while achieving a localizationerror of \(\mathbf{3.01 \times 10^{-6}}\) m, offers an inference time of\(\mathbf{0.147}\) s, highlighting the trade-off between accuracy andcomputational efficiency among different methodologies.</description>
      <author>example@mail.com (Ayse Sila Okcu, Ozgur B. Akan)</author>
      <guid isPermaLink="false">2502.07112v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects</title>
      <link>http://arxiv.org/abs/2502.07005v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages main text, 30 pages all included&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于异构图的策略模型HEPi，以解决机器人操作中涉及不同几何形状和可变形物体的任务。该方法采用$SE(3)$等变消息传递网络，并引入了显式的异质性建模。&lt;h4&gt;背景&lt;/h4&gt;操纵具有各种几何形状的对象以及处理可变形物体是机器人领域中的一个重要挑战。例如，插入不同类型的对象或悬挂衣物需要精确的控制和复杂的动态模型。&lt;h4&gt;目的&lt;/h4&gt;通过构建一种统一的图表示形式来解决此类问题，并提出了一种新的强化学习基准测试方法以评估该框架的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个异构图表示模型HEPi，利用$SE(3)$等变消息传递网络作为主要架构，并引入了显式的异质性建模。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，相较于基于Transformer的方法以及非异质的等变策略，HEPi在平均回报、样本效率和对未见过物体的泛化能力方面表现更优。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新的机器人任务处理框架，并展示了其对于复杂动态模型的有效性和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;操控具有不同几何形状的对象以及可变形对象是机器人技术中的一个主要挑战。例如，插入不同类型对象或悬挂衣物需要精确控制和有效的复杂动力学建模。在这项工作中，我们通过异构图的视角来解决这个问题，该图包含较小的子图（如致动器和物体），并且有不同类型的边描述它们之间的交互作用。这种图表示既适用于刚性物体任务也适用于可变形对象任务，并且可以进一步扩展到多致动器的任务中。为了评估这一设置，我们提出了一种新的具有挑战性的强化学习基准测试，包括插入不同类型物体的刚性插入和使用多个末端执行器进行绳索及布料操作。这些任务由于初始配置和目标配置在3D空间中的均匀采样而呈现出较大的搜索空间。为了解决这个问题，我们提出了一个新颖的基于图策略模型HEPi，利用$SE(3)$等变消息传递网络作为主要架构来利用几何对称性。此外，通过显式地建模异质性，HEPi在平均回报、样本效率以及未见过对象上的泛化能力方面优于Transformer基线和非异构等变策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manipulating objects with varying geometries and deformable objects is amajor challenge in robotics. Tasks such as insertion with different objects orcloth hanging require precise control and effective modelling of complexdynamics. In this work, we frame this problem through the lens of aheterogeneous graph that comprises smaller sub-graphs, such as actuators andobjects, accompanied by different edge types describing their interactions.This graph representation serves as a unified structure for both rigid anddeformable objects tasks, and can be extended further to tasks comprisingmultiple actuators. To evaluate this setup, we present a novel and challengingreinforcement learning benchmark, including rigid insertion of diverse objects,as well as rope and cloth manipulation with multiple end-effectors. These taskspresent a large search space, as both the initial and target configurations areuniformly sampled in 3D space. To address this issue, we propose a novelgraph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi),utilizing $SE(3)$  equivariant message passing networks as the main backbone to exploit thegeometric symmetry. In addition, by modeling explicit heterogeneity, HEPi canoutperform Transformer-based and non-heterogeneous equivariant policies interms of average returns, sample efficiency, and generalization to unseenobjects.</description>
      <author>example@mail.com (Tai Hoang, Huy Le, Philipp Becker, Vien Anh Ngo, Gerhard Neumann)</author>
      <guid isPermaLink="false">2502.07005v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Select before Act: Spatially Decoupled Action Repetition for Continuous Control</title>
      <link>http://arxiv.org/abs/2502.06919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种新的重复框架SDAR，通过独立执行每个动作维度的闭环选择来实现空间解耦的动作重复。&lt;h4&gt;背景&lt;/h4&gt;强化学习在连续控制任务中取得了显著成功，如机器人操作和行走。最近的研究将动作重复集成到RL中，提高了样本效率并增强了性能。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法忽视各动作维度差异的问题，提高决策灵活性，并改进策略的敏捷性和效果。&lt;h4&gt;方法&lt;/h4&gt;引入SDAR框架，通过执行每个动作维度的闭环选择来实现空间解耦的动作重复，从而获得更灵活的重复策略。&lt;h4&gt;主要发现&lt;/h4&gt;相比现有的重复框架，SDAR在样本效率、策略性能和减少行动波动方面表现更好，并在多种连续控制场景中进行了实验验证其有效性。&lt;h4&gt;结论&lt;/h4&gt;通过将动作维度分离进行独立决策的方式提高了强化学习中的动作持久性和多样性之间的平衡，改进了现有方法的局限性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：强化学习（RL）已经在各种连续控制任务中取得了显著的成功，例如机器人操作和行走。与主流RL在每个步骤做出决策不同的是，最近的研究将行动重复集成到RL中，通过增强行为持久性和提高样本效率来获得更好的性能。然而，现有方法在重复期间将所有动作维度视为整体，忽略了它们之间的差异。这种限制导致了决策的不灵活性，从而降低了策略的敏捷性并影响了效果。在这项工作中，我们提出了一种称为SDAR的新颖重复框架，它通过为每个动作维度单独执行闭环行动或重复选择来实现空间解耦的动作重复。SDAR实现了更灵活的重复策略，提高了行为持久性和多样性的平衡。与现有的重复框架相比，SDAR在样本效率、更高的策略性能和减少的行为波动方面表现更好。我们在各种连续控制场景中进行了实验，展示了本文提出的空间解耦重复设计的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) has achieved remarkable success in variouscontinuous control tasks, such as robot manipulation and locomotion. Differentto mainstream RL which makes decisions at individual steps, recent studies haveincorporated action repetition into RL, achieving enhanced action persistencewith improved sample efficiency and superior performance. However, existingmethods treat all action dimensions as a whole during repetition, ignoringvariations among them. This constraint leads to inflexibility in decisions,which reduces policy agility with inferior effectiveness. In this work, wepropose a novel repetition framework called SDAR, which implements SpatiallyDecoupled Action Repetition through performing closed-loop act-or-repeatselection for each action dimension individually. SDAR achieves more flexiblerepetition strategies, leading to an improved balance between actionpersistence and diversity. Compared to existing repetition frameworks, SDAR ismore sample efficient with higher policy performance and reduced actionfluctuation. Experiments are conducted on various continuous control scenarios,demonstrating the effectiveness of spatially decoupled repetition designproposed in this work.</description>
      <author>example@mail.com (Buqing Nie, Yangqing Fu, Yue Gao)</author>
      <guid isPermaLink="false">2502.06919v1</guid>
      <pubDate>Wed, 12 Feb 2025 17:28:58 +0800</pubDate>
    </item>
    <item>
      <title>Learning Efficient Flocking Control based on Gibbs Random Fields</title>
      <link>http://arxiv.org/abs/2502.02984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于Gibbs随机场的多智能体强化学习框架，用于解决多机器人系统在拥挤环境下的群集控制问题。&lt;h4&gt;背景&lt;/h4&gt;群集控制对于多机器人系统的各种应用至关重要，但在拥挤环境中实现高效的群集控制面临着计算负担、性能最优性和运动安全性的挑战。&lt;h4&gt;目的&lt;/h4&gt;该论文通过构建基于Gibbs随机场的多智能体强化学习框架来应对这些挑战。&lt;h4&gt;方法&lt;/h4&gt;[{'方法1': '利用Gibbs随机场表示一个多机器人系统，将其视为一组符合联合概率分布的随机变量，为群集奖励设计提供新的视角'}, {'方法2': '通过基于GRF的信用分配方法实现去中心化的训练和执行机制，增强多智能体强化学习对于机器人数量的可扩展性'}, {'方法3': '引入动作注意模块以隐式预测邻近机器人的运动意图，从而减轻MARL中的潜在非平稳问题'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'发现1': '提出框架能够在具有挑战性的环境中通过与最新的解决方案进行详细的模拟和实验比较证明学习高效的分布式控制策略的成功率为99%左右'}, {'发现2': '进行了消融研究以验证不同框架模块的效率'}]&lt;h4&gt;结论&lt;/h4&gt;所提出的基于Gibbs随机场的方法为解决多机器人系统在复杂环境下的群集控制问题提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Flocking control is essential for multi-robot systems in diverseapplications, yet achieving efficient flocking in congested environments poseschallenges regarding computation burdens, performance optimality, and motionsafety. This paper addresses these challenges through a multi-agentreinforcement learning (MARL) framework built on Gibbs Random Fields (GRFs).With GRFs, a multi-robot system is represented by a set of random variablesconforming to a joint probability distribution, thus offering a freshperspective on flocking reward design. A decentralized training and executionmechanism, which enhances the scalability of MARL concerning robot quantity, isrealized using a GRF-based credit assignment method. An action attention moduleis introduced to implicitly anticipate the motion intentions of neighboringrobots, consequently mitigating potential non-stationarity issues in MARL. Theproposed framework enables learning an efficient distributed control policy formulti-robot systems in challenging environments with success rate around$99\%$, as demonstrated through thorough comparisons with state-of-the-artsolutions in simulations and experiments. Ablation studies are also performedto validate the efficiency of different framework modules.</description>
      <author>example@mail.com (Dengyu Zhang, Chenghao, Feng Xue, Qingrui Zhang)</author>
      <guid isPermaLink="false">2502.02984v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
  <item>
      <title>Discovering Physics Laws of Dynamical Systems via Invariant Function Learning</title>
      <link>http://arxiv.org/abs/2502.04495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了学习由常微分方程（ODE）支配的动力系统的内在规律的问题，特别是在不同环境中发现基本动力学而非特定环境机制的方法。&lt;h4&gt;背景&lt;/h4&gt;研究对象是在多种环境下探索和识别动力系统的基本动态规律，而不是针对某个具体环境的特殊机制。挑战在于如何在功能系数变化甚至完全不同的函数形式变化的情况下进行学习。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于因果分析的新方法DIF（Invariant Function Disentanglement），以解决复杂环境中发现不变函数的问题，并展示其有效性和效率。&lt;h4&gt;方法&lt;/h4&gt;该研究通过因果图的构建和编码-解码超网络的设计，明确地将环境特有的动力学与不变函数分离。这种方法依赖于信息基础原则来保证从提取的不变函数中独立出环境影响。&lt;h4&gt;主要发现&lt;/h4&gt;在三个ODE系统上的定量对比表明了该方法的有效性和效率；此外，符号回归解释结果强调了框架揭示基本规律的能力。&lt;h4&gt;结论&lt;/h4&gt;通过提出DIF方法，研究解决了复杂环境下发现动力学基本规律的问题，并展示了其在不同环境下的应用价值和潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们考虑学习由普通微分方程（ODE）支配的动力系统的基本规律。主要挑战在于如何跨多个环境发现内在动态，同时避免特定于环境的机制。不同于以往的工作，本文解决的是更加复杂的情况，在这种情况下变化不仅限于功能系数的变化，还包括完全不同的函数形式的变化...我们通过因果图和编码-解码超网络的设计来明确分离不变函数与特定于环境的动力学，并保证它们之间的独立性...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider learning underlying laws of dynamical systems governed byordinary differential equations (ODE). A key challenge is how to discoverintrinsic dynamics across multiple environments while circumventingenvironment-specific mechanisms. Unlike prior work, we tackle more complexenvironments where changes extend beyond function coefficients to entirelydifferent function forms. For example, we demonstrate the discovery of idealpendulum's natural motion $\alpha^2 \sin{\theta_t}$ by observing pendulumdynamics in different environments, such as the damped environment $\alpha^2\sin(\theta_t) - \rho \omega_t$ and powered environment $\alpha^2\sin(\theta_t) + \rho \frac{\omega_t}{\left|\omega_t\right|}$. Here, weformulate this problem as an \emph{invariant function learning} task andpropose a new method, known as \textbf{D}isentanglement of \textbf{I}nvariant\textbf{F}unctions (DIF), that is grounded in causal analysis. We propose acausal graph and design an encoder-decoder hypernetwork that explicitlydisentangles invariant functions from environment-specific dynamics. Thediscovery of invariant functions is guaranteed by our information-basedprinciple that enforces the independence between extracted invariant functionsand environments. Quantitative comparisons with meta-learning and invariantlearning baselines on three ODE systems demonstrate the effectiveness andefficiency of our method. Furthermore, symbolic regression explanation resultshighlight the ability of our framework to uncover intrinsic laws.</description>
      <author>example@mail.com (Shurui Gui, Xiner Li, Shuiwang Ji)</author>
      <guid isPermaLink="false">2502.04495v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>AnyPlace: Learning Generalized Object Placement for Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.04531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AnyPlace 是一种基于合成数据训练的两阶段方法，用于预测真实世界任务中的可行放置姿态。&lt;h4&gt;背景&lt;/h4&gt;机器人在处理对象放置时面临挑战，由于物体几何形状和放置配置的多样性。&lt;h4&gt;目的&lt;/h4&gt;提出 AnyPlace 方法来解决由对象多样化带来的放置问题。&lt;h4&gt;方法&lt;/h4&gt;利用视觉-语言模型（VLM）识别大致放置位置，并专注于局部放置区域以训练低级别放置姿态预测模型。通过生成包含随机生成对象的不同放置配置（插入、堆叠、悬挂）的完全合成数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在成功率、可能放置模式的覆盖率和精度方面优于基线模型，并且能够直接将仅基于合成数据训练的模型应用于真实世界场景中。&lt;h4&gt;结论&lt;/h4&gt;AnyPlace 方法成功地展示了如何利用合成数据来解决实际对象放置任务中的复杂问题，包括处理不同几何形状的对象以及实现精细放置的高精度。&lt;h4&gt;翻译&lt;/h4&gt;物体在机器人任务中的放置本质上具有挑战性，因为对象几何形状和放置配置的多样性。为了解决这个问题，我们提出了 AnyPlace 方法，这是一种完全基于合成数据训练的两阶段方法，能够预测真实世界任务中的一系列可行放置姿态。我们的关键见解是利用视觉-语言模型（VLM）识别大致放置位置，并专注于局部放置区域进行训练。在评估过程中，在模拟环境中展示了该方法优于基线模型的表现，尤其是在成功率、可能放置模式覆盖率和精度方面。在现实世界的实验中证明了，该方法能够直接将仅基于合成数据的模型应用于真实场景，即使是在对象几何形状变化多样且需要高精度精细放置的情况下也能成功执行任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object placement in robotic tasks is inherently challenging due to thediversity of object geometries and placement configurations. To address this,we propose AnyPlace, a two-stage method trained entirely on synthetic data,capable of predicting a wide range of feasible placement poses for real-worldtasks. Our key insight is that by leveraging a Vision-Language Model (VLM) toidentify rough placement locations, we focus only on the relevant regions forlocal placement, which enables us to train the low-levelplacement-pose-prediction model to capture diverse placements efficiently. Fortraining, we generate a fully synthetic dataset of randomly generated objectsin different placement configurations (insertion, stacking, hanging) and trainlocal placement-prediction models. We conduct extensive evaluations insimulation, demonstrating that our method outperforms baselines in terms ofsuccess rate, coverage of possible placement modes, and precision. Inreal-world experiments, we show how our approach directly transfers modelstrained purely on synthetic data to the real world, where it successfullyperforms placements in scenarios where other models struggle -- such as withvarying object geometries, diverse placement modes, and achieving highprecision for fine placement. More at: https://any-place.github.io.</description>
      <author>example@mail.com (Yuchi Zhao, Miroslav Bogdanovic, Chengyuan Luo, Steven Tohme, Kourosh Darvish, Alán Aspuru-Guzik, Florian Shkurti, Animesh Garg)</author>
      <guid isPermaLink="false">2502.04531v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Data Processing and Benchmarking of AI Models for Pathology</title>
      <link>http://arxiv.org/abs/2502.06750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在计算病理学领域取得了重大进展。&lt;h4&gt;目的&lt;/h4&gt;解决可用模型数量增加及缺乏标准化基准的问题，评估模型的优缺点以及进一步发展的潜力。&lt;h4&gt;方法&lt;/h4&gt;开发了一套新的软件工具，用于全切片图像处理、基础模型评测和公开任务管理。&lt;h4&gt;主要发现&lt;/h4&gt;这些资源有望促进透明度、可重复性和该领域的持续进步。&lt;h4&gt;翻译&lt;/h4&gt;在基础建模方面取得的进展已经重塑了计算病理学领域。然而，可用模型数量增加以及缺乏标准化基准评估其优缺点及进一步发展的潜力使得这些问题更加复杂化。为了解决这一挑战，我们引入了一套新的软件工具，用于全切片图像处理、基础模型评测和公开任务管理。我们期待这些资源能够促进该领域的透明度、可重复性以及持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in foundation modeling have reshaped computational pathology.However, the increasing number of available models and lack of standardizedbenchmarks make it increasingly complex to assess their strengths, limitations,and potential for further development. To address these challenges, weintroduce a new suite of software tools for whole-slide image processing,foundation model benchmarking, and curated publicly available tasks. Weanticipate that these resources will promote transparency, reproducibility, andcontinued progress in the field.</description>
      <author>example@mail.com (Andrew Zhang, Guillaume Jaume, Anurag Vaidya, Tong Ding, Faisal Mahmood)</author>
      <guid isPermaLink="false">2502.06750v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Multi-Teacher Knowledge Distillation for Real-Time Object Detection using 4D Radar</title>
      <link>http://arxiv.org/abs/2502.06114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文探讨了在恶劣天气条件下3D物体检测的重要性，以及雷达系统如何弥补激光雷达的不足。提出了一个基于知识蒸馏框架的方法来处理4D雷达点云稀疏性问题。&lt;h4&gt;背景&lt;/h4&gt;准确的3D物体检测对于自主导航的安全至关重要，在不同天气条件下的表现可靠性要求极高。尽管LiDAR在恶劣天气中的性能下降，但雷达系统保持了其稳定性。然而，传统雷达缺乏高度信息，最近出现的4D雷达通过测量范围、方位角和多普勒速度同时捕捉高度数据来克服这一限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用4D雷达特有的密集雷达成像（Radar Tensor）解决点云稀疏性问题的新方法。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新颖的知识蒸馏框架，该框架使学生模型能够通过模仿一组教师模型在潜在空间中对稀疏输入进行稠密化处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在K-Radar数据集上与当前最先进的RTNH模型相比，性能提升了25%，同时保持了实时推理速度。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了4D雷达特有的密集雷达成像的潜在价值，并展示了通过知识蒸馏框架增强其在3D物体检测中的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D object detection is crucial for safe autonomous navigation,requiring reliable performance across diverse weather conditions. While LiDARperformance deteriorates in challenging weather, Radar systems maintain theirreliability. Traditional Radars have limitations due to their lack of elevationdata, but the recent 4D Radars overcome this by measuring elevation alongsiderange, azimuth, and Doppler velocity, making them invaluable for autonomousvehicles. The primary challenge in utilizing 4D Radars is the sparsity of theirpoint clouds. Previous works address this by developing architectures thatbetter capture semantics and context in sparse point cloud, largely drawingfrom LiDAR-based approaches. However, these methods often overlook a uniqueadvantage of 4D Radars: the dense Radar tensor, which encapsulates powermeasurements across three spatial dimensions and the Doppler dimension. Ourpaper leverages this tensor to tackle the sparsity issue. We introduce a novelknowledge distillation framework that enables a student model to densify itssparse input in the latent space by emulating an ensemble of teacher models.Our experiments demonstrate a 25% performance improvement over thestate-of-the-art RTNH model on the K-Radar dataset. Notably, this improvementis achieved while still maintaining a real-time inference speed.</description>
      <author>example@mail.com (Seung-Hyun Song, Dong-Hee Paek, Minh-Quan Dao, Ezio Malis, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.06114v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation</title>
      <link>http://arxiv.org/abs/2502.06336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了DefTransNet，一种用于非刚性点云注册的端到端Transformer架构。它能够处理大变形、异常值、噪声和部分数据等问题。&lt;h4&gt;背景&lt;/h4&gt;软组织手术由于组织变形可能导致组织位置和形状变得不清晰，影响手术准确性。现有的基于特征的方法难以应对噪音、异常值等挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的非刚性点云注册方法（DefTransNet），增强在具有挑战性的场景中的鲁棒性和精度。&lt;h4&gt;方法&lt;/h4&gt;设计了一种端到端的Transformer架构，输入源和目标点云数据，并输出位移矢量场。该模型通过学习变换矩阵来提高对仿射变换的鲁棒性，并集成了全局与局部几何信息以及使用Transformer捕捉点之间的长程依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;在ModelNet、SynBench、4DMatch和DeformedTissue四个数据集上的实验表明，DefTransNet在各种困难条件下优于现有的最先进的注册网络。&lt;h4&gt;结论&lt;/h4&gt;通过利用Transformer的注意力机制并综合全局与局部信息，DefTransNet成功地提高了非刚性点云注册任务中的鲁棒性和精度，并为软组织手术提供了一个有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;软组织外科手术如肿瘤切除术因其难以预测的组织变形而复杂化。将这些组织表面表示为点云并通过应用非刚性点云配准（PCR）方法，外科医生可以在术前、术中和术后更好地了解组织变形情况。然而，现有的非刚性PCR方法在面对噪声、异常值等挑战时鲁棒性较差。尽管基于学习的方法尤其是Transformer方法由于其注意力机制在捕捉交互方面显示出巨大潜力，但它们在复杂场景中的适应性仍有待提高。本文提出了一种新颖的端到端Transformer架构DefTransNet用于非刚性PCR，旨在解决大变形、异常值等问题，并且通过实验验证了该方法的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft-tissue surgeries, such as tumor resections, are complicated by tissuedeformations that can obscure the accurate location and shape of tissues. Byrepresenting tissue surfaces as point clouds and applying non-rigid point cloudregistration (PCR) methods, surgeons can better understand tissue deformationsbefore, during, and after surgery. Existing non-rigid PCR methods, such asfeature-based approaches, struggle with robustness against challenges likenoise, outliers, partial data, and large deformations, making accurate pointcorrespondence difficult. Although learning-based PCR methods, particularlyTransformer-based approaches, have recently shown promise due to theirattention mechanisms for capturing interactions, their robustness remainslimited in challenging scenarios. In this paper, we present DefTransNet, anovel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNetis designed to address the key challenges of deformable registration, includinglarge deformations, outliers, noise, and partial data, by inputting source andtarget point clouds and outputting displacement vector fields. The proposedmethod incorporates a learnable transformation matrix to enhance robustness toaffine transformations, integrates global and local geometric information, andcaptures long-range dependencies among points using Transformers. We validateour approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue,using both synthetic and real-world data to demonstrate the generalization ofour proposed method. Experimental results demonstrate that DefTransNetoutperforms current state-of-the-art registration networks across variouschallenging conditions. Our code and data are publicly available.</description>
      <author>example@mail.com (Sara Monji-Azad, Marvin Kinz, Siddharth Kothari, Robin Khanna, Amrei Carla Mihan, David Maennel, Claudia Scherl, Juergen Hesser)</author>
      <guid isPermaLink="false">2502.06336v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks</title>
      <link>http://arxiv.org/abs/2502.06684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近用于处理表格数据的基础模型在通过上下文学习适应新任务方面表现出色，但这些模型忽视了一个关键的等变性属性：目标维度的任意排序不应影响模型预测。&lt;h4&gt;背景&lt;/h4&gt;TabPFN和其他基础模型已经在各种表格数据任务中展示了强大的表现能力。然而，这类模型存在一个严重的不足，即它们未能考虑到输出维度上的等变性问题，这会导致不稳定性和不可压缩误差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有模型中存在的等变性问题，并通过实验验证该新方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种能够保持输出维度间等变性的新型模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的模型不仅有效地解决了原有模型的不足，还取得了与基准性能相竞争的结果。&lt;h4&gt;结论&lt;/h4&gt;新的模型通过确保目标维度排序对预测结果没有影响，显著提高了模型的稳定性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent foundational models for tabular data, such as TabPFN, havedemonstrated remarkable effectiveness in adapting to new tasks throughin-context learning. However, these models overlook a crucial equivarianceproperty: the arbitrary ordering of target dimensions should not influencemodel predictions. In this study, we identify this oversight as a source ofincompressible error, termed the equivariance gap, which introduces instabilityin predictions. To mitigate these issues, we propose a novel model designed topreserve equivariance across output dimensions. Our experimental resultsindicate that our proposed model not only addresses these pitfalls effectivelybut also achieves competitive benchmark performance.</description>
      <author>example@mail.com (Michael Arbel, David Salinas, Frank Hutter)</author>
      <guid isPermaLink="false">2502.06684v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Prototype Contrastive Consistency Learning for Semi-Supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.06650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为原型对比一致性分割（PCCS）的新方法，用于半监督医学图像分割。&lt;h4&gt;背景&lt;/h4&gt;医疗影像分割在医疗图像分析中至关重要，但在缺乏标注数据而有大量未标记数据的情况下尤其具有挑战性。对比学习通过从部分像素构建对比样本已被证明可用于改进这种情况下的医学影像分割。&lt;h4&gt;目的&lt;/h4&gt;解决现有对比学习方法忽视了未标记图像的整体上下文信息的问题，以提高精确分割效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种原型对比一致性分割（PCCS）新方法。该方法通过构造带有标志距离图和不确定性图的未标注图像来强制相同语义类别的原型彼此接近，并使不同类别之间的原型远离。此外，还设计了学生-教师架构下的原型更新机制来优化对比学习中的原型。&lt;h4&gt;主要发现&lt;/h4&gt;PCCS方法能够从大量未标记数据中挖掘出更可靠的信息，并通过不确定性一致性损失函数进行增强。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，与现有最先进的方法相比，PCCS在医学图像分割方面取得了更好的表现。代码公开于GitHub（https://github.com/comphsh/PCCS）。&lt;h4&gt;翻译&lt;/h4&gt;医疗影像分割是医疗图像分析中的关键任务，但在较少标记数据和大量未标记数据的情况下尤其具有挑战性。对比学习通过从部分像素构建对比样本已被证明对半监督医学影像分割非常有效。然而，尽管先前的对比学习方法可以从图内部分像素中挖掘语义信息，但它们忽略了整个未标记图像的上下文信息，这对于精确分割至关重要。为了解决这个问题，我们提出了一种新颖的原型对比学习方法，称为原型对比一致性分割（PCCS），用于半监督医学影像分割。核心思想是强制相同语义类别的原型彼此接近，并使不同类别之间的原型远离。具体而言，我们从未标记图像中构建了标志距离图和不确定性图。使用标志距离图来构造对比学习中的原型，然后根据不确定性地图估计原型不确定性作为权衡。为了获得更好的原型，在学生-教师架构的基础上设计了一种新的机制——原型更新机制，用于辅助对比学习中的原型更新。此外，我们提出了一种不确定性一致性损失函数，以挖掘未标记数据中的更多可靠信息。广泛的医学图像分割实验表明，PCCS方法在分割性能上优于现有最先进的方法。代码可在GitHub（https://github.com/comphsh/PCCS）获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation is a crucial task in medical image analysis, butit can be very challenging especially when there are less labeled data but withlarge unlabeled data. Contrastive learning has proven to be effective formedical image segmentation in semi-supervised learning by constructingcontrastive samples from partial pixels. However, although previous contrastivelearning methods can mine semantic information from partial pixels withinimages, they ignore the whole context information of unlabeled images, which isvery important to precise segmentation. In order to solve this problem, wepropose a novel prototype contrastive learning method called PrototypeContrastive Consistency Segmentation (PCCS) for semi-supervised medical imagesegmentation. The core idea is to enforce the prototypes of the same semanticclass to be closer and push the prototypes in different semantic classes faraway from each other. Specifically, we construct a signed distance map and anuncertainty map from unlabeled images. The signed distance map is used toconstruct prototypes for contrastive learning, and then we estimate theprototype uncertainty from the uncertainty map as trade-off among prototypes.In order to obtain better prototypes, based on the student-teacherarchitecture, a new mechanism named prototype updating prototype is designed toassist in updating the prototypes for contrastive learning. In addition, wepropose an uncertainty-consistency loss to mine more reliable information fromunlabeled data. Extensive experiments on medical image segmentation demonstratethat PCCS achieves better segmentation performance than the state-of-the-artmethods. The code is available at https://github.com/comphsh/PCCS.</description>
      <author>example@mail.com (Shihuan He, Zhihui Lai, Ruxin Wang, Heng Kong)</author>
      <guid isPermaLink="false">2502.06650v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundational Models for Dynamical System Reconstruction: Hierarchical Meta-Learning via Mixture of Experts</title>
      <link>http://arxiv.org/abs/2502.05335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 11 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;随着基础模型重塑科学研究，动力系统重构（DSR）中仍存在一个瓶颈：跨层次学习的能力。虽然许多元学习方法已经成功地应用于单一系统，但当面对稀疏且松散相关数据集时，这些方法就显得力不从心了。&lt;h4&gt;背景&lt;/h4&gt;在进行科学发现的过程中，基础模型正在重塑动力系统的重构（DSR），然而其主要瓶颈在于跨越不同层次的学习能力。现有的元学习方法虽然对单个系统有效，但在面对稀疏且松散相关数据集时效果不佳，尤其是在需要同时处理多个层次的情况下。&lt;h4&gt;目的&lt;/h4&gt;引入一种基于混合专家（Mixture of Experts, MoE）的新框架来克服现有模型在跨层次动力学重构中的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MixER的方法：混合专家重构器。这种方法采用稀疏的Top-1 Mixture of Expert层，并使用基于K-means和最小二乘法的自定义门控更新算法，以解决传统MoE方法在训练过程中由于梯度下降基线机制导致的学习效率低以及路由冲突问题。&lt;h4&gt;主要发现&lt;/h4&gt;混合专家重构器（MixER）通过定制化的门控更新机制实现了更高效的训练过程，并能够处理多达十个参数化常微分方程的系统。然而，在数据量非常大且每个专家只能处理一小部分高度相关的数据集时，其性能不如现有的元学习者。&lt;h4&gt;结论&lt;/h4&gt;通过合成和神经科学时间序列的数据分析表明，MixER生成上下文表示的质量与数据中层次结构的存在紧密相关。这项研究为未来解决复杂系统中的跨层次学习问题提供了新的思路和方向。&lt;h4&gt;其他要点&lt;/h4&gt;混合专家（MoE）方法具有处理多个层级系统的自然范式优势，但由于其基于梯度下降的门控更新机制，在训练过程中面临效率低下及路由冲突的问题。通过引入MixER解决了这些问题，并展示了该框架在不同领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As foundational models reshape scientific discovery, a bottleneck persists indynamical system reconstruction (DSR): the ability to learn across systemhierarchies. Many meta-learning approaches have been applied successfully tosingle systems, but falter when confronted with sparse, loosely relateddatasets requiring multiple hierarchies to be learned. Mixture of Experts (MoE)offers a natural paradigm to address these challenges. Despite their potential,we demonstrate that naive MoEs are inadequate for the nuanced demands ofhierarchical DSR, largely due to their gradient descent-based gating updatemechanism which leads to slow updates and conflicted routing during training.To overcome this limitation, we introduce MixER: Mixture of ExpertReconstructors, a novel sparse top-1 MoE layer employing a custom gating updatealgorithm based on $K$-means and least squares. Extensive experiments validateMixER's capabilities, demonstrating efficient training and scalability tosystems of up to ten parametric ordinary differential equations. However, ourlayer underperforms state-of-the-art meta-learners in high-data regimes,particularly when each expert is constrained to process only a fraction of adataset composed of highly related data points. Further analysis with syntheticand neuroscientific time series suggests that the quality of the contextualrepresentations generated by MixER is closely linked to the presence ofhierarchical structure in the data.</description>
      <author>example@mail.com (Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin)</author>
      <guid isPermaLink="false">2502.05335v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Evaluation of Deep Audio Representations for Hearables</title>
      <link>http://arxiv.org/abs/2502.06664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference on Acoustics, Speech, and Signal  Processing (ICASSP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍并发布了DEAR，这是一个用于评估基础模型在捕捉对hearables（可听设备）至关重要的声学属性的有效性的数据集和基准。&lt;h4&gt;背景&lt;/h4&gt;理解用户周围的声环境对于有效地引导可听设备至关重要。在声音场景的计算分析中，基于大模型产生了高质量、鲁棒性和多用途的声音表示。&lt;h4&gt;目的&lt;/h4&gt;为了评估基础模型捕捉对hearables至关重要的声学属性的有效性，引入并发布了DEAR数据集和基准。&lt;h4&gt;方法&lt;/h4&gt;该数据集包含1,158段30秒长的音频片段，这些音频片段通过将专有的独白与商业高品质的日常声音场景录音进行空间混合生成。评估基准涵盖了八个任务，用于评价音频场景的一般背景、语音来源及技术声学特性。&lt;h4&gt;主要发现&lt;/h4&gt;通过对四个通用音频表示模型的评估，展示了BEATs模型比其他模型表现得更好，这突显了在多样化的音频集合上训练的大模型的优势，并确认它们适用于广泛的听觉任务，包括编码hearables所需的环境属性。&lt;h4&gt;结论&lt;/h4&gt;DEAR数据集及其相关代码可用于进一步的研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;有效引导可听设备需要了解用户周围的声音环境。在声音场景的计算分析中，基础大模型已成为生成高性能、鲁棒且多功能音频表示的最佳状态方法。我们介绍了并发布了深度评估音频表示（DEAR），这是首个用于评价基础模型捕捉对hearables至关重要的声学属性的数据集和基准。该数据集包括1,158段30秒长的音频片段，这些音频片段通过将专有的独白与商业高品质的日常声音场景录音进行空间混合生成。我们的评估基准涵盖了八个任务，用于评价音频场景的一般背景、语音来源及技术声学特性。通过对四个通用音频表示模型的评估，我们展示了BEATs模型比其他模型表现得更好。这突显了在多样化的音频集合上训练的大模型的优势，并确认它们适用于广泛的听觉任务，包括编码hearables所需的环境属性。DEAR数据集及其相关代码可在https://dear-dataset.github.io获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively steering hearable devices requires understanding the acousticenvironment around the user. In the computational analysis of sound scenes,foundation models have emerged as the state of the art to producehigh-performance, robust, multi-purpose audio representations. We introduce andrelease Deep Evaluation of Audio Representations (DEAR), the first dataset andbenchmark to evaluate the efficacy of foundation models in capturing essentialacoustic properties for hearables. The dataset includes 1,158 audio tracks,each 30 seconds long, created by spatially mixing proprietary monologues withcommercial, high-quality recordings of everyday acoustic scenes. Our benchmarkencompasses eight tasks that assess the general context, speech sources, andtechnical acoustic properties of the audio scenes. Through our evaluation offour general-purpose audio representation models, we demonstrate that the BEATsmodel significantly surpasses its counterparts. This superiority underscoresthe advantage of models trained on diverse audio collections, confirming theirapplicability to a wide array of auditory tasks, including encoding theenvironment properties necessary for hearable steering. The DEAR dataset andassociated code are available at https://dear-dataset.github.io.</description>
      <author>example@mail.com (Fabian Gröger, Pascal Baumann, Ludovic Amruthalingam, Laurent Simon, Ruksana Giurda, Simone Lionetti)</author>
      <guid isPermaLink="false">2502.06664v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>RelGNN: Composite Message Passing for Relational Deep Learning</title>
      <link>http://arxiv.org/abs/2502.06784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了RelGNN，这是一种专门为捕捉关系数据库独特特性设计的新颖图神经网络框架。&lt;h4&gt;背景&lt;/h4&gt;在电子商务、医疗保健和社会媒体等现实世界应用中，基于关系数据库的预测任务至关重要。为了有效应对这些任务，关系深度学习将关系数据编码为图形，使图神经网络能够利用关系结构进行改进的预测。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的GNN框架RelGNN，旨在解决现有异构GNN在建模效率上的不足，更好地捕捉关系数据库的独特特性。&lt;h4&gt;方法&lt;/h4&gt;引入原子路线的概念，并在此基础上设计了新颖的复合消息传递机制，使不同类型的节点之间可以直接进行单跳交互。这避免了冗余聚合和信息纠缠的问题。&lt;h4&gt;主要发现&lt;/h4&gt;RelGNN在来自RelBench的30个不同的现实世界任务上进行了评估，并且始终达到了最先进的精度，最多提高了25%。&lt;h4&gt;结论&lt;/h4&gt;通过利用关系数据库的独特特性以及创新的消息传递机制，RelGNN能够更高效、准确地进行预测。&lt;h4&gt;翻译&lt;/h4&gt;基于关系数据库的预测任务在电子商务、医疗保健和社会媒体等现实世界应用中至关重要。为了有效应对这些任务，现有的图神经网络方法往往忽视了关系数据库固有的结构性质，导致建模效率低下。我们提出了一种新的框架RelGNN，它专门设计来捕捉关系数据库的独特特性，并通过引入原子路线和新颖的消息传递机制提高了预测的准确性和效率。在30个不同现实世界任务上的评估显示，RelGNN能够实现最先进的精度提升，最多提高25%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predictive tasks on relational databases are critical in real-worldapplications spanning e-commerce, healthcare, and social media. To addressthese tasks effectively, Relational Deep Learning (RDL) encodes relational dataas graphs, enabling Graph Neural Networks (GNNs) to exploit relationalstructures for improved predictions. However, existing heterogeneous GNNs oftenoverlook the intrinsic structural properties of relational databases, leadingto modeling inefficiencies. Here we introduce RelGNN, a novel GNN frameworkspecifically designed to capture the unique characteristics of relationaldatabases. At the core of our approach is the introduction of atomic routes,which are sequences of nodes forming high-order tripartite structures. Buildingupon these atomic routes, RelGNN designs new composite message passingmechanisms between heterogeneous nodes, allowing direct single-hop interactionsbetween them. This approach avoids redundant aggregations and mitigatesinformation entanglement, ultimately leading to more efficient and accuratepredictive modeling. RelGNN is evaluated on 30 diverse real-world tasks fromRelBench (Fey et al., 2024), and consistently achieves state-of-the-artaccuracy with up to 25% improvement.</description>
      <author>example@mail.com (Tianlang Chen, Charilaos Kanatsoulis, Jure Leskovec)</author>
      <guid isPermaLink="false">2502.06784v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Institutional Preferences in the Laboratory</title>
      <link>http://arxiv.org/abs/2502.06748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文研究了在社会互动中，个体如何通过改变游戏规则来促进合作。&lt;h4&gt;背景&lt;/h4&gt;在现实世界中，个人不仅被动接受静态环境，还会积极地影响和塑造自己所处的社会系统。这引发了关于动态环境下个体行为对合作的影响的讨论：是阻碍还是推动合作？&lt;h4&gt;目的&lt;/h4&gt;研究团队是否能够通过改变环境参数引导自身达到协作结果。&lt;h4&gt;方法&lt;/h4&gt;设计了一种实验室场景来测试经济游戏中不同社会困境下群体的合作情况，这些游戏在制度特征（稳定性、效率和公平性）方面有所不同。实验提供给参与者一定的行为选择自由以及对规则的二次操控权。&lt;h4&gt;主要发现&lt;/h4&gt;研究关注于自然环境中动态且可选的游戏规则如何影响合作过程，探讨了跨场景转移学习中特性间相互作用的重要性及其对于促进或阻碍协作学习的影响。&lt;h4&gt;结论&lt;/h4&gt;研究表明在具有灵活性和可调性的游戏规则下，群体可以通过改变环境参数来引导自身达到更有效率、公平的合作状态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Getting a group to adopt cooperative norms is an enduring challenge. But inreal-world settings, individuals don't just passively accept staticenvironments, they act both within and upon the social systems that structuretheir interactions. Should we expect the dynamism of player-driven changes tothe "rules of the game" to hinder cooperation -- because of the substantialadded complexity -- or help it, as prosocial agents tweak their environmenttoward non-zero-sum games? We introduce a laboratory setting to test whethergroups can guide themselves to cooperative outcomes by manipulating theenvironmental parameters that shape their emergent cooperation process. We testfor cooperation in a set of economic games that impose different socialdilemmas. These games vary independently in the institutional features ofstability, efficiency, and fairness. By offering agency over behavior alongwith second-order agency over the rules of the game, we understand emergentcooperation in naturalistic settings in which the rules of the game arethemselves dynamic and subject to choice. The literature on transfer learningin games suggests that interactions between features are important and mightaid or hinder the transfer of cooperative learning to new settings.</description>
      <author>example@mail.com (Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey)</author>
      <guid isPermaLink="false">2502.06748v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Particle Tracking with Neuromorphic Computing</title>
      <link>http://arxiv.org/abs/2502.06771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 21 figures, submitted to MDPI Particles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了神经网络架构在无监督学习条件下，通过延迟和突触权重的学习来识别带电粒子轨迹的应用。&lt;h4&gt;背景&lt;/h4&gt;利用脉冲时间依赖性可塑性规则（spike-time-dependent plasticity rule）进行学习。模型中的神经元接收有关粒子碰撞检测器中粒子击中位置的时间编码信息，该检测器基于紧凑型μ介子螺线管第二阶段探测器的几何形状。&lt;h4&gt;目的&lt;/h4&gt;展示一种尖峰神经网络如何能够完全无监督地成功识别带电粒子留下的信号，并且在存在明显噪声的情况下也能有效区分随机或组合撞击产生的假象信号。&lt;h4&gt;方法&lt;/h4&gt;使用模拟数据进行研究，该数据反映了紧凑型μ介子螺线管第二阶段探测器的几何结构和运作模式。利用神经网络模型来学习识别带电粒子轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明尖峰神经网络能够成功地在无监督条件下从背景噪声中区分出带电粒子信号。&lt;h4&gt;结论&lt;/h4&gt;这些研究开启了脉冲神经形态计算应用于粒子追踪的可能性，为进一步探索其在未来高能物理实验中的实时、低能耗的粒子跟踪应用潜力提供了动力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the application of a neural network architecture for identifyingcharged particle trajectories via unsupervised learning of delays and synapticweights using a spike-time-dependent plasticity rule. In the considered model,the neurons receive time-encoded information on the position of particle hitsin a tracking detector for a particle collider, modeled according to thegeometry of the Compact Muon Solenoid Phase II detector. We show how a spikingneural network is capable of successfully identifying in a completelyunsupervised way the signal left by charged particles in the presence ofconspicuous noise from accidental or combinatorial hits. These results open theway to applications of neuromorphic computing to particle tracking, motivatingfurther studies into its potential for real-time, low-power particle trackingin future high-energy physics experiments.</description>
      <author>example@mail.com (Emanuele Coradin, Fabio Cufino, Muhammad Awais, Tommaso Dorigo, Enrico Lupi, Eleonora Porcu, Jinu Raj, Fredrik Sandin, Mia Tosi)</author>
      <guid isPermaLink="false">2502.06771v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>FairDropout: Using Example-Tied Dropout to Enhance Generalization of Minority Groups</title>
      <link>http://arxiv.org/abs/2502.06695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;深度学习模型常利用训练数据中的虚假特征来达到低训练误差，这通常导致在测试分布发生变化时泛化能力差。本文提出了一种名为FairDropout的方法，通过调整记忆机制以减少对虚假相关性的依赖，并提高了对抗虚假关联的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型经常利用训练数据中的虚假特征来达到低训练误差，这使得它们在面对测试分布变化时泛化能力较差。已有多种方法被提出增强深度神经网络的稳健性，但这些方法往往无法很好地处理多数群体和少数群体之间的记忆问题。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过调整模型的记忆机制，减少对虚假相关性的依赖，并提高深度学习模型在不同子群间的公平性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;基于最近的研究发现，即记忆可以被限制为有限数量的神经元中，作者提出了名为FairDropout的方法。这种方法通过对特定神经元应用示例绑定dropout，在推理过程中删除这些神经元，从而重新定向了模型的记忆过程到特定的神经元上。&lt;h4&gt;主要发现&lt;/h4&gt;通过在包含视觉、语言和医疗任务的子群体基准套件上的实验评估，作者证明该方法显著减少了对虚假相关性的依赖，并且优于现有的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;FairDropout作为一种新颖的方法，在减少深度学习模型中虚假特征的影响方面显示出了巨大潜力。这种方法不仅提高了模型在不同环境下的鲁棒性，也增强了模型的公平性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models frequently exploit spurious features in training data toachieve low training error, often resulting in poor generalization when facedwith shifted testing distributions. To address this issue, various methods fromimbalanced learning, representation learning, and classifier recalibration havebeen proposed to enhance the robustness of deep neural networks againstspurious correlations. In this paper, we observe that models trained withempirical risk minimization tend to generalize well for examples from themajority groups while memorizing instances from minority groups. Building onrecent findings that show memorization can be localized to a limited number ofneurons, we apply example-tied dropout as a method we term FairDropout, aimedat redirecting this memorization to specific neurons that we subsequently dropout during inference. We empirically evaluate FairDropout using thesubpopulation benchmark suite encompassing vision, language, and healthcaretasks, demonstrating that it significantly reduces reliance on spuriouscorrelations, and outperforms state-of-the-art methods.</description>
      <author>example@mail.com (Geraldin Nanfack, Eugene Belilovsky)</author>
      <guid isPermaLink="false">2502.06695v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Driven Continual Graph Learning</title>
      <link>http://arxiv.org/abs/2502.06327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为PROMPTCGL的新型提示驱动的连续图学习框架，该框架旨在解决传统记忆回放方法在处理不断演化的图数据时遇到的可扩展性和隐私问题。&lt;h4&gt;背景&lt;/h4&gt;连续图学习(CGL)的目标是在不忘记先前知识的情况下适应新的任务和不断变化的图数据。主流解决方案采用基于记忆重播的思想，但这种方法面对大规模持续进化的图数据时存在可扩展性问题，并且在处理用户敏感信息时可能引发隐私担忧。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的提示驱动连续图学习(PROMPTCGL)框架，旨在解决传统方法的局限性，同时保持模型固定不变以避免先前任务知识的灾难性遗忘。&lt;h4&gt;方法&lt;/h4&gt;提出层次化提示机制，从特征和拓扑层面指导模型处理动态环境中任务图的变化。开发个性化提示生成器为每个节点生成定制化的提示，并尽量减少使用的提示数量，从而实现与图规模无关的记忆消耗量。&lt;h4&gt;主要发现&lt;/h4&gt;PROMPTCGL框架在四个基准测试中展示了比现有连续图学习方法更优越的性能和显著降低的内存占用。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的提示机制解决了持续演化图数据处理中的知识遗忘问题，并且有效减少了内存使用，证明了该方法的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容为：连续图学习（CGL）旨在无需忘记先前的知识的情况下适应不断演变的图形数据中新出现的任务。主流解决方案采用基于记忆回放的思想，即通过存储早期任务中的代表性数据重新训练图形模型。然而，这种策略在面对持续进化的图形时面临可扩展性问题，并且引发关于数据隐私的关注。本文受最近提示学习范式的进展启发，提出了一种新的提示驱动连续图学习（PROMPTCGL）框架，该框架为每个新任务学习一个单独的提示并保持底层图神经网络模型不变。以此方式，PROMPTCGL自然避免了先前任务知识的灾难性遗忘。具体而言，我们提出了分层提示机制，在特征和拓扑级别上引导模型以全面应对动态连续学习中任务图形的变化多样性。此外，我们开发了一个个性化提示生成器为每个图节点生成定制化提示，并尽量减少所需提示的数量，从而实现了与图形规模无关的恒定内存消耗。在四个基准测试上的广泛实验表明，PROMPTCGL相比现有的CGL方法表现出更优越的性能并显著减少了内存使用量。我们的代码可在https://github.com/QiWang98/PromptCGL获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual Graph Learning (CGL), which aims to accommodate new tasks overevolving graph data without forgetting prior knowledge, is garneringsignificant research interest. Mainstream solutions adopt the memoryreplay-based idea, ie, caching representative data from earlier tasks forretraining the graph model. However, this strategy struggles with scalabilityissues for constantly evolving graphs and raises concerns regarding dataprivacy. Inspired by recent advancements in the prompt-based learning paradigm,this paper introduces a novel prompt-driven continual graph learning(PROMPTCGL) framework, which learns a separate prompt for each incoming taskand maintains the underlying graph neural network model fixed. In this way,PROMPTCGL naturally avoids catastrophic forgetting of knowledge from previoustasks. More specifically, we propose hierarchical prompting to instruct themodel from both feature- and topology-level to fully address the variability oftask graphs in dynamic continual learning. Additionally, we develop apersonalized prompt generator to generate tailored prompts for each graph nodewhile minimizing the number of prompts needed, leading to constant memoryconsumption regardless of the graph scale. Extensive experiments on fourbenchmarks show that PROMPTCGL achieves superior performance against existingCGL approaches while significantly reducing memory consumption. Our code isavailable at https://github.com/QiWang98/PromptCGL.</description>
      <author>example@mail.com (Qi Wang, Tianfei Zhou, Ye Yuan, Rui Mao)</author>
      <guid isPermaLink="false">2502.06327v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification</title>
      <link>http://arxiv.org/abs/2502.06619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了一种新的用于增强域通用再识别（DG Re-ID）的方法，通过结合辨别式和对比性重识别模型与预训练的扩散模型，并引入一种感知相关性的条件化方案来提高特征泛化能力。&lt;h4&gt;背景&lt;/h4&gt;领域可迁移的重识别任务旨在在一个或多个源领域上训练模型，并在未见的目标领域上评估其性能。由于其实用价值，这个任务越来越受到研究者的关注。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法DCAC（扩散模型辅助表示学习和感知相关性的条件化方案），以提高域通用重识别的性能。&lt;h4&gt;方法&lt;/h4&gt;该方法将辨别式和对比性重识别模型与预训练的扩散模型通过一种感知相关性的条件化方案相结合。该方案利用了来自重识别模型的身份分类概率，并结合一组可学习的身份提示，从而注入暗知识来捕捉身份之间的关联以指导扩散过程。同时，从扩散模型反馈的信息也通过此条件化方案反向传播到重识别模型。&lt;h4&gt;主要发现&lt;/h4&gt;在单一源域和多源域的DG Re-ID任务上进行了广泛的实验，结果表明该方法实现了最先进的性能。并且，全面消融研究表明了所提出的方法的有效性，并提供了关于其鲁棒性的见解。&lt;h4&gt;结论&lt;/h4&gt;通过利用预训练扩散模型与重识别模型之间的交互，可以显著提高特征的泛化能力，在DG Re-ID任务中取得了很好的效果。&lt;h4&gt;翻译&lt;/h4&gt;领域可迁移的重识别（DG Re-ID）旨在在一个或多个源领域上训练一个模型，并在未见的目标域上评估其性能。虽然已经提出了许多方法，但大多数依赖于辨别式或对比性学习框架来学习通用特征表示。然而，这些方法通常无法缓解捷径学习问题，导致性能不佳。本文提出了一种新的名为扩散模型辅助表示学习与感知相关性的条件化方案（DCAC）的方法来增强DG Re-ID任务的处理能力。该方法将一个辨别式和对比性重识别模型与预训练的扩散模型通过一种感知相关性的条件化方案结合在一起，从而提高特征的泛化性能。大量的实验显示，在单一源域和多源域上，我们的方法达到了最先进的性能水平，并且全面消融研究进一步验证了所提出的方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s25020552&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain-generalizable re-identification (DG Re-ID) aims to train a model onone or more source domains and evaluate its performance on unseen targetdomains, a task that has attracted growing attention due to its practicalrelevance. While numerous methods have been proposed, most rely ondiscriminative or contrastive learning frameworks to learn generalizablefeature representations. However, these approaches often fail to mitigateshortcut learning, leading to suboptimal performance. In this work, we proposea novel method called diffusion model-assisted representation learning with acorrelation-aware conditioning scheme (DCAC) to enhance DG Re-ID. Our methodintegrates a discriminative and contrastive Re-ID model with a pre-traineddiffusion model through a correlation-aware conditioning scheme. Byincorporating ID classification probabilities generated from the Re-ID modelwith a set of learnable ID-wise prompts, the conditioning scheme injects darkknowledge that captures ID correlations to guide the diffusion process.Simultaneously, feedback from the diffusion model is back-propagated throughthe conditioning scheme to the Re-ID model, effectively improving thegeneralization capability of Re-ID features. Extensive experiments on bothsingle-source and multi-source DG Re-ID tasks demonstrate that our methodachieves state-of-the-art performance. Comprehensive ablation studies furthervalidate the effectiveness of the proposed approach, providing insights intoits robustness. Codes will be available at https://github.com/RikoLi/DCAC.</description>
      <author>example@mail.com (Jiachen Li, Xiaojin Gong)</author>
      <guid isPermaLink="false">2502.06619v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>IceBerg: Debiased Self-Training for Class-Imbalanced Node Classification</title>
      <link>http://arxiv.org/abs/2502.06280v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf (WWW) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IceBerg的去偏自训练框架，用于解决图神经网络在处理类别不平衡和少量样本情况时面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）虽然在处理非欧几里得图结构数据方面取得了巨大成功，并被广泛应用于现实世界的应用中，但在类别不平衡的数据集中其效果往往会受到威胁。现有的大多数研究从监督学习的角度分析了类别不平衡的节点分类问题，但并未充分利用半监督场景下的大量未标记节点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自训练框架IceBerg来同时解决图神经网络在类别不平衡和少量样本情况下的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了Double Balancing策略以解决自我训练中的马太效应和标签分布偏移问题，以及通过分离传播与转换操作提升GNN的长距离传播能力。&lt;h4&gt;主要发现&lt;/h4&gt;利用未标记节点可以显著增强图神经网络在类别不平衡和少量样本场景下的性能，并且即使进行微小、手术性的修改也能带来显著的性能改进。&lt;h4&gt;结论&lt;/h4&gt;IceBerg框架在基准数据集上的系统实验表明，它能大大超越现有的类别不平衡节点分类基线。同时由于其卓越的利用无监督信号的能力，在少量样本节点分类场景中也取得了最先进的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）已在处理非欧几里得图结构数据方面取得巨大成功，并被广泛应用于许多现实世界的应用程序中。然而，它们的效果往往在类别不平衡的训练集下受到威胁。大多数现有研究从监督学习的角度分析了类别不平衡的节点分类问题，但并未充分利用半监督场景下的大量未标记节点。我们主张监督信号只是冰山一角，大量的未标记节点尚未被有效利用。在这项工作中，我们提出了一种名为IceBerg的去偏自训练框架，以同时解决图神经网络在处理类别不平衡和少量样本情况时面临的挑战。具体而言，为了解决自我训练中的马太效应和标签分布偏移问题，我们提出了双平衡策略，只需几行代码就可以作为简单的即插即用模块极大地改进现有基线的性能。其次，为了增强GNNs的长距离传播能力，我们将传播与转换操作分开。因此，弱监督信号可以更有效地传播到未标记节点中以解决少量样本问题。总之，我们发现利用未标记节点可以在类别不平衡和少量样本场景下显著提高图神经网络的性能，并且即使是微小、手术性的修改也可以带来可观的性能改进。基准数据集上的系统实验表明我们的方法能大大超越现有的类别不平衡节点分类基线。此外，由于IceBerg卓越地利用无监督信号的能力，在少量样本节点分类场景中也取得了最先进的结果。IceBerg代码可在https://github.com/ZhixunLEE/IceBerg获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved great success in dealing withnon-Euclidean graph-structured data and have been widely deployed in manyreal-world applications. However, their effectiveness is often jeopardizedunder class-imbalanced training sets. Most existing studies have analyzedclass-imbalanced node classification from a supervised learning perspective,but they do not fully utilize the large number of unlabeled nodes insemi-supervised scenarios. We claim that the supervised signal is just the tipof the iceberg and a large number of unlabeled nodes have not yet beeneffectively utilized. In this work, we propose IceBerg, a debiasedself-training framework to address the class-imbalanced and few-shot challengesfor GNNs at the same time. Specifically, to figure out the Matthew effect andlabel distribution shift in self-training, we propose Double Balancing, whichcan largely improve the performance of existing baselines with just a few linesof code as a simple plug-and-play module. Secondly, to enhance the long-rangepropagation capability of GNNs, we disentangle the propagation andtransformation operations of GNNs. Therefore, the weak supervision signals canpropagate more effectively to address the few-shot issue. In summary, we findthat leveraging unlabeled nodes can significantly enhance the performance ofGNNs in class-imbalanced and few-shot scenarios, and even small, surgicalmodifications can lead to substantial performance improvements. Systematicexperiments on benchmark datasets show that our method can deliver considerableperformance gain over existing class-imbalanced node classification baselines.Additionally, due to IceBerg's outstanding ability to leverage unsupervisedsignals, it also achieves state-of-the-art results in few-shot nodeclassification scenarios. The code of IceBerg is available at:https://github.com/ZhixunLEE/IceBerg.</description>
      <author>example@mail.com (Zhixun Li, Dingshuo Chen, Tong Zhao, Daixin Wang, Hongrui Liu, Zhiqiang Zhang, Jun Zhou, Jeffrey Xu Yu)</author>
      <guid isPermaLink="false">2502.06280v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Clustering-based Prototypes for Compositional Zero-shot Learning</title>
      <link>http://arxiv.org/abs/2502.06501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025; Project page:  https://github.com/quhongyu/ClusPro&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ClusPro的框架，该框架旨在解决组成零样本学习（CZSL）中的挑战，通过开发一个基于聚类的原型挖掘框架来应对现有解决方案中过度简化的数据假设问题。&lt;h4&gt;背景&lt;/h4&gt;在构成性零样本学习（Compositional Zero-Shot Learning, CZSL）领域，从已知组合中学习基本概念是主要的挑战。现有的CZSL解决方案往往依赖于过于简单的数据假设，并忽视了属性或对象在与其他实体结合时的自然多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的原型挖掘框架来解决现有CZSL方法中的局限性问题。&lt;h4&gt;方法&lt;/h4&gt;ClusPro通过聚类技术自动发现和动态更新嵌入空间中的原型，进而构建出一个结构良好且独立的基本概念（属性或对象）表示空间。这些原型用于进行基于对比学习的去相关化学习，确保了同类内部分离和不同类型之间的去相关。&lt;h4&gt;主要发现&lt;/h4&gt;ClusPro框架在多个基准测试中表现出色，在闭集世界和开放世界的设置下均超越了许多领先的CZSL解决方案。&lt;h4&gt;结论&lt;/h4&gt;ClusPro提供了一种无需引入额外可学习参数或计算预算即可进行原型聚类的有效方法，从而为解决构成性零样本学习问题开辟了新的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning primitive (i.e., attribute and object) concepts from seencompositions is the primary challenge of Compositional Zero-Shot Learning(CZSL). Existing CZSL solutions typically rely on oversimplified dataassumptions, e.g., modeling each primitive with a single centroid primitiverepresentation, ignoring the natural diversities of the attribute (resp.object) when coupled with different objects (resp. attribute). In this work, wedevelop ClusPro, a robust clustering-based prototype mining framework for CZSLthat defines the conceptual boundaries of primitives through a set ofdiversified prototypes. Specifically, ClusPro conducts within-primitiveclustering on the embedding space for automatically discovering and dynamicallyupdating prototypes. These representative prototypes are subsequently used torepaint a well-structured and independent primitive embedding space, ensuringintra-primitive separation and inter-primitive decorrelation throughprototype-based contrastive learning and decorrelation learning. Moreover,ClusPro efficiently performs prototype clustering in a non-parametric fashionwithout the introduction of additional learnable parameters or computationalbudget during testing. Experiments on three benchmarks demonstrate ClusProoutperforms various top-leading CZSL solutions under both closed-world andopen-world settings.</description>
      <author>example@mail.com (Hongyu Qu, Jianan Wei, Xiangbo Shu, Wenguan Wang)</author>
      <guid isPermaLink="false">2502.06501v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning for Feature Extraction and Temporal Alignment of 3D+t Point Clouds of Zebrafish Embryos</title>
      <link>http://arxiv.org/abs/2502.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种无需人工标注的自动对齐斑马鱼胚胎发育阶段的方法。&lt;h4&gt;背景&lt;/h4&gt;斑马鱼在生物医学研究中被广泛使用，其胚胎发育阶段需要同步以进行进一步分析。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来从3D+t点云数据提取描述性特征，并将相应的发展阶段时间上对齐。&lt;h4&gt;方法&lt;/h4&gt;设计了一种自编码器架构用于学习点云的描述表示，并采用深度回归网络实现它们的时间对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实现了高达98.14%的对齐准确度，平均偏差仅为3.83分钟，在整个实验持续时间5.3小时的情况下表现优异。&lt;h4&gt;结论&lt;/h4&gt;作为一种完全无监督的方法，无需手动标记和主观偏见影响，易于扩展且避免了人工分析的限制。&lt;h4&gt;翻译&lt;/h4&gt;斑马鱼在生物医学研究中广泛用于胚胎发育阶段的研究。为了对这些阶段进行同步分析，研究人员提出了一种新的方法，该方法通过自动编码器架构学习点云数据，并使用深度回归网络将不同时间点的数据进行精确的时间对齐，平均偏差仅为3.83分钟，整个实验过程中无须人工干预或标签输入。这种方法不仅提高了研究效率，而且减少了主观偏见的影响，并且能够适应大规模数据分析的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-43993-3_58&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zebrafish are widely used in biomedical research and developmental stages oftheir embryos often need to be synchronized for further analysis. We present anunsupervised approach to extract descriptive features from 3D+t point clouds ofzebrafish embryos and subsequently use those features to temporally aligncorresponding developmental stages. An autoencoder architecture is proposed tolearn a descriptive representation of the point clouds and we designed a deepregression network for their temporal alignment. We achieve a high alignmentaccuracy with an average mismatch of only 3.83 minutes over an experimentalduration of 5.3 hours. As a fully-unsupervised approach, there is no manuallabeling effort required and unlike manual analyses the method easily scales.Besides, the alignment without human annotation of the data also avoids anyinfluence caused by subjective bias.</description>
      <author>example@mail.com (Zhu Chen, Ina Laube, Johannes Stegmaier)</author>
      <guid isPermaLink="false">2502.06543v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Feature Fusion with Image-Driven Spatial Integration for Left Atrium Segmentation from Cardiac MRI Images</title>
      <link>http://arxiv.org/abs/2502.06615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于DINOv2和UNet的框架，用于从心脏MRI图像中自动分割左心房（LA），以提高心血管疾病诊断和管理的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确地从延迟钆增强磁共振成像中分割出左心房对可视化病变的心脏结构至关重要，特别是在使用消融疗法治疗心房颤动时。然而，手动分割耗时且容易出现观察者间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一个自动化的解决方案来提高心脏MRI图像中左心房的分割精度。&lt;h4&gt;方法&lt;/h4&gt;将类不可知基础模型DINOv2作为编码器，与UNet风格解码器结合，并加入多尺度特征融合和输入图像集成以增强分割准确性。引入了可学习加权机制以及在解码阶段重新引入原始输入图象来保持高分辨率空间细节。&lt;h4&gt;主要发现&lt;/h4&gt;通过LAScarQS 2022数据集验证，该方法比nnUNet基线模型的性能有所提高，在大型架构下Dice分数为92.3%，IoU得分为84.1%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明了所提出的方法在自动左心房分割领域的有效性。&lt;h4&gt;翻译&lt;/h4&gt;准确地从延迟钆增强磁共振成像中分割出左心房对于可视化病变的心脏结构至关重要，特别是在使用消融疗法治疗心房颤动时。然而，手动分割耗时且容易出现观察者间差异。为了应对这一挑战，研究团队提出了一种结合DINOv2作为编码器和UNet风格解码器的框架，并通过多尺度特征融合和输入图像集成来增强分割准确性。实验结果表明，在LAScarQS 2022数据集上的Dice分数达到92.3%，IoU得分为84.1%。这突显了该方法在自动左心房分割领域的有效性，有望推动相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate segmentation of the left atrium (LA) from late gadolinium-enhancedmagnetic resonance imaging plays a vital role in visualizing diseased atrialstructures, enabling the diagnosis and management of cardiovascular diseases.It is particularly essential for planning treatment with ablation therapy, akey intervention for atrial fibrillation (AF). However, manual segmentation istime-intensive and prone to inter-observer variability, underscoring the needfor automated solutions. Class-agnostic foundation models like DINOv2 havedemonstrated remarkable feature extraction capabilities in vision tasks.However, their lack of domain specificity and task-specific adaptation canreduce spatial resolution during feature extraction, impacting the capture offine anatomical detail in medical imaging. To address this limitation, wepropose a segmentation framework that integrates DINOv2 as an encoder with aUNet-style decoder, incorporating multi-scale feature fusion and input imageintegration to enhance segmentation accuracy. The learnable weighting mechanismdynamically prioritizes hierarchical features from different encoder blocks ofthe foundation model, optimizing feature selection for task relevance.Additionally, the input image is reintroduced during the decoding stage topreserve high-resolution spatial details, addressing limitations ofdownsampling in the encoder. We validate our approach on the LAScarQS 2022dataset and demonstrate improved performance with a 92.3% Dice and 84.1% IoUscore for giant architecture compared to the nnUNet baseline model. Thesefindings emphasize the efficacy of our approach in advancing the field ofautomated left atrium segmentation from cardiac MRI.</description>
      <author>example@mail.com (Bipasha Kundu, Zixin Yang, Richard Simon, Cristian Linte)</author>
      <guid isPermaLink="false">2502.06615v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Structure-preserving contrastive learning for spatial time series</title>
      <link>http://arxiv.org/abs/2502.06380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TL;DR: Preserving certain structures of similarity relations in  spatio-temporal data can improve downstream task performance via contrastive  learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的自监督学习方法，通过引入两个结构保持正则化器来增强时空序列（如交通互动）的信息表示，并展示了该方法在多变量时间序列分类、宏观和微观交通预测中的有效性。&lt;h4&gt;背景&lt;/h4&gt;时空序列数据的表示学习面临挑战，尤其是在维护隐藏空间中细粒度相似性关系时。自监督学习需要有效的方法来保持结构信息。&lt;h4&gt;目的&lt;/h4&gt;通过引入两个新的正则化器改进对比学习方法，并提出动态机制以适应性调整权衡，从而提高模型在时空序列任务中的表现和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;论文提出了两个用于对比学习的结构保持正则化器：一个保持实例间的相似性的拓扑结构，另一个保持跨空间和时间维度的图几何结构。此外，还提出了一种动态机制来平衡对比学习与结构保存之间的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法在多变量时间序列分类、宏观及微观交通预测任务中显著提高了现有最佳性能，并展示了更高相似性结构保留意味着更具有信息量和有用性的表示。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种通用且有效的自监督学习框架，对于时空或地理特征的时间序列特别有益。这一方法有助于理解神经网络在模式识别中的表征学习贡献，并公开了相关代码和数据。&lt;h4&gt;翻译&lt;/h4&gt;本文通过引入两个结构保持正则化器改进对比学习的方法来增强时空序列的数据表示，从而提高自监督模型的性能及泛化能力。该研究显示所提出的方法能更有效地保留相似性关系的结构，并在多变量时间序列分类以及宏观和微观交通预测任务中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Informative representations enhance model performance and generalisability indownstream tasks. However, learning self-supervised representations forspatially characterised time series, like traffic interactions, poseschallenges as it requires maintaining fine-grained similarity relations in thelatent space. In this study, we incorporate two structure-preservingregularisers for the contrastive learning of spatial time series: oneregulariser preserves the topology of similarities between instances, and theother preserves the graph geometry of similarities across spatial and temporaldimensions. To balance contrastive learning and structure preservation, wepropose a dynamic mechanism that adaptively weighs the trade-off and stabilisestraining. We conduct experiments on multivariate time series classification, aswell as macroscopic and microscopic traffic prediction. For all three tasks,our approach preserves the structures of similarity relations more effectivelyand improves state-of-the-art task performances. The proposed approach can beapplied to an arbitrary encoder and is particularly beneficial for time serieswith spatial or geographical features. Furthermore, this study suggests thathigher similarity structure preservation indicates more informative and usefulrepresentations. This may help to understand the contribution of representationlearning in pattern recognition with neural networks. Our code is made openlyaccessible with all resulting data at https://github.com/yiru-jiao/spclt.</description>
      <author>example@mail.com (Yiru Jiao, Sander van Cranenburgh, Simeon Calvert, Hans van Lint)</author>
      <guid isPermaLink="false">2502.06380v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Physically-Based Mesh Generation for Confined 3D Point Clouds Using Flexible Foil Models</title>
      <link>http://arxiv.org/abs/2502.06541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个通过模拟空间约束下的柔性箔片来从受限的3D点云构造高质量封闭表面网格的方法。&lt;h4&gt;背景&lt;/h4&gt;在计算机图形学和计算几何领域，需要一种能够生成物理上准确且现实的网格结构的技术方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于物理的模拟技术，用于从3D点云数据中创建高真实性和物理准确性要求的闭合表面网格。&lt;h4&gt;方法&lt;/h4&gt;采用动态弹性、压力驱动变形以及自适应固定顶点捕获等机制来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法可以有效地构建高质量且封闭的表面网格，适用于各种计算机图形学和计算几何的应用场景。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为从受限3D点云构造物理上准确的闭合表面网格提供了一个稳健框架，并展示了其在计算机图形学和计算几何领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种通过模拟空间约束下的柔性箔片来从限制性3D点云中构建高质量封闭表面网格的方法。该方法结合了动态弹性、压力驱动变形以及固定顶点的自适应捕捉，提供了一个用于创建现实且物理准确网格的强大框架。讨论了这种方法在计算机图形学和计算几何中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a method for constructing high-quality, closed-surface meshes fromconfined 3D point clouds via a physically-based simulation of flexible foilsunder spatial constraints. The approach integrates dynamic elasticity,pressure-driven deformation, and adaptive snapping to fixed vertices, providinga robust framework for realistic and physically accurate mesh creation.Applications in computer graphics and computational geometry are discussed.</description>
      <author>example@mail.com (Netzer Moriya)</author>
      <guid isPermaLink="false">2502.06541v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?</title>
      <link>http://arxiv.org/abs/2502.06555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;差分隐私（DP）合成数据是一种使私人数据分析成为可能的多功能工具。近年来，在大型语言模型（LLMs）方面的进展激发了许多改进DP合成数据生成的技术。&lt;h4&gt;目的&lt;/h4&gt;提出两种仅需访问基础模型API就能进行DP合成表格数据算法的方法，并探讨这些方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;{'私有演化算法扩展': '将适用于图像和文本数据的Private Evolution算法（Lin et al., 2023; Xie et al., 2024）适应到表格数据领域，定义基于查询工作负载的距离度量。', '一次性API访问算法': '提出一系列使用一次性的LLM API访问，而不是对LLM进行自适应查询的算法家族。'}&lt;h4&gt;主要发现&lt;/h4&gt;强大的LLMs通过API访问并不总是能提高DP合成数据的质量，这与不使用此类访问的传统基线方法相比。&lt;h4&gt;结论&lt;/h4&gt;提供关于为何这种现象发生的原因，并提出改进LLMs的具体建议，使它们更加适用于此类应用。&lt;h4&gt;翻译&lt;/h4&gt;差分隐私（DP）合成数据是处理私人数据分析的一种多功能工具。大型语言模型的最新进展激发了一系列旨在改善DP合成数据生成技术的方法。一种方法通过在基础模型权重上进行差分私有微调来实现；然而，最先进的模型的权重可能不会公开共享。本研究提出两种仅需API访问到基础模型就能执行DP合成表格数据算法。我们适应了适用于图像和文本数据的Private Evolution算法（Lin et al., 2023; Xie et al., 2024），并将它应用于表格数据领域，定义了一种基于查询工作负载的距离度量。此外，提出了一系列使用单次API访问到LLM的方法而非多次自适应查询到LLM的算法家族。我们的研究结果表明，通过API访问强大的LLMs并不总是能够提高DP合成数据的质量，与传统基线方法相比，并提供了导致这一现象的根本原因以及改进LLMs以使其在这个应用中更有效的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentially private (DP) synthetic data is a versatile tool for enablingthe analysis of private data. Recent advancements in large language models(LLMs) have inspired a number of algorithm techniques for improving DPsynthetic data generation. One family of approaches uses DP finetuning on thefoundation model weights; however, the model weights for state-of-the-artmodels may not be public. In this work we propose two DP synthetic tabular dataalgorithms that only require API access to the foundation model. We adapt thePrivate Evolution algorithm (Lin et al., 2023; Xie et al., 2024) -- which wasdesigned for image and text data -- to the tabular data domain. In ourextension of Private Evolution, we define a query workload-based distancemeasure, which may be of independent interest. We propose a family ofalgorithms that use one-shot API access to LLMs, rather than adaptive queriesto the LLM. Our findings reveal that API-access to powerful LLMs does notalways improve the quality of DP synthetic data compared to establishedbaselines that operate without such access. We provide insights into theunderlying reasons and propose improvements to LLMs that could make them moreeffective for this application.</description>
      <author>example@mail.com (Marika Swanberg, Ryan McKenna, Edo Roth, Albert Cheu, Peter Kairouz)</author>
      <guid isPermaLink="false">2502.06555v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Koopman-Equivariant Gaussian Processes</title>
      <link>http://arxiv.org/abs/2502.06645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 28th International Conference on Artificial  Intelligence and Statistics (AISTATS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了针对线性时不变响应的动力系统的一系列高斯过程（GP）模型，该类模型仅在初始条件上是非线性的。这种线性特性允许同时可追踪地量化预测和表示不确定性，并简化了从基于GP的动力学系统中计算轨迹分布的挑战。&lt;h4&gt;背景&lt;/h4&gt;可靠的决策制定需要对动力系统的可信预测及表征学习的能力不断提高。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的高斯过程（GP）模型家族，用于解决线性时不变响应的动力系统中的可预测性和表示不确定性问题，并采用基于诱导点的变分推理方法支持大规模回归。&lt;h4&gt;方法&lt;/h4&gt;使用了轨迹等价性的概念——称为“Koopman等价性”——来提高GP模型的一般化能力。同时采用了基于适当诱导点的变分推断，以应对大规模回归的任务。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示所提出的模型在预测性能上与基于核的方法学习动力系统时相比，至少相当且有时更好。&lt;h4&gt;结论&lt;/h4&gt;通过利用线性响应特性及Koopman等价性的概念，能够有效地解决从高斯过程驱动的动力学系统中推断轨迹分布的问题，并展示了该方法的有效性和潜在优势。&lt;h4&gt;翻译&lt;/h4&gt;可信的预测和表示学习对于动力系统的可靠决策至关重要。为此，我们提出了针对线性时不变响应的动力系统的一系列高斯过程（GP）模型，这些模型仅在初始条件上是非线性的。这种线性特性使我们可以同时可追踪地量化预测和表示不确定性，并简化了从基于GP的动力学系统中计算轨迹分布的挑战。利用一种被称为“Koopman等价性”的轨迹等价性概念，我们得到了一个具有增强泛化能力的GP模型。为了支持大规模回归，我们在框架中引入了基于适当诱导点的变分推理方法。实验结果表明，与用于学习动力系统的基于核的方法相比，我们的预测性能至少相当且通常更好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Credible forecasting and representation learning of dynamical systems are ofever-increasing importance for reliable decision-making. To that end, wepropose a family of Gaussian processes (GP) for dynamical systems with lineartime-invariant responses, which are nonlinear only in initial conditions. Thislinearity allows us to tractably quantify forecasting and representationaluncertainty, simultaneously alleviating the challenge of computing thedistribution of trajectories from a GP-based dynamical system and enabling anew probabilistic treatment of learning Koopman operator representations. Usinga trajectory-based equivariance -- which we refer to as \textit{Koopmanequivariance} -- we obtain a GP model with enhanced generalizationcapabilities. To allow for large-scale regression, we equip our framework withvariational inference based on suitable inducing points. Experimentsdemonstrate on-par and often better forecasting performance compared tokernel-based methods for learning dynamical systems.</description>
      <author>example@mail.com (Petar Bevanda, Max Beier, Armin Lederer, Alexandre Capone, Stefan Sosnowski, Sandra Hirche)</author>
      <guid isPermaLink="false">2502.06645v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Hyperparameters in Score-Based Membership Inference Attacks</title>
      <link>http://arxiv.org/abs/2502.06374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted for publication in the 3rd IEEE  Conference on Secure and Trustworthy Machine Learning (SaTML'25). The final  version will be available on IEEE Xplore&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Membership Inference Attacks (MIA) 方法，展示了在转移学习环境中进行MIA时，攻击者不需要知道目标模型的超参数。通过匹配目标和影子模型的输出分布来选择合适的超参数。&lt;h4&gt;背景&lt;/h4&gt;现有的基于分数的MIA方法假设攻击者了解目标模型的超参数，这些信息可用于训练用于攻击的影子模型。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的方法，在不知道目标模型超参数的情况下，为影子模型选择适当的超参数以进行有效的MIA。&lt;h4&gt;方法&lt;/h4&gt;通过匹配输出分布来选择适合的超参数。这种方法在性能上与使用实际目标模型超参数训练得到的结果相近。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，提出的基于输出分布的方法能够找到近似的目标模型的超参数，并且这种新方法不会因为进行超参数优化而增加MIA攻击的风险。&lt;h4&gt;结论&lt;/h4&gt;新的MIA方法不需要了解目标模型的具体信息就能有效地执行。此外，在使用训练数据进行超参数优化时，不同隐私保护机制下的隐私风险差异不大。&lt;h4&gt;翻译&lt;/h4&gt;成员推断攻击（MIAs）已成为评估机器学习模型隐私泄漏的有价值的框架。基于分数的MIAs尤其因为能够利用模型为特定输入生成的信心得分而著称。现有的基于分数的MIA方法隐含地假设攻击者可以访问目标模型的超参数，这些信息可用于训练影子模型进行攻击。在这项工作中，我们证明了在转移学习环境中执行MIA并不需要知道目标模型的超参数知识。基于此，当攻击者没有关于其先前的知识时，我们提出了一个新方法来选择用于训练影子模型以进行MIA的超参数，通过匹配目标和影子模型的输出分布实现。我们展示了使用这种方法可以得到几乎与利用实际目标超参数训练出来的影子模型效果相当的超参数集合。此外，我们研究了在不同的隐私保护机制下，未考虑到的用于训练数据进行超参数优化（HPO）的实践隐私风险，并没有发现显著统计证据表明使用训练数据执行超参数优化会增加对MIA攻击的脆弱性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Membership Inference Attacks (MIAs) have emerged as a valuable framework forevaluating privacy leakage by machine learning models. Score-based MIAs aredistinguished, in particular, by their ability to exploit the confidence scoresthat the model generates for particular inputs. Existing score-based MIAsimplicitly assume that the adversary has access to the target model'shyperparameters, which can be used to train the shadow models for the attack.In this work, we demonstrate that the knowledge of target hyperparameters isnot a prerequisite for MIA in the transfer learning setting. Based on this, wepropose a novel approach to select the hyperparameters for training the shadowmodels for MIA when the attacker has no prior knowledge about them by matchingthe output distributions of target and shadow models. We demonstrate that usingthe new approach yields hyperparameters that lead to an attack nearindistinguishable in performance from an attack that uses targethyperparameters to train the shadow models. Furthermore, we study the empiricalprivacy risk of unaccounted use of training data for hyperparameteroptimization (HPO) in differentially private (DP) transfer learning. We find nostatistically significant evidence that performing HPO using training datawould increase vulnerability to MIA.</description>
      <author>example@mail.com (Gauri Pradhan, Joonas Jälkö, Marlon Tobaben, Antti Honkela)</author>
      <guid isPermaLink="false">2502.06374v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model</title>
      <link>http://arxiv.org/abs/2502.06438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures, 5 tables, pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为FEMBA的新型自我监督框架，用于高效和准确地分析长时间EEG记录。该模型通过双向状态空间建模，在资源受限环境中表现出色。&lt;h4&gt;背景&lt;/h4&gt;精确且高效的脑电图（EEG）分析对于检测长期监测中的癫痫发作和伪迹至关重要，并广泛应用于医院诊断到可穿戴健康设备等领域。&lt;h4&gt;目的&lt;/h4&gt;提出FEMBA框架，以解决传统深度学习模型在处理长时间EEG数据时的计算资源限制问题。&lt;h4&gt;方法&lt;/h4&gt;使用超过21000小时未标记的EEG数据训练FEMBA，并对三个下游任务进行微调。与基于Transformer的模型相比，FEMBA通过线性扩展序列长度实现更高效的处理。&lt;h4&gt;主要发现&lt;/h4&gt;在TUAB任务上达到81.82%的平衡准确率（AUROC为0.8921），在TUAR任务上的AUROC为0.949；一种只有7.8M参数的小型变体也表现出良好的性能，适用于资源受限设备。&lt;h4&gt;结论&lt;/h4&gt;FEMBA框架不仅能够提供高效的EEG分析，在临床应用和可穿戴技术方面也有巨大潜力。这项工作证明了其在处理大规模长时间记录中的优越性，并且为未来的研究铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;精确而高效的脑电图（EEG）分析对于检测长期监测中的癫痫发作和伪迹至关重要，应用场景包括医院诊断到可穿戴健康设备等。强大的EEG分析有潜力极大地改善患者的护理质量。然而，传统的深度学习模型，特别是基于Transformer的架构，在时间和内存复杂性上具有二次特性，使得它们在资源受限环境下不太适用。为了解决这些问题，我们提出了FEMBA（基础EEG曼巴+双向架构），这是一个新颖的自我监督框架，通过双向状态空间建模建立了新的效率基准。与基于Transformer的模型不同，后者由于时间和内存复杂性而具有二次特性，FEMBA随着序列长度线性扩展，能够更有效地处理延长的EEG记录。在超过21,000小时未标记的EEG数据和三个下游任务上的微调之后，FEMBA与转换器模型相比实现了竞争力的表现，并且计算成本显著降低。具体而言，在TUAB上实现81.82%的平衡准确率（AUROC为0.8921），在TUAR上达到0.949 AUROC；一个只有7.8M参数的小型变体显示了在资源受限设备上的适用性。这些结果为临床EEG分析提供了可扩展、通用的方法，并强调FEMBA是可穿戴应用的有希望的候选者。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and efficient electroencephalography (EEG) analysis is essential fordetecting seizures and artifacts in long-term monitoring, with applicationsspanning hospital diagnostics to wearable health devices. Robust EEG analyticshave the potential to greatly improve patient care. However, traditional deeplearning models, especially Transformer-based architectures, are hindered bytheir quadratic time and memory complexity, making them less suitable forresource-constrained environments. To address these challenges, we presentFEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novelself-supervised framework that establishes new efficiency benchmarks for EEGanalysis through bidirectional state-space modeling. Unlike Transformer-basedmodels, which incur quadratic time and memory complexity, FEMBA scales linearlywith sequence length, enabling more scalable and efficient processing ofextended EEG recordings. Trained on over 21,000 hours of unlabeled EEG andfine-tuned on three downstream tasks, FEMBA achieves competitive performance incomparison with transformer models, with significantly lower computationalcost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUABand 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstratesviability for resource-constrained devices. These results pave the way forscalable, general-purpose EEG analytics in both clinical and highlight FEMBA asa promising candidate for wearable applications.</description>
      <author>example@mail.com (Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li)</author>
      <guid isPermaLink="false">2502.06438v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>A Data-Efficient Pan-Tumor Foundation Model for Oncology CT Interpretation</title>
      <link>http://arxiv.org/abs/2502.06171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  57 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;人工智能辅助影像分析在肿瘤诊断和管理方面取得了显著进展。本文介绍了PASTA，这是一种全肿瘤CT基础模型，在46个代表性肿瘤学任务中的45项上实现了最先进的性能——包括病灶分割、平扫CT中肿瘤检测、肿瘤分期、生存预测、结构化报告生成以及跨模态迁移学习等，并在其中35个任务中显著优于次佳模型。&lt;h4&gt;背景&lt;/h4&gt;人工智能辅助影像分析已经在肿瘤诊断和管理领域取得了重要进展。然而，缺乏高质量的公开标注数据集已成为CT基础模型开发的重要瓶颈。&lt;h4&gt;目的&lt;/h4&gt;介绍PASTA，一个在多项代表性肿瘤学任务上表现出色的全肿瘤CT基础模型，并展示其通过合成数据生成框架PASTA-Gen来解决数据稀缺问题的方法和性能。&lt;h4&gt;方法&lt;/h4&gt;研发了创新性的合成肿瘤生成框架PASTA-Gen，生产出包含来自十种器官的恶性病变及五类良性病变在内的30,000张CT扫描图像及其像素级标注病灶和配对的结构化报告。通过这种高质量、丰富的合成数据集解决了公开可用且高质量的数据稀缺问题。&lt;h4&gt;主要发现&lt;/h4&gt;PASTA在多个任务上超越了现有最佳模型，尤其是在生存预测及跨模态迁移学习方面表现突出；该模型具有出色的数据效率，在仅少量真实世界数据的支持下，其性能得到了显著提升。&lt;h4&gt;结论&lt;/h4&gt;通过公开发布合成数据集和PASTA基础模型，有效解决了数据稀缺问题，并促进了肿瘤学研究与临床应用的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence-assisted imaging analysis has made substantialstrides in tumor diagnosis and management. Here we present PASTA, a pan-tumorCT foundation model that achieves state-of-the-art performance on 45 of 46representative oncology tasks -- including lesion segmentation, tumor detectionin plain CT, tumor staging, survival prediction, structured report generation,and cross-modality transfer learning, significantly outperforming thesecond-best models on 35 tasks. This remarkable advancement is driven by ourdevelopment of PASTA-Gen, an innovative synthetic tumor generation frameworkthat produces a comprehensive dataset of 30,000 CT scans with pixel-levelannotated lesions and paired structured reports, encompassing malignanciesacross ten organs and five benign lesion types. By leveraging this rich,high-quality synthetic data, we overcome a longstanding bottleneck in thedevelopment of CT foundation models -- specifically, the scarcity of publiclyavailable, high-quality annotated datasets due to privacy constraints and thesubstantial labor required for scaling precise data annotation. Encouragingly,PASTA demonstrates exceptional data efficiency with promising practical value,markedly improving performance on various tasks with only a small amount ofreal-world data. The open release of both the synthetic dataset and PASTAfoundation model effectively addresses the challenge of data scarcity, therebyadvancing oncological research and clinical translation.</description>
      <author>example@mail.com (Wenhui Lei, Hanyu Chen, Zitian Zhang, Luyang Luo, Qiong Xiao, Yannian Gu, Peng Gao, Yankai Jiang, Ci Wang, Guangtao Wu, Tongjia Xu, Yingjie Zhang, Xiaofan Zhang, Pranav Rajpurkar, Shaoting Zhang, Zhenning Wang)</author>
      <guid isPermaLink="false">2502.06171v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>AppVLM: A Lightweight Vision Language Model for Online App Control</title>
      <link>http://arxiv.org/abs/2502.06395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了一种名为AppVLM的轻量级Vision-Language Model (VLM)，用于解决智能手机助手（appagents）面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;当前的方法在使用大型专有模型时计算成本高昂，而采用小型微调模型则难以适应分布外任务。这些限制阻碍了智能助手的有效利用。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级且高效的解决方案来克服现有方法的局限性，以便更好地执行人类指令。&lt;h4&gt;方法&lt;/h4&gt;1. 在AndroidControl数据集上离线微调AppVLM；2. 收集来自AndroidWorld环境的数据，并进行额外的训练迭代以优化策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相比于所有评估的基础模型，在离线评测时AppVLM具有最高的动作预测准确率。在线任务完成成功率与GPT-4o相当，但速度提高了10倍。&lt;h4&gt;结论&lt;/h4&gt;AppVLM作为一种实用且高效的解决方案，非常适合现实世界的部署应用。&lt;h4&gt;翻译&lt;/h4&gt;基础模型作为智能手机助手（统称为appagents）的应用是一个重要的研究挑战。这些助手旨在通过解析文本指令并通过设备界面执行操作来完成人类命令。尽管有前景，但现有方法面临着重大限制：使用大型专有模型如GPT-4o的方法计算成本高昂；而采用小型微调模型的方法则往往无法适应分布外任务。本工作引入了一种轻量级的Vision-Language Model (VLM)，名为AppVLM。首先，在AndroidControl数据集上离线对其进行微调，然后通过在AndroidWorld环境中收集数据并进行额外训练迭代来优化其策略。实验结果表明，与所有评估的基础模型相比，AppVLM在离线评估时实现了最高的动作预测准确率，并且在线任务完成成功率与GPT-4o相当，在AndroidWorld环境中的速度提高了10倍。因此，AppVLM为现实世界的部署提供了一个实用且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The utilisation of foundation models as smartphone assistants, termed appagents, is a critical research challenge. These agents aim to execute humaninstructions on smartphones by interpreting textual instructions and performingactions via the device's interface. While promising, current approaches facesignificant limitations. Methods that use large proprietary models, such asGPT-4o, are computationally expensive, while those that use smaller fine-tunedmodels often lack adaptability to out-of-distribution tasks. In this work, weintroduce AppVLM, a lightweight Vision-Language Model (VLM). First, wefine-tune it offline on the AndroidControl dataset. Then, we refine its policyby collecting data from the AndroidWorld environment and performing furthertraining iterations. Our results indicate that AppVLM achieves the highestaction prediction accuracy in offline evaluation on the AndroidControl dataset,compared to all evaluated baselines, and matches GPT-4o in online taskcompletion success rate in the AndroidWorld environment, while being up to tentimes faster. This makes AppVLM a practical and efficient solution forreal-world deployment.</description>
      <author>example@mail.com (Georgios Papoudakis, Thomas Coste, Zhihao Wu, Jianye Hao, Jun Wang, Kun Shao)</author>
      <guid isPermaLink="false">2502.06395v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks at a Fraction</title>
      <link>http://arxiv.org/abs/2502.06136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, accepted at PAKKD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了Quaternion Message Passing Neural Networks (QMPNNs)，这是一种通过利用四元数空间来计算节点表示的框架，旨在减少模型大小的同时保持与原始尺寸GNN相当的准确性。&lt;h4&gt;背景&lt;/h4&gt;图形神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实数值GNN外，四元数GNN在处理图结构数据的任务中也表现出色。&lt;h4&gt;目的&lt;/h4&gt;为了降低能源消耗，该研究旨在减少模型大小，同时保持与原始尺寸的GNN相当的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出Quaternion Message Passing Neural Networks (QMPNNs)框架，并采用四元数表示以减少参数量。同时重新定义了Graph Lottery Tickets的概念，应用于GNN和QMPNN中寻找可训练模型参数更少的初始化方案。&lt;h4&gt;主要发现&lt;/h4&gt;提出的QMPNN框架以及用于GNN和QMPNN中的LTH方法在三个基本图任务（节点分类、链接预测和图形分类）上验证了其有效性，并在实际数据集上的表现良好。&lt;h4&gt;结论&lt;/h4&gt;通过使用四元数表示的QMPNN框架可以显著减少模型参数，同时保持与传统GNN相似的表现。此外，在GNN和QMPNN中应用Graph Lottery Tickets的概念有助于进一步优化可训练模型参数的数量。&lt;h4&gt;翻译&lt;/h4&gt;图形神经网络（GNN）已成为学习图结构数据表示的强大工具。除了实数值的GNN外，四元数GNN在处理图结构数据的任务中也表现出色。为了减少能耗，我们在保持相当精度的同时缩小了模型大小。本文介绍了Quaternion Message Passing Neural Networks (QMPNNs)框架，该框架利用四元数空间来计算节点表示，并以原始参数量的1/4提供了通用方法将四元数表示融入GNN架构中。此外，我们提出了Graph Lottery Tickets的新视角，在GNN和QMPNN背景下重新定义了其适用性，旨在从GNN子网络找到一个初始化方案，该方案在训练后能达到与原始GNN相当的表现，并进一步减少可训练模型参数的数量。为了验证所提出的QMPNN框架及LTH对GNN和QMPNN的有效性，我们在节点分类、链接预测以及图分类这三个基本的基于图的任务上评估了它们在实际数据集上的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for learningrepresentations of graph-structured data. In addition to real-valued GNNs,quaternion GNNs also perform well on tasks on graph-structured data. With theaim of reducing the energy footprint, we reduce the model size whilemaintaining accuracy comparable to that of the original-sized GNNs. This paperintroduces Quaternion Message Passing Neural Networks (QMPNNs), a frameworkthat leverages quaternion space to compute node representations. Our approachoffers a generalizable method for incorporating quaternion representations intoGNN architectures at one-fourth of the original parameter count. Furthermore,we present a novel perspective on Graph Lottery Tickets, redefining theirapplicability within the context of GNNs and QMPNNs. We specifically aim tofind the initialization lottery from the subnetwork of the GNNs that canachieve comparable performance to the original GNN upon training. Therebyreducing the trainable model parameters even further. To validate theeffectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs,we evaluate their performance on real-world datasets across three fundamentalgraph-based tasks: node classification, link prediction, and graphclassification.</description>
      <author>example@mail.com (Rucha Bhalchandra Joshi, Sagar Prakash Barad, Nidhi Tiwari, Subhankar Mishra)</author>
      <guid isPermaLink="false">2502.06136v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Transformers versus the EM Algorithm in Multi-class Clustering</title>
      <link>http://arxiv.org/abs/2502.06007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了Transformer模型在无监督学习任务中多类高斯混合聚类问题上的理论保证，建立了Softmax注意力层与EM算法之间的联系，并证明了其逼近能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）通过使用变换器模型作为骨干，在复杂的机器学习任务中展示了强大的推理能力。然而，对于这些模型在无监督学习问题中的理解还很有限。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer在执行高斯混合聚类的多分类聚类时的学习保证，并建立Softmax注意力层与EM算法之间的理论联系。&lt;h4&gt;方法&lt;/h4&gt;通过证明多变量映射由softmax函数实现的通用逼近能力，为期望和最大化步骤提供了近似界限。同时表明，在有足够的预训练样本和初始化的情况下，Transformer可以达到问题考虑的最小最大最优率。&lt;h4&gt;主要发现&lt;/h4&gt;论文发展了一种理论框架，将Softmax注意力层与EM算法的工作流程联系起来，并展示了Transformers在多类高斯混合聚类中的强大学习能力。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了该理论，表明Transformer即使在超出理论假设的情况下也具有强大的推理能力。这为LLMs的推断能力提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）展示了在复杂机器学习任务中进行推理的能力，这些任务以变换器模型作为其核心架构。为了进一步理解这类模型在无监督学习问题上的表现，我们研究了Transformer执行多类高斯混合聚类时的学习保证，并建立了一个将Softmax注意力层与EM算法的工作流程联系起来的理论框架。通过证明softmax函数在实现多变量映射中的通用逼近能力，我们的理论为期望和最大化步骤提供了近似界限。此外，在给定足够的预训练样本和初始化的情况下，我们还展示了Transformer可以达到考虑问题的最小最大最优率。广泛的模拟实验从经验上验证了我们的理论，并揭示了Transformer即使超出假设条件也具备强大的学习能力，这强调了LLMs的强大推理潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs demonstrate significant inference capacities in complicated machinelearning tasks, using the Transformer model as its backbone. Motivated by thelimited understanding of such models on the unsupervised learning problems, westudy the learning guarantees of Transformers in performing multi-classclustering of the Gaussian Mixture Models. We develop a theory drawing strongconnections between the Softmax Attention layers and the workflow of the EMalgorithm on clustering the mixture of Gaussians. Our theory providesapproximation bounds for the Expectation and Maximization steps by proving theuniversal approximation abilities of multivariate mappings by Softmaxfunctions. In addition to the approximation guarantees, we also show that witha sufficient number of pre-training samples and an initialization, Transformerscan achieve the minimax optimal rate for the problem considered. Our extensivesimulations empirically verified our theory by revealing the strong learningcapacities of Transformers even beyond the assumptions in the theory, sheddinglight on the powerful inference capacities of LLMs.</description>
      <author>example@mail.com (Yihan He, Hong-Yu Chen, Yuan Cao, Jianqing Fan, Han Liu)</author>
      <guid isPermaLink="false">2502.06007v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Learning Musical Representations for Music Performance Question Answering</title>
      <link>http://arxiv.org/abs/2502.06710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;音乐表演为音频-视觉建模提供了典型的应用场景，与常见稀疏声音的场景不同，音乐表演中持续存在密集的声音信号。&lt;h4&gt;背景问题&lt;/h4&gt;现有的多模式学习方法在通用场景中的表现令人印象深刻，但在处理音乐表演的基本问题时却显得不足：它们未能深入探索多种感官信号之间的交互，并未考虑到乐器和音乐的独特特性。&lt;h4&gt;研究目的&lt;/h4&gt;为了解决上述研究差距，该论文旨在提出一种能够更好地理解和分析音乐表演的方法。&lt;h4&gt;方法介绍&lt;/h4&gt;{'(i) 多模态互动设计': '鉴于音乐数据中固有的复杂多模式互连性，本研究主要采用了一种结合了音频和视频信号在音乐上下文中的交互作用的设计方案;', '(ii) 学习音乐特性': '为了使模型能够学习音乐的特性，作者对当前音乐数据集进行了节奏和音乐来源的注释并开放;', '(iii) 时间感知建模': '为实现时间感知音频-视觉建模，该方法将模型预测与时间维度进行对齐'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在Music AVQA 数据集中实现了最先进的效果。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法在音乐表演场景中表现出色，并通过公开源代码促进相关领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;音乐表演代表了音频-视觉建模的典型应用场景。与普通稀疏声音场景不同，音乐表演中持续存在密集的声音信号。虽然现有的多模式学习方法在通用情景下展示了出色的能力，但在处理音乐表演的基本问题时却显得不足：它们未能深入探索多种感官信号之间的交互，并未考虑到乐器和音乐的独特特性。因此，现有方法倾向于不准确地回答关于音乐表演的问题。为了弥补上述研究差距，(i) 由于音乐数据中固有的复杂多模式互连性，我们的主干设计旨在结合音频和视频信号在音乐上下文中的互动；(ii) 为了让模型学习到音乐的特点，我们对现有的音乐数据集进行节奏和音乐来源的注释并开放给公众；(iii) 对于时间感知的音频-视觉建模，我们将模型预测与时间维度进行对齐。实验显示，在Music AVQA 数据集中我们的方法取得了最先进的效果。代码可在https://github.com/xid32/Amuse获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Music performances are representative scenarios for audio-visual modeling.Unlike common scenarios with sparse audio, music performances continuouslyinvolve dense audio signals throughout. While existing multimodal learningmethods on the audio-video QA demonstrate impressive capabilities in generalscenarios, they are incapable of dealing with fundamental problems within themusic performances: they underexplore the interaction between the multimodalsignals in performance and fail to consider the distinctive characteristics ofinstruments and music. Therefore, existing methods tend to answer questionsregarding musical performances inaccurately. To bridge the above research gaps,(i) given the intricate multimodal interconnectivity inherent to music data,our primary backbone is designed to incorporate multimodal interactions withinthe context of music; (ii) to enable the model to learn music characteristics,we annotate and release rhythmic and music sources in the current musicdatasets; (iii) for time-aware audio-visual modeling, we align the model'smusic predictions with the temporal dimension. Our experiments showstate-of-the-art effects on the Music AVQA datasets. Our code is available athttps://github.com/xid32/Amuse.</description>
      <author>example@mail.com (Xingjian Diao, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui)</author>
      <guid isPermaLink="false">2502.06710v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.06301v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于新颖性的NS-ES和NSR-ES算法在强化学习问题上训练复杂Transformer架构的有效性，并探讨了通过预训练模型加速这些大型模型的训练的可能性。&lt;h4&gt;背景&lt;/h4&gt;进化策略（如OpenAI-ES）已被用于训练决策变压器等复杂架构，但需要评估其性能是否适用于基于新颖性的变体和更大规模的问题。&lt;h4&gt;目的&lt;/h4&gt;测试NS-ES和NSR-ES算法在大规模Transformer架构上的有效性，并研究预训练模型能否加速这些算法的训练过程。&lt;h4&gt;方法&lt;/h4&gt;实验使用了新颖性为基础的OpenAI-ES变种（NS-ES和NSR-ES），并评估其对复杂强化学习问题中使用的变压器型架构的有效性。同时测试是否可以通过一个预训练模型来加速基于新颖性的大规模模型的训练。&lt;h4&gt;主要发现&lt;/h4&gt;虽然NS-ES显示出了一定的进步，但仍需要更多的迭代才能获得有趣的结果；而NSR-ES在更大规模模型上的表现与先前工作的Feed-forward模型和决策变压器之间的性能相似，并且证明了其能够直接应用于更大的模型上。此外，在大型模型中引入预训练种子加速新颖性搜索的潜力也被探讨。&lt;h4&gt;结论&lt;/h4&gt;基于新颖性的进化策略变种（NSR-ES）显示出在大规模Transformer架构上的强大能力，通过进一步的研究可以为这一领域提供新的见解和可能的应用。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们实验了OpenAI-ES的新颖性变体——NS-ES和NSR-ES算法，并评估它们训练复杂、基于变压器的强化学习问题（如决策变压器）架构的有效性。我们还测试是否可以通过预训练模型来加速这些大型模型的新颖性训练。通过这种方法，我们在以前的工作基础上进一步研究了进化策略（特别是OpenAI-ES）对Decision Transformer架构的培训能力。结果是混合的。NS-ES显示出了进步，但显然还需要更多的迭代才能产生有趣的结果。而另一方面，NSR-ES证明可以直接用在更大的模型上，因为其性能在前馈网络模型和决策变压器之间似乎与我们在先前工作中使用OpenAI-ES时的表现相似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we experiment with novelty-based variants of OpenAI-ES, theNS-ES and NSR-ES algorithms, and evaluate their effectiveness in trainingcomplex, transformer-based architectures designed for the problem ofreinforcement learning such as Decision Transformers. We also test if we canaccelerate the novelty-based training of these larger models by seeding thetraining by a pretrained models. By this, we build on our previous work, wherewe tested the ability of evolution strategies - specifically the aforementionedOpenAI-ES - to train the Decision Transformer architecture. The results weremixed. NS-ES showed progress, but it would clearly need many more iterationsfor it to yield interesting results. NSR-ES, on the other hand, proved quitecapable of being straightforwardly used on larger models, since its performanceappears as similar between the feed-forward model and Decision Transformer, asit was for the OpenAI-ES in our previous work.</description>
      <author>example@mail.com (Matyáš Lorenc)</author>
      <guid isPermaLink="false">2502.06301v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Task Representation Memory Bank vs. Catastrophic Forgetting in Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.06194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于无监督连续异常检测（UCAD）的多模态任务表示记忆库方法(MTRMB)，该方法通过两个关键技术创新来解决现有的代表性学习和灾难性遗忘的问题。&lt;h4&gt;背景&lt;/h4&gt;在多任务表征学习中，现有无监督模型缺乏先验信息，难以有效区分冗余和互补的多模态特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的解决方案以改进无监督连续异常检测中的表示学习和防止灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;提出了两个关键技术：1. 使用简洁的关键提示来指导BERT和ViT之间的跨模式特征交互的Key-Prompt-Multimodal Knowledge (KPMK)机制；2. 基于结构化的对比学习（RSCL），利用Grounding DINO和SAM生成精确的分割掩码，将同一结构区域的特性拉近，而不同结构区域的特性推开。&lt;h4&gt;主要发现&lt;/h4&gt;在MVtec AD和VisA数据集上的实验表明，MTRMB方法具有优越性，在最低遗忘率下达到了0.921的平均检测准确度，显著优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;计划在未来将此工作开源到GitHub上。&lt;h4&gt;翻译&lt;/h4&gt;无监督连续异常检测（UCAD）在多任务表征学习中面临重大挑战。现有方法由于表示不完整和灾难性遗忘而表现不佳。与监督模型不同的是，无监督场景缺乏先验信息，难以有效区分冗余和互补的多模态特征。为了解决这一问题，我们通过两个关键技术创新提出了Multimodal Task Representation Memory Bank (MTRMB)方法：一种Key-Prompt-Multimodal Knowledge (KPMK)机制，利用简洁的关键提示来指导BERT与ViT之间的跨模式特性交互；以及基于结构化的对比学习（RSCL），它使用Grounding DINO和SAM生成精确的分割掩码，将同一结构区域中的特性拉近，同时推开不同的结构区域。在MVtec AD和VisA数据集上的实验表明MTRMB方法具有优越性，在最低遗忘率下达到了0.921的平均检测准确度，显著优于最先进的方法。我们计划在未来将此工作开源到GitHub上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Continuous Anomaly Detection (UCAD) faces significant challengesin multi-task representation learning, with existing methods suffering fromincomplete representation and catastrophic forgetting. Unlike supervisedmodels, unsupervised scenarios lack prior information, making it difficult toeffectively distinguish redundant and complementary multimodal features. Toaddress this, we propose the Multimodal Task Representation Memory Bank (MTRMB)method through two key technical innovations: A Key-Prompt-Multimodal Knowledge(KPMK) mechanism that uses concise key prompts to guide cross-modal featureinteraction between BERT and ViT. Refined Structure-based Contrastive Learning(RSCL) leveraging Grounding DINO and SAM to generate precise segmentationmasks, pulling features of the same structural region closer while pushingdifferent structural regions apart. Experiments on MVtec AD and VisA datasetsdemonstrate MTRMB's superiority, achieving an average detection accuracy of0.921 at the lowest forgetting rate, significantly outperformingstate-of-the-art methods. We plan to open source on GitHub.</description>
      <author>example@mail.com (You Zhou, Jiangshan Zhao, Deyu Zeng, Zuo Zuo, Weixiang Liu, Zongze Wu)</author>
      <guid isPermaLink="false">2502.06194v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?</title>
      <link>http://arxiv.org/abs/2502.06289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了通用视觉基础模型DINOv2和特定于眼科的基础模型RETFound在眼科疾病检测和系统性疾病预测任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型（FMs）的出现，医学领域正在发生变革。在眼科中，专门针对视网膜的RETFound表现出了较高的适应性，而通用视觉基础模型DINOv2则可能适用于非医疗领域但其临床应用尚未充分研究。&lt;h4&gt;目的&lt;/h4&gt;为了评估不同大小的DINOv2模型与RETFound在眼部疾病检测和系统性疾病预测任务中的性能差异。&lt;h4&gt;方法&lt;/h4&gt;通过在八组标准化开源眼科数据集以及Moorfields AlzEye和UK Biobank数据集上进行微调，对RETFound和三个DINOv2模型（大、中、小）进行了头对头的评估。&lt;h4&gt;主要发现&lt;/h4&gt;{'糖尿病性视网膜病变检测': '在三种数据集中，DINOv2-large模型的表现优于RETFound（AUROC=0.850-0.952 vs 0.823-0.944）', '多类眼疾分类': 'DINOv2-large模型也表现得比RETFound更好（AUROC=0.892 vs 0.846）', '青光眼检测': '在青光眼的检测中，DINOv2-base模型优于RETFound（AUROC=0.958 vs 0.940）', '系统性疾病预测': '在心力衰竭、心肌梗死和缺血性卒中的预测任务上，RETFound表现出色，优于所有大小的DINOv2模型'}&lt;h4&gt;结论&lt;/h4&gt;该研究展示了通用视觉基础模型与领域特定基础模型各自的优势场景，并强调了根据具体任务需求选择适当的基础模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;随着基础模型（FMs）在医学领域的引入，它们正在改变眼科等专业领域。虽然专门针对视网膜的RETFound模型在临床应用中表现出色，但通用视觉基础模型DINOv2在非医疗场景中的潜力尚未被充分研究。通过在标准化眼科数据集和Moorfields AlzEye及UK Biobank上的测试对比分析，我们发现不同大小的DINOv2模型在某些特定的眼科疾病检测任务中优于RETFound；同时，在系统性疾病预测方面，RETFound的表现则超过所有版本的DINOv2。这些发现表明了通用与领域专用基础模型各自的优势场景，并强调应根据具体任务需求选择最合适的模型以优化临床效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of foundation models (FMs) is transforming medical domain. Inophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4million natural images and 1.6 million retinal images, has demonstrated highadaptability across clinical applications. Conversely, DINOv2, ageneral-purpose vision FM pre-trained on 142 million natural images, has shownpromise in non-medical domains. However, its applicability to clinical tasksremains underexplored. To address this, we conducted head-to-head evaluationsby fine-tuning RETFound and three DINOv2 models (large, base, small) for oculardisease detection and systemic disease prediction tasks, across eightstandardized open-source ocular datasets, as well as the Moorfields AlzEye andthe UK Biobank datasets. DINOv2-large model outperformed RETFound in detectingdiabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,all P&lt;=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P&lt;0.001). Inglaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,P&lt;0.001). Conversely, RETFound achieved superior performance over all DINOv2models in predicting heart failure, myocardial infarction, and ischaemic stroke(AUROC=0.732-0.796 vs 0.663-0.771, all P&lt;0.001). These trends persisted evenwith 10% of the fine-tuning data. These findings showcase the distinctscenarios where general-purpose and domain-specific FMs excel, highlighting theimportance of aligning FM selection with task-specific requirements to optimiseclinical performance.</description>
      <author>example@mail.com (Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K. Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, AnRan Ran, Rui Santos, Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Yim-Lui Cheung, Pearse A. Keane, Yih Chung Tham)</author>
      <guid isPermaLink="false">2502.06289v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:16 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised deep learning for semantic segmentation of multispectral LiDAR forest point clouds</title>
      <link>http://arxiv.org/abs/2502.06227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为GrowSP-ForMS的全无人工监督深度学习模型，专门用于高密度多光谱ALS点云数据中的叶木分离。&lt;h4&gt;背景&lt;/h4&gt;激光扫描系统捕捉到的森林环境点云可以应用于树木属性估计、叶片角度分布和地上生物量等多个领域。有效的利用这些数据需要对木材和树叶点进行语义分割（即叶木分离）。传统的方法依赖于几何和辐射度测量的无监督算法，但其在高密度ALS数据上表现不佳。虽然最近的一些机器学习方法在这方面取得了显著成果，但他们通常需要大量的手工标注训练数据。&lt;h4&gt;目的&lt;/h4&gt;提出一个不需要人工标签、基于深度学习的新方法来提高叶木分离的准确性。&lt;h4&gt;方法&lt;/h4&gt;GrowSP-ForMS模型是基于GrowSP架构并专为多光谱ALS点云设计的方法。该方法利用了多光谱信息以改进叶木分离精度。&lt;h4&gt;主要发现&lt;/h4&gt;在测试集上，该模型达到了84.3%的平均准确率和69.6%的平均交并比（mIoU），超过了参考无监督方法，并且使用多光谱数据可以将mIoU从单光谱情况下的5.6个百分点提高。&lt;h4&gt;结论&lt;/h4&gt;虽然与最新的监督深度学习方法相比，GrowSP-ForMS的表现稍逊一筹，但它仍然是一种无需人工标签的非常有效的叶木分离工具。&lt;h4&gt;翻译&lt;/h4&gt;点云捕获自森林环境的激光扫描系统数据在林业和植物生态学应用中广泛使用。有效利用这些数据需要将木材和树叶点进行语义分割（即叶木分离）。传统的方法基于几何和辐射度测量，但在高密度ALS数据上表现不佳。尽管最近一些机器学习方法在这类问题上取得了显著成果，但它们通常要求手动标注的训练集。多光谱信息被证明可以提高叶木分离精度，但是其效果至今缺乏定量评估。本研究提出了一种基于GrowSP架构设计的完全无人工监督深度学习模型（名为GrowSP-ForMS），专门针对高密度多光谱ALS点云数据中的叶木分离问题。在我们的测试集中，该模型实现了84.3%的平均准确率和69.6%的平均交并比（mIoU），显著优于无监督参考方法。相较于有监督深度学习方法，该模型的表现与略早一些的PointNet架构相似，并被更近的方法超越。最后进行两组消融实验表明，相比原始GrowSP模型，我们提出的改进将GrowSP-ForMS在测试集上的mIoU提高了29.4个百分点；同时利用多光谱数据相较于单光谱情况可以提高5.6个百分点的mIoU。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point clouds captured with laser scanning systems from forest environmentscan be utilized in a wide variety of applications within forestry and plantecology, such as the estimation of tree stem attributes, leaf angledistribution, and above-ground biomass. However, effectively utilizing the datain such tasks requires the semantic segmentation of the data into wood andfoliage points, also known as leaf-wood separation. The traditional approach toleaf-wood separation has been geometry- and radiometry-based unsupervisedalgorithms, which tend to perform poorly on data captured with airborne laserscanning (ALS) systems, even with a high point density. While recent machineand deep learning approaches achieve great results even on sparse point clouds,they require manually labeled training data, which is often extremely laboriousto produce. Multispectral (MS) information has been demonstrated to havepotential for improving the accuracy of leaf-wood separation, but quantitativeassessment of its effects has been lacking. This study proposes a fullyunsupervised deep learning method, GrowSP-ForMS, which is specifically designedfor leaf-wood separation of high-density MS ALS point clouds and based on theGrowSP architecture. GrowSP-ForMS achieved a mean accuracy of 84.3% and a meanintersection over union (mIoU) of 69.6% on our MS test set, outperforming theunsupervised reference methods by a significant margin. When compared tosupervised deep learning methods, our model performed similarly to the slightlyolder PointNet architecture but was outclassed by more recent approaches.Finally, two ablation studies were conducted, which demonstrated that ourproposed changes increased the test set mIoU of GrowSP-ForMS by 29.4 percentagepoints (pp) in comparison to the original GrowSP model and that utilizing MSdata improved the mIoU by 5.6 pp from the monospectral case.</description>
      <author>example@mail.com (Lassi Ruoppa, Oona Oinonen, Josef Taher, Matti Lehtomäki, Narges Takhtkeshha, Antero Kukko, Harri Kaartinen, Juha Hyyppä)</author>
      <guid isPermaLink="false">2502.06227v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>ARISE: Iterative Rule Induction and Synthetic Data Generation for Text Classification</title>
      <link>http://arxiv.org/abs/2502.05923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Findings of NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在文本分类任务中，合成数据生成和自动规则归纳是非常重要的技术。&lt;h4&gt;目的&lt;/h4&gt;提出ARISE框架，旨在通过迭代地诱导规则并生成合成数据来提高文本分类的性能。&lt;h4&gt;方法&lt;/h4&gt;结合了基于引导的数据生成与自动规则诱导技术，以迭代方式过滤产生的规则和数据。通过语法n-grams的归纳概括诱导规则。&lt;h4&gt;主要发现&lt;/h4&gt;{'单独使用规则': '在上下文学习（ICL）和微调（FT）设置中都能带来性能提升。', '单独使用增强的数据': '模型性能提高，优于依赖复杂方法如对比学习的配置。', '实验结果': '在三个全量样本、八个少量样本及七个跨语言变体设置上进行广泛的实验，证明生成的规则和数据能跨越这些多样化的领域和语言带来性能改进。'}&lt;h4&gt;结论&lt;/h4&gt;ARISE框架通过迭代地过滤合成数据和规则来提高文本分类任务中的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为ARISE的框架，该框架用于迭代诱导规则并生成合成数据以进行文本分类。我们结合了基于引导的数据生成与自动规则归纳技术，以迭代方式过滤产生的规则和数据。通过语法n-grams的归纳概括诱导规则，并且这些规则单独使用就能在上下文学习（ICL）和微调（FT）设置中带来性能提升。同样地，仅使用ARISE生成的增强数据也能提高模型性能，在对比其他复杂方法如对比学习的配置时表现出色。我们还在覆盖三个全量样本、八个少量样本及七个跨语言变体设置的各种数据集上进行了广泛的实验，结果表明我们生成的规则和数据在这些多样化的领域和语言中都有所改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose ARISE, a framework that iteratively induces rules and generatessynthetic data for text classification. We combine synthetic data generationand automatic rule induction, via bootstrapping, to iteratively filter thegenerated rules and data. We induce rules via inductive generalisation ofsyntactic n-grams, enabling us to capture a complementary source ofsupervision. These rules alone lead to performance gains in both, in-contextlearning (ICL) and fine-tuning (FT) settings. Similarly, use of augmented datafrom ARISE alone improves the performance for a model, outperformingconfigurations that rely on complex methods like contrastive learning. Further,our extensive experiments on various datasets covering three full-shot, eightfew-shot and seven multilingual variant settings demonstrate that the rules anddata we generate lead to performance improvements across these diverse domainsand languages.</description>
      <author>example@mail.com (Yashwanth M., Vaibhav Singh, Ayush Maheshwari, Amrith Krishna, Ganesh Ramakrishnan)</author>
      <guid isPermaLink="false">2502.05923v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time LiDAR Point Cloud Compression and Transmission for Resource-constrained Robots</title>
      <link>http://arxiv.org/abs/2502.06123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种针对资源受限的机器人应用的新颖点云压缩和传输框架，名为RCPCC。&lt;h4&gt;背景&lt;/h4&gt;激光雷达（LiDAR）在自主机器人中广泛应用，因为它能够提供准确的环境结构信息。然而，大量的点云数据带来了存储和传输方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;为资源受限的机器人应用设计一种新的点云压缩和传输框架。&lt;h4&gt;方法&lt;/h4&gt;迭代拟合具有类似范围值的点云表面并消除冗余；使用形状自适应离散余弦变换（SA-DCT）转换未拟合的点，通过量化变换系数减少数据量；基于QoE（用户体验质量）设计了自适应比特率控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架在保持下游应用高精度的同时实现了40到80倍的数据压缩。当压缩比超过70倍时，方法的准确性明显优于其他基准方法。此外，在通信带宽降低的情况下，自适应比特率控制策略显示出显著的质量提升。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效地解决点云数据存储和传输的问题，并且在各种资源限制条件下表现出色。&lt;h4&gt;翻译&lt;/h4&gt;激光雷达由于其提供准确环境结构信息的能力而在自主机器人中广泛应用。然而，大量的点云数据给存储和传输带来了挑战。本文提出了一种新的适用于资源受限的机器人应用的点云压缩和传输框架RCPCC。通过迭代拟合具有相似范围值的点云表面并消除冗余，并使用形状自适应离散余弦变换（SA-DCT）处理未拟合的点，减少数据量。设计了一个基于用户体验质量（QoE）的自适应比特率控制策略来优化传输点云的质量。实验结果表明，在保持下游应用高精度的同时实现了40到80倍的数据压缩。当压缩比超过70倍时，该方法明显优于其他基准方法。此外，在通信带宽减少的情况下，自适应比特率控制策略能够显著提升用户体验质量。代码可以在 https://github.com/HITSZ-NRSL/RCPCC.git 上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDARs are widely used in autonomous robots due to their ability to provideaccurate environment structural information. However, the large size of pointclouds poses challenges in terms of data storage and transmission. In thispaper, we propose a novel point cloud compression and transmission frameworkfor resource-constrained robotic applications, called RCPCC. We iteratively fitthe surface of point clouds with a similar range value and eliminate redundancythrough their spatial relationships. Then, we use Shape-adaptive DCT (SA-DCT)to transform the unfit points and reduce the data volume by quantizing thetransformed coefficients. We design an adaptive bitrate control strategy basedon QoE as the optimization goal to control the quality of the transmitted pointcloud. Experiments show that our framework achieves compression rates of40$\times$ to 80$\times$ while maintaining high accuracy for downstreamapplications. our method significantly outperforms other baselines in terms ofaccuracy when the compression rate exceeds 70$\times$. Furthermore, insituations of reduced communication bandwidth, our adaptive bitrate controlstrategy demonstrates significant QoE improvements. The code will be availableat https://github.com/HITSZ-NRSL/RCPCC.git.</description>
      <author>example@mail.com (Yuhao Cao, Yu Wang, Haoyao Chen)</author>
      <guid isPermaLink="false">2502.06123v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions</title>
      <link>http://arxiv.org/abs/2502.06536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  47 pages, 16 figures, 9 Tables, Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在现实世界中应用广泛，但黑盒AI系统缺乏解释性和鲁棒性等问题仍然存在。概念模型（CBM）通过从高维数据如图像中学习可解释的概念来解决这些问题，然而这些模型中存在的概念泄漏问题会影响预测准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管概念模型能够帮助理解机器学习系统中的决策过程，但是它们经常包含不相关的信息或"错误"概念的误导信息。现有的缓解策略需要强烈假设或大量的手动干预。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于因果表示学习（CRL）的新框架，该框架在不需要任何干预的情况下提供关于所学概念正确性的理论保证，并且降低了所需标签的数量。&lt;h4&gt;方法&lt;/h4&gt;利用因果表示学习从低级数据中提取高层因果变量，并试图将这些变量与可解释的概念对齐。针对这种映射提出了线性估计器和非参数估计器，分别在有限样本下给出高概率结果，在无限样本的情况下则得到一致性结果。&lt;h4&gt;主要发现&lt;/h4&gt;新框架实现了概念模型的准确性和鲁棒性的提升，通过合成数据集和图像基准测试验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架提供了一种无需人工干预即可学习正确且可解释的概念的方法，这对于提高机器学习系统的透明度至关重要。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含在问题描述中&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning is a vital part of many real-world systems, but severalconcerns remain about the lack of interpretability, explainability androbustness of black-box AI systems. Concept-based models (CBM) address some ofthese challenges by learning interpretable concepts from high-dimensional data,e.g. images, which are used to predict labels. An important issue in CBMs isconcept leakage, i.e., spurious information in the learned concepts, whicheffectively leads to learning "wrong" concepts. Current mitigating strategiesare heuristic, have strong assumptions, e.g., they assume that the concepts arestatistically independent of each other, or require substantial humaninteraction in terms of both interventions and labels provided by annotators.In this paper, we describe a framework that provides theoretical guarantees onthe correctness of the learned concepts and on the number of required labels,without requiring any interventions. Our framework leverages causalrepresentation learning (CRL) to learn high-level causal variables fromlow-level data, and learns to align these variables with interpretableconcepts. We propose a linear and a non-parametric estimator for this mapping,providing a finite-sample high probability result in the linear case and anasymptotic consistency result for the non-parametric estimator. We implementour framework with state-of-the-art CRL methods, and show its efficacy inlearning the correct concepts in synthetic and image benchmarks.</description>
      <author>example@mail.com (Hidde Fokkema, Tim van Erven, Sara Magliacane)</author>
      <guid isPermaLink="false">2502.06536v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Norm Augmented Graph AutoEncoders for Link Prediction</title>
      <link>http://arxiv.org/abs/2502.05868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图自编码器（GAE）在链路预测任务中性能不佳的问题，并提出了一种通过增加低度节点嵌入向量的范数来提高其表现的方法。&lt;h4&gt;背景&lt;/h4&gt;链路预测是图结构数据中的重要问题，而图神经网络（尤其是图自编码器）已被广泛用于解决这一问题。然而，实验证明GAE在处理长尾节点分布时性能较差，即低度节点的表现通常不如高度节点。&lt;h4&gt;目的&lt;/h4&gt;研究造成这种与节点度数相关偏差的原因，并提出一种减轻该偏差的方法。&lt;h4&gt;方法&lt;/h4&gt;本文发现GAE学习到的节点嵌入向量范数在其不同度节点之间存在差异，这影响了链路预测最终结果。通过为低度节点引入额外的自环来增加其嵌入向量的范数，从而提高其性能。&lt;h4&gt;主要发现&lt;/h4&gt;嵌入向量具有较大范数的节点更倾向于引导解码器对正链接赋予更高的评分，并对负链接赋予更低的评分，这导致了更好的链路预测表现。通过为低度节点增加嵌入向量的范数可以提升其在链路预测中的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于增范策略改进的GAE方法能在保持较低计算成本的同时显著提高链路预测任务中低度节点的表现，实验结果验证了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：链路预测是图结构数据中一个关键问题。图神经网络（包括图自编码器）已成为链路预测领域的重要工具，但我们的实证研究发现图自编码器在处理长尾节点度分布时性能显著下降，即低度节点的链路预测表现通常不如高度节点的表现好。这种与节点度数相关的偏差是什么原因造成的？如何减轻这一问题？本研究表明GAE学习到的不同节点间嵌入向量范数的变化是影响最终链路预测结果的关键因素之一。具体来说，具有较大范数的嵌入更倾向于引导解码器对正链接赋予更高的评分，并且降低负链接的分数，从而有助于提高性能。这一发现促使我们通过增加低度节点的嵌入向量范数来改善其链路预测表现，这可以通过在训练目标中为这些节点引入额外自环轻松实现并有效执行。该增范策略可无缝集成到现有GAE方法中，并且计算成本较小。在各种数据集和GAE方法上的广泛实验结果表明了基于增范策略的图自编码器优越的表现能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link Prediction (LP) is a crucial problem in graph-structured data. GraphNeural Networks (GNNs) have gained prominence in LP, with Graph AutoEncoders(GAEs) being a notable representation. However, our empirical findings revealthat GAEs' LP performance suffers heavily from the long-tailed node degreedistribution, i.e., low-degree nodes tend to exhibit inferior LP performancecompared to high-degree nodes. \emph{What causes this degree-related bias, andhow can it be mitigated?} In this study, we demonstrate that the norm of nodeembeddings learned by GAEs exhibits variation among nodes with differentdegrees, underscoring its central significance in influencing the finalperformance of LP. Specifically, embeddings with larger norms tend to guide thedecoder towards predicting higher scores for positive links and lower scoresfor negative links, thereby contributing to superior performance. Thisobservation motivates us to improve GAEs' LP performance on low-degree nodes byincreasing their embedding norms, which can be implemented simply yeteffectively by introducing additional self-loops into the training objectivefor low-degree nodes. This norm augmentation strategy can be seamlesslyintegrated into existing GAE methods with light computational cost. Extensiveexperiments on various datasets and GAE methods show the superior performanceof norm-augmented GAEs.</description>
      <author>example@mail.com (Yunhui Liu, Huaisong Zhang, Xinyi Gao, Liuye Guo, Zhen Tao, Tieke He)</author>
      <guid isPermaLink="false">2502.05868v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks</title>
      <link>http://arxiv.org/abs/2502.06153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的Kolmogorov-Arnold网络（KAN）微调方法——低张量秩自适应（LoTRA），该方法通过借鉴Tucker分解技术，使KAN在网络转移学习中的性能得到提升，并且在解决偏微分方程和函数表示等方面表现出色。&lt;h4&gt;背景&lt;/h4&gt;虽然Kolmogorov-Arnold网络展示了其作为多层感知机的替代方案的巨大潜力，但关于KANs的迁移学习尚未充分探索。作者通过Tucker张量分解理论以及观察到的KAN参数更新具有低张量秩结构的特点来开发了一种新颖的方法。&lt;h4&gt;目的&lt;/h4&gt;旨在研究LoTRA的表达能力，并提供一种高效的训练策略选择学习率的方法，同时证明这种方法在解决偏微分方程和功能表示任务中的有效性。&lt;h4&gt;方法&lt;/h4&gt;基于Tucker分解近似理论，提出低张量秩自适应（LoTRA）算法；分析如何根据各个组件的特点设置合适的学习率以实现有效的训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验证明了所提出的LoTRA可以有效地利用KAN的迁移学习能力解决各种偏微分方程问题。此外，作者还提出了Slim KANs，该模型在保持高性能的同时减少了参数数量。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，采用低张量秩自适应策略（LoTRA）能够有效提高基于Kolmogorov-Arnold网络的迁移学习性能，并且对于偏微分方程求解具有很大的潜力。此外，Slim KANs在函数表示和图像分类任务中展示了其表达力以及通过张量分解减少参数的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到Kolmogorov-Arnold网络（KAN）展示出作为多层感知机的替代方案的巨大潜力，特别是在科学相关领域。然而，关于KANs的迁移学习仍是一个相对未探索的领域。本文受张量Tucker分解以及KAN参数更新中低张量秩结构证据启发，开发了一种用于微调KAN的新方法——低张量秩自适应（LoTRA）。研究基于Tucker分解近似理论探讨了LoTRA的表现力，并提供了一个理论分析来为每个LoTRA组件选择合适的学习率以实现高效的训练。此外还发现使用相同学习率在所有组件之间会导致效率低下，强调了采用自适应学习率策略的重要性。除了理论见解外，本文还探索了通过微调KAN高效解决各种偏微分方程（PDE）的应用。另外，提出了包含KAN参数张量固有的低张量秩性质的Slim KANs来减少模型大小同时保持优异性能。实验结果验证了所提议的学习率选择策略的有效性，并展示了LoTRA在基于KAN的迁移学习中解决偏微分方程的能力。关于Slim KANs在功能表示和图像分类任务中的进一步评估突显了LoTRA的表现力以及通过低张量秩分解减少参数的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov--Arnold networks (KANs) have demonstrated their potential as analternative to multi-layer perceptions (MLPs) in various domains, especiallyfor science-related tasks. However, transfer learning of KANs remains arelatively unexplored area. In this paper, inspired by Tucker decomposition oftensors and evidence on the low tensor-rank structure in KAN parameter updates,we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We studythe expressiveness of LoTRA based on Tucker decomposition approximations.Furthermore, we provide a theoretical analysis to select the learning rates foreach LoTRA component to enable efficient training. Our analysis also shows thatusing identical learning rates across all components leads to inefficienttraining, highlighting the need for an adaptive learning rate strategy. Beyondtheoretical insights, we explore the application of LoTRA for efficientlysolving various partial differential equations (PDEs) by fine-tuning KANs.Additionally, we propose Slim KANs that incorporate the inherentlow-tensor-rank properties of KAN parameter tensors to reduce model size whilemaintaining superior performance. Experimental results validate the efficacy ofthe proposed learning rate selection strategy and demonstrate the effectivenessof LoTRA for transfer learning of KANs in solving PDEs. Further evaluations onSlim KANs for function representation and image classification tasks highlightthe expressiveness of LoTRA and the potential for parameter reduction throughlow tensor-rank decomposition.</description>
      <author>example@mail.com (Yihang Gao, Michael K. Ng, Vincent Y. F. Tan)</author>
      <guid isPermaLink="false">2502.06153v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Accurate, Efficient, and Interpretable MLPs on Multiplex Graphs via Node-wise Multi-View Ensemble Distillation</title>
      <link>http://arxiv.org/abs/2502.05864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by DASFAA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的知识蒸馏框架Multiplex Graph-Free Neural Networks (MGFNN)及其改进版本MGFNN+，旨在结合多路图神经网络(MGNNs)的高级性能和MLP模型高效的推断能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多路图（带有多种边类型的图）提供更丰富的结构语义，并且对于某些下游任务中的表现优于单一路径。然而，基于邻居聚合的方法在低延迟应用场景中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;结合MGNNs的性能和MLP模型推断效率，通过知识蒸馏框架进行融合。&lt;h4&gt;方法&lt;/h4&gt;直接训练学生MLP模型使用节点特征作为输入，并用教师MGNN生成的软标签作为目标。MGFNN+进一步采用基于低秩近似的重参数化学习节点级系数，使不同的视图GNN在不同节点上贡献不一。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与普通的MLPs相比，MGFNN模型实现了约10%平均准确率的提升；其性能与教师MGNN相当或更好；推断速度比MGNN快35.40到89.14倍；并且可以为不同的节点分配不同系数以实现多视图融合蒸馏（解释性）。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型不仅提高了准确率，还保证了推理效率，并且具有较好的可解释性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiplex graphs, with multiple edge types (graph views) among common nodes,provide richer structural semantics and better modeling capabilities. MultiplexGraph Neural Networks (MGNNs), typically comprising view-specific GNNs and amulti-view integration layer, have achieved advanced performance in variousdownstream tasks. However, their reliance on neighborhood aggregation poseschallenges for deployment in latency-sensitive applications. Motivated byrecent GNN-to-MLP knowledge distillation frameworks, we propose MultiplexGraph-Free Neural Networks (MGFNN and MGFNN+) to combine MGNNs' superiorperformance and MLPs' efficient inference via knowledge distillation. MGFNNdirectly trains student MLPs with node features as input and soft labels fromteacher MGNNs as targets. MGFNN+ further employs a low-rank approximation-basedreparameterization to learn node-wise coefficients, enabling adaptive knowledgeensemble from each view-specific GNN. This node-wise multi-view ensembledistillation strategy allows student MLPs to learn more informative multiplexsemantic knowledge for different nodes. Experiments show that MGFNNs achieveaverage accuracy improvements of about 10% over vanilla MLPs and performcomparably or even better to teacher MGNNs (accurate); MGFNNs achieve a35.40$\times$-89.14$\times$ speedup in inference over MGNNs (efficient); MGFNN+adaptively assigns different coefficients for multi-view ensemble distillationregarding different nodes (interpretable).</description>
      <author>example@mail.com (Yunhui Liu, Zhen Tao, Xiang Zhao, Jianhua Zhao, Tao Zheng, Tieke He)</author>
      <guid isPermaLink="false">2502.05864v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Neural Shortest Path for Surface Reconstruction from Point Clouds</title>
      <link>http://arxiv.org/abs/2502.06047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的神经最短路径（NSP）模型，该模型通过向量值隐式神经表示来近似距离函数及其梯度。&lt;h4&gt;背景&lt;/h4&gt;现有方法通常单独学习距离函数本身，而无法同时恢复距离函数和其梯度。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时恢复距离函数及其梯度的新方法，并证明NSP分解表示在$H^1$范数下的收敛性。&lt;h4&gt;方法&lt;/h4&gt;将NSP分解为幅度和方向两部分，每个分解组件分别近似于一个距离函数及其梯度；设计了一个新的损失函数以强制执行最短路径的属性。&lt;h4&gt;主要发现&lt;/h4&gt;数学证明了NSP的分解表示保证了$H^1$范数下NSP幅度的收敛性。实验验证了NSP在多种数据集上的性能，显示其能够重建高质量表面，并具有较强的噪声和数据稀疏鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过学习最短路径（ESP），即距离函数及其梯度的乘积，可以有效表示各种复杂表面。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种神经最短路径（NSP）模型，这是一种向量值隐式神经表征，用于逼近一个距离函数及它的梯度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose the neural shortest path (NSP), a vector-valuedimplicit neural representation (INR) that approximates a distance function andits gradient. The key feature of NSP is to learn the exact shortest path (ESP),which directs an arbitrary point to its nearest point on the target surface.The NSP is decomposed into its magnitude and direction, and a variablesplitting method is used that each decomposed component approximates a distancefunction and its gradient, respectively. Unlike to existing methods of learningthe distance function itself, the NSP ensures the simultaneous recovery of thedistance function and its gradient. We mathematically prove that the decomposedrepresentation of NSP guarantees the convergence of the magnitude of NSP in the$H^1$ norm. Furthermore, we devise a novel loss function that enforces theproperty of ESP, demonstrating that its global minimum is the ESP. We evaluatethe performance of the NSP through comprehensive experiments on diversedatasets, validating its capacity to reconstruct high-quality surfaces with therobustness to noise and data sparsity. The numerical results show substantialimprovements over state-of-the-art methods, highlighting the importance oflearning the ESP, the product of distance function and its gradient, forrepresenting a wide variety of complex surfaces.</description>
      <author>example@mail.com (Yesom Park, Imseong Park, Jooyoung Hahn, Myungjoo Kang)</author>
      <guid isPermaLink="false">2502.06047v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>PiKE: Adaptive Data Mixing for Multi-Task Learning Under Low Gradient Conflicts</title>
      <link>http://arxiv.org/abs/2502.06244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;现代机器学习模型通过多任务学习在多样化的数据集和任务上进行训练，以提高泛化能力。PiKE算法适应性地调整训练过程中各任务的贡献，动态优化任务采样策略。&lt;h4&gt;背景&lt;/h4&gt;传统多任务学习研究主要集中在减少任务间的梯度冲突，然而许多现实场景中的任务交互是正向且无显著冲突的。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于积极梯度交互的任务权重估计算法PiKE，以适应不同数据源下的多任务训练需求。&lt;h4&gt;方法&lt;/h4&gt;PiKE通过调整各任务贡献来最小化总体损失，在几乎不增加计算开销的情况下充分利用正面的梯度交互作用。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析证明了PiKE的有效性，并展示了其在大规模语言模型预训练中的优越表现，比静态混合策略更快收敛且提升下游任务性能。&lt;h4&gt;结论&lt;/h4&gt;实验证明，与现有启发式和固定混合策略相比，PiKE能更公平地促进多任务间的平衡学习，防止任务被忽视。它适用于跨领域、跨语言等多样化数据集的预训练模型。&lt;h4&gt;翻译&lt;/h4&gt;现代机器学习模型在多样化的数据集上进行多任务训练以提高泛化能力。当前研究主要集中在减少多任务学习中的梯度冲突问题。然而，许多真实世界的场景显示出积极的任务交互且几乎没有或没有明显的梯度冲突。基于这一观察，我们提出了PiKE（基于正向梯度交互的K任务权重估计器），这是一种适应性数据混合算法，能够在训练过程中动态调整各任务贡献以最小化总体损失。此外，我们扩展了PiKE的方法来促进多任务间的公平学习，确保各个任务能取得均衡的进步，并防止被低估的任务出现。大规模语言模型预训练的实际评估表明，PiKE在现有启发式和固定策略中均表现出色，能够更快地收敛并提升下游任务性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern machine learning models are trained on diverse datasets and tasks toimprove generalization. A key challenge in multitask learning is determiningthe optimal data mixing and sampling strategy across different data sources.Prior research in this multi-task learning setting has primarily focused onmitigating gradient conflicts between tasks. However, we observe that manyreal-world multitask learning scenarios-such as multilingual training andmulti-domain learning in large foundation models-exhibit predominantly positivetask interactions with minimal or no gradient conflict. Building on thisinsight, we introduce PiKE (Positive gradient interaction-based K-task weightsEstimator), an adaptive data mixing algorithm that dynamically adjusts taskcontributions throughout training. PiKE optimizes task sampling to minimizeoverall loss, effectively leveraging positive gradient interactions with almostno additional computational overhead. We establish theoretical convergenceguarantees for PiKE and demonstrate its superiority over static andnon-adaptive mixing strategies. Additionally, we extend PiKE to promote fairlearning across tasks, ensuring balanced progress and preventing taskunderrepresentation. Empirical evaluations on large-scale language modelpretraining show that PiKE consistently outperforms existing heuristic andstatic mixing strategies, leading to faster convergence and improved downstreamtask performance.</description>
      <author>example@mail.com (Zeman Li, Yuan Deng, Peilin Zhong, Meisam Razaviyayn, Vahab Mirrokni)</author>
      <guid isPermaLink="false">2502.06244v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>From Pixels to Components: Eigenvector Masking for Visual Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了在图像表示学习中的一种新的自监督方法，通过随机遮蔽主成分而非原始像素来改进现有的随机打乱像素的方法。&lt;h4&gt;背景&lt;/h4&gt;当前预测被掩码区域从可见部分进行视觉表征学习的主流方式是随机遮蔽一些像素块。然而这种方法存在一定的缺陷，可能导致无法学到高层有意义的特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的策略以克服现有方法的局限性，并通过更为有效的遮蔽操作来改进图像表示的学习。&lt;h4&gt;方法&lt;/h4&gt;采用主成分分析（PCA）作为数据变换方式，在此基础上随机掩码一些主成分而非原始像素，重建任务为从可见部分恢复被隐藏的部分。&lt;h4&gt;主要发现&lt;/h4&gt;对比局部像素块的处理，图片中的主成分包含了更多的全局信息。因此，预测被遮蔽的主成分能够更好地使用高层特征进行学习，并且实验结果验证了这种方法可以提高图像分类性能。&lt;h4&gt;结论&lt;/h4&gt;提出的基于主成分分析的方法为传统的掩码图像建模提供了一种简单而稳健的数据驱动替代方案。&lt;h4&gt;翻译&lt;/h4&gt;预测图片中被掩盖部分，以从可见部分获取视觉表征的学习是一种强大的自监督方法。然而，随机遮蔽像素块的常见做法显示出某些失败模式，这可能会阻止学习到下游任务所需的有意义的高级特征。我们提出了一种基于数据变换而非原始像素的替代掩码策略。具体来说，在进行主成分分析后，我们随机掩盖一定数量的分量，这些分量占整个数据方差的比例固定不变。接下来的任务则是从可见部分重建被掩盖的分量。相较于局部像素块，图像中的主成分包含了更多的全局信息。因此，预测被遮蔽的主成分涉及更多高级特征，允许我们的掩码策略提取出更有用的表示形式。通过实验证明了相比于像素掩码，使用成分掩码可以提高图像分类性能。我们提出的方法为传统的基于掩膜的图像建模方法提供了一种简单而稳健的数据驱动替代方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting masked from visible parts of an image is a powerfulself-supervised approach for visual representation learning. However, thecommon practice of masking random patches of pixels exhibits certain failuremodes, which can prevent learning meaningful high-level features, as requiredfor downstream tasks. We propose an alternative masking strategy that operateson a suitable transformation of the data rather than on the raw pixels.Specifically, we perform principal component analysis and then randomly mask asubset of components, which accounts for a fixed ratio of the data variance.The learning task then amounts to reconstructing the masked components from thevisible ones. Compared to local patches of pixels, the principal components ofimages carry more global information. We thus posit that predicting masked fromvisible components involves more high-level features, allowing our maskingstrategy to extract more useful representations. This is corroborated by ourempirical findings which demonstrate improved image classification performancefor component over pixel masking. Our method thus constitutes a simple androbust data-driven alternative to traditional masked image modeling approaches.</description>
      <author>example@mail.com (Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt)</author>
      <guid isPermaLink="false">2502.06314v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification</title>
      <link>http://arxiv.org/abs/2502.05836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted on NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的任务，即通过修辞角色分类来对法律文件进行语义分割，并且介绍了LegalSeg数据集作为该任务的最大标注数据集。&lt;h4&gt;背景&lt;/h4&gt;目前缺乏针对印度法律判决的大型语料库和有效的评估基准，这阻碍了相关研究的发展。&lt;h4&gt;目的&lt;/h4&gt;开发一个大规模的数据集并评价多种最先进的模型在法律文件修辞角色分类中的表现。&lt;h4&gt;方法&lt;/h4&gt;引入LegalSeg数据集，并评测包括Hierarchical BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)等在内的多个模型，同时还探索了RhetoricLLaMA语言模型的应用。&lt;h4&gt;主要发现&lt;/h4&gt;整合更广泛的上下文信息和结构关系的模型优于仅依赖句子级别特征的模型。此外，周边文本和标签对分类准确性的改善也被研究。&lt;h4&gt;结论&lt;/h4&gt;尽管在区分相似角色及处理类别不平衡方面仍存在挑战，但这项工作展示了高级技术对于提高法律文件理解的巨大潜力，并为未来的研究奠定了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们通过修辞角色分类的任务来解决对法律文件进行语义分割的问题，重点是印度的法律判决。我们介绍了LegalSeg，这是目前最大的针对该任务的数据集，包含超过7,000份文档和140万句句子，并用七种修辞角色进行了标注。为了评估性能，我们评测了多个最先进的模型，包括Hierarchical BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)、图神经网络(GNNs)以及Role-Aware Transformers，同时探索了一个经过指令微调的大型语言模型RhetoricLLaMA的应用情况。我们的结果表明，整合更广泛的上下文信息、结构关系和连续句子信息的模型优于仅依赖于句子级别特征的模型。此外，我们通过实验研究了使用周围文本和预测或实际标签的影响来评估它们对分类准确性的改善作用。尽管这些进展已经取得了一定成果，但在区分密切相关角色以及处理类别不平衡方面仍然存在挑战。我们的工作强调了高级技术在提高法律文件理解方面的巨大潜力，并为未来的研究奠定了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the task of semantic segmentation of legaldocuments through rhetorical role classification, with a focus on Indian legaljudgments. We introduce LegalSeg, the largest annotated dataset for this task,comprising over 7,000 documents and 1.4 million sentences, labeled with 7rhetorical roles. To benchmark performance, we evaluate multiplestate-of-the-art models, including Hierarchical BiLSTM-CRF,TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), andRole-Aware Transformers, alongside an exploratory RhetoricLLaMA, aninstruction-tuned large language model. Our results demonstrate that modelsincorporating broader context, structural relationships, and sequentialsentence information outperform those relying solely on sentence-levelfeatures. Additionally, we conducted experiments using surrounding context andpredicted or actual labels of neighboring sentences to assess their impact onclassification accuracy. Despite these advancements, challenges persist indistinguishing between closely related roles and addressing class imbalance.Our work underscores the potential of advanced techniques for improving legaldocument understanding and sets a strong foundation for future research inlegal NLP.</description>
      <author>example@mail.com (Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya)</author>
      <guid isPermaLink="false">2502.05836v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Representation Distillation via Multi-Scale Feature Decoupling</title>
      <link>http://arxiv.org/abs/2502.05835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;知识蒸馏是一种技术，旨在通过从预训练的大模型（教师网络）向较小的模型（学生网络）转移知识来提升小模型的表现，而不增加其参数量。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的方法，在特征传递过程中引入多尺度解耦，以处理不同区域嵌入的不同类型的信息，并提高学生网络的学习效率和性能。&lt;h4&gt;方法&lt;/h4&gt;该研究首次在特征传输中采用了多尺度解耦策略，其中解耦的局部特征被单独处理并使用对比学习进行整合。相比之前基于对比学习的方法，这种方法减少了计算成本并提高了效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在CIFAR-100和ImageNet数据集上的评估显示了该方法的优势；某些学生网络在蒸馏后甚至超过了教师网络的表现。&lt;h4&gt;结论&lt;/h4&gt;研究表明我们的方法使得学生模型能够充分吸收教师网络的知识，从而表现出色。&lt;h4&gt;翻译&lt;/h4&gt;知识蒸馏是一种通过将预训练的大型教师模型中的知识转移到较小的学生模型中以提高其性能的技术。现有的研究主要集中在全局特征信息上，而忽略了不同区域嵌入的不同类型的信息的重要性。本文首次在特征传输过程中引入了多尺度解耦策略，并使用对比学习来处理解耦后的局部特征。该方法不仅减少了计算成本和提升了效率，还能够通过仅用单批样本使学生网络的表现得到改进。广泛的实验证明了我们的方法的有效性，在某些情况下，蒸馏后的学生模型甚至超过了教师模型的性能，这表明学生模型可以充分吸收教师模型的知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge distillation is a technique aimed at enhancing the performance of asmaller student network without increasing its parameter size by transferringknowledge from a larger, pre-trained teacher network. Previous approaches havepredominantly focused on distilling global feature information whileoverlooking the importance of disentangling the diverse types of informationembedded within different regions of the feature. In this work, we introducemulti-scale decoupling in the feature transfer process for the first time,where the decoupled local features are individually processed and integratedwith contrastive learning. Moreover, compared to previous contrastivelearning-based distillation methods, our approach not only reducescomputational costs but also enhances efficiency, enabling performanceimprovements for the student network using only single-batch samples. Extensiveevaluations on CIFAR-100 and ImageNet demonstrate our method's superiority,with some student networks distilled using our method even surpassing theperformance of their pre-trained teacher networks. These results underscore theeffectiveness of our approach in enabling student networks to thoroughly absorbknowledge from teacher networks.</description>
      <author>example@mail.com (Cuipeng Wang, Tieyuan Chen, Haipeng Wang)</author>
      <guid isPermaLink="false">2502.05835v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Fully Exploiting Vision Foundation Model's Profound Prior Knowledge for Generalizable RGB-Depth Driving Scene Parsing</title>
      <link>http://arxiv.org/abs/2502.06219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的异构特征集成变换器(HFIT)，用于RGB-深度驾驶场景解析，该方法利用了视觉基础模型(VFM)的潜力，并在Cityscapes和KITTI Semantics数据集上展示了其优越性能。&lt;h4&gt;背景&lt;/h4&gt;虽然基于Vision Transformer (ViT)的视觉基础模型(VFMs)已经在仅关注RGB图像的任务中取得了成功，但它们在RGB-深度驾驶场景解析中的应用尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;探索一种可行的技术来充分利用VFMs进行通用化的RGB-深度驾驶场景解析。&lt;h4&gt;方法&lt;/h4&gt;研究了RGB和深度数据的内在特性，并提出了一种异构特征集成变换器(HFIT)，该网络可以在不重新训练ViT的情况下高效提取和整合全面的异质特征。&lt;h4&gt;主要发现&lt;/h4&gt;HFIT克服了依赖于深度图的限制，利用VFM生成的相关深度预测结果作为输入。在Cityscapes和KITTI Semantics数据集上，提出的HFIT比所有传统的单模态、数据融合场景解析网络以及预训练VFMs和ViT适配器表现更佳。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为基于视觉基础模型的数据融合技术未来的发展开辟了道路，并且源代码已经公开分享。&lt;h4&gt;翻译&lt;/h4&gt;最近的视觉基础模型(VFMs)，通常是基于Vision Transformer (ViT)构建的，已经在许多计算机视觉任务中取得了显著进展。尽管它们在仅关注RGB图像的任务上取得成功，但在RGB-深度驾驶场景解析中的潜力仍然未被充分开发。本文通过研究一种可行的技术来充分利用VFMs进行通用化的RGB-深度驾驶场景解析，迈向了这个新兴的研究领域。具体而言，我们探讨了RGB和深度数据的内在特性，并提出了一种异构特征集成变换器(HFIT)。该网络能够高效提取并整合全面的异质特征而无需重新训练ViTs。VFM生成的相关深度预测结果作为输入给HFIT侧面适配器，克服了依赖于深度图的限制。与所有传统的单模态和数据融合场景解析网络、预训练VFMs以及ViT适配器相比，我们提出的HFIT在Cityscapes和KITTI Semantics数据集上展示了更优越的表现。我们认为这一创新策略为基于视觉基础模型的数据融合技术未来的发展铺平了道路，并且源代码已经公开分享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent vision foundation models (VFMs), typically based on Vision Transformer(ViT), have significantly advanced numerous computer vision tasks. Despitetheir success in tasks focused solely on RGB images, the potential of VFMs inRGB-depth driving scene parsing remains largely under-explored. In thisarticle, we take one step toward this emerging research area by investigating afeasible technique to fully exploit VFMs for generalizable RGB-depth drivingscene parsing. Specifically, we explore the inherent characteristics of RGB anddepth data, thereby presenting a Heterogeneous Feature Integration Transformer(HFIT). This network enables the efficient extraction and integration ofcomprehensive heterogeneous features without re-training ViTs. Relative depthprediction results from VFMs, used as inputs to the HFIT side adapter, overcomethe limitations of the dependence on depth maps. Our proposed HFIT demonstratessuperior performance compared to all other traditional single-modal anddata-fusion scene parsing networks, pre-trained VFMs, and ViT adapters on theCityscapes and KITTI Semantics datasets. We believe this novel strategy pavesthe way for future innovations in VFM-based data-fusion techniques for drivingscene parsing. Our source code is publicly available athttps://mias.group/HFIT.</description>
      <author>example@mail.com (Sicen Guo, Tianyou Wen, Chuang-Wei Liu, Qijun Chen, Rui Fan)</author>
      <guid isPermaLink="false">2502.06219v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A 3D Multimodal Feature for Infrastructure Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.05779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的三维多模态特征3DMulti-FPFHI，用于提高老化结构点云中的裂缝检测质量。&lt;h4&gt;背景&lt;/h4&gt;老旧结构需要定期检查以识别结构缺陷。之前的工作使用了几何变形来定位合成砌体桥的点云中的裂缝，但难以发现小裂缝。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的三维多模态特征3DMulti-FPFHI，结合定制化的快速点特征直方图（FPFH）和强度特征，以增强检测小型裂缝的能力。&lt;h4&gt;方法&lt;/h4&gt;该新特征被集成到PatchCore异常检测算法中，并通过统计和参数分析进行评估。使用真实砌体拱桥的点云数据和全尺寸混凝土隧道实验模型进行了进一步验证。&lt;h4&gt;主要发现&lt;/h4&gt;3D强度特征提高了检查质量，增强了裂缝检测能力；还能够识别水分入侵产生的强度异常现象。与FPFH及最先进的多模态异常检测方法相比，3DMulti-FPFHI表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法在处理基础设施的多种异常检测场景中显示出潜在价值，尤其是在需要的数据量方面远少于基于学习的方法。&lt;h4&gt;翻译&lt;/h4&gt;老化结构需定期检查以识别结构缺陷。此前研究采用几何畸变来定位合成砌体桥点云中的裂缝，但难以探测小裂缝。为解决这一限制，本文提出一种新的3D多模态特征——3DMulti-FPFHI，结合定制的快速点特征直方图（FPFH）与强度特征。该特征被纳入PatchCore异常检测算法，并通过统计和参数分析进行评估。采用真实砌体拱桥及全尺寸混凝土隧道实验模型的点云数据进一步验证方法效果。结果显示，3D强度特性提高了检查质量并增强了裂缝检测能力；此外，它还能够识别水分入侵造成的强度异常现象。与FPFH及最先进的多模态异常检测方法相比，3DMulti-FPFHI表现更佳。该方法在处理基础设施多种异常检测场景时显示出了潜在价值，尤其是在数据需求方面低于基于学习的方法。相关代码和点云数据集可在GitHub上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ageing structures require periodic inspections to identify structuraldefects. Previous work has used geometric distortions to locate cracks insynthetic masonry bridge point clouds but has struggled to detect small cracks.To address this limitation, this study proposes a novel 3D multimodal feature,3DMulti-FPFHI, that combines a customized Fast Point Feature Histogram (FPFH)with an intensity feature. This feature is integrated into the PatchCoreanomaly detection algorithm and evaluated through statistical and parametricanalyses. The method is further evaluated using point clouds of a real masonryarch bridge and a full-scale experimental model of a concrete tunnel. Resultsshow that the 3D intensity feature enhances inspection quality by improvingcrack detection; it also enables the identification of water ingress whichintroduces intensity anomalies. The 3DMulti-FPFHI outperforms FPFH and astate-of-the-art multimodal anomaly detection method. The potential of themethod to address diverse infrastructure anomaly detection scenarios ishighlighted by the minimal requirements for data compared to learning-basedmethods. The code and related point cloud dataset are available athttps://github.com/Jingyixiong/3D-Multi-FPFHI.</description>
      <author>example@mail.com (Yixiong Jing, Wei Lin, Brian Sheil, Sinan Acikgoz)</author>
      <guid isPermaLink="false">2502.05779v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>K-ON: Stacking Knowledge On the Head Layer of Large Language Model</title>
      <link>http://arxiv.org/abs/2502.06257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;近期的大规模语言模型在各种自然语言处理任务中取得了显著进步，但这些模型与知识图谱场景存在粒度不匹配的问题。为此提出了一种名为K-ON的方法，通过引入多头层进行下一k步预测来整合知识图谱的知识。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在许多自然语言处理任务中表现出色，因为它们通常被训练来进行下一个标记的预测。然而，在知识图谱场景下，实体是基本单元，并且识别一个实体需要多个令牌，这导致了知识图谱和自然语言之间的粒度不匹配。&lt;h4&gt;目的&lt;/h4&gt;为了解决LLMs与知识图谱之间存在的粒度不匹配问题，提出了一种新的方法K-ON来整合知识图谱的知识。&lt;h4&gt;方法&lt;/h4&gt;通过在大型语言模型中引入多个头层进行下一k步预测，以适应实体识别任务的需求。这种方法不仅能够在一步内生成实体级别的结果，还可以使用与实体对比的损失函数作为最强大的工具进行知识图谱表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示K-ON方法优于现有文本和多模态融合的最佳方法。&lt;h4&gt;结论&lt;/h4&gt;提出的K-ON模型能够有效地将知识图谱的知识整合到大型语言模型中，从而提高实体识别任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language models (LLMs) have significantlyimproved various natural language processing (NLP) tasks. Typically, LLMs aretrained to predict the next token, aligning well with many NLP tasks. However,in knowledge graph (KG) scenarios, entities are the fundamental units andidentifying an entity requires at least several tokens. This leads to agranularity mismatch between KGs and natural languages. To address this issue,we propose K-ON, which integrates KG knowledge into the LLM by employingmultiple head layers for next k-step prediction. K-ON can not only generateentity-level results in one step, but also enables contrastive loss againstentities, which is the most powerful tool in KG representation learning.Experimental results show that K-ON outperforms state-of-the-art methods thatincorporate text and even the other modalities.</description>
      <author>example@mail.com (Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen)</author>
      <guid isPermaLink="false">2502.06257v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation</title>
      <link>http://arxiv.org/abs/2502.05780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了GOLD框架，用于图数据的OOD检测。&lt;h4&gt;背景&lt;/h4&gt;当前的图神经网络在处理图结构数据时面临OOD实例识别挑战，特别是缺乏额外的OOD样本。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需预训练生成模型的数据合成方法来解决图数据中的OOD问题。&lt;h4&gt;方法&lt;/h4&gt;GOLD框架采用隐式对抗学习管道，在没有预训练模型的情况下使用合成OOD数据进行检测。通过交替优化框架，训练一个潜在生成器模仿当前的ID嵌入，并同时训练图神经网络编码器和OOD探测器以区分ID和OOD数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了GOLD在五个基准图数据集上的优越性能，无需使用真实的OOD数据即可超越最先进的OOD暴露和非暴露基线方法。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种创新的方法来模拟没有额外数据的OOD场景，并证明了其在处理图结构数据中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;尽管图神经网络（GNN）在建模图结构数据方面取得了巨大成功，但当前GNN仍然面临着识别OOD测试实例的巨大挑战。一种最有效的技术是通过暴露检测器模型与额外的OOD节点集来实现，然而，在实践中获取这些额外的OOD样本非常困难。最近的方法通过使用OOD数据合成解决了图像数据中的这一问题，通常依赖于像StableDiffusion这样的预训练生成模型。但是，对于图数据而言，这种方法需要大量额外的数据以及一个通用的预训练生成模型，这是不可用的。因此，我们提出了用于图OOD检测的GOLD框架，这是一种无需预训练模型但具有合成OOD暴露的隐式对抗性学习管道。该隐式对抗训练过程采用了新颖的交替优化框架：（1）通过训练潜在生成器来定期模仿来自演进中的GNN的ID嵌入；（2）同时训练图神经网络编码器和OOD探测器以准确分类ID数据，增加ID嵌入与生成模型合成嵌入之间的能量差异。这种新颖的方法隐式地将合成嵌入转化为相对于ID数据的伪OOD实例，有效地模拟了没有辅助数据的情况下暴露于OOD场景的过程。在五个基准图数据集上进行了广泛的OOD检测实验，验证了GOLD相比于最先进的OOD曝光和非曝光基线方法，在不使用真实OOD数据时具有优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite graph neural networks' (GNNs) great success in modellinggraph-structured data, out-of-distribution (OOD) test instances still pose agreat challenge for current GNNs. One of the most effective techniques todetect OOD nodes is to expose the detector model with an additional OODnode-set, yet the extra OOD instances are often difficult to obtain inpractice. Recent methods for image data address this problem using OOD datasynthesis, typically relying on pre-trained generative models like StableDiffusion. However, these approaches require vast amounts of additional data,as well as one-for-all pre-trained generative models, which are not availablefor graph data. Therefore, we propose the GOLD framework for graph OODdetection, an implicit adversarial learning pipeline with synthetic OODexposure without pre-trained models. The implicit adversarial training processemploys a novel alternating optimisation framework by training: (1) a latentgenerative model to regularly imitate the in-distribution (ID) embeddings froman evolving GNN, and (2) a GNN encoder and an OOD detector to accuratelyclassify ID data while increasing the energy divergence between the IDembeddings and the generative model's synthetic embeddings. This novel approachimplicitly transforms the synthetic embeddings into pseudo-OOD instancesrelative to the ID data, effectively simulating exposure to OOD scenarioswithout auxiliary data. Extensive OOD detection experiments are conducted onfive benchmark graph datasets, verifying the superior performance of GOLDwithout using real OOD data compared with the state-of-the-art OOD exposure andnon-exposure baselines.</description>
      <author>example@mail.com (Danny Wang, Ruihong Qiu, Guangdong Bai, Zi Huang)</author>
      <guid isPermaLink="false">2502.05780v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis</title>
      <link>http://arxiv.org/abs/2502.05556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的知识增强认知诊断(KCD)框架，旨在利用大型语言模型(LLM)的优势来改进现有的认知诊断模型(CDM)，以更全面和精细地评估学生的认知状态。&lt;h4&gt;背景&lt;/h4&gt;现有的认知诊断模型在缺乏丰富先验知识的情况下难以对不频繁出现的学生和练习进行有效诊断。随着大型语言模型的发展，这些模型因其广泛的领域知识而被引入到认知诊断中来。&lt;h4&gt;目的&lt;/h4&gt;通过结合大型语言模型与认知诊断模型的优点，提出一种适用于多种CDM架构的知识增强框架，以解决现有CDM在处理稀疏数据时的局限性，并提高其对学习者和练习的认知诊断能力。&lt;h4&gt;方法&lt;/h4&gt;KCD框架包括两个阶段：LLM诊断和认知水平对齐。在第一个阶段中，利用大型语言模型对学生和练习进行综合详细的诊断；第二个阶段则是通过对比学习和掩码重建方法将CDMs的行为空间与LLMs的语义空间连接起来。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的KCD框架能够在多个真实数据集上有效提高认知诊断的效果。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了一种新颖的方法来利用大型语言模型的知识增强现有的认知诊断，为未来结合不同领域的知识和人工智能技术在教育评估中的应用开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitivestates by analyzing their performance across a series of exercises. However,existing CDMs often struggle with diagnosing infrequent students and exercisesdue to a lack of rich prior knowledge. With the advancement in large languagemodels (LLMs), which possess extensive domain knowledge, their integration intocognitive diagnosis presents a promising opportunity. Despite this potential,integrating LLMs with CDMs poses significant challenges. LLMs are notwell-suited for capturing the fine-grained collaborative interactions betweenstudents and exercises, and the disparity between the semantic space of LLMsand the behavioral space of CDMs hinders effective integration. To addressthese issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD)framework, which is a model-agnostic framework utilizing LLMs to enhance CDMsand compatible with various CDM architectures. The KCD framework operates intwo stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosisstage, both students and exercises are diagnosed to achieve comprehensive anddetailed modeling. In the Cognitive Level Alignment stage, we bridge the gapbetween the CDMs' behavioral space and the LLMs' semantic space usingcontrastive learning and mask-reconstruction approaches. Experiments on severalreal-world datasets demonstrate the effectiveness of our proposed framework.</description>
      <author>example@mail.com (Zhiang Dong, Jingyuan Chen, Fei Wu)</author>
      <guid isPermaLink="false">2502.05556v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Estimation with missing not at random binary outcomes via exponential tilts</title>
      <link>http://arxiv.org/abs/2502.06046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了二元结果缺失非随机（MNAR）数据集的问题，并提出了一种基于指数倾斜的方法，这种方法不需要通常进行统计估计所需的'非响应工具变量'或'影子变量'。我们建立了足够的条件来确定倾斜参数的可识别性，并提出了一个用于估算这些参数的算法。根据这些倾斜参数估计值，我们提出了重要权加权和双重稳健估计器，以估计感兴趣的任何平均函数，并通过合成数据集验证了其性能。&lt;h4&gt;背景&lt;/h4&gt;在处理缺失非随机（MNAR）的数据时，传统的统计方法往往需要额外的信息如'非响应工具变量'或'影子变量'来提高估计的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于指数倾斜的方法用于处理二元结果缺失非随机数据集的问题，并验证该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种基于指数倾斜的新方法，以避开传统的需要额外信息（如'非响应工具变量'或'影子变量'）的要求；2. 确定了确定倾斜参数的可识别性的充分条件；3. 开发了一个算法来估计这些倾斜参数。&lt;h4&gt;主要发现&lt;/h4&gt;1. 提供了一种无需依赖特殊外部变量的新方法来处理MNAR数据集中的二元结果问题。 2. 基于提出的框架，实现了重要的加权和双重稳健的估计器用于任何感兴趣的平均函数，并且在合成数据集中验证了其性能。&lt;h4&gt;结论&lt;/h4&gt;利用所提的指数倾斜框架，在Waterbirds数据集上执行无监督迁移学习实验时，当响应变量来自目标域的数据缺失时，能够达到与黄金标准相媲美的预测表现。这表明该方法在处理MNAR问题上的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了具有二元结果的'非随机缺少（MNAR）数据集的问题，并提出了一种基于指数倾斜的方法，这种方法不需要通常进行统计估计所需的“非响应工具变量”或“影子变量”。我们建立了足够的条件来确定倾斜参数的可识别性，并提出了一个用于估算这些参数的算法。根据这些倾斜参数估计值，我们提出了重要权加权和双重稳健估计器以估计感兴趣的任何平均函数，并通过合成数据集验证了其性能。在Waterbirds数据集上的实验中，我们利用我们的倾斜框架执行无监督迁移学习，在响应变量来自目标域的数据缺失时，达到了与黄金标准相媲美的预测表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of missing not at random (MNAR) datasets with binaryoutcomes. We propose an exponential tilt based approach that bypasses anyknowledge on 'nonresponse instruments' or 'shadow variables' that are usuallyrequired for statistical estimation. We establish a sufficient condition foridentifiability of tilt parameters and propose an algorithm to estimate them.Based on these tilt parameter estimates, we propose importance weighted anddoubly robust estimators for any mean functions of interest, and validate theirperformances in a synthetic dataset. In an experiment with the Waterbirdsdataset, we utilize our tilt framework to perform unsupervised transferlearning, when the responses are missing from a target domain of interest, andachieve a prediction performance that is comparable to a gold standard.</description>
      <author>example@mail.com (Subha Maity)</author>
      <guid isPermaLink="false">2502.06046v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset</title>
      <link>http://arxiv.org/abs/2502.06180v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in WASSA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了在Twitter上使用低资源语言数据进行情感和情绪分类的挑战，并评估了几种最先进的基于Transformer的预训练模型。&lt;h4&gt;背景&lt;/h4&gt;社交媒体已成为个人表达观点、分享经验的重要开放平台，但在推特上利用低资源语言的数据面临诸多困难，如内容稀缺、质量低下以及语言使用的巨大差异（包括俚语和代码混合）。&lt;h4&gt;目的&lt;/h4&gt;评估几种最先进的基于Transformer的预训练模型在肯尼亚使用代码混合数据的情感分析与情绪分类任务中的性能表现，并详细介绍了数据收集及标注的方法论及其遇到的数据整理阶段挑战。&lt;h4&gt;方法&lt;/h4&gt;使用监督学习和半监督学习两种方式，对四种最先进（SOTA）的Transformer预训练模型进行评估：XLM-R、mBERT、DistilBERT以及Afri-BERTa。具体描述了数据采集与注释的方法论及其在数据整理阶段遇到的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，对于情感分析任务，XLM-R模型（无论是监督学习还是半监督学习）都达到了最高的准确率和F1分数；而对于情绪分类，DistilBERT的监督模型表现最好，mBERT的半监督模型次之。Afri-BERTa模型在这两个任务中的准确性及F1得分均为最低值。&lt;h4&gt;结论&lt;/h4&gt;所有测试模型在预测中性情感方面存在倾向性，特别是Afri-BERTa模型对于共情情绪显示出最高的偏差和独特的敏感度。XLM-R在代码混合语言的情感分析与情绪分类任务上表现出色，尽管面临诸多挑战依然具有较高的准确性和F1分数。&lt;h4&gt;翻译&lt;/h4&gt;社交媒体已成为个人表达观点、分享经验的重要开放平台。然而，在Twitter这样的平台上利用低资源语言的数据面临着诸如内容稀缺和质量低下等巨大挑战，尤其是当出现俚语或代码混合使用时更是如此。该研究分析了肯尼亚的代码混合数据，并评估了几种最先进的（SOTA）基于Transformer预训练模型的情感和情绪分类能力，包括监督学习和半监督学习方法。文章详细描述了数据收集、注释的方法以及在数据整理阶段所遇到的挑战。实验结果显示，在情感分析任务中，XLM-R模型无论是通过监督学习还是半监督学习都达到了最高的准确率和F1分数；而在情绪分类方面，DistilBERT监督模型表现出色，其次为mBERT半监督模型。Afri-BERTa模型在这两项任务中的表现最弱。所有测试的模型倾向于预测中性情感，而Afri-BERTa模型对于共情情绪显示出最高的偏差和独特的敏感度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.18653/v1/2024.wassa-1.19&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social media has become a crucial open-access platform for individuals toexpress opinions and share experiences. However, leveraging low-resourcelanguage data from Twitter is challenging due to scarce, poor-quality contentand the major variations in language use, such as slang and code-switching.Identifying tweets in these languages can be difficult as Twitter primarilysupports high-resource languages. We analyze Kenyan code-switched data andevaluate four state-of-the-art (SOTA) transformer-based pretrained models forsentiment and emotion classification, using supervised and semi-supervisedmethods. We detail the methodology behind data collection and annotation, andthe challenges encountered during the data curation phase. Our results showthat XLM-R outperforms other models; for sentiment analysis, XLM-R supervisedmodel achieves the highest accuracy (69.2\%) and F1 score (66.1\%), XLM-Rsemi-supervised (67.2\% accuracy, 64.1\% F1 score). In emotion analysis,DistilBERT supervised leads in accuracy (59.8\%) and F1 score (31\%), mBERTsemi-supervised (accuracy (59\% and F1 score 26.5\%). AfriBERTa models show thelowest accuracy and F1 scores. All models tend to predict neutral sentiment,with Afri-BERT showing the highest bias and unique sensitivity to empathyemotion. https://github.com/NEtori21/Ride_hailing</description>
      <author>example@mail.com (Naome A. Etori, Maria L. Gini)</author>
      <guid isPermaLink="false">2502.06180v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>4DR P2T: 4D Radar Tensor Synthesis with Point Clouds</title>
      <link>http://arxiv.org/abs/2502.05550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了4D雷达点云到张量生成模型(4DR P2T)，利用条件生成对抗网络(cGAN)处理4D雷达数据，减少测量损失并优化深度学习应用。&lt;h4&gt;背景&lt;/h4&gt;在四维雷达点云生成中，使用恒虚警率(CFAR)算法去除杂波，但CFAR可能无法完全捕捉到目标的空间特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型来克服传统方法的局限性，同时提高数据的质量和减少测量损失以适应深度学习应用。&lt;h4&gt;方法&lt;/h4&gt;采用条件生成对抗网络(cGAN)，对其进行了修改以便有效处理4D雷达点云数据并生成张量数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的4DR P2T模型在K-Radar数据集上实现了平均PSNR为30.39dB和SSIM为0.96的效果。此外，分析显示5%分位数方法提供了最佳的整体性能，而1%分位数方法则在数据量减少与性能之间取得了良好的平衡。&lt;h4&gt;结论&lt;/h4&gt;4DR P2T模型有效解决了传统CFAR算法存在的问题，并且是用于深度学习应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种四维雷达点云生成模型的研究，该模型通过改进的条件生成对抗网络来处理四维雷达数据并减少测量损失。实验结果表明其在特定数据集上的优越性能和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In four-dimensional (4D) Radar-based point cloud generation, clutter removalis commonly performed using the constant false alarm rate (CFAR) algorithm.However, CFAR may not fully capture the spatial characteristics of objects. Toaddress limitation, this paper proposes the 4D Radar Point-to-Tensor (4DR P2T)model, which generates tensor data suitable for deep learning applicationswhile minimizing measurement loss. Our method employs a conditional generativeadversarial network (cGAN), modified to effectively process 4D Radar pointcloud data and generate tensor data. Experimental results on the K-Radardataset validate the effectiveness of the 4DR P2T model, achieving an averagePSNR of 30.39dB and SSIM of 0.96. Additionally, our analysis of different pointcloud generation methods highlights that the 5% percentile method provides thebest overall performance, while the 1% percentile method optimally balancesdata volume reduction and performance, making it well-suited for deep learningapplications.</description>
      <author>example@mail.com (Woo-Jin Jung, Dong-Hee Paek, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.05550v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Link Prediction for Directed Graphs</title>
      <link>http://arxiv.org/abs/2502.05724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;有向图链接预测及其在现实世界中的应用，以及改进现有评估基准的需求。&lt;h4&gt;背景&lt;/h4&gt;目前有多种方法用于有向图的链路预测任务，包括嵌入方法和图形神经网络（GNNs）。然而这些方法往往缺乏对表示能力的深入分析，并且使用的评价基准不足以进行公平评估。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架来评估现有方法的表达力，同时介绍一个新的基准测试DirLinkBench以应对当前实验设置中的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了新的有向图链路预测基准DirLinkBench，并且理论重新审视DiGAE，还提出了新的谱系定向图形自动编码器SDGAE。&lt;h4&gt;主要发现&lt;/h4&gt;目前的方法在新基准上难以取得强性能，而DiGAE总体表现最好。此外，研究展示了DiGAE的图卷积与无向二分图上的GCN一致，并提出了新颖的谱系有向图自编码器SDGAE，在DirLinkBench中取得了当前最佳结果。&lt;h4&gt;结论&lt;/h4&gt;分析了影响有向图链接预测的关键因素，并指出了开放性挑战。新的基准测试和研究方法为该领域提供了前进方向，有助于改进未来的研究成果。&lt;h4&gt;翻译&lt;/h4&gt;针对有向图的链路预测任务，本文提出了一种评估现有方法表示能力的统一框架，并且为了克服当前实验设置中的局限性，引入了新基准DirLinkBench。结果显示目前的方法在新的基准测试中难以取得强性能，而DiGAE总体表现最佳。此外还提出了谱系有向图自编码器SDGAE，在新基准中取得了最新成果。最后分析了一些关键因素，并强调了开放性的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction for directed graphs is a crucial task with diverse real-worldapplications. Recent advances in embedding methods and Graph Neural Networks(GNNs) have shown promising improvements. However, these methods often lack athorough analysis of embedding expressiveness and suffer from ineffectivebenchmarks for a fair evaluation. In this paper, we propose a unified frameworkto assess the expressiveness of existing methods, highlighting the impact ofdual embeddings and decoder design on performance. To address limitations incurrent experimental setups, we introduce DirLinkBench, a robust new benchmarkwith comprehensive coverage and standardized evaluation. The results show thatcurrent methods struggle to achieve strong performance on the new benchmark,while DiGAE outperforms others overall. We further revisit DiGAE theoretically,showing its graph convolution aligns with GCN on an undirected bipartite graph.Inspired by these insights, we propose a novel spectral directed graphauto-encoder SDGAE that achieves SOTA results on DirLinkBench. Finally, weanalyze key factors influencing directed link prediction and highlight openchallenges.</description>
      <author>example@mail.com (Mingguo He, Yuhe Guo, Yanping Zheng, Zhewei Wei, Stephan Günnemann, Xiaokui Xiao)</author>
      <guid isPermaLink="false">2502.05724v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Protecting Intellectual Property of EEG-based Neural Networks with Watermarking</title>
      <link>http://arxiv.org/abs/2502.05931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 13 figures, and 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于加密奇偶校验过滤器的水印框架，专门针对EEG（脑电图）基神经网络进行知识产权保护。&lt;h4&gt;背景&lt;/h4&gt;基于EEG的神经网络在医学诊断和脑机接口中发挥着关键作用，但由于依赖于敏感的神经生理数据且开发资源密集，面临重大的IP风险。当前的水印方法不能有效应对这些挑战。&lt;h4&gt;目的&lt;/h4&gt;通过提供一种专门针对EEG模型的独特水印框架来增强知识产权保护措施。&lt;h4&gt;方法&lt;/h4&gt;采用抗碰撞性散列和公钥加密技术，在训练过程中嵌入水印，确保最小失真（精度下降不超过5%）及高可靠性（100%的水印检测率）。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在对抗攻击下表现出持久性：即便经过严苛的神经元修剪后，带水印状态的分类准确度仍保持高于90%，而未被有效去除。此外，无法嵌入第二层水印而不会导致严重的准确性损失。&lt;h4&gt;结论&lt;/h4&gt;该方法通过DEAP数据集进行验证，在各种模型上实现超过99.4%的虚设嵌入精度，展示了其在保护敏感EEG模型方面的有效性，并保持了诊断实用性。&lt;h4&gt;翻译&lt;/h4&gt;基于脑电图（EEG）的神经网络在医疗诊断和脑机接口领域至关重要，但由于依赖于敏感的神经生理数据以及资源密集型开发过程，它们面临着重大的知识产权风险。现有的水印方法，尤其是使用抽象触发集的方法，在提供强大的身份验证方面效果不佳，并未能解决EEG模型特有的挑战。本文提出了一种基于加密奇偶校验过滤器的水印框架，专门用于保护基于EEG的神经网络。通过利用抗碰撞性散列和公钥加密技术，该框架在训练过程中嵌入水印，确保最少的失真（不超过5%的精度下降）并实现高可靠性（100%的水印检测率）。此方法经过了对抗攻击的严格评估，包括微调、迁移学习以及神经元修剪。结果表明，在极端修剪下，带水印的状态依然保持超过90%的分类准确度，而主任务性能则下降更快，从而有效阻止非法去除尝试。验证该方法对盗版行为的有效性时发现，无法嵌入第二层水印不会造成严重的精度损失（EEGNet和CCNN模型中的精度降低超过10%）。通过使用加密散列进行身份验证可以降低暴力破解攻击的成功概率。在DEAP数据集上，该方法实现了大于99.4%的虚设嵌入准确率，在各种模型中有效消除了假阳性问题（包括CCNN、EEGNet和TSception模型）。通过将奇偶校验过滤器与特定于EEG的适应性相结合，这项工作填补了神经生理学模型知识产权保护方面的关键空白，并为医疗保健和生物识别应用提供了安全且不可篡改的解决方案。该框架对对抗修改的鲁棒性彰显出其在保护敏感的EEG模型同时保持诊断实用性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; EEG-based neural networks, pivotal in medical diagnosis and brain-computerinterfaces, face significant intellectual property (IP) risks due to theirreliance on sensitive neurophysiological data and resource-intensivedevelopment. Current watermarking methods, particularly those using abstracttrigger sets, lack robust authentication and fail to address the uniquechallenges of EEG models. This paper introduces a cryptographic wonderfilter-based watermarking framework tailored for EEG-based neural networks.Leveraging collision-resistant hashing and public-key encryption, the wonderfilter embeds the watermark during training, ensuring minimal distortion ($\leq5\%$ drop in EEG task accuracy) and high reliability (100\% watermarkdetection). The framework is rigorously evaluated against adversarial attacks,including fine-tuning, transfer learning, and neuron pruning. Resultsdemonstrate persistent watermark retention, with classification accuracy forwatermarked states remaining above 90\% even after aggressive pruning, whileprimary task performance degrades faster, deterring removal attempts. Piracyresistance is validated by the inability to embed secondary watermarks withoutsevere accuracy loss ( $&gt;10\%$ in EEGNet and CCNN models). Cryptographichashing ensures authentication, reducing brute-force attack successprobabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,TSception), the method achieves $&gt;99.4\%$ null-embedding accuracy, effectivelyeliminating false positives. By integrating wonder filters with EEG-specificadaptations, this work bridges a critical gap in IP protection forneurophysiological models, offering a secure, tamper-proof solution forhealthcare and biometric applications. The framework's robustness againstadversarial modifications underscores its potential to safeguard sensitive EEGmodels while maintaining diagnostic utility.</description>
      <author>example@mail.com (Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares)</author>
      <guid isPermaLink="false">2502.05931v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>RALLRec: Improving Retrieval Augmented Large Language Model Recommendation with Representation Learning</title>
      <link>http://arxiv.org/abs/2502.06101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TheWebConf'25 (WWW'25) as a Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法RALLRec，用于增强基于大型语言模型的推荐系统。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型已被集成到推荐系统中以提高用户行为理解。然而现有Retrieval Augmented Generation (RAG) 方法主要依赖文本语义，并且常常无法有效整合最相关的项目。&lt;h4&gt;目的&lt;/h4&gt;通过引入联合表示学习方法，增强基于大语言模型的推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的方法RALLRec，该方法首先通过提示大型语言模型生成更详细的项目描述来增强文本语义，然后结合由LLM和推荐模型提取的文本与协同语义进行共同表示学习。考虑到用户兴趣的时间变化特性，引入了一种简单有效的重排序方法以捕捉用户的偏好动态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该方法的有效性，并通过公开代码供其他研究者参考。&lt;h4&gt;结论&lt;/h4&gt;RALLRec为基于大型语言模型的推荐系统提供了一个新的解决方案，提高了系统的准确性和相关性的性能。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型已被整合到推荐系统中以增强对用户行为的理解。进一步将检索增强生成（Retrieval Augmented Generation, RAG）技术融入这些系统，以便检索更多相关的项目并提高系统性能。但是现有RAG方法主要依赖于文本语义，并经常无法有效整合最相关的内容，这限制了系统的有效性。在这篇论文中，我们提出了表示学习用于检索增强大型语言模型推荐（RALLRec）。具体而言，通过提示大模型生成更详细的描述来增强文本语义，随后进行文本和协同语义的联合表示学习，这些分别由LLM 和推荐模型提取。考虑到用户兴趣的时间变化特性，我们进一步引入了一种简单而有效的重排序方法以捕捉用户的偏好动态变化。我们在三个真实数据集上进行了广泛的实验，并通过评估结果验证了该方法的有效性。代码在https://github.com/JianXu95/RALLRec 公开发布供参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been integrated into recommendation systemsto enhance user behavior comprehension. The Retrieval Augmented Generation(RAG) technique is further incorporated into these systems to retrieve morerelevant items and improve system performance. However, existing RAG methodsrely primarily on textual semantics and often fail to incorporate the mostrelevant items, limiting the effectiveness of the systems.  In this paper, we propose Representation learning for retrieval-AugmentedLarge Language model Recommendation (RALLRec). Specifically, we enhance textualsemantics by prompting LLMs to generate more detailed item descriptions,followed by joint representation learning of textual and collaborativesemantics, which are extracted by the LLM and recommendation models,respectively. Considering the potential time-varying characteristics of userinterest, a simple yet effective reranking method is further introduced tocapture the dynamics of user preference. We conducted extensive experiments onthree real-world datasets, and the evaluation results validated theeffectiveness of our method. Code is made public athttps://github.com/JianXu95/RALLRec.</description>
      <author>example@mail.com (Jian Xu, Sichun Luo, Xiangyu Chen, Haoming Huang, Hanxu Hou, Linqi Song)</author>
      <guid isPermaLink="false">2502.06101v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Efficient AC Power Flow Prediction in Power Grids</title>
      <link>http://arxiv.org/abs/2502.05702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 6 figures, NeurIPS 2025,  https://github.com/Amirtalebi83/GNN-OptimalPowerFlow&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用图神经网络（GNN）解决电力系统交流潮流问题的创新方法。&lt;h4&gt;背景&lt;/h4&gt;交流最优潮流问题在降低发电成本的同时满足电网运营约束至关重要。传统的求解器难以处理大型系统的可扩展性，特别是在存在大量可再生能源源的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的方法来预测电力系统中的AC潮流解决方案，以应对传统方法在大规模复杂系统中面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;将电力网建模为一个图结构，其中节点代表电网的母线，边表示输电线路。研究了不同类型的GNN架构（包括GCN、GAT、SAGEConv和GraphConv），以实现高效的AC潮流预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于GNN的方法可以准确地预测交流功率流动解决方案，并且能够扩展到更大的系统，在计算时间上优于传统求解器。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了图神经网络在实时电网管理中的潜力，未来计划将模型应用于更大规模的电网系统中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文提出了一种新颖的方法，利用图神经网络（GNN）来解决电力网中的交流潮流问题。AC最优潮流对于降低发电成本同时满足电网操作约束至关重要。传统求解器在大型系统的可扩展性方面面临挑战，尤其是在存在大量可再生能源的情况下。我们的方法将电力系统建模为图形，其中母线是节点，输电线路是边。我们探索了不同类型的GNN架构，包括GCN、GAT、SAGEConv和GraphConv，以高效地预测交流潮流解决方案。我们在IEEE测试系统上的实验表明，GNN可以准确预测功率流解决方案，并能够扩展到更大的系统，在计算时间上优于传统求解器。这项工作强调了图神经网络在实时电网管理中的潜力，未来计划将模型应用于更大规模的电网中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel approach using Graph Neural Networks (GNNs) tosolve the AC Power Flow problem in power grids. AC OPF is essential forminimizing generation costs while meeting the operational constraints of thegrid. Traditional solvers struggle with scalability, especially in largesystems with renewable energy sources. Our approach models the power grid as agraph, where buses are nodes and transmission lines are edges. We exploredifferent GNN architectures, including GCN, GAT, SAGEConv, and GraphConv topredict AC power flow solutions efficiently. Our experiments on IEEE testsystems show that GNNs can accurately predict power flow solutions and scale tolarger systems, outperforming traditional solvers in terms of computation time.This work highlights the potential of GNNs for real-time power grid management,with future plans to apply the model to even larger grid systems.</description>
      <author>example@mail.com (Seyedamirhossein Talebi, Kaixiong Zhou)</author>
      <guid isPermaLink="false">2502.05702v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Target Speaker Lipreading by Audio-Visual Self-Distillation Pretraining and Speaker Adaptation</title>
      <link>http://arxiv.org/abs/2502.05758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to ESWA journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种改进的唇读技术，旨在解决现有模型在跨语言应用和特定说话人适应方面的问题，并通过结合唇部区域兴趣（ROI）和面部输入来提高模型性能。&lt;h4&gt;背景&lt;/h4&gt;基于多模态自蒸馏的自监督学习方法AV2vec在英语LRS3数据集上显示出了令人鼓舞的表现，但其训练成本高且非英语语言如中文缺乏足够的视听数据。此外，现有研究主要集中在说话者无关的唇读模型，难以处理不同说话者的风格差异。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文提出了一种综合方法，包括跨语言迁移学习、说话人适应策略和结合唇部ROI与面部输入的集成模型策略。&lt;h4&gt;方法&lt;/h4&gt;首先，研究了从源语言到目标语言的跨语言迁移学习；其次，提出了增强特定说话人的唇读准确性的说话人适应策略；最后，通过引入一种新的模型集成策略，将唇部ROI与面部输入相结合，大大提高了模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ChatCLR数据集的评估集中，该方法实现了77.3%的字符错误率（CER），比2024年中文唇读挑战赛的顶级结果更低。&lt;h4&gt;结论&lt;/h4&gt;所提出的改进方案有效提升了跨语言和特定说话人的唇读模型性能，并通过引入新的模型集成策略进一步优化了整体表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lipreading is an important technique for facilitating human-computerinteraction in noisy environments. Our previously developed self-supervisedlearning method, AV2vec, which leverages multimodal self-distillation, hasdemonstrated promising performance in speaker-independent lipreading on theEnglish LRS3 dataset. However, AV2vec faces challenges such as high trainingcosts and a potential scarcity of audio-visual data for lipreading in languagesother than English, such as Chinese. Additionally, most studies concentrate onspeakerindependent lipreading models, which struggle to account for thesubstantial variation in speaking styles across di?erent speakers. To addressthese issues, we propose a comprehensive approach. First, we investigatecross-lingual transfer learning, adapting a pre-trained AV2vec model from asource language and optimizing it for the lipreading task in a target language.Second, we enhance the accuracy of lipreading for specific target speakersthrough a speaker adaptation strategy, which is not extensively explored inprevious research. Third, after analyzing the complementary performance oflipreading with lip region-of-interest (ROI) and face inputs, we introduce amodel ensembling strategy that integrates both, signi?cantly boosting modelperformance. Our method achieved a character error rate (CER) of 77.3% on theevaluation set of the ChatCLR dataset, which is lower than the top result fromthe 2024 Chat-scenario Chinese Lipreading Challenge.</description>
      <author>example@mail.com (Jing-Xuan Zhang, Tingzhi Mao, Longjiang Guo, Jin Li, Lichen Zhang)</author>
      <guid isPermaLink="false">2502.05758v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Approximation of Visual Autoregressive Transformers</title>
      <link>http://arxiv.org/abs/2502.06167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了基于变压器的基础模型的理论极限，特别探讨了视觉自回归（VAR）变压器在图像生成中的作用和潜力。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的方法包括Diffusion Transformers。新的VAR Transformer框架通过一种新颖、可扩展且从粗到细的'下一尺度预测'方法，在图像合成任务中表现出卓越性能，并超过了所有先前的方法。&lt;h4&gt;目的&lt;/h4&gt;探讨单头VAR变压器在自注意力层和插值层上的通用性，证明它们可以作为任意图像到图像Lipschitz函数的泛化逼近器。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析和验证VAR Transformer在单一头部设置下的性能，并进一步展示流基自动回归Transformer继承了相似的近似能力。&lt;h4&gt;主要发现&lt;/h4&gt;证明简单的单头VAR变压器具有通用性，可以用于任意图像到图像Lipschitz函数的泛化逼近。此外还表明基于流动的自回归变压器也具备类似的近似能力。&lt;h4&gt;结论&lt;/h4&gt;研究成果为有效且计算效率高的VAR Transformer策略提供了重要的设计原则，并能进一步应用于更复杂的VAR模型在图像生成和相关领域的应用。&lt;h4&gt;翻译&lt;/h4&gt;我们探讨了基于变压器的基础模型的基本限制，扩展分析包括视觉自回归（VAR）变压器。VAR是使用新颖、可扩展的从粗到细“下一尺度预测”框架生成图像的重要步骤。这些模型设立了新的质量标准，在所有先前的方法中表现最佳，包括扩散变换器，并在图像合成任务中保持了最先进的性能。我们的主要贡献在于证明对于单头VAR变压器具有单一自注意力层和单一插值层的情况而言，VAR Transformer是通用的。从统计学的角度来看，我们证明了这样的简单VAR变压器可以作为任何图像到图像Lipschitz函数的泛化逼近器。此外，我们展示了流基自动回归变换器继承相似的近似能力。我们的结果为有效和计算效率高的VAR Transformer策略提供了重要的设计原则，这些策略可以用于扩展其在更复杂的VAR模型中的应用价值，在图像生成和其他相关领域中具有实用意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the fundamental limits of transformer-based foundation models,extending our analysis to include Visual Autoregressive (VAR) transformers. VARrepresents a big step toward generating images using a novel, scalable,coarse-to-fine ``next-scale prediction'' framework. These models set a newquality bar, outperforming all previous methods, including DiffusionTransformers, while having state-of-the-art performance for image synthesistasks. Our primary contributions establish that, for single-head VARtransformers with a single self-attention layer and single interpolation layer,the VAR Transformer is universal. From the statistical perspective, we provethat such simple VAR transformers are universal approximators for anyimage-to-image Lipschitz functions. Furthermore, we demonstrate that flow-basedautoregressive transformers inherit similar approximation capabilities. Ourresults provide important design principles for effective and computationallyefficient VAR Transformer strategies that can be used to extend their utilityto more sophisticated VAR models in image generation and other related areas.</description>
      <author>example@mail.com (Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song)</author>
      <guid isPermaLink="false">2502.06167v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Visual Representation Learning via Knowledge Distillation from Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2502.05766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to Pattern Recognition&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个基于语音基础模型（SFM）的跨模态知识蒸馏的方法，用于提升音频-视觉表示学习的能力。&lt;h4&gt;背景&lt;/h4&gt;多模态语音处理任务中，如唇读和音频-视觉语音识别，需要有效的音频-视觉表示学习。最近的研究表明，语音基础模型在各种与语音相关的任务中展现了强大的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;利用跨模态知识蒸馏方法从SFM中提取信息以增强多模态语音处理的能力。&lt;h4&gt;方法&lt;/h4&gt;将SFM作为教师模型，通过清洁音频输入获取其多层次的隐藏表示，并引入多教师集成方法对接收音频-视觉数据的学生模型进行训练。采用了新的表征知识蒸馏损失函数在预训练阶段和微调阶段均加以应用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在自动语音识别、视觉语音识别和音频-视觉语音识别任务上均取得了优于或至少可与现有最先进的基准方法相媲美的性能。同时进行了详尽的消融研究及学习表示图可视化以评估所提方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过跨模态知识蒸馏，从SFM中提取的知识能够显著提升音频-视觉表示模型在多模态语音任务上的表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual representation learning is crucial for advancing multimodalspeech processing tasks, such as lipreading and audio-visual speechrecognition. Recently, speech foundation models (SFMs) have shown remarkablegeneralization capabilities across various speech-related tasks. Building onthis progress, we propose an audio-visual representation learning model thatleverages cross-modal knowledge distillation from SFMs. In our method, SFMsserve as teachers, from which multi-layer hidden representations are extractedusing clean audio inputs. We also introduce a multi-teacher ensemble method todistill the student, which receives audio-visual data as inputs. A novelrepresentational knowledge distillation loss is employed to train the studentduring pretraining, which is also applied during finetuning to further enhancethe performance on downstream tasks. Our experiments utilized both aself-supervised SFM, WavLM, and a supervised SFM, iFLYTEK-speech. The resultsdemonstrated that our proposed method achieved superior or at least comparableperformance to previous state-of-the-art baselines across automatic speechrecognition, visual speech recognition, and audio-visual speech recognitiontasks. Additionally, comprehensive ablation studies and the visualization oflearned representations were conducted to evaluate the effectiveness of ourproposed method.</description>
      <author>example@mail.com (Jing-Xuan Zhang, Genshun Wan, Jianqing Gao, Zhen-Hua Ling)</author>
      <guid isPermaLink="false">2502.05766v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>NOMANet: A Graph Neural Network Enabled Power Allocation Scheme for NOMA</title>
      <link>http://arxiv.org/abs/2502.05592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的非正交多址接入（NOMA）网络功率分配方案。&lt;h4&gt;背景&lt;/h4&gt;在下行场景中，一个基站为多个用户通过多个子信道进行服务。由于可用子信道的数量少于用户的数量，因此一些用户必须共享同一个子信道。&lt;h4&gt;目的&lt;/h4&gt;旨在最大化系统的能源效率，并确保每个用户的速率要求和总体预算得以满足。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度学习的方法NOMA net（NOMANet）来解决上述问题。该网络采用图神经网络，将信道状态信息映射到所有子信道的功率分配方案上。通过多头注意机制和残差/密集连接增强了特征提取能力。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明，未经过监督训练的NOMANet实现了与连续凸逼近方法相近的表现，但其推理速度提高了约700倍。此外，NOMANet具有用户数量和子信道数量可扩展性的特点。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在性能和计算效率方面均表现优越，并且具备良好的可扩展性，能够应对不同规模的网络需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a graph neural network (GNN) enabled power allocationscheme for non-orthogonal multiple access (NOMA) networks. In particular, adownlink scenario with one base station serving multiple users over severalsubchannels is considered, where the number of subchannels is less than thenumber of users, and thus, some users have to share a subchannel via NOMA. Ourgoal is to maximize the system energy efficiency subject to the raterequirement of each user and the overall budget. We propose a deep learningbased approach termed NOMA net (NOMANet) to address the considered problem.Particularly, NOMANet is GNN-based, which maps channel state information to thedesired power allocation scheme for all subchannels. The multi-head attentionand the residual/dense connection are adopted to enhance the featureextraction. The output of NOMANet is guaranteed to be feasible via thecustomized activation function and the penalty method. Numerical results showthat NOMANet trained unsupervised achieves performance close to that of thesuccessive convex approximation method but with a faster inference speed byabout $700$ times. Besides, NOMANet is featured by its scalability to bothusers and subchannels.</description>
      <author>example@mail.com (Yipu Hou, Yang Lu, Wei Chen, Bo Ai, Dusit Niyato, Zhiguo Ding)</author>
      <guid isPermaLink="false">2502.05592v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Coalition Formation for Heterogeneous Federated Learning Enabled Channel Estimation in RIS-assisted Cell-free MIMO</title>
      <link>http://arxiv.org/abs/2502.05538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于联盟形成的异构联邦学习框架，用于解决重配置智能表面辅助的非蜂窝多输入多输出通信系统中的下行链路信道估计问题。&lt;h4&gt;背景&lt;/h4&gt;传统的信道估计算法主要依赖于集中式的深度学习方法来处理高维和复杂的级联信道。这些算法需要所有用户的数据进行集中式模型训练，导致了过高的通信开销和显著的隐私问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架以解决上述挑战，该框架通过利用联盟形成来指导异构联邦学习用户组的形成，从而实现有效的信道估计。&lt;h4&gt;方法&lt;/h4&gt;引入了一种分布式深度强化学习（DRL）方法，使每个联邦学习用户能够智能地独立决定是否加入或离开一个联盟。此外，为加速DRL-FL收敛过程和减轻终端用户的计算负担，还提出了一种转移学习方法。&lt;h4&gt;主要发现&lt;/h4&gt;与基准相比，所提出的框架在减少终端用户的计算开销方面表现出16%的显著改善，并提高了数据隐私性和20%的信道估计准确性。&lt;h4&gt;结论&lt;/h4&gt;通过使用基于联盟形成的异构联邦学习框架，在保持或提高信道估计精度的同时，可以有效降低通信开销和保护用户隐私。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Downlink channel estimation remains a significant bottleneck inreconfigurable intelligent surface-assisted cell-free multiple-inputmultiple-output communication systems. Conventional approaches primarily relyon centralized deep learning methods to estimate the high-dimensional andcomplex cascaded channels. These methods require data aggregation from allusers for centralized model training, leading to excessive communicationoverhead and significant data privacy concerns. Additionally, the large size oflocal learning models imposes heavy computational demands on end users,necessitating strong computational capabilities that most commercial deviceslack. To address the aforementioned challenges, a coalition-formation-guidedheterogeneous federated learning (FL) framework is proposed. This frameworkleverages coalition formation to guide the formation of heterogeneous FL usergroups for efficient channel estimation. Specifically, by utilizing adistributed deep reinforcement learning (DRL) approach, each FL userintelligently and independently decides whether to join or leave a coalition,aiming at improving channel estimation accuracy, while reducing local modelsize and computational costs for end users. Moreover, to accelerate the DRL-FLconvergence process and reduce computational burdens on end users, a transferlearning method is introduced. This method incorporates both received referencesignal power and distance similarity metrics, by considering that nodes withsimilar distances to the base station and comparable received signal power havea strong likelihood of experiencing similar channel fading. Massive experimentsperformed that reveal that, compared with the benchmarks, the proposedframework significantly reduces the computational overhead of end users by 16%,improves data privacy, and improves channel estimation accuracy by 20%.</description>
      <author>example@mail.com (Nan Qi, Haoxuan Liu, Theodoros A. Tsiftsis, Alexandros-Apostolos A. Boulogeorgos, Fuhui Zhou, Shi Jin, Qihui Wu)</author>
      <guid isPermaLink="false">2502.05538v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model of Electronic Medical Records for Adaptive Risk Estimation</title>
      <link>http://arxiv.org/abs/2502.06124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ETHOS是一种基于Transformer架构的AI模型，用于预测患者健康时间线（PHT）。ARES系统利用ETHOS来计算个性化和动态的风险概率，并且提供了个人解释模块以识别影响风险评估的关键临床因素。&lt;h4&gt;背景&lt;/h4&gt;传统的预警系统在预测医院入院、重症监护病房（ICU）入院和住院延长等方面存在局限性，需要一种能够提供实时、个性化的风险估计的模型来改进这些系统的性能。&lt;h4&gt;目的&lt;/h4&gt;开发ETHOS模型以改善患者健康时间线的预测，并通过ARES系统将该模型应用于临床决策支持，提高对患者的诊断信任度。&lt;h4&gt;方法&lt;/h4&gt;利用MIMIC-IV v2.2数据集，在急诊科环境中评估了ETHOS和ARES系统的性能。处理后的数据包括来自超过299,721名独特患者的数据，转换为285,622条PHT记录。&lt;h4&gt;主要发现&lt;/h4&gt;ETHOS在预测医院入院、ICU入院和住院延长方面优于基准模型，并且其风险估计的个性化解释模块能提供有助于临床决策的支持信息。&lt;h4&gt;结论&lt;/h4&gt;ARES系统，基于ETHOS模型，为实时个性化风险评估提供了强大工具，增强了医生对模型的信任。该系统的灵活性和准确性使其成为临床上具有变革性的工具。&lt;h4&gt;翻译&lt;/h4&gt;我们开发了增强型变换器健康结果模拟（ETHOS），这是一个AI模型，它从电子病历中获取患者健康时间线(PHT)并通过转换架构来预测未来的PHT。ARES利用ETHOS计算个性化且动态的风险概率，并包括一个解释模块以识别影响个人风险评估的关键临床因素。在MIMIC-IV v2.2数据集的急诊科环境中，评价了该系统的性能并将其与传统的早期预警系统和机器学习模型进行了比较。我们处理了超过299,721个独特患者的数据为PHTs，其中60%包括住院记录，并包含3亿5千多万个标记。ETHOS在预测医院入院、ICU入院以及长时间住院方面优于基准模型，并实现了优异的AUC分数。基于ETHOS的风险评估显示了良好的鲁棒性，并通过校准曲线得到了验证。个性化解释模块提供了有助于临床决策的支持信息，表明其为患者特定风险因素提供见解。ARES系统提高了预测健康AI在动态、实时和个性化风险估计方面的功能，通过提供个性化的解释来增强医生的信任度。该系统的灵活性及其准确性使其成为临床决策支持中具有变革性的工具，有可能改善急诊科和住院患者的治疗结果及资源分配。我们将在github.com/ipolharvard/ethos-ares公开完整代码以促进未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOSpredicts future PHTs using transformer-based architectures. The Adaptive RiskEstimation System (ARES) employs ETHOS to compute dynamic and personalized riskprobabilities for clinician-defined critical events. ARES incorporates apersonalized explainability module that identifies key clinical factorsinfluencing risk estimates for individual patients. ARES was evaluated on theMIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking itsperformance against traditional early warning systems and machine learningmodels. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,with 60% including hospital admissions. The dataset contained over 357 milliontokens. ETHOS outperformed benchmark models in predicting hospital admissions,ICU admissions, and prolonged hospital stays, achieving superior AUC scores.ETHOS-based risk estimates demonstrated robustness across demographic subgroupswith strong model reliability, confirmed via calibration curves. Thepersonalized explainability module provides insights into patient-specificfactors contributing to risk. ARES, powered by ETHOS, advances predictivehealthcare AI by providing dynamic, real-time, and personalized risk estimationwith patient-specific explainability to enhance clinician trust. Itsadaptability and superior accuracy position it as a transformative tool forclinical decision-making, potentially improving patient outcomes and resourceallocation in emergency and inpatient settings. We release the full code atgithub.com/ipolharvard/ethos-ares to facilitate future research.</description>
      <author>example@mail.com (Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek)</author>
      <guid isPermaLink="false">2502.06124v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Robust Deep Signed Graph Clustering via Weak Balance Theory</title>
      <link>http://arxiv.org/abs/2502.05472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by WWW25 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为DSGC的深度正负图聚类框架，旨在解决现有技术在噪声处理和社区结构边界划分方面的不足。&lt;h4&gt;背景&lt;/h4&gt;签名图聚类用于探索既有积极关系也有消极关系的社会网络中的社区结构。当前面临的主要挑战是现有的光谱方法对噪声非常敏感以及主流签名图神经网络中受Social Balance Theory影响的‘敌人的敌人就是我的朋友’原则导致群组边界狭窄或中断。&lt;h4&gt;目的&lt;/h4&gt;通过引入Weak Balance理论，提高预处理和编码过程以实现更稳健的表现学习。&lt;h4&gt;方法&lt;/h4&gt;DSGC框架包括Violation Sign-Refine（用高阶邻居信息纠正噪声边）和Density-based Augmentation（根据弱平衡原则在群内添加正边，在群间添加负边），并开发了签名神经网络来强调负面连接节点之间的区别，最后通过最小化正则聚类损失优化聚类分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明DSGC框架在合成和真实数据集上均显著优于所有基线方法，确立了新的性能基准。&lt;h4&gt;结论&lt;/h4&gt;本文提出的DSGC框架有效解决了现有签名图聚类算法中的噪声问题，并且更好地保持了社区结构的边界，从而提高了聚类质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：正负图聚类是发现同时具有积极和消极关系的社会网络中社区结构的关键技术。我们识别出该领域面临的两个主要挑战：i) 当前的光谱方法在实际场景中的噪声普遍存在时非常脆弱；ii) 由Social Balance Theory衍生的‘敌人的敌人就是我的朋友’原则往往限制或打断主流签名图神经网络中的群边界划分。为解决这些挑战，我们提出了一种名为DSGC（Deep Signed Graph Clustering）的框架，该框架利用Weak Balance理论增强预处理和编码过程以实现稳健的表现学习。首先，DSGC引入Violation Sign-Refine算法通过使用高阶邻居信息来纠正噪声边对正负网络进行去噪。随后，基于密度的增强技术通过在群内添加正边以及在不同群之间添加负边来加强语义结构，并遵循弱平衡原则。框架利用弱平衡原则开发了以聚类为导向的签名神经网络，通过强调负面连接节点之间的区别来拓宽群边界。最后，DSGC通过最小化一个正则化的聚类损失来进行最佳分配优化。合成和真实数据集上的综合实验显示DSGC始终优于所有基线方法，确立了一项新的基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714915&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Signed graph clustering is a critical technique for discovering communitystructures in graphs that exhibit both positive and negative relationships. Wehave identified two significant challenges in this domain: i) existing signedspectral methods are highly vulnerable to noise, which is prevalent inreal-world scenarios; ii) the guiding principle ``an enemy of my enemy is myfriend'', rooted in \textit{Social Balance Theory}, often narrows or disruptscluster boundaries in mainstream signed graph neural networks. Addressing thesechallenges, we propose the \underline{D}eep \underline{S}igned\underline{G}raph \underline{C}lustering framework (DSGC), which leverages\textit{Weak Balance Theory} to enhance preprocessing and encoding for robustrepresentation learning. First, DSGC introduces Violation Sign-Refine todenoise the signed network by correcting noisy edges with high-order neighborinformation. Subsequently, Density-based Augmentation enhances semanticstructures by adding positive edges within clusters and negative edges acrossclusters, following \textit{Weak Balance} principles. The framework thenutilizes \textit{Weak Balance} principles to develop clustering-oriented signedneural networks to broaden cluster boundaries by emphasizing distinctionsbetween negatively linked nodes. Finally, DSGC optimizes clustering assignmentsby minimizing a regularized clustering loss. Comprehensive experiments onsynthetic and real-world datasets demonstrate DSGC consistently outperforms allbaselines, establishing a new benchmark in signed graph clustering.</description>
      <author>example@mail.com (Peiyao Zhao, Xin Li, Zeyu Zhang, Mingzhong Wang, Xueying Zhu, Lejian Liao)</author>
      <guid isPermaLink="false">2502.05472v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Calibrated Unsupervised Anomaly Detection in Multivariate Time-series using Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.03245v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication and presentation at the  2025 IEEE International systems Conference (SysCon)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用强化学习在自编码器潜在空间中的无监督异常检测方法，特别是在多变量时间序列数据中。提出了一种利用小波分析增强异常检测的新策略。&lt;h4&gt;背景&lt;/h4&gt;对于无监督异常检测的一个重要挑战在于缺乏足够的异常样本数据，这导致模型难以区分正常事件与异常事件，并产生大量的假阴性错误。&lt;h4&gt;目的&lt;/h4&gt;通过强化学习在训练过程中促进探索和开发的平衡，防止过拟合并提高模型性能。同时利用小波分析来捕捉不同时间分辨率下的细微变化，提升检测精度。&lt;h4&gt;方法&lt;/h4&gt;引入了自编码器潜在空间中的强化学习机制，并结合生成合成异常数据的方法调整决策边界。此外还嵌入了一套监督框架以辅助无监督学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过小波系数捕捉到的数据突变与细微变化可以显著提高检测精度，而采用合成异常样本校准模型的决策边界，则有助于进一步明确正常模式和异常模式之间的界限。&lt;h4&gt;结论&lt;/h4&gt;利用强化学习与小波分析结合的方法能够有效克服无监督异常检测中的难题，提高算法在实际应用中的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;该论文研究了使用自编码器潜在空间中强化学习（RL）的多变量时间序列数据无监督异常检测方法。一个显著挑战是缺乏异常样本数据，这可能导致将异常误判为正常事件，从而增加假阴性的数量。RL可以通过促进探索和在训练过程中平衡利用来克服这一限制，并有效防止过拟合。此外还采用了小波分析以增强异常检测能力，通过将其时间序列分解成时间和频率域，能够捕捉到多个分辨率下的异常情况，提取的小波系数可用于检测数据中的突然变化及微小波动，从而优化异常检测过程。最后，我们通过生成合成异常样本并嵌入监督框架来校准决策边界，这种监督组件有助于无监督学习过程中细化决策边界，并提高模型区分正常模式和异常模式的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates unsupervised anomaly detection in multivariatetime-series data using reinforcement learning (RL) in the latent space of anautoencoder. A significant challenge is the limited availability of anomalousdata, often leading to misclassifying anomalies as normal events, thus raisingfalse negatives. RL can help overcome this limitation by promoting explorationand balancing exploitation during training, effectively preventing overfitting.Wavelet analysis is also utilized to enhance anomaly detection, enablingtime-series data decomposition into both time and frequency domains. Thisapproach captures anomalies at multiple resolutions, with wavelet coefficientsextracted to detect both sudden and subtle shifts in the data, thereby refiningthe anomaly detection process. We calibrate the decision boundary by generatingsynthetic anomalies and embedding a supervised framework within the model. Thissupervised element aids the unsupervised learning process by fine-tuning thedecision boundary and increasing the model's capacity to distinguish betweennormal and anomalous patterns effectively.</description>
      <author>example@mail.com (Saba Sanami, Amir G. Aghdam)</author>
      <guid isPermaLink="false">2502.03245v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science</title>
      <link>http://arxiv.org/abs/2502.06084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合预训练机器学习模型和基于物理的模型的新型框架，旨在提高复杂系统中多个耦合过程建模的效果。&lt;h4&gt;背景&lt;/h4&gt;现有的物理引导型机器学习方法主要适用于孤立且相对简单的任务，难以应对包含多个相互作用进程及大量影响特征的复杂科学体系。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时利用预训练ML模型和基于物理模型优势的新框架，以增强在多耦合过程中的建模能力。&lt;h4&gt;方法&lt;/h4&gt;构建了一个模拟环境系统，并采用基于物理的模型生成各种影响因素和变量。在此基础上进行预训练，之后使用真实观测数据对特定任务进行微调，同时保持与已知物理学原理（如质量守恒和能量守恒原则）的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的PGFM框架在现实湖泊中的水温及溶解氧动态建模中表现出有效性，并且具有广泛的应用前景，尤其是在那些使用基于物理模型的科学领域内。&lt;h4&gt;结论&lt;/h4&gt;通过将预训练ML模型与基于物理的模型相结合的方式可以有效改善复杂系统中多个耦合过程的建模精度和效率。&lt;h4&gt;翻译&lt;/h4&gt;物理学指导型机器学习(PGML)方法因其能够整合科学理论以增强机器学习模型而被用于科学研究。然而，大多数PGML方法仅适用于孤立且简单的任务，限制了它们在包含多进程互作及大量影响因子复杂体系中的应用能力。本文提出了一种物理引导型基础模型(PGFM)，它结合预训练的机器学习模型和基于物理学的模型，并利用这些模型的优势来改进多个耦合过程建模效果。为了有效进行预训练，我们构建了一个包含各种影响因素和变量(由基于物理的模型生成)模拟环境体系。该模型在这一系统中通过多任务目标引导下适应性选择重要的特征交互完成预训练，在特定的任务中使用真实观察值对模型微调，并保持与质量守恒及能量守恒等已确立的物理学原理的一致性。我们展示了这种建模方法在现实世界湖泊中的水温及溶解氧动态预测中的有效性，所提出的PGFM同样适用于广泛采用基于物理模型的研究领域内。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-guided machine learning (PGML) has become a prevalent approach instudying scientific systems due to its ability to integrate scientific theoriesfor enhancing machine learning (ML) models. However, most PGML approaches aretailored to isolated and relatively simple tasks, which limits theirapplicability to complex systems involving multiple interacting processes andnumerous influencing features. In this paper, we propose a\textit{\textbf{P}hysics-\textbf{G}uided \textbf{F}oundation \textbf{M}odel(\textbf{PGFM})} that combines pre-trained ML models and physics-based modelsand leverages their complementary strengths to improve the modeling of multiplecoupled processes. To effectively conduct pre-training, we construct asimulated environmental system that encompasses a wide range of influencingfeatures and various simulated variables generated by physics-based models. Themodel is pre-trained in this system to adaptively select important featureinteractions guided by multi-task objectives. We then fine-tune the model foreach specific task using true observations, while maintaining consistency withestablished physical theories, such as the principles of mass and energyconservation. We demonstrate the effectiveness of this methodology in modelingwater temperature and dissolved oxygen dynamics in real-world lakes. Theproposed PGFM is also broadly applicable to a range of scientific fields wherephysics-based models are being used.</description>
      <author>example@mail.com (Runlong Yu, Chonghao Qiu, Robert Ladwig, Paul Hanson, Yiqun Xie, Xiaowei Jia)</author>
      <guid isPermaLink="false">2502.06084v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Enabled Pinching Antennas</title>
      <link>http://arxiv.org/abs/2502.05447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了图神经网络（GNN）在夹钳天线系统中用于同时优化天线布局和功率分配的传输设计。通过将配备有夹钳天线的下行通信系统建模为一个二分图，并提出了一种基于图注意力网络（GAT）的方法，称为BGAT模型来解决能效最大化的优化问题。&lt;h4&gt;背景&lt;/h4&gt;夹钳天线技术是一种新型柔性天线技术，它不仅能够对抗大规模路径损耗，还能灵活地重新配置天线阵列。该技术通过在任意长度的波导上应用小尺寸介电粒子，在靠近用户的位置布置天线以避免显著的大规模路径损耗。&lt;h4&gt;目的&lt;/h4&gt;研究基于图神经网络（GNN）的方法来同时优化夹钳天线系统的布局和功率分配，从而提高能量效率（EE）。&lt;h4&gt;方法&lt;/h4&gt;将装有夹钳天线的下行通信系统建模为二分图，并提出了一个称为BGAT（双图注意力网络）的新模型，该模型基于图注意力网络，以解决能效最大化问题。利用定制化的读取过程确保了可行解并促进无监督训练。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明夹钳天线系统在提高能源效率方面和所提出的BGAT模型的优越性、可扩展性和计算效率方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究通过引入基于图神经网络的方法，为夹钳天线系统的优化提供了一种新的有效途径，并验证了其潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pinching-antenna system is a novel flexible-antenna technology, which hasthe capabilities not only to combat large-scale path loss, but also toreconfigure the antenna array in a flexible manner. The key idea of pinchingantennas is to apply small dielectric particles on a waveguide of arbitrarylength, so that they can be positioned close to users to avoid significantlarge-scale path loss. This paper investigates the graph neural network (GNN)enabled transmit design for the joint optimization of antenna placement andpower allocation in pinching-antenna systems. We formulate the downlinkcommunication system equipped with pinching antennas as a bipartite graph, andpropose a graph attention network (GAT) based model, termed bipartite GAT(BGAT), to solve an energy efficiency (EE) maximization problem. With thetailored readout processes, the BGAT guarantees a feasible solution, which alsofacilitates the unsupervised training. Numerical results demonstrate theeffectiveness of pinching antennas in enhancing the system EE as well as theproposed BGAT in terms of optimality, scalability and computational efficiency.</description>
      <author>example@mail.com (Xinke Xie, Yang Lu, Zhiguo Ding)</author>
      <guid isPermaLink="false">2502.05447v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Latent Structure Modulation in Large Language Models Through Stochastic Concept Embedding Transitions</title>
      <link>http://arxiv.org/abs/2502.05553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于概率机制动态调整词元表示的框架，用于改进语言模型在推理阶段的表现。&lt;h4&gt;背景&lt;/h4&gt;静态或确定性的词嵌入限制了模型处理复杂语境的能力。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的转换框架，通过概率更新使每个词元嵌入能够适应性地改变，同时保持其意义的一致性和完整性。&lt;h4&gt;方法&lt;/h4&gt;在提出的框架中，词元的表示根据上下文进行动态的概率调整。实验表明这种方法提高了模型词汇多样性、生成一致性和低频词汇保留能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过统计分析显示，基于概率机制的方法能够更灵活地改变嵌入表示且不会丧失连贯性；同时，这种框架在文本完成准确性、对话一致性以及结构复杂度上有显著改进。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，引入的概率机制虽带来轻微的计算开销，但在保持生成效率的同时提高了表达能力。此外，概率更新保留了语义分组并支持上下文驱动的变化，进一步验证了该转换机制的有效性和稳定性。&lt;h4&gt;翻译&lt;/h4&gt;随机嵌入转移通过动态调整词元表示来引入一种概率机制，以此缓解静态或确定性嵌入施加的限制。提出的转换框架中每个词元嵌入通过概率更新演变，确保适应性的同时保持语义完整性。实证评估表明，包含随机过渡的模型词汇多样性更高、生成一致性更好以及低频词汇保留能力更强，这导致了更丰富的句法结构和减少对高概率选择的依赖。跨变压器层的嵌入漂移统计分析显示表示演化更加灵活且不失连贯性，支持受控随机性有助于上下文敏感表示学习的观点。实验结果表明，引入的概率嵌入带来了轻微计算开销但保持生成效率，进一步证实其在大规模应用中的可行性。与传统嵌入方法进行比较的研究强调了文本完成准确性、对话一致性和结构复杂度的可测量改进，确认了随机过渡增强表达能力的有效性。聚类模式显示概率更新保留有意义的语义组同时支持上下文驱动的变化，进一步验证转换机制的稳定性。性能指标表明，随机过渡平衡适应性与控制，确保生成输出在无过度随机化的前提下保持语言连贯性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stochastic embedding transitions introduce a probabilistic mechanism foradjusting token representations dynamically during inference, mitigating theconstraints imposed through static or deterministic embeddings. A transitionframework was proposed in which each token embedding evolved throughprobabilistic updates, ensuring adaptability while preserving semanticintegrity across linguistic contexts. Empirical evaluations demonstrated thatmodels incorporating stochastic transitions exhibited greater lexicaldiversity, improved generative coherence, and enhanced retention oflow-frequency vocabulary, contributing to more varied sentence structures andreduced reliance on high-probability token selections. Statistical analyses ofembedding drift across transformer layers indicated that representationsevolved more flexibly without losing coherence, supporting the hypothesis thatcontrolled stochasticity facilitated context-sensitive representation learning.Experimental results revealed that probabilistic embeddings introduced minorcomputational overhead while maintaining generative efficiency, reinforcingtheir feasibility in large-scale applications. A comparative study withtraditional embedding approaches highlighted measurable gains in textcompletion accuracy, dialogue coherence, and structural complexity, confirmingthe effectiveness of stochastic transitions in enhancing representationexpressiveness. Clustering patterns in the embedding space suggested thatprobabilistic updates preserved meaningful semantic groupings while enablingcontext-driven shifts, further validating the stability of the transitionmechanism. Performance metrics indicated that stochastic transitions balancedadaptability and control, ensuring that generative outputs remainedlinguistically coherent without excessive randomness.</description>
      <author>example@mail.com (Stefan Whitaker, Colin Sisate, Marcel Windsor, Nikolai Fairweather, Tarquin Goldborough, Oskar Lindenfeld)</author>
      <guid isPermaLink="false">2502.05553v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Forgetting during Finetuning with Pretraining Data Injection</title>
      <link>http://arxiv.org/abs/2502.06042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 15 figures, preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了通过微调预训练模型来提升特定领域性能的方法，并研究了在目标数据有限和模型规模变化时，如何量化过度拟合和知识遗忘的现象。&lt;h4&gt;背景&lt;/h4&gt;为了使语言模型更好地适应特定领域的任务，通常的做法是使用从该领域获取的数据对预训练模型进行微调。然而，在实践中由于目标数据量的限制，这种策略往往会导致模型快速过拟合或忘记之前学到的知识。&lt;h4&gt;目的&lt;/h4&gt;量化在不同规模的目标域、可用目标数据数量和模型大小下，过度拟合与知识遗忘的现象，并研究将少量预训练数据注入微调数据集中的方法以防止知识遗忘并减轻过拟合问题。&lt;h4&gt;方法&lt;/h4&gt;通过测量向微调数据集中加入一定比例的预训练数据对避免遗忘和减少过拟合的效果来推导出相应的缩放法则。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，即使在目标数据混合物中只包含1%的预训练数据，也足以防止模型忘记原预训练数据集中的知识。&lt;h4&gt;结论&lt;/h4&gt;通过加入少量的预训练数据到微调过程中，可以有效解决过度拟合和知识遗忘问题，从而提高模型在特定领域任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;一种广泛采用的方法是通过对目标领域的无监督下文预测进行微调以获得适用于该领域的语言模型。然而，这种方法面临两个挑战：一是当目标数据量有限时会导致快速过拟合；二是模型会偏离原始的预训练状态，忘记预训练过程中获取的知识和通用知识。本文旨在为不同规模的目标域、可用目标数据数量以及不同的模型大小推导出量化这两类现象的缩放法则，并研究将少量预训练数据注入微调数据中的效果。实验表明，向微调数据集中加入1%的预训练数据可以有效防止遗忘原预训练集的知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A widespread strategy to obtain a language model that performs well on atarget domain is to finetune a pretrained model to perform unsupervisednext-token prediction on data from that target domain. Finetuning presents twochallenges: (i) if the amount of target data is limited, as in most practicalapplications, the model will quickly overfit, and (ii) the model will driftaway from the original model, forgetting the pretraining data and the genericknowledge that comes with it. We aim to derive scaling laws that quantify thesetwo phenomena for various target domains, amounts of available target data, andmodel scales. We measure the efficiency of injecting pretraining data into thefinetuning data mixture to avoid forgetting and mitigate overfitting. A keypractical takeaway from our study is that injecting as little as 1% ofpretraining data in the finetuning data mixture prevents the model fromforgetting the pretraining set.</description>
      <author>example@mail.com (Louis Bethune, David Grangier, Dan Busbridge, Eleonora Gualdoni, Marco Cuturi, Pierre Ablin)</author>
      <guid isPermaLink="false">2502.06042v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>LRA-GNN: Latent Relation-Aware Graph Neural Network with Initial and Dynamic Residual for Facial Age Estimation</title>
      <link>http://arxiv.org/abs/2502.05423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于图神经网络的方法，用于人脸的综合表示和年龄估计。&lt;h4&gt;背景&lt;/h4&gt;脸部信息集中在面部关键点上，前沿研究开始使用图神经网络将面部分割成节点来建模复杂的面部表示。但是这些方法构建节点与节点之间的关系时依赖于相似性阈值，从而导致一些潜在的关系被忽略。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的带有初始和动态残差的潜在线条感知图神经网络（LRA-GNN），以实现稳健且综合的人脸表示。&lt;h4&gt;方法&lt;/h4&gt;首先使用面部关键点作为先验知识构建一个初始图，并通过随机游走策略获取全局结构，这些步骤共同指导后续的有效探索和全面表达。然后利用多注意机制捕捉潜在的关系并基于上述指导生成包含丰富面部信息和完整结构的全连接图。为了避免在全连接图上提取深层特征时过度平滑问题，精心设计了深度残差图卷积网络以融合自适应初始残差和动态发展残差。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够避免深度学习模型中常见的过度平滑问题，并通过逐步强化学习优化集成分类回归器来提高年龄估计的精度和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在几个年龄估计基准上超过了最先进的基线，展示了其力量和有效性。&lt;h4&gt;翻译&lt;/h4&gt;面部信息主要集中在面部关键点上。前沿研究开始使用图神经网络将面部分割成节点以建模复杂的面部表示。然而这些方法基于相似性阈值构建节点与节点之间的关系，因此一些潜在的关系被忽略了。这些潜在的关系对于深度语义的人脸老化表示至关重要。我们提出了一种新的带有初始和动态残差的潜在线条感知图神经网络（LRA-GNN）以实现稳健且综合的人脸表示。具体来说，首先使用面部关键点作为先验知识构建一个初始图，并通过随机游走策略获取全局结构，这些步骤共同指导后续的有效探索和全面表达。然后 LRA-GNN 利用多注意机制捕捉潜在的关系并基于上述指导生成包含丰富面部信息和完整结构的全连接图。为了防止在全连接图上提取深层特征时过度平滑问题，精心设计了深度残差图卷积网络以融合自适应初始残差和动态发展残差确保信息的一致性和多样性。最后，为提高年龄估计精度和泛化能力，提出逐步强化学习来优化集成分类回归器。我们所提出的框架在几个年龄估计基准上超过了最先进的基线，展示了其力量和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face information is mainly concentrated among facial key points, and frontierresearch has begun to use graph neural networks to segment faces into patchesas nodes to model complex face representations. However, these methodsconstruct node-to-node relations based on similarity thresholds, so there is aproblem that some latent relations are missing. These latent relations arecrucial for deep semantic representation of face aging. In this novel, wepropose a new Latent Relation-Aware Graph Neural Network with Initial andDynamic Residual (LRA-GNN) to achieve robust and comprehensive facialrepresentation. Specifically, we first construct an initial graph utilizingfacial key points as prior knowledge, and then a random walk strategy isemployed to the initial graph for obtaining the global structure, both of whichtogether guide the subsequent effective exploration and comprehensiverepresentation. Then LRA-GNN leverages the multi-attention mechanism to capturethe latent relations and generates a set of fully connected graphs containingrich facial information and complete structure based on the aforementionedguidance. To avoid over-smoothing issues for deep feature extraction on thefully connected graphs, the deep residual graph convolutional networks arecarefully designed, which fuse adaptive initial residuals and dynamicdevelopmental residuals to ensure the consistency and diversity of information.Finally, to improve the estimation accuracy and generalization ability,progressive reinforcement learning is proposed to optimize the ensembleclassification regressor. Our proposed framework surpasses the state-of-the-artbaselines on several age estimation benchmarks, demonstrating its strength andeffectiveness.</description>
      <author>example@mail.com (Yiping Zhang, Yuntao Shou, Wei Ai, Tao Meng, Keqin Li)</author>
      <guid isPermaLink="false">2502.05423v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models</title>
      <link>http://arxiv.org/abs/2502.06039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 2025 IEEE/ACM Second International Conference on AI  Foundation Models and Software Engineering (Forge 2025). 10 pages, 7 figures,  5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了提示工程在减少大型语言模型生成代码中的安全漏洞方面的有效性，并通过基准测试评估不同提示策略的效果。&lt;h4&gt;背景&lt;/h4&gt;当前，虽然提示工程技术被用于改善大语言模型的推理错误，但其对减轻这些模型生成代码的安全性脆弱性的效果尚未充分探究。&lt;h4&gt;目的&lt;/h4&gt;填补这一研究空白，建立一个自动化评估系统来衡量不同的提示工程策略对于提高代码安全性的效果。&lt;h4&gt;方法&lt;/h4&gt;该基准测试利用了两个经过同行评审的提示数据集，并使用静态扫描器在大规模范围内评估代码安全性。此外，还在GPT-3.5-turbo、GPT-4o和GPT-4o-mini上测试了多种提示工程技巧。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在GPT-4o和GPT-4o-mini模型中，采用安全导向的提示前缀可以将代码中的安全漏洞减少多达56%。同时，使用迭代提示技术时，所有被测模型都能检测并修复先前生成代码中41.9%-68.7%的安全问题。&lt;h4&gt;结论&lt;/h4&gt;提出了一种“提示代理”的概念，展示了如何在实际开发工作流程中应用最有效的技巧来提高代码安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了研究背景、目的、方法和主要发现，并提出了‘提示代理’的概念。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompt engineering reduces reasoning mistakes in Large Language Models(LLMs). However, its effectiveness in mitigating vulnerabilities inLLM-generated code remains underexplored. To address this gap, we implemented abenchmark to automatically assess the impact of various prompt engineeringstrategies on code security. Our benchmark leverages two peer-reviewed promptdatasets and employs static scanners to evaluate code security at scale. Wetested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, andGPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, asecurity-focused prompt prefix can reduce the occurrence of securityvulnerabilities by up to 56%. Additionally, all tested models demonstrated theability to detect and repair between 41.9% and 68.7% of vulnerabilities inpreviously generated code when using iterative prompting techniques. Finally,we introduce a "prompt agent" that demonstrates how the most effectivetechniques can be applied in real-world development workflows.</description>
      <author>example@mail.com (Marc Bruni, Fabio Gabrielli, Mohammad Ghafari, Martin Kropp)</author>
      <guid isPermaLink="false">2502.06039v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints</title>
      <link>http://arxiv.org/abs/2502.05414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了GAMIC技术，该技术结合了图神经网络和分子描述符，以优化大规模语言模型在分子任务中的上下文学习性能。&lt;h4&gt;背景&lt;/h4&gt;目前的提示检索方法主要依赖于局部特征相似性，如Morgan指纹，这无法充分捕捉到全局分子结构及其原子键合关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习技术GAMIC，以更好地表示和理解分子复杂结构，并优化小至中等规模的语言模型在特定任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络表示的全局分子结构与文本描述进行对齐，并通过Morgan指纹实现局部特征相似性检索；引入了基于最大边际相关性的多样性启发法以优化提示样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GAMIC在所有任务上均超越了简单的基于Morgan指纹的上下文学习方法，性能提升最高可达45%。&lt;h4&gt;结论&lt;/h4&gt;GAMIC为分子领域的上下文学习提供了一种有效的方法，特别是在小至中等规模的语言模型中的应用展示了潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何通过引入GAMIC技术来改善大规模语言模型在处理分子任务时的表现，特别是通过结合图神经网络和文本描述，以及利用Morgan指纹来检索特征相似性。该方法提高了输入提示样本的多样性，并且实验结果表明其性能显著优于现有的基于局部特征的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-context learning (ICL) effectively conditions large language models (LLMs)for molecular tasks, such as property prediction and molecule captioning, byembedding carefully selected demonstration examples into the input prompt. Thisapproach avoids the computational overhead of extensive pertaining andfine-tuning. However, current prompt retrieval methods for molecular tasks haverelied on molecule feature similarity, such as Morgan fingerprints, which donot adequately capture the global molecular and atom-binding relationships. Asa result, these methods fail to represent the full complexity of molecularstructures during inference. Moreover, small-to-medium-sized LLMs, which offersimpler deployment requirements in specialized systems, have remained largelyunexplored in the molecular ICL literature. To address these gaps, we propose aself-supervised learning technique, GAMIC (Graph-Aligned Molecular In-Contextlearning, which aligns global molecular structures, represented by graph neuralnetworks (GNNs), with textual captions (descriptions) while leveraging localfeature similarity through Morgan fingerprints. In addition, we introduce aMaximum Marginal Relevance (MMR) based diversity heuristic during retrieval tooptimize input prompt demonstration samples. Our experimental findings usingdiverse benchmark datasets show GAMIC outperforms simple Morgan-based ICLretrieval methods across all tasks by up to 45%.</description>
      <author>example@mail.com (Ali Al-Lawati, Jason Lucas, Zhiwei Zhang, Prasenjit Mitra, Suhang Wang)</author>
      <guid isPermaLink="false">2502.05414v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2502.05282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by T-PAMI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种新的学习方法GEMINI，用于解决医学图像在密集对比表示学习（DCRL）中的虚假正负对问题。&lt;h4&gt;背景&lt;/h4&gt;Dense contrastive representation learning (DCRL) 提高了图像密集预测任务的学习效率，并显示出减少医疗影像收集和密集标注成本的巨大潜力。但是，医学影像的特性导致不可靠的对应关系发现，从而在大规模数据中引入了大量的虚假正负样本对（FP&amp;N）。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合同胚先验的DCRL学习方法，以实现可靠的对应关系发现并有效减少密集对比中的错误配对。&lt;h4&gt;方法&lt;/h4&gt;提出了可变形同胚学习(DHL)模型来描述医学图像之间的同胚性质，并通过保持拓扑结构的方式预测像素间的对应关系；同时引入了几何语义相似性(GSS)，用于从特征中提取语义信息，以衡量对应关系的学习程度。这些创新有助于减少配对搜索空间，并促进变形和正样本对的有效学习。&lt;h4&gt;主要发现&lt;/h4&gt;GEMINI通过有效利用同胚先验减少了错误配对，并提高了密集对比表示学习的效率与性能；在两个典型的表示学习任务上的实验变体证明了其优越性，且在七个数据集上超越了现有的方法。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了GEMINI在解决大规模医学影像中虚假正负样本问题的有效性和潜力。代码将在GitHub上公开。&lt;h4&gt;翻译&lt;/h4&gt;密集对比表示学习（DCRL）极大提高了图像密集预测任务的学习效率，显示出减少医疗影像收集和密集标注成本的巨大潜力。然而，医学影像的特性导致不可靠的对应关系发现，在大规模数据中引入了虚假正负样本对的问题。为了克服这一挑战，我们提出了GEoMetricvIsual deNse sImilarity（GEMINI）学习方法，该方法将同胚先验嵌入到DCRL中，实现了可靠的对应关系发现，并为有效的密集对比奠定了基础。具体而言，我们提出了一种可变形同胚学习(DHL)，用于模型医学图像之间的同胚性质，并通过保持拓扑结构的方式预测像素间的对应关系；同时引入了几何语义相似性(GSS)，提取特征中的语义信息来衡量对应关系的学习程度。此外，在两个典型的表示学习任务上的实验变体中，我们的研究展示了GEMINI在七个数据集上超越现有方法的优越表现，并将在GitHub上公开代码以供进一步开发和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense contrastive representation learning (DCRL) has greatly improved thelearning efficiency for image-dense prediction tasks, showing its greatpotential to reduce the large costs of medical image collection and denseannotation. However, the properties of medical images make unreliablecorrespondence discovery, bringing an open problem of large-scale falsepositive and negative (FP&amp;N) pairs in DCRL. In this paper, we propose GEoMetricvIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism priorto DCRL and enables a reliable correspondence discovery for effective densecontrast. We propose a deformable homeomorphism learning (DHL) which models thehomeomorphism of medical images and learns to estimate a deformable mapping topredict the pixels' correspondence under topological preservation. Iteffectively reduces the searching space of pairing and drives an implicit andsoft learning of negative pairs via a gradient. We also propose a geometricsemantic similarity (GSS) which extracts semantic information in features tomeasure the alignment degree for the correspondence learning. It will promotethe learning efficiency and performance of deformation, constructing positivepairs reliably. We implement two practical variants on two typicalrepresentation learning tasks in our experiments. Our promising results onseven datasets which outperform the existing methods show our greatsuperiority. We will release our code on a companion link:https://github.com/YutingHe-list/GEMINI.</description>
      <author>example@mail.com (Yuting He, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li)</author>
      <guid isPermaLink="false">2502.05282v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</title>
      <link>http://arxiv.org/abs/2502.00568v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于扩散的跨模态生成AI模型PathoGen，该模型可以从数字病理图像中合成基因表达数据，并且这种合成的数据能够准确预测癌症分级和患者生存风险。&lt;h4&gt;背景&lt;/h4&gt;现有的研究显示了结合数字病理学与转录组特征的人工智能多模式融合技术可以提高癌症诊断（分级/亚型）和预后（存活风险）的准确性，然而在实际临床环境中直接应用这种联合决策方式并不现实。由于组织病理学仍然是诊断的金标准，并且转录组测试很少被要求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从数字病理图像中合成基因表达数据的新模型PathoGen，并验证该模型预测癌症分级和患者生存风险的能力。&lt;h4&gt;方法&lt;/h4&gt;利用扩散过程为基础的跨模态生成AI模型PathoGen，将数字病理学与转录组特征进行结合，以提高癌症诊断及预后的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用PathoGen模型合成基因表达数据，能够高精度地预测癌症分级和患者生存风险，并且具有确定性（通过一致性覆盖保证）和可解释性（通过分布式注意图）。&lt;h4&gt;结论&lt;/h4&gt;PathoGen模型在数字病理图像与转录组特征的融合上表现出色，为临床诊断提供了一种新的途径。&lt;h4&gt;翻译&lt;/h4&gt;新兴的研究表明基于人工智能的多模态融合技术可以提高癌症诊断（分级/亚型）和预后（生存风险）预测的准确性。然而，在实际临床环境中直接应用这种联合决策方式并不现实。病理学仍然是诊断的金标准，而转录组测试很少被要求。通过我们的新扩散跨模式生成AI模型PathoGen，我们展示了从数字病理图像合成基因表达数据可以高精度地预测癌症分级和患者生存风险（达到最新技术水平），并且具有确定性和可解释性。PathoGen代码可在GitHub上公开使用，地址为https://github.com/Samiran-Dey/PathoGen。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Samiran-Dey/PathoGen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging research has highlighted that artificial intelligence basedmultimodal fusion of digital pathology and transcriptomic features can improvecancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.However, such direct fusion for joint decision is impractical in real clinicalsettings, where histopathology is still the gold standard for diagnosis andtranscriptomic tests are rarely requested, at least in the public healthcaresystem. With our novel diffusion based crossmodal generative AI model PathoGen,we show that genomic expressions synthesized from digital histopathologyjointly predicts cancer grading and patient survival risk with high accuracy(state-of-the-art performance), certainty (through conformal coverageguarantee) and interpretability (through distributed attention maps). PathoGencode is available for open use by the research community through GitHub athttps://github.com/Samiran-Dey/PathoGen.</description>
      <author>example@mail.com (Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2502.00568v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Compositional Reasoning in Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2502.06037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了大型预训练时间序列基础模型(TSFMs)在各种领域的零样本性能，并研究它们是通过记忆训练模式还是具备推理能力来实现成功的。&lt;h4&gt;背景&lt;/h4&gt;尽管大规模语言模型(LLM)的推理能力受到了广泛关注，但在时间序列基础模型(TSFMs)中，这一概念尚未被明确界定和探索。&lt;h4&gt;目的&lt;/h4&gt;受语言建模文献启发，本文正式定义了组合式推理在预测中的作用，并将其与分布内泛化区分开来。通过评估23种流行深度学习预测模型的推理和泛化能力，研究探讨TSFM架构设计对组合式推理和泛化的影响力。&lt;h4&gt;方法&lt;/h4&gt;使用多个合成和现实世界数据集评估了23个流行的深度学习预测模型，并进行了有控制的研究以系统地检查TSFMs的设计选择如何影响它们的推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现基于补丁的Transformer在推理性能方面表现最佳，其次是残差化MLP架构。后者在计算复杂性和可训练参数数量上更为简洁（分别减少97%和86%）。此外，在某些零样本分布外场景中，这些模型可以超越在分布内数据上训练的统计基准（如移动平均值和平滑指数）。&lt;h4&gt;结论&lt;/h4&gt;只有少数设计选择（例如标记化方法）对Transformer模型性能有显著影响。这项研究揭示了TSFM架构设计对组合式推理和泛化的关键见解，并指出基于补丁的Transformers是目前的最佳选择，尽管残差MLP架构可能更易于实现且计算成本更低。&lt;h4&gt;翻译&lt;/h4&gt;大型预训练时间序列基础模型(TSFMs)在各种领域的零样本性能中展现出了潜力。然而，一个问题是：TSFMs的成功是否仅限于记忆训练模式，还是它们具备推理能力？虽然语言建模文献中有关推理的研究引起了大量关注，在TSFMs中的定义和探索仍然不足。在此研究中，我们受语言模型文献启发，正式定义了组合式推理在预测中的作用，并将其与分布内泛化区分开来。通过评估23种流行的深度学习预测模型的推理和泛化能力，我们在多个合成数据集和现实世界的数据集上进行了评价。此外，通过有控制的研究，我们系统地检查了TSFMs的设计选择如何影响它们的推理能力。我们的研究揭示了TSFM架构设计对组合式推理和泛化的关键见解：基于补丁的Transformers在推理性能方面表现最佳，其次是残差化MLP架构（后者更为简洁），同时，在某些零样本分布外场景中，这些模型可以超越传统的统计基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large pre-trained time series foundation models (TSFMs) have demonstratedpromising zero-shot performance across a wide range of domains. However, aquestion remains: Do TSFMs succeed solely by memorizing training patterns, ordo they possess the ability to reason? While reasoning is a topic of greatinterest in the study of Large Language Models (LLMs), it is undefined andlargely unexplored in the context of TSFMs. In this work, inspired by languagemodeling literature, we formally define compositional reasoning in forecastingand distinguish it from in-distribution generalization. We evaluate thereasoning and generalization capabilities of 23 popular deep learningforecasting models on multiple synthetic and real-world datasets. Additionally,through controlled studies, we systematically examine which design choices inTSFMs contribute to improved reasoning abilities. Our study yields key insightsinto the impact of TSFM architecture design on compositional reasoning andgeneralization. We find that patch-based Transformers have the best reasoningperformance, closely followed by residualized MLP-based architectures, whichare 97\% less computationally complex in terms of FLOPs and 86\% smaller interms of the number of trainable parameters. Interestingly, in some zero-shotout-of-distribution scenarios, these models can outperform moving average andexponential smoothing statistical baselines trained on in-distribution data.Only a few design choices, such as the tokenization method, had a significant(negative) impact on Transformer model performance.</description>
      <author>example@mail.com (Willa Potosnak, Cristian Challu, Mononito Goswami, Kin G. Olivares, Michał Wiliński, Nina Żukowska, Artur Dubrawski)</author>
      <guid isPermaLink="false">2502.06037v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Voltage Drop: Models, Features and Data Representation Towards a Neural Surrogate</title>
      <link>http://arxiv.org/abs/2502.05345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了机器学习技术在现代ASIC电压降（IR下降）估算中的应用，旨在减少计算时间和资源需求。&lt;h4&gt;背景&lt;/h4&gt;随着集成电路复杂性和晶体管密度的增加，准确估计现代ASIC的电压降变得越来越耗时和耗费资源。&lt;h4&gt;目的&lt;/h4&gt;通过研究包括XGBoost、CNN和GNN在内的机器学习技术如何帮助降低IC中IR下降估算所需的计算努力及时间需求。&lt;h4&gt;方法&lt;/h4&gt;利用ASIC的电气特性、定时信息和物理参数训练机器学习模型，确保在不同的设计上具有较小调整即可实现适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，机器学习模型比商业工具更优越，在预测速度方面有显著提升。特别是GNNs在电压降估算中表现出色且误差极小。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了ML算法在精确估计IR下降和优化ASIC签署工作中的有效性。使用ML模型能够加快预测时间，减少计算时间和改善能源效率，从而通过优化的功率电路降低环境影响。&lt;h4&gt;翻译&lt;/h4&gt;准确估计现代应用特定集成电路（ASIC）中的电压降是极具挑战性的，因为这需要大量的时间和资源来处理日益复杂的晶体管密度问题。本文探究了机器学习技术（如XGBoost、CNN和GNN）如何帮助减少估算集成电路中IR下降所需的计算努力以及所需时间。传统方法，包括商业工具，在产生准确近似值时需要相当长的时间，尤其是在包含大量晶体管的复杂设计中。相比之下，作为快速且精确估计IR下降的一种替代解决方案，本文探索了机器学习算法的应用，并发现其能在明显较少时间内提供有效的估算结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate estimation of voltage drop (IR drop) in modern Application-SpecificIntegrated Circuits (ASICs) is highly time and resource demanding, due to thegrowing complexity and the transistor density in recent technology nodes. Tomitigate this challenge, we investigate how Machine Learning (ML) techniques,including Extreme Gradient Boosting (XGBoost), Convolutional Neural Network(CNN), and Graph Neural Network (GNN) can aid in reducing the computationaleffort and implicitly the time required to estimate the IR drop in IntegratedCircuits (ICs). Traditional methods, including commercial tools, requireconsiderable time to produce accurate approximations, especially forcomplicated designs with numerous transistors. ML algorithms, on the otherhand, are explored as an alternative solution to offer quick and precise IRdrop estimation, but in considerably less time. Our approach leverages ASICs'electrical, timing, and physical to train ML models, ensuring adaptabilityacross diverse designs with minimal adjustments. Experimental resultsunderscore the superiority of ML models over commercial tools, greatlyenhancing prediction speed. Particularly, GNNs exhibit promising performancewith minimal prediction errors in voltage drop estimation. The incorporation ofGNNs marks a groundbreaking advancement in accurate IR drop prediction. Thisstudy illustrates the effectiveness of ML algorithms in precisely estimating IRdrop and optimizing ASIC sign-off. Utilizing ML models leads to expeditedpredictions, reducing calculation time and improving energy efficiency, therebyreducing environmental impact through optimized power circuits.</description>
      <author>example@mail.com (Yifei Jin, Dimitrios Koutlis, Hector Bandala, Marios Daoutis)</author>
      <guid isPermaLink="false">2502.05345v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal PDE Foundation Model for Prediction and Scientific Text Descriptions</title>
      <link>http://arxiv.org/abs/2502.06026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer的多模态深度学习方法，用于近似求解各种ODE和PDE。该模型结合了数值输入（如方程参数和初始条件）与物理过程或系统动态的文字描述。&lt;h4&gt;背景&lt;/h4&gt;神经网络是科学计算任务中一种常用的工具，用来逼近非线性微分方程。现有的偏微分方程基础模型集中于学习通用求解器操作符或者控制方程本身，并且只处理数值或符号模态的数据。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有方法的局限性，提出了一种能够同时处理文本分析和描述输出等更灵活数据模式的新方法。&lt;h4&gt;方法&lt;/h4&gt;采用Transformer架构来逼近广泛的ODE和PDE求解操作符。模型整合了数值输入和物理过程或系统动态的文字描述。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该模型对于分布内和分布外的数据都能提供准确的解决方案（平均相对误差分别为小于3.3%和7.8%），并能够生成精确的文字描述（100%情况下正确）；在某些测试中还展示了时间上的外推能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法为解决涉及复杂物理过程的任务提供了强大的工具，不仅准确地解决了数值问题，还能提供关于基本动力学和解性质的深入解释。&lt;h4&gt;翻译&lt;/h4&gt;神经网络是科学计算任务（如替代建模、实时预测及最优控制）中逼近非线性微分方程的一种工具。PDE基础模型利用神经网络同时训练多个微分方程的近似值，因此是一个可以适应下游任务的一般求解器。当前的PDE基础模型集中于学习通用解算子和/或支配系统方程，并且只处理数值或符号模态的数据。然而，在实际应用中可能需要更灵活的数据模式，例如文本分析或描述性输出。为了解决这一缺口，我们提出了一种基于Transformer架构的新颖多模态深度学习方法，该方法用于逼近各种ODE和PDE的解算子。我们的方法结合了数值输入（如方程参数和初始条件）与物理过程或系统动力学的文字描述。这使模型能够处理符号表示可能不完整或不可用的情况。除了提供准确的数值预测之外，我们的方法还生成可解释的科学文本描述，为底层动态和解属性提供了更深层次的理解。数值实验表明，对于分布内数据（平均相对误差小于3.3%）及分布外数据（平均相对误差小于7.8%），模型均能提供精确解决方案，并且每次都能产生正确的文字描述。在某些测试中，该模型也显示出了时间上的外推能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural networks are one tool for approximating non-linear differentialequations used in scientific computing tasks such as surrogate modeling,real-time predictions, and optimal control. PDE foundation models utilizeneural networks to train approximations to multiple differential equationssimultaneously and are thus a general purpose solver that can be adapted todownstream tasks. Current PDE foundation models focus on either learninggeneral solution operators and/or the governing system of equations, and thusonly handle numerical or symbolic modalities. However, real-world applicationsmay require more flexible data modalities, e.g. text analysis or descriptiveoutputs. To address this gap, we propose a novel multimodal deep learningapproach that leverages a transformer-based architecture to approximatesolution operators for a wide variety of ODEs and PDEs. Our method integratesnumerical inputs, such as equation parameters and initial conditions, with textdescriptions of physical processes or system dynamics. This enables our modelto handle settings where symbolic representations may be incomplete orunavailable. In addition to providing accurate numerical predictions, ourapproach generates interpretable scientific text descriptions, offering deeperinsights into the underlying dynamics and solution properties. The numericalexperiments show that our model provides accurate solutions for in-distributiondata (with average relative error less than 3.3%) and out-of-distribution data(average relative error less than 7.8%) together with precise text descriptions(with correct descriptions generated 100% of times). In certain tests, themodel is also shown to be capable of extrapolating solutions in time.</description>
      <author>example@mail.com (Elisa Negrini, Yuxuan Liu, Liu Yang, Stanley J. Osher, Hayden Schaeffer)</author>
      <guid isPermaLink="false">2502.06026v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Working Memory: Query-Guided Segment Refinement for Enhanced Multimodal Understanding</title>
      <link>http://arxiv.org/abs/2502.06020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NAACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种增强多模态基础模型（MFMs）处理时间序列能力的专用认知模块——时序工作记忆（TWM）。通过保留任务相关的信息，该模块优化了有限容量内的信息处理，使MFM在视频和音频分析中表现得更为出色。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型在图像字幕、问答和图像-文本检索等任务上表现出色，但它们在处理长时间序列时存在固有局限性。这些局限限制了它们对复杂时间敏感数据的处理能力。&lt;h4&gt;目的&lt;/h4&gt;通过引入TWM模块来提高MFMs的时间建模能力，并优化其有限容量内的信息保留机制，使其能够更好地应对视频和音频内容分析中的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于查询引导注意的方法，以在时序序列中聚焦于最具有信息量的多模态片段。TWM模块可以容易地集成到现有的MFMs中。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，通过使用TWM插件式模块，九个最先进的模型在视频字幕、问答和视频-文本检索任务上都取得了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;TWM通过增强多模态基础模型的时间建模能力，扩展了它们处理复杂时间敏感数据的能力。我们的代码可在此处获取：https://github.com/xid32/NAACL_2025_TWM。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到，尽管多模态基础模型（MFMs）在诸如视觉字幕、问答和图像-文本检索任务中取得了显著的成功，但它们由于内部容量有限而难以处理长时间序列数据。因此，研究者们设计了一种特殊认知模块——时序工作记忆（TWM），用来增强这些模型的时间建模能力，并通过只保留最关键的信息来优化其使用效率。这种模块可以轻易地加入现有的MFMs中，并且实验结果显示，它使得九个最先进的模型在视频字幕、问答和视频-文本检索等任务上的性能有了显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models (MFMs) have demonstrated significant success intasks such as visual captioning, question answering, and image-text retrieval.However, these models face inherent limitations due to their finite internalcapacity, which restricts their ability to process extended temporal sequences,a crucial requirement for comprehensive video and audio analysis. To overcomethese challenges, we introduce a specialized cognitive module, temporal workingmemory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.It selectively retains task-relevant information across temporal dimensions,ensuring that critical details are preserved throughout the processing of videoand audio content. The TWM uses a query-guided attention approach to focus onthe most informative multimodal segments within temporal sequences. Byretaining only the most relevant content, TWM optimizes the use of the model'slimited capacity, enhancing its temporal modeling ability. This plug-and-playmodule can be easily integrated into existing MFMs. With our TWM, ninestate-of-the-art models exhibit significant performance improvements acrosstasks such as video captioning, question answering, and video-text retrieval.By enhancing temporal modeling, TWM extends the capability of MFMs to handlecomplex, time-sensitive data effectively. Our code is available athttps://github.com/xid32/NAACL_2025_TWM.</description>
      <author>example@mail.com (Xingjian Diao, Chunhui Zhang, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui)</author>
      <guid isPermaLink="false">2502.06020v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Redefining Robot Generalization Through Interactive Intelligence</title>
      <link>http://arxiv.org/abs/2502.05963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文讨论了机器人基础模型如何需要从单一代理视角转向交互式的多代理视角，以应对实时的人机协作的复杂性。&lt;h4&gt;背景&lt;/h4&gt;虽然大规模机器学习的发展产生了能够适应各种下游任务的强大基础模型，但在机器人领域中仍普遍认为机器人是独立执行如抓取和导航等任务的单一决策者，与人类互动较少。然而，在现实世界中，许多类型的半自主系统（例如穿戴式设备、远程操作以及神经接口）需要持续的人机交互协作。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨基础模型在处理人机实时协同适应时所面临的挑战，并提出一种新的框架来支持这种多代理视角的需求。&lt;h4&gt;方法&lt;/h4&gt;作者提出了一个基于神经科学启发的通用架构，包括四个模块：（1）一种受感觉运动整合原则影响的多模式感知模块；（2）类似认知科学研究中联合行动框架的工作小组模型；（3）以内部模型理论为基础的动作控制预测世界信念模型；以及（4）类似于海布定律和强化学习机制的记忆/反馈系统。&lt;h4&gt;主要发现&lt;/h4&gt;提出的架构不仅适用于仿生系统的场景，而且还可以应用于任何需要半自主或交互操作的机器人。通过超越单一代理设计的理念，基础模型可以达到更强大、个性化及更具预见性的性能水平。&lt;h4&gt;结论&lt;/h4&gt;为了更好地支持实时的人机协作，未来的基础模型发展应当采纳一个多代理视角，并采用作者提议的方法和架构来实现这一目标。&lt;h4&gt;翻译&lt;/h4&gt;最近的大规模机器学习进展产生了能够适应广泛下游任务的强大基础模型。然而，在机器人领域中，传统的观点仍然将机器人视为执行如抓取、导航等单一任务的独立决策者，与人类互动有限。本文提出一个基于神经科学启发的通用架构来支持半自主或交互式操作场景中的多代理视角需求，以应对人机实时协同适应的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large-scale machine learning have produced high-capacityfoundation models capable of adapting to a broad array of downstream tasks.While such models hold great promise for robotics, the prevailing paradigmstill portrays robots as single, autonomous decision-makers, performing taskslike manipulation and navigation, with limited human involvement. However, alarge class of real-world robotic systems, including wearable robotics (e.g.,prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, aresemiautonomous, and require ongoing interactive coordination with humanpartners, challenging single-agent assumptions. In this position paper, weargue that robot foundation models must evolve to an interactive multi-agentperspective in order to handle the complexities of real-time human-robotco-adaptation. We propose a generalizable, neuroscience-inspired architectureencompassing four modules: (1) a multimodal sensing module informed bysensorimotor integration principles, (2) an ad-hoc teamwork model reminiscentof joint-action frameworks in cognitive science, (3) a predictive world beliefmodel grounded in internal model theories of motor control, and (4) amemory/feedback mechanism that echoes concepts of Hebbian andreinforcement-based plasticity. Although illustrated through the lens of cyborgsystems, where wearable devices and human physiology are inseparablyintertwined, the proposed framework is broadly applicable to robots operatingin semi-autonomous or interactive contexts. By moving beyond single-agentdesigns, our position emphasizes how foundation models in robotics can achievea more robust, personalized, and anticipatory level of performance.</description>
      <author>example@mail.com (Sharmita Dey)</author>
      <guid isPermaLink="false">2502.05963v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction</title>
      <link>http://arxiv.org/abs/2502.05218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于超图的因子模型（FactorGCL），该模型利用时间残差对比学习方法，旨在改进传统线性因素模型，并通过挖掘隐藏因素来预测股票收益。&lt;h4&gt;背景&lt;/h4&gt;因子模型是经济学和金融学中的基本方法，在量化投资中被广泛使用。近年来，从传统的专家设计的因素的线性模型转向更灵活的数据驱动非线性机器学习模型已成为趋势，但市场数据中信号与噪声的比例低使得挖掘有效因素变得困难。&lt;h4&gt;目的&lt;/h4&gt;为了提高因子模型的有效性并解决当前问题，本文旨在通过结合超图结构和时间残差对比学习方法来改进因子模型，以便更好地捕捉股票收益之间的高阶非线性关系，并提取有效的隐藏因素以补充专家设计的先验因素。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于超图的因素模型（FactorGCL），其中采用了一个级联残差超图架构，该架构可以从去除先验因素影响后的剩余信息中提取隐藏因素。此外，还提出了时间残差对比学习方法来指导有效和全面的隐藏因素的提取。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验证明了FactorGCL不仅能超越现有的最先进方法，而且还能挖掘出有效的隐藏因素用于预测股票收益。&lt;h4&gt;结论&lt;/h4&gt;通过引入超图结构和时间残差对比学习方法，本文提出的模型在预测股票收益方面表现出色，并且可以作为进一步研究的有前途的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a fundamental method in economics and finance, the factor model has beenextensively utilized in quantitative investment. In recent years, there hasbeen a paradigm shift from traditional linear models with expert-designedfactors to more flexible nonlinear machine learning-based models withdata-driven factors, aiming to enhance the effectiveness of these factormodels. However, due to the low signal-to-noise ratio in market data, miningeffective factors in data-driven models remains challenging. In this work, wepropose a hypergraph-based factor model with temporal residual contrastivelearning (FactorGCL) that employs a hypergraph structure to better capturehigh-order nonlinear relationships among stock returns and factors. To minehidden factors that supplement human-designed prior factors for predictingstock returns, we design a cascading residual hypergraph architecture, in whichthe hidden factors are extracted from the residual information after removingthe influence of prior factors. Additionally, we propose a temporal residualcontrastive learning method to guide the extraction of effective andcomprehensive hidden factors by contrasting stock-specific residual informationover different time periods. Our extensive experiments on real stock marketdata demonstrate that FactorGCL not only outperforms existing state-of-the-artmethods but also mines effective hidden factors for predicting stock returns.</description>
      <author>example@mail.com (Yitong Duan, Weiran Wang, Jian Li)</author>
      <guid isPermaLink="false">2502.05218v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>TabICL: A Tabular Foundation Model for In-Context Learning on Large Data</title>
      <link>http://arxiv.org/abs/2502.05564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为TabICL的新模型，该模型利用两阶段架构处理大规模表格数据，并在分类任务上表现出色。&lt;h4&gt;背景&lt;/h4&gt;传统的梯度增强决策树在表格数据上的主导地位正受到使用上下文学习（ICL）的新型基础模型的挑战。最近提出的TabPFNv2虽然适用于小规模数据集，但在处理大规模训练集时计算成本过高。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效扩展并在大型数据集上提供优势的新模型，以克服现有模型在大表格上的局限性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的两阶段架构的TabICL模型：首先是列然后是行注意机制来构建固定维度的行嵌入，随后使用变压器进行高效的上下文学习。该模型预训练于包含多达60K样本的合成数据集，并能在可负担资源上处理50万样本。&lt;h4&gt;主要发现&lt;/h4&gt;在200个分类任务的数据集中，TabICL的表现与TabPFNv2相当，但在速度上快至10倍；对于超过10K样本的56个数据集，它超越了TabPFNv2和CatBoost，显示了上下文学习对大规模数据的有效性。&lt;h4&gt;结论&lt;/h4&gt;TabICL模型在处理大型表格分类任务方面展示出卓越的能力，并且表明上下文学习技术有潜力为未来的大规模数据分析提供强大的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The long-standing dominance of gradient-boosted decision trees on tabulardata is currently challenged by tabular foundation models using In-ContextLearning (ICL): setting the training data as context for the test data andpredicting in a single forward pass without parameter updates. While the veryrecent TabPFNv2 foundation model (2025) excels on tables with up to 10Ksamples, its alternating column- and row-wise attentions make handling largetraining sets computationally prohibitive. So, can ICL be effectively scaledand deliver a benefit for larger tables? We introduce TabICL, a tabularfoundation model for classification, pretrained on synthetic datasets with upto 60K samples and capable of handling 500K samples on affordable resources.This is enabled by a novel two-stage architecture: a column-then-row attentionmechanism to build fixed-dimensional embeddings of rows, followed by atransformer for efficient ICL. Across 200 classification datasets from theTALENT benchmark, TabICL is on par with TabPFNv2 while being systematicallyfaster (up to 10 times), and significantly outperforms all other approaches. On56 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost,demonstrating the potential of ICL for large data.</description>
      <author>example@mail.com (Jingang Qu, David Holzmüller, Gaël Varoquaux, Marine Le Morvan)</author>
      <guid isPermaLink="false">2502.05564v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SSH: Sparse Spectrum Adaptation via Discrete Hartley Transformation</title>
      <link>http://arxiv.org/abs/2502.05539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新的参数高效微调方法SSH通过选择最有信息量的频谱分量，显著减少了训练参数的数量，并在计算成本和内存需求方面实现了重大节省。&lt;h4&gt;背景&lt;/h4&gt;低秩适应(LoRA)已经证明，在微调大型基础模型时能够减少可训练参数的数量。然而，当扩展到更大规模的模型或处理更复杂的任务自适应时，它仍然面临计算资源和内存方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法SSH，通过稀疏频谱选择来增强大语言模型在复杂任务上的适应性，并降低其计算和存储要求。&lt;h4&gt;方法&lt;/h4&gt;利用离散哈特利变换(DHT)，根据初始权重指导选择最具信息量的频谱分量。再使用轻量级逆DHT将频谱投影回空间域以进行更新。&lt;h4&gt;主要发现&lt;/h4&gt;SSH在单模态任务如语言理解和生成，以及跨模态任务如视频-文本理解上均表现出色，并超过了现有的参数高效微调方法，在计算成本和内存需求方面都有显著的减少。&lt;h4&gt;结论&lt;/h4&gt;提出的方法不仅提高了模型性能，还通过选择性地更新最具信息量的部分实现了对现有资源使用的优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has been demonstrated effective in reducing thetrainable parameter number when fine-tuning a large foundation model (LLM).However, it still encounters computational and memory challenges when scalingto larger models or addressing more complex task adaptation.  In this work, we introduce Sparse Spectrum Adaptation via Discrete HartleyTransformation (SSH), a novel approach that significantly reduces the number oftrainable parameters while enhancing model performance. It selects the mostinformative spectral components across all layers, under the guidance of theinitial weights after a discrete Hartley transformation (DHT). The lightweightinverse DHT then projects the spectrum back into the spatial domain forupdates.  Extensive experiments across both single-modality tasks such as languageunderstanding and generation and multi-modality tasks such as video-textunderstanding demonstrate that SSH outperforms existing parameter-efficientfine-tuning (PEFT) methods while achieving substantial reductions incomputational cost and memory requirements.</description>
      <author>example@mail.com (Yixian Shen, Qi Bi, Jia-Hong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania)</author>
      <guid isPermaLink="false">2502.05539v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Differentially Private Synthetic Data via APIs 3: Using Simulators Instead of Foundation Model</title>
      <link>http://arxiv.org/abs/2502.05505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为Sim-PE的新方法，它扩展了Private Evolution (PE)框架，使其能够利用各种领域特定的仿真器进行差分隐私(DP)数据合成。&lt;h4&gt;背景&lt;/h4&gt;差分隐私合成数据是一种既能保护隐私又能提供高质量数据的重要技术。近期提出的Private Evolution（PE）方法通过仅使用基础模型的推理API来生成DP合成数据，显示出其潜力。&lt;h4&gt;目的&lt;/h4&gt;探索利用领域特定仿真器作为PE框架中推理API的可能性，并评估这种方法在图像合成中的性能和效果。&lt;h4&gt;方法&lt;/h4&gt;发现并验证了PE框架可以接受除基础模型之外的其他类型推理API。具体来说，使用如计算机图形学为基础的图像合成工具等模拟器作为有效API的方法被提出。该研究探讨了利用多种仿真器进行DP数据合成的可能性，并在多个不同的仿真器上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;Sim-PE方法在图像合成中表现出色，在提高下游分类准确性和降低FID评分方面优于传统的PE方法，最高可提升至3倍和减少80%。此外，基础模型与领域特定模拟器可以结合使用以进一步改进性能。&lt;h4&gt;结论&lt;/h4&gt;本文证明了利用仿真器作为推理API的可行性，并展示了Sim-PE在多个场景中的有效性。这为DP合成数据的应用提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;差分隐私(DP)合成数据已成为一种重要工具，能够在不损害隐私的情况下释放私有数据的价值。最近提出的Private Evolution（PE）方法作为一种生成DP合成数据的前景技术出现。不同于基于训练的方法，PE仅需要访问基础模型的推理API来利用最先进的模型能力。然而，并不是所有领域都有适当的基础模型可用。本文发现PE框架足够通用，可以接受超出基础模型范围的推理API，包括如计算机图形学为基础的图像生成工具等模拟器作为有效API使用。这一发现大大扩展了PE的应用范围，使其能够利用广泛的特定领域的仿真器进行DP数据合成。我们在图像合成领域探索了这种方法（名为Sim-PE）的潜力，并在三个不同的模拟器上进行了测试。结果显示，在提高下游分类准确性和降低FID评分方面，Sim-PE表现优异，最高可提升至3倍和减少80%。此外，基础模型与特定领域的仿真器可以结合使用以进一步改进性能。代码开源于Private Evolution Python库：https://github.com/microsoft/DPSDA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differentially private (DP) synthetic data, which closely resembles theoriginal private data while maintaining strong privacy guarantees, has become akey tool for unlocking the value of private data without compromising privacy.Recently, Private Evolution (PE) has emerged as a promising method forgenerating DP synthetic data. Unlike other training-based approaches, PE onlyrequires access to inference APIs from foundation models, enabling it toharness the power of state-of-the-art models. However, a suitable foundationmodel for a specific private data domain is not always available. In thispaper, we discover that the PE framework is sufficiently general to allowinference APIs beyond foundation models. Specifically, we show that simulators-- such as computer graphics-based image synthesis tools -- can also serve aseffective APIs within the PE framework. This insight greatly expands theapplicability of PE, enabling the use of a wide variety of domain-specificsimulators for DP data synthesis. We explore the potential of this approach,named Sim-PE, in the context of image synthesis. Across three diversesimulators, Sim-PE performs well, improving the downstream classificationaccuracy of PE by up to 3x and reducing the FID score by up to 80%. We alsoshow that simulators and foundation models can be easily leveraged togetherwithin the PE framework to achieve further improvements. The code isopen-sourced in the Private Evolution Python library:https://github.com/microsoft/DPSDA.</description>
      <author>example@mail.com (Zinan Lin, Tadas Baltrusaitis, Sergey Yekhanin)</author>
      <guid isPermaLink="false">2502.05505v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>L2GNet: Optimal Local-to-Global Representation of Anatomical Structures for Generalized Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.05229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为L2GNet的新模型，该模型旨在改进医疗图像分割中连续和离散潜在空间（CDLS）方法的性能。&lt;h4&gt;背景&lt;/h4&gt;CLoS和DLS模型在医学图像分割任务上表现出色。然而，处理长程依赖关系时存在困难，尤其是冗余区域特征聚合的问题，这影响了解剖结构的理解及分类内部依赖性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架L2GNet来解决现有CDLS方法的缺点，特别是关于如何更好地建模全局依赖性和避免计算开销。&lt;h4&gt;方法&lt;/h4&gt;L2GNet通过利用最优传输将离散代码从DLS中获得，并在可训练参考上对齐这些代码，从而学习全局依赖关系。它不使用额外的权重矩阵进行自我注意模型中的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与包括SynergyNet在内的当前最佳方法相比，L2GNet在多器官分割和心脏数据集上的性能更为优越。&lt;h4&gt;结论&lt;/h4&gt;所提出的L2GNet为提高医学图像分析中深度学习模型的性能提供了一种新思路。&lt;h4&gt;翻译&lt;/h4&gt;连续潜在空间（CLS）和离散潜在空间（DLS）模型在医疗图像分割任务上表现出色。然而，处理长程依赖关系时存在困难，尤其是冗余区域特征聚合的问题，这影响了解剖结构的理解及分类内部依赖性。为此，我们提出了L2GNet，通过最优传输获取离散代码，并在可训练参考中对齐这些代码来学习全局依赖关系。实验结果表明，在多器官分割和心脏数据集上，与包括SynergyNet在内的当前最佳方法相比，L2GNet的性能更优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous Latent Space (CLS) and Discrete Latent Space (DLS) models, likeAttnUNet and VQUNet, have excelled in medical image segmentation. In contrast,Synergistic Continuous and Discrete Latent Space (CDLS) models show promise inhandling fine and coarse-grained information. However, they struggle withmodeling long-range dependencies. CLS or CDLS-based models, such as TransUNetor SynergyNet are adept at capturing long-range dependencies. Since they relyheavily on feature pooling or aggregation using self-attention, they maycapture dependencies among redundant regions. This hinders comprehension ofanatomical structure content, poses challenges in modeling intra-class andinter-class dependencies, increases false negatives and compromisesgeneralization. Addressing these issues, we propose L2GNet, which learns globaldependencies by relating discrete codes obtained from DLS using optimaltransport and aligning codes on a trainable reference. L2GNet achievesdiscriminative on-the-fly representation learning without an additional weightmatrix in self-attention models, making it computationally efficient formedical applications. Extensive experiments on multi-organ segmentation andcardiac datasets demonstrate L2GNet's superiority over state-of-the-artmethods, including the CDLS method SynergyNet, offering an novel approach toenhance deep learning models' performance in medical image analysis.</description>
      <author>example@mail.com (Vandan Gorade, Sparsh Mittal, Neethi Dasu, Rekha Singhal, KC Santosh, Debesh Jha)</author>
      <guid isPermaLink="false">2502.05229v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.05485v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to be published in ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种分层的视觉-语言-动作(VLA)模型，用于解决在机器人领域中利用非目标域数据进行有效训练的问题，并展示了其在真实机器人的实验中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;大型基础模型在视觉和语言领域的开放世界泛化能力较强，但在机器人领域尚未达到同等水平的泛化效果。主要挑战在于获取昂贵且有限的目标域机器人数据，一种可能的解决策略是利用更便宜、非目标域的数据如无动作视频或手绘草图。&lt;h4&gt;目的&lt;/h4&gt;探讨分层VLA模型在处理非目标域数据方面相较于标准单体VLA模型（直接将视觉-语言模型微调为预测动作）更为有效的假设，以及其如何实现在机器人任务中的泛化能力提升。&lt;h4&gt;方法&lt;/h4&gt;通过研究一类特定的分层VLA模型，在该模型中高层视觉-语言模型被微调以产生粗略2D路径指示期望机器人的末端执行器轨迹；基于此2D预测路径指导低层次、3D感知控制策略进行精确操作。这种设计减少了高层模型对细粒度动作预测的需求，同时减轻了低层政策的复杂任务级推理负担。&lt;h4&gt;主要发现&lt;/h4&gt;利用分层VLA模型架构，高层视觉-语言模型能够跨越显著的目标域与现实机器人测试场景间的差距（包括物理外观、动力学和语义差异等），在真实机器人实验中观察到相比于基准方法OpenVLA成功率提升20%的平均值。&lt;h4&gt;结论&lt;/h4&gt;该研究通过创新性的分层设计展示了一条利用非目标域数据有效训练机器人系统的路径，从而提高了模型在实际环境中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;大型基础模型已经在视觉和语言领域展现了对复杂问题的强大开放世界泛化能力，但在机器人领域的同等水平的泛化效果尚未实现。一个基本挑战是缺乏昂贵且难以获得的目标域机器人数据。一种有前景的方法是在视觉-语言动作(VLA)模型中引入层次结构来更有效地利用便宜、非目标域的数据，如无动作视频或手绘草图等。本文提出了一种分层VLA模型，其中高层视觉-语言模型被微调以生成指示期望机器人末端执行器轨迹的粗略2D路径。基于此路径预测作为低层次控制策略进行精确操作的指导。这种方法减轻了高层模型对细粒度动作预测的需求，并减轻了低层策略在复杂任务级推理上的负担，从而使得该方法能够跨越显著的目标域与现实机器人测试场景间的差距（包括物理外观、动力学和语义差异等）。在实际机器人的实验中，我们观察到相比于基准OpenVLA模型，在七种不同泛化轴向上有平均20%的成功率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large foundation models have shown strong open-world generalization tocomplex problems in vision and language, but similar levels of generalizationhave yet to be achieved in robotics. One fundamental challenge is the lack ofrobotic data, which are typically obtained through expensive on-robotoperation. A promising remedy is to leverage cheaper, off-domain data such asaction-free videos, hand-drawn sketches or simulation data. In this work, weposit that hierarchical vision-language-action (VLA) models can be moreeffective in utilizing off-domain data than standard monolithic VLA models thatdirectly finetune vision-language models (VLMs) to predict actions. Inparticular, we study a class of hierarchical VLA models, where the high-levelVLM is finetuned to produce a coarse 2D path indicating the desired robotend-effector trajectory given an RGB image and a task description. Theintermediate 2D path prediction is then served as guidance to the low-level,3D-aware control policy capable of precise manipulation. Doing so alleviatesthe high-level VLM from fine-grained action prediction, while reducing thelow-level policy's burden on complex task-level reasoning. We show that, withthe hierarchical design, the high-level VLM can transfer across significantdomain gaps between the off-domain finetuning data and real-robot testingscenarios, including differences on embodiments, dynamics, visual appearancesand task semantics, etc. In the real-robot experiments, we observe an averageof 20% improvement in success rate across seven different axes ofgeneralization over OpenVLA, representing a 50% relative gain. Visual resultsare provided at: https://hamster-robot.github.io/</description>
      <author>example@mail.com (Yi Li, Yuquan Deng, Jesse Zhang, Joel Jang, Marius Memme, Raymond Yu, Caelan Reed Garrett, Fabio Ramos, Dieter Fox, Anqi Li, Abhishek Gupta, Ankit Goyal)</author>
      <guid isPermaLink="false">2502.05485v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Addressing Out-of-Label Hazard Detection in Dashcam Videos: Insights from the COOOL Challenge</title>
      <link>http://arxiv.org/abs/2501.16037v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025, 5 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的方法，用于行车记录仪视频中的危险分析，包括驾驶员对危险的反应检测、危险物体识别以及生成描述性说明。&lt;h4&gt;背景&lt;/h4&gt;当前对于自动驾驶系统来说，在缺乏标记数据的情况下如何有效进行危险分析是一个挑战。现有的方法通常依赖于标签数据来训练模型，但这种情况在实际应用中并不总是可行。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过引入新的检测和识别技术来改进这一过程，这些技术可以在不完全依赖标注数据的前提下提高系统的性能。&lt;h4&gt;方法&lt;/h4&gt;{'驾驶员反应检测': '利用速度和声音异常检测的方法，并采用无监督学习技术。', '危险物检测': '使用一组启发式规则作为弱分类器，并通过集成学习方法结合这些分类器，同时引入差分隐私以进一步优化模型的稳健性。', '危险描述生成': '使用最新的视觉-语言模型为识别出的危险物体或场景生成描述性的标签。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在自动驾驶领域的无标签挑战中获得了最高分数，在驾驶员反应检测、危险物识别和生成描述性说明这三个任务上均表现出色。&lt;h4&gt;结论&lt;/h4&gt;本文介绍的新方法通过集成学习与差分隐私技术的结合，成功地提高了行车记录仪视频中的危险分析能力，并证明了其在实际应用中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已直接用中文呈现&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ffyyytt/coool_2025&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach for hazard analysis in dashcam footage,addressing the detection of driver reactions to hazards, the identification ofhazardous objects, and the generation of descriptive captions. We firstintroduce a method for detecting driver reactions through speed and soundanomaly detection, leveraging unsupervised learning techniques. For hazarddetection, we employ a set of heuristic rules as weak classifiers, which arecombined using an ensemble method. This ensemble approach is further refinedwith differential privacy to mitigate overconfidence, ensuring robustnessdespite the lack of labeled data. Lastly, we use state-of-the-artvision-language models for hazard captioning, generating descriptive labels forthe detected hazards. Our method achieved the highest scores in the Challengeon Out-of-Label in Autonomous Driving, demonstrating its effectiveness acrossall three tasks. Source codes are publicly available athttps://github.com/ffyyytt/COOOL_2025.</description>
      <author>example@mail.com (Anh-Kiet Duong, Petra Gomez-Krämer)</author>
      <guid isPermaLink="false">2501.16037v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>MoFM: A Large-Scale Human Motion Foundation Model</title>
      <link>http://arxiv.org/abs/2502.05432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FM）由于其在不同任务中的可扩展性和泛化能力而越来越受到研究者的关注。&lt;h4&gt;目的&lt;/h4&gt;受基础模型和大型语言模型进展原则的启发，本文介绍了一种新型的基础运动模型MoFM，旨在实现复杂人体运动的时间和空间语义理解。&lt;h4&gt;方法&lt;/h4&gt;为支持大规模训练，设计并采用MotionBook作为综合的人体动作词典。MotionBook利用热立方体捕捉时空运动热图，并应用离散变分模型的原则将人类运动编码成离散单元以实现更高效、可扩展的表示。&lt;h4&gt;主要发现&lt;/h4&gt;经过大量运动数据集训练后的MoFM提供了一个适应各种下游任务的基础骨干，支持如一次学习、无监督和有监督的任务范式。这种多功能性使MoFM非常适合广泛的基于动作的应用程序。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了基础运动模型在处理复杂人体运动中的时间和空间语义理解方面的潜力，并且通过有效的训练方法和创新的表示技术提高了模型的可扩展性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含中文，无需额外翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AFoundation Models (FM) have increasingly drawn the attention of researchersdue to their scalability and generalization across diverse tasks. Inspired bythe success of FMs and the principles that have driven advancements in LargeLanguage Models (LLMs), we introduce MoFM as a novel Motion Foundation Model.MoFM is designed for the semantic understanding of complex human motions inboth time and space. To facilitate large-scale training, MotionBook, acomprehensive human motion dictionary of discretized motions is designed andemployed. MotionBook utilizes Thermal Cubes to capture spatio-temporal motionheatmaps, applying principles from discrete variational models to encode humanmovements into discrete units for a more efficient and scalable representation.MoFM, trained on a large corpus of motion data, provides a foundationalbackbone adaptable to diverse downstream tasks, supporting paradigms such asone-shot, unsupervised, and supervised tasks. This versatility makes MoFMwell-suited for a wide range of motion-based applications.</description>
      <author>example@mail.com (Mohammadreza Baharani, Ghazal Alinezhad Noghre, Armin Danesh Pazho, Gabriel Maldonado, Hamed Tabkhi)</author>
      <guid isPermaLink="false">2502.05432v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation</title>
      <link>http://arxiv.org/abs/2502.05424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WWW2025 Main Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个用于多域图预训练和跨领域适应的结构对齐框架（SAMGPT），该框架能够从多个来源领域中的图形中学习到多领域的知识，并将其应用于未知的目标领域。&lt;h4&gt;背景&lt;/h4&gt;在线服务使用图形来表示相互关联的实体，支持了网络上的广泛应用。然而，来自不同域的图常常表现出不同的特性，这给跨域适应带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从多个来源领域中学习并适应到未知目标领域的模型框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结构对齐框架（SAMGPT），该框架在预训练阶段引入了结构令牌来协调多源域中的基于结构的聚合，并设计了用于跨域适应的整体提示和特定提示。&lt;h4&gt;主要发现&lt;/h4&gt;通过全面实验评估了提出的SAMGPT的有效性。&lt;h4&gt;结论&lt;/h4&gt;SAMGPT为解决图的基础模型如何从多个来源领域进行训练并适应到未知目标领域的挑战提供了一个创新的方法。&lt;h4&gt;翻译&lt;/h4&gt;图能够建模许多在线服务中的互连实体，支持网络上广泛的应用。这提出了一个问题：我们如何在多源域中训练图基础模型，并将其调整为一个未见的目标域？主要障碍是来自不同域的图经常表现出不同的特性。一些研究利用大型语言模型基于与图形关联的文字描述来对齐多个领域，限制了它们仅适用于附有文字属性的图。对于无文本图而言，最近的一些工作试图跨领域对齐不同的特征分布，但通常忽视了结构差异。在本文中，我们提出了一个新颖的结构对齐框架用于无文本多域图预训练和跨域适应（SAMGPT），该框架旨在从多个来源领域的图形中学得多领域知识，并将其应用于未见的目标领域。具体来说，在预训练阶段，我们引入了一组结构令牌以协调基于结构的聚合。然后对于跨域适应，我们设计了双提示，即整体提示和特定提示，分别用于将统一的多域结构性知识以及细粒度的、特定领域的信息调整到目标域。最后，我们在七个公开数据集上进行了全面实验，评估并分析了SAMGPT的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are able to model interconnected entities in many online services,supporting a wide range of applications on the Web. This raises an importantquestion: How can we train a graph foundational model on multiple sourcedomains and adapt to an unseen target domain? A major obstacle is that graphsfrom different domains often exhibit divergent characteristics. Some studiesleverage large language models to align multiple domains based on textualdescriptions associated with the graphs, limiting their applicability totext-attributed graphs. For text-free graphs, a few recent works attempt toalign different feature distributions across domains, while generallyneglecting structural differences. In this work, we propose a novel StructureAlignment framework for text-free Multi-domain Graph Pre-Training andcross-domain adaptation (SAMGPT). It is designed to learn multi-domainknowledge from graphs originating in multiple source domains, which can then beadapted to address applications in an unseen target domain. Specifically, weintroduce a set of structure tokens to harmonize structure-based aggregationacross source domains during the pre-training phase. Next, for cross-domainadaptation, we design dual prompts, namely, holistic prompts and specificprompts, which adapt unified multi-domain structural knowledge andfine-grained, domain-specific information, respectively, to a target domain.Finally, we conduct comprehensive experiments on seven public datasets toevaluate and analyze the effectiveness of SAMGPT.</description>
      <author>example@mail.com (Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang)</author>
      <guid isPermaLink="false">2502.05424v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Particle Trajectory Representation Learning with Masked Point Modeling</title>
      <link>http://arxiv.org/abs/2502.02558v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. 24 pages, 15 figures. Project page at  https://youngsm.com/polarmae/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于3D粒子轨迹分析的自监督学习框架PoLAr-MAE。&lt;h4&gt;背景&lt;/h4&gt;虽然许多在线语料库和带注释照片的方法已经得到发展，但在科学领域中应用这些方法仍处于初期阶段。&lt;h4&gt;目的&lt;/h4&gt;开发一种针对时间投影室（TPCs）中的3D粒子轨迹分析的自监督学习框架。&lt;h4&gt;方法&lt;/h4&gt;基于PointMAE，提出体积分词以将稀疏的离子化点分类为分辨率无关的补丁，并增加了一个辅助能量填充任务来改进轨迹语义。&lt;h4&gt;主要发现&lt;/h4&gt;PoLAr-MAE模型在不使用任何标记数据的情况下达到了与监督基线相当的表现水平（轨迹和淋浴分类F分数分别为99.4%和97.7%）。&lt;h4&gt;问题&lt;/h4&gt;尽管该模型学习了丰富的粒子轨迹表示，但它在处理子令牌现象（如重叠或短寿命的粒子轨迹）时存在困难。&lt;h4&gt;贡献&lt;/h4&gt;发布了一个大型公开LArTPC数据集PILArNet-M（超过100万个事件和52亿个标记点），以推进高能物理中的自监督学习。&lt;h4&gt;翻译&lt;/h4&gt;有效的自我监督学习技术在解锁大规模数据集用于表示学习方面发挥了关键作用。尽管许多具有前景的方法已经使用在线语料库和带注释的照片开发出来，但在包含高度专业化知识的科学领域中应用这些方法仍处于初期阶段。我们提出了一种针对时间投影室（TPCs）中的3D粒子轨迹分析的自监督屏蔽建模框架。这些探测器生成全局稀疏但局部密集的点云，以毫米分辨率捕获米尺度的粒子轨迹。基于PointMAE的工作提出了体积分词来将稀疏的离子化点分类为分辨率无关的补丁，并增加了一个辅助能量填充任务来改进轨迹语义。这一方法——我们称之为PoLAr-MAE——在不使用任何标记数据的情况下，实现了与监督基线相当的表现水平（轨迹和淋浴分类F分数分别为99.4%和97.7%）。虽然该模型学习了丰富的粒子轨迹表示，但在处理子令牌现象如重叠或短寿命的粒子轨迹时存在困难。为了支持进一步的研究，我们发布了PILArNet-M——最大的公开LArTPC数据集（超过100万个事件和52亿个标记点）以推动高能物理中的自监督学习的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective self-supervised learning (SSL) techniques have been key tounlocking large datasets for representation learning. While many promisingmethods have been developed using online corpora and captioned photographs,their application to scientific domains, where data encodes highly specializedknowledge, remains in its early stages. We present a self-supervised maskedmodeling framework for 3D particle trajectory analysis in Time ProjectionChambers (TPCs). These detectors produce globally sparse (&lt;1% occupancy) butlocally dense point clouds, capturing meter-scale particle trajectories atmillimeter resolution. Starting with PointMAE, this work proposes volumetrictokenization to group sparse ionization points into resolution-agnosticpatches, as well as an auxiliary energy infilling task to improve trajectorysemantics. This approach -- which we call Point-based Liquid Argon MaskedAutoencoder (PoLAr-MAE) -- achieves 99.4% track and 97.7% shower classificationF-scores, matching that of supervised baselines without any labeled data. Whilethe model learns rich particle trajectory representations, it struggles withsub-token phenomena like overlapping or short-lived particle trajectories. Tosupport further research, we release PILArNet-M -- the largest open LArTPCdataset (1M+ events, 5.2B labeled points) -- to advance SSL in high energyphysics (HEP). Project site: https://youngsm.com/polarmae/</description>
      <author>example@mail.com (Sam Young, Yeon-jae Jwa, Kazuhiro Terao)</author>
      <guid isPermaLink="false">2502.02558v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Infinite-Horizon Value Function Approximation for Model Predictive Control</title>
      <link>http://arxiv.org/abs/2502.06760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何使用神经网络和价值迭代以及轨迹优化来近似约束最优控制问题的无限时间价值函数，并展示了将这种价值函数作为终端成本用于模型预测控制器中的全局稳定性。该方法通过两个玩具问题和一个在线避障的真实世界场景得到了验证。&lt;h4&gt;背景&lt;/h4&gt;模型预测控制（MPC）已成为机器人生成复杂运动的一种流行工具，但由于实时要求限制了硬约束和大预览时间窗口的使用，这影响了系统的安全性和稳定性。实践中，设计人员必须仔细设计成本函数以模仿无限时间框架，这是一个繁琐且容易陷入局部最优解的过程。&lt;h4&gt;目的&lt;/h4&gt;研究如何近似约束最优控制问题的无限时间价值函数，并展示这种价值函数作为终端成本在模型预测控制器中提供的全局稳定性。&lt;h4&gt;方法&lt;/h4&gt;通过使用神经网络和价值迭代以及轨迹优化来近似无限时间价值函数。将这种方法应用于两个玩具问题和在线避障的真实世界场景验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法成功地展示了如何利用价值函数的近似作为终端成本，提供模型预测控制器中的全局稳定性，并通过实验表明这种技术的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为解决机器人在实时环境下的复杂运动控制问题提供了有效的解决方案，特别是在确保系统安全性和稳定性的前提下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model Predictive Control has emerged as a popular tool for robots to generatecomplex motions. However, the real-time requirement has limited the use of hardconstraints and large preview horizons, which are necessary to ensure safetyand stability. In practice, practitioners have to carefully design costfunctions that can imitate an infinite horizon formulation, which is tediousand often results in local minima. In this work, we study how to approximatethe infinite horizon value function of constrained optimal control problemswith neural networks using value iteration and trajectory optimization.Furthermore, we demonstrate how using this value function approximation as aterminal cost provides global stability to the model predictive controller. Theapproach is validated on two toy problems and a real-world scenario with onlineobstacle avoidance on an industrial manipulator where the value function isconditioned to the goal and obstacle.</description>
      <author>example@mail.com (Armand Jordana, Sébastien Kleff, Arthur Haffemayer, Joaquim Ortiz-Haro, Justin Carpentier, Nicolas Mansard, Ludovic Righetti)</author>
      <guid isPermaLink="false">2502.06760v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>FOCUS - Multi-View Foot Reconstruction From Synthetically Trained Dense Correspondences</title>
      <link>http://arxiv.org/abs/2502.06367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从多个校准图像重建表面是一个具有挑战性的任务，通常需要大量重叠显著的收集到的图像。&lt;h4&gt;目的&lt;/h4&gt;旨在解决人类脚部重建的具体问题，通过多视角RGB图像提取丰富的像素级几何线索，并将这些线索融合成最终的3D对象。&lt;h4&gt;方法&lt;/h4&gt;{'贡献一': 'SynFoot2，现有合成足数据集的扩展，包括新的数据类型：与参数化足模型FIND的密集对应关系。', '贡献二': '基于我们的合成数据集训练出一个感知不确定性的密集对应预测器。', '贡献三': '两种从密集对应的预测重建3D表面的方法：一种受结构从运动启发的方法；另一种使用FIND模型的优化方法。'}&lt;h4&gt;主要发现&lt;/h4&gt;在少视角设置下，重建的质量达到了最先进的水平，在多视角可用时性能也与最先进方法相当，并且运行速度显著更快。&lt;h4&gt;结论&lt;/h4&gt;我们发布我们的合成数据集供研究界使用。代码可在https://github.com/OllieBoyne/FOCUS获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种名为FOCUS的方法，用于从多视角RGB图像中重建人类脚部的3D表面，并提出了该方法在少视角设置下的优越性能及运行速度的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface reconstruction from multiple, calibrated images is a challenging task- often requiring a large number of collected images with significant overlap.We look at the specific case of human foot reconstruction. As with previoussuccessful foot reconstruction work, we seek to extract rich per-pixel geometrycues from multi-view RGB images, and fuse these into a final 3D object. Ourmethod, FOCUS, tackles this problem with 3 main contributions: (i) SynFoot2, anextension of an existing synthetic foot dataset to include a new data type:dense correspondence with the parameterized foot model FIND; (ii) anuncertainty-aware dense correspondence predictor trained on our syntheticdataset; (iii) two methods for reconstructing a 3D surface from densecorrespondence predictions: one inspired by Structure-from-Motion, and oneoptimization-based using the FIND model. We show that our reconstructionachieves state-of-the-art reconstruction quality in a few-view setting,performing comparably to state-of-the-art when many views are available, andruns substantially faster. We release our synthetic dataset to the researchcommunity. Code is available at: https://github.com/OllieBoyne/FOCUS</description>
      <author>example@mail.com (Oliver Boyne, Roberto Cipolla)</author>
      <guid isPermaLink="false">2502.06367v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Wandering around: A bioinspired approach to visual attention through object motion sensitivity</title>
      <link>http://arxiv.org/abs/2502.06747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种受生物启发的注意系统，该系统利用脉冲卷积神经网络和动态视觉传感器进行对象运动敏感性选择性关注。&lt;h4&gt;背景&lt;/h4&gt;主动视觉允许动态视觉感知，为依赖大规模数据集和高计算资源的传统前馈架构提供了替代方案。基于哺乳动物视网膜设计的事件相机通过捕获异步场景变化增强了这种能力，从而实现高效低延迟处理。&lt;h4&gt;目的&lt;/h4&gt;开发一种结合事件传感器与神经形态算法的新颖系统，以提高在动态环境中的实时响应能力和计算效率。&lt;h4&gt;方法&lt;/h4&gt;使用Speck神经形态硬件集成的动态视觉传感器（DVS）和倾斜-平移单元组成一个系统，通过固定眼球运动生成事件来识别ROI，并对目标进行中心化处理。该系统利用理想光栅进行了表征，并在Event Camera Motion Segmentation Dataset上进行了基准测试。&lt;h4&gt;主要发现&lt;/h4&gt;系统在多对象运动分割中达到了平均IoU为82.2%和SSIM为96%，办公室场景中显著物体检测精度达到88.8%，低光照条件下达到89.8%。该系统的实时演示显示，其对动态场景的响应时间为0.12秒。&lt;h4&gt;结论&lt;/h4&gt;一种无需学习的设计确保了系统在感知场景中的鲁棒性，并为实时机器人应用提供了可靠基础，也为更复杂架构的发展奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;主动视觉通过使用脉冲卷积神经网络和动态视觉传感器（DVS）进行选择性注意，在对象运动敏感性的基础上实现。该方法使系统能够高效地在低光照等复杂条件下操作，并为实时机器人应用提供了坚实的基础，同时为更复杂的架构发展开辟了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active vision enables dynamic visual perception, offering an alternative tostatic feedforward architectures in computer vision, which rely on largedatasets and high computational resources. Biological selective attentionmechanisms allow agents to focus on salient Regions of Interest (ROIs),reducing computational demand while maintaining real-time responsiveness.Event-based cameras, inspired by the mammalian retina, enhance this capabilityby capturing asynchronous scene changes enabling efficient low-latencyprocessing. To distinguish moving objects while the event-based camera is inmotion the agent requires an object motion segmentation mechanism to accuratelydetect targets and center them in the visual field (fovea). Integratingevent-based sensors with neuromorphic algorithms represents a paradigm shift,using Spiking Neural Networks to parallelize computation and adapt to dynamicenvironments. This work presents a Spiking Convolutional Neural Networkbioinspired attention system for selective attention through object motionsensitivity. The system generates events via fixational eye movements using aDynamic Vision Sensor integrated into the Speck neuromorphic hardware, mountedon a Pan-Tilt unit, to identify the ROI and saccade toward it. The system,characterized using ideal gratings and benchmarked against the Event CameraMotion Segmentation Dataset, reaches a mean IoU of 82.2% and a mean SSIM of 96%in multi-object motion segmentation. The detection of salient objects reaches88.8% accuracy in office scenarios and 89.8% in low-light conditions on theEvent-Assisted Low-Light Video Object Segmentation Dataset. A real-timedemonstrator shows the system's 0.12 s response to dynamic scenes. Itslearning-free design ensures robustness across perceptual scenes, making it areliable foundation for real-time robotic applications serving as a basis formore complex architectures.</description>
      <author>example@mail.com (Giulia D Angelo, Victoria Clerico, Chiara Bartolozzi, Matej Hoffmann, P. Michael Furlong, Alexander Hadjiivanov)</author>
      <guid isPermaLink="false">2502.06747v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Rough Stochastic Pontryagin Maximum Principle and an Indirect Shooting Method</title>
      <link>http://arxiv.org/abs/2502.06726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究推导了确定性控制下的随机最优控制的一阶Pontryagin最优条件。&lt;h4&gt;背景&lt;/h4&gt;系统由粗糙微分方程（RDE）驱动，并且这些方程是高斯粗糙路径的一部分。这种方法可以应用于遵循布朗运动驱动的随机微分方程(SDE)的系统，但不依赖于前向-后向SDE，并使用与确定性PMP相同的哈密顿量。&lt;h4&gt;目的&lt;/h4&gt;目的是推导出一种适用于RDE系统的Pontryagin最大原理（PMP），并提出了一种间接射击法来解决非线性的随机最优控制问题，这种方法比直接方法快10倍。&lt;h4&gt;方法&lt;/h4&gt;首先通过利用高斯粗糙路径的最新结果，推导了非线性及线性RDE解的各种可积误差界限。然后使用基于针状变化的标准技术得出了PMP。&lt;h4&gt;主要发现&lt;/h4&gt;首次提出了间接射击法来解决非线性的随机最优控制问题，并且该方法在稳定性任务上比直接方法收敛速度快10倍。&lt;h4&gt;结论&lt;/h4&gt;所提出的Pontryagin最大原理（PMP）及其应用于非线性随机最优控制的间接射击法，为研究和应用提供了一种新的工具。&lt;h4&gt;翻译&lt;/h4&gt;我们针对由高斯粗糙路径驱动的粗糙微分方程系统，推导了确定性控制下的随机最优控制的一阶Pontryagin最优条件。这种Pontryagin最大原理（PMP）可以应用于布朗运动驱动的随机微分方程(SDE)的系统，但它不依赖于前向-后向SDE，并使用与确定性PMP相同的哈密顿量。证明过程包括首先通过利用高斯粗糙路径的最新结果推导出非线性和线性RDE解的各种可积误差界限。然后，使用基于针状变化的标准技术得出PMP。作为应用，我们首次提出了间接射击法来解决非线性的随机最优控制问题，并显示该方法比直接方法在稳定性任务上收敛速度快10倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We derive first-order Pontryagin optimality conditions for stochastic optimalcontrol with deterministic controls for systems modeled by rough differentialequations (RDE) driven by Gaussian rough paths. This Pontryagin MaximumPrinciple (PMP) applies to systems following stochastic differential equations(SDE) driven by Brownian motion, yet it does not rely on forward-backward SDEsand involves the same Hamiltonian as the deterministic PMP. The proof consistsof first deriving various integrable error bounds for solutions to nonlinearand linear RDEs by leveraging recent results on Gaussian rough paths. The PMPthen follows using standard techniques based on needle-like variations. As anapplication, we propose the first indirect shooting method for nonlinearstochastic optimal control and show that it converges 10x faster than a directmethod on a stabilization task.</description>
      <author>example@mail.com (Thomas Lew)</author>
      <guid isPermaLink="false">2502.06726v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Video Analytics in Cloud-Edge-Terminal Collaborative Systems</title>
      <link>http://arxiv.org/abs/2502.06581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;综述了云边端协同（CETC）系统在视频数据分析中的应用，探讨了其架构、边缘计算平台和资源管理机制。&lt;h4&gt;背景&lt;/h4&gt;视频数据的爆炸性增长推动了分布式视频分析的发展，尤其是基于CETC系统的高效视频处理、实时推理以及隐私保护分析。&lt;h4&gt;目的&lt;/h4&gt;分析CETC系统的根本组成要素，包括分层框架、分布式框架及混合架构，并探讨边缘计算平台和资源管理机制。&lt;h4&gt;方法&lt;/h4&gt;研究分为两部分：一部分侧重于以设备为中心的边缘处理方式；另一部分则聚焦云中心的方法，利用强大的计算能力进行复杂的视频理解和模型训练。此外还介绍了结合自适应任务卸载和资源感知调度技术的混合视频分析。&lt;h4&gt;主要发现&lt;/h4&gt;当前研究涵盖传统方法以及大型语言模型和多模态集成带来的新机会与挑战，在平台可扩展性、数据保护及系统可靠性方面均有体现。&lt;h4&gt;结论&lt;/h4&gt;未来的研究方向包括解释性的系统设计、高效的处理机制，以及高级视频分析技术的开发，这些都将为研究人员和从业者提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了分布式视频数据分析在云边端协同（CETC）系统中的应用情况，该领域的研究涵盖了系统的架构组成要素、边缘计算平台与资源管理机制，并探讨了多种处理方法及其面临的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of video data has driven the development of distributedvideo analytics in cloud-edge-terminal collaborative (CETC) systems, enablingefficient video processing, real-time inference, and privacy-preservinganalysis. Among multiple advantages, CETC systems can distribute videoprocessing tasks and enable adaptive analytics across cloud, edge, and terminaldevices, leading to breakthroughs in video surveillance, autonomous driving,and smart cities. In this survey, we first analyze fundamental architecturalcomponents, including hierarchical, distributed, and hybrid frameworks,alongside edge computing platforms and resource management mechanisms. Buildingupon these foundations, edge-centric approaches emphasize on-device processing,edge-assisted offloading, and edge intelligence, while cloud-centric methodsleverage powerful computational capabilities for complex video understandingand model training. Our investigation also covers hybrid video analyticsincorporating adaptive task offloading and resource-aware scheduling techniquesthat optimize performance across the entire system. Beyond conventionalapproaches, recent advances in large language models and multimodal integrationreveal both opportunities and challenges in platform scalability, dataprotection, and system reliability. Future directions also encompassexplainable systems, efficient processing mechanisms, and advanced videoanalytics, offering valuable insights for researchers and practitioners in thisdynamic field.</description>
      <author>example@mail.com (Linxiao Gong, Hao Yang, Gaoyun Fang, Bobo Ju, Juncen Guo, Xiaoguang Zhu, Yan Wang, Xiping Hu, Peng Sun, Azzedine Boukerche)</author>
      <guid isPermaLink="false">2502.06581v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Building Rome with Convex Optimization</title>
      <link>http://arxiv.org/abs/2502.04640v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过深度预测和凸优化使全局束调整变得更简单。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来简化全局束调整，并提高结构从运动（SfM）管道的性能。&lt;h4&gt;方法&lt;/h4&gt;{'(i)': '提出了一个缩放的全局束调整(SBA)公式，该公式通过学习到的深度将2D关键点测量提升至3D空间。', '(ii)': '设计了一种经验上紧致的凸半定规划(SDP)松弛方案，用于以可证明的全局最优性解决SBA问题。', '(iii)': '使用Burder-Monteiro因子化和基于CUDA的信任区域黎曼优化器(XM)来在极端规模下求解SDP松弛。', '(iv)': '构建了一个结构从运动(SfM)管道，其中XM作为优化引擎，并展示了该方法相较于现有SfM管道具有更好的重建质量和更快的速度、可扩展性以及无需初始化的特点。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的XM-SfM在图像重建质量上优于或至少与现有的SfM管道相当，同时提高了速度和规模的灵活性。&lt;h4&gt;结论&lt;/h4&gt;通过结合深度学习和凸优化技术，解决了全局束调整问题，并开发了一个性能优越、无需初始化且更高效的结构从运动(SfM)系统。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已转化为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global bundle adjustment is made easy by depth prediction and convexoptimization. We (i) propose a scaled bundle adjustment (SBA) formulation thatlifts 2D keypoint measurements to 3D with learned depth, (ii) design anempirically tight convex semidfinite program (SDP) relaxation that solves SBAto certfiable global optimality, (iii) solve the SDP relaxations at extremescale with Burer-Monteiro factorization and a CUDA-based trust-regionRiemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM)pipeline with XM as the optimization engine and show that XM-SfM dominates orcompares favorably with existing SfM pipelines in terms of reconstructionquality while being faster, more scalable, and initialization-free.</description>
      <author>example@mail.com (Haoyu Han, Heng Yang)</author>
      <guid isPermaLink="false">2502.04640v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>AgilePilot: DRL-Based Drone Agent for Real-Time Motion Planning in Dynamic Environments by Leveraging Object Detection</title>
      <link>http://arxiv.org/abs/2502.06725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript has been submitted to 2025 INTERNATIONAL CONFERENCE ON  UNMANNED AIRCRAFT SYSTEMS (ICUAS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于深度强化学习的自主无人机导航方案，以解决动态环境中快速移动物体导致的目标位置变化问题。&lt;h4&gt;背景&lt;/h4&gt;现有的传统规划方法和经典优化算法在面对实时、不可预测的变化时表现不佳，适应性和实时决策能力受限。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的运动规划器AgilePilot，利用深度强化学习技术结合实时计算机视觉进行对象检测，以提高无人机在动态环境中的导航性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度强化学习的运动规划器AgilePilot，并通过训练-部署框架来缩小仿真与真实世界的差距。该系统采用先进的奖励结构促进安全性及灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;新的运动规划器相比传统的人工势场法等算法，在性能和动态目标跟踪精度方面提高3倍，实验成功率高达90%。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了深度强化学习在解决实时动态导航挑战方面的有效性，并为智能安全与灵活的无人机导航提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;自主无人机构建在动态环境中的导航仍然是一个关键挑战，特别是在处理快速移动物体以及目标位置迅速变化的情况下。传统规划方法和经典优化技术虽然广泛使用，但面对实时不可预测的变化时适应性和实时决策能力不足，导致性能不佳。本文提出了一种新的基于深度强化学习的运动规划器AgilePilot，并结合飞行中实时计算机视觉进行对象检测，以提高无人机在动态环境中的导航效果。该系统能够快速适应变化环境，并实现最大速度为3.0米/秒的实际应用场景表现。相比传统的势场法等算法，在性能和跟踪精度方面提高了三倍，并且在75次实验中的成功率高达90%。这项工作强调了深度强化学习技术解决实时动态导航挑战的有效性，提供了智能安全性和灵活度的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous drone navigation in dynamic environments remains a criticalchallenge, especially when dealing with unpredictable scenarios includingfast-moving objects with rapidly changing goal positions. While traditionalplanners and classical optimisation methods have been extensively used toaddress this dynamic problem, they often face real-time, unpredictable changesthat ultimately leads to sub-optimal performance in terms of adaptiveness andreal-time decision making. In this work, we propose a novel motion planner,AgilePilot, based on Deep Reinforcement Learning (DRL) that is trained indynamic conditions, coupled with real-time Computer Vision (CV) for objectdetections during flight. The training-to-deployment framework bridges theSim2Real gap, leveraging sophisticated reward structures that promotes bothsafety and agility depending upon environment conditions. The system canrapidly adapt to changing environments, while achieving a maximum speed of 3.0m/s in real-world scenarios. In comparison, our approach outperforms classicalalgorithms such as Artificial Potential Field (APF) based motion planner by 3times, both in performance and tracking accuracy of dynamic targets by usingvelocity predictions while exhibiting 90% success rate in 75 conductedexperiments. This work highlights the effectiveness of DRL in tacklingreal-time dynamic navigation challenges, offering intelligent safety andagility.</description>
      <author>example@mail.com (Roohan Ahmed Khan, Valerii Serpiva, Demetros Aschalew, Aleksey Fedoseev, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.06725v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>A Resilient and Energy-Efficient Smart Metering Infrastructure Utilizing a Self-Organizing UAV Swarm</title>
      <link>http://arxiv.org/abs/2502.06508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于无人机群的智能计量架构，旨在解决传统人工抄表方式带来的成本高、安全性差和准确性低的问题。&lt;h4&gt;背景&lt;/h4&gt;智能电表基础设施可能成为智慧城市中有效管理能源的关键因素之一。目前，传统的测量记录收集主要通过手动方式进行，这带来了成本、安全性和准确性的挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种基于无人机群的自动数据采集架构，用于智能计量基础设施，并确保其可扩展性、低成本和风险最小化。&lt;h4&gt;方法&lt;/h4&gt;开发了一个综合系统，包括多种操作阶段、通信协议以及可靠的故障处理机制。进行了广泛的仿真，以维护精确飞行编队、高效收集智能电表的数据以及适应各种故障场景。另外分析了无人机群的能量消耗，并提出了电池尺寸策略及无人机群的运行寿命估计。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，基于无人机群的方案在数据采集效率和可靠性方面具有显著优势，能够有效支持绿色智慧城市的发展。&lt;h4&gt;结论&lt;/h4&gt;UAV（无人飞行器）群有潜力彻底改变智能计量领域，推动更环保、更具弹性的智慧城市建设。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The smart metering infrastructure may become one of the key elements inefficiently managing energy in smart cities. At the same time, traditionalmeasurement record collection is performed by manual methods, which raisescost, safety, and accuracy issues. This paper proposes an innovative SMIarchitecture based on an unmanned aerial vehicle swarm organizing itself forthe autonomous data collection in smart metering infrastructure withscalability and cost-effectiveness while minimizing risks. We design anarchitecture-based comprehensive system with various phases of operation,communication protocols, and robust failure-handling mechanisms to ensurereliable operations. We further perform extensive simulations in maintenance ofprecise formations during flight, efficient data collection from smart meters,and adaptation to various failure scenarios. Importantly, we analyze the energyconsumption of the proposed system in both drone flight operations and networkcommunication. We now propose a battery sizing strategy and provide an estimateof the operational lifetime of the swarm, underlining the feasibility andpracticality of our approach. Our results show that UAV swarms have greatpotential to revolutionize smart metering and to bring a further brick togreener and more resilient smart cities.</description>
      <author>example@mail.com (Mustafa Siham, Qutaiba I. Ali)</author>
      <guid isPermaLink="false">2502.06508v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>HetSwarm: Cooperative Navigation of Heterogeneous Swarm in Dynamic and Dense Environments through Impedance-based Guidance</title>
      <link>http://arxiv.org/abs/2502.06722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript has been submitted to ICUAS-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HetSwarm是一种结合了无人机和地面移动机器人的异构多机器人系统，旨在解决物流和仓库管理中的高效性需求。&lt;h4&gt;背景&lt;/h4&gt;随着对高效物流和仓储管理系统的需求增加，无人飞行器（UAV）作为自动引导车（AGV）的补充正在变得越来越重要。然而，无人机受到有限飞行时间、电池寿命以及载荷能力的限制。&lt;h4&gt;目的&lt;/h4&gt;提出HetSwarm系统以应对上述挑战，该系统结合了无人机和地面移动机器人进行协作导航。&lt;h4&gt;方法&lt;/h4&gt;采用人工势场（APF）路径规划器用于无人机，并使用阻抗链接保持地面上机器人的连接稳定性。地面机器人还建立了与低高度障碍物的临时阻抗链路，避免局部碰撞。&lt;h4&gt;主要发现&lt;/h4&gt;在各种环境条件下对HetSwarm进行了实验验证，在30个测试案例中取得了90%的成功率；地面机器人表现出平均45厘米的偏离距离，有效避开了障碍物。模拟也证实了系统的鲁棒性及其实际应用潜力。&lt;h4&gt;结论&lt;/h4&gt;HetSwarm系统通过协作导航展示了其在拥挤且动态环境中的高效性和适应能力，并为未来的实时任务执行提供了可能的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;随着对物流和仓储管理效率需求的增长，无人飞行器（UAV）作为自动引导车（AGV）的有效补充正在变得越来越重要。无人机提高效率的能力在于它们可以导航密集环境并在不同高度上操作。然而，由于其有限的飞行时间、电池寿命以及载荷能力限制，需要地面站的支持来协助工作。为了应对这些挑战，我们提出了HetSwarm系统，这是一种结合了UAV和移动地面机器人的异构多机器人系统，用于在混乱和动态条件下进行协作导航。我们的方法采用人工势场（APF）路径规划器为无人机提供实时调整轨迹的能力。地面上的机器人跟随这条路径并保持通过阻抗链接建立的连接稳定性，确保协调一致。此外，地面机器人还会与低高度障碍物建立临时阻抗链路以避免局部碰撞，因为这些障碍物不会影响无人机飞行。在各种环境条件下对HetSwarm进行了实验验证，在30个测试案例中取得了90%的成功率；同时，地面上的机器人在遇到障碍物时表现出平均45厘米的偏离距离，证实了有效的避碰能力。通过Gym PyBullet环境中的广泛模拟进一步验证了我们系统的鲁棒性以适应实际应用，并证明其在混乱环境中进行动态实时任务执行方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing demand for efficient logistics and warehouse management,unmanned aerial vehicles (UAVs) are emerging as a valuable complement toautomated guided vehicles (AGVs). UAVs enhance efficiency by navigating denseenvironments and operating at varying altitudes. However, their limited flighttime, battery life, and payload capacity necessitate a supporting groundstation. To address these challenges, we propose HetSwarm, a heterogeneousmulti-robot system that combines a UAV and a mobile ground robot forcollaborative navigation in cluttered and dynamic conditions. Our approachemploys an artificial potential field (APF)-based path planner for the UAV,allowing it to dynamically adjust its trajectory in real time. The ground robotfollows this path while maintaining connectivity through impedance links,ensuring stable coordination. Additionally, the ground robot establishestemporal impedance links with low-height ground obstacles to avoid localcollisions, as these obstacles do not interfere with the UAV's flight.Experimental validation of HetSwarm in diverse environmental conditionsdemonstrated a 90% success rate across 30 test cases. The ground robotexhibited an average deviation of 45 cm near obstacles, confirming effectivecollision avoidance. Extensive simulations in the Gym PyBullet environmentfurther validated the robustness of our system for real-world applications,demonstrating its potential for dynamic, real-time task execution in clutteredenvironments.</description>
      <author>example@mail.com (Malaika Zafar, Roohan Ahmed Khan, Aleksey Fedoseev, Kumar Katyayan Jaiswal, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.06722v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimization under Attack: Resilience, Vulnerability, and the Path to Collapse</title>
      <link>http://arxiv.org/abs/2502.05954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了分布式敌对攻击下多智能体离散选择组合优化的性能轨迹，从弹性到脆弱性再到崩溃。&lt;h4&gt;背景&lt;/h4&gt;对于智慧城市的大型社会技术基础设施（如能源和交通系统），优化是提高运营效率的重要手段。尤其在多智能体系统的分布式对抗攻击下的表现尚缺乏研究。&lt;h4&gt;目的&lt;/h4&gt;探索不同敌对强度及网络位置的代理数量如何影响分布式优化性能，包括帕累托最优解点。&lt;h4&gt;方法&lt;/h4&gt;利用真实世界数据模拟超过28亿个情景来评估优化性能。创建了一个开放的大规模数据集作为基准。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了从弹性到脆弱性再到崩溃的不同敌对攻击强度下的优化轨迹，并明确了哪些条件会使系统变得脆弱或崩溃。&lt;h4&gt;结论&lt;/h4&gt;这些新发现为设计对抗分布式优化的故障容忍和故障纠正策略提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;本文首次解析了在不同的敌对影响下，从弹性到脆弱性再到最终崩溃的分布式优化路径。通过模拟超过28亿个情景，并利用真实世界数据进行评估，展示了不同数量的不同类型代理如何影响分布式优化性能和帕累托最优解点的存在情况。此研究为设计新的故障容忍及修复策略提供了宝贵见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimization is instrumental for improving operations of large-scalesocio-technical infrastructures of Smart Cities, for instance, energy andtraffic systems. In particular, understanding the performance of multi-agentdiscrete-choice combinatorial optimization under distributed adversary attacksis a compelling and underexplored problem, since multi-agent systems exhibit alarge number of remote control variables that can influence in an unprecedentedway the cost-effectiveness of distributed optimization heuristics. This paperunravels for the first time the trajectories of distributed optimization fromresilience to vulnerability, and finally to collapse under varying adversaryinfluence. Using real-world data to emulate over 28 billion multi-agentoptimization scenarios, we exhaustively assess how the number of agents withdifferent adversarial severity and network positioning influences optimizationperformance, including the influence on Pareto optimal points. With this novellarge-scale dataset, made openly available as a benchmark, we disentangle howoptimization remains resilient to adversaries and which adversary conditionsare required to make optimization vulnerable or collapsed. These new findingscan provide new insights for designing self-healing strategies forfault-tolerance and fault-correction in adversarial distributed optimizationthat have been missing so far.</description>
      <author>example@mail.com (Amal Aldawsari, Evangelos Pournaras)</author>
      <guid isPermaLink="false">2502.05954v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Discovery of skill switching criteria for learning agile quadruped locomotion</title>
      <link>http://arxiv.org/abs/2502.06676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;开发了一种分层学习和优化框架，用于实现多种技能的协调运动。&lt;h4&gt;背景&lt;/h4&gt;现有的多技能行走策略往往需要人为设定规则来切换不同的步行模式，并且在遇到意外失败时恢复能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够自动自然地进行不同技能间转换并在遭遇故障后迅速恢复的学习和优化框架，适用于追踪任意位置目标的场景。&lt;h4&gt;方法&lt;/h4&gt;{'包含接触模式': '将接触模式整合到奖励项中以学习不同类型的步伐作为独立策略，无需其他参考。', '高层政策生成': '通过深度强化学习过程与优化过程组合来学习高层策略，该策略能够为个体策略生成权重并组合成多技能运动。', '自然切换规则': '根据目标距离自动调整和自然转换技能，并在奖励计算中包含适当的切换距离以适应高阶策略的学习，并通过外层优化循环更新这些距离。', '实验验证': '首先在一个模拟的Unitree A1四足机器人上展示了全面任务中的多技能行走能力，随后将学习到的策略应用于现实世界场景，包括小跑步、跳跃和全速奔跑等动作及其自然过渡。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架能够成功地在广泛的运动技能中进行平滑且连续的转换，而不需要人为设定规则来切换不同的步行模式。&lt;h4&gt;结论&lt;/h4&gt;相较于离散单技能之间的切换（如未能在现实中从慢跑直接过渡到全速奔跑），该方法实现了所有学习到的敏捷技能，并展示了更流畅、连续的技能转换能力。&lt;h4&gt;翻译&lt;/h4&gt;本文开发了一种分层学习和优化框架，可以学习并实现协调良好的多技能步行。所学的多技能策略可以在追踪任意位置的目标时自动且自然地在不同的技能之间进行切换，并能迅速从故障中恢复过来。提出的框架由深度强化学习过程和一个优化过程组成。首先将接触模式整合到奖励项中以分别学习不同类型的步伐作为独立策略，无需其他参考。接着通过一个高级别的政策来生成个体策略的权重，以便在追踪目标的任务设置中组合多技能步行。技能会根据到目标的距离自动且自然地切换，而适当的切换距离则被包含在高阶策略的学习奖励计算中，并由外部优化循环更新。首先，在模拟的Unitree A1四足机器人上证明了成功实现多技能运动的能力。然后在现实世界场景部署学习到的政策，展示了包括慢跑、跳跃和全速奔跑在内的多种步行模式及其自然过渡能力。此外，所学策略能够及时应对意外故障，进行快速恢复，并重新开始行走任务。相比于离散切换单一技能（未能从现实中转换至全速奔跑），所提出的方法实现了所有学习到的敏捷技能，且具有更平滑和连续的技能转换特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper develops a hierarchical learning and optimization framework thatcan learn and achieve well-coordinated multi-skill locomotion. The learnedmulti-skill policy can switch between skills automatically and naturally intracking arbitrarily positioned goals and recover from failures promptly. Theproposed framework is composed of a deep reinforcement learning process and anoptimization process. First, the contact pattern is incorporated into thereward terms for learning different types of gaits as separate policies withoutthe need for any other references. Then, a higher level policy is learned togenerate weights for individual policies to compose multi-skill locomotion in agoal-tracking task setting. Skills are automatically and naturally switchedaccording to the distance to the goal. The proper distances for skill switchingare incorporated in reward calculation for learning the high level policy andupdated by an outer optimization loop as learning progresses. We firstdemonstrated successful multi-skill locomotion in comprehensive tasks on asimulated Unitree A1 quadruped robot. We also deployed the learned policy inthe real world showcasing trotting, bounding, galloping, and their naturaltransitions as the goal position changes. Moreover, the learned policy canreact to unexpected failures at any time, perform prompt recovery, and resumelocomotion successfully. Compared to discrete switch between single skillswhich failed to transition to galloping in the real world, our proposedapproach achieves all the learned agile skills, with smoother and morecontinuous skill transitions.</description>
      <author>example@mail.com (Wanming Yu, Fernando Acero, Vassil Atanassov, Chuanyu Yang, Ioannis Havoutis, Dimitrios Kanoulas, Zhibin Li)</author>
      <guid isPermaLink="false">2502.06676v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Red Teaming: Breaking Policies Without Breaking Robots</title>
      <link>http://arxiv.org/abs/2502.06575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的问题：预测性红队策略，用于在非正常场景中评估和预测视觉运动策略的性能下降。作者开发了RoboART系统，使用生成式图像编辑技术修改常规观察，并用特定于政策的异常检测器来预测各种环境变化下的性能。&lt;h4&gt;背景&lt;/h4&gt;基于模仿学习训练出的视动策略能够执行复杂的操作任务，但在不同的光照、视觉干扰和物体位置等环境下表现出极高的脆弱性。这种脆弱性的表现方式难以预料且需要昂贵和耗时的实际硬件评估才能发现。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化红队策略（ART）管道RoboART，用于在不进行实际硬件测试的情况下预测特定策略的性能下降，并基于这些预测指导目标数据收集。&lt;h4&gt;方法&lt;/h4&gt;通过使用生成式图像编辑技术修改常规观察来改变不同的环境因素，并利用特定于政策的异常检测器根据修改后的观测值预测每种情况下的表现。此外，该系统还展示了如何在条件不利时进行有针对性的数据采集以改善基线性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在500多个硬件测试中以及12个不同的非正常条件下，RoboART能够准确地预测视觉运动策略的性能下降（真实成功率与预测之间的平均差异小于0.19）。此外，通过在条件不佳的情况下有针对性的数据收集进行微调后，基线性能得到了2-7倍的提升。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一种自动化评估和提高机器学习模型鲁棒性的有效方法，并且展示了如何通过这种方法改进现有系统的实际性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visuomotor policies trained via imitation learning are capable of performingchallenging manipulation tasks, but are often extremely brittle to lighting,visual distractors, and object locations. These vulnerabilities can dependunpredictably on the specifics of training, and are challenging to exposewithout time-consuming and expensive hardware evaluations. We propose theproblem of predictive red teaming: discovering vulnerabilities of a policy withrespect to environmental factors, and predicting the corresponding performancedegradation without hardware evaluations in off-nominal scenarios. In order toachieve this, we develop RoboART: an automated red teaming (ART) pipeline that(1) modifies nominal observations using generative image editing to varydifferent environmental factors, and (2) predicts performance under eachvariation using a policy-specific anomaly detector executed on editedobservations. Experiments across 500+ hardware trials in twelve off-nominalconditions for visuomotor diffusion policies demonstrate that RoboART predictsperformance degradation with high accuracy (less than 0.19 average differencebetween predicted and real success rates). We also demonstrate how predictivered teaming enables targeted data collection: fine-tuning with data collectedunder conditions predicted to be adverse boosts baseline performance by 2-7x.</description>
      <author>example@mail.com (Anirudha Majumdar, Mohit Sharma, Dmitry Kalashnikov, Sumeet Singh, Pierre Sermanet, Vikas Sindhwani)</author>
      <guid isPermaLink="false">2502.06575v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SIREN: Semantic, Initialization-Free Registration of Multi-Robot Gaussian Splatting Maps</title>
      <link>http://arxiv.org/abs/2502.06519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了用于多机器人高斯点云地图（GSplat）注册的SIREN方法，无需使用相机姿态、图像或初始子图转换进行初始化或融合。&lt;h4&gt;背景&lt;/h4&gt;现有的多机器人地图融合技术通常依赖于精确的相机位置信息和图像数据作为初始化步骤的一部分。然而，在缺乏这些先决条件的情况下，实现有效的地图融合是一项挑战。&lt;h4&gt;目的&lt;/h4&gt;通过利用语义信息来增强GSplat地图注册过程的能力，以提高地图融合的质量和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;{'第一点': 'SIREN使用语义识别特征丰富的本地地图区域，在这些地方可以更好地解决问题，不需要任何初始化。这克服了之前工作中通常需要的初始步骤的问题。', '第二点': 'SIREN通过使用稳健的语义特征来确定局部地图中高斯分布之间的候选对应关系，从而建立了稳健几何优化的基础，并粗略对齐3D高斯元从局部地图中提取出的数据。', '第三点': '利用新视角合成和基于语义的图像滤波器计算子图之间具有较高精度的非刚性变换，实现后续光度校准。该步骤使生成高保真的融合地图成为可能。'}&lt;h4&gt;主要发现&lt;/h4&gt;SIREN方法在真实世界数据集上优于竞争基线，在包括机械臂、无人机和四足机器人在内的广泛使用的机器人硬件平台上表现突出。&lt;h4&gt;结论&lt;/h4&gt;实验表明，与现有方法相比，特别是在最具挑战性的场景中，SIREN能够显著减少旋转误差（约90倍）、平移误差（约300倍）和缩放误差（约44倍）。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种用于在多机器人环境中融合GSplat地图的新技术——SIREN。这种方法利用语义信息来实现无需相机姿态、图像等先验知识的地图注册，展示了比现有方法更好的性能，并将在评审结束后公开源代码和项目页面链接。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SIREN for registration of multi-robot Gaussian Splatting (GSplat)maps, with zero access to camera poses, images, and inter-map transforms forinitialization or fusion of local submaps. To realize these capabilities, SIRENharnesses the versatility and robustness of semantics in three critical ways toderive a rigorous registration pipeline for multi-robot GSplat maps. First,SIREN utilizes semantics to identify feature-rich regions of the local mapswhere the registration problem is better posed, eliminating the need for anyinitialization which is generally required in prior work. Second, SIRENidentifies candidate correspondences between Gaussians in the local maps usingrobust semantic features, constituting the foundation for robust geometricoptimization, coarsely aligning 3D Gaussian primitives extracted from the localmaps. Third, this key step enables subsequent photometric refinement of thetransformation between the submaps, where SIREN leverages novel-view synthesisin GSplat maps along with a semantics-based image filter to compute ahigh-accuracy non-rigid transformation for the generation of a high-fidelityfused map. We demonstrate the superior performance of SIREN compared tocompeting baselines across a range of real-world datasets, and in particular,across the most widely-used robot hardware platforms, including a manipulator,drone, and quadruped. In our experiments, SIREN achieves about 90x smallerrotation errors, 300x smaller translation errors, and 44x smaller scale errorsin the most challenging scenes, where competing methods struggle. We willrelease the code and provide a link to the project page after the reviewprocess.</description>
      <author>example@mail.com (Ola Shorinwa, Jiankai Sun, Mac Schwager, Anirudha Majumdar)</author>
      <guid isPermaLink="false">2502.06519v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Inflatable Kirigami Crawlers</title>
      <link>http://arxiv.org/abs/2502.06466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了通过在热密封纺织品中引入折纸图案，创造出的充气式折纸爬行器。这种设计利用了切割模式来指导形态变化，使得充气后能产生非对称变形并触发局部旋转。&lt;h4&gt;背景&lt;/h4&gt;传统的空气囊膨胀时会形成对称的凸起和收缩。这项工作通过引入折叠与剪切图案（kirigami）解决了这一局限性。&lt;h4&gt;目的&lt;/h4&gt;创造一种新的充气式爬行器，利用折纸技术实现非对称变形并增强压缩能力。&lt;h4&gt;方法&lt;/h4&gt;在热密封纺织品上设计特殊的切割模式，并研究其膨胀时的非线性和几何特性。通过实验测试了这种结构在摩擦力和运动方向上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;充气式kirigami驱动器展示了一致且受控的收缩，伴随着不对称的局部变形；并且显示出对不同粗糙度表面的方向性摩擦属性。&lt;h4&gt;结论&lt;/h4&gt;引入多个通道和分段的设计增强了这些软体机器人的功能性，使其具有多样化的移动能力。这项研究证明了通过几何设计可以实现预测性的行走功能。&lt;h4&gt;翻译&lt;/h4&gt;折纸技术提供了一种通过利用切割模式的几何特性来引导形态变化的独特机会。本文介绍了一种可充气式折纸爬行器的设计方法，它在热密封纺织品中引入特定的切割图案，以实现在周期性气动驱动下的运动功能。传统气囊膨胀时会产生对称性的膨胀和收缩，而这种新的设计通过积累压缩力打破了这一对称性，提高了压缩比，并且当封闭边缘重叠自组装成一个具有新尺度特征的结构时，还会触发局部旋转动作。这使得充气式折纸驱动器能够表现出一致、受控的收缩以及不对称的离面变形现象。研究通过利用几何和材料非线性的特点赋予了基于纺织品的可充气式折纸驱动器可预测的行走功能，并详细描述了这些驱动器编程变形的特性和它们对摩擦力的影响，发现当被膨胀时，这种折叠结构展现出方向性异质摩擦特性：在运动方向上的摩擦系数更高，从而能够适应不同粗糙度表面的移动。此外，通过增加多个气道和分段设计进一步提升了充气式折纸驱动器的功能，创造了具有多种行走能力的软体机器人原型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kirigami offers unique opportunities for guided morphing by leveraging thegeometry of the cuts. This work presents inflatable kirigami crawlers createdby introducing cut patterns into heat-sealable textiles to achieve locomotionupon cyclic pneumatic actuation. Inflating traditional air pouches results insymmetric bulging and contraction. In inflated kirigami actuators, theaccumulated compressive forces uniformly break the symmetry, enhancecontraction compared to simple air pouches by two folds, and trigger localrotation of the sealed edges that overlap and self-assemble into an architectedsurface with emerging scale-like features. As a result, the inflatable kirigamiactuators exhibit a uniform, controlled contraction with asymmetric localizedout-of-plane deformations. This process allows us to harness the geometric andmaterial nonlinearities to imbue inflatable textile-based kirigami actuatorswith predictable locomotive functionalities. We thoroughly characterized theprogrammed deformations of these actuators and their impact on friction. Wefound that the kirigami actuators exhibit directional anisotropic frictionproperties when inflated, having higher friction coefficients against thedirection of the movement, enabling them to move across surfaces with varyingroughness. We further enhanced the functionality of inflatable kirigamiactuators by introducing multiple channels and segments to create functionalsoft robotic prototypes with versatile locomotion capabilities.</description>
      <author>example@mail.com (Burcu Seyidoğlu, Aida Parvaresh, Bahman Taherkhani, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06466v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding</title>
      <link>http://arxiv.org/abs/2502.06440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the 2025 IEEE International Conference  on Robotics and Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于纱夫理论的去中心化深度强化学习框架，旨在解决多智能体路径规划问题中的合作决策难题。&lt;h4&gt;背景&lt;/h4&gt;在已知环境下的多智能体路径规划（MAPF）问题是机器人大规模物流和运输部署的核心挑战。现有基于学习的方法依赖于有限视野下做出的短视决策，导致复杂场景中效率低下且难以实现有效协作。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过应用纱夫理论来促进分散式深度强化学习中的智能体之间的几何交叉依赖性学习，并进行紧密合作性的决策制定。&lt;h4&gt;方法&lt;/h4&gt;利用纱夫理论提供的局部观察达成全局共识的数学条件，论文将神经网络应用于近似模型中以在潜在空间内基于纱夫理论建模共识，并通过自我监督学习对其进行训练。在此过程中，除了正常的MAPF特征外，每个智能体还分布式地考虑了一种学习到的共识特性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在大规模且复杂的情境下显示出相对于现有最佳学习型MAPF规划器的重大改进，表现出了其优越性。&lt;h4&gt;结论&lt;/h4&gt;提出的基于纱夫理论的新框架能够有效提升多智能体路径规划问题中智能体之间的合作效率和全局共识达成能力，在各种模拟实验与真实世界机器人实验中均展现了卓越性能。&lt;h4&gt;翻译&lt;/h4&gt;该论文摘要讨论了一种新的解决MAPF问题的方法，采用去中心化的深度强化学习框架，并利用纱夫理论来改进智能体间的协作机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Multi-Agent Path Finding (MAPF) problem aims to determine the shortestand collision-free paths for multiple agents in a known, potentiallyobstacle-ridden environment. It is the core challenge for robotic deploymentsin large-scale logistics and transportation. Decentralized learning-basedapproaches have shown great potential for addressing the MAPF problems,offering more reactive and scalable solutions. However, existing learning-basedMAPF methods usually rely on agents making decisions based on a limited fieldof view (FOV), resulting in short-sighted policies and inefficient cooperationin complex scenarios. There, a critical challenge is to achieve consensus onpotential movements between agents based on limited observations andcommunications. To tackle this challenge, we introduce a new framework thatapplies sheaf theory to decentralized deep reinforcement learning, enablingagents to learn geometric cross-dependencies between each other through localconsensus and utilize them for tightly cooperative decision-making. Inparticular, sheaf theory provides a mathematical proof of conditions forachieving global consensus through local observation. Inspired by this, weincorporate a neural network to approximately model the consensus in latentspace based on sheaf theory and train it through self-supervised learning.During the task, in addition to normal features for MAPF as in previous works,each agent distributedly reasons about a learned consensus feature, leading toefficient cooperation on pathfinding and collision avoidance. As a result, ourproposed method demonstrates significant improvements over state-of-the-artlearning-based MAPF planners, especially in relatively large and complexscenarios, demonstrating its superiority over baselines in various simulationsand real-world robot experiments.</description>
      <author>example@mail.com (Shuhao Liao, Weihang Xia, Yuhong Cao, Weiheng Dai, Chengyang He, Wenjun Wu, Guillaume Sartoretti)</author>
      <guid isPermaLink="false">2502.06440v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occ-LLM: Enhancing Autonomous Driving with Occupancy-Based Large Language Models</title>
      <link>http://arxiv.org/abs/2502.06419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 2025 IEEE International Conference on Robotics and  Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了基于占用的大型语言模型(Occ-LLM)，这是将大型语言模型与重要表示方式集成的第一个尝试。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在机器人和自动驾驶领域取得了显著进展。然而，如何有效地利用这些模型处理动态场景中的物体是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过开发一种新的方法来解决这个问题，并展示这种创新方法在关键任务上的有效性。&lt;h4&gt;方法&lt;/h4&gt;{'Motion Separation Variational Autoencoder (MS-VAE)': '为了解决输入中动态对象和静态背景的分类不平衡问题，研究提出了一种基于先验知识的方法，可以区分移动物体与静止场景，并利用定制化的变分自编码器进行有效的信息处理。', 'Occ-LLM': '该方法通过将占用情况作为大型语言模型的有效输入来提高模型在动态轨迹识别和静态背景重建方面的性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;研究证明了Occ-LLM在4D占用预测、自我规划和基于占用的场景问答等关键任务上的有效性，其性能优于现有的最佳方法，在交并比(IoU)和平均交并比(mIoU)上分别提高了约6%和4%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明Occ-LLM具有变革性潜力，能够重塑机器人和自动驾驶领域的现有范式。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型在机器人技术和自主驾驶领域取得了显著进步。这项研究首次提出了一种基于占用的大型语言模型(Occ-LLM)，这是将大型语言模型与重要表示方式集成的第一个尝试。为有效地将占用情况作为输入传递给大型语言模型并解决与之相关的分类不平衡问题，我们提出了运动分离变分自编码器(MS-VAE)。这种方法利用先验知识在将数据输入定制化变分自编码器之前区分动态对象和静态场景。这种分割增强了模型集中于动态轨迹的同时有效地重建静态场景的能力。Occ-LLM的有效性已经在包括4D占用预测、自我规划和基于占用的场景问答在内的关键任务上得到了验证。全面评估表明，Occ-LLM显著超越了现有最先进方法，在4D占用预测任务中分别实现了约6%交并比(IoU)和4%平均交并比(mIoU)的增长。这些发现强调了Occ-LLM在重塑机器人技术与自主驾驶领域当前范式方面的变革潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have made substantial advancements in the fieldof robotic and autonomous driving. This study presents the firstOccupancy-based Large Language Model (Occ-LLM), which represents a pioneeringeffort to integrate LLMs with an important representation. To effectivelyencode occupancy as input for the LLM and address the category imbalancesassociated with occupancy, we propose Motion Separation Variational Autoencoder(MS-VAE). This innovative approach utilizes prior knowledge to distinguishdynamic objects from static scenes before inputting them into a tailoredVariational Autoencoder (VAE). This separation enhances the model's capacity toconcentrate on dynamic trajectories while effectively reconstructing staticscenes. The efficacy of Occ-LLM has been validated across key tasks, including4D occupancy forecasting, self-ego planning, and occupancy-based scene questionanswering. Comprehensive evaluations demonstrate that Occ-LLM significantlysurpasses existing state-of-the-art methodologies, achieving gains of about 6\%in Intersection over Union (IoU) and 4\% in mean Intersection over Union (mIoU)for the task of 4D occupancy forecasting. These findings highlight thetransformative potential of Occ-LLM in reshaping current paradigms withinrobotic and autonomous driving.</description>
      <author>example@mail.com (Tianshuo Xu, Hao Lu, Xu Yan, Yingjie Cai, Bingbing Liu, Yingcong Chen)</author>
      <guid isPermaLink="false">2502.06419v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>An Automated Machine Learning Framework for Surgical Suturing Action Detection under Class Imbalance</title>
      <link>http://arxiv.org/abs/2502.06407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于自动化机器学习的方法，用于腹腔镜手术训练中的实时手术动作检测，并提供了可解释的输出。&lt;h4&gt;背景&lt;/h4&gt;在腹腔镜手术培训和评估中，实时检测外科操作及其可解释性对于自动化的即时反馈和技能发展至关重要。这需要能够处理不同技术水平外科医生的数据不平衡问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种快速部署的方法来实现基于机器学习技术的手术动作识别系统，该方法可以提供实时、可靠的反馈并促进技能培训。&lt;h4&gt;方法&lt;/h4&gt;使用自动化机器学习方法，通过收集经验丰富和培训中的外科医生的操作数据进行分析。该方法部分地考虑了模型透明度的需求，以满足医疗应用中可靠性的要求。&lt;h4&gt;主要发现&lt;/h4&gt;与深度学习方法相比，传统机器学习模型不仅有助于高效快速部署，并且在解释性方面具有明显优势。实验结果表明这种方法有潜力提供实时手术训练环境中的快速、可靠的检测。&lt;h4&gt;结论&lt;/h4&gt;通过自动化机器学习的方法，可以实现腹腔镜手术训练中准确的实时动作识别，同时保持良好的可解释性和预测稳定性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在腹腔镜外科手术培训和评估过程中，实时检测外科操作并提供可解释性输出对于自动化的即时反馈和技能发展至关重要。这种能力将能够推动机器引导的培训系统的开发。本文提出了一种快速部署方法，该方法基于从经验丰富的外科医生和受训人员处收集的外科动作数据，并利用自动化机器学习技术。所提出的这种方法有效地解决了高度不平衡类别分布的问题，确保了在不同水平外科医生中的稳健预测。此外，我们的方法部分地包含了模型透明度，满足了医疗应用中的可靠性要求。与深度学习的方法相比，传统的机器学习模型不仅促进了高效的快速部署，还提供了显著的解释性优势。通过实验，本研究展示了该方法具有提供手术训练环境中的即时、可靠和有效检测的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In laparoscopy surgical training and evaluation, real-time detection ofsurgical actions with interpretable outputs is crucial for automated andreal-time instructional feedback and skill development. Such capability wouldenable development of machine guided training systems. This paper presents arapid deployment approach utilizing automated machine learning methods, basedon surgical action data collected from both experienced and trainee surgeons.The proposed approach effectively tackles the challenge of highly imbalancedclass distributions, ensuring robust predictions across varying skill levels ofsurgeons. Additionally, our method partially incorporates model transparency,addressing the reliability requirements in medical applications. Compared todeep learning approaches, traditional machine learning models not onlyfacilitate efficient rapid deployment but also offer significant advantages ininterpretability. Through experiments, this study demonstrates the potential ofthis approach to provide quick, reliable and effective real-time detection insurgical training environments</description>
      <author>example@mail.com (Baobing Zhang, Paul Sullivan, Benjie Tang, Ghulam Nabi, Mustafa Suphi Erden)</author>
      <guid isPermaLink="false">2502.06407v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>When Data Manipulation Meets Attack Goals: An In-depth Survey of Attacks for VLMs</title>
      <link>http://arxiv.org/abs/2502.06390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文综述了针对Vision-Language Models (VLMs)的攻击策略，按照目标将这些攻击分为越狱、伪装和利用三类，并详细介绍了数据操纵的方法。同时概述了相应的防御机制以减轻脆弱性。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型（VLMs）因其能够有效整合和处理文本与图像信息而在近年来得到了广泛应用，并且显著提高了场景感知和机器人等领域的性能。但这些应用也带来了安全和隐私方面的重要问题，需要深入研究来评估潜在的漏洞。&lt;h4&gt;目的&lt;/h4&gt;系统地调查针对VLM系统的攻击策略及其防御措施，并提出一个有力的分类体系以更好地理解不同类型的攻击之间的联系与区别&lt;h4&gt;方法&lt;/h4&gt;对现有文献进行总结性分析，根据不同的攻击目标将攻击方式分类为越狱、伪装和利用三类。同时详细描述了各种用于操纵VLM数据的方法。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的针对视觉语言模型（VLMs）的攻击分类法，并且概述了一系列评价指标来全面地刻画不同类型的攻击在VLM中的特征和影响&lt;h4&gt;结论&lt;/h4&gt;展望未来的研究方向，强调持续探索以进一步增强VLM的安全性和鲁棒性的重要性。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言模型由于其出色的能力整合并处理文本与图像信息，在最近几年中获得了极大的关注。这种能力的融合显著提升了多种应用领域的表现，比如场景理解和机器人技术。然而，部署这些模型也带来了重要的安全和隐私问题，需要进行广泛的研究来评估它们潜在的安全漏洞。在这项工作中，我们提供了一种深入的针对VLM系统的攻击策略综述。基于不同的目标将这些攻击分为“越狱”、“伪装”和“利用”，同时详细描述了用于数据操纵的各种方法。此外还概述了一些被提出的防御机制，以减轻这些脆弱性带来的影响。通过辨别各种类型的攻击之间的重要关联与差异，我们提出了一个有力的分类体系来总结VLM系统的安全威胁。另外也概括了一套评价指标，全面地刻画不同类型的攻击在视觉语言模型中的特征和潜在影响。最后讨论了未来可能的研究方向以进一步提高VLM的安全性和鲁棒性，并强调这一研究领域的持续重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have gained considerable prominence in recentyears due to their remarkable capability to effectively integrate and processboth textual and visual information. This integration has significantlyenhanced performance across a diverse spectrum of applications, such as sceneperception and robotics. However, the deployment of VLMs has also given rise tocritical safety and security concerns, necessitating extensive research toassess the potential vulnerabilities these VLM systems may harbor. In thiswork, we present an in-depth survey of the attack strategies tailored for VLMs.We categorize these attacks based on their underlying objectives - namelyjailbreak, camouflage, and exploitation - while also detailing the variousmethodologies employed for data manipulation of VLMs. Meanwhile, we outlinecorresponding defense mechanisms that have been proposed to mitigate thesevulnerabilities. By discerning key connections and distinctions among thediverse types of attacks, we propose a compelling taxonomy for VLM attacks.Moreover, we summarize the evaluation metrics that comprehensively describe thecharacteristics and impact of different attacks on VLMs. Finally, we concludewith a discussion of promising future research directions that could furtherenhance the robustness and safety of VLMs, emphasizing the importance ofongoing exploration in this critical area of study. To facilitate communityengagement, we maintain an up-to-date project page, accessible at:https://github.com/AobtDai/VLM_Attack_Paper_List.</description>
      <author>example@mail.com (Aobotao Dai, Xinyu Ma, Lei Chen, Songze Li, Lin Wang)</author>
      <guid isPermaLink="false">2502.06390v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Proprioceptive Origami Manipulator</title>
      <link>http://arxiv.org/abs/2502.06362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型的自感式腱驱动折纸操作器，该操作器通过使用导电线作为执行机构，并将其与本体感觉传感功能多路复用，以实现对连续管状结构的良好控制。&lt;h4&gt;背景&lt;/h4&gt;现有的基于视觉系统的柔性机械臂在复杂和杂乱环境中的应用受到限制。为了克服这一局限性，研究人员开始探索一种无需外部传感器的帮助就能精确感知自身状态的方案。&lt;h4&gt;目的&lt;/h4&gt;开发出一个具有本体感觉能力的折纸操作器，旨在为连续管状结构提供闭合回路控制的基础，并保留其固有的灵活性。&lt;h4&gt;方法&lt;/h4&gt;使用导电线作为执行机构和传感器。通过测量导电线长度变化引起的电阻变化来实现对操纵器姿态的感知。该信息被输入到前向动力学模型中，以重建操作器配置和末端效应器位置。&lt;h4&gt;主要发现&lt;/h4&gt;将导电丝用作既可驱动又可感知的手动肌腱，并将其应用于管状折纸结构作为连续性机械臂的原型设计，通过电阻变化来实现对其状态的有效监控。&lt;h4&gt;结论&lt;/h4&gt;这种新型的操作方式不仅为复杂环境下的机器人操作提供了新的可能性，同时也展示了如何在保证灵活性的同时提高对软体机器人的控制精度。&lt;h4&gt;翻译&lt;/h4&gt;折纸提供了一个多功能框架，用于设计可变结构和软机器人，通过利用折叠的几何形状。管状折纸结构可以充当连续操纵器，平衡柔韧性和强度。然而，精确控制这种操作器通常需要依赖基于视觉的系统，这限制了它们在复杂且杂乱环境中的应用。在这里，我们提出了一种本体感觉腱驱动折纸操作器，无需牺牲其灵活性。使用导电线作为执行机构，我们将它们与本体感知传感功能多路复用。活化长度的变化在线的有效电阻中反映出来，可以简单电路测量。我们把这种变化的电阻与肌腱长度相关联。输入此信息到前向动力学模型来重建操作器配置和末端效应器位置。这个平台为连续折纸操纵器的闭合回路控制提供了基础，并保留了其固有的灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Origami offers a versatile framework for designing morphable structures andsoft robots by exploiting the geometry of folds. Tubular origami structures canact as continuum manipulators that balance flexibility and strength. However,precise control of such manipulators often requires reliance on vision-basedsystems that limit their application in complex and cluttered environments.Here, we propose a proprioceptive tendon-driven origami manipulator withoutcompromising its flexibility. Using conductive threads as actuating tendons, wemultiplex them with proprioceptive sensing capabilities. The change in theactive length of the tendons is reflected in their effective resistance, whichcan be measured with a simple circuit. We correlated the change in theresistance to the lengths of the tendons. We input this information into aforward kinematic model to reconstruct the manipulator configuration andend-effector position. This platform provides a foundation for the closed-loopcontrol of continuum origami manipulators while preserving their inherentflexibility.</description>
      <author>example@mail.com (Aida Parvaresh, Arman Goshtasbi, Jonathan Andres Tirado Rosero, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06362v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>DATCloud: A Model-Driven Framework for Multi-Layered Data-Intensive Architectures</title>
      <link>http://arxiv.org/abs/2501.18257v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DATCloud是一个框架，用于多层架构的建模、验证和改进，旨在解决数据密集型系统的需求。&lt;h4&gt;背景&lt;/h4&gt;复杂的数据密集型系统的灵活性、可扩展性和效率要求促使了像DATCloud这样的模型驱动框架的发展。&lt;h4&gt;目的&lt;/h4&gt;通过遵循ISO/IEC/IEEE 42010标准，DATCloud利用结构化和行为元模型以及特定领域的图形语言（DSL）来增强重用性和利益相关者之间的沟通。&lt;h4&gt;方法&lt;/h4&gt;DATCloud采用模型驱动的方法，并使用结构化和行为元模型及特定领域的图形语言进行架构设计。&lt;h4&gt;主要发现&lt;/h4&gt;在Uffizi画廊的VASARI系统中的初步验证显示，与手动方法相比，建模时间减少了40%，灵活性提高了32%。&lt;h4&gt;结论&lt;/h4&gt;虽然DATCloud已经展示了其有效性，但它仍是一个正在进行的工作，在未来将计划集成先进的代码生成工具、仿真工具和特定领域的扩展功能来进一步增强其实用性。&lt;h4&gt;翻译&lt;/h4&gt;多层数据密集型系统的复杂性要求确保灵活性、可扩展性和效率的框架。DATCloud是一种模型驱动框架，旨在促进多层架构的建模、验证和改进，解决可扩展性、模块化及现实世界需求的问题。通过遵循ISO/IEC/IEEE 42010标准，DATCloud利用结构和行为元模型以及图形特定领域语言（DSL）来提高重用性和利益相关者之间的沟通。初步在Uffizi画廊的VASARI系统中的验证表明，与手动方法相比，建模时间减少了40%，灵活性提高了32%。尽管有效，但DATCloud仍是一个正在进行的工作，在未来计划集成先进的代码生成工具、仿真工具和特定领域的扩展功能，以进一步增强其在医疗保健、智慧城市和其他数据密集型领域应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity of multi-layered, data-intensive systems demands frameworksthat ensure flexibility, scalability, and efficiency. DATCloud is amodel-driven framework designed to facilitate the modeling, validation, andrefinement of multi-layered architectures, addressing scalability, modularity,and real-world requirements. By adhering to ISO/IEC/IEEE 42010 standards,DATCloud leverages structural and behavioral meta-models and graphicaldomain-specific languages (DSLs) to enhance reusability and stakeholdercommunication. Initial validation through the VASARI system at the UffiziGallery demonstrates a 40% reduction in modeling time and a 32% improvement inflexibility compared to manual methods. While effective, DATCloud is a work inprogress, with plans to integrate advanced code generation, simulation tools,and domain-specific extensions to further enhance its capabilities forapplications in healthcare, smart cities, and other data-intensive domains.</description>
      <author>example@mail.com (Moamin Abughazala, Henry Muccini)</author>
      <guid isPermaLink="false">2501.18257v2</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Weld n'Cut: Automated fabrication of inflatable fabric actuators</title>
      <link>http://arxiv.org/abs/2502.06361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种用于制造纺织基轻质耐用充气软执行器的自动化平台Weld n'Cut，该平台结合了超声波焊接和振荡刀具技术。&lt;h4&gt;背景&lt;/h4&gt;现有的纺织品基充气软执行器在康复机器人和个人性能增强设备中广泛使用。然而，这些执行器的制造过程通常涉及多步且容易出错。&lt;h4&gt;目的&lt;/h4&gt;为了提高充气软执行器的生产精度和性能，引入了一种自动化制造流程Weld n'Cut平台。&lt;h4&gt;方法&lt;/h4&gt;该平台采用超声波焊接技术将纺织层融合在一起，并使用振荡刀具进行精确切割。这样可以创建具有任意复杂几何形状的充气结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，无论材料和设计如何，该制造流程都能有效地生产复杂的充气软执行器。&lt;h4&gt;结论&lt;/h4&gt;Weld n'Cut平台提供了一种准确、高效的自动化方法来制造复杂的纺织基充气软执行器。&lt;h4&gt;翻译&lt;/h4&gt;轻质耐用的基于纺织品的可充气软执行器在软机器人领域，特别是在康复辅助和提高高要求工作的人类性能方面得到广泛应用。这些执行器的传统制造过程通常包括多个步骤：使用热压机将热熔性织物层融合在一起，并用防粘隔离层定义内部腔室。这些隔离层必须在制造后小心去除，这使得过程既耗时又容易出错。为了解决这些问题并提高可充气执行器的精度和性能，我们引入了Weld n'Cut平台——一个开源、自动化制造流程，结合了超声波焊接技术用于融合纺织层，并使用振荡刀具进行精确切割，从而能够创造出具有复杂几何形状的充气结构。我们在各种材料和设计中展示了该机器的表现力及其处理任意复杂几何形状的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lightweight, durable textile-based inflatable soft actuators are widely usedin soft robotics, particularly for wearable robots in rehabilitation and inenhancing human performance in demanding jobs. Fabricating these actuatorstypically involves multiple steps: heat-sealable fabrics are fused with a heatpress, and non-stick masking layers define internal chambers. These layers mustbe carefully removed post-fabrication, often making the process labor-intensiveand prone to errors. To address these challenges and improve the accuracy andperformance of inflatable actuators, we introduce the Weld n'Cut platform-anopen-source, automated manufacturing process that combines ultrasonic weldingfor fusing textile layers with an oscillating knife for precise cuts, enablingthe creation of complex inflatable structures. We demonstrate the machine'sperformance across various materials and designs with arbitrarily complexgeometries.</description>
      <author>example@mail.com (Arman Goshtasbi, Burcu Seyidoğlu, Saravana Prashanth Murali Babu, Aida Parvaresh, Cao Danh Do, Ahmad Rafsanjani)</author>
      <guid isPermaLink="false">2502.06361v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occlusion-Aware Contingency Safety-Critical Planning for Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2502.06359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种针对动态和遮挡环境下的自动驾驶车辆实时安全规划的新方法。&lt;h4&gt;背景&lt;/h4&gt;在动态且被遮挡的环境中，确保自动驾驶汽车的安全驾驶同时保持出行效率是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一个基于风险评估的可实现性分析的方法，该方法能够计算出被遮挡车辆的速度边界，并将其整合到非线性规划框架中，以实现实时安全路径生成。&lt;h4&gt;方法&lt;/h4&gt;通过可达性分析进行风险评估，计算被遮挡车辆的前进可达集来量化动态速度界限。这些速度界限被纳入双凸非线性编程（NLP）形式化过程中，以便在退步时间窗口规划框架内同时优化探索和回退路径。为了促进实时优化并确保轨迹之间的协调，采用共识交替方向乘子法（ADMM）将双凸NLP问题分解为低维凸子问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究和现实世界实验验证了所提出方法的有效性，在被遮挡的交叉路口下展示了增强的安全性和提高的出行效率，能够在不同障碍物条件下实现实时安全路径生成。&lt;h4&gt;结论&lt;/h4&gt;该方法在动态遮挡环境中能够有效提升自动驾驶车辆的安全性能并改善其出行效率。&lt;h4&gt;翻译&lt;/h4&gt;确保自主驾驶车辆在动态且被遮挡的环境中的安全行驶同时保持旅行效率是一项关键挑战。本文提出了一种实时感知遮挡情况下的应急安全规划策略，利用可达性分析进行风险评估，并计算出遮挡物的速度边界以优化路径决策。通过实验验证了该方法的有效性和实用性，在保证安全性的同时提升了出行效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safe driving while maintaining travel efficiency for autonomousvehicles in dynamic and occluded environments is a critical challenge. Thispaper proposes an occlusion-aware contingency safety-critical planning approachfor real-time autonomous driving in such environments. Leveraging reachabilityanalysis for risk assessment, forward reachable sets of occluded phantomvehicles are computed to quantify dynamic velocity boundaries. These velocityboundaries are incorporated into a biconvex nonlinear programming (NLP)formulation, enabling simultaneous optimization of exploration and fallbacktrajectories within a receding horizon planning framework. To facilitatereal-time optimization and ensure coordination between trajectories, we employthe consensus alternating direction method of multipliers (ADMM) to decomposethe biconvex NLP problem into low-dimensional convex subproblems. Theeffectiveness of the proposed approach is validated through simulation studiesand real-world experiments in occluded intersections. Experimental resultsdemonstrate enhanced safety and improved travel efficiency, enabling real-timesafe trajectory generation in dynamic occluded intersections under varyingobstacle conditions. A video showcasing the experimental results is availableat https://youtu.be/CHayG7NChqM.</description>
      <author>example@mail.com (Lei Zheng, Rui Yang, Minzhe Zheng, Zengqi Peng, Michael Yu Wang, Jun Ma)</author>
      <guid isPermaLink="false">2502.06359v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Outlier-robust Rotation Estimation by Stereographic Projection</title>
      <link>http://arxiv.org/abs/2502.06337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;旋转估计在计算机视觉和机器人任务中起着基础性作用，但面对大量包含众多异常值（即不匹配）和噪声的数据集时，高效地进行旋转估计是一大挑战。本文提出了一种有效且鲁棒的旋转估计算法。&lt;h4&gt;背景&lt;/h4&gt;当前许多针对这一问题设计的方法由于计算时间长及陷入局部最优的风险而难以实际应用。&lt;h4&gt;目的&lt;/h4&gt;研发一种能够快速、准确解决大规模数据集上旋转估计任务的新方法。&lt;h4&gt;方法&lt;/h4&gt;{'步骤1': '首先研究仅涉及旋转轴的几何约束条件', '步骤2': '然后采用立体投影和空间投票技术确定旋转轴与角度'}&lt;h4&gt;主要发现&lt;/h4&gt;该算法能够高效地获得最优旋转估计，并且可以同时估计多个旋转，实验证明其在准确性和效率上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过使用GPU辅助计算，在处理大量数据（例如10^6个点）和高异常比率（90%的异常值率）的情况下，该算法能在0.07秒内完成任务，且角误差仅为0.01度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rotation estimation plays a fundamental role in many computer vision androbot tasks. However, efficiently estimating rotation in large inputscontaining numerous outliers (i.e., mismatches) and noise is a recognizedchallenge. Many robust rotation estimation methods have been designed toaddress this challenge. Unfortunately, existing methods are often inapplicabledue to their long computation time and the risk of local optima. In this paper,we propose an efficient and robust rotation estimation method. Specifically,our method first investigates geometric constraints involving only the rotationaxis. Then, it uses stereographic projection and spatial voting techniques toidentify the rotation axis and angle. Furthermore, our method efficientlyobtains the optimal rotation estimation and can estimate multiple rotationssimultaneously. To verify the feasibility of our method, we conduct comparativeexperiments using both synthetic and real-world data. The results show that,with GPU assistance, our method can solve large-scale ($10^6$ points) andseverely corrupted (90\% outlier rate) rotation estimation problems within 0.07seconds, with an angular error of only 0.01 degrees, which is superior toexisting methods in terms of accuracy and efficiency.</description>
      <author>example@mail.com (Taosi Xu, Yinlong Liu, Xianbo Wang, Zhi-Xin Yang)</author>
      <guid isPermaLink="false">2502.06337v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map</title>
      <link>http://arxiv.org/abs/2502.06292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于优化的SLAM方法Occupancy-SLAM，该方法能够同时联合优化机器人的轨迹和占用地图。通过参数化的地图表示，它实现了机器人姿态与不同单元顶点处占据值的同时优化。&lt;h4&gt;背景&lt;/h4&gt;在特征基础的SLAM问题中，姿势和特征的同时优化已经被广泛研究并证明可以产生更准确的结果。然而，在非特征基础上的地图和机器人的轨迹联合优化的研究较少。占用图因其能够有效地区分障碍物、自由空间以及未知区域而被广泛应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于参数化地图表示的方法，通过同时对机器人姿态与占据值进行优化来改善机器人在环境中的定位问题。&lt;h4&gt;方法&lt;/h4&gt;提出Occupancy-SLAM方法，在该方法中，机器人轨迹和占用图可以通过参数化的地图表示一起被联合优化。这种方法的关键创新在于能够同时处理机器人位置的确定以及空间单元上的占据值计算。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真数据和实际2D激光雷达数据集进行评估后发现，所提出的方法在计算时间接近的情况下比现有技术获得了更准确的机器人轨迹和占用图结果。初步研究还表明，在3D场景下该方法同样具有更高的准确性。&lt;h4&gt;结论&lt;/h4&gt;Occupancy-SLAM是一种创新性地联合优化机器人姿态与非特征地图的新方法，并且已经在2D及3D环境中显示出了强大的性能，未来有望在实际应用中得到广泛应用。&lt;h4&gt;翻译&lt;/h4&gt;共同优化姿势和基于特征的地图已广泛研究并证明可以产生更准确的结果。然而，同时优化姿势和非特征基础地图的研究仍然有限。因为它们能够有效地将空间划分为障碍物、自由区域以及未知区域，所以占用图被用作环境表示的常见方法。本文提出了一种新的SLAM方法Occupancy-SLAM，它通过参数化地图表示实现了机器人的轨迹与占用图的同时优化。这种方法的关键创新在于可以在同一过程中进行机器人姿势和占据值的不同单元顶点上的同时优化。使用模拟数据及实际2D激光雷达数据集的评估显示，在计算时间相近的情况下所提出的该方法比现有的技术能够产生更准确的结果，这在三维场景中的初步研究中也得到了验证，进一步证明了其在未来3D应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint optimization of poses and features has been extensively studied anddemonstrated to yield more accurate results in feature-based SLAM problems.However, research on jointly optimizing poses and non-feature-based mapsremains limited. Occupancy maps are widely used non-feature-based environmentrepresentations because they effectively classify spaces into obstacles, freeareas, and unknown regions, providing robots with spatial information forvarious tasks. In this paper, we propose Occupancy-SLAM, a noveloptimization-based SLAM method that enables the joint optimization of robottrajectory and the occupancy map through a parameterized map representation.The key novelty lies in optimizing both robot poses and occupancy values atdifferent cell vertices simultaneously, a significant departure from existingmethods where the robot poses need to be optimized first before the map can beestimated. Evaluations using simulations and practical 2D laser datasetsdemonstrate that the proposed approach can robustly obtain more accurate robottrajectories and occupancy maps than state-of-the-art techniques withcomparable computational time. Preliminary results in the 3D case furtherconfirm the potential of the proposed method in practical 3D applications,achieving more accurate results than existing methods.</description>
      <author>example@mail.com (Yingyu Wang, Liang Zhao, Shoudong Huang)</author>
      <guid isPermaLink="false">2502.06292v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>CT-UIO: Continuous-Time UWB-Inertial-Odometer Localization Using Non-Uniform B-spline with Fewer Anchors</title>
      <link>http://arxiv.org/abs/2502.06287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The codebase and datasets will be open-sourced at  https://github.com/JasonSun623/CT-UIO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于非均匀B样条框架的高效UWB-惯性里程计定位系统，适用于能量受限条件下使用较少基站的情况。&lt;h4&gt;背景&lt;/h4&gt;近年来，在能量限制条件下利用少量锚点进行超宽带（UWB）定位引起了广泛的研究兴趣。然而，大多数现有方法依赖于离散时间表示和光滑先验来推断机器人的运动状态，并且在保证多传感器数据同步方面面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的UWB-惯性里程计定位系统，能够在能量受限条件下使用较少的基站，同时确保高精度和鲁棒性能。&lt;h4&gt;方法&lt;/h4&gt;{'非均匀B样条框架': '引入了基于自适应结点跨度调整策略的非均匀连续时间轨迹表示方法，能够根据运动速度动态调整控制点。', '改进的EKF滤波器': '提出了一种基于创新性的自适应估计改进的扩展卡尔曼滤波器（EKF），以提供短期准确的运动先验。', '虚拟锚生成法': '针对少量基站条件下实现完全可观测UWB定位系统的挑战，提出了基于多假设的虚拟锚生成方法。', 'CT-UIO因子图': '在系统后端采用了一种带有自适应滑动窗口的CT-UIO因子图进行全局轨迹估计。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的系统具有高精度和稳健性，在走廊和展览厅数据集上的表现尤为出色。&lt;h4&gt;结论&lt;/h4&gt;该研究为能量受限条件下使用较少基站实现UWB定位提供了一种有效的方法，并将公开源代码和数据集供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到，近年来在能量限制条件下的超宽带（UWB）定位引起了广泛的研究兴趣，特别是在使用少量锚点的情况下。然而，大多数现有方法依赖于离散时间表示和光滑先验来推断机器人的运动状态，并且通常难以确保多传感器数据的同步。本文提出了一种利用非均匀B样条框架实现高效UWB-惯性里程计定位系统的方案，在能量受限条件下可以使用较少基站进行定位。为了适应连续时间轨迹的表现，我们引入了一个基于移动速度调整控制点的自适应结点跨度调整策略。此外，为了解决在少量锚点条件下难以构建完全可观测的UWB定位系统的问题，提出了基于多假设生成虚拟锚的方法。通过提出一种采用CT-UIO因子图和自适应滑动窗口进行全局轨迹估计后端方法来实现高效的传感器数据融合。实验结果表明所提出的系统的准确性和鲁棒性非常高，并且开源代码库与数据集将会在 https://github.com/JasonSun623/CT-UIO 上发布供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultra-wideband (UWB) based positioning with fewer anchors has attractedsignificant research interest in recent years, especially underenergy-constrained conditions. However, most existing methods rely ondiscrete-time representations and smoothness priors to infer a robot's motionstates, which often struggle with ensuring multi-sensor data synchronization.In this paper, we present an efficient UWB-Inertial-odometer localizationsystem, utilizing a non-uniform B-spline framework with fewer anchors. Unliketraditional uniform B-spline-based continuous-time methods, we introduce anadaptive knot-span adjustment strategy for non-uniform continuous-timetrajectory representation. This is accomplished by adjusting control pointsdynamically based on movement speed. To enable efficient fusion of IMU andodometer data, we propose an improved Extended Kalman Filter (EKF) withinnovation-based adaptive estimation to provide short-term accurate motionprior. Furthermore, to address the challenge of achieving a fully observableUWB localization system under few-anchor conditions, the Virtual Anchor (VA)generation method based on multiple hypotheses is proposed. At the backend, wepropose a CT-UIO factor graph with an adaptive sliding window for globaltrajectory estimation. Comprehensive experiments conducted on corridor andexhibition hall datasets validate the proposed system's high precision androbust performance. The codebase and datasets of this work will be open-sourcedat https://github.com/JasonSun623/CT-UIO.</description>
      <author>example@mail.com (Jian Sun, Wei Sun, Genwei Zhang, Kailun Yang, Song Li, Xiangqi Meng, Na Deng, Chongbin Tan)</author>
      <guid isPermaLink="false">2502.06287v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Interaction-aware Conformal Prediction for Crowd Navigation</title>
      <link>http://arxiv.org/abs/2502.06221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WAFR 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '介绍了一种名为交互感知符合预测（ICP）的方法，用于交替进行不确定性感知的机器人运动规划和基于决策的人类运动不确定量化。通过实验验证了ICP在导航效率、社交意识和不确定性量化之间取得了良好的平衡，并展示了其在不同人群密度下的泛化能力。', '背景': '在群体导航中，机器人的运动计划需要考虑人类移动的不确定性，而这种不确定性又依赖于机器人的运动规划方案。', '目的': '提出一种方法来解决机器人与人类交互中的不确定性和决策相关性问题。', '方法': 'ICP由轨迹预测器、模型预测控制器、人类模拟器和符合预测模块组成。通过加入概率安全性的时间间隔半径，使用计划的机器人移动条件下的校准数据集收集人行轨迹，量化轨迹预测误差。', '主要发现': '实验表明ICP在导航效率、社交意识以及不确定性量化方面表现优越，并能很好地适应各种人群密度的任务。', '结论': 'ICP具备快速运行时间和高效内存使用的特点，使其适用于现实世界的应用。代码可在GitHub上获取（https://github.com/tedhuang96/icp）', '翻译': '在群体导航过程中，机器人的运动计划需要考虑人类移动的不确定性，并且这种不确定性又依赖于机器人自身的运动规划方案。为解决此问题引入了交互感知符合预测ICP方法，用于交替进行不确定性感知的机器人运动规划和基于决策的人类运动不确定量化。经过实验验证，ICP在导航效率、社交意识以及不确定性量化方面表现卓越，适应各种人群密度的任务，并且具有快速运行时间和高效内存使用的特点，使其适用于现实世界的应用。该研究已开源（https://github.com/tedhuang96/icp）'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; During crowd navigation, robot motion plan needs to consider human motionuncertainty, and the human motion uncertainty is dependent on the robot motionplan. We introduce Interaction-aware Conformal Prediction (ICP) to alternateuncertainty-aware robot motion planning and decision-dependent human motionuncertainty quantification. ICP is composed of a trajectory predictor topredict human trajectories, a model predictive controller to plan robot motionwith confidence interval radii added for probabilistic safety, a humansimulator to collect human trajectory calibration dataset conditioned on theplanned robot motion, and a conformal prediction module to quantify trajectoryprediction error on the decision-dependent calibration dataset. Crowdnavigation simulation experiments show that ICP strikes a good balance ofperformance among navigation efficiency, social awareness, and uncertaintyquantification compared to previous works. ICP generalizes well to navigationtasks under various crowd densities. The fast runtime and efficient memoryusage make ICP practical for real-world applications. Code is available athttps://github.com/tedhuang96/icp.</description>
      <author>example@mail.com (Zhe Huang, Tianchen Ji, Heling Zhang, Fatemeh Cheraghi Pouria, Katherine Driggs-Campbell, Roy Dong)</author>
      <guid isPermaLink="false">2502.06221v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Improved Extrinsic Calibration of Acoustic Cameras via Batch Optimization</title>
      <link>http://arxiv.org/abs/2502.06196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and is going to be presented at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个用于声学摄像机的自动标定技术，该技术使用同时包含视觉和听觉标记的校准板来确定麦克风阵列中每个麦克风的位置。&lt;h4&gt;背景&lt;/h4&gt;声学摄像机在实践中有着广泛的应用。为了融合视觉与听觉测量数据，准确且可靠的麦克风阵列与视觉传感器之间的外参标定至关重要。现有的方法要么需要已知麦克风阵列的几何结构信息，要么依赖于网格搜索策略，这导致迭代速度慢或收敛性差。&lt;h4&gt;目的&lt;/h4&gt;提出一种不需要先验知识并且能够快速、准确地进行外参标定的方法。&lt;h4&gt;方法&lt;/h4&gt;使用同时包含视觉和听觉标记的校准板来自动识别每个麦克风的位置，并将外参标定问题形式化为一个非线性最小二乘问题，采用批量优化策略求解。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法提高了声学摄像机外参数标定的准确性和鲁棒性，在精度和稳定性上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的数值模拟和实际实验验证了该技术的有效性，并将相关代码与数据开源以供社区使用（https://github.com/AISLAB-sustech/AcousticCamera）。&lt;h4&gt;翻译&lt;/h4&gt;声学摄像机在实践中有着广泛的应用。为了融合视觉与听觉测量数据，准确且可靠的麦克风阵列与视觉传感器之间的外参标定至关重要。现有的方法要么需要已知麦克风阵列的几何结构信息，要么依赖于网格搜索策略，这导致迭代速度慢或收敛性差。为了解决这些问题，在本文中我们提出了一种使用同时包含视觉和听觉标记校准板的自动标定技术来确定每个麦克风的位置。我们将外参标定问题（即麦克风与视觉传感器之间）形式化为非线性最小二乘问题，并采用批量优化策略求解相关问题。广泛的数值模拟以及实际实验表明，所提出的方法提高了声学摄像机外参数标定的准确性和鲁棒性，在精度和稳定性上优于现有方法。为了使社区受益，我们开源了所有代码与数据（https://github.com/AISLAB-sustech/AcousticCamera）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Acoustic cameras have found many applications in practice. Accurate andreliable extrinsic calibration of the microphone array and visual sensorswithin acoustic cameras is crucial for fusing visual and auditory measurements.Existing calibration methods either require prior knowledge of the microphonearray geometry or rely on grid search which suffers from slow iteration speedor poor convergence. To overcome these limitations, in this paper, we proposean automatic calibration technique using a calibration board with both visualand acoustic markers to identify each microphone position in the camera frame.We formulate the extrinsic calibration problem (between microphones and thevisual sensor) as a nonlinear least squares problem and employ a batchoptimization strategy to solve the associated problem. Extensive numericalsimulations and realworld experiments show that the proposed method improvesboth the accuracy and robustness of extrinsic parameter calibration foracoustic cameras, in comparison to existing methods. To benefit the community,we open-source all the codes and data athttps://github.com/AISLAB-sustech/AcousticCamera.</description>
      <author>example@mail.com (Zhi Li, Jiang Wang, Xiaoyang Li, He Kong)</author>
      <guid isPermaLink="false">2502.06196v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Calibration of Multiple Asynchronous Microphone Arrays using Hybrid TDOA</title>
      <link>http://arxiv.org/abs/2502.06195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and is going to be presented at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的声学传感系统校准方法，该方法结合了相邻声音事件之间的时间差测量（TDOAS），以提高多麦克风阵列系统的定位和追踪性能。&lt;h4&gt;背景&lt;/h4&gt;准确校准由多个异步麦克风组成的声学传感系统对于实现满意的音源定位和跟踪至关重要。当前最先进的校准技术依赖于时间到达差异(TDOA)和方向到达(DOA)的测量。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入TDOAS来提高系统的校准精度，以改进现有的声学传感器阵列校准方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两阶段校准方案：首先利用混合时间差（包括TDOAM和TDOA-S）、车轮里程计数据、方向到达(DOA)等信息进行初始值估计(IVE)，然后通过迭代最近点算法来确定麦克风阵列的方向。在最终的联合优化步骤中，同时估算多个麦克风阵列的位置、方向、时间偏移、时钟漂移率和声源位置。&lt;h4&gt;主要发现&lt;/h4&gt;无论是模拟还是实验结果都表明，在低或中等TDOA噪声水平的情况下，该方法在准确性方面优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入相邻声音事件之间的时间差测量并结合其他校准技术，可以显著提高多麦克风阵列系统的校准精度。所有代码和数据可在https://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib获取。&lt;h4&gt;翻译&lt;/h4&gt;精确校准由多个异步麦克风组成的声学传感系统对于实现满意的音源定位和跟踪至关重要。当前的校准方法依赖于时间到达差异（TDOA）和方向到达（DOA）测量值来确定麦克风阵列之间的相对位置。本文提出了将相邻声音事件之间的时间差测量（TDOAS）加入现有技术的方法，以增强系统的准确性。我们提出了一种两阶段的校准流程：首先是初始值估算(IVE)过程，使用混合时间到达差异、车轮里程计数据以及方向到达(DOA)来初始化参数；接着通过迭代最近点方法估计麦克风阵列的方向。最终的联合优化步骤同时对多个麦克风阵列的位置、方向、时钟偏移和漂移率以及声源位置进行了估算。仿真和实验结果表明，在低至中等水平的时间到达差异噪声下，本方法在精度上优于现有技术。所有代码和数据可在https://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate calibration of acoustic sensing systems made of multipleasynchronous microphone arrays is essential for satisfactory performance insound source localization and tracking. State-of-the-art calibration methodsfor this type of system rely on the time difference of arrival and direction ofarrival measurements among the microphone arrays (denoted as TDOA-M and DOA,respectively). In this paper, to enhance calibration accuracy, we propose toincorporate the time difference of arrival measurements between adjacent soundevents (TDOAS) with respect to the microphone arrays. More specifically, wepropose a two-stage calibration approach, including an initial value estimation(IVE) procedure and the final joint optimization step. The IVE stage firstinitializes all parameters except for microphone array orientations, usinghybrid TDOA (i.e., TDOAM and TDOA-S), odometer data from a moving robotcarrying a speaker, and DOA. Subsequently, microphone orientations areestimated through the iterative closest point method. The final jointoptimization step estimates multiple microphone array locations, orientations,time offsets, clock drift rates, and sound source locations simultaneously.Both simulation and experiment results show that for scenarios with low ormoderate TDOA noise levels, our approach outperforms existing methods in termsof accuracy. All code and data are available athttps://github.com/AISLABsustech/Hybrid-TDOA-Multi-Calib.</description>
      <author>example@mail.com (Chengjie Zhang, Wenda Pan, Xinyang Han, He Kong)</author>
      <guid isPermaLink="false">2502.06195v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Portable, High-Frequency, and High-Voltage Control Circuits for Untethered Miniature Robots Driven by Dielectric Elastomer Actuators</title>
      <link>http://arxiv.org/abs/2502.06166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 10 figures, accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无绳应用的介电弹性体执行器(DEA)的高压、高频控制电路。&lt;h4&gt;背景&lt;/h4&gt;现有的DEA驱动系统通常体积较大且需要连接电源线，这限制了其在便携式和穿戴设备中的使用。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于无绳应用的小型化高电压、高频率控制电路。&lt;h4&gt;方法&lt;/h4&gt;利用低电压电阻元件串联以实现高达1.8kV的电压控制，并测试该控制电路的不同负载条件和电源下的性能。基于此电路，结合商用小型高压电源转换器，构建了一种由圆柱形DEA驱动的无绳爬行机器人。&lt;h4&gt;主要发现&lt;/h4&gt;42克重的无绳机器人能够在15Hz的驱动频率下，在桌面上及管道内成功实现爬行运动，并通过机载摄像机和天线实时传输视频数据。&lt;h4&gt;结论&lt;/h4&gt;该研究为使用低电压控制电子设备来实现DEA的无绳驱动提供了一种实用的方法，从而促进了便携式和穿戴设备的发展。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种用于无绳应用的介电弹性体执行器(DEA)的高压、高频控制电路。该电路板利用低电压电阻元件串联以在紧凑尺寸内实现高达1.8kV的电压控制，适用于0至1kHz范围内的频率变化。单通道控制板仅重2.5克。我们测试了该控制电路在不同负载条件和电源下的性能表现。基于此控制电路，并结合商用小型高压电源转换器，我们构建了一种由圆柱形DEA驱动的无绳爬行机器人。42克重的无绳机器人能够在15Hz的驱动频率下，在桌面上及管道内成功实现爬行运动，并通过机载摄像机和天线实时传输视频数据。我们的工作提供了一种使用低电压控制电子设备来实现DEA的无绳驱动的实际方法，从而促进了便携式和穿戴设备的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a high-voltage, high-frequency control circuit forthe untethered applications of dielectric elastomer actuators (DEAs). Thecircuit board leverages low-voltage resistive components connected in series tocontrol voltages of up to 1.8 kV within a compact size, suitable forfrequencies ranging from 0 to 1 kHz. A single-channel control board weighs only2.5 g. We tested the performance of the control circuit under different loadconditions and power supplies. Based on this control circuit, along with acommercial miniature high-voltage power converter, we construct an untetheredcrawling robot driven by a cylindrical DEA. The 42-g untethered robotssuccessfully obtained crawling locomotion on a bench and within a pipeline at adriving frequency of 15 Hz, while simultaneously transmitting real-time videodata via an onboard camera and antenna. Our work provides a practical way touse low-voltage control electronics to achieve the untethered driving of DEAs,and therefore portable and wearable devices.</description>
      <author>example@mail.com (Qi Shao, Xin-Jun Liu, Huichan Zhao)</author>
      <guid isPermaLink="false">2502.06166v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Reward-Based Collision-Free Algorithm for Trajectory Planning of Autonomous Robots</title>
      <link>http://arxiv.org/abs/2502.06149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的自主机器人任务规划算法，该算法能够从预定义的路点集中选择出最优路径序列，并基于此优化机器人的奖励值。&lt;h4&gt;背景&lt;/h4&gt;当前的任务规划问题通常涉及到如何最大化效益同时避免障碍物、满足约束条件等挑战。现有的方法往往无法很好地解决这一复杂性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够高效地处理奖赏收集旅行商问题的新算法，通过遗传算法寻找最佳路径序列，并优化机器人的导航性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一种新的基于惩罚函数和交叉操作的遗传算法；利用微分平坦性和Clothoid曲线特性进行轨迹规划与评估；采用动态时间规整法进行高效的解空间搜索。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能够在保证路径可行性的前提下，有效地寻找最优路点序列，并对高奖励目标给予优先权。此外，在仿真和实际试验中展示出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的任务规划算法成功解决了奖赏收集旅行商问题，能够有效避免不可行的路点并优化机器人的导航策略。&lt;h4&gt;翻译&lt;/h4&gt;摘要：该论文介绍了一种新的自主机器人任务规划算法，通过奖励导向的选择机制来确定从预定义集合中获得最优路径序列。该算法计算了机器人在遵循状态、输入及其导数约束的情况下，在避开障碍物的同时行进于路点之间的可行轨迹和相应的控制指令，并最大化总收益以及符合任务时间窗口和最大距离的限制。这也解决了广义的奖赏收集旅行商问题。提议的方法利用了一种新颖的遗传算法，该算法通过基于适应度函数及交叉操作演化的候选解决方案来趋近最优解。在适应度评估期间，使用惩罚方法强制执行约束条件，并通过微分平坦性与Clothoid曲线高效地惩罚不可行轨迹。与最小瞬时和加速度多项式相比，欧拉螺旋法显示出更优的轨迹参数化结果。由于探索空间是离散性的，采用基于动态时间规整的方法及扩展凸组合与投影来进行交叉操作，并通过突变步骤来增强探索能力。实验结果显示该算法能够发现最优路点序列、满足约束条件、避免不可行路径以及优先选择高收益目标点。同时提供了一系列涉及地面车辆、四旋翼和四足机器人的仿真及试验结果，辅以基准测试与时间复杂性分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a new mission planning algorithm for autonomous robotsthat enables the reward-based selection of an optimal waypoint sequence from apredefined set. The algorithm computes a feasible trajectory and correspondingcontrol inputs for a robot to navigate between waypoints while avoidingobstacles, maximizing the total reward, and adhering to constraints on state,input and its derivatives, mission time window, and maximum distance. This alsosolves a generalized prize-collecting traveling salesman problem. The proposedalgorithm employs a new genetic algorithm that evolves solution candidatestoward the optimal solution based on a fitness function and crossover. Duringfitness evaluation, a penalty method enforces constraints, and the differentialflatness property with clothoid curves efficiently penalizes infeasibletrajectories. The Euler spiral method showed promising results for trajectoryparameterization compared to minimum snap and jerk polynomials. Due to thediscrete exploration space, crossover is performed using a dynamictime-warping-based method and extended convex combination with projection. Amutation step enhances exploration. Results demonstrate the algorithm's abilityto find the optimal waypoint sequence, fulfill constraints, avoid infeasiblewaypoints, and prioritize high-reward ones. Simulations and experiments with aground vehicle, quadrotor, and quadruped are presented, complemented bybenchmarking and a time-complexity analysis.</description>
      <author>example@mail.com (Jose D. Hoyos, Tianyu Zhou, Zehui Lu, Shaoshuai Mou)</author>
      <guid isPermaLink="false">2502.06149v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Mixed Reality Outperforms Virtual Reality for Remote Error Resolution in Pick-and-Place Tasks</title>
      <link>http://arxiv.org/abs/2502.06141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究评估了混合现实（MR）、虚拟现实（VR）和摄像头流接口在远程错误解决任务中的性能和可用性，特别是对于仓库包装错误的纠正。&lt;h4&gt;背景&lt;/h4&gt;当前情况下，机器人手臂检测到错误后停止运行，需要远程操作员通过抓取放置动作介入并解决问题。这些任务通常由不同的技术界面支持进行操作。&lt;h4&gt;目的&lt;/h4&gt;评估混合现实（MR）、虚拟现实（VR）和摄像头流接口在执行远程错误解决任务时的性能和可用性。&lt;h4&gt;方法&lt;/h4&gt;21名参与者进行了模拟抓取和放置任务，分别使用三种不同类型的接口。通过线性混合模型（LMM）分析了任务解决时间、可用性得分（SUS）和心理工作量评分（NASA-TLX）。&lt;h4&gt;主要发现&lt;/h4&gt;{'MR性能优势': '混合现实界面在任务完成速度上显著优于VR和摄像头流接口，且在可用性和认知负荷方面也表现出色。', '空间理解能力': 'MR通过将虚拟机器人投影到物理桌面上提供了更好的空间理解和实际参考线索。'}&lt;h4&gt;结论&lt;/h4&gt;混合现实（MR）界面因其较高的性能、可用性以及较低的认知负担而被参与者偏好，表明MR在远程错误解决任务中具有明显优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已完成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study evaluates the performance and usability of Mixed Reality (MR),Virtual Reality (VR), and camera stream interfaces for remote error resolutiontasks, such as correcting warehouse packaging errors. Specifically, we considera scenario where a robotic arm halts after detecting an error, requiring aremote operator to intervene and resolve it via pick-and-place actions.Twenty-one participants performed simulated pick-and-place tasks using eachinterface. A linear mixed model (LMM) analysis of task resolution time,usability scores (SUS), and mental workload scores (NASA-TLX) showed that theMR interface outperformed both VR and camera interfaces. MR enabledsignificantly faster task completion, was rated higher in usability, and wasperceived to be less cognitively demanding. Notably, the MR interface, whichprojected a virtual robot onto a physical table, provided superior spatialunderstanding and physical reference cues. Post-study surveys further confirmedparticipants' preference for MR over other interfaces.</description>
      <author>example@mail.com (Advay Kumar, Stephanie Simangunsong, Pamela Carreno-Medrano, Akansel Cosgun)</author>
      <guid isPermaLink="false">2502.06141v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Bio-inspired Heuristically Accelerated Reinforcement Learning for Adaptive Underwater Multi-Agents Behaviour</title>
      <link>http://arxiv.org/abs/2502.06113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  i-SAIRAS 2024 Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文讨论了在复杂环境中协调自主多智能体系统（MAS）的问题，特别是用于检测和识别感兴趣物体的覆盖规划问题。这些任务对于太空应用至关重要，并且同样适用于包括水下环境在内的多个领域。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种新的策略来解决由于学习时间长而限制当前大多数MARL算法在实际应用场景中的应用这一问题。&lt;h4&gt;方法&lt;/h4&gt;通过引入生物启发式算法（如粒子群优化PSO）作为引导智能体训练过程的启发法，加速了MAS在水下环境覆盖规划任务中的收敛速度。具体来说，该策略应用于MSAC算法，并在一个连续控制环境中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;新的方法让智能体能够更快地达到最优性能，减少了训练中所需的交互次数。&lt;h4&gt;结论&lt;/h4&gt;通过结合生物启发式算法和MARL技术，研究提供了一种有效的方法来加速MAS在复杂且动态的水下环境中的学习过程。这种方法有助于解决覆盖规划问题中的不确定性、通信限制等问题，并展示了在实际应用（如探索水下区域）中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes the problem of coordination of an autonomous Multi-AgentSystem which aims to solve the coverage planning problem in a complexenvironment. The considered applications are the detection and identificationof objects of interest while covering an area. These tasks, which are highlyrelevant for space applications, are also of interest among various domainsincluding the underwater context, which is the focus of this study. In thiscontext, coverage planning is traditionally modelled as a Markov DecisionProcess where a coordinated MAS, a swarm of heterogeneous autonomous underwatervehicles, is required to survey an area and search for objects. This MDP isassociated with several challenges: environment uncertainties, communicationconstraints, and an ensemble of hazards, including time-varying andunpredictable changes in the underwater environment. MARL algorithms can solvehighly non-linear problems using deep neural networks and display greatscalability against an increased number of agents. Nevertheless, most of thecurrent results in the underwater domain are limited to simulation due to thehigh learning time of MARL algorithms. For this reason, a novel strategy isintroduced to accelerate this convergence rate by incorporating biologicallyinspired heuristics to guide the policy during training. The PSO method, whichis inspired by the behaviour of a group of animals, is selected as a heuristic.It allows the policy to explore the highest quality regions of the action andstate spaces, from the beginning of the training, optimizing theexploration/exploitation trade-off. The resulting agent requires fewerinteractions to reach optimal performance. The method is applied to the MSACalgorithm and evaluated for a 2D covering area mission in a continuous controlenvironment.</description>
      <author>example@mail.com (Antoine Vivien, Thomas Chaffre, Matthew Stephenson, Eva Artusi, Paulo Santos, Benoit Clement, Karl Sammut)</author>
      <guid isPermaLink="false">2502.06113v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>CDM: Contact Diffusion Model for Multi-Contact Point Localization</title>
      <link>http://arxiv.org/abs/2502.06109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication at the 2025 IEEE  International Conference on Robotics and Automation (ICRA), Atlanta, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于学习的方法，即接触扩散模型(CDM)，用于多接触点定位。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在处理多个接触点和力对传感器测量值产生相同结果的情况时存在问题。&lt;h4&gt;目的&lt;/h4&gt;通过利用扩散模型解决上述问题，并提高机器人表面任意位置的接触点定位准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种条件化的扩散模型(CDM)，该模型基于过去的输出并考虑到多接触场景的时间特性。此外，为了有效处理复杂形状的机器人表面，在去噪过程中引入了符号距离场。&lt;h4&gt;主要发现&lt;/h4&gt;CDM能够以高精度在任意位置定位接触点，并且实验结果表明该方法的有效性。具体而言，CDM运行时间为15.97毫秒，在单次接触和双重接触场景中分别实现了0.44厘米和1.24厘米的误差。&lt;h4&gt;结论&lt;/h4&gt;提出的扩散模型（CDM）是一种有效的解决多点接触定位问题的方法，并且在真实世界的应用中显示出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a Contact Diffusion Model (CDM), a novellearning-based approach for multi-contact point localization. We consider arobot equipped with joint torque sensors and a force/torque sensor at the base.By leveraging a diffusion model, CDM addresses the singularity where multiplepairs of contact points and forces produce identical sensor measurements. Weformulate CDM to be conditioned on past model outputs to account for thetime-dependent characteristics of the multi-contact scenarios. Moreover, toeffectively address the complex shape of the robot surfaces, we incorporate thesigned distance field in the denoising process. Consequently, CDM can localizecontacts at arbitrary locations with high accuracy. Simulation and real-worldexperiments demonstrate the effectiveness of the proposed method. Inparticular, CDM operates at 15.97ms and, in the real world, achieves an errorof 0.44cm in single-contact scenarios and 1.24cm in dual-contact scenarios.</description>
      <author>example@mail.com (Seo Wook Han, Min Jun Kim)</author>
      <guid isPermaLink="false">2502.06109v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.05996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了深度强化学习（DRL）在无人机添加剂制造中的运动控制挑战的应用。&lt;h4&gt;背景&lt;/h4&gt;基于无人机的添加剂制造能够在大型或危险环境中实现灵活和自主的材料沉积。然而，多旋翼空中机器人在不同负载和潜在干扰下的实时控制仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种深度强化学习框架，该框架能够为执行路径导航任务的多旋翼无人机学习适应性的控制策略。&lt;h4&gt;方法&lt;/h4&gt;比较了DDPG（Deep Deterministic Policy Gradient）和TD3（Twin Delayed Deep Deterministic Policy Gradient），并在处理不断增加复杂度的学习课程方案中进行了测试。实验表明，当引入质量变化时，TD3在训练稳定性、精度和成功率方面表现更佳。&lt;h4&gt;主要发现&lt;/h4&gt;结果证明了使用DRL方法能够实现稳健且自主的无人机控制，并为添加剂制造提供了可扩展路径。&lt;h4&gt;结论&lt;/h4&gt;通过深度强化学习技术，特别是在处理动态场景中的参数调节问题时，可以提高多旋翼无人机在添加剂制造任务中的适应性和性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文探讨了将深度强化（DRL）学习应用于解决无人机添加剂制造的运动控制挑战。基于无人机的添加剂制造能够在大型或危险环境中实现灵活和自主的材料沉积。然而，多旋翼空中机器人在不同负载和潜在干扰下的实时控制仍然具有挑战性。传统的控制器如PID经常需要频繁调节参数，在动态场景中限制了它们的应用。我们提出了一种DRL框架，该框架能够为执行路径导航任务的多旋翼无人机学习适应性的控制策略。我们在处理不断增加复杂度的学习课程方案中比较了DDPG和TD3，并在实验中展示了TD3能够平衡训练稳定性、精度和成功率，尤其是在引入质量变化时。这些发现提供了一条向添加剂制造中稳健且自主的无人机控制扩展的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the application of Deep Reinforcement (DRL) Learningto address motion control challenges in drones for additive manufacturing (AM).Drone-based additive manufacturing promises flexible and autonomous materialdeposition in large-scale or hazardous environments. However, achieving robustreal-time control of a multi-rotor aerial robot under varying payloads andpotential disturbances remains challenging. Traditional controllers like PIDoften require frequent parameter re-tuning, limiting their applicability indynamic scenarios. We propose a DRL framework that learns adaptable controlpolicies for multi-rotor drones performing waypoint navigation in AM tasks. Wecompare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed DeepDeterministic Policy Gradient (TD3) within a curriculum learning schemedesigned to handle increasing complexity. Our experiments show TD3 consistentlybalances training stability, accuracy, and success, particularly when massvariability is introduced. These findings provide a scalable path towardrobust, autonomous drone control in additive manufacturing.</description>
      <author>example@mail.com (Gaurav Shetty, Mahya Ramezani, Hamed Habibi, Holger Voos, Jose Luis Sanchez-Lopez)</author>
      <guid isPermaLink="false">2502.05996v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>Mechanic Modeling and Nonlinear Optimal Control of Actively Articulated Suspension of Mobile Heavy-Duty Manipulators</title>
      <link>http://arxiv.org/abs/2502.05972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种对移动重型机械臂的分析建模及其最优控制，以最大化其静态和动态稳定性的方法。&lt;h4&gt;背景&lt;/h4&gt;研究采用螺旋理论形式化方法，将悬架机制视为由两个闭合运动链组成的刚体多体系统。&lt;h4&gt;目的&lt;/h4&gt;通过这种方法来提高计算车轮反作用力的准确性，并提供机械臂质心及惯性张量的确切解。&lt;h4&gt;方法&lt;/h4&gt;利用铰接体惯性法，根据悬架的线性执行器计算整个平台的空间惯性参数。这些惯性参数和正向力用于定义静态和动态稳定性的指标，并建立一个非线性规划问题以优化这些指标来生成防止平台翻倒的最佳稳定性运动。&lt;h4&gt;主要发现&lt;/h4&gt;通过在C++中模拟具有主动铰接悬架的7自由度重型并联-串联移动机械臂，证明了该方法在计算速度、精度和性能改进方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;研究展示了一种提高移动重型机械臂稳定性的新途径，并证实了所提出的方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文提出了对装备有主动铰接悬架的移动重型机械臂进行分析建模及其最优控制，以最大化其静态和动态稳定性。通过采用螺旋理论形式化方法，将悬架机制视为由两个闭合运动链组成的刚体多体系统。该机械模型使我们能够根据悬架的线性执行器计算整个平台的空间惯性参数，并利用铰接体惯性法提供精确的质量中心及惯性张量解。这些惯性参数和正向力用于定义移动机械臂静态和动态稳定性的指标，并构建一个非线性规划问题以优化这些指标，生成防止平台翻倒的最佳稳定性运动。最优执行器位置通过状态反馈液压阀控制跟踪实现。通过在C++中模拟具有主动铰接悬架的7自由度重型并联-串联移动机械臂，验证了该方法的有效性，具体体现在计算速度、精度和性能改进方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the analytic modeling of mobile heavy-duty manipulatorswith actively articulated suspension and its optimal control to maximize itsstatic and dynamic stabilization. By adopting the screw theory formalism, weconsider the suspension mechanism as a rigid multibody composed of two closedkinematic chains. This mechanical modeling allows us to compute the spatialinertial parameters of the whole platform as a function of the suspension'slinear actuators through the articulated-body inertia method. Our solutionenhances the computation accuracy of the wheels' reaction normal forces byproviding an exact solution for the center of mass and inertia tensor of themobile manipulator. Moreover, these inertial parameters and the normal forcesare used to define metrics of both static and dynamic stability of the mobilemanipulator and formulate a nonlinear programming problem that optimizes suchmetrics to generate an optimal stability motion that prevents the platform'soverturning, such optimal position of the actuator is tracked with astate-feedback hydraulic valve control. We demonstrate our method's efficiencyin terms of C++ computational speed, accuracy and performance improvement bysimulating a 7 degrees-of-freedom heavy-duty parallel-serial mobile manipulatorwith four wheels and actively articulated suspension.</description>
      <author>example@mail.com (Alvaro Paz, Jouni Mattila)</author>
      <guid isPermaLink="false">2502.05972v1</guid>
      <pubDate>Tue, 11 Feb 2025 19:03:17 +0800</pubDate>
    </item>
    <item>
      <title>PixFoundation: Are We Heading in the Right Direction with Pixel-level Vision Foundation Models?</title>
      <link>http://arxiv.org/abs/2502.04192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文探讨了多模态大规模语言模型（MLLMs）在像素级理解领域的现状和挑战。&lt;h4&gt;背景&lt;/h4&gt;目前研究的趋势是通过使用大规模标注数据训练MLLMs以实现像素级视觉接地，然而这些模型在具有挑战性的视觉基准测试中表现出了较弱的视觉问答能力。一些方法甚至降低了从未受过此类监督的MLLMs的能力。&lt;h4&gt;目的&lt;/h4&gt;提出两个新的具有挑战性的基准，并证明即使没有接受像素级视觉接地训练的MLLMs也能在某些任务上超越当前最佳性能，同时探讨当MLLMs未接受像素级视觉接地监督时，何时会出现接地现象的研究问题。&lt;h4&gt;方法&lt;/h4&gt;提出了简单基线PixFoundation，可以提取任何MLLM中的接地信息，并进行了实验验证。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现即使在没有像素级视觉接地训练的模型中，接地也可能与物体部分或位置/外观信息重合。另外，在某些任务上未接受过像素级监督的模型也可以超越当前的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;提出了PixFoundation方法来解决现有MLLMs的局限性，并展示了它在特定任务上的优越表现。&lt;h4&gt;翻译&lt;/h4&gt;多模态大规模语言模型（MLLMs）的研究工作正在推动向像素级理解领域的发展。这些方法已经在指代表达分割和基于视觉的任务生成等基准测试中表现出色，但是现有的趋势是通过使用大规模标注数据进行训练来实现像素级的视觉接地监督。然而，在具有挑战性的视觉中心基准测试中，这些模型在视觉问答方面的能力较弱，并且一些方法甚至降低了从未受过此类监督的MLLMs的表现能力。为了应对这一问题，论文提出了两个新的具有挑战性的基准，并证明即使没有接受像素级视觉接地训练的MLLMs也能在某些任务上超越当前最佳性能，同时探讨了未接受像素级视觉接地监督的情况下何时会出现接地现象的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple works have emerged to push the boundaries on multi-modal largelanguage models (MLLMs) towards pixel-level understanding. Such approaches haveshown strong performance on benchmarks for referring expression segmentationand grounded conversation generation. The current trend in pixel-level MLLMs isto train with pixel-level grounding supervision on large-scale labelled data.However, we show that such MLLMs when evaluated on recent challenging visioncentric benchmarks, exhibit a weak ability in visual question answering.Surprisingly, some of these methods even downgrade the grounding ability ofMLLMs that were never trained with such supervision. In this work, we proposetwo novel challenging benchmarks and show that MLLMs without pixel-levelgrounding supervision can outperform the state of the art in such tasks whenevaluating both the pixel-level grounding and visual question answering. Wepropose simple baselines to extract the grounding information that can beplugged into any MLLM, which we call as PixFoundation. More importantly, westudy the research question of ``When does grounding emerge in MLLMs that arenot trained with pixel-level grounding supervision?'' We show that groundingcan coincide with object parts or location/appearance information. Coderepository is at https://github.com/MSiam/PixFoundation/.</description>
      <author>example@mail.com (Mennatullah Siam)</author>
      <guid isPermaLink="false">2502.04192v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
  <item>
      <title>SLCGC: A lightweight Self-supervised Low-pass Contrastive Graph Clustering Network for Hyperspectral Images</title>
      <link>http://arxiv.org/abs/2502.03497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对高光谱图像（HSI）的自监督高效低通对比图聚类方法(SLCGC)，该方法通过生成同质区域、构建结构化图和引入去噪机制，结合双支路图对比学习模块来提高聚类准确性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;高光谱图像的无监督聚类由于缺乏标签数据且存在空间-光谱交互复杂性的挑战而具有根本的重要性。尽管最近的研究探索了创新的方法，但现有方法在准确性、特征区分度、计算效率和抗噪能力方面仍面临关键限制。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些挑战，提出了一种新的自监督高效低通对比图聚类（SLCGC）算法，旨在提高HSI的聚类性能。&lt;h4&gt;方法&lt;/h4&gt;- 生成同质区域以聚合光谱一致性区域。- 构建结构化图并引入低通去噪机制来抑制图形拓扑中的高频噪声。- 开发双支路图对比学习模块，使用两层多层感知机（MLP）通过高斯噪声扰动产生增强视图，并通过跨视图对比损失强制执行结构一致性以学习抗噪表示。&lt;h4&gt;主要发现&lt;/h4&gt;- SLCGC在聚类准确性和鲁棒性方面表现出色。- 与现有方法相比，SLCGC具有低计算复杂度和更高的效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的自监督高效低通对比图聚类算法（SLCGC）展示了高光谱图像中无监督聚类任务的优越性能，并为实际部署奠定了坚实的基础。实验结果证明了该方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种针对高光谱图像(HSI)的自监督高效低通对比图聚类(SLCGC)方法，解决了现有HSI聚类算法在准确性、特征区分度等方面存在的问题，并通过生成同质区域和结构化图来提高鲁棒性和计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised hyperspectral image (HSI) clustering remains a fundamentalyet challenging task due to the absence of labeled data and the inherentcomplexity of spatial-spectral interactions. While recent advancements haveexplored innovative approaches, existing methods face critical limitations inclustering accuracy, feature discriminability, computational efficiency, androbustness to noise, hindering their practical deployment. In this paper, aself-supervised efficient low-pass contrastive graph clustering (SLCGC) isintroduced for HSIs. Our approach begins with homogeneous region generation,which aggregates pixels into spectrally consistent regions to preserve localspatial-spectral coherence while drastically reducing graph complexity. We thenconstruct a structural graph using an adjacency matrix A and introduce alow-pass graph denoising mechanism to suppress high-frequency noise in thegraph topology, ensuring stable feature propagation. A dual-branch graphcontrastive learning module is developed, where Gaussian noise perturbationsgenerate augmented views through two multilayer perceptrons (MLPs), and across-view contrastive loss enforces structural consistency between views tolearn noise-invariant representations. Finally, latent embeddings optimized bythis process are clustered via K-means. Extensive experiments and repeatedcomparative analysis have verified that our SLCGC contains high clusteringaccuracy, low computational complexity, and strong robustness. The code sourcewill be available at https://github.com/DY-HYX.</description>
      <author>example@mail.com (Yao Ding, Zhili Zhang, Aitao Yang, Yaoming Cai, Xiongwu Xiao, Danfeng Hong, Junsong Yuan)</author>
      <guid isPermaLink="false">2502.03497v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance</title>
      <link>http://arxiv.org/abs/2502.04883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了针对低资源语言弗里西语及其方言的自动语音识别（ASR）性能提升方法。&lt;h4&gt;背景&lt;/h4&gt;当前，低资源语言如弗里西语的ASR表现远低于高资源语言如英语的表现。原因是缺乏足够的标注数据。&lt;h4&gt;目的&lt;/h4&gt;研究一种基于自监督学习的方法来提高弗里西语及其方言的ASR性能。&lt;h4&gt;方法&lt;/h4&gt;采用多语言（包括弗里西语、荷兰语、英语和德语）微调数据以及辅助的语言识别任务，对一个预训练模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;[{'内容': '使用多种语言的微调数据可以提升弗里西语ASR性能'}, {'内容': '方言语音的表现受到严重影响'}, {'内容': '采集方言数据的方法可以缓解其影响'}]&lt;h4&gt;结论&lt;/h4&gt;单纯依赖标准语言数据评估ASR可能低估了实际表现，特别是在有大量方言变化的语言中。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种针对低资源语言弗里西语及其方言的自动语音识别性能提升方法。该研究指出，采用多语言微调数据和辅助任务可以改善模型的表现，并揭示了采集方言数据的方法对ASR性能的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic Speech Recognition (ASR) performance for low-resource languages isstill far behind that of higher-resource languages such as English, due to alack of sufficient labeled data. State-of-the-art methods deployself-supervised transfer learning where a model pre-trained on large amounts ofdata is fine-tuned using little labeled data in a target low-resource language.In this paper, we present and examine a method for fine-tuning an SSL-basedmodel in order to improve the performance for Frisian and its regional dialects(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASRperformance can be improved by using multilingual (Frisian, Dutch, English andGerman) fine-tuning data and an auxiliary language identification task. Inaddition, our findings show that performance on dialectal speech sufferssubstantially, and, importantly, that this effect is moderated by theelicitation approach used to collect the dialectal data. Our findings alsoparticularly suggest that relying solely on standard language data for ASRevaluation may underestimate real-world performance, particularly in languageswith substantial dialectal variation.</description>
      <author>example@mail.com (Reihaneh Amooie, Wietse de Vries, Yun Hao, Jelske Dijkstra, Matt Coler, Martijn Wieling)</author>
      <guid isPermaLink="false">2502.04883v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Pre-training Capsule Networks: Overcoming Medical Imaging Dataset Challenges</title>
      <link>http://arxiv.org/abs/2502.04748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该研究探讨了在结肠癌息肉诊断中使用胶囊网络的自监督学习预训练方法。&lt;h4&gt;背景&lt;/h4&gt;深度学习技术越来越多地被应用于医学影像诊断，但高质量的大规模医疗数据集的缺乏限制了其应用。为了解决这个问题，通常采用迁移学习的方法。然而，在主流深度学习框架中对胶囊网络的支持有限且缺少预先训练版本。&lt;h4&gt;目的&lt;/h4&gt;研究自监督学习方法用于在小而不平衡的数据集中预训练胶囊网络的有效性，以改善结肠息肉诊断任务的性能。&lt;h4&gt;方法&lt;/h4&gt;使用PICCOLO数据集进行实验（包含3,433个样本），探索了两种辅助的自监督学习任务——着色和对比学习，来为胶囊网络做预训练，并与其它初始化策略进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果显示，对比学习和图像修复技术是适用于医疗领域自监督学习的有效辅助任务。这些方法帮助模型更好地捕捉重要的视觉特征，从而在息肉分类下游任务中提高了5.26%的准确性。&lt;h4&gt;结论&lt;/h4&gt;自监督学习中的对比学习和着色等辅助任务可以为胶囊网络提供更好的初始化权重，在小规模数据集上提高诊断准确率。&lt;h4&gt;翻译&lt;/h4&gt;深度学习技术越来越多地应用于医学影像的诊断领域，但是高质量的大规模医疗数据集的稀缺是一个重要的挑战。本研究调查了自监督学习方法在结肠息肉诊断中用于预训练胶囊网络的应用情况。实验结果表明，在对比学习和图像修复等辅助任务的帮助下，可以提高模型对关键视觉特征的捕捉能力，并且通过这些方法初始化权重后，与其它方法相比，模型在息肉分类上的准确率提高了5.26%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques are increasingly being adopted in diagnostic medicalimaging. However, the limited availability of high-quality, large-scale medicaldatasets presents a significant challenge, often necessitating the use oftransfer learning approaches. This study investigates self-supervised learningmethods for pre-training capsule networks in polyp diagnostics for coloncancer. We used the PICCOLO dataset, comprising 3,433 samples, whichexemplifies typical challenges in medical datasets: small size, classimbalance, and distribution shifts between data splits. Capsule networks offerinherent interpretability due to their architecture and inter-layer informationrouting mechanism. However, their limited native implementation in mainstreamdeep learning frameworks and the lack of pre-trained versions pose asignificant challenge. This is particularly true if aiming to train them onsmall medical datasets, where leveraging pre-trained weights as initialparameters would be beneficial. We explored two auxiliary self-supervisedlearning tasks, colourisation and contrastive learning, for capsule networkpre-training. We compared self-supervised pre-trained models againstalternative initialisation strategies. Our findings suggest that contrastivelearning and in-painting techniques are suitable auxiliary tasks forself-supervised learning in the medical domain. These techniques helped guidethe model to capture important visual features that are beneficial for thedownstream task of polyp classification, increasing its accuracy by 5.26%compared to other weight initialisation methods.</description>
      <author>example@mail.com (Heba El-Shimy, Hind Zantout, Michael A. Lones, Neamat El Gayar)</author>
      <guid isPermaLink="false">2502.04748v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Graph Contrastive Learning for Connectome Classification</title>
      <link>http://arxiv.org/abs/2502.05109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to EMBC '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了通过图信号处理（GSP）技术研究大脑结构和功能网络，并引入了一种基于监督对比学习的图表示学习方法，用于生成区分性别分类任务中同标签或不同标签个体的连接体嵌入。&lt;h4&gt;背景&lt;/h4&gt;非侵入性脑活动测量技术的进步，如磁共振成像(MRI)，促进了对通过GSP处理的大脑结构和功能网络的研究。这种新技术使得我们可以更好地理解大脑各区域之间的互动关系，即所谓的'连接体'&lt;h4&gt;目的&lt;/h4&gt;探索基于图表示学习的监督对比方法来生成特定于每个被试（即图形级别的）矢量表示。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络编码器-解码器架构，该结构同时考虑了大脑的结构性和功能性连通性，并通过数据增强技术提升了性别分类任务的表现。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在利用人类连接体项目数据进行性别分类时达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;这项研究为使用GSP更好地了解大脑功能提供了一种潜在方法，有望对神经退行性疾病的理解及精准医疗和诊断产生重要影响。&lt;h4&gt;翻译&lt;/h4&gt;随着非侵入性脑活动测量技术的进展，例如磁共振成像（MRI），通过图信号处理（GSP）来研究结构和功能性脑网络得到了显著的关注。我们的工作进一步探索了在图形表示学习领域的监督对比学习方法，并生成了结合相同标签但区分不同标签被试的图级别向量表示。这些连接体嵌入是由一种考虑了结构性和功能性连通性的图神经网络编码器-解码器架构提取出来的。通过利用数据增强技术，所提出的框架在人类连接体项目的数据性别分类任务中实现了最先进的性能。更广泛地说，这种方法论进步支持了GSP用于发现更多关于大脑功能的潜力，并可能对理解神经退行性疾病的异质性以及精准医疗和诊断产生影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With recent advancements in non-invasive techniques for measuring brainactivity, such as magnetic resonance imaging (MRI), the study of structural andfunctional brain networks through graph signal processing (GSP) has gainednotable prominence. GSP stands as a key tool in unraveling the interplaybetween the brain's function and structure, enabling the analysis of graphsdefined by the connections between regions of interest -- referred to asconnectomes in this context. Our work represents a further step in thisdirection by exploring supervised contrastive learning methods within the realmof graph representation learning. The main objective of this approach is togenerate subject-level (i.e., graph-level) vector representations that bringtogether subjects sharing the same label while separating those with differentlabels. These connectome embeddings are derived from a graph neural networkEncoder-Decoder architecture, which jointly considers structural and functionalconnectivity. By leveraging data augmentation techniques, the proposedframework achieves state-of-the-art performance in a gender classification taskusing Human Connectome Project data. More broadly, our connectome-centricmethodological advances support the promising prospect of using GSP to discovermore about brain function, with potential impact to understanding heterogeneityin the neurodegeneration for precision medicine and diagnosis.</description>
      <author>example@mail.com (Martín Schmidt, Sara Silva, Federico Larroca, Gonzalo Mateos, Pablo Musé)</author>
      <guid isPermaLink="false">2502.05109v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>A Meta-learner for Heterogeneous Effects in Difference-in-Differences</title>
      <link>http://arxiv.org/abs/2502.04699v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新颖的双重稳健元学习器来估计条件平均处理效应（CATT），利用辅助模型集合将问题转化为凸风险最小化问题，提高异质性治疗效果的估计准确性。&lt;h4&gt;背景&lt;/h4&gt;在面板数据中估算不同的治疗影响是当前研究的重要议题。差分法（DiD）框架常被用作基础分析工具，并且该方法假设条件平行趋势成立。&lt;h4&gt;目的&lt;/h4&gt;开发一种灵活和稳健的方法来估计异质性处理效果，特别是对于有条件平行趋势假设下的差异在差异框架中的应用。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的双重稳健元学习器，通过引入一组辅助模型将CATT的估算问题转化为凸风险最小化问题。利用Neyman正交性原理使该方法对辅助模型估计误差具有鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的双重重学习框架不仅提高了CATT的估计准确性，还能够处理协变量漂移下的一般条件函数估计，并且可以扩展到使用工具变量的DiD设置中。&lt;h4&gt;结论&lt;/h4&gt;实证结果表明，与现有基准方法相比，该研究提出的方法在估算异质性治疗效果方面具有优越性。&lt;h4&gt;翻译&lt;/h4&gt;我们解决了面板数据中的不同治疗方法效应估计问题，在条件平行趋势假设下采用广受欢迎的差分法（DiD）框架。我们为条件平均处理效果提出了一个新的双重稳健元学习器，并将其简化为涉及辅助模型集的凸风险最小化问题。我们的框架允许使用通用机器学习灵活地估算任何感兴趣的变量子集上的CATT。通过利用Neyman正交性，我们提出的方法对辅助模型中的估计错误具有鲁棒性。作为主要结果的一般化，我们开发了一种用于在协变量漂移下估算一般条件功能的元学习方法，并为非合规情况下的工具DiD设置提供扩展。实证结果显示了我们的方法相对于现有基准的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the problem of estimating heterogeneous treatment effects in paneldata, adopting the popular Difference-in-Differences (DiD) framework under theconditional parallel trends assumption. We propose a novel doubly robustmeta-learner for the Conditional Average Treatment Effect on the Treated(CATT), reducing the estimation to a convex risk minimization problem involvinga set of auxiliary models. Our framework allows for the flexible estimation ofthe CATT, when conditioning on any subset of variables of interest usinggeneric machine learning. Leveraging Neyman orthogonality, our proposedapproach is robust to estimation errors in the auxiliary models. As ageneralization to our main result, we develop a meta-learning approach for theestimation of general conditional functionals under covariate shift. We alsoprovide an extension to the instrumented DiD setting with non-compliance.Empirical results demonstrate the superiority of our approach over existingbaselines.</description>
      <author>example@mail.com (Hui Lan, Haoge Chang, Eleanor Dillon, Vasilis Syrgkanis)</author>
      <guid isPermaLink="false">2502.04699v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer</title>
      <link>http://arxiv.org/abs/2502.04573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的Transformer模型APT，它通过对抗性合成数据预训练，在不依赖任何真实世界数据集的情况下进行零样本元学习。&lt;h4&gt;背景&lt;/h4&gt;基于最近发展的Prior-Data Fitted Networks (PFNs)和TabPFN的工作，作者提出一种新的方法来解决深度表征零样本学习中的类别大小限制问题。&lt;h4&gt;目的&lt;/h4&gt;目的是通过引入对抗性合成数据预训练技术以及混合块架构，增强模型在分类任务上的性能，并提高泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 预训练过程：使用对抗性的生成器不断改变其产生的分布来挑战Transformer模型；2. 架构创新：提出了一种可以处理任意类别数量的分类任务的新混合块架构，解决了先前深度表征零样本学习框架中的类别大小限制问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在小型分类任务上能够达到业界领先的表现，同时保持平均运行时间在一秒钟之内。此外，在多个基准数据集上的实验证明对抗性预训练可以增强TabPFN的性能，并且混合块神经网络设计具有更好的泛化性和更快的预训练速度。&lt;h4&gt;结论&lt;/h4&gt;通过引入对抗性的合成数据生成和改进架构设计，该方法不仅提高了模型在零样本学习任务中的表现，还增强了模型的学习效率与实用性。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一个能进行无任何真实世界数据集预训练的零样本元学习的Adversarially Pre-trained Transformer (APT)，扩展了最近Prior-Data Fitted Networks (PFNs)和TabPFN的发展。特别地，AP T通过对抗性合成数据代理来预训练模型，并持续改变其生成的数据分布以挑战模型，使用不同的合成数据集。此外，我们提出了一种混合块架构能够处理任意数量类别的分类任务，解决了先前深度表征零样本学习器的类别大小限制问题——这是一个关键弱点。实验中，我们展示了我们的框架在不考虑数据集特征（如类别数量和缺失值的数量）的情况下，在小分类任务上达到了行业标准性能，并且保持平均运行时间在一秒钟以内。在常见的基准测试数据集中，无论是分类还是回归，我们都证明了对抗性预训练能够增强TabPFN的性能。分析中我们还展示了对抗性合成数据代理可以生成比普通随机生成器更多的多样化数据集合。此外，我们还表明我们的混合块神经网络设计提高了泛化能力和极大地加速了预训练过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an Adversarially Pre-trained Transformer (APT) that is able toperform zero-shot meta-learning on tabular prediction tasks withoutpre-training on any real-world dataset, extending on the recent development ofPrior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trainedwith adversarial synthetic data agents, who continue to shift their underlyingdata generating distribution and deliberately challenge the model withdifferent synthetic datasets. In addition, we propose a mixture blockarchitecture that is able to handle classification tasks with arbitrary numberof classes, addressing the class size limitation -- a crucial weakness of priordeep tabular zero-shot learners. In experiments, we show that our frameworkmatches state-of-the-art performance on small classification tasks withoutfiltering on dataset characteristics such as number of classes and number ofmissing values, while maintaining an average runtime under one second. Oncommon benchmark dataset suites in both classification and regression, we showthat adversarial pre-training was able to enhance TabPFN's performance. In ouranalysis, we demonstrate that the adversarial synthetic data agents were ableto generate a more diverse collection of data compared to the ordinary randomgenerator in TabPFN. In addition, we demonstrate that our mixture block neuraldesign has improved generalizability and greatly accelerated pre-training.</description>
      <author>example@mail.com (Yulun Wu, Doron L. Bergman)</author>
      <guid isPermaLink="false">2502.04573v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>A Foundational Brain Dynamics Model via Stochastic Optimal Control</title>
      <link>http://arxiv.org/abs/2502.04892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究背景': '提出了一个用于大脑动态的基础模型，该模型利用随机最优控制(SOC)和现成推理方法。fMRI信号的复杂性和噪音使其处理变得困难。', '目的': '设计一种能够高效、稳健地处理fMRI数据的方法，并且能够在不同的下游任务中表现优秀。', '方法': {'连续离散状态空间模型(SSM)': '利用SSM，该模型可以有效应对fMRI信号的复杂和噪声特性。', '随机最优控制(SOC)框架下的近似策略': '为了克服计算限制，提出了基于SOC框架的近似策略。', '无需模拟的潜在动力学方法': '通过局部线性逼近，提出了一种不需要模拟的高效、可扩展的推理方法。', '证据下界(ELBO)': '从SOC公式推导出了一个有效的ELBO，该方法可以与最新的自监督学习技术无缝集成。'}, '主要发现': {'预训练模型表现': '在大规模数据集（如UKB）上进行预训练后，在多种下游任务中达到了业界领先的结果。', '外部验证': '通过HCP-A、ABIDE和ADHD200等外部数据集的评估，进一步证明了其在不同人口统计学分布和临床分布中的优越性能。'}, '结论': '该基础模型为解码大脑动态提供了一种可扩展且高效的方法，这开启了神经科学领域的大量应用前景。', '翻译': '我们介绍了一个基于随机最优控制(SOC)和现成推理方法的大脑动力学基础模型。利用连续离散状态空间模型(SSM)，可以有效地处理fMRI信号的复杂性和噪声特性。为解决计算限制问题，提出了一种基于SOC框架的近似策略，并采用局部线性逼近提出了无需模拟的方法以实现高效且可扩展的推理过程。通过推导出与最新自监督学习技术兼容的有效证据下界(ELBO)，实现了高效的表示学习。在大规模数据集（如UKB）上预训练后，该模型在多种下游任务中表现优异，并在外部分布不同的外部数据集中进一步验证了其优越性和鲁棒性。此基础模型为解码大脑动态提供了一种可扩展且高效的方法，这开启了神经科学领域的大量应用前景。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a foundational model for brain dynamics that utilizes stochasticoptimal control (SOC) and amortized inference. Our method features acontinuous-discrete state space model (SSM) that can robustly handle theintricate and noisy nature of fMRI signals. To address computationallimitations, we implement an approximation strategy grounded in the SOCframework. Additionally, we present a simulation-free latent dynamics approachthat employs locally linear approximations, facilitating efficient and scalableinference. For effective representation learning, we derive an Evidence LowerBound (ELBO) from the SOC formulation, which integrates smoothly with recentadvancements in self-supervised learning (SSL), thereby promoting robust andtransferable representations. Pre-trained on extensive datasets such as theUKB, our model attains state-of-the-art results across a variety of downstreamtasks, including demographic prediction, trait analysis, disease diagnosis, andprognosis. Moreover, evaluating on external datasets such as HCP-A, ABIDE, andADHD200 further validates its superior abilities and resilience acrossdifferent demographic and clinical distributions. Our foundational modelprovides a scalable and efficient approach for deciphering brain dynamics,opening up numerous applications in neuroscience.</description>
      <author>example@mail.com (Joonhyeong Park, Byoungwoo Park, Chang-Bae Bang, Jungwon Choi, Hyungjin Chung, Byung-Hoon Kim, Juho Lee)</author>
      <guid isPermaLink="false">2502.04892v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>PhyloVAE: Unsupervised Learning of Phylogenetic Trees via Variational Autoencoders</title>
      <link>http://arxiv.org/abs/2502.04730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025. 22 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了用于树结构表示学习和生成模型的无监督框架——基于变分自动编码器（PhyloVAE）的方法，该方法结合了高效的编码机制以及可学习拓扑特征的合作推理模型。&lt;h4&gt;背景&lt;/h4&gt;研究进化关系时，将系统发育树投影到欧几里得空间中是非常重要的。传统的基于距离的方法被广泛使用，但它们对距离度量的选择敏感，并且可能缺乏足够的分辨率。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效生成树拓扑结构和提供高分辨率表示的框架。&lt;h4&gt;方法&lt;/h4&gt;引入了利用自回归树拓扑生成启发的编码机制的深度潜在变量生成模型。此模型结合了一个基于可学习拓扑特征的合作推理模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，展示了PhyloVAE强大的表征学习能力以及快速生成系统发育树拓扑结构的能力。&lt;h4&gt;结论&lt;/h4&gt;PhyloVAE提供了一种高效、鲁棒的方法来处理和生成复杂的系统发育树数据。&lt;h4&gt;翻译&lt;/h4&gt;学习系统发育树结构的信息表示对于分析进化关系至关重要。传统的基于距离的方法被广泛用于将系统发育树投影到欧几里得空间中，但它们往往对距离度量的选择敏感，并且可能缺乏足够的分辨率。本文引入了系统发育变分自动编码器（PhyloVAEs），这是一种无监督学习框架，旨在进行树拓扑表示学习和生成建模。利用自回归树拓扑生成启发的高效编码机制，我们开发了一种深度潜在变量生成模型，该模型支持快速、并行化的拓扑生成。PhyloVAE将此生成模型与基于可学习拓扑特征的合作推理模型相结合，以实现系统发育树样本的高分辨率表示。广泛的实验表明了PhyloVAE强大的表征学习能力和对系统发育树拓扑结构的快速生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning informative representations of phylogenetic tree structures isessential for analyzing evolutionary relationships. Classical distance-basedmethods have been widely used to project phylogenetic trees into Euclideanspace, but they are often sensitive to the choice of distance metric and maylack sufficient resolution. In this paper, we introduce phylogeneticvariational autoencoders (PhyloVAEs), an unsupervised learning frameworkdesigned for representation learning and generative modeling of treetopologies. Leveraging an efficient encoding mechanism inspired byautoregressive tree topology generation, we develop a deep latent-variablegenerative model that facilitates fast, parallelized topology generation.PhyloVAE combines this generative model with a collaborative inference modelbased on learnable topological features, allowing for high-resolutionrepresentations of phylogenetic tree samples. Extensive experiments demonstratePhyloVAE's robust representation learning capabilities and fast generation ofphylogenetic tree topologies.</description>
      <author>example@mail.com (Tianyu Xie, Harry Richman, Jiansi Gao, Frederick A. Matsen IV, Cheng Zhang)</author>
      <guid isPermaLink="false">2502.04730v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting</title>
      <link>http://arxiv.org/abs/2502.04737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，深度学习与量化交易的结合在股票投资领域取得了显著的成功。许多基于深度学习的模型被开发出来用于预测股票回报，这些模型利用神经网络强大的表征能力来识别影响股价的因素和模式。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的深度学习模型已经能够捕捉市场中的普遍模式，如股价趋势、量价关系以及时间变化，但关于特殊非理性因素（例如市场情绪、投机行为、市场操纵及心理偏见）的影响却并未得到充分考虑。这些问题的原因在于这些因素具有相对抽象的特性，并且缺乏明确的数据标签和描述。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，我们提出了一种通用多层次市场非理性因子模型（UMI），旨在提升股票回报预测能力。&lt;h4&gt;方法&lt;/h4&gt;在股票层面，UMI模型会针对每个股票构建一个估计的合理价格，该价格与实际股价协整。两者之间的差异作为反映股票水平上非理性的因素指标。同时，在市场层面，我们将异常同步波动定义为市场内的非理性行为，并通过两个自我监督表示学习任务——子市场比较学习和市场同步性预测，将这些市场的非理性因素整合进一个市场表征向量中。&lt;h4&gt;主要发现&lt;/h4&gt;UMI模型能够有效地捕捉并反映影响股票回报的多种非理性因素，包括来自单个股票层面和整个市场层面的非理性的表现。&lt;h4&gt;结论&lt;/h4&gt;通过在深度学习框架内集成对市场不理智行为的理解，我们期望改进现有预测模型的有效性，以更好地应对金融市场中的复杂情况。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed the perfect encounter of deep learning andquantitative trading has achieved great success in stock investment. Numerousdeep learning-based models have been developed for forecasting stock returns,leveraging the powerful representation capabilities of neural networks toidentify patterns and factors influencing stock prices. These models caneffectively capture general patterns in the market, such as stock price trends,volume-price relationships, and time variations. However, the impact of specialirrationality factors -- such as market sentiment, speculative behavior, marketmanipulation, and psychological biases -- have not been fully considered inexisting deep stock forecasting models due to their relative abstraction aswell as lack of explicit labels and data description. To fill this gap, wepropose UMI, a Universal multi-level Market Irrationality factor model toenhance stock return forecasting. The UMI model learns factors that can reflectirrational behaviors in market from both individual stock and overall marketlevels. For the stock-level, UMI construct an estimated rational price for eachstock, which is cointegrated with the stock's actual price. The discrepancybetween the actual and the rational prices serves as a factor to indicatestock-level irrational events. Additionally, we define market-level irrationalbehaviors as anomalous synchronous fluctuations of stocks within a market.Using two self-supervised representation learning tasks, i.e., sub-marketcomparative learning and market synchronism prediction, the UMI modelincorporates market-level irrationalities into a market representation vector,which is then used as the market-level irrationality factor.</description>
      <author>example@mail.com (Chen Yang, Jingyuan Wang, Xiaohan Jiang, Junjie Wu)</author>
      <guid isPermaLink="false">2502.04737v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Performance Evaluation of Image Enhancement Techniques on Transfer Learning for Touchless Fingerprint Recognition</title>
      <link>http://arxiv.org/abs/2502.04680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了图像增强技术对基于深度学习模型的非接触式指纹识别性能的影响，特别是使用迁移学习方法。研究采用了IIT-Bombay的数据库，并测试了几种不同的深度学习架构。&lt;h4&gt;背景&lt;/h4&gt;传统的指纹识别系统依赖于接触式的扫描器，这些设备容易受到表面污染和用户交互不一致的问题影响。为了克服这些问题，非接触式指纹识别作为替代方案受到了关注。&lt;h4&gt;目的&lt;/h4&gt;评估图像增强技术对基于迁移学习的预训练深度学习模型在无触碰指纹识别中的性能提升作用。&lt;h4&gt;方法&lt;/h4&gt;使用IIT-Bombay数据库进行测试，该数据库包含了200名参与者的数据，并采用了VGG-16, VGG-19, Inception-V3和ResNet-50等不同的深度学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在迁移学习方法中，使用指纹图像增强的方法（间接法）显著优于未进行图像增强的方法（直接法）。特别是VGG-16模型在训练集上达到了98%的准确率和测试集上的93%，这比直接方法的表现要好。&lt;h4&gt;结论&lt;/h4&gt;本文提供了关于利用图像增强技术提高非接触式指纹识别系统性能的有效性的深入见解，为开发更高效的生物认证系统提供了关键信息。&lt;h4&gt;翻译&lt;/h4&gt;指纹识别因其高精度和独特性而仍然是最可靠的生物特征技术之一。传统的系统依赖于基于接触的扫描器，这些设备容易受到诸如表面污染引起的图像退化以及用户交互不一致等问题的影响。为了应对这些问题，非接触式指纹识别作为一种有前途的替代方案已经出现，提供了无创性和卫生性的认证方式。这项研究评估了图像增强技术对使用迁移学习方法预训练深度学习模型在非接触式指纹识别性能上的影响。采用IIT-Bombay触控和非触控指纹数据库进行测试，该数据库包含200名参与者的数据，并测试了几种不同的深度学习架构（如VGG-16, VGG-19, Inception-V3, 和ResNet-50）。实验结果表明，在迁移学习方法中，使用指纹图像增强的方法显著优于未进行图像增强的方法。具体而言，当使用增强的图像时，VGG-16模型在训练集上达到了98%的准确率和测试集上的93%，这比直接方法的表现要好得多。本文提供了关于利用图像增强技术提高迁移学习模型非接触式指纹识别准确性有效性的深入比较分析，为开发更高效的生物认证系统提供关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICSPIS63676.2024.10812653&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fingerprint recognition remains one of the most reliable biometrictechnologies due to its high accuracy and uniqueness. Traditional systems relyon contact-based scanners, which are prone to issues such as image degradationfrom surface contamination and inconsistent user interaction. To address theselimitations, contactless fingerprint recognition has emerged as a promisingalternative, providing non-intrusive and hygienic authentication. This studyevaluates the impact of image enhancement tech-niques on the performance ofpre-trained deep learning models using transfer learning for touchlessfingerprint recognition. The IIT-Bombay Touchless and Touch-Based FingerprintDatabase, containing data from 200 subjects, was employed to test theper-formance of deep learning architectures such as VGG-16, VGG-19,Inception-V3, and ResNet-50. Experimental results reveal that transfer learningmethods with fingerprint image enhance-ment (indirect method) significantlyoutperform those without enhancement (direct method). Specifically, VGG-16achieved an accuracy of 98% in training and 93% in testing when using theenhanced images, demonstrating superior performance compared to the directmethod.  This paper provides a detailed comparison of the effectiveness of imageenhancement in improving the accuracy of transfer learning models for touchlessfingerprint recognition, offering key insights for developing more efficientbiometric systems.</description>
      <author>example@mail.com (S Sreehari, Dilavar P D, S M Anzar, Alavikunhu Panthakkan, Saad Ali Amin)</author>
      <guid isPermaLink="false">2502.04680v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>DetVPCC: RoI-based Point Cloud Sequence Compression for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.04804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了DetVPCC，一种结合区域兴趣编码和视频点云压缩的方法，以提高3D对象检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的MPEG标准化的基于视频的点云压缩（VPCC）虽然在人类感知方面实现了高效的压缩效率，但在支持3D物体探测器时，在比特率节省与检测准确性之间存在较差的权衡问题。&lt;h4&gt;目的&lt;/h4&gt;改进现有技术以优化VPCC处理区域不同时重要性的能力，并提高其在三维对象检测中的表现。&lt;h4&gt;方法&lt;/h4&gt;通过引入非均匀质量分配来增强VPCC，使其支持基于区域兴趣（RoI）的压缩；开发了一种轻量级的RoI探测器用于识别潜在包含物体的关键区域。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在nuScenes数据集上采用该方法可以显著提高检测精度。&lt;h4&gt;结论&lt;/h4&gt;通过将VPCC与ROI编码相结合，可以实现高效的点云序列压缩并保持3D对象检测准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：尽管基于视频的点云压缩（VPCC）实现了对人类感知而言高效率的压缩效果，但在支持3D物体探测器时，在比特率节省和检测准确性的权衡上表现不佳。问题根源在于VPCC无法在点云的不同重要区域中进行优先级排序。为了解决这一挑战，我们提出了一种名为DetVPCC的新方法，该方法将区域兴趣（RoI）编码与VPCC结合使用，以实现高效的点云序列压缩同时保持3D物体检测精度。具体而言，我们将VPCC增强为支持基于空间非均匀质量级别的RoI编码；此外引入了一个轻量级的RoI探测器来识别含有潜在物体的重要区域。实验结果在nuScenes数据集上表明了该方法能够显著提高检测准确性。相关代码和演示视频可在补充材料中获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While MPEG-standardized video-based point cloud compression (VPCC) achieveshigh compression efficiency for human perception, it struggles with a poortrade-off between bitrate savings and detection accuracy when supporting 3Dobject detectors. This limitation stems from VPCC's inability to prioritizeregions of different importance within point clouds. To address this issue, wepropose DetVPCC, a novel method integrating region-of-interest (RoI) encodingwith VPCC for efficient point cloud sequence compression while preserving the3D object detection accuracy. Specifically, we augment VPCC to supportRoI-based compression by assigning spatially non-uniform quality levels. Then,we introduce a lightweight RoI detector to identify crucial regions thatpotentially contain objects. Experiments on the nuScenes dataset demonstratethat our approach significantly improves the detection accuracy. The code anddemo video are available in supplementary materials.</description>
      <author>example@mail.com (Mingxuan Yan, Ruijie Zhang, Xuedou Xiao, Wei Wang)</author>
      <guid isPermaLink="false">2502.04804v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Chest X-ray Foundation Model with Global and Local Representations Integration</title>
      <link>http://arxiv.org/abs/2502.05142v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为CheXFound的自监督视觉基础模型，该模型通过预训练学习出强大的胸部X光图像表示，并能在多种下游任务中表现出色。它在CXR-1M数据集上进行了预训练，包含超过一百万个独特的胸部X光影像。&lt;h4&gt;背景&lt;/h4&gt;胸部X光（CXR）是最常用的成像测试之一，支持从胸腔疾病检测到术后监测等多种临床任务。然而，现有的特定任务分类模型存在局限性，需要大量标注的数据，并且在面对非分布数据集时缺乏泛化能力。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够学习强大胸部X光表示并有效泛化至多种下游任务的自监督视觉基础模型。&lt;h4&gt;方法&lt;/h4&gt;通过预训练CheXFound于CXR-1M数据集中，该数据集包含超过一百万个独特的胸部X光影像。同时提出了全局和局部特征整合（GLoRI）模块以增强多标签分类中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在CXR-LT 24数据集上，CheXFound在多种流行率水平下对40种疾病表现的分类中优于现有最佳模型，并且在下游任务中表现出更强的数据效率。此外，该模型对于新任务和非分布数据集（如机会性心血管病风险评估及死亡率预测）的表现也得到了显著改善。&lt;h4&gt;结论&lt;/h4&gt;CheXFound具有强大的泛化能力，能够进行多种适应并提高标签效率。这些结果强调了其在各种胸部X光分析应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种名为CheXFound的自监督视觉基础模型的设计和评估过程，该模型旨在通过学习强大的胸部X光表示来解决现有分类模型的问题，并展示了它在多个领域的优越性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chest X-ray (CXR) is the most frequently ordered imaging test, supportingdiverse clinical tasks from thoracic disease detection to postoperativemonitoring. However, task-specific classification models are limited in scope,require costly labeled data, and lack generalizability to out-of-distributiondatasets. To address these challenges, we introduce CheXFound, aself-supervised vision foundation model that learns robust CXR representationsand generalizes effectively across a wide range of downstream tasks. Wepretrain CheXFound on a curated CXR-1M dataset, comprising over one millionunique CXRs from publicly available sources. We propose a Global and LocalRepresentations Integration (GLoRI) module for downstream adaptations, byincorporating disease-specific local features with global image features forenhanced performance in multilabel classification. Our experimental resultsshow that CheXFound outperforms state-of-the-art models in classifying 40disease findings across different prevalence levels on the CXR-LT 24 datasetand exhibits superior label efficiency on downstream tasks with limitedtraining data. Additionally, CheXFound achieved significant improvements on newtasks with out-of-distribution datasets, including opportunistic cardiovasculardisease risk estimation and mortality prediction. These results highlightCheXFound's strong generalization capabilities, enabling diverse adaptationswith improved label efficiency. The project source code is publicly availableat https://github.com/RPIDIAL/CheXFound.</description>
      <author>example@mail.com (Zefan Yang, Xuanang Xu, Jiajin Zhang, Ge Wang, Mannudeep K. Kalra, Pingkun Yan)</author>
      <guid isPermaLink="false">2502.05142v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Identifying Flaky Tests in Quantum Code: A Machine Learning Approach</title>
      <link>http://arxiv.org/abs/2502.04471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 1 figure, accepted by Q-SANER 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个利用多种机器学习模型来自动检测量子程序中不稳定测试的平台。&lt;h4&gt;背景问题&lt;/h4&gt;由于量子力学固有的复杂性，如叠加和纠缠，量子软件的测试与调试面临重大挑战。其中一个主要问题是不确定性导致量子程序中的测试不稳定性增加。&lt;h4&gt;研究目的&lt;/h4&gt;开发一个能够识别并分类量子程序中不稳定测试的机器学习平台，并扩大现有的数据集供其他研究人员使用。&lt;h4&gt;方法描述&lt;/h4&gt;采用多种机器学习模型，如极端梯度提升、决策树、随机森林、k近邻和支持向量机等来检测和分类量子不稳定的测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，在平衡数据集中，极端梯度提升模型表现最优；在不平衡数据集中，基于决策树的模型效果最好。它们分别达到了最高的F1分数和马修斯相关系数。&lt;h4&gt;未来研究方向&lt;/h4&gt;计划探索无监督学习技术的发展，以更有效地检测和分类量子程序中的不稳定测试。&lt;h4&gt;贡献&lt;/h4&gt;为当前缺乏对量子不稳定性系统研究提供了一个平台，并扩大了现有数据集供进一步的研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Testing and debugging quantum software pose significant challenges due to theinherent complexities of quantum mechanics, such as superposition andentanglement. One challenge is indeterminacy, a fundamental characteristic ofquantum systems, which increases the likelihood of flaky tests in quantumprograms. To the best of our knowledge, there is a lack of comprehensivestudies on quantum flakiness in the existing literature. In this paper, wepresent a novel machine learning platform that leverages multiple machinelearning models to automatically detect flaky tests in quantum programs. Ourevaluation shows that the extreme gradient boosting and decision tree-basedmodels outperform other models (i.e., random forest, k-nearest neighbors, andsupport vector machine), achieving the highest F1 score and MatthewsCorrelation Coefficient in a balanced dataset and an imbalanced dataset,respectively. Furthermore, we expand the currently limited dataset forresearchers interested in quantum flaky tests. In the future, we plan toexplore the development of unsupervised learning techniques to detect andclassify quantum flaky tests more effectively. These advancements aim toimprove the reliability and robustness of quantum software testing.</description>
      <author>example@mail.com (Khushdeep Kaur, Dongchan Kim, Ainaz Jamshidi, Lei Zhang)</author>
      <guid isPermaLink="false">2502.04471v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Autoregressive Generation of Static and Growing Trees</title>
      <link>http://arxiv.org/abs/2502.04762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;我们提出了一种用于树生成的变压器架构和训练策略。该架构在多个分辨率上处理数据，并具有沙漏形状，中间层处理的标记少于外围层。类似于卷积网络，我们引入了更长范围的跳跃连接以补充这种多分辨率方法。此架构的关键优势在于更快的处理速度和更低的内存消耗。因此，我们可以处理比使用普通变压器架构可能更为复杂的树。此外，我们将这种方法扩展到执行图像到树和点云到树的条件生成，并模拟树木生长过程，生成4D树木。实证结果验证了我们在速度、内存消耗和生成质量方面的方法。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于树生成任务的新变压器架构及其训练策略，通过优化处理流程提高了效率并扩展了应用场景。&lt;h4&gt;背景&lt;/h4&gt;现有Transformer架构在复杂数据如大树结构的处理上面临速度慢及内存占用高的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够提高速度和降低内存使用量的同时还能处理更复杂树生成任务的新Transformer架构。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多分辨率的数据处理方式，具有类似卷积网络中的沙漏形状，中间层减少标记处理以优化性能，并引入长程跳跃连接来增强模型的能力。此方法还被扩展到图像和点云数据的条件生成以及树木生长模拟。&lt;h4&gt;主要发现&lt;/h4&gt;新架构能够比传统Transformer更快地生成复杂树结构且内存消耗更少；实验验证了该方法在速度、内存使用及生成质量上的优越性。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的Transformer架构，成功解决了处理复杂数据时的性能瓶颈，并展示了应用于不同领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a transformer architecture and training strategy for treegeneration. The architecture processes data at multiple resolutions and has anhourglass shape, with middle layers processing fewer tokens than outer layers.Similar to convolutional networks, we introduce longer range skip connectionsto completent this multi-resolution approach. The key advantage of thisarchitecture is the faster processing speed and lower memory consumption. Weare therefore able to process more complex trees than would be possible with avanilla transformer architecture. Furthermore, we extend this approach toperform image-to-tree and point-cloud-to-tree conditional generation and tosimulate the tree growth processes, generating 4D trees. Empirical resultsvalidate our approach in terms of speed, memory consumption, and generationquality.</description>
      <author>example@mail.com (Hanxiao Wang, Biao Zhang, Jonathan Klein, Dominik L. Michels, Dongming Yan, Peter Wonka)</author>
      <guid isPermaLink="false">2502.04762v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Learning Temporal Invariance in Android Malware Detectors</title>
      <link>http://arxiv.org/abs/2502.05098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基于学习的Android恶意软件检测器在面对自然分布漂移时性能下降的问题，并提出了TIF框架，以提高检测器跨时间稳定表示的能力。&lt;h4&gt;背景&lt;/h4&gt;由于恶意软件变种和新家族的出现，基于学习的安卓恶意软件检测器会随着时间的推移而性能退化。这种退化主要是由训练数据集的自然分布漂移导致的。&lt;h4&gt;目的&lt;/h4&gt;为了提高检测器在面对时间变化时的能力，本文提出了一种名为TIF的时间不变性训练框架。&lt;h4&gt;方法&lt;/h4&gt;TIF通过基于应用观察日期组织环境来揭示时间上的漂移，并结合专门设计的多代理对比学习和不变梯度对齐技术生成高质量、稳定的表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TIF在长时间数据集上表现出色，尤其是在早期部署阶段，优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;TIF框架提供了一种有效的方法来提高基于学习的恶意软件检测器的时间稳定性，并能无缝集成到任何学习基础的检测器中。&lt;h4&gt;翻译&lt;/h4&gt;学习型安卓恶意软件检测器由于自然分布漂移导致性能随时间退化，该论文系统地研究了在经验风险最小化（ERM）训练的分类器面对此类分布偏移时所面临的挑战，并将这些问题归因于它们无法学习稳定的判别性特征。不变学习理论提供了一个有前景的解决方案，通过鼓励模型生成跨越暴露训练集不稳定性的环境的稳定表示来解决这一问题。然而，缺乏先前环境标签、漂移因素多样性以及由于家族多样性的低质量表示使得此任务具有挑战性。为了解决这些问题，我们提出了TIF——第一个用于恶意软件检测的时间不变性训练框架，旨在增强检测器跨时间学习稳定表示的能力。TIF根据应用观察日期组织环境来揭示时间漂移，并结合专门设计的多代理对比学习和不变梯度对齐技术生成并调整具有高质量、稳定表示的环境。TIF可以无缝集成到任何基于学习的检测器中。在十年数据集上的实验表明，TIF表现出色，特别是在早期部署阶段，满足了现实世界的需求，并超越了最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based Android malware detectors degrade over time due to naturaldistribution drift caused by malware variants and new families. This papersystematically investigates the challenges classifiers trained with empiricalrisk minimization (ERM) face against such distribution shifts and attributestheir shortcomings to their inability to learn stable discriminative features.Invariant learning theory offers a promising solution by encouraging models togenerate stable representations crossing environments that expose theinstability of the training set. However, the lack of prior environment labels,the diversity of drift factors, and low-quality representations caused bydiverse families make this task challenging. To address these issues, wepropose TIF, the first temporal invariant training framework for malwaredetection, which aims to enhance the ability of detectors to learn stablerepresentations across time. TIF organizes environments based on applicationobservation dates to reveal temporal drift, integrating specialized multi-proxycontrastive learning and invariant gradient alignment to generate and alignenvironments with high-quality, stable representations. TIF can be seamlesslyintegrated into any learning-based detector. Experiments on a decade-longdataset show that TIF excels, particularly in early deployment stages,addressing real-world needs and outperforming state-of-the-art methods.</description>
      <author>example@mail.com (Xinran Zheng, Shuo Yang, Edith C. H. Ngai, Suman Jana, Lorenzo Cavallaro)</author>
      <guid isPermaLink="false">2502.05098v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Provable Sample-Efficient Transfer Learning Conditional Diffusion Models via Representation Learning</title>
      <link>http://arxiv.org/abs/2502.04491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了在小数据集情况下条件扩散模型的迁移学习理论基础，通过分析表示学习来研究样本效率。&lt;h4&gt;背景&lt;/h4&gt;条件扩散模型虽然在实际应用中取得了显著成功，但需要大量的训练数据。为解决这一问题，迁移学习成为了一种关键的方法。&lt;h4&gt;目的&lt;/h4&gt;探索和理解条件扩散模型迁移学习的样本效率。&lt;h4&gt;方法&lt;/h4&gt;通过假设所有任务共享一个低维表示来研究转移学习条件扩散模型的理论基础，并分析在目标任务中使用来源任务的学习表示可以显著减少所需的样本复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，当有一个从源任务中学到的良好表示时，目标任务所需的样本数量可以大大降低。此外，在几个现实世界的应用中验证了该理论结果的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过迁移学习的视角来理解条件扩散模型的理论基础，对实际中的小数据问题提供了有效的解决方案，并为未来的研究指明方向。&lt;h4&gt;翻译&lt;/h4&gt;虽然条件扩散模型在各种应用中取得了显著的成功，但它们需要大量的数据从头开始训练，在实践中这通常是不切实际的。为了应对这一挑战，迁移学习作为一种重要的方法出现在了数据量较小的情况下。尽管其实验结果令人满意，但对于转移学习条件扩散模型背后的理论依据尚未进行探索。在这篇论文中，我们首次通过表示学习来理解迁移学习条件下扩散模型的样本效率。受到实践中训练程序的启发，我们假设所有任务共享一个低维的条件表示。我们的分析表明，在源任务上有了良好的表示学习后，目标任务上的样本复杂度可以显著降低。此外，我们也研究了该理论成果在几个实际应用中的实际意义，并通过数值实验验证了这些发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While conditional diffusion models have achieved remarkable success invarious applications, they require abundant data to train from scratch, whichis often infeasible in practice. To address this issue, transfer learning hasemerged as an essential paradigm in small data regimes. Despite its empiricalsuccess, the theoretical underpinnings of transfer learning conditionaldiffusion models remain unexplored. In this paper, we take the first steptowards understanding the sample efficiency of transfer learning conditionaldiffusion models through the lens of representation learning. Inspired bypractical training procedures, we assume that there exists a low-dimensionalrepresentation of conditions shared across all tasks. Our analysis shows thatwith a well-learned representation from source tasks, the samplecomplexity oftarget tasks can be reduced substantially. In addition, we investigate thepractical implications of our theoretical results in several real-worldapplications of conditional diffusion models. Numerical experiments are alsoconducted to verify our results.</description>
      <author>example@mail.com (Ziheng Cheng, Tianyu Xie, Shiyue Zhang, Cheng Zhang)</author>
      <guid isPermaLink="false">2502.04491v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification</title>
      <link>http://arxiv.org/abs/2502.05000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for poster at WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文提出了一种名为DiffSP的基于扩散结构净化框架，旨在通过去除对抗性样本来提高图神经网络对不同类型逃避攻击的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的防御方法通常依赖于关于干净图或攻击策略的先验知识，这些知识往往是启发式的且不一致的。为了在没有这些假设的情况下实现健壮的图学习，需要新的解决方案。&lt;h4&gt;目的&lt;/h4&gt;研究一种无先验的结构净化框架来对抗不同类型的逃避攻击，并适用于多种数据集。&lt;h4&gt;方法&lt;/h4&gt;提出了DiffSP框架，该框架包含前向扩散过程和反向去噪过程。通过前向过程捕获干净图的内在分布，并在不依赖于先验的情况下去除受扰结构中的对抗性样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DiffSP在抵御逃避攻击方面表现出优越的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DiffSP框架提供了一种有效的方法来提高图神经网络对各种逃避攻击的防御能力。&lt;h4&gt;翻译&lt;/h4&gt;论文摘要描述了用于改善图学习对抗逃避攻击鲁棒性的Diffusion-based Structure Purification(DiffSP)框架，该框架能够通过去除受扰结构中的对抗性样本而不依赖于先验知识，从而提高不同数据集上的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adversarial evasion attacks pose significant threats to graph learning, withlines of studies that have improved the robustness of Graph Neural Networks(GNNs). However, existing works rely on priors about clean graphs or attackingstrategies, which are often heuristic and inconsistent. To achieve robust graphlearning over different types of evasion attacks and diverse datasets, weinvestigate this problem from a prior-free structure purification perspective.Specifically, we propose a novel Diffusion-based Structure Purificationframework named DiffSP, which creatively incorporates the graph diffusion modelto learn intrinsic distributions of clean graphs and purify the perturbedstructures by removing adversaries under the direction of the capturedpredictive patterns without relying on priors. DiffSP is divided into theforward diffusion process and the reverse denoising process, during whichstructure purification is achieved. To avoid valuable information loss duringthe forward process, we propose an LID-driven nonisotropic diffusion mechanismto selectively inject noise anisotropically. To promote semantic alignmentbetween the clean graph and the purified graph generated during the reverseprocess, we reduce the generation uncertainty by the proposed graph transferentropy guided denoising mechanism. Extensive experiments demonstrate thesuperior robustness of DiffSP against evasion attacks.</description>
      <author>example@mail.com (Jiayi Luo, Qingyun Sun, Haonan Yuan, Xingcheng Fu, Jianxin Li)</author>
      <guid isPermaLink="false">2502.05000v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Pre-Trained Decision Transformers with Prompt-Tuning Bandits</title>
      <link>http://arxiv.org/abs/2502.04979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于离线强化学习的多任务模型Prompting Decision Transformer (PDT)，该模型通过特定于任务的轨迹提示来区分不同的任务。然而，PDT 在采样这些令牌时采用了均匀随机的方法，这可能导致性能下降。为了解决这一问题，作者引入了一个可扩展的基于bandit（赌博机）策略的学习方法来进行动态地构建高性能的轨迹提示。&lt;h4&gt;背景&lt;/h4&gt;利用大型离线数据集对于训练能够跨多样任务泛化的基础模型至关重要。离线强化学习提供了在处理次优数据时推导出最优策略的强大框架。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进的方法，以提升Prompting Decision Transformer (PDT) 在多任务环境中的性能表现，并减少对预训练Transformer骨干的修改。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于bandit（赌博机）策略的学习方法来动态学习构建高性能轨迹提示，该方法能够根据任务需求调整令牌选取的方式，从而提高模型的整体性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在基准任务和新设计的多任务环境中均表现出了有效性。此外，还展示了该方法能够在一般的多任务离线预训练与特定任务在线适应之间建立无缝连接。&lt;h4&gt;结论&lt;/h4&gt;通过改进令牌采样机制，论文展示了一种有效的方法来增强Prompting Decision Transformer (PDT) 的性能，并且这种方法不需要对基础模型进行显著修改。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Harnessing large offline datasets is vital for training foundation modelsthat can generalize across diverse tasks. Offline Reinforcement Learning (RL)offers a powerful framework for these scenarios, enabling the derivation ofoptimal policies even from suboptimal data. The Prompting Decision Transformer(PDT) is an offline RL multi-task model that distinguishes tasks throughstochastic trajectory prompts, which are task-specific tokens maintained incontext during rollouts. However, PDT samples these tokens uniformly at randomfrom per-task demonstration datasets, failing to account for differences intoken informativeness and potentially leading to performance degradation. Toaddress this limitation, we introduce a scalable bandit-based prompt-tuningmethod that dynamically learns to construct high-performance trajectoryprompts. Our approach significantly enhances downstream task performancewithout modifying the pre-trained Transformer backbone. Empirical results onbenchmark tasks and a newly designed multi-task environment demonstrate theeffectiveness of our method, creating a seamless bridge between generalmulti-task offline pre-training and task-specific online adaptation.</description>
      <author>example@mail.com (Finn Rietz, Oleg Smirnov, Sara Karimi, Lele Cao)</author>
      <guid isPermaLink="false">2502.04979v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Learning Street View Representations with Spatiotemporal Contrast</title>
      <link>http://arxiv.org/abs/2502.04638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种创新的自监督学习框架，利用街道视图图像的时间和空间属性来学习动态城市环境的图像表示。&lt;h4&gt;背景&lt;/h4&gt;街道视图图像在城市视觉环境中广泛用于表征学习，并支持诸如环境感知和社会经济评估等可持续发展任务。然而，现有的图像表示方法难以具体编码街景中描绘的城市环境、建筑环境以及社会文化氛围等动态元素。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用街道视图图像的时间和空间属性来学习适用于不同下游任务的动态城市环境图像表示的方法。&lt;h4&gt;方法&lt;/h4&gt;通过使用在相同地点随时间变化捕获的街景图片及同一时刻附近视点的街景图片，构建对比学习任务以学习建筑环境中的时间不变特性和邻域氛围的空间不变特性。这种方法显著优于传统的监督和无监督方法，在视觉地方识别、社会经济估算以及人与环境感知等任务中表现突出。&lt;h4&gt;主要发现&lt;/h4&gt;通过不同的对比学习目标所学到的图像表示在各种下游任务中有不同的行为表现，为城市研究中的表征学习策略提供了一个基准。&lt;h4&gt;结论&lt;/h4&gt;该研究系统地讨论了基于街景图片的城市科学研究中的表示学习策略，并增强了视觉数据在城市科学中的适用性。代码可在GitHub上找到：https://github.com/yonglleee/UrbanSTCL&lt;h4&gt;翻译&lt;/h4&gt;街道视图图像被广泛应用于城市视觉环境的表征学习，支持诸如环境感知和社会经济评估等可持续发展目标任务。然而，现有图像表示难以具体编码街景中描绘的城市动态、建筑环境以及社会文化氛围以解决与城市发展相关的下游任务。为此，我们提出了一种创新性的自监督学习框架，该框架利用街道视图影像的时间和空间属性来学习适用于各种下游任务的动态城市环境的图像表征。通过使用同一地点随时间变化捕获的街景图片及同一时刻附近视点的街景图片构建对比学习任务，以学习建筑环境中的时间不变特性和邻域氛围的空间不变特性。我们的方法在视觉地方识别、社会经济估算以及人与环境感知等任务中显著优于传统监督和无监督的方法，并且展示了通过不同对比学习目标所学到的图像表示如何在各种下游任务中有不同的行为表现。该研究系统地讨论了基于街景图片的城市科学研究中的表征学习策略，为视觉数据的应用提供了基准并增强了其在城市科学中的适用性。代码可在GitHub上找到：https://github.com/yonglleee/UrbanSTCL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Street view imagery is extensively utilized in representation learning forurban visual environments, supporting various sustainable development taskssuch as environmental perception and socio-economic assessment. However, it ischallenging for existing image representations to specifically encode thedynamic urban environment (such as pedestrians, vehicles, and vegetation), thebuilt environment (including buildings, roads, and urban infrastructure), andthe environmental ambiance (such as the cultural and socioeconomic atmosphere)depicted in street view imagery to address downstream tasks related to thecity. In this work, we propose an innovative self-supervised learning frameworkthat leverages temporal and spatial attributes of street view imagery to learnimage representations of the dynamic urban environment for diverse downstreamtasks. By employing street view images captured at the same location over timeand spatially nearby views at the same time, we construct contrastive learningtasks designed to learn the temporal-invariant characteristics of the builtenvironment and the spatial-invariant neighborhood ambiance. Our approachsignificantly outperforms traditional supervised and unsupervised methods intasks such as visual place recognition, socioeconomic estimation, andhuman-environment perception. Moreover, we demonstrate the varying behaviors ofimage representations learned through different contrastive learning objectivesacross various downstream tasks. This study systematically discussesrepresentation learning strategies for urban studies based on street viewimages, providing a benchmark that enhances the applicability of visual data inurban science. The code is available at https://github.com/yonglleee/UrbanSTCL.</description>
      <author>example@mail.com (Yong Li, Yingjing Huang, Gengchen Mai, Fan Zhang)</author>
      <guid isPermaLink="false">2502.04638v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>AIQViT: Architecture-Informed Post-Training Quantization for Vision Transformers</title>
      <link>http://arxiv.org/abs/2502.04628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对视觉变压器（ViTs）的创新后训练量化方法AIQViT，旨在提高其在低比特情况下的性能，并减少存储和计算成本。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数后训练量化方法低估了权重量化的信息损失，导致显著的性能下降。特别是在量化工件后的Softmax激活值时，通常采用对数转换来优先处理接近零的信息较少的部分。&lt;h4&gt;目的&lt;/h4&gt;通过设计新的补偿机制和适应不平衡分布的动态聚焦量化器，AIQViT旨在解决现有方法中存在的问题，并提高ViTs在不同视觉任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 设计了一种架构感知低秩补偿机制，在其中引入了可学习的低秩权重来补偿由权重量化引起的退化。2. 设计了一个动态聚焦量化器，以适应工件后Softmax激活值不平衡分布，并在最重要的区间内提供更高的量化分辨率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AIQViT在图像分类、目标检测、实例分割、点云分类和点云部分分割等五项视觉任务上优于现有的最先进的PTQ方法。&lt;h4&gt;结论&lt;/h4&gt;该论文提出的AIQViT方法有效解决了现有后训练量化技术中遇到的问题，并显著提高了ViTs的性能，尤其适用于低比特情况下的应用。&lt;h4&gt;翻译&lt;/h4&gt;后训练量化（PTQ）已经作为减少存储和计算成本的一种有前途的方法出现。最近的研究主要集中在为处理由ViTs特有的激活而设计量化的技术上。然而，大多数现有方法低估了权重量化引起的信息损失，在低比特情况下导致性能显著下降。在量化ViTs的工件后Softmax激活值时，常用的是对数转换，不幸地优先考虑接近零的不太重要的值，这引入额外冗余，并最终导致次优量化的效率。为解决这些问题，本文提出了一种针对ViTs的新PTQ方法AIQViT（架构感知的ViTs后训练量化）。第一，设计了架构感知低秩补偿机制，在其中引入可学习的低秩权重来补偿由权重量化引起的退化。第二，设计了一个动态聚焦量化器以适应工件后Softmax激活值分布不平衡，并在最重要的区间内提供更高的量化分辨率。广泛的实验结果表明AIQViT优于现有的最先进的PTQ方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Post-training quantization (PTQ) has emerged as a promising solution forreducing the storage and computational cost of vision transformers (ViTs).Recent advances primarily target at crafting quantizers to deal with peculiaractivations characterized by ViTs. However, most existing methods underestimatethe information loss incurred by weight quantization, resulting in significantperformance deterioration, particularly in low-bit cases. Furthermore, a commonpractice in quantizing post-Softmax activations of ViTs is to employlogarithmic transformations, which unfortunately prioritize less informativevalues around zero. This approach introduces additional redundancies,ultimately leading to suboptimal quantization efficacy. To handle these, thispaper proposes an innovative PTQ method tailored for ViTs, termed AIQViT(Architecture-Informed Post-training Quantization for ViTs). First, we designan architecture-informed low rank compensation mechanism, wherein learnablelow-rank weights are introduced to compensate for the degradation caused byweight quantization. Second, we design a dynamic focusing quantizer toaccommodate the unbalanced distribution of post-Softmax activations, whichdynamically selects the most valuable interval for higher quantizationresolution. Extensive experiments on five vision tasks, including imageclassification, object detection, instance segmentation, point cloudclassification, and point cloud part segmentation, demonstrate the superiorityof AIQViT over state-of-the-art PTQ methods.</description>
      <author>example@mail.com (Runqing Jiang, Ye Zhang, Longguang Wang, Pengpeng Yu, Yulan Guo)</author>
      <guid isPermaLink="false">2502.04628v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Goku: Flow Based Video Generative Foundation Models</title>
      <link>http://arxiv.org/abs/2502.04896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  page: https://saiyan-world.github.io/goku/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Goku是一个先进的联合图像和视频生成模型系列，利用校正流Transformer来实现业内领先的表现。&lt;h4&gt;背景&lt;/h4&gt;目前的视觉生成任务中存在数据管理和训练效率的问题，特别是在大规模的数据集上进行有效且稳健的大规模训练方面。&lt;h4&gt;目的&lt;/h4&gt;介绍并详细阐述了Goku的设计理念、架构和功能，以及它如何在质量和数量评估中表现出色，并设置新的基准。&lt;h4&gt;方法&lt;/h4&gt;介绍了Goku模型的基础元素，包括数据整理管道、模型架构设计、流公式化以及用于高效且稳健的大规模训练的先进基础设施。&lt;h4&gt;主要发现&lt;/h4&gt;Goku在多项任务上设置了新的性能基准，在GenEval上的得分为0.76，在DPG-Bench上的得分为83.65（针对文本到图像生成），以及在VBench上的得分达到了84.85（针对文本到视频任务）。&lt;h4&gt;结论&lt;/h4&gt;这项工作为研究社区提供了有价值的见解和实际进展，特别是在联合图像和视频生成模型的发展方面。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了Goku，这是一个最先进的联合图像和视频生成模型系列，利用校正流Transformer来实现业内领先的表现。我们详细描述了支撑高质量视觉生成的基础元素，包括数据整理管道、模型架构设计、流公式化以及用于有效且稳健的大规模训练的先进基础设施。Goku模型在定性和定量评估中表现出色，在主要任务上设置了新的基准。特别是，Goku在GenEval和DPG-Bench上的文本到图像生成得分为0.76和83.65，在VBench上的文本到视频任务得分达到了84.85。我们相信这项工作为研究社区提供了有价值的见解和实际进展，特别是在开发联合图像和视频生成模型方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces Goku, a state-of-the-art family of jointimage-and-video generation models leveraging rectified flow Transformers toachieve industry-leading performance. We detail the foundational elementsenabling high-quality visual generation, including the data curation pipeline,model architecture design, flow formulation, and advanced infrastructure forefficient and robust large-scale training. The Goku models demonstrate superiorperformance in both qualitative and quantitative evaluations, setting newbenchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench fortext-to-video tasks. We believe that this work provides valuable insights andpractical advancements for the research community in developing jointimage-and-video generation models.</description>
      <author>example@mail.com (Shoufa Chen, Chongjian Ge, Yuqi Zhang, Yida Zhang, Fengda Zhu, Hao Yang, Hongxiang Hao, Hui Wu, Zhichao Lai, Yifei Hu, Ting-Che Lin, Shilong Zhang, Fu Li, Chuan Li, Xing Wang, Yanghua Peng, Peize Sun, Ping Luo, Yi Jiang, Zehuan Yuan, Bingyue Peng, Xiaobing Liu)</author>
      <guid isPermaLink="false">2502.04896v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin</title>
      <link>http://arxiv.org/abs/2502.04794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为MedMimic的多模态框架，该框架旨在通过结合18F-FDG PET/CT成像和临床数据来诊断发热病因不明（FUO）病例。&lt;h4&gt;背景&lt;/h4&gt;发热病因不明（FUO）仍然是一个难以诊断的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于真实世界诊断过程的多模态框架MedMimic，用于改进对发热病因不明（FUO）患者的诊断。&lt;h4&gt;方法&lt;/h4&gt;利用预训练模型如DINOv2、Vision Transformer和ResNet-18将高维的18F-FDG PET/CT图像转化为低维度且具有语义意义的特征。然后通过一个可学习自注意力融合网络将这些成像数据与临床数据结合进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;在四川大学华西医院收集的416例FUO患者病例（2017年至2023年）上，多模态融合分类器MFCN实现了从0.8654到0.9291不等的宏AUROC评分，在七项任务中优于传统的机器学习和单一模式深度学习方法。消融研究和五倍交叉验证进一步证实了其有效性。&lt;h4&gt;结论&lt;/h4&gt;通过结合大型预训练模型和深度学习的优势，MedMimic为疾病分类提供了一种有前景的方法。&lt;h4&gt;翻译&lt;/h4&gt;发热病因不明（FUO）仍然是一个诊断难题。MedMimic被引入作为一种多模态框架，灵感来源于现实世界的诊断过程。它使用预训练的模型如DINOv2、Vision Transformer和ResNet-18将高维的18F-FDG PET/CT成像转化为低维度且具有语义意义的特征。接着通过一个基于可学习自注意力机制的融合网络整合这些成像特征与临床数据进行分类。使用四川大学华西医院从2017年至2023年收集的416例FUO患者病例，多模态融合分类器MFCN在七项任务中实现了宏观AUROC评分范围为0.8654到0.9291的成绩，超过了传统机器学习和单一模式深度学习方法的表现。消融研究和五倍交叉验证进一步验证了其有效性。通过结合大型预训练模型和深度学习的优势，MedMimic提供了一种有前景的疾病分类解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fever of unknown origin FUO remains a diagnostic challenge. MedMimic isintroduced as a multimodal framework inspired by real-world diagnosticprocesses. It uses pretrained models such as DINOv2, Vision Transformer, andResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging intolow-dimensional, semantically meaningful features. A learnableself-attention-based fusion network then integrates these imaging features withclinical data for classification. Using 416 FUO patient cases from SichuanUniversity West China Hospital from 2017 to 2023, the multimodal fusionclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to0.9291 across seven tasks, outperforming conventional machine learning andsingle-modality deep learning methods. Ablation studies and five-foldcross-validation further validated its effectiveness. By combining thestrengths of pretrained large models and deep learning, MedMimic offers apromising solution for disease classification.</description>
      <author>example@mail.com (Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo)</author>
      <guid isPermaLink="false">2502.04794v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Neural Clustering for Prefractured Mesh Generation in Real-time Object Destruction</title>
      <link>http://arxiv.org/abs/2502.04615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于深度学习的方法，用于生成预破碎网格，以提高实时物体破坏的现实性和质量。&lt;h4&gt;背景&lt;/h4&gt;传统的预碎方法在性能约束下难以实现真实的实时对象破坏效果，并且由于其启发式性质可能会产生不切实际的结果。&lt;h4&gt;目的&lt;/h4&gt;通过将预碎网格的聚类视为点云数据上的无序分割问题，利用基于物理的数据训练深度神经网络来预测物体结构弱点。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的范例，该范例采用在基于物理数据集上训练的深层神经网络来生成有序且高质量的预破碎网格。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型能够准确地预测物体的结构弱点，并产生可直接使用的、质量出色的预碎效果。&lt;h4&gt;结论&lt;/h4&gt;新方法成功解决了传统预碎技术中的问题，提高了实时对象破坏模拟的质量和真实性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预破碎法是实现实时对象破坏的一种实用实施方案，在性能限制下难以达成真实的效果，但因其启发式性质可能会导致不现实的结果。为了解决这个问题，我们以无序分割的形式处理基于点云数据的预制网格生成问题，并提出利用在物理基础数据集上训练的深度神经网络的方法。我们的新方法成功预测出结构脆弱性的有限物体，展示了出色的可直接使用结果和质量水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3681756.3697973&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prefracture method is a practical implementation for real-time objectdestruction that is hardly achievable within performance constraints, but canproduce unrealistic results due to its heuristic nature. To mitigate it, weapproach the clustering of prefractured mesh generation as an unorderedsegmentation on point cloud data, and propose leveraging the deep neuralnetwork trained on a physics-based dataset. Our novel paradigm successfullypredicts the structural weakness of object that have been limited, exhibitingready-to-use results with remarkable quality.</description>
      <author>example@mail.com (Seunghwan Kim, Sunha Park, Seungkyu Lee)</author>
      <guid isPermaLink="false">2502.04615v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring</title>
      <link>http://arxiv.org/abs/2502.04891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了三种不同的图重连策略，以改进消息传递图神经网络（GNN）的性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;最大化谱间隙通过图重构被认为可以增强基于消息传递的GNN的表现来解决过度压缩问题。然而，本文表明最小化谱间隙也可以提高泛化性。&lt;h4&gt;目的&lt;/h4&gt;分析如何通过重连优化改进GNN在随机块模型中的性能，并提出三种不同的策略以进一步改善社区结构和标签之间的对齐。&lt;h4&gt;方法&lt;/h4&gt;提出了基于社区结构的重连（ComMa）、基于特征相似性的重连（FeaSt）以及结合上述两种方法的混合策略（ComFy）。这些方法旨在优化节点标签与社区结构之间的一致性，同时提高全局同质性和保持社区强度。&lt;h4&gt;主要发现&lt;/h4&gt;谱间隙优化主要影响社区强度，并且当社区结构与节点标签相匹配时会提升性能。基于这一见解提出的三种重连策略在实验中被证明是有效的。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法不仅能够改进GNN的泛化性，还提供了一种更加计算效率高的替代方案（ComMa），这种方案可以实现类似于谱间隙优化的目标。&lt;h4&gt;翻译&lt;/h4&gt;通过最大化或最小化图中的谱间隙来增强基于消息传递的图形神经网络（GNN）的表现是一个研究热点。本文探讨了如何通过改变社区结构和节点标签之间的关系，以改进模型在随机块模型中的性能。结果表明，当社区结构与节点标签一致时，调整图可以显著提高泛化能力。根据这一发现，作者提出了一系列策略来优化这种一致性，包括基于社区结构的重连、特征相似性重连以及两者结合的方式。这些方法经过实验验证，在提升GNN效果方面展现了良好的潜力和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Maximizing the spectral gap through graph rewiring has been proposed toenhance the performance of message-passing graph neural networks (GNNs) byaddressing over-squashing. However, as we show, minimizing the spectral gap canalso improve generalization. To explain this, we analyze how rewiring canbenefit GNNs within the context of stochastic block models. Since spectral gapoptimization primarily influences community strength, it improves performancewhen the community structure aligns with node labels. Building on this insight,we propose three distinct rewiring strategies that explicitly target communitystructure, node labels, and their alignment: (a) community structure-basedrewiring (ComMa), a more computationally efficient alternative to spectral gapoptimization that achieves similar goals; (b) feature similarity-based rewiring(FeaSt), which focuses on maximizing global homophily; and (c) a hybridapproach (ComFy), which enhances local feature similarity while preservingcommunity structure to optimize label-community alignment. Extensiveexperiments confirm the effectiveness of these strategies and support ourtheoretical insights.</description>
      <author>example@mail.com (Celia Rubio-Madrigal, Adarsh Jamadandi, Rebekka Burkholz)</author>
      <guid isPermaLink="false">2502.04891v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging a Simulator for Learning Causal Representations from Post-Treatment Covariates for CATE</title>
      <link>http://arxiv.org/abs/2502.05037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at TMLR-25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了在治疗后收集协变量和结果时，如何估计条件平均处理效应（CATE）。提出了一种新方法SimPONet，通过对比学习从现实数据与模拟器生成的数据中恢复CATE。&lt;h4&gt;背景&lt;/h4&gt;传统的方法是基于观察性数据集来估计CATE，在这种情况下，协变量是在治疗分配之前收集的，而结果则在之后被观察到。然而当协变量和结果都是在处理后获取时，现有的方法无法有效工作。&lt;h4&gt;目的&lt;/h4&gt;系统地分析模拟器在估计CATE中的作用，并提出一种新方法SimPONet来克服现有模型的局限性。&lt;h4&gt;方法&lt;/h4&gt;通过对比学习从有反事实监督的数据中恢复治疗独立因果表示。进一步发展了基于泛化界限的新方法SimPONet，该方法可以调整仿真器对学习目标的影响以适应CATE任务的需求。&lt;h4&gt;主要发现&lt;/h4&gt;提出了SimPONet模型，并通过实验表明它在各种数据生成过程（DGPs）下优于现有的基准模型。&lt;h4&gt;结论&lt;/h4&gt;通过结合现实和模拟的数据来估计CATE是可能的，且新方法SimPONet可以有效地调整其学习目标以适应不同类型的仿真器。这为解决CATE问题提供了一种新的途径。&lt;h4&gt;翻译&lt;/h4&gt;治疗效果估计涉及到评估不同的治疗方法对个人结果的影响。当前的方法使用观察性数据集来估计条件平均处理效应（CATE），其中协变量是在治疗分配之前收集的，而结果则在之后被观察到，在假设如肯定性和无混淆性的前提下进行。本文解决了这样一种情况：即协变量和结果都是在治疗后获取的。我们展示了治疗后的协变量使CATE不可识别，并且恢复CATE需要学习处理独立的因果表示。之前的工作表明，如果观测数据中有反事实监督，则可以通过对比学习来学习这样的表示形式。然而，由于反事实是罕见的，其他工作探索了使用提供合成反事实监督的模拟器的方法。本文的目标是在估计CATE时系统地分析模拟器的作用。我们分析了几种基线的CATE误差，并指出了它们的局限性。然后确立了一个泛化界限，该界限表征联合训练于现实和模拟分布上的CATE误差作为现实-模拟器不匹配函数的功能。最后，引入了SimPONet这一新方法，其损失函数灵感来自我们的泛化界限。我们进一步展示了如何根据仿真器与CATE任务的相关性来调整SimPONet的仿真器影响。通过系统地改变真实和仿真的分布差距来评估SimPONet相对于最先进的CATE基准的方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Treatment effect estimation involves assessing the impact of differenttreatments on individual outcomes. Current methods estimate Conditional AverageTreatment Effect (CATE) using observational datasets where covariates arecollected before treatment assignment and outcomes are observed afterward,under assumptions like positivity and unconfoundedness. In this paper, weaddress a scenario where both covariates and outcomes are gathered aftertreatment. We show that post-treatment covariates render CATE unidentifiable,and recovering CATE requires learning treatment-independent causalrepresentations. Prior work shows that such representations can be learnedthrough contrastive learning if counterfactual supervision is available inobservational data. However, since counterfactuals are rare, other works haveexplored using simulators that offer synthetic counterfactual supervision. Ourgoal in this paper is to systematically analyze the role of simulators inestimating CATE. We analyze the CATE error of several baselines and highlighttheir limitations. We then establish a generalization bound that characterizesthe CATE error from jointly training on real and simulated distributions, as afunction of the real-simulator mismatch. Finally, we introduce SimPONet, anovel method whose loss function is inspired from our generalization bound. Wefurther show how SimPONet adjusts the simulator's influence on the learningobjective based on the simulator's relevance to the CATE task. We experimentwith various DGPs, by systematically varying the real-simulator distributiongap to evaluate SimPONet's efficacy against state-of-the-art CATE baselines.</description>
      <author>example@mail.com (Lokesh Nagalapatti, Pranava Singhal, Avishek Ghosh, Sunita Sarawagi)</author>
      <guid isPermaLink="false">2502.05037v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning-Enhanced Large Language Models for Monolith-to-Microservice Decomposition</title>
      <link>http://arxiv.org/abs/2502.04604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种基于语言模型的方法MonoEmbed，用于自动化将单体应用分解为微服务的过程。&lt;h4&gt;背景&lt;/h4&gt;随着单体应用程序的发展，维护和改进变得越来越困难，导致了扩展性和组织问题。微服务架构因其模块化、灵活性和可扩展性而提供了大型规模应用程序的解决方案。&lt;h4&gt;目的&lt;/h4&gt;解决从单体架构迁移到微服务架构时遇到的复杂且成本高昂的问题，特别是分解步骤的挑战。&lt;h4&gt;方法&lt;/h4&gt;MonoEmbed利用最先进的大规模语言模型（LLMs）和技术进行表示学习，生成用于表征单体组件的向量，并通过聚类形成微服务。同时采用对比学习和低秩适应等技术对预训练模型进行调优。&lt;h4&gt;主要发现&lt;/h4&gt;经过调优后的模型在改善表示向量的质量方面表现出显著的优势，与预训练模型和传统方法相比有明显改进。提出的这种方法在生成单体应用程序的连贯且平衡的微服务方面优于现有分解方法。&lt;h4&gt;结论&lt;/h4&gt;MonoEmbed提供了一种有效的方法来克服将单体应用迁移到微服务架构时遇到的技术挑战，并为这一领域的研究提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As Monolithic applications evolve, they become increasingly difficult tomaintain and improve, leading to scaling and organizational issues. TheMicroservices architecture, known for its modularity, flexibility andscalability, offers a solution for large-scale applications allowing them toadapt and meet the demand on an ever increasing user base. Despite itsadvantages, migrating from a monolithic to a microservices architecture isoften costly and complex, with the decomposition step being a significantchallenge. This research addresses this issue by introducing MonoEmbed, aLanguage Model based approach for automating the decomposition process.MonoEmbed leverages state-of-the-art Large Language Models (LLMs) andrepresentation learning techniques to generate representation vectors formonolithic components, which are then clustered to form microservices. Byevaluating various pre-trained models and applying fine-tuning techniques suchas Contrastive Learning and Low Rank Adaptation (LoRA), MonoEmbed aims tooptimize these representations for microservice partitioning. The evaluation ofthe fine-tuned models showcases that they were able to significantly improvethe quality of the representation vectors when compared with pre-trained modelsand traditional representations. The proposed approach was benchmarked againstexisting decomposition methods, demonstrating superior performance ingenerating cohesive and balanced microservices for monolithic applications withvarying scales.</description>
      <author>example@mail.com (Khaled Sellami, Mohamed Aymen Saied)</author>
      <guid isPermaLink="false">2502.04604v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation</title>
      <link>http://arxiv.org/abs/2502.04774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的框架Self-Direct Instruction generation (SeDi-Instruct)，用于以低成本生成高质量的指令数据，该框架通过多样性过滤和迭代反馈任务生成来提高基础模型适应目标领域的表现。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型(LLMs)的发展促使了AI服务的多样化。为了提供给客户高品质的服务，在将基础模型调整到特定领域时，需要进行指令微调(instruction tuning)，然而获取高质量的数据是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个低成本生成高质量指令数据的方法，以提高基础模型在目标领域的适应性和服务质量。&lt;h4&gt;方法&lt;/h4&gt;提出了SeDi-Instruct框架，该框架包含多样性过滤(diversity-based filtering)和迭代反馈任务生成(iterative feedback task generation)，前者通过增强批次中指令的多样性来减少合成成本而不牺牲准确性；后者则结合指令生成与训练任务，并利用训练期间获得的信息创建高质量指令集。&lt;h4&gt;主要发现&lt;/h4&gt;SeDi-Instruct框架相比传统方法，能够提升AI模型准确率5.2%，同时降低36%的数据生成成本。&lt;h4&gt;结论&lt;/h4&gt;SeDi-Instruct通过有效提高数据质量和减少不必要的API调用，为解决指令微调中的数据稀缺问题提供了新的思路和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型(LLMs)的快速发展使行业能够开发各种基于AI的服务。为了适应特定领域并提供高质量服务给客户，需要对基础模型进行指令微调(instruction tuning)，而获取高质数据是一大挑战。Self-Instruct通过使用ChatGPT API自动产生指令数据来缓解此问题，尽管它在经济上不高效（因大量无用的API调用）。为了以低成本生成高质量的数据，我们提出了一个新框架SeDi-Instruct，该框架采用多样性过滤和迭代反馈任务生成技术。实验结果显示，相比传统方法，SeDi-Instruct能提升5.2%的模型准确率，并减少36%的成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of Large Language Models (LLMs) has enabled the industryto develop various AI-based services. Instruction tuning is consideredessential in adapting foundation models for target domains to providehigh-quality services to customers. A key challenge in instruction tuning isobtaining high-quality instruction data. Self-Instruct, which automaticallygenerates instruction data using ChatGPT APIs, alleviates the data scarcityproblem. To improve the quality of instruction data, Self-Instruct discardsmany of the instructions generated from ChatGPT, even though it is inefficientin terms of cost owing to many useless API calls. To generate high-qualityinstruction data at a low cost, we propose a novel data generation framework,Self-Direct Instruction generation (SeDi-Instruct), which employsdiversity-based filtering and iterative feedback task generation.Diversity-based filtering maintains model accuracy without excessivelydiscarding low-quality generated instructions by enhancing the diversity ofinstructions in a batch. This reduces the cost of synthesizing instructiondata. The iterative feedback task generation integrates instruction generationand training tasks and utilizes information obtained during the training tocreate high-quality instruction sets. Our results show that SeDi-Instructenhances the accuracy of AI models by 5.2%, compared with traditional methods,while reducing data generation costs by 36%.</description>
      <author>example@mail.com (Jungwoo Kim, Minsang Kim, Sungjin Lee)</author>
      <guid isPermaLink="false">2502.04774v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Graph Federated Learning Based Proactive Content Caching in Edge Computing</title>
      <link>http://arxiv.org/abs/2502.04760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于图联邦学习的前瞻性内容缓存方案（GFPCC），旨在提高缓存效率同时保护用户隐私。&lt;h4&gt;背景&lt;/h4&gt;随着移动数据流量的快速增长和视频流媒体使用的增加，边缘计算中的前瞻性内容缓存在减少延迟和缓解网络拥堵方面变得至关重要。然而，传统的缓存策略如FIFO、LRU和LFU无法有效预测未来的内容流行度，而现有的前瞻性缓存方法通常需要用户将数据上传到中央服务器，这引发了隐私和可扩展性方面的担忧。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战，本文提出了一种基于图联邦学习的前瞻性内容缓存（GFPCC）方案，旨在提高缓存效率同时保护用户隐私。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了联邦学习和图神经网络，使用户能够本地训练轻量级图卷积网络（LightGCN），以捕获用户-项目关系并预测内容流行度。中央服务器仅接收经过训练的模型参数，并通过联邦平均算法聚合更新、优化全局模型并选择热门文件进行前瞻性缓存。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据集上的实验验证表明，GFPCC通过更准确的内容流行度预测实现了比基线缓存算法更高的缓存效率。此外，联邦学习框架加强了隐私保护的同时保持高效的模型训练；然而，在大规模网络中存在动态用户偏好时的可扩展性仍然是一个挑战。&lt;h4&gt;结论&lt;/h4&gt;GFPCC是一种有效的前瞻性内容缓存策略，能够在不损害用户隐私的情况下提高缓存性能，并具有在现实场景中的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid growth of mobile data traffic and the increasing prevalence ofvideo streaming, proactive content caching in edge computing has become crucialfor reducing latency and alleviating network congestion. However, traditionalcaching strategies such as FIFO, LRU, and LFU fail to effectively predictfuture content popularity, while existing proactive caching approaches oftenrequire users to upload data to a central server, raising concerns regardingprivacy and scalability. To address these challenges, this paper proposes aGraph Federated Learning-based Proactive Content Caching (GFPCC) scheme thatenhances caching efficiency while preserving user privacy. The proposedapproach integrates federated learning and graph neural networks, enablingusers to locally train Light Graph Convolutional Networks (LightGCN) to captureuser-item relationships and predict content popularity. Instead of sharing rawdata, only the trained model parameters are transmitted to the central server,where a federated averaging algorithm aggregates updates, refines the globalmodel, and selects the most popular files for proactive caching. Experimentalevaluations on real-world datasets, such as MovieLens, demonstrate that GFPCCoutperforms baseline caching algorithms by achieving higher cache efficiencythrough more accurate content popularity predictions. Moreover, the federatedlearning framework strengthens privacy protection while maintaining efficientmodel training; however, scalability remains a challenge in large-scalenetworks with dynamic user preferences.</description>
      <author>example@mail.com (Rui Wang)</author>
      <guid isPermaLink="false">2502.04760v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces</title>
      <link>http://arxiv.org/abs/2502.04548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种结构化梯度精炼框架，通过引入多层次上下文调整来优化大规模神经架构的训练方法。该框架利用动态加权策略改进参数适应性，并减少梯度振荡以实现更稳定的训练过程。&lt;h4&gt;背景&lt;/h4&gt;当前用于训练大型神经网络的方法通常依赖于均匀传播机制，这在处理层次化语言结构时效果不佳，从而限制了它们在多样化的语言分布中泛化的能力。&lt;h4&gt;目的&lt;/h4&gt;通过引入多层次上下文调整来改进参数适应性，并实现更稳定的梯度传播过程以增强优化效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于动态权重策略的多尺度语境调整框架，该框架能够更好地对齐参数更新和广泛的语言依赖关系而不是孤立令牌级别的关联。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，结构化传播机制可以减少梯度振荡并提高训练稳定性及优化效率。实验结果表明，采用层次化传播策略的模型在长时间依赖性保持和跨域适应方面表现得更为稳健。&lt;h4&gt;结论&lt;/h4&gt;通过引入层次化的权重更新调整提供了传统反向传播的一个替代方案，减少了对初始化条件的敏感性同时提高了总体收敛效率。该研究验证了结构化梯度传播对于优化语言模型中复杂表示学习的重要性，为有效整合语言依赖性于优化动态提供了一种经实证支持的方法框架。&lt;h4&gt;翻译&lt;/h4&gt;优化大规模神经架构训练的方法通常依赖于均匀的梯度传播机制，这些方法在处理分层的语言结构时表现不佳，限制了它们在多样化的语言分布中泛化的能力。一种包含多尺度上下文调整的结构化梯度精炼框架被引入到改进参数适应性上，通过动态加权策略增强了表示的一致性。经验评估表明，结构化传播机制减少了梯度振荡，促进了更稳定的训练过程和优化效率的提高。性能对比分析显示，采用层次化传播策略的模型在保持长期依赖性和跨域迁移方面具有更好的鲁棒性。层次化的权重更新调整为传统反向传播提供了一种替代方案，降低了对初始化条件的敏感性，并提高了整体收敛效率。实验结果表明，结构化梯度传播影响了表示学习轨迹，使参数更新与广泛的语言关系而非孤立令牌级别的联系相一致。统计评价显示，分层优化策略减少了过拟合并保持在异构文本分布中的适应性。研究证明了结构化梯度传播为改进层次化表示学习提供了一个经实证验证的框架，并支持更有效地整合语言依赖性到优化动态中去。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimization methodologies for training large-scale neural architecturesoften rely on uniform gradient propagation mechanisms that fail to align withhierarchical linguistic structures, limiting their capacity to generalizeacross diverse language distributions. A structured gradient refinementframework was introduced to incorporate multi-scale contextual adjustments,improving parameter adaptation through dynamic weighting strategies thatenhanced representation coherence. Empirical evaluations demonstrated thatstructured propagation mechanisms contributed to reductions in gradientoscillations, resulting in more stable training dynamics and improvedoptimization efficiency. The comparative performance assessment indicated thatmodels incorporating hierarchical propagation strategies exhibited greaterrobustness in long-range dependency retention and cross-domain adaptation. Thehierarchical adjustment of weight updates provided an alternative toconventional backpropagation, reducing sensitivity to initialization conditionswhile improving overall convergence efficiency. The experimental resultsconfirmed that structured gradient propagation influenced representationlearning trajectories, aligning parameter updates with broader linguisticdependencies rather than isolated token-level relationships. Statisticalevaluations indicated that structured optimization strategies mitigatedoverfitting while preserving adaptability across heterogeneous textdistributions. The findings established that structured gradient propagationprovided an empirically validated framework for refining hierarchicalrepresentation learning, supporting more effective integration of linguisticdependencies into optimization dynamics.</description>
      <author>example@mail.com (Daphne Quillington, Kingsley Fairbrother, Xavier Tattershall, Irin Kabakum)</author>
      <guid isPermaLink="false">2502.04548v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective</title>
      <link>http://arxiv.org/abs/2502.04591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文探讨了图神经网络（GNN）中的过度平滑问题，并提出了新的度量方法来评估这一现象。&lt;h4&gt;背景&lt;/h4&gt;在构建更深的图神经网络模型时，过度平滑会导致节点嵌入变得过于相似，从而导致性能急剧下降。传统的过度平滑度量标准主要通过邻居节点特征的相似性进行衡量，例如Dirichlet能量。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的方法来更可靠地量化和捕捉图神经网络中的过度平滑现象。&lt;h4&gt;方法&lt;/h4&gt;作者建议使用数值秩或有效秩来测量过平滑现象。并通过理论证明了非线性激活函数在假设权重训练为非负的情况下，特征表示的数值秩会收敛至1。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果显示基于秩的度量指标可以一致地捕捉过度平滑问题，而能量相关的指标常常失效。值得注意的是，在一些情况下，能量度量标准保持不变时，基于秩的度量显示出显著下降的趋势，并且与性能下降密切相关。&lt;h4&gt;结论&lt;/h4&gt;提出了一种更可靠、有效的评估图神经网络中过度平滑现象的方法，为深入研究和优化模型提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Oversmoothing是图神经网络（GNN）中的一个基本挑战：随着层数的增加，节点嵌入变得越来越相似，并且模型性能急剧下降。传统上，过度平滑是通过衡量邻居节点特征相似性的度量标准来量化，例如Dirichlet能量。然而，作者认为这些指标在实际场景中存在关键限制并且无法可靠地捕捉到过度平滑现象。为了提供一个替代方案，本文提出了通过检查特征表示的数值秩或有效秩来进行测量的方法，并提供了理论支持，证明了非负训练权重假设下对于广义的非线性激活函数，特征表示的数值秩会收敛至1。这是首次在不假设权重矩阵有界性的条件下证明过度平滑现象的结果。除了理论发现外，本文还进行了广泛的数值评估以验证不同图结构下的模型性能变化，并证实了基于秩的度量指标始终能够有效捕捉到过度平滑问题而能量相关的指标常常失效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Oversmoothing is a fundamental challenge in graph neural networks (GNNs): asthe number of layers increases, node embeddings become increasingly similar,and model performance drops sharply. Traditionally, oversmoothing has beenquantified using metrics that measure the similarity of neighbouring nodefeatures, such as the Dirichlet energy. While these metrics are related tooversmoothing, we argue they have critical limitations and fail to reliablycapture oversmoothing in realistic scenarios. For instance, they providemeaningful insights only for very deep networks and under somewhat strictconditions on the norm of network weights and feature representations. As analternative, we propose measuring oversmoothing by examining the numerical oreffective rank of the feature representations. We provide theoretical supportfor this approach, demonstrating that the numerical rank of featurerepresentations converges to one for a broad family of nonlinear activationfunctions under the assumption of nonnegative trained weights. To the best ofour knowledge, this is the first result that proves the occurrence ofoversmoothing without assumptions on the boundedness of the weight matrices.Along with the theoretical findings, we provide extensive numerical evaluationacross diverse graph architectures. Our results show that rank-based metricsconsistently capture oversmoothing, whereas energy-based metrics often fail.Notably, we reveal that a significant drop in the rank aligns closely withperformance degradation, even in scenarios where energy metrics remainunchanged.</description>
      <author>example@mail.com (Piero Deidda, Kaicheng Zhang, Desmond Higham, Francesco Tudisco)</author>
      <guid isPermaLink="false">2502.04591v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Safety is Essential for Responsible Open-Ended Systems</title>
      <link>http://arxiv.org/abs/2502.04512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了开放性AI的发展趋势及其面临的潜在风险，并提出了相应的缓解策略。&lt;h4&gt;背景&lt;/h4&gt;人工智能的进步得益于基础模型和好奇心驱动学习的结合，而其中一个重要领域是开放性（Open-Endedness），它使AI系统能够持续自主地生成新颖且多样的解决方案或产品。&lt;h4&gt;目的&lt;/h4&gt;论文旨在分析开放性AI带来的挑战，并提出相应策略以促进其安全、负责任的发展。&lt;h4&gt;方法&lt;/h4&gt;通过系统化研究，探讨了维持开放性AI系统的对齐（alignment）、可预测性和可控性的挑战及其缓解措施。&lt;h4&gt;主要发现&lt;/h4&gt;开放式AI的固有动态性和自我传播性质带来了尚未被充分探索的风险。&lt;h4&gt;结论&lt;/h4&gt;呼吁各方采取行动，以支持开放性AI的安全、负责任和成功的开发。&lt;h4&gt;翻译&lt;/h4&gt;人工智能的进步显著地由基础模型和好奇心驱动学习相结合所推动，旨在提高能力和适应性。这一领域中一个日益增长的兴趣点是开放性——即AI系统能够持续并自主生成新颖且多样化的艺术品或解决方案的能力。这对加速科学发现以及使AI代理实现持续的适应变得尤为重要。本文认为，开放式AI固有的动态性和自我传播性质引入了重大、尚未充分探讨的风险，包括在保持对齐（alignment）、可预测性以及控制方面的挑战。论文系统地分析了这些挑战，提出了缓解策略，并呼吁不同利益相关者采取行动以支持开放性AI的安全、负责任和成功开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI advancements have been significantly driven by a combination of foundationmodels and curiosity-driven learning aimed at increasing capability andadaptability. A growing area of interest within this field is Open-Endedness -the ability of AI systems to continuously and autonomously generate novel anddiverse artifacts or solutions. This has become relevant for acceleratingscientific discovery and enabling continual adaptation in AI agents. Thisposition paper argues that the inherently dynamic and self-propagating natureof Open-Ended AI introduces significant, underexplored risks, includingchallenges in maintaining alignment, predictability, and control. This papersystematically examines these challenges, proposes mitigation strategies, andcalls for action for different stakeholders to support the safe, responsibleand successful development of Open-Ended AI.</description>
      <author>example@mail.com (Ivaxi Sheth, Jan Wehner, Sahar Abdelnabi, Ruta Binkyte, Mario Fritz)</author>
      <guid isPermaLink="false">2502.04512v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Learning Semantics-aware Search Operators for Genetic Programming</title>
      <link>http://arxiv.org/abs/2502.04568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to GECCO 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种语义感知搜索算子，该算子在程序合成中引导搜索向具有潜在高价值的候选程序发展。&lt;h4&gt;背景&lt;/h4&gt;测试基础程序合成中的适应度景观极为崎岖，即使是微小的程序修改也可能导致行为的根本变化和适应值的变化。基于适应度的传统迭代搜索算法（如遗传编程）在这种情况下显得过于限制性。&lt;h4&gt;目的&lt;/h4&gt;引入一种语义感知的搜索算子以克服传统方法的局限性，并提高潜在高质量解的发现效率。&lt;h4&gt;方法&lt;/h4&gt;提出的方法利用图神经网络学习程序指令和处理数据之间的交互，生成表示可能搜索决策的重要性的图节点上的重要性映射（salience map）。&lt;h4&gt;主要发现&lt;/h4&gt;在符号回归基准测试上，所提方法优于传统的树基遗传编程及简化版的方法。&lt;h4&gt;结论&lt;/h4&gt;语义感知的搜索算子能有效地增强程序合成中的探索能力，并促进高适应度解决方案的生成。&lt;h4&gt;翻译&lt;/h4&gt;健身景观（即适应性地形）在基于测试的程序综合中被认为是极其崎岖不平的。即使是对程序进行轻微修改，也可能导致其行为的根本变化和适应值的变化。仅依赖于适应度作为迭代搜索算法如遗传编程中的唯一指导是不必要的限制，尤其是在结合完全忽视对程序影响的纯语法搜索算子时更是如此。在此研究中，我们提出了一种语义感知的搜索算子，它引导搜索向那些不仅在实际（高适应性）上而且在潜在上有价值的候选程序发展，即使当前这些程序的适应值较低，它们也有很大可能被转化为高质量的解决方案。该方法的核心是图神经网络，它可以学习程序指令和处理数据之间的相互作用，并生成表示可能搜索决策的重要性的图节点上的重要性映射（salience map）。当应用于一组符号回归基准测试时，所提出的方法优于传统的基于树的遗传编程以及简化版的方法版本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fitness landscapes in test-based program synthesis are known to be extremelyrugged, with even minimal modifications of programs often leading tofundamental changes in their behavior and, consequently, fitness values.Relying on fitness as the only guidance in iterative search algorithms likegenetic programming is thus unnecessarily limiting, especially when combinedwith purely syntactic search operators that are agnostic about their impact onprogram behavior. In this study, we propose a semantics-aware search operatorthat steers the search towards candidate programs that are valuable not onlyactually (high fitness) but also only potentially, i.e. are likely to be turnedinto high-quality solutions even if their current fitness is low. The keycomponent of the method is a graph neural network that learns to model theinteractions between program instructions and processed data, and produces asaliency map over graph nodes that represents possible search decisions. Whenapplied to a suite of symbolic regression benchmarks, the proposed methodoutperforms conventional tree-based genetic programming and the ablated variantof the method.</description>
      <author>example@mail.com (Piotr Wyrwiński, Krzysztof Krawiec)</author>
      <guid isPermaLink="false">2502.04568v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>TexLiDAR: Automated Text Understanding for Panoramic LiDAR Data</title>
      <link>http://arxiv.org/abs/2502.04385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用Ouster OS1传感器生成的2D图像而非3D点云，将LiDAR数据与文本连接的新方法。研究使用Florence 2大型模型在零样本设置下进行图像描述和目标检测，并展示了该方法比现有技术（如CLIP）更优的表现。&lt;h4&gt;背景&lt;/h4&gt;现有的将LiDAR数据与文本关联的方法主要集中在将3D点云嵌入到CLIP的图文空间中，但这种方法依赖于3D点云，这在编码效率和神经网络处理方面面临挑战。随着高级LiDAR传感器（如Ouster OS1）的发展，这些传感器不仅产生3D点云，还生成固定分辨率的深度、信号以及环境全景2D图像。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用先进LiDAR传感器数据的新方法来连接LiDAR数据与文本，并通过实验展示这种方法在零样本设置下的性能优于现有技术如CLIP。&lt;h4&gt;方法&lt;/h4&gt;使用Ouster OS1生成的2D图像和Florence 2大型预训练模型进行图像描述和目标检测，利用固定的全景2D图像作为输入，以克服3D点云数据带来的挑战，并探索LiDAR传感器的新机会。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在零样本设置下使用Florence 2模型可以生成更详细的描述并获得比现有方法如CLIP更高的目标检测性能。这种方法为包括实时应用在内的具有高准确性和鲁棒性的检测场景提供了可靠的解决方案。&lt;h4&gt;结论&lt;/h4&gt;通过结合高级LiDAR传感器数据和大型预训练模型，本文提出的方法提供了一种稳健且精确的解决复杂检测问题的新途径，并展示了在图像描述和对象检测任务中的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efforts to connect LiDAR data with text, such as LidarCLIP, have primarilyfocused on embedding 3D point clouds into CLIP text-image space. However, theseapproaches rely on 3D point clouds, which present challenges in encodingefficiency and neural network processing. With the advent of advanced LiDARsensors like Ouster OS1, which, in addition to 3D point clouds, produce fixedresolution depth, signal, and ambient panoramic 2D images, new opportunitiesemerge for LiDAR based tasks. In this work, we propose an alternative approachto connect LiDAR data with text by leveraging 2D imagery generated by the OS1sensor instead of 3D point clouds. Using the Florence 2 large model in azero-shot setting, we perform image captioning and object detection. Ourexperiments demonstrate that Florence 2 generates more informative captions andachieves superior performance in object detection tasks compared to existingmethods like CLIP. By combining advanced LiDAR sensor data with a largepre-trained model, our approach provides a robust and accurate solution forchallenging detection scenarios, including real-time applications requiringhigh accuracy and robustness.</description>
      <author>example@mail.com (Naor Cohen, Roy Orfaig, Ben-Zion Bobrovsky)</author>
      <guid isPermaLink="false">2502.04385v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration</title>
      <link>http://arxiv.org/abs/2502.03238v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted in Computers in Biology and Medicine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的长尾医学诊断框架（LMD），该框架旨在解决医疗图像分类中的样本不平衡问题，通过增强表示学习和迭代分类器校准来平衡不同类别的表现。&lt;h4&gt;背景&lt;/h4&gt;计算机辅助诊断在减轻临床医生的工作负担方面显示出有前景的性能。然而，由于不同类型疾病之间样本数量的巨大差异，导致算法偏向于大多数类别，从而对稀有类别造成不良影响。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的长尾医学诊断框架（LMD），以解决医疗图像分类中因样本不平衡而导致的表示学习偏差和分类器校准不足的问题。&lt;h4&gt;方法&lt;/h4&gt;{'Relation-aware Representation Learning (RRL) 方案': '通过不同的数据增强来提高表示能力，鼓励编码器捕捉内在语义特征。', 'Iterative Classifier Calibration (ICC) 方案': '生成大量平衡虚拟特征，并采用期望最大化方式微调编码器以迭代校准分类器。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该LMD框架在三个公共长尾医学数据集上的表现明显优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的LMD框架能够有效缓解医疗图像中长尾问题导致的表示学习和分类偏差，有助于提高对稀有类别的诊断性能。&lt;h4&gt;翻译&lt;/h4&gt;最近计算机辅助诊断显示出令人鼓舞的表现，有效地减轻了临床医生的工作负担。然而，不同疾病之间的样本不平衡导致算法偏向于多数类别，从而导致罕见类别的表现不佳。现有工作将这一挑战视为一个长尾问题，并试图通过解耦特征表示和分类来解决它。但由于尾部类别的分布不均衡和样本有限，这些工作容易出现偏置的表示学习以及不足的分类器校准。为了解决这些问题，我们提出了一种新的长尾医学诊断（LMD）框架，用于在长尾数据集上进行平衡医疗图像分类。初始阶段，我们开发了一个关系感知表示学习（RRL）方案，通过不同的数据增强来提高表示能力，鼓励编码器捕捉内在语义特征。随后，在此基础上提出了一个迭代分类器校准（ICC）方案，以迭代方式校准分类器。这通过生成大量平衡虚拟特征并使用期望最大化方式微调编码器实现。所提出的ICC方案能够补偿少数类别的不足，使无偏的分类器优化成为可能，同时保持多数类别的诊断知识。在三个公共长尾医学数据集上的全面实验表明，我们的LMD框架显著优于现有方法。&lt;h4&gt;其他&lt;/h4&gt;{'源代码链接': 'https://github.com/peterlipan/LMD'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently computer-aided diagnosis has demonstrated promising performance,effectively alleviating the workload of clinicians. However, the inherentsample imbalance among different diseases leads algorithms biased to themajority categories, leading to poor performance for rare categories. Existingworks formulated this challenge as a long-tailed problem and attempted totackle it by decoupling the feature representation and classification. Yet, dueto the imbalanced distribution and limited samples from tail classes, theseworks are prone to biased representation learning and insufficient classifiercalibration. To tackle these problems, we propose a new Long-tailed MedicalDiagnosis (LMD) framework for balanced medical image classification onlong-tailed datasets. In the initial stage, we develop a Relation-awareRepresentation Learning (RRL) scheme to boost the representation ability byencouraging the encoder to capture intrinsic semantic features throughdifferent data augmentations. In the subsequent stage, we propose an IterativeClassifier Calibration (ICC) scheme to calibrate the classifier iteratively.This is achieved by generating a large number of balanced virtual features andfine-tuning the encoder using an Expectation-Maximization manner. The proposedICC compensates for minority categories to facilitate unbiased classifieroptimization while maintaining the diagnostic knowledge in majority classes.Comprehensive experiments on three public long-tailed medical datasetsdemonstrate that our LMD framework significantly surpasses state-of-the-artapproaches. The source code can be accessed athttps://github.com/peterlipan/LMD.</description>
      <author>example@mail.com (Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen)</author>
      <guid isPermaLink="false">2502.03238v2</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Interpolation: Extrapolative Reasoning with Reinforcement Learning and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.04402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally to this work. Accepted as  workshop paper at NEURMAD@AAAI25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;尽管取得了巨大的进步，许多神经架构在训练分布之外的泛化方面仍然存在不足。因此，在机器学习中正确且可泛化的推理是当前的一个基本挑战。&lt;h4&gt;背景&lt;/h4&gt;逻辑谜题提供了一个很好的测试环境，因为我们可以完全理解并控制学习环境。这使得评价模型在未见过的更大更难的问题上的表现成为可能，这些问题遵循相同的底层规则。&lt;h4&gt;目的&lt;/h4&gt;探索如何利用图论方法建模这些逻辑谜题，并研究使所提出的模型能够在强化学习设置中学习泛化解决方案的关键因素。&lt;h4&gt;方法&lt;/h4&gt;本研究关注架构的归纳偏差、不同的奖励系统以及递归建模在支持顺序推理中的作用。通过广泛实验展示这些元素对复杂问题成功外推的影响。&lt;h4&gt;主要发现&lt;/h4&gt;论文揭示了设计能够超越内插进行泛化的学习系统的系统性途径，包括架构的归纳偏差、奖励机制和模型的序贯处理能力等因素的作用。&lt;h4&gt;结论&lt;/h4&gt;研究为机器学习领域如何构建具备泛化推理能力的学习系统提供了见解与框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite incredible progress, many neural architectures fail to properlygeneralize beyond their training distribution. As such, learning to reason in acorrect and generalizable way is one of the current fundamental challenges inmachine learning. In this respect, logic puzzles provide a great testbed, as wecan fully understand and control the learning environment. Thus, they allow toevaluate performance on previously unseen, larger and more difficult puzzlesthat follow the same underlying rules. Since traditional approaches oftenstruggle to represent such scalable logical structures, we propose to modelthese puzzles using a graph-based approach. Then, we investigate the keyfactors enabling the proposed models to learn generalizable solutions in areinforcement learning setting. Our study focuses on the impact of theinductive bias of the architecture, different reward systems and the role ofrecurrent modeling in enabling sequential reasoning. Through extensiveexperiments, we demonstrate how these elements contribute to successfulextrapolation on increasingly complex puzzles.These insights and frameworksoffer a systematic way to design learning-based systems capable ofgeneralizable reasoning beyond interpolation.</description>
      <author>example@mail.com (Niccolò Grillo, Andrea Toccaceli, Joël Mathys, Benjamin Estermann, Stefania Fresca, Roger Wattenhofer)</author>
      <guid isPermaLink="false">2502.04402v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models</title>
      <link>http://arxiv.org/abs/2502.03950v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种评估视觉语言基础模型在低分辨率图像分类性能的新基准LR0.FM，提出了加权聚合鲁棒性这一新指标，并通过实验揭示了模型大小、预训练数据集质量对模型鲁棒性的影响以及细粒度细节的重要性。&lt;h4&gt;背景&lt;/h4&gt;现有视觉语言基础模型的零样本泛化能力强，但在处理低分辨率图像时的表现并不充分研究。现实场景中经常遇到低分辨率或像素化的图像。&lt;h4&gt;目的&lt;/h4&gt;评估10个不同基础模型在66种架构和15个数据集上对低分辨率图像分类性能的影响，并提出改进策略以增强模型鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;设计了LR0.FM基准测试，引入加权聚合鲁棒性这一新指标来量化模型的鲁棒性和跨分辨率及数据集上的表现。同时提出了简单策略LR-TK0来提高模型在低分辨率图像下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;{'(i)': '模型大小与对分辨率下降的鲁棒性正相关，预训练数据集的质量比其规模更重要，微调和高分辨率模型对于处理低分辨率图像不如未经调整的基础模型效果好。', '(ii)': '分析表明，在面对低分辨率输入时，模型在语义层面上仍能做出合理的预测，但缺乏细粒度细节会严重影响早期网络层次。', '(iii)': '提出的简单策略LR-TK0能够在不改变预训练权重的情况下显著增强模型的鲁棒性。'}&lt;h4&gt;结论&lt;/h4&gt;通过综合基准测试和新指标的应用，研究不仅揭示了视觉语言基础模型处理低分辨率图像的关键因素，还提供了一种有效的方法来提高其在该领域的表现。&lt;h4&gt;翻译&lt;/h4&gt;Visual-language foundation Models (FMs) exhibit remarkable zero-shot generalization across diverse tasks, largely attributed to extensive pre-training on large-scale datasets. However, their robustness on low-resolution/pixelated (LR) images remains underexplored.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shyammarjit/LR0.FM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual-language foundation Models (FMs) exhibit remarkable zero-shotgeneralization across diverse tasks, largely attributed to extensivepre-training on largescale datasets. However, their robustness onlow-resolution/pixelated (LR) images, a common challenge in real-worldscenarios, remains underexplored. We introduce LR0.FM, a comprehensivebenchmark evaluating the impact of low resolution on the zero-shotclassification performance of 10 FM(s) across 66 backbones and 15 datasets. Wepropose a novel metric, Weighted Aggregated Robustness, to address thelimitations of existing metrics and better evaluate model performance acrossresolutions and datasets. Our key findings show that: (i) model size positivelycorrelates with robustness to resolution degradation, (ii) pre-training datasetquality is more important than its size, and (iii) fine-tuned and higherresolution models are less robust against LR. Our analysis further reveals thatthe model makes semantically reasonable predictions at LR, and the lack offine-grained details in input adversely impacts the model's initial layers morethan the deeper layers. We use these insights and introduce a simple strategy,LR-TK0, to enhance the robustness of models without compromising theirpre-trained weights. We demonstrate the effectiveness of LR-TK0 for robustnessagainst low-resolution across several datasets and its generalizationcapability across backbones and other approaches. Code is available athttps://github.com/shyammarjit/LR0.FM</description>
      <author>example@mail.com (Priyank Pathak, Shyam Marjit, Shruti Vyas, Yogesh S Rawat)</author>
      <guid isPermaLink="false">2502.03950v2</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning</title>
      <link>http://arxiv.org/abs/2502.04399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了边缘辅助车辆在智能城市背景下的应用场景，特别是在处理订单配送与基础模型微调的联合任务中发挥的作用。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能（AI）的进步和基础模型的发展，智慧城市正在改变人们的日常生活。其中，车载群体感知技术利用汽车移动性和传感器能力成为了关键技术之一，而网约车则是收集灵活数据、贡献于城市智慧的重要途径。&lt;h4&gt;目的&lt;/h4&gt;研究边缘辅助车辆如何同时执行订单配送和服务新出现的基础模型微调任务，并解决这些不同时间空间特性的任务整合挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多智能体强化学习（MARL）的在线框架，设计了新的服务质量指标以平衡两个联合任务中的实用性。将图神经网络与MARL集成，增强状态表示，捕捉车辆之间及地点之间的图形结构化、时间变化依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的基于多智能体强化学习的方法具有优势，在纽约市出租车订单数据集和各种真实世界的基础模型微调任务中得到了验证。&lt;h4&gt;结论&lt;/h4&gt;通过边缘辅助车辆来执行联合任务是一种有前途的解决方案，可以有效促进智慧城市的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in artificial intelligence (AI) including foundation models (FMs),are increasingly transforming human society, with smart city driving theevolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged asa key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.In particular, ride-hailing vehicles can effectively facilitate flexible datacollection and contribute towards urban intelligence, despite resourcelimitations. Therefore, this work explores a promising scenario, whereedge-assisted vehicles perform joint tasks of order serving and the emergingfoundation model fine-tuning using various urban data. However, integrating theVCS AI task with the conventional order serving task is challenging, due totheir inconsistent spatio-temporal characteristics: (i) The distributions ofride orders and data point-of-interests (PoIs) may not coincide in geography,both following a priori unknown patterns; (ii) they have distinct forms oftemporal effects, i.e., prolonged waiting makes orders become instantly invalidwhile data with increased staleness gradually reduces its utility for modelfine-tuning.To overcome these obstacles, we propose an online framework basedon multi-agent reinforcement learning (MARL) with careful augmentation. A newquality-of-service (QoS) metric is designed to characterize and balance theutility of the two joint tasks, under the effects of varying data volumes andstaleness. We also integrate graph neural networks (GNNs) with MARL to enhancestate representations, capturing graph-structured, time-varying dependenciesamong vehicles and across locations. Extensive experiments on our testbedsimulator, utilizing various real-world foundation model fine-tuning tasks andthe New York City Taxi ride order dataset, demonstrate the advantage of ourproposed method.</description>
      <author>example@mail.com (Bokeng Zheng, Bo Rao, Tianxiang Zhu, Chee Wei Tan, Jingpu Duan, Zhi Zhou, Xu Chen, Xiaoxi Zhang)</author>
      <guid isPermaLink="false">2502.04399v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>SLCGC: A lightweight Self-supervised Low-pass Contrastive Graph Clustering Network for Hyperspectral Images</title>
      <link>http://arxiv.org/abs/2502.03497v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一个用于自监督的高效低通对比图聚类（SLCGC）算法，针对高光谱图像中的未标记数据和空间-光谱相互作用复杂性问题。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏标注的数据以及固有的空间-光谱交互复杂度，自我监督的高光谱影像分类任务仍然是一大挑战。尽管最近的研究已经探索了创新的方法，但现有的方法在聚类精度、特征区分能力、计算效率和抗噪性方面仍面临重大限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督高效低通对比图聚类（SLCGC）算法以解决高光谱图像分类中的问题，同时提高其鲁棒性和实用性。&lt;h4&gt;方法&lt;/h4&gt;1. 生成同质区域：通过聚合像素到一致的光谱区域内来保持局部空间-光谱一致性，并大大减少图复杂性。 2. 使用邻接矩阵构建结构化图并引入低通图去噪机制以抑制图拓扑中的高频噪声，确保稳定特征传播。3. 开发了一个双分支对比学习模块：通过两个多层感知器（MLP）生成增强视角，并通过跨视图对比损失执行视图之间的结构性一致性的强制措施。学习噪声不变的表示。&lt;h4&gt;主要发现&lt;/h4&gt;SLCGC具有较高的聚类精度，较低的计算复杂度和较强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的自监督高效低通对比图聚类方法在多个实验中展现了其有效性和优越性，并且该研究为高光谱图像分类提供了一种新的可行解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：自我监督的高光谱影像（HSI）聚类由于缺乏标记数据和固有的空间-光谱交互复杂度，仍然是一项基础但具有挑战性的任务。尽管最近的研究已经探索了创新的方法，现有的方法在聚类精度、特征区分能力、计算效率以及对噪声的鲁棒性方面仍面临重大限制，阻碍了它们的实际部署。本文介绍了一种针对HSIs的自监督高效低通对比图聚类（SLCGC）算法。我们的方法从同质区域生成开始，通过聚合像素到一致光谱区域内来保持局部空间-光谱一致性，并大大减少图复杂性。然后使用邻接矩阵构建结构化图，并引入低通图去噪机制以抑制图拓扑中的高频噪声，确保稳定特征传播。开发了一个双分支对比学习模块：通过两个多层感知器（MLP）生成增强视角，并通过跨视图对比损失执行视图之间的结构性一致性的强制措施，以学习噪声不变的表示。最后，通过K-means方法聚类该过程优化得到的潜在嵌入。大量的实验和重复比较分析已经验证了我们的SLCGC具有高聚类精度、低计算复杂度以及强鲁棒性。代码源将在https://github.com/DY-HYX提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised hyperspectral image (HSI) clustering remains a fundamentalyet challenging task due to the absence of labeled data and the inherentcomplexity of spatial-spectral interactions. While recent advancements haveexplored innovative approaches, existing methods face critical limitations inclustering accuracy, feature discriminability, computational efficiency, androbustness to noise, hindering their practical deployment. In this paper, aself-supervised efficient low-pass contrastive graph clustering (SLCGC) isintroduced for HSIs. Our approach begins with homogeneous region generation,which aggregates pixels into spectrally consistent regions to preserve localspatial-spectral coherence while drastically reducing graph complexity. We thenconstruct a structural graph using an adjacency matrix A and introduce alow-pass graph denoising mechanism to suppress high-frequency noise in thegraph topology, ensuring stable feature propagation. A dual-branch graphcontrastive learning module is developed, where Gaussian noise perturbationsgenerate augmented views through two multilayer perceptrons (MLPs), and across-view contrastive loss enforces structural consistency between views tolearn noise-invariant representations. Finally, latent embeddings optimized bythis process are clustered via K-means. Extensive experiments and repeatedcomparative analysis have verified that our SLCGC contains high clusteringaccuracy, low computational complexity, and strong robustness. The code sourcewill be available at https://github.com/DY-HYX.</description>
      <author>example@mail.com (Yao Ding, Zhili Zhang, Aitao Yang, Yaoming Cai, Xiongwu Xiao, Danfeng Hong, Junsong Yuan)</author>
      <guid isPermaLink="false">2502.03497v2</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Transforming Multimodal Models into Action Models for Radiotherapy</title>
      <link>http://arxiv.org/abs/2502.04408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;放射治疗是一种关键的癌症治疗方法，需要精确规划以平衡肿瘤消除和保护健康组织的需求。传统治疗计划（TP）是迭代的、耗时且依赖于人类专业知识，这可能会引入变异性和低效率。&lt;h4&gt;背景&lt;/h4&gt;传统的放疗计划制定过程依赖于专家经验和繁琐的人工步骤，缺乏一致性，并可能影响治疗效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖框架，利用少量样本强化学习方法将大型多模态预训练模型转化为用于放射治疗规划的动作模型。&lt;h4&gt;方法&lt;/h4&gt;该方法通过结合MLM的广泛先验知识以及使用蒙特卡洛模拟器进行迭代优化来增强基础模型。具体而言，它借助于物理、辐射和解剖学的知识库，并且在少量示例下迅速学习并改进放疗计划。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的基于RL的方法相比，在前列腺癌数据集的仿真中，该方法实现了更高的奖励分数以及更优剂量分布，从而证明了其优越性。&lt;h4&gt;结论&lt;/h4&gt;这项概念验证研究表明将高级AI模型集成到临床工作流程中的潜力，可以增强放疗计划的速度、质量和标准化。&lt;h4&gt;翻译&lt;/h4&gt;放射治疗是一种重要的癌症治疗方法，它需要精确的规划来平衡肿瘤消除与健康组织保护之间的关系。传统的方法是基于迭代过程且耗时长，并依赖于人类专家的知识，这可能引入变异性和效率低下。我们提出了一种新的框架，通过少量样本强化学习方法将大型多模态预训练模型转变为治疗计划动作模型。这种方法利用了MLM的广泛先验知识库，在物理、辐射和解剖学领域具有深度理解，并在模拟器的帮助下不断优化放疗方案。实验结果表明，在前列腺癌数据集上进行仿真时，本框架优于传统的基于RL的方法，提供了更高的奖励分数和更优剂量分布。这项研究为将高级AI模型整合进临床工作流程以提高治疗计划的速度、质量和标准化方面提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radiotherapy is a crucial cancer treatment that demands precise planning tobalance tumor eradication and preservation of healthy tissue. Traditionaltreatment planning (TP) is iterative, time-consuming, and reliant on humanexpertise, which can potentially introduce variability and inefficiency. Wepropose a novel framework to transform a large multimodal foundation model(MLM) into an action model for TP using a few-shot reinforcement learning (RL)approach. Our method leverages the MLM's extensive pre-existing knowledge ofphysics, radiation, and anatomy, enhancing it through a few-shot learningprocess. This allows the model to iteratively improve treatment plans using aMonte Carlo simulator. Our results demonstrate that this method outperformsconventional RL-based approaches in both quality and efficiency, achievinghigher reward scores and more optimal dose distributions in simulations onprostate cancer data. This proof-of-concept suggests a promising direction forintegrating advanced AI models into clinical workflows, potentially enhancingthe speed, quality, and standardization of radiotherapy treatment planning.</description>
      <author>example@mail.com (Matteo Ferrante, Alessandra Carosi, Rolando Maria D Angelillo, Nicola Toschi)</author>
      <guid isPermaLink="false">2502.04408v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Medical Code Tokenizer</title>
      <link>http://arxiv.org/abs/2502.04397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了MedTok，一种用于电子健康记录（EHR）的多模态医学代码分词器。它不仅考虑了文本描述，还利用了代码之间的关系和层级结构，并将这些信息整合进统一的令牌空间。&lt;h4&gt;背景&lt;/h4&gt;现有的EHR分词器仅将医疗编码视为孤立的文字标记，忽视了每个编码由其文本描述、在概念层次中的位置以及与其他编码的关系定义的事实。医学词汇包含超过60万个代码，这对于临床推理至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出MedTok以改进基于电子健康记录的模型对医学数据的理解和处理能力。&lt;h4&gt;方法&lt;/h4&gt;MedTok使用语言模型编码器处理文本，并通过图编码器捕捉关系结构；接着将其转换成统一令牌空间，保留了特定模态及跨模态的信息。在五个EHR模型中整合MedTok并进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;与标准的EHR分词器相比，用MedTok替换后，在所有测试任务和数据集上平均AUPRC提高了4.10%（MIMIC-III）到11.30%（EHRshot），特别是在药物推荐方面表现最佳。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明MedTok在医学代码的统一分词中具有潜力，能够改进医疗基础模型对文本和关系信息的理解能力。此外，在非EHR建模任务如医学问答系统应用上也展示了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要的内容已直接作为翻译部分给出，描述了论文提出的方法（MedTok）、目的、主要发现及结论&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models trained on patient electronic health records (EHRs) requiretokenizing medical data into sequences of discrete vocabulary items. Existingtokenizers treat medical codes from EHRs as isolated textual tokens. However,each medical code is defined by its textual description, its position inontological hierarchies, and its relationships to other codes, such as diseaseco-occurrences and drug-treatment associations. Medical vocabularies containmore than 600,000 codes with critical information for clinical reasoning. Weintroduce MedTok, a multimodal medical code tokenizer that uses the textdescriptions and relational context of codes. MedTok processes text using alanguage model encoder and encodes the relational structure with a graphencoder. It then quantizes both modalities into a unified token space,preserving modality-specific and cross-modality information. We integrateMedTok into five EHR models and evaluate it on operational and clinical tasksacross in-patient and out-patient datasets, including outcome prediction,diagnosis classification, drug recommendation, and risk stratification.Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHRmodels, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, withthe largest gains in drug recommendation. Beyond EHR modeling, we demonstrateusing MedTok tokenizer with medical QA systems. Our results demonstrate thepotential of MedTok as a unified tokenizer for medical codes, improvingtokenization for medical foundation models.</description>
      <author>example@mail.com (Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik)</author>
      <guid isPermaLink="false">2502.04397v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Token-level Explanations for Graph-based Rumour Detection</title>
      <link>http://arxiv.org/abs/2502.04366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CT-LRP框架，旨在提高基于图神经网络（GNN）的谣言检测系统的透明度和可解释性。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的广泛应用加速了信息传播，但也促进了有害谣言的扩散，这可能破坏经济、影响政治结果，并在公共卫生危机中加剧问题，例如新冠疫情。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的框架来增强基于GNN的谣言检测模型的透明度和可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入对比令牌逐层相关传播（CT-LRP），该方法提供更细致的令牌级解释，超越现有的图可解释技术。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个公开可用的谣言数据集上训练的不同GNN模型评估了CT-LRP的有效性，证明其能够产生高质量、有意义的解释。&lt;h4&gt;结论&lt;/h4&gt;CT-LRP为构建更加稳健和值得信赖的基于GNN的谣言检测系统奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;社交媒体的普及加速了信息传播的同时也促进了有害谣言的扩散。现有的图神经网络方法在自动谣言检测方面显示出显著潜力，但缺乏透明度，导致预测难以解释。本文提出了一种新的框架CT-LRP来增强基于GNN的谣言检测模型的可解释性，并展示了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of social media has accelerated the dissemination ofinformation, but it has also facilitated the spread of harmful rumours, whichcan disrupt economies, influence political outcomes, and exacerbate publichealth crises, such as the COVID-19 pandemic. While Graph Neural Network(GNN)-based approaches have shown significant promise in automated rumourdetection, they often lack transparency, making their predictions difficult tointerpret. Existing graph explainability techniques fall short in addressingthe unique challenges posed by the dependencies among feature dimensions inhigh-dimensional text embeddings used in GNN-based models. In this paper, weintroduce Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novelframework designed to enhance the explainability of GNN-based rumour detection.CT-LRP extends current graph explainability methods by providing token-levelexplanations that offer greater granularity and interpretability. We evaluatethe effectiveness of CT-LRP across multiple GNN models trained on threepublicly available rumour detection datasets, demonstrating that itconsistently produces high-fidelity, meaningful explanations, paving the wayfor more robust and trustworthy rumour detection systems.</description>
      <author>example@mail.com (Daniel Wai Kit Chin, Roy Ka-Wei Lee)</author>
      <guid isPermaLink="false">2502.04366v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings</title>
      <link>http://arxiv.org/abs/2502.04386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;自监督学习技术在医学成像领域取得了重大突破，通过从大规模未标记数据集中提取高效的通用特征，推动了该领域的进步。&lt;h4&gt;背景信息&lt;/h4&gt;最新的研究将自监督基础模型扩展到了三维（3D）CT数据中，生成具有1408个特征的紧凑型、富含信息量的嵌入，并在诸如颅内出血检测和肺癌风险预测等下游任务上达到了最先进的性能。然而，这些嵌入被发现编码了人口统计学信息如年龄、性别和种族，这给临床应用中的公平性带来了重大风险。&lt;h4&gt;研究目的&lt;/h4&gt;提出了一种基于变分自编码器（VAE）的对抗去偏框架，该方法能够将原始特征转换到一个新的潜在空间，在此空间中不再包含人口统计学信息，同时保持关键下游任务的表现。&lt;h4&gt;研究方法&lt;/h4&gt;验证了这种方法在NLST肺癌筛查数据集上的有效性，展示了其通过消除多个编码的人口统计数据提高了公平性，而不会损害一年和两年间隔的肺癌风险预测准确性，并确保嵌入对抗偏见攻击时具有鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;基于VAE的去偏框架能够有效去除特征中的种族、性别等人口统计学信息，同时保持临床任务中的预测性能不受影响；此外，该方法还能增强模型对对抗偏见攻击的防御能力。&lt;h4&gt;结论&lt;/h4&gt;研究表明，对抗去偏技术在确保自监督3D CT嵌入在临床应用中的公平性和公正性方面具有潜力，并为无偏差医疗决策制定的更广泛应用铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning has transformed medical imaging by enabling efficient and generalizable feature extraction from large-scale unlabeled datasets. The latest research extends self-supervised foundation models to three-dimensional (3D) CT data, generating compact, information-rich embeddings with 1408 features that achieve state-of-the-art performance on downstream tasks such as intracranial hemorrhage detection and lung cancer risk forecasting. However, these embeddings have been shown to encode demographic information like age, sex, and race, posing a significant risk to the fairness of clinical applications. In this study, we propose an adversarial debiasing framework based on Variational Autoencoder (VAE) that transforms original features into a new latent space where population statistics are no longer encoded while maintaining key downstream task performance. We validate our approach using the NLST lung cancer screening dataset and demonstrate its effectiveness in eliminating multiple encoded demographic information to improve fairness without compromising predictive accuracy for one-year and two-year intervals of lung cancer risk prediction, as well as enhancing robustness against adversarial bias attacks. The study highlights the potential of adversarial debiasing techniques to ensure fairness and equity in clinical applications of self-supervised 3D CT embeddings, paving the way for their broader adoption in unbiased medical decision-making.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has revolutionized medical imaging by enablingefficient and generalizable feature extraction from large-scale unlabeleddatasets. Recently, self-supervised foundation models have been extended tothree-dimensional (3D) computed tomography (CT) data, generating compact,information-rich embeddings with 1408 features that achieve state-of-the-artperformance on downstream tasks such as intracranial hemorrhage detection andlung cancer risk forecasting. However, these embeddings have been shown toencode demographic information, such as age, sex, and race, which poses asignificant risk to the fairness of clinical applications.  In this work, we propose a Variation Autoencoder (VAE) based adversarialdebiasing framework to transform these embeddings into a new latent space wheredemographic information is no longer encoded, while maintaining the performanceof critical downstream tasks. We validated our approach on the NLST lung cancerscreening dataset, demonstrating that the debiased embeddings effectivelyeliminate multiple encoded demographic information and improve fairness withoutcompromising predictive accuracy for lung cancer risk at 1-year and 2-yearintervals. Additionally, our approach ensures the embeddings are robust againstadversarial bias attacks. These results highlight the potential of adversarialdebiasing techniques to ensure fairness and equity in clinical applications ofself-supervised 3D CT embeddings, paving the way for their broader adoption inunbiased medical decision-making.</description>
      <author>example@mail.com (Guangyao Zheng, Michael A. Jacobs, Vladimir Braverman, Vishwa S. Parekh)</author>
      <guid isPermaLink="false">2502.04386v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Reasoning to Adapt Large Language Models for Domain-Specific Applications</title>
      <link>http://arxiv.org/abs/2502.04384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop AFM (Adaptive Foundation Models: Evolving AI  for Personalized and Efficient Learning)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SOLOMON是一种基于神经灵感的大型语言模型（LLM）推理网络架构，旨在增强基础模型在特定领域的适应性。通过半导体布局设计案例研究展示如何利用提示工程和上下文学习技术使通用目的的LLM迅速适应专业任务。&lt;h4&gt;背景&lt;/h4&gt;当前LLM面临空间推理以及将领域知识应用于实际问题中的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的神经灵感大型语言模型推理网络架构SOLOMON，旨在改善基础模型在特定领域的应用能力。&lt;h4&gt;方法&lt;/h4&gt;通过半导体布局设计案例研究来验证SOLOMON如何利用提示工程和上下文学习技术提高LLM的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基线LLM相比，SOLOMON实例表现出显著更好的性能，并且其性能可与最先进的推理模型o1-preview相媲美。&lt;h4&gt;结论&lt;/h4&gt;讨论了未来研究方向，以开发更具有适应性的AI系统，这些系统能够持续学习、适应和进化，以应对新信息和不断变化的需求。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了SOLOMON，这是一种新的基于神经灵感的大型语言模型（LLM）推理网络架构，旨在增强基础模型在特定领域的应用能力。通过一个半导体布局设计案例研究展示如何利用提示工程和上下文学习技术使通用目的的LLM迅速适应专业任务。实验结果揭示了LLM在空间推理以及将领域知识应用于实际问题中的挑战。结果显示SOLOMON实例显著优于其基线LLM，并达到与最先进的推理模型o1-preview相当的性能水平。论文还讨论了未来研究方向，即开发更具有适应性的AI系统，这些系统能够持续学习、适应和进化以应对新信息和不断变化的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents SOLOMON, a novel Neuro-inspired Large Language Model(LLM) Reasoning Network architecture that enhances the adaptability offoundation models for domain-specific applications. Through a case study insemiconductor layout design, we demonstrate how SOLOMON enables swiftadaptation of general-purpose LLMs to specialized tasks by leveraging PromptEngineering and In-Context Learning techniques. Our experiments reveal thechallenges LLMs face in spatial reasoning and applying domain knowledge topractical problems. Results show that SOLOMON instances significantlyoutperform their baseline LLM counterparts and achieve performance comparableto state-of-the-art reasoning model, o1-preview. We discuss future researchdirections for developing more adaptive AI systems that can continually learn,adapt, and evolve in response to new information and changing requirements.</description>
      <author>example@mail.com (Bo Wen, Xin Zhang)</author>
      <guid isPermaLink="false">2502.04384v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>TLXML: Task-Level Explanation of Meta-Learning via Influence Functions</title>
      <link>http://arxiv.org/abs/2501.14271v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages; v2: modification in metadata&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习通过适应解决数据不足或分布变化问题的方法被视为一种关键手段。&lt;h4&gt;目的&lt;/h4&gt;旨在提出解释性方法来应对因用户环境中的不合适更新而带来的新风险，同时考虑到元学习的双层训练结构。&lt;h4&gt;方法&lt;/h4&gt;提出了基于影响函数的方法，用来衡量任务和推理过程中的适应敏感度。此外，使用高斯-牛顿矩阵近似Hessian解决了计算障碍。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在区分不同任务和任务分布方面是有效的，尤其是在图像分类任务中通过MAML和原型网络进行了验证。&lt;h4&gt;结论&lt;/h4&gt;这项工作填补了元学习解释性研究领域的空白，并且提供了一种新的视角来理解模型的适应性和推理过程中的敏感度。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经用中文概述。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scheme of adaptation via meta-learning is seen as an ingredient forsolving the problem of data shortage or distribution shift in real-worldapplications, but it also brings the new risk of inappropriate updates of themodel in the user environment, which increases the demand for explainability.Among the various types of XAI methods, establishing a method of explanationbased on past experience in meta-learning requires special consideration due toits bi-level structure of training, which has been left unexplored. In thiswork, we propose influence functions for explaining meta-learning that measurethe sensitivities of training tasks to adaptation and inference. We also arguethat the approximation of the Hessian using the Gauss-Newton matrix resolvescomputational barriers peculiar to meta-learning. We demonstrate the adequacyof the method through experiments on task distinction and task distributiondistinction using image classification tasks with MAML and PrototypicalNetwork.</description>
      <author>example@mail.com (Yoshihiro Mitsuka, Shadan Golestan, Zahin Sufiyan, Sheila Schoepp, Shotaro Miwa, Osmar R. Zaiane)</author>
      <guid isPermaLink="false">2501.14271v2</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Building Rome with Convex Optimization</title>
      <link>http://arxiv.org/abs/2502.04640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了全局束调整简化方法，通过学习到的深度将二维关键点提升至三维，并使用凸半定规划（SDP）松弛实现全局最优解。使用Burer-Monteiro因子化和基于CUDA的信任域黎曼优化器解决了大规模问题。&lt;h4&gt;背景&lt;/h4&gt;现有的全局束调整技术在解决大规模问题时面临挑战，需要引入新的方法来简化并提高其效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全局束调整（SBA）公式，并设计相应的凸半定规划松弛算法，以实现高精度的三维重建。&lt;h4&gt;方法&lt;/h4&gt;(i) 提出了一种缩放全局束调整（Scaled Bundle Adjustment, SBA）形式化方法。(ii) 设计了经验上紧致的凸半定规划(SDP)松弛方案解决SBA问题，并保证全局最优性。(iii) 使用Burer-Monteiro因子化和基于CUDA的信任域黎曼优化器(XM)来大规模求解SDP松弛。(iv) 建立了一个使用XM作为优化引擎的结构从运动（Structure from Motion, SfM）流水线。&lt;h4&gt;主要发现&lt;/h4&gt;新方法可以实现高精度三维重建，同时在速度、可扩展性和初始化方面优于现有的SfM管道。&lt;h4&gt;结论&lt;/h4&gt;提出的缩放全局束调整（SBA）公式和SDP松弛方案显著提高了大规模问题的解决效率，并展示了使用XM优化器作为结构从运动(SfM)流水线核心引擎的优势。&lt;h4&gt;翻译&lt;/h4&gt;通过深度预测和凸优化简化了全局束调整。方法包括：(i) 提出了一种缩放全局束调整（Scaled Bundle Adjustment, SBA）形式化，利用学习到的深度将二维关键点测量提升至三维。(ii) 设计了一个经验上紧致的凸半定规划(SDP)松弛方案来解决SBA问题并保证全局最优性。(iii) 使用Burer-Monteiro因子化和基于CUDA的信任域黎曼优化器(XM)大规模求解SDP松弛。(iv) 构建了使用XM作为优化引擎的结构从运动（Structure from Motion, SfM）流水线，并显示XM-SfM在重建质量方面优于或与现有SfM管道相比具有竞争力，同时速度更快、更可扩展且无需初始化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global bundle adjustment is made easy by depth prediction and convexoptimization. We (i) propose a scaled bundle adjustment (SBA) formulation thatlifts 2D keypoint measurements to 3D with learned depth, (ii) design anempirically tight convex semidfinite program (SDP) relaxation that solves SBAto certfiable global optimality, (iii) solve the SDP relaxations at extremescale with Burer-Monteiro factorization and a CUDA-based trust-regionRiemannian optimizer (dubbed XM), (iv) build a structure from motion (SfM)pipeline with XM as the optimization engine and show that XM-SfM dominates orcompares favorably with existing SfM pipelines in terms of reconstructionquality while being faster, more scalable, and initialization-free.</description>
      <author>example@mail.com (Haoyu Han, Heng Yang)</author>
      <guid isPermaLink="false">2502.04640v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Use of Winsome Robots for Understanding Human Feedback (UWU)</title>
      <link>http://arxiv.org/abs/2502.05118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  placeholder&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了在强化学习场景中，机器人可爱外观对人类反馈的影响。&lt;h4&gt;背景&lt;/h4&gt;随着社会机器人的普及，许多机器人采用了可爱的美学设计以提高用户的舒适感和接受度。然而，这种审美选择如何影响人类在强化学习中的反馈尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;探究机器人外表的可爱程度是否加剧了用户积极偏见对机器人行为优化的影响。&lt;h4&gt;方法&lt;/h4&gt;通过让用户评价一个执行任务时轨迹的机器人的实验来研究这个问题，并分析机器人外观的可爱度对其收到的反馈类型的影响。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，随着感知到的可爱的程度的变化，正向与负面反馈的比例发生了变化。&lt;h4&gt;结论&lt;/h4&gt;基于此，研究人员尝试了一种随机版本的TAMER算法，该算法可以根据用户的积极反馈偏差进行自适应调整以减少这种影响。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As social robots become more common, many have adopted cute aesthetics aimingto enhance user comfort and acceptance. However, the effect of this aestheticchoice on human feedback in reinforcement learning scenarios remains unclear.Previous research has shown that humans tend to give more positive thannegative feedback, which can cause failure to reach optimal robot behavior. Wehypothesize that this positive bias may be exacerbated by the robot's level ofperceived cuteness. To investigate, we conducted a user study whereparticipants critique a robot's trajectories while it performs a task. We thenanalyzed the impact of the robot's aesthetic cuteness on the type ofparticipant feedback. Our results suggest that there is a shift in the ratio ofpositive to negative feedback when perceived cuteness changes. In light ofthis, we experiment with a stochastic version of TAMER which adapts based onthe user's level of positive feedback bias to mitigate these effects.</description>
      <author>example@mail.com (Jessica Eggers, Angela Dai, Matthew C. Gombolay)</author>
      <guid isPermaLink="false">2502.05118v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Data-driven Modality Fusion: An AI-enabled Framework for Large-Scale Sensor Network Management</title>
      <link>http://arxiv.org/abs/2502.04937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的传感范式——数据驱动模态融合（DMF），旨在提高智能城市物联网网络管理的效率。&lt;h4&gt;背景&lt;/h4&gt;智慧城市的发展和运行严重依赖大规模的物联网（IoT）网络和传感器基础设施，这些网络不断监测城市的各个方面并产生大量数据。&lt;h4&gt;目的&lt;/h4&gt;减少物理传感器的数量，以降低能耗、通信带宽占用及整体部署成本，并确保资源受限的设备不承受密集处理任务。&lt;h4&gt;方法&lt;/h4&gt;利用不同传感模态之间的时序数据分析相关性，通过减少所需监控的物理传感器数量来提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;在马德里的一个真实世界IoT部署中验证了DMF的有效性，证明从较少的传感器集中准确估计交通、环境和污染指标是可能的。&lt;h4&gt;结论&lt;/h4&gt;提出的解决方案提供了一种可扩展且高效的机制用于管理城市物联网网络，并解决了有关传感器故障和隐私的问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的描述内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development and operation of smart cities relyheavily on large-scaleInternet-of-Things (IoT) networks and sensor infrastructures that continuouslymonitor various aspects of urban environments. These networks generate vastamounts of data, posing challenges related to bandwidth usage, energyconsumption, and system scalability. This paper introduces a novel sensingparadigm called Data-driven Modality Fusion (DMF), designed to enhance theefficiency of smart city IoT network management. By leveraging correlationsbetween timeseries data from different sensing modalities, the proposed DMFapproach reduces the number of physical sensors required for monitoring,thereby minimizing energy expenditure, communication bandwidth, and overalldeployment costs. The framework relocates computational complexity from theedge devices to the core, ensuring that resource-constrained IoT devices arenot burdened with intensive processing tasks. DMF is validated using data froma real-world IoT deployment in Madrid, demonstrating the effectiveness of theproposed system in accurately estimating traffic, environmental, and pollutionmetrics from a reduced set of sensors. The proposed solution offers a scalable,efficient mechanism for managing urban IoT networks, while addressing issues ofsensor failure and privacy concerns.</description>
      <author>example@mail.com (Hrishikesh Dutta, Roberto Minerva, Maira Alvi, Noel Crespi)</author>
      <guid isPermaLink="false">2502.04937v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>REASSEMBLE: A Multimodal Dataset for Contact-rich Robotic Assembly and Disassembly</title>
      <link>http://arxiv.org/abs/2502.05086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 12 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的数据集REASSEMBLE（Robotic assEmbly disASSEMBLy datasEt），用于解决复杂的机器人操作任务，特别是装配和拆卸。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集虽然在对象重新排列等简单的操作任务上取得了显著进展，但在捕捉复杂物理动态方面仍存在不足。&lt;h4&gt;目的&lt;/h4&gt;通过提供一个专门针对接触密集型操纵任务的新数据集来填补现有研究的空白。&lt;h4&gt;方法&lt;/h4&gt;基于NIST装配任务板1基准建立，包含四类基本动作（拾取、插入、移除和放置），涉及17个物体。总共有4,551次演示，其中4,035次成功，总计耗时781分钟。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集包括多种传感器的数据类型，如事件相机、力矩传感器、麦克风以及多视角RGB相机，为研究任务条件识别、动作分割等领域提供了支持。&lt;h4&gt;结论&lt;/h4&gt;REASSEMBLE将作为推进复杂现实场景中机器人操作的重要资源。&lt;h4&gt;翻译&lt;/h4&gt;机器人操纵仍然是机器人领域的一个核心挑战，尤其是在接触密集型任务（如工业装配和拆卸）方面。现有的数据集虽然在对象重新排列等简单的操作任务上取得了显著进展，但在捕捉复杂物理动态方面仍存在不足。为了解决这一问题，我们提出了REASSEMBLE，一个专门针对接触密集型操纵任务的数据集。该数据集基于NIST装配任务板1基准建立，并包含了四种基本动作（拾取、插入、移除和放置），涉及17个物体。总共有4,551次演示，其中4,035次成功，总计耗时781分钟。我们的数据集包括多种传感器的数据类型，如事件相机、力矩传感器、麦克风以及多视角RGB相机，支持研究学习接触密集型操纵、任务条件识别、动作分割等领域的工作。我们认为REASSEMBLE将作为推进复杂现实场景中机器人操作的重要资源。该数据集可以在我们的项目网站上公开获取：https://dsliwowski1.github.io/REASSEMBLE_page.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation remains a core challenge in robotics, particularly forcontact-rich tasks such as industrial assembly and disassembly. Existingdatasets have significantly advanced learning in manipulation but are primarilyfocused on simpler tasks like object rearrangement, falling short of capturingthe complexity and physical dynamics involved in assembly and disassembly. Tobridge this gap, we present REASSEMBLE (Robotic assEmbly disASSEMBLy datasEt),a new dataset designed specifically for contact-rich manipulation tasks. Builtaround the NIST Assembly Task Board 1 benchmark, REASSEMBLE includes fouractions (pick, insert, remove, and place) involving 17 objects. The datasetcontains 4,551 demonstrations, of which 4,035 were successful, spanning a totalof 781 minutes. Our dataset features multi-modal sensor data including eventcameras, force-torque sensors, microphones, and multi-view RGB cameras. Thisdiverse dataset supports research in areas such as learning contact-richmanipulation, task condition identification, action segmentation, and more. Webelieve REASSEMBLE will be a valuable resource for advancing roboticmanipulation in complex, real-world scenarios. The dataset is publiclyavailable on our project website:https://dsliwowski1.github.io/REASSEMBLE_page.</description>
      <author>example@mail.com (Daniel Sliwowski, Shail Jadav, Sergej Stanovcic, Jedrzej Orbik, Johannes Heidersberger, Dongheui Lee)</author>
      <guid isPermaLink="false">2502.05086v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Generalizability of Geomagnetic Navigation: A Deep Reinforcement Learning approach with Policy Distillation</title>
      <link>http://arxiv.org/abs/2502.05069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探索了通过深度强化学习（DRL）来提高自动车辆的磁导航策略在不同环境下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶技术的发展，自主车辆可以在未知环境中进行导航和探索。磁导航因其不需要GPS或惯性导航设备而越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用深度强化学习使已学得的磁导航策略具备跨区域的通用性，以提高其在新环境中的性能。&lt;h4&gt;方法&lt;/h4&gt;设计了一个奖励塑造机制来训练教师模型，并整合这些教师模型，通过多老师策略蒸馏法来获得具有广泛适应性的导航策略。该研究使用了基于潜在值和内在动机的混合奖励系统。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，利用深度强化学习模型可以有效地将源域学到的知识转移到新的导航区域中，相比现有基于进化的方法，在导航长度、持续时间、航向偏差和成功率方面表现更优。&lt;h4&gt;结论&lt;/h4&gt;通过深度强化学习实现的磁导航策略具有跨领域的泛化能力，并在多个性能指标上优于传统的基于进化的几何导航方法。&lt;h4&gt;翻译&lt;/h4&gt;随着自动驾驶车辆的进步，自主导航和探索未知环境的能力得到了提升。鉴于其独立于GPS或惯性导航设备的特点，磁导航技术吸引了越来越多的关注。尽管已经对各种磁导航方法进行了深入的研究，但学习到的策略是否具备跨域应用能力依然是未解之谜。由于缺乏新进入区域的地磁场特征知识，源领域中获取的学习策略在新的环境中的性能可能会下降。本研究通过深度强化学习探索了学习磁导航策略的泛化性问题，提出了一种基于奖励塑形机制和多教师模型合并的方法以提高策略的通用性和效率。实验结果表明该方法能够有效提升自主车辆跨领域的磁导航能力，并且在导航效果方面优于现有的进化型算法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement in autonomous vehicles has empowered navigation andexploration in unknown environments. Geomagnetic navigation for autonomousvehicles has drawn increasing attention with its independence from GPS orinertial navigation devices. While geomagnetic navigation approaches have beenextensively investigated, the generalizability of learned geomagneticnavigation strategies remains unexplored. The performance of a learned strategycan degrade outside of its source domain where the strategy is learned, due toa lack of knowledge about the geomagnetic characteristics in newly enteredareas. This paper explores the generalization of learned geomagnetic navigationstrategies via deep reinforcement learning (DRL). Particularly, we employ DRLagents to learn multiple teacher models from distributed domains that representdispersed navigation strategies, and amalgamate the teacher models forgeneralizability across navigation areas. We design a reward shaping mechanismin training teacher models where we integrate both potential-based andintrinsic-motivated rewards. The designed reward shaping can enhance theexploration efficiency of the DRL agent and improve the representation of theteacher models. Upon the gained teacher models, we employ multi-teacher policydistillation to merge the policies learned by individual teachers, leading to anavigation strategy with generalizability across navigation domains. We conductnumerical simulations, and the results demonstrate an effective transfer of thelearned DRL model from a source domain to new navigation areas. Compared toexisting evolutionary-based geomagnetic navigation methods, our approachprovides superior performance in terms of navigation length, duration, headingdeviation, and success rate in cross-domain navigation.</description>
      <author>example@mail.com (Wenqi Bai, Shiliang Zhang, Xiaohui Zhang, Xuehui Ma, Songnan Yang, Yushuai Li, Tingwen Huang)</author>
      <guid isPermaLink="false">2502.05069v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Gaze-Guided Robotic Vascular Ultrasound Leveraging Human Intention Estimation</title>
      <link>http://arxiv.org/abs/2502.05053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于注视的机器人超声系统（RUSS）用于血管应用，该系统利用眼动追踪信号引导机器人在血管分叉时跟随正确的路径，并通过开发稳定模块处理不准确的注视数据。&lt;h4&gt;背景&lt;/h4&gt;传统超声检查面临操作者之间和内部差异的问题，导致稳定性与再现性不足。而人体复杂的解剖结构使得多条血管同时出现在图像中或者单个血管分裂成分支。&lt;h4&gt;目的&lt;/h4&gt;为解决上述挑战，开发了一套基于眼动追踪的RUSS系统及其辅助的眼动引导分割网络。&lt;h4&gt;方法&lt;/h4&gt;利用眼动跟踪器捕获操作者的视线运动，并通过稳定模块处理原始注视数据。然后使用推断出的关注热图作为区域提议来帮助血管图像分割，并在需要调整扫描目标时（如遇到分叉）提供触发信号。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，提出的基于注视引导的分割流程比其他方法更有效，在模拟人体手臂模型上的测试中验证了整个基于注视引导的RUSS系统的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的眼动指导的RUSS系统和分割网络能够提高血管图像的稳定性和再现性，为临床应用提供了一种新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;医学超声波在现代临床实践中广泛用于检查血管结构。然而，传统的超声检查经常面临操作者之间和内部差异的问题，影响了其稳定性与再现性。鉴于人体复杂的解剖学特性，多个血管往往出现在同一图像中或者单个血管分裂成分支，这增加了诊断过程的复杂度。本文提出了一种基于注视引导的RUSS系统来解决这一挑战。该系统通过捕捉操作者的视线运动，并利用眼动追踪信号在血管分叉时指导机器人跟随正确的路径。此外，还开发了基于注视的信息增强分割网络以提高分割准确性。然而，眼动数据往往带有噪音，需要进一步处理才能准确识别操作者的真实意图。为此，设计了一种稳定模块来处理原始的眼动信息。推断出的注意力热图被用作区域提议以帮助血管图像分割，并在遇到分叉时作为触发信号提醒操作者调整扫描目标。为了保证探头与皮肤表面之间的适当接触，在检查过程中还开发了基于超声波信心值自动导向校正方法。实验结果表明，提出的注视引导的分割流程比其他方法更有效。此外，整个基于注视指导的RUSS系统在模拟人体手臂模型上的测试中也得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical ultrasound has been widely used to examine vascular structure inmodern clinical practice. However, traditional ultrasound examination oftenfaces challenges related to inter- and intra-operator variation. The roboticultrasound system (RUSS) appears as a potential solution for such challengesbecause of its superiority in stability and reproducibility. Given the complexanatomy of human vasculature, multiple vessels often appear in ultrasoundimages, or a single vessel bifurcates into branches, complicating theexamination process. To tackle this challenge, this work presents a gaze-guidedRUSS for vascular applications. A gaze tracker captures the eye movements ofthe operator. The extracted gaze signal guides the RUSS to follow the correctvessel when it bifurcates. Additionally, a gaze-guided segmentation network isproposed to enhance segmentation robustness by exploiting gaze information.However, gaze signals are often noisy, requiring interpretation to accuratelydiscern the operator's true intentions. To this end, this study proposes astabilization module to process raw gaze data. The inferred attention heatmapis utilized as a region proposal to aid segmentation and serve as a triggersignal when the operator needs to adjust the scanning target, such as when abifurcation appears. To ensure appropriate contact between the probe andsurface during scanning, an automatic ultrasound confidence-based orientationcorrection method is developed. In experiments, we demonstrated the efficiencyof the proposed gaze-guided segmentation pipeline by comparing it with othermethods. Besides, the performance of the proposed gaze-guided RUSS was alsovalidated as a whole on a realistic arm phantom with an uneven surface.</description>
      <author>example@mail.com (Yuan Bi, Yang Su, Nassir Navab, Zhongliang Jiang)</author>
      <guid isPermaLink="false">2502.05053v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>FlightForge: Advancing UAV Research with Procedural Generation of High-Fidelity Simulation and Integrated Autonomy</title>
      <link>http://arxiv.org/abs/2502.05038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures, Accepted to 2025 IEEE International Conference on  Robotics &amp; Automation (ICRA 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种新的开放源代码无人机模拟器FlightForge，该模拟器具备高级渲染能力、多样化的控制方式和程序化生成环境的能力，并且已经集成了能够进行远程飞行的完全自主无人机系统。&lt;h4&gt;背景&lt;/h4&gt;现有的无人机模拟器在复杂的自主导航任务中缺乏高阶自主性。这些现有模拟器难以整合现实物理效果、光栅真实感渲染以及多种传感器模式，导致它们主要用于低级任务如控制和碰撞避免。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的无人机开放源代码模拟器FlightForge，以解决当前模拟器在高级自主性和环境多样性上的不足。&lt;h4&gt;方法&lt;/h4&gt;FlightForge提供了先进的渲染能力和多样化的控制方式，并且能够程序化生成环境。此外，该模拟器已经集成了一套可以在杂乱未知环境中进行远程飞行的完全自主无人机系统。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，FlightForge在传感器渲染能力上优于现有的模拟器，并且能够在近乎无限大的环境中实现自主导航。&lt;h4&gt;结论&lt;/h4&gt;通过引入程序化环境生成和无缝集成了高阶自主性的功能，FlightForge为无人机系统的复杂任务提供了更好的模拟测试平台。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic simulators play a crucial role in the development and testing ofautonomous systems, particularly in the realm of Uncrewed Aerial Vehicles(UAV). However, existing simulators often lack high-level autonomy, hinderingtheir immediate applicability to complex tasks such as autonomous navigation inunknown environments. This limitation stems from the challenge of integratingrealistic physics, photorealistic rendering, and diverse sensor modalities intoa single simulation environment. At the same time, the existing photorealisticUAV simulators use mostly hand-crafted environments with limited environmentsizes, which prevents the testing of long-range missions. This restricts theusage of existing simulators to only low-level tasks such as control andcollision avoidance. To this end, we propose the novel FlightForge UAVopen-source simulator. FlightForge offers advanced rendering capabilities,diverse control modalities, and, foremost, procedural generation ofenvironments. Moreover, the simulator is already integrated with a fullyautonomous UAV system capable of long-range flights in cluttered unknownenvironments. The key innovation lies in novel procedural environmentgeneration and seamless integration of high-level autonomy into the simulationenvironment. Experimental results demonstrate superior sensor renderingcapability compared to existing simulators, and also the ability of autonomousnavigation in almost infinite environments.</description>
      <author>example@mail.com (David Čapek, Jan Hrnčíř, Tomáš Báča, Jakub Jirkal, Vojtěch Vonásek, Robert Pěnička, Martin Saska)</author>
      <guid isPermaLink="false">2502.05038v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Seasonal Station-Keeping of Short Duration High Altitude Balloons using Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.05014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高空气球（HAB）在特定区域进行位置保持是一项具有挑战性的路径规划问题，因为这涉及到部分可观测、复杂且动态变化的风流。&lt;h4&gt;目的&lt;/h4&gt;研究使用深度强化学习算法来解决短时间内的高空气球位置保持问题，并评估其有效性。&lt;h4&gt;方法&lt;/h4&gt;{'开发定制模拟环境': '为了训练和评估短期HAB代理（Deep Q-Learning），创建了一个自定义模拟环境，用于在该环境中培训代理。', '生成合成风预报': '使用聚合的历史气象气球数据生成合成风预测，以应用于仿真代理的水平动力学。', '引入Forecast Score算法': '为了突出不同月份中风场差异明显的情况，开发了一种基于风多样性独立分类预测的方法——Forecast Score算法。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'训练和评估结果': '深度Q学习（DQN）HAB代理在不同的季节月份进行了训练并得到了评估。', '预报与趋势': '通过Forecast Score算法，在所有季节中都分析了位置保持成功与风预测评分之间的关系。'}&lt;h4&gt;结论&lt;/h4&gt;合成的风预测数据与ECWMF ERA5再分析预报紧密相关，提供了一个现实化的模拟风场，并在风模型之间呈现出显著的季节和高度差异。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的大意是关于如何使用深度强化学习方法来解决短期高空气球的位置保持问题。通过创建一个定制的模拟环境以及生成基于历史数据合成风预报的方法来进行代理训练，然后利用Forecast Score算法来分析不同月份中位置保持的成功率与预测评分之间的关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Station-Keeping short-duration high-altitude balloons (HABs) in a region ofinterest is a challenging path-planning problem due to partially observable,complex, and dynamic wind flows. Deep reinforcement learning is a popularstrategy for solving the station-keeping problem. A custom simulationenvironment was developed to train and evaluate Deep Q-Learning (DQN) forshort-duration HAB agents in the simulation. To train the agents on realisticwinds, synthetic wind forecasts were generated from aggregated historicalradiosonde data to apply horizontal kinematics to simulated agents. Thesynthetic forecasts were closely correlated with ECWMF ERA5 Reanalysisforecasts, providing a realistic simulated wind field and seasonal andaltitudinal variances between the wind models. DQN HAB agents were then trainedand evaluated across different seasonal months. To highlight differences andtrends in months with vastly different wind fields, a Forecast Score algorithmwas introduced to independently classify forecasts based on wind diversity, andtrends between station-keeping success and the Forecast Score were evaluatedacross all seasons.</description>
      <author>example@mail.com (Tristan K. Schuler, Chinthan Prasad, Georgiy Kiselev, Donald Sofge)</author>
      <guid isPermaLink="false">2502.05014v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>A Transformation-based Consistent Estimation Framework: Analysis, Design and Applications</title>
      <link>http://arxiv.org/abs/2502.05008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了非线性系统中观测不匹配导致的一致性问题，特别是在多机器人协同定位和同时定位与地图构建中的情况。提出了两种新的扩展卡尔曼滤波器（EKF）估计器T-EKF 1 和 T-EKF 2，解决了状态独立不可观子空间的问题，并通过实验验证了其在多个代表性示例中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;非线性系统中由于观测不匹配导致的一致性问题普遍存在，尤其是在多机器人协同定位和同时定位与地图构建等场景下。这些问题可能导致估计的准确性下降以及计算效率降低。&lt;h4&gt;目的&lt;/h4&gt;研究并解决非线性系统中由观测不匹配引起的状态一致性问题，并提出一种新的方法来实现状态一致性和可观测性的匹配。&lt;h4&gt;方法&lt;/h4&gt;发现并证明了EKF估计器系统的不可观子空间独立于状态，并属于原始系统的不可观子空间。基于此，建立了达到可观测性匹配的充要条件，并引入了一种线性时变变换以实现具备状态独立不可观子空间的新系统。提出了T-EKF 1 和 T-EKF 2两种等效的一致化转换基EKF估计器。&lt;h4&gt;主要发现&lt;/h4&gt;发现了非线性系统的可观测性匹配的充要条件，并证明了通过适当的线性时变变换可以实现具有状态独立不可观子空间的新系统，从而解决了观测不匹配问题。提出了T-EKF 1 和 T-EKF 2两种等效的一致化转换基EKF估计器。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在多个代表性示例中表现出卓越的性能，在精度、一致性、计算效率和实际应用方面达到了最先进的水平。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们研究了由于可观察性不匹配引起的非线性系统中的不一致问题，特别是在多机器人合作定位和同时定位与构建地图时出现的问题。对于一般的非线性系统，我们发现并理论证明了EKF估计器系统的不可观测子空间独立于状态，并属于原始系统的不可观测子空间。基于此，我们建立了实现可观测性匹配的充分必要条件。这些理论成果促使我们引入了一种线性时变变换以获得具有与状态无关的不可观测子空间的新系统。我们证明了这种变换的存在，并提出了两种设计方法来构建它们。此外，我们还提出并建议了两个等效的一致转换基础EKF估计器，分别称为T-EKF 1和T-EKF 2。T-EKF 1利用转化后的系统进行一致估计，而T-EKF 2则使用原始系统但通过来自变换的状态和协方差修正来保证一致性。为了验证我们提出的方法的有效性，在包括多机器人合作定位、多源目标跟踪以及3D视觉惯性里程计在内的多个代表性实例中进行了实验测试，结果表明我们的方法在精度、一致性、计算效率及实用实现等方面达到了最前沿的水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate the inconsistency problem arising fromobservability mismatch that frequently occurs in nonlinear systems such asmulti-robot cooperative localization and simultaneous localization and mapping.For a general nonlinear system, we discover and theoretically prove that theunobservable subspace of the EKF estimator system is independent of the stateand belongs to the unobservable subspace of the original system. On this basis,we establish the necessary and sufficient conditions for achievingobservability matching. These theoretical findings motivate us to introduce alinear time-varying transformation to achieve a transformed system possessing astate-independent unobservable subspace. We prove the existence of suchtransformations and propose two design methodologies for constructing them.Moreover, we propose two equivalent consistent transformation-based EKFestimators, referred to as T-EKF 1 and T-EKF 2, respectively. T-EKF 1 employsthe transformed system for consistent estimation, whereas T-EKF 2 leverages theoriginal system but ensures consistency through state and covariancecorrections from transformations. To validate our proposed methods, we conductexperiments on several representative examples, including multi-robotcooperative localization, multi-source target tracking, and 3D visual-inertialodometry, demonstrating that our approach achieves state-of-the-art performancein terms of accuracy, consistency, computational efficiency, and practicalrealizations.</description>
      <author>example@mail.com (Ning Hao, Chungeng Tian, Fenghua He)</author>
      <guid isPermaLink="false">2502.05008v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Convergent NMPC-based Reinforcement Learning Using Deep Expected Sarsa and Nonlinear Temporal Difference Learning</title>
      <link>http://arxiv.org/abs/2502.04925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于强化学习（RL）的方法，用于优化非线性模型预测控制器（NMPC）的权重，并通过深度Expected Sarsa进行控制。&lt;h4&gt;背景&lt;/h4&gt;现有的方法在使用神经网络近似后续的动作价值函数时存在不足。作者提出的改进方案旨在解决这些问题并提高性能稳定性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的学习方法，以优化非线性模型预测控制器的权重并改善闭环系统的性能。&lt;h4&gt;方法&lt;/h4&gt;采用深度Expected Sarsa结合增强学习技术来更新NMPC的参数，并使用神经网络近似动作价值函数。同时引入了梯度时间差分法和参数化NMPC作为功能逼近器，以解决潜在的参数发散和不稳定问题。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够使闭环性能在实时计算负担几乎减半的同时保持不变；模拟结果表明提出的方案能收敛到局部最优解且无稳定性问题。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法可以有效改进NMPC的学习过程，并保证系统的稳定性和高性能。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们介绍了一种基于强化学习（RL）方法的非线性模型预测控制器（NMPC），该方法用于学习最优权重。控制器用作深度Expected Sarsa中的当前动作价值函数，而后续的动作价值函数通常通过二次NMPC获得，并由神经网络（NN）近似。与现有方法相比，我们向NN输入了NMPC中所学参数的当前值，使网络能够逼近动作价值函数并稳定学习性能。此外，在使用NN的情况下，实时计算负担大约减少了50%，而不会影响闭环性能。另外，我们结合梯度时间差分法和参数化NMPC作为Expected Sarsa RL方法的功能近似器，以克服在功能近似中存在非线性时可能出现的潜在参数发散和不稳定问题。模拟结果显示该提出的方法能够收敛到局部最优解而不会出现稳定性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a learning-based nonlinear model predictivecontroller (NMPC) using an original reinforcement learning (RL) method to learnthe optimal weights of the NMPC scheme. The controller is used as the currentaction-value function of a deep Expected Sarsa where the subsequentaction-value function, usually obtained with a secondary NMPC, is approximatedwith a neural network (NN). With respect to existing methods, we add to theNN's input the current value of the NMPC's learned parameters so that thenetwork is able to approximate the action-value function and stabilize thelearning performance. Additionally, with the use of the NN, the real-timecomputational burden is approximately halved without affecting the closed-loopperformance. Furthermore, we combine gradient temporal difference methods withparametrized NMPC as function approximator of the Expected Sarsa RL method toovercome the potential parameters divergence and instability issues whennonlinearities are present in the function approximation. The simulation resultshows that the proposed approach converges to a locally optimal solutionwithout instability problems.</description>
      <author>example@mail.com (Amine Salaje, Thomas Chevet, Nicolas Langlois)</author>
      <guid isPermaLink="false">2502.04925v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>The Role of Integrity Monitoring in Connected and Automated Vehicles: Current State-of-Practice and Future Directions</title>
      <link>http://arxiv.org/abs/2502.04874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了车载定位系统的最新进展及其在自动驾驶车辆（CAV）中的应用，特别是准确且可靠的位置信息的重要性。同时探讨了基于车对车（V2V）和车路协同技术的定位系统所带来的准确性提升以及传感器融合中完整性风险的问题。&lt;h4&gt;背景&lt;/h4&gt;由于感知、导航、通信和控制功能的进步，自动驾驶汽车的研究在过去十年里取得了进展。&lt;h4&gt;目的&lt;/h4&gt;回顾现有车辆位置完整性的监测研究，并识别其中的研究空白。特别关注强调合作性完整性监控方法的研究。&lt;h4&gt;方法&lt;/h4&gt;分析了在协同定位环境中多传感器融合的完整性风险，以及现有的关于定位系统完整性的监控研究。&lt;h4&gt;主要发现&lt;/h4&gt;目前对于如何处理和最小化在多传感器融合环境中的完整性风险还有许多未探索的空间。此外，在开发新的协作位置解决方案的整体监测框架方面也存在机会。&lt;h4&gt;结论&lt;/h4&gt;通过识别现有研究的空白，为未来合作定位解决方案中整体监控框架的发展铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;联网与自动车辆（CAV）的研究在过去的十年里由于感知、导航、通信和控制功能方面的显著进步而得到了广泛的关注。准确且可靠的位置信息对于满足CAV应用的需求至关重要，尤其是在涉及到安全性时。随着各种感知传感器（例如摄像头、激光雷达等）的出现，车载定位系统在精度和鲁棒性方面都有了提升。基于车辆到车辆（V2V）以及车辆到基础设施（V2I）的合作定位可以提高位置估计的准确性，但多传感器融合环境下涉及的整体风险尚未得到充分探讨。本文回顾了现有研究中关于定位完整性监测的研究，并指出了各种研究空白。特别关注强调合作性完整性监控方法的研究。这项分析有助于为未来合作定位解决方案中整体监控框架的发展铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Connected and Automated Vehicle (CAV) research has gained traction in thelast decade due to significant advancements in perception, navigation,communication, and control functions. Accurate and reliable positioninformation is needed to meet the requirements of CAV applications, especiallywhen safety is concerned. With the advent of various perception sensors (e.g.camera, LiDAR, etc.), the vehicular positioning system has improved both inaccuracy and robustness. Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure(V2I) based cooperative positioning can improve the accuracy of the positionestimates, but the integrity risks involved in multi-sensor fusion in acooperative environment have not yet been fully explored. This paper reviewsexisting research in the field of positioning Integrity Monitoring (IM) andidentifies various research gaps. Particular attention has been placed onidentifying research that highlights cooperative IM methods. This analysishelps pave the way for the development of new IM frameworks for cooperativepositioning solutions in the future.</description>
      <author>example@mail.com (Saswat Priyadarshi Nayak, Matthew Barth)</author>
      <guid isPermaLink="false">2502.04874v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Training-free Task-oriented Grasp Generation</title>
      <link>http://arxiv.org/abs/2502.04873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种无训练的流水线，用于任务导向抓取生成，该流水线结合了预训练的抓取生成模型和视觉-语言模型（VLMs）。与传统的仅关注稳定抓取的方法不同，我们的方法通过利用VLM的语义推理能力来整合特定于任务的需求。&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，传统的方法主要集中在寻找稳定的抓取方式上。然而，在许多现实场景中，需要考虑更复杂的因素如物体的具体用途和环境限制。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的、无训练的管道，以利用视觉-语言模型的能力来生成特定于任务需求的抓取方案。&lt;h4&gt;方法&lt;/h4&gt;结合预训练的抓取生成器与VLM，并测试了五种查询策略，每种策略使用候选抓握的不同视觉表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在成功率和任务遵循率方面，我们的方法比基线方法有了显著提高，整体成功率为36.9%。这些成就突显了VLM在改进面向任务的操作中的潜力。&lt;h4&gt;结论&lt;/h4&gt;研究证明了VLM在增强机器人抓取操作的效率与准确性上的巨大可能性，并为未来的研究提供有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a training-free pipeline for task-oriented graspgeneration that combines pre-trained grasp generation models withvision-language models (VLMs). Unlike traditional approaches that focus solelyon stable grasps, our method incorporates task-specific requirements byleveraging the semantic reasoning capabilities of VLMs. We evaluate fivequerying strategies, each utilizing different visual representations ofcandidate grasps, and demonstrate significant improvements over a baselinemethod in both grasp success and task compliance rates, with absolute gains ofup to 36.9% in overall success rate. Our results underline the potential ofVLMs to enhance task-oriented manipulation, providing insights for futureresearch in robotic grasping and human-robot interaction.</description>
      <author>example@mail.com (Jiaming Wang, Jizhuo Chen, Diwen Liu)</author>
      <guid isPermaLink="false">2502.04873v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>$TAR^2$: Temporal-Agent Reward Redistribution for Optimal Policy Preservation in Multi-Agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.04864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了Temporal-Agent Reward Redistribution ($TAR^2$)，一种解决合作多智能体强化学习中稀疏和延迟全局奖励挑战的新方法。&lt;h4&gt;背景&lt;/h4&gt;在合作多智能体强化学习（MARL）中，当全局奖励稀疏且延迟时，难以有效地学习策略。这个问题源于需要跨时间和跨代理分配信用的问题，而现有的方法往往无法解决这一问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来分解稀疏的全球奖励为特定于代理和时间步骤的部分，提供更频繁、更准确的学习反馈。&lt;h4&gt;方法&lt;/h4&gt;$TAR^2$通过将全局奖励分解成针对每个智能体的时间步长的具体部分，并且确保信用分配信号无偏。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，$TAR^2$与基于潜在的奖励塑造一致，保持了原始环境下的最优策略。实验证明，在两个具有挑战性的基准上，$TAR^2$显著地稳定并加速了收敛速度，并且在学习速率和最终性能方面超过了AREL和STAS等强大基线。&lt;h4&gt;结论&lt;/h4&gt;$TAR^2$为稀疏奖励多智能体系统中的代理-时间信用分配提供了一个原则性和实用性的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在合作式的多智能体强化学习（MARL）中，当全局奖励稀疏且延迟时，学习有效的策略是一项挑战。这个问题源于需要跨越时间和多个智能体进行信用分配的问题，而现有方法通常无法解决这种周期性、长时间范围内任务中的问题。我们提出了Temporal-Agent Reward Redistribution ($TAR^2$)，一种新的分解稀疏全局奖励的方法，将其转换为每个代理和时间步骤特有的组成部分，从而提供更频繁和准确的反馈以促进策略学习。理论上，我们展示了($TAR^2$)（i）与基于潜在值的奖励塑造一致，在保持原始环境下的最优策略的同时；(ii)确保在稀疏奖励下，政策梯度更新方向不变，使信用分配信号无偏。实证结果表明，$TAR^2$在两个具有挑战性的基准测试SMACLite和Google Research Football上显著稳定并加速了收敛性，并且在学习速度和最终性能方面超过了AREL和STAS等强基线模型。这些发现确立了$TAR^2$为稀疏奖励多智能体系统中代理-时间信用分配的一项原则性和实用性的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In cooperative multi-agent reinforcement learning (MARL), learning effectivepolicies is challenging when global rewards are sparse and delayed. Thisdifficulty arises from the need to assign credit across both agents and timesteps, a problem that existing methods often fail to address in episodic,long-horizon tasks. We propose Temporal-Agent Reward Redistribution $TAR^2$, anovel approach that decomposes sparse global rewards into agent-specific,time-step-specific components, thereby providing more frequent and accuratefeedback for policy learning. Theoretically, we show that $TAR^2$ (i) alignswith potential-based reward shaping, preserving the same optimal policies asthe original environment, and (ii) maintains policy gradient update directionsidentical to those under the original sparse reward, ensuring unbiased creditsignals. Empirical results on two challenging benchmarks, SMACLite and GoogleResearch Football, demonstrate that $TAR^2$ significantly stabilizes andaccelerates convergence, outperforming strong baselines like AREL and STAS inboth learning speed and final performance. These findings establish $TAR^2$ asa principled and practical solution for agent-temporal credit assignment insparse-reward multi-agent systems.</description>
      <author>example@mail.com (Aditya Kapoor, Kale-ab Tessera, Mayank Baranwal, Harshad Khadilkar, Stefano Albrecht, Mingfei Sun)</author>
      <guid isPermaLink="false">2502.04864v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Online Robot Motion Planning Methodology Guided by Group Social Proxemics Feature</title>
      <link>http://arxiv.org/abs/2502.04837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种机器人在社会环境中感知和导航的方法，通过建立个体及群体的亲缘性模型，并据此确定最佳观察位置，最终生成引导机器人穿梭于人群中的路径。&lt;h4&gt;背景&lt;/h4&gt;现有大多数机器人的运动规划方法无法满足展示类似人类感知、推理和社会行为的需求。这些算法通常将人视为障碍物处理，忽视了社会原则和意识。&lt;h4&gt;目的&lt;/h4&gt;研究如何在机器人导航中融入社会群体的亲缘性模型，以实现更自然的人机交互。&lt;h4&gt;方法&lt;/h4&gt;引入了一种考虑社交关联性和空间置信度的群体聚类方法，并提出了基于磁偶极子模型定义个体亲缘性的概念。进一步建立了群体亲缘性和场景地图，通过向量场叠加的方式完成这些任务。在这些基础上，确定了群体的最佳观察位置（OOP），并利用启发式路径生成引导机器人穿梭于人群中的路径。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在群体识别准确率和路径生成效率上均表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;基于群体意识的模块对于使机器人能够在实际场景中展示出更自然的社会行为至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays robot is supposed to demonstrate human-like perception, reasoningand behavior pattern in social or service application. However, most of theexisting motion planning methods are incompatible with above requirement. Apotential reason is that the existing navigation algorithms usually intend totreat people as another kind of obstacle, and hardly take the social principleor awareness into consideration. In this paper, we attempt to model theproxemics of group and blend it into the scenario perception and navigation ofrobot. For this purpose, a group clustering method considering both socialrelevance and spatial confidence is introduced. It can enable robot to identifyindividuals and divide them into groups. Next, we propose defining theindividual proxemics within magnetic dipole model, and further established thegroup proxemics and scenario map through vector-field superposition. On thebasis of the group clustering and proxemics modeling, we present the method toobtain the optimal observation positions (OOPs) of group. Once the OOPs gridand scenario map are established, a heuristic path is employed to generate paththat guide robot cruising among the groups for interactive purpose. A series ofexperiments are conducted to validate the proposed methodology on the practicalrobot, the results have demonstrated that our methodology has achievedpromising performance on group recognition accuracy and path-generationefficiency. This concludes that the group awareness evolved as an importantmodule to make robot socially behave in the practical scenario.</description>
      <author>example@mail.com (Xuan Mu, Xiaorui Liu, Shuai Guo, Wenzheng Chi, Wei Wang, Shuzhi Sam Ge)</author>
      <guid isPermaLink="false">2502.04837v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>An Extended Benchmarking of Multi-Agent Reinforcement Learning Algorithms in Complex Fully Cooperative Tasks</title>
      <link>http://arxiv.org/abs/2502.04773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了多智能体强化学习（MARL）领域中系统性评估的不足，并提出了一种改进的方法。&lt;h4&gt;背景&lt;/h4&gt;现有的MARL算法主要在团队游戏场景如SMAC和GRF等基准测试上进行评估，这些场景并不能全面反映实际合作任务的需求。此外，大多数研究集中在低维状态空间上的性能评估，对于高维度（例如图像）观测的适应性评估较少。&lt;h4&gt;目的&lt;/h4&gt;扩展系统化评估范围到更多现存基准，并深入比较已知MARL算法在复杂的合作环境下表现差异。&lt;h4&gt;方法&lt;/h4&gt;开发了一套PyMARLzoo+工具集用于测试和对比多种MARL算法，这套工具集基于现有的(E)PyMARL库并改进以支持PettingZoo的各类游戏场景以及Overcooked、PressurePlate等具体任务。&lt;h4&gt;主要发现&lt;/h4&gt;一些被认为在SMAC和GRF上表现优秀的算法可能在全面合作基准测试中不如标准的MARL基线算法。&lt;h4&gt;结论&lt;/h4&gt;为了更好地评估和促进未来研究，开放了PyMARLzoo+工具集作为社区资源。&lt;h4&gt;翻译&lt;/h4&gt;多智能体强化学习（MARL）近年来成为一个重要研究领域。然而，MARL算法评价缺乏系统多样性，阻碍了对其能力的全面理解。特别是在合作MARL中，主流评估集中在像SMAC和GRF这样的基准测试上，这些主要涉及团队游戏场景，并未充分考虑真实世界完全合作任务所需的各种代理能力方面，如多机器人协作、仓库资源管理等。此外，MARL算法通常在低维状态空间环境中进行评价，因此其处理高维度（例如图像）观测的能力尚未得到充分研究。为解决这一问题，该论文强调需要在更广泛的现有基准上进行系统化评估。为此，我们对知名的合作MARL算法进行了广泛且详细的测试与对比，包括基于图像的观察任务。有趣的是，我们的分析表明，在SMAC和GRF中表现优异的一些算法可能在全面合作基准上不及标准的MARL基线算法的表现。最后，为更系统地评估合作MARL算法，我们开源了PyMARLzoo+工具集，这是(E)PyMARL库的一个扩展版本，解决了[TBG++21]提出的一项开放挑战，并支持PettingZoo所有基准测试以及Overcooked、PressurePlate等特定任务的无缝集成与兼容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-Agent Reinforcement Learning (MARL) has recently emerged as asignificant area of research. However, MARL evaluation often lacks systematicdiversity, hindering a comprehensive understanding of algorithms' capabilities.In particular, cooperative MARL algorithms are predominantly evaluated onbenchmarks such as SMAC and GRF, which primarily feature team game scenarioswithout assessing adequately various aspects of agents' capabilities requiredin fully cooperative real-world tasks such as multi-robot cooperation andwarehouse, resource management, search and rescue, and human-AI cooperation.Moreover, MARL algorithms are mainly evaluated on low dimensional state spaces,and thus their performance on high-dimensional (e.g., image) observations isnot well-studied. To fill this gap, this paper highlights the crucial need forexpanding systematic evaluation across a wider array of existing benchmarks. Tothis end, we conduct extensive evaluation and comparisons of well-known MARLalgorithms on complex fully cooperative benchmarks, including tasks with imagesas agents' observations. Interestingly, our analysis shows that manyalgorithms, hailed as state-of-the-art on SMAC and GRF, may underperformstandard MARL baselines on fully cooperative benchmarks. Finally, towards moresystematic and better evaluation of cooperative MARL algorithms, we haveopen-sourced PyMARLzoo+, an extension of the widely used (E)PyMARL libraries,which addresses an open challenge from [TBG++21], facilitating seamlessintegration and support with all benchmarks of PettingZoo, as well asOvercooked, PressurePlate, Capture Target and Box Pushing.</description>
      <author>example@mail.com (George Papadopoulos, Andreas Kontogiannis, Foteini Papadopoulou, Chaido Poulianou, Ioannis Koumentis, George Vouros)</author>
      <guid isPermaLink="false">2502.04773v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Learning-based Model Predictive Control Strategy for Drift Vehicles</title>
      <link>http://arxiv.org/abs/2502.04696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种自适应路径跟踪（APT）控制方法，用于动态调整车辆漂移状态以遵循参考路径，并在此基础上提出了基于学习的模型预测控制策略（ALMPC），解决了传统追踪方法在极端条件下的不适用性。&lt;h4&gt;背景&lt;/h4&gt;汽车在极端条件下进行自动驾驶时，需要维持车辆状态接近于特定的漂移平衡点（DEP）来跟踪指定路径。然而，传统的跟踪方法由于转向角度和偏航率的原因不适合用于漂移车辆。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的控制策略以适应漂移车辆，并确保其在极端条件下的自动驾驶安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自适应路径跟踪（APT）的模型预测控制策略（ALMPC），其中高层使用贝叶斯优化学习DEP和APT控制规律，而低层则是一个基于DEP的模型预测控制器。这种方法通过将路径追踪与漂移目标分离到不同的层级解决了这两个任务之间的固有冲突。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的ALMPC策略能够有效地调整车辆状态以跟随参考路径，并且即使在道路摩擦参数被错误标识的情况下也能保持良好的性能。&lt;h4&gt;结论&lt;/h4&gt;ALMPC策略通过动态地适应漂移状态并在跟踪和漂移之间找到平衡，证明了其在极端条件下支持安全自动驾驶的有效性。&lt;h4&gt;翻译&lt;/h4&gt;漂移车辆控制为支持极端条件下的安全自主驾驶提供了有价值的见解。然而，传统的追踪方法由于转向角度与偏航率的原因无法适用于此类情况。本文提出了一种自适应路径跟踪（APT）控制策略来调整漂移状态以跟随参考路径，并在此基础上提出了基于学习的模型预测控制策略（ALMPC），解决了传统控制系统对精确系统模型的需求以及非线性漂移动态带来的挑战。通过Matlab-Carsim平台验证了该方法的有效性，证明其在道路摩擦系数错误标识的情况下仍然可以有效地控制车辆跟随基于 Clothoid 的参考路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drift vehicle control offers valuable insights to support safe autonomousdriving in extreme conditions, which hinges on tracking a particular path whilemaintaining the vehicle states near the drift equilibrium points (DEP).However, conventional tracking methods are not adaptable for drift vehicles dueto their opposite steering angle and yaw rate. In this paper, we propose anadaptive path tracking (APT) control method to dynamically adjust drift statesto follow the reference path, improving the commonly utilized predictive pathtracking methods with released computation burden. Furthermore, existingcontrol strategies necessitate a precise system model to calculate the DEP,which can be more intractable due to the highly nonlinear drift dynamics andsensitive vehicle parameters. To tackle this problem, an adaptivelearning-based model predictive control (ALMPC) strategy is proposed based onthe APT method, where an upper-level Bayesian optimization is employed to learnthe DEP and APT control law to instruct a lower-level MPC drift controller.This hierarchical system architecture can also resolve the inherent controlconflict between path tracking and drifting by separating these objectives intodifferent layers. The ALMPC strategy is verified on the Matlab-Carsim platform,and simulation results demonstrate its effectiveness in controlling the driftvehicle to follow a clothoid-based reference path even with the misidentifiedroad friction parameter.</description>
      <author>example@mail.com (Bei Zhou, Cheng Hu, Jun Zeng, Zhouheng Li, Johannes Betz, Lei Xie, Hongye Su)</author>
      <guid isPermaLink="false">2502.04696v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>STRIDE: Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion</title>
      <link>http://arxiv.org/abs/2502.04692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STRIDE 是一种自动化设计奖励函数、深度强化学习训练和反馈优化的框架，用于人形机器人行走任务。该框架结合了代理工程原理和大型语言模型（LLM）的能力，在无需特定任务提示或模板的情况下自动生成、评估并迭代优化奖励函数。&lt;h4&gt;背景&lt;/h4&gt;在人工智能领域，特别是针对高自由度系统的人形机器人的精确协调与控制提出了重大挑战。设计有效的深度强化学习（DRL）奖励函数是关键瓶颈之一，需要大量的手动工作和专业知识以及反复修正。&lt;h4&gt;目的&lt;/h4&gt;提出 STRIDE 框架以自动处理人形机器人行走任务中的奖励设计、DRL 训练及反馈优化问题，旨在减少人工干预并提高效率。&lt;h4&gt;方法&lt;/h4&gt;STRIDE 结合代理工程的结构化原则与大型语言模型的能力，在不同的人形机器人形态和环境中自动生成并优化奖励函数。框架能够进行零样本生成，并在上下文中完成优化。&lt;h4&gt;主要发现&lt;/h4&gt;在涵盖多种环境特征的研究中，STRIDE 超过了最先进的奖励设计框架 EUREKA，展示了显著的效率提升以及任务性能改进。使用 STRIDE 产生的奖励函数后，模拟的人形机器人可以在复杂地形上实现类似短跑的速度移动。&lt;h4&gt;结论&lt;/h4&gt;STRIDE 成功推进了深度强化学习工作流程和人形机器人的研究进展，显示出了大型语言模型在自动化设计中的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要的原文为：人形机器人技术对人工智能提出了重大挑战，要求高自由度系统进行精确协调与控制。为此，在这个领域中为深度强化学习 (DRL) 设计有效的奖励函数仍然是一项关键瓶颈任务，需要大量的手动工作、领域专业知识以及反复迭代调整。为了克服这些难题，我们介绍了 STRIDE——一个新颖的框架，基于代理工程理论来自动化设计 DRL 中所需的奖励函数，并执行训练及反馈优化以适用于人形机器人的行走任务。通过结合代理工程结构化原则和大型语言模型 (LLMs) 的代码编写能力、零样本生成能力和上下文内优化能力，STRIDE 能够在无需特定任务提示或模板的情况下自动生成、评估并迭代奖励函数设计。研究结果表明，在涉及不同人形机器人形态的各种环境中，与最先进的奖励设计框架 EUREKA 相比，STRIDE 表现更优，效率更高且任务性能更加出色。利用 STRIDE 设计的奖励函数，模拟的人形机器人能够在复杂地形上实现短跑级别的运动表现，显示了其在推进 DRL 工作流程和人形机器人研究领域的强大能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robotics presents significant challenges in artificial intelligence,requiring precise coordination and control of high-degree-of-freedom systems.Designing effective reward functions for deep reinforcement learning (DRL) inthis domain remains a critical bottleneck, demanding extensive manual effort,domain expertise, and iterative refinement. To overcome these challenges, weintroduce STRIDE, a novel framework built on agentic engineering to automatereward design, DRL training, and feedback optimization for humanoid robotlocomotion tasks. By combining the structured principles of agentic engineeringwith large language models (LLMs) for code-writing, zero-shot generation, andin-context optimization, STRIDE generates, evaluates, and iteratively refinesreward functions without relying on task-specific prompts or templates. Acrossdiverse environments featuring humanoid robot morphologies, STRIDE outperformsthe state-of-the-art reward design framework EUREKA, achieving significantimprovements in efficiency and task performance. Using STRIDE-generatedrewards, simulated humanoid robots achieve sprint-level locomotion acrosscomplex terrains, highlighting its ability to advance DRL workflows andhumanoid robotics research.</description>
      <author>example@mail.com (Zhenwei Wu, Jinxiong Lu, Yuxiao Chen, Yunxin Liu, Yueting Zhuang, Luhui Hu)</author>
      <guid isPermaLink="false">2502.04692v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Exercise Specialists Evaluation of Robot-led Physical Therapy for People with Parkinsons Disease</title>
      <link>http://arxiv.org/abs/2502.04635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器人辅助的物理治疗提供了一种增强临床专家和理疗师为患者提供的护理的方法，特别是在家庭环境中保证患者的锻炼依从性。&lt;h4&gt;背景&lt;/h4&gt;现有的物理治疗通常依赖于人工监督，在家中的持续性和准确性难以保证。引入机器人的互动可以帮助解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;评估一种新的针对帕金森病患者的机器人引导的物理疗法系统的有效性和接受度。&lt;h4&gt;方法&lt;/h4&gt;通过混合研究方法，包括技术接受问卷、任务负荷问卷和半结构化访谈，对11名临床专家进行了用户研究。&lt;h4&gt;主要发现&lt;/h4&gt;系统获得了广泛的好评，被认为能够增强传统治疗手段，并提高患者的参与度。但是也有两个关键领域需要改进：增加更人性化的反馈机制以及提升机器人的易用性。&lt;h4&gt;结论&lt;/h4&gt;这项研究表明机器人辅助在帕金森病的物理治疗中有巨大的潜力和价值，可以指导未来康复技术的发展方向。&lt;h4&gt;翻译&lt;/h4&gt;机器人引导的物理疗法为提高临床专家和理疗师提供的护理质量提供了一种有前景的方式。通过合作开发互动、个性化的锻炼系统，可以满足每位利益相关者的需求。研究发现，新的机器人引导的PT系统的有效性得到了广泛认可，并且有助于增强传统的帕金森病治疗方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot-led physical therapy (PT) offers a promising avenue to enhance the careprovided by clinical exercise specialists (ES) and physical and occupationaltherapists to improve patients' adherence to prescribed exercises outside of aclinic, such as at home. Collaborative efforts among roboticists, ES, physicaland occupational therapists, and patients are essential for developinginteractive, personalized exercise systems that meet each stakeholder's needs.We conducted a user study in which 11 ES evaluated a novel robot-led PT systemfor people with Parkinson's disease (PD), introduced in [1], focusing on thesystem's perceived efficacy and acceptance. Utilizing a mixed-methods approach,including technology acceptance questionnaires, task load questionnaires, andsemi-structured interviews, we gathered comprehensive insights into ESperspectives and experiences after interacting with the system. Findings reveala broadly positive reception, which highlights the system's capacity to augmenttraditional PT for PD, enhance patient engagement, and ensure consistentexercise support. We also identified two key areas for improvement:incorporating more human-like feedback systems and increasing the robot's easeof use. This research emphasizes the value of incorporating robotic aids intoPT for PD, offering insights that can guide the development of more effectiveand user-friendly rehabilitation technologies.</description>
      <author>example@mail.com (Matthew Lamsey, Meredith D. Wells, Lydia Hamby, Paige Scanlon, Rouida Siddiqui, You Liang Tan, Jerry Feldman, Charles C. Kemp, Madeleine E. Hackney)</author>
      <guid isPermaLink="false">2502.04635v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>High-Speed Dynamic 3D Imaging with Sensor Fusion Splatting</title>
      <link>http://arxiv.org/abs/2502.04630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的传感器融合方法，利用高斯点云技术结合RGB、深度和事件相机来捕捉并重构高速变化的3D场景。&lt;h4&gt;背景&lt;/h4&gt;现有的单一成像模态难以满足快速动态三维场景捕捉的需求。传统RGB摄像头因低帧率、曝光时间和基线宽度限制而受到限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种传感器融合方法，以克服现有技术在捕捉和重构高动态变化的3D场景中的挑战。&lt;h4&gt;方法&lt;/h4&gt;利用Gaussian splatting技术将多种成像模态的优点结合起来：RGB摄像头捕捉细节颜色信息；事件相机记录微秒级快速场景变化；深度相机提供三维几何结构。通过变形三维高斯表示来统一这些模式下的场景表示，并通过优化参数和时间变形场实现对快速移动场景的有效处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有技术相比，该方法在合成数据集和真实数据集中都能显著提高渲染精度和结构性准确性。&lt;h4&gt;结论&lt;/h4&gt;所提出的融合方案能够有效地解决现有单一成像模式的局限性，在低光照、窄基线或快速运动等条件下提供高质量的高速场景捕捉。&lt;h4&gt;翻译&lt;/h4&gt;捕捉并重构高动态三维场景在计算机图形学、视觉以及机器人技术、气动工程和进化生物学等领域有广泛的应用。然而，利用单个成像模态来实现这一点仍然具有挑战性。传统RGB摄像头受限于低帧率、有限的曝光时间和狭窄的基线宽度。为解决这一问题，我们提出了一种新的传感器融合方法，采用高斯点云技术结合RGB、深度和事件相机，以捕捉并重构高速动态场景中的变形部分。本研究的关键在于利用这些成像模态的优点：RGB摄像头捕捉详细的色彩信息；事件相机记录微秒级的快速场景变化；而深度摄像头提供三维场景几何结构。为了在不同模式之间统一场景表示，我们采用可变形3D高斯来代表场景，并通过优化参数及其时间变形场实现对快速移动场景的有效处理。这种融合方案能够高效地捕捉和重构复杂且高速度的场景，在低光、窄基线或快速运动条件下也能保持高质量成像。实验结果表明，与现有先进技术相比，我们的方法在合成数据集及真实数据集中显著提高了渲染质量和结构准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Capturing and reconstructing high-speed dynamic 3D scenes has numerousapplications in computer graphics, vision, and interdisciplinary fields such asrobotics, aerodynamics, and evolutionary biology. However, achieving this usinga single imaging modality remains challenging. For instance, traditional RGBcameras suffer from low frame rates, limited exposure times, and narrowbaselines. To address this, we propose a novel sensor fusion approach usingGaussian splatting, which combines RGB, depth, and event cameras to capture andreconstruct deforming scenes at high speeds. The key insight of our method liesin leveraging the complementary strengths of these imaging modalities: RGBcameras capture detailed color information, event cameras record rapid scenechanges with microsecond resolution, and depth cameras provide 3D scenegeometry. To unify the underlying scene representation across these modalities,we represent the scene using deformable 3D Gaussians. To handle rapid scenemovements, we jointly optimize the 3D Gaussian parameters and their temporaldeformation fields by integrating data from all three sensor modalities. Thisfusion enables efficient, high-quality imaging of fast and complex scenes, evenunder challenging conditions such as low light, narrow baselines, or rapidmotion. Experiments on synthetic and real datasets captured with our prototypesensor fusion setup demonstrate that our method significantly outperformsstate-of-the-art techniques, achieving noticeable improvements in bothrendering fidelity and structural accuracy.</description>
      <author>example@mail.com (Zihao Zou, Ziyuan Qu, Xi Peng, Vivek Boominathan, Adithya Pediredla, Praneeth Chakravarthula)</author>
      <guid isPermaLink="false">2502.04630v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Force interaction, modeling and soft tissue deformation during reciprocating insertion of multi-part probe</title>
      <link>http://arxiv.org/abs/2502.04609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages with 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过开发一种模仿寄生蜂卵刺的往复运动探针，探索了软组织插入时减少作用力和最小化组织损伤的方法。实验使用力传感器和激光光学技术进行测试。&lt;h4&gt;背景&lt;/h4&gt;受产卵黄蜂生物启发的工程设计利用往复运动来实现软组织插入，这可能降低插入力并减少组织损伤。然而，有关组织交互和保护机制的原理尚未完全明了。&lt;h4&gt;目的&lt;/h4&gt;研究开发了一种模仿卵刺多部件探针及其往复运动模式，并分析其与软组织相互作用时的动力学特性。&lt;h4&gt;方法&lt;/h4&gt;建立了往复插入模型来研究探针与软组织之间的互动，通过力传感器和激光光学技术进行实验测试。&lt;h4&gt;主要发现&lt;/h4&gt;在往复运动的切割阶段，峰值力比直接插入减少了约19%，平均位移减少约20%（均基于探针速度为1mm/s的情况下）。&lt;h4&gt;结论&lt;/h4&gt;这项研究提出了一种结合机械建模与实验分析的新方法来探讨往复插入方式的动力学特性，并更好地理解了探针和软组织之间的相互作用。&lt;h4&gt;翻译&lt;/h4&gt;生物启发的寄生蜂产卵行为工程设计展示了利用往复运动实现软组织插入的优势，这有助于减少插入力并保护组织不受损伤。然而，这种模式背后的机制尚未完全了解。这项研究旨在探讨一种模仿黄蜂卵刺多部件探针及其往复运动的设计，并使用力学模型和实验技术来分析其与软组织交互的动力学特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The bio-inspired engineering of ovipositing wasps, which employ areciprocating motion for soft tissue insertion, offers potential advantages inreducing insertion force and minimizing tissue damage. However, the underlyingmechanisms of tissue interaction and sparing are not fully understood. In thisstudy, we aim to investigate a multi-part probe designed to mimic thereciprocating motion of ovipositors. A reciprocal insertion model was developedto study the interaction between the probe and soft tissue, and experimentaltesting was conducted using a force sensor and laser optical technique to gaininsights into interacting forces and tissue deformation. The results revealthat during the cutting phase of reciprocal motion, the peak force and averagedisplacement of the soft substrate were approximately 19% and 20% lower,respectively, compared to direct insertion at an overall probe velocity of 1mm/s. This study presents a novel approach combining mechanical modeling andexperimental analysis to explore the force mechanics of the reciprocatinginsertion method, providing a better understanding of the interaction betweenthe probe and soft tissue.</description>
      <author>example@mail.com (Tassanai Parittotokkaporn, Matthew Oldfield, Luca Frasson, Ferdinando Rodriguez y Baena)</author>
      <guid isPermaLink="false">2502.04609v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Cooperative Payload Estimation by a Team of Mocobots</title>
      <link>http://arxiv.org/abs/2502.04600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures. Submitted to IEEE Robotics and Automation Letters  (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种机器人团队自主发现共同负载的位置和惯性属性的方法。&lt;h4&gt;背景&lt;/h4&gt;在人类引导多个移动机械手抓取同一负载的场景下，为了后续高效率的自动化操作或是与人的协作，机器人们需要知道彼此是如何附着于负载上的，并且能够了解负载的质量和惯性特性。&lt;h4&gt;目的&lt;/h4&gt;描述一种使机器人能够自主发现这些信息的方法。&lt;h4&gt;方法&lt;/h4&gt;通过合作操纵负载并使用夹持点处的旋转、旋转导数以及扭力数据来估计抓取框架之间的变换矩阵，负载质心的位置及负载的惯性矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了三台移动协作机器人或称莫科博特(team of mocobots)的方法有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法为多机械手团队在自动化操作和与人类协作中提供了一个有效解决方案。&lt;h4&gt;翻译&lt;/h4&gt;考虑以下场景：一个人引导多个移动机械手抓取同一个负载。为了后续高效率的自主操作，或者与人的合作，机器人应该能够发现其他机器人附着于负载的位置，并了解负载的质量和惯性特性。本文描述了一种让机器人自主发现这些信息的方法。通过合作操纵负载并使用夹持点处的旋转、旋转导数以及扭力数据来估计抓取框架之间的变换矩阵、负载质心位置及负载的惯性矩阵。该方法通过一个由三台移动协作机器人组成的团队进行了实验验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Consider the following scenario: a human guides multiple mobile manipulatorsto grasp a common payload. For subsequent high-performance autonomousmanipulation of the payload by the mobile manipulator team, or forcollaborative manipulation with the human, the robots should be able todiscover where the other robots are attached to the payload, as well as thepayload's mass and inertial properties. In this paper, we describe a method forthe robots to autonomously discover this information. The robots cooperativelymanipulate the payload, and the twist, twist derivative, and wrench data attheir grasp frames are used to estimate the transformation matrices between thegrasp frames, the location of the payload's center of mass, and the payload'sinertia matrix. The method is validated experimentally with a team of threemobile cobots, or mocobots.</description>
      <author>example@mail.com (Haoxuan Zhang, C. Lin Liu, Matthew L. Elwin, Randy A. Freeman, Kevin M. Lynch)</author>
      <guid isPermaLink="false">2502.04600v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Joint State and Noise Covariance Estimation</title>
      <link>http://arxiv.org/abs/2502.04584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在测量受高斯噪声影响的情况下，同时估计噪声协方差矩阵和主要参数（如姿态和点）的问题，并提出了两个新颖的算法。&lt;h4&gt;背景&lt;/h4&gt;现有的方法往往单独考虑主要参数或仅提供噪声协方差矩阵的粗略估算，而忽略了两者的联合优化可能带来的性能提升。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以更准确地估计噪声协方差矩阵和主要参数（如姿态、点等），并证明该问题在某些框架下具有凸结构。&lt;h4&gt;方法&lt;/h4&gt;通过分析联合最大后验概率和似然性框架以及多个变体下的最优噪声协方差估计，提出两个新颖的算法来同时估算主要参数和噪声协方差矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;证明了联合估计问题在某些情况下是凸优化问题，并提供了理论上的解析解。实验结果表明，在各种场景中，新方法比现有技术更为有效。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法提供了一种更加准确的噪声协方差估计和主要参数估算的方式，尤其适用于机器人学和计算机视觉中的SLAM等任务。&lt;h4&gt;翻译&lt;/h4&gt;此论文解决了在测量数据受高斯噪声污染的情况下同时估计噪声协方差矩阵以及诸如姿态和点的主要参数的问题。本文展示了该联合问题具有凸结构，并提供了几种框架下的最优噪声协方差估计的完整特征（包括解析解）。基于这些理论结果，我们提出两个新的算法来共同估计主要参数和噪声协方差矩阵。为了验证我们的方法，我们在不同的场景下进行了广泛的实验，并为在机器人学和计算机视觉中的估算问题应用提供实用见解，特别是SLAM方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles the problem of jointly estimating the noise covariancematrix alongside primary parameters (such as poses and points) frommeasurements corrupted by Gaussian noise. In such settings, the noisecovariance matrix determines the weights assigned to individual measurements inthe least squares problem. We show that the joint problem exhibits a convexstructure and provide a full characterization of the optimal noise covarianceestimate (with analytical solutions) within joint maximum a posteriori andlikelihood frameworks and several variants. Leveraging this theoretical result,we propose two novel algorithms that jointly estimate the primary parametersand the noise covariance matrix. To validate our approach, we conduct extensiveexperiments across diverse scenarios and offer practical insights into theirapplication in robotics and computer vision estimation problems with aparticular focus on SLAM.</description>
      <author>example@mail.com (Kasra Khosoussi, Iman Shames)</author>
      <guid isPermaLink="false">2502.04584v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>The Mini Wheelbot: A Testbed for Learning-based Balancing, Flips, and Articulated Driving</title>
      <link>http://arxiv.org/abs/2502.04582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mini Wheelbot是一款用于学习型控制算法测试的轮式机器人，具有自我平衡功能和非线性动态特性。该机器人可以利用其车轮从任何初始姿态站立起来，并能够根据用户指令进行移动。&lt;h4&gt;背景&lt;/h4&gt;设计了一个称为Mini Wheelbot的小型、强力且耐用的单轮机器人作为基于学习的控制算法的测试平台。&lt;h4&gt;目的&lt;/h4&gt;展示Mini Wheelbot作为一种测试平台的有效性，通过实现两种流行的基于学习的控制算法来验证其功能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用贝叶斯优化调整平衡控制器；2. 利用专家非线性MPC进行模仿学习，该算法利用陀螺效应重新定向机器人，并能够跟踪更高的速度和方向命令。&lt;h4&gt;主要发现&lt;/h4&gt;Mini Wheelbot能够在任何初始姿态下站立起来并执行基于用户指令的移动任务，展示了其在学习型控制算法测试中的潜力。&lt;h4&gt;结论&lt;/h4&gt;Mini Wheelbot不仅为研究提供了有价值的工具，而且由于其独特的功能和操作方式也十分有趣。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Mini Wheelbot是一种平衡式反应轮独轮机器人，作为基于学习的控制系统试验平台而设计。这是一个不稳定的系统，具有高度非线性的偏航动态、非完整驱动以及在小型、强力且坚固的形式因素中的离散接触开关。Mini Wheelbot可以使用其车轮从任何初始姿态站立起来——使得它可以在重复实验中自动重置环境，并能应对半翻转等挑战性动作。我们通过实现两种流行的基于学习的控制算法，展示了Mini Wheelbot作为试验平台的有效性。首先，我们展示贝叶斯优化用于调整平衡控制器；其次，我们使用模仿学习从一个专家非线性MPC进行学习，该方法利用陀螺效应重新定向机器人，并且可以跟踪高级别的速度和方向命令。后者使机器人能够根据用户指令移动——这是这类机器人首次实现的功能。Mini Wheelbot不仅作为测试基于学习的控制算法很有吸引力，而且在操作上也非常有趣，如我们在实验视频中所演示的一样。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Mini Wheelbot is a balancing, reaction wheel unicycle robot designed as atestbed for learning-based control. It is an unstable system with highlynonlinear yaw dynamics, non-holonomic driving, and discrete contact switches ina small, powerful, and rugged form factor. The Mini Wheelbot can use its wheelsto stand up from any initial orientation - enabling automatic environmentresets in repetitive experiments and even challenging half flips. We illustratethe effectiveness of the Mini Wheelbot as a testbed by implementing two popularlearning-based control algorithms. First, we showcase Bayesian optimization fortuning the balancing controller. Second, we use imitation learning from anexpert nonlinear MPC that uses gyroscopic effects to reorient the robot and cantrack higher-level velocity and orientation commands. The latter allows therobot to drive around based on user commands - for the first time in this classof robots. The Mini Wheelbot is not only compelling for testing learning-basedcontrol algorithms, but it is also just fun to work with, as demonstrated inthe video of our experiments.</description>
      <author>example@mail.com (Henrik Hose, Jan Weisgerber, Sebastian Trimpe)</author>
      <guid isPermaLink="false">2502.04582v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture</title>
      <link>http://arxiv.org/abs/2502.04558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 Pages, 4 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项工作旨在通过探索OpenVLA模型的隐藏层来揭示视觉和语言输入转化为机器人行动过程中的符号表示，从而增强认知架构（CA）的理解性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;目前的vision-language-action (VLA) 模型可以将视觉和语言输入转换为机器人的行动指令，但是由于其黑箱性质和对环境变化的高度敏感性，在可靠性方面存在局限。而另一方面，认知架构在符号推理和状态监控上表现出色，但受限于预定义执行的僵化。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过探索OpenVLA模型的隐藏层来揭示视觉和语言输入转化为机器人行动过程中的符号表示，从而增强认知架构的理解性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;在LIBERO空间抓取放置任务上进行实验，分析了不同层次中OpenVLA的Llama骨干网络对符号状态的编码情况。&lt;h4&gt;主要发现&lt;/h4&gt;探针结果显示，几乎所有层对于物体和行动状态的编码准确性都非常高（&gt; 0.90），但没有观察到我们假设的先编码物体状态再编码动作状态的现象。展示了DIARC-OpenVLA集成系统的实时监控能力，该系统利用这些符号表示。&lt;h4&gt;结论&lt;/h4&gt;通过将视觉语言行为模型与认知架构相结合，可以创建一个更可解释且可靠的机器人操作基础框架，为未来的研究提供了新的方向和可能性。&lt;h4&gt;翻译&lt;/h4&gt;Vision-language-action (VLA) 模型作为通用的机器人解决方案显示出前景，然而它们缺乏可靠性。本研究探讨了如何通过揭示OpenVLA模型中的符号表示来增强认知架构的理解性和鲁棒性，并展示了DIARC-OpenVLA集成系统的实时监控能力，为未来的机器人操作奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action (VLA) models hold promise as generalist roboticssolutions by translating visual and linguistic inputs into robot actions, yetthey lack reliability due to their black-box nature and sensitivity toenvironmental changes. In contrast, cognitive architectures (CA) excel insymbolic reasoning and state monitoring but are constrained by rigid predefinedexecution. This work bridges these approaches by probing OpenVLA's hiddenlayers to uncover symbolic representations of object properties, relations, andaction states, enabling integration with a CA for enhanced interpretability androbustness. Through experiments on LIBERO-spatial pick-and-place tasks, weanalyze the encoding of symbolic states across different layers of OpenVLA'sLlama backbone. Our probing results show consistently high accuracies (&gt; 0.90)for both object and action states across most layers, though contrary to ourhypotheses, we did not observe the expected pattern of object states beingencoded earlier than action states. We demonstrate an integrated DIARC-OpenVLAsystem that leverages these symbolic representations for real-time statemonitoring, laying the foundation for more interpretable and reliable roboticmanipulation.</description>
      <author>example@mail.com (Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz)</author>
      <guid isPermaLink="false">2502.04558v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Learning Based Prediction of PID Controller Gains for Quadrotor UAVs</title>
      <link>http://arxiv.org/abs/2502.04552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出并实现了一种基于强化学习的方法，用于在线微调PID控制器参数以提高四旋翼飞行器的轨迹跟踪精度和有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的PID控制方法需要手动调整参数，这可能无法适应所有环境条件。&lt;h4&gt;目的&lt;/h4&gt;通过使用RL算法自动优化PID控制器参数，以提升四轴飞行器的姿态追踪性能。&lt;h4&gt;方法&lt;/h4&gt;{'训练方式': '首先在模拟环境中离线训练RL代理，然后通过仿真和实际飞行测试进行验证。', '工具与平台': '利用Matlab/Simulink及PX4自动驾驶仪支持包中的无人机工具箱进行训练和仿真研究。', '比较对象': '对比人工调参方法的性能表现'}&lt;h4&gt;主要发现&lt;/h4&gt;基于RL的方法可以在线调整控制器参数，减少姿态误差，显著改善姿态追踪性能。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证了使用RL优化PID控制器参数的有效性。与手动调优相比，该方法在实际飞行中表现出更好的姿态跟踪效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A reinforcement learning (RL) based methodology is proposed and implementedfor online fine-tuning of PID controller gains, thus, improving quadrotoreffective and accurate trajectory tracking. The RL agent is first trainedoffline on a quadrotor PID attitude controller and then validated throughsimulations and experimental flights. RL exploits a Deep Deterministic PolicyGradient (DDPG) algorithm, which is an off-policy actor-critic method. Trainingand simulation studies are performed using Matlab/Simulink and the UAV ToolboxSupport Package for PX4 Autopilots. Performance evaluation and comparisonstudies are performed between the hand-tuned and RL-based tuned approaches. Theresults show that the controller parameters based on RL are adjusted duringflights, achieving the smallest attitude errors, thus significantly improvingattitude tracking performance compared to the hand-tuned approach.</description>
      <author>example@mail.com (Serhat Sönmez, Luca Montecchio, Simone Martini, Matthew J. Rutherford, Alessandro Rizzo, Margareta Stefanovic, Kimon P. Valavanis)</author>
      <guid isPermaLink="false">2502.04552v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>OneTrack-M: A multitask approach to transformer-based MOT models</title>
      <link>http://arxiv.org/abs/2502.04478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OneTrack-M的基于变压器的多目标跟踪模型，旨在提高计算效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉领域中，多目标跟踪（MOT）是一个关键问题，用于理解视频中的对象如何移动和交互。面对遮挡和复杂环境动态等挑战，传统方法依赖于卷积神经网络（CNN），引入变压器带来了显著的进步。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Transformer的MOT模型OneTrack-M，以提高跟踪计算效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;简化传统的基于Transformer的架构，删除用于对象检测和跟踪的解码器模型，仅使用编码器作为骨干来解释时间数据。采用创新的数据预处理技术和多任务训练技术解决单一权重集合内的遮挡和多样目标挑战问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，OneTrack-M在推理速度方面比现有文献中的最佳模型快至少25%，同时保持或提高了跟踪准确性指标。&lt;h4&gt;结论&lt;/h4&gt;这些改进突显了所提出解决方案在实时应用（如自动驾驶汽车、监控系统和机器人技术）的潜力，其中快速响应对于系统的有效性至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-Object Tracking (MOT) is a critical problem in computer vision,essential for understanding how objects move and interact in videos. This fieldfaces significant challenges such as occlusions and complex environmentaldynamics, impacting model accuracy and efficiency. While traditional approacheshave relied on Convolutional Neural Networks (CNNs), introducing transformershas brought substantial advancements. This work introduces OneTrack-M, atransformer-based MOT model designed to enhance tracking computationalefficiency and accuracy. Our approach simplifies the typical transformer-basedarchitecture by eliminating the need for a decoder model for object detectionand tracking. Instead, the encoder alone serves as the backbone for temporaldata interpretation, significantly reducing processing time and increasinginference speed. Additionally, we employ innovative data pre-processing andmultitask training techniques to address occlusion and diverse objectivechallenges within a single set of weights. Experimental results demonstratethat OneTrack-M achieves at least 25% faster inference times compared tostate-of-the-art models in the literature while maintaining or improvingtracking accuracy metrics. These improvements highlight the potential of theproposed solution for real-time applications such as autonomous vehicles,surveillance systems, and robotics, where rapid responses are crucial forsystem effectiveness.</description>
      <author>example@mail.com (Luiz C. S. de Araujo, Carlos M. S. Figueiredo)</author>
      <guid isPermaLink="false">2502.04478v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Efficient variable-length hanging tether parameterization for marsupial robot planning in 3D environments</title>
      <link>http://arxiv.org/abs/2502.04467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted in T-RO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的方法来有效地参数化和估计悬挂绳索的状态，以优化UGV（地面无人车）与UAV（无人机）在袋鼠配置下的路径和轨迹规划。&lt;h4&gt;背景&lt;/h4&gt;现有技术通常假设绳索是紧绷的或使用悬链线模型来表示悬挂绳索的形状。然而，悬链线计算复杂且需要在规划过程中多次计算；而紧绷绳索假设虽然简化了问题但可能过度限制平台的运动。&lt;h4&gt;目的&lt;/h4&gt;为了加速路径和轨迹规划过程，本文提出了一种新的分析方法来高效地计算悬挂绳索的状态，并提出了一个避免碰撞的绳索状态参数化的方法。&lt;h4&gt;方法&lt;/h4&gt;利用悬链线与抛物线曲线之间的相似性推导出用于表示绳索状态的解析表达式。&lt;h4&gt;主要发现&lt;/h4&gt;通过新方法，可以更快速、准确地进行路径和轨迹规划。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新的途径来优化UGV-UAV组合的路径和轨迹规划问题，在不牺牲精度的情况下提高了计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译为：本文提出一种新颖的方法以有效地参数化并估计悬挂缆绳的状态，从而加快袋鼠配置下联结地面无人车（UGV）与无人机（UAV）的路径及轨迹规划进程。大多数现有方法要么假设缆绳紧绷，要么使用悬链线模型来表示悬挂缆绳形态；前者简化了问题但过度限制平台运动灵活性，后者计算复杂且需在规划过程中反复应用数千次，成为耗时任务。本文为加速规划过程，提出了建立一种解析模型高效求解悬挂缆绳状态，并提供免碰撞的缆索状态参数化的方法。利用悬链线与抛物线曲线之间的相似性推导出该解析表达式来描述缆绳形态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to efficiently parameterize and estimatethe state of a hanging tether for path and trajectory planning of a UGV tied toa UAV in a marsupial configuration. Most implementations in the state of theart assume a taut tether or make use of the catenary curve to model the shapeof the hanging tether. The catenary model is complex to compute and must beinstantiated thousands of times during the planning process, becoming atime-consuming task, while the taut tether assumption simplifies the problem,but might overly restrict the movement of the platforms. In order to acceleratethe planning process, this paper proposes defining an analytical model toefficiently compute the hanging tether state, and a method to get a tetherstate parameterization free of collisions. We exploit the existing similaritybetween the catenary and parabola curves to derive analytical expressions ofthe tether state.</description>
      <author>example@mail.com (S. Martínez-Rozas, D. Alejo, F. Caballero, L. Merino, M. A. Pérez-Cutiño, F. Rodriguez, V. Sánchez-Canales, I. Ventura, J. M. Díaz-Bañez)</author>
      <guid isPermaLink="false">2502.04467v1</guid>
      <pubDate>Mon, 10 Feb 2025 16:52:25 +0800</pubDate>
    </item>
    <item>
      <title>Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation</title>
      <link>http://arxiv.org/abs/2502.02548v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://nvlabs.github.io/Mosaic3D/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种处理开放词汇3D场景理解的新数据生成流程和训练框架。&lt;h4&gt;背景&lt;/h4&gt;当前的3D场景理解方法在精确性、语义丰富性和大规模训练数据方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的方法来满足精准3D区域分割、全面文本描述以及足够大的数据集规模等三项关键需求。&lt;h4&gt;方法&lt;/h4&gt;{'1': '利用最先进的开放词汇图像分割模型和基于视觉的语言模型，创建了一种自动生成高质量的3D掩码-文本对的自动化流程。', '2': '该流程应用于多个3D场景数据集，并构建了一个包含超过30,000个注释场景和560万掩码-文本对的大规模新数据集Mosaic3D-5.6M。', '3': '基于此数据集，提出了一种基础模型Mosaic3D，结合了通过对比学习训练的3D编码器和用于开放词汇3D语义及实例分割的轻量级掩码解码器。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '所提出的框架实现了开放词汇3D语义和实例分割任务（包括ScanNet200、Matterport3D和ScanNet++）上的最新技术水平。', '2': '消融研究表明，大规模训练数据的有效性得到了验证。'}&lt;h4&gt;结论&lt;/h4&gt;通过引入一种创新的数据生成流程和模型架构，有效地推进了开放词汇3D场景理解的发展。&lt;h4&gt;翻译&lt;/h4&gt;我们通过引入一个新颖的数据库生成管道和训练框架来处理开放词汇的三维场景理解问题。我们的方法解决了有效训练中的三个关键要求：精确的三维区域分割、全面的文本描述以及足够的数据集规模。利用最先进的开放词汇图像分割模型和基于视觉的语言模型，开发了一种自动生成高质量3D掩码-文本对的自动化流程。我们将此流程应用于多个3D场景数据库，并创建了一个包含超过30,000个注释场景与560万掩码-文本对的大规模新数据集Mosaic3D-5.6M，该数据集比现有数据集大得多。基于这个数据集，我们提出了一种基础模型Mosaic3D，结合了通过对比学习训练的3D编码器和用于开放词汇三维语义及实例分割的轻量级掩码解码器。我们的方法在包括ScanNet200、Matterport3D和ScanNet++在内的开放词汇三维语义和实例分割任务上实现了最先进的技术水平，消融研究表明大规模训练数据的有效性得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We tackle open-vocabulary 3D scene understanding by introducing a novel datageneration pipeline and training framework. Our method addresses three criticalrequirements for effective training: precise 3D region segmentation,comprehensive textual descriptions, and sufficient dataset scale. By leveragingstate-of-the-art open-vocabulary image segmentation models and region-awareVision-Language Models, we develop an automatic pipeline that generateshigh-quality 3D mask-text pairs. Applying this pipeline to multiple 3D scenedatasets, we create Mosaic3D-5.6M, a dataset of over 30K annotated scenes with5.6M mask-text pairs, significantly larger than existing datasets. Buildingupon this data, we propose Mosaic3D, a foundation model combining a 3D encodertrained with contrastive learning and a lightweight mask decoder foropen-vocabulary 3D semantic and instance segmentation. Our approach achievesstate-of-the-art results on open-vocabulary 3D semantic and instancesegmentation tasks including ScanNet200, Matterport3D, and ScanNet++, withablation studies validating the effectiveness of our large-scale training data.</description>
      <author>example@mail.com (Junha Lee, Chunghyun Park, Jaesung Choe, Yu-Chiang Frank Wang, Jan Kautz, Minsu Cho, Chris Choy)</author>
      <guid isPermaLink="false">2502.02548v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
  <item>
      <title>On The Concurrence of Layer-wise Preconditioning Methods and Provable Feature Learning</title>
      <link>http://arxiv.org/abs/2502.01763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了一种记忆高效优化算法——逐层预处理方法，这种算法在神经网络优化任务中表现出相对于传统的对角线预处理（如Adam(W)）更优异的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于层的预处理方法经历了一个复兴，特别是在解决广泛的神经网络优化问题时。这些方法不仅从实践中表现卓越，而且从统计学的角度来看，是必要的。&lt;h4&gt;目的&lt;/h4&gt;展示在非理想的输入和不良条件下逐层预处理方法如何有效地学习有用的特征来支持泛化，以及标准工具如Adam预处理和批归一化的限制。&lt;h4&gt;方法&lt;/h4&gt;通过研究两种典型的模型（线性表示学习和单一索引学习），作者展示了SGD在这种情况下不是最优的特征学习者，并证明了逐层预处理是自然解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;在非理想输入条件下，SGD无法有效地泛化。而逐层预处理方法可以显著改善这一问题，显示出其相对于标准工具的独特优势。&lt;h4&gt;结论&lt;/h4&gt;逐层预处理对于解决神经网络优化中的挑战具有独特的优势和必要性，并且是自然的学习过程解决方案。&lt;h4&gt;翻译&lt;/h4&gt;逐层预处理方法是一类记忆高效的优化算法，这些方法在每个层的权重张量轴上引入预处理器。近年来，它们经历了复兴，在广泛的神经网络优化任务中相对于传统对角线预处理（如Adam(W)）显示出了优异的表现。除了其实际性能之外，该研究还从统计学的角度证明了逐层预处理方法是必要的。通过考虑两种典型的模型——线性表示学习和单一索引学习，作者展示了在扩展至理想各向同性的输入及以往工作中通常假设的良好条件下时，SGD不是一个最优的特征学习者。理论与数值分析均表明这一不足是本质上的，并证明逐层预处理作为解决方案自然地出现。此外，研究还显示标准工具如Adam预处理和批归一化只能轻微缓解这些问题，进一步支持了逐层预处理的独特益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Layer-wise preconditioning methods are a family of memory-efficientoptimization algorithms that introduce preconditioners per axis of each layer'sweight tensors. These methods have seen a recent resurgence, demonstratingimpressive performance relative to entry-wise ("diagonal") preconditioningmethods such as Adam(W) on a wide range of neural network optimization tasks.Complementary to their practical performance, we demonstrate that layer-wisepreconditioning methods are provably necessary from a statistical perspective.To showcase this, we consider two prototypical models, linear representationlearning and single-index learning, which are widely used to study how typicalalgorithms efficiently learn useful features to enable generalization. In theseproblems, we show SGD is a suboptimal feature learner when extending beyondideal isotropic inputs $\mathbf{x} \sim \mathsf{N}(\mathbf{0}, \mathbf{I})$ andwell-conditioned settings typically assumed in prior work. We demonstratetheoretically and numerically that this suboptimality is fundamental, and thatlayer-wise preconditioning emerges naturally as the solution. We further showthat standard tools like Adam preconditioning and batch-norm only mildlymitigate these issues, supporting the unique benefits of layer-wisepreconditioning.</description>
      <author>example@mail.com (Thomas T. Zhang, Behrad Moniri, Ansh Nagwekar, Faraz Rahman, Anton Xue, Hamed Hassani, Nikolai Matni)</author>
      <guid isPermaLink="false">2502.01763v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Multimarginal Schrödinger Barycenter</title>
      <link>http://arxiv.org/abs/2502.02726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了基于熵正则化的多边际最优传输问题的多重Schrödinger平均中心（MSB），提供了一种快速计算高维分布Wasserstein平均的方法。&lt;h4&gt;背景&lt;/h4&gt;Wasserstein barycenter在度量值数据的平均中起重要作用，但计算和估计高维分布下的Wasserstein barycenter面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于熵正则化的多边际最优传输问题来解决高维分布下Wasserstein barycenter计算的问题，并提供理论上的收敛速度保证。&lt;h4&gt;方法&lt;/h4&gt;引入了多重Schrödinger平均中心（MSB），并通过识别适当的对偶几何结构，推导了从随机采样点估计关键的MSB量的非渐近收敛率。&lt;h4&gt;主要发现&lt;/h4&gt;该研究证明所获得的样本复杂度在统计上是最优的，可以用来估计成本函数、Schrödinger耦合和barycenter。&lt;h4&gt;结论&lt;/h4&gt;新提出的多重Schrödinger平均中心（MSB）为高维分布下的Wasserstein barycenter提供了一个有效的计算方法，并且从理论上证明了其统计最优性。&lt;h4&gt;翻译&lt;/h4&gt;Wasserstein重心在度量值数据的平均中扮演着基础性的角色。然而，在最优传输框架下，对于高维度分布，计算和估计Wasserstein重心面临巨大的挑战。本文提出了基于熵正则化的多边际最优传输问题的多重Schrödinger重心（MSB），该方法提供了用于快速计算的一般算法。通过识别适当的对偶几何结构，我们推导了从随机点云中估计多个关键MSB量的非渐近收敛率。具体而言，我们展示了我们的样本复杂度在统计上是最优的，适用于成本函数、Schrödinger耦合和重心的估计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Wasserstein barycenter plays a fundamental role in averagingmeasure-valued data under the framework of optimal transport. However, thereare tremendous challenges in computing and estimating the Wassersteinbarycenter for high-dimensional distributions. In this paper, we introduce themultimarginal Schr\"{o}dinger barycenter (MSB) based on the entropy regularizedmultimarginal optimal transport problem that admits general-purpose fastalgorithms for computation. By recognizing a proper dual geometry, we derivenon-asymptotic rates of convergence for estimating several key MSB quantitiesfrom point clouds randomly sampled from the input marginal distributions.Specifically, we show that our obtained sample complexity is statisticallyoptimal for estimating the cost functional, Schr\"{o}dinger coupling andbarycenter.</description>
      <author>example@mail.com (Pengtao Li, Xiaohui Chen)</author>
      <guid isPermaLink="false">2502.02726v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Mapping and Localization Using LiDAR Fiducial Markers</title>
      <link>http://arxiv.org/abs/2502.03510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于LiDAR测距仪的新型框架，用于利用LiDAR标识符（LFMs）进行地图绘制和定位，并展示了其在多种现实应用中的潜在价值。&lt;h4&gt;背景&lt;/h4&gt;当前LiDAR标识符在采用率和实用性方面落后于视觉标识符，主要是由于3D LiDAR数据稀疏且无结构化，以及现有的2D重点设计的限制。&lt;h4&gt;目的&lt;/h4&gt;开发一种新型框架，以便使用LFMs进行地图绘制和定位，并提高其在各种现实世界应用中的性能。&lt;h4&gt;方法&lt;/h4&gt;[{'IFM系统': '引入了一种基于强度图像的LiDAR标识符（IFM）系统，该系统兼容视觉标识符的薄、A4大小的标记。检测算法能够通过强度图像定位3D标识符，并实现LiDAR姿态估计。', '增强方法': '扩展了检测到3D地图的方法，增加了标记范围并克服了几何检测方法的限制，利用了强度和几何特征。', 'LFM映射与定位法': '该论文介绍了一种基于LFMs的新方法，用于配准无序、重叠度低的点云，并采用自适应阈值检测及两级图框架解决最大后验估计问题（MAP），优化点云及其标志的位置。'}, {'数据集改进': '提出Livox-3DMatch数据集，改进基于学习的多视角点云配准方法。'}]&lt;h4&gt;主要发现&lt;/h4&gt;该研究在各种LiDAR型号和不同室内室外场景中进行了广泛的实验，证明了所提框架的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的基于LFMs的地图绘制与定位框架展现出了广泛的应用潜力，并为自主系统中的3D LiDAR数据处理开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR sensors are essential for autonomous systems, yet LiDAR fiducialmarkers (LFMs) lag behind visual fiducial markers (VFMs) in adoption andutility. Bridging this gap is vital for robotics and computer vision butchallenging due to the sparse, unstructured nature of 3D LiDAR data and2D-focused fiducial marker designs. This dissertation proposes a novelframework for mapping and localization using LFMs is proposed to benefit avariety of real-world applications, including the collection of 3D assets andtraining data for point cloud registration, 3D map merging, Augmented Reality(AR), and many more.  First, an Intensity Image-based LiDAR Fiducial Marker (IFM) system isintroduced, using thin, letter-sized markers compatible with VFMs. A detectionmethod locates 3D fiducials from intensity images, enabling LiDAR poseestimation. Second, an enhanced algorithm extends detection to 3D maps,increasing marker range and facilitating tasks like 3D map merging. This methodleverages both intensity and geometry, overcoming limitations of geometry-onlydetection approaches. Third, a new LFM-based mapping and localization methodregisters unordered, low-overlap point clouds. It employs adaptive thresholddetection and a two-level graph framework to solve a maximum a-posteriori (MAP)problem, optimizing point cloud and marker poses. Additionally, theLivox-3DMatch dataset is introduced, improving learning-based multiview pointcloud registration methods.  Extensive experiments with various LiDAR models in diverse indoor and outdoorscenes demonstrate the effectiveness and superiority of the proposed framework.</description>
      <author>example@mail.com (Yibo Liu)</author>
      <guid isPermaLink="false">2502.03510v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Factorized Implicit Global Convolution for Automotive Computational Fluid Dynamics Prediction</title>
      <link>http://arxiv.org/abs/2502.04317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Factorized Implicit Global Convolution (FIGConv)的新架构，该架构可以有效解决大型3D网格的计算流体动力学(CFD)问题。&lt;h4&gt;背景&lt;/h4&gt;CFD在汽车设计中至关重要，但现有深度学习方法难以处理高分辨率3D数据带来的复杂性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的神经网络架构来简化CFD问题，特别是在处理非常大的3D网格时能够降低计算成本。&lt;h4&gt;方法&lt;/h4&gt;新架构包括因子化隐式网格、通过2D重新参数化的高效全局卷积以及用于有效信息收集和集成的U形结构。该方法在Ahmed车身数据集和DrivAerNet大规模数据集上进行了验证。&lt;h4&gt;主要发现&lt;/h4&gt;与现有的3D神经CFD模型相比，新架构将复杂度从立方降低到了二次方($O(N^2)$)；在DrivAerNet上的预测结果显示出$R^2$值为0.95，并且相对均方误差和绝对均方误差分别提高了40%和70%，超越了现有最佳方法。&lt;h4&gt;结论&lt;/h4&gt;新提出的FIGConv架构能够在保持高精度的同时，显著降低CFD问题的计算复杂度，为汽车设计中的流体动力学分析提供了一种更高效的方法。&lt;h4&gt;翻译&lt;/h4&gt;计算流体动力学(CFD)在汽车行业设计中至关重要。为了研究车辆几何形状如何影响压力场和阻力力，需要对大型3D点云进行分析。然而，现有的深度学习方法处理高分辨率3D数据时面临计算复杂性的问题。我们提出了一种名为因子化隐式全局卷积(FIGConv)的新架构来解决这些问题。该架构结合了因子化隐式网格、通过2D重新参数化的高效全局卷积以及U形结构，以有效信息收集和集成，并且在标准Ahmed车身数据集和大型DrivAerNet数据集中进行了验证。实验结果表明，在预测阻力方面，新方法的$R^2$值为0.95，相对均方误差提高了40%，绝对均方误差提高70%。这比现有最佳方法有显著改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational Fluid Dynamics (CFD) is crucial for automotive design,requiring the analysis of large 3D point clouds to study how vehicle geometryaffects pressure fields and drag forces. However, existing deep learningapproaches for CFD struggle with the computational complexity of processinghigh-resolution 3D data. We propose Factorized Implicit Global Convolution(FIGConv), a novel architecture that efficiently solves CFD problems for verylarge 3D meshes with arbitrary input and output geometries. FIGConv achievesquadratic complexity $O(N^2)$, a significant improvement over existing 3Dneural CFD models that require cubic complexity $O(N^3)$. Our approach combinesFactorized Implicit Grids to approximate high-resolution domains, efficientglobal convolutions through 2D reparameterization, and a U-shaped architecturefor effective information gathering and integration. We validate our approachon the industry-standard Ahmed body dataset and the large-scale DrivAerNetdataset. In DrivAerNet, our model achieves an $R^2$ value of 0.95 for dragprediction, outperforming the previous state-of-the-art by a significantmargin. This represents a 40% improvement in relative mean squared error and a70% improvement in absolute mean squared error over previous methods.</description>
      <author>example@mail.com (Chris Choy, Alexey Kamenev, Jean Kossaifi, Max Rietmann, Jan Kautz, Kamyar Azizzadenesheli)</author>
      <guid isPermaLink="false">2502.04317v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Orthogonal Representation Learning for Estimating Causal Quantities</title>
      <link>http://arxiv.org/abs/2502.04274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了OR-learners，一种用于估计因果量的新型Neyman正交学习器类。&lt;h4&gt;背景&lt;/h4&gt;目前的表示学习方法虽然支持端到端学习，但缺乏Neyman正交学习者的理论性质（如双重稳健性和准最优效率）。这些方法还常使用额外约束，可能导致不一致估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的因果量表示层定义的Neyman正交学习器类，称为OR-learners。&lt;h4&gt;方法&lt;/h4&gt;OR-learners允许基于任何已学得表示的一致因果量估计，并提供了包括双重稳健性和准最优效率在内的理论优势。&lt;h4&gt;主要发现&lt;/h4&gt;在多个实验中显示，在一定规律条件下，OR-learners优于现有表示学习方法并达到业界领先性能。&lt;h4&gt;结论&lt;/h4&gt;据作者所知，他们的OR-learners是首个提供表示学习方法和Neyman正交学习者统一框架的工作。&lt;h4&gt;翻译&lt;/h4&gt;表示学习被广泛用于从观测数据估计因果量（例如条件平均处理效应）。虽然现有表示学习方法的好处是可以进行端到端学习，但它们不具有如双重稳健性和准最优效率等Neyman-orthogonal学习者的有利理论性质。此外，这些表示学习方法常常使用额外约束（如平衡），甚至可能导致不一致估计。在本文中，我们提出了一类新的Neyman正交学习器用于定义在表示层的因果量，称为OR-learners。我们的OR-learners具有几个实际优势：它们允许基于任何已学得表示的一致因果量估计，并提供了包括双重稳健性和准最优效率在内的理论性质。在多个实验中，在一定规律条件下，我们展示了OR-learners改进了现有的表示学习方法并达到业界领先性能。据作者所知，我们的OR-learners是首个提供表示学习方法和Neyman正交学习者统一框架的工作用于因果量估计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning is widely used for estimating causal quantities(e.g., the conditional average treatment effect) from observational data. Whileexisting representation learning methods have the benefit of allowing forend-to-end learning, they do not have favorable theoretical properties ofNeyman-orthogonal learners, such as double robustness and quasi-oracleefficiency. Also, such representation learning methods often employ additionalconstraints, like balancing, which may even lead to inconsistent estimation. Inthis paper, we propose a novel class of Neyman-orthogonal learners for causalquantities defined at the representation level, which we call OR-learners. OurOR-learners have several practical advantages: they allow for consistentestimation of causal quantities based on any learned representation, whileoffering favorable theoretical properties including double robustness andquasi-oracle efficiency. In multiple experiments, we show that, under certainregularity conditions, our OR-learners improve existing representation learningmethods and achieve state-of-the-art performance. To the best of our knowledge,our OR-learners are the first work to offer a unified framework ofrepresentation learning methods and Neyman-orthogonal learners for causalquantities estimation.</description>
      <author>example@mail.com (Valentyn Melnychuk, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel)</author>
      <guid isPermaLink="false">2502.04274v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>ICGNN: Graph Neural Network Enabled Scalable Beamforming for MISO Interference Channels</title>
      <link>http://arxiv.org/abs/2502.03936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了图神经网络（GNN）在干扰信道中的波束成形设计。提出了一种模型，称为干扰信道GNN (ICGNN)，以解决服务质量约束下的能量效率最大化问题。&lt;h4&gt;背景&lt;/h4&gt;研究集中在利用GNN优化无线通信系统中波束成形的挑战，特别是在存在多个传输接收对的情况下处理复杂的多用户和干扰环境。&lt;h4&gt;目的&lt;/h4&gt;目的是设计一种新的基于图神经网络的方法（ICGNN），用于在受限服务质量条件下提高能量效率。&lt;h4&gt;方法&lt;/h4&gt;{'模型结构': 'ICGNN是一个两阶段模型，其中波束成形向量的方向和功率部分分别学习但联合训练。通过独立于传输接收对数量的特征维度来实现可扩展性。', '性能提升措施': ['混合最大比率传输与零强迫方案', '特征增强模块统一两种类型的链接', '子图表示提高消息传递效率', '多头注意力机制和残差连接促进特征提取'], '分布式实施': '介绍了一种空中分布式的ICGNN实现。', '评估方法': '通过消融研究验证关键组件的有效性，数值结果展示了ICGNN在平均推理时间小于0.1毫秒的情况下接近最优性能的能力。使用有限的微调成本进行迁移学习以增强未知问题规模下的可扩展性。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能表现': '通过实验表明，所提出的模型能够实现接近最优的能量效率，并且具有快速的推理能力。', '分布式实施效果': '集中式和分布式ICGNN实施方案的效果均被评估并展示了良好的结果。', '可扩展性': '使用迁移学习技术提高了模型在未知传输接收对数量下的性能表现。'}&lt;h4&gt;结论&lt;/h4&gt;ICGNN为解决干扰信道中波束成形设计问题提供了一种有效且高效的解决方案，展现了其出色的性能和广泛的适用性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了用于干扰信道的图神经网络（GNN）支持的波束形成设计。我们提出了一种称为干扰通道GNN (ICGNN) 的模型来解决服务质量约束下的能量效率最大化问题。该ICGNN是两阶段的，其中通过无监督学习分别学习波束成形向量的方向和功率部分但联合训练。通过将特征维度与传输接收对的数量独立化，使得ICGNN在面对不同数量的传输接收对时具有可扩展性。此外，为了提高ICGNN的表现，混合最大比率传输与零强迫方案减少了输出端口数目；特征增强模块统一了两种类型的链接为一种类型；子图表示提高了消息传递效率；多头注意力机制和残差连接促进了特征提取。此外，本文还提出了空中分布式实施的ICGNN。消融研究验证了ICGNN中关键组件的有效性。数值结果展示了ICGNN在平均推理时间小于0.1毫秒的情况下实现接近最优性能的能力。通过迁移学习及有限的成本微调增强了ICGNN对于未知问题规模下的可扩展性。集中式和分布式实施的ICGNN的结果均被呈现出来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the graph neural network (GNN)-enabled beamformingdesign for interference channels. We propose a model termed interferencechannel GNN (ICGNN) to solve a quality-of-service constrained energy efficiencymaximization problem. The ICGNN is two-stage, where the direction and powerparts of beamforming vectors are learned separately but trained jointly viaunsupervised learning. By formulating the dimensionality of featuresindependent of the transceiver pairs, the ICGNN is scalable with the number oftransceiver pairs. Besides, to improve the performance of the ICGNN, the hybridmaximum ratio transmission and zero-forcing scheme reduces the output ports,the feature enhancement module unifies the two types of links into one type,the subgraph representation enhances the message passing efficiency, and themulti-head attention and residual connection facilitate the feature extracting.Furthermore, we present the over-the-air distributed implementation of theICGNN. Ablation studies validate the effectiveness of key components in theICGNN. Numerical results also demonstrate the capability of ICGNN in achievingnear-optimal performance with an average inference time less than 0.1 ms. Thescalability of ICGNN for unseen problem sizes is evaluated and enhanced bytransfer learning with limited fine-tuning cost. The results of the centralizedand distributed implementations of ICGNN are illustrated.</description>
      <author>example@mail.com (Changpeng He, Yang Lu, Bo Ai, Octavia A. Dobre, Zhiguo Ding, Dusit Niyato)</author>
      <guid isPermaLink="false">2502.03936v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Consistency of augmentation graph and network approximability in contrastive learning</title>
      <link>http://arxiv.org/abs/2502.04312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;对比学习利用数据增强来开发特征表示，并不依赖于大型标注数据集。然而，尽管在实践中取得成功，其理论基础尚不完备。&lt;h4&gt;背景&lt;/h4&gt;对比学习的理论基础尚未完全建立，特别是在神经网络可近似性方面的假设（关于最优谱对比损失解）仍未得到充分解决。&lt;h4&gt;目的&lt;/h4&gt;通过分析增强图拉普拉斯算子的逐点和谱一致性来克服这些限制，并在特定条件下证明增强数据集大小增加时，增强图拉普拉斯算子收敛于自然数据流形上的加权拉普拉斯-贝尔特拉米算子。&lt;h4&gt;方法&lt;/h4&gt;研究了数据生成条件和图连通性对一致性的贡献，以及如何通过分析来建立神经网络可近似性框架。&lt;h4&gt;主要发现&lt;/h4&gt;在特定条件下证明了增强图拉普拉斯算子的一致性和收敛性，并由此建立了神经网络可近似性理论框架。&lt;h4&gt;结论&lt;/h4&gt;这些一致性结果确保图拉普拉斯谱能有效地捕捉流形几何，为解决当前范式下的实现假设问题提供了坚实的理论基础。&lt;h4&gt;翻译&lt;/h4&gt;对比学习通过利用数据增强技术来构建特征表示而不依赖大规模标注数据集。尽管在实际应用中取得了成功，但其背后的理论支撑仍然不完善，特别是关于最优谱对比损失解的神经网络可近似性假设。本文通过研究增强图拉普拉斯算子的逐点和谱一致性，解决了这些问题，并证明了随着增大数据集规模的增长，该图拉普拉斯算子会收敛于自然数据流形上的加权拉普拉斯-贝尔特拉米算子。这些发现为理解图谱如何有效捕捉到流形结构提供了理论依据，并直接回答了当前范式下的实现假设问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning leverages data augmentation to develop featurerepresentation without relying on large labeled datasets. However, despite itsempirical success, the theoretical foundations of contrastive learning remainincomplete, with many essential guarantees left unaddressed, particularly therealizability assumption concerning neural approximability of an optimalspectral contrastive loss solution. In this work, we overcome these limitationsby analyzing the pointwise and spectral consistency of the augmentation graphLaplacian. We establish that, under specific conditions for data generation andgraph connectivity, as the augmented dataset size increases, the augmentationgraph Laplacian converges to a weighted Laplace-Beltrami operator on thenatural data manifold. These consistency results ensure that the graphLaplacian spectrum effectively captures the manifold geometry. Consequently,they give way to a robust framework for establishing neural approximability,directly resolving the realizability assumption in a current paradigm.</description>
      <author>example@mail.com (Chenghui Li, A. Martina Neuman)</author>
      <guid isPermaLink="false">2502.04312v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features</title>
      <link>http://arxiv.org/abs/2502.04320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ConceptAttention的新方法，该方法利用多模态扩散变压器（DiT）注意力层的表达能力生成高质量的热图，以精确地定位图像中的文本概念。&lt;h4&gt;背景&lt;/h4&gt;研究了富有多模态特性的Diffusion Transformer模型是否具有独特的属性来增强其可解释性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过重新利用DiT注意层参数来产生高度上下文化的概念嵌入，并发现直接在DiT注意力层的输出空间中执行线性投影可以生成比常用的交叉注意机制更清晰的热图。&lt;h4&gt;方法&lt;/h4&gt;ConceptAttention不需额外训练，而是复用了已有的DiT注意力层参数来生成高质量的局部关注图。&lt;h4&gt;主要发现&lt;/h4&gt;ConceptAttention不仅在无监督图像分割基准测试上表现出色，在ImageNet-Segmentation数据集和PascalVOC单类子集中也超越了其他11种零样本可解释性方法。此外，研究还证明多模态DiT模型（如Flux）的表示能力可以很好地迁移到视觉任务中，并且甚至优于像CLIP这样的多模态基础模型。&lt;h4&gt;结论&lt;/h4&gt;通过ConceptAttention，首次提供了证据表明多模态DiT模型的表征具有高度可转移性，能够为诸如图像分割之类的视觉任务提供优越性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已经过中文解释，无须额外翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Do the rich representations of multi-modal diffusion transformers (DiTs)exhibit unique properties that enhance their interpretability? We introduceConceptAttention, a novel method that leverages the expressive power of DiTattention layers to generate high-quality saliency maps that precisely locatetextual concepts within images. Without requiring additional training,ConceptAttention repurposes the parameters of DiT attention layers to producehighly contextualized concept embeddings, contributing the major discovery thatperforming linear projections in the output space of DiT attention layersyields significantly sharper saliency maps compared to commonly usedcross-attention mechanisms. Remarkably, ConceptAttention even achievesstate-of-the-art performance on zero-shot image segmentation benchmarks,outperforming 11 other zero-shot interpretability methods on theImageNet-Segmentation dataset and on a single-class subset of PascalVOC. Ourwork contributes the first evidence that the representations of multi-modal DiTmodels like Flux are highly transferable to vision tasks like segmentation,even outperforming multi-modal foundation models like CLIP.</description>
      <author>example@mail.com (Alec Helbling, Tuna Han Salih Meral, Ben Hoover, Pinar Yanardag, Duen Horng Chau)</author>
      <guid isPermaLink="false">2502.04320v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Contextual Manifold Alignment for Structuring Latent Representations in Large Language Models</title>
      <link>http://arxiv.org/abs/2502.03766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种层次对齐的方法，用于重构语言模型中的token嵌入表示而不改变核心权重参数。这种方法能够提高稀有词的检索效率、对抗鲁棒性和长距离依赖关系处理，并且在计算效率和表征质量之间实现了良好的平衡。&lt;h4&gt;背景&lt;/h4&gt;传统的嵌入优化方法通常通过修改参数来实现，这可能会引入额外的计算开销。为了改善语言模型的表现，需要一种更有效的方法来组织潜在token表示。&lt;h4&gt;目的&lt;/h4&gt;提出了一种层次对齐的方法，用于重构token嵌入而不需要改变核心模型权重，以提高模型在稳定性、泛化能力和上下文一致性方面的性能。&lt;h4&gt;方法&lt;/h4&gt;通过引入层次结构的对齐过程，可以调整token之间的关系分布而不影响预训练的语义关联。这种方法能够在不增加计算开销的前提下改进表示质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明该方法能够提高稀有词检索、对抗鲁棒性和长距离依赖跟踪的能力，并且在与传统微调和嵌入扰动方法对比时，展示了计算效率和表征质量的双重优势。&lt;h4&gt;结论&lt;/h4&gt;层次结构化的方法能够在不牺牲模型效率的情况下有效改进潜在空间组织中的不一致性问题，为结构化表示学习提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;潜在token表示的组织在确定语言模型的稳定性、泛化能力和上下文一致性方面发挥着关键作用。但是传统嵌入优化方法往往依赖于引入额外计算开销的参数修改。本文介绍了一种层次对齐的方法，用于重构token嵌入而不需要改变核心模型权重，并且实验表明这种方法在稀有词检索、对抗鲁棒性和长距离依赖跟踪等方面有所改进，同时通过详细的计算评估确认该过程几乎不会增加推理负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The organization of latent token representations plays a crucial role indetermining the stability, generalization, and contextual consistency oflanguage models, yet conventional approaches to embedding refinement often relyon parameter modifications that introduce additional computational overhead. Ahierarchical alignment method was introduced to restructure token embeddingswithout altering core model weights, ensuring that representationaldistributions maintained coherence across different linguistic contexts.Experimental evaluations demonstrated improvements in rare token retrieval,adversarial robustness, and long-range dependency tracking, highlighting theadvantages of hierarchical structuring in mitigating inconsistencies in latentspace organization. The comparative analysis against conventional fine-tuningand embedding perturbation methods revealed that hierarchical restructuringmaintained computational efficiency while achieving measurable gains inrepresentation quality. Structural refinements introduced through the alignmentprocess resulted in improved contextual stability across varied linguistictasks, reducing inconsistencies in token proximity relationships and enhancinginterpretability in language generation. A detailed computational assessmentconfirmed that the realignment process introduced minimal inference overhead,ensuring that representational improvements did not compromise modelefficiency. The findings reinforced the broader significance of structuredrepresentation learning, illustrating that hierarchical embedding modificationscould serve as an effective strategy for refining latent space distributionswhile preserving pre-learned semantic associations.</description>
      <author>example@mail.com (Meiquan Dong, Haoran Liu, Yan Huang, Zixuan Feng, Jianhong Tang, Ruoxi Wang)</author>
      <guid isPermaLink="false">2502.03766v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Multi-fidelity emulator for large-scale 21 cm lightcone images: a few-shot transfer learning approach with generative adversarial network</title>
      <link>http://arxiv.org/abs/2502.04246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 16 figures. Comments welcome. Text overlap with  arXiv:2307.04976&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了利用少样本迁移学习技术训练生成对抗网络（GAN），以实现从小规模模拟数据到大规模21厘米光锥图像的高效仿真。&lt;h4&gt;背景&lt;/h4&gt;随着天文实验和调查的规模不断扩大，传统的大型数值模拟方法变得过于昂贵。机器学习技术产生的模拟器成为了一种替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种多保真度仿真的方法来生成高精度、大规模21厘米光锥图像。&lt;h4&gt;方法&lt;/h4&gt;首先利用大量小规模模拟数据训练GAN，然后使用少量大规模模拟数据进行迁移学习以实现大尺度的仿真。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在大多数情况下，由转移学习后的GAN生成的小尺度光照图像可以达到百分比级别的精度；而大尺度误差仅轻微增加到少数几个百分点。&lt;h4&gt;结论&lt;/h4&gt;该技术显著节省了训练GAN所需的计算资源，并且能够以经济的方式模拟出高保真度、传统上过于昂贵的图像。&lt;h4&gt;翻译&lt;/h4&gt;基于机器学习方法生成仿真的模拟器已经出现，用以高效地产生匹配未来实验大规模观测的数据。然而，随着模拟规模增加到数百兆秒差距时，这种高度保真的仿真模型变得计算成本高昂。本文提出了一种多保真度的大规模21厘米光锥图像仿真技术，并通过将迁移学习应用于从小尺度向大尺度的GAN训练来实现这一目标。首先利用大量的小尺度数据训练一个GAN模拟器，然后仅使用少量大规模数据进行转移学习以生成大规模的21厘米光锥图像。实验结果显示，在代表性的统计指标（包括全局21厘米亮度温度历史、二维功率谱和散射变换系数）上，该方法可以实现较高的精度，并且在大尺度上的误差相对较小。这项技术能够显著减少计算资源消耗，并允许以经济的方式生成高保真度的图像，而传统的方法在这方面是不可行的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emulators using machine learning techniques have emerged to efficientlygenerate mock data matching the large survey volume for upcoming experiments,as an alternative approach to large-scale numerical simulations. However,high-fidelity emulators have become computationally expensive as the simulationvolume grows to hundreds of megaparsecs. Here, we present a {\itmulti-fidelity} emulation of large-scale 21~cm lightcone images from the epochof reionization, which is realized by applying the {\it few-shot transferlearning} to training generative adversarial networks (GAN) from small-scale tolarge-scale simulations. Specifically, a GAN emulator is first trained with ahuge number of small-scale simulations, and then transfer-learned with only alimited number of large-scale simulations, to emulate large-scale 21~cmlightcone images. We test the precision of our transfer-learned GAN emulator interms of representative statistics including global 21~cm brightnesstemperature history, 2D power spectrum, and scattering transform coefficients.We demonstrate that the lightcone images generated by the transfer-learned GANemulator can reach the percentage level precision in most cases on smallscales, and the error on large scales only increases mildly to the level of afew tens of per cent. Nevertheless, our multi-fidelity emulation techniquesaves a significant portion of computational resources that are mostly consumedfor generating training samples for GAN. On estimate, the computationalresource by training GAN completely with large-scale simulations would be oneto two orders of magnitude larger than using our multi-fidelity technique. Thisimplies that our technique allows for emulating high-fidelity, traditionallycomputationally prohibitive, images in an economic manner.</description>
      <author>example@mail.com (Kangning Diao, Yi Mao)</author>
      <guid isPermaLink="false">2502.04246v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks</title>
      <link>http://arxiv.org/abs/2502.04224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;XGNNCert是首个针对图结构扰动攻击具有鲁棒性的可证明的图神经网络解释方法。&lt;h4&gt;背景&lt;/h4&gt;尽管对图神经网络（GNN）的解释性（XGNN）的研究日益增多，但是其在面对攻击时的稳健性尚未得到充分探索。研究者发现，对手可以通过轻微改变图结构使XGNN的结果发生巨大变化。&lt;h4&gt;目的&lt;/h4&gt;首次研究XGNN在图扰动攻击下的鲁棒性，并提出一种新的可证明安全的方法（XGNNCert）。&lt;h4&gt;方法&lt;/h4&gt;提出了XGNNCert方法，在保证不干扰原始的GNN预测的前提下，确保在最差情况下图结构被改变后得到的解释结果依然接近于未受攻击时的结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，通过限制扰动边的数量，XGNNCert能够在多种图数据集和GNN解释器中有效工作。&lt;h4&gt;结论&lt;/h4&gt;研究证明了XGNN在面对图结构扰动时的安全性问题，并提出了一种具有稳健性的解决方案，对安全性和安全性至关重要的应用尤其重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explaining Graph Neural Network (XGNN) has gained growing attention tofacilitate the trust of using GNNs, which is the mainstream method to learngraph data. Despite their growing attention, Existing XGNNs focus on improvingthe explanation performance, and its robustness under attacks is largelyunexplored. We noticed that an adversary can slightly perturb the graphstructure such that the explanation result of XGNNs is largely changed. Suchvulnerability of XGNNs could cause serious issues particularly insafety/security-critical applications. In this paper, we take the first step tostudy the robustness of XGNN against graph perturbation attacks, and proposeXGNNCert, the first provably robust XGNN. Particularly, our XGNNCert canprovably ensure the explanation result for a graph under the worst-case graphperturbation attack is close to that without the attack, while not affectingthe GNN prediction, when the number of perturbed edges is bounded. Evaluationresults on multiple graph datasets and GNN explainers show the effectiveness ofXGNNCert.</description>
      <author>example@mail.com (Jiate Li, Meng Pang, Yun Dong, Jinyuan Jia, Binghui Wang)</author>
      <guid isPermaLink="false">2502.04224v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Margin Contrastive Learning for Ambiguity-aware 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2502.04111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种用于三维点云语义分割的自适应边缘对比学习方法AMContrast3D。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数方法采用等同惩罚的目标函数，忽视了由过渡区域引起的每个点的模糊性和较少区分性的特征。然而，高模糊度的点即使是人类也难以分辨，其手动标注的标签可靠性较低，对这些点施加严格约束会导致次优模型。&lt;h4&gt;目的&lt;/h4&gt;设计基于个体点模糊程度的自适应目标函数，以确保低模糊性点的准确性的同时允许高模糊性点出错。&lt;h4&gt;方法&lt;/h4&gt;首先通过位置嵌入估计模糊度；其次开发了一种边缘生成器来调整对比特征嵌入的决策边界，随着模糊度增加，边缘变得狭窄，并且对于极高模糊度的点会出现负边距。&lt;h4&gt;主要发现&lt;/h4&gt;在大规模数据集S3DIS和ScanNet上的实验结果表明，所提出的方法优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入自适应目标函数并基于模糊度调整决策边界来提高三维点云语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了用于三维点云语义分割的一种自适应边缘对比学习方法AMContrast3D。大多数现有的方法使用等同惩罚的目标函数，这忽视了来自过渡区域的每个点的模糊性和较少区分性的特征。然而，高模糊度的点即使是人类也难以分辨，其手动标注的标签可靠性较低，对这些点施加严格约束会导致次优模型。为了应对这一问题，我们设计了一种基于个体点模糊程度的自适应目标函数，旨在确保低模糊性点的准确性的同时允许高模糊性点出错。具体来说，我们首先通过位置嵌入估计模糊度；其次开发了一种边缘生成器来调整对比特征嵌入的决策边界，随着模糊度增加，边缘变得狭窄，并且对于极高模糊度的点会出现负边距。在大规模数据集S3DIS和ScanNet上的实验结果表明，所提出的方法优于现有最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICME57554.2024.10688017&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose an adaptive margin contrastive learning method for3D point cloud semantic segmentation, namely AMContrast3D. Most existingmethods use equally penalized objectives, which ignore per-point ambiguitiesand less discriminated features stemming from transition regions. However, ashighly ambiguous points may be indistinguishable even for humans, theirmanually annotated labels are less reliable, and hard constraints over thesepoints would lead to sub-optimal models. To address this, we design adaptiveobjectives for individual points based on their ambiguity levels, aiming toensure the correctness of low-ambiguity points while allowing mistakes forhigh-ambiguity points. Specifically, we first estimate ambiguities based onposition embeddings. Then, we develop a margin generator to shift decisionboundaries for contrastive feature embeddings, so margins are narrowed due toincreasing ambiguities with even negative margins for extremely high-ambiguitypoints. Experimental results on large-scale datasets, S3DIS and ScanNet,demonstrate that our method outperforms state-of-the-art methods.</description>
      <author>example@mail.com (Yang Chen, Yueqi Duan, Runzhong Zhang, Yap-Peng Tan)</author>
      <guid isPermaLink="false">2502.04111v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cramér-Rao Bound</title>
      <link>http://arxiv.org/abs/2502.04242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种理论框架，用于确定多源迁移学习中每个源任务应使用的最优样本数量，以提高训练效率和模型性能。&lt;h4&gt;背景&lt;/h4&gt;在处理真实世界监督学习中的数据稀缺问题时，利用多个源任务的多源迁移学习提供了一个有效的解决方案。然而，现有的研究通常使用所有可用的源样本进行训练，这限制了训练效率并可能导致次优结果。&lt;h4&gt;目的&lt;/h4&gt;为了优化源样本的数量，从而提高训练效率和模型性能，提出了一种理论框架，并开发了一种架构无关且数据高效的算法OTQMS来实现这一目标。&lt;h4&gt;方法&lt;/h4&gt;引入了一个与交叉熵损失相一致的泛化误差度量，并基于Cramér-Rao界最小化该度量以确定每个源任务的最佳迁移样本数量。同时，设计了OTQMS算法来实施理论结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验研究表明，在不同的架构和两个真实世界基准数据集上，所提出的算法在准确性和数据效率方面均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过优化多源迁移学习中的源样本数量，可以显著提高模型的训练效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;多源迁移学习提供了一种有效解决现实世界监督学习中数据稀缺问题的方法。为了解决当前实践中过度依赖所有可用源样本的问题，研究者提出了一个新的理论框架以及一种名为OTQMS的新算法来确定每个任务的最佳样本数量，并通过实验展示了该方法的有效性与高效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-source transfer learning provides an effective solution to datascarcity in real-world supervised learning scenarios by leveraging multiplesource tasks. In this field, existing works typically use all available samplesfrom sources in training, which constrains their training efficiency and maylead to suboptimal results. To address this, we propose a theoretical frameworkthat answers the question: what is the optimal quantity of source samplesneeded from each source task to jointly train the target model? Specifically,we introduce a generalization error measure that aligns with cross-entropyloss, and minimize it based on the Cram\'er-Rao Bound to determine the optimaltransfer quantity for each source task. Additionally, we develop anarchitecture-agnostic and data-efficient algorithm OTQMS to implement ourtheoretical results for training deep multi-source transfer learning models.Experimental studies on diverse architectures and two real-world benchmarkdatasets show that our proposed algorithm significantly outperformsstate-of-the-art approaches in both accuracy and data efficiency. The code andsupplementary materials are available inhttps://anonymous.4open.science/r/Materials.</description>
      <author>example@mail.com (Qingyue Zhang, Haohao Fu, Guanbo Huang, Yaoyuan Liang, Chang Chu, Tianren Peng, Yanru Wu, Qi Li, Yang Li, Shao-Lun Huang)</author>
      <guid isPermaLink="false">2502.04242v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Human Mesh Recovery with Vision-Language Feedback</title>
      <link>http://arxiv.org/abs/2502.03836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合大型视觉语言模型(VLM)生成的身体部位描述来改进单目人体网格恢复的方法，通过将该任务视为分布适应问题，并利用扩散框架在考虑2D观察和文本描述的同时优化初始参数。&lt;h4&gt;背景&lt;/h4&gt;人形网格恢复可以通过回归方法或优化方法实现。虽然回归模型能够达到高姿态准确性，但它们难以解决模态对齐问题；而基于优化的方法容易陷入局部极小值且存在深度模糊问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合语言描述作为隐含约束来增强3D感知并限制优化空间的新方法。&lt;h4&gt;方法&lt;/h4&gt;该研究通过大型视觉语言模型生成身体部位的交互式描述，将其视为分布适应任务。具体来说，他们训练了一个文本编码器和姿态VQ-VAE，以便在共享潜在空间中将文本与人体姿势对齐，并使用扩散框架根据2D观察和文本描述来优化初始参数。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法能够产生具有准确3D感知和图像一致性的姿态。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了如何利用大型视觉语言模型生成的交互式身体部位描述，以增强单目人体网格恢复技术，并且计划将代码公开发布。&lt;h4&gt;翻译&lt;/h4&gt;人形网格恢复可以采用基于回归的方法或优化方法。虽然基于回归的方法能够实现高姿态准确性，但它们在模态对齐方面存在问题；而基于优化的方法尽管能将3D模型与2D观察对齐，却容易陷入局部极小值并受深度模糊影响。这项研究利用大型视觉语言模型生成身体部位描述作为隐含约束来增强3D感知，并限制了优化空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human mesh recovery can be approached using either regression-based oroptimization-based methods. Regression models achieve high pose accuracy butstruggle with model-to-image alignment due to the lack of explicit 2D-3Dcorrespondences. In contrast, optimization-based methods align 3D models to 2Dobservations but are prone to local minima and depth ambiguity. In this work,we leverage large vision-language models (VLMs) to generate interactive bodypart descriptions, which serve as implicit constraints to enhance 3D perceptionand limit the optimization space. Specifically, we formulate monocular humanmesh recovery as a distribution adaptation task by integrating both 2Dobservations and language descriptions. To bridge the gap between text and 3Dpose signals, we first train a text encoder and a pose VQ-VAE, aligning textsto body poses in a shared latent space using contrastive learning.Subsequently, we employ a diffusion-based framework to refine the initialparameters guided by gradients derived from both 2D observations and textdescriptions. Finally, the model can produce poses with accurate 3D perceptionand image consistency. Experimental results on multiple benchmarks validate itseffectiveness. The code will be made publicly available.</description>
      <author>example@mail.com (Chongyang Xu, Buzhen Huang, Chengfang Zhang, Ziliang Feng, Yangang Wang)</author>
      <guid isPermaLink="false">2502.03836v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>sshELF: Single-Shot Hierarchical Extrapolation of Latent Features for 3D Reconstruction from Sparse-Views</title>
      <link>http://arxiv.org/abs/2502.04318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Joint first authorship&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;sshELF是一种快速、单次拍摄的管道，用于通过层次化的潜在特征外推来重建稀疏视角下的三维场景。&lt;h4&gt;背景&lt;/h4&gt;由于视图重叠度低，从稀疏的向外看的角度重建户外场景存在挑战。先前的方法常常缺乏跨场景的理解，并且它们基于原始元素的形式化方法依赖于局部特征进行补充以弥补缺失的整体上下文，导致未观察部分出现模糊。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的单次拍摄管道sshELF，旨在解决稀疏视角下三维场景重建中的问题。&lt;h4&gt;方法&lt;/h4&gt;{'(1)': '学习跨场景的先验知识来生成中间虚拟视图以外推到未观测区域。', '(2)': '提供两阶段网络设计，将虚拟视图生成和3D原始解码分离，以实现高效的训练和模块化模型设计。', '(3)': '整合预训练的基础模型进行潜在特征和纹理的联合推理，增强场景理解和泛化能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;sshELF可以从六个稀疏输入视图中重建360度场景，并在合成数据集和真实世界数据集中取得竞争力的结果。&lt;h4&gt;结论&lt;/h4&gt;sshELF能够忠实于重建被遮挡区域、支持实时渲染并提供丰富的潜在特征供下游应用使用。计划公开源代码。&lt;h4&gt;翻译&lt;/h4&gt;从稀疏的向外看的角度重建户外场景存在挑战，由于视图重叠度低导致缺少全局上下文信息。先前的方法通常依赖局部特征来补偿缺失的信息，但会导致未观察部分模糊不清。sshELF通过层次化的潜在特征外推解决了这些问题，并且可以从六个输入视角中实现360度场景的重建，在合成数据集和真实世界数据集中表现良好，提供丰富的潜在特征供下游应用使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing unbounded outdoor scenes from sparse outward-facing viewsposes significant challenges due to minimal view overlap. Previous methodsoften lack cross-scene understanding and their primitive-centric formulationsoverload local features to compensate for missing global context, resulting inblurriness in unseen parts of the scene. We propose sshELF, a fast, single-shotpipeline for sparse-view 3D scene reconstruction via hierarchal extrapolationof latent features. Our key insights is that disentangling informationextrapolation from primitive decoding allows efficient transfer of structuralpatterns across training scenes. Our method: (1) learns cross-scene priors togenerate intermediate virtual views to extrapolate to unobserved regions, (2)offers a two-stage network design separating virtual view generation from 3Dprimitive decoding for efficient training and modular model design, and (3)integrates a pre-trained foundation model for joint inference of latentfeatures and texture, improving scene understanding and generalization. sshELFcan reconstruct 360 degree scenes from six sparse input views and achievescompetitive results on synthetic and real-world datasets. We find that sshELFfaithfully reconstructs occluded regions, supports real-time rendering, andprovides rich latent features for downstream applications. The code will bereleased.</description>
      <author>example@mail.com (Eyvaz Najafli, Marius Kästingschäfer, Sebastian Bernhard, Thomas Brox, Andreas Geiger)</author>
      <guid isPermaLink="false">2502.04318v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>SWIPTNet: A Unified Deep Learning Framework for SWIPT based on GNN and Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.03928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了基于深度学习的SWIPT（同时无线信息和能量传输）方法，并提出了一个统一的图神经网络模型来解决QoS约束下的最大总速率问题。&lt;h4&gt;背景&lt;/h4&gt;无线通信系统中，同时实现信息传输和能量收集的需求日益增加。通过使用SWIPT技术可以有效应对这一需求。&lt;h4&gt;目的&lt;/h4&gt;探讨基于深度学习的方法，以优化PS（功率分割）接收器和TS（时间切换）接收器在QoS约束下的总速率最大化问题。&lt;h4&gt;方法&lt;/h4&gt;{'模型构建': '提出了一种名为SWIPTNet的图神经网络模型来解决上述问题。', '改进措施': ['单类型输出法以减少学习复杂度并简化满足QoS条件的过程', '使用拉普拉斯变换增强输入特征，使其包含结构信息', '采用多头注意力机制和层连接技术以提高特征提取能力'], '转移学习应用': '实现了PS和TS接收器之间的SWIPTNet的迁移学习。', '验证方法': '通过消融实验展示关键组件的有效性，并通过数值结果证明模型的能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;['SWIPTNet能够实现接近最优性能，且推理速度达到毫秒级，比传统优化算法快很多', '转移学习有效提升了收敛速度和表达能力']&lt;h4&gt;结论&lt;/h4&gt;提出的深度学习方法（尤其是SWIPTNet）显著提高了在SWIPT场景下的性能，并为解决类似问题提供了一种新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文译文：本文研究了基于深度学习的方法，用于同时无线信息和能量传输(SWIPT)。针对功率分割(PS)接收器和时间切换(TS)接收器，分别制定了质量服务(QoS)约束下的总速率最大化问题，并通过一个统一的图神经网络(GNN)模型——SWIPT网(SWIPTNet)来解决这些问题。为了提高SWIPTNet的性能，我们首先提出了一种单类型输出方法以减少学习复杂度并简化满足QoS条件的过程，接着利用拉普拉斯变换增强输入特征中的结构信息。此外，我们还采用了多头注意力机制和层连接技术来提升特征提取能力，并且实现了PS和TS接收器之间的SWIPTNet的迁移学习。通过消融实验展示了关键组件的有效性，数值结果也证明了SWIPTNet在实现接近最优性能的同时能够达到毫秒级推理速度，这比传统的优化算法快得多。我们还展示了转移学习的有效性，即快速收敛能力和表达能力提升的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the deep learning based approaches for simultaneouswireless information and power transfer (SWIPT). The quality-of-service (QoS)constrained sum-rate maximization problems are, respectively, formulated forpower-splitting (PS) receivers and time-switching (TS) receivers and solved bya unified graph neural network (GNN) based model termed SWIPT net (SWIPTNet).To improve the performance of SWIPTNet, we first propose a single-type outputmethod to reduce the learning complexity and facilitate the satisfaction of QoSconstraints, and then, utilize the Laplace transform to enhance input featureswith the structural information. Besides, we adopt the multi-head attention andlayer connection to enhance feature extracting. Furthermore, we present theimplementation of transfer learning to the SWIPTNet between PS and TSreceivers. Ablation studies show the effectiveness of key components in theSWIPTNet. Numerical results also demonstrate the capability of SWIPTNet inachieving near-optimal performance with millisecond-level inference speed whichis much faster than the traditional optimization algorithms. We also show theeffectiveness of transfer learning via fast convergence and expressivecapability improvement.</description>
      <author>example@mail.com (Hong Han, Yang Lu, Zihan Song, Ruichen Zhang, Wei Chen, Bo Ai, Dusit Niyato, Dong In Kim)</author>
      <guid isPermaLink="false">2502.03928v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Enabled Fluid Antenna Systems: A Two-Stage Approach</title>
      <link>http://arxiv.org/abs/2502.03922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种无监督学习优化框架来解决流体天线系统中的传输设计挑战。&lt;h4&gt;背景&lt;/h4&gt;流体天线系统（FAS）通过引入天线位置作为新的维度，以应对深度衰落问题。然而，这同时带来了与传输设计相关的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督学习优化方法来改进多用户、多输入单输出（MU-MISO）FAS的性能。&lt;h4&gt;方法&lt;/h4&gt;将总速率和能量效率最大化的问题建模，并利用两阶段图神经网络（GNN）进行求解。第一阶段用于推断天线位置，第二阶段则用于确定波束成形矢量。两个阶段的输出通过无监督损失函数共同输入到训练过程中。&lt;h4&gt;主要发现&lt;/h4&gt;数值结果表明了FAS在性能改进方面的优势以及两阶段GNN在实时和可扩展优化中的效能。此外，这两个阶段可以独立运作。&lt;h4&gt;结论&lt;/h4&gt;该研究成功地开发了一种新的框架来解决流体天线系统中的问题，并展示了其优越的性能表现。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到一种新兴的流体天线系统（FAS）通过引入天线位置作为新的维度，以应对深度衰落问题。为了优化这种新系统，提出了一种无监督学习优化方法，特别是针对多用户、多输入单输出（MU-MISO）FAS中的总速率和能量效率最大化的问题进行建模，并用两阶段图神经网络（GNN）求解。该框架通过数值实验展示了其在性能改进方面的优势及其实时性和可扩展性的优化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An emerging fluid antenna system (FAS) brings a new dimension, i.e., theantenna positions, to deal with the deep fading, but simultaneously introduceschallenges related to the transmit design. This paper proposes an``unsupervised learning to optimize" paradigm to optimize the FAS.Particularly, we formulate the sum-rate and energy efficiency (EE) maximizationproblems for a multiple-user multiple-input single-output (MU-MISO) FAS andsolved by a two-stage graph neural network (GNN) where the first stage and thesecond stage are for the inference of antenna positions and beamformingvectors, respectively. The outputs of the two stages are jointly input into aunsupervised loss function to train the two-stage GNN. The numerical resultsdemonstrates that the advantages of the FAS for performance improvement and thetwo-stage GNN for real-time and scalable optimization. Besides, the two stagescan function separately.</description>
      <author>example@mail.com (Changpeng He, Yang Lu, Wei Chen, Bo Ai, Kai-Kit Wong, Dusit Niyato)</author>
      <guid isPermaLink="false">2502.03922v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>TD3: Tucker Decomposition Based Dataset Distillation Method for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.02854v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by WWW2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Tucker分解的数据蒸馏方法TD3，旨在加速序列推荐系统的训练过程同时保持模型性能。&lt;h4&gt;背景&lt;/h4&gt;在数据驱动的AI时代，推荐系统的研究重点从以模型为中心的方法转向了更注重数据本身的方法。成功的大规模AI模型依赖于大规模数据集，但这也导致了高昂的训练成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据蒸馏方法TD3，在元学习框架内解决序列推荐中用户-物品交互离散且时间相关的挑战，并通过代理目标优化进一步调整特征空间以提高性能匹配和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TD3利用Tucker分解将原始数据提炼为一个完全表达的合成序列摘要，该过程包括四个因素：合成用户的潜在因子、时间动态的潜在因子、共享物品的潜在因子以及连接这些因素的关系核心。此外，还提出了双层优化中的代理目标来对齐在原始数据和合成序列摘要上训练模型所提取出的特征空间。&lt;h4&gt;主要发现&lt;/h4&gt;TD3通过使用RaT-BPTT进行双层优化加速了优化过程，并且解决了长期依赖问题。实验结果表明该设计具有优越性和跨架构泛化性。&lt;h4&gt;结论&lt;/h4&gt;通过代码发布在GitHub上的实验证明，TD3方法在序列推荐任务上表现出色并能有效降低训练成本。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：在数据为中心的人工智能时代，推荐系统的研究焦点从模型为中心的创新转向了以数据为中心的方法。现代AI模型的成功基于大规模的数据集，但这也导致了显著的训练成本。数据蒸馏作为一种关键解决方案应运而生，它能够将大型数据集压缩为更小的集合来加速模型训练同时保持模型性能。然而，将离散且时间相关的用户-物品交互（特别是具有广泛项目集的情况）进行浓缩带来了相当大的挑战。本文介绍了一种基于Tucker分解的数据蒸馏方法TD3，在元学习框架内设计用于序列推荐。TD3从原始数据中提炼出一个完全表达的合成序列摘要。为了有效地减少计算复杂性和提取精细的潜在模式，Tucker分解将摘要解耦为四个因子：合成用户潜在因素、时间动态潜在因素、共享项目潜在因素以及连接这些因素的关系核心。此外，在双层优化中提出了代理目标以对齐从原始数据和合成序列摘要上训练出的模型特征空间，超越了简单的性能匹配方法。在内循环中使用增强技术使学习者能够紧密拟合合成摘要，并确保在外循环中准确更新它。为了加速优化过程并解决长期依赖问题，采用了RaT-BPTT进行双层优化。在多个公共数据集上的实验和分析证实了所提出设计的优越性和跨架构泛化能力。代码可在https://github.com/USTC-StarTeam/TD3上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714613&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of data-centric AI, the focus of recommender systems has shiftedfrom model-centric innovations to data-centric approaches. The success ofmodern AI models is built on large-scale datasets, but this also results insignificant training costs. Dataset distillation has emerged as a key solution,condensing large datasets to accelerate model training while preserving modelperformance. However, condensing discrete and sequentially correlated user-iteminteractions, particularly with extensive item sets, presents considerablechallenges. This paper introduces \textbf{TD3}, a novel \textbf{T}ucker\textbf{D}ecomposition based \textbf{D}ataset \textbf{D}istillation methodwithin a meta-learning framework, designed for sequential recommendation. TD3distills a fully expressive \emph{synthetic sequence summary} from originaldata. To efficiently reduce computational complexity and extract refined latentpatterns, Tucker decomposition decouples the summary into four factors:\emph{synthetic user latent factor}, \emph{temporal dynamics latent factor},\emph{shared item latent factor}, and a \emph{relation core} that models theirinterconnections. Additionally, a surrogate objective in bi-level optimizationis proposed to align feature spaces extracted from models trained on bothoriginal data and synthetic sequence summary beyond the na\"ive performancematching approach. In the \emph{inner-loop}, an augmentation technique allowsthe learner to closely fit the synthetic summary, ensuring an accurate updateof it in the \emph{outer-loop}. To accelerate the optimization process andaddress long dependencies, RaT-BPTT is employed for bi-level optimization.Experiments and analyses on multiple public datasets have confirmed thesuperiority and cross-architecture generalizability of the proposed designs.Codes are released at https://github.com/USTC-StarTeam/TD3.</description>
      <author>example@mail.com (Jiaqing Zhang, Mingjia Yin, Hao Wang, Yawen Li, Yuyang Ye, Xingyu Lou, Junping Du, Enhong Chen)</author>
      <guid isPermaLink="false">2502.02854v2</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Position: Untrained Machine Learning for Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.03876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages,0 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于3D点云数据的异常检测是近年来备受关注的重要研究问题。本文针对仅凭一个样本进行未训练的异常检测的研究课题提供了形式化定义，并讨论了该方法与当前无监督异常检测方法之间的差异。&lt;h4&gt;背景&lt;/h4&gt;在个性化制造等真实制造业中，只收集到单个样本而没有其他标签信息的情况日益增多，这种情况下如何基于单一3D点云样本准确识别异常是一项重要的挑战。&lt;h4&gt;目的&lt;/h4&gt;提供一个基于3D点云数据的未训练异常检测问题的形式化定义，并讨论未训练方法与现有的无监督学习方法的区别。此外，还回顾了该领域的文献并展望未训练深度神经网络在异常检测中的潜力。&lt;h4&gt;方法&lt;/h4&gt;介绍了未训练方法不依赖于任何数据（包括未标记的数据），而是利用关于制造表面和异常的先验知识来实现异常识别，并通过实例展示了这种知识如何应用于未训练机器学习模型中。&lt;h4&gt;主要发现&lt;/h4&gt;基于3D点云的未训练异常检测技术是可行且有潜力的方法，尤其在个性化制造等新兴工业领域具有重要作用。同时指出了该方法与传统无监督学习之间的关键差异：不依赖于任何数据样本。&lt;h4&gt;结论&lt;/h4&gt;本文强调了未训练异常检测模型利用先验知识的重要性，并讨论了深度神经网络在未来可能发挥的作用。&lt;h4&gt;翻译&lt;/h4&gt;基于3D点云的异常检测是一个重要的研究问题，近年来受到了越来越多的关注。完全无监督地仅凭一个样本来进行异常检测是受到制造业（如个性化制造）推动而兴起的一个新兴研究课题，在这种情况下只能收集到一个样本且没有额外标签信息。如何准确识别单个3D点云样本中的异常对于工业应用和机器学习领域来说都是一个关键挑战。本文旨在提供基于3D点云数据的未训练异常检测问题的形式化定义，讨论未训练方法与当前无监督学习方法之间的差异。不同于无监督学习，未训练的方法不依赖任何数据（包括未标记的数据）。相反，它们利用有关制造表面和异常的先验知识。通过实例说明了这些先验知识以及未训练机器学习模型的应用。此外，还提供了基于3D点云数据的未训练异常检测文献综述，并讨论了未来未训练深度神经网络在该领域可能发挥的作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection based on 3D point cloud data is an important researchproblem and receives more and more attention recently. Untrained anomalydetection based on only one sample is an emerging research problem motivated byreal manufacturing industries such as personalized manufacturing that only onesample can be collected without any additional labels. How to accuratelyidentify anomalies based on one 3D point cloud sample is a critical challengein both industrial applications and the field of machine learning. This paperaims to provide a formal definition of untrained anomaly detection problembased on 3D point cloud data, discuss the differences between untrained anomalydetection and current unsupervised anomaly detection methods. Unlikeunsupervised learning, untrained methods do not rely on any data, includingunlabeled data. Instead, they leverage prior knowledge about the manufacturingsurfaces and anomalies. Examples are used to illustrate these prior knowledgeand untrained machine learning model. Afterwards, literature review onuntrained anomaly detection based on 3D point cloud data is also provided, andthe potential of untrained deep neural networks for anomaly detection is alsodiscussed as outlooks.</description>
      <author>example@mail.com (Juan Du, Dongheng Chen, Hao Yan)</author>
      <guid isPermaLink="false">2502.03876v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Randomized Experiments Using Foundation Models</title>
      <link>http://arxiv.org/abs/2502.04262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合多种基础模型预测与实验数据的新颖方法，以保持有效的统计推断同时提高统计精度。&lt;h4&gt;背景&lt;/h4&gt;随机实验是评估干预效果的首选方式，但成本高昂且往往产生不确定性的估计结果。相比之下，在硅实验利用基础模型提供了更具成本效益的选择，并有可能达到更高的统计精确度。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合多模型预测与实际实验数据的方法，确保有效的统计推断同时提高精度。&lt;h4&gt;方法&lt;/h4&gt;通过整合多个基础模型的预测并加入实验数据来构建一个新估计器，该估计器具有渐近一致性且在大样本情况下服从正态分布，其渐近方差不会大于仅基于实验数据的标准估计器。这种统计特性即使模型预测存在任意偏误也依然成立。&lt;h4&gt;主要发现&lt;/h4&gt;实证研究表明，所提出的估计方法显著提高了精度水平，相当于降低了多达20%的样本来达到与标准实验估计器相同的精确度。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了结合基础模型预测和实际数据可以有效提高统计精度，并为更高效、成本更低的研究方案开辟了一条新路径。&lt;h4&gt;翻译&lt;/h4&gt;随机化试验是评估干预措施效果的首选方法，但它们的成本高且通常会产生不确定性较大的估计结果。另一方面，在硅实验利用基础模型提供了更具成本效益的选择，有可能达到更高的统计精确度。然而，这种好处伴随着一个显著的风险：如果模型无法准确预测干预措施的实验响应，则统计推断将无效。本文提出了一种结合多模型预测和实验数据的新方法，同时保持有效的统计推断。我们的估计器是一致且渐近正态分布的，其渐近方差不大于仅基于实验数据的标准估计器。实证研究结果表明，相对于仅依赖实验数据的标准估计器而言，本研究所提出的估计器能够显著减少20%样本量以达到相同精度水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Randomized experiments are the preferred approach for evaluating the effectsof interventions, but they are costly and often yield estimates withsubstantial uncertainty. On the other hand, in silico experiments leveragingfoundation models offer a cost-effective alternative that can potentiallyattain higher statistical precision. However, the benefits of in silicoexperiments come with a significant risk: statistical inferences are not validif the models fail to accurately predict experimental responses tointerventions. In this paper, we propose a novel approach that integrates thepredictions from multiple foundation models with experimental data whilepreserving valid statistical inference. Our estimator is consistent andasymptotically normal, with asymptotic variance no larger than the standardestimator based on experimental data alone. Importantly, these statisticalproperties hold even when model predictions are arbitrarily biased. Empiricalresults across several randomized experiments show that our estimator offerssubstantial precision gains, equivalent to a reduction of up to 20% in thesample size needed to match the same precision as the standard estimator basedon experimental data alone.</description>
      <author>example@mail.com (Piersilvio De Bartolomeis, Javier Abad, Guanbo Wang, Konstantin Donhauser, Raymond M. Duch, Fanny Yang, Issa J. Dahabreh)</author>
      <guid isPermaLink="false">2502.04262v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>LeAP: Consistent multi-domain 3D labeling using Foundation Models</title>
      <link>http://arxiv.org/abs/2502.03901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures. ICRA25 preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种自动标注3D点云数据的方法，使用2D视觉基础模型（VFM）并结合贝叶斯更新和新颖的3D一致性网络来生成高质量的语义标签。&lt;h4&gt;背景&lt;/h4&gt;获得未标记的3D点云数据相对容易，但手动为这些数据添加语义标签耗时且成本高。最近出现的2D VFM虽然有助于开放集语义分割，但在标注3D数据时可能导致不一致性问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动注释3D点云数据的方法，并确保标签的一致性，同时适用于各种应用和类别的集合。&lt;h4&gt;方法&lt;/h4&gt;提出了Label Any Pointcloud (LeAP) 方法，该方法利用2D VFM为3D数据进行自动语义标注。结合贝叶斯更新将点标签合并到体素中以提高时空一致性，并使用新颖的3D一致性网络进一步提升标签质量。&lt;h4&gt;主要发现&lt;/h4&gt;通过多种实验显示，这种方法能够在没有人工标记的情况下生成高质量的3D语义标签；利用这些自动生成的标签来适应新领域的模型可以显著提高语义分割任务的表现（最高可达34.2 mIoU）。&lt;h4&gt;结论&lt;/h4&gt;LeAP方法能够有效地为各种应用场景提供一致且高质量的3D数据自动标注，从而推动相关领域的发展。&lt;h4&gt;翻译&lt;/h4&gt;数据集的可用性是促进三维语义理解研究的强大动力。虽然获取未标记的3D点云数据较为容易，但手动为其添加语义标签却耗时且成本高。最近，视觉基础模型（VFM）在相机图像上的开放集语义分割应用中展现出潜力，可能有助于自动标注。然而，在三维数据上使用VFMs的传统方式是从二维模型适应而来，这可能会导致标签不一致问题。这项工作介绍了一种称为Label Any Pointcloud (LeAP) 的方法，该方法利用2D VFMs为3D数据进行自动语义标注，同时确保标签的一致性，并适用于任何类别的集合以及各种应用领域。通过使用贝叶斯更新将点标签组合成体素以提高时空一致性，并且一个新颖的三维一致性网络（3D-CN）被用来进一步提升标签质量。通过多种实验展示，我们的方法能够在没有任何人工标注的情况下生成高质量的3D语义标签，适用于不同领域。此外，应用我们自动生成标签来调整新领域的模型可以显著提高语义分割任务的表现（最高可达34.2 mIoU）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Availability of datasets is a strong driver for research on 3D semanticunderstanding, and whilst obtaining unlabeled 3D point cloud data isstraightforward, manually annotating this data with semantic labels istime-consuming and costly. Recently, Vision Foundation Models (VFMs) enableopen-set semantic segmentation on camera images, potentially aiding automaticlabeling. However,VFMs for 3D data have been limited to adaptations of 2Dmodels, which can introduce inconsistencies to 3D labels. This work introducesLabel Any Pointcloud (LeAP), leveraging 2D VFMs to automatically label 3D datawith any set of classes in any kind of application whilst ensuring labelconsistency. Using a Bayesian update, point labels are combined into voxels toimprove spatio-temporal consistency. A novel 3D Consistency Network (3D-CN)exploits 3D information to further improve label quality. Through variousexperiments, we show that our method can generate high-quality 3D semanticlabels across diverse fields without any manual labeling. Further, modelsadapted to new domains using our labels show up to a 34.2 mIoU increase insemantic segmentation tasks.</description>
      <author>example@mail.com (Simon Gebraad, Andras Palffy, Holger Caesar)</author>
      <guid isPermaLink="false">2502.03901v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Covert Speech Classification Using EEG Hilbert Envelope and Temporal Fine Structure</title>
      <link>http://arxiv.org/abs/2502.04132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;本文提出了一种通过将公开演讲数据训练的分类器转移到隐语识别中的方法，以解决脑机接口在解码想象语言时面临的高培训负担和低识别准确度问题。&lt;h4&gt;背景&lt;/h4&gt;现有的脑计算机接口系统需要大量重复词语想象训练，这会导致参与者精神疲劳，并且难以确定词语开始的时间点，特别是当涉及到连续的单词序列时。&lt;h4&gt;目的&lt;/h4&gt;通过使用公开演讲数据训练分类器并将其应用到隐语（即内部思考）识别中来减轻培训负担并提高解码准确性。&lt;h4&gt;方法&lt;/h4&gt;采用了基于Hilbert包络和时间精细结构提取的脑电图（EEG）特征，利用这些特征训练双向长短期记忆网络模型进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;此方法能够减少大量重复词语想象所需的训练量，并且达到了最新的解码准确性标准：公开演讲为86.44%，隐语识别达到79.82%的准确率（使用来自公开演讲数据训练的分类器）。&lt;h4&gt;结论&lt;/h4&gt;通过转移学习的方法，可以在不牺牲准确性的前提下大大减少脑计算机接口系统的培训负担，并且提高了解码想象语音的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain-Computer Interfaces (BCIs) can decode imagined speech from neuralactivity. However, these systems typically require extensive training sessionswhere participants imaginedly repeat words, leading to mental fatigue anddifficulties identifying the onset of words, especially when imaginingsequences of words. This paper addresses these challenges by transferring aclassifier trained in overt speech data to covert speech classification. Weused electroencephalogram (EEG) features derived from the Hilbert envelope andtemporal fine structure, and used them to train a bidirectional long-short-termmemory (BiLSTM) model for classification. Our method reduces the burden ofextensive training and achieves state-of-the-art classification accuracy:86.44% for overt speech and 79.82% for covert speech using the overt speechclassifier.</description>
      <author>example@mail.com (Saravanakumar Duraisamy, Mateusz Dubiel, Maurice Rekrut, Luis A. Leiva)</author>
      <guid isPermaLink="false">2502.04132v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali &amp; Marathi</title>
      <link>http://arxiv.org/abs/2502.04245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;印度的文化和语言多样性给自然语言处理（NLP）领域带来了各种挑战，特别是在命名实体识别（NER）方面。&lt;h4&gt;目的&lt;/h4&gt;构建一个多语言NER模型，用于处理印地语、孟加拉语和马拉地语这三种在印度最广泛使用的语言。&lt;h4&gt;方法&lt;/h4&gt;训练了一个自定义的Transformer模型，并对几个预训练模型进行了微调，以实现多种实体类型的识别。&lt;h4&gt;主要发现&lt;/h4&gt;通过该研究实现了92.11的F1分数，在总共六个实体组中进行分类，这表明了跨三种语言的一致性和标签名称减少的重要性。&lt;h4&gt;结论&lt;/h4&gt;引入了一种单模型解决方案来执行NER任务，并显著减少了实体组和标签名在不同语言间的不一致性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了印度的多元文化和多语言环境对自然语言处理（NLP）领域，尤其是命名实体识别（NER），所带来的挑战。研究团队开发了一个能够处理印地语、孟加拉语及马拉地语的多语言模型，并通过对特定Transformer架构的训练和微调达到了较高的F1分数。此外，该工作还旨在减少跨三种目标语言在实体分类上的差异性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; India's rich cultural and linguistic diversity poses various challenges inthe domain of Natural Language Processing (NLP), particularly in Named EntityRecognition (NER). NER is a NLP task that aims to identify and classify tokensinto different entity groups like Person, Location, Organization, Number, etc.This makes NER very useful for downstream tasks like context-awareanonymization. This paper details our work to build a multilingual NER modelfor the three most spoken languages in India - Hindi, Bengali &amp; Marathi. Wetrain a custom transformer model and fine tune a few pretrained models,achieving an F1 Score of 92.11 for a total of 6 entity groups. Through thispaper, we aim to introduce a single model to perform NER and significantlyreduce the inconsistencies in entity groups and tag names, across the threelanguages.</description>
      <author>example@mail.com (Mohammed Amaan Dhamaskar, Rasika Ransing)</author>
      <guid isPermaLink="false">2502.04245v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Group Convolutional Networks for Sign Problem Mitigation via Contour Deformation</title>
      <link>http://arxiv.org/abs/2502.04104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings for the 41st International Symposium on Lattice Field  Theory (LATTICE2024) 28 July - 3 August 2024 Liverpool, UK Accepted by  Proceedings of Science&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了在混合蒙特卡洛计算中通过变形积分流形来减轻符号问题的方法，并比较了全连接网络与群卷积模型的性能差异。&lt;h4&gt;背景&lt;/h4&gt;在Hybrid Monte Carlo计算中，符号问题是由于温度降低和相互作用增加而引起的。机器学习模型可以进一步改善这一情况，但需要额外的计算资源和前期训练。物理对称性被编码进神经网络结构中的好处包括更高的准确度、更快的训练速度以及更好的稳定性。&lt;h4&gt;目的&lt;/h4&gt;研究群卷积模型相较于全连接网络在解决符号问题及计算性能方面的优势，并探究其在迁移学习中的能力，以进一步减少训练成本。&lt;h4&gt;方法&lt;/h4&gt;本研究基于Hubbard模型，在选定的低维系统上进行探索和实验。&lt;h4&gt;主要发现&lt;/h4&gt;群卷积模型相对于全连接网络具有更好的准确性、更快的训练速度以及更稳定的性能。此外，它们在迁移学习中表现出色，可以进一步降低训练成本。&lt;h4&gt;结论&lt;/h4&gt;通过在Hubbard模型上的研究，表明了群卷积模型相比传统方法更具优势，尤其是在解决物理系统中的符号问题方面，并且在减少计算资源消耗方面具有潜在的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The sign problem that arises in Hybrid Monte Carlo calculations can bemitigated by deforming the integration manifold. While simple transformationsare highly efficient for simulation, their efficacy systematically decreaseswith decreasing temperature and increasing interaction. Machine learning modelshave demonstrated the ability to push further, but require additionalcomputational effort and upfront training. While neural networks possess thecapacity to learn physical symmetries through proper training, there areanticipated advantages associated with encoding them into the network'sstructure. These include enhanced accuracy, accelerated training, and improvedstability. The objective of the present study is twofold. First, we investigatethe benefits of group convolutional models in comparison to fully connectednetworks, with a specific focus on the effects on the sign problem and oncomputational aspects. Second, we examine their capabilities for transferlearning, demonstrating the ability to further reduce training cost. We performour investigations on the Hubbard model on select low-dimensional systems.</description>
      <author>example@mail.com (Christoph Gäntgen, Thomas Luu, Marcel Rodekamp)</author>
      <guid isPermaLink="false">2502.04104v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.03715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种结合知识图谱(KG)和大型语言模型(LLM)的推荐框架，旨在提高KG的质量和相关性，从而增强基于KG的推荐系统的性能。&lt;h4&gt;背景&lt;/h4&gt;基于知识图谱的推荐系统由于其利用丰富语义关系的能力而受到广泛关注。然而，构建和维护知识图谱是资源密集型的任务，并且知识图谱可能因噪声、过时或无关三元组的存在而影响准确性。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种结合大型语言模型(LLM)增强知识图谱的方法，以提高基于KG的推荐系统的质量和性能。&lt;h4&gt;方法&lt;/h4&gt;{'框架名称': 'Confidence-aware KG-based Recommendation Framework with LLM Augmentation (CKG-LLMA)', '具体组成部分': ['一个基于LLM的子图扩充器，用于丰富知识图谱', '一种具有信心感知的消息传播机制来过滤噪声三元组', '一种双视图对比学习方法，以整合用户-物品交互和KG数据']}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CKG-LLMA框架在多个公共数据集上有效改善了基于KG的推荐系统的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出了一种结合知识图谱和大型语言模型的新颖推荐框架，并展示了其提升推荐系统表现的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的研究成果是通过整合先进的大型语言模型来改进知识图谱的质量，进而提高基于知识图谱的推荐系统的性能。该研究提出的方法包括增强KG的子图扩充器、过滤噪声三元组的消息传播机制以及结合用户-物品交互和KG数据的双视图对比学习方法。实验结果证实了所提出的框架的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge Graph-based recommendations have gained significant attention dueto their ability to leverage rich semantic relationships. However, constructingand maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracyof KGs can suffer from noisy, outdated, or irrelevant triplets. Recentadvancements in Large Language Models (LLMs) offer a promising way to improvethe quality and relevance of KGs for recommendation tasks. Despite this,integrating LLMs into KG-based systems presents challenges, such as efficientlyaugmenting KGs, addressing hallucinations, and developing effective jointlearning methods. In this paper, we propose the Confidence-aware KG-basedRecommendation Framework with LLM Augmentation (CKG-LLMA), a novel frameworkthat combines KGs and LLMs for recommendation task. The framework includes: (1)an LLM-based subgraph augmenter for enriching KGs with high-qualityinformation, (2) a confidence-aware message propagation mechanism to filternoisy triplets, and (3) a dual-view contrastive learning method to integrateuser-item interactions and KG data. Additionally, we employ a confidence-awareexplanation generation process to guide LLMs in producing realisticexplanations for recommendations. Finally, extensive experiments demonstratethe effectiveness of CKG-LLMA across multiple public datasets.</description>
      <author>example@mail.com (Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong)</author>
      <guid isPermaLink="false">2502.03715v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization</title>
      <link>http://arxiv.org/abs/2502.04034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种名为panCancerDR的新颖领域泛化框架被提出，旨在预测药物在单细胞水平上的反应，并解决训练过程中无法访问目标域数据的问题。&lt;h4&gt;背景&lt;/h4&gt;准确预测药物对个体细胞和患者的响应仍然是一个重大挑战。现有的研究使用转移学习技术进行预测，但需要在训练期间获得目标领域的数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的领域泛化框架panCancerDR来提取跨不同类型癌症的细胞系表达谱中不变特征，并提高其预测能力以适应未见过的癌类型样本。&lt;h4&gt;方法&lt;/h4&gt;将每种癌症视为一个独立源域，引入了隐变量独立投影（LIP）模块和非对称自适应聚类约束，前者鼓励编码器提取的信息具有相关性但又不冗余，后者在潜在空间中聚集敏感样品并将抗性样品分散到不同的簇。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示panCancerDR能够从多种源域学习任务相关的特征，并且对于训练期间未见过的癌类型实现了准确预测；并且，在单细胞和患者级别预测任务上，模型仅使用体外细胞系数据进行训练，而无需访问目标领域信息的情况下表现优异。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界的临床应用中具有潜在价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate prediction of drug responses remains a formidable challenge,particularly at the single-cell level and in clinical treatment contexts. Somestudies employ transfer learning techniques to predict drug responses inindividual cells and patients, but they require access to target-domain dataduring training, which is often unavailable or only obtainable in future. Inthis study, we propose a novel domain generalization framework, termedpanCancerDR, to address this challenge. We conceptualize each cancer type as adistinct source domain, with its cell lines serving as domain-specific samples.Our primary objective is to extract domain-invariant features from theexpression profiles of cell lines across diverse cancer types, therebygeneralize the predictive capacity to out-of-distribution samples. To enhancerobustness, we introduce a latent independence projection (LIP) module thatencourages the encoder to extract informative yet non-redundant features. Also,we propose an asymmetric adaptive clustering constraint, which clustersdrug-sensitive samples into a compact group while drives resistant samplesdispersed across separate clusters in the latent space. Our empiricalexperiments demonstrate that panCancerDR effectively learns task-relevantfeatures from diverse source domains, and achieves accurate predictions of drugresponse for unseen cancer type during training. Furthermore, when evaluated onsingle-cell and patient-level prediction tasks, our model-trained solely on invitro cell line data without access to target-domain information-consistentlyoutperforms and matched current state-of-the-art methods. These findingshighlights the potential of our method for real-world clinical applications.</description>
      <author>example@mail.com (Ran Song, Yinpu Bai, Hui Liu)</author>
      <guid isPermaLink="false">2502.04034v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning for Cold Start Recommendation with Adaptive Feature Fusion</title>
      <link>http://arxiv.org/abs/2502.03664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合对比学习的冷启动推荐模型，旨在解决由于用户和物品交互数据稀缺而导致的推荐系统在冷启动场景中性能下降的问题。&lt;h4&gt;背景&lt;/h4&gt;当前推荐系统的冷启动问题严重影响了用户体验，尤其是在缺乏用户行为记录的情况下。现有的推荐方法通常难以在这种情况下保持高推荐准确性。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有推荐模型面对冷启动挑战时的表现不足，本文提出了一种新的推荐模型来解决该问题。&lt;h4&gt;方法&lt;/h4&gt;{'自适应特征选择模块': '用于动态调整关键特征的权重，以更好地利用有限的数据资源。', '多模态特性融合机制': '有效整合用户属性、项目元信息和上下文特征，提高推荐效果。', '对比学习机制': '通过构建正负样本对来增强特性的表示能力和模型的鲁棒性和泛化能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'实验结果': '在MovieLens-1M数据集上的实验证明了所提出的模型相较于传统的矩阵分解、LightGBM、DeepFM和AutoRec等主流推荐方法，在HR（命中率）、NDCG、MRR（平均倒数排名）及召回率等方面有显著提升，特别是在冷启动场景下表现更为出色。', '消融实验': '进一步验证了各模块在提高模型性能中的关键作用，以及学习速率对优化效果的影响分析显示适度的学习速率对于获得最佳模型性能至关重要。'}&lt;h4&gt;结论&lt;/h4&gt;本研究不仅为解决冷启动问题提供了新方案，并且为对比学习技术在推荐系统中的应用提供了重要参考。未来该模型有望在实时推荐和跨域推荐等更广泛的场景中发挥作用。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文已提供，无需再次翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a cold start recommendation model that integratescontrastive learning, aiming to solve the problem of performance degradation ofrecommendation systems in cold start scenarios due to the scarcity of user anditem interaction data. The model dynamically adjusts the weights of keyfeatures through an adaptive feature selection module and effectivelyintegrates user attributes, item meta-information, and contextual features bycombining a multimodal feature fusion mechanism, thereby improvingrecommendation performance. In addition, the model introduces a contrastivelearning mechanism to enhance the robustness and generalization ability offeature representation by constructing positive and negative sample pairs.Experiments are conducted on the MovieLens-1M dataset. The results show thatthe proposed model significantly outperforms mainstream recommendation methodssuch as Matrix Factorization, LightGBM, DeepFM, and AutoRec in terms of HR,NDCG, MRR, and Recall, especially in cold start scenarios. Ablation experimentsfurther verify the key role of each module in improving model performance, andthe learning rate sensitivity analysis shows that a moderate learning rate iscrucial to the optimization effect of the model. This study not only provides anew solution to the cold start problem but also provides an important referencefor the application of contrastive learning in recommendation systems. In thefuture, this model is expected to play a role in a wider range of scenarios,such as real-time recommendation and cross-domain recommendation.</description>
      <author>example@mail.com (Jiacheng Hu, Tai An, Zidong Yu, Junliang Du, Yuanshuai Luo)</author>
      <guid isPermaLink="false">2502.03664v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>The Cake that is Intelligence and Who Gets to Bake it: An AI Analogy and its Implications for Participation</title>
      <link>http://arxiv.org/abs/2502.03038v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文扩展了Yann LeCun关于机器智能如同蛋糕的类比，将其从简单的结构比喻发展到AI系统的整个生命周期，并探讨每个阶段的社会影响。&lt;h4&gt;背景&lt;/h4&gt;Yann LeCun将机器智能与蛋糕进行比较，其中无监督学习构成基础，有监督学习添加装饰，强化学习则是点睛之笔。但是这种比喻仅限于结构性描述，未涉及更广泛的应用过程和社会影响。&lt;h4&gt;目的&lt;/h4&gt;通过重新构建这一类比来探讨AI系统的全生命周期，并研究其技术根基与社会成果之间的相互作用和限制。&lt;h4&gt;方法&lt;/h4&gt;将整个AI系统的发展比喻为蛋糕的制作流程，包括数据采集（获取食材）、模型设计（制定食谱）、训练过程（烘焙过程）以及评估和部署（品尝及销售）。&lt;h4&gt;主要发现&lt;/h4&gt;每个阶段的技术基础都伴随着社会影响，并且技术与社会结果之间的界限常常模糊不清。&lt;h4&gt;结论&lt;/h4&gt;重新构建的类比有助于促进跨学科对话，为AI从业者、用户和研究人员提供了行动建议，以便他们能够更广泛地参与AI讨论。&lt;h4&gt;翻译&lt;/h4&gt;该论文通过将机器智能比喻成蛋糕的过程来探讨其从数据获取到模型部署整个生命周期中的技术与社会互动情况，并提出了一系列旨在促进更广阔领域中AI讨论的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a widely popular analogy by Turing Award Laureate Yann LeCun, machineintelligence has been compared to cake - where unsupervised learning forms thebase, supervised learning adds the icing, and reinforcement learning is thecherry on top. We expand this 'cake that is intelligence' analogy from a simplestructural metaphor to the full life-cycle of AI systems, extending it tosourcing of ingredients (data), conception of recipes (instructions), thebaking process (training), and the tasting and selling of the cake (evaluationand distribution). Leveraging our re-conceptualization, we describe each step'sentailed social ramifications and how they are bounded by statisticalassumptions within machine learning. Whereas these technical foundations andsocial impacts are deeply intertwined, they are often studied in isolation,creating barriers that restrict meaningful participation. Ourre-conceptualization paves the way to bridge this gap by mapping wheretechnical foundations interact with social outcomes, highlighting opportunitiesfor cross-disciplinary dialogue. Finally, we conclude with actionablerecommendations at each stage of the metaphorical AI cake's life-cycle,empowering prospective AI practitioners, users, and researchers, with increasedawareness and ability to engage in broader AI discourse.</description>
      <author>example@mail.com (Martin Mundt, Anaelia Ovalle, Felix Friedrich, A Pranav, Subarnaduti Paul, Manuel Brack, Kristian Kersting, William Agnew)</author>
      <guid isPermaLink="false">2502.03038v2</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Driven Hierarchical Mining for Complex Imbalanced Data</title>
      <link>http://arxiv.org/abs/2502.03803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种层次化挖掘框架，用于处理高维不平衡数据，并采用深度图模型来克服传统方法在处理复杂、高维度且样本分布不均的数据时的性能限制。该研究通过构建数据集的结构化图表示，并结合图神经网络嵌入技术，有效地捕捉到样本间的全局依赖性。&lt;h4&gt;背景&lt;/h4&gt;传统的数据分析方法难以有效应对具有高维度和不平衡特征的数据分布问题，尤其是在发现少数类别的特征模式方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的方法来提高在处理复杂、高维且不平衡数据时的性能，特别是对于少数类别特征提取和模式相关分析的改进。&lt;h4&gt;方法&lt;/h4&gt;该研究利用深度图模型构建一个结构化的图表示，并集成图神经网络嵌入技术，采用层次化策略强化对少数类特征模式的表征与提取能力。这种框架能够捕获全局样本间的关系以及增强不平衡数据中的少数类别识别和挖掘性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在模式发现数量、平均支持度和少数类别覆盖度等关键指标上，所提出的层次化挖掘方法明显优于传统技术，并且在少数类特征提取和模式相关分析方面表现出卓越的能力。这些结果强调了深度图模型结合分层挖掘策略处理不平衡数据时的潜在优势。&lt;h4&gt;结论&lt;/h4&gt;该研究贡献了一个适用于高维度复杂数据处理的新颖计算框架，为未来的动态演化的不平衡数据分析及多模态应用场景打下了基础，进一步拓宽了高级数据挖掘方法的应用领域。&lt;h4&gt;翻译&lt;/h4&gt;这项研究介绍了一种用于高维不平衡数据的层次化挖掘框架，并利用深度图模型来解决传统方法在处理复杂、高维度和样本分布不均的数据时固有的性能限制问题。通过构建数据集的结构化图表示并结合图神经网络嵌入技术，所提出的方法能够有效地捕获样本间的全局依赖性。此外，还采用了一种层次策略来增强对少数类别特征模式的表征与提取能力，从而促进不平衡数据挖掘的精准性和鲁棒性。多个实验场景中的实证评估验证了该方法的有效性，在包括模式发现数量、平均支持度和少数类别覆盖度等关键性能指标上取得了显著改进。值得注意的是，此方法在少数类特征提取及模式相关分析方面表现出卓越的能力。这些结果强调了深度图模型与层次化挖掘策略结合处理不平衡数据时的潜在优势，并为高维度复杂数据处理贡献了一个新颖计算框架，同时也为未来动态演化的不平衡数据分析和多模态应用场景奠定了基础，从而扩展了先进数据挖掘方法的应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents a hierarchical mining framework for high-dimensionalimbalanced data, leveraging a depth graph model to address the inherentperformance limitations of conventional approaches in handling complex,high-dimensional data distributions with imbalanced sample representations. Byconstructing a structured graph representation of the dataset and integratinggraph neural network (GNN) embeddings, the proposed method effectively capturesglobal interdependencies among samples. Furthermore, a hierarchical strategy isemployed to enhance the characterization and extraction of minority classfeature patterns, thereby facilitating precise and robust imbalanced datamining. Empirical evaluations across multiple experimental scenarios validatethe efficacy of the proposed approach, demonstrating substantial improvementsover traditional methods in key performance metrics, including patterndiscovery count, average support, and minority class coverage. Notably, themethod exhibits superior capabilities in minority-class feature extraction andpattern correlation analysis. These findings underscore the potential of depthgraph models, in conjunction with hierarchical mining strategies, tosignificantly enhance the efficiency and accuracy of imbalanced data analysis.This research contributes a novel computational framework for high-dimensionalcomplex data processing and lays the foundation for future extensions todynamically evolving imbalanced data and multi-modal data applications, therebyexpanding the applicability of advanced data mining methodologies to moreintricate analytical domains.</description>
      <author>example@mail.com (Yijiashun Qi, Quanchao Lu, Shiyu Dou, Xiaoxuan Sun, Muqing Li, Yankaiqi Li)</author>
      <guid isPermaLink="false">2502.03803v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Principal Curvatures Estimation with Applications to Single Cell Data</title>
      <link>http://arxiv.org/abs/2502.03750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in ICASSP 2025-2025 IEEE International Conference on  Acoustics, Speech and Signal Processing (ICASSP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Adaptive Local PCA (AdaL-PCA)算法，该算法基于局部主成分分析估计数据流形上的切平面，并准确估算内禀曲率。&lt;h4&gt;背景&lt;/h4&gt;单细胞转录组测序技术产生的大规模数据集给数据分析带来了挑战。流形学习中的常用方法假设数据分布在低维流形上，通过提取如曲率等有意义的描述符来研究点云的几何结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于局部主成分分析的数据驱动方法AdaL-PCA，用于准确估算不同内禀曲率的概念，并应用于单细胞RNA测序数据分析以揭示关键差异。&lt;h4&gt;方法&lt;/h4&gt;利用局部主成分分析（Local PCA）估计切平面，并通过PHATE嵌入技术将模型应用到单细胞RNA测序数据中。&lt;h4&gt;主要发现&lt;/h4&gt;在采样表面上的评估表明，AdaL-PCA算法能够提供当前最佳的结果。该模型能识别出与细胞分化相关的关键变化。&lt;h4&gt;结论&lt;/h4&gt;Adaptive Local PCA (AdaL-PCA)方法不仅在曲率估计方面表现优异，还能通过PHATE嵌入技术有效揭示单细胞RNA测序数据中的重要差异。&lt;h4&gt;翻译&lt;/h4&gt;随着单细胞转录组测序（scRNA-seq）领域的快速发展，大数据集给数据分析带来了挑战。流形学习中常用的方法假设数据分布在低维流形上，允许我们研究点云的几何结构并提取如曲率等有意义的描述符。本文介绍了一种基于局部主成分分析的数据驱动方法AdaL-PCA，用于准确估算不同内禀曲率的概念，特别是在表面情况下估计主要曲率。在采样表面上评估该模型显示了当前最佳的结果，并且当与PHATE嵌入结合使用时，应用于单细胞RNA测序数据中可以识别出关键的变化和细胞分化差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)presents challenges for data analysis due to its massive datasets. A commonmethod in manifold learning consists in hypothesizing that datasets lie on alower dimensional manifold. This allows to study the geometry of point cloudsby extracting meaningful descriptors like curvature. In this work, we willpresent Adaptive Local PCA (AdaL-PCA), a data-driven method for accuratelyestimating various notions of intrinsic curvature on data manifolds, inparticular principal curvatures for surfaces. The model relies on local PCA toestimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfacesshows state-of-the-art results. Combined with a PHATE embedding, the modelapplied to single-cell RNA sequencing data allows us to identify key variationsin the cellular differentiation.</description>
      <author>example@mail.com (Yanlei Zhang, Lydia Mezrag, Xingzhi Sun, Charles Xu, Kincaid Macdonald, Dhananjay Bhaskar, Smita Krishnaswamy, Guy Wolf, Bastian Rieck)</author>
      <guid isPermaLink="false">2502.03750v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>LR0.FM: Low-Resolution Zero-shot Classification Benchmark For Foundation Models</title>
      <link>http://arxiv.org/abs/2502.03950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了LR0.FM，这是一个评估视觉语言基础模型在低分辨率图像上的零样本分类性能的基准。&lt;h4&gt;背景&lt;/h4&gt;尽管视觉语言基础模型通过大规模预训练展示出跨任务的强大泛化能力，但它们在处理低分辨率或像素化的图像时的鲁棒性还未充分研究。&lt;h4&gt;目的&lt;/h4&gt;开发一个全面的基准测试来评估10个基础模型在66种架构和15个数据集上的零样本分类性能，并提出一个新的评价指标Weighted Aggregated Robustness。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的度量标准，用以更好地跨分辨率和数据集评估模型性能。该研究还探索了预训练的数据集质量与模型大小对鲁棒性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;{'i': '模型规模越大，其在图像分辨率下降时的鲁棒性越强；', 'ii': '预训练数据集的质量比其规模更重要；', 'iii': '微调和高分辨率模型在低分辨率图像上的鲁棒性较差。'}&lt;h4&gt;结论&lt;/h4&gt;通过分析发现，在低分辨率输入下，缺乏细节对模型早期层的影响大于深层。为此提出了一种简单策略LR-TK0来提升模型的鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;论文提出了一个用于评估视觉语言基础模型在处理低分辨率图像时零样本分类性能的新基准和度量标准，并通过实验证明了提高模型鲁棒性的新方法的有效性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shyammarjit/LR0.FM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual-language foundation Models (FMs) exhibit remarkable zero-shotgeneralization across diverse tasks, largely attributed to extensivepre-training on large-scale datasets. However, their robustness onlow-resolution/pixelated (LR) images, a common challenge in real-worldscenarios, remains underexplored. We introduce LR0.FM, a comprehensivebenchmark evaluating the impact of low resolution on the zero-shotclassification performance of 10 FM(s) across 66 backbones and 15 datasets. Wepropose a novel metric, Weighted Aggregated Robustness, to address thelimitations of existing metrics and better evaluate model performance acrossresolutions and datasets. Our key findings show that: (i) model size positivelycorrelates with robustness to resolution degradation, (ii) pre-training datasetquality is more important than its size, and (iii) fine-tuned andhigher-resolution models are less robust against LR. Our analysis furtherreveals that the model makes semantically reasonable predictions at LR, and thelack of fine-grained details in input adversely impacts the model's initiallayers more than the deeper layers. We use these insights and introduce asimple strategy, LR-TK0, to enhance the robustness of models withoutcompromising their pre-trained weights. We demonstrate the effectiveness ofLR-TK0 for robustness against low-resolution across several datasets and itsgeneralization capability across backbones and other approaches. Code isavailable at this https://github.com/shyammarjit/LR0.FM</description>
      <author>example@mail.com (Priyank Pathak, Shyam Marjit, Shruti Vyas, Yogesh S Rawat)</author>
      <guid isPermaLink="false">2502.03950v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Unravelling Causal Genetic Biomarkers of Alzheimer's Disease via Neuron to Gene-token Backtracking in Neural Architecture: A Groundbreaking Reverse-Gene-Finder Approach</title>
      <link>http://arxiv.org/abs/2502.03938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;阿尔茨海默病（AD）影响了全球超过5500万人，但其关键遗传因素仍不清楚。利用最近的基因组基础模型进展，我们提出了Reverse-Gene-Finder技术，这是一种神经网络架构中的逆向基因发现方法，用于揭示驱动AD发病的新颖因果遗传生物标志物。&lt;h4&gt;背景&lt;/h4&gt;阿尔茨海默病（AD）影响了全球超过5500万人。然而，导致这种疾病的最关键遗传因素仍未被充分理解。&lt;h4&gt;目的&lt;/h4&gt;通过利用神经网络架构中的新颖逆向基因发现方法Reverse-Gene-Finder技术，揭示驱动AD发病的新颖因果遗传生物标志物。&lt;h4&gt;方法&lt;/h4&gt;{'第一创新点': '观察到与阿尔茨海默病（AD）关系最为密切的基因必须激活那些最有可能导致AD发生的神经元。这些具有最高致病性的基因被称为MCGs，而那些最可能引发疾病的神经元则称为MCNs。', '第二创新点': '在输入层使用基因令牌表示法，使每个基因能够作为独特的实体被表示出来。', '第三创新点': '与现有网络架构不同，Reverse-Gene-Finder技术采用一种逆向方法，从最高概率的神经元（MCNs）追溯到输入层，从而找到最有因果关系的标记和相关基因。'}&lt;h4&gt;主要发现&lt;/h4&gt;Reverse-Gene-Finder具有高度解释性、通用性和适应性。&lt;h4&gt;结论&lt;/h4&gt;Reverse-Gene-Finder技术为其他疾病场景的应用提供了有希望的方法途径。&lt;h4&gt;翻译&lt;/h4&gt;阿尔茨海默病（AD）影响了全球超过5500万人，但其关键遗传因素仍不清楚。利用最近的基因组基础模型进展，我们提出了Reverse-Gene-Finder技术，这是一种神经网络架构中的逆向基因发现方法，用于揭示驱动AD发病的新颖因果遗传生物标志物。该方法包含三个关键创新点：观察到与阿尔茨海默病（AD）关系最为密切的基因必须激活那些最有可能导致AD发生的神经元；在输入层使用基因令牌表示法，使每个基因能够作为独特的实体被表示出来；逆向追溯从最高概率的神经元（MCNs）至输入层来识别最有因果关系的标记和相关基因。Reverse-Gene-Finder技术因其高度解释性、通用性和适应性而成为其他疾病场景中的潜在应用途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alzheimer's Disease (AD) affects over 55 million people globally, yet the keygenetic contributors remain poorly understood. Leveraging recent advancementsin genomic foundation models, we present the innovative Reverse-Gene-Findertechnology, a ground-breaking neuron-to-gene-token backtracking approach in aneural network architecture to elucidate the novel causal genetic biomarkersdriving AD onset. Reverse-Gene-Finder comprises three key innovations. Firstly,we exploit the observation that genes with the highest probability of causingAD, defined as the most causal genes (MCGs), must have the highest probabilityof activating those neurons with the highest probability of causing AD, definedas the most causal neurons (MCNs). Secondly, we utilize a gene tokenrepresentation at the input layer to allow each gene (known or novel to AD) tobe represented as a discrete and unique entity in the input space. Lastly, incontrast to the existing neural network architectures, which track neuronactivations from the input layer to the output layer in a feed-forward manner,we develop an innovative backtracking method to track backwards from the MCNsto the input layer, identifying the Most Causal Tokens (MCTs) and thecorresponding MCGs. Reverse-Gene-Finder is highly interpretable, generalizable,and adaptable, providing a promising avenue for application in other diseasescenarios.</description>
      <author>example@mail.com (Victor OK Li, Yang Han, Jacqueline CK Lam)</author>
      <guid isPermaLink="false">2502.03938v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Network-Wide Traffic Flow Estimation Across Multiple Cities with Global Open Multi-Source Data: A Large-Scale Case Study in Europe and North America</title>
      <link>http://arxiv.org/abs/2502.03798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用全球开放多源(GOMS)数据和先进的深度学习框架来估计网络级交通流量的新方法，该方法解决了传统研究中由于传感器部署成本高昂而导致的观察数据不足的问题。&lt;h4&gt;背景&lt;/h4&gt;智能移动应用的基础是网络范围内的交通流，但安装和维护成本导致实际观测到的数据受限。现有研究试图通过使用各种补充数据源（如天气、社交媒体等）来弥补这一缺口，然而这些方法往往在准确性与通用性之间存在权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架，该框架利用全球开放多源(GOMS)数据，包括地理和人口统计数据，以解决现有研究中所面临的问题。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个基于注意力机制的图神经网络来融合GOMS地图信息，并从观测到的交通数据中捕捉时空动态。这种方法可以跨城市保持一致的数据收集方式，同时利用这些数据作为交通活动的原因或结果进行准确估计。&lt;h4&gt;主要发现&lt;/h4&gt;通过在欧洲和北美15个城市的案例研究，该方法展示了令人满意的网络级流量估计准确性，表明可以通过本方法解决现有问题。&lt;h4&gt;结论&lt;/h4&gt;基于全球开放多源(GOMS)数据的先进深度学习框架能够有效打破现有交通流量预测模型中的准确性与通用性之间的权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Network-wide traffic flow, which captures dynamic traffic volume on each linkof a general network, is fundamental to smart mobility applications. However,the observed traffic flow from sensors is usually limited across the entirenetwork due to the associated high installation and maintenance costs. Toaddress this issue, existing research uses various supplementary data sourcesto compensate for insufficient sensor coverage and estimate the unobservedtraffic flow. Although these studies have shown promising results, theinconsistent availability and quality of supplementary data across cities maketheir methods typically face a trade-off challenge between accuracy andgenerality. In this research, we first time advocate using the Global OpenMulti-Source (GOMS) data within an advanced deep learning framework to breakthe trade-off. The GOMS data primarily encompass geographical and demographicinformation, including road topology, building footprints, and populationdensity, which can be consistently collected across cities. More importantly,these GOMS data are either causes or consequences of transportation activities,thereby creating opportunities for accurate network-wide flow estimation.Furthermore, we use map images to represent GOMS data, instead of traditionaltabular formats, to capture richer and more comprehensive geographical anddemographic information. To address multi-source data fusion, we develop anattention-based graph neural network that effectively extracts and synthesizesinformation from GOMS maps while simultaneously capturing spatiotemporaltraffic dynamics from observed traffic data. A large-scale case study across 15cities in Europe and North America was conducted. The results demonstratestable and satisfactory estimation accuracy across these cities, which suggeststhat the trade-off challenge can be successfully addressed using our approach.</description>
      <author>example@mail.com (Zijian Hu, Zhenjie Zheng, Monica Menendez, Wei Ma)</author>
      <guid isPermaLink="false">2502.03798v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying Correlations of Machine Learning Models</title>
      <link>http://arxiv.org/abs/2502.03937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习模型在安全关键的应用中被广泛使用，这些模型中的错误可能导致用户受到伤害。当多个同时部署的机器学习模型相互作用并同时出错时，这种风险会被放大。&lt;h4&gt;目的&lt;/h4&gt;探讨和量化多个机器学习模型之间产生误差相关性的三种场景及其导致的风险聚合。&lt;h4&gt;方法&lt;/h4&gt;利用真实世界的数据模拟了上述三个场景，并量化不同模型之间的错误关联。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，当多模型采用相同的算法、训练数据集或基础模型时，聚合风险尤为显著。此外，跨模型的这种相关性普遍存在，并且随着对基础模型和广泛使用的公共数据集依赖性的增加而加剧。&lt;h4&gt;结论&lt;/h4&gt;这些挑战突显了需要有效的缓解策略来应对机器学习应用中的风险聚合问题。&lt;h4&gt;翻译&lt;/h4&gt;机器学习模型在安全关键的应用中被广泛应用，它们可能带来的错误会危害用户。当多个同时部署的机器学习模型之间发生相互作用并产生误差时，这种潜在的风险会被进一步放大。本文研究了三个可能导致多模型之间出现误差相关性的场景，并利用真实世界的数据进行了模拟和量化分析。研究表明，这些风险在特定条件下（如模型采用相似算法、训练数据集或基础模型）尤为突出。总体而言，跨模型的相关性普遍存在且有加剧的趋势，这反映了对常用公共数据集依赖度增加的大环境背景下的问题。基于此，提出了需要采取有效措施来应对这一挑战的建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine Learning models are being extensively used in safety criticalapplications where errors from these models could cause harm to the user. Suchrisks are amplified when multiple machine learning models, which are deployedconcurrently, interact and make errors simultaneously. This paper exploresthree scenarios where error correlations between multiple models arise,resulting in such aggregated risks. Using real-world data, we simulate thesescenarios and quantify the correlations in errors of different models. Ourfindings indicate that aggregated risks are substantial, particularly whenmodels share similar algorithms, training datasets, or foundational models.Overall, we observe that correlations across models are pervasive and likely tointensify with increased reliance on foundational models and widely used publicdatasets, highlighting the need for effective mitigation strategies to addressthese challenges.</description>
      <author>example@mail.com (Yuanyuan Li, Neeraj Sarna, Yang Lin)</author>
      <guid isPermaLink="false">2502.03937v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>On the Expressive Power of Subgraph Graph Neural Networks for Graphs with Bounded Cycles</title>
      <link>http://arxiv.org/abs/2502.03703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了k阶子图GNNs，这种网络可以聚合与节点距离不超过k的邻居信息，并利用子图结构。在适当假设下，证明k阶子图GNN可以在不包含超过长度2k+1环的情况下近似任何置换不变或等变连续函数。&lt;h4&gt;背景&lt;/h4&gt;图形神经网络（GNNs）被广泛应用于与图相关的上下文中，但它们的分离能力仅相当于Weisfeiler-Lehman (WL) 测试。因此，GNNs不能识别所有非同构的图，这严重限制了其表达力。&lt;h4&gt;目的&lt;/h4&gt;研究k阶子图GNNs在聚合信息时的表现，并证明这些网络在不包含超过特定长度环的情况下可以近似任何置换不变或等变连续函数。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新类型的GNN——k阶子图GNN，该模型利用了距离节点不超过k的邻居的信息以及子图结构。同时提供了无需考虑子图结构的k阶GNN扩展。&lt;h4&gt;主要发现&lt;/h4&gt;在适当假设下，研究证明了k阶子图GNNs可以近似任何置换不变或等变连续函数，并且实验表明信息聚合的距离与环大小之间的关系得到了验证。&lt;h4&gt;结论&lt;/h4&gt;通过理论和实证研究表明，利用适当的假设，新的k-hop subgraph GNN模型具有强大的表达能力，能够处理特定结构的图形数据。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图神经网络（GNNs）被广泛应用于与图相关的上下文中。已知GNNs的分离能力等同于Weisfeiler-Lehman (WL) 测试；因此，GNNs无法识别所有非同构的图，这极大地限制了它们的表现力。本研究探讨了聚合来自距离不超过k的邻居信息并包含子图结构的k-hop subgraph GNNs。在适当的假设下，我们证明了这些网络可以在不包含长度大于2k+1环的情况下近似任何置换不变或等变连续函数。此外还提供了一种无需考虑子图结构的k阶GNN扩展形式。我们在现有基准和新颖架构上的数值实验验证了信息聚合距离与环大小之间的关系理论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have been widely used in graph-related contexts.It is known that the separation power of GNNs is equivalent to that of theWeisfeiler-Lehman (WL) test; hence, GNNs are imperfect at identifying allnon-isomorphic graphs, which severely limits their expressive power. This workinvestigates $k$-hop subgraph GNNs that aggregate information from neighborswith distances up to $k$ and incorporate the subgraph structure. We prove thatunder appropriate assumptions, the $k$-hop subgraph GNNs can approximate anypermutation-invariant/equivariant continuous function over graphs withoutcycles of length greater than $2k+1$ within any error tolerance. We alsoprovide an extension to $k$-hop GNNs without incorporating the subgraphstructure. Our numerical experiments on established benchmarks and novelarchitectures validate our theory on the relationship between the informationaggregation distance and the cycle size.</description>
      <author>example@mail.com (Ziang Chen, Qiao Zhang, Runzhong Wang)</author>
      <guid isPermaLink="false">2502.03703v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Solar Radio Spectrum Classification</title>
      <link>http://arxiv.org/abs/2502.03778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于自监督学习的太阳射电频谱分类方法，旨在解决传统深度学习方法对大量训练数据的需求问题。&lt;h4&gt;背景&lt;/h4&gt;太阳射电观测是研究太阳活动的重要手段。太阳射电爆发包含了重要的太阳物理信息，因此实时自动检测和分类太阳射电爆发对于后续的研究以及空间天气预警非常重要。&lt;h4&gt;目的&lt;/h4&gt;为了克服自然图像与太阳光谱图之间差异对迁移学习效果的影响，并解决基于深度学习的太阳射电频谱图像分类所需的大量训练数据问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的方法，该方法利用自监督学习技术进行预训练，随后在太阳射电频谱数据集上进行微调。具体而言，采用了类似于自然语言处理中自我屏蔽的方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的方法能够达到与监督式卷积神经网络和Transformer网络相似的分类精度。&lt;h4&gt;结论&lt;/h4&gt;自监督学习方法更有利于从图像中提取本质信息，并且更适合进行迁移学习。这使得在训练数据有限的情况下也能有效提高太阳射电频谱分类的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含于问题描述之中&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/universe8120656&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Solar radio observation is an important way to study the Sun. Solar radiobursts contain important information about solar activity. Therefore, real-timeautomatic detection and classification of solar radio bursts are of great valuefor subsequent solar physics research and space weather warnings. Traditionalimage classification methods based on deep learning often require consid-erabletraining data. To address insufficient solar radio spectrum images, transferlearning is generally used. However, the large difference between naturalimages and solar spectrum images has a large impact on the transfer learningeffect. In this paper, we propose a self-supervised learning method for solarradio spectrum classification. Our method uses self-supervised training with aself-masking approach in natural language processing. Self-supervised learningis more conducive to learning the essential information about images comparedwith supervised methods, and it is more suitable for transfer learning. First,the method pre-trains using a large amount of other existing data. Then, thetrained model is fine-tuned on the solar radio spectrum dataset. Experimentsshow that the method achieves a classification accuracy similar to that ofconvolutional neural networks and Transformer networks with supervisedtraining.</description>
      <author>example@mail.com (Siqi Li, Guowu Yuan, Jian Chen, Chengming Tan, Hao Zhou)</author>
      <guid isPermaLink="false">2502.03778v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>HEP-JEPA: A foundation model for collider physics using joint embedding predictive architecture</title>
      <link>http://arxiv.org/abs/2502.03933v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 8 tables. Project website:  https://hep-jepa.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Transformer架构的模型，用于高能粒子对撞机任务。通过自监督策略训练该模型进行喷注分类。&lt;h4&gt;背景&lt;/h4&gt;在大型强子对撞机等高能粒子对撞机中需要高效准确地处理复杂数据集，特别是在分类和识别不同类型的喷注时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;目的是利用基于Transformer的架构来改进喷注分类任务，并探索该模型在其他相关下游任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用JetClass数据集（包含1亿个各种已知粒子的喷注）进行预训练，采用一种以数据为中心的方法。此方法让模型使用部分喷注成分作为上下文来预测未见目标成分的嵌入。此外，该模型还针对两个额外下游任务：顶夸克标记和区分轻夸克喷注与胶子喷注。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的模型在标准分类基准测试中表现出色，并且在特定任务上通过使用任务特定指标进行评估时也优于现有最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;该基于Transformer架构的基础模型对于高能粒子对撞机中的各种任务具有潜力，特别是在分类和识别不同类型喷注方面。它展示了良好的泛化能力和强大的学习能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：我们提出了一种用于大型强子对撞器等高能粒子对撞机任务的基于Transformer架构的基础模型。我们利用自监督策略训练该模型进行喷注分类，这种方法受到联合嵌入预测体系结构的启发。使用包含1亿个各种已知粒子的喷注的JetClass数据集对该模型进行了预训练，采用了一种以数据为中心的方法——即模型利用部分喷注成分作为上下文来预测未见目标成分的嵌入。我们的预训练模型在其他标准分类基准测试数据集中表现出色，并且我们在两个额外下游任务上对其性能进行了评估：顶夸克标记和区分轻夸克喷注与胶子喷注。我们还使用任务特定指标及基线对该模型进行评价，并将其与高能物理学中的最新模型进行了比较。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a transformer architecture-based foundation model for tasks athigh-energy particle colliders such as the Large Hadron Collider. We train themodel to classify jets using a self-supervised strategy inspired by the JointEmbedding Predictive Architecture. We use the JetClass dataset containing 100Mjets of various known particles to pre-train the model with a data-centricapproach -- the model uses a fraction of the jet constituents as the context topredict the embeddings of the unseen target constituents. Our pre-trained modelfares well with other datasets for standard classification benchmark tasks. Wetest our model on two additional downstream tasks: top tagging anddifferentiating light-quark jets from gluon jets. We also evaluate our modelwith task-specific metrics and baselines and compare it with state-of-the-artmodels in high-energy physics. Project site: https://hep-jepa.github.io/</description>
      <author>example@mail.com (Jai Bardhan, Radhikesh Agrawal, Abhiram Tilak, Cyrin Neeraj, Subhadip Mitra)</author>
      <guid isPermaLink="false">2502.03933v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Simplicial Hausdorff Distance for Topological Data Analysis</title>
      <link>http://arxiv.org/abs/2502.03744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个修正的Hausdorff距离，将几何接近度与单纯复形（simplicial complex）的拓扑特征相结合。同时给出了过滤复杂性的单纯Hausdorff度量版本，并探讨了测量函数单调性的问题。&lt;h4&gt;背景&lt;/h4&gt;许多实际应用中涉及的数据形式为点云数据，这些数据会生成单纯复形。单纯复形的组合结构捕获了元素之间的拓扑关系，而其几何实现则提供了可视化和理解几何性质的具体方法。&lt;h4&gt;目的&lt;/h4&gt;为了更好地结合几何接近度与单纯复形的拓扑特性，提出了一种扩展度量——修正Hausdorff距离，并研究过滤单纯复形中的计算复杂性问题。&lt;h4&gt;方法&lt;/h4&gt;引入了修正Hausdorff距离作为扩展度量，适用于具有组合和几何结构的单纯复形。此外还给出了针对过滤复形版本的单纯Hausdorff度量。&lt;h4&gt;主要发现&lt;/h4&gt;提出了用于表示拓扑数据分析应用中点云数据的新度量方法，并讨论了测量函数单调性问题以及其对整体框架的影响。&lt;h4&gt;结论&lt;/h4&gt;修正后的Hausdorff距离为单纯复形提供了新的几何和组合度量工具，有利于进一步理解复杂结构的特性及其在不同场景中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many practical applications in topological data analysis arise from data inthe form of point clouds, which then yield simplicial complexes. Thecombinatorial structure of simplicial complexes captures the topologicalrelationships between the elements of the complex. In addition to thecombinatorial structure, simplicial complexes possess a geometric realizationthat provides a concrete way to visualize the complex and understand itsgeometric properties. This work presents an amended Hausdorff distance as anextended metric that integrates geometric proximity with the topologicalfeatures of simplicial complexes. We also present a version of the simplicialHausdorff metric for filtered complexes and show results on its computationalcomplexity. In addition, we discuss concerns about the monotonicity of themeasurement functions involved in the setup of the simplicial complexes.</description>
      <author>example@mail.com (Nkechi Nnadi, Daniel Isaksen)</author>
      <guid isPermaLink="false">2502.03744v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards characterizing dark matter subhalo perturbations in stellar streams with graph neural networks</title>
      <link>http://arxiv.org/abs/2502.03522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用图卷积神经网络（GCNN）数据压缩和基于模拟的推理技术，改进了通过银河系中GD-1类似星流探测暗物质子结构质量约束的方法。&lt;h4&gt;背景&lt;/h4&gt;在冷暗物质模型及其替代方案下，星流相空间被提议用于检测由穿过次晕造成的扰动来识别暗物质亚结构。&lt;h4&gt;目的&lt;/h4&gt;通过模拟GD-1类似星流并使用GCNN和SBI方法改进对不同质量的穿行次晕的约束。&lt;h4&gt;方法&lt;/h4&gt;首先利用图卷积神经网络（GCNN）数据压缩技术，然后结合基于模拟的推理技术（SBI），用以估计次晕质量和速度的联合后验概率。研究了GCNN大小、输入坐标系统和不完整观测的影响。&lt;h4&gt;主要发现&lt;/h4&gt;与当前最先进的密度功率谱分析相比，在模拟的GD-1类似星流中利用GCNN可将对不同质量范围（$10^8$, $10^7$, $10^6$）次晕的质量约束提高了11、7和3倍。发现GCNN产生的后验概率比密度功率谱更准确。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，利用具有完整六维相空间数据的小样本量（例如300颗星），其效果可媲美只具备三维数据的大样本量（例如3000颗星）。这激发了未来GCNN在结合光度、光谱和天体测量流观测方面的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译版本&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The phase space of stellar streams is proposed to detect dark substructure inthe Milky Way through the perturbations created by passing subhalos - and thusis a powerful test of the cold dark matter paradigm and its alternatives. Usinggraph convolutional neural network (GCNN) data compression and simulation-basedinference (SBI) on a simulated GD-1-like stream, we improve the constraint onthe mass of a [$10^8$, $10^7$, $10^6$] $M_\odot$ perturbing subhalo by factorsof [11, 7, 3] with respect to the current state-of-the-art density powerspectrum analysis. We find that the GCNN produces posteriors that are moreaccurate (better calibrated) than the power spectrum. We simulate the positionsand velocities of stars in a GD-1-like stream and perturb the stream withsubhalos of varying mass and velocity. Leveraging the feature encoding of theGCNN to compress the input phase space data, we then use SBI to estimate thejoint posterior of the subhalo mass and velocity. We investigate how ourresults scale with the size of the GCNN, the coordinate system of the input andthe effect of incomplete observations. Our results suggest that a survey with$10 \times$ fewer stars (300 stars) with complete 6-D phase space data performsabout as well as a deeper survey (3000 stars) with only 3-D data (photometry,spectroscopy). The stronger constraining power and more accurate posteriorestimation motivate further development of GCNNs in combining futurephotometric, spectroscopic and astrometric stream observations.</description>
      <author>example@mail.com (Peter Xiangyuan Ma, Keir K. Rogers, Ting S. Li, Renée Hložek, Jeremy Webb, Ruth Huang, Julian Meunier)</author>
      <guid isPermaLink="false">2502.03522v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>No Free Lunch in Annotation either: An objective evaluation of foundation models for streamlining annotation in animal tracking</title>
      <link>http://arxiv.org/abs/2502.03907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  \c{opyright} 2025 IEEE. Personal use of this material is permitted.  Permission from IEEE must be obtained for all other uses, in any current or  future media, including reprinting/republishing this material for advertising  or promotional purposes, creating new collective works, for resale or  redistribution to servers or lists, or reuse of any copyrighted component of  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了基础模型在动物跟踪数据注释生成中的应用，强调高质量的注释对于训练出准确和鲁棒性强的跟踪模型的重要性。&lt;h4&gt;背景&lt;/h4&gt;在动物追踪中，标注大量数据是必不可少的，这直接关系到跟踪模型的鲁棒性。但是仅依赖于自动化生成的数据标注可能会引入噪音和不准确性。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用基础模型生成高质量注释的同时保持模型性能不受影响，并寻找最佳的数据注释策略。&lt;h4&gt;方法&lt;/h4&gt;通过比较纯手工标注数据与结合自动标注和手动检查的混合策略在IDF1得分上的表现来评估不同的注释技术的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;综合使用自动化注释和人工审核的方法能够显著提高模型的表现（IDF1得分为80.8），而仅依赖于基础模型SAM2video进行自动标注则会导致性能下降（IDF1得分为65.6）。&lt;h4&gt;结论&lt;/h4&gt;为了确保高质量的训练数据，需要在自动化注释工具和人工审查之间找到平衡点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We analyze the capabilities of foundation models addressing the tedious taskof generating annotations for animal tracking. Annotating a large amount ofdata is vital and can be a make-or-break factor for the robustness of atracking model. Robustness is particularly crucial in animal tracking, asaccurate tracking over long time horizons is essential for capturing thebehavior of animals. However, generating additional annotations usingfoundation models can be counterproductive, as the quality of the annotationsis just as important. Poorly annotated data can introduce noise andinaccuracies, ultimately compromising the performance and accuracy of thetrained model. Over-reliance on automated annotations without ensuringprecision can lead to diminished results, making careful oversight and qualitycontrol essential in the annotation process. Ultimately, we demonstrate that athoughtful combination of automated annotations and manually annotated data isa valuable strategy, yielding an IDF1 score of 80.8 against blind usage of SAM2video with an IDF1 score of 65.6.</description>
      <author>example@mail.com (Emil Mededovic, Valdy Laurentius, Yuli Wu, Marcin Kopaczka, Zhu Chen, Mareike Schulz, René Tolba, Johannes Stegmaier)</author>
      <guid isPermaLink="false">2502.03907v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Classification of Solar Radio Spectrum Based on Swin Transformer</title>
      <link>http://arxiv.org/abs/2502.03782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于Swin变换器的太阳射电光谱分类方法，能够实现100%的确诊率，并且模型参数数量仅为20百万，远低于传统的VGG16卷积神经网络。&lt;h4&gt;背景&lt;/h4&gt;太阳射电观测是一种研究太阳的方法，对于空间天气预警和日球物理研究而言，自动实时地对太阳射电光谱进行分类并判断是否有太阳射电爆发非常重要。然而，由于太阳射电爆发的样本量少且分布不均。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Swin变换器的太阳射电光谱分类方法。&lt;h4&gt;方法&lt;/h4&gt;首先将预训练模型的参数迁移到Swin变换器模型中；然后冻结Swin变换器隐藏层权重，仅对全连接层在目标数据集上进行训练；最后进行参数调优。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够达到100%的确诊率，并且比先前的方法更准确。此外，该模型的参数数量仅为20百万，远低于传统VGG16卷积神经网络（后者具有超过1亿3千万个参数）。&lt;h4&gt;结论&lt;/h4&gt;基于Swin变换器的方法在太阳射电光谱分类中展现了优越性能和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：太阳射电观测是一种研究太阳的方法。对于空间天气预警和日球物理研究来说，自动实时地对太阳射电光谱进行分类并判断是否有太阳射电爆发非常重要。由于太阳射电爆发的样本量少且分布不均，本文提出了一种基于Swin变换器的太阳射电光谱分类方法。首先将预训练模型的参数迁移到Swin变换器模型中；然后冻结Swin变换器隐藏层权重，仅对全连接层在目标数据集上进行训练；最后进行参数调优。实验结果表明，该方法能够实现100%的确诊率，并且比先前的方法更准确。此外，该模型的参数数量仅为20百万，远低于传统VGG16卷积神经网络（后者具有超过1亿3千万个参数）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/universe9010009&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Solar radio observation is a method used to study the Sun. It is veryimportant for space weather early warning and solar physics research toautomatically classify solar radio spectrums in real time and judge whetherthere is a solar radio burst. As the number of solar radio burst spectrums issmall and uneven, this paper proposes a classification method for solar radiospectrums based on the Swin transformer. First, the method transfers theparameters of the pretrained model to the Swin transformer model. Then, thehidden layer weights of the Swin transformer are frozen, and the fullyconnected layer of the Swin transformer is trained on the target dataset.Finally, pa-rameter tuning is performed. The experimental results show that themethod can achieve a true positive rate of 100%, which is more accurate thanprevious methods. Moreover, the number of our model parameters is only 20million, which is 80% lower than that of the traditional VGG16 con-volutionalneural network with more than 130 million parameters.</description>
      <author>example@mail.com (Jian Chen, Guowu Yuan, Hao Zhou, Chengming Tan, Lei Yang, Siqi Li)</author>
      <guid isPermaLink="false">2502.03782v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Omni-DNA: A Unified Genomic Foundation Model for Cross-Modal and Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2502.03499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Omni-DNA是一个基于Transformer的跨模态多任务模型家族，参数量从2000万到10亿不等。该研究旨在解决基因组基础模型在不同下游应用中需要单独微调的问题，并通过引入新的预训练和联合微调方法来提升其性能。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多种任务上表现出卓越的泛化能力，而基因组基础模型（GFMs）则因输出格式固定而在各种基因组任务的应用中受限。现有的GFMs需要为每个下游应用单独进行微调，随着模型规模的增长带来了显著的工作负担。&lt;h4&gt;目的&lt;/h4&gt;提出Omni-DNA家族模型，通过预训练和多任务联合微调解决现有GFMs的局限性问题，并扩大其在基因组学中的应用场景。&lt;h4&gt;方法&lt;/h4&gt;该研究包括两个阶段：首先，在DNA序列上进行基于下一令牌预测目标的预训练；然后，扩展特定于模态的任务标记并针对多个下游任务同时进行微调。引入两种复杂的基因组任务：DNA2Function和Needle-in-DNA，分别将DNA序列映射为文本功能描述和图像。&lt;h4&gt;主要发现&lt;/h4&gt;Omni-DNA在Nucleotide Transformer和GB基准测试的26个任务中取得了18项最佳性能，尤其在乙酰化和甲基化任务方面表现突出。此外，它展示了跨模态的能力，拓宽了基因组应用范围。&lt;h4&gt;结论&lt;/h4&gt;通过预训练和多任务微调方法，Omni-DNA克服了现有GFMs的限制，在多个下游任务中实现了优越性能，并表明其具有广泛的基因组学应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在多种任务上表现出卓越的泛化能力，而基因组基础模型（GFMs）则因输出格式固定而在各种基因组任务的应用中受限。现有的GFMs需要为每个下游应用单独进行微调，随着模型规模的增长带来了显著的工作负担。在此工作中，我们回顾了基于Transformer的自回归模型，并引入了Omni-DNA家族模型，参数量从2000万到10亿不等。我们的方法包括两个阶段：（i）在DNA序列上进行预训练，目标是下一令牌预测；以及（ii）扩展特定于模态的任务标记并针对多个下游任务同时微调。当评估Nucleotide Transformer和GB基准时，Omni-DNA在26个任务中的18项中取得了最佳性能。通过多任务微调，Omni-DNA一次性解决了乙酰化和甲基化的10项任务，超越了单独训练每个任务的模型。最后，我们设计了两种复杂的基因组任务：DNA2Function（将DNA序列映射为文本功能描述）和Needle-in-DNA（将DNA序列映射为图像），表明Omni-DNA具有跨模态能力以扩大基因组应用范围。所有这些模型都可以通过https://huggingface.co/collections/zehui127获得&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) demonstrate remarkable generalizability acrossdiverse tasks, yet genomic foundation models (GFMs) still require separatefinetuning for each downstream application, creating significant overhead asmodel sizes grow. Moreover, existing GFMs are constrained by rigid outputformats, limiting their applicability to various genomic tasks. In this work,we revisit the transformer-based auto-regressive models and introduce Omni-DNA,a family of cross-modal multi-task models ranging from 20 million to 1 billionparameters. Our approach consists of two stages: (i) pretraining on DNAsequences with next token prediction objective, and (ii) expanding themulti-modal task-specific tokens and finetuning for multiple downstream taskssimultaneously. When evaluated on the Nucleotide Transformer and GB benchmarks,Omni-DNA achieves state-of-the-art performance on 18 out of 26 tasks. Throughmulti-task finetuning, Omni-DNA addresses 10 acetylation and methylation tasksat once, surpassing models trained on each task individually. Finally, wedesign two complex genomic tasks, DNA2Function and Needle-in-DNA, which map DNAsequences to textual functional descriptions and images, respectively,indicating Omni-DNA's cross-modal capabilities to broaden the scope of genomicapplications. All the models are available throughhttps://huggingface.co/collections/zehui127</description>
      <author>example@mail.com (Zehui Li, Vallijah Subasri, Yifei Shen, Dongsheng Li, Yiren Zhao, Guy-Bart Stan, Caihua Shan)</author>
      <guid isPermaLink="false">2502.03499v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of FPGA and GPU Performance for Machine Learning-Based Track Reconstruction at LHCb</title>
      <link>http://arxiv.org/abs/2502.02304v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;高能物理领域数据处理需求的背景介绍和机器学习技术的应用评估。&lt;h4&gt;总结&lt;/h4&gt;该论文探讨了在大型强子对撞机实验中，通过比较现场可编程门阵列(FPGA)与图形处理器(GPU)在多层感知器(MLP)模型推理中的性能差异，来优化高能物理实验中的数据处理流程。重点在于FPGAs可能比GPUs提供更高的吞吐量和更低的延迟。&lt;h4&gt;背景&lt;/h4&gt;大型强子对撞机(LHC)中不断增加的亮度和探测器颗粒度导致了更高效的数据处理解决方案需求的增长。机器学习，特别是基于图神经网络的算法，在粒子轨迹重建中的应用显示出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;比较FPGA和GPU在多层感知器模型推理上的吞吐量性能，并展示FPGAs在未来高能物理实验中作为高性能、低延迟推断平台的可能性。&lt;h4&gt;方法&lt;/h4&gt;使用HLS4ML工具将机器学习模型部署到FPGA上，然后与相同模型的GPU实现进行基准测试。重点是在LHCb实验第一级触发中的轨迹重建管道的第一步。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，在不需专业知识的情况下，FPGAs能够提供比GPUs更高的推断吞吐量和更低延迟，并且耗电量显著降低。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了在高能物理实验中使用FPGA作为机器学习模型推理平台的潜在优势，尤其是在追求高效、低功耗解决方案的应用场景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In high-energy physics, the increasing luminosity and detector granularity atthe Large Hadron Collider are driving the need for more efficient dataprocessing solutions. Machine Learning has emerged as a promising tool forreconstructing charged particle tracks, due to its potentially linearcomputational scaling with detector hits. The recent implementation of a graphneural network-based track reconstruction pipeline in the first level triggerof the LHCb experiment on GPUs serves as a platform for comparative studiesbetween computational architectures in the context of high-energy physics. Thispaper presents a novel comparison of the throughput of ML model inferencebetween FPGAs and GPUs, focusing on the first step of the track reconstructionpipeline$\unicode{x2013}$an implementation of a multilayer perceptron. UsingHLS4ML for FPGA deployment, we benchmark its performance against the GPUimplementation and demonstrate the potential of FPGAs for high-throughput,low-latency inference without the need for an expertise in FPGA development andwhile consuming significantly less power.</description>
      <author>example@mail.com (Fotis I. Giasemis, Vladimir Lončar, Bertrand Granado, Vladimir Vava Gligorov)</author>
      <guid isPermaLink="false">2502.02304v2</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>SMART: Advancing Scalable Map Priors for Driving Topology Reasoning</title>
      <link>http://arxiv.org/abs/2502.04329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025. Project page: https://jay-ye.github.io/smart&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SMART是一种利用标准定义（SD）和卫星地图学习道路拓扑模型的可扩展解决方案，它独立于传感器设置，并且能够显著提高自主驾驶中车道理解的能力。&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶领域，拓扑推理对于全面了解车道之间的连接性和关系至关重要。然而，现有的方法依赖于特定配置车辆传感器捕获的数据，这限制了其应用范围和可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种不受传感器依赖影响的解决方案，以实现大规模车道感知和拓扑推理。&lt;h4&gt;方法&lt;/h4&gt;SMART通过大型地理参考高精度（HD）地图指导的标准定义（SD）和卫星地图学习地图先验模型。该系统能够在仅使用SD和卫星输入的情况下实现卓越的离线车道理解性能，并能无缝集成到任何在线拓扑推理方法中，从而提高其性能。&lt;h4&gt;主要发现&lt;/h4&gt;SMART在OpenLane-V2基准测试上取得了显著改进，提高了高达28%的表现。&lt;h4&gt;结论&lt;/h4&gt;SMART提供了一种新的可扩展性方案来解决自动驾驶中的车道感知和拓扑推理问题，通过利用现有的地图资源克服了传统方法对传感器数据的依赖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topology reasoning is crucial for autonomous driving as it enablescomprehensive understanding of connectivity and relationships between lanes andtraffic elements. While recent approaches have shown success in perceivingdriving topology using vehicle-mounted sensors, their scalability is hinderedby the reliance on training data captured by consistent sensor configurations.We identify that the key factor in scalable lane perception and topologyreasoning is the elimination of this sensor-dependent feature. To address this,we propose SMART, a scalable solution that leverages easily availablestandard-definition (SD) and satellite maps to learn a map prior model,supervised by large-scale geo-referenced high-definition (HD) maps independentof sensor settings. Attributed to scaled training, SMART alone achievessuperior offline lane topology understanding using only SD and satelliteinputs. Extensive experiments further demonstrate that SMART can be seamlesslyintegrated into any online topology reasoning methods, yielding significantimprovements of up to 28% on the OpenLane-V2 benchmark.</description>
      <author>example@mail.com (Junjie Ye, David Paz, Hengyuan Zhang, Yuliang Guo, Xinyu Huang, Henrik I. Christensen, Yue Wang, Liu Ren)</author>
      <guid isPermaLink="false">2502.04329v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>DexterityGen: Foundation Controller for Unprecedented Dexterity</title>
      <link>http://arxiv.org/abs/2502.04307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project: https://zhaohengyin.github.io/dexteritygen&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要描述了一种新的机器人训练方法DexterityGen（简称DexGen），该方法结合了强化学习和人类远程操作的优势，用于训练复杂的灵巧抓握技能。通过预训练大规模的运动基本动作，并利用这些数据来优化一个基础控制器，在实际环境中可以实现高精度的操作。&lt;h4&gt;背景&lt;/h4&gt;当前机器人学习灵巧操作的方法主要分为两种：人类遥操作（用于模仿学习）和仿真到现实环境中的强化学习方法，但是两者都存在显著的挑战。人类很难在没有触觉反馈的情况下远程控制不同实体的机械臂执行安全且灵巧的动作，而基于强化学习的方法则难以克服从模拟到真实场景之间的差距，并需要针对复杂任务进行高度特定的任务奖励工程。&lt;h4&gt;目的&lt;/h4&gt;探索并提出一种结合了人类命令和机器学习方法的新策略来解决机器人灵巧操作训练的问题。&lt;h4&gt;方法&lt;/h4&gt;DexterityGen（DexGen）首先利用强化学习预训练大规模的灵巧运动基本动作，如手内旋转和平移。然后使用这个预训练的数据集来训练一个基础控制器，在实际环境中通过人类遥操作提示该控制器产生高度灵活的行为。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和现实世界中的测试显示，DexGen是一种通用控制器，能够实现输入的灵巧抓握命令，并显著提高了稳定性（通过物体保持时间测量为10-100倍）。更重要的是，它首次展示了前所未有的复杂技能，包括多样化的物体重新定向以及笔、注射器和螺丝刀等工具使用的灵巧操作。&lt;h4&gt;结论&lt;/h4&gt;DexterityGen提供了一种新颖且有效的方法来训练机器人执行复杂的灵巧任务，结合了人类的直观指导能力和机器学习算法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Teaching robots dexterous manipulation skills, such as tool use, presents asignificant challenge. Current approaches can be broadly categorized into twostrategies: human teleoperation (for imitation learning) and sim-to-realreinforcement learning. The first approach is difficult as it is hard forhumans to produce safe and dexterous motions on a different embodiment withouttouch feedback. The second RL-based approach struggles with the domain gap andinvolves highly task-specific reward engineering on complex tasks. Our keyinsight is that RL is effective at learning low-level motion primitives, whilehumans excel at providing coarse motion commands for complex, long-horizontasks. Therefore, the optimal solution might be a combination of bothapproaches. In this paper, we introduce DexterityGen (DexGen), which uses RL topretrain large-scale dexterous motion primitives, such as in-hand rotation ortranslation. We then leverage this learned dataset to train a dexterousfoundational controller. In the real world, we use human teleoperation as aprompt to the controller to produce highly dexterous behavior. We evaluate theeffectiveness of DexGen in both simulation and real world, demonstrating thatit is a general-purpose controller that can realize input dexterousmanipulation commands and significantly improves stability by 10-100x measuredas duration of holding objects across diverse tasks. Notably, with DexGen wedemonstrate unprecedented dexterous skills including diverse objectreorientation and dexterous tool use such as pen, syringe, and screwdriver forthe first time.</description>
      <author>example@mail.com (Zhao-Heng Yin, Changhao Wang, Luis Pineda, Francois Hogan, Krishna Bodduluri, Akash Sharma, Patrick Lancaster, Ishita Prasad, Mrinal Kalakrishnan, Jitendra Malik, Mike Lambeta, Tingfan Wu, Pieter Abbeel, Mustafa Mukadam)</author>
      <guid isPermaLink="false">2502.04307v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning Real-World Action-Video Dynamics with Heterogeneous Masked Autoregression</title>
      <link>http://arxiv.org/abs/2502.04296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://liruiw.github.io/hma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Heterogeneous Masked Autoregression (HMA) 的新模型，用于生成高质量的机器人视频数据和评价，在扩展机器人学习方面具有重要应用。&lt;h4&gt;背景&lt;/h4&gt;构建交互式视频世界模型及政策对于机器人来说颇具挑战性，特别是在处理多样化环境的同时保持计算效率以实现实时运行。&lt;h4&gt;目的&lt;/h4&gt;通过观察和不同机器人实体、领域以及任务中的动作序列进行异构预训练来解决上述问题，并使用遮蔽自回归生成量化或软标记的视频预测。&lt;h4&gt;方法&lt;/h4&gt;HMA利用了来自不同物理形态机器人的观测数据和行动序列进行异质性预训练；模型采用屏蔽自动回归技术，用于生成高质量、高逼真的视频预测结果。&lt;h4&gt;主要发现&lt;/h4&gt;相较于之前机器人视频生成模型，HMA在保持视觉真实性和可控制性的前提下，运行速度提高了15倍。&lt;h4&gt;结论&lt;/h4&gt;经过后期训练后，该模型可以作为从低级动作输入进行视频仿真的工具，用于评估政策和产生合成数据。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种异构屏蔽自回归（HMA）模型，旨在通过处理不同机器人实体、任务域中的观察数据及行动序列来进行混合预训练，生成逼真且具备可控性的视频数据。此模型能以15倍的速度优于现有机器人视频生成系统，并支持从低级动作输入到视频仿真的转换过程，为政策评估和合成数据生成提供了有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Heterogeneous Masked Autoregression (HMA) for modelingaction-video dynamics to generate high-quality data and evaluation in scalingrobot learning. Building interactive video world models and policies forrobotics is difficult due to the challenge of handling diverse settings whilemaintaining computational efficiency to run in real time. HMA usesheterogeneous pre-training from observations and action sequences acrossdifferent robotic embodiments, domains, and tasks. HMA uses maskedautoregression to generate quantized or soft tokens for video predictions.\ourshort achieves better visual fidelity and controllability than the previousrobotic video generation models with 15 times faster speed in the real world.After post-training, this model can be used as a video simulator from low-levelaction inputs for evaluating policies and generating synthetic data. See thislink https://liruiw.github.io/hma for more information.</description>
      <author>example@mail.com (Lirui Wang, Kevin Zhao, Chaoqi Liu, Xinlei Chen)</author>
      <guid isPermaLink="false">2502.04296v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Compliant Beaded-String Jamming For Variable Stiffness Anthropomorphic Fingers</title>
      <link>http://arxiv.org/abs/2502.04190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 9 figures, accepted by the 8th IEEE-RAS International  Conference on Soft Robotics, RoboSoft 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于仿人手指的柔顺关节夹紧机制，该机制具备被动残余顺应性和可调刚度，并且其运动范围与人类指节关节相匹配。&lt;h4&gt;背景&lt;/h4&gt;实现类人的机器人抓手灵巧性仍然是一个未解决的问题，尤其是在不确定环境中确保牢固操作方面。软体机器人手通过利用被动柔顺性来增强适应性以达到更牢固的操作，同时减少对高分辨率传感器和复杂控制的依赖。&lt;h4&gt;目的&lt;/h4&gt;研究旨在改进精度和操纵任务中的姿态稳定性，并引入一种新的机制，该机制可以解决现有可变刚度机构所面临的问题：缺乏残余顺应性、体积庞大且响应缓慢。&lt;h4&gt;方法&lt;/h4&gt;提出了一种用于仿人手指的柔顺关节夹紧机制。通过控制夹紧力来调整其刚度范围（0.48 Nm/rad 到 1.95 Nm/rad，增加四倍）。还对重复性、滞回现象和刚度进行了表征。&lt;h4&gt;主要发现&lt;/h4&gt;所提出系统提供的被动残余顺应性的重要性通过执行一个插销孔任务得到了展示。结果表明，与硬手指相比，集成该关节设计的抓手成功率为60%更高。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一种新颖的方法来解决机器人手指在不确定环境中操作时面临的挑战，并且可以通过进一步的研究和应用来改善机械手的整体性能。&lt;h4&gt;翻译&lt;/h4&gt;实现类人灵巧性的机器人抓取器仍然是一个开放性问题，尤其是在不确定环境中的牢固操纵方面。软体机器手臂尝试通过利用被动柔顺性（这种特性对于人类手的适应性至关重要）来增强操作的坚固性，并减少对高分辨率传感器和复杂控制系统的依赖。通过整合可变刚度机制进一步提高了精度和操作任务中姿态稳定性，但这些机制往往缺乏残余柔顺性、体积庞大且响应缓慢。为了克服这些限制，本工作引入了一种用于仿人手指的柔顺关节夹紧机制，其具有被动残余柔顺性和可调刚度，并实现了与人类指间关节相匹配的运动范围。该机制提供的刚度范围可控在0.48 Nm/rad至1.95 Nm/rad（增加四倍）。通过控制夹紧力来表征重复性、滞回现象和刚度特性。为了展示所提出系统所提供的被动残余柔顺性的关键作用，进行了一项插销孔任务，显示了集成我们关节设计的抓手在与硬式手指相比时成功率为60%更高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving human-like dexterity in robotic grippers remains an open challenge,particularly in ensuring robust manipulation in uncertain environments. Softrobotic hands try to address this by leveraging passive compliance, acharacteristic that is crucial to the adaptability of the human hand, toachieve more robust manipulation while reducing reliance on high-resolutionsensing and complex control. Further improvements in terms of precision andpostural stability in manipulation tasks are achieved through the integrationof variable stiffness mechanisms, but these tend to lack residual compliance,be bulky and have slow response times. To address these limitations, this workintroduces a Compliant Joint Jamming mechanism for anthropomorphic fingers thatexhibits passive residual compliance and adjustable stiffness, while achievinga range of motion in line with that of human interphalangeal joints. Thestiffness range provided by the mechanism is controllable from 0.48 Nm/rad to1.95 Nm/rad (a 4x increase). Repeatability, hysteresis and stiffness were alsocharacterized as a function of the jamming force. To demonstrate the importanceof the passive residual compliance afforded by the proposed system, apeg-in-hole task was conducted, which showed a 60% higher success rate for agripper integrating our joint design when compared to a rigid one.</description>
      <author>example@mail.com (Maximilian Westermann, Marco Pontin, Leone Costi, Alessandro Albini, Perla Maiolino)</author>
      <guid isPermaLink="false">2502.04190v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Dense Fixed-Wing Swarming using Receding-Horizon NMPC</title>
      <link>http://arxiv.org/abs/2502.04174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;该论文介绍了一种控制一组敏捷固定翼飞行器在彼此近距离内自主操作的方法。&lt;h4&gt;背景&lt;/h4&gt;现有的方法难以实现多架固定翼无人机在狭小空间内的安全协作。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于非线性模型预测控制（NMPC）的方案，以规划机动动作并避免相互碰撞。&lt;h4&gt;方法&lt;/h4&gt;利用退化时域非线性模型预测控制技术来制定飞行计划，并计算系统脱离预定轨迹管的概率统计界限。&lt;h4&gt;主要发现&lt;/h4&gt;提出了评估动态集群的新指标，并通过模拟和硬件实验验证了该方法的有效性，这是首次实现物理特技固定翼无人机的近距离编队操作。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效避免多架固定翼飞行器之间的碰撞，在狭小空间内实现安全协作。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们展示了如何控制一组敏捷固定翼无人飞行器在彼此间紧密接近的情况下进行自主操作。我们的方法基于退化时域非线性模型预测控制(NMPC)，用于规划涵盖扩大飞行包络的机动动作以防止相互碰撞。为了促进稳健的避撞和表征相互碰撞的可能性，我们计算了系统离开围绕计划轨迹管的概率统计界限。此外，我们还提出了一种评估高度动态集群的新指标，并利用此指标来评估我们的方法。通过模拟和硬件实验成功展示了我们的方案，据我们所知，这是首次实现具有物理特技能力的固定翼无人机在近距离内编队操作的技术成就。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an approach for controlling a team of agilefixed-wing aerial vehicles in close proximity to one another. Our approachrelies on receding-horizon nonlinear model predictive control (NMPC) to planmaneuvers across an expanded flight envelope to enable inter-agent collisionavoidance. To facilitate robust collision avoidance and characterize thelikelihood of inter-agent collisions, we compute a statistical bound on theprobability of the system leaving a tube around the planned nominal trajectory.Finally, we propose a metric for evaluating highly dynamic swarms and use thismetric to evaluate our approach. We successfully demonstrated our approachthrough both simulation and hardware experiments, and to our knowledge, thisthe first time close-quarters swarming has been achieved with physicalaerobatic fixed-wing vehicles.</description>
      <author>example@mail.com (Varun Madabushi, Yocheved Kopel, Adam Polevoy, Joseph Moore)</author>
      <guid isPermaLink="false">2502.04174v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>From Configuration-Space Clearance to Feature-Space Margin: Sample Complexity in Learning-Based Collision Detection</title>
      <link>http://arxiv.org/abs/2502.04170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文探讨了基于学习的机器人运动规划中的碰撞检测问题，特别关注支持向量机（SVM）在评估机器人配置是否无碰撞方面的应用。&lt;h4&gt;背景&lt;/h4&gt;机器人的运动规划是当前研究的一个重要领域，而基于学习的方法近年来受到了广泛关注。然而，在这些方法的支持理论方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;填补现有的理论空白，通过分析用于基于学习的碰撞检测的SVM分类器的样本复杂性来支持其效率和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于理论结果的新算法，该算法可以为机器人的配置是否无碰撞提供统计保证。&lt;h4&gt;主要发现&lt;/h4&gt;这项研究界定了实现给定精度所需样本数量的界限，并以此为基础提出了一种能够给出误差概率范围的碰撞检测算法。&lt;h4&gt;结论&lt;/h4&gt;通过建立SVM在机器人运动规划中的应用理论基础，提高了基于学习的方法在实际场景中的可靠性和效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：运动规划是机器人技术的核心挑战之一，在过去几年里，基于学习的方法得到了极大的关注。我们专注于这些方法的一个特定方面：使用机器学习技术（特别是支持向量机SVM）来评估机器人的配置是否为无碰撞状态，这个操作被称为‘碰撞检测’。尽管这种方法越来越受欢迎，但在理论支持上仍然存在空白，特别是在机器学习方法和SVM的效率及预测准确性方面更是如此。我们的研究通过分析用于基于学习的运动规划中的SVM分类器的学习样本复杂性来填补这一空白，并设定了在给定置信水平下实现指定精度所需的样本数界限。该结果以机器人运动规划中相关的术语，如系统的安全距离表示出来。基于这些理论成果，我们提出了一个碰撞检测算法，它可以为机器人的配置是否无碰撞提供统计保证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning is a central challenge in robotics, with learning-basedapproaches gaining significant attention in recent years. Our work focuses on aspecific aspect of these approaches: using machine-learning techniques,particularly Support Vector Machines (SVM), to evaluate whether robotconfigurations are collision free, an operation termed ``collision detection''.Despite the growing popularity of these methods, there is a lack of theorysupporting their efficiency and prediction accuracy. This is in stark contrastto the rich theoretical results of machine-learning methods in general and ofSVMs in particular. Our work bridges this gap by analyzing the samplecomplexity of an SVM classifier for learning-based collision detection inmotion planning. We bound the number of samples needed to achieve a specifiedaccuracy at a given confidence level. This result is stated in terms relevantto robot motion-planning such as the system's clearance. Building on thesetheoretical results, we propose a collision-detection algorithm that can alsoprovide statistical guarantees on the algorithm's error in classifying robotconfigurations as collision-free or not.</description>
      <author>example@mail.com (Sapir Tubul, Aviv Tamar, Kiril Solovey, Oren Salzman)</author>
      <guid isPermaLink="false">2502.04170v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Making Sense of Touch: Unsupervised Shapelet Learning in Bag-of-words Sense</title>
      <link>http://arxiv.org/abs/2502.04167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种名为NN-STNE的神经网络，使用t分布随机邻域嵌入(t-SNE)作为隐藏层以减少长时间序列数据的输入维度。&lt;h4&gt;背景&lt;/h4&gt;现有的特征学习方法在处理高维的时间序列数据时面临挑战，特别是在低维空间中的拥挤问题和非凸优化难题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的神经网络框架NN-STNE来改进时间和电气组件操作任务上的聚类准确度。&lt;h4&gt;方法&lt;/h4&gt;{'t-SNE': '用于将长时间序列数据映射为形状成员概率以减少输入维度，缓解低维空间中的拥挤问题', 'Gaussian核基均方误差': '保留局部数据结构', 'K-means算法': '初始化形体候选物以应对非凸优化挑战', 'L1范数正则化': '用于优化形状长度'}&lt;h4&gt;主要发现&lt;/h4&gt;在UCR数据集和电气组件操作任务上的实验表明，与现有的最先进的特征学习方法相比，NN-STNE的聚类准确度得到了提高。&lt;h4&gt;结论&lt;/h4&gt;提出的神经网络框架能够有效解决时间序列数据中的低维拥挤问题，并提供比现有方法更优的聚类性能&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种新的神经网络方法——NN-STNE，该方法通过在模型中使用t-SNE来将长的时间序列数据映射到形状成员概率上，从而实现输入维度的降低。相较于其他方法，在低维空间中使用t-SNE能够更有效地解决拥挤问题，并且利用L1范数正则化技术优化形体长度。此外，该研究还采用了基于高斯核的均方误差来保持局部数据结构的完整性以及K-means算法作为初始化候选形状的方法以应对非凸优化难题。实验结果表明，在UCR数据集和电气组件操作任务上（如开关切换），NN-STNE相较于当前最先进的时间序列特征学习方法展现出了更高的聚类准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces NN-STNE, a neural network using t-distributedstochastic neighbor embedding (t-SNE) as a hidden layer to reduce inputdimensions by mapping long time-series data into shapelet membershipprobabilities. A Gaussian kernel-based mean square error preserves local datastructure, while K-means initializes shapelet candidates due to the non-convexoptimization challenge. Unlike existing methods, our approach uses t-SNE toaddress crowding in low-dimensional space and applies L1-norm regularization tooptimize shapelet length. Evaluations on the UCR dataset and an electricalcomponent manipulation task, like switching on, demonstrate improved clusteringaccuracy over state-of-the-art feature-learning methods in robotics.</description>
      <author>example@mail.com (Zhicong Xian, Tabish Chaudhary, Jürgen Bock)</author>
      <guid isPermaLink="false">2502.04167v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Behavioral Entropy-Guided Dataset Generation for Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.04141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了使用行为熵（BE）作为原则性探索目标，以系统生成复杂连续高维领域中提供多样状态空间覆盖的多样化数据集。&lt;h4&gt;背景&lt;/h4&gt;基于熵的目标广泛应用于强化学习中的状态空间探索和离线强化学习的数据集生成。最近提出的考虑代理认知与感知偏差的行为熵在离散设置中被证明是机器人探索问题的一个有前景的度量。&lt;h4&gt;目的&lt;/h4&gt;研究行为熵如何用于系统地生成具有多样态空间覆盖的数据集，特别是针对复杂、连续且潜在高维的领域，并开发出实用奖励函数以配合标准强化学习方法来学习最大化行为熵的策略。&lt;h4&gt;方法&lt;/h4&gt;将行为熵的概念推广到连续设置中，推导了可处理的$k$-最近邻估计器，并为这些估计器提供了理论保证。此外，还设计了一些实践中的奖励函数，可以用于标准的RL方法以实现BE最大化的政策学习。&lt;h4&gt;主要发现&lt;/h4&gt;在使用标准MuJoCo环境进行实验后，比较了离线强化学习算法在由行为熵、Renyi和Shannon熵最大化策略收集的数据集上的表现。结果显示，在考虑的所有任务中，使用BE生成的数据集训练的离线RL算法优于使用Shannon熵、SMM和RND方法收集数据集所训练的算法；且在80%的任务上，优于使用Renyi熵生成的数据集。&lt;h4&gt;结论&lt;/h4&gt;利用行为熵最大化策略生成的数据集可以为复杂环境下的任务提供更有效的学习机会，有助于离线强化学习领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文是关于如何运用行为熵作为探索目标来生成多样化数据集的研究。该研究提出了连续设置下行为熵的概念扩展、$k$-最近邻估计器及其理论保证，并开发了基于此的奖励函数以用于标准RL方法。通过实验对比发现，使用行为熵最大化策略收集的数据集在各类任务上表现优越，尤其是与Shannon熵和SMM/RND方法相比，在80%的任务中优于Renyi熵数据集所训练算法的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Entropy-based objectives are widely used to perform state space explorationin reinforcement learning (RL) and dataset generation for offline RL.Behavioral entropy (BE), a rigorous generalization of classical entropies thatincorporates cognitive and perceptual biases of agents, was recently proposedfor discrete settings and shown to be a promising metric for roboticexploration problems. In this work, we propose using BE as a principledexploration objective for systematically generating datasets that providediverse state space coverage in complex, continuous, potentiallyhigh-dimensional domains. To achieve this, we extend the notion of BE tocontinuous settings, derive tractable $k$-nearest neighbor estimators, providetheoretical guarantees for these estimators, and develop practical rewardfunctions that can be used with standard RL methods to learn BE-maximizingpolicies. Using standard MuJoCo environments, we experimentally compare theperformance of offline RL algorithms for a variety of downstream tasks ondatasets generated using BE, R\'{e}nyi, and Shannon entropy-maximizingpolicies, as well as the SMM and RND algorithms. We find that offline RLalgorithms trained on datasets collected using BE outperform those trained ondatasets collected using Shannon entropy, SMM, and RND on all tasks considered,and on 80% of the tasks compared to datasets collected using R\'{e}nyi entropy.</description>
      <author>example@mail.com (Wesley A. Suttle, Aamodh Suresh, Carlos Nieto-Granda)</author>
      <guid isPermaLink="false">2502.04141v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Safe Quadrotor Navigation using Composite Control Barrier Functions</title>
      <link>http://arxiv.org/abs/2502.04101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for Presentation at International Conference on Robotics and  Automation (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种安全过滤器，用于确保多旋翼飞行机器人避免碰撞。该方法使用单一复合控制障碍函数来处理所有位置约束，并基于机器人的三阶非线性动力学模型。&lt;h4&gt;背景&lt;/h4&gt;现有的避碰算法可能无法应对复杂场景中的大量障碍物和复杂的环境条件。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的安全过滤器方法，以保证多旋翼飞行机器人在面对多种障碍时的碰撞避免能力。&lt;h4&gt;方法&lt;/h4&gt;通过使用单一复合控制障碍函数处理所有位置约束，并基于机器人的三阶非线性动力学模型来实现计算上的可扩展性和安全性。&lt;h4&gt;主要发现&lt;/h4&gt;该安全过滤器具有递归可行性，不满足条件的情况可以忽略不计。此外，在复杂环境中进行实验时，证明了其能够保证飞行机器人在有障碍物存在的情况下保持安全操作的能力。&lt;h4&gt;结论&lt;/h4&gt;提出的这种方法不仅适用于简单的环境，而且还能有效处理复杂的多障碍物场景，并且能够在内、外部的复杂环境下确保无人机的安全运行。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：本文介绍了一种用于确保多旋翼飞行机器人避免碰撞的安全过滤器。所提出的形式主义利用了一个单一复合控制障碍函数来处理所有位置约束，基于机器人的三阶非线性动力学模型。我们分析了在组合约束下的安全过滤器的递归可行性，并证明不满足条件的情况可以忽略不计。该方法允许针对成千上万的约束进行计算上的可扩展性，从而适用于复杂场景中的众多障碍物。实验上展示了它能够保证配备有LiDAR（光探测和测距）设备的四旋翼飞行器在内部和外部拥挤环境中操作的安全性，无论是在简单策略还是敌对策略下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a safety filter to ensure collision avoidance formultirotor aerial robots. The proposed formalism leverages a single CompositeControl Barrier Function from all position constraints acting on a third-ordernonlinear representation of the robot's dynamics. We analyze the recursivefeasibility of the safety filter under the composite constraint and demonstratethat the infeasible set is negligible. The proposed method allows computationalscalability against thousands of constraints and, thus, complex scenes withnumerous obstacles. We experimentally demonstrate its ability to guarantee thesafety of a quadrotor with an onboard LiDAR, operating in both indoor andoutdoor cluttered environments against both naive and adversarial nominalpolicies.</description>
      <author>example@mail.com (Marvin Harms, Martin Jacquet, Kostas Alexis)</author>
      <guid isPermaLink="false">2502.04101v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Soft and Highly-Integrated Optical Fiber Bending Sensors for Proprioception in Multi-Material 3D Printed Fingers</title>
      <link>http://arxiv.org/abs/2502.04094v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures, to be included in proceedings of IEEE  International Conference on Soft Robotics (Robosoft) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种半自动化印刷工艺，将塑料光学纤维嵌入读出电子设备并与3D打印的柔性件结合在一起。这种方法可以制造出一种可重复、单片式的弯矩传感器。&lt;h4&gt;背景&lt;/h4&gt;精确的形状感测对于软机器人的闭环控制至关重要，而低成本且高效的基于柔韧材料的光电传感器是最佳选择，因为它们能够适应软机器人产生的大变形而不影响性能。&lt;h4&gt;目的&lt;/h4&gt;提出了一种简便的方法来集成塑料光学纤维和读出电子设备，用于制造适用于软机器人的弯曲传感器。&lt;h4&gt;方法&lt;/h4&gt;通过3D打印工艺将塑料光学光纤与柔性件相结合，并嵌入了读出电子设备。这种方法在大变形条件下也能保持良好的性能。&lt;h4&gt;主要发现&lt;/h4&gt;制作的多材料3D打印手指表现出优异的线性度（平均70%）和角度误差（4.81° RMS），并且能够维持外部静态力作用下的指尖位置估计精度为12毫米。&lt;h4&gt;结论&lt;/h4&gt;分布式传感器架构在机器人应用中具有巨大的潜力，可以构建一个独立于致动反馈的数据驱动模型来检测环境中的物体接触。&lt;h4&gt;翻译&lt;/h4&gt;准确的形状感测是软机器人闭环控制的关键需求。由于能够适应大变形且不会影响性能，基于柔韧材料制造的低成本光电传感器成为自然选择。然而，现有的集成方法繁琐并且需要手动步骤和复杂的组装过程。我们提出了一种半自动印刷工艺，在3D打印柔性件中嵌入塑料光学纤维和读出电子设备。纤维被固定在位，并且当柔性件发生大弯曲变形时，读出电子设备仍然与其保持光耦合，从而形成一个可重复的、单片式制造的弯矩传感器，整个手动嵌入步骤仅需10分钟。我们通过制作多材料3D打印手指并详细评估每个本体感觉关节的表现来展示这一过程。这些传感器平均实现了70%的线性度和4.81° RMS的角度误差。此外，分布式的架构允许在外部静态力作用下维持指尖位置估计精度为12毫米。为了展示分布式传感器架构在机器人应用中的潜力，我们构建了一个独立于致动反馈的数据驱动模型来检测环境中物体接触。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate shape sensing, only achievable through distributed proprioception,is a key requirement for closed-loop control of soft robots. Low-cost powerefficient optoelectronic sensors manufactured from flexible materials representa natural choice as they can cope with the large deformations of soft robotswithout loss of performance. However, existing integration approaches arecumbersome and require manual steps and complex assembly. We propose asemi-automated printing process where plastic optical fibers are embedded withreadout electronics in 3D printed flexures. The fibers become locked in placeand the readout electronics remain optically coupled to them while the flexuresundergo large bending deformations, creating a repeatable, monolithicallymanufactured bending transducer with only 10 minutes required in total for themanual embedding steps. We demonstrate the process by manufacturingmulti-material 3D printed fingers and extensively evaluating the performance ofeach proprioceptive joint. The sensors achieve 70% linearity and 4.81{\deg} RMSerror on average. Furthermore, the distributed architecture allows formaintaining an average fingertip position estimation accuracy of 12 mm in thepresence of external static forces. To demonstrate the potential of thedistributed sensor architecture in robotics applications, we build adata-driven model independent of actuation feedback to detect contact withobjects in the environment.</description>
      <author>example@mail.com (Ellis Capp, Marco Pontin, Peter Walters, Perla Maiolino)</author>
      <guid isPermaLink="false">2502.04094v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Controllable Emotion Generation with Emotion Vectors</title>
      <link>http://arxiv.org/abs/2502.04075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于大规模语言模型的技术在客户服务、内容创作和实体智能等领域取得了显著进展，但这些模型在情感表达方面的能力仍有不足。&lt;h4&gt;背景&lt;/h4&gt;近年来，基于大型语言模型（LLMs）的技术在多个领域如客户服务中心、内容生成以及具身智能上展现出了卓越的潜力。然而，尽管LLM的应用前景广阔，它们在以适当的语调、时机和直接或间接的方式进行情感表达方面仍显不足。&lt;h4&gt;目的&lt;/h4&gt;探讨构建能够控制性地表达情感的大型语言模型的方法&lt;h4&gt;方法&lt;/h4&gt;提出了一种适用于多种大型语言模型的情感输出方法，并通过广泛的实验验证了其普适性和灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法在不同规模和架构的语言模型上进行了广泛测试，证明了该方法的有效性和可控性。&lt;h4&gt;结论&lt;/h4&gt;这种方法具有广阔的应用前景，在智能客户服务、文学创作以及家庭陪伴机器人等领域有潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;最近几年来，基于大规模语言模型的技术已经在许多领域取得了显著的进步，特别是在客户服务中心、内容生成和实体智能方面。这些技术展示了广泛的应用潜力，但大型语言模型在以适当的情感语调、时机及直接或间接方式表达情感的能力上仍然存在明显不足，而这也是一个非常重要的研究方向。目前少有文献对此进行了深入探讨。在这项工作中，我们提出了一种用于通过大型语言模型输出情绪的方法，并通过广泛的实验和验证证明了该方法的通用性、高度灵活性以及可控性。此方法在涉及情感表达的应用场景中有着广阔的应用前景，例如智能客户服务、文学创作及家庭陪伴机器人等。我们在不同规模和架构的语言模型上的广泛测试显示了所提出方法的强大适应性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, technologies based on large-scale language models (LLMs)have made remarkable progress in many fields, especially in customer service,content creation, and embodied intelligence, showing broad applicationpotential. However, The LLM's ability to express emotions with proper tone,timing, and in both direct and indirect forms is still insufficient butsignificant. Few works have studied on how to build the controlable emotionalexpression capability of LLMs. In this work, we propose a method for emotionexpression output by LLMs, which is universal, highly flexible, and wellcontrollable proved with the extensive experiments and verifications. Thismethod has broad application prospects in fields involving emotions output byLLMs, such as intelligent customer service, literary creation, and homecompanion robots. The extensive experiments on various LLMs with differentmodel-scales and architectures prove the versatility and the effectiveness ofthe proposed method.</description>
      <author>example@mail.com (Yurui Dong, Luozhijie Jin, Yao Yang, Bingjie Lu, Jiaxi Yang, Zhi Liu)</author>
      <guid isPermaLink="false">2502.04075v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Echo-Teddy: Preliminary Design and Development of Large Language Model-based Social Robot for Autistic Students</title>
      <link>http://arxiv.org/abs/2502.04029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Echo-Teddy，一款基于大型语言模型（LLM）的社交机器人，旨在帮助自闭症学生提升社交和沟通能力。&lt;h4&gt;背景&lt;/h4&gt;自闭症学生在社会交往中常常面临挑战，这可能阻碍他们的教育和个人发展。现有的聊天机器人解决方案难以提供自然且适应性强的互动。&lt;h4&gt;目的&lt;/h4&gt;探讨有效基于LLM的社交机器人的设计原则及初始原型特性；根据开发者反思和专家访谈提出改进措施。&lt;h4&gt;方法&lt;/h4&gt;研究采用混合方法，结合原型开发与定性分析（包括开发者反思和专家访谈）。&lt;h4&gt;主要发现&lt;/h4&gt;{'关键设计原则': '灵活性、伦理考量以及年龄适宜的互动方式', '初始原型特点': '基于Raspberry Pi平台构建，拥有定制语音组件及基础电机功能'}&lt;h4&gt;结论&lt;/h4&gt;该研究展示了LLM基社交机器人在支持自闭症学生中的潜力，并为特殊教育领域中开发有效且实用的社会辅助工具提供了宝贵的见解。&lt;h4&gt;翻译&lt;/h4&gt;自闭症学生通常面临社会互动的挑战，这可能阻碍他们的教育和个人发展。这项研究介绍了一款名为Echo-Teddy的大规模语言模型(LLM)基社交机器人，旨在帮助自闭症学生提升社交和沟通技能。不同于以往基于聊天机器人的解决方案，Echo-Teddy利用先进的LLM能力提供更自然且适应性的互动。该研究探讨了两个主要问题：1）有效的LLM基社交机器人为自闭症学生的特征及设计原则是什么？2）如何根据开发者反思行动与专家访谈改进这些机器人？本研究采用混合方法，结合原型开发和对开发者反思以及专家访谈的定性分析进行探究。确定的关键设计原则包括灵活性、伦理考量及年龄适宜互动方式等。初始原型基于Raspberry Pi平台构建，并具有定制语音组件及基本电机功能。原型评估表明，在用户界面、教育价值及实际教育环境中的应用等方面仍有改进空间。这项研究为人工智能辅助特殊教育领域做出了贡献，展示了LLM基社交机器人在支持自闭症学生方面的潜力，并提供了关于未来开发有效且实用社会支持工具的重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autistic students often face challenges in social interaction, which canhinder their educational and personal development. This study introducesEcho-Teddy, a Large Language Model (LLM)-based social robot designed to supportautistic students in developing social and communication skills. Unlikeprevious chatbot-based solutions, Echo-Teddy leverages advanced LLMcapabilities to provide more natural and adaptive interactions. The researchaddresses two key questions: (1) What are the design principles and initialprototype characteristics of an effective LLM-based social robot for autisticstudents? (2) What improvements can be made based on developerreflection-on-action and expert interviews? The study employed a mixed-methodsapproach, combining prototype development with qualitative analysis ofdeveloper reflections and expert interviews. Key design principles identifiedinclude customizability, ethical considerations, and age-appropriateinteractions. The initial prototype, built on a Raspberry Pi platform, featurescustom speech components and basic motor functions. Evaluation of the prototyperevealed potential improvements in areas such as user interface, educationalvalue, and practical implementation in educational settings. This researchcontributes to the growing field of AI-assisted special education bydemonstrating the potential of LLM-based social robots in supporting autisticstudents. The findings provide valuable insights for future developments inaccessible and effective social support tools for special education.</description>
      <author>example@mail.com (Unggi Lee, Hansung Kim, Juhong Eom, Hyeonseo Jeong, Seungyeon Lee, Gyuri Byun, Yunseo Lee, Minji Kang, Gospel Kim, Jihoi Na, Jewoong Moon, Hyeoncheol Kim)</author>
      <guid isPermaLink="false">2502.04029v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing people localisation in drone imagery for better crowd management by utilising every pixel in high-resolution images</title>
      <link>http://arxiv.org/abs/2502.04014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the pre-print. The article is submitted to the Engineering  Applications of Artificial Intelligence journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的人群定位是无人机有效管理人群的关键，在大型活动、公共集会以及日常城市人流监控中都非常重要。&lt;h4&gt;问题&lt;/h4&gt;传统方法在使用高分辨率无人机图像进行小目标定位时，由于图像缩放和滑动窗口技术的限制，存在精度和效率的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的点导向对象定位的方法来解决上述挑战。&lt;h4&gt;创新模块&lt;/h4&gt;Pixel Distill 模块用于处理高清图像，通过一次提取每个像素的空间信息来增强处理能力。&lt;h4&gt;新数据集&lt;/h4&gt;推出了专为现代无人机应用设计的新数据集 UP-COUNT。该数据集针对无人机成像中的各种难题，如在获取过程中相机和目标同时移动的问题。&lt;h4&gt;评估结果&lt;/h4&gt;对提出的算法在自建的 UP-COUNT 数据集和常用的 DroneCrowd 数据集上的全面评价表明，本方法相对于现有技术具有明显优势，并展示了其在基于无人机的人群对象定位任务中的有效性。&lt;h4&gt;改进点&lt;/h4&gt;这些改进显著提高了算法处理现实世界场景的能力，使得个体在动态环境下的定位和计数更为可靠。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate people localisation using drones is crucial for effective crowdmanagement, not only during massive events and public gatherings but also formonitoring daily urban crowd flow. Traditional methods for tiny objectlocalisation using high-resolution drone imagery often face limitations inprecision and efficiency, primarily due to constraints in image scaling andsliding window techniques. To address these challenges, a novel approachdedicated to point-oriented object localisation is proposed. Along with thisapproach, the Pixel Distill module is introduced to enhance the processing ofhigh-definition images by extracting spatial information from individual pixelsat once. Additionally, a new dataset named UP-COUNT, tailored to contemporarydrone applications, is shared. It addresses a wide range of challenges in droneimagery, such as simultaneous camera and object movement during the imageacquisition process, pushing forward the capabilities of crowd managementapplications. A comprehensive evaluation of the proposed method on the proposeddataset and the commonly used DroneCrowd dataset demonstrates the superiorityof our approach over existing methods and highlights its efficacy indrone-based crowd object localisation tasks. These improvements markedlyincrease the algorithm's applicability to operate in real-world scenarios,enabling more reliable localisation and counting of individuals in dynamicenvironments.</description>
      <author>example@mail.com (Bartosz Ptak, Marek Kraft)</author>
      <guid isPermaLink="false">2502.04014v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Malleable Robots</title>
      <link>http://arxiv.org/abs/2502.04012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages, 22 figures, chapter 7 of "Handbook on Soft Robotics"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了柔性机器人（一种新的协作机械臂类型）的基本原理，这些机器人基于可调刚度的结构设计，在保持高灵活性的同时减少驱动器的数量。&lt;h4&gt;背景&lt;/h4&gt;当前的协作机器人通常采用六轴或更多自由度的串联式机械臂来实现空间内的定位和任务适应性。传统的做法是通过增加系统的自由度数量来提高机械臂的灵活性，但一旦任务确定后（例如拾取放置操作），末端执行器的动作可以使用少于六个自由度完成。&lt;h4&gt;目的&lt;/h4&gt;开发柔性机器人以缩小现有协作机器人的技术差距，并实现具有较低驱动数目的灵活、可访问的制造自动化。&lt;h4&gt;方法&lt;/h4&gt;采用调整刚性结构的方法设计新型机械臂，通过减少自由度的数量来提高灵活性和操作简便性。&lt;h4&gt;主要发现&lt;/h4&gt;柔性机器人可以通过较少的驱动力实现高精度任务的操作，从而降低复杂性和成本。&lt;h4&gt;结论&lt;/h4&gt;柔性机器人的研究为未来的协作机器人技术提供了一种新的可能性，即在保持或提升性能的同时，减少所需的驱动器数量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本章讲述了基于可调刚度结构设计的新型协作机械臂——称为柔性机器人——的基本原理。这种类型的机器人旨在通过降低活动自由度来实现高灵活性，同时保持较低的移动性手臂配置。现有的协作机器人通常集成六或更多轴（DOF）的串联式机械臂，在受限空间内定位和任务适应上具有优势。然而，一旦一个机器人任务被确定下来（例如拾取放置操作），末端执行器的动作往往可以通过少于六个自由度实现。柔性机器人的目标是弥合现有协作机器人与灵活、可访问制造自动化之间的技术差距，并且使用较少的驱动装置完成这些工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-68620-7&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This chapter is about the fundamentals of fabrication, control, andhuman-robot interaction of a new type of collaborative robotic manipulators,called malleable robots, which are based on adjustable architectures of varyingstiffness for achieving high dexterity with lower mobility arms. Collaborativerobots, or cobots, commonly integrate six or more degrees of freedom (DOF) in aserial arm in order to allow positioning in constrained spaces and adaptabilityacross tasks. Increasing the dexterity of robotic arms has been indeedtraditionally accomplished by increasing the number of degrees of freedom ofthe system; however, once a robotic task has been established (e.g., apick-and-place operation), the motion of the end-effector can be normallyachieved using less than 6-DOF (i.e., lower mobility). The aim of malleablerobots is to close the technological gap that separates current cobots fromachieving flexible, accessible manufacturing automation with a reduced numberof actuators.</description>
      <author>example@mail.com (Angus B. Clark, Xinran Wang, Alex Ranne, Nicolas Rojas)</author>
      <guid isPermaLink="false">2502.04012v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Bilevel Multi-Armed Bandit-Based Hierarchical Reinforcement Learning for Interaction-Aware Self-Driving at Unsignalized Intersections</title>
      <link>http://arxiv.org/abs/2502.03960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by IEEE Transactions on Vehicular  Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于双层多臂赌博机的层次化强化学习框架BiM-ACPPO，旨在无信号控制交叉路口进行考虑周围车辆不确定性的交互感知决策与规划。&lt;h4&gt;背景&lt;/h4&gt;在无信号控制交叉口的自驾车场景中，传统的强化学习方法难以处理由于驾驶员意图、互动行为及周围车辆数量变化带来的不确定性问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入中间决策变量和利用无信号化路口自动驾驶结构特性，开发一种能够提高交互感知能力并增强泛化性能的层次化强化学习框架。&lt;h4&gt;方法&lt;/h4&gt;提出了基于Exp3.S算法的双层多臂赌博机（BiM-AB）策略来解决高维复杂场景下的自驾车决策问题，并通过动态调整训练课程以提升样本效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在CARLA仿真环境中的性能优于所有基准方法，在两个新的城市驾驶场景中也展示了良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;BiM-ACPPO框架为无信号控制交叉路口的自驾车交互感知决策提供了一种有效解决方案，并且具有较高的样本效率和强大的泛化性能。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种基于双层多臂赌博机（Bilevel Multi-Armed Bandit）的方法BiM-ACPPO，用于无信号控制交叉路口的交互感知决策制定与规划。该方法主动考虑周围车辆不确定性因素的影响，包括驾驶员意图、互动行为和周围车辆数量的变化。通过引入中间决策变量，能够使高层次强化学习策略提供具有交互意识的参考意见，进而指导低层次模型预测性控制（MPC）并提升所提框架的泛化能力。借助无信号控制交叉口自动驾驶的特点，将RL政策训练问题建模为一个双层课程学习任务，并通过提出的基于Exp3.S算法的BiM-AB策略解决此任务。值得一提的是，该方法支持动态调整培训课程以提高强化学习训练过程中的样本效率。在高保真的CARLA模拟器中进行了比较实验，结果表明所提出的方法优于所有基准方法。此外，在两个新的城市驾驶场景中进行的实验进一步证明了其卓越的泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we present BiM-ACPPO, a bilevel multi-armed bandit-basedhierarchical reinforcement learning framework for interaction-awaredecision-making and planning at unsignalized intersections. Essentially, itproactively takes the uncertainties associated with surrounding vehicles (SVs)into consideration, which encompass those stemming from the driver's intention,interactive behaviors, and the varying number of SVs. Intermediate decisionvariables are introduced to enable the high-level RL policy to provide aninteraction-aware reference, for guiding low-level model predictive control(MPC) and further enhancing the generalization ability of the proposedframework. By leveraging the structured nature of self-driving at unsignalizedintersections, the training problem of the RL policy is modeled as a bilevelcurriculum learning task, which is addressed by the proposed Exp3.S-based BiMABalgorithm. It is noteworthy that the training curricula are dynamicallyadjusted, thereby facilitating the sample efficiency of the RL trainingprocess. Comparative experiments are conducted in the high-fidelity CARLAsimulator, and the results indicate that our approach achieves superiorperformance compared to all baseline methods. Furthermore, experimental resultsin two new urban driving scenarios clearly demonstrate the commendablegeneralization performance of the proposed method.</description>
      <author>example@mail.com (Zengqi Peng, Yubin Wang, Lei Zheng, Jun Ma)</author>
      <guid isPermaLink="false">2502.03960v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond</title>
      <link>http://arxiv.org/abs/2502.03945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Afrispeech-Dialog数据集，该数据集包含50个模拟的带有非洲口音的英语对话，用于评估自动语音识别（ASR）和相关技术。&lt;h4&gt;背景&lt;/h4&gt;在医疗、呼叫中心和机器人等领域中，语音技术正在改变交互方式。然而，在处理具有非洲口音的对话时，这些系统的性能尚未得到充分研究。&lt;h4&gt;目的&lt;/h4&gt;通过创建一个基准数据集来评估自动语音识别（ASR）系统和说话人区分系统对长篇幅且带口音的英语对话的表现能力，并探讨大型语言模型在医疗对话总结中的应用及其受到ASR错误的影响。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含50个模拟的带有非洲口音的英语对话的数据集，涵盖了医疗和非医疗场景。使用最新的说话人区分系统和自动语音识别（ASR）系统进行了评估，并将这些系统的性能与母语发音做了对比。&lt;h4&gt;主要发现&lt;/h4&gt;对于带有非洲口音的英语对话，自动语音识别（ASR）系统的性能比对标准英语对话的表现下降了10%以上。大型语言模型在处理带错误的医疗对话总结时的能力也受到了影响。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调需要更多包容性的数据集来推动低资源环境下的会话AI的发展。&lt;h4&gt;翻译&lt;/h4&gt;语音技术正在改变包括医疗、呼叫中心和机器人在内的各个行业的互动方式，然而，在处理带有非洲口音的对话方面，这些系统的性能仍需进一步探索。为了评估自动语音识别（ASR）及相关技术，我们创建了Afrispeech-Dialog基准数据集，该数据集包含了50个模拟的具有非洲口音的英语医疗和非医疗场景对话，并对其进行了详细的评估。研究发现最先进的说话人区分系统和自动语音识别系统的性能在处理长篇幅且带口音的对话时相比母语发音会下降10%以上。此外，我们还探讨了大型语言模型在生成医学对话摘要方面的能力，以展示ASR错误对下游医学总结的影响，并为全球南半球地区的语音技术提供了挑战和机遇的新见解。这项研究强调了开发更具包容性的数据集的必要性，以便促进低资源环境下会话AI的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech technologies are transforming interactions across various sectors,from healthcare to call centers and robots, yet their performance onAfrican-accented conversations remains underexplored. We introduceAfrispeech-Dialog, a benchmark dataset of 50 simulated medical and non-medicalAfrican-accented English conversations, designed to evaluate automatic speechrecognition (ASR) and related technologies. We assess state-of-the-art (SOTA)speaker diarization and ASR systems on long-form, accented speech, comparingtheir performance with native accents and discover a 10%+ performancedegradation. Additionally, we explore medical conversation summarizationcapabilities of large language models (LLMs) to demonstrate the impact of ASRerrors on downstream medical summaries, providing insights into the challengesand opportunities for speech technologies in the Global South. Our workhighlights the need for more inclusive datasets to advance conversational AI inlow-resource settings.</description>
      <author>example@mail.com (Mardhiyah Sanni, Tassallah Abdullahi, Devendra D. Kayande, Emmanuel Ayodele, Naome A. Etori, Michael S. Mollel, Moshood Yekini, Chibuzor Okocha, Lukman E. Ismaila, Folafunmi Omofoye, Boluwatife A. Adewale, Tobi Olatunji)</author>
      <guid isPermaLink="false">2502.03945v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Oblivious Robots Under Round Robin: Gathering on Rings</title>
      <link>http://arxiv.org/abs/2502.03939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器人在环形图上移动并集合到同一个顶点的问题，特别是在顺序调度器下，其中一个关键挑战是没有多重检测能力和初始配置可能包含多个机器人的顶点。&lt;h4&gt;背景&lt;/h4&gt;大多数关于机器人集合问题的研究集中在异步设置下的可行性挑战。现有的研究表明，在这种情况下，通常假设机器人具有多重检测能力，并且初始配置限制为每个顶点最多一个机器人。&lt;h4&gt;目的&lt;/h4&gt;探讨在没有多重检测能力和初始配置中可能包含多个机器人的条件下，环形图上的机器人集合问题的解决方案&lt;h4&gt;方法&lt;/h4&gt;本文研究了在顺序调度器下，特别是使用固定周期循环激活机器人的Round Robin调度器下的GATHERING问题，并完全描述了DISTINCT GATHERING问题。&lt;h4&gt;主要发现&lt;/h4&gt;证明了一般顺序调度器下广义GATHERING问题无法解决；然而，在特定的Round Robin调度器下可以提供完整的问题表征。&lt;h4&gt;结论&lt;/h4&gt;在没有多重检测能力和初始配置中可能包含多个机器人的条件下，Ring图上的机器人集合问题是可解的，但需要使用特殊的调度机制来克服对称性所带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots with very limited capabilities are placed on the vertices of a graphand are required to move toward a single, common vertex, where they remainstationary once they arrive. This task is referred to as the GATHERING problem.Most of the research on this topic has focused on feasibility challenges in theasynchronous setting, where robots operate independently of each other. Acommon assumption in these studies is that robots are equipped withmultiplicity detection, the ability to recognize whether a vertex is occupiedby more than one robot. Additionally, initial configurations are oftenrestricted to ensure that no vertex hosts more than one robot. A key difficultyarises from the possible symmetries in the robots' placement relative to thegraph's topology. This paper investigates the GATHERING problem on Rings undera sequential scheduler, where only one robot at a time is active. While thissequential activation helps to break symmetries, we remove two commonassumptions: robots do not have multiplicity detection, and in initialconfigurations, vertices can be occupied by multiplicities. We prove that sucha generalized GATHERING problem cannot be solved under general sequentialschedulers. However, we provide a complete characterization of the problem whena sequential Round Robin scheduler is used, where robots are activated one at atime in a fixed cyclic order that repeats indefinitely. Furthermore, we fullycharacterize the DISTINCT GATHERING problem, the most used variant ofGATHERING, in which the initial configurations do not admit multiplicities.</description>
      <author>example@mail.com (Alfredo Navarra, Francesco Piselli)</author>
      <guid isPermaLink="false">2502.03939v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Adaptation of Task Goal States from Prior Knowledge</title>
      <link>http://arxiv.org/abs/2502.03918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种框架，用于定义具有目标状态自由度和可变性的任务。机器人可以使用这个框架从观察到的任务执行中确定不同于初始目标的新目标，该新目标与任务描述相兼容但对机器人来说更容易实现。&lt;h4&gt;背景&lt;/h4&gt;当前机器人任务规划存在固定的目标设定问题，限制了机器人的灵活性和适应性。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的模型来定义包含自由度和可变性的环境状态，使机器人能根据观察到的任务执行调整其目标。&lt;h4&gt;方法&lt;/h4&gt;提出了一种环境变化的建模方式，并通过实验展示了如何从单一任务演示中交互式地创建这种变化以及利用这些变化制定执行计划，以将任何环境带入目标状态。&lt;h4&gt;主要发现&lt;/h4&gt;能够通过观察任务执行动态生成目标变化，并据此为机器人提供灵活的目标规划策略。&lt;h4&gt;结论&lt;/h4&gt;提出的框架和方法可以显著提高机器人的适应性和任务完成效率。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a framework to define a task with freedom and variability in its goal state. A robot could use this to observe the execution of a task and target a different goal from the observed one; a goal that is still compatible with the task description but would be easier for the robot to execute. We define the model of an environment state and an environment variation, and present experiments on how to interactively create the variation from a single task demonstration and how to use this variation to create an execution plan for bringing any environment into the goal state.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework to define a task with freedom and variabilityin its goal state. A robot could use this to observe the execution of a taskand target a different goal from the observed one; a goal that is stillcompatible with the task description but would be easier for the robot toexecute. We define the model of an environment state and an environmentvariation, and present experiments on how to interactively create the variationfrom a single task demonstration and how to use this variation to create anexecution plan for bringing any environment into the goal state.</description>
      <author>example@mail.com (Andrei Costinescu, Darius Burschka)</author>
      <guid isPermaLink="false">2502.03918v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>A Flexible FBG-Based Contact Force Sensor for Robotic Gripping Systems</title>
      <link>http://arxiv.org/abs/2502.03914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文介绍了一种基于光纤布拉格光栅的小型高灵敏度力传感器，旨在解决软机器人夹爪在执行精确和安全抓取时由于缺乏集成传感器而产生的问题。这种灵活的力传感器被整合到一个软机器人夹手中，并通过一系列实验验证了其效果。&lt;h4&gt;背景&lt;/h4&gt;软夹爪具有轻柔、安全处理物体的巨大潜力，但由于缺乏集成了传感器的问题导致无法实现更精确的安全握持动作。&lt;h4&gt;目的&lt;/h4&gt;设计并开发一种新型高灵敏度力传感器，以提高软机器人夹爪的性能和稳定性。&lt;h4&gt;方法&lt;/h4&gt;使用3D打印技术制造了一种含有小突起结构、双光纤布拉格光栅阵列及保护管的TPU外壳，并进行了包括力量校准、重复性测试、滞回研究等在内的多项实验来评估力传感器的有效性和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;该传感器具有良好的重复性，测力范围为4.69N，灵敏度约为1169.04 pm/N。与商用负载细胞相比，误差百分比仅为2.56%，RMSE值为0.14N。温度补偿效果也得到了验证，在温度变化达到11摄氏度时，测力的RMSE仍保持在0.01 N。&lt;h4&gt;结论&lt;/h4&gt;这种新型传感器可以集成到各种应用场景中，包括制造、农业、医疗保健（如假肢手）、物流和包装等，为操作提供情境感知，并提高工作效率。此外，在自动化取放任务中的闭环力量控制显著提高了抓握的稳定性。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robotic grippers demonstrate great potential for gently and safelyhandling objects; however, their full potential for executing precise andsecure grasping has been limited by the lack of integrated sensors, leading toproblems such as slippage and excessive force exertion. To address thischallenge, we present a small and highly sensitive Fiber Bragg Grating-basedforce sensor designed for accurate contact force measurement. The flexibleforce sensor comprises a 3D-printed TPU casing with a small bump and uvulastructure, a dual FBG array, and a protective tube. A series of tests have beenconducted to evaluate the effectiveness of the proposed force sensor, includingforce calibration, repeatability test, hysteresis study, force measurementcomparison, and temperature calibration and compensation tests. The resultsdemonstrated good repeatability, with a force measurement range of 4.69 N, ahigh sensitivity of approximately 1169.04 pm/N, a root mean square error (RMSE)of 0.12 N, and a maximum hysteresis of 4.83%. When compared to a commercialload cell, the sensor showed a percentage error of 2.56% and an RMSE of 0.14 N.Besides, the proposed sensor validated its temperature compensationeffectiveness, with a force RMSE of 0.01 N over a temperature change of 11Celsius degree. The sensor was integrated with a soft grow-and-twine gripper tomonitor interaction forces between different objects and the robotic gripper.Closed-loop force control was applied during automated pick-and-place tasks andsignificantly improved gripping stability, as demonstrated in tests. This forcesensor can be used across manufacturing, agriculture, healthcare (likeprosthetic hands), logistics, and packaging, to provide situation awareness andhigher operational efficiency.</description>
      <author>example@mail.com (Wenjie Lai, Huu Duoc Nguyen, Jiajun Liu, Xingyu Chen, Soo Jay Phee)</author>
      <guid isPermaLink="false">2502.03914v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Advanced Object Detection and Pose Estimation with Hybrid Task Cascade and High-Resolution Networks</title>
      <link>http://arxiv.org/abs/2502.03877v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于改进的6D-VNet框架的新颖的六维物体检测和姿态估计方法，通过结合Hybrid Task Cascade (HTC) 和 High-Resolution Network (HRNet)，提高了检测精度和姿态估计准确性。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉领域，六维物体检测与姿态估计对于机器人、增强现实及自动驾驶等应用至关重要。传统的方法往往难以同时实现高准确性的物体检测和精确的姿态估计。&lt;h4&gt;目的&lt;/h4&gt;通过集成HTC多阶段优化流程和HRNet的高分辨率表示能力来改进6D-VNet框架，提升物体检测和姿态估计的整体性能。&lt;h4&gt;方法&lt;/h4&gt;利用HTC和HRNet增强现有的6D-VNet模型；引入先进的后处理技术和新的模型集成策略，以提高公共和私人基准测试中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在多个公开和私有数据集上的性能显著优于当前最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法为六维物体检测与姿态估计提供了有价值的贡献，并展示了其相对于现有技术的优越性。&lt;h4&gt;翻译&lt;/h4&gt;计算机视觉领域中，6D目标检测及姿势估算是机器人、增强现实和自动驾驶等应用的关键。传统方法在同时实现高准确性的目标检测及精确的姿势估算上面临挑战。本研究基于现有的6D-VNet框架提出了一种改进的方法，并通过集成Hybrid Task Cascade (HTC) 和 High-Resolution Network (HRNet) 来提升性能，利用了HTC多阶段优化流程和HRNet保持高分辨率表示的能力来显著提高检测准确性和姿态估算精度。此外，还引入先进的后处理技术以及一种新的模型整合策略，共同促进了在公共及私人基准上的卓越表现。该方法相较于现有的顶尖模型展示出了实质性的改进，对6D目标检测与姿势估计领域具有重要贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of computer vision, 6D object detection and pose estimation arecritical for applications such as robotics, augmented reality, and autonomousdriving. Traditional methods often struggle with achieving high accuracy inboth object detection and precise pose estimation simultaneously. This studyproposes an improved 6D object detection and pose estimation pipeline based onthe existing 6D-VNet framework, enhanced by integrating a Hybrid Task Cascade(HTC) and a High-Resolution Network (HRNet) backbone. By leveraging thestrengths of HTC's multi-stage refinement process and HRNet's ability tomaintain high-resolution representations, our approach significantly improvesdetection accuracy and pose estimation precision. Furthermore, we introduceadvanced post-processing techniques and a novel model integration strategy thatcollectively contribute to superior performance on public and privatebenchmarks. Our method demonstrates substantial improvements overstate-of-the-art models, making it a valuable contribution to the domain of 6Dobject detection and pose estimation.</description>
      <author>example@mail.com (Yuhui Jin, Yaqiong Zhang, Zheyuan Xu, Wenqing Zhang, Jingyu Xu)</author>
      <guid isPermaLink="false">2502.03877v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training</title>
      <link>http://arxiv.org/abs/2502.03822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种称为DRIFT的框架，通过奇异值分解实现扩散策略训练中的动态秩调整。&lt;h4&gt;背景&lt;/h4&gt;基于离线行为克隆训练的扩散政策在机器人运动生成中越来越受欢迎。尽管有效，但这些策略通常需要大量的可训练参数，增加了计算成本。&lt;h4&gt;目的&lt;/h4&gt;为了平衡表示能力和计算效率，在不需要的情况下可以动态地调整可训练部分。&lt;h4&gt;方法&lt;/h4&gt;提出了一种框架DRIFT，它利用奇异值分解技术实现扩散政策训练中的动态秩调整。通过DRIFT-DAgger算法展示了该框架的优势，这是一种能够无缝切换于离线引导阶段和在线互动阶段的模仿学习算法。&lt;h4&gt;主要发现&lt;/h4&gt;进行了广泛的实验以更好地理解所提出的框架，结果显示DRIFT-DAgger在样本效率和训练速度方面有所提高，并且对模型性能影响很小。&lt;h4&gt;结论&lt;/h4&gt;通过采用动态秩调整技术，可以实现更好的计算资源利用和更快的学习过程，同时保持良好的学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion policies trained via offline behavioral cloning have recentlygained traction in robotic motion generation. While effective, these policiestypically require a large number of trainable parameters. This model sizeaffords powerful representations but also incurs high computational cost duringtraining. Ideally, it would be beneficial to dynamically adjust the trainableportion as needed, balancing representational power with computationalefficiency. For example, while overparameterization enables diffusion policiesto capture complex robotic behaviors via offline behavioral cloning, theincreased computational demand makes online interactive imitation learningimpractical due to longer training time. To address this challenge, we presenta framework, called DRIFT, that uses the Singular Value Decomposition to enabledynamic rank adjustment during diffusion policy training. We implement anddemonstrate the benefits of this framework in DRIFT-DAgger, an imitationlearning algorithm that can seamlessly slide between an offline bootstrappingphase and an online interactive phase. We perform extensive experiments tobetter understand the proposed framework, and demonstrate that DRIFT-DAggerachieves improved sample efficiency and faster training with minimal impact onmodel performance.</description>
      <author>example@mail.com (Xiatao Sun, Shuo Yang, Yinxing Chen, Francis Fan, Yiyan, Liang, Daniel Rakita)</author>
      <guid isPermaLink="false">2502.03822v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models for Multi-Robot Systems: A Survey</title>
      <link>http://arxiv.org/abs/2502.03814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了大型语言模型(LLM)在多机器人系统(MRS)中的应用，概述了LLM在任务分配、运动规划和动作生成等层面的应用，并探讨了当前面临的挑战及未来的研究机会。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型的快速发展，在多机器人系统中出现了新的可能性，例如增强通信、任务规划和人机交互。与传统的单机器人或多智能体系统相比，MRS面临独特的挑战，如协调性、可扩展性和现实世界适应性。&lt;h4&gt;目的&lt;/h4&gt;提供首个关于LLM在MRS中的综合探索，分类描述了它们的应用，并探讨了当前限制因素和未来研究机会。&lt;h4&gt;方法&lt;/h4&gt;对不同层次的MRS应用进行系统分类，包括高层次任务分配、中层运动规划和低层动作生成；同时还展示了人类干预下的具体应用案例。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在多个领域展示出了广泛的应用潜力，如家庭机器人技术、建筑施工、编队控制等。同时指出了数学推理限制、幻觉问题、延迟以及缺乏鲁棒基准测试系统等问题。&lt;h4&gt;结论&lt;/h4&gt;强调了在未来的研究中改进微调、推理技术和特定任务模型的重要性，并通过开放源代码的GitHub仓库不断更新相关文献，以反映研究领域的快速进展。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型(LLMs)在多机器人系统的快速发展开启了新的可能性，包括增强通信、任务规划和人机交互。不同于传统的单个机器人或多代理系统，MRS提出了独特的挑战，如协调性、可扩展性和现实世界适应性。本文首次全面探索了LLM与MRS的融合，并系统地分类了它们在高层级任务分配、中层级运动计划以及低层级动作生成中的应用；同时展示了包括家用机器人技术、建筑施工、编队控制和目标跟踪等多样化领域的关键应用，证明了LLMs在MRS中的多功能性和变革潜力。此外，本文还探讨了限制将LLMs应用于MRS的问题，如数学推理能力的局限性、幻觉现象以及延迟问题，并强调需要建立稳健的基准测试系统；最后指出未来研究的机会在于微调技术、推理方法和特定任务模型的进步上。该综述旨在指导研究人员在智能部署和支持LLM驱动的多机器人系统的实际应用中进行工作。鉴于领域内研究的快速发展，我们通过开源的GitHub存储库持续更新相关论文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of Large Language Models (LLMs) has opened newpossibilities in Multi-Robot Systems (MRS), enabling enhanced communication,task planning, and human-robot interaction. Unlike traditional single-robot andmulti-agent systems, MRS poses unique challenges, including coordination,scalability, and real-world adaptability. This survey provides the firstcomprehensive exploration of LLM integration into MRS. It systematicallycategorizes their applications across high-level task allocation, mid-levelmotion planning, low-level action generation, and human intervention. Wehighlight key applications in diverse domains, such as household robotics,construction, formation control, target tracking, and robot games, showcasingthe versatility and transformative potential of LLMs in MRS. Furthermore, weexamine the challenges that limit adapting LLMs in MRS, including mathematicalreasoning limitations, hallucination, latency issues, and the need for robustbenchmarking systems. Finally, we outline opportunities for future research,emphasizing advancements in fine-tuning, reasoning techniques, andtask-specific models. This survey aims to guide researchers in the intelligenceand real-world deployment of MRS powered by LLMs. Based on the fast-evolvingnature of research in the field, we keep updating the papers in the open-sourceGithub repository.</description>
      <author>example@mail.com (Peihan Li, Zijian An, Shams Abrar, Lifeng Zhou)</author>
      <guid isPermaLink="false">2502.03814v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Action-Free Reasoning for Policy Generalization</title>
      <link>http://arxiv.org/abs/2502.03729v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的机器人政策训练方法RAD，该方法结合了机器人演示数据和无动作的人类视频数据，通过语言推理来提高机器人策略的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;端到端模仿学习是训练机器人策略的一种有前景的方法，但在新环境下的泛化仍然是一个挑战。大规模的机器人展示数据集展示了诱导泛化的潜力，但其扩展需要大量的资源。相比之下，人类视频数据更为丰富多样，并且可以作为替代方案。然而，这些人类视频数据缺乏动作标签，这使得它们在模仿学习中的应用变得复杂。&lt;h4&gt;目的&lt;/h4&gt;通过利用人类视频中基于语言的推理来指导机器人行为，本文旨在提出一种新的方法以训练出更具有泛化能力的机器人策略。&lt;h4&gt;方法&lt;/h4&gt;RAD模型同时从带有推理和动作标签的机器人演示数据以及仅包含推理标签的人类无动作视频数据学习。该模型首先通过机器人演示数据学习将推理映射到低级动作，然后利用无动作的数据来增强推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，RAD能够有效跨过人机之间存在的行为差异（即从人类的行为表现中获得的策略可以有效地应用于机器人），使机器人能够在仅在无动作数据中看到的任务上执行。此外，扩大无动作用于推理的数据规模显著提升了策略性能和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本文的方法显示了基于推理的学习从无动作用于行动的大型数据集对于提高机器人控制的可扩展性具有极大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;端到端模仿学习为训练机器人策略提供了一种有前景的方式。然而，将其推广至新的环境仍是一个挑战。虽然大规模的机器人演示数据集显示了诱导泛化的潜力，但其扩展需要大量的资源。相比之下，人类视频数据更为丰富多样，并且可以作为替代方案。但是，这些人类视频数据缺乏动作标签，使得它们在模仿学习中的应用变得复杂。现有方法试图提取基于地面的动作表示（例如手部姿势），而生成的策略很难跨越人机之间的存在行为差异。本文提出了另一种方法：利用从人类视频中获取的语言推理来指导机器人行动，以训练出具有泛化的机器人策略。在此基础上，我们引入了RAD模型，该模型可以从带有推理和动作标签的机器人演示数据以及仅包含推理标签的人类无动作视频数据学习。机器人数据教给模型将推理映射到低级行动的能力，而无动作用于提升其推理能力的数据则增强了这种能力。此外，本文还将发布一个新的数据集，其中包括3,377个人手操作的展示，并带有与BridgeV2基准兼容的原因注释，旨在促进未来基于原因驱动的机器人学习的研究。实验表明RAD能够有效跨越人机之间的存在行为差异，使机器人能够在仅在无动作用于行动的数据中看到的任务上执行。进一步扩大用于推理的无动作数据显著提升了策略性能和新任务上的泛化能力。这些结果突显了从无动作用于行动的数据集中进行基于原因驱动的学习对提高可扩展性的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end imitation learning offers a promising approach for training robotpolicies. However, generalizing to new settings remains a significantchallenge. Although large-scale robot demonstration datasets have shownpotential for inducing generalization, they are resource-intensive to scale. Incontrast, human video data is abundant and diverse, presenting an attractivealternative. Yet, these human-video datasets lack action labels, complicatingtheir use in imitation learning. Existing methods attempt to extract groundedaction representations (e.g., hand poses), but resulting policies struggle tobridge the embodiment gap between human and robot actions. We propose analternative approach: leveraging language-based reasoning from humanvideos-essential for guiding robot actions-to train generalizable robotpolicies. Building on recent advances in reasoning-based policy architectures,we introduce Reasoning through Action-free Data (RAD). RAD learns from bothrobot demonstration data (with reasoning and action labels) and action-freehuman video data (with only reasoning labels). The robot data teaches the modelto map reasoning to low-level actions, while the action-free data enhancesreasoning capabilities. Additionally, we will release a new dataset of 3,377human-hand demonstrations with reasoning annotations compatible with the BridgeV2 benchmark and aimed at facilitating future research on reasoning-drivenrobot learning. Our experiments show that RAD enables effective transfer acrossthe embodiment gap, allowing robots to perform tasks seen only in action-freedata. Furthermore, scaling up action-free reasoning data significantly improvespolicy performance and generalization to novel tasks. These results highlightthe promise of reasoning-driven learning from action-free datasets foradvancing generalizable robot control. Project page:https://rad-generalization.github.io</description>
      <author>example@mail.com (Jaden Clark, Suvir Mirchandani, Dorsa Sadigh, Suneel Belkhale)</author>
      <guid isPermaLink="false">2502.03729v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning</title>
      <link>http://arxiv.org/abs/2502.03717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新方法Language-Guided Preference Learning (LGPL)，结合了预训练语言模型和偏好学习，以提高机器人行为适应性。&lt;h4&gt;背景&lt;/h4&gt;当前的交互方式要么依赖自然语言输入但信息量有限，要么通过人类偏好数学建模但是样本效率低。&lt;h4&gt;目的&lt;/h4&gt;开发一种更高效、分辨率更高的方法来确定机器人在不同场景下与用户互动的最佳行为。&lt;h4&gt;方法&lt;/h4&gt;LGPL利用预训练的大规模语言模型生成初步的行为样本，并通过偏好反馈进行优化，从而产生符合人类期望的精确行为。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在少量查询情况下快速学习出准确且表达丰富的机器人行为，优于单纯的语言参数化模型和传统偏好学习方式。&lt;h4&gt;结论&lt;/h4&gt;LGPL展示了其在提高交互式机器人的样本效率方面具有巨大潜力，并为未来的社会环境中广泛应用机器人提供了可能的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;表现力强的机器人行为对于机器人在社交环境中的广泛接受至关重要。最近，基于学习的腿足运动控制器的进步已经使更动态和多样化的机器人行为成为可能。然而，确定与不同用户在各种场景下互动的最佳行为仍然是一项挑战。当前的方法要么依赖于自然语言输入，这虽然高效但分辨率较低；要么从人类偏好中学习，尽管分辨率较高但却样本效率低下。本文介绍了一种新颖的方案，它结合了预训练LLMs生成先验和基于偏好的学习精确度。我们的方法被命名为Language-Guided Preference Learning (LGPL)，利用LLMs来产生初步的行为样本，并通过基于偏好的反馈进行优化，以学习与人类期望相符的行为。我们核心的想法是LLMs可以引导偏好学习的采样过程，从而显著提高样本效率。实验证明，LGPL能够在仅四次查询的情况下快速学习出准确且表达丰富的机器人行为，超过了单纯的用语言参数化模型和传统的基于偏好的学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Expressive robotic behavior is essential for the widespread acceptance ofrobots in social environments. Recent advancements in learned legged locomotioncontrollers have enabled more dynamic and versatile robot behaviors. However,determining the optimal behavior for interactions with different users acrossvaried scenarios remains a challenge. Current methods either rely on naturallanguage input, which is efficient but low-resolution, or learn from humanpreferences, which, although high-resolution, is sample inefficient. This paperintroduces a novel approach that leverages priors generated by pre-trained LLMsalongside the precision of preference learning. Our method, termedLanguage-Guided Preference Learning (LGPL), uses LLMs to generate initialbehavior samples, which are then refined through preference-based feedback tolearn behaviors that closely align with human expectations. Our core insight isthat LLMs can guide the sampling process for preference learning, leading to asubstantial improvement in sample efficiency. We demonstrate that LGPL canquickly learn accurate and expressive behaviors with as few as four queries,outperforming both purely language-parameterized models and traditionalpreference learning approaches. Website with videos:https://lgpl-gaits.github.io/</description>
      <author>example@mail.com (Jaden Clark, Joey Hejna, Dorsa Sadigh)</author>
      <guid isPermaLink="false">2502.03717v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>How vulnerable is my policy? Adversarial attacks on modern behavior cloning policies</title>
      <link>http://arxiv.org/abs/2502.03698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文对学习演示（LfD）算法在机器人操控任务中的对抗性攻击进行了全面研究。&lt;h4&gt;背景&lt;/h4&gt;学习演示(LfD)算法已经在机器人操作任务中展示了有前景的结果，但它们对于对抗性攻击的脆弱性尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;该论文旨在探讨经典和最近提出的LfD算法（如行为克隆、LSTM-GMM、隐式行为克隆、扩散策略以及VQ-Behavior Transformer）在未经定向、定向及通用对抗性扰动下的脆弱性。&lt;h4&gt;方法&lt;/h4&gt;本文采用多种模拟机器人操作任务进行实验，测试了这些算法对未针对性攻击、针对性攻击和普遍性攻击的抵抗力。此外还研究了随机平滑等广泛使用的防御策略，并展示了其限制。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明大多数当前方法都高度易受对抗性扰动的影响，且这种攻击在不同算法、架构和任务之间具有可转移性。&lt;h4&gt;结论&lt;/h4&gt;该论文的发现揭示了现代行为克隆算法的安全漏洞，并为未来解决此类问题的工作指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;学习演示（LfD）算法已在机器人操控领域展示出显著成果，但它们对对抗攻击的抵抗力依然需要深入研究。本文重点分析了几种经典和新型LfD方法在面对不同类型对抗性扰动时的表现，并通过实验展示了当前方法面临的普遍脆弱性及可能的安全威胁问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from Demonstration (LfD) algorithms have shown promising results inrobotic manipulation tasks, but their vulnerability to adversarial attacksremains underexplored. This paper presents a comprehensive study of adversarialattacks on both classic and recently proposed algorithms, including BehaviorCloning (BC), LSTM-GMM, Implicit Behavior Cloning (IBC), Diffusion Policy (DP),and VQ-Behavior Transformer (VQ-BET). We study the vulnerability of thesemethods to untargeted, targeted and universal adversarial perturbations. Whileexplicit policies, such as BC, LSTM-GMM and VQ-BET can be attacked in the samemanner as standard computer vision models, we find that attacks for implicitand denoising policy models are nuanced and require developing novel attackmethods. Our experiments on several simulated robotic manipulation tasks revealthat most of the current methods are highly vulnerable to adversarialperturbations. We also show that these attacks are transferable acrossalgorithms, architectures, and tasks, raising concerning securityvulnerabilities with potentially a white-box threat model. In addition, we testthe efficacy of a randomized smoothing, a widely used adversarial defensetechnique, and highlight its limitation in defending against attacks on complexand multi-modal action distribution common in complex control tasks. Insummary, our findings highlight the vulnerabilities of modern BC algorithms,paving way for future work in addressing such limitations.</description>
      <author>example@mail.com (Basavasagar Patil, Akansha Kalra, Guanhong Tao, Daniel S. Brown)</author>
      <guid isPermaLink="false">2502.03698v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Reduce Lap Time for Autonomous Racing with Curvature-Integrated MPCC Local Trajectory Planning Method</title>
      <link>http://arxiv.org/abs/2502.03695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种针对自动驾驶赛车的优化轨迹规划算法——曲率集成模型预测轮廓控制（CiMPCC），该方法改进了传统模型预测轮廓控制（MPCC）在处理赛道显著弯曲变化时的局限性。&lt;h4&gt;背景&lt;/h4&gt;自主驾驶技术在赛车领域的广泛应用推动了相关研究的发展，而传统的MPCC方法在面对具有显著曲线变化的赛道时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的本地轨迹规划方法CiMPCC以解决传统MPCC在处理高曲率赛道中的性能限制问题。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将赛道中心线的曲率映射到参考速度轮廓，并将其整合进优化本地轨迹的速度成本函数中，以此优化基于赛道曲率变化的速度。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在具有挑战性的、包含急转弯的赛道上应用提出的CiMPCC算法后，赛车的整体圈速比其他自主赛车轨迹规划方法快11.4%-12.5%。&lt;h4&gt;结论&lt;/h4&gt;通过实施CiMPCC方法，可以显著提高自动驾驶赛车在复杂弯曲赛道上的性能，并缩短完成比赛的时间。&lt;h4&gt;翻译&lt;/h4&gt;自动驾驶技术的广泛应用极大地推动了自主赛车领域的进步。然而，传统模型预测轮廓控制（MPCC）在处理高曲率变化赛道时的表现不佳。为解决这一问题，论文提出了一种新的方法——曲率集成模型预测轮廓控制（CiMPCC），它根据赛道中心线的曲率优化本地轨迹的速度。该方案通过将赛道曲率映射到速度参考轮廓，并将其整合进成本函数中来实现，从而确保了在复杂弯曲赛道上的高效性能规划。研究团队使用1:10比例F1TENTH赛车进行了实验验证，结果显示，CiMPCC方法显著改善了赛车的整体圈速表现，在具有挑战性的急弯赛道上比其他方法快11.4%-12.5%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread application of autonomous driving technology has significantlyadvanced the field of autonomous racing. Model Predictive Contouring Control(MPCC) is a highly effective local trajectory planning method for autonomousracing. However, the traditional MPCC method struggles with racetracks thathave significant curvature changes, limiting the performance of the vehicleduring autonomous racing. To address this issue, we propose acurvature-integrated MPCC (CiMPCC) local trajectory planning method forautonomous racing. This method optimizes the velocity of the local trajectorybased on the curvature of the racetrack centerline. The specific implementationinvolves mapping the curvature of the racetrack centerline to a referencevelocity profile, which is then incorporated into the cost function foroptimizing the velocity of the local trajectory. This reference velocityprofile is created by normalizing and mapping the curvature of the racetrackcenterline, thereby ensuring efficient and performance-oriented localtrajectory planning in racetracks with significant curvature. The proposedCiMPCC method has been experimented on a self-built 1:10 scale F1TENTH racingvehicle deployed with ROS platform. The experimental results demonstrate thatthe proposed method achieves outstanding results on a challenging racetrackwith sharp curvature, improving the overall lap time by 11.4%-12.5% compared toother autonomous racing trajectory planning methods. Our code is available athttps://github.com/zhouhengli/CiMPCC.</description>
      <author>example@mail.com (Zhouheng Li, Lei Xie, Cheng Hu, Hongye Su)</author>
      <guid isPermaLink="false">2502.03695v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Anytime Planning for End-Effector Trajectory Tracking</title>
      <link>http://arxiv.org/abs/2502.03676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Robotics and Automation Letters (RAL)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种适应性框架，将常见的基于图的轨迹跟踪算法改进为任何时间（anytime）算法，并提高其效率和效果。&lt;h4&gt;背景&lt;/h4&gt;终端执行器轨迹跟踪算法用于驱动机器人操纵器跟随参考轨迹。在实际场景中，由于它们能够快速生成初始运动并在一段时间内持续优化这些运动，因此经常使用任何时间（anytime）算法。&lt;h4&gt;目的&lt;/h4&gt;提出一种适应性框架，使常见的基于图的轨迹跟踪算法成为任何时间算法，并提高其效率和效果。&lt;h4&gt;方法&lt;/h4&gt;通过识别参考路径的引导路径并偏向于沿着这些引导路径进行采样来改进现有基于图的轨迹跟踪算法。&lt;h4&gt;主要发现&lt;/h4&gt;重新设计了两个现有的基于图的轨迹跟踪算法，结果显示更新后的算法在三个实验中的表现更加有效。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够显著提高基于图的轨迹跟踪算法的效率和效果。&lt;h4&gt;翻译&lt;/h4&gt;末端执行器轨迹跟踪算法确定使机器人操作臂跟随参考路径所需的关节运动。在实际应用中，由于它们可以快速生成初始动作并在一段时间内不断改进这些动作，因此优选任何时间（anytime）算法。本文提出了一种框架，用于适应常见基于图的轨迹跟踪算法以实现任何时间特性，并提升其效率和性能。关键见解是识别出近似追踪参考路径的引导路径，并战略性地偏向于沿着这些引导路径进行采样。通过重新设计两个现有基于图的轨迹跟踪算法并在三个实验中评估改进后的算法，展示了所提出框架的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-effector trajectory tracking algorithms find joint motions that driverobot manipulators to track reference trajectories. In practical scenarios,anytime algorithms are preferred for their ability to quickly generate initialmotions and continuously refine them over time. In this paper, we present analgorithmic framework that adapts common graph-based trajectory trackingalgorithms to be anytime and enhances their efficiency and effectiveness. Ourkey insight is to identify guide paths that approximately track the referencetrajectory and strategically bias sampling toward the guide paths. Wedemonstrate the effectiveness of the proposed framework by restructuring twoexisting graph-based trajectory tracking algorithms and evaluating the updatedalgorithms in three experiments.</description>
      <author>example@mail.com (Yeping Wang, Michael Gleicher)</author>
      <guid isPermaLink="false">2502.03676v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control</title>
      <link>http://arxiv.org/abs/2502.03640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, accepted by the thirteenth International  Conference on Learning Representations (ICLR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架DGPPO，该框架能够同时学习离散图控制屏障函数和分布式高性能安全策略，以解决多智能体系统在处理未知离散时间动态、部分可观测性、邻居变化及输入约束等问题时的挑战。&lt;h4&gt;背景&lt;/h4&gt;对于任何系统而言，包括多智能体系统(MAS)，制定既能保证高任务性能又能满足安全性限制的控制政策是非常有必要的。一种确保MAS安全性的技术是分布式控制屏障函数(CBF)。然而，在缺乏高性能名义策略的情况下设计分布式的CBF策略以解决这些问题很困难。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架来学习处理未知离散时间动态、部分可观测性、邻居变化和输入约束的离散图CBF以及MAS的安全策略，从而在保证任务性能的同时满足安全性的限制。&lt;h4&gt;方法&lt;/h4&gt;设计了DGPPO框架，该框架能够在不同的模拟引擎上进行一系列多智能体任务，并且通过实验验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，DGPPO框架能够获得同时实现高任务性能和高安全性比率的策略，在所有环境中均使用相同的超参数设置。&lt;h4&gt;结论&lt;/h4&gt;DGPPO框架为解决MAS中未知离散时间动态、部分可观测性等问题提供了一种有效的解决方案，并且可以在保证安全性的前提下，达到与忽略安全约束的方法相当的任务性能水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：确保多智能体系统（MAS）的安全性的一种有前景的技术是分布式控制屏障函数（CBF）。然而，在缺乏高性能名义策略的情况下设计能够处理未知离散时间动态、部分可观测性、邻居变化和输入约束的分布式的CBF策略是很困难的。为此，我们提出了一种新的框架DGPPO，该框架可以同时学习处理邻居变化及输入限制的离散图控制屏障函数以及分布式高性能的安全政策。我们在三个不同的模拟引擎上进行了一系列多智能体任务以验证我们的方法，并且结果表明，在与现有方法相比时，DGPPO框架能够获得既实现高任务性能（匹配忽略安全约束的方法）又达到高安全性比率（匹配最保守的方法）的策略，并且在所有环境中使用相同的超参数设置。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Control policies that can achieve high task performance and satisfy safetyconstraints are desirable for any system, including multi-agent systems (MAS).One promising technique for ensuring the safety of MAS is distributed controlbarrier functions (CBF). However, it is difficult to design distributedCBF-based policies for MAS that can tackle unknown discrete-time dynamics,partial observability, changing neighborhoods, and input constraints,especially when a distributed high-performance nominal policy that can achievethe task is unavailable. To tackle these challenges, we propose DGPPO, a newframework that simultaneously learns both a discrete graph CBF which handlesneighborhood changes and input constraints, and a distributed high-performancesafe policy for MAS with unknown discrete-time dynamics. We empiricallyvalidate our claims on a suite of multi-agent tasks spanning three differentsimulation engines. The results suggest that, compared with existing methods,our DGPPO framework obtains policies that achieve high task performance(matching baselines that ignore the safety constraints), and high safety rates(matching the most conservative baselines), with a constant set ofhyperparameters across all environments.</description>
      <author>example@mail.com (Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan)</author>
      <guid isPermaLink="false">2502.03640v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.03607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近在扩散模型领域的进展为机器人技术带来了生成环境原始表示中的多样化和平滑轨迹的潜力，但这些模型难以执行关键约束（例如碰撞避免和运动学可行性）仍然是应用到路径规划中的挑战。特别是在多机器人路径规划中，该问题更加突出。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在机器人领域显示出巨大前景，尤其是在根据环境原始数据生成多样化且平滑的轨迹方面。然而，在实际的应用过程中，确保满足关键约束（如碰撞避免和运动学可行性）仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以解决多机器人路径规划中的这些问题，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;该工作提出了Simultaneous MRMP Diffusion (SMD) 方法，它将受限优化整合进扩散采样过程，产生不碰撞且符合运动学条件的轨迹。此外，还引入了一个全面的多机器人路径规划基准测试以在不同场景下评估轨迹规划算法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与传统的和基于学习的方法相比，SMD在复杂多机器人的环境中实现了更高的成功率和效率。&lt;h4&gt;结论&lt;/h4&gt;通过结合受限优化和扩散模型，可以有效提高多机器人运动规划的性能。同时，引入基准测试能够更好地评估不同算法的效果。&lt;h4&gt;翻译&lt;/h4&gt;最近在扩散模型领域的进展为机器人技术带来了生成环境原始表示中的多样化和平滑轨迹的潜力，但这些模型难以执行关键约束（例如碰撞避免和运动学可行性）仍然是应用到路径规划中的挑战。特别是在多机器人路径规划中，该问题更加突出。为了应对这一挑战，提出了一种新的方法Simultaneous MRMP Diffusion (SMD)，它将受限优化整合进扩散采样过程，产生不碰撞且符合运动学条件的轨迹。此外还引入了一个全面的多机器人路径规划基准测试以在不同场景下评估轨迹规划算法。实验结果表明，在复杂多机器人的环境中，与传统的和基于学习的方法相比，SMD实现了更高的成功率和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in diffusion models hold significant potential in robotics,enabling the generation of diverse and smooth trajectories directly from rawrepresentations of the environment. Despite this promise, applying diffusionmodels to motion planning remains challenging due to their difficulty inenforcing critical constraints, such as collision avoidance and kinematicfeasibility. These limitations become even more pronounced in Multi-RobotMotion Planning (MRMP), where multiple robots must coordinate in shared spaces.To address this challenge, this work proposes Simultaneous MRMP Diffusion(SMD), a novel approach integrating constrained optimization into the diffusionsampling process to produce collision-free, kinematically feasibletrajectories. Additionally, the paper introduces a comprehensive MRMP benchmarkto evaluate trajectory planning algorithms across scenarios with varying robotdensities, obstacle complexities, and motion constraints. Experimental resultsshow SMD consistently outperforms classical and learning-based motion planners,achieving higher success rates and efficiency in complex multi-robotenvironments.</description>
      <author>example@mail.com (Jinhao Liang, Jacob K Christopher, Sven Koenig, Ferdinando Fioretto)</author>
      <guid isPermaLink="false">2502.03607v1</guid>
      <pubDate>Fri, 07 Feb 2025 16:57:10 +0800</pubDate>
    </item>
    <item>
      <title>A Direct Semi-Exhaustive Search Method for Robust, Partial-to-Full Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2502.00115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;点云配准是一种寻找两个给定点云之间刚性变换的问题，对于机器人和计算机视觉领域至关重要。本文提出了一种名为Direct Semi-Exhaustive Search (DSES)的算法，该算法通过利用现代GPU并行化计算的优势来直接优化无对应关系的点云配准问题。&lt;h4&gt;背景&lt;/h4&gt;点云配准在机器人技术和计算机视觉中非常重要，其目的是找到使两个给定点云对齐的最佳刚性变换。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的点云配准算法DSES，该算法通过简化搜索过程和利用GPU并行化计算来提高性能。&lt;h4&gt;方法&lt;/h4&gt;DSES算法通过对可能的旋转矩阵进行迭代，并为每个旋转高效地计算出与其相关的最大内点平移。然后根据任何所需的距离度量直接计算每种变换候选{R, t}的相关误差，从而确定最佳刚性变换。&lt;h4&gt;主要发现&lt;/h4&gt;DSES在模拟ModelNet40基准测试中比现有的最先进的方法具有更好的性能，并且对于现实世界的机器人定位问题也表现出高性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过利用现代GPU的并行化计算能力，提出的直接半穷举搜索算法（DSES）为点云配准提供了一种有效的解决方案，尤其适用于部分到全范围内的点云注册任务及实际应用中的姿态估计。&lt;h4&gt;翻译&lt;/h4&gt;点云配准是指寻找使两个给定点云对齐的最佳刚性变换的问题，在机器人技术和计算机视觉领域中至关重要。本文的主要见解是可以通过利用算法简单但计算复杂的半穷举搜索方法直接优化无对应关系的点云配准问题，这种方法非常适合在现代GPU上并行化执行。我们提出的Direct Semi-Exhaustive Search (DSES)算法迭代可能的旋转矩阵，并为每个旋转高效地计算最大内点平移。它还根据任何所需的距离度量通过直接计算每种变换候选{R, t}的相关误差来确定最佳刚性变换。借助现代GPU的并行化计算能力，DSES在模拟ModelNet40基准测试中超越了最先进的方法，并且对于现实世界的机器人定位问题也表现出了高性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IROS58592.2024.10801518&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration refers to the problem of finding the rigidtransformation that aligns two given point clouds, and is crucial for manyapplications in robotics and computer vision. The main insight of this paper isthat we can directly optimize the point cloud registration problem withoutcorrespondences by utilizing an algorithmically simple, yet computationallycomplex, semi-exhaustive search approach that is very well-suited forparallelization on modern GPUs. Our proposed algorithm, Direct Semi-ExhaustiveSearch (DSES), iterates over potential rotation matrices and efficientlycomputes the inlier-maximizing translation associated with each rotation. Itthen computes the optimal rigid transformation based on any desired distancemetric by directly computing the error associated with each transformationcandidate $\{R, t\}$. By leveraging the parallelism of modern GPUs, DSESoutperforms state-of-the-art methods for partial-to-full point cloudregistration on the simulated ModelNet40 benchmark and demonstrates highperformance and robustness for pose estimation on a real-world robotics problem(https://youtu.be/q0q2-s2KSuA).</description>
      <author>example@mail.com (Richard Cheng, Chavdar Papozov, Dan Helmick, Mark Tjersland)</author>
      <guid isPermaLink="false">2502.00115v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
  <item>
      <title>Meta-Learning-Based People Counting and Localization Models Employing CSI from Commodity WiFi NICs</title>
      <link>http://arxiv.org/abs/2502.03117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 15 figures, submitted to IEEE Internet of Things Journal  (IoTJ)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用WiFi网络接口卡（NIC）测量的信道状态信息（CSI）进行人员计数和定位系统的开发。通过预处理去除CSI中的偏移，提出了基于迁移学习的人体计数和定位模型，并展示了其在不同环境下的高精度感知能力。&lt;h4&gt;背景&lt;/h4&gt;信道状态信息（CSI）能够提供信号传播的幅度和相位等有用信息，在人员计数和定位系统中具有潜在的应用价值。然而，由于各种不确定因素导致的偏移以及外部WiFi设备通信产生的干扰信号，使得直接使用CSI存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种预处理方法以消除CSI中的偏移，并在此基础上设计出适应不同测量环境的人体计数与定位模型。&lt;h4&gt;方法&lt;/h4&gt;首先提出了CSI数据的预处理算法来去除由于各种不确定性带来的偏移。然后基于迁移学习，设计了人员计数和定位模型。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的元学习（meta-learning）基的人体计数和定位模型相较于简单的训练测试过程展现出更高的感知精度。&lt;h4&gt;结论&lt;/h4&gt;通过CSI预处理以及基于元学习的建模方法能够有效提高WiFi网络在人体位置检测与计数方面的性能，为无线环境中的人员计数提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;在这篇文章中，我们考虑了利用从商用WiFi网络接口卡（NIC）测量出的信道状态信息（CSI）来进行人员计数和定位系统。虽然CSI能够提供信号传播幅度和相位的有用信息来描述感兴趣的测量环境中的信号特性，但是由于各种不确定因素导致的偏移以及外部WiFi设备通信产生的干扰信号问题，使得直接使用CSI存在诸多挑战。在本文中，我们首先提出了一种预处理算法以去除这种偏移，并确保了低延迟操作而不需过滤过程。然后基于迁移学习设计人员计数和定位模型，使之能够适应不同的测量环境。数值结果表明，所提出的元学习基的人体计数与定位模型相比其它遵循简单训练测试流程的学习方案可以实现更高的感知精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider people counting and localization systemsexploiting channel state information (CSI) measured from commodity WiFi networkinterface cards (NICs). While CSI has useful information of amplitude and phaseto describe signal propagation in a measurement environment of interest, CSImeasurement suffers from offsets due to various uncertainties. Moreover, anuncontrollable external environment where other WiFi devices communicate eachother induces interfering signals, resulting in erroneous CSI captured at areceiver. In this paper, preprocessing of CSI is first proposed for offsetremoval, and it guarantees low-latency operation without any filtering process.Afterwards, we design people counting and localization models based onpre-training. To be adaptive to different measurement environments,meta-learning-based people counting and localization models are also proposed.Numerical results show that the proposed meta-learning-based people countingand localization models can achieve high sensing accuracy, compared to otherlearning schemes that follow simple training and test procedures.</description>
      <author>example@mail.com (Jihoon Cha, Hwanjin Kim, Junil Choi)</author>
      <guid isPermaLink="false">2502.03117v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Intent Representation Learning with Large Language Model for Recommendation</title>
      <link>http://arxiv.org/abs/2502.03307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;意图导向的推荐系统由于揭示了潜在的细粒度偏好而受到关注。这些系统利用用户和物品之间的交互来推断隐藏意图，从而提高推荐的可解释性。&lt;h4&gt;背景&lt;/h4&gt;当前的方法大多将意图定义为随着用户与系统的互动而更新的学习参数。然而，大多数方法忽视了文本信息（例如用户评论、商品描述）的重要性，这有助于缓解交互意图稀疏的问题。&lt;h4&gt;目的&lt;/h4&gt;为了利用多模态数据中的丰富信息解决上述挑战，论文提出了一种基于大语言模型的框架来构建和优化推荐系统。&lt;h4&gt;方法&lt;/h4&gt;该研究提出了IRLLRec框架，它通过使用双塔架构学习跨模式意图表示，并且采用成对和翻译对齐技术消除模式间差异，提升系统的鲁棒性。此外，利用动量蒸馏技术在融合后的意图表示上实现教师-学生模型的学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示IRLLRec框架显著优于基准方法，在多个数据集上的性能测试中取得了优秀的成果。&lt;h4&gt;结论&lt;/h4&gt;通过结合大规模语言模型的能力，该研究提出了一种增强推荐系统的有效策略。这一工作不仅提高了多模态意图表示的一致性和鲁棒性，还为解决基于交互的推荐系统中的文本和行为信息差异提供了解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Intent-based recommender systems have garnered significant attention for uncovering latent fine-grained preferences. Intents, as underlying factors of interactions, are crucial for improving recommendation interpretability. Most methods define intents as learnable parameters updated alongside interactions. However, existing frameworks often overlook textual information (e.g., user reviews, item descriptions), which is crucial for alleviating the sparsity of interaction intents. Exploring these multimodal intents, especially the inherent differences in representation spaces, poses two key challenges: i) How to align multimodal intents and effectively mitigate noise issues; ii) How to extract and match latent key intents across modalities. To tackle these challenges, we propose a model-agnostic framework, Intent Representation Learning with Large Language Model (IRLLRec), which leverages large language models (LLMs) to construct multimodal intents and enhance recommendations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intent-based recommender systems have garnered significant attention foruncovering latent fine-grained preferences. Intents, as underlying factors ofinteractions, are crucial for improving recommendation interpretability. Mostmethods define intents as learnable parameters updated alongside interactions.However, existing frameworks often overlook textual information (e.g., userreviews, item descriptions), which is crucial for alleviating the sparsity ofinteraction intents. Exploring these multimodal intents, especially theinherent differences in representation spaces, poses two key challenges: i) Howto align multimodal intents and effectively mitigate noise issues; ii) How toextract and match latent key intents across modalities. To tackle thesechallenges, we propose a model-agnostic framework, Intent RepresentationLearning with Large Language Model (IRLLRec), which leverages large languagemodels (LLMs) to construct multimodal intents and enhance recommendations.Specifically, IRLLRec employs a dual-tower architecture to learn multimodalintent representations. Next, we propose pairwise and translation alignment toeliminate inter-modal differences and enhance robustness against noisy inputfeatures. Finally, to better match textual and interaction-based intents, weemploy momentum distillation to perform teacher-student learning on fusedintent representations. Empirical evaluations on three datasets show that ourIRLLRec framework outperforms baselines. The implementation is available athttps://github.com/wangyu0627/IRLLRec.</description>
      <author>example@mail.com (Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang)</author>
      <guid isPermaLink="false">2502.03307v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>TopoCL: Topological Contrastive Learning for Time Series</title>
      <link>http://arxiv.org/abs/2502.02924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to TNNLS (under review)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章提出了一种新的时间序列表示学习方法，通过拓扑对比学习（TopoCL），解决了传统对比学习在数据增强过程中可能破坏季节性模式和时间依赖关系的问题。&lt;h4&gt;背景&lt;/h4&gt;通用的时间序列表示学习对于现实世界中的分类、异常检测和预测等应用至关重要。然而，现有的对比学习方法容易因为数据增强过程而丢失时间序列的语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于拓扑学的方法来改善时间序列对比学习，从而更有效地捕捉和保持时间序列的数据特征。&lt;h4&gt;方法&lt;/h4&gt;将时间序列的时间特性和拓扑特性视为不同的模式，并利用持久同调构建时间序列数据的拓扑特征，在持久图表示中体现。设计神经网络对这些持久图进行编码，同时优化时间和时间-拓扑对应关系中的对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过在四个下游任务上的实验验证了TopoCL的有效性，并证明它能够达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效解决了现有对比学习方法中可能出现的信息损失问题，为时间序列的分类、异常检测和预测等应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;通用的时间序列表示学习具有挑战性但对现实世界的应用（如分类、异常检测及预测）至关重要。最近，对比学习被积极研究以解决时间序列表示的问题。然而，一个关键问题是数据增强过程可能扭曲季节模式或时间依赖关系，导致语义信息的丢失。为了解决这个问题，我们提出了用于时间序列的时间拓扑对比学习方法（TopoCL）。TopoCL通过引入持久同调来缓解这种信息损失，该方法能够捕捉在转换下不变的数据拓扑特征。在这篇文章中，我们将时间序列数据的时间和拓扑属性视为不同的模式。具体而言，我们利用持久同调构建时间序列数据的拓扑特征，并用持续图表示这些特征。然后设计了一个神经网络来编码这些持续图。我们的方法同时优化了时间模态中的对比学习和时间-拓扑对应关系，促进了对时间序列的时间语义和拓扑属性的全面理解。我们针对分类、异常检测、预测和迁移学习四个下游任务进行了广泛的实验。结果表明TopoCL达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal time series representation learning is challenging but valuable inreal-world applications such as classification, anomaly detection, andforecasting. Recently, contrastive learning (CL) has been actively explored totackle time series representation. However, a key challenge is that the dataaugmentation process in CL can distort seasonal patterns or temporaldependencies, inevitably leading to a loss of semantic information. To addressthis challenge, we propose Topological Contrastive Learning for time series(TopoCL). TopoCL mitigates such information loss by incorporating persistenthomology, which captures the topological characteristics of data that remaininvariant under transformations. In this paper, we treat the temporal andtopological properties of time series data as distinct modalities.Specifically, we compute persistent homology to construct topological featuresof time series data, representing them in persistence diagrams. We then designa neural network to encode these persistent diagrams. Our approach jointlyoptimizes CL within the time modality and time-topology correspondence,promoting a comprehensive understanding of both temporal semantics andtopological properties of time series. We conduct extensive experiments on fourdownstream tasks-classification, anomaly detection, forecasting, and transferlearning. The results demonstrate that TopoCL achieves state-of-the-artperformance.</description>
      <author>example@mail.com (Namwoo Kim, Hyungryul Baik, Yoonjin Yoon)</author>
      <guid isPermaLink="false">2502.02924v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Calibrated Unsupervised Anomaly Detection in Multivariate Time-series using Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.03245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication and presentation at the  2025 IEEE International systems Conference (SysCon)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文研究了使用潜空间中的强化学习（RL）进行多变量时间序列数据的无监督异常检测。提出的方法利用自编码器来克服由于缺乏异常样本而导致的误报问题。&lt;h4&gt;背景&lt;/h4&gt;在进行多变量时间序列数据的无监督异常检测时，一个显著的问题是缺少异常数据样本，这常常导致将异常事件错误分类为正常事件，从而产生假阴性结果。强化学习能够通过促进探索和平衡利用来克服这一局限，并且可以通过生成合成异常数据并引入监督框架进一步微调模型。&lt;h4&gt;目的&lt;/h4&gt;本文旨在研究在多变量时间序列数据的无监督异常检测中应用强化学习的有效性和波变换分析增强技术，以提高对时间和频率域内细微变化的识别能力。&lt;h4&gt;方法&lt;/h4&gt;利用自编码器（AE）和强化学习在潜空间进行探索。引入了小波变换用于改进异常检测过程，并通过生成合成数据校准决策边界。&lt;h4&gt;主要发现&lt;/h4&gt;小波变换能够增强多分辨率下的异常检测，提取的小波系数可以用来识别时间序列中的突然或微妙的变化，从而提高异常检测的精确度。&lt;h4&gt;结论&lt;/h4&gt;结合自编码器、强化学习和小波分析的方法，在无监督环境中有效提高了对时间和频率域内异常模式的区分能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已从英文原文翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates unsupervised anomaly detection in multivariatetime-series data using reinforcement learning (RL) in the latent space of anautoencoder. A significant challenge is the limited availability of anomalousdata, often leading to misclassifying anomalies as normal events, thus raisingfalse negatives. RL can help overcome this limitation by promoting explorationand balancing exploitation during training, effectively preventing overfitting.Wavelet analysis is also utilized to enhance anomaly detection, enablingtime-series data decomposition into both time and frequency domains. Thisapproach captures anomalies at multiple resolutions, with wavelet coefficientsextracted to detect both sudden and subtle shifts in the data, thereby refiningthe anomaly detection process. We calibrate the decision boundary by generatingsynthetic anomalies and embedding a supervised framework within the model. Thissupervised element aids the unsupervised learning process by fine-tuning thedecision boundary and increasing the model's capacity to distinguish betweennormal and anomalous patterns effectively.</description>
      <author>example@mail.com (Saba Sanami, Amir G. Aghdam)</author>
      <guid isPermaLink="false">2502.03245v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>UMC: Unified Resilient Controller for Legged Robots with Joint Malfunctions</title>
      <link>http://arxiv.org/abs/2502.03035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新的无模型、两阶段训练框架（UMC），旨在提高自主腿足机器人在不可预测的损坏情况下的适应能力。&lt;h4&gt;背景&lt;/h4&gt;现有的基于多策略或元学习的方法存在泛化能力有限和维护复杂的问题，限制了它们的应用效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够增强腿部机器人损伤容忍度的新框架，以解决现有方法存在的问题。&lt;h4&gt;方法&lt;/h4&gt;该研究首先分析并总结出八种损坏场景类型，并提出了一个新的无模型、两阶段训练框架（UMC），引入掩码机制来提高对损害的适应能力。第一阶段在正常环境中训练模型，第二阶段通过使用掩码来阻止机器人依赖故障部件，从而实现灵活的步态调整。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法能使任务完成率提升36%（对于transformer）和39%（对于MLP），在三种运动任务中均表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法能够显著提高腿足机器人在面对未知损坏情况时的任务执行能力。未来将公开源代码及训练模型，以便于研究社区使用。&lt;h4&gt;翻译&lt;/h4&gt;适应不可预测的损害是自主腿部机器人的关键需求，现有的多策略或元学习框架面临泛化能力和维护复杂度等挑战。本文首先分析总结了八种损坏场景类型，并提出了一种无模型、两阶段的训练框架（UMC），通过掩码机制增强损伤耐受性。实验结果表明，在三种运动任务中，所提方法能使任务完成率分别提升36%和39%，未来将公开源代码及训练模型供社区使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptation to unpredictable damages is crucial for autonomous legged robots,yet existing methods based on multi-policy or meta-learning frameworks facechallenges like limited generalization and complex maintenance. To address thisissue, we first analyze and summarize eight types of damage scenarios,including sensor failures and joint malfunctions. Then, we propose a novel,model-free, two-stage training framework, Unified Malfunction Controller (UMC),incorporating a masking mechanism to enhance damage resilience. Specifically,the model is initially trained with normal environments to ensure robustperformance under standard conditions. In the second stage, we use masks toprevent the legged robot from relying on malfunctioning limbs, enablingadaptive gait and movement adjustments upon malfunction. Experimental resultsdemonstrate that our approach improves the task completion capability by anaverage of 36% for the transformer and 39% for the MLP across three locomotiontasks. The source code and trained models will be made available to the public.</description>
      <author>example@mail.com (Yu Qiu, Xin Lin, Jingbo Wang, Xiangtai Li, Lu Qi, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2502.03035v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Linearized Optimal Transport pyLOT Library: A Toolkit for Machine Learning on Point Clouds</title>
      <link>http://arxiv.org/abs/2502.03439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;pyLOT库提供了线性化最优传输（LOT）技术及其在下游任务中的应用方法的Python实现。&lt;h4&gt;背景&lt;/h4&gt;论文介绍了一种通过最优传输映射将概率分布嵌入到Hilbert空间的方法，该方法可以简化后续任务的处理。&lt;h4&gt;目的&lt;/h4&gt;旨在展示pyLOT库的功能，并提供一个案例研究来说明如何使用3D灵长类动物牙齿扫描数据进行机器学习任务。&lt;h4&gt;方法&lt;/h4&gt;利用pyLOT库中的线性化最优传输技术将原始数据转换为Hilbert空间内的表示，这样可以方便地应用现成的线性机器学习算法来执行分类、聚类等任务。&lt;h4&gt;主要发现&lt;/h4&gt;在3D灵长类动物牙齿扫描数据上进行的实验表明，使用LOT嵌入表示能够简化复杂问题，并将其转化为简单的线性操作。例如，分类、聚类和降维等下游任务都可以通过直接应用标准的机器学习算法轻松完成。&lt;h4&gt;结论&lt;/h4&gt;提出的方法展示了将概率分布映射到Hilbert空间中的潜在价值，使得复杂的机器学习任务可以通过简单的线性方法来处理，并且适用于广泛的领域如计算机视觉和数据科学。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经按照要求进行了中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pyLOT library offers a Python implementation of linearized optimaltransport (LOT) techniques and methods to use in downstream tasks. The pipelineembeds probability distributions into a Hilbert space via the Optimal Transportmaps from a fixed reference distribution, and this linearization allowsdownstream tasks to be completed using off the shelf (linear) machine learningalgorithms. We provide a case study of performing ML on 3D scans of lemurteeth, where the original questions of classification, clustering, dimensionreduction, and data generation reduce to simple linear operations performed onthe LOT embedded representations.</description>
      <author>example@mail.com (Jun Linwu, Varun Khurana, Nicholas Karris, Alexander Cloninger)</author>
      <guid isPermaLink="false">2502.03439v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>TD3: Tucker Decomposition Based Dataset Distillation Method for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2502.02854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TD3是一种基于Tucker分解的新型数据蒸馏方法，旨在通过提取合成序列摘要来加速推荐系统的模型训练，并在元学习框架中保持模型性能。&lt;h4&gt;背景&lt;/h4&gt;随着AI转向以数据为中心的方法，如何从大规模数据集中有效地提炼出关键信息成为研究热点。尤其是在处理用户和物品之间离散且顺序相关互动的场景下，这种方法面临着挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Tucker分解的数据蒸馏方法TD3，用于序列推荐系统中的高效模型训练。&lt;h4&gt;方法&lt;/h4&gt;TD3利用元学习框架内的Tucker分解将原始数据提炼成一个完全表达性的合成序列摘要，并将其解耦为四个因子：合成用户潜在因子、时间动态潜在因子、共享物品潜在因子以及关系核心。同时，为了超越简单的性能匹配方法，引入了双层优化中的代理目标来对齐基于原始数据和合成序列摘要的模型特征空间。&lt;h4&gt;主要发现&lt;/h4&gt;TD3能够在保持模型表现的同时显著降低训练成本，并且通过实验在多个公共数据集上验证了其优越性和跨架构泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TD3是一种高效的序列推荐系统中的数据蒸馏技术，能够加速模型训练过程，同时确保模型的性能不受影响。该方法已开源，可供研究者使用和进一步开发。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种基于Tucker分解的数据蒸馏方法（TD3），旨在通过从原始用户-物品互动序列中提炼出一个精简且完全表达性的合成序列摘要来加速推荐模型的训练过程，并保持其性能。该方法利用元学习框架，采用双层优化技术来实现目标功能和特征空间对齐，同时引入RaT-BPTT以处理长依赖问题。实验结果表明，TD3在多个公开数据集上表现出了优越性和广泛的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3696410.3714613&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of data-centric AI, the focus of recommender systems has shiftedfrom model-centric innovations to data-centric approaches. The success ofmodern AI models is built on large-scale datasets, but this also results insignificant training costs. Dataset distillation has emerged as a key solution,condensing large datasets to accelerate model training while preserving modelperformance. However, condensing discrete and sequentially correlated user-iteminteractions, particularly with extensive item sets, presents considerablechallenges. This paper introduces \textbf{TD3}, a novel \textbf{T}ucker\textbf{D}ecomposition based \textbf{D}ataset \textbf{D}istillation methodwithin a meta-learning framework, designed for sequential recommendation. TD3distills a fully expressive \emph{synthetic sequence summary} from originaldata. To efficiently reduce computational complexity and extract refined latentpatterns, Tucker decomposition decouples the summary into four factors:\emph{synthetic user latent factor}, \emph{temporal dynamics latent factor},\emph{shared item latent factor}, and a \emph{relation core} that models theirinterconnections. Additionally, a surrogate objective in bi-level optimizationis proposed to align feature spaces extracted from models trained on bothoriginal data and synthetic sequence summary beyond the na\"ive performancematching approach. In the \emph{inner-loop}, an augmentation technique allowsthe learner to closely fit the synthetic summary, ensuring an accurate updateof it in the \emph{outer-loop}. To accelerate the optimization process andaddress long dependencies, RaT-BPTT is employed for bi-level optimization.Experiments and analyses on multiple public datasets have confirmed thesuperiority and cross-architecture generalizability of the proposed designs.Codes are released at https://github.com/USTC-StarTeam/TD3.</description>
      <author>example@mail.com (Jiaqing Zhang, Mingjia Yin, Hao Wang, Yawen Li, Yuyang Ye, Xingyu Lou, Junping Du, Enhong Chen)</author>
      <guid isPermaLink="false">2502.02854v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>IRIS: An Immersive Robot Interaction System</title>
      <link>http://arxiv.org/abs/2502.03297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的机器人交互系统IRIS，该系统利用扩展现实（XR）技术进行机器人数据采集和多模拟器、基准测试及真实场景中的交互。&lt;h4&gt;背景&lt;/h4&gt;现有的基于XR的数据收集系统虽然提供高效直观的解决方案，但难以复制和重复使用。这是因为当前系统高度定制化于特定模拟器的具体用例和环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的、易于扩展的框架IRIS，支持多种模拟器、基准测试及头显设备，并能够从现实世界传感器（如深度相机捕获的点云）中获取额外信息。&lt;h4&gt;方法&lt;/h4&gt;生成统一场景规范直接来自模拟器或真实世界的传感器并传输到XR头显，创建相同的场景。该规范使IRIS支持模拟器提供的任何对象、资产和机器人。引入共享空间锚点和稳健的通信协议来链接多个XR头显之间的仿真。&lt;h4&gt;主要发现&lt;/h4&gt;在使用流行机器人模拟器（如MuJoCo，IsaacSim，CoppeliaSim和Genesis）以及在Meta Quest 3和HoloLens 2上的用户研究中展示了IRIS的多功能性。研究表明，在LIBERO基准测试的数据收集任务上，IRIS显著优于基线方案。&lt;h4&gt;结论&lt;/h4&gt;IRIS展示出其作为机器人数据采集工具的强大潜力，并为未来的研究提供了坚实的基础。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种基于扩展现实（XR）技术的沉浸式机器人交互系统——IRIS。此系统旨在支持跨多个模拟器、基准测试以及真实场景中的机器人数据收集和互动。现有的基于XR的数据采集方案虽然高效直观，但因其高度定制化而难以复制使用。相较之下，IRIS提供了一个易于扩展的新框架，并能够从现实世界传感器中获取额外信息，如通过深度相机捕获的点云。该系统生成统一场景规范，并支持所有模拟器提供的对象、资产和机器人。它还引入了共享空间锚点及稳健通信协议，使多个XR设备之间可以同步共享同一个场景。经过多款流行机器人模拟器以及在Meta Quest 3和HoloLens 2上的测试后，IRIS展示出其广泛的适用性。用户研究证实，在LIBERO基准数据收集任务中，IRIS相比基线方案表现出明显优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces IRIS, an immersive Robot Interaction System leveragingExtended Reality (XR), designed for robot data collection and interactionacross multiple simulators, benchmarks, and real-world scenarios. Whileexisting XR-based data collection systems provide efficient and intuitivesolutions for large-scale data collection, they are often challenging toreproduce and reuse. This limitation arises because current systems are highlytailored to simulator-specific use cases and environments. IRIS is a novel,easily extendable framework that already supports multiple simulators,benchmarks, and even headsets. Furthermore, IRIS is able to include additionalinformation from real-world sensors, such as point clouds captured throughdepth cameras. A unified scene specification is generated directly fromsimulators or real-world sensors and transmitted to XR headsets, creatingidentical scenes in XR. This specification allows IRIS to support any of theobjects, assets, and robots provided by the simulators. In addition, IRISintroduces shared spatial anchors and a robust communication protocol thatlinks simulations between multiple XR headsets. This feature enables multipleXR headsets to share a synchronized scene, facilitating collaborative andmulti-user data collection. IRIS can be deployed on any device that supportsthe Unity Framework, encompassing the vast majority of commercially availableheadsets. In this work, IRIS was deployed and tested on the Meta Quest 3 andthe HoloLens 2. IRIS showcased its versatility across a wide range ofreal-world and simulated scenarios, using current popular robot simulators suchas MuJoCo, IsaacSim, CoppeliaSim, and Genesis. In addition, a user studyevaluates IRIS on a data collection task for the LIBERO benchmark. The studyshows that IRIS significantly outperforms the baseline in both objective andsubjective metrics.</description>
      <author>example@mail.com (Xinkai Jiang, Qihao Yuan, Enes Ulas Dincer, Hongyi Zhou, Ge Li, Xueyin Li, Julius Haag, Nicolas Schreiber, Kailai Li, Gerhard Neumann, Rudolf Lioutikov)</author>
      <guid isPermaLink="false">2502.03297v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications</title>
      <link>http://arxiv.org/abs/2502.03395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文评估了统计、机器学习(ML)、深度学习和基础模型在使用德国数千家餐厅的真实世界数据预测14天内的小时销售额方面的性能。这些方法包括天气条件、日历事件以及时间段等特征。结果表明，基于ML的元模型表现出色，并强调像Chronos和TimesFM这样的基础模型具有巨大的潜力，它们能够通过零样本推理提供竞争力的表现，而无需过多地进行特征工程。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测对酒店行业的运营智能至关重要，在大规模分布式系统中尤为挑战性。在这样复杂的情境下，如何有效地预测销售额成为了一个关键问题。&lt;h4&gt;目的&lt;/h4&gt;评估不同模型（统计、机器学习(ML)、深度学习和基础模型）在使用德国数千家餐厅的真实世界数据进行时间序列预测方面的性能。&lt;h4&gt;方法&lt;/h4&gt;研究中采用了天气条件、日历事件以及时间段等特征来构建预测模型。同时，比较了各种模型包括基于机器学习的元模型，以及像Chronos和TimesFM这样的基础模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;1. 基于ML的元模型表现优异；2. Chronos和TimesFM这类的基础模型通过零样本推理提供了竞争力的表现；3. 采用PySpark-Pandas混合方法在大规模部署中实现了水平可扩展性。&lt;h4&gt;结论&lt;/h4&gt;机器学习及深度学习模型尤其基于Meta-Model的方法以及新兴基础模型（如Chronos、TimesFM）表现出良好性能，同时建议在未来的研究和实际应用中进一步探索零样本推理的潜力，并考虑采用PySpark-Pandas混合方法来提高大规模系统的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is essential for operational intelligence in thehospitality industry, and particularly challenging in large-scale, distributedsystems. This study evaluates the performance of statistical, machine learning(ML), deep learning, and foundation models in forecasting hourly sales over a14-day horizon using real-world data from a network of thousands of restaurantsacross Germany. The forecasting solution includes features such as weatherconditions, calendar events, and time-of-day patterns. Results demonstrate thestrong performance of ML-based meta-models and highlight the emerging potentialof foundation models like Chronos and TimesFM, which deliver competitiveperformance with minimal feature engineering, leveraging only the pre-trainedmodel (zero-shot inference). Additionally, a hybrid PySpark-Pandas approachproves to be a robust solution for achieving horizontal scalability inlarge-scale deployments.</description>
      <author>example@mail.com (Issar Arab, Rodrigo Benitez)</author>
      <guid isPermaLink="false">2502.03395v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators</title>
      <link>http://arxiv.org/abs/2502.03424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under review at Computer-Aided Civil and  Infrastructure Engineering&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了一种用于预测建筑结构中最易燃点（MFSP）的新框架，该框架使用集成火灾动力学和有限元分析的神经网络方法。&lt;h4&gt;背景&lt;/h4&gt;消防安全是土木工程与机械工程中的关键研究领域，特别是在确保建筑物在火灾事件中的结构稳定性方面。准确地预测MFSP对于优化建筑结构评估过程至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个利用可微代理模型（differentiable agent model）的新框架，以高效生成标记数据来预测MFSP，并直接训练用于该重要指标的预测器。&lt;h4&gt;方法&lt;/h4&gt;- 生成了广泛的模拟数据，包括建筑和火灾场景。- 使用图神经网络表示建筑物结构。- 应用迁移学习优化训练过程。- 引入边更新机制以动态调整边属性，反映火灾条件下的财产变化。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在准确预测最大层间位移比（MIDR）和MFSP方面表现出色，从而推进了建筑结构消防安全分析的发展。&lt;h4&gt;结论&lt;/h4&gt;该神经网络框架提供了一种有效的方法来预测建筑中的最易燃点，有助于优化设计过程并提高火灾安全性能。&lt;h4&gt;翻译&lt;/h4&gt;消防安全是土木工程与机械工程中的关键研究领域，特别是在确保建筑物在火灾事件中的结构稳定性方面。文中提出一种新的MFSP预测框架，该框架结合了火灾动力学和有限元分析，并利用可微代理模型生成标记数据，直接训练用于关键指标的预测器。通过应用迁移学习、边更新机制以及大量模拟数据的支持，所提出的模型准确地预测了建筑结构在火灾条件下的性能（MIDR）与MFSP，从而提升了消防安全分析水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fire safety is a critical area of research in civil and mechanicalengineering, particularly in ensuring the structural stability of buildingsduring fire events. The Most Fire-Sensitive Point (MFSP) in a structure is thelocation where a fire would cause the greatest impact on structural stability.Accurate prediction of the MFSP is vital for streamlining structuralassessments and optimizing the design process. This paper presents a novelframework for MFSP prediction using a neural network-based approach thatintegrates fire dynamics and finite element analysis through a differentiableagent model. The framework focuses on predicting the Maximum Interstory DriftRatio (MIDR), a key indicator of structural performance under fire conditions.By leveraging the differentiable agent model, we efficiently generate labeleddata for MFSP and directly train a predictor for this critical metric. Toachieve this, we generated extensive simulation data encompassing structuraland fire scenarios and employed graph neural networks to represent the buildingstructures. Transfer learning was applied to optimize the training process, andan edge update mechanism was introduced to dynamically adjust edge attributes,reflecting property changes under fire conditions. The proposed model wasrigorously evaluated on simulation data, demonstrating strong performance inaccurately predicting both MIDR and MFSP, thus advancing fire safety analysisfor building structures.</description>
      <author>example@mail.com (Yuan Xinjie, Khalid M. Mosalam)</author>
      <guid isPermaLink="false">2502.03424v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-based Event Data Coding: A Joint Spatiotemporal and Polarity Solution</title>
      <link>http://arxiv.org/abs/2502.03285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种基于深度学习的联合事件数据编码（DL-JEC）方案，用于压缩神经形态视觉传感器生成的高分辨率、实时性要求高的事件数据。&lt;h4&gt;背景&lt;/h4&gt;神经形态视觉传感器或称作事件相机因需要高速度、宽动态范围和低延迟的数据采集而变得重要。这类相机产生的像素级事件包含时空信息与极性信息，传统帧基摄像头无法比拟。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的编码方案来处理神经形态视觉传感器生成的大量数据，并探讨损失压缩技术在保证计算机视觉任务性能的情况下减少比特率的可能性。&lt;h4&gt;方法&lt;/h4&gt;利用点云编码解决方案对事件数据进行编码的方法被提出。该研究引入了一种采用单一点云表示方式的新颖深度学习（DL）联合事件数据编码方案，此方案能够更好地利用时空和极性事件信息之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的DL-JEC方案比现有传统和基于DL的最先进的事件数据编码解决方案实现了显著的压缩性能改进。此外，还表明在某些计算机视觉任务中（如事件分类）使用损失压缩技术并不会影响最终的任务执行效果。&lt;h4&gt;结论&lt;/h4&gt;提出了一种创新性的深度学习联合事件数据编码方法，该方法不仅能有效降低比特率还能维持高质量的神经形态数据传输和处理，适用于多种需要高速度、低延迟的数据采集应用场合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuromorphic vision sensors, commonly referred to as event cameras, haverecently gained relevance for applications requiring high-speed, high dynamicrange and low-latency data acquisition. Unlike traditional frame-based camerasthat capture 2D images, event cameras generate a massive number of pixel-levelevents, composed by spatiotemporal and polarity information, with very hightemporal resolution, thus demanding highly efficient coding solutions. Existingsolutions focus on lossless coding of event data, assuming that no distortionis acceptable for the target use cases, mostly including computer vision tasks.One promising coding approach exploits the similarity between event data andpoint clouds, thus allowing to use current point cloud coding solutions to codeevent data, typically adopting a two-point clouds representation, one for eachevent polarity. This paper proposes a novel lossy Deep Learning-based JointEvent data Coding (DL-JEC) solution adopting a single-point cloudrepresentation, thus enabling to exploit the correlation between thespatiotemporal and polarity event information. DL-JEC can achieve significantcompression performance gains when compared with relevant conventional andDL-based state-of-the-art event data coding solutions. Moreover, it is shownthat it is possible to use lossy event data coding with its reduced rateregarding lossless coding without compromising the target computer vision taskperformance, notably for event classification. The use of novel adaptive voxelbinarization strategies, adapted to the target task, further enables DL-JEC toreach a superior performance.</description>
      <author>example@mail.com (Abdelrahman Seleem, André F. R. Guarda, Nuno M. M. Rodrigues, Fernando Pereira)</author>
      <guid isPermaLink="false">2502.03285v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration</title>
      <link>http://arxiv.org/abs/2502.03238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted in Computers in Biology and Medicine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;计算机辅助诊断在减轻医生工作负担方面表现出色，但样本不平衡导致算法偏向于多数类别，对少数类别的表现不佳。研究提出了一种新的长尾医学诊断（LMD）框架来解决这个问题。&lt;h4&gt;背景&lt;/h4&gt;现有的方法试图通过解耦特征表示和分类来解决长尾问题，但由于分布不均和少数类别的有限样本量，这些方法容易导致偏见的表示学习和不足的分类器校准。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的LMD框架以实现平衡医学图像分类在长尾数据集上的性能。&lt;h4&gt;方法&lt;/h4&gt;开发了一种关系感知表示学习（RRL）方案来增强表征能力，通过不同的数据增强鼓励编码器捕捉内在语义特征。还提出了一个迭代分类器校准（ICC）方案，通过生成大量均衡的虚拟特征并以期望最大化方式微调编码器来进行分类器的迭代校准。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开的长尾医学数据集上的综合实验表明，该LMD框架显著超过了现有的先进方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法可以平衡少数类别的表现，并使分类器优化无偏，同时保持多数类别中的诊断知识。源代码可以在https://github.com/peterlipan/LMD访问到。&lt;h4&gt;翻译&lt;/h4&gt;最近计算机辅助诊断展示了有希望的表现，有效地减轻了临床医生的工作负担。然而，不同疾病之间固有的样本不平衡导致算法偏向于大多数类别，从而导致罕见类别的表现不佳。现有的工作将这一挑战视为长尾问题并试图通过解耦特征表示和分类来解决这个问题。但是，由于分布不均和少数类别的有限样本量，这些工作容易导致偏见的表示学习和不足的分类器校准。为了应对这些问题，我们提出了一种新的Long-tailed Medical Diagnosis（LMD）框架，在长尾数据集上进行平衡医学图像分类。在初始阶段，我们开发了一种关系感知表示学习（RRL）方案来通过不同的数据增强鼓励编码器捕捉内在语义特征以提高表征能力。随后，我们提出了一种迭代分类器校准（ICC）方案来进行迭代校准。这可以通过生成大量均衡的虚拟特征并以期望最大化方式微调编码器来实现。提出的ICC补偿了少数类别，使无偏分类器优化成为可能，同时保持多数类别的诊断知识。在三个公开的长尾医学数据集上的综合实验表明，我们的LMD框架显著超过了现有的先进方法。源代码可以在https://github.com/peterlipan/LMD访问到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently computer-aided diagnosis has demonstrated promising performance,effectively alleviating the workload of clinicians. However, the inherentsample imbalance among different diseases leads algorithms biased to themajority categories, leading to poor performance for rare categories. Existingworks formulated this challenge as a long-tailed problem and attempted totackle it by decoupling the feature representation and classification. Yet, dueto the imbalanced distribution and limited samples from tail classes, theseworks are prone to biased representation learning and insufficient classifiercalibration. To tackle these problems, we propose a new Long-tailed MedicalDiagnosis (LMD) framework for balanced medical image classification onlong-tailed datasets. In the initial stage, we develop a Relation-awareRepresentation Learning (RRL) scheme to boost the representation ability byencouraging the encoder to capture intrinsic semantic features throughdifferent data augmentations. In the subsequent stage, we propose an IterativeClassifier Calibration (ICC) scheme to calibrate the classifier iteratively.This is achieved by generating a large number of balanced virtual features andfine-tuning the encoder using an Expectation-Maximization manner. The proposedICC compensates for minority categories to facilitate unbiased classifieroptimization while maintaining the diagnostic knowledge in majority classes.Comprehensive experiments on three public long-tailed medical datasetsdemonstrate that our LMD framework significantly surpasses state-of-the-artapproaches. The source code can be accessed athttps://github.com/peterlipan/LMD.</description>
      <author>example@mail.com (Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen)</author>
      <guid isPermaLink="false">2502.03238v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>MobiCLR: Mobility Time Series Contrastive Learning for Urban Region Representations</title>
      <link>http://arxiv.org/abs/2502.02912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Information Sciences (under review)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，学习有效的城市区域表示已成为理解城市动态和推进智慧城市的关键方法，并获得了广泛关注。&lt;h4&gt;背景&lt;/h4&gt;现有的研究已经展示了利用移动数据生成潜在表示的有效性，这些表示提供了对城市地区内在特征的宝贵见解。然而，将人类流动性模式中的时间动态和详细语义纳入其中仍然有待探索。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一空白，我们提出了一种新颖的城市区域表示学习模型Mobility Time Series Contrastive Learning for Urban Region Representations (MobiCLR)，旨在从流入量和流出量的移动性模式中捕获具有语义意义的嵌入。&lt;h4&gt;方法&lt;/h4&gt;MobiCLR使用对比学习来增强其表示的区分能力，采用实例级对比损失来捕捉特定流动特征。此外，我们开发了一种正则化技术以使输出特征与这些流特异性的表示对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在芝加哥、纽约和华盛顿特区进行了一系列广泛的实验后，我们的模型优于现有的最先进的模型，在预测收入、教育水平和社会脆弱性方面表现尤为出色。&lt;h4&gt;结论&lt;/h4&gt;通过引入MobiCLR模型，我们成功地捕捉到了城市区域的动态特性，并证明了该方法对于理解城市的复杂性和推进智慧城市建设的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, learning effective representations of urban regions has gainedsignificant attention as a key approach to understanding urban dynamics andadvancing smarter cities. Existing approaches have demonstrated the potentialof leveraging mobility data to generate latent representations, providingvaluable insights into the intrinsic characteristics of urban areas. However,incorporating the temporal dynamics and detailed semantics inherent in humanmobility patterns remains underexplored. To address this gap, we propose anovel urban region representation learning model, Mobility Time SeriesContrastive Learning for Urban Region Representations (MobiCLR), designed tocapture semantically meaningful embeddings from inflow and outflow mobilitypatterns. MobiCLR uses contrastive learning to enhance the discriminative powerof its representations, applying an instance-wise contrastive loss to capturedistinct flow-specific characteristics. Additionally, we develop a regularizerto align output features with these flow-specific representations, enabling amore comprehensive understanding of mobility dynamics. To validate our model,we conduct extensive experiments in Chicago, New York, and Washington, D.C. topredict income, educational attainment, and social vulnerability. The resultsdemonstrate that our model outperforms state-of-the-art models.</description>
      <author>example@mail.com (Namwoo Kim, Takahiro Yabe, Chanyoung Park, Yoonjin Yoon)</author>
      <guid isPermaLink="false">2502.02912v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Tell2Reg: Establishing spatial correspondence between images by the same language prompts</title>
      <link>http://arxiv.org/abs/2502.03118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于GroundingDINO和SAM的预训练大模型，能够使用相同的语言提示在两张不同图像上预测空间对应的区域对。这种方法无需训练即可实现自动化的图像配准，并且适用于广泛的图像配准任务。&lt;h4&gt;背景&lt;/h4&gt;传统的图像配准方法通常依赖于预测位移场或转换参数，而该研究则探讨了一种新的方式：通过分割对应区域来表示空间对应关系。&lt;h4&gt;目的&lt;/h4&gt;展示如何使用预训练的多模态模型在两个不同的图像上利用相同的语言提示预测对应的区域对，并验证这种方法在无需训练的情况下实现自动化的配准算法的有效性。&lt;h4&gt;方法&lt;/h4&gt;论文采用了基于GroundingDINO和SAM的预训练模型，通过给定的语言提示自动识别并匹配不同图像中的对应区域，用于前列腺MR图像之间的注册任务。&lt;h4&gt;主要发现&lt;/h4&gt;Tell2Reg不仅在实验中表现出比无监督学习法更好的性能，并且其效果与弱监督方法相当。此外，还首次观察到语言语义和空间对应之间可能存在相关性。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种无需训练的图像配准算法Tell2Reg，极大地降低了数据管理和标注的成本，同时适用于多种复杂的配准任务。&lt;h4&gt;翻译&lt;/h4&gt;空间对应可以通过成对分割区域来表示，使得图像注册网络的目标是识别对应的区域而非预测位移场或转换参数。在此工作中，我们展示了如何使用相同的语言提示在两张不同的图象上通过基于GroundingDINO和SAM的预训练大模型预测这样的区域对。这使完全自动化且无需训练的注册算法成为可能，并可潜在地适用于广泛的图像注册任务中。论文还提供了一种具有挑战性的任务——注册跨受试者前列腺MR图像，它涉及到患者间高度变化的强度与形态。Tell2Reg无需训练，消除了之前对于此配准任务所需的成本高昂且耗时的数据管理和标注需求。该方法在测试过的无监督学习法中表现更好，并且性能与弱监督方法相当。此外还有额外的定性结果表明语言提示所获得局部和全局对应之间的差异以及语言语义与空间一致性间可能存在相关性的首次观察。代码可在https://github.com/yanwenCi/Tell2Reg.git上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial correspondence can be represented by pairs of segmented regions, suchthat the image registration networks aim to segment corresponding regionsrather than predicting displacement fields or transformation parameters. Inthis work, we show that such a corresponding region pair can be predicted bythe same language prompt on two different images using the pre-trained largemultimodal models based on GroundingDINO and SAM. This enables a fullyautomated and training-free registration algorithm, potentially generalisableto a wide range of image registration tasks. In this paper, we presentexperimental results using one of the challenging tasks, registeringinter-subject prostate MR images, which involves both highly variable intensityand morphology between patients. Tell2Reg is training-free, eliminating theneed for costly and time-consuming data curation and labelling that waspreviously required for this registration task. This approach outperformsunsupervised learning-based registration methods tested, and has a performancecomparable to weakly-supervised methods. Additional qualitative results arealso presented to suggest that, for the first time, there is a potentialcorrelation between language semantics and spatial correspondence, includingthe spatial invariance in language-prompted regions and the difference inlanguage prompts between the obtained local and global correspondences. Code isavailable at https://github.com/yanwenCi/Tell2Reg.git.</description>
      <author>example@mail.com (Wen Yan, Qianye Yang, Shiqi Huang, Yipei Wang, Shonit Punwani, Mark Emberton, Vasilis Stavrinides, Yipeng Hu, Dean Barratt)</author>
      <guid isPermaLink="false">2502.03118v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>The Cake that is Intelligence and Who Gets to Bake it: An AI Analogy and its Implications for Participation</title>
      <link>http://arxiv.org/abs/2502.03038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文扩展了Yann LeCun提出的机器智能'蛋糕模型'的比喻，从简单的结构类比扩展到了AI系统的整个生命周期，包括数据采集、指令设计、训练过程和评估分发。通过重新构建这一模型，文章探讨了每个阶段的社会影响及其与统计假设的关系，并提出了促进跨学科对话的建议。&lt;h4&gt;背景&lt;/h4&gt;Yann LeCun使用蛋糕来比喻机器智能的发展结构，其中无监督学习作为基础，有监督学习为装饰，强化学习则是在顶部添加樱桃。这个比喻帮助人们更好地理解AI技术的不同组成部分。&lt;h4&gt;目的&lt;/h4&gt;将LeCun的'蛋糕模型'扩展到整个AI系统的生命周期，并探讨每个阶段的社会影响及其与机器学习统计假设的关系，以促进跨学科对话和更广泛的参与。&lt;h4&gt;方法&lt;/h4&gt;通过重新概念化LeCun的'蛋糕模型'并将其应用到数据采集、指令设计、训练过程和评估分发四个主要步骤中，研究了技术基础和社会影响之间的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;技术基础和社会结果通常是孤立研究的，这造成了参与障碍。而重新概念化的AI生命周期提供了明确的技术基础与社会成果互动的地图，强调跨学科对话的机会。&lt;h4&gt;结论&lt;/h4&gt;文章提出了一系列在每个阶段提高对广泛AI讨论认识和能力的具体建议，使未来的AI从业者、用户和研究人员能够更积极地参与到这个领域中来。&lt;h4&gt;翻译&lt;/h4&gt;在Yann LeCun提出的广受欢迎的'蛋糕模型'比喻下，机器智能被比作是一个由无监督学习构建基础，有监督学习添加装饰，强化学习作为顶部点缀的蛋糕。我们扩展了这一简单的结构隐喻到AI系统的完整生命周期中，涵盖数据采集、指令设计、训练过程以及评估分发阶段。利用我们的重新概念化，我们将描述每个步骤的社会影响，并说明这些技术基础如何受到机器学习统计假设的限制。虽然这些技术背景和社会效应紧密相连，但它们往往被孤立地研究，造成参与障碍。我们提出的新模型通过映射技术基础与社会结果之间的互动，为促进跨学科对话铺平了道路。最后，我们在整个隐喻性的AI蛋糕生命周期中的每个阶段提供可操作的建议，使未来的AI从业者、用户和研究人员能够更深入地参与到广泛的AI讨论中来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a widely popular analogy by Turing Award Laureate Yann LeCun, machineintelligence has been compared to cake - where unsupervised learning forms thebase, supervised learning adds the icing, and reinforcement learning is thecherry on top. We expand this 'cake that is intelligence' analogy from a simplestructural metaphor to the full life-cycle of AI systems, extending it tosourcing of ingredients (data), conception of recipes (instructions), thebaking process (training), and the tasting and selling of the cake (evaluationand distribution). Leveraging our re-conceptualization, we describe each step'sentailed social ramifications and how they are bounded by statisticalassumptions within machine learning. Whereas these technical foundations andsocial impacts are deeply intertwined, they are often studied in isolation,creating barriers that restrict meaningful participation. Ourre-conceptualization paves the way to bridge this gap by mapping wheretechnical foundations interact with social outcomes, highlighting opportunitiesfor cross-disciplinary dialogue. Finally, we conclude with actionablerecommendations at each stage of the metaphorical AI cake's life-cycle,empowering prospective AI practitioners, users, and researchers, with increasedawareness and ability to engage in broader AI discourse.</description>
      <author>example@mail.com (Martin Mundt, Anaelia Ovalle, Felix Friedrich, Pranav Agrawal, Subarnaduti Paul, Manuel Brack, Kristian Kersting, William Agnew)</author>
      <guid isPermaLink="false">2502.03038v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>LIMO: Less is More for Reasoning</title>
      <link>http://arxiv.org/abs/2502.03387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个新的模型LIMO，该模型在使用极少量训练数据的情况下，在复杂的数学推理任务上表现出超越现有方法的性能，并挑战了传统的大型语言模型需要大量训练数据才能完成复杂推理的认知。&lt;h4&gt;背景&lt;/h4&gt;现有的观点认为，进行复杂的推理任务需要大量的训练样本。然而，新的研究结果表明，通过精心选择的小规模训练集可以有效激活大规模预训练语言模型中的复杂推理能力。&lt;h4&gt;目的&lt;/h4&gt;证明可以通过少量的、高质量的训练数据来显著提高大型语言模型在数学推理上的性能，并挑战现有的超大训练数据量是必要条件的观点。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法LIMO，该方法仅使用817个精心挑选的数据样本，在两个公开基准测试（AIME和MATH）上大幅提升了先前SFT基线模型的准确率。同时展示了其在广泛任务上的泛化能力，超过了需要大量训练数据的方法。&lt;h4&gt;主要发现&lt;/h4&gt;LIMO模型不仅在特定数学推理任务中表现优异，还具有出色的跨领域泛化能力，在10个不同类型的基准测试中平均提升了40.5%的表现，证明了少量但高质量的示例对于复杂推理能力的激发至关重要。&lt;h4&gt;结论&lt;/h4&gt;论文提出了“少即是多”推理假设（LIMO Hypothesis），认为在预训练阶段已经全面编码领域知识的大规模模型可以通过精心设计的小数量演示来解锁复杂的推理能力。该研究为未来数据高效推理的研究提供了新的方向，并发布了开源代码供进一步探索。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一项基本发现，它挑战了我们对大型语言模型如何产生复杂推理的理解。传统的观点认为，完成高级别推理任务需要大量的训练样本（&gt;100,000个），然而研究表明通过极少数的示例可以有效激发复杂的数学推理能力。通过全面实验，所提出的LIMO模型在数学推理方面表现出了前所未有的性能，仅用817个精心挑选的训练样本，在AIME上达到57.1%的准确率，在MATH上达到了94.8%，分别比以前基于SFT的方法提高了6.5%和59.2%，而所使用的训练数据仅为先前方法所需的1%。LIMO模型展示了卓越的分布外泛化能力，跨10个不同的基准测试绝对提升了40.5%，超过了在一百倍更多数据上训练出来的模型的表现，质疑了SFT导致记忆而非泛化的观点。基于这些结果，我们提出了“少即是多推理假设”（LIMO Hypothesis）：在一个领域知识已经全面编码到预训练阶段的基础模型中，复杂的推理能力可以通过最少但精心策划的认知过程展示来激活，其激发门槛由两个关键因素决定：1）在预训练期间编码的知识基础的完整性；2）作为“认知模板”的后训练示例的有效性，以向模型展示如何利用知识库解决复杂推理任务。为了促进可重复性和未来的高效数据推理研究，我们开放了LIMO的开源代码（https://github.com/GAIR-NLP/LIMO）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a fundamental discovery that challenges our understanding of howcomplex reasoning emerges in large language models. While conventional wisdomsuggests that sophisticated reasoning tasks demand extensive training data(&gt;100,000 examples), we demonstrate that complex mathematical reasoningabilities can be effectively elicited with surprisingly few examples. Throughcomprehensive experiments, our proposed model LIMO demonstrates unprecedentedperformance in mathematical reasoning. With merely 817 curated trainingsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving fromprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% ofthe training data required by previous approaches. LIMO demonstratesexceptional out-of-distribution generalization, achieving 40.5% absoluteimprovement across 10 diverse benchmarks, outperforming models trained on 100xmore data, challenging the notion that SFT leads to memorization rather thangeneralization. Based on these results, we propose the Less-Is-More ReasoningHypothesis (LIMO Hypothesis): In foundation models where domain knowledge hasbeen comprehensively encoded during pre-training, sophisticated reasoningcapabilities can emerge through minimal but precisely orchestrateddemonstrations of cognitive processes. This hypothesis posits that theelicitation threshold for complex reasoning is determined by two key factors:(1) the completeness of the model's encoded knowledge foundation duringpre-training, and (2) the effectiveness of post-training examples as "cognitivetemplates" that show the model how to utilize its knowledge base to solvecomplex reasoning tasks. To facilitate reproducibility and future research indata-efficient reasoning, we release LIMO as a comprehensive open-source suiteat https://github.com/GAIR-NLP/LIMO.</description>
      <author>example@mail.com (Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu)</author>
      <guid isPermaLink="false">2502.03387v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Transformers and Their Roles as Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2502.03383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 Pages, 2 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文对变压器作为时间序列基础模型的能力进行了全面分析，重点研究了其近似和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;探讨变压器在处理单变量和多变量时间序列中的应用以及它们的自动回归模型拟合能力。&lt;h4&gt;目的&lt;/h4&gt;展示Transformer网络如何通过梯度下降拟合自回归模型，并证明MOIRAI能够适应任意数量协变量的时间序列问题。&lt;h4&gt;方法&lt;/h4&gt;首先，作者演示了存在能够通过梯度下降在输入单变量时间序列上匹配自回归模型的变压器。其次，分析了处理多变量时间序列基础模型的能力以及它自动拟合具有任意数目的协变量的自回归模型的能力，并为预训练数据满足Dobrushin条件时建立了界限。&lt;h4&gt;主要发现&lt;/h4&gt;证明MOIRAI能够适应并拟合任何数量协变量的时间序列问题，并通过实验验证了理论结果，强调了Transformer在时间序列基础模型中的有效性和成功性。&lt;h4&gt;结论&lt;/h4&gt;研究支持了变压器作为时间序列任务中强大而有效的基础模型地位，特别关注于它们的自动回归能力及泛化性能。&lt;h4&gt;翻译&lt;/h4&gt;我们对transformer作为时间序列基础模型进行了全面分析，着重探讨其近似和泛化的潜力。首先展示了存在能够通过梯度下降拟合输入单变量自回归模型的时间序列transformer网络；接着证明了MOIRAI这一多变量时间序列基础模型有能力处理任意数量协变量，并自动适配任意数目协变量的自回归模型。进一步，我们为满足Dobrushin条件的数据建立了预训练界限。实验结果验证了我们的理论发现，强调Transformer在时间序列任务中的卓越性能和应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We give a comprehensive analysis of transformers as time series foundationmodels, focusing on their approximation and generalization capabilities. First,we demonstrate that there exist transformers that fit an autoregressive modelon input univariate time series via gradient descent. We then analyze MOIRAI, amultivariate time series foundation model capable of handling an arbitrarynumber of covariates. We prove that it is capable of automatically fittingautoregressive models with an arbitrary number of covariates, offering insightsinto its design and empirical success. For generalization, we establish boundsfor pretraining when the data satisfies Dobrushin's condition. Experimentssupport our theoretical findings, highlighting the efficacy of transformers astime series foundation models.</description>
      <author>example@mail.com (Dennis Wu, Yihan He, Yuan Cao, Jianqing Fan, Han Liu)</author>
      <guid isPermaLink="false">2502.03383v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Dependence Minimization</title>
      <link>http://arxiv.org/abs/2502.03227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种可微分和可扩展的算法，用于超越线性成对去相关的依赖关系最小化。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习技术通过减少输出特征维度之间的协方差来提取尽可能不冗余的数据表示。但是这些方法不能消除所有依赖性和冗余，因为线性无关变量仍可能表现出非线性关系。&lt;h4&gt;目的&lt;/h4&gt;提供一种超越线性成对去相关的依赖最小化算法。&lt;h4&gt;方法&lt;/h4&gt;采用对抗博弈的方法，其中小网络识别特征维度之间的依赖性，而编码器利用这些信息来减少依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;提供了该算法收敛性的实验证据，并在三个应用中展示了其效用：将PCA扩展到非线性去相关、提高图像分类方法的泛化能力以及防止自监督表示学习中的维度崩溃。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法超越了传统的依赖最小化方法，具有更高的实用价值和广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many machine learning techniques rely on minimizing the covariance betweenoutput feature dimensions to extract minimally redundant representations fromdata. However, these methods do not eliminate all dependencies/redundancies, aslinearly uncorrelated variables can still exhibit nonlinear relationships. Thiswork provides a differentiable and scalable algorithm for dependenceminimization that goes beyond linear pairwise decorrelation. Our method employsan adversarial game where small networks identify dependencies among featuredimensions, while the encoder exploits this information to reduce dependencies.We provide empirical evidence of the algorithm's convergence and demonstrateits utility in three applications: extending PCA to nonlinear decorrelation,improving the generalization of image classification methods, and preventingdimensional collapse in self-supervised representation learning.</description>
      <author>example@mail.com (Pierre-François De Plaen, Tinne Tuytelaars, Marc Proesmans, Luc Van Gool)</author>
      <guid isPermaLink="false">2502.03227v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry</title>
      <link>http://arxiv.org/abs/2502.03251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WWW25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为RiemannGFM的通用预训练模型，用于学习图结构的知识，并在非欧几里得空间中实现跨领域迁移。&lt;h4&gt;背景&lt;/h4&gt;基础模型（foundation model）在人工智能领域开辟了新纪元，通过单个模型的预先训练来实现在不同数据集上的跨域迁移能力。然而，在处理没有丰富文本属性的真实图形时，现有的研究主要集中在具有文本属性的图上，并且针对大型语言模型设计的序列化图描述忽略了结构复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种超越大型语言模型的方法，预训练一个通用模型来学习任何图中的结构知识。&lt;h4&gt;方法&lt;/h4&gt;通过发现简单而有效的树和环形结构词汇表的关键创新点，结合黎曼几何与图领域中共同存在的次级结构，创建了一种新的产品包以融合词汇的各种几何特征，并在此构建的空间上堆叠黎曼层来学习结构词汇。&lt;h4&gt;主要发现&lt;/h4&gt;在不同的真实图形上的广泛实验表明RiemannGFM的有效性。通过这种模型可以有效地利用黎曼流形中的结构词汇进行跨域迁移，从而更好地捕捉和表示图的复杂结构信息。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发通用预训练图基础模型提供了一种新的机会，并证明了使用黎曼几何来描述图形结构词汇表的有效性。未来的工作可能会探索如何进一步优化这种模型以适应更多的应用场景。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在人工智能领域开辟了一个新时代，通过预先训练单个模型，在不同的数据集上实现跨领域的转移能力。图神经网络擅长于学习非欧几里得结构的图数据，但往往缺乏泛化能力。因此，图形基础模型正在吸引越来越多的关注，并且最近的努力集中于利用大型语言模型。一方面，现有的研究主要集中在具有文本属性的图上，而广泛的现实图则不具备丰富的文本属性。另一方面，为大型语言模型设计的序列化图描述忽略了结构复杂性，这是图的主要特征之一。这些限制促使了一个重要的问题：我们是否可以超越大型语言模型，并预训练一个通用模型来学习任何图形的结构知识？在语言或视觉领域中的答案是共享词汇表。观察到图域中也存在共同的基本结构，从而为具有结构词汇表的图形基础模型开辟了新的机会。关键创新在于发现了简单而有效的树和环形结构词汇表，并探索其与黎曼几何学之间的内在联系。本文提出了一个通用预训练模型RiemannGFM：首先构建了一个新颖的产品包以整合多样化的几何词汇；然后在此构建的空间上堆叠黎曼层，使无具体图限制的结构词汇在黎曼流形中学习，提供跨域迁移能力。广泛的实验表明RiemannGFM在各种真实图形上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The foundation model has heralded a new era in artificial intelligence,pretraining a single model to offer cross-domain transferability on differentdatasets. Graph neural networks excel at learning graph data, the omnipresentnon-Euclidean structure, but often lack the generalization capacity. Hence,graph foundation model is drawing increasing attention, and recent efforts havebeen made to leverage Large Language Models. On the one hand, existing studiesprimarily focus on text-attributed graphs, while a wider range of real graphsdo not contain fruitful textual attributes. On the other hand, the sequentialgraph description tailored for the Large Language Model neglects the structuralcomplexity, which is a predominant characteristic of the graph. Suchlimitations motivate an important question: Can we go beyond Large LanguageModels, and pretrain a universal model to learn the structural knowledge forany graph? The answer in the language or vision domain is a shared vocabulary.We observe the fact that there also exist shared substructures underlying graphdomain, and thereby open a new opportunity of graph foundation model withstructural vocabulary. The key innovation is the discovery of a simple yeteffective structural vocabulary of trees and cycles, and we explore itsinherent connection to Riemannian geometry. Herein, we present a universalpretraining model, RiemannGFM. Concretely, we first construct a novel productbundle to incorporate the diverse geometries of the vocabulary. Then, on thisconstructed space, we stack Riemannian layers where the structural vocabulary,regardless of specific graph, is learned in Riemannian manifold offeringcross-domain transferability. Extensive experiments show the effectiveness ofRiemannGFM on a diversity of real graphs.</description>
      <author>example@mail.com (Li Sun, Zhenhao Huang, Suyang Zhou, Qiqi Wan, Hao Peng, Philip Yu)</author>
      <guid isPermaLink="false">2502.03251v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable Composite Neural Signed Distance Fields for Robot Navigation in Dynamic Indoor Environments</title>
      <link>http://arxiv.org/abs/2502.02664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于神经SDF的组合框架，用于解决仅使用RGB-D传感器进行室内环境机器人导航的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的神经SDF更新方法在动态环境中需要重新训练模型，导致效率低下且不适合具有有限视野的机器人导航任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来提高机器人在复杂环境中的导航性能，特别是在视觉受限的情况下能够快速有效地规划路径。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双模式程序框架：第一阶段利用障碍物点云查询路径上的碰撞成本；第二阶段通过场景构成元素的SDF表示进行组合推理。这两个阶段共同工作以优化轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;该方案在iGibson 2.0环境中的成功率为98%，比基线方法高出14.4%，同时保持了相近的时间开销，展示了其在真实世界场景中的适应性。&lt;h4&gt;结论&lt;/h4&gt;所提出的双模式框架通过结合两个阶段的优势，在机器人导航任务中提供了更高的成功率和效率。&lt;h4&gt;翻译&lt;/h4&gt;神经签名距离字段（SDF）为机器人导航任务提供了一种可微分的环境表示方法。然而，随着场景的变化更新神经SDF需要重新训练模型，这在具有有限视野的动态环境中显得繁琐、耗时且低效。针对这一问题，我们提出了一种基于神经SDF的组合框架，用于仅利用机载RGB-D传感器解决室内环境下的机器人导航任务。该框架采用双模式程序流程进行轨迹优化，在第一阶段使用障碍物点云查询路径上的碰撞成本；在第二阶段推理可见场景的SDF并进行组合以提供更好的代价和梯度估计。最终，该方案取得了98%的成功率，比基线方法高出14.4%，同时保持了相近的时间开销，并展示了其在真实世界情景中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Signed Distance Fields (SDFs) provide a differentiable environmentrepresentation to readily obtain collision checks and well-defined gradientsfor robot navigation tasks. However, updating neural SDFs as the scene evolvesentails re-training, which is tedious, time consuming, and inefficient, makingit unsuitable for robot navigation with limited field-of-view in dynamicenvironments. Towards this objective, we propose a compositional framework ofneural SDFs to solve robot navigation in indoor environments using only anonboard RGB-D sensor. Our framework embodies a dual mode procedure fortrajectory optimization, with different modes using complementary methods ofmodeling collision costs and collision avoidance gradients. The primary stagequeries the robot body's SDF, swept along the route to goal, at the obstaclepoint cloud, enabling swift local optimization of trajectories. The secondarystage infers the visible scene's SDF by aligning and composing the SDFrepresentations of its constituents, providing better informed costs andgradients for trajectory optimization. The dual mode procedure combines thebest of both stages, achieving a success rate of 98%, 14.4% higher thanbaseline with comparable amortized plan time on iGibson 2.0. We alsodemonstrate its effectiveness in adapting to real-world indoor scenarios.</description>
      <author>example@mail.com (S. Talha Bukhari, Daniel Lawson, Ahmed H. Qureshi)</author>
      <guid isPermaLink="false">2502.02664v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models Are Universal Recommendation Learners</title>
      <link>http://arxiv.org/abs/2502.03041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型（LLM）在推荐系统中的应用研究，展示了其作为通用推荐学习器的能力，并提出改进推荐性能的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的推荐系统任务通常使用针对特定任务设计的数据集和专门的模型架构进行监督学习。&lt;h4&gt;目的&lt;/h4&gt;展示大型语言模型可以处理多种推荐任务而不需专为每个任务设计特殊模型，同时引入方法以提升其在推荐上的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多模态融合模块用于项目表示以及序列到集合的方法来高效生成候选集。&lt;h4&gt;主要发现&lt;/h4&gt;LLM在工业规模数据上表现出色，并且发现文本输入对推荐结果有显著影响。&lt;h4&gt;结论&lt;/h4&gt;大型语言模型可以作为通用的推荐学习器，其性能与专家设计的专业模型相当甚至更优。此外，优化提示工程有望进一步提升大规模推荐系统的效率和效果。&lt;h4&gt;翻译&lt;/h4&gt;在现实世界的推荐系统中，不同的任务通常通过针对特定任务的数据集进行监督学习，并使用精心设计的模型架构来解决。我们展示了大型语言模型（LLM）可以作为通用推荐学习器，在统一的输入-输出框架内处理多个任务，无需专门的设计模型。为了提升LLM的推荐性能，我们引入了一个用于项目表示的多模态融合模块和一种序列到集合的方法以高效生成候选集。在工业规模数据应用中，我们的LLM与为不同推荐任务精心设计的专业模型表现相当甚至更优。此外，我们的分析揭示了推荐结果对文本输入高度敏感，这表明通过优化提示工程可以改进大规模的推荐系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world recommender systems, different tasks are typically addressedusing supervised learning on task-specific datasets with carefully designedmodel architectures. We demonstrate that large language models (LLMs) canfunction as universal recommendation learners, capable of handling multipletasks within a unified input-output framework, eliminating the need forspecialized model designs. To improve the recommendation performance of LLMs,we introduce a multimodal fusion module for item representation and asequence-in-set-out approach for efficient candidate generation. When appliedto industrial-scale data, our LLM achieves competitive results with expertmodels elaborately designed for different recommendation tasks. Furthermore,our analysis reveals that recommendation outcomes are highly sensitive to textinput, highlighting the potential of prompt engineering in optimizingindustrial-scale recommender systems.</description>
      <author>example@mail.com (Junguang Jiang, Yanwen Huang, Bin Liu, Xiaoyu Kong, Ziru Xu, Han Zhu, Jian Xu, Bo Zheng)</author>
      <guid isPermaLink="false">2502.03041v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>RadVLM: A Multitask Conversational Vision-Language Model for Radiology</title>
      <link>http://arxiv.org/abs/2502.03333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了RadVLM，一个专为胸部X光片（CXRs）解读设计的紧凑型多任务对话基础模型。&lt;h4&gt;背景&lt;/h4&gt;由于胸透的广泛应用和放射科医生短缺，自动化分析和AI辅助报告的兴趣日益增加。现有的视觉-语言模型在特定任务中表现出色，但在互动诊断能力方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发RadVLM，一个能够处理多任务对话交互并且具有结构化CXRs解读和互动诊断能力的模型。&lt;h4&gt;方法&lt;/h4&gt;创建了一个大规模指令数据集，包含超过100万张图像-指令对，涵盖单次任务（如报告生成、异常分类、视觉定位）和多次任务多任务对话交互。基于此数据集进行微调，并在不同任务上评估RadVLM及其基线模型。&lt;h4&gt;主要发现&lt;/h4&gt;RadVLM在对话能力和视觉定位方面表现出色，在其他放射科任务中也具有竞争力。消融实验进一步突出了跨多项任务联合训练的好处，特别是在标注数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;这些研究结果表明，RadVLM作为临床相关AI助手的潜力，能够提供结构化的CXRs解读和互动能力，以支持更有效和可访问的诊断工作流程。&lt;h4&gt;翻译&lt;/h4&gt;广泛使用胸部X光片（CXRs）与放射科医生短缺相结合，激发了对自动化CXRs分析和AI辅助报告的兴趣。尽管现有的视觉-语言模型在诸如报告生成或异常检测等特定任务中表现出色，但它们通常缺乏支持互动诊断功能的支持。在这项工作中，我们介绍了RadVLM，这是一种专为CXRs解读设计的紧凑型多任务对话基础模型。为此，我们策划了一个大规模指令数据集，包含超过100万张图像-指令对，涵盖单次任务（如报告生成、异常分类和视觉定位）以及多次任务多任务对话交互。在基于该指令数据集微调RadVLM之后，在不同的任务上评估其与重新实现的基线视觉语言模型相比的效果。我们的结果表明，RadVLM在对话能力和视觉定位方面达到了最先进的性能，并且在其他放射学任务中也保持了竞争力。消融实验进一步强调了跨多个任务联合训练的好处，特别是在标注数据有限的情况下。总之，这些发现突出了RadVLM作为临床相关AI助手的潜力，提供结构化的CXRs解读和互动能力，以支持更有效和可访问的诊断工作流程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of chest X-rays (CXRs), coupled with a shortage ofradiologists, has driven growing interest in automated CXR analysis andAI-assisted reporting. While existing vision-language models (VLMs) showpromise in specific tasks such as report generation or abnormality detection,they often lack support for interactive diagnostic capabilities. In this workwe present RadVLM, a compact, multitask conversational foundation modeldesigned for CXR interpretation. To this end, we curate a large-scaleinstruction dataset comprising over 1 million image-instruction pairscontaining both single-turn tasks -- such as report generation, abnormalityclassification, and visual grounding -- and multi-turn, multi-taskconversational interactions. After fine-tuning RadVLM on this instructiondataset, we evaluate it across different tasks along with re-implementedbaseline VLMs. Our results show that RadVLM achieves state-of-the-artperformance in conversational capabilities and visual grounding while remainingcompetitive in other radiology tasks. Ablation studies further highlight thebenefit of joint training across multiple tasks, particularly for scenarioswith limited annotated data. Together, these findings highlight the potentialof RadVLM as a clinically relevant AI assistant, providing structured CXRinterpretation and conversational capabilities to support more effective andaccessible diagnostic workflows.</description>
      <author>example@mail.com (Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Blüthgen, Farhad Nooralahzadeh, Michael Krauthammer)</author>
      <guid isPermaLink="false">2502.03333v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Lingual Transfer for Low-Resource Natural Language Processing</title>
      <link>http://arxiv.org/abs/2502.02722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Doctoral Thesis: University of the Basque Country UPV/EHU&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了自然语言处理领域中跨语言迁移学习的方法，旨在通过利用高资源语言的数据和模型来提高低资源语言的NLP性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，随着大型语言模型的发展，自然语言处理取得了显著的进步。然而，这些发展主要使英语等少数高资源语言受益。大多数语言由于训练数据和计算资源匮乏而面临巨大挑战。&lt;h4&gt;目的&lt;/h4&gt;本论文专注于跨语言迁移学习研究领域，旨在通过改进的翻译和注释投影技术推进基于数据的跨语言迁移学习方法；利用最先进的多语言模型开发增强的基于模型的迁移学习方法；并将其应用于实际问题解决，同时创建开源资源以促进低资源NLP领域的未来研究。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种新的基于T-Projection的方法来改进数据基础转移，并引入了限制解码算法，该算法利用文本到文本多语言模型在零样本设置中增强跨语言序列标注。此外，还开发了Medical mT5，这是第一个用于医学领域的多语言文本到文本模型。&lt;h4&gt;主要发现&lt;/h4&gt;论文展示了T-Projection相比之前的方法有显著改进，并提出了一种限制解码算法以提高零样本设置下的跨语言序列标注性能；同时开发了专为医疗领域设计的Multilingual Text-to-text Model (Medical mT5)。&lt;h4&gt;结论&lt;/h4&gt;通过这些研究，论文证明了基于数据和模型的迁移学习方法可以有效地改善低资源语言在自然语言处理任务中的表现，并且开发的实际应用表明这种方法具有重要的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural Language Processing (NLP) has seen remarkable advances in recentyears, particularly with the emergence of Large Language Models that haveachieved unprecedented performance across many tasks. However, thesedevelopments have mainly benefited a small number of high-resource languagessuch as English. The majority of languages still face significant challengesdue to the scarcity of training data and computational resources. To addressthis issue, this thesis focuses on cross-lingual transfer learning, a researcharea aimed at leveraging data and models from high-resource languages toimprove NLP performance for low-resource languages. Specifically, we focus onSequence Labeling tasks such as Named Entity Recognition, Opinion TargetExtraction, and Argument Mining.  The research is structured around three main objectives: (1) advancingdata-based cross-lingual transfer learning methods through improved translationand annotation projection techniques, (2) developing enhanced model-basedtransfer learning approaches utilizing state-of-the-art multilingual models,and (3) applying these methods to real-world problems while creatingopen-source resources that facilitate future research in low-resource NLP.  More specifically, this thesis presents a new method to improve data-basedtransfer with T-Projection, a state-of-the-art annotation projection methodthat leverages text-to-text multilingual models and machine translationsystems. T-Projection significantly outperforms previous annotation projectionmethods by a wide margin. For model-based transfer, we introduce a constraineddecoding algorithm that enhances cross-lingual Sequence Labeling in zero-shotsettings using text-to-text models. Finally, we develop Medical mT5, the firstmultilingual text-to-text medical model, demonstrating the practical impact ofour research on real-world applications.</description>
      <author>example@mail.com (Iker García-Ferrero)</author>
      <guid isPermaLink="false">2502.02722v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Disentanglement in Difference: Directly Learning Semantically Disentangled Representations by Maximizing Inter-Factor Differences</title>
      <link>http://arxiv.org/abs/2502.03123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的表示学习方法DiD，旨在解决传统表示学习中隐变量统计独立性和语义解耦之间存在的内在不一致性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的解耦表示学习方法主要通过提高隐变量之间的统计独立性来实现解耦，但这并不能保证隐变量在语义上是无关的。因此，单纯提升统计独立性并不一定能增强解耦性能。&lt;h4&gt;目的&lt;/h4&gt;提出DiD（Disentanglement in Difference）这一新框架，直接从学习隐变量间的语义差异出发解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;设计了差分编码器来测量语义差异，并建立了对比损失函数以促进跨维度的比较。这些工具使模型能够直接区分和解耦不同的语义因素，从而解决了统计独立性和语义解耦之间的不一致性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在dSprites和3DShapes数据集上的实验结果表明，所提出的DiD方法在各种解耦度量指标上均优于现有的主流方法。&lt;h4&gt;结论&lt;/h4&gt;DiD提供了一种有效的途径来直接学习隐变量的语义差异，从而实现更好的解耦表示，并且其性能已通过实验证明。&lt;h4&gt;翻译&lt;/h4&gt;在这项研究中，提出了解耦在差分（DiD）的方法来解决传统解耦表示学习方法中存在的隐变量统计独立性与语义解耦之间的内在不一致性问题。传统的解耦方法通过提高隐变量间的统计独立性来实现解耦，但这并不意味着它们在语义上是无关的，因此仅提升统计独立性不一定能增强解耦性能。为解决上述问题，DiD直接学习了隐变量间语义差异而不是其统计独立性，并设计了一种差分编码器和对比损失函数以促进模型区分不同的语义因素，从而解决了统计独立性和语义解耦之间的不一致性。实验结果表明，在dSprites和3DShapes数据集上，所提出的DiD方法在各种解耦度量指标上的表现优于现有的主流方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, Disentanglement in Difference(DiD) is proposed to address theinherent inconsistency between the statistical independence of latent variablesand the goal of semantic disentanglement in disentanglement representationlearning. Conventional disentanglement methods achieve disentanglementrepresentation by improving statistical independence among latent variables.However, the statistical independence of latent variables does not necessarilyimply that they are semantically unrelated, thus, improving statisticalindependence does not always enhance disentanglement performance. To addressthe above issue, DiD is proposed to directly learn semantic differences ratherthan the statistical independence of latent variables. In the DiD, a DifferenceEncoder is designed to measure the semantic differences; a contrastive lossfunction is established to facilitate inter-dimensional comparison. Both ofthem allow the model to directly differentiate and disentangle distinctsemantic factors, thereby resolving the inconsistency between statisticalindependence and semantic disentanglement. Experimental results on the dSpritesand 3DShapes datasets demonstrate that the proposed DiD outperforms existingmainstream methods across various disentanglement metrics.</description>
      <author>example@mail.com (Xingshen Zhang, Shuangrong Liu, Xintao Lu, Chaoran Pang, Lin Wang, Bo Yang)</author>
      <guid isPermaLink="false">2502.03123v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>SpaceGNN: Multi-Space Graph Neural Network for Node Anomaly Detection with Extremely Limited Labels</title>
      <link>http://arxiv.org/abs/2502.03201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个名为SpaceGNN的新模型，专门用于具有极其有限标签的节点异常检测任务。&lt;h4&gt;背景介绍&lt;/h4&gt;Node Anomaly Detection (NAD) 在深度学习领域受到广泛关注，并且现有的方法主要是在单一欧几里得空间内嵌入图，忽视了非欧几里得空间的潜力。此外，在实际应用中普遍存在监督不足的问题，以往的方法通过合成数据来收集辅助信息，但这种方法在实验中表现不佳。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种克服现有NAD方法局限性的新模型SpaceGNN，并提供一个有效解决极端有限标签条件下节点表示学习问题的方法框架。&lt;h4&gt;主要方法&lt;/h4&gt;{'Learnable Space Projection函数': '用于将节点编码到合适的非欧几里得空间中，从而提升异常检测的准确性', '加权同质性概念': '引入了新的权重同质性的概念，并设计了一个Distance Aware Propagation模块来促进信息传播的有效系数计算。', 'Multiple Space Ensemble模块': '该模块用于在极端有限监督条件下提取全面的信息，以改进节点表示学习和异常检测性能'}&lt;h4&gt;主要发现&lt;/h4&gt;{'SpaceGNN效果显著': '实验结果表明，与现有最佳方法相比，在9个真实数据集上平均提高了8.55%的AUC分数和4.31%的F1评分。', '合成数据不足为据': '合成数据在解决监督不足的问题中并不如预期那样有效', '极端有限标签情况下优势明显': '提出的Multiple Space Ensemble模块相比数据增强技术，在NAD任务中的效果更好'}&lt;h4&gt;结论&lt;/h4&gt;通过实验验证，证明了SpaceGNN模型在处理具有极少量标签的节点异常检测问题上的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到Node Anomaly Detection (NAD) 已经成为了深度学习社区中一个受关注的话题。传统的NAD方法大多是在单一的欧几里得空间内嵌入图，并忽视了非欧几里得空间的可能性。此外，为了解决实际任务中的监督不足问题，以往的方法倾向于利用合成数据来收集辅助信息，但这种方法并不如预期那样有效。为了克服这些挑战，我们提出了一种名为SpaceGNN的新模型，专门用于具有极其有限标签的节点异常检测任务。具体而言，通过实证分析不同空间对于节点表示的好处，提供了对该任务相关框架更深入的理解，并基于此设计了一个可学习的空间投影函数，该函数能够有效地将节点编码到合适的非欧几里得空间中。此外，我们还引入了加权同质性的概念，经过理论和实验验证其作为信息传播的有效系数的重要性，这个理念启发了距离感知传播模块的设计。最后，提出了一种多重空间集成模块，在极端有限监督条件下提取全面的信息以改进NAD的性能。我们的发现表明，该模块比数据增强技术更有优势。在9个真实的数据集上进行广泛的实验结果证实，SpaceGNN优于现有最佳方法平均8.55%的AUC分数和4.31%的F1评分。相关代码可以在此GitHub仓库中找到：https://github.com/xydong127/SpaceGNN。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node Anomaly Detection (NAD) has gained significant attention in the deeplearning community due to its diverse applications in real-world scenarios.Existing NAD methods primarily embed graphs within a single Euclidean space,while overlooking the potential of non-Euclidean spaces. Besides, to addressthe prevalent issue of limited supervision in real NAD tasks, previous methodstend to leverage synthetic data to collect auxiliary information, which is notan effective solution as shown in our experiments. To overcome thesechallenges, we introduce a novel SpaceGNN model designed for NAD tasks withextremely limited labels. Specifically, we provide deeper insights into atask-relevant framework by empirically analyzing the benefits of differentspaces for node representations, based on which, we design a Learnable SpaceProjection function that effectively encodes nodes into suitable spaces.Besides, we introduce the concept of weighted homogeneity, which we empiricallyand theoretically validate as an effective coefficient during informationpropagation. This concept inspires the design of the Distance Aware Propagationmodule. Furthermore, we propose the Multiple Space Ensemble module, whichextracts comprehensive information for NAD under conditions of extremelylimited supervision. Our findings indicate that this module is more beneficialthan data augmentation techniques for NAD. Extensive experiments conducted on 9real datasets confirm the superiority of SpaceGNN, which outperforms the bestrival by an average of 8.55% in AUC and 4.31% in F1 scores. Our code isavailable at https://github.com/xydong127/SpaceGNN.</description>
      <author>example@mail.com (Xiangyu Dong, Xingyi Zhang, Lei Chen, Mingxuan Yuan, Sibo Wang)</author>
      <guid isPermaLink="false">2502.03201v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>A Poisson Process AutoDecoder for X-ray Sources</title>
      <link>http://arxiv.org/abs/2502.01627v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新的神经网络模型——Poisson Process AutoDecoder (PPAD)，用于处理X射线观测数据中的高能现象，并通过无监督学习方法对连续的泊松率函数进行重构。&lt;h4&gt;背景&lt;/h4&gt;X射线观测设备检测到了数百万与高能量现象相关的天体源。到达时间的光子遵循泊松过程，变化范围可达多个数量级，这为常见任务如来源分类、物理性质推导和异常检测带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够直接捕获数据泊松特性的方法，并同时进行率函数重构。&lt;h4&gt;方法&lt;/h4&gt;使用神经场解码器（PPAD），该模型通过无监督学习将固定长度的潜在特征映射为在时间和能量带上的连续泊松率函数。此外，它还能重建率函数并生成相应的表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在Chandra源目录上进行重构、回归、分类和异常检测时，PPAD表现出色。&lt;h4&gt;结论&lt;/h4&gt;通过引入PPAD模型，解决了以往工作未能直接捕获数据泊松特性的局限，并且在多种任务中展示了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; X-ray observing facilities, such as the Chandra X-ray Observatory and theeROSITA, have detected millions of astronomical sources associated withhigh-energy phenomena. The arrival of photons as a function of time follows aPoisson process and can vary by orders-of-magnitude, presenting obstacles forcommon tasks such as source classification, physical property derivation, andanomaly detection. Previous work has either failed to directly capture thePoisson nature of the data or only focuses on Poisson rate functionreconstruction. In this work, we present Poisson Process AutoDecoder (PPAD).PPAD is a neural field decoder that maps fixed-length latent features tocontinuous Poisson rate functions across energy band and time via unsupervisedlearning. PPAD reconstructs the rate function and yields a representation atthe same time. We demonstrate the efficacy of PPAD via reconstruction,regression, classification and anomaly detection experiments using the ChandraSource Catalog.</description>
      <author>example@mail.com (Yanke Song, Victoria Ashley Villar, Juan Rafael Martinez-Galarza, Steven Dillmann)</author>
      <guid isPermaLink="false">2502.01627v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>ZISVFM: Zero-Shot Object Instance Segmentation in Indoor Robotic Environments with Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2502.03266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法（ZISVFM）来解决未见物体实例分割问题，该方法结合了Segment Anything Model (SAM) 的零样本能力以及自监督视觉变换器的显式视觉表示。&lt;h4&gt;背景&lt;/h4&gt;服务机器人在无结构环境中运行时需要有效地识别和分割未知对象以提高其功能。传统的基于有监督学习的分割技术需要大量的标注数据集，这在现实世界的场景中难以实现。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决未见物体实例分割问题，该方法利用合成数据训练模型以推广到新出现的对象，并通过结合SAM和自监督ViT克服模拟与现实之间的差距。&lt;h4&gt;方法&lt;/h4&gt;提出的框架包括三个阶段：（1）使用色彩化的深度图像生成对象无关的掩码提案；（2）利用自监督视觉变换器的基于注意力的功能细化这些提案以过滤非目标掩码；（3）应用K-Medoids聚类来生成点提示，引导SAM进行精确的对象分割。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集和一个自我收集的数据集上的实验验证显示ZISVFM在复杂环境中表现优秀，尤其是在抽屉、橱柜等层次结构中以及手持物体的场景下。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效解决未见对象实例分割问题，并且优于现有的方法。该源代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service robots operating in unstructured environments must effectivelyrecognize and segment unknown objects to enhance their functionality.Traditional supervised learningbased segmentation techniques require extensiveannotated datasets, which are impractical for the diversity of objectsencountered in real-world scenarios. Unseen Object Instance Segmentation (UOIS)methods aim to address this by training models on synthetic data to generalizeto novel objects, but they often suffer from the simulation-to-reality gap.This paper proposes a novel approach (ZISVFM) for solving UOIS by leveragingthe powerful zero-shot capability of the segment anything model (SAM) andexplicit visual representations from a selfsupervised vision transformer (ViT).The proposed framework operates in three stages: (1) generating object-agnosticmask proposals from colorized depth images using SAM, (2) refining theseproposals using attention-based features from the selfsupervised ViT to filternon-object masks, and (3) applying K-Medoids clustering to generate pointprompts that guide SAM towards precise object segmentation. Experimentalvalidation on two benchmark datasets and a self-collected dataset demonstratesthe superior performance of ZISVFM in complex environments, includinghierarchical settings such as cabinets, drawers, and handheld objects. Oursource code is available at https://github.com/Yinmlmaoliang/zisvfm.</description>
      <author>example@mail.com (Ying Zhang, Maoliang Yin, Wenfu Bi, Haibao Yan, Shaohan Bian, Cui-Hua Zhang, Changchun Hua)</author>
      <guid isPermaLink="false">2502.03266v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study</title>
      <link>http://arxiv.org/abs/2502.02451v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了在非英语语料库中计算道德基础（MFs）的计算方法，特别关注机器翻译、本地词典、多语言模型以及大型语言模型（LLMs）的应用效果。&lt;h4&gt;背景&lt;/h4&gt;尽管大多数资源主要为英语开发，但跨语言应用道德基础理论仍面临挑战。目前这些资源对于非英语文本的应用较为有限。&lt;h4&gt;目的&lt;/h4&gt;以中文作为案例研究对象，评估将英文资源应用于机译文本、本地词汇表和多语言模型等方法在测量非英语文本中的MFs时的有效性及局限。&lt;h4&gt;方法&lt;/h4&gt;使用了机器翻译、本地词典法、多语言模型以及大型语言模型（LLMs）来评价这些工具对测量非英语语料库中道德基础的能力。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，单纯依靠机译和本地词汇表的方法对于复杂的道德评估来说效果不佳，往往会导致文化信息的大量丢失。而采用多语言模型和大型语言模型则能在跨语言任务上表现出色，尤其是LLMs在数据效率方面更为突出。&lt;h4&gt;结论&lt;/h4&gt;研究强调了自动化MF评估中人工介入验证的重要性，即便是最先进的模型也可能忽略跨语言测量中的文化差异。结果表明，大型语言模型具有在跨语种道德基础测量和其他复杂多语言分析任务中的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了使用不同方法和技术进行非英语文本的道德基础计算的研究，并强调了大型语言模型在此领域的应用前景以及自动化评估中的人工验证需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores computational approaches for measuring moral foundations(MFs) in non-English corpora. Since most resources are developed primarily forEnglish, cross-linguistic applications of moral foundation theory remainlimited. Using Chinese as a case study, this paper evaluates the effectivenessof applying English resources to machine translated text, local languagelexicons, multilingual language models, and large language models (LLMs) inmeasuring MFs in non-English texts. The results indicate that machinetranslation and local lexicon approaches are insufficient for complex moralassessments, frequently resulting in a substantial loss of culturalinformation. In contrast, multilingual models and LLMs demonstrate reliablecross-language performance with transfer learning, with LLMs excelling in termsof data efficiency. Importantly, this study also underscores the need forhuman-in-the-loop validation of automated MF assessment, as the most advancedmodels may overlook cultural nuances in cross-language measurements. Thefindings highlight the potential of LLMs for cross-language MF measurements andother complex multilingual deductive coding tasks.</description>
      <author>example@mail.com (Calvin Yixiang Cheng, Scott A Hale)</author>
      <guid isPermaLink="false">2502.02451v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Triangular Arbitrage Detection via Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.03194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种使用图神经网络（GNN）检测三角套汇的新方法，旨在解决传统方法计算复杂度高且难以捕捉动态市场中的潜在机会的问题。&lt;h4&gt;背景&lt;/h4&gt;三角套汇是一种利用货币汇率差异在金融市场中盈利的策略。传统的检测方法如穷举搜索算法和线性规划求解器，往往由于较高的计算复杂性和动态市场的特性而无法找到所有的套汇机会。&lt;h4&gt;目的&lt;/h4&gt;通过将货币兑换网络表示为图，并利用GNN的强大表现力和学习能力来更有效地识别有利可图的套汇机会。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于图形优化任务的形式化三角套汇问题的方法，设计了一种可以捕获货币之间复杂关系及其汇率的GNN架构。引入了松弛损失函数以实现更具弹性的学习，并结合深度Q-学习原则来最大化预期收益。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在合成数据集上提出的基于GNN的方法相比于传统方法能够获得更高的平均收益率，同时大幅度减少了计算时间。&lt;h4&gt;结论&lt;/h4&gt;这项研究展示了使用GNN解决金融领域中的优化问题的潜力，并为在动态金融市场中实现实时套汇检测提供了一种有前景的方法。&lt;h4&gt;翻译&lt;/h4&gt;三角套汇是一种利用货币汇率差异进行盈利交易的战略。传统的检测方法，如穷举搜索算法和线性规划求解器，在处理计算复杂性和捕捉动态市场中的机会时存在局限性。本文提出一种新的基于图神经网络（GNN）的策略来识别三角套汇的机会，通过将外汇网络表示成图形，并利用GNN的有效学习能力来提高识别效率。实验结果表明该方法在减少计算时间的同时能获得更高的平均收益率。这项工作揭示了使用GNN解决金融领域优化问题的可能性，同时也为动态市场中的实时套汇检测提供了新途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Triangular arbitrage is a profitable trading strategy in financial marketsthat exploits discrepancies in currency exchange rates. Traditional methods fordetecting triangular arbitrage opportunities, such as exhaustive searchalgorithms and linear programming solvers, often suffer from high computationalcomplexity and may miss potential opportunities in dynamic markets. In thispaper, we propose a novel approach to triangular arbitrage detection usingGraph Neural Networks (GNNs). By representing the currency exchange network asa graph, we leverage the powerful representation and learning capabilities ofGNNs to identify profitable arbitrage opportunities more efficiently.Specifically, we formulate the triangular arbitrage problem as a graph-basedoptimization task and design a GNN architecture that captures the complexrelationships between currencies and exchange rates. We introduce a relaxedloss function to enable more flexible learning and integrate Deep Q-Learningprinciples to optimize the expected returns. Our experiments on a syntheticdataset demonstrate that the proposed GNN-based method achieves a higheraverage yield with significantly reduced computational time compared totraditional methods. This work highlights the potential of using GNNs forsolving optimization problems in finance and provides a promising approach forreal-time arbitrage detection in dynamic financial markets.</description>
      <author>example@mail.com (Di Zhang)</author>
      <guid isPermaLink="false">2502.03194v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction</title>
      <link>http://arxiv.org/abs/2502.02945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于大语言模型的个性化教育知识追踪框架LLM-KT，该框架将大语言模型的强大推理能力和传统序列交互模型的学习行为模式相结合。&lt;h4&gt;背景&lt;/h4&gt;知识追踪（KT）在个性化教育中是一个非常重要的议题，旨在根据学生的历史答题记录预测他们能否正确回答下一个问题。之前的研究主要集中在基于ID或文本信息的顺序行为学习上，但往往无法捕捉到足够的学生行为模式和关于题目的丰富世界知识。&lt;h4&gt;目的&lt;/h4&gt;提出一个结合大语言模型优势与传统序列交互模型优点的知识追踪框架LLM-KT。&lt;h4&gt;方法&lt;/h4&gt;{'任务级别对齐': '设计了Plug-and-Play指令来使大语言模型适应KT，利用大语言模型的丰富知识和强大推理能力。', '模态级别对齐': '设计了插件上下文和序列以整合传统方法学习到的多种模式。为了捕捉历史记录中的长上下文，提出了一个插件上下文，可以使用特定于问题和概念的令牌灵活地将压缩后的上下文嵌入插入到大语言模型中。', '行为表示增强': '通过序列适配器引入了插件序列，以利用传统顺序模型学习的行为模式来增强大语言模型。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明LLM-KT在四个典型数据集上与约20个强大基线相比达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架有效地结合了大语言模型的知识和推理能力以及序列交互模型的学习模式，为知识追踪提供了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译：知识追踪（KT）是个性化教育中一个极其重要的议题，旨在预测学生能否根据他们的过往答题记录正确回答下一个问题。先前针对该任务的研究主要集中在基于ID或文本信息的行为顺序学习上。然而，这些研究通常未能捕捉到足够的行为模式，并且在没有通过丰富的问题世界知识进行推理的情况下往往失败。在这篇论文中，我们提出了一个基于大语言模型（LLMs）的知识追踪框架，名为“LLM-KT”，以结合大语言模型和传统序列交互模型的优势。为了实现任务级别的对齐，我们设计了一种即插即用指令来使大语言模型与KT相适应，利用了大语言模型的丰富知识和强大的推理能力。为了解决模态级别对齐问题，我们设计了一个插件上下文和序列，以整合传统方法学习到的各种模式。为了捕捉历史记录中的长上下文，我们提出了一种使用特定于问题和概念令牌灵活插入压缩后的上下文嵌入到大语言模型中的插件上下文方案。此外，我们还引入了通过序列适配器利用顺序行为表示来增强大语言模型的插件序列。大量的实验表明，与大约20个强大的基准相比，“LLM-KT”在四个典型数据集上获得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The knowledge tracing (KT) problem is an extremely important topic inpersonalized education, which aims to predict whether students can correctlyanswer the next question based on their past question-answer records. Priorwork on this task mainly focused on learning the sequence of behaviors based onthe IDs or textual information. However, these studies usually fail to capturestudents' sufficient behavioral patterns without reasoning with rich worldknowledge about questions. In this paper, we propose a large language models(LLMs)-based framework for KT, named \texttt{\textbf{LLM-KT}}, to integrate thestrengths of LLMs and traditional sequence interaction models. For task-levelalignment, we design Plug-and-Play instruction to align LLMs with KT,leveraging LLMs' rich knowledge and powerful reasoning capacity. Formodality-level alignment, we design the plug-in context and sequence tointegrate multiple modalities learned by traditional methods. To capture thelong context of history records, we present a plug-in context to flexiblyinsert the compressed context embedding into LLMs using question-specific andconcept-specific tokens. Furthermore, we introduce a plug-in sequence toenhance LLMs with sequence interaction behavior representation learned bytraditional sequence models using a sequence adapter. Extensive experimentsshow that \texttt{\textbf{LLM-KT}} obtains state-of-the-art performance on fourtypical datasets by comparing it with approximately 20 strong baselines.</description>
      <author>example@mail.com (Ziwei Wang, Jie Zhou, Qin Chen, Min Zhang, Bo Jiang, Aimin Zhou, Qinchun Bai, Liang He)</author>
      <guid isPermaLink="false">2502.02945v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Electric Vehicles Charging using Large Language Models and Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.03067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了如何在电动汽车广泛采用的情况下维持电网稳定，并提出了一种结合大型语言模型和图神经网络的新方法，以优化电动汽车的智能充电策略。&lt;h4&gt;背景&lt;/h4&gt;随着电动汽车普及率提高，保持电力系统的稳定性变得至关重要。传统优化方法及强化学习技术由于面对实时充电高维度数据及其动态特性时效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方案来解决现有电动车智能充电系统面临的挑战，并探索更有效的方法。&lt;h4&gt;方法&lt;/h4&gt;采用大型语言模型（LLM）进行序列建模，结合图神经网络（GNN）抽取关系信息，以优化电动汽车的实时充电过程。&lt;h4&gt;主要发现&lt;/h4&gt;新的组合方法在性能上优于传统电动汽车智能充电方式，并为未来研究开辟了新途径。&lt;h4&gt;结论&lt;/h4&gt;这种结合大型语言模型与图神经网络的方法不仅能有效解决当前电动车充电带来的电网稳定性问题，还可能引领未来的创新解决方案方向。&lt;h4&gt;翻译&lt;/h4&gt;维持电力系统稳定性和优化电动汽车的实时充电策略是关键。传统方法和强化学习技术难以应对复杂性挑战。研究采用了新的组合方案——大型语言模型结合图神经网络，并显示出显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Maintaining grid stability amid widespread electric vehicle (EV) adoption isvital for sustainable transportation. Traditional optimization methods andReinforcement Learning (RL) approaches often struggle with the highdimensionality and dynamic nature of real-time EV charging, leading tosub-optimal solutions. To address these challenges, this study demonstratesthat combining Large Language Models (LLMs), for sequence modeling, with GraphNeural Networks (GNNs), for relational information extraction, not onlyoutperforms conventional EV smart charging methods, but also paves the way forentirely new research directions and innovative solutions.</description>
      <author>example@mail.com (Stavros Orfanoudakis, Peter Palensky, Pedro P. Vergara)</author>
      <guid isPermaLink="false">2502.03067v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.02202v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;对比学习在表征学习中是一个成熟的范式。标准的对比学习框架通过最小化相似样本之间的距离并最大化不相似样本之间的距离来工作，但在投影空间内忽略了两个样本之间可能存在的多样化的相似性方面。&lt;h4&gt;背景&lt;/h4&gt;现有的对比学习方法依赖于单一的投影头，在处理具有有限训练数据的情景时难以捕捉一个样本在不同方面的全部复杂性，导致性能欠佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的监督对比学习方法——多级对比学习（MLCL），旨在应用于多标签和层级分类任务中，并能够利用多个投影头来捕捉不同标签或层级间的样本相似性。&lt;h4&gt;方法&lt;/h4&gt;提出的框架称为多级对比学习(MLCL)，在统一框架下，可以通过多个不同的投影头来捕捉样本的多样化的相似性方面。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在文本和图像数据集上，所提出的方法优于现有最先进的对比学习方法。&lt;h4&gt;结论&lt;/h4&gt;多级对比学习通过利用多个投影头能够更有效地从复杂的数据集中提取有意义的信息，并在不同的分类任务中表现出优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning is a well-established paradigm in representationlearning. The standard framework of contrastive learning minimizes the distancebetween similar instances and maximizes the distance between dissimilar onesin the projection space, disregarding various aspects of similarity thatcan exist between two samples. Current methods rely on a single projectionhead, which fails to capture full complexity of different aspects of asample, leading to suboptimal performance in scenarios with limited trainingdata. In this paper, we present a novel supervised contrastive learningmethod called multilevel contrastive learning (MLCL) that can be applied tomulti-label and hierarchical classification tasks and utilizes multipleprojection heads to capture similarities between samples across differentlabels/hierarchies. Extensive experiments on text and image datasetsdemonstrate that the proposed approach outperforms state-of-the-artcontrastive learning methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning is a well-established paradigm in representationlearning. The standard framework of contrastive learning minimizes the distancebetween "similar" instances and maximizes the distance between dissimilar onesin the projection space, disregarding the various aspects of similarity thatcan exist between two samples. Current methods rely on a single projectionhead, which fails to capture the full complexity of different aspects of asample, leading to suboptimal performance, especially in scenarios with limitedtraining data. In this paper, we present a novel supervised contrastivelearning method in a unified framework called multilevel contrastive learning(MLCL), that can be applied to both multi-label and hierarchical classificationtasks. The key strength of the proposed method is the ability to capturesimilarities between samples across different labels and/or hierarchies usingmultiple projection heads. Extensive experiments on text and image datasetsdemonstrate that the proposed approach outperforms state-of-the-art contrastivelearning methods</description>
      <author>example@mail.com (Naghmeh Ghanooni, Barbod Pajoum, Harshit Rawal, Sophie Fellenz, Vo Nguyen Le Duy, Marius Kloft)</author>
      <guid isPermaLink="false">2502.02202v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>GP-GS: Gaussian Processes for Enhanced Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.02283v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的3D重建框架Gaussian Processes Gaussian Splatting (GP-GS)，通过多输出高斯过程模型实现稀疏结构从运动(SfM)点云的自适应和不确定性引导下的稠密化。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting作为一种高效的逼真视图合成方法已经出现，但其依赖于稀疏的SfM点云的问题一直影响着场景重建的质量。&lt;h4&gt;目的&lt;/h4&gt;解决3D Gaussian Splatting在利用稀疏SfM点云时面临的问题，提高整体的重建质量。&lt;h4&gt;方法&lt;/h4&gt;开发了基于多输出高斯过程模型的方法，提出了一种动态采样和过滤流水线，该流水线通过利用GP预测从输入2D像素和深度图中推断新的候选点来自适应地扩展SfM点云。同时采用不确定性估计指导高方差预测的修剪。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架能够生成稠密且高质量的3D Gaussians，从而提高了重建性能。&lt;h4&gt;结论&lt;/h4&gt;通过在合成和真实世界数据集上的大量实验验证了该框架的有效性和实用性。&lt;h4&gt;翻译&lt;/h4&gt;三维高斯点阵作为一种高效的逼真视图合成方法已崭露头角。然而，它依赖于稀疏的结构从运动(SfM)点云的问题始终制约着场景重建的质量。为了解决这些限制，本文提出了一种新的3D重建框架——基于高斯过程的三维高斯点阵(GP-GS)，其中开发了一个多输出高斯过程模型来实现自适应和不确定性引导下的稀疏SfM点云稠密化。具体而言，我们提出了一种动态采样和过滤流水线，通过利用GP预测从输入2D像素和深度图中推断新的候选点，从而自适应地扩展SfM点云。该流水线利用不确定性估计来指导高方差预测的修剪，确保几何一致性并生成稠密点云。稠密化后的点云为高质量初始3D Gaussians提供了基础，增强了重建性能。在合成和真实世界数据集上进行的各种规模实验验证了所提出框架的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting has emerged as an efficient photorealistic novel viewsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)point clouds consistently compromises the scene reconstruction quality. Toaddress these limitations, this paper proposes a novel 3D reconstructionframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-outputGaussian Process model is developed to achieve adaptive and uncertainty-guideddensification of sparse SfM point clouds. Specifically, we propose a dynamicsampling and filtering pipeline that adaptively expands the SfM point clouds byleveraging GP-based predictions to infer new candidate points from the input 2Dpixels and depth maps. The pipeline utilizes uncertainty estimates to guide thepruning of high-variance predictions, ensuring geometric consistency andenabling the generation of dense point clouds. The densified point cloudsprovide high-quality initial 3D Gaussians to enhance reconstructionperformance. Extensive experiments conducted on synthetic and real-worlddatasets across various scales validate the effectiveness and practicality ofthe proposed framework.</description>
      <author>example@mail.com (Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Liangxiu Han, Peng Wang)</author>
      <guid isPermaLink="false">2502.02283v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>General Time-series Model for Universal Knowledge Representation of Multivariate Time-Series data</title>
      <link>http://arxiv.org/abs/2502.03264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列（MTS）基础模型的通用知识表示是一个核心问题，但目前还没有得到解决。&lt;h4&gt;目的&lt;/h4&gt;从基本原则出发研究这一问题，并为此做出四项贡献。&lt;h4&gt;主要发现1&lt;/h4&gt;不同的时间粒度的时间序列在频率域中表现出独特的联合分布，这表明了学习通用知识的一个重要方面之前被忽视的方面。&lt;h4&gt;方法1&lt;/h4&gt;提出了一种新的傅里叶知识注意力机制，使模型能够从时间和频域两个维度学习到感知时间粒度的表示。&lt;h4&gt;主要贡献2&lt;/h4&gt;首次将自回归空白填充预训练框架引入时间序列分析，从而实现一种与生成任务无关的预训练策略。&lt;h4&gt;方法2&lt;/h4&gt;开发了一种统一的时间序列模型（GTM），该模型解决了现有时间序列模型在下游任务适应性上的限制问题。&lt;h4&gt;实验结果&lt;/h4&gt;广泛的实验证明了GTM在所有生成任务中优于现有的最先进的方法，包括长期预测、异常检测和插补。&lt;h4&gt;翻译&lt;/h4&gt;通用知识表示是多变量时间序列（MTS）基础模型的核心问题，但目前仍未解决。本文从基本原则出发研究该问题，并做出四项贡献：揭示了一个新的经验发现：不同时间粒度的时间序列在频率域中表现出独特的联合分布；提出了一种新的傅里叶知识注意力机制，使模型能够从时间和频域两个维度学习到感知时间粒度的表示；首次将自回归空白填充预训练框架引入时间序列分析，从而实现一种与生成任务无关的预训练策略，并开发了统一的时间序列模型（GTM），该模型解决了现有时间序列模型在下游任务适应性上的限制问题。广泛的实验表明，GTM在所有生成任务中优于现有的最先进的方法，包括长期预测、异常检测和插补。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Universal knowledge representation is a central problem for multivariate timeseries(MTS) foundation models and yet remains open. This paper investigatesthis problem from the first principle and it makes four folds of contributions.First, a new empirical finding is revealed: time series with different timegranularities (or corresponding frequency resolutions) exhibit distinct jointdistributions in the frequency domain. This implies a crucial aspect oflearning universal knowledge, one that has been overlooked by previous studies.Second, a novel Fourier knowledge attention mechanism is proposed to enablelearning time granularity-aware representations from both the temporal andfrequency domains. Third, an autoregressive blank infilling pre-trainingframework is incorporated to time series analysis for the first time, leadingto a generative tasks agnostic pre-training strategy. To this end, we developthe General Time-series Model (GTM), a unified MTS foundation model thataddresses the limitation of contemporary time series models, which oftenrequire token, pre-training, or model-level customizations for downstream tasksadaption. Fourth, extensive experiments show that GTM outperformsstate-of-the-art (SOTA) methods across all generative tasks, includinglong-term forecasting, anomaly detection, and imputation.</description>
      <author>example@mail.com (Cheng He, Xu Huang, Gangwei Jiang, Zhaoyi Li, Defu Lian, Hong Xie, Enhong Chen, Xijie Liang, Zengrong Zheng)</author>
      <guid isPermaLink="false">2502.03264v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>T-SCEND: Test-time Scalable MCTS-enhanced Diffusion Model</title>
      <link>http://arxiv.org/abs/2502.01989v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的框架T-SCEND，该框架通过改进的训练目标和测试时间计算扩展来显著提高扩散模型的推理能力。&lt;h4&gt;背景&lt;/h4&gt;当前扩散模型在增加推理预算时性能提升有限。为了改善这一情况，提出了一个新的线性回归负对比学习目标以及KL正则化方法以优化能量景观并减少对抗采样。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进扩散模型推理能力和能源效率的方法，并展示其在复杂任务上的有效性。&lt;h4&gt;方法&lt;/h4&gt;T-SCEND框架包括两个主要部分：训练和推理。在训练阶段，引入了线性回归负对比学习目标以优化能量景观；同时使用KL正则化减少对抗采样问题。在推理阶段，通过与MCTS结合的混合蒙特卡洛树搜索（hMCTS）方法来提高解噪过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在迷宫和数独等具有挑战性的推理任务中，T-SCEND框架表现出色，并且能够解决大规模问题。例如，在训练时使用$6imes6$大小的迷宫，该模型可以解决高达$15imes15$大小的迷宫问题。&lt;h4&gt;结论&lt;/h4&gt;通过优化扩散模型的能量景观和引入混合蒙特卡洛树搜索方法，T-SCEND在推理性能上取得了显著改进，并为未来的研究提供了有价值的参考。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了测试时间可扩展MCTS增强型扩散模型（T-SCEND），这是一种新颖的框架，它通过更好的基于能量的训练和增加测试时间计算来显著提高扩散模型的推理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Test-time Scalable MCTS-enhanced Diffusion Model (T-SCEND), anovel framework that significantly improves diffusion model's reasoningcapabilities with better energy-based training and scaling up test-timecomputation. We first show that na\"ively scaling up inference budget fordiffusion models yields marginal gain. To address this, the training of T-SCENDconsists of a novel linear-regression negative contrastive learning objectiveto improve the performance-energy consistency of the energy landscape, and a KLregularization to reduce adversarial sampling. During inference, T-SCENDintegrates the denoising process with a novel hybrid Monte Carlo Tree Search(hMCTS), which sequentially performs best-of-N random search and MCTS asdenoising proceeds. On challenging reasoning tasks of Maze and Sudoku, wedemonstrate the effectiveness of T-SCEND's training objective and scalableinference method. In particular, trained with Maze sizes of up to $6\times6$,our T-SCEND solves $88\%$ of Maze problems with much larger sizes of$15\times15$, while standard diffusion completely fails. Code to reproduce theexperiments can be found at https://github.com/AI4Science-WestlakeU/t_scend.</description>
      <author>example@mail.com (Tao Zhang, Jia-Shu Pan, Ruiqi Feng, Tailin Wu)</author>
      <guid isPermaLink="false">2502.01989v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics</title>
      <link>http://arxiv.org/abs/2502.02975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  published at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了TGB-Seq，一个新的基准测试集，用于评估模型在处理时间序列图数据中的顺序动态方面的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的链接预测方法往往侧重于重复边的预测，并且常用的基准测试集中包含大量的重复边，缺乏复杂的时间序列动态特征。这导致了现有方法对学习序列动态的重要性被低估。&lt;h4&gt;目的&lt;/h4&gt;展示目前的方法在处理简单的序列动态时存在的局限性，并引入一个新的基准测试集TGB-Seq来挑战模型的学习和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;通过创建一个减少重复边、包含复杂顺序动态的基准测试集，用于评估现有技术如GraphMixer和DyGFormer的表现。该数据集包括电商互动、电影评分、企业评论等不同领域的大量真实世界数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在处理TGB-Seq时，当前方法通常表现出性能下降，并且训练成本高昂。&lt;h4&gt;结论&lt;/h4&gt;这个新的基准测试集为未来的研究提供了挑战和机会。它包含了一系列的数据集、排行榜以及示例代码，供研究者们使用。&lt;h4&gt;翻译&lt;/h4&gt;未来链接预测是各种现实世界动态系统中的一个基本难题。为了应对这一挑战，已经开发出了大量的时序图神经网络（temporal GNNs）及基准数据集。然而这些数据集通常包含过多的重复边，并缺乏复杂的时间序列动态特性，这是许多实际应用场景如推荐系统和社交媒体上的“Who-To-Follow”等的关键特征。这种忽视导致现有方法无意中低估了学习时间序列动态的重要性，主要关注于预测重复边。在本研究中，我们展示出现有的方法（例如GraphMixer和DyGFormer）无法天然地学习简单的顺序动力学，如：“一个追随OpenAI和Anthropic的用户更可能接下来会追随Meta的AI”。受到这一问题的启发，我们引入了时间图基准集TGB-Seq，一个精心策划的数据集以最小化重复边的存在，挑战模型去学习序列动态并泛化到未见过的边。TGB-Seq包括电商互动、电影评分、企业评论、社交网络、引文网络和网页链接网络等众多真实世界数据集。基准测试实验显示，在处理TGB-Seq时，当前方法通常会遭受显著性能下降，并且训练成本高昂，这为未来的研究提出了新的挑战与机遇。TGB-Seq的数据集、排行榜以及示例代码可访问 https://tgb-seq.github.io/ 获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Future link prediction is a fundamental challenge in various real-worlddynamic systems. To address this, numerous temporal graph neural networks(temporal GNNs) and benchmark datasets have been developed. However, thesedatasets often feature excessive repeated edges and lack complex sequentialdynamics, a key characteristic inherent in many real-world applications such asrecommender systems and ``Who-To-Follow'' on social networks. This oversighthas led existing methods to inadvertently downplay the importance of learningsequential dynamics, focusing primarily on predicting repeated edges.  In this study, we demonstrate that existing methods, such as GraphMixer andDyGFormer, are inherently incapable of learning simple sequential dynamics,such as ``a user who has followed OpenAI and Anthropic is more likely to followAI at Meta next.'' Motivated by this issue, we introduce the Temporal GraphBenchmark with Sequential Dynamics (TGB-Seq), a new benchmark carefully curatedto minimize repeated edges, challenging models to learn sequential dynamics andgeneralize to unseen edges. TGB-Seq comprises large real-world datasetsspanning diverse domains, including e-commerce interactions, movie ratings,business reviews, social networks, citation networks and web link networks.Benchmarking experiments reveal that current methods usually suffer significantperformance degradation and incur substantial training costs on TGB-Seq, posingnew challenges and opportunities for future research. TGB-Seq datasets,leaderboards, and example codes are available at https://tgb-seq.github.io/.</description>
      <author>example@mail.com (Lu Yi, Jie Peng, Yanping Zheng, Fengran Mo, Zhewei Wei, Yuhang Ye, Yue Zixuan, Zengfeng Huang)</author>
      <guid isPermaLink="false">2502.02975v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Topological Self-Explainable GNNs: A Formal Explainability Perspective</title>
      <link>http://arxiv.org/abs/2502.02719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了自解释图神经网络（SE-GNNs）的特性和限制，并提出了一种双通道GNN模型，以解决现有方法在可解释性与性能上的不足。&lt;h4&gt;背景&lt;/h4&gt;SE-GNN作为设计之初就具备可解释性的GNN模型受到广泛关注，但其生成的解释的质量和局限尚未被充分理解。&lt;h4&gt;目的&lt;/h4&gt;深入分析SE-GNN生成的解释（Trivial Explanations, TEs）的特点，并提出一种新的双通道GNN架构以提高模型性能同时保持较高的可解释性。&lt;h4&gt;方法&lt;/h4&gt;通过理论分析对比TEs与其他两种类型的解释——主析取范式（PI）和忠实解释之间的异同，发现TEs在某些情况下与PI解释一致但在大多数情况中不如PI解释信息量大且不够忠实。此外还提出了一种结合白盒规则提取器的双通道GNN架构。&lt;h4&gt;主要发现&lt;/h4&gt;1. TEs匹配特定任务下的PI解释，但通常比PI解释不那么有信息量并且与忠诚度的概念不太一致。     2. PI和忠实解释虽然具有较高的信息性，但是难以被准确找到且可能过于庞大以致于不可行。     3. 双通道GNN架构能够通过结合白盒规则提取器和标准的SE-GNN来生成简洁有效的规则并保持良好的性能。&lt;h4&gt;结论&lt;/h4&gt;双通道图神经网络在提供强大解释能力和优良模型性能方面显示了潜在的价值，可能为实际应用中的可解释性需求开辟新的途径。代码材料见补充资料。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文主要研究自解释性的图神经网络（SE-GNNs）的特性和限制，并通过理论分析对比其生成的解释与其他类型的解释的不同，提出了新的双通道GNN架构以提高模型性能同时保持较高可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-Explainable Graph Neural Networks (SE-GNNs) are popularexplainable-by-design GNNs, but the properties and the limitations of theirexplanations are not well understood. Our first contribution fills this gap byformalizing the explanations extracted by SE-GNNs, referred to as TrivialExplanations (TEs), and comparing them to established notions of explanations,namely Prime Implicant (PI) and faithful explanations. Our analysis revealsthat TEs match PI explanations for a restricted but significant family oftasks. In general, however, they can be less informative than PI explanationsand are surprisingly misaligned with widely accepted notions of faithfulness.Although faithful and PI explanations are informative, they are intractable tofind and we show that they can be prohibitively large. Motivated by this, wepropose Dual-Channel GNNs that integrate a white-box rule extractor and astandard SE-GNN, adaptively combining both channels when the task benefits. Ourexperiments show that even a simple instantiation of Dual-Channel GNNs canrecover succinct rules and perform on par or better than widely used SE-GNNs.Our code can be found in the supplementary material.</description>
      <author>example@mail.com (Steve Azzolin, Sagar Malhotra, Andrea Passerini, Stefano Teso)</author>
      <guid isPermaLink="false">2502.02719v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Physically Consistent Global Atmospheric Data Assimilation with Machine Learning in a Latent Space</title>
      <link>http://arxiv.org/abs/2502.02884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的数据同化方法，即潜变量数据同化（LDA），旨在解决传统数据同化技术在大气复杂性及误差估计上的局限。&lt;h4&gt;背景信息&lt;/h4&gt;数据同化是提高数值天气预报初始条件准确性的关键技术。然而，由于难以精确估算背景错误协方差矩阵B以及同化步骤中标准线性假设的要求，现有方法存在一定的限制。&lt;h4&gt;研究目的&lt;/h4&gt;为了克服传统方法的缺点，开发了一种基于非线性机器学习的Bayesian数据同化的LDA技术。&lt;h4&gt;采用的方法&lt;/h4&gt;通过自动编码器在大气潜变量空间内执行非线性机器学习基的数据同化。实验证明了潜在空间增量与模型空间影响之间的近似线性关系，从而确保最优分析的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;LDA能够将观测信息物理地传播到未被观测的区域和大气变量中，并在模型空间内优于传统数据同化方法，同时处理真实观测的数据也展示了其在操作再分析和天气预报系统中的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;新提出的Latent Data Assimilation（LDA）技术通过利用潜变量空间的关系克服了现有数据同化的限制，为提高大气模型的准确性和效率开辟了一条新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data assimilation (DA) provides more accurate, physically consistent analysisfields and is used for estimating initial conditions in numerical weatherforecasting. Traditional DA methods derive statistically optimal analyses inmodel space based on Bayesian theory. However, their effectiveness is limitedby the difficulty of accurately estimating the background error covariancesmatrix B, which represents the intricate interdependencies among atmosphericvariables, as well as the standard linearity assumptions required during theassimilation step. To address these limitations, we propose Latent DataAssimilation (LDA) for a multi-variable global atmosphere, performingnon-linear Machine-Learning based Bayesian DA on an atmospheric latentrepresentation learned by an autoencoder. The feasibility of LDA is supportedby the near-linear relationship between increments in latent space (within thetypical magnitude range for DA) and their corresponding impacts in model space,ensuring that the optimal analysis obtained in latent space approximates theoptimal analysis in model space. Due to the relationships among the atmosphericvariables encoded in the latent space, LDA can physically propagate observationinformation across unobserved regions and atmospheric variables, even with afully diagonal B in latent space. We perform idealized experiments withsimulated observations and demonstrate the superiority of LDA over traditionalDA methods in model space, while the experiments assimilating real observationshighlight its potential application for operational reanalysis and weatherforecasting systems.</description>
      <author>example@mail.com (Hang Fan, Ben Fei, Pierre Gentine, Yi Xiao, Kun Chen, Yubao Liu, Yongquan Qu, Fenghua Ling, Lei Bai)</author>
      <guid isPermaLink="false">2502.02884v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>scBIT: Integrating Single-cell Transcriptomic Data into fMRI-based Prediction for Alzheimer's Disease Diagnosis</title>
      <link>http://arxiv.org/abs/2502.02630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;scBIT是一种结合功能性磁共振成像（fMRI）和单核RNA测序(snRNA)的新方法，用于改善阿尔茨海默病(AD)的预测模型，并通过跨模态学习揭示复杂的脑区-基因关联。&lt;h4&gt;背景&lt;/h4&gt;功能磁共振成像(fMRI)和单细胞转录组学在阿尔茨海默病研究中至关重要，每种技术都提供了关于神经元功能和分子机制的独特见解。然而，将这两种互补模式整合在一起的方法仍鲜有人探索。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法(scBIT)，通过结合fMRI和snRNA数据来增强AD的预测准确性，并提高诊断模型的解释性。&lt;h4&gt;方法&lt;/h4&gt;scBIT采用采样策略对snRNA数据进行分割，生成特定细胞类型特异性的基因网络。同时使用自解释图神经网络提取关键子图，并利用人口统计学和遗传相似度将个体间的snRNA和fMRI数据配对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与单独使用fMRI相比，scBIT结合snRNA可显著提高AD预测模型的准确性，二分类准确率提升了3.39%，五类分类准确率提高了26.59%。此外，scBIT有助于揭示复杂的脑区-基因关联。&lt;h4&gt;结论&lt;/h4&gt;通过将大脑成像转录组学推进到单细胞水平，scBIT为阿尔茨海默病的生物标志物发现带来了新的启示，并可能促进该领域的研究进展。&lt;h4&gt;翻译&lt;/h4&gt;功能性磁共振成像(fMRI)和单细胞转录组测序在阿尔茨海默病(AD)的研究中扮演着关键角色。然而，如何整合这两种互补模式的方法仍有待探索。scBIT提供了一种结合fMRI与snRNA的新方法，以改善基于fMRI的预测模型，并且通过跨模态学习揭示复杂的脑区-基因关联。实验表明，将snRNA数据纳入到scBIT模型中可以显著提高AD诊断预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Functional MRI (fMRI) and single-cell transcriptomics are pivotal inAlzheimer's disease (AD) research, each providing unique insights into neuralfunction and molecular mechanisms. However, integrating these complementarymodalities remains largely unexplored. Here, we introduce scBIT, a novel methodfor enhancing AD prediction by combining fMRI with single-nucleus RNA (snRNA).scBIT leverages snRNA as an auxiliary modality, significantly improvingfMRI-based prediction models and providing comprehensive interpretability. Itemploys a sampling strategy to segment snRNA data into cell-type-specific genenetworks and utilizes a self-explainable graph neural network to extractcritical subgraphs. Additionally, we use demographic and genetic similaritiesto pair snRNA and fMRI data across individuals, enabling robust cross-modallearning. Extensive experiments validate scBIT's effectiveness in revealingintricate brain region-gene associations and enhancing diagnostic predictionaccuracy. By advancing brain imaging transcriptomics to the single-cell level,scBIT sheds new light on biomarker discovery in AD research. Experimentalresults show that incorporating snRNA data into the scBIT model significantlyboosts accuracy, improving binary classification by 3.39% and five-classclassification by 26.59%. The codes were implemented in Python and have beenreleased on GitHub (https://github.com/77YQ77/scBIT) and Zenodo(https://zenodo.org/records/11599030) with detailed instructions.</description>
      <author>example@mail.com (Yu-An Huang, Yao Hu, Yue-Chao Li, Xiyue Cao, Xinyuan Li, Kay Chen Tan, Zhu-Hong You, Zhi-An Huang)</author>
      <guid isPermaLink="false">2502.02630v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>PH-VAE: A Polynomial Hierarchical Variational Autoencoder Towards Disentangled Representation Learning</title>
      <link>http://arxiv.org/abs/2502.02856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages,14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种多项式分层变分自编码器（PH-VAE），旨在改进传统变分自编码器在复杂数据分布上的生成效果。&lt;h4&gt;背景&lt;/h4&gt;传统的变分自编码器存在缺乏可解释性、训练过程中超参数难以调整、产生的下游输出模糊或不真实以及信息丢失等问题，这些问题限制了其处理具有复杂分布的数据的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的PH-VAE模型，通过引入多项式分层数据格式来生成或重构数据分布，并在损失函数中使用多项式散度代替Kullback-Leibler（KL）散度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的多项式散度，并将其应用于损失函数，同时保持了数据集大小不变，但提高了重建分布函数和数据图像的质量。此外还展示了PH-VAE具有某种程度上的解耦表示学习能力。&lt;h4&gt;主要发现&lt;/h4&gt;提出的PH-VAE系统地且显著地改进了重构分布函数的准确性和再现性，并且提高了重构数据图像质量的同时保持了数据集大小，能够捕捉到更精细的数据分辨率。&lt;h4&gt;结论&lt;/h4&gt;通过引入多项式分层和新散度机制，所开发的PH-VAE模型在处理复杂分布数据方面比传统的变分自编码器更为优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The variational autoencoder (VAE) is a simple and efficient generativeartificial intelligence method for modeling complex probability distributionsof various types of data, such as images and texts. However, it suffers somemain shortcomings, such as lack of interpretability in the latent variables,difficulties in tuning hyperparameters while training, producing blurry,unrealistic downstream outputs or loss of information due to how it calculatesloss functions and recovers data distributions, overfitting, and origin gravityeffect for small data sets, among other issues. These and other limitationshave caused unsatisfactory generation effects for the data with complexdistributions. In this work, we proposed and developed a polynomialhierarchical variational autoencoder (PH-VAE), in which we used a polynomialhierarchical date format to generate or to reconstruct the data distributions.In doing so, we also proposed a novel Polynomial Divergence in the lossfunction to replace or generalize the Kullback-Leibler (KL) divergence, whichresults in systematic and drastic improvements in both accuracy andreproducibility of the re-constructed distribution function as well as thequality of re-constructed data images while keeping the dataset size the samebut capturing fine resolution of the data. Moreover, we showed that theproposed PH-VAE has some form of disentangled representation learning ability.</description>
      <author>example@mail.com (Xi Chen, Shaofan Li)</author>
      <guid isPermaLink="false">2502.02856v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Structure Learning for Tumor Microenvironment with Cell Type Annotation from non-spatial scRNA-seq data</title>
      <link>http://arxiv.org/abs/2502.02629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的图神经网络(scGSL)模型，用于单细胞RNA测序数据中的肿瘤微环境(TME)异质性分析。该模型提高了细胞类型预测和细胞间相互作用的准确性。&lt;h4&gt;背景&lt;/h4&gt;利用单细胞RNA测序技术探索肿瘤微环境中细胞异质性的研究对于理解癌症的发展及治疗反应至关重要。然而，当前的技术缺乏空间信息，并且依赖于不完整的配体-受体相互作用数据集，限制了对细胞类型的精确注释和细胞间通讯的推断。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图神经网络的新模型(scGSL)，以增强细胞类型预测及细胞间通讯分析的能力。&lt;h4&gt;方法&lt;/h4&gt;本研究使用了一个包含49,020个单细胞的数据集，这些数据来自19位患者，涉及三种癌症：白血病、乳腺浸润性癌和结直肠癌。scGSL模型在所有数据集中实现了平均84.83%的准确率、86.23%的精确度、81.51%的召回率以及80.92%的F1值，显著超过了现有方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;该scGSL模型能够以无监督的方式识别生物上有意义的基因相互作用，并通过在不同癌症中的关键基因对表达差异得到验证。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络(scGSL)的方法可以有效提高单细胞RNA测序数据分析中关于肿瘤微环境异质性、细胞类型预测和细胞间通讯分析的能力。该模型对于理解癌症生物学以及开发新的治疗方法具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exploration of cellular heterogeneity within the tumor microenvironment(TME) via single-cell RNA sequencing (scRNA-seq) is essential for understandingcancer progression and response to therapy. Current scRNA-seq approaches,however, lack spatial context and rely on incomplete datasets ofligand-receptor interactions (LRIs), limiting accurate cell type annotation andcell-cell communication (CCC) inference. This study addresses these challengesusing a novel graph neural network (GNN) model that enhances cell typeprediction and cell interaction analysis. Our study utilized a datasetconsisting of 49,020 cells from 19 patients across three cancer types:Leukemia, Breast Invasive Carcinoma, and Colorectal Cancer. The proposed scGSLmodel demonstrated robust performance, achieving an average accuracy of 84.83%,precision of 86.23%, recall of 81.51%, and an F1 score of 80.92% across alldatasets. These metrics represent a significant enhancement over existingmethods, which typically exhibit lower performance metrics. Additionally, byreviewing existing literature on gene interactions within the TME, the scGSLmodel proves to robustly identify biologically meaningful gene interactions inan unsupervised manner, validated by significant expression differences in keygene pairs across various cancers. The source code and data used in this papercan be found in https://github.com/LiYuechao1998/scGSL.</description>
      <author>example@mail.com (Yu-An Huang, Yue-Chao Li, Hai-Ru You, Jie Pan, Xiyue Cao, Xinyuan Li, Zhi-An Huang, Zhu-Hong You)</author>
      <guid isPermaLink="false">2502.02629v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Metis: A Foundation Speech Generation Model with Masked Generative Pre-training</title>
      <link>http://arxiv.org/abs/2502.03128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Metis模型，它是一个用于统一语音生成的基础模型。通过大规模无标记语音数据的预训练和精细调整适应多种任务。&lt;h4&gt;背景&lt;/h4&gt;传统的任务特定或多任务模型不能有效处理多样化的工作负载。Meta模型能够利用大规模未标注的数据进行预训练，并且在不同条件下进行微调以适应各种任务。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的语音生成基础模型，可以高效地适应不同的语音生成任务。&lt;h4&gt;方法&lt;/h4&gt;{'1': 'Metis使用两种离散语音表示：一种是从语音自我监督学习（SSL）特征派生出的SSL令牌，另一种是直接从波形量化得出的声学令牌。', '2': 'Metis在不附加任何其他条件的情况下，在30万小时多样化的语音数据上进行无掩码生成预训练。', '3': '通过任务特定条件的微调，使得模型可以适应各种语音生成任务，并支持多模态输入。即使使用有限的数据和可训练参数也能高效完成任务。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，Metis在零样本文本到语音、声码转换、目标说话人提取、语音增强和唇动至语音等五种任务中优于最先进的任务特定或多任务系统，尽管其参数量小于20M，训练数据也只有其他系统的300分之一。&lt;h4&gt;结论&lt;/h4&gt;Meta模型可以作为一个统一的语音生成基础模型，展示出了强大的适应性和性能优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Metis, a foundation model for unified speech generation. Unlikeprevious task-specific or multi-task models, Metis follows a pre-training andfine-tuning paradigm. It is pre-trained on large-scale unlabeled speech datausing masked generative modeling and then fine-tuned to adapt to diverse speechgeneration tasks. Specifically, 1) Metis utilizes two discrete speechrepresentations: SSL tokens derived from speech self-supervised learning (SSL)features, and acoustic tokens directly quantized from waveforms. 2) Metisperforms masked generative pre-training on SSL tokens, utilizing 300K hours ofdiverse speech data, without any additional condition. 3) Through fine-tuningwith task-specific conditions, Metis achieves efficient adaptation to variousspeech generation tasks while supporting multimodal input, even when usinglimited data and trainable parameters. Experiments demonstrate that Metis canserve as a foundation model for unified speech generation: Metis outperformsstate-of-the-art task-specific or multi-task systems across five speechgeneration tasks, including zero-shot text-to-speech, voice conversion, targetspeaker extraction, speech enhancement, and lip-to-speech, even with fewer than20M trainable parameters or 300 times less training data. Audio samples are areavailable at https://metis-demo.github.io/.</description>
      <author>example@mail.com (Yuancheng Wang, Jiachen Zheng, Junan Zhang, Xueyao Zhang, Huan Liao, Zhizheng Wu)</author>
      <guid isPermaLink="false">2502.03128v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Task-Aware Virtual Training: Enhancing Generalization in Meta-Reinforcement Learning for Out-of-Distribution Tasks</title>
      <link>http://arxiv.org/abs/2502.02834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages main paper, 19 pages appendices with reference, Submitted to  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的算法Task-Aware Virtual Training (TAVT)，旨在改进元强化学习中任务表示，特别是在处理未见过的任务分布时的问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于上下文的元增强学习方法虽然能够通过任务潜在变量改善任务表示，但在面对分布外(OOD)任务时仍然存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种新算法来更准确地捕捉训练和OOD场景中的任务特性。&lt;h4&gt;方法&lt;/h4&gt;TAVT利用度量学习方法获取基于特征的任务表示，并使用状态正则化技术减少在变化环境下的过度估计误差，同时保留虚拟任务中的任务特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在多种MuJoCo和MetaWorld环境中，TAVT显著提高了对OOD任务的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过准确捕捉训练与OOD场景的任务特性以及应用状态正则化技术，TAVT为处理元强化学习中的任务表示问题提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;元增强学习旨在开发能够推广到从任务分布中采样的未见过任务的策略。虽然基于上下文的元增强学习方法通过使用任务潜在变量改进了任务表示，但它们在应对分布外(OOD)任务时仍然面临挑战。为了克服这一问题，我们提出了任务感知虚拟训练(TAVT)，这是一种新的算法，它利用度量学习准确地捕捉训练和OOD场景中的任务特征。我们的方法成功保留了虚拟任务中特定于任务的特性，并采用状态正则化技术来减轻在变化环境下的过度估计误差。数值结果表明，在多种MuJoCo和MetaWorld环境中，TAVT显著提高了对OOD任务的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta reinforcement learning aims to develop policies that generalize tounseen tasks sampled from a task distribution. While context-based meta-RLmethods improve task representation using task latents, they often strugglewith out-of-distribution (OOD) tasks. To address this, we propose Task-AwareVirtual Training (TAVT), a novel algorithm that accurately captures taskcharacteristics for both training and OOD scenarios using metric-basedrepresentation learning. Our method successfully preserves task characteristicsin virtual tasks and employs a state regularization technique to mitigateoverestimation errors in state-varying environments. Numerical resultsdemonstrate that TAVT significantly enhances generalization to OOD tasks acrossvarious MuJoCo and MetaWorld environments.</description>
      <author>example@mail.com (Jeongmo Kim, Yisak Park, Minung Kim, Seungyul Han)</author>
      <guid isPermaLink="false">2502.02834v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>RepLoRA: Reparameterizing Low-Rank Adaptation via the Perspective of Mixture of Experts</title>
      <link>http://arxiv.org/abs/2502.03044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对LoRA的理论基础进行了深入分析，并提出了新的Reparameterized Low-rank Adaptation（RepLoRA）方法，通过在训练过程中引入轻量级MLP来重新参数化LoRA矩阵，显著提高了低秩矩阵估计过程的速度和效果。&lt;h4&gt;背景&lt;/h4&gt;Low-rank adaptation (LoRA)是一种用于大规模基础模型微调的强大方法。尽管它很受欢迎，但对其理论理解仍然有限。&lt;h4&gt;目的&lt;/h4&gt;通过探索LoRA与混合专家（Mixture of Experts）模型之间的联系，对LoRA进行理论分析，并提出新的优化策略以提高其性能和效率。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个新的方法Reparameterized Low-rank Adaptation (RepLoRA)，该方法引入了轻量级MLP来重新参数化LoRA矩阵。此外，还进行了广泛的实验验证这种方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;通过简单的重参数化，可以显著加速低秩矩阵估计过程，并减少所需的数据量，从指数级别降低到多项式级别；RepLoRA在多个领域中均优于原始的LoRA方法，特别是在数据有限的情况下表现更佳。&lt;h4&gt;结论&lt;/h4&gt;Reparameterized Low-rank Adaptation（RepLoRA）展示了强大的理论和实证稳健性。通过引入轻量级MLP进行重参数化，这种方法不仅提高了模型的学习效率，还在各种任务中取得了优于原始LoRA的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：低秩适应法(LoRA)已经成为大规模基础模型微调的一种强大方法。尽管它受到广泛欢迎，但对其理论理解仍然有限。本文通过分析其与专家混合（Mixture of Experts）模型之间的联系来提供对LoRA的一个理论性探讨。在这一框架下，我们展示了简单的重新参数化低秩矩阵可以显著加速估计过程，并证明了通过重参数化可以在达到相同的估计误差情况下减少所需的数据量从指数级下降到多项式级别。受到该见解的启发，本文提出了一个新方法：Reparameterized Low-rank Adaptation (RepLoRA)，它将轻量级MLP用于重新参数化低秩适应矩阵。广泛的实验显示了RepLoRA在多个领域的持续优越表现，并且与普通LoRA相比，在数据受限的情况下，RepLoRA的表现甚至高出最多40.0%，仅需30%的训练数据即可达到相同性能水平，这说明了我们这一PEFT方法的强大和稳健性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-rank adaptation (LoRA) has emerged as a powerful method for fine-tuninglarge-scale foundation models. Despite its popularity, the theoreticalunderstanding of LoRA has remained limited. This paper presents a theoreticalanalysis of LoRA by examining its connection to the Mixture of Experts models.Under this framework, we show that simple reparameterizations of the LoRAmatrices can notably accelerate the low-rank matrix estimation process. Inparticular, we prove that reparameterization can reduce the data needed toachieve a desired estimation error from an exponential to a polynomial scale.Motivated by this insight, we propose Reparameterized Low-rank Adaptation(RepLoRA), which incorporates lightweight MLPs to reparameterize the LoRAmatrices. Extensive experiments across multiple domains demonstrate thatRepLoRA consistently outperforms vanilla LoRA. Notably, with limited data,RepLoRA surpasses LoRA by a margin of up to 40.0% and achieves LoRA'sperformance with only 30.0% of the training data, highlighting both thetheoretical and empirical robustness of our PEFT method.</description>
      <author>example@mail.com (Tuan Truong, Chau Nguyen, Huy Nguyen, Minh Le, Trung Le, Nhat Ho)</author>
      <guid isPermaLink="false">2502.03044v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Sample-Efficient Deep Learning for Change Detection in Remote Sensing: Tasks, Strategies, and Challenges</title>
      <link>http://arxiv.org/abs/2502.02835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE GRSM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;过去十年中，深度学习技术的迅速发展使得在大规模遥感图像上进行自动、准确且稳健的变化检测成为可能。&lt;h4&gt;问题与挑战&lt;/h4&gt;尽管变化检测方法有了进步，但它们在实际场景中的应用依然有限。原因包括输入数据多样性和应用场景复杂性等挑战，以及难以获取大量训练样本的问题。&lt;h4&gt;解决方案&lt;/h4&gt;为应对这些挑战，各种特定的应用场景和培训资源被开发出来以解决变化检测问题。&lt;h4&gt;新技术的进展&lt;/h4&gt;图像生成、自监督学习及视觉基础模型（VFMs）等领域的最新进展提供了解决深度学习方法中数据需求量大的新途径。&lt;h4&gt;研究展望&lt;/h4&gt;未来需要进一步调查这些技术在更广泛应用场景中的发展，包括训练和部署基于深度学习的变化检测方法的新策略和技术。&lt;h4&gt;目标&lt;/h4&gt;本文总结了不同的变化检测任务的文献方法，并提供了样本受限场景下训练及部署基于DL的方法的有效策略和技术。期望该综述为本领域的研究者提供新的见解和灵感，以开发更有效的变化检测方法适用于更广泛的环境。&lt;h4&gt;翻译&lt;/h4&gt;在过去的十年里，深度学习（DL）技术迅速发展，使得在大量遥感图像上进行自动、准确且稳健的变化检测成为可能。然而，尽管变化检测方法取得了进展，但它们的实际应用仍然受到多样化的输入数据和应用场景限制的影响。例如，收集的RSI可以是时间序列观察，并需要更多相关信息来指示改变的时间或具体的改变类型。此外，在许多情况下获取大量训练样本是很困难的，而训练深度神经网络（DNN）则需要大量的训练样本。为解决这些挑战，考虑到不同的应用情景和培训资源，已开发出各种特定的变化检测方法。最近在图像生成、自监督学习以及视觉基础模型（VFMs）领域的进步开辟了新的途径来应对基于DL的变化检测中‘数据饥饿’的问题。在未来的发展研究中需要进一步探讨这些技术在其更广泛的应用场景中的发展。因此，本文总结了不同变化检测任务的文献方法，并提供了在样本受限的情况下训练和部署基于深度学习的方法的有效策略和技术。我们期望这项综述能够为本领域的研究人员提供新的见解和灵感，以开发适用于更广泛环境的更加有效的变化检测方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/MGRS.2025.3533605&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the last decade, the rapid development of deep learning (DL) has made itpossible to perform automatic, accurate, and robust Change Detection (CD) onlarge volumes of Remote Sensing Images (RSIs). However, despite advances in CDmethods, their practical application in real-world contexts remains limited dueto the diverse input data and the applicational context. For example, thecollected RSIs can be time-series observations, and more informative resultsare required to indicate the time of change or the specific change category.Moreover, training a Deep Neural Network (DNN) requires a massive amount oftraining samples, whereas in many cases these samples are difficult to collect.To address these challenges, various specific CD methods have been developedconsidering different application scenarios and training resources.Additionally, recent advancements in image generation, self-supervision, andvisual foundation models (VFMs) have opened up new approaches to address the'data-hungry' issue of DL-based CD. The development of these methods in broaderapplication scenarios requires further investigation and discussion. Therefore,this article summarizes the literature methods for different CD tasks and theavailable strategies and techniques to train and deploy DL-based CD methods insample-limited scenarios. We expect that this survey can provide new insightsand inspiration for researchers in this field to develop more effective CDmethods that can be applied in a wider range of contexts.</description>
      <author>example@mail.com (Lei Ding, Danfeng Hong, Maofan Zhao, Hongruixuan Chen, Chenyu Li, Jie Deng, Naoto Yokoya, Lorenzo Bruzzone, Jocelyn Chanussot)</author>
      <guid isPermaLink="false">2502.02835v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography</title>
      <link>http://arxiv.org/abs/2502.02779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了FM-CT，这是一个基于自我监督学习的头颅CT图像基础模型，用于广泛疾病检测。&lt;h4&gt;背景&lt;/h4&gt;头部计算机断层扫描（CT）成像是评估大脑、颅骨和脑血管系统的常见影像学检查手段。它常被用作神经紧急情况下的首选成像方式。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的基于自我监督学习的方法来创建一个通用的头颅CT图像基础模型，用于检测各种疾病。&lt;h4&gt;方法&lt;/h4&gt;通过自监督学习预训练深度学习模型，使用大规模、多样化的361,663个无对比剂3D头部CT扫描数据集进行培训。采用歧视和自我蒸馏以及掩码图像建模的方法，在3D水平上构建模型以更全面有效地利用头颅CT扫描的结构。&lt;h4&gt;主要发现&lt;/h4&gt;与从零开始训练的模型和先前基于稀缺标注数据集的3D CT基础模型相比，自监督基础模型在下游诊断任务中的性能显著提升。&lt;h4&gt;结论&lt;/h4&gt;这项工作展示了自我监督学习在医学成像中应用的有效性，并为头颅CT图像分析设立了新的基准。该方法扩大了人工智能在头颅CT诊断中的使用范围。&lt;h4&gt;翻译&lt;/h4&gt;头部计算机断层扫描（CT）成像是广泛使用的影像学手段，特别是在评估大脑、颅骨和脑血管系统的病理状况时。它通常作为神经紧急情况下的首选成像方式，因其获取图像的速度快、安全且成本效益高。深度学习模型可能有助于多种疾病的检测，但由于高质量标签和注释的缺乏，尤其是对于罕见病症，阻碍了强大模型的发展。为了解决这一挑战，我们引入了FM-CT：一个用于通用疾病检测的基础模型，该模型通过自监督学习在大量多样化的无对比剂3D头部CT扫描数据集上进行了预训练。这种方法使模型能够从无需手动注释的大量数据中学习到健壮且通用的功能特征。为了研究头颅CT成像中的自我监督学习潜力，我们采用了歧视性与自我蒸馏以及掩码图像建模的方法，并将我们的模型构建在3D水平而不是切片级别（2D），以更全面和有效地利用头颅CT扫描的结构。通过内部及三个外部数据集对模型的下游分类性能进行了评估，包括分布内（ID）和分布外（OOD）的数据。结果显示，自我监督基础模型相比从零开始训练的模型以及基于稀缺标注数据集的3D CT基础模型在下游诊断任务中的表现有显著提升。这项工作突出了自监督学习在医学成像中的有效性，并为头颅CT图像分析设立了一个新的基准，使人工智能在基于头部CT的诊断中得到更广泛的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Head computed tomography (CT) imaging is a widely-used imaging modality withmultitudes of medical indications, particularly in assessing pathology of thebrain, skull, and cerebrovascular system. It is commonly the first-line imagingin neurologic emergencies given its rapidity of image acquisition, safety,cost, and ubiquity. Deep learning models may facilitate detection of a widerange of diseases. However, the scarcity of high-quality labels andannotations, particularly among less common conditions, significantly hindersthe development of powerful models. To address this challenge, we introduceFM-CT: a Foundation Model for Head CT for generalizable disease detection,trained using self-supervised learning. Our approach pre-trains a deep learningmodel on a large, diverse dataset of 361,663 non-contrast 3D head CT scanswithout the need for manual annotations, enabling the model to learn robust,generalizable features. To investigate the potential of self-supervisedlearning in head CT, we employed both discrimination with self-distillation andmasked image modeling, and we construct our model in 3D rather than at theslice level (2D) to exploit the structure of head CT scans more comprehensivelyand efficiently. The model's downstream classification performance is evaluatedusing internal and three external datasets, encompassing both in-distribution(ID) and out-of-distribution (OOD) data. Our results demonstrate that theself-supervised foundation model significantly improves performance ondownstream diagnostic tasks compared to models trained from scratch andprevious 3D CT foundation models on scarce annotated datasets. This workhighlights the effectiveness of self-supervised learning in medical imaging andsets a new benchmark for head CT image analysis in 3D, enabling broader use ofartificial intelligence for head CT-based diagnosis.</description>
      <author>example@mail.com (Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell, Seena Dehkharghani, Jennifer A. Frontera, Arjun V. Masurkar, Kara Melmed, Narges Razavian)</author>
      <guid isPermaLink="false">2502.02779v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Vision Transformer for Object Centric Foundation Models</title>
      <link>http://arxiv.org/abs/2502.02763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新颖的FLIP（Fovea-Like Input Patching）对象聚焦编码技术，该技术在图像分割任务中实现了高效的计算和较高的精度。&lt;h4&gt;背景&lt;/h4&gt;现有的最先进的目标分割机制如SAM和FastSAM通过多层处理整个图像后针对特定物体生成掩膜。这些方法存在计算效率低的问题，特别是在高分辨率场景中小物体的分割上表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种更高效的数据编码方式FLIP，旨在改善小物体在高分辨率视觉场景中的分割精度，同时减少计算量。&lt;h4&gt;方法&lt;/h4&gt;FLIP通过选择性输入图像并从一开始就在对象中心的方式进行编码，将位置编码与以对象为中心的感知代码分开处理。此外，还引入了一个半自然但高度直观的数据集用于评估。&lt;h4&gt;主要发现&lt;/h4&gt;在标准基准测试（如Hypersim、KITTI-360和OpenImages）上，FLIP在计算资源较少的情况下达到了接近SAM的表现，并且在所有IoU度量中都超过了FastSAM。特别是在小目标的分割任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;作为端到端的对象中心分割方法，FLIP对于需要高效、高选择性对象跟踪的应用具有很高的潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近最先进的物体分割机制（如Segment Anything Model (SAM)和FastSAM）首先对整个图像进行多层编码，然后专注于生成特定物体或区域的掩码。我们提出了一种无网格Fovea-Like Input Patching (FLIP)方法，该方法选择性地输入图像并从一开始就以对象为中心的方式进行编码。在此过程中，它将位置编码与对象中心感知代码分开处理。FLIP在高分辨率视觉场景中小物体的掩码生成中更为高效，并提高了分割性能。在Hypersim、KITTI-360和OpenImages等标准基准上，FLIP实现了接近SAM表现但需要较少计算资源的交并比（IoU）分数，在所有IoU测量值中都超过了FastSAM。此外，我们还引入了一个半自然但高度直观的数据集，其中FLIP整体上以及在相对较小的对象分割任务中优于SAM和FastSAM。鉴于FLIP是一种端到端的对象中心分割方法，它特别适用于需要计算效率高、空间选择性高的对象跟踪的应用程序。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent state-of-the-art object segmentation mechanisms, such as the SegmentAnything Model (SAM) and FastSAM, first encode the full image over severallayers and then focus on generating the mask for one particular object or area.We present an off-grid Fovea-Like Input Patching (FLIP) approach, which selectsimage input and encodes it from the beginning in an object-focused manner.While doing so, it separates locational encoding from an object-centricperceptual code. FLIP is more data-efficient and yields improved segmentationperformance when masking relatively small objects in high-resolution visualscenes. On standard benchmarks such as Hypersim, KITTI-360, and OpenImages,FLIP achieves Intersection over Union (IoU) scores that approach theperformance of SAM with much less compute effort. It surpasses FastSAM in allIoU measurements. We also introduce an additional semi-natural but highlyintuitive dataset where FLIP outperforms SAM and FastSAM overall andparticularly on relatively small objects. Seeing that FLIP is an end-to-endobject-centric segmentation approach, it has high potential particularly forapplications that benefit from computationally efficient, spatially highlyselective object tracking.</description>
      <author>example@mail.com (Manuel Traub, Martin V. Butz)</author>
      <guid isPermaLink="false">2502.02763v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>RFMedSAM 2: Automatic Prompt Refinement for Enhanced Volumetric Medical Image Segmentation with SAM 2</title>
      <link>http://arxiv.org/abs/2502.02741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于Segment Anything Model 2（SAM 2）的医学图像分割改进方法，通过定制化的微调适配器和自动提示生成机制提升模型性能。&lt;h4&gt;背景&lt;/h4&gt;SAM 2在零样本条件下表现优异，并且在医疗影像领域具有巨大潜力。但是存在输出二值掩码、无法推断语义标签以及依赖精确提示的限制。&lt;h4&gt;目的&lt;/h4&gt;通过定制化微调适配器探索SAM 2在医学图像分割中的上界性能，减轻对精确提示的依赖性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种UNet用于自动产生预测掩模和边界框作为输入给SAM 2，并结合双阶段优化进一步提升模型效果。同时利用BTCV数据集进行微调训练，验证改进方案的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;在AMOS2022数据集上Dice相似度系数（DSC）相较于nnUNet提升了2.9%，而在BTCV数据集中则领先6.4%的性能提升。这些结果表明所提出的方法达到了当前最优水平。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种有效的方式以改进SAM 2在医学图像分割中的表现，进一步扩大了其应用范围和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segment Anything Model 2 (SAM 2), a prompt-driven foundation model extendingSAM to both image and video domains, has shown superior zero-shot performancecompared to its predecessor. Building on SAM's success in medical imagesegmentation, SAM 2 presents significant potential for further advancement.However, similar to SAM, SAM 2 is limited by its output of binary masks,inability to infer semantic labels, and dependence on precise prompts for thetarget object area. Additionally, direct application of SAM and SAM 2 tomedical image segmentation tasks yields suboptimal results. In this paper, weexplore the upper performance limit of SAM 2 using custom fine-tuning adapters,achieving a Dice Similarity Coefficient (DSC) of 92.30% on the BTCV dataset,surpassing the state-of-the-art nnUNet by 12%. Following this, we address theprompt dependency by investigating various prompt generators. We introduce aUNet to autonomously generate predicted masks and bounding boxes, which serveas input to SAM 2. Subsequent dual-stage refinements by SAM 2 further enhanceperformance. Extensive experiments show that our method achievesstate-of-the-art results on the AMOS2022 dataset, with a Dice improvement of2.9% compared to nnUNet, and outperforms nnUNet by 6.4% on the BTCV dataset.</description>
      <author>example@mail.com (Bin Xie, Hao Tang, Yan Yan, Gady Agam)</author>
      <guid isPermaLink="false">2502.02741v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Astromer 2</title>
      <link>http://arxiv.org/abs/2502.02717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 17 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Astromer 2，这是一种专门用于从光曲线中提取嵌入的基础模型。相较于其前身Astromer 1，该论文详细地探讨了它的预训练嵌入的优越性，并通过一系列实验展示了它在分类任务中的卓越性能。&lt;h4&gt;背景&lt;/h4&gt;基础模型已经成为深度学习领域的一个强大范式，能够利用大规模数据集来学习稳健的表示并向多种下游应用提供有效支持。&lt;h4&gt;目的&lt;/h4&gt;介绍并评估Astromer 2，一种专门用于光曲线分析的基础模型，并比较其与前代模型（Astromer 1）在性能上的差异和改进。&lt;h4&gt;方法&lt;/h4&gt;使用来自MACHO调查的单波段光曲线的大规模数据集对Astromer 2进行预训练。通过预测随机遮罩序列中的观测值，完成了自监督学习任务。然后，在较小的标记数据集上微调模型，并根据MLP分类器在F1分数上的表现评估其嵌入质量。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的模型相比，Astromer 2在所有评估场景中都表现出显著优越性，尤其是在样本量较少的数据集中性能尤其出色。使用加权的每样本嵌入特别有效，这集成了注意力块中的中间表示。&lt;h4&gt;结论&lt;/h4&gt;通过展示Astromer 2在ATLAS数据集上相对于先前模型15%的F1分数改进，论文强调了其对新数据集的强大泛化能力，并突出了在标记数据有限的情况下进行更高效和可扩展光曲线分析的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;基础模型已经成为深度学习领域的一个强大范式，能够利用大规模数据集来学习稳健的表示并向多种下游应用提供有效支持。本文介绍了Astromer 2，这是一种专门用于从光曲线中提取嵌入的基础模型。相较于其前身Astromer 1，该论文详细地探讨了它的预训练嵌入的优越性，并通过一系列实验展示了它在分类任务中的卓越性能。使用来自MACHO调查的单波段光曲线的大规模数据集对Astromer 2进行预训练。通过预测随机遮罩序列中的观测值，完成了自监督学习任务。然后，在较小的标记数据集上微调模型，并根据MLP分类器在F1分数上的表现评估其嵌入质量。结果表明，与之前的模型相比，Astromer 2在所有评估场景中都表现出显著优越性，尤其是在样本量较少的数据集中性能尤其出色。使用加权的每样本嵌入特别有效，这集成了注意力块中的中间表示。通过展示Astromer 2在ATLAS数据集上相对于先前模型15%的F1分数改进，论文强调了其对新数据集的强大泛化能力，并突出了在标记数据有限的情况下进行更高效和可扩展光曲线分析的巨大潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundational models have emerged as a powerful paradigm in deep learningfield, leveraging their capacity to learn robust representations fromlarge-scale datasets and effectively to diverse downstream applications such asclassification. In this paper, we present Astromer 2 a foundational modelspecifically designed for extracting light curve embeddings. We introduceAstromer 2 as an enhanced iteration of our self-supervised model for lightcurve analysis. This paper highlights the advantages of its pre-trainedembeddings, compares its performance with that of its predecessor, Astromer 1,and provides a detailed empirical analysis of its capabilities, offering deeperinsights into the model's representations. Astromer 2 is pretrained on 1.5million single-band light curves from the MACHO survey using a self-supervisedlearning task that predicts randomly masked observations within sequences.Fine-tuning on a smaller labeled dataset allows us to assess its performance inclassification tasks. The quality of the embeddings is measured by the F1 scoreof an MLP classifier trained on Astromer-generated embeddings. Our resultsdemonstrate that Astromer 2 significantly outperforms Astromer 1 across allevaluated scenarios, including limited datasets of 20, 100, and 500 samples perclass. The use of weighted per-sample embeddings, which integrate intermediaterepresentations from Astromer's attention blocks, is particularly impactful.Notably, Astromer 2 achieves a 15% improvement in F1 score on the ATLAS datasetcompared to prior models, showcasing robust generalization to new datasets.This enhanced performance, especially with minimal labeled data, underscoresthe potential of Astromer 2 for more efficient and scalable light curveanalysis.</description>
      <author>example@mail.com (Cristobal Donoso-Oliva, Ignacio Becker, Pavlos Protopapas, Guillermo Cabrera-Vives, Martina Cádiz-Leyton, Daniel Moreno-Cartagena)</author>
      <guid isPermaLink="false">2502.02717v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Calibrating Wireless AI via Meta-Learned Context-Dependent Conformal Prediction</title>
      <link>http://arxiv.org/abs/2501.14566v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的校准方法，用于解决软件定义网络（如Open RAN系统）中的人工智能应用在部署前的校准问题。&lt;h4&gt;背景&lt;/h4&gt;现代软件定义网络依赖于运行在网络控制器上的AI应用程序，这些控制器与无线接入网接口。为了确保这些AI应用能够可靠地运行，在部署之前必须进行适当的校准。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法来解决由于不同上下文导致的校准和运行时分布不匹配的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于元学习的方法，称为元学习上下文依赖加权置信预测（ML-WCP），该方法仅使用上下文信息就可以估计分布偏移，并能有效地对AI应用进行校准。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的ML-WCP方法可以在不获取当前环境数据的情况下有效校准AI模型，同时还能结合多个不同上下文的数据进一步提升校准的可靠性。&lt;h4&gt;结论&lt;/h4&gt;通过利用元学习技术发展出的新方法可以解决现有软件定义网络中的校准问题，并为未来研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern software-defined networks, such as Open Radio Access Network (O-RAN)systems, rely on artificial intelligence (AI)-powered applications running oncontrollers interfaced with the radio access network. To ensure that these AIapplications operate reliably at runtime, they must be properly calibratedbefore deployment. A promising and theoretically grounded approach tocalibration is conformal prediction (CP), which enhances any AI model bytransforming it into a provably reliable set predictor that provides error barsfor estimates and decisions. CP requires calibration data that matches thedistribution of the environment encountered during runtime. However, inpractical scenarios, network controllers often have access only to datacollected under different contexts -- such as varying traffic patterns andnetwork conditions -- leading to a mismatch between the calibration and runtimedistributions. This paper introduces a novel methodology to address thiscalibration-test distribution shift. The approach leverages meta-learning todevelop a zero-shot estimator of distribution shifts, relying solely oncontextual information. The proposed method, called meta-learnedcontext-dependent weighted conformal prediction (ML-WCP), enables effectivecalibration of AI applications without requiring data from the current context.Additionally, it can incorporate data from multiple contexts to further enhancecalibration reliability.</description>
      <author>example@mail.com (Seonghoon Yoo, Sangwoo Park, Petar Popovski, Joonhyuk Kang, Osvaldo Simeone)</author>
      <guid isPermaLink="false">2501.14566v3</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>IPO: Iterative Preference Optimization for Text-to-Video Generation</title>
      <link>http://arxiv.org/abs/2502.02088v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;视频基础模型在性能上有显著提升，但生成的视频质量仍不能满足应用需求。为解决此问题，提出了一种迭代偏好优化(IPO)策略，通过引入批评者模型将人类反馈纳入训练过程，从而提高生成视频的质量。&lt;h4&gt;背景&lt;/h4&gt;随着网络升级和模型规模扩大，视频基础模型在性能上取得了显著进步，但生成的视频质量仍然不尽如人意，无法满足应用需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够优化视频基础模型生成质量的方法，使得生成的视频在主观一致性、运动平滑度和美学质量等方面得到改善。&lt;h4&gt;方法&lt;/h4&gt;提出了迭代偏好优化(IPO)策略。IPO利用批评者模型对生成的视频进行成对排名或点状评分，并据此调整视频基础模型，以提高其生成的质量。&lt;h4&gt;主要发现&lt;/h4&gt;1. IPO能有效提升预训练模型的视频生成质量；2. 小规模参数模型（仅含20亿参数）通过IPO优化可以超过大规模模型（50亿参数）；3. IPO在VBench基准测试中达到了新的最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的迭代偏好优化(IPO)策略能够有效地提高视频基础模型的生成质量，并且这种方法可以通过自动分配偏好标签来避免繁琐的手动标注过程，从而实现多轮优化。&lt;h4&gt;翻译&lt;/h4&gt;视频基础模型通过网络升级和规模扩大在性能方面取得了显著进展。然而，由于生成的质量不尽如人意，它们仍然难以满足应用需求。为了克服这一问题，在本文中我们提出了一种迭代偏好优化(IPO)策略，它从后训练的角度将视频基础模型与人类偏好对齐。IPO利用批评者模型根据直接偏好优化或卡恩曼-特维斯基优化来为生成的视频进行成对排名或点状评分，并据此调整视频基础模型。通过引入多模态大语言模型，批评者模型能够自动分配偏好标签而无需重新训练或重标记。因此，IPO可以在不进行繁琐的手动标注的情况下，在迭代方式下高效地执行多轮优化。综合实验表明，所提出的IPO可以有效提高预训练模型的视频生成质量，并且可以使仅含20亿参数的小型模型超越含50亿参数的大规模模型。此外，IPO在VBench基准测试中达到了新的最先进的性能。我们将开源代码、模型和数据集以促进未来的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video foundation models have achieved significant advancement with the helpof network upgrade as well as model scale-up. However, they are still hard tomeet requirements of applications due to unsatisfied generation quality. Tosolve this problem, we propose to align video foundation models with humanpreferences from the perspective of post-training in this paper. Consequently,we introduce an Iterative Preference Optimization strategy to enhance generatedvideo quality by incorporating human feedback. Specifically, IPO exploits acritic model to justify video generations for pairwise ranking as in DirectPreference Optimization or point-wise scoring as in Kahneman-TverskyOptimization. Given this, IPO optimizes video foundation models with guidanceof signals from preference feedback, which helps improve generated videoquality in subject consistency, motion smoothness and aesthetic quality, etc.In addition, IPO incorporates the critic model with the multi-modality largelanguage model, which enables it to automatically assign preference labelswithout need of retraining or relabeling. In this way, IPO can efficientlyperform multi-round preference optimization in an iterative manner, without theneed of tediously manual labeling. Comprehensive experiments demonstrate thatthe proposed IPO can effectively improve the video generation quality of apretrained model and help a model with only 2B parameters surpass the one with5B parameters. Besides, IPO achieves new state-of-the-art performance on VBenchbenchmark. We will release our source codes, models as well as dataset toadvance future research and applications.</description>
      <author>example@mail.com (Xiaomeng Yang, Zhiyu Tan, Xuecheng Nie, Hao Li)</author>
      <guid isPermaLink="false">2502.02088v2</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Kineto-Dynamical Planning and Accurate Execution of Minimum-Time Maneuvers on Three-Dimensional Circuits</title>
      <link>http://arxiv.org/abs/2502.03454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper will be presented at the 2025 IEEE International  Conference on Robotics &amp; Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为ARD的人工赛车手系统，用于学习车辆动力学，并在三维赛道上执行最短时间行驶策略。&lt;h4&gt;背景&lt;/h4&gt;在线规划和执行自动驾驶车辆比赛中的最短时间内操作是当前面临的一项挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够实现最短时间赛跑的自主赛车解决方案。&lt;h4&gt;方法&lt;/h4&gt;ARD系统结合了新型动动力学模型（KD）用于轨迹规划以及经济非线性预测控制（E-NMPC）。使用高保真车辆模拟器来比较闭环下的ARD结果与最小圈速优化控制问题的结果。&lt;h4&gt;主要发现&lt;/h4&gt;ARD设置的圈速接近于离线解决相同问题得到的最佳方案，同时新的KD模型也超过了文献中的基准表现。&lt;h4&gt;结论&lt;/h4&gt;研究了在执行错误下重新规划能力，视频补充材料提供了主要成果。&lt;h4&gt;翻译&lt;/h4&gt;在线规划和执行三维赛道上的最短时间行驶策略是自主车辆赛车领域的一个开放性挑战。本文提出了一个称为人工比赛驾驶员(ARD)的系统来学习车辆动态，并进行轨迹规划以及执行最短时间内行驶的操作。ARD结合了新的动动力学(KD)模型，用于路径规划与经济非线性预测控制(E-NMPC)。使用高保真度车辆模拟器将闭环下的ARD结果与离线计算的最佳方案进行了比较。结果显示，ARD设置的圈速接近于最佳方案的结果，并且新型KD模型的表现优于文献中的基准模型。此外，该研究还分析了在执行错误情况下的路径重规划能力。主要成果可通过补充视频材料查看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Online planning and execution of minimum-time maneuvers on three-dimensional(3D) circuits is an open challenge in autonomous vehicle racing. In this paper,we present an artificial race driver (ARD) to learn the vehicle dynamics, planand execute minimum-time maneuvers on a 3D track. ARD integrates a novelkineto-dynamical (KD) vehicle model for trajectory planning with economicnonlinear model predictive control (E-NMPC). We use a high-fidelity vehiclesimulator (VS) to compare the closed-loop ARD results with a minimum-lap-timeoptimal control problem (MLT-VS), solved offline with the same VS. Our ARD setslap times close to the MLT-VS, and the new KD model outperforms a literaturebenchmark. Finally, we study the vehicle trajectories, to assess there-planning capabilities of ARD under execution errors. A video with the mainresults is available as supplementary material.</description>
      <author>example@mail.com (Mattia Piccinini, Sebastiano Taddei, Johannes Betz, Francesco Biral)</author>
      <guid isPermaLink="false">2502.03454v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)</title>
      <link>http://arxiv.org/abs/2502.03450v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了SG-RwR框架，用于在场景图上进行基于大型语言模型的推理和规划。&lt;h4&gt;背景&lt;/h4&gt;场景图作为一种结构化的环境表示方法，在与大语言模型结合后的空间推理领域中越来越受到重视。现有的研究大多利用完整的场景图数据来指导推理过程。&lt;h4&gt;目的&lt;/h4&gt;提出一个Schema-Guided Retrieve-while-Reason框架，用于基于场景图的推理和规划任务，并减少输入令牌的数量以限制幻觉发生。&lt;h4&gt;方法&lt;/h4&gt;两个协同工作的代码编写语言模型代理：一个是生成任务计划和信息查询的推断器，另一个是根据方案理解程序化地查询场景图数据的检索器。这两个代理按照一个迭代过程进行合作，实现序列推理并动态关注图的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过多种模拟环境中的实验显示，该框架在数值问答和规划任务上超越了现有基于大语言模型的方法，并且可以在缺乏代理级演示的情况下受益于任务级别的少量示例。&lt;h4&gt;结论&lt;/h4&gt;论文提出的方法展示了在结构化数据推理领域的优越性，并为未来的研究提供了新的思路。项目代码将被发布以供进一步探索。&lt;h4&gt;翻译&lt;/h4&gt;场景图作为一种结构化的环境表示方法，在与大型语言模型结合后的空间推理领域中越来越受到重视。本文提出了SG-RwR框架，这是一个基于方案引导的Retrieve-while-Reason架构，用于在场景图上进行推理和规划任务。该方法使用两个协同工作的代码编写大语言模型代理：一个是生成任务计划和信息查询的推断器；另一个是根据提出的查询从场景图中提取相关信息的检索器。这两个代理通过迭代协作实现了序列推理，并能够动态地关注到整个图形，增强推理与检索之间的对齐效果。实验结果显示，在多种模拟环境中，该框架在数值问答和规划任务方面优于现有基于大语言模型的方法，并且可以利用任务级别的少量示例来改进性能，即使没有提供代理级的演示实例也不例外。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene graphs have emerged as a structured and serializable environmentrepresentation for grounded spatial reasoning with Large Language Models(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reasonframework for reasoning and planning with scene graphs. Our approach employstwo cooperative, code-writing LLM agents: a (1) Reasoner for task planning andinformation queries generation, and a (2) Retriever for extractingcorresponding graph information following the queries. Two agents collaborateiteratively, enabling sequential reasoning and adaptive attention to graphinformation. Unlike prior works, both agents are prompted only with the scenegraph schema rather than the full graph data, which reduces the hallucinationby limiting input tokens, and drives the Reasoner to generate reasoning traceabstractly.Following the trace, the Retriever programmatically query the scenegraph data based on the schema understanding, allowing dynamic and globalattention on the graph that enhances alignment between reasoning and retrieval.Through experiments in multiple simulation environments, we show that ourframework surpasses existing LLM-based approaches in numerical Q\&amp;A andplanning tasks, and can benefit from task-level few-shot examples, even in theabsence of agent-level demonstrations. Project code will be released.</description>
      <author>example@mail.com (Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell)</author>
      <guid isPermaLink="false">2502.03450v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Intelligent Sensing-to-Action for Robust Autonomy at the Edge: Opportunities and Challenges</title>
      <link>http://arxiv.org/abs/2502.02692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了自主边缘计算在机器人、智慧城市和自动驾驶汽车中的应用，重点在于传感到动作循环及其面临的挑战和解决方案。&lt;h4&gt;背景&lt;/h4&gt;自主边缘计算依赖于感知、处理与执行的无缝集成以实现在动态环境下的实时决策。核心是传感到动作循环，该循环通过迭代地将传感器输入与计算模型对齐来驱动适应性控制策略。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过主动和上下文感知的传感到动作及动作到传感调整提高效率，并通过多代理传感-动作环路优化资源使用。&lt;h4&gt;方法&lt;/h4&gt;提出动态调节感知和计算的方法，根据任务需求仅感测环境的一部分并预测其余部分。同时强调了神经形态计算在边缘自主性中的作用及其如何支持多代理协同。&lt;h4&gt;主要发现&lt;/h4&gt;神经形态计算提供了基于脉冲驱动处理的有效框架，能够节省能源、减少延迟和支持层次化控制，是多代理优化的理想选择。&lt;h4&gt;结论&lt;/h4&gt;文章指出，端到端共设计策略对于实现能效边缘自主性至关重要。这些策略通过将算法模型与硬件和环境动态对齐来改善跨层相互依赖关系，从而提高吞吐量、精度和适应能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容描述了自主边缘计算在机器人技术、智慧城市及自动驾驶汽车等领域的应用，并讨论了传感到动作循环的挑战及其解决方案。文章强调通过上下文感知调整传感器输入与控制行动之间的动态关联可以提升效率，同时介绍了神经形态计算作为一种节省能源和减少延迟的有效方式来支持多代理优化策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous edge computing in robotics, smart cities, and autonomous vehiclesrelies on the seamless integration of sensing, processing, and actuation forreal-time decision-making in dynamic environments. At its core is thesensing-to-action loop, which iteratively aligns sensor inputs withcomputational models to drive adaptive control strategies. These loops canadapt to hyper-local conditions, enhancing resource efficiency andresponsiveness, but also face challenges such as resource constraints,synchronization delays in multi-modal data fusion, and the risk of cascadingerrors in feedback loops. This article explores how proactive, context-awaresensing-to-action and action-to-sensing adaptations can enhance efficiency bydynamically adjusting sensing and computation based on task demands, such assensing a very limited part of the environment and predicting the rest. Byguiding sensing through control actions, action-to-sensing pathways can improvetask relevance and resource use, but they also require robust monitoring toprevent cascading errors and maintain reliability. Multi-agent sensing-actionloops further extend these capabilities through coordinated sensing and actionsacross distributed agents, optimizing resource use via collaboration.Additionally, neuromorphic computing, inspired by biological systems, providesan efficient framework for spike-based, event-driven processing that conservesenergy, reduces latency, and supports hierarchical control--making it ideal formulti-agent optimization. This article highlights the importance of end-to-endco-design strategies that align algorithmic models with hardware andenvironmental dynamics and improve cross-layer interdependencies to improvethroughput, precision, and adaptability for energy-efficient edge autonomy incomplex environments.</description>
      <author>example@mail.com (Amit Ranjan Trivedi, Sina Tayebati, Hemant Kumawat, Nastaran Darabi, Divake Kumar, Adarsh Kumar Kosta, Yeshwanth Venkatesha, Dinithi Jayasuriya, Nethmi Jayasinghe, Priyadarshini Panda, Saibal Mukhopadhyay, Kaushik Roy)</author>
      <guid isPermaLink="false">2502.02692v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Active Human Involvement through Proxy Value Propagation</title>
      <link>http://arxiv.org/abs/2502.03369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2023 Spotlight. Project page:  https://metadriverse.github.io/pvp&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的奖励无关的主动人类参与方法——代理价值传播，用于策略优化。&lt;h4&gt;背景&lt;/h4&gt;通过积极的人类干预和示范，在AI训练过程中可以带来安全性和与人类目标的一致性。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够表达人类意图的代理价值函数，并将其应用于策略优化中。&lt;h4&gt;方法&lt;/h4&gt;使用TD学习框架将人类演示中的状态-动作对进行高值标签化，而被干预的动作则标记为低值。通过这种方式，可以将这些标记后的值传播到其他未标记的数据上，从而促进更接近于人类行为的策略生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在解决连续和离散控制任务方面具有通用性和效率，并且能够使用各种人类控制设备完成任务，包括《侠盗猎车手V》中的驾驶挑战。&lt;h4&gt;结论&lt;/h4&gt;通过最小化对现有强化学习算法的修改，可以有效地解决问题，这证明了所提出的方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;从积极的人类参与中学习使人类主体能够主动干预并在训练过程中向AI代理展示。这种互动和纠正反馈为学习过程带来了安全性和与人类目标的一致性。在这项工作中，我们提出了一个新的奖励无关的主动人类参与方法——代理价值传播用于策略优化。我们的关键见解是可以通过设计一个表示人类意图的代理值函数来实现这一点，在这个函数中，通过人类演示的状态-动作对被赋予了高值标签，而那些受到干预的行为则获得了低值标签。通过TD学习框架，标记后的状态-动作对的价值进一步传播到从代理探索生成的数据上。因此，代理价值函数诱导出一种忠实模仿人类行为的策略。人类参与的实验展示了我们方法的通用性和效率。只需对现有强化学习算法进行最小修改，我们的方法就可以学习解决包括《侠盗猎车手V》中的驾驶挑战在内的各种连续和离散控制任务。演示视频和代码可在此处获得：https://metadriverse.github.io/pvp&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from active human involvement enables the human subject to activelyintervene and demonstrate to the AI agent during training. The interaction andcorrective feedback from human brings safety and AI alignment to the learningprocess. In this work, we propose a new reward-free active human involvementmethod called Proxy Value Propagation for policy optimization. Our key insightis that a proxy value function can be designed to express human intents,wherein state-action pairs in the human demonstration are labeled with highvalues, while those agents' actions that are intervened receive low values.Through the TD-learning framework, labeled values of demonstrated state-actionpairs are further propagated to other unlabeled data generated from agents'exploration. The proxy value function thus induces a policy that faithfullyemulates human behaviors. Human-in-the-loop experiments show the generality andefficiency of our method. With minimal modification to existing reinforcementlearning algorithms, our method can learn to solve continuous and discretecontrol tasks with various human control devices, including the challengingtask of driving in Grand Theft Auto V. Demo video and code are available at:https://metadriverse.github.io/pvp</description>
      <author>example@mail.com (Zhenghao Peng, Wenjie Mo, Chenda Duan, Quanyi Li, Bolei Zhou)</author>
      <guid isPermaLink="false">2502.03369v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>SiLVR: Scalable Lidar-Visual Radiance Field Reconstruction with Uncertainty Quantification</title>
      <link>http://arxiv.org/abs/2502.02657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  webpage: https://dynamic.robots.ox.ac.uk/projects/silvr/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于神经辐射场（NeRF）的大规模重建系统，通过融合激光雷达和视觉数据来生成高质量的、几何准确且具有逼真纹理的重建。&lt;h4&gt;背景&lt;/h4&gt;当前技术在处理大规模场景时面临挑战，特别是在捕捉几何精确度及真实感纹理方面。传统方法可能无法有效结合这两种传感器类型的数据，难以实现高效的几何约束与纹理细节相结合。&lt;h4&gt;目的&lt;/h4&gt;开发一个融合激光雷达和视觉数据的大规模三维重建系统，该系统采用NeRF表示法来提高重建质量和准确性。&lt;h4&gt;方法&lt;/h4&gt;[{'关键技术': '将NeRF表示引入到大规模场景的三维重建中，并结合使用激光雷达数据以增强几何约束。'}, {'不确定性估计': '利用相机和激光雷达传感器观测值，评估重建过程中的知识不确定性和空间变化性，从而识别各模态下可靠地重建区域并据此优化地图精度。'}, {'实时定位与建图（SLAM）技术': '运用实时姿态图激光SLAM系统生成的轨迹引导后处理结构从运动(SfM)重建过程，并大幅减少训练时间，提高全局尺度约束的有效性。'}, {'光谱聚类算法': '通过将全局一致性的轨迹划分成子地图来优化视觉重构方法，这种方法更适合于基于可见度的图像分组。每个子地图根据点不确定性进行过滤并合并以获得最终的大规模3D重建结果。'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'增强几何约束': '激光雷达数据增强了深度和表面法线的几何约束，特别是在处理具有模糊视觉重构线索的均匀纹理表面时更为关键。'}, {'提高建图效率': '利用实时SLAM系统生成的数据轨迹可以显著减少SfM训练时间，同时确保整体度量尺度的正确性对于激光雷达深度损失至关重要。'}]&lt;h4&gt;结论&lt;/h4&gt;通过实验展示该方法在处理大规模场景中的有效性和优越性，在涉及机器人固定和手持扫描设备的情况下均进行了测试，并涵盖了超过20,000平方米的不同复杂建筑环境。&lt;h4&gt;翻译&lt;/h4&gt;论文提出了基于NeRF的大型规模重建系统，利用激光雷达与视觉数据融合生成高质量且几何准确、具有逼真纹理的重建效果。该方法通过引入NeRF表示并结合激光雷达增强几何约束，并使用不确定性估计优化地图精度和传感器可靠性识别；同时采用实时SLAM轨迹引导后处理SfM过程以提高效率和度量尺度准确性，利用光谱聚类划分子地图来提升视觉重构结果的适用性。实验显示该方法在各种复杂环境下的表现优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a neural radiance field (NeRF) based large-scale reconstructionsystem that fuses lidar and vision data to generate high-qualityreconstructions that are geometrically accurate and capture photorealistictexture. Our system adopts the state-of-the-art NeRF representation toadditionally incorporate lidar. Adding lidar data adds strong geometricconstraints on the depth and surface normals, which is particularly useful whenmodelling uniform texture surfaces which contain ambiguous visualreconstruction cues. Furthermore, we estimate the epistemic uncertainty of thereconstruction as the spatial variance of each point location in the radiancefield given the sensor observations from camera and lidar. This enables theidentification of areas that are reliably reconstructed by each sensormodality, allowing the map to be filtered according to the estimateduncertainty. Our system can also exploit the trajectory produced by a real-timepose-graph lidar SLAM system during online mapping to bootstrap a(post-processed) Structure-from-Motion (SfM) reconstruction procedure reducingSfM training time by up to 70%. It also helps to properly constrain the overallmetric scale which is essential for the lidar depth loss. Theglobally-consistent trajectory can then be divided into submaps using SpectralClustering to group sets of co-visible images together. This submappingapproach is more suitable for visual reconstruction than distance-basedpartitioning. Each submap is filtered according to point-wise uncertaintyestimates and merged to obtain the final large-scale 3D reconstruction. Wedemonstrate the reconstruction system using a multi-camera, lidar sensor suitein experiments involving both robot-mounted and handheld scanning. Our testdatasets cover a total area of more than 20,000 square metres, includingmultiple university buildings and an aerial survey of a multi-storey.</description>
      <author>example@mail.com (Yifu Tao, Maurice Fallon)</author>
      <guid isPermaLink="false">2502.02657v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Inverse Mixed Strategy Games with Generative Trajectory Models</title>
      <link>http://arxiv.org/abs/2502.03356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. 8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种逆向游戏方法，结合生成式轨迹模型和可微混合策略博弈框架，以解决现有逆向博弈方法在处理行为不确定性及测量噪声时的局限性。&lt;h4&gt;背景&lt;/h4&gt;博弈论模型是建模多智能体交互的有效工具，尤其是在机器人需要与人类协调的情况下。然而，在实际应用中，从观察到的行为推断这些模型的具体参数（即逆向游戏问题）是一项极具挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的逆向博弈方法以改进现有方法对行为不确定性和测量噪声的处理能力，并在仿真导航基准测试中进行验证。&lt;h4&gt;方法&lt;/h4&gt;该研究结合了生成式轨迹模型和可微混合策略博弈框架，使用条件变分自动编码器（CVAE）来表示混合策略。这种方法能够从含噪测量中推断出高维、多模态的行为分布，并能实时适应新观测结果。&lt;h4&gt;主要发现&lt;/h4&gt;通过在具有未知游戏模型生成的观察数据的模拟导航基准测试中的表现，该方法即使在不确定代理目标和噪声测量的情况下也能推断出与真实模型和最优逆向博弈基线相比可比拟的纳什最优行动。&lt;h4&gt;结论&lt;/h4&gt;新提出的逆向博弈方法能够有效解决行为不确定性及测量噪声的问题，并在仿真环境中表现出色，证明了其潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Game-theoretic models are effective tools for modeling multi-agentinteractions, especially when robots need to coordinate with humans. However,applying these models requires inferring their specifications from observedbehaviors -- a challenging task known as the inverse game problem. Existinginverse game approaches often struggle to account for behavioral uncertaintyand measurement noise, and leverage both offline and online data. To addressthese limitations, we propose an inverse game method that integrates agenerative trajectory model into a differentiable mixed-strategy gameframework. By representing the mixed strategy with a conditional variationalautoencoder (CVAE), our method can infer high-dimensional, multi-modal behaviordistributions from noisy measurements while adapting in real-time to newobservations. We extensively evaluate our method in a simulated navigationbenchmark, where the observations are generated by an unknown game model.Despite the model mismatch, our method can infer Nash-optimal actionscomparable to those of the ground-truth model and the oracle inverse gamebaseline, even in the presence of uncertain agent objectives and noisymeasurements.</description>
      <author>example@mail.com (Max Muchen Sun, Pete Trautman, Todd Murphey)</author>
      <guid isPermaLink="false">2502.03356v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>AIoT-based smart traffic management system</title>
      <link>http://arxiv.org/abs/2502.02821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于AI的智能交通管理系统，旨在通过分析现有CCTV摄像头的实时视频来优化城市中的交通流量并减少拥堵。&lt;h4&gt;背景&lt;/h4&gt;当前的城市交通系统面临交通拥堵和效率低下的问题，需要更先进的解决方案来应对。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够优化交通流量、减少城市环境中的交通拥堵，并且部署成本低廉的智能交通管理系统。&lt;h4&gt;方法&lt;/h4&gt;利用AI模型处理实时视频流，准确计算车辆数量并评估交通密度。通过这种方式实现适应性信号控制，优先考虑车流量较大的方向。&lt;h4&gt;主要发现&lt;/h4&gt;在使用PyGame进行的各种交通条件下的模拟测试中，该基于AI的系统比传统的静态红绿灯系统性能高出34%，显著提高了交通流畅度和效率。&lt;h4&gt;结论&lt;/h4&gt;利用AI优化交通信号可以成为解决城市交通挑战的关键方法，并且为现代城市的智能基础设施提供了成本效益高、可扩展性强和高效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces an AI-based smart traffic management system designed to optimize traffic flow and reduce congestion in urban environments by analyzing live footage from existing CCTV cameras. Utilizing an AI model to process real-time video feeds, it accurately counts vehicles and assesses traffic density for adaptive signal control prioritizing busier directions. Simulations using PyGame show that the AI-based system outperforms traditional static systems by 34%, significantly improving traffic flow efficiency. Leveraging AI for optimizing traffic signals plays a critical role in addressing urban traffic challenges with cost-effective, scalable, and efficient solutions for modern cities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel AI-based smart traffic management systemde-signed to optimize traffic flow and reduce congestion in urban environments.By analysing live footage from existing CCTV cameras, this approach eliminatesthe need for additional hardware, thereby minimizing both deployment costs andongoing maintenance expenses. The AI model processes live video feeds toaccurately count vehicles and assess traffic density, allowing for adaptivesignal control that prioritizes directions with higher traffic volumes. Thisreal-time adaptability ensures smoother traffic flow, reduces congestion, andminimizes waiting times for drivers. Additionally, the proposed system issimulated using PyGame to evaluate its performance under various trafficconditions. The simulation results demonstrate that the AI-based systemout-performs traditional static traffic light systems by 34%, leading tosignificant improvements in traffic flow efficiency. The use of AI to optimizetraffic signals can play a crucial role in addressing urban traffic challenges,offering a cost-effective, scalable, and efficient solution for modern cities.This innovative system represents a key advancement in the field of smart cityinfra-structure and intelligent transportation systems.</description>
      <author>example@mail.com (Ahmed Mahmoud Elbasha, Mohammad M. Abdellatif)</author>
      <guid isPermaLink="false">2502.02821v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Robust Autonomy Emerges from Self-Play</title>
      <link>http://arxiv.org/abs/2502.03349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了一种全新的策略，即通过大规模模拟中的自我对弈（self-play）来生成稳健且自然的自动驾驶系统。这种方法使得在仿真环境中累积了相当于16亿公里驾驶距离的数据量，实现了前所未有的训练规模。&lt;h4&gt;背景&lt;/h4&gt;自博弈技术已经在两人或多人游戏中取得了突破性进展，如AlphaGo等。然而，这种策略能否应用于其他领域还有待研究和验证。&lt;h4&gt;目的&lt;/h4&gt;探索自我对弈在自动驾驶领域的应用潜力，并评估其相对于现有方法的性能优势。&lt;h4&gt;方法&lt;/h4&gt;利用名为Gigaflow的大规模批处理模拟器进行训练，在单个8-GPU节点上每小时可以合成并训练相当于42年人类驾驶经验的数据。通过这种大规模训练，开发出了能够在三项独立自动驾驶基准测试中达到最佳表现的策略模型。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的自我对弈方法能够生成性能卓越、自然且稳健的自动驾驶策略，在真实世界记录场景和混合交通环境中表现出色，无需使用任何人类数据进行训练即可实现这一点。此外，该策略在仿真环境中的连续无故障驾驶时间平均可达17.5年。&lt;h4&gt;结论&lt;/h4&gt;证明了自我对弈可以有效应用于自动驾驶领域，并且可以通过大规模模拟来显著提高车辆的性能和鲁棒性，同时保持自然行为。&lt;h4&gt;翻译&lt;/h4&gt;摘要中描述的研究成果表明，在不使用任何人类数据的情况下，通过在仿真环境中进行大规模自我博弈训练，可以获得高性能、稳健且自然的自动驾驶策略。这些策略不仅能在独立基准测试中取得领先地位，而且还能在复杂的真实驾驶场景下表现出色，具备长期无故障运行的能力（模拟环境中17.5年）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-play has powered breakthroughs in two-player and multi-player games.Here we show that self-play is a surprisingly effective strategy in anotherdomain. We show that robust and naturalistic driving emerges entirely fromself-play in simulation at unprecedented scale -- 1.6~billion~km of driving.This is enabled by Gigaflow, a batched simulator that can synthesize and trainon 42 years of subjective driving experience per hour on a single 8-GPU node.The resulting policy achieves state-of-the-art performance on three independentautonomous driving benchmarks. The policy outperforms the prior state of theart when tested on recorded real-world scenarios, amidst human drivers, withoutever seeing human data during training. The policy is realistic when assessedagainst human references and achieves unprecedented robustness, averaging 17.5years of continuous driving between incidents in simulation.</description>
      <author>example@mail.com (Marco Cusumano-Towner, David Hafner, Alex Hertzberg, Brody Huval, Aleksei Petrenko, Eugene Vinitsky, Erik Wijmans, Taylor Killian, Stuart Bowers, Ozan Sener, Philipp Krähenbühl, Vladlen Koltun)</author>
      <guid isPermaLink="false">2502.03349v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Implicit Communication in Human-Robot Collaborative Transport</title>
      <link>http://arxiv.org/abs/2502.03346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Accepted to HRI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文关注人类与机器人协作搬运，即机器人和用户共同将一个物体移动到目标位置。在没有显式通信的情况下，这种合作具有挑战性，因为它需要两个异质代理之间紧密的隐式协调。&lt;h4&gt;背景&lt;/h4&gt;研究团队注意到，当存在明确交流时，在机器人和人类之间的合作会面临困难，因为它们有不同的感知、行动和推理能力。&lt;h4&gt;目的&lt;/h4&gt;论文旨在设计一种机制来解决这种协作搬运问题，并通过引入概率模型来改善双方的合作效率。&lt;h4&gt;方法&lt;/h4&gt;研究人员构建了一种基于观察双方执行的联合动作的概率映射推断机制。他们定义了一个表示人类对于正在展开的路径策略不确定性的成本函数，该成本被纳入了预测控制器中以平衡不确定性最小化和效率最大化之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在没有沟通机制的情况下，团队的表现不如拥有这种机制的框架。后者使机器人被认为是一个更流畅、更有能力的合作伙伴。&lt;h4&gt;结论&lt;/h4&gt;本研究证明通过嵌入微妙、沟通信号到双方执行的动作中来改善人机合作搬运的有效性。该方法可以提高人类对机器人的信任度，并能显著提升团队整体表现。&lt;h4&gt;翻译&lt;/h4&gt;我们专注于人机协作运输问题，在这种情况下，机器人和用户共同将一个物体移动至目标位置。在没有明确交流的情况下，这个问题具有挑战性，因为它需要两个异质代理之间的紧密隐式协调。我们的主要见解是通过为所搬运的物件编码微妙、通信信号的动作来促进双方的合作流畅性。为此，我们设计了一种概率推理机制，用于将观察到的两方执行的联合动作映射至工作空间遍历的一系列联合策略上。基于此机制，我们定义了表示人类不确定性的一个成本函数，并将其纳入模型预测控制器中以平衡不确定性和效率之间的关系。我们在移动机械手（Hello Robot Stretch）上部署了该框架，并通过一项主体内部实验室研究（N=24）评估其效果。结果显示，我们的框架能够提高团队表现，并使机器人被感知为一个更流畅、更有能力的合作伙伴相比缺乏沟通机制的基线方案而言具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We focus on human-robot collaborative transport, in which a robot and a usercollaboratively move an object to a goal pose. In the absence of explicitcommunication, this problem is challenging because it demands tight implicitcoordination between two heterogeneous agents, who have very different sensing,actuation, and reasoning capabilities. Our key insight is that the two agentscan coordinate fluently by encoding subtle, communicative signals into actionsthat affect the state of the transported object. To this end, we design aninference mechanism that probabilistically maps observations of joint actionsexecuted by the two agents to a set of joint strategies of workspace traversal.Based on this mechanism, we define a cost representing the human's uncertaintyover the unfolding traversal strategy and introduce it into a model predictivecontroller that balances between uncertainty minimization and efficiencymaximization. We deploy our framework on a mobile manipulator (Hello RobotStretch) and evaluate it in a within-subjects lab study (N=24). We show thatour framework enables greater team performance and empowers the robot to beperceived as a significantly more fluent and competent partner compared tobaselines lacking a communicative mechanism.</description>
      <author>example@mail.com (Elvin Yang, Christoforos Mavrogiannis)</author>
      <guid isPermaLink="false">2502.03346v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Contact-Aware Motion Planning Among Movable Objects</title>
      <link>http://arxiv.org/abs/2502.03317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新型接触感知的机器人运动规划方法CAMP，该方法解决了现有移动机器人路径规划中仅关注碰撞避免而忽视了接触必要性的局限性。&lt;h4&gt;背景&lt;/h4&gt;大多数现有的移动机器人路径规划方法旨在生成不发生碰撞的轨迹，这限制了机器人的行动，并不能适用于必须或有意进行物理接触的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的接触感知运动规划（CAMP）范式来克服现有技术的问题，使机器人能够在涉及不可回避和必要接触任务中有效工作。&lt;h4&gt;方法&lt;/h4&gt;该方法在基于优化的轨迹规划中将机器人与可移动物体之间的接触作为互补性约束，并利用增广拉格朗日方法（ALMs）高效求解包含互补性约束的优化问题，从而生成机器人的时空最优轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟实验表明，在导航和重新排列可移动物体等基本任务中，提出的CAMP方法相较于现有最佳技术显著扩大了机器人可达的空间，并提高了成功率。实际应用证明所提出的方法在多种任务中的可行性及快速部署能力。&lt;h4&gt;结论&lt;/h4&gt;该研究成功开发了一种能够处理接触情况的运动规划新范式，展示了其在扩展移动机器人的操作范围和提升任务完成效率方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已全部转化为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing methods for motion planning of mobile robots involve generatingcollision-free trajectories. However, these methods focusing solely on contactavoidance may limit the robots' locomotion and can not be applied to taskswhere contact is inevitable or intentional. To address these issues, we proposea novel contact-aware motion planning (CAMP) paradigm for robotic systems. Ourapproach incorporates contact between robots and movable objects ascomplementarity constraints in optimization-based trajectory planning. Byleveraging augmented Lagrangian methods (ALMs), we efficiently solve theoptimization problem with complementarity constraints, producingspatial-temporal optimal trajectories of the robots. Simulations demonstratethat, compared to the state-of-the-art method, our proposed CAMP method expandsthe reachable space of mobile robots, resulting in a significant improvement inthe success rate of two types of fundamental tasks: navigation among movableobjects (NAMO) and rearrangement of movable objects (RAMO). Real-worldexperiments show that the trajectories generated by our proposed method arefeasible and quickly deployed in different tasks.</description>
      <author>example@mail.com (Haokun Wang, Qianhao Wang, Fei Gao, Shaojie Shen)</author>
      <guid isPermaLink="false">2502.03317v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Prediction by Simulation for Automated Driving</title>
      <link>http://arxiv.org/abs/2502.03286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at "16. Uni-DAS e.V. Workshop  Fahrerassistenz und automatisiertes Fahren". Link:  https://www.uni-das.de/fas-workshop/2025.html&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模块化自动驾驶系统通常将预测和规划视为独立的任务，从而无法支持协作行为。&lt;h4&gt;目的&lt;/h4&gt;为了实现协同规划，引入了一种基于条件依赖关系建模轨迹间关联的新预测模型。&lt;h4&gt;方法&lt;/h4&gt;{'1': '使用微观交通仿真生成预测数据。', '2': '个体交通参与者的操作由通过对抗逆向强化学习训练的现实行为模型控制。', '3': '为自动驾驶车辆假设多种候选轨迹，根据每个候选轨迹进行条件化预测。', '4': '在预测阶段允许候选轨迹动态调整。', '5': '提供多个示例场景以展示方法的有效性。'}&lt;h4&gt;主要发现&lt;/h4&gt;新的预测模型能够更好地支持自动化驾驶系统中的协作行为。&lt;h4&gt;结论&lt;/h4&gt;通过引入基于仿真和对抗逆向强化学习的条件化预测，可以有效实现自动驾驶车辆间的协同规划。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：模块化的自动驱动系统通常将预测与计划处理为独立的任务，这阻碍了合作行动的发生。为了支持合作规划，这项工作介绍了一种预测模型，该模型通过模拟交通中的个体行为之间的条件依赖关系来生成预测。这些预测是基于微观交通仿真完成的，并且每个交通参与者的行为模式都是使用对抗逆向强化学习训练出来的。为了测试这种新方法的效果，为自动车辆假设了多种可能轨迹并根据每一条轨迹进行条件化预测；同时，在整个预测过程中允许候选轨迹动态调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modular automated driving systems commonly handle prediction and planning assequential, separate tasks, thereby prohibiting cooperative maneuvers. Toenable cooperative planning, this work introduces a prediction model thatmodels the conditional dependencies between trajectories. For this, predictionsare generated by a microscopic traffic simulation, with the individual trafficparticipants being controlled by a realistic behavior model trained viaAdversarial Inverse Reinforcement Learning. By assuming various candidatetrajectories for the automated vehicle, we generate predictions conditioned oneach of them. Furthermore, our approach allows the candidate trajectories toadapt dynamically during the prediction rollout. Several example scenarios areavailable at https://conditionalpredictionbysimulation.github.io/.</description>
      <author>example@mail.com (Fabian Konstantinidis, Moritz Sackmann, Ulrich Hofmann, Christoph Stiller)</author>
      <guid isPermaLink="false">2502.03286v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Fault-Tolerant Control for System Availability and Continuous Operation in Heavy-Duty Wheeled Mobile Robots</title>
      <link>http://arxiv.org/abs/2502.03278v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is under review by IEEE/ASME Transactions on Mechatronics  (TMECH)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对液压驱动重型轮式移动机器人（HD-WMR）的无模型分层故障容错控制框架，以提高其在传感器和执行器发生故障时的安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;当重型轮式移动机器人的控制系统出现故障时，会导致运动偏差，增加越野不稳定风险并可能造成重大损失。因此，控制系统需要有一定的容错能力来保证连续运行。&lt;h4&gt;目的&lt;/h4&gt;为了满足安全、可靠性和可控制性的需求，在HD-WMR中引入了一种无模型分层故障容错控制框架（MFHCA），以应对传感器和执行器的故障。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种新的数学表示法，用于描述带独立控制轮子的液压驱动重型轮式移动机器人的运动动力学，并考虑了传感器和执行器的各种故障模式。2. 设计了一个无模型分层故障容错控制框架（MFHCA），以在各种故障模式下管理所有车轮，确保每个车轮都能跟踪参考驱动力速度和转向角度。通过逆向几何映射获得这些值，并生成适当的功率努力来适应隔离的故障。&lt;h4&gt;主要发现&lt;/h4&gt;实验分析证明了该无模型分层故障容错控制框架（MFHCA）在6500公斤液压驱动重型轮式移动机器人中的有效性，尤其是在各种故障模式和恶劣地形条件下。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效提高HD-WMR的故障容忍能力，确保其在复杂的环境中可靠运行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When the control system in a heavy-duty wheeled mobile robot (HD-WMR)malfunctions, deviations from ideal motion occur, significantly heightening therisks of off-road instability and costly damage. To meet the demands forsafety, reliability, and controllability in HD-WMRs, the control system musttolerate faults to a certain extent, ensuring continuous operation. To thisend, this paper introduces a model-free hierarchical control with faultaccommodation (MFHCA) framework designed to address sensor and actuator faultsin hydraulically powered HD-WMRs with independently controlled wheels. Tobegin, a novel mathematical representation of the motion dynamics of HD-WMRs,incorporating both sensor and actuator fault modes, is investigated.Subsequently, the MFHCA framework is proposed to manage all wheels undervarious fault modes, ensuring that each wheel tracks the reference drivingvelocities and steering angles, which are inverse kinematically mapped from theangular and linear velocities commanded in the HD-WMR's base frame. To do so,this framework generates appropriate power efforts in independentlyvalve-regulated wheels to accommodate the adaptively isolated faults, therebyensuring exponential stability. The experimental analysis of a 6,500-kghydraulic-powered HD-WMR under various fault modes and rough terrainsdemonstrates the validity of the MFHCA framework.</description>
      <author>example@mail.com (Mehdi Heydari Shahna, Pauli Mustalahti, Jouni Mattila)</author>
      <guid isPermaLink="false">2502.03278v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning</title>
      <link>http://arxiv.org/abs/2502.03270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;预训练视觉表示（PVR）在视动机器人学习中的应用带来了希望，但其在策略学习中面临挑战，如时间纠缠和对场景变化的不鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;利用预训练视觉表示（PVRs）进行视动机器人的学习已经成为了一个有前景的方法，然而，这些模型在策略学习中遇到诸如时间纠缠以及面对小范围环境扰动时无法泛化的问题。&lt;h4&gt;目的&lt;/h4&gt;该研究旨在识别并解决PVR应用于机器人政策学习中的不足。&lt;h4&gt;方法&lt;/h4&gt;提出两种解决方案：一是通过增加时间感知能力和任务完成感来解耦PVR特征；二是引入一个模块，学会选择性地关注任务相关的局部特性，以提高在不同场景下的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在使用掩码目标训练的PVR中性能有了显著改进，并且这些增强措施有效地解决了针对PVR特有局限性的挑战。&lt;h4&gt;结论&lt;/h4&gt;通过结合时间感知和选择性注意机制来解决视觉预训练模型在机器人政策学习中的问题，可以极大地提高其性能。&lt;h4&gt;翻译&lt;/h4&gt;将预训练的视觉表示（PVR）集成到视动机器人的学习中已成为一个令人兴奋的替代方案。然而，在策略学习背景下，这些模型面临着重大的挑战，包括时间纠缠和即使面对轻微场景变化也无法泛化的问题。这些问题阻碍了它们在需要对时间和环境变化具有感知能力的任务中的表现。该研究识别了这些不足，并提出了相应的解决方案来解决它们。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of pre-trained visual representations (PVRs) into visuo-motorrobot learning has emerged as a promising alternative to training visualencoders from scratch. However, PVRs face critical challenges in the context ofpolicy learning, including temporal entanglement and an inability to generaliseeven in the presence of minor scene perturbations. These limitations hinderperformance in tasks requiring temporal awareness and robustness to scenechanges. This work identifies these shortcomings and proposes solutions toaddress them. First, we augment PVR features with temporal perception and asense of task completion, effectively disentangling them in time. Second, weintroduce a module that learns to selectively attend to task-relevant localfeatures, enhancing robustness when evaluated on out-of-distribution scenes.Our experiments demonstrate significant performance improvements, particularlyin PVRs trained with masking objectives, and validate the effectiveness of ourenhancements in addressing PVR-specific limitations.</description>
      <author>example@mail.com (Nikolaos Tsagkas, Andreas Sochopoulos, Duolikun Danier, Chris Xiaoxuan Lu, Oisin Mac Aodha)</author>
      <guid isPermaLink="false">2502.03270v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>JAMMit! Monolithic 3D-Printing of a Bead Jamming Soft Pneumatic Arm</title>
      <link>http://arxiv.org/abs/2502.03232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 8 figures, accepted by the 8th IEEE-RAS International  Conference on Soft Robotics, RoboSoft 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种集成有碗状珠子的肌腱驱动中央脊柱的单件打印技术，用于制造软气动臂。通过实验研究了在未锁合和锁合状态下的活动范围，并且探讨了其刚度特性。&lt;h4&gt;背景&lt;/h4&gt;3D打印的柔韧型气动机械臂因其设计灵活、制作简单及变形能力大而被广泛应用。然而，它们较低的刚性限制了实际应用。现有的增强软致动器刚性的方法往往需要复杂的制造过程，这与现代单件和自动化增材制造的目标不符。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用珠子锁合（bead-jamming）简单有效的解决方案来提高3D打印气动臂的刚性，并保持设计灵活性。通过实验研究探讨在不同条件下该机械臂的活动范围及其刚度特性，为实际应用提供最佳策略。&lt;h4&gt;方法&lt;/h4&gt;将碗状珠子集成到单件制造的软气动臂中，形成肌腱驱动中央脊柱；然后测试未锁合和锁合状态下的机械臂活动性能，并进行一系列实验来确定最优的锁合策略。&lt;h4&gt;主要发现&lt;/h4&gt;研究了机械臂在不同条件下的刚度特性以及如何通过锁合珠子来优化其运动范围与刚性之间的平衡，进而提出了一种有效的锁合策略。&lt;h4&gt;结论&lt;/h4&gt;该设计展示出了潜在的实际应用价值，特别是在开关切换任务中的表现。这种方法为未来软气动机器人的发展提供了新的思路和可能性。&lt;h4&gt;翻译&lt;/h4&gt;3D打印的柔韧型气动机械臂因其灵活的设计、易于制造以及巨大的变形能力而被广泛采用。然而，它们较低的刚性限制了实际应用。虽然存在几种增强软致动器刚性的方法，但许多方法涉及复杂的制造过程，这与现代单件和自动化增材制造的目标不符。由于其简便性，珠子锁合代表了一种简单有效的解决方案来应对这些挑战。这项工作介绍了一种单件打印柔性气动臂的方法，并集成了肌腱驱动的碗形珠中央脊柱。我们通过实验对该机械臂在未锁合和锁合状态下的运动范围以及各种致动和锁合条件下的刚度进行了表征。结果，我们提供了一个最优锁合策略作为保持运动范围与最大化刚性之间的权衡。提出的这种设计在一个开关切换任务中进一步得到了展示，表明了其潜在的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D-printed bellow soft pneumatic arms are widely adopted for their flexibledesign, ease of fabrication, and large deformation capabilities. However, theirlow stiffness limits their real-world applications. Although several methodsexist to enhance the stiffness of soft actuators, many involve complexmanufacturing processes not in line with modern goals of monolithic andautomated additive manufacturing. With its simplicity, bead-jamming representsa simple and effective solution to these challenges. This work introduces amethod for monolithic printing of a bellow soft pneumatic arm, integrating atendon-driven central spine of bowl-shaped beads. We experimentallycharacterized the arm's range of motion in both unjammed and jammed states, aswell as its stiffness under various actuation and jamming conditions. As aresult, we provide an optimal jamming policy as a trade-off between preservingthe range of motion and maximizing stiffness. The proposed design was furtherdemonstrated in a switch-toggling task, showing its potential for practicalapplications.</description>
      <author>example@mail.com (Yao Yao, Maximilian Westermann, Marco Pontin, Alessandro Albini, Perla Maiolino)</author>
      <guid isPermaLink="false">2502.03232v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>GARAD-SLAM: 3D GAussian splatting for Real-time Anti Dynamic SLAM</title>
      <link>http://arxiv.org/abs/2502.03228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为GARAD-SLAM的实时3DGS（三维高斯点阵）基于SLAM系统，专为动态场景设计。该方法通过改进跟踪和映射步骤解决了现有3DGS SLAM系统在处理动态对象时出现的地图错误及追踪漂移问题。&lt;h4&gt;背景&lt;/h4&gt;现有的3D Gaussian Splatting (3DGS) 基于的SLAM系统因其实时光线追踪高质量渲染而在研究界受到广泛关注。然而，在包含动态物体的真实环境里，这些系统常常遇到地图构建误差和跟踪漂移的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种针对具有动态场景的应用程序更加高效的实时3DGS SLAM系统，以解决现有系统面对动态对象时的难题。&lt;h4&gt;方法&lt;/h4&gt;在追踪方面，该研究直接对高斯点进行动态分割，并通过Gaussian Pyramid网络将结果反馈到前端获取动态标签，实现精确的动态点去除和稳健跟踪。对于地图构建部分，研究人员对被标记为动态的高斯分布施加渲染惩罚，在更新时避免了由于简单的修剪而导致不可逆的错误删除。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明GARAD-SLAM与基线方法相比在追踪方面更具竞争力，并且在生成图像的过程中产生较少的伪影，重建质量更高。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法解决了现有3DGS SLAM系统处理动态场景时存在的问题，在保证实时性的同时提高了映射精度和跟踪稳定性。&lt;h4&gt;翻译&lt;/h4&gt;The 3D Gaussian Splatting (3DGS) based SLAM system has gained significant attention due to its excellent performance in real-time high-fidelity rendering. However, existing systems encounter mapping errors and tracking drift issues when dealing with dynamic objects in the real world. To address these challenges, we introduce GARAD-SLAM: a real-time 3DGS-based SLAM system specifically tailored for dynamic scenes. This innovative approach enhances tracking by directly segmenting dynamics on Gaussians and feeding back this information to the front-end through Gaussian Pyramid networks to achieve accurate dynamic removal and robust tracking. For mapping, it imposes rendering penalties on dynamically labeled Gaussians updated via network interaction, thereby preventing irreversible erroneous removal caused merely by pruning. Our experimental results show that our method outperforms baseline approaches in terms of tracking accuracy, producing fewer artifacts and higher-quality reconstructions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The 3D Gaussian Splatting (3DGS)-based SLAM system has garnered widespreadattention due to its excellent performance in real-time high-fidelityrendering. However, in real-world environments with dynamic objects, existing3DGS-based SLAM systems often face mapping errors and tracking drift issues. Toaddress these problems, we propose GARAD-SLAM, a real-time 3DGS-based SLAMsystem tailored for dynamic scenes. In terms of tracking, unlike traditionalmethods, we directly perform dynamic segmentation on Gaussians and map themback to the front-end to obtain dynamic point labels through a Gaussian pyramidnetwork, achieving precise dynamic removal and robust tracking. For mapping, weimpose rendering penalties on dynamically labeled Gaussians, which are updatedthrough the network, to avoid irreversible erroneous removal caused by simplepruning. Our results on real-world datasets demonstrate that our method iscompetitive in tracking compared to baseline methods, generating fewerartifacts and higher-quality reconstructions in rendering.</description>
      <author>example@mail.com (Mingrui Li, Weijian Chen, Na Cheng, Jingyuan Xu, Dong Li, Hongyu Wang)</author>
      <guid isPermaLink="false">2502.03228v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>A Unified and General Humanoid Whole-Body Controller for Fine-Grained Locomotion</title>
      <link>http://arxiv.org/abs/2502.03206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contribute equally. Project page:  https://hugwbc.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了HUGWBC，一个统一且通用的人形机器人全身控制器，用于精细的移动控制。&lt;h4&gt;背景&lt;/h4&gt;当前大多数研究将人形机器人的运动视为单一、乏味和不可扩展的任务。相比之下，人类拥有广泛的体能能力，如跑步、跳跃和调整步行参数等。&lt;h4&gt;目的&lt;/h4&gt;探索如何使人形机器人具备类似的多功能性，并设计一个能够支持各种自然步态的全身控制器。&lt;h4&gt;方法&lt;/h4&gt;通过在任务和行为方面设计通用命令空间以及使用对称损失和干预训练等高级技术，在模拟环境中学习人形机器人的控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;HUGWBC能够在单一策略下实现步行（包括跑步）、跳跃、站立和单脚跳，支持自定义频率、足部摆动高度及身体高度、腰旋转和身体倾斜的组合。&lt;h4&gt;结论&lt;/h4&gt;实验验证了HUGWBC在有或没有上身干预的情况下对所有命令具有高跟踪准确性和鲁棒性，并提供了深入分析各种命令如何影响人形机器人运动以及这些命令之间的关系。HUGWBC是第一个支持高度稳健且灵活的精细移动行为的人形全身控制器。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了一个名为HUGWBC的新系统，它使人形机器人能够执行复杂和多样的步态动作，并且在任何类型的行动中都可以与外部控制结合使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Locomotion is a fundamental skill for humanoid robots. However, most existingworks made locomotion a single, tedious, unextendable, and passive movement.This limits the kinematic capabilities of humanoid robots. In contrast, humanspossess versatile athletic abilities-running, jumping, hopping, and finelyadjusting walking parameters such as frequency, and foot height. In this paper,we investigate solutions to bring such versatility into humanoid locomotion andthereby propose HUGWBC: a unified and general humanoid whole-body controllerfor fine-grained locomotion. By designing a general command space in the aspectof tasks and behaviors, along with advanced techniques like symmetrical lossand intervention training for learning a whole-body humanoid controlling policyin simulation, HugWBC enables real-world humanoid robots to produce variousnatural gaits, including walking (running), jumping, standing, and hopping,with customizable parameters such as frequency, foot swing height, furthercombined with different body height, waist rotation, and body pitch, all in onesingle policy. Beyond locomotion, HUGWBC also supports real-time interventionsfrom external upper-body controllers like teleoperation, enablingloco-manipulation while maintaining precise control under any locomotivebehavior. Our experiments validate the high tracking accuracy and robustness ofHUGWBC with/without upper-body intervention for all commands, and we furtherprovide an in-depth analysis of how the various commands affect humanoidmovement and offer insights into the relationships between these commands. Toour knowledge, HugWBC is the first humanoid whole-body controller that supportssuch fine-grained locomotion behaviors with high robustness and flexibility.</description>
      <author>example@mail.com (Yufei Xue, Wentao Dong, Minghuan Liu, Weinan Zhang, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2502.03206v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Underwater Soft Fin Flapping Motion with Deep Neural Network Based Surrogate Model</title>
      <link>http://arxiv.org/abs/2502.03135v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE International Conference on Soft Robotics 2025  (Robosoft)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的框架，通过结合基于深度神经网络（DNN）的替代模型和强化学习（RL），实现了由鳍驱动的水下机器人进行精确力控制。&lt;h4&gt;背景&lt;/h4&gt;解决与水下环境复杂的相互作用问题，并且实验成本高昂，提出了使用DNN替代模型作为模拟器的方法，以提高RL代理人的训练效率。&lt;h4&gt;目的&lt;/h4&gt;通过应用网格切换控制选择特定推力参考范围下的优化模型，提升控制精度和稳定性。&lt;h4&gt;方法&lt;/h4&gt;利用基于深度神经网络的替代模型来模拟复杂环境，进行高效的强化学习代理训练，并在实际软鳍驱动器上验证控制效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在DNN仿真环境中训练出来的RL代理人能够生成复杂的推力运动，并对真实软鳍执行器实现了精确控制。&lt;h4&gt;结论&lt;/h4&gt;该方法为解决挑战性的水下环境中的鳍驱动机器人提供了高效的控制解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本研究提出了一种新颖的框架，用于通过结合基于深度神经网络（DNN）的替代模型与强化学习（RL），实现由鳍驱动的水下机器人的精确力控制。为解决复杂水下环境中的相互作用以及高昂的实验成本问题，使用DNN替代模型作为模拟器来提高RL代理人的训练效率。另外，应用网格切换控制选择特定推力参考范围下的优化模型，提升了控制精度和稳定性。实验结果表明，在替代仿真中经过训练的RL代理人能够生成复杂的推力运动，并实现了对真实软鳍执行器的精确控制。本方法为挑战性的水下环境中鳍驱动机器人提供了一种有效的控制解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents a novel framework for precise force control offin-actuated underwater robots by integrating a deep neural network (DNN)-basedsurrogate model with reinforcement learning (RL). To address the complexinteractions with the underwater environment and the high experimental costs, aDNN surrogate model acts as a simulator for enabling efficient training for theRL agent. Additionally, grid-switching control is applied to select optimizedmodels for specific force reference ranges, improving control accuracy andstability. Experimental results show that the RL agent, trained in thesurrogate simulation, generates complex thrust motions and achieves precisecontrol of a real soft fin actuator. This approach provides an efficientcontrol solution for fin-actuated robots in challenging underwaterenvironments.</description>
      <author>example@mail.com (Yuya Hamamatsu, Pavlo Kupyn, Roza Gkliva, Asko Ristolainen, Maarja Kruusmaa)</author>
      <guid isPermaLink="false">2502.03135v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>SPARK: A Modular Benchmark for Humanoid Robot Safety</title>
      <link>http://arxiv.org/abs/2502.03132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Safe Protective and Assistive Robot Kit (SPARK)，一个旨在确保人形机器人自主性和远程操作安全性的全面基准。&lt;h4&gt;背景&lt;/h4&gt;人形机器人由于其复杂的物理结构和与复杂环境互动的能力，存在显著的安全风险。设计通用的安全解决方案因此变得非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了促进复杂机器人系统的安全部署，SPARK被开发为一个工具箱，包含最先进的安全控制算法，并提供模块化可组合的机器人控制系统框架。&lt;h4&gt;方法&lt;/h4&gt;SPARK可以方便地配置安全性标准和敏感度级别以优化安全性和性能之间的平衡。它还提供了模拟基准来比较不同环境、任务和机器人模型的安全策略，同时支持快速在真实机器上部署合成的安全控制器。&lt;h4&gt;主要发现&lt;/h4&gt;SPARK使用了Apple Vision Pro (AVP)或运动捕捉系统作为外部传感器，并为其他硬件设置提供了无缝集成的接口。&lt;h4&gt;结论&lt;/h4&gt;通过模拟实验和与Unitree G1人形机器人相关的案例研究，证明了SPARK的能力。利用SPARK的优势，用户和研究人员可以显著提高其人形系统的安全性并加速相关研究。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一个名为Safe Protective and Assistive Robot Kit (SPARK)的工具箱，旨在确保人形机器人的安全性和性能。它提供了一套最先进的安全控制算法，并允许根据具体需求进行配置。此外，它还支持模拟环境下的实验以及真实硬件上的部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the Safe Protective and Assistive Robot Kit (SPARK), acomprehensive benchmark designed to ensure safety in humanoid autonomy andteleoperation. Humanoid robots pose significant safety risks due to theirphysical capabilities of interacting with complex environments. The physicalstructures of humanoid robots further add complexity to the design of generalsafety solutions. To facilitate the safe deployment of complex robot systems,SPARK can be used as a toolbox that comes with state-of-the-art safe controlalgorithms in a modular and composable robot control framework. Users caneasily configure safety criteria and sensitivity levels to optimize the balancebetween safety and performance. To accelerate humanoid safety research anddevelopment, SPARK provides a simulation benchmark that compares safetyapproaches in a variety of environments, tasks, and robot models. Furthermore,SPARK allows quick deployment of synthesized safe controllers on real robots.For hardware deployment, SPARK supports Apple Vision Pro (AVP) or a MotionCapture System as external sensors, while also offering interfaces for seamlessintegration with alternative hardware setups. This paper demonstrates SPARK'scapability with both simulation experiments and case studies with a Unitree G1humanoid robot. Leveraging these advantages of SPARK, users and researchers cansignificantly improve the safety of their humanoid systems as well asaccelerate relevant research. The open-source code is available athttps://github.com/intelligent-control-lab/spark.</description>
      <author>example@mail.com (Yifan Sun, Rui Chen, Kai S. Yun, Yikuan Fang, Sebin Jung, Feihan Li, Bowei Li, Weiye Zhao, Changliu Liu)</author>
      <guid isPermaLink="false">2502.03132v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>HiLo: Learning Whole-Body Human-like Locomotion with Motion Tracking Controller</title>
      <link>http://arxiv.org/abs/2502.03122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架HiLo，该框架结合了强化学习与运动追踪技术来实现类人行走行为，并通过实验展示了其在真实世界环境中的稳定性和灵活性。&lt;h4&gt;背景&lt;/h4&gt;深度强化学习（RL）已被证明是开发人形机器人步行控制器的有效方法。虽然之前的RL控制器已经展示出稳健和稳定的步行能力，但它们的行为往往缺乏人类情景中所需的自然与敏捷的运动模式。&lt;h4&gt;目的&lt;/h4&gt;提出HiLo框架，旨在通过学习类人的行走策略来克服复杂奖励工程和领域随机化的挑战，并提高人形机器人在真实世界中的表现。&lt;h4&gt;方法&lt;/h4&gt;HiLo框架包括开发基于RL的运动追踪控制器和简单的领域随机化技术。问题被分解为两部分：一部分使用开环控制方法解决，另一部分则通过RL策略处理。另外还实施了分布价值函数来改善受扰动动力学下的累积奖励估计。&lt;h4&gt;主要发现&lt;/h4&gt;训练出的运动跟踪控制器能够执行自然且敏捷的人类行走模式，并在面对外部干扰时表现出强大的适应能力。此外，残差机制允许任务需求快速调整而无需微调。&lt;h4&gt;结论&lt;/h4&gt;HiLo框架通过结合RL和开环控制方法以及引入分布价值函数解决了现有RL控制器的一些局限性，从而能够更好地实现人形机器人的真实场景适应性和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;深度强化学习（RL）已经成为开发类人行走控制器的一种有前景的方法。尽管以前的RL控制器已经展示了稳健且稳定的步行行为，但它们的行为往往缺乏在人类中心情景下所需的自然和敏捷的动作模式。在这个工作中，我们提出了HiLo框架（具有运动追踪的人形机器人类似行走），这是一种有效的学习RL策略以执行类似人的行走方式的设计方法。类人行走的主要挑战是复杂的奖励工程和领域随机化问题。通过基于RL的运动追踪控制器和简单域随机化的开发，HiLo可以解决这些问题，后者包括通过力注入和动作延迟进行随机处理。在HiLo框架内，全身控制问题可被分解为两部分：一部分使用开环控制方法来解决，而剩余的部分则用RL策略来应对。为了改进扰动动力学下累积奖励的估计并稳定训练过程，还实现了分布价值函数。我们的实验表明，在现实系统中，使用HiLo框架训练出的运动追踪控制器能够进行自然且敏捷的人形行走，并显示出对外部干扰的强大抵抗力。此外，我们展示了通过残差机制可以对人形机器人的动作模式进行适应性调整而无需进一步微调，从而快速响应任务需求变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Reinforcement Learning (RL) has emerged as a promising method to develophumanoid robot locomotion controllers. Despite the robust and stable locomotiondemonstrated by previous RL controllers, their behavior often lacks the naturaland agile motion patterns necessary for human-centric scenarios. In this work,we propose HiLo (human-like locomotion with motion tracking), an effectiveframework designed to learn RL policies that perform human-like locomotion. Theprimary challenges of human-like locomotion are complex reward engineering anddomain randomization. HiLo overcomes these issues by developing an RL-basedmotion tracking controller and simple domain randomization through random forceinjection and action delay. Within the framework of HiLo, the whole-bodycontrol problem can be decomposed into two components: One part is solved usingan open-loop control method, while the residual part is addressed with RLpolicies. A distributional value function is also implemented to stabilize thetraining process by improving the estimation of cumulative rewards underperturbed dynamics. Our experiments demonstrate that the motion trackingcontroller trained using HiLo can perform natural and agile human-likelocomotion while exhibiting resilience to external disturbances in real-worldsystems. Furthermore, we show that the motion patterns of humanoid robots canbe adapted through the residual mechanism without fine-tuning, allowing quickadjustments to task requirements.</description>
      <author>example@mail.com (Qiyuan Zhang, Chenfan Weng, Guanwu Li, Fulai He, Yusheng Cai)</author>
      <guid isPermaLink="false">2502.03122v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>RoboGrasp: A Universal Grasping Policy for Robust Robotic Control</title>
      <link>http://arxiv.org/abs/2502.03072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为RoboGrasp的通用抓取策略框架，该框架集成了预训练的抓取检测模型和机器人学习方法，旨在提高机器人的抓取精度、稳定性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;模仿学习和世界模型在推进通用化的机器人学习方面显示出显著潜力，但精确的手部操作仍然是一个关键挑战。现有的方法依赖于机器人手臂状态数据和RGB图像，导致对特定物体形状或位置的过度拟合。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法中存在的限制问题，提出一种能够提升抓取精度、稳定性和泛化能力的方法框架。&lt;h4&gt;方法&lt;/h4&gt;RoboGrasp利用基于扩散的方法构建，通过将预训练的抓取检测模型与机器人学习相结合，并借助物体检测和分割任务中的稳健视觉指导来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;RoboGrasp在少样本学习和抓取框提示任务中实现了高达34%的成功率提高。&lt;h4&gt;结论&lt;/h4&gt;该框架适用于多种机器人学习范式，能够在不同复杂场景下实现精确且可靠的操作，是解决现实世界中机器人抓取挑战的可扩展和灵活解决方案。&lt;h4&gt;翻译&lt;/h4&gt;模仿学习和世界模型在推进通用化的机器人学习方面显示出了显著潜力。然而，机器人抓取仍然是一项关键挑战，需要达到更高的精确度。现有的方法通常严重依赖于机械臂的状态数据和RGB图像，导致过度拟合特定物体的形状或位置。为了解决这些问题，我们提出了RoboGrasp框架，该框架将预训练的抓取检测模型与机器人学习相结合，通过利用来自对象检测和分割任务的稳健视觉指导来显著提高抓取精度、稳定性和泛化能力，在少样本学习和抓取框提示任务中实现了高达34%的成功率提升。基于扩散方法构建的RoboGrasp框架可适应各种机器人学习范式，并能够实现不同复杂场景下的精确且可靠的操作，代表了一种应对现实世界挑战中的机器人工具抓握问题的可扩展、灵活解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning and world models have shown significant promise inadvancing generalizable robotic learning, with robotic grasping remaining acritical challenge for achieving precise manipulation. Existing methods oftenrely heavily on robot arm state data and RGB images, leading to overfitting tospecific object shapes or positions. To address these limitations, we proposeRoboGrasp, a universal grasping policy framework that integrates pretrainedgrasp detection models with robotic learning. By leveraging robust visualguidance from object detection and segmentation tasks, RoboGrasp significantlyenhances grasp precision, stability, and generalizability, achieving up to 34%higher success rates in few-shot learning and grasping box prompt tasks. Builton diffusion-based methods, RoboGrasp is adaptable to various robotic learningparadigms, enabling precise and reliable manipulation across diverse andcomplex scenarios. This framework represents a scalable and versatile solutionfor tackling real-world challenges in robotic grasping.</description>
      <author>example@mail.com (Yiqi Huang, Travis Davies, Jiahuan Yan, Xiang Chen, Yu Tian, Luhui Hu)</author>
      <guid isPermaLink="false">2502.03072v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Label Anything: An Interpretable, High-Fidelity and Prompt-Free Annotator</title>
      <link>http://arxiv.org/abs/2502.02972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个标签生成模型Label Anything Model (LAM)，旨在减轻自动驾驶系统训练数据标注成本高的问题。&lt;h4&gt;背景&lt;/h4&gt;基于学习的街景语义理解在自动驾驶领域取得了显著进展，但性能严重依赖于高质量和大量注释数据。传统的人工标注方法代价高昂且耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种低成本、高精度的数据自动标注方案以减少人工成本。&lt;h4&gt;方法&lt;/h4&gt;引入预训练的Vision Transformer (ViT)用于提取特征，并在此基础上设计了语义类适配器(SCA)和优化导向解卷算法(OptOU)，两者参数量小且容易解释。SCA负责融合特征，OptOU通过多级优化来调整输出以接近真实值。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明LAM在多个现实世界的数据集（如Camvid、Cityscapes和ApolloScape）以及CARLA模拟数据集中生成的注释准确性高（mIoU达到100%左右），且只需少量预标注图像即可训练成功。&lt;h4&gt;结论&lt;/h4&gt;提出的方法可以有效降低自动驾驶系统模型训练的成本，同时保持高质量的数据标注效果。&lt;h4&gt;翻译&lt;/h4&gt;基于学习的街景语义理解在自动驾驶中取得了重大进展，但其性能严重依赖于大量和高质量的注释数据。然而，传统的人工标注过程由于需要大量的时间和成本而难以承受。为了减少这种手动标记的成本，我们提出了一种解释性、高保真度且无需提示的数据注解器——Label Anything Model（简称LAM）。首先，使用预先训练好的视觉变换器（Vision Transformer, ViT）来提取潜在特征；其次，在ViT基础上提出了语义类适配器(SCA)和优化导向的展开算法(OptOU)，两者参数量极小。SCA用于融合从ViT中提取到的特征以支持后续自动注释，而OptOU通过级联多层结构（每层包含一个优化公式）来尽可能贴近真实值地调整其输出，并因此具有较强的可解释性而非学习型黑箱性质；训练SCA和OptOU仅需单个预标注RGB种子图像，归因于它们微小的参数量。多项实验结果清晰表明所提出的LAM可以为多个现实世界数据集（Camvid、Cityscapes及ApolloScape）以及CARLA仿真数据集生成接近100%精度(mIoU)的高保真度标注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning-based street scene semantic understanding in autonomous driving (AD)has advanced significantly recently, but the performance of the AD model isheavily dependent on the quantity and quality of the annotated training data.However, traditional manual labeling involves high cost to annotate the vastamount of required data for training robust model. To mitigate this cost ofmanual labeling, we propose a Label Anything Model (denoted as LAM), serving asan interpretable, high-fidelity, and prompt-free data annotator. Specifically,we firstly incorporate a pretrained Vision Transformer (ViT) to extract thelatent features. On top of ViT, we propose a semantic class adapter (SCA) andan optimization-oriented unrolling algorithm (OptOU), both with a quite smallnumber of trainable parameters. SCA is proposed to fuse ViT-extracted featuresto consolidate the basis of the subsequent automatic annotation. OptOU consistsof multiple cascading layers and each layer contains an optimizationformulation to align its output with the ground truth as closely as possible,though which OptOU acts as being interpretable rather than learning-basedblackbox nature. In addition, training SCA and OptOU requires only a singlepre-annotated RGB seed image, owing to their small volume of learnableparameters. Extensive experiments clearly demonstrate that the proposed LAM cangenerate high-fidelity annotations (almost 100% in mIoU) for multiplereal-world datasets (i.e., Camvid, Cityscapes, and Apolloscapes) and CARLAsimulation dataset.</description>
      <author>example@mail.com (Wei-Bin Kou, Guangxu Zhu, Rongguang Ye, Shuai Wang, Ming Tang, Yik-Chung Wu)</author>
      <guid isPermaLink="false">2502.02972v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Bowel Incision Closure with a Semi-Automated Robot-Assisted Laser Tissue Soldering System</title>
      <link>http://arxiv.org/abs/2502.02971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了使用新型机器人辅助激光组织焊接系统（RLTS）进行的首次体内半自动化无接触手术，该系统用于猪小肠切口的闭合。&lt;h4&gt;背景&lt;/h4&gt;传统的胃肠手术伤口关闭方法如缝合和夹子可能会导致严重的并发症，特别是在机器人辅助微创手术中需要高超的手工技能。这些技术的重复性和耗时性使得它们适合于自动化处理，但复杂的组织接触需求阻碍了这一过程。&lt;h4&gt;目的&lt;/h4&gt;展示一种新型机器人辅助激光焊接系统在猪小肠上的体内应用，并评估其相对于传统缝合方法的优势。&lt;h4&gt;方法&lt;/h4&gt;通过体外实验优化焊料协议和系统参数后，在活猪身上进行Heineke-Mikulicz手术来闭合小肠切口。然后对术后两周内的愈合并进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;所有成功完成该程序的猪（n=5）均无泄漏现象，组织学分析显示了粘膜再生和纤维组织附着。&lt;h4&gt;结论&lt;/h4&gt;这是首次体内半自动化接触闭合技术的应用案例，为未来胃肠手术切口关闭方法的自动化开辟了新的路径。&lt;h4&gt;翻译&lt;/h4&gt;传统的胃肠道(GI)手术伤口关闭方法，如缝合和夹子，在机器人辅助微创手术(RAMIS)中面临着严重的挑战。这些技术需要高级的手动技能，并且由于其重复性和耗时性而适合于自动化处理。然而，复杂的组织接触需求阻碍了这一过程。我们展示了使用新型机器人辅助激光焊接系统（RLTS）的半自动无接触闭合手术在猪小肠切口的应用，该方法为未来胃肠手术切口关闭技术的自动化开辟了一条新的路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional methods for closing gastrointestinal (GI) surgery incisions, likesuturing and stapling, present significant challenges, including potentiallylife-threatening leaks. These techniques, especially in robot-assistedminimally invasive surgery (RAMIS), require advanced manual skills. While theirrepetitive and time-consuming nature makes them suitable candidates forautomation, the automation process is complicated by the need for extensivecontact with the tissue. Addressing this, we demonstrate a semi-autonomouscontactless surgical procedure using our novel Robot-assisted Laser TissueSoldering (RLTS) system on a live porcine bowel. Towards this in-vivodemonstration, we optimized soldering protocols and system parameters inex-vivo experiments on porcine bowels and a porcine cadaver. To assess the RLTSsystem performance, we compared the pressure at which the anastomosis leakedbetween our robotic soldering and manual suturing. With the best setup, weadvanced to an in-vivo Heineke Mikulicz closure on small bowel incision in livepigs and evaluated their healing for two weeks. All pigs successfullycompleting the procedure (N=5) survived without leaks and the histologyindicated mucosal regeneration and fibrous tissue adhesion. This marks thefirst in-vivo semi-automated contactless incision closure, paving the way forautomating GI surgery incision closure which has the potential to become analternative to traditional methods.</description>
      <author>example@mail.com (Shani Arusi, Max Platkov, Barak Rosenberg, Svetlana Basov, Ido Ashbell, Tom Polovin, Yoel Chocron, Abraham Katzir, Ilana Nisky, Uri Netz)</author>
      <guid isPermaLink="false">2502.02971v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Demonstrating a Control Framework for Physical Human-Robot Interaction Toward Industrial Applications</title>
      <link>http://arxiv.org/abs/2502.02967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Demo Paper submitted to Robotics: Science and Systems (RSS2025),  pending review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了一个人机交互（pHRI）控制框架，旨在解决工业5.0中人本方法与实际应用之间存在的性能差距。&lt;h4&gt;背景&lt;/h4&gt;当前很少有研究探讨将人机交互原理应用于实现符合工业标准的性能。工业5.0强调以人为本的方法，但如何将其有效融入实践中仍是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍一种控制框架，旨在通过集成基于扭矩的控制模式来弥合理论与实践之间的差距，并确保安全和高性能。&lt;h4&gt;方法&lt;/h4&gt;该框架采用了二阶二次规划（QP）公式化设计，包括静态和动态场景下的顺应性控制、空域顺应性和双重顺应性控制。实验使用了Kinova Gen3协作机器人配以Bota力/扭矩传感器，并附带DualShock 4游戏控制器来展示其功能。&lt;h4&gt;主要发现&lt;/h4&gt;框架具备无缝切换不同模式的能力，支持实时参数调整和定制的低级扭矩控制器的选择，确保了在各种条件下的任务追踪性能。该框架基于开源软件mc_rtc构建，保证了研究与工业部署中的可重复性。&lt;h4&gt;结论&lt;/h4&gt;研究成果展示了作为人机交互控制系统的潜在能力，并且具备工业级别的可靠性和再现性，具有广泛的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文描述了一种用于实现以人为本的工业5.0目标的人机机器人交互（pHRI）控制框架。研究引入了一个集成多种基于扭矩控制模式的控制架构，旨在提升机器人系统的性能和安全性，并确保其在各种场景中的可靠性和可重复性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Robot Interaction (pHRI) is critical for implementing Industry 5.0which focuses on human-centric approaches. However, few studies explore thepractical alignment of pHRI to industrial grade performance. This paperintroduces a versatile control framework designed to bridge this gap byincorporating the torque-based control modes: compliance control, null-spacecompliance, dual compliance, all in static and dynamic scenarios. Thanks to oursecond-order Quadratic Programming (QP) formulation, strict kinematic andcollision constraints are integrated into the system as safety features, and aweighted hierarchy guarantees singularity-robust task tracking performance. Theframework is implemented on a Kinova Gen3 collaborative robot (cobot) equippedwith a Bota force/torque sensor. A DualShock 4 game controller is attached atthe robot's end-effector to demonstrate the framework's capabilities. Thissetup enables seamless dynamic switching between the modes, and real-timeadjustment of parameters, such as transitioning between position and torquecontrol or selecting a more robust custom-developed low-level torque controllerover the default one.Built on the open-source robotic control software mc_rtc,to ensure reproducibility for both research and industrial deployment, thisframework demonstrates industrial-grade performance and repeatability,showcasing its potential as a robust pHRI control system for industrialenvironments.</description>
      <author>example@mail.com (Bastien Muraccioli, Celerier Mathieu, Benallegue Mehdi, Venture Gentiane)</author>
      <guid isPermaLink="false">2502.02967v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Gait-Net-augmented Implicit Kino-dynamic MPC for Dynamic Variable-frequency Humanoid Locomotion over Discrete Terrains</title>
      <link>http://arxiv.org/abs/2502.02934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种基于Gait-Net的增强型隐式动力学模型预测控制(MPC)方法被提出，用于自然频率变化的行走中同时优化步态、持续时间和接触力。&lt;h4&gt;背景&lt;/h4&gt;当前的人形机器人步行控制技术在适应动态步态时难以同时调整步长和步频，并且由于依赖于固定时间离散化的方法，在面对复杂地形条件时反应能力较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于Gait-Net的增强型隐式动力学模型预测控制(MPC)方法，以提高人形机器人在变化环境中的行走性能。&lt;h4&gt;方法&lt;/h4&gt;该方法使用了一种带Gait-Net增强功能的顺序凸MPC算法，通过迭代二次规划来解决多线性约束变量问题。其中，一个轻量级的步态频率网络(Gait-Net)用于确定最佳的步频，在可变MPC采样时间下简化了步长优化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在高保真仿真和小型人形机器人硬件上进行了验证，并展示了其在三维离散地形条件下，利用仅一步预览地形数据即可实现变量频率行走的能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于Gait-Net的增强型隐式动力学模型预测控制(MPC)方法能够有效提高人形机器人的适应性和性能，在复杂的动态环境中表现出优异的效果。&lt;h4&gt;翻译&lt;/h4&gt;当前的人形机器人步态优化技术在处理复杂地形条件下的步行时，由于其依赖于固定的离散化时间间隔策略而难以同时调整步长和持续时间。这限制了它们对环境变化的响应能力，并导致在挑战性环境下表现不佳。本研究提出了一个集成Gait-Net增强功能的隐式动力学模型预测控制(MPC)方案，该方法能够实现自然频率变化下的行走中步态、步时以及接触力的同时优化。通过迭代二次规划技术解决多线性约束变量问题，并采用一种轻量级的步频网络(Gait-Net)，确定可变MPC采样时间下的最优步长，在每一步次迭代过程中更新空间参考轨迹，允许将动力学限制映射到参考轨迹设计中。该方案在高保真模拟和小型人形机器人硬件上进行了验证，并展示了利用单个地形数据预览即可实现三维离散地形下频率变化行走的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current optimization-based control techniques for humanoid locomotionstruggle to adapt step duration and placement simultaneously in dynamic walkinggaits due to their reliance on fixed-time discretization, which limitsresponsiveness to terrain conditions and results in suboptimal performance inchallenging environments. In this work, we propose a Gait-Net-augmentedimplicit kino-dynamic model-predictive control (MPC) to simultaneously optimizestep location, step duration, and contact forces for natural variable-frequencylocomotion. The proposed method incorporates a Gait-Net-augmented SequentialConvex MPC algorithm to solve multi-linearly constrained variables by iterativequadratic programs. At its core, a lightweight Gait-frequency Network(Gait-Net) determines the preferred step duration in terms of variable MPCsampling times, simplifying step duration optimization to the parameter level.Additionally, it enhances and updates the spatial reference trajectory withineach sequential iteration by incorporating local solutions, allowing theprojection of kinematic constraints to the design of reference trajectories. Wevalidate the proposed algorithm in high-fidelity simulations and on small-sizehumanoid hardware, demonstrating its capability for variable-frequency and 3-Ddiscrete terrain locomotion with only a one-step preview of terrain data.</description>
      <author>example@mail.com (Junheng Li, Ziwei Duan, Junchao Ma, Quan Nguyen)</author>
      <guid isPermaLink="false">2502.02934v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Achieving Operational Universality through a Turing Complete Chemputer</title>
      <link>http://arxiv.org/abs/2502.02872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 28 references&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用图灵完备性概念应用于化学合成领域，通过机器人平台和XDL编程语言实现复杂分子的合成。&lt;h4&gt;背景&lt;/h4&gt;现代计算机的基础抽象是图灵机。在化学中，程序化化学过程面临挑战，因为难以将高层次的理解转化为实际操作。&lt;h4&gt;目的&lt;/h4&gt;目的是利用图灵完备性的概念来创建可执行特定化学操作并支持自动化和自主化的框架。&lt;h4&gt;方法&lt;/h4&gt;通过使用颜色空间的RGB组合以及条件逻辑来演示图灵完备性，并讨论了多个具体的化学应用场景。&lt;h4&gt;主要发现&lt;/h4&gt;超过1670万种RGB色彩组合被简化为5个离散值，覆盖了10个感兴趣区域（ROI），形成了一个可以作为概念上探索化学空间代理的体系。&lt;h4&gt;结论&lt;/h4&gt;通过此正式描述建立了未来化学编程语言框架，确保复杂的逻辑操作能够准确表达和执行，并具备错误纠正的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中探讨的是将图灵完备性应用到化学合成过程中的机器人平台上，利用一种称为XDL的化学感知编程语言来实现复杂分子的合成。这种方法通过计算机可计算性的概念，扩展到了化学化合物的自动合成机器人的合成能力上。研究者展示了使用颜色空间和条件逻辑进行图灵完备性互动演示的结果，并讨论了多个具体的化学应用场景。他们用超过16.7百万种RGB色彩组合来模拟可能存在的化学状态空间，为未来化学编程语言的发展提供了一个正式框架，以确保复杂的逻辑操作能够在自动化和自主化的追求过程中被准确地表达并执行，同时具备错误纠正的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The most fundamental abstraction underlying all modern computers is theTuring Machine, that is if any modern computer can simulate a Turing Machine,an equivalence which is called Turing completeness, it is theoreticallypossible to achieve any task that can be algorithmically described by executinga series of discrete unit operations. In chemistry, the ability to programchemical processes is demanding because it is hard to ensure that the processcan be understood at a high level of abstraction, and then reduced to practice.Herein we exploit the concept of Turing completeness applied to roboticplatforms for chemistry that can be used to synthesise complex moleculesthrough unit operations that execute chemical processes using achemically-aware programming language, XDL. We leverage the concept ofcomputability by computers to synthesizability of chemical compounds byautomated synthesis machines. The results of an interactive demonstration ofTuring completeness using the colour gamut and conditional logic are presentedand examples of chemical use-cases are discussed. Over 16.7 millioncombinations of Red, Green, Blue (RGB) colour space were binned into 5 discretevalues and measured over 10 regions of interest (ROIs), affording 78 millionpossible states per step and served as a proxy for conceptual, chemical spaceexploration. This formal description establishes a formal framework in futurechemical programming languages to ensure complex logic operations are expressedand executed correctly, with the possibility of error correction, in theautomated and autonomous pursuit of increasingly complex molecules.</description>
      <author>example@mail.com (Daniel Gahler, Dean Thomas, Slawomir Lach, Leroy Cronin)</author>
      <guid isPermaLink="false">2502.02872v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Dexterous Safe Control for Humanoids in Cluttered Environments via Projected Safe Set Algorithm</title>
      <link>http://arxiv.org/abs/2502.02858v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的算法，用于解决在复杂环境中人形机器人操作时的安全性问题，确保其性能不受影响。&lt;h4&gt;背景&lt;/h4&gt;随着人形机器人的广泛应用，如何保证它们在实际环境中的安全性和高性能成为了一个重要课题。传统的简化几何边界方法在稀疏环境中应用较好，但在拥挤环境中会导致大量的约束条件，从而使得控制变得不可行。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，以解决复杂环境下的机器人碰撞避免问题，并确保机器人的操作是可行的。&lt;h4&gt;方法&lt;/h4&gt;提出了Projected Safe Set Algorithm（p-SSA），这是一种经典安全控制算法在多约束情况下的扩展。该算法通过系统地放松冲突约束来最小化安全性违规，从而保证了机器人控制的可行性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，p-SSA使得人形机器人能够在困难情况下稳健操作，并且直接推广到各种任务中无需参数调整。&lt;h4&gt;结论&lt;/h4&gt;p-SSA算法有效地解决了复杂环境中的人形机器人的安全问题，提高了它们的操作性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;确保在实际应用中人形机器人的安全性而不影响其性能至关重要。本文研究了灵巧的安全性问题，即通过肢体级别的几何约束来避免外部碰撞及自我碰撞的问题。与稀疏环境中使用简化边界方法相比，在复杂环境下执行安全操作会产生大量的约束条件，这往往会导致不可行的控制方案。为了解决这一问题，我们提出了一种Projected Safe Set Algorithm (p-SSA)，它是经典安全控制算法在多约束情况下的扩展。该算法以一种原则化的方式放松冲突约束，并最小化安全性违规来保证机器人操作的可行性。我们在模拟和真实的Unitree G1人形机器人上验证了这一方法，结果表明p-SSA能够使机器人在具有挑战性的环境中稳健运行，并且直接推广到各种任务中无需参数调整。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is critical to ensure safety for humanoid robots in real-worldapplications without compromising performance. In this paper, we consider theproblem of dexterous safety, featuring limb-level geometry constraints foravoiding both external and self-collisions in cluttered environments. Comparedto safety with simplified bounding geometries in sprase environments, dexteroussafety produces numerous constraints which often lead to infeasible constraintsets when solving for safe robot control. To address this issue, we proposeProjected Safe Set Algorithm (p-SSA), an extension of classical safe controlalgorithms to multi-constraint cases. p-SSA relaxes conflicting constraints ina principled manner, minimizing safety violations to guarantee feasible robotcontrol. We verify our approach in simulation and on a real Unitree G1 humanoidrobot performing complex collision avoidance tasks. Results show that p-SSAenables the humanoid to operate robustly in challenging situations with minimalsafety violations and directly generalizes to various tasks with zero parametertuning.</description>
      <author>example@mail.com (Rui Chen, Yifan Sun, Changliu Liu)</author>
      <guid isPermaLink="false">2502.02858v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Latent Representations in Behavior Cloning: An Information Bottleneck Approach for Robot Manipulation</title>
      <link>http://arxiv.org/abs/2502.02853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;行为克隆（BC）是一种广泛应用于机器人操作的视觉模仿学习方法。本文通过引入信息理论来解决现有方法中忽略表征冗余和缺乏坚实的理论基础的问题，提出了一种新的方法，即在BC框架中集成信息瓶颈（IB）原则。&lt;h4&gt;背景&lt;/h4&gt;现有的行为克隆方法通常通过使用大型数据集并结合额外的视觉和文本模态来增强泛化能力。然而这些方法往往忽略了学习到的表征中是否存在冗余的信息，并且缺乏理论基础来指导学习过程。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决现有BC方法中的冗余问题，采用信息论的方法量化并减少潜在表示中的冗余信息，并将IB原则引入BC框架中。&lt;h4&gt;方法&lt;/h4&gt;通过信息瓶颈（IB）原理压缩无关信息而保留任务相关特征，提供一种结构化的框架来指导学习过程。同时开展了一项全面的研究，探讨了不同方法、骨干网络和实验设置下的潜在表征中的冗余问题，并将IB的一般化能力扩展到BC。&lt;h4&gt;主要发现&lt;/h4&gt;在CortexBench和LIBERO基准测试上进行的大量实验和分析表明，使用IB可以显著提高性能。这进一步证明减少输入数据冗余的重要性及其对实际应用的实际价值。&lt;h4&gt;结论&lt;/h4&gt;通过引入信息瓶颈（IB）原理并将其应用于行为克隆框架中，可以有效减少表征中的冗余信息，并增强泛化能力，从而在机器人操作等领域展示出重要的实践意义和潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Behavior Cloning (BC) is a widely adopted visual imitation learning method inrobot manipulation. Current BC approaches often enhance generalization byleveraging large datasets and incorporating additional visual and textualmodalities to capture more diverse information. However, these methods overlookwhether the learned representations contain redundant information and lack asolid theoretical foundation to guide the learning process. To address theselimitations, we adopt an information-theoretic perspective and introduce mutualinformation to quantify and mitigate redundancy in latent representations.Building on this, we incorporate the Information Bottleneck (IB) principle intoBC, which extends the idea of reducing redundancy by providing a structuredframework for compressing irrelevant information while preserving task-relevantfeatures. This work presents the first comprehensive study on redundancy inlatent representations across various methods, backbones, and experimentalsettings, while extending the generalizability of the IB to BC. Extensiveexperiments and analyses on the CortexBench and LIBERO benchmarks demonstratesignificant performance improvements with IB, underscoring the importance ofreducing input data redundancy and highlighting its practical value for morepractical applications. Project Page:https://baishuanghao.github.io/BC-IB.github.io.</description>
      <author>example@mail.com (Shuanghai Bai, Wanqi Zhou, Pengxiang Ding, Wei Zhao, Donglin Wang, Badong Chen)</author>
      <guid isPermaLink="false">2502.02853v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Global Contact-Rich Planning with Sparsity-Rich Semidefinite Relaxations</title>
      <link>http://arxiv.org/abs/2502.02829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://computationalrobotics.seas.harvard.edu/project-spot/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文展示了当将接触丰富的运动规划视为多项式优化问题时，它也具有稀疏性。通过利用相关的和项的稀疏模式以及从机器人动力学结构和接触模式分离中提取的专业化稀疏模式，可以设计高阶但稀疏的半定规划（SDP）松弛算法。&lt;h4&gt;背景&lt;/h4&gt;在处理涉及大量接触点的运动规划问题时，传统的非凸优化方法往往难以找到全局最优解或需要大量的计算资源。通过将这类问题转化为多项式优化问题，并利用其内在的稀疏性结构，可以设计更高效的求解方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Lasserre矩和平方和层次的新算法框架，用于快速解决接触丰富的运动规划问题，并验证该方法的有效性和实用性。&lt;h4&gt;方法&lt;/h4&gt;通过分析机器人动力学结构中的特殊稀疏模式来构建高阶但稀疏的SDP松弛方案。利用现成的SDP求解器可以在几秒钟内找到近全局最优解。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法不仅能够快速解决接触丰富的非凸规划问题，还能保证较小的次优性认证。实验结果表明该方法在模拟和真实世界环境中均具有强大的性能表现。&lt;h4&gt;结论&lt;/h4&gt;论文提供了一种新的高效算法框架，并且开源了一个名为SPOT（稀疏多项式优化工具箱）的C++实现版本，支持Python和Matlab接口。这个工具箱可以帮助自动化地利用稀疏性来解决机器人和其他领域的复杂优化问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其中文翻译及总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We show that contact-rich motion planning is also sparsity-rich when viewedas polynomial optimization (POP). We can exploit not only the correlative andterm sparsity patterns that are general to all POPs, but also specializedsparsity patterns from the robot kinematic structure and the separability ofcontact modes. Such sparsity enables the design of high-order but sparsesemidefinite programming (SDPs) relaxations--building upon Lasserre's momentand sums of squares hierarchy--that (i) can be solved in seconds byoff-the-shelf SDP solvers, and (ii) compute near globally optimal solutions tothe nonconvex contact-rich planning problems with small certifiedsuboptimality. Through extensive experiments both in simulation (Push Bot, PushBox, Push Box with Obstacles, and Planar Hand) and real world (Push T), wedemonstrate the power of using convex SDP relaxations to generate globalcontact-rich motion plans. As a contribution of independent interest, werelease the Sparse Polynomial Optimization Toolbox (SPOT)--implemented in C++with interfaces to both Python and Matlab--that automates sparsity exploitationfor robotics and beyond.</description>
      <author>example@mail.com (Shucheng Kang, Guorui Liu, Heng Yang)</author>
      <guid isPermaLink="false">2502.02829v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs</title>
      <link>http://arxiv.org/abs/2502.02773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了使用大型语言模型（LLMs）将道路手册的信息融入标准定义地图（SD地图），以提高其质量。&lt;h4&gt;背景&lt;/h4&gt;高精度地图对于自动驾驶非常重要，但成本高昂且获取困难。而标准定义地图虽然准确性较低，但更易于获得和更新。&lt;h4&gt;目的&lt;/h4&gt;开发一种名为SD++的端到端管道，用于增强SD地图，并从道路手册中提取位置相关的信息。&lt;h4&gt;方法&lt;/h4&gt;使用LLMs来比较并建议几种将道路手册信息整合进SD地图的方法。&lt;h4&gt;主要发现&lt;/h4&gt;论文展示了SD++在加州和日本的实际效果，证明了其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究成功地开发了一种新的方法，利用大型语言模型增强标准定义地图的质量，并提高了这些地图对于自动驾驶车辆的适用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到高精度地图（HD图）详细记录车道中心线和道路元素，对自动驾驶非常有用但成本高昂且不易获取。相比之下，标准定义地图提供了数米级别的道路中心线数据。论文提出通过使用大型语言模型将道路手册的信息融入SD地图中，以增强其质量，并展示了名为SD++的端到端管道在加州和日本的实际效果，证明了其泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-definition maps (HD maps) are detailed and informative maps capturinglane centerlines and road elements. Although very useful for autonomousdriving, HD maps are costly to build and maintain. Furthermore, access to thesehigh-quality maps is usually limited to the firms that build them. On the otherhand, standard definition (SD) maps provide road centerlines with an accuracyof a few meters. In this paper, we explore the possibility of enhancing SD mapsby incorporating information from road manuals using LLMs. We develop SD++, anend-to-end pipeline to enhance SD maps with location-dependent road informationobtained from a road manual. We suggest and compare several ways of using LLMsfor such a task. Furthermore, we show the generalization ability of SD++ byshowing results from both California and Japan.</description>
      <author>example@mail.com (Hitvarth Diwanji, Jing-Yan Liao, Akshar Tumu, Henrik I. Christensen, Marcell Vazquez-Chanlatte, Chikao Tsuchiya)</author>
      <guid isPermaLink="false">2502.02773v1</guid>
      <pubDate>Thu, 06 Feb 2025 17:18:52 +0800</pubDate>
    </item>
    <item>
      <title>Calibrated Multi-Preference Optimization for Aligning Diffusion Models</title>
      <link>http://arxiv.org/abs/2502.02588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的文本到图像扩散模型对齐的方法——Calibrated Preference Optimization (CaPO)，该方法无需人工标注数据，通过从多个奖励模型中整合一般偏好信息来优化T2I（Text-to-Image）生成过程。&lt;h4&gt;背景&lt;/h4&gt;利用奖励模型进行T2I扩散模型的偏好优化比使用人类注释的数据集更具可扩展性，但是现有的偏好优化方法在处理多偏好场景和奖励不一致时表现不佳。它们仅考虑成对偏好的分布信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的文本到图像生成模型的优化方法CaPO，该方法通过从多个奖励模型中综合一般偏好来提升T2I扩散模型的表现。&lt;h4&gt;方法&lt;/h4&gt;{'核心方法': '引入了奖励校准方法，用以计算预训练模型生成样本之间的预期胜率，以此近似出一般的偏好信息。提出了基于前沿的成对选择方法，有效地处理多偏好的分布情况，并通过回归损失函数来微调扩散模型。', '技术细节': '采用帕累托前沿的成对选择策略来管理多偏好分布，使用回归损失来调整T2I生成模型以匹配选定配对之间的校准奖励差异。'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在单个和多个奖励设置下，CaPO方法在文本到图像基准测试（如GenEval和T2I-Compbench）中均优于传统的Direct Preference Optimization (DPO) 方法。&lt;h4&gt;结论&lt;/h4&gt;CaPO提供了一种无需人工注释数据的优化策略来改进T2I扩散模型的表现，并且它能够有效地处理多偏好场景及奖励之间的不一致问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aligning text-to-image (T2I) diffusion models with preference optimization isvaluable for human-annotated datasets, but the heavy cost of manual datacollection limits scalability. Using reward models offers an alternative,however, current preference optimization methods fall short in exploiting therich information, as they only consider pairwise preference distribution.Furthermore, they lack generalization to multi-preference scenarios andstruggle to handle inconsistencies between rewards. To address this, we presentCalibrated Preference Optimization (CaPO), a novel method to align T2Idiffusion models by incorporating the general preference from multiple rewardmodels without human annotated data. The core of our approach involves a rewardcalibration method to approximate the general preference by computing theexpected win-rate against the samples generated by the pretrained models.Additionally, we propose a frontier-based pair selection method thateffectively manages the multi-preference distribution by selecting pairs fromPareto frontiers. Finally, we use regression loss to fine-tune diffusion modelsto match the difference between calibrated rewards of a selected pair.Experimental results show that CaPO consistently outperforms prior methods,such as Direct Preference Optimization (DPO), in both single and multi-rewardsettings validated by evaluation on T2I benchmarks, including GenEval andT2I-Compbench.</description>
      <author>example@mail.com (Kyungmin Lee, Xiaohang Li, Qifei Wang, Junfeng He, Junjie Ke, Ming-Hsuan Yang, Irfan Essa, Jinwoo Shin, Feng Yang, Yinxiao Li)</author>
      <guid isPermaLink="false">2502.02588v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
  <item>
      <title>Learning Fine-to-Coarse Cuboid Shape Abstraction</title>
      <link>http://arxiv.org/abs/2502.01855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种新的细粒度到粗粒度的无监督学习方法，用于抽象3D形状集合。这种方法可以将复杂的几何结构用简单的几何原语（如立方体）表示，并且能减少所需的几何原语数量。&lt;h4&gt;背景&lt;/h4&gt;使用简单几何原语来表示三维物体的抽象有助于从复杂几何中推断出结构信息，这对于三维形状理解、结构分析和几何建模至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督学习方法，在训练过程中可以将3D形状的数量级减少到只有几个立方体等原语。同时，该方法可以让网络优化重建错误，并确保整个数据集的结构一致性。&lt;h4&gt;方法&lt;/h4&gt;通过引入抽象损失和重构损失的方法，使得模型不仅能够准确地逼近表面，还能保持体积的一致性。最终使用较少的几何原语更精确地表示3D形状。&lt;h4&gt;主要发现&lt;/h4&gt;该研究提出的新方法实现了对之前基于立方体形状抽象技术的改进，并且在聚类、检索和检测部分对称性的下游任务中表现优秀。&lt;h4&gt;结论&lt;/h4&gt;研究成果确认了通过精细到粗糙层次的方法以及结合重构损失和抽象损失，可以更精确地使用少量几何原语表示3D形状。&lt;h4&gt;翻译&lt;/h4&gt;三维对象用简单的几何原语（如立方体）进行抽象使得能够从复杂结构中推断出结构性信息。这对于三维形状理解、结构分析及几何建模很重要。我们介绍了一种新的由细到粗的无监督学习方法，用于从3D形状集合中抽取出简洁结构。我们的架构设计允许在训练期间将几何原语的数量从数百个（精细重建）减少为几个（粗略抽象），同时确保整个数据集的一致性结构的学习。通过渐进式惩罚冗余几何原语的损失函数和不仅考虑表面逼近而且还保持体积一致性的重构损失，我们能够比之前的工作更精确地用较少的立方体表示3D形状。我们在人造和人体模型数据集合上与先前的最先进的学习方法进行了比较，并在聚类、检索和部分对称性检测等下游任务中展示了我们的立方体抽象的优点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The abstraction of 3D objects with simple geometric primitives like cuboidsallows to infer structural information from complex geometry. It is importantfor 3D shape understanding, structural analysis and geometric modeling. Weintroduce a novel fine-to-coarse unsupervised learning approach to abstractcollections of 3D shapes. Our architectural design allows us to reduce thenumber of primitives from hundreds (fine reconstruction) to only a few (coarseabstraction) during training. This allows our network to optimize thereconstruction error and adhere to a user-specified number of primitives pershape while simultaneously learning a consistent structure across the wholecollection of data. We achieve this through our abstraction loss formulationwhich increasingly penalizes redundant primitives. Furthermore, we introduce areconstruction loss formulation to account not only for surface approximationbut also volume preservation. Combining both contributions allows us torepresent 3D shapes more precisely with fewer cuboid primitives than previouswork. We evaluate our method on collections of man-made and humanoid shapescomparing with previous state-of-the-art learning methods on commonly usedbenchmarks. Our results confirm an improvement over previous cuboid-based shapeabstraction techniques. Furthermore, we demonstrate our cuboid abstraction indownstream tasks like clustering, retrieval, and partial symmetry detection.</description>
      <author>example@mail.com (Gregor Kobsik, Morten Henkel, Yanjiang He, Victor Czech, Tim Elsner, Isaak Lim, Leif Kobbelt)</author>
      <guid isPermaLink="false">2502.01855v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Particle Trajectory Representation Learning with Masked Point Modeling</title>
      <link>http://arxiv.org/abs/2502.02558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 15 figures. Project page at https://youngsm.com/polarmae/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于3D粒子轨迹分析的自监督学习框架PoLAr-MAE，该框架利用时间投影室(TPC)中稀疏但局部密集的点云数据。PoLAr-MAE使用体积标记化技术将离子化点分组，并引入能量填充辅助任务以改善轨迹语义。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习方法主要应用于在线语料库和带注释的照片，但在科学领域（特别是高能物理）中的应用仍处于初级阶段。TPC产生全局稀疏但局部密集的3D粒子轨迹数据。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于TPC中3D粒子轨迹分析的自监督学习方法，以充分利用这些高度专业化的科学数据。&lt;h4&gt;方法&lt;/h4&gt;基于PointMAE框架提出PoLAr-MAE模型。该模型采用体积标记化技术将稀疏离子化点分组，并引入能量填充辅助任务来改善粒子轨迹语义。&lt;h4&gt;主要发现&lt;/h4&gt;PoLAr-MAE在没有使用任何标注数据的情况下，达到了与监督学习基线相当的跟踪和簇射分类F值（分别为99.4% 和 97.7%）。然而，在处理子标记现象如重叠或短寿命粒子轨迹时遇到挑战。&lt;h4&gt;结论&lt;/h4&gt;PoLAr-MAE是一个有效的自监督学习方法，可以为TPC中的粒子轨迹分析提供丰富的表示。为了支持进一步的研究，发布了PILArNet-M数据集，该数据集中包含超过100万事件和52亿个标记点。&lt;h4&gt;翻译&lt;/h4&gt;有效的自监督学习技术在解锁大型数据集用于表示学习方面发挥了关键作用。虽然许多有前景的方法已经利用在线语料库和带注释的照片进行开发，但在科学领域（特别是在高能物理中）的应用仍然处于初级阶段。我们提出了一种针对时间投影室(TPC)中的3D粒子轨迹分析的自监督掩码建模框架。这些探测器产生的数据是全局稀疏但局部密集的点云，用于捕捉米级粒子轨迹在毫米分辨率下的细节。基于PointMAE，本研究提出了体积标记化方法，将稀疏离子化点分组为分辨率无关的补丁，并引入了能量填充辅助任务以改进轨迹语义。这种被称为PoLAr-MAE的方法实现了99.4% 的跟踪F值和97.7% 的簇射分类F值，与不需要任何标注数据的监督基线相当。虽然模型学会了丰富的粒子轨迹表示，但在处理子标记现象如重叠或短寿命粒子轨迹时表现不佳。为了支持进一步研究，我们发布了PILArNet-M——这是最大的开放LArTPC数据集（超过100万事件和52亿个标注点），以推进高能物理中的自监督学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective self-supervised learning (SSL) techniques have been key tounlocking large datasets for representation learning. While many promisingmethods have been developed using online corpora and captioned photographs,their application to scientific domains, where data encodes highly specializedknowledge, remains in its early stages. We present a self-supervised maskedmodeling framework for 3D particle trajectory analysis in Time ProjectionChambers (TPCs). These detectors produce globally sparse (&lt;1% occupancy) butlocally dense point clouds, capturing meter-scale particle trajectories atmillimeter resolution. Starting with PointMAE, this work proposes volumetrictokenization to group sparse ionization points into resolution-agnosticpatches, as well as an auxiliary energy infilling task to improve trajectorysemantics. This approach -- which we call Point-based Liquid Argon MaskedAutoencoder (PoLAr-MAE) -- achieves 99.4% track and 97.7% shower classificationF-scores, matching that of supervised baselines without any labeled data. Whilethe model learns rich particle trajectory representations, it struggles withsub-token phenomena like overlapping or short-lived particle trajectories. Tosupport further research, we release PILArNet-M -- the largest open LArTPCdataset (1M+ events, 5.2B labeled points) -- to advance SSL in high energyphysics (HEP). Project site: https://youngsm.com/polarmae/</description>
      <author>example@mail.com (Sam Young, Yeon-jae Jwa, Kazuhiro Terao)</author>
      <guid isPermaLink="false">2502.02558v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Improving Generalization Ability for 3D Object Detection by Learning Sparsity-invariant Features</title>
      <link>http://arxiv.org/abs/2502.02322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICRA 2025. Code is available at  https://github.com/Tiffamy/3DOD-LSF&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;在自动驾驶领域，3D物体检测对于准确识别和跟踪对象至关重要。然而，大多数现有技术在处理未见领域的目标时性能明显下降。&lt;h4&gt;背景&lt;/h4&gt;尽管针对3D物体检测任务的技术不断进步，但大多数方法仍然存在一个主要问题：当面对与训练数据不同的传感器配置和场景分布的领域时，它们的表现会显著下降。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种改进单个域上3D物体检测泛化能力的方法。重点是从单一源域推广到具有不同点云密度的目标域。&lt;h4&gt;方法&lt;/h4&gt;为了从单一源域学习稀疏不变特征，我们选择性地对源数据进行抽样，并使用当前探测器确定的置信分数来识别探测器最重要的密度。接着利用教师-学生框架将不同点云密度的Bird's Eye View (BEV) 特征对齐。还采用了基于图嵌入关系对齐（GERA）和特征内容对齐（FCA）的技术，使检测器在面对新的领域时更具鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法与其他基准相比展现出更强的泛化能力，并且即使没有访问目标领域的数据也能超过一些领域适应的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效改善了3D物体检测任务中的跨域泛化问题，在自动驾驶等领域具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autonomous driving, 3D object detection is essential for accuratelyidentifying and tracking objects. Despite the continuous development of varioustechnologies for this task, a significant drawback is observed in most ofthem-they experience substantial performance degradation when detecting objectsin unseen domains. In this paper, we propose a method to improve thegeneralization ability for 3D object detection on a single domain. We primarilyfocus on generalizing from a single source domain to target domains withdistinct sensor configurations and scene distributions. To learnsparsity-invariant features from a single source domain, we selectivelysubsample the source data to a specific beam, using confidence scoresdetermined by the current detector to identify the density that holds utmostimportance for the detector. Subsequently, we employ the teacher-studentframework to align the Bird's Eye View (BEV) features for different pointclouds densities. We also utilize feature content alignment (FCA) andgraph-based embedding relationship alignment (GERA) to instruct the detector tobe domain-agnostic. Extensive experiments demonstrate that our method exhibitssuperior generalization capabilities compared to other baselines. Furthermore,our approach even outperforms certain domain adaptation methods that can accessto the target domain data.</description>
      <author>example@mail.com (Hsin-Cheng Lu, Chung-Yi Lin, Winston H. Hsu)</author>
      <guid isPermaLink="false">2502.02322v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study</title>
      <link>http://arxiv.org/abs/2502.02451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 2 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了计算方法在非英语语料中测量道德基础的有效性，并以中文为例进行研究。&lt;h4&gt;背景&lt;/h4&gt;大多数关于道德基础的资源主要针对英文设计，限制了该理论跨语言应用的可能性。&lt;h4&gt;目的&lt;/h4&gt;评估将英文资源应用于机器翻译文本、本地词典、多语言模型和大型语言模型（LLMs）在非英语文本中测量道德基础的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用中文作为案例研究，测试了几种不同的技术方案来衡量道德基础。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，机器翻译和本地词汇表的方法不足以应对复杂的道德评估问题，并且经常丢失重要的文化信息。相比之下，多语言模型和LLMs通过迁移学习展现了可靠的跨语言性能，而LLMs在数据效率方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了人为验证自动化道德基础评估的重要性，因为即使是先进的模型也可能忽视跨语言测量中的文化差异。此外，研究成果表明LLMs在进行复杂的多语种推理任务中具有巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;这项研究探讨了计算方法应用于非英语文本以衡量道德基础的有效性，并通过中文案例强调了大型语言模型（LLMs）的潜力以及人为验证自动化评估的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores computational approaches for measuring moral foundations(MFs) in non-English corpora. Since most resources are developed primarily forEnglish, cross-linguistic applications of moral foundation theory remainlimited. Using Chinese as a case study, this paper evaluates the effectivenessof applying English resources to machine translated text, local languagelexicons, multilingual language models, and large language models (LLMs) inmeasuring MFs in non-English texts. The results indicate that machinetranslation and local lexicon approaches are insufficient for complex moralassessments, frequently resulting in a substantial loss of culturalinformation. In contrast, multilingual models and LLMs demonstrate reliablecross-language performance with transfer learning, with LLMs excelling in termsof data efficiency. Importantly, this study also underscores the need forhuman-in-the-loop validation of automated MF assessment, as the most advancedmodels may overlook cultural nuances in cross-language measurements. Thefindings highlight the potential of LLMs for cross-language MF measurements andother complex multilingual deductive coding tasks.</description>
      <author>example@mail.com (Calvin Yixiang Cheng, Scott A Hale)</author>
      <guid isPermaLink="false">2502.02451v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning</title>
      <link>http://arxiv.org/abs/2502.02247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13pages, supplementary included, early accepted by TPAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新颖的旋转自适应域泛化框架，用于解决3D点云分析中方向感知的域泛化问题。&lt;h4&gt;背景&lt;/h4&gt;在3D点云分析领域，如何应对不可预测的旋转带来的挑战是个开放且棘手的问题。传统的通过旋转增强实现跨域鲁棒性和适应性的方式效果不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种能够有效缓解定向变化的方法，提高模型在不同方向下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;首先识别每个点云中最具挑战性的旋转角度，并优化复杂的方位集；其次使用一个感知方向的对比学习框架，该框架结合了方向一致性损失和边界分离损失，以有效地从数据中学习到类别区分性和可泛化的特征。&lt;h4&gt;主要发现&lt;/h4&gt;提出的旋转适应性域泛化框架在3D跨域基准测试上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够在保留类间差异的同时增强模型的泛化能力，特别适用于应对不可预测的方向变化问题。&lt;h4&gt;翻译&lt;/h4&gt;3D点云分析对于不可预知的旋转具有脆弱性，这构成了一个开放而挑战性的领域：方向感知的三维域泛化。3D表示的跨域鲁棒性和适应性至关重要但难以通过简单的旋转增强来实现。为了利用复杂的方向带来的泛化能力提升的优势，我们提出了一种创新的旋转自适应域泛化框架用于3D点云分析。我们的方法旨在通过迭代学习过程利用复杂的样本减轻方向偏移问题。具体而言，识别每个点云中最具挑战性的旋转，并优化这些复杂的方向以形成一个复杂的方位集；随后应用一种感知方向的对比学习框架，该框架结合了方向一致性损失和边界分离损失，从而使模型能够有效地从数据中学习到类别区分性和可泛化的特征并保持旋转的一致性。在3D跨域基准测试上进行的大规模实验和消融研究表明，我们提出的方法在方向感知的三维领域泛化上下达到了最先进的性能水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2025.3535230&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vulnerability of 3D point cloud analysis to unpredictable rotations posesan open yet challenging problem: orientation-aware 3D domain generalization.Cross-domain robustness and adaptability of 3D representations are crucial butnot easily achieved through rotation augmentation. Motivated by the inherentadvantages of intricate orientations in enhancing generalizability, we proposean innovative rotation-adaptive domain generalization framework for 3D pointcloud analysis. Our approach aims to alleviate orientational shifts byleveraging intricate samples in an iterative learning process. Specifically, weidentify the most challenging rotation for each point cloud and construct anintricate orientation set by optimizing intricate orientations. Subsequently,we employ an orientation-aware contrastive learning framework that incorporatesan orientation consistency loss and a margin separation loss, enablingeffective learning of categorically discriminative and generalizable featureswith rotation consistency. Extensive experiments and ablations conducted on 3Dcross-domain benchmarks firmly establish the state-of-the-art performance ofour proposed approach in the context of orientation-aware 3D domaingeneralization.</description>
      <author>example@mail.com (Bangzhen Liu, Chenxi Zheng, Xuemiao Xu, Cheng Xu, Huaidong Zhang, Shengfeng He)</author>
      <guid isPermaLink="false">2502.02247v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Mask-informed Deep Contrastive Incomplete Multi-view Clustering</title>
      <link>http://arxiv.org/abs/2502.02234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新颖的Mask-informed Deep Contrastive Incomplete Multi-view Clustering (Mask-IMvC) 方法，旨在减轻特定视图中缺失样本对不同视图知识集成的影响。&lt;h4&gt;背景&lt;/h4&gt;多视角聚类（MvC）利用来自多个视角的信息来揭示数据的潜在结构。然而，如何减少特定视图中的缺失样本对不同视角知识整合产生的负面影响仍然是一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来处理多视角聚类中由于某些视图缺少样本而导致的问题，并提升跨视图集成信息的能力。&lt;h4&gt;方法&lt;/h4&gt;通过引入基于掩码的融合网络，该网络在聚合不完整多视角信息时考虑了各视图间样本观察状态作为掩码。此外，设计了一种辅助对比学习损失函数，利用不同视图中样本的邻域信息增强整合后的共视图表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明所提出的Mask-IMvC方法在多个MvC数据集上都优于现有最先进的方法，在完整和不完整的场景下均表现出色。&lt;h4&gt;结论&lt;/h4&gt;该工作通过引入掩码指导的信息聚合机制与对比学习损失，成功提高了处理缺失视图信息时的多视角聚类性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多视角聚类（MvC）利用来自多个视角的信息来揭示数据潜在结构。尽管在MvC方面取得了显著进展，但如何减轻特定视角中缺少样本对不同视角知识整合产生的负面影响仍然是一个关键挑战。本文提出了一种新颖的Mask-informed Deep Contrastive Incomplete Multi-view Clustering (Mask-IMvC) 方法，该方法巧妙地确定了用于聚类的公共视图表示。具体而言，我们引入了一个基于掩码的信息融合网络，它在聚合不完整多视角信息时考虑了样本在各种视图中的观察状态作为掩码，从而减少了缺失值的不利影响。此外，设计了一种辅助对比学习损失函数，通过注入来自不同视图的样本邻域信息来增强整合后的共视图表示的能力。最后，进行了广泛的实验以证明所提出的Mask-IMvC方法在多个MvC数据集上优于最先进的方法，在完整和不完整的场景下都表现出了优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view clustering (MvC) utilizes information from multiple views touncover the underlying structures of data. Despite significant advancements inMvC, mitigating the impact of missing samples in specific views on theintegration of knowledge from different views remains a critical challenge.This paper proposes a novel Mask-informed Deep Contrastive IncompleteMulti-view Clustering (Mask-IMvC) method, which elegantly identifies aview-common representation for clustering. Specifically, we introduce amask-informed fusion network that aggregates incomplete multi-view informationwhile considering the observation status of samples across various views as amask, thereby reducing the adverse effects of missing values. Additionally, wedesign a prior knowledge-assisted contrastive learning loss that boosts therepresentation capability of the aggregated view-common representation byinjecting neighborhood information of samples from different views. Finally,extensive experiments are conducted to demonstrate the superiority of theproposed Mask-IMvC method over state-of-the-art approaches across multiple MvCdatasets, both in complete and incomplete scenarios.</description>
      <author>example@mail.com (Zhenglai Li, Yuqi Shi, Xiao He, Chang Tang)</author>
      <guid isPermaLink="false">2502.02234v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene Analysis</title>
      <link>http://arxiv.org/abs/2502.01785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为AquaticCLIP的新模型，旨在通过对比语言图像预训练来提高水下场景理解的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;保护水生生物多样性对于缓解气候变化的影响至关重要。水下场景的理解在帮助海洋科学家进行决策方面发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;开发一种专门针对水下环境的新型对比语言-图像预训练模型（AquaticCLIP），用于辅助水下场景的任务如分割、分类、检测和物体计数等。&lt;h4&gt;方法&lt;/h4&gt;{'构建数据集': '利用异质资源构建了一个200万对水下图片和文本的数据集，包括YouTube, Netflix, NatGeo等。', '模型设计': 'AquaticCLIP提出了一个无监督学习框架，通过可学习的提示逐步聚合图像块特征，并使用视觉引导机制增强语言编码器以结合视觉上下文。该模型通过对比预训练损失来优化，对齐视觉和文本模态。', '微调策略': '为了微调AquaticCLIP，提出了一种基于提示指导的视觉编码器及一种由视觉驱动的语言编码器强化方法'}&lt;h4&gt;主要发现&lt;/h4&gt;在多种水下计算机视觉任务中，AquaticCLIP在零样本设置下的性能有了显著提高，表现出色且具有更好的鲁棒性和可解释性。&lt;h4&gt;结论&lt;/h4&gt;该模型为水下环境中的视觉-语言应用设立了新的基准，并证明了其在未来研究和实践中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;保护水生生物多样性对于缓解气候变化的影响至关重要。水下场景的理解在帮助海洋科学家进行决策方面发挥着重要作用。在这篇论文中，我们介绍了AquaticCLIP，这是一种为水下场景理解设计的新型对比语言-图像预训练模型。通过我们的大规模水下图文对数据集（无需地面真实标注），该模型丰富了现有的视觉-语言模型，在水生领域取得了显著进步。为了微调AquaticCLIP，我们提出了一种基于提示指导的视觉编码器及一种由视觉驱动的语言编码器强化方法。经过优化后，AquaticCLIP在多种零样本设置下的水下计算机视觉任务中表现出色，超过了现有方法的性能，并且具有更好的鲁棒性和可解释性。我们的模型为水生领域内的视觉-语言应用树立了新的标准。相关代码和数据集可在GitHub上公开获取（地址：xxx）&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The preservation of aquatic biodiversity is critical in mitigating theeffects of climate change. Aquatic scene understanding plays a pivotal role inaiding marine scientists in their decision-making processes. In this paper, weintroduce AquaticCLIP, a novel contrastive language-image pre-training modeltailored for aquatic scene understanding. AquaticCLIP presents a newunsupervised learning framework that aligns images and texts in aquaticenvironments, enabling tasks such as segmentation, classification, detection,and object counting. By leveraging our large-scale underwater image-text paireddataset without the need for ground-truth annotations, our model enrichesexisting vision-language models in the aquatic domain. For this purpose, weconstruct a 2 million underwater image-text paired dataset using heterogeneousresources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP,we propose a prompt-guided vision encoder that progressively aggregates patchfeatures via learnable prompts, while a vision-guided mechanism enhances thelanguage encoder by incorporating visual context. The model is optimizedthrough a contrastive pretraining loss to align visual and textual modalities.AquaticCLIP achieves notable performance improvements in zero-shot settingsacross multiple underwater computer vision tasks, outperforming existingmethods in both robustness and interpretability. Our model sets a new benchmarkfor vision-language applications in underwater environments. The code anddataset for AquaticCLIP are publicly available on GitHub at xxx.</description>
      <author>example@mail.com (Basit Alawode, Iyyakutti Iyappan Ganapathi, Sajid Javed, Naoufel Werghi, Mohammed Bennamoun, Arif Mahmood)</author>
      <guid isPermaLink="false">2502.01785v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Do Graph Diffusion Models Accurately Capture and Generate Substructure Distributions?</title>
      <link>http://arxiv.org/abs/2502.02488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图扩散模型在生成新图时未能准确保持训练集中子结构分布的问题，并提出了一种改进方法，通过使用更先进的图神经网络（GNN）来提高模型的表达能力。&lt;h4&gt;背景&lt;/h4&gt;图扩散模型在图形生成任务中越来越受欢迎，但是它们对复杂图数据分布的学习能力和表达能力仍不完全清楚。现有的流行架构如Graph Transformers无法准确建模这些复杂的图数据分布。&lt;h4&gt;目的&lt;/h4&gt;通过关注特定子结构频率作为目标图分布的关键特性来解决现有图扩散模型的局限性，并改进其生成新图形时保持训练集中子结构数量分布的能力。&lt;h4&gt;方法&lt;/h4&gt;本文建立了图神经网络（GNN）表达能力和图扩散模型整体性能之间的理论联系，证明了使用更富有表现力的GNN作为骨干架构可以更好地捕捉复杂的分布模式。通过将先进的GNN集成到模型中实现了显著改进。&lt;h4&gt;主要发现&lt;/h4&gt;现有图生成模型在保持训练集中观察到的子结构数量分布方面存在不足；更有表达能力的GNN能显著改善这一状况，提高新图形中的子结构生成质量。&lt;h4&gt;结论&lt;/h4&gt;通过采用更先进的图神经网络作为基础架构可以增强图扩散模型的能力，使其更好地建模复杂图数据的分布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have gained popularity in graph generation tasks; however,the extent of their expressivity concerning the graph distributions they canlearn is not fully understood. Unlike models in other domains, popularbackbones for graph diffusion models, such as Graph Transformers, do notpossess universal expressivity to accurately model the distribution scores ofcomplex graph data. Our work addresses this limitation by focusing on thefrequency of specific substructures as a key characteristic of target graphdistributions. When evaluating existing models using this metric, we find thatthey fail to maintain the distribution of substructure counts observed in thetraining set when generating new graphs. To address this issue, we establish atheoretical connection between the expressivity of Graph Neural Networks (GNNs)and the overall performance of graph diffusion models, demonstrating that moreexpressive GNN backbones can better capture complex distribution patterns. Byintegrating advanced GNNs into the backbone architecture, we achievesignificant improvements in substructure generation.</description>
      <author>example@mail.com (Xiyuan Wang, Yewei Liu, Lexi Pang, Siwei Chen, Muhan Zhang)</author>
      <guid isPermaLink="false">2502.02488v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-level Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.02202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的监督对比学习方法，名为多级对比学习(MLCL)，用于处理多标签和层级分类任务。&lt;h4&gt;背景&lt;/h4&gt;传统的对比学习框架在表示学习中广泛应用。然而，现有的方法依赖于单一的投影头，忽略了样本之间的不同方面相似性，导致在数据较少的情况下性能不佳。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的监督对比学习方法来改进传统方法的不足，特别是在多标签和层级分类任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为MLCL的新框架，使用多个投影头捕捉样本之间跨标签或层次结构的不同方面相似性。&lt;h4&gt;主要发现&lt;/h4&gt;通过文本和图像数据集上的广泛实验，所提出的MLCL方法优于现有的对比学习方法。&lt;h4&gt;结论&lt;/h4&gt;多级对比学习(MLCL)是一种有效的监督对比学习方法，能够处理多种类型的分类任务，并且在各种数据集中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;对比学习是表示学习中的一个成熟范式。标准的对比学习框架旨在最小化'相似'实例之间的距离并最大化'不相似'实例之间的距离，忽略两个样本之间可能存在不同方面的相似性。目前的方法依赖于单一投影头，这无法捕捉样本各方面的全部复杂度，在数据有限的情况下导致性能不佳。在本文中，我们提出了一种新的监督对比学习方法，称为多级对比学习(MLCL)，该方法可以应用于多标签和层级分类任务。所提方法的关键优势在于使用多个投影头来捕捉不同标签或层次结构之间的样本相似性。广泛的实验表明，所提出的这种方法优于现有的对比学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning is a well-established paradigm in representationlearning. The standard framework of contrastive learning minimizes the distancebetween "similar" instances and maximizes the distance between dissimilar onesin the projection space, disregarding the various aspects of similarity thatcan exist between two samples. Current methods rely on a single projectionhead, which fails to capture the full complexity of different aspects of asample, leading to suboptimal performance, especially in scenarios with limitedtraining data. In this paper, we present a novel supervised contrastivelearning method in a unified framework called multilevel contrastive learning(MLCL), that can be applied to both multi-label and hierarchical classificationtasks. The key strength of the proposed method is the ability to capturesimilarities between samples across different labels and/or hierarchies usingmultiple projection heads. Extensive experiments on text and image datasetsdemonstrate that the proposed approach outperforms state-of-the-art contrastivelearning methods</description>
      <author>example@mail.com (Naghmeh Ghanooni, Barbod Pajoum, Harshit Rawal, Sophie Fellenz, Vo Nguyen Le Duy, Marius Kloft)</author>
      <guid isPermaLink="false">2502.02202v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Quality-Diversity Algorithms via Meta-Black-Box Optimization</title>
      <link>http://arxiv.org/abs/2502.02190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于元学习的方法来自动寻找新的Quality-Diversity算法，通过使用注意力机制的神经网络架构参数化竞争规则，生成的新算法在性能和泛化能力上都有显著优势。&lt;h4&gt;背景&lt;/h4&gt;Quality-Diversity算法是一类强大的进化算法，能够通过实施受生物进化启发的竞争原则来产生多样化的高质量解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，即使用元学习自动发现新颖的Quality-Diversity算法，以取代传统的启发式策略。&lt;h4&gt;方法&lt;/h4&gt;引入参数化竞争规则的方法，利用注意力机制的神经网络架构来生成新的Quality-Diversity算法，这些新算法能够捕捉描述空间中个体之间的复杂关系。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的元学习框架能自动找到性能优于现有基准的新Quality-Diversity算法；它们在高维度、大规模种群和机器人控制等离散分布领域上表现出了强大的泛化能力，并且即使仅优化适应度，这些新算法也能自然保持多样化的人口。&lt;h4&gt;结论&lt;/h4&gt;通过元学习发现的新型Quality-Diversity算法能够有效捕捉描述空间中的复杂关系，展现出比传统方法更好的性能和更强的泛化能力，这表明多样性对于有效的优化至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Quality-Diversity作为一种强大的进化算法家族已经出现，通过实施基于生物进化的本地竞争原则来生成高质量且多样性的解决方案。尽管这些算法成功地促进多样化与创新，但它们的具体机制依赖于启发式策略，例如MAP-Elites中的网格竞争或无结构档案中最近邻的竞争。本文提出了一种根本不同的方法：利用元学习自动发现新型Quality-Diversity算法。通过使用基于注意力的神经架构参数化竞争规则，我们进化的新的算法能够捕获描述空间中个体之间的复杂关系。我们的新算法相比于已建立的基准显示出竞争力或优越性能，并且在高维度、大规模人口和如机器人控制等离散分布域中展现出强大的泛化能力。值得注意的是，即使仅优化适应度时，这些算法自然保持多样化的人口，这表明元学习重新发现多样性是有效优化的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quality-Diversity has emerged as a powerful family of evolutionary algorithmsthat generate diverse populations of high-performing solutions by implementinglocal competition principles inspired by biological evolution. While thesealgorithms successfully foster diversity and innovation, their specificmechanisms rely on heuristics, such as grid-based competition in MAP-Elites ornearest-neighbor competition in unstructured archives. In this work, we proposea fundamentally different approach: using meta-learning to automaticallydiscover novel Quality-Diversity algorithms. By parameterizing the competitionrules using attention-based neural architectures, we evolve new algorithms thatcapture complex relationships between individuals in the descriptor space. Ourdiscovered algorithms demonstrate competitive or superior performance comparedto established Quality-Diversity baselines while exhibiting stronggeneralization to higher dimensions, larger populations, andout-of-distribution domains like robot control. Notably, even when optimizedsolely for fitness, these algorithms naturally maintain diverse populations,suggesting meta-learning rediscovers that diversity is fundamental to effectiveoptimization.</description>
      <author>example@mail.com (Maxence Faldor, Robert Tjarko Lange, Antoine Cully)</author>
      <guid isPermaLink="false">2502.02190v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective</title>
      <link>http://arxiv.org/abs/2502.01524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对34种视觉大规模语言模型（VLLMs）进行了分类和回顾，着重于从训练范式角度探讨在适应过程中的参数效率。文章首先介绍了大规模语言模型的架构和节省参数的学习方法，然后讨论了视觉编码器以及模态整合器的全面分类，并总结了三种训练范式的效率考虑及其基准测试。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）的发展，多模式学习的研究重点从传统的Vision-Language预训练模型转向了将LLMs与视觉模态结合的方法。然而，现有的综述主要关注于双阶段调优的VLLM，忽视了对训练范式演变及其参数效率的独特考虑的理解。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究在训练范式演进和独特参数效率方面的理解空白，为研究人员提供指导。&lt;h4&gt;方法&lt;/h4&gt;介绍了大规模语言模型架构及节省参数的学习策略，讨论视觉编码器以及模态整合器的全面分类，综述三种训练范式的效率考虑及其基准测试，并复制直接适应范式的实验以比较其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;文章提供了关于VLLM领域内不同训练范式和其效率问题的独特视角。通过将Direct Adaptation范式的效果与现有方法进行对比分析，揭示了参数节省策略的有效性。&lt;h4&gt;结论&lt;/h4&gt;综述为研究人员提供了一个宝贵的指南，帮助他们了解如何在大规模语言模型中高效地整合视觉模态，并推动这一领域的进一步发展。&lt;h4&gt;翻译&lt;/h4&gt;多模式学习中视觉-语言模态的融合已成为一个重要焦点。传统上依赖于Vision-Language预训练模型（VLPM），但随着大型语言模型的发展，研究重点转向了将这些模型与视觉模态结合的方式。此转变催生了训练范式的演变，初期采用单一阶段调优方法整合不同模态，随后演化出强调性能提升的双阶段调优和注重参数效率的直接适应方法。然而，大多数综述专注于后者，忽略了对前者的全面理解。本文系统地回顾并分类了来自顶尖会议、期刊及高引Arxiv论文中的34种VLLM，特别关注在训练范式视角下的适应过程中的参数节省策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of vision-language modalities has been a significant focus inmultimodal learning, traditionally relying on Vision-Language PretrainedModels. However, with the advent of Large Language Models (LLMs), there hasbeen a notable shift towards incorporating LLMs with vision modalities.Following this, the training paradigms for incorporating vision modalities intoLLMs have evolved. Initially, the approach was to integrate the modalitiesthrough pretraining the modality integrator, named Single-stage Tuning. It hassince branched out into methods focusing on performance enhancement, denoted asTwo-stage Tuning, and those prioritizing parameter efficiency, referred to asDirect Adaptation. However, existing surveys primarily address the latestVision Large Language Models (VLLMs) with Two-stage Tuning, leaving a gap inunderstanding the evolution of training paradigms and their uniqueparameter-efficient considerations. This paper categorizes and reviews 34 VLLMsfrom top conferences, journals, and highly cited Arxiv papers, focusing onparameter efficiency during adaptation from the training paradigm perspective.We first introduce the architecture of LLMs and parameter-efficient learningmethods, followed by a discussion on vision encoders and a comprehensivetaxonomy of modality integrators. We then review three training paradigms andtheir efficiency considerations, summarizing benchmarks in the VLLM field. Togain deeper insights into their effectiveness in parameter efficiency, wecompare and discuss the experimental results of representative models, amongwhich the experiment of the Direct Adaptation paradigm is replicated. Providinginsights into recent developments and practical uses, this survey is a vitalguide for researchers and practitioners navigating the efficient integration ofvision modalities into LLMs.</description>
      <author>example@mail.com (Xiaorui Ma, Haoran Xie, S. Joe Qin)</author>
      <guid isPermaLink="false">2502.01524v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Inferring Ambient Cycles of Point Samples on Manifolds with Universal Coverings</title>
      <link>http://arxiv.org/abs/2502.02400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;拓扑数据分析的核心目标是识别在数据点云中具有拓扑意义的特征。本文考虑了这些点样本所在的环境空间是一个紧致黎曼流形的情况。通过构建在点集上的单纯复形，我们可以将该复形的第一同调群与流形的第一同调群相关联。通过对复形中的边进行处理，并将其与两点间的最短测地线相匹配，可以识别这些边缘是否对应于非平凡的循环。&lt;h4&gt;背景&lt;/h4&gt;论文研究的是如何在给定数据点集构建的单纯复形中寻找其第一同调类和环境流形的第一同调类之间的关系。通过利用覆盖空间理论中的群胚（groupoid）结构以及单值化过程，探讨了如何识别一个特定的边循环是否对应于非平凡的基本闭合路径。&lt;h4&gt;目的&lt;/h4&gt;论文旨在提供一种识别单纯复形中的边缘循环与环境流形中非平凡同调类之间关系的方法。通过构造性方法来确定给定的边缘环路（或代表第一同调循环）是否对应到环境流形的一个非平凡的闭合路径（或第一同调类）。&lt;h4&gt;方法&lt;/h4&gt;论文利用了点云数据及其在覆盖空间中的纤维上的度量数据，提出了一个基于群胚理论和单值化过程的方法框架。该方法的核心在于将单纯复形的第一同调与流形本身的第一同调之间建立联系，并通过最短测地线的匹配来识别非平凡循环。&lt;h4&gt;主要发现&lt;/h4&gt;论文证明了在已知流形的通用覆盖空间的情况下，可以构造性地识别出哪些边缘环路（或代表第一同调类）对应于环境流形中的非平凡闭合路径。使用点云数据及其纤维上的度量信息就足够进行这项工作。&lt;h4&gt;结论&lt;/h4&gt;通过引入群胚和单值化的概念框架，论文提供了一种新的方法来解决识别单纯复形与紧致黎曼流形之间同调类关系的问题。该研究为拓扑数据分析中关于复杂几何结构的分析提供了重要的理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A central objective of topological data analysis is to identify topologicallysignificant features in data represented as a finite point cloud. We considerthe setting where the ambient space of the point sample is a compact Riemannianmanifold. Given a simplicial complex constructed on the point set, we canrelate the first homology of the complex with that of the ambient manifold bymatching edges in the complex with minimising geodesics between points.Provided the universal covering of the manifold is known, we give aconstructive method for identifying whether a given edge loop (orrepresentative first homology cycle) on the complex corresponds to anon-trivial loop (or first homology class) of the ambient manifold. We showthat metric data on the point cloud and its fibre in the covering suffices forthe construction, and formalise our approach in the framework of groupoids andmonodromy of coverings.</description>
      <author>example@mail.com (Ka Man Yim)</author>
      <guid isPermaLink="false">2502.02400v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification</title>
      <link>http://arxiv.org/abs/2502.02471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了通用基础模型与专门用于细胞分析等专业任务的领域特定组织病理学基础模型之间的表示学习差距。&lt;h4&gt;背景&lt;/h4&gt;最近，基础模型在计算机视觉领域的进展显著推动了包括数字组织病理学在内的多种领域性能提升。然而，针对专门任务如细胞分析时，领域特定组织病理学基础模型相较于通用模型的优势仍被忽视。&lt;h4&gt;目的&lt;/h4&gt;本研究通过分析应用于细胞实例分割和分类的多层补丁嵌入来探究这两类模型之间的表示学习差距。&lt;h4&gt;方法&lt;/h4&gt;本文实施了编码器-解码器架构，其中包含一致的解码器以及不同的编码器（包括基于卷积、视觉变换器（ViT）和混合编码器）。这些编码器在ImageNet-22K或LVD-142M上预训练，代表通用基础模型。同时比较了从数十万张组织病理学整片图像中提取的补丁训练得到的UNI、Virchow2和Prov-GigaPath基础模型中的ViT编码器。&lt;h4&gt;主要发现&lt;/h4&gt;解码器通过跳过连接整合不同深度的编码器生成语义和距离图。这些地图经过后期处理以创建实例分割掩模，每个标签对应一个单独的细胞，并执行细胞类型分类。评估采用PanNuke和CoNIC组织病理学数据集以及新引入的用于脑细胞结构研究的Nissl染色CytoDArk0数据集，在实例级别检测、分割准确性及细胞类型分类方面进行。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了通用基础模型与领域特定组织病理学基础模型比较的优势和限制的见解，为在以细胞为中心的组织病理学和脑细胞结构分析工作流程中选择模型提供指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in foundation models have transformed computer vision,driving significant performance improvements across diverse domains, includingdigital histopathology. However, the advantages of domain-specifichistopathology foundation models over general-purpose models for specializedtasks such as cell analysis remain underexplored. This study investigates therepresentation learning gap between these two categories by analyzingmulti-level patch embeddings applied to cell instance segmentation andclassification. We implement an encoder-decoder architecture with a consistentdecoder and various encoders. These include convolutional, vision transformer(ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M,representing general-purpose foundation models. These are compared against ViTencoders from the recently released UNI, Virchow2, and Prov-GigaPath foundationmodels, trained on patches extracted from hundreds of thousands ofhistopathology whole-slide images. The decoder integrates patch embeddings fromdifferent encoder depths via skip connections to generate semantic and distancemaps. These maps are then post-processed to create instance segmentation maskswhere each label corresponds to an individual cell and to perform cell-typeclassification. All encoders remain frozen during training to assess theirpre-trained feature extraction capabilities. Using the PanNuke and CoNIChistopathology datasets, and the newly introduced Nissl-stained CytoDArk0dataset for brain cytoarchitecture studies, we evaluate instance-leveldetection, segmentation accuracy, and cell-type classification. This studyprovides insights into the comparative strengths and limitations ofgeneral-purpose vs. histopathology foundation models, offering guidance formodel selection in cell-focused histopathology and brain cytoarchitectureanalysis workflows.</description>
      <author>example@mail.com (Valentina Vadori, Antonella Peruffo, Jean-Marie Graïc, Livio Finos, Enrico Grisan)</author>
      <guid isPermaLink="false">2502.02471v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>SimBEV: A Synthetic Multi-Task Multi-Sensor Driving Data Generation Tool and Dataset</title>
      <link>http://arxiv.org/abs/2502.01894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鸟瞰视角（BEV）感知在自动驾驶领域受到了极大的关注，因为它便于多传感器数据的融合，有助于执行各种感知任务。&lt;h4&gt;目的&lt;/h4&gt;由于现有的数据集不能完全支持这种表示方法，并且创建新数据集需要花费大量时间，因此本文介绍了SimBEV，一个可以生成随机合成数据的数据生成工具。&lt;h4&gt;方法&lt;/h4&gt;SimBEV能够从多个来源获取信息以捕捉准确的BEV地面实况数据，支持广泛的传感器类型，并能执行各种感知任务（如BEV分割和3D目标检测）。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用SimBEV创建了SimBEV数据集，这是一个包含大量注释感知数据的大规模集合，涵盖了多种驾驶场景。&lt;h4&gt;结论&lt;/h4&gt;SimBEV工具及其生成的数据集为自动驾驶研究提供了一个重要的资源。&lt;h4&gt;翻译&lt;/h4&gt;近年来，鸟瞰视角（BEV）在自主驾驶中的感知技术引起了极大关注。这种表示方法使得多传感器数据融合成为可能，并支持包括BEV分割在内的多种任务。然而，现有的数据集无法完全支持这些表示方法的使用，并且创建新数据集需要耗费大量时间。为了解决这个问题，在本文中我们介绍了SimBEV——一个可配置性强且能扩展的数据生成工具。它能够从多个来源获取信息以捕捉准确的BEV地面实况数据，同时还能支持广泛的传感器类型及各种感知任务（例如：BEV分割、3D目标检测等）。利用SimBEV创建了SimBEV数据集，该数据集是一个大规模的注释感知数据集合，并涵盖了多种驾驶场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bird's-eye view (BEV) perception for autonomous driving has garneredsignificant attention in recent years, in part because BEV representationfacilitates the fusion of multi-sensor data. This enables a variety ofperception tasks including BEV segmentation, a concise view of the environmentthat can be used to plan a vehicle's trajectory. However, this representationis not fully supported by existing datasets, and creation of new datasets canbe a time-consuming endeavor. To address this problem, in this paper weintroduce SimBEV, an extensively configurable and scalable randomized syntheticdata generation tool that incorporates information from multiple sources tocapture accurate BEV ground truth data, supports a comprehensive array ofsensors, and enables a variety of perception tasks including BEV segmentationand 3D object detection. We use SimBEV to create the SimBEV dataset, a largecollection of annotated perception data from diverse driving scenarios.</description>
      <author>example@mail.com (Goodarz Mehr, Azim Eskandarian)</author>
      <guid isPermaLink="false">2502.01894v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Convolutional Audio Models are Flexible Acoustic Feature Learners: A Domain Specificity and Transfer-Learning Study</title>
      <link>http://arxiv.org/abs/2502.02366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了自监督学习算法在未标记音频数据上预训练模型的能力，特别是在语音和非语音任务中的表现。结果表明，不同预训练数据集的模型都可以很好地支持各种下游任务，并且这些方法可以作为灵活表示学习的有效方式。&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）算法已经成为了利用大量未标注音频数据来预训练鲁棒表示的强大工具，从而在多种下游任务中表现出色。然而，此前大多数的研究都是分别针对语音和非语音应用进行的。&lt;h4&gt;目的&lt;/h4&gt;探索卷积模型在不同下游语音和非语音任务中的领域特异性，并比较基于自监督预训练方法（BYOL-A）的各种预训练数据集的效果。&lt;h4&gt;方法&lt;/h4&gt;使用BYOL-A方法，对卷积模型进行了针对不同类型预训练数据（包括语音、非语音以及两者结合的数据）的实验，并评估了它们在不同下游任务中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;无论采用何种类型的预训练数据，所有预训练模型都能接近或超越专用领域特定基准模型的表现。仅观察到少量针对特定领域的微小优势差异。这些域特异性模型在目标领域表现出色，但在其他领域则表现欠佳。&lt;h4&gt;结论&lt;/h4&gt;自监督学习方法可以成为学习领域特定数据灵活表示的有效方式，无论是否有标签。这种预训练的模型可能对未来的学习迁移、微调或数据探索应用都非常有用，即使是在存在领域不匹配的情况下也是如此。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的内容包括了关于SSL算法在语音和非语音任务中的研究进展，以及卷积模型在不同下游任务中的表现评估结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) algorithms have emerged as powerful tools thatcan leverage large quantities of unlabeled audio data to pre-train robustrepresentations that support strong performance on diverse downstream tasks. Upto now these have mostly been developed separately for speech and non-speechapplications. Here, we explored the domain specificity of a convolutionalmodel's pre-training data relative to different downstream speech andnon-speech tasks using a self-supervised pre-training approach (BYOL-A). Wefound that these pre-trained models (regardless of whether they werepre-trained on speech data, non-speech data or both) enabled good performanceon nearly all downstream tasks, beating or nearly matching the performance ofpopular domain-specific models. Only small domain-specificity advantages wereobserved between the different pre-training datasets. The populardomain-specific models used as baselines performed very well in their targetdomains, but generally faltered outside of them. Together, these resultsdemonstrate that SSL methods can be a powerful way to learn flexiblerepresentations for domain specific data without labels. These models can be apowerful resource for later transfer learning, fine-tuning or data explorationapplications when the downstream data are similar, but also perhaps when theremay be a domain mismatch.</description>
      <author>example@mail.com (Mattson Ogg)</author>
      <guid isPermaLink="false">2502.02366v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks</title>
      <link>http://arxiv.org/abs/2502.01158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Transactions on Machine Learning Research (01/2025),  https://openreview.net/forum?id=BhOJreYmur&amp;noteId=ymnAhncuez&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于知识蒸馏的多模态模型压缩框架Modality-INformed knowledge Distillation (MIND)，该框架可以将预训练深度神经网络的知识转移到一个较小的多模态学生模型中。&lt;h4&gt;背景&lt;/h4&gt;多模态数据集通常比单模态数据集小，这限制了多模态模型的表现。增加模态数量会导致整个多模态网络变大，在医学应用中这是不可取的。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来优化多模态和单模态表示，并平衡训练期间的多模态学习。&lt;h4&gt;方法&lt;/h4&gt;MIND框架通过使用不同大小预训练模型的知识蒸馏将知识传递给一个较小的多模态学生模型。该框架采用多头联合融合模型，允许在处理单模态样本时直接利用未缺失模态的信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相较于最先进的基线方法，MIND能够在五项任务中提升较小的多模态网络的表现，并且适用于各种融合方式和多模态架构。&lt;h4&gt;结论&lt;/h4&gt;MIND框架能够有效优化多模态模型，在多个医学预测任务以及非医疗领域的多模态数据集上表现出色。&lt;h4&gt;翻译&lt;/h4&gt;多模态融合利用跨模式的信息学习更好的特征表示，旨在提高基于融合的任务性能。然而，多模态数据集通常比单模态数据集小，这可能限制了多模态模型的表现。此外，增加模态的数量往往会导致整个多模态网络变大，在医学应用中这是不可取的。使用较小的单模态编码器可能会导致次优表现，特别是处理高维临床数据时。在本论文中，我们提出了基于知识蒸馏的多模态模型压缩方法Modality-INformed knowledge Distillation (MIND)框架，该框架可以将来自不同大小预训练深度神经网络的知识传递给一个较小的多模态学生模型。教师模型包括单模态网络，使学生可以从多样化的表示中学习。MIND采用多头联合融合模型，而非单一头部模型，这使得在处理单模态样本时可以直接使用单模态编码器，无需对缺失模态进行插值或掩码操作。因此，MIND能够生成优化的多模态模型，增强多模态和单模态表示，并且可以平衡训练期间的多模态学习。我们在二元和多元临床预测任务中评估了MIND框架，这些任务使用时间序列数据和胸部X射线图像。此外，我们还在三个非医疗领域的多模态分类数据集上测试了该框架的一般性表现。实验结果表明，在五项任务、各种融合方法及多模态架构下，与最先进的基线相比，MIND能够提升较小的多模态网络的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal fusion leverages information across modalities to learn betterfeature representations with the goal of improving performance in fusion-basedtasks. However, multimodal datasets, especially in medical settings, aretypically smaller than their unimodal counterparts, which can impede theperformance of multimodal models. Additionally, the increase in the number ofmodalities is often associated with an overall increase in the size of themultimodal network, which may be undesirable in medical use cases. Utilizingsmaller unimodal encoders may lead to sub-optimal performance, particularlywhen dealing with high-dimensional clinical data. In this paper, we propose theModality-INformed knowledge Distillation (MIND) framework, a multimodal modelcompression approach based on knowledge distillation that transfers knowledgefrom ensembles of pre-trained deep neural networks of varying sizes into asmaller multimodal student. The teacher models consist of unimodal networks,allowing the student to learn from diverse representations. MIND employsmulti-head joint fusion models, as opposed to single-head models, enabling theuse of unimodal encoders in the case of unimodal samples without requiringimputation or masking of absent modalities. As a result, MIND generates anoptimized multimodal model, enhancing both multimodal and unimodalrepresentations. It can also be leveraged to balance multimodal learning duringtraining. We evaluate MIND on binary and multilabel clinical prediction tasksusing time series data and chest X-ray images. Additionally, we assess thegeneralizability of the MIND framework on three non-medical multimodalmulticlass datasets. Experimental results demonstrate that MIND enhances theperformance of the smaller multimodal network across all five tasks, as well asvarious fusion methods and multimodal architectures, compared tostate-of-the-art baselines.</description>
      <author>example@mail.com (Alejandro Guerra-Manzanares, Farah E. Shamout)</author>
      <guid isPermaLink="false">2502.01158v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images</title>
      <link>http://arxiv.org/abs/2502.00712v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种全自动MRI-TRUS融合分割方法，用于前列腺癌肿瘤的直接识别，减少了手动注释的需求，并在实际数据集上验证了其优越性。&lt;h4&gt;背景&lt;/h4&gt;前列腺癌是男性癌症死亡的主要原因之一，早期检测可显著提高生存率。尽管MRI-TRUS融合活检通过结合MRI详细可视化和TRUS实时指导提供了更高的准确性，但该过程复杂且耗时，依赖于手动注释可能导致错误。&lt;h4&gt;目的&lt;/h4&gt;开发一种全自动的MRI-TRUS融合方法，用于前列腺癌肿瘤识别，以提高精度并减少人为误差。&lt;h4&gt;方法&lt;/h4&gt;提出了一种将配准和分割集成到同一框架的方法，利用了MRI和TRUS模态之间的空间信息。该方法在斯坦福医院1747名患者的图像数据集上进行了验证。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法实现了0.212的平均Dice系数，在前列腺癌肿瘤识别中优于单独使用TRUS（0.117）和简单的MRI-TRUS融合方法（0.132），且差异具有统计学意义(p &lt; 0.01)。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架展示了减少前列腺癌诊断复杂性的潜力，并提供了一个适用于其他多模态医学成像任务的灵活架构。&lt;h4&gt;翻译&lt;/h4&gt;前列腺癌是男性癌症相关死亡的主要原因，早期检测能显著提高生存率。尽管MRI-TRUS融合活检通过结合MRI详细可视化和超声实时引导提供了更高的准确性，但由于其复杂且耗时，并严重依赖于手动注释而可能导致错误。为解决这些问题，我们提出了一种全自动的MRI-TRUS融合分割方法，能够在不依赖手动注释的情况下直接在超声图像中识别前列腺肿瘤。不同于传统的多模态融合技术，我们的方法集成了配准和分割框架以对齐并利用两种模式之间的空间信息。这种对齐提高了分割精度，并减少了人工参与的需求。该方案在斯坦福医院1747名患者的数据集中进行了验证，平均Dice系数为0.212，超越了单独使用超声（0.117）和简单的MRI-TRUS融合方法（0.132），差异显著（p &lt; 0.01）。此框架展示了减少前列腺癌诊断复杂性的潜力，并提供了一个适用于其他多模态医学成像任务的灵活架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prostate cancer is a major cause of cancer-related deaths in men, where earlydetection greatly improves survival rates. Although MRI-TRUS fusion biopsyoffers superior accuracy by combining MRI's detailed visualization with TRUS'sreal-time guidance, it is a complex and time-intensive procedure that reliesheavily on manual annotations, leading to potential errors. To address thesechallenges, we propose a fully automatic MRI-TRUS fusion-based segmentationmethod that identifies prostate tumors directly in TRUS images withoutrequiring manual annotations. Unlike traditional multimodal fusion approachesthat rely on naive data concatenation, our method integrates aregistration-segmentation framework to align and leverage spatial informationbetween MRI and TRUS modalities. This alignment enhances segmentation accuracyand reduces reliance on manual effort. Our approach was validated on a datasetof 1,747 patients from Stanford Hospital, achieving an average Dice coefficientof 0.212, outperforming TRUS-only (0.117) and naive MRI-TRUS fusion (0.132)methods, with significant improvements (p $&lt;$ 0.01). This frameworkdemonstrates the potential for reducing the complexity of prostate cancerdiagnosis and provides a flexible architecture applicable to other multimodalmedical imaging tasks.</description>
      <author>example@mail.com (Shengtian Sang, Hassan Jahanandish, Cynthia Xinran Li, Indrani Bhattachary, Jeong Hoon Lee, Lichun Zhang, Sulaiman Vesal, Pejman Ghanouni, Richard Fan, Geoffrey A. Sonn, Mirabela Rusu)</author>
      <guid isPermaLink="false">2502.00712v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation</title>
      <link>http://arxiv.org/abs/2502.02340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;如何减轻迁移学习中的负向转移是一个长期且具有挑战性的问题，尤其是在医学图像分割的应用中。现有的减少负向转移的方法主要集中在分类或回归任务上，并忽略了不同图像区域中存在的非均匀负向转移风险。&lt;h4&gt;背景&lt;/h4&gt;迁移学习的负向转移问题在医学图像分割领域尤为突出，因为现有方法大多针对分类和回归任务设计，并未充分考虑不同图像区域内潜在的负向转移风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单而有效的方法来减少医学语义分割中的负向转移，特别是在处理跨模式和任务时的情况。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于迁移引导的风险图（transferability-guided transfer risk map）的方法，该方法能够量化每个像素的迁移难度及潜在的负向转移风险。在微调阶段，使用了风险地图加权损失函数，并通过将图像前景大小归一化来解决类别不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在脑分割数据集上应用所提出的方法可以显著提高目标任务性能：FeTS2021提高了4.37%，iSeg2019提高了1.81%。此外，该方法在少量样本场景下验证了其鲁棒性（提升了2.9%）。&lt;h4&gt;结论&lt;/h4&gt;通过上述实验结果表明，所提出的加权微调策略能够有效避免跨模式和任务的负向迁移，并且展示了良好的性能提升潜力。&lt;h4&gt;翻译&lt;/h4&gt;如何减轻迁移学习中的负向转移是一个长期存在的挑战，尤其是在医学图像分割领域。现有方法主要集中在分类或回归任务上，忽视了不同图像区域中存在的非均匀负向转移风险。本文提出了一种简单而有效的方法，通过引入一个基于迁移引导的风险图来量化每个像素的迁移难度及潜在风险，并在微调阶段使用加权损失函数解决了类别不平衡的问题。实验表明该方法在脑分割数据集中表现出显著性能提升，在FeTS2021和iSeg2019数据集上分别提高了4.37%和1.81%，并且在少量样本条件下也展示了鲁棒性（提升了2.9%）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How to mitigate negative transfer in transfer learning is a long-standing andchallenging issue, especially in the application of medical image segmentation.Existing methods for reducing negative transfer focus on classification orregression tasks, ignoring the non-uniform negative transfer risk in differentimage regions. In this work, we propose a simple yet effective weightedfine-tuning method that directs the model's attention towards regions withsignificant transfer risk for medical semantic segmentation. Specifically, wecompute a transferability-guided transfer risk map to quantify the transferhardness for each pixel and the potential risks of negative transfer. Duringthe fine-tuning phase, we introduce a map-weighted loss function, normalizedwith image foreground size to counter class imbalance. Extensive experiments onbrain segmentation datasets show our method significantly improves the targettask performance, with gains of 4.37% on FeTS2021 and 1.81% on iSeg2019,avoiding negative transfer across modalities and tasks. Meanwhile, a 2.9% gainunder a few-shot scenario validates the robustness of our approach.</description>
      <author>example@mail.com (Shutong Duan, Jingyun Yang, Yang Tan, Guoqing Zhang, Yang Li, Xiao-Ping Zhang)</author>
      <guid isPermaLink="false">2502.02340v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>GP-GS: Gaussian Processes for Enhanced Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2502.02283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个新的三维重建框架Gaussian Processes Gaussian Splatting (GP-GS)，旨在通过多输出高斯过程模型来提高稀疏Structure-from-Motion点云的密度，从而改善场景重建质量。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting是一种高效的逼真视图合成方法，但它依赖于稀疏的结构从运动(SfM)点云，这会损害场景重建的质量。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的三维重建框架GP-GS来解决现有技术对稀疏SfM点云依赖的问题，并通过改进点云密度提高重建质量。&lt;h4&gt;方法&lt;/h4&gt;采用多输出高斯过程模型预测新候选点以扩充SfM点云，利用不确定性估计指导高方差预测的修剪工作，确保几何一致性并生成稠密点云。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够自适应地稀疏SfM点云进行密度化，并通过高质量初始3D高斯分布来增强重建性能。实验验证了所提方法的有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;GP-GS框架在合成和真实世界数据集上的表现表明，它能够在不同规模下改善场景的三维重建质量。&lt;h4&gt;翻译&lt;/h4&gt;3D Gaussian Splatting作为一种高效的逼真视图合成方法已经出现，但是其依赖于稀疏的结构从运动(SfM)点云会持续影响场景的重建质量。为了克服这些限制，本文提出了一种新的三维重建框架Gaussian Processes Gaussian Splatting (GP-GS)，其中开发了一个多输出高斯过程模型来实现对稀疏SfM点云的自适应和不确定性指导下的稠密化。具体来说，我们提出了一个动态采样和过滤流水线，通过利用基于GP的预测从输入2D像素和深度图中推理出新的候选点来自适应地扩展SfM点云。该流水线使用不确定性估计来引导高方差预测的修剪工作，确保几何一致性并生成稠密点云。这些稠密化后的点云提供高质量初始3D高斯分布以增强重建性能。在合成和真实世界数据集上进行广泛的实验验证了所提框架的有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting has emerged as an efficient photorealistic novel viewsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)point clouds consistently compromises the scene reconstruction quality. Toaddress these limitations, this paper proposes a novel 3D reconstructionframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-outputGaussian Process model is developed to achieve adaptive and uncertainty-guideddensification of sparse SfM point clouds. Specifically, we propose a dynamicsampling and filtering pipeline that adaptively expands the SfM point clouds byleveraging GP-based predictions to infer new candidate points from the input 2Dpixels and depth maps. The pipeline utilizes uncertainty estimates to guide thepruning of high-variance predictions, ensuring geometric consistency andenabling the generation of dense point clouds. The densified point cloudsprovide high-quality initial 3D Gaussians to enhance reconstructionperformance. Extensive experiments conducted on synthetic and real-worlddatasets across various scales validate the effectiveness and practicality ofthe proposed framework.</description>
      <author>example@mail.com (Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Liangxiu Han, Peng Wang)</author>
      <guid isPermaLink="false">2502.02283v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Poisson Process AutoDecoder for X-ray Sources</title>
      <link>http://arxiv.org/abs/2502.01627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的神经网络模型Poisson Process AutoDecoder (PPAD)，该模型通过无监督学习将固定长度的潜在特征映射为连续的泊松率函数，适用于X射线天文观测数据处理。&lt;h4&gt;背景&lt;/h4&gt;高能现象相关的天文源数量庞大，其光子到达时间遵循泊松过程，并且具有很大变化。这给天文数据的任务如来源分类、物理属性推导和异常检测带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够直接捕捉数据的泊松特性并同时进行率函数重构和表示学习的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为Poisson Process AutoDecoder (PPAD)的新模型，这是一种神经场解码器，它通过无监督学习将固定长度的潜在特征映射为连续的泊松率函数。该模型不仅可以重建率函数，还能生成有效的数据表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过对Chandra Source Catalog的数据进行重构、回归、分类和异常检测实验来证明PPAD的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的PPAD模型在处理天文观测中的高能现象数据时表现出色，能够有效克服现有方法的局限，并且可以应用到更广泛的任务中。&lt;h4&gt;翻译&lt;/h4&gt;X射线观测设施，如钱德拉X射线天文台和eROSITA，已经检测到了数百万与高能现象相关的天文物源。光子到达时间作为时间函数遵循泊松过程，并且变化幅度很大，这为常见任务（例如来源分类、物理属性推导和异常检测）带来了挑战。以往的工作要么未能直接捕捉数据的泊松特性，要么只关注泊松率函数重建。在这项工作中，我们提出了一种名为Poisson Process AutoDecoder (PPAD)的新方法。PPAD是一种神经场解码器，它通过无监督学习将固定长度的潜在特征映射为连续的泊松率函数，在能量带和时间上进行。PPAD不仅能够重建率函数，还能生成有效表示。我们使用钱德拉源目录数据进行了重构、回归、分类及异常检测实验来证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; X-ray observing facilities, such as the Chandra X-ray Observatory and theeROSITA, have detected millions of astronomical sources associated withhigh-energy phenomena. The arrival of photons as a function of time follows aPoisson process and can vary by orders-of-magnitude, presenting obstacles forcommon tasks such as source classification, physical property derivation, andanomaly detection. Previous work has either failed to directly capture thePoisson nature of the data or only focuses on Poisson rate functionreconstruction. In this work, we present Poisson Process AutoDecoder (PPAD).PPAD is a neural field decoder that maps fixed-length latent features tocontinuous Poisson rate functions across energy band and time via unsupervisedlearning. PPAD reconstructs the rate function and yields a representation atthe same time. We demonstrate the efficacy of PPAD via reconstruction,regression, classification and anomaly detection experiments using the ChandraSource Catalog.</description>
      <author>example@mail.com (Yanke Song, Victoria Ashley Villar, Juan Rafael Martinez-Galarza, Steven Dillmann)</author>
      <guid isPermaLink="false">2502.01627v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Using Random Noise Equivariantly to Boost Graph Neural Networks Universally</title>
      <link>http://arxiv.org/abs/2502.02479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;近年来，图神经网络（GNNs）通过探索随机噪声作为输入特征来增强表达能力以应对多样任务的潜力。然而，直接加入噪声可能会降低性能，而针对特定任务优化的设计又缺乏广泛适用性。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明，在GNN中引入随机噪声能够提升其在不同任务中的表现力，但未经精心设计的噪声添加会导致性能下降；而专门为了利用噪声效果进行结构化改进的方法虽然能解决特定问题却不能普遍应用。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过建立一个理论框架来说明未加小心地向GNN引入随机噪声时样本复杂度增加的原因，并提出一种新的架构Equivariant Noise GNN (ENGNN) 以减小样本复杂性并增强泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了Equivairent Noise GNN（ENGNN）这一新架构，该架构利用了噪声的对称特性来降低样本复杂度并且加强模型在不同任务上的泛化性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用等变噪声显著提升了节点级别、链接级别、子图和全图级别的任务表现，并且其性能能够媲美专门为特定任务设计的模型。&lt;h4&gt;结论&lt;/h4&gt;ENGNN提供了一种通用方法来提升GNN在各种图形任务上的表达能力，为解决引入随机噪声时样本复杂度增加的问题提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Graph Neural Networks (GNNs) have explored the potentialof random noise as an input feature to enhance expressivity across diversetasks. However, naively incorporating noise can degrade performance, whilearchitectures tailored to exploit noise for specific tasks excel yet lack broadapplicability. This paper tackles these issues by laying down a theoreticalframework that elucidates the increased sample complexity when introducingrandom noise into GNNs without careful design. We further propose EquivariantNoise GNN (ENGNN), a novel architecture that harnesses the symmetricalproperties of noise to mitigate sample complexity and bolster generalization.Our experiments demonstrate that using noise equivariantly significantlyenhances performance on node-level, link-level, subgraph, and graph-level tasksand achieves comparable performance to models designed for specific tasks,thereby offering a general method to boost expressivity across various graphtasks.</description>
      <author>example@mail.com (Xiyuan Wang, Muhan Zhang)</author>
      <guid isPermaLink="false">2502.02479v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion</title>
      <link>http://arxiv.org/abs/2502.00695v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, accepted by IEEE ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Triple-Modal Interaction Chronic Liver Network (TMI-CLNet)的方法，用于慢性肝病预后的综合评估。&lt;h4&gt;背景&lt;/h4&gt;慢性肝病是全球重大的健康挑战之一，准确的预后评价对于个性化治疗方案至关重要。研究表明，结合多模态数据可以提供更全面的预后信息。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在融合更多医学模态时难以适应和捕捉跨模态关系的问题，本研究提出了一种新的网络架构。&lt;h4&gt;方法&lt;/h4&gt;提出了Intra-Modality Aggregation模块和Triple-Modal Cross-Attention Fusion模块，旨在消除同模态冗余并提取跨模态信息。还设计了Triple-Modal Feature Fusion损失函数来对齐不同模态的特征表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过在肝病预后数据集上的大量实验表明，本方法显著优于现有的单一模态模型和其他多模态技术。&lt;h4&gt;结论&lt;/h4&gt;TMI-CLNet提供了一种有效的方法来解决慢性肝病预后的异质性问题，并提高了跨模态融合的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：慢性肝病在全球范围内是一个重要的健康挑战，准确的预后评估对于个性化的治疗方案至关重要。最近的研究表明，整合多模态数据（如计算机断层扫描成像、影像组学特征和临床信息）可以提供更全面的预后信息。然而，各种模态之间存在固有的异质性，并且引入更多的模态可能会加剧异质性数据融合的问题。此外，现有的多模态融合方法通常难以适应更丰富的医学模态，从而难以捕捉跨模态关系。为了解决这些限制，我们提出了Triple-Modal Interaction Chronic Liver Network (TMI-CLNet)。具体而言，我们开发了Intra-Modality Aggregation模块和Triple-Modal Cross-Attention Fusion模块，旨在消除同模态冗余并提取跨模态信息。此外，我们设计了一个Triple-Modal Feature Fusion损失函数来对齐不同模态的特征表示。在肝病预后数据集上的大量实验表明，我们的方法显著优于现有的单模态模型和其他多模态技术。我们的代码可在https://github.com/Mysterwll/liver.git获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chronic liver disease represents a significant health challenge worldwide andaccurate prognostic evaluations are essential for personalized treatment plans.Recent evidence suggests that integrating multimodal data, such as computedtomography imaging, radiomic features, and clinical information, can providemore comprehensive prognostic information. However, modalities have an inherentheterogeneity, and incorporating additional modalities may exacerbate thechallenges of heterogeneous data fusion. Moreover, existing multimodal fusionmethods often struggle to adapt to richer medical modalities, making itdifficult to capture inter-modal relationships. To overcome these limitations,We present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).Specifically, we develop an Intra-Modality Aggregation module and aTriple-Modal Cross-Attention Fusion module, which are designed to eliminateintra-modality redundancy and extract cross-modal information, respectively.Furthermore, we design a Triple-Modal Feature Fusion loss function to alignfeature representations across modalities. Extensive experiments on the liverprognosis dataset demonstrate that our approach significantly outperformsexisting state-of-the-art unimodal models and other multi-modal techniques. Ourcode is available at https://github.com/Mysterwll/liver.git.</description>
      <author>example@mail.com (Linglong Wu, Xuhao Shan, Ruiquan Ge, Ruoyu Liang, Chi Zhang, Yonghong Li, Ahmed Elazab, Huoling Luo, Yunbi Liu, Changmiao Wang)</author>
      <guid isPermaLink="false">2502.00695v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning</title>
      <link>http://arxiv.org/abs/2502.02048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了将基础模型的多模态嵌入适应到下游任务的新方法，以克服资源受限环境中高性能和易用性之间的差距。&lt;h4&gt;背景&lt;/h4&gt;机器学习、自然语言处理和基础模型在医疗等计算资源有限的关键领域显示出应用潜力。然而，在这些环境下使用预训练模型进行特定任务调整或者精细调优都需要大量计算资源，这使得它们难以应用于性能要求高而计算资源稀缺的场景中。&lt;h4&gt;目的&lt;/h4&gt;为了弥合最佳性能与可访问性之间的差距，提出了一种新的方法，该方法可以在不进行昂贵的微调过程的情况下，将基础模型的多模态嵌入适应到下游任务上。&lt;h4&gt;方法&lt;/h4&gt;该方法利用了大型语言模型和视觉模型中的冻结嵌入，并通过对比学习训练一个小规模的任务特定非线性投影器来完成这一目标。这种方法不需要对原始的基础模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与不使用任务特定适应的预训练模型相比，以及与需要大量计算资源的传统微调方法相比，该新方法在各种下游任务中都能获得显著性能提升，并且具有极低的计算开销。&lt;h4&gt;结论&lt;/h4&gt;这种方法为在资源受限设置下利用先进基础机器学习模型提供了一个实用解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in machine learning (ML), natural language processing(NLP), and foundational models have shown promise for real-life applications incritical, albeit compute-constrainted fields like healthcare.  In such areas, combining foundational models with supervised ML offerspotential for automating tasks like diagnosis and treatment planning, but thelimited availability of onsite computational resources pose significantchallenges before applying these technologies effectively: Current approacheseither yield subpar results when using pretrained models without task-specificadaptation, or require substantial computational resources for fine-tuning,which is often a barrier to entry in such environments.  This renders them inaccessible in applications where performance and qualitystandards are high, but computational resources are scarce.  To bridge the gap between best-in-class performance and accessibility, wepropose a novel method for adapting foundational, multimodal embeddings todownstream tasks, without the need of expensive fine-tuning processes.  Our method leverages frozen embeddings from Large Language Models (LLMs) andVision Models, and uses contrastive learning to train a small, task-specificnonlinear projection that can be used in the downstream task, without having tofine-tune the original foundational models.  We show that this efficient procedure leads to significant performanceimprovements across various downstream tasks, and perhaps more importantly withminimal computational overhead, offering a practical solution for the use ofadvanced, foundational ML models in resource-constrained settings.</description>
      <author>example@mail.com (Georgios Margaritis, Periklis Petridis, Dimitris J. Bertsimas)</author>
      <guid isPermaLink="false">2502.02048v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards graph neural networks for provably solving convex optimization problems</title>
      <link>http://arxiv.org/abs/2502.02446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种迭代消息传递图神经网络框架，用于解决带线性约束的二次优化问题，并且能保证解的可行性。&lt;h4&gt;背景&lt;/h4&gt;现有的方法利用消息传递图神经网络（MPNN）来近似求解或者作为传统求解器的初始点，但在凸优化中缺乏可行性的保证。&lt;h4&gt;目的&lt;/h4&gt;提出一种迭代的MPNN框架解决凸优化问题，并提供可证明的可行性保证。&lt;h4&gt;方法&lt;/h4&gt;1. 证明MPNN可以模拟标准内点法来解决带线性约束的二次优化问题；2. 引入从可行点开始并逐步限制搜索范围在可行区域内的变体，确保解的可行性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该方法在解决方案质量和可行性方面优于现有神经网络基线，在某些情况下甚至比Gurobi等最先进的求解器更快地找到解答。&lt;h4&gt;结论&lt;/h4&gt;提出的迭代MPNN框架能够有效地解决凸优化问题，并且具有较好的泛化能力，能够在未见过的问题规模上表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, message-passing graph neural networks (MPNNs) have shown potentialfor solving combinatorial and continuous optimization problems due to theirability to capture variable-constraint interactions. While existing approachesleverage MPNNs to approximate solutions or warm-start traditional solvers, theyoften lack guarantees for feasibility, particularly in convex optimizationsettings. Here, we propose an iterative MPNN framework to solve convexoptimization problems with provable feasibility guarantees. First, wedemonstrate that MPNNs can provably simulate standard interior-point methodsfor solving quadratic problems with linear constraints, covering relevantproblems such as SVMs. Secondly, to ensure feasibility, we introduce a variantthat starts from a feasible point and iteratively restricts the search withinthe feasible region. Experimental results show that our approach outperformsexisting neural baselines in solution quality and feasibility, generalizes wellto unseen problem sizes, and, in some cases, achieves faster solution timesthan state-of-the-art solvers such as Gurobi.</description>
      <author>example@mail.com (Chendi Qian, Christopher Morris)</author>
      <guid isPermaLink="false">2502.02446v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation</title>
      <link>http://arxiv.org/abs/2502.02489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种针对B模式超声（US）图像的对比自监督学习(RCL)方法，该方法在数据受限条件下特别是在公共乳腺US数据库上的分割任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;超声成像由于其非侵入性和安全性，在临床诊断中非常重要。然而，解释超声图像需要大量的专业知识和时间，并且容易出错。深度学习为辅助解决方案提供了一种途径，如分割技术。但监督方法依赖于大型高质量标注数据集，这很难获得。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用未标记数据增强模型性能和泛化的对比自监督学习(RCL)方法，以解决超声图像分割中数据缺乏的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的对比损失函数（Relation Contrastive Loss, RCL），通过可学习的度量标准区分正样本与负样本对来促进特征学习。此外还提出基于空间和频率的增强策略用于超声图像表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个公共乳腺US数据集上显著优于传统监督分割方法，尤其是在数据有限的情况下。例如，在DICE相似度指标中分别提高了4%，5.9%和6.4%等。此外，其在外来分布的UDIAT数据集中显示出更好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，领域启发式的自监督学习可以改善超声图像分割性能，特别是在数据有限的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultrasound (US) imaging is clinically invaluable due to its noninvasive andsafe nature. However, interpreting US images is challenging, requiressignificant expertise, and time, and is often prone to errors. Deep learningoffers assistive solutions such as segmentation. Supervised methods rely onlarge, high-quality, and consistently labeled datasets, which are challengingto curate. Moreover, these methods tend to underperform on out-of-distributiondata, limiting their clinical utility. Self-supervised learning (SSL) hasemerged as a promising alternative, leveraging unlabeled data to enhance modelperformance and generalisability. We introduce a contrastive SSL approachtailored for B-mode US images, incorporating a novel Relation Contrastive Loss(RCL). RCL encourages learning of distinct features by differentiating positiveand negative sample pairs through a learnable metric. Additionally, we proposespatial and frequency-based augmentation strategies for the representationlearning on US images. Our approach significantly outperforms traditionalsupervised segmentation methods across three public breast US datasets,particularly in data-limited scenarios. Notable improvements on the Dicesimilarity metric include a 4% increase on 20% and 50% of the BUSI dataset,nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4%and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.Furthermore, we demonstrate superior generalisability on theout-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6%compared to the supervised baseline using 20% and 50% of the BUSI and BrEaSTtraining data, respectively. Our research highlights that domain-inspired SSLcan improve US segmentation, especially under data-limited conditions.</description>
      <author>example@mail.com (Edward Ellis, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali)</author>
      <guid isPermaLink="false">2502.02489v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>INTACT: Inducing Noise Tolerance through Adversarial Curriculum Training for LiDAR-based Safety-Critical Perception and Autonomy</title>
      <link>http://arxiv.org/abs/2502.01896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;INTACT是一种针对增强深度神经网络在3D点云数据中的鲁棒性的两阶段框架，通过结合元学习和对抗课程训练来解决由于数据损坏和稀疏性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;目前的模型难以处理安全关键任务中存在噪声干扰的数据，尤其是在自动驾驶场景下对3D点云的理解问题。传统的抗噪方法效果有限。&lt;h4&gt;目的&lt;/h4&gt;提出INTACT框架以提高深度神经网络在安全性至关重要的感知任务中的鲁棒性，特别是在存在噪音的情况下。&lt;h4&gt;方法&lt;/h4&gt;INTACT包括元学习阶段和对抗课程训练（ACT）阶段。元学习阶段使教师网络获取任务无关的先验知识来生成健壮性的注意力图；ACT阶段使用这些注意力图逐步向学生模型引入更复杂的噪声模式。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI、Argoverse和ModelNet40等数据集上的全面评估显示，INTACT框架提高了20%以上的模型鲁棒性，特别是在物体跟踪任务中提升显著。&lt;h4&gt;结论&lt;/h4&gt;INTACT提出了一种新的抗噪3D感知训练方法，为安全关键应用提供了一个有效的解决方案，并且在现实世界的应用中表现出色，尤其适用于资源受限的系统。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了INTACT，这是一种针对提高深度神经网络对噪声LiDAR数据鲁棒性的新型两阶段框架。该框架结合了元学习和对抗课程训练（ACT）来解决3D点云中的数据损坏和稀疏性带来的挑战...&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we present INTACT, a novel two-phase framework designed toenhance the robustness of deep neural networks (DNNs) against noisy LiDAR datain safety-critical perception tasks. INTACT combines meta-learning withadversarial curriculum training (ACT) to systematically address challengesposed by data corruption and sparsity in 3D point clouds. The meta-learningphase equips a teacher network with task-agnostic priors, enabling it togenerate robust saliency maps that identify critical data regions. The ACTphase leverages these saliency maps to progressively expose a student networkto increasingly complex noise patterns, ensuring targeted perturbation andimproved noise resilience. INTACT's effectiveness is demonstrated throughcomprehensive evaluations on object detection, tracking, and classificationbenchmarks using diverse datasets, including KITTI, Argoverse, and ModelNet40.Results indicate that INTACT improves model robustness by up to 20% across alltasks, outperforming standard adversarial and curriculum training methods. Thisframework not only addresses the limitations of conventional trainingstrategies but also offers a scalable and efficient solution for real-worlddeployment in resource-constrained safety-critical systems. INTACT's principledintegration of meta-learning and adversarial training establishes a newparadigm for noise-tolerant 3D perception in safety-critical applications.INTACT improved KITTI Multiple Object Tracking Accuracy (MOTA) by 9.6% (64.1%-&gt; 75.1%) and by 12.4% under Gaussian noise (52.5% -&gt; 73.7%). Similarly, KITTImean Average Precision (mAP) rose from 59.8% to 69.8% (50% point drop) and49.3% to 70.9% (Gaussian noise), highlighting the framework's ability toenhance deep learning model resilience in safety-critical object trackingscenarios.</description>
      <author>example@mail.com (Nastaran Darabi, Divake Kumar, Sina Tayebati, Amit Ranjan Trivedi)</author>
      <guid isPermaLink="false">2502.01896v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Personalization Toolkit: Training Free Personalization of Large Vision Language Models</title>
      <link>http://arxiv.org/abs/2502.02452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型视觉语言模型（LVLM）具有通过适应个人用户的独特需求和偏好提供个性化服务的巨大潜力。本文提出了一种无需训练的方法，利用预训练的视觉基础模型、检索增强生成技术和视觉提示方法来实现LVLM的个性化。&lt;h4&gt;背景&lt;/h4&gt;现有的LVLM个性化方法依赖于针对每个用户和对象的时间消耗型测试时间训练，这使得这些方法在实际应用中难以实施。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需重新训练的方法，使大型视觉语言模型能够更加灵活、高效地进行个性化设置。&lt;h4&gt;方法&lt;/h4&gt;利用预训练的视觉基础模型提取独特特征；使用检索增强生成技术（RAG）来识别视觉输入中的实例；采用视觉提示技术；并设计了一种与模型无关的视觉工具包，以支持无需大量重新训练的个性化调整。&lt;h4&gt;主要发现&lt;/h4&gt;该论文展示的方法在LVLM个性化方面取得了当前最佳的结果，并且超过了基于传统训练方法的性能表现。&lt;h4&gt;结论&lt;/h4&gt;这项研究为LVLM的个性化提供了新的标准，使得个人化服务能够更加灵活高效地提供给用户。&lt;h4&gt;翻译&lt;/h4&gt;大型视觉语言模型（LVLM）通过适应个体用户的独特需求和偏好，在提供个性化的帮助方面具有巨大的潜力。LVLM的个性化是一个新兴领域，涉及定制模型以识别特定的对象实例并提供定制响应。然而，现有的方法依赖于为每个用户和对象进行耗时的测试时间训练，这使得它们在实践中不切实际。本文提出了一种新颖且无需训练的方法来实现LVLM的个性化，通过利用预训练的视觉基础模型提取独特的特征、检索增强生成技术（RAG）识别视觉输入中的实例以及视觉提示方法。我们的与模型无关的视觉工具包使灵活而高效的个性化成为可能，而不需要广泛的再训练。我们展示了最先进的结果，并且优于传统的基于训练的方法，为LVLM的个性化设定了新的标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Vision Language Models (LVLMs) have significant potential to deliverpersonalized assistance by adapting to individual users' unique needs andpreferences. Personalization of LVLMs is an emerging area that involvescustomizing models to recognize specific object instances and provide tailoredresponses. However, existing approaches rely on time-consuming test-timetraining for each user and object, rendering them impractical. This paperproposes a novel, training-free approach to LVLM personalization by leveragingpre-trained vision foundation models to extract distinct features,retrieval-augmented generation (RAG) techniques to recognize instances in thevisual input, and visual prompting methods. Our model-agnostic vision toolkitenables flexible and efficient personalization without extensive retraining. Wedemonstrate state-of-the-art results, outperforming conventional training-basedapproaches and establish a new standard for LVLM personalization.</description>
      <author>example@mail.com (Soroush Seifi, Vaggelis Dorovatas, Daniel Olmeda Reino, Rahaf Aljundi)</author>
      <guid isPermaLink="false">2502.02452v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Reliability-Driven LiDAR-Camera Fusion for Robust 3D Object Detection</title>
      <link>http://arxiv.org/abs/2502.01856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种用于自动驾驶的可靠LiDAR-相机融合框架ReliFusion。&lt;h4&gt;背景&lt;/h4&gt;精确且鲁棒的3D物体检测对于自动驾驶至关重要，传感器数据（如激光雷达和相机）的融合可以提高检测精度。然而，传感器故障可能会降低性能，并且现有融合模型在单一模式失效时难以保持可靠性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的LiDAR-相机融合框架ReliFusion，以解决现有的融合模型在单一模式故障下无法保持可靠性的挑战。&lt;h4&gt;方法&lt;/h4&gt;ReliFusion框架包括三个关键组件：时空特征聚合（STFA）模块、可靠性模块和置信度加权互交叉注意（CW-MCA）模块。这些组件使ReliFusion能够在鸟瞰图空间中操作，同时动态平衡来自LiDAR和相机模态的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验显示，与现有的方法相比，ReliFusion显著提高了鲁棒性和准确性，在有限的LiDAR视场和严重的传感器故障下表现出色。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为自动驾驶中的3D物体检测提供了一种新的有效途径。通过集成三个关键组件，ReliFusion能够在各种场景中保持高度可靠且准确的表现。&lt;h4&gt;翻译&lt;/h4&gt;精确且鲁棒的三维目标检测对于自主驾驶至关重要，其中将来自激光雷达和相机等传感器的数据融合可以提高检测精度。然而，诸如数据损坏或断开之类的传感器故障会降低性能，并且现有的融合模型往往难以在单一模态失效时保持可靠性。为了应对这一挑战，我们提出了ReliFusion，这是一个新的激光雷达-摄像机融合框架，在鸟瞰图（BEV）空间中操作。ReliFusion整合了三个关键组成部分：时空特征聚合（STFA）模块，通过捕获帧间的依赖性来稳定时间上的预测；可靠性模块，它为每个模态在困难条件下的可信赖度分配信心分数；以及置信加权互注意力（CW-MCA）模块，根据这些信心评分动态平衡来自激光雷达和相机模式的信息。在nuScenes数据集上的实验表明，ReliFusion显著超越了最先进的方法，在具有有限激光雷达视野和严重传感器故障的场景中实现了卓越的可靠性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust 3D object detection is essential for autonomous driving,where fusing data from sensors like LiDAR and camera enhances detectionaccuracy. However, sensor malfunctions such as corruption or disconnection candegrade performance, and existing fusion models often struggle to maintainreliability when one modality fails. To address this, we propose ReliFusion, anovel LiDAR-camera fusion framework operating in the bird's-eye view (BEV)space. ReliFusion integrates three key components: the Spatio-Temporal FeatureAggregation (STFA) module, which captures dependencies across frames tostabilize predictions over time; the Reliability module, which assignsconfidence scores to quantify the dependability of each modality underchallenging conditions; and the Confidence-Weighted Mutual Cross-Attention(CW-MCA) module, which dynamically balances information from LiDAR and cameramodalities based on these confidence scores. Experiments on the nuScenesdataset show that ReliFusion significantly outperforms state-of-the-artmethods, achieving superior robustness and accuracy in scenarios with limitedLiDAR fields of view and severe sensor malfunctions.</description>
      <author>example@mail.com (Reza Sadeghian, Niloofar Hooshyaripour, Chris Joslin, WonSook Lee)</author>
      <guid isPermaLink="false">2502.01856v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions</title>
      <link>http://arxiv.org/abs/2502.00568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新兴研究指出基于人工智能的多模态融合技术可以提高癌症诊断（分级/亚型）和预后预测。然而，在实际临床环境中直接进行此类融合不切实际。&lt;h4&gt;目的&lt;/h4&gt;展示一种新的扩散基础跨模式生成AI模型PathoGen，该模型利用数字病理学合成基因表达以准确预测癌症分级及患者生存风险，并保证预测的确定性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于扩散机制的跨模态生成人工智能模型PathoGen。此模型能从数字化病理图像中推断出相应的转录组特征，用于预测癌症的等级和患者的预后情况。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用PathoGen模型，可以利用数字病理学合成基因表达信息来准确预测癌症分级及患者生存风险，同时提供可解释性的分布式注意力图。该方法在公开数据集上实现了最先进的性能，并保证了预测结果的确定性。&lt;h4&gt;结论&lt;/h4&gt;PathoGen是一个有效的工具，它能够在不依赖于常规转录组测序的情况下利用病理图像来提高癌症诊断和预后的准确性。&lt;h4&gt;翻译&lt;/h4&gt;新兴研究已强调基于人工智能的多模态融合技术能够改善癌症诊断（分级/亚型）以及生存风险预测。然而，在实际临床环境中直接进行此类融合并不现实，因为在公共医疗系统中，组织病理学仍然是诊断的金标准，而转录组测试几乎从未被要求使用。利用我们新颖的基于扩散机制的跨模态生成AI模型PathoGen，我们展示了从数字病理图像合成出的基因表达可以高精度地预测癌症分级和患者生存风险，并通过一致性覆盖保证和分布注意力图确保其准确性和可解释性。 PathoGen代码可在GitHub（https://github.com/Samiran-Dey/PathoGen）上免费使用供研究界使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging research has highlighted that artificial intelligence basedmultimodal fusion of digital pathology and transcriptomic features can improvecancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.However, such direct fusion for joint decision is impractical in real clinicalsettings, where histopathology is still the gold standard for diagnosis andtranscriptomic tests are rarely requested, at least in the public healthcaresystem. With our novel diffusion based crossmodal generative AI model PathoGen,we show that genomic expressions synthesized from digital histopathologyjointly predicts cancer grading and patient survival risk with high accuracy(state-of-the-art performance), certainty (through conformal coverageguarantee) and interpretability (through distributed attention maps). PathoGencode is available for open use by the research community through GitHub athttps://github.com/Samiran-Dey/PathoGen.</description>
      <author>example@mail.com (Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti)</author>
      <guid isPermaLink="false">2502.00568v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a Vision Foundation Model</title>
      <link>http://arxiv.org/abs/2502.00315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的单目3D目标检测模型改进方案，该方案通过利用视觉基础模型的广义特征提取能力来提高性能。&lt;h4&gt;背景&lt;/h4&gt;传统的基于CNN的方法在深度估计上往往不准确，并且依赖于多阶段的目标检测管道。这些问题阻碍了这些方法的有效性。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在开发一种能够同时改进深度估计和单目3D目标检测的模型，通过引入Vision Transformer（ViT）作为基础架构来替代传统的CNN。&lt;h4&gt;方法&lt;/h4&gt;{'使用ViT为基础结构': '该论文利用视觉Transformer(ViT)作为模型的基础框架，这种结构在捕捉全局特征以进行深度估计算法方面表现出色。', '集成DETR架构': '引入了一种检测变换器（DETR）架构来改进一次性的深度估计和目标检测性能。', '层级特征融合块': '提出一种分层特征融合模块从基础模型中提取更丰富的视觉特征，以进一步增强特征提取能力。', '相对深度估计算法': '通过大规模数据训练并转移学习的方式提高相对深度估计算法的精度。', '解码器中的查询使用': '在变压器解码器中采用参考点和2D边界框尺寸考虑的查询机制来提升识别性能。'}&lt;h4&gt;主要发现&lt;/h4&gt;该模型相较于当前最先进的方法，通过量化评估和质性评估（基于KITTI 3D基准测试及从高空赛车环境收集的数据集）都表现出了优越的表现。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法改进了单目3D目标检测的性能，并证明它在复杂且具有挑战性的场景中是有效且高效的。代码可在指定链接获得。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文，上述内容为其中文翻译及总结形式&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes novel methods to enhance the performance of monocular 3Dobject detection models by leveraging the generalized feature extractioncapabilities of a vision foundation model. Unlike traditional CNN-basedapproaches, which often suffer from inaccurate depth estimation and rely onmulti-stage object detection pipelines, this study employs a Vision Transformer(ViT)-based foundation model as the backbone, which excels at capturing globalfeatures for depth estimation. It integrates a detection transformer (DETR)architecture to improve both depth estimation and object detection performancein a one-stage manner. Specifically, a hierarchical feature fusion block isintroduced to extract richer visual features from the foundation model, furtherenhancing feature extraction capabilities. Depth estimation accuracy is furtherimproved by incorporating a relative depth estimation model trained onlarge-scale data and fine-tuning it through transfer learning. Additionally,the use of queries in the transformer's decoder, which consider referencepoints and the dimensions of 2D bounding boxes, enhances recognitionperformance. The proposed model outperforms recent state-of-the-art methods, asdemonstrated through quantitative and qualitative evaluations on the KITTI 3Dbenchmark and a custom dataset collected from high-elevation racingenvironments. Code is available at https://github.com/JihyeokKim/MonoDINO-DETR.</description>
      <author>example@mail.com (Jihyeok Kim, Seongwoo Moon, Sungwon Nah, David Hyunchul Shim)</author>
      <guid isPermaLink="false">2502.00315v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Similarity for High-Yield Corporate Bonds with Quantum Cognition Machine Learning</title>
      <link>http://arxiv.org/abs/2502.01495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了量子认知机器学习(QCML)在债券市场距离度量学习中的应用，该方法基于量子理论数学形式化，并适用于监督和非监督学习任务。与股票相比，公司债券流动性较低且交易数据较为稀缺，因此衡量公司债券之间的距离/相似性对于多个实际应用场景都特别有用。&lt;h4&gt;背景&lt;/h4&gt;相对而言，公司债券的流动性和市场报价及交易记录稀疏，这使得在低流动性债券交易中度量债券间的距离或相似性变得尤为关键。以往的研究主要集中在基于经典树模型进行监督学习以获取债券间相似性的方法上。&lt;h4&gt;目的&lt;/h4&gt;研究量子认知机器学习(QCML)框架在公司债券市场中的表现，特别关注其在高收益（HY）市场与投资级（IG）市场的对比效果。&lt;h4&gt;方法&lt;/h4&gt;将QCML应用于距离度量学习，并将其性能与经典树模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在高收益市场上，量子认知机器学习(QCML)的性能优于传统的基于树的方法；而在投资等级市场中，则根据评估指标的不同而表现出相似或更好的性能。&lt;h4&gt;结论&lt;/h4&gt;尽管QCML在某些情况下表现得比经典模型好，但其具体优势可能依赖于特定市场的特性以及所采用的距离度量标准。未来的研究可以进一步探索该方法在其他金融资产中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了量子认知机器学习(QCML)在债券市场距离度量学习的应用，这是一种基于量子理论数学形式化的新型模式，适用于监督和非监督学习任务。相比于股票，公司债券流动性较差且交易数据较为稀缺，在这种情况下衡量公司债券之间的距离/相似性尤为重要。以往的研究主要集中在经典树模型上的监督相似性学习方法上；而本文则探索了在该背景下使用QCML进行监督距离度量学习的方法，并证明它在高收益市场中的表现优于基于树的经典模型，同时在投资级市场上给出的表现根据评估指标的不同而达到相等或更好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the application of quantum cognition machine learning (QCML),a novel paradigm for both supervised and unsupervised learning tasks rooted inthe mathematical formalism of quantum theory, to distance metric learning incorporate bond markets. Compared to equities, corporate bonds are relativelyilliquid and both trade and quote data in these securities are relativelysparse. Thus, a measure of distance/similarity among corporate bonds isparticularly useful for a variety of practical applications in the trading ofilliquid bonds, including the identification of similar tradable alternatives,pricing securities with relatively few recent quotes or trades, and explainingthe predictions and performance of ML models based on their training data.Previous research has explored supervised similarity learning based onclassical tree-based models in this context; here, we explore the applicationof the QCML paradigm for supervised distance metric learning in the samecontext, showing that it outperforms classical tree-based models in high-yield(HY) markets, while giving comparable or better performance (depending on theevaluation metric) in investment grade (IG) markets.</description>
      <author>example@mail.com (Joshua Rosaler, Luca Candelori, Vahagn Kirakosyan, Kharen Musaelian, Ryan Samson, Martin T. Wells, Dhagash Mehta, Stefano Pasquali)</author>
      <guid isPermaLink="false">2502.01495v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Framework for 3D Cell Segmentation Correction</title>
      <link>http://arxiv.org/abs/2502.01890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一个可解释的几何框架，用于纠正2D图像分割结果中的过度分割问题，进而改善3D细胞图像的最终分割效果。&lt;h4&gt;背景&lt;/h4&gt;当前的3D细胞图像分割方法通常分为非二维（non-2D-based）和基于二维的方法。后者通过将二维层的结果重建为三维形状来工作，但二维分割错误常会传递到三维结果中，导致过度分割问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的几何框架以纠正基于二维的3D细胞图像分割方法中的过度分割现象。&lt;h4&gt;方法&lt;/h4&gt;利用几何（相邻层次之间的2D）和拓扑（3D形状）特征进行二元分类，判断相邻细胞是否应该被缝合。此外，还引入了预训练分类器，并通过公开植物细胞数据集验证其性能。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在动物细胞数据集中表现出有效性，证实了它在迁移学习设置下修正过度分割的能力。另外，研究证明该框架也可以应用于非二维基础的方法来纠正过度分割问题。&lt;h4&gt;结论&lt;/h4&gt;提供了一条清晰的流水线供最终用户将预训练模型应用到任何标注的数据集上。&lt;h4&gt;翻译&lt;/h4&gt;三维细胞图像分割方法通常分为基于2D和非基于2D两种。后者通过重建二维层的结果来构建3D形状，但这种做法会导致过度分割问题。为解决这一难题，本文介绍了一种可解释的几何框架，利用几何信息修正相邻层次之间的二维错误，进而减少最终三维结果中的过度分割现象。同时，在公开植物细胞数据集上训练了一个预分类器，并验证了它在动物细胞上的效果，表明其具备迁移学习的能力以改善过度分割问题。该方法不仅适用于基于2D的方法，也可以应用于非2D基础的3D图像分割技术。最后还为用户提供了搭建预训练模型到任何标注数据集的具体流程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D cellular image segmentation methods are commonly divided into non-2D-basedand 2D-based approaches, the latter reconstructing 3D shapes from thesegmentation results of 2D layers. However, errors in 2D results oftenpropagate, leading to oversegmentations in the final 3D results. To tackle thisissue, we introduce an interpretable geometric framework that addresses theoversegmentations by correcting the 2D segmentation results based on geometricinformation from adjacent layers. Leveraging both geometric (layer-to-layer,2D) and topological (3D shape) features, we use binary classification todetermine whether neighboring cells should be stitched. We develop apre-trained classifier on public plant cell datasets and validate itsperformance on animal cell datasets, confirming its effectiveness in correctingoversegmentations under the transfer learning setting. Furthermore, wedemonstrate that our framework can be extended to correcting oversegmentationon non-2D-based methods. A clear pipeline is provided for end-users to buildthe pre-trained model to any labeled dataset.</description>
      <author>example@mail.com (Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Yining Liu)</author>
      <guid isPermaLink="false">2502.01890v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>SpikingRTNH: Spiking Neural Network for 4D Radar Object Detection</title>
      <link>http://arxiv.org/abs/2502.00074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arxiv preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于基于4D雷达数据的3D物体检测的尖峰神经网络（SNN），即SpikingRTNH，该模型通过使用生物灵感的上行推理过程有效降低了能量消耗。&lt;h4&gt;背景&lt;/h4&gt;近年来，4D雷达作为一种关键传感器，在恶劣天气中为自主车辆提供了稳定的感知，并且在三维物体识别方面具有高密度点云的优势。但是处理这些高密度数据需要大量的计算资源和能源。&lt;h4&gt;目的&lt;/h4&gt;为了提高基于4D雷达的3D物体检测的能量效率，提出了SpikingRTNH模型，该模型采用尖峰神经网络并通过引入生物上行推理（BTI）来降低能量消耗。&lt;h4&gt;方法&lt;/h4&gt;通过将传统的ReLU激活函数替换为漏电积分和发射（LIF）尖峰神经元以提高能源效率。此外，还提出了一种模拟人类认知过程的生物上行推理（BTI），该方法按从高密度到低密度顺序处理点云数据。&lt;h4&gt;主要发现&lt;/h4&gt;在K-Radar数据集上的实验表明，SpikingRTNH与生物上行推理结合使用时，在保持类似检测性能的情况下，相较于其人工神经网络对应模型，能量消耗减少了78%（51.1％AP 3D, 57.0％ AP BEV）。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了尖峰神经网络在基于4D雷达的物体检测中的可行性和节能潜力。&lt;h4&gt;翻译&lt;/h4&gt;最近，4D雷达作为自主车辆中进行三维物体检测的关键传感器已经出现，它提供了恶劣天气下的稳定感知以及用于形状识别的高密度点云。然而，处理这些高密度数据需要大量的计算资源和能耗。我们提出了SpikingRTNH，这是第一个基于4D雷达数据进行3D物体检测的尖峰神经网络（SNN）。通过用漏电积分发射（LIF）尖峰神经元取代传统的ReLU激活函数，SpikingRTNH实现了显著的能量效率提升。此外，受到人类认知过程的启发，我们引入了生物上行推理（BTI），按从高密度到低密度顺序处理点云，这有助于利用噪声较低且检测重要性较高的点数据。在K-Radar数据集上的实验表明，与人工神经网络（ANN）对应的模型相比，SpikingRTNH结合BTI显著减少了78％的能量消耗（同时实现了类似水平的检测性能：3D AP 51.1%，BEV AP 57.0%）。这些结果证明了SNN在自驾车系统中基于4D雷达数据进行节能型物体检测的可行性。所有代码均可以在https://github.com/kaist-avelab/k-radar获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, 4D Radar has emerged as a crucial sensor for 3D object detection inautonomous vehicles, offering both stable perception in adverse weather andhigh-density point clouds for object shape recognition. However, processingsuch high-density data demands substantial computational resources and energyconsumption. We propose SpikingRTNH, the first spiking neural network (SNN) for3D object detection using 4D Radar data. By replacing conventional ReLUactivation functions with leaky integrate-and-fire (LIF) spiking neurons,SpikingRTNH achieves significant energy efficiency gains. Furthermore, inspiredby human cognitive processes, we introduce biological top-down inference (BTI),which processes point clouds sequentially from higher to lower densities. Thisapproach effectively utilizes points with lower noise and higher importance fordetection. Experiments on K-Radar dataset demonstrate that SpikingRTNH with BTIsignificantly reduces energy consumption by 78% while achieving comparabledetection performance to its ANN counterpart (51.1% AP 3D, 57.0% AP BEV). Theseresults establish the viability of SNNs for energy-efficient 4D Radar-basedobject detection in autonomous driving systems. All codes are available athttps://github.com/kaist-avelab/k-radar.</description>
      <author>example@mail.com (Dong-Hee Paek, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2502.00074v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>T-SCEND: Test-time Scalable MCTS-enhanced Diffusion Model</title>
      <link>http://arxiv.org/abs/2502.01989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的框架Test-time Scalable MCTS-enhanced Diffusion Model (T-SCEND)，该框架通过更好的能量训练和测试时间计算的扩展，显著提高了扩散模型的推理能力。&lt;h4&gt;背景&lt;/h4&gt;简单的增加推理预算对于提升扩散模型的效果几乎没有什么帮助。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的线性回归负对比学习目标来提高性能与能耗的一致性，并引入KL正则化以减少对抗采样。同时，在推理阶段，T-SCEND结合了降噪过程和新颖的混合蒙特卡洛树搜索（hMCTS）方法。&lt;h4&gt;方法&lt;/h4&gt;训练阶段采用线性回归负对比学习目标和KL正则化；测试时使用新的混合蒙特卡洛树搜索（hybrid Monte Carlo Tree Search, hMCTS），即在降噪过程中交替进行最佳的N随机搜索和MCTS。&lt;h4&gt;主要发现&lt;/h4&gt;T-SCEND在迷宫和数独等复杂的推理任务上展示了其训练目标的有效性和可扩展推理方法的成功。具体来说，在6x6大小迷宫训练的基础上，可以解决15x15大小的92%的问题，而标准扩散模型完全失败。&lt;h4&gt;结论&lt;/h4&gt;T-SCEND框架证明了在复杂推理问题上的有效性和优越性，并且其代码可以在GitHub上找到以供重复实验使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Test-time Scalable MCTS-enhanced Diffusion Model (T-SCEND), anovel framework that significantly improves diffusion model's reasoningcapabilities with better energy-based training and scaling up test-timecomputation. We first show that na\"ively scaling up inference budget fordiffusion models yields marginal gain. To address this, the training of T-SCENDconsists of a novel linear-regression negative contrastive learning objectiveto improve the performance-energy consistency of the energy landscape, and a KLregularization to reduce adversarial sampling. During inference, T-SCENDintegrates the denoising process with a novel hybrid Monte Carlo Tree Search(hMCTS), which sequentially performs best-of-N random search and MCTS asdenoising proceeds. On challenging reasoning tasks of Maze and Sudoku, wedemonstrate the effectiveness of T-SCEND's training objective and scalableinference method. In particular, trained with Maze sizes of up to $6\times6$,our T-SCEND solves $88\%$ of Maze problems with much larger sizes of$15\times15$, while standard diffusion completely fails.Code to reproduce theexperiments can be found at https://github.com/AI4Science-WestlakeU/t_scend.</description>
      <author>example@mail.com (Tao Zhang, Jia-Shu Pan, Ruiqi Feng, Tailin Wu)</author>
      <guid isPermaLink="false">2502.01989v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>MAGNNET: Multi-Agent Graph Neural Network-based Efficient Task Allocation for Autonomous Vehicles with Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.02311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Intelligent Vehicle Symposium (2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于异构多智能体系统在通信受限条件下的去中心化任务分配问题。该框架结合了图神经网络（GNN）、集中式训练和分布式执行（CTDE）方法以及针对多智能体深度强化学习（MARL）量身定制的近端策略优化（PPO）算法。&lt;h4&gt;背景&lt;/h4&gt;在异构多智能体系统中，特别是在通信受限的情况下，去中心化任务分配是一个挑战。现有的解决办法往往需要中央协调或不能有效处理复杂的动态环境。&lt;h4&gt;目的&lt;/h4&gt;本文旨在开发一种无需中央协调即可使无人飞行器（UAV）和地面车辆（UGV）在三维网格环境中高效动态地进行任务分配的方法。&lt;h4&gt;方法&lt;/h4&gt;研究采用了基于图神经网络的集中训练与分布式执行框架，结合了定制化的近端策略优化算法。为了计算成本并规划路径，使用了基于预订的A*和R*搜索算法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该方法在避免任务冲突的情况下成功率达到92.5%，性能仅比中央匈牙利方法低7.49%，并且优于基于贪婪算法的启发式分散基准。框架能够支持最多20个代理，并且响应动态生成的任务具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法展示了在复杂多智能体场景中的潜力，特别是在去中心化和通信受限的情况下。它提供了高效的任务分配解决方案，同时保持了良好的可扩展性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of decentralized task allocation withinheterogeneous multi-agent systems operating under communication constraints. Weintroduce a novel framework that integrates graph neural networks (GNNs) with acentralized training and decentralized execution (CTDE) paradigm, furtherenhanced by a tailored Proximal Policy Optimization (PPO) algorithm formulti-agent deep reinforcement learning (MARL). Our approach enables unmannedaerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to dynamicallyallocate tasks efficiently without necessitating central coordination in a 3Dgrid environment. The framework minimizes total travel time whilesimultaneously avoiding conflicts in task assignments. For the cost calculationand routing, we employ reservation-based A* and R* path planners. Experimentalresults revealed that our method achieves a high 92.5% conflict-free successrate, with only a 7.49% performance gap compared to the centralized Hungarianmethod, while outperforming the heuristic decentralized baseline based ongreedy approach. Additionally, the framework exhibits scalability with up to 20agents with allocation processing of 2.8 s and robustness in responding todynamically generated tasks, underscoring its potential for real-worldapplications in complex multi-agent scenarios.</description>
      <author>example@mail.com (Lavanya Ratnabala, Aleksey Fedoseev, Robinroy Peter, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2502.02311v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-neural Topology Optimization: Knowledge Infusion with Meta-learning</title>
      <link>http://arxiv.org/abs/2502.01830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种元学习策略，称为元神经拓扑优化（meta-neural TO），旨在通过相关任务之间的知识系统性转移来找到有效的初始设计。&lt;h4&gt;背景&lt;/h4&gt;工程师在每次设计中积累经验，能够快速识别新问题的解决方案。然而，现有的拓扑优化方法缺乏从过往经验中学习的能力，每解决一个新问题是都从零开始。&lt;h4&gt;目的&lt;/h4&gt;提出一种元学习策略，改善传统拓扑优化方法无法利用历史数据的问题，实现跨任务的知识迁移和高效的设计迭代。&lt;h4&gt;方法&lt;/h4&gt;使用神经重参数化提供的网格无关表示法来系统地转移知识，以发现有效的初始设计。与传统的拓扑优化方法进行比较，展示了在不同测试案例中的高效优化能力。&lt;h4&gt;主要发现&lt;/h4&gt;元学习策略能够实现跨分辨率的知识迁移，在低分辨率初始化的基础上，74.1%的任务在高分辨率测试集上获得更优的收敛性，减少了33.6%的标准神经拓扑优化平均迭代次数。另外，这种方法自然倾向于均匀密度设计中的应变能模式作为有效的起点。&lt;h4&gt;结论&lt;/h4&gt;元学习策略展示了其强大的跨任务知识迁移能力和更高的优化效率，为解决工程设计问题提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;工程师通过每项设计积累经验，迅速识别新挑战的有效解决方案。拓扑优化（TO）作为一种成熟的计算方法用于结构性能的最优化设计，缺乏从过往经历中学习的能力。现有的方法将任务视为独立处理，在面对新问题是每次都重新开始，这通常需要许多昂贵的计算步骤才能收敛。我们提出了一种元学习策略，称为元神经拓扑优化，通过在相关任务之间系统地转移知识来找到有效的初始设计，基于神经重参数化的网格无关表示法进行构建。我们将这种方法与现有的TO方法进行了比较，在不降低设计质量的情况下实现了不同测试案例中的高效优化。此外，我们展示了强大的跨分辨率的知识迁移能力，在较低分辨率的离散化初始化基础上在74.1%的任务上达到较高的高分辨率测试集收敛性，与标准神经拓扑优化相比平均减少了33.6%的迭代次数。值得注意的是，元学习策略自然倾向于均匀密度设计中的应变能模式作为有效起点，这符合工程直觉。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Engineers learn from every design they create, building intuition that helpsthem quickly identify promising solutions for new problems. Topologyoptimization (TO) - a well-established computational method for designingstructures with optimized performance - lacks this ability to learn fromexperience. Existing approaches treat design tasks in isolation, starting froma "blank canvas" design for each new problem, often requiring manycomputationally expensive steps to converge. We propose a meta-learningstrategy, termed meta-neural TO, that finds effective initial designs through asystematic transfer of knowledge between related tasks, building on themesh-agnostic representation provided by neural reparameterization. We compareour approach against established TO methods, demonstrating efficientoptimization across diverse test cases without compromising design quality.Further, we demonstrate powerful cross-resolution transfer capabilities, whereinitializations learned on lower-resolution discretizations lead to superiorconvergence in 74.1% of tasks on a higher-resolution test set, reducing theaverage number of iterations by 33.6% compared to standard neural TO.Remarkably, we discover that meta-learning naturally gravitates toward thestrain energy patterns found in uniform density designs as effective startingpoints, aligning with engineering intuition.</description>
      <author>example@mail.com (Igor Kuszczak, Gawel Kus, Federico Bosi, Miguel A. Bessa)</author>
      <guid isPermaLink="false">2502.01830v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Flatten Graphs as Sequences: Transformers are Scalable Graph Generators</title>
      <link>http://arxiv.org/abs/2502.02216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AutoGraph 是一个用于生成大型属性图的自动回归框架，它使用解码器专用变压器。该方法的核心是一种可逆的“扁平化”过程，将图转换为随机序列。&lt;h4&gt;背景&lt;/h4&gt;现有的扩散模型依赖于计算密集型节点特征来生成图结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需额外训练即可高效且灵活地生成大型稀疏图的方法。&lt;h4&gt;方法&lt;/h4&gt;通过将图形转化为序列并使用解码器专用变压器，AutoGraph 可以在类似自然语言的方式下建模和生成复杂的图形结构。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AutoGraph 在多种合成和分子图生成基准测试中达到了最先进的性能，并且比领先的扩散模型快100倍的生成速度和三倍的训练速度。此外，它还展示了出色的迁移能力和无需额外微调即可支持子结构条件下的生成。&lt;h4&gt;结论&lt;/h4&gt;通过将语言建模技术应用于图形生成领域，这项工作为开发图形基础模型铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了 AutoGraph，这是一个新颖的自回归框架，用于使用解码器专用变压器生成大型属性图。该方法的核心是一种可逆的“扁平化”过程，将图转换成随机序列。通过从这些序列中采样和学习，AutoGraph 使变压器能够以类似于自然语言的方式建模并生成复杂的图形结构。与依赖于计算密集型节点特征的扩散模型不同，我们的方法仅在这些序列上操作。采样复杂性和序列长度随边数线性缩放，使得 AutoGraph 在为大型稀疏图生成时非常高效且可扩展。实证研究表明，在各种合成和分子图生成基准测试中，AutoGraph 达到了最先进的性能，并比领先的扩散模型快100倍的生成速度和三倍的训练速度。此外，它还展示了有前景的迁移能力和在无额外微调的情况下支持子结构条件下的生成的能力。通过将语言建模技术扩展到图形生成领域，这项工作为开发图形基础模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce AutoGraph, a novel autoregressive framework for generating largeattributed graphs using decoder-only transformers. At the core of our approachis a reversible "flattening" process that transforms graphs into randomsequences. By sampling and learning from these sequences, AutoGraph enablestransformers to model and generate complex graph structures in a manner akin tonatural language. In contrast to diffusion models that rely on computationallyintensive node features, our approach operates exclusively on these sequences.The sampling complexity and sequence length scale linearly with the number ofedges, making AutoGraph highly scalable for generating large sparse graphs.Empirically, AutoGraph achieves state-of-the-art performance across diversesynthetic and molecular graph generation benchmarks, while delivering a100-fold generation and a 3-fold training speedup compared to leading diffusionmodels. Additionally, it demonstrates promising transfer capabilities andsupports substructure-conditioned generation without additional fine-tuning. Byextending language modeling techniques to graph generation, this work paves theway for developing graph foundation models.</description>
      <author>example@mail.com (Dexiong Chen, Markus Krimmel, Karsten Borgwardt)</author>
      <guid isPermaLink="false">2502.02216v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Intelligence for 3D Understanding: A Survey on 3D Scene Question Answering</title>
      <link>http://arxiv.org/abs/2502.00342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对3D场景问答（3D SQA）领域进行了全面的综述，涵盖了数据集、方法论和评估指标，并指出了该领域的关键挑战与未来机遇。&lt;h4&gt;背景&lt;/h4&gt;3D SQA是一个跨学科的任务，结合了3D视觉感知和自然语言处理技术，使智能代理能够理解和互动复杂的3D环境。&lt;h4&gt;目的&lt;/h4&gt;通过对各种数据集、模型方法及评价标准的系统性回顾，强调了标准化数据集、多模态融合以及任务设计方面的挑战与未来机会。&lt;h4&gt;方法&lt;/h4&gt;介绍了大量多模态建模进展如何推动多样化数据集的发展，并促进了指令微调和零样本方法在3D SQA中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;尽管有快速的进步，但仍然存在统一分析及不同基准间比较的挑战。&lt;h4&gt;结论&lt;/h4&gt;首次提出对整个3D场景问答领域的综合调查报告，旨在推动该领域未来的发展和标准化进程。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了论文概述了关于多模态建模进步如何驱动多样化数据集创建以及促进指令微调与零样本方法发展的现状，并指出了统一分析比较的挑战。此外还强调了在3D SQA中标准制定、跨模态融合及任务设计的重要性，提出了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Scene Question Answering (3D SQA) represents an interdisciplinary taskthat integrates 3D visual perception and natural language processing,empowering intelligent agents to comprehend and interact with complex 3Denvironments. Recent advances in large multimodal modelling have driven thecreation of diverse datasets and spurred the development of instruction-tuningand zero-shot methods for 3D SQA. However, this rapid progress introduceschallenges, particularly in achieving unified analysis and comparison acrossdatasets and baselines. This paper presents the first comprehensive survey of3D SQA, systematically reviewing datasets, methodologies, and evaluationmetrics while highlighting critical challenges and future opportunities indataset standardization, multimodal fusion, and task design.</description>
      <author>example@mail.com (Zechuan Li, Hongshan Yu, Yihao Ding, Yan Li, Yong He, Naveed Akhtar)</author>
      <guid isPermaLink="false">2502.00342v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of FPGA and GPU Performance for Machine Learning-Based Track Reconstruction at LHCb</title>
      <link>http://arxiv.org/abs/2502.02304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在高能物理领域中，为了应对大型强子对撞机（LHC）的高亮度和探测器分辨率增加所带来的挑战，机器学习特别是图神经网络如何被用于优化数据处理流程。通过比较现场可编程门阵列（FPGA）与图形处理器（GPU）在多层感知器模型推理中的性能表现，展示了FPGA在高吞吐量、低延迟推断方面的潜力。&lt;h4&gt;背景&lt;/h4&gt;随着大型强子对撞机的亮度增加和探测器分辨率提升，高效的数据处理方案变得尤为重要。机器学习技术因能够线性扩展计算资源而被用于粒子跟踪重建任务中。&lt;h4&gt;目的&lt;/h4&gt;通过比较FPGA与GPU在多层感知器模型推理中的性能表现，展示FPGA在高能物理领域内的应用潜力和优势。&lt;h4&gt;方法&lt;/h4&gt;利用HLS4ML工具将多层感知器模型部署到FPGA上，并与其在GPU上的实现进行了对比测试。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相较于GPU，基于FPGA的模型推理具有更高的吞吐量、更低延迟且功耗更小。同时，该方法降低了对硬件专业知识的要求。&lt;h4&gt;结论&lt;/h4&gt;研究证明了利用FPGA进行机器学习模型部署的有效性和优越性，在高能物理数据处理中显示出巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;在高能物理学领域，大型强子对撞机（LHC）的亮度提升和探测器精细度增加推动了更加高效的资料处理解决方案的需求。机器学习已被证实为重建带电粒子轨迹的一种有前途的技术，因为它有可能与探测器撞击点呈线性比例地扩展计算资源。最近，在LHCb实验的第一级触发系统中使用基于图神经网络的跟踪重构流水线在GPU上实现了一个比较不同计算架构性能的研究平台。本文提供了一种新颖的方法来对比FPGA和GPU上的机器学习模型推理吞吐量，重点是跟踪重构管道的第一步——一个多层感知器的实现。利用HLS4ML工具将多层感知器部署到FPGA中，并对其与GPU实现进行了基准测试，展示了在无需深入了解FPGA开发的情况下，使用更少电力仍能实现实时、低延迟推理的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In high-energy physics, the increasing luminosity and detector granularity atthe Large Hadron Collider are driving the need for more efficient dataprocessing solutions. Machine Learning has emerged as a promising tool forreconstructing charged particle tracks, due to its potentially linearcomputational scaling with detector hits. The recent implementation of a graphneural network-based track reconstruction pipeline in the first level triggerof the LHCb experiment on GPUs serves as a platform for comparative studiesbetween computational architectures in the context of high-energy physics. Thispaper presents a novel comparison of the throughput of ML model inferencebetween FPGAs and GPUs, focusing on the first step of the track reconstructionpipeline$\unicode{x2013}$an implementation of a multilayer perceptron. UsingHLS4ML for FPGA deployment, we benchmark its performance against the GPUimplementation and demonstrate the potential of FPGAs for high-throughput,low-latency inference without the need for an expertise in FPGA development andwhile consuming significantly less power.</description>
      <author>example@mail.com (Fotis I. Giasemis, Vladimir Lončar, Bertrand Granado, Vladimir Vava Gligorov)</author>
      <guid isPermaLink="false">2502.02304v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Policy-Guided Causal State Representation for Offline Reinforcement Learning Recommendation</title>
      <link>http://arxiv.org/abs/2502.02327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为Policy-Guided Causal Representation (PGCR)的两阶段框架，旨在解决基于离线强化学习的推荐系统中的有效状态表示问题。&lt;h4&gt;背景&lt;/h4&gt;在基于离线强化学习的推荐系统（RLRS）中，准确捕捉用户偏好以实现长期奖励至关重要。然而原始状态表示通常包含高维、嘈杂的信息以及与回报无关的因素，且缺少数据转移使得识别对用户体验至关重要的特征更加困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的两阶段框架——Policy-Guided Causal Representation (PGCR)，用于离线RLRS中的因果特性选择和状态表征学习。&lt;h4&gt;方法&lt;/h4&gt;第一阶段通过Wasserstein距离奖励函数引导的因果特性选择策略生成修改后的状态，保留仅与回报相关的组件，并改变不相关部分。第二阶段训练编码器以最小化原始状态和修改后状态之间隐式表示的均方误差损失，确保表征集中于关键因果成分。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析证明了干预识别因果效应的可能性，实验表明PGCR显著提升了推荐性能，验证了其在离线RL系统中的有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的Policy-Guided Causal Representation (PGCR)框架能有效解决状态表示问题，并提升基于离线强化学习的推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在离线强化学习为基础的推荐系统（RLRS）中，学得有效的状态表征对于捕捉直接影响长期奖励的用户偏好至关重要。然而原始的状态表征常常包含高维、嘈杂的信息以及与回报无因果关系的因素，并且由于缺少数据转换，在离线数据中难以准确识别出最影响用户体验的相关特征。为解决这些挑战，我们提出了Policy-Guided Causal Representation（PGCR），一种新颖的两阶段框架，用于因果特性选择和状态表示学习中的离线RLRS。在第一阶段中，我们学得一个基于Wasserstein距离奖励函数引导的因果特性选择策略，该策略通过隔离并仅保留与回报相关的组件生成修改后的状态，同时改变不相关部分。此奖励函数测量了状态成分对回报的影响，并鼓励保存直接影响用户兴趣的关键因果成分（CRC）。在第二阶段中，我们训练一个编码器以学习紧凑的状态表示，这通过最小化原始状态和修改后状态之间隐式表示的均方误差损失实现，确保表示集中在关键因果组件上。我们提供了一个理论分析来证明干预识别因果效应的可能性，验证了PGCR能够隔离用于决策制定的关键状态组成部分的能力。广泛的实验表明，PGCR显著改善了推荐性能，证实其对基于离线RL系统的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In offline reinforcement learning-based recommender systems (RLRS), learningeffective state representations is crucial for capturing user preferences thatdirectly impact long-term rewards. However, raw state representations oftencontain high-dimensional, noisy information and components that are notcausally relevant to the reward. Additionally, missing transitions in offlinedata make it challenging to accurately identify features that are most relevantto user satisfaction. To address these challenges, we propose Policy-GuidedCausal Representation (PGCR), a novel two-stage framework for causal featureselection and state representation learning in offline RLRS. In the firststage, we learn a causal feature selection policy that generates modifiedstates by isolating and retaining only the causally relevant components (CRCs)while altering irrelevant components. This policy is guided by a rewardfunction based on the Wasserstein distance, which measures the causal effect ofstate components on the reward and encourages the preservation of CRCs thatdirectly influence user interests. In the second stage, we train an encoder tolearn compact state representations by minimizing the mean squared error (MSE)loss between the latent representations of the original and modified states,ensuring that the representations focus on CRCs. We provide a theoreticalanalysis proving the identifiability of causal effects from interventions,validating the ability of PGCR to isolate critical state components fordecision-making. Extensive experiments demonstrate that PGCR significantlyimproves recommendation performance, confirming its effectiveness for offlineRL-based recommender systems.</description>
      <author>example@mail.com (Siyu Wang, Xiaocong Chen, Lina Yao)</author>
      <guid isPermaLink="false">2502.02327v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Resilient UAV Trajectory Planning via Few-Shot Meta-Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2502.01268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种结合离线强化学习和元学习的新型算法，用于在5G及其后续系统中优化无人机轨迹和调度策略。&lt;h4&gt;背景&lt;/h4&gt;目前的强化学习框架依赖于与环境的在线交互，在现实应用中由于安全性和成本原因可能不可行。同时，在线RL算法难以适应动态或新的环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于离线数据训练强化学习模型的方法，以及能够扩展到新未知环境的技术解决方案。&lt;h4&gt;方法&lt;/h4&gt;该工作结合了保守的Q学习（CQL）和无模型元学习（MAML），提出了一个新型、鲁棒且适应性高的少量样本元离线RL算法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的少数样本元离线RL算法比现有的基准方案如深度Q网络和CQL更快地收敛，并能使用少量数据点的离线数据集实现最优联合AoI和传输功率，同时还能抵御由于环境变化导致的网络故障。&lt;h4&gt;结论&lt;/h4&gt;该工作提供了一种有效的方法来解决复杂无线环境中强化学习算法面临的挑战，尤其在5G及其后续系统中具有应用前景。&lt;h4&gt;翻译&lt;/h4&gt;强化学习（RL）是未来5G及6G系统的有希望的本质。其主要优势在于复杂的、高维度的无线环境中的稳健无模型决策能力。然而，大多数现有的RL框架依赖于与环境的在线交互，在现实情况中因安全性和成本原因可能不可行。在线RL的另一个问题是所设计算法在动态或新环境中缺乏可扩展性。本文提出了一种新的、鲁棒且适应性高的少量样本元离线RL算法，结合了使用保守Q学习（CQL）的离线RL和使用模型无关元学习（MAML）的元学习。所提出的算法可以在没有与环境在线交互的情况下仅利用静态离线数据集训练RL模型。此外，在MAML的帮助下，该模型可以扩展到新的未知环境中。我们展示了将此算法用于优化无人机轨迹及调度策略以最小化信息老化度（AoI）和受限功率设备的传输功率的应用示例。数值结果表明所提出的少量样本元离线RL算法比基准方案如深度Q网络、CQL更快地收敛，并且它是唯一能在利用少样本数据点的离线数据集中实现最优联合AoI和传输功率的算法，同时还能抵御由于环境变化导致的网络故障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) has been a promising essence in future 5G-beyondand 6G systems. Its main advantage lies in its robust model-freedecision-making in complex and large-dimension wireless environments. However,most existing RL frameworks rely on online interaction with the environment,which might not be feasible due to safety and cost concerns. Another problemwith online RL is the lack of scalability of the designed algorithm withdynamic or new environments. This work proposes a novel, resilient, few-shotmeta-offline RL algorithm combining offline RL using conservative Q-learning(CQL) and meta-learning using model-agnostic meta-learning (MAML). The proposedalgorithm can train RL models using static offline datasets without any onlineinteraction with the environments. In addition, with the aid of MAML, theproposed model can be scaled up to new unseen environments. We showcase theproposed algorithm for optimizing an unmanned aerial vehicle (UAV) 'strajectory and scheduling policy to minimize the age-of-information (AoI) andtransmission power of limited-power devices. Numerical results show that theproposed few-shot meta-offline RL algorithm converges faster than baselineschemes, such as deep Q-networks and CQL. In addition, it is the only algorithmthat can achieve optimal joint AoI and transmission power using an offlinedataset with few shots of data points and is resilient to network failures dueto unprecedented environmental changes.</description>
      <author>example@mail.com (Eslam Eldeeb, Hirley Alves)</author>
      <guid isPermaLink="false">2502.01268v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>IPO: Iterative Preference Optimization for Text-to-Video Generation</title>
      <link>http://arxiv.org/abs/2502.02088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种称为迭代偏好优化（IPO）的新策略，旨在通过引入人类反馈来改进视频生成模型的质量。&lt;h4&gt;背景&lt;/h4&gt;尽管网络升级和模型规模扩大使得视频基础模型取得了重大进展，但其生成质量仍无法满足应用需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够将视频基础模型与人的偏好对齐的后训练方法，从而提高生成视频的质量。&lt;h4&gt;方法&lt;/h4&gt;引入了迭代偏好优化策略（IPO），该策略使用批评者模型根据直接偏好优化或卡恩曼-特沃斯基优化来评估和排序视频生成。这种方法利用来自偏好反馈信号指导视频基础模型的优化。&lt;h4&gt;主要发现&lt;/h4&gt;1. IPO通过多模态大规模语言模型，能够自动分配偏好标签而无需重新训练或重新标注；2. IPO能够在迭代模式下高效地执行多轮偏好优化，从而提高预训练模型生成视频的质量，并帮助具有较小参数量（仅20亿）的模型超越拥有更多参数量（50亿）的模型。&lt;h4&gt;结论&lt;/h4&gt;实验表明IPO在VBench基准测试中实现了新的最佳性能。团队计划发布源代码、模型以及数据集以推动未来的研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;视频基础模型借助网络升级及规模扩大取得了显著进展，但生成质量仍无法满足应用需求。为了改进这一状况，提出了迭代偏好优化策略（IPO），该方法通过引入人类反馈来增强生成的视频质量。具体而言，IPO利用批评者模型来进行成对排名或点状评分，并根据这些信号调整基础视频模型以提高生成视频在主题一致性、运动流畅性和美学质量等方面的表现。此外，IPO还结合了多模态大型语言模型，能够在无需重新训练或重新标注的情况下自动分配偏好标签，从而实现高效且迭代式的多轮优化过程。实验结果显示，与具有更少参数的预训练模型相比，该方法能够显著提高其生成视频的质量，并达到新的最佳性能标准（VBench基准测试）。研究团队计划发布源代码、模型以及数据集以促进未来的相关研究和应用进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video foundation models have achieved significant advancement with the helpof network upgrade as well as model scale-up. However, they are still hard tomeet requirements of applications due to unsatisfied generation quality. Tosolve this problem, we propose to align video foundation models with humanpreferences from the perspective of post-training in this paper. Consequently,we introduce an Iterative Preference Optimization strategy to enhance generatedvideo quality by incorporating human feedback. Specifically, IPO exploits acritic model to justify video generations for pairwise ranking as in DirectPreference Optimization or point-wise scoring as in Kahneman-TverskyOptimization. Given this, IPO optimizes video foundation models with guidanceof signals from preference feedback, which helps improve generated videoquality in subject consistency, motion smoothness and aesthetic quality, etc.In addition, IPO incorporates the critic model with the multi-modality largelanguage model, which enables it to automatically assign preference labelswithout need of retraining or relabeling. In this way, IPO can efficientlyperform multi-round preference optimization in an iterative manner, without theneed of tediously manual labeling. Comprehensive experiments demonstrate thatthe proposed IPO can effectively improve the video generation quality of apretrained model and help a model with only 2B parameters surpass the one with5B parameters. Besides, IPO achieves new state-of-the-art performance on VBenchbenchmark. We will release our source codes, models as well as dataset toadvance future research and applications.</description>
      <author>example@mail.com (Xiaomeng Yang, Zhiyu Tan, Xuecheng Nie, Hao Li)</author>
      <guid isPermaLink="false">2502.02088v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Ensembling with Multimodal Image Fusion for Efficient Classification of Lung Cancer</title>
      <link>http://arxiv.org/abs/2502.00078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究关注从多模态肺部图像中区分癌变组织与健康组织，采用CT和PET影像数据进行分类。通过主成分分析（PCA）和自动编码器实现了PET和CT影像的融合，并提出了新的基于集成学习的方法Deep Ensembled Multimodal Fusion (DEMF)用于样本影像的分类。&lt;h4&gt;背景&lt;/h4&gt;肺部癌症诊断中多模态医学图像的应用日益广泛，但现有方法在有限数据条件下表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来利用CT和PET影像进行肺癌组织分类，并解决小规模数据集中的挑战问题。&lt;h4&gt;方法&lt;/h4&gt;使用PCA和自动编码器融合CT与PET影像；开发了新的集成学习模型DEMF，采用多数投票机制进行分类；应用Grad-CAM可视化癌变图像的分类精度。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的DEMF网络在三个公开数据集上表现优秀，在准确性、F1-Score、精确度和召回率等指标上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了DEMF模型在利用多模态医学影像进行肺癌诊断中的有效性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;这项研究的重点是利用CT和PET影像从多模态肺部图像中分类癌变组织与健康组织。所使用的数据包括了计算机断层扫描（CT）和正电子发射断层成像（PET）的图像。通过主成分分析（PCA）及自动编码器实现PET与CT影像的融合，并提出了一种新的集成学习分类方法Deep Ensembled Multimodal Fusion (DEMF)，它使用多数投票机制对样本图像进行分类。同时，利用Grad-CAM技术可视化了癌变组织影像的分类准确率。鉴于样本数据有限的问题，在训练阶段采用了随机影像增强策略。该网络在计算机辅助医学影像分析的小规模数据挑战中表现出色。所提出的模型与现有先进技术相比，在准确性、F1-Score、精确度和召回率等多个指标上取得了更高的成绩，这表明了所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICCCNT61001.2024.10726043&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study focuses on the classification of cancerous and healthy slices frommultimodal lung images. The data used in the research comprises ComputedTomography (CT) and Positron Emission Tomography (PET) images. The proposedstrategy achieves the fusion of PET and CT images by utilizing PrincipalComponent Analysis (PCA) and an Autoencoder. Subsequently, a new ensemble-basedclassifier developed, Deep Ensembled Multimodal Fusion (DEMF), employingmajority voting to classify the sample images under examination.Gradient-weighted Class Activation Mapping (Grad-CAM) employed to visualize theclassification accuracy of cancer-affected images. Given the limited samplesize, a random image augmentation strategy employed during the training phase.The DEMF network helps mitigate the challenges of scarce data in computer-aidedmedical image analysis. The proposed network compared with state-of-the-artnetworks across three publicly available datasets. The network outperformsothers based on the metrics - Accuracy, F1-Score, Precision, and Recall. Theinvestigation results highlight the effectiveness of the proposed network.</description>
      <author>example@mail.com (Surochita Pal, Sushmita Mitra)</author>
      <guid isPermaLink="false">2502.00078v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>EdgeGFL: Rethinking Edge Information in Graph Feature Preference Learning</title>
      <link>http://arxiv.org/abs/2502.02302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络(GNN)的框架，通过引入多维度边信息来改进节点特征的学习过程。&lt;h4&gt;背景&lt;/h4&gt;GNN在处理非欧几里得数据方面具有显著优势，并且已在各种领域广泛应用。然而，现有的大多数GNN模型面临一个挑战：即节点和边缘特征信息之间的脱节。&lt;h4&gt;目的&lt;/h4&gt;本文旨在开发一种基于边增强的图特征偏好学习框架，通过捕捉边嵌入来辅助节点嵌入的学习过程。&lt;h4&gt;方法&lt;/h4&gt;利用学到的多维边特征矩阵构建多通道滤波器以更有效地捕获精确的节点特征，并获取非局部结构特性和细粒度高阶节点特征。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够整合关系表示学习到消息传递架构中，使图中的节点接收更多的有用信息，从而促进节点表征学习。实验结果显示了所提出模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过将多维度边信息纳入GNN模型，增强了其功能性和灵活性，使其能更有效地处理复杂且多样化的图数据。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译已经完成&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have significant advantages in handlingnon-Euclidean data and have been widely applied across various areas, thusreceiving increasing attention in recent years. The framework of GNN modelsmainly includes the information propagation phase and the aggregation phase,treating nodes and edges as information entities and propagation channels,respectively. However, most existing GNN models face the challenge ofdisconnection between node and edge feature information, as these modelstypically treat the learning of edge and node features as independent tasks. Toaddress this limitation, we aim to develop an edge-empowered graph featurepreference learning framework that can capture edge embeddings to assist nodeembeddings. By leveraging the learned multidimensional edge feature matrix, weconstruct multi-channel filters to more effectively capture accurate nodefeatures, thereby obtaining the non-local structural characteristics andfine-grained high-order node features. Specifically, the inclusion ofmultidimensional edge information enhances the functionality and flexibility ofthe GNN model, enabling it to handle complex and diverse graph data moreeffectively. Additionally, integrating relational representation learning intothe message passing framework allows graph nodes to receive more usefulinformation, thereby facilitating node representation learning. Finally,experiments on four real-world heterogeneous graphs demonstrate theeffectiveness of theproposed model.</description>
      <author>example@mail.com (Shengda Zhuo, Jiwang Fang, Hongguang Lin, Yin Tang, Min Chen, Changdong Wang, Shuqiang Huang)</author>
      <guid isPermaLink="false">2502.02302v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2502.01201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In The Thirty-eighth Annual Conference on Neural Information  Processing Systems (NeurIPS2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的异常检测方法，通过个性化的图像生成模型改进了传统的无监督学习方式，并引入了三元对比异常推理策略以提高预测结果的稳定性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;传统异常检测方法主要依赖于从大量正常数据中进行无监督学习。随着大规模预训练视觉语言模型的发展，最近的方法在少量样本异常检测方面有所改进，但仍然存在准确性提升的局限性。&lt;h4&gt;目的&lt;/h4&gt;解决现有AD方法中的精度损失问题，并探索更复杂的应用场景。&lt;h4&gt;方法&lt;/h4&gt;提出了异常个性化方法，使用异常生成模型将查询图像转换为与正常数据流形紧密对齐的形式；同时引入三元对比异常推理策略以增强预测结果的稳定性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在三个领域的11个数据集上的广泛评估证明了该模型的有效性，并且证实了这种方法可以灵活地转移到其他AD方法中，生成的数据能够提升其它AD方法的表现。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法提供了比最新异常检测技术更准确的结果，并展示了其在扩展应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;传统的异常检测（AD）方法主要依赖于从大量正常数据进行无监督学习。随着大规模预训练视觉语言模型的出现，最近的AD方法改进了少量样本下的异常检测能力，但这些最新方法仍然存在准确性提升的局限性。我们提出了一种新的方法——异常个性化方法，通过使用异常生成模型将查询图像转换为与正常流形紧密对齐的形式，并引入三元对比异常推理策略以增强预测结果的稳定性和鲁棒性。广泛的评估表明该模型在各种数据集上的表现优于最新的AD方法，并且可以灵活地应用于其他AD方法中提升性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional Anomaly Detection (AD) methods have predominantly relied onunsupervised learning from extensive normal data. Recent AD methods haveevolved with the advent of large pre-trained vision-language models, enhancingfew-shot anomaly detection capabilities. However, these latest AD methods stillexhibit limitations in accuracy improvement. One contributing factor is theirdirect comparison of a query image's features with those of few-shot normalimages. This direct comparison often leads to a loss of precision andcomplicates the extension of these techniques to more complex domains--an areathat remains underexplored in a more refined and comprehensive manner. Toaddress these limitations, we introduce the anomaly personalization method,which performs a personalized one-to-normal transformation of query imagesusing an anomaly-free customized generation model, ensuring close alignmentwith the normal manifold. Moreover, to further enhance the stability androbustness of prediction results, we propose a triplet contrastive anomalyinference strategy, which incorporates a comprehensive comparison between thequery and generated anomaly-free data pool and prompt information. Extensiveevaluations across eleven datasets in three domains demonstrate our model'seffectiveness compared to the latest AD methods. Additionally, our method hasbeen proven to transfer flexibly to other AD methods, with the generated imagedata effectively improving the performance of other AD methods.</description>
      <author>example@mail.com (Yiyue Li, Shaoting Zhang, Kang Li, Qicheng Lao)</author>
      <guid isPermaLink="false">2502.01201v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hyperparameters via a Data-Emphasized Variational Objective</title>
      <link>http://arxiv.org/abs/2502.01861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2410.19675&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在训练大规模灵活模型时，从业人员常常依赖于网格搜索来选择控制过拟合的超参数。然而，这种做法存在计算成本高、需要划分验证集减少可用于训练的数据量以及用户需指定候选值等缺点。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代方案：直接通过变分方法中的证据下界（ELBo）目标函数在完整训练集上学习正则化超参数。&lt;h4&gt;方法&lt;/h4&gt;对于包含数百万个参数的深度神经网络，推荐使用一种修改后的ELBo，在该过程中数据似然度的影响被加强以相对于先验而言。&lt;h4&gt;主要发现&lt;/h4&gt;通过案例研究展示：我们的方法将图像分类器迁移学习中的88+小时网格搜索时间缩短到了不到3小时内，同时保持了相当的准确性。另外展示了这种方法能有效且准确地进行高斯过程的学习长度尺度内核近似。&lt;h4&gt;结论&lt;/h4&gt;所提出的技术克服了网格搜索的所有三个缺点，并证明在特定应用中能够显著减少计算时间和提高效率。&lt;h4&gt;翻译&lt;/h4&gt;当训练大规模灵活模型时，研究人员常常依赖于网格搜索来选择控制过拟合的超参数。但是这种做法存在计算成本高、需要划分验证集以牺牲一部分训练数据量以及用户需手动指定候选值等缺点。在本文中，我们提出了一种替代方案：直接利用变分方法中的证据下界（ELBo）目标函数，在完整训练集中学习正则化超参数。针对包含数百万个参数的深度神经网络模型，建议采用一种修改后的ELBo方式，加强数据似然度的影响以相对于先验而言。我们所提出的技术克服了网格搜索的所有缺点，并展示了在图像分类器迁移学习案例研究中将88+小时的网格搜索时间减少到不足3小时，同时保持相当高的准确性。进一步证明了这种方法能够有效地实现高斯过程的学习长度尺度内核近似。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When training large flexible models, practitioners often rely on grid searchto select hyperparameters that control over-fitting. This grid search hasseveral disadvantages: the search is computationally expensive, requirescarving out a validation set that reduces the available data for training, andrequires users to specify candidate values. In this paper, we propose analternative: directly learning regularization hyperparameters on the fulltraining set via the evidence lower bound ("ELBo") objective from variationalmethods. For deep neural networks with millions of parameters, we recommend amodified ELBo that upweights the influence of the data likelihood relative tothe prior. Our proposed technique overcomes all three disadvantages of gridsearch. In a case study on transfer learning of image classifiers, we show howour method reduces the 88+ hour grid search of past work to under 3 hours whiledelivering comparable accuracy. We further demonstrate how our approach enablesefficient yet accurate approximations of Gaussian processes with learnablelength-scale kernels.</description>
      <author>example@mail.com (Ethan Harvey, Mikhail Petrov, Michael C. Hughes)</author>
      <guid isPermaLink="false">2502.01861v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Combinatorial Optimization Perspective based Framework for Multi-behavior Recommendation</title>
      <link>http://arxiv.org/abs/2502.02232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by KDD 2025 Research Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于组合优化视角的多行为推荐框架COPF，旨在通过改进多行为融合和预测步骤来提升推荐系统的性能。&lt;h4&gt;背景&lt;/h4&gt;在现实世界的推荐场景中，用户的行为多样化。现有的主流方法利用图神经网络进行多行为融合，并采用多任务学习联合优化预测过程，但这些方法在捕捉用户行为模式方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法中存在的问题，提出了一种新的基于组合优化视角的多行为推荐框架COPF。&lt;h4&gt;方法&lt;/h4&gt;将多行为融合视为一个组合优化问题，并针对每个行为的不同阶段施加不同的约束条件以限制解决方案空间。此外，在预测步骤中改进了前向和后向传播过程，减少了由特征分布和标签分布差异引起的负面转移。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明COPF框架在三个实际数据集上的性能优于现有方法，进一步分析验证了COGCN和DFME模块的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于组合优化视角的多行为推荐框架能够有效提升推荐系统的性能。该框架通过改进融合过程中的解决方案空间限制以及预测步骤中特征分布和标签分布差异造成的负面转移问题来实现这一目标。&lt;h4&gt;翻译&lt;/h4&gt;在现实世界推荐场景中，用户通过各种类型的行为与项目互动。利用多样化的用户行为信息进行学习可以增强对目标行为（如购买）的推荐效果，近期多行为方法已证明了这一点。主流的多行为推荐框架包括两个步骤：融合和预测。最近的方法使用图神经网络实现多行为融合，并在预测阶段采用多任务学习范式联合优化，取得了显著的成功。然而，这些方法对多行为融合的视角有限制，在融合步骤中无法准确捕捉用户的行为模式。此外，在利用多任务学习进行预测时，目标任务与辅助任务之间的关系协调不足，导致了负面信息转移。为解决这些问题，我们提出了一种基于组合优化视角的新颖多行为推荐框架COPF。具体来说，我们将多行为融合视为一个组合优化问题，并在每个行为的不同阶段施加不同的约束条件以限制解决方案空间，从而显著提升融合效率（COGCN）。在预测步骤中，我们在生成和聚合多个专家时改进了前向传播和后向传播过程，减轻了特征分布和标签分布差异造成的负面转移（DFME）。对三个实际数据集的全面实验表明COPF具有优越性。进一步分析也验证了COGCN和DFME模块的有效性。我们的代码可在https://github.com/1918190/COPF上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world recommendation scenarios, users engage with items throughvarious types of behaviors. Leveraging diversified user behavior informationfor learning can enhance the recommendation of target behaviors (e.g., buy), asdemonstrated by recent multi-behavior methods. The mainstream multi-behaviorrecommendation framework consists of two steps: fusion and prediction. Recentapproaches utilize graph neural networks for multi-behavior fusion and employmulti-task learning paradigms for joint optimization in the prediction step,achieving significant success. However, these methods have limited perspectiveson multi-behavior fusion, which leads to inaccurate capture of user behaviorpatterns in the fusion step. Moreover, when using multi-task learning forprediction, the relationship between the target task and auxiliary tasks is notsufficiently coordinated, resulting in negative information transfer. Toaddress these problems, we propose a novel multi-behavior recommendationframework based on the combinatorial optimization perspective, named COPF.Specifically, we treat multi-behavior fusion as a combinatorial optimizationproblem, imposing different constraints at various stages of each behavior torestrict the solution space, thus significantly enhancing fusion efficiency(COGCN). In the prediction step, we improve both forward and backwardpropagation during the generation and aggregation of multiple experts tomitigate negative transfer caused by differences in both feature and labeldistributions (DFME). Comprehensive experiments on three real-world datasetsindicate the superiority of COPF. Further analyses also validate theeffectiveness of the COGCN and DFME modules. Our code is available athttps://github.com/1918190/COPF.</description>
      <author>example@mail.com (Chenhao Zhai, Chang Meng, Yu Yang, Kexin Zhang, Xuhao Zhao, Xiu Li)</author>
      <guid isPermaLink="false">2502.02232v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Consensus Network for Multiview Feature Learning</title>
      <link>http://arxiv.org/abs/2502.01961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  AAAI 2025 accepted paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个层次共识网络(HCN)，旨在通过捕捉跨视图的层级一致性来改进多视图特征学习，从而提高特征的判别能力。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数方法在学习视图一致性的特征时仍然面临重大挑战。而这些问题对于有效的多视图学习至关重要。&lt;h4&gt;目的&lt;/h4&gt;论文提出了一种新的网络结构（HCN），利用CCA理论和对比学习理论来解决现有方法面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;HCN开发了三个共识指标——分类一致性、编码一致性和全局一致性，分别从不同层次捕捉跨视图的一致性。具体而言，分类一致性通过CCA视角强化类级别的对应关系；编码一致性类似于对比学习，并反映个体实例之间的对比比较；全局一致性则同时从两个角度提取一致性信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过强制执行层级共识，HCN能够更好地整合各视图内的信息，从而获得更全面和判别性更强的特征。在四个多视图数据集上的广泛实验结果表明，该方法显著优于几种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的层次共识网络（HCN）是解决多视图学习中一致性和特征提取问题的有效途径，并且从多个基准测试证明了其优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiview feature learning aims to learn discriminative features byintegrating the distinct information in each view. However, most existingmethods still face significant challenges in learning view-consistencyfeatures, which are crucial for effective multiview learning. Motivated by thetheories of CCA and contrastive learning in multiview feature learning, wepropose the hierarchical consensus network (HCN) in this paper. The HCN derivesthree consensus indices for capturing the hierarchical consensus across views,which are classifying consensus, coding consensus, and global consensus,respectively. Specifically, classifying consensus reinforces class-levelcorrespondence between views from a CCA perspective, while coding consensusclosely resembles contrastive learning and reflects contrastive comparison ofindividual instances. Global consensus aims to extract consensus informationfrom two perspectives simultaneously. By enforcing the hierarchical consensus,the information within each view is better integrated to obtain morecomprehensive and discriminative features. The extensive experimental resultsobtained on four multiview datasets demonstrate that the proposed methodsignificantly outperforms several state-of-the-art methods.</description>
      <author>example@mail.com (Chengwei Xia, Chaoxi Niu, Kun Zhan)</author>
      <guid isPermaLink="false">2502.01961v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Invariant Kernels: Rank Stabilization and Generalization Across Dimensions</title>
      <link>http://arxiv.org/abs/2502.01886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了对称性如何影响高维数据学习算法的统计效率和数值效率，特别是对于点云、图和无序集合等具有丰富内在对称性的数据集。&lt;h4&gt;背景&lt;/h4&gt;在现代应用中，经常遇到由点云、图和无序集合构成的数据集，这些数据集中蕴含着丰富的内部对称性。理解对称性如何影响学习算法的效率是一个活跃的研究领域。&lt;h4&gt;目的&lt;/h4&gt;探讨对称性对于核矩阵秩的影响，并展示对某些特定情况而言，对称性能显著降低核矩阵的秩，使其与数据维度无关。&lt;h4&gt;方法&lt;/h4&gt;研究了一种在两个独立作用于其参数上的不同群的作用下不变的多项式核函数，在给定情况下计算其核矩阵的秩。&lt;h4&gt;主要发现&lt;/h4&gt;当存在对称性时，核矩阵的秩显著下降。对于某些特定情况（如点云、图和无序集合），这种现象使得从有限数量的不同维度样本中估计不变多项式的简单回归过程成为最优解。&lt;h4&gt;结论&lt;/h4&gt;论文通过数值实验验证了上述发现，并展示了对称性在优化学习算法效率方面的重要作用。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Symmetry arises often when learning from high dimensional data. For example,data sets consisting of point clouds, graphs, and unordered sets appearroutinely in contemporary applications, and exhibit rich underlying symmetries.Understanding the benefits of symmetry on the statistical and numericalefficiency of learning algorithms is an active area of research. In this work,we show that symmetry has a pronounced impact on the rank of kernel matrices.Specifically, we compute the rank of a polynomial kernel of fixed degree thatis invariant under various groups acting independently on its two arguments. Inconcrete circumstances, including the three aforementioned examples, symmetrydramatically decreases the rank making it independent of the data dimension. Insuch settings, we show that a simple regression procedure is minimax optimalfor estimating an invariant polynomial from finitely many samples drawn acrossdifferent dimensions. We complete the paper with numerical experiments thatillustrate our findings.</description>
      <author>example@mail.com (Mateo Díaz, Dmitriy Drusvyatskiy, Jack Kendrick, Rekha R. Thomas)</author>
      <guid isPermaLink="false">2502.01886v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Informed Neural Network based Damage Identification for Truss Railroad Bridges</title>
      <link>http://arxiv.org/abs/2502.00194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;铁路桥梁在美国货运铁路系统中扮演着关键角色，但因老化和交通增加而带来的安全风险日益加剧。&lt;h4&gt;背景&lt;/h4&gt;美国铁路网络包括超过10万座铁路桥，平均每1.4英里轨道一座。其中50%以上为钢结构桥梁，这些结构面临早期识别与评估损坏的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究提出了一种基于物理信息神经网络（PINN）的方法来在钢桁架铁路桥中进行损伤识别。&lt;h4&gt;方法&lt;/h4&gt;该方法采用无监督学习方式，利用列车轮载数据和跨桥事件中的桥梁响应作为输入，同时将线性时变系统的基本微分方程明确纳入模型。此外，此模型采用了带有自定义Runge-Kutta积分器单元的递归神经网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;在芝加哥伊利诺伊州Calumet桥的仿真损坏场景中进行了案例研究，展示了该模型的有效性和低误报率性能。&lt;h4&gt;结论&lt;/h4&gt;提出的损伤识别流程设计为能够无缝集成来自检查和无人机调查之前的先验知识，并且支持根据背景信息进行桥梁状态更新与评估。&lt;h4&gt;翻译&lt;/h4&gt;铁路桥梁在美国货运铁路系统中的重要性以及所面临的安全挑战，通过物理信息神经网络方法对钢桁架铁路桥的损伤识别、无监督学习的应用、递归神经网络架构的设计及其在实际案例中的应用进行了阐述。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Railroad bridges are a crucial component of the U.S. freight rail system,which moves over 40 percent of the nation's freight and plays a critical rolein the economy. However, aging bridge infrastructure and increasing traintraffic pose significant safety hazards and risk service disruptions. The U.S.rail network includes over 100,000 railroad bridges, averaging one every 1.4miles of track, with steel bridges comprising over 50% of the network's totalbridge length. Early identification and assessment of damage in these bridgesremain challenging tasks. This study proposes a physics-informed neural network(PINN) based approach for damage identification in steel truss railroadbridges. The proposed approach employs an unsupervised learning approach,eliminating the need for large datasets typically required by supervisedmethods. The approach utilizes train wheel load data and bridge response duringtrain crossing events as inputs for damage identification. The PINN modelexplicitly incorporates the governing differential equations of the lineartime-varying (LTV) bridge-train system. Herein, this model employs a recurrentneural network (RNN) based architecture incorporating a custom Runge-Kutta (RK)integrator cell, designed for gradient-based learning. The proposed approachupdates the bridge finite element model while also quantifying damage severityand localizing the affected structural members. A case study on the CalumetBridge in Chicago, Illinois, with simulated damage scenarios, is used todemonstrate the model's effectiveness in identifying damage while maintaininglow false-positive rates. Furthermore, the damage identification pipeline isdesigned to seamlessly integrate prior knowledge from inspections and dronesurveys, also enabling context-aware updating and assessment of bridge'scondition.</description>
      <author>example@mail.com (Althaf Shajihan, Kirill Mechitov, Girish Chowdhary, Billie F. Spencer Jr)</author>
      <guid isPermaLink="false">2502.00194v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Grokking Explained: A Statistical Phenomenon</title>
      <link>http://arxiv.org/abs/2502.01774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了深度学习网络中的一个有趣现象——grokking，即模型在训练集损失收敛后，测试集上的性能突然提升。&lt;h4&gt;背景&lt;/h4&gt;Grokkng是一种学习现象，在这种现象中，尽管模型的训练数据损失已经收敛，但在测试集中表现急剧下降的现象依然存在。这挑战了对深度学习网络训练动态的传统理解。&lt;h4&gt;目的&lt;/h4&gt;形式化并探讨grokking现象，并通过特定设计的数据集研究其原因和机制。&lt;h4&gt;方法&lt;/h4&gt;引入两个专门用于分析grokking的合成数据集，一个关注有限采样的影响，另一个调查迁移学习在其中的作用。通过控制不平衡子类别的抽样来诱导分布偏移，系统地重现了这种现象。&lt;h4&gt;主要发现&lt;/h4&gt;小样本并不是导致grokking的原因，而是实现所需分布转移的一种便捷机制；当类别形成等变映射时，模型可以利用相似类别或子类的学习能力来解释grokking。此外，grokking不仅在高正则化和稀疏数据中出现，在稠密数据和微调参数的情况下也能发生。&lt;h4&gt;结论&lt;/h4&gt;研究结果加深了对grokking的理解，并为未来训练过程中开发更好的停止准则铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种学习现象——Grokkng，以及作者们如何通过设计特定的合成数据集来探究这一现象背后的原因和机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grokking, or delayed generalization, is an intriguing learning phenomenonwhere test set loss decreases sharply only after a model's training set losshas converged. This challenges conventional understanding of the trainingdynamics in deep learning networks. In this paper, we formalize and investigategrokking, highlighting that a key factor in its emergence is a distributionshift between training and test data. We introduce two synthetic datasetsspecifically designed to analyze grokking. One dataset examines the impact oflimited sampling, and the other investigates transfer learning's role ingrokking. By inducing distribution shifts through controlled imbalancedsampling of sub-categories, we systematically reproduce the phenomenon,demonstrating that while small-sampling is strongly associated with grokking,it is not its cause. Instead, small-sampling serves as a convenient mechanismfor achieving the necessary distribution shift. We also show that when classesform an equivariant map, grokking can be explained by the model's ability tolearn from similar classes or sub-categories. Unlike earlier work suggestingthat grokking primarily arises from high regularization and sparse data, wedemonstrate that it can also occur with dense data and minimal hyper-parametertuning. Our findings deepen the understanding of grokking and pave the way fordeveloping better stopping criteria in future training processes.</description>
      <author>example@mail.com (Breno W. Carvalho, Artur S. d'Avila Garcez, Luís C. Lamb, Emílio Vital Brazil)</author>
      <guid isPermaLink="false">2502.01774v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Domain Graph Foundation Models: Robust Knowledge Transfer via Topology Alignment</title>
      <link>http://arxiv.org/abs/2502.02017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多领域图基础模型（MDGFM），旨在解决跨不同领域的图拓扑差异和稀疏性、噪声及对抗攻击的问题，通过统一框架促进鲁棒的知识迁移。&lt;h4&gt;背景&lt;/h4&gt;计算机视觉和自然语言处理的进展促使研究者开发通用图的基础模型。然而，不同域之间的图拓扑差异构成了一个基本挑战，实际中的图往往稀疏且易受噪声干扰和对抗性攻击。&lt;h4&gt;目的&lt;/h4&gt;为了应对这些挑战并促进跨领域的知识迁移，提出了MDGFM以统一框架来处理这些问题，并通过有效的提示微调方法进一步增强知识迁移能力。&lt;h4&gt;方法&lt;/h4&gt;MDGFM通过自适应平衡特征和拓扑结构以及改进原始图来消除噪声和对齐拓扑结构的方式连接不同领域。它还引入了一种高效的提示微调方法，以促进有效且可泛化的知识转移。&lt;h4&gt;主要发现&lt;/h4&gt;理论上分析了MDGFM的有效性和域泛化能力，并通过在同质和异质图形数据集上的广泛实验验证了该方法的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的MDGFM框架不仅改进了跨多领域的预训练，还增强了从已知领域到未见领域的知识迁移的能力，展示了其在处理复杂现实世界问题中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;近期计算机视觉和自然语言处理的进步激励研究者通过在不同域的预训练来开发通用图的基础模型。然而，来自各领域间显著不同的图拓扑结构带来了基本挑战，并且实际中的图通常稀疏并容易受到噪声连接和对抗性攻击的影响。为应对这些问题，我们提出了多域图基础模型（MDGFM），一种统一框架通过对齐和利用跨领域的拓扑信息来促进鲁棒的知识迁移。MDGFM通过自适应平衡特征与拓扑，并改进原始图表以消除噪声及对齐结构的方式连接不同领域。为了进一步增强知识迁移，我们提出了一种高效的提示微调方法。通过对齐图的拓扑结构，MDGFM不仅提高了跨多领域的预训练效果，还使从已知域到未见域的知识转移变得更加可靠。理论分析保证了MDGFM的有效性和在新领域中的泛化能力，并通过同质和异质图形数据集上的广泛实验验证其鲁棒性与有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in CV and NLP have inspired researchers to developgeneral-purpose graph foundation models through pre-training across diversedomains. However, a fundamental challenge arises from the substantialdifferences in graph topologies across domains. Additionally, real-world graphsare often sparse and prone to noisy connections and adversarial attacks. Toaddress these issues, we propose the Multi-Domain Graph Foundation Model(MDGFM), a unified framework that aligns and leverages cross-domain topologicalinformation to facilitate robust knowledge transfer. MDGFM bridges differentdomains by adaptively balancing features and topology while refining originalgraphs to eliminate noise and align topological structures. To further enhanceknowledge transfer, we introduce an efficient prompt-tuning approach. Byaligning topologies, MDGFM not only improves multi-domain pre-training but alsoenables robust knowledge transfer to unseen domains. Theoretical analysesprovide guarantees of MDGFM's effectiveness and domain generalizationcapabilities. Extensive experiments on both homophilic and heterophilic graphdatasets validate the robustness and efficacy of our method.</description>
      <author>example@mail.com (Shuo Wang, Bokui Wang, Zhixiang Shen, Boyan Deng, Zhao Kang)</author>
      <guid isPermaLink="false">2502.02017v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>PolyhedronNet: Representation Learning for Polyhedra with Surface-attributed Graph</title>
      <link>http://arxiv.org/abs/2502.01814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为PolyhedronNet的框架，用于学习三维多面体对象的表示。该方法引入了表面属性图的概念，能够无缝建模顶点、边和面及其几何关系，并通过局部刚性表示以及跨面信息传递模块来聚合得到全局表示。&lt;h4&gt;背景&lt;/h4&gt;在处理像分类、聚类和生成这样的任务时，将多面体转化为向量表示对于数学工具和统计方法来说是至关重要的。然而，现有的大多数研究主要集中在多面体顶点序列上，忽略了建模复杂表面的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出一个全面且信息丰富的三维多面体对象表示学习框架，以解决现有技术的不足并提高对现实世界中多面体模型处理的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了PolyhedronNet框架以及其核心部分——表面属性图和PolyhedronGNN。前者通过局部刚性表示有效地建模整个表面积的几何关系；后者通过跨边与跨面的消息传递模块聚合这些局部信息，以减少信息丢失同时保持旋转和平移不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，PolyhedronNet在四个不同的数据集上，无论是分类任务还是检索任务中都展现了其有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的PolyhedronNet框架通过引入表面属性图和局部刚性表示的概念，成功地解决了现有技术对复杂多面体建模的忽视问题，并展示了它在多项实验中的强大性能。&lt;h4&gt;翻译&lt;/h4&gt;普遍存在且具有几何形状的对象可以被精确而高效地表示为多面体。将一个多面体转换成向量的过程称为多面体表示学习，在诸如分类、聚类和生成这样的任务中，这对于使用数学工具进行操作至关重要。最近几年在这一领域取得了显著的进展，但大多数努力集中在多面体顶点序列上，并忽略了对现实世界中复杂多面体模型表面建模的重要性。这项研究提出了PolyhedronNet框架，这是一种针对三维多面体对象表示学习而设计的一般性框架。我们提出了一种基于表面属性图的概念，可以无缝地模拟多面体内顶点、边和面及其几何关系。为了有效地从整个表面积中获取其表示，我们将该概念进一步细化为局部刚性表示以在不丢失任何几何信息的前提下有效学习每个区域相对于其他部分的相对位置。紧接着我们提出了PolyhedronGNN通过跨边以及跨面的几何消息传递模块层次化聚合这些局部刚性表示来获得全局表示，并尽量减少信息损失同时保持旋转和平移不变性。我们的实验验证了PolyhedronNet在分类与检索任务上四个不同数据集中的有效性，其能够捕获全面且具信息性的三维多面体对象表示。相关代码和数据可从GitHub上的{https://github.com/dyu62/3D_polyhedron}获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ubiquitous geometric objects can be precisely and efficiently represented aspolyhedra. The transformation of a polyhedron into a vector, known as polyhedrarepresentation learning, is crucial for manipulating these shapes withmathematical and statistical tools for tasks like classification, clustering,and generation. Recent years have witnessed significant strides in this domain,yet most efforts focus on the vertex sequence of a polyhedron, neglecting thecomplex surface modeling crucial in real-world polyhedral objects. This studyproposes \textbf{PolyhedronNet}, a general framework tailored for learningrepresentations of 3D polyhedral objects. We propose the concept of thesurface-attributed graph to seamlessly model the vertices, edges, faces, andtheir geometric interrelationships within a polyhedron. To effectively learnthe representation of the entire surface-attributed graph, we first propose tobreak it down into local rigid representations to effectively learn each localregion's relative positions against the remaining regions without geometricinformation loss. Subsequently, we propose PolyhedronGNN to hierarchicallyaggregate the local rigid representation via intra-face and inter-facegeometric message passing modules, to obtain a global representation thatminimizes information loss while maintaining rotation and translationinvariance. Our experimental evaluations on four distinct datasets,encompassing both classification and retrieval tasks, substantiatePolyhedronNet's efficacy in capturing comprehensive and informativerepresentations of 3D polyhedral objects. Code and data are available at{https://github.com/dyu62/3D_polyhedron}.</description>
      <author>example@mail.com (Dazhou Yu, Genpei Zhang, Liang Zhao)</author>
      <guid isPermaLink="false">2502.01814v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards Robust and Generalizable Lensless Imaging with Modular Learned Reconstruction</title>
      <link>http://arxiv.org/abs/2502.01102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了无镜头相机的模块化重建技术，通过预先处理和图像恢复来实现先进的无透镜成像。&lt;h4&gt;背景&lt;/h4&gt;传统的成像设计模仿人类的眼睛，使用透镜进行光学聚焦。然而，新兴的无镜头相机通过使用薄型掩模替代传统透镜，并将图像形成转移到数字后处理中来挑战这一模式。&lt;h4&gt;目的&lt;/h4&gt;为了改善现有学习方法在不同掩模类型中的泛化能力，论文提出了一种模块化的重建技术，该技术可以通过预处理器提高标准图像恢复算法的性能。&lt;h4&gt;方法&lt;/h4&gt;利用物理建模和神经网络结合的方式实现无镜头成像。通过广泛的实验展示其对多种无镜头成像方法的有效性，并且在不同掩模类型的数据集上进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;论文展示了预处理器对于标准图像恢复技术（如维纳滤波器和迭代算法）的必要性和有效性，以及该技术如何改进现有学习方法以适应新的掩模。&lt;h4&gt;结论&lt;/h4&gt;提出的模块化重建技术可以使用预先训练的组件并通过迁移学习在新系统中应用，从而大大减少测量和训练所需的时间。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种先进的无镜头成像技术的研究。此研究挑战了传统的光学聚焦方式，通过采用物理模型与神经网络结合的方法，并引入模块化重建方法以改善现有算法的效果，特别是在不同掩模类型之间的泛化能力上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lensless cameras disregard the conventional design that imaging should mimicthe human eye. This is done by replacing the lens with a thin mask, and movingimage formation to the digital post-processing. State-of-the-art lenslessimaging techniques use learned approaches that combine physical modeling andneural networks. However, these approaches make simplifying modelingassumptions for ease of calibration and computation. Moreover, thegeneralizability of learned approaches to lensless measurements of new maskshas not been studied. To this end, we utilize a modular learned reconstructionin which a key component is a pre-processor prior to image recovery. Wetheoretically demonstrate the pre-processor's necessity for standard imagerecovery techniques (Wiener filtering and iterative algorithms), and throughextensive experiments show its effectiveness for multiple lensless imagingapproaches and across datasets of different mask types (amplitude and phase).We also perform the first generalization benchmark across mask types toevaluate how well reconstructions trained with one system generalize to others.Our modular reconstruction enables us to use pre-trained components andtransfer learning on new systems to cut down weeks of tedious measurements andtraining. As part of our work, we open-source four datasets, and software formeasuring datasets and for training our modular reconstruction.</description>
      <author>example@mail.com (Eric Bezzam, Yohann Perron, Martin Vetterli)</author>
      <guid isPermaLink="false">2502.01102v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>SE Arena: Benchmarking Software Engineering Chatbots with Iterative Interactions</title>
      <link>http://arxiv.org/abs/2502.01860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://huggingface.co/spaces/SE-Arena/Software-Engineering-Arena&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了SE Arena，这是一个用于评估软件工程（SE）领域专用聊天机器人的互动平台。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在代码生成、调试和需求细化等软件工程任务中展现出巨大潜力。然而，现有的评估框架无法充分衡量这些模型在迭代的、富含上下文的工作流程中的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个透明且开源的排行榜系统，支持多轮对话工作流，并提供端到端的模型比较能力。&lt;h4&gt;方法&lt;/h4&gt;SE Arena设计用于全面评价专注于软件工程任务的聊天机器人，包括代码相关问题和需求细化等。&lt;h4&gt;主要发现&lt;/h4&gt;引入RepoChat功能，该功能自动将仓库相关的上下文（如问题、提交记录、拉取请求）注入对话中，使评估结果更符合真实开发流程。&lt;h4&gt;结论&lt;/h4&gt;SE Arena及其RepoChat功能有望推进基础模型在软件工程中的评价和实际应用。&lt;h4&gt;翻译&lt;/h4&gt;基础模型在各种软件工程任务中展示了巨大的潜力，特别是在代码生成、调试和需求细化方面。现有的评估框架不足以衡量这些模型在迭代的、富含上下文的工作流程中的表现。为了弥补这一不足，我们介绍了SE Arena，这是一个互动平台，用于评价以软件工程为中心的聊天机器人。该平台提供了一个透明且开源的排行榜系统，支持多轮对话工作流，并能够进行端到端的模型比较。此外，SE Arena引入了名为RepoChat的新功能，它自动将仓库相关的上下文（如问题、提交记录和拉取请求）注入对话中，进一步使评估结果与实际开发流程保持一致。本文概述了SE Arena的设计和能力，强调其在基础模型评价及其在软件工程中的实际应用方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs), particularly large language models (LLMs), haveshown significant promise in various software engineering (SE) tasks, includingcode generation, debugging, and requirement refinement. Despite these advances,existing evaluation frameworks are insufficient for assessing model performancein iterative, context-rich workflows characteristic of SE activities. Toaddress this limitation, we introduce SE Arena, an interactive platformdesigned to evaluate SE-focused chatbots. SE Arena provides a transparent,open-source leaderboard, supports multi-round conversational workflows, andenables end-to-end model comparisons. Moreover, SE Arena incorporates a newfeature called RepoChat, which automatically injects repository-related context(e.g., issues, commits, pull requests) into the conversation, further aligningevaluations with real-world development processes. This paper outlines thedesign and capabilities of SE Arena, emphasizing its potential to advance theevaluation and practical application of FMs in software engineering.</description>
      <author>example@mail.com (Zhimin Zhao)</author>
      <guid isPermaLink="false">2502.01860v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Few-Shot Defect Segmentation in General Industrial Scenarios with Metric Learning and Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2502.01216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;工业缺陷分割对于制造业的质量控制至关重要。由于训练样本稀缺，少样本语义分割(FSS)在这一领域具有重要意义。&lt;h4&gt;背景&lt;/h4&gt;现有研究大多应用FSS来处理简单纹理上的缺陷问题，而忽视了更多样化的场景考虑。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补上述空白，通过探索更广泛的工业产品（包括各种类型缺陷）中的少样本语义分割任务。&lt;h4&gt;方法&lt;/h4&gt;为此，我们贡献了一个新的真实世界数据集，并重组了一些现有的数据集以构建一个更为全面的FDS基准。在此基础上，对基于度量学习的FSS方法进行了深入研究，涵盖元学习和视觉基础模型(VFM)两类。&lt;h4&gt;主要发现&lt;/h4&gt;现有基于元学习的方法通常不适合此任务，而VFM在该领域展示出巨大潜力。进一步地，系统性探讨了不同VFMs在此任务中的适用性，并提出了一种基于特征匹配的高效FDS方法，以及发现SAM2模型特别适合通过其视频跟踪模式解决FDS问题。&lt;h4&gt;结论&lt;/h4&gt;本文贡献的数据集和代码可在以下链接获取：https://github.com/liutongkun/GFDS。&lt;h4&gt;翻译&lt;/h4&gt;工业缺陷分割是制造质量控制的关键环节。由于训练样本的稀缺性，少样本语义分割（FSS）在这一领域具有重要价值。然而，现有研究主要应用FSS来解决简单纹理上的缺陷问题，并未考虑更多样化的场景。本文旨在通过探索更广泛的工业产品（包括各种类型缺陷）中的少样本语义分割任务以填补上述空白。为此，我们贡献了一个新的真实世界数据集，并重组了一些现有的数据集以构建一个更为全面的FDS基准。在此基础上，对基于度量学习的FSS方法进行了深入研究，涵盖元学习和视觉基础模型（VFM）两类。观察到现有基于元学习的方法通常不适合此任务，而VFM展示出巨大潜力。进一步地，系统性探讨了不同VFMs在此任务中的适用性，并提出了一种基于特征匹配的高效FDS方法，以及发现SAM2模型特别适合通过其视频跟踪模式解决FDS问题。本文贡献的数据集和代码可在以下链接获取：https://github.com/liutongkun/GFDS。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial defect segmentation is critical for manufacturing quality control.Due to the scarcity of training defect samples, few-shot semantic segmentation(FSS) holds significant value in this field. However, existing studies mostlyapply FSS to tackle defects on simple textures, without considering morediverse scenarios. This paper aims to address this gap by exploring FSS inbroader industrial products with various defect types. To this end, wecontribute a new real-world dataset and reorganize some existing datasets tobuild a more comprehensive few-shot defect segmentation (FDS) benchmark. Onthis benchmark, we thoroughly investigate metric learning-based FSS methods,including those based on meta-learning and those based on Vision FoundationModels (VFMs). We observe that existing meta-learning-based methods aregenerally not well-suited for this task, while VFMs hold great potential. Wefurther systematically study the applicability of various VFMs in this task,involving two paradigms: feature matching and the use of Segment Anything (SAM)models. We propose a novel efficient FDS method based on feature matching.Meanwhile, we find that SAM2 is particularly effective for addressing FDSthrough its video track mode. The contributed dataset and code will beavailable at: https://github.com/liutongkun/GFDS.</description>
      <author>example@mail.com (Tongkun Liu, Bing Li, Xiao Jin, Yupeng Shi, Qiuying Li, Xiang Wei)</author>
      <guid isPermaLink="false">2502.01216v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Fruit Fly Classification (Diptera: Tephritidae) in Images, Applying Transfer Learning</title>
      <link>http://arxiv.org/abs/2502.00939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages and 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文开发了一种迁移学习模型，用于在实验室环境中自动分类两种果蝇（Anastrepha fraterculus 和 Ceratitis capitata）。该研究旨在通过机器学习技术提高分类效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;目前对这两种果蝇的识别与分类主要由专家手动完成，存在人为因素影响且耗时较长的问题。&lt;h4&gt;目的&lt;/h4&gt;优化果蝇的自动识别和分类流程，减少人类错误并提高工作效率。&lt;h4&gt;方法&lt;/h4&gt;使用手机摄像头和立体显微镜拍摄高质量图像，并通过分割技术处理以聚焦于关键形态特征。利用预训练卷积神经网络模型（VGG16、VGG19 和 Inception-v3）进行模型训练，并用 F1 分数评估分类准确性。&lt;h4&gt;主要发现&lt;/h4&gt;Inception-v3 模型在未受控环境中测试时取得了最高的 93% 的 F1 得分，证明了其可靠性和有效性。同时，Grad-CAM 技术的使用显示该模型能够捕捉到重要的形态特征。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明 Inception-v3 是一种有效的、可重复的方法来分类这两种果蝇，并具有应用于自动化监测系统的潜力。&lt;h4&gt;翻译&lt;/h4&gt;这项研究开发了一种迁移学习模型，在受控实验室环境中用于两种果蝇（Anastrepha fraterculus 和 Ceratitis capitata）的自动分类。该研究解决了专家手动进行识别和分类时受到人为因素影响以及时间挑战的问题。通过手机摄像头和立体显微镜捕获高质量图像，并使用分割技术减少图像大小并聚焦于相关的形态特征区域。经过精心标注和预处理的数据集用于训练 VGG16、VGG19 和 Inception-v3 预训练卷积神经网络模型，其中 Inception-v3 模型达到了最高的 F1 得分（93%）。该模型在未受控环境中的测试结果为正，结合 Grad-CAM 技术证明其能够捕获到关键形态特征。研究发现表明 Inception-v3 是一种有效且可重复的方法来分类这两种果蝇，并具有应用于自动化监测系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study develops a transfer learning model for the automatedclassification of two species of fruit flies, Anastrepha fraterculus andCeratitis capitata, in a controlled laboratory environment. The researchaddresses the need to optimize identification and classification, which arecurrently performed manually by experts, being affected by human factors andfacing time challenges. The methodological process of this study includes thecapture of high-quality images using a mobile phone camera and a stereomicroscope, followed by segmentation to reduce size and focus on relevantmorphological areas. The images were carefully labeled and preprocessed toensure the quality and consistency of the dataset used to train the pre-trainedconvolutional neural network models VGG16, VGG19, and Inception-v3. The resultswere evaluated using the F1-score, achieving 82% for VGG16 and VGG19, whileInception-v3 reached an F1-score of 93%. Inception-v3's reliability wasverified through model testing in uncontrolled environments, with positiveresults, complemented by the Grad-CAM technique, demonstrating its ability tocapture essential morphological features. These findings indicate thatInception-v3 is an effective and replicable approach for classifying Anastrephafraterculus and Ceratitis capitata, with potential for implementation inautomated monitoring systems.</description>
      <author>example@mail.com (Erick Andrew Bustamante Flores, Harley Vera Olivera, Ivan Cesar Medrano Valencia, Carlos Fernando Montoya Cubas)</author>
      <guid isPermaLink="false">2502.00939v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting</title>
      <link>http://arxiv.org/abs/2502.01850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于基础模型的框架，用于高效地估计苹果的成熟度和大小。该研究通过创建一个包含4027张图像和16257个标注苹果的数据集，并利用Grounding-DINO进行苹果检测和成熟度分类，实现了对苹果成熟度和大小的有效评估。&lt;h4&gt;背景&lt;/h4&gt;果实收获是果树产业中的重要任务，需要大量的人工劳动、高额的成本以及潜在的安全风险。现有的自动收获技术往往不分青红皂白地采摘所有可见且可及的果实，包括未成熟的或过小的果实。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于基础模型的新框架来估计苹果的成熟度和大小，以实现高效的自动化和选择性收获。&lt;h4&gt;方法&lt;/h4&gt;创建了两个公共RGBD（红色、绿色、蓝色深度）为基础的数据集，并针对这些数据集进行了扩展标注。使用Grounding-DINO进行对象检测与成熟度分类，同时开发并评估六种不同的大小估计算法。&lt;h4&gt;主要发现&lt;/h4&gt;通过Grounding-DINO实现苹果检测和成熟度分类优于其他最先进的模型，选择了一种误差和变化最小的尺寸估计算法以达到最佳性能。&lt;h4&gt;结论&lt;/h4&gt;该数据集和苹果检测及尺寸估计算法公开提供给研究者使用，为未来的研究提供了有价值的基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何通过开发一个基于基础模型的新框架来解决现有自动化收获技术中存在的问题。该系统能够有效地识别并分类成熟度，并根据果实大小进行选择性采摘。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Harvesting is a critical task in the tree fruit industry, demanding extensivemanual labor and substantial costs, and exposing workers to potential hazards.Recent advances in automated harvesting offer a promising solution by enablingefficient, cost-effective, and ergonomic fruit picking within tight harvestingwindows. However, existing harvesting technologies often indiscriminatelyharvest all visible and accessible fruits, including those that are unripe orundersized. This study introduces a novel foundation model-based framework forefficient apple ripeness and size estimation. Specifically, we curated twopublic RGBD-based Fuji apple image datasets, integrating expanded annotationsfor ripeness ("Ripe" vs. "Unripe") based on fruit color and image capturedates. The resulting comprehensive dataset, Fuji-Ripeness-Size Dataset,includes 4,027 images and 16,257 annotated apples with ripeness and sizelabels. Using Grounding-DINO, a language-model-based object detector, weachieved robust apple detection and ripeness classification, outperformingother state-of-the-art models. Additionally, we developed and evaluated sixsize estimation algorithms, selecting the one with the lowest error andvariation for optimal performance. The Fuji-Ripeness-Size Dataset and the appledetection and size estimation algorithms are made publicly available, whichprovides valuable benchmarks for future studies in automated and selectiveharvesting.</description>
      <author>example@mail.com (Keyi Zhu, Jiajia Li, Kaixiang Zhang, Chaaran Arunachalam, Siddhartha Bhattacharya, Renfu Lu, Zhaojian Li)</author>
      <guid isPermaLink="false">2502.01850v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Learn Weight Generation via Trajectory Diffusion</title>
      <link>http://arxiv.org/abs/2502.01117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了Lt-Di，一种结合扩散算法和元学习的方法，用于生成未见任务的权重。&lt;h4&gt;背景&lt;/h4&gt;基于扩散的算法在多任务学习等需要频繁更新权重的情景中表现出了潜力。然而，现有的解决方案存在跨任务迁移能力有限的问题，并且仅利用最优权重作为训练样本，忽视了其他权重的价值。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法中存在的问题，提高跨任务迁移能力和优化效率。&lt;h4&gt;方法&lt;/h4&gt;引入Lt-Di，通过结合扩散算法和元学习来生成未见任务的权重；改进扩散算法为轨迹扩散算法，利用优化路径中的其他权重；将整个扩散链分解为多个较短的链条以提升训练和推理效率。&lt;h4&gt;主要发现&lt;/h4&gt;分析了权重生成范式的收敛性质，在不增加额外时间开销的情况下提高了收敛效率。实验显示Lt-Di在各种任务中（包括零样本学习、少量样本学习、跨域泛化及大规模语言模型微调）具有更高的准确性并减少了计算负担。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖的方法来改进基于扩散的算法，使其适用于生成未见任务的权重，并展示了其在多个领域的优越性能和效率提升。&lt;h4&gt;翻译&lt;/h4&gt;基于扩散的算法已成为一种有前途的技术，特别是在需要频繁更新权重的情况下，例如多任务学习。但是现有的解决方案存在跨任务迁移能力有限的问题。此外，它们仅利用最优权重作为训练样本，忽视了优化过程中其他权重的价值。为了解决这些问题，我们提出了一种结合元学习和扩散算法的方法Lt-Di来生成未见任务的权重。进一步地，我们将基本扩散算法扩展为轨迹扩散算法以利用优化路径中的所有权重。轨迹扩散将整个扩散链分解成许多较短的链条，从而提高训练和推理效率。我们分析了权重生成范式的收敛性质，并在不增加额外时间开销的情况下提高了收敛效率。我们的实验表明Lt-Di在各种任务中（包括零样本学习、少量样本学习、跨域泛化以及大规模语言模型微调）具有更高的准确性并减少了计算负担。我们的代码发布于https://github.com/tuantuange/Lt-Di。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion-based algorithms have emerged as promising techniques for weightgeneration, particularly in scenarios like multi-task learning that requirefrequent weight updates. However, existing solutions suffer from limitedcross-task transferability. In addition, they only utilize optimal weights astraining samples, ignoring the value of other weights in the optimizationprocess. To address these issues, we propose Lt-Di, which integrates thediffusion algorithm with meta-learning to generate weights for unseen tasks.Furthermore, we extend the vanilla diffusion algorithm into a trajectorydiffusion algorithm to utilize other weights along the optimization trajectory.Trajectory diffusion decomposes the entire diffusion chain into multipleshorter ones, improving training and inference efficiency. We analyze theconvergence properties of the weight generation paradigm and improveconvergence efficiency without additional time overhead. Our experimentsdemonstrate Lt-Di's higher accuracy while reducing computational overheadacross various tasks, including zero-shot and few-shot learning, multi-domaingeneralization, and large-scale language model fine-tuning.Our code is releasedat https://github.com/tuantuange/Lt-Di.</description>
      <author>example@mail.com (Yunchuan Guan, Yu Liu, Ke Zhou, Zhiqi Shen, Serge Belongie, Jenq-Neng Hwang, Lei Li)</author>
      <guid isPermaLink="false">2502.01117v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Dance recalibration for dance coherency with recurrent convolution block</title>
      <link>http://arxiv.org/abs/2502.01190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文提出了一种名为R-Lodge的改进模型，通过引入递归序列表示学习（Dance Recalibration）方法来增强原始的Lodge模型。这种新方法解决了Lodge模型中粗略舞蹈表示的一致性问题。&lt;h4&gt;背景&lt;/h4&gt;随着生成式AI技术如GAN、Diffusion和VAE的发展，利用这些技术进行舞蹈生成受到了广泛关注，并取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的改进模型R-Lodge以提高长舞蹈生成的连贯性和一致性。&lt;h4&gt;方法&lt;/h4&gt;通过引入$N$个Dance Recalibration Block来实现递归序列表示学习（Dance Recalibration）方法，确保每次生成的舞蹈动作都包含前一个舞蹈动作的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在FineDance数据集上的评估结果显示，R-Lodge显著提高了整个生成舞蹈的一致性。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的Dance Recalibration方法，R-Lodge模型改进了Lodge模型在长舞蹈生成方面的问题，并且效果得到了验证。&lt;h4&gt;翻译&lt;/h4&gt;随着生成式AI技术的发展，如GAN、Diffusion和VAE等，在舞蹈生成方面的应用已经取得了显著进展。本文提出了一个增强版的Lodge模型——R-Lodge，该模型通过引入递归序列表示学习方法（Dance Recalibration）来改进原始的粗到细长舞蹈生成模型。此方法利用$N$个Dance Recalibration Block解决了原始Lodge模型在粗略舞蹈表示一致性上的问题，并且每个生成的舞蹈动作都能从之前的动作中获取信息。实验结果显示，R-Lodge模型在FineDance数据集上显著提高了整个生成舞蹈的一致性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the recent advancements in generative AI such as GAN, Diffusion, andVAE, the use of generative AI for dance generation has seen significantprogress and received considerable interest. In this study, We propose R-Lodge,an enhanced version of Lodge. R-Lodge incorporates Recurrent SequentialRepresentation Learning named Dance Recalibration to original coarse-to-finelong dance generation model. R-Lodge utilizes Dance Recalibration method using$N$ Dance Recalibration Block to address the lack of consistency in the coarsedance representation of the Lodge model. By utilizing this method, eachgenerated dance motion incorporates a bit of information from the previousdance motions. We evaluate R-Lodge on FineDance dataset and the results showthat R-Lodge enhances the consistency of the whole generated dance motions.</description>
      <author>example@mail.com (Seungho Eum, Ihjoon Cho, Junghyeon Kim)</author>
      <guid isPermaLink="false">2502.01190v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for O-RAN Mobility Management: A Link Prediction Approach</title>
      <link>http://arxiv.org/abs/2502.02170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 2 figures, 2 tables. Submitted to IEEE Vehicular Technology  Magazine, Special Issue on "AI for 6G O-RAN Intelligent, Cost-Efficient and  Secure Automation"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的前瞻性切换框架，用于O-RAN中的移动性管理。该框架利用用户-小区链路预测来识别最佳目标小区进行切换。&lt;h4&gt;背景&lt;/h4&gt;在5G及之前的标准中，提高切换性能一直是蜂窝网络的关键问题。为解决此问题，3GPP引入了条件切换（CHO）和分层1/2触发式移动性（LTM）机制以平衡切换失败和乒乓效应的矛盾，但这些策略导致了额外的切换准备，从而降低了无线资源利用率。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有切换策略的问题并提高5G/O-RAN中移动性的效率，本文提出了一种基于用户-小区链路预测的前瞻性切换框架。&lt;h4&gt;方法&lt;/h4&gt;探索了几类图神经网络（GNN）模型进行链路预测，并分析了这些模型应用于移动性管理领域的复杂度。使用真实数据集比较了两种不同的GNN模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证明，所提出的基于GNN的前瞻性切换框架能够捕捉蜂窝网络动态和结构化特性，提高了切换决策的质量。&lt;h4&gt;结论&lt;/h4&gt;这项研究为在6G中整合图神经网络链路预测技术用于移动性管理奠定了基础，并提出了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobility performance has been a key focus in cellular networks up to 5G. Toenhance handover (HO) performance, 3GPP introduced Conditional Handover (CHO)and Layer 1/Layer 2 Triggered Mobility (LTM) mechanisms in 5G. While thesereactive HO strategies address the trade-off between HO failures (HOF) andping-pong effects, they often result in inefficient radio resource utilizationdue to additional HO preparations. To overcome these challenges, this articleproposes a proactive HO framework for mobility management in O-RAN, leveraginguser-cell link predictions to identify the optimal target cell for HO. Weexplore various categories of Graph Neural Networks (GNNs) for link predictionand analyze the complexity of applying them to the mobility management domain.Two GNN models are compared using a real-world dataset, with experimentalresults demonstrating their ability to capture the dynamic and graph-structurednature of cellular networks. Finally, we present key insights from our studyand outline future steps to enable the integration of GNN-based link predictionfor mobility management in 6G networks.</description>
      <author>example@mail.com (Ana Gonzalez Bermudez, Miquel Farreras, Milan Groshev, José Antonio Trujillo, Isabel de la Bandera, Raquel Barco)</author>
      <guid isPermaLink="false">2502.02170v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>qNBO: quasi-Newton Meets Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2502.01076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;双层优化在解决层次化学习任务中的挑战方面获得了机器学习领域的广泛关注。梯度下降法在双层优化的实际应用中遇到了计算难题，特别是下层问题的确切解和下层目标的逆海森矩阵（Hessian）的计算。尽管这两个方面本质上是相互关联的，现有的方法通常分别处理这些问题，通过解决下层问题和求解线性系统来近似逆Hessian向量积。本文提出了一种通用框架，以协调的方式应对这些计算挑战。具体来说，我们利用拟牛顿算法加速下层问题的解决方案，并有效逼近逆Hessian向量积。此外，通过利用BFGS超线性收敛特性，我们在我们的框架中建立了BFGS改进的非渐近收敛分析。数值实验表明，在包括超参数优化、数据清洗和少量样本元学习在内的实际学习任务中，所提出的算法表现出相当或更好的性能。&lt;h4&gt;背景&lt;/h4&gt;双层优化在机器学习中的层级化学习问题上面临挑战，并且使用梯度下降法解决这些问题时会遇到计算上的困难，如下层问题的确切解以及逆Hessian矩阵的计算。&lt;h4&gt;目的&lt;/h4&gt;引入一种通用框架来协调处理双层优化中涉及的关键计算难题。&lt;h4&gt;方法&lt;/h4&gt;通过利用拟牛顿算法（如BFGS）加速下层问题解决，并有效逼近逆Hessian向量积。并基于非渐近收敛分析建立理论基础。&lt;h4&gt;主要发现&lt;/h4&gt;在各种实际学习任务中的数值实验表明，所提出的方法具有更好的性能或至少与现有方法相当的性能。&lt;h4&gt;结论&lt;/h4&gt;通过利用拟牛顿算法和BFGS特性提出的框架能够在双层优化问题上提供有效的解决方案，并且在实践中展示了良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bilevel optimization, addressing challenges in hierarchical learning tasks,has gained significant interest in machine learning. The practicalimplementation of the gradient descent method to bilevel optimizationencounters computational hurdles, notably the computation of the exactlower-level solution and the inverse Hessian of the lower-level objective.Although these two aspects are inherently connected, existing methods typicallyhandle them separately by solving the lower-level problem and a linear systemfor the inverse Hessian-vector product. In this paper, we introduce a generalframework to address these computational challenges in a coordinated manner.Specifically, we leverage quasi-Newton algorithms to accelerate the resolutionof the lower-level problem while efficiently approximating the inverseHessian-vector product. Furthermore, by exploiting the superlinear convergenceproperties of BFGS, we establish the non-asymptotic convergence analysis of theBFGS adaptation within our framework. Numerical experiments demonstrate thecomparable or superior performance of the proposed algorithms in real-worldlearning tasks, including hyperparameter optimization, data hyper-cleaning, andfew-shot meta-learning.</description>
      <author>example@mail.com (Sheng Fang, Yong-Jin Liu, Wei Yao, Chengming Yu, Jin Zhang)</author>
      <guid isPermaLink="false">2502.01076v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Boundary-Driven Table-Filling with Cross-Granularity Contrastive Learning for Aspect Sentiment Triplet Extraction</title>
      <link>http://arxiv.org/abs/2502.01942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了边界驱动的表格填充与跨粒度对比学习（BTF-CCL）方法，改进了细粒度情感分析中三元组抽取任务的性能。&lt;h4&gt;背景&lt;/h4&gt;ASTE任务旨在从给定句子中提取方面术语、意见术语及其相应的情感极性。现有方法通常将三元组抽取视为一个端到端的二维表格填充过程，主要关注词级交互而忽略句级表示，导致无法有效捕捉全局上下文信息，尤其是在处理复杂的多单词方面和意见术语时。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在处理复杂句子中的多单词方面与意见术语时的问题，并提高模型捕获全局上下文信息的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种边界驱动的表格填充结合跨粒度对比学习（BTF-CCL）的方法，通过构建正负样本对，强制模型同时从句级和词级学习关联。此外，还提出了多尺度、多粒度卷积方法以更好地捕捉丰富的语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够更有效地捕获句子级别的上下文信息，并保持对局部细节的敏感性，在公共基准测试中实现了最先进的性能，根据F1得分衡量。&lt;h4&gt;结论&lt;/h4&gt;BTF-CCL 方法通过结合边界驱动的表格填充与跨粒度对比学习显著提升了细粒度情感分析中的三元组抽取任务的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：ASTE 任务旨在从给定句子中提取方面术语、意见术语及其相应的情感极性。这仍然是细粒度情感分析中最突出的子任务之一。大多数现有方法将三元组抽取视为端到端的二维表格填充过程，主要关注词级交互而忽略了句级表示。这种限制阻碍了模型捕捉全局上下文信息的能力，特别是在处理复杂的多单词方面与意见术语时。为了解决这些问题，我们提出了一种边界驱动的表格填充结合跨粒度对比学习（BTF-CCL）的方法来增强句子级别表示和词级别表示之间的语义一致性。通过构建正负样本对，模型被迫同时从句级和词级进行关联的学习。此外，还提出了多尺度、多粒度卷积方法以更好地捕捉丰富的语义信息。我们的方法能够更有效地捕获句子级别的上下文信息，并保持对局部细节的敏感性，在公共基准测试中实现了最先进的性能根据F1得分衡量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Aspect Sentiment Triplet Extraction (ASTE) task aims to extract aspectterms, opinion terms, and their corresponding sentiment polarity from a givensentence. It remains one of the most prominent subtasks in fine-grainedsentiment analysis. Most existing approaches frame triplet extraction as a 2Dtable-filling process in an end-to-end manner, focusing primarily on word-levelinteractions while often overlooking sentence-level representations. Thislimitation hampers the model's ability to capture global contextualinformation, particularly when dealing with multi-word aspect and opinion termsin complex sentences. To address these issues, we propose boundary-driventable-filling with cross-granularity contrastive learning (BTF-CCL) to enhancethe semantic consistency between sentence-level representations and word-levelrepresentations. By constructing positive and negative sample pairs, the modelis forced to learn the associations at both the sentence level and the wordlevel. Additionally, a multi-scale, multi-granularity convolutional method isproposed to capture rich semantic information better. Our approach can capturesentence-level contextual information more effectively while maintainingsensitivity to local details. Experimental results show that the proposedmethod achieves state-of-the-art performance on public benchmarks according tothe F1 score.</description>
      <author>example@mail.com (Qingling Li, Wushao Wen, Jinghui Qin)</author>
      <guid isPermaLink="false">2502.01942v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>SAM-guided Pseudo Label Enhancement for Multi-modal 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2502.00960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了一种基于图像引导的伪标签增强方法，利用2D先验知识来提高多模态3D语义分割中的领域适应性能。&lt;h4&gt;背景&lt;/h4&gt;跨域适配技术对于部署多模态3D语义分割模型在实际场景中至关重要。自我训练是目前主流的方法之一，但生成可靠的伪标签需要严格的限制条件，这可能导致生成的伪标签稀疏化。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用2D图像信息来增强伪标签质量的方法，从而提高跨域适应性能。&lt;h4&gt;方法&lt;/h4&gt;该研究结合Segment Anything Model (SAM) 提供的2D掩码和3D点云数据，通过多数投票确定每个掩码的类别，并引入Geometry-Aware Progressive Propagation（GAPP）传播算法来增强伪标签质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，所提出的方法能够显著增加高质量伪标签的数量，并且在多个数据集上都比基线方法有更好的适应性能表现。&lt;h4&gt;结论&lt;/h4&gt;该论文通过结合2D图像和3D点云信息改进了多模态3D语义分割中的跨域适配问题。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种用于提高多模态3D语义分割模型在现实世界应用中领域适应性的方法，特别是针对自动驾驶和虚拟现实等领域的挑战。这种方法通过引入基于图像的伪标签增强技术，利用2D先验知识来改进跨域适配性能，并通过实验验证了其有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal 3D semantic segmentation is vital for applications such asautonomous driving and virtual reality (VR). To effectively deploy these modelsin real-world scenarios, it is essential to employ cross-domain adaptationtechniques that bridge the gap between training data and real-world data.Recently, self-training with pseudo-labels has emerged as a predominant methodfor cross-domain adaptation in multi-modal 3D semantic segmentation. However,generating reliable pseudo-labels necessitates stringent constraints, whichoften result in sparse pseudo-labels after pruning. This sparsity canpotentially hinder performance improvement during the adaptation process. Wepropose an image-guided pseudo-label enhancement approach that leverages thecomplementary 2D prior knowledge from the Segment Anything Model (SAM) tointroduce more reliable pseudo-labels, thereby boosting domain adaptationperformance. Specifically, given a 3D point cloud and the SAM masks from itspaired image data, we collect all 3D points covered by each SAM mask thatpotentially belong to the same object. Then our method refines thepseudo-labels within each SAM mask in two steps. First, we determine the classlabel for each mask using majority voting and employ various constraints tofilter out unreliable mask labels. Next, we introduce Geometry-AwareProgressive Propagation (GAPP) which propagates the mask label to all 3D pointswithin the SAM mask while avoiding outliers caused by 2D-3D misalignment.Experiments conducted across multiple datasets and domain adaptation scenariosdemonstrate that our proposed method significantly increases the quantity ofhigh-quality pseudo-labels and enhances the adaptation performance overbaseline methods.</description>
      <author>example@mail.com (Mingyu Yang, Jitong Lu, Hun-Seok Kim)</author>
      <guid isPermaLink="false">2502.00960v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning</title>
      <link>http://arxiv.org/abs/2502.01184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 13 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为FragmentNet的新框架，该框架利用图到序列的基础模型通过自适应学习的分词器将分子图分解为化学有效的片段，并保持其结构连通性。&lt;h4&gt;背景&lt;/h4&gt;当前的方法在分子属性预测中大多依赖于基于原子或规则的碎片标记化方法，这些方法可能不是最优的，且不具备可扩展性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自适应地将分子图分解为化学有效片段并保持其结构连通性的新模型。&lt;h4&gt;方法&lt;/h4&gt;FragmentNet使用VQVAE-GCN进行分层片段嵌入、空间位置编码用于图形序列化，并结合全局分子描述符和transformer。该模型通过掩码碎片建模预训练，然后在MoleculeNet任务上微调。&lt;h4&gt;主要发现&lt;/h4&gt;FragmentNet的性能优于具有类似规模架构和数据集的其他模型，甚至能与需要更多资源的状态-of-the-art大型模型匹敌。&lt;h4&gt;结论&lt;/h4&gt;此框架为分子设计和优化提供了一种强大的工具，支持基于片段编辑并可视化学习嵌入中的属性趋势。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种新的分子预测方法FragmentNet，它通过自适应的分词器将分子图转化为有效的化学片段，并保持其结构。模型利用了VQVAE-GCN和空间位置编码等先进技术，在多个任务中表现出色，能够高效地支持分子设计与优化工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction uses molecular structure to infer chemicalproperties. Chemically interpretable representations that capture meaningfulintramolecular interactions enhance the usability and effectiveness of thesepredictions. However, existing methods often rely on atom-based or rule-basedfragment tokenization, which can be chemically suboptimal and lack scalability.We introduce FragmentNet, a graph-to-sequence foundation model with anadaptive, learned tokenizer that decomposes molecular graphs into chemicallyvalid fragments while preserving structural connectivity. FragmentNetintegrates VQVAE-GCN for hierarchical fragment embeddings, spatial positionalencodings for graph serialization, global molecular descriptors, and atransformer. Pre-trained with Masked Fragment Modeling and fine-tuned onMoleculeNet tasks, FragmentNet outperforms models with similarly scaledarchitectures and datasets while rivaling larger state-of-the-art modelsrequiring significantly more resources. This novel framework enables adaptivedecomposition, serialization, and reconstruction of molecular graphs,facilitating fragment-based editing and visualization of property trends inlearned embeddings - a powerful tool for molecular design and optimization.</description>
      <author>example@mail.com (Ankur Samanta, Rohan Gupta, Aditi Misra, Christian McIntosh Clarke, Jayakumar Rajadas)</author>
      <guid isPermaLink="false">2502.01184v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Query-Based and Unnoticeable Graph Injection Attack from Neighborhood Perspective</title>
      <link>http://arxiv.org/abs/2502.01936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的查询驱动且隐蔽的图注入攻击方法QUGIA。该方法通过选择连接节点和使用贝叶斯框架生成节点特征来实现隐蔽性。&lt;h4&gt;背景&lt;/h4&gt;由于图神经网络（GNNs）应用范围的扩大，其鲁棒性和安全性的研究变得越来越重要。尽管已提出了多种针对GNN的安全威胁模型，包括图修改攻击（GMA）和更为实用且灵活的图注入攻击（GIA），但是这些方法仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新颖的方法QUGIA来克服现有方法的两个主要限制：对替代模型的依赖以及在未经防御的环境下牺牲攻击成功率以绕过某些防御模型，从而影响整体效果。&lt;h4&gt;方法&lt;/h4&gt;QUGIA通过选择基于目标节点连接的边并使用贝叶斯框架生成节点特征来进行注入。该方法确保了插入的节点与原图中的节点相似，并隐式保持同质性而使攻击更加隐蔽且不依赖于替代模型，从而避免性能下降。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明QUGIA在六个具有不同特性的实际数据集上实现了不可见攻击并超越了现有最佳攻击方法的表现。&lt;h4&gt;结论&lt;/h4&gt;QUGIA通过不使用替代模型，并采用基于查询和贝叶斯生成的方法来提高隐蔽性，从而避免性能下降并增强泛化能力。该研究为GNN安全性领域提供了一个重要的新视角。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）的鲁棒性因其应用范围的扩展而成为越来越重要的话题。各种攻击方法已被提出以探索GNN的安全漏洞，从图修改攻击到更加实用和灵活的图注入攻击。然而，现有方法面临两个关键挑战：一是对替代模型的依赖，这通常会因为结构差异和先前偏见导致攻击效果降低；二是现有的图注入攻击方法往往牺牲在没有防御设置中的成功几率以绕过某些防御机制，从而限制了整体效力。为克服这些局限性，我们提出了一种基于查询且隐蔽的图注入攻击——QUGIA。QUGIA通过首先根据目标节点连接选择边，然后利用贝叶斯框架生成节点特征来进行节点插入。这种方法确保了插入的节点与原始图形中的节点相似，并隐式保持同质性和隐藏特性，使攻击更加不显眼。不同于以往的方法，QUGIA不需要替代模型的支持，因此避免了性能下降并实现了更好的泛化能力。在具有各种特性的六个实际数据集上的广泛实验表明，QUGIA能够实现不可见的攻击效果，并且优于现有的最先进攻击者。该代码将在接受后发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The robustness of Graph Neural Networks (GNNs) has become an increasinglyimportant topic due to their expanding range of applications. Various attackmethods have been proposed to explore the vulnerabilities of GNNs, ranging fromGraph Modification Attacks (GMA) to the more practical and flexible GraphInjection Attacks (GIA). However, existing methods face two key challenges: (i)their reliance on surrogate models, which often leads to reduced attackeffectiveness due to structural differences and prior biases, and (ii) existingGIA methods often sacrifice attack success rates in undefended settings tobypass certain defense models, thereby limiting their overall effectiveness. Toovercome these limitations, we propose QUGIA, a Query-based and UnnoticeableGraph Injection Attack. QUGIA injects nodes by first selecting edges based onvictim node connections and then generating node features using a Bayesianframework. This ensures that the injected nodes are similar to the originalgraph nodes, implicitly preserving homophily and making the attack moreunnoticeable. Unlike previous methods, QUGIA does not rely on surrogate models,thereby avoiding performance degradation and achieving better generalization.Extensive experiments on six real-world datasets with diverse characteristicsdemonstrate that QUGIA achieves unnoticeable attacks and outperformsstate-of-the-art attackers. The code will be released upon acceptance.</description>
      <author>example@mail.com (Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo)</author>
      <guid isPermaLink="false">2502.01936v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges</title>
      <link>http://arxiv.org/abs/2502.01612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;大型语言模型在处理超出训练分布的复杂问题时面临困难。本文提出了一种自改进方法，使模型能够通过迭代生成和学习自己的解决方案逐步解决更难的问题。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在遇到超过其训练数据集范围的任务（例如长序列计算、字符串操作等）时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;探索一种新的自提升机制，使得大型语言模型能够在不改变架构的情况下更好地处理超出其训练分布的复杂问题。&lt;h4&gt;方法&lt;/h4&gt;采用了一种迭代生成与学习的方法，其中模型逐步生成并从自己的解决方案中学习以解决更复杂的任务。该过程在算术、字符串操作和迷宫求解等不同任务上进行测试，并观察到通过过滤正确的自生成示例可以显著提高其处理未见数据的能力。&lt;h4&gt;主要发现&lt;/h4&gt;自改进机制允许大型语言模型解决远超出初始训练分布的问题，例如从10位数加法扩展至100位数加法。此外，从预训练模型开始加速了某些任务的自我提升过程。这种方法展示了如何通过控制弱到强的学习课程来系统地教授模型逻辑外推。&lt;h4&gt;结论&lt;/h4&gt;通过迭代生成和学习自己的解决方案，大型语言模型可以在没有改变架构的情况下显著提高其处理超出初始训练分布的任务的能力。这种自改进的方法在算术、字符串操作和迷宫求解等任务上表现出色，并且从预训练开始可以加速这一过程。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种让大型语言模型通过自身生成和学习来逐步克服训练数据局限性的方法，这种方法展示了如何系统地增强模型的推理能力以处理更复杂的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models often struggle with length generalization and solvingcomplex problem instances beyond their training distribution. We present aself-improvement approach where models iteratively generate and learn fromtheir own solutions, progressively tackling harder problems while maintaining astandard transformer architecture. Across diverse tasks including arithmetic,string manipulation, and maze solving, self-improving enables models to solveproblems far beyond their initial training distribution-for instance,generalizing from 10-digit to 100-digit addition without apparent saturation.We observe that in some cases filtering for correct self-generated examplesleads to exponential improvements in out-of-distribution performance acrosstraining rounds. Additionally, starting from pretrained models significantlyaccelerates this self-improvement process for several tasks. Our resultsdemonstrate how controlled weak-to-strong curricula can systematically teach amodel logical extrapolation without any changes to the positional embeddings,or the model architecture.</description>
      <author>example@mail.com (Nayoung Lee, Ziyang Cai, Avi Schwarzschild, Kangwook Lee, Dimitris Papailiopoulos)</author>
      <guid isPermaLink="false">2502.01612v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-frequency wavefield solutions for variable velocity models using meta-learning enhanced low-rank physics-informed neural network</title>
      <link>http://arxiv.org/abs/2502.00897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架Meta-LRPINN，用于解决物理信息神经网络（PINNs）在复杂速度模型中模拟多频波场时遇到的收敛缓慢、高频细节难以表示以及对不同频率和速度场景缺乏泛化能力的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的物理信息神经网络（PINNs）在处理复杂的多频波场问题时存在挑战，包括慢速收敛、无法有效表示高频细节以及对于不同的频率和速度模型缺乏泛化的现象。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架Meta-LRPINN，以解决传统PINNs在复杂多频波场模拟中的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用奇异值分解（SVD）进行低秩参数化，并结合元学习和频率嵌入技术。引入了一种创新的频率嵌入超网络（FEH），通过连接输入频率与奇异值来实现高效且适应不同频率的波场表示。此外，利用元学习提供稳健的初始化，以提高优化稳定性和减少训练时间。&lt;h4&gt;主要发现&lt;/h4&gt;Meta-LRPINN在模拟多频散射波场时表现出显著的优势：比传统的基准方法（如Meta-PINN和纯PINN）具有更快的收敛速度以及更高的准确性。此外，在面对未见过频率时，该框架也展示了强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，Meta-LRPINN在地震波场建模中展现出巨大的潜力，特别是在可扩展性和适应性方面。这些发现强调了利用低秩参数化和元学习等技术改进复杂物理问题的神经网络模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Physics-informed neural networks (PINNs) face significant challenges in modeling multi-frequency wavefields in complex velocity models due to their slow convergence, difficulty in representing high-frequency details, and lack of generalization to varying frequencies and velocity scenarios. To address these issues, we propose Meta-LRPINN, a novel framework that combines low-rank parameterization using singular value decomposition (SVD) with meta-learning and frequency embedding. Specifically, we decompose the weights of PINN's hidden layers using SVD and introduce an innovative frequency embedding hypernetwork (FEH) that links input frequencies with the singular values, enabling efficient and frequency-adaptive wavefield representation. Meta-learning is employed to provide robust initialization, improving optimization stability and reducing training time. Additionally, we implement adaptive rank reduction and FEH pruning during the meta-testing phase to further enhance efficiency. Numerical experiments, which are presented on multi-frequency scattered wavefields for different velocity models, demonstrate that Meta-LRPINN achieves much faster convergence speed and higher accuracy compared to baseline methods such as Meta-PINN and vanilla PINN. Also, the proposed framework shows strong generalization to out-of-distribution frequencies while maintaining computational efficiency. These results highlight the potential of our Meta-LRPINN for scalable and adaptable seismic wavefield modeling.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-informed neural networks (PINNs) face significant challenges inmodeling multi-frequency wavefields in complex velocity models due to theirslow convergence, difficulty in representing high-frequency details, and lackof generalization to varying frequencies and velocity scenarios. To addressthese issues, we propose Meta-LRPINN, a novel framework that combines low-rankparameterization using singular value decomposition (SVD) with meta-learningand frequency embedding. Specifically, we decompose the weights of PINN'shidden layers using SVD and introduce an innovative frequency embeddinghypernetwork (FEH) that links input frequencies with the singular values,enabling efficient and frequency-adaptive wavefield representation.Meta-learning is employed to provide robust initialization, improvingoptimization stability and reducing training time. Additionally, we implementadaptive rank reduction and FEH pruning during the meta-testing phase tofurther enhance efficiency. Numerical experiments, which are presented onmulti-frequency scattered wavefields for different velocity models, demonstratethat Meta-LRPINN achieves much fast convergence speed and much high accuracycompared to baseline methods such as Meta-PINN and vanilla PINN. Also, theproposed framework shows strong generalization to out-of-distributionfrequencies while maintaining computational efficiency. These results highlightthe potential of our Meta-LRPINN for scalable and adaptable seismic wavefieldmodeling.</description>
      <author>example@mail.com (Shijun Cheng, Tariq Alkhalifah)</author>
      <guid isPermaLink="false">2502.00897v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Privacy-Preserving Domain Adversarial Federated learning for multi-site brain functional connectivity analysis</title>
      <link>http://arxiv.org/abs/2502.01885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;功能性磁共振成像（rs-fMRI）及其衍生的功能连接网络（FCNs）在理解神经系统疾病方面变得至关重要。然而，由于隐私法规和多数据源的非独立同分布特性，协作分析以及模型泛化能力仍面临重大挑战。&lt;h4&gt;背景&lt;/h4&gt;静息态功能磁共振成像(rs-fMRI)及由此产生的功能性连接网络(FCNs)对于理解神经性疾病具有重要作用。但因隐私保护规则与多元数据集之间的非I.I.D（独立且同分布）特性，跨地区协作分析和模型的泛化能力面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出了一种新的联邦深度学习框架——领域对抗联邦学习(DAFed)，旨在解决多站点环境下非IID fMRI数据分析的问题，同时保护隐私。&lt;h4&gt;方法&lt;/h4&gt;DAFed通过特征分离将潜在功能空间分解为域不变和特定于域的组件，以此确保在保持本地数据独特性的基础上实现稳健的整体学习。此外，使用对抗训练促进标记和未标记数据集之间的有效知识转移，并且引入对比学习模块以增强领域不变特征的全局表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过自闭症谱系障碍(ASD)诊断评估了DAFed的有效性，并在阿尔茨海默病(AD)分类中验证了其泛化能力，显示相比现有方法具有更好的分类精度。此外，改进后的Score-CAM模块识别与ASD和轻度认知障碍(MCI)相关的关键脑区及功能连接。&lt;h4&gt;结论&lt;/h4&gt;DAFed框架揭示了跨站点的共同神经生物学模式，并展示了在保护数据隐私的同时推进多站点协作神经成像研究的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到了基于rs-fMRI的功能性连接网络(FCNs)用于理解神经系统疾病的重要性和面临的挑战，以及如何通过新的联邦学习方法DAFed来克服这些问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Resting-state functional magnetic resonance imaging (rs-fMRI) and its derivedfunctional connectivity networks (FCNs) have become critical for understandingneurological disorders. However, collaborative analyses and thegeneralizability of models still face significant challenges due to privacyregulations and the non-IID (non-independent and identically distributed)property of multiple data sources. To mitigate these difficulties, we proposeDomain Adversarial Federated Learning (DAFed), a novel federated deep learningframework specifically designed for non-IID fMRI data analysis in multi-sitesettings. DAFed addresses these challenges through feature disentanglement,decomposing the latent feature space into domain-invariant and domain-specificcomponents, to ensure robust global learning while preserving local dataspecificity. Furthermore, adversarial training facilitates effective knowledgetransfer between labeled and unlabeled datasets, while a contrastive learningmodule enhances the global representation of domain-invariant features. Weevaluated DAFed on the diagnosis of ASD and further validated itsgeneralizability in the classification of AD, demonstrating its superiorclassification accuracy compared to state-of-the-art methods. Additionally, anenhanced Score-CAM module identifies key brain regions and functionalconnectivity significantly associated with ASD and MCI, respectively,uncovering shared neurobiological patterns across sites. These findingshighlight the potential of DAFed to advance multi-site collaborative researchin neuroimaging while protecting data confidentiality.</description>
      <author>example@mail.com (Yipu Zhang, Likai Wang, Kuan-Jui Su, Aiying Zhang, Hao Zhu, Xiaowen Liu, Hui Shen, Vince D. Calhoun, Yuping Wang, Hongwen Deng)</author>
      <guid isPermaLink="false">2502.01885v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>FlexCloud: Direct, Modular Georeferencing and Drift-Correction of Point Cloud Maps</title>
      <link>http://arxiv.org/abs/2502.00395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at VEHITS 2025, Proceedings of the 11th  International Conference on Vehicle Technology and Intelligent Transport  Systems - VEHITS; 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为FlexCloud的方法，用于自动地理参考来自SLAM（即时定位与地图构建）生成的点云地图。&lt;h4&gt;背景&lt;/h4&gt;当前自动驾驶软件堆栈依赖于地图信息来确保可靠的定位、路径规划和运动预测。然而，最近的发展大多不包括全球位置数据，导致生成的地图存在内部扭曲且缺少地理参照，无法用于基于地图的定位方法。&lt;h4&gt;目的&lt;/h4&gt;提出FlexCloud以实现点云地图的自动地理参考，该地图由各种SLAM方法创建，并仅使用本地点云图和里程计。&lt;h4&gt;方法&lt;/h4&gt;利用相应的GNSS位置进行直接地理参考，通过三维橡皮膜变换校正地图中的长期漂移导致的扭曲，同时保持其结构完整。&lt;h4&gt;主要发现&lt;/h4&gt;FlexCloud能够从移动测绘系统收集的数据中创建一致且具有全球参照系的点云地图。&lt;h4&gt;结论&lt;/h4&gt;该方法可以应用于任何SLAM框架，并利用来自不同供应商硬件和软件的点云数据。源代码可以在GitHub上找到：https://github.com/TUMFTM/FlexCloud。&lt;h4&gt;翻译&lt;/h4&gt;当前用于自动驾驶现实世界应用的软件堆栈依赖于地图信息来确保可靠的定位、路径规划及运动预测。一个重要的研究领域是生成点云地图，即即时定位与地图构建(SLAM)的话题。由于大多数最新的发展不包括全球位置数据，导致产生的点云地图内部扭曲且缺少地理参照，无法用于基于地图的定位方法。因此，我们提出了FlexCloud以实现自动地参考由SLAM创建的点云地图。我们的方法设计为可以模块化地与不同的SLAM方法一起工作，仅使用生成的本地点云图和里程计。利用相应的GNSS位置可以直接进行地理参照而无需额外控制点。通过三维橡皮膜变换，我们可以校正由于长期漂移导致的地图内部扭曲同时保持其结构不变。我们的方法可以创建一致且具有全球参照系的点云地图，这些地图是由移动测绘系统(MMS)收集的数据生成的。该工作的源代码可以在https://github.com/TUMFTM/FlexCloud上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current software stacks for real-world applications of autonomous drivingleverage map information to ensure reliable localization, path planning, andmotion prediction. An important field of research is the generation of pointcloud maps, referring to the topic of simultaneous localization and mapping(SLAM). As most recent developments do not include global position data, theresulting point cloud maps suffer from internal distortion and missinggeoreferencing, preventing their use for map-based localization approaches.Therefore, we propose FlexCloud for an automatic georeferencing of point cloudmaps created from SLAM. Our approach is designed to work modularly withdifferent SLAM methods, utilizing only the generated local point cloud map andits odometry. Using the corresponding GNSS positions enables directgeoreferencing without additional control points. By leveraging a 3Drubber-sheet transformation, we can correct distortions within the map causedby long-term drift while maintaining its structure. Our approach enables thecreation of consistent, globally referenced point cloud maps from datacollected by a mobile mapping system (MMS). The source code of our work isavailable at https://github.com/TUMFTM/FlexCloud.</description>
      <author>example@mail.com (Maximilian Leitenstern, Marko Alten, Christian Bolea-Schaser, Dominik Kulmer, Marcel Weinmann, Markus Lienkamp)</author>
      <guid isPermaLink="false">2502.00395v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Subgraph Neural Network With Deep Reinforcement Walk Exploration</title>
      <link>http://arxiv.org/abs/2502.01809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新的自监督框架，用于改进图神经网络（GNN）在复杂现实世界现象中的表现。&lt;h4&gt;背景&lt;/h4&gt;图形数据代表了化学化合物、蛋白质结构和社交网络等复杂的现实世界现象。传统的GNN主要使用消息传递机制，但其表达能力有限且预测缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统GNN的局限性，研究人员专注于图子结构的研究，并提出了一些解决方案如SGNNs（基于子图包计算图形表示以增强表达力）和GNN解释器。但是这些方法都有各自的缺点。&lt;h4&gt;方法&lt;/h4&gt;我们提出了一个新的自监督框架，该框架结合了SGNNs与GNN解释器的生成方法，称为强化游走探索SGNN (RWE-SGNN)。我们的方法包括一个以解释方式训练的采样模型，优化子图以提高模型性能，并提出了一种新的数据驱动采样方法。&lt;h4&gt;主要发现&lt;/h4&gt;我们提出的基于游走探索的过程与传统的子图生成过程具有相同的生成能力，可以高效地提取重要子结构，简化嵌入过程并避免同构问题。实验结果在各种图形数据集上验证了我们的方法的有效性，展示了显著的性能和精度提升。&lt;h4&gt;结论&lt;/h4&gt;通过结合SGNNs和GNN解释器的方法，我们提供了一种新的有效策略来提高图神经网络的表现力和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph data, with its structurally variable nature, represents complexreal-world phenomena like chemical compounds, protein structures, and socialnetworks. Traditional Graph Neural Networks (GNNs) primarily utilize themessage-passing mechanism, but their expressive power is limited and theirprediction lacks explainability. To address these limitations, researchers havefocused on graph substructures. Subgraph neural networks (SGNNs) and GNNexplainers have emerged as potential solutions, but each has its limitations.SGNNs computes graph representations based on the bags of subgraphs to enhancethe expressive power. However, they often rely on predefined algorithm-basedsampling strategies, which is inefficient. GNN explainers adopt data-drivenapproaches to generate important subgraphs to provide explanation.Nevertheless, their explanation is difficult to be translated into practicalimprovements on GNNs. To overcome these issues, we propose a novelself-supervised framework that integrates SGNNs with the generation approach ofGNN explainers, named the Reinforcement Walk Exploration SGNN (RWE-SGNN). Ourapproach features a sampling model trained in an explainer fashion, optimizingsubgraphs to enhance model performance. To achieve a data-driven samplingapproach, unlike traditional subgraph generation approaches, we propose a novelwalk exploration process, which efficiently extracts important substructures,simplifying the embedding process and avoiding isomorphism problems. Moreover,we prove that our proposed walk exploration process has equivalent generationcapability to the traditional subgraph generation process. Experimental resultson various graph datasets validate the effectiveness of our proposed method,demonstrating significant improvements in performance and precision.</description>
      <author>example@mail.com (Jianming Huang, Hiroyuki Kasai)</author>
      <guid isPermaLink="false">2502.01809v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Choose Your Model Size: Any Compression by a Single Gradient Descent</title>
      <link>http://arxiv.org/abs/2502.01717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的算法ACIP，用于从单次随机梯度下降运行中确定压缩和性能之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;在资源受限的环境中使用基础模型面临挑战，因为它们的大小较大且推理成本高。解决这个问题的一个有前途的方法是后训练压缩。&lt;h4&gt;目的&lt;/h4&gt;开发一种算法来平衡减少模型大小与性能降低之间的关系，并允许生成任何目标大小的模型。&lt;h4&gt;方法&lt;/h4&gt;ACIP通过使用线性层的SVD重新参数化和迭代稀疏惩罚，以确定一个全球参数排名。这使得可以不经过昂贵的微调步骤就获得具有强预测能力的小型化模型。&lt;h4&gt;主要发现&lt;/h4&gt;在各种公开权重的大规模语言模型（LLMs）和任务上评估了ACIP，并展示了与现有基于因子分解的压缩方法相比，取得了最先进的成果。&lt;h4&gt;结论&lt;/h4&gt;ACIP不仅有效减少了大型语言模型的大小，而且保持或提高了其性能。此外，它还可以无缝地与其他常见的量化压缩技术结合使用。&lt;h4&gt;翻译&lt;/h4&gt;由于基础模型在资源受限环境中的部署困难（它们的大小和推理成本大），一种有前途的方法是后训练压缩。这项工作提出了一种新算法ACIP，用于确定从一次随机梯度下降运行中得出的压缩性能权衡。该方法通过线性层的SVD重新参数化和迭代稀疏惩罚来实现参数效率，并生成可材料化的模型以满足任何目标大小的需求。重要的是，这种压缩后的模型在不进行昂贵微调的情况下仍表现出强大的预测性能。我们在大量公开权重的语言模型上评估了ACIP，并显示其结果优于现有的基于因子分解的压缩方法。此外，ACIP还能与常见的量化压缩技术无缝结合使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The adoption of Foundation Models in resource-constrained environmentsremains challenging due to their large size and inference costs. A promisingway to overcome these limitations is post-training compression, which aims tobalance reduced model size against performance degradation. This work presentsAny Compression via Iterative Pruning (ACIP), a novel algorithmic approach todetermine a compression-performance trade-off from a single stochastic gradientdescent run. To ensure parameter efficiency, we use an SVD-reparametrization oflinear layers and iteratively prune their singular values with asparsity-inducing penalty. The resulting pruning order gives rise to a globalparameter ranking that allows us to materialize models of any target size.Importantly, the compressed models exhibit strong predictive downstreamperformance without the need for costly fine-tuning. We evaluate ACIP on alarge selection of open-weight LLMs and tasks, and demonstrate state-of-the-artresults compared to existing factorisation-based compression methods. We alsoshow that ACIP seamlessly complements common quantization-based compressiontechniques.</description>
      <author>example@mail.com (Martin Genzel, Patrick Putzky, Pengfei Zhao, Sebastian Schulze, Mattes Mollenhauer, Robert Seidel, Stefan Dietzel, Thomas Wollmann)</author>
      <guid isPermaLink="false">2502.01717v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>VisTA: Vision-Text Alignment Model with Contrastive Learning using Multimodal Data for Evidence-Driven, Reliable, and Explainable Alzheimer's Disease Diagnosis</title>
      <link>http://arxiv.org/abs/2502.01535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VisTA是一种用于阿尔茨海默病（AD）诊断的多模态语言-视觉模型，通过对比学习进行训练，能够优化疾病预测并提供基于证据、可解释性的临床决策依据。&lt;h4&gt;背景&lt;/h4&gt;利用高维放射学图像评估阿尔茨海默病在临床上具有重要意义但极具挑战性。尽管人工智能技术已经推进了AD的诊断，但仍不清楚如何设计同时具备预测性和解释性的AI模型。&lt;h4&gt;目的&lt;/h4&gt;提出并开发一种多模态语言-视觉模型VisTA（视觉文本对齐模型），通过对比学习来优化疾病预测，并提供基于证据且可解释的临床决策依据。&lt;h4&gt;方法&lt;/h4&gt;我们使用BiomedCLIP构建了VisTA，然后利用包含医学专家验证过的图像、异常类型和描述的参考数据集对其进行微调。训练完毕后，VisTA可以输出预测的异常类型、与参考案例的相似度、基于证据的解释以及最终AD诊断。&lt;h4&gt;主要发现&lt;/h4&gt;相比于用于基线预训练的1500万张图片，仅使用170个样本进行微调后的VisTA在异常检索和痴呆症预测方面取得了显著改善。对于异常检测，VisTA达到了74%的准确率和AUC为0.87（分别比基线模型高出26个百分点和0.74）。对于痴呆症预测，VisTA实现了88%的准确性以及AUC 0.82（相比基线模型提高了30%和0.57）。&lt;h4&gt;结论&lt;/h4&gt;通过优化预测、临床推理及解释，该研究展示了VisTA在提高阿尔茨海默病诊断中的潜在价值，并且生成的解释与人类专家的一致性很高，为诊断过程提供了新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: Assessing Alzheimer's disease (AD) using high-dimensionalradiology images is clinically important but challenging. Although ArtificialIntelligence (AI) has advanced AD diagnosis, it remains unclear how to designAI models embracing predictability and explainability. Here, we propose VisTA,a multimodal language-vision model assisted by contrastive learning, tooptimize disease prediction and evidence-based, interpretable explanations forclinical decision-making.  Methods: We developed VisTA (Vision-Text Alignment Model) for AD diagnosis.Architecturally, we built VisTA from BiomedCLIP and fine-tuned it usingcontrastive learning to align images with verified abnormalities and theirdescriptions. To train VisTA, we used a constructed reference datasetcontaining images, abnormality types, and descriptions verified by medicalexperts. VisTA produces four outputs: predicted abnormality type, similarity toreference cases, evidence-driven explanation, and final AD diagnoses. Toillustrate VisTA's efficacy, we reported accuracy metrics for abnormalityretrieval and dementia prediction. To demonstrate VisTA's explainability, wecompared its explanations with human experts' explanations.  Results: Compared to 15 million images used for baseline pretraining, VisTAonly used 170 samples for fine-tuning and obtained significant improvement inabnormality retrieval and dementia prediction. For abnormality retrieval, VisTAreached 74% accuracy and an AUC of 0.87 (26% and 0.74, respectively, frombaseline models). For dementia prediction, VisTA achieved 88% accuracy and anAUC of 0.82 (30% and 0.57, respectively, from baseline models). The generatedexplanations agreed strongly with human experts' and provided insights into thediagnostic process. Taken together, VisTA optimize prediction, clinicalreasoning, and explanation.</description>
      <author>example@mail.com (Duy-Cat Can, Linh D. Dang, Quang-Huy Tang, Dang Minh Ly, Huong Ha, Guillaume Blanc, Oliver Y. Chén, Binh T. Nguyen)</author>
      <guid isPermaLink="false">2502.01535v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>UniGraph2: Learning a Unified Embedding Space to Bind Multimodal Graphs</title>
      <link>http://arxiv.org/abs/2502.00806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;UniGraph2是一个新型跨域图基础模型，旨在实现多模态图（MMG）的通用表示学习，并提供统一的嵌入空间。&lt;h4&gt;背景&lt;/h4&gt;现有的基础模型如CLIP主要关注于学习用于多媒体数据的单一嵌入空间，但对于包含实体及其关系的内在图形结构则考虑不足。现有针对文本属性图(TAG)设计的基础图模型无法处理多模态图(MMGs)的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出UniGraph2以解决现有的基础图模型在处理MMGs时面临的挑战，并通过跨域大规模多图预训练算法和专家混合组件来确保不同领域和模式间的有效迁移学习，实现稳健统一的信息嵌入。&lt;h4&gt;方法&lt;/h4&gt;UniGraph2采用模态特定编码器与图形神经网络(GNN)相结合的方式，以同时捕捉多模态信息及其底层的图结构。此外，它使用一种新的大规模跨域多图预训练算法和专家混合组件来确保在不同领域和模式之间的有效迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验结果表明，UniGraph2显著优于现有的模型，在表示学习、迁移学习以及多模态生成任务等方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;UniGraph2为处理MMGs提供了一个可扩展且灵活的解决方案，其统一嵌入空间和跨域大规模预训练算法有助于实现稳健有效的多模态图信息融合。&lt;h4&gt;翻译&lt;/h4&gt;现有的基础模型如CLIP旨在学习多媒体数据的一致性嵌入空间，适用于诸如搜索、推荐和内容分类等一系列下游网络应用。然而这些模型常常忽视了在多模式数据集中的内在图形结构，其中实体及其关系至关重要。多模态图（MMG）代表的是每个节点与来自不同模式的特征相关联而边则捕捉这些实体之间的关系的此类图形。另一方面，现有的基础图模型主要关注文本属性图(TAG)，并且不适用于处理MMGs的复杂性。为了克服这些限制，我们提出了UniGraph2，这是一个新型跨域图基础模型，它实现了多模态图（MMG）上的通用表示学习，并提供了统一嵌入空间。UniGraph2采用特定模式编码器以及图形神经网络(GNN)来学习一致且低维的嵌入空间，以同时捕捉多模态信息及其底层的图结构。我们提出了一种新的跨域大规模多图预训练算法以确保在不同领域和模式间的有效迁移学习，并采用了专家混合（MoE）组件来对齐来自不同领域的特征，从而实现一致且稳健的信息统一嵌入。广泛的实验表明，UniGraph2在诸如表示学习、迁移学习以及多模态生成任务中显著优于现有最佳模型，在这些方面提供了一个可扩展和灵活的解决方案用于处理MMGs。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing foundation models, such as CLIP, aim to learn a unified embeddingspace for multimodal data, enabling a wide range of downstream web-basedapplications like search, recommendation, and content classification. However,these models often overlook the inherent graph structures in multimodaldatasets, where entities and their relationships are crucial. Multimodal graphs(MMGs) represent such graphs where each node is associated with features fromdifferent modalities, while the edges capture the relationships between theseentities. On the other hand, existing graph foundation models primarily focuson text-attributed graphs (TAGs) and are not designed to handle thecomplexities of MMGs. To address these limitations, we propose UniGraph2, anovel cross-domain graph foundation model that enables general representationlearning on MMGs, providing a unified embedding space. UniGraph2 employsmodality-specific encoders alongside a graph neural network (GNN) to learn aunified low-dimensional embedding space that captures both the multimodalinformation and the underlying graph structure. We propose a new cross-domainmulti-graph pre-training algorithm at scale to ensure effective transferlearning across diverse graph domains and modalities. Additionally, we adopt aMixture of Experts (MoE) component to align features from different domains andmodalities, ensuring coherent and robust embeddings that unify the informationacross modalities. Extensive experiments on a variety of multimodal graph tasksdemonstrate that UniGraph2 significantly outperforms state-of-the-art models intasks such as representation learning, transfer learning, and multimodalgenerative tasks, offering a scalable and flexible solution for learning onMMGs.</description>
      <author>example@mail.com (Yufei He, Yuan Sui, Xiaoxin He, Yue Liu, Yifei Sun, Bryan Hooi)</author>
      <guid isPermaLink="false">2502.00806v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Robust-LLaVA: On the Effectiveness of Large-Scale Robust Image Encoders for Multi-modal Large Language Models</title>
      <link>http://arxiv.org/abs/2502.01576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新的方法，利用预先针对大规模数据进行对抗训练的视觉分类模型来增强多模态大型语言模型（MLLMs）在面对视觉对抗性攻击时的鲁棒性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的MLLMs虽然擅长处理图像-文本任务，但容易受到视觉对抗性干扰的影响。为了减轻这一风险，已有的方法通过限制性对抗微调CLIP视觉编码器来提高其鲁棒性，但这可能会影响模型的一般化性能。&lt;h4&gt;目的&lt;/h4&gt;探索一种替代方案：使用预先在大规模数据上进行过对抗训练的现有视觉分类模型，以增强MLLMs的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;(1) 利用大规模、多样化对抗预训练的视觉分类模型来展示对各种类型对手攻击的强大抵抗能力；(2) 将这些强健模型集成到端到端的MLLM架构中，提高语言组件适应稳健视觉特征的能力。&lt;h4&gt;主要发现&lt;/h4&gt;(1) 对抗预训练规模和多样性使模型能够对抗多种类型的对抗性威胁；(2) 与现有的插件方法相比，在复杂的推理任务上实现了性能提升。通过系统评估表明，使用这些强健模型的MLLMs在保持清洁数据表现的同时，取得了显著的对手鲁棒性增强。&lt;h4&gt;结论&lt;/h4&gt;提出的框架在图像描述和视觉问答任务中表现出约2倍和1.5倍的平均鲁棒性增益，并且在应对劫持攻击方面提高了超过10%的表现。这表明了利用预先训练的强健模型来提高MLLMs的安全性和性能的有效性。&lt;h4&gt;翻译&lt;/h4&gt;多模态大型语言模型(MLLM)在图像-文本任务中表现出色，但仍然容易受到诱导幻觉、操纵回应或绕过安全机制的视觉对抗性干扰的影响。现有方法通过针对大规模数据进行限制性对抗微调CLIP视觉编码器来缓解这些问题，并保持其泛化能力。然而，这种受限的对抗训练限制了模型的鲁棒性和更广泛的泛化能力。本文探讨了一种替代方案：利用已经在大规模数据上进行了对抗预训练的现有视觉分类模型。我们的分析揭示了两个主要贡献：(1) 大规模和多样化的对抗预训练使这些模型在不需要额外对抗训练的情况下，对各种类型的对手威胁展示出了更强的鲁棒性；(2) 将端到端MLLM与这些强健模型集成起来，能够更好地适应语言组件到稳健视觉特征的变化，在复杂的推理任务上超越了现有的插件方法。通过在图像描述、问答以及劫持攻击方面的系统评估，我们证明了使用这些强健模型训练的MLLMs实现了对手鲁棒性增强的同时保持清洁性能的优势。我们的框架在图像描述和VQA任务中分别获得了2倍和1.5倍的平均鲁棒性增益，并且在应对劫持攻击时提高了超过10%的表现。代码和预训练模型将在https://github.com/HashmatShadab/Robust-LLaVA上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal Large Language Models (MLLMs) excel in vision-language tasks butremain vulnerable to visual adversarial perturbations that can inducehallucinations, manipulate responses, or bypass safety mechanisms. Existingmethods seek to mitigate these risks by applying constrained adversarialfine-tuning to CLIP vision encoders on ImageNet-scale data, ensuring theirgeneralization ability is preserved. However, this limited adversarial trainingrestricts robustness and broader generalization. In this work, we explore analternative approach of leveraging existing vision classification models thathave been adversarially pre-trained on large-scale data. Our analysis revealstwo principal contributions: (1) the extensive scale and diversity ofadversarial pre-training enables these models to demonstrate superiorrobustness against diverse adversarial threats, ranging from imperceptibleperturbations to advanced jailbreaking attempts, without requiring additionaladversarial training, and (2) end-to-end MLLM integration with these robustmodels facilitates enhanced adaptation of language components to robust visualfeatures, outperforming existing plug-and-play methodologies on complexreasoning tasks. Through systematic evaluation across visualquestion-answering, image captioning, and jail-break attacks, we demonstratethat MLLMs trained with these robust models achieve superior adversarialrobustness while maintaining favorable clean performance. Our frameworkachieves 2x and 1.5x average robustness gains in captioning and VQA tasks,respectively, and delivers over 10% improvement against jailbreak attacks. Codeand pretrained models will be available athttps://github.com/HashmatShadab/Robust-LLaVA.</description>
      <author>example@mail.com (Hashmat Shadab Malik, Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar, Fahad Khan, Salman Khan)</author>
      <guid isPermaLink="false">2502.01576v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2502.01778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了GNN-DT，这是一种结合了图神经网络嵌入器和新颖残差连接的决策变压器架构。GNN-DT解决了真实世界优化问题中动态状态-动作空间、规模较大及奖励稀疏所带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;强化学习（RL）方法在解决实际优化问题时面临动态环境变化，状态-行动空间规模大以及回报稀疏等问题，导致收敛性、可扩展性和解决方案探索效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出GNN-DT架构以减少对精确模拟器的依赖，并克服在线RL算法中遇到的稀疏奖励限制。同时展示该模型在样本效率和泛化能力上的优越表现。&lt;h4&gt;方法&lt;/h4&gt;引入一种新的决策变压器（DT）架构，通过将图神经网络嵌入器与输入输出令牌之间的残差连接结合在一起，以处理动态环境中的问题，并从先前收集的轨迹中学习。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂电动汽车充电优化问题上对GNN-DT进行评估，结果表明该模型性能优于现有DT基线方法并且需要更少的训练轨迹。此外，在未见过的环境中和更大的动作空间内也表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;GNN-DT架构成功地解决了先前基于决策变压器的方法在动态环境中的限制，并且提供了更强的样本效率以及更好的泛化性能，特别是在处理大规模行动空间时更为明显。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习（RL）方法用于解决现实世界的优化问题时常涉及动态的状态-动作空间、更大规模以及稀疏奖励的问题，导致了收敛性、可扩展性和解决方案探索效率方面的重大挑战。本研究引入了一种新的决策变压器（DT）架构GNN-DT，该架构整合了图神经网络（GNN）嵌入器，并且在输入和输出令牌之间使用了一个新颖的残差连接以处理动态环境中的问题。通过学习先前收集的轨迹数据，GNN-DT减少了对精确模拟器的依赖性并克服了在线RL算法中稀疏奖励的限制。我们评估了GNN-DT在复杂电动汽车（EV）充电优化问题上的性能，并证明其相对于现有DT基线方法表现出更优的表现且所需的训练轨迹显著减少，从而提高了样本效率。此外，GNN-DT展示了对未见过环境和更大动作空间的强大泛化能力，弥补了之前基于决策变压器的方法中的关键不足之处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) methods used for solving real-world optimizationproblems often involve dynamic state-action spaces, larger scale, and sparserewards, leading to significant challenges in convergence, scalability, andefficient exploration of the solution space. This study introduces GNN-DT, anovel Decision Transformer (DT) architecture that integrates Graph NeuralNetwork (GNN) embedders with a novel residual connection between input andoutput tokens crucial for handling dynamic environments. By learning frompreviously collected trajectories, GNN-DT reduces dependence on accuratesimulators and tackles the sparse rewards limitations of online RL algorithms.We evaluate GNN-DT on the complex electric vehicle (EV) charging optimizationproblem and prove that its performance is superior and requires significantlyfewer training trajectories, thus improving sample efficiency compared toexisting DT baselines. Furthermore, GNN-DT exhibits robust generalization tounseen environments and larger action spaces, addressing a critical gap inprior DT-based approaches</description>
      <author>example@mail.com (Stavros Orfanoudakis, Nanda Kishor Panda, Peter Palensky, Pedro P. Vergara)</author>
      <guid isPermaLink="false">2502.01778v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Graph Robustness Against Backdoor Attacks: An Over-Similarity Perspective</title>
      <link>http://arxiv.org/abs/2502.01272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图后门防御方法SimGuard，通过利用基于相似性的度量来检测触发器，并使用对比学习训练一个后门检测器以生成能够区分触发器和干净节点的嵌入。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在社交和交通网络等任务中取得了显著的成功。然而，最近的研究揭示了GNN对后门攻击的脆弱性，引发了对其实际应用可靠性的严重关注。&lt;h4&gt;目的&lt;/h4&gt;设计一种有效的防御方法来应对现有的图后门攻击，并解决现有防御方法面临的挑战：无法区分触发器和干净节点或无法消除触发器的影响。&lt;h4&gt;方法&lt;/h4&gt;SimGuard方法首先利用基于相似性的度量检测触发器，然后采用对比学习训练一个后门检测器，该检测器生成能够将触发器与干净节点区分开来的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;通过实证分析各种现有的图后门攻击，观察到这些方法产生的触发器在特征和结构上表现出过度相似性。SimGuard方法可以有效抵御多种图后门攻击，并保持对干净节点的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的SimGuard方法能够有效地防御各种图后门攻击，同时保留了在干净数据上的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于图神经网络（GNNs）的成功及其面对后门攻击脆弱性的研究。通过实证分析得出触发器过度相似的特征，提出了基于相似性度量和对比学习的SimGuard防御方法，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved notable success in tasks such associal and transportation networks. However, recent studies have highlightedthe vulnerability of GNNs to backdoor attacks, raising significant concernsabout their reliability in real-world applications. Despite initial efforts todefend against specific graph backdoor attacks, existing defense methods facetwo main challenges: either the inability to establish a clear distinctionbetween triggers and clean nodes, resulting in the removal of many clean nodes,or the failure to eliminate the impact of triggers, making it challenging torestore the target nodes to their pre-attack state. Through empirical analysisof various existing graph backdoor attacks, we observe that the triggersgenerated by these methods exhibit over-similarity in both features andstructure. Based on this observation, we propose a novel graph backdoor defensemethod SimGuard. We first utilizes a similarity-based metric to detect triggersand then employs contrastive learning to train a backdoor detector thatgenerates embeddings capable of separating triggers from clean nodes, therebyimproving detection efficiency. Extensive experiments conducted on real-worlddatasets demonstrate that our proposed method effectively defends againstvarious graph backdoor attacks while preserving performance on clean nodes. Thecode will be released upon acceptance.</description>
      <author>example@mail.com (Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo)</author>
      <guid isPermaLink="false">2502.01272v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning, Lightweight Fine-Tuning, and Low-Rank Adaptation</title>
      <link>http://arxiv.org/abs/2502.00782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探索了物理信息神经网络(PINNs)在不同类型边界条件、材料和几何形状下的迁移学习能力。&lt;h4&gt;背景&lt;/h4&gt;AI在求解偏微分方程（PDEs）领域得到广泛应用，尤其是物理信息神经网络（PINNs）。然而，传统的PINNs在问题变化时需要重新训练。&lt;h4&gt;目的&lt;/h4&gt;探讨PINNs在不同类型边界条件、材料和几何形状下的泛化能力和迁移学习方法的效果。&lt;h4&gt;方法&lt;/h4&gt;采用全微调、轻量级微调以及低秩适应（LoRA）等迁移学习技术，评估其对不同问题的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，全微调和LoRA可以显著提高模型的收敛速度，并且在精度上也有轻微提升。&lt;h4&gt;结论&lt;/h4&gt;迁移学习方法能够有效改善PINNs在不同类型PDEs求解中的泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI for PDEs has garnered significant attention, particularly Physics-InformedNeural Networks (PINNs). However, PINNs are typically limited to solvingspecific problems, and any changes in problem conditions necessitateretraining. Therefore, we explore the generalization capability of transferlearning in the strong and energy form of PINNs across different boundaryconditions, materials, and geometries. The transfer learning methods we employinclude full finetuning, lightweight finetuning, and Low-Rank Adaptation(LoRA). The results demonstrate that full finetuning and LoRA can significantlyimprove convergence speed while providing a slight enhancement in accuracy.</description>
      <author>example@mail.com (Yizheng Wang, Jinshuai Bai, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu)</author>
      <guid isPermaLink="false">2502.00782v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction</title>
      <link>http://arxiv.org/abs/2502.01550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;随着气候变化加剧了火灾天气条件，准确及时地预测野火对于灾害缓解变得越来越重要。在这项研究中，我们利用SeasFire这一包含气候、植被、海洋指数和人类相关变量的全球野火综合数据集，通过机器学习来实现季节性的野火预报。为了进行预测分析，我们提出了FireCastNet架构，该架构结合了用于使用图神经网络进行全球短期天气预报的3D卷积编码器与GraphCast。FireCastNet被训练用来捕捉导致野火的不同空间和时间尺度下的上下文信息。我们的研究重点在于评估模型在全球范围内在不同的预测时间段内（最长可达六个月）预测烧毁区域存在性的有效性，以及不同空间或/和时间背景如何影响性能。结果表明深度学习模型在季节性火灾预报中的潜力；更长的输入时间序列会导致更为稳健的预测，而整合空间信息以捕捉野火的空间-时间动态则会提高性能。最后，我们的研究暗示为了增强长期预报范围内的表现，需要考虑更大的空间感知域。&lt;h4&gt;背景&lt;/h4&gt;气候变化导致了更加严峻的火灾天气条件，使得准确及时地预测野火对于灾害管理变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;利用SeasFire数据集和机器学习方法进行季节性野火预报，并评估预测模型的有效性和性能因素。&lt;h4&gt;方法&lt;/h4&gt;开发了一种名为FireCastNet的新架构，结合了3D卷积编码器与图神经网络的GraphCast模块。该模型用于捕捉不同空间和时间尺度下的野火前兆信息并进行长期预测。&lt;h4&gt;主要发现&lt;/h4&gt;更长的时间序列输入可以提高预测的稳定性；整合空间信息以捕捉火灾的空间-时间动态有助于改进性能。&lt;h4&gt;结论&lt;/h4&gt;深度学习模型在季节性野火预报中显示出巨大的潜力。为了进一步优化长时间尺度内的预测效果，需要考虑更大的空间感知范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With climate change expected to exacerbate fire weather conditions, theaccurate and timely anticipation of wildfires becomes increasingly crucial fordisaster mitigation. In this study, we utilize SeasFire, a comprehensive globalwildfire dataset with climate, vegetation, oceanic indices, and human-relatedvariables, to enable seasonal wildfire forecasting with machine learning. Forthe predictive analysis, we present FireCastNet, a novel architecture whichcombines a 3D convolutional encoder with GraphCast, originally developed forglobal short-term weather forecasting using graph neural networks. FireCastNetis trained to capture the context leading to wildfires, at different spatialand temporal scales. Our investigation focuses on assessing the effectivenessof our model in predicting the presence of burned areas at varying forecastingtime horizons globally, extending up to six months into the future, and on howdifferent spatial or/and temporal context affects the performance. Our findingsdemonstrate the potential of deep learning models in seasonal fire forecasting;longer input time-series leads to more robust predictions, while integratingspatial information to capture wildfire spatio-temporal dynamics boostsperformance. Finally, our results hint that in order to enhance performance atlonger forecasting horizons, a larger receptive field spatially needs to beconsidered.</description>
      <author>example@mail.com (Dimitrios Michail, Charalampos Davalas, Lefki-Ioanna Panagiotou, Ioannis Prapas, Spyros Kondylatos, Nikolaos Ioannis Bountos, Ioannis Papoutsis)</author>
      <guid isPermaLink="false">2502.01550v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>The in-context inductive biases of vision-language models differ across modalities</title>
      <link>http://arxiv.org/abs/2502.01530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文研究了基础模型在情境学习中如何基于形状和颜色进行泛化，并探讨了视觉呈现与文本描述对这一过程的影响。&lt;h4&gt;背景&lt;/h4&gt;归纳偏差使学习者能够在没有充分证据的情况下作出猜测。这类偏差通常通过认知科学中的概念或类别来研究，例如测试人类如何从几个模棱两可的例子中概括一个新的类别。&lt;h4&gt;目的&lt;/h4&gt;使用类似的方法研究基础模型在基于视觉和文本的情境学习中的泛化能力，并探讨不同呈现方式对结果的影响。&lt;h4&gt;方法&lt;/h4&gt;通过三个不同的实验范式，在三种不同的视觉-语言模型上进行研究，以探究模型如何根据刺激的模态和描述方式进行泛化。&lt;h4&gt;主要发现&lt;/h4&gt;模型在很大程度上倾向于基于形状而非颜色来概括。当例子以视觉形式呈现时，这种偏见会增强；而以文本形式呈现时，则受形容词顺序的影响。&lt;h4&gt;结论&lt;/h4&gt;这些结果揭示了视觉-语言模型如何表示不同类型的输入，并可能对基础模型的实际应用产生影响。&lt;h4&gt;翻译&lt;/h4&gt;归纳偏差是指学习者在没有确凿证据的情况下作出猜测的能力。该研究探讨了现代基础模型在接受基于视觉和文本的情境信息时的泛化能力，发现它们通常更倾向于根据形状而非颜色来概括新类别，并且呈现方式对这种泛化的程度有所影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inductive biases are what allow learners to make guesses in the absence ofconclusive evidence. These biases have often been studied in cognitive scienceusing concepts or categories -- e.g. by testing how humans generalize a newcategory from a few examples that leave the category boundary ambiguous. We usethese approaches to study generalization in foundation models during in-contextlearning. Modern foundation models can condition on both vision and text, anddifferences in how they interpret and learn from these different modalities isan emerging area of study. Here, we study how their generalizations vary by themodality in which stimuli are presented, and the way the stimuli are describedin text. We study these biases with three different experimental paradigms,across three different vision-language models. We find that the modelsgenerally show some bias towards generalizing according to shape over color.This shape bias tends to be amplified when the examples are presented visually.By contrast, when examples are presented in text, the ordering of adjectivesaffects generalization. However, the extent of these effects vary across modelsand paradigms. These results help to reveal how vision-language modelsrepresent different types of inputs in context, and may have practicalimplications for the use of vision-language models.</description>
      <author>example@mail.com (Kelsey Allen, Ishita Dasgupta, Eliza Kosoy, Andrew K. Lampinen)</author>
      <guid isPermaLink="false">2502.01530v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Environmental Robustness in Few-shot Learning via Conditional Representation Learning</title>
      <link>http://arxiv.org/abs/2502.01183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 8 figures, Accepted by IEEE Transactions on Image  Processing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;该论文介绍了在现实世界中使用少量样本学习(FSL)面临的环境挑战，提出了一种新的基准测试来评估FSL模型的鲁棒性，并引入了一种新颖的方法来改进特征表示。&lt;h4&gt;背景&lt;/h4&gt;现有研究忽视了“环境鲁棒性”的概念，导致FSL模型的实际性能低于训练时的表现。现实场景中的复杂因素如复杂的背景、光照变化等影响了目标识别的效果。&lt;h4&gt;目的&lt;/h4&gt;通过建立一个新的多域少量样本学习(RD-FSL)基准测试来评估和改进现有方法的环境适应能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种条件表示学习网络(CRLNet)，该网络能够利用训练图像与测试图像之间的相互作用，从而改善特征表达的效果。&lt;h4&gt;主要发现&lt;/h4&gt;现有的FSL模型在处理具有挑战性的测试数据时表现不佳。CRLNet通过降低类别内的变化或增强类别间的差异，在不同设置和架构下实现了显著的性能提升（6.83%至16.98%）。&lt;h4&gt;结论&lt;/h4&gt;研究展示了改进环境适应性的重要性，并为未来的FSL研究提供了一种新的方向和基准测试方法。&lt;h4&gt;翻译&lt;/h4&gt;少量样本学习(FSL)被广泛用于克服特定领域视觉识别中的训练数据不足问题。然而，现有研究忽视了模型在复杂多变的物理环境中表现的一致性（即环境鲁棒性），导致实际应用中性能下降。为解决这一问题，作者提出了一种新的基于现实世界的跨域少量样本学习(RD-FSL)基准测试，并引入了条件表示学习网络(CRLNet)，该网络通过结合训练与测试图像间的相互作用改善特征表达效果，在各类设置下均超越现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot learning (FSL) has recently been extensively utilized to overcomethe scarcity of training data in domain-specific visual recognition. Inreal-world scenarios, environmental factors such as complex backgrounds,varying lighting conditions, long-distance shooting, and moving targets oftencause test images to exhibit numerous incomplete targets or noise disruptions.However, current research on evaluation datasets and methodologies has largelyignored the concept of "environmental robustness", which refers to maintainingconsistent performance in complex and diverse physical environments. Thisneglect has led to a notable decline in the performance of FSL models duringpractical testing compared to their training performance. To bridge this gap,we introduce a new real-world multi-domain few-shot learning (RD-FSL)benchmark, which includes four domains and six evaluation datasets. The testimages in this benchmark feature various challenging elements, such ascamouflaged objects, small targets, and blurriness. Our evaluation experimentsreveal that existing methods struggle to utilize training images effectively togenerate accurate feature representations for challenging test images. Toaddress this problem, we propose a novel conditional representation learningnetwork (CRLNet) that integrates the interactions between training and testingimages as conditional information in their respective representation processes.The main goal is to reduce intra-class variance or enhance inter-class varianceat the feature representation level. Finally, comparative experiments revealthat CRLNet surpasses the current state-of-the-art methods, achievingperformance improvements ranging from 6.83% to 16.98% across diverse settingsand backbones. The source code and dataset are available athttps://github.com/guoqianyu-alberta/Conditional-Representation-Learning.</description>
      <author>example@mail.com (Qianyu Guo, Jingrong Wu, Tianxing Wu, Haofen Wang, Weifeng Ge, Wenqiang Zhang)</author>
      <guid isPermaLink="false">2502.01183v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents</title>
      <link>http://arxiv.org/abs/2502.01218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新的学习视觉-语言表示的方法，用于减少训练具身代理对大规模专家演示的依赖。&lt;h4&gt;背景&lt;/h4&gt;在人类动作视频上进行预训练以生成视觉-语言表示已成为一种有前景的方法来减少训练具身智能体时需要大规模专家演示的需求。然而，以前的方法往往通过基于目标达成启发式的对比时间学习方法，并逐步将语言指令从初始帧对齐到最终帧。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法过度依赖未来帧导致的错误视觉-语言关联问题，本文提出了一种新的方法Action Temporal Coherence Learning (AcTOL)，以在没有刚性目标约束的情况下学习有序和连续的视觉-语言表示。&lt;h4&gt;方法&lt;/h4&gt;AcTOL将视频视为一个连续轨迹，在其中对比各帧之间的语义差异以反映其自然顺序，并在中间帧之间施加局部布朗桥约束，确保平滑过渡。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的模仿学习实验显示，预训练的特征可以显著提高下游操作任务的表现（最高可达49%），并且对于不同语言风格指令具有高鲁棒性，为通用具身智能体的发展提供了一条可行路径。&lt;h4&gt;结论&lt;/h4&gt;源代码已在补充材料中包括作为参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-training vision-language representations on human action videos hasemerged as a promising approach to reduce reliance on large-scale expertdemonstrations for training embodied agents. However, prior methods oftenemploy time contrastive learning based on goal-reaching heuristics,progressively aligning language instructions from the initial to the finalframe. This overemphasis on future frames can result in erroneousvision-language associations, as actions may terminate early or includeirrelevant moments in the end. To address this issue, we propose ActionTemporal Coherence Learning (AcTOL) to learn ordered and continuousvision-language representations without rigid goal-based constraint. AcTOLtreats a video as a continuous trajectory where it (1) contrasts semanticdifferences between frames to reflect their natural ordering, and (2) imposes alocal Brownian bridge constraint to ensure smooth transitions acrossintermediate frames. Extensive imitation learning experiments across varyingnumbers of demonstrations show that the pretrained features significantlyenhance downstream manipulation tasks by up to 49% with high robustness todifferent linguistic styles of instructions, offering a viable pathway towardgeneralized embodied agents. The source code is included in the supplementarymaterial for reference.</description>
      <author>example@mail.com (Zhizhen Zhang, Lei Zhu, Zhen Fang, Zi Huang, Yadan Luo)</author>
      <guid isPermaLink="false">2502.01218v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Role of Mixup in Topological Persistence Based Knowledge Distillation for Wearable Sensor Data</title>
      <link>http://arxiv.org/abs/2502.00779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Sensors Journal (2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文分析了可穿戴传感器数据的拓扑数据分析(TDA)和时间序列特征表示，以及如何通过知识蒸馏(KD)技术将这些复杂特征简化为更小模型的方法。同时引入了mixup作为增强训练期间模型性能的数据增强技术。&lt;h4&gt;背景&lt;/h4&gt;通过对高采样率时间序列进行详细描述，TDA被用于可穿戴传感器数据分析中，并发现它能补充其他时间序列特征表示方法。然而，由于提取拓扑特征需要大量计算资源和长时间消耗，难以在各种应用中部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用知识蒸馏技术将复杂的时间序列和拓扑特征简化为更小模型的方法，并探讨mixup数据增强技术在这一过程中的作用。&lt;h4&gt;方法&lt;/h4&gt;通过使用多个教师的KD，同时转移时间序列和拓扑持久性特征，最终从仅使用时间序列数据的学生模型中提炼出更好的性能。此外，研究了混合方法如何与知识蒸馏结合使用以提高学生模型的学习效率。&lt;h4&gt;主要发现&lt;/h4&gt;分析了mixup在多老师框架下的知识蒸馏过程中的角色，并且展示了这种技术对于可穿戴传感器数据分析的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过引入mixup和知识蒸馏，可以有效地利用复杂的拓扑特征信息来改进基于时间序列的模型性能。这种方法为高效使用高维数据提供了新途径。&lt;h4&gt;翻译&lt;/h4&gt;对可穿戴设备传感器的数据进行分析已经取得了许多成功，在多个应用领域中。为了以足够的细节表示出高采样率的时间序列，已经考虑了使用拓扑数据分析（TDA），并发现它能够补充其他时间序列特征。然而，由于提取拓扑特征通过TDA需要大量计算资源和长时间消耗，很难在各种应用中部署这种知识。为了解决这个问题，可以采用知识蒸馏(KD)，这是一种模型压缩和技术转移学习的技术，生成一个更小的模型，该模型可以通过从更大的网络传输知识来获取。借助于KD中的多个教师，可以在时间序列特征和拓扑特征之间进行传输，并最终提炼出仅使用时间序列数据的学生模型。另一方面，在训练期间作为增强模型性能的稳健数据增强技术的mixup已经广泛流行。在KD中，学生模型从由老师模型生成的平滑分布中学习，而mixup通过混合两个标签创建平滑标签。因此，这种共同的光滑性充当了这两种方法之间的连接，建立了它们之间的联系。在这篇论文中，我们分析了在使用多个教师的时间序列以及拓扑持久性的知识蒸馏过程中，mixup的作用。我们对各种KD和mixup方法进行了详细的可穿戴传感器数据综合分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/JSEN.2024.3517653&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The analysis of wearable sensor data has enabled many successes in severalapplications. To represent the high-sampling rate time-series with sufficientdetail, the use of topological data analysis (TDA) has been considered, and itis found that TDA can complement other time-series features. Nonetheless, dueto the large time consumption and high computational resource requirements ofextracting topological features through TDA, it is difficult to deploytopological knowledge in various applications. To tackle this problem,knowledge distillation (KD) can be adopted, which is a technique facilitatingmodel compression and transfer learning to generate a smaller model bytransferring knowledge from a larger network. By leveraging multiple teachersin KD, both time-series and topological features can be transferred, andfinally, a superior student using only time-series data is distilled. On theother hand, mixup has been popularly used as a robust data augmentationtechnique to enhance model performance during training. Mixup and KD employsimilar learning strategies. In KD, the student model learns from the smootheddistribution generated by the teacher model, while mixup creates smoothedlabels by blending two labels. Hence, this common smoothness serves as theconnecting link that establishes a connection between these two methods. Inthis paper, we analyze the role of mixup in KD with time-series as well astopological persistence, employing multiple teachers. We present acomprehensive analysis of various methods in KD and mixup on wearable sensordata.</description>
      <author>example@mail.com (Eun Som Jeon, Hongjun Choi, Matthew P. Buman, Pavan Turaga)</author>
      <guid isPermaLink="false">2502.00779v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Transformers trained on proteins can learn to attend to Euclidean distance</title>
      <link>http://arxiv.org/abs/2502.01533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文探讨了Transformer模型在处理结构数据时的独立性，特别是在3D应用中蛋白质建模方面的潜力。&lt;h4&gt;背景介绍&lt;/h4&gt;传统的Transformer主要用于序列数据分析，但可以通过与SE(3)-不变或等变图神经网络(GNN)结合的方式应用于三维应用场景如蛋白质结构建模。这些混合方法通常涉及将结构特征作为输入预处理/分词给Transformer或者使用Transformer嵌入并在结构表示中进行进一步的处理。&lt;h4&gt;研究目的&lt;/h4&gt;展示Transformer模型可以通过直接接受坐标线性嵌入的方式独立工作，成为有效的结构模型，并验证此理论。&lt;h4&gt;研究方法&lt;/h4&gt;1. 理论解释：通过3D高斯分布学习注意力机制；2. 实验验证：使用模拟的3D点进行验证，在蛋白质掩码令牌预测中进一步验证理论；3. 预训练实验：预训练蛋白质Transformer编码器以结构为基础，提升下游任务性能。&lt;h4&gt;主要发现&lt;/h4&gt;1. Transformer可以独立处理结构信息（如AlphaFold3中的结构性扩散模型所展示）；2. 使用线性坐标嵌入的Transformer可以在不依赖于其他结构化模型的情况下作为有效的结构模型。&lt;h4&gt;结论&lt;/h4&gt;这项工作为使用标准Transformer作为混合结构语言模型提供了理论依据，并证明了这种方法在蛋白质建模等任务中具有良好的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While conventional Transformers generally operate on sequence data, they canbe used in conjunction with structure models, typically SE(3)-invariant orequivariant graph neural networks (GNNs), for 3D applications such as proteinstructure modelling. These hybrids typically involve either (1)preprocessing/tokenizing structural features as input for Transformers or (2)taking Transformer embeddings and processing them within a structuralrepresentation. However, there is evidence that Transformers can learn toprocess structural information on their own, such as the AlphaFold3 structuraldiffusion model. In this work we show that Transformers can functionindependently as structure models when passed linear embeddings of coordinates.We first provide a theoretical explanation for how Transformers can learn tofilter attention as a 3D Gaussian with learned variance. We then validate thistheory using both simulated 3D points and in the context of masked tokenprediction for proteins. Finally, we show that pre-training protein Transformerencoders with structure improves performance on a downstream task, yieldingbetter performance than custom structural models. Together, this work providesa basis for using standard Transformers as hybrid structure-language models.</description>
      <author>example@mail.com (Isaac Ellmen, Constantin Schneider, Matthew I. J. Raybould, Charlotte M. Deane)</author>
      <guid isPermaLink="false">2502.01533v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning Efficient Positional Encodings with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.01122v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;{'背景': '位置编码（PEs）在有效的图表示学习中至关重要，因为它们为本质上缺乏位置感知的变换器架构提供了位置信息，并增加了图形神经网络（GNNs）的表现力。', '目的': '本文确定了图位置编码应满足的四个关键属性：稳定性、表现力、可扩展性和通用性。现有基于特征向量的方法通常无法同时满足这些标准，因此提出了PEARL框架来解决这一问题。', '方法': '利用消息传递GNN作为非线性映射的功能设计生成强大且高效的PEs架构，并通过随机节点输入或标准基矢量初始化GNN以解锁消息传递操作的表现力。使用统计池化函数保持置换不变性。', '主要发现': '分析表明，PEARL可以以线性复杂度近似特征向量的等变函数，同时严格保证其稳定性和高表现力。', '结论': '实验结果表明，与基于特征向量的方法相比，PEARL具有更好的性能或可比性，并且复杂度要低一个或两个数量级。'}&lt;h4&gt;翻译&lt;/h4&gt;位置编码对于有效的图表示学习至关重要，因为它们为本质上没有固定节点顺序的变换器架构提供了位置感知信息并增加了GNN的表现力。但是设计适合大规模无序节点的强大的高效PEs具有挑战性。作者通过引入PEARL框架，解决了这一难题，该框架使用随机初始化和消息传递操作来生成强大且高效的图位置编码，并展示了其在性能上的优越性和复杂度上的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Positional encodings (PEs) are essential for effective graph representationlearning because they provide position awareness in inherentlyposition-agnostic transformer architectures and increase the expressivecapacity of Graph Neural Networks (GNNs). However, designing powerful andefficient PEs for graphs poses significant challenges due to the absence ofcanonical node ordering and the scale of the graph. {In this work, we identifyfour key properties that graph PEs should satisfy}: stability, expressivepower, scalability, and genericness. We find that existing eigenvector-based PEmethods often fall short of jointly satisfying these criteria. To address thisgap, we introduce PEARL, a novel framework of learnable PEs for graphs. Ourprimary insight is that message-passing GNNs function as nonlinear mappings ofeigenvectors, enabling the design of GNN architectures for generating powerfuland efficient PEs. A crucial challenge lies in initializing node attributes ina manner that is both expressive and permutation equivariant. We tackle this byinitializing GNNs with random node inputs or standard basis vectors, therebyunlocking the expressive power of message-passing operations, while employingstatistical pooling functions to maintain permutation equivariance. Ouranalysis demonstrates that PEARL approximates equivariant functions ofeigenvectors with linear complexity, while rigorously establishing itsstability and high expressive power. Experimental evaluations show that PEARLoutperforms lightweight versions of eigenvector-based PEs and achievescomparable performance to full eigenvector-based PEs, but with one or twoorders of magnitude lower complexity. Our code is available athttps://github.com/ehejin/Pearl-PE.</description>
      <author>example@mail.com (Charilaos I. Kanatsoulis, Evelyn Choi, Stephanie Jegelka, Jure Leskovec, Alejandro Ribeiro)</author>
      <guid isPermaLink="false">2502.01122v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>General Feature Extraction In SAR Target Classification: A Contrastive Learning Approach Across Sensor Types</title>
      <link>http://arxiv.org/abs/2502.01162v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着SAR数据可用性的提高，越来越多的研究人员开始应用深度学习算法。然而，标记数据的限制对于监督训练构成了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍一种基于最少标注图像进行分类的新方法，旨在利用未经标记的大规模数据集来克服上述挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法采用基于ViT（视觉变换器）作为特征提取器，并通过对比学习进行预训练。训练过程中使用的数据集与用于分类的任务不同。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，在MSTAR数据集中，仅利用每个类别的10张标注图像就能达到95.9%的准确率，这一结果优于基于PCA处理后的k-NN和专门为此任务设计的ResNet-34模型。&lt;h4&gt;结论&lt;/h4&gt;该方法通过2D可视化t-SNE进行定性评估，并使用少量标记数据进行定量评价。结果显示，这种新方法在SAR图像分类中具有显著的优势。&lt;h4&gt;翻译&lt;/h4&gt;随着合成孔径雷达（SAR）数据可用性的增加，深度学习算法的应用引起了越来越多的关注。然而，由于缺少标注的数据，监督训练面临重大挑战。本文介绍了一种新的方法来使用最少的标签图像对SAR数据进行分类。该方法基于用对比学习训练过的ViT特征提取器，并在与用于分类任务完全不同的数据集上进行了训练。通过2D t-SNE可视化和少量标记数据的k-NN分类进行了效果评估，显示出优于PCA处理后的k-NN以及专门为任务设计的ResNet-34模型的表现，在MSTAR数据集中实现了95.9%的准确率，仅使用每个类别的10张标注图像。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/IGARSS53475.2024.10642123&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increased availability of SAR data has raised a growing interest inapplying deep learning algorithms. However, the limited availability of labeleddata poses a significant challenge for supervised training. This articleintroduces a new method for classifying SAR data with minimal labeled images.The method is based on a feature extractor Vit trained with contrastivelearning. It is trained on a dataset completely different from the one on whichclassification is made. The effectiveness of the method is assessed through 2Dvisualization using t-SNE for qualitative evaluation and k-NN classificationwith a small number of labeled data for quantitative evaluation. Notably, ourresults outperform a k-NN on data processed with PCA and a ResNet-34specifically trained for the task, achieving a 95.9% accuracy on the MSTARdataset with just ten labeled images per class.</description>
      <author>example@mail.com (M. Muzeau, J. Frontera-Pons, Chengfang Ren, J. -P. Ovarlez)</author>
      <guid isPermaLink="false">2502.01162v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>SSRepL-ADHD: Adaptive Complex Representation Learning Framework for ADHD Detection from Visual Attention Tasks</title>
      <link>http://arxiv.org/abs/2502.00376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种基于自监督表示学习（SSRepL）和迁移学习（TL）的框架被提出，该框架使用长短期记忆模型（LSTM）与门控循环单元模型（GRU），通过分析儿童在视觉注意力任务中的脑电图（EEG）信号来检测注意力缺陷多动障碍（ADHD）的症状。&lt;h4&gt;背景&lt;/h4&gt;自监督表示学习能够捕获ADHD数据的有意义且鲁棒的表现，有可能提高对其他神经发育障碍类型下游任务性能的模型表现。&lt;h4&gt;目的&lt;/h4&gt;提出一个结合SSRepL和TL框架，利用EEG信号检测儿童潜在的ADHD症状的新方法。&lt;h4&gt;方法&lt;/h4&gt;该研究使用三种不同的模型进行实验分析：1) SSRepL-ADHD，整合了LSTM和GRU层以捕捉数据中的时间依赖性；2) 基于SSRepL的轻量级深度神经网络（DNN）模型(LSSRepL-DNN)；3) 随机森林(RF)。这些模型通过精度、召回率等常见性能指标进行彻底评估。&lt;h4&gt;主要发现&lt;/h4&gt;提出的SSRepL-ADHD模型在克服数据不平衡和特征选择困难的情况下，达到了最高的81.11%的准确性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效地利用EEG信号来检测潜在的ADHD症状，并且可能对于其他类型的神经发育障碍也有类似的提高效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的自监督表示学习和迁移学习框架，该框架结合了LSTM和GRU模型以检测儿童ADHD症状。通过预处理脑电图信号的质量并使用多种性能指标进行评估，该方法展示了其在识别潜在的ADHD方面的潜力，并承认了数据不平衡和特征选择的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self Supervised Representation Learning (SSRepL) can capture meaningful androbust representations of the Attention Deficit Hyperactivity Disorder (ADHD)data and have the potential to improve the model's performance on alsodownstream different types of Neurodevelopmental disorder (NDD) detection. Inthis paper, a novel SSRepL and Transfer Learning (TL)-based framework thatincorporates a Long Short-Term Memory (LSTM) and a Gated Recurrent Units (GRU)model is proposed to detect children with potential symptoms of ADHD. Thismodel uses Electroencephalogram (EEG) signals extracted during visual attentiontasks to accurately detect ADHD by preprocessing EEG signal quality throughnormalization, filtering, and data balancing. For the experimental analysis, weuse three different models: 1) SSRepL and TL-based LSTM-GRU model named asSSRepL-ADHD, which integrates LSTM and GRU layers to capture temporaldependencies in the data, 2) lightweight SSRepL-based DNN model (LSSRepL-DNN),and 3) Random Forest (RF). In the study, these models are thoroughly evaluatedusing well-known performance metrics (i.e., accuracy, precision, recall, andF1-score). The results show that the proposed SSRepL-ADHD model achieves themaximum accuracy of 81.11% while admitting the difficulties associated withdataset imbalance and feature selection.</description>
      <author>example@mail.com (Abdul Rehman, Ilona Heldal, Jerry Chun-Wei Lin)</author>
      <guid isPermaLink="false">2502.00376v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Can message-passing GNN approximate triangular factorizations of sparse matrices?</title>
      <link>http://arxiv.org/abs/2502.01397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了图神经网络（GNNs）在学习稀疏矩阵预处理器方面的基本限制。&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，使用GNN预测不完全因子化取得了令人鼓舞的结果。然而，消息传递的局部性质为捕捉最优预条件所需的非局部依赖关系设置了固有障碍。&lt;h4&gt;目的&lt;/h4&gt;引入一个新的基准数据集，该数据集中存在良好的稀疏预处理器，但需要非局部计算，以展示当前GNN架构在这些条件下的不足。&lt;h4&gt;方法&lt;/h4&gt;使用合成示例和现实世界的矩阵构建了一个新的基准数据集。对现有的GNN架构进行了实验测试，发现它们难以近似所需的有效预处理器。&lt;h4&gt;主要发现&lt;/h4&gt;目前的GNN架构在捕捉稀疏矩阵预处理器所需的非局部依赖关系方面遇到困难，这表明需要超越传统消息传递网络的新建筑方法。&lt;h4&gt;结论&lt;/h4&gt;理论分析和实证证据表明了GNN在这种任务中的局限性，并对更广泛地使用GNN于数值线性代数提出了挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们研究图神经网络（GNNs）在学习稀疏矩阵预处理器方面的基本限制。虽然最近的研究显示，利用GNN预测不完全因子化取得了令人鼓舞的结果，但我们证明了消息传递的局部性质为捕捉最优预条件所需的非本地依赖关系设置了固有障碍。我们引入了一个新的基准数据集，其中存在良好的稀疏预处理器但需要非本地计算，使用合成示例和现实世界的矩阵构建而成。我们的实验结果显示，当前GNN架构难以近似这些预处理器，这表明需要超越传统消息传递网络的新建筑方法。我们提供了理论分析和实证证据来解释这些限制，并对更广泛地使用GNN于数值线性代数提出了挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study fundamental limitations of Graph Neural Networks (GNNs) for learningsparse matrix preconditioners. While recent works have shown promising resultsusing GNNs to predict incomplete factorizations, we demonstrate that the localnature of message passing creates inherent barriers for capturing non-localdependencies required for optimal preconditioning. We introduce a new benchmarkdataset of matrices where good sparse preconditioners exist but requirenon-local computations, constructed using both synthetic examples andreal-world matrices. Our experimental results show that current GNNarchitectures struggle to approximate these preconditioners, suggesting theneed for new architectural approaches beyond traditional message passingnetworks. We provide theoretical analysis and empirical evidence to explainthese limitations, with implications for the broader use of GNNs in numericallinear algebra.</description>
      <author>example@mail.com (Vladislav Trifonov, Ekaterina Muravleva, Ivan Oseledets)</author>
      <guid isPermaLink="false">2502.01397v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Active Learning based Experimental Design to Uncover Synergistic Genetic Interactions for Host Targeted Therapeutics</title>
      <link>http://arxiv.org/abs/2502.01012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近的技术进步引入了新的高通量方法来研究宿主-病毒相互作用，但测试感染过程中宿主基因对的协同作用仍然相对缓慢且劳动密集。&lt;h4&gt;背景&lt;/h4&gt;识别多个基因敲低以有效抑制病毒复制需要在所有可能的目标基因对组合空间中搜索。现有的主动学习方法主要用于单基因敲低或小规模双敲除数据集，难以处理大规模复杂情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合生物知识图谱信息的集成深度积极学习框架（DeepAL），用于高效搜索大量人类基因在HIV感染中的所有成对敲低配置空间。&lt;h4&gt;方法&lt;/h4&gt;通过图表示学习生成任务特定的基因表示，并平衡探索与利用之间的权衡，以确定高度有效的双敲除对。此外，提出了一种不确定性量化的方法以及通过通路分析来解释所选基因对的方法。&lt;h4&gt;主要发现&lt;/h4&gt;该研究首次展示了在较大规模（356x356矩阵）的双基因敲低实验数据上取得良好结果的工作成果。&lt;h4&gt;结论&lt;/h4&gt;DeepAL框架能够有效识别病毒复制中的关键宿主-病毒相互作用，为高通量筛选和治疗策略提供新的视角。&lt;h4&gt;翻译&lt;/h4&gt;最近的技术进步引入了用于研究宿主-病毒相互作用的新高通量方法。但是，在感染期间测试宿主基因对之间的协同效应仍然相对缓慢且劳动密集。为了识别能够有效抑制病毒复制的多个基因敲低，需要在所有可能的目标基因对组合空间中进行搜索，这是通过暴力实验无法实现的。尽管主动学习方法已被证明有希望用于顺序实验设计，但现有的方法通常仅限于单基因敲低或小规模双敲除数据集。在这项研究中，我们提出了一种集成深度积极学习（DeepAL）框架，该框架结合了生物知识图谱（SPOKE，可扩展的精密医学开放知识引擎）的信息，以有效搜索由356个人类基因在HIV感染中的所有成对敲低组成的大型数据集的空间。通过图表示学习，该框架能够生成任务特定的基因表示，并同时平衡探索与利用之间的权衡，以确定高度有效的双敲除配对。我们还提出了一种不确定性量化的方法以及通过通路分析来解释所选基因对的方法。据我们所知，这是首次在具有一定规模（356x356矩阵）的双基因敲低实验数据上展示有希望的结果的工作成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent technological advances have introduced new high-throughput methods forstudying host-virus interactions, but testing synergistic interactions betweenhost gene pairs during infection remains relatively slow and labor intensive.Identification of multiple gene knockdowns that effectively inhibit viralreplication requires a search over the combinatorial space of all possibletarget gene pairs and is infeasible via brute-force experiments. Althoughactive learning methods for sequential experimental design have shown promise,existing approaches have generally been restricted to single-gene knockdowns orsmall-scale double knockdown datasets. In this study, we present an integratedDeep Active Learning (DeepAL) framework that incorporates information from abiological knowledge graph (SPOKE, the Scalable Precision Medicine OpenKnowledge Engine) to efficiently search the configuration space of a largedataset of all pairwise knockdowns of 356 human genes in HIV infection. Throughgraph representation learning, the framework is able to generate task-specificrepresentations of genes while also balancing the exploration-exploitationtrade-off to pinpoint highly effective double-knockdown pairs. We additionallypresent an ensemble method for uncertainty quantification and an interpretationof the gene pairs selected by our algorithm via pathway analysis. To ourknowledge, this is the first work to show promising results on double-geneknockdown experimental data of appreciable scale (356 by 356 matrix).</description>
      <author>example@mail.com (Haonan Zhu, Mary Silva, Jose Cadena, Braden Soper, Michał Lisicki, Braian Peetoom, Sergio E. Baranzini, Shivshankar Sundaram, Priyadip Ray, Jeff Drocco)</author>
      <guid isPermaLink="false">2502.01012v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>BC-GAN: A Generative Adversarial Network for Synthesizing a Batch of Collocated Clothing</title>
      <link>http://arxiv.org/abs/2502.01080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted by IEEE TCSVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于生成网络的同场景服装合成成为时尚智能领域的新兴研究方向，具有显著的经济价值潜力。&lt;h4&gt;背景&lt;/h4&gt;已有研究表明使用生成对抗网络（GAN）可以根据给定衣物物品合成视觉上协调的配套服饰，并取得了一些积极成果。然而这些方法每次只能合成为一个配套服饰。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一局限性，本文提出了一种新型批量服装生成框架BC-GAN，能够同时合成多个视觉上协调的配套服饰图像。&lt;h4&gt;方法&lt;/h4&gt;特别地，为提高合成结果的时尚兼容性，BC-GAN在对比学习视角下提出了一个新的时尚兼容性判别器，并充分利用所有衣物间的配对关系。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在一个大型自建数据集上进行了验证，实验结果显示与最新技术相比，在多样性、视觉真实性和时尚协调性方面均有显著优势。&lt;h4&gt;结论&lt;/h4&gt;BC-GAN在同场景服装合成中展示了其有效性，解决了单一配套生成的局限性，并提升了合成结果的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TCSVT.2023.3318216&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collocated clothing synthesis using generative networks has become anemerging topic in the field of fashion intelligence, as it has significantpotential economic value to increase revenue in the fashion industry. Inprevious studies, several works have attempted to synthesizevisually-collocated clothing based on a given clothing item using generativeadversarial networks (GANs) with promising results. These works, however, canonly accomplish the synthesis of one collocated clothing item each time.Nevertheless, users may require different clothing items to meet their multiplechoices due to their personal tastes and different dressing scenarios. Toaddress this limitation, we introduce a novel batch clothing generationframework, named BC-GAN, which is able to synthesize multiplevisually-collocated clothing images simultaneously. In particular, to furtherimprove the fashion compatibility of synthetic results, BC-GAN proposes a newfashion compatibility discriminator in a contrastive learning perspective byfully exploiting the collocation relationship among all clothing items. Ourmodel was examined in a large-scale dataset with compatible outfits constructedby ourselves. Extensive experiment results confirmed the effectiveness of ourproposed BC-GAN in comparison to state-of-the-art methods in terms ofdiversity, visual authenticity, and fashion compatibility.</description>
      <author>example@mail.com (Dongliang Zhou, Haijun Zhang, Jianghong Ma, Jianyang Shi)</author>
      <guid isPermaLink="false">2502.01080v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Generalization Error Analysis for Selective State-Space Models Through the Lens of Attention</title>
      <link>http://arxiv.org/abs/2502.01473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章深入分析了选择性状态空间模型（selective SSMs）的理论特性，揭示其与自注意力机制之间的联系，并提供了基于覆盖数的一般化界限，探讨了状态矩阵稳定性和输入依赖离散化的关键作用。&lt;h4&gt;背景&lt;/h4&gt;状态空间模型(SSMs)作为序列处理任务的一种新基础模型类，为传统的Transformer及其注意机制提供了一种有吸引力的替代方案。选择性SSM是Mamba和Mamba-2架构的核心组成部分。&lt;h4&gt;目的&lt;/h4&gt;通过理论分析建立对选择性SSMs性能保证的理解，并探讨影响其泛化能力的关键因素。&lt;h4&gt;方法&lt;/h4&gt;利用选择性SSM与自注意力机制之间的联系，基于覆盖数提出了一种长度独立的一般化界限。同时分析了状态矩阵稳定性及输入依赖离散化的影响。&lt;h4&gt;主要发现&lt;/h4&gt;文章证明了选择性SSMs在序列长度上的性能表现与其理论边界相一致，并且强调了状态矩阵稳定性和输入依赖离散化对于模型泛化的关键作用。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，通过深入理解选择性SSM的理论基础，可以更好地掌握其在各种序列任务中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;状态空间模型（SSMs）作为新兴的一种处理序列任务的基础模型类型，为Transformer及其注意力机制提供了新的竞争者。本文对选择性SSM进行了详尽的理论分析，并通过建立基于覆盖数的一般化界限来探讨其特性，揭示了它们与自注意机制之间的本质相似之处。此外，还研究了状态矩阵稳定性及输入依赖离散化对于模型泛化能力的影响。最后，在两个任务上实验验证了所获得性能边界不受序列长度的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-space models (SSMs) are a new class of foundation models that haveemerged as a compelling alternative to Transformers and their attentionmechanisms for sequence processing tasks. This paper provides a detailedtheoretical analysis of selective SSMs, the core components of the Mamba andMamba-2 architectures. We leverage the connection between selective SSMs andthe self-attention mechanism to highlight the fundamental similarities betweenthese models. Building on this connection, we establish a length independentcovering number-based generalization bound for selective SSMs, providing adeeper understanding of their theoretical performance guarantees. We analyzethe effects of state matrix stability and input-dependent discretization,shedding light on the critical role played by these factors in thegeneralization capabilities of selective SSMs. Finally, we empiricallydemonstrate the sequence length independence of the derived bounds on twotasks.</description>
      <author>example@mail.com (Arya Honarpisheh, Mustafa Bozdag, Mario Sznaier, Octavia Camps)</author>
      <guid isPermaLink="false">2502.01473v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Models for Reinforced Concrete Pipes Condition Prediction: The State-of-the-Art Using Artificial Neural Networks and Multiple Linear Regression in a Wisconsin Case Study</title>
      <link>http://arxiv.org/abs/2502.00363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;美国的老化下水道基础设施面临着结构问题，导致每年约有75,000起卫生污水溢流事件。研究通过机器学习模型（人工神经网络和多元线性回归）预测管道状况，旨在提高准确性。&lt;h4&gt;背景&lt;/h4&gt;美国的下水道基础设施老化，总长度达到210万公里，正面临严重的结构问题，每年导致大约75,000起污水溢流事件。传统的检测方法和技术及确定性的模型无法应对这种不可预知的问题变化，而概率性方法又缺乏必要的历史数据支持。&lt;h4&gt;目的&lt;/h4&gt;研究的目的是通过结合管道年龄、材质、直径以及环境因素和PACP评级等因素来改进对下水道管线状况预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用了人工神经网络（ANNs）和多元线性回归（MLR），其中ANNS采用ReLU激活函数和Adam优化，而MLR应用正则化处理多重共线性。评估这些模型时采用了RMSE、MAE和R2等标准。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，人工神经网络在预测准确性方面优于多元线性回归（R2为0.9066对0.8474），能够更好地捕捉非线性关系并保持泛化能力。而多元线性回归则通过识别关键的预测因子如残余堆积提升了模型可解释性。&lt;h4&gt;结论&lt;/h4&gt;管道退化的驱动因素包括管道长度、年龄和直径，深度、土壤类型和分段的影响较小。未来的研究应该优先考虑混合模型，结合人工神经网络的准确性与多元线性回归的解释能力，并采用SHAP分析和迁移学习等高级方法来提高基础设施管理的可扩展性和环境可持续性。&lt;h4&gt;翻译&lt;/h4&gt;美国下水道基础设施老化严重，导致大量污水溢流事件。本研究利用机器学习模型预测管道状况，以提高预测准确性。通过人工神经网络和多元线性回归模型的比较发现，人工神经网络在预测非线性关系方面表现更佳，而多元线性回归则提高了可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The aging sewer infrastructure in the U.S., covering 2.1 million kilometers,encounters increasing structural issues, resulting in around 75,000 yearlysanitary sewer overflows that present serious economic, environmental, andpublic health hazards. Conventional inspection techniques and deterministicmodels do not account for the unpredictable nature of sewer decline, whereasprobabilistic methods depend on extensive historical data, which is frequentlylacking or incomplete. This research intends to enhance predictive accuracy forthe condition of sewer pipelines through machine learning models artificialneural networks (ANNs) and multiple linear regression (MLR) by integratingfactors such as pipe age, material, diameter, environmental influences, andPACP ratings. ANNs utilized ReLU activation functions and Adam optimization,whereas MLR applied regularization to address multicollinearity, with bothmodels assessed through metrics like RMSE, MAE, and R2. The findings indicatedthat ANNs surpassed MLR, attaining an R2 of 0.9066 compared to MLRs 0.8474,successfully modeling nonlinear relationships while preserving generalization.MLR, on the other hand, offered enhanced interpretability by pinpointingsignificant predictors such as residual buildup. As a result, pipelinedegradation is driven by pipe length, age, and pipe diameter as key predictors,while depth, soil type, and segment show minimal influence in this analysis.Future studies ought to prioritize hybrid models that merge the accuracy ofANNs with the interpretability of MLR, incorporating advanced methods such asSHAP analysis and transfer learning to improve scalability in managinginfrastructure and promoting environmental sustainability.</description>
      <author>example@mail.com (Mohsen Mohammadagha, Mohammad Najafi, Vinayak Kaushal, Ahmad Mahmoud Ahmad Jibreen)</author>
      <guid isPermaLink="false">2502.00363v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>CausalCOMRL: Context-Based Offline Meta-Reinforcement Learning with Causal Representation</title>
      <link>http://arxiv.org/abs/2502.00983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了CausalCOMRL，一种基于因果表示学习的离线元强化学习（OMRL）方法，通过揭示任务组件间的因果关系来增强算法的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有上下文依赖的OMRL方法在利用预收集的数据集开发引导策略学习的任务表示时取得了显著成果。然而，由于混淆变量的作用，这些方法往往引入了虚假的相关性，这会降低当测试任务中的混淆因素与训练任务中不同的时候策略的表现。&lt;h4&gt;目的&lt;/h4&gt;提出一种能解决现有上下文依赖的OMRL方法中存在的虚假相关问题的方法，提升强化学习代理在不同任务环境下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;通过整合因果表示学习技术来揭示和利用任务组件间的因果关系，并且采用了互信息优化和对比学习进一步区分来自不同任务的任务表示。使用SAC算法根据元强化学习基准进行策略优化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CausalCOMRL在大多数基准测试中的表现优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;提出的基于因果表示学习的上下文依赖OMRL方法能够在一定程度上解决现有方法引入虚假相关性的局限性，并且展示了其在各种强化学习任务上的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context-based offline meta-reinforcement learning (OMRL) methods haveachieved appealing success by leveraging pre-collected offline datasets todevelop task representations that guide policy learning. However, currentcontext-based OMRL methods often introduce spurious correlations, where taskcomponents are incorrectly correlated due to confounders. These correlationscan degrade policy performance when the confounders in the test task differfrom those in the training task. To address this problem, we proposeCausalCOMRL, a context-based OMRL method that integrates causal representationlearning. This approach uncovers causal relationships among the task componentsand incorporates the causal relationships into task representations, enhancingthe generalizability of RL agents. We further improve the distinction of taskrepresentations from different tasks by using mutual information optimizationand contrastive learning. Utilizing these causal task representations, weemploy SAC to optimize policies on meta-RL benchmarks. Experimental resultsshow that CausalCOMRL achieves better performance than other methods on mostbenchmarks.</description>
      <author>example@mail.com (Zhengzhe Zhang, Wenjia Meng, Haoliang Sun, Gang Pan)</author>
      <guid isPermaLink="false">2502.00983v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning Traffic Anomalies from Generative Models on Real-Time Observations</title>
      <link>http://arxiv.org/abs/2502.01391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究提出了一种基于时空生成对抗网络（STGAN）结合图神经网络和长短时记忆网络的方法，用于检测城市交通异常。&lt;h4&gt;背景&lt;/h4&gt;准确地检测交通异常对于有效管理城市交通流量和缓解拥堵至关重要。交通数据中复杂的时空依赖关系难以捕捉。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够高效识别交通异常的模型，并通过实时监控数据验证其性能。&lt;h4&gt;方法&lt;/h4&gt;利用STGAN框架结合图神经网络和长短时记忆网络，以捕获交通数据中的复杂空间和时间依赖关系。输入的数据是基于瑞典哥德堡42个摄像头收集的分钟级观测值转换而来的车辆密度流量指标。&lt;h4&gt;主要发现&lt;/h4&gt;模型在检测到真实世界中包括信号中断、视觉伪影及极端天气影响下的异常情况时，表现出较高的准确性和较低的假阳性率。&lt;h4&gt;结论&lt;/h4&gt;所提出的STGAN框架能够有效识别交通数据中的时空异常，并且在实际应用中表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate detection of traffic anomalies is crucial for effective urbantraffic management and congestion mitigation. We use the SpatiotemporalGenerative Adversarial Network (STGAN) framework combining Graph NeuralNetworks and Long Short-Term Memory networks to capture complex spatial andtemporal dependencies in traffic data. We apply STGAN to real-time,minute-by-minute observations from 42 traffic cameras across Gothenburg,Sweden, collected over several months in 2020. The images are processed tocompute a flow metric representing vehicle density, which serves as input forthe model. Training is conducted on data from April to November 2020, andvalidation is performed on a separate dataset from November 14 to 23, 2020. Ourresults demonstrate that the model effectively detects traffic anomalies withhigh precision and low false positive rates. The detected anomalies includecamera signal interruptions, visual artifacts, and extreme weather conditionsaffecting traffic flow.</description>
      <author>example@mail.com (Fotis I. Giasemis, Alexandros Sopasakis)</author>
      <guid isPermaLink="false">2502.01391v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>FourieRF: Few-Shot NeRFs via Progressive Fourier Frequency Control</title>
      <link>http://arxiv.org/abs/2502.01405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3DV 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FourieRF是一种新颖的方法，用于实现快速且高质量的少量样本重构。&lt;h4&gt;背景&lt;/h4&gt;在有限数据的情况下进行高效和高质量的重建是一个挑战。传统的方法可能无法有效处理复杂场景的变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的参数化特征的方法，并通过实验验证其适应性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过显式的课程训练程序，逐步增加场景的复杂度来优化特征参数化。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法产生的先验在各种各样的场景中都显示出强大的适应性和鲁棒性。然而，在视图遮挡等极端情况下，仍可能存在重建错误。&lt;h4&gt;结论&lt;/h4&gt;FourieRF为少量样本渲染问题提供了强大的基线，并且未来可以通过集成基础模型来改进，以利用大规模数据驱动的先验完成缺失部分。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们介绍了FourieRF，这是一种新颖的方法，在少量样本的情况下实现快速和高质量重建。我们的方法通过显式的课程训练程序有效地参数化特征，逐步增加优化期间场景的复杂性。实验结果表明，由我们的方法产生的先验是稳健且适应性强的，适用于各种各样的场景，从而将FourieRF确立为解决少数样本渲染问题的强大而灵活的基线。虽然这种方法大大减少了伪影，但在极端未约束的情况下，例如视图遮挡导致形状的部分被遮盖时，仍可能产生重建错误。在未来，可以通过结合基础模型来增强我们的方法，利用大规模数据驱动的先验完成缺失部分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce FourieRF, a novel approach for achieving fast andhigh-quality reconstruction in the few-shot setting. Our method effectivelyparameterizes features through an explicit curriculum training procedure,incrementally increasing scene complexity during optimization. Experimentalresults show that the prior induced by our approach is both robust andadaptable across a wide variety of scenes, establishing FourieRF as a strongand versatile baseline for the few-shot rendering problem. While our approachsignificantly reduces artifacts, it may still lead to reconstruction errors inseverely under-constrained scenarios, particularly where view occlusion leavesparts of the shape uncovered. In the future, our method could be enhanced byintegrating foundation models to complete missing parts using large data-drivenpriors.</description>
      <author>example@mail.com (Diego Gomez, Bingchen Gong, Maks Ovsjanikov)</author>
      <guid isPermaLink="false">2502.01405v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Sundial: A Family of Highly Capable Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2502.00816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为Sundial的新型时间序列基础模型，它基于灵活、可扩展的时间序列原生预训练方法。&lt;h4&gt;背景&lt;/h4&gt;现有的时间序列预测模型通常依赖于参数化密度，并且难以进行无监督的原生预训练。为了克服这些限制，研究团队提出了一个新的解决方案。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够生成多个可能预测的新模型，以提高表示学习的灵活性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于流匹配的时间Flow损失函数（TimeFlow Loss），用于在任意长度时间序列上原生预训练Transformer模型。此外，还收集了一个包含1万亿个时间点的数据集TimeBench，其中包括大量真实世界数据和合成数据。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用TimeFlow Loss进行微调，Sundial模型能够避免模式崩溃，并显示出前所未有的模型容量和零样本预测性能。&lt;h4&gt;结论&lt;/h4&gt;Sundial模型在点预测和概率预测基准测试中均达到了新的最佳状态。这表明Sundial开创的生成性范式将有助于广泛的时间序列预测场景。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了Sundial，这是一个灵活、可扩展的时间序列基础模型族。为了预测下一个补丁的概率分布，提出了基于流匹配的时间Flow损失函数（TimeFlow Loss），它使Transformer可以在时间序列上进行原生预训练而不必进行离散标记化。条件设置为任意长度的时间序列后，我们的模型在不指定先验分布的情况下进行了无监督的预训练，并能够生成多个可能的预测，在表示学习中超越了使用参数密度的方法。为了实现时间序列基础模型，我们对Transformer进行了最少但关键的适应性调整，并创建了一个包含1万亿个时间点的数据集TimeBench，其中大部分是真实世界数据和合成数据。通过利用TimeFlow Loss来缓解模式崩溃问题，我们在TimeBench上预训练了一系列Sundial模型，这些模型在零样本预测方面表现出前所未有的模型容量和泛化性能。除了展示良好的扩展行为之外，Sundial还在点预测和概率预测基准测试中达到了新的最佳状态。我们相信Sundial的开创性生成范式将有助于广泛的时间序列预测场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Sundial, a family of native, flexible, and scalable time seriesfoundation models. To predict the next-patch's distribution, we propose aTimeFlow Loss based on flow-matching, which facilitates native pre-training ofTransformers on time series without discrete tokenization. Conditioned onarbitrary-length time series, our model is pre-trained without specifying anyprior distribution and can generate multiple probable predictions, achievingflexibility in representation learning beyond using parametric densities.Towards time series foundation models, we leverage minimal but crucialadaptations of Transformers and curate TimeBench with 1 trillion time points,comprising mostly real-world datasets and synthetic data. By mitigating modecollapse through TimeFlow Loss, we pre-train a family of Sundial models onTimeBench, which exhibit unprecedented model capacity and generalizationperformance on zero-shot forecasting. In addition to presenting good scalingbehavior, Sundial achieves new state-of-the-art on both point forecasting andprobabilistic forecasting benchmarks. We believe that Sundial's pioneeringgenerative paradigm will facilitate a wide variety of forecasting scenarios.</description>
      <author>example@mail.com (Yong Liu, Guo Qin, Zhiyuan Shi, Zhi Chen, Caiyin Yang, Xiangdong Huang, Jianmin Wang, Mingsheng Long)</author>
      <guid isPermaLink="false">2502.00816v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.00848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了首个基于真实物体的检索增强生成框架（RealRAG），解决了现有文本到图像模型在处理细粒度和未见过的真实世界对象时的知识缺口问题。&lt;h4&gt;背景&lt;/h4&gt;现有的文本到图像生成模型，如Stable Diffusion V3和Flux，在性能上取得了显著进展。然而，这些模型由于其固定的参数训练于封闭的数据集中而存在知识限制，导致它们在面对细粒度且未见过的真实世界对象时会出现幻觉或失真。&lt;h4&gt;目的&lt;/h4&gt;通过学习并检索真实世界的图像来补充生成模型的知识缺口，从而增强对未见过的细粒度新物体的生成能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自我反思对比学习训练的反射检索器，该检索器将生成器的知识注入到自反负样本中。这种框架通过集成精细级视觉知识以解决失真问题，并提高细粒度对象生成的真实感。&lt;h4&gt;主要发现&lt;/h4&gt;RealRAG在所有类型的最新文本到图像生成模型上都能模块化应用，并且能够显著提升这些模型的性能，例如使用自动回归模型时在Stanford Car基准测试中FID分数提升了16.18%。&lt;h4&gt;结论&lt;/h4&gt;基于真实物体的检索增强生成框架（RealRAG）是一种有效的解决方案，它通过集成真实世界的图像来克服现有文本到图像生成模型的知识限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux,have achieved notable progress. However, these models are strongly restrictedto their limited knowledge, a.k.a., their own fixed parameters, that aretrained with closed datasets. This leads to significant hallucinations ordistortions when facing fine-grained and unseen novel real-world objects, e.g.,the appearance of the Tesla Cybertruck. To this end, we present the firstreal-object-based retrieval-augmented generation framework (RealRAG), whichaugments fine-grained and unseen novel object generation by learning andretrieving real-world images to overcome the knowledge gaps of generativemodels. Specifically, to integrate missing memory for unseen novel objectgeneration, we train a reflective retriever by self-reflective contrastivelearning, which injects the generator's knowledge into the sef-reflectivenegatives, ensuring that the retrieved augmented images compensate for themodel's missing knowledge. Furthermore, the real-object-based frameworkintegrates fine-grained visual knowledge for the generative models, tacklingthe distortion problem and improving the realism for fine-grained objectgeneration. Our Real-RAG is superior in its modular application to all types ofstate-of-the-art text-to-image generative models and also delivers remarkableperformance boosts with all of them, such as a gain of 16.18% FID score withthe auto-regressive model on the Stanford Car benchmark.</description>
      <author>example@mail.com (Yuanhuiyi Lyu, Xu Zheng, Lutao Jiang, Yibo Yan, Xin Zou, Huiyu Zhou, Linfeng Zhang, Xuming Hu)</author>
      <guid isPermaLink="false">2502.00848v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Framework for Double-Blind Federated Adaptation of Foundation Models</title>
      <link>http://arxiv.org/abs/2502.01289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种用于基础模型（FM）的双盲联邦适应框架，该框架利用全同态加密(FHE)技术，在保护数据隐私的同时优化图像分类任务。&lt;h4&gt;背景&lt;/h4&gt;当前的基础模型在大型数据集上预训练后，在许多计算机视觉任务中取得了先进成果。然而，由于法规和隐私问题，这些模型需要的数据通常分散在多个实体之间，无法集中处理。&lt;h4&gt;目的&lt;/h4&gt;设计一个双盲联邦适应算法框架，允许基础模型所有者（学习服务提供商LSP）与其数据持有者合作，提高模型性能，同时确保双方的敏感信息不被泄露。&lt;h4&gt;方法&lt;/h4&gt;该框架首先通过知识蒸馏将基础模型分解为一系列FHE友好的模块。然后利用低秩并行适配器来适应下游任务，而无需反向传播通过整个FM网络。此外设计了隐私保护置换方案以防止数据持有者从中间表示中提取模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的双盲联邦框架在四个不同数据集上的性能优于传统方法，证明其实际可行性。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一种新颖的全同态加密下的基础模型优化策略，在保护隐私的前提下实现了有效的跨机构模型协作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of foundational models (FMs) pre-trained on large-scale datahas advanced the state-of-the-art in many computer vision tasks. While FMs havedemonstrated good zero-shot performance on many image classification tasks,there is often scope for performance improvement by adapting the FM to thedownstream task. However, the data that is required for this adaptationtypically exists in silos across multiple entities (data owners) and cannot becollated at a central location due to regulations and privacy concerns. At thesame time, a learning service provider (LSP) who owns the FM cannot share themodel with the data owners due to proprietary reasons. In some cases, the dataowners may not even have the resources to store such large FMs. Hence, there isa need for algorithms to adapt the FM in a double-blind federated manner, i.e.,the data owners do not know the FM or each other's data, and the LSP does notsee the data for the downstream tasks. In this work, we propose a framework fordouble-blind federated adaptation of FMs using fully homomorphic encryption(FHE). The proposed framework first decomposes the FM into a sequence ofFHE-friendly blocks through knowledge distillation. The resulting FHE-friendlymodel is adapted for the downstream task via low-rank parallel adapters thatcan be learned without backpropagation through the FM. Since the proposedframework requires the LSP to share intermediate representations with the dataowners, we design a privacy-preserving permutation scheme to prevent the dataowners from learning the FM through model extraction attacks. Finally, a secureaggregation protocol is employed for federated learning of the low-rankparallel adapters. Empirical results on four datasets demonstrate the practicalfeasibility of the proposed framework.</description>
      <author>example@mail.com (Nurbek Tastan, Karthik Nandakumar)</author>
      <guid isPermaLink="false">2502.01289v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Improving Quality Control Of MRI Images Using Synthetic Motion Data</title>
      <link>http://arxiv.org/abs/2502.00160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;通过合成数据预训练模型并进行迁移学习，提高MRI质量控制（QC）的准确性、减少资源需求。&lt;h4&gt;背景&lt;/h4&gt;由于不平衡和有限的数据集以及主观评分问题，开发可靠的自动化MRI QC系统面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决上述问题，提出一种改进的自动化QC方法，以便在各种研究环境中更广泛地应用。&lt;h4&gt;方法&lt;/h4&gt;先使用合成生成的运动伪影对模型进行预训练，然后通过迁移学习应用于QC分类任务。&lt;h4&gt;主要发现&lt;/h4&gt;相比从头开始训练的方法，这种方法不仅提高了识别低质量扫描的准确性，还减少了训练时间和资源需求。&lt;h4&gt;结论&lt;/h4&gt;利用合成数据提供了一种更稳健且资源效率更高的解决方案，为MRI QC自动化在多样化研究环境中的广泛应用铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;MRI质量控制（QC）由于不平衡和有限的数据集以及主观评分问题而具有挑战性。这些问题阻碍了可靠自动化的开发。为了应对这些挑战，我们引入了一种先使用合成生成的运动伪影对模型进行预训练，并通过迁移学习应用于实际QC分类的方法。此方法不仅提高了识别低质量扫描的准确性，还减少了与从头开始训练相比所需的时间和资源需求。通过利用合成数据，提供了一种更稳健且资源效率更高的解决方案以实现MRI QC自动化，在各种研究环境中的应用更具可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; MRI quality control (QC) is challenging due to unbalanced and limiteddatasets, as well as subjective scoring, which hinder the development ofreliable automated QC systems. To address these issues, we introduce anapproach that pretrains a model on synthetically generated motion artifactsbefore applying transfer learning for QC classification. This method not onlyimproves the accuracy in identifying poor-quality scans but also reducestraining time and resource requirements compared to training from scratch. Byleveraging synthetic data, we provide a more robust and resource-efficientsolution for QC automation in MRI, paving the way for broader adoption indiverse research settings.</description>
      <author>example@mail.com (Charles Bricout, Sylvain Bouix, Samira Ebrahimi Kahou, Kang Ik K. Cho, Michael Harms, Ofer Pasternak, Carrie E. Bearden, Patrick D. McGorry, Rene S. Kahn, John Kane, Barnaby Nelson, Scott W. Woods, Martha E. Shenton)</author>
      <guid isPermaLink="false">2502.00160v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>CycleGuardian: A Framework for Automatic RespiratorySound classification Based on Improved Deep clustering and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2502.00734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级网络CycleGuardian及其基于改进的深度聚类和对比学习框架，用于区分正常和异常的呼吸声音。该方法在ICBHI2017数据集上取得了当前最佳性能。&lt;h4&gt;背景&lt;/h4&gt;听诊对于早期呼吸道和肺部疾病的诊断至关重要。尽管有研究利用深度学习技术自动分类呼吸音，但由于缺乏大规模的数据集限制了这些模型的优化。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级网络CycleGuardian及相应框架，以解决当前模型在参数规模过大、难以部署到资源受限平台的问题，并提高异常呼吸声音识别性能。&lt;h4&gt;方法&lt;/h4&gt;首先生成混合光谱图来提供特征多样性并分组光谱以捕捉间歇性异常音；接着设计了一个集成了深度聚类模块和对比学习模块的网络，通过多目标优化增强训练效果。模型在ICBHI2017数据集上的表现优于当前最佳模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法达到了Sp: 82.06%，Se:44.47%以及Score: 63.26%的成绩，在网络模型大小为38M的情况下比现有模型高出近7%。此外，该系统还能部署到Android设备上。&lt;h4&gt;结论&lt;/h4&gt;CycleGuardian及其框架提供了一种新的途径来优化呼吸声音分类问题，特别是对于移动平台上的智能听诊应用具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;听诊在早期呼吸道和肺部疾病的诊断中起着决定性的作用。尽管新冠疫情后基于深度学习的方法出现用于自动呼吸音分类，但受限的数据集阻碍了性能的提升。区分正常和异常呼吸声音因两种类型均存在正常的呼吸成分和噪声而具有挑战性。此外，不同的异常呼吸声音表现出类似的异常特征，导致难以进行差异识别。除此之外，现有的最先进模型面临参数规模过大问题，难以部署到资源有限的移动平台。为解决这些问题，我们设计了一种轻量级网络CycleGuardian，并提出基于改进深度聚类和对比学习的框架。首先生成混合光谱图以提供特征多样性并分组光谱来捕捉间歇性异常音；然后，CycleGuardian整合了一个深度聚类模块与一个相似度约束聚类组件，以提高捕捉异常特性能力以及一个带群混杂对比学习模块，增强了对异常特征的识别。多目标优化在训练过程中提升了整体性能。实验中我们使用ICBHI2017数据集，并采用官方划分方法，在没有预训练权重的情况下，我们的方法达到了Sp: 82.06%，Se:44.47%和Score: 63.26%，而模型大小仅为38M，比当前模型性能提高了近7%。另外，我们在Android设备上部署了该网络，展示了全面的智能听诊系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chumingqian/CycleGuardian&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auscultation plays a pivotal role in early respiratory and pulmonary diseasediagnosis. Despite the emergence of deep learning-based methods for automaticrespiratory sound classification post-Covid-19, limited datasets impedeperformance enhancement. Distinguishing between normal and abnormal respiratorysounds poses challenges due to the coexistence of normal respiratory componentsand noise components in both types. Moreover, different abnormal respiratorysounds exhibit similar anomalous features, hindering their differentiation.Besides, existing state-of-the-art models suffer from excessive parameter size,impeding deployment on resource-constrained mobile platforms. To address theseissues, we design a lightweight network CycleGuardian and propose a frameworkbased on an improved deep clustering and contrastive learning. We firstgenerate a hybrid spectrogram for feature diversity and grouping spectrogramsto facilitating intermittent abnormal sound capture.Then, CycleGuardianintegrates a deep clustering module with a similarity-constrained clusteringcomponent to improve the ability to capture abnormal features and a contrastivelearning module with group mixing for enhanced abnormal feature discernment.Multi-objective optimization enhances overall performance during training. Inexperiments we use the ICBHI2017 dataset, following the official split methodand without any pre-trained weights, our method achieves Sp: 82.06 $\%$, Se:44.47$\%$, and Score: 63.26$\%$ with a network model size of 38M, comparing tothe current model, our method leads by nearly 7$\%$, achieving the current bestperformances. Additionally, we deploy the network on Android devices,showcasing a comprehensive intelligent respiratory sound auscultation system.</description>
      <author>example@mail.com (Yun Chu, Qiuhao Wang, Enze Zhou, Ling Fu, Qian Liu, Gang Zheng)</author>
      <guid isPermaLink="false">2502.00734v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>PerfSeer: An Efficient and Accurate Deep Learning Models Performance Predictor</title>
      <link>http://arxiv.org/abs/2502.01206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了PerfSeer，一种基于图神经网络的深度学习模型性能预测系统。&lt;h4&gt;背景&lt;/h4&gt;准确预测深度学习模型的执行时间、资源利用等性能对于神经架构搜索（NAS）、DL集群调度器和其他技术至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了提高深度学习模型性能预测的准确性，提出了一种新的表示和预测方法。&lt;h4&gt;方法&lt;/h4&gt;将模型表示为包括拓扑结构、节点特征、边特征和全局特征的图，并基于此提出了SeerNet模型。引入了协同最大均值聚合（Synergistic Max-Mean Aggregation, SynMM）和全局节点视角增强（Global-Node Perspective Boost, GNPB）来优化预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，PerfSeer在多个指标上超越了现有的性能评估系统，如nn-Meter、Brp-NAS 和 DIPPM。&lt;h4&gt;结论&lt;/h4&gt;PerfSeer为深度学习模型的高效和精确性能预测提供了新的解决方案，并且能够扩展到多任务场景。&lt;h4&gt;翻译&lt;/h4&gt;预测深度学习（DL）模型的性能，例如执行时间和资源利用率，在神经架构搜索（NAS）、DL集群调度器和其他推进深度学习技术方面至关重要。现有的表示方法无法全面代表多样化的模型配置，导致准确性不足。为了解决这个问题，我们提出了一种新的表示方式：将模型视为一个图，包括拓扑结构、节点特征、边特征和全局特性，这些对于有效地捕捉模型性能至关重要。基于这种表示，我们提出了PerfSeer，一个新的预测器，它使用基于图神经网络（GNN）的性能预测模型SeerNet。SeerNet充分利用了拓扑结构和各种特征，并通过协同最大均值聚合(SynMM) 和全局节点视角增强(GNPB) 优化来更有效地捕捉关键性能信息，从而准确地预测模型性能。此外，SeerNet可以扩展为使用项目冲突梯度（PCGrad）的SeerNet-Multi，使同时预测多个性能指标更加有效，并且不会显著影响准确性。我们构建了一个数据集，包含超过53,000种不同模型配置的执行时间、内存使用情况和流处理器利用率等性能指标的数据。评估结果显示，PerfSeer在多个基准测试中优于现有的nn-Meter、Brp-NAS 和 DIPPM系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the performance of deep learning (DL) models, such as executiontime and resource utilization, is crucial for Neural Architecture Search (NAS),DL cluster schedulers, and other technologies that advance deep learning. Therepresentation of a model is the foundation for its performance prediction.However, existing methods cannot comprehensively represent diverse modelconfigurations, resulting in unsatisfactory accuracy. To address this, werepresent a model as a graph that includes the topology, along with the node,edge, and global features, all of which are crucial for effectively capturingthe performance of the model. Based on this representation, we proposePerfSeer, a novel predictor that uses a Graph Neural Network (GNN)-basedperformance prediction model, SeerNet. SeerNet fully leverages the topology andvarious features, while incorporating optimizations such as SynergisticMax-Mean aggregation (SynMM) and Global-Node Perspective Boost (GNPB) tocapture the critical performance information more effectively, enabling it topredict the performance of models accurately. Furthermore, SeerNet can beextended to SeerNet-Multi by using Project Conflicting Gradients (PCGrad),enabling efficient simultaneous prediction of multiple performance metricswithout significantly affecting accuracy. We constructed a dataset containingperformance metrics for 53k+ model configurations, including execution time,memory usage, and Streaming Multiprocessor (SM) utilization during bothtraining and inference. The evaluation results show that PerfSeer outperformsnn-Meter, Brp-NAS, and DIPPM.</description>
      <author>example@mail.com (Xinlong Zhao, Jiande Sun, Jia Zhang, Sujuan Hou, Shuai Li, Tong Liu, Ke Liu)</author>
      <guid isPermaLink="false">2502.01206v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Transfer Learning for Deep Learning Polyp Detection in Colonoscopy Images Using YOLOv8</title>
      <link>http://arxiv.org/abs/2502.00133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 6 tables, SPIE conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;深度学习在目标识别任务中表现出色，但在有限训练数据下进行领域特定应用的学习仍具挑战。迁移学习通过利用相关数据集上的预训练知识来解决这一问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习方法已经在物体检测等任务上展示了强劲的表现，但缺乏大量训练数据的情况下，针对具体领域的适应性仍然是一个难题。迁移学习可以缓解这个问题，它通过从相关的数据集中进行预训练来提高新任务的学习效率。&lt;h4&gt;目的&lt;/h4&gt;研究YOLOv8n模型在七种不同的数据集上进行预训练的效果，并评估其在息肉检测任务中的效果。比较通用的大规模数据集和具有类似息肉特征的专用数据集的有效性，同时考察数据集大小对迁移学习的影响。&lt;h4&gt;方法&lt;/h4&gt;在息肉数据集上实验了YOLOv8n模型在七种不同预训练数据集上的性能表现，并对比从头开始训练的效果。这些预训练的数据集包括大规模、通用型和专门针对类似息肉特征的多个数据集。&lt;h4&gt;主要发现&lt;/h4&gt;预训练数据集的相关性对迁移学习的成功至关重要，预训练后转移到特定任务中的模型通常比完全从零开始训练的模型表现更好。特别地，在具有共享领域特性的数据集上进行预训练能够显著提高模型性能。&lt;h4&gt;结论&lt;/h4&gt;相关领域的预训练对于深度学习模型在有限训练数据条件下的泛化能力和效率有着重要影响，适当的预训练可以显著提升目标检测任务中的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已包含&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning methods have demonstrated strong performance in objectiontasks; however, their ability to learn domain-specific applications withlimited training data remains a significant challenge. Transfer learningtechniques address this issue by leveraging knowledge from pre-training onrelated datasets, enabling faster and more efficient learning for new tasks.Finding the right dataset for pre-training can play a critical role indetermining the success of transfer learning and overall model performance. Inthis paper, we investigate the impact of pre-training a YOLOv8n model on sevendistinct datasets, evaluating their effectiveness when transferred to the taskof polyp detection. We compare whether large, general-purpose datasets withdiverse objects outperform niche datasets with characteristics similar topolyps. In addition, we assess the influence of the size of the dataset on theefficacy of transfer learning. Experiments on the polyp datasets show thatmodels pre-trained on relevant datasets consistently outperform those trainedfrom scratch, highlighting the benefit of pre-training on datasets with shareddomain-specific features.</description>
      <author>example@mail.com (Fabian Vazquez, Jose Angel Nuñez, Xiaoyan Fu, Pengfei Gu, Bin Fu)</author>
      <guid isPermaLink="false">2502.00133v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>TeamVision: An AI-powered Learning Analytics System for Supporting Reflection in Team-based Healthcare Simulation</title>
      <link>http://arxiv.org/abs/2501.09930v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CHI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究介绍了一种名为TeamVision的AI驱动的多模态学习分析系统，该系统通过记录语音、自动转录、身体旋转和定位数据来支持医疗模拟后的反思性讨论。&lt;h4&gt;背景&lt;/h4&gt;在医疗教育中，仿真训练有助于学员在无风险环境中发展团队合作和临床技能，并通过结构化的讨论促进对现实世界实践的反思。然而，视频难以使用，缺乏提供简洁的数据驱动总结以支撑有效反馈。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，研究开发了TeamVision系统来捕捉医疗模拟中的多模态数据并为教育者提供即时引导性反馈工具。&lt;h4&gt;方法&lt;/h4&gt;进行了一个野外研究，涉及56个团队（221名学生）和六位教师使用TeamVision进行记录的反馈会议。后续访谈调查了15名学生和五位教师对系统的使用感受、准确性和信任度。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，TeamVision系统使反思性讨论更加灵活，并且揭示了在医疗模拟中应用AI驱动系统的挑战与意义。&lt;h4&gt;结论&lt;/h4&gt;研究表明，虽然团队视图能有效支持医疗仿真后的反馈流程，但也面临一些挑战和实施中的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3706598.3713395&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Healthcare simulations help learners develop teamwork and clinical skills ina risk-free setting, promoting reflection on real-world practices throughstructured debriefs. However, despite video's potential, it is hard to use,leaving a gap in providing concise, data-driven summaries for supportingeffective debriefing. Addressing this, we present TeamVision, an AI-poweredmultimodal learning analytics (MMLA) system that captures voice presence,automated transcriptions, body rotation, and positioning data, offeringeducators a dashboard to guide debriefs immediately after simulations. Weconducted an in-the-wild study with 56 teams (221 students) and recordeddebriefs led by six teachers using TeamVision. Follow-up interviews with 15students and five teachers explored perceptions of its usefulness, accuracy,and trustworthiness. This paper examines: i) how TeamVision was used indebriefing, ii) what educators found valuable and challenging, and iii)perceptions of its effectiveness. Results suggest TeamVision enables flexibledebriefing and highlights the challenges and implications of using AI-poweredsystems in healthcare simulation.</description>
      <author>example@mail.com (Vanessa Echeverria, Linxuan Zhao, Riordan Alfredo, Mikaela Milesi, Yuequiao Jin, Sophie Abel, Jie Fan, Lixiang Yan, Xinyu Li, Samantha Dix, Rosie Wotherspoon, Hollie Jaggard, Abra Osborne, Simon Buckingham Shum, Dragan Gasevic, Roberto Martinez-Maldonado)</author>
      <guid isPermaLink="false">2501.09930v3</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Scalable Density Functional Theory Hamiltonian Prediction through Adaptive Sparsity</title>
      <link>http://arxiv.org/abs/2502.01171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SPHNet的新模型，该模型利用自适应稀疏性有效地预测哈密顿矩阵，并在保持准确性的前提下显著减少计算量。&lt;h4&gt;背景&lt;/h4&gt;在计算化学领域中，使用SE(3)等变图神经网络虽然取得了巨大成功，但其高阶张量积运算导致的大量计算成本限制了它们在大型分子系统中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且可扩展的SPHNet模型，通过引入自适应稀疏性来解决现有方法中存在的问题，并提高大规模系统的适用性和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了两个创新性的稀疏门控机制以选择性地限制非关键相互作用组合；开发了三阶段稀疏调度器优化稀疏表示；并在QH9和PubchemQH数据集上进行了广泛的评估。&lt;h4&gt;主要发现&lt;/h4&gt;SPHNet不仅在哈密顿矩阵预测任务中实现了最先进的精度，还提供了比现有模型高达7倍的速度提升。此外，提出的稀疏化技术也具有潜在的应用前景以改善其他SE(3)等变网络的效率和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法显著提高了大规模分子系统的计算效率，同时保持了高预测准确率，为未来研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;哈密顿矩阵预测是计算化学中的关键部分，用于确定广泛范围内的分子特性。虽然SE(3)等变图神经网络在该领域取得了重大成功，但由高阶张量积运算引发的大量计算成本限制了其对于大型分子系统和扩展基集的应用。为了解决这个问题，我们引入了一个高效的SPHNet模型，它将自适应稀疏性纳入哈密顿矩阵预测中，并通过两种新颖的稀疏门控机制显著减少了张量乘法操作的数量。为了优化稀疏表示，我们设计了一种三阶段稀疏调度器，在保证精度的前提下实现了高达70%的稀疏率和稳定的收敛性能。在QH9和PubchemQH数据集上的广泛评估表明，SPHNet不仅达到了最先进的预测准确度，并且比现有模型快了多达7倍的速度。除此之外，提出的稀疏化技术还为改善其他SE(3)等变网络的效率和可扩展性提供了潜在的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hamiltonian matrix prediction is pivotal in computational chemistry, servingas the foundation for determining a wide range of molecular properties. WhileSE(3) equivariant graph neural networks have achieved remarkable success inthis domain, their substantial computational cost-driven by high-order tensorproduct (TP) operations-restricts their scalability to large molecular systemswith extensive basis sets. To address this challenge, we introduce SPHNet, anefficient and scalable equivariant network that incorporates adaptive sparsityinto Hamiltonian prediction. SPHNet employs two innovative sparse gates toselectively constrain non-critical interaction combinations, significantlyreducing tensor product computations while maintaining accuracy. To optimizethe sparse representation, we develop a Three-phase Sparsity Scheduler,ensuring stable convergence and achieving high performance at sparsity rates ofup to 70 percent. Extensive evaluations on QH9 and PubchemQH datasetsdemonstrate that SPHNet achieves state-of-the-art accuracy while providing upto a 7x speedup over existing models. Beyond Hamiltonian prediction, theproposed sparsification techniques also hold significant potential forimproving the efficiency and scalability of other SE(3) equivariant networks,further broadening their applicability and impact.</description>
      <author>example@mail.com (Erpai Luo, Xinran Wei, Lin Huang, Yunyang Li, Han Yang, Zun Wang, Chang Liu, Zaishuo Xia, Jia Zhang, Bin Shao)</author>
      <guid isPermaLink="false">2502.01171v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Forward-Forward: A Training Algorithm of Vision Transformer</title>
      <link>http://arxiv.org/abs/2502.00571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 8 figures, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Forward-Forward算法是一种模拟大脑神经网络训练的新方法，尽管其性能目前不如反向传播算法，但研究者在Vision Transformer模型上对其进行了改进，引入了Contrastive Forward-Forward，显著提高了准确率和收敛速度。&lt;h4&gt;背景&lt;/h4&gt;虽然反向传播是人工神经网络广泛接受的训练算法，研究人员仍在从大脑中寻找灵感以找到性能可能更好的方法。Forward-Forward是一种新训练算法，尽管它在性能上与反向传播存在差距，但它更接近于大脑中的实际操作。&lt;h4&gt;目的&lt;/h4&gt;将Forward-Forward算法扩展到更为复杂和现代的Vision Transformer模型，并尝试对其进行改进。&lt;h4&gt;方法&lt;/h4&gt;基于对比学习的见解，对Forward-Forward算法进行了修订，引入了Contrastive Forward-Forward。实验中使用交叉熵作为反向传播的基础损失函数进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法在Vision Transformer上比基础的Forward-Forward表现显著更好，准确率提高了高达10%，并且收敛速度提升了5到20倍。此外，在不精确监督等条件下，修改后的Forward-Forward甚至超过了反向传播算法的表现。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习的启发对Forward-Forward进行改进后，其性能与反向传播之间的差距缩小了，并且在某些情况下实现了超越。&lt;h4&gt;翻译&lt;/h4&gt;尽管反向传播算法是人工神经网络中被广泛接受的训练方法，但研究人员一直在寻找从大脑获得灵感的方法，以期找到具有潜在更好性能的方式。Forward-Forward是一种新的训练算法，它更接近于大脑中的实际情况运作方式，不过其性能与反向传播相比仍有较大差距。在Forward-Forward算法中，损失函数位于每一层之后，并通过两个局部前向传递和一个局部后向传递来更新一层的数据。尽管Forward-Forward尚处于初级阶段，并且是在简单的多层感知器网络上开发并评估了解决图像分类任务的能力，但在本工作中，研究者将其应用扩展到了更为复杂和现代的Vision Transformer模型上。受到对比学习见解的启发，尝试对算法进行了修订，引入了Contrastive Forward-Forward。实验结果表明，在Vision Transformer中，我们提出的算法比基础的Forward-Forward表现显著更好，其准确率提高了高达10%，并且收敛速度提升了5到20倍。此外，如果使用交叉熵作为反向传播的基本损失函数，将证明对基础Forward-Forward的改进可以减少与反向传播在Vision Transformer上的性能差距，并且在不精确监督等条件下甚至能超越它。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although backpropagation is widely accepted as a training algorithm forartificial neural networks, researchers are always looking for inspiration fromthe brain to find ways with potentially better performance. Forward-Forward isa new training algorithm that is more similar to what occurs in the brain,although there is a significant performance gap compared to backpropagation. Inthe Forward-Forward algorithm, the loss functions are placed after each layer,and the updating of a layer is done using two local forward passes and onelocal backward pass. Forward-Forward is in its early stages and has beendesigned and evaluated on simple multi-layer perceptron networks to solve imageclassification tasks. In this work, we have extended the use of this algorithmto a more complex and modern network, namely the Vision Transformer. Inspiredby insights from contrastive learning, we have attempted to revise thisalgorithm, leading to the introduction of Contrastive Forward-Forward.Experimental results show that our proposed algorithm performs significantlybetter than the baseline Forward-Forward leading to an increase of up to 10% inaccuracy and boosting the convergence speed by 5 to 20 times on VisionTransformer. Furthermore, if we take Cross Entropy as the baseline lossfunction in backpropagation, it will be demonstrated that the proposedmodifications to the baseline Forward-Forward reduce its performance gapcompared to backpropagation on Vision Transformer, and even outperforms it incertain conditions, such as inaccurate supervision.</description>
      <author>example@mail.com (Hossein Aghagolzadeh, Mehdi Ezoji)</author>
      <guid isPermaLink="false">2502.00571v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Al-Khwarizmi: Discovering Physical Laws with Foundation Models</title>
      <link>http://arxiv.org/abs/2502.01702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了一种名为Al-Khwarizmi的新型代理框架，用于从数据中自动推断物理定律。此方法结合了基于简单组件构建模型的理念和Sparse Identification of Nonlinear Dynamics (SINDy) 方法，并利用大语言模型、视觉语言模型以及检索增强生成技术来自动化这一过程。&lt;h4&gt;背景&lt;/h4&gt;从数据中推导出物理法则一直是科学与工程领域的核心挑战，包括医疗保健、物理学、生物科学、社会科学、可持续性、气候学及机器人技术等领域。深度网络虽然能提供高精度的结果，但缺乏可解释性，因此人们开始关注基于简单组件构建模型的方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在不需要大量专业知识的情况下自动推断物理定律的框架，并能够整合先验知识和迭代优化候选解决方案。&lt;h4&gt;方法&lt;/h4&gt;利用大语言模型、视觉语言模型以及检索增强生成技术（LLMs, VLMs, RAG），通过自动化系统观测总结及特征库生成过程来实现此目标。Al-Khwarizmi采用两步法：首先，它对系统的文本描述、原始数据和图表进行总结；其次，根据这些信息自动生成候选特征库并配置优化器。&lt;h4&gt;主要发现&lt;/h4&gt;该算法在超过198个模型上的评估中表现出色，相较于现有最佳方法提高了20%的性能。&lt;h4&gt;结论&lt;/h4&gt;Al-Khwarizmi框架通过自动化物理定律发现过程，展示了从复杂数据集中推断物理法则的强大潜力，并且可以广泛应用于多个学科领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到的方法利用了先进的机器学习技术来简化物理规律的发现流程，旨在实现更广泛的科学应用并提高现有方法的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inferring physical laws from data is a central challenge in science andengineering, including but not limited to healthcare, physical sciences,biosciences, social sciences, sustainability, climate, and robotics. Deepnetworks offer high-accuracy results but lack interpretability, promptinginterest in models built from simple components. The Sparse Identification ofNonlinear Dynamics (SINDy) method has become the go-to approach for buildingsuch modular and interpretable models. SINDy leverages sparse regression withL1 regularization to identify key terms from a library of candidate functions.However, SINDy's choice of candidate library and optimization method requiressignificant technical expertise, limiting its widespread applicability. Thiswork introduces Al-Khwarizmi, a novel agentic framework for physical lawdiscovery from data, which integrates foundational models with SINDy.Leveraging LLMs, VLMs, and Retrieval-Augmented Generation (RAG), our approachautomates physical law discovery, incorporating prior knowledge and iterativelyrefining candidate solutions via reflection. Al-Khwarizmi operates in twosteps: it summarizes system observations-comprising textual descriptions, rawdata, and plots-followed by a secondary step that generates candidate featurelibraries and optimizer configurations to identify hidden physics lawscorrectly. Evaluating our algorithm on over 198 models, we demonstratestate-of-the-art performance compared to alternatives, reaching a 20 percentincrease against the best-performing alternative.</description>
      <author>example@mail.com (Christopher E. Mower, Haitham Bou-Ammar)</author>
      <guid isPermaLink="false">2502.01702v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Joint Predictive Embedding and Bayesian Inference in Graph Self Supervised Learning</title>
      <link>http://arxiv.org/abs/2502.01684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的联合嵌入预测框架，用于图的自监督学习。该框架消除了对比目标和负采样，同时保持了语义和结构信息，并引入了一个基于伪标签的目标项以增强节点区分能力。&lt;h4&gt;背景&lt;/h4&gt;图表示学习已成为节点分类和链接预测等任务的基础，但现有的自监督学习方法面临计算效率低、依赖于对比目标以及嵌入塌陷等问题。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出了一种新的联合嵌入预测框架来提高图的自监督学习性能。&lt;h4&gt;方法&lt;/h4&gt;该框架包括非对比性视角不变的联合嵌入预测架构，利用子图之间的单个上下文和多个目标的关系，并使用基于高斯混合模型（GMM）的伪标签评分来捕捉语义贡献。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，提出的框架在没有复杂解码器或对比损失的情况下超越了现有的最先进的图自监督学习方法，展示了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;这项工作通过提供一种计算效率高且抵抗嵌入塌陷的方法，在将空间和语义图特征连接以支持下游任务方面取得了进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种用于改进图表示学习的新框架。该框架解决了当前自监督方法中存在的问题，提供了更高效、更可靠的解决方案，并在实验中证明了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning has emerged as a cornerstone for tasks likenode classification and link prediction, yet prevailing self-supervisedlearning (SSL) methods face challenges such as computational inefficiency,reliance on contrastive objectives, and representation collapse. Existingapproaches often depend on feature reconstruction, negative sampling, orcomplex decoders, which introduce training overhead and hinder generalization.Further, current techniques which address such limitations fail to account forthe contribution of node embeddings to a certain prediction in the absence oflabeled nodes. To address these limitations, we propose a novel joint embeddingpredictive framework for graph SSL that eliminates contrastive objectives andnegative sampling while preserving semantic and structural information.Additionally, we introduce a semantic-aware objective term that incorporatespseudo-labels derived from Gaussian Mixture Models (GMMs), enhancing nodediscriminability by evaluating latent feature contributions. Extensiveexperiments demonstrate that our framework outperforms state-of-the-art graphSSL methods across benchmarks, achieving superior performance withoutcontrastive loss or complex decoders. Key innovations include (1) anon-contrastive, view-invariant joint embedding predictive architecture, (2)Leveraging single context and multiple targets relationship between subgraphs,and (3) GMM-based pseudo-label scoring to capture semantic contributions. Thiswork advances graph SSL by offering a computationally efficient,collapse-resistant paradigm that bridges spatial and semantic graph featuresfor downstream tasks. The code for our paper can be found athttps://github.com/Deceptrax123/JPEB-GSSL</description>
      <author>example@mail.com (Srinitish Srinivasan, Omkumar CU)</author>
      <guid isPermaLink="false">2502.01684v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Prostate-Specific Foundation Models for Enhanced Detection of Clinically Significant Cancer</title>
      <link>http://arxiv.org/abs/2502.00366v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为ProViCNet的新型前列腺癌诊断工具，该工具基于MRI和TRUS影像建立，并通过对比学习进行训练。研究结果表明，该模型在多种验证队列中表现出色，超过了放射科医生的表现。&lt;h4&gt;背景&lt;/h4&gt;当前利用MRI对前列腺癌做出精确诊断仍然具有挑战性，即使采用高级成像技术如MRI，放射学家的特异性和观察者间的一致性仍较低，可能导致临床重要癌症识别延迟或不准确。这导致了不必要的活检和漏诊的风险增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于对比学习的新模型——前列腺视野对比网络（ProViCNet），用于提高前列腺癌诊断的准确性，并减少不必要的活检。&lt;h4&gt;方法&lt;/h4&gt;使用4,401名患者的多中心数据对ProViCNet进行了训练和验证。该模型在放射学图像上依赖于由经证实的活检结果指导的斑块级对比学习，特别适用于MRI和TRUS影像。&lt;h4&gt;主要发现&lt;/h4&gt;ProViCNet在多种内部和外部验证队列中的表现一致，AUC值从0.875到0.966不等。与放射科医生相比，在mpMRI上的性能明显更优（AUC为0.907 vs 0.805, p&lt;0.001），而在TRUS上的表现为0.670至0.740。此外，将ProViCNet与PSA结合使用后，可以同时保持高敏感性和大幅度提高特异性（从15%增加到38%，p&lt;0.001），显著减少不必要的活检。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，ProViCNet有潜力通过优化诊断途径来增强前列腺癌的准确诊断，并减少不必要的活检。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prostate cancer diagnosis remains challenging. Even when using MRI,radiologists exhibit low specificity and significant inter-observervariability, leading to potential delays or inaccuracies in identifyingclinically significant cancers. This leads to numerous unnecessary biopsies andrisks of missing clinically significant cancers. Here we present prostatevision contrastive network (ProViCNet), prostate organ-specific visionfoundation models for Magnetic Resonance Imaging (MRI) and Trans-RectalUltrasound imaging (TRUS) for comprehensive cancer detection. ProViCNet wastrained and validated using 4,401 patients across six institutions, as aprostate cancer detection model on radiology images relying on patch-levelcontrastive learning guided by biopsy confirmed radiologist annotations.ProViCNet demonstrated consistent performance across multiple internal andexternal validation cohorts with area under the receiver operating curve valuesranging from 0.875 to 0.966, significantly outperforming radiologists in thereader study (0.907 versus 0.805, p&lt;0.001) for mpMRI, while achieving 0.670 to0.740 for TRUS. We also integrated ProViCNet with standard PSA to develop avirtual screening test, and we showed that we can maintain the high sensitivityfor detecting clinically significant cancers while more than doublingspecificity from 15% to 38% (p&lt;0.001), thereby substantially reducingunnecessary biopsies. These findings highlight that ProViCNet's potential forenhancing prostate cancer diagnosis accuracy and reduce unnecessary biopsies,thereby optimizing diagnostic pathways.</description>
      <author>example@mail.com (Jeong Hoon Lee, Cynthia Xinran Li, Hassan Jahanandish, Indrani Bhattacharya, Sulaiman Vesal, Lichun Zhang, Shengtian Sang, Moon Hyung Choi, Simon John Christoph Soerensen, Steve Ran Zhou, Elijah Richard Sommer, Richard Fan, Pejman Ghanouni, Yuze Song, Tyler M. Seibert, Geoffrey A. Sonn, Mirabela Rusu)</author>
      <guid isPermaLink="false">2502.00366v2</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.00681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主要内容总结&lt;/h4&gt;近年来，图表示学习取得了迅速进展，连续嵌入成为主流。然而，这些方法面临参数效率、可解释性和鲁棒性的问题。因此，量化图表示（QGR）作为一种新兴的方法受到越来越多的关注。&lt;h4&gt;背景介绍&lt;/h4&gt;概述了通用量化方法及其优点，并介绍了连续嵌入方法在处理图结构中的局限性。&lt;h4&gt;研究目的&lt;/h4&gt;旨在通过全面调查促进QGR的快速未来繁荣和发展，提供QGR领域的综合视图并激发未来的研究方向。&lt;h4&gt;研究方法&lt;/h4&gt;从量化策略、训练目标、独特设计、知识图量化及应用等角度深入探讨了当前QGR研究。同时探索代码依赖学习和与大规模语言模型（LLMs）集成的策略。&lt;h4&gt;主要发现&lt;/h4&gt;QGR具备无缝融合图结构和大规模语言模型的能力，因其表示形式类似于自然语言。&lt;h4&gt;结论与未来方向&lt;/h4&gt;对现有工作进行了讨论，并指出了未来的可能发展方向，如提高量化效果、增强鲁棒性等。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，在图表示学习领域取得了快速进步，连续嵌入方法已成为主导范式。然而，这种方法在参数效率、可解释性和鲁棒性方面遇到了问题。因此，最近人们对量化图表示（QGR）学习产生了越来越多的兴趣，它用离散代码而不是传统的连续嵌入来表示图形结构。鉴于其与自然语言相似的表示形式，QGR还具备无缝融合大规模语言模型的能力。由于这一新兴范式仍处于起步阶段但充满潜力，我们进行了这项全面调查以促进其未来迅速繁荣发展。我们首先介绍了通用量化方法及其优点。此外，从量化策略、训练目标、独特设计、知识图量化以及应用等角度深入展示了当前的QGR研究。进一步探讨了代码依赖学习和与大规模语言模型集成的方法。最后，我们进行了讨论并指出了未来的方向，旨在提供QGR领域的综合视图，并激发未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed rapid advances in graph representation learning,with the continuous embedding approach emerging as the dominant paradigm.However, such methods encounter issues regarding parameter efficiency,interpretability, and robustness. Thus, Quantized Graph Representation (QGR)learning has recently gained increasing interest, which represents the graphstructure with discrete codes instead of conventional continuous embeddings.Given its analogous representation form to natural language, QGR also possessesthe capability to seamlessly integrate graph structures with large languagemodels (LLMs). As this emerging paradigm is still in its infancy yet holdssignificant promise, we undertake this thorough survey to promote its rapidfuture prosperity. We first present the background of the general quantizationmethods and their merits. Moreover, we provide an in-depth demonstration ofcurrent QGR studies from the perspectives of quantized strategies, trainingobjectives, distinctive designs, knowledge graph quantization, andapplications. We further explore the strategies for code dependence learningand integration with LLMs. At last, we give discussions and conclude futuredirections, aiming to provide a comprehensive picture of QGR and inspire futureresearch.</description>
      <author>example@mail.com (Qika Lin, Zhen Peng, Kaize Shi, Kai He, Yiming Xu, Erik Cambria, Mengling Feng)</author>
      <guid isPermaLink="false">2502.00681v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation</title>
      <link>http://arxiv.org/abs/2502.01113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了GFM-RAG模型，这是一种基于图的增强检索生成模型，旨在改进传统RAG在复杂知识关系捕捉方面的不足。&lt;h4&gt;背景&lt;/h4&gt;Retrieval-augmented generation (RAG) 方法已经证明可以有效地将知识集成到大型语言模型中，但是它无法有效处理来自多个来源的知识整合所需的复杂推理问题。为了克服这个问题，Graph-enhanced retrieval augmented generation (GraphRAG) 被引入来构建图结构以明确地建模这些关系。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的基于图的增强检索生成方法GFM-RAG，以解决现有模型在处理不完整和有噪声的数据时存在的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新颖的图形神经网络，该网络可以对图形结构进行推理并捕捉复杂的查询-知识关系。GFM经过大规模数据集上的两阶段训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在三个多跳问答数据集和七个领域特定的RAG数据集中，GFM-RAG达到了最先进的性能，并且在效率和神经扩展规律的一致性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;GFM-RAG展示了良好的泛化能力，无需对未见过的数据集进行微调即可实现检索增强生成任务中的优秀表现。它的潜力在于进一步改进的前景光明。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的图形基础模型GFM-RAG的设计和训练过程及其在多种数据集上的性能评估结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval-augmented generation (RAG) has proven effective in integratingknowledge into large language models (LLMs). However, conventional RAGsstruggle to capture complex relationships between pieces of knowledge, limitingtheir performance in intricate reasoning that requires integrating knowledgefrom multiple sources. Recently, graph-enhanced retrieval augmented generation(GraphRAG) builds graph structure to explicitly model these relationships,enabling more effective and efficient retrievers. Nevertheless, its performanceis still hindered by the noise and incompleteness within the graph structure.To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) forretrieval augmented generation. GFM-RAG is powered by an innovative graphneural network that reasons over graph structure to capture complexquery-knowledge relationships. The GFM with 8M parameters undergoes a two-stagetraining process on large-scale datasets, comprising 60 knowledge graphs withover 14M triples and 700k documents. This results in impressive performance andgeneralizability for GFM-RAG, making it the first graph foundation modelapplicable to unseen datasets for retrieval without any fine-tuning required.Extensive experiments on three multi-hop QA datasets and seven domain-specificRAG datasets demonstrate that GFM-RAG achieves state-of-the-art performancewhile maintaining efficiency and alignment with neural scaling laws,highlighting its potential for further improvement.</description>
      <author>example@mail.com (Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, Shirui Pan)</author>
      <guid isPermaLink="false">2502.01113v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale</title>
      <link>http://arxiv.org/abs/2502.01681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了DeepGate4，一种专门针对大规模电路设计的可扩展且高效的图变换器。&lt;h4&gt;背景介绍&lt;/h4&gt;电路表示学习在电子设计自动化中至关重要，支持诸如测试性分析、逻辑推理、功耗估计和SAT求解等关键任务。然而，现有的模型由于如图神经网络中的过度压缩以及基于变压器模型的二次复杂度等问题，在扩展到大规模电路时面临挑战。&lt;h4&gt;研究目的&lt;/h4&gt;为了解决这些问题，我们提出了一种新的方法来改进现有模型在处理大型电路设计方面的性能和效率。&lt;h4&gt;主要方法&lt;/h4&gt;[{'创新1': '为电路图定制的更新策略，该策略将内存复杂度降低到次线性，并且可以适应任何图变换器'}, {'创新2': '一种基于GAT（图形注意力网络）的稀疏变压器，具有AIGs（与非门图）的全局和局部结构编码'}, {'创新3': '一个用于推理加速的CUDA内核，充分利用AIGs的独特稀疏模式'}]&lt;h4&gt;实验结果&lt;/h4&gt;[{'性能提升': '在ITC99和EPFL基准测试中，DeepGate4相较于最佳现有模型分别提升了15.5%和31.1%'}, {'效率改进': 'Fused-DeepGate4变种将运行时间减少了35.1%，内存使用量减少46.8%'}]&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，DeepGate4具有处理复杂EDA任务的能力，并提供了卓越的可扩展性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Circuit representation learning has become crucial in electronic design automation, supporting critical tasks such as testability analysis, logic reasoning, power estimation, and SAT solving. However, existing models face significant challenges when scaling to large circuits due to issues like over-squashing in graph neural networks and the quadratic complexity of transformer-based models. To address these problems, we propose DeepGate4, a scalable and efficient graph transformer specifically designed for large-scale circuit design. It includes several key innovations: (1) an update strategy tailored for circuit graphs with sub-linear memory complexity adaptable to any graph transformer; (2) a GAT-based sparse transformer with global and local structural encodings for AIGs; and (3) an inference acceleration CUDA kernel that fully exploits the unique sparsity patterns of AIGs. Our experiments on ITC99 and EPFL benchmarks show DeepGate4 surpasses state-of-the-art methods by 15.5% and 31.1%, respectively, while the Fused-DeepGate4 variant reduces runtime by 35.1% and memory usage by 46.8%. These results highlight the potential of DeepGate4 to handle complex EDA tasks with superior scalability and efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit representation learning has become pivotal in electronic designautomation, enabling critical tasks such as testability analysis, logicreasoning, power estimation, and SAT solving. However, existing models facesignificant challenges in scaling to large circuits due to limitations likeover-squashing in graph neural networks and the quadratic complexity oftransformer-based models. To address these issues, we introduce DeepGate4, ascalable and efficient graph transformer specifically designed for large-scalecircuits. DeepGate4 incorporates several key innovations: (1) an updatestrategy tailored for circuit graphs, which reduce memory complexity tosub-linear and is adaptable to any graph transformer; (2) a GAT-based sparsetransformer with global and local structural encodings for AIGs; and (3) aninference acceleration CUDA kernel that fully exploit the unique sparsitypatterns of AIGs. Our extensive experiments on the ITC99 and EPFL benchmarksshow that DeepGate4 significantly surpasses state-of-the-art methods, achieving15.5% and 31.1% performance improvements over the next-best models.Furthermore, the Fused-DeepGate4 variant reduces runtime by 35.1% and memoryusage by 46.8%, making it highly efficient for large-scale circuit analysis.These results demonstrate the potential of DeepGate4 to handle complex EDAtasks while offering superior scalability and efficiency.</description>
      <author>example@mail.com (Ziyang Zheng, Shan Huang, Jianyuan Zhong, Zhengyuan Shi, Guohao Dai, Ningyi Xu, Qiang Xu)</author>
      <guid isPermaLink="false">2502.01681v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of static and dynamic batching algorithms for graph neural networks</title>
      <link>http://arxiv.org/abs/2502.00944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNN）在训练过程中采用不同的批处理算法对模型性能和训练时间的影响，通过Jraph库构建的实验揭示了静态与动态批处理方法在不同数据集上的表现差异。&lt;h4&gt;背景&lt;/h4&gt;图神经网络已经在材料科学、化学和社会科学等多个领域展示了其优越的表现。然而，在实际应用中，由于参数量巨大，GNN模型通常会采用批量处理的方式来优化训练过程中的内存和计算资源使用效率。&lt;h4&gt;目的&lt;/h4&gt;评估静态与动态批处理算法对于图数据集在训练时间以及模型性能上的影响，并探索最适合给定任务的最优方法。&lt;h4&gt;方法&lt;/h4&gt;利用基于JAX开发的Jraph库，针对QM9小分子数据库及AFLOW材料数据库这两大数据集进行了实验对比研究，测试了两种不同的批量处理策略——静态批处理和动态批处理——的效果差异。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在特定的数据、模型大小、批次数量以及训练步数下，改变批处理算法能够节省显著的训练时间；然而没有一种策略能在所有情况下均优于另一种。此外，研究还指出两种批处理方法对模型的学习能力影响不大。&lt;h4&gt;结论&lt;/h4&gt;对于图神经网络而言，选择合适的批量处理策略可以提升效率和性能表现，但最优方案需视具体应用场景而定。&lt;h4&gt;翻译&lt;/h4&gt;Graph神经网络(GNN)已经在多个领域展示了其潜力，包括材料科学、化学和社会科学。GNN模型通常含有数百万个参数，并且像其他神经网络(NN)一样，在训练数据集中仅以图的子集形式分批次更新模型参数。批量算法对训练时间和模型性能的影响已经被广泛研究应用于NN模型中，但尚未深入研究于GNN之中。我们分析了两种用于基于图的模型的不同批量算法：静态和动态批量处理。利用在JAX上构建的Jraph库进行实验，并针对两个数据集进行了比较研究：QM9小分子数据库及AFLOW材料数据库。我们的实验证明，改变批处理算法可以节省显著的训练时间，但最快的方法依赖于数据、模型、批次大小以及运行的训练步数；此外，两种方法对模型的学习能力没有显示出显著的区别。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNN) have shown promising results for several domainssuch as materials science, chemistry, and the social sciences. GNN models oftencontain millions of parameters, and like other neural network (NN) models, areoften fed only a fraction of the graphs that make up the training dataset inbatches to update model parameters. The effect of batching algorithms ontraining time and model performance has been thoroughly explored for NNs butnot yet for GNNs. We analyze two different batching algorithms for graph basedmodels, namely static and dynamic batching. We use the Jraph library built onJAX to perform our experiments, where we compare the two batching methods fortwo datasets, the QM9 dataset of small molecules and the AFLOW materialsdatabase. Our experiments show that significant training time savings can befound from changing the batching algorithm, but the fastest algorithm dependson the data, model, batch size and number of training steps run. Experimentsshow no significant difference in model learning between the algorithms.</description>
      <author>example@mail.com (Daniel Speckhard, Tim Bechtel, Sebastian Kehl, Jonathan Godwin, Claudia Draxl)</author>
      <guid isPermaLink="false">2502.00944v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis</title>
      <link>http://arxiv.org/abs/2502.00545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于傅里叶变换的增强重建网络（FARNet），旨在解决故障诊断中未见工作条件分布偏移的问题。通过频率域的数据增强策略，该方法能够提高模型在未知环境下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有的通用故障诊断研究主要关注于学习领域不变表示以应对已知和未知工作条件之间的分布变化问题。然而，随着越来越多的未知领域的出现，领域不变特征可能包含实例层面的相关性错误，从而影响现有模型的泛化性能。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些限制，提出了傅里叶增强重建网络（FARNet），旨在通过频率域的数据增强策略来构建更稳健的通用故障诊断模型。&lt;h4&gt;方法&lt;/h4&gt;该方法利用傅里叶变换相位成分和幅度成分分别保存信号的不同语义信息。FARNet由一个幅值谱子网和一个相位谱子网组成，这些网络能够逐层减少源域与目标域之间的差异。此外，还引入了一个频率空间交互模块（FSIM）来处理全局信息及局部特征空间，以促进两个子网间的表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的流形三重损失函数，相比传统的三重损失能够更精细地优化模型的决策边界。实验结果显示，在CWRU和SJTU数据集上FARNet与当前跨域方法相比具有优越的表现能力。&lt;h4&gt;结论&lt;/h4&gt;通过广泛实验证明，FARNet在处理故障诊断中的领域偏移问题时有效且优于现有的技术方案。&lt;h4&gt;翻译&lt;/h4&gt;最近的通用性故障诊断研究有效地解决了未知工作条件分布变化的问题。大部分的研究主要集中在学习领域不变表示上，采用特征层面的方法。然而，随着越来越多未见领域的出现，领域不变特性可能会包含实例级别的相关错误，这会影响先前模型的泛化能力。为了解决这些限制，我们提出了一种基于傅里叶增强重建网络（FARNet）。该方法受到观察到傅里叶相位成分和幅度组件分别保留信号不同语义信息的启发，并且可以用于领域增强技术中。该网络由一个幅值谱子网和一个相位谱子网组成，它们依次减少源域与目标域之间的差异。为了构建更稳健的泛化模型，我们采用了一种多源领域的频率域数据增强策略。具体而言，引入了频域-空间交互模块（FSIM）来处理全局信息及局部特征空间问题，促进两个子网间的表示学习。为了细化我们的模型输出与传统三重损失相比的决策边界，提出了一种流形三重损失以促进泛化能力提升。在CWRU和SJTU数据集上进行广泛的实验后，FARNet表现出有效性能，并且在基准测试中优于当前跨域方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent generalizable fault diagnosis researches have effectively tackled thedistributional shift between unseen working conditions. Most of them mainlyfocus on learning domain-invariant representation through feature-levelmethods. However, the increasing numbers of unseen domains may lead todomain-invariant features contain instance-level spurious correlations, whichimpact the previous models' generalizable ability. To address the limitations,we propose the Fourier-based Augmentation Reconstruction Network, namelyFARNet.The methods are motivated by the observation that the Fourier phasecomponent and amplitude component preserve different semantic information ofthe signals, which can be employed in domain augmentation techniques. Thenetwork comprises an amplitude spectrum sub-network and a phase spectrumsub-network, sequentially reducing the discrepancy between the source andtarget domains. To construct a more robust generalized model, we employ amulti-source domain data augmentation strategy in the frequency domain.Specifically, a Frequency-Spatial Interaction Module (FSIM) is introduced tohandle global information and local spatial features, promoting representationlearning between the two sub-networks. To refine the decision boundary of ourmodel output compared to conventional triplet loss, we propose a manifoldtriplet loss to contribute to generalization. Through extensive experiments onthe CWRU and SJTU datasets, FARNet demonstrates effective performance andachieves superior results compared to current cross-domain approaches on thebenchmarks.</description>
      <author>example@mail.com (Xiaotong Tu, Chenyu Ma, Qingyao Wu, Yinhao Liu, Hongyang Zhang)</author>
      <guid isPermaLink="false">2502.00545v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Identifying Steady-State Behavior in Complex Networks</title>
      <link>http://arxiv.org/abs/2502.01693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种基于图神经网络的框架，用于识别线性动力学系统在复杂网络上的稳态行为，并通过分析推导揭示了模型的可解释性。&lt;h4&gt;背景&lt;/h4&gt;信息传播在网络中可以定义为扩散、弱局域化和强局域化的状态。线性动力学系统的机器学习建模是一个重要的研究领域，特别是在理解网络传播机制时。&lt;h4&gt;目的&lt;/h4&gt;开发一种图神经网络框架来识别复杂系统中的线性动力学系统的稳态行为，并探究模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于图神经网络的方法，利用该方法分析和预测线性动力学系统的不同状态，同时提供了一个前向传播和反向传播的解析推导过程。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型能够以高精度学习线性动力学系统在不同状态下（扩散、弱局域化和强局域化）的行为，并且通过分析证明了模型的可解释性和有效性。&lt;h4&gt;结论&lt;/h4&gt;研究成功地开发了一个框架，该框架可以有效地识别复杂网络中线性动力学系统的稳态行为。同时，为理解图神经网络在这一问题中的作用提供了理论依据。&lt;h4&gt;翻译&lt;/h4&gt;在复杂的系统中，信息传播可以被定义为扩散或局部化、弱局域化和强局域化的状态。机器学习模型能否学习到线性动力学系统在网络上的行为？在这项工作中，我们开发了一个图神经网络框架来识别线性动力学系统的稳态行为。我们揭示了我们的模型能够以高精度学习不同的状态，并通过提供前向传播和反向传播的分析推导来理解模型的可解释性。最后，我们使用实际世界中的图形对模型进行验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In complex systems, information propagation can be defined as diffused ordelocalized, weakly localized, and strongly localized. Can a machine learningmodel learn the behavior of a linear dynamical system on networks? In thiswork, we develop a graph neural network framework for identifying thesteady-state behavior of the linear dynamical system. We reveal that our modellearns the different states with high accuracy. To understand theexplainability of our model, we provide an analytical derivation for theforward and backward propagation of our framework. Finally, we use thereal-world graphs in our model for validation.</description>
      <author>example@mail.com (Priodyuti Pradhan, Amit Reza)</author>
      <guid isPermaLink="false">2502.01693v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Generic Multimodal Spatially Graph Network for Spatially Embedded Network Representation Learning</title>
      <link>http://arxiv.org/abs/2502.00530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一个通用多模态空间图卷积网络（GMu-SGCN），用于有效表示空间嵌入网络。该模型能够通过节点和边的多模态特征学习节点连接模式。&lt;h4&gt;背景&lt;/h4&gt;空间嵌入网络代表了一种特殊的复杂图，其拓扑结构受到嵌入的空间环境的影响。这种网络的表现形式受制于节点和边的物理位置属性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模型来准确表示具有地理限制的复杂图形的数据结构及其特征。&lt;h4&gt;方法&lt;/h4&gt;提出并实现了一个名为GMu-SGCN的网络，该网络能够利用多模态信息（包括位置、方向等）进行更高效的图卷积操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相比于仅考虑节点位置特性的GraphSAGE模型，在电力网环境下使用本研究提出的GMu-SGCN可以提高37.1%的边存在预测准确率。这证明了在空间网络表示中考虑多维空间特征的重要性。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种新的方法来处理复杂的空间嵌入网络，这种方法能够更好地捕捉和利用空间信息，从而提升相关任务的效果。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了用于有效表示空间嵌入网络的通用多模态空间图卷积网络（GMu-SGCN）。此模型具备通过节点及边的多模态特征学习出节点连接模式的能力。为了评估该模型的有效性，使用了河流网和电力网数据集作为实验环境。河流网络代表自然发展的空间嵌入网络，而电力网络则是人为构建的。两种类型的空间网络均受到物理地理环境以及自然不确定性的严格限制。综合分析显示，在电力网络测试环境中，本研究提出的GMu-SGCN相较于仅考虑节点位置特征的GraphSAGE模型能将边存在预测任务的准确度提升37.1%，这表明对于空间嵌入网络表示而言，考虑多维度的空间信息具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatially embedded networks (SENs) represent a special type of complex graph,whose topologies are constrained by the networks' embedded spatialenvironments. The graph representation of such networks is thereby influencedby the embedded spatial features of both nodes and edges. Accurate networkrepresentation of the graph structure and graph features is a fundamental taskfor various graph-related tasks. In this study, a Generic Multimodal SpatiallyGraph Convolutional Network (GMu-SGCN) is developed for efficientrepresentation of spatially embedded networks. The developed GMu-SGCN model hasthe ability to learn the node connection pattern via multimodal node and edgefeatures. In order to evaluate the developed model, a river network dataset anda power network dataset have been used as test beds. The river networkrepresents the naturally developed SENs, whereas the power network represents aman-made network. Both types of networks are heavily constrained by the spatialenvironments and uncertainties from nature. Comprehensive evaluation analysisshows the developed GMu-SGCN can improve accuracy of the edge existenceprediction task by 37.1\% compared to a GraphSAGE model which only considersthe node's position feature in a power network test bed. Our model demonstratesthe importance of considering the multidimensional spatial feature forspatially embedded network representation.</description>
      <author>example@mail.com (Xudong Fan, Jürgen Hackl)</author>
      <guid isPermaLink="false">2502.00530v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Predicting concentration levels of air pollutants by transfer learning and recurrent neural network</title>
      <link>http://arxiv.org/abs/2502.01654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Forecasting, environment monitoring, transfer learning, recurrent  neural network, airborne particle matter&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用长短期记忆（LSTM）循环神经网络预测澳门未来空气污染物的浓度，并通过转移学习和预训练神经网络辅助数据量较少的空气质量监测站建立高精度预测模型。&lt;h4&gt;背景&lt;/h4&gt;空气污染对人类健康构成重大威胁，人们对空气质量预报的关注日益增加。准确的空气质量预报可以帮助人们规划户外活动并保护人体健康。&lt;h4&gt;目的&lt;/h4&gt;利用LSTM循环神经网络基于气象数据和污染物浓度数据进行空气质量预报，并解决部分监测站数据量较少的问题。&lt;h4&gt;方法&lt;/h4&gt;使用了澳门12年以上的历史数据，包括多个空气污染指数（APS）的每日测量值及其他经典气象数值。通过五个站点的数据建立预测知识系统，其中四个为空气质量监测站，另一个是自动气象站。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，经过转移学习初始化的LSTM RNN比随机初始化的循环神经网络具有更高的预测精度和更短的训练时间。&lt;h4&gt;结论&lt;/h4&gt;利用转移学习方法初始化的LSTM模型在空气污染物浓度预测中表现出了较好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air pollution (AP) poses a great threat to human health, and people arepaying more attention than ever to its prediction. Accurate prediction of APhelps people to plan for their outdoor activities and aids protecting humanhealth. In this paper, long-short term memory (LSTM) recurrent neural networks(RNNs) have been used to predict the future concentration of air pollutants(APS) in Macau. Additionally, meteorological data and data on the concentrationof APS have been utilized. Moreover, in Macau, some air quality monitoringstations (AQMSs) have less observed data in quantity, and, at the same time,some AQMSs recorded less observed data of certain types of APS. Therefore, thetransfer learning and pre-trained neural networks have been employed to assistAQMSs with less observed data to build a neural network with high predictionaccuracy. The experimental sample covers a period longer than 12-year andincludes daily measurements from several APS as well as other more classicalmeteorological values. Records from five stations, four out of them are AQMSsand the remaining one is an automatic weather station, have been prepared fromthe aforesaid period and eventually underwent to computational intelligencetechniques to build and extract a prediction knowledge-based system. As shownby experimentation, LSTM RNNs initialized with transfer learning methods havehigher prediction accuracy; it incurred shorter training time than randomlyinitialized recurrent neural networks.</description>
      <author>example@mail.com (Iat Hang Fong, Tengyue Li, Simon Fong, Raymond K. Wong, Antonio J. Tallón-Ballesteros)</author>
      <guid isPermaLink="false">2502.01654v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>BrainOOD: Out-of-distribution Generalizable Brain Network Analysis</title>
      <link>http://arxiv.org/abs/2502.01688v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了BrainOOD框架，该框架通过改进图信息瓶颈（GIB）目标来解决多站点脑网络数据分布变化问题，并提高对关键脑区域识别的可解释性。&lt;h4&gt;背景&lt;/h4&gt;在神经科学中，辨识与神经系统疾病相关的独特模式对于早期诊断和有效干预至关重要。图神经网络（GNNs）在分析脑网络方面展现出巨大潜力，但面临两大挑战：多站点脑网络数据分布变化导致较差的“出界”（OOD）泛化能力以及识别关键脑区域时缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;提出BrainOOD框架以增强GNNs针对脑网络的数据泛化能力和可解释性。&lt;h4&gt;方法&lt;/h4&gt;BrainOOD框架包含一个特征选择器和结构提取器，通过引入改进的图信息瓶颈（GIB）目标来恢复因果子图，并在不同脑网络之间对齐结构选择以及过滤噪音特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，BrainOOD相较于16种现有方法，在提高OOD泛化性能方面有显著提升，最高可达8.5%，并且案例研究证实了提取模式的科学有效性，这些模式与已知神经科学研究文献中的结果相吻合。此外还提出了首个ODD脑网络基准。&lt;h4&gt;结论&lt;/h4&gt;BrainOOD提供了一种改进的方法来应对多站点脑网络数据分布变化问题，并提高了对关键脑区域识别的可解释性，这对于诊断神经系统疾病具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;在神经科学领域，区分与如阿尔茨海默病和自闭症等神经系统疾病相关的独特模式对于早期诊断及有效干预至关重要。尽管图神经网络（GNNs）显示出分析脑网络的巨大潜力，但在其应用中存在两大挑战：一是多站点脑网络数据分布变化导致较差的出界泛化能力；二是识别与神经系统疾病关键脑区域时可解释性不足。现有的图OOD方法虽然在其他领域有效但无法解决脑网络的独特特性。为了填补这一空白，我们提出了BrainOOD框架，这是一个专门针对脑网络设计的新颖框架，旨在增强GNNs对OOD的泛化能力和提高可解释性。该框架包括特征选择器和结构提取器，它利用了各种辅助损失函数，其中包括改进后的图信息瓶颈（Graph Information Bottleneck, GIB）目标以恢复因果子图。通过在不同脑网络之间对齐结构选择以及过滤噪音特征，BrainOOD提供了关键脑区域的可靠解释。我们的方法优于16种现有方法，在提升对OOD样本的一般化能力方面提高了8.5%。案例研究证明了提取模式的科学有效性，并且这些模式与神经科学研究文献中的发现相吻合。我们还提出了首个ODD脑网络基准，为该领域的未来研究提供了一个坚实的基础。我们的代码可从https://github.com/AngusMonroe/BrainOOD获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In neuroscience, identifying distinct patterns linked to neurologicaldisorders, such as Alzheimer's and Autism, is critical for early diagnosis andeffective intervention. Graph Neural Networks (GNNs) have shown promising inanalyzing brain networks, but there are two major challenges in using GNNs: (1)distribution shifts in multi-site brain network data, leading to poorOut-of-Distribution (OOD) generalization, and (2) limited interpretability inidentifying key brain regions critical to neurological disorders. Existinggraph OOD methods, while effective in other domains, struggle with the uniquecharacteristics of brain networks. To bridge these gaps, we introduce BrainOOD,a novel framework tailored for brain networks that enhances GNNs' OODgeneralization and interpretability. BrainOOD framework consists of a featureselector and a structure extractor, which incorporates various auxiliary lossesincluding an improved Graph Information Bottleneck (GIB) objective to recovercausal subgraphs. By aligning structure selection across brain networks andfiltering noisy features, BrainOOD offers reliable interpretations of criticalbrain regions. Our approach outperforms 16 existing methods and improvesgeneralization to OOD subjects by up to 8.5%. Case studies highlight thescientific validity of the patterns extracted, which aligns with the findingsin known neuroscience literature. We also propose the first OOD brain networkbenchmark, which provides a foundation for future research in this field. Ourcode is available at https://github.com/AngusMonroe/BrainOOD.</description>
      <author>example@mail.com (Jiaxing Xu, Yongqiang Chen, Xia Dong, Mengcheng Lan, Tiancheng Huang, Qingtian Bian, James Cheng, Yiping Ke)</author>
      <guid isPermaLink="false">2502.01688v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Spectro-Riemannian Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2502.00401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Spectro-Riemannian图神经网络（CUSP），一种新的图形表示学习框架，该框架统一了几何形状和频谱的见解，以优化节点嵌入。&lt;h4&gt;背景&lt;/h4&gt;非欧几里得几何学特别适用于表示具有规模自由、层次化和循环模式等复杂特性的图形结构。同时，光谱滤波在处理图上的信号变化方面表现出色，无论是在同质性还是异质性设置下都有效。&lt;h4&gt;目的&lt;/h4&gt;通过结合光谱过滤和曲率信号来增强学习的表示能力。&lt;h4&gt;方法&lt;/h4&gt;提出了CUSP模型，该模型使用Ollivier-Ricci曲率扩展的传统图拉普拉斯算子（Cusp Laplacian）；多种黎曼图滤波器（Cusp Filtering），用于从特征谱的不同频段获取线索；以及结合了基于曲率的位置编码的分层注意力机制（Cusp Pooling）。&lt;h4&gt;主要发现&lt;/h4&gt;实证评估显示，在八个同质性和异质性数据集上，CUSP在节点分类和链接预测任务中表现出显著优于最先进的模型的表现。&lt;h4&gt;结论&lt;/h4&gt;通过统一几何和频谱的见解，可以解锁图形表示学习的新潜力。&lt;h4&gt;翻译&lt;/h4&gt;将光谱信号与曲率信号结合是否能开启图表示学习中的新潜力？非欧几里得几何，特别是黎曼流形（如负曲率双曲空间和正曲率球面），提供了强大的归纳偏差来嵌入复杂图形结构。同时，频谱滤波在处理图形上信号的变化方面表现出色，在同质性和异质性设置下都有效。结合两者可以显著增强学习的表示能力。为此，我们提出了Spectro-Riemannian图神经网络（CUSP）——第一个统一几何（曲率）和频谱见解的图表示学习范式。CUSP是一个混合曲率的光谱GNN，它学习在常数曲率流形的乘积空间中优化节点嵌入。具体而言，CUSP引入了三个新颖组件：Cusp Laplacian，这是基于Ollivier-Ricci曲率的传统图拉普拉斯算子扩展，在捕捉曲率信号方面更胜一筹；Cusp Filtering，使用多个黎曼图滤波器从特征谱的不同频段中获取线索；以及Cusp Pooling，这是一种结合了基于曲率的位置编码的分层注意力机制，用于评估具有不同曲率的子结构的重要性。实证研究表明，在八个同质性和异质性数据集上，CUSP在节点分类和链接预测任务中表现出显著优于最先进的模型的表现，性能提升了最多5.3%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Can integrating spectral and curvature signals unlock new potential in graphrepresentation learning? Non-Euclidean geometries, particularly Riemannianmanifolds such as hyperbolic (negative curvature) and spherical (positivecurvature), offer powerful inductive biases for embedding complex graphstructures like scale-free, hierarchical, and cyclic patterns. Meanwhile,spectral filtering excels at processing signal variations across graphs, makingit effective in homophilic and heterophilic settings. Leveraging both cansignificantly enhance the learned representations. To this end, we proposeSpectro-Riemannian Graph Neural Networks (CUSP) - the first graphrepresentation learning paradigm that unifies both CUrvature (geometric) andSPectral insights. CUSP is a mixed-curvature spectral GNN that learns spectralfilters to optimize node embeddings in products of constant-curvature manifolds(hyperbolic, spherical, and Euclidean). Specifically, CUSP introduces threenovel components: (a) Cusp Laplacian, an extension of the traditional graphLaplacian based on Ollivier-Ricci curvature, designed to capture the curvaturesignals better; (b) Cusp Filtering, which employs multiple Riemannian graphfilters to obtain cues from various bands in the eigenspectrum; and (c) CuspPooling, a hierarchical attention mechanism combined with a curvature-basedpositional encoding to assess the relative importance of differently curvedsubstructures in our graph. Empirical evaluation across eight homophilic andheterophilic datasets demonstrates the superiority of CUSP in nodeclassification and link prediction tasks, with a gain of up to 5.3% overstate-of-the-art models.</description>
      <author>example@mail.com (Karish Grover, Haiyang Yu, Xiang Song, Qi Zhu, Han Xie, Vassilis N. Ioannidis, Christos Faloutsos)</author>
      <guid isPermaLink="false">2502.00401v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A generative foundation model for an all-in-one seismic processing framework</title>
      <link>http://arxiv.org/abs/2502.01111v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了用于地震数据处理的生成式地震基础模型(GSFM)，该模型基于生成扩散模型（GDM），旨在解决多任务地震处理挑战。&lt;h4&gt;背景&lt;/h4&gt;地震数据分析面临噪音污染、采集不完整和低频信息不足等问题，传统的处理方法难以应对这些变化的数据。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架GSFM来克服传统处理方法在多样性和适应性上的局限性。&lt;h4&gt;方法&lt;/h4&gt;GSFM利用合成数据进行预训练，并采用迭代微调策略以提高模型对实际地震数据的适用性。通过目标导向的扩散过程预测，该模型提高了计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;1. 合成数据分析显示，GSFM在所有任务上超过了具有类似架构的基准方法，在精细调整后仍保持了传统预训练策略相当的表现；2. 实际地震数据测试表明，迭代微调可以解决传统预训练和微调方案中的泛化限制问题，并显著提高了不同任务上的性能。&lt;h4&gt;结论&lt;/h4&gt;GSFM通过其固有的概率特性提供了有效的不确定性量化能力，为处理结果的可靠性提供有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的地震数据经常面临由于噪音污染、采集不完整和低频信息不足等问题导致的挑战。这些因素阻碍了地下成像和解释的准确性。传统方法严重依赖特定任务的设计来应对这些问题，并未能考虑到数据的变化性。为解决这一局限，研究团队提出了基于生成扩散模型（GDM）的统一框架GSFM，用于多任务地震处理挑战，包括去噪、反散射噪音抑制、插值以及低频外推。该模型通过合成数据预训练捕捉干净完整宽带地震数据特征，并采用迭代微调策略适应现场数据。通过目标导向的扩散过程预测，GSFM在不牺牲精度的情况下提高了计算效率。合成数据分析显示，GSFM超越了具有类似架构的基准方法，在所有任务上表现优异；实际地震数据测试结果表明，该模型显著增强了不同处理任务上的性能。此外，其固有的概率特性提供了有效的不确定性量化能力，为处理结果的可靠性提供有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Seismic data often face challenges in their utilization due to noisecontamination, incomplete acquisition, and limited low-frequency information,which hinder accurate subsurface imaging and interpretation. Traditionalprocessing methods rely heavily on task-specific designs to address thesechallenges and fail to account for the variability of data. To address theselimitations, we present a generative seismic foundation model (GSFM), a unifiedframework based on generative diffusion models (GDMs), designed to tacklemulti-task seismic processing challenges, including denoising, backscatterednoise attenuation, interpolation, and low-frequency extrapolation. GSFMleverages a pre-training stage on synthetic data to capture the features ofclean, complete, and broadband seismic data distributions and applies aniterative fine-tuning strategy to adapt the model to field data. By adopting atarget-oriented diffusion process prediction, GSFM improves computationalefficiency without compromising accuracy. Synthetic data tests demonstrate GSFMsurpasses benchmarks with equivalent architectures in all tasks and achievesperformance comparable to traditional pre-training strategies, even after theirfine-tuning. Also, field data tests suggest that our iterative fine-tuningapproach addresses the generalization limitations of conventional pre-trainingand fine-tuning paradigms, delivering significantly enhanced performance acrossdiverse tasks. Furthermore, GSFM's inherent probabilistic nature enableseffective uncertainty quantification, offering valuable insights into thereliability of processing results.</description>
      <author>example@mail.com (Shijun Cheng, Randy Harsuko, Tariq Alkhalifah)</author>
      <guid isPermaLink="false">2502.01111v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings</title>
      <link>http://arxiv.org/abs/2502.01108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two listed authors contributed equally to this research&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本论文介绍了Pulse-PPG，这是首个仅基于野外采集的原始PPG数据训练的开放源代码PPG基础模型。与现有PPG基础模型相比，Pulse-PPG具有更好的泛化能力，并在多个数据集和下游任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;光体积描记法（PPG）基础模型因其在生物信号监测中的广泛应用以及其在多种健康应用中的潜在泛化能力而受到关注。现有公开源代码的PPG基础模型通常是在临床数据上训练，而非开放源代码的模型限制了它们在实际环境下的适用性。&lt;h4&gt;目的&lt;/h4&gt;展示Pulse-PPG如何利用未经过滤的真实世界PPG数据训练来提高其适应性和泛化能力，并鼓励更多研究者使用野外数据开发更稳健的基础模型。&lt;h4&gt;方法&lt;/h4&gt;基于120名参与者为期100天的田野研究收集到的原始PPG数据，训练了Pulse-PPG。然后在多个数据集和下游任务中评估其性能，并将其与临床数据上预训练的状态最先进基础模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;Pulse-PPG展示了在实验室和现场环境中，针对临床及移动健康应用的泛化能力优于基于临床数据训练的基础模型。这表明接触真实世界的变化有助于学习更细腻的表现形式，从而使其更加适应各种任务。&lt;h4&gt;结论&lt;/h4&gt;野外预训练对许多任务来说表现优于临床数据预训练，强调了在多样化的、真实世界的数据库上进行培训的重要性。为了促进稳健基础模型利用田野数据的研究进展，计划开放Pulse-PPG的源代码，为研究者提供强大资源来开发更泛化能力的PPG基础模型。&lt;h4&gt;翻译&lt;/h4&gt;光体积描记法（PPG）基础模型因其在生物信号监测中的广泛应用以及其在多种健康应用中的潜在泛化能力而受到关注。在这篇论文中，我们介绍了Pulse-PPG，这是首个开放源代码且仅基于野外采集的原始PPG数据训练的基础模型，该研究收集自为期100天涉及120名参与者的田野调查项目。现有的PPG基础模型要么是开源但基于临床数据培训，或者是封闭源代码，限制了它们在实际环境下的适用性。我们通过多个数据集和下游任务评估Pulse-PPG的表现，并将其与目前基于临床数据训练的状态最先进基础模型进行比较。我们的结果显示：尽管是在未经整理的真实世界田野数据上进行预训练，但Pulse-PPG展示了优于其他基础模型在实验室及现场环境中针对临床以及移动健康应用的泛化能力。这表明接触真实世界的多样性有助于学习更细腻的表现形式，从而使其更加适应各种任务。此外，在许多任务中，基于野外数据的预训练表现超过了基于临床数据的预训练，进一步强调了使用多样化的、真实世界数据库进行培训的重要性。为了鼓励开发更具鲁棒性的基础模型利用田野数据的研究进展，我们计划公开Pulse-PPG源代码，为研究者提供一种强大的资源来开发更泛化能力的PPG基础模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photoplethysmography (PPG)-based foundation models are gaining traction dueto the widespread use of PPG in biosignal monitoring and their potential togeneralize across diverse health applications. In this paper, we introducePulse-PPG, the first open-source PPG foundation model trained exclusively onraw PPG data collected over a 100-day field study with 120 participants.Existing PPG foundation models are either open-source but trained on clinicaldata or closed-source, limiting their applicability in real-world settings. Weevaluate Pulse-PPG across multiple datasets and downstream tasks, comparing itsperformance against a state-of-the-art foundation model trained on clinicaldata. Our results demonstrate that Pulse-PPG, trained on uncurated field data,exhibits superior generalization across clinical and mobile health applicationsin both lab and field settings. This suggests that exposure to real-worldvariability enables the model to learn fine-grained representations, making itmore adaptable across tasks. Furthermore, pre-training on field datasurprisingly outperforms its pre-training on clinical data in many tasks,reinforcing the importance of training on real-world, diverse datasets. Toencourage further advancements in robust foundation models leveraging fielddata, we plan to release Pulse-PPG, providing researchers with a powerfulresource for developing more generalizable PPG-based models.</description>
      <author>example@mail.com (Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar)</author>
      <guid isPermaLink="false">2502.01108v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>AGNNCert: Defending Graph Neural Networks against Arbitrary Perturbations with Deterministic Certification</title>
      <link>http://arxiv.org/abs/2502.00765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Usenix Security 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文介绍了AGNNCert，这是一种针对图神经网络（GNNs）的新防御机制。&lt;h4&gt;背景&lt;/h4&gt;现有的GNNs在面对对抗性攻击时表现脆弱，包括边、节点和节点特征的扰动。尽管有了一些实证防御措施，但它们很快就被更高级的攻击破解了。认证防御虽然提供了保证的鲁棒性，但是存在局限：1) 几乎所有都限制了对手的能力仅限于一种类型的扰动；2) 都是为了特定的GNN任务设计的，其适用范围有限；3) 除了一个方法外，其他方法的鲁棒性保证都不是100%准确。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够防御任意类型图结构（边、节点和节点特征）扰动，并提供确定性鲁棒性保障的方法。此外，该方法应能适用于最常见的节点分类和图形分类任务。&lt;h4&gt;方法&lt;/h4&gt;提出AGNNCert作为第一种针对GNNs的认证防御机制，它能够抵御任意类型的攻击，并且适用于最常见的两种任务（节点分类和图分类）。AGNNCert还涵盖了现有的所有认证防御方法，视为其特殊案例。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集和两个实际世界的数据集上进行了广泛的评估，证明了AGNNCert的有效性。结果显示，该方法能够验证地抵御任意扰动，并且优于现有针对个别边或节点扰动的防御措施。&lt;h4&gt;结论&lt;/h4&gt;提出的AGNNCert代表了一种新的认证防御机制，它克服了当前认证防御中的局限性，为GNNs提供了全面的安全保障。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）在诸如节点和图形分类等涉及图的任务中达到了最先进的性能。然而，最近的研究表明，这些模型容易受到包括边、节点以及节点特征扰动在内的对抗攻击。尽管已有一些实证防御方法被提出以应对这些攻击，但它们很快就被适应性更强的攻击所破解。认证防御虽然提供了鲁棒性的保证，但也面临几个限制：1) 几乎所有都仅限于对手能力的一种类型的干扰；2) 都为特定的GNN任务设计，从而限制了其适用范围；3) 除了一个方法外，其他方法的鲁棒性保障都不是百分之百准确。为了克服这些局限性，我们开发了一种新的防御机制AGNNCert，这是第一个能够抵御任意（边、节点和节点特征）扰动，并提供确定性鲁棒性保证的方法，适用于最常见节点分类和图形分类任务。此外，AGNNCert还涵盖了现有的认证防御方法作为特殊情况。通过对多个基准数据集上的节点/图分类以及两个实际世界的数据集中进行广泛的评估验证了AGNNCert的有效性，证明其能够有效地抵御任意扰动。与最先进的个体边或节点干扰认证防御相比，AGNNCert显示出优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) achieve the state-of-the-art on graph-relevanttasks such as node and graph classification. However, recent works show GNNsare vulnerable to adversarial perturbations include the perturbation on edges,nodes, and node features, the three components forming a graph. Empiricaldefenses against such attacks are soon broken by adaptive ones. While certifieddefenses offer robustness guarantees, they face several limitations: 1) almostall restrict the adversary's capability to only one type of perturbation, whichis impractical; 2) all are designed for a particular GNN task, which limitstheir applicability; and 3) the robustness guarantees of all methods except oneare not 100% accurate.  We address all these limitations by developing AGNNCert, the first certifieddefense for GNNs against arbitrary (edge, node, and node feature) perturbationswith deterministic robustness guarantees, and applicable to the two most commonnode and graph classification tasks. AGNNCert also encompass existing certifieddefenses as special cases. Extensive evaluations on multiple benchmarknode/graph classification datasets and two real-world graph datasets, andmultiple GNNs validate the effectiveness of AGNNCert to provably defend againstarbitrary perturbations. AGNNCert also shows its superiority over thestate-of-the-art certified defenses against the individual edge perturbationand node perturbation.</description>
      <author>example@mail.com (Jiate Li, Binghui Wang)</author>
      <guid isPermaLink="false">2502.00765v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Adapting Foundation Models for Few-Shot Medical Image Segmentation: Actively and Sequentially</title>
      <link>http://arxiv.org/abs/2502.01000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于动态辅助数据集选择的主动和顺序域适应框架（ASAP），以解决在目标任务具有较大领域差异且注释样本较少的情况下的模型适配问题。&lt;h4&gt;背景&lt;/h4&gt;当前基础模型在计算机视觉，尤其是医学图像分割中取得了显著进展。然而，在处理领域差距大且标注样本少的任务时，确保可靠的和稳健的模型适应仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有少量样本域适应方法中的局限性，提出了一种新的主动和顺序域适应框架（ASAP），旨在通过动态选择辅助数据集来解决这一问题。&lt;h4&gt;方法&lt;/h4&gt;将少量样本域适应问题视为多臂赌博机问题，并推导出一种有效的奖励函数以优先考虑与目标任务对齐紧密的辅助数据集，通过单轮微调实现高效训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明了该方法在多种医学分割数据集上的优越表现，显著优于现有的最先进少量样本域适应方法，在MRI和CT数据集中分别实现了27.75%和7.52%的Dice分数提升。&lt;h4&gt;结论&lt;/h4&gt;ASAP框架通过动态选择适当的辅助数据集来提高模型在目标任务中的性能，特别是在领域差异较大的情况下。该研究为解决低资源医学图像分割任务提供了一个有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，在计算机视觉领域的基础模型取得了令人瞩目的成果，包括医学图像分割。对特定的低资源医学任务进行微调已成为一种标准做法。然而，在目标任务具有较大领域差距且很少有注释样本的情况下，确保可靠和稳健的模型适应仍然是一项挑战。以前的少量样本域适应（FSDA）方法试图通过利用辅助数据来弥合源域与目标域之间的分布差异。辅助数据的选择和调度通常是基于直觉的，这可能会轻易导致负面转移。在这项工作中，我们提出了一种主动且顺序领域适配（ASAP）框架，用于动态选择辅助数据集以进行FSDA。我们将FSDA视为一个多臂赌博机问题，并推导出一种有效的奖励函数来优先考虑与目标任务对齐紧密的辅助数据集，在单轮微调中实现这一目标。在各种医学分割数据集上的实证验证表明，我们的方法取得了优越的分割性能，显著优于现有的最先进FSDA方法，分别在MRI和CT数据集中实现了27.75%和7.52%的Dice分数提升。代码可在git仓库https://github.com/techicoco/ASAP获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in foundation models have brought promising results incomputer vision, including medical image segmentation. Fine-tuning foundationmodels on specific low-resource medical tasks has become a standard practice.However, ensuring reliable and robust model adaptation when the target task hasa large domain gap and few annotated samples remains a challenge. Previousfew-shot domain adaptation (FSDA) methods seek to bridge the distribution gapbetween source and target domains by utilizing auxiliary data. The selectionand scheduling of auxiliaries are often based on heuristics, which can easilycause negative transfer. In this work, we propose an Active and Sequentialdomain AdaPtation (ASAP) framework for dynamic auxiliary dataset selection inFSDA. We formulate FSDA as a multi-armed bandit problem and derive an efficientreward function to prioritize training on auxiliary datasets that align closelywith the target task, through a single-round fine-tuning. Empirical validationon diverse medical segmentation datasets demonstrates that our method achievesfavorable segmentation performance, significantly outperforming thestate-of-the-art FSDA methods, achieving an average gain of 27.75% on MRI and7.52% on CT datasets in Dice score. Code is available at the git repository:https://github.com/techicoco/ASAP.</description>
      <author>example@mail.com (Jingyun Yang, Guoqing Zhang, Jingge Wang, Yang Li)</author>
      <guid isPermaLink="false">2502.01000v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Hypo3D: Exploring Hypothetical Reasoning in 3D</title>
      <link>http://arxiv.org/abs/2502.00954v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 15 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Hypothetical 3D Reasoning (Hypo3D) 指标，用于评估模型在没有实时场景数据访问的情况下进行推理的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的3D推理基准假设可以随时获取到场景信息，这在实际操作中由于频繁更新场景的成本高昂而难以实现。&lt;h4&gt;目的&lt;/h4&gt;设计一个新的基准来测试模型在想象的场景状态下基于给定的变化描述进行推理的能力。&lt;h4&gt;方法&lt;/h4&gt;Hypo3D作为一个三维视觉问答（VQA）指标构建，包含了700个室内场景中的7,727次上下文变化，产生了14,885对问题和答案。所有场景都使用了锚点来建立一致的世界框架。&lt;h4&gt;主要发现&lt;/h4&gt;最先进的基础模型在假设的场景变化中进行推理时表现挣扎，尤其在涉及移动变化和方向性推理的情景中与人类相比有显著性能差距。&lt;h4&gt;结论&lt;/h4&gt;该研究揭示了现有模型在不依赖实时数据访问的情况下处理假设情景的能力尚不足，并提出了进一步改进的方向。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言基础模型的兴起标志着弥合人机能力差异在3D场景理解方面的一个进步。现有的3D推理基准假设可以随时获取到场景信息，这实际操作中由于频繁更新场景的成本高昂而难以实现。为了应对这个问题，我们引入了Hypothetical 3D Reasoning (Hypo3D)，这是一个用于评估模型在没有实时场景数据访问情况下进行推理能力的指标。模型需要基于提供的变化描述来想象场景的状态然后才能进行推理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of vision-language foundation models marks an advancement inbridging the gap between human and machine capabilities in 3D scene reasoning.Existing 3D reasoning benchmarks assume real-time scene accessibility, which isimpractical due to the high cost of frequent scene updates. To this end, weintroduce Hypothetical 3D Reasoning, namely Hypo3D, a benchmark designed toevaluate models' ability to reason without access to real-time scene data.Models need to imagine the scene state based on a provided change descriptionbefore reasoning. Hypo3D is formulated as a 3D Visual Question Answering (VQA)benchmark, comprising 7,727 context changes across 700 indoor scenes, resultingin 14,885 question-answer pairs. An anchor-based world frame is established forall scenes, ensuring consistent reference to a global frame for directionalterms in context changes and QAs. Extensive experiments show thatstate-of-the-art foundation models struggle to reason in hypothetically changedscenes. This reveals a substantial performance gap compared to humans,particularly in scenarios involving movement changes and directional reasoning.Even when the context change is irrelevant to the question, models oftenincorrectly adjust their answers.</description>
      <author>example@mail.com (Ye Mao, Weixun Luo, Junpeng Jing, Anlan Qiu, Krystian Mikolajczyk)</author>
      <guid isPermaLink="false">2502.00954v2</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Converting Transformers into DGNNs Form</title>
      <link>http://arxiv.org/abs/2502.00585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 3 figures, and 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个新的模型Converter，它将Transformer架构转换为基于单元正交有向图卷积的Directed Graph Neural Network (DGNN)形式。&lt;h4&gt;背景&lt;/h4&gt;最近深度学习的进步使Transformer架构成为主要建模范式。自注意力机制是其成功的关键。&lt;h4&gt;目的&lt;/h4&gt;探讨有向图卷积是否可以作为自注意力的一种替代方案，并引入一个合成单元正交有向图卷积模型来验证这个概念。&lt;h4&gt;方法&lt;/h4&gt;通过基于有向图傅里叶变换的合成单元正交有向图卷积，将Transformer转换为DGNN形式。&lt;h4&gt;主要发现&lt;/h4&gt;Converter在长文本分类和DNA序列基础分类等任务中表现出卓越性能，同时保持计算效率和架构简洁性。&lt;h4&gt;结论&lt;/h4&gt;Converter作为轻量级且强大的Transformer变体被确立下来。&lt;h4&gt;翻译&lt;/h4&gt;最近深度学习的进步已经建立了Transformer架构作为主导的建模范式。自注意力机制的成功关键在于它通过评估查询矩阵与键矩阵之间的相似度来调节值矩阵的操作，这与有向图卷积操作惊人地类似。在这项研究中，我们正式提出了一种合成单元正交有向图卷积的概念，并基于有向图傅里叶变换将其引入Transformer架构，构建了一个新的模型Converter，它将Transformer转换为Directed Graph Neural Network (DGNN)形式。我们在Long-Range Arena基准测试、长文档分类和DNA序列基础分类上对Converter进行了实验验证，结果表明该方法在保持计算效率和架构简洁性的同时，性能卓越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have established Transformer architecturesas the predominant modeling paradigm. Central to the success of Transformers isthe self-attention mechanism, which scores the similarity between query and keymatrices to modulate a value matrix. This operation bears striking similaritiesto digraph convolution, prompting an investigation into whether digraphconvolution could serve as an alternative to self-attention. In this study, weformalize this concept by introducing a synthetic unitary digraph convolutionbased on the digraph Fourier transform. The resulting model, which we termConverter, effectively converts a Transformer into a Directed Graph NeuralNetwork (DGNN) form. We have tested Converter on Long-Range Arena benchmark,long document classification, and DNA sequence-based taxonomy classification.Our experimental results demonstrate that Converter achieves superiorperformance while maintaining computational efficiency and architecturalsimplicity, which establishes it as a lightweight yet powerful Transformervariant.</description>
      <author>example@mail.com (Jie Zhang, Kuan-Chieh Wang, Bo-Wei Chiu, Min-Te Sun)</author>
      <guid isPermaLink="false">2502.00585v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>HASSLE-free: A unified Framework for Sparse plus Low-Rank Matrix Decomposition for LLMs</title>
      <link>http://arxiv.org/abs/2502.00899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种统一的框架HASSLE-free，用于大型基础模型的稀疏加低秩矩阵分解，旨在降低这些模型的部署成本。&lt;h4&gt;背景&lt;/h4&gt;大型预训练模型在提供强大功能的同时消耗了大量的计算资源。将这些模型压缩成更小的形式可以减少推理时的成本，并使更多人能够使用它们。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架用于有效和可扩展地解决稀疏加低秩矩阵分解问题，从而提高基础模型的部署效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种局部逐层重构误差目标函数，证明了现有的工作解决了优化问题的一个松弛版本，并提供了解决这一实际优化问题的有效和可扩展的方法。&lt;h4&gt;主要发现&lt;/h4&gt;HASSLE-free框架在引入的目标函数以及一系列大型语言模型评估基准上显著优于现有方法。具体而言，在稀疏2:4低秩64的分解方案下，对于Llama3-8B模型，HASSLE-free比现有的压缩技术减少了15%的任务差距，并且在WikiText-2数据集上的测试困惑度降低了12%。&lt;h4&gt;结论&lt;/h4&gt;通过将大型基础模型进行稀疏加低秩矩阵分解，可以实现有效的模型压缩，降低推理成本。HASSLE-free框架展示了显著的性能优势。&lt;h4&gt;翻译&lt;/h4&gt;大尺寸预训练模型的能力令人印象深刻，但它们需要大量的计算资源来运行。这些预训练模型的压缩对于降低成本和让更多机器学习社区成员能够部署它们具有实际意义。一种有前途的方法是将基础模型的密集权重分解为稀疏矩阵与低秩矩阵之和。本文设计了一种称为HASSLE-free的统一框架，用于（半结构化）稀疏加低秩矩阵分解的基础模型。该框架引入了局部逐层重构误差目标函数，并表明之前的工作解决了优化问题的一个松弛版本；同时提供了有效且可扩展的方法来最小化所提出的精确优化问题。HASSLE-free在提出的目标和各种大型语言模型评估基准上显著优于现有方法。对于稀疏2:4低秩64的Llama3-8B分解方案，该框架比现有的压缩技术减少了15%的任务差距，并且在WikiText-2数据集上的测试困惑度降低了12%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The impressive capabilities of large foundation models come at a cost ofsubstantial computing resources to serve them. Compressing these pre-trainedmodels is of practical interest as it can democratize deploying them to themachine learning community at large by lowering the costs associated withinference. A promising compression scheme is to decompose foundation models'dense weights into a sum of sparse plus low-rank matrices. In this paper, wedesign a unified framework coined HASSLE-free for (semi-structured) sparse pluslow-rank matrix decomposition of foundation models. Our framework introducesthe local layer-wise reconstruction error objective for this decomposition, wedemonstrate that prior work solves a relaxation of this optimization problem;and we provide efficient and scalable methods to minimize the exact introducedoptimization problem. HASSLE-free substantially outperforms state-of-the-artmethods in terms of the introduced objective and a wide range of LLM evaluationbenchmarks. For the Llama3-8B model with a 2:4 sparsity component plus a64-rank component decomposition, a compression scheme for which recent workshows important inference acceleration on GPUs, HASSLE-free reduces the testperplexity by 12% for the WikiText-2 dataset and reduces the gap (compared tothe dense model) of the average of eight popular zero-shot tasks by 15%compared to existing methods.</description>
      <author>example@mail.com (Mehdi Makni, Kayhan Behdin, Zheng Xu, Natalia Ponomareva, Rahul Mazumder)</author>
      <guid isPermaLink="false">2502.00899v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Data Management and Graph Machine Learning: Synergies and Opportunities</title>
      <link>http://arxiv.org/abs/2502.00529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文综述了图数据管理和图机器学习之间的协同作用，以及它们如何在从存储到分析整个图数据分析和机器学习流水线中相互促进。&lt;h4&gt;背景&lt;/h4&gt;图机器学习（特别是深度学习）应用广泛，在化学信息学、生物信息学等领域都有重要应用。同时，图数据管理致力于开发有效且用户友好的系统和算法来处理大量的异构复杂图数据。&lt;h4&gt;目的&lt;/h4&gt;综述了图数据管理和图机器学习之间的协同作用，并指出了两者相互促进的两个关键方面：图数据管理如何增强图机器学习以及图机器学习如何帮助改进图数据管理。&lt;h4&gt;方法&lt;/h4&gt;论文没有具体提及特定的研究方法，而是从总体上概述了研究领域中的重要进展和挑战。&lt;h4&gt;主要发现&lt;/h4&gt;1. 图数据管理通过提高图神经网络性能、可扩展的图嵌入、高效的向量数据管理和用户友好的解释性方法来增强图机器学习；2. 图机器学习有助于改进知识图谱查询等应用，并对各种数据科学任务有帮助。&lt;h4&gt;结论&lt;/h4&gt;该论文指出了图数据管理与图机器学习领域中存在的开放问题和未来的研究方向，强调了两者在图数据分析中的重要性和相互关系。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文是关于图机器学习及其与图数据管理之间协同作用的综述。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ubiquity of machine learning, particularly deep learning, applied tographs is evident in applications ranging from cheminformatics (drug discovery)and bioinformatics (protein interaction prediction) to knowledge graph-basedquery answering, fraud detection, and social network analysis. Concurrently,graph data management deals with the research and development of effective,efficient, scalable, robust, and user-friendly systems and algorithms forstoring, processing, and analyzing vast quantities of heterogeneous and complexgraph data. Our survey provides a comprehensive overview of the synergiesbetween graph data management and graph machine learning, illustrating how theyintertwine and mutually reinforce each other across the entire spectrum of thegraph data science and machine learning pipeline. Specifically, the surveyhighlights two crucial aspects: (1) How graph data management enhances graphmachine learning, including contributions such as improved graph neural networkperformance through graph data cleaning, scalable graph embedding, efficientgraph-based vector data management, robust graph neural networks, user-friendlyexplainability methods; and (2) how graph machine learning, in turn, aids ingraph data management, with a focus on applications like query answering overknowledge graphs and various data science tasks. We discuss pertinent openproblems and delineate crucial research directions.</description>
      <author>example@mail.com (Arijit Khan, Xiangyu Ke, Yinghui Wu)</author>
      <guid isPermaLink="false">2502.00529v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation</title>
      <link>http://arxiv.org/abs/2502.01694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  55 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提高大型语言模型（LLMs）的推理能力的一个关键范式是在推断时分配更多计算资源来搜索验证器或奖励模型。&lt;h4&gt;目的&lt;/h4&gt;研究在推理过程中如何利用链式思考（CoT）生成作为元稳定马尔可夫过程，通过优化算法改进模型推理性能并探索信息获取方法以获得更好的推理模型。&lt;h4&gt;方法&lt;/h4&gt;将链式思考（CoT）生成视作一个元稳定马尔科夫过程：容易的推理步骤形成密集连接的簇，而困难的推理步骤则在簇之间创建稀疏且概率低的边，并证明通过奖励稀疏边可以改进CoT。&lt;h4&gt;主要发现&lt;/h4&gt;1. 实施搜索协议以奖励稀疏边能减少到达不同簇所需的预期步数。2. 限制模型仅使用预训练图中的局部信息时，推理能力存在上限。3. 搜索获得的信息可用于优化预训练模型并提炼成更小、更高效的模型。&lt;h4&gt;结论&lt;/h4&gt;通过搜索协议奖励稀疏边可以改进大型语言模型的推理性能，并且可以通过搜索获取的信息来优化和简化模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：提高大型语言模型（LLMs）的推理能力的一个关键范式是在推断时分配更多计算资源来搜索验证器或奖励模型。这种方法可用于细化预训练模型或将其推理模式提炼到更高效的模型中。在论文中，我们通过将链式思考（CoT）生成视作一个元稳定马尔科夫过程来研究推断时间的计算：容易的推理步骤形成密集连接的簇，而困难的推理步骤则在这些簇之间创建稀疏且概率低的边，并导致长时间尺度下的相变。在此框架下，我们证明了通过奖励稀疏边可以改进CoT，因为这减少了到达不同簇所需的预期步数。相反地，当模型被限制只能使用预训练图中的局部信息时，我们建立了推理能力的上限。此外，我们还展示了搜索获得的信息可用于获取更好的推理模型：（1）可以通过策略梯度方法直接微调预训练模型以偏向稀疏边；（2）可以提炼出压缩后的元稳定表示，并将其转移至一个更小、更高效的模型中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A key paradigm to improve the reasoning capabilities of large language models(LLMs) is to allocate more inference-time compute to search against a verifieror reward model. This process can then be utilized to refine the pretrainedmodel or distill its reasoning patterns into more efficient models. In thispaper, we study inference-time compute by viewing chain-of-thought (CoT)generation as a metastable Markov process: easy reasoning steps (e.g.,algebraic manipulations) form densely connected clusters, while hard reasoningsteps (e.g., applying a relevant theorem) create sparse, low-probability edgesbetween clusters, leading to phase transitions at longer timescales. Under thisframework, we prove that implementing a search protocol that rewards sparseedges improves CoT by decreasing the expected number of steps to reachdifferent clusters. In contrast, we establish a limit on reasoning capabilitywhen the model is restricted to local information of the pretrained graph. Wealso show that the information gained by search can be utilized to obtain abetter reasoning model: (1) the pretrained model can be directly finetuned tofavor sparse edges via policy gradient methods, and moreover (2) a compressedmetastable representation of the reasoning dynamics can be distilled into asmaller, more efficient model.</description>
      <author>example@mail.com (Juno Kim, Denny Wu, Jason Lee, Taiji Suzuki)</author>
      <guid isPermaLink="false">2502.01694v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Comprehensive Analysis on LLM-based Node Classification Algorithms</title>
      <link>http://arxiv.org/abs/2502.00829v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了基于大型语言模型（LLM）的节点分类算法的设计指南，开发了一个全面的代码库和测试平台LLMNodeBed，并通过广泛的实验得出了多项关键发现。&lt;h4&gt;背景&lt;/h4&gt;节点分类是图分析中的基本任务，在多个领域中有着广泛的应用。近期在大型语言模型方面取得的重大突破促进了LLM在此领域的应用研究。然而，缺乏明确的设计指导原则可能会阻碍其实际应用。&lt;h4&gt;目的&lt;/h4&gt;通过公平和系统的比较，建立基于LLM的节点分类算法的设计指南，并开发了一个易于扩展的新方法和数据集测试平台（LLMNodeBed）。&lt;h4&gt;方法&lt;/h4&gt;该工作构建了包含十种数据集、八种基于LLM的方法以及三种学习范式的全面代码库和实验环境。进行了广泛的训练和评估，涉及超过2,200个模型。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '在半监督设置下，LLM方法可以显著优于传统方法；然而，在完全监督环境下这种优势较小。', '2': '图基础模型虽然能胜过开源的大型语言模型，但在零样本场景下仍不及像GPT-4这样的强大型语言模型。'}&lt;h4&gt;结论&lt;/h4&gt;该研究希望LLMNodeBed平台及所获得的见解能够促进可复现的研究，并激发未来关于基于大型语言模型进行节点分类方面的更多探索。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node classification is a fundamental task in graph analysis, with broadapplications across various fields. Recent breakthroughs in Large LanguageModels (LLMs) have enabled LLM-based approaches for this task. Although manystudies demonstrate the impressive performance of LLM-based methods, the lackof clear design guidelines may hinder their practical application. In thiswork, we aim to establish such guidelines through a fair and systematiccomparison of these algorithms. As a first step, we developed LLMNodeBed, acomprehensive codebase and testbed for node classification using LLMs. Itincludes ten datasets, eight LLM-based algorithms, and three learningparadigms, and is designed for easy extension with new methods and datasets.Subsequently, we conducted extensive experiments, training and evaluating over2,200 models, to determine the key settings (e.g., learning paradigms andhomophily) and components (e.g., model size) that affect performance. Ourfindings uncover eight insights, e.g., (1) LLM-based methods can significantlyoutperform traditional methods in a semi-supervised setting, while theadvantage is marginal in a supervised setting; (2) Graph Foundation Models canbeat open-source LLMs but still fall short of strong LLMs like GPT-4o in azero-shot setting. We hope that the release of LLMNodeBed, along with ourinsights, will facilitate reproducible research and inspire future studies inthis field. Codes and datasets are released at\href{https://llmnodebed.github.io/}{https://llmnodebed.github.io/}.</description>
      <author>example@mail.com (Xixi Wu, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, Hong Cheng)</author>
      <guid isPermaLink="false">2502.00829v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>OneForecast: A Universal Framework for Global and Regional Weather Forecasting</title>
      <link>http://arxiv.org/abs/2502.00338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络的全局-区域嵌套天气预报框架，以提高天气预报的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;精确的气象预报对于防灾、农业规划和水资源管理至关重要。传统数值天气预测方法虽然物理解释性强且精度高，但计算成本高昂并且无法充分利用大量历史数据。近年来，深度学习在天气预报中取得显著进展，但仍面临诸如平衡全球和地区高分辨率预报、极端事件预测中的过度平滑问题以及动态系统建模不足等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的全局-区域嵌套天气预报框架，以解决现有方法存在的上述问题。&lt;h4&gt;方法&lt;/h4&gt;结合动力学系统的视角和多网格理论构建了多层次图结构，并在目标区域内进行细化捕捉局部高频特征。引入自适应信息传播机制，使用动态门控单元深度整合节点和边缘特征以提高极端事件预测的准确性。针对高分辨率区域预报提出了神经嵌套网格法来减少边界信息损失。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在从全球到区域尺度以及短期到长期预报中表现出色，特别是在极端事件（如台风）预测方面显著提高了预报精度。&lt;h4&gt;结论&lt;/h4&gt;通过结合图神经网络和多尺度建模策略，实现了高分辨率、高效能的天气预报，并为解决实际应用中的关键问题提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;准确的气象预报对于灾害预防、农业规划及水资源管理至关重要。传统数值天气预测方法虽然物理可解释性好且精度较高，但计算成本高昂且无法充分利用不断增长的历史数据。近年来，深度学习在天气预报领域取得了显著进展，但仍面临一些挑战：如何平衡全球和区域高分辨率预报、极端事件预测中的过度平滑问题以及动态系统建模的不足。为了解决这些问题，本文提出了一种基于图神经网络（GNN）的全局-区域嵌套天气预报框架。该方法结合了动力学系统的视角与多网格理论构建多层次图结构，并在目标区域内细化捕捉局部高频特征。通过引入自适应信息传播机制，使用动态门控单元深度整合节点和边缘特征以提高极端事件预测精度。针对高分辨率的区域预报，提出了一种神经嵌套网格法来减少边界信息损失。实验结果显示，该方法在全球到区域尺度及短期至长期预报中均表现出色，特别是在台风等极端事件预测方面显著提升了预报准确度。代码可在https://github.com/YuanGao-YG/OneForecast获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate weather forecasts are important for disaster prevention,agricultural planning, and water resource management. Traditional numericalweather prediction (NWP) methods offer physically interpretable high-accuracypredictions but are computationally expensive and fail to fully leveragerapidly growing historical data. In recent years, deep learning methods havemade significant progress in weather forecasting, but challenges remain, suchas balancing global and regional high-resolution forecasts, excessive smoothingin extreme event predictions, and insufficient dynamic system modeling. Toaddress these issues, this paper proposes a global-regional nested weatherforecasting framework based on graph neural networks (GNNs). By combining adynamic system perspective with multi-grid theory, we construct a multi-scalegraph structure and densify the target region to capture local high-frequencyfeatures. We introduce an adaptive information propagation mechanism, usingdynamic gating units to deeply integrate node and edge features for moreaccurate extreme event forecasting. For high-resolution regional forecasts, wepropose a neural nested grid method to mitigate boundary information loss.Experimental results show that the proposed method performs excellently acrossglobal to regional scales and short-term to long-term forecasts, especially inextreme event predictions (e.g., typhoons), significantly improving forecastaccuracy. Our codes are available at https://github.com/YuanGao-YG/OneForecast.</description>
      <author>example@mail.com (Yuan Gao, Hao Wu, Ruiqi Shu, Huanshuo Dong, Fan Xu, Rui Chen, Yibo Yan, Qingsong Wen, Xuming Hu, Kun Wang, Jiahao Wu, Qing Li, Hui Xiong, Xiaomeng Huang)</author>
      <guid isPermaLink="false">2502.00338v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling</title>
      <link>http://arxiv.org/abs/2502.02590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Articulate Anymesh框架，该框架能够将任何刚性3D网格转换为其活动形式的对应物，并且可以应用于广泛的物体类别。&lt;h4&gt;背景&lt;/h4&gt;长期以来，建模具有关节连接的三维对象（例如橱柜和抽屉）是一个挑战。现有的方法依赖于有限的手工制作的艺术对象类别的训练数据，这限制了它们在开放词汇环境中对各种类型的可活动3D对象进行建模的能力。&lt;h4&gt;目的&lt;/h4&gt;提出Articulate Anymesh框架以解决现有方法的局限性，该框架能够将任何刚性的三维网格转换为具有关节连接的功能形式，并可以应用于广泛的物体类别。&lt;h4&gt;方法&lt;/h4&gt;利用先进的视觉语言模型和视觉提示技术提取语义信息，实现对象部件的分割以及功能关节的构建。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明Articulate Anymesh能够生成大规模、高质量的各种类型可活动3D对象（如工具、玩具、机械装置和车辆），显著扩展了现有可活动3D对象数据集的应用范围，并且这些产生的资产有助于在模拟中获取新的可活动物体操作技能，然后可以转移到实际的机器人系统。&lt;h4&gt;结论&lt;/h4&gt;Articulate Anymesh为建模各种类型的具有关节连接的对象提供了通用的方法，在开放词汇环境中有着广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;三维连杆对象建模长期以来一直是一个挑战性问题，因为它需要捕捉准确的表面几何形状和语义上合理且空间精确的部分以及接头。现有的方法严重依赖于来自有限的手工制作连杆物体类别的训练数据（例如橱柜和抽屉），这限制了它们在开放词汇环境中对广泛类型的三维连杆对象进行建模的能力。为了克服这些限制，我们提出了Articulate Anymesh框架，这是一个能够将任何刚性3D网格转换为其可活动对应物的自动化框架，在开放词汇环境下工作。给定一个3D网格，我们的框架利用先进的视觉语言模型和视觉提示技术来提取语义信息，从而实现对象部分的分割以及功能接头的构建。实验显示Articulate Anymesh能够生成大规模、高质量的各种类型的可活动3D对象（如工具、玩具、机械装置和车辆），显著扩展了现有可活动三维物体数据集的应用范围。此外，我们还展示了这些生成的资产如何有助于在模拟中获得新的可活动物体操作技能，然后可以转移到实际机器人系统中。我们的GitHub网站是https://articulate-anymesh.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D articulated objects modeling has long been a challenging problem, since itrequires to capture both accurate surface geometries and semanticallymeaningful and spatially precise structures, parts, and joints. Existingmethods heavily depend on training data from a limited set of handcraftedarticulated object categories (e.g., cabinets and drawers), which restrictstheir ability to model a wide range of articulated objects in anopen-vocabulary context. To address these limitations, we propose ArticulateAnymesh, an automated framework that is able to convert any rigid 3D mesh intoits articulated counterpart in an open-vocabulary manner. Given a 3D mesh, ourframework utilizes advanced Vision-Language Models and visual promptingtechniques to extract semantic information, allowing for both the segmentationof object parts and the construction of functional joints. Our experiments showthat Articulate Anymesh can generate large-scale, high-quality 3D articulatedobjects, including tools, toys, mechanical devices, and vehicles, significantlyexpanding the coverage of existing 3D articulated object datasets.Additionally, we show that these generated assets can facilitate theacquisition of new articulated object manipulation skills in simulation, whichcan then be transferred to a real robotic system. Our Github website ishttps://articulate-anymesh.github.io.</description>
      <author>example@mail.com (Xiaowen Qiu, Jincheng Yang, Yian Wang, Zhehuan Chen, Yufei Wang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan)</author>
      <guid isPermaLink="false">2502.02590v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>GTG: Generalizable Trajectory Generation Model for Urban Mobility</title>
      <link>http://arxiv.org/abs/2502.01107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为GTG的模型，该模型能够基于城市间不变性的移动模式生成轨迹数据，适用于智慧城市的管理。&lt;h4&gt;背景&lt;/h4&gt;收集大规模轨迹数据集在智能城市管理中至关重要，但受到商业冲突和隐私法规的影响而变得困难。&lt;h4&gt;目的&lt;/h4&gt;开发通用的轨迹生成技术以解决大规模轨迹数据集难以获取的问题。&lt;h4&gt;方法&lt;/h4&gt;1) 基于Space Syntax方法提取城市不变的道路表示；2) 通过解耦对抗训练进行跨城市旅行成本预测；3) 通过最短路径搜索和偏好更新学习出行偏好。&lt;h4&gt;主要发现&lt;/h4&gt;存在不同城市间的不变性移动模式：人们倾向于选择最低交通成本的路线，且道路的旅行成本与其拓扑特征之间有不变的关系。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明该模型在三个数据集上的泛化能力显著优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;轨迹数据分析对于智能城市管理至关重要。由于商业竞争和隐私法规等障碍，收集大规模轨迹数据非常困难。因此迫切需要开发能够生成真实轨迹的通用技术来应对这一挑战。基于对不同城市间不变性移动模式的认识（例如人们偏好选择低交通成本路线，并且道路旅行成本与其网络拓扑特征之间存在恒定关系），本文提出了一种称为GTG的模型，该模型能够在新城市中生成轨迹数据。通过在三个数据集上的实验结果证明了模型具有显著优于现有方法的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory data mining is crucial for smart city management. However,collecting large-scale trajectory datasets is challenging due to factors suchas commercial conflicts and privacy regulations. Therefore, we urgently needtrajectory generation techniques to address this issue. Existing trajectorygeneration methods rely on the global road network structure of cities. Whenthe road network structure changes, these methods are often not transferable toother cities. In fact, there exist invariant mobility patterns betweendifferent cities: 1) People prefer paths with the minimal travel cost; 2) Thetravel cost of roads has an invariant relationship with the topologicalfeatures of the road network. Based on the above insight, this paper proposes aGeneralizable Trajectory Generation model (GTG). The model consists of threeparts: 1) Extracting city-invariant road representation based on Space Syntaxmethod; 2) Cross-city travel cost prediction through disentangled adversarialtraining; 3) Travel preference learning by shortest path search and preferenceupdate. By learning invariant movement patterns, the model is capable ofgenerating trajectories in new cities. Experiments on three datasetsdemonstrates that our model significantly outperforms existing models in termsof generalization ability.</description>
      <author>example@mail.com (Jingyuan Wang, Yujing Lin, Yudong Li)</author>
      <guid isPermaLink="false">2502.01107v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</title>
      <link>http://arxiv.org/abs/2502.02562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Videos of STRING-based robotics controllers can be found here:  https://sites.google.com/view/string-robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要介绍&lt;/h4&gt;提出STRING：可分离的平移不变位置编码，它扩展了旋转位置编码（Rotary Position Encodings），这是大型语言模型中最近提出并广泛使用的一种算法。&lt;h4&gt;背景&lt;/h4&gt;在大规模语言模型中，旋转位置编码作为一种新颖且广泛应用的方法被引入。然而，在机器人学等领域，高效的3D标记表示是关键，这需要保持平移不变性的同时减少计算负担。&lt;h4&gt;目的&lt;/h4&gt;通过统一的理论框架扩展Rotary Position Encodings，并提供完全的平移不变性和低计算开销。&lt;h4&gt;方法&lt;/h4&gt;将STRING集成到接收RGB（-D）输入的视觉变换器中，展示在开放词汇对象检测和机器人控制器上的显著改善。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STRING能够在保持效率的同时提高模型性能，尤其是在需要3D表示的任务上。此外，通过严格的数学分析证明了方法的普适性。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种改进位置编码的新方式，特别是在涉及高效三维空间处理的情况下，并且这种方法已经过实证验证和理论支持。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了STRING：可分离的平移不变位置编码。STRING通过统一的理论框架扩展了最近在大型语言模型中广泛使用的旋转位置编码算法。重要的是，STRING仍然提供了精确的平移不变性，包括任意维度的标记坐标，并且保持了低计算开销。这些特性对于机器人学尤其关键，在该领域有效的3D标记表示至关重要。我们将STRING集成到视觉变换器中并采用RGB（-D）输入（颜色加可选深度），在开放词汇对象检测和为机器人控制器展示出实质性的收益。我们还通过严格的数学分析补充了实验，证明了我们的方法的普适性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce STRING: Separable Translationally Invariant Position Encodings.STRING extends Rotary Position Encodings, a recently proposed and widely usedalgorithm in large language models, via a unifying theoretical framework.Importantly, STRING still provides exact translation invariance, includingtoken coordinates of arbitrary dimensionality, whilst maintaining a lowcomputational footprint. These properties are especially important in robotics,where efficient 3D token representation is key. We integrate STRING into VisionTransformers with RGB(-D) inputs (color plus optional depth), showingsubstantial gains, e.g. in open-vocabulary object detection and for roboticscontrollers. We complement our experiments with a rigorous mathematicalanalysis, proving the universality of our methods.</description>
      <author>example@mail.com (Connor Schenck, Isaac Reid, Mithun George Jacob, Alex Bewley, Joshua Ainslie, David Rendleman, Deepali Jain, Mohit Sharma, Avinava Dubey, Ayzaan Wahid, Sumeet Singh, Rene Wagner, Tianli Ding, Chuyuan Fu, Arunkumar Byravan, Jake Varley, Alexey Gritsenko, Matthias Minderer, Dmitry Kalashnikov, Jonathan Tompson, Vikas Sindhwani, Krzysztof Choromanski)</author>
      <guid isPermaLink="false">2502.02562v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications</title>
      <link>http://arxiv.org/abs/2502.01297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新颖的视觉惯性里程计(VIO)方法，重点在于初始化和特征匹配模块。&lt;h4&gt;背景&lt;/h4&gt;现有初始化方法通常存在视觉结构从运动(SfM)稳定性差或同时解决大量参数时易失效的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒处理各种复杂场景的新管道，增强视觉SfM的稳定性和准确性，并引入结合光流和描述符匹配的方法来实现高效、准确且鲁棒的跟踪结果。&lt;h4&gt;方法&lt;/h4&gt;{'初始化模块': '通过紧密耦合陀螺仪测量，改进了视觉惯性初始化流程，即使在仅有四个图像帧的情况下也能表现出稳定的性能。', '特征匹配模块': '提出一种结合光流和描述符匹配的混合方法，利用连续光流跟踪的鲁棒性和描述符匹配的准确性来实现高效、准确且鲁棒的跟踪结果。', '实验验证': '通过多个基准测试证明了该方法在精度和成功率方面具有最先进的性能，并通过移动设备上的视频演示展示了其在增强现实/虚拟现实(AR/VR)领域的实际应用性。'}&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法能够实现稳定的初始化流程，即使是在非常有限的数据条件下也能表现出色；特征匹配模块结合了光流跟踪和描述符匹配的优势，实现了高效且鲁棒的跟踪结果。&lt;h4&gt;结论&lt;/h4&gt;该方法通过实验验证显示出了在精度和成功率方面的优越性能，并展示了其在AR/VR领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel approach to Visual Inertial Odometry (VIO),focusing on the initialization and feature matching modules. Existing methodsfor initialization often suffer from either poor stability in visual Structurefrom Motion (SfM) or fragility in solving a huge number of parameterssimultaneously. To address these challenges, we propose a new pipeline forvisual inertial initialization that robustly handles various complex scenarios.By tightly coupling gyroscope measurements, we enhance the robustness andaccuracy of visual SfM. Our method demonstrates stable performance even withonly four image frames, yielding competitive results. In terms of featurematching, we introduce a hybrid method that combines optical flow anddescriptor-based matching. By leveraging the robustness of continuous opticalflow tracking and the accuracy of descriptor matching, our approach achievesefficient, accurate, and robust tracking results. Through evaluation onmultiple benchmarks, our method demonstrates state-of-the-art performance interms of accuracy and success rate. Additionally, a video demonstration onmobile devices showcases the practical applicability of our approach in thefield of Augmented Reality/Virtual Reality (AR/VR).</description>
      <author>example@mail.com (Shangjin Zhai, Nan Wang, Xiaomeng Wang, Danpeng Chen, Weijian Xie, Hujun Bao, Guofeng Zhang)</author>
      <guid isPermaLink="false">2502.01297v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Anytime Incremental $ρ$POMDP Planning in Continuous Spaces</title>
      <link>http://arxiv.org/abs/2502.02549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章介绍了一种新的在线求解器ρPOMCPOW，该求解器解决了连续空间中的信念表示固定问题，并且可以动态地细化信念表示。此外，它提出了一种增量计算方法来降低计算成本。&lt;h4&gt;背景&lt;/h4&gt;部分可观测马尔可夫决策过程(POMDPs)在自主驾驶和机器人探索等应用中提供了在不确定性下的稳健决策框架。ρPOMDPs作为其扩展引入了依赖于信念的奖励机制，允许明确地考虑不确定性的效果。&lt;h4&gt;目的&lt;/h4&gt;解决现有在线ρPOMDP求解器存在的固定信念表示限制问题，并提高信息采集任务中的适应性和细化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的任意时间求解器ρPOMCPOW，该求解器可以动态地细化信念表示并提供随着时间改善的正式保证。同时提出了更新依赖于信念的奖励时减少计算成本的新增量计算方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ρPOMCPOW在效率和解决方案质量上都优于现有的最先进的求解器，并且对于常见的熵估计器可以显著地减少计算成本。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法（即动态信念细化与新的增量计算策略）提供了比现有方法更有效率的在线求解方案，特别适用于信息采集等复杂任务。&lt;h4&gt;翻译&lt;/h4&gt;部分可观测马尔可夫决策过程(POMDPs)为诸如自主驾驶和机器人探索的应用在不确定性下进行稳健决策提供了一个强大的框架。它们的扩展ρPOMDP引入了依赖于信念的奖励机制，使得明确处理不确定性成为可能。现有的连续空间在线ρPOMDP求解器依赖于固定的信念表示，这限制了适应性和细化能力，在信息采集等任务中尤为重要。我们提出了一种新的任意时间求解器ρPOMCPOW，它能够动态地细化信念表示，并提供了随着时间改善的正式保证。为了减轻更新依赖于信念的奖励时的高昂计算成本，我们提出了一个新颖的增量计算方法。我们展示了这种方法对于常见的熵估计器的有效性，将计算成本降低了几个数量级。实验结果表明ρPOMCPOW在效率和解决方案质量方面都优于现有的最先进的求解器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partially Observable Markov Decision Processes (POMDPs) provide a robustframework for decision-making under uncertainty in applications such asautonomous driving and robotic exploration. Their extension, $\rho$POMDPs,introduces belief-dependent rewards, enabling explicit reasoning aboutuncertainty. Existing online $\rho$POMDP solvers for continuous spaces rely onfixed belief representations, limiting adaptability and refinement - criticalfor tasks such as information-gathering. We present $\rho$POMCPOW, an anytimesolver that dynamically refines belief representations, with formal guaranteesof improvement over time. To mitigate the high computational cost of updatingbelief-dependent rewards, we propose a novel incremental computation approach.We demonstrate its effectiveness for common entropy estimators, reducingcomputational cost by orders of magnitude. Experimental results show that$\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency andsolution quality.</description>
      <author>example@mail.com (Ron Benchetrit, Idan Lev-Yehudi, Andrey Zhitnikov, Vadim Indelman)</author>
      <guid isPermaLink="false">2502.02549v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Geoinformatics-Guided Machine Learning for Power Plant Classification</title>
      <link>http://arxiv.org/abs/2502.01039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种结合卷积神经网络（CNN）、视觉变换器（ViT）和地理信息系统（GIS）的新框架，以增强电力设施分类。&lt;h4&gt;背景&lt;/h4&gt;当前的电力管理中存在对高效、精确电力设施分类的需求。&lt;h4&gt;目的&lt;/h4&gt;通过知识引导机器学习方法改善从卫星图像中识别多种类型电力设施的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种将空间掩码（SM）获取到的地理信息与CNN和ViT架构结合的新KGML框架。&lt;h4&gt;主要发现&lt;/h4&gt;该研究显示，与仅使用CNN和ViT的方法相比，新框架在分类真实卫星图像中的多种电力设施方面表现更佳。&lt;h4&gt;结论&lt;/h4&gt;此工作强调了基于地理信息引导方法的重要性和价值，并为智能城市和环境计算等领域带来了广泛影响。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an approach in the area of Knowledge-Guided MachineLearning (KGML) via a novel integrated framework comprising CNN (ConvolutionalNeural Networks) and ViT (Vision Transformers) along with GIS (GeographicInformation Systems) to enhance power plant classification in the context ofenergy management. Knowledge from geoinformatics derived through Spatial Masks(SM) in GIS is infused into an architecture of CNN and ViT, in this proposedKGML approach. It is found to provide much better performance compared to thebaseline of CNN and ViT only in the classification of multiple types of powerplants from real satellite imagery, hence emphasizing the vital role of thegeoinformatics-guided approach. This work makes a contribution to the maintheme of KGML that can be beneficial in many AI systems today. It makes broaderimpacts on AI in Smart Cities, and Environmental Computing.</description>
      <author>example@mail.com (Blessing Austin-Gabriel, Aparna S. Varde, Hao Liu)</author>
      <guid isPermaLink="false">2502.01039v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation</title>
      <link>http://arxiv.org/abs/2502.02525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于扩散模型的范式，用于实现从合成数据到真实场景泛化的九自由度物体姿态估计。&lt;h4&gt;背景&lt;/h4&gt;九自由度（9-DoF）对象姿态和尺寸估计对于增强现实和机器人操作至关重要。类别级别的方法因能够在未知类别内推广而受到广泛关注。然而，这些方法需要手动收集大规模的真实世界训练数据。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，论文引入了一种基于扩散模型的领域泛化9-DoF物体姿态估计的新范式。&lt;h4&gt;方法&lt;/h4&gt;该研究提出了一种有效的扩散模型从生成的角度重新定义了9-DoF对象姿态估计。通过使用去噪扩散隐式模型，展示了反向扩散过程可以在仅3步内完成，实现接近实时的性能。&lt;h4&gt;主要发现&lt;/h4&gt;论文设计了一个包括硬件和软件组件的机器人抓取系统，并在两个基准数据集以及真实世界中的机器人系统中进行了全面实验，证明了该方法达到了最先进的领域泛化性能。&lt;h4&gt;结论&lt;/h4&gt;论文的方法不依赖于3D形状先验，在训练和推理阶段都不需要。最后通过公开代码（https://github.com/CNJianLiu/Diff9D）支持研究的可重复性。&lt;h4&gt;翻译&lt;/h4&gt;九自由度物体姿态与大小估计对于增强现实及机器人操作至关重要。类别级别的方法因能够在未知类别内推广而备受关注，但这些方法需要大量手动收集的真实世界训练数据。论文提出了基于扩散模型的方法解决这一问题，通过仅使用渲染的合成数据进行训练来实现真实场景中的泛化能力，并设计了一种有效的机器人抓取系统，在基准和实际测试中展现了优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nine-degrees-of-freedom (9-DoF) object pose and size estimation is crucialfor enabling augmented reality and robotic manipulation. Category-level methodshave received extensive research attention due to their potential forgeneralization to intra-class unknown objects. However, these methods requiremanual collection and labeling of large-scale real-world training data. Toaddress this problem, we introduce a diffusion-based paradigm fordomain-generalized category-level 9-DoF object pose estimation. Our motivationis to leverage the latent generalization ability of the diffusion model toaddress the domain generalization challenge in object pose estimation. Thisentails training the model exclusively on rendered synthetic data to achievegeneralization to real-world scenes. We propose an effective diffusion model toredefine 9-DoF object pose estimation from a generative perspective. Our modeldoes not require any 3D shape priors during training or inference. By employingthe Denoising Diffusion Implicit Model, we demonstrate that the reversediffusion process can be executed in as few as 3 steps, achieving nearreal-time performance. Finally, we design a robotic grasping system comprisingboth hardware and software components. Through comprehensive experiments on twobenchmark datasets and the real-world robotic system, we show that our methodachieves state-of-the-art domain generalization performance. Our code will bemade public at https://github.com/CNJianLiu/Diff9D.</description>
      <author>example@mail.com (Jian Liu, Wei Sun, Hui Yang, Pengchao Deng, Chongpei Liu, Nicu Sebe, Hossein Rahmani, Ajmal Mian)</author>
      <guid isPermaLink="false">2502.02525v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging LLMs for Dynamic IoT Systems Generation through Mixed-Initiative Interaction</title>
      <link>http://arxiv.org/abs/2502.00689v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了IoT-Together系统，该系统通过集成大型语言模型（LLMs）来增强物联网系统的适应性和用户体验。&lt;h4&gt;背景&lt;/h4&gt;物联网系统在满足用户需求方面面临挑战，这些需求往往不明确且随环境变化而演变。现有系统需要更好地与用户互动以提供定制化服务。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合倡议交互(MII)方法，使IoT系统能够通过协作的方式学习并支持用户探索新的可能性。&lt;h4&gt;方法&lt;/h4&gt;引入了物联网协同（IoT-Together）框架，并将其扩展为包括大型语言模型的架构。该体系结构使用多轮对话来智能解析目标并通过实时动态服务生成来响应用户需求。&lt;h4&gt;主要发现&lt;/h4&gt;通过在智慧城市旅游案例研究中设计和实施系统，并采用基于代理的模拟和用户体验测试评估其性能，结果表明系统能够有效地识别和适应新的服务请求。&lt;h4&gt;结论&lt;/h4&gt;将大型语言模型整合到物联网架构中可以显著增强系统的适应性和实际应用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; IoT systems face significant challenges in adapting to user needs, which areoften under-specified and evolve with changing environmental contexts. Toaddress these complexities, users should be able to explore possibilities,while IoT systems must learn and support users in the process of providingproper services, e.g., to serve novel experiences. The IoT-Together paradigmaims to meet this demand through the Mixed-Initiative Interaction (MII)paradigm that facilitates a collaborative synergy between users and IoTsystems, enabling the co-creation of intelligent and adaptive solutions thatare precisely aligned with user-defined goals. This work advances IoT-Togetherby integrating Large Language Models (LLMs) into its architecture. Our approachenables intelligent goal interpretation through a multi-pass dialogue frameworkand dynamic service generation at runtime according to user needs. Todemonstrate the efficacy of our methodology, we design and implement the systemin the context of a smart city tourism case study. We evaluate the system'sperformance using agent-based simulation and user studies. Results indicateefficient and accurate service identification and high adaptation quality. Theempirical evidence indicates that the integration of Large Language Models(LLMs) into IoT architectures can significantly enhance the architecturaladaptability of the system while ensuring real-world usability.</description>
      <author>example@mail.com (Bassam Adnan, Sathvika Miryala, Aneesh Sambu, Karthik Vaidhyanathan, Martina De Sanctis, Romina Spalazzese)</author>
      <guid isPermaLink="false">2502.00689v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Distributional Diffusion Models with Scoring Rules</title>
      <link>http://arxiv.org/abs/2502.02483v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种改进的扩散模型，通过学习给定其噪声版本后的干净数据样本的后验分布来加速生成高质量输出的过程。&lt;h4&gt;背景&lt;/h4&gt;扩散模型是当前生成高保真合成数据的有效工具。它们的工作原理是定义一个连续时间正向过程，逐步将高斯噪音添加到原始数据中直到完全破坏。&lt;h4&gt;目的&lt;/h4&gt;减少逆向过程中的离散化步骤数量，同时保持输出质量不受太大影响，加速推理过程。&lt;h4&gt;方法&lt;/h4&gt;使用评分规则取代标准回归损失函数来估计条件均值，允许在较粗的时间尺度上从反向过程中概率转换进行采样。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过学习后验分布显著提高了扩散模型的效率，并且在图像生成和机器人轨迹生成任务中优于传统的扩散模型，特别是在较少离散化步骤的情况下表现更好。&lt;h4&gt;结论&lt;/h4&gt;提出的方法提供了加速扩散模型生成过程的新途径，同时保持高质量输出。这为更多应用场景中的高效数据合成开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种改进的扩散模型技术，该技术通过学习给定噪声版本后干净数据样本的后验分布来提高生成效率。传统的方法需要大量的离散步骤来准确模拟逆向过程，而这种新方法则允许在较粗的时间尺度上快速采样，并且仅造成很小的质量损失。实验结果表明，在图像和机器人轨迹生成任务中，该方法优于标准扩散模型，尤其是在较少的离散化步骤下性能更为出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models generate high-quality synthetic data. They operate bydefining a continuous-time forward process which gradually adds Gaussian noiseto data until fully corrupted. The corresponding reverse process progressively"denoises" a Gaussian sample into a sample from the data distribution. However,generating high-quality outputs requires many discretization steps to obtain afaithful approximation of the reverse process. This is expensive and hasmotivated the development of many acceleration methods. We propose toaccomplish sample generation by learning the posterior {\em distribution} ofclean data samples given their noisy versions, instead of only the mean of thisdistribution. This allows us to sample from the probability transitions of thereverse process on a coarse time scale, significantly accelerating inferencewith minimal degradation of the quality of the output. This is accomplished byreplacing the standard regression loss used to estimate conditional means witha scoring rule. We validate our method on image and robot trajectorygeneration, where we consistently outperform standard diffusion models at fewdiscretization steps.</description>
      <author>example@mail.com (Valentin De Bortoli, Alexandre Galashov, J. Swaroop Guntupalli, Guangyao Zhou, Kevin Murphy, Arthur Gretton, Arnaud Doucet)</author>
      <guid isPermaLink="false">2502.02483v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Null Space Compliance Approach for Maintaining Safety and Tracking Performance in Human-Robot Interactions</title>
      <link>http://arxiv.org/abs/2502.02443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种改进的卡迪尔阻抗控制方法结合动力学系统（DS）运动生成器，以增强机器人末端执行器与人协作时的互动能力，并通过一种新的零空间阻抗控制方法使机器人的身体也能够适应未知物理交互，从而避免严重的意外伤害。&lt;h4&gt;背景&lt;/h4&gt;近年来，开发机器人机械臂的重点转向了在人类-机器人互动（HRI）中优先考虑安全性。然而，典型的交互控制系统如阻抗控制存在两个主要限制：末端执行器的柔顺性有限以及无法应对未知物理交互。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以解决传统阻抗控制存在的问题，使机器人的工作性能不受影响的同时，能够更好地与人协作互动，并且当发生意外接触时能避免严重的伤害。&lt;h4&gt;方法&lt;/h4&gt;引入了改进的卡迪尔阻抗控制结合动力学系统（DS）运动生成器的方法以及新的零空间阻尼控制法来增强末端执行器和机器人身体的柔顺性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法允许人类工人在协作任务中实时与机器人末端执行器互动，如更换工具后，机器人能够以柔顺的方式继续其任务。同时，在发生意外接触时可以有效避免严重伤害，并减少对主任务跟踪性能的影响。&lt;h4&gt;结论&lt;/h4&gt;证明了系统的无源性并通过广泛的对比实验验证了所提出的方法在7自由度KUKA LWR IV+机器人的应用中是有效的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，开发机器人机械臂的重点转向了在人类-机器人互动（HRI）中的安全性。阻抗控制是一种典型的合作任务中的交互控制系统。然而，这种方法有两个主要限制：1) 末端执行器(EE)的柔顺性有限，无法适应未知物理交互；2) 机器人的身体不能够柔顺地应对未知物理交互。在本文中，我们提出了一种解决这些缺点的方法。我们引入了改进的卡迪尔阻抗控制结合动力学系统（DS）运动生成器方法，旨在增强EE与人类协作时的能力而不影响主任务跟踪性能。这使得人类同事可以在实时过程中互动，例如更换工具，之后机器人以柔顺的方式继续其任务。此外，通过新的零空间阻尼控制法使机器人的身体也能够展现出符合性行为来应对交互，避免意外接触造成的严重伤害，并减少对主要任务跟踪性能的影响。最后，我们证明了系统的无源性并通过广泛的对比实验在7自由度KUKA LWR IV+机器人上验证了所提出的方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the focus on developing robot manipulators has shiftedtowards prioritizing safety in Human-Robot Interaction (HRI). Impedance controlis a typical approach for interaction control in collaboration tasks. However,such a control approach has two main limitations: 1) the end-effector (EE)'slimited compliance to adapt to unknown physical interactions, and 2) inabilityof the robot body to compliantly adapt to unknown physical interactions. Inthis work, we present an approach to address these drawbacks. We introduce amodified Cartesian impedance control method combined with a Dynamical System(DS)-based motion generator, aimed at enhancing the interaction capability ofthe EE without compromising main task tracking performance. This approachenables human coworkers to interact with the EE on-the-fly, e.g. toolchangeover, after which the robot compliantly resumes its task. Additionally,combining with a new null space impedance control method enables the robot bodyto exhibit compliant behaviour in response to interactions, avoiding seriousinjuries from accidental contact while mitigating the impact on main tasktracking performance. Finally, we prove the passivity of the system andvalidate the proposed approach through comprehensive comparative experiments ona 7 Degree-of-Freedom (DOF) KUKA LWR IV+ robot.</description>
      <author>example@mail.com (Zi-Qi Yang, Miaomiao Wang, Mehrdad R. Kermani)</author>
      <guid isPermaLink="false">2502.02443v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>mPOLICE: Provable Enforcement of Multi-Region Affine Constraints in Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2502.02434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;介绍了mPOLICE，一种用于在深度神经网络中处理多个约束区域的方法。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习技术的应用扩展到气候建模、机器人技术和工业控制等领域，保持严格的输出限制变得至关重要。已有方法如POLICE算法可以调整网络参数来满足单一凸区域内线性约束的要求，但对于多个分离的区域则难以避免冲突或意外影响。&lt;h4&gt;目的&lt;/h4&gt;提出mPOLICE以解决在处理多区域约束时的问题，即为每个受限区域分配独特的激活模式，同时确保不会对其他输入领域产生过大的影响。&lt;h4&gt;方法&lt;/h4&gt;通过分层优化问题来调整权重和偏差值，使得能够将唯一的激活模式赋予每一个凸区域。此外，在满足要求的同时保持学习函数的连续性和平滑性。&lt;h4&gt;主要发现&lt;/h4&gt;mPOLICE能有效地应对多区域约束挑战，并且实验结果表明它能在回归、分类及非凸域通过近似处理等方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;与现有技术相比，mPOLICE不仅没有增加推理开销，而且训练负担也非常小。该方法适用于各种应用场景，包括但不限于气候建模和工业控制等领域。&lt;h4&gt;翻译&lt;/h4&gt;深度神经网络在诸如气候建模、机器人技术和工业控制等领域的应用日益广泛，在这些领域中必须保持严格的输出限制。虽然之前的方法如POLICE算法能够通过调整网络参数来在一个单一的凸区域内实施线性约束，但在处理多个分离区域时却往往会出现冲突或意外的影响。我们提出了一种新的方法mPOLICE，它扩展了POLICE以应对施加在多个区域上的限制条件。mPOLICE为每个受限区域分配一个独特的激活模式，在局部保持精确的线性行为的同时避免向其他输入领域过度延伸。我们制定了逐层优化问题来调整权重和偏差，以便将唯一的激活模式赋予每一个凸区域，确保满足要求的同时没有冲突，并且同时维持学习函数的连续性和平滑性。实验结果显示了在回归、分类以及通过近似处理非凸域等多种情况下的多区域约束实施能力。值得注意的是，mPOLICE几乎不增加推理开销和训练负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks are increasingly employed in fields such as climatemodeling, robotics, and industrial control, where strict output constraintsmust be upheld. Although prior methods like the POLICE algorithm can enforceaffine constraints in a single convex region by adjusting network parameters,they struggle with multiple disjoint regions, often leading to conflicts orunintended affine extensions. We present mPOLICE, a new method that extendsPOLICE to handle constraints imposed on multiple regions. mPOLICE assigns adistinct activation pattern to each constrained region, preserving exact affinebehavior locally while avoiding overreach into other parts of the input domain.We formulate a layer-wise optimization problem that adjusts both the weightsand biases to assign unique activation patterns to each convex region, ensuringthat constraints are met without conflicts, while maintaining the continuityand smoothness of the learned function. Our experiments show the enforcement ofmulti-region constraints for multiple scenarios, including regression andclassification, function approximation, and non-convex regions throughapproximation. Notably, mPOLICE adds zero inference overhead and minimaltraining overhead.</description>
      <author>example@mail.com (Mohammadmehdi Ataei, Hyunmin Cheong, Adrian Butscher)</author>
      <guid isPermaLink="false">2502.02434v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Event-aided Semantic Scene Completion</title>
      <link>http://arxiv.org/abs/2502.02334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The established datasets and codebase will be made publicly at  https://github.com/Pandapan01/EvSSC&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种用于自主驾驶的事件相机辅助语义场景完成(DSEC-SSC)系统，并设计了一个新的4D标签生成流水线，以提供高质量的训练数据。研究还开发了RGB-Event融合框架EvSSC，包括一个桥接2D RGB-Event特征到3D空间的模块（ELM），并在多种设置中证明了其有效性。&lt;h4&gt;背景&lt;/h4&gt;自主驾驶系统依赖于强大的3D场景理解能力，传统的基于RGB的方法在运动模糊、光线不足和极端天气条件下表现不佳。事件相机由于其高动态范围和低延迟特性解决了这些问题，并能提供异步数据来补充RGB输入。&lt;h4&gt;目的&lt;/h4&gt;为了提高自主驾驶中的语义场景完成（SSC）性能，本文提出了一种新的评估基准DSEC-SSC以及一个融合框架EvSSC，旨在利用事件相机的优势以增强3D空间的构建和视图转换能力。&lt;h4&gt;方法&lt;/h4&gt;首先设计了4D标签生成流程；其次提出了RGB-Event融合框架EvSSC，包含事件辅助提升模块ELM来有效连接2D RGB-Event特征到3D空间，并评估其在不同架构（如基于Transformer的和LSS的）上的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与仅使用RGB数据相比，EvSSC在五种退化模式下表现出更高的预测准确性，在图像传感器部分失效的情况下，mIoU相对提高了52.5%，展示了其在运动模糊及极端天气条件下的优越性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入DSEC-SSC基准和创新的EvSSC框架，本文成功提升了基于事件相机的自主驾驶系统中的3D场景理解能力。未来的研究将探索更多的潜在应用场景。&lt;h4&gt;翻译&lt;/h4&gt;自主驾驶系统依靠强大的三维场景理解能力。最近在自动驾驶领域对语义场景完成（Semantic Scene Completion, SSC）的研究强调了RGB方法的局限性，这些方法在运动模糊、光线不足以及恶劣天气条件下表现不佳。事件相机通过提供高动态范围和低延迟的数据来解决这些问题，并且它们提供的异步数据可以补充RGB输入。本文提出了DSEC-SSC，这是第一个专门为事件辅助的SSC设计的真实世界基准测试，它包含了一种新型4D标签生成管道，用于根据物体运动自适应地生成密集、可见性感知的标签。我们还提出了一种新的RGB-Event融合框架EvSSC，其中包括了一个事件辅助提升模块（ELM），该模块能够有效地将2D RGB-Event特征转换到3D空间中，从而增强了视图转换能力以及各种SSC模型下3D体积构建的鲁棒性。在DSEC-SSC和模拟SemanticKITTI-E上的大量实验表明，EvSSC可以适应基于Transformer和LSS的架构。特别值得注意的是，在SemanticKITTI-C的数据集上进行评估时发现，与仅使用RGB相比，EvSSC在五种退化模式下以及域内和域外设置中都取得了明显更高的预测精度，在图像传感器部分失效的情况下mIoU相对提高了52.5%。此外，我们从定量和定性两个方面验证了EvSSC在运动模糊和极端天气条件下表现优异，这是自动驾驶汽车面临的挑战之一。本文建立的数据集和代码库将在https://github.com/Pandapan01/EvSSC上公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving systems rely on robust 3D scene understanding. Recentadvances in Semantic Scene Completion (SSC) for autonomous driving underscorethe limitations of RGB-based approaches, which struggle under motion blur, poorlighting, and adverse weather. Event cameras, offering high dynamic range andlow latency, address these challenges by providing asynchronous data thatcomplements RGB inputs. We present DSEC-SSC, the first real-world benchmarkspecifically designed for event-aided SSC, which includes a novel 4D labelingpipeline for generating dense, visibility-aware labels that adapt dynamicallyto object motion. Our proposed RGB-Event fusion framework, EvSSC, introduces anEvent-aided Lifting Module (ELM) that effectively bridges 2D RGB-Event featuresto 3D space, enhancing view transformation and the robustness of 3D volumeconstruction across SSC models. Extensive experiments on DSEC-SSC and simulatedSemanticKITTI-E demonstrate that EvSSC is adaptable to both transformer-basedand LSS-based SSC architectures. Notably, evaluations on SemanticKITTI-Cdemonstrate that EvSSC achieves consistently improved prediction accuracyacross five degradation modes and both In-domain and Out-of-domain settings,achieving up to a 52.5% relative improvement in mIoU when the image sensorpartially fails. Additionally, we quantitatively and qualitatively validate thesuperiority of EvSSC under motion blur and extreme weather conditions, whereautonomous driving is challenged. The established datasets and our codebasewill be made publicly at https://github.com/Pandapan01/EvSSC.</description>
      <author>example@mail.com (Shangwei Guo, Hao Shi, Song Wang, Xiaoting Yin, Kailun Yang, Kaiwei Wang)</author>
      <guid isPermaLink="false">2502.02334v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Rational Motions of Minimal Quaternionic Degree with Prescribed Plane Trajectories</title>
      <link>http://arxiv.org/abs/2502.02330v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要翻译&lt;/h4&gt;本文研究了生成预定义平面轨迹（即“有理扭线”）的最小四元数度理性运动构造。利用双四元数代数框架，我们将问题表述为多项式方程组的形式。&lt;h4&gt;背景&lt;/h4&gt;在机器人学、计算机辅助设计以及计算几何等领域中，理解及构建具有小代数复杂性的理性运动是一项重要任务。&lt;h4&gt;目的&lt;/h4&gt;旨在探讨生成预定义平面轨迹的最小四元数度理性运动的存在性条件及其构造方法，并建立一个用于实际应用的理论框架。&lt;h4&gt;方法&lt;/h4&gt;利用双四元数代数框架，将问题转化为多项式方程组的形式。通过研究方程组的解来获得必要的和充分的存在性条件，以及解决该问题的方法。&lt;h4&gt;主要发现&lt;/h4&gt;{'存在性条件': '有理扭线作为理性运动轨迹实现的必要且充分条件是其高斯映射为有理函数。', '最小度相关性': '理性运动多项式的最小度与高斯映射的度数下降以及相关的平面多项式结构和向量部分的真实最大公约数有关。', '应用价值': '所得理论框架在机器人学、计算机辅助设计及计算几何等领域具有潜在的应用前景，提供了一种系统化的方法来构建小代数复杂性的理性运动。'}&lt;h4&gt;结论&lt;/h4&gt;本文通过双四元数方法揭示了生成预定义平面轨迹的最小四元数度理性运动的关键条件和构造策略，为相关领域的理论研究与实际应用提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the construction of rational motions with minimal quaternionic degree that generate a prescribed plane trajectory, known as a ``rational torse''. Using dual quaternions algebra framework, we formulate the problem into a system of polynomial equations. We derive necessary and sufficient conditions for the existence of such motions and establish methods to compute solutions and characterize those of minimum degree. Our results indicate that a rational torse can be realized as a trajectory of a rational motion if its Gauss map is rational. Furthermore, we found that the minimal degree of a motion polynomial is geometrically related to the drop in degree of the Gauss mapping and algebraically determined by the structure of the plane polynomial associated with the torse and the real greatest common divisor of its vector part. The theoretical framework developed has potential applications in robotics, computer-aided design, and computational kinematics, offering a systematic approach for constructing rational motions of small algebraic complexity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the construction of rational motions of a minimalquaternionic degree that generate a prescribed plane trajectory (a ``rationaltorse''). Using the algebraic framework of dual quaternions, we formulate theproblem as a system of polynomial equations. We derive necessary and sufficientconditions for the existence of such motions, establish a method to computesolutions and characterize solutions of minimal degree. Our findings revealthat a rational torse is realizable as a trajectory of a rational motion if andonly if its Gauss map is rational. Furthermore, we demonstrate that the minimaldegree of a motion polynomial is geometrically related to a drop of degree ofthe Gauss and algebraically determined by the structure of the torse'sassociated plane polynomial and the real greatest common divisor of its vectorpart. The developed theoretical framework has potential applications inrobotics, computer-aided design, and computational kinematic, offering asystematic approach to constructing rational motions of small algebraiccomplexity.</description>
      <author>example@mail.com (Zülal Derin Yaqub, Hans-Peter Schröcker)</author>
      <guid isPermaLink="false">2502.02330v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Operator Takeover for Visuomotor Diffusion Policy Training</title>
      <link>http://arxiv.org/abs/2502.02308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种实时操作员接管（RTOT）的范式，使操作员可以无缝地接管正在进行中的视觉运动扩散策略，引导系统回到理想状态或强化特定演示。&lt;h4&gt;背景&lt;/h4&gt;现有方法难以在视觉运动任务中实现人类干预与自动控制之间的平滑过渡。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的实时操作员接管方案，并使用马氏距离自动识别不理想的执行状态。&lt;h4&gt;方法&lt;/h4&gt;引入RTOT范式，利用Mahalanobis距离检测异常行为或故障点，确保操作员可以及时介入并纠正问题；随后系统会继续由策略指导直至再次需要干预。&lt;h4&gt;主要发现&lt;/h4&gt;将目标接管演示融入训练中比仅使用初始较长的演示效果更好，提高了策略性能。&lt;h4&gt;结论&lt;/h4&gt;RTOT方法能够有效提升视觉运动系统的鲁棒性和灵活性，同时提供的项目网站包含了初期和接管演示视频以及所有实验数据的支持材料。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种实时操作员接管（RTOT）范式，使操作员可以无缝地接管正在进行中的视觉运动扩散策略。该范式有助于引导系统回归到理想状态或强化特定示范动作，并通过马氏距离自动识别不理想的执行状况。当操作员介入并重新定向系统后，控制权会立即交还给策略继续生成行动直至再次需要干预。我们展示了将目标接管演示融入训练中比仅使用等量但时间更长的初始演示更能显著提高策略性能。此外，我们对利用马氏距离检测异常状态进行了深入分析，并在项目网站上提供了支持材料，包括初期和接管示范视频以及所有实验数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a Real-Time Operator Takeover (RTOT) paradigm enabling operatorsto seamlessly take control of a live visuomotor diffusion policy, guiding thesystem back into desirable states or reinforcing specific demonstrations. Wepresents new insights in using the Mahalonobis distance to automaicaly identifyundesirable states. Once the operator has intervened and redirected the system,the control is seamlessly returned to the policy, which resumes generatingactions until further intervention is required. We demonstrate thatincorporating the targeted takeover demonstrations significantly improvespolicy performance compared to training solely with an equivalent number of,but longer, initial demonstrations. We provide an in-depth analysis of usingthe Mahalanobis distance to detect out-of-distribution states, illustrating itsutility for identifying critical failure points during execution. Supportingmaterials, including videos of initial and takeover demonstrations and allrice-scooping experiments, are available on the project website:https://operator-takeover.github.io/</description>
      <author>example@mail.com (Nils Ingelhag, Jesper Munkeby, Michael C. Welle, Marco Moletta, Danica Kragic)</author>
      <guid isPermaLink="false">2502.02308v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Adviser-Actor-Critic: Eliminating Steady-State Error in Reinforcement Learning Control</title>
      <link>http://arxiv.org/abs/2502.02265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Adviser-Actor-Critic (AAC)算法，该算法结合了反馈控制理论的精确性与强化学习的自适应能力，通过一个导师组件来指导执行者优化其控制动作。&lt;h4&gt;背景&lt;/h4&gt;在高精度任务中，现有的强化学习（RL）算法通常因为网络近似误差和样本质量不足导致性能不理想。特别是当任务要求智能体达到某个特定目标状态时，这些问题更为严重。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够提高精确度的算法，特别是在需要实现精准控制的目标导向型任务中。&lt;h4&gt;方法&lt;/h4&gt;AAC通过引入Adviser组件来指导Actor（执行者），这个组件利用反馈控制理论帮助Actor优化其动作策略，从而提升目标状态达成的精度和可靠性。&lt;h4&gt;主要发现&lt;/h4&gt;在高精度要求的任务中，通过基准测试，AAC算法相对于标准RL算法展示了更高的精度、可靠性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法证明了结合经典反馈控制理论与现代强化学习框架的有效性，并且该方法对于实现精确目标导向任务提供了可行的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;高精度控制系统对强化学习（RL）算法提出了重大挑战，经常导致性能不理想，这主要是由于网络近似误差和样本质量不足所致。这些问题在智能体需要达到特定目标状态的任务中更为显著，如机器人技术和其他现实世界应用。我们介绍了一种结合了反馈控制理论的精确性和强化学习自适应能力的新方法——Adviser-Actor-Critic（AAC），其中Advisor组件指导执行者优化其动作策略，从而提高目标达成精度。通过在高精度、目标导向型任务中的基准测试，AAC算法展示了优于标准RL算法的表现，在精度、可靠性和鲁棒性方面都有所突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-precision control tasks present substantial challenges for reinforcementlearning (RL) algorithms, frequently resulting in suboptimal performanceattributed to network approximation inaccuracies and inadequate samplequality.These issues are exacerbated when the task requires the agent toachieve a precise goal state, as is common in robotics and other real-worldapplications.We introduce Adviser-Actor-Critic (AAC), designed to address theprecision control dilemma by combining the precision of feedback control theorywith the adaptive learning capability of RL and featuring an Adviser thatmentors the actor to refine control actions, thereby enhancing the precision ofgoal attainment.Finally, through benchmark tests, AAC outperformed standard RLalgorithms in precision-critical, goal-conditioned tasks, demonstrating AAC'shigh precision, reliability, and robustness.Code are available at:https://anonymous.4open.science/r/Adviser-Actor-Critic-8AC5.</description>
      <author>example@mail.com (Donghe Chen, Yubin Peng, Tengjie Zheng, Han Wang, Chaoran Qu, Lin Cheng)</author>
      <guid isPermaLink="false">2502.02265v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Network Digital Twin for 5G-Enabled Mobile Robots</title>
      <link>http://arxiv.org/abs/2502.02253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;5G技术的成熟和商业化部署使其成为机器人等垂直行业应用的关键推动力。通过提供超低延迟、高速数据传输和广泛覆盖，5G解锁了机器人的自主潜力，并促进了自动移动机器人的新兴应用。&lt;h4&gt;背景&lt;/h4&gt;在动态环境中实时获取网络条件信息是一个重大且实际的挑战。需要对部署环境中的预期网络质量有清晰的理解以确保机器人在网络中的无缝导航和操作。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于机器人收集的实时数据构建网络数字孪生（NDT）的新框架，为动态网络环境中机器人的监控、控制和优化提供全面解决方案。&lt;h4&gt;方法&lt;/h4&gt;开发了一条集成机器人数据到NDT的数据流管道，并展示了其在无线感知导航用例中的演化过程，使用真实世界的机器人轨迹进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够增强5G支持的机器人操作的能量效率和可靠性。通过实证测试，证明了这一方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;这项工作提供了一个强大的工具来解决动态网络环境中实时监测和优化机器人的需求，展示了未来机器人技术在复杂环境中的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经翻译为中文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The maturity and commercial roll-out of 5G networks and its deployment forprivate networks makes 5G a key enabler for various vertical industries andapplications, including robotics. Providing ultra-low latency, high data rates,and ubiquitous coverage and wireless connectivity, 5G fully unlocks thepotential of robot autonomy and boosts emerging robotic applications,particularly in the domain of autonomous mobile robots. Ensuring seamless,efficient, and reliable navigation and operation of robots within a 5G networkrequires a clear understanding of the expected network quality in thedeployment environment. However, obtaining real-time insights into networkconditions, particularly in highly dynamic environments, presents a significantand practical challenge. In this paper, we present a novel framework forbuilding a Network Digital Twin (NDT) using real-time data collected by robots.This framework provides a comprehensive solution for monitoring, controlling,and optimizing robotic operations in dynamic network environments. We develop apipeline integrating robotic data into the NDT, demonstrating its evolutionwith real-world robotic traces. We evaluate its performances in radio-awarenavigation use case, highlighting its potential to enhance energy efficiencyand reliability for 5Genabled robotic operations.</description>
      <author>example@mail.com (Luis Roda Sanchez, Lanfranco Zanzi, Xi Li, Guillem Gari, Xavier Costa Perez)</author>
      <guid isPermaLink="false">2502.02253v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Human-Aided Trajectory Planning for Automated Vehicles through Teleoperation and Arbitration Graphs</title>
      <link>http://arxiv.org/abs/2502.02207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures, handed in for possible publication at IEEE IV  2025, video demonstration available at  https://www.youtube.com/watch?v=fVSO-YOeGMk&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用仲裁图的模块化决策框架，旨在将远程协助概念无缝地集成到现有的自动驾驶系统中。&lt;h4&gt;背景&lt;/h4&gt;在自动化车辆无法找到适当解决方案的情况下，遥控操作可以提供远程的人类支持。通过向特定的自动化模块（如规划）提供离散输入以辅助其工作，远程协助概念正变得越来越受欢迎，因为它们可以减少人类操作员的工作负担并提高安全性。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决方案来促进在不修改原始软件组件的情况下实施干预于计划层面的远程协助概念，并扩展车辆运行时的操作设计域。&lt;h4&gt;方法&lt;/h4&gt;使用仲裁图这种模块化决策框架将远程援助集成到现有的自动驾驶系统中，无需对现有软件进行改动。通过两个用例展示了该方法如何使操作员能够在超出名义操作设计领域的情况下调整规划器约束并启用轨迹生成。&lt;h4&gt;主要发现&lt;/h4&gt;仿真实施证明了所提出的远程协助解决方案能够有效地提高自动化车辆的安全性和灵活性，同时减少人类操作员的工作负担。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为在实际部署中实现有效的远程协助提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Teleoperation enables remote human support of automated vehicles in scenarioswhere the automation is not able to find an appropriate solution. Remoteassistance concepts, where operators provide discrete inputs to aid specificautomation modules like planning, is gaining interest due to its reducedworkload on the human remote operator and improved safety. However, theseconcepts are challenging to implement and maintain due to their deepintegration and interaction with the automated driving system. In this paper,we propose a solution to facilitate the implementation of remote assistanceconcepts that intervene on planning level and extend the operational designdomain of the vehicle at runtime. Using arbitration graphs, a modulardecision-making framework, we integrate remote assistance into an existingautomated driving system without modifying the original software components.Our simulative implementation demonstrates this approach in two use cases,allowing operators to adjust planner constraints and enable trajectorygeneration beyond nominal operational design domains.</description>
      <author>example@mail.com (Nick Le Large, David Brecht, Willi Poh, Jan-Hendrik Pauls, Martin Lauer, Frank Diermeyer)</author>
      <guid isPermaLink="false">2502.02207v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>VLA-Cache: Towards Efficient Vision-Language-Action Model via Adaptive Token Caching in Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2502.02175v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Vision-Language-Action (VLA)模型能够处理指令和视觉感知，并直接生成动作输出，由于其强大的多模态推理能力，实现了端到端的处理。&lt;h4&gt;背景&lt;/h4&gt;尽管VLA模型性能良好，但它们计算成本较高。这给在需要实时决策以快速响应环境变化的机器人任务中的应用带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的Vision-Language-Action (VLA)模型——VLA-Cache。&lt;h4&gt;方法&lt;/h4&gt;VLA-Cache模型引入了一个令牌选择机制，该机制将每一步的视觉输入与前一步的输入进行比较，并适应性地识别未发生变化的视觉令牌。这些不变的令牌计算结果通过KV缓存在后续步骤中被重复使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，在模拟和实际机器人任务上，VLA-Cache模型能够实现显著的实际加速效果，同时对成功率的影响最小。&lt;h4&gt;结论&lt;/h4&gt;VLA-Cache通过引入令牌选择机制有效地提高了计算效率，并且能够在保持成功概率的同时减少计算成本，为解决实时决策问题提供了一种新的方法。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language-Action (VLA)模型可以通过处理指令和视觉感知来直接生成动作输出，在端到端的方式中展现其强大的多模态推理能力。尽管VLA模型的性能令人满意，但它们高昂的成本带来了挑战，特别是在需要实时决策以应对环境变化的机器人任务中的应用。考虑到机器人的控制涉及顺序决策问题，并且在连续步骤之间的视觉输入往往表现出最小的变化，可以自然地重用前一步中未改变的视觉令牌的计算结果的想法被提出。受到这一想法的启发，我们提出了VLA-Cache，一种高效的Vision-Language-Action模型。该模型采用了一种令牌选择机制，能够对比每个步骤中的视觉输入与上一个步骤中的输入，并适应性识别出变化最小的视觉令牌，然后在后续步骤中通过KV缓存重复使用这些未改变的令牌计算结果，从而显著提高了VLA-Cache模型的效率。实验结果显示，在仿真（例如LIBERO基准和SIMPLER）和真实世界机器人任务上验证的有效VLA-Cache可以实现实际加速，并且仅需微小的成功率牺牲。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language-Action (VLA) model can process instructions and visualperception to directly generate actions as output in an end-to-end fashion dueto its strong multi-modal reasoning capabilities. While the performance of VLAmodels is promising, their computational cost can be substantial. This raiseschallenge for applying them on robotics tasks, which requires real-timedecision-making to respond quickly to environmental changes. Since roboticcontrol involves sequential decision-making, the visual input often exhibitsminimal variation between successive steps. A natural idea is to reuse thecomputational results of unchanged visual tokens from the last step. Motivatedby this idea, we propose VLA-Cache, an efficient vision-language-action model.VLA-Cache incorporates a token-selection mechanism that compares the visualinput at each step with the input from the previous step, adaptivelyidentifying visual tokens with minimal changes. The computational results forthese unchanged tokens are then reused in subsequent steps via KV-cache,thereby significantly improving the efficiency of the VLA-Cache model.Experimental results on both simulation (e.g., LIBERO benchmark and SIMPLER)and real-world robot valid VLA-Cache can achieve practical acceleration withminimal sacrifice in success rate.</description>
      <author>example@mail.com (Siyu Xu, Yunke Wang, Chenghao Xia, Dihao Zhu, Tao Huang, Chang Xu)</author>
      <guid isPermaLink="false">2502.02175v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Risk-Aware Driving Scenario Analysis with Large Language Models</title>
      <link>http://arxiv.org/abs/2502.02145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Intelligent Vehicles Symposium 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用大语言模型（LLMs）进行风险感知分析的新框架，旨在评估自动驾驶仿真系统生成驾驶场景的安全性，并通过对抗方法改进安全检测。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型能够捕捉复杂的语境关系和推理能力，在处理大规模信息方面表现出色。这种技术可以被用于解决特定领域的挑战，包括自动驾驶系统中的难题。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用大语言模型来评估由自主驾驶测试模拟器生成的场景是否具有安全关键性，并验证该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型框架，通过实验来检验LLMs在识别和分类仿真环境生成的驾驶场景时的安全关键性的能力。同时使用对抗方式修改非关键情景以产生新的、更有效的测试案例。&lt;h4&gt;主要发现&lt;/h4&gt;大语言模型能够有效评估自主驾驶仿真器生成的驾驶场景是否具有安全相关性，这为改进自动驾驶系统的安全性提供了一种可能的方法。&lt;h4&gt;结论&lt;/h4&gt;框架通过利用LLMs对潜在危险场景进行识别和分类，促进了自动化测试算法的发展。该研究结果将有助于提高自动驾驶系统中的决策准确性和反应速度。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文已被直接包含在描述中，并且没有额外的翻译部分需要添加。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) can capture nuanced contextual relationships,reasoning, and complex problem-solving. By leveraging their ability to processand interpret large-scale information, LLMs have shown potential to addressdomain-specific challenges, including those in autonomous driving systems. Thispaper proposes a novel framework that leverages LLMs for risk-aware analysis ofgenerated driving scenarios. We hypothesize that LLMs can effectively evaluatewhether driving scenarios generated by autonomous driving testing simulatorsare safety-critical. To validate this hypothesis, we conducted an empiricalevaluation to assess the effectiveness of LLMs in performing this task. Thisframework will also provide feedback to generate the new safety-criticalscenario by using adversarial method to modify existing non-critical scenariosand test their effectiveness in validating motion planning algorithms. Code andscenarios are available at:https://github.com/yuangao-tum/Riskaware-Scenario-analyse</description>
      <author>example@mail.com (Yuan Gao, Mattia Piccinini, Johannes Betz)</author>
      <guid isPermaLink="false">2502.02145v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>DOC-Depth: A novel approach for dense depth ground truth generation</title>
      <link>http://arxiv.org/abs/2502.02144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Code and dataset available on the project page :  https://simondemoreau.github.io/DOC-Depth/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的、高效的深度数据生成方法DOC-Depth，该方法可以从任何LiDAR传感器获取的数据中产生密集的深度信息。&lt;h4&gt;背景&lt;/h4&gt;准确的深度信息对于许多计算机视觉应用至关重要。然而，目前还没有可以大规模动态环境中进行完全密集且精确的深度估计的方法或数据集。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决大规模动态环境中的深度数据生成问题，并提供一个公开的数据集以推动相关研究的发展。&lt;h4&gt;方法&lt;/h4&gt;利用LiDAR测距仪获取数据，通过LiDAR里程计重建出一致且密集的3D环境。同时引入DOC（Dynamic Object Classification）算法自动处理动态物体遮挡的问题。该方法快速、可扩展性强，适合大规模数据集创建。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上，密度从16.1%提升至71.2%，展示了该方法的有效性，并且公开了这一新的密集深度标注以促进未来的研究。&lt;h4&gt;结论&lt;/h4&gt;DOC-Depth不仅适用于多种LiDAR传感器和不同环境，而且所有软件组件都对研究社区开放使用。&lt;h4&gt;翻译&lt;/h4&gt;准确的深度信息对于许多计算机视觉应用至关重要。然而，目前没有可用的数据记录方法能够在大规模动态环境中进行完全密集且精确的深度估计。本文介绍了DOC-Depth，这是一种新的、高效且易于部署的方法，用于从任何LiDAR传感器生成密集的深度数据。在利用LiDAR里程计重建一致的密集3D环境后，我们通过我们的最先进的动态物体分类方法DOC自动解决动态对象遮挡问题。此外，DOC-Depth快速且可扩展，允许创建不受大小和时间限制的数据集。我们在KITTI数据集上展示了这种方法的有效性，将其密度从16.1%提高到71.2%，并发布这一新的完全密集的深度标注，以促进未来的研究进展。我们还展示了使用各种LiDAR传感器以及在多个环境中取得的结果。所有软件组件都公开提供给研究社区使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate depth information is essential for many computer visionapplications. Yet, no available dataset recording method allows for fully denseaccurate depth estimation in a large scale dynamic environment. In this paper,we introduce DOC-Depth, a novel, efficient and easy-to-deploy approach fordense depth generation from any LiDAR sensor. After reconstructing consistentdense 3D environment using LiDAR odometry, we address dynamic objectsocclusions automatically thanks to DOC, our state-of-the art dynamic objectclassification method. Additionally, DOC-Depth is fast and scalable, allowingfor the creation of unbounded datasets in terms of size and time. Wedemonstrate the effectiveness of our approach on the KITTI dataset, improvingits density from 16.1% to 71.2% and release this new fully dense depthannotation, to facilitate future research in the domain. We also showcaseresults using various LiDAR sensors and in multiple environments. All softwarecomponents are publicly available for the research community.</description>
      <author>example@mail.com (Simon de Moreau, Mathias Corsia, Hassan Bouchiba, Yasser Almehio, Andrei Bursuc, Hafid El-Idrissi, Fabien Moutarde)</author>
      <guid isPermaLink="false">2502.02144v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Synthesis of Model Predictive Control and Reinforcement Learning: Survey and Classification</title>
      <link>http://arxiv.org/abs/2502.02133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型预测控制（MPC）和强化学习（RL）是两种用于马尔可夫决策过程的成功控制技术。&lt;h4&gt;目的&lt;/h4&gt;探讨这两种方法的异同及其根本原理，并分析如何结合两者的优势以提升系统性能。&lt;h4&gt;主要发现&lt;/h4&gt;[{'发现1': '尽管MPC和RL在某些方面相似，但它们源自不同的社区并且有不同的需求，因此遵循不同的范式'}, {'发现2': '环境模型作为算法的一部分，在这两种方法中扮演的角色不同，导致了几乎互补的优势'}, {'发现3': '由于两者提供的正交优势，最近的研究兴趣转向结合MPC和RL的方法'}]&lt;h4&gt;结论&lt;/h4&gt;提出了一种基于通用的actor-critic RL方法来分类现有工作，并探讨如何利用MPC在线优化技术提升策略的整体闭环性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要中描述了模型预测控制（MPC）和强化学习（RL）作为两种成功用于马尔可夫决策过程的控制手段。尽管两者都广泛应用于机器人、工艺控制、能源系统和自动驾驶等领域，并且基于相似的基本原理，但是它们源于不同的社区并且满足不同需求，因此遵循截然不同的范式。环境模型的角色差异导致了这些方法几乎互补的优势。由于MPC与RL各自提供的正交利益，研究者们开始探索结合两者的复杂策略以进一步优化系统性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The fields of MPC and RL consider two successful control techniques forMarkov decision processes. Both approaches are derived from similar fundamentalprinciples, and both are widely used in practical applications, includingrobotics, process control, energy systems, and autonomous driving. Despitetheir similarities, MPC and RL follow distinct paradigms that emerged fromdiverse communities and different requirements. Various technicaldiscrepancies, particularly the role of an environment model as part of thealgorithm, lead to methodologies with nearly complementary advantages. Due totheir orthogonal benefits, research interest in combination methods hasrecently increased significantly, leading to a large and growing set of complexideas leveraging MPC and RL. This work illuminates the differences,similarities, and fundamentals that allow for different combination algorithmsand categorizes existing work accordingly. Particularly, we focus on theversatile actor-critic RL approach as a basis for our categorization andexamine how the online optimization approach of MPC can be used to improve theoverall closed-loop performance of a policy.</description>
      <author>example@mail.com (Rudolf Reiter, Jasper Hoffmann, Dirk Reinhardt, Florian Messerer, Katrin Baumgärtner, Shamburaj Sawant, Joschka Boedecker, Moritz Diehl, Sebastien Gros)</author>
      <guid isPermaLink="false">2502.02133v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>The Induced Matching Distance: A Novel Topological Metric with Applications in Robotics</title>
      <link>http://arxiv.org/abs/2502.02112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的拓扑度量——诱导匹配距离，用于比较由对称非负函数表示的离散结构。该方法通过动态时间规整来衡量轨迹相似性，并使用0维持续同调来识别相关的连通组件。&lt;h4&gt;背景&lt;/h4&gt;目前缺少一种有效的拓扑度量能够同时捕捉到时间和空间的变化以分析多智能体系统的轨迹特征和行为模式。&lt;h4&gt;目的&lt;/h4&gt;引入诱导匹配距离这一新的度量标准，用于描述随时间变化的离散结构（如机器人路径）的动态演化过程。&lt;h4&gt;方法&lt;/h4&gt;使用动态时间规整技术来衡量轨迹相似性；利用0维持续同调算法找到有意义的时间连通组件。计算这些组件之间的诱导匹配距离以跟踪它们随时间的变化情况，从而得到表示轨迹组稳定性的1维信号。&lt;h4&gt;主要发现&lt;/h4&gt;该研究成功地区分了不同智能体的行为模式，并展示了其在机器人科学及其他相关领域作为强大工具的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为分析多智能体系统中的行为和结构变化提供了一种新的视角，尤其适用于那些需要同时考虑时间和空间因素的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the induced matching distance, a novel topologicalmetric designed to compare discrete structures represented by a symmetricnon-negative function. We apply this notion to analyze agent trajectories overtime. We use dynamic time warping to measure trajectory similarity and computethe 0-dimensional persistent homology to identify relevant connectedcomponents, which, in our context, correspond to groups of similartrajectories. To track the evolution of these components across time, wecompute induced matching distances, which preserve the coherence of theirdynamic behavior. We then obtain a 1-dimensional signal that quantifies theconsistency of trajectory groups over time. Our experiments demonstrate thatour approach effectively differentiates between various agent behaviors,highlighting its potential as a robust tool for topological analysis inrobotics and related fields.</description>
      <author>example@mail.com (Javier Perera-Lago, Álvaro Torras-Casas, Jérôme Guzzi, Rocio Gonzalez-Diaz)</author>
      <guid isPermaLink="false">2502.02112v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement</title>
      <link>http://arxiv.org/abs/2502.02067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE International Conference on Robotics and Automation  (ICRA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种框架，该框架结合了大型语言模型（LLM）的泛化预测和领域特定知识图谱（KG），以使实体代理能够快速适应新任务和场景。&lt;h4&gt;背景&lt;/h4&gt;实体代理常常需要在新的场景中执行未训练过的任务。在这种情况下，往往缺乏足够的资源来重新培训代理。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法框架，使得实体代理能在有限的资源下高效地完成未知的任务或进入陌生的领域。&lt;h4&gt;方法&lt;/h4&gt;利用大型语言模型预测抽象动作序列，并结合知识图谱中的先验特定领域知识以及必要的人类输入，使机器人能够适应新的任务和场景。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验评估，在模拟环境下的烹饪和清洁任务中证明了LLM、KG与人类输入的交互带来了显著的表现提升。&lt;h4&gt;结论&lt;/h4&gt;该框架为实体代理在多种任务类型中的快速适应性提供了解决方案，表明这种方法在实际应用中有较高的潜力和价值。&lt;h4&gt;翻译&lt;/h4&gt;实体助手经常被要求在一个新的场景下完成一项新任务。例如，在厨房根据已知食谱准备特定菜肴的代理可能需要去制作新菜或是在储藏室执行清洁任务。由于缺乏足够的资源（如时间或标注实例），很难为这些新情况重新训练代理。然而，大型语言模型（LLMs）能够对许多领域的广泛知识进行训练，从而预测新的任务和场景下的抽象动作序列，尽管实体代理可能因为任务、自身属性或者领域特定限制而无法执行这些动作。我们的框架通过利用LLM提供的泛化预测以及在知识图谱中编码的先前特定领域知识，来应对这种挑战，使一个代理能够快速适应新任务和场景。机器人也会根据需要寻求并使用人类输入以完善其现有知识。基于模拟环境下的烹饪和清洁任务实验评估，我们证明了LLM、KG与人类输入之间的交互相比仅依赖于LLM输出带来了显著的表现提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied agents assisting humans are often asked to complete a new task in anew scenario. An agent preparing a particular dish in the kitchen based on aknown recipe may be asked to prepare a new dish or to perform cleaning tasks inthe storeroom. There may not be sufficient resources, e.g., time or labeledexamples, to train the agent for these new situations. Large Language Models(LLMs) trained on considerable knowledge across many domains are able topredict a sequence of abstract actions for such new tasks and scenarios,although it may not be possible for the agent to execute this action sequencedue to task-, agent-, or domain-specific constraints. Our framework addressesthese challenges by leveraging the generic predictions provided by LLM and theprior domain-specific knowledge encoded in a Knowledge Graph (KG), enabling anagent to quickly adapt to new tasks and scenarios. The robot also solicits anduses human input as needed to refine its existing knowledge. Based onexperimental evaluation over cooking and cleaning tasks in simulation domains,we demonstrate that the interplay between LLM, KG, and human input leads tosubstantial performance gains compared with just using the LLM output.</description>
      <author>example@mail.com (Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna)</author>
      <guid isPermaLink="false">2502.02067v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Anticipate &amp; Act : Integrating LLMs and Classical Planning for Efficient Task Execution in Household Environments</title>
      <link>http://arxiv.org/abs/2502.02066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE International Conference on Robotics and Automation  (ICRA) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新的框架通过少量提示来利用大语言模型的通用知识，实现高级任务预测，并将这些预测的任务作为经典规划系统的目标，计算出能够共同完成多个任务的动作序列。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的任务预见方法使用数据驱动深度网络和大型语言模型（LLM），但它们通常在高层次任务上操作或需要大量的训练样本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架来提高家务助手执行任务时的效率，通过利用大语言模型的知识进行高级任务预测，并计算出一个动作序列以共同完成多个预见的任务。&lt;h4&gt;方法&lt;/h4&gt;该框架利用大语言模型的通用知识通过少量提示来进行高级任务预测，并将这些预测的任务作为经典规划系统的目标，以此来计算能够共同实现这些目标的动作序列。在VirtualHome环境中对框架的能力进行了实际场景下的验证和评估。&lt;h4&gt;主要发现&lt;/h4&gt;与不考虑预见任务的系统相比，在真实情况下实现了执行时间31%的减少。&lt;h4&gt;结论&lt;/h4&gt;通过利用大语言模型的知识进行高级任务预测并计算出一个动作序列来共同完成多个任务，可以显著提高家务助手的工作效率。&lt;h4&gt;翻译&lt;/h4&gt;辅助代理在执行诸如铺床或做早餐之类的家庭任务时通常会一次只计算和执行实现单个任务的动作。然而，可以通过预见即将出现的任务，并计算能够同时实现这些任务的一系列动作来提高效率。最先进的方法使用数据驱动的深度网络和大型语言模型（LLM）来进行任务预测，但它们往往在高层次任务上操作或需要大量的训练样本。我们的框架通过少量提示利用大语言模型的知识进行高级任务预测，然后在经典规划系统中将这些预见的任务作为目标，以此来计算一个动作序列以共同实现多个目标。我们在VirtualHome环境中对框架的能力进行了实际场景下的验证和评估，并且展示了与不考虑预见任务的系统相比，在执行时间上减少了31%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Assistive agents performing household tasks such as making the bed or cookingbreakfast often compute and execute actions that accomplish one task at a time.However, efficiency can be improved by anticipating upcoming tasks andcomputing an action sequence that jointly achieves these tasks.State-of-the-art methods for task anticipation use data-driven deep networksand Large Language Models (LLMs), but they do so at the level of high-leveltasks and/or require many training examples. Our framework leverages thegeneric knowledge of LLMs through a small number of prompts to performhigh-level task anticipation, using the anticipated tasks as goals in aclassical planning system to compute a sequence of finer-granularity actionsthat jointly achieve these goals. We ground and evaluate our framework'sabilities in realistic scenarios in the VirtualHome environment and demonstratea 31% reduction in execution time compared with a system that does not considerupcoming tasks.</description>
      <author>example@mail.com (Raghav Arora, Shivam Singh, Karthik Swaminathan, Ahana Datta, Snehasis Banerjee, Brojeshwar Bhowmick, Krishna Murthy Jatavallabhula, Mohan Sridharan, Madhava Krishna)</author>
      <guid isPermaLink="false">2502.02066v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>RAPID: Robust and Agile Planner Using Inverse Reinforcement Learning for Vision-Based Drone Navigation</title>
      <link>http://arxiv.org/abs/2502.02054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 11 figures, 58 references, and appendix is included&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于学习的视觉规划器，用于在复杂环境中进行无人机敏捷飞行。该规划器能在毫秒级生成无碰撞航点。&lt;h4&gt;背景&lt;/h4&gt;现有的基于行为克隆（BC）和强化学习（RL）的方法在基于视觉导航中表现出了潜力，但面临着累积错误、奖励函数设计困难等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种逆向强化学习（IRL）框架来解决现有方法的局限性，并通过收集来自不同环境的数据集提高算法的鲁棒性和性能。&lt;h4&gt;方法&lt;/h4&gt;1. 采用基于动作原语的路径规划算法，利用特权地图数据从多种环境中采集专家数据集；2. 结合获取到的专家和学习者数据集，在各种状态下进行奖励函数及策略的学习。3. 所提方法仅在仿真环境训练中完成，并可以直接应用于现实场景。&lt;h4&gt;主要发现&lt;/h4&gt;该研究首次成功应用逆向强化学习框架于高速视觉导航，实验结果表明所提出的政策能够达到7 m/s的平均速度和8.8 m/s的最大速度。&lt;h4&gt;结论&lt;/h4&gt;提出的方法展示了在复杂环境中进行无人机敏捷飞行的强大潜力，并且可以直接应用于实际场景中而无需额外训练或调整。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了一种用于在拥挤环境中的敏捷无人机飞行的学习型视觉规划器。所提出的规划器能够在毫秒内生成无碰撞的航点，使无人机能够执行复杂环境中不借助单独感知、映射和计划模块进行的敏捷机动操作。尽管基于行为克隆（BC）和强化学习（RL）的方法在视觉导航中表现出色但仍存在累积错误及奖励函数设计困难等问题。为了解决这些问题，论文提出了一个适用于高速视觉导航的逆向强化学习框架，并通过减少与仿真环境互动次数和改善处理高维空间的能力来增强鲁棒性。该方法利用动作原语进行路径规划收集了来自各种环境的专家数据集，确保全面覆盖场景。同时结合从代理与其模拟环境相互作用中获得的学习者数据集进行奖励函数及策略学习。尽管所提出的方法仅在仿真环境中训练完成，但可以直接应用于现实情况而无需额外培训或调整。该方法性能已在模拟和实际飞行测试中得到验证，包括森林和各种结构在内的复杂场景，实飞实验达到了平均速度7米/秒和最大速度8.8米/秒的优异表现。据我们所知，这是首次成功应用逆向强化学习框架进行高速视觉导航的研究成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a learning-based visual planner for agile drone flightin cluttered environments. The proposed planner generates collision-freewaypoints in milliseconds, enabling drones to perform agile maneuvers incomplex environments without building separate perception, mapping, andplanning modules. Learning-based methods, such as behavior cloning (BC) andreinforcement learning (RL), demonstrate promising performance in visualnavigation but still face inherent limitations. BC is susceptible tocompounding errors due to limited expert imitation, while RL struggles withreward function design and sample inefficiency. To address these limitations,this paper proposes an inverse reinforcement learning (IRL)-based framework forhigh-speed visual navigation. By leveraging IRL, it is possible to reduce thenumber of interactions with simulation environments and improve capability todeal with high-dimensional spaces while preserving the robustness of RLpolicies. A motion primitive-based path planning algorithm collects an expertdataset with privileged map data from diverse environments, ensuringcomprehensive scenario coverage. By leveraging both the acquired expert andlearner dataset gathered from the agent's interactions with the simulationenvironments, a robust reward function and policy are learned across diversestates. While the proposed method is trained in a simulation environment only,it can be directly applied to real-world scenarios without additional trainingor tuning. The performance of the proposed method is validated in bothsimulation and real-world environments, including forests and variousstructures. The trained policy achieves an average speed of 7 m/s and a maximumspeed of 8.8 m/s in real flight experiments. To the best of our knowledge, thisis the first work to successfully apply an IRL framework for high-speed visualnavigation of drones.</description>
      <author>example@mail.com (Minwoo Kim, Geunsik Bae, Jinwoo Lee, Woojae Shin, Changseung Kim, Myong-Yol Choi, Heejung Shin, Hyondong Oh)</author>
      <guid isPermaLink="false">2502.02054v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Sound Judgment: Properties of Consequential Sounds Affecting Human-Perception of Robots</title>
      <link>http://arxiv.org/abs/2502.02051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 6 figures - Accepted to be published in the conference  proceedings for HRI'25 - the 20th IEEE/ACM International Conference on  Human-Robot Interaction. This paper has a companion paper: arXiv:2406.02938  Copyright 2025 IEEE. Personal use of this material is permitted. Permission  from IEEE must be obtained for all other uses, in any current or future media&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过分析参与者对不同机器人声音的反应，探讨了人类对机器人操作过程中产生的后续声音的好恶偏好。&lt;h4&gt;背景&lt;/h4&gt;积极的人类感知对于机器人在共享环境中的持续使用至关重要。机器发出的声音是影响人类感受的关键因素之一。&lt;h4&gt;目的&lt;/h4&gt;探索人们对于机器人产生后果性声音的态度和看法，以改善人机互动体验。&lt;h4&gt;方法&lt;/h4&gt;研究让182名参与者观看不同机器人执行典型动作的视频，并通过在线调查收集他们对机器人及其声音的看法。&lt;h4&gt;主要发现&lt;/h4&gt;{'喜欢的声音特点': '偏好信息丰富且可听见的声音，这些声音能提供机器的目的和轨迹预测。', '不喜欢的声音特点': '大多数受访者不喜欢高音调和响亮的声音。', '更想要的声音': '节奏性声音优于尖锐或持续的噪音；许多参与者希望机器人发出自然声（如风声、猫叫声）代替机械噪声。', '偏好变化': '虽然多数人不喜欢单一类型的后果性声音，但他们倾向于支持提供信息和可预测性的声音。'}&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了改进机器人产生负面感知的声音的特征，并为改善人类对机器人的感受提供了见解，从而增强人机互动。&lt;h4&gt;翻译&lt;/h4&gt;积极的人类对于机器人的感知是至关重要的，这对于在共享环境中持续使用机器人来说至关重要。影响人类对机器人感知的一个关键因素就是他们的声音，特别是作为机械设备必然产生的操作过程中发出的后果性声音。这项研究通过分析182名参与者的定性反应来深入了解人们对机器人后果性声音的看法。参与者观看了不同类型的机器人执行典型动作的视频，并在在线调查中回答了他们对机器人及其声音的态度。使用主题分析方法识别了受访者表达出喜欢、不喜欢、希望或避免听到机器人的常见后果性声音的特点。除了预期报告中的高音调和大声的声音会让人反感外，许多参与者还偏好有信息量且可听见的声音（而非没有声音），因为这些声音可以提供关于机器人目的和轨迹的预测性。与尖锐或连续的噪音相比，节奏性的声音更受欢迎；很多受访者希望听到自然界的声音（如风声、猫叫声）代替机器噪声。本文呈现的研究成果支持未来研究方法的发展，以改善由机器人产生的后果性声音，并突出产生负面感知的声音特征，同时为提升人类对机器人的感受提供了见解，从而增强人机互动体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Positive human-perception of robots is critical to achieving sustained use ofrobots in shared environments. One key factor affecting human-perception ofrobots are their sounds, especially the consequential sounds which robots (asmachines) must produce as they operate. This paper explores qualitativeresponses from 182 participants to gain insight into human-perception of robotconsequential sounds. Participants viewed videos of different robots performingtheir typical movements, and responded to an online survey regarding theirperceptions of robots and the sounds they produce. Topic analysis was used toidentify common properties of robot consequential sounds that participantsexpressed liking, disliking, wanting or wanting to avoid being produced byrobots. Alongside expected reports of disliking high pitched and loud sounds,many participants preferred informative and audible sounds (over no sound) toprovide predictability of purpose and trajectory of the robot. Rhythmic soundswere preferred over acute or continuous sounds, and many participants wantedmore natural sounds (such as wind or cat purrs) in-place of machine-like noise.The results presented in this paper support future research on methods toimprove consequential sounds produced by robots by highlighting features ofsounds that cause negative perceptions, and providing insights into soundprofile changes for improvement of human-perception of robots, thus enhancinghuman robot interaction.</description>
      <author>example@mail.com (Aimee Allen, Tom Drummond, Dana Kulić)</author>
      <guid isPermaLink="false">2502.02051v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>From Human Hands to Robotic Limbs: A Study in Motor Skill Embodiment for Telemanipulation</title>
      <link>http://arxiv.org/abs/2502.02036v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种使用人体手臂手势控制冗余自由度机器人操作器的远程控制系统。&lt;h4&gt;背景&lt;/h4&gt;现有系统在利用人类自然的手势来远程操控复杂机械臂方面存在局限性，特别是在捕捉和理解复杂的关节运动学特性上。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够通过学习机器人的配置空间表示并实时生成对应轨迹的方法，从而使得机器人操作器可以模仿和生成新的姿态。&lt;h4&gt;方法&lt;/h4&gt;采用基于GRU的变分自动编码器来学习机械臂配置空间的潜在表示，并使用全连接神经网络将人类手臂的姿态映射到这种潜在空间中。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在没有训练过的特征下，从人类手势产生新颖的操作器姿态，展示了在远程操作机械臂方面的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;这种方法为通过人体自然手势控制复杂的机器人提供了新的可能性，并且能够实时生成与手势相对应的机器人动作。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：本文提出了一种使用人体手臂手势控制冗余自由度机器人操作器的远程控制系统。我们提出了一个基于GRU的变分自动编码器，以学习机器人的配置空间表示，捕捉其复杂的关节运动学特性。全连接神经网络将人类手臂的姿态映射到这种潜在空间中，允许系统实时模仿和生成对应的机械臂轨迹。所提出的方法在远程操作机器人方面显示出有希望的结果，能够从训练数据中没有出现的人类特征生成新的机器人物姿。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a teleoperation system for controlling a redundant degreeof freedom robot manipulator using human arm gestures. We propose a GRU-basedVariational Autoencoder to learn a latent representation of the manipulator'sconfiguration space, capturing its complex joint kinematics. A fully connectedneural network maps human arm configurations into this latent space, allowingthe system to mimic and generate corresponding manipulator trajectories in realtime through the VAE decoder. The proposed method shows promising results inteleoperating the manipulator, enabling the generation of novel manipulatorconfigurations from human features that were not present during training.</description>
      <author>example@mail.com (Haoyi Shi, Mingxi Su, Ted Morris, Vassilios Morellas, Nikolaos Papanikolopoulos)</author>
      <guid isPermaLink="false">2502.02036v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>Online Adaptive Traversability Estimation through Interaction for Unstructured, Densely Vegetated Environments</title>
      <link>http://arxiv.org/abs/2502.01987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了一种新的基于激光雷达的在线自适应通过性估计方法，用于自主地面车辆在密集植被环境中导航。&lt;h4&gt;背景&lt;/h4&gt;在密集植被环境下行驶对自动驾驶地面车辆提出了重大挑战。学习系统通常使用先验和现场数据来预测地形可通过性，但在遇到由环境快速变化或新条件引起的分布外元素时性能往往会下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的、仅基于激光雷达的在线自适应通过性估计方法，该方法直接在机器人上利用机器人与环境互动收集到的自我监督数据进行训练。&lt;h4&gt;方法&lt;/h4&gt;该方法使用概率3D体素表示法来整合激光雷达测量和机器人的经验，创建显著的环境模型。为了确保计算效率，采用了基于稀疏图的表示法来更新暂时演化的体素分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该系统能够在仅有8分钟的操作数据的情况下适应复杂的环境，并在密集植被环境中实现安全导航（Matthews相关系数MCC得分为0.63）。&lt;h4&gt;结论&lt;/h4&gt;论文探讨了针对基于体素的通过性估计方法的不同训练策略，并提出提高适应性的训练策略建议。所提方法在计算资源有限的机器人平台上验证，其准确性可与离线训练模型相媲美，在各种环境中均保持可靠性能。&lt;h4&gt;翻译&lt;/h4&gt;导航密集植被环境对自主地面车辆构成重大挑战。基于学习的方法通常利用先验和现场数据预测地形通过性，但面对由快速环境变化或新条件引起的分布外元素时性能会下降。本文提出一种新的、仅依赖激光雷达的在线自适应通过性估计方法，在机器人上直接训练模型，并使用机器人与环境互动中收集到的自我监督数据。该方法利用概率3D体素表示，将激光雷达测量和机器人的经验整合起来，创建显著的环境模型。为了确保计算效率，采用基于稀疏图的方法更新暂时演化的体素分布。通过无人驾驶地面车辆在自然地形上的大量实验显示，系统仅用8分钟的操作数据就能适应复杂环境，并实现了0.63的Matthews相关系数评分，在密集植被环境中实现安全导航。该研究还探讨了不同训练策略以改进基于体素的TE方法的可扩展性，并提供提高适应性的建议。在计算资源有限（25W GPU）的机器人平台上验证所提方法，其准确性与离线训练模型相当，且能够在各种环境条件下保持可靠性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating densely vegetated environments poses significant challenges forautonomous ground vehicles. Learning-based systems typically use prior andin-situ data to predict terrain traversability but often degrade in performancewhen encountering out-of-distribution elements caused by rapid environmentalchanges or novel conditions. This paper presents a novel, lidar-only, onlineadaptive traversability estimation (TE) method that trains a model directly onthe robot using self-supervised data collected through robot-environmentinteraction. The proposed approach utilises a probabilistic 3D voxelrepresentation to integrate lidar measurements and robot experience, creating asalient environmental model. To ensure computational efficiency, a sparsegraph-based representation is employed to update temporarily evolving voxeldistributions. Extensive experiments with an unmanned ground vehicle in naturalterrain demonstrate that the system adapts to complex environments with aslittle as 8 minutes of operational data, achieving a Matthews CorrelationCoefficient (MCC) score of 0.63 and enabling safe navigation in denselyvegetated environments. This work examines different training strategies forvoxel-based TE methods and offers recommendations for training strategies toimprove adaptability. The proposed method is validated on a robotic platformwith limited computational resources (25W GPU), achieving accuracy comparableto offline-trained models while maintaining reliable performance across variedenvironments.</description>
      <author>example@mail.com (Fabio A. Ruetz, Nicholas Lawrance, Emili Hernández, Paulo V. K. Borges, Thierry Peynot)</author>
      <guid isPermaLink="false">2502.01987v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>DHP: Discrete Hierarchical Planning for Hierarchical Reinforcement Learning Agents</title>
      <link>http://arxiv.org/abs/2502.01956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于层次强化学习（HRL）的离散层级规划（DHP）方法，用于解决长时视觉规划任务。通过理论和实证分析展示了其有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的距离基线方法在处理长时视觉规划任务中存在局限性，需要新的解决方案来提高效率和性能。&lt;h4&gt;目的&lt;/h4&gt;提出并验证一种新颖的层次强化学习方法（DHP），以改进长时视觉规划问题中的计划构建。&lt;h4&gt;方法&lt;/h4&gt;该方法通过递归预测次级目标，在长期目标背景下运行，并采用基于抽象动作组合的离散奖励机制。引入了新的优势估计策略，鼓励生成较短的规划路径并允许超出最大树深度的一般化。训练过程中使用软演员评论家（SAC）框架和想象数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在长时视觉规划任务中，该方法显著优于先前基准测试的成功率和平均集长度，并且通过消融研究证明了关键模块对整体性能的重要贡献。&lt;h4&gt;结论&lt;/h4&gt;提出的DHP方法能够有效地解决层次强化学习中的挑战性问题，为未来的相关研究提供了理论基础和支持。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们解决了长时视觉规划任务的挑战，使用分层强化学习（HRL）。我们的关键贡献是一种离散层级规划（DHP）的方法，作为传统基于距离方法的替代方案。我们提供该方法的理论基础，并通过广泛的实证评估证明其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the challenge of long-horizon visual planning tasksusing Hierarchical Reinforcement Learning (HRL). Our key contribution is aDiscrete Hierarchical Planning (DHP) method, an alternative to traditionaldistance-based approaches. We provide theoretical foundations for the methodand demonstrate its effectiveness through extensive empirical evaluations.  Our agent recursively predicts subgoals in the context of a long-term goaland receives discrete rewards for constructing plans as compositions ofabstract actions. The method introduces a novel advantage estimation strategyfor tree trajectories, which inherently encourages shorter plans and enablesgeneralization beyond the maximum tree depth. The learned policy functionallows the agent to plan efficiently, requiring only $\log N$ computationalsteps, making re-planning highly efficient. The agent, based on a soft-actorcritic (SAC) framework, is trained using on-policy imagination data.Additionally, we propose a novel exploration strategy that enables the agent togenerate relevant training examples for the planning modules. We evaluate ourmethod on long-horizon visual planning tasks in a 25-room environment, where itsignificantly outperforms previous benchmarks at success rate and averageepisode length. Furthermore, an ablation study highlights the individualcontributions of key modules to the overall performance.</description>
      <author>example@mail.com (Shashank Sharma, Janina Hoffmann, Vinay Namboodiri)</author>
      <guid isPermaLink="false">2502.01956v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>HeRCULES: Heterogeneous Radar Dataset in Complex Urban Environment for Multi-session Radar SLAM</title>
      <link>http://arxiv.org/abs/2502.01946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2025 IEEE International Conference on Robotics and Automation (ICRA  2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的多模态雷达数据集HeRCULES，该数据集结合了不同类型雷达的优势，并且包含了FMCW LiDAR、IMU、GPS和相机等传感器。&lt;h4&gt;背景&lt;/h4&gt;近年来，雷达在机器人技术中因其在恶劣天气条件下的鲁棒性而广泛使用。现有的数据集中通常只包含一种类型的雷达，导致算法开发局限于特定的雷达类型。&lt;h4&gt;目的&lt;/h4&gt;通过整合不同类型雷达的数据集来促进多场景研究，并推出首个结合4D雷达和旋转式雷达与FMCW LiDAR的综合数据集。&lt;h4&gt;方法&lt;/h4&gt;构建了HeRCULES数据集，它包含多样化天气、光照条件以及城市交通场景下的多传感器类型（包括但不限于雷达、LiDAR、IMU等）的数据。&lt;h4&gt;主要发现&lt;/h4&gt;新的HeRCULES数据集为定位、地图绘制和地点识别提供了无与伦比的能力，并且通过提供多次访问路径和每个传感器的真实位置，增强了其在地方识别研究中的适用性。&lt;h4&gt;结论&lt;/h4&gt;预计该数据集将促进里程计估计、地图构建、地点识别以及传感器融合领域的进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;最近，雷达因其在恶劣天气条件下的鲁棒性而在机器人技术中广泛应用。两种常用的类型是旋转式雷达和相控阵雷达，它们各自提供不同的传感器特性。现有的数据集中通常只包含一种类型的雷达，这限制了算法的发展。在此工作中，我们强调结合不同类型的雷达可以带来互补的优势，并且可以通过异构雷达数据集来利用这些优势。此外，这个新的数据集促进了多会话和多机器人场景的研究，在这种场景中，每个机器人配备了不同类型雷达。为此，我们介绍了HeRCULES数据集——一个包含多样化传感器（如FMCW LiDAR、IMU、GPS和相机）的综合异构雷达数据集。这是第一个集成4D雷达与旋转式雷达及FMCW LiDAR的数据集，提供无与伦比的定位、制图和地点识别能力。该数据集涵盖了多样的天气和照明条件以及一系列城市交通场景，支持在各种环境下的全面分析。路径序列中多次访问以及每个传感器的真实位置为地方识别研究提供了额外的价值。我们预计HeRCULES数据集将促进里程计估计、地图构建、地方识别及传感器融合的研究。数据集及其开发工具可以在https://sites.google.com/view/herculesdataset找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, radars have been widely featured in robotics for their robustnessin challenging weather conditions. Two commonly used radar types are spinningradars and phased-array radars, each offering distinct sensor characteristics.Existing datasets typically feature only a single type of radar, leading to thedevelopment of algorithms limited to that specific kind. In this work, wehighlight that combining different radar types offers complementary advantages,which can be leveraged through a heterogeneous radar dataset. Moreover, thisnew dataset fosters research in multi-session and multi-robot scenarios whererobots are equipped with different types of radars. In this context, weintroduce the HeRCULES dataset, a comprehensive, multi-modal dataset withheterogeneous radars, FMCW LiDAR, IMU, GPS, and cameras. This is the firstdataset to integrate 4D radar and spinning radar alongside FMCW LiDAR, offeringunparalleled localization, mapping, and place recognition capabilities. Thedataset covers diverse weather and lighting conditions and a range of urbantraffic scenarios, enabling a comprehensive analysis across variousenvironments. The sequence paths with multiple revisits and ground truth posefor each sensor enhance its suitability for place recognition research. Weexpect the HeRCULES dataset to facilitate odometry, mapping, place recognition,and sensor fusion research. The dataset and development tools are available athttps://sites.google.com/view/herculesdataset.</description>
      <author>example@mail.com (Hanjun Kim, Minwoo Jung, Chiyun Noh, Sangwoo Jung, Hyunho Song, Wooseong Yang, Hyesu Jang, Ayoung Kim)</author>
      <guid isPermaLink="false">2502.01946v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>A Comprehensive Study of Bug-Fix Patterns in Autonomous Driving Systems</title>
      <link>http://arxiv.org/abs/2502.01937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript accepted by FSE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;随着自动驾驶系统的复杂性和其在日常生活中的重要性日益增加，了解这些系统中软件错误的性质及其缓解手段变得至关重要。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统面临的维护挑战包括处理实时决策和确保操作失败时的关键安全性。自动化工具在这个领域显示出潜力，但目前对这类系统手动调试和修复过程中遇到的挑战及策略的理解仍然不足。&lt;h4&gt;目的&lt;/h4&gt;本文通过调查两个主要自主驾驶项目Apollo和Autoware中的1,331个错误修正模式来提高系统的可靠性和安全性。&lt;h4&gt;方法&lt;/h4&gt;作者分析了这两个项目的提交历史记录和错误报告，研究了错误症状、根本原因以及错误修复模式。&lt;h4&gt;主要发现&lt;/h4&gt;{'关键发现': '发现了几种主导的错误修复模式，例如路径规划、数据流管理和配置管理相关的模式。此外，还观察到某些类型的错误反复出现且难以彻底消除。', '分类体系': '基于研究成果，提出了一种自动驾驶系统中软件错误分层结构以及15个语法修复模式和27个语义修复模式的分类体系，为错误识别和解决提供指导。', '基准贡献': '提供了包含1,331个ADS错误修复实例的数据集'}&lt;h4&gt;结论&lt;/h4&gt;本研究揭示了自动驾驶系统中软件维护的独特挑战，并提出了提高此类系统可靠性和安全性的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-02-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3715733&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As autonomous driving systems (ADSes) become increasingly complex andintegral to daily life, the importance of understanding the nature andmitigation of software bugs in these systems has grown correspondingly.Addressing the challenges of software maintenance in autonomous driving systems(e.g., handling real-time system decisions and ensuring safety-criticalreliability) is crucial due to the unique combination of real-timedecision-making requirements and the high stakes of operational failures inADSes. The potential of automated tools in this domain is promising, yet thereremains a gap in our comprehension of the challenges faced and the strategiesemployed during manual debugging and repair of such systems. In this paper, wepresent an empirical study that investigates bug-fix patterns in ADSes, withthe aim of improving reliability and safety. We have analyzed the commithistories and bug reports of two major autonomous driving projects, Apollo andAutoware, from 1,331 bug fixes with the study of bug symptoms, root causes, andbug-fix patterns. Our study reveals several dominant bug-fix patterns,including those related to path planning, data flow, and configurationmanagement. Additionally, we find that the frequency distribution of bug-fixpatterns varies significantly depending on their nature and types and thatcertain categories of bugs are recurrent and more challenging to exterminate.Based on our findings, we propose a hierarchy of ADS bugs and two taxonomies of15 syntactic bug-fix patterns and 27 semantic bug-fix patterns that offerguidance for bug identification and resolution. We also contribute a benchmarkof 1,331 ADS bug-fix instances.</description>
      <author>example@mail.com (Yuntianyi Chen, Yuqi Huai, Yirui He, Shilong Li, Changnam Hong, Qi Alfred Chen, Joshua Garcia)</author>
      <guid isPermaLink="false">2502.01937v1</guid>
      <pubDate>Wed, 05 Feb 2025 17:16:59 +0800</pubDate>
    </item>
    <item>
      <title>\underline{E2}Former: A Linear-time \underline{E}fficient and \underline{E}quivariant Trans\underline{former} for Scalable Molecular Modeling</title>
      <link>http://arxiv.org/abs/2501.19216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为E2Former的等变和高效的变换器架构，用于改进大规模系统的建模效率。&lt;h4&gt;背景&lt;/h4&gt;等变图神经网络(EGNNs)在化学、生物学和材料科学中的微尺度系统建模中表现出显著的成功。然而，由于构建边缘特征的成本高昂，这些模型对于大规模系统而言计算上不可行。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的架构以解决现有的图形神经网络在处理大规模系统的计算挑战。&lt;h4&gt;方法&lt;/h4&gt;引入了Wigner 6j卷积(Wigner 6j Conv)，它将计算负担从边转移到节点，同时保留了模型的表达能力和旋转等变性。这种方法通过减少复杂度而提高了效率。&lt;h4&gt;主要发现&lt;/h4&gt;E2Former架构在与传统的SO(3)卷积相比时，实现了7到30倍的速度提升，并且保持了对细节几何信息捕获的能力。&lt;h4&gt;结论&lt;/h4&gt;这种新的方法为大规模和高效的分子建模提供了一条有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;等变图神经网络（EGNNs）在化学、生物学和材料科学中的微尺度系统建模中表现出色，但因构建边缘特征的高昂成本，在处理大型系统时面临计算挑战。本文提出了E2Former架构，结合了Wigner 6j卷积技术，将计算负担从边转移到节点上，提高了效率的同时保持模型的能力。实验表明，这种方法相比传统的SO(3)卷积在速度上有显著提升，同时保持对细节几何信息的捕获能力，为大规模高效的分子建模提供了新的可能方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Equivariant Graph Neural Networks (EGNNs) have demonstrated significantsuccess in modeling microscale systems, including those in chemistry, biologyand materials science. However, EGNNs face substantial computational challengesdue to the high cost of constructing edge features via spherical tensorproducts, making them impractical for large-scale systems. To address thislimitation, we introduce E2Former, an equivariant and efficient transformerarchitecture that incorporates the Wigner $6j$ convolution (Wigner $6j$ Conv).By shifting the computational burden from edges to nodes, the Wigner $6j$ Convreduces the complexity from $O(|\mathcal{E}|)$ to $ O(| \mathcal{V}|)$ whilepreserving both the model's expressive power and rotational equivariance. Weshow that this approach achieves a 7x-30x speedup compared to conventional$\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstratethat the derived E2Former mitigates the computational challenges of existingapproaches without compromising the ability to capture detailed geometricinformation. This development could suggest a promising direction for scalableand efficient molecular modeling.</description>
      <author>example@mail.com (Yunyang Li, Lin Huang, Zhihao Ding, Chu Wang, Xinran Wei, Han Yang, Zun Wang, Chang Liu, Yu Shi, Peiran Jin, Jia Zhang, Mark Gerstein, Tao Qin)</author>
      <guid isPermaLink="false">2501.19216v1</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
  <item>
      <title>E2Former: A Linear-time Efficient and Equivariant Transformer for Scalable Molecular Modeling</title>
      <link>http://arxiv.org/abs/2501.19216v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了一种新的等变且高效的变换器架构E2Former，它通过引入Wigner 6j卷积解决了现有EGNNs在大规模系统中的计算挑战。&lt;h4&gt;背景&lt;/h4&gt;等变图神经网络（EGNN）在化学、生物学和材料科学中建模微观系统的成功显著受到构建边特征的高成本限制，这使得它们对于大型系统来说是不切实际的。&lt;h4&gt;目的&lt;/h4&gt;提出E2Former架构以解决现有EGNNs在大规模系统中的计算挑战问题。&lt;h4&gt;方法&lt;/h4&gt;通过将计算负担从边缘转移到节点上引入Wigner 6j卷积来降低复杂度，并保持模型的表现力和旋转等变性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的E2Former相比传统的SO(3)卷积方法在速度上有7倍到30倍的提升，同时能够捕捉详细的几何信息而不牺牲计算效率。&lt;h4&gt;结论&lt;/h4&gt;这一发展为大规模分子建模提供了有希望的方向，表明了提高效率和可扩展性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;等变图神经网络（EGNN）已经在化学、生物学及材料科学中对微观系统的建模上展现出了显著的成功。然而，由于通过球形张量积构建边特征的成本过高，使得它们在大型系统中变得不切实际。为了解决这一限制，我们提出了E2Former，这是一种等变且高效的变换器架构，它采用了Wigner 6j卷积（Wigner 6j Conv）。通过将计算负担从边缘转移到节点上，这种卷积方法能够降低复杂度，并保持模型的表现力和旋转等变性。我们的方法相较于传统SO(3)卷积获得了7到30倍的速度提升。此外，我们实证结果表明所提出的E2Former在不损害捕捉详细几何信息能力的情况下解决了现有方法的计算挑战问题。这可能预示着大规模且高效分子建模的新方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Equivariant Graph Neural Networks (EGNNs) have demonstrated significantsuccess in modeling microscale systems, including those in chemistry, biologyand materials science. However, EGNNs face substantial computational challengesdue to the high cost of constructing edge features via spherical tensorproducts, making them impractical for large-scale systems. To address thislimitation, we introduce E2Former, an equivariant and efficient transformerarchitecture that incorporates the Wigner $6j$ convolution (Wigner $6j$ Conv).By shifting the computational burden from edges to nodes, the Wigner $6j$ Convreduces the complexity from $O(|\mathcal{E}|)$ to $ O(| \mathcal{V}|)$ whilepreserving both the model's expressive power and rotational equivariance. Weshow that this approach achieves a 7x-30x speedup compared to conventional$\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstratethat the derived E2Former mitigates the computational challenges of existingapproaches without compromising the ability to capture detailed geometricinformation. This development could suggest a promising direction for scalableand efficient molecular modeling.</description>
      <author>example@mail.com (Yunyang Li, Lin Huang, Zhihao Ding, Chu Wang, Xinran Wei, Han Yang, Zun Wang, Chang Liu, Yu Shi, Peiran Jin, Jia Zhang, Mark Gerstein, Tao Qin)</author>
      <guid isPermaLink="false">2501.19216v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>What is causal about causal models and representations?</title>
      <link>http://arxiv.org/abs/2501.19335v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个形式框架，用于明确不同行动解释为干预要求，并证明了自然的行动干预解释是循环的。&lt;h4&gt;背景&lt;/h4&gt;因果贝叶斯网络通过预测干预分布来连接模型预测与现实世界结果。为了使这种联系有效，必须确定哪些实际操作对应于模型中的哪种干预。&lt;h4&gt;目的&lt;/h4&gt;开发一个形式框架以精确描述将各种行为视为干预的要求，并探讨该框架对因果表示学习、因果发现和因果抽象的理论贡献及其局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了正式框架并证明了自然行动解释为循环且不能验证模型，进而探索非循环但可能违反某些标准的其他解释方式。&lt;h4&gt;主要发现&lt;/h4&gt;证明了任何正确模拟观察分布的因果贝叶斯网络在自然解释下均被视为干预有效，并提出了一种不可能性结果：不存在既非循环又能满足特定期望条件的解释。&lt;h4&gt;结论&lt;/h4&gt;该形式框架有助于深化对因果模型作为世界‘原因’模型而非数学对象的理解，指出了现有方法的一些局限性。&lt;h4&gt;翻译&lt;/h4&gt;因果贝叶斯网络是'因果'模型，因为它们预测干预分布。为了将此类因果模型预测与现实结果联系起来，必须确定哪种行动对应于模型中的哪类干预。我们引入了一个正式框架来精确说明不同行为解释为干预的要求，并证明自然的解释会导致循环性问题且不能验证模型的有效性。进一步探讨了非循环但可能违反某些条件的其他解释方式及其对因果表示学习和发现的影响，同时指出了现有方法的一些局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal Bayesian networks are 'causal' models since they make predictionsabout interventional distributions. To connect such causal model predictions toreal-world outcomes, we must determine which actions in the world correspond towhich interventions in the model. For example, to interpret an action as anintervention on a treatment variable, the action will presumably have to a)change the distribution of treatment in a way that corresponds to theintervention, and b) not change other aspects, such as how the outcome dependson the treatment; while the marginal distributions of some variables may changeas an effect. We introduce a formal framework to make such requirements fordifferent interpretations of actions as interventions precise. We prove thatthe seemingly natural interpretation of actions as interventions is circular:Under this interpretation, every causal Bayesian network that correctly modelsthe observational distribution is trivially also interventionally valid, and noaction yields empirical data that could possibly falsify such a model. We provean impossibility result: No interpretation exists that is non-circular andsimultaneously satisfies a set of natural desiderata. Instead, we examinenon-circular interpretations that may violate some desiderata and show how thismay in turn enable the falsification of causal models. By rigorously examininghow a causal Bayesian network could be a 'causal' model of the world instead ofmerely a mathematical object, our formal framework contributes to theconceptual foundations of causal representation learning, causal discovery, andcausal abstraction, while also highlighting some limitations of existingapproaches.</description>
      <author>example@mail.com (Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald)</author>
      <guid isPermaLink="false">2501.19335v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition</title>
      <link>http://arxiv.org/abs/2501.19010v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NAACL 2025 main conference, 9pages, 1 page appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种动态音素级对比学习（DyPCL）方法，以提高构音障碍语音识别性能。&lt;h4&gt;背景&lt;/h4&gt;构音障碍言语识别因患者病情严重程度的多样性以及与正常言语的差异而性能下降。&lt;h4&gt;目的&lt;/h4&gt;通过引入新的对比学习方法来改善构音障碍患者的语音识别精度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于动态连接时序分类对齐的DyPCL方法，该方法将说话人的言语分解为音素级进行细粒度对比学习，进而实现不同说话人之间的不变表示。&lt;h4&gt;主要发现&lt;/h4&gt;采用难度分层训练策略（动态课程学习），逐步从简单的负样本过渡到复杂的负样本，基于音素的语音相似性选择训练样本。这种方法更好地应对了说话人的内在变异性，提高了对挑战性演讲的识别能力。&lt;h4&gt;结论&lt;/h4&gt;在UASpeech数据集上进行评估，DyPCL方法相较于基线模型，在整体构音障碍组中平均降低了22.10%的单词错误率（WER）。&lt;h4&gt;翻译&lt;/h4&gt;Dysarthric speech recognition often suffers from performance degradation due to the intrinsic diversity of dysarthric severity and extrinsic disparity from normal speech. To bridge these gaps, we propose a Dynamic Phoneme-level Contrastive Learning (DyPCL) method, which leads to obtaining invariant representations across diverse speakers. We decompose the speech utterance into phoneme segments for phoneme-level contrastive learning, leveraging dynamic connectionist temporal classification alignment. Unlike prior studies focusing on utterance-level embeddings, our granular learning allows discrimination of subtle parts of speech. In addition, we introduce dynamic curriculum learning, which progressively transitions from easy negative samples to difficult-to-distinguishable negative samples based on phonetic similarity of phoneme. Our approach to training by difficulty levels alleviates the inherent variability of speakers, better identifying challenging speeches. Evaluated on the UASpeech dataset, DyPCL outperforms baseline models, achieving an average 22.10% relative reduction in word error rate (WER) across the overall dysarthria group.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dysarthric speech recognition often suffers from performance degradation dueto the intrinsic diversity of dysarthric severity and extrinsic disparity fromnormal speech. To bridge these gaps, we propose a Dynamic Phoneme-levelContrastive Learning (DyPCL) method, which leads to obtaining invariantrepresentations across diverse speakers. We decompose the speech utterance intophoneme segments for phoneme-level contrastive learning, leveraging dynamicconnectionist temporal classification alignment. Unlike prior studies focusingon utterance-level embeddings, our granular learning allows discrimination ofsubtle parts of speech. In addition, we introduce dynamic curriculum learning,which progressively transitions from easy negative samples todifficult-to-distinguishable negative samples based on phonetic similarity ofphoneme. Our approach to training by difficulty levels alleviates the inherentvariability of speakers, better identifying challenging speeches. Evaluated onthe UASpeech dataset, DyPCL outperforms baseline models, achieving an average22.10\% relative reduction in word error rate (WER) across the overalldysarthria group.</description>
      <author>example@mail.com (Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee)</author>
      <guid isPermaLink="false">2501.19010v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</title>
      <link>http://arxiv.org/abs/2501.18592v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page:  https://github.com/donghao51/Awesome-Multimodal-Adaptation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了从传统方法到多模态基础模型在领域适应和泛化方面的最新进展。&lt;h4&gt;背景&lt;/h4&gt;现实场景中实现域适应和泛化面临重大挑战，尤其是在处理未知的多模态分布时更加困难。随着大规模预训练多模态基础模型的发展（如CLIP），利用这些模型增强适应性和泛化的性能或将其应用于下游任务成为研究热点。&lt;h4&gt;目的&lt;/h4&gt;该综述旨在提供一个多方面且全面回顾，涵盖从传统方法到基于现代大规模预训练的多模态基础模型的各种领域适应和泛化问题的研究。&lt;h4&gt;方法&lt;/h4&gt;涵盖了以下五个主要部分：（1）多模态域适应；（2）测试时的多模态域适应；（3）多模态域泛化；（4）基于多模态基础模型的帮助进行领域的适应和泛化；以及（5）多模态基础模型的适应。&lt;h4&gt;主要发现&lt;/h4&gt;对于每个主题，论文提供了对问题的正式定义，并详细回顾了现有方法。同时分析相关数据集和应用案例，并指出开放性挑战及未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;该综述不仅提供了一个全面的学术视角来理解领域适应与泛化的发展趋势，还为有兴趣的研究人员维护了一个最新的文献资源库。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于如何在现实世界中实现域适应和泛化的挑战，并概述了近年来在此领域的研究进展。特别提到了大规模预训练多模态基础模型（如CLIP）的出现及其在增强领域适应性和泛化性能或应用于下游任务中的应用潜力。本文综述涵盖了五个主要部分，包括传统方法到基于现代大规模预训练的基础模型的研究成果，并对相关数据集、案例以及未来研究方向进行了分析和讨论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/donghao51/awesome-multimodal-adaptation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world scenarios, achieving domain adaptation and generalization posessignificant challenges, as models must adapt to or generalize across unknowntarget distributions. Extending these capabilities to unseen multimodaldistributions, i.e., multimodal domain adaptation and generalization, is evenmore challenging due to the distinct characteristics of different modalities.Significant progress has been made over the years, with applications rangingfrom action recognition to semantic segmentation. Besides, the recent advent oflarge-scale pre-trained multimodal foundation models, such as CLIP, hasinspired works leveraging these models to enhance adaptation and generalizationperformances or adapting them to downstream tasks. This survey provides thefirst comprehensive review of recent advances from traditional approaches tofoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodaltest-time adaptation; (3) Multimodal domain generalization; (4) Domainadaptation and generalization with the help of multimodal foundation models;and (5) Adaptation of multimodal foundation models. For each topic, we formallydefine the problem and thoroughly review existing methods. Additionally, weanalyze relevant datasets and applications, highlighting open challenges andpotential future research directions. We maintain an active repository thatcontains up-to-date literature athttps://github.com/donghao51/Awesome-Multimodal-Adaptation.</description>
      <author>example@mail.com (Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink)</author>
      <guid isPermaLink="false">2501.18592v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>Calibrating Wireless AI via Meta-Learned Context-Dependent Conformal Prediction</title>
      <link>http://arxiv.org/abs/2501.14566v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的校准方法，该方法利用元学习来估计分布偏移，并提出了基于上下文依赖的加权符合预测的方法。这种方法可以有效地在没有当前环境数据的情况下进行AI应用的校准。&lt;h4&gt;背景&lt;/h4&gt;现代软件定义网络如Open Radio Access Network (O-RAN)系统依赖于运行在网络控制器上的由人工智能驱动的应用程序，这些应用程序需要在部署前被适当校准以确保可靠运行。&lt;h4&gt;目的&lt;/h4&gt;解决实际场景中由于网络上下文变化导致的训练集和测试集分布差异的问题，提出一种无需当前环境数据即可进行有效校准的方法。&lt;h4&gt;方法&lt;/h4&gt;利用元学习开发了一个零样本估计器来评估不同上下文的数据分布偏移，并提出了基于加权符合预测的新技术Meta-learned Context-dependent Weighted Conformal Prediction (ML-WCP)。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够通过仅使用上下文信息就有效地校准AI应用，还可以结合多个上下文数据进一步增强校准的可靠性。&lt;h4&gt;结论&lt;/h4&gt;所提出的ML-WCP方法为解决实际应用场景中的分布偏移问题提供了一种有效途径，提高了人工智能在动态变化环境下的可靠性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern software-defined networks, such as Open Radio Access Network (O-RAN)systems, rely on artificial intelligence (AI)-powered applications running oncontrollers interfaced with the radio access network. To ensure that these AIapplications operate reliably at runtime, they must be properly calibratedbefore deployment. A promising and theoretically grounded approach tocalibration is conformal prediction (CP), which enhances any AI model bytransforming it into a provably reliable set predictor that provides error barsfor estimates and decisions. CP requires calibration data that matches thedistribution of the environment encountered during runtime. However, inpractical scenarios, network controllers often have access only to datacollected under different contexts -- such as varying traffic patterns andnetwork conditions -- leading to a mismatch between the calibration and runtimedistributions. This paper introduces a novel methodology to address thiscalibration-test distribution shift. The approach leverages meta-learning todevelop a zero-shot estimator of distribution shifts, relying solely oncontextual information. The proposed method, called meta-learnedcontext-dependent weighted conformal prediction (ML-WCP), enables effectivecalibration of AI applications without requiring data from the current context.Additionally, it can incorporate data from multiple contexts to further enhancecalibration reliability.</description>
      <author>example@mail.com (Seonghoon Yoo, Sangwoo Park, Petar Popovski, Joonhyuk Kang, Osvaldo Simeone)</author>
      <guid isPermaLink="false">2501.14566v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>Single-neuron deep generative model uncovers underlying physics of neuronal activity in Ca imaging data</title>
      <link>http://arxiv.org/abs/2501.14615v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures, ECCB 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;钙成像技术作为一种研究神经元活动的有力工具，提供了空间分辨率和非侵入性测量大量神经元群体的能力。该文提出了一种新的基于自回归变分自动编码器（AVAE）的方法来学习单个神经元的表现形式。&lt;h4&gt;背景&lt;/h4&gt;钙成像是研究神经元活动的一个重要替代方案，能够提供高空间分辨率，并且可以以最小的侵入性方式测量大量神经元群体。这种方法在神经科学、神经工程和医学领域有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;该文旨在通过引入自回归变分自动编码器（AVAE）来解决现有模型无法有效处理单个神经元分析的问题，提出了一种新的方法框架以改进这一领域的研究。&lt;h4&gt;方法&lt;/h4&gt;利用自回归变分自动编码器（AVAE），该研究将单个神经元的时空信号嵌入到一个低维空间中，并且无需使用脉冲推断算法。这种方法生成了比传统线性方法更有信息量和区分度的潜在表示，提高了可视化、聚类等任务的表现。&lt;h4&gt;主要发现&lt;/h4&gt;1. AVAE在重建性能方面超越了现有的最先进技术，能够从学习到的表示中准确恢复出原始荧光信号。2. 通过现实仿真展示了模型捕捉物理属性和连接模式的能力，并且能够在不同发放类型和连接类型之间进行区分。&lt;h4&gt;结论&lt;/h4&gt;AVAE作为一种灵活强大的工具，为单神经元分析提供了重要的基础。该研究还为将来在神经科学中整合多模态单细胞数据奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;钙成像已经成为一种用于研究神经元活动的强大替代方案，它提供空间分辨率，并且能够以最小的侵入性方式测量大量神经元群体。这种技术在神经科学、神经工程和医学领域有着广泛的应用，使研究人员能够探索神经元位置与活性之间的关系。最近深度生成模型（DGM）的进步促进了对神经元群体动态的建模，揭示了潜在表示，这些表示为行为预测和神经元方差提供了见解。然而，这些模型通常依赖于脉冲推断算法，并且主要关注群体水平的动力学，限制了它们在单个神经元分析中的适用性。为了弥补这一差距，我们提出了一种新的基于自回归变分自动编码器（AVAE）的方法来学习单个神经元的表现形式。我们的方法将个体神经元的时空信号嵌入到一个低维空间中，并且无需使用脉冲推断算法。相较于传统线性方法，AVAE通过生成更多信息量和区分度的潜在表示，在诸如可视化、聚类等任务上表现更佳，有助于更好地理解神经元活动。此外，AVAE在重建性能方面超越了最先进技术，展示了其从学习到的表现形式中准确恢复原始荧光信号的能力。利用现实仿真实验，我们展示了模型捕捉物理属性和连接模式的能力，并且能够在不同发放类型和连接类型之间进行区分。这些发现将AVAE确立为单神经元分析的灵活强大工具，并为进一步整合多模态单细胞数据奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Calcium imaging has become a powerful alternative to electrophysiology forstudying neuronal activity, offering spatial resolution and the ability tomeasure large populations of neurons in a minimally invasive manner. Thistechnique has broad applications in neuroscience, neuroengineering, andmedicine, enabling researchers to explore the relationship between neuronlocation and activity. Recent advancements in deep generative models (DGMs)have facilitated the modeling of neuronal population dynamics, uncoveringlatent representations that provide insights into behavior prediction andneuronal variance. However, these models often rely on spike inferencealgorithms and primarily focus on population-level dynamics, limiting theirapplicability for single-neuron analyses. To address this gap, we propose anovel framework for single-neuron representation learning using autoregressivevariational autoencoders (AVAEs). Our approach embeds individual neurons'spatiotemporal signals into a reduced-dimensional space without the need forspike inference algorithms. The AVAE excels over traditional linear methods bygenerating more informative and discriminative latent representations,improving tasks such as visualization, clustering, and the understanding ofneuronal activity. Additionally, the reconstruction performance of the AVAEoutperforms the state of the art, demonstrating its ability to accuratelyrecover the original fluorescence signal from the learned representation. Usingrealistic simulations, we show that our model captures underlying physicalproperties and connectivity patterns, enabling it to distinguish betweendifferent firing and connectivity types. These findings position the AVAE as aversatile and powerful tool for advancing single-neuron analysis and lays thegroundwork for future integration of multimodal single-cell datasets inneuroscience.</description>
      <author>example@mail.com (Jordi Abante, Angelo Piga, Berta Ros, Clara F López-León, Josep M Canals, Jordi Soriano)</author>
      <guid isPermaLink="false">2501.14615v2</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:43 +0800</pubDate>
    </item>
    <item>
      <title>Continually Evolved Multimodal Foundation Models for Cancer Prognosis</title>
      <link>http://arxiv.org/abs/2501.18170v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;癌症预后预测是一项重要的任务，通过整合多种数据模态来提高预测准确性。然而，现有方法存在两个主要问题：难以有效集成不同来源的新数据，以及无法充分捕捉跨模态之间的复杂相互关系。&lt;h4&gt;背景&lt;/h4&gt;癌症预后的研究中，结合临床记录、医学影像和基因组等多模态数据可以提升预测精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够不断演化的多模态基础模型，以解决现有方法在集成新数据及捕捉跨模态交互方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个可适应持续变化的新数据并能有效捕获不同模态间复杂相互关系的多模态基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过TCGA数据库进行广泛的实验验证了所提方法的有效性，表明其在癌症预后研究中的应用潜力巨大。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够增强癌症预后的预测准确性，并为真实世界的应用提供了更强泛化能力和实用性。&lt;h4&gt;翻译&lt;/h4&gt;癌症预后是利用多种数据模态（如临床记录、医学影像和基因组信息）来提高患者结果预测准确性的关键任务。尽管现有的方法在整合这些模态的信息方面已经取得了一定的成果，但它们面临着两个主要挑战：如何将不同来源的新数据集成到训练中以及如何捕捉各个模态之间的复杂相互作用关系。为了应对这些问题，我们提出了一种不断发展的多模态基础模型，并通过在TCGA数据库上的实验展示了其有效性，该方法有望推动癌症预后的进步，因为它可以实现稳健且适应性强的多模态整合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cancer prognosis is a critical task that involves predicting patient outcomesand survival rates. To enhance prediction accuracy, previous studies haveintegrated diverse data modalities, such as clinical notes, medical images, andgenomic data, leveraging their complementary information. However, existingapproaches face two major limitations. First, they struggle to incorporatenewly arrived data with varying distributions into training, such as patientrecords from different hospitals, thus rendering sub-optimal generalizabilityand limited utility in real-world applications. Second, most multimodalintegration methods rely on simplistic concatenation or task-specificpipelines, which fail to capture the complex interdependencies acrossmodalities. To address these, we propose a continually evolving multi-modalfoundation model. Extensive experiments on the TCGA dataset demonstrate theeffectiveness of our approach, highlighting its potential to advance cancerprognosis by enabling robust and adaptive multimodal integration.</description>
      <author>example@mail.com (Jie Peng, Shuang Zhou, Longwei Yang, Yiran Song, Mohan Zhang, Kaixiong Zhou, Feng Xie, Mingquan Lin, Rui Zhang, Tianlong Chen)</author>
      <guid isPermaLink="false">2501.18170v2</guid>
      <pubDate>Tue, 04 Feb 2025 10:23:18 +0800</pubDate>
    </item>
  <item>
      <title>Current Pathology Foundation Models are unrobust to Medical Center Differences</title>
      <link>http://arxiv.org/abs/2501.18055v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文评估了当前公开的病理学基础模型（FMs）对医学中心差异的稳健性，并引入了一种新的稳健性指标——Robustness Index。&lt;h4&gt;背景&lt;/h4&gt;病理学基础模型在医疗领域展现出巨大潜力，但在临床应用前需要确保这些模型能够应对不同医疗机构间的变异性。&lt;h4&gt;目的&lt;/h4&gt;评估当前病理学基础模型是否更侧重于生物学特征还是医学中心特有的混淆因素，并提出一种新的稳健性衡量标准。&lt;h4&gt;方法&lt;/h4&gt;引入并使用Robustness Index来量化病理学基础模型的稳健性，该指标反映了生物标志物相对于非生物标记（如医疗机构的影响）的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;评估的十种公开可用的病理学FMs都强烈地代表了医学中心。其中仅有一种模型的稳健性指数略高于1，表明其生物学特征略微占主导地位。此外，作者还描述了一种量化医学中心差异对基于FM预测性能影响的方法，并分析了非鲁棒性对于下游分类性能的影响。&lt;h4&gt;结论&lt;/h4&gt;病理学FMs在嵌入空间中更加关注医疗机构而非生物因素，导致这些模型可能更准确地预测原发医疗中心而不是组织来源或癌症类型。引入的稳健性指数旨在推动病理学基础模型向临床应用的发展。&lt;h4&gt;翻译&lt;/h4&gt;Pathology Foundation Models (FMs) 在医疗健康领域具有巨大潜力。然而，在它们可以在临床上使用之前，确保这些模型对不同医疗机构之间的变异性具有鲁棒性是至关重要的。研究团队评估了病理学FM是否更关注生物特征（如组织和癌症类型），还是由染色过程和其他差异引入的已知混杂因素——医学中心签名。他们介绍了Robustness Index这一新的稳健度指标，该指标反映了生物学特征相对于混淆因素的重要性程度。对十种目前公开可用的病理学FMs进行了评估，发现所有这些模型都强烈代表了医疗中心。观察到稳健性指数存在显著差异，但迄今为止只有一个是略微大于1的，这意味着生物标志物仅稍微占主导地位。此外，作者描述了一种定量方法来衡量医学中心差异对FM预测性能的影响，并分析了非鲁棒性如何影响下游分类模型的表现，发现在癌症类型分类错误中，这些错误并非随机发生，而是特定于同一医疗机构内的不同类别图像。通过对FM嵌入空间的可视化发现，这些空间更加受医疗机构而不是生物因素的影响组织来源和癌症类型的预测准确度低于原发医疗中心的预测准确性。这项研究旨在推进临床采纳稳健可靠的病理学基础模型的发展进程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology Foundation Models (FMs) hold great promise for healthcare. Beforethey can be used in clinical practice, it is essential to ensure they arerobust to variations between medical centers. We measure whether pathology FMsfocus on biological features like tissue and cancer type, or on the well knownconfounding medical center signatures introduced by staining procedure andother differences. We introduce the Robustness Index. This novel robustnessmetric reflects to what degree biological features dominate confoundingfeatures. Ten current publicly available pathology FMs are evaluated. We findthat all current pathology foundation models evaluated represent the medicalcenter to a strong degree. Significant differences in the robustness index areobserved. Only one model so far has a robustness index greater than one,meaning biological features dominate confounding features, but only slightly. Aquantitative approach to measure the influence of medical center differences onFM-based prediction performance is described. We analyze the impact ofunrobustness on classification performance of downstream models, and find thatcancer-type classification errors are not random, but specifically attributableto same-center confounders: images of other classes from the same medicalcenter. We visualize FM embedding spaces, and find these are more stronglyorganized by medical centers than by biological factors. As a consequence, themedical center of origin is predicted more accurately than the tissue sourceand cancer type. The robustness index introduced here is provided with the aimof advancing progress towards clinical adoption of robust and reliablepathology FMs.</description>
      <author>example@mail.com (Edwin D. de Jong, Eric Marcus, Jonas Teuwen)</author>
      <guid isPermaLink="false">2501.18055v2</guid>
      <pubDate>Tue, 04 Feb 2025 10:23:18 +0800</pubDate>
    </item>
    <item>
      <title>Reliable Pseudo-labeling via Optimal Transport with Attention for Short Text Clustering</title>
      <link>http://arxiv.org/abs/2501.15194v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个名为POTA的新颖短文本聚类框架，用于生成可靠的伪标签以帮助区分表示学习。&lt;h4&gt;背景&lt;/h4&gt;短文本聚类在数据挖掘社区中引起了广泛的关注。然而，由于短文本包含的有价值信息有限，导致了低分辨度的表示形式和难以处理的聚类问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决短文本聚类中的区分性表示学习难题，并通过生成可靠的伪标签来增强这一过程。&lt;h4&gt;方法&lt;/h4&gt;POTA框架首先实现了一个实例级注意力机制以捕捉样本之间的语义关系，然后将这些关系作为一致性正则化项融入最优传输问题中。通过求解该OT问题，可以获得同时考虑样本间语义一致性和全局结构信息的可靠伪标签。此外，所提出的最优传输可以自适应地估计集群分布，使其适用于不同程度的数据不平衡。&lt;h4&gt;主要发现&lt;/h4&gt;利用生成的伪标签指导对比学习以产生区分性表示并实现高效的聚类。实验结果表明POTA优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该论文通过引入一种新颖的短文本聚类框架，有效地解决了现有技术面临的挑战，并展示了优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;短文聚类在数据挖掘领域受到广泛关注。然而，由于短文中包含的信息有限，导致了低分辨度表示的问题，增加了聚类的难度。本文提出了一种新的短文聚类框架POTA（基于注意力机制的最佳传输可靠伪标签生成），通过产生可靠的伪标签来促进区分性表示学习和高效聚类。实验结果显示该方法优于当前最先进的技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yzh0905/pota-stc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Short text clustering has gained significant attention in the data miningcommunity. However, the limited valuable information contained in short textsoften leads to low-discriminative representations, increasing the difficulty ofclustering. This paper proposes a novel short text clustering framework, calledReliable \textbf{P}seudo-labeling via \textbf{O}ptimal \textbf{T}ransport with\textbf{A}ttention for Short Text Clustering (\textbf{POTA}), that generatereliable pseudo-labels to aid discriminative representation learning forclustering. Specially, \textbf{POTA} first implements an instance-levelattention mechanism to capture the semantic relationships among samples, whichare then incorporated as a semantic consistency regularization term into anoptimal transport problem. By solving this OT problem, we can yield reliablepseudo-labels that simultaneously account for sample-to-sample semanticconsistency and sample-to-cluster global structure information. Additionally,the proposed OT can adaptively estimate cluster distributions, making\textbf{POTA} well-suited for varying degrees of imbalanced datasets. Then, weutilize the pseudo-labels to guide contrastive learning to generatediscriminative representations and achieve efficient clustering. Extensiveexperiments demonstrate \textbf{POTA} outperforms state-of-the-art methods. Thecode is available at:\href{https://github.com/YZH0905/POTA-STC/tree/main}{https://github.com/YZH0905/POTA-STC/tree/main}.</description>
      <author>example@mail.com (Zhihao Yao, Jixuan Yin, Bo Li)</author>
      <guid isPermaLink="false">2501.15194v2</guid>
      <pubDate>Tue, 04 Feb 2025 10:23:18 +0800</pubDate>
    </item>
    <item>
      <title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.18032v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于大型语言模型的多代理系统GraphTeam，用于图分析。该系统由五个具有不同专长的代理组成，并通过模拟人类解决问题策略（如类比和协作）来处理复杂问题。&lt;h4&gt;背景&lt;/h4&gt;现有的基于LLM的图数据分析方法要么将图神经网络(GNNs)集成到特定机器学习任务中，从而限制了它们的可转移性；要么仅仅依赖于LLMs内在的推理能力，导致性能不佳。因此提出了GraphTeam以解决这些问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种多代理系统，利用大型语言模型的优势来改进图数据分析的能力。&lt;h4&gt;方法&lt;/h4&gt;1. 输入-输出规范化模块：问题代理提取并精炼原始问题中的四个关键参数，帮助理解问题；答案代理组织结果以满足输出要求。2. 外部知识检索模块：建立包含相关文档和经验信息的知识库，并由搜索代理根据每个问题检索最相关的条目。3. 问题解决模块：编程代理使用从搜索代理获取的信息及既定算法生成解决方案，如果编程代理无法工作，则推理代理将直接计算结果。&lt;h4&gt;主要发现&lt;/h4&gt;GraphTeam在六个图分析基准测试上取得了最先进的性能，平均准确率提高了25.85%。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了如何利用大型语言模型的外部工具和知识能力来改进复杂问题解决的能力，并提出了一个能够有效处理各种图数据任务的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在现实场景中，如社交网络和城市计算领域，图被广泛用于建模关系型数据。现有基于LLM的图数据分析方法要么将图神经网络(GNNs)集成到特定机器学习任务中，从而限制了它们的可转移性；要么仅仅依赖于LLMs内在的推理能力，导致性能不佳。为了克服这些局限，我们利用最近关于基于LLM代理的研究成果，展示了这类系统能够利用外部知识或工具来解决问题的能力。通过模拟人类解决策略（如类比和协作），我们提出了一种基于LLM的多代理系统GraphTeam来进行图分析。该系统由三个模块中的五个代理组成，并且不同专长的代理可以互相合作来处理复杂问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bupt-gamma/graphteam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description>
      <author>example@mail.com (Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang)</author>
      <guid isPermaLink="false">2410.18032v3</guid>
      <pubDate>Tue, 04 Feb 2025 10:23:18 +0800</pubDate>
    </item>
    <item>
      <title>CULTURE3D: Cultural Landmarks and Terrain Dataset for 3D Applications</title>
      <link>http://arxiv.org/abs/2501.06927v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个大规模的精细粒度数据集，利用来自世界各地的高分辨率图像构建。&lt;h4&gt;背景&lt;/h4&gt;现有的数据集中存在规模较小和细节水平较低的问题。&lt;h4&gt;目的&lt;/h4&gt;创建一个更大且包含更多详细信息的数据集，特别适合于细粒度3D应用。&lt;h4&gt;方法&lt;/h4&gt;该数据集通过无人机捕获的航空影像进行建立，提供了更准确的世界现场布局和建筑结构视图。使用这些详细的图像重建环境，并支持COLMAP格式下的高斯散射、基于运动恢复结构（SfM）的方法以及其他常用技术如SLAM、多视角立体视觉和神经辐射场（NeRF）。&lt;h4&gt;主要发现&lt;/h4&gt;数据集兼容多种三维应用，包括建筑重构到虚拟旅游，并且具有良好的灵活性。&lt;h4&gt;结论&lt;/h4&gt;该数据集成为重建任务与分割任务的基准。它的多功能性促进了3D建模和分析领域的创新。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个利用高分辨率图像建立的大规模精细粒度数据集，这些图像是从世界各地捕捉到的。它特别适用于细粒度三维应用，并且是通过无人机捕获航空影像来构建，这使得该数据集能够更准确地捕捉现实世界的场地布局和建筑结构。此外，所提出的数据集支持COLMAP格式下的高斯散射、基于运动恢复结构的方法以及其他常用技术如SLAM（即时定位与地图构建）、多视角立体视觉和神经辐射场等方法，并且可以无缝集成多种模态数据，促进三维应用的创新与发展，包括建筑重建到虚拟旅游。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a large-scale fine-grained dataset usinghigh-resolution images captured from locations worldwide. Compared to existingdatasets, our dataset offers a significantly larger size and includes a higherlevel of detail, making it uniquely suited for fine-grained 3D applications.Notably, our dataset is built using drone-captured aerial imagery, whichprovides a more accurate perspective for capturing real-world site layouts andarchitectural structures. By reconstructing environments with these detailedimages, our dataset supports applications such as the COLMAP format forGaussian Splatting and the Structure-from-Motion (SfM) method. It is compatiblewith widely-used techniques including SLAM, Multi-View Stereo, and NeuralRadiance Fields (NeRF), enabling accurate 3D reconstructions and point clouds.This makes it a benchmark for reconstruction and segmentation tasks. Thedataset enables seamless integration with multi-modal data, supporting a rangeof 3D applications, from architectural reconstruction to virtual tourism. Itsflexibility promotes innovation, facilitating breakthroughs in 3D modeling andanalysis.</description>
      <author>example@mail.com (Xinyi Zheng, Steve Zhang, Weizhe Lin, Aaron Zhang, Walterio W. Mayol-Cuevas, Junxiao Shen)</author>
      <guid isPermaLink="false">2501.06927v2</guid>
      <pubDate>Tue, 04 Feb 2025 10:23:18 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network Flavor Tagger and measurement of $\mathrm{sin}2β$ at Belle II</title>
      <link>http://arxiv.org/abs/2501.17631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;B介子是一种在粒子物理学中研究非常重要的基本粒子，特别是其中性态下的味道鉴别技术对于理解其物理性质至关重要。&lt;h4&gt;目的&lt;/h4&gt;本文提出了一种新的算法GFlaT，使用图神经网络确定在Υ(4S)衰变过程中产生的中性B介子的味道，并评估了该算法的性能。&lt;h4&gt;方法&lt;/h4&gt;利用BELLE II探测器在超级KEKB对撞机上记录的电子-正电子碰撞数据，在362 fb^-1样本中的B衰变为特定味道的末态粒子来测试该算法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实现了(37.40 ± 0.43 ± 0.36)%的有效标记效率，比之前的BELLE II算法高出了18%。利用B^0 -&gt; J/ψ K_S^0衰变测量了直接和混合引起的CP违反参数C = (-0.035 ± 0.026 ± 0.013)以及S = (0.724 ± 0.035 ± 0.014)，从而得到β = (23.2 ± 1.5 ± 0.6)^°。&lt;h4&gt;结论&lt;/h4&gt;该算法在味道鉴别方面表现出了优越的性能，为未来的粒子物理研究提供了重要的技术手段。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种新的算法GFlaT，该算法使用图神经网络来确定由Υ(4S)衰变产生的中性B介子的味道。我们利用BELLE II探测器在超级KEKB对撞机上记录的362 fb^-1样本中的电子-正电子碰撞数据来进行性能评估。我们实现了(37.40 ± 0.43 ± 0.36)%的有效标记效率，其中第一个不确定性是统计性的，第二个系统性，这比之前的BELLE II算法高出了18%。通过B^0 -&gt; J/ψ K_S^0衰变来测量直接和混合引起的CP违反参数C = (-0.035 ± 0.026 ± 0.013)以及S = (0.724 ± 0.035 ± 0.014)，从而得到β = (23.2 ± 1.5 ± 0.6)^°。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GFlaT, a new algorithm that uses a graph-neural-network todetermine the flavor of neutral B mesons produced in $\mathrm{\Upsilon(4S)}$decays. We evaluate its performance using $B$ decays to flavor-specifichadronic final states reconstructed in a $362$ $\mathrm{fb}^{-1}$ sample ofelectron-positron collisions recorded at the $\mathrm{\Upsilon(4S)}$ resonancewith the Belle II detector at the SuperKEKB collider. We achieve an effectivetagging efficiency of $(37.40 \pm 0.43 \pm 0.36) \%$, where the firstuncertainty is statistical and the second systematic, which is $18\%$ betterthan the previous Belle II algorithm. Demonstrating the algorithm, we use $B^0\to J/\psi K_\mathrm{S}^0$ decays to measure the direct and mixing-induced CPviolation parameters, $C = (-0.035 \pm 0.026 \pm 0.013)$ and $S = (0.724 \pm0.035 \pm 0.014)$, from which we obtain $\beta = (23.2 \pm 1.5 \pm0.6)^{\circ}$.</description>
      <author>example@mail.com (Petros Stavroulakis)</author>
      <guid isPermaLink="false">2501.17631v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
  <item>
      <title>A Cartesian Encoding Graph Neural Network for Crystal Structures Property Prediction: Application to Thermal Ellipsoid Estimation</title>
      <link>http://arxiv.org/abs/2501.18369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于图神经网络(CartNet)的新模型，用于预测晶体结构中的原子位移参数(ADPs)，它能够高效且准确地编码晶体的几何和温度信息。&lt;h4&gt;背景&lt;/h4&gt;在晶体结构分析中，通过Anisotropic Displacement Parameters (ADPs)量化热椭圆体来捕捉原子振动是至关重要的。然而，传统的计算方法成本高且复杂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图神经网络模型CartNet以解决传统方法的不足，并预测晶体的各种属性。&lt;h4&gt;方法&lt;/h4&gt;CartNet将原子几何信息和温度编码成笛卡尔坐标系中的向量表示；采用邻居等化技术来强调共价和接触相互作用，同时使用基于Cholesky的方法确保有效的ADP预测结果。此外，在训练过程中引入SO(3)旋转数据增强策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证表明，CartNet在ADPs的预测上比现有方法提高了10.87%，并且在理论方法的基础上提高了34.77%；在其他晶体属性的数据集上的表现也优于现有的模型。&lt;h4&gt;结论&lt;/h4&gt;研究证实了CartNet作为一种新颖且高效的工具，在多种晶体性质预测任务中具有卓越的表现，可以用于未来的材料科学和结构生物学领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的图神经网络(CartNet)方法，该方法通过将原子几何学与温度一起编码成笛卡尔坐标来有效预测晶体内ADPs。CartNet采用邻居等化技术和Cholesky基元头以确保有效的ADP预测，并利用SO(3)旋转数据增强策略处理未见的晶体取向问题。实验在包含超过20万种实验晶体结构的数据集上验证了该方法的有效性，显示出相比于传统和理论方法显著的成本降低与性能提高。CartNet在Jarvis Dataset和Materials Project Dataset等其他晶体现象预测任务中也表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/imatge-upc/CartNet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In diffraction-based crystal structure analysis, thermal ellipsoids,quantified via Anisotropic Displacement Parameters (ADPs), are critical yetchallenging to determine. ADPs capture atomic vibrations, reflecting thermaland structural properties, but traditional computation is often expensive. Thispaper introduces CartNet, a novel graph neural network (GNN) for efficientlypredicting crystal properties by encoding atomic geometry into Cartesiancoordinates alongside the crystal temperature. CartNet integrates a neighbourequalization technique to emphasize covalent and contact interactions, and aCholesky-based head to ensure valid ADP predictions. We also propose arotational SO(3) data augmentation strategy during training to handle unseenorientations. An ADP dataset with over 200,000 experimental crystal structuresfrom the Cambridge Structural Database (CSD) was curated to validate theapproach. CartNet significantly reduces computational costs and outperformsexisting methods in ADP prediction by 10.87%, while delivering a 34.77%improvement over theoretical approaches. We further evaluated CartNet on otherdatasets covering formation energy, band gap, total energy, energy above theconvex hull, bulk moduli, and shear moduli, achieving 7.71% better results onthe Jarvis Dataset and 13.16% on the Materials Project Dataset. These gainsestablish CartNet as a state-of-the-art solution for diverse crystal propertypredictions. Project website and online demo: https://www.ee.ub.edu/cartnet</description>
      <author>example@mail.com (Àlex Solé, Albert Mosella-Montoro, Joan Cardona, Silvia Gómez-Coca, Daniel Aravena, Eliseo Ruiz, Javier Ruiz-Hidalgo)</author>
      <guid isPermaLink="false">2501.18369v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>REMOTE: Real-time Ego-motion Tracking for Various Endoscopes via Multimodal Visual Feature Learning</title>
      <link>http://arxiv.org/abs/2501.18124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种用于内窥镜实时自我运动跟踪的新型框架。&lt;h4&gt;背景&lt;/h4&gt;内窥镜的实时自我运动追踪是实现高效导航和内窥镜机器人自动化的重要任务。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够提取多模态视觉特征并预测相对姿态变化的网络，提高内窥镜手术中的导航精度和效率。&lt;h4&gt;方法&lt;/h4&gt;{'提出了一种多模态视觉特征学习网络': '用于相对姿势预测，该网络从光学流、场景特征以及两个连续观测帧中获取信息。', '设计了基于注意力机制的新型特征提取器': '以整合来自两帧图像连接后的多维信息。', '提出了新的姿态解码器': '利用融合后特性进行姿态变换预测。', '计算绝对内窥镜姿势': '通过相对姿态来实现。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'所提出的方法在三个不同内窥镜场景的数据集上的实验结果表明': '其性能优于现有方法。', '推理速度超过30帧每秒': '满足实时要求。'}&lt;h4&gt;结论&lt;/h4&gt;该研究为内窥镜手术的高效导航和机器人自动化提供了一种新的解决方案，实现了高精度的同时保证了较高的处理效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个用于内窥镜实时自我运动跟踪的新框架的设计与实现情况，它在提高内窥镜操作中的导航性能方面取得了显著成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time ego-motion tracking for endoscope is a significant task forefficient navigation and robotic automation of endoscopy. In this paper, anovel framework is proposed to perform real-time ego-motion tracking forendoscope. Firstly, a multi-modal visual feature learning network is proposedto perform relative pose prediction, in which the motion feature from theoptical flow, the scene features and the joint feature from two adjacentobservations are all extracted for prediction. Due to more correlationinformation in the channel dimension of the concatenated image, a novel featureextractor is designed based on an attention mechanism to integratemulti-dimensional information from the concatenation of two continuous frames.To extract more complete feature representation from the fused features, anovel pose decoder is proposed to predict the pose transformation from theconcatenated feature map at the end of the framework. At last, the absolutepose of endoscope is calculated based on relative poses. The experiment isconducted on three datasets of various endoscopic scenes and the resultsdemonstrate that the proposed method outperforms state-of-the-art methods.Besides, the inference speed of the proposed method is over 30 frames persecond, which meets the real-time requirement. The project page is here:\href{https://remote-bmxs.netlify.app}{remote-bmxs.netlify.app}</description>
      <author>example@mail.com (Liangjing Shao, Benshuang Chen, Shuting Zhao, Xinrong Chen)</author>
      <guid isPermaLink="false">2501.18124v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>SynthmanticLiDAR: A Synthetic Dataset for Semantic Segmentation on LiDAR Imaging</title>
      <link>http://arxiv.org/abs/2501.19035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 IEEE International Conference on Image Processing (ICIP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种针对LiDAR语义分割设计的修改版CARLA仿真器，并生成了SynthmanticLiDAR，这是一个模拟SemanticKITTI的LiDAR图像语义分割的数据集。&lt;h4&gt;背景&lt;/h4&gt;由于LiDAR成像的语义分割在感知系统和自动驾驶领域的重要性增加，收集和标记真实LiDAR数据变得既昂贵又耗时。尽管存在如SemanticKITTI这样的手动收集和标注的数据集，但诸如CARLA之类的仿真工具现在可以创建按需生成的合成数据集。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门为LiDAR语义分割设计、具有新类别的修改版CARLA模拟器，并通过评估其对不同语义分割算法训练过程中的贡献来证明该数据集SynthmanticLiDAR的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用改良的CARLA仿真器生成了名为SynthmanticLiDAR的数据集，此数据集在设计上类似于SemanticKITTI。通过简单转移学习的方法评估其对训练过程的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在训练过程中引入SynthmanticLiDAR可以提高测试算法的整体性能。&lt;h4&gt;结论&lt;/h4&gt;这些发现证明了我们的数据集和修改后的CARLA模拟器在语义分割中的有用性。该数据集和仿真器可在GitHub上获得。&lt;h4&gt;翻译&lt;/h4&gt;针对激光雷达（LiDAR）图像的语义分割正在逐渐受到关注，因为它可以为感知系统提供有用的见解，并有助于自动驾驶的应用。然而，收集和标记真实的LiDAR数据是一项既费时又耗资的任务。尽管存在如SemanticKITTI这样的手动采集并标注的数据集，但诸如CARLA等仿真工具现在可以使按需生成的合成数据集得以实现。本文中，我们介绍了一种专门为LiDAR语义分割设计的改良版CARLA仿真器，该仿真器具有新的分类类别、与真实数据集中如SemanticKITTI的对象标签更一致，并且能够调整对象类别的分布。利用这个工具，我们生成了名为SynthmanticLiDAR的合成数据集，这是针对LiDAR图像语义分割设计的数据集，旨在类似SemanticKITTI，通过使用一种简单的转移学习方法来评估其对不同语义分割算法训练过程中的贡献。我们的结果显示，在训练过程中包含SynthmanticLiDAR可以提高测试算法的整体性能，证明了我们数据集和改良CARLA仿真器的有用性。该数据集和模拟器可从https://github.com/vpulab/SynthmanticLiDAR获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICIP51287.2024.10648055&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation on LiDAR imaging is increasingly gaining attention, asit can provide useful knowledge for perception systems and potential forautonomous driving. However, collecting and labeling real LiDAR data is anexpensive and time-consuming task. While datasets such as SemanticKITTI havebeen manually collected and labeled, the introduction of simulation tools suchas CARLA, has enabled the creation of synthetic datasets on demand.  In this work, we present a modified CARLA simulator designed with LiDARsemantic segmentation in mind, with new classes, more consistent objectlabeling with their counterparts from real datasets such as SemanticKITTI, andthe possibility to adjust the object class distribution. Using this tool, wehave generated SynthmanticLiDAR, a synthetic dataset for semantic segmentationon LiDAR imaging, designed to be similar to SemanticKITTI, and we evaluate itscontribution to the training process of different semantic segmentationalgorithms by using a naive transfer learning approach. Our results show thatincorporating SynthmanticLiDAR into the training process improves the overallperformance of tested algorithms, proving the usefulness of our dataset, andtherefore, our adapted CARLA simulator.  The dataset and simulator are available inhttps://github.com/vpulab/SynthmanticLiDAR.</description>
      <author>example@mail.com (Javier Montalvo, Pablo Carballeira, Álvaro García-Martín)</author>
      <guid isPermaLink="false">2501.19035v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Meta-learning of shared linear representations beyond well-specified linear regression</title>
      <link>http://arxiv.org/abs/2501.18975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了跨任务或用户共享结构的学习问题，包括共享低秩表示和聚类结构。研究不仅限于传统的线性回归模型，而是涵盖了更广泛的凸优化目标。&lt;h4&gt;背景&lt;/h4&gt;受多任务学习和元学习方法的启发，研究人员关注不同任务间共享的基础结构（如低秩表示或分组结构）的学习问题。&lt;h4&gt;目的&lt;/h4&gt;提出在广泛适用的凸优化框架下解决上述问题的方法，并探讨样本量对模型性能的影响。&lt;h4&gt;方法&lt;/h4&gt;通过引入温和假设（例如Hessian矩阵集中度和噪声集中在最优解附近的条件），提出了针对秩约束和集群化正则化的估计器，用以恢复此类结构。此外，在每个任务仅有一个样本的情况下研究了子空间恢复问题，并提供了核范数限制下的多项式时间算法来学习共享线性表示。&lt;h4&gt;主要发现&lt;/h4&gt;在满足一定假设的条件下，秩受限和分组的正则化估计器能够成功恢复目标结构；当每项任务只有一个样本时，利用秩受限估计器可实现子空间恢复，但是需要任务数量随子空间维度呈指数级增长。此外，在凸学习目标上下文中，通过核范数限制提出了多项式时间算法来获取共享线性表示。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在处理大规模多任务场景下的结构共享问题时具有潜在的应用价值和理论意义。&lt;h4&gt;翻译&lt;/h4&gt;受多任务学习及元学习方法的激励，本研究探讨了由任务或用户间共享的基础结构，比如低秩表示与聚类模式所引发的问题。不同于以往的研究局限于线性回归模型，我们在这次研究中考虑了更广泛的凸优化目标，在这些函数的最优解上表达了低秩和分组假设。在适度的前提如'Hessian矩阵集中度'及'噪声集中在最优解附近'下，展示了当每项任务的样本数与任务总数足够大时，秩受限与集群化正则化的估计器能够恢复这类结构。接着，在每个任务仅有单一实例的情况下探讨了子空间恢复问题：我们发现，此时利用秩受限估计器能实现这一目的，不过需要任务的数量随子空间维度呈指数级增长。最后，通过核范数限制提供了一种多项式时间算法来在凸学习目标的上下文中获得共享线性表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by multi-task and meta-learning approaches, we consider the problemof learning structure shared by tasks or users, such as shared low-rankrepresentations or clustered structures. While all previous works focus onwell-specified linear regression, we consider more general convex objectives,where the structural low-rank and cluster assumptions are expressed on theoptima of each function. We show that under mild assumptions such as\textit{Hessian concentration} and \textit{noise concentration at the optimum},rank and clustered regularized estimators recover such structure, provided thenumber of samples per task and the number of tasks are large enough. We thenstudy the problem of recovering the subspace in which all the solutions lie, inthe setting where there is only a single sample per task: we show that in thatcase, the rank-constrained estimator can recover the subspace, but that thenumber of tasks needs to scale exponentially large with the dimension of thesubspace. Finally, we provide a polynomial-time algorithm via nuclear normconstraints for learning a shared linear representation in the context ofconvex learning objectives.</description>
      <author>example@mail.com (Mathieu Even, Laurent Massoulié)</author>
      <guid isPermaLink="false">2501.18975v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>LiDAR Loop Closure Detection using Semantic Graphs with Graph Attention Networks</title>
      <link>http://arxiv.org/abs/2501.19382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新颖的循环闭合检测算法，该算法利用图注意力神经网络编码语义图来进行位置识别，并使用语义注册来估计六自由度相对姿态约束。&lt;h4&gt;背景&lt;/h4&gt;当前的SLAM系统在处理环境中的动态变化和相似区域时面临挑战，尤其是在进行长时间导航时。现有的方法通常基于几何特征或局部地图匹配，但这些方法难以区分具有相似视觉外观的不同位置。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的循环闭合检测算法，以提高定位精度并增强长期SLAM系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;{'模块1': '一个语义图编码器模块和图比较模块。其中，语义图编码器采用图注意力网络高效地从输入点云的语义图中提取空间、语义和几何信息。', '模块2': '通过在节点嵌入和图嵌入步骤中使用自注意机制来创建具有区别的图向量。然后，在图比较模块中将当前扫描与关键帧扫描的图向量进行对比，以识别潜在的循环闭合。', '算法实现': '最后实现了语义注册算法，该算法接收循环闭合候选扫描并估计LiDAR SLAM系统中的相对6自由度姿态约束。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能提升': '实验表明，在SemanticKITTI数据集上，相比于基线的语义图算法，本文的方法在最大F1评分方面提高了13%。', '技术贡献': '通过两个图向量之间的差异表现出显著的性能改进。'}&lt;h4&gt;结论&lt;/h4&gt;提出的模型不仅准确性和鲁棒性更强，在公共数据集上的评估显示了其优越性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种新颖的循环闭合检测算法，该算法采用图注意力神经网络编码语义图来进行位置识别，并使用语义注册来估计六自由度相对姿态约束。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s10846-025-02223-6&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/crepuscularlight/semanticloopclosure&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel loop closure detection algorithm that usesgraph attention neural networks to encode semantic graphs to perform placerecognition and then use semantic registration to estimate the 6 DoF relativepose constraint. Our place recognition algorithm has two key modules, namely, asemantic graph encoder module and a graph comparison module. The semantic graphencoder employs graph attention networks to efficiently encode spatial,semantic and geometric information from the semantic graph of the input pointcloud. We then use self-attention mechanism in both node-embedding andgraph-embedding steps to create distinctive graph vectors. The graph vectors ofthe current scan and a keyframe scan are then compared in the graph comparisonmodule to identify a possible loop closure. Specifically, employing thedifference of the two graph vectors showed a significant improvement inperformance, as shown in ablation studies. Lastly, we implemented a semanticregistration algorithm that takes in loop closure candidate scans and estimatesthe relative 6 DoF pose constraint for the LiDAR SLAM system. Extensiveevaluation on public datasets shows that our model is more accurate and robust,achieving 13% improvement in maximum F1 score on the SemanticKITTI dataset,when compared to the baseline semantic graph algorithm. For the benefit of thecommunity, we open-source the complete implementation of our proposed algorithmand custom implementation of semantic registration athttps://github.com/crepuscularlight/SemanticLoopClosure</description>
      <author>example@mail.com (Liudi Yang, Ruben Mascaro, Ignacio Alzugaray, Sai Manoj Prakhya, Marco Karrer, Ziyuan Liu, Margarita Chli)</author>
      <guid isPermaLink="false">2501.19382v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Lightspeed Geometric Dataset Distance via Sliced Optimal Transport</title>
      <link>http://arxiv.org/abs/2501.18901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的数据集对比方法在处理类别数量变化、不需要训练模型和处理不相交标签集合时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数据集对比方法——切片最优传输数据集距离（s-OTDD），它无需特定的模型或嵌入，并且能够高效地比较包含不同类别的数据集。&lt;h4&gt;方法&lt;/h4&gt;通过使用时刻变换投影（MTP）将标签映射到实数，然后计算数据点投影，从而将数据集转化为一维分布。最终通过求解一维最优传输的距离来定义s-OTDD。&lt;h4&gt;主要发现&lt;/h4&gt;s-OTDD不仅在理论上具有闭合形式的解决方案，还能实现线性的计算复杂度，在数据增强和迁移学习中的性能差异上也有很好的相关性。&lt;h4&gt;结论&lt;/h4&gt;与现有的数据集差异测量方法相比，s-OTDD既高效又准确，并且在处理不同数量类别的场景下表现尤为出色。&lt;h4&gt;翻译&lt;/h4&gt;我们引入了切片最优传输数据集距离（s-OTDD），这是一种无需训练模型、对类别数变化鲁棒并且能够处理不相交标签集合的数据集对比方法。核心创新在于时刻变换投影（MTP），该技术将作为特征分布的标签映射到实数上。利用MTP，我们推导出了数据点投影，进而可以将数据集转换为一维分布。s-OTDD被定义为随机投影参数下一维分布之间预期的Wasserstein距离。基于一维最优传输的封闭形式解，s-OTDD在数据点数量和特征维度上的计算复杂度接近线性，并且与类别数无关。凭借几何上具有意义的投影，s-OTDD能够强烈地反映最优传输数据集距离的相关信息，同时比现有的数据集差异度量更为高效。此外，在迁移学习中的性能差距和数据增强后的分类准确率上有很好的相关性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce sliced optimal transport dataset distance (s-OTDD), amodel-agnostic, embedding-agnostic approach for dataset comparison thatrequires no training, is robust to variations in the number of classes, and canhandle disjoint label sets. The core innovation is Moment Transform Projection(MTP), which maps a label, represented as a distribution over features, to areal number. Using MTP, we derive a data point projection that transformsdatasets into one-dimensional distributions. The s-OTDD is defined as theexpected Wasserstein distance between the projected distributions, with respectto random projection parameters. Leveraging the closed form solution ofone-dimensional optimal transport, s-OTDD achieves (near-)linear computationalcomplexity in the number of data points and feature dimensions and isindependent of the number of classes. With its geometrically meaningfulprojection, s-OTDD strongly correlates with the optimal transport datasetdistance while being more efficient than existing dataset discrepancy measures.Moreover, it correlates well with the performance gap in transfer learning andclassification accuracy in data augmentation.</description>
      <author>example@mail.com (Khai Nguyen, Hai Nguyen, Tuan Pham, Nhat Ho)</author>
      <guid isPermaLink="false">2501.18901v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Imagine with the Teacher: Complete Shape in a Multi-View Distillation Way</title>
      <link>http://arxiv.org/abs/2501.19270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 3 figures 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的视角蒸馏点云完成网络（VD-PCN），用于解决3D形状补全问题，通过多视角蒸馏方式，充分利用二维像素的有序性、二维处理的灵活性和二维网络的强大能力。&lt;h4&gt;背景&lt;/h4&gt;点云补全是三维重建领域的关键任务之一，旨在从不完整观测中恢复物体完整的3D形状。由于遮挡或传感器限制等原因导致部分信息丢失时，需要神经网络基于现有输入推断缺失的部分。&lt;h4&gt;目的&lt;/h4&gt;通过引入知识蒸馏的师生学习策略，设计一种用于点云补全的知识转移方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为View Distillation Point Completion Network (VD-PCN)的新模型，该模型利用多视角蒸馏方式解决3D形状补全问题。具体而言，它结合了二维像素的有序性、二维处理的灵活性以及二维网络的强大能力来改进现有点云完成技术。&lt;h4&gt;主要发现&lt;/h4&gt;在PCN、ShapeNet55/34和MVP等数据集上的广泛评估表明，所提出的设计方法及其知识转移策略在数量级和质量上都是有效的。&lt;h4&gt;结论&lt;/h4&gt;本文通过多视角蒸馏方式引入了一种新颖的点云补全网络VD-PCN，并证明了该模型的有效性。为了促进未来研究的发展，作者承诺将公开发布相关代码。&lt;h4&gt;翻译&lt;/h4&gt;点云补全的目标是从遮挡、传感器限制或噪声等因素引起的不完整观测中恢复物体完整的3D形状。当关键语义信息在不完整的点云数据中丢失时，神经网络需要根据输入的信息来推测缺失的部分。直观的想法是采用自动编码器架构解决此类问题：从不完整的点云作为输入，并通过与地面真实值比较来进行监督学习。这种将模型的想象能力从不完整形状发展到完整形状的过程是在潜在空间内自动完成的。然而，关于如何从不完整映射到完整之间的知识仍然不清楚，可以进一步研究和探索。受到知识蒸馏教师-学生学习策略启发，我们设计了一种用于点云补全的知识转移方法。在该工作中，我们提出了一种名为View Distillation Point Completion Network (VD-PCN)的新模型，通过多视角蒸馏方式解决3D形状补全问题。设计方法充分利用了二维像素的有序性、二维处理的灵活性以及二维网络的强大能力。广泛的评估证明了所提方案的有效性，并且在定量和定性的层面上都得到了验证。为了支持未来的研究发展，我们将公开发布我们的代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion aims to recover the completed 3D shape of an objectfrom its partial observation caused by occlusion, sensor's limitation, noise,etc. When some key semantic information is lost in the incomplete point cloud,the neural network needs to infer the missing part based on the inputinformation. Intuitively we would apply an autoencoder architecture to solvethis kind of problem, which take the incomplete point cloud as input and issupervised by the ground truth. This process that develops model's imaginationfrom incomplete shape to complete shape is done automatically in the latentspace. But the knowledge for mapping from incomplete to complete still remainsdark and could be further explored. Motivated by the knowledge distillation'steacher-student learning strategy, we design a knowledge transfer way forcompleting 3d shape. In this work, we propose a novel View Distillation PointCompletion Network (VD-PCN), which solve the completion problem by a multi-viewdistillation way. The design methodology fully leverages the orderliness of 2dpixels, flexibleness of 2d processing and powerfulness of 2d network. Extensiveevaluations on PCN, ShapeNet55/34, and MVP datasets confirm the effectivenessof our design and knowledge transfer strategy, both quantitatively andqualitatively. Committed to facilitate ongoing research, we will make our codepublicly available.</description>
      <author>example@mail.com (Zhanpeng Luo, Linna Wang, Guangwu Qian, Li Lu)</author>
      <guid isPermaLink="false">2501.19270v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Improving Multi-Label Contrastive Learning by Leveraging Label Distribution</title>
      <link>http://arxiv.org/abs/2501.19145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种改进多标签对比学习的新方法，通过利用标签分布来优化正样本和负样本的选择过程。&lt;h4&gt;背景&lt;/h4&gt;在多标签学习中，采用对比学习来获取更好的表示面临选择正负样本以及有效使用标签信息的挑战。之前的方法基于标签之间的重叠来选择正负样本，并用于标签级别的损失平衡。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法中复杂的样本选择过程及不同标签重要性未被充分考虑的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的多标签对比学习改进方案，通过引入两种基于径向基函数（RBF）和对比损失的方法来恢复从逻辑标签得到的标签分布，仅需关注标签之间是否存在交集。&lt;h4&gt;主要发现&lt;/h4&gt;在九个常用的多标签数据集中进行了评估，并且我们的方法在六个评价指标上都优于现有的最佳方案。&lt;h4&gt;结论&lt;/h4&gt;提出的新方法能够更有效地利用标签信息进行对比学习，在多个公共数据集上的实验结果表明该方法的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-label learning, leveraging contrastive learning to learn betterrepresentations faces a key challenge: selecting positive and negative samplesand effectively utilizing label information. Previous studies selected positiveand negative samples based on the overlap between labels and used them forlabel-wise loss balancing. However, these methods suffer from a complexselection process and fail to account for the varying importance of differentlabels. To address these problems, we propose a novel method that improvesmulti-label contrastive learning through label distribution. Specifically, whenselecting positive and negative samples, we only need to consider whether thereis an intersection between labels. To model the relationships between labels,we introduce two methods to recover label distributions from logical labels,based on Radial Basis Function (RBF) and contrastive loss, respectively. Weevaluate our method on nine widely used multi-label datasets, including imageand vector datasets. The results demonstrate that our method outperformsstate-of-the-art methods in six evaluation metrics.</description>
      <author>example@mail.com (Ning Chen, Shen-Huan Lyu, Tian-Shuang Wu, Yanyan Wang, Bin Tang)</author>
      <guid isPermaLink="false">2501.19145v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>What is causal about causal models and representations?</title>
      <link>http://arxiv.org/abs/2501.19335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个正式框架，用于确定在因果贝叶斯网络中行动如何对应于干预，并证明了某些自然的解释是循环的。&lt;h4&gt;背景&lt;/h4&gt;因果贝叶斯网络作为‘因果’模型进行预测时需要与现实世界的结果建立联系。这需要准确地定义世界中的哪些行动对应着模型内的哪种干预。&lt;h4&gt;目的&lt;/h4&gt;引入一个正式框架，使得在不同情境下将行动视作干预的要求更加精确化，并探讨因果贝叶斯网络如何成为世界的‘因果’模型而非仅仅是一个数学对象。&lt;h4&gt;方法&lt;/h4&gt;通过证明某些自然的解释是循环的，以及不存在同时满足一系列自然标准且非循环的解释来构建理论框架。&lt;h4&gt;主要发现&lt;/h4&gt;1) 将行动视为干预的标准解释会导致所有正确建模观察分布的因果贝叶斯网络在干预下都是有效的；2) 不存在能够同时是非循环并符合一系列自然期望条件的解释。&lt;h4&gt;结论&lt;/h4&gt;通过严格考察如何使因果贝叶斯网络成为世界的‘因果’模型，该论文为因果表示学习、因果发现和因果抽象的概念基础做出了贡献，并指出了现有方法的一些局限性。&lt;h4&gt;翻译&lt;/h4&gt;因果贝叶斯网络由于它们对干预分布做出预测而被认为是'因果'模型。为了将这样的因果模型预测连接到现实世界的结果，我们必须确定哪些世界的行动对应于模型中的哪一种干预。例如，要将某行为解释为在治疗变量上的干预，该行为可能需要：a) 以某种方式改变治疗的分布，这种变化与干预相对应；b) 不影响其他方面，如结果如何依赖于治疗；虽然某些变量的边际分布可能会因此发生变化。我们引入了一个正式框架来使不同类型的行为作为干预的要求更加精确化。我们证明了看似自然的解释是循环的：在这种解释下，所有正确建模观察分布的因果贝叶斯网络在干预上也都是有效的，且任何行为都不会产生可以否定这种模型的经验数据。我们还证明了一个不可能的结果：不存在同时是非循环并满足一系列自然期望条件的解释。相反地，我们研究了非循环但可能违反某些标准的解释，并展示了这如何可能导致因果模型的否证。通过严格考察因果贝叶斯网络如何成为世界的‘因果’模型而不是仅仅是一个数学对象，我们的正式框架为因果表示学习、因果发现和因果抽象的概念基础做出了贡献，同时也突显了一些现有方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal Bayesian networks are 'causal' models since they make predictionsabout interventional distributions. To connect such causal model predictions toreal-world outcomes, we must determine which actions in the world correspond towhich interventions in the model. For example, to interpret an action as anintervention on a treatment variable, the action will presumably have to a)change the distribution of treatment in a way that corresponds to theintervention, and b) not change other aspects, such as how the outcome dependson the treatment; while the marginal distributions of some variables may changeas an effect. We introduce a formal framework to make such requirements fordifferent interpretations of actions as interventions precise. We prove thatthe seemingly natural interpretation of actions as interventions is circular:Under this interpretation, every causal Bayesian network that correctly modelsthe observational distribution is trivially also interventionally valid, and noaction yields empirical data that could possibly falsify such a model. We provean impossibility result: No interpretation exists that is non-circular andsimultaneously satisfies a set of natural desiderata. Instead, we examinenon-circular interpretations that may violate some desiderata and show how thismay in turn enable the falsification of causal models. By rigorously examininghow a causal Bayesian network could be a 'causal' model of the world instead ofmerely a mathematical object, our formal framework contributes to theconceptual foundations of causal representation learning, causal discovery, andcausal abstraction, while also highlighting some limitations of existingapproaches.</description>
      <author>example@mail.com (Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald)</author>
      <guid isPermaLink="false">2501.19335v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>PixelWorld: Towards Perceiving Everything as Pixels</title>
      <link>http://arxiv.org/abs/2501.19339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个统一感知框架，将所有模态（文本、表格、代码、图表、图像等）视为像素输入，以此来解决现有基础模型在多模态处理中的问题。通过PixelWorld评估套件，作者展示了该方法在多模态数据集上的优越性能，并指出提升基础模型的感知能力是未来研究的重点。&lt;h4&gt;背景&lt;/h4&gt;现有的基础模型通常将视觉输入作为像素处理，文本输入作为标记处理，这种模式与人类感知方式不同，在后者中所有模态都是统一处理的。随着具身和代理人工智能的发展，需要一种能够统一各种输入形式的新框架来提升现有模型的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的方法“Perceive Everything as Pixels”（PEAP），并将所有数据类型统一为像素空间中的表示，以评估基础模型在感知任务上的性能，并探索其改进方向。&lt;h4&gt;方法&lt;/h4&gt;介绍了PixelWorld这个新的评估套件，它将各种模态转换成像素输入，用来测试现有模型的性能表现。此外还比较了基于标记和基于像素两种方式处理数据的效果差异。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '在多模态数据集中，PEAP优于基线方法（token-based输入），因为它可以从统一的输入中更好地进行歧义消除', '2': '所有模型在处理像素输入时推理能力和编码能力都有显著下降，显示了改进基础模型感知能力的需求', '3': '较大的模型在非推理任务上仍然表现出色，而较小的模型（如Phi-3.5-V）在使用PEAP时性能明显下滑', '4': 'PEAP与文本标记输入的注意力模式高度一致', '5': '可以通过利用空间稀疏性显著加速PEAP'}&lt;h4&gt;结论&lt;/h4&gt;尽管现有前沿模型已经具备一定的像素感知能力，但它们仍然需要进一步改进以更好地处理各种模态的数据。&lt;h4&gt;翻译&lt;/h4&gt;现有的基础模型通常将视觉输入作为像素处理，文本输入作为标记处理。随着具身和代理人工智能的发展，统一所有输入形式的需求变得日益迫切。本文提出了一种新方法——‘Perceive Everything as Pixels’ (PEAP)，即将所有数据类型视为像素输入，并通过PixelWorld评估套件展示了该方法的优越性能，特别是在多模态任务中的表现更为明显。同时，研究指出较大的模型在非推理任务上仍能保持较好的性能水平，但需要进一步提高较小模型的能力以适应新的统一感知框架的要求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing foundation models typically process visual input as pixels andtextual input as tokens, a paradigm that contrasts with human perception, whereboth modalities are processed in a unified manner. With the rise of embodiedand agentic AI, where inputs primarily come from camera pixels, the need for aunified perception framework becomes increasingly evident. In this paper, wepropose to unify all modalities (text, tables, code, diagrams, images, etc) aspixel inputs, i.e. "Perceive Everything as Pixels" (PEAP). We introducePixelWorld, a novel evaluation suite that unifies all the mentioned modalitiesinto pixel space to gauge the existing models' performance. Our findings showthat (1) PEAP outperforms baseline with token-based input in multimodaldatasets, benefiting from unified input for better disambiguation, (2)significant declines in reasoning and coding capabilities across all modelswhen processing pixel-based input, underscoring the need to enhance foundationmodels' perceptual abilities, (3) larger models can maintain strong performanceon non-reasoning tasks under PEAP, while smaller models like Phi-3.5-V suffersignificant performance degradation, (4) the attention pattern of PEAP ishighly aligned with text token input, (5) PEAP can be accelerated significantlyby exploiting the spatial sparsity. We conclude that the existing frontiermodels are competent in pixel perception, however, there is still headroom forimprovement. Our code, dataset will be released upon acceptance.</description>
      <author>example@mail.com (Zhiheng Lyu, Xueguang Ma, Wenhu Chen)</author>
      <guid isPermaLink="false">2501.19339v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Improving vision-language alignment with graph spiking hybrid Networks</title>
      <link>http://arxiv.org/abs/2501.19069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个综合的视觉语义表示模块，利用全景分割生成连贯的细粒度语义特征，并提出了一种新的Graph Spiking Hybrid Network (GSHN)，融合了脉冲神经网络(SNN)和图注意力网络(GAT)的优势。&lt;h4&gt;背景&lt;/h4&gt;现有的方法使用基于检测器的边界框或具有规则分区的补丁来表示视觉语义，但这些方法在捕捉不同对象之间的细微上下文关系方面仍然不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的视觉-语言对齐策略，以更好地处理语义多样性、抽象表示视觉信息和模型泛化能力。&lt;h4&gt;方法&lt;/h4&gt;1. 利用全景分割生成细粒度的连贯语义特征。2. 提出Graph Spiking Hybrid Network (GSHN)，整合SNN和GAT的优点来编码视觉语义信息。3. 使用对比学习(CL)增强嵌入表示的相似性，并通过构建正负样本对降低计算开销，同时丰富有意义的视觉表示。4. 设计了一种创新的预训练方法Spiked Text Learning (STL)，利用文本特征提高离散语义编码能力。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的GSHN在多个视觉-语言下游任务中表现出有希望的结果。该模型能够有效编码实例的离散和连续潜在变量，并且可以熟练捕捉局部和全局上下文特征，从而显著增强了语义表示的丰富性和多样性。&lt;h4&gt;结论&lt;/h4&gt;通过综合利用SNN和GAT的优点以及采用对比学习策略，本研究提出的方法在视觉-语言对齐任务上取得了良好的性能，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To bridge the semantic gap between vision and language (VL), it is necessaryto develop a good alignment strategy, which includes handling semanticdiversity, abstract representation of visual information, and generalizationability of models. Recent works use detector-based bounding boxes or patcheswith regular partitions to represent visual semantics. While current paradigmshave made strides, they are still insufficient for fully capturing the nuancedcontextual relations among various objects. This paper proposes a comprehensivevisual semantic representation module, necessitating the utilization ofpanoptic segmentation to generate coherent fine-grained semantic features.Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) thatintegrates the complementary advantages of Spiking Neural Networks (SNNs) andGraph Attention Networks (GATs) to encode visual semantic information.Intriguingly, the model not only encodes the discrete and continuous latentvariables of instances but also adeptly captures both local and globalcontextual features, thereby significantly enhancing the richness and diversityof semantic representations. Leveraging the spatiotemporal properties inherentin SNNs, we employ contrastive learning (CL) to enhance the similarity-basedrepresentation of embeddings. This strategy alleviates the computationaloverhead of the model and enriches meaningful visual representations byconstructing positive and negative sample pairs. We design an innovativepre-training method, Spiked Text Learning (STL), which uses text features toimprove the encoding ability of discrete semantics. Experiments show that theproposed GSHN exhibits promising results on multiple VL downstream tasks.</description>
      <author>example@mail.com (Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen)</author>
      <guid isPermaLink="false">2501.19069v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Decorrelated Soft Actor-Critic for Efficient Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2501.19133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于去相关反向传播算法的在线去相关方法，用于深度强化学习中的表示学习，以提高深度RL算法的样本效率。&lt;h4&gt;背景&lt;/h4&gt;在处理高维数据时，信用分配的有效性受深度神经网络中表示学习成功的影响，并对深度RL算法的样本效率有重要影响。输入去相关已被引入作为加速神经网络优化的方法，在有效深度学习和深度RL算法中的表示学习方法方面产生了重大影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于去相关反向传播算法的在线去相关方法，将去相关过程无缝集成到强化学习训练流程中，并通过实验验证其在提高样本效率方面的效果。&lt;h4&gt;方法&lt;/h4&gt;为每个层次添加了去相关矩阵，并使用单独的去相关学习规则对其进行更新，同时最小化所有层上的总去相关损失和标准RL损失。该方法与软演员评论(SAC)结合，在Atari 100k基准测试中进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;在七项游戏中的五项游戏中实现了更快的训练速度，并且有两项游戏显示奖励性能提高了大约50%的实际时间，同时保持了其他游戏的表现水平。&lt;h4&gt;结论&lt;/h4&gt;网络级去相关对深度RL样本效率的提高具有积极影响，通过更有效的信用分配加速其样本效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的有效性受到表示学习的成功以及用于处理高维数据时的强化学习中的信用分配的影响。输入去相关已引入为神经网络优化的方法，并且在有效深度学习和深度RL算法的有效表示学习方法方面产生了影响。提出了一种基于去相关反向传播的新在线去相关方法，该方法无缝集成到强化学习训练管道中。实验结果表明，在Atari 100k基准测试中的大部分游戏中，与常规的SAC基线相比，DSAC表现出更快的训练速度和改善了奖励性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The effectiveness of credit assignment in reinforcement learning (RL) whendealing with high-dimensional data is influenced by the success ofrepresentation learning via deep neural networks, and has implications for thesample efficiency of deep RL algorithms. Input decorrelation has beenpreviously introduced as a method to speed up optimization in neural networks,and has proven impactful in both efficient deep learning and as a method foreffective representation learning for deep RL algorithms. We propose a novelapproach to online decorrelation in deep RL based on the decorrelatedbackpropagation algorithm that seamlessly integrates the decorrelation processinto the RL training pipeline. Decorrelation matrices are added to each layer,which are updated using a separate decorrelation learning rule that minimizesthe total decorrelation loss across all layers, in parallel to minimizing theusual RL loss. We used our approach in combination with the soft actor-critic(SAC) method, which we refer to as decorrelated soft actor-critic (DSAC).Experiments on the Atari 100k benchmark with DSAC shows, compared to theregular SAC baseline, faster training in five out of the seven games tested andimproved reward performance in two games with around 50% reduction inwall-clock time, while maintaining performance levels on the other games. Theseresults demonstrate the positive impact of network-wide decorrelation in deepRL for speeding up its sample efficiency through more effective creditassignment.</description>
      <author>example@mail.com (Burcu Küçükoğlu, Sander Dalm, Marcel van Gerven)</author>
      <guid isPermaLink="false">2501.19133v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Nonparametric Contextual Dynamic Pricing</title>
      <link>http://arxiv.org/abs/2501.18836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了非参数上下文动态定价的迁移学习技术，特别是在边际分布不同的源域和目标域之间进行优化。&lt;h4&gt;背景&lt;/h4&gt;企业在最大化收入时需要根据市场条件和客户特性调整价格。然而，在缺乏历史数据的情况下（例如推出新产品或进入新市场）设计最优定价策略变得极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的迁移学习动态定价算法（TLDP），该算法能够有效利用源域的预收集数据来增强目标领域的定价决策。&lt;h4&gt;方法&lt;/h4&gt;在边际分布不同的源域和目标域之间，采用上下文转换模型，并假设奖励函数相同。此外，还建立了TLDP的遗憾上界以及匹配的最小下界。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的数值实验验证了该方法的有效性及其相对于现有方法的优势。所提出的算法适用于实际应用并具有实用价值。&lt;h4&gt;结论&lt;/h4&gt;本文贡献了一个新颖的迁移学习动态定价框架，并提供了理论分析和实证证据支持其有效性，展示了在有限历史数据情况下优化定价策略的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chrisfanwang/dynamic-pricing&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic pricing strategies are crucial for firms to maximize revenue byadjusting prices based on market conditions and customer characteristics.However, designing optimal pricing strategies becomes challenging whenhistorical data are limited, as is often the case when launching new productsor entering new markets. One promising approach to overcome this limitation isto leverage information from related products or markets to inform the focalpricing decisions. In this paper, we explore transfer learning fornonparametric contextual dynamic pricing under a covariate shift model, wherethe marginal distributions of covariates differ between source and targetdomains while the reward functions remain the same. We propose a novel TransferLearning for Dynamic Pricing (TLDP) algorithm that can effectively leveragepre-collected data from a source domain to enhance pricing decisions in thetarget domain. The regret upper bound of TLDP is established under a simpleLipschitz condition on the reward function. To establish the optimality ofTLDP, we further derive a matching minimax lower bound, which includes thetarget-only scenario as a special case and is presented for the first time inthe literature. Extensive numerical experiments validate our approach,demonstrating its superiority over existing methods and highlighting itspractical utility in real-world applications.</description>
      <author>example@mail.com (Fan Wang, Feiyu Jiang, Zifeng Zhao, Yi Yu)</author>
      <guid isPermaLink="false">2501.18836v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition</title>
      <link>http://arxiv.org/abs/2501.19010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NAACL 2025, 9pages, 1 page appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种动态音素级对比学习（DyPCL）方法，以解决失语症语音识别中性能下降的问题。&lt;h4&gt;背景&lt;/h4&gt;失语症语音识别由于患者病情的多样性及与正常语言之间的差异性，往往存在表现力降低的问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入动态音素级别的对比学习来改进失语症语音的表现能力。&lt;h4&gt;方法&lt;/h4&gt;{'Dynamic Phoneme-level Contrastive Learning (DyPCL)': '将语音分解成音素段进行音素级对比学习，并利用动态连接时序分类对齐，基于音位相似性引入动态课程学习策略，逐步从容易区分的负样本过渡到难以区分的负样本。', '区别于前人研究': '以往的研究大多集中在句子级别的嵌入上，而DyPCL通过细粒度的学习方法来识别语音中的细微部分。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能改进': '在UASpeech数据集上的评估表明，DyPCL优于基准模型，在整体失语症群体中平均减少了22.10%的单词错误率（WER）。', '挑战性提升': '通过按难度级别进行训练的方式缓解了说话者固有的可变性问题，更好地识别出具有挑战性的语音。'}&lt;h4&gt;结论&lt;/h4&gt;提出的DyPCL方法在解决失语症语音识别中的性能下降方面表现出了显著的改进效果。&lt;h4&gt;翻译&lt;/h4&gt;为了应对由于患者病情多样性和与正常语言之间的差异而导致的表现力降低的问题，在失语症言语理解领域提出了一种动态音素级对比学习（Dynamic Phoneme-level Contrastive Learning，DyPCL）方法。该方法通过细化为音素级别的学习来更好地识别语音中的细节部分，并且在训练过程中采用了基于难度等级的策略，使得系统能够更有效地处理难以区分的情况，从而显著提高了失语症言语识别的表现能力，在UASpeech数据集上的测试显示其性能优于基准模型，平均减少了22.10%的单词错误率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dysarthric speech recognition often suffers from performance degradation dueto the intrinsic diversity of dysarthric severity and extrinsic disparity fromnormal speech. To bridge these gaps, we propose a Dynamic Phoneme-levelContrastive Learning (DyPCL) method, which leads to obtaining invariantrepresentations across diverse speakers. We decompose the speech utterance intophoneme segments for phoneme-level contrastive learning, leveraging dynamicconnectionist temporal classification alignment. Unlike prior studies focusingon utterance-level embeddings, our granular learning allows discrimination ofsubtle parts of speech. In addition, we introduce dynamic curriculum learning,which progressively transitions from easy negative samples todifficult-to-distinguishable negative samples based on phonetic similarity ofphoneme. Our approach to training by difficulty levels alleviates the inherentvariability of speakers, better identifying challenging speeches. Evaluated onthe UASpeech dataset, DyPCL outperforms baseline models, achieving an average22.10\% relative reduction in word error rate (WER) across the overalldysarthria group.</description>
      <author>example@mail.com (Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee)</author>
      <guid isPermaLink="false">2501.19010v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>RIGNO: A Graph-based framework for robust and accurate operator learning for PDEs on arbitrary domains</title>
      <link>http://arxiv.org/abs/2501.19205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;学习任意域上偏微分方程(PDE)的解算子具有挑战性，原因在于可能存在的多种多样的域形状以及潜在复杂的物理原理。&lt;h4&gt;目的&lt;/h4&gt;提出一种端到端图神经网络(GNN)基元的方法来从点云数据中学习PDE解算子。&lt;h4&gt;方法&lt;/h4&gt;我们的模型RIGNO通过使用降采样区域网格在输入/输出点云之间映射数据，采用多尺度建模，并引入了多种新颖元素确保分辨率不变性和时间连续性。&lt;h4&gt;主要发现&lt;/h4&gt;在包含各种时变和稳态PDE的挑战性基准测试集上，展示了RIGNO比神经算子基线模型更为准确且能够稳健地推广到未见过的空间分辨率和时间实例。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种新的方法可以有效地学习解偏微分方程的方法，并在广泛的域形状和条件下表现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;学习PDE的解决方案操作符具有挑战性，因为可能存在多种可能的区域形状以及通常复杂的潜在物理原理。我们提出一种基于图神经网络(GNN)的端到端神经算子来从任意域上的点云数据中学习PDE解算器。我们的多尺度模型通过降采样区域网格在输入/输出点云之间映射数据，并引入了多种新颖元素以确保分辨率不变性和时间连续性。RIGNO被测试在一个由各种时变和稳态PDE组成的挑战性基准测试集上，这些PDE定义在多样化的域中。我们证明了RIGNO比神经算子基线模型更准确，并且能够稳健地推广到未见过的空间分辨率和时间实例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/camlab-ethz/rigno&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning the solution operators of PDEs on arbitrary domains is challengingdue to the diversity of possible domain shapes, in addition to the oftenintricate underlying physics. We propose an end-to-end graph neural network(GNN) based neural operator to learn PDE solution operators from data on pointclouds in arbitrary domains. Our multi-scale model maps data betweeninput/output point clouds by passing it through a downsampled regional mesh.Many novel elements are also incorporated to ensure resolution invariance andtemporal continuity. Our model, termed RIGNO, is tested on a challenging suiteof benchmarks, composed of various time-dependent and steady PDEs defined on adiverse set of domains. We demonstrate that RIGNO is significantly moreaccurate than neural operator baselines and robustly generalizes to unseenspatial resolutions and time instances.</description>
      <author>example@mail.com (Sepehr Mousavi, Shizheng Wen, Levi Lingsch, Maximilian Herde, Bogdan Raonić, Siddhartha Mishra)</author>
      <guid isPermaLink="false">2501.19205v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Learning Non-Local Molecular Interactions via Equivariant Local Representations and Charge Equilibration</title>
      <link>http://arxiv.org/abs/2501.19179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新型的用于长程相互作用建模的Charge Equilibration Layer for Long-range Interactions (CELLI)，该模型解决了传统Message-passing神经网络难以处理非局部效应的问题，并在计算成本上比MPNNs更为高效。&lt;h4&gt;背景&lt;/h4&gt;基于化学局域性的图神经网络（GNN）能够以较低的计算成本达到接近量子力学级别的准确性。然而，这种局限性阻碍了长程效应如电荷转移、静电相互作用和色散效应等的建模。&lt;h4&gt;目的&lt;/h4&gt;解决非局部相互作用建模的问题，并降低传统MPNN模型的高计算成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为Charge Equilibration Layer for Long-range Interactions (CELLI)的新架构，它结合了第四代高维神经网络（4GHDNN）的概念和电荷均衡方法，形成了一种适用于现代等变GNN潜力的功能模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过一系列基准测试证明，CELLI能够扩展严格局域化的Allegro架构以建模高度非局部相互作用以及电荷转移，并且在准确度上与MPNNs相当，但计算效率大约是其两倍。&lt;h4&gt;结论&lt;/h4&gt;该新型架构具有广泛的适用性，在各种数据集和大规模结构中都能实现高精度，同时保持较低的计算成本。&lt;h4&gt;翻译&lt;/h4&gt;基于图神经网络（GNN）的潜力利用化学局部性提供接近量子力学级别的准确性，但减少了显著的计算成本。通过传播本地信息到距离较远的粒子上，消息传递神经网络（MPNNs）扩展了局部概念以建模超出其邻域范围的相互作用。然而，这种局域性阻碍了长程效应如电荷转移、静电相互作用和色散效应等模型的建立，这些都是许多现实世界系统精确描述的关键因素。在这项工作中，我们提出了用于长程相互作用的Charge Equilibration Layer for Long-range Interactions (CELLI)，以解决非局部相互作用建模的问题以及MPNNs的高计算成本问题。这种新型架构概括了第四代高维神经网络（4GHDNN）的概念，将电荷均衡方法整合为适用于现代等变GNN潜力的模型无关功能模块。一系列基准测试表明，CELLI可以扩展严格局域化的Allegro架构以建模高度非局部相互作用和电荷转移。我们的架构在多样数据集和大规模结构中具有普适性，在精度上与MPNNs相当但计算效率为大约两倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Network (GNN) potentials relying on chemical locality offernear-quantum mechanical accuracy at significantly reduced computational costs.By propagating local information to distance particles, Message-passing neuralnetworks (MPNNs) extend the locality concept to model interactions beyond theirlocal neighborhood. Still, this locality precludes modeling long-range effects,such as charge transfer, electrostatic interactions, and dispersion effects,which are critical to adequately describe many real-world systems. In thiswork, we propose the Charge Equilibration Layer for Long-range Interactions(CELLI) to address the challenging modeling of non-local interactions and thehigh computational cost of MPNNs. This novel architecture generalizes thefourth-generation high-dimensional neural network (4GHDNN) concept, integratingthe charge equilibration (Qeq) method into a model-agnostic building block formodern equivariant GNN potentials. A series of benchmarks show that CELLI canextend the strictly local Allegro architecture to model highly non-localinteractions and charge transfer. Our architecture generalizes to diversedatasets and large structures, achieving an accuracy comparable to MPNNs atabout twice the computational efficiency.</description>
      <author>example@mail.com (Paul Fuchs, Michał Sanocki, Julija Zavadlav)</author>
      <guid isPermaLink="false">2501.19179v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Clustering in hyperbolic balls</title>
      <link>http://arxiv.org/abs/2501.19247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，在负曲率流形上表示数据的想法引起了广泛关注，并催生了一个名为‘双曲机器学习’的新研究方向。&lt;h4&gt;目的&lt;/h4&gt;为了揭示这一新范式的所有潜力，需要高效的数据分析和统计建模技术在双曲空间中使用。&lt;h4&gt;方法&lt;/h4&gt;{'第一部分': '提出了基于新颖定义的中心（barycenter）的双曲球中的$k$-均值聚类。', '第二部分': '介绍了学习新概率分布混合物的期望最大化算法，这些分布在双曲球内。'}&lt;h4&gt;主要发现&lt;/h4&gt;建立了在双曲空间中进行聚类的严格数学框架，并为无监督学习奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;该研究为在双曲空间中的数据分析和统计建模提供了必要的技术支撑。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文版本，涉及数据表示、负曲率流形、机器学习、高效分析方法和技术等内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The idea of representations of the data in negatively curved manifoldsrecently attracted a lot of attention and gave a rise to the new researchdirection named {\it hyperbolic machine learning} (ML). In order to unveil thefull potential of this new paradigm, efficient techniques for data analysis andstatistical modeling in hyperbolic spaces are necessary. In the present paperrigorous mathematical framework for clustering in hyperbolic spaces isestablished. First, we introduce the $k$-means clustering in hyperbolic balls,based on the novel definition of barycenter. Second, we present theexpectation-maximization (EM) algorithm for learning mixtures of novelprobability distributions in hyperbolic balls. In such a way we lay thefoundation of unsupervised learning in hyperbolic spaces.</description>
      <author>example@mail.com (Vladimir Jaćimović, Aladin Crnkić)</author>
      <guid isPermaLink="false">2501.19247v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Magic Elevating Depression Detection with a Fusion of Text and Audio Intelligence</title>
      <link>http://arxiv.org/abs/2501.16813v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages,7 figures.1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于教师-学生架构的创新多模态融合模型，以提高抑郁症分类的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统方法在特征融合和模式权重分配方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;通过引入多头注意力机制和加权多模态迁移学习来改进现有模型。&lt;h4&gt;方法&lt;/h4&gt;利用DAIC-WOZ数据集，学生融合模型在文本和音频教师模型的指导下提高了分类准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明该模型在测试集中取得了99.1%的F1分数，显著优于单模态和其他传统方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效捕捉文本和音频特征之间的互补性，并通过动态调整教师模型的贡献来增强泛化能力。此研究为抑郁症分析中的多模态大型模型学习提供了一个新的技术框架。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了基于教师-学生架构的一个创新多模态融合模型，以提高抑郁症分类的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study proposes an innovative multimodal fusion model based on ateacher-student architecture to enhance the accuracy of depressionclassification. Our designed model addresses the limitations of traditionalmethods in feature fusion and modality weight allocation by introducingmulti-head attention mechanisms and weighted multimodal transfer learning.Leveraging the DAIC-WOZ dataset, the student fusion model, guided by textualand auditory teacher models, achieves significant improvements inclassification accuracy. Ablation experiments demonstrate that the proposedmodel attains an F1 score of 99. 1% on the test set, significantlyoutperforming unimodal and conventional approaches. Our method effectivelycaptures the complementarity between textual and audio features whiledynamically adjusting the contributions of the teacher models to enhancegeneralization capabilities. The experimental results highlight the robustnessand adaptability of the proposed framework in handling complex multimodal data.This research provides a novel technical framework for multimodal large modellearning in depression analysis, offering new insights into addressing thelimitations of existing methods in modality fusion and feature extraction.</description>
      <author>example@mail.com (Lindy Gan, Yifan Huang, Xiaoyang Gao, Jiaming Tan, Fujun Zhao, Tao Yang)</author>
      <guid isPermaLink="false">2501.16813v2</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>No Foundations without Foundations -- Why semi-mechanistic models are essential for regulatory biology</title>
      <link>http://arxiv.org/abs/2501.19178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;尽管在基因表达预测方面做出了巨大努力，深度学习尚未对揭示调控生物学产生革命性的影响。本文提出了一种基于机制的综合框架，该框架结合了体内和体外CRISPR筛选中的扰动实验设计，并针对分化与非分化的细胞系统进行调整。&lt;h4&gt;背景&lt;/h4&gt;尽管在基因表达预测方面取得了重大进展，但深度学习尚未对揭示调控生物学产生革命性的影响。目前的方法未能充分利用实验设计中蕴含的先验知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种将机制洞察力和原则性实验设计相结合的框架，以实现调节生物科学的基础模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一个从头开始构建、半机械化的框架，该框架统一了体内与体外CRISPR筛选中的扰动实验设计，并针对分化与非分化的细胞系统进行了调整。通过揭示已发表机器学习方法中未被注意的假设，阐明了这一方法与其他流行技术（如变分自动编码器和结构因果模型）之间的联系。&lt;h4&gt;主要发现&lt;/h4&gt;该框架建议了一种改进预测性能的修改损失函数，并提出了影响批量策略的误差分析方法。此外，揭示了解释生物学现象、生成数据的过程如何在更忠实的建模架构中体现的重要性。&lt;h4&gt;结论&lt;/h4&gt;细胞调控来自于无数未知分子成分之间的相互作用，因此通过结构生物学单独实现系统级别的理解是不可能的。需要从原理出发审视实验如何捕捉生物现象，以及这些过程如何反映在更准确的模型设计中。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在此领域已付出巨大努力，深度学习尚未对阐明调控生物学产生革命性的影响，尤其是在预测基因表达谱方面。在这里，我们论证除非通过整合机制洞察与原则性实验设计框架的指引，“真正的基础模型”将难以实现。我们提出了一种从底层构建、半机械化的框架，该框架统一了基于扰动的设计在体外和体内CRISPR筛选中使用，并适用于分化及非分化的细胞系统。通过揭示发表的机器学习方法中的未被注意假设，我们的方法阐明了与流行技术（如变分自动编码器和结构因果模型）之间的联系。从实践来看，该框架建议了一种能够改善预测性能的修改损失函数，并提出了一种误差分析策略以指导批量设计。最终，由于细胞调控源自无数分子成分间的相互作用，而这些成分为未知领域，我们认为仅通过结构生物学不能达到系统级别的理解层次。相反，我们需要从基本原则出发看待实验如何捕捉生物现象、数据生成过程以及这些流程在更准确建模架构中的反映方法论视角以实现真正的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite substantial efforts, deep learning has not yet delivered atransformative impact on elucidating regulatory biology, particularly in therealm of predicting gene expression profiles. Here, we argue that genuine"foundation models" of regulatory biology will remain out of reach unlessguided by frameworks that integrate mechanistic insight with principledexperimental design. We present one such ground-up, semi-mechanistic frameworkthat unifies perturbation-based experimental designs across both in vitro andin vivo CRISPR screens, accounting for differentiating and non-differentiatingcellular systems. By revealing previously unrecognised assumptions in publishedmachine learning methods, our approach clarifies links with popular techniquessuch as variational autoencoders and structural causal models. In practice,this framework suggests a modified loss function that we demonstrate canimprove predictive performance, and further suggests an error analysis thatinforms batching strategies. Ultimately, since cellular regulation emerges frominnumerable interactions amongst largely uncharted molecular components, wecontend that systems-level understanding cannot be achieved through structuralbiology alone. Instead, we argue that real progress will require afirst-principles perspective on how experiments capture biological phenomena,how data are generated, and how these processes can be reflected in morefaithful modelling architectures.</description>
      <author>example@mail.com (Luka Kovačević, Thomas Gaudelet, James Opzoomer, Hagen Triendl, John Whittaker, Caroline Uhler, Lindsay Edwards, Jake P. Taylor-King)</author>
      <guid isPermaLink="false">2501.19178v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning Using Nonlinear Dependence</title>
      <link>http://arxiv.org/abs/2501.18875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的自监督学习框架CDSSL，该框架结合了线性相关和非线性依赖关系，旨在提高复杂数据的表示质量。&lt;h4&gt;背景&lt;/h4&gt;当前自监督学习方法主要关注特征变化和线性关联，但对于样本之间的复杂关系以及非线性依赖关系考虑不足。这导致在缺乏标记数据的情况下难以获得有效的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的自监督学习框架CDSSL，通过整合现有的SSL方法并加入非线性依赖捕捉能力来改进复杂的表示学习问题。&lt;h4&gt;方法&lt;/h4&gt;引入Hilbert-Schmidt独立度量（HSIC）准则在重生成核希尔伯特空间中捕获非线性关系。该方法不仅关注样本级别的交互作用，还关注特征级别的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了CDSSL框架在多种基准数据集上的有效性，证明它能够提高表示质量。&lt;h4&gt;结论&lt;/h4&gt;新提出的Correlation-Dependence Self-Supervised Learning（CDSSL）框架为自监督学习提供了一种新的视角和实现方法，展示了其在未来研究中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的原始英文文本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has gained significant attention in contemporaryapplications, particularly due to the scarcity of labeled data. While existingSSL methodologies primarily address feature variance and linear correlations,they often neglect the intricate relations between samples and the nonlineardependencies inherent in complex data. In this paper, we introduceCorrelation-Dependence Self-Supervised Learning (CDSSL), a novel framework thatunifies and extends existing SSL paradigms by integrating both linearcorrelations and nonlinear dependencies, encapsulating sample-wise andfeature-wise interactions. Our approach incorporates the Hilbert-SchmidtIndependence Criterion (HSIC) to robustly capture nonlinear dependencies withina Reproducing Kernel Hilbert Space, enriching representation learning.Experimental evaluations on diverse benchmarks demonstrate the efficacy ofCDSSL in improving representation quality.</description>
      <author>example@mail.com (M. Hadi Sepanj, Benyamin Ghojogh, Paul Fieguth)</author>
      <guid isPermaLink="false">2501.18875v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Early Diagnosis and Severity Assessment of Weligama Coconut Leaf Wilt Disease and Coconut Caterpillar Infestation using Deep Learning-based Image Processing Techniques</title>
      <link>http://arxiv.org/abs/2501.18835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究提出了一种使用基于迁移学习的卷积神经网络（CNN）和Mask区域基础-CNN（Mask R-CNN）来早期识别椰子叶枯萎病（WCWLD）和椰子毛虫侵害（CCI），并通过收集自斯里兰卡马塔拉、普特拉姆和马坎杜拉的数据集进行测试，结果表明所提方法可以以90%的准确率识别WCWLD和95%的准确率识别CCI，并且对于计算叶上的毛虫数量，YOLOv5模型显示了最高的准确性。&lt;h4&gt;背景&lt;/h4&gt;全球椰子种植面临病害爆发导致的产量损失等挑战。特别是斯里兰卡及其邻国受到椰子叶枯萎病（WCWLD）和椰子毛虫侵害（CCI）的影响，目前这两种疾病的检测主要依赖于人工观察，耗时且难以实现早期发现。&lt;h4&gt;目的&lt;/h4&gt;展示使用卷积神经网络（CNN）、Mask R-CNN 和 YOLO 对 WCWLD 和 CCI 进行早期识别，并计算受感染叶子上的毛虫数量的准确性。&lt;h4&gt;方法&lt;/h4&gt;研究团队在斯里兰卡进行了实地测试，使用来自马塔拉、普特拉姆和马坎杜拉地区的数据集评估了基于迁移学习的方法对于椰子叶枯萎病（WCWLD）和椰子毛虫侵害（CCI）早期识别的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法能够以90%的准确率识别WCWLD，95%的准确率识别CCI。此外，通过使用YOLO模型对叶子上的毛虫数量进行计数，YOLOv5显示了最高的准确性为96.87%，其次是YOLOv8（96.1%）和YOLO11（95.9%）。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于CNN和Mask R-CNN的识别方法在早期诊断WCWLD和CCI方面表现出色，并且对计算叶上毛虫数量的方法也显示出高精度，这为椰子生产损失提供了一种有效的预防措施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ACCESS.2025.3537664&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global Coconut (Cocos nucifera (L.)) cultivation faces significantchallenges, including yield loss, due to pest and disease outbreaks. Inparticular, Weligama Coconut Leaf Wilt Disease (WCWLD) and Coconut CaterpillarInfestation (CCI) damage coconut trees, causing severe coconut production lossin Sri Lanka and nearby coconut-producing countries. Currently, both WCWLD andCCI are detected through on-field human observations, a process that is notonly time-consuming but also limits the early detection of infections. Thispaper presents a study conducted in Sri Lanka, demonstrating the effectivenessof employing transfer learning-based Convolutional Neural Network (CNN) andMask Region-based-CNN (Mask R-CNN) to identify WCWLD and CCI at their earlystages and to assess disease progression. Further, this paper presents the useof the You Only Look Once (YOLO) object detection model to count the number ofcaterpillars distributed on leaves with CCI. The introduced methods were testedand validated using datasets collected from Matara, Puttalam, and Makandura,Sri Lanka. The results show that the proposed methods identify WCWLD and CCIwith an accuracy of 90% and 95%, respectively. In addition, the proposed WCWLDdisease severity identification method classifies the severity with an accuracyof 97%. Furthermore, the accuracies of the object detection models forcalculating the number of caterpillars in the leaflets were: YOLOv5-96.87%,YOLOv8-96.1%, and YOLO11-95.9%.</description>
      <author>example@mail.com (Samitha Vidhanaarachchi, Janaka L. Wijekoon, W. A. Shanaka P. Abeysiriwardhana, Malitha Wijesundara)</author>
      <guid isPermaLink="false">2501.18835v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification</title>
      <link>http://arxiv.org/abs/2501.19086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for presentation at the 2025 IEEE  International Symposium on Biomedical Imaging (ISBI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;X射线成像是医学诊断中不可或缺的一部分，可以为各种健康状况提供非侵入性的洞察。最近，诸如对比语言-图像预训练（CLIP）模型之类的视觉语言模型通过利用大规模的图像文本数据集，在提高诊断准确性方面展示了潜力。然而，由于CLIP最初并不是为了医疗影像设计的，因此开发了几个专门为医学图像训练的类似CLIP的模型。尽管这些模型在性能上有了一定提升，但关于公平性的问题，特别是在涉及人口统计属性时，仍然几乎没有得到解决。&lt;h4&gt;背景&lt;/h4&gt;X射线成像技术对于诊断多种健康状况至关重要，并且最近视觉语言模型如CLIP通过使用大规模图像文本数据集显示出提高医学诊断准确性的潜力。然而这些模型在医疗影像的应用上存在公平性问题，特别是在人口统计属性方面。&lt;h4&gt;目的&lt;/h4&gt;对类似CLIP的模型应用于X射线影像分类时进行全面的公平性分析，并评估它们在不同患者人群和疾病类别中的性能与公平性。&lt;h4&gt;方法&lt;/h4&gt;使用零样本推理以及包括线性探测、多层感知器（MLP）、低秩适应（LoRA）和全量微调在内的各种微调技术来评估这些模型。&lt;h4&gt;主要发现&lt;/h4&gt;尽管通过微调可以提高模型的准确性，但公平性的担忧仍然存在。这表明在这些基础模型中需要进一步进行公平性干预。&lt;h4&gt;结论&lt;/h4&gt;为了改善医学图像分类模型的性能和公平性问题，未来的研究应当专注于开发更加全面的方法来解决当前存在的公平性挑战。&lt;h4&gt;翻译&lt;/h4&gt;X射线成像是医疗诊断中的关键工具，提供了一系列健康状况的非侵入性视图。最近，像CLIP这样的视觉语言模型通过利用大规模图像-文本数据集，在提高准确性方面显示了潜力。然而由于它们最初并非为医学影像设计的，所以开发了许多专门为医学影像训练的类似CLIP的模型。尽管这些新模型在性能上有所提升，但关于公平性的问题（特别是涉及人口统计属性）仍然鲜少有人探讨。这项研究对应用于X射线图像分类中的此类模型进行了全面的公平性分析，并使用零样本推理和包括线性探测、多层感知器(MLP)、低秩适应(LoRA)和全量微调在内的各种技术，评估了它们在不同患者群体和疾病类别中的性能与公平性。研究结果表明：尽管微调可以提高模型的准确性，但其公平性问题仍需进一步解决，这凸显出未来对这类基础模型进行更多公平性干预的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; X-ray imaging is pivotal in medical diagnostics, offering non-invasiveinsights into a range of health conditions. Recently, vision-language models,such as the Contrastive Language-Image Pretraining (CLIP) model, havedemonstrated potential in improving diagnostic accuracy by leveraginglarge-scale image-text datasets. However, since CLIP was not initially designedfor medical images, several CLIP-like models trained specifically on medicalimages have been developed. Despite their enhanced performance, issues offairness - particularly regarding demographic attributes - remain largelyunaddressed. In this study, we perform a comprehensive fairness analysis ofCLIP-like models applied to X-ray image classification. We assess theirperformance and fairness across diverse patient demographics and diseasecategories using zero-shot inference and various fine-tuning techniques,including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation(LoRA), and full fine-tuning. Our results indicate that while fine-tuningimproves model accuracy, fairness concerns persist, highlighting the need forfurther fairness interventions in these foundational models.</description>
      <author>example@mail.com (Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang)</author>
      <guid isPermaLink="false">2501.19086v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization</title>
      <link>http://arxiv.org/abs/2501.18793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Transformer模型在众多任务中表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一种连续时间形式的Transformer，通过最优传输理论对其进行正则化以增强训练稳定性并改善泛化能力。&lt;h4&gt;方法&lt;/h4&gt;将动力系统方程参数化为由Transformer块构成，并利用最优传输理论进行正则化。该模型具有灵活性，可以几乎采用任何现有的Transformer架构来构建动力学系统。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了这种正则化是必要的，因为它促进了解的唯一性和规律性；实验结果显示所提出的连续时间方法改进了离散版本的效果，并优于相关比较模型。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了将最优传输理论应用于Transformer网络的可能性和有效性，可以进一步提高其性能。&lt;h4&gt;翻译&lt;/h4&gt;变换器在多种任务中达到了最先进的表现。本文提出了一种连续时间的变换器表述方式。具体而言，我们考虑了一个由变换器模块参数化的动力系统方程。利用最优传输理论来正则化训练问题，这增强了训练过程中的稳定性，并改善了生成模型的泛化能力。此外，理论上证明这种正则化是必要的因为它促进了解的唯一性和规律性。我们的模型具有灵活性，因为几乎所有的现有变换器架构都可以采用稍作修改后的代码构建动力系统。我们在自然语言处理、图像分类和点云分类任务上进行了广泛的数值实验。实验证明了所提出的方法改进了离散版本的表现，并优于相关的比较模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have achieved state-of-the-art performance in numerous tasks. Inthis paper, we propose a continuous-time formulation of transformers.Specifically, we consider a dynamical system whose governing equation isparametrized by transformer blocks. We leverage optimal transport theory toregularize the training problem, which enhances stability in training andimproves generalization of the resulting model. Moreover, we demonstrate intheory that this regularization is necessary as it promotes uniqueness andregularity of solutions. Our model is flexible in that almost any existingtransformer architectures can be adopted to construct the dynamical system withonly slight modifications to the existing code. We perform extensive numericalexperiments on tasks motivated by natural language processing, imageclassification, and point cloud classification. Our experimental results showthat the proposed method improves the performance of its discrete counterpartand outperforms relevant comparing models.</description>
      <author>example@mail.com (Kelvin Kan, Xingjian Li, Stanley Osher)</author>
      <guid isPermaLink="false">2501.18793v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Learning the Hamiltonian Matrix of Large Atomic Systems</title>
      <link>http://arxiv.org/abs/2501.19110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  *Equal Contribution&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种严格局部等变图神经网络，能够学习现实材料的电子哈密顿量。这种方法通过引入增强分割策略，在处理任意大小结构的同时保持了原子环境的局部特性。&lt;h4&gt;背景&lt;/h4&gt;基于图形的神经网络在预测材料的基础状态电子属性方面表现出色，尤其是在可以表示为小型或可重复单元格（如分子和周期性晶体）的情况下能够替代第一原理密度泛函理论计算。然而，在实际系统中，这些理想情况往往并不存在，非理想的现实体系通常具有更高的结构复杂性和更大的单元细胞。&lt;h4&gt;目的&lt;/h4&gt;该研究的目的是开发一种新的图神经网络方法来解决真实材料中的电子属性预测问题，特别是那些难以通过传统DFT计算处理的大规模和复杂系统。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一种严格局部等变GNN模型，可以学习现实扩展材料的电子哈密顿量。该模型采用增强分割策略，可以在保持原子环境局部特性的同时训练任意大小结构的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用所提出的模型预测各种包含多达3,000个节点（原子），50万+条边和近28百万轨道相互作用（H的非零元素）的系统的电子哈密顿量，研究团队证明了该模型在特征值谱误差不超过0.55%的情况下具有强大能力。&lt;h4&gt;结论&lt;/h4&gt;这项工作扩展了现有电子属性预测方法的应用范围，并解决了计算材料科学中最具挑战性的问题之一：处理无序、界面和缺陷系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have shown promise in learning the ground-stateelectronic properties of materials, subverting ab initio density functionaltheory (DFT) calculations when the underlying lattices can be represented assmall and/or repeatable unit cells (i.e., molecules and periodic crystals).Realistic systems are, however, non-ideal and generally characterized by higherstructural complexity. As such, they require large (10+ Angstroms) unit cellsand thousands of atoms to be accurately described. At these scales, DFT becomescomputationally prohibitive, making GNNs especially attractive. In this work,we present a strictly local equivariant GNN capable of learning the electronicHamiltonian (H) of realistically extended materials. It incorporates anaugmented partitioning approach that enables training on arbitrarily largestructures while preserving local atomic environments beyond boundaries. Wedemonstrate its capabilities by predicting the electronic Hamiltonian ofvarious systems with up to 3,000 nodes (atoms), 500,000+ edges, ~28 millionorbital interactions (nonzero entries of H), and $\leq$0.55% error in theeigenvalue spectra. Our work expands the applicability of current electronicproperty prediction methods to some of the most challenging cases encounteredin computational materials science, namely systems with disorder, interfaces,and defects.</description>
      <author>example@mail.com (Chen Hao Xia, Manasa Kaniselvan, Alexandros Nikolaos Ziogas, Marko Mladenović, Rayen Mahjoub, Alexander Maeder, Mathieu Luisier)</author>
      <guid isPermaLink="false">2501.19110v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Are Representation Disentanglement and Interpretability Linked in Recommendation Models? A Critical Review and Reproducibility Study</title>
      <link>http://arxiv.org/abs/2501.18805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 47th European Conference on Information Retrieval  (ECIR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;这篇论文研究了无监督学习中解纠缠表示在推荐系统中的应用，量化了解纠缠与推荐效果和表征可解释性之间的关系。&lt;h4&gt;背景&lt;/h4&gt;无监督学习的解纠缠方法被认为可以增强推荐系统的表示可解释性和特征贡献度。然而之前的研究主要集中在定性的探索上，而忽视了对模型推荐性能的影响。&lt;h4&gt;目的&lt;/h4&gt;重现五种知名推荐模型在四个数据集上的推荐表现、表示解纠缠和表征可解释性，并探究它们之间的量化关系。&lt;h4&gt;方法&lt;/h4&gt;通过实验评估五个推荐模型的推荐效果、特征分离度以及表示理解能力，以此来研究解纠缠与推荐性能的关系。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，虽然解纠缠被认为可以提升有效性（即推荐效果）和表征可解释性，但实际数据证明解纠缠并不一定直接影响到推荐的效果，而是更直接地影响到了表示的可解释性。&lt;h4&gt;结论&lt;/h4&gt;通过公开代码和实验结果验证了上述发现，并在GitHub上提供项目链接以供进一步研究。&lt;h4&gt;翻译&lt;/h4&gt;无监督学习中，解纠缠表示与提高推荐系统的表征可解释性紧密相关。这主要是通过对个体特征的表示做出更明确区分来实现的，从而使特征贡献更容易归因于模型预测。然而，这种增强可解释性和特征归属的优势主要被定性的探索所研究，并且解纠缠对模型推荐性能的影响被广泛忽视。在这项工作中，我们复现了五种著名推荐模型在四个推荐系统数据集上的推荐表现、表示解纠缠和表征可解释性。我们量化了解纠缠，并调查了其与推荐效果及表示可解释性的关联。虽然现有的推荐系统工作提出了通过解纠缠表示提高有效性和可解释性的方法，但我们的研究结果表明，解纠缠不一定与有效性相关联，而是与表示的可解释性紧密相关。本项目的代码和结果在https://github.com/edervishaj/disentanglement-interpretability-recsys上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/edervishaj/disentanglement-interpretability-recsys&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised learning of disentangled representations has been closely tiedto enhancing the representation intepretability of Recommender Systems (RSs).This has been achieved by making the representation of individual features moredistinctly separated, so that it is easier to attribute the contribution offeatures to the model's predictions. However, such advantages ininterpretability and feature attribution have mainly been exploredqualitatively. Moreover, the effect of disentanglement on the model'srecommendation performance has been largely overlooked. In this work, wereproduce the recommendation performance, representation disentanglement andrepresentation interpretability of five well-known recommendation models onfour RS datasets. We quantify disentanglement and investigate the link ofdisentanglement with recommendation effectiveness and representationinterpretability. While several existing work in RSs have proposed disentangledrepresentations as a gateway to improved effectiveness and interpretability,our findings show that disentanglement is not necessarily related toeffectiveness but is closely related to representation interpretability. Ourcode and results are publicly available athttps://github.com/edervishaj/disentanglement-interpretability-recsys.</description>
      <author>example@mail.com (Ervin Dervishaj, Tuukka Ruotsalo, Maria Maistro, Christina Lioma)</author>
      <guid isPermaLink="false">2501.18805v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Oversmoothing in GNNs as Consensus in Opinion Dynamics</title>
      <link>http://arxiv.org/abs/2501.19089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了图神经网络（GNN）中的过度平滑现象，并提出了一种基于非线性意见动态的新连续深度GNN模型BIMP，解决了普遍输入下的过度平滑问题。&lt;h4&gt;背景&lt;/h4&gt;与神经网络学习表示随着网络深度的增加而变得越来越复杂不同，在图神经网络中，学习到的表示趋向于越来越相似。这种现象被称为过度平滑，导致预测性能下降。&lt;h4&gt;目的&lt;/h4&gt;通过类比图神经网络中的过度平滑和意见动力学（如线性共识模型）中的共识或一致性的方法，设计一种能够避免普遍输入下过度平滑的新连续深度GNN模型。&lt;h4&gt;方法&lt;/h4&gt;利用对意见动态的理解，作者基于非线性意见动态提出了行为启发的消息传递神经网络（BIMP），并通过理论证明了该模型可以避开过度平滑问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的BIMP模型能够有效地应对过度平滑和对抗攻击，并在多个基准测试中优于竞争的基线模型。&lt;h4&gt;结论&lt;/h4&gt;论文通过类比图神经网络中的过度平滑现象与意见动力学中的共识或一致性的方法，设计了一种新的连续深度GNN模型BIMP。这种新模型可以有效解决普遍输入下的过度平滑问题，并表现出更好的性能稳定性及对抗性。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于研究图神经网络（GNN）中过度平滑现象的论文摘要，提出了解决该问题的新方法——行为启发的消息传递神经网络（BIMP）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contrast to classes of neural networks where the learned representationsbecome increasingly expressive with network depth, the learned representationsin graph neural networks (GNNs), tend to become increasingly similar. Thisphenomena, known as oversmoothing, is characterized by learned representationsthat cannot be reliably differentiated leading to reduced predictiveperformance. In this paper, we propose an analogy between oversmoothing in GNNsand consensus or agreement in opinion dynamics. Through this analogy, we showthat the message passing structure of recent continuous-depth GNNs isequivalent to a special case of opinion dynamics (i.e., linear consensusmodels) which has been theoretically proven to converge to consensus (i.e.,oversmoothing) for all inputs. Using the understanding developed through thisanalogy, we design a new continuous-depth GNN model based on nonlinear opiniondynamics and prove that our model, which we call behavior-inspired messagepassing neural network (BIMP) circumvents oversmoothing for general inputs.Through extensive experiments, we show that BIMP is robust to oversmoothing andadversarial attack, and consistently outperforms competitive baselines onnumerous benchmarks.</description>
      <author>example@mail.com (Keqin Wang, Yulong Yang, Ishan Saha, Christine Allen-Blanchette)</author>
      <guid isPermaLink="false">2501.19089v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Unpaired Translation of Point Clouds for Modeling Detector Response</title>
      <link>http://arxiv.org/abs/2501.18674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS Machine Learning and the Physical Sciences Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的框架，用于解决时间投影室中检测器响应建模的问题。&lt;h4&gt;背景&lt;/h4&gt;在时间投影室(TPC)中，模拟数据和实验数据之间的映射是一个关键问题。这个问题被看作是无配对点云翻译任务。&lt;h4&gt;目的&lt;/h4&gt;通过有效转换来帮助噪声消除，并构建高保真度的仿真器。&lt;h4&gt;方法&lt;/h4&gt;基于最近的概率扩散模型工作，提出了一种新的框架来进行这种映射。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法在合成域和从Active-Target TPC收集的数据中都取得了成功。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一个有效的解决方案来处理TPC中的检测器响应建模问题。&lt;h4&gt;翻译&lt;/h4&gt;建模探测器响应是时间投影室(TPC)中的关键挑战。我们将这个问题看作是从模拟数据和实验运行数据之间进行无配对点云转换的任务。有效的转换可以帮助噪声消除，并构建高保真度的仿真器。基于最近的概率扩散模型的工作，我们提出了一种新的框架来执行这种映射。我们在合成域以及从Active-Target TPC收集的数据中都展示了这种方法的成功应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling detector response is a key challenge in time projection chambers. Wecast this problem as an unpaired point cloud translation task, between datacollected from simulations and from experimental runs. Effective translationcan assist with both noise rejection and the construction of high-fidelitysimulators. Building on recent work in diffusion probabilistic models, wepresent a novel framework for performing this mapping. We demonstrate thesuccess of our approach in both synthetic domains and in data sourced from theActive-Target Time Projection Chamber.</description>
      <author>example@mail.com (Mingyang Li, Michelle Kuchera, Raghuram Ramanujan, Adam Anthony, Curtis Hunt, Yassid Ayyad)</author>
      <guid isPermaLink="false">2501.18674v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying HiPSC-CM Structural Organization at Scale with Deep Learning-Enhanced SarcGraph</title>
      <link>http://arxiv.org/abs/2501.18714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这项研究扩展了SarcGraph计算框架，以更好地适应未成熟心脏细胞的结构特征。通过改进后的框架，可以从公开的数据集中提取关键的结构特性，并使用这些结构特征预测专家评分和识别专家评分中的偏见。&lt;h4&gt;背景&lt;/h4&gt;在心脏细胞中，结构组织是细胞成熟度和健康功能的重要指标。健康的成肌细胞表现出排列整齐且紧凑有组织的形态，而未成熟的或患病的心肌细胞则缺乏这种有序结构。&lt;h4&gt;目的&lt;/h4&gt;改进SarcGraph计算框架，使其能够更准确地分析人类诱导多能干细胞衍生心肌细胞（hiPSC-CMs）中的不规则结构，从而更好地理解心脏细胞的功能和健康状态。&lt;h4&gt;方法&lt;/h4&gt;1) 引入基于深度学习的Z-disc分类器；2) 采用新的集成图评分法。这些改进显著降低了未成熟细胞中假阳性肌节检测，并提高了成熟样本中肌原纤维长度的检测能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过优化后的SarcGraph框架，首次能够从公开数据集中提取关键结构特性，用以预测专家打分及识别其中可能存在的偏见。此外还提出了一种基于可解释聚类的无监督学习方法。&lt;h4&gt;结论&lt;/h4&gt;改进后的SarcGraph框架在提取具有生物学意义特征方面非常有效，有助于深入理解hiPSC-CM的结构完整性和健康状态。通过开源代码和工具，研究者希望推动心脏组织分析领域的计算工具的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何利用改进的SarcGraph计算框架来更好地分析未成熟或患病的心肌细胞中的不规则结构，并通过公开数据集验证了该方法的有效性，同时提供了基于无监督学习的新方法来识别专家评分中的偏见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In cardiac cells, structural organization is an important indicator of cellmaturity and healthy function. Healthy cardiomyocytes exhibit well-alignedmorphology with densely packed and organized sarcomeres. Immature or diseasedcardiomyocytes typically lack this organized structure. Critically, humaninduced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) offer avaluable model for studying human cardiac cells in a controlled environment.However, these cells often exhibit a disorganized structure. In this work, weextend the SarcGraph computational framework -- designed to assess thestructural and functional behavior of hiPSC-CMs -- to better accommodate thestructural features of immature cells. There are two key enhancements: (1)incorporating a deep learning-based z-disc classifier, and (2) introducing anovel ensemble graph-scoring approach. These modification significantly reducedfalse positive sarcomere detections in immature cells, and resulted in thedetection of longer myofibrils in mature samples. With this enhanced framework,we analyze an open-source dataset published by the Allen Institute for CellScience, where, for the first time, we are able to extract key structuralfeatures from these data using information from each individually detectedsarcomere. Not only are we able to use these structural features to predictexpert scores, but we are also able to use these structural features toidentify bias in expert scoring and offer an alternative unsupervised learningapproach based on explainable clustering. These results demonstrate theefficacy of our modified SarcGraph in extracting biologically meaningfulfeatures, enabling a deeper understanding of hiPSC-CM structural integrity. Bymaking our code and tools open-source, we aim to empower the broader cardiacresearch community and foster further development of computational tools forcardiac tissue analysis.</description>
      <author>example@mail.com (Saeed Mohammadzadeh, Emma Lejeune)</author>
      <guid isPermaLink="false">2501.18714v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Structural Embedding Projection for Contextual Large Language Model Inference</title>
      <link>http://arxiv.org/abs/2501.18826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;结构化嵌入转换提供了一种增强语言模型推理效率和一致性的有前途的方法。&lt;h4&gt;背景&lt;/h4&gt;传统的语言模型在处理复杂的语义关系时可能不够高效且一致性不足。&lt;h4&gt;目的&lt;/h4&gt;通过引入结构嵌入投影（SEP）机制，改进词表示并集成层级和关系依赖性以提高语义准确性。&lt;h4&gt;方法&lt;/h4&gt;数学公式化SEP使嵌入空间能够捕捉结构化的上下文关系，并在不显著增加计算开销的情况下提高了语义保真度。&lt;h4&gt;实验结果&lt;/h4&gt;一系列语言数据集上的实验证明了SEP减少了困惑度并增强了上下文一致性，从而改善了语言模型的输出质量。&lt;h4&gt;效率评估&lt;/h4&gt;计算机效率评估表明不同数据集上存在差异，这说明结构化嵌入集成引入了基于数据集依赖性的推断速度和表示丰富性之间的权衡。&lt;h4&gt;生成响应分析&lt;/h4&gt;对生成响应进行定性分析发现SEP增强了叙述的一致性和主题一致性，进而提高了多句子文本生成的流畅度。&lt;h4&gt;优化挑战&lt;/h4&gt;为确保稳定的训练动态，嵌入层需要精确的优化以应对结构化转换引入的变化。这些调整影响了推理延迟和内存消耗。&lt;h4&gt;词汇使用影响&lt;/h4&gt;对词汇多样性的影响表明嵌入修改会影响模型使用的词库选择，反映了生成令牌时更加上下文感知的选择。&lt;h4&gt;总结&lt;/h4&gt;SEP通过改进语言模型中的语义表示和上下文一致性来提高性能，但需要在效率提升和额外处理需求之间找到平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Structured embedding transformations offer a promising approach for enhancingthe efficiency and coherence of language model inference. The introduction ofStructural Embedding Projection (SEP) provides a mechanism for refining tokenrepresentations through projection matrices that integrate hierarchical andrelational dependencies. The mathematical formulation of SEP enables embeddingspaces to capture structured contextual relationships, thereby improvingsemantic fidelity without significantly increasing computational overhead.Experimental evaluations conducted on a range of linguistic datasets revealedthat SEP contributed to reductions in perplexity and enhanced contextualcoherence, demonstrating its potential to refine language model outputs.Computational efficiency assessments highlighted variations across differentdatasets, suggesting that the integration of structured embeddings introduceddataset-dependent trade-offs between inference speed and representationalrichness. The qualitative analysis of generated responses indicated that SEPenhanced narrative consistency and topic alignment, leading to improved fluencyin multi-sentence text generation. The modifications to embedding layersrequired precise optimization to ensure stable training dynamics, as theintroduction of structured transformations altered the traditionalrepresentation-learning process. The architectural adjustments necessary forSEP implementation influenced inference latency and memory consumption,requiring a balance between efficiency gains and additional processing demands.The impact of SEP on lexical diversity suggested that embedding modificationsinfluenced the model's vocabulary usage, reflecting a more context-awareselection of generated tokens.</description>
      <author>example@mail.com (Vincent Enoasmo, Cedric Featherstonehaugh, Xavier Konstantinopoulos, Zacharias Huntington)</author>
      <guid isPermaLink="false">2501.18826v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>XRF V2: A Dataset for Action Summarization with Wi-Fi Signals, and IMUs in Phones, Watches, Earbuds, and Glasses</title>
      <link>http://arxiv.org/abs/2501.19034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 11 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文介绍了一种新的数据集XRF V2，用于室内日常活动的时间动作定位(TAL)和动作概要生成。&lt;h4&gt;背景信息&lt;/h4&gt;人体行为识别(HAR)在健康监测、智能家居自动化和人机交互等领域中扮演着重要角色。尽管HAR已得到广泛研究，但连续动作的识别与概括仍然是一项新兴任务。&lt;h4&gt;目的声明&lt;/h4&gt;目的是通过引入XRF V2数据集以及提出一种新型神经网络XRFMamba来解决TAL和动作概要生成的问题。&lt;h4&gt;方法描述&lt;/h4&gt;提出了一个结合Wi-Fi信号、IMU传感器（智能手机、智能手表、耳机、智能眼镜）及同步视频记录的多模态数据集成，设计了适合室内日常活动的XRF V2数据集。此外，还引入了一种新型神经网络模型XRFMamba。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的XRFMamba模型能够出色地捕捉未裁剪的感觉序列中的长期依赖关系，并且优于当前的最佳方法如ActionFormer和WiFiTAD。&lt;h4&gt;结论陈述&lt;/h4&gt;XRF V2数据集被视为推动人体动作定位、行为预测、姿态估计、多模态基础模型预训练、合成数据生成等研究领域发展的宝贵资源。&lt;h4&gt;翻译&lt;/h4&gt;Human Action Recognition (HAR)在健康监测、智能家居自动化和人机交互等领域中发挥着关键作用。虽然HAR已经得到了广泛的探讨，但动作概要化——即识别并概述连续的动作——仍是新兴的任务之一。本文介绍了专为室内日常活动的时间动作定位(TAL)以及动作概要生成而设计的新数据集XRF V2。该数据集整合了来自Wi-Fi信号、IMU传感器（包括智能手机、智能手表、耳机和智能眼镜）及同步视频记录的多模态数据，提供了16名志愿者在三种不同环境下的多样化的室内活动集合。为解决TAL及动作概要生成问题，我们提出了XRFMamba神经网络模型，它擅长捕捉未裁剪的感觉序列中的长期依赖性，并超越了最先进的方法如ActionFormer和WiFiTAD。我们将XRF V2视为进一步推进人体行为定位、行为预测、姿态估计、多模态基础模型预训练、合成数据生成等领域研究的宝贵资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/aiotgroup/xrfv2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Action Recognition (HAR) plays a crucial role in applications such ashealth monitoring, smart home automation, and human-computer interaction. WhileHAR has been extensively studied, action summarization, which involvesidentifying and summarizing continuous actions, remains an emerging task. Thispaper introduces the novel XRF V2 dataset, designed for indoor daily activityTemporal Action Localization (TAL) and action summarization. XRF V2 integratesmultimodal data from Wi-Fi signals, IMU sensors (smartphones, smartwatches,headphones, and smart glasses), and synchronized video recordings, offering adiverse collection of indoor activities from 16 volunteers across threedistinct environments. To tackle TAL and action summarization, we propose theXRFMamba neural network, which excels at capturing long-term dependencies inuntrimmed sensory sequences and outperforms state-of-the-art methods, such asActionFormer and WiFiTAD. We envision XRF V2 as a valuable resource foradvancing research in human action localization, action forecasting, poseestimation, multimodal foundation models pre-training, synthetic datageneration, and more.</description>
      <author>example@mail.com (Bo Lan, Pei Li, Jiaxi Yin, Yunpeng Song, Ge Wang, Han Ding, Jinsong Han, Fei Wang)</author>
      <guid isPermaLink="false">2501.19034v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Job Allocation using Reinforcement Learning with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2501.19063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了利用强化学习（RL）和图神经网络（GNNs）解决复杂调度问题中作业分配的方法。&lt;h4&gt;背景&lt;/h4&gt;在实际应用中的复杂调度问题，高效的作业分配面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;通过结合RL和GNNs提出一种新的方法来解决Job Allocation Problem (JAP)，即最大化地将任务分派到可用资源上同时满足各种限制条件。&lt;h4&gt;方法&lt;/h4&gt;利用图结构化数据的优势并通过与环境的交互式学习，使策略能够自适应调整；使用RL消除了人工标注的需求，这在监督学习方法中是一个主要瓶颈。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的方法无论是在合成还是真实世界的数据上都展示了有效性和泛化性，并且超出了基线算法的表现，证明了其优化复杂调度问题作业分配的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究为解决复杂的作业分配问题提供了一种新的视角和方法，通过结合RL和GNNs能够有效地提高资源利用率并减少人工干预的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient job allocation in complex scheduling problems poses significantchallenges in real-world applications. In this report, we propose a novelapproach that leverages the power of Reinforcement Learning (RL) and GraphNeural Networks (GNNs) to tackle the Job Allocation Problem (JAP). The JAPinvolves allocating a maximum set of jobs to available resources whileconsidering several constraints. Our approach enables learning of adaptivepolicies through trial-and-error interactions with the environment whileexploiting the graph-structured data of the problem. By leveraging RL, weeliminate the need for manual annotation, a major bottleneck in supervisedlearning approaches. Experimental evaluations on synthetic and real-world datademonstrate the effectiveness and generalizability of our proposed approach,outperforming baseline algorithms and showcasing its potential for optimizingjob allocation in complex scheduling problems.</description>
      <author>example@mail.com (Lars C. P. M. Quaedvlieg)</author>
      <guid isPermaLink="false">2501.19063v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>BCAT: A Block Causal Transformer for PDE Foundation Models for Fluid Dynamics</title>
      <link>http://arxiv.org/abs/2501.18972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了一种名为BCAT的PDE基础模型，用于二维流体动力学问题解的自回归预测。&lt;h4&gt;背景&lt;/h4&gt;当前在图像生成方法中常用子帧或基于像素的输入来做出预测，而这些方法对于捕捉非线性时空动态和物理现象的空间依赖关系效果有限。&lt;h4&gt;目的&lt;/h4&gt;通过使用块因果Transformer架构，BCAT模型旨在更有效地捕获流体动力学问题中的空间依赖关系。&lt;h4&gt;方法&lt;/h4&gt;采用了块因果变换器架构来建模下一帧预测，并利用之前的帧作为上下文先验。该框架在多个流体动力学数据集上进行训练，包括不可压缩和可压缩的Navier-Stokes方程以及浅水波方程。&lt;h4&gt;主要发现&lt;/h4&gt;消融研究显示，在下一帧预测方面，BCAT模型相较于基于下一个令牌的方法提升了2.9倍的准确性。此外，BCAT在6个不同的下游预测任务上进行了性能评估，并通过8K轨迹进行鲁棒性测试。&lt;h4&gt;结论&lt;/h4&gt;BCAT在标准基准上的相对误差为1.92%，优于之前的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了BCAT，这是一个PDE基础模型，用于二维流体动力学问题解的自回归预测。该方法使用块因果Transformer架构来建模下一帧预测，并利用之前的帧作为上下文先验，而不是仅仅依赖于图像生成中常用的子帧或像素输入。这种块因果框架更有效地捕捉了非线性时空动态和物理现象的空间相关性。在消融研究中，下一帧预测比下一个令牌预测提高了2.9倍的准确性。BCAT是在广泛的流体动力学数据集上训练的，包括不可压缩和可压缩Navier-Stokes方程以及浅水波方程，涉及各种几何形状和参数范围。该模型针对六个不同的下游预测任务进行了性能评估，并通过大约8K条轨迹测试了其对多种流体动力学模拟的鲁棒性。BCAT在所有评价任务中的平均相对误差为1.92%，优于以前的方法标准基准测试。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce BCAT, a PDE foundation model designed for autoregressiveprediction of solutions to two dimensional fluid dynamics problems. Ourapproach uses a block causal transformer architecture to model next framepredictions, leveraging previous frames as contextual priors rather thanrelying solely on sub-frames or pixel-based inputs commonly used in imagegeneration methods. This block causal framework more effectively captures thespatial dependencies inherent in nonlinear spatiotemporal dynamics and physicalphenomena. In an ablation study, next frame prediction demonstrated a 2.9xaccuracy improvement over next token prediction. BCAT is trained on a diverserange of fluid dynamics datasets, including incompressible and compressibleNavier-Stokes equations across various geometries and parameter regimes, aswell as the shallow-water equations. The model's performance was evaluated on 6distinct downstream prediction tasks and tested on about 8K trajectories tomeasure robustness on a variety of fluid dynamics simulations. BCAT achieved anaverage relative error of 1.92% across all evaluation tasks, outperformingprior approaches on standard benchmarks.</description>
      <author>example@mail.com (Yuxuan Liu, Jingmin Sun, Hayden Schaeffer)</author>
      <guid isPermaLink="false">2501.18972v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data Boostrapping</title>
      <link>http://arxiv.org/abs/2501.18962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了现代基础模型在迭代训练过程中，生成数据和再训练预算分配策略对最终性能的影响。&lt;h4&gt;背景&lt;/h4&gt;现代大型模型通常采用迭代“引导”过程，在后训练阶段生成合成数据、外部验证器过滤低质量样本，并使用高质量子集进行进一步微调。多轮迭代后，模型性能提升。&lt;h4&gt;目的&lt;/h4&gt;开发理论框架分析预算分配策略如何最大化最终性能。&lt;h4&gt;方法&lt;/h4&gt;研究了恒定政策和增长政策（特别是指数增长政策）的收敛性及优势；实验验证图像去噪和数学推理任务中不同增长策略的表现。&lt;h4&gt;主要发现&lt;/h4&gt;恒定政策难以实现高概率收敛，而增长政策表现出显著理论优势。在实际应用中，指数增长政策通常比多项式增长政策更稳定，优于常数预算分配政策。&lt;h4&gt;结论&lt;/h4&gt;对于现代基础模型的训练，建议采用逐渐增加（特别是以指数形式）的生成数据和再训练预算策略来优化最终性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经用中文总结并整理为了JSON格式&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern foundation models often undergo iterative ``bootstrapping'' in theirpost-training phase: a model generates synthetic data, an external verifierfilters out low-quality samples, and the high-quality subset is used forfurther fine-tuning. Over multiple iterations, the model's performanceimproves--raising a crucial question: how should the total budget on generationand training be allocated across iterations to maximize final performance? Inthis work, we develop a theoretical framework to analyze budget allocationstrategies. Specifically, we show that constant policies fail to converge withhigh probability, while increasing policies--particularly exponential growthpolicies--exhibit significant theoretical advantages. Experiments on imagedenoising with diffusion probabilistic models and math reasoning with largelanguage models show that both exponential and polynomial growth policiesconsistently outperform constant policies, with exponential policies oftenproviding more stable performance.</description>
      <author>example@mail.com (Pu Yang, Yunzhen Feng, Ziyuan Chen, Yuhang Wu, Zhuoyuan Li)</author>
      <guid isPermaLink="false">2501.18962v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Project-and-Fuse: Improving RGB-D Semantic Segmentation via Graph Convolution Networks</title>
      <link>http://arxiv.org/abs/2501.18851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的RGB-D语义分割方法，通过延迟融合和利用图神经网络（GNNs）来改善特征对齐问题并减少不规则补丁。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数RGB-D语义分割方法集中在复杂的跨模态和跨尺度融合模块上，这可能导致特征融合过程中的偏差，并产生不符合直觉的分割结果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的延迟融合方式以及使用图神经网络来改进现有方法存在的问题，并在深度地图处理中引入法线图编码以提高效率。&lt;h4&gt;方法&lt;/h4&gt;[{'1) 延迟融合': '将两种模态的特征进行延迟融合，通过纹理特征先验指导几何特征注入'}, {'2) 使用GNNs': '使用图神经网络(GNNs)来缓解不规则补丁的出现，通过推断块之间的关系来进行优化'}, {'3D 特征提取阶段': '将深度图编码为法线图以利用传统CNNs的优势'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'Biased-Assignment问题': '采用Kullback-Leibler Loss确保不丢失重要像素特征，防止关键信息的遗漏'}, {'Ambiguous-Locality问题': '在欧几里得空间和语义空间中连接相近区域，并赋予更大的边缘权重以考虑位置信息'}]&lt;h4&gt;结论&lt;/h4&gt;实验结果表明所提出的方法可以显著提升RGB-D语义分割任务的表现。&lt;h4&gt;翻译&lt;/h4&gt;大多数现有的RGB-D语义分割方法集中在特征级别的融合上，包括复杂的跨模态和跨尺度的融合模块。然而，这些方法可能会导致特征融合过程中的对齐问题，并在分割结果中出现不合直觉的块。受流行的像素-节点-像素流水线启发，我们提出：1) 将两种模态的特征以延迟融合的方式进行合并，在此过程中由纹理特征先验引导几何特征注入；2) 使用图神经网络（GNNs）来缓解不规则块的出现，并通过推断块之间的关系来进行优化。在3D特征提取阶段，我们提出传统的CNN们对于深度图不够高效。所以我们将深度图编码为法线图，在此之后CNN可以轻松提取物体表面倾向。在投影矩阵生成阶段，我们在原始流水线上发现了Biased-Assignment和Ambiguous-Locality的问题。因此，1) 我们采用Kullback-Leibler Loss来确保不会丢失重要的像素特征，这可以被视为硬像素挖掘过程；2）将欧几里得空间以及语义空间中相近的区域用更大的边缘权重连接起来，以便考虑位置信息。在NYU-DepthV2和SUN RGB-D两个公开数据集上的广泛实验表明我们的方法可以显著提升RGB-D语义分割任务的表现。&lt;h4&gt;关键字&lt;/h4&gt;['RGB-D', '延迟融合', '图神经网络（GNNs）', '法线图编码']&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing RGB-D semantic segmentation methods focus on the feature levelfusion, including complex cross-modality and cross-scale fusion modules.However, these methods may cause misalignment problem in the feature fusionprocess and counter-intuitive patches in the segmentation results. Inspired bythe popular pixel-node-pixel pipeline, we propose to 1) fuse features from twomodalities in a late fusion style, during which the geometric feature injectionis guided by texture feature prior; 2) employ Graph Neural Networks (GNNs) onthe fused feature to alleviate the emergence of irregular patches by inferringpatch relationship. At the 3D feature extraction stage, we argue thattraditional CNNs are not efficient enough for depth maps. So, we encode depthmap into normal map, after which CNNs can easily extract object surfacetendencies.At projection matrix generation stage, we find the existence ofBiased-Assignment and Ambiguous-Locality issues in the original pipeline.Therefore, we propose to 1) adopt the Kullback-Leibler Loss to ensure nomissing important pixel features, which can be viewed as hard pixel miningprocess; 2) connect regions that are close to each other in the Euclidean spaceas well as in the semantic space with larger edge weights so that locationinformations can been considered. Extensive experiments on two public datasets,NYU-DepthV2 and SUN RGB-D, have shown that our approach can consistently boostthe performance of RGB-D semantic segmentation task.</description>
      <author>example@mail.com (Xiaoyan Jiang, Bohan Wang, Xinlong Wan, Zhi Zhou, Hamido Fujita)</author>
      <guid isPermaLink="false">2501.18851v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Neural Graph Pattern Machine</title>
      <link>http://arxiv.org/abs/2501.18739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;论文提出了一种新的框架Neural Graph Pattern Machine (GPM)，该框架旨在直接从图模式中学习，以克服现有图神经网络（GNN）在识别基本子结构方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;图学习任务需要模型理解与下游任务相关的本质子结构模式。然而，现有的图神经网络依赖于消息传递机制来聚合局部邻居信息，这种机制难以有效识别如三角形这样的基础子结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架GPM，旨在通过直接从图的模式中学习，克服现有方法在表达能力和长距离信息建模方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种称为Neural Graph Pattern Machine (GPM)的新框架，该框架能够高效地提取和编码子结构，并识别对下游任务最有用的部分。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与最先进的基线相比，GPM在节点分类、链接预测、图分类和回归等任务上表现出优越性。进一步分析显示它具有出色的出界分布稳健性、可扩展性和解释性。&lt;h4&gt;结论&lt;/h4&gt;论文认为GPM代表了超越消息传递机制的一种途径，展示了其在多个领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;图形学习任务要求模型理解与下游任务相关的本质子结构模式，如社交网络中的三元闭包和分子图中的苯环。由于图的非欧几里得性质，现有的图神经网络依赖于消息传递来迭代地从局部邻域聚合信息。尽管在经验上取得了成功，但消息传递难以识别基础子结构（例如三角形），限制了其表达能力。为了克服这一局限性，我们提出了Neural Graph Pattern Machine (GPM)框架，该框架旨在直接从图模式中学习。GPM能够高效地提取和编码子结构，并且可以确定对下游任务最有用的部分。我们还展示了与消息传递相比，GPM在表达性和长距离信息建模方面具有优越性。在节点分类、链接预测、图形分类和回归的实验评估显示了相对于最先进的基线模型的优势。进一步分析揭示了其出色的出界分布稳健性、可扩展性和解释性。我们认为GPM是超越消息传递的一种途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph learning tasks require models to comprehend essential substructurepatterns relevant to downstream tasks, such as triadic closures in socialnetworks and benzene rings in molecular graphs. Due to the non-Euclidean natureof graphs, existing graph neural networks (GNNs) rely on message passing toiteratively aggregate information from local neighborhoods. Despite theirempirical success, message passing struggles to identify fundamentalsubstructures, such as triangles, limiting its expressiveness. To overcome thislimitation, we propose the Neural Graph Pattern Machine (GPM), a frameworkdesigned to learn directly from graph patterns. GPM efficiently extracts andencodes substructures while identifying the most relevant ones for downstreamtasks. We also demonstrate that GPM offers superior expressivity and improvedlong-range information modeling compared to message passing. Empiricalevaluations on node classification, link prediction, graph classification, andregression show the superiority of GPM over state-of-the-art baselines. Furtheranalysis reveals its desirable out-of-distribution robustness, scalability, andinterpretability. We consider GPM to be a step toward going beyond messagepassing.</description>
      <author>example@mail.com (Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye)</author>
      <guid isPermaLink="false">2501.18739v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Node Classification and Search on the Rubik's Cube Graph with GNNs</title>
      <link>http://arxiv.org/abs/2501.18580v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过深度几何模型解决3x3x3魔方问题，使用图神经网络（GNN）将距离近似任务重新表述为节点分类问题，并利用A*搜索算法进行验证。&lt;h4&gt;背景&lt;/h4&gt;该论文关注于运用深度学习技术解决经典难题——3x3x3魔方的复原问题。&lt;h4&gt;目的&lt;/h4&gt;通过构建深度几何模型来优化魔方解法的过程，特别是探索图表示和距离定义在其中的作用。&lt;h4&gt;方法&lt;/h4&gt;首先讨论了魔方的图结构及定义了其上的距离作为目标函数；然后将距离近似任务转化为节点分类问题，并采用图神经网络（GNN）进行学习。模型训练完成后，利用预测结果构建启发式算法用于A*搜索。&lt;h4&gt;主要发现&lt;/h4&gt;提出的深度几何模型方法在解决魔方复原任务上展现出良好的性能和效率。&lt;h4&gt;结论&lt;/h4&gt;通过实验将所提出的方法与DeepCubeA模型进行了对比，验证了其有效性和创新性。&lt;h4&gt;翻译&lt;/h4&gt;这项研究关注于利用深度几何模型来解决3x3x3魔方的问题。文章首先讨论了魔方的图表示，并定义了解决问题所需的距离作为优化目标。接着将距离逼近任务重新表述为节点分类问题，可以有效地用图神经网络（GNN）进行解决。在对随机子图训练完模型后，利用预测结果构建启发式算法用于A*搜索方法中。最后通过实验比较了与DeepCubeA模型的启发式的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study focuses on the application of deep geometric models to solve the3x3x3 Rubik's Cube. We begin by discussing the cube's graph representation anddefining distance as the model's optimization objective. The distanceapproximation task is reformulated as a node classification problem,effectively addressed using Graph Neural Networks (GNNs). After training themodel on a random subgraph, the predicted classes are used to construct aheuristic for $A^*$ search. We conclude with experiments comparing ourheuristic to that of the DeepCubeA model.</description>
      <author>example@mail.com (Alessandro Barro)</author>
      <guid isPermaLink="false">2501.18580v2</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait</title>
      <link>http://arxiv.org/abs/2501.17159v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;现有的扩散模型在保持身份一致性生成方面表现出巨大的潜力，但在个性化肖像生成上仍面临挑战。这些挑战源于用户资料的多样性，包括外观和光照条件的变化。&lt;h4&gt;背景&lt;/h4&gt;尽管现有扩散模型展示了其潜在的应用于个性化肖像生成的能力，但个性化肖像生成仍然具有挑战性，主要问题在于用户资料的高度多样化，包括面部特征差异及不同的照明条件。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，我们提出了IC-Portrait这一创新框架，旨在精确编码个体身份以实现个性化的肖像生成。&lt;h4&gt;方法&lt;/h4&gt;我们的关键见解是预训练的扩散模型在上下文密集对应匹配方面学习速度快（例如100~200步），由此设计了IC-Portrait框架。具体来说，我们将肖像生成重构为两个子任务：光照感知拼接和视角一致性调整。&lt;h4&gt;主要发现&lt;/h4&gt;通过将参考图像中高比例的部分（如80%）进行遮挡，可以获得非常有效的自我监督表示学习来识别参考图的照明条件。并且通过合成的视图一致性的资料集可以更好地学习上下文对应关系，从而增强肖像生成的身份保持能力。&lt;h4&gt;结论&lt;/h4&gt;IC-Portrait框架在定量和定性上均优于现有的最先进方法，并且展示了3D光照感知的能力。&lt;h4&gt;翻译&lt;/h4&gt;现有扩散模型在身份一致性生成方面展现出巨大潜力。然而，由于用户资料的多样性（包括外观变化及照明条件的不同），个性化肖像生成依然存在挑战。为此，我们提出了IC-Portrait框架，旨在精确编码个人身份以实现个性化的肖像生成。该框架通过快速学习预训练模型的密集上下文匹配特性设计，并将问题分为两个子任务：光照感知拼接和视角一致性调整。实验表明，此方法在质量和视觉效果方面均优于现有的最佳方法，并且具备3D感知重新照明的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing diffusion models show great potential for identity-preservinggeneration. However, personalized portrait generation remains challenging dueto the diversity in user profiles, including variations in appearance andlighting conditions. To address these challenges, we propose IC-Portrait, anovel framework designed to accurately encode individual identities forpersonalized portrait generation. Our key insight is that pre-trained diffusionmodels are fast learners (e.g.,100 ~ 200 steps) for in-context densecorrespondence matching, which motivates the two major designs of ourIC-Portrait framework. Specifically, we reformulate portrait generation intotwo sub-tasks: 1) Lighting-Aware Stitching: we find that masking a highproportion of the input image, e.g., 80%, yields a highly effectiveself-supervisory representation learning of reference image lighting. 2)View-Consistent Adaptation: we leverage a synthetic view-consistent profiledataset to learn the in-context correspondence. The reference profile can thenbe warped into arbitrary poses for strong spatial-aligned view conditioning.Coupling these two designs by simply concatenating latents to formControlNet-like supervision and modeling, enables us to significantly enhancethe identity preservation fidelity and stability. Extensive evaluationsdemonstrate that IC-Portrait consistently outperforms existing state-of-the-artmethods both quantitatively and qualitatively, with particularly notableimprovements in visual qualities. Furthermore, IC-Portrait even demonstrates3D-aware relighting capabilities.</description>
      <author>example@mail.com (Han Yang, Enis Simsar, Sotiris Anagnostidis, Yanlong Zang, Thomas Hofmann, Ziwei Liu)</author>
      <guid isPermaLink="false">2501.17159v2</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Consistency Diffusion Models for Single-Image 3D Reconstruction with Priors</title>
      <link>http://arxiv.org/abs/2501.16737v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从单张图像重建3D点云的问题，提出了一种基于贝叶斯框架的Consistency Diffusion Model，通过结合2D和3D先验知识来提高重建的一致性。&lt;h4&gt;背景&lt;/h4&gt;现有的重建方法在确保一致性和利用先验信息方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的扩散模型训练框架，引入两种创新技术以解决现有方法的不足。&lt;h4&gt;方法&lt;/h4&gt;{'第一点': '将初始3D点云中的结构先验作为约束项，在变分贝叶斯框架中增强证据，控制扩散训练过程并提高一致性。', '第二点': '从输入单张图像中提取2D先验信息，并将其投影到3D点云上以丰富指导作用'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示该方法在合成和真实数据集上的性能优于现有方法，确立了新的基准。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架不仅提高了重建一致性，还避免了模型训练过程中可能出现的学习偏移问题，并成功地将2D先验转换到3D领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper delves into the study of 3D point cloud reconstruction from asingle image. Our objective is to develop the Consistency Diffusion Model,exploring synergistic 2D and 3D priors in the Bayesian framework to ensuresuperior consistency in the reconstruction process, a challenging yet criticalrequirement in this field. Specifically, we introduce a pioneering trainingframework under diffusion models that brings two key innovations. First, weconvert 3D structural priors derived from the initial 3D point cloud as a boundterm to increase evidence in the variational Bayesian framework, leveragingthese robust intrinsic priors to tightly govern the diffusion training processand bolster consistency in reconstruction. Second, we extract and incorporate2D priors from the single input image, projecting them onto the 3D point cloudto enrich the guidance for diffusion training. Our framework not only sidestepspotential model learning shifts that may arise from directly imposingadditional constraints during training but also precisely transposes the 2Dpriors into the 3D domain. Extensive experimental evaluations reveal that ourapproach sets new benchmarks in both synthetic and real-world datasets. Thecode is included with the submission.</description>
      <author>example@mail.com (Chenru Jiang, Chengrui Zhang, Xi Yang, Jie Sun, Yifei Zhang, Bin Dong, Kaizhu Huang)</author>
      <guid isPermaLink="false">2501.16737v2</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Vintix: Action Model via In-Context Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2501.19400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. In review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种通过上下文强化学习来开发通用代理的方法，这些代理在推理时通过试错互动进行学习，并且专注于奖励最大化。&lt;h4&gt;背景&lt;/h4&gt;ICRL（上下文强化学习）是一种有前途的范式，旨在通过试错交互来进行泛化代理的学习。尽管类大型语言模型可以通过上下文适应性来模拟这种行为，但将其扩展到玩具任务和单一领域设置之外仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;该工作的目的是探讨如何将ICRL扩展至更广泛的跨域应用中，并引入了一种固定、跨领域的模型以实现这一目标。&lt;h4&gt;方法&lt;/h4&gt;论文介绍了Algorithm Distillation框架的设计，旨在促进上下文强化学习的发展。该框架提供了一个替代专家蒸馏的选项来构建适应性强的动作模型。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果表明，算法蒸馏提供的是一种有竞争力且富有潜力的方法，可以作为一种可扩展的通用决策制定系统的构建方式。&lt;h4&gt;结论&lt;/h4&gt;论文通过代码（在https://github.com/dunnolab/vintix发布）展示了ICRL作为泛化决策系统中一种可扩展方法的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dunnolab/vintix&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-Context Reinforcement Learning (ICRL) represents a promising paradigm fordeveloping generalist agents that learn at inference time throughtrial-and-error interactions, analogous to how large language models adaptcontextually, but with a focus on reward maximization. However, the scalabilityof ICRL beyond toy tasks and single-domain settings remains an open challenge.In this work, we present the first steps toward scaling ICRL by introducing afixed, cross-domain model capable of learning behaviors through in-contextreinforcement learning. Our results demonstrate that Algorithm Distillation, aframework designed to facilitate ICRL, offers a compelling and competitivealternative to expert distillation to construct versatile action models. Thesefindings highlight the potential of ICRL as a scalable approach for generalistdecision-making systems. Code to be released athttps://github.com/dunnolab/vintix</description>
      <author>example@mail.com (Andrey Polubarov, Nikita Lyubaykin, Alexander Derevyagin, Ilya Zisman, Denis Tarasov, Alexander Nikulin, Vladislav Kurenkov)</author>
      <guid isPermaLink="false">2501.19400v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Precision Harvesting in Cluttered Environments: Integrating End Effector Design with Dual Camera Perception</title>
      <link>http://arxiv.org/abs/2501.19395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种新颖的框架，用于解决在高隧道环境下的水果采摘问题，尤其是在劳动力短缺的情况下。&lt;h4&gt;背景&lt;/h4&gt;由于特殊作物行业中的劳动力短缺，对机器人自动化的需求增加以提高农业效率和生产力。现有的操纵系统在未拥挤且结构化的环境中表现良好，但在更紧凑、杂乱的高隧道环境中效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的协同设计框架，该框架结合了全局检测相机和局部眼手协调相机，旨在实现小水果的精确定位并通过闭环视觉反馈可靠地处理误差。&lt;h4&gt;方法&lt;/h4&gt;提出的系统利用一个全局检测相机进行粗略定位，并通过一个本地的眼手协调相机提供精确的抓取位置。实验在高隧道中进行了验证。&lt;h4&gt;主要发现&lt;/h4&gt;该系统的现场试验表明，平均可以在10.98秒内捕获到樱桃番茄果实的85%以上。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统能够在复杂的高隧道环境中有效地定位和采摘水果，证明了其在农业机器人自动化领域的潜力。&lt;h4&gt;翻译&lt;/h4&gt;由于特殊作物行业劳动力短缺的问题，对机器人自动化的需求日益增长，以提高农业效率和生产力。现有的操纵系统虽然在未拥挤且结构化的环境中表现出色，但在更紧凑、杂乱的高隧道环境中的应用存在挑战。为此，研究团队设计了一种新的框架，该框架结合了全局检测相机与本地眼手协调相机，以便通过闭环视觉反馈实现小水果的精确定位，并能够可靠地处理误差。实验表明，在高隧道环境中平均可以在10.98秒内捕获到樱桃番茄果实的85%以上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to labor shortages in specialty crop industries, a need for roboticautomation to increase agricultural efficiency and productivity has arisen.Previous manipulation systems perform well in harvesting in uncluttered andstructured environments. High tunnel environments are more compact andcluttered in nature, requiring a rethinking of the large form factor systemsand grippers. We propose a novel codesigned framework incorporating a globaldetection camera and a local eye-in-hand camera that demonstrates preciselocalization of small fruits via closed-loop visual feedback and reliable errorhandling. Field experiments in high tunnels show our system can reach anaverage of 85.0\% of cherry tomato fruit in 10.98s on average.</description>
      <author>example@mail.com (Kendall Koe, Poojan Kalpeshbhai Shah, Benjamin Walt, Jordan Westphal, Samhita Marri, Shivani Kamtikar, James Seungbum Nam, Naveen Kumar Uppalapati, Girish Krishnan, Girish Chowdhary)</author>
      <guid isPermaLink="false">2501.19395v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Perceptive Mixed-Integer Footstep Control for Underactuated Bipedal Walking on Rough Terrain</title>
      <link>http://arxiv.org/abs/2501.19391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种全栈感知和控制系统，用于在不连续地形上实现欠驱动步行。该系统包括模型预测足部控制（MPFC）算法和实时的地面分割技术。&lt;h4&gt;背景&lt;/h4&gt;穿越崎岖地带对动态双足机器人来说是一个挑战，需要稳定地通过脚步放置避免进入危险区域。由于安全地形的非凸性和不完美的感知及状态估计，在线规划脚步非常困难。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决这些在线足迹规划中的挑战，提供一种全栈感知和控制系统来实现欠驱动行走。&lt;h4&gt;方法&lt;/h4&gt;开发了一种模型预测足部控制（MPFC）算法，这是一种单个混合整数二次程序，假设地形是凸多边形分解的，可以优化离散踏步选择、脚步位置、踝关节扭矩、模板动力学以及脚步时间间隔超过100Hz。此外还提出一种在线生成凸多边形地形的方法。&lt;h4&gt;主要发现&lt;/h4&gt;感知栈解耦了安全地面分类和平面多边形拟合的过程，使用单个CPU线程实时生成一致性良好的地面分割。&lt;h4&gt;结论&lt;/h4&gt;通过户外实验验证了该系统的性能，在不连续地形上实现了欠驱动步行的最新感知双足行走水平。&lt;h4&gt;翻译&lt;/h4&gt;穿越崎岖地带需要动态双足机器人通过脚步放置来稳定自身，并避免进入危险区域。考虑到非凸安全地形、不完美的感知和状态估计，规划这些脚步在线进行极具挑战性。本文提出了一种全栈感知和控制系统，用于在不连续地形上实现欠驱动步行。首先开发了模型预测足部控制（MPFC），这是一种混合整数二次程序，在假设地形为凸多边形分解的基础上优化离散踏步选择、脚步位置、踝关节扭矩、模板动力学以及脚步时间间隔超过100Hz。此外，本文还提出了一种在线生成凸多边形地形分割的新方法。感知栈解耦了安全地面分类和平面多边形拟合的过程，并使用单个CPU线程实时生成一致性良好的地面分割。通过户外实验验证了该系统的性能，在不连续地形上实现了欠驱动步行的最新感知双足行走水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traversing rough terrain requires dynamic bipeds to stabilize themselvesthrough foot placement without stepping in unsafe areas. Planning thesefootsteps online is challenging given non-convexity of the safe terrain, andimperfect perception and state estimation. This paper addresses thesechallenges with a full-stack perception and control system for achievingunderactuated walking on discontinuous terrain. First, we developmodel-predictive footstep control (MPFC), a single mixed-integer quadraticprogram which assumes a convex polygon terrain decomposition to optimize overdiscrete foothold choice, footstep position, ankle torque, template dynamics,and footstep timing at over 100 Hz. We then propose a novel approach forgenerating convex polygon terrain decompositions online. Our perception stackdecouples safe-terrain classification from fitting planar polygons, generatinga temporally consistent terrain segmentation in real time using a single CPUthread. We demonstrate the performance of our perception and control stackthrough outdoor experiments with the underactuated biped Cassie, achievingstate of the art perceptive bipedal walking on discontinuous terrain.Supplemental Video: https://youtu.be/eCOD1bMi638</description>
      <author>example@mail.com (Brian Acosta, Michael Posa)</author>
      <guid isPermaLink="false">2501.19391v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Trust and Trustworthiness from Human-Centered Perspective in HRI -- A Systematic Literature Review</title>
      <link>http://arxiv.org/abs/2501.19323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, Systematic Literature Review on Human-Robot Interaction&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章通过系统性文献回顾，探讨了信任和可信度在推动从工业4.0向5.0过渡中的关键作用，并强调了这些因素对于实现人机协作的安全性和可靠性的重要性。&lt;h4&gt;背景&lt;/h4&gt;欧盟正在努力设计能够与人类协同工作的智能设备，以增强人的能力。这种愿景旨在满足用户对安全性的需求，即在使用此类系统时能感到安心。这需要一种以人为本的研究视角和对技术进步的社会及教育观念进行转变。&lt;h4&gt;目的&lt;/h4&gt;为了更好地理解这一观点，作者进行了一项系统性文献回顾，着重于了解信任和可信度如何成为支持向工业5.0过渡的关键方面。&lt;h4&gt;方法&lt;/h4&gt;遵循《系统综述与元分析指南》进行了严格的质量评估，通过严格的研究标准筛选文章，并由至少两位评审者独立筛查后，最终确定了34篇文章作为研究对象。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，信任和安全性是促进人机协作安全性和可信性的基础元素。此外，近30%的修订后的论文未提供明确的信任定义，这种概念上的模糊性可能阻碍相关研究工作，并导致文献中对方法和工具的选择出现矛盾。&lt;h4&gt;结论&lt;/h4&gt;文章强调了在人机交互领域选择适当的方法和技术对于用户偏好及其对机器人能力的认知有着重大影响。同时，缺乏清晰的概念框架可能是建立人机信任的潜在障碍。&lt;h4&gt;翻译&lt;/h4&gt;工业5.0转型凸显了欧盟设计智能设备的努力，这些设备可以与人类协同工作以增强人的能力，并且这种愿景符合用户的偏好和需求，在使用此类系统时感到安全是首要考虑的问题。这需要一种以人为本的研究视角，要求我们在如何看待技术进步方面进行社会和教育转变。为了更好地理解这一观点，我们进行了关于信任和可信度在支持向工业5.0过渡中的关键作用的系统性文献回顾。该审查旨在概述最常见的方法论和测量手段，并收集有关促进人机交互（HRI）中可信赖性的障碍与推动因素的见解。经过严格的质量评估后，按照《系统综述和元分析指南》使用严格的研究标准筛选文章并由至少两位评审者独立筛查，最终确定了34篇文章作为研究对象。发现强调了信任和安全是促进人机合作的安全性和可信性基础的重要性。几乎30%的修订后的论文没有提供明确的信任定义，这可能是有问题的，因为这种概念上的模糊可能破坏从中心视角解决问题的研究工作。它还指出选择领域和应用范围应该影响促进HRI中信任的方法和技术的选择，这些选择可以显著地影响用户的偏好以及他们对机器人能力的认知与评估。此外，缺乏清晰的概念框架可能是建立HRI信任的潜在障碍，并解释了文献中的方法和工具的选择或有时矛盾的结果的原因。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Industry 5.0 transition highlights EU efforts to design intelligentdevices that can work alongside humans to enhance human capabilities, and suchvision aligns with user preferences and needs to feel safe while collaboratingwith such systems take priority. This demands a human-centric research visionand requires a societal and educational shift in how we perceive technologicaladvancements. To better understand this perspective, we conducted a systematicliterature review focusing on understanding how trust and trustworthiness canbe key aspects of supporting this move towards Industry 5.0. This review aimsto overview the most common methodologies and measurements and collect insightsabout barriers and facilitators for fostering trustworthy HRI. After a rigorousquality assessment following the Systematic Reviews and Meta-Analysesguidelines, using rigorous inclusion criteria and screening by at least tworeviewers, 34 articles were included in the review. The findings underscoresthe significance of trust and safety as foundational elements for promotingsecure and trustworthy human-machine cooperation. Confirm that almost 30% ofthe revised articles do not present a definition of trust, which can beproblematic as this lack of conceptual clarity can undermine research effortsin addressing this problem from a central perspective. It highlights that thechoice of domain and area of application should influence the choice of methodsand approaches to fostering trust in HRI, as those choices can significantlyaffect user preferences and their perceptions and assessment of robotcapabilities. Additionally, this lack of conceptual clarity can be a potentialbarrier to fostering trust in HRI and explains the sometimes contradictoryfindings or choice of methods and instruments used to investigate trust inrobots and other autonomous systems in the literature.</description>
      <author>example@mail.com (Debora Firmino de Souza, Sonia Sousa, Kadri Kristjuhan-Ling, Olga Dunajeva, Mare Roosileht, Avar Pentel, Mati Mõttus, Mustafa Can Özdemir, Žanna Gratšjova)</author>
      <guid isPermaLink="false">2501.19323v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the effectiveness of park-and-ride facilities on multimodal networks in smart cities</title>
      <link>http://arxiv.org/abs/2501.18999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种优化程序来选择停车场，并考虑了不同的标准：总旅行时间（包括换乘）、停车费以及在到达时没有可用停车位的风险因素。&lt;h4&gt;背景&lt;/h4&gt;研究针对塞维利亚的历史市中心，该地区限制私人车辆的交通并鼓励使用停车场。这种城市规划背景促进了对优化停车策略的需求。&lt;h4&gt;目的&lt;/h4&gt;目的是通过提出一个整数编程模型来确定最有效的停车策略，从而最小化成本，并考虑现有的信息、不同的场景以及每个用户的个人资料。&lt;h4&gt;方法&lt;/h4&gt;提出了一个整数规划公式以找到最优的低代价策略。此模型考虑了不同用户的行为模式和城市交通状况下可能发生的多种情况。&lt;h4&gt;主要发现&lt;/h4&gt;该研究通过在塞维利亚的城市环境中进行计算实验，评估并验证了所提出的方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;优化程序能够根据用户的个人资料、历史信息及各种场景下的成本因素为每个用户提供最佳的停车选择建议。这对于促进城市交通管理和减少私人车辆对市中心的影响具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文介绍了一种优化过程，用于根据不同标准（包括但不限于总旅行时间含换乘、停车费以及到达时停车场无空位的风险）来挑选最优的停车设施。通过提出整数规划模型，考虑了现有的信息和不同的场景，为每个用户提供了成本最低的选择策略。为了评估性能，在西班牙塞维利亚进行了计算实验，该城市中心的历史区域限制私人车辆通行，并鼓励使用公共停车位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1080/01605682.2020.1854628&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an optimization procedure to choose a parking facilityaccording to different criteria: total travel time including transfers, parkingfee and a factor depending on the risk of not having an available spot in theparking facility at the arrival time. An integer programming formulation isproposed to determine an optimal strategy of minimum cost considering theavailable information, different scenarios, and each user profile. To evaluatethe performance, a computational experience has been carried out on Seville(Spain), where a historical city center restricts the traffic of privatevehicles and encourages the use of parking facilities.</description>
      <author>example@mail.com (Juan A Mesa, Francisco A Ortega, Miguel A Pozo, Ramón Piedra-de-la-Cuadra)</author>
      <guid isPermaLink="false">2501.18999v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Dense Endoscopic Reconstruction with Gaussian Splatting-driven Surface Normal-aware Tracking and Mapping</title>
      <link>http://arxiv.org/abs/2501.19319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Endo-2DTAM是一种实时内窥镜SLAM系统，结合了二维高斯点阵（2DGS），以解决多视角不一致导致的深度和表面重建问题。&lt;h4&gt;背景&lt;/h4&gt;精确的手术干预和微创程序中的机器人任务需要Simultaneous Localization and Mapping (SLAM)技术。虽然3D Gaussian Splatting(3DGS)在高质量的新视图合成和快速渲染方面有了显著进步，但它们仍难以解决由于多视角不一致而导致的深度和表面重建问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合二维高斯点阵（2DGS）的实时内窥镜SLAM系统，以改进几何精确度，并且实现高效而几何连贯的关键帧采样策略。&lt;h4&gt;方法&lt;/h4&gt;Endo-2DTAM采用了面向表面法线的流水线技术，包括跟踪、映射和捆绑调整模块。跟踪模块结合了点到点和点到平面的距离测量指标；映射模块利用法线一致性和深度失真来增强表面重建的质量。此外，还引入了一种姿势一致策略以进行有效且几何连贯的关键帧采样。&lt;h4&gt;主要发现&lt;/h4&gt;在公共内窥镜数据集上的大量实验表明，Endo-2DTAM能够在保持计算效率的跟踪、高质量视觉表现和实时渲染的同时，实现1.87±0.63毫米的手术场景深度重建RMSE值。&lt;h4&gt;结论&lt;/h4&gt;提出的系统能够有效地解决现有SLAM系统中的多视角不一致问题，并且在多个内窥镜数据集上展示出了卓越的表现。Endo-2DTAM提供了一个高效的解决方案，能够在微创程序中实现准确的位置和地图构建。&lt;h4&gt;翻译&lt;/h4&gt;同步定位与建图（SLAM）对于精确的手术干预以及微创程序中的机器人任务至关重要。虽然最近关于3D高斯点阵（3DGS）的研究提高了使用高质量新视图合成和快速渲染进行SLAM的能力，但由于多视角不一致的问题，这些系统仍然难以准确地重建深度和表面。简单地将SLAM与3DGS结合会导致重构帧之间出现错配问题。在这项工作中，我们提出了Endo-2DTAM，这是一种利用二维高斯点阵（2DGS）来解决挑战的实时内窥镜SLAM系统。Endo-2DTAM包含一个面向表面法线的流水线技术，包括跟踪、映射和捆绑调整模块，用于几何精确度重构。我们的稳健跟踪模块结合了点到点和点到平面的距离测量指标，而映射模块利用法线一致性和深度失真来增强表面重建质量。我们还引入了一种姿势一致策略以进行有效且几何连贯的关键帧采样。在公共内窥镜数据集上的广泛实验表明，Endo-2DTAM实现了1.87±0.63毫米的手术场景深度重构RMSE值，同时保持了计算效率、高质量视觉表现和实时渲染。我们的代码将在github.com/lastbasket/Endo-2DTAM上公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lastbasket/endo-2dtam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous Localization and Mapping (SLAM) is essential for precisesurgical interventions and robotic tasks in minimally invasive procedures.While recent advancements in 3D Gaussian Splatting (3DGS) have improved SLAMwith high-quality novel view synthesis and fast rendering, these systemsstruggle with accurate depth and surface reconstruction due to multi-viewinconsistencies. Simply incorporating SLAM and 3DGS leads to mismatches betweenthe reconstructed frames. In this work, we present Endo-2DTAM, a real-timeendoscopic SLAM system with 2D Gaussian Splatting (2DGS) to address thesechallenges. Endo-2DTAM incorporates a surface normal-aware pipeline, whichconsists of tracking, mapping, and bundle adjustment modules for geometricallyaccurate reconstruction. Our robust tracking module combines point-to-point andpoint-to-plane distance metrics, while the mapping module utilizes normalconsistency and depth distortion to enhance surface reconstruction quality. Wealso introduce a pose-consistent strategy for efficient and geometricallycoherent keyframe sampling. Extensive experiments on public endoscopic datasetsdemonstrate that Endo-2DTAM achieves an RMSE of $1.87\pm 0.63$ mm for depthreconstruction of surgical scenes while maintaining computationally efficienttracking, high-quality visual appearance, and real-time rendering. Our codewill be released at github.com/lastbasket/Endo-2DTAM.</description>
      <author>example@mail.com (Yiming Huang, Beilei Cui, Long Bai, Zhen Chen, Jinlin Wu, Zhen Li, Hongbin Liu, Hongliang Ren)</author>
      <guid isPermaLink="false">2501.19319v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>GO: The Great Outdoors Multimodal Dataset</title>
      <link>http://arxiv.org/abs/2501.19274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;The Great Outdoors (GO) 数据集是一个多模态的标注数据资源，旨在推动未结构化环境中地面机器人的研究。&lt;h4&gt;背景&lt;/h4&gt;现有的越野数据集中缺乏全面的数据模式和注释。&lt;h4&gt;目的&lt;/h4&gt;提供涵盖多种传感器类型、高质量语义注释及GPS轨迹的数据集，以支持任务如语义分割、目标检测和SLAM等。&lt;h4&gt;方法&lt;/h4&gt;GO 数据集包含了六种独特的传感类型，并且提供了丰富的环境条件变化的数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集中包含的多样化实际挑战为开发更强大的解决方案提供了机会，有助于领域机器人技术、自主探索及感知系统的进一步发展。&lt;h4&gt;结论&lt;/h4&gt;该数据集可以在https://www.unmannedlab.org/the-great-outdoors-dataset/下载。&lt;h4&gt;翻译&lt;/h4&gt;The Great Outdoors (GO) 数据集是一个多模态的标注数据资源，旨在推动未结构化环境中地面机器人的研究。与现有的越野数据集相比，此数据集提供了最全面的数据模式和注释。总共有六种独特的传感器类型，并且包含了高质量的语义注释及GPS轨迹来支持诸如语义分割、目标检测等任务以及SLAM技术。数据集中所包含的各种环境条件展示了实际应用中的挑战性问题，这为开发更可靠的解决方案提供了机会，以支持领域机器人技术、自主探索和感知系统的进一步发展。该数据集可以在https://www.unmannedlab.org/the-great-outdoors-dataset/下载。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Great Outdoors (GO) dataset is a multi-modal annotated data resourceaimed at advancing ground robotics research in unstructured environments. Thisdataset provides the most comprehensive set of data modalities and annotationscompared to existing off-road datasets. In total, the GO dataset includes sixunique sensor types with high-quality semantic annotations and GPS traces tosupport tasks such as semantic segmentation, object detection, and SLAM. Thediverse environmental conditions represented in the dataset present significantreal-world challenges that provide opportunities to develop more robustsolutions to support the continued advancement of field robotics, autonomousexploration, and perception systems in natural environments. The dataset can bedownloaded at: https://www.unmannedlab.org/the-great-outdoors-dataset/</description>
      <author>example@mail.com (Peng Jiang, Kasi Viswanath, Akhil Nagariya, George Chustz, Maggie Wigness, Philip Osteen, Timothy Overbye, Christian Ellis, Long Quang, Srikanth Saripalli)</author>
      <guid isPermaLink="false">2501.19274v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge</title>
      <link>http://arxiv.org/abs/2501.19259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种基于神经形态视觉系统的实时导航框架Neuro-LIFT，该系统在Parrot Bebop2四旋翼无人机上实现了自然语言处理和事件驱动的物理规划相结合的自主导航。&lt;h4&gt;背景&lt;/h4&gt;当前的人机交互在自动化系统中的应用有限。传统NLP系统难以理解上下文和意图，阻碍了人与机器人之间的互动。虽然大型语言模型的进步改善了这种状况，但基于AI的自动驾驶算法在需要快速决策的关键任务中仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够将人类自然语言指令转换为高级规划命令并使用事件驱动神经形态视觉进行自主执行的新系统，以实现实时导航和人机交互。&lt;h4&gt;方法&lt;/h4&gt;Neuro-LIFT框架利用大型语言模型处理自然语言，并结合基于事件的神经形态视觉和物理驱动的规划来实现无人机在动态环境中的实时导航和障碍物避让功能。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在动态环境中进行有效导航，避免障碍，并根据人类指令实时调整行为。同时展示了低能耗、低延迟的优势。&lt;h4&gt;结论&lt;/h4&gt;Neuro-LIFT框架展示了一种新颖的方法来解决传统视觉系统的局限性，为未来的自主机器人提供了可能的解决方案和应用前景。&lt;h4&gt;翻译&lt;/h4&gt;将人性化交互融入自动化系统中一直是个难题。传统的自然语言处理（NLP）系统在理解上下文和意图方面存在困难，阻碍了人机互动的发展。大型语言模型的进步改变了这种状况，通过语音和文本实现直观且高层次的沟通，减少了人类指令与机器人动作之间的隔阂。此外，自主导航已成为机器人研究的核心焦点，人工智能技术被广泛应用于改进这些系统。然而，基于AI的导航算法在需要快速决策的关键任务中仍面临挑战。传统的帧式视觉系统虽然有效于高层决策，但在实时场景中的高能耗和延迟限制了其应用。神经形态视觉系统结合事件驱动相机和脉冲神经网络（SNNs），提供了一种潜在解决方案，使能高效、低延迟的导航。尽管这些系统的实际应用在诸如无人机等物理平台上仍不常见，本文提出了Neuro-LIFT框架，在Parrot Bebop2四旋翼上实现自然语言处理与事件驱动物理规划相结合的实时自主导航能力，展示了动态环境中导航和人机指令交互的实现实例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of human-intuitive interactions into autonomous systems hasbeen limited. Traditional Natural Language Processing (NLP) systems strugglewith context and intent understanding, severely restricting human-robotinteraction. Recent advancements in Large Language Models (LLMs) havetransformed this dynamic, allowing for intuitive and high-level communicationthrough speech and text, and bridging the gap between human commands androbotic actions. Additionally, autonomous navigation has emerged as a centralfocus in robotics research, with artificial intelligence (AI) increasinglybeing leveraged to enhance these systems. However, existing AI-based navigationalgorithms face significant challenges in latency-critical tasks where rapiddecision-making is critical. Traditional frame-based vision systems, whileeffective for high-level decision-making, suffer from high energy consumptionand latency, limiting their applicability in real-time scenarios. Neuromorphicvision systems, combining event-based cameras and spiking neural networks(SNNs), offer a promising alternative by enabling energy-efficient, low-latencynavigation. Despite their potential, real-world implementations of thesesystems, particularly on physical platforms such as drones, remain scarce. Inthis work, we present Neuro-LIFT, a real-time neuromorphic navigation frameworkimplemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for naturallanguage processing, Neuro-LIFT translates human speech into high-levelplanning commands which are then autonomously executed using event-basedneuromorphic vision and physics-driven planning. Our framework demonstrates itscapabilities in navigating in a dynamic environment, avoiding obstacles, andadapting to human instructions in real-time.</description>
      <author>example@mail.com (Amogh Joshi, Sourav Sanyal, Kaushik Roy)</author>
      <guid isPermaLink="false">2501.19259v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2501.19256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;解释过程是人类的本质活动。了解解释的目标和受众对于有效的解释至关重要，但现有的可解释强化学习(XRL)研究在评估时很少咨询实际的人类使用者。&lt;h4&gt;背景&lt;/h4&gt;当前的XRL研究缺乏与真实用户的互动，并倾向于使用主观评价指标（如信心或理解程度）来衡量效果。&lt;h4&gt;目的&lt;/h4&gt;呼吁研究人员采用基于观察和行动行为的对象性人类度量标准，以构建更可重复、可比较且认识论基础的研究。&lt;h4&gt;方法&lt;/h4&gt;整理并描述了几种客观评估方法，用于应用解释调试智能体的行为和支持人机团队合作，并通过一个新颖的网格环境展示了提议的方法。&lt;h4&gt;主要发现&lt;/h4&gt;主观和对象性度量标准可以互补地提供全面验证。未来的工作需要利用标准化基准进行测试，以促进研究之间的更大比较。&lt;h4&gt;结论&lt;/h4&gt;强调了使用客观人类衡量指标的重要性，以及主观与对象性方法如何共同作用于解释的有效评估。&lt;h4&gt;翻译&lt;/h4&gt;解释是一种根本上属于人类的活动过程。理解解释的目标和受众对于有效的沟通至关重要，然而现有的可解释强化学习（XRL）研究在没有真正咨询使用者的情况下进行评价的情况十分普遍。即使有些研究中涉及了人类反馈，它们也往往依赖于如信心或理解度这样的主观指标，只能反映用户的个人看法而非实际问题的实用性效果。这篇论文呼吁研究人员使用基于可观测和可操作行为的对象性人类评估标准来构建更可复制、更具比较性的且具有认识论基础的研究成果。为此，我们整理并描述了几种用于将解释应用于调试智能体行为和支持人机协作的任务中的客观评价方法，并通过一个新颖的网格环境展示了我们的提议方法。文章还讨论了如何利用主观和对象性指标互相补充来提供全面验证的方式，并指出了未来研究需要使用标准化基准测试以促进研究成果之间的更公平比较的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explanation is a fundamentally human process. Understanding the goal andaudience of the explanation is vital, yet existing work on explainablereinforcement learning (XRL) routinely does not consult humans in theirevaluations. Even when they do, they routinely resort to subjective metrics,such as confidence or understanding, that can only inform researchers of users'opinions, not their practical effectiveness for a given problem. This papercalls on researchers to use objective human metrics for explanation evaluationsbased on observable and actionable behaviour to build more reproducible,comparable, and epistemically grounded research. To this end, we curate,describe, and compare several objective evaluation methodologies for applyingexplanations to debugging agent behaviour and supporting human-agent teaming,illustrating our proposed methods using a novel grid-based environment. Wediscuss how subjective and objective metrics complement each other to provideholistic validation and how future work needs to utilise standardisedbenchmarks for testing to enable greater comparisons between research.</description>
      <author>example@mail.com (Balint Gyevnar, Mark Towers)</author>
      <guid isPermaLink="false">2501.19256v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Shaping Sparse Rewards in Reinforcement Learning: A Semi-supervised Approach</title>
      <link>http://arxiv.org/abs/2501.19128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种结合半监督学习和新颖数据增强技术的方法，以解决在稀疏奖励场景中有效奖励函数的学习难题。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的许多情形下，代理的回报信号非常稀疏，这使得通过奖励塑形来学习有效的回报函数变得极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，在利用非零奖励转换的同时结合半监督学习技术及新颖的数据增强技术从大部分过渡（包括零奖励过渡）中学习轨迹空间表示，以此改进奖励塑形的有效性。&lt;h4&gt;方法&lt;/h4&gt;该方法采用了一种双熵数据增强技术以提高性能。它在Atari和机器人操作任务中的实验结果展示了其优越的表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明此方法在稀疏回报场景下有效推广奖励塑形，与好奇心驱动的方法相比，在达到更高最佳得分时表现更好（最高提升4倍）。&lt;h4&gt;结论&lt;/h4&gt;提出的双熵数据增强方法展现了比其他增强技术更高的性能改进，最佳得分数值提高了15.8％。&lt;h4&gt;翻译&lt;/h4&gt;在许多现实世界场景中，代理的回报信号非常稀疏，这使得通过奖励塑形来学习有效的回报函数极具挑战性。为了解决这一问题，本研究提出了一种结合半监督学习技术与新颖数据增强的方法，用于从大部分转换（包括零回报转换）中学习轨迹空间表示，从而提高奖励塑形的有效性。实验结果显示，在Atari和机器人操作任务中的稀疏回报场景下，该方法显著提高了最佳得分的实现能力，并且相对于好奇心驱动的方法最多提升了四倍性能表现。特别是提出的双熵数据增强技术在最佳分数上比其他数据增强方法高出15.8%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world scenarios, reward signal for agents are exceedinglysparse, making it challenging to learn an effective reward function for rewardshaping. To address this issue, our approach performs reward shaping not onlyby utilizing non-zero-reward transitions but also by employing theSemi-Supervised Learning (SSL) technique combined with a novel dataaugmentation to learn trajectory space representations from the majority oftransitions, zero-reward transitions, thereby improving the efficacy of rewardshaping. Experimental results in Atari and robotic manipulation demonstratethat our method effectively generalizes reward shaping to sparse rewardscenarios, achieving up to four times better performance in reaching higherbest scores compared to curiosity-driven methods. The proposed double entropydata augmentation enhances performance, showcasing a 15.8\% increase in bestscore over other augmentation methods.</description>
      <author>example@mail.com (Wenyun Li, Wenjie Huang)</author>
      <guid isPermaLink="false">2501.19128v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Learning on Reconfigurable Hardware: Overcoming Material Variability in Laser Material Processing</title>
      <link>http://arxiv.org/abs/2501.19102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for the 2025 IEEE International Conference on Robotics and  Automation (ICRA), May 19-23, 2025, Atlanta, USA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于实时强化学习的激光加工控制方法，该方法在可编程门阵列上实现，能够在不同材料特性和表面条件下确保稳定的处理质量。&lt;h4&gt;背景&lt;/h4&gt;由于材料特性及表面状况的变化，保持激光工艺的一致性是一项挑战。尽管一些自动化的方法显示出一定的成效，但它们通常依赖于预设的目标或者只适用于模拟环境。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文提出了一种新的实时强化学习方法来控制激光过程。&lt;h4&gt;方法&lt;/h4&gt;通过在可编程门阵列上实现该算法以达到实时执行的效果。使用不锈钢样品进行了激光焊接测试，并且这些样本的表面粗糙度各不相同。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，此方法能够在没有奖励工程和预先设定信息的情况下自主适应不同情况，同时学习到适合每种独特表面特性的正确功率配置文件，对于粗糙表面和混合表面表现出显著改善（前者提高23%，后者提高7%）。&lt;h4&gt;结论&lt;/h4&gt;该研究标志着在激光工艺自动化与优化方面取得了重要进展，并具有跨行业的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring consistent processing quality is challenging in laser processes dueto varying material properties and surface conditions. Although some approacheshave shown promise in solving this problem via automation, they often rely onpredetermined targets or are limited to simulated environments. To addressthese shortcomings, we propose a novel real-time reinforcement learningapproach for laser process control, implemented on a Field Programmable GateArray to achieve real-time execution. Our experimental results from laserwelding tests on stainless steel samples with a range of surface roughnessesvalidated the method's ability to adapt autonomously, without relying on rewardengineering or prior setup information. Specifically, the algorithm learned thecorrect power profile for each unique surface characteristic, demonstratingsignificant improvements over hand-engineered optimal constant power strategies-- up to 23% better performance on rougher surfaces and 7% on mixed surfaces.This approach represents a significant advancement in automating and optimizinglaser processes, with potential applications across multiple industries.</description>
      <author>example@mail.com (Giulio Masinelli, Chang Rajani, Patrik Hoffmann, Kilian Wasmer, David Atienza)</author>
      <guid isPermaLink="false">2501.19102v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>SpikingSoft: A Spiking Neuron Controller for Bio-inspired Locomotion with Soft Snake Robots</title>
      <link>http://arxiv.org/abs/2501.19072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8th IEEE-RAS International Conference on Soft Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为SpikingSoft的方法，通过利用软体蛇机器人的物理振荡和低级脉冲神经机制来生成运动步态。&lt;h4&gt;背景&lt;/h4&gt;受到动物中运动神经元与物理弹性动态耦合的启发，研究探索了如何通过软体机器人中的物理振荡来产生步态。&lt;h4&gt;目的&lt;/h4&gt;引入一种可调阈值的双阈值脉冲神经模型，以激发软体机器蛇的自然动力学并简化其学习反应性移动的方式。&lt;h4&gt;方法&lt;/h4&gt;使用了一种可以生成不同输出模式的调整阈值机制的神经元模型，并展示了这种方法如何与强化学习结合使用。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够通过调节两个阈值来产生复杂的运动模式，从而使软体蛇机器人在成功率、目标到达时间和移动流畅性方面都有显著提高。&lt;h4&gt;结论&lt;/h4&gt;SpikingSoft方法为软体机器人的控制提供了一种新的有效途径，使得它们可以更好地适应环境变化并完成任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到的研究通过引入一种新颖的神经模型和强化学习相结合的方式，成功提升了软体蛇机器人在复杂环境下的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inspired by the dynamic coupling of moto-neurons and physical elasticity inanimals, this work explores the possibility of generating locomotion gaits byutilizing physical oscillations in a soft snake by means of a low-level spikingneural mechanism. To achieve this goal, we introduce the Double ThresholdSpiking neuron model with adjustable thresholds to generate varied outputpatterns. This neuron model can excite the natural dynamics of soft roboticsnakes, and it enables distinct movements, such as turning or moving forward,by simply altering the neural thresholds. Finally, we demonstrate that ourapproach, termed SpikingSoft, naturally pairs and integrates with reinforcementlearning. The high-level agent only needs to adjust the two thresholds togenerate complex movement patterns, thus strongly simplifying the learning ofreactive locomotion. Simulation results demonstrate that the proposedarchitecture significantly enhances the performance of the soft snake robot,enabling it to achieve target objectives with a 21.6% increase in success rate,a 29% reduction in time to reach the target, and smoother movements compared tothe vanilla reinforcement learning controllers or Central Pattern Generatorcontroller acting in torque space.</description>
      <author>example@mail.com (Chuhan Zhang, Cong Wang, Wei Pan, Cosimo Della Santina)</author>
      <guid isPermaLink="false">2501.19072v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>EgoMe: Follow Me via Egocentric View in Real World</title>
      <link>http://arxiv.org/abs/2501.19061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种新型大规模第一人称视角数据集EgoMe，旨在通过现实世界中的第一人称视角模拟人类模仿学习的过程。&lt;h4&gt;背景&lt;/h4&gt;人类在与真实世界的互动中倾向于以自我为中心的视角作为基准，并将从他人角度观察到的行为转化为自身行为。这一认知理论为研究机器人如何更有效地模仿人类行为提供了基础。&lt;h4&gt;目的&lt;/h4&gt;填补当前研究没有充分利用人类实际生活中的认知行为，该论文提出了一种新的大规模第一人称视角数据集EgoMe，以促进机器人模仿学习能力的研究。&lt;h4&gt;方法&lt;/h4&gt;EgoMe 数据集中包括了7902对视频（共15804个视频），涵盖了现实场景中各种日常行为。每对视频记录了一个观察者从第三人称视角观看示范者的动作和随后第一人称视角下复制这些动作的过程，还包括了多种传感器数据。&lt;h4&gt;主要发现&lt;/h4&gt;提出八个具有挑战性的基准任务以充分利用这个数据集，并通过广泛的数据统计分析显示相比现有数据集有显著优势。&lt;h4&gt;结论&lt;/h4&gt;该论文旨在促进机器人模仿学习的研究，提出的EgoMe 数据集和基准将很快发布。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在与真实世界互动时，人类通常采用第一人称视角作为行为参照，并自然地从第三人称视角观察的行为中复制自己的行为。这种认知理论为研究机器人如何更有效地模仿人类行为提供了基础。然而，目前的研究要么使用多个不同视角同时关注同一个体的相机，要么面对无法配对的第一人称和第三人称视图场景，没有充分利用人类在现实生活中的认知行为。为了填补这一空白，在本文中我们引入了一个新颖的大规模第一人称视角数据集EgoMe，该数据集旨在模拟通过第一人称视角进行的人类模仿学习过程。我们的数据集中包含了7902对视频（共15804个视频），涵盖了现实场景中的各种日常行为。对于一对视频，其中一个记录了观察者从第三人称视角观看示范者的动作，另一个则记录了观察者随后以第一人称视角复制这些动作的过程。值得注意的是，该数据集还包含第三人称与第一人称眼动、角速度、加速度和磁场强度等多种传感器多模态数据，以便于建立观察和模仿之间的相关性。此外，我们提出了八个具有挑战性的基准任务以充分利用这一数据资源，并促进机器人模仿学习能力的研究。广泛的数据统计分析显示了相比现有数据集的显著优势。所提出的EgoMe 数据集和基准将很快发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When interacting with the real world, human often take the egocentric(first-person) view as a benchmark, naturally transferring behaviors observedfrom a exocentric (third-person) view to their own. This cognitive theoryprovides a foundation for researching how robots can more effectively imitatehuman behavior. However, current research either employs multiple cameras withdifferent views focusing on the same individual's behavior simultaneously orencounters unpair ego-exo view scenarios, there is no effort to fully exploithuman cognitive behavior in the real world. To fill this gap, in this paper, weintroduce a novel large-scale egocentric dataset, called EgoMe, which towardsfollowing the process of human imitation learning via egocentric view in thereal world. Our dataset includes 7902 pairs of videos (15804 videos) fordiverse daily behaviors in real-world scenarios. For a pair of videos, onevideo captures a exocentric view of the imitator observing the demonstrator'sactions, while the other captures a egocentric view of the imitatorsubsequently following those actions. Notably, our dataset also contain exo-egoeye gaze, angular velocity, acceleration, magnetic strength and other sensormulti-modal data for assisting in establishing correlations between observingand following process. In addition, we also propose eight challenging benchmarktasks for fully leveraging this data resource and promoting the research ofrobot imitation learning ability. Extensive statistical analysis demonstratessignificant advantages compared to existing datasets. The proposed EgoMedataset and benchmark will be released soon.</description>
      <author>example@mail.com (Heqian Qiu, Zhaofeng Shi, Lanxiao Wang, Huiyu Xiong, Xiang Li, Hongliang Li)</author>
      <guid isPermaLink="false">2501.19061v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Gravity Compensation of the dVRK-Si Patient Side Manipulator based on Dynamic Model Identification</title>
      <link>http://arxiv.org/abs/2501.19058v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;达芬奇研究套件（dVRK，也被称为dVRK Classic）是一个开源远程操作外科手术机器人系统，其硬件来源于第一代达芬奇外科手术系统。在过去十年中，dVRK极大地促进了机器人辅助手术的研究，并帮助研究人员解决了多个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍一个新的dVRK-Si版本的系统，该版本使用了第二代达芬奇Si外科手术系统的机械部件，提出了针对该新版本的新方法。&lt;h4&gt;问题&lt;/h4&gt;由于结构升级，新的dVRK-Si PSM在控制精度和响应时间方面存在问题，并且需要基于动态模型识别的方法进行重力补偿。&lt;h4&gt;方法&lt;/h4&gt;提出了一种全新的dVRK-Si PSM完整运动学模型以及一种基于动态模型识别的重力补偿方案来解决这些问题。&lt;h4&gt;结论&lt;/h4&gt;提出的方案可以提高新版本dVRK系统的控制性能，有助于未来在机器人辅助手术领域的进一步研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了达芬奇研究套件(dVRK)及其最新版本dVRK-Si的背景、目的以及为解决其存在的问题所提出的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The da Vinci Research Kit (dVRK, also known as dVRK Classic) is anopen-source teleoperated surgical robotic system whose hardware is obtainedfrom the first generation da Vinci Surgical System (Intuitive, Sunnyvale, CA,USA). The dVRK has greatly facilitated research in robot-assisted surgery overthe past decade and helped researchers address multiple major challenges inthis domain. Recently, the dVRK-Si system, a new version of the dVRK which usesmechanical components from the da Vinci Si Surgical System, became available tothe community. The major difference between the first generation da Vinci andthe da Vinci Si is in the structural upgrade of the Patient Side Manipulator(PSM). Because of this upgrade, the gravity of the dVRK-Si PSM can no longer beignored as in the dVRK Classic. The high gravity offset may lead to relativelylow control accuracy and longer response time. In addition, althoughsubstantial progress has been made in addressing the dynamic modelidentification problem for the dVRK Classic, further research is required onmodel-based control for the dVRK-Si, due to differences in mechanicalcomponents and the demand for enhanced control performance. To address theseproblems, in this work, we present (1) a novel full kinematic model of thedVRK-Si PSM, and (2) a gravity compensation approach based on the dynamic modelidentification.</description>
      <author>example@mail.com (Haoying Zhou, Hao Yang, Anton Deguet, Loris Fichera, Jie Ying Wu, Peter Kazanzides)</author>
      <guid isPermaLink="false">2501.19058v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Optimization Under Stochastic Dynamics Leveraging Maximum Mean Discrepancy</title>
      <link>http://arxiv.org/abs/2501.19045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://github.com/Basant1861/MPC-MMD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了针对随机动力学下的风险感知导航的采样基础轨迹优化方法，并在统计信息提取和碰撞风险评估方面进行了创新。&lt;h4&gt;背景&lt;/h4&gt;现有的基于样本的方法通常通过计算围绕名义动态的$ilde{N}$扰动滚动生成来估计与控制命令序列相关的碰撞风险。然而，当涉及到昂贵的碰撞检测时，这种方法变得不经济。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法，该算法能够从大量随机轨迹中提取出少量关键样本，并使用这些样本进行碰撞风险评估；同时，开发一个新的代理函数用于利用精简后的统计信息来估计碰撞风险。&lt;h4&gt;方法&lt;/h4&gt;首先提出了一个算法，将大量的扰动滚动生成过程的数据提炼为一个小的样本集，从而减少所需的样本数量$N&lt;&lt;ilde{N}$。其次，提出了一种新的风险代理模型，它能够有效地使用简化后的小样本集中包含的信息来估计碰撞风险。&lt;h4&gt;主要发现&lt;/h4&gt;通过在重分布嵌入到再生核希尔伯特空间（RKHS）和最大平均差异（MMD）的基础上正式化了上述两个方法，并进行了广泛的基准测试。实验结果表明，在低样本数量的情况下，基于MMD的方法可以生成比现有的条件价值-风险（CVaR）基线更安全的轨迹。&lt;h4&gt;结论&lt;/h4&gt;所提出的采样优化技术不仅可以显著减少估计碰撞风险所需的计算成本，而且还能够提高导航安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种旨在解决随机动力学下风险感知导航问题的方法。该方法通过提炼统计信息到精简集来降低样本数量，并提出了一个基于MMD的新模型用于评估碰撞风险。实验结果表明，新方法在低采样条件下生成的轨迹更安全，比现有的CVaR基线有明显优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses sampling-based trajectory optimization for risk-awarenavigation under stochastic dynamics. Typically such approaches operate bycomputing $\tilde{N}$ perturbed rollouts around the nominal dynamics toestimate the collision risk associated with a sequence of control commands. Weconsider a setting where it is expensive to estimate risk using perturbedrollouts, for example, due to expensive collision-checks. We put forward twokey contributions. First, we develop an algorithm that distills the statisticalinformation from a larger set of rollouts to a reduced-set with sample size$N&lt;&lt;\tilde{N}$. Consequently, we estimate collision risk using just $N$rollouts instead of $\tilde{N}$. Second, we formulate a novel surrogate for thecollision risk that can leverage the distilled statistical informationcontained in the reduced-set. We formalize both algorithmic contributions usingdistribution embedding in Reproducing Kernel Hilbert Space (RKHS) and MaximumMean Discrepancy (MMD). We perform extensive benchmarking to demonstrate thatour MMD-based approach leads to safer trajectories at low sample regime thanexisting baselines using Conditional Value-at Risk (CVaR) based collision riskestimate.</description>
      <author>example@mail.com (Basant Sharma, Arun Kumar Singh)</author>
      <guid isPermaLink="false">2501.19045v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors</title>
      <link>http://arxiv.org/abs/2501.19042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to RAL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器人集群行为的多样性生成问题，并提出了一种结合生成模型和安全过滤器（SF）的方法，能够快速有效地生成多模态、可行的轨迹。&lt;h4&gt;背景&lt;/h4&gt;机器人集群的行为本质上是多模式的，存在多种方式使机器人群避免相互间的碰撞并达到各自的目标。然而，如何在可扩展的方式下生成多样化的可行行为仍然是一个尚未完全解决的问题。&lt;h4&gt;目的&lt;/h4&gt;填补现有方法在这方面的空白，结合生成模型和安全过滤器来生成多样化且可行的机器人集群行为。&lt;h4&gt;方法&lt;/h4&gt;1. 从学习到的生成模型中采样多样化的轨迹，并使用安全过滤器将其投影到可行集上。2. 使用两种类型的生成模型：条件变分自动编码器（CVAE）和向量量化变分自动编码器（VQ-VAE），并比较它们在计算时间和轨迹多样性方面的权衡。3. 开发了一个带有初始化网络的定制安全过滤器，该网络能够根据上下文预测初始值，并通过自监督的方式进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;1. 能够在几十分之一秒内生成大量的多模态、可行的行为轨迹，模拟多种机器人集群行为。2. 开发的初始化网络比其他替代启发式方法更快地收敛于安全过滤器求解器。&lt;h4&gt;结论&lt;/h4&gt;通过结合生成模型和安全过滤器，能够在保证多样性的同时快速有效地生成机器人集群的可行行为。未来可以进一步优化计算效率和扩展性。&lt;h4&gt;翻译&lt;/h4&gt;协调行为在机器人蜂群中本质上是多模态的性质。也就是说，存在多种方式使机器人群避免相互间的碰撞并达到各自的目标。然而，在可扩展的方式下生成多样化的可行行为的问题仍然很大程度上未得到解决。本文填补了这一空白，通过结合生成模型和安全过滤器（SF）来实现。具体来说，从学习到的生成模型中采样多样化轨迹，并使用安全过滤器将其投影到可行集上。实验采用了两种类型的生成模型：条件变分自动编码器（CVAE）和向量量化变分自动编码器（VQ-VAE），并探讨了它们在计算时间和轨迹多样性方面的权衡。开发了一个带有初始化网络的定制安全过滤器，该网络能够根据上下文预测初始值，并通过自监督的方式进行训练。提供了两组实证结果：首先，在几十分之一秒内可以生成大量多模态、可行的行为轨迹；其次，所开发的初始化网络比其他替代启发式方法更快地收敛于安全过滤器求解器。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cisimon7/swarmgen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coordination behavior in robot swarms is inherently multi-modal in nature.That is, there are numerous ways in which a swarm of robots can avoidinter-agent collisions and reach their respective goals. However, the problemof generating diverse and feasible swarm behaviors in a scalable manner remainslargely unaddressed. In this paper, we fill this gap by combining generativemodels with a safety-filter (SF). Specifically, we sample diverse trajectoriesfrom a learned generative model which is subsequently projected onto thefeasible set using the SF. We experiment with two choices for generativemodels, namely: Conditional Variational Autoencoder (CVAE) and Vector-QuantizedVariational Autoencoder (VQ-VAE). We highlight the trade-offs these two modelsprovide in terms of computation time and trajectory diversity. We develop acustom solver for our SF and equip it with a neural network that predictscontext-specific initialization. Thecinitialization network is trained in aself-supervised manner, taking advantage of the differentiability of the SFsolver. We provide two sets of empirical results. First, we demonstrate that wecan generate a large set of multi-modal, feasible trajectories, simulatingdiverse swarm behaviors, within a few tens of milliseconds. Second, we showthat our initialization network provides faster convergence of our SF solvervis-a-vis other alternative heuristics.</description>
      <author>example@mail.com (Simon Idoko, B. Bhanu Teja, K. Madhava Krishna, Arun Kumar Singh)</author>
      <guid isPermaLink="false">2501.19042v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable Simulation of Soft Robots with Frictional Contacts</title>
      <link>http://arxiv.org/abs/2501.18956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，软机器人仿真器发展迅速，提供了模拟不同材料类型（如弹性、超弹性）和驱动方法（如气动、缆绳驱动、伺服电机）的功能。这些仿真工具还支持各种任务，包括校准、设计和控制。&lt;h4&gt;目的&lt;/h4&gt;然而，在物理接触交互存在的情况下，有效地计算导数在软机器人仿真中仍是一个挑战。该论文旨在解决这一问题，引入了一种统一的方法来计算有限元方法框架内的机械方程的导数，特别是在处理接触交互时将其建模为非线性互补问题。&lt;h4&gt;方法&lt;/h4&gt;提出的方法涵盖了碰撞和摩擦阶段，并考虑到它们的动力学是非光滑的特性，同时利用了基于网格模型带来的稀疏性。该方法通过几种软系统控制与校准的例子证明了其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;将这些导数纳入仿真器中可以显著提高诸如强化学习、轨迹优化等控制方法的收敛速度；还可以为设计工作提供梯度基础技术，并支持端到端的机器学习方法进行模型简化。&lt;h4&gt;结论&lt;/h4&gt;通过引入一个统一的方法来解决计算机械方程导数的问题，尤其是在处理物理接触互动时，能够显著提升软机器人仿真器的功能和效率。该论文展示了这种方法在多个例子中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在最近几年里，软机器人的模拟器已经进化到提供多种功能，包括不同材料类型（例如弹性体、超弹体）和驱动方法（如气动式、缆绳驱动式、伺服马达式）。这些模拟器还为各种任务提供了工具，比如校准、设计以及控制。然而，在处理物理接触互动的时候，高效且准确地计算导数依然是个挑战。将这些导数纳入可以显著提高诸如强化学习和轨迹优化的控制方法的收敛速度；也可以用它来进行基于梯度的设计技术或简化模型的端到端机器学习的方法。这篇论文通过在有限元法框架下介绍一种统一方法来解决这个问题，该方法处理了如非线性互补问题之类的接触互动，并且考虑到了碰撞和摩擦阶段及其非光滑动力学特性。这种方法利用网格模型所带来的稀疏特性，并通过几个软系统的控制与校准的例子展示了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, soft robotics simulators have evolved to offer variousfunctionalities, including the simulation of different material types (e.g.,elastic, hyper-elastic) and actuation methods (e.g., pneumatic, cable-driven,servomotor). These simulators also provide tools for various tasks, such ascalibration, design, and control. However, efficiently and accurately computingderivatives within these simulators remains a challenge, particularly in thepresence of physical contact interactions. Incorporating these derivatives can,for instance, significantly improve the convergence speed of control methodslike reinforcement learning and trajectory optimization, enable gradient-basedtechniques for design, or facilitate end-to-end machine-learning approaches formodel reduction. This paper addresses these challenges by introducing a unifiedmethod for computing the derivatives of mechanical equations within the finiteelement method framework, including contact interactions modeled as a nonlinearcomplementarity problem. The proposed approach handles both collision andfriction phases, accounts for their nonsmooth dynamics, and leverages thesparsity introduced by mesh-based models. Its effectiveness is demonstratedthrough several examples of controlling and calibrating soft systems.</description>
      <author>example@mail.com (Etienne Ménager, Louis Montaut, Quentin Le Lidec, Justin Carpentier)</author>
      <guid isPermaLink="false">2501.18956v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning based Quasi-consciousness Training for Robot Intelligent Model</title>
      <link>http://arxiv.org/abs/2501.18955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了一种基于深度学习的机器人智能模型，旨在使机器人能够学习和推理复杂任务。&lt;h4&gt;背景&lt;/h4&gt;为了提高机器人的自主性和适应性，研究者们正在探索如何通过模拟人类意识来增强机器人的能力。&lt;h4&gt;目的&lt;/h4&gt;该研究的目标是构建一个深度学习驱动的机器人智能模型，使其具备处理复杂的环境信息并作出合理决策的能力。&lt;h4&gt;方法&lt;/h4&gt;首先，通过构造环境因素矩阵网络来激发机器人智能模型的学习过程，并对模型参数进行粗调和精调以优化损失函数。其次，为培养具有初级意识的机器人智能模型，每个机器人都需要接受至少1到3年的特殊训练，学习人类行为模式。&lt;h4&gt;主要发现&lt;/h4&gt;该研究展示了基于深度学习的方法在实现类似人类意识的机器人系统方面的潜在应用价值，并能够将已知概念融合在一起以表达未曾经历的事物，从而增强模型的一般性。&lt;h4&gt;结论&lt;/h4&gt;通过深度学习技术可以有效推进机器人的智能水平发展和行为模式训练，为未来机器人的广泛应用提供了新的可能路径。&lt;h4&gt;翻译&lt;/h4&gt;此摘要的中文版本已经如上所示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores a deep learning based robot intelligent model thatrenders robots learn and reason for complex tasks. First, by constructing anetwork of environmental factor matrix to stimulate the learning process of therobot intelligent model, the model parameters must be subjected to coarse &amp;fine tuning to optimize the loss function for minimizing the loss score,meanwhile robot intelligent model can fuse all previously known conceptstogether to represent things never experienced before, which need robotintelligent model can be generalized extensively. Secondly, in order toprogressively develop a robot intelligent model with primary consciousness,every robot must be subjected to at least 1~3 years of special school fortraining anthropomorphic behaviour patterns to understand and process complexenvironmental information and make rational decisions. This work explores anddelivers the potential application of deep learning-based quasi-consciousnesstraining in the field of robot intelligent model.</description>
      <author>example@mail.com (Yuchun Li, Fang Zhang)</author>
      <guid isPermaLink="false">2501.18955v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>HeLiOS: Heterogeneous LiDAR Place Recognition via Overlap-based Learning and Local Spherical Transformer</title>
      <link>http://arxiv.org/abs/2501.18943v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, 5 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;LiDAR位置识别是定位中的关键模块，用于将当前位置与先前观察到的环境进行匹配。传统的研究大多集中在旋转式激光雷达上，利用其大视场角来实现匹配。&lt;h4&gt;背景&lt;/h4&gt;随着不同类型激光雷达技术的发展，不同类型的激光雷达数据之间的匹配变得越来越重要，而这一挑战长期以来并未得到充分关注。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一挑战，研究人员引入了HeLiOS（Heterogeneous LiDAR Place Recognition System），这是一种专为异构激光雷达位置识别设计的深度网络。&lt;h4&gt;方法&lt;/h4&gt;HeLiOS利用小局部窗口和球形变换器以及基于最优传输的聚类分配来生成稳健的全局描述符。此外，该系统采用重叠数据挖掘技术和引导三元组损失函数以克服传统距离基元数据挖掘和离散类别约束的限制。&lt;h4&gt;主要发现&lt;/h4&gt;HeLiOS在公共数据集上的表现展示了其在异构激光雷达位置识别方面的有效性，并且包括长期识别能力评估，表明它可以处理未见过类型的激光雷达。&lt;h4&gt;结论&lt;/h4&gt;研究人员将HeLiOS代码开源发布于GitHub上（https://github.com/minwoo0611/HeLiOS），供机器人社区使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的深度网络——HeLiOS，旨在解决不同种类激光雷达之间的位置识别问题。它利用了一系列创新方法来提高匹配的准确性和鲁棒性，并展示了在公共数据集上的出色性能以及处理未知类型激光雷达的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR place recognition is a crucial module in localization that matches thecurrent location with previously observed environments. Most existingapproaches in LiDAR place recognition dominantly focus on the spinning typeLiDAR to exploit its large FOV for matching. However, with the recent emergenceof various LiDAR types, the importance of matching data across different LiDARtypes has grown significantly-a challenge that has been largely overlooked formany years. To address these challenges, we introduce HeLiOS, a deep networktailored for heterogeneous LiDAR place recognition, which utilizes small localwindows with spherical transformers and optimal transport-based clusterassignment for robust global descriptors. Our overlap-based data mining andguided-triplet loss overcome the limitations of traditional distance-basedmining and discrete class constraints. HeLiOS is validated on public datasets,demonstrating performance in heterogeneous LiDAR place recognition whileincluding an evaluation for long-term recognition, showcasing its ability tohandle unseen LiDAR types. We release the HeLiOS code as an open source for therobotics community at https://github.com/minwoo0611/HeLiOS.</description>
      <author>example@mail.com (Minwoo Jung, Sangwoo Jung, Hyeonjae Gil, Ayoung Kim)</author>
      <guid isPermaLink="false">2501.18943v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Open-Source Autonomous Driving Software Platforms: Comparison of Autoware and Apollo</title>
      <link>http://arxiv.org/abs/2501.18942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arxiv preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文详细比较了开源自主驾驶软件平台Autoware和Apollo的核心模块及中间件性能，提供了选择适合特定开发环境的平台的实际参考。&lt;h4&gt;背景&lt;/h4&gt;全栈自动驾驶系统包括感知、规划和控制等多个技术领域，每一方面都需要深入研究。此外，验证这些技术需要大量的支持性基础设施，如模拟器、传感器和高精度地图等，这使得个人开发者和研究小组面临着很高的进入壁垒。&lt;h4&gt;目的&lt;/h4&gt;通过提供详细的量化对比，帮助研究人员和工程师选择最合适的开源平台以适应他们的特定开发环境，并推动全栈自动驾驶系统的发展。&lt;h4&gt;方法&lt;/h4&gt;系统地审查了Autoware和Apollo的核心模块，并评估了它们的中间件性能。&lt;h4&gt;主要发现&lt;/h4&gt;论文强调了两个平台之间的关键差异，并提出了在不同应用场景下如何选择合适平台的实际建议。&lt;h4&gt;结论&lt;/h4&gt;开源自主驾驶软件平台可以有效地支持研究人员和工程师进行实施和评估自动驾驶功能，通过全面对比Autoware和Apollo，为研究者提供宝贵的参考意见。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了全栈自动驾驶系统的技术挑战、验证需求以及新兴的开源平台如何帮助解决这些问题。同时指出了目前对于这些平台比较的不足，并强调了本论文通过对Autoware和Apollo进行详细对比来填补这一空白的重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-stack autonomous driving system spans diverse technologicaldomains-including perception, planning, and control-that each require in-depthresearch. Moreover, validating such technologies of the system necessitatesextensive supporting infrastructure, from simulators and sensors tohigh-definition maps. These complexities with barrier to entry pose substantiallimitations for individual developers and research groups. Recently,open-source autonomous driving software platforms have emerged to address thischallenge by providing autonomous driving technologies and practical supportinginfrastructure for implementing and evaluating autonomous drivingfunctionalities. Among the prominent open-source platforms, Autoware and Apolloare frequently adopted in both academia and industry. While previous studieshave assessed each platform independently, few have offered a quantitative anddetailed head-to-head comparison of their capabilities. In this paper, wesystematically examine the core modules of Autoware and Apollo and evaluatetheir middleware performance to highlight key differences. These insights serveas a practical reference for researchers and engineers, guiding them inselecting the most suitable platform for their specific developmentenvironments and advancing the field of full-stack autonomous driving system.</description>
      <author>example@mail.com (Hee-Yang Jung, Dong-Hee Paek, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2501.18942v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Minimum Time Strategies for a Differential Drive Robot Escaping from a Circular Detection Region</title>
      <link>http://arxiv.org/abs/2501.18899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文研究了一种在圆形检测区域内的差分驱动机器人（DDR）如何以最短时间逃离的问题，并将其应用于各种现实场景。&lt;h4&gt;背景&lt;/h4&gt;许多机器人应用可以建模为一个问题，即差分驱动机器人需要尽快从危险或禁止区域内逃脱或者离开无人驾驶飞行器的传感器覆盖范围。这些问题可以通过博弈论中的追逃游戏来描述和解决。&lt;h4&gt;目的&lt;/h4&gt;找出在两个不同情景下DDR逃离检测区域的时间最优运动策略：一种是检测区域移动速度较慢且试图阻止DDR逃脱；另一种是检测区域位置固定不变。&lt;h4&gt;方法&lt;/h4&gt;将问题形式化为零和博弈理论中的追逃游戏，并利用微分博弈理论计算了玩家的时间最优运动策略。考虑到DDR的速度优势，它可以通过以最大速度远离检测区域的中心来逃离。&lt;h4&gt;主要发现&lt;/h4&gt;尽管已知策略在某些情况下可能是最佳的，但根据玩家之间的速度比以及初始配置的不同，会出现其他不同的时间最优运动策略。&lt;h4&gt;结论&lt;/h4&gt;通过微分博弈理论的应用，研究者展示了在不同条件下DDR如何选择不同的最优化逃逸策略以实现其目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A Differential Drive Robot (DDR) located inside a circular detection regionin the plane wants to escape from it in minimum time. Various roboticsapplications can be modeled like the previous problem, such as a DDR escapingas soon as possible from a forbidden/dangerous region in the plane or runningout from the sensor footprint of an unmanned vehicle flying at a constantaltitude. In this paper, we find the motion strategies to accomplish its goalunder two scenarios. In one, the detection region moves slower than the DDR andseeks to prevent escape; in another, its position is fixed. We formulate theproblem as a zero-sum pursuit-evasion game, and using differential gamestheory, we compute the players' time-optimal motion strategies. Given the DDR'sspeed advantage, it can always escape by translating away from the center ofthe detection region at maximum speed. In this work, we show that the previousstrategy could be optimal in some cases; however, other motion strategiesemerge based on the player's speed ratio and the players' initialconfigurations.</description>
      <author>example@mail.com (Ubaldo Ruiz)</author>
      <guid isPermaLink="false">2501.18899v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Learning of Flexible Policies for Symbolic Instructions with Adjustable Mapping Specifications</title>
      <link>http://arxiv.org/abs/2501.18848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, Accepted by IEEE Robotics and Automation Letters (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;符号任务表示是一种强大的工具，用于编码人类指令和领域知识。通过强化学习（RL），这些指令指导机器人完成多样化的目标并满足约束条件。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来帮助机器人应对灵活的符号映射，并解决当前大多数基于固定环境状态到符号映射的方法在设备检查任务中的局限性问题，即需要从多个角度评估设备状况以避免遗漏错误。&lt;h4&gt;方法&lt;/h4&gt;我们引入了一种学习灵活策略的方法，称为具有可调整映射规范的符号指令(SIAMS)。该方法使用线性时态逻辑（LTL）表示符号指令，并通过状态调制和任务课程等手段来处理多样化的完成模式。&lt;h4&gt;主要发现&lt;/h4&gt;SIAMS可以有效应对不同视角下的设备检查问题，能够根据学习进度逐步提供任务并调整映射规范，从而提高机器人的适应性和灵活性。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，在具有离散和连续动作空间的3D仿真中，我们的方法优于基于上下文感知多任务RL的方法。&lt;h4&gt;翻译&lt;/h4&gt;符号任务表示是编码人类指令和领域知识的强大工具。通过强化学习（RL），这些指令指导机器人完成多样化的目标并满足约束条件。然而，当前大多数基于固定环境状态到符号映射的方法在设备检查任务中表现出局限性。为了解决这一问题，我们引入了一种新的方法，即具有可调整映射规范的符号指令(SIAMS)，它能够处理多样化的完成模式，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Symbolic task representation is a powerful tool for encoding humaninstructions and domain knowledge. Such instructions guide robots to accomplishdiverse objectives and meet constraints through reinforcement learning (RL).Most existing methods are based on fixed mappings from environmental states tosymbols. However, in inspection tasks, where equipment conditions must beevaluated from multiple perspectives to avoid errors of oversight, robots mustfulfill the same symbol from different states. To help robots respond toflexible symbol mapping, we propose representing symbols and their mappingspecifications separately within an RL policy. This approach imposes on RLpolicy to learn combinations of symbolic instructions and mappingspecifications, requiring an efficient learning framework. To cope with thisissue, we introduce an approach for learning flexible policies called SymbolicInstructions with Adjustable Mapping Specifications (SIAMS). This paperrepresents symbolic instructions using linear temporal logic (LTL), a formallanguage that can be easily integrated into RL. Our method addresses thediversified completion patterns of instructions by (1) a specification-awarestate modulation, which embeds differences in mapping specifications in statefeatures, and (2) a symbol-number-based task curriculum, which graduallyprovides tasks according to the learning's progress. Evaluations in 3Dsimulations with discrete and continuous action spaces demonstrate that ourmethod outperforms context-aware multitask RL comparisons.</description>
      <author>example@mail.com (Wataru Hatanaka, Ryota Yamashina, Takamitsu Matsubara)</author>
      <guid isPermaLink="false">2501.18848v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Physics-informed Neural Model Predictive Control of Interacting Active Brownian Particles</title>
      <link>http://arxiv.org/abs/2501.18809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了活性物质系统在自然和工程领域中的应用潜力，并提出了一种结合物理信息机器学习与模型预测控制的框架，以解决对这些系统的宏观行为进行精确控制的挑战。&lt;h4&gt;背景&lt;/h4&gt;活性物质由能够将能量转化为定向运动的自推进代理组成，展现出诸如运动诱导相分离、群集和聚集等新兴现象。这些系统在编程材料、定向装配及微机器人等领域具有巨大应用潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一种结合物理信息机器学习与模型预测控制的方法框架，以便精确地控制系统中的宏观连续场（例如密度或流速）。&lt;h4&gt;方法&lt;/h4&gt;提出了一种将物理信息纳入机器学习模型的方法，通过该方法获得复杂粒子相互作用的闭合模型，并将其集成到模型预测控制框架中，以实时调整系统行为。&lt;h4&gt;主要发现&lt;/h4&gt;展示了一个框架可以同时控制活性物质系统的数量密度和平均流速，并且能够使后者遵循预设的正弦波轮廓。这表明所提出的方法具有良好的适应性和灵活性。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新的方法来系统地控制复杂的动态行为，从而为开发自适应和编程材料开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;活性物质由能将能量转化为定向运动的单元组成，展示了多种新兴现象。这些现象在自然和技术系统中普遍存在，并对编程材料、定向装配及微机器人等应用领域具有重要价值。然而，因多体互动和相关粒子动态性复杂性的原因，精确控制系统的宏观连续场（如密度或流速）仍具挑战。为应对这一问题，本文提出了一种结合物理信息机器学习与模型预测控制的方法框架，并通过两个示例展示了其有效性及灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active matter systems, composed of self-propelled agents that convert energyinto directed motion, exhibit a wide range of emergent behaviors, such asmotility-induced phase separation, flocking, and swarming. These phenomena,observed across natural and engineered systems, hold immense potential forapplications in programmable materials, directed assembly, and micro-robotics.However, precisely controlling their macroscopic continuum fields, e.g.,density or flux, remains a significant challenge due to the complexity ofmultibody interactions and correlated particle dynamics. To address thischallenge, we present a framework that combines physics-informed machinelearning with Model Predictive Control. Our approach learns a closure model forcomplex particle interactions while incorporating known physical principles,resulting in an accurate predictive model suitable for real-time control. Byintegrating this model into a Model Predictive Control framework, we enablesystematic optimization of control actions that can guide the system towarddesired macroscopic behaviors. Through two illustrative examples, we showcasethe versatility of the framework. First, we control the spatial distribution ofparticles by splitting them into two groups and dynamically juggling theirdensities. Second, we simultaneously control both the number density and themean flux, guiding the latter to follow a prescribed sinusoidal profile. Theseresults highlight the framework's potential to systematically control complexdynamics in active matter systems and provide a foundation for broaderapplications in programmable and adaptive materials.</description>
      <author>example@mail.com (Titus Quah, Sho C. Takatori, James B. Rawlings)</author>
      <guid isPermaLink="false">2501.18809v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hamiltonian Dynamics with Bayesian Data Assimilation</title>
      <link>http://arxiv.org/abs/2501.18808v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于神经网络的时间序列预测方法，用于未知哈密顿动力系统的长期预测。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在许多领域都具有重要应用，特别是在动态系统的研究中。对于复杂或未完全了解的哈密顿动力系统来说，传统的预测技术可能无法提供足够的准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于神经网络的方法来提高未知哈密顿动力系统的长期预测精度。&lt;h4&gt;方法&lt;/h4&gt;{'1': '利用代理模型学习系统动态，并使用广义坐标（位置）及其共轭动量，在保持常数哈密顿的情况下进行建模。', '2': '提出了一种自回归哈密顿神经网络，该网络在训练目标中加入自回归预测误差，以进一步提高长期预测的准确性。', '3': '采用贝叶斯数据同化方法，利用在线测量数据实时优化预测结果。'}&lt;h4&gt;主要发现&lt;/h4&gt;通过弹簧-质量系统和高度椭圆轨道下的引力摄动实验验证了所提方法的有效性，显示出了其准确性和鲁棒性的长期预测潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在处理未知哈密顿动力系统的长期预测问题上表现优异，展示了强大的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we develop a neural network-based approach for time-seriesprediction in unknown Hamiltonian dynamical systems. Our approach leverages asurrogate model and learns the system dynamics using generalized coordinates(positions) and their conjugate momenta while preserving a constantHamiltonian. To further enhance long-term prediction accuracy, we introduce anAutoregressive Hamiltonian Neural Network, which incorporates autoregressiveprediction errors into the training objective. Additionally, we employ Bayesiandata assimilation to refine predictions in real-time using online measurementdata. Numerical experiments on a spring-mass system and highly elliptic orbitsunder gravitational perturbations demonstrate the effectiveness of the proposedmethod, highlighting its potential for accurate and robust long-termpredictions.</description>
      <author>example@mail.com (Taehyeun Kim, Tae-Geun Kim, Anouck Girard, Ilya Kolmanovsky)</author>
      <guid isPermaLink="false">2501.18808v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Agile and Cooperative Aerial Manipulation of a Cable-Suspended Load</title>
      <link>http://arxiv.org/abs/2501.18802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;四旋翼无人机可以以高速将吊索负载运送到难以到达的地点。鉴于单个四旋翼载荷能力有限，使用多架四旋翼协作搬运重物是一个可扩展且有前景的方法。&lt;h4&gt;背景&lt;/h4&gt;现有的多提升系统控制算法由于四旋翼与负载之间的复杂动力耦合效应，在低速和低加速度操作中受限，这限制了其在搜救等时间紧迫任务中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种方案以显著提高悬索式多提升系统的灵活性。&lt;h4&gt;方法&lt;/h4&gt;引入基于轨迹的框架解决整体机动运动规划问题，并实时考虑四旋翼与负载之间的动力耦合效应和约束。采用滑动窗口方式提供参考路径，由内置控制器根据缆绳张力进行观察和补偿来跟踪。&lt;h4&gt;主要发现&lt;/h4&gt;该研究证明了所提出的框架可以在保持高鲁棒性和无需额外加载传感器的情况下实现比现有最佳方法快八倍的加速度，并能执行诸如高速穿越狭窄通道等复杂操作。&lt;h4&gt;结论&lt;/h4&gt;本方案展示了在提高多四旋翼协同搬运任务灵活性方面的巨大潜力，具有显著的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quadrotors can carry slung loads to hard-to-reach locations at high speed.Since a single quadrotor has limited payload capacities, using a team ofquadrotors to collaboratively manipulate a heavy object is a scalable andpromising solution. However, existing control algorithms for multi-liftingsystems only enable low-speed and low-acceleration operations due to thecomplex dynamic coupling between quadrotors and the load, limiting their use intime-critical missions such as search and rescue. In this work, we present asolution to significantly enhance the agility of cable-suspended multi-liftingsystems. Unlike traditional cascaded solutions, we introduce a trajectory-basedframework that solves the whole-body kinodynamic motion planning problemonline, accounting for the dynamic coupling effects and constraints between thequadrotors and the load. The planned trajectory is provided to the quadrotorsas a reference in a receding-horizon fashion and is tracked by an onboardcontroller that observes and compensates for the cable tension. Real-worldexperiments demonstrate that our framework can achieve at least eight timesgreater acceleration than state-of-the-art methods to follow agiletrajectories. Our method can even perform complex maneuvers such as flyingthrough narrow passages at high speed. Additionally, it exhibits highrobustness against load uncertainties and does not require adding any sensorsto the load, demonstrating strong practicality.</description>
      <author>example@mail.com (Sihao Sun, Xuerui Wang, Dario Sanalitro, Antonio Franchi, Marco Tognon, Javier Alonso-Mora)</author>
      <guid isPermaLink="false">2501.18802v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Designing Kresling Origami for Personalised Wrist Orthosis</title>
      <link>http://arxiv.org/abs/2501.18796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the 2025 IEEE/RAS International  Conference on Soft Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型腕部矫形器设计，灵感来自Kresling折纸结构。这种设计能够适应不同的个体形状参数，并且具有可拆卸的肌腱驱动系统。&lt;h4&gt;背景&lt;/h4&gt;手腕在促进运动灵巧性和手功能方面起着至关重要的作用。现有的腕部矫形器从被动支架到主动外骨骼提供了有效的解决方案，但其类型化的动作有限，个性化设计不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有腕部矫形器的限制，本研究提出了一种新颖的设计方法，旨在开发个性化的腕部矫形器具以用于训练和康复。&lt;h4&gt;方法&lt;/h4&gt;通过使用可热封织物模仿Kresling折纸结构的非刚性性质来实现。该设计可以适应各种个体形状参数，并具备六种不同的运动模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验测试表明，这种腕部矫形器在各个方向上的最大弯曲角度范围从18.81度到32.63度不等；当肌腱组合拉伸时，在背侧、掌侧、桡侧和尺侧方向的最大弯曲角分别为31.66度、30.38度、27.14度和14.92度。&lt;h4&gt;结论&lt;/h4&gt;这项工作为开发个性化腕部矫形器具提供了有前景的基础，能够促进运动训练和康复。&lt;h4&gt;翻译&lt;/h4&gt;手腕在增强动作灵巧性和手功能方面扮演着核心角色。从被动支架到主动外骨骼的腕部矫形器提供了解决方案来辅助和支持运动能力的发展与恢复。然而，现有设备所能支持的动作类型有限且不够个性化。为了填补这一空白，本文提出了一种新的设计概念——基于Kresling折纸结构的腕部矫形器设计。这种设计可以根据个体的不同形态参数进行调整，并充分利用了折纸拓扑变化和内在柔韧性。通过使用可热封材料复制非刚性性质（即模仿Kresling折纸的特点），该矫形器具能够实现六种不同的运动模式，配有一个可拆卸的肌腱驱动系统。当单独激活各个肌腱时，实验测试表明，在每个方向上的最大弯曲角度范围从18.81度至32.63度不等；而当组合拉伸肌腱时，在背侧、掌侧、桡侧和尺侧的最大弯曲角分别为31.66度、30.38度、27.14度和14.92度。此外，还通过实验验证了复杂动作（如投掷动作和圆周运动）生成的能力。总的来说，这项研究为开发个性化腕部矫形器具用于训练和康复提供了坚实的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The wrist plays a pivotal role in facilitating motion dexterity and handfunctions. Wrist orthoses, from passive braces to active exoskeletons, providean effective solution for the assistance and rehabilitation of motor abilities.However, the type of motions facilitated by currently available orthoses islimited, with little emphasis on personalised design. To address these gaps,this paper proposes a novel wrist orthosis design inspired by the Kreslingorigami. The design can be adapted to accommodate various individual shapeparameters, which benefits from the topological variations and intrinsiccompliance of origami. Heat-sealable fabrics are used to replicate thenon-rigid nature of the Kresling origami. The orthosis is capable of sixdistinct motion modes with a detachable tendon-based actuation system.Experimental characterisation of the workspace has been conducted by activatingtendons individually. The maximum bending angle in each direction ranges from18.81{\deg} to 32.63{\deg}. When tendons are pulled in combination, the maximumbending angles in the dorsal, palmar, radial, and ulnar directions are31.66{\deg}, 30.38{\deg}, 27.14{\deg}, and 14.92{\deg}, respectively. Thecapability to generate complex motions such as the dart-throwing motion andcircumduction has also been experimentally validated. The work presents apromising foundation for the development of personalised wrist orthoses fortraining and rehabilitation.</description>
      <author>example@mail.com (Chenying Liu, Shuai Mao, Yixing Lei, Liang He)</author>
      <guid isPermaLink="false">2501.18796v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>One Stack, Diverse Vehicles: Checking Safe Portability of Automated Driving Software</title>
      <link>http://arxiv.org/abs/2501.18769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint to appear in 2025 IEEE/SICE International Symposium on  System Integration (SII)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种使用形式化端口检查适应性巡航控制代码的方法，旨在解决自动化驾驶软件栈在不同配置的车辆中集成时所面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;将自动驾驶软件堆栈整合到具有不同配置的汽车中是一项艰巨的任务，尤其是在面对不同的硬件特性时。此外，为了向行驶中的车队提供软件更新，必须确保每个受影响配置的功能安全性。&lt;h4&gt;目的&lt;/h4&gt;满足这些可靠性需求并应对自动化驾驶日益增加的硬件多样性，严格的自动分析变得至关重要。本文通过使用适应性巡航控制器代码的形式化端口检查来解决这一挑战。&lt;h4&gt;方法&lt;/h4&gt;给定一个形式化的安全行为规范，目标配置模型被推导出来以捕捉传感器、执行器和计算平台的相关效应。然后获得对应的安全集，并用于检查所需的行为是否可以在所有目标上实现。&lt;h4&gt;主要发现&lt;/h4&gt;在案例研究中，传统控制器和神经网络控制器的端口检查可以自动完成，在几分钟内对每种车辆硬件配置进行检查。该检查为必要的控制器调整提供了反馈，从而允许快速集成和测试软件或参数更改。&lt;h4&gt;结论&lt;/h4&gt;通过采用形式化的方法来保证自动化驾驶系统在不同硬件平台上的可移植性和安全性，可以加速自动驾驶技术的应用和发展。&lt;h4&gt;翻译&lt;/h4&gt;将自动化的驾驶软件栈整合到具有变化配置的车辆中是一项挑战，尤其是因为不同的硬件特性。进一步地，为了给行驶中的车队提供软件更新，必须确保每个受影响配置的功能安全性。这些额外的需求对可靠性的要求以及自动化驾驶中日益增加的硬件多样性使得严格的自动分析变得至关重要。本文通过使用适应性巡航控制器代码的形式化端口检查来解决这一挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating an automated driving software stack into vehicles with variableconfiguration is challenging, especially due to different hardwarecharacteristics. Further, to provide software updates to a vehicle fleet in thefield, the functional safety of every affected configuration has to be ensured.These additional demands for dependability and the increasing hardwarediversity in automated driving make rigorous automatic analysis essential. Thispaper addresses this challenge by using formal portability checking of adaptivecruise controller code for different vehicle configurations. Given a formalspecification of the safe behavior, models of target configurations arederived, which capture relevant effects of sensors, actuators and computingplatforms. A corresponding safe set is obtained and used to check if thedesired behavior is achievable on all targets. In a case study, portabilitychecking of a traditional and a neural network controller are performedautomatically within minutes for each vehicle hardware configuration. The checkprovides feedback for necessary adaptations of the controllers, thus, allowingrapid integration and testing of software or parameter changes.</description>
      <author>example@mail.com (Vladislav Nenchev)</author>
      <guid isPermaLink="false">2501.18769v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation</title>
      <link>http://arxiv.org/abs/2501.18733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了LMM-3DP框架，旨在结合大型多模态模型（LMM）规划器和三维技能策略，从而增强机器人的能力。&lt;h4&gt;背景&lt;/h4&gt;视觉推理能力和三维特征域语义丰富化的最新进展为机器人技术开辟了新的可能性。这些发展有助于弥合从LMM得出的高级推理与利用3D特征场进行低级控制政策之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够集成LMM规划器和3D技能策略的框架，以提高机器人的行动效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;{'高阶规划': ['动态场景理解以应对环境干扰', '自我反馈的批评者代理', '历史政策记忆', '失败后的重试'], '低级控制': ['利用语义感知3D特征场进行精确操作']}&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，在真实厨房环境中，与基于LLM的基线方法相比，LMM-3DP框架在低级控制方面提高了1.45倍的成功率，并且高级规划准确度提高了约1.5倍。&lt;h4&gt;结论&lt;/h4&gt;该工作展示了如何通过结合视觉推理能力和三维特征域语义丰富化来增强机器人的能力。它还证明了将大型多模态模型和3D技能策略有效集成的可能性，从而实现更有效的机器人操作。&lt;h4&gt;翻译&lt;/h4&gt;最近在大型多模态模型（LMM）的视觉推理能力和三维特征场语义丰富的进步已经扩展了机器人技术的能力范围。这些发展具有重要的潜力来弥合从LMM得出的高级推理与利用3D特征场进行低级控制策略之间的差距。在这项工作中，我们引入了LMM-3DP框架，它可以集成LMM规划器和三维技能策略。我们的方法包括三个方面：高阶计划、低级控制以及有效整合。对于高阶规划，LMM-3DP支持动态场景理解以应对环境干扰，拥有自我反馈的批评者代理，历史政策记忆，以及在失败后的重试尝试。对于低级控制，LMM-3DP利用语义感知三维特征场进行精确操作。为了将高级和低级控制对接机器人行动，使用语言嵌入来表示高级策略，并将其与3D特征域一起关注于3D变换器中以实现无缝整合。我们在多个技能以及长时段任务的现实厨房环境中进行了广泛的评估。我们的结果显示，在低级控制方面成功率提高了1.45倍，而在高阶规划精度上提升了大约1.5倍相比于基于LLM的方法。更多演示视频和LMM-3DP概述可访问https://lmm-3dp-release.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancements in visual reasoning capabilities of large multimodalmodels (LMMs) and the semantic enrichment of 3D feature fields have expandedthe horizons of robotic capabilities. These developments hold significantpotential for bridging the gap between high-level reasoning from LMMs andlow-level control policies utilizing 3D feature fields. In this work, weintroduce LMM-3DP, a framework that can integrate LMM planners and 3D skillPolicies. Our approach consists of three key perspectives: high-level planning,low-level control, and effective integration. For high-level planning, LMM-3DPsupports dynamic scene understanding for environment disturbances, a criticagent with self-feedback, history policy memorization, and reattempts afterfailures. For low-level control, LMM-3DP utilizes a semantic-aware 3D featurefield for accurate manipulation. In aligning high-level and low-level controlfor robot actions, language embeddings representing the high-level policy arejointly attended with the 3D feature field in the 3D transformer for seamlessintegration. We extensively evaluate our approach across multiple skills andlong-horizon tasks in a real-world kitchen environment. Our results show asignificant 1.45x success rate increase in low-level control and an approximate1.5x improvement in high-level planning accuracy compared to LLM-basedbaselines. Demo videos and an overview of LMM-3DP are available athttps://lmm-3dp-release.github.io.</description>
      <author>example@mail.com (Yuelei Li, Ge Yan, Annabella Macaluso, Mazeyu Ji, Xueyan Zou, Xiaolong Wang)</author>
      <guid isPermaLink="false">2501.18733v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Strong and Controllable 3D Motion Generation</title>
      <link>http://arxiv.org/abs/2501.18726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人体动作生成在生成计算机视觉中具有重要意义，在电影制作、视频游戏、AR/VR和人机交互等领域有广泛应用。&lt;h4&gt;挑战&lt;/h4&gt;['现有的基于扩散模型或自回归模型的方法在文本到动作的生成过程中耗时长，阻碍了实时应用的发展。', '这些方法通常学习的是由文本指导的相对运动表示，难以精确地控制关节级别的动作序列']&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术中存在的问题，提出了一种简单但有效的架构，旨在提高硬件效率和计算复杂度，并增强人体运动生成中更精确的关节级别控制。&lt;h4&gt;方法&lt;/h4&gt;['优化基于Transformer的扩散模型以高效生成人体运动，通过定制快速线性注意力来实现。', '在动作潜在空间中定制一致性模型以进一步加速动作生成。', '引入Motion ControlNet，该技术使相比之前的方法可以更精确地控制关节级别的身体动作。']&lt;h4&gt;主要发现&lt;/h4&gt;这些贡献代表了文本到运动生成的重大进展，将这项技术推向了现实世界应用的边缘。&lt;h4&gt;结论&lt;/h4&gt;所提出的架构和方法能够有效解决当前人体运动生成中存在的问题，并显著提高了其在实际场景中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;人类动作生成是生成计算机视觉领域的一个重要研究方向，在电影制作、视频游戏、AR/VR以及人机交互等众多领域都有广泛的应用。然而，目前的方法主要依赖于基于扩散的生成模型或自回归模型进行文本到动作的转换，并且面临两大挑战：一是生成过程耗时长，难以满足游戏、机器人操纵和在线环境下的实时应用需求；二是这些方法通常学习的是相对运动表示，在根据文本指导生成动作序列时很难精确控制关节级别的动作。这些问题严重阻碍了这一领域的进步和发展。为解决上述问题，本文提出了一种简单但有效的架构，通过定制快速线性注意力优化基于Transformer的扩散模型，并在潜在的动作空间中自定义一致性模型以进一步加快动作生成速度。此外，还引入了Motion ControlNet技术，该技术能够提供比现有方法更精确的关节级别控制。这些贡献是文本到运动生成领域的重大突破，有助于这一技术更好地应用于实际场景之中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human motion generation is a significant pursuit in generative computervision with widespread applications in film-making, video games, AR/VR, andhuman-robot interaction. Current methods mainly utilize either diffusion-basedgenerative models or autoregressive models for text-to-motion generation.However, they face two significant challenges: (1) The generation process istime-consuming, posing a major obstacle for real-time applications such asgaming, robot manipulation, and other online settings. (2) These methodstypically learn a relative motion representation guided by text, making itdifficult to generate motion sequences with precise joint-level control. Thesechallenges significantly hinder progress and limit the real-world applicationof human motion generation techniques. To address this gap, we propose a simpleyet effective architecture consisting of two key components. Firstly, we aim toimprove hardware efficiency and computational complexity in transformer-baseddiffusion models for human motion generation. By customizing flash linearattention, we can optimize these models specifically for generating humanmotion efficiently. Furthermore, we will customize the consistency model in themotion latent space to further accelerate motion generation. Secondly, weintroduce Motion ControlNet, which enables more precise joint-level control ofhuman motion compared to previous text-to-motion generation methods. Thesecontributions represent a significant advancement for text-to-motiongeneration, bringing it closer to real-world applications.</description>
      <author>example@mail.com (Canxuan Gang)</author>
      <guid isPermaLink="false">2501.18726v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Policy Gradient Quality-Diversity with Massive Parallelization via Behavioral Variations</title>
      <link>http://arxiv.org/abs/2501.18723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为ASCII-ME的快速且样本高效的算法，旨在克服MAP-Elites在处理高维度问题时遇到的限制，并能够在大规模并行化计算环境中有效运行。&lt;h4&gt;背景&lt;/h4&gt;质量多样性优化是一类以生成多样化和高性能解决方案为目标的进化算法。其中，MAP-Elites（ME）是一个著名例子，在诸如进化机器人等领域广泛应用。然而，ME依赖于遗传算法中的随机突变来运作，这在处理高维度问题时显得力不从心。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够大规模并行化工作的快速且样本高效的MAP-Elites算法，以显著减少运行时间而不影响性能。&lt;h4&gt;方法&lt;/h4&gt;ASCII-ME基于行为变异的时间步长表现指标进行操作，并使用策略梯度将这些变异映射到解决方案。与现有策略梯度质量多样性方法不同的是，ASCII-ME不依赖于集中式的演员-评论家训练机制。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，ASCII-ME能够在单一GPU上以不到250秒的时间生成一组多样化且高性能的深层神经网络政策，并且平均运行速度是当前最先进技术的五倍，同时仍然保持样本效率。&lt;h4&gt;结论&lt;/h4&gt;ASCII-ME算法为质量多样性优化提供了一种高效解决方案，尤其是在处理大规模并行化计算任务时表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quality-Diversity optimization comprises a family of evolutionary algorithmsaimed at generating a collection of diverse and high-performing solutions.MAP-Elites (ME), a notable example, is used effectively in fields likeevolutionary robotics. However, the reliance of ME on random mutations fromGenetic Algorithms limits its ability to evolve high-dimensional solutions.Methods proposed to overcome this include using gradient-based operators likepolicy gradients or natural evolution strategies. While successful at scalingME for neuroevolution, these methods often suffer from slow training speeds, ordifficulties in scaling with massive parallelization due to high computationaldemands or reliance on centralized actor-critic training. In this work, weintroduce a fast, sample-efficient ME based algorithm capable of scaling upwith massive parallelization, significantly reducing runtimes withoutcompromising performance. Our method, ASCII-ME, unlike existing policy gradientquality-diversity methods, does not rely on centralized actor-critic training.It performs behavioral variations based on time step performance metrics andmaps these variations to solutions using policy gradients. Our experiments showthat ASCII-ME can generate a diverse collection of high-performing deep neuralnetwork policies in less than 250 seconds on a single GPU. Additionally, itoperates on average, five times faster than state-of-the-art algorithms whilestill maintaining competitive sample efficiency.</description>
      <author>example@mail.com (Konstantinos Mitsides, Maxence Faldor, Antoine Cully)</author>
      <guid isPermaLink="false">2501.18723v1</guid>
      <pubDate>Mon, 03 Feb 2025 15:20:24 +0800</pubDate>
    </item>
    </channel>
</rss>