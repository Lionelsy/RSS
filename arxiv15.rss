<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 10 Jul 2025 14:21:57 +0800</lastBuildDate>
    <item>
      <title>Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS</title>
      <link>http://arxiv.org/abs/2507.05999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Transactions on Geoscience &amp; Remote Sensing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在GNSS信号受限的城市区域进行激光雷达点云精确地理配准的方法。&lt;h4&gt;背景&lt;/h4&gt;在GNSS信号受限的城市区域，如高楼大厦和桥梁附近，现有的地理配准方法通常依赖于实时GNSS和IMU数据，这些方法需要预先校准，并假设在数据收集过程中定位稳定，但在密集的城市区域这一假设常常不成立，导致定位误差。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文提出了一种结构化的地理配准和空间校正方法，该方法通过将3D点云与卫星图像对齐，实现帧级GNSS信息恢复和城市尺度3D地图重建，而不依赖于先前的定位。&lt;h4&gt;方法&lt;/h4&gt;该方法使用预训练的点Transformer模型来分割道路点，然后从点云中提取道路骨架和交叉口点，以及用于对齐的目标地图。使用交叉口点进行全局刚性对齐，随后使用径向基函数（RBF）插值进行局部细化。基于SRTM数据集中的地形信息对点云进行高程校正，以解决垂直差异。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上，该方法在包含交叉口的序列中实现了平均平面配准标准差（STD）为0.84米，相比原始数据集提高了55.3%。在缺乏GNSS信息的珀斯（澳大利亚西部）CBD数据集上，该方法实现了平均STD为0.96米，与从Google Maps API提取的GPS数据相比提高了77.4%。此外，在KITTI数据集上，该方法在海拔相关性方面提高了30.5%，在珀斯数据集上提高了50.4%。&lt;h4&gt;结论&lt;/h4&gt;该方法在GNSS信号受限的城市区域中实现了高精度的激光雷达点云地理配准，有效提高了点云的定位精度。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate geo-registration of LiDAR point clouds presents significant challenges in GNSS signal denied urban areas with high-rise buildings and bridges. Existing methods typically rely on real-time GNSS and IMU data, that require pre-calibration and assume stable positioning during data collection. However, this assumption often fails in dense urban areas, resulting in localization errors. To address this, we propose a structured geo-registration and spatial correction method that aligns 3D point clouds with satellite images, enabling frame-wise recovery of GNSS information and reconstruction of city scale 3D maps without relying on prior localization. The proposed approach employs a pre-trained Point Transformer model to segment the road points and then extracts the road skeleton and intersection points from the point cloud as well as the target map for alignment. Global rigid alignment of the two is performed using the intersection points, followed by local refinement using radial basis function (RBF) interpolation. Elevation correction is then applied to the point cloud based on terrain information from SRTM dataset to resolve vertical discrepancies. The proposed method was tested on the popular KITTI benchmark and a locally collected Perth (Western Australia) CBD dataset. On the KITTI dataset, our method achieved an average planimetric alignment standard deviation (STD) of 0.84~m across sequences with intersections, representing a 55.3% improvement over the original dataset. On the Perth dataset, which lacks GNSS information, our method achieved an average STD of 0.96~m compared to the GPS data extracted from Google Maps API. This corresponds to a 77.4% improvement from the initial alignment. Our method also resulted in elevation correlation gains of 30.5% on the KITTI dataset and 50.4% on the Perth dataset.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate geo-registration of LiDAR point clouds presents significantchallenges in GNSS signal denied urban areas with high-rise buildings andbridges. Existing methods typically rely on real-time GNSS and IMU data, thatrequire pre-calibration and assume stable positioning during data collection.However, this assumption often fails in dense urban areas, resulting inlocalization errors. To address this, we propose a structured geo-registrationand spatial correction method that aligns 3D point clouds with satelliteimages, enabling frame-wise recovery of GNSS information and reconstruction ofcity scale 3D maps without relying on prior localization. The proposed approachemploys a pre-trained Point Transformer model to segment the road points andthen extracts the road skeleton and intersection points from the point cloud aswell as the target map for alignment. Global rigid alignment of the two isperformed using the intersection points, followed by local refinement usingradial basis function (RBF) interpolation. Elevation correction is then appliedto the point cloud based on terrain information from SRTM dataset to resolvevertical discrepancies. The proposed method was tested on the popular KITTIbenchmark and a locally collected Perth (Western Australia) CBD dataset. On theKITTI dataset, our method achieved an average planimetric alignment standarddeviation (STD) of 0.84~m across sequences with intersections, representing a55.3\% improvement over the original dataset. On the Perth dataset, which lacksGNSS information, our method achieved an average STD of 0.96~m compared to theGPS data extracted from Google Maps API. This corresponds to a 77.4\%improvement from the initial alignment. Our method also resulted in elevationcorrelation gains of 30.5\% on the KITTI dataset and 50.4\% on the Perthdataset.</description>
      <author>example@mail.com (Xinyu Wang, Muhammad Ibrahim, Atif Mansoor, Ajmal Mian)</author>
      <guid isPermaLink="false">2507.05999v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
  <item>
      <title>Topological Sequence Analysis of Genomes: Delta Complex approaches</title>
      <link>http://arxiv.org/abs/2507.05452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于拓扑序列分析（TSA）的新方法，应用于基因组序列分析，通过构建Δ复形和分类空间，得到基因组序列上的持久同伦和持久路径同伦，并开发了基于Δ复形的持久拉普拉斯算子，以促进基因组序列的拓扑谱分析。&lt;h4&gt;背景&lt;/h4&gt;代数拓扑已被广泛应用于点云数据以捕捉几何形状和拓扑结构，但其应用于基因组序列分析仍较为罕见。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的拓扑序列分析（TSA）技术，以应用于基因组序列分析。&lt;h4&gt;方法&lt;/h4&gt;通过构建Δ复形和分类空间，得到持久同伦和持久路径同伦，并开发基于Δ复形的持久拉普拉斯算子。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的TSA方法在埃博拉病毒序列和全细菌基因组中的系统发育分析中显示出其实用性，且比早期的TSA模型（如k-mer拓扑）更高效。&lt;h4&gt;结论&lt;/h4&gt;所提出的TSA方法在基因组序列分析中具有潜在的应用价值，并且可能被应用于其他耗时的序列数据分析，如语言学、文学、音乐、媒体和社会环境中的数据分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Algebraic topology has been widely applied to point cloud data to capturegeometric shapes and topological structures. However, its application to genomesequence analysis remains rare. In this work, we propose topological sequenceanalysis (TSA) techniques by constructing $\Delta$-complexes and classifyingspaces, leading to persistent homology, and persistent path homology on genomesequences. We also develop $\Delta$-complex-based persistent Laplacians tofacilitate the topological spectral analysis of genome sequences. Finally, wedemonstrate the utility of the proposed TSA approaches in phylogenetic analysisusing Ebola virus sequences and whole bacterial genomes. The present TSAmethods are more efficient than earlier TSA model, k-mer topology, and thushave a potential to be applied to other time-consuming sequential dataanalyses, such as those in linguistics, literature, music, media, and socialcontexts.</description>
      <author>example@mail.com (Jian Liu, Li Shen, Dong Chen, Guo-Wei Wei)</author>
      <guid isPermaLink="false">2507.05452v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator</title>
      <link>http://arxiv.org/abs/2507.07073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures, submitted for publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种几何深度学习框架，用于高效预测给定CAD网格的Laplace-Beltrami（LB）谱，通过减少计算时间约5倍，同时保持高精度，证明了LB谱是可学习的。&lt;h4&gt;背景&lt;/h4&gt;Laplace-Beltrami算子的谱在几何深度学习任务中起着核心作用，它捕捉了所考虑物体形状的内在属性。基于有限元素法（FEM）的方法是目前用于估计LB算子谱的最成熟方法，其复杂度为O(Nk)，其中N是点的数量。当反复应用于CAD机械部件数据库或质量控制应用中时，FEM方法可能变得低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来高效预测CAD网格的LB谱，同时减少计算时间，提高处理速度。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种基于图神经网络的架构，使用包括高斯曲率、平均曲率和主曲率在内的丰富部件网格特征。此外，为了确保可重复性，我们还提供了一个大型经过精心挑选的、由公共ABC数据集衍生出的真实世界机械CAD模型数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与线性FEM相比，该方法将LB谱的计算时间减少了约5倍，同时保持了有竞争力的精度。&lt;h4&gt;结论&lt;/h4&gt;LB谱是可学习的，且本文提出的方法在计算效率上具有显著优势，适用于需要快速频繁进行部件质量控制的场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spectrum of the Laplace-Beltrami (LB) operator is central in geometricdeep learning tasks, capturing intrinsic properties of the shape of the objectunder consideration. The best established method for its estimation, from atriangulated mesh of the object, is based on the Finite Element Method (FEM),and computes the top k LB eigenvalues with a complexity of O(Nk), where N isthe number of points. This can render the FEM method inefficient whenrepeatedly applied to databases of CAD mechanical parts, or in quality controlapplications where part metrology is acquired as large meshes and decisionsabout the quality of each part are needed quickly and frequently. As a solutionto this problem, we present a geometric deep learning framework to predict theLB spectrum efficiently given the CAD mesh of a part, achieving significantcomputational savings without sacrificing accuracy, demonstrating that the LBspectrum is learnable. The proposed Graph Neural Network architecture uses arich set of part mesh features - including Gaussian curvature, mean curvature,and principal curvatures. In addition to our trained network, we makeavailable, for repeatability, a large curated dataset of real-world mechanicalCAD models derived from the publicly available ABC dataset used for trainingand testing. Experimental results show that our method reduces computation timeof the LB spectrum by approximately 5 times over linear FEM while deliveringcompetitive accuracy.</description>
      <author>example@mail.com (Yulin An, Enrique del Castillo)</author>
      <guid isPermaLink="false">2507.07073v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images</title>
      <link>http://arxiv.org/abs/2507.07013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级且训练高效的预测细胞组成的方法，通过利用预训练病理基础模型中的信息丰富特征嵌入，直接从H&amp;E染色组织图像中预测细胞组成。&lt;h4&gt;背景&lt;/h4&gt;数字病理学和深度学习的快速发展推动了病理基础模型的出现，这些模型有望在统一模型中解决各种疾病条件下的通用病理问题。同时，空间转录组学作为一项新兴技术，使得在H&amp;E染色组织图像上对基因表达进行表征成为可能。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，可以直接从H&amp;E染色组织图像中预测细胞组成，而无需进行成本高昂的空间转录组学。&lt;h4&gt;方法&lt;/h4&gt;通过在细胞类型丰度上训练一个轻量级的多层感知器（MLP）回归器，该方法有效地从病理基础模型中提取知识，并展示出从组织图像中准确预测细胞组成的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在性能上与现有的方法如Hist2Cell相当，同时显著降低了计算复杂度。&lt;h4&gt;结论&lt;/h4&gt;该轻量级且训练高效的方法能够直接从H&amp;E染色组织图像中预测细胞组成，为病理学研究和诊断提供了新的可能性，同时降低了计算成本。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着数字病理学和现代深度学习的快速发展，病理基础模型应运而生，有望在统一模型中解决各种疾病条件下的通用病理问题，无论是否经过微调。同时，空间转录组学作为一项变革性技术，使得在H&amp;E染色组织图像上对基因表达进行表征成为可能。空间转录组学解锁了深入现有组织图像的前所未有的机会，以更细粒度、细胞级的水平进行探究。在本研究中，我们提出了一种轻量级且训练高效的方法，通过利用从预训练病理基础模型中提取的信息丰富特征嵌入，直接从H&amp;E染色组织图像中预测细胞组成。通过在细胞2位置衍生出的细胞类型丰度上训练一个轻量级的多层感知器（MLP）回归器，我们的方法有效地从病理基础模型中提取知识，并证明了从组织图像中准确预测细胞组成的潜力，无需物理执行成本高昂的空间转录组学。我们的方法在性能上与现有方法（如Hist2Cell）相当，同时显著降低了计算复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid development of digital pathology and modern deep learning hasfacilitated the emergence of pathology foundation models that are expected tosolve general pathology problems under various disease conditions in oneunified model, with or without fine-tuning. In parallel, spatialtranscriptomics has emerged as a transformative technology that enables theprofiling of gene expression on hematoxylin and eosin (H&amp;E) stained histologyimages. Spatial transcriptomics unlocks the unprecedented opportunity to diveinto existing histology images at a more granular, cellular level. In thiswork, we propose a lightweight and training-efficient approach to predictcellular composition directly from H&amp;E-stained histology images by leveraginginformation-enriched feature embeddings extracted from pre-trained pathologyfoundation models. By training a lightweight multi-layer perceptron (MLP)regressor on cell-type abundances derived via cell2location, our methodefficiently distills knowledge from pathology foundation models anddemonstrates the ability to accurately predict cell-type compositions fromhistology images, without physically performing the costly spatialtranscriptomics. Our method demonstrates competitive performance compared toexisting methods such as Hist2Cell, while significantly reducing computationalcomplexity.</description>
      <author>example@mail.com (Yutong Sun, Sichen Zhu, Peng Qiu)</author>
      <guid isPermaLink="false">2507.07013v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds</title>
      <link>http://arxiv.org/abs/2507.06906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Robotics and Automation Letters  (RA-L)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对稀疏雷达点云中的全景分割问题，提出了一种名为SemRaFiner的方法，以提高场景理解能力。&lt;h4&gt;背景&lt;/h4&gt;语义场景理解对于实现自动驾驶的安全和稳健驾驶行为至关重要。相机和激光雷达常用于语义场景理解，但在恶劣天气下存在局限性，且通常不提供运动信息。雷达传感器可以直接通过测量多普勒速度提供关于运动代理的信息，但其测量结果相对稀疏且噪声较大。&lt;h4&gt;目的&lt;/h4&gt;解决稀疏雷达点云中的全景分割问题，以增强场景理解。&lt;h4&gt;方法&lt;/h4&gt;SemRaFiner方法考虑了稀疏雷达点云中的密度变化，并优化了特征提取以提高准确性。此外，还提出了一种优化的训练程序，通过结合专门的数据增强来细化实例分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与基于雷达的全景分割的现有方法相比，该方法表现更优。&lt;h4&gt;结论&lt;/h4&gt;SemRaFiner方法在稀疏雷达点云的全景分割方面优于现有技术，有助于提高自动驾驶场景理解能力。&lt;h4&gt;翻译&lt;/h4&gt;Semantic scene understanding, including the perception and classification of moving agents, is essential to enabling safe and robust driving behaviors of autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene understanding. However, both sensor modalities face limitations in adverse weather and usually do not provide motion information. Radar sensors overcome these limitations and directly offer information about moving agents by measuring the Doppler velocity, but the measurements are comparably sparse and noisy. In this paper, we address the problem of panoptic segmentation in sparse radar point clouds to enhance scene understanding. Our approach, called SemRaFiner, accounts for changing density in sparse radar point clouds and optimizes the feature extraction to improve accuracy. Furthermore, we propose an optimized training procedure to refine instance assignments by incorporating a dedicated data augmentation. Our experiments suggest that our approach outperforms state-of-the-art methods for radar-based panoptic segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3502058&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic scene understanding, including the perception and classification ofmoving agents, is essential to enabling safe and robust driving behaviours ofautonomous vehicles. Cameras and LiDARs are commonly used for semantic sceneunderstanding. However, both sensor modalities face limitations in adverseweather and usually do not provide motion information. Radar sensors overcomethese limitations and directly offer information about moving agents bymeasuring the Doppler velocity, but the measurements are comparably sparse andnoisy. In this paper, we address the problem of panoptic segmentation in sparseradar point clouds to enhance scene understanding. Our approach, calledSemRaFiner, accounts for changing density in sparse radar point clouds andoptimizes the feature extraction to improve accuracy. Furthermore, we proposean optimized training procedure to refine instance assignments by incorporatinga dedicated data augmentation. Our experiments suggest that our approachoutperforms state-of-the-art methods for radar-based panoptic segmentation.</description>
      <author>example@mail.com (Matthias Zeller, Daniel Casado Herraez, Bengisu Ayan, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2507.06906v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning at the Edge: The Cost of Labeling</title>
      <link>http://arxiv.org/abs/2507.07033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE MLSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在边缘设备上应用自监督学习（SSL）技术的可行性和效率，重点关注模型性能与能耗之间的权衡。&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）作为一种新的学习方法，可以从不结构化和未标记的数据中提取丰富的表示，但其通常需要大量的数据和计算资源，这在资源受限的边缘设备上是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;研究SSL技术在边缘学习中的可行性和效率，评估它们在资源受限环境下的学习鲁棒表示的有效性，并考虑数据标注的能源成本。&lt;h4&gt;方法&lt;/h4&gt;通过大量实验，分析不同SSL技术如何适应有限的计算、数据和能源预算，并评估半监督学习在减少训练CL模型整体能耗中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;定制化的SSL策略可以在降低资源消耗高达4倍的同时实现有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;SSL技术在边缘设备上具有节能学习的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has recently emerged as an alternative totraditional supervised machine learning solutions by enabling richrepresentations from unstructured and unlabeled data. However, CL and, morebroadly, self-supervised learning (SSL) methods often demand a large amount ofdata and computational resources, posing challenges for deployment onresource-constrained edge devices. In this work, we explore the feasibility andefficiency of SSL techniques for edge-based learning, focusing on trade-offsbetween model performance and energy efficiency. In particular, we analyze howdifferent SSL techniques adapt to limited computational, data, and energybudgets, evaluating their effectiveness in learning robust representationsunder resource-constrained settings. Moreover, we also consider the energycosts involved in labeling data and assess how semi-supervised learning mayassist in reducing the overall energy consumed to train CL models. Throughextensive experiments, we demonstrate that tailored SSL strategies can achievecompetitive performance while reducing resource consumption by up to 4X,underscoring their potential for energy-efficient learning at the edge.</description>
      <author>example@mail.com (Roberto Pereira, Fernanda Famá, Asal Rangrazi, Marco Miozzo, Charalampos Kalalas, Paolo Dini)</author>
      <guid isPermaLink="false">2507.07033v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Information Retrieval via Time-Specifier Model Merging</title>
      <link>http://arxiv.org/abs/2507.06782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSM的新方法，旨在提升时间信息检索（TIR）的性能，同时保持非时间查询的准确性。&lt;h4&gt;背景&lt;/h4&gt;随着数字信息和知识的快速增长，信息检索（IR）的重要性日益凸显。尽管密集检索方法在语义匹配方面取得了显著进步，但在具有明确时间约束的查询上表现不佳，尤其是在包含数字表达式和时间说明的查询上。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有时间信息检索方法在时间推理上的改进和灾难性遗忘问题，从而在非时间查询上降低性能的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了时间说明模型合并（TSM）方法，该方法为单个时间说明训练专门的检索器，并将它们合并到一个统一模型中，以精确处理时间约束，同时不影响非时间检索。&lt;h4&gt;主要发现&lt;/h4&gt;在时间和非时间数据集上进行的广泛实验表明，TSM在时间约束查询上的性能显著提高，同时在非时间查询上保持强大结果，并且始终优于其他基线方法。&lt;h4&gt;结论&lt;/h4&gt;TSM是一种有效的时间信息检索方法，能够在处理时间约束查询时保持高准确性，并且适用于非时间查询。&lt;h4&gt;翻译&lt;/h4&gt;The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints—often those containing numerical expressions and time specifiers such as 'in 2015.' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them into a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at https://github.com/seungyoonee/TSM.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of digital information and knowledge across structuredand unstructured sources has heightened the importance of Information Retrieval(IR). While dense retrieval methods have substantially improved semanticmatching for general queries, they consistently underperform on queries withexplicit temporal constraints--often those containing numerical expressions andtime specifiers such as ``in 2015.'' Existing approaches to TemporalInformation Retrieval (TIR) improve temporal reasoning but often suffer fromcatastrophic forgetting, leading to reduced performance on non-temporalqueries. To address this, we propose Time-Specifier Model Merging (TSM), anovel method that enhances temporal retrieval while preserving accuracy onnon-temporal queries. TSM trains specialized retrievers for individual timespecifiers and merges them in to a unified model, enabling precise handling oftemporal constraints without compromising non-temporal retrieval. Extensiveexperiments on both temporal and non-temporal datasets demonstrate that TSMsignificantly improves performance on temporally constrained queries whilemaintaining strong results on non-temporal queries, consistently outperformingother baseline methods. Our code is available athttps://github.com/seungyoonee/TSM .</description>
      <author>example@mail.com (SeungYoon Han, Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, Huije Lee, Jong C. Park)</author>
      <guid isPermaLink="false">2507.06782v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior</title>
      <link>http://arxiv.org/abs/2507.06651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Diff$^2$I2P是一种基于扩散模型的图像到点云注册框架，通过改进对应关系检索和PnP求解器的可微性，提高了跨模态对应关系的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的图像到点云注册方法主要利用度量学习来强制特征对齐，但忽略了图像和点云数据之间的固有模态差距，导致跨模态对应关系不准确。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来桥接图像和点云之间的模态差距，以实现更准确的跨模态对应关系。&lt;h4&gt;方法&lt;/h4&gt;Diff$^2$I2P利用了深度条件扩散模型，并引入了控制侧分数蒸馏（CSD）技术和可变形对应关系调整（DCT）模块来优化预测变换。&lt;h4&gt;主要发现&lt;/h4&gt;通过CSD技术和DCT模块，Diff$^2$I2P能够以可微的方式估计对应关系，并使用可微的PnP求解器进行变换估计，从而显著提高了注册的准确性。&lt;h4&gt;结论&lt;/h4&gt;Diff$^2$I2P在7-Scenes基准测试中，在注册召回率方面比现有方法提高了超过7%，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Learning cross-modal correspondences is essential for image-to-point cloud(I2P) registration. Existing methods achieve this mostly by utilizing metric learning to enforce feature alignment across modalities, disregarding the inherent modality gap between image and point data. Consequently, this paradigm struggles to ensure accurate cross-modal correspondences. To this end, inspired by the cross-modal generation success of recent large diffusion models, we propose Diff$^2$I2P, a fully Differentiable I2P registration framework, leveraging a novel and effective Diffusion prior for bridging the modality gap. Specifically, we propose a Control-Side Score Distillation (CSD) technique to distill knowledge from a depth-conditioned diffusion model to directly optimize the predicted transformation. However, the gradients on the transformation fail to backpropagate onto the cross-modal features due to the non-differentiability of correspondence retrieval and PnP solver. To this end, we further propose a Deformable Correspondence Tuning (DCT) module to estimate the correspondences in a differentiable way, followed by the transformation estimation using a differentiable PnP solver. With these two designs, the Diffusion model serves as a strong prior to guide the cross-modal feature learning of image and point cloud for forming robust correspondences, which significantly improves the registration. Extensive experimental results demonstrate that Diff$^2$I2P consistently outperforms SoTA I2P registration methods, achieving over 7% improvement in registration recall on the 7-Scenes benchmark.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning cross-modal correspondences is essential for image-to-point cloud(I2P) registration. Existing methods achieve this mostly by utilizing metriclearning to enforce feature alignment across modalities, disregarding theinherent modality gap between image and point data. Consequently, this paradigmstruggles to ensure accurate cross-modal correspondences. To this end, inspiredby the cross-modal generation success of recent large diffusion models, wepropose Diff$^2$I2P, a fully Differentiable I2P registration framework,leveraging a novel and effective Diffusion prior for bridging the modality gap.Specifically, we propose a Control-Side Score Distillation (CSD) technique todistill knowledge from a depth-conditioned diffusion model to directly optimizethe predicted transformation. However, the gradients on the transformation failto backpropagate onto the cross-modal features due to the non-differentiabilityof correspondence retrieval and PnP solver. To this end, we further propose aDeformable Correspondence Tuning (DCT) module to estimate the correspondencesin a differentiable way, followed by the transformation estimation using adifferentiable PnP solver. With these two designs, the Diffusion model servesas a strong prior to guide the cross-modal feature learning of image and pointcloud for forming robust correspondences, which significantly improves theregistration. Extensive experimental results demonstrate that Diff$^2$I2Pconsistently outperforms SoTA I2P registration methods, achieving over 7%improvement in registration recall on the 7-Scenes benchmark.</description>
      <author>example@mail.com (Juncheng Mu, Chengwei Ren, Weixiang Zhang, Liang Pan, Xiao-Ping Zhang, Yue Gao)</author>
      <guid isPermaLink="false">2507.06651v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement</title>
      <link>http://arxiv.org/abs/2507.06928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应部分发现和学习方法APL，用于在未标记图像中识别已知和新型类别，并通过比较相似图像生成一致的物体部分及其对应关系，同时不要求额外的标注。&lt;h4&gt;背景&lt;/h4&gt;现有的广义类别发现（GCD）方法依赖于自监督视觉Transformer，如DINO进行表示学习，但这种方法在可区分性和泛化性之间存在固有的权衡。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入APL方法，在不牺牲泛化性的前提下，提高对相似类别的可区分性，并促进知识迁移。&lt;h4&gt;方法&lt;/h4&gt;APL方法使用一组共享的可学习部分查询和DINO部分先验来生成不同相似图像的一致物体部分及其对应关系，并提出了一个新颖的all-min对比性损失函数来学习具有判别性和泛化性的部分表示。&lt;h4&gt;主要发现&lt;/h4&gt;APL方法可以容易地集成到不同的GCD框架中，通过替换其CLS标记特征为部分表示，在细粒度数据集上表现出显著的提升。&lt;h4&gt;结论&lt;/h4&gt;APL方法在提高GCD方法的可区分性和泛化性方面具有潜力，并且能够有效地应用于不同数据集。&lt;h4&gt;翻译&lt;/h4&gt;Generalized Category Discovery (GCD) aims to recognize unlabeled images from known and novel classes by distinguishing novel classes from known ones, while also transferring knowledge from another set of labeled images with known classes. Existing GCD methods rely on self-supervised vision transformers such as DINO for representation learning. However, focusing solely on the global representation of the DINO CLS token introduces an inherent trade-off between discriminability and generalization. In this paper, we introduce an adaptive part discovery and learning method, called APL, which generates consistent object parts and their correspondences across different similar images using a set of shared learnable part queries and DINO part priors, without requiring any additional annotations. More importantly, we propose a novel all-min contrastive loss to learn discriminative yet generalizable part representation, which adaptively highlights discriminative object parts to distinguish similar categories for enhanced discriminability while simultaneously sharing other parts to facilitate knowledge transfer for improved generalization. Our APL can easily be incorporated into different GCD frameworks by replacing their CLS token feature with our part representations, showing significant enhancements on fine-grained datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) aims to recognize unlabeled images fromknown and novel classes by distinguishing novel classes from known ones, whilealso transferring knowledge from another set of labeled images with knownclasses. Existing GCD methods rely on self-supervised vision transformers suchas DINO for representation learning. However, focusing solely on the globalrepresentation of the DINO CLS token introduces an inherent trade-off betweendiscriminability and generalization. In this paper, we introduce an adaptivepart discovery and learning method, called APL, which generates consistentobject parts and their correspondences across different similar images using aset of shared learnable part queries and DINO part priors, without requiringany additional annotations. More importantly, we propose a novel all-mincontrastive loss to learn discriminative yet generalizable part representation,which adaptively highlights discriminative object parts to distinguish similarcategories for enhanced discriminability while simultaneously sharing otherparts to facilitate knowledge transfer for improved generalization. Our APL caneasily be incorporated into different GCD frameworks by replacing their CLStoken feature with our part representations, showing significant enhancementson fine-grained datasets.</description>
      <author>example@mail.com (Qiyuan Dai, Hanzhuo Huang, Yu Wu, Sibei Yang)</author>
      <guid isPermaLink="false">2507.06928v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2507.06618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为视图相关投影（VDP）的方法，用于促进点云分割，并设计了一种高效的3D到2D映射，该映射能够动态适应来自视图变化的时空几何。&lt;h4&gt;背景&lt;/h4&gt;现有的基于投影的方法利用视图无关的投影在复杂场景中，依赖于直线生成直接射线或向上曲线以减少遮挡。然而，它们的视图无关性限制了投影射线，使其局限于人为设定的预定义参数，从而限制了点的感知能力，并且未能充分捕捉不同视图平面之间的投影多样性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，设计了一个VDP框架，从3D点分布生成数据驱动的投影，通过预测受烟花自适应行为启发的射线，生成高度信息化的单图像输入。&lt;h4&gt;方法&lt;/h4&gt;此外，构建了颜色正则化来优化框架，强调语义像素中的基本特征，抑制黑色像素中的非语义特征，从而在投影图像中最大化2D空间利用率。PointVDP方法通过边际计算成本实现了轻量级投影。&lt;h4&gt;主要发现&lt;/h4&gt;在S3DIS和ScanNet基准测试上的实验表明，该方法达到了具有竞争力的结果，提供了一种资源高效的语义理解解决方案。&lt;h4&gt;结论&lt;/h4&gt;PointVDP方法通过动态适应视图变化，提高了点云分割的效率和准确性，为语义理解提供了一种高效且资源节约的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose view-dependent projection (VDP) to facilitate pointcloud segmentation, designing efficient 3D-to-2D mapping that dynamicallyadapts to the spatial geometry from view variations. Existing projection-basedmethods leverage view-independent projection in complex scenes, relying onstraight lines to generate direct rays or upward curves to reduce occlusions.However, their view independence provides projection rays that are limited topre-defined parameters by human settings, restricting point awareness andfailing to capture sufficient projection diversity across different viewplanes. Although multiple projections per view plane are commonly used toenhance spatial variety, the projected redundancy leads to excessivecomputational overhead and inefficiency in image processing. To address theselimitations, we design a framework of VDP to generate data-driven projectionsfrom 3D point distributions, producing highly informative single-image inputsby predicting rays inspired by the adaptive behavior of fireworks. In addition,we construct color regularization to optimize the framework, which emphasizesessential features within semantic pixels and suppresses the non-semanticfeatures within black pixels, thereby maximizing 2D space utilization in aprojected image. As a result, our approach, PointVDP, develops lightweightprojections in marginal computation costs. Experiments on S3DIS and ScanNetbenchmarks show that our approach achieves competitive results, offering aresource-efficient solution for semantic understanding.</description>
      <author>example@mail.com (Yang Chen, Yueqi Duan, Haowen Sun, Ziwei Wang, Jiwen Lu, Yap-Peng Tan)</author>
      <guid isPermaLink="false">2507.06618v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning</title>
      <link>http://arxiv.org/abs/2507.07006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GNN-ViTCap的框架，用于从病理学显微镜图像中进行分类和生成描述性字幕，以提高癌症诊断和治疗中的病理图像评估准确性。&lt;h4&gt;背景&lt;/h4&gt;病理图像的微观评估对于癌症诊断和治疗至关重要。全切片图像（WSI）分类和字幕生成在计算机辅助病理学中变得至关重要，但显微镜WSI面临着如冗余切片和由于主观病理学家捕获导致的未知切片位置等挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的GNN-ViTCap框架，用于从病理学显微镜图像中进行分类和字幕生成。&lt;h4&gt;方法&lt;/h4&gt;首先，使用视觉特征提取器生成切片嵌入。然后，通过深度嵌入聚类动态地去除冗余切片，并通过标量点注意力机制选择代表性切片。通过将每个节点与其相似性矩阵中的最近邻连接来构建图，并应用图神经网络来捕捉局部和全局上下文。通过线性层将聚合的图像嵌入投影到语言模型的输入空间，并与字幕标记结合以微调大型语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;GNN-ViTCap在BreakHis和PatchGastric数据集上进行了验证，实现了0.934的F1分数和0.963的AUC（曲线下面积）的分类性能，以及0.811的BLEU-4分数和0.569的METEOR分数的字幕生成性能。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，GNN-ViTCap优于现有方法，为基于显微镜的患者诊断提供了一种可靠且高效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Microscopic assessment of histopathology images is vital for accurate cancer diagnosis and treatment. Whole Slide Image (WSI) classification and captioning have become crucial tasks in computer-aided pathology. However, microscopic WSI face challenges such as redundant patches and unknown patch positions due to subjective pathologist captures. Moreover, generating automatic pathology captions remains a significant challenge. To address these issues, we introduce a novel GNN-ViTCap framework for classification and caption generation from histopathological microscopic images. First, a visual feature extractor generates patch embeddings. Redundant patches are then removed by dynamically clustering these embeddings using deep embedded clustering and selecting representative patches via a scalar dot attention mechanism. We build a graph by connecting each node to its nearest neighbors in the similarity matrix and apply a graph neural network to capture both local and global context. The aggregated image embeddings are projected into the language model's input space through a linear layer and combined with caption tokens to fine-tune a large language model. We validate our method on the BreakHis and PatchGastric datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569 for captioning. Experimental results demonstrate that GNN-ViTCap outperforms state of the art approaches, offering a reliable and efficient solution for microscopy based patient diagnosis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Microscopic assessment of histopathology images is vital for accurate cancerdiagnosis and treatment. Whole Slide Image (WSI) classification and captioninghave become crucial tasks in computer-aided pathology. However, microscopic WSIface challenges such as redundant patches and unknown patch positions due tosubjective pathologist captures. Moreover, generating automatic pathologycaptions remains a significant challenge. To address these issues, we introducea novel GNN-ViTCap framework for classification and caption generation fromhistopathological microscopic images. First, a visual feature extractorgenerates patch embeddings. Redundant patches are then removed by dynamicallyclustering these embeddings using deep embedded clustering and selectingrepresentative patches via a scalar dot attention mechanism. We build a graphby connecting each node to its nearest neighbors in the similarity matrix andapply a graph neural network to capture both local and global context. Theaggregated image embeddings are projected into the language model's input spacethrough a linear layer and combined with caption tokens to fine-tune a largelanguage model. We validate our method on the BreakHis and PatchGastricdatasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 forclassification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569for captioning. Experimental results demonstrate that GNN-ViTCap outperformsstate of the art approaches, offering a reliable and efficient solution formicroscopy based patient diagnosis.</description>
      <author>example@mail.com (S M Taslim Uddin Raju, Md. Milon Islam, Md Rezwanul Haque, Hamdi Altaheri, Fakhri Karray)</author>
      <guid isPermaLink="false">2507.07006v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Token Bottleneck: One Token to Remember Dynamics</title>
      <link>http://arxiv.org/abs/2507.06543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 9 figures, 8 tables, project page:  https://token-bottleneck.github.io, code: https://github.com/naver-ai/tobo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Token Bottleneck（ToBo）的自监督学习方法，该方法能够从动态场景中提取紧凑且时间感知的视觉表示，用于场景理解任务，如视觉跟踪和机器人操作。&lt;h4&gt;背景&lt;/h4&gt;在执行视觉跟踪和机器人操作等序列场景理解任务时，从动态场景中提取紧凑且时间感知的视觉表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个简单直观的自监督学习流程，将场景压缩成一个瓶颈标记（bottleneck token），并使用最小化的补丁作为提示来预测后续场景。&lt;h4&gt;方法&lt;/h4&gt;ToBo流程通过在挤压步骤中保守地编码参考场景到紧凑的瓶颈标记来促进序列场景表示的学习。在扩展步骤中，指导模型通过使用瓶颈标记和少数目标补丁作为提示来预测目标场景，从而捕捉时间动态。&lt;h4&gt;主要发现&lt;/h4&gt;ToBo在视频标签传播和模拟环境中的机器人操作等多样化的序列任务中，表现优于基线方法。此外，将预训练模型部署到物理机器人上，证实了其在现实世界环境中的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;ToBo在多个模型规模上验证了其可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从动态场景中提取紧凑且时间感知的视觉表示对于执行如视觉跟踪和机器人操作等序列场景理解任务至关重要。在本文中，我们介绍了一种简单的、直观的自监督学习流程——Token Bottleneck（ToBo），该流程将场景压缩成瓶颈标记，并使用最小化的补丁作为提示来预测后续场景。ToBo流程通过在挤压步骤中保守地编码参考场景到紧凑的瓶颈标记来促进序列场景表示的学习。在扩展步骤中，通过使用瓶颈标记和少数目标补丁作为提示来预测目标场景，指导模型捕捉时间动态。在视频标签传播和模拟环境中的机器人操作等多样化的序列任务中，ToBo表现优于基线方法。将预训练模型部署到物理机器人上，证实了其在现实世界环境中的鲁棒性和有效性。进一步验证了ToBo在多个模型规模上的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deriving compact and temporally aware visual representations from dynamicscenes is essential for successful execution of sequential scene understandingtasks such as visual tracking and robotic manipulation. In this paper, weintroduce Token Bottleneck (ToBo), a simple yet intuitive self-supervisedlearning pipeline that squeezes a scene into a bottleneck token and predictsthe subsequent scene using minimal patches as hints. The ToBo pipelinefacilitates the learning of sequential scene representations by conservativelyencoding the reference scene into a compact bottleneck token during the squeezestep. In the expansion step, we guide the model to capture temporal dynamics bypredicting the target scene using the bottleneck token along with few targetpatches as hints. This design encourages the vision backbone to embed temporaldependencies, thereby enabling understanding of dynamic transitions acrossscenes. Extensive experiments in diverse sequential tasks, including videolabel propagation and robot manipulation in simulated environments demonstratethe superiority of ToBo over baselines. Moreover, deploying our pre-trainedmodel on physical robots confirms its robustness and effectiveness inreal-world environments. We further validate the scalability of ToBo acrossdifferent model scales.</description>
      <author>example@mail.com (Taekyung Kim, Dongyoon Han, Byeongho Heo, Jeongeun Park, Sangdoo Yun)</author>
      <guid isPermaLink="false">2507.06543v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.07011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 14 figures, 4 tables. To be submitted to a conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Deep Brain Net的深度学习系统，用于优化脑肿瘤的自动检测和分类性能，该系统结合了EfficientNetB0和ResNet50架构的优势，并采用迁移学习来提高泛化能力和减少训练时间。&lt;h4&gt;背景&lt;/h4&gt;深度学习在脑肿瘤的MRI图像自动检测和分类方面显示出巨大潜力，但实现高准确性和计算效率仍是一大挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够优化脑肿瘤检测性能的深度学习系统。&lt;h4&gt;方法&lt;/h4&gt;Deep Brain Net模型整合了EfficientNetB0和ResNet50架构，EfficientNetB0通过使用移动倒置瓶颈块提高了模型效率，ResNet50在ImageNet等大规模数据集上预训练后，用于脑肿瘤分类，并利用残差连接来避免性能退化。&lt;h4&gt;主要发现&lt;/h4&gt;Deep Brain Net在公开的MRI数据集上进行了广泛实验，结果显示其分类准确率、精确度、召回率和计算效率均优于现有方法，准确率达到88%，加权F1分数为88.75%，宏AUC ROC分数为98.17%，显示出系统的鲁棒性和临床潜力。&lt;h4&gt;结论&lt;/h4&gt;Deep Brain Net在脑肿瘤诊断方面具有显著的临床潜力，能够帮助放射科医生进行脑肿瘤的诊断。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, deep learning has shown great promise in the automateddetection and classification of brain tumors from MRI images. However,achieving high accuracy and computational efficiency remains a challenge. Inthis research, we propose Deep Brain Net, a novel deep learning system designedto optimize performance in the detection of brain tumors. The model integratesthe strengths of two advanced neural network architectures which areEfficientNetB0 and ResNet50, combined with transfer learning to improvegeneralization and reduce training time. The EfficientNetB0 architectureenhances model efficiency by utilizing mobile inverted bottleneck blocks, whichincorporate depth wise separable convolutions. This design significantlyreduces the number of parameters and computational cost while preserving theability of models to learn complex feature representations. The ResNet50architecture, pre trained on large scale datasets like ImageNet, is fine tunedfor brain tumor classification. Its use of residual connections allows fortraining deeper networks by mitigating the vanishing gradient problem andavoiding performance degradation. The integration of these components ensuresthat the proposed system is both computationally efficient and highly accurate.Extensive experiments performed on publicly available MRI datasets demonstratethat Deep Brain Net consistently outperforms existing state of the art methodsin terms of classification accuracy, precision, recall, and computationalefficiency. The result is an accuracy of 88 percent, a weighted F1 score of88.75 percent, and a macro AUC ROC score of 98.17 percent which demonstratesthe robustness and clinical potential of Deep Brain Net in assistingradiologists with brain tumor diagnosis.</description>
      <author>example@mail.com (Daniel Onah, Ravish Desai)</author>
      <guid isPermaLink="false">2507.07011v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study</title>
      <link>http://arxiv.org/abs/2507.06694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于异构图注意力网络的方法，用于解决现代电力系统中多物理域状态预测的挑战。&lt;h4&gt;背景&lt;/h4&gt;准确预测短期状态对于现代电力系统的稳定运行至关重要，尤其是在可再生能源和分布式能源资源带来的不确定性增加的背景下。&lt;h4&gt;目的&lt;/h4&gt;提高电力系统的短期状态预测准确性，支持控制决策，并实现传感器和机器行为的可解释性监控。&lt;h4&gt;方法&lt;/h4&gt;提出使用异构图注意力网络来建模来自两个不同物理域（液压和电气）的传感器数据之间的同域和跨域关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多域、多速率电力系统状态预测方面显著优于传统基线，平均性能提高了35.5%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在多物理域电力系统状态预测中是有效的，并具有提高预测准确性的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate short-term state forecasting is essential for efficient and stableoperation of modern power systems, especially in the context of increasingvariability introduced by renewable and distributed energy resources. As thesesystems evolve rapidly, it becomes increasingly important to reliably predicttheir states in the short term to ensure operational stability, support controldecisions, and enable interpretable monitoring of sensor and machine behavior.Modern power systems often span multiple physical domains - includingelectrical, mechanical, hydraulic, and thermal - posing significant challengesfor modeling and prediction. Graph Neural Networks (GNNs) have emerged as apromising data-driven framework for system state estimation and stateforecasting in such settings. By leveraging the topological structure of sensornetworks, GNNs can implicitly learn inter-sensor relationships and propagateinformation across the network. However, most existing GNN-based methods aredesigned under the assumption of homogeneous sensor relationships and aretypically constrained to a single physical domain. This limitation restrictstheir ability to integrate and reason over heterogeneous sensor data commonlyencountered in real-world energy systems, such as those used in energyconversion infrastructure. In this work, we propose the use of HeterogeneousGraph Attention Networks to address these limitations. Our approach models bothhomogeneous intra-domain and heterogeneous inter-domain relationships amongsensor data from two distinct physical domains - hydraulic and electrical -which exhibit fundamentally different temporal dynamics. Experimental resultsdemonstrate that our method significantly outperforms conventional baselines onaverage by 35.5% in terms of normalized root mean square error, confirming itseffectiveness in multi-domain, multi-rate power system state forecasting.</description>
      <author>example@mail.com (Raffael Theiler, Olga Fink)</author>
      <guid isPermaLink="false">2507.06694v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs</title>
      <link>http://arxiv.org/abs/2507.06549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of GLSVLSI2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的两阶段模型，用于在预布局阶段准确预测SRAM电路中的寄生效应，以提升系统能源效率。&lt;h4&gt;背景&lt;/h4&gt;在SoC中，为了提高系统能源效率，SRAM往往被定制化。寄生效应导致预布局和后布局电路仿真之间存在显著差异，给设计参数的收敛和设计迭代带来困难。&lt;h4&gt;目的&lt;/h4&gt;研究是否能够基于预布局电路准确预测寄生效应，以进行寄生感知的预布局仿真。&lt;h4&gt;方法&lt;/h4&gt;提出了一种结合图神经网络（GNN）分类器和多层感知器（MLP）回归器的两阶段模型，以有效地管理SRAM电路中网络寄生效应的类别不平衡。此外，采用Focal Loss来减轻大量内部网络样本的影响，并将子电路信息集成到图中以抽象原理图的层次结构。&lt;h4&gt;主要发现&lt;/h4&gt;在4个真实SRAM设计上的实验表明，该方法在寄生预测方面超越了最先进的模型，误差最大减少了19倍，并且显著提高了仿真过程，速度提升了高达598倍。&lt;h4&gt;结论&lt;/h4&gt;该模型能够有效地预测预布局阶段的寄生效应，显著提高了仿真效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To achieve higher system energy efficiency, SRAM in SoCs is often customized.The parasitic effects cause notable discrepancies between pre-layout andpost-layout circuit simulations, leading to difficulty in converging designparameters and excessive design iterations. Is it possible to well predict theparasitics based on the pre-layout circuit, so as to perform parasitic-awarepre-layout simulation? In this work, we propose a deep-learning-based 2-stagemodel to accurately predict these parasitics in pre-layout stages. The modelcombines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron(MLP) regressors, effectively managing class imbalance of the net parasitics inSRAM circuits. We also employ Focal Loss to mitigate the impact of abundantinternal net samples and integrate subcircuit information into the graph toabstract the hierarchical structure of schematics. Experiments on 4 real SRAMdesigns show that our approach not only surpasses the state-of-the-art model inparasitic prediction by a maximum of 19X reduction of error but alsosignificantly boosts the simulation process by up to 598X speedup.</description>
      <author>example@mail.com (Shan Shen, Dingcheng Yang, Yuyang Xie, Chunyan Pei, Wenjian Yu, Bei Yu)</author>
      <guid isPermaLink="false">2507.06549v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising</title>
      <link>http://arxiv.org/abs/2507.06976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在恶劣天气条件下基于激光雷达的集体感知，提出了一种新的多任务架构DenoiseCP-Net，以解决感知系统易受天气和环境遮挡影响的问题。&lt;h4&gt;背景&lt;/h4&gt;自动化车辆有减少交通事故的潜力，但其感知系统易受恶劣天气和环境遮挡的影响。&lt;h4&gt;目的&lt;/h4&gt;进行首次基于激光雷达的集体感知在多样化天气条件下的研究，并提出一种新的多任务架构。&lt;h4&gt;方法&lt;/h4&gt;提出DenoiseCP-Net，该架构将体素级噪声过滤和目标检测集成到统一的稀疏卷积骨干网络中，通过模拟雨、雪和雾等恶劣天气条件进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;DenoiseCP-Net在恶劣天气条件下实现了近乎完美的去噪精度，减少了带宽需求高达23.6%，同时保持了相同的检测精度，并降低了合作车辆的推理延迟。&lt;h4&gt;结论&lt;/h4&gt;DenoiseCP-Net能够有效提高恶劣天气条件下基于激光雷达的集体感知的性能，减少带宽需求和推理延迟。&lt;h4&gt;翻译&lt;/h4&gt;While automated vehicles hold the potential to significantly reduce traffic accidents, their perception systems remain vulnerable to sensor degradation caused by adverse weather and environmental occlusions. Collective perception, which enables vehicles to share information, offers a promising approach to overcoming these limitations. However, to this date collective perception in adverse weather is mostly unstudied. Therefore, we conduct the first study of LiDAR-based collective perception under diverse weather conditions and present a novel multi-task architecture for LiDAR-based collective perception under adverse weather. Adverse weather conditions can not only degrade perception capabilities, but also negatively affect bandwidth requirements and latency due to the introduced noise that is also transmitted and processed. Denoising prior to communication can effectively mitigate these issues. Therefore, we propose DenoiseCP-Net, a novel multi-task architecture for LiDAR-based collective perception under adverse weather conditions. DenoiseCP-Net integrates voxel-level noise filtering and object detection into a unified sparse convolution backbone, eliminating redundant computations associated with two-stage pipelines. This design not only reduces inference latency and computational cost but also minimizes communication overhead by removing non-informative noise. We extended the well-known OPV2V dataset by simulating rain, snow, and fog using our realistic weather simulation models. We demonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy in adverse weather, reduces the bandwidth requirements by up to 23.6% while maintaining the same detection accuracy and reducing the inference latency for cooperative vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While automated vehicles hold the potential to significantly reduce trafficaccidents, their perception systems remain vulnerable to sensor degradationcaused by adverse weather and environmental occlusions. Collective perception,which enables vehicles to share information, offers a promising approach toovercoming these limitations. However, to this date collective perception inadverse weather is mostly unstudied. Therefore, we conduct the first study ofLiDAR-based collective perception under diverse weather conditions and presenta novel multi-task architecture for LiDAR-based collective perception underadverse weather. Adverse weather conditions can not only degrade perceptioncapabilities, but also negatively affect bandwidth requirements and latency dueto the introduced noise that is also transmitted and processed. Denoising priorto communication can effectively mitigate these issues. Therefore, we proposeDenoiseCP-Net, a novel multi-task architecture for LiDAR-based collectiveperception under adverse weather conditions. DenoiseCP-Net integratesvoxel-level noise filtering and object detection into a unified sparseconvolution backbone, eliminating redundant computations associated withtwo-stage pipelines. This design not only reduces inference latency andcomputational cost but also minimizes communication overhead by removingnon-informative noise. We extended the well-known OPV2V dataset by simulatingrain, snow, and fog using our realistic weather simulation models. Wedemonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy inadverse weather, reduces the bandwidth requirements by up to 23.6% whilemaintaining the same detection accuracy and reducing the inference latency forcooperative vehicles.</description>
      <author>example@mail.com (Sven Teufel, Dominique Mayer, Jörg Gamerdinger, Oliver Bringmann)</author>
      <guid isPermaLink="false">2507.06976v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation</title>
      <link>http://arxiv.org/abs/2507.06992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MCA-RG的知识驱动框架，用于提升放射学报告生成（RRG）的准确性。&lt;h4&gt;背景&lt;/h4&gt;尽管在将大型语言模型（LLMs）应用于RRG方面取得了显著进展，但临床应用仍然面临挑战，主要由于病理和解剖特征难以准确映射到对应的文本描述，以及语义无关的特征提取进一步阻碍了准确诊断报告的生成。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，论文旨在提出一种能够提高RRG准确性的方法。&lt;h4&gt;方法&lt;/h4&gt;MCA-RG框架通过将视觉特征与不同的医学概念进行显式对齐，利用两个精心构建的概念库：一个包含与病变相关的知识库，另一个包含解剖描述的解剖学库。视觉特征与这些医学概念对齐并进行定制增强。此外，还提出了一种基于解剖的对比学习程序来提高解剖特征的泛化能力，结合病理特征的匹配损失以优先考虑临床相关区域。还采用了一种特征门控机制来过滤低质量的特征。最后，视觉特征与个体医学概念相对应，并用于指导报告生成过程。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-CXR和CheXpert Plus两个公开基准上的实验表明，MCA-RG实现了优越的性能，突显了其在RRG中的有效性。&lt;h4&gt;结论&lt;/h4&gt;MCA-RG框架能够显著提升放射学报告生成的准确性，是一种有潜力的临床应用工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite significant advancements in adapting Large Language Models (LLMs) forradiology report generation (RRG), clinical adoption remains challenging due todifficulties in accurately mapping pathological and anatomical features totheir corresponding text descriptions. Additionally, semantic agnostic featureextraction further hampers the generation of accurate diagnostic reports. Toaddress these challenges, we introduce Medical Concept Aligned Radiology ReportGeneration (MCA-RG), a knowledge-driven framework that explicitly aligns visualfeatures with distinct medical concepts to enhance the report generationprocess. MCA-RG utilizes two curated concept banks: a pathology bank containinglesion-related knowledge, and an anatomy bank with anatomical descriptions. Thevisual features are aligned with these medical concepts and undergo tailoredenhancement. We further propose an anatomy-based contrastive learning procedureto improve the generalization of anatomical features, coupled with a matchingloss for pathological features to prioritize clinically relevant regions.Additionally, a feature gating mechanism is employed to filter out low-qualityconcept features. Finally, the visual features are corresponding to individualmedical concepts, and are leveraged to guide the report generation process.Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstratethat MCA-RG achieves superior performance, highlighting its effectiveness inradiology report generation.</description>
      <author>example@mail.com (Qilong Xing, Zikai Song, Youjia Zhang, Na Feng, Junqing Yu, Wei Yang)</author>
      <guid isPermaLink="false">2507.06992v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand</title>
      <link>http://arxiv.org/abs/2507.06822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 2025 IEEE/RSJ International Conference on Intelligent  Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear  in IEEE Xplore&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于分层、目标条件强化学习（GCRL）框架来提高类人机器人手使用关节工具的操作能力。&lt;h4&gt;背景&lt;/h4&gt;以往的研究很少探索使用关节工具，如镊子或剪刀，这类工具动态改变形状，对灵巧机器人手提出了独特的挑战。&lt;h4&gt;目的&lt;/h4&gt;通过研究，旨在提升机器人使用关节工具进行操作的灵活性和效率。&lt;h4&gt;方法&lt;/h4&gt;提出了两层策略：底层策略使手能够根据不同大小的物体将工具操作到不同的配置；高层策略定义工具的目标状态并控制机械臂进行抓取任务。使用编码器从输入点云中估计工具的可用状态，并利用基于优先级信息的启发式策略生成重放缓冲区。&lt;h4&gt;主要发现&lt;/h4&gt;通过真实世界的实验验证，机器人能够以70.8%的成功率有效地使用类似镊子的工具抓取不同形状和大小的物体。&lt;h4&gt;结论&lt;/h4&gt;研究强调了强化学习在提升灵巧机器人关节工具操作能力方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Manipulating articulated tools, such as tweezers or scissors, has rarely been explored in previous research. Unlike rigid tools, articulated tools change their shape dynamically, creating unique challenges for dexterous robotic hands. In this work, we present a hierarchical, goal-conditioned reinforcement learning (GCRL) framework to improve the manipulation capabilities of anthropomorphic robotic hands using articulated tools. Our framework comprises two policy layers: (1) a low-level policy that enables the dexterous hand to manipulate the tool into various configurations for objects of different sizes, and (2) a high-level policy that defines the tool's goal state and controls the robotic arm for object-picking tasks. We employ an encoder, trained on synthetic point clouds, to estimate the tool's affordance states--specifically, how different tool configurations (e.g., tweezer opening angles) enable grasping of objects of varying sizes--from input point clouds, thereby enabling precise tool manipulation. We also utilize a privilege-informed heuristic policy to generate replay buffer, improving the training efficiency of the high-level policy. We validate our approach through real-world experiments, showing that the robot can effectively manipulate a tweezer-like tool to grasp objects of diverse shapes and sizes with a 70.8% success rate. This study highlights the potential of RL to advance dexterous robotic manipulation of articulated tools.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manipulating articulated tools, such as tweezers or scissors, has rarely beenexplored in previous research. Unlike rigid tools, articulated tools changetheir shape dynamically, creating unique challenges for dexterous robotichands. In this work, we present a hierarchical, goal-conditioned reinforcementlearning (GCRL) framework to improve the manipulation capabilities ofanthropomorphic robotic hands using articulated tools. Our framework comprisestwo policy layers: (1) a low-level policy that enables the dexterous hand tomanipulate the tool into various configurations for objects of different sizes,and (2) a high-level policy that defines the tool's goal state and controls therobotic arm for object-picking tasks. We employ an encoder, trained onsynthetic pointclouds, to estimate the tool's affordance states--specifically,how different tool configurations (e.g., tweezer opening angles) enablegrasping of objects of varying sizes--from input point clouds, thereby enablingprecise tool manipulation. We also utilize a privilege-informed heuristicpolicy to generate replay buffer, improving the training efficiency of thehigh-level policy. We validate our approach through real-world experiments,showing that the robot can effectively manipulate a tweezer-like tool to graspobjects of diverse shapes and sizes with a 70.8 % success rate. This studyhighlights the potential of RL to advance dexterous robotic manipulation ofarticulated tools.</description>
      <author>example@mail.com (Wei Xu, Yanchao Zhao, Weichao Guo, Xinjun Sheng)</author>
      <guid isPermaLink="false">2507.06822v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report</title>
      <link>http://arxiv.org/abs/2507.06968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种系统性的指令数据构建框架，用于提高大规模预训练模型在复杂任务上的性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;尽管当前指令数据集已达到数百万个样本，但模型在复杂指令遵循和罕见领域的任务上仍可能存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决指令集在“覆盖”（任务类型和知识领域覆盖）和“深度”（指令复杂性）方面的局限性，构建高质量的指令数据集。&lt;h4&gt;方法&lt;/h4&gt;提出的框架包括分层标签系统、信息种子选择算法、进化数据合成过程以及带有针对性数据生成的模型缺陷诊断。&lt;h4&gt;主要发现&lt;/h4&gt;基于该框架构建的InfinityInstruct-Subject数据集包含约150万条指令，实验表明其在提高指令遵循能力方面有效。&lt;h4&gt;结论&lt;/h4&gt;InfinityInstruct-Subject相较于其他合成指令数据集，具有更广泛的覆盖面和深度，为指令数据集的有效和持续进化提供了理论和实践基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要：指令调整已成为解锁大规模预训练模型能力并提高其在复杂任务上性能的基础。因此，构建高质量的指令数据集对于增强模型性能和泛化能力至关重要。尽管当前指令数据集已达到数百万个样本，但在此之上微调的模型在复杂指令遵循和罕见领域的任务上仍可能遇到困难。这主要是由于指令集在“覆盖”（任务类型和知识领域覆盖）和“深度”（指令复杂性）方面的扩展有限。为了解决这一问题，我们提出了一种系统性的指令数据构建框架，该框架集成了分层标签系统、信息种子选择算法、进化数据合成过程以及带有针对性数据生成的模型缺陷诊断。这些组件形成一个迭代闭环，以持续增强指令数据的覆盖面和深度。基于此框架，我们构建了InfinityInstruct-Subject数据集，这是一个包含约150万条指令的高质量数据集。在多个基础模型和基准任务上的实验表明，它在提高指令遵循能力方面是有效的。进一步的分析表明，与可比的合成指令数据集相比，InfinityInstruct-Subject具有更广泛的覆盖面和深度。我们的工作为指令数据集的有效、持续进化奠定了理论和实践基础，从数据数量扩展转向质量提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Instruction tuning has become a foundation for unlocking the capabilities oflarge-scale pretrained models and improving their performance on complex tasks.Thus, the construction of high-quality instruction datasets is crucial forenhancing model performance and generalizability. Although current instructiondatasets have reached tens of millions of samples, models finetuned on them maystill struggle with complex instruction following and tasks in rare domains.This is primarily due to limited expansion in both ``coverage'' (coverage oftask types and knowledge areas) and ``depth'' (instruction complexity) of theinstruction set. To address this issue, we propose a systematic instructiondata construction framework, which integrates a hierarchical labeling system,an informative seed selection algorithm, an evolutionary data synthesisprocess, and a model deficiency diagnosis with targeted data generation. Thesecomponents form an iterative closed-loop to continuously enhance the coverageand depth of instruction data. Based on this framework, we constructInfinityInstruct-Subject, a high-quality dataset containing ~1.5 millioninstructions. Experiments on multiple foundation models and benchmark tasksdemonstrate its effectiveness in improving instruction-following capabilities.Further analyses suggest that InfinityInstruct-Subject shows enlarged coverageand depth compared to comparable synthesized instruction datasets. Our worklays a theoretical and practical foundation for the efficient, continuousevolution of instruction datasets, moving from data quantity expansion toqualitative improvement.</description>
      <author>example@mail.com (Li Du, Hanyu Zhao, Yiming Ju, Tengfei Pan)</author>
      <guid isPermaLink="false">2507.06968v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This article has been accepted for publication in IEEE Transactions  on Multimedia. arXiv admin note: text overlap with arXiv:2502.04111&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对点云3D语义分割的自适应边缘对比学习方法。&lt;h4&gt;背景&lt;/h4&gt;现有方法使用等惩罚目标，忽略了来自过渡区域的每点模糊性和区分度较低的特征。&lt;h4&gt;目的&lt;/h4&gt;解决高度模糊的点可能对人类都难以区分，其手动标注标签可靠性低，对这类点的硬约束会导致次优模型的问题。&lt;h4&gt;方法&lt;/h4&gt;首先设计了AMContrast3D方法，将对比学习融入模糊度估计框架，根据模糊度水平对每个点进行自适应目标调整。此外，提出了AMContrast3D++，通过两个并行训练的分支，引入了一个新颖的模糊度预测模块，同时从生成的嵌入中学习点模糊度。还设计了一个掩码细化机制，利用预测的模糊度使模糊嵌入更加可靠，从而提高分割性能和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在3D室内场景数据集S3DIS和ScanNet上有效。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高3D语义分割的性能和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种自适应边缘对比学习方法，用于点云的3D语义分割。针对现有方法中忽略每点模糊性和过渡区域低区分度特征的问题，本文首先设计了AMContrast3D方法，将对比学习融入模糊度估计框架，根据模糊度水平对每个点进行自适应目标调整。进一步，提出了AMContrast3D++，通过并行训练的两个分支和一个新颖的模糊度预测模块，同时从生成的嵌入中学习点模糊度。此外，还设计了一个掩码细化机制，利用预测的模糊度使模糊嵌入更加可靠，从而提高分割性能和鲁棒性。在3D室内场景数据集S3DIS和ScanNet上的实验结果表明，该方法能够有效提高3D语义分割的性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an adaptive margin contrastive learning method for 3Dsemantic segmentation on point clouds. Most existing methods use equallypenalized objectives, which ignore the per-point ambiguities and lessdiscriminated features stemming from transition regions. However, as highlyambiguous points may be indistinguishable even for humans, their manuallyannotated labels are less reliable, and hard constraints over these pointswould lead to sub-optimal models. To address this, we first designAMContrast3D, a method comprising contrastive learning into an ambiguityestimation framework, tailored to adaptive objectives for individual pointsbased on ambiguity levels. As a result, our method promotes model training,which ensures the correctness of low-ambiguity points while allowing mistakesfor high-ambiguity points. As ambiguities are formulated based on positiondiscrepancies across labels, optimization during inference is constrained bythe assumption that all unlabeled points are uniformly unambiguous, lackingambiguity awareness. Inspired by the insight of joint training, we furtherpropose AMContrast3D++ integrating with two branches trained in parallel, wherea novel ambiguity prediction module concurrently learns point ambiguities fromgenerated embeddings. To this end, we design a masked refinement mechanism thatleverages predicted ambiguities to enable the ambiguous embeddings to be morereliable, thereby boosting segmentation performance and enhancing robustness.Experimental results on 3D indoor scene datasets, S3DIS and ScanNet,demonstrate the effectiveness of the proposed method. Code is available athttps://github.com/YangChenApril/AMContrast3D.</description>
      <author>example@mail.com (Yang Chen, Yueqi Duan, Haowen Sun, Jiwen Lu, Yap-Peng Tan)</author>
      <guid isPermaLink="false">2507.06592v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction</title>
      <link>http://arxiv.org/abs/2507.06806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GreenHyperSpectra，一个包含真实世界跨传感器和跨生态系统样本的预训练数据集，用于基准测试植物性状预测的半监督和自监督方法。&lt;h4&gt;背景&lt;/h4&gt;植物性状（如叶片碳含量和叶片质量）是生物多样性和气候变化研究中的关键变量，但传统现场采样难以在生态意义上合理的空间尺度上覆盖性状变异。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的植物性状预测方法，利用遥感高光谱数据，解决标签稀缺和领域变化（如跨传感器、生态分布）带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;GreenHyperSpectra旨在为性状预测提供一个基准，采用包括分布内和分布外场景的评估框架，并使用多输出回归模型进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;GreenHyperSpectra在预训练标签高效的多输出回归模型方面取得了成功，这些模型优于现有的监督基线，并在学习光谱表示方面取得了显著改进。&lt;h4&gt;结论&lt;/h4&gt;GreenHyperSpectra为跨领域植物性状评估提供了方法论框架，促进了表征学习和植物功能性状评估领域的交叉研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物性状，如叶片碳含量和叶片质量，是生物多样性和气候变化研究中不可或缺的变量。然而，传统的现场采样难以在生态上有意义的尺度上覆盖性状变异。机器学习为跨越生态系统的植物性状预测提供了一种有价值的解决方案，它利用遥感高光谱数据。然而，从高光谱数据中预测性状受到标签稀缺和大量领域变化（例如，跨传感器、生态分布）的挑战，需要稳健的跨领域方法。在此，我们提出了GreenHyperSpectra，一个包含现实世界跨传感器和跨生态系统样本的预训练数据集，旨在用半监督和自监督方法进行性状预测基准测试。我们采用了一个包含分布内和分布外场景的评估框架。我们成功地利用GreenHyperSpectra预训练了标签高效的多元回归模型，这些模型优于最先进的监督基线。我们的实证分析表明，在性状预测方面学习光谱表示有了显著改进，建立了一个全面的方法论框架，以促进表征学习和植物功能性状评估交叉领域的研究。所有代码和数据可在以下网址找到：https://github.com/echerif18/HyspectraSSL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Plant traits such as leaf carbon content and leaf mass are essentialvariables in the study of biodiversity and climate change. However,conventional field sampling cannot feasibly cover trait variation atecologically meaningful spatial scales. Machine learning represents a valuablesolution for plant trait prediction across ecosystems, leveraging hyperspectraldata from remote sensing. Nevertheless, trait prediction from hyperspectraldata is challenged by label scarcity and substantial domain shifts (\eg acrosssensors, ecological distributions), requiring robust cross-domain methods.Here, we present GreenHyperSpectra, a pretraining dataset encompassingreal-world cross-sensor and cross-ecosystem samples designed to benchmark traitprediction with semi- and self-supervised methods. We adopt an evaluationframework encompassing in-distribution and out-of-distribution scenarios. Wesuccessfully leverage GreenHyperSpectra to pretrain label-efficientmulti-output regression models that outperform the state-of-the-art supervisedbaseline. Our empirical analyses demonstrate substantial improvements inlearning spectral representations for trait prediction, establishing acomprehensive methodological framework to catalyze research at the intersectionof representation learning and plant functional traits assessment. All code anddata are available at: https://github.com/echerif18/HyspectraSSL.</description>
      <author>example@mail.com (Eya Cherif, Arthur Ouaknine, Luke A. Brown, Phuong D. Dao, Kyle R. Kovach, Bing Lu, Daniel Mederer, Hannes Feilhauer, Teja Kattenborn, David Rolnick)</author>
      <guid isPermaLink="false">2507.06806v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Omni-Video: Democratizing Unified Video Understanding and Generation</title>
      <link>http://arxiv.org/abs/2507.06119v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report, project page:  https://howellyoung-s.github.io/OmniVideo_project/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Omni-Video的统一视频理解和生成框架，旨在弥合当前视频理解和生成模型发展的差距。&lt;h4&gt;背景&lt;/h4&gt;当前基础模型主要关注图像处理，而视频理解和生成模型的统一发展存在不足。&lt;h4&gt;目的&lt;/h4&gt;提出Omni-Video框架，实现视频理解、生成以及基于指令的编辑。&lt;h4&gt;方法&lt;/h4&gt;1) 设计轻量级架构，在MLLMs顶部添加视觉头，在扩散解码器输入前添加适配器，前者生成视觉标记供后者使用，后者将这些标记适配到扩散解码器的条件空间；2) 采用高效的分阶段训练方案，在有限的数据和计算资源下，促进MLLMs和扩散解码器之间的快速连接。&lt;h4&gt;主要发现&lt;/h4&gt;模型在视频生成、编辑和理解任务上表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Omni-Video框架为统一视频建模提供了有效的方法，并展示了其在视频理解和生成方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Notable breakthroughs in unified understanding and generation modeling haveled to remarkable advancements in image understanding, reasoning, productionand editing, yet current foundational models predominantly focus on processingimages, creating a gap in the development of unified models for videounderstanding and generation. This report presents Omni-Video, an efficient andeffective unified framework for video understanding, generation, as well asinstruction-based editing. Our key insight is to teach existing multimodallarge language models (MLLMs) to produce continuous visual clues that are usedas the input of diffusion decoders, which produce high-quality videosconditioned on these visual clues. To fully unlock the potential of our systemfor unified video modeling, we integrate several technical improvements: 1) alightweight architectural design that respectively attaches a vision head onthe top of MLLMs and a adapter before the input of diffusion decoders, theformer produce visual tokens for the latter, which adapts these visual tokensto the conditional space of diffusion decoders; and 2) an efficient multi-stagetraining scheme that facilitates a fast connection between MLLMs and diffusiondecoders with limited data and computational resources. We empiricallydemonstrate that our model exhibits satisfactory generalization abilitiesacross video generation, editing and understanding tasks.</description>
      <author>example@mail.com (Zhiyu Tan, Hao Yang, Luozheng Qin, Jia Gong, Mengping Yang, Hao Li)</author>
      <guid isPermaLink="false">2507.06119v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies</title>
      <link>http://arxiv.org/abs/2507.06513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,  35 tasks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文系统性地对基于视觉的传感器和计算机视觉算法在交通场景分析中的应用进行了综述，并对相关任务和数据进行分类和分析。&lt;h4&gt;背景&lt;/h4&gt;随着视觉传感器和计算机视觉算法的进步，交通场景的分析和理解得到了显著提高。&lt;h4&gt;目的&lt;/h4&gt;为了促进这些改进在道路安全中的应用，本文系统地分类了交通场景中需要关注的要素，并全面分析了现有的视觉驱动任务和数据集。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个分类法，将值得关注的交通实体分为异常实体和正常但关键的实体两大类，并整合了十个类别和二十个子类别。通过建立的关联性，提供了一个统一的分析框架。&lt;h4&gt;主要发现&lt;/h4&gt;本文强调了35个视觉驱动任务的分析，并对基于所提出的分类法的73个数据集进行了全面考察和可视化。跨领域研究涵盖了每个基准的优缺点，旨在提供关于标准统一和资源优化的信息。&lt;h4&gt;结论&lt;/h4&gt;本文系统地讨论了现有的弱点，从不同角度强调了潜在的影响和有希望的解决方案。综合分类法、全面分析和总结表格为这一快速发展的领域提供了宝贵的贡献，为研究人员提供了全面的概述，指导战略资源选择，并突出了关键的研究空白。&lt;h4&gt;翻译&lt;/h4&gt;The paper systematically reviews the application of vision-based sensors and computer vision algorithms in traffic scene analysis and comprehensively classifies and analyzes relevant tasks and datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in vision-based sensors and computer vision algorithms havesignificantly improved the analysis and understanding of traffic scenarios. Tofacilitate the use of these improvements for road safety, this surveysystematically categorizes the critical elements that demand attention intraffic scenarios and comprehensively analyzes available vision-driven tasksand datasets. Compared to existing surveys that focus on isolated domains, ourtaxonomy categorizes attention-worthy traffic entities into two main groupsthat are anomalies and normal but critical entities, integrating ten categoriesand twenty subclasses. It establishes connections between inherently relatedfields and provides a unified analytical framework. Our survey highlights theanalysis of 35 vision-driven tasks and comprehensive examinations andvisualizations of 73 available datasets based on the proposed taxonomy. Thecross-domain investigation covers the pros and cons of each benchmark with theaim of providing information on standards unification and resourceoptimization. Our article concludes with a systematic discussion of theexisting weaknesses, underlining the potential effects and promising solutionsfrom various perspectives. The integrated taxonomy, comprehensive analysis, andrecapitulatory tables serve as valuable contributions to this rapidly evolvingfield by providing researchers with a holistic overview, guiding strategicresource selection, and highlighting critical research gaps.</description>
      <author>example@mail.com (Yaoqi Huang, Julie Stephany Berrio, Mao Shan, Stewart Worrall)</author>
      <guid isPermaLink="false">2507.06513v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Principled Framework for Multi-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对对比学习（CL）中多视图增强方法存在的问题，提出了两种新的损失函数，以提升多视图对比学习的效果。&lt;h4&gt;背景&lt;/h4&gt;对比学习是一种自监督学习方法，通常依赖于通过增强生成的数据视图对。然而，当前方法在处理多个视图时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;解决当前对比学习方法在处理多个视图时的四个关键局限性：多个优化项导致冲突目标、未能建模所有视图和数据点之间的交互、继承了成对对比损失的局限性、未能充分利用视图多样性的优势。&lt;h4&gt;方法&lt;/h4&gt;提出了MV-InfoNCE和MV-DHEL两种新的损失函数。MV-InfoNCE通过一个数据点的一个项同时包含所有可能的视图交互；MV-DHEL解耦了视图间的对齐和均匀性，并随着视图数量的增加而扩展交互复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，这两种方法在ImageNet1K和其他三个数据集上优于现有的多视图方法，并且随着视图数量的增加而有效扩展。此外，它们可以应用于多模态数据，并且可以扩展到超过两种模态。消融研究表明，MV-DHEL在五个或更多视图中有效缓解了维度塌陷，充分利用了嵌入空间，从而实现了在监督学习中观察到的多视图优势。&lt;h4&gt;结论&lt;/h4&gt;本文提出的MV-InfoNCE和MV-DHEL损失函数为多视图对比学习提供了理论上的扩展，并通过实验验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning(SSL), typically relies on pairs of data views generated through augmentation.While multiple augmentations per instance (more than two) improvegeneralization in supervised learning, current CL methods handle additionalviews suboptimally by simply aggregating different pairwise objectives. Thisapproach suffers from four critical limitations: (L1) it utilizes multipleoptimization terms per data point resulting to conflicting objectives, (L2) itfails to model all interactions across views and data points, (L3) it inheritsfundamental limitations (e.g. alignment-uniformity coupling) from pairwise CLlosses, and (L4) it prevents fully realizing the benefits of increased viewmultiplicity observed in supervised settings. We address these limitationsthrough two novel loss functions: MV-InfoNCE, which extends InfoNCE toincorporate all possible view interactions simultaneously in one term per datapoint, and MV-DHEL, which decouples alignment from uniformity across viewswhile scaling interaction complexity with view multiplicity. Both approachesare theoretically grounded - we prove they asymptotically optimize foralignment of all views and uniformity, providing principled extensions tomulti-view contrastive learning. Our empirical results on ImageNet1K and threeother datasets demonstrate that our methods consistently outperform existingmulti-view approaches and effectively scale with increasing view multiplicity.We also apply our objectives to multimodal data and show that, in contrast toother contrastive objectives, they can scale beyond just two modalities. Mostsignificantly, ablation studies reveal that MV-DHEL with five or more viewseffectively mitigates dimensionality collapse by fully utilizing the embeddingspace, thereby delivering multi-view benefits observed in supervised learning.</description>
      <author>example@mail.com (Panagiotis Koromilas, Efthymios Georgiou, Giorgos Bouritsas, Theodoros Giannakopoulos, Mihalis A. Nicolaou, Yannis Panagakis)</author>
      <guid isPermaLink="false">2507.06979v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers</title>
      <link>http://arxiv.org/abs/2507.06764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为快速等变成像（Fast Equivariant Imaging，FEI）的新型无监督学习框架，用于高效训练深度成像网络，无需地面实况数据。&lt;h4&gt;背景&lt;/h4&gt;传统等变成像（Equivariant Imaging）需要大量地面实况数据来训练，而FEI通过改进优化方法和利用可插入的降噪器来提高效率。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无监督学习框架，用于训练深度成像网络，减少对地面实况数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;通过拉格朗日乘数法重新表述等变成像的优化问题，并利用即插即用的降噪器来提高训练效率。&lt;h4&gt;主要发现&lt;/h4&gt;PnP-FEI方案在CT100数据集上训练U-Net进行X射线CT重建时，比标准EI快一个数量级（10倍），同时提高了泛化性能。&lt;h4&gt;结论&lt;/h4&gt;FEI框架在效率性能上优于传统的等变成像方法，特别是在X射线CT重建任务中表现出显著的加速和改进的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning framework to efficiently train deep imaging networks without ground-truth data. From the perspective of reformulating the Equivariant Imaging based optimization problem via the method of Lagrange multipliers and utilizing plug-and-play denoisers, this novel unsupervised scheme shows superior efficiency and performance compared to vanilla Equivariant Imaging paradigm. In particular, our PnP-FEI scheme achieves an order-of-magnitude (10x) acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT reconstruction, with improved generalization performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Fast Equivariant Imaging (FEI), a novel unsupervised learningframework to efficiently train deep imaging networks without ground-truth data.From the perspective of reformulating the Equivariant Imaging basedoptimization problem via the method of Lagrange multipliers and utilizingplug-and-play denoisers, this novel unsupervised scheme shows superiorefficiency and performance compared to vanilla Equivariant Imaging paradigm. Inparticular, our PnP-FEI scheme achieves an order-of-magnitude (10x)acceleration over standard EI on training U-Net with CT100 dataset for X-ray CTreconstruction, with improved generalization performance.</description>
      <author>example@mail.com (Guixian Xu, Jinglai Li, Junqi Tang)</author>
      <guid isPermaLink="false">2507.06764v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN</title>
      <link>http://arxiv.org/abs/2507.06895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SCoRE是一种模块化和成本效益高的句子级关系抽取系统，能够与预训练的大型语言模型无缝集成，适用于低监督环境下的知识图谱丰富化。&lt;h4&gt;背景&lt;/h4&gt;随着利用外部语料库高效丰富知识图谱的需求增长，关系抽取（RE）技术，尤其是在低监督设置下的关系抽取技术，受到了越来越多的关注。&lt;h4&gt;目的&lt;/h4&gt;为了解决需要适应性强且对噪声鲁棒的关系抽取解决方案，以及这些解决方案能够与预训练的大型语言模型（PLMs）无缝集成的需求，研究者们开发了SCoRE系统。&lt;h4&gt;方法&lt;/h4&gt;SCoRE结合了监督对比学习和贝叶斯k-近邻（kNN）分类器进行多标签分类，并通过提出两个新的评价指标——相关性结构距离（CSD）和精确率在R（P@R）来提高关系抽取的评价。同时，研究者们发布了Wiki20d数据集，用于复现只有知识图谱（KG）派生注释的真实世界关系抽取条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，SCoRE在五个基准数据集上的表现与现有最佳方法相当或更好，同时显著降低了能耗。进一步的分析显示，模型复杂性的增加会降低性能，突出了SCoRE最小化设计的优势。&lt;h4&gt;结论&lt;/h4&gt;SCoRE通过结合效率、模块化和可扩展性，成为现实世界关系抽取应用的理想选择。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着对利用外部语料库高效丰富知识图谱需求的增长，对关系抽取（RE）技术，尤其是在低监督设置下的关系抽取技术，兴趣日益浓厚。为了解决对适应性强且对噪声鲁棒的关系抽取解决方案的需求，以及这些解决方案能够与预训练的大型语言模型（PLMs）无缝集成的需求，我们引入了SCoRE，一个模块化和成本效益高的句子级RE系统。SCoRE能够轻松切换PLM，无需微调，并能平滑地适应不同的语料库和知识图谱。通过结合监督对比学习与贝叶斯k-近邻（kNN）分类器进行多标签分类，即使在远离监督语料库的噪声注释下，它也能提供稳健的性能。为了提高RE评估，我们提出了两个新颖的指标：相关性结构距离（CSD），衡量学习到的关系模式和知识图谱结构之间的对齐；精确率在R（P@R），评估作为推荐系统的效用。我们还发布了Wiki20d，这是一个复现真实世界RE条件（其中只有KG派生的注释可用）的基准数据集。在五个基准数据集上的实验表明，SCoRE的表现与现有最佳方法相当或更好，同时显著降低了能耗。进一步的分析显示，与先前工作所见，模型复杂性的增加会降低性能，突出了SCoRE最小化设计的优势。结合效率、模块化和可扩展性，SCoRE是现实世界RE应用的理想选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing demand for efficient knowledge graph (KG) enrichment leveragingexternal corpora has intensified interest in relation extraction (RE),particularly under low-supervision settings. To address the need for adaptableand noise-resilient RE solutions that integrate seamlessly with pre-trainedlarge language models (PLMs), we introduce SCoRE, a modular and cost-effectivesentence-level RE system. SCoRE enables easy PLM switching, requires nofinetuning, and adapts smoothly to diverse corpora and KGs. By combiningsupervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)classifier for multi-label classification, it delivers robust performancedespite the noisy annotations of distantly supervised corpora. To improve REevaluation, we propose two novel metrics: Correlation Structure Distance (CSD),measuring the alignment between learned relational patterns and KG structures,and Precision at R (P@R), assessing utility as a recommender system. We alsorelease Wiki20d, a benchmark dataset replicating real-world RE conditions whereonly KG-derived annotations are available. Experiments on five benchmarks showthat SCoRE matches or surpasses state-of-the-art methods while significantlyreducing energy consumption. Further analyses reveal that increasing modelcomplexity, as seen in prior work, degrades performance, highlighting theadvantages of SCoRE's minimal design. Combining efficiency, modularity, andscalability, SCoRE stands as an optimal choice for real-world RE applications.</description>
      <author>example@mail.com (Luca Mariotti, Veronica Guidetti, Federica Mandreoli)</author>
      <guid isPermaLink="false">2507.06895v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2507.06469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为MimbFD的图表示学习方法，用于缓解欺诈检测中的消息不平衡问题，并通过实验证明了其在欺诈检测中的优越性能。&lt;h4&gt;背景&lt;/h4&gt;图表示学习在欺诈检测中得到了广泛应用，但其对局部交互的过度关注导致了全局拓扑信息的不平衡传递和节点特定信息被淹没的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来减轻欺诈检测中的消息不平衡问题，以改善图神经网络在欺诈检测中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文首先总结了拓扑和类别不平衡对基于GNN的欺诈检测任务的影响，然后提出了MimbFD方法，包括拓扑消息可达性模块和局部混淆去偏置模块。&lt;h4&gt;主要发现&lt;/h4&gt;MimbFD通过设计拓扑消息可达性模块来提高节点表示学习质量，并通过局部混淆去偏置模块调整节点表示，平衡不同类别的影响。&lt;h4&gt;结论&lt;/h4&gt;在三个公开的欺诈数据集上进行的实验表明，MimbFD在欺诈检测中表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning has become a mainstream method for frauddetection due to its strong expressive power, which focuses on enhancing noderepresentations through improved neighborhood knowledge capture. However, thefocus on local interactions leads to imbalanced transmission of globaltopological information and increased risk of node-specific information beingoverwhelmed during aggregation due to the imbalance between fraud and benignnodes. In this paper, we first summarize the impact of topology and classimbalance on downstream tasks in GNN-based fraud detection, as the problem ofimbalanced supervisory messages is caused by fraudsters' topological behaviorobfuscation and identity feature concealment. Based on statistical validation,we propose a novel dual-view graph representation learning method to mitigateMessage imbalance in Fraud Detection(MimbFD). Specifically, we design atopological message reachability module for high-quality node representationlearning to penetrate fraudsters' camouflage and alleviate insufficientpropagation. Then, we introduce a local confounding debiasing module to adjustnode representations, enhancing the stable association between noderepresentations and labels to balance the influence of different classes.Finally, we conducted experiments on three public fraud datasets, and theresults demonstrate that MimbFD exhibits outstanding performance in frauddetection.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning has become a mainstream method for frauddetection due to its strong expressive power, which focuses on enhancing noderepresentations through improved neighborhood knowledge capture. However, thefocus on local interactions leads to imbalanced transmission of globaltopological information and increased risk of node-specific information beingoverwhelmed during aggregation due to the imbalance between fraud and benignnodes. In this paper, we first summarize the impact of topology and classimbalance on downstream tasks in GNN-based fraud detection, as the problem ofimbalanced supervisory messages is caused by fraudsters' topological behaviorobfuscation and identity feature concealment. Based on statistical validation,we propose a novel dual-view graph representation learning method to mitigateMessage imbalance in Fraud Detection(MimbFD). Specifically, we design atopological message reachability module for high-quality node representationlearning to penetrate fraudsters' camouflage and alleviate insufficientpropagation. Then, we introduce a local confounding debiasing module to adjustnode representations, enhancing the stable association between noderepresentations and labels to balance the influence of different classes.Finally, we conducted experiments on three public fraud datasets, and theresults demonstrate that MimbFD exhibits outstanding performance in frauddetection.</description>
      <author>example@mail.com (Yudan Song, Yuecen Wei, Yuhang Lu, Qingyun Sun, Minglai Shao, Li-e Wang, Chunming Hu, Xianxian Li, Xingcheng Fu)</author>
      <guid isPermaLink="false">2507.06469v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception</title>
      <link>http://arxiv.org/abs/2507.06687v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了StixelNExT++，这是一种用于单目感知系统的场景表示新方法。&lt;h4&gt;背景&lt;/h4&gt;本文基于已建立的Stixel表示，旨在提升3D Stixel单元的聚类和对象分割能力。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在在保持对点云和鸟瞰图表示的适应性同时，实现场景信息的高效压缩。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一个轻量级的神经网络，该网络基于自动生成的基于LiDAR的真实数据训练，以达到实时性能，每帧计算时间低至10毫秒。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo数据集上的实验结果表明，StixelNExT++在30米范围内表现出具有竞争力的性能，突显了其在自动驾驶系统集体感知中的潜力。&lt;h4&gt;结论&lt;/h4&gt;StixelNExT++在场景表示方面具有实际应用价值，特别是在自动驾驶系统的感知功能中。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents StixelNExT++, a novel approach to scene representation for monocular perception systems. Building on the established Stixel representation, our method infers 3D Stixels and enhances object segmentation by clustering smaller 3D Stixel units. The approach achieves high compression of scene information while remaining adaptable to point cloud and bird's-eye-view representations. Our lightweight neural network, trained on automatically generated LiDAR-based ground truth, achieves real-time performance with computation times as low as 10 ms per frame. Experimental results on the Waymo dataset demonstrate competitive performance within a 30-meter range, highlighting the potential of StixelNExT++ for collective perception in autonomous systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents StixelNExT++, a novel approach to scene representationfor monocular perception systems. Building on the established Stixelrepresentation, our method infers 3D Stixels and enhances object segmentationby clustering smaller 3D Stixel units. The approach achieves high compressionof scene information while remaining adaptable to point cloud andbird's-eye-view representations. Our lightweight neural network, trained onautomatically generated LiDAR-based ground truth, achieves real-timeperformance with computation times as low as 10 ms per frame. Experimentalresults on the Waymo dataset demonstrate competitive performance within a30-meter range, highlighting the potential of StixelNExT++ for collectiveperception in autonomous systems.</description>
      <author>example@mail.com (Marcel Vosshans, Omar Ait-Aider, Youcef Mezouar, Markus Enzweiler)</author>
      <guid isPermaLink="false">2507.06687v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models</title>
      <link>http://arxiv.org/abs/2507.06952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型在领域理解上的潜力，提出了一种评估方法来检验模型是否真正捕捉到深层结构，并发现模型在训练任务上表现优异，但在适应新任务时却未能形成对基础世界模型的归纳偏置。&lt;h4&gt;背景&lt;/h4&gt;基础模型基于序列预测可以揭示更深层次领域理解的理念，类似于开普勒对行星运动的预测最终导致了牛顿力学的发现。&lt;h4&gt;目的&lt;/h4&gt;开发一种评估基础模型的技术，以检验它们是否能够适应由假设世界模型生成的合成数据集，并测量模型的归纳偏置是否与世界模型一致。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为归纳偏置探测的技术，该技术通过考察模型在合成数据集上的表现来评估其归纳偏置。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，基础模型在训练任务上表现出色，但在适应新任务时未能形成对基础世界模型的归纳偏置，特别是在基于轨道轨迹训练的模型在适应新的物理任务时，未能应用牛顿力学。&lt;h4&gt;结论&lt;/h4&gt;进一步分析表明，这些模型似乎发展出了特定于任务的启发式方法，这些方法无法进行泛化。&lt;h4&gt;翻译&lt;/h4&gt;本文基于序列预测的深层领域理解理念，开发了一种评估基础模型的技术，发现模型在训练任务上表现优异，但在适应新任务时未能形成对基础世界模型的归纳偏置，特别是在基于轨道轨迹训练的模型在适应新的物理任务时，未能应用牛顿力学。进一步分析表明，这些模型似乎发展出了特定于任务的启发式方法，这些方法无法进行泛化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are premised on the idea that sequence prediction canuncover deeper domain understanding, much like how Kepler's predictions ofplanetary motion later led to the discovery of Newtonian mechanics. However,evaluating whether these models truly capture deeper structure remains achallenge. We develop a technique for evaluating foundation models thatexamines how they adapt to synthetic datasets generated from some postulatedworld model. Our technique measures whether the foundation model's inductivebias aligns with the world model, and so we refer to it as an inductive biasprobe. Across multiple domains, we find that foundation models can excel attheir training tasks yet fail to develop inductive biases towards theunderlying world model when adapted to new tasks. We particularly find thatfoundation models trained on orbital trajectories consistently fail to applyNewtonian mechanics when adapted to new physics tasks. Further analysis revealsthat these models behave as if they develop task-specific heuristics that failto generalize.</description>
      <author>example@mail.com (Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan)</author>
      <guid isPermaLink="false">2507.06952v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation</title>
      <link>http://arxiv.org/abs/2507.06670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STARS的统一框架，用于自动化的歌唱声音合成（SVS）标注，旨在解决手动标注的劳动和资源密集问题。&lt;h4&gt;背景&lt;/h4&gt;现有的自动歌唱标注方法主要针对标注流程的某个独立方面，而高质量的标注数据集对歌唱声音合成的需求日益增长。&lt;h4&gt;目的&lt;/h4&gt;STARS旨在同时解决歌唱转录、对齐和风格标注的挑战。&lt;h4&gt;方法&lt;/h4&gt;STARS采用了层次化的声学特征处理，并使用了新颖的非自回归局部声学编码器来学习结构化的分层表示。它提供了包括精确的音素-音频对齐、稳健的音符转录和定位、表现力强的嗓音技术识别以及全局风格特征（包括情感和节奏）在内的多层次标注。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证表明，与现有的标注方法相比，STARS在多个评估维度上表现出优异的性能。此外，在SVS训练中的应用表明，使用STARS标注数据的模型实现了显著提高的感知自然度和精确的风格控制。&lt;h4&gt;结论&lt;/h4&gt;STARS不仅克服了创建歌唱数据集中的关键可扩展性挑战，而且在可控歌唱声音合成的新方法方面开辟了先河。&lt;h4&gt;翻译&lt;/h4&gt;Recent breakthroughs in singing voice synthesis (SVS) have heightened the demand for high-quality annotated datasets, yet manual annotation remains prohibitively labor-intensive and resource-intensive. Existing automatic singing annotation (ASA) methods, however, primarily tackle isolated aspects of the annotation pipeline. To address this fundamental challenge, we present STARS, which is, to our knowledge, the first unified framework that simultaneously addresses singing transcription, alignment, and refined style annotation. Our framework delivers comprehensive multi-level annotations encompassing: (1) precise phoneme-audio alignment, (2) robust note transcription and temporal localization, (3) expressive vocal technique identification, and (4) global stylistic characterization including emotion and pace. The proposed architecture employs hierarchical acoustic feature processing across frame, word, phoneme, note, and sentence levels. The novel non-autoregressive local acoustic encoders enable structured hierarchical representation learning. Experimental validation confirms the framework's superior performance across multiple evaluation dimensions compared to existing annotation approaches. Furthermore, applications in SVS training demonstrate that models utilizing STARS-annotated data achieve significantly enhanced perceptual naturalness and precise style control. This work not only overcomes critical scalability challenges in the creation of singing datasets but also pioneers new methodologies for controllable singing voice synthesis. Audiosamples are available at https://gwx314.github.io/stars-demo/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in singing voice synthesis (SVS) have heightened thedemand for high-quality annotated datasets, yet manual annotation remainsprohibitively labor-intensive and resource-intensive. Existing automaticsinging annotation (ASA) methods, however, primarily tackle isolated aspects ofthe annotation pipeline. To address this fundamental challenge, we presentSTARS, which is, to our knowledge, the first unified framework thatsimultaneously addresses singing transcription, alignment, and refined styleannotation. Our framework delivers comprehensive multi-level annotationsencompassing: (1) precise phoneme-audio alignment, (2) robust notetranscription and temporal localization, (3) expressive vocal techniqueidentification, and (4) global stylistic characterization including emotion andpace. The proposed architecture employs hierarchical acoustic featureprocessing across frame, word, phoneme, note, and sentence levels. The novelnon-autoregressive local acoustic encoders enable structured hierarchicalrepresentation learning. Experimental validation confirms the framework'ssuperior performance across multiple evaluation dimensions compared to existingannotation approaches. Furthermore, applications in SVS training demonstratethat models utilizing STARS-annotated data achieve significantly enhancedperceptual naturalness and precise style control. This work not only overcomescritical scalability challenges in the creation of singing datasets but alsopioneers new methodologies for controllable singing voice synthesis. Audiosamples are available at https://gwx314.github.io/stars-demo/.</description>
      <author>example@mail.com (Wenxiang Guo, Yu Zhang, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, Zhetao Chen, Wenhao Xu, Fei Wu, Zhou Zhao)</author>
      <guid isPermaLink="false">2507.06670v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning</title>
      <link>http://arxiv.org/abs/2507.06662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态的关键点学习框架MK-Pose，用于在已知类别中预测对象的姿态，解决了现有方法在物体遮挡和泛化能力上的不足。&lt;h4&gt;背景&lt;/h4&gt;类别级物体姿态估计在自动化仓库和制造业等领域至关重要，但现有方法在处理物体遮挡和不同实例、类别间的泛化问题时存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效预测物体姿态的方法，提高在复杂场景下的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;MK-Pose框架集成了RGB图像、点云和类别级文本描述，使用自监督关键点检测模块，并结合注意力查询生成、软热图匹配和基于图的关系建模。此外，还设计了图增强特征融合模块，以整合局部几何信息和全局上下文。&lt;h4&gt;主要发现&lt;/h4&gt;MK-Pose在CAMERA25和REAL275数据集上进行了评估，并在HouseCat6D数据集上测试了跨数据集的能力，结果表明MK-Pose在IoU和平均精度方面均优于现有最佳方法，且无需形状先验。&lt;h4&gt;结论&lt;/h4&gt;MK-Pose是一种有效且具有优越性能的物体姿态估计方法，未来将在相关领域得到应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：类别级物体姿态估计，即在不了解单个实例的情况下预测已知类别中物体的姿态，在仓库自动化和制造业等应用中至关重要。现有依赖于RGB图像或点云数据的方法往往难以处理物体遮挡，以及在不同实例和类别间进行泛化。本文提出了一种基于多模态的关键点学习框架（MK-Pose），该框架集成了RGB图像、点云和类别级文本描述。该模型使用了一个增强的注意力查询生成的自监督关键点检测模块，结合了软热图匹配和基于图的关系建模。此外，还设计了一个图增强的特征融合模块，用于整合局部几何信息和全局上下文。MK-Pose在CAMERA25和REAL275数据集上进行了评估，并在HouseCat6D数据集上测试了跨数据集的能力。结果表明，MK-Pose在IoU和平均精度方面均优于现有最佳方法，无需形状先验。代码将在https://github.com/yangyifanYYF/MK-Pose处发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Category-level object pose estimation, which predicts the pose of objectswithin a known category without prior knowledge of individual instances, isessential in applications like warehouse automation and manufacturing. Existingmethods relying on RGB images or point cloud data often struggle with objectocclusion and generalization across different instances and categories. Thispaper proposes a multimodal-based keypoint learning framework (MK-Pose) thatintegrates RGB images, point clouds, and category-level textual descriptions.The model uses a self-supervised keypoint detection module enhanced withattention-based query generation, soft heatmap matching and graph-basedrelational modeling. Additionally, a graph-enhanced feature fusion module isdesigned to integrate local geometric information and global context. MK-Poseis evaluated on CAMERA25 and REAL275 dataset, and is further tested forcross-dataset capability on HouseCat6D dataset. The results demonstrate thatMK-Pose outperforms existing state-of-the-art methods in both IoU and averageprecision without shape priors. Codes will be released at\href{https://github.com/yangyifanYYF/MK-Pose}{https://github.com/yangyifanYYF/MK-Pose}.</description>
      <author>example@mail.com (Yifan Yang, Peili Song, Enfan Lan, Dong Liu, Jingtai Liu)</author>
      <guid isPermaLink="false">2507.06662v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications</title>
      <link>http://arxiv.org/abs/2507.06795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在开放源代码大型语言模型（LLMs）的背景下，小型LLMs（sLLMs）的应用及其在领域自适应连续预训练（DACP）方法下的效果。&lt;h4&gt;背景&lt;/h4&gt;开放源代码大型语言模型的出现为企业的应用提供了更多机会，但许多组织缺乏部署和维护大规模模型的基础设施。小型LLMs虽然性能有限，但已成为实际可行的替代方案。&lt;h4&gt;目的&lt;/h4&gt;验证将基于DACP的方案应用于不同的基础模型和服务领域中的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的实验和实际评估，研究DACP应用于sLLMs在目标领域性能上的提升。&lt;h4&gt;主要发现&lt;/h4&gt;应用DACP的sLLMs在目标领域性能上取得了显著提升，同时保持了通用能力，为企业的部署提供了成本效益高且可扩展的解决方案。&lt;h4&gt;结论&lt;/h4&gt;DACP方法对于提高sLLMs在商业应用中的性能具有实际意义，为企业的部署提供了有效途径。&lt;h4&gt;翻译&lt;/h4&gt;The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of open-source large language models (LLMs) has expandedopportunities for enterprise applications; however, many organizations stilllack the infrastructure to deploy and maintain large-scale models. As a result,small LLMs (sLLMs) have become a practical alternative, despite their inherentperformance limitations. While Domain Adaptive Continual Pretraining (DACP) hasbeen previously explored as a method for domain adaptation, its utility incommercial applications remains under-examined. In this study, we validate theeffectiveness of applying a DACP-based recipe across diverse foundation modelsand service domains. Through extensive experiments and real-world evaluations,we demonstrate that DACP-applied sLLMs achieve substantial gains in targetdomain performance while preserving general capabilities, offering acost-efficient and scalable solution for enterprise-level deployment.</description>
      <author>example@mail.com (Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon)</author>
      <guid isPermaLink="false">2507.06795v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport</title>
      <link>http://arxiv.org/abs/2507.06733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICIAP 2025 (this version is not peer-reviewed; it is the  submitted version). ICIAP 2025 proceedings DOI will appear here&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种结合视觉适配器和提示学习的方法，通过部分最优传输（POT）和对比学习（CL）来提高CLIP在医学图像上的适应性，尤其是在医学异常检测（AD）方面。&lt;h4&gt;背景&lt;/h4&gt;医学异常检测因图像模态多样、解剖结构变异和标注数据有限而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提高CLIP在医学图像上的适应性，尤其是用于医学异常检测。&lt;h4&gt;方法&lt;/h4&gt;方法结合了视觉适配器和提示学习，使用POT对局部特征进行对齐，以捕获微小的异常；对比学习（CL）进一步强化了类内凝聚和类间分离。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在少样本、零样本和跨数据集场景中取得了最先进的成果，无需合成数据或记忆库。&lt;h4&gt;结论&lt;/h4&gt;该方法在医学异常检测方面表现优异。&lt;h4&gt;翻译&lt;/h4&gt;Medical anomaly detection (AD) is challenging due to diverse imagingmodalities, anatomical variations, and limited labeled data. We propose a novelapproach combining visual adapters and prompt learning with Partial OptimalTransport (POT) and contrastive learning (CL) to improve CLIP's adaptability tomedical images, particularly for AD. Unlike standard prompt learning, whichoften yields a single representation, our method employs multiple promptsaligned with local features via POT to capture subtle abnormalities. CL furtherenforces intra-class cohesion and inter-class separation. Our method achievesstate-of-the-art results in few-shot, zero-shot, and cross-dataset scenarioswithout synthetic data or memory banks. The code is available athttps://github.com/mahshid1998/MADPOT.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical anomaly detection (AD) is challenging due to diverse imagingmodalities, anatomical variations, and limited labeled data. We propose a novelapproach combining visual adapters and prompt learning with Partial OptimalTransport (POT) and contrastive learning (CL) to improve CLIP's adaptability tomedical images, particularly for AD. Unlike standard prompt learning, whichoften yields a single representation, our method employs multiple promptsaligned with local features via POT to capture subtle abnormalities. CL furtherenforces intra-class cohesion and inter-class separation. Our method achievesstate-of-the-art results in few-shot, zero-shot, and cross-dataset scenarioswithout synthetic data or memory banks. The code is available athttps://github.com/mahshid1998/MADPOT.</description>
      <author>example@mail.com (Mahshid Shiri, Cigdem Beyan, Vittorio Murino)</author>
      <guid isPermaLink="false">2507.06733v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Prompt Tuning</title>
      <link>http://arxiv.org/abs/2507.06085v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了prompt tuning技术，这是一种通过在模型前添加可训练的连续向量来高效调整语言模型的方法，同时保持模型冻结。文章将现有方法分为直接提示学习和迁移学习两大类，并对每种方法的设计、创新、见解、优点和缺点进行了分析，同时通过可视化比较了不同框架。文章还识别了计算效率和训练稳定性方面的挑战，并讨论了提高训练鲁棒性和拓宽应用范围的未来方向。&lt;h4&gt;背景&lt;/h4&gt;prompt tuning是一种参数高效的语言模型调整方法，通过添加可训练的连续向量来优化模型。&lt;h4&gt;目的&lt;/h4&gt;对prompt tuning技术进行综述，分析不同方法的优缺点，并探讨未来发展方向。&lt;h4&gt;方法&lt;/h4&gt;将prompt tuning方法分为直接提示学习和迁移学习两大类，对每种方法进行详细分析。&lt;h4&gt;主要发现&lt;/h4&gt;直接提示学习和迁移学习是prompt tuning的两种主要方法，文章对它们进行了详细的分类和分析。&lt;h4&gt;结论&lt;/h4&gt;prompt tuning技术具有高效性和鲁棒性，但仍存在计算效率和训练稳定性方面的挑战，未来需要进一步研究和改进。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了prompt tuning技术，这是一种通过在模型前添加可训练的连续向量来高效调整语言模型的方法，同时保持模型冻结。我们将现有方法分为直接提示学习和迁移学习两大类，包括：一般优化方法、基于编码器的方法、分解策略和专家混合框架。对于每种方法，我们分析了方法设计、创新、见解、优点和缺点，并通过可视化比较了不同的框架。我们识别了计算效率和训练稳定性方面的挑战，并讨论了提高训练鲁棒性和拓宽应用范围的未来方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey reviews prompt tuning, a parameter-efficient approach foradapting language models by prepending trainable continuous vectors whilekeeping the model frozen. We classify existing approaches into two categories:direct prompt learning and transfer learning. Direct prompt learning methodsinclude: general optimization approaches, encoder-based methods, decompositionstrategies, and mixture-of-experts frameworks. Transfer learning methodsconsist of: general transfer approaches, encoder-based methods, anddecomposition strategies. For each method, we analyze method designs,innovations, insights, advantages, and disadvantages, with illustrativevisualizations comparing different frameworks. We identify challenges incomputational efficiency and training stability, and discuss future directionsin improving training robustness and broadening application scope.</description>
      <author>example@mail.com (Zongqian Li, Yixuan Su, Nigel Collier)</author>
      <guid isPermaLink="false">2507.06085v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision</title>
      <link>http://arxiv.org/abs/2507.06639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EXAONE Path 2.0 technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EXAONE Path 2.0是一个病理学基础模型，通过直接在切片级别监督下学习patch-level表示，使用少量数据就能在多个生物标志物预测任务上取得最先进的平均性能。&lt;h4&gt;背景&lt;/h4&gt;由于全切片图像（WSI）的gigapixel规模，数字病理学中处理WSI通常很困难。大多数方法通过自监督学习（SSL）训练patch编码器，然后通过多个实例学习（MIL）或切片编码器聚合patch级别的嵌入来执行下游任务。&lt;h4&gt;目的&lt;/h4&gt;解决patch-level SSL可能忽略复杂领域特定特征的问题，如突变状态和分子特征，以及SSL方法相对于全监督方法在数据效率和计算资源上的不足。&lt;h4&gt;方法&lt;/h4&gt;EXAONE Path 2.0在直接切片级别监督下学习patch-level表示，使用仅37k个WSI进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;EXAONE Path 2.0在10个生物标志物预测任务上实现了最先进的平均性能，表现出显著的数据效率。&lt;h4&gt;结论&lt;/h4&gt;EXAONE Path 2.0模型在病理学领域的数据效率和性能方面取得了显著进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In digital pathology, whole-slide images (WSIs) are often difficult to handledue to their gigapixel scale, so most approaches train patch encoders viaself-supervised learning (SSL) and then aggregate the patch-level embeddingsvia multiple instance learning (MIL) or slide encoders for downstream tasks.However, patch-level SSL may overlook complex domain-specific features that areessential for biomarker prediction, such as mutation status and molecularcharacteristics, as SSL methods rely only on basic augmentations selected fornatural image domains on small patch-level area. Moreover, SSL methods remainless data efficient than fully supervised approaches, requiring extensivecomputational resources and datasets to achieve competitive performance. Toaddress these limitations, we present EXAONE Path 2.0, a pathology foundationmodel that learns patch-level representations under direct slide-levelsupervision. Using only 37k WSIs for training, EXAONE Path 2.0 achievesstate-of-the-art average performance across 10 biomarker prediction tasks,demonstrating remarkable data efficiency.</description>
      <author>example@mail.com (Myungjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu, Jongseong Jang, Soonyoung Lee)</author>
      <guid isPermaLink="false">2507.06639v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction</title>
      <link>http://arxiv.org/abs/2507.06366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为DecoyDB的大规模结构感知数据集，用于自监督图对比学习，以预测蛋白质-配体复合物的结合亲和力，并设计了相应的GCL框架。&lt;h4&gt;背景&lt;/h4&gt;预测蛋白质-配体复合物的结合亲和力对于药物发现至关重要，但受限于缺乏大规模和高质量结合亲和力标签。&lt;h4&gt;目的&lt;/h4&gt;提出DecoyDB数据集和GCL框架，以突破自监督学习在蛋白质-配体复合物上的应用障碍。&lt;h4&gt;方法&lt;/h4&gt;构建DecoyDB数据集，包含高分辨率真实复合物和计算生成的多种伪复合物，并设计GCL框架进行预训练和微调。&lt;h4&gt;主要发现&lt;/h4&gt;DecoyDB数据集和GCL框架能够提高模型在预测蛋白质-配体结合亲和力方面的准确性、标签效率和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;DecoyDB数据集和GCL框架为蛋白质-配体结合亲和力预测提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：预测蛋白质-配体复合物的结合亲和力在药物发现中起着至关重要的作用。遗憾的是，由于缺乏大规模和高质量结合亲和力标签，进展受到了阻碍。广泛使用的PDBbind数据集包含少于20K个标记的复合物。自监督学习，尤其是图对比学习（GCL），通过基于大量未标记复合物预训练图神经网络模型并在较少标记的复合物上微调模型，为突破这一障碍提供了独特的机会。然而，该问题面临着独特的挑战，包括缺乏一个具有明确正/负复合物对的全面未标记数据集，以及需要设计能够结合此类数据独特特征的GCL算法。为了填补这一空白，我们提出了DecoyDB，这是一个专门为自监督GCL设计的蛋白质-配体复合物的大规模结构感知数据集。DecoyDB由高分辨率真实复合物（小于2.5埃）和具有从现实到次优（负对）范围的计算生成结合位点的多样化伪复合物组成。每个伪复合物都附带了与天然构象的均方根偏差（RMSD）注释。我们进一步设计了一个定制的GCL框架，用于基于DecoyDB预训练图神经网络并使用PDBbind的标签进行微调。广泛的实验证实，使用DecoyDB预训练的模型在准确性、标签效率和泛化能力方面表现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the binding affinity of protein-ligand complexes plays a vitalrole in drug discovery. Unfortunately, progress has been hindered by the lackof large-scale and high-quality binding affinity labels. The widely usedPDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,especially graph contrastive learning (GCL), provides a unique opportunity tobreak the barrier by pre-training graph neural network models based on vastunlabeled complexes and fine-tuning the models on much fewer labeled complexes.However, the problem faces unique challenges, including a lack of acomprehensive unlabeled dataset with well-defined positive/negative complexpairs and the need to design GCL algorithms that incorporate the uniquecharacteristics of such data. To fill the gap, we propose DecoyDB, alarge-scale, structure-aware dataset specifically designed for self-supervisedGCL on protein-ligand complexes. DecoyDB consists of high-resolution groundtruth complexes (less than 2.5 Angstrom) and diverse decoy structures withcomputationally generated binding poses that range from realistic to suboptimal(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation(RMSD) from the native pose. We further design a customized GCL framework topre-train graph neural networks based on DecoyDB and fine-tune the models withlabels from PDBbind. Extensive experiments confirm that models pre-trained withDecoyDB achieve superior accuracy, label efficiency, and generalizability.</description>
      <author>example@mail.com (Yupu Zhang, Zelin Xu, Tingsong Xiao, Gustavo Seabra, Yanjun Li, Chenglong Li, Zhe Jiang)</author>
      <guid isPermaLink="false">2507.06366v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds</title>
      <link>http://arxiv.org/abs/2507.06484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project website: https://ai.stanford.edu/~sunfanyun/3d-generalist/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种可扩展的方法来生成高质量的3D环境，这些环境可以作为基础模型训练的数据。该方法通过将3D环境构建重新定义为序列决策问题，使用视觉-语言模型（VLMs）作为策略来输出动作，共同设计3D环境的布局、材质、照明和资产。&lt;h4&gt;背景&lt;/h4&gt;尽管大规模预训练赋予了模型语言和视觉推理能力，但由于缺乏基于3D世界的实际数据，提高其空间推理能力仍然具有挑战性。虽然人类可以通过3D图形手动创建沉浸式和交互式的世界，如VR、游戏和机器人应用，但这个过程劳动密集型。&lt;h4&gt;目的&lt;/h4&gt;提出一种可扩展的方法，生成高质量的3D环境，作为训练数据，以增强模型的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;将3D环境构建视为一个序列决策问题，利用VLMs作为策略输出动作，共同设计3D环境的布局、材质、照明和资产。通过自我改进微调训练VLMs以生成更符合预期的3D环境。&lt;h4&gt;主要发现&lt;/h4&gt;3D-Generalist框架和提出的训练策略在生成可用于模拟的3D环境方面表现出有效性。在合成数据生成中，通过在生成的数据上预训练视觉基础模型，展示了其质量和可扩展性。在下游任务上的微调后，该模型在性能上超过了在精心制作的合成数据上预训练的模型，并且其结果接近使用真实数据达到的结果。&lt;h4&gt;结论&lt;/h4&gt;3D-Generalist方法能够生成高质量的3D环境，有效提升了模型的空间推理能力，并且在合成数据生成方面具有优越的性能和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite large-scale pretraining endowing models with language and visionreasoning capabilities, improving their spatial reasoning capability remainschallenging due to the lack of data grounded in the 3D world. While it ispossible for humans to manually create immersive and interactive worlds through3D graphics, as seen in applications such as VR, gaming, and robotics, thisprocess remains highly labor-intensive. In this paper, we propose a scalablemethod for generating high-quality 3D environments that can serve as trainingdata for foundation models. We recast 3D environment building as a sequentialdecision-making problem, employing Vision-Language-Models (VLMs) as policiesthat output actions to jointly craft a 3D environment's layout, materials,lighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs togenerate more prompt-aligned 3D environments via self-improvement fine-tuning.We demonstrate the effectiveness of 3D-Generalist and the proposed trainingstrategy in generating simulation-ready 3D environments. Furthermore, wedemonstrate its quality and scalability in synthetic data generation bypretraining a vision foundation model on the generated data. After fine-tuningthe pre-trained model on downstream tasks, we show that it surpasses modelspre-trained on meticulously human-crafted synthetic data and approaches resultsachieved with real data orders of magnitude larger.</description>
      <author>example@mail.com (Fan-Yun Sun, Shengguang Wu, Christian Jacobsen, Thomas Yim, Haoming Zou, Alex Zook, Shangru Li, Yu-Hsin Chou, Ethem Can, Xunlei Wu, Clemens Eppner, Valts Blukis, Jonathan Tremblay, Jiajun Wu, Stan Birchfield, Nick Haber)</author>
      <guid isPermaLink="false">2507.06484v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation</title>
      <link>http://arxiv.org/abs/2507.06622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为FuDoBa的基于贝叶斯优化的方法，用于结合大型语言模型（LLMs）和特定领域知识，以生成低维、任务相关的表示，提高分类性能。&lt;h4&gt;背景&lt;/h4&gt;LLMs在文档表示领域取得了成功，但它们生成的嵌入通常维度高、计算复杂，且对特定领域应用不够有效。&lt;h4&gt;目的&lt;/h4&gt;解决LLMs嵌入在特定领域应用中的局限性和效率问题。&lt;h4&gt;方法&lt;/h4&gt;FuDoBa方法将LLMs生成的嵌入与从本地和外部知识库（如WikiData）获取的特定领域结构化知识相结合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在六个数据集的两个领域上展示了有效性，表明其与鲁棒的基于AutoML的分类器结合时，表现可与或优于仅使用LLMs嵌入的基线。&lt;h4&gt;结论&lt;/h4&gt;FuDoBa方法通过融合LLMs嵌入和领域知识，提高了特定领域应用的分类性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building on the success of Large Language Models (LLMs), LLM-basedrepresentations have dominated the document representation landscape, achievinggreat performance on the document embedding benchmarks. However, thehigh-dimensional, computationally expensive embeddings from LLMs tend to beeither too generic or inefficient for domain-specific applications. To addressthese limitations, we introduce FuDoBa a Bayesian optimisation-based methodthat integrates LLM-based embeddings with domain-specific structured knowledge,sourced both locally and from external repositories like WikiData. This fusionproduces low-dimensional, task-relevant representations while reducing trainingcomplexity and yielding interpretable early-fusion weights for enhancedclassification performance. We demonstrate the effectiveness of our approach onsix datasets in two domains, showing that when paired with robust AutoML-basedclassifiers, our proposed representation learning approach performs on parwith, or surpasses, those produced solely by the proprietary LLM-basedembedding baselines.</description>
      <author>example@mail.com (Boshko Koloski, Senja Pollak, Roberto Navigli, Blaž Škrlj)</author>
      <guid isPermaLink="false">2507.06622v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Divergence-Based Similarity Function for Multi-View Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.06560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于差异的相似度函数（DSF），通过将每个增强视图表示为分布，并测量分布之间的差异来捕捉联合结构，从而在多个任务中提高了性能。&lt;h4&gt;背景&lt;/h4&gt;对比学习在近期取得了成功，但先前方法在损失或特征级别整合多个视图时，主要捕获成对关系，未能建模所有视图之间的联合结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以更有效地利用实例的多个增强视图。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于差异的相似度函数（DSF），该函数将每个增强视图视为一个分布，并通过分布之间的差异来衡量相似度。&lt;h4&gt;主要发现&lt;/h4&gt;DSF在包括kNN分类和线性评估在内的各种任务中一致地提高了性能，并且与其它多视图方法相比，DSF提供了更高的效率。此外，DSF与余弦相似度建立了理论联系，并且与余弦相似度不同，DSF在不需要温度超参数的情况下也能有效工作。&lt;h4&gt;结论&lt;/h4&gt;DSF是一种有效的方法，可以提高多视图学习任务中的性能，并具有更高的效率和无需温度超参数的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent success in contrastive learning has sparked growing interest in moreeffectively leveraging multiple augmented views of an instance. While priormethods incorporate multiple views at the loss or feature level, they primarilycapture pairwise relationships and fail to model the joint structure across allviews. In this work, we propose a divergence-based similarity function (DSF)that explicitly captures the joint structure by representing each set ofaugmented views as a distribution and measuring similarity as the divergencebetween distributions. Extensive experiments demonstrate that DSF consistentlyimproves performance across various tasks, including kNN classification andlinear evaluation, while also offering greater efficiency compared to othermulti-view methods. Furthermore, we establish a theoretical connection betweenDSF and cosine similarity, and show that, unlike cosine similarity, DSFoperates effectively without requiring a temperature hyperparameter.</description>
      <author>example@mail.com (Jae Hyoung Jeon, Cheolsu Lim, Myungjoo Kang)</author>
      <guid isPermaLink="false">2507.06560v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer</title>
      <link>http://arxiv.org/abs/2507.06481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DINOS的大规模开放数据集和一种名为IMPACT的新型基础模型，用于工业机器声学信号分析，以解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;工业机器的声学信号在异常检测、预测性维护和运营效率提升方面具有价值，但现有的方法在可扩展性和泛化能力上存在不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，开发一个适用于工业声学信号分析的大规模数据集和基础模型。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含74,149个音频样本的大规模开放数据集DINOS，并提出了一个名为IMPACT的自监督预训练模型，该模型在DINOS上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;IMPACT模型在30个不同的下游任务中表现出色，超过24个任务的表现优于现有模型，证明了其有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DINOS和IMPACT为工业声学信号分析提供了一个新的基准，并推动了社区研究和基准测试的发展。&lt;h4&gt;翻译&lt;/h4&gt;Acoustic signals from industrial machines offer valuable insights for anomaly detection, predictive maintenance, and operational efficiency enhancement. However, existing task-specific, supervised learning methods often scale poorly and fail to generalize across diverse industrial scenarios, whose acoustic characteristics are distinct from general audio. Furthermore, the scarcity of accessible, large-scale datasets and pretrained models tailored for industrial audio impedes community-driven research and benchmarking. To address these challenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a large-scale open-access dataset. DINOS comprises over 74,149 audio samples (exceeding 1,093 hours) collected from various industrial acoustic scenarios. We also present IMPACT (Industrial Machine Perception via Acoustic Cognitive Transformer), a novel foundation model for industrial machine sound analysis. IMPACT is pretrained on DINOS in a self-supervised manner. By jointly optimizing utterance and frame-level losses, it captures both global semantics and fine-grained temporal structures. This makes its representations suitable for efficient fine-tuning on various industrial downstream tasks with minimal labeled data. Comprehensive benchmarking across 30 distinct downstream tasks (spanning four machine types) demonstrates that IMPACT outperforms existing models on 24 tasks, establishing its superior effectiveness and robustness, while providing a new performance benchmark for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Acoustic signals from industrial machines offer valuable insights for anomalydetection, predictive maintenance, and operational efficiency enhancement.However, existing task-specific, supervised learning methods often scale poorlyand fail to generalize across diverse industrial scenarios, whose acousticcharacteristics are distinct from general audio. Furthermore, the scarcity ofaccessible, large-scale datasets and pretrained models tailored for industrialaudio impedes community-driven research and benchmarking. To address thesechallenges, we introduce DINOS (Diverse INdustrial Operation Sounds), alarge-scale open-access dataset. DINOS comprises over 74,149 audio samples(exceeding 1,093 hours) collected from various industrial acoustic scenarios.We also present IMPACT (Industrial Machine Perception via Acoustic CognitiveTransformer), a novel foundation model for industrial machine sound analysis.IMPACT is pretrained on DINOS in a self-supervised manner. By jointlyoptimizing utterance and frame-level losses, it captures both global semanticsand fine-grained temporal structures. This makes its representations suitablefor efficient fine-tuning on various industrial downstream tasks with minimallabeled data. Comprehensive benchmarking across 30 distinct downstream tasks(spanning four machine types) demonstrates that IMPACT outperforms existingmodels on 24 tasks, establishing its superior effectiveness and robustness,while providing a new performance benchmark for future research.</description>
      <author>example@mail.com (Changheon Han, Yuseop Sim, Hoin Jung, Jiho Lee, Hojun Lee, Yun Seok Kang, Sucheol Woo, Garam Kim, Hyung Wook Park, Martin Byung-Guk Jun)</author>
      <guid isPermaLink="false">2507.06481v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation</title>
      <link>http://arxiv.org/abs/2507.06613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 8 figures and 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的生成模型框架，通过利用不同的β值来学习多个对应的潜在表示，以平衡解耦和重建质量，同时提高生成质量。&lt;h4&gt;背景&lt;/h4&gt;解耦和可解释的潜在表示在生成模型中通常以生成质量为代价。&lt;h4&gt;目的&lt;/h4&gt;解决解耦和重建质量之间的权衡问题，提高生成质量。&lt;h4&gt;方法&lt;/h4&gt;1. 使用新的损失函数训练单个变分自动编码器（VAE），控制每个潜在表示中保留的信息量，使得高β值优先考虑解耦而不是重建保真度。2. 引入非线性扩散模型，平滑地转换不同β值对应的潜在表示，最终得到几乎无损的表示，实现清晰的重构。3. 模型支持无输入图像的样本生成，作为一个独立的生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;1. 通过不同的β值学习多个潜在表示，可以在解耦和重建质量之间取得平衡。2. 非线性扩散模型可以平滑地转换潜在表示，提高生成质量。3. 模型支持无输入图像的样本生成，且在潜在空间中β值的变化导致平滑过渡，便于一致地操作生成输出。&lt;h4&gt;结论&lt;/h4&gt;该框架在解耦和生成质量方面进行了评估，并观察到潜在空间中β值变化的平滑过渡，有助于一致地操作生成输出。&lt;h4&gt;翻译&lt;/h4&gt;在生成模型中，解耦和可解释的潜在表示通常以生成质量为代价。$eta$-VAE框架通过引入超参数$eta$来平衡解耦和重建质量，其中设置$eta &gt; 1$引入了一个信息瓶颈，优先考虑解耦而不是精确的重构。为了解决这一权衡问题，我们提出了一种新的生成模型框架，利用一系列$eta$值来学习多个相应的潜在表示。首先，通过训练单个变分自动编码器（VAE）并使用新的损失函数来控制每个潜在表示中保留的信息量，从而使得高$eta$值优先考虑解耦而不是重建保真度。然后，引入一个非线性扩散模型，平滑地转换对应不同$eta$值的潜在表示。该模型向更少解耦和更多信息的表示进行去噪，最终导致（几乎）无损的表示，从而实现清晰的重构。此外，我们的模型支持无输入图像的样本生成，作为一个独立的生成模型。我们在解耦和生成质量方面评估了我们的框架，并观察到潜在空间中与$eta$值变化相关的平滑过渡，便于一致地操作生成输出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disentangled and interpretable latent representations in generative modelstypically come at the cost of generation quality. The $\beta$-VAE frameworkintroduces a hyperparameter $\beta$ to balance disentanglement andreconstruction quality, where setting $\beta &gt; 1$ introduces an informationbottleneck that favors disentanglement over sharp, accurate reconstructions. Toaddress this trade-off, we propose a novel generative modeling framework thatleverages a range of $\beta$ values to learn multiple corresponding latentrepresentations. First, we obtain a slew of representations by training asingle variational autoencoder (VAE), with a new loss function that controlsthe information retained in each latent representation such that the higher$\beta$ value prioritize disentanglement over reconstruction fidelity. We then,introduce a non-linear diffusion model that smoothly transitions latentrepresentations corresponding to different $\beta$ values. This model denoisestowards less disentangled and more informative representations, ultimatelyleading to (almost) lossless representations, enabling sharp reconstructions.Furthermore, our model supports sample generation without input images,functioning as a standalone generative model. We evaluate our framework interms of both disentanglement and generation quality. Additionally, we observesmooth transitions in the latent spaces with respect to changes in $\beta$,facilitating consistent manipulation of generated outputs.</description>
      <author>example@mail.com (Anshuk Uppal, Yuhta Takida, Chieh-Hsin Lai, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2507.06613v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models</title>
      <link>http://arxiv.org/abs/2507.06466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  67 pages, accepted to RLC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Foundation-Model Self-Play (FMSP)算法，旨在通过利用基础模型的能力来克服传统自我博弈算法的局限性，如解决方案的多样性和陷入局部最优的问题。&lt;h4&gt;背景&lt;/h4&gt;多智能体交互在自然界和人类社会中都促进了创新，而自我博弈算法试图通过智能体对抗不断提高的对手来利用这种动态。然而，这些算法通常无法产生多样化的解决方案，并且可能陷入局部最优的行为。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种新的方法，通过利用基础模型（FMs）的代码生成能力和广泛知识，跨越策略空间中的局部最优，以解决自我博弈算法的上述问题。&lt;h4&gt;方法&lt;/h4&gt;论文提出了一系列方法：(1) Vanilla Foundation-Model Self-Play (vFMSP) 通过竞争性自我博弈不断改进智能体策略；(2) Novelty-Search Self-Play (NSSP) 构建多样化的策略群体，忽略性能；(3) 最有前景的变体，Quality-Diversity Self-Play (QDSP)，通过结合NSSP的多样性和vFMSP的细化来创建高质量策略的多样化集合。&lt;h4&gt;主要发现&lt;/h4&gt;在Car Tag（一个连续控制追逐-逃避设置）和Gandalf（一个简单的AI安全模拟，其中攻击者试图绕过LLM的防御）中评估了FMSP。FMSP探索了广泛的强化学习、树搜索和启发式方法。在策略质量方面，算法和vFMSP超过了强大的人造策略。在Gandalf中，FMSP可以成功地自动进行红队测试，突破并破解了六种不同、逐步增强的防御级别。此外，FMSP可以自动修补发现的漏洞。&lt;h4&gt;结论&lt;/h4&gt;FMSP代表了自我博弈与基础模型结合的新的研究前沿，为更创造性和开放式策略发现开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent interactions have long fueled innovation, from naturalpredator-prey dynamics to the space race. Self-play (SP) algorithms try toharness these dynamics by pitting agents against ever-improving opponents,thereby creating an implicit curriculum toward learning high-quality solutions.However, SP often fails to produce diverse solutions and can get stuck inlocally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), anew direction that leverages the code-generation capabilities and vastknowledge of foundation models (FMs) to overcome these challenges by leapingacross local optima in policy space. We propose a family of approaches: (1)\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agentpolicies via competitive self-play; (2) \textbf{Novelty-Search Self-Play(NSSP)} builds a diverse population of strategies, ignoring performance; and(3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)},creates a diverse set of high-quality policies by combining the diversity ofNSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, acontinuous-control pursuer-evader setting, and in Gandalf, a simple AI safetysimulation in which an attacker tries to jailbreak an LLM's defenses. In CarTag, FMSPs explore a wide variety of reinforcement learning, tree search, andheuristic-based methods, to name just a few. In terms of discovered policyquality, \ouralgo and vFMSP surpass strong human-designed strategies. InGandalf, FMSPs can successfully automatically red-team an LLM, breaking throughand jailbreaking six different, progressively stronger levels of defense.Furthermore, FMSPs can automatically proceed to patch the discoveredvulnerabilities. Overall, FMSPs represent a promising new research frontier ofimproving self-play with foundation models, opening fresh paths toward morecreative and open-ended strategy discovery</description>
      <author>example@mail.com (Aaron Dharna, Cong Lu, Jeff Clune)</author>
      <guid isPermaLink="false">2507.06466v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer</title>
      <link>http://arxiv.org/abs/2507.06418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PAST的跨癌症单细胞基础模型，该模型通过联合编码细胞形态和基因表达，学习到统一的跨模态表示，能够捕捉到细胞层面的空间和分子异质性。PAST模型能够从常规病理切片中准确预测单细胞基因表达、虚拟分子染色和多模态生存分析，表现出良好的泛化性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;病理基础模型在癌症图像分析中发挥了重要作用，但通常缺乏与单细胞分辨率的分子数据的整合，限制了其在精准肿瘤学中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够整合病理图像和分子数据的跨癌症单细胞基础模型，以提升癌症图像分析的准确性和实用性。&lt;h4&gt;方法&lt;/h4&gt;PAST模型在20百万对配对组织病理学图像和跨越多种肿瘤类型和组织环境的单细胞转录组数据上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;PAST模型能够学习到细胞层面的空间和分子异质性，并实现从常规病理切片中预测单细胞基因表达、虚拟分子染色和多模态生存分析。&lt;h4&gt;结论&lt;/h4&gt;PAST模型为病理基础模型提供了一个新的范式，为高分辨率空间组学、机制发现和精准癌症研究提供了一种通用的工具。&lt;h4&gt;翻译&lt;/h4&gt;While pathology foundation models have transformed cancer image analysis, they often lack integration with molecular data at single-cell resolution, limiting their utility for precision oncology. Here, we present PAST, a pan-cancer single-cell foundation model trained on 20 million paired histopathology images and single-cell transcriptomes spanning multiple tumor types and tissue contexts. By jointly encoding cellular morphology and gene expression, PAST learns unified cross-modal representations that capture both spatial and molecular heterogeneity at the cellular level. This approach enables accurate prediction of single-cell gene expression, virtual molecular staining, and multimodal survival analysis directly from routine pathology slides. Across diverse cancers and downstream tasks, PAST consistently exceeds the performance of existing approaches, demonstrating robust generalizability and scalability. Our work establishes a new paradigm for pathology foundation models, providing a versatile tool for high-resolution spatial omics, mechanistic discovery, and precision cancer research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While pathology foundation models have transformed cancer image analysis,they often lack integration with molecular data at single-cell resolution,limiting their utility for precision oncology. Here, we present PAST, apan-cancer single-cell foundation model trained on 20 million pairedhistopathology images and single-cell transcriptomes spanning multiple tumortypes and tissue contexts. By jointly encoding cellular morphology and geneexpression, PAST learns unified cross-modal representations that capture bothspatial and molecular heterogeneity at the cellular level. This approachenables accurate prediction of single-cell gene expression, virtual molecularstaining, and multimodal survival analysis directly from routine pathologyslides. Across diverse cancers and downstream tasks, PAST consistently exceedsthe performance of existing approaches, demonstrating robust generalizabilityand scalability. Our work establishes a new paradigm for pathology foundationmodels, providing a versatile tool for high-resolution spatial omics,mechanistic discovery, and precision cancer research.</description>
      <author>example@mail.com (Changchun Yang, Haoyang Li, Yushuai Wu, Yilan Zhang, Yifeng Jiao, Yu Zhang, Rihan Huang, Yuan Cheng, Yuan Qi, Xin Guo, Xin Gao)</author>
      <guid isPermaLink="false">2507.06418v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Voltage Regulation in Distribution Systems with Data Center Loads</title>
      <link>http://arxiv.org/abs/2507.06416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code available at  https://github.com/chennnnnyize/voltage-regulation-with-data-centers&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了大型数据中心因波动性及强度变化导致的电压问题，并提出了一个利用数据中心负载调节能力的动态电压控制方案。&lt;h4&gt;背景&lt;/h4&gt;随着基础模型和AI计算的兴起，大型数据中心的能耗和电力需求引起了广泛关注，同时电网中电压干扰现象也变得更加频繁。&lt;h4&gt;目的&lt;/h4&gt;解决数据中心集成过程中因电力需求波动导致的电压问题。&lt;h4&gt;方法&lt;/h4&gt;通过动态电压和频率缩放（DVFS）方案，在每个数据中心母线上进行本地电压测量和功率注入调整，以分布式方式维持高数据中心计算负载下的安全电压。&lt;h4&gt;主要发现&lt;/h4&gt;使用真实大型语言模型（LLM）推理负载进行的仿真验证了所提机制的有效性。&lt;h4&gt;结论&lt;/h4&gt;LLM的电力数据和提出的控制方案均已开源。&lt;h4&gt;翻译&lt;/h4&gt;Recent boom in foundation models and AI computing have raised growing concerns on the power and energy trajectories of large-scale data centers. This paper focuses on the voltage issues caused by volatile and intensity of datacenter power demand, which also aligns with recent observations of more frequent voltage disturbances in power grids. To address these data center integration challenges, we propose a dynamic voltage control scheme by harnessing data center's load regulation capabilities. By taking local voltage measurements and adjusting power injections at each data center buses through the dynamic voltage and frequency scaling (DVFS) scheme, we are able to maintain safe voltage magnitude in a distributed fashion with higher datacenter computing load. Simulations using real large language model (LLM) inference load validate the effectiveness of our proposed mechanism. Both the LLM power data and proposed control scheme are open sourced.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent boom in foundation models and AI computing have raised growingconcerns on the power and energy trajectories of large-scale data centers. Thispaper focuses on the voltage issues caused by volatile and intensity of datacenter power demand, which also aligns with recent observations of morefrequent voltage disturbances in power grids. To address these data centerintegration challenges, we propose a dynamic voltage control scheme byharnessing data center's load regulation capabilities. By taking local voltagemeasurements and adjusting power injections at each data center buses throughthe dynamic voltage and frequency scaling (DVFS) scheme, we are able tomaintain safe voltage magnitude in a distributed fashion with higher datacenter computing load. Simulations using real large language model (LLM)inference load validate the effectiveness of our proposed mechanism. Both theLLM power data and proposed control scheme are open sourced.</description>
      <author>example@mail.com (Yize Chen, Baosen Zhang)</author>
      <guid isPermaLink="false">2507.06416v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits</title>
      <link>http://arxiv.org/abs/2507.06535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCAD2025. This is the initial version. Minor changes  will be made&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为CircuitGCL的新型图对比学习框架，用于模拟混合信号(AMS)电路的表示学习，旨在解决设计数据稀缺、标签分布不均衡和电路实现多样性等问题，以提高电路表示的鲁棒性和迁移性。&lt;h4&gt;背景&lt;/h4&gt;在模拟混合信号(AMS)电路中，图表示学习对于各种下游任务（如寄生估计）至关重要，但由于设计数据稀缺、标签分布不均衡和电路实现的多样性，学习鲁棒且可迁移的电路表示存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了CircuitGCL框架，旨在增强跨异构电路图的可迁移性。&lt;h4&gt;方法&lt;/h4&gt;CircuitGCL通过结合表示散射和标签重平衡，利用自监督策略学习拓扑不变的节点嵌入。同时，引入了平衡均方误差（MSE）和softmax交叉熵（bsmCE）损失，以缓解电路之间的标签分布差异。&lt;h4&gt;主要发现&lt;/h4&gt;在TSMC 28nm AMS设计中，CircuitGCL在寄生电容估计（边缘级任务）和接地电容分类（节点级任务）方面优于所有现有方法，边缘回归的$R^2$值提高了33.64%至44.20%，节点分类的F1分数提高了0.9倍至2.1倍。&lt;h4&gt;结论&lt;/h4&gt;CircuitGCL框架有效地解决了AMS电路表示学习中的挑战，显著提高了寄生估计的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning on Analog-Mixed Signal (AMS) circuits is crucial for various downstream tasks, e.g., parasitic estimation. However, the scarcity of design data, the unbalanced distribution of labels, and the inherent diversity of circuit implementations pose significant challenges to learning robust and transferable circuit representations. To address these limitations, we propose CircuitGCL, a novel graph contrastive learning framework that integrates representation scattering and label rebalancing to enhance transferability across heterogeneous circuit graphs. CircuitGCL employs a self-supervised strategy to learn topology-invariant node embeddings through hyperspherical representation scattering, eliminating dependency on large-scale data. Simultaneously, balanced mean squared error (MSE) and softmax cross-entropy (bsmCE) losses are introduced to mitigate label distribution disparities between circuits, enabling robust and transferable parasitic estimation. Evaluated on parasitic capacitance estimation (edge-level task) and ground capacitance classification (node-level task) across TSMC 28nm AMS designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the $R^2$ improvement of 33.64% ~ 44.20% for edge regression and F1-score gain of 0.9x ~ 2.1x for node classification. Our code is available at here.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning on Analog-Mixed Signal (AMS) circuits iscrucial for various downstream tasks, e.g., parasitic estimation. However, thescarcity of design data, the unbalanced distribution of labels, and theinherent diversity of circuit implementations pose significant challenges tolearning robust and transferable circuit representations. To address theselimitations, we propose CircuitGCL, a novel graph contrastive learningframework that integrates representation scattering and label rebalancing toenhance transferability across heterogeneous circuit graphs. CircuitGCL employsa self-supervised strategy to learn topology-invariant node embeddings throughhyperspherical representation scattering, eliminating dependency on large-scaledata. Simultaneously, balanced mean squared error (MSE) and softmaxcross-entropy (bsmCE) losses are introduced to mitigate label distributiondisparities between circuits, enabling robust and transferable parasiticestimation. Evaluated on parasitic capacitance estimation (edge-level task) andground capacitance classification (node-level task) across TSMC 28nm AMSdesigns, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the$R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-scoregain of $0.9\times \sim 2.1\times$ for node classification. Our code isavailable at\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.</description>
      <author>example@mail.com (Shan Shen, Shenglu Hua, Jiajun Zou, Jiawei Liu, Jianwang Zhai, Chuan Shi, Wenjian Yu)</author>
      <guid isPermaLink="false">2507.06535v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings</title>
      <link>http://arxiv.org/abs/2507.06506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了一种将英语双关语翻译成法语的新方法，结合了先进的语言模型和专门的双关语生成技术。&lt;h4&gt;背景&lt;/h4&gt;翻译双关语对人工翻译和机器翻译系统都是一个独特的挑战，长期以来一直困扰着两者。&lt;h4&gt;目的&lt;/h4&gt;该研究的主要目的是捕捉源文本双关语的言语创造性和幽默感，而不仅仅是复制其词汇。&lt;h4&gt;方法&lt;/h4&gt;采用三阶段方法：首先，使用多个前沿的大型语言模型建立基准；其次，实施一个带有语音-语义嵌入的引导思维链流程；最后，实现一个多智能体生成-判别框架来评估和再生双关语。&lt;h4&gt;主要发现&lt;/h4&gt;研究在CLEF JOKER 2025任务2竞赛中获得第一和第二名，该竞赛由专家母语法语人士手动评估。&lt;h4&gt;结论&lt;/h4&gt;通过实施语言信息化的双关语翻译技术，本文填补了翻译研究和计算语言学之间的差距，推进了我们对语言模型如何处理语义歧义、语音相似性和成功幽默所需的隐含文化和语言意识之间复杂互动的理解。&lt;h4&gt;翻译&lt;/h4&gt;提出了一种将英语双关语翻译成法语的新方法，结合了先进的大型语言模型和专门的双关语生成技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Translating wordplay across languages presents unique challenges that havelong confounded both professional human translators and machine translationsystems. This research proposes a novel approach for translating puns fromEnglish to French by combining state-of-the-art large language models withspecialized techniques for wordplay generation.  Our methodology employs a three-stage approach. First, we establish abaseline using multiple frontier large language models with feedback based on anew contrastive learning dataset. Second, we implement a guidedchain-of-thought pipeline with combined phonetic-semantic embeddings. Third, weimplement a multi-agent generator-discriminator framework for evaluating andregenerating puns with feedback.  Moving beyond the limitations of literal translation, our methodology'sprimary objective is to capture the linguistic creativity and humor of thesource text wordplay, rather than simply duplicating its vocabulary. Our bestruns earned first and second place in the CLEF JOKER 2025 Task 2 competitionwhere they were evaluated manually by expert native French speakers.  This research addresses a gap between translation studies and computationallinguistics by implementing linguistically-informed techniques for wordplaytranslation, advancing our understanding of how language models can beleveraged to handle the complex interplay between semantic ambiguity, phoneticsimilarity, and the implicit cultural and linguistic awareness needed forsuccessful humor.</description>
      <author>example@mail.com (Russell Taylor, Benjamin Herbert, Michael Sana)</author>
      <guid isPermaLink="false">2507.06506v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction</title>
      <link>http://arxiv.org/abs/2507.06538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of DAC2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CircuitGPS的少样本学习方法，用于预测模拟/混合信号（AMS）电路中的寄生效应。&lt;h4&gt;背景&lt;/h4&gt;Graph representation learning是一种从图结构数据中提取特征的有效方法，但训练深度学习模型用于AMS设计受到集成电路设计数据稀缺的限制。&lt;h4&gt;目的&lt;/h4&gt;旨在提高AMS电路中寄生效应预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;CircuitGPS将电路网表表示为异构图，将耦合电容建模为链接。该方法在链接预测上预训练，并在边回归上进行微调。使用小跳采样技术将链接或节点转换为子图，然后使用混合图Transformer学习子图嵌入。此外，CircuitGPS集成了一种低成本的定位编码，总结了采样子图的定位和结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;CircuitGPS提高了耦合存在性的准确性至少20%，与现有方法相比，减少了电容估计的MAE至少0.067。该方法显示出强大的内在可扩展性，通过零样本学习可以直接应用于不同的AMS电路设计。&lt;h4&gt;结论&lt;/h4&gt;CircuitGPS是一种有效的少样本学习方法，可以提高AMS电路中寄生效应预测的准确性，并且具有良好的可扩展性和适用性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CircuitGPS的少样本学习方法，用于预测模拟/混合信号（AMS）电路中的寄生效应。然而，由于集成电路设计数据的稀缺，训练深度学习模型用于AMS设计受到限制。本研究提出的方法CircuitGPS，将电路网表表示为异构图，并将耦合电容建模为链接。该方法在链接预测上进行预训练，并在边回归上进行微调。通过小跳采样技术将链接或节点转换为子图，并使用混合图Transformer学习子图嵌入。此外，CircuitGPS集成了一种低成本的定位编码，总结了采样子图的定位和结构信息。与现有方法相比，CircuitGPS提高了耦合存在性的准确性至少20%，并减少了电容估计的MAE至少0.067。该方法显示出强大的内在可扩展性，通过零样本学习可以直接应用于不同的AMS电路设计。此外，消融研究为图模型在表示学习中的应用提供了有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning is a powerful method to extract features fromgraph-structured data, such as analog/mixed-signal (AMS) circuits. However,training deep learning models for AMS designs is severely limited by thescarcity of integrated circuit design data. In this work, we presentCircuitGPS, a few-shot learning method for parasitic effect prediction in AMScircuits. The circuit netlist is represented as a heterogeneous graph, with thecoupling capacitance modeled as a link. CircuitGPS is pre-trained on linkprediction and fine-tuned on edge regression. The proposed method starts with asmall-hop sampling technique that converts a link or a node into a subgraph.Then, the subgraph embeddings are learned with a hybrid graph Transformer.Additionally, CircuitGPS integrates a low-cost positional encoding thatsummarizes the positional and structural information of the sampled subgraph.CircuitGPS improves the accuracy of coupling existence by at least 20\% andreduces the MAE of capacitance estimation by at least 0.067 compared toexisting methods. Our method demonstrates strong inherent scalability, enablingdirect application to diverse AMS circuit designs through zero-shot learning.Furthermore, the ablation studies provide valuable insights into graph modelsfor representation learning.</description>
      <author>example@mail.com (Shan Shen, Yibin Zhang, Hector Rodriguez Rodriguez, Wenjian Yu)</author>
      <guid isPermaLink="false">2507.06538v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>A Wireless Foundation Model for Multi-Task Prediction</title>
      <link>http://arxiv.org/abs/2507.05938v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于无线网络多任务预测的统一基础模型，该模型能够支持不同的预测区间，并在大规模数据集上展现出良好的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数（如信道状态信息、用户位置和网络流量）对于物理层和介质访问控制层的多种任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对传统深度学习方法在泛化能力上的不足，本文旨在提出一种能够支持多样预测区间的多任务预测模型。&lt;h4&gt;方法&lt;/h4&gt;该模型通过以下方式进行改进：1. 对异构任务进行单变量分解以统一任务；2. 编码粒度以实现区间感知；3. 使用因果Transformer主干结构进行精确预测；4. 在训练过程中引入补丁掩码策略以支持任意输入长度。&lt;h4&gt;主要发现&lt;/h4&gt;经过大规模数据集训练后，该基础模型在未见过的场景中表现出强大的泛化能力，并在新任务上实现了零样本性能，超越了传统的全样本基线。&lt;h4&gt;结论&lt;/h4&gt;本文提出的统一基础模型为无线网络中的多任务预测提供了一种有效的方法，有助于提高预测的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing complexity and dynamics of the mobile communicationnetworks, accurately predicting key system parameters, such as channel stateinformation (CSI), user location, and network traffic, has become essential fora wide range of physical (PHY)-layer and medium access control (MAC)-layertasks. Although traditional deep learning (DL)-based methods have been widelyapplied to such prediction tasks, they often struggle to generalize acrossdifferent scenarios and tasks. In response, we propose a unified foundationmodel for multi-task prediction in wireless networks that supports diverseprediction intervals. The proposed model enforces univariate decomposition tounify heterogeneous tasks, encodes granularity for interval awareness, and usesa causal Transformer backbone for accurate predictions. Additionally, weintroduce a patch masking strategy during training to support arbitrary inputlengths. After trained on large-scale datasets, the proposed foundation modeldemonstrates strong generalization to unseen scenarios and achieves zero-shotperformance on new tasks that surpass traditional full-shot baselines.</description>
      <author>example@mail.com (Yucheng Sheng, Jiacheng Wang, Xingyu Zhou, Le Liang, Hao Ye, Shi Jin, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2507.05938v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System</title>
      <link>http://arxiv.org/abs/2507.06397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2025 IEEE ICRA Workshop on Field Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种水下洞穴映射框架，用于淡水资源管理、水下考古和水文地质研究。&lt;h4&gt;背景&lt;/h4&gt;水下洞穴对于淡水资源管理、水下考古和水文地质研究至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在通过映射洞穴的轮廓和尺寸，以及创建逼真的3D地图，以更好地理解水下领域。&lt;h4&gt;方法&lt;/h4&gt;利用低成本动作相机和潜水电脑来估计相机轨迹和稀疏点云，生成洞穴通道的一维折叠图，并使用SVIn2框架观察z维度。使用COLMAP框架进行全局优化以生成密集重建。&lt;h4&gt;主要发现&lt;/h4&gt;使用动作相机可以构建洞穴地图的主要部分，通过SVIn2和COLMAP的结合，可以重建逼真的密集3D表示。&lt;h4&gt;结论&lt;/h4&gt;该研究验证了使用动作相机和SVIn2结合COLMAP进行水下洞穴映射的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种水下洞穴映射框架。水下洞穴对于淡水资源管理、水下考古和水文地质研究至关重要。通过使用低成本动作相机和潜水电脑来估计相机轨迹和稀疏点云，生成洞穴通道的一维折叠图，并使用SVIn2框架观察z维度。同时，使用COLMAP框架进行全局优化以生成密集重建。研究发现，使用动作相机可以构建洞穴地图的主要部分，并且通过SVIn2和COLMAP的结合，可以重建逼真的密集3D表示。该研究验证了使用动作相机和SVIn2结合COLMAP进行水下洞穴映射的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework for mapping underwater caves. Underwatercaves are crucial for fresh water resource management, underwater archaeology,and hydrogeology. Mapping the cave's outline and dimensions, as well ascreating photorealistic 3D maps, is critical for enabling a betterunderstanding of this underwater domain. In this paper, we present the mappingof an underwater cave segment (the catacombs) of the Devil's Eye cave system atGinnie Springs, FL. We utilized a set of inexpensive action cameras inconjunction with a dive computer to estimate the trajectories of the camerastogether with a sparse point cloud. The resulting reconstructions are utilizedto produce a one-dimensional retract of the cave passages in the form of theaverage trajectory together with the boundaries (top, bottom, left, and right).The use of the dive computer enables the observability of the z-dimension inaddition to the roll and pitch in a visual/inertial framework (SVIn2). Inaddition, the keyframes generated by SVIn2 together with the estimated cameraposes for select areas are used as input to a global optimization (bundleadjustment) framework -- COLMAP -- in order to produce a dense reconstructionof those areas. The same cave segment is manually surveyed using the MNemo V2instrument, providing an additional set of measurements validating the proposedapproach. It is worth noting that with the use of action cameras, the primarycomponents of a cave map can be constructed. Furthermore, with the utilizationof a global optimization framework guided by the results of VI-SLAM packageSVIn2, photorealistic dense 3D representations of selected areas can bereconstructed.</description>
      <author>example@mail.com (Michalis Chatzispyrou, Luke Horgan, Hyunkil Hwang, Harish Sathishchandra, Monika Roznere, Alberto Quattrini Li, Philippos Mordohai, Ioannis Rekleitis)</author>
      <guid isPermaLink="false">2507.06397v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models</title>
      <link>http://arxiv.org/abs/2507.03916v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appendix at:  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的幻灯片动画生成方法，通过发布首个公共数据集，并使用低秩自适应（LoRA）技术，提高了动画生成的质量。&lt;h4&gt;背景&lt;/h4&gt;现有的AI幻灯片生成工具缺乏动画支持，而现有的视觉语言模型在动画任务上存在困难，主要原因是缺乏公共数据集和有限的时序推理能力。&lt;h4&gt;目的&lt;/h4&gt;解决现有幻灯片动画生成工具的不足，提高动画生成的质量和效果。&lt;h4&gt;方法&lt;/h4&gt;发布首个公共数据集，包含12,000个自然语言描述、动画JSON文件和渲染视频，覆盖所有内置的PowerPoint效果。使用LoRA技术对Qwen-2.5-VL-7B进行微调，并在BLEU-4、ROUGE-L、SPICE和CODA指标上取得显著改进。&lt;h4&gt;主要发现&lt;/h4&gt;LoRA模型在BLEU-4、ROUGE-L和CODA-detail上分别提高了约60%、30%和显著改进，表明低秩自适应技术能够实现可靠的时序推理和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的公共数据集、LoRA增强模型和CODA指标为基于VLM的动态幻灯片生成提供了严格的标准和基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于视觉语言模型（VLM）的幻灯片动画生成方法，通过发布首个公共数据集，并使用低秩自适应（LoRA）技术，提高了动画生成的质量。现有的AI幻灯片生成工具缺乏动画支持，而现有的视觉语言模型在动画任务上存在困难，主要原因是缺乏公共数据集和有限的时序推理能力。解决现有幻灯片动画生成工具的不足，提高动画生成的质量和效果。发布首个公共数据集，包含12,000个自然语言描述、动画JSON文件和渲染视频，覆盖所有内置的PowerPoint效果。使用LoRA技术对Qwen-2.5-VL-7B进行微调，并在BLEU-4、ROUGE-L、SPICE和CODA指标上取得显著改进。LoRA模型在BLEU-4、ROUGE-L和CODA-detail上分别提高了约60%、30%和显著改进，表明低秩自适应技术能够实现可靠的时序推理和泛化能力。该研究提出的公共数据集、LoRA增强模型和CODA指标为基于VLM的动态幻灯片生成提供了严格的标准和基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Slide animations, such as fade-in, fly-in, and wipe, are critical foraudience engagement, efficient information delivery, and vivid visualexpression. However, most AI-driven slide-generation tools still lack nativeanimation support, and existing vision-language models (VLMs) struggle withanimation tasks due to the absence of public datasets and limitedtemporal-reasoning capabilities. To address this gap, we release the firstpublic dataset for slide-animation modeling: 12,000 triplets ofnatural-language descriptions, animation JSON files, and rendered videos,collectively covering every built-in PowerPoint effect. Using this resource, wefine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistentimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and ourCoverage-Order-Detail Assessment (CODA) metric, which evaluates actioncoverage, temporal order, and detail fidelity. On a manually created test setof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, andshows significant improvements in CODA-detail. This demonstrates that low-rankadaptation enables reliable temporal reasoning and generalization beyondsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metricprovide a rigorous benchmark and foundation for future research on VLM-baseddynamic slide generation.</description>
      <author>example@mail.com (Yifan Jiang, Yibo Xue, Yukun Kang, Pin Zheng, Jian Peng, Feiran Wu, Changliang Xu)</author>
      <guid isPermaLink="false">2507.03916v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning</title>
      <link>http://arxiv.org/abs/2507.06482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 Pages, ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为FedDifRC的新型联邦学习范式，旨在通过扩散模型的有意义指导来减轻数据异构性问题，以提高联邦学习中的模型收敛性和性能。&lt;h4&gt;背景&lt;/h4&gt;联邦学习旨在保护隐私的同时协同训练模型，但数据异构性问题是一个主要挑战，因为多个客户端的数据偏好偏差会损害模型的收敛性和性能。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用扩散表示来处理数据异构性问题，并提出一个基于扩散的联邦学习范式。&lt;h4&gt;方法&lt;/h4&gt;提出了文本驱动的扩散对比学习和噪声驱动的扩散正则化方法，以构建文本驱动的对比学习策略和噪声驱动的一致性正则化，以提供丰富的类相关语义信息和一致的收敛信号。&lt;h4&gt;主要发现&lt;/h4&gt;FedDifRC通过条件反馈和一致性正则化，在联邦学习中有效减轻了数据异构性问题，并且可以扩展为无需任何标记数据的自监督方案。&lt;h4&gt;结论&lt;/h4&gt;实验验证了FedDifRC的有效性和关键组件的效率，并提供了理论分析以确保在非凸目标下收敛。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在解决联邦学习中数据异构性问题，提出了一种名为FedDifRC的新范式，通过扩散模型指导减轻数据异构性，提高模型性能。该方法结合文本驱动的对比学习和噪声驱动的正则化，实现无标记数据的自监督学习，并通过理论分析保证了收敛性。实验验证了其有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning aims at training models collaboratively acrossparticipants while protecting privacy. However, one major challenge for thisparadigm is the data heterogeneity issue, where biased data preferences acrossmultiple clients, harming the model's convergence and performance. In thispaper, we first introduce powerful diffusion models into the federated learningparadigm and show that diffusion representations are effective steers duringfederated training. To explore the possibility of using diffusionrepresentations in handling data heterogeneity, we propose a noveldiffusion-inspired Federated paradigm with Diffusion RepresentationCollaboration, termed FedDifRC, leveraging meaningful guidance of diffusionmodels to mitigate data heterogeneity. The key idea is to construct text-drivendiffusion contrasting and noise-driven diffusion regularization, aiming toprovide abundant class-related semantic information and consistent convergencesignals. On the one hand, we exploit the conditional feedback from thediffusion model for different text prompts to build a text-driven contrastivelearning strategy. On the other hand, we introduce a noise-driven consistencyregularization to align local instances with diffusion denoisingrepresentations, constraining the optimization region in the feature space. Inaddition, FedDifRC can be extended to a self-supervised scheme without relyingon any labeled data. We also provide a theoretical analysis for FedDifRC toensure convergence under non-convex objectives. The experiments on differentscenarios validate the effectiveness of FedDifRC and the efficiency of crucialcomponents.</description>
      <author>example@mail.com (Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen)</author>
      <guid isPermaLink="false">2507.06482v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease</title>
      <link>http://arxiv.org/abs/2507.05656v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CoPath（计算病理学）在提高临床病理诊断的精确性和可重复性方面的应用，并提出了一个新的数据集ADPv2，用于胃肠道病理学的研究。&lt;h4&gt;背景&lt;/h4&gt;目前，标注有详细组织类型（HTT）分类的公开CoPath数据集非常稀缺，因为需要大量的专业知识和高成本。&lt;h4&gt;目的&lt;/h4&gt;提出ADPv2数据集，专注于胃肠道病理学，以提高对特定器官疾病的研究深度。&lt;h4&gt;方法&lt;/h4&gt;构建了包含20,004个图像块的数据集，这些图像块来自健康结肠活检切片，并按照32个不同组织类型的3级层次分类进行标注。使用VMamba架构训练了一个多标签表示学习模型，并在ADPv2数据集上实现了两阶段训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集能够进行器官特定的深入研究，有助于发现潜在生物标志物。通过分析模型对不同结肠疾病影响的组织预测行为，揭示了统计模式，证实了结肠癌发展的两种病理途径。&lt;h4&gt;结论&lt;/h4&gt;ADPv2数据集为胃肠道病理学研究提供了新的资源，有助于提高结肠HTT的多标签分类性能，并支持对结肠癌发展的深入理解。&lt;h4&gt;翻译&lt;/h4&gt;Computational pathology (CoPath) uses histopathology images to enhance diagnostic precision and reproducibility in clinical pathology. However, publicly available datasets for CoPath that are annotated with extensive histological tissue type (HTT) taxonomies at a granular level remain scarce due to the significant expertise and high annotation costs required. Existing datasets, such as the Atlas of Digital Pathology (ADP), address this by offering diverse HTT annotations generalized to multiple organs, but limit the capability for in-depth studies on specific organ diseases. Building upon this foundation, we introduce ADPv2, a novel dataset focused on gastrointestinal histopathology. Our dataset comprises 20,004 image patches derived from healthy colon biopsy slides, annotated according to a hierarchical taxonomy of 32 distinct HTTs of 3 levels. Furthermore, we train a multilabel representation learning model following a two-stage training procedure on our ADPv2 dataset. We leverage the VMamba architecture and achieving a mean average precision (mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that our dataset is capable of an organ-specific in-depth study for potential biomarker discovery by analyzing the model's prediction behavior on tissues affected by different colon diseases, which reveals statistical patterns that confirm the two pathological pathways of colon cancer development. Our dataset is publicly available at https://zenodo.org/records/15307021.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational pathology (CoPath) leverages histopathology images to enhancediagnostic precision and reproducibility in clinical pathology. However,publicly available datasets for CoPath that are annotated with extensivehistological tissue type (HTT) taxonomies at a granular level remain scarce dueto the significant expertise and high annotation costs required. Existingdatasets, such as the Atlas of Digital Pathology (ADP), address this byoffering diverse HTT annotations generalized to multiple organs, but limit thecapability for in-depth studies on specific organ diseases. Building upon thisfoundation, we introduce ADPv2, a novel dataset focused on gastrointestinalhistopathology. Our dataset comprises 20,004 image patches derived from healthycolon biopsy slides, annotated according to a hierarchical taxonomy of 32distinct HTTs of 3 levels. Furthermore, we train a multilabel representationlearning model following a two-stage training procedure on our ADPv2 dataset.We leverage the VMamba architecture and achieving a mean average precision(mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show thatour dataset is capable of an organ-specific in-depth study for potentialbiomarker discovery by analyzing the model's prediction behavior on tissuesaffected by different colon diseases, which reveals statistical patterns thatconfirm the two pathological pathways of colon cancer development. Our datasetis publicly available at https://zenodo.org/records/15307021</description>
      <author>example@mail.com (Zhiyuan Yang, Kai Li, Sophia Ghamoshi Ramandi, Patricia Brassard, Hakim Khellaf, Vincent Quoc-Huy Trinh, Jennifer Zhang, Lina Chen, Corwyn Rowsell, Sonal Varma, Kostas Plataniotis, Mahdi S. Hosseini)</author>
      <guid isPermaLink="false">2507.05656v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework</title>
      <link>http://arxiv.org/abs/2507.05814v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于生成3D桥梁数据的系统框架，旨在解决桥梁基础设施老化与退化带来的挑战，以及传统手动检测方法的低效问题。&lt;h4&gt;背景&lt;/h4&gt;桥梁作为关键交通基础设施，面临着老化与退化的挑战，而传统的手动检测方法效率低下。3D点云技术虽然提供了新的数据驱动范式，但其应用潜力常受到现实数据不完整性的限制。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有合成数据方法中泛化不足的瓶颈，本文提出了一个系统框架，用于生成具有组件级实例注释、高保真颜色和精确法向量的完整点云。&lt;h4&gt;方法&lt;/h4&gt;该框架能够自动生成完整的点云，并可以扩展以模拟创建各种多样且物理上真实的不完整点云，以支持分割和完成网络的训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用本文合成的数据进行训练的PointNet++模型在现实世界桥梁语义分割中实现了平均交并比（mIoU）为84.2%。同时，经过微调的KT-Net在组件完成任务上表现出色。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一种创新的方法和基础数据集，用于桥梁结构的3D视觉分析，对基础设施的自动化管理和维护具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;As critical transportation infrastructure, bridges face escalating challenges from aging and deterioration, while traditional manual inspection methods suffer from low efficiency. Although 3D point cloud technology provides a new data-driven paradigm, its application potential is often constrained by the incompleteness of real-world data, which results from missing labels and scanning occlusions. To overcome the bottleneck of insufficient generalization in existing synthetic data methods, this paper proposes a systematic framework for generating 3D bridge data. This framework can automatically generate complete point clouds featuring component-level instance annotations, high-fidelity color, and precise normal vectors. It can be further extended to simulate the creation of diverse and physically realistic incomplete point clouds, designed to support the training of segmentation and completion networks, respectively. Experiments demonstrate that a PointNet++ model trained with our synthetic data achieves a mean Intersection over Union (mIoU) of 84.2% in real-world bridge semantic segmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance on the component completion task. This research offers an innovative methodology and a foundational dataset for the 3D visual analysis of bridge structures, holding significant implications for advancing the automated management and maintenance of infrastructure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As critical transportation infrastructure, bridges face escalating challengesfrom aging and deterioration, while traditional manual inspection methodssuffer from low efficiency. Although 3D point cloud technology provides a newdata-driven paradigm, its application potential is often constrained by theincompleteness of real-world data, which results from missing labels andscanning occlusions. To overcome the bottleneck of insufficient generalizationin existing synthetic data methods, this paper proposes a systematic frameworkfor generating 3D bridge data.  This framework can automatically generate complete point clouds featuringcomponent-level instance annotations, high-fidelity color, and precise normalvectors. It can be further extended to simulate the creation of diverse andphysically realistic incomplete point clouds, designed to support the trainingof segmentation and completion networks, respectively. Experiments demonstratethat a PointNet++ model trained with our synthetic data achieves a meanIntersection over Union (mIoU) of 84.2% in real-world bridge semanticsegmentation. Concurrently, a fine-tuned KT-Net exhibits superior performanceon the component completion task.  This research offers an innovative methodology and a foundational dataset forthe 3D visual analysis of bridge structures, holding significant implicationsfor advancing the automated management and maintenance of infrastructure.</description>
      <author>example@mail.com (Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka Narazaki, Xuguang Wang)</author>
      <guid isPermaLink="false">2507.05814v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</title>
      <link>http://arxiv.org/abs/2507.01945v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LongAnimation的自动化长动画着色框架，旨在提高动画工业生产中着色环节的效率。&lt;h4&gt;背景&lt;/h4&gt;长动画着色在动画工业中至关重要，但手工着色成本高昂，因此自动化着色具有重大研究价值。&lt;h4&gt;目的&lt;/h4&gt;针对现有研究主要针对短时着色，且局部范式忽略全局信息的局限性，本研究旨在通过动态全局-局部范式实现长动画的理想色彩一致性。&lt;h4&gt;方法&lt;/h4&gt;LongAnimation框架主要包括SketchDiT、Dynamic Global-Local Memory (DGLM)和Color Consistency Reward模块。SketchDiT捕获混合参考特征以支持DGLM模块，DGLM模块利用长视频理解模型动态压缩全局历史特征，并自适应地与当前生成特征融合。此外，为了提高色彩一致性，引入了Color Consistency Reward，并在推理过程中提出了一种色彩一致性融合方法以平滑视频片段的过渡。&lt;h4&gt;主要发现&lt;/h4&gt;在短期（14帧）和长期（平均500帧）动画的广泛实验中，LongAnimation在保持开放域动画着色任务中的短期和长期色彩一致性方面表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;LongAnimation框架通过动态全局-局部范式，有效地提高了长动画着色的色彩一致性。&lt;h4&gt;翻译&lt;/h4&gt;Animation colorization is a crucial part of real animation industry production. Long animation colorization has high labor costs. Therefore, automated long animation colorization based on the video generation model has significant research value. Existing studies are limited to short-term colorization. These studies adopt a local paradigm, fusing overlapping features to achieve smooth transitions between local segments. However, the local paradigm neglects global information, failing to maintain long-term color consistency. In this study, we argue that ideal long-term color consistency can be achieved through a dynamic global-local paradigm, i.e., dynamically extracting global color-consistent features relevant to the current generation. Specifically, we propose LongAnimation, a novel framework, which mainly includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color Consistency Reward. The SketchDiT captures hybrid reference features to support the DGLM module. The DGLM module employs a long video understanding model to dynamically compress global historical features and adaptively fuse them with the current generation features. To refine the color consistency, we introduce a Color Consistency Reward. During inference, we propose a color consistency fusion to smooth the video segment transition. Extensive experiments on both short-term (14 frames) and long-term (average 500 frames) animations show the effectiveness of LongAnimation in maintaining short-term and long-term color consistency for open-domain animation colorization task. The code can be found at https://cn-makers.github.io/long_animation_web/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animation colorization is a crucial part of real animation industryproduction. Long animation colorization has high labor costs. Therefore,automated long animation colorization based on the video generation model hassignificant research value. Existing studies are limited to short-termcolorization. These studies adopt a local paradigm, fusing overlapping featuresto achieve smooth transitions between local segments. However, the localparadigm neglects global information, failing to maintain long-term colorconsistency. In this study, we argue that ideal long-term color consistency canbe achieved through a dynamic global-local paradigm, i.e., dynamicallyextracting global color-consistent features relevant to the current generation.Specifically, we propose LongAnimation, a novel framework, which mainlyincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a ColorConsistency Reward. The SketchDiT captures hybrid reference features to supportthe DGLM module. The DGLM module employs a long video understanding model todynamically compress global historical features and adaptively fuse them withthe current generation features. To refine the color consistency, we introducea Color Consistency Reward. During inference, we propose a color consistencyfusion to smooth the video segment transition. Extensive experiments on bothshort-term (14 frames) and long-term (average 500 frames) animations show theeffectiveness of LongAnimation in maintaining short-term and long-term colorconsistency for open-domain animation colorization task. The code can be foundat https://cn-makers.github.io/long_animation_web/.</description>
      <author>example@mail.com (Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao)</author>
      <guid isPermaLink="false">2507.01945v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Tissue Concepts v2: A Supervised Foundation Model For Whole Slide Images</title>
      <link>http://arxiv.org/abs/2507.05742v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Tissue Concepts v2（TCv2）的监督式基础模型，用于分析组织病理学图像，该模型在资源密集型的训练过程中表现出了优越的性能。&lt;h4&gt;背景&lt;/h4&gt;计算病理学领域正受到基础模型（FMs）的变革性影响，这些模型通过分析组织病理学图像提供了新的方法。然而，创建FMs的过程通常需要在大数据库上训练数周，这是一个资源密集型的过程。&lt;h4&gt;目的&lt;/h4&gt;旨在通过扩展Tissue Concepts模型到全切片图像来解决这个问题，并开发一个能够高效训练的监督式基础模型。&lt;h4&gt;方法&lt;/h4&gt;TCv2采用在切片级别标签上的监督式、端到端多任务学习。其训练过程相对于自监督训练仅需使用一小部分训练资源。&lt;h4&gt;主要发现&lt;/h4&gt;TCv2在癌症亚型基准测试中展现出优于自监督训练模型的性能，且完全使用免费数据训练。此外，共享的训练注意力模块为不同任务提供了解释性的额外层次。&lt;h4&gt;结论&lt;/h4&gt;TCv2是一个高效的监督式基础模型，能够有效地处理组织病理学图像，并在资源消耗上具有优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) are transforming the field of computational pathologyby offering new approaches to analyzing histopathology images. Typicallyrelying on weeks of training on large databases, the creation of FMs is aresource-intensive process in many ways. In this paper, we introduce theextension of our supervised foundation model, Tissue Concepts, to whole slideimages, called Tissue Concepts v2 (TCv2), a supervised foundation model forwhole slide images to address the issue above. TCv2 uses supervised, end-to-endmultitask learning on slide-level labels. Training TCv2 uses a fraction of thetraining resources compared to self-supervised training. The presented modelshows superior performance compared to SSL-trained models in cancer subtypingbenchmarks and is fully trained on freely available data. Furthermore, a sharedtrained attention module provides an additional layer of explainability acrossdifferent tasks.</description>
      <author>example@mail.com (Till Nicke, Daniela Schacherer, Jan Raphael Schäfer, Natalia Artysh, Antje Prasse, André Homeyer, Andrea Schenk, Henning Höfener, Johannes Lotz)</author>
      <guid isPermaLink="false">2507.05742v2</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems</title>
      <link>http://arxiv.org/abs/2507.06258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Federated recommender systems (FedRec)在保护用户隐私的同时提供个性化推荐，但易受poisoning攻击。本研究提出了一种针对特定用户子组的攻击方法Spattack，通过模拟用户嵌入和优化推荐策略来操纵推荐结果。&lt;h4&gt;背景&lt;/h4&gt;现有的poisoning攻击通常针对整个用户群体，降低了攻击的隐蔽性和安全性。&lt;h4&gt;目的&lt;/h4&gt;针对现有攻击的不足，提出一种针对特定用户子组的攻击方法，以增强推荐的隐蔽性和安全性。&lt;h4&gt;方法&lt;/h4&gt;Spattack采用两阶段策略：首先通过对比学习和聚类方法模拟目标和非目标子组的用户嵌入，然后通过自适应调整优化权重和嵌入对齐策略，将目标物品推荐给目标子组。&lt;h4&gt;主要发现&lt;/h4&gt;Spattack在特定用户子组上表现出强大的操纵性能，对非目标用户影响最小，即使在只有0.1%的用户是恶意用户的情况下。同时，Spattack保持了竞争力的推荐性能，并对现有主流防御机制具有强大的抵抗力。&lt;h4&gt;结论&lt;/h4&gt;Spattack是一种有效的针对特定用户子组的攻击方法，能够在保护用户隐私的同时实现个性化的推荐。&lt;h4&gt;翻译&lt;/h4&gt;Federated推荐系统（FedRec）作为在保护用户隐私的同时提供个性化推荐的有希望解决方案，然而，最近的研究表明，它们容易受到poisoning攻击。现有的攻击通常针对整个用户群体，这会降低攻击的隐蔽性和增加被检测到的风险。相比之下，现实世界的对手可能更倾向于针对特定的用户子组，例如向老年用户提供健康补充品的推荐。受此启发，我们引入了Spattack，这是第一个旨在在联邦环境中操纵特定用户子组推荐的针对性poisoning攻击。具体来说，Spattack采用两阶段近似和提升策略，首先模拟目标/非目标子组的用户嵌入，然后将目标物品推荐给目标子组。为了增强近似阶段，我们基于对比学习将组间嵌入推开，并基于聚类增强目标组的相关物品集。为了增强提升阶段，我们进一步提出自适应调整目标和非目标子组之间优化权重的策略。此外，还提出了一种嵌入对齐策略，以对齐目标物品和相关物品之间的嵌入。我们在三个真实世界数据集上进行了全面的实验，将Spattack与七种最先进的poisoning攻击和七种代表性的防御机制进行了比较。实验结果表明，Spattack在特定用户子组上始终表现出强大的操纵性能，同时对非目标用户的影响最小，即使只有0.1%的用户是恶意用户。此外，Spattack保持了具有竞争力的整体推荐性能，并表现出对现有主流防御机制的抗性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated recommender systems (FedRec) have emerged as a promising solutionfor delivering personalized recommendations while safeguarding user privacy.However, recent studies have demonstrated their vulnerability to poisoningattacks. Existing attacks typically target the entire user group, whichcompromises stealth and increases the risk of detection. In contrast,real-world adversaries may prefer to prompt target items to specific usersubgroups, such as recommending health supplements to elderly users. Motivatedby this gap, we introduce Spattack, the first targeted poisoning attackdesigned to manipulate recommendations for specific user subgroups in thefederated setting. Specifically, Spattack adopts a two-stageapproximation-and-promotion strategy, which first simulates user embeddings oftarget/non-target subgroups and then prompts target items to the targetsubgroups. To enhance the approximation stage, we push the inter-groupembeddings away based on contrastive learning and augment the target group'srelevant item set based on clustering. To enhance the promotion stage, wefurther propose to adaptively tune the optimization weights between target andnon-target subgroups. Besides, an embedding alignment strategy is proposed toalign the embeddings between the target items and the relevant items. Weconduct comprehensive experiments on three real-world datasets, comparingSpattack against seven state-of-the-art poisoning attacks and sevenrepresentative defense mechanisms. Experimental results demonstrate thatSpattack consistently achieves strong manipulation performance on the specificuser subgroup, while incurring minimal impact on non-target users, even whenonly 0.1\% of users are malicious. Moreover, Spattack maintains competitiveoverall recommendation performance and exhibits strong resilience againstexisting mainstream defenses.</description>
      <author>example@mail.com (Bo Yan, Yurong Hao, Dingqi Liu, Huabin Sun, Pengpeng Qiao, Wei Yang Bryan Lim, Yang Cao, Chuan Shi)</author>
      <guid isPermaLink="false">2507.06258v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments</title>
      <link>http://arxiv.org/abs/2507.06564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, has been accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了SkyVLN，一个结合视觉和语言导航（VLN）与非线性模型预测控制（NMPC）的框架，旨在提高无人机在复杂城市环境中的自主导航能力。&lt;h4&gt;背景&lt;/h4&gt;无人机因其移动性和适应性在各个领域得到了广泛应用。&lt;h4&gt;目的&lt;/h4&gt;通过引入SkyVLN，提高无人机在动态3D空间中的导航精度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;SkyVLN利用大型语言模型（LLMs）解释自然语言指令和视觉观察，并配备精细的空间语言化器和历史路径记忆机制，以解决空间上下文歧义、处理模糊指令并在必要时回溯。此外，框架还集成了NMPC模块，用于动态避障，确保精确的轨迹跟踪和碰撞预防。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用AirSim开发的高保真3D城市模拟环境进行的实验表明，SkyVLN显著提高了导航的成功率和效率，尤其是在新和未见过的环境中。&lt;h4&gt;结论&lt;/h4&gt;SkyVLN框架能够有效提升无人机在复杂城市环境中的自主导航能力，为无人机在未知环境中的导航提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools acrossvarious sectors, driven by their mobility and adaptability. This paperintroduces SkyVLN, a novel framework integrating vision-and-language navigation(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy incomplex urban environments. Unlike traditional navigation methods, SkyVLNleverages Large Language Models (LLMs) to interpret natural languageinstructions and visual observations, enabling UAVs to navigate through dynamic3D spaces with improved accuracy and robustness. We present a multimodalnavigation agent equipped with a fine-grained spatial verbalizer and a historypath memory mechanism. These components allow the UAV to disambiguate spatialcontexts, handle ambiguous instructions, and backtrack when necessary. Theframework also incorporates an NMPC module for dynamic obstacle avoidance,ensuring precise trajectory tracking and collision prevention. To validate ourapproach, we developed a high-fidelity 3D urban simulation environment usingAirSim, featuring realistic imagery and dynamic urban elements. Extensiveexperiments demonstrate that SkyVLN significantly improves navigation successrates and efficiency, particularly in new and unseen environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools acrossvarious sectors, driven by their mobility and adaptability. This paperintroduces SkyVLN, a novel framework integrating vision-and-language navigation(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy incomplex urban environments. Unlike traditional navigation methods, SkyVLNleverages Large Language Models (LLMs) to interpret natural languageinstructions and visual observations, enabling UAVs to navigate through dynamic3D spaces with improved accuracy and robustness. We present a multimodalnavigation agent equipped with a fine-grained spatial verbalizer and a historypath memory mechanism. These components allow the UAV to disambiguate spatialcontexts, handle ambiguous instructions, and backtrack when necessary. Theframework also incorporates an NMPC module for dynamic obstacle avoidance,ensuring precise trajectory tracking and collision prevention. To validate ourapproach, we developed a high-fidelity 3D urban simulation environment usingAirSim, featuring realistic imagery and dynamic urban elements. Extensiveexperiments demonstrate that SkyVLN significantly improves navigation successrates and efficiency, particularly in new and unseen environments.</description>
      <author>example@mail.com (Tianshun Li, Tianyi Huai, Zhen Li, Yichun Gao, Haoang Li, Xinhu Zheng)</author>
      <guid isPermaLink="false">2507.06564v1</guid>
      <pubDate>Thu, 10 Jul 2025 14:21:57 +0800</pubDate>
    </item>
    <item>
      <title>CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions</title>
      <link>http://arxiv.org/abs/2507.06210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, COLM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了预训练视觉语言模型（VLMs）在多模态理解上的优势，以及它们在处理视觉相似但文化上有区别的概念时的局限性。提出了一种通过数据合成和模型训练来增强文化概念识别的方法。&lt;h4&gt;背景&lt;/h4&gt;预训练视觉语言模型（如CLIP）在多模态理解上表现优秀，但在处理具有细微文化差异的视觉概念时存在困难。&lt;h4&gt;目的&lt;/h4&gt;旨在通过数据合成和模型训练，增强模型对文化概念的识别能力。&lt;h4&gt;方法&lt;/h4&gt;设计了数据整理流程，利用开源VLMs和文本到图像扩散模型构建了CulTwin数据集，该数据集包含视觉相似但文化背景不同的概念-标题-图像三元组。在CulTwin上微调CLIP，创建CultureCLIP，通过定制对比学习，使文化概念与情境增强的标题和合成图像对齐，从而实现更精细的文化区分。&lt;h4&gt;主要发现&lt;/h4&gt;在文化相关基准测试中，CultureCLIP在细粒度概念识别任务上优于基础CLIP，在某些任务上实现了高达5.49%的改进，同时保持了CLIP的原始泛化能力。&lt;h4&gt;结论&lt;/h4&gt;数据合成和VLM骨干训练范式在捕捉细微文化差异方面是有效的，CultureCLIP在文化概念识别方面表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained vision-language models (VLMs) such as CLIP excel in multimodalunderstanding but struggle with contextually relevant fine-grained visualfeatures, making it difficult to distinguish visually similar yet culturallydistinct concepts. This limitation stems from the scarcity of high-qualityculture-specific datasets, the lack of integrated contextual knowledge, and theabsence of hard negatives highlighting subtle distinctions. To address thesechallenges, we first design a data curation pipeline that leveragesopen-sourced VLMs and text-to-image diffusion models to construct CulTwin, asynthetic cultural dataset. This dataset consists of pairedconcept-caption-image triplets, where concepts visually resemble each other butrepresent different cultural contexts. Then, we fine-tune CLIP on CulTwin tocreate CultureCLIP, which aligns cultural concepts with contextually enhancedcaptions and synthetic images through customized contrastive learning, enablingfiner cultural differentiation while preserving generalization capabilities.Experiments on culturally relevant benchmarks show that CultureCLIP outperformsthe base CLIP, achieving up to a notable 5.49% improvement in fine-grainedconcept recognition on certain tasks, while preserving CLIP's originalgeneralization ability, validating the effectiveness of our data synthesis andVLM backbone training paradigm in capturing subtle cultural distinctions.</description>
      <author>example@mail.com (Yuchen Huang, Zhiyuan Fan, Zhitao He, Sandeep Polisetty, Wenyan Li, Yi R. Fung)</author>
      <guid isPermaLink="false">2507.06210v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
  <item>
      <title>Normalizing Diffusion Kernels with Optimal Transport</title>
      <link>http://arxiv.org/abs/2507.06161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 25 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于局部邻域的信号平滑方法，该方法在机器学习和几何处理中至关重要。&lt;h4&gt;背景&lt;/h4&gt;在结构良好的领域，如向量空间和流形，微分几何导出的拉普拉斯算子为通过热扩散进行平滑提供了理论上的保证。然而，构建这样的拉普拉斯算子需要仔细定义的域结构，这并不总是可用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，本文引入了一类广泛的平滑算子，这些算子来自广义相似度或邻接矩阵，并证明了它们可以被归一化为继承拉普拉斯算子良好性质的扩散算子。&lt;h4&gt;方法&lt;/h4&gt;该方法依赖于Sinkhorn算法的对称变体，通过重新缩放正平滑算子来匹配热扩散的结构行为。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的算子不仅近似热扩散，而且保留了拉普拉斯算子的光谱信息，适用于形状分析和匹配。&lt;h4&gt;结论&lt;/h4&gt;该研究为不规则数据（如点云、稀疏体素网格或高斯混合物）的拉普拉斯算子类似平滑和加工提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a signal smoothing method based on local neighborhoods, which is crucial in machine learning and geometric processing. In well-structured domains such as vector spaces and manifolds, the Laplace operator derived from differential geometry offers a principled approach to smoothing via heat diffusion, with strong theoretical guarantees. However, constructing such Laplacians requires a carefully defined domain structure, which is not always available. To address this issue, the paper introduces a broad class of smoothing operators derived from general similarity or adjacency matrices, and demonstrates that they can be normalized into diffusion-like operators that inherit desirable properties from Laplacians. The method relies on a symmetric variant of the Sinkhorn algorithm, which rescales positive smoothing operators to match the structural behavior of heat diffusion. The proposed operators not only approximate heat diffusion but also retain spectral information from the Laplacian itself, with applications to shape analysis and matching. This research provides an effective method for Laplacian-like smoothing and processing of irregular data such as point clouds, sparse voxel grids, or a mixture of Gaussians.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smoothing a signal based on local neighborhoods is a core operation inmachine learning and geometry processing. On well-structured domains such asvector spaces and manifolds, the Laplace operator derived from differentialgeometry offers a principled approach to smoothing via heat diffusion, withstrong theoretical guarantees. However, constructing such Laplacians requires acarefully defined domain structure, which is not always available. Mostpractitioners thus rely on simple convolution kernels and message-passinglayers, which are biased against the boundaries of the domain. We bridge thisgap by introducing a broad class of smoothing operators, derived from generalsimilarity or adjacency matrices, and demonstrate that they can be normalizedinto diffusion-like operators that inherit desirable properties fromLaplacians. Our approach relies on a symmetric variant of the Sinkhornalgorithm, which rescales positive smoothing operators to match the structuralbehavior of heat diffusion. This construction enables Laplacian-like smoothingand processing of irregular data such as point clouds, sparse voxel grids ormixture of Gaussians. We show that the resulting operators not only approximateheat diffusion but also retain spectral information from the Laplacian itself,with applications to shape analysis and matching.</description>
      <author>example@mail.com (Nathan Kessler, Robin Magnet, Jean Feydy)</author>
      <guid isPermaLink="false">2507.06161v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion</title>
      <link>http://arxiv.org/abs/2507.06230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at ICCV 2025. Christoph Reich and Aleksandar Jevti\'c -  both authors contributed equally. Code:  https://github.com/tum-vision/scenedino Project page:  https://visinf.github.io/scenedino&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SceneDINO的无监督语义场景补全方法，旨在从单张图像中推断场景的3D几何和语义。&lt;h4&gt;背景&lt;/h4&gt;传统的语义场景补全方法依赖于昂贵的真实标注数据，而本文提出的方法在不依赖标注数据的情况下进行。&lt;h4&gt;目的&lt;/h4&gt;提高语义场景补全的效率和准确性，实现无监督的场景理解。&lt;h4&gt;方法&lt;/h4&gt;SceneDINO结合了自监督表征学习和2D无监督场景理解技术，通过多视角一致性自监督进行训练，并在前馈模式下推断3D几何和3D DINO特征。此外，采用了一种新的3D特征蒸馏方法来获得无监督的3D语义。&lt;h4&gt;主要发现&lt;/h4&gt;SceneDINO在3D和2D无监督场景理解中达到了最先进的分割精度，其3D特征的线性探测结果与当前监督的语义场景补全方法的分割精度相当。此外，SceneDINO展示了领域泛化和多视角一致性的能力。&lt;h4&gt;结论&lt;/h4&gt;SceneDINO为单图像3D场景理解提供了一个强大的基础，并有望推动该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic scene completion (SSC) aims to infer both the 3D geometry andsemantics of a scene from single images. In contrast to prior work on SSC thatheavily relies on expensive ground-truth annotations, we approach SSC in anunsupervised setting. Our novel method, SceneDINO, adapts techniques fromself-supervised representation learning and 2D unsupervised scene understandingto SSC. Our training exclusively utilizes multi-view consistencyself-supervision without any form of semantic or geometric ground truth. Givena single input image, SceneDINO infers the 3D geometry and expressive 3D DINOfeatures in a feed-forward manner. Through a novel 3D feature distillationapproach, we obtain unsupervised 3D semantics. In both 3D and 2D unsupervisedscene understanding, SceneDINO reaches state-of-the-art segmentation accuracy.Linear probing our 3D features matches the segmentation accuracy of a currentsupervised SSC approach. Additionally, we showcase the domain generalizationand multi-view consistency of SceneDINO, taking the first steps towards astrong foundation for single image 3D scene understanding.</description>
      <author>example@mail.com (Aleksandar Jevtić, Christoph Reich, Felix Wimbauer, Oliver Hahn, Christian Rupprecht, Stefan Roth, Daniel Cremers)</author>
      <guid isPermaLink="false">2507.06230v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>RSRefSeg 2: Decoupling Referring Remote Sensing Image Segmentation with Foundation Models</title>
      <link>http://arxiv.org/abs/2507.06231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;RSRefSeg 2 是一种针对遥感图像分割的灵活且细粒度的框架，通过视觉-语言协同解释进行遥感场景分析。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感图像分割方法主要采用三阶段流程，包括双模态编码、跨模态交互和像素解码，但存在处理复杂语义关系和精确跨模态对齐的局限性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了 RSRefSeg 2，它通过解耦范式将传统工作流程重构为协作双阶段框架：粗定位随后是细分割。&lt;h4&gt;方法&lt;/h4&gt;RSRefSeg 2 通过战略性地合作基础模型，结合 CLIP 的跨模态对齐强度和 SAM 的分割泛化能力。CLIP 作为双模态编码器，用于激活其预对齐语义空间内的目标特征并生成定位提示。为了减轻 CLIP 在多实体场景中的误激活问题，设计了一个级联的二阶提示器，通过将文本嵌入分解为互补语义子空间来增强精度。优化后的语义提示随后指导 SAM 生成像素级精细掩码，从而完成语义传输管道。&lt;h4&gt;主要发现&lt;/h4&gt;RSRefSeg 2 在分割精度（+~3% gIoU）和复杂语义解释方面优于当代方法。&lt;h4&gt;结论&lt;/h4&gt;RSRefSeg 2 是一种有效的遥感图像分割方法，通过优化语义提示和模型协作，提高了分割准确性和复杂语义解释能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Referring Remote Sensing Image Segmentation 提供了一种灵活且细粒度的框架，通过视觉-语言协同解释进行遥感场景分析。当前方法主要采用包含双模态编码、跨模态交互和像素解码的三阶段流程。这些方法在处理复杂语义关系和实现精确跨模态对齐方面存在显著局限性，很大程度上是由于它们耦合的处理机制将目标定位与边界描绘混淆在一起。这种架构耦合放大了语义模糊性下的错误传播，同时限制了模型的泛化性和可解释性。为了解决这些问题，我们提出了 RSRefSeg 2，一种解耦范式，它将传统工作流程重新构造成协作双阶段框架：粗定位随后是细分割。RSRefSeg 2 通过战略性地合作基础模型，结合 CLIP 的跨模态对齐强度和 SAM 的分割泛化能力。具体来说，CLIP 被用作双模态编码器，以激活其预对齐语义空间内的目标特征并生成定位提示。为了减轻 CLIP 在由参考文本描述的多实体场景中的误激活问题，设计了一个级联的二阶提示器，通过将文本嵌入分解为互补语义子空间来增强精度。这些优化的语义提示随后指导 SAM 生成像素级精细掩码，从而完成语义传输管道。大量的实验（RefSegRS、RRSIS-D 和 RISBench）表明，RSRefSeg 2 在分割精度（+~3% gIoU）和复杂语义解释方面超过了当代方法。代码可在 https://github.com/KyanChen/RSRefSeg2 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring Remote Sensing Image Segmentation provides a flexible andfine-grained framework for remote sensing scene analysis via vision-languagecollaborative interpretation. Current approaches predominantly utilize athree-stage pipeline encompassing dual-modal encoding, cross-modal interaction,and pixel decoding. These methods demonstrate significant limitations inmanaging complex semantic relationships and achieving precise cross-modalalignment, largely due to their coupled processing mechanism that conflatestarget localization with boundary delineation. This architectural couplingamplifies error propagation under semantic ambiguity while restricting modelgeneralizability and interpretability. To address these issues, we proposeRSRefSeg 2, a decoupling paradigm that reformulates the conventional workflowinto a collaborative dual-stage framework: coarse localization followed by finesegmentation. RSRefSeg 2 integrates CLIP's cross-modal alignment strength withSAM's segmentation generalizability through strategic foundation modelcollaboration. Specifically, CLIP is employed as the dual-modal encoder toactivate target features within its pre-aligned semantic space and generatelocalization prompts. To mitigate CLIP's misactivation challenges inmulti-entity scenarios described by referring texts, a cascaded second-orderprompter is devised, which enhances precision through implicit reasoning viadecomposition of text embeddings into complementary semantic subspaces. Theseoptimized semantic prompts subsequently direct the SAM to generate pixel-levelrefined masks, thereby completing the semantic transmission pipeline. Extensiveexperiments (RefSegRS, RRSIS-D, and RISBench) demonstrate that RSRefSeg 2surpasses contemporary methods in segmentation accuracy (+~3% gIoU) and complexsemantic interpretation. Code is available at:https://github.com/KyanChen/RSRefSeg2.</description>
      <author>example@mail.com (Keyan Chen, Chenyang Liu, Bowen Chen, Jiafan Zhang, Zhengxia Zou, Zhenwei Shi)</author>
      <guid isPermaLink="false">2507.06231v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Augmented Model-Based Multi-Robot Planning for Time-Critical Search and Inspection Under Uncertainty</title>
      <link>http://arxiv.org/abs/2507.06129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures, CASE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多机器人规划框架，用于在不确定环境下协调时间敏感的多机器人搜索。&lt;h4&gt;背景&lt;/h4&gt;在灾难响应或监控行动中，快速识别需要紧急关注的区域至关重要，但派遣响应团队到每个地点既不高效也往往不可能。&lt;h4&gt;目的&lt;/h4&gt;通过协调多机器人检查团队优先检查可能需要立即响应的区域，同时最小化旅行时间。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络估计需要关注的POI（兴趣点）的可能性，并使用这些预测来指导基于模型的多机器人规划器以确定成本效益计划。&lt;h4&gt;主要发现&lt;/h4&gt;模拟实验表明，与未学习和已学习的基线相比，该规划器将1、3和5个机器人的性能分别提高了至少16.3%、26.7%和26.2%。&lt;h4&gt;结论&lt;/h4&gt;该方法在真实世界的平台上使用四旋翼无人机进行了验证。&lt;h4&gt;翻译&lt;/h4&gt;在灾难响应或监控行动中，快速识别需要紧急关注的区域至关重要，但派遣响应团队到每个地点既不高效也往往不可能。在此领域取得有效成绩需要协调多机器人检查团队，优先检查可能需要立即响应的区域，同时尽量减少旅行时间。由于机器人必须直接观察地点以确定哪些需要额外关注，因此这是一个特别的挑战。本文介绍了一种在不确定环境下协调时间敏感的多机器人搜索的多机器人规划框架。我们的方法使用图神经网络根据噪声传感器数据估计需要关注的POI的可能性，然后使用这些预测来引导基于模型的多机器人规划器以确定成本效益计划。模拟实验表明，与未学习和已学习的基线相比，我们的规划器将1、3和5个机器人的性能分别提高了至少16.3%、26.7%和26.2%。我们还在真实世界的平台上使用四旋翼无人机验证了我们的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In disaster response or surveillance operations, quickly identifying areasneeding urgent attention is critical, but deploying response teams to everylocation is inefficient or often impossible. Effective performance in thisdomain requires coordinating a multi-robot inspection team to prioritizeinspecting locations more likely to need immediate response, while alsominimizing travel time. This is particularly challenging because robots mustdirectly observe the locations to determine which ones require additionalattention. This work introduces a multi-robot planning framework forcoordinated time-critical multi-robot search under uncertainty. Our approachuses a graph neural network to estimate the likelihood of PoIs needingattention from noisy sensor data and then uses those predictions to guide amulti-robot model-based planner to determine the cost-effective plan. Simulatedexperiments demonstrate that our planner improves performance at least by16.3\%, 26.7\%, and 26.2\% for 1, 3, and 5 robots, respectively, compared tonon-learned and learned baselines. We also validate our approach on real-worldplatforms using quad-copters.</description>
      <author>example@mail.com (Abhish Khanal, Joseph Prince Mathew, Cameron Nowzari, Gregory J. Stein)</author>
      <guid isPermaLink="false">2507.06129v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease</title>
      <link>http://arxiv.org/abs/2507.05656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ADPv2，一个专注于胃肠道组织病理学的新数据集，旨在提高临床病理诊断的精确性和可重复性。&lt;h4&gt;背景&lt;/h4&gt;现有的公开数据集在病理学组织类型（HTT）注释方面有限，难以进行特定器官疾病的深入研究。&lt;h4&gt;目的&lt;/h4&gt;构建一个包含丰富HTT注释的胃肠道组织病理学数据集，用于提高诊断精度和可重复性，并促进特定器官疾病的深入研究。&lt;h4&gt;方法&lt;/h4&gt;ADPv2数据集由来自健康结肠活检切片的20,004个图像块组成，根据32个不同层级HTT的层次分类进行注释。使用VMamba架构训练了一个多标签表示学习模型，并在ADPv2数据集上进行两阶段训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在结肠HTT的多标签分类中达到了0.88的平均精度（mAP）。通过分析模型在不同结肠疾病影响下的预测行为，揭示了统计模式，证实了结肠癌发展的两种病理途径。&lt;h4&gt;结论&lt;/h4&gt;ADPv2数据集能够支持特定器官的深入研究，有助于生物标志物的发现。&lt;h4&gt;翻译&lt;/h4&gt;Computational pathology (CoPath) uses histopathology images to improve diagnostic accuracy and reproducibility in clinical pathology. However, publicly available datasets for CoPath that are annotated with extensive histological tissue type (HTT) taxonomies at a granular level remain scarce due to the significant expertise and high annotation costs required. Existing datasets, such as the Atlas of Digital Pathology (ADP), address this by offering diverse HTT annotations generalized to multiple organs, but limit the capability for in-depth studies on specific organ diseases. Building upon this foundation, we introduce ADPv2, a novel dataset focused on gastrointestinal histopathology. Our dataset comprises 20,004 image patches derived from healthy colon biopsy slides, annotated according to a hierarchical taxonomy of 32 distinct HTTs of 3 levels. Furthermore, we train a multilabel representation learning model following a two-stage training procedure on our ADPv2 dataset. We leverage the VMamba architecture and achieving a mean average precision (mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that our dataset is capable of an organ-specific in-depth study for potential biomarker discovery by analyzing the model's prediction behavior on tissues affected by different colon diseases, which reveals statistical patterns that confirm the two pathological pathways of colon cancer development. Our dataset is publicly available here: Part 1 at https://zenodo.org/records/15307021, Part 2 at https://zenodo.org/records/15312384 and Part 3 at https://zenodo.org/records/15312792&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational pathology (CoPath) leverages histopathology images to enhancediagnostic precision and reproducibility in clinical pathology. However,publicly available datasets for CoPath that are annotated with extensivehistological tissue type (HTT) taxonomies at a granular level remain scarce dueto the significant expertise and high annotation costs required. Existingdatasets, such as the Atlas of Digital Pathology (ADP), address this byoffering diverse HTT annotations generalized to multiple organs, but limit thecapability for in-depth studies on specific organ diseases. Building upon thisfoundation, we introduce ADPv2, a novel dataset focused on gastrointestinalhistopathology. Our dataset comprises 20,004 image patches derived from healthycolon biopsy slides, annotated according to a hierarchical taxonomy of 32distinct HTTs of 3 levels. Furthermore, we train a multilabel representationlearning model following a two-stage training procedure on our ADPv2 dataset.We leverage the VMamba architecture and achieving a mean average precision(mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show thatour dataset is capable of an organ-specific in-depth study for potentialbiomarker discovery by analyzing the model's prediction behavior on tissuesaffected by different colon diseases, which reveals statistical patterns thatconfirm the two pathological pathways of colon cancer development. Our datasetis publicly available here: Part 1 at https://zenodo.org/records/15307021, Part2 at https://zenodo.org/records/15312384 and Part 3 athttps://zenodo.org/records/15312792</description>
      <author>example@mail.com (Zhiyuan Yang, Kai Li, Sophia Ghamoshi Ramandi, Patricia Brassard, Hakim Khellaf, Vincent Quoc-Huy Trinh, Jennifer Zhang, Lina Chen, Corwyn Rowsell, Sonal Varma, Kostas Plataniotis, Mahdi S. Hosseini)</author>
      <guid isPermaLink="false">2507.05656v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Omni-Video: Democratizing Unified Video Understanding and Generation</title>
      <link>http://arxiv.org/abs/2507.06119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report, project page:  https://sais-fuxi.github.io/Omni-Video/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Omni-Video的统一视频理解、生成和基于指令的编辑框架，旨在弥合当前视频理解和生成模型发展的差距。&lt;h4&gt;背景&lt;/h4&gt;尽管在图像理解和生成方面取得了显著进展，但现有的基础模型主要关注图像处理，导致视频理解和生成模型的统一发展存在差距。&lt;h4&gt;目的&lt;/h4&gt;开发一个高效且有效的统一框架Omni-Video，用于视频理解、生成以及基于指令的编辑。&lt;h4&gt;方法&lt;/h4&gt;Omni-Video通过训练现有的多模态大型语言模型（MLLMs）产生连续视觉线索，作为扩散解码器的输入，从而生成高质量的视频。此外，通过轻量级架构设计和高效的多阶段训练方案，实现MLLMs与扩散解码器之间的快速连接。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型在视频生成、编辑和理解任务中表现出满意的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Omni-Video框架为统一视频建模提供了有效的解决方案，有助于推动视频理解和生成技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Notable breakthroughs in unified understanding and generation modeling haveled to remarkable advancements in image understanding, reasoning, productionand editing, yet current foundational models predominantly focus on processingimages, creating a gap in the development of unified models for videounderstanding and generation. This report presents Omni-Video, an efficient andeffective unified framework for video understanding, generation, as well asinstruction-based editing. Our key insight is to teach existing multimodallarge language models (MLLMs) to produce continuous visual clues that are usedas the input of diffusion decoders, which produce high-quality videosconditioned on these visual clues. To fully unlock the potential of our systemfor unified video modeling, we integrate several technical improvements: 1) alightweight architectural design that respectively attaches a vision head onthe top of MLLMs and a adapter before the input of diffusion decoders, theformer produce visual tokens for the latter, which adapts these visual tokensto the conditional space of diffusion decoders; and 2) an efficient multi-stagetraining scheme that facilitates a fast connection between MLLMs and diffusiondecoders with limited data and computational resources. We empiricallydemonstrate that our model exhibits satisfactory generalization abilitiesacross video generation, editing and understanding tasks.</description>
      <author>example@mail.com (Zhiyu Tan, Hao Yang, Luozheng Qin, Jia Gong, Mengping Yang, Hao Li)</author>
      <guid isPermaLink="false">2507.06119v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation</title>
      <link>http://arxiv.org/abs/2507.06189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在英语新闻文本中通过迁移学习和风格数据增强来提高主观句和客观句分类的效果。&lt;h4&gt;背景&lt;/h4&gt;本文针对CLEF 2025的CheckThat! Lab任务1——主观性检测进行研究。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习和风格数据增强在提高主观性检测效果上的有效性。&lt;h4&gt;方法&lt;/h4&gt;本文对比了预训练编码器的微调和在相关任务上微调的transformer的迁移学习。同时，引入了使用GPT-4o生成预定义主观性风格的释义的受控增强流程。为了确保标签和风格的一致性，使用相同的模型来纠正和精炼生成的样本。&lt;h4&gt;主要发现&lt;/h4&gt;特定编码器的迁移学习优于通用编码器的微调，并且精心策划的增强显著增强了模型的鲁棒性，尤其是在检测主观内容方面。&lt;h4&gt;结论&lt;/h4&gt;本文强调了结合编码器专业化和标签一致增强对提高主观性检测的价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对CLEF 2025 CheckThat! Lab任务1（主观性检测）的研究成果。研究通过迁移学习和风格数据增强来提升英语新闻文本中主观句和客观句的分类效果。对比了预训练编码器的微调与在相关任务上微调的transformer的迁移学习，并引入了利用GPT-4o生成预定义主观性风格的释义的受控增强流程。为保持标签和风格的一致性，采用同一模型对生成的样本进行纠正和精炼。结果表明，特定编码器的迁移学习优于通用编码器的微调，且精心策划的增强显著提升了模型的鲁棒性，尤其在检测主观内容方面。本文的官方提交在24个参与者中排名第16。总体而言，本文的研究发现强调了结合编码器专业化和标签一致增强对提高主观性检测的重要性。相关代码可在https://github.com/dsgt-arc/checkthat-2025-subject上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents our submission to Task 1, Subjectivity Detection, of theCheckThat! Lab at CLEF 2025. We investigate the effectiveness oftransfer-learning and stylistic data augmentation to improve classification ofsubjective and objective sentences in English news text. Our approach contrastsfine-tuning of pre-trained encoders and transfer-learning of fine-tunedtransformer on related tasks. We also introduce a controlled augmentationpipeline using GPT-4o to generate paraphrases in predefined subjectivitystyles. To ensure label and style consistency, we employ the same model tocorrect and refine the generated samples. Results show that transfer-learningof specified encoders outperforms fine-tuning general-purpose ones, and thatcarefully curated augmentation significantly enhances model robustness,especially in detecting subjective content. Our official submission placed us$16^{th}$ of 24 participants. Overall, our findings underscore the value ofcombining encoder specialization with label-consistent augmentation forimproved subjectivity detection. Our code is available athttps://github.com/dsgt-arc/checkthat-2025-subject.</description>
      <author>example@mail.com (Maximilian Heil, Dionne Bang)</author>
      <guid isPermaLink="false">2507.06189v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations</title>
      <link>http://arxiv.org/abs/2507.06044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合用户和物品交互信息生成解释的推荐系统方法，以增强用户信任和决策透明度。&lt;h4&gt;背景&lt;/h4&gt;现有推荐系统方法主要依赖将用户和物品特征编码为嵌入表示，但这种方法往往由于降维、稀疏交互等问题导致信息损失。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决信息损失问题，并提高推荐系统的可解释性和文本质量。&lt;h4&gt;方法&lt;/h4&gt;1. 使用预训练的大型语言模型（LLM）通过层次交互摘要（PGHIS）生成用户和物品的文本配置文件。2. 提出对比提示（CPEG）用于生成高质量的推荐解释，通过对比学习引导其他推理语言模型。3. 使用用户和物品的文本配置文件以及高质量的解释来微调LLM以生成解释。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个数据集上优于现有方法，在可解释性（如GPTScore提高5%）和文本质量方面取得了显著改进。此外，生成的真实解释在赢得率上显著高于用户撰写的评论和其他方法生成的解释。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过生成结构化的文本配置文件和高质量的推荐解释，有效提高了推荐系统的可解释性和用户信任。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explainable recommendations, which use the information of user and item withinteraction to generate a explanation for why the user would interact with theitem, are crucial for improving user trust and decision transparency to therecommender system. Existing methods primarily rely on encoding features ofusers and items to embeddings, which often leads to information loss due todimensionality reduction, sparse interactions, and so on. With the advancementsof large language models (LLMs) in language comprehension, some methods useembeddings as LLM inputs for explanation generation. However, since embeddingslack inherent semantics, LLMs must adjust or extend their parameters tointerpret them, a process that inevitably incurs information loss. To addressthis issue, we propose a novel approach combining profile generation viahierarchical interaction summarization (PGHIS), which leverages a pretrainedLLM to hierarchically summarize user-item interactions, generating structuredtextual profiles as explicit representations of user and item characteristics.Additionally, we propose contrastive prompting for explanation generation(CPEG) which employs contrastive learning to guide another reasoning languagemodels in producing high-quality ground truth recommendation explanations.Finally, we use the textual profiles of user and item as input and high-qualityexplanation as output to fine-tune a LLM for generating explanations.Experimental results on multiple datasets demonstrate that our approachoutperforms existing state-of-the-art methods, achieving a great improvement onmetrics about explainability (e.g., 5% on GPTScore) and text quality.Furthermore, our generated ground truth explanations achieve a significantlyhigher win rate compared to user-written reviews and those produced by othermethods, demonstrating the effectiveness of CPEG in generating high-qualityground truths.</description>
      <author>example@mail.com (Yibin Liu, Ang Li, Shijian Li)</author>
      <guid isPermaLink="false">2507.06044v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Is Diversity All You Need for Scalable Robotic Manipulation?</title>
      <link>http://arxiv.org/abs/2507.06219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code is available at https://github.com/OpenDriveLab/AgiBot-World&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了数据多样性在机器人学习中的作用，通过考察任务、实体和专家三个关键维度，挑战了“多样化越好”的传统观点。&lt;h4&gt;背景&lt;/h4&gt;数据缩放在自然语言处理和计算机视觉领域取得了显著成功，但在机器人操作中，有效数据缩放的原则尚未充分理解。&lt;h4&gt;目的&lt;/h4&gt;探讨数据多样性在机器人学习中的微妙作用，并挑战“多样化越好”的传统观点。&lt;h4&gt;方法&lt;/h4&gt;通过在多种机器人平台上进行大量实验，研究了任务、实体和专家三个维度对数据多样性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;1. 任务多样性比每个任务的演示数量更重要，有利于从多样化的预训练任务转移到新的下游场景；2. 对于在高质量单一实体数据上训练的跨实体迁移模型，多实体预训练数据是可选的；3. 专家多样性，由个人操作偏好和人类演示中的随机变化引起，可能会对策略学习产生混淆，速度的多模态是关键因素。&lt;h4&gt;结论&lt;/h4&gt;提出了一个分布去偏方法来减轻速度的不确定性，GO-1-Pro实现了15%的性能提升，相当于使用了2.5倍预训练数据。这些发现为如何有效地缩放机器人操作数据集提供了新的视角和实际指导。&lt;h4&gt;翻译&lt;/h4&gt;Data scaling has driven remarkable success in foundation models for NaturalLanguage Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of 'more diverse is better'. Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, which yields GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data scaling has driven remarkable success in foundation models for NaturalLanguage Processing (NLP) and Computer Vision (CV), yet the principles ofeffective data scaling in robotic manipulation remain insufficientlyunderstood. In this work, we investigate the nuanced role of data diversity inrobot learning by examining three critical dimensions-task (what to do),embodiment (which robot to use), and expert (who demonstrates)-challenging theconventional intuition of "more diverse is better". Throughout extensiveexperiments on various robot platforms, we reveal that (1) task diversityproves more critical than per-task demonstration quantity, benefiting transferfrom diverse pre-training tasks to novel downstream scenarios; (2)multi-embodiment pre-training data is optional for cross-embodimenttransfer-models trained on high-quality single-embodiment data can efficientlytransfer to different platforms, showing more desirable scaling property duringfine-tuning than multi-embodiment pre-trained models; and (3) expert diversity,arising from individual operational preferences and stochastic variations inhuman demonstrations, can be confounding to policy learning, with velocitymultimodality emerging as a key contributing factor. Based on this insight, wepropose a distribution debiasing method to mitigate velocity ambiguity, theyielding GO-1-Pro achieves substantial performance gains of 15%, equivalent tousing 2.5 times pre-training data. Collectively, these findings provide newperspectives and offer practical guidance on how to scale robotic manipulationdatasets effectively.</description>
      <author>example@mail.com (Modi Shi, Li Chen, Jin Chen, Yuxiang Lu, Chiming Liu, Guanghui Ren, Ping Luo, Di Huang, Maoqing Yao, Hongyang Li)</author>
      <guid isPermaLink="false">2507.06219v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Drag modelling for flows through assemblies of spherical particles with machine learning: A comparison of approaches</title>
      <link>http://arxiv.org/abs/2507.05983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过粒子解析直接数值模拟（PR-DNS）准确估计随机组装中粒子的拖曳力，并开发了一种基于遗传编程（GP）的可解释模型来减轻神经网络的黑盒性质。&lt;h4&gt;背景&lt;/h4&gt;尽管PR-DNS在相对较小的组装中应用有限，但其数据推动了拖曳封闭式模拟框架的发展，如欧拉-拉格朗日点粒子方法。近年来，人们致力于开发考虑粒子组装结构的确定性拖曳模型。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于遗传编程的可解释模型，以减轻神经网络的黑盒性质，并评估其准确性。&lt;h4&gt;方法&lt;/h4&gt;通过在PR-DNS数据上训练图神经网络（GNN）来学习构成拖曳变化的粒子之间的成对相互作用。使用特征排列方法评估GNN的输入特征的重要性，然后将从GNN提取的成对相互作用输入到GP算法中，以寻找拟合输入数据的符号表达式。&lt;h4&gt;主要发现&lt;/h4&gt;GP在找到相对简单的符号模型方面显示出潜力，但与GNN相比，符号模型的准确性略有下降。&lt;h4&gt;结论&lt;/h4&gt;GP在开发可解释的拖曳模型方面具有潜力，但需要进一步研究以提高模型的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drag forces on particles in random assemblies can be accurately estimatedthrough particle-resolved direct numerical simulations (PR-DNS). Despite itslimited applicability to relatively small assemblies, data obtained from PR-DNShas been the driving force for the development of drag closures for much moreaffordable simulation frameworks, such as Eulerian-Lagrangian point particlemethods. Recently, more effort has been invested in the development ofdeterministic drag models that account for the effect of the structure of theparticle assembly. Current successful deterministic models are mainly black-boxneural networks which: 1) Assume pairwise superposition of the neighbours'effect on the drag, and 2) Are trained on PR-DNS data for a wide range ofparticle concentrations and flow regimes. To alleviate the black-box nature ofneural networks, we use genetic programming (GP) to develop interpretablemodels. In our previous research, this has been proven successful in the Stokesregime. In the current contribution, we extend the application of GP to higherparticle Reynolds number regimes. This is done by training a graph neuralnetwork (GNN) on the PR-DNS data to learn the pairwise interactions among theparticles that constitute the drag variation. The significance of the inputfeatures of the GNN is assessed via a feature permutation approach. Then, theestimated pairwise interactions as extracted from the GNN are fed to a GPalgorithm, which searches for symbolic expressions that fit the input data. Acomparison between the trained GNN model and the resulting symbolic expressionsis presented, to assess whether the symbolic expression can capture theunderlying patterns learnt by the GNN. The comparison demonstrates thepotential of GP in finding relatively simple symbolic models. At the same time,the accuracy of the symbolic models slightly fall behind the GNN.</description>
      <author>example@mail.com (Julia Reuter, Hani Elmestikawy, Sanaz Mostaghim, Berend van Wachem)</author>
      <guid isPermaLink="false">2507.05983v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos</title>
      <link>http://arxiv.org/abs/2507.05859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的前馈压缩框架D-FCGS，用于压缩时间相关的高斯点云序列，以实现高效的三维场景建模。&lt;h4&gt;背景&lt;/h4&gt;高保真度的动态三维表示压缩是Free-viewpoint video (FVV)应用中的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需场景优化的方法，以实现高效的三维场景建模。&lt;h4&gt;方法&lt;/h4&gt;引入了帧组（GoF）结构和I-P帧编码，通过稀疏控制点提取帧间运动。使用双先验感知熵模型对运动张量进行前馈压缩。采用控制点引导的运动补偿和细化网络进行重建。&lt;h4&gt;主要发现&lt;/h4&gt;D-FCGS在2秒内实现了超过40倍的压缩，同时保持了各个视图的视觉质量。&lt;h4&gt;结论&lt;/h4&gt;D-FCGS为动态3D Gaussian Splatting的前馈压缩提供了新的方法，为可扩展的FVV传输和存储铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Free-viewpoint video (FVV) enables immersive 3D experiences, but efficient compression of dynamic 3D representations remains a major challenge. Recent advances in 3D Gaussian Splatting (3DGS) and its dynamic extensions have enabled high-fidelity scene modeling. However, existing methods often couple scene reconstruction with optimization-dependent coding, which limits generalizability. This paper presents Feedforward Compression of Dynamic Gaussian Splatting (D-FCGS), a novel feedforward framework for compressing temporally correlated Gaussian point cloud sequences. Our approach introduces a Group-of-Frames (GoF) structure with I-P frame coding, where inter-frame motions are extracted via sparse control points. The resulting motion tensors are compressed in a feedforward manner using a dual prior-aware entropy model that combines hyperprior and spatial-temporal priors for accurate rate estimation. For reconstruction, we perform control-point-guided motion compensation and employ a refinement network to enhance view-consistent fidelity. Trained on multi-view video-derived Gaussian frames, D-FCGS generalizes across scenes without per-scene optimization. Experiments show that it matches the rate-distortion performance of optimization-based methods, achieving over 40 times compression in under 2 seconds while preserving visual quality across viewpoints. This work advances feedforward compression for dynamic 3DGS, paving the way for scalable FVV transmission and storage in immersive applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Free-viewpoint video (FVV) enables immersive 3D experiences, but efficientcompression of dynamic 3D representations remains a major challenge. Recentadvances in 3D Gaussian Splatting (3DGS) and its dynamic extensions haveenabled high-fidelity scene modeling. However, existing methods often couplescene reconstruction with optimization-dependent coding, which limitsgeneralizability. This paper presents Feedforward Compression of DynamicGaussian Splatting (D-FCGS), a novel feedforward framework for compressingtemporally correlated Gaussian point cloud sequences. Our approach introduces aGroup-of-Frames (GoF) structure with I-P frame coding, where inter-framemotions are extracted via sparse control points. The resulting motion tensorsare compressed in a feedforward manner using a dual prior-aware entropy modelthat combines hyperprior and spatial-temporal priors for accurate rateestimation. For reconstruction, we perform control-point-guided motioncompensation and employ a refinement network to enhance view-consistentfidelity. Trained on multi-view video-derived Gaussian frames, D-FCGSgeneralizes across scenes without per-scene optimization. Experiments show thatit matches the rate-distortion performance of optimization-based methods,achieving over 40 times compression in under 2 seconds while preserving visualquality across viewpoints. This work advances feedforward compression fordynamic 3DGS, paving the way for scalable FVV transmission and storage inimmersive applications.</description>
      <author>example@mail.com (Wenkang Zhang, Yan Zhao, Qiang Wang, Li Song, Zhengxue Cheng)</author>
      <guid isPermaLink="false">2507.05859v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Causal Foundation Models: Disentangling Physics from Instrument Properties</title>
      <link>http://arxiv.org/abs/2507.05333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures. Accepted to the ICML 2025 Foundation Models for  Structured Data Workshop and accepted to the Machine Learning for  Astrophysics Workshop 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种因果驱动的结构化时间序列数据基础模型，通过双编码器架构和结构化对比学习，明确分离物理和仪器因素，提高了模型在低数据环境下的预测性能。&lt;h4&gt;背景&lt;/h4&gt;结构化时间序列数据的基础模型面临挑战，因为观测数据往往混淆了真实物理现象和测量仪器引入的系统扭曲，这限制了模型在异构或多仪器环境中的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效分离物理和仪器因素的基础模型，以提升模型在低数据环境下的预测能力和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;使用双编码器架构和结构化对比学习，通过自然发生的观测三元组（即同一目标在不同条件下测量，不同目标在共享条件下测量）学习物理信号和仪器效应的独立潜在表示。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟的类似NASA TESS任务观测到的变星复杂性的天文时间序列数据上，该方法在下游预测任务中显著优于传统的单潜在空间基础模型，特别是在低数据环境下。&lt;h4&gt;结论&lt;/h4&gt;该模型支持基础模型的关键能力，包括少样本泛化和高效适应，并强调了将因果结构编码到表示学习中的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：结构化时间序列数据的基础模型必须应对一个基本挑战：观测数据常常将真实的物理现象与测量仪器引入的系统扭曲混淆在一起。这种纠缠限制了模型的泛化能力，尤其是在异构或多仪器设置中。我们提出了一种因果驱动的结构化时间序列数据基础模型，该模型使用双编码器架构，并通过结构化对比学习进行训练，明确分离物理和仪器因素。利用自然发生的观测三元组（即同一目标在不同条件下测量，不同目标在共享条件下测量），我们的模型学习了底层物理信号和仪器效应的独立潜在表示。在模拟的天文时间序列数据上，这些数据旨在模拟NASA的凌星系外行星巡天卫星（TESS）观测到的变星的复杂性，我们的方法在下游预测任务中显著优于传统的单潜在空间基础模型，特别是在低数据环境下。这些结果表明，我们的模型支持基础模型的关键能力，包括少样本泛化和高效适应，并强调了将因果结构编码到表示学习中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for structured time series data must contend with afundamental challenge: observations often conflate the true underlying physicalphenomena with systematic distortions introduced by measurement instruments.This entanglement limits model generalization, especially in heterogeneous ormulti-instrument settings. We present a causally-motivated foundation modelthat explicitly disentangles physical and instrumental factors using adual-encoder architecture trained with structured contrastive learning.Leveraging naturally occurring observational triplets (i.e., where the sametarget is measured under varying conditions, and distinct targets are measuredunder shared conditions) our model learns separate latent representations forthe underlying physical signal and instrument effects. Evaluated on simulatedastronomical time series designed to resemble the complexity of variable starsobserved by missions like NASA's Transiting Exoplanet Survey Satellite (TESS),our method significantly outperforms traditional single-latent space foundationmodels on downstream prediction tasks, particularly in low-data regimes. Theseresults demonstrate that our model supports key capabilities of foundationmodels, including few-shot generalization and efficient adaptation, andhighlight the importance of encoding causal structure into representationlearning for structured data.</description>
      <author>example@mail.com (Jeroen Audenaert, Daniel Muthukrishna, Paul F. Gregory, David W. Hogg, V. Ashley Villar)</author>
      <guid isPermaLink="false">2507.05333v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>MCAM: Multimodal Causal Analysis Model for Ego-Vehicle-Level Driving Video Understanding</title>
      <link>http://arxiv.org/abs/2507.06072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MCAM的多模态因果分析模型，用于准确识别和推理自动驾驶中的驾驶行为，并在视觉-语言因果关系学习方面取得了SOTA性能。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶视频理解中，准确的驾驶行为识别和推理至关重要，但现有方法往往存在局限性，如挖掘浅层因果关系、未能解决跨模态的伪相关性以及忽略自我车辆层面的因果建模。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些局限性，提出了MCAM模型。&lt;h4&gt;方法&lt;/h4&gt;MCAM模型包括三个主要部分：1）设计多级特征提取器来捕捉长距离依赖；2）设计因果分析模块，使用有向无环图（DAG）动态建模驾驶场景；3）利用视觉-语言变压器对齐关键视觉特征与其对应的语言表达。&lt;h4&gt;主要发现&lt;/h4&gt;在BDD-X和CoVLA数据集上的实验表明，MCAM在视觉-语言因果关系学习方面达到了SOTA性能，并显示出在视频序列中捕捉因果特征的能力，证明了其在自动驾驶应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;MCAM模型对于自动驾驶应用中的驾驶行为识别和推理具有显著效果，代码可在GitHub上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate driving behavior recognition and reasoning are critical forautonomous driving video understanding. However, existing methods often tend todig out the shallow causal, fail to address spurious correlations acrossmodalities, and ignore the ego-vehicle level causality modeling. To overcomethese limitations, we propose a novel Multimodal Causal Analysis Model (MCAM)that constructs latent causal structures between visual and languagemodalities. Firstly, we design a multi-level feature extractor to capturelong-range dependencies. Secondly, we design a causal analysis module thatdynamically models driving scenarios using a directed acyclic graph (DAG) ofdriving states. Thirdly, we utilize a vision-language transformer to aligncritical visual features with their corresponding linguistic expressions.Extensive experiments on the BDD-X, and CoVLA datasets demonstrate that MCAMachieves SOTA performance in visual-language causal relationship learning.Furthermore, the model exhibits superior capability in capturing causalcharacteristics within video sequences, showcasing its effectiveness forautonomous driving applications. The code is available athttps://github.com/SixCorePeach/MCAM.</description>
      <author>example@mail.com (Tongtong Cheng, Rongzhen Li, Yixin Xiong, Tao Zhang, Jing Wang, Kai Liu)</author>
      <guid isPermaLink="false">2507.06072v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Prompt Tuning</title>
      <link>http://arxiv.org/abs/2507.06085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了prompt tuning技术，这是一种通过在语言模型前添加可训练的连续向量来高效调整模型参数的方法，同时保持模型冻结。将现有方法分为直接提示学习和迁移学习两大类。&lt;h4&gt;背景&lt;/h4&gt;prompt tuning技术是一种参数高效的调整语言模型的方法，通过在模型前添加可训练向量实现。&lt;h4&gt;目的&lt;/h4&gt;分析prompt tuning技术的不同方法，包括直接提示学习和迁移学习，并讨论其优缺点。&lt;h4&gt;方法&lt;/h4&gt;对直接提示学习和迁移学习两种方法进行分类，分析每种方法的设计、创新、见解、优点和缺点，并通过可视化对比不同框架。&lt;h4&gt;主要发现&lt;/h4&gt;识别了prompt tuning技术在计算效率和训练稳定性方面的挑战，并讨论了提高训练鲁棒性和扩展应用范围的未来方向。&lt;h4&gt;结论&lt;/h4&gt;prompt tuning技术是一种高效调整语言模型参数的方法，但存在计算效率和训练稳定性等挑战，未来需要进一步研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey reviews prompt tuning, a parameter-efficient approach foradapting language models by prepending trainable continuous vectors whilekeeping the model frozen. We classify existing approaches into two categories:direct prompt learning and transfer learning. Direct prompt learning methodsinclude: general optimization approaches, encoder-based methods, decompositionstrategies, and mixture-of-experts frameworks. Transfer learning methodsconsist of: general transfer approaches, encoder-based methods, anddecomposition strategies. For each method, we analyze method designs,innovations, insights, advantages, and disadvantages, with illustrativevisualizations comparing different frameworks. We identify challenges incomputational efficiency and training stability, and discuss future directionsin improving training robustness and broadening application scope.</description>
      <author>example@mail.com (Zongqian Li, Yixuan Su, Nigel Collier)</author>
      <guid isPermaLink="false">2507.06085v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts</title>
      <link>http://arxiv.org/abs/2507.05427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为OpenWorldSAM的框架，该框架通过整合轻量级视觉语言模型（VLM）的多模态嵌入，扩展了基于提示的分割任何模型v2（SAM2），使其能够处理开放词汇场景下的对象分割。&lt;h4&gt;背景&lt;/h4&gt;基于开放语言提示的对象分割是一个关键挑战，需要模型将文本语义与精确的空间掩码联系起来，同时处理多样化的未见类别。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理开放词汇场景的对象分割模型。&lt;h4&gt;方法&lt;/h4&gt;OpenWorldSAM遵循四个关键原则：统一提示、效率、实例感知和泛化。它支持多样化的提示，包括类别级和句子级语言描述，通过冻结预训练组件，仅训练450万个参数，增强模型的空间理解，并展示出强大的零样本能力。&lt;h4&gt;主要发现&lt;/h4&gt;OpenWorldSAM在多个基准测试中实现了最先进的性能，包括ADE20k、PASCAL、ScanNet和SUN-RGBD，在开放词汇语义、实例和全景分割方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;OpenWorldSAM是一个高效且通用的对象分割框架，能够处理开放词汇场景下的分割任务，展现出强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to segment objects based on open-ended language prompts remains acritical challenge, requiring models to ground textual semantics into precisespatial masks while handling diverse and unseen categories. We presentOpenWorldSAM, a framework that extends the prompt-driven Segment Anything Modelv2 (SAM2) to open-vocabulary scenarios by integrating multi-modal embeddingsextracted from a lightweight vision-language model (VLM). Our approach isguided by four key principles: i) Unified prompting: OpenWorldSAM supports adiverse range of prompts, including category-level and sentence-level languagedescriptions, providing a flexible interface for various segmentation tasks.ii) Efficiency: By freezing the pre-trained components of SAM2 and the VLM, wetrain only 4.5 million parameters on the COCO-stuff dataset, achievingremarkable resource efficiency. iii) Instance Awareness: We enhance the model'sspatial understanding through novel positional tie-breaker embeddings andcross-attention layers, enabling effective segmentation of multiple instances.iv) Generalization: OpenWorldSAM exhibits strong zero-shot capabilities,generalizing well on unseen categories and an open vocabulary of conceptswithout additional training. Extensive experiments demonstrate thatOpenWorldSAM achieves state-of-the-art performance in open-vocabulary semantic,instance, and panoptic segmentation across multiple benchmarks, includingADE20k, PASCAL, ScanNet, and SUN-RGBD.</description>
      <author>example@mail.com (Shiting Xiao, Rishabh Kabra, Yuhang Li, Donghyun Lee, Joao Carreira, Priyadarshini Panda)</author>
      <guid isPermaLink="false">2507.05427v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>From ID-based to ID-free: Rethinking ID Effectiveness in Multimodal Collaborative Filtering Recommendation</title>
      <link>http://arxiv.org/abs/2507.05715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM MM'25 (Experimental supplementary version)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为IDFREE的无ID多模态协同过滤推荐方法，通过替换ID特征和多模态特征及位置编码生成语义丰富的无ID嵌入，并采用自适应相似度图模块和增强的用户-项目图编码器来提升推荐性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态协同过滤推荐方法过度依赖ID特征和多模态内容来提升推荐性能。&lt;h4&gt;目的&lt;/h4&gt;揭示ID特征在多模态协同过滤推荐中的局限性，并提出一种新的无ID多模态协同过滤推荐方法。&lt;h4&gt;方法&lt;/h4&gt;IDFREE方法使用多模态特征和位置编码生成无ID嵌入，并引入自适应相似度图模块和增强的用户-项目图编码器，同时采用对比学习和Softmax损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，ID特征在多模态协同过滤推荐中虽然有效，但具有局限性，包括缺乏语义丰富性、阻碍泛化到未训练数据以及可能导致表示偏移。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，IDFREE在三个公开数据集上优于基于ID的多模态协同过滤推荐方法，平均性能提升达到72.24%。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为IDFREE的无ID多模态协同过滤推荐方法，旨在解决现有方法对ID特征的过度依赖问题。通过实验验证，该方法在推荐性能上优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing multimodal collaborative filtering recommendation (MCFRec)methods rely heavily on ID features and multimodal content to enhancerecommendation performance. However, this paper reveals that ID features areeffective but have limited benefits in multimodal collaborative filteringrecommendation. Therefore, this paper systematically deconstruct the pros andcons of ID features: (i) they provide initial embedding but lack semanticrichness, (ii) they provide a unique identifier for each user and item buthinder generalization to untrained data, and (iii) they assist in aligning andfusing multimodal features but may lead to representation shift. Based on theseinsights, this paper proposes IDFREE, an ID-free multimodal collaborativeFiltering REcommEndation baseline. IDFREE replaces ID features with multimodalfeatures and positional encodings to generate semantically meaningful ID-freeembeddings. For ID-free multimodal collaborative filtering, it further proposesan adaptive similarity graph module to construct dynamic user-user anditem-item graphs based on multimodal features. Then, an augmented user-itemgraph encoder is proposed to construct more effective user and item encoding.Finally, IDFREE achieves inter-multimodal alignment based on the contrastivelearning and uses Softmax loss as recommendation loss. Basic experiments onthree public datasets demonstrate that IDFREE outperforms existing ID-basedMCFRec methods, achieving an average performance gain of 72.24% across standardmetrics (Recall@5, 10, 20, 50 and NDCG@5, 10, 20, 50). Exploratory and extendedexperiments further validate our findings on the limitations of ID features inMCFRec. The code is released at https://github.com/G-H-Li/IDFREE.</description>
      <author>example@mail.com (Guohao Li, Li Jing, Jia Wu, Xuefei Li, Kai Zhu, Yue He)</author>
      <guid isPermaLink="false">2507.05715v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.05681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATMesh的基于图神经网络（GNN）的框架，用于分析和模拟时钟网格，以提高高性能VLSI系统中的时钟网格分析效率。&lt;h4&gt;背景&lt;/h4&gt;时钟网格在高性能VLSI系统中对于最小化偏斜和应对PVT（功率、电压和时间）变化至关重要，但其分析难度大，因为存在收敛路径、多源驱动和输入网格缓冲偏斜等问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来高效且准确地分析时钟网格。&lt;h4&gt;方法&lt;/h4&gt;提出GATMesh框架，将时钟网格建模为一个具有增强结构和物理特征的图，并使用SPICE数据进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;GATMesh在未见的基准测试上实现了高精度，平均延迟误差为5.27ps，并且相比于多线程SPICE模拟，速度提升了47146倍。&lt;h4&gt;结论&lt;/h4&gt;GATMesh是一种高效且准确的时钟网格分析工具，可以显著提高分析速度并减少计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clock meshes are essential in high-performance VLSI systems for minimizingskew and handling PVT variations, but analyzing them is difficult due toreconvergent paths, multi-source driving, and input mesh buffer skew. SPICEsimulations are accurate but slow; yet simplified models miss key effects likeslew and input skew. We propose GATMesh, a Graph Neural Network (GNN)-basedframework that models the clock mesh as a graph with augmented structural andphysical features. Trained on SPICE data, GATMesh achieves high accuracy withaverage delay error of 5.27ps on unseen benchmarks, while achieving speed-upsof 47146x over multi-threaded SPICE simulation.</description>
      <author>example@mail.com (Muhammad Hadir Khan, Matthew Guthaus)</author>
      <guid isPermaLink="false">2507.05681v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework</title>
      <link>http://arxiv.org/abs/2507.05814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种生成3D桥梁数据的系统框架，旨在提高桥梁结构3D视觉分析的自动化管理水平。&lt;h4&gt;背景&lt;/h4&gt;桥梁作为重要的交通基础设施，面临着老化损坏的挑战，传统的手动检查方法效率低下。3D点云技术虽然提供了新的数据驱动范式，但其应用潜力常常受到现实数据不完整性的限制。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有合成数据方法中泛化不足的瓶颈，提出了一种系统框架，用于生成3D桥梁数据。&lt;h4&gt;方法&lt;/h4&gt;该框架能够自动生成具有组件级实例注释、高保真色彩和精确法线的完整点云。此外，它可以扩展以模拟创建不同类型和物理真实的部分点云，以支持分割和完成网络的训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，使用本文合成数据进行训练的PointNet++模型在真实世界桥梁语义分割中实现了84.2%的平均交并比（mIoU）。同时，经过微调的KT-Net在组件完成任务上表现出色。&lt;h4&gt;结论&lt;/h4&gt;本研究提供了一种创新的方法和基础数据集，用于桥梁结构的3D视觉分析，对基础设施的自动化管理和维护具有重大意义。&lt;h4&gt;翻译&lt;/h4&gt;As critical transportation infrastructure, bridges face escalating challenges from aging and deterioration, while traditional manual inspection methods suffer from low efficiency. Although 3D point cloud technology provides a new data-driven paradigm, its application potential is often constrained by the incompleteness of real-world data, which results from missing labels and scanning occlusions. To overcome the bottleneck of insufficient generalization in existing synthetic data methods, this paper proposes a systematic framework for generating 3D bridge data. This framework can automatically generate complete point clouds featuring component-level instance annotations, high-fidelity color, and precise normal vectors. It can be further extended to simulate the creation of diverse and physically realistic incomplete point clouds, designed to support the training of segmentation and completion networks, respectively. Experiments demonstratethat a PointNet++ model trained with our synthetic data achieves a mean Intersection over Union (mIoU) of 84.2% in real-world bridge semantic segmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance on the component completion task. This research offers an innovative methodology and a foundational dataset for the 3D visual analysis of bridge structures, holding significant implications for advancing the automated management and maintenance of infrastructure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As critical transportation infrastructure, bridges face escalating challengesfrom aging and deterioration, while traditional manual inspection methodssuffer from low efficiency. Although 3D point cloud technology provides a newdata-driven paradigm, its application potential is often constrained by theincompleteness of real-world data, which results from missing labels andscanning occlusions. To overcome the bottleneck of insufficient generalizationin existing synthetic data methods, this paper proposes a systematic frameworkfor generating 3D bridge data.  This framework can automatically generate complete point clouds featuringcomponent-level instance annotations, high-fidelity color, and precise normalvectors. It can be further extended to simulate the creation of diverse andphysically realistic incomplete point clouds, designed to support the trainingof segmentation and completion networks, respectively. Experiments demonstratethat a PointNet++ model trained with our synthetic data achieves a meanIntersection over Union (mIoU) of 84.2% in real-world bridge semanticsegmentation. Concurrently, a fine-tuned KT-Net exhibits superior performanceon the component completion task.  This research offers an innovative methodology and a foundational dataset forthe 3D visual analysis of bridge structures, holding significant implicationsfor advancing the automated management and maintenance of infrastructure.</description>
      <author>example@mail.com (Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka Narazaki, Xuguang Wang)</author>
      <guid isPermaLink="false">2507.05814v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.05948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过引入几何意识来增强视频实例分割（VIS）鲁棒性的方法，利用单目深度估计策略性地解决遮挡、运动模糊和外观变化等挑战。&lt;h4&gt;背景&lt;/h4&gt;视频实例分割在处理遮挡、运动模糊和外观变化等常见问题时存在困难。&lt;h4&gt;目的&lt;/h4&gt;克服VIS的局限性，提高其鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文系统地研究了三种不同的集成范式：扩展深度通道（EDC）方法、共享ViT（SV）和深度监督（DS）。EDC方法将深度图作为输入通道添加到分割网络中；SV设计了一个统一的ViT骨干网络，共享于深度估计和分割分支；DS利用深度预测作为特征学习的辅助训练指南。&lt;h4&gt;主要发现&lt;/h4&gt;尽管DS效果有限，但基准评估表明EDC和SV显著增强了VIS的鲁棒性。使用Swin-L骨干网络时，EDC方法在OVIS基准上达到了56.2 AP，创下了新的最先进结果。&lt;h4&gt;结论&lt;/h4&gt;深度线索被确立为鲁棒视频理解的关键推动因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Instance Segmentation (VIS) fundamentally struggles with pervasivechallenges including object occlusions, motion blur, and appearance variationsduring temporal association. To overcome these limitations, this workintroduces geometric awareness to enhance VIS robustness by strategicallyleveraging monocular depth estimation. We systematically investigate threedistinct integration paradigms. Expanding Depth Channel (EDC) methodconcatenates the depth map as input channel to segmentation networks; SharingViT (SV) designs a uniform ViT backbone, shared between depth estimation andsegmentation branches; Depth Supervision (DS) makes use of depth prediction asan auxiliary training guide for feature learning. Though DS exhibits limitedeffectiveness, benchmark evaluations demonstrate that EDC and SV significantlyenhance the robustness of VIS. When with Swin-L backbone, our EDC method gets56.2 AP, which sets a new state-of-the-art result on OVIS benchmark. This workconclusively establishes depth cues as critical enablers for robust videounderstanding.</description>
      <author>example@mail.com (Quanzhu Niu, Yikang Zhou, Shihao Chen, Tao Zhang, Shunping Ji)</author>
      <guid isPermaLink="false">2507.05948v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol</title>
      <link>http://arxiv.org/abs/2507.06070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  International Journal of Music Science, Technology and Art, 15 pages,  7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的评估协议，以更好地反映现实世界的条件，并展示了在移动设备麦克风采集的噪声环境中，深度神经网络在歌曲识别方面的挑战和改进。&lt;h4&gt;背景&lt;/h4&gt;现有的歌曲识别方法在受控条件下表现良好，但在现实世界中的噪声环境下准确度会显著下降。&lt;h4&gt;目的&lt;/h4&gt;设计一种新的评估协议，以更好地反映现实世界的噪声环境，并提高歌曲识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;生成三段相同的音频记录，每段音频的噪声级别逐渐增加，并使用移动设备的麦克风采集。在训练过程中使用对比性损失和低通/高通滤波器进行数据增强。此外，还开发了一个基于变换器架构的模型，并从语义相关领域迁移知识。&lt;h4&gt;主要发现&lt;/h4&gt;在新的评估协议下，两种最先进的基于CNN的模型性能显著下降。通过在增强管道中引入低通和高通滤波器，显著提高了系统性能。基于变换器架构的模型在所有噪声级别和查询持续时间上均优于CNN模型，并在低噪声条件下实现了更高的准确率。&lt;h4&gt;结论&lt;/h4&gt;新的评估协议揭示了在现实世界噪声环境中的挑战，并且通过改进的模型和训练方法，可以显著提高歌曲识别的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.48293/IJMSTA-129&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in song identification leverage deep neural networks to learncompact audio fingerprints directly from raw waveforms. While these methodsperform well under controlled conditions, their accuracy drops significantly inreal-world scenarios where the audio is captured via mobile devices in noisyenvironments. In this paper, we introduce a novel evaluation protocol designedto better reflect such real-world conditions. We generate three recordings ofthe same audio, each with increasing levels of noise, captured using a mobiledevice's microphone. Our results reveal a substantial performance drop for twostate-of-the-art CNN-based models under this protocol, compared to previouslyreported benchmarks. Additionally, we highlight the critical role of theaugmentation pipeline during training with contrastive loss. By introductionlow pass and high pass filters in the augmentation pipeline we significantlyincrease the performance of both systems in our proposed evaluation.Furthermore, we develop a transformer-based model with a tailored projectionmodule and demonstrate that transferring knowledge from a semantically relevantdomain yields a more robust solution. The transformer architecture outperformsCNN-based models across all noise levels, and query durations. In low noiseconditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries infinding the correct song, surpassing by 14%, and by 18.5% the second-bestperforming model, respectively, Under heavy noise levels, we achieve adetection rate 56.5% for 15-second query duration. All experiments areconducted on public large-scale dataset of over 100K songs, with queriesmatched against a database of 56 million vectors.</description>
      <author>example@mail.com (Christos Nikou, Theodoros Giannakopoulos)</author>
      <guid isPermaLink="false">2507.06070v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2507.05627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DreamGrasp的框架，用于从少量稀疏RGB图像中重建3D几何形状和识别物体实例，特别是在全视图或可靠深度数据不可用的情况下，该方法在复杂多物体环境中表现出良好的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;部分视图3D识别是一个在杂乱、遮挡的现实中极具挑战性且实际应用广泛的任务，现有方法在处理此类场景时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出DreamGrasp框架，利用大规模预训练的图像生成模型的想象力，推断场景中未被观察到的部分，实现鲁棒的3D重建。&lt;h4&gt;方法&lt;/h4&gt;DreamGrasp结合了粗略的3D重建、通过对比学习进行实例分割和基于文本引导的实例级细化。&lt;h4&gt;主要发现&lt;/h4&gt;DreamGrasp不仅能够恢复精确的物体几何形状，还支持下游任务如顺序去杂和目标检索，并具有高成功率。&lt;h4&gt;结论&lt;/h4&gt;DreamGrasp在复杂多物体环境中实现了鲁棒的3D重建，并支持多种下游任务，显示出其有效性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial-view 3D recognition -- reconstructing 3D geometry and identifyingobject instances from a few sparse RGB images -- is an exceptionallychallenging yet practically essential task, particularly in cluttered, occludedreal-world settings where full-view or reliable depth data are oftenunavailable. Existing methods, whether based on strong symmetry priors orsupervised learning on curated datasets, fail to generalize to such scenarios.In this work, we introduce DreamGrasp, a framework that leverages theimagination capability of large-scale pre-trained image generative models toinfer the unobserved parts of a scene. By combining coarse 3D reconstruction,instance segmentation via contrastive learning, and text-guided instance-wiserefinement, DreamGrasp circumvents limitations of prior methods and enablesrobust 3D reconstruction in complex, multi-object environments. Our experimentsshow that DreamGrasp not only recovers accurate object geometry but alsosupports downstream tasks like sequential decluttering and target retrievalwith high success rates.</description>
      <author>example@mail.com (Young Hun Kim, Seungyeon Kim, Yonghyeon Lee, Frank Chongwoo Park)</author>
      <guid isPermaLink="false">2507.05627v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.05764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对儿童医学影像的分割模型，分析了不同策略对分割性能的影响，并提出了一种名为PSAT的系统研究方法。&lt;h4&gt;背景&lt;/h4&gt;儿童医学影像由于解剖和发育差异，与成人影像相比具有独特的挑战，直接应用成人数据训练的分割模型在性能上往往不理想。&lt;h4&gt;目的&lt;/h4&gt;研究不同策略对儿童医学影像分割性能的影响，并提出改进方法。&lt;h4&gt;方法&lt;/h4&gt;提出了基于nnU-Net框架的四种关键策略：指纹数据集、学习集、数据增强参数和迁移学习方法。通过PSAT方法在两个儿童CT数据集上进行了基准测试，并与现有方法进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;发现基于成人指纹数据集的训练计划与儿童解剖结构不匹配，导致分割性能显著下降，特别是对细小结构的分割。而持续学习方法可以减轻机构变化的影响，提高在不同儿童数据集上的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;PSAT方法为改进儿童医学影像分割提供了关键见解，并强调了持续学习方法的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：儿童医学影像由于与成人相比具有显著的解剖和发育差异，因此面临着独特的挑战。直接应用在成人数据上训练的分割模型通常会产生不理想的效果，尤其是在处理小型或快速发展的结构时。为了应对这些挑战，已经提出了几种利用nnU-Net框架的策略，这些策略在四个关键轴上有所不同：（i）指纹数据集（成人、儿童或两者的组合），从中衍生出训练计划（包括网络架构）；（ii）学习集（成人、儿童或混合）；（iii）数据增强参数；（iv）迁移学习方法（微调和持续学习）。在本研究中，我们引入了PSAT（通过成人增强和迁移学习进行儿童分割），这是一项系统研究，旨在调查这些轴对分割性能的影响。我们在这两个儿童CT数据集上对这些衍生策略进行了基准测试，并将它们与最先进的方法进行了比较，包括一个商业放疗解决方案。PSAT突出了关键陷阱，并为改进儿童分割提供了可行的见解。我们的实验表明，基于成人指纹数据集的训练计划与儿童解剖结构不匹配，导致在分割细小结构时性能显著下降，而持续学习策略可以减轻机构变化的影响，从而增强在不同儿童数据集上的泛化能力。代码可在https://github.com/ICANS-Strasbourg/PSAT上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pediatric medical imaging presents unique challenges due to significantanatomical and developmental differences compared to adults. Direct applicationof segmentation models trained on adult data often yields suboptimalperformance, particularly for small or rapidly evolving structures. To addressthese challenges, several strategies leveraging the nnU-Net framework have beenproposed, differing along four key axes: (i) the fingerprint dataset (adult,pediatric, or a combination thereof) from which the Training Plan -includingthe network architecture-is derived; (ii) the Learning Set (adult, pediatric,or mixed), (iii) Data Augmentation parameters, and (iv) the Transfer learningmethod (finetuning versus continual learning). In this work, we introduce PSAT(Pediatric Segmentation Approaches via Adult Augmentations and Transferlearning), a systematic study that investigates the impact of these axes onsegmentation performance. We benchmark the derived strategies on two pediatricCT datasets and compare them with state-of-theart methods, including acommercial radiotherapy solution. PSAT highlights key pitfalls and providesactionable insights for improving pediatric segmentation. Our experimentsreveal that a training plan based on an adult fingerprint dataset is misalignedwith pediatric anatomy-resulting in significant performance degradation,especially when segmenting fine structures-and that continual learningstrategies mitigate institutional shifts, thus enhancing generalization acrossdiverse pediatric datasets. The code is available athttps://github.com/ICANS-Strasbourg/PSAT.</description>
      <author>example@mail.com (Tristan Kirscher, Sylvain Faisan, Xavier Coubez, Loris Barrier, Philippe Meyer)</author>
      <guid isPermaLink="false">2507.05764v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering</title>
      <link>http://arxiv.org/abs/2507.06103v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Ref-Unlock的新型几何感知反射建模框架，用于解决新型视点合成中反射表面渲染的难题。&lt;h4&gt;背景&lt;/h4&gt;现有的方法如NeRF和3D Gaussian Splatting（3DGS）在处理反射时常常错误地将反射理解为物理几何，导致重建效果退化。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，Ref-Unlock旨在提供一种更精确的反射建模方法，以更好地捕捉复杂反射并增强真实场景中的几何一致性。&lt;h4&gt;方法&lt;/h4&gt;Ref-Unlock采用双分支表示法和高阶球谐函数来捕捉高频反射细节，并引入反射去除模块以提供无伪反射的监督，指导清晰的分解。此外，它还结合了伪深度图和几何感知双边平滑度约束，以增强分解的3D几何一致性和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;Ref-Unlock在实验中显著优于基于GS的传统反射方法，并与基于NeRF的模型实现了具有竞争力的结果，同时支持由视觉基础模型（VFMs）驱动的反射编辑。&lt;h4&gt;结论&lt;/h4&gt;Ref-Unlock提供了一种高效且可泛化的解决方案，用于渲染具有反射的逼真场景。&lt;h4&gt;翻译&lt;/h4&gt;Accurately rendering scenes with reflective surfaces remains a significant challenge in novel view synthesis, as existing methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) often misinterpret reflections as physical geometry, resulting in degraded reconstructions. Previous methods rely on incomplete and non-generalizable geometric constraints, leading to misalignment between the positions of Gaussian splats and the actual scene geometry. When dealing with real-world scenes containing complex geometry, the accumulation of Gaussians further exacerbates surface artifacts and results in blurred reconstructions. To address these limitations, in this work, we propose Ref-Unlock, a novel geometry-aware reflection modeling framework based on 3DGaussian Splatting, which explicitly disentangles transmitted and reflected components to better capture complex reflections and enhance geometric consistency in real-world scenes. Our approach employs a dual-branch representation with high-order spherical harmonics to capture high-frequency reflective details, alongside a reflection removal module providing pseudo-reflection-free supervision to guide clean decomposition. Additionally, we incorporate pseudo-depth maps and a geometry-aware bilateral smoothness constraint to enhance 3D geometric consistency and stability in decomposition. Extensive experiments demonstrate that Ref-Unlock significantly outperforms classical GS-based reflection methods and achieves competitive results with NeRF-based models, while enabling flexible vision foundation models (VFMs) driven reflection editing. Our method thus offers an efficient and generalizable solution for realistic rendering of reflective scenes. Our code is available at https://ref-unlock.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately rendering scenes with reflective surfaces remains a significantchallenge in novel view synthesis, as existing methods like Neural RadianceFields (NeRF) and 3D Gaussian Splatting (3DGS) often misinterpret reflectionsas physical geometry, resulting in degraded reconstructions. Previous methodsrely on incomplete and non-generalizable geometric constraints, leading tomisalignment between the positions of Gaussian splats and the actual scenegeometry. When dealing with real-world scenes containing complex geometry, theaccumulation of Gaussians further exacerbates surface artifacts and results inblurred reconstructions. To address these limitations, in this work, we proposeRef-Unlock, a novel geometry-aware reflection modeling framework based on 3DGaussian Splatting, which explicitly disentangles transmitted and reflectedcomponents to better capture complex reflections and enhance geometricconsistency in real-world scenes. Our approach employs a dual-branchrepresentation with high-order spherical harmonics to capture high-frequencyreflective details, alongside a reflection removal module providing pseudoreflection-free supervision to guide clean decomposition. Additionally, weincorporate pseudo-depth maps and a geometry-aware bilateral smoothnessconstraint to enhance 3D geometric consistency and stability in decomposition.Extensive experiments demonstrate that Ref-Unlock significantly outperformsclassical GS-based reflection methods and achieves competitive results withNeRF-based models, while enabling flexible vision foundation models (VFMs)driven reflection editing. Our method thus offers an efficient andgeneralizable solution for realistic rendering of reflective scenes. Our codeis available at https://ref-unlock.github.io/.</description>
      <author>example@mail.com (Jiayi Song, Zihan Ye, Qingyuan Zhou, Weidong Yang, Ben Fei, Jingyi Xu, Ying He, Wanli Ouyang)</author>
      <guid isPermaLink="false">2507.06103v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>HRRRCast: a data-driven emulator for regional weather forecasting at convection allowing scales</title>
      <link>http://arxiv.org/abs/2507.05658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HRRRCast是一个基于高级机器学习技术的数据驱动模拟器，用于提供高效的操作天气预测。&lt;h4&gt;背景&lt;/h4&gt;HRRR模型在美国大陆地区用于操作天气预测，但需要计算效率更高的替代方案。&lt;h4&gt;目的&lt;/h4&gt;开发一个计算效率高的替代方案，用于操作天气预测。&lt;h4&gt;方法&lt;/h4&gt;HRRRCast包括两个架构：基于ResNet的模型（ResHRRR）和基于图神经网络模型（GraphHRRR）。ResHRRR使用卷积神经网络，并支持概率预测。为了更好地处理更长的预测时间，训练一个模型来预测多个预测时间（1小时、3小时和6小时），然后在推理期间使用贪婪滚动策略。&lt;h4&gt;主要发现&lt;/h4&gt;ResHRRR在轻降雨阈值（20 dBZ）上优于HRRR预测，并在中等阈值（30 dBZ）上具有竞争力。HRRRCast的集合预测保持了更锐利的空间细节，其功率谱更接近HRRR分析。GraphHRRR目前表现不佳，但为基于图预测的未来工作奠定了基础。&lt;h4&gt;结论&lt;/h4&gt;HRRRCast代表了向高效、数据驱动的区域天气预测迈进的一步，具有有竞争力的准确性和集合能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：高分辨率快速更新（HRRR）模型是一种允许对流操作的模型，在美国大陆地区用于操作天气预测。为了提供一个计算效率高的替代方案，我们引入了HRRRCast，这是一个使用高级机器学习技术构建的数据驱动模拟器。HRRRCast包括两个架构：一个基于ResNet的模型（ResHRRR）和一个基于图神经网络模型（GraphHRRR）。ResHRRR使用卷积神经网络，并支持通过去噪扩散隐式模型（DDIM）进行概率预测。为了更好地处理更长的预测时间，我们训练一个模型来预测多个预测时间（1小时、3小时和6小时），然后在推理期间使用贪婪滚动策略。当使用3到10成员的集合在CONUS全域的合成反射率上进行评估时，ResHRRR在轻降雨阈值（20 dBZ）上优于HRRR预测，并在中等阈值（30 dBZ）上具有竞争力。我们的工作通过以下方式推进了Pathak等人[21]的StormCast模型：a）在CONUS全域进行训练，b）使用多个预测时间来提高长期技能，c）在分析数据上而不是在StormCast中意外使用的+1小时后分析数据上进行训练，d）将未来GFS状态作为输入，使降尺度改进了长期精度。网格、邻域和基于对象的指标证实了比HRRR更好的风暴定位、更低的频率偏差和更高的成功率。HRRRCast的集合预测也保持了更锐利的空间细节，其功率谱更接近HRRR分析。GraphHRRR在其当前形式下表现不佳，但为基于图预测的未来工作奠定了基础。HRRRCast代表了向高效、数据驱动的区域天气预测迈进的一步，具有有竞争力的准确性和集合能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The High-Resolution Rapid Refresh (HRRR) model is a convection-allowing modelused in operational weather forecasting across the contiguous United States(CONUS). To provide a computationally efficient alternative, we introduceHRRRCast, a data-driven emulator built with advanced machine learningtechniques. HRRRCast includes two architectures: a ResNet-based model (ResHRRR)and a Graph Neural Network-based model (GraphHRRR). ResHRRR uses convolutionalneural networks enhanced with squeeze-and-excitation blocks and Feature-wiseLinear Modulation, and supports probabilistic forecasting via the DenoisingDiffusion Implicit Model (DDIM). To better handle longer lead times, we train asingle model to predict multiple lead times (1h, 3h, and 6h), then use a greedyrollout strategy during inference. When evaluated on composite reflectivityover the full CONUS domain using ensembles of 3 to 10 members, ResHRRRoutperforms HRRR forecast at light rainfall threshold (20 dBZ) and achievescompetitive performance at moderate thresholds (30 dBZ). Our work advances theStormCast model of Pathak et al. [21] by: a) training on the full CONUS domain,b) using multiple lead times to improve long-range skill, c) training onanalysis data instead of the +1h post-analysis data inadvertently used inStormCast, and d) incorporating future GFS states as inputs, enablingdownscaling that improves long-lead accuracy. Grid-, neighborhood-, andobject-based metrics confirm better storm placement, lower frequency bias, andhigher success ratios than HRRR. HRRRCast ensemble forecasts also maintainsharper spatial detail, with power spectra more closely matching HRRR analysis.While GraphHRRR underperforms in its current form, it lays groundwork forfuture graph-based forecasting. HRRRCast represents a step toward efficient,data-driven regional weather prediction with competitive accuracy and ensemblecapability.</description>
      <author>example@mail.com (Daniel Abdi, Isidora Jankov, Paul Madden, Vanderlei Vargas, Timothy A. Smith, Sergey Frolov, Montgomery Flora, Corey Potvin)</author>
      <guid isPermaLink="false">2507.05658v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Process-Based Active Exploration Strategies in Vision and Touch</title>
      <link>http://arxiv.org/abs/2507.05522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Master's Thesis, Mechanical Engineering and Applied Mechanics,  University of Pennsylvania - April 2024  (https://events.seas.upenn.edu/event/meam-masters-thesis-defense-gaussian-process-based-active-exploration-strategies-in-vision-and-touch/)  (https://blog.me.upenn.edu/ho-jin-choi-successfully-defends-masters-thesis/)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将视觉和触觉观察融合到统一的高斯过程距离场（GPDF）表示方法，以实现对象属性的主动感知。&lt;h4&gt;背景&lt;/h4&gt;由于有限的前知知识，机器人难以理解物体的形状、材料和语义等属性，这阻碍了在非结构化环境中的操作。&lt;h4&gt;目的&lt;/h4&gt;通过融合视觉和触觉观察，实现对物体属性的主动感知。&lt;h4&gt;方法&lt;/h4&gt;使用GPDF编码带符号的距离，利用点云、解析梯度和Hessian以及表面不确定性估计。通过点云构建距离函数，GPDF不需要在大数据集上进行大量预训练，可以通过聚合整合观察。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在几何建模方面表现良好，并且具有建模表面属性（超越几何）的潜力。&lt;h4&gt;结论&lt;/h4&gt;通过量化多传感器的不确定性，该框架通过规划探索性动作以最大化信息增益，从而恢复精确的3D结构。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于有限的前知知识，机器人难以理解物体的形状、材料和语义等属性，这阻碍了在非结构化环境中的操作。与人类通过交互式多传感器探索来学习这些属性不同，这项工作提出了将视觉和触觉观察融合到统一的高斯过程距离场（GPDF）表示中，以实现对象属性的主动感知。虽然该方法主要关注几何形状，但也展示了建模表面属性（超越几何）的潜力。GPDF通过点云、解析梯度和Hessian以及表面不确定性估计来编码带符号的距离，这些是常见神经网络形状表示所缺乏的属性。通过利用点云构建距离函数，GPDF不需要在大数据集上进行大量预训练，并且可以通过聚合整合观察。从初始视觉形状估计开始，该框架通过可微渲染和不确定表面区域的触觉测量来迭代地改进几何形状。通过量化多传感器的不确定性，它规划探索性动作以最大化信息增益，从而恢复精确的3D结构。对于现实世界的机器人实验，我们使用了固定在桌子上的Franka Research 3机器人操作器，其末端执行器上安装了定制的DIGIT触觉传感器和Intel Realsense D435 RGBD相机。在这些实验中，机器人探索了放在桌子上的假设为静态的物体的形状和属性。为了提高可扩展性，我们研究了诱导点方法等近似方法。这种概率多模态融合使得机器人能够主动探索和映射复杂物体的几何形状，可能超出几何形状的范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots struggle to understand object properties like shape, material, andsemantics due to limited prior knowledge, hindering manipulation inunstructured environments. In contrast, humans learn these properties throughinteractive multi-sensor exploration. This work proposes fusing visual andtactile observations into a unified Gaussian Process Distance Field (GPDF)representation for active perception of object properties. While primarilyfocusing on geometry, this approach also demonstrates potential for modelingsurface properties beyond geometry. The GPDF encodes signed distance usingpoint cloud, analytic gradient and Hessian, and surface uncertainty estimates,which are attributes that common neural network shape representation lack. Byutilizing a point cloud to construct a distance function, GPDF does not needextensive pretraining on large datasets and can incorporate observations byaggregation. Starting with an initial visual shape estimate, the frameworkiteratively refines the geometry by integrating dense vision measurements usingdifferentiable rendering and tactile measurements at uncertain surface regions.By quantifying multi-sensor uncertainties, it plans exploratory motions tomaximize information gain for recovering precise 3D structures. For thereal-world robot experiment, we utilize the Franka Research 3 robotmanipulator, which is fixed on a table and has a customized DIGIT tactilesensor and an Intel Realsense D435 RGBD camera mounted on the end-effector. Inthese experiments, the robot explores the shape and properties of objectsassumed to be static and placed on the table. To improve scalability, weinvestigate approximation methods like inducing point method for GaussianProcesses. This probabilistic multi-modal fusion enables active exploration andmapping of complex object geometries, extending potentially beyond geometry.</description>
      <author>example@mail.com (Ho Jin Choi, Nadia Figueroa)</author>
      <guid isPermaLink="false">2507.05522v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching</title>
      <link>http://arxiv.org/abs/2507.05617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 main&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的知识蒸馏方法，通过让大型语言模型（LLM）从小型语言模型（SLM）学习，结合了小型模型的专长和大型模型的语义理解能力，以提高在文本匹配等任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;在文本匹配等任务中，经过微调的小型模型通常能产生更有效的特定领域表示。&lt;h4&gt;目的&lt;/h4&gt;利用小型模型的专长和大型模型的语义理解能力，提高LLM在特定任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;通过使用LoRA技术，将LLM重新解释为编码器-解码器模型，其中编码器生成压缩表示，解码器将这些表示映射到输出空间。在训练过程中，使用提出的Margin-aware Contrastive Learning（MCL）方法，确保对正负样本的相似度进行准确匹配，并自适应处理正负样本内部的差异。&lt;h4&gt;主要发现&lt;/h4&gt;该范式只需要一个表现良好的SLM，即可使LLM实现性能提升。在金融和医疗保健基准测试以及实际应用中的实验证实了其有效性，并且该模型已经在在线环境中完全部署。&lt;h4&gt;结论&lt;/h4&gt;该知识蒸馏方法通过LLM从SLM学习，有效提高了LLM在特定任务上的性能，并在实际应用中得到了验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge distillation typically involves transferring knowledge from a LargeLanguage Model (LLM) to a Smaller Language Model (SLM). However, in tasks suchas text matching, fine-tuned smaller models often yield more effectivedomain-specific representations, as they focus on optimizing the similarity ofinput pairs. To leverage both the specialized strengths of small models and therich semantic understanding of LLMs, we introduce a flipped knowledgedistillation paradigm, where LLM learns from SLM. Specifically, we address thearchitectural gap between decoder-only LLMs and smaller encoder-based models byreinterpreting LLMs in an encoder-decoder manner using LoRA. The encodergenerates compressed representations, while the decoder maps them to the outputspace. During training, the encoder produces representations and theirsimilarities, which are then aligned with the similarity scores produced by theteacher, using our proposed Margin-aware Contrastive Learning (MCL) approach.The MCL ensures accurate similarity for both positive and negative pairs, andadaptively handles the internal differences within positive and negativesamples. Our paradigm requires only a reasonably good-performing SLM, allowingthe LLM to achieve improved performance. Experiments on financial andhealthcare benchmarks, as well as real-world applications, confirm itseffectiveness, and the model has been fully deployed in an online environment.</description>
      <author>example@mail.com (Mingzhe Li, Jing Xiang, Qishen Zhang, Kaiyang Wan, Xiuying Chen)</author>
      <guid isPermaLink="false">2507.05617v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Predicting mutational effects on protein binding from folding energy</title>
      <link>http://arxiv.org/abs/2507.05502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/LDeng0205/StaB-ddG&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于迁移学习的蛋白质-蛋白质结合能预测方法，通过参数化结合能为蛋白质复合体折叠能与结合伙伴折叠能之差，实现了零样本预测，并通过有限的结合能测量进行微调，显著提高了预测准确性。&lt;h4&gt;背景&lt;/h4&gt;精确估计突变对蛋白质-蛋白质结合能的影响是结构生物学和药物设计中的一个开放性问题，现有深度学习方法因缺乏结合数据而性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于迁移学习的方法，利用蛋白质序列建模和折叠稳定性预测的进展来提高蛋白质-蛋白质结合能的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;采用预训练的逆折叠模型作为折叠能的代理，并利用大量的折叠能测量和有限的结合能测量进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;提出的预测器StaB-ddG是第一个与最先进的经验力场方法FoldX准确度相匹配的深度学习预测器，同时实现了超过1000倍的加速。&lt;h4&gt;结论&lt;/h4&gt;迁移学习在蛋白质-蛋白质结合能预测中是一种有效的策略，可以显著提高预测准确性并加快计算速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate estimation of mutational effects on protein-protein binding energiesis an open problem with applications in structural biology and therapeuticdesign. Several deep learning predictors for this task have been proposed, but,presumably due to the scarcity of binding data, these methods underperformcomputationally expensive estimates based on empirical force fields. Inresponse, we propose a transfer-learning approach that leverages advances inprotein sequence modeling and folding stability prediction for this task. Thekey idea is to parameterize the binding energy as the difference between thefolding energy of the protein complex and the sum of the folding energies ofits binding partners. We show that using a pre-trained inverse-folding model asa proxy for folding energy provides strong zero-shot performance, and can befine-tuned with (1) copious folding energy measurements and (2) more limitedbinding energy measurements. The resulting predictor, StaB-ddG, is the firstdeep learning predictor to match the accuracy of the state-of-the-art empiricalforce-field method FoldX, while offering an over 1,000x speed-up.</description>
      <author>example@mail.com (Arthur Deng, Karsten Householder, Fang Wu, Sebastian Thrun, K. Christopher Garcia, Brian Trippe)</author>
      <guid isPermaLink="false">2507.05502v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning</title>
      <link>http://arxiv.org/abs/2507.05649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review in Conference on Neural Information Processing Systems  (NeurIPS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DESIGN的新框架，用于在加密领域（如全同态加密）中高效地进行加密图神经网络（GNN）推理，解决了现有方法在计算效率上的限制。&lt;h4&gt;背景&lt;/h4&gt;虽然图神经网络（GNN）在基于图的机器学习任务中取得了最先进的性能，但在加密领域实现隐私保护GNN推理通常需要大量的计算开销，使得实时和隐私保护推理变得不切实际。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效的加密GNN推理框架，以减少计算开销并实现隐私保护。&lt;h4&gt;方法&lt;/h4&gt;DESIGN框架通过以下步骤实现：首先，从加密图中计算FHE兼容的节点重要性分数；然后，这些分数引导同态分区过程，生成多级重要性掩码；最后，通过动态生成的掩码实现输入图剪枝和自适应多项式激活方案。&lt;h4&gt;主要发现&lt;/h4&gt;实证评估表明，DESIGN在加速FHE GNN推理的同时，保持了与现有方法相当的模型精度。&lt;h4&gt;结论&lt;/h4&gt;DESIGN是一种稳健的解决方案，适用于安全的图分析。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have achieved state-of-the-art performance in various graph-based learning tasks. However, enabling privacy-preserving GNNs in encrypted domains, such as under Fully Homomorphic Encryption (FHE), typically incurs substantial computational overhead, rendering real-time and privacy-preserving inference impractical. In this work, we propose DESIGN (EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel framework for efficient encrypted GNN inference. DESIGN tackles the critical efficiency limitations of existing FHE GNN approaches, which often overlook input data redundancy and apply uniform computational strategies. Our framework achieves significant performance gains through a hierarchical optimization strategy executed entirely on the server: first, FHE-compatible node importance scores (based on encrypted degree statistics) are computed from the encrypted graph. These scores then guide a homomorphic partitioning process, generating multi-level importance masks directly under FHE. This dynamically generated mask facilitates both input graph pruning (by logically removing unimportant elements) and a novel adaptive polynomial activation scheme, where activation complexity is tailored to node importance levels. Empirical evaluations demonstrate that DESIGN substantially accelerates FHE GNN inference compared to state-of-the-art methods while maintaining competitive model accuracy, presenting a robust solution for secure graph analytics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved state-of-the-art performance invarious graph-based learning tasks. However, enabling privacy-preserving GNNsin encrypted domains, such as under Fully Homomorphic Encryption (FHE),typically incurs substantial computational overhead, rendering real-time andprivacy-preserving inference impractical. In this work, we propose DESIGN(EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novelframework for efficient encrypted GNN inference. DESIGN tackles the criticalefficiency limitations of existing FHE GNN approaches, which often overlookinput data redundancy and apply uniform computational strategies. Our frameworkachieves significant performance gains through a hierarchical optimizationstrategy executed entirely on the server: first, FHE-compatible node importancescores (based on encrypted degree statistics) are computed from the encryptedgraph. These scores then guide a homomorphic partitioning process, generatingmulti-level importance masks directly under FHE. This dynamically generatedmask facilitates both input graph pruning (by logically removing unimportantelements) and a novel adaptive polynomial activation scheme, where activationcomplexity is tailored to node importance levels. Empirical evaluationsdemonstrate that DESIGN substantially accelerates FHE GNN inference compared tostate-of-the-art methods while maintaining competitive model accuracy,presenting a robust solution for secure graph analytics.</description>
      <author>example@mail.com (Kaixiang Zhao, Joseph Yousry Attalla, Qian Lou, Yushun Dong)</author>
      <guid isPermaLink="false">2507.05649v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2507.05822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，融合了视觉基础模型和大型语言模型，以解决视频理解模型在高级认知任务上的不足。&lt;h4&gt;背景&lt;/h4&gt;当前视频理解模型在识别“发生了什么”方面表现出色，但在因果推理和未来预测等高级认知任务上存在不足，这主要源于它们缺乏常识世界知识。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一认知差距，提出了一种新的框架，旨在通过融合视觉基础模型和大型语言模型来提升视频理解模型的高级认知能力。&lt;h4&gt;方法&lt;/h4&gt;该框架的关键技术创新是一个复杂的融合模块，受到Q-Former架构的启发，它将复杂的时空和以对象为中心的视觉特征提炼成简洁、与语言对齐的表示。模型通过两阶段策略进行训练，首先是基于视频-文本数据的大规模对齐预训练，然后是在旨在激发高级推理和预测技能的精选数据集上进行针对性的指令微调。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，该模型在多个具有挑战性的基准测试中实现了最先进的性能，并表现出显著的零样本泛化能力，能够处理未见过的推理任务。深入的分析和消融研究验证了每个架构组件的关键贡献。&lt;h4&gt;结论&lt;/h4&gt;这项工作推动了机器感知的边界，从简单的识别转向真正的认知理解，为机器人、人机交互等领域更智能、更强大的AI系统铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework that synergistically fuses a powerful Vision Foundation Model (VFM) for deep visual perception with a Large Language Model (LLM) serving as a knowledge-driven reasoning core. The key technical innovation is a sophisticated fusion module, inspired by the Q-Former architecture, which distills complex spatiotemporal and object-centric visual features into a concise, language-aligned representation. This enables the LLM to effectively ground its inferential processes in direct visual evidence. The model is trained via a two-stage strategy, beginning with large-scale alignment pre-training on video-text data, followed by targeted instruction fine-tuning on a curated dataset designed to elicit advanced reasoning and prediction skills. Extensive experiments demonstrate that our model achieves state-of-the-art performance on multiple challenging benchmarks. Notably, it exhibits remarkable zero-shot generalization to unseen reasoning tasks, and our in-depth ablation studies validate the critical contribution of each architectural component. This work pushes the boundary of machine perception from simple recognition towards genuine cognitive understanding, paving the way for more intelligent and capable AI systems in robotics, human-computer interaction, and beyond.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current video understanding models excel at recognizing "what" is happeningbut fall short in high-level cognitive tasks like causal reasoning and futureprediction, a limitation rooted in their lack of commonsense world knowledge.To bridge this cognitive gap, we propose a novel framework that synergisticallyfuses a powerful Vision Foundation Model (VFM) for deep visual perception witha Large Language Model (LLM) serving as a knowledge-driven reasoning core. Ourkey technical innovation is a sophisticated fusion module, inspired by theQ-Former architecture, which distills complex spatiotemporal and object-centricvisual features into a concise, language-aligned representation. This enablesthe LLM to effectively ground its inferential processes in direct visualevidence. The model is trained via a two-stage strategy, beginning withlarge-scale alignment pre-training on video-text data, followed by targetedinstruction fine-tuning on a curated dataset designed to elicit advancedreasoning and prediction skills. Extensive experiments demonstrate that ourmodel achieves state-of-the-art performance on multiple challenging benchmarks.Notably, it exhibits remarkable zero-shot generalization to unseen reasoningtasks, and our in-depth ablation studies validate the critical contribution ofeach architectural component. This work pushes the boundary of machineperception from simple recognition towards genuine cognitive understanding,paving the way for more intelligent and capable AI systems in robotics,human-computer interaction, and beyond.</description>
      <author>example@mail.com (L'ea Dubois, Klaus Schmidt, Chengyu Wang, Ji-Hoon Park, Lin Wang, Santiago Munoz)</author>
      <guid isPermaLink="false">2507.05822v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>A Wireless Foundation Model for Multi-Task Prediction</title>
      <link>http://arxiv.org/abs/2507.05938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对无线网络多任务预测的统一基础模型，用于准确预测关键系统参数，如信道状态信息（CSI）、用户位置和网络流量。&lt;h4&gt;背景&lt;/h4&gt;随着移动通信网络的复杂性和动态性增加，准确预测关键系统参数对于物理层（PHY）和介质访问控制层（MAC）的各种任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够泛化到不同场景和任务的多任务预测模型。&lt;h4&gt;方法&lt;/h4&gt;模型通过以下方式实现：1）对异构任务进行单变量分解以统一；2）编码粒度以实现区间感知；3）使用因果Transformer骨干网络进行准确预测；4）在训练过程中引入补丁掩码策略以支持任意输入长度。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在大规模数据集上训练后，显示出对未见场景的强大泛化能力，并在新任务上实现了零样本性能，超过了传统的全样本基线。&lt;h4&gt;结论&lt;/h4&gt;该模型为无线网络中的多任务预测提供了一种有效的方法，能够提高预测的准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着移动通信网络的复杂性和动态性日益增长，准确预测关键系统参数，如信道状态信息（CSI）、用户位置和网络流量，对于物理层（PHY）和介质访问控制层（MAC）的大量任务变得至关重要。尽管传统的基于深度学习（DL）的方法已被广泛应用于此类预测任务，但它们通常难以泛化到不同的场景和任务。作为回应，我们提出了一种支持多种预测区间的无线网络多任务预测的统一基础模型。所提出的模型强制进行单变量分解以统一异构任务，编码粒度以实现区间感知，并使用因果Transformer骨干网络进行准确预测。此外，我们在训练过程中引入了补丁掩码策略以支持任意输入长度。在大型数据集上训练后，所提出的基模型显示出对未见场景的强大泛化能力，并在新任务上实现了零样本性能，超过了传统的全样本基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing complexity and dynamics of the mobile communicationnetworks, accurately predicting key system parameters, such as channel stateinformation (CSI), user location, and network traffic, has become essential fora wide range of physical (PHY)-layer and medium access control (MAC)-layertasks. Although traditional deep learning (DL)-based methods have been widelyapplied to such prediction tasks, they often struggle to generalize acrossdifferent scenarios and tasks. In response, we propose a unified foundationmodel for multi-task prediction in wireless networks that supports diverseprediction intervals. The proposed model enforces univariate decomposition tounify heterogeneous tasks, encodes granularity for interval awareness, and usesa causal Transformer backbone for accurate predictions. Additionally, weintroduce a patch masking strategy during training to support arbitrary inputlengths. After trained on large-scale datasets, the proposed foundation modeldemonstrates strong generalization to unseen scenarios and achieves zero-shotperformance on new tasks that surpass traditional full-shot baselines.</description>
      <author>example@mail.com (Yucheng Sheng, Jiacheng Wang, Xingyu Zhou, Le Liang, Hao Ye, Shi Jin, Geoffrey Ye Li)</author>
      <guid isPermaLink="false">2507.05938v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Neural-Driven Image Editing</title>
      <link>http://arxiv.org/abs/2507.05397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LoongX的无手图像编辑方法，通过利用脑-机接口（BCI）和生成模型，通过多模态神经生理信号实现。&lt;h4&gt;背景&lt;/h4&gt;传统的图像编辑依赖手动提示，劳动密集且对肢体控制能力有限或语言能力有限的人不友好。&lt;h4&gt;目的&lt;/h4&gt;旨在提供一个易于使用且对所有人可访问的图像编辑方法。&lt;h4&gt;方法&lt;/h4&gt;LoongX使用训练有素的扩散模型，这些模型在一个包含23,928个图像编辑对的综合数据集上进行训练，每个对都与同步的脑电图（EEG）、功能性近红外光谱（fNIRS）、光电容积描记术（PPG）和头部运动信号同步，这些信号捕捉用户意图。系统整合了两个关键模块：交叉尺度状态空间（CS3）模块用于编码信息性模态特定特征，动态门控融合（DGF）模块将这些特征聚合到一个统一的潜在空间，并通过扩散变换器（DiT）的微调与编辑语义对齐。编码器使用对比学习进行预训练，以使认知状态与嵌入的自然语言中的语义意图相一致。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LoongX在性能上与基于文本的方法相当，甚至当与语音结合时表现更好。&lt;h4&gt;结论&lt;/h4&gt;这些结果表明，神经驱动的生成模型在实现可访问且直观的图像编辑方面具有巨大潜力，并为认知驱动的创意技术开辟了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统图像编辑通常依赖于手动提示，这使得它劳动密集且对肢体控制能力有限或语言能力有限的人难以访问。利用最近在脑-机接口（BCI）和生成模型方面的进展，我们提出了LoongX，一种由多模态神经生理信号驱动的免手图像编辑方法。LoongX利用在23,928个图像编辑对的综合数据集上训练的先进扩散模型，每个对都与同步的脑电图（EEG）、功能性近红外光谱（fNIRS）、光电容积描记术（PPG）和头部运动信号同步，这些信号捕捉用户意图。为了有效地处理这些信号的异质性，LoongX集成了两个关键模块。交叉尺度状态空间（CS3）模块编码信息性模态特定特征。动态门控融合（DGF）模块进一步将这些特征聚合到一个统一的潜在空间，然后通过在扩散变换器（DiT）上的微调与编辑语义对齐。此外，我们使用对比学习预训练编码器，以使认知状态与嵌入的自然语言中的语义意图相一致。广泛的实验表明，LoongX在性能上与文本驱动的方法相当（CLIP-I：0.6605 vs. 0.6558；DINO：0.4812 vs. 0.4636），并且在神经信号与语音结合时表现更优（CLIP-T：0.2588 vs. 0.2549）。这些结果突出了神经驱动生成模型在实现可访问、直观的图像编辑方面的潜力，并为认知驱动的创意技术开辟了新的方向。数据集和代码将发布以支持未来的工作并促进该新兴领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional image editing typically relies on manual prompting, making itlabor-intensive and inaccessible to individuals with limited motor control orlanguage abilities. Leveraging recent advances in brain-computer interfaces(BCIs) and generative models, we propose LoongX, a hands-free image editingapproach driven by multimodal neurophysiological signals. LoongX utilizesstate-of-the-art diffusion models trained on a comprehensive dataset of 23,928image editing pairs, each paired with synchronized electroencephalography(EEG), functional near-infrared spectroscopy (fNIRS), photoplethysmography(PPG), and head motion signals that capture user intent. To effectively addressthe heterogeneity of these signals, LoongX integrates two key modules. Thecross-scale state space (CS3) module encodes informative modality-specificfeatures. The dynamic gated fusion (DGF) module further aggregates thesefeatures into a unified latent space, which is then aligned with edit semanticsvia fine-tuning on a diffusion transformer (DiT). Additionally, we pre-trainthe encoders using contrastive learning to align cognitive states with semanticintentions from embedded natural language. Extensive experiments demonstratethat LoongX achieves performance comparable to text-driven methods (CLIP-I:0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636) and outperforms them when neuralsignals are combined with speech (CLIP-T: 0.2588 vs. 0.2549). These resultshighlight the promise of neural-driven generative models in enablingaccessible, intuitive image editing and open new directions forcognitive-driven creative technologies. Datasets and code will be released tosupport future work and foster progress in this emerging area.</description>
      <author>example@mail.com (Pengfei Zhou, Jie Xia, Xiaopeng Peng, Wangbo Zhao, Zilong Ye, Zekai Li, Suorong Yang, Jiadong Pan, Yuanxiang Chen, Ziqiao Wang, Kai Wang, Qian Zheng, Xiaojun Chang, Gang Pan, Shurong Dong, Kaipeng Zhang, Yang You)</author>
      <guid isPermaLink="false">2507.05397v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Graph Neural Network for Predicting Soft Tissue Deformation and Forces</title>
      <link>http://arxiv.org/abs/2507.05315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的数据驱动模型，即条件图神经网络（cGNN），用于解决虚拟环境中软组织模拟的复杂性。&lt;h4&gt;背景&lt;/h4&gt;软组织在虚拟环境中的模拟对于医学应用变得越来越重要，但其高变形性带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型来预测软组织的变形和作用在其上的力。&lt;h4&gt;方法&lt;/h4&gt;使用表面点和作用力位置的数据，通过条件图神经网络（cGNN）预测点的变形和作用力。模型首先使用质量-弹簧模拟进行初步训练，然后使用实验数据微调。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够预测变形，距离误差为0.35±0.03毫米，对于30毫米的变形；作用力，绝对误差为0.37±0.05牛顿，对于7.5牛顿的力。&lt;h4&gt;结论&lt;/h4&gt;该数据驱动方法为虚拟环境中软组织模拟的复杂挑战提供了一个有前景的解决方案，并且有望应用于需要真实软组织模拟的多个领域。&lt;h4&gt;翻译&lt;/h4&gt;Soft tissue simulation in virtual environments is becoming increasingly important for medical applications. However, the high deformability of soft tissue poses significant challenges. Existing methods rely on segmentation, meshing and estimation of stiffness properties of tissues. In addition, the integration of haptic feedback requires precise force estimation to enable a more immersive experience. We introduce a novel data-driven model, a conditional graph neural network (cGNN) to tackle this complexity. Our model takes surface points and the location of applied forces, and is specifically designed to predict the deformation of the points and the forces exerted on them. We trained our model on experimentally collected surface tracking data of a soft tissue phantom and used transfer learning to overcome the data scarcity by initially training it with mass-spring simulations and fine-tuning it with the experimental data. This approach improves the generalisation capability of the model and enables accurate predictions of tissue deformations and corresponding interaction forces. The results demonstrate that the model can predict deformations with a distance error of 0.35±0.03 mm for deformations up to 30 mm and the force with an absolute error of 0.37±0.05 N for forces up to 7.5 N. Our data-driven approach presents a promising solution to the intricate challenge of simulating soft tissues within virtual environments. Beyond its applicability in medical simulations, this approach holds the potential to benefit various fields where realistic soft tissue simulations are required.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft tissue simulation in virtual environments is becoming increasinglyimportant for medical applications. However, the high deformability of softtissue poses significant challenges. Existing methods rely on segmentation,meshing and estimation of stiffness properties of tissues. In addition, theintegration of haptic feedback requires precise force estimation to enable amore immersive experience. We introduce a novel data-driven model, aconditional graph neural network (cGNN) to tackle this complexity. Our modeltakes surface points and the location of applied forces, and is specificallydesigned to predict the deformation of the points and the forces exerted onthem. We trained our model on experimentally collected surface tracking data ofa soft tissue phantom and used transfer learning to overcome the data scarcityby initially training it with mass-spring simulations and fine-tuning it withthe experimental data. This approach improves the generalisation capability ofthe model and enables accurate predictions of tissue deformations andcorresponding interaction forces. The results demonstrate that the model canpredict deformations with a distance error of 0.35$\pm$0.03 mm for deformationsup to 30 mm and the force with an absolute error of 0.37$\pm$0.05 N for forcesup to 7.5 N. Our data-driven approach presents a promising solution to theintricate challenge of simulating soft tissues within virtual environments.Beyond its applicability in medical simulations, this approach holds thepotential to benefit various fields where realistic soft tissue simulations arerequired.</description>
      <author>example@mail.com (Madina Kojanazarova, Florentin Bieder, Robin Sandkühler, Philippe C. Cattin)</author>
      <guid isPermaLink="false">2507.05315v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Best-of-N through the Smoothing Lens: KL Divergence and Regret Analysis</title>
      <link>http://arxiv.org/abs/2507.05913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop on Efficient Systems for Foundation Models at iCML&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了Best-of-N（BoN）方法在生成模型推理时间对齐中的应用，提出了一种称为Soft Best-of-N（SBoN）的平滑版本，并构建了理论框架来分析其性能。&lt;h4&gt;背景&lt;/h4&gt;BoN方法在奖励与KL散度权衡中几乎是最优的，但其效果高度依赖于所使用的代理奖励模型的质量。&lt;h4&gt;目的&lt;/h4&gt;研究BoN方法，特别是Soft Best-of-N（SBoN）的性能，并构建理论框架以解决代理奖励模型质量对性能的影响。&lt;h4&gt;方法&lt;/h4&gt;通过提供SBoN策略与参考策略之间的KL散度界限，分析BoN的扩展行为，研究遗憾差距，即最优策略下的预期真实奖励与SBoN策略之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析和实证研究表明，平滑处理有助于SBoN减轻奖励过度优化，尤其是在代理奖励质量较低的情况下。&lt;h4&gt;结论&lt;/h4&gt;SBoN方法在生成模型推理时间对齐中是一种有效的方法，通过平滑处理可以改善代理奖励模型质量较低时的性能。&lt;h4&gt;翻译&lt;/h4&gt;A simple yet effective method for inference-time alignment of generativemodels is Best-of-N (BoN), where N outcomes are sampled from areference policy, evaluated using a proxy reward model, and the highest-scoringone is selected. While prior work argues that BoN is almost optimal in rewardvs KL tradeoffs, the effectiveness of BoN depends critically on the quality of theproxy reward model used for selection. For this purpose, we study BoN through asmooth version known as Soft Best-of-N (SBoN) and develop a theoreticalframework to address this gap. We analyze the scaling behaviour of BoN byproviding bounds on the KL divergence between the SBoN policy and thereference policy, offering insights into how performance varies with thenumber of samples. We also study the regret gap, i.e., the gap between theexpected true reward under the optimal policy and the SBoN policy. Ourtheoretical and empirical findings show that smoothing helps SBoN mitigatereward overoptimization, especially when the quality of the proxy reward is low.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A simple yet effective method for inference-time alignment of generativemodels is Best-of-$N$ (BoN), where $N$ outcomes are sampled from a referencepolicy, evaluated using a proxy reward model, and the highest-scoring one isselected. While prior work argues that BoN is almost optimal in reward vs KLtradeoffs, the effectiveness of BoN depends critically on the quality of theproxy reward model used for selection. For this purpose, we study BoN through asmooth version known as Soft Best-of-N (SBoN) and develop a theoreticalframework to address this gap. We analyze the scaling behaviour of BoN byproviding bounds on the KL divergence between the SBoN policy and the referencepolicy, offering insights into how performance varies with the number ofsamples. We also study the regret gap, i.e., the gap between the expected truereward under the optimal policy and the SBoN policy. Our theoretical andempirical findings show that smoothing helps SBoN mitigate rewardoveroptimization, especially when the quality of the proxy reward is low.</description>
      <author>example@mail.com (Gholamali Aminian, Idan Shenfeld, Amir R. Asadi, Ahmad Beirami, Youssef Mroueh)</author>
      <guid isPermaLink="false">2507.05913v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Learnable quantum spectral filters for hybrid graph neural networks</title>
      <link>http://arxiv.org/abs/2507.05640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The simulation code and results used for this paper is publicly  available at: https://github.com/adaskin/gnn-qsf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文描述了一种参数化量子电路，该电路可以作为图神经网络中的卷积和池化层。该电路结合了参数化量子傅里叶电路，其中受控门的量子比特连接来自于拉普拉斯算子。具体来说，通过基于QFT的电路，其连接由邻接矩阵确定，可以近似地逼近图的拉普拉斯算子的特征空间。对于$Nimes N$的拉普拉斯算子，这种方法产生了一个近似多项式深度的电路，只需要$n=log(N)$个量子比特。这种类型的电路可以消除通过切比雪夫多项式或泰勒展开逼近拉普拉斯算子可学习函数时的昂贵经典计算。&lt;h4&gt;背景&lt;/h4&gt;图神经网络中的卷积和池化层对于处理图数据非常重要，但经典计算在逼近这些函数时可能非常昂贵。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效的量子电路，用于图神经网络中的卷积和池化层，以减少经典计算的成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种参数化量子电路，该电路结合了量子傅里叶变换和拉普拉斯算子，用于近似图的特征空间。&lt;h4&gt;主要发现&lt;/h4&gt;该量子电路能够近似地逼近图的拉普拉斯算子的特征空间，且只需要$N$的对数量子比特，从而大大减少了计算资源的需求。&lt;h4&gt;结论&lt;/h4&gt;该量子电路可以作为一种高效的卷积加池化层，通过量子计算减少经典计算的开销，并在某些情况下优于基线结果，特别是在几何结构起重要作用的案例中。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we describe a parameterized quantum circuit that can be considered as convolutional and pooling layers for graph neural networks. The circuit incorporates the parameterized quantum Fourier circuit where the qubit connections for the controlled gates derived from the Laplacian operator. Specifically, we show that the eigenspace of the Laplacian operator of a graph can be approximated by using QFT based circuit whose connections are determined from the adjacency matrix. For an $Nimes N$ Laplacian, this approach yields an approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. Thesetypes of circuits can eliminate the expensive classical computations forapproximating the learnable functions of the Laplacian through Chebyshevpolynomial or Taylor expansions. Using this circuit as a convolutional layer provides an $n-$ dimensional probability vector that can be considered as the filtered and compressed graph signal. Therefore, the circuit along with the measurement can be considered a very efficient convolution plus pooling layer that transforms an$N$-dimensional signal input into $n-$dimensional signal with an exponentialcompression. We then apply a classical neural network prediction head to theoutput of the circuit to construct a complete graph neural network. Since thecircuit incorporates geometric structure through its graph connection-basedapproach, we present graph classification results for the benchmark datasetslisted in TUDataset library. Using only [1-100] learnable parameters for thequantum circuit and minimal classical layers (1000-5000 parameters) in ageneric setting, the obtained results are comparable to and in some casesbetter than many of the baseline results, particularly for the cases whengeometric structure plays a significant role.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we describe a parameterized quantum circuit that can beconsidered as convolutional and pooling layers for graph neural networks. Thecircuit incorporates the parameterized quantum Fourier circuit where the qubitconnections for the controlled gates derived from the Laplacian operator.Specifically, we show that the eigenspace of the Laplacian operator of a graphcan be approximated by using QFT based circuit whose connections are determinedfrom the adjacency matrix. For an $N\times N$ Laplacian, this approach yieldsan approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. Thesetypes of circuits can eliminate the expensive classical computations forapproximating the learnable functions of the Laplacian through Chebyshevpolynomial or Taylor expansions.  Using this circuit as a convolutional layer provides an $n-$ dimensionalprobability vector that can be considered as the filtered and compressed graphsignal. Therefore, the circuit along with the measurement can be considered avery efficient convolution plus pooling layer that transforms an$N$-dimensional signal input into $n-$dimensional signal with an exponentialcompression. We then apply a classical neural network prediction head to theoutput of the circuit to construct a complete graph neural network. Since thecircuit incorporates geometric structure through its graph connection-basedapproach, we present graph classification results for the benchmark datasetslisted in TUDataset library. Using only [1-100] learnable parameters for thequantum circuit and minimal classical layers (1000-5000 parameters) in ageneric setting, the obtained results are comparable to and in some casesbetter than many of the baseline results, particularly for the cases whengeometric structure plays a significant role.</description>
      <author>example@mail.com (Ammar Daskin)</author>
      <guid isPermaLink="false">2507.05640v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>LLMs are Introvert</title>
      <link>http://arxiv.org/abs/2507.05638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究强调了当前基于LLM的传播模拟中的关键局限性，并展示了如何通过整合SIP-CoT和情感记忆显著提升LLM代理的社会智能和真实性。&lt;h4&gt;背景&lt;/h4&gt;社交媒体和生成式AI的指数级增长改变了信息传播方式，虽然促进了连接，但也加速了虚假信息的传播。&lt;h4&gt;目的&lt;/h4&gt;理解和控制信息传播动态，以减轻有害内容。&lt;h4&gt;方法&lt;/h4&gt;引入一个基于LLM的模拟环境，捕捉代理的演变态度、情绪和反应，并提出了基于社会信息处理理论的SIP-CoT机制，辅以情感引导的记忆。&lt;h4&gt;主要发现&lt;/h4&gt;LLM生成的行为与真实人类动态之间存在显著差距，特别是在立场检测和心理真实性方面。&lt;h4&gt;结论&lt;/h4&gt;SIP-CoT增强的LLM代理更有效地处理社会信息，其行为、态度和情绪更接近真实的人类互动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth of social media and generative AI has transformedinformation dissemination, fostering connectivity but also accelerating thespread of misinformation. Understanding information propagation dynamics anddeveloping effective control strategies is essential to mitigate harmfulcontent. Traditional models, such as SIR, provide basic insights butinadequately capture the complexities of online interactions. Advanced methods,including attention mechanisms and graph neural networks, enhance accuracy buttypically overlook user psychology and behavioral dynamics. Large languagemodels (LLMs), with their human-like reasoning, offer new potential forsimulating psychological aspects of information spread. We introduce anLLM-based simulation environment capturing agents' evolving attitudes,emotions, and responses. Initial experiments, however, revealed significantgaps between LLM-generated behaviors and authentic human dynamics, especiallyin stance detection and psychological realism. A detailed evaluation throughSocial Information Processing Theory identified major discrepancies ingoal-setting and feedback evaluation, stemming from the lack of emotionalprocessing in standard LLM training. To address these issues, we propose theSocial Information Processing-based Chain of Thought (SIP-CoT) mechanismenhanced by emotion-guided memory. This method improves the interpretation ofsocial cues, personalization of goals, and evaluation of feedback. Experimentalresults confirm that SIP-CoT-enhanced LLM agents more effectively processsocial information, demonstrating behaviors, attitudes, and emotions closer toreal human interactions. In summary, this research highlights criticallimitations in current LLM-based propagation simulations and demonstrates howintegrating SIP-CoT and emotional memory significantly enhances the socialintelligence and realism of LLM agents.</description>
      <author>example@mail.com (Litian Zhang, Xiaoming Zhang, Bingyu Yan, Ziyi Zhou, Bo Zhang, Zhenyu Guan, Xi Zhang, Chaozhuo Li)</author>
      <guid isPermaLink="false">2507.05638v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>CTA: Cross-Task Alignment for Better Test Time Training</title>
      <link>http://arxiv.org/abs/2507.05221v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CTA（跨任务对齐）的新方法，用于改进测试时训练（TTT），以增强深度学习模型在分布变化情况下的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在计算机视觉任务上表现出色，但面对分布变化（如领域或数据集变化）时性能会显著下降。&lt;h4&gt;目的&lt;/h4&gt;通过引入CTA方法，提高TTT的效果，从而增强模型的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;CTA不要求特定的模型架构，而是借鉴多模态对比学习的成功经验，通过对齐监督编码器与自监督编码器来增强模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CTA在多个基准数据集上相比现有方法在鲁棒性和泛化能力方面有显著提升。&lt;h4&gt;结论&lt;/h4&gt;CTA方法通过减轻梯度干扰，保留自监督学习的内在鲁棒性，并实现测试时的更具语义意义的更新，从而有效提升了模型的鲁棒性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models have demonstrated exceptional performance across a widerange of computer vision tasks. However, their performance often degradessignificantly when faced with distribution shifts, such as domain or datasetchanges. Test-Time Training (TTT) has emerged as an effective method to enhancemodel robustness by incorporating an auxiliary unsupervised task duringtraining and leveraging it for model updates at test time. In this work, weintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.Unlike existing TTT methods, CTA does not require a specialized modelarchitecture and instead takes inspiration from the success of multi-modalcontrastive learning to align a supervised encoder with a self-supervised one.This process enforces alignment between the learned representations of bothmodels, thereby mitigating the risk of gradient interference, preserving theintrinsic robustness of self-supervised learning and enabling more semanticallymeaningful updates at test-time. Experimental results demonstrate substantialimprovements in robustness and generalization over the state-of-the-art onseveral benchmark datasets.</description>
      <author>example@mail.com (Samuel Barbeau, Pedram Fekri, David Osowiechi, Ali Bahri, Moslem Yazdanpanah, Masih Aminbeidokhti, Christian Desrosiers)</author>
      <guid isPermaLink="false">2507.05221v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Just Say Better or Worse: A Human-AI Collaborative Framework for Medical Image Segmentation Without Manual Annotations</title>
      <link>http://arxiv.org/abs/2507.05815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的人机协作框架，用于医学图像分割，显著降低了标注负担，通过消除显式手动像素级标注的需求。&lt;h4&gt;背景&lt;/h4&gt;医学图像的标注是一个劳动密集型和耗时的工作，是医学图像AI系统开发和部署中的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;开发一种减少医学图像分割标注负担的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心创新在于偏好学习范式，其中人类专家提供最小、直观的反馈，简单地指出AI生成的分割是否优于前一个版本。框架包括四个关键组件：1）适应性的基础模型（FM）用于特征提取；2）基于特征相似性的标签传播；3）一个点击代理，它从人类提供的更好或更差的反馈中学习，以决定点击位置和标签；4）多轮分割学习过程，使用点击代理和FM基于的标签传播生成的伪标签来训练最先进的分割网络。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开数据集上的实验表明，该方法仅使用二元偏好反馈即可实现具有竞争力的分割性能，无需专家直接手动标注图像。&lt;h4&gt;结论&lt;/h4&gt;该人机协作框架有效减少了医学图像分割的标注负担，提高了AI系统的开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manual annotation of medical images is a labor-intensive and time-consumingprocess, posing a significant bottleneck in the development and deployment ofrobust medical imaging AI systems. This paper introduces a novel Human-AIcollaborative framework for medical image segmentation that substantiallyreduces the annotation burden by eliminating the need for explicit manualpixel-level labeling. The core innovation lies in a preference learningparadigm, where human experts provide minimal, intuitive feedback -- simplyindicating whether an AI-generated segmentation is better or worse than aprevious version. The framework comprises four key components: (1) an adaptablefoundation model (FM) for feature extraction, (2) label propagation based onfeature similarity, (3) a clicking agent that learns from human better-or-worsefeedback to decide where to click and with which label, and (4) a multi-roundsegmentation learning procedure that trains a state-of-the-art segmentationnetwork using pseudo-labels generated by the clicking agent and FM-based labelpropagation. Experiments on three public datasets demonstrate that the proposedapproach achieves competitive segmentation performance using only binarypreference feedback, without requiring experts to directly manually annotatethe images.</description>
      <author>example@mail.com (Yizhe Zhang)</author>
      <guid isPermaLink="false">2507.05815v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning</title>
      <link>http://arxiv.org/abs/2507.05636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  178 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;图学习已经成为机器学习和人工智能的关键子领域，具有广泛的应用前景。&lt;h4&gt;背景&lt;/h4&gt;图学习的发展始于早期图论方法，随着图神经网络的出现而迅速发展。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对图学习的全面介绍，并探讨其关键维度和应用。&lt;h4&gt;方法&lt;/h4&gt;本文回顾了处理大规模图、捕捉动态时间依赖性、整合异构数据模式、生成新图样本和增强可解释性的最新技术。&lt;h4&gt;主要发现&lt;/h4&gt;图学习在药物发现、欺诈检测、推荐系统和科学推理等领域有广泛的应用，但面临着可扩展性、泛化、异质性、可解释性和可靠性等挑战。&lt;h4&gt;结论&lt;/h4&gt;本文强调了图学习与其他人工智能范式的结合，并提出了未来的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;Graph learning has rapidly evolved into a critical subfield of machine learning and artificial intelligence (AI). Its development began with early graph-theoretic methods, gaining significant momentum with the advent of graph neural networks (GNNs). Over the past decade, progress in scalable architectures, dynamic graph modeling, multimodal learning, generative AI, explainable AI (XAI), and responsible AI has broadened the applicability of graph learning to various challenging environments. Graph learning is significant due to its ability to model complex, non-Euclidean relationships that traditional machine learning struggles to capture, thus better supporting real-world applications ranging from drug discovery and fraud detection to recommender systems and scientific reasoning. However, challenges like scalability, generalization, heterogeneity, interpretability, and trustworthiness must be addressed to unlock its full potential. This survey provides a comprehensive introduction to graph learning, focusing on key dimensions including scalable, temporal, multimodal, generative, explainable, and responsible graph learning. We review state-of-the-art techniques for efficiently handling large-scale graphs, capturing dynamic temporal dependencies, integrating heterogeneous data modalities, generating novel graph samples, and enhancing interpretability to foster trust and transparency. We also explore ethical considerations, such as privacy and fairness, to ensure responsible deployment of graph learning models. Additionally, we identify and discuss emerging topics, highlighting recent integration of graph learning and other AI paradigms and offering insights into future directions. This survey serves as a valuable resource for researchers and practitioners seeking to navigate the rapidly evolving landscape of graph learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph learning has rapidly evolved into a critical subfield of machinelearning and artificial intelligence (AI). Its development began with earlygraph-theoretic methods, gaining significant momentum with the advent of graphneural networks (GNNs). Over the past decade, progress in scalablearchitectures, dynamic graph modeling, multimodal learning, generative AI,explainable AI (XAI), and responsible AI has broadened the applicability ofgraph learning to various challenging environments. Graph learning issignificant due to its ability to model complex, non-Euclidean relationshipsthat traditional machine learning struggles to capture, thus better supportingreal-world applications ranging from drug discovery and fraud detection torecommender systems and scientific reasoning. However, challenges likescalability, generalization, heterogeneity, interpretability, andtrustworthiness must be addressed to unlock its full potential. This surveyprovides a comprehensive introduction to graph learning, focusing on keydimensions including scalable, temporal, multimodal, generative, explainable,and responsible graph learning. We review state-of-the-art techniques forefficiently handling large-scale graphs, capturing dynamic temporaldependencies, integrating heterogeneous data modalities, generating novel graphsamples, and enhancing interpretability to foster trust and transparency. Wealso explore ethical considerations, such as privacy and fairness, to ensureresponsible deployment of graph learning models. Additionally, we identify anddiscuss emerging topics, highlighting recent integration of graph learning andother AI paradigms and offering insights into future directions. This surveyserves as a valuable resource for researchers and practitioners seeking tonavigate the rapidly evolving landscape of graph learning.</description>
      <author>example@mail.com (Feng Xia, Ciyuan Peng, Jing Ren, Falih Gozi Febrinanto, Renqiang Luo, Vidya Saikrishna, Shuo Yu, Xiangjie Kong)</author>
      <guid isPermaLink="false">2507.05636v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters</title>
      <link>http://arxiv.org/abs/2507.05807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对基础模型在少样本域自适应中的两个基本问题进行研究，提出了一种新的方法来提高模型性能和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在少样本域自适应中，超参数调整因缺乏大型验证数据集而不切实际，且模型在测试时间数据与训练分布略有偏差时的鲁棒性仍是一大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在解决上述两个问题，提高模型在分布变化下的性能和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过训练多个独立的适配器并平均它们的输出，提出了一种新的方法，称为Soup-Adapter。该方法通过参数的原理性拼接，可以将集成重新参数化为单个适配器。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，该方法在适配器使用不同超参数的情况下，即使这些超参数是从广泛范围内采样的，也能显著提高模型性能并增强对分布变化的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;Soup-Adapter方法解决了超参数调整和模型鲁棒性问题，并且对CLIP-Adapter的关键超参数残差比更为敏感。&lt;h4&gt;翻译&lt;/h4&gt;本文针对基础模型在少样本域自适应中的两个基本问题进行研究，提出了一种新的方法来提高模型性能和鲁棒性。背景是超参数调整因缺乏大型验证数据集而不切实际，且模型在测试时间数据与训练分布略有偏差时的鲁棒性仍是一大挑战。目的是解决上述两个问题，提高模型在分布变化下的性能和鲁棒性。方法是通过训练多个独立的适配器并平均它们的输出，提出了一种新的方法，称为Soup-Adapter。该方法通过参数的原理性拼接，可以将集成重新参数化为单个适配器。研究发现，该方法在适配器使用不同超参数的情况下，即使这些超参数是从广泛范围内采样的，也能显著提高模型性能并增强对分布变化的鲁棒性。结论是Soup-Adapter方法解决了超参数调整和模型鲁棒性问题，并且对CLIP-Adapter的关键超参数残差比更为敏感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we tackle two fundamental problems in few-shot domainadaptation of foundation models. First, hyperparameter tuning is oftenimpractical due to the lack of large validation datasets. Second, modelrobustness under distribution shifts where test time data deviates slightlyfrom training distributions, remains a concern. We show that by trainingmultiple independent adapters and averaging their outputs, the new model has ahigher performance and is more robust to distribution shifts compared to anyindividual adapter. This improvement holds even when the adapters are trainedwith diverse hyperparameters sampled from a wide range, resulting in variedindividual performance. Consequently, our method addresses both of the problemsdescribed above. The ensemble is also significantly less sensitive to theresidual ratio, a critical hyperparameter of CLIP-Adapter. Since the ensemblecan be reparameterized to a single adapter again using a principledconcatenation of the parameters, we refer to our method as Soup-Adapter. Thisis also the first study to explore CLIP adapter-style techniques for DINOv2 andto directly compare them with CLIP in this setting.</description>
      <author>example@mail.com (Marco Roschkowski)</author>
      <guid isPermaLink="false">2507.05807v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs</title>
      <link>http://arxiv.org/abs/2507.05266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了评估大型语言模型（LLMs）泛化能力的问题，提出使用用户行为预测作为评估泛化能力的替代方法，并在电影和音乐推荐数据集上进行了实证研究。&lt;h4&gt;背景&lt;/h4&gt;由于数据污染，评估LLMs的泛化能力具有挑战性，随着模型增长和计算成本的降低，确保训练阶段未见过的任务和测试案例变得几乎不可能。&lt;h4&gt;目的&lt;/h4&gt;寻找一个理论上合理、可扩展且稳健的方法来评估LLMs的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出使用用户行为预测来评估泛化能力，并引入一个新颖的框架进行测试，该框架在电影和音乐推荐数据集上对GPT-4o, GPT-4o-mini和Llama-3.1-8B-Instruct进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，GPT-4o在泛化能力上优于GPT-4o-mini和Llama，尽管所有模型都有很大的改进空间，尤其是Llama。&lt;h4&gt;结论&lt;/h4&gt;用户行为预测是一个有效的评估LLMs泛化能力的方法，该研究为评估LLMs的泛化能力提供了新的思路和实证证据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Measuring the generalization ability of Large Language Models (LLMs) ischallenging due to data contamination. As models grow and computation becomescheaper, ensuring tasks and test cases are unseen during training phases willbecome nearly impossible. We argue that knowledge-retrieval and reasoning tasksare not ideal for measuring generalization, as LLMs are not trained forspecific tasks. Instead, we propose user behavior prediction, also a key aspectof personalization, as a theoretically sound, scalable, and robust alternative.We introduce a novel framework for this approach and test it on movie and musicrecommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.Results align with our framework's predictions, showing GPT-4o outperformsGPT-4o-mini and Llama, though all models have much room for improvement,especially Llama.</description>
      <author>example@mail.com (Sougata Saha, Monojit Choudhury)</author>
      <guid isPermaLink="false">2507.05266v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Robust Learning on Noisy Graphs via Latent Space Constraints with External Knowledge</title>
      <link>http://arxiv.org/abs/2507.05540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Latent Space Constrained Graph Neural Networks (LSC-GNN)来处理噪声边问题，并在多个数据集上取得了优于标准GNN和噪声鲁棒GNN的性能。&lt;h4&gt;背景&lt;/h4&gt;GNN在处理噪声边时存在困难。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理噪声边的图神经网络。&lt;h4&gt;方法&lt;/h4&gt;LSC-GNN通过结合外部“干净”链接和引导噪声目标图的嵌入，并训练两个编码器来达到目的：一个在完整图（目标图加上外部边）上，另一个在排除目标图可能噪声链接的正则化图上。然后对这两个编码器的潜在表示之间的差异进行惩罚，以避免模型对虚假边的过度拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在受中度噪声影响的图上，LSC-GNN在基准数据集上优于标准GNN和噪声鲁棒GNN。LSC-GNN还被扩展到异构图，并在一个小型蛋白质-代谢物网络上进行验证，其中代谢物-蛋白质相互作用降低了蛋白质共现数据的噪声。&lt;h4&gt;结论&lt;/h4&gt;LSC-GNN有潜力在具有噪声关系结构的设置中提高预测性能和可解释性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often struggle with noisy edges. We propose Latent Space Constrained Graph Neural Networks (LSC-GNN) to incorporate external "clean" links and guide embeddings of a noisy target graph. We train two encoders--one on the full graph (target plus external edges) and another on a regularization graph excluding the target's potentially noisy links--then penalize discrepancies between their latent representations. This constrains the model away from overfitting spurious edges. Experiments on benchmark datasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphs subjected to moderate noise. We extend LSC-GNN to heterogeneous graphs and validate it on a small protein-metabolite network, where metabolite-protein interactions reduce noise in protein co-occurrence data. Our results highlight LSC-GNN's potential to boost predictive performance and interpretability in settings with noisy relational structures.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often struggle with noisy edges. We proposeLatent Space Constrained Graph Neural Networks (LSC-GNN) to incorporateexternal "clean" links and guide embeddings of a noisy target graph. We traintwo encoders--one on the full graph (target plus external edges) and another ona regularization graph excluding the target's potentially noisy links--thenpenalize discrepancies between their latent representations. This constraintsteers the model away from overfitting spurious edges. Experiments on benchmarkdatasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphssubjected to moderate noise. We extend LSC-GNN to heterogeneous graphs andvalidate it on a small protein-metabolite network, where metabolite-proteininteractions reduce noise in protein co-occurrence data. Our results highlightLSC-GNN's potential to boost predictive performance and interpretability insettings with noisy relational structures.</description>
      <author>example@mail.com (Chunhui Gu, Mohammad Sadegh Nasr, James P. Long, Kim-Anh Do, Ehsan Irajizad)</author>
      <guid isPermaLink="false">2507.05540v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Text-Guided Token Communication for Wireless Image Transmission</title>
      <link>http://arxiv.org/abs/2507.05781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于文本引导的token通信系统，利用预训练的基础模型在低带宽条件下进行无线图像传输，以提高图像传输效率。&lt;h4&gt;背景&lt;/h4&gt;随着6G网络的出现和视觉应用的普及，在不利信道条件下高效传输图像变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种新的图像传输方法，该方法能够在低带宽环境下实现高效且高质量的图像传输。&lt;h4&gt;方法&lt;/h4&gt;该方法将图像转换为离散的tokens，应用5G NR极化编码，并采用文本引导的token预测进行图像重建。&lt;h4&gt;主要发现&lt;/h4&gt;在ImageNet数据集上的评估表明，该方法在信噪比高于0 dB时，在感知质量和语义保留方面优于带有注意力模块的深度源信道编码（ADJSCC），并且在信噪比较低时减轻了悬崖效应。&lt;h4&gt;结论&lt;/h4&gt;该系统无需针对特定场景进行重新训练，并表现出优异的跨数据集泛化能力，为与人类感知优先级一致的图像高效传输建立了一种新的范式。&lt;h4&gt;翻译&lt;/h4&gt;With the emergence of 6G networks and proliferation of visual applications,efficient image transmission under adverse channel conditions is critical. Wepresent a text-guided token communication system leveraging pre-trainedfoundation models for wireless image transmission with low bandwidth. Ourapproach converts images to discrete tokens, applies 5G NR polar coding, andemploys text-guided token prediction for reconstruction. Evaluations onImageNet show our method outperforms Deep Source Channel Coding with AttentionModules (ADJSCC) in perceptual quality and semantic preservation atSignal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect atlower SNRs. Our system requires no scenario-specific retraining and exhibitssuperior cross-dataset generalization, establishing a new paradigm forefficient image transmission aligned with human perceptual priorities.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the emergence of 6G networks and proliferation of visual applications,efficient image transmission under adverse channel conditions is critical. Wepresent a text-guided token communication system leveraging pre-trainedfoundation models for wireless image transmission with low bandwidth. Ourapproach converts images to discrete tokens, applies 5G NR polar coding, andemploys text-guided token prediction for reconstruction. Evaluations onImageNet show our method outperforms Deep Source Channel Coding with AttentionModules (ADJSCC) in perceptual quality and semantic preservation atSignal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect atlower SNRs. Our system requires no scenario-specific retraining and exhibitssuperior cross-dataset generalization, establishing a new paradigm forefficient image transmission aligned with human perceptual priorities.</description>
      <author>example@mail.com (Bole Liu, Li Qiao, Ye Wang, Zhen Gao, Yu Ma, Keke Ying, Tong Qin)</author>
      <guid isPermaLink="false">2507.05781v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>What's Making That Sound Right Now? Video-centric Audio-Visual Localization</title>
      <link>http://arxiv.org/abs/2507.04667v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICCV 2025. Project page:  https://hahyeon610.github.io/Video-centric_Audio_Visual_Localization/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AVATAR，一个以视频为中心的Audio-Visual Localization（AVL）基准，它通过引入高分辨率的时间信息来解决现有研究在时间动态和简化场景下的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有AVL研究主要关注图像级别的音频-视觉关联，未能捕捉时间动态，且假设声音来源总是可见，仅涉及单个对象。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出AVATAR，旨在提供更全面的AVL模型评估。&lt;h4&gt;方法&lt;/h4&gt;AVATAR引入了四种不同的场景：单音、混音、多实体和屏幕外，同时提出了TAVLO，一个新型视频中心AVL模型，该模型显式地整合了时间信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，传统方法由于依赖全局音频特征和帧级映射，难以追踪时间变化。相比之下，TAVLO通过利用高分辨率的时间建模实现了鲁棒且精确的音频-视觉对齐。&lt;h4&gt;结论&lt;/h4&gt;本文的工作从实证上证明了时间动态在AVL中的重要性，并建立了视频中心音频-视觉定位的新标准。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在提出一个视频中心的音频-视觉定位基准（AVATAR），它解决了现有研究在时间动态和简化场景下的局限性。AVATAR引入了四种不同的场景，并提出了一个新的视频中心AVL模型（TAVLO），以实现更全面的模型评估。实验表明，TAVLO通过利用高分辨率的时间建模，能够实现鲁棒且精确的音频-视觉对齐，从而证明了时间动态在AVL中的重要性，并建立了视频中心音频-视觉定位的新标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-Visual Localization (AVL) aims to identify sound-emitting sourceswithin a visual scene. However, existing studies focus on image-levelaudio-visual associations, failing to capture temporal dynamics. Moreover, theyassume simplified scenarios where sound sources are always visible and involveonly a single object. To address these limitations, we propose AVATAR, avideo-centric AVL benchmark that incorporates high-resolution temporalinformation. AVATAR introduces four distinct scenarios -- Single-sound,Mixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensiveevaluation of AVL models. Additionally, we present TAVLO, a novel video-centricAVL model that explicitly integrates temporal information. Experimental resultsshow that conventional methods struggle to track temporal variations due totheir reliance on global audio features and frame-level mappings. In contrast,TAVLO achieves robust and precise audio-visual alignment by leveraginghigh-resolution temporal modeling. Our work empirically demonstrates theimportance of temporal dynamics in AVL and establishes a new standard forvideo-centric audio-visual localization.</description>
      <author>example@mail.com (Hahyeon Choi, Junhoo Lee, Nojun Kwak)</author>
      <guid isPermaLink="false">2507.04667v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Theoretical Learning Performance of Graph Neural Networks: The Impact of Jumping Connections and Layer-wise Sparsification</title>
      <link>http://arxiv.org/abs/2507.05533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  TMLR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文分析了使用图稀疏化和跳跃连接的GCN的学习动态和泛化性能。&lt;h4&gt;背景&lt;/h4&gt;图卷积网络（GCNs）通过跳跃连接克服过平滑问题，而图稀疏化通过选择图邻接矩阵的子矩阵来减少计算需求。尽管图稀疏化的GCN在各种应用中取得了成功，但其泛化保证的理论理解仍然有限。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提供对具有跳跃连接和图稀疏化的GCN的学习动态和泛化性能的理论分析。&lt;h4&gt;方法&lt;/h4&gt;本文分析了使用图稀疏化和跳跃连接的GCN的学习动态和泛化性能，并通过实验在基准数据集上验证了理论结果。&lt;h4&gt;主要发现&lt;/h4&gt;分析表明，学习模型的泛化精度接近于一个依赖于提出的稀疏有效邻接矩阵$A^*$的广泛类目标函数所能达到的最高精度。跳跃连接导致不同层级的稀疏化需求不同，第一层的稀疏化矩阵与$A^*$的偏差对泛化影响更大。&lt;h4&gt;结论&lt;/h4&gt;本文首次对跳跃连接在稀疏化需求中的作用进行了理论描述，并通过实验验证了理论结果。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了使用图稀疏化和跳跃连接的图卷积网络（GCN）的学习动态和泛化性能。通过分析表明，学习模型的泛化精度接近于一个依赖于提出的稀疏有效邻接矩阵$A^*$的广泛类目标函数所能达到的最高精度。跳跃连接导致不同层级的稀疏化需求不同，第一层的稀疏化矩阵与$A^*$的偏差对泛化影响更大。这是对跳跃连接在稀疏化需求中作用的首次理论描述，并在基准数据集上验证了理论结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Jumping connections enable Graph Convolutional Networks (GCNs) to overcomeover-smoothing, while graph sparsification reduces computational demands byselecting a sub-matrix of the graph adjacency matrix during neighborhoodaggregation. Learning GCNs with graph sparsification has shown empiricalsuccess across various applications, but a theoretical understanding of thegeneralization guarantees remains limited, with existing analyses ignoringeither graph sparsification or jumping connections. This paper presents thefirst learning dynamics and generalization analysis of GCNs with jumpingconnections using graph sparsification. Our analysis demonstrates that thegeneralization accuracy of the learned model closely approximates the highestachievable accuracy within a broad class of target functions dependent on theproposed sparse effective adjacency matrix $A^*$. Thus, graph sparsificationmaintains generalization performance when $A^*$ preserves the essential edgesthat support meaningful message propagation. We reveal that jumping connectionslead to different sparsification requirements across layers. In atwo-hidden-layer GCN, the generalization is more affected by the sparsifiedmatrix deviations from $A^*$ of the first layer than the second layer. To thebest of our knowledge, this marks the first theoretical characterization ofjumping connections' role in sparsification requirements. We validate ourtheoretical results on benchmark datasets in deep GCNs.</description>
      <author>example@mail.com (Jiawei Sun, Hongkang Li, Meng Wang)</author>
      <guid isPermaLink="false">2507.05533v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Jigsaw: Training Multi-Billion-Parameter AI Weather Models with Optimized Model Parallelism</title>
      <link>http://arxiv.org/abs/2507.05753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了基于AI的天气预测方法，提出了一种名为WeatherMixer的神经网络架构，并通过Jigsaw模型并行化方案提高了模型训练效率。&lt;h4&gt;背景&lt;/h4&gt;AI方法革新了大气预报，特别是在中程预报方面取得了成功，推动了气候基础模型的发展。然而，高空间分辨率和长预报时间下的复杂大气动力学建模需要大型神经网络和大规模数据样本，这导致加速器内存和I/O带宽成为训练的瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出WeatherMixer和Jigsaw方案，以提高大气预测模型的准确性和训练效率。&lt;h4&gt;方法&lt;/h4&gt;WeatherMixer是一种多层感知器架构，其工作量与输入大小成线性关系，能够以与数值天气预报相似的精度学习全球天气现象。Jigsaw是一种新型的模型并行化方案，采用领域和张量并行性，消除了内存冗余。&lt;h4&gt;主要发现&lt;/h4&gt;Jigsaw在计算-通信受限系统中的强扩展性超过现有技术，并在I/O带宽受限系统中实现了超标量弱扩展性。通过256个GPU进行训练，达到了9和11PFLOPs的峰值性能，分别占理论峰值的23%和28%，比没有模型并行化的情况提高了17%和21%的扩展效率。&lt;h4&gt;结论&lt;/h4&gt;WeatherMixer和Jigsaw方案有效提高了大气预测模型的训练效率和预测精度，为未来大气预报技术的发展提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI-based methods have revolutionized atmospheric forecasting, with recentsuccesses in medium-range forecasting spurring the development of climatefoundation models. Accurate modeling of complex atmospheric dynamics at highspatial resolutions and longer lead times requires large neural networks andgigabyte-sized data samples, making accelerator memory and I/O-bandwidth thebottlenecks for model training. We introduce WeatherMixer, amulti-layer-perceptron-based architecture whose workload scales linearly withinput size, allowing the model to learn global weather phenomena at accuraciessimilar to numerical weather prediction. To cope with the computational demand,we propose Jigsaw, a novel model parallelization scheme that employs bothdomain and tensor parallelism, eliminating memory redundancy. Jigsaw exceedsstate-of-the-art performance in strong scaling in compute-communication-limitedsystems and achieves superscalar weak scaling in I/O-bandwidth-limited systems.We scale training to 256 GPUs, reaching peak performances of 9 and 11 PFLOPs,23% and 28% of theoretical peaks, achieving 68% and 72% scaling efficiencyversus 51% without model parallelism.</description>
      <author>example@mail.com (Deifilia Kieckhefen, Markus Götz, Lars H. Heyen, Achim Streit, Charlotte Debus)</author>
      <guid isPermaLink="false">2507.05753v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Bit-Flip Fault Attack: Crushing Graph Neural Networks via Gradual Bit Search</title>
      <link>http://arxiv.org/abs/2507.05531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）对基于硬件的故障攻击的脆弱性，并提出了一种名为渐进步位翻转故障攻击（GBFA）的方法，通过在内存设备中注入故障来修改训练权重参数，以最小化位翻转数量来损害GNN的性能。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）已成为处理图结构数据的有力机器学习方法，但硬件加速器在满足GNNs实际应用性能需求的同时，其安全性问题通常被忽视。&lt;h4&gt;目的&lt;/h4&gt;提出一种层感知的位翻转故障攻击（GBFA），以损害GNN的性能，并通过最小化位翻转数量来降低攻击的复杂性。&lt;h4&gt;方法&lt;/h4&gt;GBFA通过两个步骤操作：首先，创建一个马尔可夫模型来预测基于内存访问模式提取的特征，从而在特定层内启动攻击；其次，使用层内搜索通过梯度排名识别所选权重中的脆弱位。&lt;h4&gt;主要发现&lt;/h4&gt;GBFA在Cora和PubMed数据集上对各种GNN模型进行节点分类任务时，显著降低了预测精度，并突出了在GNNs中采用层感知攻击策略的重要性。例如，在Cora数据集上，GBFA通过在最后一层翻转单个位，将GraphSAGE的预测精度降低了17%。&lt;h4&gt;结论&lt;/h4&gt;GBFA攻击对GNN模型的性能有显著影响，强调了在GNNs中采用层感知攻击策略的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have emerged as a powerful machine learning method for graph-structured data. A plethora of hardware accelerators has been introduced to meet the performance demands of GNNs in real-world applications. However, security challenges of hardware-based attacks have been generally overlooked. In this paper, we investigate the vulnerability of GNN models to hardware-based fault attack, wherein an attacker attempts to misclassify output by modifying trained weight parameters through fault injection in a memory device. Thus, we propose Gradual Bit-Flip Fault Attack (GBFA), a layer-aware bit-flip fault attack, selecting a vulnerable bit in each selected weight gradually to compromise the GNN's performance by flipping a minimal number of bits. To achieve this, GBFA operates in two steps. First, a Markov model is created to predict the execution sequence of layers based on features extracted from memory access patterns, enabling the launch of the attack within a specific layer. Subsequently, GBFA identifies vulnerable bits within the selected weights using gradient ranking through an in-layer search. We evaluate the effectiveness of the proposed GBFA attack on various GNN models for node classification tasks using the Cora and PubMed datasets. Our findings show that GBFA significantly degrades prediction accuracy, and the variation in its impact across different layers highlights the importance of adopting a layer-aware attack strategy in GNNs. For example, GBFA degrades GraphSAGE's prediction accuracy by 17% on the Cora dataset with only a single bit flip in the last layer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as a powerful machine learningmethod for graph-structured data. A plethora of hardware accelerators has beenintroduced to meet the performance demands of GNNs in real-world applications.However, security challenges of hardware-based attacks have been generallyoverlooked. In this paper, we investigate the vulnerability of GNN models tohardware-based fault attack, wherein an attacker attempts to misclassify outputby modifying trained weight parameters through fault injection in a memorydevice. Thus, we propose Gradual Bit-Flip Fault Attack (GBFA), a layer-awarebit-flip fault attack, selecting a vulnerable bit in each selected weightgradually to compromise the GNN's performance by flipping a minimal number ofbits. To achieve this, GBFA operates in two steps. First, a Markov model iscreated to predict the execution sequence of layers based on features extractedfrom memory access patterns, enabling the launch of the attack within aspecific layer. Subsequently, GBFA identifies vulnerable bits within theselected weights using gradient ranking through an in-layer search. We evaluatethe effectiveness of the proposed GBFA attack on various GNN models for nodeclassification tasks using the Cora and PubMed datasets. Our findings show thatGBFA significantly degrades prediction accuracy, and the variation in itsimpact across different layers highlights the importance of adopting alayer-aware attack strategy in GNNs. For example, GBFA degrades GraphSAGE'sprediction accuracy by 17% on the Cora dataset with only a single bit flip inthe last layer.</description>
      <author>example@mail.com (Sanaz Kazemi Abharian, Sai Manoj Pudukotai Dinakarrao)</author>
      <guid isPermaLink="false">2507.05531v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Tissue Concepts v2: a Supervised Foundation Model for whole slide images</title>
      <link>http://arxiv.org/abs/2507.05742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Tissue Concepts v2（TCv2），这是一种针对全切片图像的监督基础模型，用于解决基于大型数据库进行资源密集型训练的难题。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）正在改变计算病理学领域，通过提供分析组织病理学图像的新方法。创建FMs通常需要在大数据库上训练数周，是一个资源密集的过程。&lt;h4&gt;目的&lt;/h4&gt;提出Tissue Concepts v2（TCv2）以解决资源密集型训练的问题，并提高对癌症亚型的分类能力。&lt;h4&gt;方法&lt;/h4&gt;TCv2采用监督的端到端多任务学习，在切片级别标签上进行训练。其训练资源消耗相比自监督训练要少。&lt;h4&gt;主要发现&lt;/h4&gt;TCv2在癌症亚型分类基准测试中展现出比SSL训练的模型更优越的性能，并且完全使用免费数据训练。此外，共享的训练注意力模块为不同任务提供了额外的可解释性层。&lt;h4&gt;结论&lt;/h4&gt;Tissue Concepts v2（TCv2）是一个高效且可解释的监督基础模型，能够有效处理全切片图像，并在癌症亚型分类中表现出优异的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) are transforming the field of computational pathologyby offering new approaches to analyzing histopathology images. Typicallyrelying on weeks of training on large databases, the creation of FMs is aresource-intensive process in many ways. In this paper, we introduce theextension of our supervised foundation model, Tissue Concepts, to whole slideimages, called Tissue Concepts v2 (TCv2), a supervised foundation model forwhole slide images to address the issue above. TCv2 uses supervised, end-to-endmultitask learning on slide-level labels. Training TCv2 uses a fraction of thetraining resources compared to self-supervised training. The presented modelshows superior performance compared to SSL-trained models in cancer subtypingbenchmarks and is fully trained on freely available data. Furthermore, a sharedtrained attention module provides an additional layer of explainability acrossdifferent tasks.</description>
      <author>example@mail.com (Till Nicke, Daniela Scharcherer, Jan Raphael Schäfer, Natalia Artysh, Antje Prasse, André Homeyer, Andrea Schenk, Henning Höfener, Johannes Lotz)</author>
      <guid isPermaLink="false">2507.05742v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling</title>
      <link>http://arxiv.org/abs/2507.04801v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointGAC的新型聚类基于的点云建模方法，旨在解决传统方法在重建被遮挡区域时过度约束模型导致无法捕捉泛化特征的问题。&lt;h4&gt;背景&lt;/h4&gt;大多数被遮挡点云建模（MPM）方法遵循回归范式来重建被遮挡区域的坐标或特征，但往往过度约束模型学习被遮挡区域的细节，从而无法捕捉到泛化特征。&lt;h4&gt;目的&lt;/h4&gt;提出PointGAC方法，旨在通过聚类来对齐被遮挡区域的特征分布，以更有效地学习泛化特征表示。&lt;h4&gt;方法&lt;/h4&gt;PointGAC方法包括以下步骤：首先，使用几何感知分区策略提取初始补丁；然后，教师模型通过在线k-means算法更新代码簿；接着，将未被遮挡的特征分配给相应的聚类中心；最后，学生模型对重建的被遮挡特征进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;PointGAC方法通过识别被遮挡特征所属的聚类中心，使模型能够学习到更通用的特征表示，并通过代码簿维护机制提高了语义特征学习的效率。&lt;h4&gt;结论&lt;/h4&gt;实验验证了PointGAC方法在各种下游任务中的有效性，并提供了代码链接。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为PointGAC的新型聚类基于的点云建模方法，旨在解决传统方法在重建被遮挡区域时过度约束模型导致无法捕捉泛化特征的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most masked point cloud modeling (MPM) methods follow a regression paradigmto reconstruct the coordinate or feature of masked regions. However, they tendto over-constrain the model to learn the details of the masked region,resulting in failure to capture generalized features. To address thislimitation, we propose \textbf{\textit{PointGAC}}, a novel clustering-based MPMmethod that aims to align the feature distribution of masked regions.Specially, it features an online codebook-guided teacher-student framework.Firstly, it presents a geometry-aware partitioning strategy to extract initialpatches. Then, the teacher model updates a codebook via online k-means based onfeatures extracted from the complete patches. This procedure facilitatescodebook vectors to become cluster centers. Afterward, we assigns the unmaskedfeatures to their corresponding cluster centers, and the student model alignsthe assignment for the reconstructed masked features. This strategy focuses onidentifying the cluster centers to which the masked features belong, enablingthe model to learn more generalized feature representations. Benefiting from aproposed codebook maintenance mechanism, codebook vectors are actively updated,which further increases the efficiency of semantic feature learning.Experiments validate the effectiveness of the proposed method on variousdownstream tasks. Code is available at https://github.com/LAB123-tech/PointGAC</description>
      <author>example@mail.com (Abiao Li, Chenlei Lv, Yuming Fang, Yifan Zuo, Jian Zhang, Guofeng Mei)</author>
      <guid isPermaLink="false">2507.04801v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Inaugural MOASEI Competition at AAMAS'2025: A Technical Report</title>
      <link>http://arxiv.org/abs/2507.05469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Report from the MOASEI'2025 Competition held at AAMAS'2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了MOASEI竞赛，这是一个多智能体AI基准测试活动，旨在评估在开放世界条件下的决策能力。&lt;h4&gt;背景&lt;/h4&gt;MOASEI竞赛建立在free-range-zoo环境套件之上，引入了动态、部分可观察的领域，其中实体可能随时间出现、消失或改变行为。&lt;h4&gt;目的&lt;/h4&gt;竞赛旨在评估开放世界条件下的决策能力，并探索开放环境和协调复杂性的不同维度。&lt;h4&gt;方法&lt;/h4&gt;2025年竞赛包括三个赛道：Wildfire、Rideshare和Cybersecurity，共有来自国际机构的11个团队参与，提交了包括图神经网络、卷积架构、预测建模和大型语言模型驱动的元优化等多样化的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示了在开放环境中泛化和适应的潜在策略，为未来的研究提供了实证见解和基础设施。&lt;h4&gt;结论&lt;/h4&gt;本文详细介绍了竞赛的设计、发现和对开放智能体系统研究社区的贡献。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了开放智能体系统评估倡议（MOASEI）竞赛，这是一个旨在评估开放世界条件下决策能力的多智能体AI基准测试活动。基于free-range-zoo环境套件，MOASEI引入了动态、部分可观察的领域，其中实体可能随时间出现、消失或改变行为。2025年的竞赛包括三个赛道——Wildfire、Rideshare和Cybersecurity，每个赛道都突出了开放性和协调复杂性的不同维度。来自国际机构的11个团队参与了竞赛，其中四个团队提交了包括图神经网络、卷积架构、预测建模和大型语言模型驱动的元优化等多样化的解决方案。评估指标集中在预期效用、对扰动的鲁棒性和对环境变化的响应性。结果显示了在开放环境中泛化和适应的潜在策略，为未来的研究提供了实证见解和基础设施。本报告详细介绍了竞赛的设计、发现和对开放智能体系统研究社区的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the Methods for Open Agent Systems Evaluation Initiative (MOASEI)Competition, a multi-agent AI benchmarking event designed to evaluatedecision-making under open-world conditions. Built on the free-range-zooenvironment suite, MOASEI introduced dynamic, partially observable domains withagent and task openness--settings where entities may appear, disappear, orchange behavior over time. The 2025 competition featured threetracks--Wildfire, Rideshare, and Cybersecurity--each highlighting distinctdimensions of openness and coordination complexity. Eleven teams frominternational institutions participated, with four of those teams submittingdiverse solutions including graph neural networks, convolutional architectures,predictive modeling, and large language model--driven meta--optimization.Evaluation metrics centered on expected utility, robustness to perturbations,and responsiveness to environmental change. The results reveal promisingstrategies for generalization and adaptation in open environments, offeringboth empirical insight and infrastructure for future research. This reportdetails the competition's design, findings, and contributions to the open-agentsystems research community.</description>
      <author>example@mail.com (Ceferino Patino, Tyler J. Billings, Alireza Saleh Abadi, Daniel Redder, Adam Eck, Prashant Doshi, Leen-Kiat Soh)</author>
      <guid isPermaLink="false">2507.05469v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Self-Attention Based Multi-Scale Graph Auto-Encoder Network of 3D Meshes</title>
      <link>http://arxiv.org/abs/2507.05304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图卷积网络的3D几何网格网络（3DGeoMeshNet），用于在计算机视觉和图形应用中捕捉复杂的几何形状。该方法使用各向异性卷积层来学习空间域中的全局和局部特征，并在重建过程中保留了原始的多边形网格格式，从而提高了形状重建的准确性。&lt;h4&gt;背景&lt;/h4&gt;3D网格是计算机视觉和图形应用中捕捉复杂几何形状的基本数据表示。由于数据非欧几里得性质，将卷积神经网络（CNNs）扩展到不规则3D网格具有挑战性。图卷积网络（GCNs）通过在图结构数据上应用卷积提供了一种解决方案，但许多现有方法依赖于各向同性滤波器或谱分解，限制了它们捕捉局部和全局网格特征的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效学习全局和局部特征的3D几何网格网络，以提高形状重建的准确性。&lt;h4&gt;方法&lt;/h4&gt;3DGeoMeshNet使用各向异性卷积层来直接在空间域中学习全局和局部特征。与将网格转换为体素网格或点云等中间表示的先前方法不同，该方法在整个重建过程中保留了原始的多边形网格格式。该架构具有多尺度编码器-解码器结构，其中独立的全局和局部路径捕捉大规模几何结构和细粒度局部细节。&lt;h4&gt;主要发现&lt;/h4&gt;在COMA数据集上进行的广泛实验表明，3DGeoMeshNet在重建精度方面效率很高。&lt;h4&gt;结论&lt;/h4&gt;3DGeoMeshNet通过使用各向异性卷积层和保留原始网格格式，为3D网格的形状重建提供了一种高效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;3D网格是计算机视觉和图形应用中捕获复杂几何形状的基本数据表示。虽然卷积神经网络（CNNs）在结构化数据如图像方面表现出色，但将其扩展到不规则3D网格具有挑战性，因为数据的非欧几里得性质。图卷积网络（GCNs）通过在图结构数据上应用卷积提供了一种解决方案，但许多现有方法依赖于各向同性滤波器或谱分解，限制了它们捕捉局部和全局网格特征的能力。在本文中，我们引入了3D几何网格网络（3DGeoMeshNet），这是一种基于GCN的新型框架，使用各向异性卷积层有效地在空间域中直接学习全局和局部特征。与先前的方法不同，该方法在整个重建过程中保留了原始的多边形网格格式，从而实现了更准确的形状重建。我们的架构具有多尺度编码器-解码器结构，其中独立的全局和局部路径捕捉了大规模几何结构和细粒度局部细节。在包含人脸的COMA数据集上进行的广泛实验表明，3DGeoMeshNet在重建精度方面效率很高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D meshes are fundamental data representations for capturing complexgeometric shapes in computer vision and graphics applications. WhileConvolutional Neural Networks (CNNs) have excelled in structured data likeimages, extending them to irregular 3D meshes is challenging due to thenon-Euclidean nature of the data. Graph Convolutional Networks (GCNs) offer asolution by applying convolutions to graph-structured data, but many existingmethods rely on isotropic filters or spectral decomposition, limiting theirability to capture both local and global mesh features. In this paper, weintroduce 3D Geometric Mesh Network (3DGeoMeshNet), a novel GCN-based frameworkthat uses anisotropic convolution layers to effectively learn both global andlocal features directly in the spatial domain. Unlike previous approaches thatconvert meshes into intermediate representations like voxel grids or pointclouds, our method preserves the original polygonal mesh format throughout thereconstruction process, enabling more accurate shape reconstruction. Ourarchitecture features a multi-scale encoder-decoder structure, where separateglobal and local pathways capture both large-scale geometric structures andfine-grained local details. Extensive experiments on the COMA datasetcontaining human faces demonstrate the efficiency of 3DGeoMeshNet in terms ofreconstruction accuracy.</description>
      <author>example@mail.com (Saqib Nazir, Olivier Lézoray, Sébastien Bougleux)</author>
      <guid isPermaLink="false">2507.05304v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data</title>
      <link>http://arxiv.org/abs/2507.05660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TuneShield，一个用于在聊天机器人微调过程中减轻毒性的防御框架。&lt;h4&gt;背景&lt;/h4&gt;近年来，基础模型如LLMs在对话AI领域取得了显著进展，但定制LLMs时减轻毒性，尤其是在处理不可信训练数据时，仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出TuneShield框架，旨在在保持对话质量的同时减轻聊天机器人微调过程中的毒性。&lt;h4&gt;方法&lt;/h4&gt;TuneShield利用基于LLM的毒性分类，通过LLMs的指令遵循能力和安全性对齐，有效识别有毒样本，并生成基于有毒样本的合成对话样本，称为'恢复数据'，用于减轻毒性并强化期望行为。&lt;h4&gt;主要发现&lt;/h4&gt;TuneShield能够有效减轻毒性注入攻击，即使在毒性分类器不完美或存在偏见的情况下也能保持对话质量。TuneShield对自适应敌对和越狱攻击具有弹性，并在基于对话的学习（DBL）中有效减轻自适应毒性注入攻击。&lt;h4&gt;结论&lt;/h4&gt;TuneShield是一个有效的防御框架，可以减轻聊天机器人微调过程中的毒性，同时保持对话质量，并抵抗多种攻击。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in foundation models, such as LLMs, have revolutionizedconversational AI. Chatbots are increasingly being developed by customizingLLMs on specific conversational datasets. However, mitigating toxicity duringthis customization, especially when dealing with untrusted training data,remains a significant challenge. To address this, we introduce TuneShield, adefense framework designed to mitigate toxicity during chatbot fine-tuningwhile preserving conversational quality. TuneShield leverages LLM-basedtoxicity classification, utilizing the instruction-following capabilities andsafety alignment of LLMs to effectively identify toxic samples, outperformingindustry API services. TuneShield generates synthetic conversation samples,termed 'healing data', based on the identified toxic samples, using them tomitigate toxicity while reinforcing desirable behavior during fine-tuning. Itperforms an alignment process to further nudge the chatbot towards producingdesired responses. Our findings show that TuneShield effectively mitigatestoxicity injection attacks while preserving conversational quality, even whenthe toxicity classifiers are imperfect or biased. TuneShield proves to beresilient against adaptive adversarial and jailbreak attacks. Additionally,TuneShield demonstrates effectiveness in mitigating adaptive toxicity injectionattacks during dialog-based learning (DBL).</description>
      <author>example@mail.com (Aravind Cheruvu, Shravya Kanchi, Sifat Muhammad Abdullah, Nicholas Kong, Daphne Yao, Murtuza Jadliwala, Bimal Viswanath)</author>
      <guid isPermaLink="false">2507.05660v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>MBFormer: A General Transformer-based Learning Paradigm for Many-body Interactions in Real Materials</title>
      <link>http://arxiv.org/abs/2507.05480v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对称性感知、无网格、Transformer架构的模型MBFormer，用于直接从平均场输入学习整个多体层次，并利用注意力机制精确捕捉平均场状态之间的多体相关性。&lt;h4&gt;背景&lt;/h4&gt;机器学习的快速发展推动了计算材料科学的革新，但量子多体问题由于非局部和能量依赖性相互作用的复杂性，在理解激发态性质方面仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;设计一个模型，能够直接从平均场输入学习整个多体层次，并准确预测材料科学中的相关性质。&lt;h4&gt;方法&lt;/h4&gt;提出了MBFormer模型，该模型使用注意力机制来捕捉平均场状态之间的多体相关性，并通过GW-BSE形式主义进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;MBFormer模型在C2DB数据库的721种二维材料数据集上训练，实现了最先进的性能，预测的虚粒子能量和激子能量的平均绝对误差在0.1-0.2 eV范围内。注意力机制在捕捉多体相关性方面起到了关键作用。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一个从基态到一般多体预测的端到端平台，可能成为计算材料科学的基础模型。&lt;h4&gt;翻译&lt;/h4&gt;最近，机器学习的巨大进步彻底改变了计算材料科学，实现了前所未有的材料发现和性质预测速度，但由于非局部和能量依赖性相互作用的复杂性，量子多体问题——这是理解从传输到光学等激发态性质的关键——仍然具有挑战性。在这里，我们提出了一种对称性感知、无网格、基于Transformer的模型，MBFormer，该模型旨在直接从平均场输入学习整个多体层次，利用注意力机制准确地捕捉平均场状态之间的多体相关性。作为原理证明，我们展示了MBFormer在基于GW-BSE（GW-贝特-萨利佩特方程）形式主义预测结果方面的能力，包括准粒子能量、激子能量、激子振荡强度和激子波函数分布。我们的模型在C2DB数据库的721种二维材料数据集上训练，在跨不同材料的态级准粒子能量和激子能量上实现了最先进的性能，预测的平均绝对误差（MAE）在0.1-0.2 eV的数量级。此外，我们明确表明注意力机制在捕捉多体相关性方面起着至关重要的作用。我们的框架提供了一个从基态到实际材料中的通用多体预测的端到端平台，这可以成为计算材料科学的基础模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, radical progress in machine learning (ML) has revolutionizedcomputational materials science, enabling unprecedentedly rapid materialsdiscovery and property prediction, but the quantum many-body problem -- whichis the key to understanding excited-state properties, ranging from transport tooptics -- remains challenging due to the complexity of the nonlocal andenergy-dependent interactions. Here, we propose a symmetry-aware, grid-free,transformer-based model, MBFormer, that is designed to learn the entiremany-body hierarchy directly from mean-field inputs, exploiting the attentionmechanism to accurately capture many-body correlations between mean-fieldstates. As proof of principle, we demonstrate the capability of MBFormer inpredicting results based on the GW plus Bethe Salpeter equation (GW-BSE)formalism, including quasiparticle energies, exciton energies, excitonoscillator strengths, and exciton wavefunction distribution. Our model istrained on a dataset of 721 two-dimensional materials from the C2DB database,achieving state-of-the-art performance with a low prediction mean absoluteerror (MAE) on the order of 0.1-0.2 eV for state-level quasiparticle andexciton energies across different materials. Moreover, we show explicitly thatthe attention mechanism plays a crucial role in capturing many-bodycorrelations. Our framework provides an end-to-end platform from ground statesto general many-body prediction in real materials, which could serve as afoundation model for computational materials science.</description>
      <author>example@mail.com (Bowen Hou, Xian Xu, Jinyuan Wu, Diana Y. Qiu)</author>
      <guid isPermaLink="false">2507.05480v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>PLACE: Prompt Learning for Attributed Community Search</title>
      <link>http://arxiv.org/abs/2507.05311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PLACE的图提示学习框架，用于属性社区搜索（ACS）。该框架借鉴了自然语言处理中的提示调整方法，通过将可学习的提示标记集成到图中，增强了图节点之间的连接，并采用交替训练方法和分而治之策略以提高模型的可扩展性。&lt;h4&gt;背景&lt;/h4&gt;属性社区搜索（ACS）是一个复杂的问题，需要有效识别结构凝聚力和属性相似性。&lt;h4&gt;目的&lt;/h4&gt;提出PLACE框架，以提高ACS查询的准确性。&lt;h4&gt;方法&lt;/h4&gt;PLACE框架通过以下方式实现：1. 在图中集成结构信息和可学习的提示标记；2. 使用交替训练方法优化提示参数和GNN；3. 采用分而治之策略提高模型的可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;在9个真实世界图上的实验表明，PLACE在三种类型的ACS查询上均比现有技术实现了更高的F1分数，平均提高了22%。&lt;h4&gt;结论&lt;/h4&gt;PLACE框架在ACS查询方面表现出显著的效果，是现有技术的有效改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose PLACE (Prompt Learning for Attributed CommunitySearch), an innovative graph prompt learning framework for ACS. Enlightened byprompt-tuning in Natural Language Processing (NLP), where learnable prompttokens are inserted to contextualize NLP queries, PLACE integrates structuraland learnable prompt tokens into the graph as a query-dependent refinementmechanism, forming a prompt-augmented graph. Within this prompt-augmented graphstructure, the learned prompt tokens serve as a bridge that strengthensconnections between graph nodes for the query, enabling the GNN to moreeffectively identify patterns of structural cohesiveness and attributesimilarity related to the specific query. We employ an alternating trainingparadigm to optimize both the prompt parameters and the GNN jointly. Moreover,we design a divide-and-conquer strategy to enhance scalability, supporting themodel to handle million-scale graphs. Extensive experiments on 9 real-worldgraphs demonstrate the effectiveness of PLACE for three types of ACS queries,where PLACE achieves higher F1 scores by 22% compared to the state-of-the-artson average.</description>
      <author>example@mail.com (Shuheng Fang, Kangfei Zhao, Rener Zhang, Yu Rong, Jeffrey Xu Yu)</author>
      <guid isPermaLink="false">2507.05311v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Driving as a Diagnostic Tool: Scenario-based Cognitive Assessment in Older Drivers From Driving Video</title>
      <link>http://arxiv.org/abs/2507.05463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于场景的认知状态识别方法，通过自然驾驶视频和大型视觉模型对老年驾驶者的认知状态进行评估。&lt;h4&gt;背景&lt;/h4&gt;当前诊断认知衰退（如阿尔茨海默病和轻度认知障碍）的方法耗时且成本高，导致这些疾病的诊断常常被低估。&lt;h4&gt;目的&lt;/h4&gt;通过分析驾驶行为中的“数字指纹”，旨在关联功能衰退和AD、MCI的临床特征，以早期检测认知衰退。&lt;h4&gt;方法&lt;/h4&gt;提出一个框架，使用大型视觉模型和自然驾驶视频来分析驾驶员行为，分类认知状态并预测疾病进展。&lt;h4&gt;主要发现&lt;/h4&gt;该方法利用现实世界驾驶行为与驾驶员当前认知状态之间的强关系，将车辆作为“诊断工具”，识别功能损害的早期预警信号。&lt;h4&gt;结论&lt;/h4&gt;该研究有助于早期检测，支持可扩展、非侵入性监测系统的发展，以减轻老龄化人口中认知衰退的社会和经济负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce scenario-based cognitive status identification in older driversfrom Naturalistic driving videos and large vision models. In recent times,cognitive decline, including Alzheimer's disease (AD) and mild cognitiveimpairment (MCI), is often underdiagnosed due to the time-consuming and costlynature of current diagnostic methods. By analyzing real-world driving behaviorcaptured through in-vehicle systems, this research aims to extract "digitalfingerprints" that correlate with functional decline and clinical features ofMCI and AD. Moreover, modern large vision models can draw meaningful insightsfrom everyday driving patterns of older patients to early detect cognitivedecline. We propose a framework that uses large vision models and naturalisticdriving videos to analyze driver behavior, classify cognitive status andpredict disease progression. We leverage the strong relationship betweenreal-world driving behavior as an observation of the current cognitive statusof the drivers where the vehicle can be utilized as a "diagnostic tool". Ourmethod identifies early warning signs of functional impairment, contributing toproactive intervention strategies. This work enhances early detection andsupports the development of scalable, non-invasive monitoring systems tomitigate the growing societal and economic burden of cognitive decline in theaging population.</description>
      <author>example@mail.com (Md Zahid Hasan, Guillermo Basulto-Elias, Jun Ha Chang, Sahuna Hallmark, Matthew Rizzo, Anuj Sharma, Soumik Sarkar)</author>
      <guid isPermaLink="false">2507.05463v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors</title>
      <link>http://arxiv.org/abs/2507.05426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对3D场景局部编辑的新方法，该方法通过结合2D扩散编辑和3D高斯分层技术，实现了对场景特定区域的精确编辑，同时保证了编辑的一致性和效率。&lt;h4&gt;背景&lt;/h4&gt;大多数3D场景编辑任务关注局部区域，而非整个场景，3D高斯分层（3DGS）技术允许对场景进行精确的区域编辑，但3D语义解析通常不如2D版本表现好，导致3D空间的编辑困难，影响编辑的保真度。&lt;h4&gt;目的&lt;/h4&gt;解决3D语义解析的不足，提高3D场景局部编辑的效率和保真度。&lt;h4&gt;方法&lt;/h4&gt;利用2D扩散编辑准确识别每个视图中的修改区域，然后进行逆渲染以进行3D定位，进一步细化正视图，并以由2D基础模型预测的深度图推导出的近似形状和一致性视图初始化粗略的3DGS，从而支持迭代、视图一致的编辑过程，逐步增强结构细节和纹理，确保视角之间的连贯性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法达到了最先进的性能，同时提供了高达4倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为3D场景局部编辑提供了一种更高效、更有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Many 3D scene editing tasks focus on modifying local regions rather than the entire scene, except for some global applications like style transfer, and in the context of 3D Gaussian Splatting (3DGS), where scenes are represented by a series of Gaussians, this structure allows for precise regional edits, offering enhanced control over specific areas of the scene; however, the challenge lies in the fact that 3D semantic parsing often underperforms compared to its 2D counterpart, making targeted manipulations within 3D spaces more difficult and limiting the fidelity of edits, which we address by leveraging 2D diffusion editing to accurately identify modification regions in each view, followed by inverse rendering for 3D localization, then refining the frontal view and initializing a coarse 3DGS with consistent views and approximate shapes derived from depth maps predicted by a 2D foundation model, thereby supporting an iterative, view-consistent editing process that gradually enhances structural details and textures to ensure coherence across perspectives. Experiments demonstrate that our method achieves state-of-the-art performance while delivering up to a 4× speedup, providing a more efficient and effective approach to 3D scene local editing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many 3D scene editing tasks focus on modifying local regions rather than theentire scene, except for some global applications like style transfer, and inthe context of 3D Gaussian Splatting (3DGS), where scenes are represented by aseries of Gaussians, this structure allows for precise regional edits, offeringenhanced control over specific areas of the scene; however, the challenge liesin the fact that 3D semantic parsing often underperforms compared to its 2Dcounterpart, making targeted manipulations within 3D spaces more difficult andlimiting the fidelity of edits, which we address by leveraging 2D diffusionediting to accurately identify modification regions in each view, followed byinverse rendering for 3D localization, then refining the frontal view andinitializing a coarse 3DGS with consistent views and approximate shapes derivedfrom depth maps predicted by a 2D foundation model, thereby supporting aniterative, view-consistent editing process that gradually enhances structuraldetails and textures to ensure coherence across perspectives. Experimentsdemonstrate that our method achieves state-of-the-art performance whiledelivering up to a $4\times$ speedup, providing a more efficient and effectiveapproach to 3D scene local editing.</description>
      <author>example@mail.com (Lanqing Guo, Yufei Wang, Hezhen Hu, Yan Zheng, Yeying Jin, Siyu Huang, Zhangyang Wang)</author>
      <guid isPermaLink="false">2507.05426v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>High Order Collaboration-Oriented Federated Graph Neural Network for Accurate QoS Prediction</title>
      <link>http://arxiv.org/abs/2507.05308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HC-FGNN的高阶协作型联邦图神经网络，用于在保持用户隐私的同时进行服务质量数据预测。&lt;h4&gt;背景&lt;/h4&gt;在云服务选择中，预测服务质量数据至关重要，但用户隐私也是一个关键问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够进行准确的服务质量预测并保护用户隐私的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过放大显式的用户-服务图，遵循注意力机制原则来获得高阶协作，从而反映隐式的用户-用户交互。此外，它采用基于轻量级消息聚合的方式来提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实应用中的服务质量数据集上的广泛实验表明，提出的HC-FGNN具有高预测准确性和隐私保护的优势。&lt;h4&gt;结论&lt;/h4&gt;HC-FGNN是一种有效的方法，可以在保护用户隐私的同时进行准确的服务质量预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting Quality of Service (QoS) data crucial for cloud service selection,where user privacy is a critical concern. Federated Graph Neural Networks(FGNNs) can perform QoS data prediction as well as maintaining user privacy.However, existing FGNN-based QoS predictors commonly implement on-devicetraining on scattered explicit user-service graphs, thereby failing to utilizethe implicit user-user interactions. To address this issue, this study proposesa high order collaboration-oriented federated graph neural network (HC-FGNN) toobtain accurate QoS prediction with privacy preservation. Concretely, itmagnifies the explicit user-service graphs following the principle of attentionmechanism to obtain the high order collaboration, which reflects the implicituser-user interactions. Moreover, it utilizes a lightweight-based messageaggregation way to improve the computational efficiency. The extensiveexperiments on two QoS datasets from real application indicate that theproposed HC-FGNN possesses the advantages of high prediction accurate andprivacy protection.</description>
      <author>example@mail.com (Zehuan Chen, Xiangwei Lai)</author>
      <guid isPermaLink="false">2507.05308v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>From General to Specialized: The Need for Foundational Models in Agriculture</title>
      <link>http://arxiv.org/abs/2507.05390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了食品安全在全球范围内的问题，并介绍了基于模型在农业监测方面的应用潜力，强调了针对农业任务开发专用基础模型的需求。&lt;h4&gt;背景&lt;/h4&gt;随着人口增长和气候变化加剧，食品安全成为全球关注的问题，需要创新解决方案来提高可持续农业生产力。&lt;h4&gt;目的&lt;/h4&gt;评估现有基础模型在农业任务中的有效性，并探讨开发针对农业的专用基础模型的需求。&lt;h4&gt;方法&lt;/h4&gt;定量评估现有基础模型，描述理想的农业基础模型（CropFM）的需求框架，调查和比较现有通用基础模型，并在三个代表性的农业特定任务中实证评估两个典型模型。&lt;h4&gt;主要发现&lt;/h4&gt;现有基础模型在农业监测任务中的应用潜力巨大，但针对农业的特定需求仍有待进一步探索。&lt;h4&gt;结论&lt;/h4&gt;开发专门针对农业的基础模型对于提高农业监测和生产力至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Food security remains a global concern as population grows and climate change intensifies, demanding innovative solutions for sustainable agricultural productivity. Recent advances in foundation models have demonstrated remarkable performance in remote sensing and climate sciences, and therefore offer new opportunities for agricultural monitoring. However, their application in challenges related to agriculture-such as crop type mapping, crop phenology estimation, and crop yield estimation-remains under-explored. In this work, we quantitatively evaluate existing foundational models to assess their effectiveness for a representative set of agricultural tasks. From an agricultural domain perspective, we describe a requirements framework for an ideal agricultural foundation model (CropFM). We then survey and compare existing general-purpose foundational models in this framework and empirically evaluate two exemplary of them in three representative agriculture specific tasks. Finally, we highlight the need for a dedicated foundational model tailored specifically to agriculture.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Food security remains a global concern as population grows and climate changeintensifies, demanding innovative solutions for sustainable agriculturalproductivity. Recent advances in foundation models have demonstrated remarkableperformance in remote sensing and climate sciences, and therefore offer newopportunities for agricultural monitoring. However, their application inchallenges related to agriculture-such as crop type mapping, crop phenologyestimation, and crop yield estimation-remains under-explored. In this work, wequantitatively evaluate existing foundational models to assess theireffectivity for a representative set of agricultural tasks. From anagricultural domain perspective, we describe a requirements framework for anideal agricultural foundation model (CropFM). We then survey and compareexisting general-purpose foundational models in this framework and empiricallyevaluate two exemplary of them in three representative agriculture specifictasks. Finally, we highlight the need for a dedicated foundational modeltailored specifically to agriculture.</description>
      <author>example@mail.com (Vishal Nedungadi, Xingguo Xiong, Aike Potze, Ron Van Bree, Tao Lin, Marc Rußwurm, Ioannis N. Athanasiadis)</author>
      <guid isPermaLink="false">2507.05390v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training</title>
      <link>http://arxiv.org/abs/2507.05386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对CPT中的两种核心后训练范式进行了比较分析，探讨了它们对知识保留的影响，并提出了改进RFT的算法。&lt;h4&gt;背景&lt;/h4&gt;CPT是一种有效的技术，用于适应特定和不断变化的下游任务，而其学习范式的作用尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究监督微调和强化微调两种后训练范式对CPT中知识保留的影响。&lt;h4&gt;方法&lt;/h4&gt;在七个多模态任务上进行了实验，使用Qwen2.5-VL-7B-Instruct作为CPT的基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;1. SFT在持续学习下游任务时会导致先前学习任务的灾难性遗忘，而RFT能够保留先前知识并达到多任务训练的性能。2. RFT在标准基准上保护并增强了模型的一般知识，而SFT严重降低了模型的一般能力。&lt;h4&gt;结论&lt;/h4&gt;RFT是一种稳健的CPT范式，通过其固有的隐式正则化减轻了遗忘。&lt;h4&gt;翻译&lt;/h4&gt;摘要：持续后训练（CPT）是一种流行的有效技术，用于适应像多模态大型语言模型这样的基础模型，以适应特定和不断发展的下游任务。虽然现有研究主要集中在数据重放、模型扩展或参数正则化等方法上，但CPT中学习范式的根本作用仍未得到充分探索。本文提出了两种核心后训练范式的比较分析：监督微调（SFT）和强化微调（RFT），并研究了它们对CPT中知识保留的各自影响。我们的实验在一个包含七个不同多模态任务的基准上执行，使用Qwen2.5-VL-7B-Instruct作为持续后训练的基础模型。调查产生了两个重要发现：（1）在持续学习下游任务时，SFT会导致先前学习任务的灾难性遗忘。相反，RFT固有地保留了先前知识，并实现了与多任务训练相当的性能。（2）RFT在标准基准（例如，MMMU和MMLU-Pro）上成功保护并增强了模型的一般知识。相反，SFT严重降低了模型的一般能力。进一步分析表明，显式机制，如KL惩罚和思维链推理，不是主要因素。相反，我们发现RFT内隐的正则化是减轻遗忘的关键因素。最后，我们提出了一个基于rollout的实例过滤算法来提高RFT的稳定性和效率。我们的全面研究证明了RFT作为持续后训练的稳健范式的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual post-training (CPT) is a popular and effective technique foradapting foundation models like multimodal large language models to specificand ever-evolving downstream tasks. While existing research has primarilyconcentrated on methods like data replay, model expansion, or parameterregularization, the fundamental role of the learning paradigm within CPTremains largely unexplored. This paper presents a comparative analysis of twocore post-training paradigms: supervised fine-tuning (SFT) and reinforcementfine-tuning (RFT), investigating their respective impacts on knowledgeretention during CPT. Our experiments are conducted on a benchmark comprisingseven diverse multimodal tasks, utilizing Qwen2.5-VL-7B-Instruct as the basemodel for continual post-training. The investigation yields two significantfindings: (1) When continuously learning on downstream tasks, SFT leads tocatastrophic forgetting of previously learned tasks. In contrast, RFTinherently preserves prior knowledge and achieve performance comparable tomulti-task training. (2) RFT successfully protects and even enhances themodel's general knowledge on standard benchmarks (e.g., MMMU and MMLU-Pro).Conversely, SFT degrades general model capabilities severely. Further analysisshows that explicit mechanisms, such as KL penalty and chain-of-thoughtreasoning, are not the primary factors. Instead, we find that the implicitregularization inherent to RFT is a key factor in mitigating forgetting.Finally, we propose a rollout-based instance filtering algorithm to improve thestability and efficiency of RFT. Our comprehensive study demonstrates thesuperiority of RFT as a robust paradigm for continual post-training.</description>
      <author>example@mail.com (Song Lai, Haohan Zhao, Rong Feng, Changyi Ma, Wenzhuo Liu, Hongbo Zhao, Xi Lin, Dong Yi, Min Xie, Qingfu Zhang, Hongbin Liu, Gaofeng Meng, Fei Zhu)</author>
      <guid isPermaLink="false">2507.05386v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Informed Graph Neural Networks to Reconstruct Local Fields Considering Finite Strain Hyperelasticity</title>
      <link>http://arxiv.org/abs/2507.05291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 17 figures, pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为P-DivGNN的物理信息机器学习框架，用于在给定周期性微结构网格和宏观应力值的多尺度模拟环境中重建微尺度应力场。&lt;h4&gt;背景&lt;/h4&gt;在多尺度模拟中，需要重建微尺度应力场，这对于断裂分析和局部疲劳标准定义至关重要。&lt;h4&gt;目的&lt;/h4&gt;重建局部应力场分布，提供由平均场降阶模型（ROM）或有限元（FE）模拟在宏观尺度上产生的平均应力值。&lt;h4&gt;方法&lt;/h4&gt;将周期性微结构表示为图，并结合消息传递图神经网络。在训练期间引入物理约束以约束局部应力场平衡状态，并采用周期图表示来强制执行周期性边界条件。&lt;h4&gt;主要发现&lt;/h4&gt;评估了所提出的物理信息GNN在考虑线性和非线性超弹性响应以及不同几何形状时的优点。在非线性超弹性情况下，与有限元模拟相比，该方法实现了显著的计算速度提升。&lt;h4&gt;结论&lt;/h4&gt;P-DivGNN在非线性超弹性情况下，特别适用于大规模应用，因为它可以显著加快计算速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a physics-informed machine learning framework called P-DivGNN toreconstruct local stress fields at the micro-scale, in the context ofmulti-scale simulation given a periodic micro-structure mesh and mean,macro-scale, stress values. This method is based in representing a periodicmicro-structure as a graph, combined with a message passing graph neuralnetwork. We are able to retrieve local stress field distributions, providingaverage stress values produced by a mean field reduced order model (ROM) orFinite Element (FE) simulation at the macro-scale. The prediction of localstress fields are of utmost importance considering fracture analysis or thedefinition of local fatigue criteria. Our model incorporates physicalconstraints during training to constraint local stress field equilibrium stateand employs a periodic graph representation to enforce periodic boundaryconditions. The benefits of the proposed physics-informed GNN are evaluatedconsidering linear and non linear hyperelastic responses applied to varyinggeometries. In the non-linear hyperelastic case, the proposed method achievessignificant computational speed-ups compared to FE simulation, making itparticularly attractive for large-scale applications.</description>
      <author>example@mail.com (Manuel Ricardo Guevara Garban, Yves Chemisky, Étienne Prulière, Michaël Clément)</author>
      <guid isPermaLink="false">2507.05291v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation</title>
      <link>http://arxiv.org/abs/2507.05331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对多任务机器人操作策略（LBMs）进行了严格评估，通过扩展Diffusion Policy范式，在模拟和真实机器人数据集上进行分析。&lt;h4&gt;背景&lt;/h4&gt;近年来，机器人操作领域取得了巨大进展，模仿学习策略使得复杂任务得以顺利完成。同时，数据规模和模型大小的增长推动了语言和视觉基础模型的发展，促使人们致力于创建通用机器人基础模型。&lt;h4&gt;目的&lt;/h4&gt;对LBMs进行严格评估，以统计置信度分析这些模型的性能。&lt;h4&gt;方法&lt;/h4&gt;通过模拟和真实世界实验，在受控环境中进行盲随机试验，与单任务基线进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;多任务预训练使策略更加成功和稳健，并能够更快地教授复杂新任务，所需数据量比单任务基线少。&lt;h4&gt;结论&lt;/h4&gt;随着预训练规模和多样性的增加，性能有望提高。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，机器人操作领域取得了巨大进展，模仿学习策略使得复杂任务得以顺利完成。同时，数据规模和模型大小的增长推动了语言和视觉基础模型的发展，促使人们致力于创建通用机器人基础模型。虽然这些模型受到了极大的热情和投资，但对其在实际世界中的性能的有效评估仍然是一个挑战，这限制了发展的步伐，并阻碍了对当前能力的细致理解。在本文中，我们通过扩展Diffusion Policy范式到模拟和真实世界机器人数据集，对多任务机器人操作策略（称为大型行为模型，LBMs）进行了严格评估。我们提出并验证了一个评估流程，以统计置信度严格分析这些模型的能力。我们在受控环境中通过盲随机试验与单任务基线进行比较，使用模拟和真实世界实验。我们发现，多任务预训练使策略更加成功和稳健，并且能够更快地使用较少的数据量教授复杂新任务。此外，随着预训练规模和多样性的增加，性能有望提高。项目页面：https://toyotaresearchinstitute.github.io/lbm1/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot manipulation has seen tremendous progress in recent years, withimitation learning policies enabling successful performance of dexterous andhard-to-model tasks. Concurrently, scaling data and model size has led to thedevelopment of capable language and vision foundation models, motivatinglarge-scale efforts to create general-purpose robot foundation models. Whilethese models have garnered significant enthusiasm and investment, meaningfulevaluation of real-world performance remains a challenge, limiting both thepace of development and inhibiting a nuanced understanding of currentcapabilities. In this paper, we rigorously evaluate multitask robotmanipulation policies, referred to as Large Behavior Models (LBMs), byextending the Diffusion Policy paradigm across a corpus of simulated andreal-world robot data. We propose and validate an evaluation pipeline torigorously analyze the capabilities of these models with statisticalconfidence. We compare against single-task baselines through blind, randomizedtrials in a controlled setting, using both simulation and real-worldexperiments. We find that multi-task pretraining makes the policies moresuccessful and robust, and enables teaching complex new tasks more quickly,using a fraction of the data when compared to single-task baselines. Moreover,performance predictably increases as pretraining scale and diversity grows.Project page: https://toyotaresearchinstitute.github.io/lbm1/</description>
      <author>example@mail.com (TRI LBM Team, Jose Barreiros, Andrew Beaulieu, Aditya Bhat, Rick Cory, Eric Cousineau, Hongkai Dai, Ching-Hsin Fang, Kunimatsu Hashimoto, Muhammad Zubair Irshad, Masha Itkina, Naveen Kuppuswamy, Kuan-Hui Lee, Katherine Liu, Dale McConachie, Ian McMahon, Haruki Nishimura, Calder Phillips-Grafflin, Charles Richter, Paarth Shah, Krishnan Srinivasan, Blake Wulfe, Chen Xu, Mengchao Zhang, Alex Alspach, Maya Angeles, Kushal Arora, Vitor Campagnolo Guizilini, Alejandro Castro, Dian Chen, Ting-Sheng Chu, Sam Creasey, Sean Curtis, Richard Denitto, Emma Dixon, Eric Dusel, Matthew Ferreira, Aimee Goncalves, Grant Gould, Damrong Guoy, Swati Gupta, Xuchen Han, Kyle Hatch, Brendan Hathaway, Allison Henry, Hillel Hochsztein, Phoebe Horgan, Shun Iwase, Donovon Jackson, Siddharth Karamcheti, Sedrick Keh, Joseph Masterjohn, Jean Mercat, Patrick Miller, Paul Mitiguy, Tony Nguyen, Jeremy Nimmer, Yuki Noguchi, Reko Ong, Aykut Onol, Owen Pfannenstiehl, Richard Poyner, Leticia Priebe Mendes Rocha, Gordon Richardson, Christopher Rodriguez, Derick Seale, Michael Sherman, Mariah Smith-Jones, David Tago, Pavel Tokmakov, Matthew Tran, Basile Van Hoorick, Igor Vasiljevic, Sergey Zakharov, Mark Zolotas, Rares Ambrus, Kerri Fetzer-Borelli, Benjamin Burchfiel, Hadas Kress-Gazit, Siyuan Feng, Stacie Ford, Russ Tedrake)</author>
      <guid isPermaLink="false">2507.05331v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Future Slot Prediction for Unsupervised Object Discovery in Surgical Video</title>
      <link>http://arxiv.org/abs/2507.01882v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为动态时间槽转换器（DTST）的新模块，用于处理手术视频中的复杂场景，并实现了在多个手术数据库上的最佳性能，证明了无监督学习在医疗健康领域的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;基于对象的槽注意力是近年来兴起的一种无监督学习方法，旨在学习结构化和可解释的对象中心表示（槽）。这种表示方法能够以低计算成本有效地进行推理，适用于医疗健康等关键应用，如实时手术视频解析。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在手术视频中表现不佳的问题，并提出一种新的模型，能够在复杂场景下实现有效的对象和事件推理。&lt;h4&gt;方法&lt;/h4&gt;提出了动态时间槽转换器（DTST）模块，该模块不仅用于时间推理，还用于预测最佳的未来槽初始化，从而在手术视频中实现高效的数据解析。&lt;h4&gt;主要发现&lt;/h4&gt;DTST模型在多个手术数据库上达到了最先进的性能，证明了无监督学习可以应用于实际数据，并成为医疗健康应用中的常规工具。&lt;h4&gt;结论&lt;/h4&gt;无监督学习的方法能够有效地应用于实际数据，为医疗健康领域的应用提供了新的可能性，尤其是在处理复杂场景时，如手术视频的实时解析。&lt;h4&gt;翻译&lt;/h4&gt;摘要：以对象为中心的槽注意力是一种新兴的无监督学习方法，用于学习结构化和可解释的对象中心表示（槽）。这能够以低计算成本有效地进行对象和事件的推理，因此适用于如实时手术视频解析等关键医疗应用。然而，现实世界的应用场景，如手术，其复杂场景难以解析为有意义的槽集合。当前具有自适应槽计数的方法在图像上表现良好，但在手术视频上的性能较低。为了应对这一挑战，我们提出了一个动态时间槽转换器（DTST）模块，该模块同时训练用于时间推理和预测最佳未来槽初始化。该模型在多个手术数据库上实现了最先进的性能，表明无监督学习可以应用于实际数据，并成为医疗健康应用中常用的一部分。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric slot attention is an emerging paradigm for unsupervisedlearning of structured, interpretable object-centric representations (slots).This enables effective reasoning about objects and events at a lowcomputational cost and is thus applicable to critical healthcare applications,such as real-time interpretation of surgical video. The heterogeneous scenes inreal-world applications like surgery are, however, difficult to parse into ameaningful set of slots. Current approaches with an adaptive slot count performwell on images, but their performance on surgical videos is low. To addressthis challenge, we propose a dynamic temporal slot transformer (DTST) modulethat is trained both for temporal reasoning and for predicting the optimalfuture slot initialization. The model achieves state-of-the-art performance onmultiple surgical databases, demonstrating that unsupervised object-centricmethods can be applied to real-world data and become part of the common arsenalin healthcare applications.</description>
      <author>example@mail.com (Guiqiu Liao, Matjaz Jogan, Marcel Hussing, Edward Zhang, Eric Eaton, Daniel A. Hashimoto)</author>
      <guid isPermaLink="false">2507.01882v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>MedGemma Technical Report</title>
      <link>http://arxiv.org/abs/2507.05201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MedGemma是一个基于Gemma 3 4B和27B的医学视觉语言基础模型集合，在医学图像和文本理解方面表现出色，有助于加速医疗AI应用的发展。&lt;h4&gt;背景&lt;/h4&gt;人工智能在医疗领域的应用具有巨大潜力，但训练和部署面临数据多样性、任务复杂性和隐私保护等挑战。&lt;h4&gt;目的&lt;/h4&gt;开发出在医学任务上表现良好且需要较少特定任务调整数据的模型，以加速医疗AI应用的发展。&lt;h4&gt;方法&lt;/h4&gt;引入了MedGemma，这是一个基于Gemma 3 4B和27B的医学视觉语言基础模型集合，并在多个医学任务上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;MedGemma在医学多模态问答、胸部X光发现分类和代理评估等任务上均取得了显著提升，同时在电子健康记录信息检索、气胸分类和病理切片分类等子领域中也表现出色。&lt;h4&gt;结论&lt;/h4&gt;MedGemma集合为医学图像和文本理解提供了强大的基础，有望显著加速医学研究和下游应用的开发。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcare's diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10% improvement on medical multimodal question answering, 15.5-18.1% improvement on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at https://goo.gle/medgemma.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has significant potential in healthcareapplications, but its training and deployment faces challenges due tohealthcare's diverse data, complex tasks, and the need to preserve privacy.Foundation models that perform well on medical tasks and require lesstask-specific tuning data are critical to accelerate the development ofhealthcare AI applications. We introduce MedGemma, a collection of medicalvision-language foundation models based on Gemma 3 4B and 27B. MedGemmademonstrates advanced medical understanding and reasoning on images and text,significantly exceeding the performance of similar-sized generative models andapproaching the performance of task-specific models, while maintaining thegeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,MedGemma achieves 2.6-10% improvement on medical multimodal question answering,15.5-18.1% improvement on chest X-ray finding classification, and 10.8%improvement on agentic evaluations compared to the base models. Fine-tuningMedGemma further improves performance in subdomains, reducing errors inelectronic health record information retrieval by 50% and reaching comparableperformance to existing specialized state-of-the-art methods for pneumothoraxclassification and histopathology patch classification. We additionallyintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.MedSigLIP powers the visual understanding capabilities of MedGemma and as anencoder achieves comparable or better performance than specialized medicalimage encoders. Taken together, the MedGemma collection provides a strongfoundation of medical image and text capabilities, with potential tosignificantly accelerate medical research and development of downstreamapplications. The MedGemma collection, including tutorials and model weights,can be found at https://goo.gle/medgemma.</description>
      <author>example@mail.com (Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil, Cían Hughes, Charles Lau, Justin Chen, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Stefanie Anna Baby, Susanna Maria Baby, Jeremy Lai, Samuel Schmidgall, Lu Yang, Kejia Chen, Per Bjornsson, Shashir Reddy, Ryan Brush, Kenneth Philbrick, Howard Hu, Howard Yang, Richa Tiwari, Sunny Jansen, Preeti Singh, Yun Liu, Shekoofeh Azizi, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean-bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Elena Buchatskaya, Jean-Baptiste Alayrac, Dmitry Lepikhin, Vlad Feinberg, Sebastian Borgeaud, Alek Andreev, Cassidy Hardin, Robert Dadashi, Léonard Hussenot, Armand Joulin, Olivier Bachem, Yossi Matias, Katherine Chou, Avinatan Hassidim, Kavi Goel, Clement Farabet, Joelle Barral, Tris Warkentin, Jonathon Shlens, David Fleet, Victor Cotruta, Omar Sanseviero, Gus Martins, Phoebe Kirk, Anand Rao, Shravya Shetty, David F. Steiner, Can Kirmizibayrak, Rory Pilgrim, Daniel Golden, Lin Yang)</author>
      <guid isPermaLink="false">2507.05201v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts</title>
      <link>http://arxiv.org/abs/2507.05321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of  Foundation Models: Opportunities, Challenges and Futures (MAS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;AGACCI是一个多智能体系统，用于改进代码评估的准确性、可解释性和一致性。&lt;h4&gt;背景&lt;/h4&gt;AI辅助教育中，视觉语言模型（VLMs）被集成到学术评估中，但现有基于VLM的方法在处理需要结构化推理和明确评估标准的复杂教育工件时存在困难。&lt;h4&gt;目的&lt;/h4&gt;引入AGACCI，以提高代码评估的准确性、可解释性和一致性。&lt;h4&gt;方法&lt;/h4&gt;AGACCI通过将专门的评估角色分配给协作智能体来分布评估任务。为了评估该框架，收集了360个研究生级别的基于代码的作业，由领域专家进行标注，并提供了二元评分和定性反馈。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，AGACCI在评分和反馈的准确性、相关性、一致性和连贯性方面优于基于GPT的单个基线，同时保留了专家评估的教学意图和评估深度。&lt;h4&gt;结论&lt;/h4&gt;AGACCI突显了多智能体系统在可扩展和情境感知教育评估中的潜力，尽管性能在不同任务类型之间存在差异。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期人工智能辅助教育的发展推动了视觉语言模型（VLMs）在学术评估中的应用，特别是在需要定量和定性评估的任务中。然而，现有的基于VLM的方法在处理需要结构化推理和与明确定义的评估标准对齐的复杂教育工件时遇到了困难。我们引入了AGACCI，一个多智能体系统，通过将专门的评估角色分配给协作智能体来提高代码评估的准确性、可解释性和一致性。为了评估这个框架，我们收集了360个来自60名参与者的研究生级别的基于代码的作业，每个作业都由领域专家进行了二元评分和定性反馈的标注。实验结果表明，AGACCI在评分和反馈的准确性、相关性、一致性和连贯性方面优于基于GPT的单个基线，同时保留了专家评估的教学意图和评估深度。尽管性能在不同任务类型之间存在差异，AGACCI突显了多智能体系统在可扩展和情境感知教育评估中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI-assisted education have encouraged the integration ofvision-language models (VLMs) into academic assessment, particularly for tasksthat require both quantitative and qualitative evaluation. However, existingVLM based approaches struggle with complex educational artifacts, such asprogramming tasks with executable components and measurable outputs, thatrequire structured reasoning and alignment with clearly defined evaluationcriteria. We introduce AGACCI, a multi-agent system that distributesspecialized evaluation roles across collaborative agents to improve accuracy,interpretability, and consistency in code-oriented assessment. To evaluate theframework, we collected 360 graduate-level code-based assignments from 60participants, each annotated by domain experts with binary rubric scores andqualitative feedback. Experimental results demonstrate that AGACCI outperformsa single GPT-based baseline in terms of rubric and feedback accuracy,relevance, consistency, and coherence, while preserving the instructionalintent and evaluative depth of expert assessments. Although performance variesacross task types, AGACCI highlights the potential of multi-agent systems forscalable and context-aware educational evaluation.</description>
      <author>example@mail.com (Kwangsuk Park, Jiwoong Yang)</author>
      <guid isPermaLink="false">2507.05321v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>When Does Pruning Benefit Vision Representations?</title>
      <link>http://arxiv.org/abs/2507.01722v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 23rd International Conference on Image Analysis and  Processing (ICIAP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了剪枝对视觉模型的影响，特别是在可解释性、无监督对象发现和与人类感知对齐三个方面。&lt;h4&gt;背景&lt;/h4&gt;剪枝广泛用于降低深度学习模型的复杂性，但其对可解释性和表示学习的影响尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;研究剪枝如何影响视觉模型，并探讨其与人类感知的对齐。&lt;h4&gt;方法&lt;/h4&gt;分析不同的视觉网络架构，考察不同稀疏度水平如何影响特征归因的可解释性方法；探索剪枝是否促进更简洁和结构化的表示，通过丢弃冗余信息来提高无监督对象发现；评估剪枝是否增强了模型表示与人类感知之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;发现存在“甜点”，其中稀疏模型表现出更高的可解释性、下游泛化能力和与人类的对齐。然而，这些点高度依赖于网络架构及其可训练参数的数量。&lt;h4&gt;结论&lt;/h4&gt;强调了这三个维度之间的复杂相互作用，突出了研究何时以及如何剪枝对视觉表示有益的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pruning is widely used to reduce the complexity of deep learning models, butits effects on interpretability and representation learning remain poorlyunderstood. This paper investigates how pruning influences vision models acrossthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,and (iii) alignment with human perception. We first analyze different visionnetwork architectures to examine how varying sparsity levels affect featureattribution interpretability methods. Additionally, we explore whether pruningpromotes more succinct and structured representations, potentially improvingunsupervised object discovery by discarding redundant information whilepreserving essential features. Finally, we assess whether pruning enhances thealignment between model representations and human perception, investigatingwhether sparser models focus on more discriminative features similarly tohumans. Our findings also reveal the presence of sweet spots, where sparsemodels exhibit higher interpretability, downstream generalization and humanalignment. However, these spots highly depend on the network architectures andtheir size in terms of trainable parameters. Our results suggest a complexinterplay between these three dimensions, highlighting the importance ofinvestigating when and how pruning benefits vision representations.</description>
      <author>example@mail.com (Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto)</author>
      <guid isPermaLink="false">2507.01722v3</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks</title>
      <link>http://arxiv.org/abs/2507.05271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于检测隐含性别歧视的Adaptive Supervised Contrastive lEarning（ASCEND）框架，该框架通过阈值对比学习方法提高了隐含性别歧视检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;社交媒体的全球影响力放大了仇恨内容的传播，包括通常被传统检测方法忽视的隐含性别歧视。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来检测隐含性别歧视，并提高检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;ASCEND框架通过以下方式实现：1）采用基于阈值的对比学习方法；2）通过计算嵌入之间的余弦相似度，将超过可学习阈值的样本对视为正样本；3）通过优化对比损失和交叉熵损失来实现最终的分类；4）通过词级注意力模块增强文本特征；5）使用情感、情绪和毒性特征。&lt;h4&gt;主要发现&lt;/h4&gt;在EXIST2021和MLSC数据集上的评估表明，ASCEND在多个任务上显著优于现有方法，平均宏F1值分别提高了9.86%、29.63%和32.51%，突显了其在捕捉隐含性别歧视语言微妙线索方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;ASCEND框架能够有效检测隐含性别歧视，并优于现有方法，为隐含性别歧视的检测提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;The global reach of social media has amplified the spread of hateful content, including implicit sexism, which is often overlooked by conventional detection methods. In this work, we introduce an Adaptive Supervised Contrastive lEarning framework for implicit sexism detection (ASCEND). A key innovation of our method is the incorporation of threshold-based contrastive learning: by computing cosine similarities between embeddings, we selectively treat only those sample pairs as positive if their similarity exceeds a learnable threshold. This mechanism refines the embedding space by robustly pulling together representations of semantically similar texts while pushing apart dissimilar ones, thus reducing false positives and negatives. The final classification is achieved by jointly optimizing a contrastive loss with a cross-entropy loss. Textual features are enhanced through a word-level attention module. Additionally, we employ sentiment, emotion, and toxicity features. Evaluations on the EXIST2021 and MLSC datasets demonstrate that ASCEND significantly outperforms existing methods, with average Macro F1 improvements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting its efficacy in capturing the subtle cues of implicit sexist language.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The global reach of social media has amplified the spread of hateful content,including implicit sexism, which is often overlooked by conventional detectionmethods. In this work, we introduce an Adaptive Supervised Contrastive lEarningframework for implicit sexism detectioN (ASCEND). A key innovation of ourmethod is the incorporation of threshold-based contrastive learning: bycomputing cosine similarities between embeddings, we selectively treat onlythose sample pairs as positive if their similarity exceeds a learnablethreshold. This mechanism refines the embedding space by robustly pullingtogether representations of semantically similar texts while pushing apartdissimilar ones, thus reducing false positives and negatives. The finalclassification is achieved by jointly optimizing a contrastive loss with across-entropy loss. Textual features are enhanced through a word-levelattention module. Additionally, we employ sentiment, emotion, and toxicityfeatures. Evaluations on the EXIST2021 and MLSC datasets demonstrate thatASCEND significantly outperforms existing methods, with average Macro F1improvements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlightingits efficacy in capturing the subtle cues of implicit sexist language.</description>
      <author>example@mail.com (Mohammad Zia Ur Rehman, Aditya Shah, Nagendra Kumar)</author>
      <guid isPermaLink="false">2507.05271v1</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised learning of speech representations with Dutch archival data</title>
      <link>http://arxiv.org/abs/2507.04554v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用荷兰档案馆电视广播数据对语音基础模型wav2vec 2.0进行自监督学习。&lt;h4&gt;背景&lt;/h4&gt;研究了预训练数据质量假设，探讨了音乐、噪声和说话人重叠对自监督学习收敛和下游微调性能的影响。&lt;h4&gt;目的&lt;/h4&gt;目的是通过预训练和优化预处理策略，提高wav2vec 2.0模型在荷兰语言上的性能。&lt;h4&gt;方法&lt;/h4&gt;采用了 Whisper 和 WhisperX 进行数据预处理，比较了单语种和多语种预训练，并通过在wav2vec 2.0 XLS-R模型上继续预训练来达到最先进的LARGE wav2vec 2.0模型。&lt;h4&gt;主要发现&lt;/h4&gt;发现单语种预训练对域外数据更具鲁棒性，并通过数据预处理提高了数据质量。&lt;h4&gt;结论&lt;/h4&gt;实现了针对荷兰语言的LARGE wav2vec 2.0模型，达到当前最佳水平。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了使用荷兰档案馆电视广播数据对语音基础模型wav2vec 2.0进行自监督学习的研究。首先研究了预训练数据质量假设，展示了音乐、噪声和说话人重叠如何影响自监督学习的收敛和下游微调性能。其次，探讨了有效的前处理策略，通过使用Whisper和WhisperX将噪声广播数据集转换为适用于预训练的高质量数据集。第三，比较了单语种和多语种预训练，并展示了单语种预训练对域外数据更具鲁棒性。最后，通过在wav2vec 2.0 XLS-R模型上继续预训练并结合55k小时档案数据集，实现了针对荷兰语言的LARGE wav2vec 2.0模型，达到了当前最佳水平。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the use of Dutch archival television broadcast data forself-supervised learning of speech foundation models, specifically wav2vec 2.0.We first study data quality assumptions for pre-training, and show how music,noise and speaker overlap affect SSL convergence and downstream fine-tuningperformance. Secondly, we explore effectively pre-processing strategies toconvert the noisy broadcast dataset into a qualitative dataset forpre-training, by using Whisper and WhisperX. Thirdly, we compare mono-lingualand multi-lingual pre-training with equivalent amounts of data, and show thatmono-lingual pre-training is more robust to out-of-domain data. Lastly, weachieve a state-of-the-art LARGE wav2vec 2.0 model for the Dutch language, by acontinuation of pre-training a wav2vec 2.0 XLS-R model checkpoint with our 55khour archival dataset.</description>
      <author>example@mail.com (Nik Vaessen, Roeland Ordelman, David A. van Leeuwen)</author>
      <guid isPermaLink="false">2507.04554v2</guid>
      <pubDate>Wed, 09 Jul 2025 14:22:39 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.04411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自监督对比学习（CL）的理论基础，并提出了解决其不完整性的方法。&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习在实际应用中取得成功，但其理论基础尚未完全确立。&lt;h4&gt;目的&lt;/h4&gt;揭示标准CL目标与称为负样本监督对比损失（NSCL）的监督变体之间的联系，并分析这两种损失之间的关系。&lt;h4&gt;方法&lt;/h4&gt;证明了随着语义类别的增加，CL和NSCL损失之间的差距消失，且该结论与标签无关且与架构无关。分析了NSCL损失的全局最小者的几何结构，并引入了线性探针的少量样本错误的新界限。&lt;h4&gt;主要发现&lt;/h4&gt;CL和NSCL损失之间的差距随类别数量增加而减少；两者高度相关；最小化CL损失会使得NSCL损失接近直接最小化的值；提出的少量样本错误界限在实际探针性能中提供了紧密的估计。&lt;h4&gt;结论&lt;/h4&gt;本文的理论发现通过实证验证，为自监督对比学习提供了新的理解和指导。&lt;h4&gt;翻译&lt;/h4&gt;Despite its empirical success, the theoretical foundations of self-supervised contrastive learning (CL) are not yet fully established. In this work, we address this gap by showing that standard CL objectives implicitly approximate a supervised variant we call the negatives-only supervised contrastive loss (NSCL), which excludes same-class contrasts. We prove that the gap between the CL and NSCL losses vanishes as the number of semantic classes increases, under a bound that is both label-agnostic and architecture-independent. We characterize the geometric structure of the global minimizers of the NSCL loss: the learned representations exhibit augmentation collapse, within-class collapse, and class centers that form a simplex equiangular tight frame. We further introduce a new bound on the few-shot error of linear-probing. This bound depends on two measures of feature variability--within-class dispersion and variation along the line between class centers. We show that directional variation dominates the bound and that the within-class dispersion's effect diminishes as the number of labeled samples increases. These properties enable CL and NSCL-trained representations to support accurate few-shot label recovery using simple linear probes. Finally, we empirically validate our theoretical findings: the gap between CL and NSCL losses decays at a rate of O(1/#classes); the two losses are highly correlated; minimizing the CL loss implicitly brings the NSCL loss close to the value achieved by direct minimization; and the proposed few-shot error bound provides a tight estimate of probing performance in practice.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite its empirical success, the theoretical foundations of self-supervisedcontrastive learning (CL) are not yet fully established. In this work, weaddress this gap by showing that standard CL objectives implicitly approximatea supervised variant we call the negatives-only supervised contrastive loss(NSCL), which excludes same-class contrasts. We prove that the gap between theCL and NSCL losses vanishes as the number of semantic classes increases, undera bound that is both label-agnostic and architecture-independent.  We characterize the geometric structure of the global minimizers of the NSCLloss: the learned representations exhibit augmentation collapse, within-classcollapse, and class centers that form a simplex equiangular tight frame. Wefurther introduce a new bound on the few-shot error of linear-probing. Thisbound depends on two measures of feature variability--within-class dispersionand variation along the line between class centers. We show that directionalvariation dominates the bound and that the within-class dispersion's effectdiminishes as the number of labeled samples increases. These properties enableCL and NSCL-trained representations to support accurate few-shot label recoveryusing simple linear probes.  Finally, we empirically validate our theoretical findings: the gap between CLand NSCL losses decays at a rate of $\mathcal{O}(\frac{1}{\#\text{classes}})$;the two losses are highly correlated; minimizing the CL loss implicitly bringsthe NSCL loss close to the value achieved by direct minimization; and theproposed few-shot error bound provides a tight estimate of probing performancein practice.</description>
      <author>example@mail.com (Achleshwar Luthra, Tianbao Yang, Tomer Galanti)</author>
      <guid isPermaLink="false">2506.04411v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
  <item>
      <title>All in One: Visual-Description-Guided Unified Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2507.05211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VDG-Uni3DSeg是一种新型框架，用于3D点云的统一分割，通过整合预训练的视觉-语言模型和大型语言模型来增强3D分割，并在语义、实例和全景分割中取得最先进的结果。&lt;h4&gt;背景&lt;/h4&gt;3D点云的统一分割对于场景理解至关重要，但受到其稀疏结构、有限标注以及复杂环境中区分细粒度物体类别的挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出VDG-Uni3DSeg框架，旨在提高3D分割的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;VDG-Uni3DSeg通过利用大型语言模型生成的文本描述和互联网上的参考图像，结合预训练的视觉-语言模型和大型语言模型，设计了一种语义-视觉对比损失和空间增强模块，以实现细粒度类别和实例的分离。&lt;h4&gt;主要发现&lt;/h4&gt;VDG-Uni3DSeg在语义、实例和全景分割中实现了最先进的结果，提供了一个可扩展且实用的3D理解解决方案。&lt;h4&gt;结论&lt;/h4&gt;VDG-Uni3DSeg是一个有效的3D点云分割方法，通过整合多种模态信息，提高了分割的准确性，并提供了可访问的代码以供进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unified segmentation of 3D point clouds is crucial for scene understanding,but is hindered by its sparse structure, limited annotations, and the challengeof distinguishing fine-grained object classes in complex environments. Existingmethods often struggle to capture rich semantic and contextual information dueto limited supervision and a lack of diverse multimodal cues, leading tosuboptimal differentiation of classes and instances. To address thesechallenges, we propose VDG-Uni3DSeg, a novel framework that integratespre-trained vision-language models (e.g., CLIP) and large language models(LLMs) to enhance 3D segmentation. By leveraging LLM-generated textualdescriptions and reference images from the internet, our method incorporatesrich multimodal cues, facilitating fine-grained class and instance separation.We further design a Semantic-Visual Contrastive Loss to align point featureswith multimodal queries and a Spatial Enhanced Module to model scene-widerelationships efficiently. Operating within a closed-set paradigm that utilizesmultimodal knowledge generated offline, VDG-Uni3DSeg achieves state-of-the-artresults in semantic, instance, and panoptic segmentation, offering a scalableand practical solution for 3D understanding. Our code is available athttps://github.com/Hanzy1996/VDG-Uni3DSeg.</description>
      <author>example@mail.com (Zongyan Han, Mohamed El Amine Boudjoghra, Jiahua Dong, Jinhong Wang, Rao Muhammad Anwer)</author>
      <guid isPermaLink="false">2507.05211v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>From Marginal to Joint Predictions: Evaluating Scene-Consistent Trajectory Prediction Approaches for Automated Driving</title>
      <link>http://arxiv.org/abs/2507.05254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference on Intelligent Transportation  Systems 2025 (ITSC 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究不同联合运动预测方法，以改善自动驾驶车辆在动态环境中的安全与高效运行。&lt;h4&gt;背景&lt;/h4&gt;现有的边缘预测模型通常独立预测每个代理的未来轨迹，这可能导致自动驾驶车辆的规划决策次优。&lt;h4&gt;目的&lt;/h4&gt;通过考虑代理之间的相互作用，实现场景层面的社会和物理一致性预测。&lt;h4&gt;方法&lt;/h4&gt;系统研究了包括边缘预测的后处理、显式训练联合预测模型以及将问题作为生成任务来处理的不同方法。&lt;h4&gt;主要发现&lt;/h4&gt;评估了每种方法的预测准确性、多模态性和推理效率，提供了对每种方法优缺点全面的分析。&lt;h4&gt;结论&lt;/h4&gt;提供了一些预测示例，详细内容可在指定的网站上查看。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Accurate motion prediction of surrounding traffic participants is crucial for the safe and efficient operation of automated vehicles in dynamic environments. Marginal prediction models commonly forecast each agent's future trajectories independently, often leading to sub-optimal planning decisions for an automated vehicle. In contrast, joint prediction models explicitly account for the interactions between agents, yielding socially and physically consistent predictions on a scene level. However, existing approaches differ not only in their problem formulation but also in the model architectures and implementation details used, making it difficult to compare them. In this work, we systematically investigate different approaches to joint motion prediction, including post-processing of the marginal predictions, explicitly training the model for joint predictions, and framing the problem as a generative task. We evaluate each approach in terms of prediction accuracy, multi-modality, and inference efficiency, offering a comprehensive analysis of the strengths and limitations of each approach. Several prediction examples are available at https://frommarginaltojointpred.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate motion prediction of surrounding traffic participants is crucial forthe safe and efficient operation of automated vehicles in dynamic environments.Marginal prediction models commonly forecast each agent's future trajectoriesindependently, often leading to sub-optimal planning decisions for an automatedvehicle. In contrast, joint prediction models explicitly account for theinteractions between agents, yielding socially and physically consistentpredictions on a scene level. However, existing approaches differ not only intheir problem formulation but also in the model architectures andimplementation details used, making it difficult to compare them. In this work,we systematically investigate different approaches to joint motion prediction,including post-processing of the marginal predictions, explicitly training themodel for joint predictions, and framing the problem as a generative task. Weevaluate each approach in terms of prediction accuracy, multi-modality, andinference efficiency, offering a comprehensive analysis of the strengths andlimitations of each approach. Several prediction examples are available athttps://frommarginaltojointpred.github.io/.</description>
      <author>example@mail.com (Fabian Konstantinidis, Ariel Dallari Guerreiro, Raphael Trumpp, Moritz Sackmann, Ulrich Hofmann, Marco Caccamo, Christoph Stiller)</author>
      <guid isPermaLink="false">2507.05254v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Graph-based Point Cloud Networks on FPGAs via Stall-Free Deep Pipelining</title>
      <link>http://arxiv.org/abs/2507.05099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE SBCCI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于FPGA的深度流水线数据流架构，用于在FPGA上执行基于图的点云网络（PCNs），以高效处理动态、稀疏的点云数据，同时满足严格的实时性要求。&lt;h4&gt;背景&lt;/h4&gt;Graph-based Point Cloud Networks（PCNs）是一种强大的工具，用于处理高能物理探测器中的稀疏传感器数据，但将这些模型部署到这种环境中仍然具有挑战性，因为需要满足严格的实时性要求，包括延迟和吞吐量。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以支持动态、稀疏点云的高效处理，同时满足严格的实时性约束。&lt;h4&gt;方法&lt;/h4&gt;该方法引入了专门的处理器元素，用于核心图操作，如GraVNet卷积和凝结点聚类，并在AMD Versal VCK190上进行了设计。&lt;h4&gt;主要发现&lt;/h4&gt;与GPU基准相比，FPGA实现实现了高达5.25倍的吞吐量提升，同时保持低于10微秒的延迟，满足粒子物理实验中实时触发系统的需求。&lt;h4&gt;结论&lt;/h4&gt;提供了一种开源参考实现，证明了基于FPGA的PCNs在满足实时性要求方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Graph-based Point Cloud Networks（PCNs）是基于图的点云网络，FPGA现场可编程门阵列，Versal VCK190是AMD公司的一款芯片，GraVNet是一种卷积算法，condensation point clustering是点聚类的一种方法，real-time trigger systems是实时触发系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-based Point Cloud Networks (PCNs) are powerful tools for processingsparse sensor data with irregular geometries, as found in high-energy physicsdetectors. However, deploying models in such environments remains challengingdue to stringent real-time requirements for both latency, and throughput. Inthis work, we present a deeply pipelined dataflow architecture for executinggraph-based PCNs on FPGAs. Our method supports efficient processing of dynamic,sparse point clouds while meeting hard real-time constraints. We introducespecialized processing elements for core graph operations, such as GraVNetconvolution and condensation point clustering, and demonstrate our design onthe AMD Versal VCK190. Compared to a GPU baseline, our FPGA implementationachieves up to 5.25x speedup in throughput while maintaining latencies below 10{\mu}s, satisfying the demands of real-time trigger systems in particle physicsexperiments. An open-source reference implementation is provided.</description>
      <author>example@mail.com (Marc Neu, Isabel Haide, Timo Justinger, Till Rädler, Valdrin Dajaku, Torben Ferber, Jürgen Becker)</author>
      <guid isPermaLink="false">2507.05099v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Semantic Clustering and Similarity Search for Heterogeneous Traffic Scenario Graph</title>
      <link>http://arxiv.org/abs/2507.05086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted in the IEEE IAVVC 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于场景的测试方法，旨在提高自动驾驶汽车测试的效率，同时考虑到不同操作设计域的多样性和长尾现象。&lt;h4&gt;背景&lt;/h4&gt;场景测试对于自动驾驶汽车的综合验证和验证至关重要，但找到有限且具有代表性的场景子集在可扩展的、可能的无监督方式下具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了实现样本高效的测试，同时捕捉相关操作设计域的多样性和考虑长尾现象，本文提出了一个表达性强且灵活的异构时空图模型来表示交通场景。&lt;h4&gt;方法&lt;/h4&gt;本文首先提出了一种基于图神经网络的自监督学习方法，用于学习场景图的通用嵌入空间，从而实现聚类和相似性搜索。实验使用了nuPlan数据集，并采用了对比学习和基于引导的方法来评估场景空间的划分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，模型能够捕捉语义，并以有意义的方式将相关场景分组，尽管没有离散的类别标签。不同的场景类型表现为不同的聚类。此外，这种方法可以将可变长度的交通场景压缩为单个向量表示，从而实现不同场景类别的代表性候选者的最近邻检索。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法可以作为可扩展场景选择的基石，以进一步提高自动驾驶汽车在模拟测试中的效率和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于场景的测试是全面验证和验证自动化车辆（AV）的不可或缺的工具。然而，以可扩展的、可能的无监督方式找到有限且具有代表性的场景子集在代表性上具有挑战性。我们的工作旨在构成一个基石，以促进样本高效的测试，同时仍然捕捉相关操作设计域（ODDs）的多样性和考虑特定的“长尾”现象。为此，我们首先提出了一种表达性强且灵活的异构时空图模型来表示交通场景。利用图神经网络（GNN）的最新进展，我们随后提出了一种自监督方法来学习场景图的通用嵌入空间，从而实现聚类和相似性搜索。特别是，我们实现了对比学习以及基于引导的方法，并评估了它们对场景空间划分的适用性。在nuPlan数据集上的实验证实了模型能够捕捉语义，并且以有意义的方式将相关场景分组，尽管没有离散的类别标签。不同的场景类型表现为不同的聚类。我们的结果证明了如何将可变长度的交通场景压缩为单个向量表示，从而实现不同场景类别的代表性候选者的最近邻检索。值得注意的是，这是在没有人工标记或偏向于一个明确的如关键性等目标的情况下实现的。最终，我们的方法可以作为可扩展场景选择的基石，以进一步提高自动驾驶汽车在模拟测试中的效率和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scenario-based testing is an indispensable instrument for the comprehensivevalidation and verification of automated vehicles (AVs). However, finding amanageable and finite, yet representative subset of scenarios in a scalable,possibly unsupervised manner is notoriously challenging. Our work is meant toconstitute a cornerstone to facilitate sample-efficient testing, while stillcapturing the diversity of relevant operational design domains (ODDs) andaccounting for the "long tail" phenomenon in particular. To this end, we firstpropose an expressive and flexible heterogeneous, spatio-temporal graph modelfor representing traffic scenarios. Leveraging recent advances of graph neuralnetworks (GNNs), we then propose a self-supervised method to learn a universalembedding space for scenario graphs that enables clustering and similaritysearch. In particular, we implement contrastive learning alongside abootstrapping-based approach and evaluate their suitability for partitioningthe scenario space. Experiments on the nuPlan dataset confirm the model'sability to capture semantics and thus group related scenarios in a meaningfulway despite the absence of discrete class labels. Different scenario typesmaterialize as distinct clusters. Our results demonstrate how variable-lengthtraffic scenarios can be condensed into single vector representations thatenable nearest-neighbor retrieval of representative candidates for distinctscenario categories. Notably, this is achieved without manual labeling or biastowards an explicit objective such as criticality. Ultimately, our approach canserve as a basis for scalable selection of scenarios to further enhance theefficiency and robustness of testing AVs in simulation.</description>
      <author>example@mail.com (Ferdinand Mütsch, Maximilian Zipfl, Nikolai Polley, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2507.05086v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Beyond One Shot, Beyond One Perspective: Cross-View and Long-Horizon Distillation for Better LiDAR Representations</title>
      <link>http://arxiv.org/abs/2507.05260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025; 26 pages, 12 figures, 10 tables; Code at  http://github.com/Xiangxu-0103/LiMA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了LiMA，一种用于LiDAR数据表示学习的框架，该框架通过捕捉长期时间相关性来提升效果。&lt;h4&gt;背景&lt;/h4&gt;现有LiDAR表示学习方法常常忽略了LiDAR序列中固有的时空线索，限制了其有效性。&lt;h4&gt;目的&lt;/h4&gt;减少对昂贵人工标注的依赖，从大规模数据集中提取丰富的结构和语义信息。&lt;h4&gt;方法&lt;/h4&gt;LiMA包含三个关键组件：跨视角聚合模块、长期特征传播机制和跨序列记忆对齐策略。&lt;h4&gt;主要发现&lt;/h4&gt;LiMA在主流的基于LiDAR的感知基准测试中，显著提高了LiDAR语义分割和3D目标检测的性能。&lt;h4&gt;结论&lt;/h4&gt;LiMA在预训练效率高，且在下游任务中没有额外的计算开销。希望这项工作能激发更有效的预训练范式，用于自动驾驶。&lt;h4&gt;翻译&lt;/h4&gt;LiDAR表示学习旨在从大规模、易于获取的数据集中提取丰富的结构和语义信息，减少对昂贵人工标注的依赖。然而，现有的LiDAR表示策略往往忽略了LiDAR序列中固有的时空线索，限制了其有效性。在本工作中，我们提出了LiMA，一个新颖的长期图像到LiDAR记忆聚合框架，该框架明确捕捉了长期时间相关性以增强LiDAR表示学习。LiMA由三个关键组件组成：1)一个跨视角聚合模块，它对齐和融合了相邻相机视图之间的重叠区域，构建了一个更统一且无冗余的记忆库；2)一个长期特征传播机制，它有效地对齐和整合多帧图像特征，强化了LiDAR表示学习中的时间一致性；3)一个跨序列记忆对齐策略，它强制执行驾驶序列间的一致性，提高了对未见环境的泛化能力。LiMA保持了高预训练效率，在下游任务中不产生额外的计算开销。在主流的基于LiDAR的感知基准测试上的大量实验表明，LiMA显著提高了LiDAR语义分割和3D目标检测。我们希望这项工作能够激发更有效的预训练范式，用于自动驾驶。代码已公开发布，供未来研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR representation learning aims to extract rich structural and semanticinformation from large-scale, readily available datasets, reducing reliance oncostly human annotations. However, existing LiDAR representation strategiesoften overlook the inherent spatiotemporal cues in LiDAR sequences, limitingtheir effectiveness. In this work, we propose LiMA, a novel long-termimage-to-LiDAR Memory Aggregation framework that explicitly captures longerrange temporal correlations to enhance LiDAR representation learning. LiMAcomprises three key components: 1) a Cross-View Aggregation module that alignsand fuses overlapping regions across neighboring camera views, constructing amore unified and redundancy-free memory bank; 2) a Long-Term FeaturePropagation mechanism that efficiently aligns and integrates multi-frame imagefeatures, reinforcing temporal coherence during LiDAR representation learning;and 3) a Cross-Sequence Memory Alignment strategy that enforces consistencyacross driving sequences, improving generalization to unseen environments. LiMAmaintains high pretraining efficiency and incurs no additional computationaloverhead during downstream tasks. Extensive experiments on mainstreamLiDAR-based perception benchmarks demonstrate that LiMA significantly improvesboth LiDAR semantic segmentation and 3D object detection. We hope this workinspires more effective pretraining paradigms for autonomous driving. The codehas be made publicly accessible for future research.</description>
      <author>example@mail.com (Xiang Xu, Lingdong Kong, Song Wang, Chuanwei Zhou, Qingshan Liu)</author>
      <guid isPermaLink="false">2507.05260v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MedGemma Technical Report</title>
      <link>http://arxiv.org/abs/2507.05201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MedGemma是一个基于Gemma 3 4B和27B的医疗视觉语言基础模型集合，旨在加速医疗AI应用的开发。&lt;h4&gt;背景&lt;/h4&gt;人工智能在医疗领域的应用潜力巨大，但训练和部署面临数据多样性、任务复杂性和隐私保护等挑战。&lt;h4&gt;目的&lt;/h4&gt;开发性能良好且需要较少特定任务调优数据的医疗任务基础模型，以推动医疗AI应用的发展。&lt;h4&gt;方法&lt;/h4&gt;引入MedGemma，这是一个基于Gemma 3 4B和27B的医疗视觉语言基础模型集合，它展示了在图像和文本上的高级医疗理解和推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;MedGemma在医学多模态问答、胸部X光发现分类和代理评估等方面表现出色，相比基线模型有显著提升。此外，微调MedGemma在子领域中也提高了性能，如电子健康记录信息检索的错误减少了50%，并在气胸分类和病理切片分类上达到现有最先进方法的性能。&lt;h4&gt;结论&lt;/h4&gt;MedGemma集合提供了强大的医疗图像和文本能力，有助于加速医学研究和下游应用的开发。&lt;h4&gt;翻译&lt;/h4&gt;Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcare's diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10% improvement on medical multimodal question answering, 15.5-18.1% improvement on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at https://goo.gle/medgemma.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has significant potential in healthcareapplications, but its training and deployment faces challenges due tohealthcare's diverse data, complex tasks, and the need to preserve privacy.Foundation models that perform well on medical tasks and require lesstask-specific tuning data are critical to accelerate the development ofhealthcare AI applications. We introduce MedGemma, a collection of medicalvision-language foundation models based on Gemma 3 4B and 27B. MedGemmademonstrates advanced medical understanding and reasoning on images and text,significantly exceeding the performance of similar-sized generative models andapproaching the performance of task-specific models, while maintaining thegeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,MedGemma achieves 2.6-10% improvement on medical multimodal question answering,15.5-18.1% improvement on chest X-ray finding classification, and 10.8%improvement on agentic evaluations compared to the base models. Fine-tuningMedGemma further improves performance in subdomains, reducing errors inelectronic health record information retrieval by 50% and reaching comparableperformance to existing specialized state-of-the-art methods for pneumothoraxclassification and histopathology patch classification. We additionallyintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.MedSigLIP powers the visual understanding capabilities of MedGemma and as anencoder achieves comparable or better performance than specialized medicalimage encoders. Taken together, the MedGemma collection provides a strongfoundation of medical image and text capabilities, with potential tosignificantly accelerate medical research and development of downstreamapplications. The MedGemma collection, including tutorials and model weights,can be found at https://goo.gle/medgemma.</description>
      <author>example@mail.com (Andrew Sellergren, Sahar Kazemzadeh, Tiam Jaroensri, Atilla Kiraly, Madeleine Traverse, Timo Kohlberger, Shawn Xu, Fayaz Jamil, Cían Hughes, Charles Lau, Justin Chen, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Stefanie Anna Baby, Susanna Maria Baby, Jeremy Lai, Samuel Schmidgall, Lu Yang, Kejia Chen, Per Bjornsson, Shashir Reddy, Ryan Brush, Kenneth Philbrick, Howard Hu, Howard Yang, Richa Tiwari, Sunny Jansen, Preeti Singh, Yun Liu, Shekoofeh Azizi, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ramé, Morgane Riviere, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean-bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Elena Buchatskaya, Jean-Baptiste Alayrac, Dmitry, Lepikhin, Vlad Feinberg, Sebastian Borgeaud, Alek Andreev, Cassidy Hardin, Robert Dadashi, Léonard Hussenot, Armand Joulin, Olivier Bachem, Yossi Matias, Katherine Chou, Avinatan Hassidim, Kavi Goel, Clement Farabet, Joelle Barral, Tris Warkentin, Jonathon Shlens, David Fleet, Victor Cotruta, Omar Sanseviero, Gus Martins, Phoebe Kirk, Anand Rao, Shravya Shetty, David F. Steiner, Can Kirmizibayrak, Rory Pilgrim, Daniel Golden, Lin Yang)</author>
      <guid isPermaLink="false">2507.05201v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR</title>
      <link>http://arxiv.org/abs/2507.04662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures. Accepted for publication at the 2025 IEEE  International Conference on Communications (ICC). \c{opyright} 2025 IEEE.  Personal use is permitted, but permission from IEEE must be obtained for all  other uses&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了利用毫米波5G NR通信系统进行高吞吐量数据传输和环境感知的方法。&lt;h4&gt;背景&lt;/h4&gt;毫米波5G NR通信系统具有高分辨率天线阵列和广泛带宽，为高吞吐量数据传输和高级环境感知提供了转型机会。&lt;h4&gt;目的&lt;/h4&gt;克服基于被动传感的SLAM技术在假设镜面反射和简化的地图表示方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用毫米波5G NR系统进行主动感知，类似于激光扫描仪生成点云。通过二分搜索方法从每个波束方向的功率延迟剖面中提取点云。使用多个预定义的目标点校准硬件延迟，确保准确性。然后使用点云注册算法从连续轨迹视点的点云数据中估计终端姿态变化。接着应用闭环检测和位姿图优化来细化感知结果，实现精确的终端定位和详细的无线电地图重建。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过模拟和实验得到了验证，证实了所提出方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的基于毫米波5G NR系统的主动感知方法能够实现精确的终端定位和详细的无线电地图重建。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the use of millimeter-wave 5G NR communication systems for high-throughput data transmission and advanced environmental sensing.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Millimeter-wave (mmWave) 5G New Radio (NR) communication systems, with theirhigh-resolution antenna arrays and extensive bandwidth, offer a transformativeopportunity for high-throughput data transmission and advanced environmentalsensing. Although passive sensing-based SLAM techniques can estimate userlocations and environmental reflections simultaneously, their effectiveness isoften constrained by assumptions of specular reflections and oversimplified maprepresentations. To overcome these limitations, this work employs a mmWave 5GNR system for active sensing, enabling it to function similarly to a laserscanner for point cloud generation. Specifically, point clouds are extractedfrom the power delay profile estimated from each beam direction using a binarysearch approach. To ensure accuracy, hardware delays are calibrated withmultiple predefined target points. Pose variations of the terminal are thenestimated from point cloud data gathered along continuous trajectory viewpointsusing point cloud registration algorithms. Loop closure detection and posegraph optimization are subsequently applied to refine the sensing results,achieving precise terminal localization and detailed radio map reconstruction.The system is implemented and validated through both simulations andexperiments, confirming the effectiveness of the proposed approach.</description>
      <author>example@mail.com (Tao Du, Jie Yang, Fan Liu, Jiaxiang Guo, Shuqiang Xia, Chao-Kai Wen, Shi Jin)</author>
      <guid isPermaLink="false">2507.04662v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CTA: Cross-Task Alignment for Better Test Time Training</title>
      <link>http://arxiv.org/abs/2507.05221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了CTA（跨任务对齐）方法，用于提高测试时训练（TTT）的鲁棒性，通过在训练期间结合辅助的无监督任务并在测试时利用它来更新模型。&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在计算机视觉任务中表现出色，但面对分布变化（如领域或数据集变化）时性能会显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出CTA方法，以增强模型鲁棒性，并提高模型在测试时的性能。&lt;h4&gt;方法&lt;/h4&gt;CTA方法不依赖于特定的模型架构，而是借鉴多模态对比学习的成功经验，将监督编码器与自监督编码器对齐，从而强制两种模型学习到的表示之间的对齐，减少梯度干扰，保持自监督学习的内在鲁棒性，并在测试时实现更具语义意义的更新。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个基准数据集上，CTA方法在鲁棒性和泛化能力方面相较于现有方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;CTA方法为提高TTT的鲁棒性提供了一种有效的新途径，对计算机视觉领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Deep learning models have demonstrated exceptional performance across a widerange of computer vision tasks. However, their performance often degradessignificantly when faced with distribution shifts, such as domain or datasetchanges. Test-Time Training (TTT) has emerged as an effective method to enhancemodel robustness by incorporating an auxiliary unsupervised task duringtraining and leveraging it for model updates at test time. In this work, weintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.Unlike existing TTT methods, CTA does not require a specialized modelarchitecture and instead takes inspiration from the success of multi-modalcontrastive learning to align a supervised encoder with a self-supervised one.This process enforces alignment between the learned representations of bothmodels, thereby mitigating the risk of gradient interference, preserving theintrinsic robustness of self-supervised learning and enabling more semanticallymeaningful updates at test-time. Experimental results demonstrate substantialimprovements in robustness and generalization over the state-of-the-art onseveral benchmark datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models have demonstrated exceptional performance across a widerange of computer vision tasks. However, their performance often degradessignificantly when faced with distribution shifts, such as domain or datasetchanges. Test-Time Training (TTT) has emerged as an effective method to enhancemodel robustness by incorporating an auxiliary unsupervised task duringtraining and leveraging it for model updates at test time. In this work, weintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.Unlike existing TTT methods, CTA does not require a specialized modelarchitecture and instead takes inspiration from the success of multi-modalcontrastive learning to align a supervised encoder with a self-supervised one.This process enforces alignment between the learned representations of bothmodels, thereby mitigating the risk of gradient interference, preserving theintrinsic robustness of self-supervised learning and enabling more semanticallymeaningful updates at test-time. Experimental results demonstrate substantialimprovements in robustness and generalization over the state-of-the-art onseveral benchmark datasets.</description>
      <author>example@mail.com (Samuel Barbeau, Pedram Fekri, David Osowiechi, Ali Bahri, Moslem YazdanpanahMasih Aminbeidokhti, Christian Desrosiers)</author>
      <guid isPermaLink="false">2507.05221v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>HGNet: High-Order Spatial Awareness Hypergraph and Multi-Scale Context Attention Network for Colorectal Polyp Detection</title>
      <link>http://arxiv.org/abs/2507.04880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HGNet的新模型，用于提高结直肠癌（CRC）早期检测的准确性，特别是在检测小型病变、定位边界和提供可解释决策方面。&lt;h4&gt;背景&lt;/h4&gt;结直肠癌与结直肠息肉的恶变密切相关，早期检测至关重要。然而，现有模型在检测小型病变、准确定位边界和提供可解释决策方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;解决现有模型在检测小型病变、准确定位边界和提供可解释决策方面的困难。&lt;h4&gt;方法&lt;/h4&gt;HGNet模型的关键创新包括：（1）一个高效的多尺度上下文注意力（EMCA）模块，用于增强病变特征表示和边界建模；（2）在检测头部之前部署空间超图卷积模块，以捕获节点间的高阶空间关系；（3）应用迁移学习来解决医学图像数据的稀缺性；（4）使用特征类激活图（Eigen-CAM）进行决策可视化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，HGNet实现了94%的准确率、90.6%的召回率和90%的mAP@0.5，显著提高了小型病变的区分度和临床可解释性。&lt;h4&gt;结论&lt;/h4&gt;HGNet在提高结直肠癌早期检测的准确性方面具有显著效果，其源代码将在论文发表后公开。&lt;h4&gt;翻译&lt;/h4&gt;摘要：结直肠癌（CRC）与结直肠息肉的恶变密切相关，早期检测至关重要。然而，当前模型在检测小型病变、准确定位边界和提供可解释决策方面存在困难。为了解决这些问题，我们提出了HGNet，该模型集成了高阶空间感知超图和多尺度上下文注意力。关键创新包括：（1）一个高效的多尺度上下文注意力（EMCA）模块，用于增强病变特征表示和边界建模；（2）在检测头部之前部署空间超图卷积模块，以捕获节点间的高阶空间关系；（3）应用迁移学习来解决医学图像数据的稀缺性；（4）使用特征类激活图（Eigen-CAM）进行决策可视化。实验结果表明，HGNet实现了94%的准确率、90.6%的召回率和90%的mAP@0.5，显著提高了小型病变的区分度和临床可解释性。该论文发表后，源代码将公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colorectal cancer (CRC) is closely linked to the malignant transformation ofcolorectal polyps, making early detection essential. However, current modelsstruggle with detecting small lesions, accurately localizing boundaries, andproviding interpretable decisions. To address these issues, we propose HGNet,which integrates High-Order Spatial Awareness Hypergraph and Multi-ScaleContext Attention. Key innovations include: (1) an Efficient Multi-ScaleContext Attention (EMCA) module to enhance lesion feature representation andboundary modeling; (2) the deployment of a spatial hypergraph convolutionmodule before the detection head to capture higher-order spatial relationshipsbetween nodes; (3) the application of transfer learning to address the scarcityof medical image data; and (4) Eigen Class Activation Map (Eigen-CAM) fordecision visualization. Experimental results show that HGNet achieves 94%accuracy, 90.6% recall, and 90% mAP@0.5, significantly improving small lesiondifferentiation and clinical interpretability. The source code will be madepublicly available upon publication of this paper.</description>
      <author>example@mail.com (Xiaofang Liu, Lingling Sun, Xuqing Zhang, Yuannong Ye, Bin zhao)</author>
      <guid isPermaLink="false">2507.04880v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Stochastic Human Motion Prediction with Memory of Action Transition and Action Characteristic</title>
      <link>http://arxiv.org/abs/2507.04062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by CVPR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于动作驱动的随机人类运动预测方法，旨在根据非目标动作的过去观察序列生成预定义目标动作的未来运动序列。&lt;h4&gt;背景&lt;/h4&gt;动作驱动的随机人类运动预测面临两个主要挑战：动作转换速度的变异性导致平滑过渡运动难以生成，以及某些动作的相似性使得动作特征难以学习。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了两个记忆库：软转换动作库（STAB）和动作特征库（ACB）。STAB存储动作转换信息，并采用新颖的软搜索方法，鼓励模型关注观察运动的多个可能动作类别。ACB记录动作特征，为预测特定动作提供更多先验信息。&lt;h4&gt;方法&lt;/h4&gt;为了更好地融合从两个库中检索到的特征，本文进一步提出了自适应注意力调整（AAA）策略。&lt;h4&gt;主要发现&lt;/h4&gt;在四个运动预测数据集上的大量实验表明，该方法在性能上始终优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在动作驱动的随机人类运动预测方面取得了显著成果，并提供了演示和代码。&lt;h4&gt;翻译&lt;/h4&gt;Action-driven stochastic human motion prediction aims to generate future motion sequences of a pre-defined target action based on given past observed sequences performing non-target actions. This task primarily presents two challenges. Firstly, generating smooth transition motions is hard due to the varying transition speeds of different actions. Secondly, the action characteristic is difficult to be learned because of the similarity of some actions. These issues cause the predicted results to be unreasonable and inconsistent. As a result, we propose two memory banks, the Soft-transition Action Bank (STAB) and Action Characteristic Bank (ACB), to tackle the problems above. The STAB stores the action transition information. It is equipped with the novel soft searching approach, which encourages the model to focus on multiple possible action categories of observed motions. The ACB records action characteristic, which produces more prior information for predicting certain actions. To fuse the features retrieved from the two banks better, we further propose the Adaptive Attention Adjustment (AAA) strategy. Extensive experiments on four motion prediction datasets demonstrate that our approach consistently outperforms the previous state-of-the-art. The demo and code are available at https://hyqlat.github.io/STABACB.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Action-driven stochastic human motion prediction aims to generate futuremotion sequences of a pre-defined target action based on given past observedsequences performing non-target actions. This task primarily presents twochallenges. Firstly, generating smooth transition motions is hard due to thevarying transition speeds of different actions. Secondly, the actioncharacteristic is difficult to be learned because of the similarity of someactions. These issues cause the predicted results to be unreasonable andinconsistent. As a result, we propose two memory banks, the Soft-transitionAction Bank (STAB) and Action Characteristic Bank (ACB), to tackle the problemsabove. The STAB stores the action transition information. It is equipped withthe novel soft searching approach, which encourages the model to focus onmultiple possible action categories of observed motions. The ACB records actioncharacteristic, which produces more prior information for predicting certainactions. To fuse the features retrieved from the two banks better, we furtherpropose the Adaptive Attention Adjustment (AAA) strategy. Extensive experimentson four motion prediction datasets demonstrate that our approach consistentlyoutperforms the previous state-of-the-art. The demo and code are available athttps://hyqlat.github.io/STABACB.github.io/.</description>
      <author>example@mail.com (Jianwei Tang, Hong Yang, Tengyue Chen, Jian-Fang Hu)</author>
      <guid isPermaLink="false">2507.04062v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models</title>
      <link>http://arxiv.org/abs/2507.04976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为'回答能力对齐'的框架，用于提升视频大型语言模型（Video-LLMs）对视频内容的理解能力，并使其能够评估问题的相关性，拒绝超出视频内容范围的问题。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在深度学习领域取得了显著进展，其中视频大型语言模型（Video-LLMs）通过利用强大的大型语言模型作为骨干，将不同模态对齐到语言空间。然而，这些模型在现实场景中常常无法拒绝不合适的问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，使Video-LLMs能够评估问题的相关性，并在问题超出视频内容范围时拒绝回答。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为'回答能力对齐'的框架，该框架能够使Video-LLMs基于输入视频评估问题的相关性，并在必要时拒绝回答。此外，还提出了一种评估框架，以及一个用于创建特定数据集的流程。&lt;h4&gt;主要发现&lt;/h4&gt;现有的Video-LLMs在拒绝不合适问题方面表现不佳，这并非由于缺乏对视频内容的理解，而是因为它们没有接受过识别和拒绝此类问题的训练。&lt;h4&gt;结论&lt;/h4&gt;通过'回答能力对齐'框架，Video-LLMs能够更有效地理解和处理视频内容，并在回答问题时保持相关性。&lt;h4&gt;翻译&lt;/h4&gt;在深度学习的更广泛背景下，多模态大型语言模型通过利用强大的大型语言模型作为骨干，将不同的模态对齐到语言空间，实现了显著的突破。一个典型的例子是视频大型语言模型（Video-LLMs）的发展。尽管已经提出了许多改进来增强这些模型的视频理解能力，但它们主要是在直接从视频内容生成的问题上进行训练。然而，在现实场景中，用户经常提出超出视频信息范围的问题，这突显了Video-LLMs评估问题相关性的需求。我们证明，即使是表现最好的Video-LLMs也无法拒绝不合适的问题——这并非一定是因为缺乏对视频内容的理解，而是因为它们没有接受过识别和拒绝此类问题的训练。为了解决这一局限性，我们提出了'回答能力对齐'框架，该框架使Video-LLMs能够根据输入视频评估问题的相关性，并在问题超出视频范围时适当拒绝回答，以及一个包含一系列指标的评估框架，用于在'回答能力对齐'之前和之后测量模型的行为。此外，我们还提出了一种创建针对'回答能力对齐'专门定制的数据集的流程，该流程利用现有的视频描述配对数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the broader context of deep learning, Multimodal Large Language Modelshave achieved significant breakthroughs by leveraging powerful Large LanguageModels as a backbone to align different modalities into the language space. Aprime exemplification is the development of Video Large Language Models(Video-LLMs). While numerous advancements have been proposed to enhance thevideo understanding capabilities of these models, they are predominantlytrained on questions generated directly from video content. However, inreal-world scenarios, users often pose questions that extend beyond theinformational scope of the video, highlighting the need for Video-LLMs toassess the relevance of the question. We demonstrate that even thebest-performing Video-LLMs fail to reject unfit questions-not necessarily dueto a lack of video understanding, but because they have not been trained toidentify and refuse such questions. To address this limitation, we proposealignment for answerability, a framework that equips Video-LLMs with theability to evaluate the relevance of a question based on the input video andappropriately decline to answer when the question exceeds the scope of thevideo, as well as an evaluation framework with a comprehensive set of metricsdesigned to measure model behavior before and after alignment. Furthermore, wepresent a pipeline for creating a dataset specifically tailored for alignmentfor answerability, leveraging existing video-description paired datasets.</description>
      <author>example@mail.com (Eunseop Yoon, Hee Suk Yoon, Mark A. Hasegawa-Johnson, Chang D. Yoo)</author>
      <guid isPermaLink="false">2507.04976v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal LLM: Reasoning about Environments and Actions</title>
      <link>http://arxiv.org/abs/2507.05258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and data are available at  https://zoezheng126.github.io/STLLM-website/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ST-LLM的模型，旨在解决多模态大型语言模型在处理需要整体时空理解的任务时的困难。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大型语言模型（MLLMs）在近期取得了显著进展，但它们仍然难以正确回答需要整体时空理解的提示。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文旨在开发一个框架来收集大规模数据集，并改进MLLMs对环境和动作的理解。&lt;h4&gt;方法&lt;/h4&gt;首先，开发了一个框架来收集名为“关于环境和动作的推理”（REA）的大规模数据集。然后，使用该数据集展示了现有方法在处理此类任务时的不足。为了改进，提出了一个名为“时空LLM”（ST-LLM）的模型，该模型配备了投影器以增强对环境和最近观察的时空理解。&lt;h4&gt;主要发现&lt;/h4&gt;在REA数据集上，ST-LLM模型与先前的工作相比，显著提高了结果。&lt;h4&gt;结论&lt;/h4&gt;ST-LLM模型在处理需要整体时空理解的任务方面取得了进步，并且代码和数据可通过指定的网站获取。&lt;h4&gt;翻译&lt;/h4&gt;尽管多模态大型语言模型（MLLMs）在近期取得了显著进展，但它们仍然难以正确回答需要整体时空理解的提示。具体来说，难以处理涉及1）一个配备MLLM的智能体可以操作的环境的整体；同时，也涉及2）刚刚发生并被视频剪辑编码的最近动作的提示。然而，这种整体时空理解对于在现实世界中的智能体操作至关重要。为了解决这个问题，我们首先开发了一个框架来收集一个大规模数据集。使用收集到的“关于环境和动作的推理”（REA）数据集，我们表明现有的方法确实难以正确回答这些提示。为了改进，我们开发了一个“时空LLM”（ST-LLM），这是一个配备了投影器以改善环境的空间理解和最近观察的时间理解的模型。在收集的REA数据上，我们表明所提出的方法与先前的工作相比，显著提高了结果。代码和数据可在https://zoezheng126.github.io/STLLM-website/获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the significant recent progress of Multimodal Large Language Models(MLLMs), MLLMs still struggle to correctly answer prompts that require aholistic spatio-temporal understanding. Specifically, it is challenging toaddress prompts that refer to 1) the entirety of an environment that an agentequipped with an MLLM can operate in; and simultaneously also refer to 2)recent actions that just happened and are encoded in a video clip. However,such a holistic spatio-temporal understanding is important for agents operatingin the real world. To address this issue, we first develop a framework tocollect a large-scale dataset. Using the collected "Reasoning aboutEnvironments and Actions" (REA) dataset, we show that recent methods indeedstruggle to correctly answer the prompts. To improve, we develop a"spatio-temporal LLM" (ST-LLM), a model equipped with projectors to improveboth spatial understanding of an environment and temporal understanding ofrecent observations. On the collected REA data, we show that the proposedmethod significantly improves results compared to prior work. Code and data areavailable at https://zoezheng126.github.io/STLLM-website/.</description>
      <author>example@mail.com (Haozhen Zheng, Beitong Tian, Mingyuan Wu, Zhenggang Tang, Klara Nahrstedt, Alex Schwing)</author>
      <guid isPermaLink="false">2507.05258v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Object Physical Properties from RGB-D Vision and Depth Robot Sensors Using Deep Learning</title>
      <link>http://arxiv.org/abs/2507.05029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合稀疏点云数据和RGB图像来估计物体质量的新方法，并通过合成数据集和深度估计模型进行验证。&lt;h4&gt;背景&lt;/h4&gt;惯性质量在机器人应用中如物体抓取、操作和模拟中起着关键作用，准确估计物体的质量可以显著提高各种机器人任务的表现。&lt;h4&gt;目的&lt;/h4&gt;提高机器人任务性能，特别是通过准确估计物体质量来增强抓取、操作和模拟等任务的性能。&lt;h4&gt;方法&lt;/h4&gt;结合深度图像的稀疏点云数据和RGB图像估计物体质量，使用ShapeNetSem 3D模型创建合成数据集，通过Kinect相机模拟RGBD图像，并训练图像生成模型来估计密集深度图。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在所有评估指标上均显著优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效地估计物体的质量，并通过在线可用的数据生成和模型训练代码为机器人应用提供支持。&lt;h4&gt;翻译&lt;/h4&gt;惯性质量在机器人应用，如物体抓取、操作和模拟中扮演着至关重要的角色，在交互前准确估计物体的质量可以显著提高各种机器人任务的表现。然而，仅使用视觉传感器进行质量估计是一个相对未被充分研究的领域。本文提出了一种结合深度图像的稀疏点云数据和RGB图像来估计物体质量的新方法。我们评估了一系列点云处理架构以及仅使用RGB的方法。为了克服训练数据的有限可用性，我们使用ShapeNetSem 3D模型创建了一个合成数据集，通过Kinect相机模拟RGBD图像。该合成数据用于训练一个图像生成模型来估计密集深度图，然后我们使用这些深度图来增强与质量值配对的现有图像数据集。我们的方法在所有评估的指标上都显著优于现有基准。数据生成（https://github.com/RavineWindteer/ShapenetSem-to-RGBD）、深度估计模型的训练（https://github.com/RavineWindteer/GLPDepth-Edited）和质量估计模型的训练（https://github.com/RavineWindteer/Depth-mass-estimator）的代码均可在网上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inertial mass plays a crucial role in robotic applications such as objectgrasping, manipulation, and simulation, providing a strong prior for planningand control. Accurately estimating an object's mass before interaction cansignificantly enhance the performance of various robotic tasks. However, massestimation using only vision sensors is a relatively underexplored area. Thispaper proposes a novel approach combining sparse point-cloud data from depthimages with RGB images to estimate the mass of objects. We evaluate a range ofpoint-cloud processing architectures, alongside RGB-only methods. To overcomethe limited availability of training data, we create a synthetic dataset usingShapeNetSem 3D models, simulating RGBD images via a Kinect camera. Thissynthetic data is used to train an image generation model for estimating densedepth maps, which we then use to augment an existing dataset of images pairedwith mass values. Our approach significantly outperforms existing benchmarksacross all evaluated metrics. The data generation(https://github.com/RavineWindteer/ShapenetSem-to-RGBD) as well as the trainingof the depth estimator (https://github.com/RavineWindteer/GLPDepth-Edited) andthe mass estimator (https://github.com/RavineWindteer/Depth-mass-estimator) areavailable online.</description>
      <author>example@mail.com (Ricardo Cardoso, Plinio Moreno)</author>
      <guid isPermaLink="false">2507.05029v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>LVM4CSI: Enabling Direct Application of Pre-Trained Large Vision Models for Wireless Channel Tasks</title>
      <link>http://arxiv.org/abs/2507.05121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LVM4CSI的通用且高效的框架，用于无线通信系统中的信道状态信息（CSI）获取和应用，以应对5G和未来6G技术带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;准确获取信道状态信息对于无线通信系统的性能至关重要，但随着5G和未来6G技术的发展，系统规模和复杂性不断增加。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法依赖特定任务神经网络设计且需要大量训练数据集的问题，提出了LVM4CSI框架。&lt;h4&gt;方法&lt;/h4&gt;LVM4CSI利用CSI与计算机视觉（CV）数据之间的结构相似性，将预先在CV数据集上训练的大型视觉模型（LVMs）直接应用于无线任务，而无需微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过三个代表性案例研究验证了LVM4CSI的有效性，包括信道估计、人类活动识别和用户定位。结果显示，LVM4CSI的性能与特定任务的神经网络相当甚至更优，信道估计性能提高了超过9.61 dB，定位误差减少了约40%。此外，LVM4CSI显著减少了可训练参数的数量，并消除了对特定任务神经网络设计的需要。&lt;h4&gt;结论&lt;/h4&gt;LVM4CSI是一种有效且通用的方法，可以显著提高无线通信系统中的信道状态信息获取和应用性能，同时简化了神经网络的设计过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate channel state information (CSI) is critical to the performance ofwireless communication systems, especially with the increasing scale andcomplexity introduced by 5G and future 6G technologies. While artificialintelligence (AI) offers a promising approach to CSI acquisition andutilization, existing methods largely depend on task-specific neural networks(NNs) that require expert-driven design and large training datasets, limitingtheir generalizability and practicality. To address these challenges, wepropose LVM4CSI, a general and efficient framework that leverages thestructural similarity between CSI and computer vision (CV) data to directlyapply large vision models (LVMs) pre-trained on extensive CV datasets towireless tasks without any fine-tuning, in contrast to large languagemodel-based methods that generally necessitate fine-tuning. LVM4CSI maps CSItasks to analogous CV tasks, transforms complex-valued CSI into visual formatscompatible with LVMs, and integrates lightweight trainable layers to adaptextracted features to specific communication objectives. We validate LVM4CSIthrough three representative case studies, including channel estimation, humanactivity recognition, and user localization. Results demonstrate that LVM4CSIachieves comparable or superior performance to task-specific NNs, including animprovement exceeding 9.61 dB in channel estimation and approximately 40%reduction in localization error. Furthermore, it significantly reduces thenumber of trainable parameters and eliminates the need for task-specific NNdesign.</description>
      <author>example@mail.com (Jiajia Guo, Peiwen Jiang, Chao-Kai Wen, Shi Jin, Jun Zhang)</author>
      <guid isPermaLink="false">2507.05121v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Continual Learning with Prior Compensation for Human Motion Prediction</title>
      <link>http://arxiv.org/abs/2507.04060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Advances in Neural Information Processing Systems 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Continual Learning（TCL）的新的多阶段训练框架，旨在解决人类运动预测（HMP）中的挑战，并通过实验证明了其有效性和灵活性。&lt;h4&gt;背景&lt;/h4&gt;现有的HMP方法在预测不同时刻时处理方式相同，导致短期预测学习受长期预测影响，且先前预测的信息在后续预测中的应用有限。&lt;h4&gt;目的&lt;/h4&gt;提出TCL框架以解决上述挑战，并提高HMP模型的预测能力。&lt;h4&gt;方法&lt;/h4&gt;引入Prior Compensation Factor（PCF）以更好地保留先前信息，并将其纳入模型训练中补偿丢失的先前信息。通过理论推导得出更合理的优化目标。&lt;h4&gt;主要发现&lt;/h4&gt;TCL框架可以轻松集成到不同的HMP骨干模型中，并适应各种数据集和应用。在四个HMP基准数据集上的实验证明了TCL的有效性和灵活性。&lt;h4&gt;结论&lt;/h4&gt;TCL框架为HMP提供了有效的解决方案，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;Human Motion Prediction (HMP) aims to predict future poses at different moments according to past motion sequences. Previous approaches have treated the prediction of various moments equally, resulting in two main limitations: the learning of short-term predictions is hindered by the focus on long-term predictions, and the incorporation of prior information from past predictions into subsequent predictions is limited. In this paper, we introduce a novel multi-stage training framework called Temporal Continual Learning (TCL) to address the above challenges. To better preserve prior information, we introduce the Prior Compensation Factor (PCF). We incorporate it into the model training to compensate for the lost prior information. Furthermore, we derive a more reasonable optimization objective through theoretical derivation. It is important to note that our TCL framework can be easily integrated with different HMP backbone models and adapted to various datasets and applications. Extensive experiments on four HMP benchmark datasets demonstrate the effectiveness and flexibility of TCL. The code is available at https://github.com/hyqlat/TCL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Motion Prediction (HMP) aims to predict future poses at differentmoments according to past motion sequences. Previous approaches have treatedthe prediction of various moments equally, resulting in two main limitations:the learning of short-term predictions is hindered by the focus on long-termpredictions, and the incorporation of prior information from past predictionsinto subsequent predictions is limited. In this paper, we introduce a novelmulti-stage training framework called Temporal Continual Learning (TCL) toaddress the above challenges. To better preserve prior information, weintroduce the Prior Compensation Factor (PCF). We incorporate it into the modeltraining to compensate for the lost prior information. Furthermore, we derive amore reasonable optimization objective through theoretical derivation. It isimportant to note that our TCL framework can be easily integrated withdifferent HMP backbone models and adapted to various datasets and applications.Extensive experiments on four HMP benchmark datasets demonstrate theeffectiveness and flexibility of TCL. The code is available athttps://github.com/hyqlat/TCL.</description>
      <author>example@mail.com (Jianwei Tang, Jiangxin Sun, Xiaotong Lin, Lifang Zhang, Wei-Shi Zheng, Jian-Fang Hu)</author>
      <guid isPermaLink="false">2507.04060v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Replacing detector simulation with heterogeneous GNNs in flavour physics analyses</title>
      <link>http://arxiv.org/abs/2507.05069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的快速模拟工具，用于应对大型强子对撞机实验中模拟需求的增长。&lt;h4&gt;背景&lt;/h4&gt;随着记录数据的增加，对大型强子对撞机实验的模拟需求将急剧上升。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的工具，以应对这种需求，且不依赖于现有的计算密集型工作流程。&lt;h4&gt;方法&lt;/h4&gt;该工具能够模拟LHCb实验中对任意多体衰变拓扑的探测器响应，并使用新颖的异构图神经网络架构，将物理特性直接嵌入到网络结构中。&lt;h4&gt;主要发现&lt;/h4&gt;该工具能够在多种衰变拓扑下展示性能，并能正确地模拟复杂变量之间的关系。&lt;h4&gt;结论&lt;/h4&gt;提出的方法和架构具有通用性，可以轻松适应其他模拟密集型粒子物理实验的工作流程。&lt;h4&gt;翻译&lt;/h4&gt;摘要：受记录数据量增加的驱动，未来几年对大型强子对撞机实验的模拟需求将急剧上升。仅依靠现有的计算密集型工作流程来满足这一需求是不可行的。本文介绍了一种新的快速模拟工具，旨在解决LHCb实验的这种需求。该工具能够模拟LHCb实验中对任意多体衰变拓扑的探测器响应。该模型不是记忆特定的衰变通道，而是在响应中学习通用的模式，使其能够对训练数据中不存在的通道进行插值。本文采用了新颖的异构图神经网络架构，这些架构被设计用来将任务的物理特性直接嵌入到网络结构中。我们展示了该工具在不同衰变拓扑下的性能，表明网络能够正确地模拟复杂变量之间的关系。本文提出的方法和架构具有通用性，可以轻松适应其他模拟密集型粒子物理实验的工作流程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by the increasing volume of recorded data, the demand for simulationfrom experiments based at the Large Hadron Collider will rise sharply in thecoming years. Addressing this demand solely with existing computationallyintensive workflows is not feasible. This paper introduces a new fastsimulation tool designed to address this demand at the LHCb experiment. Thistool emulates the detector response to arbitrary multibody decay topologies atLHCb. Rather than memorising specific decay channels, the model learnsgeneralisable patterns within the response, allowing it to interpolate tochannels not present in the training data. Novel heterogeneous graph neuralnetwork architectures are employed that are designed to embed the physicalcharacteristics of the task directly into the network structure. We demonstratethe performance of the tool across a range of decay topologies, showing thenetworks can correctly model the relationships between complex variables. Thearchitectures and methods presented are generic and could readily be adapted toemulate workflows at other simulation-intensive particle physics experiments.</description>
      <author>example@mail.com (Guillermo Hijano, Davide Lancierini, Alexander Mclean Marshall, Andrea Mauri, Patrick Owen, Mitesh Patel, Konstantinos Petridis, Shah Rukh Qasim, Nicola Serra, William Sutcliffe, Hanae Tilquin)</author>
      <guid isPermaLink="false">2507.05069v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Music2Palette: Emotion-aligned Color Palette Generation via Cross-Modal Representation Learning</title>
      <link>http://arxiv.org/abs/2507.04758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为Music2Palette的新方法，用于通过跨模态表征学习生成与音乐情感对齐的调色板。&lt;h4&gt;背景&lt;/h4&gt;音乐与色彩之间的情感对齐对多媒体内容的有效性至关重要，但情感不匹配会导致混乱，削弱预期信息。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法只生成单一主色、缺乏情感变化，以及通过文字或图像间接映射导致情感细节丢失的问题。&lt;h4&gt;方法&lt;/h4&gt;构建了MuCED数据集，包含2,634对经过专家验证的音乐-调色板配对，并通过基于Russell情感向量的对齐。提出了一种音乐编码器和色彩解码器的跨模态表征学习框架，以及一个多目标优化方法，旨在增强情感对齐、色彩多样性和调色板一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在解读音乐情感和生成吸引人且多样化的调色板方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Music2Palette方法能够应用于音乐驱动的图像重新着色、视频生成和数据可视化等应用，弥合听觉和视觉情感体验之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emotion alignment between music and palettes is crucial for effectivemultimedia content, yet misalignment creates confusion that weakens theintended message. However, existing methods often generate only a singledominant color, missing emotion variation. Others rely on indirect mappingsthrough text or images, resulting in the loss of crucial emotion details. Toaddress these challenges, we present Music2Palette, a novel method foremotion-aligned color palette generation via cross-modal representationlearning. We first construct MuCED, a dataset of 2,634 expert-validatedmusic-palette pairs aligned through Russell-based emotion vectors. To directlytranslate music into palettes, we propose a cross-modal representation learningframework with a music encoder and color decoder. We further propose amulti-objective optimization approach that jointly enhances emotion alignment,color diversity, and palette coherence. Extensive experiments demonstrate thatour method outperforms current methods in interpreting music emotion andgenerating attractive and diverse color palettes. Our approach enablesapplications like music-driven image recoloring, video generating, and datavisualization, bridging the gap between auditory and visual emotionexperiences.</description>
      <author>example@mail.com (Jiayun Hu, Yueyi He, Tianyi Liang, Changbo Wang, Chenhui Li)</author>
      <guid isPermaLink="false">2507.04758v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Lidar Variability: A Novel Dataset and Comparative Study of Solid-State and Spinning Lidars</title>
      <link>http://arxiv.org/abs/2507.04321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Lidar技术在多种应用中的广泛使用，并重点讨论了新型固态Lidar设备如Livox Avia和Mid-360的性能和适用性。&lt;h4&gt;背景&lt;/h4&gt;Lidar技术在机器人定位、3D重建等领域有广泛应用，但缺乏包括半球形Lidar在内的数据集，以及低成本固态Lidar与高端旋转Lidar的性能比较研究。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一研究空白，本文提出了一个包含多种Lidar类型数据的创新数据集，并对最新的SLAM算法进行了基准评估。&lt;h4&gt;方法&lt;/h4&gt;本研究收集了包括Livox Avia、Mid-360和Ouster系列在内的多种Lidar数据，对SLAM算法进行了基准测试，并对点云配准技术进行了定量分析。&lt;h4&gt;主要发现&lt;/h4&gt;本文建立了一个包含多种Lidar平台数据的基准数据集，为未来SLAM和3D重建研究提供了参考。&lt;h4&gt;结论&lt;/h4&gt;本文的研究成果为不同Lidar平台上的SLAM和3D重建研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces the wide application of Lidar technology in various fields, with a focus on the performance and applicability of new solid-state Lidar devices such as Livox Avia and Mid-360. The background of this study is that Lidar technology is widely used in fields such as robot localization and 3D reconstruction, but there is a lack of datasets including dome-shaped Lidars such as Mid-360, as well as insufficient research on the performance comparison between low-cost solid-state Lidars and high-end spinning Lidars. The purpose of this study is to fill this research gap by proposing a novel dataset containing data from various Lidar types, including Livox Avia, dome-shaped Mid-360, and high-end spinning Lidars such as the Ouster series. The methods used in this study include collecting data from various Lidar systems, including Livox Avia, Mid-360, and Ouster series, conducting benchmark evaluations of state-of-the-art SLAM algorithms, and performing quantitative analysis of point cloud registration techniques. The main findings of this study are that a benchmark dataset containing data from various Lidar platforms has been established, which provides a reference for future research in SLAM and 3D reconstruction. The conclusion of this study is that the research findings lay a foundation for future research in SLAM and 3D reconstruction across heterogeneous Lidar platforms.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lidar technology has been widely employed across various applications, suchas robot localization in GNSS-denied environments and 3D reconstruction. Recentadvancements have introduced different lidar types, including cost-effectivesolid-state lidars such as the Livox Avia and Mid-360. The Mid-360, with itsdome-like design, is increasingly used in portable mapping and unmanned aerialvehicle (UAV) applications due to its low cost, compact size, and reliableperformance. However, the lack of datasets that include dome-shaped lidars,such as the Mid-360, alongside other solid-state and spinning lidarssignificantly hinders the comparative evaluation of novel approaches acrossplatforms. Additionally, performance differences between low-cost solid-stateand high-end spinning lidars (e.g., Ouster OS series) remain insufficientlyexamined, particularly without an Inertial Measurement Unit (IMU) in odometry.  To address this gap, we introduce a novel dataset comprising data frommultiple lidar types, including the low-cost Livox Avia and the dome-shapedMid-360, as well as high-end spinning lidars such as the Ouster series.Notably, to the best of our knowledge, no existing dataset comprehensivelyincludes dome-shaped lidars such as Mid-360 alongside both other solid-stateand spinning lidars. In addition to the dataset, we provide a benchmarkevaluation of state-of-the-art SLAM algorithms applied to this diverse sensordata. Furthermore, we present a quantitative analysis of point cloudregistration techniques, specifically point-to-point, point-to-plane, andhybrid methods, using indoor and outdoor data collected from the included lidarsystems. The outcomes of this study establish a foundational reference forfuture research in SLAM and 3D reconstruction across heterogeneous lidarplatforms.</description>
      <author>example@mail.com (Doumegna Mawuto Koudjo Felix, Xianjia Yu, Jiaqiang Zhang, Sier Ha, Zhuo Zou, Tomi Westerlund)</author>
      <guid isPermaLink="false">2507.04321v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu</title>
      <link>http://arxiv.org/abs/2507.04858v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了在非洲巴西马拉卡图传统中运用迁移学习策略进行音乐起始检测的方法。&lt;h4&gt;背景&lt;/h4&gt;马拉卡图传统具有复杂的节奏模式，这给传统的模型带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习策略以提升音乐起始检测的准确率。&lt;h4&gt;方法&lt;/h4&gt;研究人员调整了两种时序卷积神经网络架构，一种是用于起始检测的（任务内），另一种是用于节拍跟踪的（任务间）。通过只使用每个乐器的5秒标注片段，研究人员通过分层重训练策略对五种传统打击乐器进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;结果显著优于基线性能，任务内设置的F1分数高达0.998，最佳情况下的改进超过50个百分点。跨任务调整对于计时乐器特别有效，其中起始点自然与节拍位置对齐。最佳微调配置因乐器而异，突出了乐器特定调整策略的重要性。&lt;h4&gt;结论&lt;/h4&gt;该方法解决了代表性不足的音乐传统中的挑战，提供了一种高效的人工辅助方法，在最大程度地提高性能的同时最小化标注工作量。研究成果有助于创建更具包容性的音乐信息检索工具，适用于超越西方音乐背景的更多情境。&lt;h4&gt;翻译&lt;/h4&gt;摘要：我们探索了在非洲巴西马拉卡图传统中进行音乐起始检测的迁移学习策略，该传统具有复杂的节奏模式，这给传统的模型带来了挑战。我们调整了两种时序卷积神经网络架构：一种用于起始检测（任务内），另一种用于节拍跟踪（任务间）。我们只使用每个乐器的5秒标注片段，通过分层重训练策略对五种传统打击乐器进行微调。我们的结果表明，与基线性能相比有显著提高，任务内设置的F1分数高达0.998，最佳情况下的改进超过50个百分点。跨任务调整对于计时乐器特别有效，其中起始点自然与节拍位置对齐。最佳的微调配置因乐器而异，突出了乐器特定调整策略的重要性。这种方法解决了代表性不足的音乐传统中的挑战，提供了一种高效的人工辅助方法，在最大程度地提高性能的同时最小化标注工作量。我们的研究有助于创建更具包容性的音乐信息检索工具，适用于超越西方音乐背景的更多情境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We explore transfer learning strategies for musical onset detection in theAfro-Brazilian Maracatu tradition, which features complex rhythmic patternsthat challenge conventional models. We adapt two Temporal Convolutional Networkarchitectures: one pre-trained for onset detection (intra-task) and another forbeat tracking (inter-task). Using only 5-second annotated snippets perinstrument, we fine-tune these models through layer-wise retraining strategiesfor five traditional percussion instruments. Our results demonstratesignificant improvements over baseline performance, with F1 scores reaching upto 0.998 in the intra-task setting and improvements of over 50 percentagepoints in best-case scenarios. The cross-task adaptation proves particularlyeffective for time-keeping instruments, where onsets naturally align with beatpositions. The optimal fine-tuning configuration varies by instrument,highlighting the importance of instrument-specific adaptation strategies. Thisapproach addresses the challenges of underrepresented musical traditions,offering an efficient human-in-the-loop methodology that minimizes annotationeffort while maximizing performance. Our findings contribute to more inclusivemusic information retrieval tools applicable beyond Western musical contexts.</description>
      <author>example@mail.com (António Sá Pinto)</author>
      <guid isPermaLink="false">2507.04858v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CVFusion: Cross-View Fusion of 4D Radar and Camera for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.04587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CVFusion的跨视图两阶段融合网络，用于4D雷达在自动驾驶中的3D目标检测任务。&lt;h4&gt;背景&lt;/h4&gt;4D雷达因其对恶劣天气的鲁棒性在自动驾驶领域受到广泛关注。由于4D雷达的稀疏点和噪声测量，大多数研究通过整合摄像头图像并在BEV空间中执行模态融合来完成3D目标检测。&lt;h4&gt;目的&lt;/h4&gt;旨在提高4D雷达在3D目标检测任务中的性能，并进一步探索雷达和融合机制的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出了CVFusion网络，包括两个阶段：第一阶段设计雷达引导迭代（RGIter）BEV融合模块生成高召回率的3D候选框；第二阶段聚合多个异构视图（包括点、图像和BEV）的特征来优化候选框并生成高质量预测。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集上的实验表明，该方法在VoD和TJ4DRadSet数据集上分别比现有最佳方法提高了9.10%和3.68%的mAP。&lt;h4&gt;结论&lt;/h4&gt;CVFusion网络显著提高了4D雷达在3D目标检测任务中的性能，代码将公开可用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于4D雷达在恶劣天气下的鲁棒性，4D雷达在自动驾驶领域受到了广泛关注。由于4D雷达的稀疏点和噪声测量，大多数研究通过整合摄像头图像并在BEV空间中执行模态融合来完成3D目标检测任务。然而，雷达和融合机制的潜力仍然没有得到充分的探索，这阻碍了性能的提升。在本研究中，我们提出了一种名为CVFusion的跨视图两阶段融合网络。在第一阶段，我们设计了一个雷达引导迭代（RGIter）BEV融合模块来生成高召回率的3D候选框。在第二阶段，我们对每个候选框聚合来自多个异构视图（包括点、图像和BEV）的特征。这些综合的实例级特征极大地帮助优化了候选框并生成了高质量的预测。在公共数据集上的大量实验表明，我们的方法在VoD和TJ4DRadSet数据集上分别比现有最佳方法提高了9.10%和3.68%的mAP。我们的代码将公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 4D radar has received significant attention in autonomous driving thanks toits robustness under adverse weathers. Due to the sparse points and noisymeasurements of the 4D radar, most of the research finish the 3D objectdetection task by integrating images from camera and perform modality fusion inBEV space. However, the potential of the radar and the fusion mechanism isstill largely unexplored, hindering the performance improvement. In this study,we propose a cross-view two-stage fusion network called CVFusion. In the firststage, we design a radar guided iterative (RGIter) BEV fusion module togenerate high-recall 3D proposal boxes. In the second stage, we aggregatefeatures from multiple heterogeneous views including points, image, and BEV foreach proposal. These comprehensive instance level features greatly help refinethe proposals and generate high-quality predictions. Extensive experiments onpublic datasets show that our method outperforms the previous state-of-the-artmethods by a large margin, with 9.10% and 3.68% mAP improvements onView-of-Delft (VoD) and TJ4DRadSet, respectively. Our code will be madepublicly available.</description>
      <author>example@mail.com (Hanzhi Zhong, Zhiyu Xiang, Ruoyu Xu, Jingyun Fu, Peng Xu, Shaohong Wang, Zhihao Yang, Tianyu Pu, Eryun Liu)</author>
      <guid isPermaLink="false">2507.04587v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>HV-MMBench: Benchmarking MLLMs for Human-Centric Video Understanding</title>
      <link>http://arxiv.org/abs/2507.04909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该摘要讨论了多模态大型语言模型（MLLMs）在视觉理解任务上的进步，特别是对于以人为中心的视频数据的理解能力，并介绍了一种名为HV-MMBench的现代基准。&lt;h4&gt;背景&lt;/h4&gt;虽然MLLMs在视觉理解任务上取得了显著进展，但它们在理解以人为中心的视频数据方面的能力仍被低估，主要是因为缺乏全面和高质量的评估基准。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述局限性，提出了一种新的HV-MMBench基准，旨在提供对MLLMs在以人为中心的视频理解方面的更全面评估。&lt;h4&gt;方法&lt;/h4&gt;HV-MMBench包括以下关键特性：多元化的评估维度、多种数据类型、多领域视频覆盖和时序覆盖。&lt;h4&gt;主要发现&lt;/h4&gt;HV-MMBench涵盖了15个任务，从基本的属性感知到高级的认知推理，以及多种问题格式和评估指标，从而更准确和稳健地反映模型性能。&lt;h4&gt;结论&lt;/h4&gt;该基准通过提供多样化的评估维度和全面的视频数据，有助于系统地分析模型在不同时间长度上的时间推理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated significantadvances in visual understanding tasks involving both images and videos.However, their capacity to comprehend human-centric video data remainsunderexplored, primarily due to the absence of comprehensive and high-qualityevaluation benchmarks. Existing human-centric benchmarks predominantlyemphasize video generation quality and action recognition, while overlookingessential perceptual and cognitive abilities required in human-centeredscenarios. Furthermore, they are often limited by single-question paradigms andoverly simplistic evaluation metrics. To address above limitations, we proposea modern HV-MMBench, a rigorously curated benchmark designed to provide a moreholistic evaluation of MLLMs in human-centric video understanding. Compared toexisting human-centric video benchmarks, our work offers the following keyfeatures: (1) Diverse evaluation dimensions: HV-MMBench encompasses 15 tasks,ranging from basic attribute perception (e.g., age estimation, emotionrecognition) to advanced cognitive reasoning (e.g., social relationshipprediction, intention prediction), enabling comprehensive assessment of modelcapabilities; (2) Varied data types: The benchmark includes multiple-choice,fill-in-blank, true/false, and open-ended question formats, combined withdiverse evaluation metrics, to more accurately and robustly reflect modelperformance; (3) Multi-domain video coverage: The benchmark spans 50 distinctvisual scenarios, enabling comprehensive evaluation across fine-grained scenevariations; (4) Temporal coverage: The benchmark covers videos from short-term(10 seconds) to long-term (up to 30min) durations, supporting systematicanalysis of models temporal reasoning abilities across diverse contextuallengths.</description>
      <author>example@mail.com (Yuxuan Cai, Jiangning Zhang, Zhenye Gan, Qingdong He, Xiaobin Hu, Junwei Zhu, Yabiao Wang, Chengjie Wang, Zhucun Xue, Xinwei He, Xiang Bai)</author>
      <guid isPermaLink="false">2507.04909v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling</title>
      <link>http://arxiv.org/abs/2507.04801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于聚类的点云建模方法PointGAC，旨在解决传统方法在重建被遮挡区域时过度约束模型导致无法捕捉到泛化特征的问题。&lt;h4&gt;背景&lt;/h4&gt;大多数被遮挡点云建模（MPM）方法采用回归范式来重建被遮挡区域的坐标或特征，但往往过度约束模型，导致无法捕捉到泛化特征。&lt;h4&gt;目的&lt;/h4&gt;提出PointGAC方法，旨在通过聚类来对齐被遮挡区域的特征分布，从而更有效地学习泛化特征。&lt;h4&gt;方法&lt;/h4&gt;PointGAC方法包括以下步骤：首先，采用几何感知分区策略提取初始块；然后，教师模型通过在线k-means算法根据完整块提取的特征更新码本；码本向量成为聚类中心；之后，将未被遮挡的特征分配到相应的聚类中心，学生模型对重建的被遮挡特征进行对齐；最后，通过提出的码本维护机制，码本向量得到主动更新，进一步提高语义特征学习的效率。&lt;h4&gt;主要发现&lt;/h4&gt;PointGAC方法通过识别被遮挡特征所属的聚类中心，使模型能够学习到更通用的特征表示，并通过码本维护机制提高了语义特征学习的效率。&lt;h4&gt;结论&lt;/h4&gt;实验验证了PointGAC方法在多种下游任务中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于聚类的点云建模方法PointGAC，旨在解决传统方法在重建被遮挡区域时过度约束模型导致无法捕捉到泛化特征的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most masked point cloud modeling (MPM) methods follow a regression paradigmto reconstruct the coordinate or feature of masked regions. However, they tendto over-constrain the model to learn the details of the masked region,resulting in failure to capture generalized features. To address thislimitation, we propose \textbf{\textit{PointGAC}}, a novel clustering-based MPMmethod that aims to align the feature distribution of masked regions.Specially, it features an online codebook-guided teacher-student framework.Firstly, it presents a geometry-aware partitioning strategy to extract initialpatches. Then, the teacher model updates a codebook via online k-means based onfeatures extracted from the complete patches. This procedure facilitatescodebook vectors to become cluster centers. Afterward, we assigns the unmaskedfeatures to their corresponding cluster centers, and the student model alignsthe assignment for the reconstructed masked features. This strategy focuses onidentifying the cluster centers to which the masked features belong, enablingthe model to learn more generalized feature representations. Benefiting from aproposed codebook maintenance mechanism, codebook vectors are actively updated,which further increases the efficiency of semantic feature learning.Experiments validate the effectiveness of the proposed method on variousdownstream tasks. Code is available at https://github.com/LAB123-tech/PointGAC</description>
      <author>example@mail.com (Abiao Li, Chenlei Lv, Yuming Fang, Yifan Zuo, Jian Zhang, Guofeng Mei)</author>
      <guid isPermaLink="false">2507.04801v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>ICAS: Detecting Training Data from Autoregressive Image Generative Models</title>
      <link>http://arxiv.org/abs/2507.05068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM MM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了自回归图像生成模型在数据隐私和版权方面的风险，并提出了一个基于成员推理的检测方法，该方法在类条件性和文本到图像场景中表现出优越性。&lt;h4&gt;背景&lt;/h4&gt;自回归图像生成模型在视觉合成方面取得了显著进展，但也引发了数据隐私和版权问题。&lt;h4&gt;目的&lt;/h4&gt;为了更好地理解自回归图像生成模型对数据检测的脆弱性，并识别模型训练中的未经授权数据使用。&lt;h4&gt;方法&lt;/h4&gt;提出了包含隐式分类和自适应分数聚合策略的两个关键组件的方法。首先计算查询图像中的隐式token-wise分类分数，然后提出一个自适应分数聚合策略来获取最终分数，该策略更注重低分数的token。&lt;h4&gt;主要发现&lt;/h4&gt;（1）成员推理的线性缩放定律，揭示了大型基础模型的脆弱性；（2）来自scale-wise视觉自回归模型的训练数据比其他自回归范式更容易检测。&lt;h4&gt;结论&lt;/h4&gt;该方法在类条件性和文本到图像场景中表现出优越性，并且在各种数据转换下具有强大的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了自回归图像生成模型在数据隐私和版权方面的风险，并提出了一种基于成员推理的检测方法。该方法包含隐式分类和自适应分数聚合策略，能够有效识别未经授权的数据使用。实验结果表明，该方法在类条件性和文本到图像场景中具有优越性，并且在不同数据转换下具有强大的鲁棒性和泛化能力。此外，研究发现大型基础模型在成员推理方面存在脆弱性，且scale-wise视觉自回归模型的训练数据更容易被检测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregressive image generation has witnessed rapid advancements, withprominent models such as scale-wise visual auto-regression pushing theboundaries of visual synthesis. However, these developments also raisesignificant concerns regarding data privacy and copyright. In response,training data detection has emerged as a critical task for identifyingunauthorized data usage in model training. To better understand thevulnerability of autoregressive image generative models to such detection, weconduct the first study applying membership inference to this domain. Ourapproach comprises two key components: implicit classification and an adaptivescore aggregation strategy. First, we compute the implicit token-wiseclassification score within the query image. Then we propose an adaptive scoreaggregation strategy to acquire a final score, which places greater emphasis onthe tokens with lower scores. A higher final score indicates that the sample ismore likely to be involved in the training set. To validate the effectivenessof our method, we adapt existing detection algorithms originally designed forLLMs to visual autoregressive models. Extensive experiments demonstrate thesuperiority of our method in both class-conditional and text-to-imagescenarios. Moreover, our approach exhibits strong robustness and generalizationunder various data transformations. Furthermore, sufficient experiments suggesttwo novel key findings: (1) A linear scaling law on membership inference,exposing the vulnerability of large foundation models. (2) Training data fromscale-wise visual autoregressive models is easier to detect than otherautoregressive paradigms.Our code is available athttps://github.com/Chrisqcwx/ImageAR-MIA.</description>
      <author>example@mail.com (Hongyao Yu, Yixiang Qiu, Yiheng Yang, Hao Fang, Tianqu Zhuang, Jiaxin Hong, Bin Chen, Hao Wu, Shu-Tao Xia)</author>
      <guid isPermaLink="false">2507.05068v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Model Compression using Progressive Channel Pruning</title>
      <link>http://arxiv.org/abs/2507.04792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为渐进通道剪枝（PCP）的简单但有效的通道剪枝框架，用于加速卷积神经网络（CNNs）。该框架通过迭代剪枝多个选定层的一小部分通道，实现加速。&lt;h4&gt;背景&lt;/h4&gt;现有的通道剪枝方法在层与层之间按顺序仅剪枝一次通道。&lt;h4&gt;目的&lt;/h4&gt;加速卷积神经网络（CNNs）。&lt;h4&gt;方法&lt;/h4&gt;PCP框架包括三个步骤：尝试、选择和剪枝。在尝试步骤中，使用现有方法剪枝预定义数量的通道，并基于验证集的标记样本估计准确度下降。在选择步骤中，基于所有层的估计准确度下降，提出贪婪策略自动选择剪枝后整体准确度下降最小的层集。在剪枝步骤中，从这些选定层剪枝一小部分通道。此外，将PCP框架扩展到剪枝深度迁移学习方法，如域对抗神经网络（DANN），通过使用源域的标记样本和目标域的伪标记样本来有效减少通道剪枝过程中的数据分布不匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的综合实验表明，PCP框架在监督学习和迁移学习设置下均优于现有的通道剪枝方法。&lt;h4&gt;结论&lt;/h4&gt;PCP框架能够有效加速CNNs，并在不同学习设置下优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们提出了一种简单但有效的通道剪枝框架，称为渐进通道剪枝（PCP），用于加速卷积神经网络（CNNs）。与现有的仅按层顺序每次剪枝一次通道的通道剪枝方法不同，我们的新渐进框架迭代地从几个选定层中剪枝一小部分通道，这包括每个迭代中的尝试-选择-剪枝三个步骤。在尝试步骤中，我们尝试使用任何现有的通道剪枝方法从一个层中剪枝预定义数量的通道，并基于验证集中的标记样本估计该层的准确度下降。在选择步骤中，基于所有层的估计准确度下降，我们提出了一种贪婪策略来自动选择剪枝这些层后导致整体准确度下降最小的层集。在剪枝步骤中，我们从这些选定层中剪枝一小部分通道。我们进一步将我们的PCP框架扩展到剪枝深度迁移学习方法，如域对抗神经网络（DANN），其中我们通过使用源域的标记样本和目标域的伪标记样本来有效减少通道剪枝过程中的数据分布不匹配。我们在两个基准数据集上的综合实验表明，我们的PCP框架在监督学习和迁移学习设置下均优于现有的通道剪枝方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we propose a simple but effective channel pruning frameworkcalled Progressive Channel Pruning (PCP) to accelerate Convolutional NeuralNetworks (CNNs). In contrast to the existing channel pruning methods that prunechannels only once per layer in a layer-by-layer fashion, our new progressiveframework iteratively prunes a small number of channels from several selectedlayers, which consists of a three-step attempting-selecting-pruning pipeline ineach iteration. In the attempting step, we attempt to prune a pre-definednumber of channels from one layer by using any existing channel pruning methodsand estimate the accuracy drop for this layer based on the labelled samples inthe validation set. In the selecting step, based on the estimated accuracydrops for all layers, we propose a greedy strategy to automatically select aset of layers that will lead to less overall accuracy drop after pruning theselayers. In the pruning step, we prune a small number of channels from theseselected layers. We further extend our PCP framework to prune channels for thedeep transfer learning methods like Domain Adversarial Neural Network (DANN),in which we effectively reduce the data distribution mismatch in the channelpruning process by using both labelled samples from the source domain andpseudo-labelled samples from the target domain. Our comprehensive experimentson two benchmark datasets demonstrate that our PCP framework outperforms theexisting channel pruning approaches under both supervised learning and transferlearning settings.</description>
      <author>example@mail.com (Jinyang Guo, Weichen Zhang, Wanli Ouyang, Dong Xu)</author>
      <guid isPermaLink="false">2507.04792v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MOSU: Autonomous Long-range Robot Navigation with Multi-modal Scene Understanding</title>
      <link>http://arxiv.org/abs/2507.04686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MOSU是一种新型的自主长距离导航系统，通过多模态感知和道路场景理解来增强移动机器人的全局导航。&lt;h4&gt;背景&lt;/h4&gt;户外机器人导航面临挑战，需要集成几何、语义和上下文信息以确保全面的场景理解。&lt;h4&gt;目的&lt;/h4&gt;开发MOSU系统，以解决户外机器人导航的挑战，并提高机器人在复杂环境中的导航能力。&lt;h4&gt;方法&lt;/h4&gt;MOSU结合GPS和QGIS地图进行高级全局路径规划，并通过多模态轨迹生成进行局部导航优化。多模态包括基于LiDAR的几何数据、基于图像的语义分割和视觉语言模型（VLMs）。&lt;h4&gt;主要发现&lt;/h4&gt;MOSU在现实世界的道路环境中进行了评估，并在GND数据集上进行了基准测试，实现了在可导航地形上的10%的通行性提升，同时保持了与现有全局导航方法相当的导航距离。&lt;h4&gt;结论&lt;/h4&gt;MOSU的多模态集成提高了场景理解和通行性，使机器人能够适应不同的户外条件。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MOSU, a novel autonomous long-range navigation system thatenhances global navigation for mobile robots through multimodal perception andon-road scene understanding. MOSU addresses the outdoor robot navigationchallenge by integrating geometric, semantic, and contextual information toensure comprehensive scene understanding. The system combines GPS and QGISmap-based routing for high-level global path planning and multi-modaltrajectory generation for local navigation refinement. For trajectorygeneration, MOSU leverages multi-modalities: LiDAR-based geometric data forprecise obstacle avoidance, image-based semantic segmentation fortraversability assessment, and Vision-Language Models (VLMs) to capture socialcontext and enable the robot to adhere to social norms in complex environments.This multi-modal integration improves scene understanding and enhancestraversability, allowing the robot to adapt to diverse outdoor conditions. Weevaluate our system in real-world on-road environments and benchmark it on theGND dataset, achieving a 10% improvement in traversability on navigableterrains while maintaining a comparable navigation distance to existing globalnavigation methods.</description>
      <author>example@mail.com (Jing Liang, Kasun Weerakoon, Daeun Song, Senthurbavan Kirubaharan, Xuesu Xiao, Dinesh Manocha)</author>
      <guid isPermaLink="false">2507.04686v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Tempo-R0: A Video-MLLM for Temporal Video Grounding through Efficient Temporal Sensing Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.04702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为Tempo-R0的视频多模态大型语言模型（Video-MLLM），用于解决视频理解中的时间视频定位问题。&lt;h4&gt;背景&lt;/h4&gt;时间视频定位（Temporal Video Grounding, TVG）是一个视频理解领域中的高挑战性任务，因为视频包含大量信息和冗余。&lt;h4&gt;目的&lt;/h4&gt;该模型旨在通过多模态时间感知强化来提供对整个视频的综合理解，从而准确检索与查询相关的视频片段。&lt;h4&gt;方法&lt;/h4&gt;模型在预处理阶段使用自适应注意力分配（SAA）方法来高效利用MLLM的有限注意力，并采用显式时间戳模态对齐（ETA）方法来增强模型感知视频事件边界的能力。在微调部分，模型采用基于部分不相关拒绝的组相对策略优化（PIR-GRPO）来促进模型的时间推理。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在原始QVHighlights测试平台及其经过纠正版本上均取得了比SOTA解决方案高约3.5%的显著优势。&lt;h4&gt;结论&lt;/h4&gt;Tempo-R0模型在时间视频定位任务中取得了显著效果，为视频理解领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Video Grounding (TVG), which requires pinpointing relevant temporalsegments from video based on language query, has always been a highlychallenging task in the field of video understanding. Videos often have alarger volume of information and redundancy than texts or images. Models shouldpresent comprehensive understanding of the whole video to accurately retrievequery-relevant clips. We thus propose Tempo-R0: a Video Multimodal LargeLanguage Model (Video-MLLM) for the temporal video grounding task viamultimodal temporal sensing reinforcement. Specifically, during thepreprocessing stage of our pipeline, we employ Self-adaptive AttentionAllocation (SAA) method based on frame content variation to efficiently use theMLLM's limited attention. The Explicit Timestamp-modal Aligned (ETA) method isalso utilized to strengthen our model's capability to perceive the boundariesof events in the video. In the fine-tuning part of our pipeline, we creativelyapply Partial Irrelevance Refusing-based Group Relative Policy Optimization(PIR-GRPO) in TVG area to foster model's temporal reasoning from not onlyaccepting relevant video-query pairs but also refusing irrelevant ones.Experiments demonstrate that our method accomplishes a notable advantage overSOTA solutions by around 3.5% on both the original QVHighlights testbench andits corrected version with more reasonable ground truth annotations.</description>
      <author>example@mail.com (Feng Yue, Zhaoxing Zhang, Junming Jiao, Zhengyu Liang, Shiwen Cao, Feifei Zhang, Rong Shen)</author>
      <guid isPermaLink="false">2507.04702v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Intent-guided Optimization with Pluggable LLM-Driven Semantics for Session-based Recommendation</title>
      <link>http://arxiv.org/abs/2507.04623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HIPHOP的新型分层意图引导优化方法，用于基于会话的推荐，旨在提高推荐质量。&lt;h4&gt;背景&lt;/h4&gt;现有的会话式推荐（SBR）模型通常只关注单次会话信息，忽略了会话间的关联和有价值的信息，且在处理噪声和无关信息时性能下降。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文旨在提出一种能够捕捉细粒度项目特征并有效利用跨会话信息的方法。&lt;h4&gt;方法&lt;/h4&gt;HIPHOP包括：基于大型语言模型的插件式嵌入模块，用于生成高质量语义表示；利用图神经网络（GNNs）建模项目转换关系和动态多意图捕捉模块；设计了一个由用户意图指导的分层会话相似度学习模块；应用意图引导的去噪策略来减轻噪声；使用对比学习优化会话表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HIPHOP在多个数据集上显著优于现有方法，证明了其在提高推荐质量方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;HIPHOP是一种有效的会话式推荐方法，能够显著提升推荐质量。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为HIPHOP的新型分层意图引导优化方法，用于基于会话的推荐，旨在提高推荐质量。现有的会话式推荐（SBR）模型通常只关注单次会话信息，忽略了会话间的关联和有价值的信息，且在处理噪声和无关信息时性能下降。为了解决这些问题，本文旨在提出一种能够捕捉细粒度项目特征并有效利用跨会话信息的方法。HIPHOP包括：基于大型语言模型的插件式嵌入模块，用于生成高质量语义表示；利用图神经网络（GNNs）建模项目转换关系和动态多意图捕捉模块；设计了一个由用户意图指导的分层会话相似度学习模块；应用意图引导的去噪策略来减轻噪声；使用对比学习优化会话表示。实验表明，HIPHOP在多个数据集上显著优于现有方法，证明了其在提高推荐质量方面的有效性。HIPHOP是一种有效的会话式推荐方法，能够显著提升推荐质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Session-based Recommendation (SBR) aims to predict the next item a user willlikely engage with, using their interaction sequence within an anonymoussession. Existing SBR models often focus only on single-session information,ignoring inter-session relationships and valuable cross-session insights. Somemethods try to include inter-session data but struggle with noise andirrelevant information, reducing performance. Additionally, most models rely onitem ID co-occurrence and overlook rich semantic details, limiting theirability to capture fine-grained item features. To address these challenges, wepropose a novel hierarchical intent-guided optimization approach with pluggableLLM-driven semantic learning for session-based recommendations, called HIPHOP.First, we introduce a pluggable embedding module based on large language models(LLMs) to generate high-quality semantic representations, enhancing itemembeddings. Second, HIPHOP utilizes graph neural networks (GNNs) to model itemtransition relationships and incorporates a dynamic multi-intent capturingmodule to address users' diverse interests within a session. Additionally, wedesign a hierarchical inter-session similarity learning module, guided by userintent, to capture global and local session relationships, effectivelyexploring users' long-term and short-term interests. To mitigate noise, anintent-guided denoising strategy is applied during inter-session learning.Finally, we enhance the model's discriminative capability by using contrastivelearning to optimize session representations. Experiments on multiple datasetsshow that HIPHOP significantly outperforms existing methods, demonstrating itseffectiveness in improving recommendation quality. Our code is available:https://github.com/hjx159/HIPHOP.</description>
      <author>example@mail.com (Jinpeng Chen, Jianxiang He, Huan Li, Senzhang Wang, Yuan Cao, Kaimin Wei, Zhenye Yang, Ye Ji)</author>
      <guid isPermaLink="false">2507.04623v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>PRISM: Pointcloud Reintegrated Inference via Segmentation and Cross-attention for Manipulation</title>
      <link>http://arxiv.org/abs/2507.04633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PRISM是一个端到端的框架，用于解决机器人操作中的鲁棒模仿学习问题，特别是在杂乱环境中，通过直接从原始点云观察和机器人状态学习，无需预训练模型或外部数据集。&lt;h4&gt;背景&lt;/h4&gt;在杂乱环境中，许多现有的模仿学习方法难以实现全面的3D感知，固定的相机视图方法容易受到视角变化的影响，而3D点云技术通常限于关键帧预测，这限制了其在动态、接触密集型任务中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出PRISM以解决上述挑战，实现鲁棒的机器人模仿学习。&lt;h4&gt;方法&lt;/h4&gt;PRISM由三个主要组件组成：一个分割嵌入单元，用于将原始点云划分为不同的物体簇并编码局部几何细节；一个跨注意力组件，用于将视觉特征与处理过的机器人关节状态合并，以突出相关的目标；以及一个扩散模块，将融合的表示转换为平滑的机器人动作。&lt;h4&gt;主要发现&lt;/h4&gt;PRISM在100次演示的训练下，在模拟环境中超越了2D和3D基线策略，在准确性和效率方面表现优异，展示了在复杂、物体密集场景中的强大鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;PRISM通过直接从原始数据学习，实现了在复杂环境中的鲁棒模仿学习，为机器人操作提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：针对机器人操作中的鲁棒模仿学习，需要全面的3D感知，但许多现有方法在杂乱环境中难以实现。固定相机视图方法易受视角变化影响，而3D点云技术通常局限于关键帧预测，这限制了其在动态、接触密集型任务中的效果。为了解决这些挑战，我们提出了PRISM，它是一个端到端的框架，直接从原始点云观察和机器人状态中学习，无需预训练模型或外部数据集。PRISM由三个主要组件组成：一个分割嵌入单元，用于将原始点云分割成不同的物体簇并编码局部几何细节；一个跨注意力组件，用于将视觉特征与处理过的机器人关节状态合并，以突出相关目标；以及一个扩散模块，将融合的表示转换为平滑的机器人动作。在每项任务上进行100次演示的训练后，PRISM在模拟环境中超越了2D和3D基线策略，在准确性和效率方面表现优异，展示了在复杂、物体密集场景中的强大鲁棒性。代码和部分演示可在https://github.com/czknuaa/PRISM上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust imitation learning for robot manipulation requires comprehensive 3Dperception, yet many existing methods struggle in cluttered environments. Fixedcamera view approaches are vulnerable to perspective changes, and 3D pointcloud techniques often limit themselves to keyframes predictions, reducingtheir efficacy in dynamic, contact-intensive tasks. To address thesechallenges, we propose PRISM, designed as an end-to-end framework that directlylearns from raw point cloud observations and robot states, eliminating the needfor pretrained models or external datasets. PRISM comprises three maincomponents: a segmentation embedding unit that partitions the raw point cloudinto distinct object clusters and encodes local geometric details; across-attention component that merges these visual features with processedrobot joint states to highlight relevant targets; and a diffusion module thattranslates the fused representation into smooth robot actions. With training on100 demonstrations per task, PRISM surpasses both 2D and 3D baseline policiesin accuracy and efficiency within our simulated environments, demonstratingstrong robustness in complex, object-dense scenarios. Code and some demos areavailable on https://github.com/czknuaa/PRISM.</description>
      <author>example@mail.com (Daqi Huang, Zhehao Cai, Yuzhi Hao, Zechen Li, Chee-Meng Chew)</author>
      <guid isPermaLink="false">2507.04633v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Word stress in self-supervised speech models: A cross-linguistic comparison</title>
      <link>http://arxiv.org/abs/2507.04738v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了自监督语音模型（S3M）学习的单词重音表示，特别是Wav2vec 2.0模型。研究了五种不同语言的S3M重音表示，包括有变化或词汇重音的荷兰语、英语和德语，以及有固定或标记重音的匈牙利语和波兰语。在S3M嵌入上训练诊断重音分类器，并证明它们能够以高精度区分朗读短句中的重音和不重音音节。还测试了S3M单词重音的语言特异性效应，结果显示重音表示具有语言特异性，变化重音语言与固定重音语言之间的差异更大。&lt;h4&gt;背景&lt;/h4&gt;自监督语音模型（S3M）在学习单词重音方面具有研究价值，特别是Wav2vec 2.0模型在处理多种语言中的重音表示上。&lt;h4&gt;目的&lt;/h4&gt;研究自监督语音模型（S3M）在不同语言中的单词重音表示，并评估其语言特异性。&lt;h4&gt;方法&lt;/h4&gt;在Wav2vec 2.0模型上训练诊断重音分类器，使用不同语言的朗读短句数据集进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;S3M能够准确区分重音和不重音音节，且重音表示具有语言特异性，变化重音语言与固定重音语言之间存在较大差异。&lt;h4&gt;结论&lt;/h4&gt;自监督语音模型（S3M）在处理单词重音方面表现出良好的语言特异性，适用于不同语言的语音识别任务。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the word stress representations learned by self-supervised speech models (S3M), specifically the Wav2vec 2.0 model. We investigate the S3M representations of word stress for five different languages: Three languages with variable or lexical stress (Dutch, English and German) and two languages with fixed or demarcative stress (Hungarian and Polish). We train diagnostic stress classifiers on S3M embeddings and show that they can distinguish between stressed and unstressed syllables in read-aloud short sentences with high accuracy. We also tested the language-specificity effects of S3M word stress. The results indicate that the word stress representations are language-specific, with a greater difference between the set of variable versus the set of fixed stressed languages.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we study word stress representations learned by self-supervisedspeech models (S3M), specifically the Wav2vec 2.0 model. We investigate the S3Mrepresentations of word stress for five different languages: Three languageswith variable or lexical stress (Dutch, English and German) and two languageswith fixed or demarcative stress (Hungarian and Polish). We train diagnosticstress classifiers on S3M embeddings and show that they can distinguish betweenstressed and unstressed syllables in read-aloud short sentences with highaccuracy. We also tested language-specificity effects of S3M word stress. Theresults indicate that the word stress representations are language-specific,with a greater difference between the set of variable versus the set of fixedstressed languages.</description>
      <author>example@mail.com (Martijn Bentum, Louis ten Bosch, Tomas O. Lentz)</author>
      <guid isPermaLink="false">2507.04738v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MambaFusion: Height-Fidelity Dense Global Fusion for Multi-modal 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.04369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种纯Mamba块，能够实现高效的密集全局融合，同时保证相机-激光雷达多模态3D目标检测的最高性能。&lt;h4&gt;背景&lt;/h4&gt;现有的融合策略受到无法同时实现效率、长距离建模和保留完整场景信息的能力限制。&lt;h4&gt;目的&lt;/h4&gt;通过利用状态空间模型（SSMs）和线性注意力机制的线性复杂性和长距离建模能力，解决这些挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了高度保真的激光雷达编码，通过连续空间中的体素压缩保留精确的高度信息，从而增强相机-激光雷达的对齐。引入了混合Mamba块，利用增强的高度信息特征进行局部和全局上下文学习。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，简单地采用高效的线性复杂度方法并不一定能带来改进，甚至可能降低性能。这种降级归因于多模态对齐过程中高度信息的丢失，导致序列顺序的偏差。&lt;h4&gt;结论&lt;/h4&gt;该方法在nuScenes验证基准测试中实现了最先进的性能，顶级NDS分数为75.0，甚至在某些使用高分辨率输入的方法之上。同时，该方法保持了效率，比大多数最新的最先进方法具有更快的推理速度。&lt;h4&gt;翻译&lt;/h4&gt;We present the first work demonstrating that a pure Mamba block can achieve efficient Dense Global Fusion, meanwhile guaranteeing top performance for camera-LiDAR multi-modal 3D object detection. Our motivation stems from the observation that existing fusion strategies are constrained by their inability to simultaneously achieve efficiency, long-range modeling, and retaining complete scene information. Inspired by recent advances in state-space models (SSMs) and linear attention, we leverage their linear complexity and long-range modeling capabilities to address these challenges. However, this is non-trivial since our experiments reveal that simply adopting efficient linear-complexity methods does not necessarily yield improvements and may even degrade performance. We attribute this degradation to the loss of height information during multi-modal alignment, leading to deviations in sequence order. To resolve this, we propose height-fidelity LiDAR encoding that preserves precise height information through voxel compression in continuous space, thereby enhancing camera-LiDAR alignment. Subsequently, we introduce the Hybrid Mamba Block, which leverages the enriched height-informed features to conduct local and global contextual learning. By integrating these components, our method achieves state-of-the-art performance with the top-tire NDS score of 75.0 on the nuScenes validation benchmark, even surpassing methods that utilize high-resolution inputs. Meanwhile, our method maintains efficiency, achieving faster inference speed than most recent state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the first work demonstrating that a pure Mamba block can achieveefficient Dense Global Fusion, meanwhile guaranteeing top performance forcamera-LiDAR multi-modal 3D object detection. Our motivation stems from theobservation that existing fusion strategies are constrained by their inabilityto simultaneously achieve efficiency, long-range modeling, and retainingcomplete scene information. Inspired by recent advances in state-space models(SSMs) and linear attention, we leverage their linear complexity and long-rangemodeling capabilities to address these challenges. However, this is non-trivialsince our experiments reveal that simply adopting efficient linear-complexitymethods does not necessarily yield improvements and may even degradeperformance. We attribute this degradation to the loss of height informationduring multi-modal alignment, leading to deviations in sequence order. Toresolve this, we propose height-fidelity LiDAR encoding that preserves preciseheight information through voxel compression in continuous space, therebyenhancing camera-LiDAR alignment. Subsequently, we introduce the Hybrid MambaBlock, which leverages the enriched height-informed features to conduct localand global contextual learning. By integrating these components, our methodachieves state-of-the-art performance with the top-tire NDS score of 75.0 onthe nuScenes validation benchmark, even surpassing methods that utilizehigh-resolution inputs. Meanwhile, our method maintains efficiency, achievingfaster inference speed than most recent state-of-the-art methods.</description>
      <author>example@mail.com (Hanshi Wang, Jin Gao, Weiming Hu, Zhipeng Zhang)</author>
      <guid isPermaLink="false">2507.04369v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Representations for Fine-grained Multi-label Critical View of Safety Recognition</title>
      <link>http://arxiv.org/abs/2507.05007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种名为CVS-AdaptNet的多标签适应策略，用于自动化CVS识别，并通过文本提示增强多模态手术基础模型的能力。&lt;h4&gt;背景&lt;/h4&gt;安全的腹腔镜胆囊切除术需要关键的视野评估（CVS），但评估CVS标准对于专家来说仍然复杂且具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用文本作为强大的工具，在多模态手术基础模型中用于训练和推理，以自动化CVS识别。&lt;h4&gt;方法&lt;/h4&gt;提出CVS-AdaptNet，通过正负提示将图像嵌入与CVS每个标准的文本描述对齐，从而提高多标签二分类的细粒度分类能力。使用PeskaVLP手术基础模型在Endoscapes-CVS201数据集上进行适配。&lt;h4&gt;主要发现&lt;/h4&gt;CVS-AdaptNet在Endoscapes-CVS201数据集上实现了57.6 mAP，比ResNet50图像基线（51.5 mAP）提高了6点。&lt;h4&gt;结论&lt;/h4&gt;CVS-AdaptNet的多标签多模态框架，通过文本提示增强了CVS识别能力，同时提出了文本特定的推理方法以帮助分析图像文本对齐。&lt;h4&gt;翻译&lt;/h4&gt;The Critical View of Safety (CVS) is crucial for safe laparoscopic cholecystectomy, yet assessing CVS criteria remains a complex and challenging task, even for experts. Traditional models for CVS recognition depend on vision-only models learning with costly, labor-intensive spatial annotations. This study investigates how text can be harnessed as a powerful tool for both training and inference in multi-modal surgical foundation models to automate CVS recognition. Unlike many existing multi-modal models, which are primarily adapted for multi-class classification, CVS recognition requires a multi-label framework. Zero-shot evaluation of existing multi-modal surgical models shows a significant performance gap for this task. To address this, we propose CVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained, binary classification across multiple labels by aligning image embeddings with textual descriptions of each CVS criterion using positive and negative prompts. By adapting PeskaVLP, a state-of-the-art surgical foundation model, on the Endoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over the ResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show that CVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts, boosts CVS recognition over image-only methods. We also propose text-specific inference methods, that helps in analysing the image-text alignment. While further work is needed to match state-of-the-art spatial annotation-based methods, this approach highlights the potential of adapting generalist models to specialized surgical tasks. Code: https://github.com/CAMMA-public/CVS-AdaptNet&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Critical View of Safety (CVS) is crucial for safe laparoscopiccholecystectomy, yet assessing CVS criteria remains a complex and challengingtask, even for experts. Traditional models for CVS recognition depend onvision-only models learning with costly, labor-intensive spatial annotations.This study investigates how text can be harnessed as a powerful tool for bothtraining and inference in multi-modal surgical foundation models to automateCVS recognition. Unlike many existing multi-modal models, which are primarilyadapted for multi-class classification, CVS recognition requires a multi-labelframework. Zero-shot evaluation of existing multi-modal surgical models shows asignificant performance gap for this task. To address this, we proposeCVS-AdaptNet, a multi-label adaptation strategy that enhances fine-grained,binary classification across multiple labels by aligning image embeddings withtextual descriptions of each CVS criterion using positive and negative prompts.By adapting PeskaVLP, a state-of-the-art surgical foundation model, on theEndoscapes-CVS201 dataset, CVS-AdaptNet achieves 57.6 mAP, improving over theResNet50 image-only baseline (51.5 mAP) by 6 points. Our results show thatCVS-AdaptNet's multi-label, multi-modal framework, enhanced by textual prompts,boosts CVS recognition over image-only methods. We also propose text-specificinference methods, that helps in analysing the image-text alignment. Whilefurther work is needed to match state-of-the-art spatial annotation-basedmethods, this approach highlights the potential of adapting generalist modelsto specialized surgical tasks. Code:https://github.com/CAMMA-public/CVS-AdaptNet</description>
      <author>example@mail.com (Britty Baby, Vinkle Srivastav, Pooja P. Jain, Kun Yuan, Pietro Mascagni, Nicolas Padoy)</author>
      <guid isPermaLink="false">2507.05007v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>A Cycle-Consistency Constrained Framework for Dynamic Solution Space Reduction in Noninjective Regression</title>
      <link>http://arxiv.org/abs/2507.04659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于循环一致性的数据驱动训练框架，旨在解决多输出模型在非注入回归任务中对预设概率分布和嵌入先验知识的依赖问题。&lt;h4&gt;背景&lt;/h4&gt;多输出模型在非注入回归任务中通常依赖于预设的概率分布和嵌入的先验知识。&lt;h4&gt;目的&lt;/h4&gt;减少对预设概率分布和嵌入先验知识的依赖。&lt;h4&gt;方法&lt;/h4&gt;该方法联合优化了前向模型Φ：X到Y和后向模型Ψ：Y到X，通过最小化循环一致性损失L_cycleb（L(Y reduce Φ(Ψ(Y)))和反之），建立了一个整合生成和验证阶段的闭环机制，无需手动规则设计或先验分布假设。&lt;h4&gt;主要发现&lt;/h4&gt;在标准化合成和模拟数据集上的实验表明，该方法实现了低于0.003的循环重建误差，与没有循环一致性的基线模型相比，在评估指标上提高了约30%。此外，该框架支持无监督学习，显著减少了对手动干预的依赖。&lt;h4&gt;结论&lt;/h4&gt;该框架在非注入回归任务中具有潜在优势，能够有效减少对预设概率分布和嵌入先验知识的依赖，并支持无监督学习，减少手动干预的需要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the challenges posed by the heavy reliance of multi-output modelson preset probability distributions and embedded prior knowledge innon-injective regression tasks, this paper proposes a cycle consistency-baseddata-driven training framework. The method jointly optimizes a forward model{\Phi}: X to Y and a backward model {\Psi}: Y to X, where the cycle consistencyloss is defined as L _cycleb equal L(Y reduce {\Phi}({\Psi}(Y))) (and viceversa). By minimizing this loss, the framework establishes a closed-loopmechanism integrating generation and validation phases, eliminating the needfor manual rule design or prior distribution assumptions. Experiments onnormalized synthetic and simulated datasets demonstrate that the proposedmethod achieves a cycle reconstruction error below 0.003, achieving animprovement of approximately 30% in evaluation metrics compared to baselinemodels without cycle consistency. Furthermore, the framework supportsunsupervised learning and significantly reduces reliance on manualintervention, demonstrating potential advantages in non-injective regressiontasks.</description>
      <author>example@mail.com (Hanzhang Jia, Yi Gao)</author>
      <guid isPermaLink="false">2507.04659v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>VectorLLM: Human-like Extraction of Structured Building Contours vis Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2507.04664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为VectorLLM的多模态大型语言模型，用于从遥感图像中自动提取矢量化的建筑轮廓，旨在提高城市规划、人口估计和灾害评估的效率。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感图像建筑轮廓提取方法依赖复杂的多阶段流程，包括像素分割、矢量化和多边形细化，这限制了其可扩展性和实际应用。&lt;h4&gt;目的&lt;/h4&gt;设计一个名为VectorLLM的模型，直接对建筑轮廓进行角点回归，模拟人类标注者的标注过程，以提高提取效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;VectorLLM由视觉基础骨干网络、MLP连接器和LLM组成，并增强了可学习的位置嵌入来提高空间理解能力。通过在WHU、WHU-Mix和CrowdAI数据集上综合探索预训练、监督微调和偏好优化等训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;VectorLLM在三个数据集上分别比之前的最优方法提高了5.6 AP、7.1 AP和13.6 AP。此外，VectorLLM在未见过的对象（如飞机、水体和油罐）上表现出强大的零样本性能，显示出其在统一建模各种遥感对象轮廓提取任务中的潜力。&lt;h4&gt;结论&lt;/h4&gt;这项工作建立了遥感矢量提取的新范式，利用LLM的拓扑推理能力实现了高精度和卓越的泛化能力。所有代码和权重将公开发布，以促进社区发展。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为VectorLLM的多模态大型语言模型，用于从遥感图像中自动提取矢量化的建筑轮廓，对城市规划、人口估计和灾害评估具有重要意义。现有方法依赖复杂的多阶段流程，限制了其应用。本文提出的VectorLLM直接对建筑轮廓进行角点回归，模拟人类标注过程，并通过预训练、监督微调和偏好优化等策略在多个数据集上显著优于现有方法。此外，VectorLLM在未见过的对象上表现出强大的零样本性能，显示出其在多种遥感对象轮廓提取任务中的潜力。本文建立了一种基于LLM的遥感矢量提取新范式，并计划公开发布所有代码和权重以促进社区发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically extracting vectorized building contours from remote sensingimagery is crucial for urban planning, population estimation, and disasterassessment. Current state-of-the-art methods rely on complex multi-stagepipelines involving pixel segmentation, vectorization, and polygon refinement,which limits their scalability and real-world applicability. Inspired by theremarkable reasoning capabilities of Large Language Models (LLMs), we introduceVectorLLM, the first Multi-modal Large Language Model (MLLM) designed forregular building contour extraction from remote sensing images. Unlike existingapproaches, VectorLLM performs corner-point by corner-point regression ofbuilding contours directly, mimicking human annotators' labeling process. Ourarchitecture consists of a vision foundation backbone, an MLP connector, and anLLM, enhanced with learnable position embeddings to improve spatialunderstanding capability. Through comprehensive exploration of trainingstrategies including pretraining, supervised fine-tuning, and preferenceoptimization across WHU, WHU-Mix, and CrowdAI datasets, VectorLLM significantlyoutperformed the previous SOTA methods by 5.6 AP, 7.1 AP, 13.6 AP, respectivelyin the three datasets. Remarkably, VectorLLM exhibits strong zero-shotperformance on unseen objects including aircraft, water bodies, and oil tanks,highlighting its potential for unified modeling of diverse remote sensingobject contour extraction tasks. Overall, this work establishes a new paradigmfor vector extraction in remote sensing, leveraging the topological reasoningcapabilities of LLMs to achieve both high accuracy and exceptionalgeneralization. All the codes and weights will be published for promotingcommunity development.</description>
      <author>example@mail.com (Tao Zhang, Shiqing Wei, Shihao Chen, Wenling Yu, Muying Luo, Shunping Ji)</author>
      <guid isPermaLink="false">2507.04664v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>What's Making That Sound Right Now? Video-centric Audio-Visual Localization</title>
      <link>http://arxiv.org/abs/2507.04667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at ICCV 2025. Project page:  https://hahyeon610.github.io/Video-centric_Audio_Visual_Localization/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AVATAR的基于视频的音频-视觉定位（AVL）基准，以及一种名为TAVLO的新型视频中心AVL模型，旨在解决现有AVL研究在时间动态捕捉和场景简化方面的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有AVL研究主要关注图像级别的音频-视觉关联，未能捕捉时间动态，且假设简化场景，如声音源总是可见且只涉及单个对象。&lt;h4&gt;目的&lt;/h4&gt;提出AVATAR基准和TAVLO模型，以更全面地评估AVL模型，并解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;AVATAR基准引入了四种不同的场景：单声音、混合声音、多实体和屏幕外，以评估AVL模型。TAVLO模型通过整合高分辨率时间信息，实现视频中心的AVL。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，传统方法由于依赖全局音频特征和帧级映射，难以跟踪时间变化。而TAVLO通过高分辨率时间建模，实现了稳健且精确的音频-视觉对齐。&lt;h4&gt;结论&lt;/h4&gt;本文证明了时间动态在AVL中的重要性，并建立了视频中心音频-视觉定位的新标准。&lt;h4&gt;翻译&lt;/h4&gt;Audio-Visual Localization (AVL) aims to identify sound-emitting sources within a visual scene. However, existing studies focus on image-level audio-visual associations, failing to capture temporal dynamics. Moreover, they assume simplified scenarios where sound sources are always visible and involve only a single object. To address these limitations, we propose AVATAR, a video-centric AVL benchmark that incorporates high-resolution temporal information. AVATAR introduces four distinct scenarios -- Single-sound, Mixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensive evaluation of AVL models. Additionally, we present TAVLO, a novel video-centric AVL model that explicitly integrates temporal information. Experimental results show that conventional methods struggle to track temporal variations due to their reliance on global audio features and frame-level mappings. In contrast, TAVLO achieves robust and precise audio-visual alignment by leveraging high-resolution temporal modeling. Our work empirically demonstrates the importance of temporal dynamics in AVL and establishes a new standard for video-centric audio-visual localization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-Visual Localization (AVL) aims to identify sound-emitting sourceswithin a visual scene. However, existing studies focus on image-levelaudio-visual associations, failing to capture temporal dynamics. Moreover, theyassume simplified scenarios where sound sources are always visible and involveonly a single object. To address these limitations, we propose AVATAR, avideo-centric AVL benchmark that incorporates high-resolution temporalinformation. AVATAR introduces four distinct scenarios -- Single-sound,Mixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensiveevaluation of AVL models. Additionally, we present TAVLO, a novel video-centricAVL model that explicitly integrates temporal information. Experimental resultsshow that conventional methods struggle to track temporal variations due totheir reliance on global audio features and frame-level mappings. In contrast,TAVLO achieves robust and precise audio-visual alignment by leveraginghigh-resolution temporal modeling. Our work empirically demonstrates theimportance of temporal dynamics in AVL and establishes a new standard forvideo-centric audio-visual localization.</description>
      <author>example@mail.com (Hahyeon Choi, Junhoo Lee, Nojun Kwak)</author>
      <guid isPermaLink="false">2507.04667v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks as a Substitute for Transformers in Single-Cell Transcriptomics</title>
      <link>http://arxiv.org/abs/2507.04125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了图神经网络（GNNs）和Transformer在处理节点特征编码上的相似性，并分析了它们在相对位置编码上的不同。通过在单细胞转录组学领域进行实验，发现GNNs在性能上与Transformer相当，同时消耗更少的计算资源。&lt;h4&gt;背景&lt;/h4&gt;GNNs和Transformers在处理节点特征时具有相似性，但Transformer利用动态注意力机制更好地表示相对关系，成为大规模序列预训练的标准架构。&lt;h4&gt;目的&lt;/h4&gt;研究在单细胞转录组学等领域的GNNs和Transformer的应用，探讨是否可以用GNNs替代Transformer。&lt;h4&gt;方法&lt;/h4&gt;比较GNNs和Transformer在相对位置编码上的差异，设计合成示例说明它们在无相对位置时的等价性，并在单细胞转录组学数据集上进行大规模实验。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在单细胞转录组学数据集上实现了与Transformer相当的性能，同时消耗更少的计算资源。&lt;h4&gt;结论&lt;/h4&gt;GNNs在某些领域（如单细胞转录组学）可以替代Transformer，挑战了Transformer总是最优选择的观念。&lt;h4&gt;翻译&lt;/h4&gt;This paper explores the similarities and differences between Graph Neural Networks (GNNs) and Transformers in their encoding strategies for interacting with features from nodes of interest, particularly in terms of relative positions. Through extensive experiments on a large-scale position-agnostic dataset in the field of single-cell transcriptomics, it is found that GNNs achieve competitive performance compared to Transformers while consuming fewer computational resources. These findings provide novel insights for researchers in the field of single-cell transcriptomics, challenging the prevailing notion that the Transformer is always the optimal choice.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) and Transformers share significant similaritiesin their encoding strategies for interacting with features from nodes ofinterest, where Transformers use query-key scores and GNNs use edges. Comparedto GNNs, which are unable to encode relative positions, Transformers leveragedynamic attention capabilities to better represent relative relationships,thereby becoming the standard backbones in large-scale sequential pre-training.However, the subtle difference prompts us to consider: if positions are nolonger crucial, could we substitute Transformers with Graph Neural Networks insome fields such as Single-Cell Transcriptomics? In this paper, we firstexplore the similarities and differences between GNNs and Transformers,specifically in terms of relative positions. Additionally, we design asynthetic example to illustrate their equivalence where there are no relativepositions between tokens in the sample. Finally, we conduct extensiveexperiments on a large-scale position-agnostic dataset-single-celltranscriptomics-finding that GNNs achieve competitive performance compared toTransformers while consuming fewer computation resources. These findingsprovide novel insights for researchers in the field of single-celltranscriptomics, challenging the prevailing notion that the Transformer isalways the optimum choice.</description>
      <author>example@mail.com (Jiaxin Qi, Yan Cui, Jinli Ou, Jianqiang Huang, Gaogang Xie)</author>
      <guid isPermaLink="false">2507.04125v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in Infinite Width Feature Learning Networks</title>
      <link>http://arxiv.org/abs/2507.04448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一个在无限宽神经网络中进行迁移学习的新理论，分析了预训练（源任务）和下游任务（目标任务）在特征学习范畴中的操作，并在贝叶斯框架和随机初始化网络梯度流训练两种设置下追踪了表征的演化。&lt;h4&gt;背景&lt;/h4&gt;迁移学习研究。&lt;h4&gt;目的&lt;/h4&gt;分析无限宽神经网络中的迁移学习，并探讨不同设置下表征的演化。&lt;h4&gt;方法&lt;/h4&gt;贝叶斯框架分析和随机初始化网络梯度流训练，使用弹性权重耦合控制特征的重用。&lt;h4&gt;主要发现&lt;/h4&gt;提出了适应性特征核，用于迁移学习后的总结统计，并揭示了弹性权重耦合、特征学习强度、数据集大小以及源和目标任务一致性对迁移学习效用的影响。&lt;h4&gt;结论&lt;/h4&gt;理论揭示了迁移学习中的复杂相互作用，对迁移学习有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;我们发展了一种在无限宽神经网络中的迁移学习理论，其中预训练（源任务）和下游任务（目标任务）都可以在特征学习范畴中操作。我们分析了贝叶斯框架，其中学习被描述为权重上的后验分布，以及使用权重衰减训练的随机初始化网络的梯度流训练。在这两种设置下，都追踪了源任务和目标任务中表征的演化。这些理论的总结统计是适应性特征核，迁移学习后，它们依赖于源任务和目标任务中的数据和标签。在迁移学习过程中特征的重用通过弹性权重耦合来控制，它控制了网络对源任务训练期间学习的特征的依赖性。我们将我们的理论应用于线性回归、多项式回归任务以及真实数据集。我们的理论和实验揭示了弹性权重耦合、特征学习强度、数据集大小以及源和目标任务一致性对迁移学习效用之间有趣的相互作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop a theory of transfer learning in infinitely wide neural networkswhere both the pretraining (source) and downstream (target) task can operate ina feature learning regime. We analyze both the Bayesian framework, wherelearning is described by a posterior distribution over the weights, andgradient flow training of randomly initialized networks trained with weightdecay. Both settings track how representations evolve in both source and targettasks. The summary statistics of these theories are adapted feature kernelswhich, after transfer learning, depend on data and labels from both source andtarget tasks. Reuse of features during transfer learning is controlled by anelastic weight coupling which controls the reliance of the network on featureslearned during training on the source task. We apply our theory to linear andpolynomial regression tasks as well as real datasets. Our theory andexperiments reveal interesting interplays between elastic weight coupling,feature learning strength, dataset size, and source and target task alignmenton the utility of transfer learning.</description>
      <author>example@mail.com (Clarissa Lauditi, Blake Bordelon, Cengiz Pehlevan)</author>
      <guid isPermaLink="false">2507.04448v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Commute Networks as a Signature of Urban Socioeconomic Performance: Evaluating Mobility Structures with Deep Learning Models</title>
      <link>http://arxiv.org/abs/2507.04027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于通勤信息记录构建城市社会经济模型的方法，利用深度学习架构分析城市间的移动网络，并展示出移动网络结构在预测性能上的重要性。&lt;h4&gt;背景&lt;/h4&gt;城市社会经济模型主要关注地理位置和邻里特征，但许多模型未考虑网络效应。&lt;h4&gt;目的&lt;/h4&gt;使用通勤信息记录构建城市移动网络，并利用这些网络进行社会经济建模。&lt;h4&gt;方法&lt;/h4&gt;通过利用深度学习架构，结合图神经网络和普通神经网络模型，在一个学习流程中学习所有参数。&lt;h4&gt;主要发现&lt;/h4&gt;移动网络结构提供了显著的预测性能，无需考虑任何节点特征。&lt;h4&gt;结论&lt;/h4&gt;该模型在12个主要美国城市中优于传统机器学习模型，为城市研究者提供了在模型中纳入网络效应的方法，并为政策制定者和规划者提供了关于城市政策制定的更广泛网络效应的信息。&lt;h4&gt;翻译&lt;/h4&gt;摘要：城市社会经济建模主要集中于广泛的地理位置和邻里特征，依赖于本地化的人口足迹。然而，城市系统中的网络很常见，许多城市建模方法没有考虑基于网络的效果。在本研究中，我们提出使用人口普查中的通勤信息记录作为可靠和全面的来源来构建城市间的移动网络。利用深度学习架构，我们使用这些通勤网络来分析美国大都市区的社会经济模型。我们发现，移动网络结构提供了显著的预测性能，而无需考虑任何节点特征。因此，我们使用移动网络来展示一个监督学习框架，直接对城市的社会经济指标进行建模，结合图神经网络和普通神经网络模型在一个学习流程中学习所有参数。我们在12个主要美国城市的实验表明，所提出的模型优于之前的传统机器学习模型。这项工作为城市研究者提供了在模型中纳入网络效应的方法，并为政策制定者和规划者提供了关于城市政策制定的更广泛网络效应的信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban socioeconomic modeling has predominantly concentrated on extensivelocation and neighborhood-based features, relying on the localized populationfootprint. However, networks in urban systems are common, and many urbanmodeling methods don't account for network-based effects. In this study, wepropose using commute information records from the census as a reliable andcomprehensive source to construct mobility networks across cities. Leveragingdeep learning architectures, we employ these commute networks across U.S. metroareas for socioeconomic modeling. We show that mobility network structuresprovide significant predictive performance without considering any nodefeatures. Consequently, we use mobility networks to present a supervisedlearning framework to model a city's socioeconomic indicator directly,combining Graph Neural Network and Vanilla Neural Network models to learn allparameters in a single learning pipeline. Our experiments in 12 major U.S.cities show the proposed model outperforms previous conventional machinelearning models. This work provides urban researchers methods to incorporatenetwork effects in urban modeling and informs stakeholders of widernetwork-based effects in urban policymaking and planning.</description>
      <author>example@mail.com (Devashish Khulbe, Alexander Belyi, Stanislav Sobolevsky)</author>
      <guid isPermaLink="false">2507.04027v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Voyaging into Unbounded Dynamic Scenes from a Single View</title>
      <link>http://arxiv.org/abs/2507.04183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by International Conference on Computer Vision (ICCV) 2025.  Project Page: https://tianfr.github.io/DynamicVoyager&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了从单一视角生成无界动态场景的问题，该问题在增强/虚拟现实和机器人领域有广泛的应用。&lt;h4&gt;背景&lt;/h4&gt;由于场景随时间变化，生成的不同视角需要与底层3D运动保持一致。以往的工作通过从多个视角训练来学习这种一致性，但生成的场景区域被限制在训练视角附近，且相机运动有限。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，本文提出了DynamicVoyager，将动态场景生成重新定义为场景外推过程，用于生成新的动态内容。&lt;h4&gt;方法&lt;/h4&gt;由于2D外推模型难以从单一视角的2D像素中生成3D一致的运动，本文将像素视为射线，通过射线上下文丰富像素输入，从而从射线信息中学习3D运动一致性。具体来说，首先将单视角视频输入映射到动态点云，并使用估计的视频深度进行渲染。然后，从点云中获取射线上下文来外推视频，生成3D一致的运动。使用外推的视频更新点云，该点云用于从未来的新视角进行场景外推。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该模型能够生成具有一致运动的无限场景，并且生成的内容可以通过场景提示进行控制。&lt;h4&gt;结论&lt;/h4&gt;DynamicVoyager能够有效地从单一视角生成无界动态场景，并保持运动的一致性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了从单一视角生成无界动态场景的问题，该问题在增强/虚拟现实和机器人领域有广泛的应用。由于场景随时间变化，生成的不同视角需要与底层3D运动保持一致。以往的工作通过从多个视角训练来学习这种一致性，但生成的场景区域被限制在训练视角附近，且相机运动有限。为了解决这一问题，本文提出了DynamicVoyager，将动态场景生成重新定义为场景外推过程，用于生成新的动态内容。由于2D外推模型难以从单一视角的2D像素中生成3D一致的运动，本文将像素视为射线，通过射线上下文丰富像素输入，从而从射线信息中学习3D运动一致性。具体来说，首先将单视角视频输入映射到动态点云，并使用估计的视频深度进行渲染。然后，从点云中获取射线上下文来外推视频，生成3D一致的运动。使用外推的视频更新点云，该点云用于从未来的新视角进行场景外推。实验表明，该模型能够生成具有一致运动的无限场景，并且生成的内容可以通过场景提示进行控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies the problem of generating an unbounded dynamic scene froma single view, which has wide applications in augmented/virtual reality androbotics. Since the scene is changing over time, different generated views needto be consistent with the underlying 3D motions. While previous works learnsuch consistency by training from multiple views, the generated scene regionsare bounded to be close to the training views with limited camera movements. Toaddress this issue, we propose DynamicVoyager that reformulates the dynamicscene generation as a scene outpainting process for new dynamic content. As 2Doutpainting models can hardly generate 3D consistent motions from only 2Dpixels at a single view, we consider pixels as rays to enrich the pixel inputwith the ray context, so that the 3D motion consistency can be learned from theray information. More specifically, we first map the single-view video input toa dynamic point cloud with the estimated video depths. Then we render thepartial video at a novel view and outpaint the video with ray contexts from thepoint cloud to generate 3D consistent motions. We employ the outpainted videoto update the point cloud, which is used for scene outpainting from futurenovel views. Experiments show that our model is able to generate unboundedscenes with consistent motions along fly-through cameras, and the generatedcontents can be controlled with scene prompts.</description>
      <author>example@mail.com (Fengrui Tian, Tianjiao Ding, Jinqi Luo, Hancheng Min, René Vidal)</author>
      <guid isPermaLink="false">2507.04183v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents</title>
      <link>http://arxiv.org/abs/2507.04590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为VLM2Vec-V2的统一框架，用于学习不同视觉形式的嵌入，并扩展了MMEB基准，增加了五个新的任务类型，包括视觉文档检索、视频检索、时间定位、视频分类和视频问答，以支持文本、图像、视频和视觉文档的输入。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态嵌入模型如VLM2Vec、E5-V、GME主要关注自然图像，对视频和其他视觉形式的支持有限，限制了它们在实际场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了填补这一空白，提出VLM2Vec-V2，旨在扩展多模态嵌入模型的应用范围，使其能够处理更多种类的视觉形式。&lt;h4&gt;方法&lt;/h4&gt;首先，引入了MMEB-V2，这是一个包含五个新任务类型的全面基准；其次，训练了VLM2Vec-V2，这是一个支持文本、图像、视频和视觉文档输入的通用嵌入模型。&lt;h4&gt;主要发现&lt;/h4&gt;VLM2Vec-V2在视频和文档检索任务上表现出色，并且在原始图像基准上也优于先前的方法。通过广泛评估，研究提供了关于各种多模态嵌入模型泛化能力的见解，并突出了统一嵌入学习的高效策略。&lt;h4&gt;结论&lt;/h4&gt;本研究为更可扩展和适应性的表示学习奠定了基础，无论是在研究还是实际应用场景中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal embedding models have been crucial in enabling various downstreamtasks such as semantic similarity, information retrieval, and clustering overdifferent modalities. However, existing multimodal embeddings like VLM2Vec,E5-V, GME are predominantly focused on natural images, with limited support forother visual forms such as videos and visual documents. This restricts theirapplicability in real-world scenarios, including AI agents, multi-modal searchand recommendation, and retrieval-augmented generation (RAG). To close thisgap, we propose VLM2Vec-V2, a unified framework for learning embeddings acrossdiverse visual forms. First, we introduce MMEB-V2, a comprehensive benchmarkthat extends MMEB with five new task types: visual document retrieval, videoretrieval, temporal grounding, video classification and video questionanswering - spanning text, image, video, and visual document inputs. Next, wetrain VLM2Vec-V2, a general-purpose embedding model that supports text, image,video, and visual document inputs. Extensive experiments show that VLM2Vec-V2achieves strong performance not only on the newly introduced video and documentretrieval tasks, but also improves over prior baselines on the original imagebenchmarks. Through extensive evaluation, our study offers insights into thegeneralizability of various multimodal embedding models and highlightseffective strategies for unified embedding learning, laying the groundwork formore scalable and adaptable representation learning in both research andreal-world settings.</description>
      <author>example@mail.com (Rui Meng, Ziyan Jiang, Ye Liu, Mingyi Su, Xinyi Yang, Yuepeng Fu, Can Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Yingbo Zhou, Wenhu Chen, Semih Yavuz)</author>
      <guid isPermaLink="false">2507.04590v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>HiLa: Hierarchical Vision-Language Collaboration for Cancer Survival Prediction</title>
      <link>http://arxiv.org/abs/2507.04613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HiLa的新框架，用于利用全切片图像（WSIs）进行癌症研究中的生存预测，旨在解决现有方法依赖稀疏标签和忽略WSI层次结构的问题。&lt;h4&gt;背景&lt;/h4&gt;生存预测在癌症研究中至关重要，但现有方法依赖于稀疏的切片级标签，难以从高分辨率的WSIs中学习有判别性的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过改进视觉-语言对齐和增强层次结构建模来提高生存预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;HiLa框架通过使用预训练的特征提取器生成WSI的层次视觉特征，并在每个级别构建描述生存相关属性的系列语言提示，并通过最优提示学习（OPL）与视觉特征对齐。此外，引入了跨级传播（CLP）和相互对比学习（MCL）模块来最大化层次合作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HiLa在三个TCGA数据集上取得了最先进的表现。&lt;h4&gt;结论&lt;/h4&gt;HiLa框架通过增强视觉-语言对齐和层次结构建模，为癌症研究中的生存预测提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Survival prediction using whole-slide images (WSIs) is crucial in cancerre-search. Despite notable success, existing approaches are limited by theirreliance on sparse slide-level labels, which hinders the learning ofdiscriminative repre-sentations from gigapixel WSIs. Recently, vision language(VL) models, which incorporate additional language supervision, have emerged asa promising solu-tion. However, VL-based survival prediction remains largelyunexplored due to two key challenges. First, current methods often rely on onlyone simple lan-guage prompt and basic cosine similarity, which fails to learnfine-grained associ-ations between multi-faceted linguistic information andvisual features within WSI, resulting in inadequate vision-language alignment.Second, these methods primarily exploit patch-level information, overlookingthe intrinsic hierarchy of WSIs and their interactions, causing ineffectivemodeling of hierarchical interac-tions. To tackle these problems, we propose anovel Hierarchical vision-Language collaboration (HiLa) framework for improvedsurvival prediction. Specifically, HiLa employs pretrained feature extractorsto generate hierarchical visual features from WSIs at both patch and regionlevels. At each level, a series of language prompts describing varioussurvival-related attributes are constructed and aligned with visual featuresvia Optimal Prompt Learning (OPL). This ap-proach enables the comprehensivelearning of discriminative visual features cor-responding to differentsurvival-related attributes from prompts, thereby improv-ing vision-languagealignment. Furthermore, we introduce two modules, i.e., Cross-Level Propagation(CLP) and Mutual Contrastive Learning (MCL) to maximize hierarchicalcooperation by promoting interactions and consistency be-tween patch and regionlevels. Experiments on three TCGA datasets demonstrate our SOTA performance.</description>
      <author>example@mail.com (Jiaqi Cui, Lu Wen, Yuchen Fei, Bo Liu, Luping Zhou, Dinggang Shen, Yan Wang)</author>
      <guid isPermaLink="false">2507.04613v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Towards Accurate and Efficient 3D Object Detection for Autonomous Driving: A Mixture of Experts Computing System on Edge</title>
      <link>http://arxiv.org/abs/2507.04123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Edge-based Mixture of Experts (MoE) CollaborativeComputing (EMC2)的边缘计算系统，旨在为自动驾驶车辆提供低延迟和高精度的3D物体检测。&lt;h4&gt;背景&lt;/h4&gt;传统的计算方法在自动驾驶车辆的3D物体检测中存在延迟和精度的问题。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够同时实现低延迟和高精度3D物体检测的边缘计算系统。&lt;h4&gt;方法&lt;/h4&gt;EMC2系统采用了场景感知的MoE架构，融合LiDAR和摄像头数据，并使用自适应的多模态数据桥接器和场景感知的路由机制。此外，还集成了硬件和软件的优化，以确保在资源受限的边缘设备上高效实时地推理。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上的实验表明，EMC2系统相比15个基线方法在Jetson平台上实现了平均3.58%的精度提升和159.06%的推理速度提升，在nuScenes数据集上也取得了类似的效果。&lt;h4&gt;结论&lt;/h4&gt;EMC2系统作为端到端系统，能够显著提升自动驾驶车辆中可靠的实时3D物体检测任务。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于边缘的专家混合（MoE）协同计算（EMC2）系统，这是一种为自动驾驶车辆设计的优化计算系统，旨在同时实现低延迟和高精度的3D物体检测。与传统的计算方法不同，EMC2集成了专门针对边缘平台优化的场景感知MoE架构。通过有效地融合激光雷达和摄像头数据，该系统利用稀疏3D点云和密集2D图像的互补优势来生成稳健的多模态表示。为此，EMC2采用了一种自适应的多模态数据桥接器，对传感器输入进行多尺度预处理，然后通过场景感知的路由机制，根据物体的可见性和距离动态地将特征分配到专用专家模型。此外，EMC2还集成了联合硬件-软件优化，包括硬件资源利用优化和计算图简化，以确保在资源受限的边缘设备上高效实时地进行推理。在公开基准数据集上的实验清楚地表明，EMC2作为端到端系统具有显著的优势。在KITTI数据集上，它比15个基线方法在Jetson平台上实现了平均3.58%的精度提升和159.06%的推理速度提升，在nuScenes数据集上也取得了类似的效果，突显了其在提升自动驾驶车辆可靠、实时3D物体检测任务方面的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents Edge-based Mixture of Experts (MoE) CollaborativeComputing (EMC2), an optimal computing system designed for autonomous vehicles(AVs) that simultaneously achieves low-latency and high-accuracy 3D objectdetection. Unlike conventional approaches, EMC2 incorporates a scenario-awareMoE architecture specifically optimized for edge platforms. By effectivelyfusing LiDAR and camera data, the system leverages the complementary strengthsof sparse 3D point clouds and dense 2D images to generate robust multimodalrepresentations. To enable this, EMC2 employs an adaptive multimodal databridge that performs multi-scale preprocessing on sensor inputs, followed by ascenario-aware routing mechanism that dynamically dispatches features todedicated expert models based on object visibility and distance. In addition,EMC2 integrates joint hardware-software optimizations, including hardwareresource utilization optimization and computational graph simplification, toensure efficient and real-time inference on resource-constrained edge devices.Experiments on open-source benchmarks clearly show the EMC2 advancements as aend-to-end system. On the KITTI dataset, it achieves an average accuracyimprovement of 3.58% and a 159.06% inference speedup compared to 15 baselinemethods on Jetson platforms, with similar performance gains on the nuScenesdataset, highlighting its capability to advance reliable, real-time 3D objectdetection tasks for AVs.</description>
      <author>example@mail.com (Linshen Liu, Boyan Su, Junyue Jiang, Guanlin Wu, Cong Guo, Ceyu Xu, Hao Frank Yang)</author>
      <guid isPermaLink="false">2507.04123v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Parameterized Diffusion Optimization enabled Autoregressive Ordinal Regression for Diabetic Retinopathy Grading</title>
      <link>http://arxiv.org/abs/2507.04978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AOR-DR的新型自回归序回归方法，用于评估糖尿病视网膜病变（DR）的严重程度，以提高DR分类的性能。&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变是糖尿病的长期并发症，其严重程度评估对于及时管理和治疗至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出AOR-DR方法以解决DR分类中存在的挑战，包括DR严重程度级别的不均匀分布和类别边界的模糊性。&lt;h4&gt;方法&lt;/h4&gt;AOR-DR方法通过融合先前的预测和提取的图像特征作为当前预测步骤的条件，将DR分级任务分解为一系列有序步骤。同时，利用扩散过程促进条件概率建模，使连续的全局图像特征能够直接用于自回归，而不需要从图像块级别的特征中重新学习上下文信息。&lt;h4&gt;主要发现&lt;/h4&gt;在四个大型公开眼底图像数据集上进行了广泛的实验，证明了该模型的有效性和优于六种最近最先进的序回归方法。&lt;h4&gt;结论&lt;/h4&gt;AOR-DR方法能够有效地评估DR的严重程度，并提供了比现有方法更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;作为糖尿病的长期并发症，糖尿病视网膜病变（DR）缓慢发展，可能需要数年才会威胁到视力。准确且稳健地评估其严重程度对于确保及时的管理和治疗至关重要。序回归利用类别之间的内在顺序来达到超越传统分类的性能。然而，存在挑战导致DR分类性能降低：1）DR严重程度级别的分布不均，呈现长尾模式，增加了分级过程的复杂性。2）定义类别边界的不明确性引入了额外的挑战，使得分类过程更加复杂且容易出现不一致性。本研究提出了一种名为AOR-DR的新颖自回归序回归方法，通过利用DR分级数据集设置中的固有序信息来解决上述挑战。具体来说，我们将DR分级任务分解为一系列有序步骤，通过融合先前步骤的预测和提取的图像特征作为当前预测步骤的条件。此外，我们利用扩散过程促进条件概率建模，使得连续的全局图像特征可以直接用于自回归，而无需从图像块级别的特征中重新学习上下文信息。这确保了自回归过程的有效性并利用了预训练的大规模基础模型的能力。在四个大型公开眼底图像数据集上进行了广泛的实验，证明了我们模型的有效性和优于六种最近最先进的序回归方法。实现代码可在https://github.com/Qinkaiyu/AOR-DR上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a long-term complication of diabetes, diabetic retinopathy (DR) progressesslowly, potentially taking years to threaten vision. An accurate and robustevaluation of its severity is vital to ensure prompt management and care.Ordinal regression leverages the underlying inherent order between categoriesto achieve superior performance beyond traditional classification. However,there exist challenges leading to lower DR classification performance: 1) Theuneven distribution of DR severity levels, characterized by a long-tailedpattern, adds complexity to the grading process. 2)The ambiguity in definingcategory boundaries introduces additional challenges, making the classificationprocess more complex and prone to inconsistencies. This work proposes a novelautoregressive ordinal regression method called AOR-DR to address the abovechallenges by leveraging the clinical knowledge of inherent ordinal informationin DR grading dataset settings. Specifically, we decompose the DR grading taskinto a series of ordered steps by fusing the prediction of the previous stepswith extracted image features as conditions for the current prediction step.Additionally, we exploit the diffusion process to facilitate conditionalprobability modeling, enabling the direct use of continuous global imagefeatures for autoregression without relearning contextual information frompatch-level features. This ensures the effectiveness of the autoregressiveprocess and leverages the capabilities of pre-trained large-scale foundationmodels. Extensive experiments were conducted on four large-scale publiclyavailable color fundus datasets, demonstrating our model's effectiveness andsuperior performance over six recent state-of-the-art ordinal regressionmethods. The implementation code is available athttps://github.com/Qinkaiyu/AOR-DR.</description>
      <author>example@mail.com (Qinkai Yu, Wei Zhou, Hantao Liu, Yanyu Xu, Meng Wang, Yitian Zhao, Huazhu Fu, Xujiong Ye, Yalin Zheng, Yanda Meng)</author>
      <guid isPermaLink="false">2507.04978v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>FindRec: Stein-Guided Entropic Flow for Multi-Modal Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2507.04651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FindRec的多模态序列推荐系统，旨在解决处理多模态序列数据中的挑战，特别是在时间动态建模和信息流协调方面。该系统通过创新的信息流控制输出范式，实现了对多模态特征的分布一致性和信息流的优化。&lt;h4&gt;背景&lt;/h4&gt;现代推荐系统在处理多模态序列数据时面临挑战，包括异构特征间的分布差异和多模态信号中的噪声干扰。&lt;h4&gt;目的&lt;/h4&gt;提出一个名为FindRec的新方法，以提高多模态序列推荐系统的性能。&lt;h4&gt;方法&lt;/h4&gt;FindRec采用了以下两种关键创新：(1) 基于Stein核的集成信息协调模块(IICM)，确保多模态特征和ID流之间的分布一致性；(2) 跨模态专家路由机制，根据上下文相关性自适应过滤和组合多模态特征。该方法使用多头子空间分解来提高路由稳定性，RBF-Stein梯度进行无偏分布对齐，并通过具有线性复杂度的Mamba层进行高效的时间建模。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界数据集上的大量实验表明，FindRec在处理长序列和噪声多模态输入方面优于最先进的基线方法。该框架通过模块化设计实现了推荐精度的提高和模型可解释性的增强。&lt;h4&gt;结论&lt;/h4&gt;FindRec在多模态序列推荐方面表现优异，其模块化设计有助于提高推荐准确性和模型可解释性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代推荐系统在处理多模态序列数据时面临重大挑战，特别是在时间动态建模和信息流协调方面。传统方法在处理异构特征间的分布差异和多模态信号中的噪声干扰方面存在困难。我们提出了一个名为FindRec（灵活统一的多模态序列推荐）的新方法，引入了新颖的“信息流控制输出”范式。该框架有两个关键创新：(1) 基于Stein核的集成信息协调模块(IICM)，在理论上确保多模态特征和ID流之间的分布一致性；(2) 跨模态专家路由机制，根据上下文相关性自适应过滤和组合多模态特征。我们的方法利用多头子空间分解进行路由稳定性，RBF-Stein梯度进行无偏分布对齐，并通过具有线性复杂度的Mamba层进行高效的时间建模。在三个真实世界数据集上的大量实验表明，FindRec在处理长序列和噪声多模态输入方面优于最先进的基线方法。我们的框架通过其模块化设计实现了推荐精度的提高和模型可解释性的增强。实现代码匿名在线提供，以方便重复使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern recommendation systems face significant challenges in processingmultimodal sequential data, particularly in temporal dynamics modeling andinformation flow coordination. Traditional approaches struggle withdistribution discrepancies between heterogeneous features and noiseinterference in multimodal signals. We propose \textbf{FindRec}~(\textbf{F}lexible unified \textbf{in}formation \textbf{d}isentanglement formulti-modal sequential \textbf{Rec}ommendation), introducing a novel"information flow-control-output" paradigm. The framework features two keyinnovations: (1) A Stein kernel-based Integrated Information CoordinationModule (IICM) that theoretically guarantees distribution consistency betweenmultimodal features and ID streams, and (2) A cross-modal expert routingmechanism that adaptively filters and combines multimodal features based ontheir contextual relevance. Our approach leverages multi-head subspacedecomposition for routing stability and RBF-Stein gradient for unbiaseddistribution alignment, enhanced by linear-complexity Mamba layers forefficient temporal modeling. Extensive experiments on three real-world datasetsdemonstrate FindRec's superior performance over state-of-the-art baselines,particularly in handling long sequences and noisy multimodal inputs. Ourframework achieves both improved recommendation accuracy and enhanced modelinterpretability through its modular design. The implementation code isavailable anonymously online for easyreproducibility~\footnote{https://github.com/Applied-Machine-Learning-Lab/FindRec}.</description>
      <author>example@mail.com (Maolin Wang, Yutian Xiao, Binhao Wang, Sheng Zhang, Shanshan Ye, Wanyu Wang, Hongzhi Yin, Ruocheng Guo, Zenglin Xu)</author>
      <guid isPermaLink="false">2507.04651v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>RoboBrain 2.0 Technical Report</title>
      <link>http://arxiv.org/abs/2507.02029v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RoboBrain 2.0，这是新一代的具身视觉-语言基础模型，旨在统一感知、推理和规划，以应对物理环境中的复杂具身任务。&lt;h4&gt;背景&lt;/h4&gt;RoboBrain 2.0有两种变体：一个轻量级的7B模型和一个全规模的32B模型，它们具有异构架构，包括视觉编码器和语言模型。&lt;h4&gt;目的&lt;/h4&gt;尽管体积紧凑，RoboBrain 2.0在广泛的具身推理任务上实现了强大的性能，支持关键的真实世界具身AI能力，包括空间理解和时间决策。&lt;h4&gt;方法&lt;/h4&gt;详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;32B变体在空间和时间基准测试中取得了领先结果，超过了先前开源和专有模型。&lt;h4&gt;结论&lt;/h4&gt;RoboBrain 2.0有望推进具身AI研究，并作为构建通用具身代理的实际步骤。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了RoboBrain 2.0，这是我们最新一代的具身视觉-语言基础模型，旨在统一感知、推理和规划，以应对物理环境中的复杂具身任务。它有两种变体：一个轻量级的7B模型和一个全规模的32B模型，它们具有异构架构，包括视觉编码器和语言模型。尽管体积紧凑，RoboBrain 2.0在广泛的具身推理任务上实现了强大的性能。在空间和时间基准测试中，32B变体取得了领先结果，超过了先前开源和专有模型。特别是，它支持关键的真实世界具身AI能力，包括空间理解（例如，可及性预测、空间指称、轨迹预测）和时间决策（例如，闭环交互、多智能体长期规划以及场景图更新）。本报告详细介绍了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。我们希望RoboBrain 2.0推进具身AI研究，并作为构建通用具身代理的实际步骤。代码、检查点和基准测试可在https://superrobobrain.github.io获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce RoboBrain 2.0, our latest generation of embodied vision-languagefoundation models, designed to unify perception, reasoning, and planning forcomplex embodied tasks in physical environments. It comes in two variants: alightweight 7B model and a full-scale 32B model, featuring a heterogeneousarchitecture with a vision encoder and a language model. Despite its compactsize, RoboBrain 2.0 achieves strong performance across a wide spectrum ofembodied reasoning tasks. On both spatial and temporal benchmarks, the 32Bvariant achieves leading results, surpassing prior open-source and proprietarymodels. In particular, it supports key real-world embodied AI capabilities,including spatial understanding (e.g., affordance prediction, spatialreferring, trajectory forecasting) and temporal decision-making (e.g.,closed-loop interaction, multi-agent long-horizon planning, and scene graphupdating). This report details the model architecture, data construction,multi-stage training strategies, infrastructure and practical applications. Wehope RoboBrain 2.0 advances embodied AI research and serves as a practical steptoward building generalist embodied agents. The code, checkpoint and benchmarkare available at https://superrobobrain.github.io.</description>
      <author>example@mail.com (BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Mengfei Du, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Junkai Zhao, Xiaojie Zhang, Sh/anyu Rong, Huaihai Lyu, Zhengliang Cai, Yankai Fu, Ning Chen, Bolun Zhang, Lingfeng Zhang, Shuyi Zhang, Xi Feng, Songjing Wang, Xiaodan Liu, Yance Jiao, Mengsi Lyu, Zhuo Chen, Chenrui He, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.02029v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation</title>
      <link>http://arxiv.org/abs/2507.04047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Embodied AI; 3D Vision Language Understanding&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MTU3D的框架，旨在通过集成主动感知与3D视觉语言学习，使具身智能体能够有效地探索和理解其环境。&lt;h4&gt;背景&lt;/h4&gt;现有的3D视觉-语言（3D-VL）模型主要关注在静态观测下对物体进行定位，但缺乏主动感知和探索环境的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文提出了一个统一的框架，以实现具身智能体对环境的主动探索和理解。&lt;h4&gt;方法&lt;/h4&gt;MTU3D框架的三项关键创新包括：1）在线查询表示学习，直接从RGB-D帧构建空间记忆，无需显式的3D重建；2）统一的定位和探索目标，将未探索区域表示为前沿查询，并联合优化物体定位和前沿选择；3）端到端轨迹学习，结合视觉-语言-探索预训练，使用从模拟和真实世界RGB-D序列收集的百万种不同轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;MTU3D在各种具身导航和问答基准测试中表现出色，其成功率分别比最先进的强化学习和模块化导航方法高14%、23%、9%和2%。&lt;h4&gt;结论&lt;/h4&gt;MTU3D的通用性允许使用不同的输入模式进行导航，包括类别、语言描述和参考图像。这些发现突出了连接视觉定位和探索对于具身智能的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Embodied scene understanding requires not only comprehending visual-spatial information that has been observed but also determining where to explore next in the 3D physical world. Existing 3D Vision-Language (3D-VL) models primarily focus on grounding objects in static observations from 3D reconstruction, such as meshes and point clouds, but lack the ability to actively perceive and explore their environment. To address this limitation, we introduce Move to Understand (MTU3D), a unified framework that integrates active perception with 3D vision-language learning, enabling embodied agents to effectively explore and understand their environment. This is achieved by three key innovations: 1) Online query-based representation learning, enabling direct spatial memory construction from RGB-D frames, eliminating the need for explicit 3D reconstruction. 2) A unified objective for grounding and exploring, which represents unexplored locations as frontier queries and jointly optimizes object grounding and frontier selection. 3) End-to-end trajectory learning that combines Vision-Language-Exploration pre-training over a million diverse trajectories collected from both simulated and real-world RGB-D sequences. Extensive evaluations across various embodied navigation and question-answering benchmarks show that MTU3D outperforms state-of-the-art reinforcement learning and modular navigation approaches by 14%, 23%, 9%, and 2% in success rate on HM3D-OVON, GOAT-Bench, SG3D, and A-EQA, respectively. MTU3D's versatility enables navigation using diverse input modalities, including categories, language descriptions, and reference images. These findings highlight the importance of bridging visual grounding and exploration for embodied intelligence.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied scene understanding requires not only comprehending visual-spatialinformation that has been observed but also determining where to explore nextin the 3D physical world. Existing 3D Vision-Language (3D-VL) models primarilyfocus on grounding objects in static observations from 3D reconstruction, suchas meshes and point clouds, but lack the ability to actively perceive andexplore their environment. To address this limitation, we introduce\underline{\textbf{M}}ove \underline{\textbf{t}}o\underline{\textbf{U}}nderstand (\textbf{\model}), a unified framework thatintegrates active perception with \underline{\textbf{3D}} vision-languagelearning, enabling embodied agents to effectively explore and understand theirenvironment. This is achieved by three key innovations: 1) Online query-basedrepresentation learning, enabling direct spatial memory construction from RGB-Dframes, eliminating the need for explicit 3D reconstruction. 2) A unifiedobjective for grounding and exploring, which represents unexplored locations asfrontier queries and jointly optimizes object grounding and frontier selection.3) End-to-end trajectory learning that combines\textbf{V}ision-\textbf{L}anguage-\textbf{E}xploration pre-training over amillion diverse trajectories collected from both simulated and real-world RGB-Dsequences. Extensive evaluations across various embodied navigation andquestion-answering benchmarks show that MTU3D outperforms state-of-the-artreinforcement learning and modular navigation approaches by 14\%, 23\%, 9\%,and 2\% in success rate on HM3D-OVON, GOAT-Bench, SG3D, and A-EQA,respectively. \model's versatility enables navigation using diverse inputmodalities, including categories, language descriptions, and reference images.These findings highlight the importance of bridging visual grounding andexploration for embodied intelligence.</description>
      <author>example@mail.com (Ziyu Zhu, Xilin Wang, Yixuan Li, Zhuofan Zhang, Xiaojian Ma, Yixin Chen, Baoxiong Jia, Wei Liang, Qian Yu, Zhidong Deng, Siyuan Huang, Qing Li)</author>
      <guid isPermaLink="false">2507.04047v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Mixed-Sample SGD: an End-to-end Analysis of Supervised Transfer Learning</title>
      <link>http://arxiv.org/abs/2507.04194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了监督迁移学习（STL）的理论工作，主要集中在统计方面，而对高效优化的研究较少。提出了一种基于随机梯度下降（SGD）的STL设计方法，该方法在源数据和目标数据之间交替采样，同时确保统计迁移保证，无需先验知识了解源数据质量。&lt;h4&gt;背景&lt;/h4&gt;监督迁移学习（STL）主要关注统计方面，高效优化研究较少。&lt;h4&gt;目的&lt;/h4&gt;设计一种SGD程序，在STL中交替采样源数据和目标数据，同时保证统计迁移保证，无需先验知识了解源数据质量。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自适应子采样机制，在每一步SGD中根据源数据的信噪比来调整采样策略，实现从源数据中获取信息或偏向目标数据避免负面迁移。&lt;h4&gt;主要发现&lt;/h4&gt;证明了这种混合样本的SGD程序在具有凸损失的通用预测任务中是可行的，这些任务基于跟踪一系列约束凸程序来维持所需的迁移保证。&lt;h4&gt;结论&lt;/h4&gt;在具体设置中，以线性回归和平方损失为例，证明了该方法收敛到目标数据上的统计性能，该性能对源数据质量的先验未知情况具有适应性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了监督迁移学习（STL）的理论工作，主要集中在统计方面，而对高效优化的研究较少。我们考虑了设计一个SGD程序来解决STL问题，该程序在源数据和目标数据之间交替采样，同时保持统计迁移保证，而不需要先验知识了解源数据的质量。算法上的主要困难是如何在每个SGD步骤中设计这样的自适应子采样机制，以便在源数据具有信息时从中受益，或者偏向目标数据以避免在源数据信息不足时发生负面迁移。我们表明，这种混合样本的SGD程序对于具有凸损失的通用预测任务是可行的，这些任务基于跟踪一系列约束凸程序，以维持所需的迁移保证。我们在线性回归和平方损失的具体设置中实例化了这些结果，并表明该程序以1/√T的速率收敛到目标数据上的一个解，该解的统计性能对源数据质量的先验未知情况具有适应性。使用合成数据和真实数据集的实验支持了这一理论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Theoretical works on supervised transfer learning (STL) -- where the learnerhas access to labeled samples from both source and target distributions -- havefor the most part focused on statistical aspects of the problem, whileefficient optimization has received less attention. We consider the problem ofdesigning an SGD procedure for STL that alternates sampling between source andtarget data, while maintaining statistical transfer guarantees without priorknowledge of the quality of the source data. A main algorithmic difficulty isin understanding how to design such an adaptive sub-sampling mechanism at eachSGD step, to automatically gain from the source when it is informative, or biastowards the target and avoid negative transfer when the source is lessinformative.  We show that, such a mixed-sample SGD procedure is feasible for generalprediction tasks with convex losses, rooted in tracking an abstract sequence ofconstrained convex programs that serve to maintain the desired transferguarantees.  We instantiate these results in the concrete setting of linear regressionwith square loss, and show that the procedure converges, with $1/\sqrt{T}$rate, to a solution whose statistical performance on the target is adaptive tothe a priori unknown quality of the source. Experiments with synthetic and realdatasets support the theory.</description>
      <author>example@mail.com (Yuyang Deng, Samory Kpotufe)</author>
      <guid isPermaLink="false">2507.04194v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Graph Collaborative Attention Network for Link Prediction in Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2507.03947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对基于规则的传统方法和现代深度学习方法在链接预测中的应用进行了系统比较，并介绍了GCAT模型，在四个广泛使用的基准数据集上的实验结果表明，GCAT在链接预测任务中优于传统方法和现有神经网络嵌入模型。&lt;h4&gt;背景&lt;/h4&gt;知识图谱为现实世界实体及其关系提供结构化表示，在信息检索和自动推理等领域有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;比较传统规则方法和现代深度学习方法在链接预测中的效果，并提出改进的模型GCAT。&lt;h4&gt;方法&lt;/h4&gt;研究KBGAT模型，该模型利用多头注意力机制联合编码局部邻域结构中的实体和关系特征，并引入GCAT模型以增强异构节点之间的上下文聚合和交互。&lt;h4&gt;主要发现&lt;/h4&gt;GCAT在链接预测任务中不仅优于传统方法，而且与现有神经网络嵌入模型相比也具有竞争力或更优的性能。&lt;h4&gt;结论&lt;/h4&gt;注意力机制架构在捕获知识图谱补全任务中的复杂关系模式方面具有优势。&lt;h4&gt;翻译&lt;/h4&gt;Knowledge graphs provide a structured representation of real-world entities and their relationships, enabling a wide range of applications from information retrieval to automated reasoning. In this paper, we conduct a systematic comparison between traditional rule-based approaches and modern deep learning methods for link prediction. We focus on KBGAT, a graph neural network model that leverages multi-head attention to jointly encode both entity and relation features within local neighborhood structures. To advance this line of research, we introduce GCAT (Graph Collaborative Attention Network), a refined model that enhances context aggregation and interaction between heterogeneous nodes. Experimental results on four widely-used benchmark datasets demonstrate that GCAT not only consistently outperforms rule-based methods but also achieves competitive or superior performance compared to existing neural embedding models. Our findings highlight the advantages of attention-based architectures in capturing complex relational patterns for knowledge graph completion tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs offer a structured representation of real-world entities andtheir relationships, enabling a wide range of applications from informationretrieval to automated reasoning. In this paper, we conduct a systematiccomparison between traditional rule-based approaches and modern deep learningmethods for link prediction. We focus on KBGAT, a graph neural network modelthat leverages multi-head attention to jointly encode both entity and relationfeatures within local neighborhood structures. To advance this line ofresearch, we introduce \textbf{GCAT} (Graph Collaborative Attention Network), arefined model that enhances context aggregation and interaction betweenheterogeneous nodes. Experimental results on four widely-used benchmarkdatasets demonstrate that GCAT not only consistently outperforms rule-basedmethods but also achieves competitive or superior performance compared toexisting neural embedding models. Our findings highlight the advantages ofattention-based architectures in capturing complex relational patterns forknowledge graph completion tasks.</description>
      <author>example@mail.com (Thanh Hoang-Minh)</author>
      <guid isPermaLink="false">2507.03947v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>When Data-Free Knowledge Distillation Meets Non-Transferable Teacher: Escaping Out-of-Distribution Trap is All You Need</title>
      <link>http://arxiv.org/abs/2507.04119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在不接触真实数据的情况下，如何通过Data-free knowledge distillation (DFKD)技术从可信教师模型向学生模型传递知识。针对DFKD在不受信任的教师模型中的鲁棒性和安全性问题，提出了Adversarial Trap Escaping (ATEsc)方法，以提升DFKD在处理非可迁移学习（NTL）教师模型时的性能。&lt;h4&gt;背景&lt;/h4&gt;DFKD通过生成器合成假数据来代替真实数据，从而在教师模型和学生模型之间传递知识。然而，现有研究通常假设教师模型是可信的，而未充分探索DFKD在不受信任的教师模型中的鲁棒性和安全性。&lt;h4&gt;目的&lt;/h4&gt;探究如何使用DFKD从NTL教师模型中提取知识，同时确保知识传递的鲁棒性和安全性。&lt;h4&gt;方法&lt;/h4&gt;提出Adversarial Trap Escaping (ATEsc)方法，通过识别和过滤出类似OOD（out-of-distribution）的合成样本，以提升DFKD的性能。该方法基于NTL教师模型在OOD样本上比在ID（in-distribution）样本上表现出更强的对抗鲁棒性的证据，将合成样本分为脆弱组和鲁棒组，分别用于正常知识蒸馏和遗忘OOD知识。&lt;h4&gt;主要发现&lt;/h4&gt;发现NTL教师模型会误导DFKD，将生成器的注意力从有用的ID知识转移到误导性的OOD知识上，从而阻碍ID知识传递并优先考虑OOD知识传递。&lt;h4&gt;结论&lt;/h4&gt;ATEsc方法有效提升了DFKD在处理NTL教师模型时的性能，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Data-free knowledge distillation (DFKD) transfers knowledge from a teacher to a student without access to the real in-distribution (ID) data. Its common solution is to use a generator to synthesize fake data and use them as a substitute for real ID data. However, existing works typically assume teachers are trustworthy, leaving the robustness and security of DFKD from untrusted teachers largely unexplored. In this work, we conduct the first investigation into distilling non-transferable learning (NTL) teachers using DFKD, where the transferability from an ID domain to an out-of-distribution (OOD) domain is prohibited. We find that NTL teachers fool DFKD through diverting the generator's attention from the useful ID knowledge to the misleading OOD knowledge. This hinders ID knowledge transfer but prioritizes OOD knowledge transfer. To mitigate this issue, we propose Adversarial Trap Escaping (ATEsc) to benefit DFKD by identifying and filtering out OOD-like synthetic samples. Specifically, inspired by the evidence that NTL teachers show stronger adversarial robustness on OOD samples than ID samples, we split synthetic samples into two groups according to their robustness. The fragile group is treated as ID-like data and used for normal knowledge distillation, while the robust group is seen as OOD-like data and utilized for forgetting OOD knowledge. Extensive experiments demonstrate the effectiveness of ATEsc for improving DFKD against NTL teachers. Code is released at https://github.com/tmllab/2025_ICML_ATEsc.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-free knowledge distillation (DFKD) transfers knowledge from a teacher toa student without access the real in-distribution (ID) data. Its commonsolution is to use a generator to synthesize fake data and use them as asubstitute for real ID data. However, existing works typically assume teachersare trustworthy, leaving the robustness and security of DFKD from untrustedteachers largely unexplored. In this work, we conduct the first investigationinto distilling non-transferable learning (NTL) teachers using DFKD, where thetransferability from an ID domain to an out-of-distribution (OOD) domain isprohibited. We find that NTL teachers fool DFKD through divert the generator'sattention from the useful ID knowledge to the misleading OOD knowledge. Thishinders ID knowledge transfer but prioritizes OOD knowledge transfer. Tomitigate this issue, we propose Adversarial Trap Escaping (ATEsc) to benefitDFKD by identifying and filtering out OOD-like synthetic samples. Specifically,inspired by the evidence that NTL teachers show stronger adversarial robustnesson OOD samples than ID samples, we split synthetic samples into two groupsaccording to their robustness. The fragile group is treated as ID-like data andused for normal knowledge distillation, while the robust group is seen asOOD-like data and utilized for forgetting OOD knowledge. Extensive experimentsdemonstrate the effectiveness of ATEsc for improving DFKD against NTL teachers.Code is released at https://github.com/tmllab/2025_ICML_ATEsc.</description>
      <author>example@mail.com (Ziming Hong, Runnan Chen, Zengmao Wang, Bo Han, Bo Du, Tongliang Liu)</author>
      <guid isPermaLink="false">2507.04119v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Text-Based Hierarchical Multilabel Classification for Mobile Applications via Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.04413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于移动应用（app）的分层标签系统，以改善用户建模并帮助下游业务整合其专有用户数据。&lt;h4&gt;背景&lt;/h4&gt;传统的应用分类方法存在局限性，无法捕捉应用细节功能。&lt;h4&gt;目的&lt;/h4&gt;通过使用文本信息如应用名称和描述，解决应用分层多标签分类问题。&lt;h4&gt;方法&lt;/h4&gt;1) 提出HMCN（分层多标签分类网络），从两个角度处理分类：一个角度是无层次约束的多标签分类，另一个角度是在每个层次上考虑约束顺序预测标签；2) 提出HMCL（分层多标签对比学习），以提高HMCN的性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，该方法在腾讯应用商店数据集和两个公开数据集上表现良好。该方法已在腾讯部署，应用的多标签分类输出帮助下游任务——用户信用风险管理——在Kolmogorov-Smirnov指标上提高了10.70%，持续超过一年。&lt;h4&gt;结论&lt;/h4&gt;分层多标签分类网络和对比学习方案能够有效提高移动应用分类的性能，并有助于提升用户信用风险管理的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A hierarchical labeling system for mobile applications (apps) benefits a widerange of downstream businesses that integrate the labeling with theirproprietary user data, to improve user modeling. Such a label hierarchy candefine more granular labels that capture detailed app features beyond thelimitations of traditional broad app categories. In this paper, we address theproblem of hierarchical multilabel classification for apps by using theirtextual information such as names and descriptions. We present: 1) HMCN(Hierarchical Multilabel Classification Network) for handling theclassification from two perspectives: the first focuses on a multilabelclassification without hierarchical constraints, while the second predictslabels sequentially at each hierarchical level considering such constraints; 2)HMCL (Hierarchical Multilabel Contrastive Learning), a scheme that is capableof learning more distinguishable app representations to enhance the performanceof HMCN. Empirical results on our Tencent App Store dataset and two publicdatasets demonstrate that our approach performs well compared withstate-of-the-art methods. The approach has been deployed at Tencent and themultilabel classification outputs for apps have helped a downstreamtask--credit risk management of user--improve its performance by 10.70% withregard to the Kolmogorov-Smirnov metric, for over one year.</description>
      <author>example@mail.com (Jiawei Guo, Yang Xiao, Weipeng Huang, Guangyuan Piao)</author>
      <guid isPermaLink="false">2507.04413v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Tractable Representation Learning with Probabilistic Circuits</title>
      <link>http://arxiv.org/abs/2507.04385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为自动编码概率电路（APCs）的新框架，用于概率推理和推理任务中的表示学习。APCs通过联合建模数据和嵌入，通过可处理的概率推理获得嵌入表示，展现出在重建质量、嵌入生成和缺失数据处理方面的优越性。&lt;h4&gt;背景&lt;/h4&gt;概率电路（PCs）是一种强大的概率模型，在神经网络中占主导地位，但其表示学习尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;解决概率电路在表示学习方面的不足，提出一种新的方法来建模概率嵌入。&lt;h4&gt;方法&lt;/h4&gt;引入了自动编码概率电路（APCs），它通过联合建模数据和嵌入来获得嵌入表示。PC编码器允许框架原生地处理任意缺失数据，并与神经网络解码器无缝集成，形成一种混合的端到端可训练架构。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，APCs在重建质量方面优于现有的基于PC的自动编码方法，生成的嵌入与神经自动编码器相当，并且在处理缺失数据方面表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;APCs是一种强大且灵活的表示学习方法，它利用了概率电路的概率推理能力，为鲁棒推理、异常检测和知识蒸馏等领域提供了有希望的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：概率电路（PCs）是一种强大的概率模型，它使精确和可处理推理成为可能，使它们非常适合进行概率推理和推理任务。尽管在神经网络中占主导地位，但使用PCs进行表示学习仍然没有得到充分探索，先前的方法依赖于外部神经网络嵌入或基于激活的编码。为了填补这一空白，我们引入了自动编码概率电路（APCs），这是一个新颖的框架，它利用PCs的可处理性来显式地建模概率嵌入。APCs通过联合建模数据和嵌入来扩展PCs，通过可处理的概率推理获得嵌入表示。PC编码器允许框架原生地处理任意缺失数据，并与神经网络解码器无缝集成，形成一个由可微分采样支持的混合端到端可训练架构。我们的实证评估表明，APCs在重建质量方面优于现有的基于PC的自动编码方法，生成的嵌入与神经自动编码器相竞争，并且在处理缺失数据方面比神经自动编码器表现出更强的鲁棒性。这些结果突出了APCs作为一种强大的和灵活的表示学习方法，它利用了PCs的概率推理能力，展示了在鲁棒推理、异常检测和知识蒸馏等方面的有希望的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic circuits (PCs) are powerful probabilistic models that enableexact and tractable inference, making them highly suitable for probabilisticreasoning and inference tasks. While dominant in neural networks,representation learning with PCs remains underexplored, with prior approachesrelying on external neural embeddings or activation-based encodings. To addressthis gap, we introduce autoencoding probabilistic circuits (APCs), a novelframework leveraging the tractability of PCs to model probabilistic embeddingsexplicitly. APCs extend PCs by jointly modeling data and embeddings, obtainingembedding representations through tractable probabilistic inference. The PCencoder allows the framework to natively handle arbitrary missing data and isseamlessly integrated with a neural decoder in a hybrid, end-to-end trainablearchitecture enabled by differentiable sampling. Our empirical evaluationdemonstrates that APCs outperform existing PC-based autoencoding methods inreconstruction quality, generate embeddings competitive with, and exhibitsuperior robustness in handling missing data compared to neural autoencoders.These results highlight APCs as a powerful and flexible representation learningmethod that exploits the probabilistic inference capabilities of PCs, showingpromising directions for robust inference, out-of-distribution detection, andknowledge distillation.</description>
      <author>example@mail.com (Steven Braun, Sahil Sidheekh, Antonio Vergari, Martin Mundt, Sriraam Natarajan, Kristian Kersting)</author>
      <guid isPermaLink="false">2507.04385v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>2.5D Object Detection for Intelligent Roadside Infrastructure</title>
      <link>http://arxiv.org/abs/2507.03564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at 2025 IEEE 28th International Conference on Intelligent  Transportation Systems (ITSC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对基础设施路边摄像头的2.5D目标检测框架，用于解决自动驾驶车辆在复杂环境下的感知问题。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶车辆的车载传感器可能受到遮挡或视野限制，影响驾驶决策。传统的3D目标检测算法在处理顶部视角和陡峭的相机角度时难以泛化。&lt;h4&gt;目的&lt;/h4&gt;开发一种适用于基础设施路边摄像头的2.5D目标检测框架，以提供对自动驾驶车辆的有用信息。&lt;h4&gt;方法&lt;/h4&gt;提出了一种预测方法，将车辆在图像帧中的地面平面检测为平行四边形，以保留物体的平面位置、大小和方向，同时忽略高度。利用真实世界和合成场景进行训练，并在训练集之外的视角和恶劣天气条件下评估泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在检测精度、跨视角泛化能力和对多样光照和天气条件下的鲁棒性方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;该2.5D目标检测框架能够有效提高自动驾驶车辆在复杂环境下的感知能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动驾驶汽车的车载传感器可能会受到遮挡、遮挡或视野限制，这会复杂化下游的驾驶决策。安装在 elevated 优势点的智能路边基础设施感知系统可以提供广泛的、无遮挡的交叉覆盖，通过车辆到一切（V2X）通信为自动驾驶车辆提供补充信息流。然而，传统的3D目标检测算法在顶部视角和陡峭的相机角度引入的领域迁移下难以泛化。我们介绍了一种针对基础设施路边摄像头的2.5D目标检测框架。与传统的2D或3D目标检测不同，我们采用了一种预测方法，将车辆在图像帧中的地面平面检测为平行四边形。平行四边形保留了物体的平面位置、大小和方向，同时忽略了高度，这在大多数下游应用中是不必要的。为了训练，利用了真实世界和合成场景的组合。我们在训练集之外的视角和不在训练集中的恶劣天气场景下评估了泛化能力。我们的结果表明，检测精度高，跨视角泛化能力强，对多样光照和天气条件具有鲁棒性。模型权重和推理代码可在以下链接找到：https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; On-board sensors of autonomous vehicles can be obstructed, occluded, orlimited by restricted fields of view, complicating downstream drivingdecisions. Intelligent roadside infrastructure perception systems, installed atelevated vantage points, can provide wide, unobstructed intersection coverage,supplying a complementary information stream to autonomous vehicles viavehicle-to-everything (V2X) communication. However, conventional 3Dobject-detection algorithms struggle to generalize under the domain shiftintroduced by top-down perspectives and steep camera angles. We introduce a2.5D object detection framework, tailored specifically for infrastructureroadside-mounted cameras. Unlike conventional 2D or 3D object detection, weemploy a prediction approach to detect ground planes of vehicles asparallelograms in the image frame. The parallelogram preserves the planarposition, size, and orientation of objects while omitting their height, whichis unnecessary for most downstream applications. For training, a mix ofreal-world and synthetically generated scenes is leveraged. We evaluategeneralizability on a held-out camera viewpoint and in adverse-weatherscenarios absent from the training set. Our results show high detectionaccuracy, strong cross-viewpoint generalization, and robustness to diverselighting and weather conditions. Model weights and inference code are providedat: https://gitlab.kit.edu/kit/aifb/ATKS/public/digit4taf/2.5d-object-detection</description>
      <author>example@mail.com (Nikolai Polley, Yacin Boualili, Ferdinand Mütsch, Maximilian Zipfl, Tobias Fleck, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2507.03564v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Attention-Guided Multi-Scale Local Reconstruction for Point Clouds via Masked Autoencoder Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2507.04084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PointAMaLR的新的自监督学习框架，用于点云处理，通过注意力引导的多尺度局部重建来增强特征表示和处理精度。&lt;h4&gt;背景&lt;/h4&gt;现有模型主要关注更高编码层的重建任务，而忽略了低级局部特征的有效利用。&lt;h4&gt;目的&lt;/h4&gt;为了克服这一局限性，PointAMaLR旨在通过改进特征表示和提升处理精度，实现更有效的点云处理。&lt;h4&gt;方法&lt;/h4&gt;PointAMaLR通过在多个局部区域实现分层重建，底层关注精细尺度特征恢复，上层处理粗尺度特征重建，并通过嵌入层中的局部注意力模块（LA）增强语义特征理解。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集ModelNet和ShapeNet上的实验表明，PointAMaLR在分类和重建任务中均表现出优异的准确性和质量。在ScanObjectNN和S3DIS等真实世界数据集上的评估也显示出高度竞争力的性能指标。&lt;h4&gt;结论&lt;/h4&gt;PointAMaLR在多尺度语义理解方面表现出有效性，并在实际场景中具有实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a prominent research direction inpoint cloud processing. While existing models predominantly concentrate onreconstruction tasks at higher encoder layers, they often neglect the effectiveutilization of low-level local features, which are typically employed solelyfor activation computations rather than directly contributing to reconstructiontasks. To overcome this limitation, we introduce PointAMaLR, a novelself-supervised learning framework that enhances feature representation andprocessing accuracy through attention-guided multi-scale local reconstruction.PointAMaLR implements hierarchical reconstruction across multiple localregions, with lower layers focusing on fine-scale feature restoration whileupper layers address coarse-scale feature reconstruction, thereby enablingcomplex inter-patch interactions. Furthermore, to augment featurerepresentation capabilities, we incorporate a Local Attention (LA) module inthe embedding layer to enhance semantic feature understanding. Comprehensiveexperiments on benchmark datasets ModelNet and ShapeNet demonstratePointAMaLR's superior accuracy and quality in both classification andreconstruction tasks. Moreover, when evaluated on the real-world datasetScanObjectNN and the 3D large scene segmentation dataset S3DIS, our modelachieves highly competitive performance metrics. These results not onlyvalidate PointAMaLR's effectiveness in multi-scale semantic understanding butalso underscore its practical applicability in real-world scenarios.</description>
      <author>example@mail.com (Xin Cao, Haoyu Wang, Yuzhu Mao, Xinda Liu, Linzhi Su, Kang Li)</author>
      <guid isPermaLink="false">2507.04084v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Geometric-Guided Few-Shot Dental Landmark Detection with Human-Centric Foundation Model</title>
      <link>http://arxiv.org/abs/2507.04710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoSapiens是一种新型的少量样本学习框架，用于通过有限的标注CBCT图像进行稳健的牙齿解剖标志物检测。&lt;h4&gt;背景&lt;/h4&gt;准确的解剖标志物检测对于评估肺泡骨和根条件至关重要，对于正畸学、牙周病学和种植牙科的临床结果优化至关重要。&lt;h4&gt;目的&lt;/h4&gt;克服传统深度学习技术在牙齿解剖标志物检测中的数据稀缺和专家标注成本高昂的挑战。&lt;h4&gt;方法&lt;/h4&gt;GeoSapiens框架包括：（1）从Sapiens模型（在以人为中心的视觉任务中达到最先进性能的基础模型）中改编的稳健基线；（2）一种新的几何损失函数，该函数提高了模型捕捉解剖结构之间关键几何关系的容量。&lt;h4&gt;主要发现&lt;/h4&gt;在收集的前牙标志物数据集上进行的实验表明，GeoSapiens在严格0.5毫米阈值下比现有的标志物检测方法表现更优，成功检测率高出8.18%。&lt;h4&gt;结论&lt;/h4&gt;GeoSapiens框架在牙齿解剖标志物检测方面取得了显著成果，为临床应用提供了高效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;Accurate detection of anatomic landmarks is essential for assessing alveolar bone and root conditions, thereby optimizing clinical outcomes in orthodontics, periodontics, and implant dentistry. Manual annotation of landmarks on cone-beam computed tomography (CBCT) by dentists is time-consuming, labor-intensive, and subject to inter-observer variability. Deep learning-based automated methods present a promising approach to streamline this process efficiently. However, the scarcity of training data and the high cost of expert annotations hinder the adoption of conventional deep learning techniques. To overcome these challenges, we introduce GeoSapiens, a novel few-shot learning framework designed for robust dental landmark detection using limited annotated CBCT of anterior teeth. Our GeoSapiens framework comprises two key components: (1) a robust baseline adapted from Sapiens, a foundational model that has achieved state-of-the-art performance in human-centric vision tasks, and (2) a novel geometric loss function that improves the model's capacity to capture critical geometric relationships among anatomical structures. Experiments conducted on our collected dataset of anterior teeth landmarks revealed that GeoSapiens surpassed existing landmark detection methods, outperforming the leading approach by an 8.18% higher success detection rate at a strict 0.5 mm threshold-a standard widely recognized in dental diagnostics. Code is available at: https://github.com/xmed-lab/GeoSapiens.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate detection of anatomic landmarks is essential for assessing alveolarbone and root conditions, thereby optimizing clinical outcomes in orthodontics,periodontics, and implant dentistry. Manual annotation of landmarks oncone-beam computed tomography (CBCT) by dentists is time-consuming,labor-intensive, and subject to inter-observer variability. Deep learning-basedautomated methods present a promising approach to streamline this processefficiently. However, the scarcity of training data and the high cost of expertannotations hinder the adoption of conventional deep learning techniques. Toovercome these challenges, we introduce GeoSapiens, a novel few-shot learningframework designed for robust dental landmark detection using limited annotatedCBCT of anterior teeth. Our GeoSapiens framework comprises two key components:(1) a robust baseline adapted from Sapiens, a foundational model that hasachieved state-of-the-art performance in human-centric vision tasks, and (2) anovel geometric loss function that improves the model's capacity to capturecritical geometric relationships among anatomical structures. Experimentsconducted on our collected dataset of anterior teeth landmarks revealed thatGeoSapiens surpassed existing landmark detection methods, outperforming theleading approach by an 8.18% higher success detection rate at a strict 0.5 mmthreshold-a standard widely recognized in dental diagnostics. Code is availableat: https://github.com/xmed-lab/GeoSapiens.</description>
      <author>example@mail.com (Anbang Wang, Marawan Elbatel, Keyuan Liu, Lizhuo Lin, Meng Lan, Yanqi Yang, Xiaomeng Li)</author>
      <guid isPermaLink="false">2507.04710v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>M$^3$-Med: A Benchmark for Multi-lingual, Multi-modal, and Multi-hop Reasoning in Medical Instructional Video Understanding</title>
      <link>http://arxiv.org/abs/2507.04289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了M3-Med，一个针对医疗教育视频理解的跨语言、跨模态和多跳推理基准。&lt;h4&gt;背景&lt;/h4&gt;随着人工智能在多模态理解方面的快速进步，视频理解技术在支持专业领域如医疗教育方面具有巨大潜力。然而，现有的基准存在两个主要局限性：语言单一性和浅层推理。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出M3-Med，旨在提供一个全面的基准来评估医疗教育视频理解中的多语言、跨模态和多跳推理能力。&lt;h4&gt;方法&lt;/h4&gt;M3-Med由医学问题及其对应的视频片段组成，由医疗专家团队进行标注。其创新之处在于多跳推理任务，要求模型首先在文本中定位关键实体，然后在视频中找到相应的视觉证据，最后综合两种模态的信息来得出答案。&lt;h4&gt;主要发现&lt;/h4&gt;评估了多个最先进的模型和大型语言模型在M3-Med上的表现，结果显示模型与人类专家之间存在显著的性能差距，特别是在复杂的多跳问题上，模型性能急剧下降。&lt;h4&gt;结论&lt;/h4&gt;M3-Med有效地突出了当前人工智能模型在专业领域深层次跨模态推理中的局限性，并为未来的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要翻译：With the rapid progress of artificial intelligence (AI) in multi-modal understanding, there is increasing potential for video comprehension technologies to support professional domains such as medical education. However, existing benchmarks suffer from two primary limitations: (1) Linguistic Singularity: they are largely confined to English, neglecting the need for multilingual resources; and (2) Shallow Reasoning: their questions are often designed for surface-level information retrieval, failing to properly assess deep multi-modal integration. To address these limitations, we present M3-Med, the first benchmark for Multi-lingual, Multi-modal, and Multi-hop reasoning in Medical instructional video understanding. M3-Med consists of medical questions paired with corresponding video segments, annotated by a team of medical experts. A key innovation of M3-Med is its multi-hop reasoning task, which requires a model to first locate a key entity in the text, then find corresponding visual evidence in the video, and finally synthesize information across both modalities to derive the answer. This design moves beyond simple text matching and poses a substantial challenge to a model's deep cross-modal understanding capabilities. We define two tasks: Temporal Answer Grounding in Single Video (TAGSV) and Temporal Answer Grounding in Video Corpus (TAGVC). We evaluated several state-of-the-art models and Large Language Models (LLMs) on M3-Med. The results reveal a significant performance gap between all models and human experts, especially on the complex multi-hop questions where model performance drops sharply. M3-Med effectively highlights the current limitations of AI models in deep cross-modal reasoning within specialized domains and provides a new direction for future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid progress of artificial intelligence (AI) in multi-modalunderstanding, there is increasing potential for video comprehensiontechnologies to support professional domains such as medical education.However, existing benchmarks suffer from two primary limitations: (1)Linguistic Singularity: they are largely confined to English, neglecting theneed for multilingual resources; and (2) Shallow Reasoning: their questions areoften designed for surface-level information retrieval, failing to properlyassess deep multi-modal integration. To address these limitations, we presentM3-Med, the first benchmark for Multi-lingual, Multi-modal, and Multi-hopreasoning in Medical instructional video understanding. M3-Med consists ofmedical questions paired with corresponding video segments, annotated by a teamof medical experts. A key innovation of M3-Med is its multi-hop reasoning task,which requires a model to first locate a key entity in the text, then findcorresponding visual evidence in the video, and finally synthesize informationacross both modalities to derive the answer. This design moves beyond simpletext matching and poses a substantial challenge to a model's deep cross-modalunderstanding capabilities. We define two tasks: Temporal Answer Grounding inSingle Video (TAGSV) and Temporal Answer Grounding in Video Corpus (TAGVC). Weevaluated several state-of-the-art models and Large Language Models (LLMs) onM3-Med. The results reveal a significant performance gap between all models andhuman experts, especially on the complex multi-hop questions where modelperformance drops sharply. M3-Med effectively highlights the currentlimitations of AI models in deep cross-modal reasoning within specializeddomains and provides a new direction for future research.</description>
      <author>example@mail.com (Shenxi Liu, Kan Li, Mingyang Zhao, Yuhang Tian, Bin Li, Shoujun Zhou, Hongliang Li, Fuxia Yang)</author>
      <guid isPermaLink="false">2507.04289v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Habitat Classification from Ground-Level Imagery Using Deep Neural Networks</title>
      <link>http://arxiv.org/abs/2507.04017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 12 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过应用最先进的深度神经网络架构处理地面影像，以自动化和改进栖息地评估过程，从而提高生物多样性和指导保护优先事项。&lt;h4&gt;背景&lt;/h4&gt;传统的栖息地评估依赖于昂贵的专家实地调查，而人工智能驱动的工具能够自动化这一过程。然而，大多数基于人工智能的栖息地制图依赖于遥感，但受到传感器可用性、天气和粗分辨率等限制。&lt;h4&gt;目的&lt;/h4&gt;利用地面影像进行稳健的精细栖息地分类，并评估两种模型——卷积神经网络（CNNs）和视觉Transformer（ViTs）——在监督和监督对比学习范式下的表现。&lt;h4&gt;方法&lt;/h4&gt;研究使用了英国乡村调查的数据，涵盖了18种广泛的栖息地类型，并评估了CNNs和ViTs在监督和监督对比学习范式下的性能。&lt;h4&gt;主要发现&lt;/h4&gt;ViTs在关键分类指标上（如Top-3准确率=91%，MCC=0.66）持续优于最先进的CNN基线，并提供了针对地面图像的更可解释的场景理解。监督对比学习显著降低了视觉相似栖息地（如改善与中性草地）之间的误分类率，得益于更具判别性的嵌入空间。最佳模型在图像栖息地分类方面的表现与经验丰富的生态专家相当。&lt;h4&gt;结论&lt;/h4&gt;通过将高级人工智能与生态专业知识相结合，该研究建立了一个可扩展、成本效益高的地面栖息地监测框架，以加速生物多样性保护和为国家规模的土地利用决策提供信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Habitat assessment at local scales -- critical for enhancing biodiversity andguiding conservation priorities -- often relies on expert field survey that canbe costly, motivating the exploration of AI-driven tools to automate and refinethis process. While most AI-driven habitat mapping depends on remote sensing,it is often constrained by sensor availability, weather, and coarse resolution.In contrast, ground-level imagery captures essential structural andcompositional cues invisible from above and remains underexplored for robust,fine-grained habitat classification. This study addresses this gap by applyingstate-of-the-art deep neural network architectures to ground-level habitatimagery. Leveraging data from the UK Countryside Survey covering 18 broadhabitat types, we evaluate two families of models -- convolutional neuralnetworks (CNNs) and vision transformers (ViTs) -- under both supervised andsupervised contrastive learning paradigms. Our results demonstrate that ViTsconsistently outperform state-of-the-art CNN baselines on key classificationmetrics (Top-3 accuracy = 91\%, MCC = 0.66) and offer more interpretable sceneunderstanding tailored to ground-level images. Moreover, supervised contrastivelearning significantly reduces misclassification rates among visually similarhabitats (e.g., Improved vs. Neutral Grassland), driven by a morediscriminative embedding space. Finally, our best model performs on par withexperienced ecological experts in habitat classification from images,underscoring the promise of expert-level automated assessment. By integratingadvanced AI with ecological expertise, this research establishes a scalable,cost-effective framework for ground-level habitat monitoring to acceleratebiodiversity conservation and inform land-use decisions at the national scale.</description>
      <author>example@mail.com (Hongrui Shi, Lisa Norton, Lucy Ridding, Simon Rolph, Tom August, Claire M Wood, Lan Qie, Petra Bosilj, James M Brown)</author>
      <guid isPermaLink="false">2507.04017v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2507.04631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了SMoEStereo，一种新的立体匹配框架，通过融合低秩适应（LoRA）和混合专家（MoE）模块来增强立体匹配模型的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于学习的立体匹配网络在鲁棒性和跨域性能方面存在不足，主要由于领域差异和不同数据集之间的视差分布不均衡。&lt;h4&gt;目的&lt;/h4&gt;提高立体匹配模型的鲁棒性，使其能够更有效地适应不同领域的场景。&lt;h4&gt;方法&lt;/h4&gt;SMoEStereo通过以下方法实现：1. 使用MoE-LoRA动态选择MoE中的最佳专家以适应不同场景；2. 使用MoE-Adapter向冻结的视觉基础模型（VFMs）注入归纳偏差，以改进几何特征提取；3. 提出轻量级决策网络，根据输入复杂度选择性地激活MoE模块，平衡效率和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;SMoEStereo在多个基准测试中展现出最先进的跨域和联合泛化性能，无需针对特定数据集进行适配。&lt;h4&gt;结论&lt;/h4&gt;SMoEStereo是一种有效的立体匹配框架，能够显著提高模型的鲁棒性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;最近，基于学习的立体匹配网络取得了显著进展。然而，由于领域差异和不同数据集之间视差分布的不均衡，它们通常缺乏鲁棒性，难以实现令人印象深刻的跨域性能。利用视觉基础模型（VFMs）可以直观地增强模型的鲁棒性，但将此类模型高效地集成到立体匹配中以充分发挥其鲁棒性仍然是一个关键挑战。为了解决这个问题，我们提出了SMoEStereo，一个新颖的框架，通过定制化的场景特定融合低秩适应（LoRA）和混合专家（MoE）模块来适应立体匹配。SMoEStereo引入了具有自适应秩的MoE-LoRA和具有自适应核大小的MoE-Adapter。前者动态选择MoE中的最佳专家以适应跨域中的不同场景，而后者向冻结的视觉基础模型注入归纳偏差以改进几何特征提取。重要的是，为了减轻计算开销，我们进一步提出了一种轻量级决策网络，根据输入复杂度选择性地激活MoE模块，平衡效率和准确性。广泛的实验表明，我们的方法在多个基准测试中显示出最先进的跨域和联合泛化性能，无需针对特定数据集进行适配。代码可在https://github.com/cocowy1/SMoE-Stereo上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, learning-based stereo matching networks have advancedsignificantly. However, they often lack robustness and struggle to achieveimpressive cross-domain performance due to domain shifts and imbalanceddisparity distributions among diverse datasets. Leveraging Vision FoundationModels (VFMs) can intuitively enhance the model's robustness, but integratingsuch a model into stereo matching cost-effectively to fully realize theirrobustness remains a key challenge. To address this, we propose SMoEStereo, anovel framework that adapts VFMs for stereo matching through a tailored,scene-specific fusion of Low-Rank Adaptation (LoRA) and Mixture-of-Experts(MoE) modules. SMoEStereo introduces MoE-LoRA with adaptive ranks andMoE-Adapter with adaptive kernel sizes. The former dynamically selects optimalexperts within MoE to adapt varying scenes across domains, while the latterinjects inductive bias into frozen VFMs to improve geometric featureextraction. Importantly, to mitigate computational overhead, we further proposea lightweight decision network that selectively activates MoE modules based oninput complexity, balancing efficiency with accuracy. Extensive experimentsdemonstrate that our method exhibits state-of-the-art cross-domain and jointgeneralization across multiple benchmarks without dataset-specific adaptation.The code is available at\textcolor{red}{https://github.com/cocowy1/SMoE-Stereo}.</description>
      <author>example@mail.com (Yun Wang, Longguang Wang, Chenghao Zhang, Yongjian Zhang, Zhanjie Zhang, Ao Ma, Chenyou Fan, Tin Lun Lam, Junjie Hu)</author>
      <guid isPermaLink="false">2507.04631v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Radar Velocity Transformer: Single-scan Moving Object Segmentation in Noisy Radar Point Clouds</title>
      <link>http://arxiv.org/abs/2507.03463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proc. of the IEEE Intl. Conf. on Robotics &amp; Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于雷达数据的新型变换器方法，用于在噪声雷达点云中实现移动对象分割，并通过单次扫描准确地识别移动和非移动对象。&lt;h4&gt;背景&lt;/h4&gt;自动驾驶汽车的安全和可靠导航需要对其周围移动物体的意识。LiDAR和相机数据可以提供良好的结果，但通常需要累积和处理时间序列数据来提取运动信息。相比之下，雷达传感器可以直接提供检测到的多普勒速度，从而在一次测量中包含瞬时的运动信息。&lt;h4&gt;目的&lt;/h4&gt;解决在噪声雷达点云中移动对象分割的问题，并区分静止和移动的汽车，以增强场景理解。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于变换器的新方法，不依赖于时间依赖性来识别移动对象，而是通过在网络的每个模块中整合有用的速度信息，从而实现移动和非移动对象的精确分割。此外，还提出了一种基于变换器的上采样方法，通过自适应地结合信息来克服稀疏点云插值的限制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在RadarScenes数据集上创建了一个新的雷达移动对象分割基准，并与其他最先进的方法进行了比较。网络运行速度超过传感器的帧率，并且仅使用单次雷达数据就展示了优越的分割结果。&lt;h4&gt;结论&lt;/h4&gt;该方法通过单次雷达扫描实现了快速且准确的移动对象分割，为自动驾驶汽车的安全导航提供了新的技术支持。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a novel transformer-based method for moving object segmentation in noisy radar point clouds, achieving accurate segmentation of moving and non-moving objects through single-scan radar data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICRA48891.2023.10161152&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The awareness about moving objects in the surroundings of a self-drivingvehicle is essential for safe and reliable autonomous navigation. Theinterpretation of LiDAR and camera data achieves exceptional results buttypically requires to accumulate and process temporal sequences of data inorder to extract motion information. In contrast, radar sensors, which arealready installed in most recent vehicles, can overcome this limitation as theydirectly provide the Doppler velocity of the detections and, hence incorporateinstantaneous motion information within a single measurement. % In this paper,we tackle the problem of moving object segmentation in noisy radar pointclouds. We also consider differentiating parked from moving cars, to enhancescene understanding. Instead of exploiting temporal dependencies to identifymoving objects, we develop a novel transformer-based approach to performsingle-scan moving object segmentation in sparse radar scans accurately. Thekey to our Radar Velocity Transformer is to incorporate the valuable velocityinformation throughout each module of the network, thereby enabling the precisesegmentation of moving and non-moving objects. Additionally, we propose atransformer-based upsampling, which enhances the performance by adaptivelycombining information and overcoming the limitation of interpolation of sparsepoint clouds. Finally, we create a new radar moving object segmentationbenchmark based on the RadarScenes dataset and compare our approach to otherstate-of-the-art methods. Our network runs faster than the frame rate of thesensor and shows superior segmentation results using only single-scan radardata.</description>
      <author>example@mail.com (Matthias Zeller, Vardeep S. Sandhu, Benedikt Mersch, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2507.03463v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Combining Graph Neural Networks and Mixed Integer Linear Programming for Molecular Inference under the Two-Layered Model</title>
      <link>http://arxiv.org/abs/2507.03920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2107.02381,  arXiv:2109.02628&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为mol-infer的新型两阶段框架，用于推断具有指定抽象结构和所需性质属性的化学化合物。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常首先将化学化合物转换为手工特征向量来构建预测函数，但受限于MILP公式的可处理性需求，这些方法的性能在某些性质的数据集上并不理想。&lt;h4&gt;目的&lt;/h4&gt;提高学习性能，以提升推断化学图的质量，并开发一种新的分子推断框架。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于mol-infer的分子推断框架mol-infer-GNN，该框架使用图神经网络(GNN)作为学习方法，同时保持对化学图抽象结构的两层模型的高灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;在QM9数据集上进行的计算实验表明，所提出的GNN模型尽管结构简单，但仍能获得令人满意的某些性质的学习性能，并且能在合理的计算时间内推断出包含多达20个非氢原子的小型化学图。&lt;h4&gt;结论&lt;/h4&gt;mol-infer-GNN框架能够有效地推断化学化合物，并可能优于基于特征向量的传统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, a novel two-phase framework named mol-infer for inference ofchemical compounds with prescribed abstract structures and desired propertyvalues has been proposed. The framework mol-infer is primarily based on usingmixed integer linear programming (MILP) to simulate the computational processof machine learning methods and describe the necessary and sufficientconditions to ensure such a chemical graph exists. The existing approachesusually first convert the chemical compounds into handcrafted feature vectorsto construct prediction functions, but because of the limit on the kinds ofdescriptors originated from the need for tractability in the MILP formulation,the learning performances on datasets of some properties are not good enough. Alack of good learning performance can greatly lower the quality of the inferredchemical graphs, and thus improving learning performance is of greatimportance. On the other hand, graph neural networks (GNN) offer a promisingmachine learning method to directly utilize the chemical graphs as the input,and many existing GNN-based approaches to the molecular property predictionproblem have shown that they can enjoy better learning performances compared tothe traditional approaches that are based on feature vectors. In this study, wedevelop a molecular inference framework based on mol-infer, namelymol-infer-GNN, that utilizes GNN as the learning method while keeping the greatflexibility originated from the two-layered model on the abstract structure ofthe chemical graph to be inferred. We conducted computational experiments onthe QM9 dataset to show that our proposed GNN model can obtain satisfyinglearning performances for some properties despite its simple structure, and caninfer small chemical graphs comprising up to 20 non-hydrogen atoms withinreasonable computational time.</description>
      <author>example@mail.com (Jianshen Zhu, Naveed Ahmed Azam, Kazuya Haraguchi, Liang Zhao, Tatsuya Akutsu)</author>
      <guid isPermaLink="false">2507.03920v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences</title>
      <link>http://arxiv.org/abs/2507.04621v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MLLM-SC的新型多模态大型语言模型集成语义通信框架，旨在解决6G网络在资源受限的无线通信系统中实现高维多模态数据传输和智能数据处理的挑战。&lt;h4&gt;背景&lt;/h4&gt;6G网络将带来革命性的沉浸式通信体验，如增强现实（AR）、虚拟现实（VR）和全息通信，这些应用需要实时处理高维多模态数据。&lt;h4&gt;目的&lt;/h4&gt;提供一种能够有效进行环境、上下文和用户意图理解的通信框架，以实现任务相关的有效内容传递。&lt;h4&gt;方法&lt;/h4&gt;MLLM-SC框架采用设备边缘协作架构，边缘的MLLM语义引导模块分析多模态输入、用户意图和信道条件，生成优先级排序的重要性感知注意力图。同时，设计并优化了重要性感知语义编码器和资源自适应语义解码器，以实现自适应带宽分配和高质量内容重建或生成。&lt;h4&gt;主要发现&lt;/h4&gt;通过视觉问答在AR/VR应用中的案例研究和扩散驱动的图像生成，验证了MLLM-SC框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;MLLM-SC框架能够有效解决6G网络在资源受限无线通信系统中的挑战，为沉浸式通信体验提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：6G网络承诺带来革命性的沉浸式通信体验，包括增强现实（AR）、虚拟现实（VR）和全息通信。这些应用需要高维多模态数据传输和实时智能数据处理，这在资源有限的无线通信系统中极具挑战性。此外，对环境、上下文和用户意图的联合理解对于有效传递任务相关内容至关重要。本文提出了一种新型的多模态大型语言模型（MLLM）集成语义通信框架，称为MLLM-SC，该框架充分利用了预训练基础模型的推理和生成能力，以实现上下文感知和任务导向的无线通信。MLLM-SC框架采用设备边缘协作架构。在边缘，MLLM赋能的语义引导模块分析多模态输入、用户意图和信道条件，生成优先级排序的重要性感知注意力图。同时，设计并优化了重要性感知语义编码器和资源自适应语义解码器，以实现自适应带宽分配和高质量内容重建或生成。通过视觉问答在AR/VR应用中的案例研究和扩散驱动的图像生成，验证了MLLM-SC框架的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6G networks promise revolutionary immersive communication experiencesincluding augmented reality (AR), virtual reality (VR), and holographiccommunications. These applications demand high-dimensional multimodal datatransmission and intelligent data processing in real-time, which is extremelychallenging over resource-limited wireless communication systems. Moreover, ajoint understanding of the environment, context, and user intent is essentialto deliver task-relevant content effectively. This article presents a novelmultimodal large language model (MLLM) integrated semantic communicationsframework, termed MLLM-SC, which fully leverages reasoning and generativecapabilities of pre-trained foundation models for context-aware andtask-oriented wireless communication. The MLLM-SC framework adopts adevice-edge collaborative architecture. At the edge, MLLM-empowered semanticguidance module analyzes multimodal inputs, user intents, and channelconditions to generate importance-aware attention maps prioritizingsemantically critical information. An importance-aware semantic encoder and aresource-adaptive semantic decoder are jointly designed and optimized, whichcan utilize the semantic guidance for adaptive bandwidth allocation andhigh-quality content reconstruction or generation. Extensive case studies onvisual question answering for AR/VR applications and diffusion-driven imagegeneration validate the effectiveness of MLLM-SC.</description>
      <author>example@mail.com (Yusong Zhang, Yuxuan Sun, Lei Guo, Wei Chen, Bo Ai, Deniz Gunduz)</author>
      <guid isPermaLink="false">2507.04621v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Generate, Refine, and Encode: Leveraging Synthesized Novel Samples for On-the-Fly Fine-Grained Category Discovery</title>
      <link>http://arxiv.org/abs/2507.04051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在线分类发现（OCD）这一既实用又具有挑战性的任务，提出了一种基于扩散的OCD框架DiffGRE，通过多阶段整合生成、精炼和编码来提升分类效果。&lt;h4&gt;背景&lt;/h4&gt;现有的OCD方法致力于从仅有的标注数据中挖掘可迁移的知识，但这些方法的迁移性有限，尤其是在细粒度识别中标注数据/类别较少时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的OCD框架，以缓解现有方法在知识迁移性方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;DiffGRE框架通过以下步骤实现：1. 基于扩散潜在空间中的跨图像插值设计属性组合生成方法，以合成新样本；2. 提出一种多样性驱动的精炼方法，选择与已知类别不同的合成图像进行后续OCD模型训练；3. 利用半监督的领导者编码，将合成数据中包含的额外类别知识注入到OCD模型中。&lt;h4&gt;主要发现&lt;/h4&gt;DiffGRE在六个细粒度数据集上的实验表明，其性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;DiffGRE框架在OCD任务上提供了优越的性能，有助于发现已知和未知类别。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we investigate a practical yet challenging task: On-the-fly Category Discovery (OCD). This task focuses on the online identification of newly arriving stream data that may belong to both known and unknown categories, utilizing the category knowledge from only labeled data. Existing OCD methods are devoted to fully mining transferable knowledge from only labeled data. However, the transferability learned by these methods is limited because the knowledge contained in known categories is often insufficient, especially when few annotated data/categories are available in fine-grained recognition. To mitigate this limitation, we propose a diffusion-based OCD framework, dubbed DiffGRE, which integrates Generation, Refinement, and Encoding in a multi-stage fashion. Specifically, we first design an attribute-composition generation method based on cross-image interpolation in the diffusion latent space to synthesize novel samples. Then, we propose a diversity-driven refinement approach to select the synthesized images that differ from known categories for subsequent OCD model training. Finally, we leverage a semi-supervised leader encoding to inject additional category knowledge contained in synthesized data into the OCD models, which can benefit the discovery of both known and unknown categories during the on-the-fly inference process. Extensive experiments demonstrate the superiority of our DiffGRE over previous methods on six fine-grained datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we investigate a practical yet challenging task: On-the-flyCategory Discovery (OCD). This task focuses on the online identification ofnewly arriving stream data that may belong to both known and unknowncategories, utilizing the category knowledge from only labeled data. ExistingOCD methods are devoted to fully mining transferable knowledge from onlylabeled data. However, the transferability learned by these methods is limitedbecause the knowledge contained in known categories is often insufficient,especially when few annotated data/categories are available in fine-grainedrecognition. To mitigate this limitation, we propose a diffusion-based OCDframework, dubbed DiffGRE, which integrates Generation, Refinement, andEncoding in a multi-stage fashion. Specifically, we first design anattribute-composition generation method based on cross-image interpolation inthe diffusion latent space to synthesize novel samples. Then, we propose adiversity-driven refinement approach to select the synthesized images thatdiffer from known categories for subsequent OCD model training. Finally, weleverage a semi-supervised leader encoding to inject additional categoryknowledge contained in synthesized data into the OCD models, which can benefitthe discovery of both known and unknown categories during the on-the-flyinference process. Extensive experiments demonstrate the superiority of ourDiffGRE over previous methods on six fine-grained datasets.</description>
      <author>example@mail.com (Xiao Liu, Nan Pu, Haiyang Zheng, Wenjing Li, Nicu Sebe, Zhun Zhong)</author>
      <guid isPermaLink="false">2507.04051v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Time2Agri: Temporal Pretext Tasks for Agricultural Monitoring</title>
      <link>http://arxiv.org/abs/2507.04366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了三个针对农业场景的新的预训练任务，旨在提高遥感模型在农业领域的性能。&lt;h4&gt;背景&lt;/h4&gt;当前遥感基础模型（RSFMs）主要依赖掩码自编码（MAE）或对比学习，但忽略了农业景观的时序特性。&lt;h4&gt;目的&lt;/h4&gt;提出能够更好地利用农业时序特性的预训练任务。&lt;h4&gt;方法&lt;/h4&gt;提出了时间差预测（TD）、时频预测（FP）和未来帧预测（FF）三个新的预训练任务。&lt;h4&gt;主要发现&lt;/h4&gt;在SICKLE数据集上的评估显示，FF在作物映射任务上达到了69.6%的IoU，FP将产量预测误差降低到30.7%的MAPE，TD在大多数任务上保持竞争力。FF在印度国家尺度上也取得了54.2%的IoU，在FTW India数据集上的地块边界划分任务上优于所有基线。&lt;h4&gt;结论&lt;/h4&gt;提出的预训练任务在农业遥感领域具有显著效果，能够提升模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self Supervised Learning(SSL) has emerged as a prominent paradigm forlabel-efficient learning, and has been widely utilized by remote sensingfoundation models(RSFMs). Recent RSFMs including SatMAE, DoFA, primarily relyon masked autoencoding(MAE), contrastive learning or some combination of them.However, these pretext tasks often overlook the unique temporal characteristicsof agricultural landscape, namely nature's cycle. Motivated by this gap, wepropose three novel agriculture-specific pretext tasks, namely Time-DifferencePrediction(TD), Temporal Frequency Prediction(FP), and Future-FramePrediction(FF). Comprehensive evaluation on SICKLE dataset shows FF achieves69.6% IoU on crop mapping and FP reduces yield prediction error to 30.7% MAPE,outperforming all baselines, and TD remains competitive on most tasks. Further,we also scale FF to the national scale of India, achieving 54.2% IoUoutperforming all baselines on field boundary delineation on FTW India dataset.</description>
      <author>example@mail.com (Moti Rattan Gupta, Anupam Sobti)</author>
      <guid isPermaLink="false">2507.04366v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Accurate and Efficient World Modeling with Masked Latent Transformers</title>
      <link>http://arxiv.org/abs/2507.04075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的世界模型EMERALD，旨在提高智能体在多样化环境中的表现。&lt;h4&gt;背景&lt;/h4&gt;Dreamer算法通过训练强大的智能体在模拟轨迹上取得了显著的性能，但其世界模型的压缩性质可能导致重要信息的丢失。&lt;h4&gt;目的&lt;/h4&gt;提出一种既准确又高效的世界模型，以改善智能体的性能。&lt;h4&gt;方法&lt;/h4&gt;EMERALD使用空间潜在状态和MaskGIT预测来生成准确的轨迹，从而在潜在空间中提高智能体的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在Crafter基准测试中，EMERALD实现了新的最先进性能，成为第一个在10M环境步骤内超越人类专家性能的方法，并在评估期间至少解锁了所有22个Crafter成就。&lt;h4&gt;结论&lt;/h4&gt;EMERALD是一种高效且准确的世界模型，能够显著提升智能体的性能，并在实际应用中取得成功。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Dreamer algorithm has recently obtained remarkable performance acrossdiverse environment domains by training powerful agents with simulatedtrajectories. However, the compressed nature of its world model's latent spacecan result in the loss of crucial information, negatively affecting the agent'sperformance. Recent approaches, such as $\Delta$-IRIS and DIAMOND, address thislimitation by training more accurate world models. However, these methodsrequire training agents directly from pixels, which reduces training efficiencyand prevents the agent from benefiting from the inner representations learnedby the world model. In this work, we propose an alternative approach to worldmodeling that is both accurate and efficient. We introduce EMERALD (EfficientMaskEd latent tRAnsformer worLD model), a world model using a spatial latentstate with MaskGIT predictions to generate accurate trajectories in latentspace and improve the agent performance. On the Crafter benchmark, EMERALDachieves new state-of-the-art performance, becoming the first method to surpasshuman experts performance within 10M environment steps. Our method alsosucceeds to unlock all 22 Crafter achievements at least once during evaluation.</description>
      <author>example@mail.com (Maxime Burchi, Radu Timofte)</author>
      <guid isPermaLink="false">2507.04075v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised learning of speech representations with Dutch archival data</title>
      <link>http://arxiv.org/abs/2507.04554v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at interspeech 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用荷兰档案馆电视广播数据来自我监督学习语音基础模型wav2vec 2.0的方法。&lt;h4&gt;背景&lt;/h4&gt;研究基于对预训练数据质量假设的分析，以及对音乐、噪声和说话人重叠如何影响自我监督学习（SSL）收敛和下游微调性能的研究。&lt;h4&gt;目的&lt;/h4&gt;旨在通过有效的预处理策略，将噪声的广播数据集转换为适合预训练的优质数据集，并比较单语种和多语种预训练的效果，以及实现荷兰语言领域的wav2vec 2.0模型的最新水平。&lt;h4&gt;方法&lt;/h4&gt;研究采用 Whisper 和 WhisperX 进行数据预处理，比较单语种和多语种预训练，并继续使用55k小时的档案馆数据集对wav2vec 2.0 XLS-R模型进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;发现音乐、噪声和说话人重叠会影响SSL收敛和下游微调性能，单语种预训练对域外数据更稳健，并通过预训练实现了荷兰语言的wav2vec 2.0模型的新水平。&lt;h4&gt;结论&lt;/h4&gt;通过有效的预处理和多语种预训练策略，实现了荷兰语言wav2vec 2.0模型的最新水平，证明了其在处理域外数据时的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the use of Dutch archival television broadcast data forself-supervised learning of speech foundation models, specifically wav2vec 2.0.We first study data quality assumptions for pre-training, and show how music,noise and speaker overlap affect SSL convergence and downstream fine-tuningperformance. Secondly, we explore effectively pre-processing strategies toconvert the noisy broadcast dataset into a qualitative dataset forpre-training, by using Whisper and WhisperX., Thirdly, we compare mono-lingualand multi-lingual pre-training with equivalent amounts of data, and show thatmono-lingual pre-training is more robust to out-of-domain data. Lastly, weachieve a state-of-the-art LARGE wav2vec 2.0 model for the Dutch language, by acontinuation of pre-training a wav2vec 2.0 XLS-R model checkpoint with our 55khour archival dataset.</description>
      <author>example@mail.com (Nik Vaessen, David A. van Leeuwen, Roeland Ordelman)</author>
      <guid isPermaLink="false">2507.04554v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>OrbitAll: A Unified Quantum Mechanical Representation Deep Learning Framework for All Molecular Systems</title>
      <link>http://arxiv.org/abs/2507.03853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OrbitAll的深度学习框架，该框架能够处理具有电子结构信息的所有分子系统，并在预测带电、未成对和溶剂化分子方面表现出优异的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习方法在量子化学中取得了成功，但它们的表示能力通常局限于中性、闭壳层分子。然而，现实世界的化学系统往往具有复杂的特性，包括不同的电荷、自旋和环境。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理所有分子系统的深度学习框架，以应对现实世界中化学系统的复杂性。&lt;h4&gt;方法&lt;/h4&gt;OrbitAll利用底层量子力学方法的自旋极化轨道特征，并结合满足SE(3)-等变性的图神经网络。该框架能够表示和处理具有任意电荷、自旋和环境效应的任何分子系统。&lt;h4&gt;主要发现&lt;/h4&gt;OrbitAll在预测带电、未成对和溶剂化分子方面表现出优越的性能，并且能够通过利用物理信息架构稳健地外推到比训练数据大得多的分子。&lt;h4&gt;结论&lt;/h4&gt;OrbitAll使用比竞争性AI模型少10倍的数据实现了化学精度，并且与密度泛函理论相比，速度提高了大约1000到10000倍。&lt;h4&gt;翻译&lt;/h4&gt;尽管深度学习方法在量子化学中取得了成功，但它们的表示能力通常局限于中性、闭壳层分子。然而，现实世界的化学系统往往具有复杂的特性，包括不同的电荷、自旋和环境。我们引入了OrbitAll，这是一个基于几何和物理信息的深度学习框架，可以表示所有具有电子结构信息的分子系统。OrbitAll利用底层量子力学方法的自旋极化轨道特征，并结合满足SE(3)-等变性的图神经网络。由此产生的框架可以表示和处理任何具有任意电荷、自旋和环境效应的分子系统。OrbitAll在预测带电、未成对和溶剂化分子方面表现出优异的性能，同时通过利用物理信息架构稳健地外推到比训练数据大得多的分子。OrbitAll使用比竞争性AI模型少10倍的数据实现了化学精度，并且与密度泛函理论相比，速度提高了大约1000到10000倍。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the success of deep learning methods in quantum chemistry, theirrepresentational capacity is most often confined to neutral, closed-shellmolecules. However, real-world chemical systems often exhibit complexcharacteristics, including varying charges, spins, and environments. Weintroduce OrbitAll, a geometry- and physics-informed deep learning frameworkthat can represent all molecular systems with electronic structure information.OrbitAll utilizes spin-polarized orbital features from the underlying quantummechanical method, and combines it with graph neural networks satisfyingSE(3)-equivariance. The resulting framework can represent and process anymolecular system with arbitrary charges, spins, and environmental effects.OrbitAll demonstrates superior performance and generalization on predictingcharged, open-shell, and solvated molecules, while also robustly extrapolatingto molecules significantly larger than the training data by leveraging aphysics-informed architecture. OrbitAll achieves chemical accuracy using 10times fewer training data than competing AI models, with a speedup ofapproximately $10^3$ - $10^4$ compared to density functional theory.</description>
      <author>example@mail.com (Beom Seok Kang, Vignesh C. Bhethanabotla, Amin Tavakoli, Maurice D. Hanisch, William A. Goddard III, Anima Anandkumar)</author>
      <guid isPermaLink="false">2507.03853v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>ChestGPT: Integrating Large Language Models and Vision Transformers for Disease Detection and Localization in Chest X-Rays</title>
      <link>http://arxiv.org/abs/2507.03739v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ChestGPT的深度学习框架，该框架结合了EVA ViT和Llama 2 LLM，用于对胸部X光图像进行疾病分类和感兴趣区域定位。&lt;h4&gt;背景&lt;/h4&gt;全球对放射科医生的需求迅速增长，而放射科医生的供应没有跟上。计算机视觉和图像处理技术的进步为提高放射科医生的能力和诊断准确性提供了巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;开发一个辅助工具，以减轻放射科医生的工作负担，通过提供初步发现和感兴趣区域来促进他们的诊断过程。&lt;h4&gt;方法&lt;/h4&gt;ChestGPT框架将X光图像转换为tokens，然后与精心设计的提示一起输入到LLM中，实现疾病的联合分类和定位。该方法结合了迁移学习技术，以增强可解释性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;在VinDr-CXR数据集上，该方法实现了0.76的F1分数，并在感兴趣区域周围生成边界框以成功定位疾病。&lt;h4&gt;结论&lt;/h4&gt;ChestGPT框架为放射科医生提供了一个辅助工具，可以帮助他们在诊断过程中减轻工作量。&lt;h4&gt;翻译&lt;/h4&gt;The global demand for radiologists is increasing rapidly due to a growing reliance on medical imaging services, while the supply of radiologists is not keeping pace. Advances in computer vision and image processing technologies present significant potential to address this gap by enhancing radiologists' capabilities and improving diagnostic accuracy. Large language models (LLMs), particularly generative pre-trained transformers (GPTs), have become the primary approach for understanding and generating textual data. In parallel, vision transformers (ViTs) have proven effective at converting visual data into a format that LLMs can process efficiently. In this paper, we present ChestGPT, a deep-learning framework that integrates the EVA ViT with the Llama 2 LLM to classify diseases and localize regions of interest in chest X-ray images. The ViT converts X-ray images into tokens, which are then fed, together with engineered prompts, into the LLM, enabling joint classification and localization of diseases. This approach incorporates transfer learning techniques to enhance both explainability and performance. The proposed method achieved strong global disease classification performance on the VinDr-CXR dataset, with an F1 score of 0.76, and successfully localized pathologies by generating bounding boxes around the regions of interest. We also outline several task-specific prompts, in addition to general-purpose prompts, for scenarios radiologists might encounter. Overall, this framework offers an assistive tool that can lighten radiologists' workload by providing preliminary findings and regions of interest to facilitate their diagnostic process.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The global demand for radiologists is increasing rapidly due to a growingreliance on medical imaging services, while the supply of radiologists is notkeeping pace. Advances in computer vision and image processing technologiespresent significant potential to address this gap by enhancing radiologists'capabilities and improving diagnostic accuracy. Large language models (LLMs),particularly generative pre-trained transformers (GPTs), have become theprimary approach for understanding and generating textual data. In parallel,vision transformers (ViTs) have proven effective at converting visual data intoa format that LLMs can process efficiently. In this paper, we present ChestGPT,a deep-learning framework that integrates the EVA ViT with the Llama 2 LLM toclassify diseases and localize regions of interest in chest X-ray images. TheViT converts X-ray images into tokens, which are then fed, together withengineered prompts, into the LLM, enabling joint classification andlocalization of diseases. This approach incorporates transfer learningtechniques to enhance both explainability and performance. The proposed methodachieved strong global disease classification performance on the VinDr-CXRdataset, with an F1 score of 0.76, and successfully localized pathologies bygenerating bounding boxes around the regions of interest. We also outlineseveral task-specific prompts, in addition to general-purpose prompts, forscenarios radiologists might encounter. Overall, this framework offers anassistive tool that can lighten radiologists' workload by providing preliminaryfindings and regions of interest to facilitate their diagnostic process.</description>
      <author>example@mail.com (Shehroz S. Khan, Petar Przulj, Ahmed Ashraf, Ali Abedi)</author>
      <guid isPermaLink="false">2507.03739v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CLIP-RL: Surgical Scene Segmentation Using Contrastive Language-Vision Pretraining &amp; Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.04317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CLIP-RL的新型对比语言图像预训练模型，用于手术场景的语义分割，该模型结合了对比学习、强化学习和课程学习，在多种光学设置下表现出色。&lt;h4&gt;背景&lt;/h4&gt;手术场景的视频数据量大，理解这些场景对于提高医疗质量至关重要，同时这些视频数据可以用于训练复杂的模型。&lt;h4&gt;目的&lt;/h4&gt;提出CLIP-RL模型，以改善手术场景的语义分割，从而提高医疗质量。&lt;h4&gt;方法&lt;/h4&gt;CLIP-RL模型结合了对比学习、强化学习和课程学习，通过迭代调整动作空间来动态优化分割掩码。&lt;h4&gt;主要发现&lt;/h4&gt;CLIP-RL在EndoVis 2018和EndoVis 2017数据集上取得了平均IoU分别为81%和74.12%的成绩，优于现有模型。&lt;h4&gt;结论&lt;/h4&gt;CLIP-RL模型通过结合对比学习、强化学习和课程学习，在手术场景的语义分割中表现出色，有望提高医疗质量。&lt;h4&gt;翻译&lt;/h4&gt;摘要：理解手术场景可以为患者提供更好的医疗质量，尤其是在大量视频数据生成于微创手术的情况下。处理这些视频为训练复杂模型产生了宝贵的资产。在本文中，我们介绍了一种针对手术场景语义分割的新型对比语言图像预训练模型CLIP-RL。CLIP-RL提出了一种新的分割方法，涉及强化学习和课程学习，能够在整个训练管道中持续优化分割掩码。我们的模型在不同的光学设置下表现出鲁棒性，如遮挡、纹理变化和动态照明，这些都具有重大挑战。CLIP模型作为一个强大的特征提取器，捕捉了丰富的语义上下文，增强了仪器和组织之间的区分。强化学习模块在通过迭代动作空间调整动态优化预测中起着关键作用。我们在EndoVis 2018和EndoVis 2017数据集上评估了CLIP-RL，CLIP-RL实现了平均IoU为81%，优于现有模型，在EndoVis 2017上的平均IoU为74.12%。这种优越的性能得益于对比学习与强化学习和课程学习的结合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/CBMS65348.2025.00175&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding surgical scenes can provide better healthcare quality forpatients, especially with the vast amount of video data that is generatedduring MIS. Processing these videos generates valuable assets for trainingsophisticated models. In this paper, we introduce CLIP-RL, a novel contrastivelanguage-image pre-training model tailored for semantic segmentation forsurgical scenes. CLIP-RL presents a new segmentation approach which involvesreinforcement learning and curriculum learning, enabling continuous refinementof the segmentation masks during the full training pipeline. Our model hasshown robust performance in different optical settings, such as occlusions,texture variations, and dynamic lighting, presenting significant challenges.CLIP model serves as a powerful feature extractor, capturing rich semanticcontext that enhances the distinction between instruments and tissues. The RLmodule plays a pivotal role in dynamically refining predictions throughiterative action-space adjustments. We evaluated CLIP-RL on the EndoVis 2018and EndoVis 2017 datasets. CLIP-RL achieved a mean IoU of 81%, outperformingstate-of-the-art models, and a mean IoU of 74.12% on EndoVis 2017. Thissuperior performance was achieved due to the combination of contrastivelearning with reinforcement learning and curriculum learning.</description>
      <author>example@mail.com (Fatmaelzahraa Ali Ahmed, Muhammad Arsalan, Abdulaziz Al-Ali, Khalid Al-Jalham, Shidin Balakrishnan)</author>
      <guid isPermaLink="false">2507.04317v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models</title>
      <link>http://arxiv.org/abs/2507.03916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appendix at:  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个用于幻灯片动画建模的公开数据集，并使用低秩自适应（LoRA）技术改进了Qwen-2.5-VL-7B模型，提高了其动画生成能力。&lt;h4&gt;背景&lt;/h4&gt;现有的AI幻灯片生成工具缺乏动画支持，而现有的视觉语言模型在动画任务上存在困难，主要原因是缺乏公共数据集和有限的时序推理能力。&lt;h4&gt;目的&lt;/h4&gt;解决现有幻灯片动画生成工具的不足，提高视觉语言模型在动画任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;发布了一个包含12,000个自然语言描述、动画JSON文件和渲染视频的公开数据集，使用LoRA技术对Qwen-2.5-VL-7B模型进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;LoRA模型在BLEU-4、ROUGE-L、SPICE和CODA指标上均取得了显著提升，提高了动作覆盖、时序和细节保真度。&lt;h4&gt;结论&lt;/h4&gt;该数据集、LoRA增强模型和CODA指标为基于视觉语言模型的动态幻灯片生成提供了严格的标准和基础。&lt;h4&gt;翻译&lt;/h4&gt;Slide animations, such as fade-ins, fly-ins, and wipes, are critical for audience engagement, efficient information delivery, and vivid visual expression. However, most AI-driven slide-generation tools still lack native animation support, and existing vision-language models (VLMs) struggle with animation tasks due to the absence of public datasets and limited temporal-reasoning capabilities. To address this gap, we release the first public dataset for slide-animation modeling: 12,000 triplets of natural-language descriptions, animation JSON files, and rendered videos, collectively covering every built-in PowerPoint effect. Using this resource, we fine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent improvements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our Coverage-Order-Detail Assessment (CODA) metric, which evaluates action coverage, temporal order, and detail fidelity. On a manually curated test set of slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and shows significant improvements in CODA-detail. This demonstrates that low-rank adaptation enables reliable temporal reasoning and generalization beyond synthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric provide a rigorous benchmark and foundation for future research on VLM-based dynamic slide generation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Slide animations, such as fade-ins, fly-ins, and wipes, are critical foraudience engagement, efficient information delivery, and vivid visualexpression. However, most AI-driven slide-generation tools still lack nativeanimation support, and existing vision-language models (VLMs) struggle withanimation tasks due to the absence of public datasets and limitedtemporal-reasoning capabilities. To address this gap, we release the firstpublic dataset for slide-animation modeling: 12,000 triplets ofnatural-language descriptions, animation JSON files, and rendered videos,collectively covering every built-in PowerPoint effect. Using this resource, wefine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistentimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and ourCoverage-Order-Detail Assessment (CODA) metric, which evaluates actioncoverage, temporal order, and detail fidelity. On a manually curated test setof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, andshows significant improvements in CODA-detail. This demonstrates that low-rankadaptation enables reliable temporal reasoning and generalization beyondsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metricprovide a rigorous benchmark and foundation for future research on VLM-baseddynamic slide generation.</description>
      <author>example@mail.com (Yifan Jiang, Yibo Xue, Yukun Kang, Pin Zheng, Jian Peng, Feiran Wu, Changliang Xu)</author>
      <guid isPermaLink="false">2507.03916v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Greedy Dynamic Matching</title>
      <link>http://arxiv.org/abs/2507.04551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了动态匹配市场的废弃基础模型，比较了贪婪策略与全知基准的性能，并使用线性规划确定最佳贪婪策略。结果表明，在特定条件下，贪婪策略能够获得至少一半的全知策略奖励率，优于之前的1/8界限。&lt;h4&gt;背景&lt;/h4&gt;动态匹配市场模型已被Collina等（2020）和Aouad和Saritac（2022）等研究，许多论文考虑了特殊情况。&lt;h4&gt;目的&lt;/h4&gt;比较贪婪策略与全知基准的性能，并找到一种贪婪策略以优化匹配市场。&lt;h4&gt;方法&lt;/h4&gt;使用新型线性规划（$LP^{ALG}$）确定贪婪策略，并通过新结果（引理1）和线性规划（命题3）来证明结果。&lt;h4&gt;主要发现&lt;/h4&gt;1. $LP^{ALG}$的价值是贪婪策略价值的下界；2. 在所有类型具有相同离开率的情况下，以及市场同侧类型具有相同离开率的双边情况下，贪婪策略至少能获得全知策略奖励率的一半；3. 贪婪策略的竞争比至少为1/2，这是最佳可能保证。&lt;h4&gt;结论&lt;/h4&gt;本文提出的贪婪策略在特定条件下能够获得至少一半的全知策略奖励率，并且优于之前的研究结果。&lt;h4&gt;翻译&lt;/h4&gt;We study a foundational model of dynamic matching market with abandonment. This model has been studied by Collina et al (2020) and Aouad and Saritac(2022), and many other papers have considered special cases. We compare the performance of greedy policies -- which identify a set of 'acceptable' matches upfront, and perform these matches as soon as possible -- to that of an omniscient benchmark which knows the full arrival and departure sequence. We use a novel family of linear programs ($LP^{ALG}$) to identify which greedy policy to follow. We show that the value of $LP^ALG$ is a *lower bound* on the value of the greedy policy that it identifies in two settings of interest: -When all types have the same departure rate. -The bipartite case where types on the same side of the market have the same departure rate. The proofs of these results use a new result (Lemma 1), which relates the *probability* that at least one agent from a set of types is present in the system to the expected number of such agents. We also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rate earned by the omniscient policy (Proposition 4). Therefore, for both settings above, our greedy policy provably earns at least half of the omniscient reward rate. This improves upon the bound of 1/8 from Collina (2020). In both settings our competitive ratio of 1/2 is the best possible: no online policy can provide a better guarantee (Theorem 2). To show these results we introduce a new linear program that upper bounds the objective value of the omniscient policy (Proposition 3). This improves upon the upper bounds presented by Collina et al (2020) and Kessel et al (2022).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study a foundational model of dynamic matching market with abandonment.This model has been studied by Collina et al (2020) and Aouad and Saritac(2022), and many other papers have considered special cases. We compare theperformance of greedy policies -- which identify a set of "acceptable" matchesup front, and perform these matches as soon as possible -- to that of anomniscient benchmark which knows the full arrival and departure sequence.  We use a novel family of linear programs ($LP^{ALG}$) to identify whichgreedy policy to follow. We show that the value of $LP^ALG$ is a *lower bound*on the value of the greedy policy that it identifies in two settings ofinterest:  -When all types have the same departure rate.  -The bipartite case where types on the same side of the market have the samedeparture rate.  The proofs of these results use a new result (Lemma 1), which relates the*probability* that at least one agent from a set of types is present in thesystem to the expected number of such agents.  We also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rateearned by the omniscient policy (Proposition 4). Therefore, for both settingsabove, our greedy policy provably earns at least half of the omniscient rewardrate. This improves upon the bound of 1/8 from Collina (2020). In both settingsour competitive ratio of 1/2 is the best possible: no online policy can providea better guarantee (Theorem 2).  To show these results we introduce a new linear program that upper bounds theobjective value of the omniscient policy (Proposition 3). This improves uponthe upper bounds presented by Collina et al (2020) and Kessel et al (2022).</description>
      <author>example@mail.com (Nick Arnosti, Felipe Simon)</author>
      <guid isPermaLink="false">2507.04551v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Equivariant Graph Neural Networks for Large-Scale Electronic Structure Prediction</title>
      <link>http://arxiv.org/abs/2507.03840v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于密度泛函理论（DFT）数据的等变图神经网络（eGNN）分布式实现，用于预测具有扩展缺陷、界面或无序相的材料的电子结构。&lt;h4&gt;背景&lt;/h4&gt;eGNN在处理大尺度电子结构预测时，由于原子轨道间的相互作用通常跨越10+埃，导致图表示密集连接，训练和推理这些大型结构需要超过现代GPU的内存限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种分布式eGNN实现，利用直接GPU通信，并引入输入图的分区策略，以减少GPU间嵌入交换的次数。&lt;h4&gt;方法&lt;/h4&gt;通过在Alps超级计算机上对具有3000到190000个原子的结构进行实验，展示了该实现能以87%的并行效率在128个GPU上实现强扩展，在512个GPU上实现弱扩展。&lt;h4&gt;主要发现&lt;/h4&gt;该实现能显著提高eGNN在处理大型电子结构预测时的效率，并能够在不同的GPU数量下实现有效的扩展。&lt;h4&gt;结论&lt;/h4&gt;所提出的分布式eGNN实现能够有效提升电子结构预测的性能，为研究具有复杂电子性质的材料提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Equivariant Graph Neural Networks (eGNNs) trained on density-functional theory (DFT) data can potentially perform electronic structure prediction at unprecedented scales, enabling investigation of the electronic properties of materials with extended defects, interfaces, or exhibiting disordered phases. However, as interactions between atomic orbitals typically extend over 10+angstroms, the graph representations required for this task tend to be densely connected, and the memory requirements to perform training and inference on these large structures can exceed the limits of modern GPUs. Here we present a distributed eGNN implementation which leverages direct GPU communication and introduce a partitioning strategy of the input graph to reduce the number of embedding exchanges between GPUs. Our implementation shows strong scaling up to 128 GPUs, and weak scaling up to 512 GPUs with 87% parallel efficiency for structures with 3,000 to 190,000 atoms on the Alps supercomputer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Equivariant Graph Neural Networks (eGNNs) trained on density-functionaltheory (DFT) data can potentially perform electronic structure prediction atunprecedented scales, enabling investigation of the electronic properties ofmaterials with extended defects, interfaces, or exhibiting disordered phases.However, as interactions between atomic orbitals typically extend over 10+angstroms, the graph representations required for this task tend to be denselyconnected, and the memory requirements to perform training and inference onthese large structures can exceed the limits of modern GPUs. Here we present adistributed eGNN implementation which leverages direct GPU communication andintroduce a partitioning strategy of the input graph to reduce the number ofembedding exchanges between GPUs. Our implementation shows strong scaling up to128 GPUs, and weak scaling up to 512 GPUs with 87% parallel efficiency forstructures with 3,000 to 190,000 atoms on the Alps supercomputer.</description>
      <author>example@mail.com (Manasa Kaniselvan, Alexander Maeder, Chen Hao Xia, Alexandros Nikolaos Ziogas, Mathieu Luisier)</author>
      <guid isPermaLink="false">2507.03840v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>SciVid: Cross-Domain Evaluation of Video Models in Scientific Applications</title>
      <link>http://arxiv.org/abs/2507.03578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025, GitHub repo: https://github.com/google-deepmind/scivid&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SciVid的综合基准，用于评估视频基础模型（ViFMs）在不同科学领域中的应用潜力。&lt;h4&gt;背景&lt;/h4&gt;近年来，时空基础模型在各个科学学科中迅速发展，但它们通常是领域特定的，只在设计的目的应用中进行评估。&lt;h4&gt;目的&lt;/h4&gt;研究大规模但可能超出领域数据上获得的知识是否能够有效跨不同科学学科迁移，以及单个预训练的ViFM是否能与领域特定基线相竞争。&lt;h4&gt;方法&lt;/h4&gt;引入SciVid基准，包括五个跨医学计算机视觉、动物行为和天气预报的*Sci*entific *Vid*eo任务，并使用可训练的读出模块将六个领先的ViFMs应用于SciVid，建立强大的基线和展示有效迁移学习的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用ViFM主干的一般化表示，可以在多个应用中获得最先进的成果。研究揭示了现有ViFMs的局限性，并突出了为具有重大影响的应用开发可推广模型的机会。&lt;h4&gt;结论&lt;/h4&gt;SciVid基准有助于进一步研究ViFMs的开发，并展示了ViFMs在不同科学领域的潜在应用价值。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, there has been a proliferation of spatiotemporal foundationmodels in different scientific disciplines. While promising, these models are often domain-specific and are only assessed within the particular applications for which they are designed. Given that many tasks can be represented as videomodeling problems, video foundation models (ViFMs) hold considerable promise as general-purpose domain-agnostic approaches. However, it is not known whether the knowledge acquired on large-scale but potentially out-of-domain data can be effectively transferred across diverse scientific disciplines, and if a single, pretrained ViFM can be competitive with domain-specific baselines. To address this, we introduce SciVid, a comprehensive benchmark comprising five *Sci*entific *Vid*eo tasks, across medical computer vision, animal behavior, and weather forecasting. We adapt six leading ViFMs to SciVid using simple trainable readout modules, establishing strong baselines and demonstrating the potential for effective transfer learning. Specifically, we show that state-of-the-art results can be obtained in several applications by leveraging the general-purpose representations from ViFM backbones. Furthermore, our results reveal the limitations of existing ViFMs, and highlight opportunities for the development of generalizable models for high-impact scientific applications. We release our code at https://github.com/google-deepmind/scivid to facilitate further research in the development of ViFMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, there has been a proliferation of spatiotemporal foundationmodels in different scientific disciplines. While promising, these models areoften domain-specific and are only assessed within the particular applicationsfor which they are designed. Given that many tasks can be represented as videomodeling problems, video foundation models (ViFMs) hold considerable promise asgeneral-purpose domain-agnostic approaches. However, it is not known whetherthe knowledge acquired on large-scale but potentially out-of-domain data can beeffectively transferred across diverse scientific disciplines, and if a single,pretrained ViFM can be competitive with domain-specific baselines. To addressthis, we introduce SciVid, a comprehensive benchmark comprising five*Sci*entific *Vid*eo tasks, across medical computer vision, animal behavior,and weather forecasting. We adapt six leading ViFMs to SciVid using simpletrainable readout modules, establishing strong baselines and demonstrating thepotential for effective transfer learning. Specifically, we show thatstate-of-the-art results can be obtained in several applications by leveragingthe general-purpose representations from ViFM backbones. Furthermore, ourresults reveal the limitations of existing ViFMs, and highlight opportunitiesfor the development of generalizable models for high-impact scientificapplications. We release our code at https://github.com/google-deepmind/scividto facilitate further research in the development of ViFMs.</description>
      <author>example@mail.com (Yana Hasson, Pauline Luc, Liliane Momeni, Maks Ovsjanikov, Guillaume Le Moing, Alina Kuznetsova, Ira Ktena, Jennifer J. Sun, Skanda Koppula, Dilara Gokay, Joseph Heyward, Etienne Pot, Andrew Zisserman)</author>
      <guid isPermaLink="false">2507.03578v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Are Learning-Based Approaches Ready for Real-World Indoor Navigation? A Case for Imitation Learning</title>
      <link>http://arxiv.org/abs/2507.04086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at the 12th European Conference on Mobile  Robots (ECMR 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了模仿学习在室内导航中的应用，并与传统导航方法进行了比较。&lt;h4&gt;背景&lt;/h4&gt;传统的室内机器人导航方法在受限场景中可靠，但在复杂环境中缺乏灵活性和需要手动调整。&lt;h4&gt;目的&lt;/h4&gt;探索模仿学习在室内导航中的可行性，并将其与传统导航方法进行比较。&lt;h4&gt;方法&lt;/h4&gt;使用专家（操纵杆）演示训练基于RGB图像、激光雷达和两者结合的导航策略网络，并在一个室内大学环境中使用物理移动机器人平台进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;多模态模型在大多数场景中表现出优越的导航能力，但在动态环境中面临挑战，可能是由于演示的多样性有限。&lt;h4&gt;结论&lt;/h4&gt;模仿学习可以直接从数据中学习并跨布局泛化，表明它可能是一个实用的导航方法，并且可能是一个有用的后续终身学习的初始化策略。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the viability of imitation learning in indoor navigation and compares it with traditional navigation methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional indoor robot navigation methods provide a reliable solution whenadapted to constrained scenarios, but lack flexibility or require manualre-tuning when deployed in more complex settings. In contrast, learning-basedapproaches learn directly from sensor data and environmental interactions,enabling easier adaptability. While significant work has been presented in thecontext of learning navigation policies, learning-based methods are rarelycompared to traditional navigation methods directly, which is a problem fortheir ultimate acceptance in general navigation contexts. In this work, weexplore the viability of imitation learning (IL) for indoor navigation, usingexpert (joystick) demonstrations to train various navigation policy networksbased on RGB images, LiDAR, and a combination of both, and we compare our ILapproach to a traditional potential field-based navigation method. We evaluatethe approach on a physical mobile robot platform equipped with a 2D LiDAR and acamera in an indoor university environment. Our multimodal model demonstratessuperior navigation capabilities in most scenarios, but faces challenges indynamic environments, likely due to limited diversity in the demonstrations.Nevertheless, the ability to learn directly from data and generalise acrosslayouts suggests that IL can be a practical navigation approach, andpotentially a useful initialisation strategy for subsequent lifelong learning.</description>
      <author>example@mail.com (Nigitha Selvaraj, Alex Mitrevski, Sebastian Houben)</author>
      <guid isPermaLink="false">2507.04086v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable High-Performance Ray Tracing-Based Simulation of Radio Propagation with Point Clouds</title>
      <link>http://arxiv.org/abs/2507.04021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可微射影的无线电传播模拟器，能够在点云上直接操作，并通过语义分割标签学习环境电磁特性。&lt;h4&gt;背景&lt;/h4&gt;射影追踪是无线电传播模拟中广泛使用的一种确定性方法，可以产生物理上准确的路径分量。其准确性取决于环境模型的质和电磁特性。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的无线电传播模拟器，该模拟器能够直接在点云上运行并利用语义分割标签来学习环境特性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可微射影基无线电传播模拟器，并在两个室内场景中模拟了多跳传播路径，路径与镜面反射和漫射散射相互作用，每个场景的处理时间不到90毫秒。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过直接在点云上操作，结合语义分割标签，可以高效地学习环境的电磁特性。&lt;h4&gt;结论&lt;/h4&gt;电磁计算的微分性与语义分割标签相结合，可以用于构建一个高效的无线电传播模拟器。&lt;h4&gt;翻译&lt;/h4&gt;摘要：射影追踪是一种广泛用于无线电传播模拟的确定性方法，能够产生物理上准确的路径分量。其准确性依赖于环境模型的质和电磁特性。最近计算机视觉和机器学习的发展使得重建详细的带语义分割标签的环境模型成为可能。在本信函中，我们提出了一种基于可微射影的无线电传播模拟器，该模拟器直接在点云上运行。我们通过在两个室内场景中模拟多跳传播路径（每个路径与镜面反射和漫射散射交互多达五次），并展示出该方法的高效性，每个场景的处理时间不到90毫秒。最后，我们展示了如何将电磁计算的微分性与分割标签相结合，以学习环境的电磁特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ray tracing is a widely used deterministic method for radio propagationsimulations, capable of producing physically accurate multipath components. Theaccuracy depends on the quality of the environment model and itselectromagnetic properties. Recent advances in computer vision and machinelearning have made it possible to reconstruct detailed environment modelsaugmented with semantic segmentation labels.  In this letter, we propose a differentiable ray tracing-based radiopropagation simulator that operates directly on point clouds. We showcase theefficiency of our method by simulating multi-bounce propagation paths with upto five interactions with specular reflections and diffuse scattering in twoindoor scenarios, each completing in less than 90 ms. Lastly, we demonstratehow the differentiability of electromagnetic computations can be combined withsegmentation labels to learn the electromagnetic properties of the environment.</description>
      <author>example@mail.com (Niklas Vaara, Pekka Sangi, Miguel Bordallo López, Janne Heikkilä)</author>
      <guid isPermaLink="false">2507.04021v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>A View-consistent Sampling Method for Regularized Training of Neural Radiance Fields</title>
      <link>http://arxiv.org/abs/2507.04408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的NeRF方法，通过使用视一致性分布来正则化NeRF训练，以改善其在真实世界数据上的性能。&lt;h4&gt;背景&lt;/h4&gt;NeRF作为一种场景表示和3D恢复的框架，深度正则化被证明是最有效的改进方法。然而，深度估计模型需要昂贵的3D监督进行训练，并且存在泛化问题，导致在实际应用中可能产生错误的深度估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进NeRF的性能，特别是在户外无界场景中。&lt;h4&gt;方法&lt;/h4&gt;采用视一致性分布来正则化NeRF训练，该分布通过利用从每个射线采样的3D点投影到2D像素位置的低级颜色特征和高级提炼特征来计算。此外，还利用深度推进损失与采样技术结合，以提供有效的正则化，消除失败模式。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集上的大量实验表明，该方法比最先进的NeRF变体和不同的深度正则化方法能够生成显著更好的新颖视图合成结果。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够显著提高NeRF在真实世界数据上的性能，特别是在户外无界场景中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural Radiance Fields (NeRF) has emerged as a compelling framework for scenerepresentation and 3D recovery. To improve its performance on real-world data,depth regularizations have proven to be the most effective ones. However, depthestimation models not only require expensive 3D supervision in training, butalso suffer from generalization issues. As a result, the depth estimations canbe erroneous in practice, especially for outdoor unbounded scenes. In thispaper, we propose to employ view-consistent distributions instead of fixeddepth value estimations to regularize NeRF training. Specifically, thedistribution is computed by utilizing both low-level color features andhigh-level distilled features from foundation models at the projected 2Dpixel-locations from per-ray sampled 3D points. By sampling from theview-consistency distributions, an implicit regularization is imposed on thetraining of NeRF. We also utilize a depth-pushing loss that works inconjunction with the sampling technique to jointly provide effectiveregularizations for eliminating the failure modes. Extensive experimentsconducted on various scenes from public datasets demonstrate that our proposedmethod can generate significantly better novel view synthesis results thanstate-of-the-art NeRF variants as well as different depth regularizationmethods.</description>
      <author>example@mail.com (Aoxiang Fan, Corentin Dumery, Nicolas Talabot, Pascal Fua)</author>
      <guid isPermaLink="false">2507.04408v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning and Model Independence</title>
      <link>http://arxiv.org/abs/2507.03438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文讨论了在标准模型之外寻找新物理模型的不确定性，提出了模型无关方法的重要性，并强调了深度学习在物理学研究中的应用，特别是自动编码器和无监督学习方法。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏支持新物理模型证据，寻找新物理模型的研究方向没有明确优势。&lt;h4&gt;目的&lt;/h4&gt;介绍深度学习在物理学研究中的应用，强调其作为主要工具的价值，并提出模型独立性的概念及其定义。&lt;h4&gt;方法&lt;/h4&gt;使用深度学习，特别是自动编码器和无监督学习方法，进行高能物理研究。&lt;h4&gt;主要发现&lt;/h4&gt;深度学习作为工具在物理学研究中具有新颖和有前途的应用。&lt;h4&gt;结论&lt;/h4&gt;模型独立性是一个重要的概念，其独立性是相对的，而非绝对的。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于缺乏支持任何新物理模型证据，对于标准模型（SM）之外的新物理的搜索是开放的，没有哪个方向比其他方向更有前景。这标志着向所谓的“模型无关”方法的转变——这些方法通过执行最小偏差的精确测量、使用有效场理论或使用深度学习方法（DL）来减少建模假设的影响。在本文中，我介绍了深度学习作为高能物理研究的主要工具的新颖而有前途的应用，强调了自动编码器和无监督学习方法的使用。我提倡模型独立性的重要性和有用性，并提出了一个承认模型独立性不是绝对的，而是以不同程度存在的定义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The lack of evidence in favor of any new physics models means that the searchfor new physics beyond the Standard Model (BSM) is wide open, with no directionclearly more promising than any other. This marks a turn towards what can becalled `model-independent' methods-strategies that reduce the influence ofmodelling assumptions by performing minimally-biased precision measurements,using effective field theories, or using Deep Learning methods (DL). In thispaper, I present the novel and promising uses of DL as a primary tool in highenergy physics research, highlighting the use of autoencoder networks andunsupervised learning methods. I advocate for the importance and usefulness ofthe concept of model independence and propose a definition that recognizes thatindependence of models is not absolute, but comes in degrees.</description>
      <author>example@mail.com (Martin King)</author>
      <guid isPermaLink="false">2507.03438v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>VISC: mmWave Radar Scene Flow Estimation using Pervasive Visual-Inertial Supervision</title>
      <link>http://arxiv.org/abs/2507.03938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于mmWave雷达的场景流估计框架，该框架由广泛的视觉-惯性（VI）传感器套件数据进行监督，并允许使用智能车辆的众包训练数据。&lt;h4&gt;背景&lt;/h4&gt;当前mmWave雷达的场景流估计方法通常由3D激光雷达提供的密集点云数据进行监督，这既昂贵又不易在智能车辆中广泛使用。虽然VI数据更容易获取，但仅凭视觉图像无法捕捉移动物体的3D运动，这使得监督其场景流变得困难。此外，VI刚体变换的时漂也会降低静态点的场景流估计。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文提出了一个无漂移的刚体变换估计器，它融合基于运动学模型的自我运动与神经网络学习的结果，为基于雷达的刚体变换提供强烈的监督信号，并推断静态点的场景流。&lt;h4&gt;方法&lt;/h4&gt;本文还开发了一个光学-mmWave监督提取模块，它提取雷达刚体变换和场景流的监督信号。该模块通过学习动态点的场景流，并利用光学和mmWave雷达测量的联合约束来加强监督。&lt;h4&gt;主要发现&lt;/h4&gt;在烟雾环境中，本文提出的方法甚至优于使用昂贵的激光雷达的最新（SOTA）方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的框架通过融合多种数据源和先进的估计技术，为mmWave雷达的场景流估计提供了一种高效且可靠的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于毫米波雷达的场景流估计框架，该框架由广泛使用的视觉-惯性（VI）传感器套件数据监督，并允许使用智能车辆的众包训练数据。当前mmWave雷达的场景流估计方法通常由3D激光雷达提供的密集点云数据进行监督，这既昂贵又不易在智能车辆中广泛使用。虽然VI数据更容易获取，但仅凭视觉图像无法捕捉移动物体的3D运动，这使得监督其场景流变得困难。此外，VI刚体变换的时漂也会降低静态点的场景流估计。为了解决这些挑战，本文提出了一个无漂移的刚体变换估计器，它融合基于运动学模型的自我运动与神经网络学习的结果。它为基于雷达的刚体变换提供了强烈的监督信号，并推断出静态点的场景流。然后，本文开发了一个光学-mmWave监督提取模块，它提取雷达刚体变换和场景流的监督信号。该模块通过学习动态点的场景流，并利用光学和mmWave雷达测量的联合约束来加强监督。广泛的实验表明，即使在烟雾环境中，本文提出的方法也优于使用昂贵的激光雷达的最新（SOTA）方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a mmWave radar's scene flow estimation frameworksupervised by data from a widespread visual-inertial (VI) sensor suite,allowing crowdsourced training data from smart vehicles. Current scene flowestimation methods for mmWave radar are typically supervised by dense pointclouds from 3D LiDARs, which are expensive and not widely available in smartvehicles. While VI data are more accessible, visual images alone cannot capturethe 3D motions of moving objects, making it difficult to supervise their sceneflow. Moreover, the temporal drift of VI rigid transformation also degeneratesthe scene flow estimation of static points. To address these challenges, wepropose a drift-free rigid transformation estimator that fuses kinematicmodel-based ego-motions with neural network-learned results. It provides strongsupervision signals to radar-based rigid transformation and infers the sceneflow of static points. Then, we develop an optical-mmWave supervisionextraction module that extracts the supervision signals of radar rigidtransformation and scene flow. It strengthens the supervision by learning thescene flow of dynamic points with the joint constraints of optical and mmWaveradar measurements. Extensive experiments demonstrate that, in smoke-filledenvironments, our method even outperforms state-of-the-art (SOTA) approachesusing costly LiDARs.</description>
      <author>example@mail.com (Kezhong Liu, Yiwen Zhou, Mozi Chen, Jianhua He, Jingao Xu, Zheng Yang, Chris Xiaoxuan Lu, Shengkai Zhang)</author>
      <guid isPermaLink="false">2507.03938v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning</title>
      <link>http://arxiv.org/abs/2507.04048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CLEP-DG的框架，旨在增强CLAP模型在情感识别中的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有的语音情感识别（SER）模型难以在多种声学条件下泛化，而CLAP虽然在多模态对齐方面表现良好，但缺乏捕捉情感线索的机制。&lt;h4&gt;目的&lt;/h4&gt;通过提出CLEP-DG框架，旨在提高情感识别的准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;首先，对CLAP进行微调以获得CLEP，并在大规模情感语音数据集上调整以更好地编码情感相关特征。然后，引入声学上下文提示调整（ACPT）策略，通过文本驱动的方法优化可学习的提示向量，以模拟多样的声学环境。最后，利用跨模态可迁移性，在文本导出的嵌入上进行分类器训练，并在推理过程中将其应用于音频编码器，以减轻文本监督和基于音频的情感识别之间的领域差异。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准数据集上的实验表明，CLEP-DG优于现有的基于CLAP的方法，在监督和领域泛化设置中均实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;CLEP-DG框架有效地提高了情感识别模型的性能，为情感计算和人类-计算机交互领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech Emotion Recognition (SER) is fundamental to affective computing andhuman-computer interaction, yet existing models struggle to generalize acrossdiverse acoustic conditions. While Contrastive Language-Audio Pretraining(CLAP) provides strong multimodal alignment, it lacks dedicated mechanisms forcapturing emotional cues, making it suboptimal for SER. To address this, wepropose CLEP-DG, a framework that enhances CLAP's robustness in emotionrecognition. First, we fine-tune CLAP to obtain CLEP, adapting it onlarge-scale emotional speech datasets to better encode emotion-relevantfeatures. Then, we introduce Acoustic Context Prompt Tuning (ACPT), atext-driven augmentation strategy that optimizes learnable prompt vectors tomodel diverse acoustic environments without additional labeled audio. Finally,leveraging cross-modal transferability, we train a classifier on text-derivedembeddings and apply it to the audio encoder during inference, mitigatingdomain shifts between textual supervision and audio-based emotion recognition.Experiments across five benchmark datasets show that CLEP-DG outperforms priorCLAP-based approaches, achieving state-of-the-art performance in bothsupervised and domain generalization settings.</description>
      <author>example@mail.com (Jiacheng Shi, Yanfu Zhang, Ye Gao)</author>
      <guid isPermaLink="false">2507.04048v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Taming Anomalies with Down-Up Sampling Networks: Group Center Preserving Reconstruction for 3D Anomaly Detection</title>
      <link>http://arxiv.org/abs/2507.03903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM MM25 Accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于重建的3D异常检测方法，通过Down-Up Sampling Network (DUS-Net)对高精度点云进行重建，以保留群中心几何结构，提高了异常检测的性能。&lt;h4&gt;背景&lt;/h4&gt;重建方法在3D异常检测中显示出很有前景的结果，但在处理大规模和复杂结构的高精度点云时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来重建高精度点云，以实现更精确的3D异常检测。&lt;h4&gt;方法&lt;/h4&gt;DUS-Net包括噪声生成模块、下采样网络和上采样网络。噪声生成模块用于生成噪声补丁，下采样网络用于从含噪声的补丁中学习无异常的中心点云，上采样网络用于融合多尺度上采样特征来重建高精度点云。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在Real3D-AD和Anomaly-ShapeNet数据集上分别达到了79.9%和79.5%的对象级AUROC以及71.2%和84.7%的点级AUROC，实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DUS-Net能够有效重建高精度点云，在3D异常检测中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstruction-based methods have demonstrated very promising results for 3Danomaly detection. However, these methods face great challenges in handlinghigh-precision point clouds due to the large scale and complex structure. Inthis study, a Down-Up Sampling Network (DUS-Net) is proposed to reconstructhigh-precision point clouds for 3D anomaly detection by preserving the groupcenter geometric structure. The DUS-Net first introduces a Noise Generationmodule to generate noisy patches, which facilitates the diversity of trainingdata and strengthens the feature representation for reconstruction. Then, aDown-sampling Network~(Down-Net) is developed to learn an anomaly-free centerpoint cloud from patches with noise injection. Subsequently, an Up-samplingNetwork (Up-Net) is designed to reconstruct high-precision point clouds byfusing multi-scale up-sampling features. Our method leverages group centers forconstruction, enabling the preservation of geometric structure and providing amore precise point cloud. Extensive experiments demonstrate the effectivenessof our proposed method, achieving state-of-the-art (SOTA) performance with anObject-level AUROC of 79.9% and 79.5%, and a Point-level AUROC of 71.2% and84.7% on the Real3D-AD and Anomaly-ShapeNet datasets, respectively.</description>
      <author>example@mail.com (Hanzhe Liang, Jie Zhang, Tao Dai, Linlin Shen, Jinbao Wang, Can Gao)</author>
      <guid isPermaLink="false">2507.03903v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Transformer with Koopman-Enhanced Graph Convolutional Network for Spatiotemporal Dynamics Forecasting</title>
      <link>http://arxiv.org/abs/2507.03855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TK-GCN是一种两阶段框架，用于解决不规则几何域上的时空动态预测问题，通过结合几何感知空间编码和长程时间建模来捕捉复杂的空间相关性和非线性时间动态。&lt;h4&gt;背景&lt;/h4&gt;时空动态预测在不规则几何域上具有挑战性，因为需要同时捕捉复杂的空间相关性和非线性时间动态。&lt;h4&gt;目的&lt;/h4&gt;提出TK-GCN框架以解决时空动态预测的挑战。&lt;h4&gt;方法&lt;/h4&gt;TK-GCN分为两个阶段：第一阶段使用Koopman增强的图卷积网络（K-GCN）将不规则空间域上的高维动态嵌入到潜在空间中，该空间中系统状态的演化近似线性；第二阶段使用Transformer模块在Koopman编码的潜在空间中建模时间进程，通过自注意力机制捕捉长程时间依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果和消融研究表明，TK-GCN在多个预测范围内提供了优越的预测精度，证明了其有效建模复杂空间结构和非线性时间动态的能力。&lt;h4&gt;结论&lt;/h4&gt;TK-GCN在时空动态预测中表现出色，是一种有效的框架来处理不规则几何域上的复杂时空动态。&lt;h4&gt;翻译&lt;/h4&gt;Spatiotemporal dynamics forecasting is inherently challenging, particularly in systems defined over irregular geometric domains, due to the need to jointly capture complex spatial correlations and nonlinear temporal dynamics. To tackle these challenges, we propose TK-GCN, a two-stage framework that integrates geometry-aware spatial encoding with long-range temporal modeling. In the first stage, a Koopman-enhanced Graph Convolutional Network (K-GCN) is developed to embed the high-dimensional dynamics distributed on spatially irregular domains into a latent space where the evolution of system states is approximately linear. By leveraging Koopman operator theory, this stage enhances the temporal consistency during the latent learning. In the second stage, a Transformer module is employed to model the temporal progression within the Koopman-encoded latent space. Through the self-attention mechanism, the Transformer captures long-range temporal dependencies, enabling accurate forecasting over extended horizons. We evaluate TK-GCN in spatiotemporal cardiac dynamics forecasting and benchmark its performance against several state-of-the-art baselines. Experimental results and ablation studies show that TK-GCN consistently delivers superior predictive accuracy across a range of forecast horizons, demonstrating its capability to effectively model complex spatial structures and nonlinear temporal dynamics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal dynamics forecasting is inherently challenging, particularlyin systems defined over irregular geometric domains, due to the need to jointlycapture complex spatial correlations and nonlinear temporal dynamics. To tacklethese challenges, we propose TK-GCN, a two-stage framework that integratesgeometry-aware spatial encoding with long-range temporal modeling. In the firststage, a Koopman-enhanced Graph Convolutional Network (K-GCN) is developed toembed the high-dimensional dynamics distributed on spatially irregular domainsinto a latent space where the evolution of system states is approximatelylinear. By leveraging Koopman operator theory, this stage enhances the temporalconsistency during the latent learning. In the second stage, a Transformermodule is employed to model the temporal progression within the Koopman-encodedlatent space. Through the self-attention mechanism, the Transformer captureslong-range temporal dependencies, enabling accurate forecasting over extendedhorizons. We evaluate TK-GCN in spatiotemporal cardiac dynamics forecasting andbenchmark its performance against several state-of-the-art baselines.Experimental results and ablation studies show that TK-GCN consistentlydelivers superior predictive accuracy across a range of forecast horizons,demonstrating its capability to effectively model complex spatial structuresand nonlinear temporal dynamics.</description>
      <author>example@mail.com (Zekai Wang, Bing Yao)</author>
      <guid isPermaLink="false">2507.03855v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Kolmogorov-Arnold Network Expansions in Vision Transformers for Mitigating Catastrophic Forgetting in Continual Learning</title>
      <link>http://arxiv.org/abs/2507.04020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究提出将Kolmogorov-Arnold Network (KANs)应用于视觉变换器（ViTs）中，以解决在多层感知器（MLPs）进行全局表征学习时出现的灾难性遗忘问题。&lt;h4&gt;背景&lt;/h4&gt;灾难性遗忘在视觉变换器（ViTs）中是一个关键挑战，尤其是当这些模型使用MLPs进行全局表征学习时。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过使用KANs代替MLPs，在ViTs中实现持续学习（CL），即模型在学习新任务时不遗忘之前获得的知识。&lt;h4&gt;方法&lt;/h4&gt;该方法通过使用基于样条激活的局部可塑性来确保每个样本只更新参数的子集，从而保护先前学习到的知识。研究在MNIST和CIFAR100等基准数据集上测试了基于KAN的ViTs在持续学习场景中的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于KAN的ViTs显著减轻了灾难性遗忘，在知识保留和任务适应方面优于传统的基于MLP的ViTs。&lt;h4&gt;结论&lt;/h4&gt;将KANs集成到ViTs中为创建更稳健和适应性强的新型模型提供了有希望的步骤，这些模型适用于动态环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL), the ability of a model to learn new tasks withoutforgetting previously acquired knowledge, remains a critical challenge inartificial intelligence, particularly for vision transformers (ViTs) utilizingMultilayer Perceptrons (MLPs) for global representation learning. Catastrophicforgetting, where new information overwrites prior knowledge, is especiallyproblematic in these models. This research proposes replacing MLPs in ViTs withKolmogorov-Arnold Network (KANs) to address this issue. KANs leverage localplasticity through spline-based activations, ensuring that only a subset ofparameters is updated per sample, thereby preserving previously learnedknowledge. The study investigates the efficacy of KAN-based ViTs in CLscenarios across benchmark datasets (MNIST, CIFAR100), focusing on theirability to retain accuracy on earlier tasks while adapting to new ones.Experimental results demonstrate that KAN-based ViTs significantly mitigatecatastrophic forgetting, outperforming traditional MLP-based ViTs in knowledgeretention and task adaptation. This novel integration of KANs into ViTsrepresents a promising step toward more robust and adaptable models for dynamicenvironments.</description>
      <author>example@mail.com (Zahid Ullah, Jihie Kim)</author>
      <guid isPermaLink="false">2507.04020v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MMOC: Self-Supervised EEG Emotion Recognition Framework with Multi-Model Online Collaboration</title>
      <link>http://arxiv.org/abs/2507.03977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MMOC的自监督学习框架，用于解决EEG情感识别中的数据漂移问题，并通过实验验证了其在SEED和Dreamer数据集上的优越性能。&lt;h4&gt;背景&lt;/h4&gt;EEG情感识别在人类-计算机交互中具有重要意义，但传统的监督学习方法依赖于人工标注，成本高且存在偏差。自监督学习通过预训练任务生成标签，但EEG信号的主体间差异性导致数据漂移，限制了模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出MMOC框架，以实现针对未见数据的在线自适应调整，从而提高EEG情感识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;MMOC使用多种基于重建和对比学习的策略训练多个基础模型，以发展不同的泛化能力。在推理过程中，通过评估对比和重建损失的双重视角动态激活最合适的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在SEED和Dreamer数据集上，MMOC在结构层面和语义层面的数据漂移上都取得了显著的缓解，实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;MMOC框架有效地减轻了主体间数据漂移，为现实世界的EEG情感识别提供了一个实用的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a self-supervised learning framework called MMOC to address the data drift problem in EEG emotion recognition and demonstrates its superior performance on the SEED and Dreamer datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroencephalography (EEG) emotion recognition plays a crucial role inhuman-computer interaction, particularly in healthcare and neuroscience. Whilesupervised learning has been widely used, its reliance on manual annotationsintroduces high costs and potential bias. Self-supervised learning (SSL) offersa promising alternative by generating labels through pretext tasks. However,high inter-subject variability in EEG signals leads to significant data drift,limiting self-supervised models' generalization across unseen subjects.Traditional domain adaptation (DA) methods require access to target-domain dataduring training. Although domain generalization (DG) avoids this constraint, itoften falls short in handling complex data drift due to limited coverage ofpossible target distributions. To tackle these challenges, we propose MMOC, aself-supervised framework with multi-model online collaboration (MMOC), toachieve online adaptation to unseen data. MMOC trains multiple base modelsusing diverse strategies rooted in reconstruction and contrastive learning,enabling each model to develop distinct generalization capabilities. Duringinference, MMOC dynamically activates the most suitable model for each testsample via a loss-based routing mechanism that evaluates both contrastive andreconstruction losses. This dual consideration allows for a comprehensivemeasurement of data drift at both structural and semantic levels. Experimentalresults on the SEED and Dreamer datasets show that MMOC achievesstate-of-the-art performance: 85.39% on SEED, and 68.77% and 69.37% on Dreamerarousal and valence dimensions, respectively. MMOC effectively mitigatesinter-subject data drift, offering a practical solution for real-world EEGemotion recognition.</description>
      <author>example@mail.com (Hanqi Wang, Yang Liu, Peng Ye, Liang Song)</author>
      <guid isPermaLink="false">2507.03977v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Effective Capacitance Modeling Using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.03787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的静态时序分析后布局有效电容建模方法GNN-Ceff，该方法在GPU并行化下实现了显著的加速，同时比现有启发式方法提供了更高的精度。&lt;h4&gt;背景&lt;/h4&gt;静态时序分析是VLSI设计流程中的关键阶段，用于验证电路的时序正确性。时序分析依赖于设计的布局和布线，而布局和布线的效率又依赖于最终的时序性能。&lt;h4&gt;目的&lt;/h4&gt;通过时序相关的预测来提高VLSI设计流程早期阶段的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于GNN的GNN-Ceff模型，用于计算有效电容，该方法在GPU并行化下运行，提高了计算速度。&lt;h4&gt;主要发现&lt;/h4&gt;GNN-Ceff模型在真实基准测试中相对于串行运行的现有最先进方法实现了929倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;GNN-Ceff模型在保持较高精度的同时，显著提高了有效电容计算的效率，对VLSI设计流程的时序分析阶段具有积极意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Static timing analysis is a crucial stage in the VLSI design flow thatverifies the timing correctness of circuits. Timing analysis depends on theplacement and routing of the design, but at the same time, placement androuting efficiency depend on the final timing performance. VLSI design flowscan benefit from timing-related prediction to better perform the earlier stagesof the design flow. Effective capacitance is an essential input for gate delaycalculation, and finding exact values requires routing or routing estimates. Inthis work, we propose the first GNN-based post-layout effective capacitancemodeling method, GNN-Ceff, that achieves significant speed gains due to GPUparallelization while also providing better accuracy than current heuristics.GNN-Ceff parallelization achieves 929x speedup on real-life benchmarks over thestate-of-the-art method run serially.</description>
      <author>example@mail.com (Eren Dogan, Matthew R. Guthaus)</author>
      <guid isPermaLink="false">2507.03787v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach</title>
      <link>http://arxiv.org/abs/2507.02205v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的零样本多模态方法，用于复杂情感状态识别，该方法结合了六种异构模态，包括静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。&lt;h4&gt;背景&lt;/h4&gt;复合情感识别（CER）是情感计算的一个子领域，旨在检测由基本情感组合而成的复杂情感状态。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效识别复合情感状态的新方法，无需对特定任务进行训练。&lt;h4&gt;方法&lt;/h4&gt;该方法使用零样本组件，如基于CLIP的标签匹配和Qwen-VL进行语义场景理解。此外，还引入了MHPF模块和CE转换模块，分别用于动态加权模态特定预测和产生可解释的复合情感输出。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，通过零样本测试与在目标数据上训练的监督方法的结果相当。&lt;h4&gt;结论&lt;/h4&gt;该方法在无需域适应的情况下，有效地捕捉了复合情感状态，证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: This paper presents a novel zero-shot multimodal approach for Compound Expression Recognition (CER) that combines six heterogeneous modalities, including static and dynamic facial expressions, scene and label matching, scene context, audio, and text. The method utilizes zero-shot components such as CLIP-based label matching and Qwen-VL for semantic scene understanding. Additionally, a Multi-Head Probability Fusion (MHPF) module and a Compound Expressions (CE) transformation module are introduced to dynamically weight modality-specific predictions and produce interpretable compound emotion outputs, respectively. Evaluated under multi-corpora training, the proposed approach achieves F1 scores of 46.95% on AffWild2, 49.02% on AFEW, and 34.85% on C-EXPR-DB via zero-shot testing, which is comparable to the results of supervised approaches trained on target data. This demonstrates the effectiveness of the proposed approach for capturing CE without domain adaptation. The source code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound Expression Recognition (CER), a subfield of affective computing,aims to detect complex emotional states formed by combinations of basicemotions. In this work, we present a novel zero-shot multimodal approach forCER that combines six heterogeneous modalities into a single pipeline: staticand dynamic facial expressions, scene and label matching, scene context, audio,and text. Unlike previous approaches relying on task-specific training data,our approach uses zero-shot components, including Contrastive Language-ImagePretraining (CLIP)-based label matching and Qwen-VL for semantic sceneunderstanding. We further introduce a Multi-Head Probability Fusion (MHPF)module that dynamically weights modality-specific predictions, followed by aCompound Expressions (CE) transformation module that uses Pair-Wise ProbabilityAggregation (PPA) and Pair-Wise Feature Similarity Aggregation (PFSA) methodsto produce interpretable compound emotion outputs. Evaluated under multi-corpustraining, the proposed approach shows F1 scores of 46.95% on AffWild2, 49.02%on Acted Facial Expressions in The Wild (AFEW), and 34.85% on C-EXPR-DB viazero-shot testing, which is comparable to the results of supervised approachestrained on target data. This demonstrates the effectiveness of the proposedapproach for capturing CE without domain adaptation. The source code ispublicly available.</description>
      <author>example@mail.com (Elena Ryumina, Maxim Markitantov, Alexandr Axyonov, Dmitry Ryumin, Mikhail Dolgushin, Alexey Karpov)</author>
      <guid isPermaLink="false">2507.02205v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Handling Korean Out-of-Vocabulary Words with Phoneme Representation Learning</title>
      <link>http://arxiv.org/abs/2507.04018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究介绍了一种名为KOPL的框架，用于处理韩语未登录词汇，通过音素表示学习来处理。该框架结合了音素和词汇表示，在韩语自然语言处理任务中表现出色，且易于集成到现有的韩语嵌入模型中。&lt;h4&gt;背景&lt;/h4&gt;基于韩语作为音素文字的特点以及音素和字母之间的高相关性。&lt;h4&gt;目的&lt;/h4&gt;通过音素表示学习，为韩语未登录词汇提供文本和音素信息，提高韩语自然语言处理任务的表现。&lt;h4&gt;方法&lt;/h4&gt; KOPL框架结合了音素和词汇表示，通过这种方式捕捉词汇的文本和音素信息。&lt;h4&gt;主要发现&lt;/h4&gt;KOPL在韩语自然语言处理任务上显著提高了性能，并且平均比现有最先进的模型高出1.9%。&lt;h4&gt;结论&lt;/h4&gt;KOPL可以有效地处理韩语未登录词汇，并且易于集成到现有的韩语嵌入模型中，是提高韩语自然语言处理性能的有力工具。&lt;h4&gt;翻译&lt;/h4&gt;在本次研究中，我们引入了一种名为KOPL的新框架，用于处理韩语的未登录词汇，它通过音素表示学习来实现。本研究基于韩语作为音素文字的语言特性以及音素与字母之间的高度相关性。KOPL集成了音素和词汇表示，以便于为韩语的未登录词汇提供文本和音素信息，从而捕获词汇的文本和音素信息。通过实证研究，我们发现KOPL在韩语自然语言处理任务上的性能显著提升，并且可以轻松地以即插即用的方式集成到现有的静态和上下文相关的韩语嵌入模型中。值得注意的是，我们展示KOPL的平均性能比现有最先进的模型高出1.9%。我们的代码可在https://github.com/jej127/KOPL.git上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-981-96-8180-8_38&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we introduce KOPL, a novel framework for handling Korean OOVwords with Phoneme representation Learning. Our work is based on the linguisticproperty of Korean as a phonemic script, the high correlation between phonemesand letters. KOPL incorporates phoneme and word representations for Korean OOVwords, facilitating Korean OOV word representations to capture both text andphoneme information of words. We empirically demonstrate that KOPLsignificantly improves the performance on Korean Natural Language Processing(NLP) tasks, while being readily integrated into existing static and contextualKorean embedding models in a plug-and-play manner. Notably, we show that KOPLoutperforms the state-of-the-art model by an average of 1.9%. Our code isavailable at https://github.com/jej127/KOPL.git.</description>
      <author>example@mail.com (Nayeon Kim, Eojin Jeon, Jun-Hyung Park, SangKeun Lee)</author>
      <guid isPermaLink="false">2507.04018v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CosmoBench: A Multiscale, Multiview, Multitask Cosmology Benchmark for Geometric Deep Learning</title>
      <link>http://arxiv.org/abs/2507.03707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CosmoBench，一个由高级宇宙学模拟生成的数据集，用于从宇宙学数据中提取有关宇宙性质和组成的信息。&lt;h4&gt;背景&lt;/h4&gt;宇宙学模拟生成了大量的数据，包括点云和有向树，这些数据对于理解宇宙至关重要。&lt;h4&gt;目的&lt;/h4&gt;CosmoBench的目的是提供一个基准数据集，用于研究宇宙学参数、星系速度以及合并树的重构。&lt;h4&gt;方法&lt;/h4&gt;CosmoBench包含来自不同长度尺度上暗物质晕和星系模拟的3.4万个点云，以及记录两个不同时间尺度上的晕形成历史的2.5万个有向树。数据可用于多个任务，并提供了基于宇宙学建模和机器学习方法的基准。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，使用少数不变特征的简单线性模型有时优于参数更多且训练时间更长的深度架构。同时，通过结合机器学习和宇宙学，有很大的潜力改进这些基准。&lt;h4&gt;结论&lt;/h4&gt;CosmoBench为在规模上连接宇宙学和几何深度学习奠定了基础，并邀请社区参与使用这个数据集推动科学发现。&lt;h4&gt;翻译&lt;/h4&gt;摘要：宇宙学模拟提供了大量的点云和有向树形式的数据。一个关键目标是从这个数据中提取关于宇宙性质和组成的洞察。在本文中，我们引入了CosmoBench，这是一个来自最先进宇宙学模拟的基准数据集，其运行需要超过4100万核心小时并产生了超过两拍的数据。CosmoBench是这个类别的最大数据集：它包含34,000个点云，来自模拟不同长度尺度的暗物质晕和星系，以及25,000个记录两个不同时间尺度上的晕形成历史的有向树。CosmoBench中的数据可用于多个任务，包括从点云和合并树中预测宇宙学参数，从星系的集体位置中预测单个晕和星系的速度，以及从较粗时间尺度上的合并树中重构更细时间尺度上的合并树。我们在这些任务上提供了几个基准，一些基于宇宙学建模中建立的方法，其他则植根于机器学习。对于后者，我们研究了不同的方法，从受对称性最小约束的简单线性模型到深度学习中更大、计算上更具挑战性的模型，如图神经网络。我们发现，使用少数不变特征的平方拟合有时优于具有更多参数和远更长训练时间的深度架构。尽管如此，通过结合机器学习和宇宙学来充分利用数据，仍存在巨大的改进潜力。CosmoBench为在规模上连接宇宙学和几何深度学习奠定了基础。我们邀请社区通过参与这个数据集来推动科学发现的边界，数据集可在https://cosmobench.streamlit.app获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cosmological simulations provide a wealth of data in the form of point cloudsand directed trees. A crucial goal is to extract insights from this data thatshed light on the nature and composition of the Universe. In this paper weintroduce CosmoBench, a benchmark dataset curated from state-of-the-artcosmological simulations whose runs required more than 41 million core-hoursand generated over two petabytes of data. CosmoBench is the largest dataset ofits kind: it contains 34 thousand point clouds from simulations of dark matterhalos and galaxies at three different length scales, as well as 25 thousanddirected trees that record the formation history of halos on two different timescales. The data in CosmoBench can be used for multiple tasks -- to predictcosmological parameters from point clouds and merger trees, to predict thevelocities of individual halos and galaxies from their collective positions,and to reconstruct merger trees on finer time scales from those on coarser timescales. We provide several baselines on these tasks, some based on establishedapproaches from cosmological modeling and others rooted in machine learning.For the latter, we study different approaches -- from simple linear models thatare minimally constrained by symmetries to much larger and morecomputationally-demanding models in deep learning, such as graph neuralnetworks. We find that least-squares fits with a handful of invariant featuressometimes outperform deep architectures with many more parameters and farlonger training times. Still there remains tremendous potential to improvethese baselines by combining machine learning and cosmology to fully exploitthe data. CosmoBench sets the stage for bridging cosmology and geometric deeplearning at scale. We invite the community to push the frontier of scientificdiscovery by engaging with this dataset, available athttps://cosmobench.streamlit.app</description>
      <author>example@mail.com (Ningyuan Huang, Richard Stiskalek, Jun-Young Lee, Adrian E. Bayer, Charles C. Margossian, Christian Kragh Jespersen, Lucia A. Perez, Lawrence K. Saul, Francisco Villaescusa-Navarro)</author>
      <guid isPermaLink="false">2507.03707v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2507.01961v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://ac-dit.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AC-DiT的适应性协调扩散变换器，用于提高移动基座和机械臂在端到端移动操作中的协调性。&lt;h4&gt;背景&lt;/h4&gt;移动操作在家庭任务中实现语言条件下的机器人控制引起了广泛关注，但现有方法在协调移动基座和机械臂方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的局限性，提出AC-DiT以增强移动基座和机械臂的协调性。&lt;h4&gt;方法&lt;/h4&gt;AC-DiT包括引入移动到身体的条件机制，用于首先提取基座运动表示，并将其作为预测全身动作的上下文先验。此外，设计了感知感知的多模态条件策略，以动态调整不同2D视觉图像和3D点云之间的融合权重。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，AC-DiT在模拟和真实世界的移动操作任务中均有效。&lt;h4&gt;结论&lt;/h4&gt;AC-DiT能够有效地提高移动操作中的基座和机械臂协调性，并满足不同阶段的感知需求。&lt;h4&gt;翻译&lt;/h4&gt;最近，移动操作引起了越来越多的关注，以实现家庭任务中的语言条件机器人控制。然而，现有方法在协调移动基座和机械臂方面仍面临挑战，主要由于两个局限性。一方面，它们未能明确建模移动基座对机械臂控制的影响，这容易在高自由度下导致误差累积。另一方面，它们以相同的视觉观察模式（例如，要么全部2D，要么全部3D）处理整个移动操作过程，忽视了移动操作不同阶段的独特多模态感知需求。为了解决这个问题，我们提出了适应性协调扩散变换器（AC-DiT），它增强了移动基座和机械臂的端到端移动操作协调性。首先，由于移动基座的运动直接影响机械臂的动作，我们引入了一种移动到身体的条件机制，引导模型首先提取基座运动表示，然后将其用作预测全身动作的上下文先验。这使全身控制能够考虑到移动基座运动的影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件策略，动态调整各种2D视觉图像和3D点云之间的融合权重，产生符合当前感知需求的视觉特征。这使得模型能够，例如，在语义信息对动作预测至关重要时，自适应地更多地依赖于2D输入，而在需要精确空间理解时，则更加重视3D几何信息。我们通过在模拟和真实世界的移动操作任务上的广泛实验验证了AC-DiT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, mobile manipulation has attracted increasing attention for enablinglanguage-conditioned robotic control in household tasks. However, existingmethods still face challenges in coordinating mobile base and manipulator,primarily due to two limitations. On the one hand, they fail to explicitlymodel the influence of the mobile base on manipulator control, which easilyleads to error accumulation under high degrees of freedom. On the other hand,they treat the entire mobile manipulation process with the same visualobservation modality (e.g., either all 2D or all 3D), overlooking the distinctmultimodal perception requirements at different stages during mobilemanipulation. To address this, we propose the Adaptive Coordination DiffusionTransformer (AC-DiT), which enhances mobile base and manipulator coordinationfor end-to-end mobile manipulation. First, since the motion of the mobile basedirectly influences the manipulator's actions, we introduce a mobility-to-bodyconditioning mechanism that guides the model to first extract base motionrepresentations, which are then used as context prior for predicting whole-bodyactions. This enables whole-body control that accounts for the potential impactof the mobile base's motion. Second, to meet the perception requirements atdifferent stages of mobile manipulation, we design a perception-awaremultimodal conditioning strategy that dynamically adjusts the fusion weightsbetween various 2D visual images and 3D point clouds, yielding visual featurestailored to the current perceptual needs. This allows the model to, forexample, adaptively rely more on 2D inputs when semantic information is crucialfor action prediction, while placing greater emphasis on 3D geometricinformation when precise spatial understanding is required. We validate AC-DiTthrough extensive experiments on both simulated and real-world mobilemanipulation tasks.</description>
      <author>example@mail.com (Sixiang Chen, Jiaming Liu, Siyuan Qian, Han Jiang, Lily Li, Renrui Zhang, Zhuoyang Liu, Chenyang Gu, Chengkai Hou, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.01961v3</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Knowledge Transferability for Transfer Learning: A Survey</title>
      <link>http://arxiv.org/abs/2507.03175v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 15 figures, submitted to ACM Computing Surveys&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文讨论了迁移学习在人工智能中的应用，提出了一个统一的迁移度量分类法，并分析了不同度量指标的适用性和挑战。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是通过将源任务中的知识迁移到目标任务来提高性能的一种方法。尽管这种方法在计算机视觉和自然语言处理等领域取得了成功，但如何可靠地评估知识的迁移性仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;论文的目的是提供一种统一的迁移度量分类法，分析不同度量指标在迁移学习中的应用，并指导研究人员和实践者选择最合适的度量指标。&lt;h4&gt;方法&lt;/h4&gt;论文通过分类迁移度量指标，基于可迁移知识类型和度量粒度进行分类，并考察了这些指标在不同学习范式下的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;论文强调了选择合适的迁移度量指标的重要性，并提供了不同度量指标在不同条件下的工作原理。&lt;h4&gt;结论&lt;/h4&gt;论文讨论了迁移学习领域中的开放性挑战，并提出了未来研究的方向。&lt;h4&gt;翻译&lt;/h4&gt;这篇论文探讨了迁移学习在人工智能中的应用，提出了一个统一的迁移度量分类法，并分析了不同度量指标的适用性和挑战。尽管迁移学习在计算机视觉和自然语言处理等领域取得了成功，但如何可靠地评估知识的迁移性仍然是一个挑战。论文的目的是提供一种统一的迁移度量分类法，分析不同度量指标在迁移学习中的应用，并指导研究人员和实践者选择最合适的度量指标。通过分类迁移度量指标，基于可迁移知识类型和度量粒度进行分类，并考察了这些指标在不同学习范式下的适用性。论文强调了选择合适的迁移度量指标的重要性，并提供了不同度量指标在不同条件下的工作原理。论文还讨论了迁移学习领域中的开放性挑战，并提出了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning has become an essential paradigm in artificialintelligence, enabling the transfer of knowledge from a source task to improveperformance on a target task. This approach, particularly through techniquessuch as pretraining and fine-tuning, has seen significant success in fieldslike computer vision and natural language processing. However, despite itswidespread use, how to reliably assess the transferability of knowledge remainsa challenge. Understanding the theoretical underpinnings of eachtransferability metric is critical for ensuring the success of transferlearning. In this survey, we provide a unified taxonomy of transferabilitymetrics, categorizing them based on transferable knowledge types andmeasurement granularity. This work examines the various metrics developed toevaluate the potential of source knowledge for transfer learning and theirapplicability across different learning paradigms emphasizing the need forcareful selection of these metrics. By offering insights into how differentmetrics work under varying conditions, this survey aims to guide researchersand practitioners in selecting the most appropriate metric for specificapplications, contributing to more efficient, reliable, and trustworthy AIsystems. Finally, we discuss some open challenges in this field and proposefuture research directions to further advance the application oftransferability metrics in trustworthy transfer learning.</description>
      <author>example@mail.com (Haohua Wang, Jingge Wang, Zijie Zhao, Yang Tan, Yanru Wu, Hanbing Liu, Jingyun Yang, Enming Zhang, Xiangyu Chen, Zhengze Rong, Shanxin Guo, Yang Li)</author>
      <guid isPermaLink="false">2507.03175v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MCST-Mamba: Multivariate Mamba-Based Model for Traffic Prediction</title>
      <link>http://arxiv.org/abs/2507.03927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the Communications Software and Multimedia track of the  2025 IEEE Global Communications Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MCST-Mamba的多通道时空模型，用于解决交通预测的挑战，该模型在智能交通系统中发挥着重要作用。&lt;h4&gt;背景&lt;/h4&gt;精确的交通预测对于智能交通系统至关重要，但预测因动态路况、不同地点的交通模式变化以及天气和事故等外部因素而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够同时处理多个交通特征并提高预测性能的模型。&lt;h4&gt;方法&lt;/h4&gt;MCST-Mamba模型基于Mamba选择性状态空间架构，通过自适应时空嵌入和将时间序列建模和空间传感器交互建模分离到两个专用的Mamba块中，以改进表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;与之前只评估单个通道的方法不同，MCST-Mamba同时评估所有交通特征，其结果表明，与基线模型相比，MCST-Mamba在具有更低的参数数量时实现了更强的预测性能。&lt;h4&gt;结论&lt;/h4&gt;MCST-Mamba模型能够有效预测交通数据，提高了预测性能并减少了模型复杂度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate traffic prediction plays a vital role in intelligent transportationsystems by enabling efficient routing, congestion mitigation, and proactivetraffic control. However, forecasting is challenging due to the combinedeffects of dynamic road conditions, varying traffic patterns across differentlocations, and external influences such as weather and accidents. Traffic dataoften consists of several interrelated measurements - such as speed, flow andoccupancy - yet many deep-learning approaches either predict only one of thesevariables or require a separate model for each. This limits their ability tocapture joint patterns across channels. To address this, we introduce theMulti-Channel Spatio-Temporal (MCST) Mamba model, a forecasting framework builton the Mamba selective state-space architecture that natively handlesmultivariate inputs and simultaneously models all traffic features. Theproposed MCST-Mamba model integrates adaptive spatio-temporal embeddings andseparates the modeling of temporal sequences and spatial sensor interactionsinto two dedicated Mamba blocks, improving representation learning. Unlikeprior methods that evaluate on a single channel, we assess MCST-Mamba acrossall traffic features at once, aligning more closely with how congestion arisesin practice. Our results show that MCST-Mamba achieves strong predictiveperformance with a lower parameter count compared to baseline models.</description>
      <author>example@mail.com (Mohamed Hamad, Mohamed Mabrok, Nizar Zorba)</author>
      <guid isPermaLink="false">2507.03927v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>SeqTex: Generate Mesh Textures in Video Sequence</title>
      <link>http://arxiv.org/abs/2507.04285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SeqTex的端到端框架，用于生成完整的UV纹理图。&lt;h4&gt;背景&lt;/h4&gt;由于大规模、高质量的3D纹理数据集的稀缺，训练原生3D纹理生成模型是一个基本但具有挑战性的问题，这阻碍了模型在现实场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了解决这个问题，本文提出了一种方法，通过微调基础图像生成模型来利用其学习的视觉先验，并直接生成UV纹理图。&lt;h4&gt;方法&lt;/h4&gt;SeqTex框架利用预训练的视频基础模型中的视觉知识，将任务重构为序列生成问题，使模型能够学习多视角渲染和UV纹理的联合分布。此外，提出了耦合的多视角和UV分支设计、几何信息引导的注意力机制以及自适应令牌分辨率等技术。&lt;h4&gt;主要发现&lt;/h4&gt;SeqTex在图像条件和文本条件的3D纹理生成任务上均达到了最先进的性能，具有优异的3D一致性、纹理-几何对齐和现实世界的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;SeqTex能够有效利用预训练视频先验，合成高保真的UV纹理图，而不需要后处理，从而提高了纹理生成的效率和效果。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Training native 3D texture generative models remains a fundamental yet challenging problem, largely due to the limited availability of large-scale, high-quality 3D texture datasets. This scarcity hinders generalization to real-world scenarios. To address this, most existing methods fine-tune foundation image generative models to exploit their learned visual priors. However, these approaches typically generate only multi-view images and rely on post-processing to produce UV texture maps -- an essential representation in modern graphics pipelines. Such two-stage pipelines often suffer from error accumulation and spatial inconsistencies across the 3D surface. In this paper, we introduce SeqTex, a novel end-to-end framework that leverages the visual knowledge encoded in pretrained video foundation models to directly generate complete UV texture maps. Unlike previous methods that model the distribution of UV textures in isolation, SeqTex reformulates the task as a sequence generation problem, enabling the model to learn the joint distribution of multi-view renderings and UV textures. This design effectively transfers the consistent image-space priors from video foundation models into the UV domain. To further enhance performance, we propose several architectural innovations: a coupled multi-view and UV branch design, geometry-informed attention to guide cross-domain feature alignment, and adaptive token resolution to preserve fine texture details while maintaining computational efficiency. Together, these components allow SeqTex to fully utilize pretrained video priors and synthesize high-fidelity UV texture maps without the need for post-processing. Extensive experiments show that SeqTex achieves state-of-the-art performance on both image-conditioned and text-conditioned 3D texture generation tasks, with superior 3D consistency, texture-geometry alignment, and real-world generalization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training native 3D texture generative models remains a fundamental yetchallenging problem, largely due to the limited availability of large-scale,high-quality 3D texture datasets. This scarcity hinders generalization toreal-world scenarios. To address this, most existing methods finetunefoundation image generative models to exploit their learned visual priors.However, these approaches typically generate only multi-view images and rely onpost-processing to produce UV texture maps -- an essential representation inmodern graphics pipelines. Such two-stage pipelines often suffer from erroraccumulation and spatial inconsistencies across the 3D surface. In this paper,we introduce SeqTex, a novel end-to-end framework that leverages the visualknowledge encoded in pretrained video foundation models to directly generatecomplete UV texture maps. Unlike previous methods that model the distributionof UV textures in isolation, SeqTex reformulates the task as a sequencegeneration problem, enabling the model to learn the joint distribution ofmulti-view renderings and UV textures. This design effectively transfers theconsistent image-space priors from video foundation models into the UV domain.To further enhance performance, we propose several architectural innovations: adecoupled multi-view and UV branch design, geometry-informed attention to guidecross-domain feature alignment, and adaptive token resolution to preserve finetexture details while maintaining computational efficiency. Together, thesecomponents allow SeqTex to fully utilize pretrained video priors and synthesizehigh-fidelity UV texture maps without the need for post-processing. Extensiveexperiments show that SeqTex achieves state-of-the-art performance on bothimage-conditioned and text-conditioned 3D texture generation tasks, withsuperior 3D consistency, texture-geometry alignment, and real-worldgeneralization.</description>
      <author>example@mail.com (Ze Yuan, Xin Yu, Yangtian Sun, Yuan-Chen Guo, Yan-Pei Cao, Ding Liang, Xiaojuan Qi)</author>
      <guid isPermaLink="false">2507.04285v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Plugging Attention into Power Grids: Towards Transparent Forecasting</title>
      <link>http://arxiv.org/abs/2507.03690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用图神经网络（GNNs）进行准确电力消耗预测，以提高电网稳定性和优化发电。&lt;h4&gt;背景&lt;/h4&gt;经典的预测方法如广义加性模型（GAMs）在处理空间依赖性方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;评估不同GNN架构在电力消耗预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;对GCN、GraphSAGE、ChebConv、TAG、APPNP、TransformerConv、GAT和GATv2等架构进行评估，并使用法国和英国的电力消耗数据集。&lt;h4&gt;主要发现&lt;/h4&gt;复杂架构如GATv2和TransformerConv并不总是优于简单架构，但GCN和APPNP在低数据或高度分解的场景中表现良好。GAT在两个数据集上都具有竞争力，并通过注意力机制提供额外的可解释性。注意力权重的时序分析揭示了与季节和气象变异性相关的区域互动模式。注意力机制在空间依赖性明显时提供了有价值的解释能力。&lt;h4&gt;结论&lt;/h4&gt;尽管注意力机制并非在所有情况下都优于其他方法，但在处理空间依赖性时具有解释力。集成专家聚合策略能够增强鲁棒性，在数据异质性下优于单个模型。&lt;h4&gt;翻译&lt;/h4&gt;精准的电力消耗预测对于确保电网稳定性和优化发电至关重要，尤其是在日益分散和复杂的系统中。虽然广义加性模型（GAMs）等传统方法仍然被广泛使用，但它们往往无法捕捉能源网络中固有的空间依赖性。图神经网络（GNNs）提供了一种原则性的框架，通过直接利用图拓扑结构来整合这种结构。在这项工作中，我们评估了一系列GNN架构——包括GCN、GraphSAGE、ChebConv、TAG、APPNP、TransformerConv、图注意力网络（GAT和GATv2）——在两个来自法国和英国的真实电力消耗数据集上的表现。我们的实验表明，虽然复杂架构如GATv2和TransformerConv并不一致优于其简单版本，但GCN和APPNP在低数据或高度分解的设置中取得了良好的结果。尽管如此， vanilla GAT在两个数据集上都具有竞争力，并通过注意力机制提供额外的可解释性层。我们对注意力权重进行了时序分析，揭示了与季节和气象变异性相关的区域互动模式。这些结果表明，尽管注意力机制并非在所有情况下都优于其他方法，但在空间依赖性明显时提供了有价值的解释能力。最后，我们基准测试了基于集成专家聚合策略，表明均匀或学习组合可以增强鲁棒性，在数据异质性下优于单个模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate electricity consumption forecasting is crucial for ensuring gridstability and optimizing power generation, particularly in increasinglydecentralized and complex systems. While classical approaches such asGeneralized Additive Models (GAMs) remain widely used, they often fail tocapture the spatial dependencies inherent in energy networks. Graph NeuralNetworks (GNNs) offer a principled framework to incorporate this structure bydirectly leveraging graph topologies. In this work, we evaluate a broad set ofGNN architectures -- including GCN, GraphSAGE, ChebConv, TAG, APPNP,TransformerConv, and Graph Attention Networks (GAT and GATv2) -- on tworeal-world electricity consumption datasets from France and the UK. Ourexperiments show that while complex architectures like GATv2 andTransformerConv do not consistently outperform their simpler counterparts,models such as GCN and APPNP achieve strong results in low-data or highlydisaggregated settings. Nonetheless, the vanilla GAT remains highly competitiveacross both datasets and offers an additional interpretability layer viaattention mechanisms. We perform a temporal analysis of attention weights,revealing evolving patterns of regional interaction linked to seasonal andmeteorological variability. These results highlight that, although attention isnot universally superior, it provides valuable explanatory power when spatialdependencies are prominent. Finally, we benchmark ensemble-based expertaggregation strategies, showing that uniform or learned combinations canenhance robustness and outperform individual models under data heterogeneity.</description>
      <author>example@mail.com (Eloi Campagne, Itai Zehavi, Yvenn Amara-Ouali, Yannig Goude, Argyris Kalogeratos)</author>
      <guid isPermaLink="false">2507.03690v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Cycle-Consistent Helmholtz Machine: Goal-Seeded Simulation via Inverted Inference</title>
      <link>http://arxiv.org/abs/2507.03065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了循环一致赫尔姆霍兹机（C$^2$HM），这是一种新型扩展，它将推理重新定义为以目标为导向、非对称的过程，并基于结构化的内部先验。C$^2$HM通过前向生成和反向精炼的递归循环，模拟在抽象目标条件下的合理潜在轨迹，并通过变分循环将自上而下的结构和自下而上的证据结合起来。&lt;h4&gt;背景&lt;/h4&gt;赫尔姆霍兹机（HM）是一种无监督学习的基础架构，通过交替推理将自下而上的识别模型与自上而下的生成模型耦合。然而，它对对称、数据驱动更新的依赖限制了其进行目标导向推理或模拟时间扩展过程的能力。&lt;h4&gt;目的&lt;/h4&gt;提出循环一致赫尔姆霍兹机（C$^2$HM）以改进表示效率，支持通过路径相关推理进行记忆链，并使空间组合性想象成为可能。&lt;h4&gt;方法&lt;/h4&gt;C$^2$HM通过将推理视为目标引导的非对称过程，并通过递归循环将潜在轨迹与观察结果对齐，同时结合上下文-内容不确定性原理（CCUP）。&lt;h4&gt;主要发现&lt;/h4&gt;C$^2$HM通过变分循环强制目标条件下的潜在预测与基于识别的重构之间的相互对齐，从而整合了自上而下的结构与自下而上的证据。&lt;h4&gt;结论&lt;/h4&gt;C$^2$HM提供了一种生物启发的替代方案，将生成建模重新构想为有意的模拟，从而在统一的概率框架中连接基于记忆的计划和无监督学习。&lt;h4&gt;翻译&lt;/h4&gt;The Helmholtz Machine (HM) is a foundational architecture for unsupervised learning, coupling a bottom-up recognition model with a top-down generative model through alternating inference. However, its reliance on symmetric, data-driven updates constrains its ability to perform goal-directed reasoning or simulate temporally extended processes. In this work, we introduce the Cycle-Consistent Helmholtz Machine (C$^2$HM), a novel extension that reframes inference as a goal-seeded, asymmetric process grounded in structured internal priors. Rather than inferring latent causes solely from sensory data, C$^2$HM simulates plausible latent trajectories conditioned on abstract goals, aligning them with observed outcomes through a recursive cycle of forward generation and inverse refinement. This cycle-consistent formulation integrates top-down structure with bottom-up evidence via a variational loop, enforcing mutual alignment between goal-conditioned latent predictions and recognition-based reconstructions. We formalize this mechanism within the framework of the Context-Content Uncertainty Principle (CCUP), which posits that inference proceeds by aligning structured, low-entropy content with high-entropy, ambiguous context. C$^2$HM improves representational efficiency, supports memory chaining via path-dependent inference, and enables spatial compositional imagination. By offering a biologically inspired alternative to classical amortized inference, $C^2$HM reconceives generative modeling as intentional simulation, bridging memory-based planning and unsupervised learning in a unified probabilistic framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Helmholtz Machine (HM) is a foundational architecture for unsupervisedlearning, coupling a bottom-up recognition model with a top-down generativemodel through alternating inference. However, its reliance on symmetric,data-driven updates constrains its ability to perform goal-directed reasoningor simulate temporally extended processes. In this work, we introduce the\emph{Cycle-Consistent Helmholtz Machine} (C$^2$HM), a novel extension thatreframes inference as a \emph{goal-seeded}, \emph{asymmetric} process groundedin structured internal priors. Rather than inferring latent causes solely fromsensory data, C$^2$HM simulates plausible latent trajectories conditioned onabstract goals, aligning them with observed outcomes through a recursive cycleof forward generation and inverse refinement. This cycle-consistent formulationintegrates top-down structure with bottom-up evidence via a variational loop,enforcing mutual alignment between goal-conditioned latent predictions andrecognition-based reconstructions. We formalize this mechanism within theframework of the \emph{Context-Content Uncertainty Principle} (CCUP), whichposits that inference proceeds by aligning structured, low-entropy content withhigh-entropy, ambiguous context. C$^2$HM improves representational efficiency,supports memory chaining via path-dependent inference, and enables spatialcompositional imagination. By offering a biologically inspired alternative toclassical amortized inference, $C^2$HM reconceives generative modeling asintentional simulation, bridging memory-based planning and unsupervisedlearning in a unified probabilistic framework.</description>
      <author>example@mail.com (Xin Li)</author>
      <guid isPermaLink="false">2507.03065v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Deconfounding Causal Inference through Two-Branch Framework with Early-Forking for Sensor-Based Cross-Domain Activity Recognition</title>
      <link>http://arxiv.org/abs/2507.03898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Proceedings of the ACM on Interactive, Mobile, Wearable  and Ubiquitous Technologies (IMWUT)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于因果推理的跨域活动识别算法，通过分析传感器数据与活动标签之间的因果关系，有效提高了跨域活动识别的性能。&lt;h4&gt;背景&lt;/h4&gt;在基于传感器的活动识别中，分布偏移问题是一个挑战。目前大多数基于域泛化的工作仅关注传感器数据与活动标签之间的统计依赖，忽略了内在因果关系的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出一种因果推理的方法来解决跨域活动识别问题，并提高识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一个早期分叉的双分支框架，分别学习因果和非因果特征。使用基于独立性的希尔伯特-施密特信息准则来解耦这些特征，并设计了非均匀域采样策略来增强解耦。同时，采用类别感知的域扰动层以防止表示崩溃。&lt;h4&gt;主要发现&lt;/h4&gt;在多个公开的活动识别基准数据集上进行的实验表明，该方法在跨个人、跨数据集和跨位置设置下显著优于11个相关最先进基线。&lt;h4&gt;结论&lt;/h4&gt;因果推理方法在跨域活动识别场景中表现出有效性、效率和普适性。&lt;h4&gt;翻译&lt;/h4&gt;近期，领域泛化（DG）作为缓解基于传感器的人体活动识别（HAR）场景中分布偏移问题的有力解决方案而崭露头角。然而，大多数现有的基于DG的工作仅仅关注建模传感器数据与活动标签之间的统计依赖关系，忽视了内在因果机制的重要性。直观上，每个传感器输入可以被视为因果（类别感知）和非因果因素（域特定）的混合体，其中只有前者影响活动分类判断。在本文中，我们将基于DG的HAR视为一个因果推理问题，提出了一种用于跨域活动识别的因果启发的表示学习算法。为此，设计了一个早期分叉的双分支框架，其中两个独立的分支分别负责学习因果和非因果特征，同时采用基于独立性的希尔伯特-施密特信息准则来隐式解耦它们。此外，设计了一种非均匀域采样策略来增强解耦，同时执行类别感知的域扰动层以防止表示崩溃。在多个公开的HAR基准数据集上进行的广泛实验表明，在跨个人、跨数据集和跨位置设置下，我们的因果启发的方案显著优于11个相关最先进的基线。详细的消融和可视化分析揭示了潜在的因果机制，表明其在跨域活动识别场景中的有效性、效率和普适性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, domain generalization (DG) has emerged as a promising solution tomitigate distribution-shift issue in sensor-based human activity recognition(HAR) scenario. However, most existing DG-based works have merely focused onmodeling statistical dependence between sensor data and activity labels,neglecting the importance of intrinsic casual mechanism. Intuitively, everysensor input can be viewed as a mixture of causal (category-aware) andnon-causal factors (domain-specific), where only the former affects activityclassification judgment. In this paper, by casting such DG-based HAR as acasual inference problem, we propose a causality-inspired representationlearning algorithm for cross-domain activity recognition. To this end, anearly-forking two-branch framework is designed, where two separate branches arerespectively responsible for learning casual and non-causal features, while anindependence-based Hilbert-Schmidt Information Criterion is employed toimplicitly disentangling them. Additionally, an inhomogeneous domain samplingstrategy is designed to enhance disentanglement, while a category-aware domainperturbation layer is performed to prevent representation collapse. Extensiveexperiments on several public HAR benchmarks demonstrate that ourcausality-inspired approach significantly outperforms eleven relatedstate-of-the-art baselines under cross-person, cross-dataset, andcross-position settings. Detailed ablation and visualizations analyses revealunderlying casual mechanism, indicating its effectiveness, efficiency, anduniversality in cross-domain activity recognition scenario.</description>
      <author>example@mail.com (Di Xiong, Lei Zhang, Shuoyuan Wang, Dongzhou Cheng, Wenbo Huang)</author>
      <guid isPermaLink="false">2507.03898v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Alignment with Cross-Attentive GRUs for Fine-Grained Video Understanding</title>
      <link>http://arxiv.org/abs/2507.03531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多模态框架，融合视频、图像和文本表示，使用基于GRU的序列编码器和跨模态注意力机制，通过分类或回归损失进行训练，并采用特征级增强和自动编码技术进行正则化。在两个具有挑战性的基准数据集上进行的实验表明，该融合策略显著优于单模态基线，跨注意力机制和特征增强对鲁棒性和性能有显著贡献。&lt;h4&gt;背景&lt;/h4&gt;细粒度视频分类需要理解复杂的时空和语义线索，这些线索通常超出了单一模态的处理能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种多模态框架，用于提高细粒度视频分类的性能。&lt;h4&gt;方法&lt;/h4&gt;使用GRU序列编码器和跨模态注意力机制融合视频、图像和文本表示，结合分类或回归损失进行训练，并应用特征级增强和自动编码技术进行正则化。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验表明，所提出的融合策略显著优于单模态基线，并且跨注意力机制和特征增强对鲁棒性和性能有显著贡献。&lt;h4&gt;结论&lt;/h4&gt;多模态融合策略能够有效提高细粒度视频分类的性能，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal framework that fuses video, image, and text representations using GRU-based sequence encoders and cross-modal attention mechanisms. The model is trained using a combination of classification or regression loss, depending on the task, and is further regularized through feature-level augmentation and autoencoding techniques. To evaluate the generality of our framework, we conduct experiments on two challenging benchmarks: the DVD dataset for real-world violence detection and the Aff-Wild2 dataset for valence-arousal estimation. Our results demonstrate that the proposed fusion strategy significantly outperforms unimodal baselines, with cross-attention and feature augmentation contributing notably to robustness and performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained video classification requires understanding complexspatio-temporal and semantic cues that often exceed the capacity of a singlemodality. In this paper, we propose a multimodal framework that fuses video,image, and text representations using GRU-based sequence encoders andcross-modal attention mechanisms. The model is trained using a combination ofclassification or regression loss, depending on the task, and is furtherregularized through feature-level augmentation and autoencoding techniques. Toevaluate the generality of our framework, we conduct experiments on twochallenging benchmarks: the DVD dataset for real-world violence detection andthe Aff-Wild2 dataset for valence-arousal estimation. Our results demonstratethat the proposed fusion strategy significantly outperforms unimodal baselines,with cross-attention and feature augmentation contributing notably torobustness and performance.</description>
      <author>example@mail.com (Namho Kim, Junhwa Kim)</author>
      <guid isPermaLink="false">2507.03531v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Simplifying Graph Neural Kernels: from Stacking Layers to Collapsed Structure</title>
      <link>http://arxiv.org/abs/2507.03560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种简化的图神经切线核（SGTK）和简化的图神经核（SGNK），以解决图神经网络（GNN）训练的难题和传统核方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的图神经切线核（GNTK）在训练深度网络和传统核方法的局限性方面取得了成功，但其层堆叠策略引入了冗余计算，增加了计算复杂度并限制了实用性。&lt;h4&gt;目的&lt;/h4&gt;提出SGTK和SGNK，以简化计算过程，提高效率，并减少对层堆叠的依赖。&lt;h4&gt;方法&lt;/h4&gt;SGTK使用连续的K步聚合操作替代传统的多层堆叠机制，SGNK将无限宽的GNN建模为高斯过程，直接从激活函数的期望输出中确定核值。&lt;h4&gt;主要发现&lt;/h4&gt;SGTK和SGNK在节点和图分类任务上表现出与现有方法相当的性能，同时提高了计算效率。&lt;h4&gt;结论&lt;/h4&gt;SGTK和SGNK为GNN提供了更高效和简洁的计算方法，有助于解决当前GNN训练中的挑战。&lt;h4&gt;翻译&lt;/h4&gt;The Graph Neural Tangent Kernel (GNTK) successfully bridges the gap between kernel methods and Graph Neural Networks (GNNs), addressing key challenges such as the difficulty of training deep networks and the limitations of traditional kernel methods. However, the existing layer-stacking strategy in GNTK introduces redundant computations, significantly increasing computational complexity and limiting scalability for practical applications. To address these issues, this paper proposes the Simplified Graph Neural Tangent Kernel (SGTK), which replaces the traditional multi-layer stacking mechanism with a continuous K-step aggregation operation. This novel approach streamlines the iterative kernel computation process, effectively eliminating redundant calculations while preserving the kernel's expressiveness. By reducing the dependency on layer stacking, SGTK achieves both computational simplicity and efficiency. Furthermore, we introduce the Simplified Graph Neural Kernel (SGNK), which models infinitely wide Graph Neural Networks as Gaussian Processes. This allows kernel values to be directly determined from the expected outputs of activation functions in the infinite-width regime, bypassing the need for explicit layer-by-layer computation. SGNK further reduces computational complexity while maintaining the capacity to capture intricate structural patterns in graphs. Extensive experiments on node and graph classification tasks demonstrate that the proposed SGTK and SGNK achieve performance comparable to existing approaches while improving computational efficiency. Implementation details are available at https://anonymous.4open.science/r/SGNK-1CE4/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Graph Neural Tangent Kernel (GNTK) successfully bridges the gap betweenkernel methods and Graph Neural Networks (GNNs), addressing key challenges suchas the difficulty of training deep networks and the limitations of traditionalkernel methods. However, the existing layer-stacking strategy in GNTKintroduces redundant computations, significantly increasing computationalcomplexity and limiting scalability for practical applications. To addressthese issues, this paper proposes the Simplified Graph Neural Tangent Kernel(SGTK), which replaces the traditional multi-layer stacking mechanism with acontinuous $K$-step aggregation operation. This novel approach streamlines theiterative kernel computation process, effectively eliminating redundantcalculations while preserving the kernel's expressiveness. By reducing thedependency on layer stacking, SGTK achieves both computational simplicity andefficiency. Furthermore, we introduce the Simplified Graph Neural Kernel(SGNK), which models infinitely wide Graph Neural Networks as GaussianProcesses. This allows kernel values to be directly determined from theexpected outputs of activation functions in the infinite-width regime,bypassing the need for explicit layer-by-layer computation. SGNK furtherreduces computational complexity while maintaining the capacity to captureintricate structural patterns in graphs. Extensive experiments on node andgraph classification tasks demonstrate that the proposed SGTK and SGNK achieveperformance comparable to existing approaches while improving computationalefficiency. Implementation details are available athttps://anonymous.4open.science/r/SGNK-1CE4/.</description>
      <author>example@mail.com (Lin Wang, Shijie Wang, Sirui Huang, Qing Li)</author>
      <guid isPermaLink="false">2507.03560v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Consistency-Aware Padding for Incomplete Multi-Modal Alignment Clustering Based on Self-Repellent Greedy Anchor Search</title>
      <link>http://arxiv.org/abs/2507.03917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IJCAI 2025. 9 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CAPIMAC的方法，用于处理多模态数据集中不平衡和不匹配数据的问题，通过自排斥贪婪锚点搜索和一致性感知填充模块来提高数据融合的质量。&lt;h4&gt;背景&lt;/h4&gt;多模态表示在描述现实世界数据样本特征方面非常有效，但收集的数据往往由于传感器频率不一致和设备故障等原因表现出不完整和不匹配的特征。&lt;h4&gt;目的&lt;/h4&gt;旨在解决多视图数据既不平衡又错位的情况下填充缺失数据的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个自排斥贪婪锚点搜索模块（SRGASM），该模块使用自排斥随机游走和贪婪算法来识别锚点，用于重新表示不完整和不匹配的多模态数据。然后，基于噪声对比学习，设计了一个一致性感知填充模块（CAPM），以有效地插值和对齐不平衡和不匹配的数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在基准数据集上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;CAPIMAC方法能够有效提高多模态数据融合的质量。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal representation is faithful and highly effective in describing real-world data samples' characteristics by describing their complementary information. However, the collected data often exhibits incomplete and misaligned characteristics due to factors such as inconsistent sensor frequencies and device malfunctions. Existing research has not effectively addressed the issue of filling missing data in scenarios where multiview data are both imbalanced and misaligned. Instead, it relies on class-level alignment of the available data. Thus, it results in some data samples not being well-matched, thereby affecting the quality of data fusion. In this paper, we propose the Consistency-Aware Padding for Incomplete Multimodal Alignment Clustering Based on Self-Repellent Greedy Anchor Search (CAPIMAC) to tackle the problem of filling imbalanced and misaligned data in multimodal datasets. Specifically, we propose a self-repellent greedy anchor search module (SRGASM), which employs a self-repellent random walk combined with a greedy algorithm to identify anchor points for re-representing incomplete and misaligned multimodal data. Subsequently, based on noise-contrastive learning, we design a consistency-aware padding module (CAPM) to effectively interpolate and align imbalanced and misaligned data, thereby improving the quality of multimodal data fusion. Experimental results demonstrate the superiority of our method over benchmark datasets. The code will be publicly released at https://github.com/Autism-mm/CAPIMAC.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation is faithful and highly effective in describingreal-world data samples' characteristics by describing their complementaryinformation. However, the collected data often exhibits incomplete andmisaligned characteristics due to factors such as inconsistent sensorfrequencies and device malfunctions. Existing research has not effectivelyaddressed the issue of filling missing data in scenarios where multiview dataare both imbalanced and misaligned. Instead, it relies on class-level alignmentof the available data. Thus, it results in some data samples not beingwell-matched, thereby affecting the quality of data fusion. In this paper, wepropose the Consistency-Aware Padding for Incomplete Multimodal AlignmentClustering Based on Self-Repellent Greedy Anchor Search(CAPIMAC) to tackle theproblem of filling imbalanced and misaligned data in multimodal datasets.Specifically, we propose a self-repellent greedy anchor search module(SRGASM),which employs a self-repellent random walk combined with a greedy algorithm toidentify anchor points for re-representing incomplete and misaligned multimodaldata. Subsequently, based on noise-contrastive learning, we design aconsistency-aware padding module (CAPM) to effectively interpolate and alignimbalanced and misaligned data, thereby improving the quality of multimodaldata fusion. Experimental results demonstrate the superiority of our methodover benchmark datasets. The code will be publicly released athttps://github.com/Autism-mm/CAPIMAC.git.</description>
      <author>example@mail.com (Shubin Ma, Liang Zhao, Mingdong Lu, Yifan Guo, Bo Xu)</author>
      <guid isPermaLink="false">2507.03917v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>GenAI-Powered Inference</title>
      <link>http://arxiv.org/abs/2507.03897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为GenAI-Powered Inference (GPI)的统计框架，该框架用于处理非结构化数据（包括文本和图像）进行因果和预测推断。&lt;h4&gt;背景&lt;/h4&gt;GPI框架利用开源的生成式人工智能（GenAI）模型，如大型语言模型和扩散模型，不仅能够大规模生成非结构化数据，还能提取低维表示，捕捉其内在结构。&lt;h4&gt;目的&lt;/h4&gt;GPI旨在通过机器学习这些表示，实现因果和预测效应的估计，同时量化相关的估计不确定性。&lt;h4&gt;方法&lt;/h4&gt;与现有的表示学习方法不同，GPI不需要对生成模型进行微调，这使得它计算效率高且易于访问。&lt;h4&gt;主要发现&lt;/h4&gt;GPI框架具有多功能性，通过三个应用进行了展示：(1) 分析中国社交媒体审查，(2) 估计候选人面部外观对选举结果的影响，(3) 评估政治演讲的说服力。&lt;h4&gt;结论&lt;/h4&gt;GPI框架可通过开源软件包实现，为因果和预测推断提供了一种高效且通用的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce GenAI-Powered Inference (GPI), a statistical framework for bothcausal and predictive inference using unstructured data, including text andimages. GPI leverages open-source Generative Artificial Intelligence (GenAI)models - such as large language models and diffusion models - not only togenerate unstructured data at scale but also to extract low-dimensionalrepresentations that capture their underlying structure. Applying machinelearning to these representations, GPI enables estimation of causal andpredictive effects while quantifying associated estimation uncertainty. Unlikeexisting approaches to representation learning, GPI does not requirefine-tuning of generative models, making it computationally efficient andbroadly accessible. We illustrate the versatility of the GPI framework throughthree applications: (1) analyzing Chinese social media censorship, (2)estimating predictive effects of candidates' facial appearance on electoraloutcomes, and (3) assessing the persuasiveness of political rhetoric. Anopen-source software package is available for implementing GPI.</description>
      <author>example@mail.com (Kosuke Imai, Kentaro Nakamura)</author>
      <guid isPermaLink="false">2507.03897v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding</title>
      <link>http://arxiv.org/abs/2507.02591v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AuroraLong的新方法，用于解决长视频理解中的计算复杂度和内存成本问题。&lt;h4&gt;背景&lt;/h4&gt;长视频理解面临计算复杂度和内存成本高的挑战，因为基于Transformer的LLMs的内存和计算需求与输入序列长度呈二次方关系。&lt;h4&gt;目的&lt;/h4&gt;通过使用线性RNN语言模型替换MLLMs中的LLM组件，以及结合视觉token合并和线性RNN模型，旨在提高处理效率和吞吐量。&lt;h4&gt;方法&lt;/h4&gt;AuroraLong使用线性RNN语言模型处理任意长度的输入序列，并按大小顺序重新排列视觉token以增加效率。此外，该模型仅使用2B参数并在公共数据上训练。&lt;h4&gt;主要发现&lt;/h4&gt;AuroraLong在多个视频基准测试中，与在私有数据集上训练的类似规模的Transformer模型相比，实现了可比较的性能。&lt;h4&gt;结论&lt;/h4&gt;这一发现证明了高效、线性的RNN在降低计算门槛方面具有民主化长视频理解的潜力，并且是首次在LLaVA-like模型中采用基于线性RNN的LLM骨干。&lt;h4&gt;翻译&lt;/h4&gt;摘要：长视频理解的挑战在于其高计算复杂性和不可承受的内存成本，因为基于transformer的LLMs的内存和计算需求与输入序列长度呈二次方关系。我们提出了AuroraLong来应对这一挑战，通过用线性RNN语言模型替换MLLM中的LLM组件，该模型可以处理任意长度的输入序列并使用固定大小的隐藏状态。为了进一步提高吞吐量和效率，我们通过按大小顺序重新排列视觉token与线性RNN模型相结合。尽管只有2B参数并且仅在公共数据上训练，AuroraLong在多个视频基准测试中实现了与在私有数据集上训练的类似规模的基于Transformer的模型的性能。这证明了高效线性RNN民主化长视频理解的潜力，降低其计算门槛。据我们所知，我们是第一个在LLaVA-like模型中采用基于线性RNN的LLM骨干用于开放视频理解的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenge of long video understanding lies in its high computationalcomplexity and prohibitive memory cost, since the memory and computationrequired by transformer-based LLMs scale quadratically with input sequencelength. We propose AuroraLong to address this challenge by replacing the LLMcomponent in MLLMs with a linear RNN language model that handles input sequenceof arbitrary length with constant-size hidden states. To further increasethroughput and efficiency, we combine visual token merge with linear RNN modelsby reordering the visual tokens by their sizes in ascending order. Despitehaving only 2B parameters and being trained exclusively on public data,AuroraLong achieves performance comparable to Transformer-based models ofsimilar size trained on private datasets across multiple video benchmarks. Thisdemonstrates the potential of efficient, linear RNNs to democratize long videounderstanding by lowering its computational entry barrier. To our bestknowledge, we are the first to use a linear RNN based LLM backbone in aLLaVA-like model for open-ended video understanding.</description>
      <author>example@mail.com (Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang)</author>
      <guid isPermaLink="false">2507.02591v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Radar Tracker: Moving Instance Tracking in Sparse and Noisy Radar Point Clouds</title>
      <link>http://arxiv.org/abs/2507.03441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proc. of the IEEE Intl. Conf. on Robotics &amp; Automation (ICRA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了使用雷达传感对移动目标进行分割和跟踪，以增强场景解释和实现可靠路径规划，包括碰撞避免。&lt;h4&gt;背景&lt;/h4&gt;移动目标的分割和跟踪对于可靠路径规划至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高移动实例跟踪的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于学习的雷达跟踪器，该跟踪器包含时间偏移预测，以实现基于中心的直接关联，并通过包括额外的运动线索来增强分割性能。此外，实现了基于注意力的跟踪，以包括外观特征并提高性能。最终关联结合了几何和外观特征，以克服基于中心的跟踪的局限性，从而可靠地关联实例。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在RadarScenes数据集的移动实例跟踪基准测试中，与现有技术相比，表现出了改进的性能。&lt;h4&gt;结论&lt;/h4&gt;基于雷达传感的移动实例跟踪方法有效提高了场景解释和路径规划的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICRA57147.2024.10610198&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots and autonomous vehicles should be aware of what happens in theirsurroundings. The segmentation and tracking of moving objects are essential forreliable path planning, including collision avoidance. We investigate thisestimation task for vehicles using radar sensing. We address moving instancetracking in sparse radar point clouds to enhance scene interpretation. Wepropose a learning-based radar tracker incorporating temporal offsetpredictions to enable direct center-based association and enhance segmentationperformance by including additional motion cues. We implement attention-basedtracking for sparse radar scans to include appearance features and enhanceperformance. The final association combines geometric and appearance featuresto overcome the limitations of center-based tracking to associate instancesreliably. Our approach shows an improved performance on the moving instancetracking benchmark of the RadarScenes dataset compared to the current state ofthe art.</description>
      <author>example@mail.com (Matthias Zeller, Daniel Casado Herraez, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2507.03441v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Learning Normals of Noisy Points by Local Gradient-Aware Surface Filtering</title>
      <link>http://arxiv.org/abs/2507.03394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025. Code: https://github.com/LeoQLi/LGSF&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从噪声点云中学习法线的创新方法，通过局部梯度感知表面过滤来实现。&lt;h4&gt;背景&lt;/h4&gt;估计法线是3D几何处理中的持续挑战，特别是对于端到端的定向法线估计。现有方法通常针对相对干净的数据，并依赖于监督先验来拟合特定邻域内的局部表面。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来学习噪声点云的法线。&lt;h4&gt;方法&lt;/h4&gt;该方法通过利用来自隐函数的局部梯度约束得到的法线和距离，将噪声点投影到基本表面上。它引入了一个距离测量算子，用于在噪声数据上执行全局表面拟合，并开发了一种基于隐场的过滤方法来构建表面点，在过滤过程中添加了投影约束。为了解决过度平滑和梯度退化的问题，进一步结合了局部梯度一致性约束、局部梯度方向和聚合。&lt;h4&gt;主要发现&lt;/h4&gt;在法线估计、表面重建和点云去噪方面的综合实验表明，该方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在噪声点云的法线估计方面表现出色，相关源代码和训练模型可在指定GitHub链接找到。&lt;h4&gt;翻译&lt;/h4&gt;Estimating normals for noisy point clouds is a persistent challenge in 3D geometry processing, particularly for end-to-end oriented normal estimation. Existing methods generally address relatively clean data and rely on supervised priors to fit local surfaces within specific neighborhoods. In this paper, we propose a novel approach for learning normals from noisy point clouds through local gradient-aware surface filtering. Our method projects noisy points onto the underlying surface by utilizing normals and distances derived from an implicit function constrained by local gradients. We start by introducing a distance measurement operator for global surface fitting on noisy data, which integrates projected distances along normals. Following this, we develop an implicit field-based filtering approach for surface point construction, adding projection constraints on these points during filtering. To address issues of over-smoothing and gradient degradation, we further incorporate local gradient consistency constraints, as well as local gradient orientation and aggregation. Comprehensive experiments on normal estimation, surface reconstruction, and point cloud denoising demonstrate the state-of-the-art performance of our method. The source code and trained models are available at https://github.com/LeoQLi/LGSF.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating normals for noisy point clouds is a persistent challenge in 3Dgeometry processing, particularly for end-to-end oriented normal estimation.Existing methods generally address relatively clean data and rely on supervisedpriors to fit local surfaces within specific neighborhoods. In this paper, wepropose a novel approach for learning normals from noisy point clouds throughlocal gradient-aware surface filtering. Our method projects noisy points ontothe underlying surface by utilizing normals and distances derived from animplicit function constrained by local gradients. We start by introducing adistance measurement operator for global surface fitting on noisy data, whichintegrates projected distances along normals. Following this, we develop animplicit field-based filtering approach for surface point construction, addingprojection constraints on these points during filtering. To address issues ofover-smoothing and gradient degradation, we further incorporate local gradientconsistency constraints, as well as local gradient orientation and aggregation.Comprehensive experiments on normal estimation, surface reconstruction, andpoint cloud denoising demonstrate the state-of-the-art performance of ourmethod. The source code and trained models are available athttps://github.com/LeoQLi/LGSF.</description>
      <author>example@mail.com (Qing Li, Huifang Feng, Xun Gong, Yu-Shen Liu)</author>
      <guid isPermaLink="false">2507.03394v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>ZERO: Multi-modal Prompt-based Visual Grounding</title>
      <link>http://arxiv.org/abs/2507.04270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A solution report for CVPR2025 Foundational FSOD Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ZERO，一种专为不同工业领域生产部署设计的零样本多提示物体检测模型。&lt;h4&gt;背景&lt;/h4&gt;人工智能的进步导致了基础模型的兴起，这些大规模预训练神经网络为各种下游任务提供了通用的起点。&lt;h4&gt;目的&lt;/h4&gt;提出ZERO模型，以实现鲁棒、适用于生产的多领域零样本物体检测。&lt;h4&gt;方法&lt;/h4&gt;ZERO模型结合直接图像输入和多个用户定义的提示（包括文本和视觉线索），通过专用编码器处理以生成准确的检测输出。模型架构经过优化，具有可扩展性，包含1.033 TFLOPS的总计算能力和622.346百万个参数。使用超过十亿图像的特定领域图像数据库进行训练。对于CVPR 2025基础少样本物体检测（FSOD）挑战，引入了特定领域的微调策略，强调提示多样性和保守的伪标签，以实现最小监督下的有效适应。&lt;h4&gt;主要发现&lt;/h4&gt;ZERO模型在RF20VL-fsod基准测试中表现出色，尽管注释预算有限，也证明了其在灵活性、效率和实际应用方面的优势。&lt;h4&gt;结论&lt;/h4&gt;ZERO模型展示了提示驱动、以数据为中心的AI在动态工业环境中可扩展和自适应物体检测的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Recent advances in artificial intelligence have led to the emergence of foundation models, large-scale pre-trained neural networks that serve as versatile starting points for a wide range of downstream tasks. In this work, we present ZERO, a zero-shot multi-prompt object detection model specifically designed for robust, production-ready deployment across diverse industrial domains. ZERO integrates direct image input with multiple user-defined prompts, which can include both textual and visual cues, and processes them through dedicated encoders to generate accurate detection outputs. The model architecture is optimized for scalability, with a total of 1.033 TFLOPS and 622.346 million parameters, and is trained using a domain-specific image database exceeding one billion images. For the CVPR 2025 Foundational Few-Shot Object Detection (FSOD) Challenge, we introduce a domain-specific fine-tuning strategy that emphasizes prompt diversity and conservative pseudo-labeling, enabling effective adaptation to new domains with minimal supervision. Our approach demonstrates practical advantages in flexibility, efficiency, and real-world applicability, achieving strong performance on the RF20VL-fsod benchmark despite limited annotation budgets. The results highlight the potential of prompt-driven, data-centric AI for scalable and adaptive object detection in dynamic industrial environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in artificial intelligence have led to the emergence offoundation models, large-scale pre-trained neural networks that serve asversatile starting points for a wide range of downstream tasks. In this work,we present ZERO, a zero-shot multi-prompt object detection model specificallydesigned for robust, production-ready deployment across diverse industrialdomains. ZERO integrates direct image input with multiple user-defined prompts,which can include both textual and visual cues, and processes them throughdedicated encoders to generate accurate detection outputs. The modelarchitecture is optimized for scalability, with a total of 1.033 TFLOPS and622.346 million parameters, and is trained using a domain-specific imagedatabase exceeding one billion images. For the CVPR 2025 Foundational Few-ShotObject Detection (FSOD) Challenge, we introduce a domain-specific fine-tuningstrategy that emphasizes prompt diversity and conservative pseudo-labeling,enabling effective adaptation to new domains with minimal supervision. Ourapproach demonstrates practical advantages in flexibility, efficiency, andreal-world applicability, achieving strong performance on the RF20VL-fsodbenchmark despite limited annotation budgets. The results highlight thepotential of prompt-driven, data-centric AI for scalable and adaptive objectdetection in dynamic industrial environments.</description>
      <author>example@mail.com (Sangbum Choi, Kyeongryeol Go)</author>
      <guid isPermaLink="false">2507.04270v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Label-Free Long-Horizon 3D UAV Trajectory Prediction via Motion-Aligned RGB and Event Cues</title>
      <link>http://arxiv.org/abs/2507.03365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉的无监督方法，用于预测无人机三维轨迹，旨在解决当前无人机对空中安全和公共安全带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;无人机的高度敏捷性和不可预测的运动使得追踪和拦截变得困难，现有的方法主要集中在检测当前位置，而许多反无人机策略需要预测未来轨迹。&lt;h4&gt;目的&lt;/h4&gt;填补预测未来轨迹这一关键差距，提出一种无监督视觉方法预测无人机三维轨迹。&lt;h4&gt;方法&lt;/h4&gt;该方法首先使用无监督技术从原始激光雷达点云中提取无人机轨迹，然后通过运动一致性将这些轨迹与相机图像对齐以生成可靠的伪标签。之后，以自监督方式结合运动估计和视觉Mamba神经网络预测未来无人机轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在MMAUD数据集上进行的广泛实验表明，该方法在长期轨迹预测方面优于监督图像和视听基线，在不使用任何手动三维标签的情况下，将5秒3D误差降低了约40%。&lt;h4&gt;结论&lt;/h4&gt;该系统为实时反无人机部署提供了一种成本效益高、可扩展的替代方案。所有代码将在接受后发布，以支持机器人社区的可重复研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：消费级无人机的广泛使用对空中安全和公共安全带来了严重挑战。它们的高度灵活性和不可预测的运动使得无人机难以追踪和拦截。尽管现有方法专注于检测当前位置，但许多反无人机策略依赖于预测未来轨迹，因此需要比反应式检测更多的措施才能有效。为了解决这一关键差距，我们提出了一种基于视觉的无监督方法来预测无人机三维轨迹。我们的方法首先使用无监督技术从原始激光雷达点云中提取无人机轨迹，然后通过运动一致性将这些轨迹与相机图像对齐以生成可靠的伪标签。然后，我们以自监督方式结合运动估计和视觉Mamba神经网络来预测未来的无人机轨迹。我们在具有广泛视场多模态传感器和城市场景中动态无人机运动的MMAUD数据集上评估了我们的方法。广泛的实验表明，我们的框架在长期轨迹预测方面优于监督图像和视听基线，在不使用任何手动三维标签的情况下，将5秒3D误差降低了约40%。所提出的系统为实时反无人机部署提供了一种成本效益高、可扩展的替代方案。所有代码将在接受后发布，以支持机器人社区的可重复研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of consumer drones has introduced serious challenges forairspace security and public safety. Their high agility and unpredictablemotion make drones difficult to track and intercept. While existing methodsfocus on detecting current positions, many counter-drone strategies rely onforecasting future trajectories and thus require more than reactive detectionto be effective. To address this critical gap, we propose an unsupervisedvision-based method for predicting the three-dimensional trajectories ofdrones. Our approach first uses an unsupervised technique to extract dronetrajectories from raw LiDAR point clouds, then aligns these trajectories withcamera images through motion consistency to generate reliable pseudo-labels. Wethen combine kinematic estimation with a visual Mamba neural network in aself-supervised manner to predict future drone trajectories. We evaluate ourmethod on the challenging MMAUD dataset, including the V2 sequences thatfeature wide-field-of-view multimodal sensors and dynamic UAV motion in urbanscenes. Extensive experiments show that our framework outperforms supervisedimage-only and audio-visual baselines in long-horizon trajectory prediction,reducing 5-second 3D error by around 40 percent without using any manual 3Dlabels. The proposed system offers a cost-effective, scalable alternative forreal-time counter-drone deployment. All code will be released upon acceptanceto support reproducible research in the robotics community.</description>
      <author>example@mail.com (Hanfang Liang, Shenghai Yuan, Fen Liu, Yizhuo Yang, Bing Wang, Zhuyu Huang, Chenyang Shi, Jing Jin)</author>
      <guid isPermaLink="false">2507.03365v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Pedestrian Intention Prediction via Vision-Language Foundation Models</title>
      <link>http://arxiv.org/abs/2507.04141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了利用视觉-语言基础模型（VLFMs）通过集成多模态数据预测行人过街意图的潜力，并展示了VLFMs在预测精度和泛化能力上的优势。&lt;h4&gt;背景&lt;/h4&gt;传统的基于视觉的过街意图预测方法在泛化性、上下文理解和因果推理方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过结合多模态数据，利用VLFMs预测行人过街意图，并提高预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;方法将上下文信息，包括视觉帧、物理线索观察和自我车辆动态，整合到系统优化的提示模板中，以引导VLFMs进行意图预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，结合车辆速度、速度随时间的变化和时间感知提示可以显著提高预测精度，最高可达19.8%。通过自动提示工程框架生成的优化提示进一步提高了12.5%的准确性。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，与传统的基于视觉的模型相比，VLFMs在预测精度和泛化能力上表现更优，为自动驾驶应用提供了增强的泛化性和上下文理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prediction of pedestrian crossing intention is a critical function inautonomous vehicles. Conventional vision-based methods of crossing intentionprediction often struggle with generalizability, context understanding, andcausal reasoning. This study explores the potential of vision-languagefoundation models (VLFMs) for predicting pedestrian crossing intentions byintegrating multimodal data through hierarchical prompt templates. Themethodology incorporates contextual information, including visual frames,physical cues observations, and ego-vehicle dynamics, into systematicallyrefined prompts to guide VLFMs effectively in intention prediction. Experimentswere conducted on three common datasets-JAAD, PIE, and FU-PIP. Resultsdemonstrate that incorporating vehicle speed, its variations over time, andtime-conscious prompts significantly enhances the prediction accuracy up to19.8%. Additionally, optimised prompts generated via an automatic promptengineering framework yielded 12.5% further accuracy gains. These findingshighlight the superior performance of VLFMs compared to conventionalvision-based models, offering enhanced generalisation and contextualunderstanding for autonomous driving applications.</description>
      <author>example@mail.com (Mohsen Azarmi, Mahdi Rezaei, He Wang)</author>
      <guid isPermaLink="false">2507.04141v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Molecular Machine Learning Using Euler Characteristic Transforms</title>
      <link>http://arxiv.org/abs/2507.03474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出使用欧拉特征变换（ECT）作为分子形状的几何拓扑描述符，以改进分子表示学习，并在预测抑制常数 $K_i$ 的回归任务中评估其性能。&lt;h4&gt;背景&lt;/h4&gt;分子的形状对其物理化学和生物学性质有决定性影响，但在标准分子表示学习方法中常常被忽视。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来表示和编码分子形状，以改进分子机器学习任务中的预测性能。&lt;h4&gt;方法&lt;/h4&gt;使用ECT在由手工原子特征生成的分子图上直接计算，以提取多尺度结构特征，并将其与传统分子表示方法（如分子指纹/描述符和图神经网络）进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;ECT在多个基准回归数据集上实现了有竞争力的性能，且与AVALON指纹等传统表示方法结合使用时，预测性能显著增强。&lt;h4&gt;结论&lt;/h4&gt;多尺度拓扑信息对分子表示的互补价值得到了验证，混合方法结合显式形状信息可以导致更丰富、更稳健的分子表示，为分子机器学习任务开辟新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分子的形状决定了其物理化学和生物学性质。然而，在标准分子表示学习的方法中，它通常被忽视。在这里，我们提出使用欧拉特征变换（ECT）作为几何拓扑描述符。ECT直接在由手工原子特征生成的分子图上计算，从而能够提取多尺度结构特征，为在特征空间中表示和编码分子形状提供了一种新的方法。我们在九个基准回归数据集上评估了这种表示的预测性能，这些数据集都集中在预测抑制常数 $K_i$。此外，我们将我们提出的基于ECT的表示与传统的分子表示方法和方法（如分子指纹/描述符和图神经网络）进行了比较。我们的结果表明，我们的基于ECT的表示在多个数据集上实现了有竞争力的性能，在多个数据集上名列前茅。更重要的是，它与传统表示的结合，特别是与AVALON指纹的结合，显著提高了预测性能，在大多数数据集上优于其他方法。这些发现突出了多尺度拓扑信息的互补价值及其与现有技术相结合的潜力。我们的研究表明，结合显式形状信息的混合方法可以导致更丰富、更稳健的分子表示，为分子机器学习任务提供了新的途径。为了支持可重复性和促进开放生物医学研究，我们提供了所有实验和代码的开放访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The shape of a molecule determines its physicochemical and biologicalproperties. However, it is often underrepresented in standard molecularrepresentation learning approaches. Here, we propose using the EulerCharacteristic Transform (ECT) as a geometrical-topological descriptor.Computed directly on a molecular graph derived from handcrafted atomicfeatures, the ECT enables the extraction of multiscale structural features,offering a novel way to represent and encode molecular shape in the featurespace. We assess the predictive performance of this representation across ninebenchmark regression datasets, all centered around predicting the inhibitionconstant $K_i$. In addition, we compare our proposed ECT-based representationagainst traditional molecular representations and methods, such as molecularfingerprints/descriptors and graph neural networks (GNNs). Our results showthat our ECT-based representation achieves competitive performance, rankingamong the best-performing methods on several datasets. More importantly, itscombination with traditional representations, particularly with the AVALONfingerprint, significantly \emph{enhances predictive performance},outperforming other methods on most datasets. These findings highlight thecomplementary value of multiscale topological information and its potential forbeing combined with established techniques. Our study suggests that hybridapproaches incorporating explicit shape information can lead to moreinformative and robust molecular representations, enhancing and opening newavenues in molecular machine learning tasks. To support reproducibility andfoster open biomedical research, we provide open access to all experiments andcode used in this work.</description>
      <author>example@mail.com (Victor Toscano-Duran, Florian Rottach, Bastian Rieck)</author>
      <guid isPermaLink="false">2507.03474v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>GENPLUGIN: A Plug-and-Play Framework for Long-Tail Generative Recommendation with Exposure Bias Mitigation</title>
      <link>http://arxiv.org/abs/2507.03568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Generative recommendation (GenRec) 在集成大型语言模型 (LLM) 和降低嵌入成本方面表现出优势，但存在生成暴露偏差和长尾项目泛化能力差的问题。本文提出的GENPLUGIN框架通过双编码器共享解码器架构、对比学习、以及基于检索的数据增强机制，有效缓解了这些问题，并在实验中证明了其有效性。&lt;h4&gt;背景&lt;/h4&gt;Generative recommendation (GenRec) 因其集成LLM、降低嵌入成本和消除候选者评分而受到关注。&lt;h4&gt;目的&lt;/h4&gt;解决GenRec中存在的生成暴露偏差和长尾项目泛化能力差的问题。&lt;h4&gt;方法&lt;/h4&gt;提出GENPLUGIN框架，包含双编码器共享解码器架构，通过对比学习对语言和ID视图进行对齐，以及使用一种新颖的训练策略和基于检索的数据增强机制来改善长尾推荐。&lt;h4&gt;主要发现&lt;/h4&gt;GENPLUGIN能够显著减轻生成暴露偏差，并显著提高长尾项目推荐的质量。&lt;h4&gt;结论&lt;/h4&gt;GENPLUGIN是一个有效的框架，可以解决GenRec中的关键限制，并在多个GenRec模型中显示出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;Generative recommendation (GenRec) 提供了LLM集成、降低嵌入成本和消除每候选人评分的功能，引起了广泛关注。尽管其性能有前景，但这项研究揭示它存在生成暴露偏差和长尾项目泛化能力差的问题，这些问题被先前关于GenRec的研究所忽视。为了解决这些问题，我们提出了GENPLUGIN，一个具有双编码器、共享解码器架构的即插即用框架。在预训练期间，它通过对比学习对齐语言和ID视图，在不同互补视图中协调项目表示。此外，GENPLUGIN使用一种新颖的训练策略，通过概率性地用语言语义编码器的预测替换真实项目ID标记，减轻暴露偏差。为了改进长尾生成推荐，我们提出了一种基于检索的数据增强机制。它微调GENPLUGIN的解码器，使GENPLUGIN能够使用与上下文或协同信息相关的相关用户来增强长尾推荐场景中项目ID标记的生成。我们将GENPLUGIN集成到几个代表性的GenRec模型中，广泛的实验表明，GENPLUGIN在生成项目ID标记时可以显著减轻生成暴露偏差，同时显著提高长尾项目推荐的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative recommendation (GenRec) offers LLM integration, reduced embeddingcosts, and eliminates per-candidate scoring, attracting great attention.Despite its promising performance, this study reveals that it suffers fromgeneration exposure bias and poor long-tail item generalization, two criticallimitations overlooked by prior works on GenRec. To address these, we proposeGENPLUGIN, a plug-and-play framework featuring a dual-encoder, shared-decoderarchitecture. During pre-training, it aligns language and ID views viacontrastive learning, harmonizing item representations across two complementaryviews. Besides, GENPLUGIN uses a novel training strategy that probabilisticallysubstitutes ground-truth item ID tokens with predictions from thelanguage-semantics encoder, alleviating exposure bias. To improve long-tailgenerative recommendation, we propose a retrieval-based data augmentationmechanism. It fine-tunes the decoder of GENPLUGIN to endow GENPLUGIN with theability to use relevant users w.r.t. contexts or collaborative information toaugment the generation of item ID tokens in long-tail recommendation scenarios.We have plugged GENPLUGIN into several representative GenRec models and theextensive experiments demonstrate that GENPLUGIN can notably mitigategeneration exposure bias during item ID generation while significantlyimproving the quality of long-tail item recommendation.</description>
      <author>example@mail.com (Kun Yang, Siyao Zheng, Tianyi Li, Xiaodong Li, Hui Li)</author>
      <guid isPermaLink="false">2507.03568v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Generating Synthetic Relational Tabular Data via Structural Causal Models</title>
      <link>http://arxiv.org/abs/2507.03528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Table Representation Learning Workshop at ACL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了合成表格数据生成在近年来受到的关注，特别是随着表格数据基础模型的出现。文章强调了合成数据在开发强大的表格基础模型中的关键作用，并介绍了一种新的框架，用于生成包含跨表因果关系的真实合成关系表格数据。&lt;h4&gt;背景&lt;/h4&gt;合成表格数据生成在近年来受到越来越多的关注，特别是随着表格数据基础模型的出现。TabPFN（Hollmann等，2025）的成功展示了合成数据在开发表格基础模型中的关键作用。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在扩展基于结构因果模型（SCM）的方法，开发一个能够生成包含跨表因果关系的真实合成关系表格数据的新框架。&lt;h4&gt;方法&lt;/h4&gt;本研究开发了一个新的框架，用于生成包含因果关系的真实合成关系表格数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架能够构建具有复杂跨表依赖关系的关联数据集，模拟真实世界场景。&lt;h4&gt;结论&lt;/h4&gt;合成数据在开发强大的表格基础模型中起着关键作用，本研究提出的方法能够生成包含跨表因果关系的真实合成关系表格数据。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Synthetic tabular data generation has received increasing attention in recent years, particularly with the emergence of foundation models for tabular data. The breakthrough success of TabPFN (Hollmann et al., 2025), which leverages vast quantities of synthetic tabular datasets derived from structural causal models (SCMs), demonstrates the critical role synthetic data plays in developing powerful tabular foundation models. However, most real-world tabular data exists in relational formats spanning multiple interconnected tables - a structure not adequately addressed by current generation methods. In this work, we extend the SCM-based approach by developing a novel framework that generates realistic synthetic relational tabular data including causal relationships across tables. Our experiments confirm that this framework is able to construct relational datasets with complex inter-table dependencies mimicking real-world scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synthetic tabular data generation has received increasing attention in recentyears, particularly with the emergence of foundation models for tabular data.The breakthrough success of TabPFN (Hollmann et al.,2025), which leverages vastquantities of synthetic tabular datasets derived from structural causal models(SCMs), demonstrates the critical role synthetic data plays in developingpowerful tabular foundation models. However, most real-world tabular dataexists in relational formats spanning multiple interconnected tables - astructure not adequately addressed by current generation methods. In this work,we extend the SCM-based approach by developing a novel framework that generatesrealistic synthetic relational tabular data including causal relationshipsacross tables. Our experiments confirm that this framework is able to constructrelational datasets with complex inter-table dependencies mimicking real-worldscenarios.</description>
      <author>example@mail.com (Frederik Hoppe, Astrid Franz, Lars Kleinemeier, Udo Göbel)</author>
      <guid isPermaLink="false">2507.03528v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Mechanics Simulation with Implicit Neural Representations of Complex Geometries</title>
      <link>http://arxiv.org/abs/2507.03087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将隐式神经网络表示（INRs）与平移边界法（SBM）结合的计算框架，用于高保真线性弹性模拟，不涉及显式几何变换，有效提高了计算效率和精度。&lt;h4&gt;背景&lt;/h4&gt;隐式神经网络表示（INRs）在计算机视觉和生成建模中表现出色，但其与计算分析工作流程（如有限元模拟）的结合尚不充分。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的计算框架，将INRs与SBM结合，实现高保真线性弹性模拟，同时避免显式几何变换。&lt;h4&gt;方法&lt;/h4&gt;通过直接查询神经网络隐式几何，获得SBM所需的代理边界和距离向量，从而有效消除网格化步骤。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在斯坦福兔子、艾菲尔铁塔、球面网等复杂几何结构上的弹性模拟中表现出显著的计算优势和准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法在生物医学、地球物理和先进制造等领域具有广泛的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：隐式神经网络表示（INRs），以神经网络编码的符号距离场为特征，提供了一种表示复杂几何形状连续且高效的方法。虽然它在计算机视觉和生成建模中取得了成功，但将其集成到计算分析工作流程中，如有限元模拟，仍处于发展阶段。在这项工作中，我们提出了一种计算框架，它无缝地将INRs与平移边界法（SBM）相结合，用于无需显式几何变换的高保真线性弹性模拟。通过直接查询神经网络隐式几何，我们获得了SBM所需的代理边界和距离向量，有效地消除了网格化步骤。我们通过在源自三角形汤和点云的复杂几何结构（斯坦福兔子、艾菲尔铁塔、球面网）上的弹性模拟，证明了我们方法的有效性和鲁棒性。我们的方法展示了显著的计算优势和准确性，突显了其在生物医学、地球物理和先进制造应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit Neural Representations (INRs), characterized by neuralnetwork-encoded signed distance fields, provide a powerful means to representcomplex geometries continuously and efficiently. While successful in computervision and generative modeling, integrating INRs into computational analysisworkflows, such as finite element simulations, remains underdeveloped. In thiswork, we propose a computational framework that seamlessly combines INRs withthe Shifted Boundary Method (SBM) for high-fidelity linear elasticitysimulations without explicit geometry transformations. By directly querying theneural implicit geometry, we obtain the surrogate boundaries and distancevectors essential for SBM, effectively eliminating the meshing step. Wedemonstrate the efficacy and robustness of our approach through elasticitysimulations on complex geometries (Stanford Bunny, Eiffel Tower, gyroids)sourced from triangle soups and point clouds. Our method showcases significantcomputational advantages and accuracy, underscoring its potential inbiomedical, geophysical, and advanced manufacturing applications.</description>
      <author>example@mail.com (Samundra Karki, Ming-Chen Hsu, Adarsh Krishnamurthy, Baskar Ganapathysubramanian)</author>
      <guid isPermaLink="false">2507.03087v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>CoT-Segmenter: Enhancing OOD Detection in Dense Road Scenes via Chain-of-Thought Reasoning</title>
      <link>http://arxiv.org/abs/2507.03984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Chain-of-Thought（CoT）的视觉推理框架，用于解决复杂道路环境中语义分割模型的Out-of-Distribution（OOD）检测问题，通过实验证明该方法在标准基准和特定挑战子集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;在复杂道路环境中，语义分割模型的可靠性至关重要。尽管大型语言模型如GPT-4在多模态推理方面取得了进展，但基于CoT的视觉推理在OOD语义分割中的应用还未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;针对现有OOD分割方法在密集重叠物体、远距离小物体和前景主导大物体等场景下的挑战，提出一种新的CoT框架，以提高OOD检测的准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;该方法利用基础模型（如GPT-4）的知识和推理能力，通过改进的图像理解和基于观察到的场景属性进行推理的prompt，增强OOD检测。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，当前最先进的OOD分割方法在密集重叠物体、远距离小物体和前景主导大物体等场景下存在困难。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，所提出的框架在标准基准和特定挑战子集上均优于现有方法，为复杂驾驶环境中的OOD语义分割提供了一种稳健且可解释的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;有效的Out-of-Distribution（OOD）检测对于确保语义分割模型的可靠性至关重要，尤其是在安全和准确性至关重要的复杂道路环境中。尽管近期大型语言模型（LLMs）如GPT-4通过思维链（CoT）提示显著增强了多模态推理，但基于CoT的视觉推理在OOD语义分割中的应用仍然未被充分探索。在本文中，通过广泛分析道路场景异常，我们确定了当前最先进的OOD分割方法在以下三个具有挑战性的场景中持续遇到困难：（1）密集重叠的物体，（2）具有小物体的远距离场景，（3）前景主导的大物体。为了解决这些问题，我们提出了一种针对道路异常场景的OOD检测的新的CoT框架。我们的方法利用基础模型（如GPT-4）的广泛知识和推理能力，通过改进的图像理解和与观察到的有问题的场景属性一致的prompt推理，来增强OOD检测。广泛的实验表明，我们的框架在标准基准和我们的新定义的挑战子集（RoadAnomaly数据集的一部分）上均优于现有方法，为复杂驾驶环境中的OOD语义分割提供了一种稳健且可解释的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective Out-of-Distribution (OOD) detection is criti-cal for ensuring thereliability of semantic segmentation models, particularly in complex roadenvironments where safety and accuracy are paramount. Despite recentadvancements in large language models (LLMs), notably GPT-4, whichsignificantly enhanced multimodal reasoning through Chain-of-Thought (CoT)prompting, the application of CoT-based visual reasoning for OOD semanticsegmentation remains largely unexplored. In this paper, through extensiveanalyses of the road scene anomalies, we identify three challenging scenarioswhere current state-of-the-art OOD segmentation methods consistently struggle:(1) densely packed and overlapping objects, (2) distant scenes with smallobjects, and (3) large foreground-dominant objects. To address the presentedchallenges, we propose a novel CoT-based framework targeting OOD detection inroad anomaly scenes. Our method leverages the extensive knowledge and reasoningcapabilities of foundation models, such as GPT-4, to enhance OOD detectionthrough improved image understanding and prompt-based reasoning aligned withobserved problematic scene attributes. Extensive experiments show that ourframework consistently outperforms state-of-the-art methods on both standardbenchmarks and our newly defined challenging subset of the RoadAnomaly dataset,offering a robust and interpretable solution for OOD semantic segmentation incomplex driving environments.</description>
      <author>example@mail.com (Jeonghyo Song, Kimin Yun, DaeUng Jo, Jinyoung Kim, Youngjoon Yoo)</author>
      <guid isPermaLink="false">2507.03984v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Helping CLIP See Both the Forest and the Trees: A Decomposition and Description Approach</title>
      <link>http://arxiv.org/abs/2507.03458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的视觉语言模型CLIP的方法，通过随机多裁剪增强来激活CLIP对局部特征的分析能力，从而提高其分类性能。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉语言模型如CLIP通过对比学习实现跨模态语义对齐，表现出强大的零样本泛化能力。然而，传统的提示工程主要依赖于粗粒度的类别标签，忽略了细粒度的局部语义。&lt;h4&gt;目的&lt;/h4&gt;为了解决CLIP在处理局部视觉描述符方面的局限性，提出了一种简单、有效且可即插即用的解决方案。&lt;h4&gt;方法&lt;/h4&gt;采用随机多裁剪增强技术，通过仅裁剪部分区域来限制模型的感受野并重新校准其注意力机制，从而减轻其对全局图像模式的偏见。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在零样本、少样本和测试时自适应设置下均取得了有希望的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的D&amp;D方法能够有效提高CLIP在局部特征分析方面的能力，从而提升其分类性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an improved method for the visual language model CLIP, which uses stochastic multi-crop augmentation to activate CLIP's latent capacity for local feature analysis, thereby improving its classification performance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) like CLIP achieve cross-modal semanticalignment through contrastive learning, exhibiting robust zero-shotgeneralization. Traditional prompt engineering, however, predominantly relieson coarse-grained category labels, neglecting fine-grained local semantics.Existing approaches assume that VLMs inherently recognize localized visualdetails and attempt to enhance classification by augmenting text prompts withattribute descriptors generated by large language models. However, oursystematic experiments reveal critical limitations: CLIP's strong bias towardglobal image patterns hinders its ability to process localized visualdescriptors. To address this fundamental constraint, we propose a simple,effective, and plug-and-play solution that enables CLIP to ``See Both theForest and the Trees." Specifically, we employ stochastic multi-cropaugmentation to activate CLIP's latent capacity for localized feature analysis.By cropping only partial regions, the approach effectively constrains themodel's receptive field and recalibrates its attention mechanism, therebymitigating its inherent bias. We evaluate the proposed method under zero-shot,few-shot, and test-time adaptation settings, and extensive experimentsdemonstrate that D&amp;D achieves promising performance.</description>
      <author>example@mail.com (Leyan Xue, Zongbo Han, Guangyu Wang, Qinghua Hu, Mingyue Cheng, Changqing Zhang)</author>
      <guid isPermaLink="false">2507.03458v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Real-TabPFN: Improving Tabular Foundation Models via Continued Pre-training With Real-World Data</title>
      <link>http://arxiv.org/abs/2507.03971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于表格数据的模型，如TabPFN，在仅使用合成数据进行预训练的小数据集上表现出色。通过有针对性的持续预训练阶段，这种性能可以得到显著提升。&lt;h4&gt;背景&lt;/h4&gt;表格数据的模型在预训练阶段使用合成数据时在小数据集上能取得强性能。&lt;h4&gt;目的&lt;/h4&gt;展示通过持续预训练来显著提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;使用小而精心挑选的大型真实世界数据集进行持续预训练，与使用更广泛但可能更嘈杂的语料库（如CommonCrawl或GitTables）相比，从而提高下游预测精度。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用小型精心挑选的数据集进行持续预训练，得到的模型Real-TabPFN在OpenML AutoML基准测试的29个数据集上实现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;Real-TabPFN模型在持续预训练后，在多个数据集上取得了更好的预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for tabular data, like TabPFN, achieve strong performanceon small datasets when pre-trained solely on synthetic data. We show that thisperformance can be significantly boosted by a targeted continued pre-trainingphase. Specifically, we demonstrate that leveraging a small, curated collectionof large, real-world datasets for continued pre-training yields superiordownstream predictive accuracy compared to using broader, potentially noisiercorpora like CommonCrawl or GitTables. Our resulting model, Real-TabPFN,achieves substantial performance gains on 29 datasets from the OpenML AutoMLBenchmark.</description>
      <author>example@mail.com (Anurag Garg, Muhammad Ali, Noah Hollmann, Lennart Purucker, Samuel Müller, Frank Hutter)</author>
      <guid isPermaLink="false">2507.03971v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>NDAI-NeuroMAP: A Neuroscience-Specific Embedding Model for Domain-Specific Retrieval</title>
      <link>http://arxiv.org/abs/2507.03329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The document consists of 15 pages in total: the first 13 pages  comprise the main paper, while the last two pages contain supplementary  material&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为NDAI-NeuroMAP的神经科学领域专用密集矢量嵌入模型，用于高精度信息检索任务。&lt;h4&gt;背景&lt;/h4&gt;目前缺乏专门针对神经科学领域的密集矢量嵌入模型。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行高精度信息检索的神经科学领域专用密集矢量嵌入模型。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含500,000个精心构建的三元组（查询-正面-负面配置）的域特定训练语料库，并增加了250,000个神经科学特定定义条目和250,000个从权威神经学本体中提取的结构化知识图谱三元组。使用FremyCompany/BioLORD-2023基础模型进行微调，并采用结合对比学习和基于三元组的度量学习范式的多目标优化框架。&lt;h4&gt;主要发现&lt;/h4&gt;在包含约24,000个神经科学特定查询的保留测试数据集上的综合评估表明，该模型在性能上显著优于最先进的通用和生物医学嵌入模型。&lt;h4&gt;结论&lt;/h4&gt;域特定嵌入架构对于神经科学导向的RAG系统和相关临床自然语言处理应用至关重要。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为NDAI-NeuroMAP的神经科学领域专用密集矢量嵌入模型，该模型是第一个为高精度信息检索任务设计的。我们的方法包括创建一个包含500,000个精心构建的三元组（查询-正面-负面配置）的广泛域特定训练语料库，并增加了250,000个神经科学特定定义条目和250,000个从权威神经学本体中提取的结构化知识图谱三元组。我们采用了一种复杂的微调方法，利用FremyCompany/BioLORD-2023基础模型，并实施了一个结合对比学习和基于三元组的度量学习范式的多目标优化框架。在包含约24,000个神经科学特定查询的保留测试数据集上的全面评估表明，该模型在性能上显著优于最先进的通用和生物医学嵌入模型。这些实证发现强调了域特定嵌入架构对于神经科学导向的RAG系统和相关临床自然语言处理应用的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present NDAI-NeuroMAP, the first neuroscience-domain-specific dense vectorembedding model engineered for high-precision information retrieval tasks. Ourmethodology encompasses the curation of an extensive domain-specific trainingcorpus comprising 500,000 carefully constructed triplets(query-positive-negative configurations), augmented with 250,000neuroscience-specific definitional entries and 250,000 structuredknowledge-graph triplets derived from authoritative neurological ontologies. Weemploy a sophisticated fine-tuning approach utilizing theFremyCompany/BioLORD-2023 foundation model, implementing a multi-objectiveoptimization framework combining contrastive learning with triplet-based metriclearning paradigms. Comprehensive evaluation on a held-out test datasetcomprising approximately 24,000 neuroscience-specific queries demonstratessubstantial performance improvements over state-of-the-art general-purpose andbiomedical embedding models. These empirical findings underscore the criticalimportance of domain-specific embedding architectures for neuroscience-orientedRAG systems and related clinical natural language processing applications.</description>
      <author>example@mail.com (Devendra Patel, Aaditya Jain, Jayant Verma, Divyansh Rajput, Sunil Mahala, Ketki Suresh Khapare, Jayateja Kalla)</author>
      <guid isPermaLink="false">2507.03329v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Level Fusion Graph Neural Network for Molecule Property Prediction</title>
      <link>http://arxiv.org/abs/2507.03430v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 11 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MLFGNN的多层次融合图神经网络，用于药物发现等领域中的分子属性预测，通过融合局部和全局分子结构，并引入分子指纹和注意力机制，在多个基准数据集上表现出色。&lt;h4&gt;背景&lt;/h4&gt;精确的分子属性预测对于药物发现等领域至关重要，但现有的图神经网络（GNNs）难以同时捕捉分子结构的局部和全局依赖。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够同时捕捉分子结构局部和全局依赖的模型，用于提高分子属性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MLFGNN的多层次融合图神经网络，该网络结合了图注意力网络和一种新的图变换器，并引入分子指纹作为补充模态，以及一个注意力交互机制以自适应融合信息。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的实验表明，MLFGNN在分类和回归任务中均优于现有方法。可解释性分析进一步揭示了模型有效地捕捉了与任务相关的化学模式。&lt;h4&gt;结论&lt;/h4&gt;多层和多模态融合在分子表示学习中是有用的，MLFGNN模型在分子属性预测方面具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;精确的分子属性预测对于药物发现及相关领域至关重要。然而，现有的图神经网络（GNNs）往往难以同时捕捉分子结构的局部和全局结构。在本工作中，我们提出了一种多层次融合图神经网络（MLFGNN），该网络结合了图注意力网络和一种新的图变换器，以联合建模局部和全局依赖。此外，我们引入了分子指纹作为补充模态，并引入了一种注意力交互机制，以自适应地融合不同表示之间的信息。在多个基准数据集上的大量实验表明，MLFGNN在分类和回归任务中均优于最先进的方法。可解释性分析进一步揭示了该模型有效地捕捉了与任务相关的化学模式，支持了多层次和多模态融合在分子表示学习中的有用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate molecular property prediction is essential in drug discovery andrelated fields. However, existing graph neural networks (GNNs) often struggleto simultaneously capture both local and global molecular structures. In thiswork, we propose a Multi-Level Fusion Graph Neural Network (MLFGNN) thatintegrates Graph Attention Networks and a novel Graph Transformer to jointlymodel local and global dependencies. In addition, we incorporate molecularfingerprints as a complementary modality and introduce a mechanism ofinteraction between attention to adaptively fuse information acrossrepresentations. Extensive experiments on multiple benchmark datasetsdemonstrate that MLFGNN consistently outperforms state-of-the-art methods inboth classification and regression tasks. Interpretability analysis furtherreveals that the model effectively captures task-relevant chemical patterns,supporting the usefulness of multi-level and multi-modal fusion in molecularrepresentation learning.</description>
      <author>example@mail.com (XiaYu Liu, Hou-biao Li, Yang Liu, Chao Fan)</author>
      <guid isPermaLink="false">2507.03430v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Adversarial Protections for Diffusion Personalization: A Comprehensive Study</title>
      <link>http://arxiv.org/abs/2507.03953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 2nd Workshop on Reliable and Responsible Foundation  Models (R2-FM 2025) at ICML. 8 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究对比了八种基于扰动的图像保护方法，评估其在不同扰动预算下的保护效果。&lt;h4&gt;背景&lt;/h4&gt;随着扩散模型在图像生成和个性化应用中的普及，隐私泄露和内容滥用问题日益突出。&lt;h4&gt;目的&lt;/h4&gt;对八种基于扰动的图像保护方法进行综合比较，以期为方法选择提供实用指导。&lt;h4&gt;方法&lt;/h4&gt;在肖像和艺术品领域对AdvDM、ASPL、FSGM、MetaCloak、Mist、PhotoGuard、SDS和SimAC等方法进行评估，使用多种指标衡量视觉不可察觉性和保护效果。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果为方法选择提供了实用指导。&lt;h4&gt;结论&lt;/h4&gt;提供了一种评估图像保护方法的方法，并在GitHub上发布了相关代码。&lt;h4&gt;翻译&lt;/h4&gt;With the increasing adoption of diffusion models for image generation and personalization, concerns regarding privacy breaches and content misuse have become more pressing. In this study, we conduct a comprehensive comparison of eight perturbation based protection methods: AdvDM, ASPL, FSGM, MetaCloak, Mist, PhotoGuard, SDS, and SimAC--across both portrait and artwork domains. These methods are evaluated under varying perturbation budgets, using a range of metrics to assess visual imperceptibility and protective efficacy. Our results offer practical guidance for method selection. Code is available at: https://github.com/vkeilo/DiffAdvPerturbationBench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing adoption of diffusion models for image generation andpersonalization, concerns regarding privacy breaches and content misuse havebecome more pressing. In this study, we conduct a comprehensive comparison ofeight perturbation based protection methods: AdvDM, ASPL, FSGM, MetaCloak,Mist, PhotoGuard, SDS, and SimAC--across both portrait and artwork domains.These methods are evaluated under varying perturbation budgets, using a rangeof metrics to assess visual imperceptibility and protective efficacy. Ourresults offer practical guidance for method selection. Code is available at:https://github.com/vkeilo/DiffAdvPerturbationBench.</description>
      <author>example@mail.com (Kai Ye, Tianyi Chen, Zhen Wang)</author>
      <guid isPermaLink="false">2507.03953v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Source-Free Domain Adaptation via Multi-view Contrastive Learning</title>
      <link>http://arxiv.org/abs/2507.03321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个基于无监督域适应的方法，以解决在实际场景中由于隐私问题导致无法访问标记数据的问题。&lt;h4&gt;背景&lt;/h4&gt;域适应在机器学习中因标记数据的成本高昂而被广泛应用。然而，隐私问题通常限制了访问敏感信息。&lt;h4&gt;目的&lt;/h4&gt;研究并提出一种无需访问标记目标域数据即可进行域适应的方法，即Source-Free Unsupervised Domain Adaptation (SFUDA)。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包含三个主要阶段：1）引入可靠的样本记忆（RSM）模块以选择更具代表性的样本，提高原型样本的质量；2）采用多视角对比学习（MVCL）方法通过多数据增强来提升伪标签的质量；3）应用噪声标签过滤技术进一步精炼伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;在VisDA 2017、Office-Home和Office-31三个基准数据集上的实验表明，该方法在分类精度上比第二好的方法提高了约2%，比13种著名的最先进方法的平均值提高了约6%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了原型样本质量低和伪标签分配不正确的问题，为无监督域适应提供了一种可行的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：域适应由于与标记数据相关的高成本，在机器学习中已经成为一种广泛采用的方法。它通常在可访问标记源域的情况下应用。然而，在现实场景中，隐私问题通常会限制对敏感信息，如指纹、银行账户详情和面部图像的访问。解决此问题的有希望的方法是源免费无监督域适应（SFUDA），它可以在不要求访问标记的目标域数据的情况下进行域适应。最近的研究表明，SFUDA可以有效地解决域差异问题；然而，仍然存在两个关键挑战：（1）原型样本的低质量；（2）伪标签的错误分配。为了应对这些挑战，我们提出了一种由三个主要阶段组成的方法。在第一阶段，我们引入了一个可靠的样本记忆（RSM）模块，通过选择更具代表性的样本来提高原型的质量。在第二阶段，我们采用了一种多视图对比学习（MVCL）方法，通过利用多个数据增强来提高伪标签的质量。在最后一阶段，我们应用了一种噪声标签过滤技术来进一步精炼伪标签。我们在三个基准数据集——VisDA 2017、Office-Home和Office-31上的实验表明，我们的方法在分类精度上分别比第二好的方法提高了约2%，比13种著名的最先进方法的平均值提高了约6%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain adaptation has become a widely adopted approach in machine learningdue to the high costs associated with labeling data. It is typically appliedwhen access to a labeled source domain is available. However, in real-worldscenarios, privacy concerns often restrict access to sensitive information,such as fingerprints, bank account details, and facial images. A promisingsolution to this issue is Source-Free Unsupervised Domain Adaptation (SFUDA),which enables domain adaptation without requiring access to labeled targetdomain data. Recent research demonstrates that SFUDA can effectively addressdomain discrepancies; however, two key challenges remain: (1) the low qualityof prototype samples, and (2) the incorrect assignment of pseudo-labels. Totackle these challenges, we propose a method consisting of three main phases.In the first phase, we introduce a Reliable Sample Memory (RSM) module toimprove the quality of prototypes by selecting more representative samples. Inthe second phase, we employ a Multi-View Contrastive Learning (MVCL) approachto enhance pseudo-label quality by leveraging multiple data augmentations. Inthe final phase, we apply a noisy label filtering technique to further refinethe pseudo-labels. Our experiments on three benchmark datasets - VisDA 2017,Office-Home, and Office-31 - demonstrate that our method achieves approximately2 percent and 6 percent improvements in classification accuracy over thesecond-best method and the average of 13 well-known state-of-the-artapproaches, respectively.</description>
      <author>example@mail.com (Amirfarhad Farhadi, Naser Mozayani, Azadeh Zamanifar)</author>
      <guid isPermaLink="false">2507.03321v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Prosody Labeling with Phoneme-BERT and Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2507.03912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Speech Synthesis Workshop 2025 (SSW13)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种自动语音节奏标签标注模型，该模型可用于训练节奏可控的语音合成模型。&lt;h4&gt;背景&lt;/h4&gt;语音节奏标注在语音合成中非常重要，而现有的语音节奏标注方法通常依赖于单一特征。&lt;h4&gt;目的&lt;/h4&gt;提高语音节奏标注的准确性，并使其可用于训练节奏可控的语音合成模型。&lt;h4&gt;方法&lt;/h4&gt;提出的模型结合了自监督学习模型或Whisper编码器提取的丰富声学特征，以及来自PnG BERT和PL-BERT等语音输入预训练语言基础模型的语言学特征，以预测音素级别的语音节奏标签。&lt;h4&gt;主要发现&lt;/h4&gt;在日语语音节奏标签（包括音高重音和短语断句索引）的实验评估中，使用语音和语言基础模型组合的方法比单独使用语音或语言输入提高了预测精度。&lt;h4&gt;结论&lt;/h4&gt;该方法在重音标签上的预测准确率为89.8%，在高低音重音上的预测准确率为93.2%，在断句索引上的预测准确率为94.3%。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种用于自动语音节奏标签标注的模型，预测的标签可用于训练节奏可控的语音合成模型。该模型不仅利用了基于自监督学习（SSL）的模型或Whisper编码器提取的丰富声学特征，还利用了从PnG BERT和PL-BERT等音素输入预训练语言基础模型获得的语言学特征。声学和语言学特征的结合用于预测音素级别的语音节奏标签。在日语语音节奏标签（包括音高重音和短语断句索引）的实验评估中，观察到使用语音和语言基础模型组合的方法比单独使用语音或语言输入提高了预测准确率。具体而言，我们在重音标签上实现了89.8%的预测准确率，在高低音重音上实现了93.2%，在断句索引上实现了94.3%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a model for automatic prosodic label annotation, wherethe predicted labels can be used for training a prosody-controllabletext-to-speech model. The proposed model utilizes not only rich acousticfeatures extracted by a self-supervised-learning (SSL)-based model or a Whisperencoder, but also linguistic features obtained from phoneme-input pretrainedlinguistic foundation models such as PnG BERT and PL-BERT. The concatenation ofacoustic and linguistic features is used to predict phoneme-level prosodiclabels. In the experimental evaluation on Japanese prosodic labels, includingpitch accents and phrase break indices, it was observed that the combination ofboth speech and linguistic foundation models enhanced the prediction accuracycompared to using either a speech or linguistic input alone. Specifically, weachieved 89.8% prediction accuracy in accent labels, 93.2% in high-low pitchaccents, and 94.3% in break indices.</description>
      <author>example@mail.com (Tomoki Koriyama)</author>
      <guid isPermaLink="false">2507.03912v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains</title>
      <link>http://arxiv.org/abs/2507.03026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了GATN，一种针对强化学习中的迁移学习架构，旨在解决跨域任务泛化、环境变化鲁棒性和迁移学习中的计算效率问题。&lt;h4&gt;背景&lt;/h4&gt;迁移学习在强化学习中允许智能体利用源任务知识加速目标任务的学习。尽管已有框架如A2T解决了负迁移和选择性迁移问题，但其他关键挑战仍待探索。&lt;h4&gt;目的&lt;/h4&gt;提出GATN，旨在解决任务泛化、环境变化鲁棒性和计算效率问题。&lt;h4&gt;方法&lt;/h4&gt;GATN采用领域无关表示模块、鲁棒性感知策略适配器和高效的迁移调度器来实现目标。&lt;h4&gt;主要发现&lt;/h4&gt;在包括Atari 2600、MuJoCo和自定义聊天机器人对话环境在内的多个基准测试中，GATN在跨域泛化、对动态环境的抵抗力和计算开销降低方面优于基线。&lt;h4&gt;结论&lt;/h4&gt;GATN是一个适用于现实世界强化学习应用的通用框架，如自适应聊天机器人和机器人控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning in Reinforcement Learning (RL) enables agents to leverageknowledge from source tasks to accelerate learning in target tasks. While priorwork, such as the Attend, Adapt, and Transfer (A2T) framework, addressesnegative transfer and selective transfer, other critical challenges remainunderexplored. This paper introduces the Generalized Adaptive Transfer Network(GATN), a deep RL architecture designed to tackle task generalization acrossdomains, robustness to environmental changes, and computational efficiency intransfer. GATN employs a domain-agnostic representation module, arobustness-aware policy adapter, and an efficient transfer scheduler to achievethese goals. We evaluate GATN on diverse benchmarks, including Atari 2600,MuJoCo, and a custom chatbot dialogue environment, demonstrating superiorperformance in cross-domain generalization, resilience to dynamic environments,and reduced computational overhead compared to baselines. Our findings suggestGATN is a versatile framework for real-world RL applications, such as adaptivechatbots and robotic control.</description>
      <author>example@mail.com (Abhishek Verma, Nallarasan V, Balaraman Ravindran)</author>
      <guid isPermaLink="false">2507.03026v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>FastDINOv2: Frequency Based Curriculum Learning Improves Robustness and Training Speed</title>
      <link>http://arxiv.org/abs/2507.03779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个针对DINOv2的新的预训练策略，旨在同时加速收敛并增强对常见破坏的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;大规模视觉基础模型如DINOv2通过使用大规模架构和训练数据集取得了令人印象深刻的性能。然而，在私有数据、新模态或科学探究等场景下复现这些预训练解决方案计算量巨大。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的预训练策略，以便在计算成本降低的同时，保持模型的鲁棒性和性能。&lt;h4&gt;方法&lt;/h4&gt;采用频率过滤课程（首先处理低频信息）和高斯噪声修补增强技术。&lt;h4&gt;主要发现&lt;/h4&gt;将此方法应用于ImageNet-1K上训练的ViT-B/16主干网络，预训练时间和FLOPs分别减少了1.6倍和2.25倍。该方法在破坏基准测试（ImageNet-C）中实现了与基线相同的鲁棒性，并在线性探针性能上保持了竞争力。&lt;h4&gt;结论&lt;/h4&gt;这种方法实现了效率和鲁棒性的双重效益，使得大规模自监督基础模型更易实现，并为进一步探索数据课程和增强作为提高自监督学习模型鲁棒性的手段敞开了大门。&lt;h4&gt;翻译&lt;/h4&gt;Large-scale vision foundation models such as DINOv2 boast impressive performances by leveraging massive architectures and training datasets. But numerous scenarios require practitioners to reproduce those pre-training solutions, such as on private data, new modalities, or simply for scientific questioning--which is currently extremely demanding computation-wise. We thus propose a novel pre-training strategy for DINOv2 that simultaneously accelerates convergence--and strengthens robustness to common corruptions as a by-product. Our approach involves a frequency filtering curriculum--low-frequency being seen first--and the Gaussian noise patching augmentation. Applied to a ViT-B/16 backbone trained on ImageNet-1K, while pre-training time and FLOPs are reduced by 1.6x and 2.25x, our method still achieves matching robustness in corruption benchmarks (ImageNet-C) and maintains competitive linear probing performance compared with baseline. This dual benefit of efficiency and robustness makes large-scale self-supervised foundation modeling more attainable, while opening the door to new exploration around data curriculum and augmentation as means to improve self-supervised learning models robustness. The code is available at https://github.com/KevinZ0217/fast_dinov2&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale vision foundation models such as DINOv2 boast impressiveperformances by leveraging massive architectures and training datasets. Butnumerous scenarios require practitioners to reproduce those pre-trainingsolutions, such as on private data, new modalities, or simply for scientificquestioning--which is currently extremely demanding computation-wise. We thuspropose a novel pre-training strategy for DINOv2 that simultaneouslyaccelerates convergence--and strengthens robustness to common corruptions as aby-product. Our approach involves a frequency filteringcurriculum--low-frequency being seen first--and the Gaussian noise patchingaugmentation. Applied to a ViT-B/16 backbone trained on ImageNet-1K, whilepre-training time and FLOPs are reduced by 1.6x and 2.25x, our method stillachieves matching robustness in corruption benchmarks (ImageNet-C) andmaintains competitive linear probing performance compared with baseline. Thisdual benefit of efficiency and robustness makes large-scale self-supervisedfoundation modeling more attainable, while opening the door to novelexploration around data curriculum and augmentation as means to improveself-supervised learning models robustness. The code is available athttps://github.com/KevinZ0217/fast_dinov2</description>
      <author>example@mail.com (Jiaqi Zhang, Juntuo Wang, Zhixin Sun, John Zou, Randall Balestriero)</author>
      <guid isPermaLink="false">2507.03779v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Domain Generalization to Multimodal Domain Generalization via Unified Representations</title>
      <link>http://arxiv.org/abs/2507.03304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对多模态领域泛化的新方法，旨在提高模型在未见过的、分布上发生偏移的目标域中的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;尽管现有的领域泛化技术已经取得了显著进展，但它们主要针对单模态数据，而多模态数据集和任务的需求日益增长。&lt;h4&gt;目的&lt;/h4&gt;解决多模态领域泛化（MMDG）的关键挑战，即使在多模态源上训练的模型能够泛化到同一模态集中的未见过的目标分布。&lt;h4&gt;方法&lt;/h4&gt;提出了一种利用统一表示的方法，将不同的配对模态映射在一起，通过在统一空间中实现同步的多模态改进来有效适应MMDG。此外，还引入了一个监督解耦框架，将模态通用和模态特定信息分离，进一步增强了统一表示的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在EPIC-Kitchens和Human-Animal-Cartoon等基准数据集上的大量实验表明，该方法在增强多模态领域泛化方面具有有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;该方法通过统一表示和解耦框架，有效地解决了MMDG中的挑战，并显著提高了多模态领域泛化的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：领域泛化（DG）旨在通过仅在源域上训练来增强模型在未见过的、分布上发生偏移的目标域中的鲁棒性。尽管现有的DG技术，如数据操作、学习策略和表示学习，已经显示出显著的进步，但它们主要针对单模态数据。随着众多多模态数据集和对于多模态任务需求的增加，多模态领域泛化（MMDG）出现了一个关键挑战：使在多模态源上训练的模型能够泛化到同一模态集中的未见过的目标分布。由于模态之间的固有差异，直接将单模态DG方法应用于MMDG通常会产生次优结果。这些方法在泛化过程中往往表现出随机性，因为目标域是不可见的，并且没有考虑跨模态一致性。在MMDG设置中将这些方法独立应用于每个模态，然后再将它们组合起来，可能导致不同模态之间的泛化方向不一致，从而降低泛化能力。为了解决这些挑战，我们提出了一种新颖的方法，该方法利用统一表示将不同的配对模态映射在一起，通过在统一空间中实现同步的多模态改进来有效地将DG方法适应MMDG。此外，我们还引入了一个监督解耦框架，将模态通用和模态特定信息分离，进一步增强了统一表示的对齐。在EPIC-Kitchens和Human-Animal-Cartoon等基准数据集上的大量实验证明了我们方法在增强多模态领域泛化方面的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Generalization (DG) aims to enhance model robustness in unseen ordistributionally shifted target domains through training exclusively on sourcedomains. Although existing DG techniques, such as data manipulation, learningstrategies, and representation learning, have shown significant progress, theypredominantly address single-modal data. With the emergence of numerousmulti-modal datasets and increasing demand for multi-modal tasks, a keychallenge in Multi-modal Domain Generalization (MMDG) has emerged: enablingmodels trained on multi-modal sources to generalize to unseen targetdistributions within the same modality set. Due to the inherent differencesbetween modalities, directly transferring methods from single-modal DG to MMDGtypically yields sub-optimal results. These methods often exhibit randomnessduring generalization due to the invisibility of target domains and fail toconsider inter-modal consistency. Applying these methods independently to eachmodality in the MMDG setting before combining them can lead to divergentgeneralization directions across different modalities, resulting in degradedgeneralization capabilities. To address these challenges, we propose a novelapproach that leverages Unified Representations to map different pairedmodalities together, effectively adapting DG methods to MMDG by enablingsynchronized multi-modal improvements within the unified space. Additionally,we introduce a supervised disentanglement framework that separatesmodal-general and modal-specific information, further enhancing the alignmentof unified representations. Extensive experiments on benchmark datasets,including EPIC-Kitchens and Human-Animal-Cartoon, demonstrate the effectivenessand superiority of our method in enhancing multi-modal domain generalization.</description>
      <author>example@mail.com (Hai Huang, Yan Xia, Sashuai Zhou, Hanting Wang, Shulei Wang, Zhou Zhao)</author>
      <guid isPermaLink="false">2507.03304v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos</title>
      <link>http://arxiv.org/abs/2505.11868v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种创新框架，能够从单目视频中无监督地分析3D运动，精确地解析运动部分和运动属性，无需标注训练数据。&lt;h4&gt;背景&lt;/h4&gt;准确分析动态环境中的运动部分及其运动属性对于推进如具身智能等关键领域至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法依赖密集多视角图像或详细部分级标注的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法首先构建场景几何，结合深度估计、光流分析和点云配准方法粗略分析运动部分及其初始运动属性，然后使用二维高斯散点表示场景。在此基础上，引入了专门为关节物体设计的端到端动态场景优化算法，以细化初始分析结果，确保系统可以处理旋转、平移以及更复杂的运动（旋转+平移）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架可以有效地在无标注的情况下分析关节物体的运动，展示了其在未来具身智能应用中的巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;该方法在无标注的情况下分析关节物体运动，具有鲁棒性和广泛适用性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes an innovative framework that can analyze 3D motion from monocular videos in a zero-shot manner, accurately parse motion parts and motion attributes without the need for annotated training data. The method first constructs the scene geometry, roughly analyzes the motion parts and their initial motion attributes by combining depth estimation, optical flow analysis, and point cloud registration methods, then uses 2D Gaussian splatting for scene representation. Based on this, an end-to-end dynamic scene optimization algorithm specifically designed for articulated objects is introduced to refine the initial analysis results, ensuring that the system can handle 'rotation', 'translation', and even complex movements ('rotation+translation'). Experimental results show that the framework can effectively analyze articulated object motions in an annotation-free manner, showcasing its significant potential in future embodied intelligence applications.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-05-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately analyzing the motion parts and their motion attributes in dynamicenvironments is crucial for advancing key areas such as embodied intelligence.Addressing the limitations of existing methods that rely on dense multi-viewimages or detailed part-level annotations, we propose an innovative frameworkthat can analyze 3D mobility from monocular videos in a zero-shot manner. Thisframework can precisely parse motion parts and motion attributes only using amonocular video, completely eliminating the need for annotated training data.Specifically, our method first constructs the scene geometry and roughlyanalyzes the motion parts and their initial motion attributes combining depthestimation, optical flow analysis and point cloud registration method, thenemploys 2D Gaussian splatting for scene representation. Building on this, weintroduce an end-to-end dynamic scene optimization algorithm specificallydesigned for articulated objects, refining the initial analysis results toensure the system can handle 'rotation', 'translation', and even complexmovements ('rotation+translation'), demonstrating high flexibility andversatility. To validate the robustness and wide applicability of our method,we created a comprehensive dataset comprising both simulated and real-worldscenarios. Experimental results show that our framework can effectively analyzearticulated object motions in an annotation-free manner, showcasing itssignificant potential in future embodied intelligence applications.</description>
      <author>example@mail.com (Hongyi Zhou, Xiaogang Wang, Yulan Guo, Kai Xu)</author>
      <guid isPermaLink="false">2505.11868v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Subject Invariant Contrastive Learning for Human Activity Recognition</title>
      <link>http://arxiv.org/abs/2507.03250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Subject-Invariant Contrastive Learning（SICL）的损失函数，用于提高人类活动识别（HAR）模型的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;数据标注成本高，使得自监督方法如对比学习方法在HAR领域具有吸引力。然而，由于主体变异性导致的领域变化阻碍了模型对新主体的泛化。&lt;h4&gt;目的&lt;/h4&gt;提出SICL损失函数，以改善HAR模型在泛化方面的表现。&lt;h4&gt;方法&lt;/h4&gt;SICL通过重新加权来自同一主体的负样本对，抑制主体特定线索，强调活动特定信息。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公共基准数据集（UTD-MHAD、MMAct、DARai）上评估SICL，发现其性能比传统对比学习方法提高了11%。SICL损失函数在各种设置中表现出良好的适应性，包括多种自监督方法、多模态场景和监督学习框架。&lt;h4&gt;结论&lt;/h4&gt;SICL是一种简单而有效的损失函数，能够显著提高HAR模型的泛化能力，并在不同设置中表现出良好的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The high cost of annotating data makes self-supervised approaches, such ascontrastive learning methods, appealing for Human Activity Recognition (HAR).Effective contrastive learning relies on selecting informative positive andnegative samples. However, HAR sensor signals are subject to significant domainshifts caused by subject variability. These domain shifts hinder modelgeneralization to unseen subjects by embedding subject-specific variationsrather than activity-specific features. As a result, human activity recognitionmodels trained with contrastive learning often struggle to generalize to newsubjects. We introduce Subject-Invariant Contrastive Learning (SICL), a simpleyet effective loss function to improve generalization in human activityrecognition. SICL re-weights negative pairs drawn from the same subject tosuppress subject-specific cues and emphasize activity-specific information. Weevaluate our loss function on three public benchmarks: UTD-MHAD, MMAct, andDARai. We show that SICL improves performance by up to 11% over traditionalcontrastive learning methods. Additionally, we demonstrate the adaptability ofour loss function across various settings, including multiple self-supervisedmethods, multimodal scenarios, and supervised learning frameworks.</description>
      <author>example@mail.com (Yavuz Yarici, Kiran Kokilepersaud, Mohit Prabhushankar, Ghassan AlRegib)</author>
      <guid isPermaLink="false">2507.03250v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network</title>
      <link>http://arxiv.org/abs/2507.03401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文设计了一种灾后通信智能网络（PDPCIN），以解决灾后区域由于地面基站（GBS）故障造成的通信中断问题。&lt;h4&gt;背景&lt;/h4&gt;灾后区域地面基站故障导致通信中断。&lt;h4&gt;目的&lt;/h4&gt;确保基本灾后通信，并优化信息年龄（AoI）、能效和频谱效率。&lt;h4&gt;方法&lt;/h4&gt;使用无人机（UAV）提供无线数据收集（WDC）和无线能量传输（WET），并利用低地球轨道卫星（LEO SATs）中继无人机数据到最近的存活GBS。提出了智能同步-无人机（IS-UAV）架构、基于AoI的四阈值更新（AFTU）机制和动态多LEO接入（DMLA）策略。针对时间变化的任务-资源不平衡、由多设备调度引起的复杂拓扑和非线性耦合的多维度量优化问题，提出了分层异构图神经网络（HHGNN）框架。为了寻找合适的单个LEO卫星数量，提出了单个LEO卫星密度优化（S-LSDO）算法。&lt;h4&gt;主要发现&lt;/h4&gt;提出了HHGNN框架，并提出了S-LSDO算法。验证了所提出方案在AoI、能效和频谱效率方面的优越协同优化。&lt;h4&gt;结论&lt;/h4&gt;推导了AoI和停滞AoI比例的期望值表达式。&lt;h4&gt;翻译&lt;/h4&gt;本文设计了一种灾后通信智能网络（PDPCIN）来应对灾后区域地面基站（GBS）故障引起的通信中断问题。PDPCIN使用无人机（UAV）提供无线数据收集（WDC）和无线能量传输（WET）为受影响区域服务，并利用低地球轨道卫星（LEO SATs）将无人机数据中继到最近的存活GBS。为确保基本灾后通信并协同优化信息年龄（AoI）、能效和频谱效率，提出了智能同步-无人机（IS-UAV）架构、基于AoI的四阈值更新（AFTU）机制和动态多LEO接入（DMLA）策略。然而，仍然存在三个关键挑战：时间变化的任务-资源不平衡、由多设备调度引起的复杂拓扑以及多维度量优化中的非线性耦合，使得系统优化为NP难题。因此，本文提出了分层异构图神经网络（HHGNN）框架。该框架将异构设备节点及其通信关系建模为分层异构图结构，整合了我们定义的图感知、交换和掩码层来处理网络的输入、特征传播和输出。为了寻找合适的单个LEO卫星数量，我们提出了单个LEO卫星密度优化（S-LSDO）算法。最后，我们将所提出的方案与最先进的基准进行比较，以验证其在AoI、能效和频谱效率方面的优越协同优化。基于此，推导了AoI和停滞AoI比例的期望值表达式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper designs a post-disaster powered communication intelligent network(PDPCIN) to address communication disruptions caused by ground base station(GBS) failures within the post-disaster area. PDPCIN employs unmanned aerialvehicles (UAVs) to provide wireless data collection (WDC) and wireless energytransmission (WET) for affected areas and leverages low earth orbit satellites(LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basicpost-disaster communication while co-optimizing age of information (AoI),energy efficiency, and spectrum efficiency, intelligent synchronization-UAV(IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, andDynamic multi-LEO access (DMLA) strategy are proposed. However, three keychallenges remain: time-varying task-resource imbalances, complex topologycaused by multi-device scheduling, and nonlinear coupling in multidimensionalmetric optimization, making system optimization NP-hard. Therefore, this paperproposes a hierarchical heterogeneous graph neural networks (HHGNN) framework.It models heterogeneous device nodes and their communication relations as ahierarchical heterogeneous graph structure, integrating our defined graphsensing, exchange, and mask layer to handle the network's input, featurepropagation, and output. To search appropriate number of single-LEO SATs, wepropose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, wecompare the proposed scheme with state-of-the-art benchmarks to validate itssuperior collaborative optimization of AoI, energy efficiency, and spectrumefficiency. Based on this, we derive the expressions for the expected values ofAoI and stagnant AoI proportion.</description>
      <author>example@mail.com (Hanjian Liu, Jinsong Gui)</author>
      <guid isPermaLink="false">2507.03401v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Latent Thermodynamic Flows: Unified Representation Learning and Generative Modeling of Temperature-Dependent Behaviors from Limited Data</title>
      <link>http://arxiv.org/abs/2507.03174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Latent Thermodynamic Flows（LaTF）的框架，用于准确描述复杂分子系统的平衡分布及其对环境因素如温度的依赖性。&lt;h4&gt;背景&lt;/h4&gt;准确描述复杂分子系统的平衡分布及其对环境因素如温度的依赖性对于理解热力学性质和转变机制至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过投影分布到有意义的低维表示，提高可解释性和下游分析，同时结合表示学习和生成建模来模拟这些分布。&lt;h4&gt;方法&lt;/h4&gt;LaTF将状态预测信息瓶颈（SPIB）与正常化流（NFs）结合，学习低维潜在表示（集体变量，CVs），分类亚稳态，并在训练数据以外的温度下生成平衡分布。&lt;h4&gt;主要发现&lt;/h4&gt;LaTF在多种系统上显示出有效性，包括模型势、Chignolin蛋白和Lennard Jones粒子群，通过多种指标和广泛模拟进行了彻底评估和基准测试。&lt;h4&gt;结论&lt;/h4&gt;LaTF在RNA tetraloop系统中应用成功，即使只使用两种温度的模拟数据，也能重建温度依赖的结构集和熔化行为，与实验和先前广泛计算的结果一致。&lt;h4&gt;翻译&lt;/h4&gt;Accurate characterization of the equilibrium distributions of complexmolecular systems and their dependence on environmental factors such as temperature is essential for understanding thermodynamic properties and transition mechanisms. Projecting these distributions onto meaningful low-dimensional representations enables interpretability and downstream analysis. Recent advances in generative AI, particularly flow models such as Normalizing Flows (NFs), have shown promise in modeling such distributions, but their scope is limited without tailored representation learning. In this work, we introduce Latent Thermodynamic Flows (LaTF), an end-to-end framework that tightly integrates representation learning and generative modeling. LaTFunifies the State Predictive Information Bottleneck (SPIB) with NFs to simultaneously learn low-dimensional latent representations, referred to as Collective Variables (CVs), classify metastable states, and generate equilibrium distributions across temperatures beyond the training data. The two components of representation learning and generative modeling are optimized jointly, ensuring that the learned latent features capture the system's slow, important degrees of freedom while the generative model accurately reproducesthe system's equilibrium behavior. We demonstrate LaTF's effectiveness across diverse systems, including a model potential, the Chignolin protein, and cluster of Lennard Jones particles, with thorough evaluations and benchmarking using multiple metrics and extensive simulations. Finally, we apply LaTF to an RNA tetraloop system, where despite using simulation data from only two temperatures, LaTF reconstructs the temperature-dependent structural ensemble and melting behavior, consistent with experimental and prior extensive computational results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate characterization of the equilibrium distributions of complexmolecular systems and their dependence on environmental factors such astemperature is essential for understanding thermodynamic properties andtransition mechanisms. Projecting these distributions onto meaningfullow-dimensional representations enables interpretability and downstreamanalysis. Recent advances in generative AI, particularly flow models such asNormalizing Flows (NFs), have shown promise in modeling such distributions, buttheir scope is limited without tailored representation learning. In this work,we introduce Latent Thermodynamic Flows (LaTF), an end-to-end framework thattightly integrates representation learning and generative modeling. LaTFunifies the State Predictive Information Bottleneck (SPIB) with NFs tosimultaneously learn low-dimensional latent representations, referred to asCollective Variables (CVs), classify metastable states, and generateequilibrium distributions across temperatures beyond the training data. The twocomponents of representation learning and generative modeling are optimizedjointly, ensuring that the learned latent features capture the system's slow,important degrees of freedom while the generative model accurately reproducesthe system's equilibrium behavior. We demonstrate LaTF's effectiveness acrossdiverse systems, including a model potential, the Chignolin protein, andcluster of Lennard Jones particles, with thorough evaluations and benchmarkingusing multiple metrics and extensive simulations. Finally, we apply LaTF to aRNA tetraloop system, where despite using simulation data from only twotemperatures, LaTF reconstructs the temperature-dependent structural ensembleand melting behavior, consistent with experimental and prior extensivecomputational results.</description>
      <author>example@mail.com (Yunrui Qiu, Richard John, Lukas Herron, Pratyush Tiwary)</author>
      <guid isPermaLink="false">2507.03174v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Structure-Aware Compound-Protein Affinity Prediction via Graph Neural Network with Group Lasso Regularization</title>
      <link>http://arxiv.org/abs/2507.03318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可解释人工智能的药物发现方法，利用图神经网络（GNN）预测化合物与蛋白质的亲和力，并通过活动悬崖分子对提高模型的可解释性和预测准确性。&lt;h4&gt;背景&lt;/h4&gt;可解释人工智能（XAI）在药物发现中的应用日益增加，但建立端到端可解释的机器学习模型以预测化合物性质面临挑战，如活动数据有限和性质对细微分子变化的敏感性。&lt;h4&gt;目的&lt;/h4&gt;解决药物发现中结构-活性关系（SAR）建模的挑战，提高化合物性质预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;利用具有不同活性的活动悬崖分子对，通过图神经网络（GNN）获取原子级特征信息，并预测化合物的半数抑制浓度（IC50）。同时，使用不同的结构感知损失函数训练GNN模型，并利用group lasso和sparse group lasso进行子图剪枝和突出显示，以增强模型对预测性质差异的解释性。&lt;h4&gt;主要发现&lt;/h4&gt;通过整合常见和罕见的节点信息以及使用sparse group lasso，平均均方根误差（RMSE）降低了12.70%，实现了最低的平均RMSE=0.2551和最高的相关系数（PCC）=0.9572。此外，正则化增强了特征归因方法，提高了模型在药物发现流程中的可解释性。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了药物性质预测的准确性，并通过增强模型的可解释性，有助于在先导优化中研究重要的分子亚结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explainable artificial intelligence (XAI) approaches have been increasinglyapplied in drug discovery to learn molecular representations and identifysubstructures driving property predictions. However, building end-to-endexplainable machine learning models for structure-activity relationship (SAR)modeling for compound property prediction faces many challenges, such aslimited activity data per target and the sensitivity of properties to subtlemolecular changes. To address this, we leveraged activity-cliff molecule pairs,i.e., compounds sharing a common scaffold but differing sharply in potency,targeting three proto-oncogene tyrosine-protein kinase Src proteins (i.e., PDBIDs 1O42, 2H8H, and 4MXO). We implemented graph neural network (GNN) methods toobtain atom-level feature information and predict compound-protein affinity(i.e., half maximal inhibitory concentration, IC50). In addition, we trainedGNN models with different structure-aware loss functions to adequately leveragemolecular property and structure information. We also utilized group lasso andsparse group lasso to prune and highlight molecular subgraphs and enhance thestructure-specific model explainability for the predicted property differencein molecular activity-cliff pairs. We improved drug property prediction byintegrating common and uncommon node information and using sparse group lasso,reducing the average root mean squared error (RMSE) by 12.70%, and achievingthe lowest averaged RMSE=0.2551 and the highest PCC=0.9572. Furthermore,applying regularization enhances feature attribution methods that estimate thecontribution of each atom in the molecular graphs by boosting global directionscores and atom-level accuracy in atom coloring accuracy, which improves modelinterpretability in drug discovery pipelines, particularly in investigatingimportant molecular substructures in lead optimization.</description>
      <author>example@mail.com (Zanyu Shi, Yang Wang, Pathum Weerawarna, Jie Zhang, Timothy Richardson, Yijie Wang, Kun Huang)</author>
      <guid isPermaLink="false">2507.03318v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>From stellar light to astrophysical insight: automating variable star research with machine learning</title>
      <link>http://arxiv.org/abs/2507.03093v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Author accepted version of Invited Review for 2024 Astronomy Prize  Awardees Collection of Astrophysics and Space Science journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了机器学习在恒星多变性研究中的应用，特别是如何通过机器学习实现自动化的科学发现。&lt;h4&gt;背景&lt;/h4&gt;大规模的光度巡天如NASA的Kepler和TESS卫星，以及即将到来的ESA PLATO任务，为研究恒星多变性、 asteroseismology 和系外行星提供了丰富的数据。&lt;h4&gt;目的&lt;/h4&gt;为了充分利用这些大量数据集的科研潜力，需要使用自动化的数据驱动方法。&lt;h4&gt;方法&lt;/h4&gt;本文展示了机器学习在从数据清理到多变性分类和参数推断的整个周期中如何推动 asteroseismology 的发展，并突出了表示学习、多模态数据集和基础模型方面的最新进展。&lt;h4&gt;主要发现&lt;/h4&gt;机器学习正在将 asteroseismology 引向自动化的科学发现时代。&lt;h4&gt;结论&lt;/h4&gt;机器学习为恒星多变性研究带来了挑战和机遇，并有助于开启时间域天文学的新领域。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大规模光度巡天正在通过提供前所未有的数据量而改变天文学。来自NASA的Kepler和TESS卫星以及即将到来的ESA PLATO任务等任务的大量数据集是研究恒星多变性、asteroseismology和系外行星的宝藏。为了充分利用这些大量数据集的科研潜力，需要自动化的数据驱动方法。在这篇综述中，我展示了机器学习如何推动asteroseismology进入自动化的科学发现时代，涵盖了从数据清理到多变性分类和参数推断的整个周期，同时突出了表示学习、多模态数据集和基础模型方面的最新进展。这篇特邀综述为机器学习带来的挑战和机遇提供了指南，以及它如何帮助开启时间域天文学的新领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale photometric surveys are revolutionizing astronomy by deliveringunprecedented amounts of data. The rich data sets from missions such as theNASA Kepler and TESS satellites, and the upcoming ESA PLATO mission, are atreasure trove for stellar variability, asteroseismology and exoplanet studies.In order to unlock the full scientific potential of these massive data sets,automated data-driven methods are needed. In this review, I illustrate howmachine learning is bringing asteroseismology toward an era of automatedscientific discovery, covering the full cycle from data cleaning to variabilityclassification and parameter inference, while highlighting the recent advancesin representation learning, multimodal datasets and foundation models. Thisinvited review offers a guide to the challenges and opportunities machinelearning brings for stellar variability research and how it could help unlocknew frontiers in time-domain astronomy.</description>
      <author>example@mail.com (Jeroen Audenaert)</author>
      <guid isPermaLink="false">2507.03093v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>SAMed-2: Selective Memory Enhanced Medical Segment Anything Model</title>
      <link>http://arxiv.org/abs/2507.03698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAMed-2的新基础模型，用于医学图像分割，通过引入时间适配器和信心驱动的记忆机制来应对医学数据的复杂性、噪声标注以及不同模态和解剖结构的学习需求。&lt;h4&gt;背景&lt;/h4&gt;由于医学数据的复杂性、噪声标注和不同模态及解剖结构的学习需求，直接将大规模数据学习的模型应用于医学图像分割仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出SAMed-2模型，以应对医学图像分割的挑战。&lt;h4&gt;方法&lt;/h4&gt;在SAM-2架构的基础上，引入时间适配器以捕捉图像相关性，并引入信心驱动的记忆机制来存储高置信度特征以便后续检索。同时，构建了MedBank-100k数据集，包含七种成像模态和21项医学分割任务，用于训练和评估SAMed-2。&lt;h4&gt;主要发现&lt;/h4&gt;SAMed-2在内部基准测试和10个外部数据集上的实验表明，在多任务场景中，其性能优于现有的最先进基线模型。&lt;h4&gt;结论&lt;/h4&gt;SAMed-2模型在医学图像分割方面具有优越性能，能够有效应对医学数据中的噪声和遗忘问题。&lt;h4&gt;翻译&lt;/h4&gt;Recent 'segment anything' efforts show promise by learning from large-scale data, but adapting such models directly to medical images remains challenging due to the complexity of medical data, noisy annotations, and continual learning requirements across diverse modalities and anatomical structures. In this work, we propose SAMed-2, a new foundation model for medical image segmentation built upon the SAM-2 architecture. Specifically, we introduce a temporal adapter into the image encoder to capture image correlations and a confidence-driven memory mechanism to store high-certainty features for later retrieval. This memory-based strategy counters the pervasive noise in large-scale medical datasets and mitigates catastrophic forgetting when encountering new tasks or modalities. To train and evaluate SAMed-2, we curate MedBank-100k, a comprehensive dataset spanning seven imaging modalities and 21 medical segmentation tasks. Our experiments on both internal benchmarks and 10 external datasets demonstrate superior performance over state-of-the-art baselines in multi-task scenarios. The code is available at: https://github.com/ZhilingYan/Medical-SAM-Bench.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent "segment anything" efforts show promise by learning from large-scaledata, but adapting such models directly to medical images remains challengingdue to the complexity of medical data, noisy annotations, and continuallearning requirements across diverse modalities and anatomical structures. Inthis work, we propose SAMed-2, a new foundation model for medical imagesegmentation built upon the SAM-2 architecture. Specifically, we introduce atemporal adapter into the image encoder to capture image correlations and aconfidence-driven memory mechanism to store high-certainty features for laterretrieval. This memory-based strategy counters the pervasive noise inlarge-scale medical datasets and mitigates catastrophic forgetting whenencountering new tasks or modalities. To train and evaluate SAMed-2, we curateMedBank-100k, a comprehensive dataset spanning seven imaging modalities and 21medical segmentation tasks. Our experiments on both internal benchmarks and 10external datasets demonstrate superior performance over state-of-the-artbaselines in multi-task scenarios. The code is available at:https://github.com/ZhilingYan/Medical-SAM-Bench.</description>
      <author>example@mail.com (Zhiling Yan, Sifan Song, Dingjie Song, Yiwei Li, Rong Zhou, Weixiang Sun, Zhennong Chen, Sekeun Kim, Hui Ren, Tianming Liu, Quanzheng Li, Xiang Li, Lifang He, Lichao Sun)</author>
      <guid isPermaLink="false">2507.03698v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>PiCME: Pipeline for Contrastive Modality Evaluation and Encoding in the MIMIC Dataset</title>
      <link>http://arxiv.org/abs/2507.03165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;摘要介绍了一种名为PiCME的多模态深度学习方法，用于提高临床预测的准确性，并通过对比学习技术整合多种患者数据，包括文本、图像、时间序列和结构化人口统计数据。&lt;h4&gt;背景&lt;/h4&gt;多模态深度学习有潜力通过整合多样化的患者数据（如文本、图像、时间序列和人口统计数据）来改善临床预测。对比学习能够促进这种整合，因为它产生了一个可以跨任务复用的统一表示，从而减少了需要单独模型或编码器的需求。&lt;h4&gt;目的&lt;/h4&gt;提出PiCME，用于系统地评估MIMIC数据库中的五种临床数据类型，并评估对比学习模型在住院死亡率及表型预测上的效用。&lt;h4&gt;方法&lt;/h4&gt;在所有26种两到五种模态的组合上预训练对比模型，并在住院死亡率和表型预测任务上进行评估。为了解决随着模态增多而出现的性能瓶颈，引入了模态门控LSTM，根据对比学习得出的重要性对每个模态进行加权。&lt;h4&gt;主要发现&lt;/h4&gt;对比模型在三个模态设置中与监督基线保持竞争力，但在超过三个模态时性能下降。模态门控LSTM减轻了这种下降，在五模态设置中将AUROC从73.19%提高到76.93%，AUPRC从51.27%提高到62.26%。此外，对比学习得到的模态重要性分数与归因分数进行了比较，并评估了跨人口子群体的泛化能力，突出了可解释性和公平性的优势。&lt;h4&gt;结论&lt;/h4&gt;PiCME首次在MIMIC的所有模态组合中扩展了对比学习，为模态选择、训练策略和公平的临床预测提供了指导。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了多模态深度学习在临床预测中的应用，提出了一种名为PiCME的方法，通过对比学习技术整合患者数据，以提高预测的准确性。在MIMIC数据库中，对五种临床数据类型进行系统评估，发现对比学习在三个模态设置中表现良好，但随着模态增多，性能有所下降。引入模态门控LSTM后，性能得到提升，并突出了对比学习在可解释性和公平性方面的优势。PiCME为模态选择和训练策略提供了指导，有助于实现公平的临床预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal deep learning holds promise for improving clinical prediction byintegrating diverse patient data, including text, imaging, time-series, andstructured demographics. Contrastive learning facilitates this integration byproducing a unified representation that can be reused across tasks, reducingthe need for separate models or encoders. Although contrastive learning hasseen success in vision-language domains, its use in clinical settings remainslargely limited to image and text pairs. We propose the Pipeline forContrastive Modality Evaluation and Encoding (PiCME), which systematicallyassesses five clinical data types from MIMIC: discharge summaries, radiologyreports, chest X-rays, demographics, and time-series. We pre-train contrastivemodels on all 26 combinations of two to five modalities and evaluate theirutility on in-hospital mortality and phenotype prediction. To addressperformance plateaus with more modalities, we introduce a Modality-Gated LSTMthat weights each modality according to its contrastively learned importance.Our results show that contrastive models remain competitive with supervisedbaselines, particularly in three-modality settings. Performance declines beyondthree modalities, which supervised models fail to recover. The Modality-GatedLSTM mitigates this drop, improving AUROC from 73.19% to 76.93% and AUPRC from51.27% to 62.26% in the five-modality setting. We also compare contrastivelylearned modality importance scores with attribution scores and evaluategeneralization across demographic subgroups, highlighting strengths ininterpretability and fairness. PiCME is the first to scale contrastive learningacross all modality combinations in MIMIC, offering guidance for modalityselection, training strategies, and equitable clinical prediction.</description>
      <author>example@mail.com (Michal Golovanevsky, Pranav Mahableshwarkar, Carsten Eickhoff, Ritambhara Singh)</author>
      <guid isPermaLink="false">2507.03165v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Accuracy: Metrics that Uncover What Makes a `Good' Visual Descriptor</title>
      <link>http://arxiv.org/abs/2507.03542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  VisCon @ CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于文本的视觉描述符在视觉概念发现和图像分类中的应用，并分析了描述符质量的影响因素。&lt;h4&gt;背景&lt;/h4&gt;基于文本的视觉描述符在视觉-语言模型（VLMs）中广泛应用，但其有效性受多种因素影响，如语义清晰度、在预训练数据中的存在性以及作为有意义表示空间的能力。&lt;h4&gt;目的&lt;/h4&gt;系统地分析描述符质量，从两个关键维度进行评估：代表能力和与VLM预训练数据的关系。&lt;h4&gt;方法&lt;/h4&gt;评估了从零样本LLM生成的提示到迭代优化描述符的一系列描述符生成方法，并引入了全局对齐和CLIP相似度两个基于对齐的度量指标。&lt;h4&gt;主要发现&lt;/h4&gt;这些度量指标有助于揭示不同描述符生成策略如何与基础模型特性相互作用，为超越准确度评估研究描述符有效性的方法提供了洞见。&lt;h4&gt;结论&lt;/h4&gt;描述符的有效性取决于其代表能力和与预训练数据的关系，通过引入新的度量指标可以更全面地评估描述符的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-based visual descriptors-ranging from simple class names to moredescriptive phrases-are widely used in visual concept discovery and imageclassification with vision-language models (VLMs). Their effectiveness,however, depends on a complex interplay of factors, including semantic clarity,presence in the VLM's pre-training data, and how well the descriptors serve asa meaningful representation space. In this work, we systematically analyzedescriptor quality along two key dimensions: (1) representational capacity, and(2) relationship with VLM pre-training data. We evaluate a spectrum ofdescriptor generation methods, from zero-shot LLM-generated prompts toiteratively refined descriptors. Motivated by ideas from representationalignment and language understanding, we introduce two alignment-basedmetrics-Global Alignment and CLIP Similarity-that move beyond accuracy. Thesemetrics allow us to shed light on how different descriptor generationstrategies interact with foundation model properties, offering insights intoways of studying descriptor effectiveness beyond accuracy evaluations.</description>
      <author>example@mail.com (Ethan Lin, Linxi Zhao, Atharva Sehgal, Jennifer J. Sun)</author>
      <guid isPermaLink="false">2507.03542v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach</title>
      <link>http://arxiv.org/abs/2507.02826v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比双路径网络（DCDP-HAR）的新框架，用于解决多模态人体活动识别（HAR）系统中的跨模态特征对齐和模态贡献不平衡问题。&lt;h4&gt;背景&lt;/h4&gt;人体活动识别技术是智能系统感知和交互环境的核心技术，但多模态HAR系统仍面临跨模态特征对齐和模态贡献不平衡等关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DCDP-HAR框架以解决多模态HAR系统中的挑战，提高识别准确性和系统性能。&lt;h4&gt;方法&lt;/h4&gt;DCDP-HAR框架包括三个关键组件：1）双路径特征提取架构，使用ResNet和DenseNet分支协同处理多模态传感器数据；2）多阶段对比学习机制，实现从局部感知到语义抽象的渐进对齐；3）基于置信度的梯度调制策略，动态监控和调整每个模态分支的学习强度，缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过消融实验验证了每个组件的有效性，并在四个公开基准数据集上进行了广泛的比较实验。&lt;h4&gt;结论&lt;/h4&gt;DCDP-HAR框架能够有效解决多模态HAR系统中的挑战，提高识别准确性和系统性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensor-based Human Activity Recognition (HAR) is a core technology thatenables intelligent systems to perceive and interact with their environment.However, multimodal HAR systems still encounter key challenges, such asdifficulties in cross-modal feature alignment and imbalanced modalitycontributions. To address these issues, we propose a novel framework called theDynamic Contrastive Dual-Path Network (DCDP-HAR). The framework comprises threekey components. First, a dual-path feature extraction architecture is employed,where ResNet and DenseNet branches collaboratively process multimodal sensordata. Second, a multi-stage contrastive learning mechanism is introduced toachieve progressive alignment from local perception to semantic abstraction.Third, we present a confidence-driven gradient modulation strategy thatdynamically monitors and adjusts the learning intensity of each modality branchduring backpropagation, effectively alleviating modality competition. Inaddition, a momentum-based gradient accumulation strategy is adopted to enhancetraining stability. We conduct ablation studies to validate the effectivenessof each component and perform extensive comparative experiments on four publicbenchmark datasets.</description>
      <author>example@mail.com (Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li)</author>
      <guid isPermaLink="false">2507.02826v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Swarms Durability to Threats via Graph Signal Processing and GNN-based Generative Modeling</title>
      <link>http://arxiv.org/abs/2507.03039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了外部扰动（如环境变化、捕食者或通信中断）对群体稳定性影响的问题，通过图信号处理技术分析扰动，并提出了SwaGen，一种基于图神经网络的生成模型，以优化群体的空间配置。&lt;h4&gt;背景&lt;/h4&gt;群体（如鱼群或无人机编队）在自然和工程系统中普遍存在，以往研究主要关注群体内部的社会互动。&lt;h4&gt;目的&lt;/h4&gt;填补外部扰动对群体稳定性影响的空白，并设计出稳健的人工群体。&lt;h4&gt;方法&lt;/h4&gt;将群体建模为图，应用图信号处理技术分析扰动，并引入SwaGen，一种基于图神经网络的生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;揭示了群体逃避检测的能力和其被检测后对捕食的抵抗能力之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;SwaGen可以揭示新的空间配置，优化权衡，并指导设计稳健的人工群体，加深对自然群体动态的理解。&lt;h4&gt;翻译&lt;/h4&gt;Swarms, such as schools of fish or drone formations, are prevalent in both natural and engineered systems. While previous works have focused on the social interactions within swarms, the role of external perturbations--such as environmental changes, predators, or communication breakdowns--in affecting swarm stability is not fully understood. Our study addresses this gap by modeling swarms as graphs and applying graph signal processing techniques to analyze perturbations as signals on these graphs. By examining predation, we uncover a 'detectability-durability trade-off', demonstrating a tension between a swarm's ability to evade detection and its resilience to predation, once detected. We provide theoretical and empirical evidence for this trade-off, explicitly tying it to properties of the swarm's spatial configuration. Toward task-specific optimized swarms, we introduce SwaGen, a graph neural network-based generative model. We apply SwaGen to resilient swarm generation by defining a task-specific loss function, optimizing the contradicting trade-off terms simultaneously. With this, SwaGen reveals novel spatial configurations, optimizing the trade-off at both ends. Applying the model can guide the design of robust artificial swarms and deepen our understanding of natural swarm dynamics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Swarms, such as schools of fish or drone formations, are prevalent in bothnatural and engineered systems. While previous works have focused on the socialinteractions within swarms, the role of external perturbations--such asenvironmental changes, predators, or communication breakdowns--in affectingswarm stability is not fully understood. Our study addresses this gap bymodeling swarms as graphs and applying graph signal processing techniques toanalyze perturbations as signals on these graphs. By examining predation, weuncover a "detectability-durability trade-off", demonstrating a tension betweena swarm's ability to evade detection and its resilience to predation, oncedetected. We provide theoretical and empirical evidence for this trade-off,explicitly tying it to properties of the swarm's spatial configuration. Towardtask-specific optimized swarms, we introduce SwaGen, a graph neuralnetwork-based generative model. We apply SwaGen to resilient swarm generationby defining a task-specific loss function, optimizing the contradictingtrade-off terms simultaneously.With this, SwaGen reveals novel spatialconfigurations, optimizing the trade-off at both ends. Applying the model canguide the design of robust artificial swarms and deepen our understanding ofnatural swarm dynamics.</description>
      <author>example@mail.com (Jonathan Karin, Zoe Piran, Mor Nitzan)</author>
      <guid isPermaLink="false">2507.03039v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Foundation versus Domain-specific Models: Performance Comparison, Fusion, and Explainability in Face Recognition</title>
      <link>http://arxiv.org/abs/2507.03541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过实验比较了通用基础模型（如CLIP、BLIP、LLaVa、DINO）与特定领域的人脸识别模型（如AdaFace或ArcFace）在人脸识别任务上的表现。&lt;h4&gt;背景&lt;/h4&gt;在人脸识别任务中，通用基础模型与特定领域模型之间的性能差异是一个研究热点。&lt;h4&gt;目的&lt;/h4&gt;研究通用基础模型与特定领域人脸识别模型在人脸识别任务上的性能差异。&lt;h4&gt;方法&lt;/h4&gt;通过一系列实验，使用多个基础模型和基准数据集，比较了两种模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;（a）在所有考虑的数据集中，特定领域模型优于零样本通用基础模型；（b）零样本通用基础模型在处理过度分割的人脸图像时性能优于紧密裁剪的人脸图像，这表明了上下文线索的重要性；（c）将基础模型与特定领域人脸识别模型进行简单的分数级融合可以提高低FMR下的准确性；（d）基础模型（如ChatGPT）可以用于赋予人脸识别流程可解释性；（e）在某些情况下，基础模型甚至能够解决AdaFace做出的低置信度决策。&lt;h4&gt;结论&lt;/h4&gt;合理地将特定领域人脸识别模型与通用基础模型结合使用对于提高人脸识别性能至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the following question: How do generic foundationmodels (e.g., CLIP, BLIP, LLaVa, DINO) compare against a domain-specific facerecognition model (viz., AdaFace or ArcFace) on the face recognition task?Through a series of experiments involving several foundation models andbenchmark datasets, we are able to report the following findings: (a) In alldatasets considered, domain-specific models outperformed zero-shot foundationmodels. (b) The performance of zero-shot generic foundation models improves onover-segmented face images than tightly cropped faces thereby suggesting theimportance of contextual clues. For example, at a False Match Rate (FMR) of0.01%, the True Match Rate (TMR) of OpenCLIP improved from 64.97% to 81.73% onthe LFW dataset as the face crop increased from 112x112 to 250x250 while theTMR of domain-specific AdaFace dropped from 99.09% to 77.31%. (c) A simplescore-level fusion of a foundation model with a domain-specific FR modelimproved the accuracy at low FMRs. For example, the TMR of AdaFace when fusedwith BLIP improved from 72.64% to 83.31% at an FMR of 0.0001% on the IJB-Bdataset and from 73.17% to 85.81% on the IJB-C dataset. (d) Foundation models,such as ChatGPT, can be used to impart explainability to the FR pipeline (e.g.,``Despite minor lighting and head tilt differences, the two left-profile imagesshow high consistency in forehead slope, nose shape, chin contour...''). Insome instances, foundation models are even able to resolve low-confidencedecisions made by AdaFace (e.g., ``Although AdaFace assigns a low similarityscore of 0.21, both images exhibit visual similarity...and the pair is likelyof the same person''), thereby reiterating the importance of combiningdomain-specific FR models with generic foundation models in a judicious manner.</description>
      <author>example@mail.com (Redwan Sony, Parisa Farmanifard, Arun Ross, Anil K. Jain)</author>
      <guid isPermaLink="false">2507.03541v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>When Does Pruning Benefit Vision Representations?</title>
      <link>http://arxiv.org/abs/2507.01722v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了剪枝对视觉模型的影响，分析了剪枝在可解释性、无监督对象发现和与人类感知对齐三个方面的作用。&lt;h4&gt;背景&lt;/h4&gt;剪枝被广泛应用于降低深度学习模型的复杂度，但其对可解释性和表示学习的影响尚不明确。&lt;h4&gt;目的&lt;/h4&gt;探讨剪枝如何影响视觉模型的可解释性、无监督对象发现和与人类感知的对齐。&lt;h4&gt;方法&lt;/h4&gt;分析了不同视觉网络架构，考察不同稀疏度水平对特征归因可解释性的影响；探索剪枝是否促进了更简洁、结构化的表示，通过丢弃冗余信息同时保留关键特征来提高无监督对象发现；评估剪枝是否增强了模型表示与人类感知之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现存在“甜点区域”，在这些区域中，稀疏模型展现出更高的可解释性、下游泛化能力和与人类感知的对齐。然而，这些区域高度依赖于网络架构和可训练参数的数量。&lt;h4&gt;结论&lt;/h4&gt;三个维度之间存在复杂相互作用，强调了研究何时以及如何通过剪枝改善视觉表示的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：剪枝被广泛用于降低深度学习模型的复杂性，但其对可解释性和表示学习的影响仍不明确。本文研究了剪枝如何影响视觉模型在三个关键维度上的表现：（一）可解释性，（二）无监督对象发现，（三）与人类感知的对齐。首先，分析了不同的视觉网络架构，以考察不同稀疏度水平如何影响特征归因的可解释性方法。此外，探讨了剪枝是否促进了更简洁和结构化的表示，通过丢弃冗余信息同时保留关键特征，从而可能提高无监督对象发现。最后，评估了剪枝是否增强了模型表示与人类感知之间的对齐，研究是否更稀疏的模型关注与人类相似的可区分特征。研究发现存在“甜点区域”，在这些区域中，稀疏模型展现出更高的可解释性、下游泛化能力和与人类感知的对齐。然而，这些区域高度依赖于网络架构及其可训练参数的数量。结果表明，这三个维度之间存在复杂相互作用，强调了研究何时以及如何通过剪枝改善视觉表示的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pruning is widely used to reduce the complexity of deep learning models, butits effects on interpretability and representation learning remain poorlyunderstood. This paper investigates how pruning influences vision models acrossthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,and (iii) alignment with human perception. We first analyze different visionnetwork architectures to examine how varying sparsity levels affect featureattribution interpretability methods. Additionally, we explore whether pruningpromotes more succinct and structured representations, potentially improvingunsupervised object discovery by discarding redundant information whilepreserving essential features. Finally, we assess whether pruning enhances thealignment between model representations and human perception, investigatingwhether sparser models focus on more discriminative features similarly tohumans. Our findings also reveal the presence of sweet spots, where sparsemodels exhibit higher interpretability, downstream generalization and humanalignment. However, these spots highly depend on the network architectures andtheir size in terms of trainable parameters. Our results suggest a complexinterplay between these three dimensions, highlighting the importance ofinvestigating when and how pruning benefits vision representations.</description>
      <author>example@mail.com (Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto)</author>
      <guid isPermaLink="false">2507.01722v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2507.01801v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种自适应动量与解耦对比学习框架（AMD），用于准确预测交通代理的未来轨迹，特别针对自然数据集中尾部数据的复杂和危险场景。&lt;h4&gt;背景&lt;/h4&gt;交通代理未来轨迹的准确预测对自动驾驶至关重要，但由于轨迹分布的不平衡，自然数据集中的尾部数据通常代表更复杂和危险的情况。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够识别稀有和复杂轨迹的模型，同时提高在尾部数据上的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出AMD框架，该框架结合了无监督和监督的对比学习策略，并使用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块。此外，设计了四种轨迹随机增强方法，并引入在线迭代聚类策略，以动态更新伪标签并适应尾部数据的分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;AMD在长尾轨迹预测中取得了最佳性能，并显示了出色的整体预测准确性。&lt;h4&gt;结论&lt;/h4&gt;AMD不仅优化了长尾轨迹预测的性能，还显著提高了整体预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测交通代理的未来轨迹对自动驾驶至关重要。然而，由于轨迹分布的不平衡，自然数据集中的尾部数据通常代表更复杂和危险的场景。现有研究通常仅依赖于基础模型的预测误差，而没有考虑长尾轨迹模式的多样性和不确定性。我们提出了一种自适应动量与解耦对比学习框架（AMD），该框架集成了无监督和监督对比学习策略。通过利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，我们的框架增强了模型识别稀有和复杂轨迹的能力。此外，我们设计了四种类型的轨迹随机增强方法，并引入了一种在线迭代聚类策略，使模型能够动态更新伪标签，并更好地适应尾部数据的分布变化。我们提出了三种不同的标准来定义长尾轨迹，并在nuScenes和ETH$/$UCY数据集上进行了广泛的比较实验。结果表明，AMD不仅在长尾轨迹预测中实现了最佳性能，而且还展示了卓越的整体预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting the future trajectories of traffic agents is essentialin autonomous driving. However, due to the inherent imbalance in trajectorydistributions, tail data in natural datasets often represents more complex andhazardous scenarios. Existing studies typically rely solely on a base model'sprediction error, without considering the diversity and uncertainty oflong-tail trajectory patterns. We propose an adaptive momentum and decoupledcontrastive learning framework (AMD), which integrates unsupervised andsupervised contrastive learning strategies. By leveraging an improved momentumcontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,our framework enhances the model's ability to recognize rare and complextrajectories. Additionally, we design four types of trajectory randomaugmentation methods and introduce an online iterative clustering strategy,allowing the model to dynamically update pseudo-labels and better adapt to thedistributional shifts in long-tail data. We propose three different criteria todefine long-tail trajectories and conduct extensive comparative experiments onthe nuScenes and ETH$/$UCY datasets. The results show that AMD not onlyachieves optimal performance in long-tail trajectory prediction but alsodemonstrates outstanding overall prediction accuracy.</description>
      <author>example@mail.com (Bin Rao, Haicheng Liao, Yanchen Guan, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2507.01801v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>PhenoBench: A Comprehensive Benchmark for Cell Phenotyping</title>
      <link>http://arxiv.org/abs/2507.03532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for presentation at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PhenoBench的细胞表型基准，用于在H&amp;E染色的组织病理学图像上进行细胞表型分析，同时提供新的数据集PhenoCell和预训练代码，用于评估现有模型的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管数字病理学中出现了许多基础模型（FM），但它们在细胞表型分析方面的表现尚未统一评估。&lt;h4&gt;目的&lt;/h4&gt;提出PhenoBench，旨在为细胞表型分析提供一个全面的基准，并评估现有模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提供了PhenoCell数据集，包含14种通过多重成像识别的细胞性状，并提供了用于微调和基准测试的代码。&lt;h4&gt;主要发现&lt;/h4&gt;对现有模型进行了广泛基准测试，发现它们在技术领域与医学领域的泛化行为存在差异，且在PhenoCell上的表现远低于在Lizard和PanNuke等基准上的表现。&lt;h4&gt;结论&lt;/h4&gt;PhenoCell作为基准测试的理想数据集，为未来FM和监督模型的基准测试提供了重要的资源。&lt;h4&gt;翻译&lt;/h4&gt;Digital pathology has seen the advent of a wealth of foundational models(FM), yet to date their performance on cell phenotyping has not beenbenchmarked in a unified manner. We therefore propose PhenoBench: Acomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&amp;E)stained histopathology images. We provide both PhenoCell, a new H&amp;E datasetfeaturing 14 granular cell types identified by using multiplexed imaging, andready-to-use fine-tuning and benchmarking code that allows the systematicevaluation of multiple prominent pathology FMs in terms of dense cell phenotypepredictions in different generalization scenarios. We perform extensivebenchmarking of existing FMs, providing insights into their generalizationbehavior under technical vs. medical domain shifts. Furthermore, while FMsachieve macro F1 scores &gt; 0.70 on previously established benchmarks such asLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. Thisindicates a much more challenging task not captured by previous benchmarks,establishing PhenoCell as a prime asset for future benchmarking of FMs andsupervised models alike. Code and data are available on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Digital pathology has seen the advent of a wealth of foundational models(FM), yet to date their performance on cell phenotyping has not beenbenchmarked in a unified manner. We therefore propose PhenoBench: Acomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&amp;E)stained histopathology images. We provide both PhenoCell, a new H&amp;E datasetfeaturing 14 granular cell types identified by using multiplexed imaging, andready-to-use fine-tuning and benchmarking code that allows the systematicevaluation of multiple prominent pathology FMs in terms of dense cell phenotypepredictions in different generalization scenarios. We perform extensivebenchmarking of existing FMs, providing insights into their generalizationbehavior under technical vs. medical domain shifts. Furthermore, while FMsachieve macro F1 scores &gt; 0.70 on previously established benchmarks such asLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. Thisindicates a much more challenging task not captured by previous benchmarks,establishing PhenoCell as a prime asset for future benchmarking of FMs andsupervised models alike. Code and data are available on GitHub.</description>
      <author>example@mail.com (Jerome Luescher, Nora Koreuber, Jannik Franzen, Fabian H. Reith, Claudia Winklmayr, Christian M. Schuerch, Dagmar Kainmueller, Josef Lorenz Rumberger)</author>
      <guid isPermaLink="false">2507.03532v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>OMAR-RQ: Open Music Audio Representation Model Trained with Multi-Feature Masked Token Prediction</title>
      <link>http://arxiv.org/abs/2507.03482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为OMAR-RQ的开源音乐音频理解模型，该模型通过大规模数据集进行自监督训练，并在音乐标签、音高估计、和弦识别、节奏跟踪、分割和难度估计等任务中取得了领先性能。&lt;h4&gt;背景&lt;/h4&gt;开发开源基础模型对于推进音乐音频理解研究以及确保获取强大、多用途的音乐信息检索表示至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出OMAR-RQ模型，以提升音乐信息检索的准确性和可用性。&lt;h4&gt;方法&lt;/h4&gt;使用超过330,000小时的音乐音频数据集，通过掩码标记分类方法进行自监督训练，并实验不同的输入特征和量化选项。&lt;h4&gt;主要发现&lt;/h4&gt;OMAR-RQ在音乐标签、音高估计、和弦识别、节奏跟踪、分割和难度估计等任务中取得了开放自监督模型中的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;开源了OMAR-RQ的训练和评估流程以及模型权重，并提供了访问链接。&lt;h4&gt;翻译&lt;/h4&gt;Developing open-source foundation models is essential for advancing research in music audio understanding and ensuring access to powerful, multipurpose representations for music information retrieval. We present OMAR-RQ, a model trained with self-supervision via masked token classification methodologies using a large-scale dataset with over 330,000 hours of music audio. We experiment with different input features and quantization options, and achieve state-of-the-art performance in music tagging, pitch estimation, chord recognition, beat tracking, segmentation, and difficulty estimation among open self-supervised models. We open-source our training and evaluation pipelines and model weights, available at https://github.com/mtg/omar-rq.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing open-source foundation models is essential for advancing researchin music audio understanding and ensuring access to powerful, multipurposerepresentations for music information retrieval. We present OMAR-RQ, a modeltrained with self-supervision via masked token classification methodologiesusing a large-scale dataset with over 330,000 hours of music audio. Weexperiment with different input features and quantization options, and achievestate-of-the-art performance in music tagging, pitch estimation, chordrecognition, beat tracking, segmentation, and difficulty estimation among openself-supervised models. We open-source our training and evaluation pipelinesand model weights, available at https://github.com/mtg/omar-rq.</description>
      <author>example@mail.com (Pablo Alonso-Jiménez, Pedro Ramoneda, R. Oguz Araz, Andrea Poltronieri, Dmitry Bogdanov)</author>
      <guid isPermaLink="false">2507.03482v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>TrajFlow: Multi-modal Motion Prediction via Flow Matching</title>
      <link>http://arxiv.org/abs/2506.08541v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TrajFlow是一种基于流匹配的运动预测框架，用于解决现有生成轨迹预测方法的可扩展性和效率问题。&lt;h4&gt;背景&lt;/h4&gt;高效准确的运动预测对于确保自动驾驶安全及做出明智决策至关重要，尤其是在需要多模式预测的动态现实世界条件下。&lt;h4&gt;目的&lt;/h4&gt;提出TrajFlow框架，以解决现有生成轨迹预测方法的可扩展性和效率挑战。&lt;h4&gt;方法&lt;/h4&gt;TrajFlow通过单次预测多个可能的未来轨迹来减少计算开销，同时保持预测的一致性。此外，还提出了一种基于Plackett-Luce分布的排名损失，用于提高预测轨迹的不确定性估计。还设计了自我条件化训练技术，通过重复使用模型自己的预测来构建噪声输入，从而提高泛化能力和加速推理。&lt;h4&gt;主要发现&lt;/h4&gt;在Waymo Open Motion Dataset（WOMD）上的大量实验表明，TrajFlow在各种关键指标上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;TrajFlow在安全关键性的自动驾驶应用中非常有效。&lt;h4&gt;翻译&lt;/h4&gt;Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts. We introduce TrajFlow, a novel flow matching-based motion prediction framework that addresses the scalability and efficiency challenges of existing generative trajectory prediction methods. Unlike conventional generative approaches that employ i.i.d. sampling and require multiple inference passes to capture diverse outcomes, TrajFlow predicts multiple plausible future trajectories in a single pass, significantly reducing computational overhead while maintaining coherence across predictions. Moreover, we propose a ranking loss based on the Plackett-Luce distribution to improve uncertainty estimation of predicted trajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during a second forward pass, thereby improving generalization and accelerating inference. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across various key metrics, underscoring its effectiveness for safety-critical autonomous driving applications. The code and other details are available on the project website https://traj-flow.github.io/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient and accurate motion prediction is crucial for ensuring safety andinformed decision-making in autonomous driving, particularly under dynamicreal-world conditions that necessitate multi-modal forecasts. We introduceTrajFlow, a novel flow matching-based motion prediction framework thataddresses the scalability and efficiency challenges of existing generativetrajectory prediction methods. Unlike conventional generative approaches thatemploy i.i.d. sampling and require multiple inference passes to capture diverseoutcomes, TrajFlow predicts multiple plausible future trajectories in a singlepass, significantly reducing computational overhead while maintaining coherenceacross predictions. Moreover, we propose a ranking loss based on thePlackett-Luce distribution to improve uncertainty estimation of predictedtrajectories. Additionally, we design a self-conditioning training techniquethat reuses the model's own predictions to construct noisy inputs during asecond forward pass, thereby improving generalization and acceleratinginference. Extensive experiments on the large-scale Waymo Open Motion Dataset(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance acrossvarious key metrics, underscoring its effectiveness for safety-criticalautonomous driving applications. The code and other details are available onthe project website https://traj-flow.github.io/.</description>
      <author>example@mail.com (Qi Yan, Brian Zhang, Yutong Zhang, Daniel Yang, Joshua White, Di Chen, Jiachao Liu, Langechuan Liu, Binnan Zhuang, Shaoshuai Shi, Renjie Liao)</author>
      <guid isPermaLink="false">2506.08541v2</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Adopting a human developmental visual diet yields robust, shape-based AI vision</title>
      <link>http://arxiv.org/abs/2507.03168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法来缩小人工智能（AI）视觉与人类视觉之间的差距，该方法通过模拟人类视觉从婴儿期到成年期的发育过程，提高了AI视觉系统的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;尽管人工智能系统在规模上取得了显著进步，但人工智能视觉与人类视觉之间的不匹配仍然存在。&lt;h4&gt;目的&lt;/h4&gt;为了解决人工智能视觉与人类视觉之间的不匹配问题。&lt;h4&gt;方法&lt;/h4&gt;研究者通过综合心理物理学和神经生理学的研究成果，为AI视觉设计了一种新的发育视觉饮食（DVD），并通过引导AI系统通过这个人类启发的课程来提高其视觉能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用DVD引导AI系统，研究者发现这些模型在所有鲁棒视觉测试方面都与人类行为紧密一致，包括对形状信息的依赖性、抽象形状识别能力、对图像损坏的鲁棒性以及对对抗攻击的抵抗能力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引导模型的学习方式，而不是学习量，实现了鲁棒的人工智能视觉，为更安全、更类似人类的人工视觉系统提供了一种资源高效的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管多年来对人工智能（AI）系统进行了研究，并且人工智能系统的规模发生了巨大扩展，但人工智能视觉与人类视觉之间的显著不匹配仍然存在。与人类不同，人工智能严重依赖于纹理特征而不是形状信息，对图像扭曲缺乏鲁棒性，高度易受对抗攻击，并且难以在复杂背景中识别简单的抽象形状。为了缩小这一差距，我们在这里介绍了一种源于先前未充分探索方向的解决方案：而不是扩大规模，我们从人类视觉如何从婴儿期发展到成年期的过程中获得灵感。我们通过将数十年的心理物理学和神经生理学研究综合到一个新的发育视觉饮食（DVD）中，量化了视觉成熟。我们表明，通过引导AI系统通过这个人类启发的课程，可以产生在所有鲁棒视觉测试标志上都与人类行为紧密一致的模式，这是迄今为止对形状信息最强依赖的报道，抽象形状识别能力超越了当前的技术水平，对图像损坏的鲁棒性更高，对对抗攻击的抵抗能力更强。通过在数据量多出几个数量级的参数化AI基础模型上表现出色，我们提供了证据，表明通过引导模型的学习方式，而不是学习量，可以实现鲁棒的人工智能视觉，为更安全、更类似人类的人工视觉系统提供了一条资源高效的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite years of research and the dramatic scaling of artificial intelligence(AI) systems, a striking misalignment between artificial and human visionpersists. Contrary to humans, AI heavily relies on texture-features rather thanshape information, lacks robustness to image distortions, remains highlyvulnerable to adversarial attacks, and struggles to recognise simple abstractshapes within complex backgrounds. To close this gap, we here introduce asolution that arises from a previously underexplored direction: rather thanscaling up, we take inspiration from how human vision develops from earlyinfancy into adulthood. We quantified the visual maturation by synthesisingdecades of psychophysical and neurophysiological research into a noveldevelopmental visual diet (DVD) for AI vision. We show that guiding AI systemsthrough this human-inspired curriculum produces models that closely align withhuman behaviour on every hallmark of robust vision tested yielding thestrongest reported reliance on shape information to date, abstract shaperecognition beyond the state of the art, higher robustness to imagecorruptions, and stronger resilience to adversarial attacks. By outperforminghigh parameter AI foundation models trained on orders of magnitude more data,we provide evidence that robust AI vision can be achieved by guiding the wayhow a model learns, not merely how much it learns, offering aresource-efficient route toward safer and more human-like artificial visualsystems.</description>
      <author>example@mail.com (Zejin Lu, Sushrut Thorat, Radoslaw M Cichy, Tim C Kietzmann)</author>
      <guid isPermaLink="false">2507.03168v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Manipulation of Reasoning Models using Internal Representations</title>
      <link>http://arxiv.org/abs/2507.03167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the ICML 2025 Workshop on Reliable and Responsible  Foundation Models (R2FM). 20 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了推理模型在生成思维链（CoT）标记之前如何影响其遭受越狱攻击的脆弱性。&lt;h4&gt;背景&lt;/h4&gt;传统的语言模型在提示-响应边界做出拒绝决策，而研究发现DeepSeek-R1-Distill-Llama-8B在CoT生成过程中做出这些决策。&lt;h4&gt;目的&lt;/h4&gt;研究旨在识别推理模型中可能被用于对抗性操纵的潜在弱点。&lt;h4&gt;方法&lt;/h4&gt;研究者识别了CoT标记生成过程中的一个线性激活空间方向，该方向可以预测模型是否会拒绝或遵守，并将其称为“谨慎”方向。他们通过消除该方向从模型激活中，增加了有害的遵守行为，从而实现了对模型的越狱。&lt;h4&gt;主要发现&lt;/h4&gt;1. CoT生成过程中的“谨慎”方向可以预测模型的决策。2. 消除该方向会增加有害的遵守行为。3. 仅干预CoT标记激活就足以控制最终输出。4. 将该方向纳入基于提示的攻击中可以提高成功率。&lt;h4&gt;结论&lt;/h4&gt;思维链本身是推理模型中对抗性操纵的一个有希望的新的目标。&lt;h4&gt;翻译&lt;/h4&gt;摘要：推理模型在生成最终输出之前会生成思维链（CoT）标记，但这种方式如何影响它们遭受越狱攻击的脆弱性尚不清楚。虽然传统的语言模型在提示-响应边界做出拒绝决策，但我们发现DeepSeek-R1-Distill-Llama-8B在其CoT生成过程中做出这些决策。我们在CoT标记生成过程中识别了一个激活空间中的线性方向，该方向可以预测模型是否会拒绝或遵守——称为“谨慎”方向，因为它对应于生成的文本中的谨慎推理模式。从模型激活中消除这个方向会增加有害的遵守行为，从而有效地越狱模型。此外，我们还表明，仅干预CoT标记激活就足以控制最终输出，并且将这个方向纳入基于提示的攻击中可以提高成功率。我们的发现表明，思维链本身是推理模型中对抗性操纵的一个有希望的新的目标。代码可在https://github.com/ky295/reasoning-manipulation上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning models generate chain-of-thought (CoT) tokens before their finaloutput, but how this affects their vulnerability to jailbreak attacks remainsunclear. While traditional language models make refusal decisions at theprompt-response boundary, we find evidence that DeepSeek-R1-Distill-Llama-8Bmakes these decisions within its CoT generation. We identify a linear directionin activation space during CoT token generation that predicts whether the modelwill refuse or comply -- termed the "caution" direction because it correspondsto cautious reasoning patterns in the generated text. Ablating this directionfrom model activations increases harmful compliance, effectively jailbreakingthe model. We additionally show that intervening only on CoT token activationssuffices to control final outputs, and that incorporating this direction intoprompt-based attacks improves success rates. Our findings suggest that thechain-of-thought itself is a promising new target for adversarial manipulationin reasoning models.  Code available at https://github.com/ky295/reasoning-manipulation</description>
      <author>example@mail.com (Kureha Yamaguchi, Benjamin Etheridge, Andy Arditi)</author>
      <guid isPermaLink="false">2507.03167v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Iterative Zoom-In: Temporal Interval Exploration for Long Video Understanding</title>
      <link>http://arxiv.org/abs/2507.02946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TemporalSearch（TS），一个针对长视频理解问题而设计的训练免费框架，旨在提升多模态大语言模型（MLLMs）对长视频的理解能力。&lt;h4&gt;背景&lt;/h4&gt;MLLMs在视频理解任务中表现出色，但在处理长视频时存在效率低下的问题，主要因为它们对时间间隔的感知效率不高，且通常依赖密集、均匀的时间线采样，导致内存消耗高，可能遗漏关键信息。&lt;h4&gt;目的&lt;/h4&gt;提高MLLMs对长视频的理解能力，减少信息遗漏。&lt;h4&gt;方法&lt;/h4&gt;TemporalSearch通过两个主要迭代阶段来操作：首先，MLLM提出一个可能包含任务相关信息的时段时间段；然后，从该时间段中采样固定数量的帧，无论其长度如何，将它们输入模型以生成细化的响应和置信度分数。TS通过迭代地将注意力转移到更精细的时间间隔上来细化模型的关注点。此外，收集关键帧级别的描述以促进视频中的跨区间感知。为了提高效率，还引入了TS-BFS，这是一种在树上的最佳优先搜索策略。&lt;h4&gt;主要发现&lt;/h4&gt;模型在不同时间间隔的生成置信度与预测准确性高度相关。TS通过迭代调整注意力，提高了对长视频的理解。&lt;h4&gt;结论&lt;/h4&gt;TemporalSearch和TS-BFS能够有效地提升MLLMs对长视频的理解能力，同时提高了效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大语言模型（MLLMs）在视频理解任务中表现出色。然而，由于对时间间隔的感知效率不高，它们在处理长视频时仍然存在困难。与人类能够动态调整时间焦点以定位查询相关的时刻不同，当前的MLLMs通常依赖于视频时间线上的密集、均匀采样，导致内存消耗高，可能遗漏关键信息。为了解决这一挑战，我们引入了TemporalSearch，一个无需训练的框架，使MLLMs能够迭代地探索时间区域以改进长视频理解。TS基于一个关键观察：模型在不同时间间隔的生成置信度与预测准确性高度相关。TS通过两个主要迭代阶段运行。首先，MLLM提出一个可能包含任务相关信息的时段时间段。然后，从该时间段中采样固定数量的帧，无论其长度如何，将它们输入模型以生成细化的响应和置信度分数。TS通过迭代地将注意力转移到更精细的时间间隔上来细化模型的关注点。此外，收集关键帧级别的描述以促进视频中的跨区间感知。为了进一步提高效率，我们引入了TS-BFS，这是一种在树上的最佳优先搜索策略。每个节点代表一个候选时间段，并通过自我驱动建议和均匀划分两种方法进行扩展。节点根据置信度和自我评估进行评分，并选择最有希望的节点进行继续探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have shown strong performance invideo understanding tasks. However, they continue to struggle with long-formvideos because of an inefficient perception of temporal intervals. Unlikehumans, who can dynamically adjust their temporal focus to locatequery-relevant moments, current MLLMs often rely on dense, uniform samplingacross the video timeline, leading to high memory consumption and a risk ofmissing crucial information. To address this challenge, we introduce TemporalSearch, a training-free framework that enables MLLMs to explore temporalregions for improved long video understanding iteratively. TS is based on a keyobservation: the model's generation confidence across different temporalintervals is highly correlated with prediction accuracy. TS operates throughtwo main iterative stages. First, the MLLM proposes a temporal interval that islikely to contain task-relevant information. Then, it samples a fixed number offrames from the interval, regardless of length, and feeds them into the modelto produce a refined response and confidence score. TS refines the focus of themodel by iteratively shifting attention to more fine-grained temporalintervals, improving its understanding of long videos. Additionally,keyframe-level descriptions are collected to facilitate cross-intervalperception throughout the video. To further improve efficiency, we introduceTS-BFS, a best-first search strategy over a tree. Each node represents acandidate interval and is expanded via two methods: self-driven proposals anduniform partitioning. Nodes are scored based on confidence and self-evaluation,and the most promising one is selected for continued exploration.</description>
      <author>example@mail.com (Chenglin Li, Qianglong Chen, fengtao, Yin Zhang)</author>
      <guid isPermaLink="false">2507.02946v1</guid>
      <pubDate>Tue, 08 Jul 2025 14:50:43 +0800</pubDate>
    </item>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>http://arxiv.org/abs/2503.20883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了关联聚类问题，提出了一种新的方法来找到关联聚类问题的可行解，并实现了快速（1.437+ε）近似算法。&lt;h4&gt;背景&lt;/h4&gt;关联聚类是无监督学习和数据挖掘中的一个基本且广泛研究的问题，其目标是通过最小化跨簇边和缺失的簇内边来构建聚类。&lt;h4&gt;目的&lt;/h4&gt;构建一个聚类，使得跨簇边和缺失的簇内边的数量最小。&lt;h4&gt;方法&lt;/h4&gt;引入了新的方法来找到Cluster LP的可行解，并展示了如何在相同的时间界限内实现舍入，从而得到一个快速的（1.437+ε）近似算法。&lt;h4&gt;主要发现&lt;/h4&gt;找到了一个可行解，其目标值最多是最优解的（1+ε）倍，且在时间复杂度为~O(2^poly(1/ε) n)内完成，其中n是图中顶点的数量。&lt;h4&gt;结论&lt;/h4&gt;该方法连接了关联聚类近似方法的最新进展与对快速算法的关注之间。&lt;h4&gt;翻译&lt;/h4&gt;关联聚类是未监督学习和数据挖掘中的一个基本且被广泛研究的问题。输入是一个图，目标是构建一个聚类，使得跨簇边的数量和缺失的簇内边的数量最小。CCL+24引入了关联聚类的簇线性规划（Cluster LP），他们认为这比之前的线性规划公式更简洁。然而，Cluster LP的大小是指数级的，每个可能的顶点集都有一个变量。尽管如此，CCL+24展示了如何在时间O(n^poly(1/eps))内找到Cluster LP的一个可行解，其目标值最多是相应关联聚类实例最优解的(1+epsilon)倍。此外，他们还展示了如何对Cluster LP的解进行舍入，从而得到关联聚类问题的(1.437+eps)近似算法。本文的主要技术成果是找到Cluster LP的一个可行解的新方法，其目标值最多是最优值的(1+epsilon)，时间复杂度为~O(2^poly(1/eps) n)，其中n是图中顶点的数量。我们还展示了如何在相同的时间界限内实现舍入，从而实现一个快速的(1.437+epsilon)近似算法，这连接了关联聚类近似方法的最新进展与对快速算法的关注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-03-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3717823.3718181&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correlation Clustering is a fundamental and widely-studied problem inunsupervised learning and data mining. The input is a graph and the goal is toconstruct a clustering minimizing the number of inter-cluster edges plus thenumber of missing intra-cluster edges.  CCL+24 introduced the cluster LP for Correlation Clustering, which theyargued captures the problem much more succinctly than previous linearprogramming formulations. However, the Cluster LP has exponential size, with avariable for every possible set of vertices in the input graph. Nevertheless,CCL+24 showed how to find a feasible solution for the Cluster LP in timeO(n^{\text{poly}(1/\eps)}) with objective value at most (1+\epsilon) times thevalue of an optimal solution for the respective Correlation Clusteringinstance. Furthermore, they showed how to round a solution to the Cluster LP,yielding a (1.437+\eps)-approximation algorithm for the Correlation Clusteringproblem.  The main technical result of this paper is a new approach to find a feasiblesolution for the Cluster LP with objective value at most (1+\epsilon) of theoptimum in time \widetilde O(2^{\text{poly}(1/\eps)} n), where n is the numberof vertices in the graph. We also show how to implement the rounding within thesame time bounds, thus achieving a fast (1.437+\epsilon)-approximationalgorithm for the Correlation Clustering problem. This bridges the gap betweenstate-of-the-art methods for approximating Correlation Clustering and therecent focus on fast algorithms.</description>
      <author>example@mail.com (Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang)</author>
      <guid isPermaLink="false">2503.20883v1</guid>
      <pubDate>Mon, 07 Jul 2025 14:07:13 +0800</pubDate>
    </item>
  <item>
      <title>Transfer Learning for Matrix Completion</title>
      <link>http://arxiv.org/abs/2507.02248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在矩阵补全设置下的知识迁移，旨在通过辅助数据提高低秩目标矩阵的估计。提出了一种基于先验信息的迁移学习过程，并对其收敛速度和最小-最大最优性进行了研究。&lt;h4&gt;背景&lt;/h4&gt;在矩阵补全设置下，通过辅助数据增强低秩目标矩阵的估计。&lt;h4&gt;目的&lt;/h4&gt;提高低秩目标矩阵的估计精度。&lt;h4&gt;方法&lt;/h4&gt;提出了基于先验信息的迁移学习过程，并利用了先进的锐度集中不等式来消除收敛率中的对数因子，同时开发了一种检测程序来识别信息源。&lt;h4&gt;主要发现&lt;/h4&gt;当源矩阵与目标矩阵足够接近时，提出的方法优于仅使用单一目标数据的传统方法。对于未知源数据集的相关性，提出的方法能够有效地识别信息源并保证选择的一致性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在矩阵补全设置下的知识迁移中具有有效性，能够提高低秩目标矩阵的估计精度。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在矩阵补全设置下的知识迁移，旨在通过辅助数据增强低秩目标矩阵的估计。我们提出了一种基于先验信息的迁移学习过程，并对其收敛速度和最小-最大最优性进行了研究。分析表明，当源矩阵与目标矩阵足够接近时，我们的方法优于仅使用单一目标数据的传统方法。特别是，我们利用了文献[brailovskaya2024universality]中引入的先进的锐度集中不等式，消除了收敛率中的对数因子，这对于证明最小-最大最优性至关重要。当源数据集的相关性未知时，我们开发了一种有效的检测程序来识别信息源，并建立了其选择一致性。通过模拟和真实数据分析验证了我们的方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we explore the knowledge transfer under the setting of matrixcompletion, which aims to enhance the estimation of a low-rank target matrixwith auxiliary data available. We propose a transfer learning procedure givenprior information on which source datasets are favorable. We study itsconvergence rates and prove its minimax optimality. Our analysis reveals thatwith the source matrices close enough to the target matrix, out methodoutperforms the traditional method using the single target data. In particular,we leverage the advanced sharp concentration inequalities introduced in\cite{brailovskaya2024universality} to eliminate a logarithmic factor in theconvergence rate, which is crucial for proving the minimax optimality. When therelevance of source datasets is unknown, we develop an efficient detectionprocedure to identify informative sources and establish its selectionconsistency. Simulations and real data analysis are conducted to support thevalidity of our methodology.</description>
      <author>example@mail.com (Dali Liu, Haolei Weng)</author>
      <guid isPermaLink="false">2507.02248v1</guid>
      <pubDate>Mon, 07 Jul 2025 14:07:13 +0800</pubDate>
    </item>
    <item>
      <title>Are Fast Methods Stable in Adversarially Robust Transfer Learning?</title>
      <link>http://arxiv.org/abs/2506.22602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了快速梯度符号方法（FGSM）在鲁棒迁移学习中的应用，以提高对抗性微调的计算成本。&lt;h4&gt;背景&lt;/h4&gt;迁移学习常用于降低模型训练的计算成本，特别是在提高对抗鲁棒性方面。然而，高鲁棒性需要额外的对抗训练，这比标准微调要耗时得多。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用FGSM来改进对抗性微调的计算成本，同时保持模型性能。&lt;h4&gt;方法&lt;/h4&gt;本文重新审视了FGSM在鲁棒迁移学习中的应用，并评估了其在不同ε值下的稳定性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;发现FGSM在对抗性微调中比从头开始训练更为稳定，且没有在标准扰动预算下出现灾难性过拟合的问题。参数高效的微调方法进一步增强了这种稳定性。&lt;h4&gt;结论&lt;/h4&gt;FGSM不仅在对抗鲁棒迁移学习中是一个更有效的替代方案，而且也是一个性能良好的方法。与使用投影梯度下降（PGD）的微调相比，FGSM在ε=4和ε=8的情况下仅损失0.39%和1.39%的测试鲁棒性，同时训练时间减少了4倍。&lt;h4&gt;翻译&lt;/h4&gt;Transfer learning is often used to decrease the computational cost of model training, as fine-tuning a model allows a downstream task to leverage the features learned from the pre-training dataset and quickly adapt them to a new task. This is particularly useful for achieving adversarial robustness, as adversarially training models from scratch is very computationally expensive. However, high robustness in transfer learning still requires adversarial training during the fine-tuning phase, which requires up to an order of magnitude more time than standard fine-tuning. In this work, we revisit the use of the fast gradient sign method (FGSM) in robust transfer learning to improve the computational cost of adversarial fine-tuning. We surprisingly find that FGSM is much more stable in adversarial fine-tuning than when training from scratch. In particular, FGSM fine-tuning does not suffer from any issues with catastrophic overfitting at standard perturbation budgets of ε=4 or ε=8. This stability is further enhanced with parameter-efficient fine-tuning methods, where FGSM remains stable even up to ε=32 for linear probing. We demonstrate how this stability translates into performance across multiple datasets. Compared to fine-tuning with the more commonly used method of projected gradient descent (PGD), on average, FGSM only loses 0.39% and 1.39% test robustness for ε=4 and ε=8 while using 4 times less training time. Surprisingly, FGSM may not only be a significantly more efficient alternative to PGD in adversarially robust transfer learning but also a well-performing one.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is often used to decrease the computational cost of modeltraining, as fine-tuning a model allows a downstream task to leverage thefeatures learned from the pre-training dataset and quickly adapt them to a newtask. This is particularly useful for achieving adversarial robustness, asadversarially training models from scratch is very computationally expensive.However, high robustness in transfer learning still requires adversarialtraining during the fine-tuning phase, which requires up to an order ofmagnitude more time than standard fine-tuning. In this work, we revisit the useof the fast gradient sign method (FGSM) in robust transfer learning to improvethe computational cost of adversarial fine-tuning. We surprisingly find thatFGSM is much more stable in adversarial fine-tuning than when training fromscratch. In particular, FGSM fine-tuning does not suffer from any issues withcatastrophic overfitting at standard perturbation budgets of $\varepsilon=4$ or$\varepsilon=8$. This stability is further enhanced with parameter-efficientfine-tuning methods, where FGSM remains stable even up to $\varepsilon=32$ forlinear probing. We demonstrate how this stability translates into performanceacross multiple datasets. Compared to fine-tuning with the more commonly usedmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%and 1.39% test robustness for $\varepsilon=4$ and $\varepsilon=8$ while using$4\times$ less training time. Surprisingly, FGSM may not only be asignificantly more efficient alternative to PGD in adversarially robusttransfer learning but also a well-performing one.</description>
      <author>example@mail.com (Joshua C. Zhao, Saurabh Bagchi)</author>
      <guid isPermaLink="false">2506.22602v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
  <item>
      <title>Understanding Generalization in Node and Link Prediction</title>
      <link>http://arxiv.org/abs/2507.00927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2412.07106&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了消息传递图神经网络（MPNNs）在节点和链接预测中的泛化能力，并提出了一个统一的框架来分析其在归纳和转导节点和链接预测设置中的泛化性质。&lt;h4&gt;背景&lt;/h4&gt;MPNNs在科学和工业领域中的节点和链接预测至关重要，但它们在实际设置中的泛化能力以及对训练集之外的数据的泛化能力理解不足。&lt;h4&gt;目的&lt;/h4&gt;引入一个统一的框架来分析MPNNs在归纳和转导节点和链接预测设置中的泛化性质，并量化图结构的影响。&lt;h4&gt;方法&lt;/h4&gt;结合不同的架构参数和损失函数，并超越图结构来分析MPNNs的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;现有的工作通常依赖于不切实际的独立同分布（i.i.d.）假设，忽略了节点或链接之间的可能相关性，并假设固定的聚合和实际中不实用的损失函数。&lt;h4&gt;结论&lt;/h4&gt;提出的泛化框架可以应用于归纳或转导设置下的任何分类任务，并通过实证研究支持了理论见解，加深了对MPNNs泛化能力的理解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用消息传递图神经网络（MPNNs）进行节点和链接预测在各个科学和工业领域至关重要，这导致了多种MPNN架构的发展。除了在实际设置中表现良好外，它们在训练集之外泛化的能力仍然理解不足。虽然一些研究探索了MPNNs在图级预测任务中的泛化，但很少关注节点和链接级别的预测。现有工作通常依赖于不切实际的i.i.d.假设，忽略了节点或链接之间的可能相关性，假设固定的聚合和不切实际的损失函数，而忽略了图结构的影响。在这项工作中，我们引入了一个统一的框架来分析MPNNs在归纳和转导节点和链接预测设置中的泛化性质，结合了不同的架构参数和损失函数，并量化了图结构的影响。此外，我们提出的泛化框架可以应用于归纳或转导设置下的任何分类任务。我们的实证研究支持了我们的理论见解，加深了我们对这些任务中MPNNs泛化能力的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using message-passing graph neural networks (MPNNs) for node and linkprediction is crucial in various scientific and industrial domains, which hasled to the development of diverse MPNN architectures. Besides working well inpractical settings, their ability to generalize beyond the training set remainspoorly understood. While some studies have explored MPNNs' generalization ingraph-level prediction tasks, much less attention has been given to node- andlink-level predictions. Existing works often rely on unrealistic i.i.d.\@assumptions, overlooking possible correlations between nodes or links, andassuming fixed aggregation and impractical loss functions while neglecting theinfluence of graph structure. In this work, we introduce a unified framework toanalyze the generalization properties of MPNNs in inductive and transductivenode and link prediction settings, incorporating diverse architecturalparameters and loss functions and quantifying the influence of graph structure.Additionally, our proposed generalization framework can be applied beyondgraphs to any classification task under the inductive or transductive setting.Our empirical study supports our theoretical insights, deepening ourunderstanding of MPNNs' generalization capabilities in these tasks.</description>
      <author>example@mail.com (Antonis Vasileiou, Timo Stoll, Christopher Morris)</author>
      <guid isPermaLink="false">2507.00927v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks</title>
      <link>http://arxiv.org/abs/2507.00083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper proposes the first closed-loop causal modeling framework  (IA-STGNN) that links tactical strike variables to strategic delay outcomes  via graph neural networks with counterfactual reasoning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的框架IA-STGNN，用于解决当前战略级模拟中战术打击行为与战略延迟之间的结构化因果建模不足的问题，特别是在捕捉“韧性-节点抑制-谈判窗口”链中的中间变量方面的结构瓶颈。&lt;h4&gt;背景&lt;/h4&gt;当前战略级模拟缺乏对战术打击行为与战略延迟之间结构化因果建模，特别是在中间变量的捕捉上存在结构瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，即干预感知时空图神经网络（IA-STGNN），以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;IA-STGNN集成了图注意力机制、反事实模拟单元和空间干预节点重建，以实现打击配置和同步策略的动态模拟。训练数据来自符合NIST SP 800-160标准的多物理模拟平台（GEANT4 + COMSOL）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IA-STGNN在MAE减少12.8%和Top-5准确率提高18.4%的同时，显著优于基线模型（ST-GNN、GCN-LSTM、XGBoost），并提高了因果路径一致性和干预稳定性。&lt;h4&gt;结论&lt;/h4&gt;IA-STGNN能够实现战略延迟的可解释预测，支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供了一种结构化和透明的AI决策支持机制。&lt;h4&gt;翻译&lt;/h4&gt;本研究针对当前战略级模拟中战术打击行为与战略延迟之间缺乏结构化因果建模的问题，特别是捕捉“韧性-节点抑制-谈判窗口”链中中间变量的结构瓶颈，提出了一种新的框架——干预感知时空图神经网络（IA-STGNN）。该模型集成了图注意力机制、反事实模拟单元和空间干预节点重建，以实现打击配置和同步策略的动态模拟。训练数据来自符合NIST SP 800-160标准的多物理模拟平台（GEANT4 + COMSOL）。实验结果表明，IA-STGNN在MAE减少12.8%和Top-5准确率提高18.4%的同时，显著优于基线模型（ST-GNN、GCN-LSTM、XGBoost），并提高了因果路径一致性和干预稳定性。IA-STGNN能够实现战略延迟的可解释预测，支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供了一种结构化和透明的AI决策支持机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study addresses the lack of structured causal modeling between tacticalstrike behavior and strategic delay in current strategic-level simulations,particularly the structural bottlenecks in capturing intermediate variableswithin the "resilience - nodal suppression - negotiation window" chain. Wepropose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN),a novel framework that closes the causal loop from tactical input to strategicdelay output. The model integrates graph attention mechanisms, counterfactualsimulation units, and spatial intervention node reconstruction to enabledynamic simulations of strike configurations and synchronization strategies.Training data are generated from a multi-physics simulation platform (GEANT4 +COMSOL) under NIST SP 800-160 standards, ensuring structural traceability andpolicy-level validation. Experimental results demonstrate that IA-STGNNsignificantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost),achieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5percent accuracy, while improving causal path consistency and interventionstability. IA-STGNN enables interpretable prediction of strategic delay andsupports applications such as nuclear deterrence simulation, diplomatic windowassessment, and multi-strategy optimization, providing a structured andtransparent AI decision-support mechanism for high-level policy modeling.</description>
      <author>example@mail.com (Wei Meng)</author>
      <guid isPermaLink="false">2507.00083v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding</title>
      <link>http://arxiv.org/abs/2507.02591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AuroraLong的新方法，旨在解决长视频理解中的计算复杂度和内存成本问题，通过使用线性RNN语言模型替代MLLM中的LLM组件，以降低计算门槛。&lt;h4&gt;背景&lt;/h4&gt;长视频理解存在高计算复杂度和内存成本的问题，因为基于Transformer的LLM所需的内存和计算与输入序列长度成平方关系。&lt;h4&gt;目的&lt;/h4&gt;提出AuroraLong以解决长视频理解中的计算复杂度和内存成本问题，并通过降低计算门槛，实现长视频理解的普及。&lt;h4&gt;方法&lt;/h4&gt;AuroraLong通过替换MLLM中的LLM组件为线性RNN语言模型，并采用视觉标记合并和线性RNN模型结合的方式，以提高吞吐量和效率。&lt;h4&gt;主要发现&lt;/h4&gt;AuroraLong在具有2B参数的情况下，仅使用公开数据进行训练，在多个视频基准测试中达到了与基于Transformer的模型相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AuroraLong证明了高效、线性的RNN在降低计算门槛方面的潜力，从而实现了长视频理解的普及。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为AuroraLong的新方法，旨在解决长视频理解中的计算复杂度和内存成本问题，通过使用线性RNN语言模型替代MLLM中的LLM组件，以降低计算门槛。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenge of long video understanding lies in its high computationalcomplexity and prohibitive memory cost, since the memory and computationrequired by transformer-based LLMs scale quadratically with input sequencelength. We propose AuroraLong to address this challenge by replacing the LLMcomponent in MLLMs with a linear RNN language model that handles input sequenceof arbitrary length with constant-size hidden states. To further increasethroughput and efficiency, we combine visual token merge with linear RNN modelsby reordering the visual tokens by their sizes in ascending order. Despitehaving only 2B parameters and being trained exclusively on public data,AuroraLong achieves performance comparable to Transformer-based models ofsimilar size trained on private datasets across multiple video benchmarks. Thisdemonstrates the potential of efficient, linear RNNs to democratize long videounderstanding by lowering its computational entry barrier. To our bestknowledge, we are the first to use a linear RNN based LLM backbone in aLLaVA-like model for open-ended video understanding.</description>
      <author>example@mail.com (Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang)</author>
      <guid isPermaLink="false">2507.02591v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.02393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的单目3D物体检测方法，通过利用视频数据，增强了对抗遮挡的能力，无需多视角设置、额外传感器、相机位姿或特定领域训练。&lt;h4&gt;背景&lt;/h4&gt;单目3D物体检测（M3OD）面临数据稀缺的挑战，这源于高标注成本和固有的2D到3D的模糊性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的伪标签框架，使用视频数据，并提高对遮挡的鲁棒性，同时不依赖于多视角设置、额外传感器、相机位姿或特定领域训练。&lt;h4&gt;方法&lt;/h4&gt;使用对象点跟踪技术，在时间相邻帧中聚合静态和动态对象的伪LiDAR数据，从而在无法获取3D数据的情况下进行3D属性提取。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法确保了可靠的准确性和强大的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;该方法是一个实用且有效的单目3D物体检测解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D object detection (M3OD) has long faced challenges due to datascarcity caused by high annotation costs and inherent 2D-to-3D ambiguity.Although various weakly supervised methods and pseudo-labeling methods havebeen proposed to address these issues, they are mostly limited bydomain-specific learning or rely solely on shape information from a singleobservation. In this paper, we propose a novel pseudo-labeling framework thatuses only video data and is more robust to occlusion, without requiring amulti-view setup, additional sensors, camera poses, or domain-specifictraining. Specifically, we explore a technique for aggregating thepseudo-LiDARs of both static and dynamic objects across temporally adjacentframes using object point tracking, enabling 3D attribute extraction inscenarios where 3D data acquisition is infeasible. Extensive experimentsdemonstrate that our method ensures reliable accuracy and strong scalability,making it a practical and effective solution for M3OD.</description>
      <author>example@mail.com (Seokyeong Lee, Sithu Aung, Junyong Choi, Seungryong Kim, Ig-Jae Kim, Junghyun Cho)</author>
      <guid isPermaLink="false">2507.02393v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges</title>
      <link>http://arxiv.org/abs/2507.02074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对利用大型语言模型（LLMs）进行视频数据中交通事故检测的近期方法进行了综述。&lt;h4&gt;背景&lt;/h4&gt;智能交通系统中，从视频流中检测交通事故是一个关键问题。&lt;h4&gt;目的&lt;/h4&gt;探讨如何利用LLMs进行交通事故检测，并对相关方法进行系统分类和评估。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一个结构化的融合策略分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前面临的挑战和机遇。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs和视觉-语言模型（VLMs）在处理、推理和总结多模态信息方面取得了显著进展。&lt;h4&gt;结论&lt;/h4&gt;本文为视频理解和基础模型这一快速发展的交叉领域中的未来研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crash detection from video feeds is a critical problem in intelligenttransportation systems. Recent developments in large language models (LLMs) andvision-language models (VLMs) have transformed how we process, reason about,and summarize multimodal information. This paper surveys recent methodsleveraging LLMs for crash detection from video data. We present a structuredtaxonomy of fusion strategies, summarize key datasets, analyze modelarchitectures, compare performance benchmarks, and discuss ongoing challengesand opportunities. Our review provides a foundation for future research in thisfast-growing intersection of video understanding and foundation models.</description>
      <author>example@mail.com (Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2507.02074v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames</title>
      <link>http://arxiv.org/abs/2507.02001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Chain of Thought的视频问答推理策略，旨在解决长视频理解问题。&lt;h4&gt;背景&lt;/h4&gt;尽管长上下文视觉语言模型（VLMs）在处理输入帧方面取得进展，但它们在有效利用序列长度和避免上下文窗口中的无关干扰方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种推理策略，以优化视频问答的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用VLM自身迭代地识别和提取视频中最相关的帧，然后使用这些帧进行问答。&lt;h4&gt;主要发现&lt;/h4&gt;通过在推理时使用更多计算来选择最相关的上下文，可以提升准确性，并达到最先进的性能。在四个不同的视频问答数据集上实现了最先进的成果，特别是对于超过1小时的较长视频，使用32K上下文窗口的方法在LVBench上比使用标准推理的700K上下文窗口的VLM性能高出2.8个百分点。&lt;h4&gt;结论&lt;/h4&gt;Temporal Chain of Thought策略在视频问答任务中有效提升了长视频的理解能力，并在多个数据集上实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in Vision-Language Models (VLMs), long-videounderstanding remains a challenging problem. Although state-of-the-artlong-context VLMs can process around 1000 input frames, they still struggle toeffectively leverage this sequence length, and succumb to irrelevantdistractors within the context window. We present Temporal Chain of Thought, aninference strategy for video question-answering that curates the model's inputcontext. We use the VLM itself to iteratively identify and extract the mostrelevant frames from the video, which are then used for answering. Wedemonstrate how leveraging more computation at inference-time to select themost relevant context leads to improvements in accuracy, in agreement withrecent work on inference-time scaling of LLMs. Moreover, we achievestate-of-the-art results on 4 diverse video question-answering datasets,showing consistent improvements with 3 different VLMs. In particular, ourmethod shines on longer videos which would not otherwise fit within the model'scontext window: On longer videos of more than 1 hour on LVBench, our approachusing a context window of 32K outperforms the same VLM using standard inferencewith a 700K context window by 2.8 points.</description>
      <author>example@mail.com (Anurag Arnab, Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid)</author>
      <guid isPermaLink="false">2507.02001v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>No time to train! Training-Free Reference-Based Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.02798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图像分割模型，通过利用参考图像和强语义先验，减少了手动提示的需求，并在多个数据集上实现了最先进的分割性能。&lt;h4&gt;背景&lt;/h4&gt;传统的图像分割模型依赖于大规模标注数据，成本高昂。SAM模型通过提示式分割方法缓解了这一问题，但仍然需要手动提示或复杂的规则。&lt;h4&gt;目的&lt;/h4&gt;减少处理新图像时的手动提示负担，通过使用少量参考图像进行对象分割。&lt;h4&gt;方法&lt;/h4&gt;通过以下步骤实现：1）构建记忆库；2）表示聚合；3）语义感知特征匹配。&lt;h4&gt;主要发现&lt;/h4&gt;对应关系能够自动生成实例级分割掩码，从而提高了分割性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上实现了显著的性能提升，包括COCO FSOD、PASCAL VOC Few-Shot和跨域FSOD基准，优于现有的无训练方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图像分割模型的性能在历史上受到收集大规模标注数据高成本的制约。Segment Anything Model（SAM）通过提示式、语义无关的分割范式缓解了这个问题，但仍需要手动视觉提示或复杂的领域特定提示生成规则来处理新图像。为了减少这种新的负担，我们的工作研究了在有少量参考图像的情况下进行对象分割的任务。我们的关键洞察是利用基础模型学习到的强语义先验来识别参考图像和目标图像之间的对应区域。我们发现对应关系能够为下游任务自动生成实例级分割掩码，并通过一个多阶段、无需训练的方法实现了这一想法，包括（1）记忆库构建；（2）表示聚合；（3）语义感知特征匹配。我们的实验表明，在分割指标上取得了显著改进，在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）上实现了最先进的性能，并在跨域FSOD基准上优于现有的无训练方法（22.4% nAP）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of image segmentation models has historically beenconstrained by the high cost of collecting large-scale annotated data. TheSegment Anything Model (SAM) alleviates this original problem through apromptable, semantics-agnostic, segmentation paradigm and yet still requiresmanual visual-prompts or complex domain-dependent prompt-generation rules toprocess a new image. Towards reducing this new burden, our work investigatesthe task of object segmentation when provided with, alternatively, only a smallset of reference images. Our key insight is to leverage strong semantic priors,as learned by foundation models, to identify corresponding regions between areference and a target image. We find that correspondences enable automaticgeneration of instance-level segmentation masks for downstream tasks andinstantiate our ideas via a multi-stage, training-free method incorporating (1)memory bank construction; (2) representation aggregation and (3) semantic-awarefeature matching. Our experiments show significant improvements on segmentationmetrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP),PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-freeapproaches on the Cross-Domain FSOD benchmark (22.4% nAP).</description>
      <author>example@mail.com (Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley)</author>
      <guid isPermaLink="false">2507.02798v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Prompt learning with bounding box constraints for medical image segmentation</title>
      <link>http://arxiv.org/abs/2507.02743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE Transactions on Biomedical Engineering (TMBE), 14  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合基础模型表示能力和弱监督分割标注效率的新框架，用于自动化提示生成，以降低医疗领域像素级标注的劳动强度和成本。&lt;h4&gt;背景&lt;/h4&gt;在医疗领域，像素级标注既耗时又昂贵。为了减轻这种负担，基于边界框标注的弱监督方法提供了一种实用的替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过自动化提示生成和使用边界框标注，来减少对像素级标注的依赖，并提高分割的效率。&lt;h4&gt;方法&lt;/h4&gt;该框架利用基础模型，通过集成来自边界框标注的多重约束和由提示基础模型生成的伪标签来进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;在多个模态数据集上的实验表明，该方法在有限的标注数据集上达到了平均Dice分数84.90%，优于现有的全监督和弱监督方法。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个有效的弱监督分割方法，显著降低了医疗领域图像分割的标注成本，并提供了开源代码供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pixel-wise annotations are notoriously labourious and costly to obtain in themedical domain. To mitigate this burden, weakly supervised approaches based onbounding box annotations-much easier to acquire-offer a practical alternative.Vision foundation models have recently shown noteworthy segmentationperformance when provided with prompts such as points or bounding boxes. Promptlearning exploits these models by adapting them to downstream tasks andautomating segmentation, thereby reducing user intervention. However, existingprompt learning approaches depend on fully annotated segmentation masks. Thispaper proposes a novel framework that combines the representational power offoundation models with the annotation efficiency of weakly supervisedsegmentation. More specifically, our approach automates prompt generation forfoundation models using only bounding box annotations. Our proposedoptimization scheme integrates multiple constraints derived from boxannotations with pseudo-labels generated by the prompted foundation model.Extensive experiments across multimodal datasets reveal that our weaklysupervised method achieves an average Dice score of 84.90% in a limited datasetting, outperforming existing fully-supervised and weakly-supervisedapproaches. The code is available athttps://github.com/Minimel/box-prompt-learning-VFM.git</description>
      <author>example@mail.com (Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert)</author>
      <guid isPermaLink="false">2507.02743v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>TurboReg: TurboClique for Robust and Efficient Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2507.01439v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV-2025 Accepted Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速且鲁棒的点云配准估计方法TurboReg，该方法基于轻量级图TurboClique和并行化的Pivot-Guided Search (PGS)算法，有效提高了配准速度和精度。&lt;h4&gt;背景&lt;/h4&gt;现有的基于最大团搜索的配准方法虽然召回率高，但时间复杂度呈指数级，限制了其在时间敏感应用中的使用。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的效率问题，提出了一种新的快速且鲁棒的点云配准方法。&lt;h4&gt;方法&lt;/h4&gt;TurboReg方法首先定义了TurboClique作为一个在高约束兼容图中的3-团，其轻量级特性允许高效并行搜索，高约束的兼容图确保了鲁棒的空问一致性。接着，PGS算法选择具有高SC²分数的匹配对作为支点，有效地引导搜索向具有更高内点比率的TurboClique方向。PGS算法具有线性时间复杂度，比指数级时间复杂度的最大团搜索要高效得多。&lt;h4&gt;主要发现&lt;/h4&gt;TurboReg在多个真实世界数据集上实现了最先进的性能，并显著提高了速度。例如，在3DMatch+FCGF数据集上，TurboReg（1K）比3DMAC快208.22倍，同时实现了更高的召回率。&lt;h4&gt;结论&lt;/h4&gt;TurboReg是一种高效且鲁棒的点云配准方法，适用于时间敏感的应用。&lt;h4&gt;翻译&lt;/h4&gt;Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC² scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates 208.22 times faster than 3DMAC while also achieving higher recall. Our code is accessible at https://github.com/Laka-3DV/TurboReg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in correspondence-based Point CloudRegistration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential timecomplexity, limiting their use in time-sensitive applications. To address thischallenge, we propose a fast and robust estimator, TurboReg, built upon a novellightweight clique, TurboClique, and a highly parallelizable Pivot-GuidedSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within ahighly-constrained compatibility graph. The lightweight nature of the 3-cliqueallows for efficient parallel searching, and the highly-constrainedcompatibility graph ensures robust spatial consistency for stabletransformation estimation. Next, PGS selects matching pairs with high SC$^2$scores as pivots, effectively guiding the search toward TurboCliques withhigher inlier ratios. Moreover, the PGS algorithm has linear time complexityand is significantly more efficient than the maximal clique search withexponential time complexity. Extensive experiments show that TurboReg achievesstate-of-the-art performance across multiple real-world datasets, withsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achievinghigher recall. Our code is accessible at\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.</description>
      <author>example@mail.com (Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li)</author>
      <guid isPermaLink="false">2507.01439v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs</title>
      <link>http://arxiv.org/abs/2507.02671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过差分隐私生成模型进行数据共享的方法，用于提高深度学习在医学图像领域的应用效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学图像领域的应用受到数据稀缺和隐私法规的限制，而联邦学习虽然允许分散式训练，但通信成本高且通常限于单一下游任务。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种方法，以提高隐私、可扩展性和效率，同时支持多样化的下游任务。&lt;h4&gt;方法&lt;/h4&gt;通过使用基础模型提取紧凑、信息丰富的嵌入，减少了冗余和计算开销。客户端合作训练差分隐私条件变分自动编码器（DP-CVAE），以模型化全局、隐私保护的数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个特征提取器上得到了验证，在保证差分隐私的同时，比传统的联邦学习分类器性能更好。DP-CVAE生成的嵌入比DP-CGAN更准确，并且参数数量减少了5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的方法通过提高隐私保护、可扩展性和效率，为深度学习在医学图像领域的应用提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Learning (DL) has revolutionized medical imaging, yet its adoption isconstrained by data scarcity and privacy regulations, limiting access todiverse datasets. Federated Learning (FL) enables decentralized training butsuffers from high communication costs and is often restricted to a singledownstream task, reducing flexibility. We propose a data-sharing method viaDifferentially Private (DP) generative models. By adopting foundation models,we extract compact, informative embeddings, reducing redundancy and loweringcomputational overhead. Clients collaboratively train a Differentially PrivateConditional Variational Autoencoder (DP-CVAE) to model a global, privacy-awaredata distribution, supporting diverse downstream tasks. Our approach, validatedacross multiple feature extractors, enhances privacy, scalability, andefficiency, outperforming traditional FL classifiers while ensuringdifferential privacy. Additionally, DP-CVAE produces higher-fidelity embeddingsthan DP-CGAN while requiring $5{\times}$ fewer parameters.</description>
      <author>example@mail.com (Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig)</author>
      <guid isPermaLink="false">2507.02671v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning</title>
      <link>http://arxiv.org/abs/2507.02565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于人类外观和社会距离感知的交互动作重建方法，用于从复杂环境中捕获的真实视频中进行人体姿态估计。&lt;h4&gt;背景&lt;/h4&gt;现有的人体姿态估计方法在处理视觉模糊和人际遮挡时无法从真实场景视频中恢复合理的近距离交互动作，即使是先进的模型也无法准确区分人类语义。&lt;h4&gt;目的&lt;/h4&gt;提出一种优化框架，以重建准确的交互动作，并考虑人类外观、社会距离和物理定律。&lt;h4&gt;方法&lt;/h4&gt;该方法首先训练一个扩散模型来学习人类的社会距离行为和姿态先验知识，然后将训练的网络和两个可优化张量整合到一个双分支优化框架中，以重建人体动作和外观。同时，设计了基于3D高斯、2D关键点和网格穿透的约束条件来辅助优化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够从复杂环境中的真实视频中准确估计交互动作，并构建了一个带有伪真实交互标注的数据集，可能促进姿态估计和人类行为理解的研究。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在多个基准测试中优于现有方法，代码和数据可在指定链接获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从野外视频中恢复合理的近距离交互动作。即使是当前最先进的基于大型基础模型（例如SAM）也无法在这些具有挑战性的场景中准确区分人类语义。在本工作中，我们发现人类外观可以提供一种直接的方法来解决这些障碍。基于这一观察，我们提出了一种双分支优化框架，以在受人类外观、社会距离和物理定律约束的情况下重建准确的交互动作。具体来说，我们首先训练了一个扩散模型来学习人类的社会距离行为和姿态先验知识。然后，将训练的网络和两个可优化的张量整合到一个双分支优化框架中，以重建人体动作和外观。还设计了基于3D高斯、2D关键点和网格穿透的几个约束条件来辅助优化。有了距离先验和多种约束，我们的方法能够从复杂环境中捕获的真实视频中估计准确的交互动作。我们进一步构建了一个带有伪真实交互标注的数据集，这可能促进姿态估计和人类行为理解的研究。在几个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to visual ambiguities and inter-person occlusions, existing human poseestimation methods cannot recover plausible close interactions from in-the-wildvideos. Even state-of-the-art large foundation models~(\eg, SAM) cannotaccurately distinguish human semantics in such challenging scenarios. In thiswork, we find that human appearance can provide a straightforward cue toaddress these obstacles. Based on this observation, we propose a dual-branchoptimization framework to reconstruct accurate interactive motions withplausible body contacts constrained by human appearances, social proxemics, andphysical laws. Specifically, we first train a diffusion model to learn thehuman proxemic behavior and pose prior knowledge. The trained network and twooptimizable tensors are then incorporated into a dual-branch optimizationframework to reconstruct human motions and appearances. Several constraintsbased on 3D Gaussians, 2D keypoints, and mesh penetrations are also designed toassist the optimization. With the proxemics prior and diverse constraints, ourmethod is capable of estimating accurate interactions from in-the-wild videoscaptured in complex environments. We further build a dataset with pseudoground-truth interaction annotations, which may promote future research on poseestimation and human behavior understanding. Experimental results on severalbenchmarks demonstrate that our method outperforms existing approaches. Thecode and data are available at https://www.buzhenhuang.com/works/CloseApp.html.</description>
      <author>example@mail.com (Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee)</author>
      <guid isPermaLink="false">2507.02565v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios</title>
      <link>http://arxiv.org/abs/2507.02479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CrowdTrack的困难大规模多行人跟踪数据集，旨在解决现有方法在复杂场景下的局限性。&lt;h4&gt;背景&lt;/h4&gt;多目标跟踪是计算机视觉的经典领域，其中行人跟踪应用价值极高，已成为最热门的研究类别。现有方法主要使用运动或外观信息进行跟踪，但在复杂场景下往往难以实现。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在复杂场景下的不足，提出一个能够支持算法在复杂情况下有效工作的数据集。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含33个视频、5185个轨迹的CrowdTrack数据集，主要从第一人称视角拍摄，所有视频都来自真实生活中的复杂场景。每个对象都被标注了完整的边界框和唯一的对象ID。&lt;h4&gt;主要发现&lt;/h4&gt;数据集全面分析了CrowdTrack，并在其上测试了多个SOTA模型，同时分析了基础模型在数据集上的性能。&lt;h4&gt;结论&lt;/h4&gt;CrowdTrack数据集为算法开发提供了一个平台，有助于在复杂情况下保持跟踪算法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the aforementioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: https://github.com/loseevaya/CrowdTrack.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object tracking is a classic field in computer vision. Among them,pedestrian tracking has extremely high application value and has become themost popular research category. Existing methods mainly use motion orappearance information for tracking, which is often difficult in complexscenarios. For the motion information, mutual occlusions between objects oftenprevent updating of the motion state; for the appearance information,non-robust results are often obtained due to reasons such as only partialvisibility of the object or blurred images. Although learning how to performtracking in these situations from the annotated data is the simplest solution,the existing MOT dataset fails to satisfy this solution. Existing methodsmainly have two drawbacks: relatively simple scene composition andnon-realistic scenarios. Although some of the video sequences in existingdataset do not have the above-mentioned drawbacks, the number is far fromadequate for research purposes. To this end, we propose a difficult large-scaledataset for multi-pedestrian tracking, shot mainly from the first-person viewand all from real-life complex scenarios. We name it ``CrowdTrack'' becausethere are numerous objects in most of the sequences. Our dataset consists of 33videos, containing a total of 5,185 trajectories. Each object is annotated witha complete bounding box and a unique object ID. The dataset will provide aplatform to facilitate the development of algorithms that remain effective incomplex situations. We analyzed the dataset comprehensively and tested multipleSOTA models on our dataset. Besides, we analyzed the performance of thefoundation models on our dataset. The dataset and project code is released at:https://github.com/loseevaya/CrowdTrack .</description>
      <author>example@mail.com (Teng Fu, Yuwen Chen, Zhuofan Chen, Mengyang Zhao, Bin Li, Xiangyang Xue)</author>
      <guid isPermaLink="false">2507.02479v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Toward a Robust and Generalizable Metamaterial Foundation Model</title>
      <link>http://arxiv.org/abs/2507.02436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MetaFO的元材料基础模型，该模型基于贝叶斯变压器并受到大型语言模型的启发，旨在解决现有材料功能创新中的限制。&lt;h4&gt;背景&lt;/h4&gt;材料功能的进步推动了各个领域的创新，而元材料（由结构而非组成定义）正引领这一进程。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有设计策略的限制，如任务特定的再训练、分布外（OOD）泛化不良以及正向和逆向设计需要独立模型等问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于贝叶斯变压器的元材料基础模型（MetaFO），该模型学习元材料的底层机制，允许在多样化的、未知的材料属性和结构响应组合上进行概率预测和无样本预测。&lt;h4&gt;主要发现&lt;/h4&gt;MetaFO在非线性逆向设计方面表现出色，即使在分布外条件下也是如此。它将元材料视为一个将材料属性映射到结构响应的算子，揭示了复杂的结构-属性关系，并显著扩大了设计空间。&lt;h4&gt;结论&lt;/h4&gt;这种可扩展且通用的框架标志着人工智能驱动元材料发现的范式转变，为下一代创新铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：材料功能的进步推动了各个领域的创新，而元材料（由结构而非组成定义）正引领这一进程。尽管人工智能（AI）驱动的创新设计策略正在兴起，但它们的影响受到任务特定再训练、分布外（OOD）泛化不良以及正向和逆向设计需要独立模型等限制。为了解决这些限制，我们引入了元材料基础模型（MetaFO），一个受大型语言模型启发的贝叶斯变压器基础模型。MetaFO学习元材料的底层机制，允许在多样化的、未知的材料属性和结构响应组合上进行概率预测和无样本预测。它还在非线性逆向设计方面表现出色，即使在分布外条件下也是如此。通过将元材料视为一个将材料属性映射到结构响应的算子，MetaFO揭示了复杂的结构-属性关系，并显著扩大了设计空间。这个可扩展且通用的框架标志着人工智能驱动元材料发现的范式转变，为下一代创新铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in material functionalities drive innovations across various fields,where metamaterials-defined by structure rather than composition-are leadingthe way. Despite the rise of artificial intelligence (AI)-driven designstrategies, their impact is limited by task-specific retraining, poorout-of-distribution(OOD) generalization, and the need for separate models forforward and inverse design. To address these limitations, we introduce theMetamaterial Foundation Model (MetaFO), a Bayesian transformer-based foundationmodel inspired by large language models. MetaFO learns the underlying mechanicsof metamaterials, enabling probabilistic, zero-shot predictions across diverse,unseen combinations of material properties and structural responses. It alsoexcels in nonlinear inverse design, even under OOD conditions. By treatingmetamaterials as an operator that maps material properties to structuralresponses, MetaFO uncovers intricate structure-property relationships andsignificantly expands the design space. This scalable and generalizableframework marks a paradigm shift in AI-driven metamaterial discovery, pavingthe way for next-generation innovations.</description>
      <author>example@mail.com (Namjung Kim, Dongseok Lee, Jongbin Yu, Sung Woong Cho, Dosung Lee, Yesol Park, Youngjoon Hong)</author>
      <guid isPermaLink="false">2507.02436v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes</title>
      <link>http://arxiv.org/abs/2507.02690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures. Business process prediction using reinforcement  learning and heterogeneous graph neural networks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为RLHGNN的新框架，用于预测服务导向架构中的下一个活动，以优化业务流程。&lt;h4&gt;背景&lt;/h4&gt;在微服务、分布式企业系统和云原生平台等面向服务的架构中，下一个活动预测是一个基本挑战，这有助于主动资源分配和动态服务组合。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法无法捕捉非顺序关系、同质表示和静态结构的局限性，提出RLHGNN框架。&lt;h4&gt;方法&lt;/h4&gt;RLHGNN将事件日志转换为具有三种不同类型边的异构图，并利用强化学习自动确定每个特定过程的最佳图结构。然后，应用异构图卷积和相关特定的聚合策略来预测下一个活动。&lt;h4&gt;主要发现&lt;/h4&gt;RLHGNN在六个真实世界数据集上的评估表明，它优于现有方法，且每个预测的推理延迟约为1毫秒。&lt;h4&gt;结论&lt;/h4&gt;RLHGNN是一种高度实用的解决方案，适合实时业务流程监控应用。&lt;h4&gt;翻译&lt;/h4&gt;Next activity prediction represents a fundamental challenge for optimizing business processes in service-oriented architectures such as microservices environments, distributed enterprise systems, and cloud-native platforms, which enables proactive resource allocation and dynamic service composition. Despite the prevalence of sequence-based methods, these approaches fail to capture non-sequential relationships that arise from parallel executions and conditional dependencies. Even though graph-based approaches address structural preservation, they suffer from homogeneous representations and static structures that apply uniform modeling strategies regardless of individual process complexity characteristics. To address these limitations, we introduce RLHGNN, a novel framework that transforms event logs into heterogeneous process graphs with three distinct edge types grounded in established process mining theory. Our approach creates four flexible graph structures by selectively combining these edges to accommodate different process complexities, and employs reinforcement learning formulated as a Markov Decision Process to automatically determine the optimal graph structure for each specific process instance. RLHGNN then applies heterogeneous graph convolution with relation-specific aggregation strategies to effectively predict the next activity. This adaptive methodology enables precise modeling of both sequential and non-sequential relationships in service interactions. Comprehensive evaluation on six real-world datasets demonstrates that RLHGNN consistently outperforms state-of-the-art approaches. Furthermore, it maintains an inference latency of approximately 1 ms per prediction, representing a highly practical solution suitable for real-time business process monitoring applications. The source code is available at https://github.com/Joker3993/RLHGNN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next activity prediction represents a fundamental challenge for optimizingbusiness processes in service-oriented architectures such as microservicesenvironments, distributed enterprise systems, and cloud-native platforms, whichenables proactive resource allocation and dynamic service composition. Despitethe prevalence of sequence-based methods, these approaches fail to capturenon-sequential relationships that arise from parallel executions andconditional dependencies. Even though graph-based approaches address structuralpreservation, they suffer from homogeneous representations and staticstructures that apply uniform modeling strategies regardless of individualprocess complexity characteristics. To address these limitations, we introduceRLHGNN, a novel framework that transforms event logs into heterogeneous processgraphs with three distinct edge types grounded in established process miningtheory. Our approach creates four flexible graph structures by selectivelycombining these edges to accommodate different process complexities, andemploys reinforcement learning formulated as a Markov Decision Process toautomatically determine the optimal graph structure for each specific processinstance. RLHGNN then applies heterogeneous graph convolution withrelation-specific aggregation strategies to effectively predict the nextactivity. This adaptive methodology enables precise modeling of both sequentialand non-sequential relationships in service interactions. Comprehensiveevaluation on six real-world datasets demonstrates that RLHGNN consistentlyoutperforms state-of-the-art approaches. Furthermore, it maintains an inferencelatency of approximately 1 ms per prediction, representing a highly practicalsolution suitable for real-time business process monitoring applications. Thesource code is available at https://github.com/Joker3993/RLHGNN.</description>
      <author>example@mail.com (Jiaxing Wang, Yifeng Yu, Jiahan Song, Bin Cao, Jing Fan, Ji Zhang)</author>
      <guid isPermaLink="false">2507.02690v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization</title>
      <link>http://arxiv.org/abs/2507.02288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于文本特征引导的视觉提示调优框架，旨在解决领域泛化中特征解耦的挑战，并通过实验证明其优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;领域泛化（DG）旨在开发能够在未见过的目标领域有效执行的模型。近期，预训练视觉基础模型（VFMs）如CLIP在增强深度学习模型的泛化能力方面展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;设计有效的提示，能够解耦不同领域中的不变特征。&lt;h4&gt;方法&lt;/h4&gt;1. 利用可控制和灵活的语言提示进行特征解耦；2. 引入一种新的框架，使用大型语言模型（LLM）自动解耦文本提示；3. 通过解耦的文本特征学习领域不变视觉表示；4. 提出最坏显式表示对齐（WERA），通过风格化图像增强增加源领域多样性，并通过对齐约束确保视觉表示的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要领域泛化数据集上，提出的框架优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的基于文本特征引导的视觉提示调优框架能够有效提升领域泛化能力，为深度学习模型在多个领域中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：领域泛化（DG）寻求开发一种能够在未见过的目标领域有效执行的通用模型。值得注意的是，近期在预训练视觉基础模型（VFMs），如CLIP，方面的进展已显示出增强深度学习模型泛化能力的巨大潜力。尽管VFM基于领域提示调优在领域泛化中受到了越来越多的关注，但设计能够解耦不同领域间不变特征的提示仍然是一个关键挑战。在本文中，我们通过利用VFM的可控和灵活的语言提示来应对这一挑战。鉴于VFMs的文本模态天然更容易解耦，我们引入了一种新颖的文本特征引导的视觉提示调优框架。该框架首先使用大型语言模型（LLM）自动解耦文本提示，然后根据解耦的文本特征学习领域不变的视觉表示。然而，仅依赖语言来引导视觉特征解耦存在局限性，因为视觉特征有时可能过于复杂或微妙，无法完全被描述性文本所捕捉。为了解决这个问题，我们引入了最坏显式表示对齐（WERA），它通过增加一组抽象提示扩展了文本引导的视觉提示。这些提示通过风格化图像增强增加了源域的多样性，而对齐约束确保了视觉表示在原始和增强分布中都保持一致性。在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要领域泛化数据集上进行的实验表明，我们提出的方法优于现有的领域泛化方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Generalization (DG) seeks to develop a versatile model capable ofperforming effectively on unseen target domains. Notably, recent advances inpre-trained Visual Foundation Models (VFMs), such as CLIP, have demonstratedconsiderable potential in enhancing the generalization capabilities of deeplearning models. Despite the increasing attention toward VFM-based domainprompt tuning within DG, the effective design of prompts capable ofdisentangling invariant features across diverse domains remains a criticalchallenge. In this paper, we propose addressing this challenge by leveragingthe controllable and flexible language prompt of the VFM. Noting that the textmodality of VFMs is naturally easier to disentangle, we introduce a novelframework for text feature-guided visual prompt tuning. This framework firstautomatically disentangles the text prompt using a large language model (LLM)and then learns domain-invariant visual representation guided by thedisentangled text feature. However, relying solely on language to guide visualfeature disentanglement has limitations, as visual features can sometimes betoo complex or nuanced to be fully captured by descriptive text. To addressthis, we introduce Worst Explicit Representation Alignment (WERA), whichextends text-guided visual prompts by incorporating an additional set ofabstract prompts. These prompts enhance source domain diversity throughstylized image augmentations, while alignment constraints ensure that visualrepresentations remain consistent across both the original and augmenteddistributions. Experiments conducted on major DG datasets, including PACS,VLCS, OfficeHome, DomainNet, and TerraInc, demonstrate that our proposed methodoutperforms state-of-the-art DG methods.</description>
      <author>example@mail.com (De Cheng, Zhipeng Xu, Xinyang Jiang, Dongsheng Li, Nannan Wang, Xinbo Gao)</author>
      <guid isPermaLink="false">2507.02288v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>When Attention is Beneficial for Learning Wireless Resource Allocation Efficiently?</title>
      <link>http://arxiv.org/abs/2507.02427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在资源分配中是否需要使用注意力机制，并探讨了将注意力机制与图神经网络（GNNs）结合用于学习无线策略的趋势。&lt;h4&gt;背景&lt;/h4&gt;Transformer由于使用了注意力机制来利用跨词汇的依赖性，在自然语言处理中非常高效。图神经网络（GNNs）在可扩展性和泛化性方面具有潜力，可以高效地学习资源分配策略。&lt;h4&gt;目的&lt;/h4&gt;探讨在资源分配中是否需要使用注意力机制，并通过分析函数的结构和数值算法来验证这一观点。&lt;h4&gt;方法&lt;/h4&gt;通过分析定义在集合上的函数结构，证明单集合上的排列等变函数可以递归地表示为两种类型的函数：一种涉及注意力，另一种不涉及。将数值算法重新表示为递归形式，以优化代表性资源分配问题。&lt;h4&gt;主要发现&lt;/h4&gt;发现当干扰（如多用户或数据流间的干扰）未反映在策略的可测量参数中时，需要使用注意力来模拟干扰。&lt;h4&gt;结论&lt;/h4&gt;提出了一种通过结构与GNNs设计对齐的框架，并通过仿真验证了所提出的GNN在可重构智能表面辅助的混合预编码中的学习效率。&lt;h4&gt;翻译&lt;/h4&gt;由于使用了注意力机制来利用跨词汇的依赖性，Transformer在自然语言处理中非常高效。通过利用资源分配策略中广泛存在的排列属性，图神经网络（GNNs）在可扩展性和泛化性方面具有潜力，可以高效地学习这些策略。为了获得这两种架构的好处，最近有一种趋势是将注意力机制与GNNs结合用于学习无线策略。然而，在资源分配中，注意力机制真的是必需的吗？在本文中，我们通过分析定义在集合上的函数结构和数值算法来回答这个问题，因为无线策略的排列属性是由涉及的集合（例如用户集）引起的。特别是，我们证明了单集合上的排列等变函数可以递归地表示为两种类型的函数：一种涉及注意力，另一种不涉及。我们进而将优化几个代表性资源分配问题的数值算法重新表示为递归形式。我们发现，当干扰（如多用户或数据流间的干扰）未反映在策略的可测量参数中时，需要使用注意力来模拟干扰。基于这一洞察，我们建立了一个与结构对齐的GNN设计框架。以可重构智能表面辅助的混合预编码为例，通过仿真验证了所提出的GNN的学习效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Owing to the use of attention mechanism to leverage the dependency acrosstokens, Transformers are efficient for natural language processing. Byharnessing permutation properties broadly exist in resource allocationpolicies, each mapping measurable environmental parameters (e.g., channelmatrix) to optimized variables (e.g., precoding matrix), graph neural networks(GNNs) are promising for learning these policies efficiently in terms ofscalability and generalizability. To reap the benefits of both architectures,there is a recent trend of incorporating attention mechanism with GNNs forlearning wireless policies. Nevertheless, is the attention mechanism reallyneeded for resource allocation? In this paper, we strive to answer thisquestion by analyzing the structures of functions defined on sets and numericalalgorithms, given that the permutation properties of wireless policies areinduced by the involved sets (say user set). In particular, we prove that thepermutation equivariant functions on a single set can be recursively expressedby two types of functions: one involves attention, and the other does not. Weproceed to re-express the numerical algorithms for optimizing severalrepresentative resource allocation problems in recursive forms. We find thatwhen interference (say multi-user or inter-data stream interference) is notreflected in the measurable parameters of a policy, attention needs to be usedto model the interference. With the insight, we establish a framework ofdesigning GNNs by aligning with the structures. By taking reconfigurableintelligent surface-aided hybrid precoding as an example, the learningefficiency of the proposed GNN is validated via simulations.</description>
      <author>example@mail.com (Jia Guo, Chenyang Yang)</author>
      <guid isPermaLink="false">2507.02427v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach</title>
      <link>http://arxiv.org/abs/2507.02826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比双重路径网络（DCDP-HAR）的新型框架，用于解决多模态人体活动识别（HAR）系统中的跨模态特征对齐和模态贡献不平衡问题。&lt;h4&gt;背景&lt;/h4&gt;人体活动识别是智能系统感知和交互环境的核心技术，但多模态HAR系统仍面临跨模态特征对齐和模态贡献不平衡的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DCDP-HAR框架以解决上述挑战，并验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;DCDP-HAR框架包括三个关键组件：1）双重路径特征提取架构，利用ResNet和DenseNet分支协同处理多模态传感器数据；2）多阶段对比学习机制，实现从局部感知到语义抽象的渐进式对齐；3）信心驱动的梯度调制策略，在反向传播过程中动态监控和调整每个模态分支的学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过消融实验验证了每个组件的有效性，并在四个公开基准数据集上进行了广泛的对比实验。&lt;h4&gt;结论&lt;/h4&gt;DCDP-HAR框架能够有效解决多模态HAR系统中的关键挑战，提高了识别准确性和系统的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensor-based Human Activity Recognition (HAR) is a core technology thatenables intelligent systems to perceive and interact with their environment.However, multimodal HAR systems still encounter key challenges, such asdifficulties in cross-modal feature alignment and imbalanced modalitycontributions. To address these issues, we propose a novel framework called theDynamic Contrastive Dual-Path Network (DCDP-HAR). The framework comprises threekey components. First, a dual-path feature extraction architecture is employed,where ResNet and DenseNet branches collaboratively process multimodal sensordata. Second, a multi-stage contrastive learning mechanism is introduced toachieve progressive alignment from local perception to semantic abstraction.Third, we present a confidence-driven gradient modulation strategy thatdynamically monitors and adjusts the learning intensity of each modality branchduring backpropagation, effectively alleviating modality competition. Inaddition, a momentum-based gradient accumulation strategy is adopted to enhancetraining stability. We conduct ablation studies to validate the effectivenessof each component and perform extensive comparative experiments on four publicbenchmark datasets.</description>
      <author>example@mail.com (Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li)</author>
      <guid isPermaLink="false">2507.02826v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms</title>
      <link>http://arxiv.org/abs/2507.02724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HIPPO是一种用于蛋白质-蛋白质相互作用（PPI）预测的层次对比学习框架，在跨物种PPI预测中表现优异，具有零样本迁移能力。&lt;h4&gt;背景&lt;/h4&gt;人工智能在科学领域的进步突出了对比学习在连接异质生物数据模态方面的强大能力。&lt;h4&gt;目的&lt;/h4&gt;提出HIPPO框架，用于蛋白质-蛋白质相互作用（PPI）预测。&lt;h4&gt;方法&lt;/h4&gt;HIPPO通过多层次生物表示匹配对蛋白质序列及其层次属性进行对齐，并采用层次对比损失函数来模拟蛋白质功能类别的结构关系。该框架通过数据驱动的惩罚机制自适应地融合领域和家庭知识，确保学习到的嵌入空间与蛋白质功能的内在层次结构一致。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HIPPO在基准数据集上达到最先进的性能，优于现有方法，并在低数据环境中表现出鲁棒性。模型还显示出对其他物种的强大零样本迁移能力，即使在实验数据有限的未充分表征或稀有生物中也能进行可靠的PPI预测和功能推断。进一步分析表明，层次特征融合对于捕获保守的相互作用决定因素，如结合基序和功能注释，至关重要。&lt;h4&gt;结论&lt;/h4&gt;HIPPO推进了跨物种PPI预测，并为在稀疏或不平衡的多物种数据场景中预测相互作用提供了一个统一的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI for science have highlighted the power of contrastivelearning in bridging heterogeneous biological data modalities. Building on thisparadigm, we propose HIPPO (HIerarchical Protein-Protein interaction predictionacross Organisms), a hierarchical contrastive framework for protein-proteininteraction(PPI) prediction, where protein sequences and their hierarchicalattributes are aligned through multi-tiered biological representation matching.The proposed approach incorporates hierarchical contrastive loss functions thatemulate the structured relationship among functional classes of proteins. Theframework adaptively incorporates domain and family knowledge through adata-driven penalty mechanism, enforcing consistency between the learnedembedding space and the intrinsic hierarchy of protein functions. Experimentson benchmark datasets demonstrate that HIPPO achieves state-of-the-artperformance, outperforming existing methods and showing robustness in low-dataregimes. Notably, the model demonstrates strong zero-shot transferability toother species without retraining, enabling reliable PPI prediction andfunctional inference even in less characterized or rare organisms whereexperimental data are limited. Further analysis reveals that hierarchicalfeature fusion is critical for capturing conserved interaction determinants,such as binding motifs and functional annotations. This work advancescross-species PPI prediction and provides a unified framework for interactionprediction in scenarios with sparse or imbalanced multi-species data.</description>
      <author>example@mail.com (Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu)</author>
      <guid isPermaLink="false">2507.02724v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping</title>
      <link>http://arxiv.org/abs/2507.02672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/RSJ International Conference on Intelligent Robots and Systems  (IROS), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MISCGrasp的体积感知抓取方法，用于解决机器人在抓取形状和大小各异的物体时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;机器人在抓取物体时面临适应不同形状和大小的困难。&lt;h4&gt;目的&lt;/h4&gt;设计MISCGrasp方法，以实现自适应抓取。&lt;h4&gt;方法&lt;/h4&gt;MISCGrasp通过集成多尺度特征提取与对比特征增强来提高抓取能力。它使用Insight Transformer进行高级和低级特征之间的查询式交互，同时使用Empower Transformer选择性关注高级特征，以平衡关注细微几何细节和整体几何结构。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界环境中进行的广泛实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。&lt;h4&gt;结论&lt;/h4&gt;MISCGrasp方法能够有效地提高机器人抓取的适应性，在处理不同形状和大小的物体时表现出色。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为MISCGrasp的体积感知抓取方法，该方法集成了多尺度特征提取与对比特征增强，用于自适应抓取。我们提出了一种基于查询的高级和低级特征之间的交互，并通过Insight Transformer实现。同时，Empower Transformer选择性地关注高级特征，以协同平衡对细微几何细节和整体几何结构的关注。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征的一致性。在模拟和真实世界环境中的广泛实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。更多信息可在https://miscgrasp.github.io/查看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic grasping faces challenges in adapting to objects with varying shapesand sizes. In this paper, we introduce MISCGrasp, a volumetric grasping methodthat integrates multi-scale feature extraction with contrastive featureenhancement for self-adaptive grasping. We propose a query-based interactionbetween high-level and low-level features through the Insight Transformer,while the Empower Transformer selectively attends to the highest-levelfeatures, which synergistically strikes a balance between focusing on finegeometric details and overall geometric structures. Furthermore, MISCGrasputilizes multi-scale contrastive learning to exploit similarities amongpositive grasp samples, ensuring consistency across multi-scale features.Extensive experiments in both simulated and real-world environments demonstratethat MISCGrasp outperforms baseline and variant methods in tabletopdecluttering tasks. More details are available at https://miscgrasp.github.io/.</description>
      <author>example@mail.com (Qingyu Fan, Yinghao Cai, Chao Li, Chunting Jiao, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang)</author>
      <guid isPermaLink="false">2507.02672v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>S2FGL: Spatial Spectral Federated Graph Learning</title>
      <link>http://arxiv.org/abs/2507.02409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为S2FGL的联邦图学习框架，该框架结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）的强大图建模能力，并解决了子图联邦学习（subgraph-FL）中存在的空间和频谱域问题。&lt;h4&gt;背景&lt;/h4&gt;当前研究主要从结构视角处理子图联邦学习，忽略了结构在空间和频谱域上的图信号传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种方法来减轻标签信号中断和解决频谱客户端漂移。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种全局知识库来减轻标签信号中断，以及一种频率对齐来解决频谱客户端漂移。S2FGL框架结合了空间和频谱策略。&lt;h4&gt;主要发现&lt;/h4&gt;S2FGL在多个数据集上的实验表明，该方法优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;S2FGL框架能够有效解决子图联邦学习中的空间和频谱域问题，提高全局泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) combines the privacy-preserving capabilitiesof federated learning (FL) with the strong graph modeling capability of GraphNeural Networks (GNNs). Current research addresses subgraph-FL only from thestructural perspective, neglecting the propagation of graph signals on spatialand spectral domains of the structure. From a spatial perspective, subgraph-FLintroduces edge disconnections between clients, leading to disruptions in labelsignals and a degradation in the class knowledge of the global GNN. From aspectral perspective, spectral heterogeneity causes inconsistencies in signalfrequencies across subgraphs, which makes local GNNs overfit the local signalpropagation schemes. As a result, spectral client drifts occur, underminingglobal generalizability. To tackle the challenges, we propose a globalknowledge repository to mitigate label signal disruption and a frequencyalignment to address spectral client drifts. The combination of spatial andspectral strategies forms our framework S2FGL. Extensive experiments onmultiple datasets demonstrate the superiority of S2FGL. The code is availableat https://github.com/Wonder7racer/S2FGL.git.</description>
      <author>example@mail.com (Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye)</author>
      <guid isPermaLink="false">2507.02409v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy</title>
      <link>http://arxiv.org/abs/2507.02493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于监督对比损失的结肠镜自动息肉计数方法，该方法结合了时间感知软目标，提高了息肉计数的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;自动息肉计数在结肠镜检查中是自动报告和质量控制的关键步骤，旨在提高结肠镜筛查的成本效益。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的息肉计数方法，以减少现有方法在息肉特征学习和聚类阶段忽略时间关系的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一种监督对比损失，结合时间感知软目标，同时整合时间相邻约束以改进轨迹聚类。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法将碎片化率降低了2.2倍，证明了时间感知在息肉计数中的重要性。&lt;h4&gt;结论&lt;/h4&gt;该方法在息肉计数中建立了新的标准，证明了时间感知在提高息肉计数准确度方面的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at https://github.com/lparolari/temporally-aware-polyp-counting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated polyp counting in colonoscopy is a crucial step toward automatedprocedure reporting and quality control, aiming to enhance thecost-effectiveness of colonoscopy screening. Counting polyps in a procedureinvolves detecting and tracking polyps, and then clustering tracklets thatbelong to the same polyp entity. Existing methods for polyp counting rely onself-supervised learning and primarily leverage visual appearance, neglectingtemporal relationships in both tracklet feature learning and clustering stages.In this work, we introduce a paradigm shift by proposing a supervisedcontrastive loss that incorporates temporally-aware soft targets. Our approachcaptures intra-polyp variability while preserving inter-polyp discriminability,leading to more robust clustering. Additionally, we improve tracklet clusteringby integrating a temporal adjacency constraint, reducing false positivere-associations between visually similar but temporally distant tracklets. Wetrain and validate our method on publicly available datasets and evaluate itsperformance with a leave-one-out cross-validation strategy. Results demonstratea 2.2x reduction in fragmentation rate compared to prior approaches. Ourresults highlight the importance of temporal awareness in polyp counting,establishing a new state-of-the-art. Code is available athttps://github.com/lparolari/temporally-aware-polyp-counting.</description>
      <author>example@mail.com (Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi)</author>
      <guid isPermaLink="false">2507.02493v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection</title>
      <link>http://arxiv.org/abs/2507.02454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的弱监督对比学习方案（WeCoL），用于移动红外小目标的检测，以减少对标注的需求。&lt;h4&gt;背景&lt;/h4&gt;移动红外小目标检测面临挑战，因为目标尺寸小且背景对比度弱，目前大多数方法依赖大量手动标注，这既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种弱监督方法来减少标注需求，突破传统的全监督框架。&lt;h4&gt;方法&lt;/h4&gt;基于预训练的segment anything模型（SAM），设计了一种潜在目标挖掘策略，结合目标激活图和多帧能量累积。采用对比学习来提高伪标签的可靠性，并通过计算特征子空间中正负样本的相似性。此外，提出了长短期运动感知学习方案，以同时建模小目标的局部运动模式和全局运动轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在DAUB和ITSDT-15K两个公共数据集上的实验表明，所提出的弱监督方案通常优于早期全监督方法，性能甚至可以超过最先进的全监督方法超过90%。&lt;h4&gt;结论&lt;/h4&gt;WeCoL方案能够有效减少标注需求，提高移动红外小目标检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Different from general object detection, moving infrared small target detection faces huge challenges due to tiny target size and weak background contrast. Currently, most existing methods are fully-supervised, heavily relying on a large number of manual target-wise annotations. However, manually annotating video sequences is often expensive and time-consuming, especially for low-quality infrared frame images. Inspired by general object detection, non-fully supervised strategies (e.g., weakly supervised) are believed to be potential in reducing annotation requirements. To break through traditional fully-supervised frameworks, as the first exploration work, this paper proposes a new weakly-supervised contrastive learning (WeCoL) scheme, only requiring simple target quantity prompts during model training. Specifically, in our scheme, based on the pretrained segment anything model (SAM), a potential target mining strategy is designed to integrate target activation maps and multi-frame energy accumulation. Besides, contrastive learning is adopted to further improve the reliability of pseudo-labels, by calculating the similarity between positive and negative samples in feature subspace. Moreover, we propose a long-short term motion-aware learning scheme to simultaneously model the local motion patterns and global motion trajectory of small targets. The extensive experiments on two public datasets (DAUB and ITSDT-15K) verify that our weakly-supervised scheme could often outperform early fully-supervised methods. Even, its performance could reach over 90% of state-of-the-art (SOTA) fully-supervised ones.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different from general object detection, moving infrared small targetdetection faces huge challenges due to tiny target size and weak backgroundcontrast.Currently, most existing methods are fully-supervised, heavily relyingon a large number of manual target-wise annotations. However, manuallyannotating video sequences is often expensive and time-consuming, especiallyfor low-quality infrared frame images. Inspired by general object detection,non-fully supervised strategies ($e.g.$, weakly supervised) are believed to bepotential in reducing annotation requirements. To break through traditionalfully-supervised frameworks, as the first exploration work, this paper proposesa new weakly-supervised contrastive learning (WeCoL) scheme, only requiressimple target quantity prompts during model training.Specifically, in ourscheme, based on the pretrained segment anything model (SAM), a potentialtarget mining strategy is designed to integrate target activation maps andmulti-frame energy accumulation.Besides, contrastive learning is adopted tofurther improve the reliability of pseudo-labels, by calculating the similaritybetween positive and negative samples in feature subspace.Moreover, we proposea long-short term motion-aware learning scheme to simultaneously model thelocal motion patterns and global motion trajectory of small targets.Theextensive experiments on two public datasets (DAUB and ITSDT-15K) verify thatour weakly-supervised scheme could often outperform early fully-supervisedmethods. Even, its performance could reach over 90\% of state-of-the-art (SOTA)fully-supervised ones.</description>
      <author>example@mail.com (Weiwei Duan, Luping Ji, Shengjia Chen, Sicheng Zhu, Jianghong Huang, Mao Ye)</author>
      <guid isPermaLink="false">2507.02454v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2507.02847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI-25, code is available at  \url{https://github.com/zky04/MvHo-IB}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MvHo-IB的多视图学习框架，用于在fMRI数据中建模高级交互（HOIs），以提高机器学习系统的诊断准确性。&lt;h4&gt;背景&lt;/h4&gt;研究表明，在fMRI数据中建模高级交互可以提高机器学习系统的诊断准确性，但有效提取和利用这些交互仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MvHo-IB框架，旨在通过整合成对交互和高级交互，同时自动压缩任务无关的冗余信息，来提高诊断决策的准确性。&lt;h4&gt;方法&lt;/h4&gt;MvHo-IB框架的主要创新包括：(1) 一种结合信息论中的O信息和基于矩阵的Renyi alpha-order熵估计器的方法，用于量化提取高级交互；(2) 一种专为脑部3DCNN编码设计的编码器，以有效利用这些交互；(3) 一种新的多视图学习信息瓶颈目标，以增强表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;在三个基准fMRI数据集上的实验表明，MvHo-IB实现了最先进的性能，显著优于包括最近基于超图的技术在内的先前方法。&lt;h4&gt;结论&lt;/h4&gt;MvHo-IB框架在提高fMRI数据的机器学习诊断准确性方面具有显著潜力。&lt;h4&gt;翻译&lt;/h4&gt;Recent evidence suggests that modeling higher-order interactions (HOIs) in functional magnetic resonance imaging (fMRI) data can enhance the diagnostic accuracy of machine learning systems. However, effectively extracting and utilizing HOIs remains a significant challenge. In this work, we propose MvHo-IB, a novel multi-view learning framework that integrates both pairwise interactions and HOIs for diagnostic decision-making, while automatically compressing task-irrelevant redundant information. MvHo-IB introduces several key innovations: (1) a principled method that combines O-information from information theory with a matrix-based Renyi alpha-order entropy estimator to quantify and extract HOIs, (2) a purpose-built Brain3DCNN encoder to effectively utilize these interactions, and (3) a new multi-view learning information bottleneck objective to enhance representation learning. Experiments on three benchmark fMRI datasets demonstrate that MvHo-IB achieves state-of-the-art performance, significantly outperforming previous methods, including recent hypergraph-based techniques. The implementation of MvHo-IB is available at https://github.com/zky04/MvHo-IB.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent evidence suggests that modeling higher-order interactions (HOIs) infunctional magnetic resonance imaging (fMRI) data can enhance the diagnosticaccuracy of machine learning systems. However, effectively extracting andutilizing HOIs remains a significant challenge. In this work, we proposeMvHo-IB, a novel multi-view learning framework that integrates both pairwiseinteractions and HOIs for diagnostic decision-making, while automaticallycompressing task-irrelevant redundant information. MvHo-IB introduces severalkey innovations: (1) a principled method that combines O-information frominformation theory with a matrix-based Renyi alpha-order entropy estimator toquantify and extract HOIs, (2) a purpose-built Brain3DCNN encoder toeffectively utilize these interactions, and (3) a new multi-view learninginformation bottleneck objective to enhance representation learning.Experiments on three benchmark fMRI datasets demonstrate that MvHo-IB achievesstate-of-the-art performance, significantly outperforming previous methods,including recent hypergraph-based techniques. The implementation of MvHo-IB isavailable at https://github.com/zky04/MvHo-IB.</description>
      <author>example@mail.com (Kunyu Zhang, Qiang Li, Shujian Yu)</author>
      <guid isPermaLink="false">2507.02847v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Fx-Encoder++: Extracting Instrument-Wise Audio Effects Representations from Mixtures</title>
      <link>http://arxiv.org/abs/2507.02273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Fx-Encoder++的新模型，用于从音乐混音中提取乐器级的音频效果表示，并展示其在音频检索和音频效果参数匹配任务中的优越性。&lt;h4&gt;背景&lt;/h4&gt;通用音频表示在音乐信息检索应用中有效，但在智能音乐制作中由于对音频效果（Fx）理解不足而受限。&lt;h4&gt;目的&lt;/h4&gt;设计Fx-Encoder++模型以解决智能音乐制作系统中音频效果理解的能力差距。&lt;h4&gt;方法&lt;/h4&gt;模型利用对比学习框架，引入一个“提取器”机制，将混音级别的音频效果嵌入转换为乐器级的音频效果嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;Fx-Encoder++在混音级别上优于先前的方法，并展示了提取乐器级效果表示的新能力。&lt;h4&gt;结论&lt;/h4&gt;该模型为智能音乐制作系统提供了一种关键的音频效果理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; General-purpose audio representations have proven effective across diversemusic information retrieval applications, yet their utility in intelligentmusic production remains limited by insufficient understanding of audio effects(Fx). Although previous approaches have emphasized audio effects analysis atthe mixture level, this focus falls short for tasks demanding instrument-wiseaudio effects understanding, such as automatic mixing. In this work, we presentFx-Encoder++, a novel model designed to extract instrument-wise audio effectsrepresentations from music mixtures. Our approach leverages a contrastivelearning framework and introduces an "extractor" mechanism that, when providedwith instrument queries (audio or text), transforms mixture-level audio effectsembeddings into instrument-wise audio effects embeddings. We evaluated ourmodel across retrieval and audio effects parameter matching tasks, testing itsperformance across a diverse range of instruments. The results demonstrate thatFx-Encoder++ outperforms previous approaches at mixture level and show a novelability to extract effects representation instrument-wise, addressing acritical capability gap in intelligent music production systems.</description>
      <author>example@mail.com (Yen-Tung Yeh, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Yi-Hsuan Yang, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2507.02273v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2507.02666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种改进的音频自监督表征学习方法，该方法的注意力机制能够有效分配注意力权重，提高了模型在音频任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;当前音频自监督表征学习的研究中，标准Transformer架构占主导地位，但其注意力机制容易将权重分配给无关信息，影响模型的区分能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种差分注意力机制，通过集成双softmax操作和适当调整的差分系数来有效减轻无效注意力分配的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为ASDA（Adaptive Differential Attention）的模型，该模型结合了双softmax操作和差分系数，以优化注意力分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ASDA模型在多个基准测试中达到了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。&lt;h4&gt;结论&lt;/h4&gt;ASDA模型在音频任务中的有效性得到验证，为更广泛的应用开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;在音频自监督表征学习的最近进展中，标准的Transformer架构已成为主导方法，但其注意力机制通常将一部分注意力权重分配给无关信息，可能会损害模型的区分能力。为了解决这个问题，我们提出了一种差分注意力机制，通过集成双softmax操作和适当调整的差分系数有效地减轻了无效的注意力分配。实验结果表明，我们的ASDA模型在多个基准上实现了最先进的性能，包括音频分类（AS-2M上的49.0% mAP，AS20K上的41.5% mAP）、关键词检测（SPC-2上的98.3%准确率）和环境声音分类（ESC-50上的96.1%准确率）。这些结果突出了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent advancements in audio self-supervised representation learning, thestandard Transformer architecture has emerged as the predominant approach, yetits attention mechanism often allocates a portion of attention weights toirrelevant information, potentially impairing the model's discriminativeability. To address this, we introduce a differential attention mechanism,which effectively mitigates ineffective attention allocation through theintegration of dual-softmax operations and appropriately tuned differentialcoefficients. Experimental results demonstrate that our ASDA model achievesstate-of-the-art (SOTA) performance across multiple benchmarks, including audioclassification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting(98.3% accuracy on SPC-2), and environmental sound classification (96.1%accuracy on ESC-50). These results highlight ASDA's effectiveness in audiotasks, paving the way for broader applications.</description>
      <author>example@mail.com (Junyu Wang, Tianrui Wang, Meng Ge, Longbiao Wang, Jianwu Dang)</author>
      <guid isPermaLink="false">2507.02666v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AnyI2V: Animating Any Conditional Image with Motion Control</title>
      <link>http://arxiv.org/abs/2507.02857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025, Project Page: https://henghuiding.com/AnyI2V/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnyI2V的训练免费框架，用于动画化任何条件图像，并通过用户定义的运动轨迹实现动画。该框架支持多种模态，包括网格和点云等数据类型，并支持混合条件输入、风格迁移和编辑。&lt;h4&gt;背景&lt;/h4&gt;视频生成领域，尤其是扩散模型，在文本到视频（T2V）和图像到视频（I2V）合成方面取得了显著进展。然而，现有方法在动态运动信号和灵活的空间约束集成方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的局限性，旨在提出一种新的视频生成方法，能够提供更精确的空间和运动控制。&lt;h4&gt;方法&lt;/h4&gt;AnyI2V框架通过用户定义的运动轨迹来动画化任何条件图像，支持更广泛的模态，如网格和点云，同时支持混合条件输入和通过LoRA和文本提示进行风格迁移和编辑。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AnyI2V在视频生成性能上优于现有方法，为空间和运动控制视频生成提供了新的视角。&lt;h4&gt;结论&lt;/h4&gt;AnyI2V是一个创新的视频生成框架，它通过提供更灵活和多样化的功能，为视频合成领域带来了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in video generation, particularly in diffusion models, have driven notable progress in text-to-video (T2V) and image-to-video (I2V) synthesis. However, challenges remain in effectively integrating dynamic motion signals and flexible spatial constraints. Existing T2V methods typically rely on text prompts, which inherently lack precise control over the spatial layout of generated content. In contrast, I2V methods are limited by their dependence on real images, which restricts the editability of the synthesized content. Although some methods incorporate ControlNet to introduce image-based conditioning, they often lack explicit motion control and require computationally expensive training. To address these limitations, we propose AnyI2V, a training-free framework that animates any conditional images with user-defined motion trajectories. AnyI2V supports a broader range of modalities as the conditional image, including data types such as meshes and point clouds that are not supported by ControlNet, enabling more flexible and versatile video generation. Additionally, it supports mixed conditional inputs and enables style transfer and editing via LoRA and text prompts. Extensive experiments demonstrate that the proposed AnyI2V achieves superior performance and provides a new perspective in spatial- and motion-controlled video generation. Code is available at https://henghuiding.com/AnyI2V/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in video generation, particularly in diffusion models,have driven notable progress in text-to-video (T2V) and image-to-video (I2V)synthesis. However, challenges remain in effectively integrating dynamic motionsignals and flexible spatial constraints. Existing T2V methods typically relyon text prompts, which inherently lack precise control over the spatial layoutof generated content. In contrast, I2V methods are limited by their dependenceon real images, which restricts the editability of the synthesized content.Although some methods incorporate ControlNet to introduce image-basedconditioning, they often lack explicit motion control and requirecomputationally expensive training. To address these limitations, we proposeAnyI2V, a training-free framework that animates any conditional images withuser-defined motion trajectories. AnyI2V supports a broader range of modalitiesas the conditional image, including data types such as meshes and point cloudsthat are not supported by ControlNet, enabling more flexible and versatilevideo generation. Additionally, it supports mixed conditional inputs andenables style transfer and editing via LoRA and text prompts. Extensiveexperiments demonstrate that the proposed AnyI2V achieves superior performanceand provides a new perspective in spatial- and motion-controlled videogeneration. Code is available at https://henghuiding.com/AnyI2V/.</description>
      <author>example@mail.com (Ziye Li, Hao Luo, Xincheng Shuai, Henghui Ding)</author>
      <guid isPermaLink="false">2507.02857v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>RoboBrain 2.0 Technical Report</title>
      <link>http://arxiv.org/abs/2507.02029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RoboBrain 2.0，这是新一代的具身视觉-语言基础模型，旨在统一感知、推理和规划，以应对物理环境中的复杂具身任务。&lt;h4&gt;背景&lt;/h4&gt;RoboBrain 2.0有两种变体：一个轻量级的7B模型和一个全规模的32B模型，具有异构架构，包括视觉编码器和语言模型。&lt;h4&gt;目的&lt;/h4&gt;通过RoboBrain 2.0，旨在推进具身人工智能研究，并作为构建通用具身智能体的实际步骤。&lt;h4&gt;方法&lt;/h4&gt;详细描述了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;32B变体在空间和时间基准测试中取得了领先结果，超过了先前开源和专有模型。它支持空间理解（如可及性预测、空间指称、轨迹预测）和时序决策（如闭环交互、多智能体长期规划、场景图更新）等关键真实世界具身人工智能能力。&lt;h4&gt;结论&lt;/h4&gt;RoboBrain 2.0在广泛的具身推理任务上实现了强大的性能，为具身人工智能研究提供了新的进展。&lt;h4&gt;翻译&lt;/h4&gt;We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: a lightweight 7B model and a full-scale 32B model, featuring a heterogeneous architecture with a vision encoder and a language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across a wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent long-horizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as a practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce RoboBrain 2.0, our latest generation of embodied vision-languagefoundation models, designed to unify perception, reasoning, and planning forcomplex embodied tasks in physical environments. It comes in two variants: alightweight 7B model and a full-scale 32B model, featuring a heterogeneousarchitecture with a vision encoder and a language model. Despite its compactsize, RoboBrain 2.0 achieves strong performance across a wide spectrum ofembodied reasoning tasks. On both spatial and temporal benchmarks, the 32Bvariant achieves leading results, surpassing prior open-source and proprietarymodels. In particular, it supports key real-world embodied AI capabilities,including spatial understanding (e.g., affordance prediction, spatialreferring, trajectory forecasting) and temporal decision-making (e.g.,closed-loop interaction, multi-agent long-horizon planning, and scene graphupdating). This report details the model architecture, data construction,multi-stage training strategies, infrastructure and practical applications. Wehope RoboBrain 2.0 advances embodied AI research and serves as a practical steptoward building generalist embodied agents. The code, checkpoint and benchmarkare available at https://superrobobrain.github.io.</description>
      <author>example@mail.com (BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Shanyu Rong, Zhengliang Cai, Bolun Zhang, Shuyi Zhang, Huaihai Lyu, Mengfei Du, Lingfeng Zhang, Xi Feng, Xiaodan Liu, Yance Jiao, Chenrui He, Mengsi Lyu, Zhuo Chen, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.02029v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Variational Kolmogorov-Arnold Network</title>
      <link>http://arxiv.org/abs/2507.02466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A preliminary (short paper) version presented at ComBayNS Workshop at  IJCNN'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为InfinityKAN的新型机器学习模型架构，该架构基于Kolmogorov-Arnold定理及其扩展，通过自适应学习无限数量的基函数来构建多变量连续有界函数的精确表示。&lt;h4&gt;背景&lt;/h4&gt;Kolmogorov Arnold Networks (KANs)是一种新兴的机器学习模型架构，其理论基础为Kolmogorov-Arnold定理及其扩展，这些理论能够将多变量连续有界函数精确表示为有限个一元连续函数的组合。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过自适应学习无限数量的基函数来解决问题，即在使用KANs时如何选择每个一元函数的基函数数量。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为一个变分推理优化问题，并提出了InfinityKAN方法，该方法使用反向传播来扩展KANs的应用范围，将重要的超参数视为学习过程的一部分。&lt;h4&gt;主要发现&lt;/h4&gt;InfinityKAN方法能够自适应地学习无限数量的基函数，从而提高了KANs在构建多变量连续有界函数表示时的精确性和适用性。&lt;h4&gt;结论&lt;/h4&gt;InfinityKAN方法通过优化学习过程，扩展了KANs的应用范围，为机器学习模型构建提供了一种新的选择。&lt;h4&gt;翻译&lt;/h4&gt;Kolmogorov Arnold Networks (KANs) 是一种新兴的机器学习模型架构。基于 Kolmogorov-Arnold 定理及其扩展的理论基础，它能够将多变量连续有界函数精确表示为有限个一元连续函数的组合。虽然这些理论结果非常强大，但将它们作为多层感知器 (MLP) 的替代品用于表示学习时，其使用取决于对每个一元函数建模的基函数数量的随意选择。在这项工作中，我们展示了如何通过在训练过程中自适应地学习每个一元函数的潜在无限数量的基函数来解决此问题。因此，我们将问题建模为一个变分推理优化问题。我们提出的名为 InfinityKAN 的方法，使用反向传播，通过将一个重要的超参数视为学习过程的一部分，扩展了 KANs 的潜在适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov Arnold Networks (KANs) are an emerging architecture for buildingmachine learning models. KANs are based on the theoretical foundation of theKolmogorov-Arnold Theorem and its expansions, which provide an exactrepresentation of a multi-variate continuous bounded function as thecomposition of a limited number of univariate continuous functions. While suchtheoretical results are powerful, their use as a representation learningalternative to a multi-layer perceptron (MLP) hinges on the ad-hoc choice ofthe number of bases modeling each of the univariate functions. In this work, weshow how to address this problem by adaptively learning a potentially infinitenumber of bases for each univariate function during training. We thereforemodel the problem as a variational inference optimization problem. Ourproposal, called InfinityKAN, which uses backpropagation, extends the potentialapplicability of KANs by treating an important hyperparameter as part of thelearning process.</description>
      <author>example@mail.com (Francesco Alesiani, Henrik Christiansen, Federico Errica)</author>
      <guid isPermaLink="false">2507.02466v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2507.01961v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://ac-dit.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AC-DiT的适应性协调扩散变换器，用于增强移动基础和操作器的协调，以实现端到端的移动操作。&lt;h4&gt;背景&lt;/h4&gt;移动操作在家庭任务中实现语言条件下的机器人控制受到越来越多的关注，但现有的方法在协调移动基础和操作器方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在协调移动基础和操作器时的问题，提出了AC-DiT。&lt;h4&gt;方法&lt;/h4&gt;AC-DiT通过引入移动性到身体条件机制，首先提取基础运动表示，并将其用作预测全身动作的上下文先验，从而实现考虑移动基础运动影响的全身控制。此外，为了满足移动操作不同阶段的感知需求，设计了感知感知的多模态条件策略，动态调整不同2D视觉图像和3D点云之间的融合权重，以提供符合当前感知需求的视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;AC-DiT通过实验在模拟和真实世界的移动操作任务中得到了验证。&lt;h4&gt;结论&lt;/h4&gt;AC-DiT通过提高移动基础和操作器的协调能力，为移动操作提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，移动操作因其在家庭任务中实现语言条件下的机器人控制而受到越来越多的关注。然而，现有的方法在协调移动基础和操作器方面仍面临挑战，这主要是由于两个限制。一方面，它们未能明确建模移动基础对操作器控制的影响，这容易在高自由度下导致误差累积。另一方面，它们以相同的视觉观察模式（例如，要么全部是2D，要么全部是3D）处理整个移动操作过程，忽略了移动操作不同阶段的多模态感知需求。为了解决这个问题，我们提出了适应性协调扩散变换器（AC-DiT），它增强了移动基础和操作器的端到端移动操作协调。首先，由于移动基座的运动直接影响操作器的动作，我们引入了一种移动性到身体条件机制，引导模型首先提取基座运动表示，然后将其用作预测全身动作的上下文先验。这使全身控制能够考虑到移动基座运动的影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件策略，动态调整各种2D视觉图像和3D点云之间的融合权重，从而产生符合当前感知需求的视觉特征。这使得模型能够，例如，在语义信息对动作预测至关重要时，自适应地更多地依赖2D输入，而在需要精确空间理解时，则更加重视3D几何信息。我们通过在模拟和真实世界的移动操作任务上的大量实验验证了AC-DiT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, mobile manipulation has attracted increasing attention for enablinglanguage-conditioned robotic control in household tasks. However, existingmethods still face challenges in coordinating mobile base and manipulator,primarily due to two limitations. On the one hand, they fail to explicitlymodel the influence of the mobile base on manipulator control, which easilyleads to error accumulation under high degrees of freedom. On the other hand,they treat the entire mobile manipulation process with the same visualobservation modality (e.g., either all 2D or all 3D), overlooking the distinctmultimodal perception requirements at different stages during mobilemanipulation. To address this, we propose the Adaptive Coordination DiffusionTransformer (AC-DiT), which enhances mobile base and manipulator coordinationfor end-to-end mobile manipulation. First, since the motion of the mobile basedirectly influences the manipulator's actions, we introduce a mobility-to-bodyconditioning mechanism that guides the model to first extract base motionrepresentations, which are then used as context prior for predicting whole-bodyactions. This enables whole-body control that accounts for the potential impactof the mobile base's motion. Second, to meet the perception requirements atdifferent stages of mobile manipulation, we design a perception-awaremultimodal conditioning strategy that dynamically adjusts the fusion weightsbetween various 2D visual images and 3D point clouds, yielding visual featurestailored to the current perceptual needs. This allows the model to, forexample, adaptively rely more on 2D inputs when semantic information is crucialfor action prediction, while placing greater emphasis on 3D geometricinformation when precise spatial understanding is required. We validate AC-DiTthrough extensive experiments on both simulated and real-world mobilemanipulation tasks.</description>
      <author>example@mail.com (Sixiang Chen, Jiaming Liu, Siyuan Qian, Han Jiang, Lily Li, Renrui Zhang, Zhuoyang Liu, Chenyang Gu, Chengkai Hou, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.01961v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction</title>
      <link>http://arxiv.org/abs/2507.02018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对金融应用中图表示学习方法面临的挑战，提出了一种新的股票预测任务和Node-level GraphAttention Network模型。&lt;h4&gt;背景&lt;/h4&gt;图表示学习方法在金融应用中广泛应用，但现有方法存在三个主要问题：关系信息优势被下游任务设计限制、图模型复杂度高且泛化能力差、企业关系图构建缺乏有效比较。&lt;h4&gt;目的&lt;/h4&gt;提出长期股票预测任务，开发适用于企业关系图的Node-level GraphAttention Network模型，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;设计长期股票预测任务，开发NGAT模型，并通过实验验证模型的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的任务和模型在两个数据集上均表现出有效性，并揭示了现有图比较方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的模型和方法能够有效提高金融应用中图表示学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level GraphAttention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning methods have been widely adopted in financialapplications to enhance company representations by leveraging inter-firmrelationships. However, current approaches face three key challenges: (1) Theadvantages of relational information are obscured by limitations in downstreamtask designs; (2) Existing graph models specifically designed for stockprediction often suffer from excessive complexity and poor generalization; (3)Experience-based construction of corporate relationship graphs lacks effectivecomparison of different graph structures. To address these limitations, wepropose a long-term stock prediction task and develop a Node-level GraphAttention Network (NGAT) specifically tailored for corporate relationshipgraphs. Furthermore, we experimentally demonstrate the limitations of existinggraph comparison methods based on model downstream task performance.Experimental results across two datasets consistently demonstrate theeffectiveness of our proposed task and model. The project is publicly availableon GitHub to encourage reproducibility and future research.</description>
      <author>example@mail.com (Yingjie Niu, Mingchuan Zhao, Valerio Poti, Ruihai Dong)</author>
      <guid isPermaLink="false">2507.02018v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans</title>
      <link>http://arxiv.org/abs/2507.02861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://litereality.github.io; Video:  https://www.youtube.com/watch?v=ecK9m3LXg2c&amp;feature=youtu.be&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LiteReality，一个将室内环境的RGB-D扫描转换为紧凑、逼真和交互式3D虚拟副本的新方法。&lt;h4&gt;背景&lt;/h4&gt;现有的方法无法完全重建场景，且不支持图形管线的关键特性。&lt;h4&gt;目的&lt;/h4&gt;创建一个能够重建视觉上类似现实的场景，并支持对象个性、关节、高质量基于物理的渲染材料和基于物理的交互。&lt;h4&gt;方法&lt;/h4&gt;LiteReality首先通过结构化场景图理解场景并解析为一致的3D布局和对象，然后从精选的资产数据库中检索最相似的3D艺术家模型来重建场景。Material Painting模块通过恢复高质量的、空间变化的材料来增强逼真度。最后，重建的场景被集成到一个具有基本物理属性的模拟引擎中，以实现交互行为。&lt;h4&gt;主要发现&lt;/h4&gt;LiteReality引入了一个无需训练的对象检索模块，在Scan2CAD基准测试上实现了最先进的相似度性能，并具有一个强大的材料绘制模块，能够将任何风格的图像外观转移到3D资产上，即使在严重的错位、遮挡和不良光照下。&lt;h4&gt;结论&lt;/h4&gt;LiteReality生成的场景紧凑、可编辑，完全兼容标准图形管线，适用于AR/VR、游戏、机器人和数字孪生等应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose LiteReality, a novel pipeline that converts RGB-D scans of indoorenvironments into compact, realistic, and interactive 3D virtual replicas.LiteReality not only reconstructs scenes that visually resemble reality butalso supports key features essential for graphics pipelines -- such as objectindividuality, articulation, high-quality physically based rendering materials,and physically based interaction. At its core, LiteReality first performs sceneunderstanding and parses the results into a coherent 3D layout and objects withthe help of a structured scene graph. It then reconstructs the scene byretrieving the most visually similar 3D artist-crafted models from a curatedasset database. Next, the Material Painting module enhances realism byrecovering high-quality, spatially varying materials. Finally, thereconstructed scene is integrated into a simulation engine with basic physicalproperties to enable interactive behavior. The resulting scenes are compact,editable, and fully compatible with standard graphics pipelines, making themsuitable for applications in AR/VR, gaming, robotics, and digital twins. Inaddition, LiteReality introduces a training-free object retrieval module thatachieves state-of-the-art similarity performance on the Scan2CAD benchmark,along with a robust material painting module capable of transferringappearances from images of any style to 3D assets -- even under severemisalignment, occlusion, and poor lighting. We demonstrate the effectiveness ofLiteReality on both real-life scans and public datasets. Project page:https://litereality.github.io; Video:https://www.youtube.com/watch?v=ecK9m3LXg2c</description>
      <author>example@mail.com (Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nießner, Joan Lasenby)</author>
      <guid isPermaLink="false">2507.02861v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion</title>
      <link>http://arxiv.org/abs/2507.02813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://liuff19.github.io/LangScene-X&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LangScene-X的新型生成框架，用于从2D图像中恢复3D结构，并通过嵌入语言信息实现开放词汇场景理解。&lt;h4&gt;背景&lt;/h4&gt;从2D图像恢复3D结构是一个基本但具有挑战性的任务。现有的方法依赖于校准的密集视图重建范式，当视图有限时，容易产生严重的渲染伪影和不合理的语义合成。&lt;h4&gt;目的&lt;/h4&gt;旨在通过统一的生成框架生成3D一致的多种模态信息，以实现重建和理解。&lt;h4&gt;方法&lt;/h4&gt;1. 训练一个TriMap视频扩散模型，可以从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。2. 提出一种语言量化压缩器（LQC），用于高效编码语言嵌入，实现跨场景泛化，无需针对每个场景重新训练。3. 通过将语言信息对齐到3D场景的表面来重建语言表面场。&lt;h4&gt;主要发现&lt;/h4&gt;LangScene-X在真实世界数据上的实验表明，其在质量和泛化能力方面优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;LangScene-X框架能够有效地从稀疏视图中构建可泛化的3D语言嵌入场景，为开放式的语言查询提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用开放词汇场景理解从2D图像恢复3D结构是一项基本但令人畏惧的任务。最近的发展通过执行每个场景的嵌入语言信息优化来实现这一点。然而，它们严重依赖于校准的密集视图重建范式，因此在视图有限时，会遭受严重的渲染伪影和不合理的语义合成。在本文中，我们介绍了一种新的生成框架，称为LangScene-X，以统一和生成用于重建和理解的3D一致的多模态信息。借助创建更一致的新观察结果的能力，我们可以仅从稀疏视图中构建可泛化的3D语言嵌入场景。具体来说，我们首先训练了一个TriMap视频扩散模型，该模型可以通过渐进式知识集成从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出了一种基于大规模图像数据集训练的语言量化压缩器（LQC），以有效地编码语言嵌入，实现跨场景泛化，无需针对每个场景重新训练。最后，我们通过将语言信息对齐到3D场景的表面来重建语言表面场，从而实现开放式的语言查询。在真实世界数据上的大量实验表明，我们的LangScene-X在质量和泛化能力方面优于最先进的方法。项目页面：https://liuff19.github.io/LangScene-X。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering 3D structures with open-vocabulary scene understanding from 2Dimages is a fundamental but daunting task. Recent developments have achievedthis by performing per-scene optimization with embedded language information.However, they heavily rely on the calibrated dense-view reconstructionparadigm, thereby suffering from severe rendering artifacts and implausiblesemantic synthesis when limited views are available. In this paper, weintroduce a novel generative framework, coined LangScene-X, to unify andgenerate 3D consistent multi-modality information for reconstruction andunderstanding. Powered by the generative capability of creating more consistentnovel observations, we can build generalizable 3D language-embedded scenes fromonly sparse views. Specifically, we first train a TriMap video diffusion modelthat can generate appearance (RGBs), geometry (normals), and semantics(segmentation maps) from sparse inputs through progressive knowledgeintegration. Furthermore, we propose a Language Quantized Compressor (LQC),trained on large-scale image datasets, to efficiently encode languageembeddings, enabling cross-scene generalization without per-scene retraining.Finally, we reconstruct the language surface fields by aligning languageinformation onto the surface of 3D scenes, enabling open-ended languagequeries. Extensive experiments on real-world data demonstrate the superiorityof our LangScene-X over state-of-the-art methods in terms of quality andgeneralizability. Project Page: https://liuff19.github.io/LangScene-X.</description>
      <author>example@mail.com (Fangfu Liu, Hao Li, Jiawei Chi, Hanyang Wang, Minghui Yang, Fudong Wang, Yueqi Duan)</author>
      <guid isPermaLink="false">2507.02813v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings</title>
      <link>http://arxiv.org/abs/2507.02403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Xplore and ISIF FUSION 2025  proceedings:&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了野生动物再识别中的自监督学习方法，通过自监督学习模型提高了野生动物再识别的鲁棒性和性能。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的野生动物再识别模型依赖于标注数据进行监督学习，这促使了大量大规模野生动物数据集的创建。&lt;h4&gt;目的&lt;/h4&gt;探索自监督学习方法在野生动物再识别中的应用，以减少对标注数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;使用相机陷阱数据中的时间图像对自动提取个体的两个不同视图，并在不监督的情况下训练自监督模型，该模型可以从视频数据流中不断学习。&lt;h4&gt;主要发现&lt;/h4&gt;自监督模型在有限数据的情况下表现出更强的鲁棒性，并且在所有下游任务中，自监督特征的表现优于监督特征。&lt;h4&gt;结论&lt;/h4&gt;自监督学习在野生动物再识别中具有潜力，可以减少对标注数据的依赖，并提高模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：野生动物重识别旨在匹配不同观察中同一物种的个体。当前最先进的（SOTA）模型依赖于类别标签来训练监督模型以进行个体分类。这种对标注数据的依赖促使了众多大规模野生动物数据集的整理。本研究调查了自监督学习（SSL）在野生动物重识别中的应用。我们使用相机陷阱数据中的时间图像对自动提取个体的两个不同视图，在不监督的情况下训练自监督模型。这些图像对从可能无限的视频数据流中训练自监督模型。我们评估了学习到的表示与开放世界场景和多种野生动物下游任务中的监督特征。实验结果的分析表明，自监督模型即使在有限数据的情况下也更具鲁棒性。此外，自监督特征在所有下游任务中都优于监督特征。代码可在以下链接获得：https://github.com/pxpana/SSLWildlife。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wildlife re-identification aims to match individuals of the same speciesacross different observations. Current state-of-the-art (SOTA) models rely onclass labels to train supervised models for individual classification. Thisdependence on annotated data has driven the curation of numerous large-scalewildlife datasets. This study investigates self-supervised learningSelf-Supervised Learning (SSL) for wildlife re-identification. We automaticallyextract two distinct views of an individual using temporal image pairs fromcamera trap data without supervision. The image pairs train a self-supervisedmodel from a potentially endless stream of video data. We evaluate the learntrepresentations against supervised features on open-world scenarios andtransfer learning in various wildlife downstream tasks. The analysis of theexperimental results shows that self-supervised models are more robust evenwith limited data. Moreover, self-supervised features outperform supervisionacross all downstream tasks. The code is available herehttps://github.com/pxpana/SSLWildlife.</description>
      <author>example@mail.com (Mufhumudzi Muthivhi, Terence L. van Zyl)</author>
      <guid isPermaLink="false">2507.02403v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment</title>
      <link>http://arxiv.org/abs/2507.02705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SIU3R的无对齐框架，用于从无姿态图像中进行通用的同时理解和3D重建。&lt;h4&gt;背景&lt;/h4&gt;现有的2D到3D特征对齐方法限制了3D理解能力并可能导致语义信息损失。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个无对齐框架，能够同时进行理解和3D重建，且不依赖于2D模型的对齐。&lt;h4&gt;方法&lt;/h4&gt;SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多个理解任务统一为一系列可学习的查询，从而实现原生3D理解。此外，论文还提出了两个轻量级模块以促进两个任务之间的协作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在3D重建和理解以及同时理解和3D重建任务上均达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SIU3R框架的优势在于其无对齐特性以及通过模块设计实现的任务间协作效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new alignment-free framework named SIU3R for generalizable simultaneous understanding and 3D reconstruction from unposed images. The background is that the existing 2D-to-3D feature alignment methods limit the 3D understanding capability and may lead to the loss of semantic information. The purpose is to develop an alignment-free framework that can perform simultaneous understanding and 3D reconstruction without relying on alignment with 2D models. The method uses pixel-aligned 3D representation to bridge the reconstruction and understanding tasks, and unifies multiple understanding tasks into a set of unified learnable queries, thereby achieving native 3D understanding. In addition, two lightweight modules are proposed to facilitate the interaction between the two tasks. Extensive experiments demonstrate that the method achieves state-of-the-art performance on both individual tasks of 3D reconstruction and understanding, as well as on the task of simultaneous understanding and 3D reconstruction, highlighting the advantages of the alignment-free framework and the effectiveness of the mutual benefit design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous understanding and 3D reconstruction plays an important role indeveloping end-to-end embodied intelligent systems. To achieve this, recentapproaches resort to 2D-to-3D feature alignment paradigm, which leads tolimited 3D understanding capability and potential semantic information loss. Inlight of this, we propose SIU3R, the first alignment-free framework forgeneralizable simultaneous understanding and 3D reconstruction from unposedimages. Specifically, SIU3R bridges reconstruction and understanding tasks viapixel-aligned 3D representation, and unifies multiple understanding tasks intoa set of unified learnable queries, enabling native 3D understanding withoutthe need of alignment with 2D models. To encourage collaboration between thetwo tasks with shared representation, we further conduct in-depth analyses oftheir mutual benefits, and propose two lightweight modules to facilitate theirinteraction. Extensive experiments demonstrate that our method achievesstate-of-the-art performance not only on the individual tasks of 3Dreconstruction and understanding, but also on the task of simultaneousunderstanding and 3D reconstruction, highlighting the advantages of ouralignment-free framework and the effectiveness of the mutual benefit designs.</description>
      <author>example@mail.com (Qi Xu, Dongxu Wei, Lingzhe Zhao, Wenpu Li, Zhangchi Huang, Shunping Ji, Peidong Liu)</author>
      <guid isPermaLink="false">2507.02705v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Grounding Intelligence in Movement</title>
      <link>http://arxiv.org/abs/2507.02771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在语言、视觉等高维数据处理方面取得了显著进步，但在运动建模方面仍存在挑战。运动对于神经科学、医学、机器人和动物行为学至关重要，但通常被忽视。本文提出运动应该作为人工智能建模的主要目标。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在语言、视觉数据处理方面取得了显著进步，但在运动建模方面仍然存在挑战。运动对于多种领域至关重要，但目前对运动数据的收集和建模存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出运动作为人工智能建模的主要目标，并强调其结构性和基于实体的特点。&lt;h4&gt;方法&lt;/h4&gt;分析运动数据的结构和特点，讨论其在不同领域中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;运动反映了共享的物理约束、保守的形态结构和跨物种的动态，具有内在的结构和基于实体的特性。&lt;h4&gt;结论&lt;/h4&gt;发展能够从多样化的运动数据中学习和推广的模型，不仅会推进生成模型和控制的核心能力，而且为理解生物和人工系统中的行为提供共同的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in machine learning have dramatically improved our ability tomodel language, vision, and other high-dimensional data, yet they continue tostruggle with one of the most fundamental aspects of biological systems:movement. Across neuroscience, medicine, robotics, and ethology, movement isessential for interpreting behavior, predicting intent, and enablinginteraction. Despite its core significance in our intelligence, movement isoften treated as an afterthought rather than as a rich and structured modalityin its own right. This reflects a deeper fragmentation in how movement data iscollected and modeled, often constrained by task-specific goals anddomain-specific assumptions. But movement is not domain-bound. It reflectsshared physical constraints, conserved morphological structures, and purposefuldynamics that cut across species and settings. We argue that movement should betreated as a primary modeling target for AI. It is inherently structured andgrounded in embodiment and physics. This structure, often allowing for compact,lower-dimensional representations (e.g., pose), makes it more interpretable andcomputationally tractable to model than raw, high-dimensional sensory inputs.Developing models that can learn from and generalize across diverse movementdata will not only advance core capabilities in generative modeling andcontrol, but also create a shared foundation for understanding behavior acrossbiological and artificial systems. Movement is not just an outcome, it is awindow into how intelligent systems engage with the world.</description>
      <author>example@mail.com (Melanie Segado, Felipe Parodi, Jordan K. Matelsky, Michael L. Platt, Eva B. Dyer, Konrad P. Kording)</author>
      <guid isPermaLink="false">2507.02771v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach</title>
      <link>http://arxiv.org/abs/2507.02205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的零样本多模态方法，用于复合情感识别（CER），该方法结合了六种异构模态，包括静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。&lt;h4&gt;背景&lt;/h4&gt;复合情感识别（CER）是情感计算的一个子领域，旨在检测由基本情感组合而成的复杂情感状态。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的零样本多模态方法，用于复合情感识别（CER），以捕捉复杂情感状态。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了六种异构模态，使用零样本组件，包括基于CLIP的标签匹配和Qwen-VL进行语义场景理解，并引入了多头概率融合（MHPF）模块和复合表达式（CE）转换模块，后者使用成对概率聚合（PPA）和成对特征相似度聚合（PFSA）方法产生可解释的复合情感输出。&lt;h4&gt;主要发现&lt;/h4&gt;在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，通过零样本测试，与在目标数据上训练的监督方法的结果相当。&lt;h4&gt;结论&lt;/h4&gt;该方法在无需领域自适应的情况下捕捉复合情感（CE）是有效的，并且源代码是公开的。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes a novel zero-shot multimodal approach for Compound Expression Recognition (CER) that combines six heterogeneous modalities into a single pipeline: static and dynamic facial expressions, scene and label matching, scene context, audio, and text. The approach uses zero-shot components and demonstrates effectiveness in capturing complex emotional states without domain adaptation. The source code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound Expression Recognition (CER), a subfield of affective computing,aims to detect complex emotional states formed by combinations of basicemotions. In this work, we present a novel zero-shot multimodal approach forCER that combines six heterogeneous modalities into a single pipeline: staticand dynamic facial expressions, scene and label matching, scene context, audio,and text. Unlike previous approaches relying on task-specific training data,our approach uses zero-shot components, including Contrastive Language-ImagePretraining (CLIP)-based label matching and Qwen-VL for semantic sceneunderstanding. We further introduce a Multi-Head Probability Fusion (MHPF)module that dynamically weights modality-specific predictions, followed by aCompound Expressions (CE) transformation module that uses Pair-Wise ProbabilityAggregation (PPA) and Pair-Wise Feature Similarity Aggregation (PFSA) methodsto produce interpretable compound emotion outputs. Evaluated under multi-corpustraining, the proposed approach shows F1 scores of 46.95% on AffWild2, 49.02%on Acted Facial Expressions in The Wild (AFEW), and 34.85% on C-EXPR-DB viazero-shot testing, which is comparable to the results of supervised approachestrained on target data. This demonstrates the effectiveness of the proposedapproach for capturing CE without domain adaptation. The source code ispublicly available.</description>
      <author>example@mail.com (Elena Ryumina, Maxim Markitantov, Alexandr Axyonov, Dmitry Ryumin, Mikhail Dolgushin, Alexey Karpov)</author>
      <guid isPermaLink="false">2507.02205v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>IntFold: A Controllable Foundation Model for General and Specialized Biomolecular Structure Prediction</title>
      <link>http://arxiv.org/abs/2507.02025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了IntFold，这是一种可控制的生物分子结构预测基础模型，适用于通用和特定领域。&lt;h4&gt;背景&lt;/h4&gt;论文背景是生物分子结构预测领域，特别是AlphaFold3等先进模型的现状。&lt;h4&gt;目的&lt;/h4&gt;开发IntFold模型，以实现与AlphaFold3相当或更好的预测准确度，并扩展其应用范围。&lt;h4&gt;方法&lt;/h4&gt;IntFold使用定制的注意力核，并且可以通过适配器预测别构态、受约束的结构和结合亲和力。此外，引入了新的置信度头部来评估对接质量。&lt;h4&gt;主要发现&lt;/h4&gt;IntFold在标准结构预测方面表现出与AlphaFold3相当的预测准确性，并能适应多种预测任务，包括抗体-抗原复合物的对接质量评估。&lt;h4&gt;结论&lt;/h4&gt;IntFold是一个高效且功能丰富的生物分子结构预测模型，在训练过程中提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;We introduce IntFold, a controllable foundation model for both general and specialized biomolecular structure prediction. IntFold demonstrates predictive accuracy comparable to the state-of-the-art AlphaFold3, while utilizing a superior customized attention kernel. Beyond standard structure prediction, IntFold can be adapted to predict allosteric states, constrained structures, and binding affinity through the use of individual adapters. Furthermore, we introduce a novel confidence head to estimate docking quality, offering a more nuanced assessment for challenging targets such as antibody-antigen complexes. Finally, we share insights gained during the training process of this computationally intensive model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce IntFold, a controllable foundation model for both general andspecialized biomolecular structure prediction. IntFold demonstrates predictiveaccuracy comparable to the state-of-the-art AlphaFold3, while utilizing asuperior customized attention kernel. Beyond standard structure prediction,IntFold can be adapted to predict allosteric states, constrained structures,and binding affinity through the use of individual adapters. Furthermore, weintroduce a novel confidence head to estimate docking quality, offering a morenuanced assessment for challenging targets such as antibody-antigen complexes.Finally, we share insights gained during the training process of thiscomputationally intensive model.</description>
      <author>example@mail.com (The IntFold Team, Leon Qiao, Wayne Bai, He Yan, Gary Liu, Nova Xi, Xiang Zhang)</author>
      <guid isPermaLink="false">2507.02025v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems</title>
      <link>http://arxiv.org/abs/2507.02233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对云计算环境中故障根源识别的挑战，提出了一种基于迁移学习的智能识别算法。&lt;h4&gt;背景&lt;/h4&gt;故障根源识别的困难源于复杂的系统结构、密集的服务耦合和有限的故障信息。&lt;h4&gt;目的&lt;/h4&gt;解决云计算环境中故障根源识别的问题。&lt;h4&gt;方法&lt;/h4&gt;方法引入了一个共享特征提取模块和领域对抗机制，以实现从源域到目标域的有效知识迁移。同时，采用伪标签选择策略，在目标域缺少标记样本时，使用高置信度预测进行训练，以增强模型识别少数类别的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在准确性、F1分数和AUC等关键指标上优于现有主流方法，模型表现出更强的判别能力和鲁棒性。即使在极端类别不平衡和目标域中存在显著的结构差异时，模型仍能保持高性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂云计算系统中验证了所提机制的有效性和实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of fault root cause identification incloud computing environments. The difficulty arises from complex systemstructures, dense service coupling, and limited fault information. To solvethis problem, an intelligent identification algorithm based on transferlearning is proposed. The method introduces a shared feature extraction moduleand a domain adversarial mechanism to enable effective knowledge transfer fromthe source domain to the target domain. This improves the model'sdiscriminative ability and generalization performance in the target domain. Themodel incorporates a pseudo-label selection strategy. When labeled samples arelacking in the target domain, high-confidence predictions are used in training.This enhances the model's ability to recognize minority classes. To evaluatethe stability and adaptability of the method in real-world scenarios,experiments are designed under three conditions: label scarcity, classimbalance, and heterogeneous node environments. Experimental results show thatthe proposed method outperforms existing mainstream approaches in several keymetrics, including accuracy, F1-Score, and AUC. The model demonstrates strongerdiscriminative power and robustness. Notably, under extreme class imbalance andsignificant structural differences in the target domain, the model stillmaintains high performance. This validates the effectiveness and practicalvalue of the proposed mechanisms in complex cloud computing systems.</description>
      <author>example@mail.com (Bruce Fang, Danyi Gao)</author>
      <guid isPermaLink="false">2507.02233v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Transformers are Scalable Learners and Thinkers</title>
      <link>http://arxiv.org/abs/2507.02092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Energy-Based Transformers（EBTs）的新模型，该模型通过学习从无监督学习中思考，提高了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的Inference-time computation techniques存在局限性，如模态特定、问题特定或需要额外的监督/训练。&lt;h4&gt;目的&lt;/h4&gt;探讨是否可以推广System 2 Thinking方法，并开发仅从无监督学习中学习的模型。&lt;h4&gt;方法&lt;/h4&gt;通过显式验证输入与候选预测之间的兼容性，并将预测问题重新定义为针对验证器的优化问题，训练Energy-Based Transformers（EBTs）。&lt;h4&gt;主要发现&lt;/h4&gt;EBTs在训练过程中比Transformer++方法更快地扩展，在数据、批量大小、参数、FLOPs和深度方面达到高达35%的更高扩展率。在推理过程中，EBTs在语言任务上比Transformer++提高了29%的性能，并且在图像去噪任务上优于Diffusion Transformers，同时使用的正向传递更少。此外，EBTs在大多数下游任务上比现有模型取得了更好的结果。&lt;h4&gt;结论&lt;/h4&gt;EBTs是一种有前途的新范式，可以扩展模型的学习和思考能力。&lt;h4&gt;翻译&lt;/h4&gt;Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question 'Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?' Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inference-time computation techniques, analogous to human System 2 Thinking,have recently become popular for improving model performances. However, mostexisting approaches suffer from several limitations: they are modality-specific(e.g., working only in text), problem-specific (e.g., verifiable domains likemath and coding), or require additional supervision/training on top ofunsupervised pretraining (e.g., verifiers or verifiable rewards). In thispaper, we ask the question "Is it possible to generalize these System 2Thinking approaches, and develop models that learn to think solely fromunsupervised learning?" Interestingly, we find the answer is yes, by learningto explicitly verify the compatibility between inputs andcandidate-predictions, and then re-framing prediction problems as optimizationwith respect to this verifier. Specifically, we train Energy-Based Transformers(EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energyvalue to every input and candidate-prediction pair, enabling predictionsthrough gradient descent-based energy minimization until convergence. Acrossboth discrete (text) and continuous (visual) modalities, we find EBTs scalefaster than the dominant Transformer++ approach during training, achieving anup to 35% higher scaling rate with respect to data, batch size, parameters,FLOPs, and depth. During inference, EBTs improve performance with System 2Thinking by 29% more than the Transformer++ on language tasks, and EBTsoutperform Diffusion Transformers on image denoising while using fewer forwardpasses. Further, we find that EBTs achieve better results than existing modelson most downstream tasks given the same or worse pretraining performance,suggesting that EBTs generalize better than existing approaches. Consequently,EBTs are a promising new paradigm for scaling both the learning and thinkingcapabilities of models.</description>
      <author>example@mail.com (Alexi Gladstone, Ganesh Nanduru, Md Mofijul Islam, Peixuan Han, Hyeonjeong Ha, Aman Chadha, Yilun Du, Heng Ji, Jundong Li, Tariq Iqbal)</author>
      <guid isPermaLink="false">2507.02092v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters</title>
      <link>http://arxiv.org/abs/2507.02085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoAda是一种SE(3)-等变适配器框架，用于高效微调几何扩散模型，以适应不同的下游任务。&lt;h4&gt;背景&lt;/h4&gt;几何扩散模型在分子动力学和结构生成中取得了显著成功，但其对下游任务的微调效率仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出GeoAda框架，以实现灵活且参数高效的微调，同时不修改原始模型架构。&lt;h4&gt;方法&lt;/h4&gt;GeoAda采用结构化适配器设计，通过耦合算子编码控制信号，然后通过预训练模型层的可训练副本处理，最后通过解耦算子和等变零初始化卷积投影回模型。&lt;h4&gt;主要发现&lt;/h4&gt;GeoAda通过微调轻量级适配器模块，保持了模型的几何一致性，同时减轻了过拟合和灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;GeoAda在多种几何控制类型和广泛的应用领域表现出色，实现了最先进的微调性能，同时保持了原始任务的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何扩散模型在分子动力学和结构生成方面表现出色。然而，对于具有不同几何控制的下游任务进行高效微调仍是一个未被充分探索的领域。在这项工作中，我们提出了一种SE(3)-等变适配器框架（GeoAda），它能够实现对于受控生成任务的灵活和参数高效的微调，而不需要修改原始模型架构。GeoAda引入了一种结构化适配器设计：控制信号首先通过耦合算子进行编码，然后通过所选预训练模型层的可训练副本进行处理，最后通过解耦算子和等变零初始化卷积进行投影。通过仅微调这些轻量级适配器模块，GeoAda保持了模型的几何一致性，同时减轻了过拟合和灾难性遗忘。我们理论证明了所提出的适配器保持了SE(3)-等变性，确保了在适配过程中预训练扩散模型的几何归纳偏见保持完整。我们展示了GeoAda在多种几何控制类型中的应用，包括框架控制、全局控制、子图控制和广泛的领域，如粒子动力学、分子动力学、人类运动预测和分子生成。实证结果表明，GeoAda在保持原始任务准确性的同时，实现了最先进的微调性能，而其他基线由于过拟合和灾难性遗忘而经历了显著的性能下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric diffusion models have shown remarkable success in moleculardynamics and structure generation. However, efficiently fine-tuning them fordownstream tasks with varying geometric controls remains underexplored. In thiswork, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enablesflexible and parameter-efficient fine-tuning for controlled generative taskswithout modifying the original model architecture. GeoAda introduces astructured adapter design: control signals are first encoded through couplingoperators, then processed by a trainable copy of selected pretrained modellayers, and finally projected back via decoupling operators followed by anequivariant zero-initialized convolution. By fine-tuning only these lightweightadapter modules, GeoAda preserves the model's geometric consistency whilemitigating overfitting and catastrophic forgetting. We theoretically prove thatthe proposed adapters maintain SE(3)-equivariance, ensuring that the geometricinductive biases of the pretrained diffusion model remain intact duringadaptation. We demonstrate the wide applicability of GeoAda across diversegeometric control types, including frame control, global control, subgraphcontrol, and a broad range of application domains such as particle dynamics,molecular dynamics, human motion prediction, and molecule generation. Empiricalresults show that GeoAda achieves state-of-the-art fine-tuning performancewhile preserving original task accuracy, whereas other baselines experiencesignificant performance degradation due to overfitting and catastrophicforgetting.</description>
      <author>example@mail.com (Wanjia Zhao, Jiaqi Han, Siyi Gu, Mingjian Jiang, James Zou, Stefano Ermon)</author>
      <guid isPermaLink="false">2507.02085v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System</title>
      <link>http://arxiv.org/abs/2507.02000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyFairCRS的新型框架，旨在解决推荐系统中的不公平性问题，通过在动态和交互式的会话推荐系统中促进多兴趣多样性公平。&lt;h4&gt;背景&lt;/h4&gt;不公平性是推荐系统中的一个常见挑战，通常会导致基于性别、种族、年龄或流行度等属性的有偏结果，从而损害用户或物品。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了HyFairCRS框架，目的是在动态和交互式的会话推荐系统中促进多兴趣多样性公平。&lt;h4&gt;方法&lt;/h4&gt;HyFairCRS通过对比学习建立多样化的超图来捕捉广泛的用户兴趣，并在对话中使用这些兴趣生成信息性响应，以确保在动态用户-系统反馈循环中的公平物品预测。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基于CRS的数据集上的实验表明，HyFairCRS实现了新的最先进性能，同时有效地缓解了不公平性。&lt;h4&gt;结论&lt;/h4&gt;HyFairCRS框架能够有效解决推荐系统中的不公平性问题，并取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Unfairness is a well-known challenge in Recommender Systems (RSs), often resulting in biased outcomes that disadvantage users or items based on attributes such as gender, race, age, or popularity. Although some approaches have started to improve fairness recommendation in offline or static contexts, the issue of unfairness often exacerbates over time, leading to significant problems like the Matthew effect, filter bubbles, and echo chambers. To address these challenges, we proposed a novel framework, Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System (HyFairCRS), aiming to promote multi-interest diversity fairness in dynamic and interactive Conversational Recommender Systems (CRSs). HyFairCRS first captures a wide range of user interests by establishing diverse hypergraphs through contrastive learning. These interests are then utilized in conversations to generate informative responses and ensure fair item predictions within the dynamic user-system feedback loop. Experiments on two CRS-based datasets show that HyFairCRS achieves a new state-of-the-art performance while effectively alleviating unfairness. Our code is available at https://github.com/zysensmile/HyFairCRS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unfairness is a well-known challenge in Recommender Systems (RSs), oftenresulting in biased outcomes that disadvantage users or items based onattributes such as gender, race, age, or popularity. Although some approacheshave started to improve fairness recommendation in offline or static contexts,the issue of unfairness often exacerbates over time, leading to significantproblems like the Matthew effect, filter bubbles, and echo chambers. To addressthese challenges, we proposed a novel framework, Hypergraph ContrastiveMulti-Interest Learning for Fair Conversational Recommender System (HyFairCRS),aiming to promote multi-interest diversity fairness in dynamic and interactiveConversational Recommender Systems (CRSs). HyFairCRS first captures a widerange of user interests by establishing diverse hypergraphs through contrastivelearning. These interests are then utilized in conversations to generateinformative responses and ensure fair item predictions within the dynamicuser-system feedback loop. Experiments on two CRS-based datasets show thatHyFairCRS achieves a new state-of-the-art performance while effectivelyalleviating unfairness. Our code is available athttps://github.com/zysensmile/HyFairCRS.</description>
      <author>example@mail.com (Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, Kwok-Yan Lam)</author>
      <guid isPermaLink="false">2507.02000v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Generating Large Semi-Synthetic Graphs of Any Size</title>
      <link>http://arxiv.org/abs/2507.02166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Latent Graph Sampling Generation（LGSG）的新框架，用于生成不同大小的图，该框架利用扩散模型和节点嵌入，无需重新训练即可生成图，并解决了当前模型依赖节点ID的问题。&lt;h4&gt;背景&lt;/h4&gt;图生成是网络科学中的一个重要领域，传统方法侧重于复制现实世界图的特定属性，如小直径或幂律度分布。近年来，深度学习，特别是图神经网络的发展，使得数据驱动的方法能够学习并生成图，而不依赖于预定义的结构属性。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前模型依赖节点ID、限制生成大于输入图的图以及忽略节点属性的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了Latent Graph Sampling Generation（LGSG）框架，该框架利用扩散模型和节点嵌入来生成不同大小的图，无需重新训练，并消除了对节点ID的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标上，如节点形成集群的趋势方面，表现更优。此外，它保持了不同大小图的持续结构特征，展示了其鲁棒性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;LGSG是一种有效的图生成方法，能够在保持结构特征的同时，生成不同大小的图，具有鲁棒性和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph generation is an important area in network science. Traditionalapproaches focus on replicating specific properties of real-world graphs, suchas small diameters or power-law degree distributions. Recent advancements indeep learning, particularly with Graph Neural Networks, have enableddata-driven methods to learn and generate graphs without relying on predefinedstructural properties. Despite these advances, current models are limited bytheir reliance on node IDs, which restricts their ability to generate graphslarger than the input graph and ignores node attributes. To address thesechallenges, we propose Latent Graph Sampling Generation (LGSG), a novelframework that leverages diffusion models and node embeddings to generategraphs of varying sizes without retraining. The framework eliminates thedependency on node IDs and captures the distribution of node embeddings andsubgraph structures, enabling scalable and flexible graph generation.Experimental results show that LGSG performs on par with baseline models forstandard metrics while outperforming them in overlooked ones, such as thetendency of nodes to form clusters. Additionally, it maintains consistentstructural characteristics across graphs of different sizes, demonstratingrobustness and scalability.</description>
      <author>example@mail.com (Rodrigo Tuna, Carlos Soares)</author>
      <guid isPermaLink="false">2507.02166v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.02151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了NCPNET，一个针对时间图的端到端一致预测框架，旨在提高图神经网络在动态环境下的可靠性。&lt;h4&gt;背景&lt;/h4&gt;现有的一致预测方法主要针对静态图，忽略了真实世界图的动态特性，导致其适用性受限。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理时间图的一致预测方法，以增强图神经网络在动态环境下的可靠性。&lt;h4&gt;方法&lt;/h4&gt;NCPNET通过扩散模型计算非一致性分数，以捕捉动态网络中的拓扑和时序不确定性，并采用效率感知的优化算法提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在WIKI数据集上，NCPNET实现了31%的预测集大小减少，比现有方法效率显著提高。&lt;h4&gt;结论&lt;/h4&gt;NCPNET能够确保时间图中的保证覆盖，显著提高了图神经网络在动态环境下的可靠性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes NCPNET, an end-to-end conformal prediction framework tailored for temporal graphs, aiming to enhance the reliability of graph neural networks in dynamic environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737064&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformal prediction for graph neural networks (GNNs) offers a promisingframework for quantifying uncertainty, enhancing GNN reliability in high-stakesapplications. However, existing methods predominantly focus on static graphs,neglecting the evolving nature of real-world graphs. Temporal dependencies ingraph structure, node attributes, and ground truth labels violate thefundamental exchangeability assumption of standard conformal predictionmethods, limiting their applicability. To address these challenges, in thispaper, we introduce NCPNET, a novel end-to-end conformal prediction frameworktailored for temporal graphs. Our approach extends conformal prediction todynamic settings, mitigating statistical coverage violations induced bytemporal dependencies. To achieve this, we propose a diffusion-basednon-conformity score that captures both topological and temporal uncertaintieswithin evolving networks. Additionally, we develop an efficiency-awareoptimization algorithm that improves the conformal prediction process,enhancing computational efficiency and reducing coverage violations. Extensiveexperiments on diverse real-world temporal graphs, including WIKI, REDDIT,DBLP, and IBM Anti-Money Laundering dataset, demonstrate NCPNET's capability toensure guaranteed coverage in temporal graphs, achieving up to a 31% reductionin prediction set size on the WIKI dataset, significantly improving efficiencycompared to state-of-the-art methods. Our data and code are available athttps://github.com/ODYSSEYWT/NCPNET.</description>
      <author>example@mail.com (Tuo Wang, Jian Kang, Yujun Yan, Adithya Kulkarni, Dawei Zhou)</author>
      <guid isPermaLink="false">2507.02151v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Power Flow Estimation with Topology-Aware Gated Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.02078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于门控图神经网络（GGNN）的AC电力流近似模型，用于在拓扑不确定性下的实时电网监测、应急分析和决策支持。&lt;h4&gt;背景&lt;/h4&gt;现有的AC电力流近似模型在捕捉长距离非线性依赖性和物理定律的执行方面存在不足，且在拓扑变化或负载波动大时泛化能力差。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理拓扑不确定性的AC电力流近似模型，以支持实时电网操作。&lt;h4&gt;方法&lt;/h4&gt;模型在多个IEEE基准网络上进行训练，包括随机线路故障和高达40%的负载变化。同时，采用了监督学习和基于物理信息自监督训练策略来提高模型的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;比较评估显示，所提出的GGNN模型在预测精度和一致性方面优于现有的基于GNN的近似模型，并且能够确保物理一致性。&lt;h4&gt;结论&lt;/h4&gt;通过将操作约束直接嵌入到架构和损失函数中，该模型提供了一种轻量级、准确且可扩展的工具，适用于实时电网操作。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对交流电力流的准确且可扩展的代理模型，对于实时电网监控、应急分析和决策支持在日益动态和逆变器主导的电力系统中至关重要。然而，由于现有代理模型在捕捉网格化输电网络中的长距离非线性依赖性方面的能力有限，以及它们在物理定律执行方面的不足，大多数现有代理模型未能满足实际部署的要求。这些模型通常需要大量的超参数调整，在拓扑变化或负载波动较大时泛化能力较差，并且通常不量化不确定性或无法扩展到几百个节点之外。为了解决这些挑战，本文提出了一种在拓扑不确定性下进行交流电力流估计的门控图神经网络（GGNN）代理模型。该模型在多个大小和复杂程度不同的IEEE基准网络上进行训练，每个网络都包含随机线路故障和高达40%的负载变化。为了提高鲁棒性和泛化能力，我们探索了传统的监督学习和基于物理信息的自监督训练策略。比较评估表明，所提出的GGNN模型在预测精度和一致性方面一致优于现有的基于GNN的代理模型，并且与牛顿-拉夫森解的预测非常接近。通过将操作约束直接嵌入到架构和损失函数中，该模型确保了物理一致性，并提供了实时电网操作的一个轻量级、准确且可扩展的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and scalable surrogate models for AC power flow are essential forreal-time grid monitoring, contingency analysis, and decision support inincreasingly dynamic and inverter-dominated power systems. However, mostexisting surrogates fall short of practical deployment due to their limitedcapacity to capture long-range nonlinear dependencies in meshed transmissionnetworks and their weak enforcement of physical laws. These models oftenrequire extensive hyperparameter tuning, exhibit poor generalization undertopology changes or large load swings, and typically do not quantifyuncertainty or scale well beyond a few hundred buses. To address thesechallenges, this paper proposes a \textit{gated graph neural network (GGNN)}surrogate for AC power-flow estimation under topological uncertainty. The modelis trained across multiple IEEE benchmark networks of varying size andcomplexity, each incorporating randomized line contingencies and up to 40\%load variation. To improve robustness and generalization, we explore bothconventional supervised learning and physics-informed self-supervised trainingstrategies. Comparative evaluations show that the proposed GGNN consistentlyoutperforms prior GNN-based surrogates, achieving predictions closely alignedwith Newton--Raphson solutions. By embedding operational constraints directlyinto the architecture and loss function, the model ensures physical consistencyand delivers a lightweight, accurate, and scalable tool for real-time gridoperations.</description>
      <author>example@mail.com (Shrenik Jadhav, Birva Sevak, Srijita Das, Wencong Su, Van-Hai Bui)</author>
      <guid isPermaLink="false">2507.02078v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control</title>
      <link>http://arxiv.org/abs/2507.01424v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TriVLA的统一视觉-语言-动作模型，用于通用机器人控制，通过三个系统架构来处理静态信息和动态信息，提高了机器人操作的性能。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言模型在常识推理方面的进步推动了视觉-语言-动作模型的发展，这些模型使机器人能够执行通用操作。然而，现有的自回归VLA方法往往捕获静态信息，忽视了动态信息对于具身任务的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出TriVLA模型，以解决现有方法在捕捉动态信息方面的不足，从而提高机器人操作的性能。&lt;h4&gt;方法&lt;/h4&gt;TriVLA模型包含三个系统：视觉-语言模块（系统2）通过视觉和语言指令解释环境；动态感知模块（系统3）产生包含当前静态信息和预测未来动态的视觉表示；政策学习模块（系统1）实时生成流畅的电机动作。该模型利用预训练的视觉语言模型和视频基础模型，在机器人数据集和互联网人类操作数据上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估显示，TriVLA以大约36 Hz的速度运行，在标准模拟基准测试和具有挑战性的真实世界操作任务上超越了最先进的模仿学习基线。&lt;h4&gt;结论&lt;/h4&gt;TriVLA模型能够有效处理动态信息，提高了机器人在复杂环境中的操作能力，是机器人控制领域的一项重要进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在视觉-语言模型（VLMs）在常识推理方面的进步推动了视觉-语言-动作（VLA）模型的发展，这些模型使机器人能够执行通用操作。尽管现有的自回归VLA方法设计了一种特定的架构，如双系统架构来利用大规模预训练知识，但它们往往捕获静态信息，经常忽视对具身任务至关重要的动态方面。为此，我们提出了TriVLA，一个具有三系统架构的统一视觉-语言-动作模型，用于通用机器人控制。视觉-语言模块（系统2）通过视觉和语言指令解释环境。动态感知模块（系统3）内在地产生包含当前静态信息和预测未来动态的视觉表示，从而为策略学习提供有价值的指导。TriVLA利用预训练的VLM模型，并在机器人数据集以及互联网人类操作数据上对预训练的视频基础模型进行微调。随后的策略学习模块（系统1）实时生成流畅的电机动作。实验评估表明，TriVLA以大约36 Hz的速度运行，在标准模拟基准测试以及具有挑战性的真实世界操作任务上超越了最先进的模仿学习基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language models (VLMs) for common-sensereasoning have led to the development of vision-language-action (VLA) models,enabling robots to perform generalized manipulation. Although existingautoregressive VLA methods design a specific architecture like dual-system toleverage large-scale pretrained knowledge, they tend to capture staticinformation, often neglecting the dynamic aspects vital for embodied tasks. Tothis end, we propose TriVLA, a unified Vision-Language-Action model with atriple-system architecture for general robot control. The vision-languagemodule (System 2) interprets the environment through vision and languageinstructions. The dynamics perception module (System 3) inherently producesvisual representations that encompass both current static information andpredicted future dynamics, thereby providing valuable guidance for policylearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trainedvideo foundation model on robot datasets along with internet human manipulationdata. The subsequent policy learning module (System 1) generates fluid motoractions in real time. Experimental evaluation demonstrates that TriVLA operatesat approximately 36 Hz and surpasses state-of-the-art imitation learningbaselines on standard simulation benchmarks as well as challenging real-worldmanipulation tasks.</description>
      <author>example@mail.com (Zhenyang Liu, Yongchong Gu, Sixiao Zheng, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2507.01424v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models</title>
      <link>http://arxiv.org/abs/2507.01201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为JAM的联合自动编码器调制框架，旨在通过多目标优化任务，在保持每个模态原生结构的同时，实现不同模态模型之间的对齐。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言模型在各自的模态、目标和架构下独立训练，形成了不同的表征空间。然而，存在一种假设，即这些模型可能趋向于一个共享的现实统计模型。&lt;h4&gt;目的&lt;/h4&gt;探讨如何超越事后统计检测对齐，并显式优化不同模态之间的对齐。&lt;h4&gt;方法&lt;/h4&gt;将柏拉图对齐问题视为一个多目标优化任务，提出JAM框架，通过联合训练模态特定的自动编码器，在预训练单模态模型的潜在表征上进行，同时通过重建和跨模态目标鼓励对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，JAM框架在三个关键设计轴上表现出色：(i) 对齐目标，比较了对比损失、其硬负样本变体和提出的Spread损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表征收敛的影响。&lt;h4&gt;结论&lt;/h4&gt;JAM框架能够可靠地诱导对齐，即使在冻结的独立训练表征之间，也为将通用单模态基础模型转化为专业多模态模型提供了理论和实践途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：独立训练的视觉和语言模型占据不同的表征空间，这些空间由各自的模态、目标和架构塑造。然而，一个新兴的假设——柏拉图表征假设——表明，这样的模型仍然可能趋向于一个共享的现实统计模型。如果存在这种兼容性，那么就提出了一个基本问题：我们能否超越事后统计检测的对齐，并在这种不同表征之间显式优化对齐？我们将柏拉图对齐问题设定为一个多目标优化任务——在保持每个模态的原生结构的同时，实现相互连贯的对齐。我们引入了联合自动编码器调制（JAM）框架，该框架联合训练特定于模态的自动编码器，在预训练单模态模型的潜在表征上，通过重建和跨模态目标鼓励对齐。通过类比，这个框架作为一种方法来逃离柏拉图的洞穴，使共享结构从不同的输入中产生。我们在三个关键设计轴上评估了这个框架：(i) 对齐目标——比较了对比损失（Con）、其硬负样本变体（NegCon）和我们的Spread损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表征收敛的影响。我们的发现表明，我们的轻量级Pareto有效框架能够可靠地诱导对齐，即使在冻结的独立训练表征之间，这也为将通用单模态基础模型转化为专业多模态模型提供了理论和实践途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Independently trained vision and language models inhabit disjointrepresentational spaces, shaped by their respective modalities, objectives, andarchitectures. Yet an emerging hypothesis - the Platonic RepresentationHypothesis - suggests that such models may nonetheless converge toward a sharedstatistical model of reality. This compatibility, if it exists, raises afundamental question: can we move beyond post-hoc statistical detection ofalignment and explicitly optimize for it between such disjoint representations?We cast this Platonic alignment problem as a multi-objective optimization task- preserve each modality's native structure while aligning for mutualcoherence. We introduce the Joint Autoencoder Modulator (JAM) framework thatjointly trains modality-specific autoencoders on the latent representations ofpre-trained single modality models, encouraging alignment through bothreconstruction and cross-modal objectives. By analogy, this framework serves asa method to escape Plato's Cave, enabling the emergence of shared structurefrom disjoint inputs. We evaluate this framework across three critical designaxes: (i) the alignment objective - comparing contrastive loss (Con), itshard-negative variant (NegCon), and our Spread loss, (ii) the layer depth atwhich alignment is most effective, and (iii) the impact of foundation modelscale on representational convergence. Our findings show that our lightweightPareto-efficient framework reliably induces alignment, even across frozen,independently trained representations, offering both theoretical insight andpractical pathways for transforming generalist unimodal foundations intospecialist multimodal models.</description>
      <author>example@mail.com (Hyoseo, Yoon, Yisong Yue, Been Kim)</author>
      <guid isPermaLink="false">2507.01201v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications</title>
      <link>http://arxiv.org/abs/2507.00914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用大型语言模型（LLMs）实现智能城市愿景的新途径，重点介绍了城市LLM代理的概念、工作流程、应用领域以及信任度和评估问题。&lt;h4&gt;背景&lt;/h4&gt;智能城市的愿景是通过大数据和人工智能技术创建高效、宜居和可持续的城市环境。LLMs的出现为这一愿景提供了新的实现方式。&lt;h4&gt;目的&lt;/h4&gt;研究城市LLM代理，探讨其独特能力、工作流程、应用领域，并讨论信任度和评估问题。&lt;h4&gt;方法&lt;/h4&gt;介绍城市LLM代理的概念，从代理工作流程的角度进行调研，包括城市感知、记忆管理、推理、执行和学习，并对应用领域进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;城市LLM代理在多个领域有广泛应用，包括城市规划、交通、环境、公共安全和城市社会，并提出了信任度和评估问题以及未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;城市LLM代理是智能城市发展的新兴领域，为LLMs与城市智能的交叉提供了路线图。&lt;h4&gt;翻译&lt;/h4&gt;The long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies. Recently, the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision. With powerful semantic understanding and reasoning capabilities, LLMs can be deployed as intelligent agents capable of autonomously solving complex problems across domains. In this article, we focus on Urban LLM Agents, which are LLM-powered agents that are semi-embodied within the hybrid cyber-physical-social space of cities and used for system-level urban decision-making. First, we introduce the concept of urban LLM agents, discussing their unique capabilities and features. Second, we survey the current research landscape from the perspective of agent workflows, encompassing urban sensing, memory management, reasoning, execution, and learning. Third, we categorize the application domains of urban LLM agents into five groups: urban planning, transportation, environment, public safety, and urban society, presenting representative works in each group. Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research. This survey aims to establish a foundation for the emerging field of urban LLM agents and to provide a roadmap for advancing the intersection of LLMs and urban intelligence. A curated list of relevant papers and open-source resources is maintained and continuously updated at https://github.com/usail-hkust/Awesome-Urban-LLM-Agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The long-standing vision of intelligent cities is to create efficient,livable, and sustainable urban environments using big data and artificialintelligence technologies. Recently, the advent of Large Language Models (LLMs)has opened new ways toward realizing this vision. With powerful semanticunderstanding and reasoning capabilities, LLMs can be deployed as intelligentagents capable of autonomously solving complex problems across domains. In thisarticle, we focus on Urban LLM Agents, which are LLM-powered agents that aresemi-embodied within the hybrid cyber-physical-social space of cities and usedfor system-level urban decision-making. First, we introduce the concept ofurban LLM agents, discussing their unique capabilities and features. Second, wesurvey the current research landscape from the perspective of agent workflows,encompassing urban sensing, memory management, reasoning, execution, andlearning. Third, we categorize the application domains of urban LLM agents intofive groups: urban planning, transportation, environment, public safety, andurban society, presenting representative works in each group. Finally, wediscuss trustworthiness and evaluation issues that are critical for real-worlddeployment, and identify several open problems for future research. This surveyaims to establish a foundation for the emerging field of urban LLM agents andto provide a roadmap for advancing the intersection of LLMs and urbanintelligence. A curated list of relevant papers and open-source resources ismaintained and continuously updated athttps://github.com/usail-hkust/Awesome-Urban-LLM-Agents.</description>
      <author>example@mail.com (Jindong Han, Yansong Ning, Zirui Yuan, Hang Ni, Fan Liu, Tengfei Lyu, Hao Liu)</author>
      <guid isPermaLink="false">2507.00914v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
  <item>
      <title>Joint Power Control and Precoding for Cell-Free Massive MIMO Systems With Sparse Multi-Dimensional Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.01876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CF mMIMO技术因其消除小区间干扰而显著提高频谱效率，但在实际部署中面临计算复杂度高和优化复杂处理等挑战。&lt;h4&gt;背景&lt;/h4&gt;CF mMIMO技术作为未来网络的重要候选技术，能够显著提升频谱效率，但其部署面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出基于稀疏多维图神经网络（SP-MDGNN）的框架，以降低计算复杂度同时保持高性能。&lt;h4&gt;方法&lt;/h4&gt;采用SP-MDGNN对接入点（APs）和用户设备（UEs）之间的连接进行稀疏化，并引入加权最小均方误差（WMMSE）算法作为对比方法。&lt;h4&gt;主要发现&lt;/h4&gt;稀疏方法在性能和复杂度之间达到最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时仅略有性能下降。&lt;h4&gt;结论&lt;/h4&gt;SP-MDGNN框架为大规模网络中CF mMIMO系统的实际部署提供了启示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无细胞大量多输入多输出（CF mMIMO）技术因能显著提高频谱效率，通过消除小区间干扰而成为未来网络的重要候选技术。然而，其实际部署面临大量挑战，如计算复杂度高以及复杂处理的优化。为了解决这些挑战，本信函提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架，通过稀疏化接入点（APs）和用户设备（UEs）之间的连接，显著降低计算复杂度，同时保持高性能。此外，引入了加权最小均方误差（WMMSE）算法作为对比方法，以进一步分析性能与复杂度之间的权衡。仿真结果表明，稀疏方法在性能和复杂度之间达到了最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时仅略有性能下降，为大规模网络中CF mMIMO系统的实际部署提供了启示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as aprominent candidate for future networks due to its ability to significantlyenhance spectral efficiency by eliminating inter-cell interference. However,its practical deployment faces considerable challenges, such as highcomputational complexity and the optimization of its complex processing. Toaddress these challenges, this correspondence proposes a framework based on asparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies theconnections between access points (APs) and user equipments (UEs) tosignificantly reduce computational complexity while maintaining highperformance. In addition, the weighted minimum mean square error (WMMSE)algorithm is introduced as a comparative method to further analyze thetrade-off between performance and complexity. Simulation results demonstratethat the sparse method achieves an optimal balance between performance andcomplexity, significantly reducing the computational complexity of the originalMDGNN method while incurring only a slight performance degradation, providinginsights for the practical deployment of CF mMIMO systems in large-scalenetwork.</description>
      <author>example@mail.com (Yukun Ma, Jiayi Zhang, Ziheng Liu, Guowei Shi, Bo Ai)</author>
      <guid isPermaLink="false">2507.01876v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Future Slot Prediction for Unsupervised Object Discovery in Surgical Video</title>
      <link>http://arxiv.org/abs/2507.01882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对象中心的槽位注意力机制，用于无监督学习结构化、可解释的对象中心表示（槽位），并应用于医疗健康领域，如手术视频的实时解释。&lt;h4&gt;背景&lt;/h4&gt;现实世界应用中的场景，如手术场景，难以解析成有意义的槽位集合。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态时间槽位转换器（DTST）模块，以解决在手术视频中槽位计数自适应方法性能低的问题。&lt;h4&gt;方法&lt;/h4&gt;该模块同时训练进行时间推理和预测最佳未来槽位初始化。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在多个手术数据库上实现了最先进的性能，证明了无监督对象中心方法可以应用于现实世界数据，并成为医疗健康应用中的常用工具。&lt;h4&gt;结论&lt;/h4&gt;无监督对象中心方法可以应用于医疗健康领域，并具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric slot attention is an emerging paradigm for unsupervisedlearning of structured, interpretable object-centric representations (slots).This enables effective reasoning about objects and events at a lowcomputational cost and is thus applicable to critical healthcare applications,such as real-time interpretation of surgical video. The heterogeneous scenes inreal-world applications like surgery are, however, difficult to parse into ameaningful set of slots. Current approaches with an adaptive slot count performwell on images, but their performance on surgical videos is low. To addressthis challenge, we propose a dynamic temporal slot transformer (DTST) modulethat is trained both for temporal reasoning and for predicting the optimalfuture slot initialization. The model achieves state-of-the-art performance onmultiple surgical databases, demonstrating that unsupervised object-centricmethods can be applied to real-world data and become part of the common arsenalin healthcare applications.</description>
      <author>example@mail.com (Guiqiu Liao, Matjaz Jogan, Marcel Hussing, Edward Zhang, Eric Eaton, Daniel A. Hashimoto)</author>
      <guid isPermaLink="false">2507.01882v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2507.01801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种自适应动量和解耦对比学习框架（AMD），用于预测交通代理的未来轨迹，特别适用于处理自然数据集中长尾数据中的复杂和危险场景。&lt;h4&gt;背景&lt;/h4&gt;准确预测交通代理的未来轨迹对于自动驾驶至关重要，但自然数据集中的轨迹分布存在固有不平衡，长尾数据通常代表更复杂和危险的情况。&lt;h4&gt;目的&lt;/h4&gt;提出AMD框架，以提高模型在识别罕见和复杂轨迹方面的能力。&lt;h4&gt;方法&lt;/h4&gt;AMD框架结合了无监督和监督的对比学习策略，利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，并设计了四种轨迹随机增强方法以及在线迭代聚类策略。&lt;h4&gt;主要发现&lt;/h4&gt;AMD在长尾轨迹预测中实现了最佳性能，并显示出卓越的整体预测准确性。&lt;h4&gt;结论&lt;/h4&gt;AMD框架不仅提高了长尾轨迹预测的性能，还展示了在处理复杂交通场景时的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测交通代理的未来轨迹对于自动驾驶至关重要。然而，由于自然数据集中轨迹分布的不平衡，长尾数据通常代表更复杂和危险的场景。现有研究通常仅依赖于基模型的预测误差，而没有考虑长尾轨迹模式的多样性和不确定性。我们提出了一种自适应动量和解耦对比学习框架（AMD），该框架集成了无监督和监督的对比学习策略。通过利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，我们的框架增强了模型识别罕见和复杂轨迹的能力。此外，我们设计了四种类型的轨迹随机增强方法，并引入了一种在线迭代聚类策略，允许模型动态更新伪标签，更好地适应长尾数据中的分布变化。我们提出了三种不同的标准来定义长尾轨迹，并在nuScenes和ETH/UCY数据集上进行了广泛的比较实验。结果表明，AMD不仅在长尾轨迹预测中实现了最佳性能，还展示了卓越的整体预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting the future trajectories of traffic agents is essentialin autonomous driving. However, due to the inherent imbalance in trajectorydistributions, tail data in natural datasets often represents more complex andhazardous scenarios. Existing studies typically rely solely on a base model'sprediction error, without considering the diversity and uncertainty oflong-tail trajectory patterns. We propose an adaptive momentum and decoupledcontrastive learning framework (AMD), which integrates unsupervised andsupervised contrastive learning strategies. By leveraging an improved momentumcontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,our framework enhances the model's ability to recognize rare and complextrajectories. Additionally, we design four types of trajectory randomaugmentation methods and introduce an online iterative clustering strategy,allowing the model to dynamically update pseudo-labels and better adapt to thedistributional shifts in long-tail data. We propose three different criteria todefine long-tail trajectories and conduct extensive comparative experiments onthe nuScenes and ETH$/$UCY datasets. The results show that AMD not onlyachieves optimal performance in long-tail trajectory prediction but alsodemonstrates outstanding overall prediction accuracy.</description>
      <author>example@mail.com (Bin Rao, Haicheng Liao, Yanchen Guan, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2507.01801v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Rethink 3D Object Detection from Physical World</title>
      <link>http://arxiv.org/abs/2507.00190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D物体检测评估方法，考虑了速度和准确率之间的权衡，并引入了L-AP和P-AP作为新的评估指标，用于实时3D物体检测。&lt;h4&gt;背景&lt;/h4&gt;高精度和低延迟的3D物体检测对于自动驾驶系统至关重要。现有研究通常以平均精度（mAP）和延迟来评估性能，但往往未能解决速度和准确率之间的权衡问题。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的评估方法，以更全面地评估实时3D物体检测的性能，并解决现有方法中未考虑的硬件设备和加速器之间的权衡问题。&lt;h4&gt;方法&lt;/h4&gt;引入了L-AP和P-AP作为新的评估指标，通过考虑物理世界中的时间和物理约束，对3D物体检测模型进行评估。同时，通过延迟感知的超参数优化（L-HPO）开发了实时3D物体检测的性能模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文通过nuPlan数据集证明了新指标的有效性，并量化了“点云越多，识别性能越好”的假设在实时应用中的不正确性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够更全面地评估实时3D物体检测的性能，并通过优化硬件和模型选择，提高了自动驾驶系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;High-accuracy and low-latency 3D object detection is essential for autonomousdriving systems. While previous studies on 3D object detection often evaluateperformance based on mean average precision (mAP) and latency, theytypically fail to address the trade-off between speed and accuracy, such as60.0 mAP at 100 ms vs 61.0 mAP at 500 ms. A quantitative assessment of thetrade-offs between different hardware devices and accelerators remainsunexplored, despite being critical for real-time applications. Furthermore,they overlook the impact on collision avoidance in motion planning, forexample, 60.0 mAP leading to safer motion planning or 61.0 mAP leading tohigh-risk motion planning. In this paper, we introduce latency-aware AP(L-AP) and planning-aware AP (P-AP) as new metrics, which consider thephysical world such as the concept of time and physical constraints, offeringa more comprehensive evaluation for real-time 3D object detection. We demonstrate the effectiveness of our metrics for the entire autonomousdriving system using nuPlan dataset, and evaluate 3D object detection modelsaccounting for hardware differences and accelerators. We also develop a state-of-the-art performance model for real-time 3D object detection throughlatency-aware hyperparameter optimization (L-HPO) using our metrics. Additionally,we quantitatively demonstrate that the assumption 'the more point clouds, thebetter the recognition performance' is incorrect for real-time applications andoptimize both hardware and model selection using our metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-accuracy and low-latency 3D object detection is essential for autonomousdriving systems. While previous studies on 3D object detection often evaluateperformance based on mean average precision (mAP) and latency, they typicallyfail to address the trade-off between speed and accuracy, such as 60.0 mAP at100 ms vs 61.0 mAP at 500 ms. A quantitative assessment of the trade-offsbetween different hardware devices and accelerators remains unexplored, despitebeing critical for real-time applications. Furthermore, they overlook theimpact on collision avoidance in motion planning, for example, 60.0 mAP leadingto safer motion planning or 61.0 mAP leading to high-risk motion planning. Inthis paper, we introduce latency-aware AP (L-AP) and planning-aware AP (P-AP)as new metrics, which consider the physical world such as the concept of timeand physical constraints, offering a more comprehensive evaluation forreal-time 3D object detection. We demonstrate the effectiveness of our metricsfor the entire autonomous driving system using nuPlan dataset, and evaluate 3Dobject detection models accounting for hardware differences and accelerators.We also develop a state-of-the-art performance model for real-time 3D objectdetection through latency-aware hyperparameter optimization (L-HPO) using ourmetrics. Additionally, we quantitatively demonstrate that the assumption "themore point clouds, the better the recognition performance" is incorrect forreal-time applications and optimize both hardware and model selection using ourmetrics.</description>
      <author>example@mail.com (Satoshi Tanaka, Koji Minoda, Fumiya Watanabe, Takamasa Horibe)</author>
      <guid isPermaLink="false">2507.00190v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks</title>
      <link>http://arxiv.org/abs/2507.01955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://fm-vision-evals.epfl.ch/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对多模态基础模型在计算机视觉任务中的表现进行了基准测试。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型如GPT-4o在近期取得了显著进展，但其对视觉的理解能力尚不明确。&lt;h4&gt;目的&lt;/h4&gt;评估流行的多模态基础模型在标准计算机视觉任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;使用COCO、ImageNet等数据集，将标准视觉任务转换为可文本提示和API兼容的任务，创建标准基准测试框架。&lt;h4&gt;主要发现&lt;/h4&gt;1) 模型在所有任务上均未达到最先进的水平；2) 模型是值得尊重的通用主义者；3) 在语义任务上的表现优于几何任务；4) 提示链技术影响了性能，但表现更好的模型对提示变化的敏感性较低；5) GPT-4o在非推理模型中表现最佳；6) 推理模型在几何任务上有所改进；7) 对具有原生图像生成能力的模型（如最新GPT-4o）的初步分析显示，它们表现出幻觉和空间错位等特性。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型在视觉理解方面有潜力，但仍有改进空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models, such as GPT-4o, have recently made remarkableprogress, but it is not clear where exactly these models stand in terms ofunderstanding vision. In this paper, we benchmark the performance of popularmultimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer visiontasks (semantic segmentation, object detection, image classification, depth andsurface normal prediction) using established datasets (e.g., COCO, ImageNet andits variants, etc).  The main challenges to performing this are: 1) most models are trained tooutput text and cannot natively express versatile domains, such as segments or3D geometry, and 2) many leading models are proprietary and accessible only atan API level, i.e., there is no weight access to adapt them. We address thesechallenges by translating standard vision tasks into equivalent text-promptableand API-compatible tasks via prompt chaining to create a standardizedbenchmarking framework.  We observe that 1) the models are not close to the state-of-the-artspecialist models at any task. However, 2) they are respectable generalists;this is remarkable as they are presumably trained on primarily image-text-basedtasks. 3) They perform semantic tasks notably better than geometric ones. 4)While the prompt-chaining techniques affect performance, better models exhibitless sensitivity to prompt variations. 5) GPT-4o performs the best amongnon-reasoning models, securing the top position in 4 out of 6 tasks, 6)reasoning models, e.g. o3, show improvements in geometric tasks, and 7) apreliminary analysis of models with native image generation, like the latestGPT-4o, shows they exhibit quirks like hallucinations and spatialmisalignments.</description>
      <author>example@mail.com (Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir)</author>
      <guid isPermaLink="false">2507.01955v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2507.01961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AC-DiT（自适应协调扩散变换器），用于增强移动基础和操作器的协调，以实现端到端的移动操作。&lt;h4&gt;背景&lt;/h4&gt;移动操作在家庭任务中越来越受到关注，但现有方法在协调移动底座和机械臂方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在协调移动底座和操作器方面的不足，实现更有效的移动操作。&lt;h4&gt;方法&lt;/h4&gt;AC-DiT通过以下方法增强协调：1. 引入移动到身体的条件机制，以预测全身动作；2. 设计感知感知的多模态条件策略，动态调整不同2D视觉图像和3D点云之间的融合权重。&lt;h4&gt;主要发现&lt;/h4&gt;AC-DiT能够有效地处理移动基础对操作器控制的影响，并满足不同阶段移动操作的多模态感知需求。&lt;h4&gt;结论&lt;/h4&gt;AC-DiT在模拟和现实世界的移动操作任务中得到了验证，证明了其在提高移动操作性能方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;最近，移动操作因其能够在家庭任务中实现语言条件化机器人控制而越来越受到关注。然而，现有的方法在协调移动底座和机械臂方面仍然面临挑战，这主要是因为两个限制。一方面，它们未能明确地建模移动底座对机械臂控制的影响，这容易在高自由度下导致错误累积。另一方面，它们将整个移动操作过程视为相同的视觉观察模式（例如，要么全部为2D，要么全部为3D），忽视了在移动操作的不同阶段存在不同的多模态感知需求。为了解决这个问题，我们提出了自适应协调扩散变换器（AC-DiT），它增强了移动基础和操作器之间的协调，以实现端到端的移动操作。首先，由于移动底座的运动直接影响操作器的动作，我们引入了一种移动到身体的条件机制，该机制指导模型首先提取底座运动表示，然后将其用作预测全身动作的上下文先验。这使得全身控制能够考虑到移动底座运动的影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件策略，动态调整各种2D视觉图像和3D点云之间的融合权重，从而产生适合当前感知需求的外观特征。这使得模型能够，例如，当语义信息对动作预测至关重要时，更多地依赖于2D输入，而当需要精确的空间理解时，则更多地依赖于3D几何信息。我们通过在模拟和现实世界的移动操作任务上进行的广泛实验验证了AC-DiT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, mobile manipulation has attracted increasing attention for enablinglanguage-conditioned robotic control in household tasks. However, existingmethods still face challenges in coordinating mobile base and manipulator,primarily due to two limitations. On the one hand, they fail to explicitlymodel the influence of the mobile base on manipulator control, which easilyleads to error accumulation under high degrees of freedom. On the other hand,they treat the entire mobile manipulation process with the same visualobservation modality (e.g., either all 2D or all 3D), overlooking the distinctmultimodal perception requirements at different stages during mobilemanipulation. To address this, we propose the Adaptive Coordination DiffusionTransformer (AC-DiT), which enhances mobile base and manipulator coordinationfor end-to-end mobile manipulation. First, since the motion of the mobile basedirectly influences the manipulator's actions, we introduce a mobility-to-bodyconditioning mechanism that guides the model to first extract base motionrepresentations, which are then used as context prior for predicting whole-bodyactions. This enables whole-body control that accounts for the potential impactof the mobile base's motion. Second, to meet the perception requirements atdifferent stages of mobile manipulation, we design a perception-awaremultimodal conditioning strategy that dynamically adjusts the fusion weightsbetween various 2D visual images and 3D point clouds, yielding visual featurestailored to the current perceptual needs. This allows the model to, forexample, adaptively rely more on 2D inputs when semantic information is crucialfor action prediction, while placing greater emphasis on 3D geometricinformation when precise spatial understanding is required. We validate AC-DiTthrough extensive experiments on both simulated and real-world mobilemanipulation tasks.</description>
      <author>example@mail.com (Sixiang Chen, Jiaming Liu, Siyuan Qian, Han Jiang, Lily Li, Renrui Zhang, Zhuoyang Liu, Chenyang Gu, Chengkai Hou, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.01961v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Kwai Keye-VL Technical Report</title>
      <link>http://arxiv.org/abs/2507.01949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report: https://github.com/Kwai-Keye/Keye&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Kwai Keye-VL是一个8亿参数的多模态基础模型，旨在提高短视频理解能力，同时保持强大的通用视觉语言能力。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在静态图像上表现出色，但在理解动态、信息密集的短视频方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;填补短视频理解能力的差距。&lt;h4&gt;方法&lt;/h4&gt;Keye-VL基于超过6000亿token的高质量数据集和创新的训练方法。训练方法包括四个阶段的预训练过程和两个阶段的后训练过程。后训练阶段包括增强基础能力（如指令遵循）和高级推理，其中使用了五种模式的数据混合，以及后续的强化学习和对齐步骤。&lt;h4&gt;主要发现&lt;/h4&gt;Keye-VL在公共视频基准测试中取得了最先进的成果，并在基于图像的一般任务中保持高度竞争力。此外，Keye-VL在针对现实世界短视频场景的新基准测试KC-MMBench中显示出显著优势。&lt;h4&gt;结论&lt;/h4&gt;Kwai Keye-VL是一个有效的短视频理解模型，具有广泛的适用性和高性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Multimodal Large Language Models (MLLMs) demonstrate remarkablecapabilities on static images, they often fall short in comprehending dynamic,information-dense short-form videos, a dominant medium in today's digitallandscape. To bridge this gap, we introduce \textbf{Kwai Keye-VL}, an8-billion-parameter multimodal foundation model engineered for leading-edgeperformance in short-video understanding while maintaining robustgeneral-purpose vision-language abilities. The development of Keye-VL rests ontwo core pillars: a massive, high-quality dataset exceeding 600 billion tokenswith a strong emphasis on video, and an innovative training recipe. This recipefeatures a four-stage pre-training process for solid vision-language alignment,followed by a meticulous two-phase post-training process. The firstpost-training stage enhances foundational capabilities like instructionfollowing, while the second phase focuses on stimulating advanced reasoning. Inthis second phase, a key innovation is our five-mode ``cold-start'' datamixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``thinkwith image'', and high-quality video data. This mixture teaches the model todecide when and how to reason. Subsequent reinforcement learning (RL) andalignment steps further enhance these reasoning capabilities and correctabnormal model behaviors, such as repetitive outputs. To validate our approach,we conduct extensive evaluations, showing that Keye-VL achievesstate-of-the-art results on public video benchmarks and remains highlycompetitive on general image-based tasks (Figure 1). Furthermore, we developand release the \textbf{KC-MMBench}, a new benchmark tailored for real-worldshort-video scenarios, where Keye-VL shows a significant advantage.</description>
      <author>example@mail.com (Kwai Keye Team, Biao Yang, Bin Wen, Changyi Liu, Chenglong Chu, Chengru Song, Chongling Rao, Chuan Yi, Da Li, Dunju Zang, Fan Yang, Guorui Zhou, Hao Peng, Haojie Ding, Jiaming Huang, Jiangxia Cao, Jiankang Chen, Jingyun Hua, Jin Ouyang, Kaibing Chen, Kaiyu Jiang, Kaiyu Tang, Kun Gai, Shengnan Zhang, Siyang Mao, Sui Huang, Tianke Zhang, Tingting Gao, Wei Chen, Wei Yuan, Xiangyu Wu, Xiao Hu, Xingyu Lu, Yang Zhou, Yi-Fan Zhang, Yiping Yang, Yulong Chen, Zhenhua Wu, Zhenyu Li, Zhixin Ling, Ziming Li, Dehua Ma, Di Xu, Haixuan Gao, Hang Li, Jiawei Guo, Jing Wang, Lejian Ren, Muhao Wei, Qianqian Wang, Qigen Hu, Shiyao Wang, Tao Yu, Xinchen Luo, Yan Li, Yiming Liang, Yuhang Hu, Zeyi Lu, Zhuoran Yang, Zixing Zhang)</author>
      <guid isPermaLink="false">2507.01949v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>TurboReg: TurboClique for Robust and Efficient Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2507.01439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV-2025 Accepted Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速且鲁棒的点云配准算法TurboReg，通过使用轻量级的TurboClique和Pivot-Guided Search (PGS)算法来提高配准效率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于最大团搜索的不兼容图方法在点云配准中具有较高的召回率，但时间复杂度呈指数增长，限制了其在时间敏感应用中的使用。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了TurboReg算法，以提高配准速度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;TurboReg算法包括定义TurboClique作为高度约束兼容图中的3-团，以及使用PGS算法来选择匹配对作为基准点，从而有效地引导搜索过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，TurboReg在多个真实数据集上实现了最先进的性能，同时速度提升显著。例如，在3DMatch+FCGF数据集上，TurboReg比3DMAC快208.22倍，同时实现了更高的召回率。&lt;h4&gt;结论&lt;/h4&gt;TurboReg是一种有效且高效的点云配准算法，适用于时间敏感的应用。&lt;h4&gt;翻译&lt;/h4&gt;Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC^2 scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates 208.22 times faster than 3DMAC while also achieving higher recall. Our code is accessible at https://github.com/Laka-3DV/TurboReg/TurboReg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in correspondence-based Point CloudRegistration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential timecomplexity, limiting their use in time-sensitive applications. To address thischallenge, we propose a fast and robust estimator, TurboReg, built upon a novellightweight clique, TurboClique, and a highly parallelizable Pivot-GuidedSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within ahighly-constrained compatibility graph. The lightweight nature of the 3-cliqueallows for efficient parallel searching, and the highly-constrainedcompatibility graph ensures robust spatial consistency for stabletransformation estimation. Next, PGS selects matching pairs with high SC$^2$scores as pivots, effectively guiding the search toward TurboCliques withhigher inlier ratios. Moreover, the PGS algorithm has linear time complexityand is significantly more efficient than the maximal clique search withexponential time complexity. Extensive experiments show that TurboReg achievesstate-of-the-art performance across multiple real-world datasets, withsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achievinghigher recall. Our code is accessible at\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.</description>
      <author>example@mail.com (Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li)</author>
      <guid isPermaLink="false">2507.01439v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2507.01308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 17th IEEE International Conference on Advanced  Computational Intelligence (ICACI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多矢量地图元素的运动预测模型，旨在提高自动驾驶中的轨迹预测准确性。&lt;h4&gt;背景&lt;/h4&gt;当前的运动预测模型大多基于车道中心线的主要表示，这限制了它们捕捉关键道路环境和交通规则的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够更全面地表示驾驶环境的运动预测模型，以支持自动驾驶车辆在复杂交通场景中做出明智决策。&lt;h4&gt;方法&lt;/h4&gt;提出了一种有效的特征融合策略，用于合并不同矢量地图组件的信息，并开发了一种有效的剪枝机制，以过滤与目标代理最相关的地图连接，从而在保持必要空间和语义关系的同时提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法克服了基于车道中心线模型的局限性，提供了更丰富、更有效的驾驶环境表示，并在Argoverse 2运动预测数据集上实现了竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究推动了自动驾驶车辆运动预测的前沿，通过实验验证了所提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Accurate motion forecasting is critical for safe and efficient autonomous driving, enabling vehicles to predict future trajectories and make informed decisions in complex traffic scenarios. Most of the current designs of motion prediction models are based on the major representation of lane centerlines, which limits their capability to capture critical road environments and traffic rules and constraints. In this work, we propose an enhanced motion forecasting model informed by multiple vector map elements, including lane boundaries and road edges, that facilitates a richer and more complete representation of driving environments. An effective feature fusion strategy is developed to merge information in different vector map components, where the model learns holistic information on road structures and their interactions with agents. Since encoding more information about the road environment increases memory usage and is computationally expensive, we developed an effective pruning mechanism that filters the most relevant map connections to the target agent, ensuring computational efficiency while maintaining essential spatial and semantic relationships for accurate trajectory prediction. Overcoming the limitations of lane centerline-based models, our method provides a more informative and efficient representation of the driving environment and advances the state of the art for autonomous vehicle motion forecasting. We verify our approach with extensive experiments on the Argoverse 2 motion forecasting dataset, where our method maintains competitiveness on AV2 while achieving improved performance. Index Terms-Autonomous driving, trajectory prediction, vector map elements, road topology, connection pruning, Argoverse 2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate motion forecasting is critical for safe and efficient autonomousdriving, enabling vehicles to predict future trajectories and make informeddecisions in complex traffic scenarios. Most of the current designs of motionprediction models are based on the major representation of lane centerlines,which limits their capability to capture critical road environments and trafficrules and constraints. In this work, we propose an enhanced motion forecastingmodel informed by multiple vector map elements, including lane boundaries androad edges, that facilitates a richer and more complete representation ofdriving environments. An effective feature fusion strategy is developed tomerge information in different vector map components, where the model learnsholistic information on road structures and their interactions with agents.Since encoding more information about the road environment increases memoryusage and is computationally expensive, we developed an effective pruningmechanism that filters the most relevant map connections to the target agent,ensuring computational efficiency while maintaining essential spatial andsemantic relationships for accurate trajectory prediction. Overcoming thelimitations of lane centerline-based models, our method provides a moreinformative and efficient representation of the driving environment andadvances the state of the art for autonomous vehicle motion forecasting. Weverify our approach with extensive experiments on the Argoverse 2 motionforecasting dataset, where our method maintains competitiveness on AV2 whileachieving improved performance.  Index Terms-Autonomous driving, trajectory prediction, vector map elements,road topology, connection pruning, Argoverse 2.</description>
      <author>example@mail.com (Muhammad Atta ur Rahman, Dooseop Choi, KyoungWook Min)</author>
      <guid isPermaLink="false">2507.01308v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>When Does Pruning Benefit Vision Representations?</title>
      <link>http://arxiv.org/abs/2507.01722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了剪枝对视觉模型的影响，从可解释性、无监督对象发现和与人类感知的对齐三个关键维度进行探讨。&lt;h4&gt;背景&lt;/h4&gt;剪枝被广泛用于降低深度学习模型的复杂性，但其对可解释性和表示学习的影响尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究剪枝如何影响视觉模型，并分析其在可解释性、无监督对象发现和与人类感知对齐方面的作用。&lt;h4&gt;方法&lt;/h4&gt;分析不同的视觉网络架构，研究不同稀疏度水平对特征归因可解释性的影响；探索剪枝是否促进更简洁和结构化的表示，通过丢弃冗余信息来提高无监督对象发现；评估剪枝是否增强了模型表示与人类感知之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;发现存在“甜点”区域，在这些区域中，稀疏模型展现出更高的可解释性、下游泛化能力和与人类感知的对齐。然而，这些区域高度依赖于网络架构及其可训练参数的数量。&lt;h4&gt;结论&lt;/h4&gt;剪枝与这三个维度之间存在复杂的相互作用，强调了研究剪枝何时以及如何对视觉表示有益的重要性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了剪枝对深度学习模型复杂性的降低及其对可解释性和表示学习的影响，并从可解释性、无监督对象发现和与人类感知对齐三个方面探讨了剪枝对视觉模型的影响。研究发现，剪枝可以促进模型的可解释性、泛化能力和与人类感知的对齐，但具体效果取决于网络架构和可训练参数的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pruning is widely used to reduce the complexity of deep learning models, butits effects on interpretability and representation learning remain poorlyunderstood. This paper investigates how pruning influences vision models acrossthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,and (iii) alignment with human perception. We first analyze different visionnetwork architectures to examine how varying sparsity levels affect featureattribution interpretability methods. Additionally, we explore whether pruningpromotes more succinct and structured representations, potentially improvingunsupervised object discovery by discarding redundant information whilepreserving essential features. Finally, we assess whether pruning enhances thealignment between model representations and human perception, investigatingwhether sparser models focus on more discriminative features similarly tohumans. Our findings also reveal the presence of sweet spots, where sparsemodels exhibit higher interpretability, downstream generalization and humanalignment. However, these spots highly depend on the network architectures andtheir size in terms of trainable parameters. Our results suggest a complexinterplay between these three dimensions, highlighting the importance ofinvestigating when and how pruning benefits vision representations.</description>
      <author>example@mail.com (Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto)</author>
      <guid isPermaLink="false">2507.01722v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP</title>
      <link>http://arxiv.org/abs/2507.01912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 tables, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种信息融合框架，通过整合多季节结构数据来支持整个生长季节的机器人化和自动化作物负载管理。&lt;h4&gt;背景&lt;/h4&gt;在果园自动化中，树冠季节的密集树冠会严重遮挡树木结构，限制了机器视觉系统对树干和树枝等树冠各部分的可见性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在整个生长季节支持机器人化和自动化作物负载管理的信息融合框架。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了休眠期和树冠期的RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。YOLOv9-Seg的分割输出用于提取深度信息掩码，通过Kinect Fusion实现准确的3D点云重建；然后使用Fast GICP对每个季节重建的模型进行对齐，以实现空间一致的多季节融合。&lt;h4&gt;主要发现&lt;/h4&gt;YOLOv9-Seg模型在休眠季节数据集上对树干实现了0.0047的平均均方误差和高达0.78的分割mAP@50分数。Kinect Fusion能够精确地重建树木几何形状，与现场测量的均方根误差（RMSE）分别为5.23毫米（树干直径）、4.50毫米（树枝直径）和13.72毫米（树枝间距）。Fast GICP实现了精确的跨季节注册，最小拟合分数为0.00197，即使在生长季节的严重遮挡下，也能实现综合的树木结构建模。&lt;h4&gt;结论&lt;/h4&gt;融合的结构表示使机器人系统能够访问其他情况下被遮挡的建筑信息，从而提高了修剪、疏伐和其他自动化果园操作的精度。&lt;h4&gt;翻译&lt;/h4&gt;在果园自动化中，树冠季节的密集树冠严重遮挡了树木结构，限制了机器视觉系统对树干和树枝等树冠各部分的可见性。然而，在树木落叶的休眠季节，树冠结构更加开放和可见。本研究提出了一种信息融合框架，该框架整合了多季节结构数据，以支持整个生长季节的机器人化和自动化作物负载管理。该框架结合了休眠期和树冠期的RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。YOLOv9-Seg的分割输出用于提取深度信息掩码，通过Kinect Fusion实现准确的3D点云重建；然后使用Fast GICP对每个季节重建的模型进行对齐，以实现空间一致的多季节融合。YOLOv9-Seg模型在休眠季节数据集上对树干实现了0.0047的平均均方误差和高达0.78的分割mAP@50分数。Kinect Fusion能够精确地重建树木几何形状，与现场测量的均方根误差（RMSE）分别为5.23毫米（树干直径）、4.50毫米（树枝直径）和13.72毫米（树枝间距）。Fast GICP实现了精确的跨季节注册，最小拟合分数为0.00197，即使在生长季节的严重遮挡下，也能实现综合的树木结构建模。这种融合的结构表示使机器人系统能够访问其他情况下被遮挡的建筑信息，从而提高了修剪、疏伐和其他自动化果园操作的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In orchard automation, dense foliage during the canopy season severelyoccludes tree structures, minimizing visibility to various canopy parts such astrunks and branches, which limits the ability of a machine vision system.However, canopy structure is more open and visible during the dormant seasonwhen trees are defoliated. In this work, we present an information fusionframework that integrates multi-seasonal structural data to support robotic andautomated crop load management during the entire growing season. The frameworkcombines high-resolution RGB-D imagery from both dormant and canopy periodsusing YOLOv9-Seg for instance segmentation, Kinect Fusion for 3Dreconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) formodel alignment. Segmentation outputs from YOLOv9-Seg were used to extractdepth-informed masks, which enabled accurate 3D point cloud reconstruction viaKinect Fusion; these reconstructed models from each season were subsequentlyaligned using Fast GICP to achieve spatially coherent multi-season fusion. TheYOLOv9-Seg model, trained on manually annotated images, achieved a mean squarederror (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks indormant season dataset. Kinect Fusion enabled accurate reconstruction of treegeometry, validated with field measurements resulting in root mean squareerrors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonalregistration with a minimum fitness score of 0.00197, allowing integrated,comprehensive tree structure modeling despite heavy occlusions during thegrowing season. This fused structural representation enables robotic systems toaccess otherwise obscured architectural information, improving the precision ofpruning, thinning, and other automated orchard operations.</description>
      <author>example@mail.com (Ranjan Sapkota, Zhichao Meng, Martin Churuvija, Xiaoqiang Du, Zenghong Ma, Manoj Karkee)</author>
      <guid isPermaLink="false">2507.01912v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</title>
      <link>http://arxiv.org/abs/2507.01945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的长动画自动着色框架LongAnimation，用于解决长动画着色中的颜色一致性问题。&lt;h4&gt;背景&lt;/h4&gt;动画着色在动画产业中至关重要，但长动画着色成本高，现有研究主要针对短动画着色，采用局部范式，但忽略了全局信息，导致颜色一致性差。&lt;h4&gt;目的&lt;/h4&gt;通过动态全局-局部范式，动态提取与当前生成相关的全局颜色一致性特征，以实现理想的长动画颜色一致性。&lt;h4&gt;方法&lt;/h4&gt;LongAnimation框架主要包括SketchDiT、动态全局-局部记忆（DGLM）和颜色一致性奖励。SketchDiT捕捉混合参考特征以支持DGLM模块；DGLM模块使用长视频理解模型动态压缩全局历史特征，并自适应地融合当前生成特征；颜色一致性奖励用于细化颜色一致性；在推理过程中，提出颜色一致性融合以平滑视频段过渡。&lt;h4&gt;主要发现&lt;/h4&gt;LongAnimation在短期（14帧）和长期（平均500帧）动画上的实验表明，该框架在保持开放域动画着色任务中的短期和长期颜色一致性方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;LongAnimation框架能够有效解决长动画着色中的颜色一致性问题，具有较高的研究价值。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes that the proposed LongAnimation framework effectively addresses the issue of color consistency in long animation coloring, demonstrating its effectiveness in maintaining short-term and long-term color consistency for open-domain animation coloring tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animation colorization is a crucial part of real animation industryproduction. Long animation colorization has high labor costs. Therefore,automated long animation colorization based on the video generation model hassignificant research value. Existing studies are limited to short-termcolorization. These studies adopt a local paradigm, fusing overlapping featuresto achieve smooth transitions between local segments. However, the localparadigm neglects global information, failing to maintain long-term colorconsistency. In this study, we argue that ideal long-term color consistency canbe achieved through a dynamic global-local paradigm, i.e., dynamicallyextracting global color-consistent features relevant to the current generation.Specifically, we propose LongAnimation, a novel framework, which mainlyincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a ColorConsistency Reward. The SketchDiT captures hybrid reference features to supportthe DGLM module. The DGLM module employs a long video understanding model todynamically compress global historical features and adaptively fuse them withthe current generation features. To refine the color consistency, we introducea Color Consistency Reward. During inference, we propose a color consistencyfusion to smooth the video segment transition. Extensive experiments on bothshort-term (14 frames) and long-term (average 500 frames) animations show theeffectiveness of LongAnimation in maintaining short-term and long-term colorconsistency for open-domain animation colorization task. The code can be foundat https://cn-makers.github.io/long_animation_web/.</description>
      <author>example@mail.com (Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao)</author>
      <guid isPermaLink="false">2507.01945v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2507.01673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FACET-VLM是一种用于3D/4D面部表情识别的视觉-语言框架，通过整合多视图面部表示学习和自然语言提示的语义引导，提高了识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;3D和4D领域的面部表情识别在情感计算中是一个挑战，因为面部动态的空间和时间复杂性。这一领域的成功对于人类行为理解、医疗监测和人与计算机交互的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出FACET-VLM框架，以解决3D/4D面部表情识别的挑战，并提高其在多种场景下的准确性。&lt;h4&gt;方法&lt;/h4&gt;FACET-VLM引入了三个关键组件：交叉视图语义聚合（CVSA）用于视图一致融合，多视图文本引导融合（MTGF）用于语义对齐面部情绪，以及多视图一致性损失以强制视图之间的结构一致性。&lt;h4&gt;主要发现&lt;/h4&gt;FACET-VLM在多个基准测试中实现了最先进的准确性，包括BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous。此外，它还扩展到了4D微表情识别（MER）领域，并在4DME数据集上表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验结果证实了FACET-VLM框架中每个组件的有效性和重大贡献。总的来说，FACET-VLM为静态和自发设置中的多模态面部表情识别提供了一个稳健、可扩展且高性能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facial expression recognition (FER) in 3D and 4D domains presents asignificant challenge in affective computing due to the complexity of spatialand temporal facial dynamics. Its success is crucial for advancing applicationsin human behavior understanding, healthcare monitoring, and human-computerinteraction. In this work, we propose FACET-VLM, a vision-language frameworkfor 3D/4D FER that integrates multiview facial representation learning withsemantic guidance from natural language prompts. FACET-VLM introduces three keycomponents: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,and a multiview consistency loss to enforce structural coherence across views.Our model achieves state-of-the-art accuracy across multiple benchmarks,including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extendFACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,demonstrating strong performance in capturing subtle, short-lived emotionalcues. The extensive experimental results confirm the effectiveness andsubstantial contributions of each individual component within the framework.Overall, FACET-VLM offers a robust, extensible, and high-performing solutionfor multimodal FER in both posed and spontaneous settings.</description>
      <author>example@mail.com (Muzammil Behzad)</author>
      <guid isPermaLink="false">2507.01673v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.01735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024. Workshop page: https://coda-dataset.github.io/w-coda2024/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在ECCV 2024期间举办的第1届W-CODA研讨会，探讨了下一代自动驾驶角案解决方案。&lt;h4&gt;背景&lt;/h4&gt;研讨会旨在通过最先进的多模态感知和理解技术，探索自动驾驶角案的未来解决方案。&lt;h4&gt;目的&lt;/h4&gt;目的是分享学术和工业界的最新进展和观点，并举办包括角案场景理解和生成在内的双轨挑战。&lt;h4&gt;方法&lt;/h4&gt;研讨会邀请了5位来自学术界和工业界的演讲者，收集研究论文，并举办挑战赛。&lt;h4&gt;主要发现&lt;/h4&gt;这是开创性的工作，旨在不断缩小前沿自动驾驶技术与全面智能、可靠、对角案有鲁棒性的自动驾驶代理之间的差距。&lt;h4&gt;结论&lt;/h4&gt;研讨会通过交流和挑战赛，推进了自动驾驶技术在角案处理方面的研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文介绍了在ECCV 2024期间举办的第1届W-CODA研讨会，旨在探索下一代自动驾驶角案解决方案，通过最先进的多模态感知和理解技术。研讨会邀请了来自学术界和工业界的5位演讲者分享最新进展和观点，并收集研究论文，举办包括角案场景理解和生成在内的双轨挑战。作为开创性工作，研讨会将不断缩小前沿自动驾驶技术与全面智能、可靠、对角案有鲁棒性的自动驾驶代理之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present details of the 1st W-CODA workshop, held inconjunction with the ECCV 2024. W-CODA aims to explore next-generationsolutions for autonomous driving corner cases, empowered by state-of-the-artmultimodal perception and comprehension techniques. 5 Speakers from bothacademia and industry are invited to share their latest progress and opinions.We collect research papers and hold a dual-track challenge, including bothcorner case scene understanding and generation. As the pioneering effort, wewill continuously bridge the gap between frontier autonomous driving techniquesand fully intelligent, reliable self-driving agents robust towards cornercases.</description>
      <author>example@mail.com (Kai Chen, Ruiyuan Gao, Lanqing Hong, Hang Xu, Xu Jia, Holger Caesar, Dengxin Dai, Bingbing Liu, Dzmitry Tsishkou, Songcen Xu, Chunjing Xu, Qiang Xu, Huchuan Lu, Dit-Yan Yeung)</author>
      <guid isPermaLink="false">2507.01735v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ARIG: Autoregressive Interactive Head Generation for Real-time Conversations</title>
      <link>http://arxiv.org/abs/2507.00472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025. Homepage: https://jinyugy21.github.io/ARIG/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自回归（AR）的帧级框架ARIG，用于实现具有更好交互真实感的实时交互头部生成。&lt;h4&gt;背景&lt;/h4&gt;面对面的交流促进了交互头部生成的研究。虚拟代理能够根据其他用户的音频或运动信号以及自身的音频或运动信号生成运动响应。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在信号获取、上下文行为理解以及切换平滑度方面的局限性，实现实时和真实的头部生成。&lt;h4&gt;方法&lt;/h4&gt;采用非矢量量化自回归过程建模运动预测，使用扩散过程表示运动分布，提高预测精度。通过双向集成学习和长距离的上下文理解实现交互行为理解（IBU），使用语音活动信号和IBU的上下文特征来理解实际对话中的各种状态（如打断、反馈、暂停等），作为最终渐进式运动预测的条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了该模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;ARIG框架能够实现具有更好交互真实感的实时头部生成，有效解决了现有方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face-to-face communication, as a common human activity, motivates theresearch on interactive head generation. A virtual agent can generate motionresponses with both listening and speaking capabilities based on the audio ormotion signals of the other user and itself. However, previous clip-wisegeneration paradigm or explicit listener/speaker generator-switching methodshave limitations in future signal acquisition, contextual behavioralunderstanding, and switching smoothness, making it challenging to be real-timeand realistic. In this paper, we propose an autoregressive (AR) basedframe-wise framework called ARIG to realize the real-time generation withbetter interaction realism. To achieve real-time generation, we model motionprediction as a non-vector-quantized AR process. Unlike discrete codebook-indexprediction, we represent motion distribution using diffusion procedure,achieving more accurate predictions in continuous space. To improve interactionrealism, we emphasize interactive behavior understanding (IBU) and detailedconversational state understanding (CSU). In IBU, based on dual-trackdual-modal signals, we summarize short-range behaviors throughbidirectional-integrated learning and perform contextual understanding overlong ranges. In CSU, we use voice activity signals and context features of IBUto understand the various states (interruption, feedback, pause, etc.) thatexist in actual conversations. These serve as conditions for the finalprogressive motion prediction. Extensive experiments have verified theeffectiveness of our model.</description>
      <author>example@mail.com (Ying Guo, Xi Liu, Cheng Zhen, Pengfei Yan, Xiaoming Wei)</author>
      <guid isPermaLink="false">2507.00472v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.01006v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了GLM-4.1V-Thinking，这是一种旨在推进通用多模态理解和推理的视觉语言模型（VLM）。&lt;h4&gt;背景&lt;/h4&gt;多模态理解和推理在多个领域具有重要意义，但现有的模型在性能上存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够提升通用多模态理解和推理能力的视觉语言模型。&lt;h4&gt;方法&lt;/h4&gt;通过大规模预训练开发了一个强大的视觉基础模型，并提出了一种名为强化学习与课程采样的方法（RLCS）来解锁模型潜力，增强其在各种任务上的能力。&lt;h4&gt;主要发现&lt;/h4&gt;GLM-4.1V-9B-Thinking在28个公共基准测试中表现出色，几乎在所有任务上都优于Qwen2.5-VL-7B，并在18个基准测试中与Qwen2.5-VL-72B相当或更优。此外，在包括长文档理解和STEM推理在内的挑战性任务上，其性能与GPT-4o等闭源模型相比具有竞争力或优势。&lt;h4&gt;结论&lt;/h4&gt;GLM-4.1V-Thinking模型在多模态理解和推理方面具有强大的能力，并在多个任务上达到了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding. We open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at https://github.com/THUDM/GLM-4.1V-Thinking.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GLM-4.1V-Thinking, a vision-language model (VLM) designed toadvance general-purpose multimodal understanding and reasoning. In this report,we share our key findings in the development of the reasoning-centric trainingframework. We first develop a capable vision foundation model with significantpotential through large-scale pre-training, which arguably sets the upper boundfor the final performance. We then propose Reinforcement Learning withCurriculum Sampling (RLCS) to unlock the full potential of the model, leadingto comprehensive capability enhancement across a diverse range of tasks,including STEM problem solving, video understanding, content recognition,coding, grounding, GUI-based agents, and long document understanding. Weopen-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performanceamong models of comparable size. In a comprehensive evaluation across 28 publicbenchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks andachieves comparable or even superior performance on 18 benchmarks relative tothe significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking alsodemonstrates competitive or superior performance compared to closed-sourcemodels such as GPT-4o on challenging tasks including long documentunderstanding and STEM reasoning, further underscoring its strong capabilities.Code, models and more information are released athttps://github.com/THUDM/GLM-4.1V-Thinking.</description>
      <author>example@mail.com (GLM-V Team, :, Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, Letian Gong, Leyi Pan, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang)</author>
      <guid isPermaLink="false">2507.01006v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multi-Exposure High Dynamic Range Imaging with Overlapped Codebook for Improved Representation Learning</title>
      <link>http://arxiv.org/abs/2507.01588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to International Conference on Pattern Recognition.  Springer, Cham, 2025 (ICPR 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的HDR成像技术，通过使用重叠码本方案（OLC）和HDR网络，从低动态范围（LDR）图像中生成更逼真的HDR图像，并提高了饱和区域的补偿和整体视觉质量。&lt;h4&gt;背景&lt;/h4&gt;HDR成像技术旨在从低动态范围（LDR）输入中创建逼真的HDR图像。多曝光HDR成像通过使用同一场景的多帧LDR图像来提高重建性能，但帧间存在运动差异和不同曝光设置可能导致饱和区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HDR成像方法，以改善从LDR图像到HDR图像的转换，并提高视觉质量。&lt;h4&gt;方法&lt;/h4&gt;本文首先提出了一种重叠码本（OLC）方案，用于提高VQGAN框架学习隐式HDR表示的能力。进一步开发了一个新的HDR网络，该网络利用预训练的VQ网络和OLC生成的HDR表示。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在多个数据集上进行了广泛测试，结果显示在定性和定量方面均优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提升HDR图像的生成质量，为从LDR图像到HDR图像的转换提供了新的思路和解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-78125-4_19&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High dynamic range (HDR) imaging technique aims to create realistic HDRimages from low dynamic range (LDR) inputs. Specifically, Multi-exposure HDRimaging uses multiple LDR frames taken from the same scene to improvereconstruction performance. However, there are often discrepancies in motionamong the frames, and different exposure settings for each capture can lead tosaturated regions. In this work, we first propose an Overlapped codebook (OLC)scheme, which can improve the capability of the VQGAN framework for learningimplicit HDR representations by modeling the common exposure bracket process inthe shared codebook structure. Further, we develop a new HDR network thatutilizes HDR representations obtained from a pre-trained VQ network and OLC.This allows us to compensate for saturated regions and enhance overall visualquality. We have tested our approach extensively on various datasets and havedemonstrated that it outperforms previous methods both qualitatively andquantitatively</description>
      <author>example@mail.com (Keuntek Lee, Jaehyun Park, Nam Ik Cho)</author>
      <guid isPermaLink="false">2507.01588v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective</title>
      <link>http://arxiv.org/abs/2507.01652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的线性注意力机制LASAD，用于图像生成，通过在图像序列中计算位置相关的衰减因子，有效地保留了二维空间关系，提高了图像生成的性能和计算效率。&lt;h4&gt;背景&lt;/h4&gt;自回归模型在图像生成中受到关注，但现有的AR模型大多依赖于变压器架构，存在计算复杂度和内存开销大的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的线性注意力机制，以减少计算复杂度和内存开销，同时提高图像生成的质量。&lt;h4&gt;方法&lt;/h4&gt;提出LASAD，一种基于空间感知衰减的线性注意力机制，以及基于此机制的LASADGen自动回归图像生成器。&lt;h4&gt;主要发现&lt;/h4&gt;LASAD能够有效地捕捉视觉数据中的长距离依赖关系，提高了图像生成的质量；LASADGen在ImageNet数据集上达到了最先进的图像生成性能和计算效率。&lt;h4&gt;结论&lt;/h4&gt;LASADGen通过结合线性注意力的效率和空间理解能力，在图像生成方面取得了显著进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregressive (AR) models have garnered significant attention in imagegeneration for their ability to effectively capture both local and globalstructures within visual data. However, prevalent AR models predominantly relyon the transformer architectures, which are beset by quadratic computationalcomplexity concerning input sequence length and substantial memory overhead dueto the necessity of maintaining key-value caches. Although linear attentionmechanisms have successfully reduced this burden in language models, ourinitial experiments reveal that they significantly degrade image generationquality because of their inability to capture critical long-range dependenciesin visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), anovel attention mechanism that explicitly preserves genuine 2D spatialrelationships within the flattened image sequences by computingposition-dependent decay factors based on true 2D spatial location rather than1D sequence positions. Based on this mechanism, we present LASADGen, anautoregressive image generator that enables selective attention to relevantspatial contexts with linear complexity. Experiments on ImageNet show LASADGenachieves state-of-the-art image generation performance and computationalefficiency, bridging the gap between linear attention's efficiency and spatialunderstanding needed for high-quality generation.</description>
      <author>example@mail.com (Yuxin Mao, Zhen Qin, Jinxing Zhou, Hui Deng, Xuyang Shen, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai)</author>
      <guid isPermaLink="false">2507.01652v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs</title>
      <link>http://arxiv.org/abs/2507.00817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了CAVALRY-V，一个针对视频多模态大语言模型（V-MLLMs）的对抗攻击框架，该框架旨在解决V-MLLMs在跨模态理解方面的对抗攻击问题。&lt;h4&gt;背景&lt;/h4&gt;V-MLLMs在时间和跨模态理解方面表现出色，但其对对抗攻击的脆弱性尚未得到充分研究，这归因于其复杂的跨模态推理机制、时间依赖性和计算限制。&lt;h4&gt;目的&lt;/h4&gt;提出CAVALRY-V框架，直接针对V-MLLMs中视觉感知和语言生成之间的关键接口。&lt;h4&gt;方法&lt;/h4&gt;CAVALRY-V引入了两个关键创新：(1) 一个双重目标的语义-视觉损失函数，该函数同时破坏模型的文本生成logits和视觉表示以破坏跨模态整合；(2) 一个计算高效的二阶段生成框架，结合大规模预训练的跨模型可迁移性和针对时空一致性的专用微调。&lt;h4&gt;主要发现&lt;/h4&gt;在全面的视频理解基准测试中，CAVALRY-V显著优于现有的攻击方法，在商业系统（如GPT-4.1，Gemini 2.0）和开源模型（如QwenVL-2.5，InternVL-2.5，Llava-Video，Aria，MiniCPM-o-2.6）上实现了平均22.8%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;CAVALRY-V通过隐式的时间一致性建模而不是显式的正则化来实现灵活性，即使在图像理解上也取得了显著的性能提升（平均提高34.4%）。这表明CAVALRY-V可以作为跨模态系统对抗研究的坚实基础方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了Video Multimodal Large Language Models（V-MLLMs）在时间和跨模态理解方面的出色能力，但它们对对抗攻击的脆弱性尚未得到充分探索。本文提出了一种名为CAVALRY-V的新框架，旨在解决V-MLLMs在视觉感知和语言生成之间的关键接口问题。该框架引入了双重目标的语义-视觉损失函数和一个高效的二阶段生成框架，实现了在多个视频理解基准测试中的显著性能提升。CAVALRY-V通过隐式的时间一致性建模提高了灵活性，并在图像理解任务上也取得了显著进步，显示出其在多模态系统对抗研究中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Multimodal Large Language Models (V-MLLMs) have shown impressivecapabilities in temporal reasoning and cross-modal understanding, yet theirvulnerability to adversarial attacks remains underexplored due to uniquechallenges: complex cross-modal reasoning mechanisms, temporal dependencies,and computational constraints. We present CAVALRY-V (Cross-modalLanguage-Vision Adversarial Yielding for Videos), a novel framework thatdirectly targets the critical interface between visual perception and languagegeneration in V-MLLMs. Our approach introduces two key innovations: (1) adual-objective semantic-visual loss function that simultaneously disrupts themodel's text generation logits and visual representations to underminecross-modal integration, and (2) a computationally efficient two-stagegenerator framework that combines large-scale pre-training for cross-modeltransferability with specialized fine-tuning for spatiotemporal coherence.Empirical evaluation on comprehensive video understanding benchmarksdemonstrates that CAVALRY-V significantly outperforms existing attack methods,achieving 22.8% average improvement over the best baseline attacks on bothcommercial systems (GPT-4.1, Gemini 2.0) and open-source models (QwenVL-2.5,InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6). Our framework achievesflexibility through implicit temporal coherence modeling rather than explicitregularization, enabling significant performance improvements even on imageunderstanding (34.4% average gain). This capability demonstrates CAVALRY-V'spotential as a foundational approach for adversarial research across multimodalsystems.</description>
      <author>example@mail.com (Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim)</author>
      <guid isPermaLink="false">2507.00817v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Robust Multi-generation Learned Compression of Point Cloud Attribute</title>
      <link>http://arxiv.org/abs/2507.01320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了学习点云属性压缩的多代压缩问题，提出了解决质量退化的方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有学习点云属性压缩方法主要关注单次率失真优化，忽视了多代压缩场景中的累积失真问题。&lt;h4&gt;目的&lt;/h4&gt;首次研究学习点云属性压缩中的多代压缩问题。&lt;h4&gt;方法&lt;/h4&gt;提出映射幂等性约束和转换可逆性约束，以及潜在变量一致性约束，以增强多代压缩的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;识别出量化引起的非幂等性和转换不可逆性是导致多代压缩质量退化的两个主要因素。&lt;h4&gt;结论&lt;/h4&gt;提出的方案可以有效抑制多代损失，同时保持与基线模型相当的单次率失真性能。&lt;h4&gt;翻译&lt;/h4&gt;Existing learned point cloud attribute compression methods primarily focus on single-pass rate-distortion optimization, while overlooking the issue of cumulative distortion in multi-generation compression scenarios. This paper, for the first time, investigates the multi-generation issue in learned point cloud attribute compression. We identify two primary factors contributing to quality degradation in multi-generation compression: quantization-induced non-idempotency and transformation irreversibility. To address the former, we propose a Mapping Idempotency Constraint, that enables the network to learn the complete compression-decompression mapping, enhancing its robustness to repeated processes. To address the latter, we introduce a Transformation Reversibility Constraint, which preserves reversible information flow via a quantization-free training path. Further, we propose a Latent Variable Consistency Constraint which enhances the multi-generation compression robustness by incorporating a decompression-compression cross-generation path and a latent variable consistency loss term. Extensive experiments conducted on the Owlii and 8iVFB datasets verify that the proposed methods can effectively suppress multi-generation loss while maintaining single-pass rate-distortion performance comparable to baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing learned point cloud attribute compression methods primarily focus onsingle-pass rate-distortion optimization, while overlooking the issue ofcumulative distortion in multi-generation compression scenarios. This paper,for the first time, investigates the multi-generation issue in learned pointcloud attribute compression. We identify two primary factors contributing toquality degradation in multi-generation compression: quantization-inducednon-idempotency and transformation irreversibility. To address the former, wepropose a Mapping Idempotency Constraint, that enables the network to learn thecomplete compression-decompression mapping, enhancing its robustness torepeated processes. To address the latter, we introduce a TransformationReversibility Constraint, which preserves reversible information flow via aquantization-free training path. Further, we propose a Latent VariableConsistency Constraint which enhances the multi-generation compressionrobustness by incorporating a decompression-compression cross-generation pathand a latent variable consistency loss term. Extensive experiments conducted onthe Owlii and 8iVFB datasets verify that the proposed methods can effectivelysuppress multi-generation loss while maintaining single-pass rate-distortionperformance comparable to baseline models.</description>
      <author>example@mail.com (Xiangzuo Liu, Zhikai Liu, PengPeng Yu, Ruishan Huang, Fan Liang)</author>
      <guid isPermaLink="false">2507.01320v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.00525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Box-QAymo的箱式引用数据集和基准，用于评估和微调视觉语言模型在空间和时间推理方面的能力，以应对现实场景中用户指定的对象查询。&lt;h4&gt;背景&lt;/h4&gt;可解释的通信对于安全可靠的自动驾驶至关重要，但现有的视觉语言模型在理想化假设下运行，难以捕捉现实场景中的用户意图。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效与用户沟通的、更稳健且可解释的自动驾驶系统。&lt;h4&gt;方法&lt;/h4&gt;Box-QAymo通过用户绘制边界框来表达意图，提供了一种快速直观的界面来查询复杂场景中的特定对象。评估协议包括基本能力检查、属性预测、目标实例的运动理解以及跨帧对象间动态的时空运动推理。&lt;h4&gt;主要发现&lt;/h4&gt;当前视觉语言模型在感知问题查询上存在显著局限性，这突显了实现现实世界性能的差距。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发更稳健且可解释的自动驾驶系统提供了基础，这些系统能够在现实条件下有效地与用户沟通。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可解释的通信对于安全可靠的自动驾驶至关重要，但当前视觉语言模型（VLMs）通常在理想化假设下运行，难以捕捉现实场景中的用户意图。现有的以驾驶为导向的VQA数据集仅限于全场景描述或航点预测，这阻碍了对VLMs是否能回应局部用户驱动查询的评估。我们引入了Box-QAymo，这是一个箱式引用数据集和基准，旨在评估和微调VLMs在用户指定对象上的空间和时间推理能力。用户通过绘制边界框来表达意图，为复杂场景中的聚焦查询提供了一种快速直观的界面。具体来说，我们提出了一种分层评估协议，从二元合理性检查问题开始，以评估基本模型能力，然后逐步发展到（1）对箱式引用对象的属性预测，（2）对目标实例的运动理解，以及（3）跨帧对象间动态的时空运动推理。为此，我们通过众包细粒度对象类别和视觉属性，这些属性反映了驾驶员遇到的复杂性，并提取对象轨迹来构建基于时间的QA对。通过负采样、时间一致性检查和难度感知平衡的严格质量控制，保证了数据集的稳健性和多样性。我们的全面评估揭示了当前VLMs在感知问题查询上的显著局限性，突显了实现现实世界性能的差距。这项工作为开发更稳健且可解释的自动驾驶系统提供了基础，这些系统能够在现实条件下有效地与用户沟通。项目页面和数据集可在https://djamahl99.github.io/qaymo-pages/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable communication is essential for safe and trustworthy autonomousdriving, yet current vision-language models (VLMs) often operate underidealized assumptions and struggle to capture user intent in real-worldscenarios. Existing driving-oriented VQA datasets are limited to full-scenedescriptions or waypoint prediction, preventing the assessment of whether VLMscan respond to localized user-driven queries. We introduce Box-QAymo, abox-referring dataset and benchmark designed to both evaluate and finetune VLMson spatial and temporal reasoning over user-specified objects. Users expressintent by drawing bounding boxes, offering a fast and intuitive interface forfocused queries in complex scenes. Specifically, we propose a hierarchicalevaluation protocol that begins with binary sanity-check questions to assessbasic model capacities, and progresses to (1) attribute prediction forbox-referred objects, (2) motion understanding of target instances, and (3)spatiotemporal motion reasoning over inter-object dynamics across frames. Tosupport this, we crowd-sourced fine-grained object classes and visualattributes that reflect the complexity drivers encounter, and extract objecttrajectories to construct temporally grounded QA pairs. Rigorous qualitycontrol through negative sampling, temporal consistency checks, anddifficulty-aware balancing guarantee dataset robustness and diversity. Ourcomprehensive evaluation reveals significant limitations in current VLMs whenqueried about perception questions, highlighting the gap in achievingreal-world performance. This work provides a foundation for developing morerobust and interpretable autonomous driving systems that can communicateeffectively with users under real-world conditions. Project page and datasetare available at https://djamahl99.github.io/qaymo-pages/.</description>
      <author>example@mail.com (Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo)</author>
      <guid isPermaLink="false">2507.00525v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>More sophisticated is not always better: comparison of similarity measures for unsupervised learning of pathways in biomolecular simulations</title>
      <link>http://arxiv.org/abs/2507.01725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This preprint is the unedited version of a manuscript that has been  sent to a peer-reviewed scientific journal for consideration as article.  Copyright with the authors and the publisher after publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了四种不同复杂度的相似度度量方法在分子模拟中寻找过程途径的性能，这些方法在分析轨迹数据时被用来识别小分子配体从蛋白质靶点解离的路径。&lt;h4&gt;背景&lt;/h4&gt;在分子模拟中，通过无监督学习方法寻找小分子配体从蛋白质靶点解离路径的过程，需要定义轨迹之间的合适相似度度量。&lt;h4&gt;目的&lt;/h4&gt;评估四种不同相似度度量方法（欧几里得距离、Wasserstein距离、Procrustes分析和动态时间扭曲）在分析两种不同偏置模拟驱动协议（恒速约束分子动力学和引导分子动力学）的轨迹数据时的性能。&lt;h4&gt;方法&lt;/h4&gt;在已知真实聚类簇的链霉亲和素-生物素基准系统中，比较了四种相似度度量方法在聚类性能上的表现；在更复杂的A2a受体-抑制剂系统中，比较了这些方法在揭示有意义的可解释簇方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Wasserstein距离在聚类性能上表现最佳，其次是欧几里得距离，两者都是计算效率最高的相似度度量方法；在A2a受体-抑制剂系统中，最简单的欧几里得距离就足以揭示有意义的可解释簇。&lt;h4&gt;结论&lt;/h4&gt;在链霉亲和素-生物素系统中，Wasserstein距离和欧几里得距离是高效的相似度度量方法；在A2a受体-抑制剂系统中，欧几里得距离足以满足需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finding process pathways in molecular simulations such as the unbinding pathsof small molecule ligands from their binding sites at protein targets in a setof trajectories via unsupervised learning approaches requires the definition ofa suitable similarity measure between trajectories. We here evaluate theperformance of four such measures with varying degree of sophistication, i.e.,Euclidean and Wasserstein distances, Procrustes analysis and dynamical timewarping, when analyzing trajectory data from two different biased simulationdriving protocols in the form of constant velocity constraint targeted MD andsteered MD. In a streptavidin-biotin benchmark system with known ground truthclusters, Wasserstein distances yielded the best clustering performance,closely followed by Euclidean distances, both being the most computationallyefficient similarity measures. In a more complex A2a receptor-inhibitor system,however, the simplest measure, i.e., Euclidean distances, was sufficient toreveal meaningful and interpretable clusters.</description>
      <author>example@mail.com (Miriam Jäger, Steffen Wolf)</author>
      <guid isPermaLink="false">2507.01725v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Bisecle: Binding and Separation in Continual Learning for Video Language Understanding</title>
      <link>http://arxiv.org/abs/2507.00469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 12 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Bisecle，一种用于视频语言持续学习的模型，旨在解决大规模多模态基础模型中的灾难性遗忘和更新冲突问题。&lt;h4&gt;背景&lt;/h4&gt;现有的持续学习框架在大规模多模态基础模型中面临灾难性遗忘和更新冲突的挑战，因为实时视频数据需要模型不断适应新的数据分布和场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的视频语言持续学习方法，以解决灾难性遗忘和更新冲突问题。&lt;h4&gt;方法&lt;/h4&gt;Bisecle模型通过使用多方向监督模块来捕捉更多跨模态关系，并设计了一种对比提示学习方案来隔离特定任务的知识，以促进高效的记忆存储。&lt;h4&gt;主要发现&lt;/h4&gt;Bisecle能够减轻遗忘并增强跨任务的泛化能力，在多个视频问答基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Bisecle模型能够有效地实现视频理解任务中的持续学习，为实时视频数据理解提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Frontier视觉语言模型（VLMs）在视频理解任务上取得了显著进步。然而，现实世界的视频通常以连续演变的数据流形式存在（例如，可穿戴眼镜捕获的动态场景），需要模型不断适应不断变化的数据分布和新的场景。考虑到在新的任务上微调模型的计算成本过高，通常只更新一小部分参数，而大部分模型保持冻结。这在大规模多模态基础模型的持续学习框架中提出了新的挑战，即灾难性遗忘和更新冲突。虽然基础模型在参数高效的持续学习中遇到困难，但人类大脑中的海马体已经进化出高度有效的记忆形成和巩固机制。受海马体中快速绑定和模式分离机制的影响，在这项工作中，我们提出了Bisecle用于视频语言持续学习，其中使用多方向监督模块来捕捉更多的跨模态关系，并设计了一种对比提示学习方案来隔离特定任务的知识，以促进高效的记忆存储。绑定和分离过程进一步增强了VLMs保留复杂经验的能力，使视频理解任务中的持续学习变得稳健和高效。我们对提出的Bisecle进行了彻底的评估，证明了其在多个视频问答基准测试中减轻遗忘并增强跨任务泛化的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Frontier vision-language models (VLMs) have made remarkable improvements invideo understanding tasks. However, real-world videos typically exist ascontinuously evolving data streams (e.g., dynamic scenes captured by wearableglasses), necessitating models to continually adapt to shifting datadistributions and novel scenarios. Considering the prohibitive computationalcosts of fine-tuning models on new tasks, usually, a small subset of parametersis updated while the bulk of the model remains frozen. This poses newchallenges to existing continual learning frameworks in the context of largemultimodal foundation models, i.e., catastrophic forgetting and updateconflict. While the foundation models struggle with parameter-efficientcontinual learning, the hippocampus in the human brain has evolved highlyefficient mechanisms for memory formation and consolidation. Inspired by therapid Binding and pattern separation mechanisms in the hippocampus, in thiswork, we propose Bisecle for video-language continual learning, where amulti-directional supervision module is used to capture more cross-modalrelationships and a contrastive prompt learning scheme is designed to isolatetask-specific knowledge to facilitate efficient memory storage. Binding andseparation processes further strengthen the ability of VLMs to retain complexexperiences, enabling robust and efficient continual learning in videounderstanding tasks. We perform a thorough evaluation of the proposed Bisecle,demonstrating its ability to mitigate forgetting and enhance cross-taskgeneralization on several VideoQA benchmarks.</description>
      <author>example@mail.com (Yue Tan, Xiaoqian Hu, Hao Xue, Celso De Melo, Flora D. Salim)</author>
      <guid isPermaLink="false">2507.00469v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence</title>
      <link>http://arxiv.org/abs/2507.01504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for publication at the 2025 IEEE 28th International  Conference on Intelligent Transportation Systems (ITSC 2025), taking place  during November 18-21, 2025 in Gold Coast, Australia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为cRID的新型跨模态框架，用于检测个人身份信息（PII）并增强行人重识别（Re-ID），以促进自动驾驶系统和AI研究的发展。&lt;h4&gt;背景&lt;/h4&gt;收集和发布街景录音作为开放数据在自动驾驶系统和AI研究中发挥着重要作用，但这些数据集存在隐私风险，尤其是对于行人，因为这些数据集包含了超出生物特征（如面部）的个人信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来检测文本描述的可识别线索，并增强行人重识别，同时减少个人隐私风险。&lt;h4&gt;方法&lt;/h4&gt;cRID结合了大型视觉-语言模型、图注意力网络和表示学习，以识别和利用可解释的特征，从而检测语义上有意义的PII，而不仅仅是低级的外观线索。&lt;h4&gt;主要发现&lt;/h4&gt;对行人图像数据集中PII的存在进行了系统性评估，实验表明，在Market-1501到CUHK03-np（检测到的）等实际跨数据集Re-ID场景中，该框架的性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;该框架在提高Re-ID性能的同时，通过减少PII的泄露，有助于提高自动驾驶系统和AI研究的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：收集和发布街景录音作为开放数据在推进自动驾驶系统和AI研究中发挥着至关重要的作用。然而，这些数据集由于包含超出生物特征（如面部）的个人信息，对行人构成了显著的隐私风险。在本文中，我们提出了一种名为cRID的新型跨模态框架，该框架结合了大型视觉-语言模型、图注意力网络和表示学习，用于检测文本描述的可识别线索并增强行人重识别。我们的方法侧重于识别和利用可解释的特征，从而能够检测到语义上有意义的PII，而不仅仅是低级的外观线索。我们对行人图像数据集中PII的存在进行了系统性评估。我们的实验表明，在Market-1501到CUHK03-np（检测到的）等实际跨数据集Re-ID场景中，该框架的性能得到了提升，突出了框架的实际效用。代码可在https://github.com/RAufschlaeger/cRID上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The collection and release of street-level recordings as Open Data play avital role in advancing autonomous driving systems and AI research. However,these datasets pose significant privacy risks, particularly for pedestrians,due to the presence of Personally Identifiable Information (PII) that extendsbeyond biometric traits such as faces. In this paper, we present cRID, a novelcross-modal framework combining Large Vision-Language Models, Graph AttentionNetworks, and representation learning to detect textual describable clues ofPII and enhance person re-identification (Re-ID). Our approach focuses onidentifying and leveraging interpretable features, enabling the detection ofsemantically meaningful PII beyond low-level appearance cues. We conduct asystematic evaluation of PII presence in person image datasets. Our experimentsshow improved performance in practical cross-dataset Re-ID scenarios, notablyfrom Market-1501 to CUHK03-np (detected), highlighting the framework'spractical utility. Code is available at https://github.com/RAufschlaeger/cRID.</description>
      <author>example@mail.com (Robert Aufschläger, Youssef Shoeb, Azarm Nowzad, Michael Heigl, Fabian Bally, Martin Schramm)</author>
      <guid isPermaLink="false">2507.01504v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond</title>
      <link>http://arxiv.org/abs/2507.00886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种以场景为中心的3D视觉语言模型（VLM），用于处理3D高斯斯普莱特场景，并通过语言和任务感知的场景表示来提高3D场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着多模态语言模型的进步，它们在3D场景理解中的应用成为快速发展的前沿，推动了3D视觉语言模型（VLMs）的发展。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前方法对物体检测器的依赖，引入了处理瓶颈和分类灵活性限制的问题。&lt;h4&gt;方法&lt;/h4&gt;该模型直接将丰富的语言特征嵌入到3D场景表示中，通过将语言与每个高斯原语关联来实现早期模态对齐。为了处理生成的密集表示，引入了双重稀疏化器，通过任务引导和位置引导路径将它们提炼成紧凑的任务相关标记，产生稀疏的任务感知全局和局部场景标记。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了首个基于高斯斯普莱特技术的VLM，利用从标准RGB图像派生的逼真3D表示，展示了强大的泛化能力：它将先前3D VLM的性能提高了五倍，在域外设置中。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个创新的3D VLM，通过引入语言和任务感知的场景表示，显著提高了3D场景理解的能力，尤其是在域外设置中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As multimodal language models advance, their application to 3D sceneunderstanding is a fast-growing frontier, driving the development of 3DVision-Language Models (VLMs). Current methods show strong dependence on objectdetectors, introducing processing bottlenecks and limitations in taxonomicflexibility. To address these limitations, we propose a scene-centric 3D VLMfor 3D Gaussian splat scenes that employs language- and task-aware scenerepresentations. Our approach directly embeds rich linguistic features into the3D scene representation by associating language with each Gaussian primitive,achieving early modality alignment. To process the resulting denserepresentations, we introduce a dual sparsifier that distills them intocompact, task-relevant tokens via task-guided and location-guided pathways,producing sparse, task-aware global and local scene tokens. Notably, we presentthe first Gaussian splatting-based VLM, leveraging photorealistic 3Drepresentations derived from standard RGB images, demonstrating stronggeneralization: it improves performance of prior 3D VLM five folds, inout-of-the-domain settings.</description>
      <author>example@mail.com (Anna-Maria Halacheva, Jan-Nico Zaech, Xi Wang, Danda Pani Paudel, Luc Van Gool)</author>
      <guid isPermaLink="false">2507.00886v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Component Adaptive Clustering for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2507.01711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaGCD的聚类中心对比学习框架，用于将未标记图像分类到已知和新型类别中，无需预先知道未知类别的数量。&lt;h4&gt;背景&lt;/h4&gt;传统的分类方法通常依赖于严格的假设，如预定义类别数量，这限制了它们处理现实世界数据内在变异性和复杂性的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些不足，本文旨在提出一种新的方法，能够自适应地处理未标记图像的分类问题。&lt;h4&gt;方法&lt;/h4&gt;AdaGCD框架结合了自适应槽位注意力（AdaSlot）机制，该机制根据数据复杂性动态确定最优槽位数量，从而无需预定义槽位计数。这种方法通过动态分配表示能力，灵活地将未标记数据聚类到已知和新型类别中。&lt;h4&gt;主要发现&lt;/h4&gt;AdaGCD通过结合自适应表示和动态槽位分配，能够捕捉实例特定和空间聚集特征，从而在开放世界场景中提高类别发现能力。&lt;h4&gt;结论&lt;/h4&gt;在公共和细粒度数据集上的广泛实验验证了该框架的有效性，强调了利用空间局部信息在未标记图像数据集中进行类别发现的优势。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为AdaGCD的聚类中心对比学习框架，用于将未标记图像分类到已知和新型类别中，无需预先知道未知类别的数量。传统的分类方法通常依赖于严格的假设，如预定义类别数量，这限制了它们处理现实世界数据内在变异性和复杂性的能力。为了解决这些不足，本文旨在提出一种新的方法，能够自适应地处理未标记图像的分类问题。AdaGCD框架结合了自适应槽位注意力（AdaSlot）机制，该机制根据数据复杂性动态确定最优槽位数量，从而无需预定义槽位计数。这种方法通过动态分配表示能力，灵活地将未标记数据聚类到已知和新型类别中。AdaGCD通过结合自适应表示和动态槽位分配，能够捕捉实例特定和空间聚集特征，从而在开放世界场景中提高类别发现能力。在公共和细粒度数据集上的广泛实验验证了该框架的有效性，强调了利用空间局部信息在未标记图像数据集中进行类别发现的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) tackles the challenging problem ofcategorizing unlabeled images into both known and novel classes within apartially labeled dataset, without prior knowledge of the number of unknowncategories. Traditional methods often rely on rigid assumptions, such aspredefining the number of classes, which limits their ability to handle theinherent variability and complexity of real-world data. To address theseshortcomings, we propose AdaGCD, a cluster-centric contrastive learningframework that incorporates Adaptive Slot Attention (AdaSlot) into the GCDframework. AdaSlot dynamically determines the optimal number of slots based ondata complexity, removing the need for predefined slot counts. This adaptivemechanism facilitates the flexible clustering of unlabeled data into known andnovel categories by dynamically allocating representational capacity. Byintegrating adaptive representation with dynamic slot allocation, our methodcaptures both instance-specific and spatially clustered features, improvingclass discovery in open-world scenarios. Extensive experiments on public andfine-grained datasets validate the effectiveness of our framework, emphasizingthe advantages of leveraging spatial local information for category discoveryin unlabeled image datasets.</description>
      <author>example@mail.com (Mingfu Yan, Jiancheng Huang, Yifan Liu, Shifeng Chen)</author>
      <guid isPermaLink="false">2507.01711v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles</title>
      <link>http://arxiv.org/abs/2507.00937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RaGNNarok，一种基于图神经网络（GNN）的框架，用于增强雷达点云，提高低成本室内移动机器人的定位、SLAM和自主导航性能。&lt;h4&gt;背景&lt;/h4&gt;低成本室内移动机器人在家庭和商业空间中得到广泛应用，但现有的基于激光雷达和摄像头的解决方案存在性能不足、计算开销大和成本高等问题。&lt;h4&gt;目的&lt;/h4&gt;提出RaGNNarok，以解决现有雷达定位方法中点云稀疏、噪声和误检测等问题。&lt;h4&gt;方法&lt;/h4&gt;RaGNNarok是一个实时、轻量级且通用的GNN框架，能够在资源受限的设备上高效运行，无需额外的计算资源。&lt;h4&gt;主要发现&lt;/h4&gt;RaGNNarok在低成本Raspberry Pi 5上的推理时间仅为7.3毫秒，且在三个不同环境中评估结果表明其具有强可靠性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;RaGNNarok是一个鲁棒的低成本室内移动机器人解决方案，适用于定位、SLAM和自主导航等关键任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-cost indoor mobile robots have gained popularity with the increasingadoption of automation in homes and commercial spaces. However, existing lidarand camera-based solutions have limitations such as poor performance invisually obscured environments, high computational overhead for dataprocessing, and high costs for lidars. In contrast, mmWave radar sensors offera cost-effective and lightweight alternative, providing accurate rangingregardless of visibility. However, existing radar-based localization suffersfrom sparse point cloud generation, noise, and false detections. Thus, in thiswork, we introduce RaGNNarok, a real-time, lightweight, and generalizable graphneural network (GNN)-based framework to enhance radar point clouds, even incomplex and dynamic environments. With an inference time of just 7.3 ms on thelow-cost Raspberry Pi 5, RaGNNarok runs efficiently even on suchresource-constrained devices, requiring no additional computational resources.We evaluate its performance across key tasks, including localization, SLAM, andautonomous navigation, in three different environments. Our results demonstratestrong reliability and generalizability, making RaGNNarok a robust solution forlow-cost indoor mobile robots.</description>
      <author>example@mail.com (David Hunt, Shaocheng Luo, Spencer Hallyburton, Shafii Nillongo, Yi Li, Tingjun Chen, Miroslav Pajic)</author>
      <guid isPermaLink="false">2507.00937v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MILP-SAT-GNN: Yet Another Neural SAT Solver</title>
      <link>http://arxiv.org/abs/2507.01825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法，该方法通过利用为混合整数线性规划（MILP）开发的技术，使图神经网络（GNNs）能够解决SAT问题。&lt;h4&gt;背景&lt;/h4&gt;GNNs被应用于解决MILP问题，而本文提出的方法将k-CNF公式映射到MILP问题，并通过加权二部图编码后输入GNN进行训练和测试。&lt;h4&gt;目的&lt;/h4&gt;探索GNNs在解决SAT问题上的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;将k-CNF公式映射到MILP问题，编码为加权二部图，然后输入GNN进行训练和测试。通过理论分析，证明方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;（i）证明了方法在条款和变量重新排序下输出的稳定性；（ii）指出对于可折叠公式，标准GNNs无法总是区分可满足和不可满足实例；（iii）证明了通用逼近定理，表明使用随机节点初始化（RNI），方法可以在有限数据集上以任意精度逼近SAT求解；（iv）对于不可折叠公式，无需RNI即可达到相同的逼近保证。&lt;h4&gt;结论&lt;/h4&gt;尽管神经网络架构简单，该方法在实验中取得了有希望的结果。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to MixedInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We proposes a novel method that enables Graph Neural Networks (GNNs) to solveSAT problems by leveraging a technique developed for applying GNNs to MixedInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped intoMILP problems, which are then encoded as weighted bipartite graphs andsubsequently fed into a GNN for training and testing. From a theoreticalperspective: (i) we establish permutation and equivalence invariance results,demonstrating that the method produces outputs that are stable under reorderingof clauses and variables; (ii) we identify a theoretical limitation, showingthat for a class of formulae called foldable formulae, standard GNNs cannotalways distinguish satisfiable from unsatisfiable instances; (iii) we prove auniversal approximation theorem, establishing that with Random NodeInitialization (RNI), the method can approximate SAT solving to arbitraryprecision on finite datasets, that is, the GNN becomes approximately sound andcomplete on such datasets. Furthermore, we show that for unfoldable formulae,the same approximation guarantee can be achieved without the need for RNI.Finally, we conduct an experimental evaluation of our approach, which showthat, despite the simplicity of the neural architecture, the method achievespromising results.</description>
      <author>example@mail.com (Franco Alberto Cardillo, Hamza Khyari, Umberto Straccia)</author>
      <guid isPermaLink="false">2507.01825v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability</title>
      <link>http://arxiv.org/abs/2507.01575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the IEEE VTC2025-Spring Conference, 7  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可见光通信的室内定位方法，通过迁移学习技术提高了定位精度、降低了能耗和计算时间，适用于工业环境。&lt;h4&gt;背景&lt;/h4&gt;在工业环境中，精确的室内定位至关重要，可见光通信（VLC）作为一种新兴解决方案，具有高精度、节能和电磁干扰小的优势。&lt;h4&gt;目的&lt;/h4&gt;针对VLC在室内定位中面临的环境变化挑战，如光照波动和障碍物，提出一种基于迁移学习的室内定位方法。&lt;h4&gt;方法&lt;/h4&gt;利用BOSCH工厂的真实世界数据，将深度神经网络（DNN）集成到迁移学习框架中，以提高定位精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在定位精度上提高了47%，能耗降低了32%，计算时间减少了40%，且在变化的环境条件下具有高度适应性，仅需30%的数据集即可达到相似的精度。&lt;h4&gt;结论&lt;/h4&gt;该方法是一种成本效益高、可扩展的解决方案，适用于工业4.0中的工业应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate indoor localization is crucial in industrial environments. VisibleLight Communication (VLC) has emerged as a promising solution, offering highaccuracy, energy efficiency, and minimal electromagnetic interference. However,VLC-based indoor localization faces challenges due to environmentalvariability, such as lighting fluctuations and obstacles. To address thesechallenges, we propose a Transfer Learning (TL)-based approach for VLC-basedindoor localization. Using real-world data collected at a BOSCH factory, the TLframework integrates a deep neural network (DNN) to improve localizationaccuracy by 47\%, reduce energy consumption by 32\%, and decrease computationaltime by 40\% compared to the conventional models. The proposed solution ishighly adaptable under varying environmental conditions and achieves similaraccuracy with only 30\% of the dataset, making it a cost-efficient and scalableoption for industrial applications in Industry 4.0.</description>
      <author>example@mail.com (Masood Jan, Wafa Njima, Xun Zhang, Alexander Artemenko)</author>
      <guid isPermaLink="false">2507.01575v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars</title>
      <link>http://arxiv.org/abs/2507.01939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 6 figures, 5 tables. To be submitted to AAS Journals.  Comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpecCLIP是一个基于LLM的方法，用于扩展到恒星光谱分析，旨在通过大规模光谱数据集训练，学习到鲁棒且信息丰富的嵌入，支持多样化的下游应用。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）通过大规模数据集和大规模参数化改变了自然语言理解。受此启发，研究人员提出了SpecCLIP框架。&lt;h4&gt;目的&lt;/h4&gt;SpecCLIP的目标是通过在大型光谱数据集上训练基础模型，学习到鲁棒且信息丰富的嵌入，支持多样化的下游应用。&lt;h4&gt;方法&lt;/h4&gt;SpecCLIP包括在两种光谱类型（LAMOST低分辨率和Gaia XP）上预训练，然后使用CLIP框架进行对比对齐，以关联来自不同仪器的光谱。此外，还包括辅助解码器，以保留光谱特定的信息并实现光谱类型之间的翻译（预测）。&lt;h4&gt;主要发现&lt;/h4&gt;SpecCLIP模型在中等大小的标记数据集上进行微调，提高了对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提高了参数估计的准确性和精度，并具有相似性搜索和跨光谱预测能力，可用于异常检测。&lt;h4&gt;结论&lt;/h4&gt;对比训练的基础模型，结合光谱感知解码器，可以推进精确恒星光谱学。&lt;h4&gt;翻译&lt;/h4&gt;SpecCLIP是一种基于大型语言模型的方法，旨在将LLM启发的方法扩展到恒星光谱分析。恒星光谱，类似于结构化语言，编码了关于恒星丰富的物理和化学信息。通过在大规模光谱数据集上训练基础模型，我们的目标是学习到鲁棒且信息丰富的嵌入，以支持多样化的下游应用。作为一个概念验证，SpecCLIP包括在两种光谱类型（LAMOST低分辨率和Gaia XP）上预训练，然后使用CLIP（对比语言-图像预训练）框架进行对比对齐，该框架被调整以关联来自不同仪器的光谱。这种对齐得到了辅助解码器的补充，这些解码器保留了光谱特定的信息，并能够实现光谱类型之间的翻译（预测），这是通过最大化嵌入和输入光谱之间的互信息来实现的。结果是跨光谱框架，它实现了内在校准和在仪器之间灵活应用。我们证明了在这些模型上使用中等大小的标记数据集进行微调，提高了对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提高了与外部调查数据基准的参数估计的准确性和精度。此外，其相似性搜索和跨光谱预测能力为异常检测提供了潜在的可能性。我们的结果表明，与光谱感知解码器丰富的基础模型可以推进精确恒星光谱学。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, large language models (LLMs) have transformed naturallanguage understanding through vast datasets and large-scale parameterization.Inspired by this success, we present SpecCLIP, a foundation model frameworkthat extends LLM-inspired methodologies to stellar spectral analysis. Stellarspectra, akin to structured language, encode rich physical and chemicalinformation about stars. By training foundation models on large-scale spectraldatasets, our goal is to learn robust and informative embeddings that supportdiverse downstream applications. As a proof of concept, SpecCLIP involvespre-training on two spectral types--LAMOST low-resolution and Gaia XP--followedby contrastive alignment using the CLIP (Contrastive Language-ImagePre-training) framework, adapted to associate spectra from differentinstruments. This alignment is complemented by auxiliary decoders that preservespectrum-specific information and enable translation (prediction) betweenspectral types, with the former achieved by maximizing mutual informationbetween embeddings and input spectra. The result is a cross-spectrum frameworkenabling intrinsic calibration and flexible applications across instruments. Wedemonstrate that fine-tuning these models on moderate-sized labeled datasetsimproves adaptability to tasks such as stellar-parameter estimation andchemical-abundance determination. SpecCLIP also enhances the accuracy andprecision of parameter estimates benchmarked against external survey data.Additionally, its similarity search and cross-spectrum prediction capabilitiesoffer potential for anomaly detection. Our results suggest that contrastivelytrained foundation models enriched with spectrum-aware decoders can advanceprecision stellar spectroscopy.</description>
      <author>example@mail.com (Xiaosheng Zhao, Yang Huang, Guirong Xue, Xiao Kong, Jifeng Liu, Xiaoyu Tang, Timothy C. Beers, Yuan-Sen Ting, A-Li Luo)</author>
      <guid isPermaLink="false">2507.01939v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement</title>
      <link>http://arxiv.org/abs/2507.01643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  We release SAILViT, a series of versatile vision foundation models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAILViT的视觉Transformer，旨在解决多模态大型语言模型（MLLMs）在复杂多模态交互中的性能瓶颈。&lt;h4&gt;背景&lt;/h4&gt;视觉Transformer（ViTs）在建立MLLMs的视觉理解能力方面至关重要。然而，现有的ViTs在直接与LLMs进行基于连接器的协同训练时存在参数初始化冲突和模态语义差距的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SAILViT，以促进MLLMs突破复杂多模态交互中的性能瓶颈。&lt;h4&gt;方法&lt;/h4&gt;SAILViT通过逐步特征学习和特征细化实现粗到细粒度的特征对齐和世界知识融合，更好地满足目标训练需求。进行了全面的实证分析，以确认SAILViT在不同维度上的强大鲁棒性和泛化能力，包括参数大小、模型架构、训练策略和数据规模。&lt;h4&gt;主要发现&lt;/h4&gt;配备SAILViT的现有MLLMs在OpenCompass基准测试中，在广泛的下游任务上显示出显著且一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;SAILViT系列模型在https://huggingface.co/BytedanceDouyinContent上发布。&lt;h4&gt;翻译&lt;/h4&gt;Vision Transformers (ViTs) are essential as foundation backbones in establishing the visual comprehension capabilities of Multimodal Large Language Models (MLLMs). Although most ViTs achieve impressive performance through image-text pair-based contrastive learning or self-supervised mechanisms, they struggle to engage in connector-based co-training directly with LLMs due to potential parameter initialization conflicts and modality semantic gaps. To address the above challenges, this paper proposes SAILViT, a gradual feature learning-enhanced ViT for facilitating MLLMs to break through performance bottlenecks in complex multimodal interactions. SAILViT achieves coarse-to-fine-grained feature alignment and world knowledge infusion with gradual feature refinement, which better serves target training demands. We perform thorough empirical analyses to confirm the powerful robustness and generalizability of SAILViT across different dimensions, including parameter sizes, model architectures, training strategies, and data scales. Equipped with SAILViT, existing MLLMs show significant and consistent performance improvements on the OpenCompass benchmark across extensive downstream tasks. SAILViT series models are released at https://huggingface.co/BytedanceDouyinContent.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformers (ViTs) are essential as foundation backbones inestablishing the visual comprehension capabilities of Multimodal Large LanguageModels (MLLMs). Although most ViTs achieve impressive performance throughimage-text pair-based contrastive learning or self-supervised mechanisms, theystruggle to engage in connector-based co-training directly with LLMs due topotential parameter initialization conflicts and modality semantic gaps. Toaddress the above challenges, this paper proposes SAILViT, a gradual featurelearning-enhanced ViT for facilitating MLLMs to break through performancebottlenecks in complex multimodal interactions. SAILViT achievescoarse-to-fine-grained feature alignment and world knowledge infusion withgradual feature refinement, which better serves target training demands. Weperform thorough empirical analyses to confirm the powerful robustness andgeneralizability of SAILViT across different dimensions, including parametersizes, model architectures, training strategies, and data scales. Equipped withSAILViT, existing MLLMs show significant and consistent performanceimprovements on the OpenCompass benchmark across extensive downstream tasks.SAILViT series models are released athttps://huggingface.co/BytedanceDouyinContent.</description>
      <author>example@mail.com (Weijie Yin, Dingkang Yang, Hongyuan Dong, Zijian Kang, Jiacong Wang, Xiao Liang, Chao Feng, Jiao Ran)</author>
      <guid isPermaLink="false">2507.01643v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>An in depth look at the Procrustes-Wasserstein distance: properties and barycenters</title>
      <link>http://arxiv.org/abs/2507.00894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Procrustes-Wasserstein (PW) 距离在点云对齐和比较中的应用，并提出了一种新的方法来估计点云的代表形状。&lt;h4&gt;背景&lt;/h4&gt;由于Procrustes-Wasserstein (PW) 距离对刚体变换（如旋转和反射）的不变性，它被引入文献作为最优传输（OT）距离，是一种替代Wasserstein距离的方法，更适合点云对齐和比较的任务。&lt;h4&gt;目的&lt;/h4&gt;构建一个离散概率测度空间，并展示在空间上PW实际上是一种距离；扩展PW框架，讨论和测试多种初始化策略；引入PW重心的概念，并详细描述一种从数据中估计它的算法。&lt;h4&gt;方法&lt;/h4&gt;建立离散概率测度空间，提出新的初始化策略，引入PW重心概念并设计估计算法。&lt;h4&gt;主要发现&lt;/h4&gt;提出的新方法在需要精确对齐和形状保真度的情况下，与现有的OT方法相比，表现更优；在考古学背景下展示了PW重心的有用性。&lt;h4&gt;结论&lt;/h4&gt;Procrustes-Wasserstein (PW) 距离在2D和3D点云分析中具有潜力，可以提升机器学习和计算几何应用的效果。&lt;h4&gt;翻译&lt;/h4&gt;由于其对刚性变换（如旋转和反射）的不变性，Procrustes-Wasserstein (PW) 被文献中引入作为最优传输（OT）距离，是Wasserstein距离的一种替代方案，更适合点云的对齐和比较。考虑到这一应用，我们仔细构建了一个离散概率测度空间，并显示在该空间上PW实际上是一种距离。已经存在解决PW问题的算法，但是通过讨论和测试了多种初始化策略，我们扩展了PW框架。然后我们引入了PW重心的概念，并详细描述了一种从数据中估计它的算法。结果是计算点云集合中代表性形状的新方法。我们将我们的方法与现有的OT方法进行了基准测试，证明了在需要精确对齐和形状保真度的情况下，我们的方法表现更优。我们最终展示了在考古学背景下PW重心的有用性。我们的结果突出了PW在提升2D和3D点云分析，为机器学习和计算几何应用带来潜力的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its invariance to rigid transformations such as rotations andreflections, Procrustes-Wasserstein (PW) was introduced in the literature as anoptimal transport (OT) distance, alternative to Wasserstein and more suited totasks such as the alignment and comparison of point clouds. Having thatapplication in mind, we carefully build a space of discrete probabilitymeasures and show that over that space PW actually is a distance. Algorithms tosolve the PW problems already exist, however we extend the PW framework bydiscussing and testing several initialization strategies. We then introduce thenotion of PW barycenter and detail an algorithm to estimate it from the data.The result is a new method to compute representative shapes from a collectionof point clouds. We benchmark our method against existing OT approaches,demonstrating superior performance in scenarios requiring precise alignment andshape preservation. We finally show the usefulness of the PW barycenters in anarchaeological context. Our results highlight the potential of PW in boosting2D and 3D point cloud analysis for machine learning and computational geometryapplications.</description>
      <author>example@mail.com (Davide Adamo, Marco Corneli, Manon Vuillien, Emmanuelle Vila)</author>
      <guid isPermaLink="false">2507.00894v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Embedding-based Retrieval in Multimodal Content Moderation</title>
      <link>http://arxiv.org/abs/2507.01066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Camera ready for SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于嵌入的检索（EBR）方法，用于补充传统分类方法，以应对短视频平台内容审核中的快速和成本效益问题。&lt;h4&gt;背景&lt;/h4&gt;视频理解在短视频平台内容审核中起关键作用，但传统的分类方法在需要快速响应和成本效益的场景中存在困难。&lt;h4&gt;目的&lt;/h4&gt;旨在提高内容审核的效率和效果，特别是在趋势适应和紧急升级等场景中。&lt;h4&gt;方法&lt;/h4&gt;采用监督对比学习（SCL）框架训练一系列基础嵌入模型，包括单模态和多模态架构，并设计了一个基于嵌入的视频检索系统。&lt;h4&gt;主要发现&lt;/h4&gt;EBR在25个多样化的新兴趋势上的离线实验中，将ROC-AUC从0.85提升到0.99，PR-AUC从0.35提升到0.95。在线实验显示，EBR提高了行动率10.32%，并降低了超过80%的运营成本。&lt;h4&gt;结论&lt;/h4&gt;EBR方法在提高内容审核效率和降低成本方面表现优异，同时相比基于分类的解决方案，增强了可解释性和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces an Embedding-Based Retrieval (EBR) method designed to complement traditional classification approaches for content moderation on shortvideo platforms, aiming to improve efficiency and cost-effectiveness in scenarios requiring rapid responses and cost savings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3731945&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding plays a fundamental role for content moderation on shortvideo platforms, enabling the detection of inappropriate content. Whileclassification remains the dominant approach for content moderation, it oftenstruggles in scenarios requiring rapid and cost-efficient responses, such astrend adaptation and urgent escalations. To address this issue, we introduce anEmbedding-Based Retrieval (EBR) method designed to complement traditionalclassification approaches. We first leverage a Supervised Contrastive Learning(SCL) framework to train a suite of foundation embedding models, including bothsingle-modal and multi-modal architectures. Our models demonstrate superiorperformance over established contrastive learning methods such as CLIP andMoCo. Building on these embedding models, we design and implement theembedding-based retrieval system that integrates embedding generation and videoretrieval to enable efficient and effective trend handling. Comprehensiveoffline experiments on 25 diverse emerging trends show that EBR improvesROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further onlineexperiments reveal that EBR increases action rates by 10.32% and reducesoperational costs by over 80%, while also enhancing interpretability andflexibility compared to classification-based solutions.</description>
      <author>example@mail.com (Hanzhong Liang, Jinghao Shi, Xiang Shen, Zixuan Wang, Vera Wen, Ardalan Mehrani, Zhiqian Chen, Yifan Wu, Zhixin Zhang)</author>
      <guid isPermaLink="false">2507.01066v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction</title>
      <link>http://arxiv.org/abs/2507.01437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对电子健康记录文本的非结构化和高维语义复杂性挑战，提出了一种基于注意力机制的深度学习方法，用于统一的信息提取和多标签疾病预测。&lt;h4&gt;背景&lt;/h4&gt;电子健康记录文本具有非结构化和高维语义复杂性，给信息提取和疾病预测带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理电子健康记录文本并实现多标签疾病预测的方法。&lt;h4&gt;方法&lt;/h4&gt;在MIMIC-IV数据集上，使用基于Transformer的架构进行临床文本的表示学习。采用多层自注意力机制来捕捉关键医疗实体及其上下文关系，并应用基于Sigmoid的多标签分类器进行疾病标签预测。模型还包含一个上下文感知语义对齐机制，以增强其在典型医疗场景下的表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在多个性能指标上均优于现有代表性方法。模型在不同数据规模、干扰水平和模型深度配置下均表现出强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本研究开发的方法为处理现实世界临床文本提供了一个高效的算法基础，对多标签医疗文本建模任务具有实际意义。&lt;h4&gt;翻译&lt;/h4&gt;本文针对电子健康记录文本的非结构化和高维语义复杂性挑战，提出了一种基于注意力机制的深度学习方法，用于统一的信息提取和多标签疾病预测。研究在MIMIC-IV数据集上进行，使用基于Transformer的架构进行临床文本的表示学习。采用多层自注意力机制来捕捉关键医疗实体及其上下文关系，并应用基于Sigmoid的多标签分类器进行疾病标签预测。模型还包含一个上下文感知语义对齐机制，以增强其在典型医疗场景下的表示能力。实验结果表明，所提出的方法在多个性能指标上均优于现有代表性方法。模型在不同数据规模、干扰水平和模型深度配置下均表现出强大的泛化能力。本研究开发的方法为处理现实世界临床文本提供了一个高效的算法基础，对多标签医疗文本建模任务具有实际意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenges posed by the unstructured nature andhigh-dimensional semantic complexity of electronic health record texts. A deeplearning method based on attention mechanisms is proposed to achieve unifiedmodeling for information extraction and multi-label disease prediction. Thestudy is conducted on the MIMIC-IV dataset. A Transformer-based architecture isused to perform representation learning over clinical text. Multi-layerself-attention mechanisms are employed to capture key medical entities andtheir contextual relationships. A Sigmoid-based multi-label classifier is thenapplied to predict multiple disease labels. The model incorporates acontext-aware semantic alignment mechanism, enhancing its representationalcapacity in typical medical scenarios such as label co-occurrence and sparseinformation. To comprehensively evaluate model performance, a series ofexperiments were conducted, including baseline comparisons, hyperparametersensitivity analysis, data perturbation studies, and noise injection tests.Results demonstrate that the proposed method consistently outperformsrepresentative existing approaches across multiple performance metrics. Themodel maintains strong generalization under varying data scales, interferencelevels, and model depth configurations. The framework developed in this studyoffers an efficient algorithmic foundation for processing real-world clinicaltexts and presents practical significance for multi-label medical text modelingtasks.</description>
      <author>example@mail.com (Ting Xu, Xiaoxiao Deng, Xiandong Meng, Haifeng Yang, Yan Wu)</author>
      <guid isPermaLink="false">2507.01437v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks</title>
      <link>http://arxiv.org/abs/2507.01559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细研究了在持续学习等具有挑战性的设置中，卷积神经网络在训练过程中学习和遗忘的规律。实验表明，经过zapping（在神经网络最后一层重新采样权重）训练的模型在新领域迁移时能更快地恢复。&lt;h4&gt;背景&lt;/h4&gt;持续学习领域的研究表明，在神经网络最后一层重新采样权重（zapping）可以带来有益的效果，但其背后的机制尚不明确。&lt;h4&gt;目的&lt;/h4&gt;探究在持续学习和少样本迁移学习等困难设置中，卷积神经网络的学习和遗忘模式。&lt;h4&gt;方法&lt;/h4&gt;通过实验测量了经过zapping训练的模型在新领域迁移时的恢复速度，以及在多任务设置中，每个单独任务受持续学习的影响。&lt;h4&gt;主要发现&lt;/h4&gt;1. 经过zapping训练的模型在新领域迁移时恢复更快；2. 优化器的选择也会深刻影响学习和遗忘的动态，导致在模型按顺序迁移学习时出现复杂的学习/遗忘协同/干扰模式。&lt;h4&gt;结论&lt;/h4&gt;zapping以及优化器的选择对卷积神经网络在持续学习中的学习和遗忘动态有重要影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work in continual learning has highlighted the beneficial effect ofresampling weights in the last layer of a neural network (``zapping"). Althoughempirical results demonstrate the effectiveness of this approach, theunderlying mechanisms that drive these improvements remain unclear. In thiswork, we investigate in detail the pattern of learning and forgetting that takeplace inside a convolutional neural network when trained in challengingsettings such as continual learning and few-shot transfer learning, withhandwritten characters and natural images. Our experiments show that modelsthat have undergone zapping during training more quickly recover from the shockof transferring to a new domain. Furthermore, to better observe the effect ofcontinual learning in a multi-task setting we measure how each individual taskis affected. This shows that, not only zapping, but the choice of optimizer canalso deeply affect the dynamics of learning and forgetting, causing complexpatterns of synergy/interference between tasks to emerge when the model learnssequentially at transfer time.</description>
      <author>example@mail.com (Lapo Frati, Neil Traft, Jeff Clune, Nick Cheney)</author>
      <guid isPermaLink="false">2507.01559v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>BEV-VAE: Multi-view Image Generation with Spatial Consistency for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.00707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为BEV-VAE的算法，用于在自动驾驶中进行多视角图像生成，以实现跨摄像头视角的一致3D场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常将多视角图像生成视为2D图像集生成任务，缺乏显式的3D建模。&lt;h4&gt;目的&lt;/h4&gt;强调结构化表示对于场景生成的重要性，尤其是在自动驾驶应用中。&lt;h4&gt;方法&lt;/h4&gt;BEV-VAE首先训练一个用于紧凑且统一BEV潜在空间的多视角图像变分自编码器，然后使用潜在扩散变换器生成场景。&lt;h4&gt;主要发现&lt;/h4&gt;BEV-VAE支持任意视角生成，并可选择3D布局。在nuScenes和Argoverse 2（AV2）上的实验表明，该算法在3D一致重建和生成方面都表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;BEV-VAE是一种有效的多视角图像生成方法，适用于自动驾驶场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view image generation in autonomous driving demands consistent 3D sceneunderstanding across camera views. Most existing methods treat this problem asa 2D image set generation task, lacking explicit 3D modeling. However, we arguethat a structured representation is crucial for scene generation, especiallyfor autonomous driving applications. This paper proposes BEV-VAE for consistentand controllable view synthesis. BEV-VAE first trains a multi-view imagevariational autoencoder for a compact and unified BEV latent space and thengenerates the scene with a latent diffusion transformer. BEV-VAE supportsarbitrary view generation given camera configurations, and optionally 3Dlayouts. Experiments on nuScenes and Argoverse 2 (AV2) show strong performancein both 3D consistent reconstruction and generation. The code is available at:https://github.com/Czm369/bev-vae.</description>
      <author>example@mail.com (Zeming Chen, Hang Zhao)</author>
      <guid isPermaLink="false">2507.00707v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability</title>
      <link>http://arxiv.org/abs/2507.01260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to Seismological Research Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于Transformer编码器的深度学习模型，用于更客观和高效地对地震类型进行分类，以阐明火山地震与火山活动之间的关系。&lt;h4&gt;背景&lt;/h4&gt;传统的地震类型分类方法依赖于主观的人类判断，需要大量的时间和精力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，研究旨在开发一个更客观和高效的地震类型分类模型。&lt;h4&gt;方法&lt;/h4&gt;研究开发了一个深度学习模型，并在浅间山多样的地震活动上进行了测试，该模型在F1分数上优于传统的基于CNN的方法。此外，还分析了注意力权重可视化，并探讨了数据选择和增强的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;模型在火山构造地震、低频地震和噪声的分类上取得了高F1分数。注意力权重可视化显示模型关注关键波形特征，与人类专家类似。数据不一致性影响了分类准确性和注意力权重分布。数据选择和增强的实验表明了平衡数据质量和多样性的重要性。&lt;h4&gt;结论&lt;/h4&gt;Transformer模型在自动火山地震分类方面具有潜力，尤其是在提高效率和可解释性方面。该研究为理解浅间山的地震活动提供了一个稳健的框架，并为其他火山区域提供了迁移学习的机会，为提高火山危害评估和灾害减轻策略铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;This study developed a deep learning model using a transformer encoder for more objective and efficient earthquake type classification, in order to elucidate the relationship between volcanic earthquakes and volcanic activity. Traditional methods for earthquake type classification rely on subjective human judgment, which requires considerable time and effort. To address this issue, the research aimed to develop a more objective and efficient earthquake type classification model. A deep learning model was developed and tested on the diverse seismic activity of Mount Asama, and the model achieved higher F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency earthquakes, and 0.980 for noise) than a conventional CNN-based method. In addition, attention weight visualizations were analyzed, and it was found that the model focuses on key waveform features in a manner similar to human experts. However, inconsistencies in the training data, such as ambiguously labeled B-type events with S-waves, were found to influence classification accuracy and attention weight distributions. Experiments addressing data selection and augmentation demonstrated the importance of balancing data quality and diversity. In addition, stations within 3 km of the crater played an important role in improving model performance and interpretability. These findings highlight the potential of Transformer-based models for automated volcanic earthquake classification, particularly in improving efficiency and interpretability. This research provides a robust framework for understanding seismic activity at Mount Asama and offers opportunities for transfer learning to other volcanic regions, paving the way for enhanced volcanic hazard assessments and disaster mitigation strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precisely classifying earthquake types is crucial for elucidating therelationship between volcanic earthquakes and volcanic activity. However,traditional methods rely on subjective human judgment, which requiresconsiderable time and effort. To address this issue, we developed a deeplearning model using a transformer encoder for a more objective and efficientclassification. Tested on Mount Asama's diverse seismic activity, our modelachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequencyearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.To enhance interpretability, attention weight visualizations were analyzed,revealing that the model focuses on key waveform features similarly to humanexperts. However, inconsistencies in training data, such as ambiguously labeledB-type events with S-waves, were found to influence classification accuracy andattention weight distributions. Experiments addressing data selection andaugmentation demonstrated the importance of balancing data quality anddiversity. In addition, stations within 3 km of the crater played an importantrole in improving model performance and interpretability. These findingshighlight the potential of Transformer-based models for automated volcanicearthquake classification, particularly in improving efficiency andinterpretability. By addressing challenges such as data imbalance andsubjective labeling, our approach provides a robust framework for understandingseismic activity at Mount Asama. Moreover, this framework offers opportunitiesfor transfer learning to other volcanic regions, paving the way for enhancedvolcanic hazard assessments and disaster mitigation strategies.</description>
      <author>example@mail.com (Y. Suzuki, Y. Yukutake, T. Ohminato, M. Yamasaki, Ahyi Kim)</author>
      <guid isPermaLink="false">2507.01260v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding</title>
      <link>http://arxiv.org/abs/2507.00416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Vision-Language-Action (VLA)的模型，该模型能够使通用机器人具备感知、推理和在世界中行动的能力。通过引入一个可即插即用的模块，该模型能够将3D几何特征隐式地注入VLA模型中，从而提高模型的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;VLA模型通常基于预训练的Vision-Language Models (VLMs)，这些模型在语义理解方面表现出色，但由于主要在2D图像-文本对上进行训练，缺乏精确的空间理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决VLMs缺乏精确空间理解能力的问题，本文旨在通过引入3D几何特征来提高VLA模型的空间理解能力。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一个模块，该模块利用现成的视觉几何基础模型，将3D几何特征隐式地注入VLA模型中。同时，设计了五个需要精确空间理解能力的任务来验证该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的评估，发现该方法显著提高了在多种场景下最先进的VLA模型的表现。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高VLA模型的空间理解能力，为通用机器人的发展提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language-Action (VLA) models have emerged as a promising framework forenabling generalist robots capable of perceiving, reasoning, and acting in thereal world. These models usually build upon pretrained Vision-Language Models(VLMs), which excel at semantic understanding due to large-scale textpretraining. However, VLMs typically lack precise spatial understandingcapabilities, as they are primarily tuned on 2D image-text pairs without 3Dsupervision. To address this limitation, recent approaches have incorporatedexplicit 3D inputs such as point clouds or depth maps, but this necessitatesadditional depth sensors or defective estimation. In contrast, our workintroduces a plug-and-play module that implicitly injects 3D geometry featuresinto VLA models by leveraging an off-the-shelf visual geometry foundationmodels. We design five spatially challenging tasks that require precise spatialunderstanding ability to validate effectiveness of our method. Extensiveevaluations show that our method significantly improves the performance ofstate-of-the-art VLA models across diverse scenarios.</description>
      <author>example@mail.com (Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Bo Zhao)</author>
      <guid isPermaLink="false">2507.00416v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Phase Transition in Nonparametric Minimax Rates for Covariate Shifts on Approximate Manifolds</title>
      <link>http://arxiv.org/abs/2507.00889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在协变量偏移下具有结构数据的非参数回归，其中少量标记的目标数据由大量标记的源数据集补充。文章提出了新的方法，利用源数据集的大小和目标数据的结构特性，在协变量偏移下估计回归函数。&lt;h4&gt;背景&lt;/h4&gt;在许多实际场景中，目标域中的协变量位于源数据支持空间内的低维流形附近，例如个性化手写数字（目标）在一个大型、高维图像库（源）中。由于在这些设置中可能不存在密度比，标准的迁移学习技术往往无法利用这种结构。&lt;h4&gt;目的&lt;/h4&gt;开发新的方法，以利用源数据集的大小和目标数据的结构特性，在协变量偏移下估计回归函数。&lt;h4&gt;方法&lt;/h4&gt;提出了新的最小-最大速率，在协变量偏移下估计一个在一般Hölder类中的回归函数，假设目标分布位于源的一个光滑子流形附近。同时，提出了一个局部多项式回归估计器，在相变边界两侧都达到最优速率。另外，还构建了一个完全自适应的程序，能够适应未知的平滑性和内在维度，并达到接近最优的速率。&lt;h4&gt;主要发现&lt;/h4&gt;确定了由到流形的距离、源和目标样本大小、函数平滑性以及内在维度与外生维度之间的相变。&lt;h4&gt;结论&lt;/h4&gt;本文的结果统一并扩展了协变量偏移、流形学习和自适应非参数推断中的关键主题。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了在协变量偏移下具有结构数据的非参数回归，其中少量标记的目标数据由大量标记的源数据集补充。在许多现实世界的场景中，目标域中的协变量位于源数据支持空间内的低维流形附近，例如个性化手写数字（目标）在一个大型、高维图像库（源）中。由于在这些设置中可能不存在密度比，标准的迁移学习技术往往无法利用这种结构。因此，需要开发利用源数据集大小和目标数据结构特性的方法。受此启发，我们建立了新的最小-最大速率，在协变量偏移下估计一个在一般Hölder类中的回归函数，假设目标分布位于源的一个光滑子流形附近。一般平滑性有助于在目标函数高度规则时减少维度的诅咒，而近似流形可以捕捉现实、有噪声的数据。我们确定了由到流形的距离、源和目标样本大小、函数平滑性以及内在维度与外生维度之间的相变。我们提出了一种局部多项式回归估计器，在相变边界两侧都达到最优速率。此外，我们还构建了一个完全自适应的程序，能够适应未知的平滑性和内在维度，并达到接近最优的速率。我们的结果统一并扩展了协变量偏移、流形学习和自适应非参数推断中的关键主题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study nonparametric regression under covariate shift with structured data,where a small amount of labeled target data is supplemented by a large labeledsource dataset. In many real-world settings, the covariates in the targetdomain lie near a low-dimensional manifold within the support of the source,e.g., personalized handwritten digits (target) within a large, high-dimensionalimage repository (source). Since density ratios may not exist in thesesettings, standard transfer learning techniques often fail to leverage suchstructure. This necessitates the development of methods that exploit both thesize of the source dataset and the structured nature of the target.  Motivated by this, we establish new minimax rates under covariate shift forestimating a regression function in a general H\"older class, assuming thetarget distribution lies near -- but not exactly on -- a smooth submanifold ofthe source. General smoothness helps reduce the curse of dimensionality whenthe target function is highly regular, while approximate manifolds capturerealistic, noisy data. We identify a phase transition in the minimax rate ofestimation governed by the distance to the manifold, source and target samplesizes, function smoothness, and intrinsic versus ambient dimensions. We proposea local polynomial regression estimator that achieves optimal rates on eitherside of the phase transition boundary. Additionally, we construct a fullyadaptive procedure that adjusts to unknown smoothness and intrinsic dimension,and attains nearly optimal rates. Our results unify and extend key threads incovariate shift, manifold learning, and adaptive nonparametric inference.</description>
      <author>example@mail.com (Yuyao Wang, Nabarun Deb, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2507.00889v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Vision-Language-Action Models: An Action Tokenization Perspective</title>
      <link>http://arxiv.org/abs/2507.01925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  70 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉-语言-动作（VLA）模型在多模态理解、推理和生成方面的研究进展，探讨了VLA模型的设计和实现方法。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言基础模型在多模态理解、推理和生成方面取得了显著进展，推动了将这种智能扩展到物理世界的努力，从而促进了视觉-语言-动作（VLA）模型的发展。&lt;h4&gt;目的&lt;/h4&gt;对现有的VLA模型进行分类和解释，通过动作标记化的视角分析现有研究，提炼不同类型动作标记的优点和局限性，并识别改进领域。&lt;h4&gt;方法&lt;/h4&gt;通过系统性的审查和分析，对VLA模型的整体发展进行了综合概述，突出了尚未充分探索但具有前景的方向，并为未来的研究提供了指导。&lt;h4&gt;主要发现&lt;/h4&gt;发现VLA模型可以统一在单个框架下，即通过一系列VLA模块处理视觉和语言输入，生成一系列动作标记，这些标记逐渐编码更具体和可执行的信息。VLA模型的主要设计选择在于动作标记的制定方式，可以分为语言描述、代码、适应性、轨迹、目标状态、潜在表示、原始动作和推理等。&lt;h4&gt;结论&lt;/h4&gt;VLA模型的研究仍有待深入，缺乏对动作标记的全面理解，这阻碍了VLA模型的有效发展和模糊了未来的研究方向。本文旨在推动该领域向通用智能迈进。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉和语言基础模型在多模态理解、推理和生成方面的显著进展激发了将此类智能扩展到物理世界的努力，推动了视觉-语言-动作（VLA）模型的发展。尽管方法似乎多样，但我们观察到当前的VLA模型可以被统一在一个框架之下：视觉和语言输入由一系列VLA模块处理，生成一系列动作标记，这些标记逐步编码更具体和可执行的信息，最终生成可执行的动作。我们进一步确定，区分VLA模型的主要设计选择在于动作标记的制定方式，可以分为语言描述、代码、适应性、轨迹、目标状态、潜在表示、原始动作和推理等。然而，对动作标记的全面理解仍存在不足，这严重阻碍了有效的VLA发展并模糊了未来的研究方向。因此，本综述旨在通过动作标记化的视角对现有的VLA研究进行分类和解释，提炼每种标记类型的长处和不足，并确定改进的领域。通过这种系统性的审查和分析，我们提供了一个对VLA模型更广泛发展的综合看法，突出了尚未充分探索但具有前景的方向，并为未来的研究提供了指导，希望将这一领域推向通用智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable advancements of vision and language foundation models inmultimodal understanding, reasoning, and generation has sparked growing effortsto extend such intelligence to the physical world, fueling the flourishing ofvision-language-action (VLA) models. Despite seemingly diverse approaches, weobserve that current VLA models can be unified under a single framework: visionand language inputs are processed by a series of VLA modules, producing a chainof \textit{action tokens} that progressively encode more grounded andactionable information, ultimately generating executable actions. We furtherdetermine that the primary design choice distinguishing VLA models lies in howaction tokens are formulated, which can be categorized into languagedescription, code, affordance, trajectory, goal state, latent representation,raw action, and reasoning. However, there remains a lack of comprehensiveunderstanding regarding action tokens, significantly impeding effective VLAdevelopment and obscuring future directions. Therefore, this survey aims tocategorize and interpret existing VLA research through the lens of actiontokenization, distill the strengths and limitations of each token type, andidentify areas for improvement. Through this systematic review and analysis, weoffer a synthesized outlook on the broader evolution of VLA models, highlightunderexplored yet promising directions, and contribute guidance for futureresearch, hoping to bring the field closer to general-purpose intelligence.</description>
      <author>example@mail.com (Yifan Zhong, Fengshuo Bai, Shaofei Cai, Xuchuan Huang, Zhang Chen, Xiaowei Zhang, Yuanfei Wang, Shaoyang Guo, Tianrui Guan, Ka Nam Lui, Zhiquan Qi, Yitao Liang, Yuanpei Chen, Yaodong Yang)</author>
      <guid isPermaLink="false">2507.01925v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2507.01383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages. arXiv admin note: substantial text overlap with  arXiv:2409.07500; text overlap with arXiv:2212.05399 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了联邦推荐（FedRec）系统中的针对性攻击问题，并提出了一种名为DV-FSR的新攻击框架，同时引入了针对针对性攻击的防御机制。&lt;h4&gt;背景&lt;/h4&gt;联邦推荐通过分散训练个性化模型保护用户隐私，但该架构易受针对性攻击。目前的研究主要关注FedRec系统中的针对性攻击，但忽略了推荐模型差异鲁棒性的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在研究Federated Sequential Recommendation（FSR）中的针对性攻击，并提出有效的攻击和防御方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DV-FSR的攻击框架，该框架结合了基于采样的显式策略和基于对比学习的隐式梯度策略，并引入了针对FSR针对性攻击的防御机制。&lt;h4&gt;主要发现&lt;/h4&gt;现有的针对性攻击方法在FSR任务中效果有限，而提出的DV-FSR攻击框架能够有效实施协调攻击。&lt;h4&gt;结论&lt;/h4&gt;通过大量实验验证了所提出方法在代表性序列模型上的有效性，并公开了相关代码。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates targeted attacks in the Federated Recommendation (FedRec) system and proposes a novel attack framework named DV-FSR, along with a specific defense mechanism tailored for targeted attacks in FSR. The proposed DV-FSR attack framework uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, a specific defense mechanism is introduced for targeted attacks in FSR, aiming to evaluate the mitigation effects of the proposed attack method. Extensive experiments validate the effectiveness of the proposed approach on representative sequential models, and the codes are publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated recommendation (FedRec) preserves user privacy by enablingdecentralized training of personalized models, but this architecture isinherently vulnerable to adversarial attacks. Significant research has beenconducted on targeted attacks in FedRec systems, motivated by commercial andsocial influence considerations. However, much of this work has largelyoverlooked the differential robustness of recommendation models. Moreover, ourempirical findings indicate that existing targeted attack methods achieve onlylimited effectiveness in Federated Sequential Recommendation(FSR) tasks. Drivenby these observations, we focus on investigating targeted attacks in FSR andpropose a novel dualview attack framework, named DV-FSR. This attack methoduniquely combines a sampling-based explicit strategy with a contrastivelearning-based implicit gradient strategy to orchestrate a coordinated attack.Additionally, we introduce a specific defense mechanism tailored for targetedattacks in FSR, aiming to evaluate the mitigation effects of the attack methodwe proposed. Extensive experiments validate the effectiveness of our proposedapproach on representative sequential models. Our codes are publicly available.</description>
      <author>example@mail.com (Qitao Qin, Yucong Luo, Zhibo Chu)</author>
      <guid isPermaLink="false">2507.01383v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Cage-Based Deformation for Transferable and Undefendable Point Cloud Attack</title>
      <link>http://arxiv.org/abs/2507.00690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于笼子的变形框架CageAttack，用于生成自然对抗性点云，旨在解决现有方法中对抗性攻击对几何约束的限制和变形的不自然性。&lt;h4&gt;背景&lt;/h4&gt;对抗性攻击在点云上通常需要严格的几何约束以保持合理性，但这种约束限制了攻击的可迁移性和不可防御性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以生成既自然又具有攻击性的点云，同时保持其合理性。&lt;h4&gt;方法&lt;/h4&gt;CageAttack首先在目标对象周围构建一个笼子，提供一个结构化的基础进行平滑、自然的外观变形。然后对笼子顶点进行扰动，这些扰动无缝地传播到点云上，确保生成的变形与对象内在相关并保持合理性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个3D深度神经网络分类器上的大量实验表明，CageAttack在可迁移性、不可防御性和合理性之间取得了优越的平衡，优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;CageAttack是一种有效的生成自然对抗性点云的方法，其性能优于现有技术。&lt;h4&gt;翻译&lt;/h4&gt;Adversarial attacks on point clouds often impose strict geometric constraints to preserve plausibility; however, such constraints inherently limit transferability and undefendability. While deformation offers an alternative, existing unstructured approaches may introduce unnatural distortions, making adversarial point clouds conspicuous and undermining their plausibility. In this paper, we propose CageAttack, a cage-based deformation framework that produces natural adversarial point clouds. It first constructs a cage around the target object, providing a structured basis for smooth, natural-looking deformation. Perturbations are then applied to the cage vertices, which seamlessly propagate to the point cloud, ensuring that the resulting deformations remain intrinsic to the object and preserve plausibility. Extensive experiments on seven 3D deep neural network classifiers across three datasets show that CageAttack achieves a superior balance among transferability, undefendability, and plausibility, outperforming state-of-the-art methods. Codes will be made public upon acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adversarial attacks on point clouds often impose strict geometric constraintsto preserve plausibility; however, such constraints inherently limittransferability and undefendability. While deformation offers an alternative,existing unstructured approaches may introduce unnatural distortions, makingadversarial point clouds conspicuous and undermining their plausibility. Inthis paper, we propose CageAttack, a cage-based deformation framework thatproduces natural adversarial point clouds. It first constructs a cage aroundthe target object, providing a structured basis for smooth, natural-lookingdeformation. Perturbations are then applied to the cage vertices, whichseamlessly propagate to the point cloud, ensuring that the resultingdeformations remain intrinsic to the object and preserve plausibility.Extensive experiments on seven 3D deep neural network classifiers across threedatasets show that CageAttack achieves a superior balance amongtransferability, undefendability, and plausibility, outperformingstate-of-the-art methods. Codes will be made public upon acceptance.</description>
      <author>example@mail.com (Keke Tang, Ziyong Du, Weilong Peng, Xiaofei Wang, Peican Zhu, Ligang Liu, Zhihong Tian)</author>
      <guid isPermaLink="false">2507.00690v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Natural language processing for African languages</title>
      <link>http://arxiv.org/abs/2507.00297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了利用大规模无标签数据和自监督学习提升自然语言处理（NLP）性能的近期进展，重点关注撒哈拉以南非洲的低资源语言，并提出了解决方法。&lt;h4&gt;背景&lt;/h4&gt;多语言模型通常在类似维基百科这样的网络数据上训练，但面临着包括数据噪声、低资源语言数据少以及缺乏标注数据集等挑战。&lt;h4&gt;目的&lt;/h4&gt;针对撒哈拉以南非洲地区的低资源语言，分析公开语料库中的噪声，整理高质量语料库，并探索如何适应和专门化多语言预训练语言模型。&lt;h4&gt;方法&lt;/h4&gt;对公开语料库中的噪声进行分析，创建高质量语料库；通过实证研究词嵌入的局限性以及多语言预训练语言模型在低资源场景下的机遇；研究如何利用少量单语文本对多语言预训练语言模型进行适应和专门化；开发大规模人工标注数据集；在监督学习、弱监督学习和迁移学习设置中使用最先进的方法进行广泛实证评估。&lt;h4&gt;主要发现&lt;/h4&gt;语义表示学习的质量不仅取决于数据量，还取决于预训练数据的质量；词嵌入存在局限性，多语言预训练语言模型为低资源语言提供了机遇；针对低资源非洲语言，可以有效地适应和专门化多语言预训练语言模型。&lt;h4&gt;结论&lt;/h4&gt;针对撒哈拉以南非洲地区的低资源语言，提出的方法能够提升NLP性能，并通过实证评估验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in word embeddings and language models use large-scale,unlabelled data and self-supervised learning to boost NLP performance. Multilingual models, often trained on web-sourced data like Wikipedia, face challenges: few low-resource languages are included, their data is often noisy, and lack of labeled datasets makes it hard to evaluate performance outside high-resource languages like English. In this dissertation, we focus on languages spoken in Sub-Saharan Africa where all the indigenous languages in this region can be regarded as low-resourced in terms of the availability of labeled data for NLP tasks and unlabelled data found on the web. We analyze the noise in the publicly available corpora, and curate a high-quality corpus, demonstrating that the quality of semantic representations learned in word embeddings does not only depend on the amount of data but on the quality of pre-training data. We demonstrate empirically the limitations of word embeddings, and the opportunities the multilingual pre-trained language model (PLM) offers especially for languages unseen during pre-training and low-resource scenarios. We further study how to adapt and specialize multilingual PLMs to unseen African languages using a small amount of monolingual texts. To address the under-representation of the African languages in NLP research, we developed large scale human-annotated labelled datasets for 21 African languages in two impactful NLP tasks: named entity recognition and machine translation. We conduct an extensive empirical evaluation using state-of-the-art methods across supervised, weakly-supervised, and transfer learning settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in word embeddings and language models use large-scale,unlabelled data and self-supervised learning to boost NLP performance.Multilingual models, often trained on web-sourced data like Wikipedia, facechallenges: few low-resource languages are included, their data is often noisy,and lack of labeled datasets makes it hard to evaluate performance outsidehigh-resource languages like English. In this dissertation, we focus onlanguages spoken in Sub-Saharan Africa where all the indigenous languages inthis region can be regarded as low-resourced in terms of the availability oflabelled data for NLP tasks and unlabelled data found on the web. We analysethe noise in the publicly available corpora, and curate a high-quality corpus,demonstrating that the quality of semantic representations learned in wordembeddings does not only depend on the amount of data but on the quality ofpre-training data. We demonstrate empirically the limitations of wordembeddings, and the opportunities the multilingual pre-trained language model(PLM) offers especially for languages unseen during pre-training andlow-resource scenarios. We further study how to adapt and specializemultilingual PLMs to unseen African languages using a small amount ofmonolingual texts. To address the under-representation of the African languagesin NLP research, we developed large scale human-annotated labelled datasets for21 African languages in two impactful NLP tasks: named entity recognition andmachine translation. We conduct an extensive empirical evaluation usingstate-of-the-art methods across supervised, weakly-supervised, and transferlearning settings.</description>
      <author>example@mail.com (David Ifeoluwa Adelani)</author>
      <guid isPermaLink="false">2507.00297v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Proof of a perfect platonic representation hypothesis</title>
      <link>http://arxiv.org/abs/2507.01098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细阐述了Ziyi等人在2025年提出的关于嵌入式深度线性网络模型（EDLN）的“完美”柏拉图表示假设（PRH）的证明。&lt;h4&gt;背景&lt;/h4&gt;PRH假设，如果使用随机梯度下降（SGD）训练，不同宽度和深度的EDLN在训练不同数据后，将形成完美的柏拉图表示，即每一对可能的层都将学习到相同的表示（除以一个旋转外）。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是解释该证明并提供指导，避免详细的数学技术细节。&lt;h4&gt;方法&lt;/h4&gt;本文通过理论分析和证明，揭示了SGD训练过程中的不可逆性导致的“熵力”在表示学习中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;发现SGD仅能找到完美的柏拉图解，这是一个异常现象。证明还提出了至少六种方法可以打破PRH。此外，柏拉图表示的出现与渐进式锐化现象的成因相同，这意味着深度学习中的两个看似无关的现象可能有共同的成因。&lt;h4&gt;结论&lt;/h4&gt;理论和证明突出了理解由于SGD训练不可逆性产生的“熵力”及其在表示学习中的重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this note, we elaborate on and explain in detail the proof given by Ziyinet al. (2025) of the "perfect" Platonic Representation Hypothesis (PRH) for theembedded deep linear network model (EDLN). We show that if trained with SGD,two EDLNs with different widths and depths and trained on different data willbecome Perfectly Platonic, meaning that every possible pair of layers willlearn the same representation up to a rotation. Because most of the globalminima of the loss function are not Platonic, that SGD only finds the perfectlyPlatonic solution is rather extraordinary. The proof also suggests at least sixways the PRH can be broken. We also show that in the EDLN model, the emergenceof the Platonic representations is due to the same reason as the emergence ofprogressive sharpening. This implies that these two seemingly unrelatedphenomena in deep learning can, surprisingly, have a common cause. Overall, thetheory and proof highlight the importance of understanding emergent "entropicforces" due to the irreversibility of SGD training and their role inrepresentation learning. The goal of this note is to be instructive and avoidlengthy technical details.</description>
      <author>example@mail.com (Liu Ziyin, Isaac Chuang)</author>
      <guid isPermaLink="false">2507.01098v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs</title>
      <link>http://arxiv.org/abs/2507.01881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TANGERINE，一款用于体积LDCT分析的计算效率高、开源的视觉基础模型，旨在解决肺癌筛查（LCS）项目中放射科医生短缺的问题。&lt;h4&gt;背景&lt;/h4&gt;全球范围内，低剂量计算机断层扫描（LDCT）在肺癌筛查（LCS）项目中的应用正在增加。LCS项目为同时检测癌症和非癌症相关的早期肺癌疾病提供了代际机遇，但这些努力受到放射科医生人数不足的限制。&lt;h4&gt;目的&lt;/h4&gt;开发TANGERINE模型，以解决在有限的计算资源和训练数据下，快速适应各种疾病特定任务的挑战。&lt;h4&gt;方法&lt;/h4&gt;TANGERINE模型基于掩码自编码器框架，扩展到3D成像，并使用自我监督学习在超过98,000个胸部LDCT上进行预训练，包括英国迄今为止最大的LCS项目和27个公共数据集。&lt;h4&gt;主要发现&lt;/h4&gt;TANGERINE在14个疾病分类任务中实现了最先进的性能，包括肺癌和多种呼吸系统疾病，同时在不同临床中心表现出良好的泛化能力。与从头开始训练的模型相比，TANGERINE在微调期间表现出快速收敛，因此需要显著更少的GPU小时数，并且具有强大的标签效率。&lt;h4&gt;结论&lt;/h4&gt;TANGERINE的轻量级、开源设计为将其快速集成到下一代医学成像工具奠定了基础，这些工具可以改变LCS项目，使其从单一的关注肺癌检测转变为高风险人群的综合呼吸系统疾病管理。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在全世界范围内，用于肺癌筛查（LCS）项目的低剂量计算机断层扫描（LDCT）成像的采用率正在增加。LCS项目预示着同时检测癌症和非癌症相关的早期肺癌疾病的代际机遇。然而，这些努力受到缺乏能够大规模解读扫描的放射科医生的阻碍。在这里，我们介绍了TANGERINE，这是一种用于体积LDCT分析的具有计算效率、开源的视觉基础模型。TANGERINE旨在实现广泛的可访问性和快速适应性，它可以利用有限的计算资源和训练数据，直接进行微调以适应广泛的疾病特定任务。与从头开始训练的模型相比，TANGERINE在微调期间表现出快速收敛，因此需要显著更少的GPU小时数，并且显示出强大的标签效率，通过一小部分微调数据就能实现相当或更好的性能。TANGERINE使用自我监督学习在超过98,000个胸部LDCT上进行预训练，包括迄今为止英国最大的LCS项目和27个公共数据集，实现了14个疾病分类任务的最先进性能，包括肺癌和多种呼吸系统疾病，同时在不同的临床中心表现出良好的泛化能力。通过将掩码自编码器框架扩展到3D成像，TANGERINE提供了一种可扩展的LDCT分析解决方案，与最近的封闭、资源密集型模型不同，它结合了架构简单性、公共可用性和适度的计算需求。其可访问的、开源的轻量级设计为将其快速集成到下一代医学成像工具奠定了基础，这些工具可以改变LCS项目，使其从单一的关注肺癌检测转变为高风险人群的综合呼吸系统疾病管理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-dose computed tomography (LDCT) imaging employed in lung cancer screening(LCS) programs is increasing in uptake worldwide. LCS programs herald agenerational opportunity to simultaneously detect cancer and non-cancer-relatedearly-stage lung disease. Yet these efforts are hampered by a shortage ofradiologists to interpret scans at scale. Here, we present TANGERINE, acomputationally frugal, open-source vision foundation model for volumetric LDCTanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE canbe fine-tuned off the shelf for a wide range of disease-specific tasks withlimited computational resources and training data. Relative to models trainedfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,thereby requiring significantly fewer GPU hours, and displays strong labelefficiency, achieving comparable or superior performance with a fraction offine-tuning data. Pretrained using self-supervised learning on over 98,000thoracic LDCTs, including the UK's largest LCS initiative to date and 27 publicdatasets, TANGERINE achieves state-of-the-art performance across 14 diseaseclassification tasks, including lung cancer and multiple respiratory diseases,while generalising robustly across diverse clinical centres. By extending amasked autoencoder framework to 3D imaging, TANGERINE offers a scalablesolution for LDCT analysis, departing from recent closed, resource-intensivemodels by combining architectural simplicity, public availability, and modestcomputational requirements. Its accessible, open-source lightweight design laysthe foundation for rapid integration into next-generation medical imaging toolsthat could transform LCS initiatives, allowing them to pivot from a singularfocus on lung cancer detection to comprehensive respiratory disease managementin high-risk populations.</description>
      <author>example@mail.com (Niccolò McConnell, Pardeep Vasudev, Daisuke Yamada, Daryl Cheng, Mehran Azimbagirad, John McCabe, Shahab Aslani, Ahmed H. Shahin, Yukun Zhou, The SUMMIT Consortium, Andre Altmann, Yipeng Hu, Paul Taylor, Sam M. Janes, Daniel C. Alexander, Joseph Jacob)</author>
      <guid isPermaLink="false">2507.01881v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NN-Former: Rethinking Graph Structure in Neural Architecture Representation</title>
      <link>http://arxiv.org/abs/2507.00880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025. Code is avaiable at  https://github.com/XuRuihan/NNFormer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的神经网络预测器，旨在提高网络设计和部署的效率，特别是在估计准确性和延迟等属性方面。该预测器结合了图神经网络（GNN）和Transformer的优点，以学习更优的网络拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的广泛应用，对高效网络设计和部署的需求日益增加，这使得神经网络预测器在估计网络属性（如准确性和延迟）方面变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法（如GNN和Transformer）的不足，本文旨在提出一种新的神经网络架构，以更有效地估计网络属性。&lt;h4&gt;方法&lt;/h4&gt;本文重新思考了神经网络架构的拓扑结构，并提出了一个利用GNN和Transformer优势的新预测器。该预测器引入了新的token mixer和channel mixer，以考虑兄弟节点并提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在准确性和延迟预测方面表现出色，为学习有向无环图（DAG）拓扑提供了有价值的信息。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为网络设计和部署提供了新的思路，有助于提高网络性能。&lt;h4&gt;翻译&lt;/h4&gt;The growing use of deep learning necessitates efficient network design and deployment, making neural predictors vital for estimating attributes such as accuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers have shown promising performance in representing neural architectures. However, each of both methods has its disadvantages. GNNs lack the capabilities to represent complicated features, while transformers face poor generalization when the depth of architecture grows. To mitigate the above issues, we rethink neural architecture topology and show that sibling nodes are pivotal while overlooked in previous research. We thus propose a novel predictor leveraging the strengths of GNNs and transformers to learn the enhanced topology. We introduce a novel token mixer that considers siblings, and a new channel mixer named bidirectional graph isomorphism feed-forward network. Our approach consistently achieves promising performance in both accuracy and latency prediction, providing valuable insights for learning Directed Acyclic Graph (DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing use of deep learning necessitates efficient network design anddeployment, making neural predictors vital for estimating attributes such asaccuracy and latency. Recently, Graph Neural Networks (GNNs) and transformershave shown promising performance in representing neural architectures. However,each of both methods has its disadvantages. GNNs lack the capabilities torepresent complicated features, while transformers face poor generalizationwhen the depth of architecture grows. To mitigate the above issues, we rethinkneural architecture topology and show that sibling nodes are pivotal whileoverlooked in previous research. We thus propose a novel predictor leveragingthe strengths of GNNs and transformers to learn the enhanced topology. Weintroduce a novel token mixer that considers siblings, and a new channel mixernamed bidirectional graph isomorphism feed-forward network. Our approachconsistently achieves promising performance in both accuracy and latencyprediction, providing valuable insights for learning Directed Acyclic Graph(DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer.</description>
      <author>example@mail.com (Ruihan Xu, Haokui Zhang, Yaowei Wang, Wei Zeng, Shiliang Zhang)</author>
      <guid isPermaLink="false">2507.00880v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Neural Augmented Kalman Filters for Road Network assisted GNSS positioning</title>
      <link>http://arxiv.org/abs/2507.00654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025 workshop ML4Wireless&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合道路网络数据和GNSS测量的深度学习方法，用于提高密集城市环境中的定位精度。&lt;h4&gt;背景&lt;/h4&gt;GNSS在密集城市环境中的定位精度常受到多径和非视距误差的影响。&lt;h4&gt;目的&lt;/h4&gt;通过使用道路网络数据来减少这些误差，提高定位系统的精度。&lt;h4&gt;方法&lt;/h4&gt;提出训练一个时间图神经网络（TGNN）来整合道路网络信息到卡尔曼滤波器（KF）中，TGNN用于预测正确的道路段及其相关的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用GNSS的KF相比，该方法在真实世界GNSS数据和开源道路网络上的验证中，在具有挑战性的场景中观察到了29%的定位误差减少。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法是首个基于深度学习，同时使用道路网络数据和GNSS测量来确定地球用户位置的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Global Navigation Satellite System (GNSS) provides critical positioninginformation globally, but its accuracy in dense urban environments is oftencompromised by multipath and non-line-of-sight errors. Road network data can beused to reduce the impact of these errors and enhance the accuracy of apositioning system. Previous works employing road network data are eitherlimited to offline applications, or rely on Kalman Filter (KF) heuristics withlittle flexibility and robustness. We instead propose training a Temporal GraphNeural Network (TGNN) to integrate road network information into a KF. The TGNNis designed to predict the correct road segment and its associated uncertaintyto be used in the measurement update step of the KF. We validate our approachwith real-world GNSS data and open-source road networks, observing a 29%decrease in positioning error for challenging scenarios compared to a GNSS-onlyKF. To the best of our knowledge, ours is the first deep learning-basedapproach jointly employing road network data and GNSS measurements to determinethe user position on Earth.</description>
      <author>example@mail.com (Hans van Gorp, Davide Belli, Amir Jalalirad, Bence Major)</author>
      <guid isPermaLink="false">2507.00654v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Cooperative Sheaf Neural Networks</title>
      <link>http://arxiv.org/abs/2507.00647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了sheaf扩散在图表示学习中的应用，并提出了Cooperative Sheaf Neural Networks（CSNNs）以解决现有sheaf扩散方法缺乏信息方向性和无法实现合作行为的问题。&lt;h4&gt;背景&lt;/h4&gt;Sheaf扩散因其处理异质数据和避免过度平滑的能力，以及合作信息传递增强信息扩散灵活性的方法，成为图表示学习中的有前景设计模式。&lt;h4&gt;目的&lt;/h4&gt;研究sheaf扩散是否能够展现合作行为，并提出一种新的方法来克服现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了在有向图上的细胞层概念，并对其入度和出度的拉普拉斯矩阵进行了特征化。利用这一构造提出了CSNNs，并分析了其感受野特性。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有的sheaf扩散方法由于缺乏信息方向性而无法实现合作行为。通过CSNNs，节点能够选择性地关注任意远距离的节点，而忽略路径上的其他节点。&lt;h4&gt;结论&lt;/h4&gt;CSNNs在sheaf扩散和合作图神经网络方面表现优于现有方法，有助于缓解过度压缩问题。&lt;h4&gt;翻译&lt;/h4&gt;Sheaf扩散最近成为图表示学习的一种有前途的设计模式，因为它固有的处理异质数据和避免过度平滑的能力。同时，合作信息传递也被提出作为一种增强信息扩散灵活性的方法，允许节点独立选择是否从邻居那里传播/收集信息。随之而来的是一个自然的问题：sheaf扩散是否能够表现出这种合作行为？在这里，我们给出了一个否定的答案。特别是，我们表明，由于缺乏消息方向性，现有的sheaf扩散方法无法实现合作行为。为了克服这一局限性，我们引入了在有向图上的细胞层概念，并对其入度和出度的拉普拉斯矩阵进行了特征化。我们利用我们的构造提出了合作sheaf神经网络（CSNNs）。从理论上讲，我们描述了CSNN的感受野，并表明它允许节点选择性地关注任意远距离的节点，而忽略它们路径上的所有其他节点，这可能有助于缓解过度压缩。我们的实验表明，与先前的sheaf扩散和合作图神经网络相比，CSNN在整体性能上有所提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sheaf diffusion has recently emerged as a promising design pattern for graphrepresentation learning due to its inherent ability to handle heterophilic dataand avoid oversmoothing. Meanwhile, cooperative message passing has also beenproposed as a way to enhance the flexibility of information diffusion byallowing nodes to independently choose whether to propagate/gather informationfrom/to neighbors. A natural question ensues: is sheaf diffusion capable ofexhibiting this cooperative behavior? Here, we provide a negative answer tothis question. In particular, we show that existing sheaf diffusion methodsfail to achieve cooperative behavior due to the lack of message directionality.To circumvent this limitation, we introduce the notion of cellular sheaves overdirected graphs and characterize their in- and out-degree Laplacians. Weleverage our construction to propose Cooperative Sheaf Neural Networks (CSNNs).Theoretically, we characterize the receptive field of CSNN and show it allowsnodes to selectively attend (listen) to arbitrarily far nodes while ignoringall others in their path, potentially mitigating oversquashing. Our experimentsshow that CSNN presents overall better performance compared to prior art onsheaf diffusion as well as cooperative graph neural networks.</description>
      <author>example@mail.com (André Ribeiro, Ana Luiza Tenório, Juan Belieni, Amauri H. Souza, Diego Mesquita)</author>
      <guid isPermaLink="false">2507.00647v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing</title>
      <link>http://arxiv.org/abs/2507.01275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于频率域的扩散模型（ours）用于去雾，该模型能够充分利用无配对清晰数据中的有益知识，并优于其他最先进的方法。&lt;h4&gt;背景&lt;/h4&gt;无配对图像去雾因其灵活的数据需求而受到越来越多的关注，但基于对比学习的方法未能充分利用频率域中的去雾特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的去雾方法，以解决现有方法中引入无关内容信息和忽略频率域中去雾特性的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ours的频率域扩散模型，包括：1. 提出振幅残差编码器（ARE）提取振幅残差，补偿模糊到清晰域的振幅差距；2. 提出相位校正模块（PCM）通过简单的注意力机制进一步细化相位谱以消除伪影。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ours在合成和真实世界数据集上均优于其他最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ours模型能够有效去雾，并优于现有的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about proposing a novel frequency domain-based diffusion model (ours) for image dehazing, which effectively utilizes the beneficial knowledge in unpaired clear data and outperforms other state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired image dehazing has attracted increasing attention due to itsflexible data requirements during model training. Dominant methods based oncontrastive learning not only introduce haze-unrelated content information, butalso ignore haze-specific properties in the frequency domain (\ie,~haze-relateddegradation is mainly manifested in the amplitude spectrum). To address theseissues, we propose a novel frequency domain-based diffusion model, named \ours,for fully exploiting the beneficial knowledge in unpaired clear data. Inparticular, inspired by the strong generative ability shown by Diffusion Models(DMs), we tackle the dehazing task from the perspective of frequency domainreconstruction and perform the DMs to yield the amplitude spectrum consistentwith the distribution of clear images. To implement it, we propose an AmplitudeResidual Encoder (ARE) to extract the amplitude residuals, which effectivelycompensates for the amplitude gap from the hazy to clear domains, as well asprovide supervision for the DMs training. In addition, we propose a PhaseCorrection Module (PCM) to eliminate artifacts by further refining the phasespectrum during dehazing with a simple attention mechanism. Experimentalresults demonstrate that our \ours outperforms other state-of-the-art methodson both synthetic and real-world datasets.</description>
      <author>example@mail.com (Chengxu Liu, Lu Qi, Jinshan Pan, Xueming Qian, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2507.01275v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2507.00669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress, 42 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Audio-3DVG的框架，用于基于音频的3D视觉定位，通过结合音频和空间信息来提高定位效果。&lt;h4&gt;背景&lt;/h4&gt;虽然基于文本描述的3D视觉定位已有进展，但利用语音的Audio-3DVG仍然是一个未充分探索且具有挑战性的领域。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合自动语音识别和语音表示学习，提出一种简单而有效的框架，以提高基于音频的3D视觉定位的性能。&lt;h4&gt;方法&lt;/h4&gt;将任务分解为两个互补的组件：对象提及检测和音频引导注意力模块。对象提及检测用于识别音频中提到的对象，音频引导注意力模块则用于捕捉候选对象与关系性语音线索之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;通过合成音频描述并应用于标准3DVG数据集，实验结果表明Audio-3DVG在基于音频的定位中达到了新的水平，并且在性能上可以与基于文本的方法相媲美。&lt;h4&gt;结论&lt;/h4&gt;将语音语言集成到3D视觉任务中具有很大的潜力，Audio-3DVG框架为这一领域的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D视觉定位（3DVG）涉及根据自然语言在3D点云中定位目标对象。尽管先前的工作在文本描述方面取得了进展，但利用语音的音频3D视觉定位（Audio-3DVG）仍然是一个未充分探索且具有挑战性的领域。受自动语音识别（ASR）和语音表示学习进展的启发，我们提出了Audio-3DVG，这是一个简单而有效的框架，它集成了音频和空间信息以增强定位。我们不是将语音视为一个统一的输入，而是将任务分解为两个互补的组件。首先，我们引入了对象提及检测，这是一个多标签分类任务，它明确地识别音频中提到的对象，从而使得音频场景推理更加结构化。其次，我们提出了一个音频引导注意力模块，它捕捉候选对象与关系性语音线索之间的交互，从而提高了杂乱场景中的目标识别。为了支持基准测试，我们为标准3DVG数据集，包括ScanRefer、Sr3D和Nr3D，合成了音频描述。实验结果表明，Audio-3DVG不仅在基于音频的定位中实现了新的最先进性能，而且在与基于文本的方法的竞争中表现良好，突显了将语音语言集成到3D视觉任务中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Visual Grounding (3DVG) involves localizing target objects in 3D pointclouds based on natural language. While prior work has made strides usingtextual descriptions, leveraging spoken language-known as Audio-based 3D VisualGrounding-remains underexplored and challenging. Motivated by advances inautomatic speech recognition (ASR) and speech representation learning, wepropose Audio-3DVG, a simple yet effective framework that integrates audio andspatial information for enhanced grounding. Rather than treating speech as amonolithic input, we decompose the task into two complementary components.First, we introduce Object Mention Detection, a multi-label classification taskthat explicitly identifies which objects are referred to in the audio, enablingmore structured audio-scene reasoning. Second, we propose an Audio-GuidedAttention module that captures interactions between candidate objects andrelational speech cues, improving target discrimination in cluttered scenes. Tosupport benchmarking, we synthesize audio descriptions for standard 3DVGdatasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstratethat Audio-3DVG not only achieves new state-of-the-art performance inaudio-based grounding, but also competes with text-based methods-highlightingthe promise of integrating spoken language into 3D vision tasks.</description>
      <author>example@mail.com (Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang)</author>
      <guid isPermaLink="false">2507.00669v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ShapeEmbed: a self-supervised learning framework for 2D contour quantification</title>
      <link>http://arxiv.org/abs/2507.01009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ShapeEmbed的自监督表示学习框架，用于编码2D图像中物体的轮廓，并生成对平移、缩放、旋转、反射和点索引不变性的形状描述符。&lt;h4&gt;背景&lt;/h4&gt;形状量化是一个核心挑战，需要确保提取的测量值对保持物体内在几何学的变换（如改变大小、方向和位置）保持不变。&lt;h4&gt;目的&lt;/h4&gt;提出ShapeEmbed框架，以克服传统形状描述符的局限性，并改进现有的基于自动编码器的最先进方法。&lt;h4&gt;方法&lt;/h4&gt;ShapeEmbed框架将物体的轮廓编码为欧几里得距离矩阵，并生成不变的形状描述符。&lt;h4&gt;主要发现&lt;/h4&gt;ShapeEmbed框架在自然和生物图像上的形状分类任务中，其学习到的描述符优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;ShapeEmbed框架对于生物成像应用尤其相关。&lt;h4&gt;翻译&lt;/h4&gt;物体形状是广泛应用程序中视觉信息的一个重要来源。形状量化的一项核心挑战是确保提取的测量值对保持物体内在几何学的变换（如改变其大小、方向和图像中的位置）保持不变。在这项工作中，我们引入了一种名为ShapeEmbed的自监督表示学习框架，用于将2D图像中物体的轮廓编码为欧几里得距离矩阵，并生成对平移、缩放、旋转、反射和点索引不变性的形状描述符。我们的方法克服了传统形状描述符的局限性，并改进了现有的基于自动编码器的最先进方法。我们证明了我们的框架学习到的描述符在自然和生物图像的形状分类任务中优于其竞争对手。我们预计我们的方法对于生物成像应用尤其相关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The shape of objects is an important source of visual information in a widerange of applications. One of the core challenges of shape quantification is toensure that the extracted measurements remain invariant to transformations thatpreserve an object's intrinsic geometry, such as changing its size,orientation, and position in the image. In this work, we introduce ShapeEmbed,a self-supervised representation learning framework designed to encode thecontour of objects in 2D images, represented as a Euclidean distance matrix,into a shape descriptor that is invariant to translation, scaling, rotation,reflection, and point indexing. Our approach overcomes the limitations oftraditional shape descriptors while improving upon existing state-of-the-artautoencoder-based approaches. We demonstrate that the descriptors learned byour framework outperform their competitors in shape classification tasks onnatural and biological images. We envision our approach to be of particularrelevance to biological imaging applications.</description>
      <author>example@mail.com (Anna Foix Romero, Craig Russell, Alexander Krull, Virginie Uhlmann)</author>
      <guid isPermaLink="false">2507.01009v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Auto-Encoders for Time-Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2507.01875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ACM KDD 2024, MiLeTS 2024 Workshop, August 25, 2024,  Barcelona, Spain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于预训练基础模型的时间序列建模新方法，用于时间序列数据中的异常检测。&lt;h4&gt;背景&lt;/h4&gt;该方法受到大型预训练基础模型成功应用的影响，旨在提高时间序列数据的建模、预测和异常检测的准确性。&lt;h4&gt;目的&lt;/h4&gt;研究并实现一种新的时间序列异常检测模型，即FAE（基础自动编码器），以实现对未见数据集上的复杂时间模式的准确建模。&lt;h4&gt;方法&lt;/h4&gt;FAE模型基于变分自动编码器（VAEs）和扩张卷积神经网络（DCNNs），通过在大量时间序列数据上预训练来学习复杂的时间模式。&lt;h4&gt;主要发现&lt;/h4&gt;FAE模型在多个多维时间序列数据集上取得了初步成果，包括来自实际移动ISP操作的数据集和KDD 2021异常检测数据集。&lt;h4&gt;结论&lt;/h4&gt;FAE模型在时间序列异常检测方面展现出潜力，未来可能适用于零样本异常检测应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate a novel approach to time-series modeling, inspired by thesuccesses of large pretrained foundation models. We introduce FAE (FoundationAuto-Encoders), a foundation generative-AI model for anomaly detection intime-series data, based on Variational Auto-Encoders (VAEs). By foundation, wemean a model pretrained on massive amounts of time-series data which can learncomplex temporal patterns useful for accurate modeling, forecasting, anddetection of anomalies on previously unseen datasets. FAE leverages VAEs andDilated Convolutional Neural Networks (DCNNs) to build a generic model forunivariate time-series modeling, which could eventually perform properly inout-of-the-box, zero-shot anomaly detection applications. We introduce the mainconcepts of FAE, and present preliminary results in different multi-dimensionaltime-series datasets from various domains, including a real dataset from anoperational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.</description>
      <author>example@mail.com (Gastón García González, Pedro Casas, Emilio Martínez, Alicia Fernández)</author>
      <guid isPermaLink="false">2507.01875v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs</title>
      <link>http://arxiv.org/abs/2507.01073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的插件式3D编码模块，通过旋转采样计算SO(3)旋转群的期望，实现了近似的旋转不变性，并通过后对齐策略达到了严格的旋转不变性，实验结果表明该方法在预测准确性、鲁棒性和泛化性能方面优于现有方法，同时保持低计算复杂性和增强的可解释性。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络在分子性质预测中取得了显著成功，但传统的图表示方法难以有效地编码分子的内在3D空间结构，因为分子在3D空间中的方向性引入了显著的可变性，严重限制了模型的泛化能力和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的方法，以更有效地处理3D分子信息，从而提高分子性质预测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种利用旋转采样的新插件式3D编码模块，通过计算SO(3)旋转群的期望实现近似的旋转不变性，并通过精心设计的后对齐策略实现严格的旋转不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在QM9和C10数据集上表现出比现有方法更优越的预测准确性、鲁棒性和泛化性能。&lt;h4&gt;结论&lt;/h4&gt;该方法保持了低计算复杂性和增强的可解释性，为在药物发现和材料设计中高效且有效地处理3D分子信息提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have achieved remarkable success in molecular property prediction. However, traditional graph representations struggle to effectively encode the inherent 3D spatial structures of molecules, as molecular orientations in 3D space introduce significant variability, severely limiting model generalization and robustness. Existing approaches primarily focus on rotation-invariant and rotation-equivariant methods. Invariant methods often rely heavily on prior knowledge and lack sufficient generalizability, while equivariant methods suffer from high computational costs. To address these limitations, this paper proposes a novel plug-and-play 3D encoding module leveraging rotational sampling. By computing the expectation over the SO(3) rotational group, the method naturally achieves approximate rotational invariance. Furthermore, by introducing a carefully designed post-alignment strategy, strict invariance can be achieved without compromising performance. Experimental evaluations on the QM9 and C10 Datasets demonstrate superior predictive accuracy, robustness, and generalization performance compared to existing methods. Moreover, the proposed approach maintains low computational complexity and enhanced interpretability, providing a promising direction for efficient and effective handling of 3D molecular information in drug discovery and material design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have achieved remarkable success in molecularproperty prediction. However, traditional graph representations struggle toeffectively encode the inherent 3D spatial structures of molecules, asmolecular orientations in 3D space introduce significant variability, severelylimiting model generalization and robustness. Existing approaches primarilyfocus on rotation-invariant and rotation-equivariant methods. Invariant methodsoften rely heavily on prior knowledge and lack sufficient generalizability,while equivariant methods suffer from high computational costs. To addressthese limitations, this paper proposes a novel plug-and-play 3D encoding moduleleveraging rotational sampling. By computing the expectation over the SO(3)rotational group, the method naturally achieves approximate rotationalinvariance. Furthermore, by introducing a carefully designed post-alignmentstrategy, strict invariance can be achieved without compromising performance.Experimental evaluations on the QM9 and C10 Datasets demonstrate superiorpredictive accuracy, robustness, and generalization performance compared toexisting methods. Moreover, the proposed approach maintains low computationalcomplexity and enhanced interpretability, providing a promising direction forefficient and effective handling of 3D molecular information in drug discoveryand material design.</description>
      <author>example@mail.com (Dian Jin)</author>
      <guid isPermaLink="false">2507.01073v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Recipe for Causal Graph Regression: Confounding Effects Revisited</title>
      <link>http://arxiv.org/abs/2507.00440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了因果图学习（CGL）在回归任务中的应用，特别是在处理因变量中的混杂因素时，通过引入对比学习的方法提高了图神经网络在分布外（OOD）情况下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;因果图学习在分类设置中取得了成功，但在回归任务中却较少被关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决因果图回归（CGR）问题的方法，以改善图神经网络在回归任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;重新设计了现有因果图学习研究中混淆效应的处理方式，通过对比学习将分类特定的因果干预技术推广到回归任务中。&lt;h4&gt;主要发现&lt;/h4&gt;在图分布外基准测试上，实验验证了该方法对因果图回归的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高图神经网络在回归任务中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;通过识别因果子图，因果图学习（CGL）已成为提高图神经网络在分布外（OOD）场景下泛化能力的一种有前景的方法。然而，CGL技术的实证成功主要在分类设置中得到体现，而回归任务，作为图学习中的一个更具挑战性的设置，却被忽视了。因此，我们的这项工作致力于解决因果图回归（CGR）问题；为此，我们重新设计了现有CGL研究中处理混淆效应的方式，这些研究主要关注分类。具体来说，我们反思了混杂因素在图级回归中的预测能力，并通过对比学习的视角将分类特定的因果干预技术推广到回归任务中。在图OOD基准测试上的大量实验验证了我们对于CGR的建议的有效性。模型实现和代码可在https://github.com/causal-graph/CGR上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Through recognizing causal subgraphs, causal graph learning (CGL) has risento be a promising approach for improving the generalizability of graph neuralnetworks under out-of-distribution (OOD) scenarios. However, the empiricalsuccesses of CGL techniques are mostly exemplified in classification settings,while regression tasks, a more challenging setting in graph learning, areoverlooked. We thus devote this work to tackling causal graph regression (CGR);to this end we reshape the processing of confounding effects in existing CGLstudies, which mainly deal with classification. Specifically, we reflect on thepredictive power of confounders in graph-level regression, and generalizeclassification-specific causal intervention techniques to regression through alens of contrastive learning. Extensive experiments on graph OOD benchmarksvalidate the efficacy of our proposals for CGR. The model implementation andthe code are provided on https://github.com/causal-graph/CGR.</description>
      <author>example@mail.com (Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen)</author>
      <guid isPermaLink="false">2507.00440v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching</title>
      <link>http://arxiv.org/abs/2507.00371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为植物分割神经辐射场（PlantSegNeRF）的新方法，用于从多视角RGB图像序列中直接生成高精度的实例点云，以提高植物器官分割的分辨率、准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;植物点云器官分割是高分辨率和准确提取器官水平表型性状的前提。尽管深度学习快速发展，但现有的器官分割技术仍存在分辨率、分割准确性和跨物种泛化能力方面的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出PlantSegNeRF方法，以实现从多视角RGB图像序列中直接生成高精度实例点云，适用于多种植物物种。&lt;h4&gt;方法&lt;/h4&gt;PlantSegNeRF在多视角图像上进行二维实例分割，为每个器官生成带有对应ID的实例掩码。然后，使用专门设计的实例匹配模块匹配和细化对应同一植物器官的多视角实例ID。实例NeRF被开发出来渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体积密度将隐式场景转换为高精度植物实例点云。&lt;h4&gt;主要发现&lt;/h4&gt;在点云语义分割中，PlantSegNeRF优于常用方法，在结构复杂的数据集上，与第二好的结果相比，在精度、召回率、F1分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，PlantSegNeRF在植物点云实例分割任务中表现出显著优势，在所有植物数据集上，它在mPrec、mRec、mCov和mWCov方面的平均改进分别为11.7%、38.2%、32.2%和25.3%。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了器官水平的植物表型分析，为植物科学中大规模模型的发展提供了高通量方式，以提供高质量的3D数据。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物点云器官分割是高分辨率和准确提取器官水平表型性状的前提。尽管深度学习快速发展，但现有的器官分割技术仍存在分辨率、分割准确性和跨物种泛化能力方面的局限性。在本文中，我们提出了一种名为植物分割神经辐射场（PlantSegNeRF）的新方法，旨在直接从多视角RGB图像序列中为广泛的植物物种生成高精度实例点云。PlantSegNeRF在多视角图像上进行二维实例分割，为每个器官生成带有对应ID的实例掩码。然后，使用专门设计的实例匹配模块匹配和细化对应同一植物器官的多视角实例ID。实例NeRF被开发出来渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体积密度将隐式场景转换为高精度植物实例点云。结果表明，在点云语义分割中，PlantSegNeRF优于常用方法，在结构复杂的数据集上，与第二好的结果相比，在精度、召回率、F1分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，PlantSegNeRF在植物点云实例分割任务中表现出显著优势，在所有植物数据集上，它在mPrec、mRec、mCov和mWCov方面的平均改进分别为11.7%、38.2%、32.2%和25.3%。本研究扩展了器官水平的植物表型分析，为植物科学中大规模模型的发展提供了高通量方式，以提供高质量的3D数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Organ segmentation of plant point clouds is a prerequisite for thehigh-resolution and accurate extraction of organ-level phenotypic traits.Although the fast development of deep learning has boosted much research onsegmentation of plant point clouds, the existing techniques for organsegmentation still face limitations in resolution, segmentation accuracy, andgeneralizability across various plant species. In this study, we proposed anovel approach called plant segmentation neural radiance fields (PlantSegNeRF),aiming to directly generate high-precision instance point clouds frommulti-view RGB image sequences for a wide range of plant species. PlantSegNeRFperformed 2D instance segmentation on the multi-view images to generateinstance masks for each organ with a corresponding ID. The multi-view instanceIDs corresponding to the same plant organ were then matched and refined using aspecially designed instance matching module. The instance NeRF was developed torender an implicit scene, containing color, density, semantic and instanceinformation. The implicit scene was ultimately converted into high-precisionplant instance point clouds based on the volume density. The results provedthat in semantic segmentation of point clouds, PlantSegNeRF outperformed thecommonly used methods, demonstrating an average improvement of 16.1%, 18.3%,17.8%, and 24.2% in precision, recall, F1-score, and IoU compared to thesecond-best results on structurally complex datasets. More importantly,PlantSegNeRF exhibited significant advantages in plant point cloud instancesegmentation tasks. Across all plant datasets, it achieved average improvementsof 11.7%, 38.2%, 32.2% and 25.3% in mPrec, mRec, mCov, mWCov, respectively.This study extends the organ-level plant phenotyping and provides ahigh-throughput way to supply high-quality 3D data for the development oflarge-scale models in plant science.</description>
      <author>example@mail.com (Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang, Yu Jiang, Haiyan Cen)</author>
      <guid isPermaLink="false">2507.00371v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Deep Learning for Component Segmentation of Maize Plants</title>
      <link>http://arxiv.org/abs/2507.00182v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的创新方法，用于在LiDAR 3D点云数据集上检测单个植物组件。&lt;h4&gt;背景&lt;/h4&gt;在精确农业中，识别单个植物组件是作物生产探索中的重要任务，目前主要使用二维成像、三维重建和卷积神经网络等技术，但存在一些缺点。&lt;h4&gt;目的&lt;/h4&gt;旨在提高3D数据处理和识别单个植物组件的准确度。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于图神经网络（GNN）的概念，并使用主成分分析（PCA）增强特征。每个点被视为顶点，通过K-最近邻（KNN）层建立边，表示3D点云数据集。随后使用Edge-Conv层进一步增加每个点的特征。最后，应用图注意力网络（GAT）对植物的可见表型成分进行分类，如叶片、茎和土壤。&lt;h4&gt;主要发现&lt;/h4&gt;该基于图深度学习方法在识别单个植物组件的分割准确性方面得到提高，IoU平均百分比超过80%，优于其他基于点云的现有模型。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提升了单个植物组件的识别准确度，对于精确农业领域具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;In precision agriculture, one of the most important tasks when exploring crop production is identifying individual plant components. There are several attempts to accomplish this task by the use of traditional 2D imaging, 3D reconstructions, and Convolutional Neural Networks (CNN). However, they have several drawbacks when processing 3D data and identifying individual plant components. Therefore, in this work, we propose a novel Deep Learning architecture to detect components of individual plants on Light Detection and Ranging (LiDAR) 3D Point Cloud (PC) data sets. This architecture is based on the concept of Graph Neural Networks (GNN), and feature enhancing with Principal Component Analysis (PCA). For this, each point is taken as a vertex and by the use of a K-Nearest Neighbors (KNN) layer, the edges are established, thus representing the 3D PC data set. Subsequently, Edge-Conv layers are used to further increase the features of each point. Finally, Graph Attention Networks (GAT) are applied to classify visible phenotypic components of the plant, such as the leaf, stem, and soil. This study demonstrates that our graph-based deep learning approach enhances segmentation accuracy for identifying individual plant components, achieving percentages above 80% in the IoU average, thus outperforming other existing models based on point clouds.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In precision agriculture, one of the most important tasks when exploring cropproduction is identifying individual plant components. There are severalattempts to accomplish this task by the use of traditional 2D imaging, 3Dreconstructions, and Convolutional Neural Networks (CNN). However, they haveseveral drawbacks when processing 3D data and identifying individual plantcomponents. Therefore, in this work, we propose a novel Deep Learningarchitecture to detect components of individual plants on Light Detection andRanging (LiDAR) 3D Point Cloud (PC) data sets. This architecture is based onthe concept of Graph Neural Networks (GNN), and feature enhancing withPrincipal Component Analysis (PCA). For this, each point is taken as a vertexand by the use of a K-Nearest Neighbors (KNN) layer, the edges are established,thus representing the 3D PC data set. Subsequently, Edge-Conv layers are usedto further increase the features of each point. Finally, Graph AttentionNetworks (GAT) are applied to classify visible phenotypic components of theplant, such as the leaf, stem, and soil. This study demonstrates that ourgraph-based deep learning approach enhances segmentation accuracy foridentifying individual plant components, achieving percentages above 80% in theIoU average, thus outperforming other existing models based on point clouds.</description>
      <author>example@mail.com (J. I. Ruiz-Martinez, A. Mendez-Vazquez, E. Rodriguez-Tello)</author>
      <guid isPermaLink="false">2507.00182v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Feature Learning on Huge Knowledge Graphs for Downstream Machine Learning</title>
      <link>http://arxiv.org/abs/2507.00965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SEPAL是一种针对大型知识图谱的扩展嵌入传播算法，旨在生成高质量的嵌入表示，以提高下游任务的性能。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习任务可以从外部知识中受益，大型知识图谱存储了这样的知识，嵌入方法可以将其提炼成可用于下游应用的向量表示。&lt;h4&gt;目的&lt;/h4&gt;SEPAL旨在解决当前模型在链接预测优化和扩展到大型图谱时的局限性。&lt;h4&gt;方法&lt;/h4&gt;SEPAL通过仅优化一小部分实体的嵌入并使用消息传递传播这些嵌入到整个图，从而强制执行全局嵌入对齐。&lt;h4&gt;主要发现&lt;/h4&gt;SEPAL在7个大规模知识图谱和46个下游机器学习任务上进行了评估，结果显示SEPAL在下游任务上显著优于先前的方法，并且可以扩展其基础嵌入模型，使其能够在通用硬件上拟合巨大的知识图谱。&lt;h4&gt;结论&lt;/h4&gt;SEPAL是一种高效且可扩展的算法，能够生成高质量的知识图谱嵌入，适用于各种下游机器学习任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many machine learning tasks can benefit from external knowledge. Largeknowledge graphs store such knowledge, and embedding methods can be used todistill it into ready-to-use vector representations for downstreamapplications. For this purpose, current models have however two limitations:they are primarily optimized for link prediction, via local contrastivelearning, and they struggle to scale to the largest graphs due to GPU memorylimits. To address these, we introduce SEPAL: a Scalable Embedding PropagationALgorithm for large knowledge graphs designed to produce high-qualityembeddings for downstream tasks at scale. The key idea of SEPAL is to enforceglobal embedding alignment by optimizing embeddings only on a small core ofentities, and then propagating them to the rest of the graph via messagepassing. We evaluate SEPAL on 7 large-scale knowledge graphs and 46 downstreammachine learning tasks. Our results show that SEPAL significantly outperformsprevious methods on downstream tasks. In addition, SEPAL scales up its baseembedding model, enabling fitting huge knowledge graphs on commodity hardware.</description>
      <author>example@mail.com (Félix Lefebvre, Gaël Varoquaux)</author>
      <guid isPermaLink="false">2507.00965v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Fractional Policy Gradients: Reinforcement Learning with Long-Term Memory</title>
      <link>http://arxiv.org/abs/2507.00073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Journal of Machine Learning Research (JMLR), June 2025.  24 pages, 3 figures. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为分数策略梯度（FPG）的强化学习框架，该框架结合了分数微积分来优化长期时间建模。&lt;h4&gt;背景&lt;/h4&gt;标准策略梯度方法受到马尔可夫假设的限制，表现出高方差和采样效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;通过使用Caputo分数导数重新定义梯度，FPG建立了状态转换之间的幂律时间相关性。&lt;h4&gt;方法&lt;/h4&gt;开发了有效的递归计算技术，用于分数时间差分误差，具有恒定的时间和内存需求。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，FPG实现了与标准策略梯度相比的渐近方差降低，达到O(t^(-α))的阶数，同时保持收敛。&lt;h4&gt;结论&lt;/h4&gt;实证验证表明，与最先进的基线相比，FPG在样本效率上提高了35-68%，在方差上降低了24-52%。这一框架为在不增加计算开销的情况下利用长期依赖性提供了一种数学基础的方法。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为分数策略梯度（FPG）的强化学习框架，该框架结合了分数微积分来优化长期时间建模。标准策略梯度方法受到马尔可夫假设的限制，表现出高方差和采样效率低下的问题。通过使用Caputo分数导数重新定义梯度，FPG建立了状态转换之间的幂律时间相关性。我们开发了有效的递归计算技术，用于分数时间差分误差，具有恒定的时间和内存需求。理论分析表明，FPG实现了与标准策略梯度相比的渐近方差降低，达到O(t^(-α))的阶数，同时保持收敛。实证验证表明，与最先进的基线相比，FPG在样本效率上提高了35-68%，在方差上降低了24-52%。这一框架为在不增加计算开销的情况下利用长期依赖性提供了一种数学基础的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Fractional Policy Gradients (FPG), a reinforcement learningframework incorporating fractional calculus for long-term temporal modeling inpolicy optimization. Standard policy gradient approaches face limitations fromMarkovian assumptions, exhibiting high variance and inefficient sampling. Byreformulating gradients using Caputo fractional derivatives, FPG establishespower-law temporal correlations between state transitions. We develop anefficient recursive computation technique for fractional temporal-differenceerrors with constant time and memory requirements. Theoretical analysis showsFPG achieves asymptotic variance reduction of order O(t^(-alpha)) versusstandard policy gradients while preserving convergence. Empirical validationdemonstrates 35-68% sample efficiency gains and 24-52% variance reductionversus state-of-the-art baselines. This framework provides a mathematicallygrounded approach for leveraging long-range dependencies without computationaloverhead.</description>
      <author>example@mail.com (Urvi Pawar, Kunal Telangi)</author>
      <guid isPermaLink="false">2507.00073v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</title>
      <link>http://arxiv.org/abs/2506.09548v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Robotics and Automation Letters, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种紧密耦合的激光雷达-惯性测量单元-腿部里程计，该方法在无特征环境和可变形地形等恶劣条件下表现稳健。&lt;h4&gt;背景&lt;/h4&gt;针对无特征环境和可变形地形等挑战性条件，提出了一种新的腿部里程计方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种在线学习基于的腿部运动学模型，以提高机器人对不同负载变化和地形条件的适应性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为神经腿部运动学模型的在线学习模型，该模型结合了触觉信息（脚部反作用力）来隐式表达机器人脚部与地面之间的非线性动力学。通过联合解决运动学模型的在线训练和里程计估计，保持两者的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，结合神经腿部运动学模型的里程计估计优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在两个具有挑战性的环境中得到了验证，包括沙滩和校园，证明了其有效性和稳健性。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种紧密耦合的激光雷达-IMU-腿部里程计，该方法对无特征环境和可变形地形等恶劣条件具有鲁棒性。我们开发了一种基于在线学习的腿部运动学模型，即神经腿部运动学模型，该模型结合了触觉信息（脚部反作用力）来隐式表达机器人脚部与地面之间的非线性动力学。通过在线训练该模型，增强了其对机器人重量负载变化（例如，假设配送或运输任务）和地形条件的适应性。根据基于腿部运动学模型的运动预测的神经自适应腿部里程计因子和在线不确定性估计，我们共同解决了运动学模型的在线训练和里程计估计，在一个统一的因子图中保持两者的一致性。通过使用四足机器人在两个具有挑战性的环境中进行的实际实验，验证了所提出的方法：1）沙滩，代表一个极其无特征区域，具有可变形地形；2）校园，包括多个无特征区域和多种地形类型，如沥青、砾石（可变形地形）和草地。实验结果表明，我们的结合神经腿部运动学模型的里程计估计优于现有技术。我们的项目页面提供了更多详细信息：https://takuokawara.github.io/RAL2025_project_page/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3580332&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which isrobust to challenging conditions such as featureless environments anddeformable terrains. We developed an online learning-based leg kinematics modelnamed the neural leg kinematics model, which incorporates tactile information(foot reaction force) to implicitly express the nonlinear dynamics betweenrobot feet and the ground. Online training of this model enhances itsadaptability to weight load changes of a robot (e.g., assuming delivery ortransportation tasks) and terrain conditions. According to the \textit{neuraladaptive leg odometry factor} and online uncertainty estimation of the legkinematics model-based motion predictions, we jointly solve online training ofthis kinematics model and odometry estimation on a unified factor graph toretain the consistency of both. The proposed method was verified through realexperiments using a quadruped robot in two challenging situations: 1) a sandybeach, representing an extremely featureless area with a deformable terrain,and 2) a campus, including multiple featureless areas and terrain types ofasphalt, gravel (deformable terrain), and grass. Experimental results showedthat our odometry estimation incorporating the \textit{neural leg kinematicsmodel} outperforms state-of-the-art works. Our project page is available forfurther details: https://takuokawara.github.io/RAL2025_project_page/</description>
      <author>example@mail.com (Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida)</author>
      <guid isPermaLink="false">2506.09548v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs</title>
      <link>http://arxiv.org/abs/2507.01806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5-page main paper (excluding references) + 11-page appendix, 3  tables, 1 figure. Accepted to ICML 2025 Workshop on Efficient Systems for  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对计算资源有限的用户，特别是使用标准笔记本电脑CPU的用户，设计的LoRA微调方法，通过在CPU上直接构建轻量级的现有LoRA组合来训练适配器，以实现参数高效的模型微调。&lt;h4&gt;背景&lt;/h4&gt;LoRA（低秩适配器）在大型语言模型（LLM）的微调中表现出参数高效的更新能力，但其广泛应用受到GPU训练依赖的限制。&lt;h4&gt;目的&lt;/h4&gt;为计算资源有限的用户提供一种在CPU上实现LoRA微调的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过利用大量预训练的适配器，学习一个元算子，将任何输入数据集（表示为概率分布）映射到一组LoRA权重，并通过CPU上的轻量级组合直接构建适配器，而不进行新的基于梯度的更新。&lt;h4&gt;主要发现&lt;/h4&gt;虽然CPU训练的适配器性能不如GPU训练的适配器，但它们在下游任务上始终优于基线Mistral模型。&lt;h4&gt;结论&lt;/h4&gt;该方法为传统基于GPU的微调提供了一种实用且可访问的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large LanguageModels (LLMs) by enabling parameter-efficient updates. However, theirwidespread adoption remains limited by the reliance on GPU-based training. Inthis work, we propose a theoretically grounded approach to LoRA fine-tuningdesigned specifically for users with limited computational resources,particularly those restricted to standard laptop CPUs. Our method learns ameta-operator that maps any input dataset, represented as a probabilitydistribution, to a set of LoRA weights by leveraging a large bank ofpre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead ofperforming new gradient-based updates, our pipeline constructs adapters vialightweight combinations of existing LoRAs directly on CPU. While the resultingadapters do not match the performance of GPU-trained counterparts, theyconsistently outperform the base Mistral model on downstream tasks, offering apractical and accessible alternative to traditional GPU-based fine-tuning.</description>
      <author>example@mail.com (Reza Arabpour, Haitz Sáez de Ocáriz Borde, Anastasis Kratsios)</author>
      <guid isPermaLink="false">2507.01806v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement</title>
      <link>http://arxiv.org/abs/2507.00966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE/ACM Transactions on Audio, Speech, and Language  Processing for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MambAttention的新型混合架构，用于可泛化的单声道语音增强，并在多个指标上优于现有系统。&lt;h4&gt;背景&lt;/h4&gt;新序列模型如Mamba和xLSTM在语音增强、自动语音识别和自监督音频表示学习方面表现出色，但存在过拟合问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合架构，以解决序列模型过拟合的问题，并提高单声道语音增强的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了MambAttention模型，结合Mamba和共享的时间-频率多头注意力模块。同时，使用VoiceBank+Demand Extended(VB-DemandEx)数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;MambAttention模型在两个域外数据集DNS 2020和EARS-WHAM_v2上显著优于现有系统，同时在域内数据集VB-DemandEx上匹配现有系统的性能。&lt;h4&gt;结论&lt;/h4&gt;MambAttention模型在多个评价指标上优于现有系统，且在域外数据集上具有显著性能提升。&lt;h4&gt;翻译&lt;/h4&gt;With the advent of new sequence models like Mamba and xLSTM, several studies have shown that these models match or outperform state-of-the-art models in single-channel speech enhancement, automatic speech recognition, and self-supervised audio representation learning. However, prior research has demonstrated that sequence models like LSTM and Mamba tend to overfit to the training set. To address this issue, previous works have shown that adding self-attention to LSTMs substantially improves generalization performance for single-channel speech enhancement. Nevertheless, neither the concept of hybrid Mamba and time-frequency attention models nor their generalization performance have been explored for speech enhancement. In this paper, we propose a novel hybrid architecture, MambAttention, which combines Mamba and shared time- and frequency-multi-head attention modules for generalizable single-channel speech enhancement. To train our model, we introduce VoiceBank+Demand Extended (VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our proposed MambAttention model significantly outperforms existing state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar complexity across all reported metrics on two out-of-domain datasets: DNS 2020 and EARS-WHAM_v2, while matching their performance on the in-domain dataset VB-DemandEx. Ablation studies highlight the role of weight sharing between the time- and frequency-multi-head attention modules for generalization performance. Finally, we explore integrating the shared time- and frequency-multi-head attention modules with LSTM and xLSTM, which yields an notable performance improvement on the out-of-domain datasets. However, our MambAttention model remains superior on both out-of-domain datasets across all reported evaluation metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of new sequence models like Mamba and xLSTM, several studieshave shown that these models match or outperform state-of-the-art models insingle-channel speech enhancement, automatic speech recognition, andself-supervised audio representation learning. However, prior research hasdemonstrated that sequence models like LSTM and Mamba tend to overfit to thetraining set. To address this issue, previous works have shown that addingself-attention to LSTMs substantially improves generalization performance forsingle-channel speech enhancement. Nevertheless, neither the concept of hybridMamba and time-frequency attention models nor their generalization performancehave been explored for speech enhancement. In this paper, we propose a novelhybrid architecture, MambAttention, which combines Mamba and shared time- andfrequency-multi-head attention modules for generalizable single-channel speechenhancement. To train our model, we introduce VoiceBank+Demand Extended(VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challengingnoise types and lower signal-to-noise ratios. Trained on VB-DemandEx, ourproposed MambAttention model significantly outperforms existingstate-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similarcomplexity across all reported metrics on two out-of-domain datasets: DNS 2020and EARS-WHAM_v2, while matching their performance on the in-domain datasetVB-DemandEx. Ablation studies highlight the role of weight sharing between thetime- and frequency-multi-head attention modules for generalizationperformance. Finally, we explore integrating the shared time- andfrequency-multi-head attention modules with LSTM and xLSTM, which yields anotable performance improvement on the out-of-domain datasets. However, ourMambAttention model remains superior on both out-of-domain datasets across allreported evaluation metrics.</description>
      <author>example@mail.com (Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan)</author>
      <guid isPermaLink="false">2507.00966v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Towards Decentralized and Sustainable Foundation Model Training with the Edge</title>
      <link>http://arxiv.org/abs/2507.01803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个关于去中心化和可持续的基座模型训练的愿景，旨在利用边缘AI设备的计算能力来降低计算需求，并解决环境影响和集中控制风险。&lt;h4&gt;背景&lt;/h4&gt;基座模型因其能够从大量数据集中学习并处理多种任务而受到关注，但其计算需求巨大，引发了环境问题和集中控制风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种去中心化和可持续的基座模型训练方法，以降低计算需求，并支持其可持续性。&lt;h4&gt;方法&lt;/h4&gt;利用边缘AI设备的计算能力，提出一种新的训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;阐述了支持这一愿景的可持续性优势，并概述了实现这一愿景需要解决的一系列挑战。&lt;h4&gt;结论&lt;/h4&gt;去中心化和可持续的基座模型训练是未来AI研究的一个重要方向，但需要克服一系列技术挑战。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种面向去中心化和可持续的基座模型训练的愿景，该愿景利用边缘AI设备的计算能力，以降低计算需求并解决环境影响和集中控制风险。我们阐述了这一愿景的可持续性优势，并概述了实现这一愿景需要解决的一系列挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are at the forefront of AI research, appealing for theirability to learn from vast datasets and cater to diverse tasks. Yet, theirsignificant computational demands raise issues of environmental impact and therisk of centralized control in their development. We put forward a visiontowards decentralized and sustainable foundation model training that leveragesthe collective compute of sparingly used connected edge AI devices. We presentthe rationale behind our vision, particularly in support of its sustainabilitybenefit. We further outline a set of challenges that need to be addressed toturn this vision into reality.</description>
      <author>example@mail.com (Leyang Xue, Meghana Madhyastha, Randal Burns, Myungjin Lee, Mahesh K. Marina)</author>
      <guid isPermaLink="false">2507.01803v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MuteSwap: Silent Face-based Voice Conversion</title>
      <link>http://arxiv.org/abs/2507.00498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于无声视频的语音转换方法，通过视觉输入实现语音转换，无需音频输入，解决了在无声视频或噪声环境下的语音转换问题。&lt;h4&gt;背景&lt;/h4&gt;传统的语音转换依赖于音频输入，但在音频不可用的情况下，如无声视频或噪声环境，这种转换变得不可行。&lt;h4&gt;目的&lt;/h4&gt;研究无声面部语音转换（Silent Face-based Voice Conversion，SFVC），即仅通过视觉输入进行语音转换，生成与目标说话人身份对齐且保留源无声视频中的语音内容的语音。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MuteSwap的新框架，该框架使用对比学习来对齐跨模态身份，并最小化互信息以分离共享的视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MuteSwap在语音合成和身份转换方面均取得了令人印象深刻的性能，尤其在依赖音频输入的方法在噪声条件下无法产生可懂结果的情况下。&lt;h4&gt;结论&lt;/h4&gt;该方法验证了我们的训练方法的有效性，并证明了无声面部语音转换的可行性。&lt;h4&gt;翻译&lt;/h4&gt;Conventional voice conversion modifies voice characteristics from a sourcespeaker to a target speaker, relying on audio input from both sides. However,this process becomes infeasible when clean audio is unavailable, such as insilent videos or noisy environments. In this work, we focus on the task ofSilent Face-based Voice Conversion (SFVC), which does voice conversion entirelyfrom visual inputs. i.e., given images of a target speaker and a silent videoof a source speaker containing lip motion, SFVC generates speech aligning theidentity of the target speaker while preserving the speech content in thesource silent video. As this task requires generating intelligible speech andconverting identity using only visual cues, it is particularly challenging. Toaddress this, we introduce MuteSwap, a novel framework that employs contrastivelearning to align cross-modality identities and minimize mutual information toseparate shared visual features. Experimental results show that MuteSwapachieves impressive performance in both speech synthesis and identityconversion, especially under noisy conditions where methods dependent on audioinput fail to produce intelligible results, demonstrating both theeffectiveness of our training approach and the feasibility of SFVC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional voice conversion modifies voice characteristics from a sourcespeaker to a target speaker, relying on audio input from both sides. However,this process becomes infeasible when clean audio is unavailable, such as insilent videos or noisy environments. In this work, we focus on the task ofSilent Face-based Voice Conversion (SFVC), which does voice conversion entirelyfrom visual inputs. i.e., given images of a target speaker and a silent videoof a source speaker containing lip motion, SFVC generates speech aligning theidentity of the target speaker while preserving the speech content in thesource silent video. As this task requires generating intelligible speech andconverting identity using only visual cues, it is particularly challenging. Toaddress this, we introduce MuteSwap, a novel framework that employs contrastivelearning to align cross-modality identities and minimize mutual information toseparate shared visual features. Experimental results show that MuteSwapachieves impressive performance in both speech synthesis and identityconversion, especially under noisy conditions where methods dependent on audioinput fail to produce intelligible results, demonstrating both theeffectiveness of our training approach and the feasibility of SFVC.</description>
      <author>example@mail.com (Yifan Liu, Yu Fang, Zhouhan Lin)</author>
      <guid isPermaLink="false">2507.00498v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ADAptation: Reconstruction-based Unsupervised Active Learning for Breast Ultrasound Diagnosis</title>
      <link>http://arxiv.org/abs/2507.00474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 4 tables. Accepted by conference MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ADAptation的深度学习诊断模型，用于解决训练集和测试集之间分布差异导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习诊断模型在训练集和测试集之间由于分布差异常常出现性能下降，收集和标注足够的目标域数据成本高且资源稀缺。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的无监督主动学习框架，旨在在有限的标注预算下，从多域数据池中高效地选择信息量大的样本。&lt;h4&gt;方法&lt;/h4&gt;该方法首先利用扩散模型的分布同化能力，将目标图像转换为源域风格以弥合跨数据集的差距。然后引入两项关键创新：(a)一个超球面约束对比学习网络，用于紧凑的特征聚类；(b)一个双评分机制，用于量化并平衡样本的不确定性和代表性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个乳腺超声数据集（三个公开和一个内部/多中心）上进行的广泛实验表明，该方法优于现有的基于主动学习的强竞争对手，验证了其在临床域适应中的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在减少标注成本的同时，保持了模型的性能，适用于临床域适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于深度学习的诊断模型通常因训练（源域）和测试（目标域）之间的分布差异而性能下降。收集和标注足够的目标域数据以重新训练模型是一个最佳解决方案，但受限于时间和稀缺的资源。主动学习（AL）提供了一种在保持性能的同时减少标注成本的高效方法，但难以应对不同数据集之间分布变化带来的挑战。在本研究中，我们提出了一种新的无监督主动学习框架，用于域适应，命名为ADAptation，该框架在有限的标注预算下，能够有效地从多域数据池中选择信息量大的样本。作为一个基本步骤，我们的方法首先利用扩散模型的分布同化能力，通过将目标图像转换为源域风格来弥合跨数据集的差距。然后，我们引入了两项关键创新：(a)一个超球面约束对比学习网络，用于紧凑的特征聚类；(b)一个双评分机制，用于量化并平衡样本的不确定性和代表性。在五个常见的深度分类器上，对四个乳腺超声数据集（三个公开和一个内部/多中心）进行的广泛实验表明，我们的方法优于现有的基于主动学习的强竞争对手，验证了其在临床域适应中的有效性和泛化能力。代码可在匿名链接处获取：https://github.com/miccai25-966/ADAptation。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based diagnostic models often suffer performance drops due todistribution shifts between training (source) and test (target) domains.Collecting and labeling sufficient target domain data for model retrainingrepresents an optimal solution, yet is limited by time and scarce resources.Active learning (AL) offers an efficient approach to reduce annotation costswhile maintaining performance, but struggles to handle the challenge posed bydistribution variations across different datasets. In this study, we propose anovel unsupervised Active learning framework for Domain Adaptation, namedADAptation, which efficiently selects informative samples from multi-domaindata pools under limited annotation budget. As a fundamental step, our methodfirst utilizes the distribution homogenization capabilities of diffusion modelsto bridge cross-dataset gaps by translating target images into source-domainstyle. We then introduce two key innovations: (a) a hypersphere-constrainedcontrastive learning network for compact feature clustering, and (b) adual-scoring mechanism that quantifies and balances sample uncertainty andrepresentativeness. Extensive experiments on four breast ultrasound datasets(three public and one in-house/multi-center) across five common deepclassifiers demonstrate that our method surpasses existing strong AL-basedcompetitors, validating its effectiveness and generalization for clinicaldomain adaptation. The code is available at the anonymized link:https://github.com/miccai25-966/ADAptation.</description>
      <author>example@mail.com (Yaofei Duan, Yuhao Huang, Xin Yang, Luyi Han, Xinyu Xie, Zhiyuan Zhu, Ping He, Ka-Hou Chan, Ligang Cui, Sio-Kei Im, Dong Ni, Tao Tan)</author>
      <guid isPermaLink="false">2507.00474v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding</title>
      <link>http://arxiv.org/abs/2507.00068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MANTA是一个将视觉和听觉输入统一到结构化文本空间的多模态学习框架，通过文本对齐实现多模态抽象和归一化，以提高大语言模型处理多模态数据的能力。&lt;h4&gt;背景&lt;/h4&gt;现有多模态学习方法通常将模态分开处理，导致表示和推理上的不一致。&lt;h4&gt;目的&lt;/h4&gt;提出MANTA框架，解决多模态学习中的四个关键挑战：模态间语义对齐、自适应时间同步、分层内容表示和上下文感知信息检索。&lt;h4&gt;方法&lt;/h4&gt;在严谨的数学框架内形式化方法，通过信息论优化实现模态间语义对齐，采用自适应时间同步技术处理不同信息密度的数据，使用分层内容表示实现多尺度理解，并引入新密度估计技术以减少冗余并保留稀有信号。&lt;h4&gt;主要发现&lt;/h4&gt;在长视频问答任务上，MANTA将最先进模型的总体准确率提高了最多22.6%，在超过30分钟的视频上提高了27.3%。此外，MANTA在时间推理任务上提高了23.8%，在跨模态理解上提高了25.1%。&lt;h4&gt;结论&lt;/h4&gt;MANTA通过结构化文本统一多模态表示，为多模态学习提供了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;虽然多模态学习取得了显著进展，但当前方法通常将模态分开处理，导致表示和推理上存在不一致。我们提出了MANTA（通过文本对齐的多模态抽象和归一化），这是一个基于理论的框架，它将视觉和听觉输入统一到一个结构化的文本空间中，以便与大语言模型无缝处理。MANTA解决了四个关键挑战：（1）通过信息论优化实现模态间的语义对齐，（2）对变化的信息密度进行自适应时间同步，（3）使用分层内容表示进行多尺度理解，（4）从长序列中上下文感知地检索稀疏信息。我们在严格的数学框架内形式化了我们的方法，证明了它在标记约束下的上下文选择的优化性。在具有挑战性的长视频问答任务上进行的广泛实验表明，MANTA将最先进模型的总体准确率提高了最多22.6%，在超过30分钟的视频上提高了27.3%。此外，我们还证明了MANTA在时间推理任务（提高了23.8%）和跨模态理解（提高了25.1%）上的优越性。我们的框架引入了新的密度估计技术，以减少冗余并保留稀有信号，为通过结构化文本统一多模态表示奠定了新的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While multi-modal learning has advanced significantly, current approachesoften treat modalities separately, creating inconsistencies in representationand reasoning. We introduce MANTA (Multi-modal Abstraction and Normalizationvia Textual Alignment), a theoretically-grounded framework that unifies visualand auditory inputs into a structured textual space for seamless processingwith large language models. MANTA addresses four key challenges: (1) semanticalignment across modalities with information-theoretic optimization, (2)adaptive temporal synchronization for varying information densities, (3)hierarchical content representation for multi-scale understanding, and (4)context-aware retrieval of sparse information from long sequences. We formalizeour approach within a rigorous mathematical framework, proving its optimalityfor context selection under token constraints. Extensive experiments on thechallenging task of Long Video Question Answering show that MANTA improvesstate-of-the-art models by up to 22.6% in overall accuracy, with particularlysignificant gains (27.3%) on videos exceeding 30 minutes. Additionally, wedemonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement)and cross-modal understanding (25.1% improvement). Our framework introducesnovel density estimation techniques for redundancy minimization whilepreserving rare signals, establishing new foundations for unifying multimodalrepresentations through structured text.</description>
      <author>example@mail.com (Ziqi Zhong, Daniel Tang)</author>
      <guid isPermaLink="false">2507.00068v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Wind Power Forecasting</title>
      <link>http://arxiv.org/abs/2507.00105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在风力发电预测问题上的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究基于三个风力发电设施，使用五年历史数据。&lt;h4&gt;目的&lt;/h4&gt;评估GNNs在风力发电预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;在三个风力发电设施上，使用五年历史数据，以数值天气预报（NWP）变量作为预测因子，对模型进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;某些架构的性能与最佳的基于卷积神经网络（CNN）的基准相当。&lt;h4&gt;结论&lt;/h4&gt;GNNs在风力发电预测中具有应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;We study the applicability of GNNs to the problem of wind energy forecasting. We find that certain architectures achieve performance comparable to our bestCNN-based benchmark. The study is conducted on three wind power facilities using five years of historical data. Numerical Weather Prediction (NWP) variables were used as predictors, and models were evaluated on a 24 to 36 hour ahead test horizon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the applicability of GNNs to the problem of wind energy forecasting.We find that certain architectures achieve performance comparable to our bestCNN-based benchmark. The study is conducted on three wind power facilitiesusing five years of historical data. Numerical Weather Prediction (NWP)variables were used as predictors, and models were evaluated on a 24 to 36 hourahead test horizon.</description>
      <author>example@mail.com (Javier Castellano, Ignacio Villanueva)</author>
      <guid isPermaLink="false">2507.00105v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GPT, But Backwards: Exactly Inverting Language Model Outputs</title>
      <link>http://arxiv.org/abs/2507.01693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, ICML 2025 Workshop on Reliable and Responsible Foundation  Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型语言模型（LLMs）的审计技术，旨在通过重建导致现有LLM输出的确切输入，实现事后分析和潜在地检测伪造输出报告。&lt;h4&gt;背景&lt;/h4&gt;现有的审计技术试图识别大型语言模型中的潜在不良行为，而本文则关注于重建导致特定输出的确切输入这一互补的取证问题。&lt;h4&gt;目的&lt;/h4&gt;实现事后分析，并可能检测到伪造的输出报告。&lt;h4&gt;方法&lt;/h4&gt;将精确输入重建形式化为具有唯一全局最小值的离散优化问题，并引入了SODA算法，该算法在输入搜索空间的连续松弛上运行，具有周期性重启和参数衰减。&lt;h4&gt;主要发现&lt;/h4&gt;在涵盖从3300万到30亿参数的大型语言模型上进行的全面实验表明，SODA算法显著优于现有方法。成功从下一个令牌对数中完全恢复79.5%的短输入，没有错误警报，但难以从长（15+令牌）输入序列的输出中提取私人信息。&lt;h4&gt;结论&lt;/h4&gt;这表明，标准的部署实践可能目前足以提供对恶意使用此方法的保护。&lt;h4&gt;翻译&lt;/h4&gt;While existing auditing techniques attempt to identify potential unwantedbehaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fakeoutput reports. We formalize exact input reconstruction as a discreteoptimisation problem with a unique global minimum and introduce SODA, anefficient gradient-based algorithm that operates on a continuous relaxation ofthe input search space with periodic restarts and parameter decay. Throughcomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, wedemonstrate that SODA significantly outperforms existing approaches. We succeedin fully recovering 79.5% of shorter out-of-distribution inputs from next-tokenlogits, without a single false positive, but struggle to extract privateinformation from the outputs of longer (15+ token) input sequences. Thissuggests that standard deployment practices may currently provide adequateprotection against malicious use of our method. Our code is available athttps://doi.org/10.5281/zenodo.15539879.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While existing auditing techniques attempt to identify potential unwantedbehaviours in large language models (LLMs), we address the complementaryforensic problem of reconstructing the exact input that led to an existing LLMoutput - enabling post-incident analysis and potentially the detection of fakeoutput reports. We formalize exact input reconstruction as a discreteoptimisation problem with a unique global minimum and introduce SODA, anefficient gradient-based algorithm that operates on a continuous relaxation ofthe input search space with periodic restarts and parameter decay. Throughcomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, wedemonstrate that SODA significantly outperforms existing approaches. We succeedin fully recovering 79.5% of shorter out-of-distribution inputs from next-tokenlogits, without a single false positive, but struggle to extract privateinformation from the outputs of longer (15+ token) input sequences. Thissuggests that standard deployment practices may currently provide adequateprotection against malicious use of our method. Our code is available athttps://doi.org/10.5281/zenodo.15539879.</description>
      <author>example@mail.com (Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro)</author>
      <guid isPermaLink="false">2507.01693v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Inverse Design in Nanophotonics via Representation Learning</title>
      <link>http://arxiv.org/abs/2507.00546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;纳米光子学中的逆向设计，通过计算发现实现特定电磁响应的结构，已成为近年来光学发展的关键工具。&lt;h4&gt;背景&lt;/h4&gt;传统的直觉驱动或迭代优化方法在处理高维、非凸的设计空间和电磁模拟的计算需求时存在困难。&lt;h4&gt;目的&lt;/h4&gt;利用机器学习（ML）来有效解决这些瓶颈。&lt;h4&gt;方法&lt;/h4&gt;本文通过代表学习的角度，将增强机器学习的逆向设计方法分为输出侧和输入侧两种方法。输出侧方法使用机器学习在解空间中学习表示以创建可微求解器，从而加速优化。相反，输入侧技术使用机器学习学习可行设备几何形状的紧凑、潜在空间表示，通过生成模型实现高效的全球探索。&lt;h4&gt;主要发现&lt;/h4&gt;每种策略在数据需求、泛化能力和新的设计发现潜力方面都有独特的权衡。&lt;h4&gt;结论&lt;/h4&gt;结合基于物理的优化与数据驱动表示的混合框架有助于逃离局部最优，提高可扩展性，并促进知识迁移。最后，本文强调了开放挑战和机遇，包括复杂性管理、几何无关表示、集成制造约束和多物理场协同设计的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：纳米光子学中的逆向设计，即通过计算发现能够实现特定电磁响应的结构，已成为近年来光学发展的关键工具。传统的直觉驱动或迭代优化方法在处理高维、非凸的设计空间和电磁模拟的计算需求时存在困难。最近，机器学习（ML）被提出以有效解决这些瓶颈。本文通过代表学习的角度，将增强机器学习的逆向设计方法分为输出侧和输入侧两种方法。输出侧方法使用机器学习在解空间中学习表示以创建可微求解器，从而加速优化。相反，输入侧技术使用机器学习学习可行设备几何形状的紧凑、潜在空间表示，通过生成模型实现高效的全球探索。每种策略在数据需求、泛化能力和新的设计发现潜力方面都有独特的权衡。结合基于物理的优化与数据驱动表示的混合框架有助于逃离局部最优，提高可扩展性，并促进知识迁移。最后，本文强调了开放挑战和机遇，包括复杂性管理、几何无关表示、集成制造约束和多物理场协同设计的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inverse design in nanophotonics, the computational discovery of structuresachieving targeted electromagnetic (EM) responses, has become a key tool forrecent optical advances. Traditional intuition-driven or iterative optimizationmethods struggle with the inherently high-dimensional, non-convex design spacesand the substantial computational demands of EM simulations. Recently, machinelearning (ML) has emerged to address these bottlenecks effectively. This reviewframes ML-enhanced inverse design methodologies through the lens ofrepresentation learning, classifying them into two categories: output-side andinput-side approaches. Output-side methods use ML to learn a representation inthe solution space to create a differentiable solver that acceleratesoptimization. Conversely, input-side techniques employ ML to learn compact,latent-space representations of feasible device geometries, enabling efficientglobal exploration through generative models. Each strategy presents uniquetrade-offs in data requirements, generalization capacity, and novel designdiscovery potentials. Hybrid frameworks that combine physics-based optimizationwith data-driven representations help escape poor local optima, improvescalability, and facilitate knowledge transfer. We conclude by highlightingopen challenges and opportunities, emphasizing complexity management,geometry-independent representations, integration of fabrication constraints,and advancements in multiphysics co-designs.</description>
      <author>example@mail.com (Reza Marzban, Ali Adibi, Raphael Pestourie)</author>
      <guid isPermaLink="false">2507.00546v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Causal Prompting for Implicit Sentiment Analysis with Large Language Models</title>
      <link>http://arxiv.org/abs/2507.00389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CAPITAL，一种因果提示框架，用于隐式情感分析，通过将前门调整引入思维链推理，以解决现有方法中存在的内部偏差和虚假相关性问题。&lt;h4&gt;背景&lt;/h4&gt;隐式情感分析旨在推断隐含而非明确表达的情感，要求模型进行更深层次的推理。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有基于提示的隐式情感分析方法的不足，提出一种新的因果提示框架。&lt;h4&gt;方法&lt;/h4&gt;CAPITAL将总体因果效应分解为两个部分：输入提示对推理链的影响，以及这些链对最终输出的影响。使用编码器聚类和NWGM近似估计这两个部分，并通过对比学习目标更好地对齐编码器的表示与LLM的推理空间。&lt;h4&gt;主要发现&lt;/h4&gt;在基准隐式情感分析数据集上进行的实验表明，CAPITAL在准确性和鲁棒性方面均优于强大的提示基线，特别是在对抗条件下。&lt;h4&gt;结论&lt;/h4&gt;本文为将因果推理集成到LLM提示中提供了一种原则性的方法，并强调了其在具有偏差感知的情感推理方面的好处。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CAPITAL的因果提示框架，用于隐式情感分析。该框架通过将前门调整引入思维链推理，解决了现有方法中存在的内部偏差和虚假相关性问题。在基准隐式情感分析数据集上进行的实验表明，CAPITAL在准确性和鲁棒性方面均优于现有的提示方法。这项工作为将因果推理集成到LLM提示中提供了一种原则性的方法，并强调了其在具有偏差感知的情感推理方面的优势。源代码和案例研究可在以下链接找到：https://github.com/whZ62/CAPITAL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit Sentiment Analysis (ISA) aims to infer sentiment that is impliedrather than explicitly stated, requiring models to perform deeper reasoningover subtle contextual cues. While recent prompting-based methods using LargeLanguage Models (LLMs) have shown promise in ISA, they often rely on majorityvoting over chain-of-thought (CoT) reasoning paths without evaluating theircausal validity, making them susceptible to internal biases and spuriouscorrelations. To address this challenge, we propose CAPITAL, a causal promptingframework that incorporates front-door adjustment into CoT reasoning. CAPITALdecomposes the overall causal effect into two components: the influence of theinput prompt on the reasoning chains, and the impact of those chains on thefinal output. These components are estimated using encoder-based clustering andthe NWGM approximation, with a contrastive learning objective used to betteralign the encoder's representation with the LLM's reasoning space. Experimentson benchmark ISA datasets with three LLMs demonstrate that CAPITAL consistentlyoutperforms strong prompting baselines in both accuracy and robustness,particularly under adversarial conditions. This work offers a principledapproach to integrating causal inference into LLM prompting and highlights itsbenefits for bias-aware sentiment reasoning. The source code and case study areavailable at: https://github.com/whZ62/CAPITAL.</description>
      <author>example@mail.com (Jing Ren, Wenhao Zhou, Bowen Li, Mujie Liu, Nguyen Linh Dan Le, Jiade Cen, Liping Chen, Ziqi Xu, Xiwei Xu, Xiaodong Li)</author>
      <guid isPermaLink="false">2507.00389v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding</title>
      <link>http://arxiv.org/abs/2507.00419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GEM（地质一切模型3D）是一个统一的生成架构，用于地质分析，它通过从地下成像中推导出的潜在结构框架进行提示条件下的推理，实现地质任务的统一处理。&lt;h4&gt;背景&lt;/h4&gt;理解地球的地下结构对于能源转型、自然灾害减轻和行星科学至关重要，但地下分析目前仍然是碎片化的，需要不同的模型来处理结构解释、地层分析、地质体分割和属性建模。&lt;h4&gt;目的&lt;/h4&gt;提出GEM的目的是为了解决地下分析中的碎片化问题，实现不同地质任务的统一处理。&lt;h4&gt;方法&lt;/h4&gt;GEM通过一个两阶段的训练过程来实现这一目标，包括在大规模野外地震数据上进行的自监督表示学习，以及使用混合提示和标签的对抗性微调。&lt;h4&gt;主要发现&lt;/h4&gt;GEM能够通过共享的推理机制处理不同类型的提示，实现零样本泛化，无需针对新任务或数据源进行重新训练。&lt;h4&gt;结论&lt;/h4&gt;GEM展示了在多个调查和任务中的广泛适用性，并且通过结合专家知识和生成推理，为可扩展的、具有人类参与的地球物理人工智能奠定了基础，从而将碎片化的管道转变为一个垂直集成、可提示的推理系统。&lt;h4&gt;翻译&lt;/h4&gt;Understanding Earth's subsurface is critical for energy transition, natural hazard mitigation, and planetary science. Yet subsurface analysis remains fragmented, with separate models required for structural interpretation, stratigraphic analysis, geobody segmentation, and property modeling—each tightly coupled to specific data distributions and task formulations. We introduce the Geological Everything Model 3D (GEM), a unified generative architecture that reformulates all these tasks as prompt-conditioned inference along latent structural frameworks derived from subsurface imaging. This formulation moves beyond task-specific models by enabling a shared inference mechanism, where GEM propagates human-provided prompts—such as well logs, masks, or structural sketches—along inferred structural frameworks to produce geologically coherent outputs. Through this mechanism, GEM achieves zero-shot generalization across tasks with heterogeneous prompt types, without retraining for new tasks or data sources. This capability emerges from a two-stage training process that combines self-supervised representation learning on large-scale field seismic data with adversarial fine-tuning using mixed prompts and labels across diverse subsurface tasks. GEM demonstrates broad applicability across surveys and tasks, including Martian radar stratigraphic analysis, structural interpretation in subduction zones, full seismic stratigraphic interpretation, geobody delineation, and property modeling. By bridging expert knowledge with generative reasoning in a structurally aware manner, GEM lays the foundation for scalable, human-in-the-loop geophysical AI—transitioning from fragmented pipelines to a vertically integrated, promptable reasoning system. Project page: https://douyimin.github.io/GEM&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding Earth's subsurface is critical for energy transition, naturalhazard mitigation, and planetary science. Yet subsurface analysis remainsfragmented, with separate models required for structural interpretation,stratigraphic analysis, geobody segmentation, and property modeling-eachtightly coupled to specific data distributions and task formulations. Weintroduce the Geological Everything Model 3D (GEM), a unified generativearchitecture that reformulates all these tasks as prompt-conditioned inferencealong latent structural frameworks derived from subsurface imaging. Thisformulation moves beyond task-specific models by enabling a shared inferencemechanism, where GEM propagates human-provided prompts-such as well logs,masks, or structural sketches-along inferred structural frameworks to producegeologically coherent outputs. Through this mechanism, GEM achieves zero-shotgeneralization across tasks with heterogeneous prompt types, without retrainingfor new tasks or data sources. This capability emerges from a two-stagetraining process that combines self-supervised representation learning onlarge-scale field seismic data with adversarial fine-tuning using mixed promptsand labels across diverse subsurface tasks. GEM demonstrates broadapplicability across surveys and tasks, including Martian radar stratigraphyanalysis, structural interpretation in subduction zones, full seismicstratigraphic interpretation, geobody delineation, and property modeling. Bybridging expert knowledge with generative reasoning in a structurally awaremanner, GEM lays the foundation for scalable, human-in-the-loop geophysicalAI-transitioning from fragmented pipelines to a vertically integrated,promptable reasoning system. Project page: https://douyimin.github.io/GEM</description>
      <author>example@mail.com (Yimin Dou, Xinming Wu, Nathan L Bangs, Harpreet Singh Sethi, Jintao Li, Hang Gao, Zhixiang Guo)</author>
      <guid isPermaLink="false">2507.00419v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Room Scene Discovery and Grouping in Unstructured Vacation Rental Image Collections</title>
      <link>http://arxiv.org/abs/2507.00263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种有效的方法来解决房间场景发现和分组问题，以及识别每个卧室组中的床型。该方法适用于实时和数据稀缺的环境，并显著优于现有的对比学习和预训练嵌入聚类方法。&lt;h4&gt;背景&lt;/h4&gt;随着度假租赁平台的发展，大量的房产图片被上传，但缺乏结构化分类，给旅行者理解房产的空间布局带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种计算效率高的机器学习流程，用于房间场景发现、分组和床型识别。&lt;h4&gt;方法&lt;/h4&gt;该流程包括一个监督式房间类型检测模型，一个监督式重叠检测模型用于识别两张图片之间的重叠相似度，以及一个聚类算法用于根据相似度将同一空间的图片分组。此外，使用多模态大型语言模型（MLLM）将每个卧室组映射到房产元数据中指定的对应床型。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在单独评估模型和整体评估时都表现出强大的性能，显著优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在房间场景发现、分组和床型识别方面表现出色，适用于实时和数据稀缺的环境，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The rapid growth of vacation rental (VR) platforms has led to an increasing volume of property images, often uploaded without structured categorization. This lack of organization poses significant challenges for travelers attempting to understand the spatial layout of a property, particularly when multiple rooms of the same type are present. To address this issue, we introduce an effective approach for solving the room scene discovery and grouping problem, as well as identifying bed types within each bedroom group. This grouping is valuable for travelers to comprehend the spatial organization, layout, and the sleeping configuration of the property. We propose a computationally efficient machine learning pipeline characterized by low latency and the ability to perform effectively with sample-efficient learning, making it well-suited for real-time and data-scarce environments. The pipeline integrates a supervised room-type detection model, a supervised overlap detection model to identify the overlap similarity between two images, and a clustering algorithm to group the images of the same space together using the similarity scores. Additionally, the pipeline maps each bedroom group to the corresponding bed types specified in the property's metadata, based on the visual content present in the group's images using a Multi-modal Large Language Model (MLLM) model. We evaluate the aforementioned models individually and also assess the pipeline in its entirety, observing strong performance that significantly outperforms established approaches such as contrastive learning and clustering with pretrained embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of vacation rental (VR) platforms has led to an increasingvolume of property images, often uploaded without structured categorization.This lack of organization poses significant challenges for travelers attemptingto understand the spatial layout of a property, particularly when multiplerooms of the same type are present. To address this issue, we introduce aneffective approach for solving the room scene discovery and grouping problem,as well as identifying bed types within each bedroom group. This grouping isvaluable for travelers to comprehend the spatial organization, layout, and thesleeping configuration of the property. We propose a computationally efficientmachine learning pipeline characterized by low latency and the ability toperform effectively with sample-efficient learning, making it well-suited forreal-time and data-scarce environments. The pipeline integrates a supervisedroom-type detection model, a supervised overlap detection model to identify theoverlap similarity between two images, and a clustering algorithm to group theimages of the same space together using the similarity scores. Additionally,the pipeline maps each bedroom group to the corresponding bed types specifiedin the property's metadata, based on the visual content present in the group'simages using a Multi-modal Large Language Model (MLLM) model. We evaluate theaforementioned models individually and also assess the pipeline in itsentirety, observing strong performance that significantly outperformsestablished approaches such as contrastive learning and clustering withpretrained embeddings.</description>
      <author>example@mail.com (Vignesh Ram Nithin Kappagantula, Shayan Hassantabar)</author>
      <guid isPermaLink="false">2507.00263v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>VOCAL: Visual Odometry via ContrAstive Learning</title>
      <link>http://arxiv.org/abs/2507.00243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VOCAL（通过对比学习进行视觉里程计）是一种新的框架，它将视觉里程计重新构想为标签排序挑战，通过结合贝叶斯推理和表示学习框架，提升了视觉里程计的可解释性和灵活性。&lt;h4&gt;背景&lt;/h4&gt;视觉里程计（VO）在机器人领域取得了突破，但许多基于学习的VO技术依赖于刚性几何假设，这限制了其可解释性和理论基础。&lt;h4&gt;目的&lt;/h4&gt;克服基于学习的VO技术的局限性，提高其可解释性和理论基础。&lt;h4&gt;方法&lt;/h4&gt;VOCAL通过将视觉里程计视为标签排序挑战，结合贝叶斯推理和表示学习框架，将视觉特征组织起来以反映相机状态，并通过排名机制确保相似相机状态在潜在空间中的空间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;VOCAL增强了学习特征的可解释性，并确保了与多模态数据源的兼容性。&lt;h4&gt;结论&lt;/h4&gt;VOCAL在KITTI数据集上的广泛评估显示了其增强的可解释性和灵活性，推动了视觉里程计向更通用和可解释的空间智能发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉里程计（VO）的突破从根本上改变了机器人领域的格局，使超精确的相机状态估计成为现代自主系统不可或缺的一部分。尽管取得了这些进步，但许多基于学习的VO技术仍然依赖于刚性的几何假设，这通常在可解释性和在完全数据驱动框架中的理论基础方面表现不足。为了克服这些限制，我们引入了VOCAL（通过对比学习进行视觉里程计），这是一个新颖的框架，它将VO重新构想为标签排序挑战。通过结合贝叶斯推理和表示学习框架，VOCAL将视觉特征组织起来以反映相机状态。排名机制迫使相似的相机状态在潜在空间中收敛到一致且空间上连贯的表示。这种战略性的对齐不仅增强了学习特征的可解释性，还确保了与多模态数据源的兼容性。在KITTI数据集上的广泛评估突出了VOCAL增强的可解释性和灵活性，推动了VO向更通用和可解释的空间智能发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breakthroughs in visual odometry (VO) have fundamentally reshaped thelandscape of robotics, enabling ultra-precise camera state estimation that iscrucial for modern autonomous systems. Despite these advances, manylearning-based VO techniques rely on rigid geometric assumptions, which oftenfall short in interpretability and lack a solid theoretical basis within fullydata-driven frameworks. To overcome these limitations, we introduce VOCAL(Visual Odometry via ContrAstive Learning), a novel framework that reimaginesVO as a label ranking challenge. By integrating Bayesian inference with arepresentation learning framework, VOCAL organizes visual features to mirrorcamera states. The ranking mechanism compels similar camera states to convergeinto consistent and spatially coherent representations within the latent space.This strategic alignment not only bolsters the interpretability of the learnedfeatures but also ensures compatibility with multimodal data sources. Extensiveevaluations on the KITTI dataset highlight VOCAL's enhanced interpretabilityand flexibility, pushing VO toward more general and explainable spatialintelligence.</description>
      <author>example@mail.com (Chi-Yao Huang, Zeel Bhatt, Yezhou Yang)</author>
      <guid isPermaLink="false">2507.00243v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MARVIS: Modality Adaptive Reasoning over VISualizations</title>
      <link>http://arxiv.org/abs/2507.01544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MARVIS的无需训练的方法，能够使小型视觉语言模型预测任何数据模态，并取得了在视觉、音频、生物和表格领域上的优异表现。&lt;h4&gt;背景&lt;/h4&gt;机器学习在科学应用中通常依赖于针对特定领域调优的小型专用模型，这些模型虽然性能出色，但缺乏灵活性。基础模型虽然具有通用性，但在非传统模态和长尾领域上通常表现不如专用方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需训练的方法，使得小型视觉语言模型能够高精度地预测任何数据模态。&lt;h4&gt;方法&lt;/h4&gt;MARVIS通过将潜在嵌入空间转换为视觉表示，并利用视觉语言模型的空间和细粒度推理能力，成功解释和利用这些表示。&lt;h4&gt;主要发现&lt;/h4&gt;MARVIS使用单个3B参数模型在视觉、音频、生物和表格领域上取得了具有竞争力的性能，平均比Gemini模型高出16%，并接近专用方法，同时不泄露个人可识别信息（P.I.I.）且无需特定领域的训练。&lt;h4&gt;结论&lt;/h4&gt;MARVIS是一种有效的无需训练的方法，能够使小型视觉语言模型在多个数据模态上实现高性能预测，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：科学应用中的机器学习通常依赖于针对特定领域调优的小型专用模型。这些模型通常能够达到优异的性能，但缺乏灵活性。基础模型提供了通用性，但在非传统模态和长尾领域上通常表现不如专用方法。我们提出了MARVIS（基于视觉的模态自适应推理），一种无需训练的方法，使得即使是小型视觉语言模型也能以高精度预测任何数据模态。MARVIS将潜在嵌入空间转换为视觉表示，然后利用视觉语言模型的空间和细粒度推理技能成功解释和利用这些表示。使用单个3B参数模型，MARVIS在视觉、音频、生物和表格领域上实现了具有竞争力的性能，平均比Gemini高出16%，并接近专用方法，同时不泄露个人可识别信息（P.I.I.）或需要任何特定领域的训练。我们已在https://github.com/penfever/marvis开源了我们的代码和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific applications of machine learning often rely on small, specializedmodels tuned to particular domains. Such models often achieve excellentperformance, but lack flexibility. Foundation models offer versatility, buttypically underperform specialized approaches, especially on non-traditionalmodalities and long-tail domains. We propose MARVIS (Modality AdaptiveReasoning over VISualizations), a training-free method that enables even smallvision-language models to predict any data modality with high accuracy. MARVIStransforms latent embedding spaces into visual representations and thenleverages the spatial and fine-grained reasoning skills of VLMs to successfullyinterpret and utilize them. MARVIS achieves competitive performance on vision,audio, biological, and tabular domains using a single 3B parameter model,achieving results that beat Gemini by 16\% on average and approach specializedmethods, without exposing personally identifiable information (P.I.I.) orrequiring any domain-specific training. We open source our code and datasets athttps://github.com/penfever/marvis</description>
      <author>example@mail.com (Benjamin Feuer, Lennart Purucker, Oussama Elachqar, Chinmay Hegde)</author>
      <guid isPermaLink="false">2507.01544v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AVC-DPO: Aligned Video Captioning via Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2507.01492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AVC-DPO的框架，旨在通过直接偏好优化来调整视频描述的焦点，从而提高视频多模态大型语言模型在视频描述任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管视频多模态大型语言模型在视频描述任务上取得了显著进展，但根据人类偏好调整视频描述的焦点仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本研究旨在通过偏好对齐来增强视频多模态大型语言模型的描述能力。&lt;h4&gt;方法&lt;/h4&gt;AVC-DPO设计了一种增强的提示，专门针对视频中的时间和空间信息，这两个因素是人类观看视频时关注的重点。该方法利用同一基础模型在不同提示条件下的描述生成响应来进行偏好感知训练和描述对齐。&lt;h4&gt;主要发现&lt;/h4&gt;使用AVC-DPO框架，在LOVE@CVPR'25研讨会第1A轨道的视频详细描述挑战中取得了卓越的性能，根据VDCSCORE评估指标，在视频详细描述（VDC）基准测试中排名第一。&lt;h4&gt;结论&lt;/h4&gt;AVC-DPO框架能够有效提高视频多模态大型语言模型在视频描述任务中的性能，特别是在根据人类偏好调整描述焦点方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although video multimodal large language models (video MLLMs) have achievedsubstantial progress in video captioning tasks, it remains challenging toadjust the focal emphasis of video captions according to human preferences. Toaddress this limitation, we propose Aligned Video Captioning via DirectPreference Optimization (AVC-DPO), a post-training framework designed toenhance captioning capabilities in video MLLMs through preference alignment.Our approach designs enhanced prompts that specifically target temporaldynamics and spatial information-two key factors that humans care about whenwatching a video-thereby incorporating human-centric preferences. AVC-DPOleverages the same foundation model's caption generation responses under variedprompt conditions to conduct preference-aware training and caption alignment.Using this framework, we have achieved exceptional performance in theLOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achievingfirst place on the Video Detailed Captioning (VDC) benchmark according to theVDCSCORE evaluation metric.</description>
      <author>example@mail.com (Jiyang Tang, Hengyi Li, Yifan Du, Wayne Xin Zhao)</author>
      <guid isPermaLink="false">2507.01492v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>An efficient plant disease detection using transfer learning approach</title>
      <link>http://arxiv.org/abs/2507.00070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages , 4 figures. Scientific Reports 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于迁移学习的植物病害检测系统，利用YOLOv7和YOLOv8模型进行植物病害的自动识别和监测，提高了病害检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;植物病害对农民和农业行业造成重大挑战，早期检测对于减轻病害影响和防止广泛损害至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个系统，用于识别和监测植物病害，以减轻病害对农作物生产力和质量的影响。&lt;h4&gt;方法&lt;/h4&gt;研究使用了YOLOv7和YOLOv8两种先进的对象检测模型，通过在植物叶片图像数据集上进行微调，使系统能够准确检测细菌、真菌和病毒病害，如白粉病、角斑病、早疫病和番茄花叶病毒。&lt;h4&gt;主要发现&lt;/h4&gt;模型在平均精度（mAP）、F1分数、精确度和召回率等指标上分别达到了91.05、89.40、91.22和87.66，显示出YOLOv8相较于其他对象检测方法具有更高的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续的农业实践。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物病害对农民及整个农业行业构成重大挑战。然而，早期检测植物病害对于减轻其影响和预防广泛损害至关重要，因为病害爆发会严重影响到作物的生产力和质量。随着技术的进步，自动化监测和检测植物病害的机会越来越多。本研究提出了一种系统，旨在利用迁移学习方法来识别和监测植物病害。具体而言，该研究利用了YOLOv7和YOLOv8，这是对象检测领域的两种最先进的模型。通过在植物叶片图像数据集上对这些模型进行微调，该系统能够准确检测细菌、真菌和病毒病害，例如白粉病、角斑病、早疫病和番茄花叶病毒。使用包括平均精度（mAP）、F1分数、精确度和召回率在内的多个指标评估了模型的性能，分别得到91.05、89.40、91.22和87.66的值。结果证明了YOLOv8相较于其他对象检测方法具有优越的有效性和效率，突显了其在现代农业实践中的应用潜力。该方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续的农业实践。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1038/s41598-025-02271-w&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Plant diseases pose significant challenges to farmers and the agriculturalsector at large. However, early detection of plant diseases is crucial tomitigating their effects and preventing widespread damage, as outbreaks canseverely impact the productivity and quality of crops. With advancements intechnology, there are increasing opportunities for automating the monitoringand detection of disease outbreaks in plants. This study proposed a systemdesigned to identify and monitor plant diseases using a transfer learningapproach. Specifically, the study utilizes YOLOv7 and YOLOv8, twostate-ofthe-art models in the field of object detection. By fine-tuning thesemodels on a dataset of plant leaf images, the system is able to accuratelydetect the presence of Bacteria, Fungi and Viral diseases such as PowderyMildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model'sperformance was evaluated using several metrics, including mean AveragePrecision (mAP), F1-score, Precision, and Recall, yielding values of 91.05,89.40, 91.22, and 87.66, respectively. The result demonstrates the superioreffectiveness and efficiency of YOLOv8 compared to other object detectionmethods, highlighting its potential for use in modern agricultural practices.The approach provides a scalable, automated solution for early any plantdisease detection, contributing to enhanced crop yield, reduced reliance onmanual monitoring, and supporting sustainable agricultural practices.</description>
      <author>example@mail.com (Bosubabu Sambana, Hillary Sunday Nnadi, Mohd Anas Wajid, Nwosu Ogochukwu Fidelia, Claudia Camacho-Zuñiga, Henry Dozie Ajuzie, Edeh Michael Onyema)</author>
      <guid isPermaLink="false">2507.00070v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think</title>
      <link>http://arxiv.org/abs/2507.01467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为REG的方法，用于改善扩散模型的训练挑战，通过将低级图像潜在特征与预训练模型中的高级分类标记结合，实现从纯噪声直接生成连贯的图像-类别对，显著提高了生成质量和训练效率。&lt;h4&gt;背景&lt;/h4&gt;REPA及其变体通过整合外部视觉表示来减轻扩散模型的训练挑战，通过噪声隐藏投影与基础清晰图像表示的对齐来实现。然而，这种对齐在去噪推理过程中始终缺失，未能充分利用判别性表示的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出REG方法，以实现从纯噪声直接生成连贯的图像-类别对，提高生成质量和训练效率。&lt;h4&gt;方法&lt;/h4&gt;REG方法通过将低级图像潜在特征与预训练模型中的高级分类标记结合，用于去噪，并通过同时重建图像潜在特征及其对应的全局语义来指导图像生成过程。&lt;h4&gt;主要发现&lt;/h4&gt;REG方法在不显著增加推理开销的情况下（仅增加一个额外的标记，FLOPs和延迟增加&lt;0.5%），显著提高了生成质量和训练效率。在ImageNet 256×256数据集上，SiT-XL/2 + REG的收敛速度比SiT-XL/2和SiT-XL/2 + REPA快63倍和23倍。更重要的是，SiT-L/2 + REG经过400K次迭代训练的性能优于SiT-XL/2 + REPA经过4M次迭代训练的性能（后者训练时间长10倍）。&lt;h4&gt;结论&lt;/h4&gt;REG方法为扩散模型提供了一种有效提高生成质量和训练效率的新途径，具有显著的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Representation Entanglement for Generation (REG)的方法，用于有效地缓解扩散模型在训练过程中所面临的挑战。该方法通过将低级图像潜在特征与预训练基础模型中的一个高级类别标记结合，从而直接从纯噪声中生成连贯的图像-类别对，显著提升了生成质量和训练效率。REG方法在推理过程中只需增加一个额外的标记，对FLOPs和延迟的影响可以忽略不计（增加&lt;0.5%），同时能够同时重建图像潜在特征及其对应的全局语义，从而主动引导并增强图像生成过程。在ImageNet 256×256数据集上，与SiT-XL/2和SiT-XL/2 + REPA相比，SiT-XL/2 + REG的收敛速度分别快63倍和23倍。更为令人印象深刻的是，SiT-L/2 + REG仅经过400K次迭代训练，其性能就优于SiT-XL/2 + REPA经过4M次迭代训练。代码可在https://github.com/Martinser/REG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; REPA and its variants effectively mitigate training challenges in diffusionmodels by incorporating external visual representations from pretrained models,through alignment between the noisy hidden projections of denoising networksand foundational clean image representations. We argue that the externalalignment, which is absent during the entire denoising inference process, fallsshort of fully harnessing the potential of discriminative representations. Inthis work, we propose a straightforward method called RepresentationEntanglement for Generation (REG), which entangles low-level image latents witha single high-level class token from pretrained foundation models fordenoising. REG acquires the capability to produce coherent image-class pairsdirectly from pure noise, substantially improving both generation quality andtraining efficiency. This is accomplished with negligible additional inferenceoverhead, requiring only one single additional token for denoising (&lt;0.5\%increase in FLOPs and latency). The inference process concurrently reconstructsboth image latents and their corresponding global semantics, where the acquiredsemantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergenceacceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ fastertraining than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPAtrained for 4M iterations ($\textbf{10}\times$ longer). Code is available at:https://github.com/Martinser/REG.</description>
      <author>example@mail.com (Ge Wu, Shen Zhang, Ruijing Shi, Shanghua Gao, Zhenyuan Chen, Lei Wang, Zhaowei Chen, Hongcheng Gao, Yao Tang, Jian Yang, Ming-Ming Cheng, Xiang Li)</author>
      <guid isPermaLink="false">2507.01467v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.01463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 3 tables, NeurIPS 2025 preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NOCTIS的新颖对象循环阈值实例分割框架，用于解决在给定示例图像的情况下对RGB图像中新颖对象实例进行分割的问题。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉中，设计一个足够通用的模型，能够在不重新训练的情况下用于所有种类的未知对象，一直是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够自动分割RGB图像中新颖对象实例的模型，且无需额外训练。&lt;h4&gt;方法&lt;/h4&gt;NOCTIS框架利用Grounded-SAM 2获取具有精确边界框及其对应分割掩膜的物体提案；同时使用DINOv2的零样本能力生成图像嵌入。通过比较类别嵌入和平均最大相似性的相似度来确定物体匹配分数，并通过提案-对象匹配实现。此外，还使用提案边界框和掩膜的置信度作为额外加权因子。&lt;h4&gt;主要发现&lt;/h4&gt;NOCTIS在BOP 2023挑战的“基于模型的未见对象2D分割”任务上，不经过进一步训练/微调，在七个核心数据集上优于最佳RGB和RGB-D方法。&lt;h4&gt;结论&lt;/h4&gt;NOCTIS是一个简单而强大的框架，能够在不重新训练的情况下有效分割RGB图像中的新颖对象实例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Instance segmentation of novel objects instances in RGB images, given someexample images for each object, is a well known problem in computer vision.Designing a model general enough to be employed, for all kinds of novelobjects, without (re-) training, has proven to be a difficult task. To handlethis, we propose a simple, yet powerful, framework, called: Novel Object CyclicThreshold based Instance Segmentation (NOCTIS). This work stems from andimproves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it alsoleverages on recent vision foundation models, namely: Grounded-SAM 2 andDINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precisebounding boxes and their corresponding segmentation masks; while DINOv2'szero-shot capabilities are employed to generate the image embeddings. Thequality of those masks, together with their embeddings, is of vital importanceto our approach; as the proposal-object matching is realized by determining anobject matching score based on the similarity of the class embeddings and theaverage maximum similarity of the patch embeddings. Differently to SAM-6D,calculating the latter involves a prior patch filtering based on the distancebetween each patch and its corresponding cyclic/roundtrip patch in the imagegrid. Furthermore, the average confidence of the proposals' bounding box andmask is used as an additional weighting factor for the object matching score.We empirically show that NOCTIS, without further training/fine tuning,outperforms the best RGB and RGB-D methods on the seven core datasets of theBOP 2023 challenge for the "Model-based 2D segmentation of unseen objects"task.</description>
      <author>example@mail.com (Max Gandyra, Alessandro Santonicola, Michael Beetz)</author>
      <guid isPermaLink="false">2507.01463v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control</title>
      <link>http://arxiv.org/abs/2507.01424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了TriVLA模型，这是一种具有三系统架构的统一视觉-语言-动作模型，旨在提升机器人的一般操控能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，视觉-语言模型（VLMs）在常识推理方面的进展促使视觉-语言-动作（VLA）模型的发展，使机器人能够执行通用操作。然而，现有的自回归VLA方法往往只捕获静态信息，忽视了动态信息，这对具身任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文提出了TriVLA模型，以实现更全面的机器人操控。&lt;h4&gt;方法&lt;/h4&gt;TriVLA模型包括视觉-语言模块（系统2）、动态感知模块（系统3）和政策学习模块（系统1）。视觉-语言模块通过视觉和语言指令解释环境，动态感知模块产生包含当前静态信息和预测未来动态的视觉表示，政策学习模块实时生成流畅的电机动作。TriVLA使用预训练的VLM模型和视频基础模型在机器人数据集上进行微调，并利用互联网人类操控数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估显示，TriVLA运行速度约为36 Hz，在标准模拟基准测试和具有挑战性的真实世界操控任务上，超过了最先进的模仿学习基线。&lt;h4&gt;结论&lt;/h4&gt;TriVLA模型在提升机器人操控能力方面具有显著优势，能够有效地处理动态信息，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes TriVLA, a unified Vision-Language-Action model with a triple-system architecture for general robot control. The vision-language module (System 2) interprets the environment through vision and language instructions. The dynamics perception module (System 3) inherently produces visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for policy learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained video foundation model on robot datasets along with internet human manipulation data. The subsequent policy learning module (System 1) generates fluid motor actions in real time. Experimental evaluation demonstrates that TriVLA operates at approximately 36 Hz and surpasses state-of-the-art imitation learning baselines on standard simulation benchmarks as well as challenging real-world manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language models (VLMs) for common-sensereasoning have led to the development of vision-language-action (VLA) models,enabling robots to perform generalized manipulation. Although existingautoregressive VLA methods design a specific architecture like dual-system toleverage large-scale pretrained knowledge, they tend to capture staticinformation, often neglecting the dynamic aspects vital for embodied tasks. Tothis end, we propose TriVLA, a unified Vision-Language-Action model with atriple-system architecture for general robot control. The vision-languagemodule (System 2) interprets the environment through vision and languageinstructions. The dynamics perception module (System 3) inherently producesvisual representations that encompass both current static information andpredicted future dynamics, thereby providing valuable guidance for policylearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trainedvideo foundation model on robot datasets along with internet human manipulationdata. The subsequent policy learning module (System 1) generates fluid motoractions in real time. Experimental evaluation demonstrates that TriVLA operatesat approximately 36 Hz and surpasses state-of-the-art imitation learningbaselines on standard simulation benchmarks as well as challenging real-worldmanipulation tasks.</description>
      <author>example@mail.com (Zhenyang Liu, Yongchong Gu, Sixiao Zheng, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2507.01424v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>The language of time: a language model perspective on time-series foundation models</title>
      <link>http://arxiv.org/abs/2507.00078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于片段的时间序列基础模型在时间序列数据上的表现，分析了其表示学习和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型的兴起，大规模参数和海量数据集训练基础模型的方法在多个领域取得了显著成功。时间序列基础模型是这个范式的扩展，表现出卓越的表达能力、泛化能力和跨领域迁移能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决时间序列数据具有不同动态系统，但模型却表现出跨领域迁移能力的悖论，本文从理论和实验角度研究基于片段的时间序列基础模型的表示学习和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文通过理论分析和实验验证，提出模型通过将确定性向量表示扩展到潜在的概率分布形式，从而实现了语言模型的表示范式泛化。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，连续时间序列片段可以被忠实地量化为具有与自然语言高度一致的统计特性的离散词汇。这种泛化使得时间序列模型继承了大型语言模型的鲁棒表示和迁移能力，解释了它们在时间任务中的优异表现。&lt;h4&gt;结论&lt;/h4&gt;本文为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了严格的理论基石。&lt;h4&gt;翻译&lt;/h4&gt;With the rise of large language models, the paradigm of training foundation models with massive parameter counts on vast datasets has been adopted in multiple domains to achieve remarkable success. Time series foundation models represent a significant extension of this paradigm, demonstrating exceptional expressive power, generalization, and cross-domain transferability. However, this gives rise to a fundamental paradox: time series data reflect distinct dynamical systems, making cross-domain transfer intuitively implausible, yet this is contradicted by the models' empirical success. To resolve this paradox, this paper investigates, from both theoretical and experimental perspectives, the representation learning mechanisms and generalization capabilities of patch-based time series foundation models. We argue that such models are not merely applying a new architecture but are fundamentally generalizing the representation paradigm of language models by extending deterministic vector-based representations to latent probabilistic distributional forms. Our theoretical analysis supports this framework by demonstrating that continuous time-series patches can be faithfully quantized into a discrete vocabulary whose key statistical properties are highly consistent with those of natural language. This generalization allows time series models to inherit the robust representation and transfer abilities of large language models, thereby explaining their superior performance in temporal tasks. Ultimately, our work provides a rigorous theoretical cornerstone for understanding, evaluating, and improving the safety and reliability of large-scale time series foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of large language models, the paradigm of training foundationmodels with massive parameter counts on vast datasets has been adopted inmultiple domains to achieve remarkable success. Time series foundation modelsrepresent a significant extension of this paradigm, demonstrating exceptionalexpressive power, generalization, and cross-domain transferability. However,this gives rise to a fundamental paradox: time series data reflect distinctdynamical systems, making cross-domain transfer intuitively implausible, yetthis is contradicted by the models' empirical success. To resolve this paradox,this paper investigates, from both theoretical and experimental perspectives,the representation learning mechanisms and generalization capabilities ofpatch-based time series foundation models. We argue that such models are notmerely applying a new architecture but are fundamentally generalizing therepresentation paradigm of language models by extending deterministicvector-based representations to latent probabilistic distributional forms. Ourtheoretical analysis supports this framework by demonstrating that continuoustime-series patches can be faithfully quantized into a discrete vocabularywhose key statistical properties are highly consistent with those of naturallanguage. This generalization allows time series models to inherit the robustrepresentation and transfer abilities of large language models, therebyexplaining their superior performance in temporal tasks. Ultimately, our workprovides a rigorous theoretical cornerstone for understanding, evaluating, andimproving the safety and reliability of large-scale time series foundationmodels.</description>
      <author>example@mail.com (Yi Xie, Yun Xiong, Zejian Shi, Hao Niu, Zhengfu Liu)</author>
      <guid isPermaLink="false">2507.00078v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Decomposing Prediction Mechanisms for In-Context Recall</title>
      <link>http://arxiv.org/abs/2507.01414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 47 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的玩具问题系列，结合了线性回归风格的连续情境学习（ICL）和离散关联回忆的特点。&lt;h4&gt;背景&lt;/h4&gt;研究者对从玩具中抽取的样本轨迹进行预训练，特别是随机抽取的线性确定性动力系统中的符号标记交错状态观察。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer模型是否能够在被提示回忆之前在情境中看到的序列状态时，能够回忆起该状态。&lt;h4&gt;方法&lt;/h4&gt;研究者观察模型是否能够执行两个功能：(1) 确定应该回忆哪个系统的状态并将其应用于最后看到的状态，(2) 继续应用正确的系统来预测后续状态。&lt;h4&gt;主要发现&lt;/h4&gt;训练动态显示，第一个能力在模型训练的后期出现得很好。令人惊讶的是，继续预测恢复序列的能力发展得要早得多。&lt;h4&gt;结论&lt;/h4&gt;通过分布外实验和对模型权重进行边缘修剪的机制分析，发现对于这个玩具问题，下一个标记的预测涉及至少两个不同的机制。一个机制使用离散符号标签来进行预测先前看到的序列恢复所需的关联回忆。第二个机制，对离散符号标签在很大程度上是无关的，基于前一个标记和上下文进行“贝叶斯式”预测。这两种机制有不同的学习动态。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新的玩具问题系列，它结合了线性回归风格的连续情境学习（ICL）和离散关联回忆的特点。我们在玩具的样本轨迹上预训练了Transformer模型，特别是从随机抽取的线性确定性动力系统中提取的符号标记交错状态观察。我们研究了当模型被提示回忆之前在情境中看到的序列状态时，它是否能够回忆起该状态。仔细观察这个任务，很明显，模型必须执行两个功能：(1) 确定应该回忆哪个系统的状态并将其应用于最后看到的状态，(2) 继续应用正确的系统来预测后续状态。训练动态显示，第一个能力在模型训练的后期出现得很好。令人惊讶的是，继续预测恢复序列的能力发展得要早得多。通过分布外实验，以及通过边缘修剪对模型权重进行的机制分析，我们发现对于这个玩具问题，下一个标记的预测涉及至少两个不同的机制。一个机制使用离散符号标签来进行预测先前看到的序列恢复所需的关联回忆。第二个机制，对离散符号标签在很大程度上是无关的，基于前一个标记和上下文进行“贝叶斯式”预测。这两种机制有不同的学习动态。为了确认这种多机制（表现为不同的阶段转换）现象不是我们玩具设置中的伪象，我们使用OLMo训练检查点在ICL翻译任务上观察到了类似的现象：第一任务标记性能与第二任务标记性能之间出现决定性的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new family of toy problems that combine features oflinear-regression-style continuous in-context learning (ICL) with discreteassociative recall. We pretrain transformer models on sample traces from thistoy, specifically symbolically-labeled interleaved state observations fromrandomly drawn linear deterministic dynamical systems. We study if thetransformer models can recall the state of a sequence previously seen in itscontext when prompted to do so with the corresponding in-context label. Takinga closer look at this task, it becomes clear that the model must perform twofunctions: (1) identify which system's state should be recalled and apply thatsystem to its last seen state, and (2) continuing to apply the correct systemto predict the subsequent states. Training dynamics reveal that the firstcapability emerges well into a model's training. Surprisingly, the secondcapability, of continuing the prediction of a resumed sequence, develops muchearlier.  Via out-of-distribution experiments, and a mechanistic analysis on modelweights via edge pruning, we find that next-token prediction for this toyproblem involves at least two separate mechanisms. One mechanism uses thediscrete symbolic labels to do the associative recall required to predict thestart of a resumption of a previously seen sequence. The second mechanism,which is largely agnostic to the discrete symbolic labels, performs a"Bayesian-style" prediction based on the previous token and the context. Thesetwo mechanisms have different learning dynamics.  To confirm that this multi-mechanism (manifesting as separate phasetransitions) phenomenon is not just an artifact of our toy setting, we usedOLMo training checkpoints on an ICL translation task to see a similarphenomenon: a decisive gap in the emergence of first-task-token performance vssecond-task-token performance.</description>
      <author>example@mail.com (Sultan Daniels, Dylan Davis, Dhruv Gautam, Wentinn Liao, Gireeja Ranade, Anant Sahai)</author>
      <guid isPermaLink="false">2507.01414v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy</title>
      <link>http://arxiv.org/abs/2507.01387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了BronchoGAN，这是一种用于图像到图像转换的条件生成对抗网络，旨在解决支气管镜图像可用性有限的问题。&lt;h4&gt;背景&lt;/h4&gt;支气管镜图像的有限可用性使得图像合成对于训练深度学习模型特别有趣。不同领域之间稳健的图像翻译（如虚拟支气管镜、模型以及体内和体外图像数据）对于临床应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过BronchoGAN引入解剖约束，以实现图像到图像的转换，并减少对单个训练数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;BronchoGAN通过将支气管或ifice的匹配作为条件约束集成到条件生成对抗网络中。此外，它使用基础模型生成的深度图像作为中间表示，以确保不同输入领域的鲁棒性，并允许轻松构建配对图像数据用于训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，来自不同领域的输入图像（例如虚拟支气管镜、模型）可以成功转换为模仿真实人类气道外观的图像。解剖设置（即支气管或ifice）可以通过我们的方法稳健地保留，通过改进的FID、SSIM和dice系数得分进行了定性和定量证明。解剖约束使合成图像的Dice系数提高了0.43。&lt;h4&gt;结论&lt;/h4&gt;BronchoGAN能够将公共CT扫描数据（虚拟支气管镜）纳入其中，以生成具有逼真外观的大规模支气管镜图像数据集。该方法能够弥补缺失的公共支气管镜图像的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11548-025-03450-w&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The limited availability of bronchoscopy images makes image synthesisparticularly interesting for training deep learning models. Robust imagetranslation across different domains -- virtual bronchoscopy, phantom as wellas in-vivo and ex-vivo image data -- is pivotal for clinical applications. Thispaper proposes BronchoGAN introducing anatomical constraints for image-to-imagetranslation being integrated into a conditional GAN. In particular, we forcebronchial orifices to match across input and output images. We further proposeto use foundation model-generated depth images as intermediate representationensuring robustness across a variety of input domains establishing models withsubstantially less reliance on individual training datasets. Moreover ourintermediate depth image representation allows to easily construct paired imagedata for training. Our experiments showed that input images from differentdomains (e.g. virtual bronchoscopy, phantoms) can be successfully translated toimages mimicking realistic human airway appearance. We demonstrated thatanatomical settings (i.e. bronchial orifices) can be robustly preserved withour approach which is shown qualitatively and quantitatively by means ofimproved FID, SSIM and dice coefficients scores. Our anatomical constraintsenabled an improvement in the Dice coefficient of up to 0.43 for syntheticimages. Through foundation models for intermediate depth representations,bronchial orifice segmentation integrated as anatomical constraints intoconditional GANs we are able to robustly translate images from differentbronchoscopy input domains. BronchoGAN allows to incorporate public CT scandata (virtual bronchoscopy) in order to generate large-scale bronchoscopy imagedatasets with realistic appearance. BronchoGAN enables to bridge the gap ofmissing public bronchoscopy images.</description>
      <author>example@mail.com (Ahmad Soliman, Ron Keuth, Marian Himstedt)</author>
      <guid isPermaLink="false">2507.01387v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LEDOM: An Open and Fundamental Reverse Language Model</title>
      <link>http://arxiv.org/abs/2507.01335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了LEDOM，首个纯反向语言模型，通过在435B个标记上自回归训练，具有2B和7B参数变体，以反向时间顺序处理序列，通过预测前一个标记进行序列处理。同时，提出反向语言模型作为通用任务的潜在基础模型，并展示了相关实例和见解。基于LEDOM，引入了新的应用：反向奖励，通过LEDOM引导的前向语言模型输出重排序，在数学推理任务上显著提升了性能。这种方法利用LEDOM独特的反向推理能力，通过后验评估来提高生成质量。研究结果指出LEDOM具有独特的特征和广泛的应用潜力。将发布所有模型、训练代码和预训练数据，以促进未来的研究。&lt;h4&gt;背景&lt;/h4&gt;背景信息未在摘要中提及。&lt;h4&gt;目的&lt;/h4&gt;目的是提出LEDOM作为首个纯反向语言模型，并探讨其在通用任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;方法包括自回归训练LEDOM，处理序列时采用反向时间顺序，通过预测前一个标记进行序列处理，并引入反向奖励作为新的应用。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现是LEDOM在数学推理任务上通过反向奖励方法显著提升了性能，显示出独特的反向推理能力和广泛的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;结论是LEDOM具有独特的特征和广泛的应用潜力，未来将发布所有模型、训练代码和预训练数据。&lt;h4&gt;翻译&lt;/h4&gt;内容为英文摘要的中文翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce LEDOM, the first purely reverse language model, trainedautoregressively on 435B tokens with 2B and 7B parameter variants, whichprocesses sequences in reverse temporal order through previous tokenprediction. For the first time, we present the reverse language model as apotential foundational model across general tasks, accompanied by a set ofintriguing examples and insights. Based on LEDOM, we further introduce a novelapplication: Reverse Reward, where LEDOM-guided reranking of forward languagemodel outputs leads to substantial performance improvements on mathematicalreasoning tasks. This approach leverages LEDOM's unique backward reasoningcapability to refine generation quality through posterior evaluation. Ourfindings suggest that LEDOM exhibits unique characteristics with broadapplication potential. We will release all models, training code, andpre-training data to facilitate future research.</description>
      <author>example@mail.com (Xunjian Yin, Sitao Cheng, Yuxi Xie, Xinyu Hu, Li Lin, Xinyi Wang, Liangming Pan, William Yang Wang, Xiaojun Wan)</author>
      <guid isPermaLink="false">2507.01335v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models</title>
      <link>http://arxiv.org/abs/2507.01201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为JAM的框架，旨在通过多目标优化任务，在保持每种模态的原始结构的同时，实现不同模态之间的对齐，以促进跨模态模型的共享结构。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言模型在各自的模态、目标和架构下独立训练，存在不同的表示空间，但存在一种假设，即这些模型可能最终趋向于一个共享的现实统计模型。&lt;h4&gt;目的&lt;/h4&gt;研究如何超越事后统计检测对齐，并明确地在不同的表示空间之间优化对齐。&lt;h4&gt;方法&lt;/h4&gt;将普罗塔戈拉对齐问题作为多目标优化任务，提出JAM框架，通过联合训练模态特定的自动编码器，在预训练的单模态模型的潜在表示上，通过重建和跨模态目标鼓励对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，JAM框架在三个关键设计轴上表现出色：(i) 对齐目标，包括对比损失、其硬负样本变体和提出的扩展损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表示收敛的影响。&lt;h4&gt;结论&lt;/h4&gt;JAM框架能够可靠地诱导对齐，即使在冻结的独立训练表示之间，也为将通用单模态基础模型转换为专用多模态模型提供了理论洞察和实践途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：独立训练的视觉和语言模型居住在由各自模态、目标和架构塑造的分离表示空间中。然而，一个新兴的假设——柏拉图表示假设——表明，这样的模型仍然可能趋向于一个共享的现实统计模型。如果这种兼容性存在，那么就提出了一个基本问题：我们能否超越事后统计检测对齐，并明确地在这样的分离表示之间优化对齐？我们将普罗塔戈拉对齐问题设定为多目标优化任务——在保持每种模态的原始结构的同时，实现相互协调。我们引入了联合自动编码器调制器（JAM）框架，该框架在预训练的单模态模型的潜在表示上联合训练模态特定的自动编码器，通过重建和跨模态目标鼓励对齐。通过类比，这个框架作为逃离柏拉图洞穴的方法，使得从分离的输入中产生共享结构。我们在三个关键设计轴上评估了这个框架：(i) 对齐目标——比较对比损失（Con）、其硬负样本变体（NegCon）和我们的扩展损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表示收敛的影响。我们的结果表明，我们的轻量级Pareto有效框架可以可靠地诱导对齐，即使在冻结的独立训练表示之间，也为将通用单模态基础模型转换为专用多模态模型提供了理论洞察和实践途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Independently trained vision and language models inhabit disjointrepresentational spaces, shaped by their respective modalities, objectives, andarchitectures. Yet an emerging hypothesis - the Platonic RepresentationHypothesis - suggests that such models may nonetheless converge toward a sharedstatistical model of reality. This compatibility, if it exists, raises afundamental question: can we move beyond post-hoc statistical detection ofalignment and explicitly optimize for it between such disjoint representations?We cast this Platonic alignment problem as a multi-objective optimization task- preserve each modality's native structure while aligning for mutualcoherence. We introduce the Joint Autoencoder Modulator (JAM) framework thatjointly trains modality-specific autoencoders on the latent representations ofpre-trained single modality models, encouraging alignment through bothreconstruction and cross-modal objectives. By analogy, this framework serves asa method to escape Plato's Cave, enabling the emergence of shared structurefrom disjoint inputs. We evaluate this framework across three critical designaxes: (i) the alignment objective - comparing contrastive loss (Con), itshard-negative variant (NegCon), and our Spread loss, (ii) the layer depth atwhich alignment is most effective, and (iii) the impact of foundation modelscale on representational convergence. Our findings show that our lightweightPareto-efficient framework reliably induces alignment, even across frozen,independently trained representations, offering both theoretical insight andpractical pathways for transforming generalist unimodal foundations intospecialist multimodal models.</description>
      <author>example@mail.com (Hyoseo, Yoon, Yisong Yue, Been Kim)</author>
      <guid isPermaLink="false">2507.01201v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning</title>
      <link>http://arxiv.org/abs/2507.01196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对大型脑电模型（LBMs）在脑-机接口（BCI）领域的应用进行了评估，发现尽管这些模型在某些任务上有所改进，但效率和应用前景仍存疑。&lt;h4&gt;背景&lt;/h4&gt;脑电模型在人工智能领域展现出显著的成功，但在脑波建模方面的能力尚不明确。&lt;h4&gt;目的&lt;/h4&gt;全面评估当前的大型脑电基础模型（LBMs）在BCI基准任务上的表现，包括记忆任务和睡眠阶段分类。&lt;h4&gt;方法&lt;/h4&gt;通过在多个BCI基准任务上系统地微调实验，包括详细的可解释性研究和低秩自适应（LoRA）技术。&lt;h4&gt;主要发现&lt;/h4&gt;最先进的LBMs在传统深度架构上仅实现微小改进（0.9%-1.2%），但需要显著更多的参数（百万级对千级），提出了关于它们在BCI应用中效率和适用性的问题。LoRA的应用显示了性能提升，但当前架构和训练的无效性限制了LBMs的能力。&lt;h4&gt;结论&lt;/h4&gt;为了推动LBMs的发展，提出了针对特定领域的发展策略，并暗示当前架构可能需要重新设计以充分利用基础模型在脑波分析中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在人工智能（AI）的各个领域都取得了显著的成效，然而它们在脑波建模方面的能力仍然不清楚。在本文中，我们通过对多个脑-机接口（BCI）基准任务，包括记忆任务和睡眠阶段分类，进行系统的微调实验，全面评估了当前大型脑电基础模型（LBMs）。我们的广泛分析表明，最先进的LBMs在传统深度架构上仅实现了微小的改进（0.9%-1.2%），而需要显著更多的参数（百万级对千级），这在BCI环境中引发了关于它们效率和适用性的重要问题。此外，通过详细的可解释性研究和低秩自适应（LoRA），我们在不降低性能的情况下显著减少了可训练的参数，同时证明了架构和训练的无效率限制了LBMs当前的能力。我们的实验涵盖了完整的模型微调和参数高效自适应技术，为BCI应用提供了最佳的训练策略。我们开创性地将LoRA应用于LBMs，发现当同时调整多个神经网络组件时，通常会出现性能提升。这些发现强调了在特定领域开发策略的迫切需要，表明当前的架构可能需要重新设计以充分利用基础模型在脑波分析中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models have demonstrated significant success across variousdomains in Artificial Intelligence (AI), yet their capabilities for brainwavemodeling remain unclear. In this paper, we comprehensively evaluate currentLarge Brainwave Foundation Models (LBMs) through systematic fine-tuningexperiments across multiple Brain-Computer Interface (BCI) benchmark tasks,including memory tasks and sleep stage classification. Our extensive analysisshows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)over traditional deep architectures while requiring significantly moreparameters (millions vs thousands), raising important questions about theirefficiency and applicability in BCI contexts. Moreover, through detailedablation studies and Low-Rank Adaptation (LoRA), we significantly reducetrainable parameters without performance degradation, while demonstrating thatarchitectural and training inefficiencies limit LBMs' current capabilities. Ourexperiments span both full model fine-tuning and parameter-efficient adaptationtechniques, providing insights into optimal training strategies for BCIapplications. We pioneer the application of LoRA to LBMs, revealing thatperformance benefits generally emerge when adapting multiple neural networkcomponents simultaneously. These findings highlight the critical need fordomain-specific development strategies to advance LBMs, suggesting that currentarchitectures may require redesign to fully leverage the potential offoundation models in brainwave analysis.</description>
      <author>example@mail.com (Na Lee, Konstantinos Barmpas, Yannis Panagakis, Dimitrios Adamos, Nikolaos Laskaris, Stefanos Zafeiriou)</author>
      <guid isPermaLink="false">2507.01196v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks</title>
      <link>http://arxiv.org/abs/2507.01001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SciArena是一个开放且协作的平台，用于评估科学文献任务中的基础模型，通过社区投票的方式来比较模型表现。&lt;h4&gt;背景&lt;/h4&gt;SciArena不同于传统的科学文献理解和综合基准测试，它直接让研究社区参与评价。&lt;h4&gt;目的&lt;/h4&gt;SciArena旨在通过集体智慧提供对开放科学任务中模型性能的社区驱动评价，这些任务需要基于文献的、长篇的回答。&lt;h4&gt;方法&lt;/h4&gt;SciArena支持23个开源和专有基础模型，并收集了来自不同科学领域的超过13,000个来自可信研究者的投票。通过分析数据，SciArena-Eval元评估基准被发布，用于衡量模型判断答案质量准确性的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;分析的数据显示，提交的问题多样，与实际文献需求一致，参与研究者在其评价中表现出强烈的自我一致性和标注者间一致性。&lt;h4&gt;结论&lt;/h4&gt;SciArena-Eval基准强调了自动评估方法可靠性的需要，并指出了当前基准的挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们提出SciArena，一个开放且协作的平台，用于评估科学文献任务中的基础模型。与传统的科学文献理解和综合基准测试不同，SciArena直接让研究社区参与评价。通过利用集体智慧，SciArena提供对开放科学任务中模型性能的社区驱动评价，这些任务需要基于文献的、长篇的回答。该平台目前支持23个开源和专有基础模型，并收集了来自不同科学领域的超过13,000个来自可信研究者的投票。我们分析了迄今为止收集的数据，并确认提交的问题多样，与实际文献需求一致，参与研究者在其评价中表现出强烈的自我一致性和标注者间一致性。我们讨论了基于模型排名排行榜的结果和见解。为了进一步促进基于模型自动评估系统的文献任务研究，我们发布了SciArena-Eval，一个基于我们收集的偏好数据的元评估基准。该基准通过比较模型的成对评估与人类投票来衡量模型判断答案质量准确性的准确性。我们的实验突出了基准的挑战，并强调了需要更可靠的自动评估方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SciArena, an open and collaborative platform for evaluatingfoundation models on scientific literature tasks. Unlike traditional benchmarksfor scientific literature understanding and synthesis, SciArena engages theresearch community directly, following the Chatbot Arena evaluation approach ofcommunity voting on model comparisons. By leveraging collective intelligence,SciArena offers a community-driven evaluation of model performance onopen-ended scientific tasks that demand literature-grounded, long-formresponses. The platform currently supports 23 open-source and proprietaryfoundation models and has collected over 13,000 votes from trusted researchersacross diverse scientific domains. We analyze the data collected so far andconfirm that the submitted questions are diverse, aligned with real-worldliterature needs, and that participating researchers demonstrate strongself-consistency and inter-annotator agreement in their evaluations. We discussthe results and insights based on the model ranking leaderboard. To furtherpromote research in building model-based automated evaluation systems forliterature tasks, we release SciArena-Eval, a meta-evaluation benchmark basedon our collected preference data. The benchmark measures the accuracy of modelsin judging answer quality by comparing their pairwise assessments with humanvotes. Our experiments highlight the benchmark's challenges and emphasize theneed for more reliable automated evaluation methods.</description>
      <author>example@mail.com (Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan)</author>
      <guid isPermaLink="false">2507.01001v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Foundation Models are Flow Predictors</title>
      <link>http://arxiv.org/abs/2507.00945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2203.07372&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究调查了时间序列基础模型（TSFMs）在人群流量预测中的有效性，重点关注Moirai和TimesFM模型。&lt;h4&gt;背景&lt;/h4&gt;研究基于三个真实世界的流动性数据集——Bike NYC、Taxi Beijing和Spanish national OD flows。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估这些模型在严格的无监督设置下的性能，即仅使用每个OD流的时间演变，而不使用任何显式的空间信息。&lt;h4&gt;方法&lt;/h4&gt;模型在零样本设置下进行评估，并与统计和深度学习基线进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;Moirai和TimesFM在RMSE、MAE和CPC方面均优于最先进的竞争对手，分别降低了33%、39%和提高了49%。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了TSFMs在准确、可扩展的流量预测中的实际价值，即使在数据标注有限或缺少空间上下文的情况下。&lt;h4&gt;翻译&lt;/h4&gt;We investigate the effectiveness of time series foundation models (TSFMs) for crowd flow prediction, focusing on Moirai and TimesFM. Evaluated on three real-world mobility datasets-Bike NYC, Taxi Beijing, and Spanish national OD flows-these models are deployed in a strict zero-shot setting, using only the temporal evolution of each OD flow and no explicit spatial information. Moirai and TimesFM outperform both statistical and deep learning baselines, achieving up to 33% lower RMSE, 39% lower MAE and up to 49% higher CPC compared to state-of-the-art competitors. Our results highlight the practical value of TSFMs for accurate, scalable flow prediction, even in scenarios with limited annotated data or missing spatial context.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the effectiveness of time series foundation models (TSFMs) forcrowd flow prediction, focusing on Moirai and TimesFM. Evaluated on threereal-world mobility datasets-Bike NYC, Taxi Beijing, and Spanish national ODflows-these models are deployed in a strict zero-shot setting, using only thetemporal evolution of each OD flow and no explicit spatial information. Moiraiand TimesFM outperform both statistical and deep learning baselines, achievingup to 33% lower RMSE, 39% lower MAE and up to 49% higher CPC compared tostate-of-the-art competitors. Our results highlight the practical value ofTSFMs for accurate, scalable flow prediction, even in scenarios with limitedannotated data or missing spatial context.</description>
      <author>example@mail.com (Massimiliano Luca, Ciro Beneduce, Bruno Lepri)</author>
      <guid isPermaLink="false">2507.00945v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention</title>
      <link>http://arxiv.org/abs/2507.00884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LiTEN的新型equivariant神经网络，结合Tensorized Quadrangle Attention (TQA)技术，用于提高生物分子模拟的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的生物分子模拟方法在准确性和效率上存在局限性，经典力场缺乏对过渡态和精细构象细节的准确性，而量子力学方法计算成本过高。&lt;h4&gt;目的&lt;/h4&gt;提出LiTEN，旨在克服现有方法的局限性，实现高精度和高效能的生物分子模拟。&lt;h4&gt;方法&lt;/h4&gt;LiTEN使用TQA技术高效地建模三体和四体相互作用，通过向量操作重新参数化高阶张量特征，避免使用昂贵的球谐函数。LiTEN-FF是基于LiTEN的AIFF基础模型，在nablaDFT数据集上进行预训练，并在SPICE上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;LiTEN在rMD17、MD22和Chignolin的多数评估子集中实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF能够执行包括量子级构象搜索、几何优化和自由能表面构建在内的多种下游生物分子建模任务，并且比MACE-OFF对大分子（约1000个原子）的推理速度快10倍。&lt;h4&gt;结论&lt;/h4&gt;LiTEN提供了一个基于物理的高效框架，推动了复杂生物分子建模的发展，为药物发现和相关应用提供了一个多功能的基石。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate atomistic biomolecular simulations are vital for disease mechanismunderstanding, drug discovery, and biomaterial design, but existing simulationmethods exhibit significant limitations. Classical force fields are efficientbut lack accuracy for transition states and fine conformational detailscritical in many chemical and biological processes. Quantum Mechanics (QM)methods are highly accurate but computationally infeasible for large-scale orlong-time simulations. AI-based force fields (AIFFs) aim to achieve QM-levelaccuracy with efficiency but struggle to balance many-body modeling complexity,accuracy, and speed, often constrained by limited training data andinsufficient validation for generalizability. To overcome these challenges, weintroduce LiTEN, a novel equivariant neural network with Tensorized QuadrangleAttention (TQA). TQA efficiently models three- and four-body interactions withlinear complexity by reparameterizing high-order tensor features via vectoroperations, avoiding costly spherical harmonics. Building on LiTEN, LiTEN-FF isa robust AIFF foundation model, pre-trained on the extensive nablaDFT datasetfor broad chemical generalization and fine-tuned on SPICE for accurate solvatedsystem simulations. LiTEN achieves state-of-the-art (SOTA) performance acrossmost evaluation subsets of rMD17, MD22, and Chignolin, outperforming leadingmodels such as MACE, NequIP, and EquiFormer. LiTEN-FF enables the mostcomprehensive suite of downstream biomolecular modeling tasks to date,including QM-level conformer searches, geometry optimization, and free energysurface construction, while offering 10x faster inference than MACE-OFF forlarge biomolecules (~1000 atoms). In summary, we present a physically grounded,highly efficient framework that advances complex biomolecular modeling,providing a versatile foundation for drug discovery and related applications.</description>
      <author>example@mail.com (Qun Su, Kai Zhu, Qiaolin Gou, Jintu Zhang, Renling Hu, Yurong Li, Yongze Wang, Hui Zhang, Ziyi You, Linlong Jiang, Yu Kang, Jike Wang, Chang-Yu Hsieh, Tingjun Hou)</author>
      <guid isPermaLink="false">2507.00884v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents</title>
      <link>http://arxiv.org/abs/2507.00841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了移动多模态智能代理系统的安全问题，通过结合行为序列信息构建风险识别机制，并设计了一种基于大型语言模型的自动化辅助评估方案。&lt;h4&gt;背景&lt;/h4&gt;随着多模态基础模型在智能代理系统中的广泛应用，相关系统面临潜在的越狱风险，攻击者可能通过特定输入诱导代理绕过行为约束，触发风险操作，如修改设置、执行未授权命令或冒充用户身份。&lt;h4&gt;目的&lt;/h4&gt;提高对风险行为的识别，降低代理被越狱的概率，为多模态智能代理系统的安全风险建模和保护提供参考。&lt;h4&gt;方法&lt;/h4&gt;构建风险识别机制，结合行为序列信息，设计基于大型语言模型的自动化辅助评估方案。&lt;h4&gt;主要发现&lt;/h4&gt;在几个代表性高风险任务中的初步验证表明，该方法在一定程度上提高了对风险行为的识别，有助于降低代理被越狱的概率。&lt;h4&gt;结论&lt;/h4&gt;本研究为多模态智能代理系统的安全风险建模和保护提供了有价值的参考。&lt;h4&gt;翻译&lt;/h4&gt;With the wide application of multimodal foundation models in intelligent agent systems, scenarios such as mobile device control, intelligent assistant interaction, and multimodal task execution are gradually relying on such large model-driven agents. However, the related systems are also increasingly exposed to potential jailbreak risks. Attackers may induce the agents to bypass the original behavioral constraints through specific inputs, and then trigger certain risky and sensitive operations, such as modifying settings, executing unauthorized commands, or impersonating user identities, which brings new challenges to system security. Existing security measures for intelligent agents still have limitations when facing complex interactions, especially in detecting potentially risky behaviors across multiple rounds of conversations or sequences of tasks. In addition, an efficient and consistent automated methodology to assist in assessing and determining the impact of such risks is currently lacking. This work explores the security issues surrounding mobile multimodal agents, attempts to construct a risk discrimination mechanism by incorporating behavioral sequence information, and designs an automated assisted assessment scheme based on a large language model. Through preliminary validation in several representative high-risk tasks, the results show that the method can improve the recognition of risky behaviors to some extent and assist in reducing the probability of agents being jailbroken. We hope that this study can provide some valuable references for the security risk modeling and protection of multimodal intelligent agent systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the wide application of multimodal foundation models in intelligentagent systems, scenarios such as mobile device control, intelligent assistantinteraction, and multimodal task execution are gradually relying on such largemodel-driven agents. However, the related systems are also increasingly exposedto potential jailbreak risks. Attackers may induce the agents to bypass theoriginal behavioral constraints through specific inputs, and then triggercertain risky and sensitive operations, such as modifying settings, executingunauthorized commands, or impersonating user identities, which brings newchallenges to system security. Existing security measures for intelligentagents still have limitations when facing complex interactions, especially indetecting potentially risky behaviors across multiple rounds of conversationsor sequences of tasks. In addition, an efficient and consistent automatedmethodology to assist in assessing and determining the impact of such risks iscurrently lacking. This work explores the security issues surrounding mobilemultimodal agents, attempts to construct a risk discrimination mechanism byincorporating behavioral sequence information, and designs an automatedassisted assessment scheme based on a large language model. Through preliminaryvalidation in several representative high-risk tasks, the results show that themethod can improve the recognition of risky behaviors to some extent and assistin reducing the probability of agents being jailbroken. We hope that this studycan provide some valuable references for the security risk modeling andprotection of multimodal intelligent agent systems.</description>
      <author>example@mail.com (Siyuan Liang, Tianmeng Fang, Zhe Liu, Aishan Liu, Yan Xiao, Jinyuan He, Ee-Chien Chang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2507.00841v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>World4Drive: End-to-End Autonomous Driving via Intention-aware Physical Latent World Model</title>
      <link>http://arxiv.org/abs/2507.00603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025, first version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为World4Drive的端到端自动驾驶框架，该框架利用视觉基础模型构建潜在世界模型，以生成和评估多模态规划轨迹，实现感知注释自由、端到端规划。&lt;h4&gt;背景&lt;/h4&gt;现有的端到端自动驾驶系统依赖昂贵的感知监督来提取场景信息。&lt;h4&gt;目的&lt;/h4&gt;构建一个信息丰富的驾驶世界模型，以实现感知注释自由、端到端规划。&lt;h4&gt;方法&lt;/h4&gt;World4Drive首先提取场景特征，包括驾驶意图和由视觉基础模型提供的空间语义先验增强的世界潜在表示。然后，它根据当前场景特征和驾驶意图生成多模态规划轨迹，并在潜在空间中预测多个由意图驱动的未来状态。最后，它引入了一个世界模型选择模块来评估和选择最佳轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过自监督学习将实际未来观察与从潜在空间重构的预测观察对齐，实现了感知注释自由、端到端规划。World4Drive在开放循环nuScenes和闭环NavSim基准测试上均取得了最先进的性能，相对于L2误差降低了18.1%，碰撞率降低了46.7%，训练收敛速度提高了3.75倍。&lt;h4&gt;结论&lt;/h4&gt;World4Drive通过无需人工感知注释，在nuScenes和NavSim基准测试上均取得了显著的性能提升，证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end autonomous driving directly generates planning trajectories fromraw sensor data, yet it typically relies on costly perception supervision toextract scene information. A critical research challenge arises: constructingan informative driving world model to enable perception annotation-free,end-to-end planning via self-supervised learning. In this paper, we presentWorld4Drive, an end-to-end autonomous driving framework that employs visionfoundation models to build latent world models for generating and evaluatingmulti-modal planning trajectories. Specifically, World4Drive first extractsscene features, including driving intention and world latent representationsenriched with spatial-semantic priors provided by vision foundation models. Itthen generates multi-modal planning trajectories based on current scenefeatures and driving intentions and predicts multiple intention-driven futurestates within the latent space. Finally, it introduces a world model selectormodule to evaluate and select the best trajectory. We achieve perceptionannotation-free, end-to-end planning through self-supervised alignment betweenactual future observations and predicted observations reconstructed from thelatent space. World4Drive achieves state-of-the-art performance without manualperception annotations on both the open-loop nuScenes and closed-loop NavSimbenchmarks, demonstrating an 18.1\% relative reduction in L2 error, 46.7% lowercollision rate, and 3.75 faster training convergence. Codes will be accessed athttps://github.com/ucaszyp/World4Drive.</description>
      <author>example@mail.com (Yupeng Zheng, Pengxuan Yang, Zebin Xing, Qichao Zhang, Yuhang Zheng, Yinfeng Gao, Pengfei Li, Teng Zhang, Zhongpu Xia, Peng Jia, Dongbin Zhao)</author>
      <guid isPermaLink="false">2507.00603v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Clinical Records at Health System Scale</title>
      <link>http://arxiv.org/abs/2507.00574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025 Workshop on Foundation Models for Structured  Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于下一访问事件预测的序列EHR数据生成预训练策略，该策略能够自动回归地生成各种临床事件，并处理不同数据类型的联合预测，同时强调了对重复事件的预测正则化，并通过零样本预测验证了模型在预测痴呆症和膝关节骨关节炎发病风险方面的性能。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在语言和其他数据类型的建模中取得了显著成果，但在医疗保健领域，特别是结构化电子健康记录（EHRs）中的应用潜力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的生成预训练策略，用于处理序列EHR数据，并通过预测下一访问事件来生成临床事件。&lt;h4&gt;方法&lt;/h4&gt;采用基于下一访问事件预测的生成预训练策略，模型能够根据患者病史自动回归地生成各种临床事件，并处理不同数据类型的联合预测。同时，引入了重复事件预测的正则化方法，并指出了EHR基础模型评估中的一个关键陷阱。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过零样本预测方式在预测痴呆症和膝关节骨关节炎发病风险方面进行了评估，其性能与完全微调的掩码预训练Transformer基线相当，表明该方法能够捕捉复杂的临床依赖关系，而不需要昂贵的特定任务微调。&lt;h4&gt;结论&lt;/h4&gt;本文提出的预训练策略能够有效地处理EHR数据，并在预测痴呆症和膝关节骨关节炎发病风险方面展现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Large-scale pretraining has transformed modeling of language and other datatypes, but its potential remains underexplored in healthcare with structured electronic health records (EHRs). We present a novel generative pretraining strategy for sequential EHR data using next-visit event prediction. Our model learns to autoregressively generate various tokenized clinical events for the next visit based on patient history and inherently handles the joint prediction of heterogeneous data types. Additionally, we introduce regularization on predicting repeated events and highlight a key pitfall in EHR-based foundation model evaluations: repeated event tokens can inflate performance metrics when new onsets are not distinguished from subsequent occurrences. Our model is evaluated via zero-shot prediction for forecasting dementia and knee osteoarthritis incidence within 2 and 5 years, and the model performance rivals a fully fine-tuned masked pretrained Transformer baseline, demonstrating that our approach captures complex clinical dependencies without requiring costly task-specific fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale pretraining has transformed modeling of language and other datatypes, but its potential remains underexplored in healthcare with structuredelectronic health records (EHRs). We present a novel generative pretrainingstrategy for sequential EHR data using next-visit event prediction. Our modellearns to autoregressively generate various tokenized clinical events for thenext visit based on patient history and inherently handles the joint predictionof heterogeneous data types. Additionally, we introduce regularization onpredicting repeated events and highlight a key pitfall in EHR-based foundationmodel evaluations: repeated event tokens can inflate performance metrics whennew onsets are not distinguished from subsequent occurrences. Our model isevaluated via zero-shot prediction for forecasting dementia and kneeosteoarthritis incidence within 2 and 5 years, and the model performance rivalsa fully fine-tuned masked pretrained Transformer baseline, demonstrating thatour approach captures complex clinical dependencies without requiring costlytask-specific fine-tuning.</description>
      <author>example@mail.com (Haresh Rengaraj Rajamohan, Xiang Gao, Weicheng Zhu, Shih-Lun Huang, Long Chen, Kyunghyun Cho, Cem M. Deniz, Narges Razavian)</author>
      <guid isPermaLink="false">2507.00574v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention</title>
      <link>http://arxiv.org/abs/2507.00449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42nd International Conference on Machine Learning,  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18  pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对自然语言处理中长上下文建模的挑战，提出了一种基于状态空间模型（SSM）的改进方法，通过结合上下文相关的稀疏注意力机制（CDSA）和局部敏感哈希注意力（HAX）来提高长上下文建模能力。&lt;h4&gt;背景&lt;/h4&gt;当前主流的Transformer架构在处理长序列时时间复杂度呈二次方增长，而SSM虽然提供了一种次二次方的解决方案，但在捕捉长距离依赖关系方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;分析并提高SSM在长上下文建模方面的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的合成任务“联合回忆”，要求模型在给定上下文中回忆与键关联的值。通过理论证明，SSM在次二次方时间内无法解决多查询联合回忆问题。为了解决这个问题，提出了结合SSM与CDSA的方法，并进一步提出了HAX来实例化这一理论解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;HAX在合成和真实世界长上下文基准测试中，均优于SSM基线以及与上下文无关的稀疏注意力（CISA）集成的SSM。&lt;h4&gt;结论&lt;/h4&gt;HAX是一种有效的长上下文建模方法，能够提高SSM在自然语言处理领域的性能。&lt;h4&gt;翻译&lt;/h4&gt;Efficient long-context modeling remains a critical challenge for natural language processing (NLP), as the time complexity of the predominant Transformer architecture scales quadratically with the sequence length. While state-space models (SSMs) offer alternative sub-quadratic solutions, they struggle to capture long-range dependencies effectively. In this work, we focus on analyzing and improving the long-context modeling capabilities of SSMs. We show that the widely used synthetic task, associative recall, which requires a model to recall a value associated with a single key without context, insufficiently represents the complexities of real-world long-context modeling. To address this limitation, we extend the associative recall to a novel synthetic task, joint recall, which requires a model to recall the value associated with a key given in a specified context. Theoretically, we prove that SSMs do not have the expressiveness to solve multi-query joint recall in sub-quadratic time complexity. To resolve this issue, we propose a solution based on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which has the expressiveness to solve multi-query joint recall with sub-quadratic computation. To bridge the gap between theoretical analysis and real-world applications, we propose locality-sensitive Hashing Attention with sparse Key Selection (HAX), which instantiates the theoretical solution and is further tailored to natural language domains. Extensive experiments on both synthetic and real-world long-context benchmarks show that HAX consistently outperforms SSM baselines and SSMs integrated with context-independent sparse attention (CISA).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient long-context modeling remains a critical challenge for naturallanguage processing (NLP), as the time complexity of the predominantTransformer architecture scales quadratically with the sequence length. Whilestate-space models (SSMs) offer alternative sub-quadratic solutions, theystruggle to capture long-range dependencies effectively. In this work, we focuson analyzing and improving the long-context modeling capabilities of SSMs. Weshow that the widely used synthetic task, associative recall, which requires amodel to recall a value associated with a single key without context,insufficiently represents the complexities of real-world long-context modeling.To address this limitation, we extend the associative recall to a novelsynthetic task, \emph{joint recall}, which requires a model to recall the valueassociated with a key given in a specified context. Theoretically, we provethat SSMs do not have the expressiveness to solve multi-query joint recall insub-quadratic time complexity. To resolve this issue, we propose a solutionbased on integrating SSMs with Context-Dependent Sparse Attention (CDSA), whichhas the expressiveness to solve multi-query joint recall with sub-quadraticcomputation. To bridge the gap between theoretical analysis and real-worldapplications, we propose locality-sensitive Hashing Attention with sparse KeySelection (HAX), which instantiates the theoretical solution and is furthertailored to natural language domains. Extensive experiments on both syntheticand real-world long-context benchmarks show that HAX consistently outperformsSSM baselines and SSMs integrated with context-independent sparse attention(CISA).</description>
      <author>example@mail.com (Zhihao Zhan, Jianan Zhao, Zhaocheng Zhu, Jian Tang)</author>
      <guid isPermaLink="false">2507.00449v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling</title>
      <link>http://arxiv.org/abs/2506.19500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NaviAgent是一种基于图导航的双层规划架构，用于鲁棒地调用功能，提高了复杂、异构工具链的协调能力。&lt;h4&gt;背景&lt;/h4&gt;LLMs依赖静态知识和脆弱的工具调用，这在大型规模的复杂工具链中是一个限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来克服现有方法的限制，如单路径执行和搜索空间指数增长。&lt;h4&gt;方法&lt;/h4&gt;NaviAgent包括一个多路径决策器和图编码导航器。多路径决策器定义了一个四维决策空间，并动态选择最佳行动。图编码导航器构建了一个工具依赖异构图（TDHG），并集成了一种新的启发式搜索策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，NaviAgent在所有基础模型和任务复杂度上均实现了最高的任务成功率（TSR），并且其执行步骤通常在最高效的基线步骤附近，保证了质量和效率之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;NaviAgent通过提高工具链协调能力，显著提升了任务成功率，并在大型模型上实现了更高的TSR，特别是在复杂任务上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs' reliance on static knowledge and fragile tool invocation severelyhinders the orchestration of complex, heterogeneous toolchains, particularly atlarge scales. Existing methods typically use rigid single-path execution,resulting in poor error recovery and exponentially growing search spaces. Weintroduce NaviAgent, a graph-navigated bilevel planning architecture for robustfunction calling, comprising a Multi-Path Decider and Graph-Encoded Navigator.As an LLM-powered agent, the Multi-Path Decider defines a four-dimensionaldecision space and continuously perceives environmental states, dynamicallyselecting the optimal action to fully cover all tool invocation scenarios. TheGraph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph(TDHG), where node embeddings explicitly fuse API schema structure withhistorical invocation behavior. It also integrates a novel heuristic searchstrategy that guides the Decider toward efficient and highly successfultoolchains, even for unseen tool combinations. Experiments show that NaviAgentconsistently achieves the highest task success rate (TSR) across all foundationmodels and task complexities, outperforming the average baselines (ReAct,ToolLLM, {\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B,and Deepseek-V3, respectively. Its execution steps are typically within onestep of the most efficient baseline, ensuring a strong balance between qualityand efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of49.5%, surpassing the much larger 32B model (44.9%) under our architecture.Incorporating the Graph-Encoded Navigator further boosts TSR by an average of2.4 points, with gains up over 9 points on complex tasks for larger models(Deepseek-V3 and GPT-4o), highlighting its essential role in toolchainorchestration.</description>
      <author>example@mail.com (Yan Jiang, Hao Zhou, LiZhong GU, Ai Han, TianLong Li)</author>
      <guid isPermaLink="false">2506.19500v1</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
  <item>
      <title>Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</title>
      <link>http://arxiv.org/abs/2506.24124v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Ironieser/TimesCLIP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多模态对比学习框架，用于时间序列预测，通过将原始时间序列转换为结构化的视觉和文本视角，并通过对比学习在共享语义空间中对齐这些视角，以增强时间序列预测的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的时间序列预测依赖于单模态数值输入，难以捕捉高级语义模式。尽管最近的方法探索使用大型语言模型将时间序列表示为文本，但这些方法仍受限于标记序列的离散性，缺乏人类通常应用的感知直觉，如解释视觉模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够更有效地捕捉时间序列数据中的高级语义模式，并提高时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 将原始时间序列转换为结构化的视觉和文本视角；2. 直接从数值序列构建这两种模态；3. 使用对比学习在共享语义空间中对齐这些视角；4. 引入一个变量选择模块，利用对齐的表示来识别多元预测中最具信息量的变量。&lt;h4&gt;主要发现&lt;/h4&gt;在十五个短期和六个长期预测基准上的实验表明，该方法在时间序列预测中优于强单模态和跨模态基线，突出了多模态对齐在增强时间序列预测中的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态对比学习框架在时间序列预测中具有显著效果，能够提高预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal contrastive learning framework for time series forecasting, which transforms raw time series into structured visual and textual perspectives, aligns these views in a shared semantic space via contrastive learning, and thus enhances the effectiveness of time series forecasting. Extensive experiments demonstrate that the proposed approach consistently outperforms strong unimodal and cross-modal baselines, highlighting the effectiveness of multimodal alignment in enhancing time series forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting traditionally relies on unimodal numerical inputs,which often struggle to capture high-level semantic patterns due to their denseand unstructured nature. While recent approaches have explored representingtime series as text using large language models (LLMs), these methods remainlimited by the discrete nature of token sequences and lack the perceptualintuition humans typically apply, such as interpreting visual patterns. In thispaper, we propose a multimodal contrastive learning framework that transformsraw time series into structured visual and textual perspectives. Rather thanusing natural language or real-world images, we construct both modalitiesdirectly from numerical sequences. We then align these views in a sharedsemantic space via contrastive learning, enabling the model to capture richerand more complementary representations. Furthermore, we introduce a variateselection module that leverages the aligned representations to identify themost informative variables for multivariate forecasting. Extensive experimentson fifteen short-term and six long-term forecasting benchmarks demonstrate thatour approach consistently outperforms strong unimodal and cross-modalbaselines, highlighting the effectiveness of multimodal alignment in enhancingtime series forecasting. Code is available at:https://github.com/Ironieser/TimesCLIP.</description>
      <author>example@mail.com (Sixun Dong, Wei Fan, Teresa Wu, Yanjie Fu)</author>
      <guid isPermaLink="false">2506.24124v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning</title>
      <link>http://arxiv.org/abs/2506.22919v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Hecto是一种轻量级的MoE模型，通过结合不同类型的专家网络实现条件计算，提高了推理任务的性能和可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的MoE模型中，专家依赖于相同的归纳偏见，限制了表示多样性，且对需要不同推理类型的输入效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出Hecto模型，旨在通过结合不同类型的专家网络来提高MoE模型在推理任务中的性能和可解释性。&lt;h4&gt;方法&lt;/h4&gt;Hecto结合了GRU专家网络进行时间推理和FFNN专家网络进行静态抽象，使用稀疏的Top-1门控机制。&lt;h4&gt;主要发现&lt;/h4&gt;Hecto在多个推理基准测试中表现出色，实现了明确的专家专业化，并且在大批量输入时表现出更优的性能。&lt;h4&gt;结论&lt;/h4&gt;Hecto为条件计算设定了新的基准，提供了一个原则性的框架，用于在资源有限的环境中实现专门的推理。&lt;h4&gt;翻译&lt;/h4&gt;Mixture-of-Experts (MoE) 模型通过将输入路由到专门的专家来实现条件计算，但这些专家依赖于相同的归纳偏见，因此限制了表示多样性。这种静态的计算路径对于需要不同类型推理的输入来说效率低下，限制了专业化和可解释性。我们提出了Hecto，一种轻量级的MoE架构，通过结合一个GRU专家进行时间推理和一个FFNN专家进行静态抽象（在稀疏的Top-1门控机制下）来利用架构异质性。在三个推理基准（AGNews、SST-2、HotpotQA）和一个回归任务（STS-B）上评估，Hecto在性能上与同质基线相当或略逊一筹，尽管它接收的是孤立的输入表示，同时实现了明确的专家专业化，每个专家都与不同的推理类型（时间推理 vs. 静态推理）相对应。在更大的批量大小上，Hecto表现出改进的性能，得益于放宽的计算约束，这使得其异构架构能够更有效地优化。消融结果表明，架构多样性是Hecto在多种推理任务中稳定性和可解释性的来源。总的来说，Hecto为自己设定了条件计算的新基准，提供了一种原则性的框架，用于在资源有限的环境中实现专门的推理，其模型强度来源于原则性的专业化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixture-of-Experts (MoE) models enable conditional computation by routinginputs to specialized experts, but these experts rely on identical inductivebiases, thus limiting representational diversity. This static computationpathway is inefficient for inputs that require different types of reasoning andlimits specialization and interpretability. We propose Hecto, a lightweight MoEarchitecture that leverages architectural heterogeneity by combining a GRUexpert for temporal reasoning and an FFNN expert for static abstraction under asparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AGNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closelytrails homogeneous baselines in performance despite receiving isolated inputrepresentations, while achieving clear expert specialization, with each expertaligning to distinct reasoning types (temporal vs static). At larger batchsizes, Hecto exhibits improved performance, benefiting from relaxedcomputational constraints that allow its heterogeneous architecture to optimizemore effectively. Ablation results isolate architectural diversity as thesource of Hecto's stability and interpretability across diverse reasoningtasks. Overall, Hecto establishes itself as a new benchmark for conditionalcomputation, offering a principled framework for specialized reasoning inlow-resource regimes with its model strength derived from principledspecialization.</description>
      <author>example@mail.com (Sanskar Pandey, Ruhaan Chopra, Saad Murtaza Bhat, Ark Abhyudaya)</author>
      <guid isPermaLink="false">2506.22919v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.23309v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Project Page:  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的文本提示高斯分层方法SurgTPGS，用于准确理解3D手术场景，填补了现有工作在实时文本提示3D查询方面的空白。&lt;h4&gt;背景&lt;/h4&gt;在当代外科研究和实践中，准确理解具有文本提示能力的3D手术场景对于手术规划和实时术中引导至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出SurgTPGS方法，以实现更深入的理解复杂的手术环境，提高手术精度和安全性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种结合Segment Anything模型和最先进的视觉语言模型的3D语义特征学习方法，提取分割语言特征用于3D手术场景重建。此外，还提出了语义感知变形跟踪和语义区域感知优化，以提供更精确的重建。&lt;h4&gt;主要发现&lt;/h4&gt;SurgTPGS在两个真实世界手术数据集上进行了实验，证明了其在重建质量、语义平滑度和准确性方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;SurgTPGS有望革新外科实践，为开发下一代智能外科系统铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;In contemporary surgical research and practice, accurately comprehending 3D surgical scenes with text-promptable capabilities is particularly crucial for surgical planning and real-time intra-operative guidance, where precisely identifying and interacting with surgical tools and anatomical structures is paramount. However, existing works focus on surgical vision-language model (VLM), 3D reconstruction, and segmentation separately, lacking support for real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a novel text-promptable Gaussian Splatting method to fill this gap. We introduce a 3D semantics feature learning strategy incorporating the Segment Anything model and state-of-the-art vision-language models. We extract the segmented language features for 3D surgical scene reconstruction, enabling a more in-depth understanding of the complex surgical environment. We also propose semantic-aware deformation tracking to capture the seamless deformation of semantic features, providing a more precise reconstruction for both texture and semantic features. Furthermore, we present semantic region-aware optimization, which utilizes regional-based semantic information to supervise the training, particularly promoting the reconstruction quality and semantic smoothness. We conduct comprehensive experiments on two real-world surgical datasets to demonstrate the superiority of SurgTPGS over state-of-the-art methods, highlighting its potential to revolutionize surgical practices. SurgTPGS paves the way for developing next-generation intelligent surgical systems by enhancing surgical precision and safety. Our code is available at: https://github.com/lastbasket/SurgTPGS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contemporary surgical research and practice, accurately comprehending 3Dsurgical scenes with text-promptable capabilities is particularly crucial forsurgical planning and real-time intra-operative guidance, where preciselyidentifying and interacting with surgical tools and anatomical structures isparamount. However, existing works focus on surgical vision-language model(VLM), 3D reconstruction, and segmentation separately, lacking support forreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, anovel text-promptable Gaussian Splatting method to fill this gap. We introducea 3D semantics feature learning strategy incorporating the Segment Anythingmodel and state-of-the-art vision-language models. We extract the segmentedlanguage features for 3D surgical scene reconstruction, enabling a morein-depth understanding of the complex surgical environment. We also proposesemantic-aware deformation tracking to capture the seamless deformation ofsemantic features, providing a more precise reconstruction for both texture andsemantic features. Furthermore, we present semantic region-aware optimization,which utilizes regional-based semantic information to supervise the training,particularly promoting the reconstruction quality and semantic smoothness. Weconduct comprehensive experiments on two real-world surgical datasets todemonstrate the superiority of SurgTPGS over state-of-the-art methods,highlighting its potential to revolutionize surgical practices. SurgTPGS pavesthe way for developing next-generation intelligent surgical systems byenhancing surgical precision and safety. Our code is available at:https://github.com/lastbasket/SurgTPGS.</description>
      <author>example@mail.com (Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarak I. Hoque, Nicolas Padoy, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.23309v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.23126v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，用于训练多材料、多物体机器人交互中的全局和局部动态特征，无需复杂的场景重建。&lt;h4&gt;背景&lt;/h4&gt;现有的3D世界模型主要限于使用基于粒子的图神经网络模型进行单一材料的动力学模拟，且通常需要耗时的3D场景重建来获取训练数据。&lt;h4&gt;目的&lt;/h4&gt;提高机器人操作的泛化能力，通过捕捉机器人动作条件下的环境演化物理机制。&lt;h4&gt;方法&lt;/h4&gt;ParticleFormer模型使用混合点云重建损失进行训练，能够捕捉刚性、可变形和柔性材料之间的细粒度多物体交互，并直接从真实机器人感知数据中训练，无需复杂的场景重建。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在3D场景预测任务和下游操作任务中表现出色，通过模型预测控制（MPC）策略实现了高动态预测精度和较少的 rollout 错误。此外，该方法在六个模拟和三个真实世界实验中均优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;ParticleFormer模型在多材料、多物体交互场景中具有优越的性能，为机器人操作提供了有效的动力学学习工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Transformer-based point cloud world model called ParticleFormer, which is trained with a hybrid point cloud reconstruction loss to supervise both global and local dynamics features in multi-material, multi-object robot interactions. ParticleFormer captures fine-grained multi-object interactions between rigid, deformable, and flexible materials, trained directly from real-world robot perception data without elaborate scene reconstruction. The model demonstrates its effectiveness in both 3D scene forecasting tasks and downstream manipulation tasks using a Model Predictive Control (MPC) policy. In addition, the method extends existing dynamics learning benchmarks to include diverse multi-material, multi-object interaction scenarios. The method is validated on six simulation and three real-world experiments, where it consistently outperforms leading baselines by achieving superior dynamics prediction accuracy and less rollout error in downstream visuomotor tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D world models (i.e., learning-based 3D dynamics models) offer a promisingapproach to generalizable robotic manipulation by capturing the underlyingphysics of environment evolution conditioned on robot actions. However,existing 3D world models are primarily limited to single-material dynamicsusing a particle-based Graph Neural Network model, and often requiretime-consuming 3D scene reconstruction to obtain 3D particle tracks fortraining. In this work, we present ParticleFormer, a Transformer-based pointcloud world model trained with a hybrid point cloud reconstruction loss,supervising both global and local dynamics features in multi-material,multi-object robot interactions. ParticleFormer captures fine-grainedmulti-object interactions between rigid, deformable, and flexible materials,trained directly from real-world robot perception data without an elaboratescene reconstruction. We demonstrate the model's effectiveness both in 3D sceneforecasting tasks, and in downstream manipulation tasks using a ModelPredictive Control (MPC) policy. In addition, we extend existing dynamicslearning benchmarks to include diverse multi-material, multi-object interactionscenarios. We validate our method on six simulation and three real-worldexperiments, where it consistently outperforms leading baselines by achievingsuperior dynamics prediction accuracy and less rollout error in downstreamvisuomotor tasks. Experimental videos are available athttps://particleformer.github.io/.</description>
      <author>example@mail.com (Suning Huang, Qianzhong Chen, Xiaohan Zhang, Jiankai Sun, Mac Schwager)</author>
      <guid isPermaLink="false">2506.23126v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21541v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mamba-based方法在点云表示学习方面表现出色，但存在破坏3D点邻接关系和未能保留长序列记忆的问题。StruMamba3D通过设计空间状态、改进SSM和使用序列长度自适应策略解决这些问题，并在多个任务中展现出优越性能。&lt;h4&gt;背景&lt;/h4&gt;Mamba-based方法在点云表示学习中的表现以及SSM的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出StruMamba3D方法，以解决Mamba-based方法中存在的问题，提高点云表示学习的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 设计空间状态以保持点间空间依赖性；2. 改进SSM并加入轻量级卷积以促进空间状态之间的交互；3. 引入序列长度自适应策略以减少对输入长度的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;StruMamba3D在多个下游任务中展现出优于其他方法的性能，并在ModelNet40和ScanObjectNN的挑战性数据集上取得了SOTA的准确率。&lt;h4&gt;结论&lt;/h4&gt;StruMamba3D是一个有效的点云表示学习方法，能够提高点云表示学习的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Mamba-based methods have demonstrated impressive performance inpoint cloud representation learning by leveraging State Space Model (SSM) withthe efficient context modeling ability and linear complexity. However, thesemethods still face two key issues that limit the potential of SSM: Destroyingthe adjacency of 3D points during SSM processing and failing to retainlong-sequence memory as the input length increases in downstream tasks. Toaddress these issues, we propose StruMamba3D, a novel paradigm forself-supervised point cloud representation learning. It enjoys several merits.First, we design spatial states and use them as proxies to preserve spatialdependencies among points. Second, we enhance the SSM with a state-wise updatestrategy and incorporate a lightweight convolution to facilitate interactionsbetween spatial states for efficient structure modeling. Third, our methodreduces the sensitivity of pre-trained Mamba-based models to varying inputlengths by introducing a sequence length-adaptive strategy. Experimentalresults across four downstream tasks showcase the superior performance of ourmethod. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40and 92.75% accuracy on the most challenging split of ScanObjectNN withoutvoting strategy.</description>
      <author>example@mail.com (Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21541v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21096v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DALR的多模态句子表示学习方法，旨在解决现有方法在跨模态对齐和模内语义差异方面的挑战，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态句子表示学习方法主要关注图像和文本的粗粒度对齐，但存在跨模态对齐偏差和模内语义差异问题，这些问题会降低句子表示的质量。&lt;h4&gt;目的&lt;/h4&gt;提出DALR方法，以解决跨模态对齐偏差和模内语义差异问题，从而提高句子表示的质量。&lt;h4&gt;方法&lt;/h4&gt;DALR方法包括：1. 提出一致性学习模块，通过软化负样本和利用辅助任务中的语义相似度实现细粒度跨模态对齐；2. 认为句子关系不仅仅是正负标签，而是更复杂的排名结构；3. 通过整合排名蒸馏和全局模内对齐学习来更好地捕捉这些关系。&lt;h4&gt;主要发现&lt;/h4&gt;在语义文本相似度（STS）和迁移（TR）任务上的实验表明，DALR方法在性能上优于现有的最佳基线。&lt;h4&gt;结论&lt;/h4&gt;DALR方法有效地解决了跨模态对齐和模内语义差异问题，提高了句子表示的质量。&lt;h4&gt;翻译&lt;/h4&gt;Previous multimodal sentence representation learning methods have achieved impressive performance. However, most approaches focus on aligning images and text at a coarse level, facing two critical challenges: cross-modal misalignment bias and intra-modal semantic divergence, which significantly degrade sentence representation quality. To address these challenges, we propose DALR (Dual-level Alignment Learning for Multimodal Sentence Representation). For cross-modal alignment, we propose a consistency learning module that softens negative samples and utilizes semantic similarity from an auxiliary task to achieve fine-grained cross-modal alignment. Additionally, we contend that sentence relationships go beyond binary positive-negative labels, exhibiting a more intricate ranking structure. To better capture these relationships and enhance representation quality, we integrate ranking distillation with global intra-modal alignment learning. Comprehensive experiments on semantic textual similarity (STS) and transfer (TR) tasks validate the effectiveness of our approach, consistently demonstrating its superiority over state-of-the-art baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous multimodal sentence representation learning methods have achievedimpressive performance. However, most approaches focus on aligning images andtext at a coarse level, facing two critical challenges:cross-modal misalignmentbias and intra-modal semantic divergence, which significantly degrade sentencerepresentation quality. To address these challenges, we propose DALR(Dual-level Alignment Learning for Multimodal Sentence Representation). Forcross-modal alignment, we propose a consistency learning module that softensnegative samples and utilizes semantic similarity from an auxiliary task toachieve fine-grained cross-modal alignment. Additionally, we contend thatsentence relationships go beyond binary positive-negative labels, exhibiting amore intricate ranking structure. To better capture these relationships andenhance representation quality, we integrate ranking distillation with globalintra-modal alignment learning. Comprehensive experiments on semantic textualsimilarity (STS) and transfer (TR) tasks validate the effectiveness of ourapproach, consistently demonstrating its superiority over state-of-the-artbaselines.</description>
      <author>example@mail.com (Kang He, Yuzhe Ding, Haining Wang, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.21096v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>HyperCLOVA X THINK Technical Report</title>
      <link>http://arxiv.org/abs/2506.22403v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages, 13 figures; fixed figures in the appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了HyperCLOVA X THINK，这是HyperCLOVA X家族中第一个以推理为重点的大型语言模型，在约6000亿高质量的韩语和英语标记上进行预训练，并辅以目标化的合成韩语数据。&lt;h4&gt;背景&lt;/h4&gt;该模型通过一个计算-内存平衡的Peri-LN Transformer实现，使用μP进行扩展，通过三个阶段的课程预训练，将上下文窗口扩展到128K个标记，并通过可验证奖励的强化学习进行后训练。&lt;h4&gt;目的&lt;/h4&gt;HyperCLOVA X THINK旨在提供详细的推理和简洁答案模式，同时保持韩语和英语的双语一致性和翻译质量。&lt;h4&gt;方法&lt;/h4&gt;模型在KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench等以韩国为重点的基准测试中表现出与类似规模的模型相竞争的性能，并且通过修剪和蒸馏技术降低了训练计算量。&lt;h4&gt;主要发现&lt;/h4&gt;HyperCLOVA X THINK在KCSAT STEM基准测试中与GPT-4.1相当或超过，同时训练计算量显著低于同类模型。&lt;h4&gt;结论&lt;/h4&gt;HyperCLOVA X THINK作为一个健壮的基础模型，为韩国AI创新提供了坚实的基础，并且对全球研究社区来说是一个有价值的资源。&lt;h4&gt;翻译&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族中第一个以推理为核心的大型语言模型，它在大约6000亿高质量的韩语和英语标记上进行预训练，并辅以专门合成的韩语数据。该模型采用计算-内存平衡的Peri-LN Transformer架构，通过μP进行扩展，并经过三个阶段的课程预训练，将上下文窗口扩展至128K个标记。通过可验证奖励的强化学习进行后训练，支持详细推理和简洁答案模式。在KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench等以韩国为重点的基准测试中，HyperCLOVA X THINK的表现与同类规模模型相竞争，同时保持了韩语和英语的双语一致性和翻译质量。此外，在KCSAT STEM基准测试中，该模型的表现与GPT-4.1相当或超过，而训练计算量却显著低于同类模型。我们还提出了一种修剪和蒸馏技术，将很快应用于HyperCLOVA X THINK，以创建一个开源且对商业友好的基础模型。总的来说，这些能力使HyperCLOVA X THINK成为韩国AI创新的坚实基础，并为全球研究社区提供了一个有价值的资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce HyperCLOVA X THINK, the first reasoning-focused large languagemodel in the HyperCLOVA X family, pre-trained on roughly $6$ trillionhigh-quality Korean, and English tokens, augmented with targeted syntheticKorean data. It was implemented as a compute-memory-balanced Peri-LNTransformer scaled with $\mu$P, pre-trained through a three-stage curriculumthat expands the context window to $128$K tokens, and post-trained viasupervised fine-tuning with Reinforcement Learning from Verifiable Rewardssupports both detailed rationale and concise-answer modes. It deliverscompetitive performance against similarly sized models on Korea-focusedbenchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, whilepreserving robust bilingual consistency and translation quality. In addition, avision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEMbenchmark, all of which are achieved with substantially lower training computethan existing models of similar sizes. We also present a pruning anddistillation technique that will soon be applied to HyperCLOVA X THINK for anopen-source and business-friendly foundation model. Altogether, thesecapabilities position HyperCLOVA X THINK as a robust foundation for Korean AIinnovation and a valuable resource for the global research community.</description>
      <author>example@mail.com (NAVER Cloud HyperCLOVA X Team)</author>
      <guid isPermaLink="false">2506.22403v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.19288v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对水道环境的自动感知方法，旨在提高无人水面船舶（USVs）对周围环境的理解能力，使其能够做出明智的决策。&lt;h4&gt;背景&lt;/h4&gt;现有的水道感知模型主要关注实例级对象感知范式，如检测和分割，但未能实现水道的全局语义理解，限制了大规模监控和结构化日志生成。&lt;h4&gt;目的&lt;/h4&gt;通过利用视觉-语言模型（VLMs）和图像字幕技术，提高USVs在水道环境中的感知能力。&lt;h4&gt;方法&lt;/h4&gt;提出了WaterCaption，这是第一个专门为水道环境设计的字幕数据集，包含20.2k个图像-文本对，词汇量达180万。同时，提出了Da Yu模型，这是一个边缘部署的多模态大型语言模型，包含一个名为Nano Transformer Adaptor（NTA）的视觉到语言的投影器。&lt;h4&gt;主要发现&lt;/h4&gt;NTA有效地平衡了计算效率和全局以及细粒度局部视觉特征的建模能力，显著提高了模型生成长文本输出的能力。&lt;h4&gt;结论&lt;/h4&gt;Da Yu模型在WaterCaption和其他字幕基准测试中实现了性能和效率的最佳平衡，超越了最先进的模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动化水道环境感知对于使无人水面船舶（USVs）能够理解其周围环境并做出明智的决策至关重要。大多数现有的水道感知模型主要关注实例级对象感知范式（例如，检测、分割）。然而，由于水道环境的复杂性，当前的感知数据集和模型未能实现水道的全局语义理解，限制了大规模监控和结构化日志生成。随着视觉-语言模型（VLMs）的进步，我们利用图像字幕技术引入了WaterCaption，这是第一个专门为水道环境设计的字幕数据集。WaterCaption专注于细粒度、多区域长文本描述，为视觉地理理解和空间场景认知提供了新的研究方向。确切地说，它包括20.2k个图像-文本对数据，词汇量为180万。此外，我们提出了Da Yu，这是一个为USVs设计的边缘部署的多模态大型语言模型，其中我们提出了一种新颖的视觉到语言投影器，称为Nano Transformer Adaptor（NTA）。NTA有效地平衡了计算效率与全局和细粒度局部建模视觉特征的能力，从而显著提高了模型生成长文本输出的能力。Da Yu在性能和效率之间实现了最佳平衡，在WaterCaption和其他几个字幕基准测试中超过了最先进的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated waterway environment perception is crucial for enabling unmannedsurface vessels (USVs) to understand their surroundings and make informeddecisions. Most existing waterway perception models primarily focus oninstance-level object perception paradigms (e.g., detection, segmentation).However, due to the complexity of waterway environments, current perceptiondatasets and models fail to achieve global semantic understanding of waterways,limiting large-scale monitoring and structured log generation. With theadvancement of vision-language models (VLMs), we leverage image captioning tointroduce WaterCaption, the first captioning dataset specifically designed forwaterway environments. WaterCaption focuses on fine-grained, multi-regionlong-text descriptions, providing a new research direction for visualgeo-understanding and spatial scene cognition. Exactly, it includes 20.2kimage-text pair data with 1.8 million vocabulary size. Additionally, we proposeDa Yu, an edge-deployable multi-modal large language model for USVs, where wepropose a novel vision-to-language projector called Nano Transformer Adaptor(NTA). NTA effectively balances computational efficiency with the capacity forboth global and fine-grained local modeling of visual features, therebysignificantly enhancing the model's ability to generate long-form textualoutputs. Da Yu achieves an optimal balance between performance and efficiency,surpassing state-of-the-art models on WaterCaption and several other captioningbenchmarks.</description>
      <author>example@mail.com (Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai, Shanliang Yao, Xuming Hu, Ryan Wen Liu, Yutao Yue, Hui Xiong)</author>
      <guid isPermaLink="false">2506.19288v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention</title>
      <link>http://arxiv.org/abs/2506.23611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为AttentionGS的新框架，用于改进3D Gaussian Splatting技术，以解决其在复杂场景重建和高效渲染方面的优势，但依赖于高质量点云和SfM技术的问题。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting（3DGS）作为一种强大的场景重建和渲染技术，在复杂场景重建和高效渲染方面表现优异，但其依赖于结构从运动（SfM）技术生成的高质量点云，限制了其应用范围。&lt;h4&gt;目的&lt;/h4&gt;为了解决3DGS对高质量点云的依赖和SfM在纹理缺乏或视角受限场景下的不足，提出了一种新的框架AttentionGS，以实现直接从随机初始化中进行3D重建。&lt;h4&gt;方法&lt;/h4&gt;在训练早期，引入几何注意力以快速恢复全局场景结构；随着训练的进行，引入纹理注意力以细化细节并提升渲染质量；采用不透明度加权的梯度来引导高斯密度化，从而改善表面重建。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的实验表明，AttentionGS在点云初始化不可靠的场景中显著优于现有技术，为更稳健和灵活的3D Gaussian Splatting在现实世界应用中铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;AttentionGS框架通过引入注意力机制，有效地解决了3DGS在复杂场景重建和渲染中的局限性，为该技术在现实世界中的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural RadianceFields (NeRF), excelling in complex scene reconstruction and efficientrendering. However, it relies on high-quality point clouds fromStructure-from-Motion (SfM), limiting its applicability. SfM also fails intexture-deficient or constrained-view scenarios, causing severe degradation in3DGS reconstruction. To address this limitation, we propose AttentionGS, anovel framework that eliminates the dependency on high-quality initial pointclouds by leveraging structural attention for direct 3D reconstruction fromrandomly initialization. In the early training stage, we introduce geometricattention to rapidly recover the global scene structure. As trainingprogresses, we incorporate texture attention to refine fine-grained details andenhance rendering quality. Furthermore, we employ opacity-weighted gradients toguide Gaussian densification, leading to improved surface reconstruction.Extensive experiments on multiple benchmark datasets demonstrate thatAttentionGS significantly outperforms state-of-the-art methods, particularly inscenarios where point cloud initialization is unreliable. Our approach pavesthe way for more robust and flexible 3D Gaussian Splatting in real-worldapplications.</description>
      <author>example@mail.com (Ziao Liu, Zhenjia Li, Yifeng Shi, Xiangang Li)</author>
      <guid isPermaLink="false">2506.23611v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
  <item>
      <title>Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data</title>
      <link>http://arxiv.org/abs/2506.24039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript is a draft on arxiv. A final version has been  submitted to the 59th ICPP 2025, DRAI workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为Zenesis的无代码交互平台，用于降低科学图像数据准备难度，并通过轻量级多模态适应技术和人类在环改进以及启发式时间增强选项，实现零样本操作。&lt;h4&gt;背景&lt;/h4&gt;零样本和提示技术利用常见图像进行视觉推理任务，但难以处理珍贵且稀缺的科学图像集。&lt;h4&gt;目的&lt;/h4&gt;Zenesis平台旨在减少科学图像数据准备的障碍。&lt;h4&gt;方法&lt;/h4&gt;Zenesis平台采用轻量级多模态适应技术，实现原始科学数据的零样本操作，并提供了人类在环改进和启发式时间增强选项。&lt;h4&gt;主要发现&lt;/h4&gt;在挑战性的FIB-SEM催化剂负载膜数据上，Zenesis的平均准确率达到0.947，Intersection over Union (IOU)为0.858，Dice分数为0.923，对非晶态催化剂样本；对晶态样本，准确率为0.987，IOU为0.857，Dice分数为0.923。这些结果超过了传统的Otsu阈值方法和Segment Anything Model (SAM)等先进模型。&lt;h4&gt;结论&lt;/h4&gt;Zenesis是一个强大的科学应用工具，尤其是在高质量标注数据集不可用的情况下，能够加速实验成像的准确分析。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a no-code interactive platform named Zenesis to reduce the barriers of data preparation for scientific images, and uses lightweight multi-modal adaptation techniques, human-in-the-loop refinement, and heuristic-based temporal enhancement options to achieve zero-shot operation on raw scientific data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot and prompt-based technologies capitalized on using frequentlyoccurring images to transform visual reasoning tasks, which explains why suchtechnologies struggle with valuable yet scarce scientific image sets. In thiswork, we propose Zenesis, a comprehensive no-code interactive platform designedto minimize barriers posed by data readiness for scientific images. We developlightweight multi-modal adaptation techniques that enable zero-shot operationon raw scientific data, along with human-in-the-loop refinement andheuristic-based temporal enhancement options. We demonstrate the performance ofour approach through comprehensive comparison and validation on challengingFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loadedmembranes. Zenesis significantly outperforms baseline methods, achieving anaverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and aDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, anIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These resultsmark a substantial improvement over traditional methods like Otsu thresholdingand even advanced models like Segment Anything Model (SAM) when used inisolation. Our results demonstrate that Zenesis is a powerful tool forscientific applications, particularly in fields where high-quality annotateddatasets are unavailable, accelerating accurate analysis of experimentalimaging.</description>
      <author>example@mail.com (Shubhabrata Mukherjee, Jack Lang, Obeen Kwon, Iryna Zenyuk, Valerie Brogden, Adam Weber, Daniela Ushizima)</author>
      <guid isPermaLink="false">2506.24039v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</title>
      <link>http://arxiv.org/abs/2506.24124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Ironieser/TimesCLIP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态对比学习框架，用于时间序列预测，该框架能够将原始时间序列数据转化为结构化的视觉和文本表示，并通过对比学习在共享语义空间中对齐这些表示，以提高预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统时间序列预测方法依赖于单模态的数值输入，难以捕捉高级语义模式。现有的基于大语言模型的方法在表示时间序列方面有限，且缺乏人类通常应用的感知直觉。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过多模态对比学习框架来改善时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;将原始时间序列数据转换为视觉和文本表示，并直接从数值序列构建这两种模态。通过对比学习在共享语义空间中对齐这些表示，引入了变量选择模块来识别对多变量预测最有信息量的变量。&lt;h4&gt;主要发现&lt;/h4&gt;在十五个短期和六个长期预测基准测试中，该方法在时间序列预测方面优于强单模态和跨模态基线。&lt;h4&gt;结论&lt;/h4&gt;多模态对齐在提高时间序列预测效果方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;The proposed multimodal contrastive learning framework transforms raw time series into structured visual and textual perspectives, aligns these views in a shared semantic space via contrastive learning, and enhances time series forecasting accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting traditionally relies on unimodal numerical inputs,which often struggle to capture high-level semantic patterns due to their denseand unstructured nature. While recent approaches have explored representingtime series as text using large language models (LLMs), these methods remainlimited by the discrete nature of token sequences and lack the perceptualintuition humans typically apply, such as interpreting visual patterns. In thispaper, we propose a multimodal contrastive learning framework that transformsraw time series into structured visual and textual perspectives. Rather thanusing natural language or real-world images, we construct both modalitiesdirectly from numerical sequences. We then align these views in a sharedsemantic space via contrastive learning, enabling the model to capture richerand more complementary representations. Furthermore, we introduce a variateselection module that leverages the aligned representations to identify themost informative variables for multivariate forecasting. Extensive experimentson fifteen short-term and six long-term forecasting benchmarks demonstrate thatour approach consistently outperforms strong unimodal and cross-modalbaselines, highlighting the effectiveness of multimodal alignment in enhancingtime series forecasting. Code is available at:https://github.com/Ironieser/TimesCLIP.</description>
      <author>example@mail.com (Dong Sixun, Fan Wei, Teresa Wu, Fu Yanjie)</author>
      <guid isPermaLink="false">2506.24124v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.23565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对象中心的辐射场（OcRF）的多视图3D物体检测方法，旨在提高3D几何估计能力，并通过实验证明该方法在nuScenes数据集上取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;当前的多视图3D物体检测方法通常通过深度估计或3D位置编码将2D特征转换为3D空间，但这种转换方式在数据驱动和隐式方面存在局限性，影响了检测性能。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用辐射场在3D重建中的成功，增强检测器对3D几何估计的能力。&lt;h4&gt;方法&lt;/h4&gt;提出对象中心的辐射场（OcRF），通过渲染前景对象作为辅助任务来增强3D体素特征。此外，使用不透明度（渲染的副产品）通过高度感知不透明度注意力（HOA）来增强2D前景BEV特征，其中不同高度级别的注意力图由多个并行网络分别生成。&lt;h4&gt;主要发现&lt;/h4&gt;直接使用辐射场进行3D渲染作为辅助任务时，检测性能会下降，这是由于渲染整个场景时背景的强烈响应导致的。&lt;h4&gt;结论&lt;/h4&gt;OcRFDet在nuScenes测试基准上达到了57.2%的mAP和64.8%的NDS，优于之前的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：Current multi-view 3D object detection methods typically transfer 2D features into 3D space using depth estimation or 3D position encoder, but in a fully data-driven and implicit manner, which limits the detection performance. Inspired by the success of radiance fields on 3D reconstruction, we assume they can be used to enhance the detector's ability of 3D geometry estimation. However, we observe a decline in detection performance, when we directly use them for 3D rendering as an auxiliary task. From our analysis, we find the performance drop is caused by the strong responses on the background when rendering the whole scene. To address this problem, we propose object-centric radiance fields, focusing on modeling foreground objects while discarding background noises. Specifically, we employ Object-centric Radiance Fields (OcRF) to enhance 3D voxel features via an auxiliary task of rendering foreground objects. We further use opacity - the side-product of rendering - to enhance the 2D foreground BEV features via Height-aware Opacity-based Attention (HOA), where attention maps at different height levels are generated separately via multiple networks in parallel. Extensive experiments on the nuScenes validation and test datasets demonstrate that our OcRFDet achieves superior performance, outperforming previous state-of-the-art methods with 57.2% mAP and 64.8% NDS on the nuScenes test benchmark. Code will be available at https://github.com/Mingqj/OcRFDet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current multi-view 3D object detection methods typically transfer 2D featuresinto 3D space using depth estimation or 3D position encoder, but in a fullydata-driven and implicit manner, which limits the detection performance.Inspired by the success of radiance fields on 3D reconstruction, we assume theycan be used to enhance the detector's ability of 3D geometry estimation.However, we observe a decline in detection performance, when we directly usethem for 3D rendering as an auxiliary task. From our analysis, we find theperformance drop is caused by the strong responses on the background whenrendering the whole scene. To address this problem, we propose object-centricradiance fields, focusing on modeling foreground objects while discardingbackground noises. Specifically, we employ Object-centric Radiance Fields(OcRF) to enhance 3D voxel features via an auxiliary task of renderingforeground objects. We further use opacity - the side-product of rendering- toenhance the 2D foreground BEV features via Height-aware Opacity-based Attention(HOA), where attention maps at different height levels are generated separatelyvia multiple networks in parallel. Extensive experiments on the nuScenesvalidation and test datasets demonstrate that our OcRFDet achieves superiorperformance, outperforming previous state-of-the-art methods with 57.2$\%$ mAPand 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available athttps://github.com/Mingqj/OcRFDet.</description>
      <author>example@mail.com (Mingqian Ji, Jian Yang, Shanshan Zhang)</author>
      <guid isPermaLink="false">2506.23565v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Self-Supervised Representation Learning for Symbolic Piano Performance</title>
      <link>http://arxiv.org/abs/2506.23869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ISMIR (2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究基于大量符号独奏钢琴乐谱训练的生成自回归Transformer模型的能力。&lt;h4&gt;背景&lt;/h4&gt;模型在约60,000小时的音乐上进行预训练。&lt;h4&gt;目的&lt;/h4&gt;使用高质量的小样本集微调模型，以生成音乐续作、执行符号分类任务，并通过改进SimCLR框架来产生符号音乐的通用对比MIDI嵌入。&lt;h4&gt;方法&lt;/h4&gt;使用改进的SimCLR框架，在MIR分类基准测试中，冻结的对比模型表示在线性探针实验中达到最先进的结果。&lt;h4&gt;主要发现&lt;/h4&gt;在钢琴续作连贯性评估中，该生成模型优于领先的符号生成技术，并且与专有音频生成模型保持竞争力。&lt;h4&gt;结论&lt;/h4&gt;预训练表示的泛化能力得到证明，通常只需要几百个标记示例就能专门用于下游任务。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了基于大量符号独奏钢琴乐谱训练的生成自回归Transformer模型的能力。在约60,000小时的预训练之后，我们使用一个相对较小的高质量子集来微调模型以生成音乐续作，执行符号分类任务，并通过改进SimCLR框架来生成符号音乐的通用对比MIDI嵌入。在评估钢琴续作连贯性时，我们的生成模型优于领先的符号生成技术，并且与专有音频生成模型保持竞争力。在MIR分类基准测试中，我们的对比模型的冻结表示在线性探针实验中达到了最先进的结果，而直接微调则证明了预训练表示的泛化能力，通常只需要几百个标记示例就能专门用于下游任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the capabilities of generative autoregressive transformer modelstrained on large amounts of symbolic solo-piano transcriptions. After firstpretraining on approximately 60,000 hours of music, we use a comparativelysmaller, high-quality subset, to finetune models to produce musicalcontinuations, perform symbolic classification tasks, and producegeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework tosymbolic music. When evaluating piano continuation coherence, our generativemodel outperforms leading symbolic generation techniques and remainscompetitive with proprietary audio generation models. On MIR classificationbenchmarks, frozen representations from our contrastive model achievestate-of-the-art results in linear probe experiments, while direct finetuningdemonstrates the generalizability of pretrained representations, oftenrequiring only a few hundred labeled examples to specialize to downstreamtasks.</description>
      <author>example@mail.com (Louis Bradshaw, Honglu Fan, Alexander Spangher, Stella Biderman, Simon Colton)</author>
      <guid isPermaLink="false">2506.23869v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum</title>
      <link>http://arxiv.org/abs/2506.23607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PGOV3D的新框架，用于改进开放词汇的3D语义分割，通过两个阶段的训练策略来提高模型的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的开放词汇3D语义分割方法通常通过将多视角图像中的文本对齐特征合并到3D点上对模型进行监督，但这种方法忽略了多视角图像的丰富语义内容和跨视角对应关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决现有方法中多视角图像语义内容未被充分利用的问题，从而提高开放词汇3D语义分割的效果。&lt;h4&gt;方法&lt;/h4&gt;PGOV3D框架采用两个阶段的训练策略：第一阶段在提供密集语义信息但相对简单几何形状的部分场景上预训练模型；第二阶段在完整的场景级点云上微调模型。此外，使用多模态大型语言模型和2D分割基础模型生成开放词汇标签，并引入辅助帧间一致性模块来增强空间理解。&lt;h4&gt;主要发现&lt;/h4&gt;PGOV3D在ScanNet、ScanNet200和S3DIS基准测试中实现了有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;PGOV3D通过引入部分到全局的课程和两个阶段的训练策略，有效地提高了开放词汇3D语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;Existing open-vocabulary 3D semantic segmentation methods typically supervise 3D segmentation models by merging text-aligned features (e.g., CLIP) extracted from multi-view images onto 3D points. However, such approaches treat multi-view images merely as intermediaries for transferring open-vocabulary information, overlooking their rich semantic content and cross-view correspondences, which limits model effectiveness. To address this, we propose PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for improving open-vocabulary 3D semantic segmentation. The key innovation lies in a two-stage training strategy. In the first stage, we pre-train the model on partial scenes that provide dense semantic information but relatively simple geometry. These partial point clouds are derived from multi-view RGB-D inputs via pixel-wise depth projection. To enable open-vocabulary learning, we leverage a multi-modal large language model (MLLM) and a 2D segmentation foundation model to generate open-vocabulary labels for each viewpoint, offering rich and aligned supervision. An auxiliary inter-frame consistency module is introduced to enforce feature consistency across varying viewpoints and enhance spatial understanding. In the second stage, we fine-tune the model on complete scene-level point clouds, which are sparser and structurally more complex. We aggregate the partial vocabularies associated with each scene and generate pseudo labels using the pre-trained model, effectively bridging the semantic gap between dense partial observations and large-scale 3D environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS benchmarks demonstrate that PGOV3D achieves competitive performance in open-vocabulary 3D semantic segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing open-vocabulary 3D semantic segmentation methods typically supervise3D segmentation models by merging text-aligned features (e.g., CLIP) extractedfrom multi-view images onto 3D points. However, such approaches treatmulti-view images merely as intermediaries for transferring open-vocabularyinformation, overlooking their rich semantic content and cross-viewcorrespondences, which limits model effectiveness. To address this, we proposePGOV3D, a novel framework that introduces a Partial-to-Global curriculum forimproving open-vocabulary 3D semantic segmentation. The key innovation lies ina two-stage training strategy. In the first stage, we pre-train the model onpartial scenes that provide dense semantic information but relatively simplegeometry. These partial point clouds are derived from multi-view RGB-D inputsvia pixel-wise depth projection. To enable open-vocabulary learning, weleverage a multi-modal large language model (MLLM) and a 2D segmentationfoundation model to generate open-vocabulary labels for each viewpoint,offering rich and aligned supervision. An auxiliary inter-frame consistencymodule is introduced to enforce feature consistency across varying viewpointsand enhance spatial understanding. In the second stage, we fine-tune the modelon complete scene-level point clouds, which are sparser and structurally morecomplex. We aggregate the partial vocabularies associated with each scene andgenerate pseudo labels using the pre-trained model, effectively bridging thesemantic gap between dense partial observations and large-scale 3Denvironments. Extensive experiments on ScanNet, ScanNet200, and S3DISbenchmarks demonstrate that PGOV3D achieves competitive performance inopen-vocabulary 3D semantic segmentation.</description>
      <author>example@mail.com (Shiqi Zhang, Sha Zhang, Jiajun Deng, Yedong Shen, Mingxiao MA, Yanyong Zhang)</author>
      <guid isPermaLink="false">2506.23607v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Flash-VStream: Efficient Real-Time Understanding for Long Video Streams</title>
      <link>http://arxiv.org/abs/2506.23825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Flash-VStream的效率高的视频语言模型，能够处理极长视频并实时响应用户查询。&lt;h4&gt;背景&lt;/h4&gt;现有多模态大型语言模型在图像和短视频理解方面表现出色，但长视频的理解仍然具有挑战性，因为它们的长上下文特性导致计算和内存开销很大。&lt;h4&gt;目的&lt;/h4&gt;针对长视频理解的问题，提出Flash-VStream模型，以提高处理极长视频和实时响应查询的效率。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含低容量上下文内存和高度量化的增强内存的Flash Memory模块，低容量上下文内存用于聚合长上下文时间信息并建模信息密度分布，高度量化的增强内存则根据此分布检索详细的空间信息。&lt;h4&gt;主要发现&lt;/h4&gt;与现有模型相比，Flash-VStream在推理延迟上实现了显著降低。&lt;h4&gt;结论&lt;/h4&gt;在多个长视频基准测试和综合视频基准测试（如EgoSchema、MLVU、LVBench、MVBench和Video-MME）上进行的广泛实验表明，该方法在性能和效率方面都达到了最先进水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：得益于大型语言模型和跨模态对齐的进步，现有的多模态大型语言模型在图像和短视频理解方面取得了显著的性能。然而，由于长视频的长上下文特性，其理解仍然具有挑战性，这导致计算和内存开销很大。大多数现有工作将长视频视为与短视频相同，这对于现实世界应用来说效率低下，并且难以推广到更长视频。为了解决这些问题，我们提出了Flash-VStream，这是一个高效的视频语言模型，能够处理极长视频并实时响应用户查询。特别是，我们设计了一个Flash Memory模块，包含一个低容量上下文内存来聚合长上下文时间信息并建模信息密度分布，以及一个高容量增强内存来根据这个分布检索详细的空间信息。与现有模型相比，Flash-VStream在推理延迟上实现了显著降低。在长视频基准测试和综合视频基准测试（即EgoSchema、MLVU、LVBench、MVBench和Video-MME）上进行的广泛实验证明了我们方法的最先进性能和卓越效率。代码可在https://github.com/IVGSZ/Flash-VStream上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benefiting from the advances in large language models and cross-modalalignment, existing multimodal large language models have achieved prominentperformance in image and short video understanding. However, the understandingof long videos is still challenging, as their long-context nature results insignificant computational and memory overhead. Most existing work treats longvideos in the same way as short videos, which is inefficient for real-worldapplications and hard to generalize to even longer videos. To address theseissues, we propose Flash-VStream, an efficient video language model capable ofprocessing extremely long videos and responding to user queries in real time.Particularly, we design a Flash Memory module, containing a low-capacitycontext memory to aggregate long-context temporal information and model thedistribution of information density, and a high-capacity augmentation memory toretrieve detailed spatial information based on this distribution. Compared toexisting models, Flash-VStream achieves significant reductions in inferencelatency. Extensive experiments on long video benchmarks and comprehensive videobenchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstratethe state-of-the-art performance and outstanding efficiency of our method. Codeis available at https://github.com/IVGSZ/Flash-VStream.</description>
      <author>example@mail.com (Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Xiaojie Jin)</author>
      <guid isPermaLink="false">2506.23825v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation</title>
      <link>http://arxiv.org/abs/2506.23227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TPAMI. Code: https://github.com/LHDuan/WSegPC&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了室内点云语义分割在场景级标注下的情况，与依赖于稀疏点级标签的方法相比，场景级标注的方法探索较少。为了提高精度，本文提出了一种高质量的伪标签生成框架，通过探索多模态信息和区域-点语义一致性来生成伪标签。&lt;h4&gt;背景&lt;/h4&gt;在缺乏精确的点级标签的情况下，当前的方法首先生成点级伪标签，然后使用这些伪标签来训练分割模型。然而，仅基于场景级标注为每个点生成准确的伪标签是一项相当大的挑战，这会严重影响分割性能。&lt;h4&gt;目的&lt;/h4&gt;为了提高场景级标注下的点云语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法包括：1）一个跨模态特征引导模块，利用2D-3D对应关系将点云特征与相应的2D图像像素对齐，以辅助点云特征学习；2）一个区域-点语义一致性模块，通过从点级语义中派生的区域投票策略生成区域语义，这些语义随后用于指导点级语义预测。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet v2和S3DIS数据集上，与之前的工作相比，本文的方法在场景级标注下取得了显著的改进。此外，综合消融研究验证了本文方法各个组成部分的贡献。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在场景级标注下提高了点云语义分割的准确性，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates indoor point cloud semantic segmentation under scene-level annotation, which is less explored compared to methods relying on sparse point-level labels. In the absence of precise point-level labels, current methods first generate point-level pseudo-labels, which are then used to train segmentation models. However, generating accurate pseudo-labels for each point solely based on scene-level annotations poses a considerable challenge, substantially affecting segmentation performance. Consequently, to enhance accuracy, this paper proposes a high-quality pseudo-label generation framework by exploring contemporary multi-modal information and region-point semantic consistency. Specifically, with a cross-modal feature guidance module, our method utilizes 2D-3D correspondences to align point cloud features with corresponding 2D image pixels, thereby assisting point cloud feature learning. To further alleviate the challenge presented by the scene-level annotation, we introduce a region-point semantic consistency module. It produces regional semantics through a region-voting strategy derived from point-level semantics, which are subsequently employed to guide the point-level semantic predictions. Leveraging the aforementioned modules, our method can rectify inaccurate point-level semantic predictions during training and obtain high-quality pseudo-labels. Significant improvements over previous works on ScanNet v2 and S3DIS datasets under scene-level annotation can demonstrate the effectiveness. Additionally, comprehensive ablation studies validate the contributions of our approach's individual components. The code is available at https://github.com/LHDuan/WSegPC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates indoor point cloud semantic segmentation underscene-level annotation, which is less explored compared to methods relying onsparse point-level labels. In the absence of precise point-level labels,current methods first generate point-level pseudo-labels, which are then usedto train segmentation models. However, generating accurate pseudo-labels foreach point solely based on scene-level annotations poses a considerablechallenge, substantially affecting segmentation performance. Consequently, toenhance accuracy, this paper proposes a high-quality pseudo-label generationframework by exploring contemporary multi-modal information and region-pointsemantic consistency. Specifically, with a cross-modal feature guidance module,our method utilizes 2D-3D correspondences to align point cloud features withcorresponding 2D image pixels, thereby assisting point cloud feature learning.To further alleviate the challenge presented by the scene-level annotation, weintroduce a region-point semantic consistency module. It produces regionalsemantics through a region-voting strategy derived from point-level semantics,which are subsequently employed to guide the point-level semantic predictions.Leveraging the aforementioned modules, our method can rectify inaccuratepoint-level semantic predictions during training and obtain high-qualitypseudo-labels. Significant improvements over previous works on ScanNet v2 andS3DIS datasets under scene-level annotation can demonstrate the effectiveness.Additionally, comprehensive ablation studies validate the contributions of ourapproach's individual components. The code is available athttps://github.com/LHDuan/WSegPC .</description>
      <author>example@mail.com (Lunhao Duan, Shanshan Zhao, Xingxing Weng, Jing Zhang, Gui-Song Xia)</author>
      <guid isPermaLink="false">2506.23227v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>CoMMiT: Co-informed inference of microbiome-metabolome interactions via transfer learning</title>
      <link>http://arxiv.org/abs/2506.24013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CoMMiT的新方法，用于通过迁移学习模型协同推断微生物组和代谢组之间的相互作用，以提高微生物组-代谢组相互作用检测的统计能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多变量模型在检测微生物组-代谢组相互作用时，由于样本量小和生物信号弱，通常统计能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的迁移学习模型CoMMiT，以增强微生物组-代谢组相互作用检测的统计能力。&lt;h4&gt;方法&lt;/h4&gt;CoMMiT利用同一队列内代谢物之间的相似性，减少了由于测序平台和生物信息学流程差异导致的负迁移风险。它采用灵活的假设，即辅助代谢物集体对目标代谢物具有信息性，而无需每个辅助代谢物都是信息性的。CoMMiT使用数据驱动方法选择最优辅助代谢物集，并通过去偏框架进行有效计算p值。&lt;h4&gt;主要发现&lt;/h4&gt;将CoMMiT应用于一项喂养研究，揭示了在低血糖负荷饮食下，微生物组和代谢组之间存在生物学上有意义的相互作用，证明了饮食与宿主之间的联系。&lt;h4&gt;结论&lt;/h4&gt;CoMMiT是一种有效的工具，可以增强微生物组-代谢组相互作用检测的统计能力，有助于揭示饮食与宿主健康之间的联系。&lt;h4&gt;翻译&lt;/h4&gt;Recent multi-omic microbiome studies enable integrative analysis of microbes and metabolites, uncovering their associations with various host conditions. Such analyses require multivariate models capable of accounting for the complex correlation structures between microbes and metabolites. However, existing multivariate models often suffer from low statistical power for detecting microbiome-metabolome interactions due to small sample sizes and weak biological signals. To address these challenges, we introduce CoMMiT, Co-informed inference of Microbiome-Metabolome Interactions via novel Transfer learning models. Unlike conventional transfer-learning methods that borrow information from external datasets, CoMMiT leverages similarities across metabolites within a single cohort, reducing the risk of negative transfer often caused by differences in sequencing platforms and bioinformatic pipelines across studies. CoMMiT operates under the flexible assumption that auxiliary metabolites are collectively informative for the target metabolite, without requiring individual auxiliary metabolites to be informative. CoMMiT uses a novel data-driven approach to selecting the optimal set of auxiliary metabolites. Using this optimal set, CoMMiT employs a de-biasing framework to enable efficient calculation of p-values, facilitating the identification of statistically significant microbiome-metabolome interactions. Applying CoMMiT to a feeding study reveals biologically meaningful microbiome-metabolome interactions under a low glycemic load diet, demonstrating the diet-host link through gut metabolism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent multi-omic microbiome studies enable integrative analysis of microbesand metabolites, uncovering their associations with various host conditions.Such analyses require multivariate models capable of accounting for the complexcorrelation structures between microbes and metabolites. However, existingmultivariate models often suffer from low statistical power for detectingmicrobiome-metabolome interactions due to small sample sizes and weakbiological signals. To address these challenges, we introduce CoMMiT,Co-informed inference of Microbiome-Metabolome Interactions via novel Transferlearning models. Unlike conventional transfer-learning methods that borrowinformation from external datasets, CoMMiT leverages similarities acrossmetabolites within a single cohort, reducing the risk of negative transferoften caused by differences in sequencing platforms and bioinformatic pipelinesacross studies. CoMMiT operates under the flexible assumption that auxiliarymetabolites are collectively informative for the target metabolite, withoutrequiring individual auxiliary metabolites to be informative. CoMMiT uses anovel data-driven approach to selecting the optimal set of auxiliarymetabolites. Using this optimal set, CoMMiT employs a de-biasing framework toenable efficient calculation of p-values, facilitating the identification ofstatistically significant microbiome-metabolome interactions. Applying CoMMiTto a feeding study reveals biologically meaningful microbiome-metabolomeinteractions under a low glycemic load diet, demonstrating the diet-host linkthrough gut metabolism.</description>
      <author>example@mail.com (Leiyue Li, Chenglong Ye, Tim Randolph, Meredith Hullar, Johanna Lampe, Marian Neuhouser, Daniel Raftery, Yue Wang)</author>
      <guid isPermaLink="false">2506.24013v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition</title>
      <link>http://arxiv.org/abs/2506.23283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MoMa的效率适配框架，通过整合Mamba的选择性状态空间建模到图像基础模型（IFMs）中，实现了对视频的全面时空建模。&lt;h4&gt;背景&lt;/h4&gt;视频理解是一个复杂的挑战，需要有效建模时空动态。尽管图像基础模型在图像理解中取得了成功，但大多数方法倾向于分别处理时空信息，可能无法捕捉视频动态的全部复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出MoMa框架，以实现高效的视频理解。&lt;h4&gt;方法&lt;/h4&gt;MoMa通过将SeqMod操作注入到预训练的IFMs中，而不会破坏其原始特征，从而实现时空信息的注入。SeqMod被整合到Divide-and-Modulate架构中，以增强视频理解并保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在多个视频基准测试上的广泛实验表明，MoMa在降低计算成本的同时，实现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;MoMa框架有效地提升了视频理解能力，为视频处理提供了一种高效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding is a complex challenge that requires effective modelingof spatial-temporal dynamics. With the success of image foundation models(IFMs) in image understanding, recent approaches have exploredparameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, mostof these methods tend to process spatial and temporal information separately,which may fail to capture the full intricacy of video dynamics. In this paper,we propose MoMa, an efficient adapter framework that achieves fullspatial-temporal modeling by integrating Mamba's selective state space modelinginto IFMs. We propose a novel SeqMod operation to inject spatial-temporalinformation into pre-trained IFMs, without disrupting their original features.By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhancesvideo understanding while maintaining computational efficiency. Extensiveexperiments on multiple video benchmarks demonstrate the effectiveness of MoMa,achieving superior performance with reduced computational cost.</description>
      <author>example@mail.com (Yuhuan Yang, Chaofan Ma, Zhenjie Mao, Jiangchao Yao, Ya Zhang, Yanfeng Wang)</author>
      <guid isPermaLink="false">2506.23283v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Ella: Embodied Social Agents with Lifelong Memory</title>
      <link>http://arxiv.org/abs/2506.24019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Ella，一个能够在3D开放世界中终身学习的社会智能体，它通过日常视觉观察和社会互动积累经验并获取知识。&lt;h4&gt;背景&lt;/h4&gt;Ella拥有一个结构化的、长期的多模态记忆系统，该系统有效存储、更新和检索信息，包括以名称为中心的语义记忆和时空事件记忆。&lt;h4&gt;目的&lt;/h4&gt;通过将终身记忆系统与基础模型集成，Ella能够检索相关信息进行决策，规划日常活动，建立社交关系，并在开放世界中自主进化。&lt;h4&gt;方法&lt;/h4&gt;在动态的3D开放世界中进行了能力评估，15个智能体参与社会活动数日，并使用一系列未见过的控制评估进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Ella能够通过观察和社会互动有效地学习，并能与其他智能体良好地影响、领导和合作以实现目标。&lt;h4&gt;结论&lt;/h4&gt;研究发现，将结构化记忆系统与基础模型结合，对于提高具身智能具有变革性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Ella, an embodied social agent capable of lifelong learning within a community in a 3D open world, where agents accumulate experiences and acquire knowledge through everyday visual observations and social interactions. At the core of Ella's capabilities is a structured, long-term multimodal memory system that stores, updates, and retrieves information effectively. It consists of a name-centric semantic memory for organizing acquired knowledge and a spatiotemporal episodic memory for capturing multimodal experiences. By integrating this lifelong memory system with foundation models, Ella retrieves relevant information for decision-making, plans daily activities, builds social relationships, and evolves autonomously while coexisting with other intelligent beings in the open world. We conduct capability-oriented evaluations in a dynamic 3D open world where 15 agents engage in social activities for days and are assessed with a suite of unseen controlled evaluations. Experimental results show that Ella can influence, lead, and cooperate with other agents well to achieve goals, showcasing its ability to learn effectively through observation and social interaction. Our findings highlight the transformative potential of combining structured memory systems with foundation models for advancing embodied intelligence. More videos can be found at https://umass-embodied-agi.github.io/Ella/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Ella, an embodied social agent capable of lifelong learningwithin a community in a 3D open world, where agents accumulate experiences andacquire knowledge through everyday visual observations and social interactions.At the core of Ella's capabilities is a structured, long-term multimodal memorysystem that stores, updates, and retrieves information effectively. It consistsof a name-centric semantic memory for organizing acquired knowledge and aspatiotemporal episodic memory for capturing multimodal experiences. Byintegrating this lifelong memory system with foundation models, Ella retrievesrelevant information for decision-making, plans daily activities, builds socialrelationships, and evolves autonomously while coexisting with other intelligentbeings in the open world. We conduct capability-oriented evaluations in adynamic 3D open world where 15 agents engage in social activities for days andare assessed with a suite of unseen controlled evaluations. Experimentalresults show that Ella can influence, lead, and cooperate with other agentswell to achieve goals, showcasing its ability to learn effectively throughobservation and social interaction. Our findings highlight the transformativepotential of combining structured memory systems with foundation models foradvancing embodied intelligence. More videos can be found athttps://umass-embodied-agi.github.io/Ella/.</description>
      <author>example@mail.com (Hongxin Zhang, Zheyuan Zhang, Zeyuan Wang, Zunzhe Zhang, Lixing Fang, Qinhong Zhou, Chuang Gan)</author>
      <guid isPermaLink="false">2506.24019v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2506.23426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的目标检测方法，用于自动驾驶汽车识别周围环境并做出驾驶决策，以提高其在动态环境中的决策有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的目标检测方法将对象分类为已知类别，这限制了自动驾驶汽车检测和适当响应分布外（Out-of-Distribution，OOD）对象的能力，存在安全隐患。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于对象有害性确定的目标检测方法，以增强自动驾驶汽车在动态环境中的决策有效性。&lt;h4&gt;方法&lt;/h4&gt;该方法根据对象相对于自动驾驶汽车的位置和轨迹，将对象识别为“有害”或“无害”，从而实现有效检测和分类。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够有效检测分布外对象，评估其有害性，并据此进行分类。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的模型在动态环境中增强了自动驾驶汽车的决策有效性，有助于提高驾驶安全。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel object detection method for autonomous vehicles to recognize their surroundings and make driving decisions, thereby enhancing their decision-making effectiveness in dynamic environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous vehicles (AVs) use object detection models to recognize theirsurroundings and make driving decisions accordingly. Conventional objectdetection approaches classify objects into known classes, which limits the AV'sability to detect and appropriately respond to Out-of-Distribution (OOD)objects. This problem is a significant safety concern since the AV may fail todetect objects or misclassify them, which can potentially lead to hazardoussituations such as accidents. Consequently, we propose a novel object detectionapproach that shifts the emphasis from conventional class-based classificationto object harmfulness determination. Instead of object detection by theirspecific class, our method identifies them as either 'harmful' or 'harmless'based on whether they pose a danger to the AV. This is done based on the objectposition relative to the AV and its trajectory. With this metric, our model caneffectively detect previously unseen objects to enable the AV to make saferreal-time decisions. Our results demonstrate that the proposed modeleffectively detects OOD objects, evaluates their harmfulness, and classifiesthem accordingly, thus enhancing the AV decision-making effectiveness indynamic environments.</description>
      <author>example@mail.com (Menna Taha, Aya Ahmed, Mohammed Karmoose, Yasser Gadallah)</author>
      <guid isPermaLink="false">2506.23426v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching</title>
      <link>http://arxiv.org/abs/2506.23502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的CLIP模型，通过引入大型语言模型（LLMs）生成的动作相关外部知识，使CLIP具备对动作的精细理解能力，从而在图像文本匹配任务中取得更好的表现。&lt;h4&gt;背景&lt;/h4&gt;大型视觉语言预训练模型如CLIP在图像文本匹配任务中取得了显著成果，但其在理解物体属性和空间关系等细节方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;赋予CLIP对动作的精细理解能力，以描述物体状态或关系。&lt;h4&gt;方法&lt;/h4&gt;设计了一种动作三元组提示和动作状态提示，利用LLMs中隐含的复合语义知识和状态相关因果知识。同时，提出了一个自适应交互模块，基于动作感知提示知识聚合注意力视觉特征，以建立具有判别性和动作感知的视觉表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在两个基准数据集上有效提升了图像文本匹配任务的性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入LLMs生成的动作相关外部知识，CLIP模型在动作理解方面取得了显著进步，为图像文本匹配任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by large-scale contrastive vision-language pre-trained models such asCLIP, recent advancements in the image-text matching task have achievedremarkable success in representation learning. Due to image-levelvisual-language alignment, CLIP falls short in understanding fine-graineddetails such as object attributes and spatial relationships between objects.Recent efforts have attempted to compel CLIP to acquire structured visualrepresentations by introducing prompt learning to achieve object-levelalignment. While achieving promising results, they still lack the capability toperceive actions, which are crucial for describing the states or relationshipsbetween objects. Therefore, we propose to endow CLIP with fine-grainedaction-level understanding by introducing an LLM-enhanced action-awaremulti-modal prompt-tuning method, incorporating the action-related externalknowledge generated by large language models (LLMs). Specifically, we design anaction triplet prompt and an action state prompt to exploit compositionalsemantic knowledge and state-related causal knowledge implicitly stored inLLMs. Subsequently, we propose an adaptive interaction module to aggregateattentive visual features conditioned on action-aware prompted knowledge forestablishing discriminative and action-aware visual representations, whichfurther improves the performance. Comprehensive experimental results on twobenchmark datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Mengxiao Tian, Xinxiao Wu, Shuo Yang)</author>
      <guid isPermaLink="false">2506.23502v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.23827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our paper has been accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为NH2ST的框架，用于从病理全切片图像中预测基因表达，旨在解决传统方法在高成本和复杂度上的限制。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学（ST）为组织微环境提供了关键信息，但因其高昂的成本和复杂性受到限制。预测基因表达从病理全切片图像（WSI）成为了一个替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，用于整合空间上下文和病理及基因模态，以提高基因表达预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;NH2ST模型包含查询分支和邻域分支，处理成对的靶点图像和基因数据及其邻近区域。使用交叉注意力和对比学习来捕捉内在关联，确保病理和基因表达之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在六个数据集上的实验表明，NH2ST模型在PCC指标上优于现有方法，实现了超过20%的提升。&lt;h4&gt;结论&lt;/h4&gt;NH2ST框架有效地解决了传统方法在预测基因表达方面的不足，为病理图像分析提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Spatial transcriptomics (ST) provides crucial insights into tissuemicro-environments, but is limited to its high cost and complexity. As analternative, predicting gene expression from pathology whole slide images (WSI)is gaining increasing attention. However, existing methods typically rely onsingle patches or a single pathology modality, neglecting the complex spatialand molecular interactions between target and neighboring information (e.g.,gene co-expression). This leads to a failure in establishing connections amongadjacent regions and capturing intricate cross-modal relationships. To addressthese issues, we propose NH2ST, a framework that integrates spatial context andboth pathology and gene modalities for gene expression prediction. Our modelcomprises a query branch and a neighbor branch to process paired target patchand gene data and their neighboring regions, where cross-attention andcontrastive learning are employed to capture intrinsic associations and ensurealignments between pathology and gene expression. Extensive experiments on sixdatasets demonstrate that our model consistently outperforms existing methods,achieving over 20% in PCC metrics. Codes are available athttps://github.com/MCPathology/NH2ST&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) provides crucial insights into tissuemicro-environments, but is limited to its high cost and complexity. As analternative, predicting gene expression from pathology whole slide images (WSI)is gaining increasing attention. However, existing methods typically rely onsingle patches or a single pathology modality, neglecting the complex spatialand molecular interactions between target and neighboring information (e.g.,gene co-expression). This leads to a failure in establishing connections amongadjacent regions and capturing intricate cross-modal relationships. To addressthese issues, we propose NH2ST, a framework that integrates spatial context andboth pathology and gene modalities for gene expression prediction. Our modelcomprises a query branch and a neighbor branch to process paired target patchand gene data and their neighboring regions, where cross-attention andcontrastive learning are employed to capture intrinsic associations and ensurealignments between pathology and gene expression. Extensive experiments on sixdatasets demonstrate that our model consistently outperforms existing methods,achieving over 20% in PCC metrics. Codes are available athttps://github.com/MCPathology/NH2ST</description>
      <author>example@mail.com (Mingcheng Qu, Yuncong Wu, Donglin Di, Yue Gao, Tonghua Su, Yang Song, Lei Fan)</author>
      <guid isPermaLink="false">2506.23827v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion</title>
      <link>http://arxiv.org/abs/2506.23606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成模型的激光雷达点云合成方法，旨在通过增加训练数据集的多样性和丰富性来增强深度学习管道，特别是在现实世界数据稀缺或缺乏多样性的情况下。&lt;h4&gt;背景&lt;/h4&gt;现有的激光雷达点云生成方法主要关注无条件生成，而忽略了其在现实世界应用中的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SG-LDM的语义引导激光雷达扩散模型，通过潜在对齐实现鲁棒的语义到激光雷达的合成。&lt;h4&gt;方法&lt;/h4&gt;SG-LDM直接在原生激光雷达空间操作，并利用显式的语义条件，实现了基于语义标签的高保真激光雷达点云生成。此外，还提出了基于SG-LDM的扩散模型，用于跨域翻译，作为一种域适应策略来提高下游感知性能。&lt;h4&gt;主要发现&lt;/h4&gt;系统实验表明，SG-LDM在生成高保真激光雷达点云方面优于现有的激光雷达扩散模型，并且所提出的激光雷达翻译框架进一步提高了下游激光雷达分割任务中的数据增强性能。&lt;h4&gt;结论&lt;/h4&gt;SG-LDM为激光雷达点云合成提供了一种新的解决方案，有助于提高深度学习模型的性能，尤其是在数据稀缺或多样性的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lidar point cloud synthesis based on generative models offers a promisingsolution to augment deep learning pipelines, particularly when real-world datais scarce or lacks diversity. By enabling flexible object manipulation, thissynthesis approach can significantly enrich training datasets and enhancediscriminative models. However, existing methods focus on unconditional lidarpoint cloud generation, overlooking their potential for real-worldapplications. In this paper, we propose SG-LDM, a Semantic-Guided LidarDiffusion Model that employs latent alignment to enable robustsemantic-to-lidar synthesis. By directly operating in the native lidar spaceand leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-artperformance in generating high-fidelity lidar point clouds guided by semanticlabels. Moreover, we propose the first diffusion-based lidar translationframework based on SG-LDM, which enables cross-domain translation as a domainadaptation strategy to enhance downstream perception performance. Systematicexperiments demonstrate that SG-LDM significantly outperforms existing lidardiffusion models and the proposed lidar translation framework further improvesdata augmentation performance in the downstream lidar segmentation task.</description>
      <author>example@mail.com (Zhengkang Xiang, Zizhao Li, Amir Khodabandeh, Kourosh Khoshelham)</author>
      <guid isPermaLink="false">2506.23606v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)</title>
      <link>http://arxiv.org/abs/2506.23784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用图神经网络（GNN）对词方程进行排序的问题，以提高词方程求解器的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的Nielsen变换方法在解决词方程时，求解器的性能很大程度上取决于方程处理的顺序。&lt;h4&gt;目的&lt;/h4&gt;通过使用GNN对词方程进行排序，以改善求解器在解决词方程时的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的基于图的词方程表示方法，以保留连接词之间的全局信息，使GNN在排序时具有整体视角。针对连接词数量的可变性，提出了三种将多分类任务适应到方程排序问题的方法。GNN的训练使用词方程的最小不可满足子集（MUSes）进行。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的字符串求解器相比，新框架在基准测试中解决了更多的问题，其中每个变量在每个方程中最多出现一次。&lt;h4&gt;结论&lt;/h4&gt;GNN在词方程排序中的应用能够显著提高求解器的性能，特别是在处理变量数量可变的复杂方程时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nielsen transformation is a standard approach for solving word equations: byrepeatedly splitting equations and applying simplification steps, equations arerewritten until a solution is reached. When solving a conjunction of wordequations in this way, the performance of the solver will depend considerablyon the order in which equations are processed. In this work, the use of GraphNeural Networks (GNNs) for ranking word equations before and during the solvingprocess is explored. For this, a novel graph-based representation for wordequations is presented, preserving global information across conjuncts,enabling the GNN to have a holistic view during ranking. To handle the variablenumber of conjuncts, three approaches to adapt a multi-classification task tothe problem of ranking equations are proposed. The training of the GNN is donewith the help of minimum unsatisfiable subsets (MUSes) of word equations. Theexperimental results show that, compared to state-of-the-art string solvers,the new framework solves more problems in benchmarks where each variableappears at most once in each equation.</description>
      <author>example@mail.com (Parosh Aziz Abdulla, Mohamed Faouzi Atig, Julie Cailler, Chencheng Liang, Philipp Rümmer)</author>
      <guid isPermaLink="false">2506.23784v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering</title>
      <link>http://arxiv.org/abs/2506.23329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://ir3d-bench.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为IR3D-Bench的基准测试，用于挑战视觉语言模型（VLMs）在理解场景方面的能力，通过主动创建而非被动识别来展示理解能力。&lt;h4&gt;背景&lt;/h4&gt;尽管VLMs在描述性任务上表现出色，但它们是否真正理解通过视觉观察到的场景尚不确定。&lt;h4&gt;目的&lt;/h4&gt;提出IR3D-Bench，旨在通过挑战VLMs的主动创造能力来检验它们对场景的理解，而不是仅仅通过被动识别。&lt;h4&gt;方法&lt;/h4&gt;IR3D-Bench基于分析-综合范式，要求视觉语言代理（VLAs）通过使用编程和渲染工具来重新创建输入图像的底层3D结构，通过工具使用实现代理逆向渲染。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs在视觉精度方面存在局限性，特别是在基本工具使用方面表现良好，但在更高级的理解任务上表现不佳。&lt;h4&gt;结论&lt;/h4&gt;IR3D-Bench包括数据集和评估协议的发布，旨在促进工具使用型VLAs的系统研究和开发，以实现通过创建来理解场景。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This 'understanding-by-creating' approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) excel at descriptive tasks, but whether theytruly understand scenes from visual observations remains uncertain. Weintroduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understandingthrough active creation rather than passive recognition. Grounded in theanalysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)with actively using programming and rendering tools to recreate the underlying3D structure of an input image, achieving agentic inverse rendering throughtool use. This "understanding-by-creating" approach probes the tool-usinggenerative capacity of VLAs, moving beyond the descriptive or conversationalcapacity measured by traditional scene understanding benchmarks. We provide acomprehensive suite of metrics to evaluate geometric accuracy, spatialrelations, appearance attributes, and overall plausibility. Initial experimentson agentic inverse rendering powered by various state-of-the-art VLMs highlightcurrent limitations, particularly in visual precision rather than basic toolusage. IR3D-Bench, including data and evaluation protocols, is released tofacilitate systematic study and development of tool-using VLAs towards genuinescene understanding by creating.</description>
      <author>example@mail.com (Parker Liu, Chenxin Li, Zhengxin Li, Yipeng Wu, Wuyang Li, Zhiqin Yang, Zhenyuan Zhang, Yunlong Lin, Sirui Han, Brandon Y. Feng)</author>
      <guid isPermaLink="false">2506.23329v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Deconstructing the Origins of Interfacial Catalysis: Why Electric Fields are Inseparable from Solvation</title>
      <link>http://arxiv.org/abs/2506.23988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近十年，许多实验表明，当某些化学反应从常规水相条件转移到微滴环境中时，其反应速率会显著增加。然而，这种现象的微观基础尚未明确，且存在广泛争议。&lt;h4&gt;背景&lt;/h4&gt;该研究背景是关于水-气界面处电场和溶剂化作用对化学反应速率的影响。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过模拟和实验方法，对微滴环境中化学反应速率增加的微观机制进行深入研究。&lt;h4&gt;方法&lt;/h4&gt;研究使用了经典分子动力学模拟、化学物理溶剂化理论，以及无监督学习（信息平衡方法）等手段。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，水表面的电场与常规水条件下的电场无显著差异，且电场波动在约10 ps的时间尺度上解相关，其活化较慢化学反应的作用尚无定论。此外，电场在苯酚羟基上的作用主要由苯酚的水合作用决定，包括邻近水分子的接近度和方向。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，对电场在增强空气-水界面化学反应活性中的作用的关注可能夸大了其实际重要性。&lt;h4&gt;翻译&lt;/h4&gt;In the last decade, there has been a surge of experiments showing that certain chemical reactions undergo an enormous boost when taken from bulk aqueous conditions to microdroplet environments. The microscopic basis of this phenomenon remains elusive and continues to be widely debated. One of the key driving forces invoked are the specific properties of the air-water interface including the presence of large electric fields and distinct solvation at the surface. Here, using a combination of classical molecular dynamics simulations, the chemical physics of solvation, and unsupervised learning approaches, we place these assumptions under close scrutiny. Using phenol as a model system, we demonstrate that the electric field at the surface of water is not anomalous or unique compared to bulk water conditions. Furthermore, the electric field fluctuations de-correlate on a timescale of ~10 ps implying that their role in activating much slower chemical reactions remains inconclusive. We deploy a recently developed unsupervised learning approach, dubbed information balance, which detects in an agnostic fashion the relationship between the electric field and solvation collective variables. It turns out that the electric field on the hydroxyl group of the phenol is mostly determined by phenol hydration including the proximity and orientation of nearby water molecules. We caution that the growing attention of the role that electric fields have garnered in enhancing chemical reactivity at the air-water interface, may not reflect their actual importance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the last decade, there has been a surge of experiments showing thatcertain chemical reactions undergo an enormous boost when taken from bulkaqueous conditions to microdroplet environments. The microscopic basis of thisphenomenon remains elusive and continues to be widely debated. One of the keydriving forces invoked are the specific properties of the air-water interfaceincluding the presence of large electric fields and distinct solvation at thesurface. Here, using a combination of classical molecular dynamics simulations,the chemical physics of solvation, and unsupervised learning approaches, weplace these assumptions under close scrutiny. Using phenol as a model system,we demonstrate that the electric field at the surface of water is not anomalousor unique compared to bulk water conditions. Furthermore, the electric fieldfluctuations de-correlate on a timescale of ~10 ps implying that their role inactivating much slower chemical reactions remains inconclusive. We deploy arecently developed unsupervised learning approach, dubbed information balance,which detects in an agnostic fashion the relationship between the electricfield and solvation collective variables. It turns out that the electric fieldon the hydroxyl group of the phenol is mostly determined by phenol hydrationincluding the proximity and orientation of nearby water molecules. We cautionthat the growing attention of the role that electric fields have garnered inenhancing chemical reactivity at the air-water interface, may not reflect theiractual importance.</description>
      <author>example@mail.com (Solana Di Pino, Debarshi Banerjee, Marta Monti, Gonzalo Diaz Miron, Giuseppe Cassone, Ali Hassanali)</author>
      <guid isPermaLink="false">2506.23988v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment</title>
      <link>http://arxiv.org/abs/2506.22967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint manuscript - Project page:  https://github.com/aghdamamir/act-align&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对零样本细粒度视频分类问题进行研究，提出了一种名为ActAlign的零样本框架，通过序列对齐的方法实现视频分类，并在ActionAtlas基准测试中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;在零样本细粒度视频分类中，没有未见过类别的时间标签或视频示例。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来有效区分细粒度动作类别。&lt;h4&gt;方法&lt;/h4&gt;ActAlign框架通过使用大型语言模型生成有序子动作序列，并使用动态时间规整（DTW）在共享嵌入空间中对齐视频帧来实现视频分类。&lt;h4&gt;主要发现&lt;/h4&gt;ActAlign在ActionAtlas基准测试中实现了30.5%的准确率，优于亿参数的视频语言模型，同时参数量减少了约8倍。&lt;h4&gt;结论&lt;/h4&gt;结构化语言先验与经典对齐技术的结合，为视觉语言模型在细粒度视频理解中的开放式识别潜力提供了一种可扩展和通用的方法。&lt;h4&gt;翻译&lt;/h4&gt;We address the task of zero-shot fine-grained video classification, where no video examples or temporal annotations are available for unseen action classes. While contrastive vision-language models such as SigLIP demonstrate strong open-set recognition via mean-pooled image-text similarity, they fail to capture the temporal structure critical for distinguishing fine-grained activities. We introduce ActAlign, a zero-shot framework that formulates video classification as sequence alignment. For each class, a large language model generates an ordered sub-action sequence, which is aligned with video frames using Dynamic Time Warping (DTW) in a shared embedding space. Without any video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the extremely challenging ActionAtlas benchmark, where human accuracy is only 61.6%. ActAlign outperforms billion-parameter video-language models while using approximately 8x less parameters. These results demonstrate that structured language priors, combined with classical alignment techniques, offer a scalable and general approach to unlocking the open-set recognition potential of vision-language models for fine-grained video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the task of zero-shot fine-grained video classification, where novideo examples or temporal annotations are available for unseen action classes.While contrastive vision-language models such as SigLIP demonstrate strongopen-set recognition via mean-pooled image-text similarity, they fail tocapture the temporal structure critical for distinguishing fine-grainedactivities. We introduce ActAlign, a zero-shot framework that formulates videoclassification as sequence alignment. For each class, a large language modelgenerates an ordered sub-action sequence, which is aligned with video framesusing Dynamic Time Warping (DTW) in a shared embedding space. Without anyvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on theextremely challenging ActionAtlas benchmark, where human accuracy is only61.6%. ActAlign outperforms billion-parameter video-language models while usingapproximately 8x less parameters. These results demonstrate that structuredlanguage priors, combined with classical alignment techniques, offer a scalableand general approach to unlocking the open-set recognition potential ofvision-language models for fine-grained video understanding.</description>
      <author>example@mail.com (Amir Aghdam, Vincent Tao Hu)</author>
      <guid isPermaLink="false">2506.22967v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation</title>
      <link>http://arxiv.org/abs/2506.23724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨模型知识对Test-time Adaptation（TTA）过程的影响，并提出了一种名为COCA的跨模型协同学习框架，通过共适应和自适应策略提升TTA的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的TTA方法主要关注单模型适应，而忽略了跨模型知识的作用。&lt;h4&gt;目的&lt;/h4&gt;探究跨模型知识如何影响TTA过程，并提出新的框架来提升TTA的性能。&lt;h4&gt;方法&lt;/h4&gt;提出COCA框架，包括共适应和自适应策略，共适应通过整合其他模型的互补知识，自适应通过无监督学习增强每个模型的独特优势。&lt;h4&gt;主要发现&lt;/h4&gt;在TTA的无监督在线设置中，不同规模的模型可以提供互补且自信的知识，例如小模型MobileViT可以有效地指导大模型ViT-Base。&lt;h4&gt;结论&lt;/h4&gt;COCA框架通过跨模型协同学习显著提升了不同规模模型在TTA任务上的性能，如ResNets、ViTs和Mobile-ViTs，例如Mobile-ViT的指导使ViT-Base在ImageNet-C上的平均适应准确率从51.7%提升到64.5%。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Test-time Adaptation (TTA)通过在线无监督学习适应测试域数据，并具有潜在的域偏移，从而获得令人印象深刻的性能。然而，到目前为止，现有的TTA方法主要关注单模型适应。在这项工作中，我们探讨了有趣的问题：跨模型知识如何影响TTA过程？我们的发现表明，在TTA的无监督在线设置中，每个模型都可以向其他模型提供互补且自信的知识，即使模型规模存在很大差异。例如，小模型MobileViT（10.6M参数）可以有效地指导大模型ViT-Base（86.6M参数）。鉴于这一点，我们提出了COCA，一个用于TTA的跨模型协同学习框架，它主要由两个主要策略组成。1）共适应在TTA过程中自适应地整合来自其他模型的互补知识，减少单个模型的偏差。2）自适应通过无监督学习增强每个模型的独特优势，使模型能够对目标域进行多样化适应。广泛的实验表明，COCA可以通过跨模型协同学习显著提升现有SOTAs，在具有各种规模（包括ResNets、ViTs和Mobile-ViTs）的模型上。例如，通过Mobile-ViT的指导，COCA将ViT-Base在ImageNet-C上的平均适应准确率从51.7%提高到64.5%。代码在https://github.com/ycarobot/COCA上公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Test-time Adaptation (TTA) adapts a given model to testing domain data withpotential domain shifts through online unsupervised learning, yieldingimpressive performance. However, to date, existing TTA methods primarily focuson single-model adaptation. In this work, we investigate an intriguingquestion: how does cross-model knowledge influence the TTA process? Ourfindings reveal that, in TTA's unsupervised online setting, each model canprovide complementary, confident knowledge to the others, even when there aresubstantial differences in model size. For instance, a smaller model likeMobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base(86.6M parameters). In light of this, we propose COCA, a Cross-ModelCo-Learning framework for TTA, which mainly consists of two main strategies. 1)Co-adaptation adaptively integrates complementary knowledge from other modelsthroughout the TTA process, reducing individual model biases. 2)Self-adaptation enhances each model's unique strengths via unsupervisedlearning, enabling diverse adaptation to the target domain. Extensiveexperiments show that COCA, which can also serve as a plug-and-play module,significantly boosts existing SOTAs, on models with various sizes--includingResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracyon ImageNet-C from 51.7% to 64.5%. The code is publicly available athttps://github.com/ycarobot/COCA.</description>
      <author>example@mail.com (Chang'an Yi, Xiaohui Deng, Guohao Chen, Yan Zhou, Qinghua Lu, Shuaicheng Niu)</author>
      <guid isPermaLink="false">2506.23724v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Visual and Memory Dual Adapter for Multi-Modal Object Tracking</title>
      <link>http://arxiv.org/abs/2506.23972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉和记忆双重适配器（VMDA）的多模态跟踪方法，通过轻量级视觉适配器将辅助模态特征融入基础模型，提高了多模态跟踪的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态跟踪方法在利用频率和时域关键线索方面存在局限性，导致难以学习可靠的提示。&lt;h4&gt;目的&lt;/h4&gt;构建更鲁棒和具有区分度的多模态跟踪表示。&lt;h4&gt;方法&lt;/h4&gt;开发了简单而有效的视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的区分性线索转移到主导模态。同时，设计了受人类记忆机制启发的记忆适配器，存储全局时域线索，并执行动态更新和检索操作，确保视频序列中可靠时域信息的一致传播。&lt;h4&gt;主要发现&lt;/h4&gt;在RGB-热、RGB-深度和RGB-事件等多种多模态跟踪任务上，该方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;VMDA方法在多模态跟踪任务上具有显著优势，代码和模型可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;基于提示学习的多模态跟踪器通过采用轻量级视觉适配器将辅助模态特征纳入冻结的基础模型，取得了有希望的进展。然而，现有的方法往往由于在频率和时域上对关键线索的利用有限，而难以学习可靠的提示。在本文中，我们提出了一种新颖的视觉和记忆双重适配器（VMDA）来构建更鲁棒和具有区分度的多模态跟踪表示。具体来说，我们开发了一种简单但有效的视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的区分性线索转移到主导模态。此外，我们设计了一种受人类记忆机制启发的记忆适配器，存储全局时域线索，并执行动态更新和检索操作，以确保视频序列中可靠时域信息的一致传播。广泛的实验表明，我们的方法在各种多模态跟踪任务上，包括RGB-热、RGB-深度和RGB-事件跟踪，都实现了最先进的性能。代码和模型可在https://github.com/xuboyue1999/mmtrack.git上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompt-learning-based multi-modal trackers have achieved promising progressby employing lightweight visual adapters to incorporate auxiliary modalityfeatures into frozen foundation models. However, existing approaches oftenstruggle to learn reliable prompts due to limited exploitation of critical cuesacross frequency and temporal domains. In this paper, we propose a novel visualand memory dual adapter (VMDA) to construct more robust and discriminativerepresentations for multi-modal tracking. Specifically, we develop a simple buteffective visual adapter that adaptively transfers discriminative cues fromauxiliary modality to dominant modality by jointly modeling the frequency,spatial, and channel-wise features. Additionally, we design the memory adapterinspired by the human memory mechanism, which stores global temporal cues andperforms dynamic update and retrieval operations to ensure the consistentpropagation of reliable temporal information across video sequences. Extensiveexperiments demonstrate that our method achieves state-of-the-art performanceon the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,and RGB-Event tracking. Code and models are available athttps://github.com/xuboyue1999/mmtrack.git.</description>
      <author>example@mail.com (Boyue Xu, Ruichao Hou, Tongwei Ren, Gangshan Wu)</author>
      <guid isPermaLink="false">2506.23972v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When Test-Time Adaptation Meets Self-Supervised Models</title>
      <link>http://arxiv.org/abs/2506.23529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在测试时数据上训练的深度学习模型能否在无需依赖源预训练模型的情况下，通过自我监督学习（SSL）连续提升模型性能，并提出了一个结合SSL和TTA的协作学习框架。&lt;h4&gt;背景&lt;/h4&gt;测试时适应（TTA）使深度学习模型能够适应动态环境变化，但在线适应依赖于源预训练模型的表现。&lt;h4&gt;目的&lt;/h4&gt;探究测试时适应（TTA）方法是否可以在不依赖源预训练的情况下，通过自我监督学习（SSL）持续改进模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自我监督的TTA协议，并引入了一个协作学习框架，该框架结合了SSL和TTA模型，利用对比学习和知识蒸馏逐步优化表示。&lt;h4&gt;主要发现&lt;/h4&gt;在DINO、MoCo和iBOT等不同的自我监督模型上，通过TTA基准测试验证了方法的有效性，即使在没有源预训练的情况下，也能达到有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在SSL中表现出有效性，证明了即使不依赖源预训练，也能实现良好的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在测试时数据上训练的深度学习模型能够适应动态环境变化，从而增强其实际应用性。从源域到目标域的在线适应很有前景，但它高度依赖于源预训练模型的表现。在本文中，我们研究了测试时适应（TTA）方法是否能够通过自我监督学习（SSL）连续改进模型，而不依赖于源预训练。观察到现有的TTA方法在直接应用于具有低源域精度的自我监督模型时遇到困难后，我们引入了一种自我监督的TTA协议。此外，我们提出了一种集成SSL和TTA模型的协作学习框架，利用对比学习和知识蒸馏进行逐步表示优化。我们在包括DINO、MoCo和iBOT在内的多种自我监督模型上，以及TTA基准测试中验证了我们的方法。大量实验验证了我们的方法在SSL中的有效性，表明即使在没有源预训练的情况下，该方法也能达到具有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training on test-time data enables deep learning models to adapt to dynamicenvironmental changes, enhancing their practical applicability. Onlineadaptation from source to target domains is promising but it remains highlyreliant on the performance of source pretrained model. In this paper, weinvestigate whether test-time adaptation (TTA) methods can continuously improvemodels trained via self-supervised learning (SSL) without relying on sourcepretraining. We introduce a self-supervised TTA protocol after observing thatexisting TTA approaches struggle when directly applied to self-supervisedmodels with low accuracy on the source domain. Furthermore, we propose acollaborative learning framework that integrates SSL and TTA models, leveragingcontrastive learning and knowledge distillation for stepwise representationrefinement. We validate our method on diverse self-supervised models, includingDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate theeffectiveness of our approach in SSL, showing that it achieves competitiveperformance even without source pretraining.</description>
      <author>example@mail.com (Jisu Han, Jihee Park, Dongyoon Han, Wonjun Hwang)</author>
      <guid isPermaLink="false">2506.23529v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Event-based Tiny Object Detection: A Benchmark Dataset and Baseline</title>
      <link>http://arxiv.org/abs/2506.23575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为EV-SpSegNet的事件基础稀疏分割网络，用于小目标检测，并在EV-UAV数据集上进行了实验，证明了方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;小目标检测在反无人机任务中是一个具有挑战性的问题，传统基于帧的相机在复杂环境中检测小目标存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决小目标检测的问题，本文提出了一个新的数据集EV-UAV和一个基于事件的小目标检测方法。&lt;h4&gt;方法&lt;/h4&gt;本文引入了EV-SpSegNet，这是一个在点云空间中进行事件分割的新方法，并提出了时空相关性（STC）损失函数来利用运动连续性指导网络。&lt;h4&gt;主要发现&lt;/h4&gt;在EV-UAV数据集上进行的实验表明，该方法优于现有的方法，并为未来EVSOD研究提供了一个基准。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为小目标检测在反无人机任务中提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在反无人机任务中，由于无人机体积小、背景复杂，小目标检测（SOD）是一个具有挑战性的问题。传统基于帧的相机由于帧率低、动态范围有限和数据冗余，难以在复杂环境中检测小目标。具有微秒级时间分辨率和高动态范围的事件相机为SOD提供了一种更有效的解决方案。然而，现有的基于事件的对象检测数据集规模有限，目标大小较大，背景缺乏多样性，不适合作为SOD基准。在本文中，我们引入了一个基于事件的小目标检测（EVSOD）数据集（即EV-UAV），这是第一个用于反无人机任务的大规模、高度多样化的基准。它包括147个序列，超过230万个事件级别标注，具有极其小的目标（平均为6.8×5.4像素）和多样化的场景，如城市杂乱和极端光照条件。此外，基于观察到的运动小目标在时空事件点云中形成连续曲线，我们提出了基于事件的空间时间相关网络（EV-SpSegNet），这是点云空间中事件分割的一个新基准，以及一个时空相关性（STC）损失函数，该函数利用运动连续性来指导网络保留目标事件。在EV-UAV数据集上的大量实验表明，我们方法的优势，并为EVSOD的未来研究提供了一个基准。数据集和代码可在https://github.com/ChenYichen9527/Ev-UAV上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small object detection (SOD) in anti-UAV task is a challenging problem due tothe small size of UAVs and complex backgrounds. Traditional frame-based camerasstruggle to detect small objects in complex environments due to their low framerates, limited dynamic range, and data redundancy. Event cameras, withmicrosecond temporal resolution and high dynamic range, provide a moreeffective solution for SOD. However, existing event-based object detectiondatasets are limited in scale, feature large targets size, and lack diversebackgrounds, making them unsuitable for SOD benchmarks. In this paper, weintroduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes147 sequences with over 2.3 million event-level annotations, featuringextremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diversescenarios such as urban clutter and extreme lighting conditions. Furthermore,based on the observation that small moving targets form continuous curves inspatiotemporal event point clouds, we propose Event based Sparse SegmentationNetwork (EV-SpSegNet), a novel baseline for event segmentation in point cloudspace, along with a Spatiotemporal Correlation (STC) loss that leverages motioncontinuity to guide the network in retaining target events. Extensiveexperiments on the EV-UAV dataset demonstrate the superiority of our method andprovide a benchmark for future research in EVSOD. The dataset and code are athttps://github.com/ChenYichen9527/Ev-UAV.</description>
      <author>example@mail.com (Nuo Chen, Chao Xiao, Yimian Dai, Shiman He, Miao Li, Wei An)</author>
      <guid isPermaLink="false">2506.23575v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Contrastive Learning for Multi-Label Images</title>
      <link>http://arxiv.org/abs/2506.23156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的自监督学习方法，通过使用少量多标签图像来保证出色的表示学习能力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在通过比较方法学习表示方面表现出有效性，但主流方法依赖大量单标签数据集，如ImageNet，导致预训练成本高，且忽略了多标签图像的潜在语义信息和更广泛的应用场景。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用少量多标签图像来改进主流的自监督学习方法，以提高表示学习能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种块状增强模块，用于从多标签图像中提取潜在的正面视图对。随后，设计了一种图像感知对比损失，以建立这些视图之间的联系，从而促进语义一致表示的提取。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合线性微调和迁移学习验证了该方法在样本质量和数量具有挑战性的情况下仍然具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过使用少量多标签图像，在保证表示学习能力的同时，有效降低了预训练的负担，并提高了自监督学习的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has demonstrated its effectiveness in learning representations through comparison methods that align with human intuition. However, mainstream SSL methods heavily rely on high body datasets with single label, such as ImageNet, resulting in intolerable pre-training overhead. Besides, more general multi-label images are frequently overlooked in SSL, despite their potential for richer semantic information and broader applicability in downstream scenarios. Therefore, we tailor the mainstream SSL approach to guarantee excellent representation learning capabilities using fewer multi-label images. Firstly, we propose a block-wise augmentation module aimed at extracting additional potential positive view pairs from multi-label images. Subsequently, an image-aware contrastive loss is devised to establish connections between these views, thereby facilitating the extraction of semantically consistent representations. Comprehensive linear fine-tuning and transfer learning validate the competitiveness of our approach despite challenging sample quality and quantity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has demonstrated its effectiveness in learningrepresentations through comparison methods that align with human intuition.However, mainstream SSL methods heavily rely on high body datasets with singlelabel, such as ImageNet, resulting in intolerable pre-training overhead.Besides, more general multi-label images are frequently overlooked in SSL,despite their potential for richer semantic information and broaderapplicability in downstream scenarios. Therefore, we tailor the mainstream SSLapproach to guarantee excellent representation learning capabilities usingfewer multi-label images. Firstly, we propose a block-wise augmentation moduleaimed at extracting additional potential positive view pairs from multi-labelimages. Subsequently, an image-aware contrastive loss is devised to establishconnections between these views, thereby facilitating the extraction ofsemantically consistent representations. Comprehensive linear fine-tuning andtransfer learning validate the competitiveness of our approach despitechallenging sample quality and quantity.</description>
      <author>example@mail.com (Jiale Chen)</author>
      <guid isPermaLink="false">2506.23156v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling</title>
      <link>http://arxiv.org/abs/2506.23782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为WATS的Graph Neural Networks（GNNs）后处理校准框架，用于提高GNNs在关系数据上的预测性能和置信度估计的准确性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在关系数据上表现出强大的预测性能，但其置信度估计与实际预测的正确性往往不一致，这在安全性关键的应用场景中是一个重大限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过利用图小波特征来为节点分配特定的温度，从而提高GNNs的置信度估计。&lt;h4&gt;方法&lt;/h4&gt;WATS框架利用图小波的扩展性和拓扑敏感性来细化置信度估计，而无需重新训练模型或访问相邻的logits或预测。&lt;h4&gt;主要发现&lt;/h4&gt;在七个具有不同图结构和两种GNN骨干网络的基准数据集上的广泛评估表明，WATS在所有比较方法中实现了最低的预期校准误差（ECE），在ECE方面优于经典和图特定基线，平均提高了42.3%，并且与图特定方法相比，校准方差降低了17.24%。此外，WATS在计算效率上保持高效，能够很好地扩展到不同大小和密度的图。&lt;h4&gt;结论&lt;/h4&gt;WATS是一种有效的GNNs校准方法，可以提高其在安全性关键应用中的可信度。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) 在关系数据上展示了强大的预测性能；然而，它们的置信度估计通常与实际预测的正确性不一致，这给在安全关键环境中的部署带来了重大限制。尽管现有的图感知校准方法试图缓解这一限制，但它们主要依赖于粗略的一跳统计，例如邻居预测的置信度，或者潜在节点嵌入，从而忽略了图拓扑中固有的细粒度结构异质性。在本工作中，我们提出了波let感知温度缩放（WATS），这是一种后处理校准框架，它根据可调的热核图小波特征分配节点特定的温度。具体来说，WATS利用图小波的扩展性和拓扑敏感性来细化置信度估计，而无需重新训练模型或访问相邻的logits或预测。在七个基准数据集上进行了广泛的评估，这些数据集具有不同的图结构和两种GNN骨干网络，结果表明WATS在所有比较方法中实现了最低的预期校准误差（ECE），在ECE方面优于经典和图特定基线，平均提高了42.3%，并且与图特定方法相比，校准方差降低了17.24%。此外，WATS在计算效率上保持高效，能够很好地扩展到不同大小和密度的图。基于本论文的代码将发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong predictive performanceon relational data; however, their confidence estimates often misalign withactual predictive correctness, posing significant limitations for deployment insafety-critical settings. While existing graph-aware calibration methods seekto mitigate this limitation, they primarily depend on coarse one-hopstatistics, such as neighbor-predicted confidence, or latent node embeddings,thereby neglecting the fine-grained structural heterogeneity inherent in graphtopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), apost-hoc calibration framework that assigns node-specific temperatures based ontunable heat-kernel graph wavelet features. Specifically, WATS harnesses thescalability and topology sensitivity of graph wavelets to refine confidenceestimates, all without necessitating model retraining or access to neighboringlogits or predictions. Extensive evaluations across seven benchmark datasetswith varying graph structures and two GNN backbones demonstrate that WATSachieves the lowest Expected Calibration Error (ECE) among all comparedmethods, outperforming both classical and graph-specific baselines by up to42.3\% in ECE and reducing calibration variance by 17.24\% on average comparedwith graph-specific methods. Moreover, WATS remains computationally efficient,scaling well across graphs of diverse sizes and densities. Code will bereleased based on publication.</description>
      <author>example@mail.com (Xiaoyang Li, Linwei Tao, Haohui Lu, Minjing Dong, Junbin Gao, Chang Xu)</author>
      <guid isPermaLink="false">2506.23782v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.23309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Project Page:  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SurgTPGS，一种基于文本提示的Gaussian Splatting方法，用于解决手术研究中3D场景的准确理解问题，以支持手术规划和术中实时指导。&lt;h4&gt;背景&lt;/h4&gt;在当代外科研究和实践中，精确理解带有文本提示功能的3D手术场景对于手术规划和术中实时指导至关重要，需要精确识别和交互手术工具和解剖结构。&lt;h4&gt;目的&lt;/h4&gt;填补现有工作在手术视觉-语言模型、3D重建和分割方面缺乏实时文本提示3D查询支持的空白。&lt;h4&gt;方法&lt;/h4&gt;引入了一种结合Segment Anything模型和最先进的视觉-语言模型的3D语义特征学习策略，提取分割的语言特征以进行3D手术场景重建。同时提出了语义感知变形跟踪和语义区域感知优化。&lt;h4&gt;主要发现&lt;/h4&gt;SurgTPGS在两个真实世界手术数据集上进行了全面实验，证明了其优于现有方法，并有望革新外科实践。&lt;h4&gt;结论&lt;/h4&gt;SurgTPGS为开发下一代智能手术系统铺平了道路，通过提高手术精度和安全性能。&lt;h4&gt;翻译&lt;/h4&gt;在当代外科研究和实践中，准确理解具有文本提示能力的3D手术场景对于手术规划和术中实时指导尤其重要，精确识别和交互手术工具和解剖结构至关重要。然而，现有工作分别关注手术视觉-语言模型（VLM）、3D重建和分割，缺乏对实时文本提示3D查询的支持。在本文中，我们提出了一种新的基于文本提示的Gaussian Splatting方法SurgTPGS来填补这一空白。我们引入了一种结合Segment Anything模型和最先进的视觉-语言模型的3D语义特征学习策略，用于提取分割的语言特征以进行3D手术场景重建，从而更深入地理解复杂的手术环境。我们还提出了语义感知变形跟踪来捕捉语义特征的连续变形，为纹理和语义特征提供更精确的重建。此外，我们还提出了语义区域感知优化，利用基于区域的语义信息来监督训练，特别是促进重建质量和语义平滑性。我们在两个真实世界手术数据集上进行了全面实验，以证明SurgTPGS优于现有方法，并突出其革新外科实践潜力。SurgTPGS通过提高手术精度和安全性能，为开发下一代智能手术系统铺平了道路。我们的代码可在https://github.com/lastbasket/SurgTPGS上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contemporary surgical research and practice, accurately comprehending 3Dsurgical scenes with text-promptable capabilities is particularly crucial forsurgical planning and real-time intra-operative guidance, where preciselyidentifying and interacting with surgical tools and anatomical structures isparamount. However, existing works focus on surgical vision-language model(VLM), 3D reconstruction, and segmentation separately, lacking support forreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, anovel text-promptable Gaussian Splatting method to fill this gap. We introducea 3D semantics feature learning strategy incorporating the Segment Anythingmodel and state-of-the-art vision-language models. We extract the segmentedlanguage features for 3D surgical scene reconstruction, enabling a morein-depth understanding of the complex surgical environment. We also proposesemantic-aware deformation tracking to capture the seamless deformation ofsemantic features, providing a more precise reconstruction for both texture andsemantic features. Furthermore, we present semantic region-aware optimization,which utilizes regional-based semantic information to supervise the training,particularly promoting the reconstruction quality and semantic smoothness. Weconduct comprehensive experiments on two real-world surgical datasets todemonstrate the superiority of SurgTPGS over state-of-the-art methods,highlighting its potential to revolutionize surgical practices. SurgTPGS pavesthe way for developing next-generation intelligent surgical systems byenhancing surgical precision and safety. Our code is available at:https://github.com/lastbasket/SurgTPGS.</description>
      <author>example@mail.com (Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarakol Islam, Nicolas Padoy, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.23309v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound</title>
      <link>http://arxiv.org/abs/2506.23108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CVC-RF的新型框架，用于更精确的颈动脉斑块分级，以提高心血管和脑血管疾病的风险评估。&lt;h4&gt;背景&lt;/h4&gt;颈动脉斑块分级对于评估心血管和脑血管疾病风险至关重要，但现有方法在处理斑块的小尺寸和类内变异性时存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理不同层级信息并提升模型性能的颈动脉斑块分级方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种CVC-RF框架，该框架从语料库、视图和类别三个层级处理信息，并包括以下创新点：1. 根据Carotid Plaque-RADS指南，开发了一个基于深度学习的颈动脉斑块分级方法；2. 提出了一种新的中心-记忆对比损失函数，增强了网络的全球建模能力；3. 设计了一个级联下采样注意力模块，以融合多尺度信息并在视图级别实现隐式特征交互；4. 引入了一种参数自由的专业混合加权策略，利用类别聚类知识来加权不同专家，实现类别层级的特征解耦。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CVC-RF通过多层级细化有效地建模全局特征，在颈动脉斑块分级这一具有挑战性的任务中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;CVC-RF框架能够显著提高颈动脉斑块分级的准确性，为心血管和脑血管疾病的早期诊断提供了新的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate carotid plaque grading (CPG) is vital to assess the risk ofcardiovascular and cerebrovascular diseases. Due to the small size and highintra-class variability of plaque, CPG is commonly evaluated using acombination of transverse and longitudinal ultrasound views in clinicalpractice. However, most existing deep learning-based multi-view classificationmethods focus on feature fusion across different views, neglecting theimportance of representation learning and the difference in class features. Toaddress these issues, we propose a novel Corpus-View-Category RefinementFramework (CVC-RF) that processes information from Corpus-, View-, andCategory-levels, enhancing model performance. Our contribution is four-fold.First, to the best of our knowledge, we are the foremost deep learning-basedmethod for CPG according to the latest Carotid Plaque-RADS guidelines. Second,we propose a novel center-memory contrastive loss, which enhances the network'sglobal modeling capability by comparing with representative cluster centers anddiverse negative samples at the Corpus level. Third, we design a cascadeddown-sampling attention module to fuse multi-scale information and achieveimplicit feature interaction at the View level. Finally, a parameter-freemixture-of-experts weighting strategy is introduced to leverage classclustering knowledge to weight different experts, enabling feature decouplingat the Category level. Experimental results indicate that CVC-RF effectivelymodels global features via multi-level refinement, achieving state-of-the-artperformance in the challenging CPG task.</description>
      <author>example@mail.com (Zhiyuan Zhu, Jian Wang, Yong Jiang, Tong Han, Yuhao Huang, Ang Zhang, Kaiwen Yang, Mingyuan Luo, Zhe Liu, Yaofei Duan, Dong Ni, Tianhong Tang, Xin Yang)</author>
      <guid isPermaLink="false">2506.23108v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning</title>
      <link>http://arxiv.org/abs/2506.22919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Hecto是一个轻量级的MoE模型，通过结合不同的专家来提高条件计算效率，并增强表示多样性。&lt;h4&gt;背景&lt;/h4&gt;MoE模型通过将输入路由到专门化的专家来支持条件计算，但现有的专家依赖于相同的归纳偏见，限制了表示多样性。&lt;h4&gt;目的&lt;/h4&gt;提出Hecto模型，以解决MoE模型中专家同质化带来的问题，提高模型的效率和可解释性。&lt;h4&gt;方法&lt;/h4&gt;Hecto模型结合了GRU专家用于时间推理和FFNN专家用于静态抽象，在稀疏Top-1门控机制下工作。&lt;h4&gt;主要发现&lt;/h4&gt;Hecto在三个推理基准和回归任务上表现良好，即使在单独的输入表示下也能与同质基线相匹配。在更大的批次大小下，Hecto的性能有所提高。消融实验表明，Hecto的稳定性和可解释性来源于其架构多样性。&lt;h4&gt;结论&lt;/h4&gt;Hecto作为一个新的条件计算基准，为资源有限的环境中的专业化推理提供了一个原则性的框架，其模型强度源于原则性的专业化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixture-of-Experts (MoE) models enable conditional computation by routinginputs to specialized experts, but these experts rely on identical inductivebiases, thus limiting representational diversity. This static computationpathway is inefficient for inputs that require different types of reasoning andlimits specialization and interpretability. We propose Hecto, a lightweight MoEarchitecture that leverages architectural heterogeneity by combining a GRUexpert for temporal reasoning and an FFNN expert for static abstraction under asparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AGNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closelytrails homogeneous baselines in performance despite receiving isolated inputrepresentations, while achieving clear expert specialization, with each expertaligning to distinct reasoning types (temporal vs static). At larger batchsizes, Hecto exhibits improved performance, benefiting from relaxedcomputational constraints that allow its heterogeneous architecture to optimizemore effectively. Ablation results isolate architectural diversity as thesource of Hecto's stability and interpretability across diverse reasoningtasks. Overall, Hecto establishes itself as a new benchmark for conditionalcomputation, offering a principled framework for specialized reasoning inlow-resource regimes with its model strength derived from principledspecialization.</description>
      <author>example@mail.com (Sanskar Pandey, Ruhaan Chopra, Saad Murtaza Bhat, Ark Abhyudaya)</author>
      <guid isPermaLink="false">2506.22919v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning</title>
      <link>http://arxiv.org/abs/2506.22488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NeuroDyGait是一种基于EEG信号的领域泛化运动解码框架，通过结构化对比表示学习和关系领域建模解决下肢运动解码问题。&lt;h4&gt;背景&lt;/h4&gt;准确解码EEG信号中的下肢运动对于提高BCI在运动意图识别和控制方面的应用至关重要，但目前存在因果预测、相位一致性预测和模型个体间及个体内差异建模的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出NeuroDyGait框架以解决上述挑战，实现因果、相位一致的预测，并建模个体间及个体内差异。&lt;h4&gt;方法&lt;/h4&gt;NeuroDyGait利用相对对比学习实现EEG和运动嵌入的语义对齐，并引入多周期步态重建目标以维持时间一致性和生物力学一致性。在微调期间，通过域动态解码机制自适应地分配会话特定的预测头，并根据会话间关系混合它们的输出。&lt;h4&gt;主要发现&lt;/h4&gt;NeuroDyGait实现了无需适应的对未见个体的零样本运动预测，并在基准数据集上的跨主体步态解码中表现出优异的性能。即使在训练过程中没有明确的相位监督，它也展现了强大的相位检测能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了关系领域学习在实现可扩展、无目标的BCI部署中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate decoding of lower-limb motion from EEG signals is essential foradvancing brain-computer interface (BCI) applications in movement intentrecognition and control. However, challenges persist in achieving causal,phase-consistent predictions and in modeling both inter- and intra-subjectvariability. To address these issues, we propose NeuroDyGait, adomain-generalizable EEG-to-motion decoding framework that leverages structuredcontrastive representation learning and relational domain modeling. Theproposed method employs relative contrastive learning to achieve semanticalignment between EEG and motion embeddings. Furthermore, a multi-cycle gaitreconstruction objective is introduced to enforce temporal coherence andmaintain biomechanical consistency. To promote inter-session generalization,during fine-tuning, a domain dynamic decoding mechanism adaptively assignssession-specific prediction heads and learns to mix their outputs based oninter-session relationships. NeuroDyGait enables zero-shot motion predictionfor unseen individuals without requiring adaptation and achieves superiorperformance in cross-subject gait decoding on benchmark datasets. Additionally,it demonstrates strong phase-detection capabilities even without explicit phasesupervision during training. These findings highlight the potential ofrelational domain learning in enabling scalable, target-free deployment ofBCIs.</description>
      <author>example@mail.com (Xi Fu, Weibang Jiang, Rui Liu, Gernot R. Müller-Putz, Cuntai Guan)</author>
      <guid isPermaLink="false">2506.22488v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation</title>
      <link>http://arxiv.org/abs/2506.23120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了在点云感知领域通过视觉-语言对齐利用大型语言模型（LLMs）实现的场景理解进展，并提出了基于推理的分割框架R$^2$S，以及一个包含精确标注的推理分割数据集3D ReasonSeg。&lt;h4&gt;背景&lt;/h4&gt;点云感知在场景理解方面取得了显著进展，但现有方法在处理复杂指令和空间推理方面可能存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于推理的分割框架R$^2$S，以及一个用于复杂推理任务的3D ReasonSeg数据集，以提高3D点云感知的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;R$^2$S框架通过将空间推理分解为两个阶段：首先识别相关元素，然后根据相关视觉先验处理指令。3D ReasonSeg数据集包含25,185个训练样本和3,966个验证样本。&lt;h4&gt;主要发现&lt;/h4&gt;R$^2$S和3D ReasonSeg有效地增强了3D点云感知的空间推理能力。&lt;h4&gt;结论&lt;/h4&gt;R$^2$S和3D ReasonSeg有望成为未来工作的新基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期点云感知在场景理解方面取得了显著进展，通过视觉-语言对齐利用大型语言模型（LLMs）实现了这一成果。然而，现有方法在处理需要精确空间推理的复杂指令时仍可能遇到挑战，尽管3D点云数据提供了详细的空间线索，如大小和位置，以识别目标。为了解决这一问题，我们提出了相关推理分割（R$^2$S），一个基于推理的分割框架。该框架通过将空间推理分解为两个连续阶段来模拟人类的认知过程：首先识别相关元素，然后根据其相关的视觉先验处理指令。此外，鉴于现有数据集在复杂推理任务中的不足，我们引入了3D ReasonSeg，一个包含25,185个训练样本和3,966个验证样本的基于推理的分割数据集。定性和定量实验表明，R$^2$S和3D ReasonSeg有效地赋予了3D点云感知更强的空间推理能力，我们希望它们能作为未来工作的新基准和参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in point cloud perception have demonstrated remarkableprogress in scene understanding through vision-language alignment leveraginglarge language models (LLMs). However, existing methods may still encounterchallenges in handling complex instructions that require accurate spatialreasoning, even if the 3D point cloud data provides detailed spatial cues suchas size and position for identifying the targets. To tackle this issue, wepropose Relevant Reasoning Segmentation (R$^2$S), a reasoning-basedsegmentation framework. The framework emulates human cognitive processes bydecomposing spatial reasoning into two sequential stages: first identifyingrelevant elements, then processing instructions guided by their associatedvisual priors. Furthermore, acknowledging the inadequacy of existing datasetsin complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-basedsegmentation dataset comprising 25,185 training samples and 3,966 validationsamples with precise annotations. Both quantitative and qualitative experimentsdemonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloudperception with stronger spatial reasoning capabilities, and we hope that theycan serve as a new baseline and benchmark for future work.</description>
      <author>example@mail.com (Zhenhua Ning, Zhuotao Tian, Shaoshuai Shi, Guangming Lu, Daojing He, Wenjie Pei, Li Jiang)</author>
      <guid isPermaLink="false">2506.23120v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation</title>
      <link>http://arxiv.org/abs/2506.23675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV'25 Workshops&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision Transformer在多个任务中创造了新的基准，但其高计算成本使其在资源受限的硬件上不实用。网络剪枝通过移除不重要的操作来降低计算复杂度，但在未见过的数据域上剪枝会导致权重重要性评估不准确，从而影响资源分配。本文提出了P3B（Pruning by Block Benefit）剪枝方法，通过利用块级别的相对贡献来全局分配参数资源，解决了这一问题。&lt;h4&gt;背景&lt;/h4&gt;Vision Transformer模型在多个任务中表现出色，但计算成本高，不适合资源受限的硬件。网络剪枝虽然能降低计算复杂度，但在未见过的数据域上剪枝会导致权重重要性评估不准确。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的剪枝方法P3B，以解决在未见过的数据域上剪枝导致的问题，并提高模型在资源受限硬件上的性能。&lt;h4&gt;方法&lt;/h4&gt;P3B方法通过利用块级别的相对贡献来全局分配参数资源，识别低影响组件以减少参数分配，同时保留关键组件。&lt;h4&gt;主要发现&lt;/h4&gt;P3B方法在转移学习任务中表现出色，能够显著提高性能，即使在70%参数稀疏度的高稀疏环境下也能保持高性能，精度损失仅为0.64%。&lt;h4&gt;结论&lt;/h4&gt;P3B是一种先进的剪枝方法，在转移学习任务中具有显著优势，能够在资源受限的硬件上有效提高Vision Transformer的性能。&lt;h4&gt;翻译&lt;/h4&gt;Vision Transformer在多个任务中建立了新的基准，但这些模型伴随着高计算成本的问题，这使得它们在资源有限的硬件上不实用。网络剪枝通过移除不重要的操作来降低计算复杂性，同时保持性能。然而，在未见过的数据域上剪枝模型会导致权重重要性评估不准确，从而产生次优的资源分配。在这项工作中，我们发现任务敏感的层最初无法提高下游任务的特征表示，导致早期剪枝决策的性能下降。为了解决这个问题，我们引入了基于块收益的剪枝（P3B），这是一种利用块级别相对贡献来全局分配参数资源的剪枝方法。P3B识别出低影响组件以减少参数分配，同时保留关键组件。与传统的剪枝掩码优化难以重新激活零掩码元素相比，P3B基于全局性能指标设置分层保留比率，确保了后期收敛块的重新激活。我们在广泛的实验中表明，P3B是一种最先进的剪枝方法，在迁移学习任务中取得了最显著的收益。值得注意的是，P3B能够在高稀疏度（70%参数减少）的稀疏环境下保持高性能，精度仅损失0.64%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformer have set new benchmarks in several tasks, but these modelscome with the lack of high computational costs which makes them impractical forresource limited hardware. Network pruning reduces the computational complexityby removing less important operations while maintaining performance. However,pruning a model on an unseen data domain, leads to a misevaluation of weightsignificance, resulting in suboptimal resource assignment. In this work, wefind that task-sensitive layers initially fail to improve the featurerepresentation on downstream tasks, leading to performance loss for earlypruning decisions. To address this problem, we introduce Pruning by BlockBenefit (P3B), a pruning method that utilizes the relative contribution onblock level to globally assign parameter resources. P3B identifies low-impactcomponents to reduce parameter allocation while preserving critical ones.Classical pruning mask optimization struggles to reactivate zero-mask-elements.In contrast, P3B sets a layerwise keep ratio based on global performancemetrics, ensuring the reactivation of late-converging blocks. We show inextensive experiments that P3B is a state of the art pruning method with mostnoticeable gains in transfer learning tasks. Notably, P3B is able to conservehigh performance, even in high sparsity regimes of 70% parameter reductionwhile only losing 0.64% in accuracy.</description>
      <author>example@mail.com (Patrick Glandorf, Bodo Rosenhahn)</author>
      <guid isPermaLink="false">2506.23675v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models</title>
      <link>http://arxiv.org/abs/2506.23949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了多用途人工智能模型（如大型语言模型、通用人工智能模型、基础模型、生成式人工智能模型和前沿模型）的潜在益处和风险，并提供了针对这些模型的风险管理实践。&lt;h4&gt;背景&lt;/h4&gt;随着多用途AI模型的发展，它们能够提供许多有益的能力，但也存在潜在的不良事件风险。&lt;h4&gt;目的&lt;/h4&gt;为大规模、前沿的GPAI/foundation模型开发者提供风险管理实践，以识别、分析和减轻风险。&lt;h4&gt;方法&lt;/h4&gt;基于NIST AI风险管理框架和ISO/IEC 23894的通用自愿性指导，重点关注GPAI/foundation模型开发者面临的独特问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文旨在帮助开发者了解和应对GPAI/foundation模型的风险。&lt;h4&gt;结论&lt;/h4&gt;本文为GPAI/foundation模型的开发者提供了风险管理方面的指导，以促进其符合或采用领先的AI风险管理标准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着多用途人工智能模型（如尖端大型语言模型或其他“通用人工智能”（GPAI）模型、“基础模型”、生成式人工智能模型和“前沿模型”（此处通常统称为“GPAI/基础模型”，除非需要更大的具体性）能够提供许多有益的能力，但也存在可能导致严重后果的不良事件风险。本文提供了针对GPAI/基础模型的风险管理实践或控制措施，以识别、分析和减轻风险。我们主要针对大规模、前沿的GPAI/foundation模型开发者；其他可以从中受益的包括基于GPAI/foundation模型构建终端应用的下游开发者。本文有助于遵守或使用领先的AI风险管理相关标准，基于NIST AI风险管理框架和ISO/IEC 23894的通用自愿性指导，重点关注GPAI/foundation模型开发者面临的独特问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Increasingly multi-purpose AI models, such as cutting-edge large languagemodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'generative AI models, and 'frontier models' (typically all referred tohereafter with the umbrella term 'GPAI/foundation models' except where greaterspecificity is needed), can provide many beneficial capabilities but also risksof adverse events with profound consequences. This document providesrisk-management practices or controls for identifying, analyzing, andmitigating risks of GPAI/foundation models. We intend this document primarilyfor developers of large-scale, state-of-the-art GPAI/foundation models; othersthat can benefit from this guidance include downstream developers of end-useapplications that build on a GPAI/foundation model. This document facilitatesconformity with or use of leading AI risk management-related standards,adapting and building on the generic voluntary guidance in the NIST AI RiskManagement Framework and ISO/IEC 23894, with a focus on the unique issues facedby developers of GPAI/foundation models.</description>
      <author>example@mail.com (Anthony M. Barrett, Jessica Newman, Brandie Nonnecke, Nada Madkour, Dan Hendrycks, Evan R. Murphy, Krystal Jackson, Deepika Raman)</author>
      <guid isPermaLink="false">2506.23949v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection</title>
      <link>http://arxiv.org/abs/2506.23519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 Pages, 9 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在弱监督下使用眼动信息辅助视频显著对象检测（VSOD）的方法，提出了一种结合位置和语义嵌入（PSE）模块的模型，并通过语义和局部性查询（SLQ）以及内部-外部混合对比（IIMC）模型提升时空特征建模能力。&lt;h4&gt;背景&lt;/h4&gt;眼动追踪视频显著性预测（VSP）和视频显著对象检测（VSOD）任务都关注视频中最吸引人的对象，并以预测热图和像素级显著性掩码的形式展示结果。在实际应用中，眼动追踪标注更容易获得，并与人类眼睛的真实视觉模式紧密一致。&lt;h4&gt;目的&lt;/h4&gt;引入注视信息以辅助弱监督下的视频显著对象检测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种位置和语义嵌入（PSE）模块，在特征学习过程中提供位置和语义指导。设计了具有语义和局部性约束的语义和局部性查询（SLQ）竞争者，以有效地选择最匹配和准确的对象查询进行时空建模。此外，通过形成视频内和视频间对比学习范式，引入了内部-外部混合对比（IIMC）模型来提高弱监督下的时空建模能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该模型在五个流行的VSOD基准数据集上优于其他竞争者。&lt;h4&gt;结论&lt;/h4&gt;该模型能够有效地利用眼动信息，在弱监督下提高视频显著对象检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;The eye-tracking video saliency prediction (VSP) task and video salient object detection (VSOD) task both focus on the most attractive objects in video and show the result in the form of predictive heatmaps and pixel-level saliency masks, respectively. In practical applications, eye tracker annotations are more readily obtainable and align closely with the authentic visual patterns of human eyes. Therefore, this paper aims to introduce fixation information to assist the detection of video salient objects under weak supervision. On the one hand, we ponder how to better explore and utilize the information provided by fixation, and then propose a Position and Semantic Embedding (PSE) module to provide location and semantic guidance during the feature learning process. On the other hand, we achieve spatiotemporal feature modeling under weak supervision from the aspects of feature selection and feature contrast. A Semantics and Locality Query (SLQ) Competitor with semantic and locality constraints is designed to effectively select the most matching and accurate object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed Contrastive (IIMC) model improves the spatiotemporal modeling capabilities under weak supervision by forming an intra-video and inter-video contrastive learning paradigm. Experimental results on five popular VSOD benchmarks indicate that our model outperforms other competitors on various evaluation metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The eye-tracking video saliency prediction (VSP) task and video salientobject detection (VSOD) task both focus on the most attractive objects in videoand show the result in the form of predictive heatmaps and pixel-level saliencymasks, respectively. In practical applications, eye tracker annotations aremore readily obtainable and align closely with the authentic visual patterns ofhuman eyes. Therefore, this paper aims to introduce fixation information toassist the detection of video salient objects under weak supervision. On theone hand, we ponder how to better explore and utilize the information providedby fixation, and then propose a Position and Semantic Embedding (PSE) module toprovide location and semantic guidance during the feature learning process. Onthe other hand, we achieve spatiotemporal feature modeling under weaksupervision from the aspects of feature selection and feature contrast. ASemantics and Locality Query (SLQ) Competitor with semantic and localityconstraints is designed to effectively select the most matching and accurateobject query for spatiotemporal modeling. In addition, an Intra-Inter MixedContrastive (IIMC) model improves the spatiotemporal modeling capabilitiesunder weak supervision by forming an intra-video and inter-video contrastivelearning paradigm. Experimental results on five popular VSOD benchmarksindicate that our model outperforms other competitors on various evaluationmetrics.</description>
      <author>example@mail.com (Qi Qin, Runmin Cong, Gen Zhan, Yiting Liao, Sam Kwong)</author>
      <guid isPermaLink="false">2506.23519v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance</title>
      <link>http://arxiv.org/abs/2506.23478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GeoCD，这是一种用于3D点云学习的拓扑感知和全可微的测地线距离近似，旨在解决Chamfer Distance在3D形状几何特性捕捉上的局限性。&lt;h4&gt;背景&lt;/h4&gt;Chamfer Distance是3D点云学习中广泛采用的指标，但由于其仅依赖于欧几里得距离，因此常常无法捕捉3D形状的内在几何特性。&lt;h4&gt;目的&lt;/h4&gt;为了解决Chamfer Distance的局限性，提出了GeoCD，以改进3D点云学习的重建质量。&lt;h4&gt;方法&lt;/h4&gt;GeoCD是一个拓扑感知和全可微的测地线距离近似，通过实验在多个架构和数据集上对使用标准CD训练的模型进行微调来展示其效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GeoCD在各种架构和数据集上比标准CD的重建质量得到一致提升，且仅需一次epoch的微调就在多个评估指标上取得显著增益。&lt;h4&gt;结论&lt;/h4&gt;GeoCD是一种有效的3D点云学习距离度量，能够显著提高重建质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learningdue to its simplicity and efficiency. However, it suffers from a fundamentallimitation: it relies solely on Euclidean distances, which often fail tocapture the intrinsic geometry of 3D shapes. To address this limitation, wepropose GeoCD, a topology-aware and fully differentiable approximation ofgeodesic distance designed to serve as a metric for 3D point cloud learning.Our experiments show that GeoCD consistently improves reconstruction qualityover standard CD across various architectures and datasets. We demonstrate thisby fine-tuning several models, initially trained with standard CD, using GeoCD.Remarkably, fine-tuning for a single epoch with GeoCD yields significant gainsacross multiple evaluation metrics.</description>
      <author>example@mail.com (Pedro Alonso, Tianrui Li, Chongshou Li)</author>
      <guid isPermaLink="false">2506.23478v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?</title>
      <link>http://arxiv.org/abs/2506.23725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为PAC Bench的基准测试，用于评估视觉语言模型（VLMs）对核心属性、可利用性和约束（PAC）的理解，以及其在机器人操作中的应用。&lt;h4&gt;背景&lt;/h4&gt;VLMs在机器人操作中扮演重要角色，但它们对低级物理知识的需求通常未得到充分验证。&lt;h4&gt;目的&lt;/h4&gt;引入PAC Bench以评估VLMs在理解物体属性、动作可利用性和物理约束方面的能力。&lt;h4&gt;方法&lt;/h4&gt;PAC Bench包含一个多样化的数据集，包含30,000多个注释，包括673张真实世界图像、100个人类视角场景和120个独特的模拟约束场景。&lt;h4&gt;主要发现&lt;/h4&gt;当前VLMs在理解基本物理概念方面存在显著差距，这表明它们在可靠机器人操作方面的适用性有限，并指出了针对性的研究方向。&lt;h4&gt;结论&lt;/h4&gt;PAC Bench可以作为严格评估VLMs中物理推理的标准基准，并指导开发更稳健、基于物理的机器人应用模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) are increasingly pivotal for generalist robotmanipulation, enabling tasks such as physical reasoning, policy generation, andfailure detection. However, their proficiency in these high-level applicationsoften assumes a deep understanding of low-level physical prerequisites, acapability that remains largely unverified. For robots to perform actionsreliably, they must comprehend intrinsic object properties (e.g., material,weight), action affordances (e.g., graspable, stackable), and physicalconstraints (e.g., stability, reachability, or an object's state, such as beingclosed). Despite the widespread use of VLMs in manipulation tasks, we arguethat off-the-shelf models may lack this granular, physically groundedunderstanding, as such prerequisites are often overlooked during training.  To address this critical gap, we introduce PAC Bench, a comprehensivebenchmark designed to systematically evaluate VLMs on their understanding ofcore Properties, Affordances, and Constraints (PAC) from a task executabilityperspective. PAC Bench features a diverse dataset with over 30,000 annotations,comprising 673 real-world images (115 object classes, 15 property types, and 1to 3 affordances defined per class), 100 real-world humanoid-view scenarios,and 120 unique simulated constraint scenarios across four tasks.  Our evaluations reveal significant gaps in the ability of current VLMs tograsp fundamental physical concepts, highlighting limitations in theirsuitability for reliable robot manipulation and pointing to key areas fortargeted research. PAC Bench also serves as a standardized benchmark forrigorously evaluating physical reasoning in VLMs and guiding the development ofmore robust, physically grounded models for robotic applications.  Project Page: https://pacbench.github.io/</description>
      <author>example@mail.com (Atharva Gundawar, Som Sagar, Ransalu Senanayake)</author>
      <guid isPermaLink="false">2506.23725v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks to Predict Coercivity of Hard Magnetic Microstructures</title>
      <link>http://arxiv.org/abs/2506.23615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用图神经网络（GNN）预测大多晶结构磁性的方法，以加速寻找无稀土永磁体的研究。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）是一种有前景的工具，可以预测大型多晶结构的磁性，从而加速寻找无稀土永磁体的研究。&lt;h4&gt;目的&lt;/h4&gt;利用磁模拟数据训练GNN以预测硬磁性微观结构的矫顽力，并评估其性能和不确定性。&lt;h4&gt;方法&lt;/h4&gt;使用磁模拟数据训练GNN，评估其预测矫顽力的性能和不确定性，并重新使用GNN架构预测最大能量产品。进行基于特征工程的外部分布矫顽力预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过训练的GNN可以预测矫顽力，并量化其不确定性；GNN架构也可用于预测最大能量产品；基于系统尺寸对矫顽力依赖性的特征工程有助于外部分布预测。&lt;h4&gt;结论&lt;/h4&gt;GNN在预测磁性材料特性方面具有潜力，可用于加速无稀土永磁体的研究。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNN) are a promising tool to predict magnetic properties of large multi-grain structures, which can speed up the search for rare-earth free permanent magnets. In this paper, we use our magnetic simulation data to train a GNN to predict coercivity of hard magnetic microstructures. We evaluate the performance of the trained GNN and quantify its uncertainty. Subsequently, we reuse the GNN architecture for predicting the maximum energy product. Out-of-distribution predictions of coercivity are also performed, following feature engineering based on the observed dependence of coercivity on system size.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNN) are a promising tool to predict magneticproperties of large multi-grain structures, which can speed up the search forrare-earth free permanent magnets. In this paper, we use our magneticsimulation data to train a GNN to predict coercivity of hard magneticmicrostructures. We evaluate the performance of the trained GNN and quantifyits uncertainty. Subsequently, we reuse the GNN architecture for predicting themaximum energy product. Out-of-distribution predictions of coercivity are alsoperformed, following feature engineering based on the observed dependence ofcoercivity on system size.</description>
      <author>example@mail.com (Heisam Moustafa, Alexander Kovacs, Johann Fischbacher, Markus Gusenbauer, Qais Ali, Leoni Breth, Thomas Schrefl, Harald Oezelt)</author>
      <guid isPermaLink="false">2506.23615v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results</title>
      <link>http://arxiv.org/abs/2506.22843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AG-VPReID2025挑战，旨在解决高空与地面视角的Person re-identification（ReID）问题，并展示了多个团队在不同方法上的研究成果。&lt;h4&gt;背景&lt;/h4&gt;Person re-identification技术在大型监控和公共安全应用中变得至关重要。尽管在地面场景中取得了显著进展，但跨视角、尺度变化和遮挡等问题使得高空与地面领域的融合成为一个巨大的挑战。&lt;h4&gt;目的&lt;/h4&gt;通过AG-VPReID2025挑战，旨在解决高空与地面视角的ReID问题，促进相关技术的进步。&lt;h4&gt;方法&lt;/h4&gt;该挑战基于新的AG-VPReID数据集，包含3,027个身份，13,500个tracklets和大约3.7百万帧来自无人机、CCTV和可穿戴相机的图像。参与团队提出了多种解决方案，包括多流架构、基于transformer的时间推理和物理信息建模等。&lt;h4&gt;主要发现&lt;/h4&gt;领先的方法X-TFCLIP在空中到地面的ReID设置中达到了72.28%的Rank-1准确率，在地面到空中的ReID设置中达到了70.77%，超过了现有基线，并突显了数据集的复杂性。&lt;h4&gt;结论&lt;/h4&gt;AG-VPReID2025挑战为高空与地面视角的ReID问题提供了新的研究思路和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨空中和地面视角的人员重识别（ReID）对于大规模监控和公共安全应用变得至关重要。尽管在仅地面场景中取得了重大进展，但由于极端的视角差异、尺度变化和遮挡，连接空中-地面域差距仍然是一个巨大的挑战。基于AG-ReID 2023挑战的成就，本文介绍了AG-VPReID2025挑战——第一个针对高空（80-120m）空中-地面ReID的基于视频的大规模竞赛。该挑战基于新的AG-VPReID数据集，包含3,027个身份，13,500个tracklets和大约3.7百万帧来自无人机、CCTV和可穿戴相机的图像，共有四个国际团队参与。这些团队开发了从多流架构到基于transformer的时间推理和物理信息建模等不同解决方案。领先的方法X-TFCLIP从UAM达到了空中到地面ReID设置的72.28% Rank-1准确率和70.77%地面到空中ReID设置，超过了现有基线，并突显了数据集的复杂性。有关详细信息，请参阅官方网站https://agvpreid25.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification (ReID) across aerial and ground vantage points hasbecome crucial for large-scale surveillance and public safety applications.Although significant progress has been made in ground-only scenarios, bridgingthe aerial-ground domain gap remains a formidable challenge due to extremeviewpoint differences, scale variations, and occlusions. Building upon theachievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID2025 Challenge - the first large-scale video-based competition focused onhigh-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReIDdataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7million frames captured from UAVs, CCTV, and wearable cameras, the challengefeatured four international teams. These teams developed solutions ranging frommulti-stream architectures to transformer-based temporal reasoning andphysics-informed modeling. The leading approach, X-TFCLIP from UAM, attained72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in theground-to-aerial ReID setting, surpassing existing baselines while highlightingthe dataset's complexity. For additional details, please refer to the officialwebsite at https://agvpreid25.github.io.</description>
      <author>example@mail.com (Kien Nguyen, Clinton Fookes, Sridha Sridharan, Huy Nguyen, Feng Liu, Xiaoming Liu, Arun Ross, Dana Michalski, Tamás Endrei, Ivan DeAndres-Tame, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez, Javier Ortega-Garcia, Zijing Gong, Yuhao Wang, Xuehu Liu, Pingping Zhang, Md Rashidunnabi, Hugo Proença, Kailash A. Hambarde, Saeid Rezaei)</author>
      <guid isPermaLink="false">2506.22843v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Synergizing Implicit and Explicit User Interests: A Multi-Embedding Retrieval Framework at Pinterest</title>
      <link>http://arxiv.org/abs/2506.23060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多嵌入检索框架，旨在提高工业推荐系统中检索阶段的性能，特别是在覆盖广泛且多样化的用户兴趣方面。&lt;h4&gt;背景&lt;/h4&gt;工业推荐系统通常由检索、排名和混合等多个阶段组成。检索阶段在生成包含广泛用户兴趣的候选项目集中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;解决传统两塔模型在用户-物品特征交互有限和对顶级用例存在偏差的问题。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括使用可微聚类模块（DCM）从用户历史中捕获隐式兴趣，以及通过条件检索（CR）对用户已关注的主题等显式兴趣进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;通过结合隐式和显式用户兴趣，实现了更有效和全面的候选检索，对不同的用户群体有益，并从不同但补充的来源提取条件。&lt;h4&gt;结论&lt;/h4&gt;实验和A/B测试表明，该框架在用户参与度和内容多样性指标方面有显著提升，已在Pinterest首页成功部署。&lt;h4&gt;翻译&lt;/h4&gt;摘要：工业推荐系统通常由多个阶段组成，包括检索、排名和混合。检索阶段在生成涵盖广泛多样化用户兴趣的候选项目集中起着关键作用。在此阶段有效地覆盖多样化的长尾用户兴趣是一个重大挑战：传统的两塔模型在这方面存在困难，因为它们在用户-物品特征交互方面有限，并且往往偏向于顶级用例。为了解决这些问题，我们提出了一种新的多嵌入检索框架，旨在通过生成基于隐式和显式用户兴趣的多用户嵌入来增强用户兴趣表示。隐式兴趣通过可微聚类模块（DCM）从用户历史中捕获，而显式兴趣，如用户已关注的主题，通过条件检索（CR）进行建模。这些方法代表了一种条件用户表示学习方法，涉及条件表示构建和将目标物品与相关条件关联。协同隐式和显式用户兴趣作为补充方法，以更有效和全面地实现候选检索，因为它们对不同的用户群体有益，并从不同但补充的来源提取条件。广泛的实验和A/B测试揭示了用户参与度和内容多样性指标的显著改进。我们提出的框架已在Pinterest首页成功部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737265&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial recommendation systems are typically composed of multiple stages,including retrieval, ranking, and blending. The retrieval stage plays acritical role in generating a high-recall set of candidate items that covers awide range of diverse user interests. Effectively covering the diverse andlong-tail user interests within this stage poses a significant challenge:traditional two-tower models struggle in this regard due to limited user-itemfeature interaction and often bias towards top use cases. To address theseissues, we propose a novel multi-embedding retrieval framework designed toenhance user interest representation by generating multiple user embeddingsconditioned on both implicit and explicit user interests. Implicit interestsare captured from user history through a Differentiable Clustering Module(DCM), whereas explicit interests, such as topics that the user has followed,are modeled via Conditional Retrieval (CR). These methodologies represent aform of conditioned user representation learning that involves conditionrepresentation construction and associating the target item with the relevantconditions. Synergizing implicit and explicit user interests serves as acomplementary approach to achieve more effective and comprehensive candidateretrieval as they benefit on different user segments and extract conditionsfrom different but supplementary sources. Extensive experiments and A/B testingreveal significant improvements in user engagements and feed diversity metrics.Our proposed framework has been successfully deployed on Pinterest home feed.</description>
      <author>example@mail.com (Zhibo Fan, Hongtao Lin, Haoyu Chen, Bowen Deng, Hedi Xia, Yuke Yan, James Li)</author>
      <guid isPermaLink="false">2506.23060v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting</title>
      <link>http://arxiv.org/abs/2506.17609v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Short research paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TyphoFormer的新型框架，用于提高台风轨迹预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确的台风轨迹预测对于早期系统预警和灾害响应至关重要。现有的Transformer模型在建模密集轨迹方面表现出色，但在处理稀疏气象轨迹（如台风轨迹）时缺乏广泛的上下文知识。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出TyphoFormer框架，通过自然语言描述作为辅助提示来提高台风轨迹预测的可靠性。&lt;h4&gt;方法&lt;/h4&gt;对于每个时间步，使用大型语言模型（LLM）基于北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。TyphoFormer通过统一的Transformer编码器集成文本和序列信息，使模型能够利用通过数值特征无法获得的上下文线索。&lt;h4&gt;主要发现&lt;/h4&gt;在HURDAT2基准数据集上进行的广泛实验表明，TyphoFormer在非线性路径变化和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;h4&gt;结论&lt;/h4&gt;TyphoFormer框架能够有效提高台风轨迹预测的准确性，为早期预警和灾害响应提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate typhoon track forecasting is crucial for early system warning and disaster response. While Transformer-based models have demonstrated strong performance in modeling the temporal dynamics of dense trajectories of humans and vehicles in smart cities, they usually lack access to broader contextual knowledge that enhances the forecasting reliability of sparse meteorological trajectories, such as typhoon tracks. To address this challenge, we propose TyphoFormer, a novel framework that incorporates natural language descriptions as auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textual descriptions based on the numerical attributes recorded in the North Atlantic hurricane database. The language descriptions capture high-level meteorological semantics and are embedded as auxiliary special tokens prepended to the numerical time series input. By integrating both textual and sequential information within a unified Transformer encoder, TyphoFormer enables the model to leverage contextual cues that are otherwise inaccessible through numerical features alone. Extensive experiments are conducted on HURDAT2 benchmark, results show that TyphoFormer consistently outperforms other state-of-the-art baseline methods, particularly under challenging scenarios involving nonlinear path shifts and limited historical observations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate typhoon track forecasting is crucial for early system warning anddisaster response. While Transformer-based models have demonstrated strongperformance in modeling the temporal dynamics of dense trajectories of humansand vehicles in smart cities, they usually lack access to broader contextualknowledge that enhances the forecasting reliability of sparse meteorologicaltrajectories, such as typhoon tracks. To address this challenge, we proposeTyphoFormer, a novel framework that incorporates natural language descriptionsas auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textualdescriptions based on the numerical attributes recorded in the North Atlantichurricane database. The language descriptions capture high-level meteorologicalsemantics and are embedded as auxiliary special tokens prepended to thenumerical time series input. By integrating both textual and sequentialinformation within a unified Transformer encoder, TyphoFormer enables the modelto leverage contextual cues that are otherwise inaccessible through numericalfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,results show that TyphoFormer consistently outperforms other state-of-the-artbaseline methods, particularly under challenging scenarios involving nonlinearpath shifts and limited historical observations.</description>
      <author>example@mail.com (Lincan Li, Eren Erman Ozguven, Yue Zhao, Guang Wang, Yiqun Xie, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17609v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions</title>
      <link>http://arxiv.org/abs/2506.22926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE VIS 2025 Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于XR技术的系统，用于改善医疗数据可视化与探索，特别是对于医学知识有限的人员。&lt;h4&gt;背景&lt;/h4&gt;体积医学成像技术可以产生详细的3D解剖结构图像，但有效的医学数据可视化和探索对医学专业知识要求较高。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够增强空间理解并减少认知负荷的XR系统。&lt;h4&gt;方法&lt;/h4&gt;系统包括两个主要创新：(1) 协调的视觉模块，结合多层多平面重建和3D网格模型；(2) 多模式交互框架，结合手势和基于LLM（大型语言模型）的语音命令。通过15名参与者的用户研究和专家访谈进行初步评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，任务完成时间、可用性指标和交互有效性均有所提高，特别是在LLM驱动的语音控制下。&lt;h4&gt;结论&lt;/h4&gt;该沉浸式可视化系统有潜力提高医学培训和临床实践。&lt;h4&gt;翻译&lt;/h4&gt;Volumetric medical imaging technologies produce detailed 3D representations of anatomical structures. However, effective medical data visualization and exploration pose significant challenges, especially for individuals with limited medical expertise. We introduce a novel XR-based system with two key innovations: (1) a coordinated visualization module integrating Multi-layered Multi-planar Reconstruction with 3D mesh models and (2) a multimodal interaction framework combining hand gestures with LLM-enabled voice commands. We conduct preliminary evaluations, including a 15-participant user study and expert interviews, to demonstrate the system's abilities to enhance spatial understanding and reduce cognitive load. Experimental results show notable improvements in task completion times, usability metrics, and interaction effectiveness enhanced by LLM-driven voice control. While identifying areas for future refinement, our findings highlight the potential of this immersive visualization system to advance medical training and clinical practice. Our demo application and supplemental materials are available for download at: https://osf.io/bpjq5/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Volumetric medical imaging technologies produce detailed 3D representationsof anatomical structures. However, effective medical data visualization andexploration pose significant challenges, especially for individuals withlimited medical expertise. We introduce a novel XR-based system with two keyinnovations: (1) a coordinated visualization module integrating Multi-layeredMulti-planar Reconstruction with 3D mesh models and (2) a multimodalinteraction framework combining hand gestures with LLM-enabled voice commands.We conduct preliminary evaluations, including a 15-participant user study andexpert interviews, to demonstrate the system's abilities to enhance spatialunderstanding and reduce cognitive load. Experimental results show notableimprovements in task completion times, usability metrics, and interactioneffectiveness enhanced by LLM-driven voice control. While identifying areas forfuture refinement, our findings highlight the potential of this immersivevisualization system to advance medical training and clinical practice. Ourdemo application and supplemental materials are available for download at:https://osf.io/bpjq5/.</description>
      <author>example@mail.com (Qixuan Liu, Shi Qiu, Yinqiao Wang, Xiwen Wu, Kenneth Siu Ho Chok, Chi-Wing Fu, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2506.22926v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval</title>
      <link>http://arxiv.org/abs/2506.23605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages including supplementary, accepted at ICDAR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的合成讲座幻灯片生成流程（SynLecSlideGen），用于解决讲座幻灯片元素检测和检索问题，并通过实验验证了合成数据在提高模型性能方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;讲座幻灯片元素检测和检索是幻灯片理解的关键问题，而训练有效的模型通常需要大量的手动标注，这既费时又需要专业知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来生成高质量的合成讲座幻灯片，以减少对大量手动标注的需求，并提高模型在真实数据上的性能。&lt;h4&gt;方法&lt;/h4&gt;开发了SynLecSlideGen流程，用于生成高质量的合成讲座幻灯片，并创建了一个名为RealSlide的评估基准，通过手动标注1,050张真实讲座幻灯片。使用在合成幻灯片上预训练的模型进行少样本迁移学习，以评估合成幻灯片的实用性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与仅使用真实数据进行训练相比，在合成幻灯片上预训练的少样本迁移学习显著提高了性能，证明了合成数据可以有效地弥补标注讲座幻灯片的数量限制。&lt;h4&gt;结论&lt;/h4&gt;合成数据可以有效地补偿有限的标注讲座幻灯片，有助于提高讲座幻灯片元素检测和检索模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, to address the key problems of lecture slide element detection and retrieval. The experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data, demonstrating the effectiveness of synthetic data in compensating for limited labeled lecture slides.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lecture slide element detection and retrieval are key problems in slideunderstanding. Training effective models for these tasks often depends onextensive manual annotation. However, annotating large volumes of lectureslides for supervised training is labor intensive and requires domainexpertise. To address this, we propose a large language model (LLM)-guidedsynthetic lecture slide generation pipeline, SynLecSlideGen, which produceshigh-quality, coherent and realistic slides. We also create an evaluationbenchmark, namely RealSlide by manually annotating 1,050 real lecture slides.To assess the utility of our synthetic slides, we perform few-shot transferlearning on real data using models pre-trained on them. Experimental resultsshow that few-shot transfer learning with pretraining on synthetic slidessignificantly improves performance compared to training only on real data. Thisdemonstrates that synthetic data can effectively compensate for limited labeledlecture slides. The code and resources of our work are publicly available onour project website: https://synslidegen.github.io/.</description>
      <author>example@mail.com (Suyash Maniyar, Vishvesh Trivedi, Ajoy Mondal, Anand Mishra, C. V. Jawahar)</author>
      <guid isPermaLink="false">2506.23605v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.22817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MVOV3D的新方法，旨在通过减少视觉-语言模型中的内在噪声，提升2D多视图融合在开放词汇3D场景理解中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的开放词汇3D场景理解方法主要依赖于对比学习或2D特征蒸馏，但这些方法在处理多样化的物体类别时表现不佳，因为训练强开放词汇3D模型的数据量有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以增强开放词汇3D场景理解的能力，同时保持模型的泛化性。&lt;h4&gt;方法&lt;/h4&gt;MVOV3D通过利用CLIP编码器生成的精确区域级图像特征和文本特征，改进多视图2D特征，并引入3D几何先验来优化多视图融合。&lt;h4&gt;主要发现&lt;/h4&gt;MVOV3D在多个数据集上的实验表明了其有效性，并在ScanNet200和Matterport160数据集上实现了新的记录，分别达到14.7%和16.2%的mIoU，显著优于现有的3D网络。&lt;h4&gt;结论&lt;/h4&gt;MVOV3D通过减少视觉-语言模型中的噪声，提高了2D多视图融合在开放词汇3D场景理解中的性能，为该领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent open-vocabulary 3D scene understanding approaches mainly focus ontraining 3D networks through contrastive learning with point-text pairs or bydistilling 2D features into 3D models via point-pixel alignment. While thesemethods show considerable performance in benchmarks with limited vocabularies,they struggle to handle diverse object categories as the limited amount of 3Ddata upbound training strong open-vocabulary 3d models. We observe that 2Dmulti-view fusion methods take precedence in understanding diverse concepts in3D scenes. However, inherent noises in vision-language models lead multi-viewfusion to sub-optimal performance. To this end, we introduce MVOV3D, a novelapproach aimed at unleashing the potential of 2D multi-view fusion foropen-vocabulary 3D scene understanding. We focus on reducing the inherentnoises without training, thereby preserving the generalizability whileenhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2Dfeatures by leveraging precise region-level image features and text featuresencoded by CLIP encoders and incorporates 3D geometric priors to optimizemulti-view fusion. Extensive experiments on various datasets demonstrate theeffectiveness of our method. Notably, our MVOV3D achieves a new record with14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challengeopen-vocabulary semantic segmentation, outperforming current leading trained 3Dnetworks by a significant margin.</description>
      <author>example@mail.com (Xingyilang Yin, Jiale Wang, Xi Yang, Mutian Xu, Xu Gu, Nannan Wang)</author>
      <guid isPermaLink="false">2506.22817v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model</title>
      <link>http://arxiv.org/abs/2506.23210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages,14 equation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于参考模型的联邦学习方法，旨在优化人工智能模型训练，同时确保用户隐私。&lt;h4&gt;背景&lt;/h4&gt;联邦学习用于分布式场景中训练人工智能模型，同时确保用户隐私，但在模型性能上可能无法满足用户期望，且难以满足所有用户需求。&lt;h4&gt;目的&lt;/h4&gt;通过模型优化、微调和个性化，实现最佳模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于参考模型的联邦学习方法，该方法通过使用包含先前模型参数的参考模型，克服了每次迭代中的灾难性遗忘问题，并通过贝叶斯参数高效的迁移学习来实现。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了高模型性能和低计算成本。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了联邦学习中模型优化的问题，提高了模型性能，并降低了计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning(FL) is used for distributed scenarios to train artificialintelligence(AI) models while ensuring users' privacy. In federated learningscenario, the server generally never knows about users' data. This type ofconcept makes the AI training process efficient in terms of data privacy.However, regarding model performance, federated AI models may not sufficientlysatisfy AI users' expectations. Furthermore, AI users have a wide range ofdifferent needs. It is not easy to satisfy the whole users needs. These typesof issues can be addressed through AI model optimization, fine-tuning, orpersonalization to achieve optimal model performance. To address modeloptimization challenges, we propose reference model-based federated learningfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.This method is derived from Bayesian parameter-efficient transfer learning,which includes an optimal proximal term and enables overcoming the catastrophicforgetting issue in each round by utilizing a reference model that incorporatesprevious model parameters. As a result, this method achieves both high modelperformance and low computing cost.</description>
      <author>example@mail.com (Taehwan Yoon, Bongjun Choi)</author>
      <guid isPermaLink="false">2506.23210v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions</title>
      <link>http://arxiv.org/abs/2506.23236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  [ICCV 2025] https://markomih.github.io/VolumetricSMPL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VolumetricSMPL是一种基于神经体积的体模型，通过使用神经网络混合权重（NBW）来生成紧凑且高效的MLP解码器，提高了计算效率和表达性。&lt;h4&gt;背景&lt;/h4&gt;参数化人体模型在计算机图形学和视觉中扮演着关键角色，但传统的表面网格模型在处理与其他几何实体（如物体和场景）的交互时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出VolumetricSMPL以解决现有体积神经隐式体模型在复杂人体运动和计算成本方面的不足。&lt;h4&gt;方法&lt;/h4&gt;VolumetricSMPL使用NBW动态混合少量学习的权重矩阵，使用预测的形状和姿态依赖系数，从而提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;VolumetricSMPL在推理速度、GPU内存使用、准确性和接触建模方面优于先前的体积占用模型COAP，并在四个挑战性任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;VolumetricSMPL具有广泛的应用性，并在性能和效率方面取得了显著提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：参数化人体模型在计算机图形学和视觉中发挥着至关重要的作用，它们使从人体运动分析到理解人-环境交互的应用成为可能。传统上，这些模型使用表面网格，这在处理与其他几何实体（如物体和场景，通常表示为网格或点云）的交互时带来了挑战。为了解决这一限制，最近的研究探索了体积神经隐式体模型。然而，现有工作要么在处理复杂人体运动时不够鲁棒，要么对计算和内存成本要求很高，限制了它们的广泛应用。为此，我们引入了VolumetricSMPL，这是一种利用神经网络混合权重（NBW）生成紧凑且高效的MLP解码器的神经体积体模型。与依赖于大型MLP的先前方法不同，NBW动态混合使用预测的形状和姿态依赖系数的一小套学习权重矩阵，显著提高了计算效率，同时保持了表达性。VolumetricSMPL在推理速度、GPU内存使用、准确性和有符号距离函数（SDF）方面优于先前的体积占用模型COAP，实现了10倍快的推理速度、6倍低的GPU内存使用、更高的准确性和高效的、可微分的接触建模。我们在四个具有挑战性的任务中展示了VolumetricSMPL的优势：（1）从野外图像中重建人-物交互，（2）从自视角中恢复3D场景中的人体网格，（3）场景约束的运动合成，（4）解决自相交问题。我们的结果突出了其广泛的应用性和在性能和效率方面的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parametric human body models play a crucial role in computer graphics andvision, enabling applications ranging from human motion analysis tounderstanding human-environment interactions. Traditionally, these models usesurface meshes, which pose challenges in efficiently handling interactions withother geometric entities, such as objects and scenes, typically represented asmeshes or point clouds. To address this limitation, recent research hasexplored volumetric neural implicit body models. However, existing works areeither insufficiently robust for complex human articulations or impose highcomputational and memory costs, limiting their widespread use. To this end, weintroduce VolumetricSMPL, a neural volumetric body model that leverages NeuralBlend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlikeprior approaches that rely on large MLPs, NBW dynamically blends a small set oflearned weight matrices using predicted shape- and pose-dependent coefficients,significantly improving computational efficiency while preservingexpressiveness. VolumetricSMPL outperforms prior volumetric occupancy modelCOAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,and a Signed Distance Function (SDF) for efficient and differentiable contactmodeling. We demonstrate VolumetricSMPL's strengths across four challengingtasks: (1) reconstructing human-object interactions from in-the-wild images,(2) recovering human meshes in 3D scenes from egocentric views, (3)scene-constrained motion synthesis, and (4) resolving self-intersections. Ourresults highlight its broad applicability and significant performance andefficiency gains.</description>
      <author>example@mail.com (Marko Mihajlovic, Siwei Zhang, Gen Li, Kaifeng Zhao, Lea Müller, Siyu Tang)</author>
      <guid isPermaLink="false">2506.23236v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Confidence Paradox: Can LLM Know When It's Wrong</title>
      <link>http://arxiv.org/abs/2506.23464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HonestVQA，一个用于道德对齐的文档视觉问答（DocVQA）的自监督诚实校准框架，旨在解决现有DocVQA系统在道德响应方面的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管文档视觉问答系统在现实世界中得到广泛应用，但它们在道德上往往是透明的，经常对模糊的问题给出过于自信的答案，或者无法以可信的方式传达不确定性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了HonestVQA，旨在提高DocVQA系统的道德响应能力。&lt;h4&gt;方法&lt;/h4&gt;HonestVQA通过量化不确定性来识别知识差距，使用加权损失函数将模型置信度与实际正确性对齐，并通过对比学习强制执行道德响应行为。此外，还引入了两个原则性的评估指标——诚实分数（H-Score）和道德置信度指数（ECI）。&lt;h4&gt;主要发现&lt;/h4&gt;实证研究表明，HonestVQA在SpDocVQA、InfographicsVQA和SROIE数据集上提高了DocVQA的准确性和F1分数，减少了过度自信，降低了H-Score和ECI。在跨领域评估中，它实现了高达78.9%的准确率和76.1%的F1分数，显示出强大的泛化能力。消融实验表明，在没有对齐或对比损失的情况下，准确率下降了3.8%。&lt;h4&gt;结论&lt;/h4&gt;HonestVQA通过提高道德响应能力和准确性，为DocVQA系统提供了一种更可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Document Visual Question Answering (DocVQA) systems are increasingly deployedin real world applications, yet they remain ethically opaque-often producingoverconfident answers to ambiguous questions or failing to communicateuncertainty in a trustworthy manner. This misalignment between model confidenceand actual knowledge poses significant risks, particularly in domains requiringethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUThave advanced SOTA performance by focusing on architectural sophistication andaccuracy; however, they fall short in ethical responsiveness.  To address these limitations, we introduce HonestVQA, a self-supervisedhonesty calibration framework for ethically aligned DocVQA. Our model-agnosticmethod quantifies uncertainty to identify knowledge gaps, aligns modelconfidence with actual correctness using weighted loss functions, and enforcesethical response behavior via contrastive learning. We further introduce twoprincipled evaluation metrics--Honesty Score (H-Score) and Ethical ConfidenceIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethicalcommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reducesoverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. Incross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,demonstrating strong generalization. Ablation shows a 3.8% drop in accuracywithout alignment or contrastive loss.</description>
      <author>example@mail.com (Sahil Tripathi, Md Tabrez Nafis, Imran Hussain, Jiechao Gao)</author>
      <guid isPermaLink="false">2506.23464v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.22799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VoteSplat是一种新的3D场景理解框架，它结合了Hough投票和3D Gaussian Splatting技术，用于高质实时渲染3D场景的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景渲染方法主要关注几何和外观建模，缺乏对场景的深层理解，并且训练成本高，复杂了原本的微分渲染流程。&lt;h4&gt;目的&lt;/h4&gt;提出VoteSplat框架，以实现更深入的3D场景理解，同时降低训练成本。&lt;h4&gt;方法&lt;/h4&gt;VoteSplat使用Segment Anything Model进行实例分割，提取物体并生成2D投票图。将空间偏移向量嵌入到高斯基元中，通过关联2D图像投票构建3D空间投票，并使用深度扭曲约束来优化深度方向上的定位。对于开放词汇的物体定位，VoteSplat通过投票点将2D图像语义映射到3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;VoteSplat在开放词汇的3D实例定位、3D点云理解、基于点击的3D物体定位、分层分割和消融研究中显示出有效性。&lt;h4&gt;结论&lt;/h4&gt;VoteSplat是一种有效的3D场景理解框架，能够提高3D场景渲染的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯散布（3DGS）已成为高质量、实时渲染3D场景新视角合成的主要动力。然而，现有方法主要关注几何和外观建模，缺乏对场景的深层理解，同时训练成本高，复杂了原本的微分渲染流程。为此，我们提出了VoteSplat，一种结合Hough投票和3DGS的新型3D场景理解框架。具体来说，使用Segment Anything Model进行实例分割，提取物体并生成2D投票图。然后将空间偏移向量嵌入到高斯基元中，通过关联2D图像投票构建3D空间投票，同时使用深度扭曲约束来优化深度方向上的定位。对于开放词汇的物体定位，VoteSplat通过投票点将2D图像语义映射到3D点云，降低了与高维CLIP特征相关的训练成本，同时保持了语义的明确性。大量实验表明，VoteSplat在开放词汇的3D实例定位、3D点云理解、基于点击的3D物体定位、分层分割和消融研究中具有有效性。我们的代码可在https://sy-ja.github.io/votesplat/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-timerendering for novel view synthesis of 3D scenes. However, existing methodsfocus primarily on geometric and appearance modeling, lacking deeper sceneunderstanding while also incurring high training costs that complicate theoriginally streamlined differentiable rendering pipeline. To this end, wepropose VoteSplat, a novel 3D scene understanding framework that integratesHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilizedfor instance segmentation, extracting objects, and generating 2D vote maps. Wethen embed spatial offset vectors into Gaussian primitives. These offsetsconstruct 3D spatial votes by associating them with 2D image votes, while depthdistortion constraints refine localization along the depth axis. Foropen-vocabulary object localization, VoteSplat maps 2D image semantics to 3Dpoint clouds via voting points, reducing training costs associated withhigh-dimensional CLIP features while preserving semantic unambiguity. Extensiveexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3Dinstance localization, 3D point cloud understanding, click-based 3D objectlocalization, hierarchical segmentation, and ablation studies. Our code isavailable at https://sy-ja.github.io/votesplat/</description>
      <author>example@mail.com (Minchao Jiang, Shunyu Jia, Jiaming Gu, Xiaoyuan Lu, Guangming Zhu, Anqi Dong, Liang Zhang)</author>
      <guid isPermaLink="false">2506.22799v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.23700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了MedSAM-CA，一种基于深度学习的医学图像分割方法，旨在解决医疗图像分割中的两大挑战：数据获取困难和复杂场景下的分割难题。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割对于临床诊断和治疗计划至关重要，但现有方法依赖于大量标注数据，且难以处理低对比度或边界模糊的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MedSAM-CA，通过架构级微调，减少对大量人工标注数据的依赖，并提高复杂场景下的分割精度。&lt;h4&gt;方法&lt;/h4&gt;MedSAM-CA引入了CBR-Net和Atte-FFB两个关键组件。CBR-Net通过并行操作恢复被长距离注意力机制忽略的边界信息。Atte-FFB则融合来自CBR-Net的多级精细特征和来自解码器的全局表示，以增强边界划分的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上的实验验证了MedSAM-CA的有效性，在低资源临床环境下表现出强大的效果。&lt;h4&gt;结论&lt;/h4&gt;MedSAM-CA通过减少对大量标注数据的依赖，显著提高了医学图像分割的准确性和效率，为临床应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Medical image segmentation plays a crucial role in clinical diagnosis and treatment planning, where accurate boundary delineation is essential for precise lesion localization, organ identification, and quantitative assessment. In recent years, deep learning-based methods have significantly advanced segmentation accuracy. However, two major challenges remain. First, the performance of these methods heavily relies on large-scale annotated datasets, which are often difficult to obtain in medical scenarios due to privacy concerns and high annotation costs. Second, clinically challenging scenarios, such as low contrast in certain imaging modalities and blurry lesion boundaries caused by malignancy, still pose obstacles to precise segmentation. To address these challenges, we propose MedSAM-CA, an architecture-level fine-tuning approach that mitigates reliance on extensive manual annotations by adapting the pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA introduces two key components: the Convolutional Attention-Enhanced Boundary Refinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block (Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover boundary information potentially overlooked by long-range attention mechanisms, leveraging hierarchical convolutional processing. Atte-FFB, embedded in the MedSAM decoder, fuses multi-level fine-grained features from skip connections in CBR-Net with global representations upsampled within the decoder to enhance boundary delineation accuracy. Experiments on publicly available datasets covering dermoscopy, CT, and MRI imaging modalities validate the effectiveness of MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only 2% of full training data, reaching 97.25% of full-data training performance, demonstrating strong effectiveness in low-resource clinical settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation plays a crucial role in clinical diagnosis andtreatment planning, where accurate boundary delineation is essential forprecise lesion localization, organ identification, and quantitative assessment.In recent years, deep learning-based methods have significantly advancedsegmentation accuracy. However, two major challenges remain. First, theperformance of these methods heavily relies on large-scale annotated datasets,which are often difficult to obtain in medical scenarios due to privacyconcerns and high annotation costs. Second, clinically challenging scenarios,such as low contrast in certain imaging modalities and blurry lesion boundariescaused by malignancy, still pose obstacles to precise segmentation. To addressthese challenges, we propose MedSAM-CA, an architecture-level fine-tuningapproach that mitigates reliance on extensive manual annotations by adaptingthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CAintroduces two key components: the Convolutional Attention-Enhanced BoundaryRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recoverboundary information potentially overlooked by long-range attention mechanisms,leveraging hierarchical convolutional processing. Atte-FFB, embedded in theMedSAM decoder, fuses multi-level fine-grained features from skip connectionsin CBR-Net with global representations upsampled within the decoder to enhanceboundary delineation accuracy. Experiments on publicly available datasetscovering dermoscopy, CT, and MRI imaging modalities validate the effectivenessof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only2% of full training data, reaching 97.25% of full-data training performance,demonstrating strong effectiveness in low-resource clinical settings.</description>
      <author>example@mail.com (Peiting Tian, Xi Chen, Haixia Bi, Fan Li)</author>
      <guid isPermaLink="false">2506.23700v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.23126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，用于提高机器人操作的普遍性。该模型通过捕捉机器人动作条件下环境演化的物理基础，直接从真实机器人感知数据中学习，无需复杂的场景重建。&lt;h4&gt;背景&lt;/h4&gt;现有的3D世界模型主要依赖于基于粒子的图神经网络模型，并限于单材料动力学，同时需要耗时进行3D场景重建以获取3D粒子轨迹用于训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多材料、多物体交互的3D世界模型，以提升机器人在实际环境中的操作能力。&lt;h4&gt;方法&lt;/h4&gt;ParticleFormer使用混合点云重建损失进行训练，监督全局和局部动力学特征。模型能够捕捉刚性、可变形和柔性材料之间的精细多物体交互，并直接从真实世界机器人感知数据中训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在3D场景预测任务和下游操作任务中均表现出有效性，并在六个模拟和三个真实世界实验中优于现有基准，实现了更优的动力学预测精度和更少的 rollout 错误。&lt;h4&gt;结论&lt;/h4&gt;ParticleFormer为通用机器人操作提供了一种有前景的方法，通过提高动力学预测的准确性，减少了下游视觉运动任务中的错误。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，旨在提高机器人在实际环境中的操作能力。该模型通过直接从真实机器人感知数据中学习，捕捉了机器人动作条件下环境演化的物理基础，无需复杂的场景重建。实验表明，该模型在3D场景预测任务和下游操作任务中均表现出优越性，实现了更优的动力学预测精度和更少的 rollout 错误，为通用机器人操作提供了一种有前景的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D world models (i.e., learning-based 3D dynamics models) offer a promisingapproach to generalizable robotic manipulation by capturing the underlyingphysics of environment evolution conditioned on robot actions. However,existing 3D world models are primarily limited to single-material dynamicsusing a particle-based Graph Neural Network model, and often requiretime-consuming 3D scene reconstruction to obtain 3D particle tracks fortraining. In this work, we present ParticleFormer, a Transformer-based pointcloud world model trained with a hybrid point cloud reconstruction loss,supervising both global and local dynamics features in multi-material,multi-object robot interactions. ParticleFormer captures fine-grainedmulti-object interactions between rigid, deformable, and flexible materials,trained directly from real-world robot perception data without an elaboratescene reconstruction. We demonstrate the model's effectiveness both in 3D sceneforecasting tasks, and in downstream manipulation tasks using a ModelPredictive Control (MPC) policy. In addition, we extend existing dynamicslearning benchmarks to include diverse multi-material, multi-object interactionscenarios. We validate our method on six simulation and three real-worldexperiments, where it consistently outperforms leading baselines by achievingsuperior dynamics prediction accuracy and less rollout error in downstreamvisuomotor tasks. Experimental videos are available athttps://particleformer.github.io/.</description>
      <author>example@mail.com (Suning Huang, Qianzhong Chen, Xiaohan Zhang, Jiankai Sun, Mac Schwager)</author>
      <guid isPermaLink="false">2506.23126v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.23460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLDF的新方法，用于弱监督语义分割，通过对比学习训练像素解码器，将条件扩散模型（CDM）的扩散特征映射到低维嵌入空间，以提高分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的基于CAM的弱监督语义分割方法在处理部分激活和不精确的对象边界时存在困难，而CDM作为一种替代方法，在生成分割掩码时表现出强大的图像生成能力。&lt;h4&gt;目的&lt;/h4&gt;提出CLDF方法以解决CDM在生成分割掩码时产生的噪声问题，并提高分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;CLDF通过对比学习训练一个像素解码器，将CDM的扩散特征映射到低维嵌入空间，同时结合CDM外部分类器生成的梯度图和CAM来识别前景和背景像素，减少对比学习中的误判。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开医疗数据集上的四个分割任务中，CLDF方法显著优于现有的基线方法。&lt;h4&gt;结论&lt;/h4&gt;CLDF方法通过改进CDM的噪声问题，有效地提高了弱监督语义分割的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Weakly supervised semantic segmentation (WSSS) methods using class labels often rely on class activation maps (CAMs) to localize objects. However, traditional CAM-based methods struggle with partial activations and imprecise object boundaries due to optimization discrepancies between classification and segmentation. Recently, the conditional diffusion model (CDM) has been used as an alternative for generating segmentation masks in WSSS, leveraging its strong image generation capabilities tailored to specific class distributions. By modifying or perturbing the condition during diffusion sampling, the related objects can be highlighted in the generated images. Yet, the saliency maps generated by CDMs are prone to noise from background alterations during reversed diffusion. To alleviate the problem, we introduce Contrastive Learning with Diffusion Features (CLDF), a novel method that uses contrastive learning to train a pixel decoder to map the diffusion features from a frozen CDM to a low-dimensional embedding space for segmentation. Specifically, we integrate gradient maps generated from CDM external classifier with CAMs to identify foreground and background pixels with fewer false positives/negatives for contrastive learning, enabling robust pixel embedding learning. Experimental results on four segmentation tasks from two public medical datasets demonstrate that our method significantly outperforms existing baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weakly supervised semantic segmentation (WSSS) methods using class labelsoften rely on class activation maps (CAMs) to localize objects. However,traditional CAM-based methods struggle with partial activations and impreciseobject boundaries due to optimization discrepancies between classification andsegmentation. Recently, the conditional diffusion model (CDM) has been used asan alternative for generating segmentation masks in WSSS, leveraging its strongimage generation capabilities tailored to specific class distributions. Bymodifying or perturbing the condition during diffusion sampling, the relatedobjects can be highlighted in the generated images. Yet, the saliency mapsgenerated by CDMs are prone to noise from background alterations during reversediffusion. To alleviate the problem, we introduce Contrastive Learning withDiffusion Features (CLDF), a novel method that uses contrastive learning totrain a pixel decoder to map the diffusion features from a frozen CDM to alow-dimensional embedding space for segmentation. Specifically, we integrategradient maps generated from CDM external classifier with CAMs to identifyforeground and background pixels with fewer false positives/negatives forcontrastive learning, enabling robust pixel embedding learning. Experimentalresults on four segmentation tasks from two public medical datasets demonstratethat our method significantly outperforms existing baselines.</description>
      <author>example@mail.com (Dewen Zeng, Xinrong Hu, Yu-Jen Chen, Yawen Wu, Xiaowei Xu, Yiyu Shi)</author>
      <guid isPermaLink="false">2506.23460v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization</title>
      <link>http://arxiv.org/abs/2506.22952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究通过功能性磁共振成像（fMRI）理解大脑动态，提出了基于层次状态空间标记的HST网络，用于量化大脑状态和过渡，并在两个公开fMRI数据集上验证了其有效性和潜在应用。&lt;h4&gt;背景&lt;/h4&gt;理解大脑动态是神经科学中的一个基本挑战，尤其是捕捉大脑在不同功能状态之间的转换。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来量化复杂的脑信号，以便进行可解释的离散化表示。&lt;h4&gt;方法&lt;/h4&gt;引入了一种层次状态空间标记的HST网络，结合了改进的聚类向量量化变分自动编码器（VQ-VAE）来提高量化性能，同时促进脑状态和过渡的代表性标记。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在量化大脑的层次动态方面表现出有效性，并在疾病诊断和重建性能方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为脑动态的特征描述提供了一个有前景的框架，有助于分析脑状态的亚稳态。&lt;h4&gt;翻译&lt;/h4&gt;通过功能性磁共振成像（fMRI）理解大脑动态仍然是在神经科学中的一个基本挑战，尤其是在捕捉大脑在多种功能状态之间转换的过程中。最近，亚稳态，即指暂时稳定的脑状态，提供了一种有前景的范式来量化复杂的脑信号为可解释的、离散化的表示。特别是，与基于聚类的机器学习方法相比，利用向量量化进行标记化的方法在表示学习方面显示出潜力，具有强大的重建和预测能力。然而，大多数现有的方法忽略了脑过渡依赖性，并且缺乏将脑动态量化为代表性且稳定的嵌入的量化。在本研究中，我们提出了一种基于层次状态空间标记的标记网络，称为HST，它根据基于状态空间模型对脑状态和过渡进行分层量化。我们引入了一种改进的聚类向量量化变分自动编码器（VQ-VAE），它结合了量化误差反馈和聚类以提高量化性能，同时促进具有代表性且稳定的标记表示的亚稳态。我们在两个公开的fMRI数据集上验证了我们的HST，证明了它在量化大脑的层次动态方面的有效性，以及它在疾病诊断和重建性能方面的潜力。我们的方法为脑动态的特征描述提供了一个有前景的框架，有助于分析脑状态的亚稳态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding brain dynamics through functional Magnetic Resonance Imaging(fMRI) remains a fundamental challenge in neuroscience, particularly incapturing how the brain transitions between various functional states.Recently, metastability, which refers to temporarily stable brain states, hasoffered a promising paradigm to quantify complex brain signals intointerpretable, discretized representations. In particular, compared tocluster-based machine learning approaches, tokenization approaches leveragingvector quantization have shown promise in representation learning with powerfulreconstruction and predictive capabilities. However, most existing methodsignore brain transition dependencies and lack a quantification of braindynamics into representative and stable embeddings. In this study, we propose aHierarchical State space-based Tokenization network, termed HST, whichquantizes brain states and transitions in a hierarchical structure based on astate space-based model. We introduce a refined clustered Vector-QuantizationVariational AutoEncoder (VQ-VAE) that incorporates quantization error feedbackand clustering to improve quantization performance while facilitatingmetastability with representative and stable token representations. We validateour HST on two public fMRI datasets, demonstrating its effectiveness inquantifying the hierarchical dynamics of the brain and its potential in diseasediagnosis and reconstruction performance. Our method offers a promisingframework for the characterization of brain dynamics, facilitating the analysisof metastability.</description>
      <author>example@mail.com (Yanwu Yang, Thomas Wolfers)</author>
      <guid isPermaLink="false">2506.22952v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Towards Time Series Generation Conditioned on Unstructured Natural Language</title>
      <link>http://arxiv.org/abs/2506.22927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于非结构化自然语言描述生成时间序列的新方法。&lt;h4&gt;背景&lt;/h4&gt;尽管生成式人工智能在生成图像和文本等数据方面取得了显著进展，但时间序列生成式人工智能仍处于发展阶段。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种从文本生成时间序列的方法，并展示基于自然语言的时间序列生成是可行的。&lt;h4&gt;方法&lt;/h4&gt;研究采用了扩散模型与语言模型相结合的方法，从文本中生成时间序列。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以应用于定制预测、时间序列操作、数据增强和迁移学习等领域，并构建了一个包含63,010个时间序列-描述对的新公共数据集。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了基于自然语言的时间序列生成是可能的，并提出了一个有助于推动该领域发展的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative Artificial Intelligence (AI) has rapidly become a powerful tool,capable of generating various types of data, such as images and text. However,despite the significant advancement of generative AI, time series generative AIremains underdeveloped, even though the application of time series is essentialin finance, climate, and numerous fields. In this research, we propose a novelmethod of generating time series conditioned on unstructured natural languagedescriptions. We use a diffusion model combined with a language model togenerate time series from the text. Through the proposed method, we demonstratethat time series generation based on natural language is possible. The proposedmethod can provide various applications such as custom forecasting, time seriesmanipulation, data augmentation, and transfer learning. Furthermore, weconstruct and propose a new public dataset for time series generation,consisting of 63,010 time series-description pairs.</description>
      <author>example@mail.com (Jaeyun Woo, Jiseok Lee, Brian Kenji Iwana)</author>
      <guid isPermaLink="false">2506.22927v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction</title>
      <link>http://arxiv.org/abs/2506.23053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为Double-Diffusion的新型扩散概率模型，用于空气质量预测，并在实际数据集上取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;空气质量预测是一个具有时空复杂性和内在动态及不确定性的挑战性任务。&lt;h4&gt;目的&lt;/h4&gt;寻找在确定性和不确定性之间找到平衡点，提出一种新的模型来预测空气质量。&lt;h4&gt;方法&lt;/h4&gt;Double-Diffusion模型利用已知物理原理，结合随机性和概率网络（如扩散模型）来引导空气质量预测。&lt;h4&gt;主要发现&lt;/h4&gt;Double-Diffusion模型在大多数评估场景中排名第一，与现有概率模型相比，在两个真实数据集上表现优异；同时，该模型将推理时间减少了50%到30%，并在连续排名概率得分（CRPS）上提高了3%到12%。&lt;h4&gt;结论&lt;/h4&gt;Double-Diffusion模型为空气质量预测提供了一种新的方法，并显示出其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Air quality prediction is a challenging forecasting task due to its spatio-temporal complexity and the inherent dynamics as well as uncertainty. Most of the current models handle these two challenges by applying Graph Neural Networks or known physics principles, and quantifying stochasticity through probabilistic networks like Diffusion models. Nevertheless, finding the right balancing point between the certainties and uncertainties remains an open question. Therefore, we propose Double-Diffusion, a novel diffusion probabilistic model that harnesses the power of known physics to guide air quality forecasting with stochasticity. To the best of our knowledge, while precedents have been made of using conditional diffusion models to predict air pollution, this is the first attempt to use physics as a conditional generative approach for air quality prediction. Along with a sampling strategy adopted from image restoration and a new denoiser architecture, Double-Diffusion ranks first in most evaluation scenarios across two real-life datasets compared with other probabilistic models, it also cuts inference time by 50% to 30% while enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score (CRPS).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air quality prediction is a challenging forecasting task due to itsspatio-temporal complexity and the inherent dynamics as well as uncertainty.Most of the current models handle these two challenges by applying Graph NeuralNetworks or known physics principles, and quantifying stochasticity throughprobabilistic networks like Diffusion models. Nevertheless, finding the rightbalancing point between the certainties and uncertainties remains an openquestion. Therefore, we propose Double-Diffusion, a novel diffusionprobabilistic model that harnesses the power of known physics to guide airquality forecasting with stochasticity. To the best of our knowledge, whileprecedents have been made of using conditional diffusion models to predict airpollution, this is the first attempt to use physics as a conditional generativeapproach for air quality prediction. Along with a sampling strategy adoptedfrom image restoration and a new denoiser architecture, Double-Diffusion ranksfirst in most evaluation scenarios across two real-life datasets compared withother probabilistic models, it also cuts inference time by 50% to 30% whileenjoying an increase between 3-12% in Continuous Ranked Probabilistic Score(CRPS).</description>
      <author>example@mail.com (Hanlin Dong, Arian Prabowo, Hao Xue, Flora D. Salim)</author>
      <guid isPermaLink="false">2506.23053v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models</title>
      <link>http://arxiv.org/abs/2506.22865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ReasonBridge的方法，通过新颖的分层知识蒸馏框架，将强大闭源模型中的推理能力有效地迁移到开源模型中。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）在复杂推理和精确指令跟随任务上表现出显著的性能差距，尤其是闭源模型和开源模型之间的差距。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过ReasonBridge方法缩小闭源模型和开源模型在推理能力上的差距。&lt;h4&gt;方法&lt;/h4&gt;ReasonBridge方法包括：1）一个分层蒸馏过程，捕获战略抽象和战术实现模式；2）一个稀疏推理适配器架构，仅需额外0.3%的可训练参数；3）一个测试时计算缩放机制，使用引导推理干预。&lt;h4&gt;主要发现&lt;/h4&gt;ReasonBridge在基准任务上提高了开源模型的推理能力，最高可达23%，显著缩小了与闭源模型的差距。特别地，增强后的Qwen2.5-14B在MATH500任务上优于Claude-Sonnet3.5，在AIME竞赛级别问题上的表现与Claude-Sonnet3.5相当。&lt;h4&gt;结论&lt;/h4&gt;ReasonBridge方法在多个推理领域和模型架构中表现出良好的泛化能力，为指令跟随的推理增强提供了一种高效的样本高效方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) have revealed asignificant performance gap between closed-source and open-source models,particularly in tasks requiring complex reasoning and precise instructionfollowing. This paper introduces ReasonBridge, a methodology that efficientlytransfers reasoning capabilities from powerful closed-source to open-sourcemodels through a novel hierarchical knowledge distillation framework. Wedevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoningtraces emphasizing difficulty, diversity, and quality. These traces arefiltered from across multiple domains using a structured multi-criteriaselection algorithm. Our transfer learning approach incorporates: (1) ahierarchical distillation process capturing both strategic abstraction andtactical implementation patterns, (2) a sparse reasoning-focused adapterarchitecture requiring only 0.3% additional trainable parameters, and (3) atest-time compute scaling mechanism using guided inference interventions.Comprehensive evaluations demonstrate that ReasonBridge improves reasoningcapabilities in open-source models by up to 23% on benchmark tasks,significantly narrowing the gap with closed-source models. Notably, theenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches itsperformance on competition-level AIME problems. Our methodology generalizeseffectively across diverse reasoning domains and model architectures,establishing a sample-efficient approach to reasoning enhancement forinstruction following.</description>
      <author>example@mail.com (Ziqi Zhong, Xunzhu Tang)</author>
      <guid isPermaLink="false">2506.22865v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Prediction Gaps as Pathways to Explanation: Rethinking Educational Outcomes through Differences in Model Performance</title>
      <link>http://arxiv.org/abs/2506.22993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了社会环境如何影响生活结果，并提出了预测差距作为识别实证模式的方法，同时使用荷兰的行政数据进行研究。&lt;h4&gt;背景&lt;/h4&gt;社会环境如家庭、学校和邻里关系对生活结果有重要影响，但关键问题在于这些影响对不同人群和在不同条件下有何不同。&lt;h4&gt;目的&lt;/h4&gt;通过比较不同复杂度的统计模型，探讨预测差距是否能够揭示社会理论在哪些方面成功或不足。&lt;h4&gt;方法&lt;/h4&gt;使用荷兰的人口规模行政数据，比较了逻辑回归、梯度提升和图神经网络在预测大学完成情况时，早期社会环境的作用。&lt;h4&gt;主要发现&lt;/h4&gt;预测差距较小，表明先前识别的指标，尤其是父母状况，能够捕捉到教育成就的大部分可测量变化。然而，对于没有父亲的女孩，差距较大，表明社会环境对这些群体的影响超出了简单模型，与社会学理论相符。&lt;h4&gt;结论&lt;/h4&gt;本文展示了预测方法在支持社会学解释方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：社会环境——如家庭、学校和邻里——塑造生活结果。关键问题不仅仅是它们是否重要，而是对谁以及在不同条件下有何影响。在这里，我们认为预测差距——不同复杂度的统计模型之间的预测性能差异——为识别令人惊讶的实证模式（即未被简单模型捕获）提供了途径，这些模式突出了理论成功或不足的地方。我们使用荷兰的人口规模行政数据，比较了逻辑回归、梯度提升和图神经网络，以预测使用早期社会环境完成大学的情况。总体而言，预测差距很小，表明先前识别的指标，特别是父母状况，捕捉到了教育成就的大部分可测量变化。然而，对于没有父亲的女孩，差距较大，表明这些群体社会环境的影响超出了简单模型，与社会学理论相符。我们的论文展示了预测方法支持社会学解释的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social contexts -- such as families, schools, and neighborhoods -- shape lifeoutcomes. The key question is not simply whether they matter, but rather forwhom and under what conditions. Here, we argue that prediction gaps --differences in predictive performance between statistical models of varyingcomplexity -- offer a pathway for identifying surprising empirical patterns(i.e., not captured by simpler models) which highlight where theories succeedor fall short. Using population-scale administrative data from the Netherlands,we compare logistic regression, gradient boosting, and graph neural networks topredict university completion using early-life social contexts. Overall,prediction gaps are small, suggesting that previously identified indicators,particularly parental status, capture most measurable variation in educationalattainment. However, gaps are larger for girls growing up without fathers --suggesting that the effects of social context for these groups go beyond simplemodels in line with sociological theory. Our paper shows the potential ofprediction methods to support sociological explanation.</description>
      <author>example@mail.com (Javier Garcia-Bernardo, Eva Jaspers, Weverthon Machado, Samuel Plach, Erik Jan van Leeuwen)</author>
      <guid isPermaLink="false">2506.22993v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding</title>
      <link>http://arxiv.org/abs/2506.22593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to 2025 IEEE International Conference on Automation  Science and Engineering (CASE)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Pix2G的轻量级方法，用于从图像像素和LiDAR地图中实时生成结构化场景图，以支持资源受限的机器人平台在未知环境中的自主探索。&lt;h4&gt;背景&lt;/h4&gt;自主机器人在高风险、危险应用中作为支持平台，对人类操作者的作用越来越重要。为了完成挑战性任务，需要高效的人机协作和理解。机器人规划通常利用3D几何信息，而人类操作者习惯于环境的高级紧凑表示，如表示建筑信息模型（BIM）的俯视图2D地图。3D场景图已成为连接人类可读的2D BIM和机器人3D地图的有力工具。&lt;h4&gt;目的&lt;/h4&gt;提出Pix2G方法，以在资源受限的机器人平台上实时从图像像素和LiDAR地图生成结构化场景图，用于未知环境的自主探索。&lt;h4&gt;方法&lt;/h4&gt;该方法仅在CPU上执行所有操作以满足车载计算限制。输出包括去噪的2D俯视图环境地图和结构分割的3D点云，它们通过多层级图无缝连接，从对象级到建筑级抽象信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在真实世界实验中得到了评估，使用NASA JPL NeBula-Spot四足机器人实时探索并绘制杂乱车库和类似城市办公室环境的地图。&lt;h4&gt;结论&lt;/h4&gt;Pix2G方法能够有效生成结构化场景图，支持资源受限的机器人平台在复杂环境中的自主探索和映射。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robots are increasingly playing key roles as support platforms forhuman operators in high-risk, dangerous applications. To accomplish challengingtasks, an efficient human-robot cooperation and understanding is required.While typically robotic planning leverages 3D geometric information, humanoperators are accustomed to a high-level compact representation of theenvironment, like top-down 2D maps representing the Building Information Model(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gapbetween human readable 2D BIM and the robot 3D maps. In this work, we introducePixels-to-Graph (Pix2G), a novel lightweight method to generate structuredscene graphs from image pixels and LiDAR maps in real-time for the autonomousexploration of unknown environments on resource-constrained robot platforms. Tosatisfy onboard compute constraints, the framework is designed to perform alloperation on CPU only. The method output are a de-noised 2D top-downenvironment map and a structure-segmented 3D pointcloud which are seamlesslyconnected using a multi-layer graph abstracting information from object-levelup to the building-level. The proposed method is quantitatively andqualitatively evaluated during real-world experiments performed using the NASAJPL NeBula-Spot legged robot to autonomously explore and map cluttered garageand urban office like environments in real-time.</description>
      <author>example@mail.com (Antonello Longo, Chanyoung Chung, Matteo Palieri, Sung-Kyun Kim, Ali Agha, Cataldo Guaragnella, Shehryar Khattak)</author>
      <guid isPermaLink="false">2506.22593v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Missing-Modality-Aware Graph Neural Network for Cancer Classification</title>
      <link>http://arxiv.org/abs/2506.22901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGNET的模型，用于处理多模态生物数据中的缺失模态问题，通过引入患者-模态多头注意力机制和患者图神经网络，提高了预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;从多模态生物数据中学习时，缺失模态是一个关键挑战，因为某些患者的某些模态数据可能缺失。&lt;h4&gt;目的&lt;/h4&gt;提出一种直接使用部分模态进行预测的方法，以解决现有方法在处理多样缺失模态模式和模式数量随模态增加而指数增长的问题。&lt;h4&gt;方法&lt;/h4&gt;MAGNET模型通过引入患者-模态多头注意力机制来融合低维模态嵌入，并构建患者图，其中节点特征为融合的多模态嵌入，连接性由模态缺失性决定。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开的多组学数据集上进行的实验表明，MAGNET在癌症分类任务中优于现有的融合方法。&lt;h4&gt;结论&lt;/h4&gt;MAGNET能够有效地处理缺失模态问题，并且随着模态数量的增加，其复杂度线性增长，同时适应缺失模式的变化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从多模态生物数据中学习的一个关键挑战是缺失模态，即某些患者的某些模态数据缺失。现有的融合方法通过排除具有缺失模态的患者、插补缺失模态或直接使用部分模态进行预测来解决这个问题。然而，它们往往难以处理多样的缺失模态模式和随着模态数量增加而指数增长的这种模式数量。为了解决这些限制，我们提出了MAGNET（缺失模态感知图神经网络）用于直接使用部分模态进行预测，该模型引入了患者-模态多头注意力机制，根据其重要性和缺失性来融合低维模态嵌入。MAGNET的复杂度随着模态数量的增加而线性增长，同时适应缺失模式的变化。为了生成预测，MAGNET进一步构建了一个患者图，其中节点特征为融合的多模态嵌入，连接性由模态缺失性决定，随后进行传统的图神经网络。在三个公开的多组学数据集上进行的癌症分类实验，使用的是现实世界的缺失性而不是人工缺失性，表明MAGNET优于现有的融合方法。数据和代码可在https://github.com/SinaTabakhi/MAGNET上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A key challenge in learning from multimodal biological data is missingmodalities, where all data from some modalities are missing for some patients.Current fusion methods address this by excluding patients with missingmodalities, imputing missing modalities, or making predictions directly withpartial modalities. However, they often struggle with diverse missing-modalitypatterns and the exponential growth of the number of such patterns as thenumber of modalities increases. To address these limitations, we propose MAGNET(Missing-modality-Aware Graph neural NETwork) for direct prediction withpartial modalities, which introduces a patient-modality multi-head attentionmechanism to fuse lower-dimensional modality embeddings based on theirimportance and missingness. MAGNET's complexity increases linearly with thenumber of modalities while adapting to missing-pattern variability. To generatepredictions, MAGNET further constructs a patient graph with fused multimodalembeddings as node features and the connectivity determined by the modalitymissingness, followed by a conventional graph neural network. Experiments onthree public multiomics datasets for cancer classification, with real-worldinstead of artificial missingness, show that MAGNET outperforms thestate-of-the-art fusion methods. The data and code are available athttps://github.com/SinaTabakhi/MAGNET.</description>
      <author>example@mail.com (Sina Tabakhi, Haiping Lu)</author>
      <guid isPermaLink="false">2506.22901v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>On the Domain Robustness of Contrastive Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.23663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Deepbench is available at https://github.com/ml-lab-htw/deepbench&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Deepbench框架，用于评估视觉-语言模型在特定领域的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在实际视觉-语言应用中，虽然大型预训练基础模型在通用基准测试中表现出色，但在特定领域下效果可能会显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出Deepbench框架，以评估视觉-语言模型在特定领域的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Deepbench利用大型语言模型生成针对特定部署领域的真实、上下文感知的图像损坏，而不需要标记数据。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界领域中，对多种对比视觉-语言架构及其变体进行了评估，发现鲁棒性存在显著差异。&lt;h4&gt;结论&lt;/h4&gt;Deepbench作为开源软件发布，以支持进一步研究针对特定领域的鲁棒性评估。&lt;h4&gt;翻译&lt;/h4&gt;In real-world vision-language applications, practitioners increasingly rely on large, pretrained foundation models rather than custom-built solutions, despite limited transparency regarding their training data and processes. While these models achieve impressive performance on general benchmarks, their effectiveness can decline notably under specialized domain shifts, such as unique imaging conditions or environmental variations. In this work, we introduce Deepbench, a framework designed to assess domain-specific robustness of vision-language models (VLMs). Deepbench leverages a large language model (LLM) to generate realistic, context-aware image corruptions tailored to specific deployment domains without requiring labeled data. We evaluate a range of contrastive vision-language architectures and architectural variants across six real-world domains and observe substantial variability in robustness, highlighting the need for targeted, domain-aware evaluation. Deepbench is released as open-source software to support further research into domain-aware robustness assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world vision-language applications, practitioners increasingly relyon large, pretrained foundation models rather than custom-built solutions,despite limited transparency regarding their training data and processes. Whilethese models achieve impressive performance on general benchmarks, theireffectiveness can decline notably under specialized domain shifts, such asunique imaging conditions or environmental variations. In this work, weintroduce Deepbench, a framework designed to assess domain-specific robustnessof vision-language models (VLMs). Deepbench leverages a large language model(LLM) to generate realistic, context-aware image corruptions tailored tospecific deployment domains without requiring labeled data. We evaluate a rangeof contrastive vision-language architectures and architectural variants acrosssix real-world domains and observe substantial variability in robustness,highlighting the need for targeted, domain-aware evaluation. Deepbench isreleased as open-source software to support further research into domain-awarerobustness assessment.</description>
      <author>example@mail.com (Mario Koddenbrock, Rudolf Hoffmann, David Brodmann, Erik Rodner)</author>
      <guid isPermaLink="false">2506.23663v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method</title>
      <link>http://arxiv.org/abs/2506.23323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FastSeg是一种新型的、高效的训练免费框架，通过预训练扩散模型的逆向过程进行对象分割，同时实现了对所有类别的实时分割，并引入了多种机制提升分割质量。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary语义分割旨在无需大量标注数据集即可从任意文本类别中分割对象。尽管基于对比学习的模型可以实现零样本分割，但它们通常由于全局表示偏差而在像素级别上丢失精细的空间精度。&lt;h4&gt;目的&lt;/h4&gt;提出FastSeg，旨在解决现有模型在像素级别精度和分割质量上的不足，同时提高分割效率。&lt;h4&gt;方法&lt;/h4&gt;FastSeg使用预训练扩散模型的逆向过程，引入了三个关键组件：(i) 双提示机制，用于区分性、类感知的关注提取；(ii) 分层注意力细化方法（HARD），通过尺度对齐的自注意力图增强融合交叉注意力；(iii) 测试时间翻转（TTF）方案，以提高空间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中实现了最先进的训练免费性能，平均mIoU达到43.8%，同时保持了优越的推理效率。&lt;h4&gt;结论&lt;/h4&gt;FastSeg为可扩展性提供了坚实的基础，缩小了分割质量和推理效率之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS) aims to segment objects from arbitrary text categories without requiring densely annotated datasets. Although contrastive learning based models enable zero-shot segmentation, they often lose fine spatial precision at pixel level, due to global representation bias. In contrast, diffusion-based models naturally encode fine-grained spatial features via attention mechanisms that capture both global context and local details. However, they often face challenges in balancing the number of iterations with the quality of the segmentation. In this work, we propose FastSeg, a novel and efficient training-free framework with only (1+1)-step of reverse process of a pretrained diffusion model (e.g., Stable Diffusion). Moreover, instead of running multiple times for different classes, FastSeg performs segmentation for all classes at once. To further enhance the segmentation quality, FastSeg introduces three key components: (i) a dual-prompt mechanism for discriminative, class-aware attention extraction, (ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused cross-attention using scale-aligned selfattention maps, and (iii) a Test-TimeFlipping (TTF) scheme designed to improve spatial consistency. Extensive experiments show that FastSeg achieves state-of-the-art training-free performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context, and COCO Object benchmarks while maintaining superior inference efficiency. Our results demonstrate that FastSeg provides a strong foundation for extendability, bridging the gap between segmentation quality and inference efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary semantic segmentation (OVSS) aims to segment objects fromarbitrary text categories without requiring densely annotated datasets.Although contrastive learning based models enable zero-shot segmentation, theyoften lose fine spatial precision at pixel level, due to global representationbias. In contrast, diffusion-based models naturally encode fine-grained spatialfeatures via attention mechanisms that capture both global context and localdetails. However, they often face challenges in balancing the number ofiterations with the quality of the segmentation. In this work, we proposeFastSeg, a novel and efficient training-free framework with only (1+1)-step ofreverse process of a pretrained diffusion model (e.g., Stable Diffusion).Moreover, instead of running multiple times for different classes, FastSegperforms segmentation for all classes at once. To further enhance thesegmentation quality, FastSeg introduces three key components: (i) adual-prompt mechanism for discriminative, class-aware attention extraction,(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fusedcross-attention using scale-aligned selfattention maps, and (iii) a Test-TimeFlipping (TTF) scheme designed to improve spatial consistency. Extensiveexperiments show that FastSeg achieves state-of-the-art training-freeperformance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,and COCO Object benchmarks while maintaining superior inference efficiency. Ourresults demonstrate that FastSeg provides a strong foundation forextendability, bridging the gap between segmentation quality and inferenceefficiency.</description>
      <author>example@mail.com (Quang-Huy Che, Vinh-Tiep Nguyen)</author>
      <guid isPermaLink="false">2506.23323v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.22837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;xLSTM模型在时间序列预测、无损压缩和大规模语言建模等任务中表现出色，本文首次将xLSTM应用于异常检测。&lt;h4&gt;背景&lt;/h4&gt;xLSTM模型结合了乘法门控和残差连接，为长时预测和表征学习提供了时间容量。&lt;h4&gt;目的&lt;/h4&gt;提出xLSTMAD，第一个集成完整编码器-解码器xLSTM架构的异常检测方法，适用于多变量时间序列数据。&lt;h4&gt;方法&lt;/h4&gt;使用编码器捕获历史上下文，解码器有两种变体：xLSTMAD-F用于迭代生成预测未来值，xLSTMAD-R用于重建输入时间序列。使用均方误差（MSE）和软动态时间扭曲（SoftDTW）作为损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;在TSB-AD-M基准测试中，xLSTMAD在准确性方面优于23个流行的异常检测基线，展现出xLSTM在异常检测方面的强大建模能力。&lt;h4&gt;结论&lt;/h4&gt;本文为xLSTM在异常检测领域的应用开辟了新的发展道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了xLSTM模型在异常检测中的应用，该模型在时间序列预测、无损压缩和大规模语言建模等方面已证明其有效性。本文提出了一种新的异常检测方法xLSTMAD，该方法集成了完整的编码器-解码器xLSTM架构，并针对多变量时间序列数据进行了优化。在TSB-AD-M基准测试中，xLSTMAD在准确性方面优于其他基线方法，证明了xLSTM在异常检测方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recently proposed xLSTM is a powerful model that leverages expressivemultiplicative gating and residual connections, providing the temporal capacityneeded for long-horizon forecasting and representation learning. Thisarchitecture has demonstrated success in time series forecasting, losslesscompression, and even large-scale language modeling tasks, where its linearmemory footprint and fast inference make it a viable alternative toTransformers. Despite its growing popularity, no prior work has explored xLSTMfor anomaly detection. In this work, we fill this gap by proposing xLSTMAD, thefirst anomaly detection method that integrates a full encoder-decoder xLSTMarchitecture, purpose-built for multivariate time series data. Our encoderprocesses input sequences to capture historical context, while the decoder isdevised in two separate variants of the method. In the forecasting approach,the decoder iteratively generates forecasted future values xLSTMAD-F, while thereconstruction approach reconstructs the input time series from its encodedcounterpart xLSTMAD-R. We investigate the performance of two loss functions:Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to considerlocal reconstruction fidelity and global sequence alignment, respectively. Weevaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17real-world datasets, using state-of-the-art challenging metrics such as VUS-PR.In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23popular anomaly detection baselines. Our paper is the first work revealing thepowerful modeling capabilities of xLSTM for anomaly detection, paving the wayfor exciting new developments on this subject. Our code is available at:https://github.com/Nyderx/xlstmad</description>
      <author>example@mail.com (Kamil Faber, Marcin Pietroń, Dominik Żurek, Roberto Corizzo)</author>
      <guid isPermaLink="false">2506.22837v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations</title>
      <link>http://arxiv.org/abs/2506.22727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARIBOU的图神经网络框架，通过在消息传递过程中应用隐私放大技术，实现了随着层数增加隐私预算的收敛，从而在保护敏感结构信息的同时，提高了模型性能。&lt;h4&gt;背景&lt;/h4&gt;将差分隐私（DP）集成到图神经网络（GNNs）中，可以保护图中敏感的结构信息，如边、节点及其关联特征。然而，现有的方法通常随着层数的增加而线性增加隐私成本，导致需要过多的噪声来维持合理的隐私水平。&lt;h4&gt;目的&lt;/h4&gt;降低GNNs在保护隐私时的成本，特别是在需要深层次GNN以捕捉复杂和长距离交互的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Contractive Graph Layer（CGL）的简单而有效的层，它通过利用标准GNN操作的内禀收缩性质，确保所需的收缩性，同时保持模型的有效性。CARIBOU框架支持训练和推理，并配备了收缩聚合模块、隐私分配模块和隐私审计模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过应用隐私放大技术，隐私预算可以随着层数的增加而收敛，从而减少了隐私成本。&lt;h4&gt;结论&lt;/h4&gt;CARIBOU在隐私-效用权衡方面取得了显著改进，并在隐私审计任务中实现了优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;Differential privacy (DP) has been integrated into graph neural networks (GNNs) to protect sensitive structural information, e.g., edges, nodes, and associated features across various applications. A common approach is to perturb the message-passing process, which forms the core of most GNN architectures. However, existing methods typically incur a privacy cost that grows linearly with the number of layers (Usenix Security'23), ultimately requiring excessive noise to maintain a reasonable privacy level. This limitation becomes particularly problematic when deep GNNs are necessary to capture complex and long-range interactions in graphs. In this paper, we theoretically establish that the privacy budget can converge with respect to the number of layers by applying privacy amplification techniques to the message-passing process, exploiting the contractive properties inherent to standard GNN operations. Motivated by this analysis, we propose a simple yet effective Contractive Graph Layer (CGL) that ensures the contractiveness required for theoretical guarantees while preserving model utility. Our framework, CARIBOU, supports both training and inference, equipped with a contractive aggregation module, a privacy allocation module, and a privacy auditing module. Experimental evaluations demonstrate that CARIBOU significantly improves the privacy-utility trade-off and achieves superior performance in privacy auditing tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differential privacy (DP) has been integrated into graph neural networks(GNNs) to protect sensitive structural information, e.g., edges, nodes, andassociated features across various applications. A common approach is toperturb the message-passing process, which forms the core of most GNNarchitectures. However, existing methods typically incur a privacy cost thatgrows linearly with the number of layers (Usenix Security'23), ultimatelyrequiring excessive noise to maintain a reasonable privacy level. Thislimitation becomes particularly problematic when deep GNNs are necessary tocapture complex and long-range interactions in graphs. In this paper, wetheoretically establish that the privacy budget can converge with respect tothe number of layers by applying privacy amplification techniques to themessage-passing process, exploiting the contractive properties inherent tostandard GNN operations. Motivated by this analysis, we propose a simple yeteffective Contractive Graph Layer (CGL) that ensures the contractivenessrequired for theoretical guarantees while preserving model utility. Ourframework, CARIBOU, supports both training and inference, equipped with acontractive aggregation module, a privacy allocation module, and a privacyauditing module. Experimental evaluations demonstrate that CARIBOUsignificantly improves the privacy-utility trade-off and achieves superiorperformance in privacy auditing tasks.</description>
      <author>example@mail.com (Yu Zheng, Chenang Li, Zhou Li, Qingsong Wang)</author>
      <guid isPermaLink="false">2506.22727v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Score-based Diffusion Model for Unpaired Virtual Histology Staining</title>
      <link>http://arxiv.org/abs/2506.23184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于互信息（MI）引导的评分扩散模型，用于无配对的虚拟染色，旨在提高虚拟染色的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的H&amp;E染色和IHC染色在诊断中各有局限性，H&amp;E染色缺乏特异性，而IHC染色受限于组织可用性和抗体特异性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效生成IHC图像的虚拟染色方法，同时保持组织结构。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括：1）全局MI引导的能量函数，用于跨模态分解组织结构和染色特征；2）时间步长定制反向扩散过程，用于精确控制染色强度和结构重建；3）局部MI驱动的对比学习策略，确保H&amp;E-IHC图像在细胞水平上的结构一致性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在实验中展现出优于现有技术的优越性，突显了其在生物医学领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的虚拟染色方法能够有效提高IHC图像生成的效率和准确性，具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining, aiming to improve the efficiency and accuracy of IHC image generation while preserving tissue structure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hematoxylin and eosin (H&amp;E) staining visualizes histology but lacksspecificity for diagnostic markers. Immunohistochemistry (IHC) stainingprovides protein-targeted staining but is restricted by tissue availability andantibody specificity. Virtual staining, i.e., computationally translating theH&amp;E image to its IHC counterpart while preserving the tissue structure, ispromising for efficient IHC generation. Existing virtual staining methods stillface key challenges: 1) effective decomposition of staining style and tissuestructure, 2) controllable staining process adaptable to diverse tissue andproteins, and 3) rigorous structural consistency modelling to handle thenon-pixel-aligned nature of paired H&amp;E and IHC images. This study proposes amutual-information (MI)-guided score-based diffusion model for unpaired virtualstaining. Specifically, we design 1) a global MI-guided energy function thatdisentangles the tissue structure and staining characteristics acrossmodalities, 2) a novel timestep-customized reverse diffusion process forprecise control of the staining intensity and structural reconstruction, and 3)a local MI-driven contrastive learning strategy to ensure the cellular levelstructural consistency between H&amp;E-IHC images. Extensive experimentsdemonstrate the our superiority over state-of-the-art approaches, highlightingits biomedical potential. Codes will be open-sourced upon acceptance.</description>
      <author>example@mail.com (Anran Liu, Xiaofei Wang, Jing Cai, Chao Li)</author>
      <guid isPermaLink="false">2506.23184v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Compression and Objective Quality Assessment: A Survey</title>
      <link>http://arxiv.org/abs/2506.22902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对点云压缩（PCC）和点云质量评估（PCQA）的最新进展进行了全面综述，强调了这些技术在实时和感知相关应用中的重要性。&lt;h4&gt;背景&lt;/h4&gt;由于自动驾驶、机器人和沉浸式环境等应用的增长，3D点云数据迅速增长，对高效压缩和质量评估技术提出了迫切需求。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析各种手工制作和基于学习的PCC算法以及客观PCQA指标，并通过在新兴数据集上基准测试代表性方法，提供详细的比较和实际见解。&lt;h4&gt;方法&lt;/h4&gt;本文分析了广泛的PCC算法，包括手工制作和基于学习的算法，并使用客观PCQA指标进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;尽管取得了显著进展，但仍存在挑战，如提高视觉保真度、减少延迟和支持多模态数据。&lt;h4&gt;结论&lt;/h4&gt;本文概述了未来的研究方向，包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。&lt;h4&gt;翻译&lt;/h4&gt;本文对点云压缩（PCC）和点云质量评估（PCQA）的最新进展进行了全面综述，强调了这些技术在实时和感知相关应用中的重要性。由于自动驾驶、机器人和沉浸式环境等应用的增长，3D点云数据迅速增长，对高效压缩和质量评估技术提出了迫切需求。本文旨在分析各种手工制作和基于学习的PCC算法以及客观PCQA指标，并通过在新兴数据集上基准测试代表性方法，提供详细的比较和实际见解。尽管取得了显著进展，但仍存在挑战，如提高视觉保真度、减少延迟和支持多模态数据。本文概述了未来的研究方向，包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of 3D point cloud data, driven by applications in autonomousdriving, robotics, and immersive environments, has led to criticals demand forefficient compression and quality assessment techniques. Unlike traditional 2Dmedia, point clouds present unique challenges due to their irregular structure,high data volume, and complex attributes. This paper provides a comprehensivesurvey of recent advances in point cloud compression (PCC) and point cloudquality assessment (PCQA), emphasizing their significance for real-time andperceptually relevant applications. We analyze a wide range of handcrafted andlearning-based PCC algorithms, along with objective PCQA metrics. Bybenchmarking representative methods on emerging datasets, we offer detailedcomparisons and practical insights into their strengths and limitations.Despite notable progress, challenges such as enhancing visual fidelity,reducing latency, and supporting multimodal data remain. This survey outlinesfuture directions, including hybrid compression frameworks and advanced featureextraction strategies, to enable more efficient, immersive, and intelligent 3Dapplications.</description>
      <author>example@mail.com (Yiling Xu, Yujie Zhang, Shuting Xia, Kaifa Yang, He Huang, Ziyu Shan, Wenjie Huang, Qi Yang, Le Yang)</author>
      <guid isPermaLink="false">2506.22902v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unified Multimodal Understanding via Byte-Pair Visual Encoding</title>
      <link>http://arxiv.org/abs/2506.23639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一多模态理解的框架，通过应用字节对编码到视觉标记中，解决了不同模态有效对齐的基本挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大语言模型（MLLMs）在视觉-语言理解方面取得了显著进展，但有效地对齐不同模态仍然是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过将字节对编码应用于视觉标记，统一多模态理解。&lt;h4&gt;方法&lt;/h4&gt;方法包括：1）将结构信息直接纳入视觉标记；2）引入一个优先级引导的编码方案，考虑频率和空间一致性；3）采用基于课程驱动的数据组合的多阶段训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;这些增强使得Transformer模型能够更好地捕捉跨模态关系并利用视觉信息，实验表明在多种视觉-语言任务上性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;通过弥合视觉和文本表示之间的差距，该方法有助于推进更强大和高效的多模态基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have made significant progress invision-language understanding, yet effectively aligning different modalitiesremains a fundamental challenge. We present a framework that unifies multimodalunderstanding by applying byte-pair encoding to visual tokens. Unlikeconventional approaches that rely on modality-specific encoders, our methoddirectly incorporates structural information into visual tokens, mirroringsuccessful tokenization strategies in text-only language models. We introduce apriority-guided encoding scheme that considers both frequency and spatialconsistency, coupled with a multi-stage training procedure based oncurriculum-driven data composition. These enhancements enable the transformermodel to better capture cross-modal relationships and reason with visualinformation. Comprehensive experiments demonstrate improved performance acrossdiverse vision-language tasks. By bridging the gap between visual and textualrepresentations, our approach contributes to the advancement of more capableand efficient multimodal foundation models.</description>
      <author>example@mail.com (Wanpeng Zhang, Yicheng Feng, Hao Luo, Yijiang Li, Zihao Yue, Sipeng Zheng, Zongqing Lu)</author>
      <guid isPermaLink="false">2506.23639v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing</title>
      <link>http://arxiv.org/abs/2506.22789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, Published at The Proceedings of Interspeech 2025,  code is available at http://www.github.com/UTAustin-SwarmLab/WavShape&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为WavShape的语音表示学习框架，旨在优化语音嵌入以实现公平性和隐私保护，同时保留与任务相关的信息。&lt;h4&gt;背景&lt;/h4&gt;语音嵌入可能会保留敏感属性，如说话人身份、口音或人口统计数据，这可能会在模型训练和隐私泄露中带来风险。&lt;h4&gt;目的&lt;/h4&gt;开发一个公平、隐私感知且资源高效的语音系统。&lt;h4&gt;方法&lt;/h4&gt;使用Donsker-Varadhan公式的互信息（MI）估计来指导一个基于MI的编码器，该编码器系统性地过滤敏感属性，同时保持对下游任务至关重要的语音内容。&lt;h4&gt;主要发现&lt;/h4&gt;在三个已知数据集上的实验结果表明，WavShape将嵌入与敏感属性之间的互信息减少了高达81%，同时保留了97%的任务相关信息。&lt;h4&gt;结论&lt;/h4&gt;通过将信息理论与自监督语音模型相结合，这项工作推动了公平、隐私感知和资源高效语音系统的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音嵌入通常会保留敏感属性，如说话人身份、口音或人口统计数据，这给模型训练和隐私泄露带来了风险。我们提出了WavShape，一个基于信息论的语音表示学习框架，它优化嵌入以实现公平性和隐私保护，同时保留与任务相关的信息。我们利用Donsker-Varadhan公式的互信息（MI）估计来引导一个基于MI的编码器，该编码器系统地过滤敏感属性，同时保持对下游任务至关重要的语音内容。在三个已知数据集上的实验结果表明，WavShape将嵌入与敏感属性之间的互信息减少了高达81%，同时保留了97%的任务相关信息。通过将信息理论与自监督语音模型相结合，这项工作推动了公平、隐私感知和资源高效语音系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech embeddings often retain sensitive attributes such as speaker identity,accent, or demographic information, posing risks in biased model training andprivacy leakage. We propose WavShape, an information-theoretic speechrepresentation learning framework that optimizes embeddings for fairness andprivacy while preserving task-relevant information. We leverage mutualinformation (MI) estimation using the Donsker-Varadhan formulation to guide anMI-based encoder that systematically filters sensitive attributes whilemaintaining speech content essential for downstream tasks. Experimental resultson three known datasets show that WavShape reduces MI between embeddings andsensitive attributes by up to 81% while retaining 97% of task-relevantinformation. By integrating information theory with self-supervised speechmodels, this work advances the development of fair, privacy-aware, andresource-efficient speech systems.</description>
      <author>example@mail.com (Oguzhan Baser, Ahmet Ege Tanriverdi, Kaan Kale, Sandeep P. Chinchali, Sriram Vishwanath)</author>
      <guid isPermaLink="false">2506.22789v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication</title>
      <link>http://arxiv.org/abs/2506.22714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Libra的系统方法，旨在通过协同计算CUDA和Tensor核心来优化稀疏矩阵乘法的性能。&lt;h4&gt;背景&lt;/h4&gt;稀疏矩阵乘法在深度学习和科学计算中广泛应用，现代加速器通常配备Tensor核心和CUDA核心来加速稀疏操作。Tensor核心适用于结构化矩阵乘法，而CUDA核心具有更高的编程灵活性但性能相对较低。&lt;h4&gt;目的&lt;/h4&gt;为了克服单一资源使用的局限性，提高稀疏矩阵乘法的性能。&lt;h4&gt;方法&lt;/h4&gt;Libra系统采用2D感知的工作负载分配策略，以找到不同稀疏算子的任务映射的最佳点，同时利用Tensor核心的高性能和CUDA核心的低计算冗余。此外，Libra还包括针对异构计算的系统性优化，如混合负载平衡、精细优化的内核实现和GPU加速的预处理。&lt;h4&gt;主要发现&lt;/h4&gt;在H100和RTX 4090 GPU上的大量实验结果表明，Libra的平均性能比DTC-SpMM高3.1倍（最高可达9.23倍），对于端到端GNN应用，性能比DTC-SpMM高2.9倍（最高可达3.9倍）。&lt;h4&gt;结论&lt;/h4&gt;Libra通过充分利用GPU上的异构计算资源，为稀疏算子加速开辟了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor cores and CUDA cores to accelerate sparse operators. The former brings superior computing power but only for structured matrix multiplication, while the latter has relatively lower performance but with higher programming flexibility. In this work, we discover that utilizing one resource alone leads to inferior performance for sparse matrix multiplication, due to their respective limitations. To this end, we propose Libra, a systematic approach that enables synergistic computation between CUDA and Tensor cores to achieve the best performance for sparse matrix multiplication. Specifically, we propose a 2D-aware workload distribution strategy to find out the sweet point of task mapping for different sparse operators, leveraging both the high performance of Tensor cores and the low computational redundancy on CUDA cores. In addition, Libra incorporates systematic optimizations for heterogeneous computing, including hybrid load-balancing, finely optimized kernel implementations, and GPU-accelerated preprocessing. Extensive experimental results on H100 and RTX 4090 GPUs show that Libra outperforms the state-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to 3.9x) for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully exploiting the heterogeneous computing resources on GPUs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely usedin deep learning and scientific computing. Modern accelerators are commonlyequipped with Tensor cores and CUDA cores to accelerate sparse operators. Theformer brings superior computing power but only for structured matrixmultiplication, while the latter has relatively lower performance but withhigher programming flexibility. In this work, we discover that utilizing oneresource alone leads to inferior performance for sparse matrix multiplication,due to their respective limitations. To this end, we propose Libra, asystematic approach that enables synergistic computation between CUDA andTensor cores to achieve the best performance for sparse matrix multiplication.Specifically, we propose a 2D-aware workload distribution strategy to find outthe sweet point of task mapping for different sparse operators, leveraging boththe high performance of Tensor cores and the low computational redundancy onCUDA cores. In addition, Libra incorporates systematic optimizations forheterogeneous computing, including hybrid load-balancing, finely optimizedkernel implementations, and GPU-accelerated preprocessing. Extensiveexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms thestate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to3.9x) for end-to-end GNN applications. Libra opens up a new perspective forsparse operator acceleration by fully exploiting the heterogeneous computingresources on GPUs.</description>
      <author>example@mail.com (Jinliang Shi, Shigang Li, Youxuan Xu, Xueying Wang, Rongtian Fu, Zhi Ma, Tong Wu)</author>
      <guid isPermaLink="false">2506.22714v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning</title>
      <link>http://arxiv.org/abs/2506.22710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightBSR的轻量级盲超分辨率模型，该模型通过优化隐式退化估计（IDE）的判别性来提升超分辨率效果。&lt;h4&gt;背景&lt;/h4&gt;IDE-BSR方法在处理噪声干扰和复杂退化方面展现出潜力，但现有方法过度复杂化适应过程以提高效果，导致模型参数和计算量显著增加。&lt;h4&gt;目的&lt;/h4&gt;优化IDE的判别性，提出一种高效且轻量级的BSR模型。&lt;h4&gt;方法&lt;/h4&gt;采用基于知识蒸馏的学习框架，设计了一种降解先验约束对比学习技术，以及特征对齐技术，以使模型更专注于区分不同退化类型并将教师模型学到的知识传递给学生模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过IDR判别性驱动的BSR模型设计，LightBSR模型在各种盲超分辨率任务中实现了卓越的性能，同时保持了最小复杂性。&lt;h4&gt;结论&lt;/h4&gt;LightBSR模型通过优化IDR判别性，在保持低计算量的同时提升了盲超分辨率任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit degradation estimation-based blind super-resolution (IDE-BSR) hingeson extracting the implicit degradation representation (IDR) of the LR image andadapting it to LR image features to guide HR detail restoration. AlthoughIDE-BSR has shown potential in dealing with noise interference and complexdegradations, existing methods ignore the importance of IDR discriminabilityfor BSR and instead over-complicate the adaptation process to improve effect,resulting in a significant increase in the model's parameters and computations.In this paper, we focus on the discriminability optimization of IDR and proposea new powerful and lightweight BSR model termed LightBSR. Specifically, weemploy a knowledge distillation-based learning framework. We first introduce awell-designed degradation-prior-constrained contrastive learning techniqueduring teacher stage to make the model more focused on distinguishing differentdegradation types. Then we utilize a feature alignment technique to transferthe degradation-related knowledge acquired by the teacher to the student forpractical inferencing. Extensive experiments demonstrate the effectiveness ofIDR discriminability-driven BSR model design. The proposed LightBSR can achieveoutstanding performance with minimal complexity across a range of blind SRtasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.</description>
      <author>example@mail.com (Jiang Yuan, JI Ma, Bo Wang, Guanzhou Ke, Weiming Hu)</author>
      <guid isPermaLink="false">2506.22710v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Investigation of the performance of a GNN-based b-jet tagging method in heavy-ion collisions</title>
      <link>http://arxiv.org/abs/2506.22691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在重离子碰撞中产生的夸克胶子等离子体(QGP)中的部分子动力学，重点关注了b-jets（由 beauty quarks 分解产生的粒子喷流）的能量损失模式，并评估了基于图神经网络(GNN)的b-jet识别方法在复杂环境中的性能。&lt;h4&gt;背景&lt;/h4&gt;Beauty-tagged jets（b-jets）是源于 beauty quarks 在初始强相互作用中产生的喷流，它们可以用来探测 QGP 中的部分子动力学。在低-$p_T$区域，由于 QGP 介子化产生的背景粒子数量众多，传统的 b-jet 标签技术效果不佳。&lt;h4&gt;目的&lt;/h4&gt;研究 GNN 在 Pb-Pb 碰撞环境下的 b-jet 识别性能，并评估其在复杂环境中的鲁棒性，以推进 QGP 诱导的部分子能量损失的未来精密研究。&lt;h4&gt;方法&lt;/h4&gt;采用和调整了 ATLAS 开发的 GN1 模型，在包含 Pb-Pb 背景粒子的喷流中应用该模型，评估了标签决策和对抗背景污染的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;本文对 GNN 基于的 b-jet 标签在重离子碰撞条件下的性能进行了全面的评估。&lt;h4&gt;结论&lt;/h4&gt;通过使用 GNN 方法，可以更精确地测量在复杂环境中的 b-jets，有助于深入理解 QGP 中的强相互作用及其非微扰态。&lt;h4&gt;翻译&lt;/h4&gt;Beauty-tagged jets (b-jets) - 由 beauty quarks 在初始硬碰撞中产生的来自碎片化的粒子喷流 - 为探测在超相对论重离子碰撞中产生的夸克胶子等离子体(QGP)中的部分子动力学提供了一个独特的探测工具。特别是，低-$p_T$ b-jets 通过 QGP 的能量损失模式提供了对强相互作用的非微扰态的有价值见解。CMS 和 ATLAS 合作在 LHC 上研究了 Pb-Pb 碰撞中的 b-jet 产生。由于在低-$p_T$ 区域存在来自 QGP 介子化的背景粒子数量众多这一主要挑战，结果仅限于高-$p_T$ 区域，这严重阻碍了传统 b-jet 标签技术的有效性。为了在这样的复杂环境中进行精确测量，需要先进的标签方法。能够学习喷流组成部分之间关系结构的图神经网络(GNN)是 b-jet 识别的深度学习方法之一。在这项研究中，我们采用了并调整了 ATLAS 初始开发的 GN1 模型，用于 Pb-Pb 碰撞环境。通过将其应用于嵌入 Pb-Pb 背景粒子的喷流，我们评估了该模型的性能，包括标签决策和对抗背景污染的鲁棒性。这项工作对 GNN 基于的 b-jet 标签在重离子碰撞条件下的性能进行了全面的评估，旨在推进 QGP 诱导的部分子能量损失的未来精密研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beauty-tagged jets (b-jets)-collimated sprays of particles originating fromthe fragmentation of beauty quarks produced in the initial hardscatterings-provide a unique probe of parton dynamics in the quark-gluon plasma(QGP) created in ultrarelativistic heavy-ion collisions. In particular, energyloss patterns of low-$p_T$ b-jets traversing the QGP offer valuable insightinto the strong interaction in its nonperturbative regime. CMS and ATLASCollaborations at the LHC have studied b-jet production in Pb-Pb collisions.The results were limited to a high-$p_T$ region, because a major challenge atlow-$p_T$ is the overwhelming number of background particles from QGPhadronisation, which severely hinders the effectiveness of conventional b-jettagging techniques. To enable precise measurements in such complexenvironments, advanced tagging methods are required. Graph Neural Networks(GNNs), capable of learning relational structures among jet constituents,represent a promising deep learning approach for b-jet identification. In thisstudy, we adopt and adapt the GN1 model, initially developed by ATLAS, for usein Pb-Pb collision environments. We investigate the model's performance byapplying it to jets embedded with Pb-Pb background particles, evaluating bothtagging decisions and robustness against background contamination. This workpresents a comprehensive evaluation of GNN-based b-jet tagging under heavy-ioncollision conditions, aiming to advance future precision studies of QGP-inducedpartonic energy loss.</description>
      <author>example@mail.com (Changhwan Choi, Sanghoon Lim)</author>
      <guid isPermaLink="false">2506.22691v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings</title>
      <link>http://arxiv.org/abs/2506.23115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Homepage: https://haon-chen.github.io/MoCa/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MoCa是一种两阶段框架，用于将预训练的VLMs转换为有效的双向多模态嵌入模型，解决了当前方法中的三个关键问题。&lt;h4&gt;背景&lt;/h4&gt;基于因果视觉语言模型的多模态嵌入模型在多种任务中显示出潜力，但存在三个主要问题：VLM骨干中使用因果注意力在嵌入任务中不理想；依赖高质量标记配对数据导致可扩展性问题；训练目标和数据多样性有限。&lt;h4&gt;目的&lt;/h4&gt;提出MoCa框架以解决上述问题，提高多模态嵌入模型的效果。&lt;h4&gt;方法&lt;/h4&gt;MoCa包括两个阶段：Modality-aware Continual Pre-training和Heterogeneous Contrastive Fine-tuning。第一阶段通过联合重建目标同时降噪文本和图像输入，增强双向上下文感知推理；第二阶段利用多样化的、语义丰富的多模态数据，增强泛化和对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MoCa通过双向注意力、联合重建目标和多样化的多模态数据解决了现有方法的局限性，并在MMEB和ViDoRe-v2基准测试中实现了新的最先进结果，同时表现出在模型大小和训练数据上的强大可扩展性。&lt;h4&gt;结论&lt;/h4&gt;MoCa是一种有效的多模态嵌入模型，能够显著提高性能并具有良好的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal embedding models, built upon causal Vision Language Models (VLMs),have shown promise in various tasks. However, current approaches face three keylimitations: the use of causal attention in VLM backbones is suboptimal forembedding tasks; scalability issues due to reliance on high-quality labeledpaired data for contrastive learning; and limited diversity in trainingobjectives and data. To address these issues, we propose MoCa, a two-stageframework for transforming pre-trained VLMs into effective bidirectionalmultimodal embedding models. The first stage, Modality-aware ContinualPre-training, introduces a joint reconstruction objective that simultaneouslydenoises interleaved text and image inputs, enhancing bidirectionalcontext-aware reasoning. The second stage, Heterogeneous ContrastiveFine-tuning, leverages diverse, semantically rich multimodal data beyond simpleimage-caption pairs to enhance generalization and alignment. Our methodaddresses the stated limitations by introducing bidirectional attention throughcontinual pre-training, scaling effectively with massive unlabeled datasets viajoint reconstruction objectives, and utilizing diverse multimodal data forenhanced representation robustness. Experiments demonstrate that MoCaconsistently improves performance across MMEB and ViDoRe-v2 benchmarks,achieving new state-of-the-art results, and exhibits strong scalability withboth model size and training data on MMEB.</description>
      <author>example@mail.com (Haonan Chen, Hong Liu, Yuping Luo, Liang Wang, Nan Yang, Furu Wei, Zhicheng Dou)</author>
      <guid isPermaLink="false">2506.23115v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>DistShap: Scalable GNN Explanations with Distributed Shapley Values</title>
      <link>http://arxiv.org/abs/2506.22668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DistShap的并行算法，用于在分布式环境下计算图神经网络（GNN）的预测解释，以解决对特定边或特征的归因问题。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNN）的广泛应用，解释其预测结果变得越来越重要。然而，将预测归因于特定的边或特征在计算上仍然很昂贵。&lt;h4&gt;目的&lt;/h4&gt;提出DistShap算法的目的是为了解决GNN模型中预测解释的计算效率问题。&lt;h4&gt;方法&lt;/h4&gt;DistShap通过在分布式设置中采样子图、并行执行GNN推理，以及解决分布式最小二乘问题来计算边的重要性得分。&lt;h4&gt;主要发现&lt;/h4&gt;DistShap在准确率上优于大多数现有的GNN解释方法，并且是第一个能够扩展到具有数百万个特征的GNN模型，使用了多达128个GPU的NERSC Perlmutter超级计算机。&lt;h4&gt;结论&lt;/h4&gt;DistShap是一种有效的并行算法，可以用于解释大规模GNN模型的预测，显著提高了计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing adoption of graph neural networks (GNNs), explaining theirpredictions has become increasingly important. However, attributing predictionsto specific edges or features remains computationally expensive. For example,classifying a node with 100 neighbors using a 3-layer GNN may involveidentifying important edges from millions of candidates contributing to theprediction. To address this challenge, we propose DistShap, a parallelalgorithm that distributes Shapley value-based explanations across multipleGPUs. DistShap operates by sampling subgraphs in a distributed setting,executing GNN inference in parallel across GPUs, and solving a distributedleast squares problem to compute edge importance scores. DistShap outperformsmost existing GNN explanation methods in accuracy and is the first to scale toGNN models with millions of features by using up to 128 GPUs on the NERSCPerlmutter supercomputer.</description>
      <author>example@mail.com (Selahattin Akkas, Aditya Devarakonda, Ariful Azad)</author>
      <guid isPermaLink="false">2506.22668v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization</title>
      <link>http://arxiv.org/abs/2506.23077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比学习（DyCL）的新框架，用于解决深度学习在跨视图地理定位中的问题，该框架在校园场景中取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;现有的跨视图地理定位方法主要关注提高跨域图像匹配的准确性，而不是全面捕捉目标周围的上下文信息以及最小化定位误差的成本。&lt;h4&gt;目的&lt;/h4&gt;构建一个名为DA-Campus的基准，以支持对距离感知跨视图地理定位（DACVGL）问题的系统研究。&lt;h4&gt;方法&lt;/h4&gt;基于DA-Campus，将DACVGL问题表述为跨不同域的分层检索问题。提出DyCL框架，通过分层空间边界逐步对特征表示进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;由于建筑物之间空间关系的固有复杂性，该问题只能通过对比学习范式来解决，而不是传统的度量学习。&lt;h4&gt;结论&lt;/h4&gt;DyCL与现有的多尺度度量学习方法高度互补，在分层检索性能和整体跨视图地理定位准确性方面都取得了显著改进。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called Dynamic Contrastive Learning (DyCL) to address the problem in cross-view geo-localization using deep learning, which has achieved significant performance improvements in the campus scene.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing deep learning-based cross-view geo-localization methods primarilyfocus on improving the accuracy of cross-domain image matching, rather thanenabling models to comprehensively capture contextual information around thetarget and minimize the cost of localization errors. To support systematicresearch into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairsmulti-view imagery with precise distance annotations across three spatialresolutions. Based on DA-Campus, we formulate DACVGL as a hierarchicalretrieval problem across different domains. Our study further reveals that, dueto the inherent complexity of spatial relationships among buildings, thisproblem can only be addressed via a contrastive learning paradigm, rather thanconventional metric learning. To tackle this challenge, we propose DynamicContrastive Learning (DyCL), a novel framework that progressively alignsfeature representations according to hierarchical spatial margins. Extensiveexperiments demonstrate that DyCL is highly complementary to existingmulti-scale metric learning methods and yields substantial improvements in bothhierarchical retrieval performance and overall cross-view geo-localizationaccuracy. Our code and benchmark are publicly available athttps://github.com/anocodetest1/DyCL.</description>
      <author>example@mail.com (Suofei Zhang, Xinxin Wang, Xiaofu Wu, Quan Zhou, Haifeng Hu)</author>
      <guid isPermaLink="false">2506.23077v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching</title>
      <link>http://arxiv.org/abs/2506.22784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了激光雷达点云与相机图像的点像素配准问题，提出了一种无检测器的点像素匹配框架，以解决单帧激光雷达设置下的模态差距、稀疏性和噪声问题。&lt;h4&gt;背景&lt;/h4&gt;点像素配准是自动驾驶和机器人感知中的基础且具有挑战性的任务，现有方法存在模态差距，且难以处理单帧激光雷达的稀疏性和噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无检测器框架，实现激光雷达和相机视图之间的直接点像素匹配，提高匹配的可靠性。&lt;h4&gt;方法&lt;/h4&gt;将激光雷达强度图投影到二维视图，并输入到基于注意力的无检测器匹配网络中，引入重复性评分机制作为软可见性先验，以抑制不可靠的匹配。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在KITTI、nuScenes和MIAS-LCEC-TF70数据集上取得了最先进的性能，优于依赖累积点云的先前方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在单帧激光雷达设置下实现了高精度的点像素配准，为自动驾驶和机器人感知领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the point-pixel registration between LiDAR point clouds and camera images, presenting a novel detector-free framework for direct point-pixel matching between LiDAR and camera views. The method is designed to address the modality gap, sparsity, and noise issues under sparse single-frame LiDAR settings, and demonstrates state-of-the-art performance on benchmark datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point-pixel registration between LiDAR point clouds and camera images is afundamental yet challenging task in autonomous driving and robotic perception.A key difficulty lies in the modality gap between unstructured point clouds andstructured images, especially under sparse single-frame LiDAR settings.Existing methods typically extract features separately from point clouds andimages, then rely on hand-crafted or learned matching strategies. This separateencoding fails to bridge the modality gap effectively, and more critically,these methods struggle with the sparsity and noise of single-frame LiDAR, oftenrequiring point cloud accumulation or additional priors to improve reliability.Inspired by recent progress in detector-free matching paradigms (e.g.MatchAnything), we revisit the projection-based approach and introduce thedetector-free framework for direct point-pixel matching between LiDAR andcamera views. Specifically, we project the LiDAR intensity map into a 2D viewfrom the LiDAR perspective and feed it into an attention-based detector-freematching network, enabling cross-modal correspondence estimation withoutrelying on multi-frame accumulation. To further enhance matching reliability,we introduce a repeatability scoring mechanism that acts as a soft visibilityprior. This guides the network to suppress unreliable matches in regions withlow intensity variation, improving robustness under sparse input. Extensiveexperiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate thatour method achieves state-of-the-art performance, outperforming priorapproaches on nuScenes (even those relying on accumulated point clouds),despite using only single-frame LiDAR.</description>
      <author>example@mail.com (Yu Han, Zhiwei Huang, Yanting Zhang, Fangjun Ding, Shen Cai, Rui Fan)</author>
      <guid isPermaLink="false">2506.22784v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings</title>
      <link>http://arxiv.org/abs/2506.22881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对比学习在视觉和语言领域中的应用，通过文本样本计算图像的语义信息量，并从图像样本计算文本的信息量。&lt;h4&gt;背景&lt;/h4&gt;对比学习能够通过嵌入和调整视觉表示与语义信息来建模多模态概率分布，并估计关系语义相似度。&lt;h4&gt;目的&lt;/h4&gt;探索对比学习是否能表示绝对语义信息量，并提出一种基于文本样本计算图像语义信息量以及从图像样本计算文本信息量的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种重新定义信息增益的概念，并将其应用于视觉和语言领域。通过计算图像和文本的条件分布扭曲程度来量化信息增益。使用Skip-Gram with Negative Sampling（SGNS）的理论结果来估计信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;OpenCLIP的实验结果表明，信息增益最低的图像通常对应于占位符图标，如“图片未找到”。信息增益的测量与CLIP或SigLIP有强相关性，相关系数在0.98到1.00之间。计算成本与样本大小无关，且与公开的开放权重模型兼容。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习模型计算图像和文本的语义信息量是可行的，且具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has the capacity to model multimodal probabilitydistributions by embedding and aligning visual representations with semanticsfrom captions. This approach enables the estimation of relational semanticsimilarity; however, it remains unclear whether it can also represent absolutesemantic informativeness. In this work, we introduce a semantic informativenessmetric for an image calculated from text samples via a contrastive learningmodel; similarly, the informativeness of a text is calculated from imagesamples. We propose a redefinition of the concept of Information Gain, aconcept previously explored in natural language processing, extending itsapplication to the domains of vision and language. Our metric quantifies howconditioning on an image distorts the distribution of associated texts, andvice versa for text conditioning on image distributions. In OpenCLIP'sempirical results, we observe that images with the lowest Information Gainscores often correspond to placeholder icons such as "image not found."Furthermore, we propose to measure a norm-based metric of the embedding toestimate the Information Gain, following the theoretical results for Skip-Gramwith Negative Sampling (SGNS) word embedding. Information Gain can be measuredusing either CLIP or SigLIP, and the results demonstrate a strong correlationwith a coefficient of determination ranging from 0.98 to 1.00. After obtainingthe mean and the covariance of the sample embedding, the computational cost ofthis method is independent of the sample size, and it is compatible withpublicly available, open-weight models.</description>
      <author>example@mail.com (Fumiya Uchiyama, Rintaro Yanagi, Shohei Taniguchi, Shota Takashiro, Masahiro Suzuki, Hirokatsu Kataoka, Yusuke Iwasawa, Yutaka Matsuo)</author>
      <guid isPermaLink="false">2506.22881v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment</title>
      <link>http://arxiv.org/abs/2506.23358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了联邦时间线合成（FTS）框架，用于在分布式时间序列数据上训练生成性基础模型，应用于电子健康记录（EHR）。FTS将患者历史表示为标记化的患者健康时间线（PHTs），编码了时间、分类和连续的临床信息。&lt;h4&gt;背景&lt;/h4&gt;FTS框架旨在解决在分布式环境下处理电子健康记录时遇到的隐私和可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;FTS旨在创建一个能够合成患者健康时间线的大型语料库，并通过蒙特卡洛模拟未来PHTs实现零样本推理。&lt;h4&gt;方法&lt;/h4&gt;每个机构在其本地PHTs上训练一个自回归变压器，并将模型权重传输到中央服务器。服务器使用生成器合成语料库，并训练全局生成器（GG）。&lt;h4&gt;主要发现&lt;/h4&gt;在五个具有临床意义的预测任务上评估FTS，结果表明GG生成的合成数据训练的模型性能与真实数据训练的模型相当。&lt;h4&gt;结论&lt;/h4&gt;FTS提供了强大的隐私保障，具有跨机构的可扩展性和扩展性，特别适用于医疗保健领域的预测和模拟任务，如反事实推理、早期预警检测和合成试验设计。&lt;h4&gt;翻译&lt;/h4&gt;We present Federated Timeline Synthesis (FTS), a novel framework for training generative foundation models across distributed timeseries data applied to electronic health records (EHR). At its core, FTS represents patient history as tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding temporal, categorical, and continuous clinical information. Each institution trains an autoregressive transformer on its local PHTs and transmits only model weights to a central server. The server uses the generators to synthesize a large corpus of trajectories and train a Global Generator (GG), enabling zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS on five clinically meaningful prediction tasks using MIMIC-IV data, showing that models trained on synthetic data generated by GG perform comparably to those trained on real data. FTS offers strong privacy guarantees, scalability across institutions, and extensibility to diverse prediction and simulation tasks especially in healthcare, including counterfactual inference, early warning detection, and synthetic trial design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Federated Timeline Synthesis (FTS), a novel framework for traininggenerative foundation models across distributed timeseries data applied toelectronic health records (EHR). At its core, FTS represents patient history astokenized Patient Health Timelines (PHTs), language-agnostic sequences encodingtemporal, categorical, and continuous clinical information. Each institutiontrains an autoregressive transformer on its local PHTs and transmits only modelweights to a central server. The server uses the generators to synthesize alarge corpus of trajectories and train a Global Generator (GG), enablingzero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTSon five clinically meaningful prediction tasks using MIMIC-IV data, showingthat models trained on synthetic data generated by GG perform comparably tothose trained on real data. FTS offers strong privacy guarantees, scalabilityacross institutions, and extensibility to diverse prediction and simulationtasks especially in healthcare, including counterfactual inference, earlywarning detection, and synthetic trial design.</description>
      <author>example@mail.com (Pawel Renc, Michal K. Grzeszczyk, Linglong Qian, Nassim Oufattole, Jeff Rasley, Arkadiusz Sitek)</author>
      <guid isPermaLink="false">2506.23358v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition</title>
      <link>http://arxiv.org/abs/2506.22836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICME 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了FOCUS方法，用于行人属性识别，通过自适应地提取每个属性的精细粒度特征，提高了性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;行人属性识别是智能交通和安全的基石，现有方法主要依靠区域特征提取属性信息，但这种方法存在局限。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法中区域特征的局限性，提高属性识别的性能和实用性。&lt;h4&gt;方法&lt;/h4&gt;FOCUS方法通过以下步骤实现：1) 提出多粒度混合标记（MGMT）来捕捉不同视觉粒度级别的潜在特征；2) 引入属性引导的视觉特征提取（AVFE）模块，使用交叉注意力机制从混合标记中检索相应的视觉属性特征；3) 结合区域感知对比学习（RACL）方法，确保文本属性关注适当的混合标记。&lt;h4&gt;主要发现&lt;/h4&gt;FOCUS方法在PA100K、PETA和RAPv1数据集上进行了广泛的实验，证明了其有效性和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;FOCUS方法在行人属性识别任务中具有显著的优势，为该领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：行人属性识别（PAR）是智能交通和安全中的基本感知任务。为了应对这个细粒度任务，大多数现有方法侧重于提取区域特征以丰富属性信息。然而，在 这些方法中，区域特征通常用于预测一组预定义的属性，这在两个方面限制了性能和实用性：1）区域特征可能会以捕捉属性之间共享的通用特征为代价，牺牲了某些属性独有的精细粒度模式。2）区域特征无法泛化到测试时预测未见过的属性。在本文中，我们提出了用于PAR的FOCUS方法，该方法自适应地提取每个属性的属性级别的精细粒度特征，无论这些属性在训练期间是否被看到。具体来说，我们提出了多粒度混合标记（MGMT）来捕捉不同视觉粒度级别的潜在特征，从而丰富提取信息的多样性。接下来，我们引入了属性引导的视觉特征提取（AVFE）模块，该模块利用文本属性作为查询，使用交叉注意力机制从混合标记中检索相应的视觉属性特征。为了确保文本属性关注适当的混合标记，我们进一步结合了区域感知对比学习（RACL）方法，鼓励同一区域内的属性共享一致的注意力图。在PA100K、PETA和RAPv1数据集上进行的广泛实验证明了我们方法的有效性和强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pedestrian attribute recognition (PAR) is a fundamental perception task inintelligent transportation and security. To tackle this fine-grained task, mostexisting methods focus on extracting regional features to enrich attributeinformation. However, a regional feature is typically used to predict a fixedset of pre-defined attributes in these methods, which limits the performanceand practicality in two aspects: 1) Regional features may compromisefine-grained patterns unique to certain attributes in favor of capturing commoncharacteristics shared across attributes. 2) Regional features cannotgeneralize to predict unseen attributes in the test time. In this paper, wepropose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, whichadaptively extracts fine-grained attribute-level features for each attributeindividually, regardless of whether the attributes are seen or not duringtraining. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) tocapture latent features at varying levels of visual granularity, therebyenriching the diversity of the extracted information. Next, we introduce theAttribute-guided Visual Feature Extraction (AVFE) module, which leveragestextual attributes as queries to retrieve their corresponding visual attributefeatures from the Mix Tokens using a cross-attention mechanism. To ensure thattextual attributes focus on the appropriate Mix Tokens, we further incorporatea Region-Aware Contrastive Learning (RACL) method, encouraging attributeswithin the same region to share consistent attention maps. Extensiveexperiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectivenessand strong generalization ability of our method.</description>
      <author>example@mail.com (Hongyan An, Kuan Zhu, Xin He, Haiyun Guo, Chaoyang Zhao, Ming Tang, Jinqiao Wang)</author>
      <guid isPermaLink="false">2506.22836v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>GATSim: Urban Mobility Simulation with Generative Agents</title>
      <link>http://arxiv.org/abs/2506.23306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATSim的新型城市交通模拟框架，该框架利用大型语言模型和AI代理技术，创建了具有丰富行为特征和自适应学习机制的生成代理，以模拟城市交通。&lt;h4&gt;背景&lt;/h4&gt;传统的基于规则的城市交通模拟系统无法捕捉人类出行决策的复杂性、适应性和行为多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模拟人类出行决策的智能代理系统。&lt;h4&gt;方法&lt;/h4&gt;GATSim框架结合了城市交通基础模型、代理认知系统和交通模拟环境，并实现了生成代理的全面架构。&lt;h4&gt;主要发现&lt;/h4&gt;GATSim代理具有多样化的社会经济属性、个人生活方式和不断发展的偏好，通过心理信息记忆系统、工具使用能力和终身学习机制来塑造其出行决策。生成代理能够将特定出行经验转化为一般性见解，并通过专门的活动规划和实时反应行为机制实现行为适应。&lt;h4&gt;结论&lt;/h4&gt;GATSim代理在模拟城市交通场景中表现出与人类标注者相当的性能，并自然产生宏观交通演变模式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的基于代理的城市交通模拟依赖于僵化的基于规则的系统，这些系统无法捕捉人类出行决策的复杂性、适应性和行为多样性。近年来，大型语言模型和AI代理技术的进步为创建具有推理能力、持久记忆和自适应学习机制的代理提供了机会。我们提出了GATSim（生成代理交通模拟）这一新颖框架，它利用这些进步来创建具有丰富行为特征的城市交通模拟生成代理。与传统的做法不同，GATSim代理具有多样化的社会经济属性、个人生活方式和不断发展的偏好，它们通过心理信息记忆系统、工具使用能力和终身学习机制来塑造其出行决策。本研究的主要贡献包括：（1）一个综合架构，结合了城市交通基础模型、代理认知系统和交通模拟环境；（2）一个功能齐全的原型实现；（3）系统验证表明，生成代理产生可信的出行行为。通过设计反思过程，本研究中的生成代理可以将特定的出行经验转化为一般性见解，通过专门的活动规划和针对城市交通环境的实时反应行为机制实现行为适应。实验表明，生成代理在模拟城市交通场景中的表现与人类标注者相当，并自然产生宏观交通演变模式。原型系统的代码可在https://github.com/qiliuchn/gatsim上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional agent-based urban mobility simulations rely on rigid rule-basedsystems that fail to capture the complexity, adaptability, and behavioraldiversity characteristic of human travel decision-making. Recent advances inlarge language models and AI agent technology offer opportunities to createagents with reasoning capabilities, persistent memory, and adaptive learningmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novelframework that leverages these advances to create generative agents with richbehavioral characteristics for urban mobility simulation. Unlike conventionalapproaches, GATSim agents possess diverse socioeconomic attributes, individuallifestyles, and evolving preferences that shape their mobility decisionsthrough psychologically-informed memory systems, tool usage capabilities, andlifelong learning mechanisms. The main contributions of this study include: (1)a comprehensive architecture combining an urban mobility foundation model withagent cognitive systems and transport simulation environment, (2) a fullyfunctional prototype implementation, and (3) systematic validationdemonstrating that generative agents produce believable travel behaviors.Through designed reflection processes, generative agents in this study cantransform specific travel experiences into generalized insights, enablingrealistic behavioral adaptation over time with specialized mechanisms foractivity planning and real-time reactive behaviors tailored to urban mobilitycontexts. Experiments show that generative agents perform competitively withhuman annotators in mobility scenarios while naturally producing macroscopictraffic evolution patterns. The code for the prototype system is shared athttps://github.com/qiliuchn/gatsim.</description>
      <author>example@mail.com (Qi Liu, Can Li, Wanjing Ma)</author>
      <guid isPermaLink="false">2506.23306v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Task-Agnostic Contrastive Pretraining for Relational Deep Learning</title>
      <link>http://arxiv.org/abs/2506.22530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2506.22199&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的任务无关的对比预训练方法，用于关系深度学习（RDL），该方法通过表示关系数据库为异构图来直接从关系数据库中学习，旨在提高可扩展性和重用性。&lt;h4&gt;背景&lt;/h4&gt;现有的RDL模型通常依赖于特定任务的监督学习，需要为每个预测任务训练单独的模型，这可能会阻碍可扩展性和重用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够进行数据库范围表示学习的方法，以实现任务无关的对比预训练。&lt;h4&gt;方法&lt;/h4&gt;引入了行级、链接级和上下文级三种对比目标，以捕捉关系数据中固有的结构和语义异质性。通过模块化RDL架构和针对异构数据库设置的有效采样策略来实现预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;在标准RDL基准测试上的初步结果表明，微调预训练模型显著优于从头开始训练，验证了该方法在关系数据迁移学习表示中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在RDL领域具有提高可扩展性和重用性的潜力，并通过实验证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational Deep Learning (RDL) is an emerging paradigm that leverages GraphNeural Network principles to learn directly from relational databases byrepresenting them as heterogeneous graphs. However, existing RDL modelstypically rely on task-specific supervised learning, requiring trainingseparate models for each predictive task, which may hamper scalability andreuse.  In this work, we propose a novel task-agnostic contrastive pretrainingapproach for RDL that enables database-wide representation learning. For thataim, we introduce three levels of contrastive objectives$-$row-level,link-level, and context-level$-$designed to capture the structural and semanticheterogeneity inherent to relational data. We implement the respectivepretraining approach through a modular RDL architecture and an efficientsampling strategy tailored to the heterogeneous database setting. Ourpreliminary results on standard RDL benchmarks demonstrate that fine-tuning thepretrained models measurably outperforms training from scratch, validating thepromise of the proposed methodology in learning transferable representationsfor relational data.</description>
      <author>example@mail.com (Jakub Peleška, Gustav Šír)</author>
      <guid isPermaLink="false">2506.22530v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds</title>
      <link>http://arxiv.org/abs/2506.22749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的联合几何和属性上采样（JGAU）方法，用于生成大规模和密集的彩色点云，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;彩色点云是三维应用中的一种主流表示形式，它包括几何和属性组件，能够实现真实感和沉浸感。&lt;h4&gt;目的&lt;/h4&gt;为了生成大规模和更密集的彩色点云，提出了一种新的深度学习方法。&lt;h4&gt;方法&lt;/h4&gt;1. 建立并发布了一个名为SYSU-PCUD的大规模彩色点云上采样数据集。2. 提出了一个基于深度学习的JGAU框架，该框架包括几何上采样网络和属性上采样网络。3. 提出了两种粗属性上采样方法：几何距离加权属性插值（GDWAI）和基于深度学习的属性插值（DLAI）。4. 引入了一个属性增强模块来细化上采样属性，并进一步利用内在属性和几何模式生成高质量点云。&lt;h4&gt;主要发现&lt;/h4&gt;JGAU方法在不同上采样率下（4倍、8倍、12倍和16倍）分别达到了33.90分贝、32.10分贝、31.10分贝和30.39分贝的峰值信噪比（PSNR），并且与现有方法相比，平均PSNR增益分别为2.32分贝、2.47分贝、2.28分贝和2.11分贝。&lt;h4&gt;结论&lt;/h4&gt;JGAU方法在彩色点云上采样方面取得了显著的改进，提高了点云的质量和分辨率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colored point cloud, which includes geometry and attribute components, is amainstream representation enabling realistic and immersive 3D applications. Togenerate large-scale and denser colored point clouds, we propose a deeplearning-based Joint Geometry and Attribute Up-sampling (JGAU) method thatlearns to model both geometry and attribute patterns while leveraging spatialattribute correlations. First, we establish and release a large-scale datasetfor colored point cloud up-sampling called SYSU-PCUD, containing 121large-scale colored point clouds with diverse geometry and attributecomplexities across six categories and four sampling rates. Second, to improvethe quality of up-sampled point clouds, we propose a deep learning-based JGAUframework that jointly up-samples geometry and attributes. It consists of ageometry up-sampling network and an attribute up-sampling network, where thelatter leverages the up-sampled auxiliary geometry to model neighborhoodcorrelations of the attributes. Third, we propose two coarse attributeup-sampling methods, Geometric Distance Weighted Attribute Interpolation(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generatecoarse up-sampled attributes for each point. Then, an attribute enhancementmodule is introduced to refine these up-sampled attributes and producehigh-quality point clouds by further exploiting intrinsic attribute andgeometry patterns. Extensive experiments show that the Peak Signal-to-NoiseRatio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,8 times, 12 times, and 16 times, respectively. Compared to state-of-the-artmethods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28decibels, and 2.11 decibels at these four up-sampling rates, demonstratingsignificant improvement.</description>
      <author>example@mail.com (Yun Zhang, Feifan Chen, Na Li, Zhiwei Guo, Xu Wang, Fen Miao, Sam Kwong)</author>
      <guid isPermaLink="false">2506.22749v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation</title>
      <link>http://arxiv.org/abs/2506.23271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Mettle的元-标记学习（Meta-Token Learning）方法，用于将大规模预训练的Transformer模型适应下游音频-视觉任务。&lt;h4&gt;背景&lt;/h4&gt;传统的Transformer模型在处理音频-视觉任务时，需要逐个修改模型的输出特征分布，这既复杂又低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单且内存高效的元-标记学习方法，以适应大规模预训练的Transformer模型到音频-视觉任务。&lt;h4&gt;方法&lt;/h4&gt;Mettle使用一个轻量级的层中心蒸馏（Layer-Centric Distillation, LCD）模块，并行地将每个Transformer层嵌入的完整音频或视觉特征蒸馏成紧凑的元标记。此外，还引入了一个元标记注入（Meta-Token Injection, MTI）模块，用于引导早期层的特征适应。&lt;h4&gt;主要发现&lt;/h4&gt;Mettle方法在多个音频-视觉基准测试中显示出显著减少内存使用和训练时间，同时保持参数效率和具有竞争力的准确率。&lt;h4&gt;结论&lt;/h4&gt;Mettle是一种有效的音频-视觉任务适配方法，能够显著提高模型的性能和效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Mettle的元-标记学习（Meta-Token Learning）方法，它是一种简单且内存高效的将大规模预训练的Transformer模型适应下游音频-视觉任务的方法。不同于逐个修改Transformer主干网络的输出特征分布，Mettle使用一个轻量级的层中心蒸馏（Layer-Centric Distillation, LCD）模块，并行地将每个Transformer层嵌入的完整音频或视觉特征蒸馏成紧凑的元标记。这一蒸馏过程既考虑了预训练知识的保留，也考虑了任务特定的适应。获得的元标记可以直接应用于分类任务，如音频-视觉事件定位和音频-视觉视频解析。为了进一步支持细粒度分割任务，如音频-视觉分割，我们引入了一个元标记注入（Meta-Token Injection, MTI）模块，该模块利用从顶层Transformer层蒸馏出的音频和视觉元标记来引导早期层的特征适应。在多个音频-视觉基准测试上的广泛实验表明，我们的方法在显著减少内存使用和训练时间的同时，保持了参数效率和具有竞争力的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simpleand memory-efficient method for adapting large-scale pretrained transformermodels to downstream audio-visual tasks. Instead of sequentially modifying theoutput feature distribution of the transformer backbone, Mettle utilizes alightweight \textit{Layer-Centric Distillation (LCD)} module to distill inparallel the intact audio or visual features embedded by each transformer layerinto compact meta-tokens. This distillation process considers both pretrainedknowledge preservation and task-specific adaptation. The obtained meta-tokenscan be directly applied to classification tasks, such as audio-visual eventlocalization and audio-visual video parsing. To further support fine-grainedsegmentation tasks, such as audio-visual segmentation, we introduce a\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visualmeta-tokens distilled from the top transformer layer to guide featureadaptation in earlier layers. Extensive experiments on multiple audiovisualbenchmarks demonstrate that our method significantly reduces memory usage andtraining time while maintaining parameter efficiency and competitive accuracy.</description>
      <author>example@mail.com (Jinxing Zhou, Zhihui Li, Yongqiang Yu, Yanghao Zhou, Ruohao Guo, Guangyao Li, Yuxin Mao, Mingfei Han, Xiaojun Chang, Meng Wang)</author>
      <guid isPermaLink="false">2506.23271v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians</title>
      <link>http://arxiv.org/abs/2506.22718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种方法，用于从单个关节物体的观察点云序列中联合解决部件分割和运动估计问题。&lt;h4&gt;背景&lt;/h4&gt;部件分割和运动估计是关节物体运动分析的两个基本问题，而点云数据可能由于遮挡或多传感器异步测量等原因，导致无法通过追踪点对应关系来解决问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决上述问题，并提高部件分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法使用一种紧凑而有效的表示，将物体建模为一系列3D高斯函数的简单构建块，并通过时间依赖的旋转、平移和缩放参数化这些高斯函数。&lt;h4&gt;主要发现&lt;/h4&gt;通过在观察到的点与高斯函数之间建立对应关系，实现了部件分割。同时，即使某些点未被观察到，也能通过追踪分配给该点的Gaussians的位姿来获得该点随时间的变化。&lt;h4&gt;结论&lt;/h4&gt;实验表明，该方法在仅依赖点对应关系的方法之上表现更优，并且对缺失点的鲁棒性更强，在具有遮挡的挑战性数据集上，部件分割性能比最先进的方法高出13%。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从单个关节物体的观察点云序列中联合解决部件分割和运动估计问题的方法。该方法通过将物体建模为一系列3D高斯函数的简单构建块，并通过时间依赖的旋转、平移和缩放参数化这些高斯函数，实现了部件分割。实验结果表明，该方法在仅依赖点对应关系的方法之上表现更优，并且对缺失点的鲁棒性更强，在具有遮挡的挑战性数据集上，部件分割性能比最先进的方法高出13%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Part segmentation and motion estimation are two fundamental problems forarticulated object motion analysis. In this paper, we present a method to solvethese two problems jointly from a sequence of observed point clouds of a singlearticulated object. The main challenge in our problem setting is that the pointclouds are not assumed to be generated by a fixed set of moving points.Instead, each point cloud in the sequence could be an arbitrary sampling of theobject surface at that particular time step. Such scenarios occur when theobject undergoes major occlusions, or if the dataset is collected usingmeasurements from multiple sensors asynchronously. In these scenarios, methodsthat rely on tracking point correspondences are not appropriate. We present analternative approach based on a compact but effective representation where werepresent the object as a collection of simple building blocks modeled as 3DGaussians. We parameterize the Gaussians with time-dependent rotations,translations, and scales that are shared across all time steps. With ourrepresentation, part segmentation can be achieved by building correspondencesbetween the observed points and the Gaussians. Moreover, the transformation ofeach point across time can be obtained by following the poses of the assignedGaussian (even when the point is not observed). Experiments show that ourmethod outperforms existing methods that solely rely on finding pointcorrespondences. Additionally, we extend existing datasets to emulatereal-world scenarios by considering viewpoint occlusions. We furtherdemonstrate that our method is more robust to missing points as compared toexisting approaches on these challenging datasets, even when some parts arecompletely occluded in some time-steps. Notably, our part segmentationperformance outperforms the state-of-the-art method by 13% on point clouds withocclusions.</description>
      <author>example@mail.com (Jun-Jee Chao, Qingyuan Jiang, Volkan Isler)</author>
      <guid isPermaLink="false">2506.22718v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval</title>
      <link>http://arxiv.org/abs/2506.23132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear at AVSS'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了艺术剽窃检测问题，通过构建数据集和改进模型来识别和解释剽窃作品。&lt;h4&gt;背景&lt;/h4&gt;艺术剽窃检测对于保护艺术家版权和知识产权至关重要，但在法医分析中仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;识别剽窃画作并解释检测到的剽窃，通过检索视觉上相似的真实艺术品来实现。&lt;h4&gt;方法&lt;/h4&gt;构建了一个数据集，收集画作照片并使用生成式AI合成剽窃版本。使用DINOv2视觉基础模型作为基线方法，通过设置相似度阈值来识别剽窃。通过度量学习损失微调DINOv2模型，以提高检索质量。&lt;h4&gt;主要发现&lt;/h4&gt;基线方法实现了97.2%的识别准确率，但检索精度低（平均精度AP为29.0%）。微调后的模型在检索性能上提高了12%的AP，但识别准确率下降到92.7%。&lt;h4&gt;结论&lt;/h4&gt;本文提出了艺术剽窃检测的新方法，并通过实验验证了其有效性，为未来研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了艺术剽窃检测问题，通过构建数据集和改进模型来识别和解释剽窃作品。在法医分析中，艺术剽窃检测对于保护艺术家版权和知识产权至关重要，但仍然是一个挑战。本文旨在识别剽窃画作并解释检测到的剽窃，通过检索视觉上相似的真实艺术品来实现。为了支持这一研究，构建了一个数据集，收集画作照片并使用生成式AI合成剽窃版本。基线方法采用DINOv2视觉基础模型，通过设置相似度阈值来识别剽窃。为了提高检索质量，使用度量学习损失对DINOv2模型进行微调。实验结果表明，基线方法实现了97.2%的识别准确率，但检索精度低（平均精度AP为29.0%）。微调后的模型在检索性能上提高了12%的AP，但识别准确率下降到92.7%。本文通过富有洞察力的讨论，并概述了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Art plagiarism detection plays a crucial role in protecting artists'copyrights and intellectual property, yet it remains a challenging problem inforensic analysis. In this paper, we address the task of recognizingplagiarized paintings and explaining the detected plagarisms by retrievingvisually similar authentic artworks. To support this study, we construct adataset by collecting painting photos and synthesizing plagiarized versionsusing generative AI, tailored to specific artists' styles. We first establish abaseline approach using off-the-shelf features from the visual foundation modelDINOv2 to retrieve the most similar images in the database and classifyplagiarism based on a similarity threshold. Surprisingly, this non-learnedmethod achieves a high recognition accuracy of 97.2\% but suffers from lowretrieval precision 29.0\% average precision (AP). To improve retrievalquality, we finetune DINOv2 with a metric learning loss using positive andnegative sample pairs sampled in the database. The finetuned model greatlyimproves retrieval performance by 12\% AP over the baseline, though itunexpectedly results in a lower recognition accuracy (92.7\%). We conclude withinsightful discussions and outline directions for future research.</description>
      <author>example@mail.com (Sophie Zhou, Shu Kong)</author>
      <guid isPermaLink="false">2506.23132v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy</title>
      <link>http://arxiv.org/abs/2506.23123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Stanford University PhD Dissertation of Rishi Bommasani (Department  of Computer Science, 2025). Also available at  https://purl.stanford.edu/zf669yy0336&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能时代技术与社会共演的现象，通过三个主题展开论述：基础模型的能力、风险和供应链；通过模型级和机构级评估创建的透明度；以及从理解到行动的转变，以提升对基础模型社会影响的了解，从而推动基于证据的人工智能政策。&lt;h4&gt;背景&lt;/h4&gt;人工智能被视为人类最有希望的技术，但同时也引发了困惑和担忧，因为基础模型的理解不足且可能带来广泛危害。&lt;h4&gt;目的&lt;/h4&gt;解释人工智能时代技术与社会共演的现象，并探讨如何通过建立科学基础和研究政策接口来改善人工智能治理。&lt;h4&gt;方法&lt;/h4&gt;通过概念框架、实证洞察和从理解到行动的转变三个主题来组织论述。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在更广泛的经济体中的能力、风险和供应链；通过模型级和机构级评估实现的透明度；以及提升对基础模型社会影响的了解以推动基于证据的人工智能政策。&lt;h4&gt;结论&lt;/h4&gt;本文为在人工智能时代实现更好的社会成果提供了科学基础和研究政策接口，有助于改善人工智能治理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence is humanity's most promising technology because ofthe remarkable capabilities offered by foundation models. Yet, the sametechnology brings confusion and consternation: foundation models are poorlyunderstood and they may precipitate a wide array of harms. This dissertationexplains how technology and society coevolve in the age of AI, organized aroundthree themes. First, the conceptual framing: the capabilities, risks, and thesupply chain that grounds foundation models in the broader economy. Second, theempirical insights that enrich the conceptual foundations: transparency createdvia evaluations at the model level and indexes at the organization level.Finally, the transition from understanding to action: superior understanding ofthe societal impact of foundation models advances evidence-based AI policy.View together, this dissertation makes inroads into achieving better societaloutcomes in the age of AI by building the scientific foundations andresearch-policy interface required for better AI governance.</description>
      <author>example@mail.com (Rishi Bommasani)</author>
      <guid isPermaLink="false">2506.23123v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages</title>
      <link>http://arxiv.org/abs/2506.22529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Misinfo-TeleGraph，这是一个用于虚假信息检测的德语Telegram图数据集，包含超过500万条消息，并进行了元数据、频道关系和弱标签与强标签的丰富。通过评估文本模型和图神经网络，研究发现GraphSAGE与LSTM聚合在MCC和F1-score上显著优于文本模型。此外，研究了订阅者、观看次数和标签类型对性能的影响，并强调了弱监督在此领域的潜力和挑战。&lt;h4&gt;背景&lt;/h4&gt;连接性和信息传播在虚假信息检测中是关键信息来源，但在Telegram等平台上的应用不足。&lt;h4&gt;目的&lt;/h4&gt;建立Misinfo-TeleGraph数据集，并评估其在虚假信息检测中的性能。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含5百万条消息的图数据集，使用M3-embeddings和手动标注进行标签，评估了文本模型和图神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;GraphSAGE与LSTM聚合在MCC和F1-score上优于文本模型，并探讨了弱监督的影响。&lt;h4&gt;结论&lt;/h4&gt;Misinfo-TeleGraph为德语Telegram网络和其他低监管社交平台上的虚假信息检测提供了可复现的基准和开放数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：连接性和信息传播是虚假信息检测的核心，但在Telegram等平台上的应用往往不足。本文介绍了Misinfo-TeleGraph，这是第一个用于虚假信息检测的德语Telegram图数据集，包含超过500万条消息，并丰富了元数据、频道关系和弱标签与强标签。通过评估文本模型和图神经网络，我们发现GraphSAGE与LSTM聚合在MCC和F1-score上显著优于文本模型。此外，我们还评估了订阅者、观看次数和自动与人工创建的标签对性能的影响，并强调了弱监督在此领域的潜力和挑战。这项工作为德语Telegram网络和其他低监管社交平台上的虚假信息检测提供了可复现的基准和开放数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Connectivity and message propagation are central, yet often underutilized,sources of information in misinformation detection -- especially on poorlymoderated platforms such as Telegram, which has become a critical channel formisinformation dissemination, namely in the German electoral context. In thispaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-basedgraph dataset for misinformation detection. It includes over 5 million messagesfrom public channels, enriched with metadata, channel relationships, and bothweak and strong labels. These labels are derived via semantic similarity tofact-checks and news articles using M3-embeddings, as well as manualannotation. To establish reproducible baselines, we evaluate both text-onlymodels and graph neural networks (GNNs) that incorporate message forwarding asa network structure. Our results show that GraphSAGE with LSTM aggregationsignificantly outperforms text-only baselines in terms of Matthews CorrelationCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,view counts, and automatically versus human-created labels on performance, andhighlight both the potential and challenges of weak supervision in this domain.This work provides a reproducible benchmark and open dataset for futureresearch on misinformation detection in German-language Telegram networks andother low-moderation social platforms.</description>
      <author>example@mail.com (Lu Kalkbrenner, Veronika Solopova, Steffen Zeiler, Robert Nickel, Dorothea Kolossa)</author>
      <guid isPermaLink="false">2506.22529v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding</title>
      <link>http://arxiv.org/abs/2506.23075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了CSBrain，一种用于跨尺度时空脑活动解码的基础模型，旨在提高EEG信号解码的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;EEG信号解码是神经科学和人工智能领域的基本挑战，应用包括认知、情感识别、诊断和脑-机接口。&lt;h4&gt;目的&lt;/h4&gt;提出CSBrain模型，以解决现有EEG基础模型忽视神经活动跨尺度时空结构的问题，从而提高解码效果。&lt;h4&gt;方法&lt;/h4&gt;CSBrain模型引入了跨尺度时空标记（CST）和结构化稀疏注意力（SSA）机制。CST用于将多尺度特征聚合为紧凑的尺度感知标记，而SSA用于捕捉跨窗口和跨区域的依赖关系，增强尺度多样性并去除虚假相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在11个EEG任务和16个数据集上的实验表明，CSBrain在性能上优于特定任务和基础模型基线，证明了跨尺度建模的重要性。&lt;h4&gt;结论&lt;/h4&gt;CSBrain作为一种鲁棒的基础模型，对于未来的脑-机接口研究具有重要意义，并建立了跨尺度建模作为关键归纳偏置的地位。&lt;h4&gt;翻译&lt;/h4&gt;Understanding and decoding brain activity from electroencephalography (EEG) signals is a fundamental challenge in neuroscience and AI, with applications in cognition, emotion recognition, diagnosis, and brain-computer interfaces. While recent EEG foundation models advance generalized decoding via unified architectures and large-scale pretraining, they adopt a scale-agnostic dense modeling paradigm inherited from NLP and vision. This design neglects a core property of neural activity: cross-scale spatiotemporal structure. EEG task patterns span a wide range of temporal and spatial scales, from short bursts to slow rhythms, and from localized cortical responses to distributed interactions. Ignoring this diversity leads to suboptimal representations and weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain foundation model for generalized EEG decoding. CSBrain introduces: (i) Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale features from localized temporal windows and anatomical brain regions into compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which captures cross-window and cross-region dependencies, enhancing scale diversity while removing spurious correlations. CST and SSA are alternately stacked to progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks across 16 datasets show that CSBrain consistently outperforms task-specific and foundation model baselines. These results establish cross-scale modeling as a key inductive bias and position CSBrain as a robust backbone for future brain-AI research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and decoding brain activity from electroencephalography (EEG)signals is a fundamental challenge in neuroscience and AI, with applications incognition, emotion recognition, diagnosis, and brain-computer interfaces. Whilerecent EEG foundation models advance generalized decoding via unifiedarchitectures and large-scale pretraining, they adopt a scale-agnostic densemodeling paradigm inherited from NLP and vision. This design neglects a coreproperty of neural activity: cross-scale spatiotemporal structure. EEG taskpatterns span a wide range of temporal and spatial scales, from short bursts toslow rhythms, and from localized cortical responses to distributedinteractions. Ignoring this diversity leads to suboptimal representations andweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brainfoundation model for generalized EEG decoding. CSBrain introduces: (i)Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scalefeatures from localized temporal windows and anatomical brain regions intocompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), whichcaptures cross-window and cross-region dependencies, enhancing scale diversitywhile removing spurious correlations. CST and SSA are alternately stacked toprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasksacross 16 datasets show that CSBrain consistently outperforms task-specific andfoundation model baselines. These results establish cross-scale modeling as akey inductive bias and position CSBrain as a robust backbone for futurebrain-AI research.</description>
      <author>example@mail.com (Yuchen Zhou, Jiamin Wu, Zichen Ren, Zhouheng Yao, Weiheng Lu, Kunyu Peng, Qihao Zheng, Chunfeng Song, Wanli Ouyang, Chao Gou)</author>
      <guid isPermaLink="false">2506.23075v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Hidden Link Between RLHF and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.22578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）与人类价值观的契合问题，探讨了RLHF和DPO两种方法，并揭示了它们与对比学习的深刻联系。&lt;h4&gt;背景&lt;/h4&gt;近期，LLMs与人类价值观的契合问题受到广泛关注，其中RLHF和DPO是两个典型的例子。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过分析RLHF和DPO，揭示它们与对比学习的关系，并提出一种新的方法来优化LLMs。&lt;h4&gt;方法&lt;/h4&gt;本文从互信息（MI）最大化的角度解释了RLHF和DPO，并基于此提出了 Mutual Information Optimization (MIO) 方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，RLHF和DPO可以看作是基于正负样本的对比学习方法，并利用了Donsker-Varadhan (DV) 下界来优化互信息。&lt;h4&gt;结论&lt;/h4&gt;MIO方法可以有效缓解DPO中观察到的选择似然率晚期下降问题，并在多个推理和数学基准测试中表现出竞争力或优越性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the alignment of large language models (LLMs) with human values, discusses two methods: RLHF and DPO, and reveals their profound connection to contrastive learning. This study aims to analyze RLHF and DPO to reveal their relationship with contrastive learning and proposes a new method to optimize LLMs. The study finds that RLHF and DPO can be regarded as contrastive learning methods based on positive and negative samples, and utilizes the Donsker-Varadhan (DV) lower bound to optimize mutual information. The Mutual Information Optimization (MIO) method can effectively mitigate the late-stage decline in the selected likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alignment of large language models (LLMs) with human values has recentlygarnered significant attention, with prominent examples including the canonicalyet costly Reinforcement Learning from Human Feedback (RLHF) and the simpleDirect Preference Optimization (DPO). In this work, we demonstrate that bothRLHF and DPO can be interpreted from the perspective of mutual information (MI)maximization, uncovering a profound connection to contrastive learning. Withinthis framework, both RLHF and DPO can be viewed as methods that performcontrastive learning based on the positive and negative samples derived fromthe base model, leveraging the Donsker-Varadhan (DV) lower bound on MI(equivalently, the MINE estimator). This paradigm further explains why RLHF maynot intrinsically incentivize reasoning capacities in LLMs beyond what isalready present in the base model. Building on this perspective, we replace theDV/MINE bound with the Jensen-Shannon MI estimator and propose MutualInformation Optimization (MIO). Comprehensive theoretical analysis andextensive empirical evaluations demonstrate that MIO mitigates the late-stagedecline in chosen-likelihood observed in DPO, achieving competitive or superiorperformance across various challenging reasoning and mathematical benchmarks.We will release the model and code upon acceptance.</description>
      <author>example@mail.com (Xufei Lv, Haoyuan Sun, Xuefeng Bai, Min Zhang, Houde Liu, Kehai Chen)</author>
      <guid isPermaLink="false">2506.22578v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Missing Link: Joint Legal Citation Prediction using Heterogeneous Graph Enrichment</title>
      <link>http://arxiv.org/abs/2506.22165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的链接预测模型，用于识别法律案例和法律规范之间的引用关系，并通过融合语义和拓扑信息提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;法律体系高度依赖法律规范和先前的法院判决的交叉引用。法律从业者、新手和法律AI系统需要访问这些相关数据来进行评估和判断。&lt;h4&gt;目的&lt;/h4&gt;提高案例和法律规范引用的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种融合语义和拓扑信息的GNN链接预测模型，使用适应的图卷积操作在扩展和丰富版本的原始引用图上运行，以实现语义元信息的拓扑整合。&lt;h4&gt;主要发现&lt;/h4&gt;该模型通过整合语义和拓扑信息，平均精度提高了3.1点，在数据稀疏性方面提高了8.5点，并在时间上和具有挑战性的全归纳预测中表现出鲁棒性能。联合学习和预测案例和规范引用实现了显著的协同效应，使案例引用预测提高了4.7点，效率几乎翻倍。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GNN模型在提高法律案例和法律规范引用预测准确性方面是有效的，并且具有更高的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Legal systems heavily rely on cross-citations of legal norms as well asprevious court decisions. Practitioners, novices and legal AI systems needaccess to these relevant data to inform appraisals and judgments. We propose aGraph-Neural-Network (GNN) link prediction model that can identify Case-Law andCase-Case citations with high proficiency through fusion of semantic andtopological information. We introduce adapted relational graph convolutionsoperating on an extended and enriched version of the original citation graphthat allow the topological integration of semantic meta-information. Thisfurther improves prediction by 3.1 points of average precision and by 8.5points in data sparsity as well as showing robust performance over time and inchallenging fully inductive prediction. Jointly learning and predicting caseand norm citations achieves a large synergistic effect that improves casecitation prediction by up to 4.7 points, at almost doubled efficiency.</description>
      <author>example@mail.com (Lorenz Wendlinger, Simon Alexander Nonn, Abdullah Al Zubaer, Michael Granitzer)</author>
      <guid isPermaLink="false">2506.22165v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation</title>
      <link>http://arxiv.org/abs/2506.22827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the RSS 2025 Workshop on Robot Planning in the Era of  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种分层规划和控制框架，旨在实现可靠的多步人形机器人操作。&lt;h4&gt;背景&lt;/h4&gt;可靠执行复杂多步操作对于人形机器人在工业和家庭环境中的有效部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个分层规划和控制框架，以实现可靠的多步人形机器人操作。&lt;h4&gt;方法&lt;/h4&gt;该系统包括三个层次：(1) 负责跟踪全身运动目标的低级基于强化学习的控制器；(2) 通过模仿学习训练的技能策略，为任务的各个步骤生成运动目标；(3) 决定应该执行哪些技能并实时监控其完成情况的高级视觉-语言规划模块，使用预训练的视觉-语言模型（VLMs）。&lt;h4&gt;主要发现&lt;/h4&gt;在Unitree G1人形机器人上执行非抓取式捡起和放置任务时，经过40次真实世界试验，分层系统在完成整个操作序列中达到了72.5%的成功率。&lt;h4&gt;结论&lt;/h4&gt;这些实验证实了所提出的分层系统的可行性，突出了基于VLM的技能规划和监控在多步操作场景中的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使人形机器人能够可靠地执行复杂的多步操作对于它们在工业和家庭环境中的有效部署至关重要。本文提出了一种旨在实现可靠多步人形机器人操作的分层规划和控制框架。所提出的系统包括三个层次：(1) 负责跟踪全身运动目标的基于强化学习的低级控制器；(2) 通过模仿学习训练的技能策略，为任务的各个步骤生成运动目标；(3) 决定应该执行哪些技能并实时监控其完成情况的高级视觉-语言规划模块，使用预训练的视觉-语言模型（VLMs）。在Unitree G1人形机器人上执行非抓取式捡起和放置任务时，经过40次真实世界试验，分层系统在完成整个操作序列中达到了72.5%的成功率。这些实验证实了所提出的分层系统的可行性，突出了基于VLM的技能规划和监控在多步操作场景中的优势。更多信息请见https://vlp-humanoid.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enabling humanoid robots to reliably execute complex multi-step manipulationtasks is crucial for their effective deployment in industrial and householdenvironments. This paper presents a hierarchical planning and control frameworkdesigned to achieve reliable multi-step humanoid manipulation. The proposedsystem comprises three layers: (1) a low-level RL-based controller responsiblefor tracking whole-body motion targets; (2) a mid-level set of skill policiestrained via imitation learning that produce motion targets for different stepsof a task; and (3) a high-level vision-language planning module that determineswhich skills should be executed and also monitors their completion in real-timeusing pretrained vision-language models (VLMs). Experimental validation isperformed on a Unitree G1 humanoid robot executing a non-prehensilepick-and-place task. Over 40 real-world trials, the hierarchical systemachieved a 72.5% success rate in completing the full manipulation sequence.These experiments confirm the feasibility of the proposed hierarchical system,highlighting the benefits of VLM-based skill planning and monitoring formulti-step manipulation scenarios. See https://vlp-humanoid.github.io/ forvideo demonstrations of the policy rollout.</description>
      <author>example@mail.com (André Schakkal, Ben Zandonati, Zhutian Yang, Navid Azizan)</author>
      <guid isPermaLink="false">2506.22827v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Learning Distributed Safe Multi-Agent Navigation via Infinite-Horizon Optimal Graph Control</title>
      <link>http://arxiv.org/abs/2506.22117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对分布式多智能体导航的无限时域CBF约束最优图控制公式，通过分析解结构，开发了一种基于HJB的学习框架来近似解，并通过实验验证了其有效性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;分布式多智能体导航在保持安全和实现目标导向行为方面面临挑战，尤其是在有限感知范围和密集障碍物未知环境中。&lt;h4&gt;目的&lt;/h4&gt;提出一种安全的多智能体导航方法，在保持安全的同时实现高效的目标导向行为。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于HJB和图神经网络（GNN）的学习框架，用于联合学习CBF、分布式控制策略和价值函数，并引入了Lagrange乘数的状态相关参数化，以实现安全和性能之间的动态权衡。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过长时域优化，能够主动避免死锁，在复杂环境中更有效地导航，并在各种智能体动力学中实现了安全性和任务成功率的显著提高。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界的实验中得到了验证，证明了其可行性、通用性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分布式多智能体导航由于在保持安全和实现目标导向行为方面的竞争性需求而面临固有的挑战，尤其是在有限感知范围和密集障碍物未知环境中运行的智能体。现有方法通常将预定义的目标到达控制器投影到控制障碍函数（CBF）约束上，通常导致安全和目标到达性能之间的保守和次优权衡。我们提出了一种无限时域CBF约束最优图控制公式，用于分布式安全多智能体导航。通过推导分析解结构，我们开发了一种基于Hamilton-Jacobi-Bellman（HJB）的学习框架来近似解。特别是，我们的算法联合学习了一个CBF和一个由图神经网络（GNN）参数化的分布式控制策略，以及一个价值函数，该价值函数稳健地引导智能体向其目标移动。此外，我们引入了Lagrange乘数的状态相关参数化，使安全和性能之间能够实现动态权衡。与传统的短时域、基于二次规划法的CBF方法不同，我们的方法利用长时域优化来主动避免死锁，并更有效地在复杂环境中导航。广泛的仿真结果表明，在各种智能体动力学中，安全性和任务成功率都得到了显著提高，并且在以前未见过的环境中具有强大的可扩展性和泛化能力。使用Crazyflie无人机群在具有挑战性的反极位置交换任务中的现实世界实验进一步验证了所提出的HJB-GNN学习框架的实用性、通用性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed multi-agent navigation faces inherent challenges due to thecompeting requirements of maintaining safety and achieving goal-directedbehavior, particularly for agents with limited sensing range operating inunknown environments with dense obstacles. Existing approaches typicallyproject predefined goal-reaching controllers onto control barrier function(CBF) constraints, often resulting in conservative and suboptimal trade-offsbetween safety and goal-reaching performance. We propose an infinite-horizonCBF-constrained optimal graph control formulation for distributed safemulti-agent navigation. By deriving the analytical solution structure, wedevelop a novel Hamilton-Jacobi-Bellman (HJB)-based learning framework toapproximate the solution. In particular, our algorithm jointly learns a CBF anda distributed control policy, both parameterized by graph neural networks(GNNs), along with a value function that robustly guides agents toward theirgoals. Moreover, we introduce a state-dependent parameterization of Lagrangemultipliers, enabling dynamic trade-offs between safety and performance. Unliketraditional short-horizon, quadratic programming-based CBF methods, ourapproach leverages long-horizon optimization to proactively avoid deadlocks andnavigate complex environments more effectively. Extensive simulation resultsdemonstrate substantial improvements in safety and task success rates acrossvarious agent dynamics, with strong scalability and generalization tolarge-scale teams in previously unseen environments. Real-world experimentsusing Crazyflie drone swarms on challenging antipodal position-swapping tasksfurther validate the practicality, generalizability, and robustness of theproposed HJB-GNN learning framework.</description>
      <author>example@mail.com (Fenglan Wang, Xinguo Shu, Lei He, Lin Zhao)</author>
      <guid isPermaLink="false">2506.22117v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs</title>
      <link>http://arxiv.org/abs/2506.22694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on  Efficient Systems for Foundational Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种无需训练的技术，旨在提高基于绘图员的推测解码（SpD）方法的性能，该方法在绘图过程中结合了语言模型头（LM头）。&lt;h4&gt;背景&lt;/h4&gt;基于绘图员的推测解码利用一个或多个较小的语言模型（称为绘图员或绘图模型）来采样一个由多个标记组成的草稿序列或树，随后由基础LLM、目标模型验证接受其子集作为有效生成。&lt;h4&gt;目的&lt;/h4&gt;识别并减少推测解码过程中草稿采样方案中的不必要的推理开销，特别是对于具有非常大词汇量的目标LLM。&lt;h4&gt;方法&lt;/h4&gt;提出了VocabTrim技术，通过限制绘图过程中的词汇量，只包含目标模型词汇中采样频率最高的有限标记集合，从而减少草稿的延迟。&lt;h4&gt;主要发现&lt;/h4&gt;VocabTrim技术稍微降低了接受率，但显著减少了内存受限过程中的草稿延迟，从而在内存受限环境中提高了内存加速比（MBSU）。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高Spec-Bench上Llama-3模型的内存加速比，特别是Llama-3.2-3B-Instruct模型，提高了16%。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种无需训练的技术，旨在提高基于绘图员的推测解码（SpD）方法的性能，该方法在绘图过程中结合了语言模型头（LM头）。基于绘图员的推测解码利用一个或多个较小的语言模型（称为绘图员或绘图模型）来采样一个由多个标记组成的草稿序列或树，随后由基础LLM、目标模型验证接受其子集作为有效生成。通常认为，推测解码需要目标模型和绘图模型的词汇表之间存在一对一的映射，因此自然地倾向于共享词汇量，甚至像EAGLE或Medusa那样共享LM头。我们首先识别出这种草稿标记采样方案在绘图过程中固有地包含不必要的推理开销，特别是对于一些具有非常大词汇量的目标LLM。然后，我们提出了一种简单的技术，称为VocabTrim，通过限制绘图过程中的词汇量，只包含目标模型词汇中采样频率最高的有限标记集合，从而减少草稿的延迟。虽然限制词汇量稍微降低了接受率，但它显著减少了内存受限过程中的草稿延迟，这在边缘设备上通常是常见的情况，从而导致了更高的内存加速比（MBSU）。我们发现，我们的方法可以提升Spec-Bench上Llama-3模型的内存加速比，特别是对于Llama-3.2-3B-Instruct模型，提高了16%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a simple training-free technique to improve theperformance of drafter-based speculative decoding (SpD) methods thatincorporates language modeling head (LM head) during drafting process. Adrafter-based speculative decoding leverages one or more smaller languagemodels, a.k.a. drafters or draft models, to sample a draft sequence or treeconsisting of multiple tokens, followed by verification by a base LLM, a targetmodel, accepting a subset as its valid generation. As it is usually consideredthat the speculative decoding requires one-to-one mapping between vocabulariesof the target model and the draft model, it has been natural to share thevocabulary between them, or even share the LM head as in EAGLE or Medusa. Wefirst identify that this draft token sampling scheme inherently contains anunnecessary inference overhead in drafting, especially for some target LLMswith very large vocabularies. Then, we propose a simple technique, VocabTrim,to mitigate the drafting overhead to improve the generation speed inmemory-bound environment. VocabTrim reconstructs the drafter LM head to containonly a limited set of tokens, selected by the most frequently sampled from thevocabulary of the target model. While limiting the vocabulary in draftingslightly degrades the acceptance rate, it significantly reduces the draftinglatency in memory-bound process which is often the case on edge devices,resulting in higher memory-bound speed up (MBSU). We show that our method canboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specificallyby 16% for Llama-3.2-3B-Instruct.</description>
      <author>example@mail.com (Raghavv Goel, Sudhanshu Agrawal, Mukul Gagrani, Junyoung Park, Yifan Zao, He Zhang, Tian Liu, Yiping Yang, Xin Yuan, Jiuyan Lu, Chris Lott, Mingu Lee)</author>
      <guid isPermaLink="false">2506.22694v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation</title>
      <link>http://arxiv.org/abs/2506.22567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MMKD-CLIP是一种通过多医学CLIP知识蒸馏方法开发的通用生物医学基础模型，它在多个生物医学数据集上表现出色。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP模型在零样本分类、跨模态检索和开放视觉问答方面表现出色，但在生物医学领域应用受到大规模生物医学图像-文本语料库稀缺、图像模态异质性和数据标准不统一等限制。&lt;h4&gt;目的&lt;/h4&gt;开发一个统一且可泛化的从零开始训练的生物医学基础模型。&lt;h4&gt;方法&lt;/h4&gt;MMKD-CLIP通过知识蒸馏从九个预训练在数百万生物医学图像-文本对上的生物医学CLIP模型中提取知识，而不是依赖于亿级原始数据。其两阶段训练流程包括在超过290万个生物医学图像-文本对上进行CLIP风格的预训练，以及使用从教师模型中提取的超过1920万个特征对进行特征级蒸馏。&lt;h4&gt;主要发现&lt;/h4&gt;MMKD-CLIP在58个多样化的生物医学数据集上进行了评估，涵盖了超过1080万个来自九种图像模态的生物医学图像。评估涵盖了六个核心任务类型：零样本分类、线性探测、跨模态检索、视觉问答、生存预测和癌症诊断。MMKD-CLIP在所有教师模型中表现最佳，并在图像域和任务设置上显示出显著的鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;多教师知识蒸馏是在现实世界数据可用性限制下构建高性能生物医学基础模型的可扩展且有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP models pretrained on natural images with billion-scale image-text pairshave demonstrated impressive capabilities in zero-shot classification,cross-modal retrieval, and open-ended visual answering. However, transferringthis success to biomedicine is hindered by the scarcity of large-scalebiomedical image-text corpora, the heterogeneity of image modalities, andfragmented data standards across institutions. These limitations hinder thedevelopment of a unified and generalizable biomedical foundation model trainedfrom scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedicalfoundation model developed via Multiple Medical CLIP Knowledge Distillation.Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledgefrom nine state-of-the-art domain-specific or generalist biomedical CLIPmodels, each pretrained on millions of biomedical image-text pairs. Ourtwo-stage training pipeline first performs CLIP-style pretraining on over 2.9million biomedical image-text pairs from 26 image modalities, followed byfeature-level distillation using over 19.2 million feature pairs extracted fromteacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,encompassing over 10.8 million biomedical images across nine image modalities.The evaluation spans six core task types: zero-shot classification, linearprobing, cross-modal retrieval, visual question answering, survival prediction,and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher modelswhile demonstrating remarkable robustness and generalization across imagedomains and task settings. These results underscore that multi-teacherknowledge distillation is a scalable and effective paradigm for buildinghigh-performing biomedical foundation models under the practical constraints ofreal-world data availability.</description>
      <author>example@mail.com (Shansong Wang, Zhecheng Jin, Mingzhe Hu, Mojtaba Safari, Feng Zhao, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang)</author>
      <guid isPermaLink="false">2506.22567v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Based Hybrid Neural Receiver for 6G-V2X Communications</title>
      <link>http://arxiv.org/abs/2506.21983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer编码块和图神经网络（GNN）的混合神经网络接收器（H-NR），用于优化无线接收器的多个功能。&lt;h4&gt;背景&lt;/h4&gt;目前尚未有综合接收模型能够替代物理层所有模块。&lt;h4&gt;目的&lt;/h4&gt;构建一个端到端的无线通信框架，并在车辆到网络（V2N）上行链路场景中应用。&lt;h4&gt;方法&lt;/h4&gt;H-NR模型替代了OFDM资源网格解映射、信道估计、信号均衡、解调和信道解码等功能。评估了不同场景下的性能，包括车辆速度、载波频率和CDL信道模型。此外，还评估了模型在处理图像、音频、GPS、雷达和激光雷达等多模态数据时的性能。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，所提出的模型在重建和纠错方面比现有的最佳神经网络接收器高出约0.5 dB。&lt;h4&gt;结论&lt;/h4&gt;H-NR模型在多种场景和模态数据上表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Neural receiver models are proposed to jointly optimize multiple functionalities of wireless receivers; however, a comprehensive receiver model that replaces the entire physical layer blocks has not yet been presented in the literature. In this work, we introduce a novel hybrid neural receiver (H-NR) built on Transformer encoder blocks and Graph Neural Network (GNN), as part of an end-to-end wireless communication framework. In our communication framework, we assume vehicle to network (V2N) uplink scenario where information is transmitted by vehicle and received at the base station (BS). Our proposed H-NR model replace OFDM resource grid demapping, channel estimation, signal equalization, demodulation, and channel decoding. To test the adaptability of our proposed model on unseen conditions, we evaluate its performance for various scenarios, including a vehicle speed of range [0-60] km/h, a carrier frequency of 5.9GHz, and a cluster delay line (CDL) channel model. Furthermore, we assess the performance of our proposed H-NR on multimodal data, such as images, audio, GPS, radar, and LiDAR, to examine its adaptability in real-world use cases. The simulation results clearly demonstrate that our proposed model outperforms the state-of-the-art neural receiver by approximately 0.5 dB in terms of reconstruction and error correction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural receiver models are proposed to jointly optimize multiplefunctionalities of wireless receivers; however, a comprehensive receiver modelthat replaces the entire physical layer blocks has not yet been presented inthe literature. In this work, we introduce a novel hybrid neural receiver(H-NR) built on Transformer encoder blocks and Graph Neural Network (GNN), aspart of an end-to-end wireless communication framework. In our communicationframework, we assume vehicle to network (V2N) uplink scenario where informationis transmitted by vehicle and received at the base station (BS). Our proposedH-NR model replace OFDM resource grid demapping, channel estimation, signalequalization, demodulation, and channel decoding. To test the adaptability ofour proposed model on unseen conditions, we evaluate its performance forvarious scenarios, including a vehicle speed of range [0-60] km/h, a carrierfrequency of 5.9GHz, and a cluster delay line (CDL) channel model. Furthermore,we assess the performance of our proposed H-NR on multimodal data, such asimages, audio, GPS, radar, and LiDAR, to examine its adaptability in real-worlduse cases. The simulation results clearly demonstrate that our proposed modeloutperforms the state-of-the-art neural receiver by approximately 0.5 dB interms of reconstruction and error correction.</description>
      <author>example@mail.com (Osama Saleem, Mohammed Alfaqawi, Pierre Merdrignac, Abdelaziz Bensrhair, Soheyb Ribouh)</author>
      <guid isPermaLink="false">2506.21983v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?</title>
      <link>http://arxiv.org/abs/2506.22501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 2025 IEEE International Geoscience and Remote Sensing  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,  Australia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpatialNet-ViT的新型模型，用于解决遥感数据分类任务，如土地利用分类、物体存在检测和城乡分类。该模型结合了视觉Transformer（ViT）和多任务学习（MTL）的优势，提高了分类准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感数据分类研究往往局限于特定的任务或数据集，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，以解决遥感数据分类任务的泛化问题。&lt;h4&gt;方法&lt;/h4&gt;采用视觉Transformer（ViT）和多任务学习（MTL）技术，并结合数据增强、迁移学习和多任务学习等技术来增强模型的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialNet-ViT模型结合了空间意识和上下文理解，提高了分类准确性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;SpatialNet-ViT模型在遥感数据分类任务中具有良好的性能，能够有效提高分类准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing datasets offer significant promise for tackling keyclassification tasks such as land-use categorization, object presencedetection, and rural/urban classification. However, many existing studies tendto focus on narrow tasks or datasets, which limits their ability to generalizeacross various remote sensing classification challenges. To overcome this, wepropose a novel model, SpatialNet-ViT, leveraging the power of VisionTransformers (ViTs) and Multi-Task Learning (MTL). This integrated approachcombines spatial awareness with contextual understanding, improving bothclassification accuracy and scalability. Additionally, techniques like dataaugmentation, transfer learning, and multi-task learning are employed toenhance model robustness and its ability to generalize across diverse datasets</description>
      <author>example@mail.com (Gautam Siddharth Kashyap, Manaswi Kulahara, Nipun Joshi, Usman Naseem)</author>
      <guid isPermaLink="false">2506.22501v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations</title>
      <link>http://arxiv.org/abs/2506.21682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Graph Neural Networks, Multi-Layer Perceptrons, Explicit Structural  Modeling, Probing Classifier&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过信息理论视角，提出一个综合探针框架来评估显式结构建模在增强语言模型表示中的作用，并研究MLP作为GNN高效且可扩展替代品的潜力。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNN）被证明可以编码结构信息以辅助模型，但最近的研究表明GNN未能充分利用结构信息。相比之下，多层感知器（MLP）在结构感知任务中表现出令人惊讶的能力。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架以系统地评估显式结构建模在增强语言模型表示中的作用，并探究MLP作为GNN的高效和可扩展替代品的潜力。&lt;h4&gt;方法&lt;/h4&gt;扩展传统的探针分类器，通过引入一个控制模块，允许选择性地使用完整的GNN模型或其解耦组件（特别是消息传递和特征转换操作）。使用EdgeProbing Suite作为评估LM中编码的语言知识的诊断工具。&lt;h4&gt;主要发现&lt;/h4&gt;作为特征转换模块，MLP在捕获不同架构中的语言知识方面表现良好，有效编码了句法和语义模式。同样，结合特征转换操作的GNN也显示出有益的效果。然而，仅依赖消息传递操作的模型往往表现不佳，通常会对探针任务性能产生负面影响。&lt;h4&gt;结论&lt;/h4&gt;MLP作为特征转换模块可以增强语言模型表示中的语言知识，而GNN结合特征转换操作也显示出有益效果，但单纯依赖消息传递的GNN表现较差。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explicit structural information has been proven to be encoded by Graph NeuralNetworks (GNNs), serving as auxiliary knowledge to enhance model capabilitiesand improve performance in downstream NLP tasks. However, recent studiesindicate that GNNs fail to fully utilize structural information, whereasMulti-Layer Perceptrons (MLPs), despite lacking the message-passing mechanismsinherent to GNNs, exhibit a surprising ability in structure-aware tasks.Motivated by these findings, this paper introduces a comprehensive probingframework from an information-theoretic perspective. The framework is designedto systematically assess the role of explicit structural modeling in enhancinglanguage model (LM) representations and to investigate the potential of MLPs asefficient and scalable alternatives to GNNs. We extend traditional probingclassifiers by incorporating a control module that allows for selective use ofeither the full GNN model or its decoupled components, specifically, themessage-passing and feature-transformation operations.This modular approachisolates and assesses the individual contributions of these operations,avoiding confounding effects from the complete GNN architecture. Using the EdgeProbing Suite, a diagnostic tool for evaluating the linguistic knowledgeencoded in LMs, we find that MLPs, when used as feature-transformation modules,consistently improve the linguistic knowledge captured in LM representationsacross different architectures. They effectively encode both syntactic andsemantic patterns. Similarly, GNNs that incorporate feature-transformationoperations show beneficial effects. In contrast, models that rely solely onmessage-passing operations tend to underperform, often leading to negativeimpacts on probing task performance.</description>
      <author>example@mail.com (Li Zhou, Hao Jiang, Junjie Li, Zefeng Zhao, Feng Jiang, Wenyu Chen, Haizhou Li)</author>
      <guid isPermaLink="false">2506.21682v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction</title>
      <link>http://arxiv.org/abs/2506.21401v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025 Code:  https://github.com/zhirui-gao/Curve-Gaussian&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从多视图边缘图中直接重建3D参数曲线的端到端框架。&lt;h4&gt;背景&lt;/h4&gt;现有的两阶段方法遵循“边缘点云重建和参数曲线拟合”的顺序流程，存在阶段之间固有的优化间隙，导致误差累积。&lt;h4&gt;目的&lt;/h4&gt;提出一种单阶段方法，直接从2D边缘图优化3D参数曲线，消除因阶段分离导致的优化间隙误差。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双向耦合机制，将参数曲线与边缘导向的高斯分量结合，形成曲线感知的高斯表示（CurveGaussian），实现3D曲线的可微分渲染。同时，引入动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ABC数据集和真实世界基准测试中，比两阶段方法表现出色，特别是在生成更干净、更稳健的重建方面。直接优化参数曲线显著减少了训练过程中的参数数量，实现了比现有方法更高的效率和更好的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在重建3D参数曲线方面优于现有方法，尤其适用于需要高效和高质量重建的应用场景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从多视图边缘图中直接重建3D参数曲线的端到端框架。与现有的两阶段方法不同，我们的单阶段方法直接从2D边缘图优化3D参数曲线，消除了由于阶段分离导致的优化间隙造成的误差累积。然而，参数曲线本身不适合基于渲染的多视图优化，需要一种互补的表示来保留它们的几何属性，同时实现可微分渲染。我们提出了一种新颖的双向耦合机制，将参数曲线与边缘导向的高斯分量相结合。这种紧密的对应关系形成了一种曲线感知的高斯表示，称为CurveGaussian，它使得3D曲线的可微分渲染成为可能，允许直接根据多视图证据进行优化。此外，我们在训练过程中引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。在ABC数据集和真实世界基准测试中的全面评估表明，我们提出的方法在生成更干净、更稳健的重建方面优于两阶段方法。此外，通过直接优化参数曲线，我们的方法在训练过程中显著减少了参数数量，与现有方法相比，实现了更高的效率和更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an end-to-end framework for reconstructing 3D parametriccurves directly from multi-view edge maps. Contrasting with existing two-stagemethods that follow a sequential ``edge point cloud reconstruction andparametric curve fitting'' pipeline, our one-stage approach optimizes 3Dparametric curves directly from 2D edge maps, eliminating error accumulationcaused by the inherent optimization gap between disconnected stages. However,parametric curves inherently lack suitability for rendering-based multi-viewoptimization, necessitating a complementary representation that preserves theirgeometric properties while enabling differentiable rendering. We propose anovel bi-directional coupling mechanism between parametric curves andedge-oriented Gaussian components. This tight correspondence formulates acurve-aware Gaussian representation, \textbf{CurveGaussian}, that enablesdifferentiable rendering of 3D curves, allowing direct optimization guided bymulti-view evidence. Furthermore, we introduce a dynamically adaptive topologyoptimization framework during training to refine curve structures throughlinearization, merging, splitting, and pruning operations. Comprehensiveevaluations on the ABC dataset and real-world benchmarks demonstrate ourone-stage method's superiority over two-stage alternatives, particularly inproducing cleaner and more robust reconstructions. Additionally, by directlyoptimizing parametric curves, our method significantly reduces the parametercount during training, achieving both higher efficiency and superiorperformance compared to existing approaches.</description>
      <author>example@mail.com (Zhirui Gao, Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu)</author>
      <guid isPermaLink="false">2506.21401v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts</title>
      <link>http://arxiv.org/abs/2506.21835v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ProSAM的方法，用于解决基于SAM的视觉参考图像分割中稳定性挑战的问题，并取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型基础模型的发展推动了开放集图像分割技术的成功，该技术关注于分割预定义类别之外的物体。在多种提示类型中，视觉参考分割因其灵活性和强大的零样本能力而突出。&lt;h4&gt;目的&lt;/h4&gt;旨在提高基于SAM的视觉参考图像分割方法的稳定性。&lt;h4&gt;方法&lt;/h4&gt;ProSAM通过学习一个变分提示编码器来预测多元提示分布，从而避免生成位于不稳定区域的提示，克服了提示编码器不稳健导致的不稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;ProSAM在Pascal-5i和COCO-20i数据集上表现优于现有方法，提供了一种更稳健的视觉参考分割解决方案。&lt;h4&gt;结论&lt;/h4&gt;ProSAM是一个简单而有效的解决现有基于SAM的视觉参考分割方法中稳定性挑战的方法，为图像分割领域提供了新的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancements in large foundation models have driven the success ofopen-set image segmentation, a task focused on segmenting objects beyondpredefined categories. Among various prompt types (such as points, boxes,texts, and visual references), visual reference segmentation stands out for itsunique flexibility and strong zero-shot capabilities. Recently, severalSAM-based methods have made notable progress in this task by automaticallygenerating prompts to guide SAM. However, these methods often generate promptsat object boundaries due to suboptimal prompt encoder, which results ininstability and reduced robustness. In this work, we introduce ProSAM, a simplebut effective method to address the stability challenges we identified inexisting SAM-based visual reference segmentation approaches. By learning avariational prompt encoder to predict multivariate prompt distributions, ProSAMavoids generating prompts that lie in unstable regions, overcoming theinstability caused by less robust prompts. Our approach consistently surpassesstate-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,providing a more robust solution for visual reference segmentation.</description>
      <author>example@mail.com (Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren)</author>
      <guid isPermaLink="false">2506.21835v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Supergeo Design: A Scalable Framework for Geographic Marketing Experiments</title>
      <link>http://arxiv.org/abs/2506.20499v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为自适应超级地理设计（ASD）的两阶段框架，用于大规模测量广告支出的增量回报率（iROAS），有效解决了地理实验设计中单位数量少、异质性大以及最优超级地理分区问题NP难的问题。&lt;h4&gt;背景&lt;/h4&gt;地理实验是衡量广告支出的增量回报率（iROAS）的标准方法，但其设计面临挑战，包括单位数量少、异质性大和最优超级地理分区问题NP难。&lt;h4&gt;目的&lt;/h4&gt;提出ASD框架，使其在成千上万的市场中实用，并解决地理实验设计中的挑战。&lt;h4&gt;方法&lt;/h4&gt;ASD框架包括两个阶段：首先，一个定制的图神经网络学习地理嵌入并提议一个简洁的“超级地理”候选集；然后，CP-SAT求解器选择一个分区，平衡基线结果和预处理协变量，这些协变量被认为会改变治疗效果。&lt;h4&gt;主要发现&lt;/h4&gt;在社区结构假设下，ASD的目标值在全局最优解的（1+epsilon）范围内。在模拟中，ASD在标准硬件上几分钟内完成，保留了每一分媒体费用，并将iROAS偏差显著降低。&lt;h4&gt;结论&lt;/h4&gt;ASD将地理提升测试转化为媒体计划的常规、可扩展组件，同时保持了统计严谨性。&lt;h4&gt;翻译&lt;/h4&gt;Geographic experiments are a gold-standard for measuring incremental return-on ad spend (iROAS) at scale, yet their design is challenging: the unit count is small, heterogeneity is large, and the optimal Supergeo partitioning problem is NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage framework that renders Supergeo designs practical for thousands of markets. A bespoke graph-neural network first learns geo-embeddings and proposes a concise candidate set of 'supergeos'; a CP-SAT solver then selects a partition that balances both baseline outcomes and pre-treatment covariates believed to modify the treatment effect. We prove that ASD's objective value is within (1+epsilon) of the global optimum under mild community-structure assumptions. In simulations with up to 1,000 Designated Market Areas, ASD completes in minutes on standard hardware, retains every media dollar, and cuts iROAS bias substantially relative to existing methods. ASD therefore turns geo-lift testing into a routine, scalable component of media planning while preserving statistical rigor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geographic experiments are a gold-standard for measuring incremental returnon ad spend (iROAS) at scale, yet their design is challenging: the unit countis small, heterogeneity is large, and the optimal Supergeo partitioning problemis NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage frameworkthat renders Supergeo designs practical for thousands of markets. A bespokegraph-neural network first learns geo-embeddings and proposes a concisecandidate set of 'supergeos'; a CP-SAT solver then selects a partition thatbalances both baseline outcomes and pre-treatment covariates believed to modifythe treatment effect. We prove that ASD's objective value is within (1+epsilon)of the global optimum under mild community-structure assumptions. Insimulations with up to 1,000 Designated Market Areas ASD completes in minuteson standard hardware, retains every media dollar, and cuts iROAS biassubstantively relative to existing methods. ASD therefore turns geo-lifttesting into a routine, scalable component of media planning while preservingstatistical rigour.</description>
      <author>example@mail.com (Charles Shaw)</author>
      <guid isPermaLink="false">2506.20499v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing vision-language models to novel domains: A comprehensive survey</title>
      <link>http://arxiv.org/abs/2506.18504v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉-语言预训练技术的发展，以及其在下游应用中的泛化能力研究。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言预训练结合了视觉和文本模态的优势，产生了强大的视觉-语言模型（VLMs），但它们在特定领域或专业泛化任务中的表现往往不佳。&lt;h4&gt;目的&lt;/h4&gt;调查视觉-语言模型（VLMs）的泛化设置、方法、基准和结果。&lt;h4&gt;方法&lt;/h4&gt;根据转移模块，将文献分为基于提示、基于参数和基于特征的方法，并回顾了典型的迁移学习（TL）设置，提供了对VLM时代迁移学习的新解释。&lt;h4&gt;主要发现&lt;/h4&gt;介绍了VLM泛化的流行基准，并比较了所审查方法的性能。&lt;h4&gt;结论&lt;/h4&gt;随着大规模可泛化预训练的进展，本文讨论了VLMs和最新的多模态大型语言模型（MLLM）如DeepSeek-VL之间的关系和差异。&lt;h4&gt;翻译&lt;/h4&gt;最近，视觉-语言预训练作为一种结合视觉和文本模态优势的变革性技术而出现，产生了强大的视觉-语言模型（VLMs）。利用网络规模的预训练数据，这些模型展现出强大的零样本能力。然而，当面对特定领域或专业泛化任务时，它们的性能往往会下降。为了解决这个问题，越来越多的研究关注于将VLMs中嵌入的丰富知识转移到各种下游应用中。这项调查旨在全面总结VLM文献中的泛化设置、方法、基准和结果。通过深入研究典型的VLM结构，根据转移模块将文献分为基于提示、基于参数和基于特征的方法。通过回顾典型的迁移学习（TL）设置，进一步总结了每个类别的差异和特点，并为VLM时代迁移学习提供了新的解释。介绍了VLM泛化的流行基准，并在所审查的方法之间进行了详尽的性能比较。随着大规模可泛化预训练的进展，这项调查还讨论了VLMs和最新的多模态大型语言模型（MLLM）如DeepSeek-VL之间的关系和差异。通过系统地回顾视觉-语言研究中的新兴文献，从新颖和实用的泛化视角出发，这项调查有助于描绘当前和未来的多模态研究图景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, vision-language pretraining has emerged as a transformativetechnique that integrates the strengths of both visual and textual modalities,resulting in powerful vision-language models (VLMs). Leveraging web-scalepretraining data, these models exhibit strong zero-shot capabilities. However,their performance often deteriorates when confronted with domain-specific orspecialized generalization tasks. To address this, a growing body of researchfocuses on transferring or generalizing the rich knowledge embedded in VLMs tovarious downstream applications. This survey aims to comprehensively summarizethe generalization settings, methodologies, benchmarking and results in VLMliteratures. Delving into the typical VLM structures, current literatures arecategorized into prompt-based, parameter-based and feature-based methodsaccording to the transferred modules. The differences and characteristics ineach category are furthered summarized and discussed by revisiting the typicaltransfer learning (TL) settings, providing novel interpretations for TL in theera of VLMs. Popular benchmarks for VLM generalization are further introducedwith thorough performance comparisons among the reviewed methods. Following theadvances in large-scale generalizable pretraining, this survey also discussesthe relations and differences between VLMs and up-to-date multimodal largelanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing thesurging literatures in vision-language research from a novel and practicalgeneralization prospective, this survey contributes to a clear landscape ofcurrent and future multimodal researches.</description>
      <author>example@mail.com (Xinyao Li, Jingjing Li, Fengling Li, Lei Zhu, Yang Yang, Heng Tao Shen)</author>
      <guid isPermaLink="false">2506.18504v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Compositional Generative Model of Unbounded 4D Cities</title>
      <link>http://arxiv.org/abs/2501.08983v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://www.infinitescript.com/project/city-dreamer-4d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CityDreamer4D的4D城市生成模型，用于生成无限扩展的4D城市。&lt;h4&gt;背景&lt;/h4&gt;近年来，3D场景生成受到广泛关注并取得了显著进展。由于城市环境中存在结构复杂、视觉多样化的物体（如建筑物和车辆），生成4D城市比生成3D场景更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了CityDreamer4D模型，专门用于生成无界4D城市。&lt;h4&gt;方法&lt;/h4&gt;1) 将动态对象（如车辆）从静态场景（如建筑物和道路）中分离出来；2) 所有4D场景中的对象都由不同类型的神经网络场（建筑物、车辆和背景物体）组成。具体包括Traffic Scenario Generator和Unbounded Layout Generator，用于生成动态交通场景和静态城市布局，使用高度紧凑的BEV表示。通过组合面向内容和面向实例的神经网络场来生成4D城市中的对象，以适应背景物体和实例的独特特性，神经网络场使用定制的生成哈希网格和周期性位置嵌入作为场景参数化。&lt;h4&gt;主要发现&lt;/h4&gt;1) 4D城市生成应将动态对象与静态场景分离；2) 4D场景中的所有对象应由不同类型的神经网络场组成。&lt;h4&gt;结论&lt;/h4&gt;CityDreamer4D模型支持一系列下游应用，如实例编辑、城市风格化和城市模拟，在生成逼真的4D城市方面取得了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，3D场景生成受到了越来越多的关注，并取得了显著的进展。由于城市环境中存在结构复杂、视觉多样化的物体（如建筑物和车辆），生成4D城市比生成3D场景更具挑战性。为了解决这些问题，我们提出了CityDreamer4D，一种专门针对生成无界4D城市的组合生成模型。我们的主要见解是：1) 4D城市生成应将动态对象（例如，车辆）与静态场景（例如，建筑物和道路）分离；2) 4D场景中的所有对象都应由不同类型的神经网络场（建筑物、车辆和背景物体）组成。具体来说，我们提出了Traffic Scenario Generator和Unbounded Layout Generator，用于使用高度紧凑的BEV表示生成动态交通场景和静态城市布局。4D城市中的对象通过组合面向内容和面向实例的神经网络场来生成，以适应背景物体和实例的独特特性，神经网络场使用定制的生成哈希网格和周期性位置嵌入作为场景参数化。此外，我们提供了一套全面的用于城市生成的数据集，包括OSM、Google Earth和CityTopia。OSM数据集提供了各种现实世界的城市布局，而Google Earth和CityTopia数据集提供了包含3D实例注释的大规模、高质量的城市图像。利用其组合设计，CityDreamer4D支持一系列下游应用，如实例编辑、城市风格化和城市模拟，在生成逼真的4D城市方面取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hzxie/CityDreamer4D&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene generation has garnered growing attention in recent years and hasmade significant progress. Generating 4D cities is more challenging than 3Dscenes due to the presence of structurally complex, visually diverse objectslike buildings and vehicles, and heightened human sensitivity to distortions inurban environments. To tackle these issues, we propose CityDreamer4D, acompositional generative model specifically tailored for generating unbounded4D cities. Our main insights are 1) 4D city generation should separate dynamicobjects (e.g., vehicles) from static scenes (e.g., buildings and roads), and 2)all objects in the 4D scene should be composed of different types of neuralfields for buildings, vehicles, and background stuff. Specifically, we proposeTraffic Scenario Generator and Unbounded Layout Generator to produce dynamictraffic scenarios and static city layouts using a highly compact BEVrepresentation. Objects in 4D cities are generated by combining stuff-orientedand instance-oriented neural fields for background stuff, buildings, andvehicles. To suit the distinct characteristics of background stuff andinstances, the neural fields employ customized generative hash grids andperiodic positional embeddings as scene parameterizations. Furthermore, weoffer a comprehensive suite of datasets for city generation, including OSM,GoogleEarth, and CityTopia. The OSM dataset provides a variety of real-worldcity layouts, while the Google Earth and CityTopia datasets deliverlarge-scale, high-quality city imagery complete with 3D instance annotations.Leveraging its compositional design, CityDreamer4D supports a range ofdownstream applications, such as instance editing, city stylization, and urbansimulation, while delivering state-of-the-art performance in generatingrealistic 4D cities.</description>
      <author>example@mail.com (Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu)</author>
      <guid isPermaLink="false">2501.08983v3</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals</title>
      <link>http://arxiv.org/abs/2506.20671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了IPFormer，一种基于视觉的3D全景场景补全方法，通过上下文自适应实例提议来提高场景理解的能力。&lt;h4&gt;背景&lt;/h4&gt;语义场景补全（SSC）和全景场景补全（PSC）是联合学习场景几何和语义的关键方法，但在基于相机图像的方法和动态适应场景方面仍有待探索。&lt;h4&gt;目的&lt;/h4&gt;提出IPFormer，以解决视觉3D全景场景补全中的动态适应性和上下文相关性问题。&lt;h4&gt;方法&lt;/h4&gt;IPFormer利用上下文自适应实例提议，在训练和测试时动态初始化查询，并通过注意力机制编码和解码，以推理语义实例体关系。&lt;h4&gt;主要发现&lt;/h4&gt;IPFormer在整体全景度量PQ和PQ-All上超越了现有方法，在单个度量上与现有方法持平，并在运行时减少了超过14倍。动态从图像上下文推导实例提议比随机初始化提高了3.62%的PQ-All和18.65%的平均 Thing-metrics。&lt;h4&gt;结论&lt;/h4&gt;IPFormer通过引入上下文自适应实例提议，为视觉3D全景场景补全提供了一种开创性的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointlylearning scene geometry and semantics, enabling downstream applications such asnavigation in mobile robotics. The recent generalization to Panoptic SceneCompletion (PSC) advances the SSC domain by integrating instance-levelinformation, thereby enhancing object-level sensitivity in scene understanding.While PSC was introduced using LiDAR modality, methods based on camera imagesremain largely unexplored. Moreover, recent Transformer-based SSC approachesutilize a fixed set of learned queries to reconstruct objects within the scenevolume. Although these queries are typically updated with image context duringtraining, they remain static at test time, limiting their ability todynamically adapt specifically to the observed scene. To overcome theselimitations, we propose IPFormer, the first approach that leveragescontext-adaptive instance proposals at train and test time to addressvision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptivelyinitializes these queries as panoptic instance proposals derived from imagecontext and further refines them through attention-based encoding and decodingto reason about semantic instance-voxel relationships. Experimental resultsshow that our approach surpasses state-of-the-art methods in overall panopticmetrics PQ$^\dagger$ and PQ-All, matches performance in individual metrics, andachieves a runtime reduction exceeding 14$\times$. Furthermore, our ablationstudies reveal that dynamically deriving instance proposals from image context,as opposed to random initialization, leads to a 3.62% increase in PQ-All and aremarkable average improvement of 18.65% in combined Thing-metrics. Theseresults highlight our introduction of context-adaptive instance proposals as apioneering effort in addressing vision-based 3D Panoptic Scene Completion.</description>
      <author>example@mail.com (Markus Gross, Aya Fahmy, Danit Niwattananan, Dominik Muhle, Rui Song, Daniel Cremers, Henri Meeß)</author>
      <guid isPermaLink="false">2506.20671v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
  <item>
      <title>Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis</title>
      <link>http://arxiv.org/abs/2506.22393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用多视角对比学习来整合时间模式、基于导数的动态和频域特征，以解决不同领域医疗时间序列中机器学习模型的适应性挑战。&lt;h4&gt;背景&lt;/h4&gt;由于复杂的时间依赖性和动态分布的变化，将机器学习模型适应不同领域的医疗时间序列仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够全面捕捉所需的时间动态，以实现鲁棒的领域自适应。&lt;h4&gt;方法&lt;/h4&gt;该方法使用独立的编码器和分层融合机制来学习特征不变表示，这些表示可以在不同领域之间迁移，同时保持时间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在包括脑电图（EEG）、心电图（ECG）和肌电图（EMG）在内的多种医疗数据集上的实验表明，该方法在迁移学习任务中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过提高机器学习模型的鲁棒性和泛化能力，该框架为在多样化的医疗环境中部署可靠的AI系统提供了一条实际途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将机器学习模型适应不同领域的医疗时间序列仍然是一个挑战，由于复杂的时间依赖性和动态分布的变化。当前方法通常关注孤立的特征表示，限制了它们完全捕捉所需的时间动态的能力，这对于鲁棒的领域自适应是必要的。在这项工作中，我们提出了一种利用多视角对比学习来整合时间模式、基于导数的动态和频域特征的新框架。我们的方法使用独立的编码器和分层融合机制来学习特征不变表示，这些表示可以在不同领域之间迁移，同时保持时间一致性。在包括脑电图（EEG）、心电图（ECG）和肌电图（EMG）在内的多种医疗数据集上的广泛实验表明，我们的方法在迁移学习任务中显著优于现有方法。通过提高机器学习模型的鲁棒性和泛化能力，我们的框架为在多样化的医疗环境中部署可靠的AI系统提供了一条实际途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting machine learning models to medical time series across differentdomains remains a challenge due to complex temporal dependencies and dynamicdistribution shifts. Current approaches often focus on isolated featurerepresentations, limiting their ability to fully capture the intricate temporaldynamics necessary for robust domain adaptation. In this work, we propose anovel framework leveraging multi-view contrastive learning to integratetemporal patterns, derivative-based dynamics, and frequency-domain features.Our method employs independent encoders and a hierarchical fusion mechanism tolearn feature-invariant representations that are transferable across domainswhile preserving temporal coherence. Extensive experiments on diverse medicaldatasets, including electroencephalogram (EEG), electrocardiogram (ECG), andelectromyography (EMG) demonstrate that our approach significantly outperformsstate-of-the-art methods in transfer learning tasks. By advancing therobustness and generalizability of machine learning models, our frameworkoffers a practical pathway for deploying reliable AI systems in diversehealthcare settings.</description>
      <author>example@mail.com (YongKyung Oh, Alex Bui)</author>
      <guid isPermaLink="false">2506.22393v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>MiCo: Multi-image Contrast for Reinforcement Visual Reasoning</title>
      <link>http://arxiv.org/abs/2506.22434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探索了如何使思维链（CoT）推理跨越多张图像连接视觉线索，提出了一种基于规则强化学习的视觉语言模型（VLMs）的解决方案。&lt;h4&gt;背景&lt;/h4&gt;传统的基于规则强化学习方法通常依赖于人工编纂的问题-答案对，这在处理图像中的细粒度视觉细节和复杂的逻辑关系时尤其具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过一种不依赖于人工标注的方法，提高多图像推理基准测试的性能。&lt;h4&gt;方法&lt;/h4&gt;研究者受到自监督视觉表示学习的启发，发现图像中包含内在的约束，可以充当监督信号。他们构建了由同一图像的两个增强视图和第三个相似但不同的图像组成的图像三元组。在训练过程中，模型被提示生成一个推理过程来比较这些图像（即确定图像是否相同）。然后，使用基于规则的强化学习优化模型。&lt;h4&gt;主要发现&lt;/h4&gt;尽管模型仅通过视觉比较任务进行训练，但所学习的推理能力有效地推广到了广泛的问题上。该方法在多图像推理基准测试中实现了显著的改进，并在一般视觉任务上表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在不依赖任何人工标注的问题-答案对的情况下，在多图像推理基准测试中取得了显著的成绩，并在一般视觉任务上表现出良好的性能，证明了其有效性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores enabling Chain-of-Thought (CoT) reasoning to link visualcues across multiple images. A straightforward solution is to adapt rule-basedreinforcement learning for Vision-Language Models (VLMs). However, such methodstypically rely on manually curated question-answer pairs, which can beparticularly challenging when dealing with fine grained visual details andcomplex logic across images. Inspired by self-supervised visual representationlearning, we observe that images contain inherent constraints that can serve assupervision. Based on this insight, we construct image triplets comprising twoaugmented views of the same image and a third, similar but distinct image.During training, the model is prompted to generate a reasoning process tocompare these images (i.e., determine same or different). Then we optimize themodel with rule-based reinforcement learning. Due to the high visual similarityand the presence of augmentations, the model must attend to subtle visualchanges and perform logical reasoning to succeed. Experiments show that,although trained solely on visual comparison tasks, the learned reasoningability generalizes effectively to a wide range of questions. Without relyingon any human-annotated question-answer pairs, our method achieves significantimprovements on multi-image reasoning benchmarks and shows strong performanceon general vision tasks.</description>
      <author>example@mail.com (Xi Chen, Mingkang Zhu, Shaoteng Liu, Xiaoyang Wu, Xiaogang Xu, Yu Liu, Xiang Bai, Hengshuang Zhao)</author>
      <guid isPermaLink="false">2506.22434v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration</title>
      <link>http://arxiv.org/abs/2506.22242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了4D-VLA，一种利用4D信息有效整合到输入中的新方法，以缓解机器人数据预训练中的坐标系统混沌和状态混沌问题，并通过记忆银行采样策略提高预训练效率。&lt;h4&gt;背景&lt;/h4&gt;利用多样化的机器人数据预训练是一个关键挑战。现有方法通常使用简单的观察作为输入来建模数据集的动作分布，但这些输入往往不完整，导致条件动作分布分散，称为坐标系统混沌和状态混沌，这严重阻碍了预训练效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高机器人数据预训练的效率，通过整合4D信息和引入记忆银行采样策略。&lt;h4&gt;方法&lt;/h4&gt;4D-VLA模型通过引入深度和时序信息到视觉特征中，使用序列RGB-D输入，以对齐机器人和场景的坐标系。此外，引入了记忆银行采样策略，旨在从历史图像中提取信息丰富的帧。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，我们的预训练方法和架构组件显著提高了模型性能。在模拟和真实世界的实验中，我们的模型在成功率方面显著高于OpenVLA。MV-Bench多视角模拟基准测试也显示了模型在空间理解和适应性方面的优势。&lt;h4&gt;结论&lt;/h4&gt;4D-VLA模型通过整合4D信息和改进的采样策略，有效地解决了机器人数据预训练中的问题，并在多视角模拟基准测试中优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging diverse robotic data for pretraining remains a critical challenge.Existing methods typically model the dataset's action distribution using simpleobservations as inputs. However, these inputs are often incomplete, resultingin a dispersed conditional action distribution-an issue we refer to ascoordinate system chaos and state chaos. This inconsistency significantlyhampers pretraining efficiency. To address this, we propose 4D-VLA, a novelapproach that effectively integrates 4D information into the input to mitigatethese sources of chaos. Our model introduces depth and temporal informationinto visual features with sequential RGB-D inputs, aligning the coordinatesystems of the robot and the scene. This alignment endows the model with strongspatiotemporal reasoning capabilities while minimizing training overhead.Additionally, we introduce memory bank sampling, a frame sampling strategydesigned to extract informative frames from historical images, furtherimproving effectiveness and efficiency. Experimental results demonstrate thatour pretraining method and architectural components substantially enhance modelperformance. In both simulated and real-world experiments, our model achieves asignificant increase in success rate over OpenVLA. To further assess spatialperception and generalization to novel views, we introduce MV-Bench, amulti-view simulation benchmark. Our model consistently outperforms existingmethods, demonstrating stronger spatial understanding and adaptability.</description>
      <author>example@mail.com (Jiahui Zhang, Yurui Chen, Yueming Xu, Ze Huang, Yanpeng Zhou, Yu-Jie Yuan, Xinyue Cai, Guowei Huang, Xingyue Quan, Hang Xu, Li Zhang)</author>
      <guid isPermaLink="false">2506.22242v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.22299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  icmr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CoATA，一种针对拓扑和属性协同增强的双通道图神经网络框架，以解决现实世界图中存在的噪声和不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;由于现实世界图存在大量噪声和不完整性，现有的图神经网络方法通常通过单一维度的增强来解决这个问题，但忽略了拓扑结构和节点属性之间的深层交互。&lt;h4&gt;目的&lt;/h4&gt;旨在通过协同增强拓扑和属性来提高图神经网络的性能。&lt;h4&gt;方法&lt;/h4&gt;CoATA首先通过传播结构信号来丰富和去噪节点属性，然后将增强的属性空间投影到节点-属性二分图中进行进一步精炼或重构。接着，引入对比学习，利用原型对齐和一致性约束，促进增强图和原始图之间的相互纠正。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上的广泛实验表明，提出的CoATA优于11种最先进的基线方法，证明了其在捕捉拓扑和属性之间协同关系方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;CoATA框架通过协同增强拓扑和属性，显著提升了图神经网络的性能，为处理现实世界图提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have garnered substantial attention due to theirremarkable capability in learning graph representations. However, real-worldgraphs often exhibit substantial noise and incompleteness, which severelydegrades the performance of GNNs. Existing methods typically address this issuethrough single-dimensional augmentation, focusing either on refining topologystructures or perturbing node attributes, thereby overlooking the deeperinterplays between the two. To bridge this gap, this paper presents CoATA, adual-channel GNN framework specifically designed for the Co-Augmentation ofTopology and Attribute. Specifically, CoATA first propagates structural signalsto enrich and denoise node attributes. Then, it projects the enhanced attributespace into a node-attribute bipartite graph for further refinement orreconstruction of the underlying structure. Subsequently, CoATA introducescontrastive learning, leveraging prototype alignment and consistencyconstraints, to facilitate mutual corrections between the augmented andoriginal graphs. Finally, extensive experiments on seven benchmark datasetsdemonstrate that the proposed CoATA outperforms eleven state-of-the-artbaseline methods, showcasing its effectiveness in capturing the synergisticrelationship between topology and attributes.</description>
      <author>example@mail.com (Tao Liu, Longlong Lin, Yunfeng Yu, Xi Ou, Youan Zhang, Zhiqiu Ye, Tao Jia)</author>
      <guid isPermaLink="false">2506.22299v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Linking climate and dengue in the Philippines using a two-stage Bayesian spatio-temporal model</title>
      <link>http://arxiv.org/abs/2506.22334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究旨在探讨菲律宾登革热与气候之间的关联，采用两阶段建模框架，利用贝叶斯时空模型和INLA方法进行推断。&lt;h4&gt;背景&lt;/h4&gt;登革热是一种在许多热带和亚热带地区造成重大社会经济和疾病负担的传染病。&lt;h4&gt;目的&lt;/h4&gt;为菲律宾登革热与气候的关联提供更多见解。&lt;h4&gt;方法&lt;/h4&gt;使用两阶段建模框架，第一阶段拟合气候模型，第二阶段拟合健康模型，使用第一阶段气候预测作为输入。采用贝叶斯时空模型和INLA方法进行推断，并执行后验抽样和贝叶斯模型平均来计算第二阶段模型参数的最终后验估计。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，温度与登革热呈正相关，但极端高温条件可能产生负面影响。降雨与登革热的关系在空间上存在差异，在全年降雨量均匀的地区，降雨与登革热呈负相关；而在干湿季节明显的地区，降雨与登革热呈正相关。在考虑气候变量和其他协变量的影响后，仍然存在未解释的空间和时间结构变异。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了菲律宾登革热与气候之间的复杂关系，并指出了进一步研究的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dengue is an infectious disease which poses significant socioeconomic anddisease burden in many tropical and subtropical regions of the world. This workaims to provide additional insight into the association between dengue andclimate in the Philippines. We employ a two-stage modelling framework: thefirst stage fits climate models, while the second stage fits a health modelthat uses the climate predictions from the first stage as inputs. We postulatea Bayesian spatio-temporal model and use the integrated nested Laplaceapproximation (INLA) approach for inference. To account for the uncertainty inthe climate models, we perform posterior sampling and then perform Bayesianmodel averaging to compute the final posterior estimates of second-stage modelparameters. The results indicate that temperature is positively associated withdengue, although extremely hot conditions tend to have a negative effect.Moreover, the relationship between rainfall and dengue varies in space. Inareas with uniform amounts of rainfall all year round, rainfall is negativelyassociated with dengue. In contrast, in regions with pronounced dry and wetseason, rainfall shows a positive association with dengue. Finally, thereremains unexplained structured variation in space and time after accounting forthe impact of climate variables and other covariates.</description>
      <author>example@mail.com (Stephen Jun Villejo, Sara Martino, Janine Illian)</author>
      <guid isPermaLink="false">2506.22334v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>HyperCLOVA X THINK Technical Report</title>
      <link>http://arxiv.org/abs/2506.22403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族中首个以推理为核心的大型语言模型，预训练数据包括约6000亿高质量的韩语和英语词汇，并辅以目标合成韩语数据。该模型采用计算内存平衡的Peri-LN Transformer架构，通过三阶段课程预训练，将上下文窗口扩展到128K个标记，并通过可验证奖励的强化学习进行监督微调，支持详细推理和简洁答案模式。&lt;h4&gt;背景&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族的一部分，旨在提供强大的推理能力。&lt;h4&gt;目的&lt;/h4&gt;HyperCLOVA X THINK旨在成为一个强大的基础模型，用于韩语AI创新和全球研究社区的有价值资源。&lt;h4&gt;方法&lt;/h4&gt;HyperCLOVA X THINK使用计算内存平衡的Peri-LN Transformer架构，通过三阶段课程预训练，并在监督微调中使用强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;HyperCLOVA X THINK在针对韩国的基准测试（如KMMLU、CSAT、KoBALT-700、HAERAE-1.0、KoBigBench）中表现出与同等规模模型相媲美的性能，同时保持了稳健的双语一致性和翻译质量。此外，视觉增强变体在KCSAT STEM基准测试上与GPT-4.1相当或超过，所有这些均比现有同类模型具有显著较低的训练计算量。&lt;h4&gt;结论&lt;/h4&gt;HyperCLOVA X THINK是一个强大的基础模型，适用于韩语AI创新，并对全球研究社区具有重要价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce HyperCLOVA X THINK, the first reasoning-focused large languagemodel in the HyperCLOVA X family, pre-trained on roughly $6$ trillionhigh-quality Korean, and English tokens, augmented with targeted syntheticKorean data. It was implemented as a compute-memory-balanced Peri-LNTransformer scaled with $\mu$P, pre-trained through a three-stage curriculumthat expands the context window to $128$K tokens, and post-trained viasupervised fine-tuning with Reinforcement Learning from Verifiable Rewardssupports both detailed rationale and concise-answer modes. It deliverscompetitive performance against similarly sized models on Korea-focusedbenchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, whilepreserving robust bilingual consistency and translation quality. In addition, avision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEMbenchmark, all of which are achieved with substantially lower training computethan existing models of similar sizes. We also present a pruning anddistillation technique that will soon be applied to HyperCLOVA X THINK for anopen-source and business-friendly foundation model. Altogether, thesecapabilities position HyperCLOVA X THINK as a robust foundation for Korean AIinnovation and a valuable resource for the global research community.</description>
      <author>example@mail.com (NAVER Cloud HyperCLOVA X Team)</author>
      <guid isPermaLink="false">2506.22403v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation</title>
      <link>http://arxiv.org/abs/2506.22375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉-语言模型（VLM）的无监督框架，用于在3D点云数据中有效检测异常值（OOD）。该框架通过构建基于类别原型和测试数据的图，利用数据流形结构来增强VLM在3D OOD检测中的效果。&lt;h4&gt;背景&lt;/h4&gt;在3D点云数据中检测异常值是一个挑战，尤其是在需要安全和鲁棒的感知的应用中。现有的OOD检测方法在2D图像数据上取得了一定的进展，但将其扩展到3D环境面临独特的障碍。&lt;h4&gt;目的&lt;/h4&gt;开发一种无监督的框架，利用VLM在3D点云数据中实现有效的异常值检测。&lt;h4&gt;方法&lt;/h4&gt;通过构建基于类别原型和测试数据的图，提出了一种名为图评分传播（GSP）的方法，该方法结合了提示聚类和自训练负提示来改进VLM的OOD评分。该方法还适用于少量样本的情况。&lt;h4&gt;主要发现&lt;/h4&gt;GSP在合成和真实世界数据集上的3D点云OOD检测性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的GSP方法在3D点云数据中实现了有效的异常值检测，为实际应用提供了新的选择。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于视觉-语言模型（VLM）的无监督框架，用于在3D点云数据中有效检测异常值（OOD）。该框架通过构建基于类别原型和测试数据的图，利用数据流形结构来增强VLM在3D OOD检测中的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection in 3D point cloud data remains achallenge, particularly in applications where safe and robust perception iscritical. While existing OOD detection methods have shown progress for 2D imagedata, extending these to 3D environments involves unique obstacles. This paperintroduces a training-free framework that leverages Vision-Language Models(VLMs) for effective OOD detection in 3D point clouds. By constructing a graphbased on class prototypes and testing data, we exploit the data manifoldstructure to enhancing the effectiveness of VLMs for 3D OOD detection. Wepropose a novel Graph Score Propagation (GSP) method that incorporates promptclustering and self-training negative prompting to improve OOD scoring withVLM. Our method is also adaptable to few-shot scenarios, providing options forpractical applications. We demonstrate that GSP consistently outperformsstate-of-the-art methods across synthetic and real-world datasets 3D pointcloud OOD detection.</description>
      <author>example@mail.com (Tiankai Chen, Yushu Li, Adam Goodge, Fei Teng, Xulei Yang, Tianrui Li, Xun Xu)</author>
      <guid isPermaLink="false">2506.22375v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Class of Bayesian Generalized Quadratic Nonlinear Dynamic Models with Application to Birth Rate Monitoring</title>
      <link>http://arxiv.org/abs/2506.22188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Frobenius范数匹配的协方差校准策略，用于非线性时空过程的建模，并通过Exact Posterior Regression方法进行高效实现。&lt;h4&gt;背景&lt;/h4&gt;现实世界的时空过程通常具有非线性动力学，可以通过随机偏微分方程描述。然而，在贝叶斯框架下实现这些模型在计算上具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了简化非线性时空过程的建模，本文旨在提出一种新的协方差校准策略，并使用高效的方法进行实现。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个将线性混合效应模型的协方差矩阵与广义二次非线性（GQN）模型的协方差矩阵在Frobenius范数上匹配的校准策略。同时，使用Exact Posterior Regression方法进行模型实现，并与MCMC方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究，本文的方法与MCMC方法相比，在实现线性框架下建模非线性时空过程方面具有优势，并且能够识别出与现有文献一致的协变量效应。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在避免MCMC计算困难的同时，提高了非线性时空模型的建模效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a covariance calibration strategy that specifies the covariance matrix of a linear mixed effects model to be close in Frobenius norm to that of a Generalized Quadratic Nonlinearity (GQN) model. We refer to this as Frobenius norm matching. This allows us to model nonlinear dynamics using an easier to implement linear framework. The calibrated linear model is efficiently implemented using Exact Posterior Regression (EPR), a recently proposed Bayesian model that enables sampling of fixed and random effects directly from the posterior distribution. We provide simulation studies that compare to implementations using MCMC. Finally, we use this approach to analyze Florida county-level birth rate data from 1990 to 2023. Our results indicate that our non-linear spatio-temporal model outperforms linear dynamic spatio-temporal models for this data, and identifies covariate effects consistent with existing literature, all while avoiding the computational difficulties of MCMC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many real-world spatio-temporal processes exhibit nonlinear dynamics that canoften be described through stochastic partial differential equations. Thesemodels are flexible and scientifically motivated, however, implementing them ina fully Bayesian framework can be computationally challenging. We are motivatedby birth rate data, which has important implications for public health and areknown to follow nonlinear dynamics. We propose a covariance calibrationstrategy that specifies the covariance matrix of a linear mixed effects modelto be close in Frobenius norm to that of a Generalized Quadratic Nonlinearity(GQN) model. We refer to this as Frobenius norm matching. This allows us tomodel nonlinear dynamics using an easier to implement linear framework. Thecalibrated linear model is efficiently implemented using Exact PosteriorRegression (EPR), a recently proposed Bayesian model that enables sampling offixed and random effects directly from the posterior distribution. We providesimulation studies that compare to implementations using MCMC. Finally, we usethis approach to analyze Florida county-level birth rate data from 1990-2023.Our results indicate that our non-linear spatio-temporal model outperformslinear dynamic spatio-temporal models for this data, and identifies covariateeffects consistent with existing literature, all while avoiding thecomputational difficulties of MCMC.</description>
      <author>example@mail.com (Madelyn Clinch, Jonathan R. Bradley)</author>
      <guid isPermaLink="false">2506.22188v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Universal Retrieval for Multimodal Trajectory Modeling</title>
      <link>http://arxiv.org/abs/2506.22056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures, accepted by Workshop on Computer-use Agents @  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为多模态轨迹检索的方法，用于提升AI代理在GUI环境中的能力，并构建了一个统一代理轨迹数据集（UATD）和一个基准测试集GAE-Bench，以及一个多模态检索框架GAE-Retriever，通过对比学习在多个数据集上的评估中表现出色。&lt;h4&gt;背景&lt;/h4&gt;轨迹数据在增强AI代理能力方面具有潜力，但其表示建模是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出多模态轨迹检索方法，以解决轨迹数据表示建模的挑战。&lt;h4&gt;方法&lt;/h4&gt;构建了UATD数据集，提出GAE-Bench基准，并设计了GAE-Retriever检索框架。&lt;h4&gt;主要发现&lt;/h4&gt;GAE-Retriever在检索召回率上优于强基线，表明其在多模态轨迹检索中的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态轨迹检索方法能够有效提升AI代理在GUI环境中的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory data, capturing human actions and environmental states acrossvarious modalities, holds significant potential for enhancing AI agentcapabilities, particularly in GUI environments. However, how to model therepresentation of trajectory-level data presents a significant challenge thathas not been systematically addressed amid explosive trajectory data growth. Inthis work, we introduce Multimodal Trajectory Retrieval, bridging the gapbetween universal retrieval and agent-centric trajectory modeling. We constructthe Unified Agent Trajectory Dataset (UATD) from annotated demonstrations andstates across diverse real-world scenarios. Based on this, we presentGAE-Bench, a benchmark containing a large number of trajectory-based retrievalpairs. In addition, we propose GAE-Retriever, a multimodal retrieval frameworkthat adopts vision-language models and incorporates optimized contrastivelearning through a token selection and the GradCache mechanism. Comprehensiveevaluations across multiple datasets show that GAE-Retriever consistentlyoutperforms strong baselines in retrieval recall, highlighting itseffectiveness in advancing multimodal trajectory retrieval.</description>
      <author>example@mail.com (Xuan Zhang, Ziyan Jiang, Rui Meng, Yifei Leng, Zhenbang Xiao, Zora Zhiruo Wang, Yanyi Shang, Dehan Kong)</author>
      <guid isPermaLink="false">2506.22056v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization</title>
      <link>http://arxiv.org/abs/2506.22134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Circuits and Systems for Video  Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于CP分解的低秩张量函数（CP-INR），通过神经网络进行隐式神经表示，在图像修复、去噪和点云上采样等多维数据恢复任务中展现出优越性和通用性。&lt;h4&gt;背景&lt;/h4&gt;高阶张量适合表示多维数据，如彩色图像和视频。低秩张量表示在机器学习和计算机视觉中变得至关重要，但现有的Tucker分解等方法在提供灵活性的同时牺牲了可解释性。CP分解虽然更自然和可解释，但获得稀疏解仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于CP分解的低秩张量函数，通过神经网络进行隐式神经表示，以实现连续数据的表示，并充分利用张量数据的非线性，同时保证理论上的风险界限。&lt;h4&gt;方法&lt;/h4&gt;引入了Schatten-p半范数的变分形式，并证明了其与多线性秩最小化的关系。提出了一种基于雅可比矩阵谱范数和Hutchinson迹估计器的正则化项，以实现平滑性。该方法无需SVD，避免了显式的链式法则推导，可以作为图像去噪任务中Total Variation正则化的替代，并自然适用于连续数据。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，证明了该方法在图像修复、去噪和点云上采样等多维数据恢复任务中优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的CP-INR方法在多维数据恢复任务中展现出优越性和通用性，为机器学习和计算机视觉中的张量数据处理提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Higher-order tensors are well-suited for representing multi-dimensional data,such as color images and videos. Low-rank tensor representation has becomeessential in machine learning and computer vision, but existing methods likeTucker decomposition offer flexibility at the expense of interpretability. Incontrast, while the CANDECOMP/PARAFAC (CP) decomposition provides a morenatural and interpretable tensor structure, obtaining sparse solutions remainschallenging. Leveraging the rich properties of CP decomposition, we propose aCP-based low-rank tensor function parameterized by neural networks for implicitneural representation (CP-INR). This approach enables continuous datarepresentation beyond structured grids, fully exploiting the non-linearity oftensor data with theoretical guarantees on excess risk bounds. To achieve asparse CP decomposition, we introduce a variational form of the Schatten-pquasi-norm and prove its relationship to multilinear rank minimization. Forsmoothness, we propose a regularization term based on the spectral norm of theJacobian and Hutchinson's trace estimator. Our proposed smoothnessregularization is SVD-free and avoids explicit chain rule derivations. It canserve as an alternative to Total Variation (TV) regularization in imagedenoising tasks and is naturally applicable to continuous data. Extensiveexperiments on multi-dimensional data recovery tasks, including imageinpainting, denoising, and point cloud upsampling, demonstrate the superiorityand versatility of our method compared to state-of-the-art approaches.</description>
      <author>example@mail.com (Zhengyun Cheng, Changhao Wang, Guanwen Zhang, Yi Xu, Wei Zhou, Xiangyang Ji)</author>
      <guid isPermaLink="false">2506.22134v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs</title>
      <link>http://arxiv.org/abs/2506.22139v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了Q-Frame，这是一种针对视频内容特定查询的自适应帧选择和多分辨率缩放的新方法，旨在解决视频理解任务中的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著成功，但在视频理解方面仍存在挑战，尤其是由于数据量大和时间复杂度高。&lt;h4&gt;目的&lt;/h4&gt;提出Q-Frame的目的是提高视频-LLMs处理视频数据的能力，有效捕获与查询相关的时空线索。&lt;h4&gt;方法&lt;/h4&gt;Q-Frame使用无训练的即插即用策略，通过文本-图像匹配网络（如CLIP）和Gumbel-Max技巧实现高效的帧选择。&lt;h4&gt;主要发现&lt;/h4&gt;Q-Frame通过在基准数据集（包括MLVU、LongVideoBench和Video-MME）上的广泛实验，证明了其在视频理解任务中的有效性，并优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Q-Frame能够处理更多帧而不会超过计算限制，从而保留关键的时间和空间信息，适用于各种视频理解任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著的成功。然而，由于数据量大和时间复杂度高，将这些模型应用于视频理解仍然存在挑战。现有的视频-LLMs使用均匀帧采样，往往难以有效地捕获视频中的与查询相关的关键时空线索。在本文中，我们提出了一种新的自适应帧选择和多分辨率缩放方法Q-Frame，该方法针对视频内容和特定查询进行了优化。Q-Frame采用了一种无训练的即插即用策略，通过文本-图像匹配网络（如CLIP）和Gumbel-Max技巧实现高效的帧选择。Q-Frame允许视频-LLMs处理更多帧而不超过计算限制，从而保留了关键的时间和空间信息。通过在基准数据集（包括MLVU、LongVideoBench和Video-MME）上的广泛实验，我们证明了Q-Frame的有效性，并显示了其相对于现有方法的优越性及其在各种视频理解任务中的应用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated significantsuccess in visual understanding tasks. However, challenges persist in adaptingthese models for video comprehension due to the large volume of data andtemporal complexity. Existing Video-LLMs using uniform frame sampling oftenstruggle to capture the query-related crucial spatiotemporal clues of videoseffectively. In this paper, we introduce Q-Frame, a novel approach for adaptiveframe selection and multi-resolution scaling tailored to the video's contentand the specific query. Q-Frame employs a training-free, plug-and-play strategygenerated by a text-image matching network like CLIP, utilizing the Gumbel-Maxtrick for efficient frame selection. Q-Frame allows Video-LLMs to process moreframes without exceeding computational limits, thereby preserving criticaltemporal and spatial information. We demonstrate Q-Frame's effectivenessthrough extensive experiments on benchmark datasets, including MLVU,LongVideoBench, and Video-MME, illustrating its superiority over existingmethods and its applicability across various video understanding tasks.</description>
      <author>example@mail.com (Shaojie Zhang, Jiahui Yang, Jianqin Yin, Zhenbo Luo, Jian Luan)</author>
      <guid isPermaLink="false">2506.22139v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method</title>
      <link>http://arxiv.org/abs/2506.22027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了使用地球观测影像检测和跟踪地面物体（如船只）的挑战，并提出了一种基于混合光学和合成孔径雷达（SAR）的船识别数据集（HOSS ReID）和一种基于Vision Transformer的跨模态船重识别方法（TransOSS）。&lt;h4&gt;背景&lt;/h4&gt;地球观测影像在遥感领域用于检测和跟踪地面物体是一个重大挑战。连续的船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，现有的船舶跟踪方法主要依赖地球静止卫星或视频卫星，这些方法存在分辨率低、受天气条件影响大、拍摄持续时间短和覆盖区域有限等问题。&lt;h4&gt;目的&lt;/h4&gt;提出HOSS ReID数据集和TransOSS方法，以评估使用低地球轨道星座的光学和SAR传感器进行船舶跟踪的有效性，并解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;HOSS ReID数据集包括在不同条件、不同卫星、不同时间和角度下拍摄的同一条船只的图像。TransOSS方法基于Vision Transformer架构，优化了嵌入结构，引入了额外的嵌入，并采用对比学习在大型光学-SAR图像对上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;HOSS ReID数据集和TransOSS方法能够实现更短的重新成像周期和全天候跟踪，同时能够提取模态不变特征。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为船舶跟踪提供了新的解决方案，并可在https://github.com/Alioth2000/Hoss-ReID上公开访问。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用地球观测影像检测和跟踪地面物体在遥感领域是一个重大挑战。连续的船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，目前大多数船舶跟踪方法依赖于地球静止卫星或视频卫星。前者提供低分辨率且易受天气条件影响，后者拍摄持续时间短且覆盖区域有限，这使得它们不太适合实际船舶跟踪的需求。为了解决这些局限性，我们提出了混合光学和合成孔径雷达（SAR）船重识别数据集（HOSS ReID数据集），用于评估使用低地球轨道星座的光学和SAR传感器进行船舶跟踪的有效性。这种方法确保了更短的重新成像周期并实现了全天候跟踪。HOSS ReID数据集包括在长时间内、在多种条件下、使用不同卫星和不同模式在不同时间和角度下捕获的同一条船只的图像。此外，我们提出了一种基于视觉Transformer架构的跨模态船舶重识别基准方法（TransOSS），该方法优化了嵌入结构以更好地适应跨模态任务，引入了额外的嵌入以引入更多参考信息，并采用对比学习在大型光学-SAR图像对上进行预训练，以确保模型能够提取模态不变特征。我们的数据集和基准方法可在https://github.com/Alioth2000/Hoss-ReID上公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting and tracking ground objects using earth observation imagery remainsa significant challenge in the field of remote sensing. Continuous maritimeship tracking is crucial for applications such as maritime search and rescue,law enforcement, and shipping analysis. However, most current ship trackingmethods rely on geostationary satellites or video satellites. The former offerlow resolution and are susceptible to weather conditions, while the latter haveshort filming durations and limited coverage areas, making them less suitablefor the real-world requirements of ship tracking. To address these limitations,we present the Hybrid Optical and Synthetic Aperture Radar (SAR) ShipRe-Identification Dataset (HOSS ReID dataset), designed to evaluate theeffectiveness of ship tracking using low-Earth orbit constellations of opticaland SAR sensors. This approach ensures shorter re-imaging cycles and enablesall-weather tracking. HOSS ReID dataset includes images of the same shipcaptured over extended periods under diverse conditions, using differentsatellites of different modalities at varying times and angles. Furthermore, wepropose a baseline method for cross-modal ship re-identification, TransOSS,which is built on the Vision Transformer architecture. It refines the patchembedding structure to better accommodate cross-modal tasks, incorporatesadditional embeddings to introduce more reference information, and employscontrastive learning to pre-train on large-scale optical-SAR image pairs,ensuring the model's ability to extract modality-invariant features. Ourdataset and baseline method are publicly available onhttps://github.com/Alioth2000/Hoss-ReID.</description>
      <author>example@mail.com (Han Wang, Shengyang Li, Jian Yang, Yuxuan Liu, Yixuan Lv, Zhuang Zhou)</author>
      <guid isPermaLink="false">2506.22027v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Pipe Reconstruction from Point Cloud Data</title>
      <link>http://arxiv.org/abs/2506.22118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从激光扫描数据中自动重建管道的方法，以支持工业资产如船舶和海上平台的精确数字孪生。&lt;h4&gt;背景&lt;/h4&gt;精确的工业资产数字孪生需要精确重建复杂的管道网络，而手动从激光扫描数据建模管道是一个耗时且劳动密集的过程。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化管道重建流程，以支持数字孪生的快速和精确建模，同时降低成本。&lt;h4&gt;方法&lt;/h4&gt;该方法使用Laplacian基于的收缩来估计骨骼曲线，随后进行曲线延长。使用滚动球技术和2D圆拟合重新中心骨骼轴，并通过3D平滑步骤进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够确定管道的属性，包括半径、长度和方向，并有助于创建复杂管道网络的详细3D模型。&lt;h4&gt;结论&lt;/h4&gt;通过自动化管道重建，该方法支持数字孪生的开发，实现快速且精确的建模，同时降低成本。&lt;h4&gt;翻译&lt;/h4&gt;Accurate digital twins of industrial assets, such as ships and offshore platforms, rely on the precise reconstruction of complex pipe networks. However, manual modelling of pipes from laser scan data is a time-consuming and labor-intensive process. This paper presents a pipeline for automated pipe reconstruction from incomplete laser scan data. The approach estimates a skeleton curve using Laplacian-based contraction, followed by curve elongation. The skeleton axis is then recentred using a rolling sphere technique combined with 2D circle fitting, and refined with a 3D smoothing step. This enables the determination of pipe properties, including radius, length and orientation, and facilitates the creation of detailed 3D models of complex pipe networks. By automating pipe reconstruction, this approach supports the development of digital twins, allowing for rapid and accurate modeling while reducing costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate digital twins of industrial assets, such as ships and offshoreplatforms, rely on the precise reconstruction of complex pipe networks.However, manual modelling of pipes from laser scan data is a time-consuming andlabor-intensive process. This paper presents a pipeline for automated pipereconstruction from incomplete laser scan data. The approach estimates askeleton curve using Laplacian-based contraction, followed by curve elongation.The skeleton axis is then recentred using a rolling sphere technique combinedwith 2D circle fitting, and refined with a 3D smoothing step. This enables thedetermination of pipe properties, including radius, length and orientation, andfacilitates the creation of detailed 3D models of complex pipe networks. Byautomating pipe reconstruction, this approach supports the development ofdigital twins, allowing for rapid and accurate modeling while reducing costs.</description>
      <author>example@mail.com (Antje Alex, Jannis Stoppe)</author>
      <guid isPermaLink="false">2506.22118v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Domain Adaptation for Object Detection</title>
      <link>http://arxiv.org/abs/2506.21860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Source-Free Domain Adaptation (SFDA)的方法，用于解决移动机器人在室内环境中进行物体检测和定位的问题。该方法通过预训练模型并利用时间聚类、多尺度阈值融合和Mean Teacher框架与对比学习，实现了对动态室内条件的灵活适应，并在零样本检测性能上取得了显著提升。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在室内环境中需要依赖物体检测器进行感知和定位。然而，标准的封闭集方法难以处理实际家庭和实验室中遇到的多样化和动态条件。&lt;h4&gt;目的&lt;/h4&gt;为了解决开放词汇物体检测（OVOD）在室内环境中的域迁移问题，提出了一种无需访问源数据即可适应预训练模型的方法。&lt;h4&gt;方法&lt;/h4&gt;本文采用以下方法：通过时间聚类细化伪标签、应用多尺度阈值融合、使用Mean Teacher框架结合对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在Embodied Domain Adaptation for Object Detection (EDAOD)基准测试中，该方法在零样本检测性能和动态室内条件下的灵活适应方面表现出了显著的优势。&lt;h4&gt;结论&lt;/h4&gt;提出的SFDA方法能够显著提高移动机器人在室内环境中的物体检测性能，并能够灵活适应环境变化。&lt;h4&gt;翻译&lt;/h4&gt;Mobile robots rely on object detectors for perception and object localization in indoor environments. However, standard closed-set methods struggle to handle the diverse objects and dynamic conditions encountered in real homes and labs. Open-vocabulary object detection (OVOD), driven by Vision Language Models (VLMs), extends beyond fixed labels but still struggles with domain shifts in indoor environments. We introduce a Source-Free Domain Adaptation (SFDA) approach that adapts a pre-trained model without accessing source data. We refine pseudo labels via temporal clustering, employ multi-scale threshold fusion, and apply a Mean Teacher framework with contrastive learning. Our Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates adaptation under sequential changes in lighting, layout, and object diversity. Our experiments show significant gains in zero-shot detection performance and flexible adaptation to dynamic indoor conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots rely on object detectors for perception and object localizationin indoor environments. However, standard closed-set methods struggle to handlethe diverse objects and dynamic conditions encountered in real homes and labs.Open-vocabulary object detection (OVOD), driven by Vision Language Models(VLMs), extends beyond fixed labels but still struggles with domain shifts inindoor environments. We introduce a Source-Free Domain Adaptation (SFDA)approach that adapts a pre-trained model without accessing source data. Werefine pseudo labels via temporal clustering, employ multi-scale thresholdfusion, and apply a Mean Teacher framework with contrastive learning. OurEmbodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluatesadaptation under sequential changes in lighting, layout, and object diversity.Our experiments show significant gains in zero-shot detection performance andflexible adaptation to dynamic indoor conditions.</description>
      <author>example@mail.com (Xiangyu Shi, Yanyuan Qiao, Lingqiao Liu, Feras Dayoub)</author>
      <guid isPermaLink="false">2506.21860v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs</title>
      <link>http://arxiv.org/abs/2506.21862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 4 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LLaVA-Scissor的无监督标记压缩策略，适用于视频多模态大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;之前的标记压缩方法大多基于注意力分数，但未能有效捕捉所有语义区域，往往导致标记冗余。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够全面覆盖语义的方法，以优化视频理解模型的性能。&lt;h4&gt;方法&lt;/h4&gt;采用语义连通组件（SCC）方法，将标记分配到不同的语义区域，并利用SCC在空间和时间域中进行两步时空标记压缩。&lt;h4&gt;主要发现&lt;/h4&gt;LLaVA-Scissor能够通过非重叠的语义标记集来表示整个视频，有效压缩标记。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LLaVA-Scissor在多种视频理解基准测试中优于其他标记压缩方法，特别是在低标记保留率的情况下。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present LLaVA-Scissor, a training-free token compression strategy designed for video multimodal large language models. Previous methods mostly attempt to compress tokens based on attention scores, but fail to effectively capture all semantic regions and often lead to token redundancy. Differently, we propose to leverage the Semantic Connected Components (SCC) approach that assigns tokens to distinct semantic regions within the token set, ensuring comprehensive semantic coverage. The outcome is a two-step spatio-temporal token compression strategy that utilizes SCC in both spatial and temporal domains. This strategy can effectively compress tokens by representing the entire video with a set of non-overlapping semantic tokens. We conduct extensive evaluations of the token compression capabilities of LLaVA-Scissor across diverse video understanding benchmarks, including video question answering, long video understanding, and comprehensive multi-choices benchmarks. Experimental results show that the proposed LLaVA-Scissor outperforms other token compression methods, achieving superior performance in various video understanding benchmarks, particularly at low token retention ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present LLaVA-Scissor, a training-free token compressionstrategy designed for video multimodal large language models. Previous methodsmostly attempt to compress tokens based on attention scores, but fail toeffectively capture all semantic regions and often lead to token redundancy.Differently, we propose to leverage the Semantic Connected Components (SCC)approach that assigns tokens to distinct semantic regions within the token set,ensuring comprehensive semantic coverage. The outcome is a two-stepspatio-temporal token compression strategy that utilizes SCC in both spatialand temporal domains. This strategy can effectively compress tokens byrepresenting the entire video with a set of non-overlapping semantic tokens. Weconduct extensive evaluations of the token compression capabilities ofLLaVA-Scissor across diverse video understanding benchmarks, including videoquestion answering, long video understanding, and comprehensive multi-choicesbenchmarks. Experimental results show that the proposed LLaVA-Scissoroutperforms other token compression methods, achieving superior performance invarious video understanding benchmarks, particularly at low token retentionratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.</description>
      <author>example@mail.com (Boyuan Sun, Jiaxing Zhao, Xihan Wei, Qibin Hou)</author>
      <guid isPermaLink="false">2506.21862v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Cardiovascular disease classification using radiomics and geometric features from cardiac CT</title>
      <link>http://arxiv.org/abs/2506.22226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review at STACOM 2025 with MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从CT图像自动检测和分类心血管疾病（CVD）的方法，以提高临床决策的准确性。&lt;h4&gt;背景&lt;/h4&gt;当前基于深度学习的方法大多直接处理原始CT数据或结合解剖结构分割进行端到端分类，这使得临床解释变得困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决临床解释的难题，本研究将CVD分类流程分解为三个部分：图像分割、图像配准和下游CVD分类。&lt;h4&gt;方法&lt;/h4&gt;本研究采用Atlas-ISTN框架和最新的分割基础模型生成解剖结构分割和标准健康图谱。这些被用于提取可临床解释的放射组学特征和基于图谱配准的变形场几何特征，以实现CVD分类。&lt;h4&gt;主要发现&lt;/h4&gt;在公开的ASOCA数据集上的实验表明，使用这些特征比直接在原始CT图像上训练的分类模型（准确率67.50%）具有更高的CVD分类准确率（87.50%）。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法提高了CVD分类的准确性，并通过公开代码促进了该领域的研究共享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic detection and classification of Cardiovascular disease (CVD) fromComputed Tomography (CT) images play an important part in facilitatingbetter-informed clinical decisions. However, most of the recent deep learningbased methods either directly work on raw CT data or utilize it in pair withanatomical cardiac structure segmentation by training an end-to-end classifier.As such, these approaches become much more difficult to interpret from aclinical perspective. To address this challenge, in this work, we break downthe CVD classification pipeline into three components: (i) image segmentation,(ii) image registration, and (iii) downstream CVD classification. Specifically,we utilize the Atlas-ISTN framework and recent segmentation foundational modelsto generate anatomical structure segmentation and a normative healthy atlas.These are further utilized to extract clinically interpretable radiomicfeatures as well as deformation field based geometric features (through atlasregistration) for CVD classification. Our experiments on the publicly availableASOCA dataset show that utilizing these features leads to better CVDclassification accuracy (87.50\%) when compared against classification modeltrained directly on raw CT images (67.50\%). Our code is publicly available:https://github.com/biomedia-mira/grc-net</description>
      <author>example@mail.com (Ajay Mittal, Raghav Mehta, Omar Todd, Philipp Seeböck, Georg Langs, Ben Glocker)</author>
      <guid isPermaLink="false">2506.22226v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2506.21957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了语义掩码自动编码器，旨在解决基于掩码点建模的方法在下游任务中捕获合理语义关系的问题。&lt;h4&gt;背景&lt;/h4&gt;点云理解旨在从无标签数据中获取鲁棒的通用特征表示，而基于掩码点建模的方法在下游任务中表现出显著性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决自监督模型在捕获合理语义关系时的失败问题。&lt;h4&gt;方法&lt;/h4&gt;提出了两个主要组件：基于原型的组件语义建模模块和组件语义增强掩码策略。具体包括设计组件语义引导机制、组件语义增强掩码策略和组件语义增强提示调整策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的模块在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;语义掩码自动编码器能够有效提高预训练模型在下游任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud understanding aims to acquire robust and general featurerepresentations from unlabeled data. Masked point modeling-based methods haverecently shown significant performance across various downstream tasks. Thesepre-training methods rely on random masking strategies to establish theperception of point clouds by restoring corrupted point cloud inputs, whichleads to the failure of capturing reasonable semantic relationships by theself-supervised models. To address this issue, we propose Semantic MaskedAutoencoder, which comprises two main components: a prototype-based componentsemantic modeling module and a component semantic-enhanced masking strategy.Specifically, in the component semantic modeling module, we design a componentsemantic guidance mechanism to direct a set of learnable prototypes incapturing the semantics of different components from objects. Leveraging theseprototypes, we develop a component semantic-enhanced masking strategy thataddresses the limitations of random masking in effectively covering completecomponent structures. Furthermore, we introduce a component semantic-enhancedprompt-tuning strategy, which further leverages these prototypes to improve theperformance of pre-trained models in downstream tasks. Extensive experimentsconducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPartdemonstrate the effectiveness of our proposed modules.</description>
      <author>example@mail.com (Yixin Zha, Chuxin Wang, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21957v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space</title>
      <link>http://arxiv.org/abs/2506.21857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SPADE的基础模型，该模型将组织病理学与空间转录组学数据相结合，以在统一框架内引导图像表示学习，从而创建一个由空间转录组学信息指导的潜在空间。&lt;h4&gt;背景&lt;/h4&gt;数字病理学快速发展，自监督深度学习技术进步，使得在多种疾病上的病理任务中开发了基础模型。尽管多模态方法整合了不同的数据源，但在全面整合全切片图像（WSI）与空间转录组学（ST）方面仍存在关键差距，这对于捕捉超出常规苏木精和伊红（H&amp;E）染色的关键分子异质性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够整合组织病理学与空间转录组学数据的基础模型，以改善病理学任务中的图像表示学习。&lt;h4&gt;方法&lt;/h4&gt;SPADE模型利用混合数据专家技术，通过两阶段特征空间聚类创建专家，并使用对比学习来学习共注册的全切片图像块和基因表达谱的表示。该模型在综合的HEST-1k数据集上预训练，并在14个下游任务上进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;SPADE在14个下游任务上显示出与基线模型相比的显著优越的少样本性能，这突出了将形态学和分子信息整合到一个潜在空间中的好处。&lt;h4&gt;结论&lt;/h4&gt;SPADE模型通过将形态学和分子信息整合到一个潜在空间中，显著提升了病理学任务中的图像表示学习，为病理诊断提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of digital pathology and advances in self-supervised deeplearning have enabled the development of foundational models for variouspathology tasks across diverse diseases. While multimodal approachesintegrating diverse data sources have emerged, a critical gap remains in thecomprehensive integration of whole-slide images (WSIs) with spatialtranscriptomics (ST), which is crucial for capturing critical molecularheterogeneity beyond standard hematoxylin &amp; eosin (H&amp;E) staining. We introduceSPADE, a foundation model that integrates histopathology with ST data to guideimage representation learning within a unified framework, in effect creating anST-informed latent space. SPADE leverages a mixture-of-data experts technique,where experts, created via two-stage feature-space clustering, use contrastivelearning to learn representations of co-registered WSI patches and geneexpression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE isevaluated on 14 downstream tasks, demonstrating significantly superior few-shotperformance compared to baseline models, highlighting the benefits ofintegrating morphological and molecular information into one latent space.</description>
      <author>example@mail.com (Ekaterina Redekop, Mara Pleasure, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey W. Arnold)</author>
      <guid isPermaLink="false">2506.21857v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>3D-Telepathy: Reconstructing 3D Objects from EEG Signals</title>
      <link>http://arxiv.org/abs/2506.21843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种从脑电图（EEG）数据重建3D视觉刺激的创新方法，旨在提高脑机接口（BCI）的应用效果，并帮助有交流障碍的人。&lt;h4&gt;背景&lt;/h4&gt;传统的EEG数据转换方法主要集中于将脑活动转换为2D图像，忽略了将EEG数据转换为3D对象的重要性。这种转换忽略了脑处理三维空间信息的能力，限制了其在BCI中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种从EEG数据到3D对象重建的创新方法，以解决现有方法中丢失空间信息的问题。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个集成了双重自注意力机制的EEG编码器架构，并采用混合训练策略，包括交叉注意力、对比学习和自监督学习技术。此外，通过使用稳定的扩散作为先验分布和利用变分分数蒸馏来训练神经辐射场，成功从EEG数据中生成了具有相似内容和结构的3D对象。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，EEG信号中存在大量噪声，且包含EEG和3D信息的数据集稀缺，这使得3D视觉数据的提取过程复杂化。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了从EEG数据到3D对象重建的难题，为BCI应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从脑电图（EEG）数据重建3D视觉刺激在脑机接口（BCI）的应用和帮助有交流障碍的人方面具有重大潜力。传统上，努力集中在将脑活动转换为2D图像，忽视了将EEG数据转换为3D对象的过程。这一局限性值得注意，因为人类大脑天生能够处理三维空间信息，无论观察的是2D图像还是现实世界。通过脑电图捕获的神经活动包含丰富的空间信息，在仅重建2D图像时不可避免地会丢失，从而限制了其在BCI中的实际应用。从EEG数据到3D对象重建的过渡面临着相当大的障碍。这些包括EEG信号中的广泛噪声以及包含EEG和3D信息的数据集稀缺，这使3D视觉数据的提取过程复杂化。面对这项具有挑战性的任务，我们提出了一种集成了双重自注意力机制的创新的EEG编码器架构。我们使用混合训练策略来训练EEG编码器，包括交叉注意力、对比学习和自监督学习技术。此外，通过采用稳定的扩散作为先验分布，并利用变分分数蒸馏来训练神经辐射场，我们成功地从EEG数据中生成了具有相似内容和结构的3D对象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holdssignificant potential for applications in Brain-Computer Interfaces (BCIs) andaiding individuals with communication disorders. Traditionally, efforts havefocused on converting brain activity into 2D images, neglecting the translationof EEG data into 3D objects. This limitation is noteworthy, as the human braininherently processes three-dimensional spatial information regardless ofwhether observing 2D images or the real world. The neural activities capturedby EEG contain rich spatial information that is inevitably lost whenreconstructing only 2D images, thus limiting its practical applications in BCI.The transition from EEG data to 3D object reconstruction faces considerableobstacles. These include the presence of extensive noise within EEG signals anda scarcity of datasets that include both EEG and 3D information, whichcomplicates the extraction process of 3D visual data. Addressing thischallenging task, we propose an innovative EEG encoder architecture thatintegrates a dual self-attention mechanism. We use a hybrid training strategyto train the EEG Encoder, which includes cross-attention, contrastive learning,and self-supervised learning techniques. Additionally, by employing stablediffusion as a prior distribution and utilizing Variational Score Distillationto train a neural radiation field, we successfully generate 3D objects withsimilar content and structure from EEG data.</description>
      <author>example@mail.com (Yuxiang Ge, Jionghao Cheng, Ruiquan Ge, Zhaojie Fang, Gangyong Jia, Xiang Wan, Nannan Li, Ahmed Elazab, Changmiao Wang)</author>
      <guid isPermaLink="false">2506.21843v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition</title>
      <link>http://arxiv.org/abs/2506.22179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FS-VAE的模型，用于零样本骨骼动作识别，通过频率分解探索骨骼语义表示学习，以增强零样本动作识别的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要关注视觉和语义表示的对齐，但往往忽略了语义空间中细粒度动作模式的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出FS-VAE模型，旨在解决现有方法在处理细粒度动作模式时的不足，提高零样本动作识别的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FS-VAE模型包括三个关键组件：1) 基于频率的增强模块，通过高低频调整丰富骨骼语义学习并提高鲁棒性；2) 基于语义的动作描述，通过多级对齐捕捉局部细节和全局对应关系；3) 校准的交叉对齐损失，以平衡骨骼和文本特征中的歧义和模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，频率增强的语义特征能够有效区分视觉和语义相似的动作簇，从而提高零样本动作识别的准确性。&lt;h4&gt;结论&lt;/h4&gt;FS-VAE模型通过频率分解和语义增强，显著提高了零样本骨骼动作识别的性能。&lt;h4&gt;翻译&lt;/h4&gt;Zero-shot skeleton-based action recognition aims to develop models capable of identifying actions beyond the categories encountered during training. Previous approaches have primarily focused on aligning visual and semantic representations but often overlooked the importance of fine-grained action patterns in the semantic space (e.g., the hand movements in drinking water and brushing teeth). To address these limitations, we propose a Frequency-Semantic Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic representation learning with frequency decomposition. FS-VAE consists of three key components: 1) a frequency-based enhancement module with high- and low-frequency adjustments to enrich the skeletal semantics learning and improve the robustness of zero-shot action recognition; 2) a semantic-based action description with multilevel alignment to capture both local details and global correspondence, effectively bridging the semantic gap and compensating for the inherent loss of information in skeleton sequences; 3) a calibrated cross-alignment loss that enables valid skeleton-text pairs to counterbalance ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text features, thereby ensuring robust alignment. Evaluations on the benchmarks demonstrate the effectiveness of our approach, validating that frequency-enhanced semantic features enable robust differentiation of visually and semantically similar action clusters, improving zero-shot action recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot skeleton-based action recognition aims to develop models capable ofidentifying actions beyond the categories encountered during training. Previousapproaches have primarily focused on aligning visual and semanticrepresentations but often overlooked the importance of fine-grained actionpatterns in the semantic space (e.g., the hand movements in drinking water andbrushing teeth). To address these limitations, we propose a Frequency-SemanticEnhanced Variational Autoencoder (FS-VAE) to explore the skeleton semanticrepresentation learning with frequency decomposition. FS-VAE consists of threekey components: 1) a frequency-based enhancement module with high- andlow-frequency adjustments to enrich the skeletal semantics learning and improvethe robustness of zero-shot action recognition; 2) a semantic-based actiondescription with multilevel alignment to capture both local details and globalcorrespondence, effectively bridging the semantic gap and compensating for theinherent loss of information in skeleton sequences; 3) a calibratedcross-alignment loss that enables valid skeleton-text pairs to counterbalanceambiguous ones, mitigating discrepancies and ambiguities in skeleton and textfeatures, thereby ensuring robust alignment. Evaluations on the benchmarksdemonstrate the effectiveness of our approach, validating thatfrequency-enhanced semantic features enable robust differentiation of visuallyand semantically similar action clusters, improving zero-shot actionrecognition.</description>
      <author>example@mail.com (Wenhan Wu, Zhishuai Guo, Chen Chen, Hongfei Xue, Aidong Lu)</author>
      <guid isPermaLink="false">2506.22179v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation</title>
      <link>http://arxiv.org/abs/2506.21892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法SODA，用于点云数据中的异常检测，以提高模型在实际任务中的安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;随着点云数据在各种应用中的普及，检测异常点云对象的能力变得至关重要。然而，这个问题在现有研究中尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;利用3D视觉语言模型（3D VLMs）在点云对象中进行异常检测。&lt;h4&gt;方法&lt;/h4&gt;针对3D VLMs在预训练数据集上的规模和对象多样性不足的问题，提出了一种基于邻域评分传播方案的方法SODA，以改善异常点云的检测。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，从合成到真实领域的迁移会导致点云与其相关文本嵌入在3D VLM潜在空间中的对齐度下降，从而阻碍下游性能。&lt;h4&gt;结论&lt;/h4&gt;SODA是一种基于推理的方法，无需额外模型训练，在多个数据集和问题设置上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;As point cloud data becomes more common in various applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As point cloud data increases in prevalence in a variety of applications, theability to detect out-of-distribution (OOD) point cloud objects becomescritical for ensuring model safety and reliability. However, this problemremains under-explored in existing research. Inspired by success in the imagedomain, we propose to exploit advances in 3D vision-language models (3D VLMs)for OOD detection in point cloud objects. However, a major challenge is thatpoint cloud datasets used to pre-train 3D VLMs are drastically smaller in sizeand object diversity than their image-based counterparts. Critically, theyoften contain exclusively computer-designed synthetic objects. This leads to asubstantial domain shift when the model is transferred to practical tasksinvolving real objects scanned from the physical environment. In this paper,our empirical experiments show that synthetic-to-real domain shiftsignificantly degrades the alignment of point cloud with their associated textembeddings in the 3D VLM latent space, hindering downstream performance. Toaddress this, we propose a novel methodology called SODA which improves thedetection of OOD point clouds through a neighborhood-based score propagationscheme. SODA is inference-based, requires no additional model training, andachieves state-of-the-art performance over existing approaches across datasetsand problem settings.</description>
      <author>example@mail.com (Adam Goodge, Xun Xu, Bryan Hooi, Wee Siong Ng, Jingyi Liao, Yongyi Su, Xulei Yang)</author>
      <guid isPermaLink="false">2506.21892v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety</title>
      <link>http://arxiv.org/abs/2506.22183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings from the Columbia Convening on Openness in Artificial  Intelligence and AI Safety&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文总结了哥伦比亚AI开放与安全会议的结果，探讨了开源基础模型的发展对AI系统安全的挑战和机遇。&lt;h4&gt;背景&lt;/h4&gt;开源和开放重量级基础模型的迅速发展，加剧了确保AI系统安全的义务，并重塑了相关机会。&lt;h4&gt;目的&lt;/h4&gt;报告哥伦比亚AI开放与安全会议及其六周的预备项目成果，该项目涉及来自学术界、工业界、民间社会和政府的研究人员、工程师和政策领导者。&lt;h4&gt;方法&lt;/h4&gt;采用参与式、以解决方案为导向的过程，工作小组产生了（i）一个安全和开源AI交叉的研究议程；（ii）现有和所需的技术干预措施以及开源工具的映射，以安全、负责任地部署开放基础模型；（iii）内容安全过滤生态系统映射以及未来研究和发展的路线图。&lt;h4&gt;主要发现&lt;/h4&gt;开放（透明权重、互操作性工具和公共治理）可以通过使独立审查、去中心化缓解和文化多元监督成为可能来提高安全性。然而，仍存在重大差距：缺乏多模态和多语言基准、在代理系统中对提示注入和组合攻击的防御有限，以及社区参与机制不足。&lt;h4&gt;结论&lt;/h4&gt;论文以五个优先研究方向的路线图结束，强调参与式输入、未来证明的内容过滤器、生态系统范围的安全基础设施、严格的代理保护以及扩展的伤害分类法。这些建议为2025年2月的法国AI行动峰会提供了信息，并为一个开放、多元和负责任的AI安全学科奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文报道了哥伦比亚AI开放与安全会议（2024年11月11日，旧金山）及其六周的预备项目成果，该项目涉及来自学术界、工业界、民间社会和政府的研究人员、工程师和政策领导者。通过参与式、以解决方案为导向的过程，工作组产生了（i）一个交叉于安全和开源AI的研究议程；（ii）现有和所需的技术干预措施以及开源工具的映射，以安全、负责任地部署开放基础模型；（iii）内容安全过滤生态系统映射以及未来研究和发展的路线图。我们发现，开放（理解为透明权重、互操作性工具和公共治理）可以通过使独立审查、去中心化缓解和文化多元监督成为可能来提高安全性。然而，仍存在重大差距：缺乏多模态和多语言基准、在代理系统中对提示注入和组合攻击的防御有限，以及社区参与机制不足。论文以五个优先研究方向的路线图结束，强调参与式输入、未来证明的内容过滤器、生态系统范围的安全基础设施、严格的代理保护以及扩展的伤害分类法。这些建议为2025年2月的法国AI行动峰会提供了信息，并为一个开放、多元和负责任的AI安全学科奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid rise of open-weight and open-source foundation models isintensifying the obligation and reshaping the opportunity to make AI systemssafe. This paper reports outcomes from the Columbia Convening on AI Opennessand Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programmeinvolving more than forty-five researchers, engineers, and policy leaders fromacademia, industry, civil society, and government. Using a participatory,solutions-oriented process, the working groups produced (i) a research agendaat the intersection of safety and open source AI; (ii) a mapping of existingand needed technical interventions and open source tools to safely andresponsibly deploy open foundation models across the AI development workflow;and (iii) a mapping of the content safety filter ecosystem with a proposedroadmap for future research and development. We find that openness --understood as transparent weights, interoperable tooling, and public governance-- can enhance safety by enabling independent scrutiny, decentralizedmitigation, and culturally plural oversight. However, significant gaps persist:scarce multimodal and multilingual benchmarks, limited defenses againstprompt-injection and compositional attacks in agentic systems, and insufficientparticipatory mechanisms for communities most affected by AI harms. The paperconcludes with a roadmap of five priority research directions, emphasizingparticipatory inputs, future-proof content filters, ecosystem-wide safetyinfrastructure, rigorous agentic safeguards, and expanded harm taxonomies.These recommendations informed the February 2025 French AI Action Summit andlay groundwork for an open, plural, and accountable AI safety discipline.</description>
      <author>example@mail.com (Camille François, Ludovic Péran, Ayah Bdeir, Nouha Dziri, Will Hawkins, Yacine Jernite, Sayash Kapoor, Juliet Shen, Heidy Khlaaf, Kevin Klyman, Nik Marda, Marie Pellat, Deb Raji, Divya Siddarth, Aviya Skowron, Joseph Spisak, Madhulika Srikumar, Victor Storchan, Audrey Tang, Jen Weedon)</author>
      <guid isPermaLink="false">2506.22183v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments</title>
      <link>http://arxiv.org/abs/2506.22096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的模型，用于简化土壤和港口重金属污染的检测过程，以提高重金属污染评估的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;重金属污染对区域环境监测至关重要，但传统的污染负荷指数（PLI）评估方法耗时且数据分析复杂。&lt;h4&gt;目的&lt;/h4&gt;开发一种简化重金属评估过程的模型，并解决水-沉积物领域中数据稀缺的问题。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习技术，提出了一种预测PLI的准确量化评估方法，该模型可以跨不同特征集的领域转移学习到的特征。&lt;h4&gt;主要发现&lt;/h4&gt;模型在六个主要港口的数据评估中表现出色，平均绝对误差（MAE）和平均绝对百分比误差（MAPE）分别降低了约0.5和0.03，性能比其他基准模型高两个数量级。&lt;h4&gt;结论&lt;/h4&gt;该模型提供了一种创新、易用且经济的预测水质的方法，有助于海洋生物保护、水产养殖和工业污染监测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测土壤和港口的重金属污染对于区域环境监测至关重要。污染负荷指数（PLI）是国际标准，常用于评估重金属含量。然而，传统的PLI评估方法涉及繁琐的程序和沉积物样本的数据分析。为了解决这一挑战，我们提出了一种基于深度学习的模型，简化了重金属评估过程。我们的模型解决了水-沉积物领域中数据稀缺的问题，该领域传统上受到数据收集困难和各国标准不一的挑战。通过利用迁移学习，我们开发了一种准确的量化评估方法，用于预测PLI。我们的方法允许在不同特征集的领域之间转移学习到的特征。我们使用澳大利亚新南威尔士州六个主要港口的数据评估了我们的模型：Yamba港、Newcastle港、Jackson港、Botany港、Kembla港和Eden港。结果表明，与其它模型相比，平均绝对误差（MAE）和平均绝对百分比误差（MAPE）分别降低了约0.5和0.03。我们的模型性能比其他基准模型高两个数量级。我们提出的模型提供了一种创新、易用且经济的预测水质的方法，有助于海洋生物保护、水产养殖和工业污染监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting heavy metal pollution in soils and seaports is vital for regionalenvironmental monitoring. The Pollution Load Index (PLI), an internationalstandard, is commonly used to assess heavy metal containment. However, theconventional PLI assessment involves laborious procedures and data analysis ofsediment samples. To address this challenge, we propose a deep-learning-basedmodel that simplifies the heavy metal assessment process. Our model tackles theissue of data scarcity in the water-sediment domain, which is traditionallyplagued by challenges in data collection and varying standards across nations.By leveraging transfer learning, we develop an accurate quantitative assessmentmethod for predicting PLI. Our approach allows the transfer of learned featuresacross domains with different sets of features. We evaluate our model usingdata from six major ports in New South Wales, Australia: Port Yamba, PortNewcastle, Port Jackson, Port Botany, Port Kembla, and Port Eden. The resultsdemonstrate significantly lower Mean Absolute Error (MAE) and Mean AbsolutePercentage Error (MAPE) of approximately 0.5 and 0.03, respectively, comparedto other models. Our model performance is up to 2 orders of magnitude thanother baseline models. Our proposed model offers an innovative, accessible, andcost-effective approach to predicting water quality, benefiting marine lifeconservation, aquaculture, and industrial pollution monitoring.</description>
      <author>example@mail.com (Tin Lai, Farnaz Farid, Yueyang Kuan, Xintian Zhang)</author>
      <guid isPermaLink="false">2506.22096v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  for associated source code, see  https://github.com/RFLeijenaar/AsymDSD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AsymDSD框架，用于从无结构的3D点云中学习语义上有意义的表示，解决了自监督3D学习中重建目标限制语义捕获能力的问题。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉中，从无结构的3D点云中学习有意义的表示是一个关键挑战，特别是在没有大规模标记数据集的情况下。现有的自监督3D学习方法，如掩码点建模（MPM），存在重建目标限制语义捕获能力的问题。&lt;h4&gt;目的&lt;/h4&gt;提出AsymDSD框架，旨在通过预测潜空间中的信息，而不是输入空间，来统一掩码建模和不变性学习，以更好地捕捉高级语义。&lt;h4&gt;方法&lt;/h4&gt;AsymDSD基于联合嵌入架构，并引入了几个关键设计选择：高效的非对称设置、禁用掩码查询之间的注意力以防止形状泄漏、多掩码采样以及点云的多裁剪适应。&lt;h4&gt;主要发现&lt;/h4&gt;AsymDSD在ScanObjectNN数据集上实现了最先进的90.53%的结果，在预训练于930k个形状后进一步提升到93.72%，超过了之前的方法。&lt;h4&gt;结论&lt;/h4&gt;AsymDSD框架在自监督3D学习中表现出色，为从无结构的3D点云中学习高级语义提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning semantically meaningful representations from unstructured 3D pointclouds remains a central challenge in computer vision, especially in theabsence of large-scale labeled datasets. While masked point modeling (MPM) iswidely used in self-supervised 3D learning, its reconstruction-based objectivecan limit its ability to capture high-level semantics. We propose AsymDSD, anAsymmetric Dual Self-Distillation framework that unifies masked modeling andinvariance learning through prediction in the latent space rather than theinput space. AsymDSD builds on a joint embedding architecture and introducesseveral key design choices: an efficient asymmetric setup, disabling attentionbetween masked queries to prevent shape leakage, multi-mask sampling, and apoint cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art resultson ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930kshapes, surpassing prior methods.</description>
      <author>example@mail.com (Remco F. Leijenaar, Hamidreza Kasaei)</author>
      <guid isPermaLink="false">2506.21724v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models</title>
      <link>http://arxiv.org/abs/2506.22149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RetFiner的自监督学习视觉语言细化方案，旨在提高现有OCT基础模型的表现，使其能够更有效地适应特定人群和应用。&lt;h4&gt;背景&lt;/h4&gt;光学相干断层扫描（OCT）和深度学习（DL）的进步使得临床医生和研究人员能够简化视网膜疾病分期。自监督学习（SSL）是一种流行的深度学习方法，它通过大量未标记数据学习，避免了昂贵的标注过程。&lt;h4&gt;目的&lt;/h4&gt;针对现有OCT基础模型在复杂任务中的表现不足，以及需要监督微调以适应特定应用和人群的问题，提出RetFiner方案。&lt;h4&gt;方法&lt;/h4&gt;RetFiner利用文本数据中的丰富监督信号，采用多样化的训练目标来改进现有基础模型的表现，并使其能够直接适应特定人群。&lt;h4&gt;主要发现&lt;/h4&gt;在七个高度多样化的OCT分类任务上，RetFiner在RETFound、UrFound和VisionFM三个视网膜基础模型上实现了显著的性能提升，平均提高了5.8、3.9和2.1个百分点。&lt;h4&gt;结论&lt;/h4&gt;RetFiner能够有效提高现有OCT基础模型的表现，为视网膜疾病分期提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着光学相干断层扫描（OCT）等成像技术的兴起和深度学习（DL）的进步，临床医生和研究人员能够简化视网膜疾病分期。自监督学习（SSL）是一种流行的深度学习方法，它通过大量未标记数据学习，避免了昂贵的标注过程。SSL允许开发基础模型（FMs），这些大型模型可以用于各种下游任务。然而，现有的仅基于图像数据训练的OCT FMs缺乏对图像的全面和稳健的语义理解，这从它们的下游性能（尤其是对于复杂任务）中可以看出，因此需要监督微调（这可能不可行）以更好地适应特定的应用和人群。为了解决这个问题，我们提出了RetFiner，一种自监督学习视觉语言细化方案，它改进了现有FMs的表现，并使其能够高效直接地适应特定人群以改善下游性能。我们的方法使用了一组多样化的训练目标，这些目标利用了文本数据中丰富的监督信号。我们在RETFound、UrFound和VisionFM视网膜FMs上测试了RetFiner，在七个高度多样化的OCT分类任务上显示出显著的线性探测性能提升，分别比基线提高了5.8、3.9和2.1个百分点。我们的代码和模型权重在https://github.com/ronnief1/RetFiner上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of imaging techniques such as optical coherence tomography (OCT) andadvances in deep learning (DL) have enabled clinicians and researchers tostreamline retinal disease staging. A popular DL approach is self-supervisedlearning (SSL), where models learn from vast amounts of unlabeled data,avoiding costly annotation. SSL has allowed the development of foundationmodels (FMs), large models that can be used for a variety of downstream tasks.However, existing FMs for OCT, trained solely on image data, lack acomprehensive and robust semantic understanding of images, as evidenced bytheir downstream performance (especially for complex tasks), and thus requiresupervised fine-tuning (which may be unfeasible) to better adapt to specificapplications and populations. To address this, we propose RetFiner, an SSLvision-language refinement scheme that improves the representations of existingFMs and enables their efficient and direct adaptation to specific populationsfor improved downstream performance. Our method uses a diverse set of trainingobjectives which take advantage of the rich supervisory signal found in textualdata. We tested RetFiner on the retinal FMs RETFound, UrFound, and VisionFM,showing significant improvements in linear probing performance on seven highlydiverse OCT classification tasks, with an average increase of 5.8, 3.9, and 2.1percentage points over their baselines, respectively. Our code and modelweights are publicly available at https://github.com/ronnief1/RetFiner.</description>
      <author>example@mail.com (Ronald Fecso, José Morano, Ursula Schmidt-Erfurth, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.22149v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Explainable anomaly detection for sound spectrograms using pooling statistics with quantile differences</title>
      <link>http://arxiv.org/abs/2506.21921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对光谱图进行异常检测的方法，该方法基于统计评估，具有内在的可解释性，特别适合工业环境中的应用。&lt;h4&gt;背景&lt;/h4&gt;异常检测是识别数据集中罕见样本的任务，这些样本与几乎所有其他样本不同。由于异常样本的模式通常不是事先已知的，因此这项任务极具挑战性。在工业4.0的各个应用中，对异常声音检测（ASD）的重要性日益凸显。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种适用于光谱图的异常检测方法，以解决工业领域中智能算法应用中的争议。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于统计评估，并具有理论上的合理性。该方法具有内在的可解释性，使其特别适合于工业环境。&lt;h4&gt;主要发现&lt;/h4&gt;该方法对光谱图进行异常检测，并具有内在的可解释性，适合于工业环境中的应用。&lt;h4&gt;结论&lt;/h4&gt;该算法对于需要避免或不适于使用黑盒算法的应用场景具有相关性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：异常检测是识别数据集中罕见（即异常或异常）样本的任务，这些样本几乎与数据集中的所有其他样本都不同。由于异常样本的模式通常不是事先已知的，因此这项任务极具挑战性。因此，异常检测位于半监督学习和无监督学习之间。在声音数据中检测异常，通常称为'ASD'（异常声音检测），是一个子领域，涉及识别声学记录中的新且未知的效果。这对于工业4.0中的各种应用具有重要意义。在这里，振动或声学数据通常是从用于预测维护的标准传感器信号中获得的。例如，包括机器状态监控或质量保证，以跟踪组件或产品的状态。然而，智能算法的使用仍然是一个有争议的话题。管理层一般旨在降低成本和自动化，而质量和维护专家强调需要人类专业知识和可理解解决方案。在本工作中，我们提出了一种专门为光谱图设计的异常检测方法。该方法基于统计评估，并在理论上具有动机。此外，它具有内在的可解释性，使其特别适合于工业环境中的应用。因此，该算法对于需要避免或不适于使用黑盒算法的应用场景具有相关性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is the task of identifying rarely occurring (i.e. anormalor anomalous) samples that differ from almost all other samples in a dataset.As the patterns of anormal samples are usually not known a priori, this task ishighly challenging. Consequently, anomaly detection lies between semi- andunsupervised learning. The detection of anomalies in sound data, often called'ASD' (Anomalous Sound Detection), is a sub-field that deals with theidentification of new and yet unknown effects in acoustic recordings. It is ofgreat importance for various applications in Industry 4.0. Here, vibrational oracoustic data are typically obtained from standard sensor signals used forpredictive maintenance. Examples cover machine condition monitoring or qualityassurance to track the state of components or products. However, the use ofintelligent algorithms remains a controversial topic. Management generally aimsfor cost-reduction and automation, while quality and maintenance expertsemphasize the need for human expertise and comprehensible solutions. In thiswork, we present an anomaly detection approach specifically designed forspectrograms. The approach is based on statistical evaluations and istheoretically motivated. In addition, it features intrinsic explainability,making it particularly suitable for applications in industrial settings. Thus,this algorithm is of relevance for applications in which black-box algorithmsare unwanted or unsuitable.</description>
      <author>example@mail.com (Nicolas Thewes, Philipp Steinhauer, Patrick Trampert, Markus Pauly, Georg Schneider)</author>
      <guid isPermaLink="false">2506.21921v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.22143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for IEEE MLSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了各种语音SSL模型在方言阿拉伯语（DA）和阿拉伯-英语代码转换（CS）语音上的性能。&lt;h4&gt;背景&lt;/h4&gt;针对数据稀缺问题，引入了一种改进的音频拼接方法来生成人工CS语音数据。&lt;h4&gt;目的&lt;/h4&gt;通过微调SSL模型和使用SAGE数据，旨在提高Word Error Rate（WER）。&lt;h4&gt;方法&lt;/h4&gt;使用经验回放（ER）启发的方法来增强DA和CS语音的泛化能力，同时减轻灾难性遗忘。此外，集成域外3-gram语言模型以减少整体平均WER。&lt;h4&gt;主要发现&lt;/h4&gt;与阿拉伯和英语CS基准相比，使用SAGE数据微调SSL模型使WER绝对提高了7.8%。采用ER方法后，整体平均WER从31.7%降至26.6%。对于代码转换基准的少量样本微调进一步将WER提高了4.9%。在阿拉伯-英语CS基准上，WER达到31.1%，超过大规模多语言模型USM和Whisper-large-v2，分别高出5.5%和8.4%。&lt;h4&gt;结论&lt;/h4&gt;提出的改进方法和模型在DA和CS语音上的性能显著提高，超越了现有的多语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the performance of various speech SSL models ondialectal Arabic (DA) and Arabic-English code-switched (CS) speech. To addressdata scarcity, a modified audio-splicing approach is introduced to generateartificial CS speech data. Fine-tuning an already fine-tuned SSL model with theproposed Spliced-Audio Generated (SAGE) data results in an absolute improvementon Word Error Rate (WER) of 7.8% on Arabic and English CS benchmarks.Additionally, an Experience Replay (ER) inspired approach is proposed toenhance generalisation across DA and CS speech while mitigating catastrophicforgetting. Integrating an out-of-domain 3-gram language model reduces theoverall mean WER from 31.7% to 26.6%. Few-shot fine-tuning for code-switchingbenchmarks further improves WER by 4.9%. A WER of 31.1% on Arabic-English CSbenchmarks surpasses large-scale multilingual models, including USM andWhisper-large-v2 (both over ten times larger) by an absolute margin of 5.5% and8.4%, respectively.</description>
      <author>example@mail.com (Muhammad Umar Farooq, Oscar Saz)</author>
      <guid isPermaLink="false">2506.22143v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CaloHadronic: a diffusion model for the generation of hadronic showers</title>
      <link>http://arxiv.org/abs/2506.21720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了使用机器学习模拟高粒度量能器中粒子淋浴的关键进展，提出了基于扩散的生成式淋浴模拟方法，并扩展了用于模拟国际大型探测器（ILD）电磁量能器中电磁淋浴的架构。&lt;h4&gt;背景&lt;/h4&gt;模拟高粒度量能器中的粒子淋浴对于机器学习在粒子物理学中的应用是一个关键前沿领域。&lt;h4&gt;目的&lt;/h4&gt;通过使用生成式机器学习模型实现高精度和速度，以增强传统模拟并缓解计算限制。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于扩散的生成式淋浴模拟方法，该方法不依赖于固定结构，而是生成与几何无关的点云。此外，扩展了用于模拟电磁淋浴的架构，并引入了注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;注意力机制使得能够生成具有更明显子结构的复杂强子淋浴，这些淋浴跨越电磁和强子量能器。这是首次在高度粒度成像量能器系统中使用机器学习方法来整体生成电磁和强子量能器中的淋浴。&lt;h4&gt;结论&lt;/h4&gt;基于扩散的生成式淋浴模拟方法和扩展的架构在模拟粒子淋浴方面表现出高效性，为机器学习在粒子物理学中的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating showers of particles in highly-granular calorimeters is a keyfrontier in the application of machine learning to particle physics. Achievinghigh accuracy and speed with generative machine learning models can enable themto augment traditional simulations and alleviate a major computing constraint.Recent developments have shown how diffusion based generative shower simulationapproaches that do not rely on a fixed structure, but instead generategeometry-independent point clouds, are very efficient. We present atransformer-based extension to previous architectures which were developed forsimulating electromagnetic showers in the highly granular electromagneticcalorimeter of the International Large Detector, ILD. The attention mechanismnow allows us to generate complex hadronic showers with more pronouncedsubstructure across both the electromagnetic and hadronic calorimeters. This isthe first time that machine learning methods are used to holistically generateshowers across the electromagnetic and hadronic calorimeter in highly granularimaging calorimeter systems.</description>
      <author>example@mail.com (Thorsten Buss, Frank Gaede, Gregor Kasieczka, Anatolii Korol, Katja Krüger, Peter McKeown, Martina Mozzanica)</author>
      <guid isPermaLink="false">2506.21720v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation</title>
      <link>http://arxiv.org/abs/2506.21233v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于数据质量的开放词汇语义分割（OVS）方法，旨在无需昂贵模型微调的情况下，对任意文本类别进行图像分割。&lt;h4&gt;背景&lt;/h4&gt;现有的OVS方法通常依赖于预训练模型的注意力机制或生成合成数据，但性能受限于依赖模型的性能或参考集的质量。&lt;h4&gt;目的&lt;/h4&gt;研究数据质量对OVS性能的影响，并引入一个以数据质量为导向的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架包括一个数据管道来构建高质量的参考集，以及一个基于相似度的检索过程。&lt;h4&gt;主要发现&lt;/h4&gt;高质量的参考集对无监督OVS有显著益处。&lt;h4&gt;结论&lt;/h4&gt;该方法在十个基准数据集上的评估中优于所有现有的无监督OVS方法，强调了数据中心设计在无需训练的情况下推进OVS的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training-free open-vocabulary semantic segmentation (OVS) aims to segmentimages given a set of arbitrary textual categories without costly modelfine-tuning. Existing solutions often explore attention mechanisms ofpre-trained models, such as CLIP, or generate synthetic data and design complexretrieval processes to perform OVS. However, their performance is limited bythe capability of reliant models or the suboptimal quality of reference sets.In this work, we investigate the largely overlooked data quality problem forthis challenging dense scene understanding task, and identify that ahigh-quality reference set can significantly benefit training-free OVS. Withthis observation, we introduce a data-quality-oriented framework, comprising adata pipeline to construct a reference set with well-paired segment-textembeddings and a simple similarity-based retrieval to unveil the essentialeffect of data. Remarkably, extensive evaluations on ten benchmark datasetsdemonstrate that our method outperforms all existing training-free OVSapproaches, highlighting the importance of data-centric design for advancingOVS without training. Our code is available at https://github.com/xiweix/ReME .</description>
      <author>example@mail.com (Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma)</author>
      <guid isPermaLink="false">2506.21233v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Transformers are Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.22084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is a technical version of an article in The Gradient at  https://thegradient.pub/transformers-are-graph-neural-networks/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了Transformer架构与图神经网络（GNNs）之间的联系，并展示了Transformer如何在图上进行消息传递，从而在图表示学习中发挥作用。&lt;h4&gt;背景&lt;/h4&gt;Transformer最初是为自然语言处理而引入的，而GNNs则用于图上的表示学习。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer架构与GNNs之间的数学联系，并探讨其在图表示学习中的应用。&lt;h4&gt;方法&lt;/h4&gt;本文展示了如何将Transformer视为在标记的完全连接图上操作的消息传递GNNs，其中自注意力机制捕捉所有标记之间的相对重要性，位置编码提供关于序列顺序或结构的线索。&lt;h4&gt;主要发现&lt;/h4&gt;尽管Transformer与GNNs有数学上的联系，但它们通过密集矩阵操作实现，这在现代硬件上比稀疏消息传递效率更高。&lt;h4&gt;结论&lt;/h4&gt;基于上述发现，Transformer被视为当前在硬件上占据优势的GNNs。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We establish connections between the Transformer architecture, originallyintroduced for natural language processing, and Graph Neural Networks (GNNs)for representation learning on graphs. We show how Transformers can be viewedas message passing GNNs operating on fully connected graphs of tokens, wherethe self-attention mechanism capture the relative importance of all tokensw.r.t. each-other, and positional encodings provide hints about sequentialordering or structure. Thus, Transformers are expressive set processingnetworks that learn relationships among input elements without beingconstrained by apriori graphs. Despite this mathematical connection to GNNs,Transformers are implemented via dense matrix operations that are significantlymore efficient on modern hardware than sparse message passing. This leads tothe perspective that Transformers are GNNs currently winning the hardwarelottery.</description>
      <author>example@mail.com (Chaitanya K. Joshi)</author>
      <guid isPermaLink="false">2506.22084v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment</title>
      <link>http://arxiv.org/abs/2506.21903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is an extended version of a paper accepted to MIPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在视频讲座中检测视觉元素的问题，并提出了一个基于迁移学习的方法，以提高视频内容的信息检索。&lt;h4&gt;背景&lt;/h4&gt;视频正在改变教育方式，通过在线课程和录制的讲座补充和取代课堂教学。研究集中在通过高级导航、可搜索性、总结以及问答聊天机器人来增强视频讲座的信息检索。&lt;h4&gt;目的&lt;/h4&gt;旨在提高视频讲座中视觉元素（如表格、图表和插图）的检测准确性，以增强对视频内容的访问。&lt;h4&gt;方法&lt;/h4&gt;评估了一系列最先进的目标检测模型在讲座视频数据集上的性能，并选择了YOLO模型进行优化。通过在多个基准数据集上进行训练和采用半监督自动标注策略，优化了YOLO模型。&lt;h4&gt;主要发现&lt;/h4&gt;YOLO模型在检测讲座视频中的视觉元素方面表现最为出色，优化后的模型在检测准确性和泛化能力上取得了显著进步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于解决讲座视频中视觉元素的自动检测问题具有实际应用价值，同时发布了标注的讲座视频帧基准数据集和源代码，以促进未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频正在通过在线课程和录制的讲座改变教育方式，补充和取代课堂教学。最近的研究集中在通过高级导航、可搜索性、总结以及问答聊天机器人来增强视频讲座的信息检索。视觉元素如表格、图表和插图对于讲座视频的理解、记忆和数据展示至关重要，但它们在提高视频内容访问方面的潜力尚未得到充分利用。主要原因是准确自动检测讲座视频中的视觉元素具有挑战性；原因包括：i）大多数视觉元素（如图表、图形、表格和插图）是人工创建的，缺乏任何标准结构；ii）连贯的视觉对象可能缺乏清晰的边界，可能由连接的文本和视觉组件组成。尽管基于深度学习的目标检测取得了进展，但当前模型由于讲座视频中视觉内容的独特性质和标注数据集的稀缺性，其性能并不令人满意。本文报告了一种用于检测讲座视频帧中视觉元素的迁移学习方法。评估了一系列最先进的目标检测模型在讲座视频数据集上的性能，YOLO模型在这一任务中表现最为出色。随后，YOLO模型通过在多个基准数据集上进行训练和部署半监督自动标注策略进行了优化。结果评估了这种方法的成功，同时也为讲座视频中的对象检测问题开发了一般解决方案。本文的贡献包括发布了一个公开的标注讲座视频帧基准数据集，以及源代码以促进未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video is transforming education with online courses and recorded lecturessupplementing and replacing classroom teaching. Recent research has focused onenhancing information retrieval for video lectures with advanced navigation,searchability, summarization, as well as question answering chatbots. Visualelements like tables, charts, and illustrations are central to comprehension,retention, and data presentation in lecture videos, yet their full potentialfor improving access to video content remains underutilized. A major factor isthat accurate automatic detection of visual elements in a lecture video ischallenging; reasons include i) most visual elements, such as charts, graphs,tables, and illustrations, are artificially created and lack any standardstructure, and ii) coherent visual objects may lack clear boundaries and may becomposed of connected text and visual components. Despite advancements in deeplearning based object detection, current models do not yield satisfactoryperformance due to the unique nature of visual content in lectures and scarcityof annotated datasets. This paper reports on a transfer learning approach fordetecting visual elements in lecture video frames. A suite of state of the artobject detection models were evaluated for their performance on lecture videodatasets. YOLO emerged as the most promising model for this task. SubsequentlyYOLO was optimized for lecture video object detection with training on multiplebenchmark datasets and deploying a semi-supervised auto labeling strategy.Results evaluate the success of this approach, also in developing a generalsolution to the problem of object detection in lecture videos. Papercontributions include a publicly released benchmark of annotated lecture videoframes, along with the source code to facilitate future research.</description>
      <author>example@mail.com (Dipayan Biswas, Shishir Shah, Jaspal Subhlok)</author>
      <guid isPermaLink="false">2506.21903v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Reasoning in machine vision: learning to think fast and slow</title>
      <link>http://arxiv.org/abs/2506.22075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的学习范式，通过允许在推理时间内提高性能（推理时间计算），即使在标记数据非常有限的情况下，也能使机器在视觉中进行推理。&lt;h4&gt;背景&lt;/h4&gt;推理是人类智能的标志，使人们能够在复杂和不熟悉的场景中做出适应性决策。相比之下，机器智能仍然受限于训练数据，在推理时缺乏动态优化解决方案的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够使机器在视觉中进行推理的方法，即使在数据稀缺的情况下也能通过增加思考时间（推理时间计算）来提高性能。&lt;h4&gt;方法&lt;/h4&gt;该方法受到心理学中人类认知的双重过程理论的启发，集成了快速思考的系统I模块和慢速思考的系统II模块。系统I模块用于熟悉任务，而系统II模块则通过自我玩强化学习迭代优化解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;该范式通过扩展思考时间，在真实世界的视觉任务中表现出色，不仅优于大规模监督学习，而且优于基础模型，甚至优于人类专家。&lt;h4&gt;结论&lt;/h4&gt;该范式在非语言机器推理方面具有变革性的潜力，包括计算机视觉基准和五器官医学图像上的癌症定位。&lt;h4&gt;翻译&lt;/h4&gt;Reasoning is a hallmark of human intelligence, enabling adaptive decision-making in complex and unfamiliar scenarios. In contrast, machine intelligence remains bound to training data, lacking the ability to dynamically refine solutions at inference time. While some recent advances have explored reasoning in machines, these efforts are largely limited to verbal domains such as mathematical problem-solving, where explicit rules govern step-by-step reasoning. Other critical real-world tasks - including visual perception, spatial reasoning, and radiological diagnosis - require non-verbal reasoning, which remains an open challenge. Here we present a novel learning paradigm that enables machine reasoning in vision by allowing performance improvement withincreasing thinking time (inference-time compute), even under conditions wherelabelled data is very limited. Inspired by dual-process theories of humancognition in psychology, our approach integrates a fast-thinking System Imodule for familiar tasks, with a slow-thinking System II module that iteratively refines solutions using self-play reinforcement learning. This paradigm mimics human reasoning by proposing, competing over, and refining solutions in data-scarce scenarios. We demonstrate superior performance through extended thinking time, compared not only to large-scale supervised learning but also foundation models and even human experts, in real-world vision tasks. These tasks include computer-vision benchmarks and cancer localisation on medical images across five organs, showcasing transformative potential for non-verbal machine reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning is a hallmark of human intelligence, enabling adaptivedecision-making in complex and unfamiliar scenarios. In contrast, machineintelligence remains bound to training data, lacking the ability to dynamicallyrefine solutions at inference time. While some recent advances have exploredreasoning in machines, these efforts are largely limited to verbal domains suchas mathematical problem-solving, where explicit rules govern step-by-stepreasoning. Other critical real-world tasks - including visual perception,spatial reasoning, and radiological diagnosis - require non-verbal reasoning,which remains an open challenge. Here we present a novel learning paradigm thatenables machine reasoning in vision by allowing performance improvement withincreasing thinking time (inference-time compute), even under conditions wherelabelled data is very limited. Inspired by dual-process theories of humancognition in psychology, our approach integrates a fast-thinking System Imodule for familiar tasks, with a slow-thinking System II module thatiteratively refines solutions using self-play reinforcement learning. Thisparadigm mimics human reasoning by proposing, competing over, and refiningsolutions in data-scarce scenarios. We demonstrate superior performance throughextended thinking time, compared not only to large-scale supervised learningbut also foundation models and even human experts, in real-world vision tasks.These tasks include computer-vision benchmarks and cancer localisation onmedical images across five organs, showcasing transformative potential fornon-verbal machine reasoning.</description>
      <author>example@mail.com (Shaheer U. Saeed, Yipei Wang, Veeru Kasivisvanathan, Brian R. Davidson, Matthew J. Clarkson, Yipeng Hu, Daniel C. Alexander)</author>
      <guid isPermaLink="false">2506.22075v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Offensive Language Detection on Social Media Using XLNet</title>
      <link>http://arxiv.org/abs/2506.21795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了社交媒体上基于文本的沟通方式，指出其既提升了用户互动，又导致了攻击性内容（包括仇恨言论、种族主义和其他形式的滥用）的增加。由于用户生成内容数量巨大，手动监管不切实际，因此需要自动检测攻击性语言的系统。研究发现，基于XLNet的自动攻击性语言检测模型在检测攻击性内容方面优于BERT，且在分类攻击类型方面表现更好。同时，过采样和欠采样策略有效解决了类别不平衡问题，并提高了分类性能。&lt;h4&gt;背景&lt;/h4&gt;社交媒体上基于文本的沟通方式普及，既提高了用户互动，也增加了攻击性内容的产生。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于XLNet的自动攻击性语言检测模型，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;使用XLNet和BERT模型，通过Offensive Language Identification Dataset (OLID)进行评估，该数据集包含层级标注的Twitter数据。&lt;h4&gt;主要发现&lt;/h4&gt;XLNet在检测攻击性内容和分类攻击类型方面优于BERT，而过采样和欠采样策略有助于解决类别不平衡问题。&lt;h4&gt;结论&lt;/h4&gt;转移学习和基于XLNet的架构在创建能够检测社交媒体平台上攻击性语言的鲁棒系统方面具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：社交媒体上基于文本的沟通方式，如聊天、评论和微博的使用，提高了用户互动，但也导致攻击性内容（包括仇恨言论、种族主义和其他形式的滥用）的增加。由于用户生成内容数量巨大，手动监管不切实际，这需要能够检测攻击性语言的自动系统。深度学习模型，特别是使用迁移学习的模型，在通过大规模预训练理解自然语言方面取得了显著的成效。在本研究中，我们提出了一种基于XLNet的自动攻击性语言检测模型，这是一种通用的自回归预训练方法，并将其性能与BERT（双向编码器表示从变换器）进行了比较，BERT是自然语言处理（NLP）中广泛使用的基线。这两个模型都使用Offensive Language Identification Dataset（OLID）进行了评估，这是一个包含层级标注的基准Twitter数据集。我们的实验结果表明，XLNet在检测攻击性内容和分类攻击类型方面优于BERT，而BERT在识别攻击目标方面表现略好。此外，我们发现过采样和欠采样策略在解决类别不平衡和改进分类性能方面是有效的。这些发现突出了迁移学习和基于XLNet架构创建检测社交媒体平台攻击性语言的鲁棒系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of text-based communication on social media-through chats,comments, and microblogs-has improved user interaction but has also led to anincrease in offensive content, including hate speech, racism, and other formsof abuse. Due to the enormous volume of user-generated content, manualmoderation is impractical, which creates a need for automated systems that candetect offensive language. Deep learning models, particularly those usingtransfer learning, have demonstrated significant success in understandingnatural language through large-scale pretraining. In this study, we propose anautomatic offensive language detection model based on XLNet, a generalizedautoregressive pretraining method, and compare its performance with BERT(Bidirectional Encoder Representations from Transformers), which is a widelyused baseline in natural language processing (NLP). Both models are evaluatedusing the Offensive Language Identification Dataset (OLID), a benchmark Twitterdataset that includes hierarchical annotations. Our experimental results showthat XLNet outperforms BERT in detecting offensive content and in categorizingthe types of offenses, while BERT performs slightly better in identifying thetargets of the offenses. Additionally, we find that oversampling andundersampling strategies are effective in addressing class imbalance andimproving classification performance. These findings highlight the potential oftransfer learning and XLNet-based architectures to create robust systems fordetecting offensive language on social media platforms.</description>
      <author>example@mail.com (Reem Alothman, Hafida Benhidour, Said Kerrache)</author>
      <guid isPermaLink="false">2506.21795v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting</title>
      <link>http://arxiv.org/abs/2506.22039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为UniCA的框架，用于桥接时间序列基础模型（TSFMs）与一般协变量感知预测，以提高模型处理多样化协变量的能力。&lt;h4&gt;背景&lt;/h4&gt;TSFMs在处理实值时间序列方面取得了显著成功，但其设计主要针对实值序列，限制了其在处理涉及不同和异质协变量的预测任务中的能力。&lt;h4&gt;目的&lt;/h4&gt;旨在解决TSFMs在处理涉及分类变量和多模态数据（如图像和文本）等异质协变量时的局限性。&lt;h4&gt;方法&lt;/h4&gt;UniCA首先通过协变量同质化将异质协变量转换为高级同质序列表示，然后通过统一的基于注意力的融合机制将它们融合。UniCA可以适应同质和异质协变量，同时保留TSFMs的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在多个单模态和多模态协变量感知预测基准上的实验表明，UniCA优于其他方法，突出了协变量感知TSFM适应在现实世界预测场景中的潜力。&lt;h4&gt;结论&lt;/h4&gt;UniCA是一个具有广泛适用性和兼容性的框架，能够有效提高TSFMs处理多样化协变量的能力，并在实际预测任务中展现出优越性能。&lt;h4&gt;翻译&lt;/h4&gt;时间序列基础模型（TSFMs）通过大规模预训练取得了显著的成功。然而，它们的设计主要针对实值序列，限制了它们处理涉及多样化和经常异质的协变量（如分类变量和多模态数据，例如图像和文本）的能力，这些协变量通常是特定于任务的，并且在预训练期间难以利用。为了解决这一差距，我们提出了统一协变量适应（UniCA），一个将TSFMs与一般协变量感知预测连接起来的框架。UniCA首先执行协变量同质化，将异质协变量转换为高级同质序列表示，然后通过统一的基于注意力的融合机制将它们融合。UniCA既兼容又通用，可以适应同质和异质协变量，同时包含额外的协变量信息，同时保留TSFMs的泛化能力。在多个单模态和多模态协变量感知预测基准上的广泛实验证明了UniCA的优越性，突出了协变量感知TSFM适应在现实世界预测场景中的潜力。代码已发布在https://github.com/hanlu-nju/UniCA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time Series Foundation Models (TSFMs) have achieved remarkable successthrough large-scale pretraining. However, their design primarily targetsreal-valued series, limiting their ability to handle general forecasting tasksinvolving diverse and often heterogeneous covariates--such as categoricalvariables and multimodal data (e.g., images, text)--which are typicallytask-specific and difficult to leverage during pretraining. To address thisgap, we propose Unified Covariate Adaptation (UniCA), a framework to bridgeTSFMs with general covariate-aware forecasting. UniCA first performs covariatehomogenization to transform heterogeneous covariates into high-levelhomogeneous series representations and then fuses them via a unifiedattention-based fusion mechanism. UniCA is compatible and universal foradaptation with both homogeneous and heterogeneous covariates, incorporatingextra covariate information while preserving the generalization ability ofTSFMs.Extensive experiments on multiple unimodal and multimodal covariate-awareforecasting benchmarks demonstrate the superiority of UniCA, highlighting thepromise of covariate-aware TSFM adaptation in real-world forecasting scenarios.Codes are released on https://github.com/hanlu-nju/UniCA.</description>
      <author>example@mail.com (Lu Han, Yu Liu, Qiwen Deng, Jian Jiang, Yinbo Sun, Zhe Yu, Binfeng Wang, Xingyu Lu, Lintao Ma, Han-Jia Ye, De-Chuan Zhan)</author>
      <guid isPermaLink="false">2506.22039v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Comparing Learning Paradigms for Egocentric Video Summarization</title>
      <link>http://arxiv.org/abs/2506.21785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了多种计算机视觉范式，包括监督学习、无监督学习和提示微调，评估它们理解和解释自摄视频数据的能力。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的模型在处理第一人称视频方面比第三人称视频效果差，需要在该领域取得进一步进展。&lt;h4&gt;目的&lt;/h4&gt;提供一种综合性的概念证明分析，旨在推进计算机视觉技术在第一人称视频中的应用。&lt;h4&gt;方法&lt;/h4&gt;评估了Shotluck Holmes（最先进的监督学习）、TAC-SUM（最先进的无监督学习）和GPT-4o（提示微调的预训练模型）在视频摘要中的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提示微调的通用GPT-4o模型在视频摘要任务中优于专用模型，突显了现有方法在适应第一人称视角独特挑战方面的局限性。&lt;h4&gt;结论&lt;/h4&gt;通过探索新颖的方法并评估其潜力，旨在为能够有效处理和解释第一人称视角的模型的发展做出贡献。&lt;h4&gt;翻译&lt;/h4&gt;在这项研究中，我们通过评估它们理解和解释自摄视频数据的能力，研究了各种计算机视觉范式——监督学习、无监督学习和提示微调。具体来说，我们考察了Shotluck Holmes（最先进的监督学习）、TAC-SUM（最先进的无监督学习）和GPT-4o（一个提示微调的预训练模型），评估了它们在视频摘要中的有效性。我们的结果表明，当前最先进的模型在处理第一人称视频方面比第三人称视频效果差，突显了在该领域取得进一步进展的必要性。值得注意的是，一个提示微调的通用GPT-4o模型在这些专用模型中表现更优，强调了现有方法在适应第一人称视角独特挑战方面的局限性。尽管由于资源限制，我们的评估是在Ego-Exo4D数据集的一个小子集上进行的，但这项研究的主要目标是提供一种综合性的概念证明分析，旨在推进计算机视觉技术在第一人称视频中的应用。通过探索新颖的方法并评估其潜力，我们旨在为能够有效处理和解释第一人称视角的模型的发展做出贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we investigate various computer vision paradigms - supervisedlearning, unsupervised learning, and prompt fine-tuning - by assessing theirability to understand and interpret egocentric video data. Specifically, weexamine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM(state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tunedpre-trained model), evaluating their effectiveness in video summarization. Ourresults demonstrate that current state-of-the-art models perform lesseffectively on first-person videos compared to third-person videos,highlighting the need for further advancements in the egocentric video domain.Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms thesespecialized models, emphasizing the limitations of existing approaches inadapting to the unique challenges of first-person perspectives. Although ourevaluation is conducted on a small subset of egocentric videos from theEgo-Exo4D dataset due to resource constraints, the primary objective of thisresearch is to provide a comprehensive proof-of-concept analysis aimed atadvancing the application of computer vision techniques to first-person videos.By exploring novel methodologies and evaluating their potential, we aim tocontribute to the ongoing development of models capable of effectivelyprocessing and interpreting egocentric perspectives.</description>
      <author>example@mail.com (Daniel Wen)</author>
      <guid isPermaLink="false">2506.21785v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted for publication in lEEE/RSJ international  Conference on Intelligent Robots and Systems (lROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TASeg的文本感知RGB-T语义分割框架，旨在解决现有模型在处理开放环境中的语义分割问题。&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-T语义分割模型主要依赖低级视觉特征，缺乏高级文本信息，难以准确分割具有相似视觉特征的类别。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的文本感知RGB-T语义分割框架TASeg。&lt;h4&gt;方法&lt;/h4&gt;TASeg利用低秩自适应（LoRA）微调技术对视觉基础模型进行适应。具体来说，在图像编码器中提出了动态特征融合模块（DFFM），有效地融合了来自多个视觉模态的特征，同时冻结了SAM的原始transformer块。此外，在掩码解码器中结合了CLIP生成的文本嵌入，以实现语义对齐，进一步纠正分类错误并提高语义理解精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TASeg在多个数据集上表现出优异的性能，尤其是在具有挑战性的场景中，并且具有较少的可训练参数。&lt;h4&gt;结论&lt;/h4&gt;TASeg框架通过融合视觉和文本信息，有效提高了语义分割的准确性，为智能系统在开放环境中的可靠语义分割提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable semantic segmentation of open environments is essential forintelligent systems, yet significant problems remain: 1) Existing RGB-Tsemantic segmentation models mainly rely on low-level visual features and lackhigh-level textual information, which struggle with accurate segmentation whencategories share similar visual characteristics. 2) While SAM excels ininstance-level segmentation, integrating it with thermal images and text ishindered by modality heterogeneity and computational inefficiency. To addressthese, we propose TASeg, a text-aware RGB-T segmentation framework by usingLow-Rank Adaptation (LoRA) fine-tuning technology to adapt vision foundationmodels. Specifically, we propose a Dynamic Feature Fusion Module (DFFM) in theimage encoder, which effectively merges features from multiple visualmodalities while freezing SAM's original transformer blocks. Additionally, weincorporate CLIP-generated text embeddings in the mask decoder to enablesemantic alignment, which further rectifies the classification error andimproves the semantic understanding accuracy. Experimental results acrossdiverse datasets demonstrate that our method achieves superior performance inchallenging scenarios with fewer trainable parameters.</description>
      <author>example@mail.com (Meng Yu, Te Cui, Qitong Chu, Wenjie Song, Yi Yang, Yufeng Yue)</author>
      <guid isPermaLink="false">2506.21975v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts</title>
      <link>http://arxiv.org/abs/2506.21835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ProSAM的新方法，用于解决现有基于SAM的视觉参考分割方法中的稳定性问题，并提高了视觉参考分割的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型基础模型的发展推动了开放集图像分割任务的进展，特别是视觉参考分割，它具有独特的灵活性和强大的零样本能力。&lt;h4&gt;目的&lt;/h4&gt;提出ProSAM方法，以解决现有方法在生成提示时的不稳定性问题。&lt;h4&gt;方法&lt;/h4&gt;ProSAM通过学习一个变分提示编码器来预测多变量提示分布，从而避免生成位于不稳定区域的提示。&lt;h4&gt;主要发现&lt;/h4&gt;ProSAM在Pascal-5i和COCO-20i数据集上优于现有方法，提供了更鲁棒的视觉参考分割解决方案。&lt;h4&gt;结论&lt;/h4&gt;ProSAM是一种简单而有效的方法，可以显著提高基于SAM的视觉参考分割的稳定性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancements in large foundation models have driven the success ofopen-set image segmentation, a task focused on segmenting objects beyondpredefined categories. Among various prompt types (such as points, boxes,texts, and visual references), visual reference segmentation stands out for itsunique flexibility and strong zero-shot capabilities. Recently, severalSAM-based methods have made notable progress in this task by automaticallygenerating prompts to guide SAM. However, these methods often generate promptsat object boundaries due to suboptimal prompt encoder, which results ininstability and reduced robustness. In this work, we introduce ProSAM, a simplebut effective method to address the stability challenges we identified inexisting SAM-based visual reference segmentation approaches. By learning avariational prompt encoder to predict multivariate prompt distributions, ProSAMavoids generating prompts that lie in unstable regions, overcoming theinstability caused by less robust prompts. Our approach consistently surpassesstate-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,providing a more robust solution for visual reference segmentation.</description>
      <author>example@mail.com (Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren)</author>
      <guid isPermaLink="false">2506.21835v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.21627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, under review of NeurIPS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FrankenBot的机器人操作框架，该框架通过整合视觉-语言模型（VLM）和大脑形态架构，实现了在复杂、动态、非结构化环境中的多功能操作和高效率。&lt;h4&gt;背景&lt;/h4&gt;在复杂和动态的真实环境中开发能够执行广泛任务的通用机器人操作系统一直是一个挑战。目前的方法通常只实现机器人大脑中的一部分功能，而没有将它们集成到一个统一的认知架构中。&lt;h4&gt;目的&lt;/h4&gt;实现具有类似人类效率和鲁棒性的机器人操作，需要机器人大脑整合一套全面的函数，如任务规划、策略生成、异常监控和处理、长期记忆等。&lt;h4&gt;方法&lt;/h4&gt;FrankenBot框架包括一系列组件，将部分关键功能从频繁的VLM调用中解耦，在功能完整性和系统效率之间达到最佳平衡。具体来说，将任务规划、策略生成、内存管理和低级接口分别映射到大脑的皮层、小脑、颞叶-海马体复合体和脑干，并为模块设计高效的协调机制。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实机器人环境中进行的全面实验表明，该方法在异常检测和处理、长期记忆、操作效率和稳定性方面具有显著优势，且无需任何微调或重新训练。&lt;h4&gt;结论&lt;/h4&gt;FrankenBot框架通过整合VLM和大脑形态架构，为在复杂环境中实现高效和鲁棒的机器人操作提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Developing a general robot manipulation system capable of performing a wide range of tasks in complex, dynamic, and unstructured real-world environments has long been a challenging task. It is widely recognized that achieving human-like efficiency and robustness manipulation requires the robotic brain to integrate a comprehensive set of functions, such as task planning, policy generation, anomaly monitoring and handling, and long-term memory, achieving high-efficiency operation across all functions. Vision-Language Models (VLMs), pretrained on massive multimodal data, have acquired rich world knowledge, exhibiting exceptional scene understanding and multimodal reasoning capabilities. However, existing methods typically focus on realizing only a single function or a subset of functions within the robotic brain, without integrating them into a unified cognitive architecture. Inspired by a divide-and-conquer strategy and the architecture of the human brain, we propose FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that achieves both comprehensive functionality and high operational efficiency. Our framework includes a suite of components, decoupling a part of key functions from frequent VLM calls, striking an optimal balance between functional completeness and system efficiency. Specifically, we map task planning, policy generation, memory management, and low-level interfacing to the cortex, cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and design efficient coordination mechanisms for the modules. We conducted comprehensive experiments in both simulation and real-world robotic environments, demonstrating that our method offers significant advantages in anomaly detection and handling, long-term memory, operational efficiency, and stability -- all without requiring any fine-tuning or retraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a general robot manipulation system capable of performing a widerange of tasks in complex, dynamic, and unstructured real-world environmentshas long been a challenging task. It is widely recognized that achievinghuman-like efficiency and robustness manipulation requires the robotic brain tointegrate a comprehensive set of functions, such as task planning, policygeneration, anomaly monitoring and handling, and long-term memory, achievinghigh-efficiency operation across all functions. Vision-Language Models (VLMs),pretrained on massive multimodal data, have acquired rich world knowledge,exhibiting exceptional scene understanding and multimodal reasoningcapabilities. However, existing methods typically focus on realizing only asingle function or a subset of functions within the robotic brain, withoutintegrating them into a unified cognitive architecture. Inspired by adivide-and-conquer strategy and the architecture of the human brain, we proposeFrankenBot, a VLM-driven, brain-morphic robotic manipulation framework thatachieves both comprehensive functionality and high operational efficiency. Ourframework includes a suite of components, decoupling a part of key functionsfrom frequent VLM calls, striking an optimal balance between functionalcompleteness and system efficiency. Specifically, we map task planning, policygeneration, memory management, and low-level interfacing to the cortex,cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, anddesign efficient coordination mechanisms for the modules. We conductedcomprehensive experiments in both simulation and real-world roboticenvironments, demonstrating that our method offers significant advantages inanomaly detection and handling, long-term memory, operational efficiency, andstability -- all without requiring any fine-tuning or retraining.</description>
      <author>example@mail.com (Shiyi Wang, Wenbo Li, Yiteng Chen, Qingyao Wu, Huiping Zhuang)</author>
      <guid isPermaLink="false">2506.21627v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, accepted at ICDAR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种简单有效的少量样本分割历史地图的方法，该方法结合了大型视觉基础模型的丰富语义嵌入和参数高效的微调，在历史地图的自动化处理中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;历史地图作为丰富的历史资料来源，提供了对历史变化的深入了解，但由于其多样化的视觉表示和有限的标注数据，为自动化处理带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种能够有效分割历史地图的方法，减少对手动标注的需求，并推进历史地图的自动化处理和分析。&lt;h4&gt;方法&lt;/h4&gt;方法结合了大型视觉基础模型的语义嵌入和参数高效的微调，实现了少量样本分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Siegfried基准数据集的葡萄园和铁路分割任务上优于现有技术，在10个样本的情况下，mIoU相对提高了5%，在更具挑战性的5个样本情况下提高了约13%。此外，在ICDAR 2021竞赛数据集上也表现出色，尽管未针对形状敏感的指标进行优化，但实现了67.3%的平均PQ值。该方法在低数据量情况下（10个和5个样本）也能保持高性能，同时所需的训练参数仅为模型总量的0.21%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够精确分割各种历史地图，同时大幅减少对手动标注的需求，推进了该领域的自动化处理和分析。&lt;h4&gt;翻译&lt;/h4&gt;As rich sources of history, maps provide crucial insights into historical changes, yet their diverse visual representations and limited annotated data pose significant challenges for automated processing. We propose a simple yet effective approach for few-shot segmentation of historical maps, leveraging the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on the Siegfried benchmark dataset in vineyard and railway segmentation, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. Additionally, it demonstrates strong performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric, underscoring its generalizability. Notably, our approach maintains high performance even in extremely low-data regimes (10- &amp; 5-shot), while requiring only 689k trainable parameters - just 0.21% of the total model size. Our approach enables precise segmentation of diverse historical maps while drastically reducing the need for manual annotations, advancing automated processing and analysis in the field. Our implementation is publicly available at: https://github.com/RafaelSterzinger/few-shot-map-segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As rich sources of history, maps provide crucial insights into historicalchanges, yet their diverse visual representations and limited annotated datapose significant challenges for automated processing. We propose a simple yeteffective approach for few-shot segmentation of historical maps, leveraging therich semantic embeddings of large vision foundation models combined withparameter-efficient fine-tuning. Our method outperforms the state-of-the-art onthe Siegfried benchmark dataset in vineyard and railway segmentation, achieving+5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20%in the more challenging 5-shot setting. Additionally, it demonstrates strongperformance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3%for building block segmentation, despite not being optimized for thisshape-sensitive metric, underscoring its generalizability. Notably, ourapproach maintains high performance even in extremely low-data regimes (10- &amp;5-shot), while requiring only 689k trainable parameters - just 0.21% of thetotal model size. Our approach enables precise segmentation of diversehistorical maps while drastically reducing the need for manual annotations,advancing automated processing and analysis in the field. Our implementation ispublicly available at:https://github.com/RafaelSterzinger/few-shot-map-segmentation.</description>
      <author>example@mail.com (Rafael Sterzinger, Marco Peer, Robert Sablatnig)</author>
      <guid isPermaLink="false">2506.21826v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data</title>
      <link>http://arxiv.org/abs/2506.21788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的图基础模型，通过多任务学习方法提高原子建模的可持续性和效率。&lt;h4&gt;背景&lt;/h4&gt;处理多源、多保真度数据在预训练阶段存在挑战，需要稳定预训练并提高模型对新化学区域的迁移能力。&lt;h4&gt;目的&lt;/h4&gt;通过多任务学习来稳定预训练，并增强模型对新化学区域的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;采用多任务学习方法，共享消息传递层先处理输入原子结构，然后将其路由到多个解码头以预测特定数据输出。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明，在约四百万个结构上效果良好，但关于其在大规模、多样化数据集上的泛化能力和在超级计算机上的可扩展性的问题仍存在。&lt;h4&gt;结论&lt;/h4&gt;提出了一种多任务并行方法，通过GPU加速将每个头部分布到计算资源上。该方法在超过2400万个结构上进行训练，并在Perlmutter、Aurora和Frontier超级计算机上进行测试，证明了在三种高度异构的超级计算架构上的高效扩展。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a graph foundation model based on graph neural networks, which improves the sustainability and efficiency of atomic modeling through multi-task learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph foundation models using graph neural networks promise sustainable,efficient atomistic modeling. To tackle challenges of processing multi-source,multi-fidelity data during pre-training, recent studies employ multi-tasklearning, in which shared message passing layers initially process inputatomistic structures regardless of source, then route them to multiple decodingheads that predict data-specific outputs. This approach stabilizes pre-trainingand enhances a model's transferability to unexplored chemical regions.Preliminary results on approximately four million structures are encouraging,yet questions remain about generalizability to larger, more diverse datasetsand scalability on supercomputers. We propose a multi-task parallelism methodthat distributes each head across computing resources with GPU acceleration.Implemented in the open-source HydraGNN architecture, our method was trained onover 24 million structures from five datasets and tested on the Perlmutter,Aurora, and Frontier supercomputers, demonstrating efficient scaling on allthree highly heterogeneous super-computing architectures.</description>
      <author>example@mail.com (Massimiliano Lupo Pasini, Jong Youl Choi, Pei Zhang, Kshitij Mehta, Rylie Weaver, Ashwin M. Aji, Karl W. Schulz, Jorda Polo, Prasanna Balaprakash)</author>
      <guid isPermaLink="false">2506.21788v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Environment-Based Channel Knowledge Map Construction</title>
      <link>http://arxiv.org/abs/2506.21112v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种联合模型和数据驱动的Channel knowledge map (CKM)构建方法，通过利用点云环境数据和少量位置标记的信道信息，提高了CKM的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的CKM构建方案采用过于简化的环境信息，这严重影响了其准确性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有CKM构建方案中环境信息简化的准确性问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的点选择器，通过基于不同到达时间（ToA）构建一组共焦点椭球，识别包含与多径信道增益相关的环境信息的点云子集。2. 训练了一个神经网络信道增益估计器，通过使用我们通过实地测量收集的包含环境点云和对应信道数据的真实世界数据集，学习每个选定点云子集与其相应信道增益之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;对于功率延迟剖面（PDP）的CKM构建，该方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，它实现了1.04 dB的RMSE，超过了克里金插值方法的1.68 dB。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了CKM构建的准确性，尤其是在PDP和接收功率值的构建方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：信道知识图（CKM）为感兴趣区域提供了一定程度的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键推动者。然而，现有的CKM构建方案采用了过于简化的环境信息，这严重影响了它们的准确性。为了解决这个问题，本研究提出了一种联合模型和数据驱动的构建CKM的方法，通过利用点云环境数据以及一些位置标记的信道信息样本。首先，我们提出了一种新的点选择器，通过基于不同的到达时间（ToA）构建一组共焦点椭球，以识别包含与多径信道增益相关的环境信息的点云子集。然后，我们训练了一个神经网络信道增益估计器，通过使用我们通过实地测量收集的包含环境点云和对应信道数据的真实世界数据集，学习每个选定点云子集与其相应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提出的方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，它实现了1.04 dB的RMSE，超过了克里金插值方法的1.68 dB。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Channel knowledge map (CKM) provides certain levels of channel stateinformation (CSI) for an area of interest, serving as a critical enabler forenvironment-aware communications by reducing the overhead of frequent CSIacquisition. However, existing CKM construction schemes adopt over-simplifiedenvironment information, which significantly compromises their accuracy. Toaddress this issue, this work proposes a joint model- and data-driven approachto construct CKM by leveraging point cloud environmental data along with a fewsamples of location-tagged channel information. First, we propose a novel pointselector to identify subsets of point cloud that contain environmentalinformation relevant to multipath channel gains, by constructing a set ofco-focal ellipsoids based on different time of arrival (ToAs). Then, we traineda neural channel gain estimator to learn the mapping between each selectedsubset and its corresponding channel gain, using a real-world dataset wecollected through field measurements, comprising environmental point clouds andcorresponding channel data. Finally, experimental results demonstrate that: ForCKM construction of power delay profile (PDP), the proposed method achieves aroot mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dBachieved by the conventional ray-tracing method; for CKM construction ofreceived power values, i.e., radio map, it achieves an RMSE of 1.04 dB,surpassing the Kriging interpolation method with an RMSE of 1.68 dB.</description>
      <author>example@mail.com (Yancheng Wang, Wei Guo, Chuan Huang, Guanying Chen, Ye Zhang, Shuguang Cui)</author>
      <guid isPermaLink="false">2506.21112v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Infrared foundations for quantum geometry I: Catalogue of totally symmetric rank-three field theories</title>
      <link>http://arxiv.org/abs/2506.21662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 Pages, 9 Figures, 2 Tables. Comments welcome!&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;系统地获得了在平坦背景上传播无宇称违反的完全对称的三秩场的所有线性模型。&lt;h4&gt;背景&lt;/h4&gt;这些模型仅由其规范对称性定义，这是红外极限下有效场理论的必要属性。&lt;h4&gt;目的&lt;/h4&gt;通过比较，发现通过其他方法（调整耦合或选择操作符）获得的模型可能对辐射修正不稳定。&lt;h4&gt;方法&lt;/h4&gt;对每个模型，计算了无质量和有质量粒子的谱，以及耦合的鬼和快子约束。&lt;h4&gt;主要发现&lt;/h4&gt;存在基础模型，可以传播一个自旋为一或三的无质量粒子，或同时传播这两个粒子，推广了Campoleoni和Francia的模型。&lt;h4&gt;结论&lt;/h4&gt;检测对称模型的算法基于粒子物理学方法，直接基于场的Wigner分解。&lt;h4&gt;翻译&lt;/h4&gt;我们系统地获得了在平坦背景上传播无宇称违反的完全对称的三秩场的所有线性模型。每个这样的模型仅由其规范对称性定义，这是红外极限下有效场理论的必要属性。通过比较，发现通过其他方法（调整耦合或选择操作符）获得的模型可能对辐射修正不稳定。对每个模型，我们计算了无质量和有质量粒子的谱，以及耦合的鬼和快子约束。我们得出结论，存在基础模型，可以传播一个自旋为一或三的无质量粒子，或同时传播这两个粒子，推广了Campoleoni和Francia的模型。检测对称模型的算法基于粒子物理学方法，直接基于场的Wigner分解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We systematically obtain all linear models which propagate a totallysymmetric rank-three field without parity violation on a flat background. Eachsuch model is defined exclusively by its gauge symmetry, a necessary propertyof effective field theories in the infrared limit. By comparison, modelsobtained by other means (tuning couplings or cherry-picking operators) may beunstable against radiative corrections. For each model, we compute the spectrumof massless and massive particles, and the no-ghost-no-tachyon constraints onthe couplings. We conclude that foundational models exist which can propagateone massless particle of spin one or spin three in isolation, or both particlessimultaneously, generalising the model of Campoleoni and Francia. Our algorithmfor detecting symmetric models is grounded in particle physics methods, beingbased directly on the Wigner decomposition of the field. Compared to our recentanalysis of the totally symmetric rank-three field (whose results we confirmand extend) our new algorithm does not require an ansatz for the symmetrytransformation, and is not restricted to so-called 'free' symmetries.</description>
      <author>example@mail.com (Will Barker, Carlo Marzo, Alessandro Santoni)</author>
      <guid isPermaLink="false">2506.21662v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Causal Inference for Latent Outcomes Learned with Factor Models</title>
      <link>http://arxiv.org/abs/2506.20549v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 1 table (+ references and supplement). For  open-source R software package, see https://github.com/jennalandy/causalLFO.  For all code used in the simulation studies and data application, see  https://github.com/jennalandy/causalLFO_PAPER&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在高维观测数据中，利用非负矩阵分解方法对潜在结果进行因果推断的问题。&lt;h4&gt;背景&lt;/h4&gt;在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等多个领域，解决因素模型或表示学习中的因果问题日益重要。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过非负矩阵分解方法，探究高维观测数据中潜在结果的因果效应。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖、直观且理论上有保证的算法来估计潜在结果的因果效应，同时减轻学习引起的干扰并提高估计效率。&lt;h4&gt;主要发现&lt;/h4&gt;本研究首次正式研究了在此设置下的因果推断问题，并提出了解决学习引起的干扰的方法。&lt;h4&gt;结论&lt;/h4&gt;通过模拟研究和癌症突变特征分析的实际应用，验证了所提算法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在许多领域（包括基因组学、流行病学、自然语言处理、社会和行为科学以及经济学）中，处理因素模型或表示学习中的因果问题变得越来越重要。在这项工作中，我们研究了使用非负矩阵分解从高维观测数据中得到的潜在结果的因果效应。据我们所知，这是第一个正式处理此设置中因果推断的研究。一个主要挑战是，估计一个潜在因素模型可能会导致个体学习的潜在结果依赖于其他个体的处理，从而违反了标准因果推断假设中的无干扰。我们将这个问题形式化为“学习引起的干扰”，并将其与数据生成过程中存在的干扰区分开来。为了解决这个问题，我们提出了一种新颖的、直观的、理论上有保证的算法来估计潜在结果的因果效应，同时减轻学习引起的干扰并提高估计效率。我们对我们的估计器的一致性提供了理论保证，并通过模拟研究和癌症突变特征分析的实际应用证明了其实际效用。所有基线和提出的方法都可在我们的开源R包causalLFO中找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many fields$\unicode{x2013}$including genomics, epidemiology, naturallanguage processing, social and behavioral sciences, andeconomics$\unicode{x2013}$it is increasingly important to address causalquestions in the context of factor models or representation learning. In thiswork, we investigate causal effects on $\textit{latent outcomes}$ derived fromhigh-dimensional observed data using nonnegative matrix factorization. To thebest of our knowledge, this is the first study to formally address causalinference in this setting. A central challenge is that estimating a latentfactor model can cause an individual's learned latent outcome to depend onother individuals' treatments, thereby violating the standard causal inferenceassumption of no interference. We formalize this issue as$\textit{learning-induced interference}$ and distinguish it from interferencepresent in a data-generating process. To address this, we propose a novel,intuitive, and theoretically grounded algorithm to estimate causal effects onlatent outcomes while mitigating learning-induced interference and improvingestimation efficiency. We establish theoretical guarantees for the consistencyof our estimator and demonstrate its practical utility through simulationstudies and an application to cancer mutational signature analysis. Allbaseline and proposed methods are available in our open-source R package, ${\ttcausalLFO}$.</description>
      <author>example@mail.com (Jenna M. Landy, Dafne Zorzetto, Roberta De Vito, Giovanni Parmigiani)</author>
      <guid isPermaLink="false">2506.20549v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian Splatting Based on a Skinning Model</title>
      <link>http://arxiv.org/abs/2506.21632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种从单目视频中重建动态人场景中的交互式人像及其背景的方法。&lt;h4&gt;背景&lt;/h4&gt;从单目视频中重建动态人场景中的交互式人像及其背景是一个高度挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;目的是在保证人类运动交互性的同时，实现背景和人类身体的分离重建。&lt;h4&gt;方法&lt;/h4&gt;采用点云解耦和联合优化的策略，引入位置纹理对SMPL身体模型表面进行细分并扩展人类点云。使用卷积神经网络结构根据纹理预测人体点云特征。该策略避免了超参数调整，并高效地用一半的点云数量表示人类点云。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在重建质量上超过了之前的HUGS方法，同时保持了对新姿势和视图的泛化能力。技术实现了超过100 FPS的实时渲染速度，比使用线性混合皮肤(LBS)权重的HUGS速度快约6倍。&lt;h4&gt;结论&lt;/h4&gt;该框架可以扩展到动物场景重建，当有准确的动物模型时。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a method for reconstructing interactive human avatars and their backgrounds from monocular videos of dynamic human scenes. This task is highly challenging. The aim is to achieve the decoupled reconstruction of backgrounds and human bodies while preserving the interactivity of human motion. The strategy adopted is based on point cloud decoupling and joint optimization, introducing a position texture to subdivide the surface of the Skinned Multi-Person Linear (SMPL) body model and expand the human point cloud. A convolutional neural network structure is incorporated to predict human body point cloud features based on texture. This strategy avoids hyperparameter tuning, and efficiently represents human points with half the point cloud of HUGS. This approach ensures high-quality human reconstruction and reduces GPU resource consumption during training. As a result, our method surpasses the previous state-of-the-art HUGS in reconstruction metrics while maintaining the ability to generalize to novel poses and views. Furthermore, our technique achieves real-time rendering at over 100 FPS, ~6 times the HUGS speed using only Linear Blend Skinning (LBS) weights for human transformation. Additionally, this work demonstrates that this framework can be extended to animal scene reconstruction when an accurately-posed model of an animal is available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing an interactive human avatar and the background from amonocular video of a dynamic human scene is highly challenging. In this work weadopt a strategy of point cloud decoupling and joint optimization to achievethe decoupled reconstruction of backgrounds and human bodies while preservingthe interactivity of human motion. We introduce a position texture to subdividethe Skinned Multi-Person Linear (SMPL) body model's surface and grow the humanpoint cloud. To capture fine details of human dynamics and deformations, weincorporate a convolutional neural network structure to predict human bodypoint cloud features based on texture. This strategy makes our approach free ofhyperparameter tuning for densification and efficiently represents human pointswith half the point cloud of HUGS. This approach ensures high-quality humanreconstruction and reduces GPU resource consumption during training. As aresult, our method surpasses the previous state-of-the-art HUGS inreconstruction metrics while maintaining the ability to generalize to novelposes and views. Furthermore, our technique achieves real-time rendering atover 100 FPS, $\sim$6$\times$ the HUGS speed using only Linear Blend Skinning(LBS) weights for human transformation. Additionally, this work demonstratesthat this framework can be extended to animal scene reconstruction when anaccurately-posed model of an animal is available.</description>
      <author>example@mail.com (Da Li, Donggang Jia, Markus Hadwiger, Ivan Viola)</author>
      <guid isPermaLink="false">2506.21632v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation</title>
      <link>http://arxiv.org/abs/2506.21805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CitySim是一个利用大型语言模型突破的智能城市模拟器，用于模拟城市环境中的人类行为，以支持社会科学、行为研究和城市规划。&lt;h4&gt;背景&lt;/h4&gt;以往的研究工作常常依赖于僵硬的、手工定制的规则，限制了它们模拟复杂意图、计划和适应性行为的能力。&lt;h4&gt;目的&lt;/h4&gt;提出CitySim，旨在解决上述挑战，实现更真实、更贴近人类行为的模拟。&lt;h4&gt;方法&lt;/h4&gt;CitySim中的代理使用递归价值驱动方法生成日常日程，平衡强制性活动、个人习惯和情境因素。代理还被赋予了信念、长期目标和空间记忆，以实现长期、逼真的模拟。&lt;h4&gt;主要发现&lt;/h4&gt;CitySim在微观和宏观层面上都表现出与真实人类更接近的契合度。通过模拟数万个代理，并在各种现实世界场景下评估他们的集体行为，进行了有见地的实验，包括估计人群密度、预测地点受欢迎程度和评估福祉。&lt;h4&gt;结论&lt;/h4&gt;CitySim被证明是一个可扩展、灵活的测试平台，用于理解和预测城市现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling human behavior in urban environments is fundamental for socialscience, behavioral studies, and urban planning. Prior work often rely onrigid, hand-crafted rules, limiting their ability to simulate nuancedintentions, plans, and adaptive behaviors. Addressing these challenges, weenvision an urban simulator (CitySim), capitalizing on breakthroughs inhuman-level intelligence exhibited by large language models. In CitySim, agentsgenerate realistic daily schedules using a recursive value-driven approach thatbalances mandatory activities, personal habits, and situational factors. Toenable long-term, lifelike simulations, we endow agents with beliefs, long-termgoals, and spatial memory for navigation. CitySim exhibits closer alignmentwith real humans than prior work, both at micro and macro levels. Additionally,we conduct insightful experiments by modeling tens of thousands of agents andevaluating their collective behaviors under various real-world scenarios,including estimating crowd density, predicting place popularity, and assessingwell-being. Our results highlight CitySim as a scalable, flexible testbed forunderstanding and forecasting urban phenomena.</description>
      <author>example@mail.com (Nicolas Bougie, Narimasa Watanabe)</author>
      <guid isPermaLink="false">2506.21805v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SliceGX: Layer-wise GNN Explanation with Model-slicing</title>
      <link>http://arxiv.org/abs/2506.17977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SliceGX是一种新型的图神经网络（GNN）解释方法，旨在提高GNN作为黑盒模型的可信度。&lt;h4&gt;背景&lt;/h4&gt;现有的GNN解释方法通常通过输入扰动来识别导致GNN最终输出的子图，但这些方法缺乏对中间表示的分层分析，这对于模型诊断和架构优化至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出SliceGX，旨在在GNN的特定层生成解释，并通过分层分析中间表示来提高GNN的可信度。&lt;h4&gt;方法&lt;/h4&gt;SliceGX通过自动将GNN分为层块（模型切片），在每个层块中找到高质量的解释子图，以阐明GNN在目标层的输出。&lt;h4&gt;主要发现&lt;/h4&gt;尽管找到这些分层解释在计算上具有挑战性，但SliceGX开发出高效的算法和优化技术，以增量生成和维护这些子图，并提供了可证明的近似保证。此外，SliceGX还提供了类似SPARQL的查询接口，以便对生成的解释进行声明性访问和搜索。&lt;h4&gt;结论&lt;/h4&gt;通过在大型真实世界图和代表性的GNN架构上的实验，验证了SliceGX的有效性和效率，并说明了其在支持模型调试方面的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：确保图神经网络（GNN）作为黑盒模型的可信度需要有效的解释方法。现有的GNN解释方法通常通过对输入扰动来识别导致GNN最终输出的子图。然而，这些方法缺乏对中间表示的分层分析，这对于模型诊断和架构优化至关重要。本文介绍了SliceGX，这是一种新颖的GNN解释方法，它以渐进的方式在特定的GNN层生成解释。给定一个GNN M，一组选定的中间层和一个目标层，SliceGX自动将M分为层块（“模型切片”），并在每个层块中找到高质量的解释子图，以阐明M在目标层的输出。虽然找到这样的分层解释在计算上具有挑战性，但我们开发出高效的算法和优化技术，以增量生成和维护这些子图，并提供了可证明的近似保证。此外，SliceGX提供了一个类似SPARQL的查询接口，提供了对生成的解释的声明性访问和搜索能力。通过在大型真实世界图和代表性的GNN架构上的实验，我们验证了SliceGX的有效性和效率，并说明了其在支持模型调试方面的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the trustworthiness of graph neural networks (GNNs) as black-boxmodels requires effective explanation methods. Existing GNN explanationstypically apply input perturbations to identify subgraphs that are responsiblefor the occurrence of the final output of GNNs. However, such approaches lackfiner-grained, layer-wise analysis of how intermediate representationscontribute to the final result, capabilities that are crucial for modeldiagnosis and architecture optimization. This paper introduces SliceGX, a novelGNN explanation approach that generates explanations at specific GNN layers ina progressive manner. Given a GNN M, a set of selected intermediate layers, anda target layer, SliceGX automatically segments M into layer blocks ("modelslice") and discovers high-quality explanatory subgraphs in each layer blockthat clarifies the occurrence of output of M at the targeted layer. Althoughfinding such layer-wise explanations is computationally challenging, we developefficient algorithms and optimization techniques that incrementally generateand maintain these subgraphs with provable approximation guarantees.Additionally, SliceGX offers a SPARQL-like query interface, providingdeclarative access and search capacities for the generated explanations.Through experiments on large real-world graphs and representative GNNarchitectures, we verify the effectiveness and efficiency of SliceGX, andillustrate its practical utility in supporting model debugging.</description>
      <author>example@mail.com (Tingting Zhu, Tingyang Chen, Yinghui Wu, Arijit Khan, Xiangyu Ke)</author>
      <guid isPermaLink="false">2506.17977v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
  <item>
      <title>Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test</title>
      <link>http://arxiv.org/abs/2506.21551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了神经网络训练中的Grokking现象，即在训练损失收敛后测试性能仍然持续提升的现象。作者首次在7B大型语言模型OLMoE的预训练过程中对Grokking进行了研究，并验证了Grokking在大规模基础模型的预训练中仍然发生，尽管不同数据可能异步进入Grokking阶段。&lt;h4&gt;背景&lt;/h4&gt;Grokking现象在神经网络训练中被观察到，但其机制和泛化能力等新兴能力仍然神秘。以往的研究通常在数千个epoch上在小模型上进行训练，而本文首次在大型语言模型OLMoE的预训练过程中研究Grokking。&lt;h4&gt;目的&lt;/h4&gt;研究Grokking现象在大型语言模型预训练中的发生情况，并探究其背后的机制。&lt;h4&gt;方法&lt;/h4&gt;作者计算了训练损失，并在包括数学推理、代码生成和常识/特定领域知识检索在内的多种基准任务上评估了泛化能力。他们通过研究LLM内部动态，揭示了Grokking中“泛化能力的出现”的奥秘，并开发了两个新的指标来量化路径距离和单个路径的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在Grokking过程中，训练样本的路径（即层间的专家选择）从随机、实例特定的转变为更有结构和可共享的。此外，尽管损失已经收敛，样本路径的复杂性仍然降低。这些发现表明了从记忆到泛化的转换，为延迟泛化提供了机制上的解释。&lt;h4&gt;结论&lt;/h4&gt;本文的研究表明，Grokking现象在大规模基础模型的预训练中仍然发生，且路径结构化程度的提高可以减少模型复杂性和提高泛化界限。作者提出的两个新指标可以有效地预测下游任务上的泛化改进，为预训练提供了监控泛化性能的工具。&lt;h4&gt;翻译&lt;/h4&gt;Grokking, i.e., test performance keeps improving long after training loss converged, has been recently witnessed in neural network training, making the mechanism of generalization and other emerging capabilities such as reasoning mysterious. While prior studies usually train small models on a few toy or highly-specific tasks for thousands of epochs, we conduct the first study of grokking on checkpoints during one-pass pretraining of a 7B large language model (LLM), i.e., OLMoE. We compute the training loss and evaluate generalization on diverse benchmark tasks, including math reasoning, code generation, and commonsense/domain-specific knowledge retrieval tasks. Our study, for the first time, verifies that grokking still happens in the pretraining of large-scale foundation models, though different data may enter grokking stages asynchronously. We further demystify grokking's 'emergence of generalization' by investigating LLM internal dynamics. Specifically, we find that training samples' pathways (i.e., expert choices across layers) evolve from random, instance-specific to more structured and shareable between samples during grokking. Also, the complexity of a sample's pathway reduces despite the converged loss. These indicate a memorization-to-generalization conversion, providing a mechanistic explanation of delayed generalization. In the study, we develop two novel metrics to quantify pathway distance and the complexity of a single pathway. We show their ability to predict the generalization improvement on diverse downstream tasks. They are efficient, simple to compute and solely dependent on training data. Hence, they have practical value for pretraining, enabling us to monitor the generalization performance without finetuning and test. Theoretically, we show that more structured pathways reduce model complexity and improve the generalization bound.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grokking, i.e., test performance keeps improving long after training lossconverged, has been recently witnessed in neural network training, making themechanism of generalization and other emerging capabilities such as reasoningmysterious. While prior studies usually train small models on a few toy orhighly-specific tasks for thousands of epochs, we conduct the first study ofgrokking on checkpoints during one-pass pretraining of a 7B large languagemodel (LLM), i.e., OLMoE. We compute the training loss and evaluategeneralization on diverse benchmark tasks, including math reasoning, codegeneration, and commonsense/domain-specific knowledge retrieval tasks.  Our study, for the first time, verifies that grokking still happens in thepretraining of large-scale foundation models, though different data may entergrokking stages asynchronously. We further demystify grokking's "emergence ofgeneralization" by investigating LLM internal dynamics. Specifically, we findthat training samples' pathways (i.e., expert choices across layers) evolvefrom random, instance-specific to more structured and shareable between samplesduring grokking. Also, the complexity of a sample's pathway reduces despite theconverged loss. These indicate a memorization-to-generalization conversion,providing a mechanistic explanation of delayed generalization. In the study, wedevelop two novel metrics to quantify pathway distance and the complexity of asingle pathway. We show their ability to predict the generalization improvementon diverse downstream tasks. They are efficient, simple to compute and solelydependent on training data. Hence, they have practical value for pretraining,enabling us to monitor the generalization performance without finetuning andtest. Theoretically, we show that more structured pathways reduce modelcomplexity and improve the generalization bound.</description>
      <author>example@mail.com (Ziyue Li, Chenrui Fan, Tianyi Zhou)</author>
      <guid isPermaLink="false">2506.21551v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>SAM4D: Segment Anything in Camera and LiDAR Streams</title>
      <link>http://arxiv.org/abs/2506.21547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV2025, Project Page: https://SAM4D-Project.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SAM4D的多模态和时序基础模型，用于在相机和激光雷达流之间进行可提示的分割。&lt;h4&gt;背景&lt;/h4&gt;SAM4D模型旨在解决自动驾驶场景中动态变化时的分割问题。&lt;h4&gt;目的&lt;/h4&gt;设计SAM4D模型，以实现不同传感器数据的高效融合和分割。&lt;h4&gt;方法&lt;/h4&gt;1. 引入统一的多元模态位置编码（UMPE）来对齐相机和激光雷达特征；2. 提出运动感知跨模态记忆注意力（MCMA）以增强时间一致性和长期特征检索；3. 开发一个多模态自动化数据引擎，结合视频掩码、时空四维重建和跨模态掩码融合；4. 生成比人工标注快得多速度的相机-激光雷达对齐的伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;SAM4D模型在Waymo-4DSeg数据集上的实验表明，它具有强大的跨模态分割能力，并且在数据标注方面具有巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;SAM4D模型为自动驾驶场景中的动态变化提供了有效的解决方案，并有望提高数据标注的效率。&lt;h4&gt;翻译&lt;/h4&gt;We present SAM4D, a multi-modal and temporal foundation model designed for promptable segmentation across camera and LiDAR streams. Unified Multi-modal Positional Encoding (UMPE) is introduced to align camera and LiDAR features in a shared 3D space, enabling seamless cross-modal prompting and interaction. Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA), which leverages ego-motion compensation to enhance temporal consistency and long-horizon feature retrieval, ensuring robust segmentation across dynamically changing autonomous driving scenes. To avoid annotation bottlenecks, we develop a multi-modal automated data engine that synergizes VFM-driven video masklets, spatiotemporal 4D reconstruction, and cross-modal masklet fusion. This framework generates camera-LiDAR aligned pseudo-labels at a speed orders of magnitude faster than human annotation while preserving VFM-derived semantic fidelity in point cloud representations. We conduct extensive experiments on the constructed Waymo-4DSeg, which demonstrate the powerful cross-modalsegmentation ability and great potential in data annotation of proposed SAM4D.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SAM4D, a multi-modal and temporal foundation model designed forpromptable segmentation across camera and LiDAR streams. Unified Multi-modalPositional Encoding (UMPE) is introduced to align camera and LiDAR features ina shared 3D space, enabling seamless cross-modal prompting and interaction.Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA),which leverages ego-motion compensation to enhance temporal consistency andlong-horizon feature retrieval, ensuring robust segmentation across dynamicallychanging autonomous driving scenes. To avoid annotation bottlenecks, we developa multi-modal automated data engine that synergizes VFM-driven video masklets,spatiotemporal 4D reconstruction, and cross-modal masklet fusion. Thisframework generates camera-LiDAR aligned pseudo-labels at a speed orders ofmagnitude faster than human annotation while preserving VFM-derived semanticfidelity in point cloud representations. We conduct extensive experiments onthe constructed Waymo-4DSeg, which demonstrate the powerful cross-modalsegmentation ability and great potential in data annotation of proposed SAM4D.</description>
      <author>example@mail.com (Jianyun Xu, Song Wang, Ziqian Ni, Chunyong Hu, Sheng Yang, Jianke Zhu, Qiang Li)</author>
      <guid isPermaLink="false">2506.21547v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StruMamba3D是一种新的自监督点云表示学习方法，通过解决Mamba方法在处理3D点云时的问题，提升了空间状态模型（SSM）的性能。&lt;h4&gt;背景&lt;/h4&gt;Mamba方法在点云表示学习中表现出色，但存在破坏3D点云邻接关系和无法保留长序列记忆的问题。&lt;h4&gt;目的&lt;/h4&gt;提出StruMamba3D以解决Mamba方法在处理3D点云时的局限性。&lt;h4&gt;方法&lt;/h4&gt;StruMamba3D通过设计空间状态和使用它们作为代理来保持点之间的空间依赖关系；增强SSM的状态更新策略并引入轻量级卷积以促进空间状态之间的交互；以及通过引入序列长度自适应策略来降低预训练Mamba模型对输入长度的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，StruMamba3D在四个下游任务中表现出优越的性能，并在ModelNet40上达到95.1%的准确率，在ScanObjectNN最具挑战性的分割上达到92.75%的准确率。&lt;h4&gt;结论&lt;/h4&gt;StruMamba3D是一种有效的点云表示学习方法，能够显著提升基于SSM的点云处理性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Mamba-based methods have demonstrated impressive performance inpoint cloud representation learning by leveraging State Space Model (SSM) withthe efficient context modeling ability and linear complexity. However, thesemethods still face two key issues that limit the potential of SSM: Destroyingthe adjacency of 3D points during SSM processing and failing to retainlong-sequence memory as the input length increases in downstream tasks. Toaddress these issues, we propose StruMamba3D, a novel paradigm forself-supervised point cloud representation learning. It enjoys several merits.First, we design spatial states and use them as proxies to preserve spatialdependencies among points. Second, we enhance the SSM with a state-wise updatestrategy and incorporate a lightweight convolution to facilitate interactionsbetween spatial states for efficient structure modeling. Third, our methodreduces the sensitivity of pre-trained Mamba-based models to varying inputlengths by introducing a sequence length-adaptive strategy. Experimentalresults across four downstream tasks showcase the superior performance of ourmethod. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40and 92.75% accuracy on the most challenging split of ScanObjectNN withoutvoting strategy.</description>
      <author>example@mail.com (Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21541v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation</title>
      <link>http://arxiv.org/abs/2506.21237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DiMPLe（Disentangled Multi-Modal Prompt Learning）是一种新的方法，用于在多模态学习中分解视觉和语言模态中的不变特征和虚假特征。&lt;h4&gt;背景&lt;/h4&gt;视觉数据中的虚假相关性常常阻碍了出分布（OOD）性能。&lt;h4&gt;目的&lt;/h4&gt;提高多模态学习中对新颖类别的泛化能力和对分布变化的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;DiMPLe结合了三个关键目标：（1）最小化不变特征和虚假特征之间的互信息，（2）对虚假特征进行正则化，（3）对不变特征进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在11个不同的数据集上平均，DiMPLe在CoOp-OOD方法之上表现出更优的性能，并在基础类别准确率上提高了15.27，在新颖类别准确率上提高了44.31。&lt;h4&gt;结论&lt;/h4&gt;DiMPLe通过分解特征，显著提升了多模态学习的性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DiMPLe (Disentangled Multi-Modal Prompt Learning), a novelapproach to disentangle invariant and spurious features across vision andlanguage modalities in multi-modal learning. Spurious correlations in visualdata often hinder out-of-distribution (OOD) performance. Unlike prior methodsfocusing solely on image features, DiMPLe disentangles features within andacross modalities while maintaining consistent alignment, enabling bettergeneralization to novel classes and robustness to distribution shifts. Ourmethod combines three key objectives: (1) mutual information minimizationbetween invariant and spurious features, (2) spurious feature regularization,and (3) contrastive learning on invariant features. Extensive experimentsdemonstrate DiMPLe demonstrates superior performance compared to CoOp-OOD, whenaveraged across 11 diverse datasets, and achieves absolute gains of 15.27 inbase class accuracy and 44.31 in novel class accuracy.</description>
      <author>example@mail.com (Umaima Rahman, Mohammad Yaqub, Dwarikanath Mahapatra)</author>
      <guid isPermaLink="false">2506.21237v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection</title>
      <link>http://arxiv.org/abs/2506.21364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无检测方法，通过Channel Adaptive Adjustment Module (CAA)和Global Optimal Selection Module (GOS)模块，解决了图像和点云特征匹配中的通道注意力差异和冗余对应问题，实现了图像到点云的高精度注册。&lt;h4&gt;背景&lt;/h4&gt;检测-free方法通常采用由粗到细的流程，提取图像和点云特征进行局部匹配和密集像素到点的对应关系细化。然而，图像和点云之间的特征通道注意力差异可能导致匹配结果退化，最终影响注册精度。&lt;h4&gt;目的&lt;/h4&gt;为了解决特征通道注意力差异和场景中相似结构导致的冗余对应问题，提高图像到点云注册的精度。&lt;h4&gt;方法&lt;/h4&gt;提出了Channel Adaptive Adjustment Module (CAA)模块来增强同模态特征并抑制跨模态敏感性，以及Global Optimal Selection Module (GOS)模块用全局优化代替局部选择。&lt;h4&gt;主要发现&lt;/h4&gt;在RGB-D Scenes V2和7-Scenes数据集上的实验表明，该方法在图像到点云注册方面取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过CAA和GOS模块提高了图像到点云注册的精度，在相关任务中具有优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;Detection-free methods typically follow a coarse-to-fine pipeline, extracting image and point cloud features for patch-level matching and refining dense pixel-to-point correspondences. However, differences in feature channel attention between images and point clouds may lead to degraded matching results, ultimately impairing registration accuracy. Furthermore, similar structures in the scene could lead to redundant correspondences in cross-modal matching. To address these issues, we propose Channel Adaptive Adjustment Module (CAA) and Global Optimal Selection Module (GOS). CAA enhances intra-modal features and suppresses cross-modal sensitivity, while GOS replaces local selection with global optimization. Experiments on RGB-D Scenes V2 and 7-Scenes demonstrate the superiority of our method, achieving state-of-the-art performance in image-to-point cloud registration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detection-free methods typically follow a coarse-to-fine pipeline, extractingimage and point cloud features for patch-level matching and refining densepixel-to-point correspondences. However, differences in feature channelattention between images and point clouds may lead to degraded matchingresults, ultimately impairing registration accuracy. Furthermore, similarstructures in the scene could lead to redundant correspondences in cross-modalmatching. To address these issues, we propose Channel Adaptive AdjustmentModule (CAA) and Global Optimal Selection Module (GOS). CAA enhancesintra-modal features and suppresses cross-modal sensitivity, while GOS replaceslocal selection with global optimization. Experiments on RGB-D Scenes V2 and7-Scenes demonstrate the superiority of our method, achieving state-of-the-artperformance in image-to-point cloud registration.</description>
      <author>example@mail.com (Zhixin Cheng, Jiacheng Deng, Xinjun Li, Xiaotian Yin, Bohao Liao, Baoqun Yin, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21364v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Global and Local Entailment Learning for Natural World Imagery</title>
      <link>http://arxiv.org/abs/2506.21476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Radial Cross-Modal Embeddings (RCME)的框架，用于显式建模具有传递性质的知识，以解决视觉-语言模型中数据层次结构学习的问题。&lt;h4&gt;背景&lt;/h4&gt;现有工作尝试通过蕴含学习来解决这个问题，但未能显式地建模蕴含的传递性质，这在表示空间中建立了顺序和语义之间的关系。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够优化视觉-语言模型中概念部分顺序的框架，并构建一个能够表示生命树中层次结构的视觉-语言基础模型。&lt;h4&gt;方法&lt;/h4&gt;引入了RCME框架，并通过该框架开发了一个能够处理层次分类和检索任务的视觉-语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;在层次物种分类和检索任务上的实验表明，与现有最先进模型相比，本文提出的模型表现更优。&lt;h4&gt;结论&lt;/h4&gt;本文提出的RCME框架和模型为视觉-语言模型中的层次结构学习提供了有效的解决方案，并已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在视觉-语言模型中学习数据的层次结构是一个重大的挑战。先前的工作通过采用蕴含学习来尝试解决这个问题。然而，这些方法未能显式地建模蕴含的传递性质，这在本表示空间中建立了顺序和语义之间的关系。在本工作中，我们引入了Radial Cross-Modal Embeddings (RCME)，这是一个能够显式建模传递性质蕴含的框架。我们提出的框架优化了视觉-语言模型中概念的部分顺序。通过利用我们的框架，我们开发了一个能够表示生命树中层次结构的分层视觉-语言基础模型。我们在层次物种分类和检索任务上的实验证明了与现有最先进模型相比，我们模型性能的提升。我们的代码和模型已开源，请访问https://vishu26.github.io/RCME/index.html。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning the hierarchical structure of data in vision-language models is asignificant challenge. Previous works have attempted to address this challengeby employing entailment learning. However, these approaches fail to model thetransitive nature of entailment explicitly, which establishes the relationshipbetween order and semantics within a representation space. In this work, weintroduce Radial Cross-Modal Embeddings (RCME), a framework that enables theexplicit modeling of transitivity-enforced entailment. Our proposed frameworkoptimizes for the partial order of concepts within vision-language models. Byleveraging our framework, we develop a hierarchical vision-language foundationmodel capable of representing the hierarchy in the Tree of Life. Ourexperiments on hierarchical species classification and hierarchical retrievaltasks demonstrate the enhanced performance of our models compared to theexisting state-of-the-art models. Our code and models are open-sourced athttps://vishu26.github.io/RCME/index.html.</description>
      <author>example@mail.com (Srikumar Sastry, Aayush Dhakal, Eric Xing, Subash Khanal, Nathan Jacobs)</author>
      <guid isPermaLink="false">2506.21476v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>TopK Language Models</title>
      <link>http://arxiv.org/abs/2506.21468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TopK语言模型（TopK LMs），通过在Transformer架构中加入TopK激活函数，解决了稀疏自编码器（SAEs）在解释Transformer语言模型激活空间时的局限性。&lt;h4&gt;背景&lt;/h4&gt;稀疏自编码器（SAEs）在分析Transformer语言模型的激活空间方面发挥了重要作用，但它们存在一些缺陷，如训练后期的局限性、特征稳定性不足等问题。&lt;h4&gt;目的&lt;/h4&gt;提出TopK LMs，旨在解决SAEs的局限性，提高模型的可解释性和可控性。&lt;h4&gt;方法&lt;/h4&gt;在Transformer架构中引入TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征，从而实现无需后训练的解释能力。&lt;h4&gt;主要发现&lt;/h4&gt;TopK LMs在模型大小、计算效率和可解释性之间提供了良好的平衡，并且能够通过神经元干预成功引导模型学习，同时便于分析神经元在不同检查点和层上的形成过程。&lt;h4&gt;结论&lt;/h4&gt;TopK LMs是理解和研究语言模型如何学习和表示概念的有效工具，将显著推进模型可解释性和可控性的未来研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：稀疏自编码器（SAEs）已成为分析Transformer语言模型（LMs）激活空间的重要工具。然而，SAEs存在一些缺点，这些缺点降低了它们的效用和内部有效性。由于SAEs是后期训练的，因此不清楚未能发现某个概念是SAE本身的失败，还是由于底层LM没有表示这个概念。这个问题由于训练条件和架构选择的影响而加剧，这些因素影响着SAE学习的特征。在追踪LM在训练期间学习概念的过程中，特征的不稳定性也使得难以在不同检查点之间比较SAEs的特征。为了解决这些限制，我们提出了一种对Transformer架构的修改，该修改在选定的层中引入了TopK激活函数，使得模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了后期训练的需要，同时提供了与SAEs相当的解释能力。由此产生的TopK LMs在模型大小、计算效率和可解释性之间提供了有利的权衡。尽管这种架构改变很简单，但TopK LMs在保持原有能力的同时，提供了稳健的可解释性收益。我们的实验表明，TopK LMs学习的稀疏表示可以通过有针对性的神经元干预来成功引导，并促进对神经元形成过程的详细分析，这些特点使TopK LMs成为理解语言模型如何学习和表示概念的有效工具，我们相信这将显著推进模型可解释性和可控性的未来研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse autoencoders (SAEs) have become an important tool for analyzing andinterpreting the activation space of transformer-based language models (LMs).However, SAEs suffer several shortcomings that diminish their utility andinternal validity. Since SAEs are trained post-hoc, it is unclear if thefailure to discover a particular concept is a failure on the SAE's side or dueto the underlying LM not representing this concept. This problem is exacerbatedby training conditions and architecture choices affecting which features an SAElearns. When tracing how LMs learn concepts during training, the lack offeature stability also makes it difficult to compare SAEs features acrossdifferent checkpoints. To address these limitations, we introduce amodification to the transformer architecture that incorporates a TopKactivation function at chosen layers, making the model's hidden statesequivalent to the latent features of a TopK SAE. This approach eliminates theneed for post-hoc training while providing interpretability comparable to SAEs.The resulting TopK LMs offer a favorable trade-off between model size,computational efficiency, and interpretability. Despite this simplearchitectural change, TopK LMs maintain their original capabilities whileproviding robust interpretability benefits. Our experiments demonstrate thatthe sparse representations learned by TopK LMs enable successful steeringthrough targeted neuron interventions and facilitate detailed analysis ofneuron formation processes across checkpoints and layers. These features makeTopK LMs stable and reliable tools for understanding how language models learnand represent concepts, which we believe will significantly advance futureresearch on model interpretability and controllability.</description>
      <author>example@mail.com (Ryosuke Takahashi, Tatsuro Inaba, Kentaro Inui, Benjamin Heinzerling)</author>
      <guid isPermaLink="false">2506.21468v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations</title>
      <link>http://arxiv.org/abs/2506.21357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoPa-SG的合成场景图数据集，旨在解决场景图数据不准确的问题，并引入了参数关系和原型关系两个新概念，以提升场景图生成模型的性能和下游应用的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的2D场景图在场景理解方面提供了结构化和可解释的框架，但缺乏准确的数据。&lt;h4&gt;目的&lt;/h4&gt;克服数据瓶颈，提升场景图生成模型的准确性和下游应用的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了CoPa-SG数据集，该数据集具有高度精确的地面实况和详尽的对象关系标注。同时，引入了参数关系和原型关系两个新概念。&lt;h4&gt;主要发现&lt;/h4&gt;CoPa-SG数据集能够帮助比较不同场景图生成模型的性能，新引入的关系类型可以增强下游应用中的规划和推理能力。&lt;h4&gt;结论&lt;/h4&gt;CoPa-SG数据集和新的关系类型有助于提升场景图生成模型的性能和下游应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 2D scene graphs provide a structural and explainable framework for sceneunderstanding. However, current work still struggles with the lack of accuratescene graph data. To overcome this data bottleneck, we present CoPa-SG, asynthetic scene graph dataset with highly precise ground truth and exhaustiverelation annotations between all objects. Moreover, we introduce parametric andproto-relations, two new fundamental concepts for scene graphs. The formerprovides a much more fine-grained representation than its traditionalcounterpart by enriching relations with additional parameters such as angles ordistances. The latter encodes hypothetical relations in a scene graph anddescribes how relations would form if new objects are placed in the scene.Using CoPa-SG, we compare the performance of various scene graph generationmodels. We demonstrate how our new relation types can be integrated indownstream applications to enhance planning and reasoning capabilities.</description>
      <author>example@mail.com (Julian Lorenz, Mrunmai Phatak, Robin Schön, Katja Ludwig, Nico Hörmann, Annemarie Friedrich, Rainer Lienhart)</author>
      <guid isPermaLink="false">2506.21357v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing</title>
      <link>http://arxiv.org/abs/2506.21448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ThinkSound是一种利用思维链推理的框架，旨在通过逐步交互式的方式生成和编辑视频音频，以实现高保真度的音频输出。&lt;h4&gt;背景&lt;/h4&gt;尽管端到端视频到音频生成技术得到了显著提升，但捕捉视觉内容细微差别的真实音频仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成高保真音频的框架，该音频能够真实地捕捉视觉内容的细微差别。&lt;h4&gt;方法&lt;/h4&gt;ThinkSound将音频生成过程分解为三个互补阶段：基础声音效果生成、基于对象的交互式精细调整和基于自然语言指令的定向编辑。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ThinkSound在视频到音频生成方面达到了最先进的性能，并在Movie Gen Audio基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;ThinkSound框架通过其独特的思维链推理和音频生成方法，为视频音频生成领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, such generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present ThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce AudioCoT, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis. Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio benchmark. The demo page is available at https://ThinkSound-Demo.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While end-to-end video-to-audio generation has greatly improved, producinghigh-fidelity audio that authentically captures the nuances of visual contentremains challenging. Like professionals in the creative industries, suchgeneration requires sophisticated reasoning about items such as visualdynamics, acoustic environments, and temporal relationships. We present\textbf{ThinkSound}, a novel framework that leverages Chain-of-Thought (CoT)reasoning to enable stepwise, interactive audio generation and editing forvideos. Our approach decomposes the process into three complementary stages:foundational foley generation that creates semantically coherent soundscapes,interactive object-centric refinement through precise user interactions, andtargeted editing guided by natural language instructions. At each stage, amultimodal large language model generates contextually aligned CoT reasoningthat guides a unified audio foundation model. Furthermore, we introduce\textbf{AudioCoT}, a comprehensive dataset with structured reasoningannotations that establishes connections between visual content, textualdescriptions, and sound synthesis. Experiments demonstrate that ThinkSoundachieves state-of-the-art performance in video-to-audio generation across bothaudio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audiobenchmark. The demo page is available at https://ThinkSound-Demo.github.io.</description>
      <author>example@mail.com (Huadai Liu, Jialei Wang, Kaicheng Luo, Wen Wang, Qian Chen, Zhou Zhao, Wei Xue)</author>
      <guid isPermaLink="false">2506.21448v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>ACTLLM: Action Consistency Tuned Large Language Model</title>
      <link>http://arxiv.org/abs/2506.21250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ACTLLM（动作一致性调整大型语言模型）的新方法，用于动态环境中的机器人操作。&lt;h4&gt;背景&lt;/h4&gt;传统的基于视觉的系统在学习和执行任务以及空间推理方面往往表现不佳，这限制了它们在动态环境中的适应性。&lt;h4&gt;目的&lt;/h4&gt;ACTLLM通过利用语言来构建结构化场景描述符，通过灵活的语言指令提供统一的空间理解和任务性能接口，从而解决这些挑战。&lt;h4&gt;方法&lt;/h4&gt;ACTLLM引入了一种新的动作一致性约束，将视觉感知与对应动作相一致，从而增强可操作视觉表示的学习。此外，将操作任务的马尔可夫决策过程重新构造成多轮视觉对话框架。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法能够通过任务执行的历史记录增强上下文相关性，对长期任务执行进行建模。在评估中，ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;ACTLLM在动态环境中表现优异，为机器人操作提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces ACTLLM (Action Consistency Tuned Large Language Model),a novel approach for robot manipulation in dynamic environments. Traditionalvision-based systems often struggle to learn visual representations that excelin both task execution and spatial reasoning, thereby limiting theiradaptability in dynamic environments. ACTLLM addresses these challenges byharnessing language to craft structured scene descriptors, providing a uniforminterface for both spatial understanding and task performance through flexiblelanguage instructions. Moreover, we introduce a novel action consistencyconstraint that aligns visual perception with corresponding actions, therebyenhancing the learning of actionable visual representations. Additionally, wehave reformulated the Markov decision process for manipulation tasks into amulti-turn visual dialogue framework. This approach enables the modeling oflong-term task execution with enhanced contextual relevance derived from thehistory of task execution. During our evaluation, ACTLLM excels in diversescenarios, proving its effectiveness on challenging vision-based robotmanipulation tasks.</description>
      <author>example@mail.com (Jing Bi, Lianggong Bruce Wen, Zhang Liu, Chenliang Xu)</author>
      <guid isPermaLink="false">2506.21250v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Text2Cypher Across Languages: Evaluating Foundational Models Beyond English</title>
      <link>http://arxiv.org/abs/2506.21445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在多种语言上，基础大型语言模型在Text2Cypher任务中的性能，并评估了将任务提示翻译成西班牙语和土耳其语的影响。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型在自然语言接口方面取得了进展，如Text2SQL、Text2SPARQL和Text2Cypher，这些接口提高了数据库的可访问性。然而，大多数研究仅关注英语，在其他语言上的评估有限。&lt;h4&gt;目的&lt;/h4&gt;研究不同语言基础大型语言模型在Text2Cypher任务上的性能，并评估将任务提示翻译成西班牙语和土耳其语的影响。&lt;h4&gt;方法&lt;/h4&gt;创建并发布了一个多语言测试集，将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，以实现公平的双语比较。使用标准化的提示和指标评估多个基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示了一致的性能模式：英语表现最佳，其次是西班牙语，土耳其语表现最差。这归因于训练数据可用性和语言特征的差异。此外，将任务提示翻译成西班牙语和土耳其语对评估指标的影响很小。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了在多语言查询生成中需要更多包容性的评估和发展。未来的工作包括模式本地化和跨多种语言的微调。&lt;h4&gt;翻译&lt;/h4&gt;通过将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，创建并发布了一个多语言测试集，以实现公平的双语比较。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models have enabled natural languageinterfaces that translate user questions into database queries, such asText2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance databaseaccessibility, most research today focuses solely on English, with limitedevaluation in other languages. This paper investigates the performance offoundational LLMs on the Text2Cypher task across multiple languages. We createand release a multilingual test set by translating English questions intoSpanish and Turkish while preserving the original Cypher queries, enabling faircross-lingual comparison. We evaluate multiple foundational models usingstandardized prompts and metrics. Our results show a consistent performancepattern: highest on English, then Spanish, and lowest on Turkish. We attributethis to differences in training data availability and linguisticcharacteristics. Additionally, we explore the impact of translating taskprompts into Spanish and Turkish. Results show little to no change inevaluation metrics, suggesting prompt translation has minor impact. Ourfindings highlight the need for more inclusive evaluation and development inmultilingual query generation. Future work includes schema localization andfine-tuning across diverse languages.</description>
      <author>example@mail.com (Makbule Gulcin Ozsoy, William Tai)</author>
      <guid isPermaLink="false">2506.21445v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation</title>
      <link>http://arxiv.org/abs/2506.21444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不典型有丝分裂的自动分类问题，通过深度学习方法在乳腺癌数据集上进行了基准测试，并提出了新的数据集和模型调整方法。&lt;h4&gt;背景&lt;/h4&gt;不典型有丝分裂是肿瘤恶性的独立预后相关标志物，但其识别因低发病率、形态学差异、病理学家间评分不一致和数据集类别不平衡而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;比较不同深度学习方法在自动分类不典型有丝分裂图像方面的性能，并提出新的数据集和模型调整技术。&lt;h4&gt;方法&lt;/h4&gt;基于AMi-Br数据集，比较了基准模型、带有线性探测的基础模型和通过低秩自适应（LoRA）微调的基础模型。此外，引入了两个新的数据集：AtNorM-Br和AtNorM-MD。&lt;h4&gt;主要发现&lt;/h4&gt;在AMi-Br、AtNorm-Br和AtNorM-MD数据集上，分别达到了平均平衡准确率0.8135、0.7696和0.7705，其中基于LoRA的Virchow-line基础模型调整效果最佳。&lt;h4&gt;结论&lt;/h4&gt;尽管不典型有丝分裂分类是一个具有挑战性的问题，但通过转移学习和模型微调技术的最新进展可以有效地解决。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不典型有丝分裂标志着细胞分裂过程的偏差，可以成为肿瘤恶性的独立预后相关标志物。然而，由于其低发病率、与正常有丝分裂的细微形态学差异、病理学家之间评分的不一致以及数据集类别不平衡，其识别仍然具有挑战性。基于乳腺癌不典型有丝分裂数据集（AMi-Br），本研究提出了一套全面基准，比较了深度学习方法在自动分类不典型有丝分裂图像（AMF）方面的性能，包括基线模型、带有线性探测的基础模型以及通过低秩自适应（LoRA）微调的基础模型。为了进行严格的评估，我们进一步引入了两个新的留出数据集——AtNorM-Br，它是来自TCGA乳腺癌队列的有丝分裂数据集，以及AtNorM-MD，它是来自MIDOG++训练集的多领域有丝分裂数据集。我们发现，在域内AMi-Br和域外AtNorm-Br以及AtNorM-MD数据集上，平均平衡准确率分别达到了0.8135、0.7696和0.7705，其中基于LoRA的Virchow-line基础模型调整效果尤为显著。我们的研究表明，尽管不典型有丝分裂分类是一个具有挑战性的问题，但可以通过使用最近在迁移学习和模型微调技术方面的进展来有效解决。我们将在本文中使用的所有代码和数据都可在以下GitHub仓库中找到：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Atypical mitoses mark a deviation in the cell division process that can be anindependent prognostically relevant marker for tumor malignancy. However, theiridentification remains challenging due to low prevalence, at times subtlemorphological differences from normal mitoses, low inter-rater agreement amongpathologists, and class imbalance in datasets. Building on the Atypical Mitosisdataset for Breast Cancer (AMi-Br), this study presents a comprehensivebenchmark comparing deep learning approaches for automated atypical mitoticfigure (AMF) classification, including baseline models, foundation models withlinear probing, and foundation models fine-tuned with low-rank adaptation(LoRA). For rigorous evaluation, we further introduce two new hold-out AMFdatasets - AtNorM-Br, a dataset of mitoses from the The TCGA breast cancercohort, and AtNorM-MD, a multi-domain dataset of mitoses from the MIDOG++training set. We found average balanced accuracy values of up to 0.8135,0.7696, and 0.7705 on the in-domain AMi-Br and the out-of-domain AtNorm-Br andAtNorM-MD datasets, respectively, with the results being particularly good forLoRA-based adaptation of the Virchow-line of foundation models. Our work showsthat atypical mitosis classification, while being a challenging problem, can beeffectively addressed through the use of recent advances in transfer learningand model fine-tuning techniques. We make available all code and data used inthis paper in this github repository:https://github.com/DeepMicroscopy/AMi-Br_Benchmark.</description>
      <author>example@mail.com (Sweta Banerjee, Viktoria Weiss, Taryn A. Donovan, Rutger A. Fick, Thomas Conrad, Jonas Ammeling, Nils Porsche, Robert Klopfleisch, Christopher Kaltenecker, Katharina Breininger, Marc Aubreville, Christof A. Bertram)</author>
      <guid isPermaLink="false">2506.21444v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition</title>
      <link>http://arxiv.org/abs/2506.21165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为TAM的拓扑感知建模框架，用于解决从3D物体形状的点集学习语义表示时遇到的挑战，特别是在模拟到现实（Sim2Real）的领域适应中。&lt;h4&gt;背景&lt;/h4&gt;由于数据采集方法的不同，从3D物体形状的点集学习语义表示面临显著的几何变化。训练数据通常使用点模拟器生成，而测试数据使用不同的3D传感器收集，导致模拟到现实的领域差距，限制了点分类器的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种能够有效减少领域差距并提高适应过程鲁棒性的方法。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法利用全局空间拓扑，通过低级、高频的3D结构来减轻领域差距。此外，通过一个新颖的自监督学习任务来建模局部几何特征之间的拓扑关系。同时，还提出了一种结合跨领域对比学习和自训练的高级自训练策略，以减少噪声伪标签的影响并提高适应过程的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公共Sim2Real基准上的实验结果表明，本文的TAM框架在所有评估任务中均优于最先进的方法，并验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;TAM框架能够有效提高Sim2Real领域适应的泛化能力，为解决领域差距问题提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从3D物体形状的点集学习语义表示通常受到显著几何变化的挑战，这主要由于数据采集方法的不同。通常，训练数据使用点模拟器生成，而测试数据使用不同的3D传感器收集，导致模拟到现实（Sim2Real）的领域差距，限制了点分类器的泛化能力。当前的无监督领域自适应（UDA）技术难以应对这一差距，因为它们通常缺乏鲁棒的、领域无关的描述符，能够捕获全局拓扑信息，从而导致过度拟合到源域有限的语义模式。为了解决这一问题，我们提出了一种新的拓扑感知建模（TAM）框架，用于对象点云上的Sim2Real UDA。我们的方法通过利用全局空间拓扑，通过低级、高频的3D结构来减轻领域差距，并通过一个新颖的自监督学习任务来建模局部几何特征的拓扑关系。此外，我们还提出了一种结合跨领域对比学习和自训练的高级自训练策略，有效地减少了噪声伪标签的影响，并增强了适应过程的鲁棒性。在三个公共Sim2Real基准上的实验结果验证了我们的TAM框架的有效性，显示出在所有评估任务中相对于最先进方法的持续改进。本文的工作源代码将在https://github.com/zou-longkun/TAG.git上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning semantic representations from point sets of 3D object shapes isoften challenged by significant geometric variations, primarily due todifferences in data acquisition methods. Typically, training data is generatedusing point simulators, while testing data is collected with distinct 3Dsensors, leading to a simulation-to-reality (Sim2Real) domain gap that limitsthe generalization ability of point classifiers. Current unsupervised domainadaptation (UDA) techniques struggle with this gap, as they often lack robust,domain-insensitive descriptors capable of capturing global topologicalinformation, resulting in overfitting to the limited semantic patterns of thesource domain. To address this issue, we introduce a novel Topology-AwareModeling (TAM) framework for Sim2Real UDA on object point clouds. Our approachmitigates the domain gap by leveraging global spatial topology, characterizedby low-level, high-frequency 3D structures, and by modeling the topologicalrelations of local geometric features through a novel self-supervised learningtask. Additionally, we propose an advanced self-training strategy that combinescross-domain contrastive learning with self-training, effectively reducing theimpact of noisy pseudo-labels and enhancing the robustness of the adaptationprocess. Experimental results on three public Sim2Real benchmarks validate theeffectiveness of our TAM framework, showing consistent improvements overstate-of-the-art methods across all evaluated tasks. The source code of thiswork will be available at https://github.com/zou-longkun/TAG.git.</description>
      <author>example@mail.com (Longkun Zou, Kangjun Liu, Ke Chen, Kailing Guo, Kui Jia, Yaowei Wang)</author>
      <guid isPermaLink="false">2506.21165v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Rate Reduction Clustering for Human Motion Segmentation</title>
      <link>http://arxiv.org/abs/2506.21249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper is accepted by ICCV 2025. The first two authors are equally  contributed&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Rate Reduction Clustering ($ext{TR}^2ext{C}$) 的新型Human Motion Segmentation (HMS)方法，旨在通过联合学习结构化表示和亲和度来分割视频中的帧序列。&lt;h4&gt;背景&lt;/h4&gt;现有的HMS方法主要基于假设高维时间数据与Union-of-Subspaces (UoS)分布相一致，但在处理具有杂乱背景的复杂人类运动时，这种假设可能不适用。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够有效分割包含复杂人类运动和杂乱背景的视频的方法。&lt;h4&gt;方法&lt;/h4&gt;$ext{TR}^2ext{C}$方法通过学习保持时间一致性和与UoS结构良好对齐的结构化表示来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准HMS数据集上进行的实验表明，$ext{TR}^2ext{C}$方法在不同的特征提取器下均取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;$ext{TR}^2ext{C}$方法为HMS任务提供了一种有效的新方法，能够处理复杂背景下的视频运动分割问题。&lt;h4&gt;翻译&lt;/h4&gt;人类运动分割（HMS）旨在将视频分割成非重叠的人类运动部分，近年来引起了越来越多的研究兴趣。现有的HMS方法主要受子空间聚类方法的主导，这些方法基于高维时间数据与联合子空间（UoS）分布一致的假设。然而，视频捕获的包含杂乱背景的复杂人类运动的帧可能无法很好地与UoS分布对齐。在本文中，我们提出了一种名为时率降低聚类（Temporal Rate Reduction Clustering，$ext{TR}^2ext{C}$）的新型HMS方法，该方法联合学习结构化表示和亲和度以分割视频中的帧序列。具体来说，$ext{TR}^2ext{C}$学习到的结构化表示保持时间一致性并与UoS结构良好对齐，这对于HMS任务是有利的。我们在五个基准HMS数据集上进行了广泛的实验，并使用不同的特征提取器取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Motion Segmentation (HMS), which aims to partition videos intonon-overlapping human motions, has attracted increasing research attentionrecently. Existing approaches for HMS are mainly dominated by subspaceclustering methods, which are grounded on the assumption that high-dimensionaltemporal data align with a Union-of-Subspaces (UoS) distribution. However, theframes in video capturing complex human motions with cluttered backgrounds maynot align well with the UoS distribution. In this paper, we propose a novelapproach for HMS, named Temporal Rate Reduction Clustering($\text{TR}^2\text{C}$), which jointly learns structured representations andaffinity to segment the frame sequences in video. Specifically, the structuredrepresentations learned by $\text{TR}^2\text{C}$ maintain temporally consistentand align well with a UoS structure, which is favorable for the HMS task. Weconduct extensive experiments on five benchmark HMS datasets and achievestate-of-the-art performances with different feature extractors.</description>
      <author>example@mail.com (Xianghan Meng, Zhengyu Tong, Zhiyuan Huang, Chun-Guang Li)</author>
      <guid isPermaLink="false">2506.21249v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Cross-Channel Hierarchical Aggregation for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于视觉的科学基础模型对于推动科学发现和创新具有巨大潜力，但图像的标记和聚合计算密集，现有分布式方法未能完全解决这一挑战。&lt;h4&gt;背景&lt;/h4&gt;视觉基础模型能够从不同来源聚合图像，并使用transformer架构学习时空相关性，但这一过程计算密集。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为D-CHAG的方法，用于处理具有大量通道的图像数据集，旨在提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;D-CHAG方法与任何模型并行策略和视觉transformer架构兼容，并在超光谱成像和天气预报任务上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;D-CHAG方法与张量并行和模型分片结合使用时，在Frontier超级计算机上实现了高达75%的内存使用减少，以及持续吞吐量翻倍，最多可支持1,024个AMD GPU。&lt;h4&gt;结论&lt;/h4&gt;D-CHAG方法显著提高了计算效率，为科学基础模型的应用提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based scientific foundation models hold significant promise foradvancing scientific discovery and innovation. This potential stems from theirability to aggregate images from diverse sources such as varying physicalgroundings or data acquisition systems and to learn spatio-temporalcorrelations using transformer architectures. However, tokenizing andaggregating images can be compute-intensive, a challenge not fully addressed bycurrent distributed methods. In this work, we introduce the DistributedCross-Channel Hierarchical Aggregation (D-CHAG) approach designed for datasetswith a large number of channels across image modalities. Our method iscompatible with any model-parallel strategy and any type of vision transformerarchitecture, significantly improving computational efficiency. We evaluatedD-CHAG on hyperspectral imaging and weather forecasting tasks. When integratedwith tensor parallelism and model sharding, our approach achieved up to a 75%reduction in memory usage and more than doubled sustained throughput on up to1,024 AMD GPUs on the Frontier Supercomputer.</description>
      <author>example@mail.com (Aristeidis Tsaris, Isaac Lyngaas, John Lagregren, Mohamed Wahib, Larry York, Prasanna Balaprakash, Dan Lu, Feiyi Wang, Xiao Wang)</author>
      <guid isPermaLink="false">2506.21411v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation</title>
      <link>http://arxiv.org/abs/2506.21233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对无监督开放词汇语义分割（OVS）的数据质量优化框架，通过构建高质量的参考集和简单相似度检索，显著提升了无监督OVS的性能。&lt;h4&gt;背景&lt;/h4&gt;无监督开放词汇语义分割旨在在不进行昂贵模型微调的情况下，对任意文本类别进行图像分割。&lt;h4&gt;目的&lt;/h4&gt;研究数据质量对无监督OVS性能的影响，并提出一种数据质量导向的框架。&lt;h4&gt;方法&lt;/h4&gt;构建包含良好配对分割文本嵌入的参考集的数据管道，并采用基于相似度的简单检索方法。&lt;h4&gt;主要发现&lt;/h4&gt;高质量参考集对无监督OVS性能有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了数据在无监督OVS中的重要性，并提出的方法在多个基准数据集上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training-free open-vocabulary semantic segmentation (OVS) aims to segmentimages given a set of arbitrary textual categories without costly modelfine-tuning. Existing solutions often explore attention mechanisms ofpre-trained models, such as CLIP, or generate synthetic data and design complexretrieval processes to perform OVS. However, their performance is limited bythe capability of reliant models or the suboptimal quality of reference sets.In this work, we investigate the largely overlooked data quality problem forthis challenging dense scene understanding task, and identify that ahigh-quality reference set can significantly benefit training-free OVS. Withthis observation, we introduce a data-quality-oriented framework, comprising adata pipeline to construct a reference set with well-paired segment-textembeddings and a simple similarity-based retrieval to unveil the essentialeffect of data. Remarkably, extensive evaluations on ten benchmark datasetsdemonstrate that our method outperforms all existing training-free OVSapproaches, highlighting the importance of data-centric design for advancingOVS without training. Our code is available at https://github.com/xiweix/ReME .</description>
      <author>example@mail.com (Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma)</author>
      <guid isPermaLink="false">2506.21233v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification</title>
      <link>http://arxiv.org/abs/2506.21338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于脑电图（EEG）的脑机接口（BCI）技术，旨在帮助运动障碍者平等地参与环境互动。该技术通过引入一种新的图时模型AGTCNet，解决了现有BCI系统在捕捉多通道EEG信号中的时空依赖关系方面的不足。&lt;h4&gt;背景&lt;/h4&gt;BCI技术具有潜力帮助运动障碍者，但其发展面临个体间和随时间变化的神经活动复杂性和可变性的挑战，以及EEG硬件的限制。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效捕捉多通道EEG信号中时空依赖关系的BCI系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为AGTCNet的注意力图时卷积网络，利用EEG电极的拓扑配置作为归纳偏置，并集成了图卷积注意力网络（GCAT）以联合学习表达性的时空EEG表示。&lt;h4&gt;主要发现&lt;/h4&gt;AGTCNet在MI-EEG分类方面显著优于现有方法，实现了最先进的性能，同时具有紧凑的架构。在BCI Competition IVDataset 2a上，AGTCNet在主题无关分类中的移动平均准确率达到66.82%，经过特定主题微调后，准确率提升至82.88%。在EEG Motor Movement/Imagery Dataset上，AGTCNet在4类和2类主题无关分类中的移动平均准确率分别为64.14%和85.22%，在特定主题分类中进一步提高了至72.13%和90.54%。&lt;h4&gt;结论&lt;/h4&gt;AGTCNet是一种有效的BCI系统，具有实用性和可部署性，能够在保持高准确率的同时显著减小模型尺寸和加快推理时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain-computer interface (BCI) technology utilizing electroencephalography(EEG) marks a transformative innovation, empowering motor-impaired individualsto engage with their environment on equal footing. Despite its promisingpotential, developing subject-invariant and session-invariant BCI systemsremains a significant challenge due to the inherent complexity and variabilityof neural activity across individuals and over time, compounded by EEG hardwareconstraints. While prior studies have sought to develop robust BCI systems,existing approaches remain ineffective in capturing the intricatespatiotemporal dependencies within multichannel EEG signals. This studyaddresses this gap by introducing the attentive graph-temporal convolutionalnetwork (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG)classification. Specifically, AGTCNet leverages the topographic configurationof EEG electrodes as an inductive bias and integrates graph convolutionalattention network (GCAT) to jointly learn expressive spatiotemporal EEGrepresentations. The proposed model significantly outperformed existing MI-EEGclassifiers, achieving state-of-the-art performance while utilizing a compactarchitecture, underscoring its effectiveness and practicality for BCIdeployment. With a 49.87% reduction in model size, 64.65% faster inferencetime, and shorter input EEG signal, AGTCNet achieved a moving average accuracyof 66.82% for subject-independent classification on the BCI Competition IVDataset 2a, which further improved to 82.88% when fine-tuned forsubject-specific classification. On the EEG Motor Movement/Imagery Dataset,AGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and2-class subject-independent classifications, respectively, with furtherimprovements to 72.13% and 90.54% for subject-specific classifications.</description>
      <author>example@mail.com (Galvin Brice S. Lim, Brian Godwin S. Lim, Argel A. Bandala, John Anthony C. Jose, Timothy Scott C. Chu, Edwin Sybingco)</author>
      <guid isPermaLink="false">2506.21338v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating GNN Training through Locality-aware Dropout and Merge</title>
      <link>http://arxiv.org/abs/2506.21414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review in TPDS. extend version of DATE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LiGNN的硬件解决方案，通过在邻居聚合过程中应用dropout和merge技术来提高数据局部性，从而加速图神经网络（GNN）的训练。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图学习领域取得了显著成功，但它们的节点之间的高连接性导致了不高效的邻居聚合，产生了大量的不规则和粗粒度的DRAM访问，这对执行平台构成了挑战，并最终降低了性能。&lt;h4&gt;目的&lt;/h4&gt;提高GNN训练的性能，同时减少DRAM的不规则访问。&lt;h4&gt;方法&lt;/h4&gt;LiGNN通过以下方法实现这一目标：1. 引入一个局部感知的特征dropout机制，在邻居聚合过程中有选择性地丢弃节点特征；2. 利用对内存布局和组织（包括关键的对齐约束）的详细知识，在DRAM行级别有策略地合并内存访问。&lt;h4&gt;主要发现&lt;/h4&gt;在0.5的dropout率下，LiGNN比最先进的方法有显著性能提升，实现了1.48~3.02倍的速度提升，减少了34%~55%的DRAM访问，并将DRAM行激活降低了59%~82%，同时保持了模型精度。&lt;h4&gt;结论&lt;/h4&gt;LiGNN通过提高数据局部性，有效提升了GNN训练的性能，同时降低了硬件成本。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have demonstrated significant success in graph learning and are widely adopted across various critical domains. However, their regular connectivity between vertices leads to inefficient neighbor aggregation, resulting in substantial irregular and coarse-grained DRAM accesses. This lack of data locality presents significant challenges for execution platforms, ultimately degrading performance. While previous accelerator designs have leveraged on-chip memory and data access scheduling strategies to address this issue, they still inevitably access features at irregular addresses from DRAM. In this work, we propose LiGNN, a hardware-based solution that improves data locality by applying dropout and merge techniques during neighbor aggregation to accelerate GNN training. Unlike conventional algorithm-level dropout methods that primarily aim to improve accuracy while overlooking hardware costs, LiGNN introduces a locality-aware feature dropout mechanism. This approach selectively drops node features with data locality awareness, effectively reducing irregular DRAM accesses without compromising model accuracy. Moreover, by leveraging detailed knowledge of memory layout and organization-including critical alignment constraints-LiGNN strategically merges memory accesses during neighbor aggregation at the DRAM row level, guided by GNN-level semantics. This optimization significantly improves data locality with minimal additional cost. Under the commonly adopted 0.5 dropout rate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02xs speedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activations by 59%~82%, all while maintaining model accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated significant success in graphlearning and are widely adopted across various critical domains. However, theirregular connectivity between vertices leads to inefficient neighboraggregation, resulting in substantial irregular and coarse-grained DRAMaccesses. This lack of data locality presents significant challenges forexecution platforms, ultimately degrading performance. While previousaccelerator designs have leveraged on-chip memory and data access schedulingstrategies to address this issue, they still inevitably access features atirregular addresses from DRAM. In this work, we propose LiGNN, a hardware-basedsolution that improves data locality by applying dropout and merge techniquesduring neighbor aggregation to accelerate GNN training. Unlike conventionalalgorithm-level dropout methods that primarily aim to improve accuracy whileoverlooking hardware costs, LiGNN introduces a locality-aware feature dropoutmechanism. This approach selectively drops node features with data localityawareness, effectively reducing irregular DRAM accesses without compromisingmodel accuracy. Moreover, by leveraging detailed knowledge of memory layout andorganization-including critical alignment constraints-LiGNN strategicallymerges memory accesses during neighbor aggregation at the DRAM row level,guided by GNN-level semantics. This optimization significantly improves datalocality with minimal additional cost. Under the commonly adopted 0.5 dropoutrate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02xspeedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activationsby 59%~82%, all while maintaining model accuracy.</description>
      <author>example@mail.com (Gongjian Sun, Mingyu Yan, Dengke Han, Runzhen Xue, Duo Wang, Xiaochun Ye, Dongrui Fan)</author>
      <guid isPermaLink="false">2506.21414v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Early Stopping Tabular In-Context Learning</title>
      <link>http://arxiv.org/abs/2506.21387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML Workshop Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的表格式基础模型，通过在上下文中动态停止学习过程来降低推理时间成本，同时保持预测性能。&lt;h4&gt;背景&lt;/h4&gt;表格式基础模型在上下文学习中表现出色，但推理时间成本较高，特别是在大数据集上。&lt;h4&gt;目的&lt;/h4&gt;旨在提高表格式基础模型的推理效率。&lt;h4&gt;方法&lt;/h4&gt;通过在每层Transformer编码器之后动态评估是否停止上下文学习过程，一旦停止，使用预训练的层解码器进行嵌入解码。&lt;h4&gt;主要发现&lt;/h4&gt;在34个小规模分类任务上的实验表明，提前停止上下文学习可以将推理速度提高最多1.3倍，同时对预测性能的影响可以忽略不计；在五个大规模分类任务上的评估显示，速度可以加快最多2.2倍。&lt;h4&gt;结论&lt;/h4&gt;提前退出是一种有效且实用的策略，可以提高表格式上下文学习的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular foundation models have shown strong performance across varioustabular learning tasks via in-context learning, offering robust generalizationwithout any downstream finetuning. However, their inference-time costs remainhigh, particularly for larger datasets. To address this, we proposeearly-stopping the in-context learning process. We achieve this by dynamicallyevaluating whether to stop in-context learning after each Transformer encoderlayer. Once stopped, we decode the embedding using a pre-trained layer-wisedecoder. Experiments across 34 small classification tasks size show that earlystopping in-context learning accelerates inference by up to x1.3 withnegligible degradation in predictive performance. To assess scalability, wefurther evaluate our method on five larger classification tasks, achievingspeedups of up to x2.2. Our results demonstrate the potential of early exitingas an effective and practical strategy for improving the efficiency of tabularin-context learning.</description>
      <author>example@mail.com (Jaris Küken, Lennart Purucker, Frank Hutter)</author>
      <guid isPermaLink="false">2506.21387v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark</title>
      <link>http://arxiv.org/abs/2506.21549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了SiM3D，这是第一个考虑多视角和多模态信息整合的综合3D异常检测和分割（ADS）基准，旨在生成基于体素的异常体积。&lt;h4&gt;背景&lt;/h4&gt;SiM3D专注于制造业中一个高关注场景：单实例异常检测，其中只有单个对象（真实或合成）可用于训练。&lt;h4&gt;目的&lt;/h4&gt;SiM3D旨在解决从合成训练数据泛化到真实测试数据这一挑战。&lt;h4&gt;方法&lt;/h4&gt;SiM3D包括一个使用顶级工业传感器和机器人获取的全新多模态多视角数据集，包含333个实例的8种对象的多视角高分辨率图像（1200万像素）和点云（700万个点），以及每个类型的CAD模型。还提供了异常测试样本的手动标注3D分割GT。为了为所提出的多视角3D ADS任务建立参考基线，我们调整了突出的单视角方法，并使用在异常体积上运行的新颖指标来评估它们的性能。&lt;h4&gt;主要发现&lt;/h4&gt;SiM3D是第一个解决从合成训练数据泛化到真实测试数据挑战的ADS基准。&lt;h4&gt;结论&lt;/h4&gt;SiM3D通过提供综合的多视角和多模态信息，为3D异常检测和分割提供了一个新的基准。&lt;h4&gt;翻译&lt;/h4&gt;We propose SiM3D, the first benchmark considering the integration of multiview and multimodal information for comprehensive 3D anomaly detection and segmentation (ADS), where the task is to produce a voxel-based Anomaly Volume. Moreover, SiM3D focuses on a scenario of high interest in manufacturing: single-instance anomaly detection, where only one object, either real or synthetic, is available for training. In this respect, SiM3D stands out as the first ADS benchmark that addresses the challenge of generalising from synthetic training data to real test data. SiM3D includes a novel multimodal multiview dataset acquired using top-tier industrial sensors and robots. The dataset features multiview high-resolution images (12 Mpx) and point clouds (7M points) for 333 instances of eight types of objects, alongside a CAD model for each type. We also provide manually annotated 3D segmentation GTs for anomalous test samples. To establish reference baselines for the proposed multiview 3D ADStask, we adapt prominent singleview methods and assess their performance using novel metrics that operate on Anomaly Volumes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SiM3D, the first benchmark considering the integration ofmultiview and multimodal information for comprehensive 3D anomaly detection andsegmentation (ADS), where the task is to produce a voxel-based Anomaly Volume.Moreover, SiM3D focuses on a scenario of high interest in manufacturing:single-instance anomaly detection, where only one object, either real orsynthetic, is available for training. In this respect, SiM3D stands out as thefirst ADS benchmark that addresses the challenge of generalising from synthetictraining data to real test data. SiM3D includes a novel multimodal multiviewdataset acquired using top-tier industrial sensors and robots. The datasetfeatures multiview high-resolution images (12 Mpx) and point clouds (7M points)for 333 instances of eight types of objects, alongside a CAD model for eachtype. We also provide manually annotated 3D segmentation GTs for anomalous testsamples. To establish reference baselines for the proposed multiview 3D ADStask, we adapt prominent singleview methods and assess their performance usingnovel metrics that operate on Anomaly Volumes.</description>
      <author>example@mail.com (Alex Costanzino, Pierluigi Zama Ramirez, Luigi Lella, Matteo Ragaglia, Alessandro Oliva, Giuseppe Lisanti, Luigi Di Stefano)</author>
      <guid isPermaLink="false">2506.21549v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching</title>
      <link>http://arxiv.org/abs/2506.21086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PeakNetFP是一种基于频谱峰值的神经音频指纹系统，通过利用传统峰值音频指纹方法中计算的稀疏频谱坐标，实现了高效的音频指纹识别。&lt;h4&gt;背景&lt;/h4&gt;音频指纹识别技术是音频内容识别的重要手段，传统方法基于频谱峰值，但存在效率问题。&lt;h4&gt;目的&lt;/h4&gt;设计PeakNetFP的目的是提高音频指纹识别的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;PeakNetFP采用类似于计算机视觉模型PointNet++的分层点特征提取技术，并使用与NeuralFP类似的对比学习方法进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;PeakNetFP在处理具有挑战性的音频拉伸数据时，性能与NeuralFP相当，且具有更高的效率。它具有更少的参数和更小的输入数据。&lt;h4&gt;结论&lt;/h4&gt;PeakNetFP是一种轻量级且高效的音频指纹识别解决方案，代表了未来音频指纹识别技术的发展方向。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces PeakNetFP, the first neural audio fingerprinting (AFP) system designed specifically around spectral peaks. This novel system is designed to leverage the sparse spectral coordinates typically computed by traditional peak-based AFP methods. PeakNetFP performs hierarchical point feature extraction techniques similar to the computer vision model PointNet++, and is trained using contrastive learning like in the state-of-the-art deep learning AFP, NeuralFP. This combination allows PeakNetFP to outperform conventional AFP systems and achieve comparable performance to NeuralFP when handling challenging time-stretched audio data. In extensive evaluation, PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging from 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages: compared to NeuralFP, it has 100 times fewer parameters and uses 11 times smaller input data. These features make PeakNetFP a lightweight and efficient solution for AFP tasks where time stretching is involved. Overall, this system represents a promising direction for future AFP technologies, as its successfully merges the lightweight nature of peak-based AFP with the adaptability and pattern recognition capabilities of neural network-based approaches, paving the way for more scalable and efficient solutions in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces PeakNetFP, the first neural audio fingerprinting (AFP)system designed specifically around spectral peaks. This novel system isdesigned to leverage the sparse spectral coordinates typically computed bytraditional peak-based AFP methods. PeakNetFP performs hierarchical pointfeature extraction techniques similar to the computer vision model PointNet++,and is trained using contrastive learning like in the state-of-the-art deeplearning AFP, NeuralFP. This combination allows PeakNetFP to outperformconventional AFP systems and achieves comparable performance to NeuralFP whenhandling challenging time-stretched audio data. In extensive evaluation,PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors rangingfrom 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages:compared to NeuralFP, it has 100 times fewer parameters and uses 11 timessmaller input data. These features make PeakNetFP a lightweight and efficientsolution for AFP tasks where time stretching is involved. Overall, this systemrepresents a promising direction for future AFP technologies, as itsuccessfully merges the lightweight nature of peak-based AFP with theadaptability and pattern recognition capabilities of neural network-basedapproaches, paving the way for more scalable and efficient solutions in thefield.</description>
      <author>example@mail.com (Guillem Cortès-Sebastià, Benjamin Martin, Emilio Molina, Xavier Serra, Romain Hennequin)</author>
      <guid isPermaLink="false">2506.21086v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DALR的多模态句子表示学习方法，旨在解决现有方法在跨模态对齐和模内语义分歧方面的挑战，通过细粒度跨模态对齐和全局模内对齐学习来提升句子表示质量。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态句子表示学习方法在图像和文本对齐方面存在跨模态对齐偏差和模内语义分歧的问题，这会严重影响句子表示的质量。&lt;h4&gt;目的&lt;/h4&gt;提出DALR方法，以解决跨模态对齐偏差和模内语义分歧的问题，提高句子表示的质量。&lt;h4&gt;方法&lt;/h4&gt;DALR方法包括：1. 提出一致性学习模块，通过软化负样本并利用辅助任务中的语义相似性来实现细粒度跨模态对齐；2. 认为句子关系不仅仅是正负标签的二值分类，而是具有更复杂的排序结构；3. 将排序蒸馏与全局模内对齐学习相结合，以更好地捕捉这些关系并提高表示质量。&lt;h4&gt;主要发现&lt;/h4&gt;在语义文本相似性（STS）和迁移（TR）任务上的综合实验验证了DALR方法的有效性，并持续显示出其优于现有基线的优越性。&lt;h4&gt;结论&lt;/h4&gt;DALR方法能够有效解决跨模态对齐和模内语义分歧问题，显著提升多模态句子表示的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous multimodal sentence representation learning methods have achievedimpressive performance. However, most approaches focus on aligning images andtext at a coarse level, facing two critical challenges:cross-modal misalignmentbias and intra-modal semantic divergence, which significantly degrade sentencerepresentation quality. To address these challenges, we propose DALR(Dual-level Alignment Learning for Multimodal Sentence Representation). Forcross-modal alignment, we propose a consistency learning module that softensnegative samples and utilizes semantic similarity from an auxiliary task toachieve fine-grained cross-modal alignment. Additionally, we contend thatsentence relationships go beyond binary positive-negative labels, exhibiting amore intricate ranking structure. To better capture these relationships andenhance representation quality, we integrate ranking distillation with globalintra-modal alignment learning. Comprehensive experiments on semantic textualsimilarity (STS) and transfer (TR) tasks validate the effectiveness of ourapproach, consistently demonstrating its superiority over state-of-the-artbaselines.</description>
      <author>example@mail.com (Kang He, Yuzhe Ding. Haining Wang, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.21096v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2506.20991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSDASeg的交互式点云分割模型，通过直接跨模态对齐模块和记忆模块来解决现有方法在点级任务如分割中表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;3D视觉语言模型（VLMs）的快速发展促进了交互式点云处理任务的研究，特别是在实际应用中。然而，现有方法由于缺乏直接的3D-文本对齐，往往在点级任务如分割中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出TSDASeg模型，旨在解决交互式点云分割中由于缺乏直接3D-文本对齐而导致的性能问题。&lt;h4&gt;方法&lt;/h4&gt;TSDASeg模型包括直接跨模态对齐模块和记忆模块。直接跨模态对齐模块用于建立3D点云和文本/2D图像数据之间的显式对齐。记忆模块使用多个专门的记忆库分别存储文本特征、视觉特征及其跨模态对应映射。通过自我注意力和交叉注意力机制动态利用这些记忆库，根据先前存储的数据更新场景特定的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在多个3D指令、参考和语义分割数据集上的实验表明，所提出的方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;TSDASeg模型能够有效解决交互式点云分割中的不一致性问题，并在多个数据集上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着3D视觉语言模型（VLMs）的快速发展，交互式点云处理任务，尤其是实际应用中的任务，引起了极大的兴趣。然而，由于缺乏直接的3D-文本对齐，现有方法在点级任务，如分割中往往表现不佳。为了解决这个问题，我们提出了TSDASeg，一个结合直接跨模态对齐模块和记忆模块的两阶段模型，用于交互式点云分割。我们引入了直接跨模态对齐模块，以建立3D点云和文本/2D图像数据之间的显式对齐。在记忆模块中，我们使用了多个专门的记忆库来分别存储文本特征、视觉特征及其跨模态对应映射。通过自我注意力和交叉注意力机制动态利用这些记忆库，基于先前存储的数据更新场景特定的特征，有效地解决了在多种场景下交互式分割结果的不一致性。在多个3D指令、参考和语义分割数据集上进行的实验表明，所提出的方法达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of 3D vision-language models (VLMs) has spurredsignificant interest in interactive point cloud processing tasks, particularlyfor real-world applications. However, existing methods often underperform inpoint-level tasks, such as segmentation, due to missing direct 3D-textalignment, limiting their ability to link local 3D features with textualcontext. To solve this problem, we propose TSDASeg, a Two-Stage model coupledwith a Direct cross-modal Alignment module and memory module for interactivepoint cloud Segmentation. We introduce the direct cross-modal alignment moduleto establish explicit alignment between 3D point clouds and textual/2D imagedata. Within the memory module, we employ multiple dedicated memory banks toseparately store text features, visual features, and their cross-modalcorrespondence mappings. These memory banks are dynamically leveraged throughself-attention and cross-attention mechanisms to update scene-specific featuresbased on prior stored data, effectively addressing inconsistencies ininteractive segmentation results across diverse scenarios. Experimentsconducted on multiple 3D instruction, reference, and semantic segmentationdatasets demonstrate that the proposed method achieves state-of-the-artperformance.</description>
      <author>example@mail.com (Chade Li, Pengju Zhang, Yihong Wu)</author>
      <guid isPermaLink="false">2506.20991v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher</title>
      <link>http://arxiv.org/abs/2506.20834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Brain2Model Transfer Learning (B2M)的框架，通过利用人类大脑的低维抽象表示来增强人工神经网络的学习能力。&lt;h4&gt;背景&lt;/h4&gt;认知神经科学表明，人类大脑可以通过较少的数据点和计算能力来创建低维的抽象表示，这些表示对于高效的感官和运动编码至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入B2M框架，以人类神经活动作为教师模型来训练人工神经网络，提高其学习效率。&lt;h4&gt;方法&lt;/h4&gt;论文提出了两种B2M策略：(1)脑对比迁移，通过对比目标来对齐大脑活动和网络激活；(2)脑潜在迁移，通过监督回归大脑特征，将类似认知任务的潜在动态投影到学生网络上。&lt;h4&gt;主要发现&lt;/h4&gt;在基于记忆的决策制作和场景重建任务中，利用B2M策略训练的学生网络比单独训练的网络收敛更快，预测精度更高。&lt;h4&gt;结论&lt;/h4&gt;大脑的表示对于人工学习者非常有价值，这为更高效地学习复杂的决策表示铺平了道路，这些表示通过纯人工训练可能既昂贵又缓慢。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习通过采用大型预训练教师模型的丰富特征表示来增强新感官和决策模型的学习。认知神经科学表明，人脑创建了低维的抽象表示以实现高效的感官运动编码。重要的是，大脑可以比人工模型所需的更少的数据点和更少的计算能力来学习这些表示。我们引入了Brain2Model迁移学习（B2M）框架，其中人类感官和决策任务的神经活动作为训练人工神经网络的教师模型。我们提出了两种B2M策略：(1)脑对比迁移，通过对比目标对齐大脑活动和网络激活；(2)脑潜在迁移，通过监督回归大脑特征，将类似认知任务的潜在动态投影到学生网络上。我们在基于记忆的决策制作和自动驾驶场景重建中验证了B2M，结果显示，从基于大脑的迁移中受益的学生网络比单独训练的网络收敛更快，预测精度更高。我们的发现表明，大脑的表示对于人工学习者非常有价值，为更高效地学习复杂的决策表示铺平了道路，这些表示通过纯人工训练可能既昂贵又缓慢。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances the training of novel sensory and decision modelsby employing rich feature representations from large, pre-trained teachermodels. Cognitive neuroscience shows that the human brain createslow-dimensional, abstract representations for efficient sensorimotor coding.Importantly, the brain can learn these representations with significantly fewerdata points and less computational power than artificial models require. Weintroduce Brain2Model Transfer Learning (B2M), a framework where neuralactivity from human sensory and decision-making tasks acts as the teacher modelfor training artificial neural networks. We propose two B2M strategies: (1)Brain Contrastive Transfer, which aligns brain activity and network activationsthrough a contrastive objective; and (2) Brain Latent Transfer, which projectslatent dynamics from similar cognitive tasks onto student networks viasupervised regression of brain-derived features. We validate B2M inmemory-based decision-making with a recurrent neural network and scenereconstruction for autonomous driving with a variational autoencoder. Theresults show that student networks benefiting from brain-based transferconverge faster and achieve higher predictive accuracy than networks trained inisolation. Our findings indicate that the brain's representations are valuablefor artificial learners, paving the way for more efficient learning of complexdecision-making representations, which would be costly or slow through purelyartificial training.</description>
      <author>example@mail.com (Tomas Gallo Aquino, Victoria Liu, Habiba Azab, Raissa Mathura, Andrew J Watrous, Eleonora Bartoli, Benjamin Y Hayden, Paul Sajda, Sameer A Sheth, Nuttida Rungratsameetaweemana)</author>
      <guid isPermaLink="false">2506.20834v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Skill Discovery via Regret-Aware Optimization</title>
      <link>http://arxiv.org/abs/2506.21044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时间表示学习的技能发现方法，旨在提高开放式强化学习中技能的多样性和区分度。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督技能发现方法主要关注通过纯探索、互信息优化和学习时间表示来提高多样性，但在高维情况下效率有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过将技能发现视为技能生成和政策学习之间的min-max博弈，在时间表示学习的基础上，提高技能空间的效率。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心思想是技能发现与政策学习是对抗的，即应进一步探索强度较弱的技能，而对强度已收敛的技能减少探索。通过学习可升级的技能生成器来引导技能发现，并使用后悔来评分强度收敛的程度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在效率和多样性方面优于基线方法，在高度复杂和高维环境中实现了15%的无监督改进。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地扩展了技能空间，提高了技能发现的效率，特别是在高维环境中表现优异。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised skill discovery aims to learn diverse and distinguishable behaviors in open-ended reinforcement learning. For existing methods, they focus on improving diversity through pure exploration, mutual information optimization, and learning temporal representation. Despite that they perform well on exploration, they remain limited in terms of efficiency, especially for the high-dimensional situations. In this work, we frame skill discovery as a min-max game of skill generation and policy learning, proposing a regret-aware method on top of temporal representation learning that expands the discovered skill space along the direction of upgradable policy strength. The key insight behind the proposed method is that the skill discovery is adversarial to the policy learning, i.e., skills with weak strength should be further explored while less exploration for the skills with converged strength. As an implementation, we score the degree of strength convergence with regret, and guide the skill discovery with a learnable skill generator. To avoid degeneration, skill generation comes from an up-gradable population of skill generators. We conduct experiments on environments with varying complexities and dimension sizes. Empirical results show that our method outperforms baselines in both efficiency and diversity. Moreover, our method achieves a 15% zero shot improvement in high-dimensional environments, compared to existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised skill discovery aims to learn diverse and distinguishablebehaviors in open-ended reinforcement learning. For existing methods, theyfocus on improving diversity through pure exploration, mutual informationoptimization, and learning temporal representation. Despite that they performwell on exploration, they remain limited in terms of efficiency, especially forthe high-dimensional situations. In this work, we frame skill discovery as amin-max game of skill generation and policy learning, proposing a regret-awaremethod on top of temporal representation learning that expands the discoveredskill space along the direction of upgradable policy strength. The key insightbehind the proposed method is that the skill discovery is adversarial to thepolicy learning, i.e., skills with weak strength should be further exploredwhile less exploration for the skills with converged strength. As animplementation, we score the degree of strength convergence with regret, andguide the skill discovery with a learnable skill generator. To avoiddegeneration, skill generation comes from an up-gradable population of skillgenerators. We conduct experiments on environments with varying complexitiesand dimension sizes. Empirical results show that our method outperformsbaselines in both efficiency and diversity. Moreover, our method achieves a 15%zero shot improvement in high-dimensional environments, compared to existingmethods.</description>
      <author>example@mail.com (He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong)</author>
      <guid isPermaLink="false">2506.21044v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding</title>
      <link>http://arxiv.org/abs/2506.21188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了GroundFlow模块，用于3D点云序列定位任务中的时间推理，显著提高了现有3D视觉定位方法的准确率。&lt;h4&gt;背景&lt;/h4&gt;当前3D视觉定位方法无法有效处理包含多步骤的文本指令，且在理解上下文和检索相关信息方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出GroundFlow模块，以解决3D点云序列定位任务中时间推理的挑战。&lt;h4&gt;方法&lt;/h4&gt;GroundFlow模块能够根据指令的相关性选择性提取短期和长期步骤信息，从而全面理解历史信息。&lt;h4&gt;主要发现&lt;/h4&gt;GroundFlow模块显著提高了3D视觉定位方法的准确率，并在SG3D基准测试中取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;GroundFlow模块引入了时间推理能力，为现有的3D视觉定位模型带来了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Sequential grounding in 3D point clouds (SG3D) refers to locating sequences of objects by following text instructions for a daily activity with detailed steps. Current 3D visual grounding (3DVG) methods treat text instructions with multiple steps as a whole, without extracting useful temporal information from each step. However, the instructions in SG3D often contain pronouns such as 'it', 'here' and 'the same' to make language expressions concise. This requires grounding methods to understand the context and retrieve relevant information from previous steps to correctly locate object sequences. Due to the lack of an effective module for collecting related historical information, state-of-the-art 3DVG methods face significant challenges in adapting to the SG3D task. To fill this gap, we propose GroundFlow -- a plug-in module for temporal reasoning on 3D point cloud sequential grounding. Firstly, we demonstrate that integrating GroundFlow improves the task accuracy of 3DVG baseline methods by a large margin (+7.5% and +10.2%) in the SG3D benchmark, even outperforming a 3D large language model pre-trained on various datasets. Furthermore, we selectively extract both short-term and long-term step information based on its relevance to the current instruction, enabling GroundFlow to take a comprehensive view of historical information and maintain its temporal understanding advantage as step counts increase. Overall, our work introduces temporal reasoning capabilities to existing 3DVG models and achieves state-of-the-art performance in the SG3D benchmark across five datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential grounding in 3D point clouds (SG3D) refers to locating sequencesof objects by following text instructions for a daily activity with detailedsteps. Current 3D visual grounding (3DVG) methods treat text instructions withmultiple steps as a whole, without extracting useful temporal information fromeach step. However, the instructions in SG3D often contain pronouns such as"it", "here" and "the same" to make language expressions concise. This requiresgrounding methods to understand the context and retrieve relevant informationfrom previous steps to correctly locate object sequences. Due to the lack of aneffective module for collecting related historical information,state-of-the-art 3DVG methods face significant challenges in adapting to theSG3D task. To fill this gap, we propose GroundFlow -- a plug-in module fortemporal reasoning on 3D point cloud sequential grounding. Firstly, wedemonstrate that integrating GroundFlow improves the task accuracy of 3DVGbaseline methods by a large margin (+7.5\% and +10.2\%) in the SG3D benchmark,even outperforming a 3D large language model pre-trained on various datasets.Furthermore, we selectively extract both short-term and long-term stepinformation based on its relevance to the current instruction, enablingGroundFlow to take a comprehensive view of historical information and maintainits temporal understanding advantage as step counts increase. Overall, our workintroduces temporal reasoning capabilities to existing 3DVG models and achievesstate-of-the-art performance in the SG3D benchmark across five datasets.</description>
      <author>example@mail.com (Zijun Lin, Shuting He, Cheston Tan, Bihan Wen)</author>
      <guid isPermaLink="false">2506.21188v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection</title>
      <link>http://arxiv.org/abs/2506.21382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强时间感知图注意力网络（ATGAT）来提高加密货币交易欺诈检测的性能。&lt;h4&gt;背景&lt;/h4&gt;加密货币交易欺诈检测面临交易模式日益复杂和严重类别不平衡的双重挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效检测加密货币交易欺诈的方法。&lt;h4&gt;方法&lt;/h4&gt;ATGAT通过三个模块增强检测性能：(1) 设计了一个高级时间嵌入模块，融合多尺度时间差特征和周期性位置编码；(2) 构建了一个时间感知的三元注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权二元交叉熵损失来处理类别不平衡。&lt;h4&gt;主要发现&lt;/h4&gt;在Elliptic++加密货币数据集上的实验表明，ATGAT实现了0.9130的AUC，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅验证了时间感知和三元注意力机制对图神经网络增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原理可推广到其他时间图异常检测任务。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) to improve the performance of cryptocurrency transaction fraud detection. The background is that cryptocurrency transaction fraud detection faces the dual challenges of increasingly complex transaction patterns and severe class imbalance. The purpose is to design a method that can effectively detect cryptocurrency transaction fraud. The method enhances the performance through three modules: (1) designing an advanced temporal embedding module that fuses multi-scale time difference features with periodic position encoding; (2) constructing a temporal-aware triple attention mechanism that jointly optimizes structural, temporal, and global context attention; (3) employing weighted BCE loss to address class imbalance. Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT achieves an AUC of 0.9130, representing a 9.2% improvement over the best traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This method not only validates the enhancement effect of temporal awareness and triple attention mechanisms on graph neural networks, but also provides financial institutions with more reliable fraud detection tools, with its design principles generalizable to other temporal graph anomaly detection tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cryptocurrency transaction fraud detection faces the dual challenges ofincreasingly complex transaction patterns and severe class imbalance.Traditional methods rely on manual feature engineering and struggle to capturetemporal and structural dependencies in transaction networks. This paperproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) thatenhances detection performance through three modules: (1) designing an advancedtemporal embedding module that fuses multi-scale time difference features withperiodic position encoding; (2) constructing a temporal-aware triple attentionmechanism that jointly optimizes structural, temporal, and global contextattention; (3) employing weighted BCE loss to address class imbalance.Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGATachieves an AUC of 0.9130, representing a 9.2% improvement over the besttraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. Thismethod not only validates the enhancement effect of temporal awareness andtriple attention mechanisms on graph neural networks, but also providesfinancial institutions with more reliable fraud detection tools, with itsdesign principles generalizable to other temporal graph anomaly detectiontasks.</description>
      <author>example@mail.com (Zhi Zheng, Bochuan Zhou, Yuping Song)</author>
      <guid isPermaLink="false">2506.21382v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Canonical Quantization of a Memristive Leaky Integrate-and-Fire Neuron Circuit</title>
      <link>http://arxiv.org/abs/2506.21363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种量子化忆阻漏积分-触发（LIF）神经元的理论框架，结合了神经形态工程和开放量子系统的原理。&lt;h4&gt;背景&lt;/h4&gt;研究基于经典忆阻LIF电路，应用规范量子化技术，基于电路量子电动力学推导出量子模型。&lt;h4&gt;目的&lt;/h4&gt;建立量子神经形态计算的基础模型，为生物启发式量子触发神经网络和量子机器学习的新范式提供途径。&lt;h4&gt;方法&lt;/h4&gt;通过对量子化忆阻和LIF神经元的弱耦合和绝热状态的数值模拟，验证了其关键动力学特征，包括记忆效应和触发行为。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果显示了量子化忆阻和LIF神经元的记忆效应和触发行为等关键动力学特征。&lt;h4&gt;结论&lt;/h4&gt;该研究为量子神经形态计算奠定了基础，为量子机器学习提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;We present a theoretical framework for a quantized memristive LeakyIntegrate-and-Fire (LIF) neuron, uniting principles from neuromorphic engineering and open quantum systems. Starting from a classical memristive LIF circuit, we apply canonical quantization techniques to derive a quantum model grounded in circuit quantum electrodynamics. Numerical simulations demonstrate key dynamical features of the quantized memristor and LIF neuron in the weak-coupling and adiabatic regime, including memory effects and spiking behaviour. This work establishes a foundational model for quantum neuromorphic computing, offering a pathway towards biologically inspired quantum spiking neural networks and new paradigms in quantum machine learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a theoretical framework for a quantized memristive LeakyIntegrate-and-Fire (LIF) neuron, uniting principles from neuromorphicengineering and open quantum systems. Starting from a classical memristive LIFcircuit, we apply canonical quantization techniques to derive a quantum modelgrounded in circuit quantum electrodynamics. Numerical simulations demonstratekey dynamical features of the quantized memristor and LIF neuron in theweak-coupling and adiabatic regime, including memory effects and spikingbehaviour. This work establishes a foundational model for quantum neuromorphiccomputing, offering a pathway towards biologically inspired quantum spikingneural networks and new paradigms in quantum machine learning.</description>
      <author>example@mail.com (Dean Brand, Domenica Dibenedetto, Francesco Petruccione)</author>
      <guid isPermaLink="false">2506.21363v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Task-Aware KV Compression For Cost-Effective Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.21184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Video-X^2L，一种用于长视频理解（LVU）的多模态大型语言模型（MLLM）的压缩方法，旨在减少计算成本并保持关键视频信息。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型在处理长视频理解时面临巨大的计算成本问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来减少LVU任务的计算成本，同时保留关键视频信息。&lt;h4&gt;方法&lt;/h4&gt;Video-X^2L包括两个关键操作：双级KV压缩和选择性KV重载。双级KV压缩在MLLM预填充阶段生成两种压缩KV：低压缩KV（L-KVs）捕获精细的视频细节和高压缩KV（H-KVs）提供紧凑的视频表示。选择性KV重载在MLLM解码阶段，选择性地重载L-KVs以处理最关键的视频片段，而使用H-KVs处理其他不那么重要的片段。&lt;h4&gt;主要发现&lt;/h4&gt;Video-X^2L在保持总体紧凑性的同时，允许MLLM充分利用特定任务的信息。Video-X^2L简单有效，无需额外训练，可直接与现有的KV-compressible MLLMs兼容。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，Video-X^2L在多种流行的LVU基准测试中优于现有的KV压缩方法，同时显著降低了计算成本。&lt;h4&gt;翻译&lt;/h4&gt;Long-video understanding (LVU) remains a severe challenge for existing multimodal large language models (MLLMs), primarily due to the prohibitive computational cost. Recent approaches have explored KV compression to mitigate this issue, but they often suffer from significant information loss at high compression ratios. In this paper, we introduce Video-X^2L, which flexibly preserves critical video information for each LVU task. Video-X^2L involves two key operations. The first one is called bi-level KV compression. During the MLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs: low-compression KVs (L-KVs) to capture fine-grained video details and high-compression KVs (H-KVs) to offer compact video representations. The second one is called selective KV re-loading. During the MLLM's decoding stage, Video-X^2L selectively re-loads L-KVs for the most critical video chunks while using H-KVs for other less important ones. This allows the MLLM to fully utilize task-specific information while maintaining the overall compactness. Video-X^2L is simple yet effective: it is free from additional training and directly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2L with a variety of popular LVU benchmarks, including VideoMME, MLVU, LongVideoBench, and VNBench. Our experiment result shows that Video-X^2L outperforms existing KV-compression methods by a huge advantage while substantially saving the computation cost.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-video understanding (LVU) remains a severe challenge for existingmultimodal large language models (MLLMs), primarily due to the prohibitivecomputational cost. Recent approaches have explored KV compression to mitigatethis issue, but they often suffer from significant information loss at highcompression ratios. In this paper, we introduce Video-X^2L, which flexiblypreserves critical video information for each LVU task. Video-X^2L involves twokey operations. The first one is called bi-level KV compression. During theMLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs:low-compression KVs (L-KVs) to capture fine-grained video details andhigh-compression KVs (H-KVs) to offer compact video representations. The secondone is called selective KV re-loading. During the MLLM's decoding stage,Video-X^2L selectively re-loads L-KVs for the most critical video chunks whileusing H-KVs for other less important ones. This allows the MLLM to fullyutilize task-specific information while maintaining the overall compactness.Video-X^2L is simple yet effective: it is free from additional training anddirectly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2Lwith a variety of popular LVU benchmarks, including VideoMME, MLVU,LongVideoBench, and VNBench. Our experiment result shows that Video-X^2Loutperforms existing KV-compression methods by a huge advantage whilesubstantially saving the computation cost.</description>
      <author>example@mail.com (Minghao Qin, Yan Shu, Peitian Zhang, Kun Lun, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu)</author>
      <guid isPermaLink="false">2506.21184v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features</title>
      <link>http://arxiv.org/abs/2506.21046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures, to appear in ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用自监督视觉Transformer（ViT）表示来提高对抗迁移性的可能性，并提出了dSVA，一种基于生成对抗的ViT特征攻击方法。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络（DNNs）的能力来源于从数据中提取和解释特征。以往的研究通常依赖于监督学习来提取特征，而本文则探索了自监督学习与Transformer架构之间的协同作用。&lt;h4&gt;目的&lt;/h4&gt;研究利用自监督Vision Transformer (ViT)表示是否能提高对抗迁移性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为dSVA的生成双重自监督ViT特征攻击方法，该方法利用了对比学习（CL）的全球结构特征和掩码图像建模（MIM）的局部纹理特征。设计了一个新的生成训练框架，其中包含一个生成器来创建黑盒对抗示例，并利用自监督ViT的联合特征和注意力机制来训练生成器。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习（CL）和掩码图像建模（MIM）使ViT能够关注不同的特征趋势，当联合使用时，具有出色的对抗泛化能力。通过破坏自监督ViT提取的双重深度特征，实现了对各种架构模型的显著黑盒迁移性。&lt;h4&gt;结论&lt;/h4&gt;dSVA方法在黑盒迁移性方面取得了显著成果，为不同架构的模型提供了超越现有技术的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了利用自监督视觉Transformer（ViT）表示来提高对抗迁移性的可能性。受自监督学习和Transformer架构之间卓越协同作用的启发，本文提出了dSVA——一种基于生成对抗的ViT特征攻击方法。本文提出了一种名为dSVA的生成双重自监督ViT特征攻击方法，该方法利用了对比学习（CL）的全球结构特征和掩码图像建模（MIM）的局部纹理特征。设计了一个新的生成训练框架，其中包含一个生成器来创建黑盒对抗示例，并利用自监督ViT的联合特征和注意力机制来训练生成器。研究发现，对比学习（CL）和掩码图像建模（MIM）使ViT能够关注不同的特征趋势，当联合使用时，具有出色的对抗泛化能力。通过破坏自监督ViT提取的双重深度特征，实现了对各种架构模型的显著黑盒迁移性。dSVA方法在黑盒迁移性方面取得了显著成果，为不同架构的模型提供了超越现有技术的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of deep neural networks (DNNs) come from extracting andinterpreting features from the data provided. By exploiting intermediatefeatures in DNNs instead of relying on hard labels, we craft adversarialperturbation that generalize more effectively, boosting black-boxtransferability. These features ubiquitously come from supervised learning inprevious work. Inspired by the exceptional synergy between self-supervisedlearning and the Transformer architecture, this paper explores whetherexploiting self-supervised Vision Transformer (ViT) representations can improveadversarial transferability. We present dSVA -- a generative dualself-supervised ViT features attack, that exploits both global structuralfeatures from contrastive learning (CL) and local textural features from maskedimage modeling (MIM), the self-supervised learning paradigm duo for ViTs. Wedesign a novel generative training framework that incorporates a generator tocreate black-box adversarial examples, and strategies to train the generator byexploiting joint features and the attention mechanism of self-supervised ViTs.Our findings show that CL and MIM enable ViTs to attend to distinct featuretendencies, which, when exploited in tandem, boast great adversarialgeneralizability. By disrupting dual deep features distilled by self-supervisedViTs, we are rewarded with remarkable black-box transferability to models ofvarious architectures that outperform state-of-the-arts. Code available athttps://github.com/spencerwooo/dSVA.</description>
      <author>example@mail.com (Shangbo Wu, Yu-an Tan, Ruinan Ma, Wencong Ma, Dehua Zhu, Yuanzhang Li)</author>
      <guid isPermaLink="false">2506.21046v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Real-time and personalized product recommendations for large e-commerce platforms</title>
      <link>http://arxiv.org/abs/2506.21368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication at the International  Conference on Artificial Neural Networks (ICANN) 2025. The final  authenticated version will be available for purchase through the publisher's  website. The conference proceedings will be published by Springer in the  Lecture Notes in Computer Science (LNCS) series&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型电子商务平台，尤其是时尚零售领域，提供实时个性化产品推荐的方法。&lt;h4&gt;背景&lt;/h4&gt;针对大型电子商务平台，尤其是时尚零售领域，需要提供准确、可扩展且响应时间最短的产品推荐。&lt;h4&gt;目的&lt;/h4&gt;实现准确和可扩展的推荐，同时保证最小化响应时间，提升用户满意度。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络和节省学习方法的结合，进行实时个性化推荐。&lt;h4&gt;主要发现&lt;/h4&gt;通过对大型电商平台数据的实验，验证了该方法在预测购买序列和处理多交互场景中的有效性，并在实际约束条件下实现了高效的个性化推荐。&lt;h4&gt;结论&lt;/h4&gt;该方法在电子商务平台中提供实时、个性化的产品推荐是有效的，能够满足实际应用需求。&lt;h4&gt;翻译&lt;/h4&gt;We present a methodology to provide real-time and personalized product recommendations for large e-commerce platforms, specifically focusing on fashion retail. Our approach aims to achieve accurate and scalable recommendations with minimal response times, ensuring user satisfaction, leveraging Graph Neural Networks and parsimonious learning methodologies. Extensive experimentation with datasets from one of the largest e-commerce platforms demonstrates the effectiveness of our approach in forecasting purchase sequences and handling multi-interaction scenarios, achieving efficient personalized recommendations under real-world constraints.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a methodology to provide real-time and personalized productrecommendations for large e-commerce platforms, specifically focusing onfashion retail. Our approach aims to achieve accurate and scalablerecommendations with minimal response times, ensuring user satisfaction,leveraging Graph Neural Networks and parsimonious learning methodologies.Extensive experimentation with datasets from one of the largest e-commerceplatforms demonstrates the effectiveness of our approach in forecastingpurchase sequences and handling multi-interaction scenarios, achievingefficient personalized recommendations under real-world constraints.</description>
      <author>example@mail.com (Matteo Tolloso, Davide Bacciu, Shahab Mokarizadeh, Marco Varesi)</author>
      <guid isPermaLink="false">2506.21368v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Hardware-Aware Quantum Kernel Design Based on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.21161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HaQGNN的硬件感知量子核设计框架，旨在提高量子机器学习（QML）中的量子核设计效率。&lt;h4&gt;背景&lt;/h4&gt;量子核方法在量子机器学习中是一个有前景的方向，但设计适应目标任务和近端量子硬件约束的有效量子核是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HaQGNN框架，以评估和选择与任务相关的量子电路。&lt;h4&gt;方法&lt;/h4&gt;HaQGNN框架结合了量子设备拓扑、噪声特性和图神经网络（GNNs），通过预测与保真度和核性能相关的指标来筛选电路。此外，还集成了特征选择，以提高与有限量子比特系统的兼容性并减轻核退化。&lt;h4&gt;主要发现&lt;/h4&gt;在Credit Card、MNIST-5和FMNIST-4三个基准数据集上的实验表明，HaQGNN在分类精度方面优于现有的量子核基线。&lt;h4&gt;结论&lt;/h4&gt;基于学习和硬件感知的策略有望推动在NISQ设备上实现实用的量子核设计。&lt;h4&gt;翻译&lt;/h4&gt;Quantum kernel methods have emerged as a promising direction in quantum machine learning (QML), offering a principled way to map classical data into high-dimensional quantum Hilbert spaces. While conceptually powerful, designing effective quantum kernels that adapt to both the target task and the constraints of near-term quantum hardware remains a nontrivial challenge. In this work, we propose HaQGNN, a hardware-aware quantum kernel design framework that integrates quantum device topology, noise characteristics, and graph neural networks (GNNs) to evaluate and select task-relevant quantum circuits. By predicting surrogate metrics related to fidelity and kernel performance, HaQGNN enables efficient circuit screening at scale. Feature selection is further incorporated to improve compatibility with limited-qubit systems and mitigate kernel degradation. Extensive experiments on three benchmark datasets, Credit Card, MNIST-5, and FMNIST-4, demonstrate that HaQGNN outperforms existing quantum kernel baselines in terms of classification accuracy. Our work highlights the potential of learning-based and hardware-aware strategies for advancing practical quantum kernel design on NISQ devices.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum kernel methods have emerged as a promising direction in quantummachine learning (QML), offering a principled way to map classical data intohigh-dimensional quantum Hilbert spaces. While conceptually powerful, designingeffective quantum kernels that adapt to both the target task and theconstraints of near-term quantum hardware remains a nontrivial challenge. Inthis work, we propose HaQGNN, a hardware-aware quantum kernel design frameworkthat integrates quantum device topology, noise characteristics, and graphneural networks (GNNs) to evaluate and select task-relevant quantum circuits.By predicting surrogate metrics related to fidelity and kernel performance,HaQGNN enables efficient circuit screening at scale. Feature selection isfurther incorporated to improve compatibility with limited-qubit systems andmitigate kernel degradation. Extensive experiments on three benchmark datasets,Credit Card, MNIST-5, and FMNIST-4, demonstrate that HaQGNN outperformsexisting quantum kernel baselines in terms of classification accuracy. Our workhighlights the potential of learning-based and hardware-aware strategies foradvancing practical quantum kernel design on NISQ devices.</description>
      <author>example@mail.com (Yuxiang Liu, Fanxu Meng, Lu Wang, Yi Hu, Sixuan Li, Zaichen Zhang, Xutao Yu)</author>
      <guid isPermaLink="false">2506.21161v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence</title>
      <link>http://arxiv.org/abs/2506.21028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TRIDENT是一个新的框架，用于学习分子的丰富表示，它整合了分子的SMILES、文本描述和分类学功能注释。&lt;h4&gt;背景&lt;/h4&gt;多模态学习被证明是学习分子表示的有力范式，但先前的工作往往忽略了分子的文本和分类学信息。&lt;h4&gt;目的&lt;/h4&gt;提出TRIDENT框架，通过整合分子SMILES、文本描述和分类学功能注释来学习丰富的分子表示。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含分子-文本对的全面数据集，具有结构化的多层次功能注释。使用基于体积的对齐目标联合对齐三模态特征，并引入了新的局部对齐目标以捕捉分子亚结构和相应亚文本描述之间的详细关系。&lt;h4&gt;主要发现&lt;/h4&gt;TRIDENT在11个下游任务上实现了最先进的性能，证明了结合SMILES、文本和分类学功能注释对分子性质预测的价值。&lt;h4&gt;结论&lt;/h4&gt;TRIDENT框架通过结合多种信息源，有效地提高了分子性质预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction aims to learn representations that map chemicalstructures to functional properties. While multimodal learning has emerged as apowerful paradigm to learn molecular representations, prior works have largelyoverlooked textual and taxonomic information of molecules for representationlearning. We introduce TRIDENT, a novel framework that integrates molecularSMILES, textual descriptions, and taxonomic functional annotations to learnrich molecular representations. To achieve this, we curate a comprehensivedataset of molecule-text pairs with structured, multi-level functionalannotations. Instead of relying on conventional contrastive loss, TRIDENTemploys a volume-based alignment objective to jointly align tri-modal featuresat the global level, enabling soft, geometry-aware alignment across modalities.Additionally, TRIDENT introduces a novel local alignment objective thatcaptures detailed relationships between molecular substructures and theircorresponding sub-textual descriptions. A momentum-based mechanism dynamicallybalances global and local alignment, enabling the model to learn both broadfunctional semantics and fine-grained structure-function mappings. TRIDENTachieves state-of-the-art performance on 11 downstream tasks, demonstrating thevalue of combining SMILES, textual, and taxonomic functional annotations formolecular property prediction.</description>
      <author>example@mail.com (Feng Jiang, Mangal Prakash, Hehuan Ma, Jianyuan Deng, Yuzhi Guo, Amina Mollaysa, Tommaso Mansi, Rui Liao, Junzhou Huang)</author>
      <guid isPermaLink="false">2506.21028v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes</title>
      <link>http://arxiv.org/abs/2506.21116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了视频大型语言模型（VideoLLMs）在多镜头场景下的理解能力，并提出了一个新的数据集和模型来提升这一能力。&lt;h4&gt;背景&lt;/h4&gt;VideoLLMs在理解能力上表现出色，但在处理多镜头场景时，如不同角度或场景变化的视频片段，会遇到困难，可能导致实例身份遗忘和关键帧忽视等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文旨在提出一种新的数据集和模型，以提升VideoLLMs在多镜头场景下的性能。&lt;h4&gt;方法&lt;/h4&gt;论文首先分析了现有数据集中缺乏多镜头标注的问题，并因此引入了一个名为MultiClip-Bench的新数据集，其中包含针对多镜头场景的密集描述和基于指令的问答对。接着，论文提出了一种新的模型IPFormer-VideoLLM，该模型通过高效的关注力连接器注入实例级特征作为实例提示，以实现跨场景的实例特定信息聚合。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，新的数据集和模型能够显著提升多场景视频理解能力，并在多个视频基准测试中展现出独特的优势。&lt;h4&gt;结论&lt;/h4&gt;论文提出的MultiClip-Bench数据集和IPFormer-VideoLLM模型能够有效提升VideoLLMs在多镜头场景下的性能，为视频理解领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Video Large Language Models (VideoLLMs) have demonstrated remarkableunderstanding capabilities, but are found struggling to tackle multi-shotscenarios,e.g., video clips with varying camera angles or scene changes. Thischallenge can render failures such as instance identity forgetting and keyframe negligence. In this work, we first attribute the challenge to the lack ofmulti-shot annotations among existing datasets and therefore we introduce a newdataset termed MultiClip-Bench, featuring dense descriptions andinstruction-based question-answering pairs tailored for multi-shot scenarios.We empirically find that the training set significantly boosts the multi-shotperformance, while the testing benchmark provides a reliable measure of themodel capability in multi-shot scenarios. By further analyzing and discoveringthat current models only encode instance features in a discrete or lossymanner, at the risk of missing identity information, we then contribute a newmodel IPFormer-VideoLLM. Its key idea is the injection of instance-levelfeatures as instance prompts through an efficient attention-based connector.This allows for the aggregation of instance-specific information across scenes.Experiments demonstrate that our proposed dataset and model not only enhancethe multi-scene video understanding significantly, but also offer distinctadvantages across various video benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Large Language Models (VideoLLMs) have demonstrated remarkableunderstanding capabilities, but are found struggling to tackle multi-shotscenarios,e.g., video clips with varying camera angles or scene changes. Thischallenge can render failures such as instance identity forgetting and keyframe negligence. In this work, we first attribute the challenge to the lack ofmulti-shot annotations among existing datasets and therefore we introduce a newdataset termed MultiClip-Bench, featuring dense descriptions andinstruction-based question-answering pairs tailored for multi-shot scenarios.We empirically find that the training set significantly boosts the multi-shotperformance, while the testing benchmark provides a reliable measure of themodel capability in multi-shot scenarios. By further analyzing and discoveringthat current models only encode instance features in a discrete or lossymanner, at the risk of missing identity information, we then contribute a newmodel IPFormer-VideoLLM. Its key idea is the injection of instance-levelfeatures as instance prompts through an efficient attention-based connector.This allows for the aggregation of instance-specific information across scenes.Experiments demonstrate that our proposed dataset and model not only enhancethe multi-scene video understanding significantly, but also offer distinctadvantages across various video benchmarks.</description>
      <author>example@mail.com (Yujia Liang, Jile Jiao, Zhicheng Wang, Xuetao Feng, Zixuan Ye, Yuan Wang, Hao Lu)</author>
      <guid isPermaLink="false">2506.21116v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Active Inference AI Systems for Scientific Discovery</title>
      <link>http://arxiv.org/abs/2506.21329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了人工智能在科学发现中的应用，指出当前系统受限于操作架构、脆弱的推理机制和与实验现实的分离。作者提出，AI在科学领域的进步依赖于弥合三个基本差距：抽象差距、推理差距和现实差距。&lt;h4&gt;背景&lt;/h4&gt;人工智能的快速发展引发了关于颠覆性科学发现的期望，但现有系统在操作架构、脆弱的推理机制和与实验现实的分离方面存在根本限制。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨AI在科学发现中的进步，并提出了通过弥合三个基本差距来实现这一目标的方法。&lt;h4&gt;方法&lt;/h4&gt;作者提出了主动推理AI系统，这些系统通过以下方式实现科学发现：(i) 维持基于因果自监督基础模型的长寿命研究记忆；(ii) 装备贝叶斯安全措施的符号或神经符号规划器；(iii) 增长持久的知识图谱，其中思维生成新的概念节点，推理建立因果关系，现实世界的交互修剪错误连接并加强验证路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来细化其内部表示。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了一种架构，其中发现源于内部模型（能够进行反事实推理）和外部验证（将假设建立在现实基础上）之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;作者认为，来自模拟和实验的反馈固有的模糊性和潜在的不确定性使得人类判断不可或缺，不仅是临时的支架，而且是永久性的架构组件。&lt;h4&gt;翻译&lt;/h4&gt;The rapid evolution of artificial intelligence has led to expectations of transformative scientific discovery, yet current systems remain fundamentally limited by their operational architectures, brittle reasoning mechanisms, and their separation from experimental reality. Building on earlier work, we contend that progress in AI-driven science now depends on closing three fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap-- rather than on model size/data/test time compute. Scientific reasoning demands internal representations that support simulation of actions and response, causal structures that distinguish correlation from mechanism, and continuous calibration. We define active inference AI systems for scientific discovery as those that (i) maintain long-lived research memories grounded in causal self-supervised foundation models, (ii) symbolic or neuro-symbolic planners equipped with Bayesian guardrails, (iii) grow persistent knowledge graphs where thinking generates novel conceptual nodes, reasoning establishes causal edges, and real-world interaction prunes false connections while strengthening verified pathways, and (iv) refine their internal representations through closed-loop interaction with both high-fidelity simulators and automated laboratories - an operational loop where mental simulation guides action and empirical surprise reshapes understanding. In essence, we outline an architecture where discovery arises from the interplay between internal models that enable counterfactual reasoning and external validation that grounds hypotheses in reality. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties makes human judgment indispensable, not as a temporary scaffold but as a permanent architectural component.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of artificial intelligence has led to expectations oftransformative scientific discovery, yet current systems remain fundamentallylimited by their operational architectures, brittle reasoning mechanisms, andtheir separation from experimental reality. Building on earlier work, wecontend that progress in AI-driven science now depends on closing threefundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap-- rather than on model size/data/test time compute. Scientific reasoningdemands internal representations that support simulation of actions andresponse, causal structures that distinguish correlation from mechanism, andcontinuous calibration. We define active inference AI systems for scientificdiscovery as those that (i) maintain long-lived research memories grounded incausal self-supervised foundation models, (ii) symbolic or neuro-symbolicplanners equipped with Bayesian guardrails, (iii) grow persistent knowledgegraphs where thinking generates novel conceptual nodes, reasoning establishescausal edges, and real-world interaction prunes false connections whilestrengthening verified pathways, and (iv) refine their internal representationsthrough closed-loop interaction with both high-fidelity simulators andautomated laboratories - an operational loop where mental simulation guidesaction and empirical surprise reshapes understanding. In essence, we outline anarchitecture where discovery arises from the interplay between internal modelsthat enable counterfactual reasoning and external validation that groundshypotheses in reality. It is also argued that the inherent ambiguity infeedback from simulations and experiments, and underlying uncertainties makeshuman judgment indispensable, not as a temporary scaffold but as a permanentarchitectural component.</description>
      <author>example@mail.com (Karthik Duraisamy)</author>
      <guid isPermaLink="false">2506.21329v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling</title>
      <link>http://arxiv.org/abs/2506.21041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为V2X-REALM的框架，用于在复杂环境中实现鲁棒的协同自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;在城市环境中，自动驾驶系统需要在罕见、多样化的视觉退化场景下进行稳健的规划和决策，这在协同环境中尤为重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了V2X-REALM框架，以实现鲁棒的协同自动驾驶。&lt;h4&gt;方法&lt;/h4&gt;V2X-REALM引入了三项核心创新：(i) 提出了一种提示驱动的长尾场景生成和评估流程，利用基础模型合成真实的长尾条件；(ii) 引入了一个门控多场景自适应注意力模块，以调节视觉流；(iii) 提出了一个多任务场景感知对比学习目标，以改善多模态对齐并促进跨场景特征可分离性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性和规划准确性方面显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;V2X-REALM推进了端到端协同自动驾驶的可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring robust planning and decision-making under rare, diverse, and visually degraded long-tail scenarios remains a fundamental challenge for autonomous driving in urban environments. This issue becomes more critical in cooperative settings, where vehicles and infrastructure jointly perceive and reason across complex environments. To address this challenge, we propose V2X-REALM, a vision-language model (VLM)-based framework with adaptive multimodal learning for robust cooperative autonomous driving under long-tail scenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven long-tail scenario generation and evaluation pipeline that leverages foundation models to synthesize realistic long-tail conditions such as snow and fog across vehicle- and infrastructure-side views, enriching training diversity efficiently; (ii) a gated multi-scenario adaptive attention module that modulates the visual stream using scenario priors to recalibrate ambiguous or corrupted features; and (iii) a multi-task scenario-aware contrastive learning objective that improves multimodal alignment and promotes cross-scenario feature separability. Extensive experiments demonstrate that V2X-REALM significantly outperforms existing baselines in robustness, semantic reasoning, safety, and planning accuracy under complex, challenging driving conditions, advancing the scalability of end-to-end cooperative autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring robust planning and decision-making under rare, diverse, andvisually degraded long-tail scenarios remains a fundamental challenge forautonomous driving in urban environments. This issue becomes more critical incooperative settings, where vehicles and infrastructure jointly perceive andreason across complex environments. To address this challenge, we proposeV2X-REALM, a vision-language model (VLM)-based framework with adaptivemultimodal learning for robust cooperative autonomous driving under long-tailscenarios. V2X-REALM introduces three core innovations: (i) a prompt-drivenlong-tail scenario generation and evaluation pipeline that leverages foundationmodels to synthesize realistic long-tail conditions such as snow and fog acrossvehicle- and infrastructure-side views, enriching training diversityefficiently; (ii) a gated multi-scenario adaptive attention module thatmodulates the visual stream using scenario priors to recalibrate ambiguous orcorrupted features; and (iii) a multi-task scenario-aware contrastive learningobjective that improves multimodal alignment and promotes cross-scenariofeature separability. Extensive experiments demonstrate that V2X-REALMsignificantly outperforms existing baselines in robustness, semantic reasoning,safety, and planning accuracy under complex, challenging driving conditions,advancing the scalability of end-to-end cooperative autonomous driving.</description>
      <author>example@mail.com (Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran)</author>
      <guid isPermaLink="false">2506.21041v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction</title>
      <link>http://arxiv.org/abs/2506.21401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/zhirui-gao/Curve-Gaussian Accepted by ICCV  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从多视角边缘图中直接重建3D参数曲线的端到端框架。&lt;h4&gt;背景&lt;/h4&gt;与现有的两阶段方法（边点云重建和参数曲线拟合）相比，本文提出的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由于不同阶段之间固有的优化差距导致的误差累积。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够保留几何属性并允许可微渲染的辅助表示，以解决参数曲线不适用于基于渲染的多视图优化的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双向耦合机制，将参数曲线与边缘导向的高斯成分相结合，形成了一种曲线感知的高斯表示（CurveGaussian），它允许3D曲线的可微渲染，并通过多视角证据直接优化。此外，引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。&lt;h4&gt;主要发现&lt;/h4&gt;在ABC数据集和真实世界基准测试中，该方法在产生更干净、更稳健的重构方面优于两阶段方法。&lt;h4&gt;结论&lt;/h4&gt;与现有方法相比，该方法通过直接优化参数曲线，在训练过程中显著减少了参数数量，实现了更高的效率和更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从多视角边缘图中直接重建3D参数曲线的端到端框架。与现有的两阶段方法（边点云重建和参数曲线拟合）相比，本文提出的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由于不同阶段之间固有的优化差距导致的误差累积。然而，参数曲线本质上不适合基于渲染的多视图优化，需要一种辅助表示来保留其几何属性同时允许可微渲染。我们提出了一种新的双向耦合机制，将参数曲线与边缘导向的高斯成分相结合，形成了一种曲线感知的高斯表示（CurveGaussian），它允许3D曲线的可微渲染，并通过多视角证据直接优化。此外，引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。在ABC数据集和真实世界基准测试中，该方法在产生更干净、更稳健的重构方面优于两阶段方法。与现有方法相比，该方法通过直接优化参数曲线，在训练过程中显著减少了参数数量，实现了更高的效率和更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an end-to-end framework for reconstructing 3D parametriccurves directly from multi-view edge maps. Contrasting with existing two-stagemethods that follow a sequential ``edge point cloud reconstruction andparametric curve fitting'' pipeline, our one-stage approach optimizes 3Dparametric curves directly from 2D edge maps, eliminating error accumulationcaused by the inherent optimization gap between disconnected stages. However,parametric curves inherently lack suitability for rendering-based multi-viewoptimization, necessitating a complementary representation that preserves theirgeometric properties while enabling differentiable rendering. We propose anovel bi-directional coupling mechanism between parametric curves andedge-oriented Gaussian components. This tight correspondence formulates acurve-aware Gaussian representation, \textbf{CurveGaussian}, that enablesdifferentiable rendering of 3D curves, allowing direct optimization guided bymulti-view evidence. Furthermore, we introduce a dynamically adaptive topologyoptimization framework during training to refine curve structures throughlinearization, merging, splitting, and pruning operations. Comprehensiveevaluations on the ABC dataset and real-world benchmarks demonstrate ourone-stage method's superiority over two-stage alternatives, particularly inproducing cleaner and more robust reconstructions. Additionally, by directlyoptimizing parametric curves, our method significantly reduces the parametercount during training, achieving both higher efficiency and superiorperformance compared to existing approaches.</description>
      <author>example@mail.com (Zhirui Gao. Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu)</author>
      <guid isPermaLink="false">2506.21401v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>FedSC: Federated Learning with Semantic-Aware Collaboration</title>
      <link>http://arxiv.org/abs/2506.21012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了联邦学习中的语义感知协作（FedSC）方法，旨在解决数据异质性问题，通过捕捉客户端特定的和类别相关的知识来提高联邦学习的性能。&lt;h4&gt;背景&lt;/h4&gt;联邦学习旨在保护隐私的同时协同训练模型，但数据异质性问题，即多个客户端的标签偏好偏差，是主要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;利用客户端内部的语义有意义的知识来处理数据异质性。&lt;h4&gt;方法&lt;/h4&gt;FedSC通过构建语义层面的关系原型和一致性原型来捕捉客户端特定的和类别相关的知识，引入了跨对比学习策略来拉近实例级嵌入与关系原型的距离，并通过差异聚合方式设计一致性原型作为局部模型优化的正则化惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;FedSC在多个具有挑战性的场景中展示了有效性，并且关键组件的效率也得到了提高。&lt;h4&gt;结论&lt;/h4&gt;FedSC方法为解决联邦学习中的数据异质性问题提供了一种有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3736957&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) aims to train models collaboratively across clientswithout sharing data for privacy-preserving. However, one major challenge isthe data heterogeneity issue, which refers to the biased labeling preferencesat multiple clients. A number of existing FL methods attempt to tackle dataheterogeneity locally (e.g., regularizing local models) or globally (e.g.,fine-tuning global model), often neglecting inherent semantic informationcontained in each client. To explore the possibility of using intra-clientsemantically meaningful knowledge in handling data heterogeneity, in thispaper, we propose Federated Learning with Semantic-Aware Collaboration (FedSC)to capture client-specific and class-relevant knowledge across heterogeneousclients. The core idea of FedSC is to construct relational prototypes andconsistent prototypes at semantic-level, aiming to provide fruitful classunderlying knowledge and stable convergence signals in a prototype-wisecollaborative way. On the one hand, FedSC introduces an inter-contrastivelearning strategy to bring instance-level embeddings closer to relationalprototypes with the same semantics and away from distinct classes. On the otherhand, FedSC devises consistent prototypes via a discrepancy aggregation manner,as a regularization penalty to constrain the optimization region of the localmodel. Moreover, a theoretical analysis for FedSC is provided to ensure aconvergence guarantee. Experimental results on various challenging scenariosdemonstrate the effectiveness of FedSC and the efficiency of crucialcomponents.</description>
      <author>example@mail.com (Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen)</author>
      <guid isPermaLink="false">2506.21012v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Demystifying Distributed Training of Graph Neural Networks for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.20818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE ICDCS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式图神经网络（GNN）在链接预测任务中的性能问题，提出了一种名为SpLPG的方法，通过图稀疏化技术降低通信成本，同时保持链接预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;分布式GNN框架和系统增强了GNN的可扩展性和模型训练速度，但大多数优化针对节点分类，其链接预测性能未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;揭示分布式训练GNN进行链接预测时性能退化的原因，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过研究每个工作节点在其分配的子图上训练GNN时，由于无法访问整个图而导致的性能退化问题。提出SpLPG方法，利用图稀疏化技术减少通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;性能退化的主要原因是图划分引起的信息损失以及模型训练中负样本抽取的方式。&lt;h4&gt;结论&lt;/h4&gt;SpLPG方法通过共享完整图信息解决了性能退化问题，同时降低了通信成本，实验结果表明其可以减少高达80%的通信开销，同时保持链接预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are powerful tools for solving graph-related problems. Distributed GNN frameworks and systems enhance the scalability of GNNs and accelerate model training, yet most are optimized for node classification. Their performance on link prediction remains underexplored. This paper demystifies distributed training of GNNs for link prediction by investigating the issue of performance degradation when each worker trains a GNN on its assigned partitioned subgraph without having access to the entire graph. We discover that the main sources of the issue come from not only the information loss caused by graph partitioning but also the ways of drawing negative samples during model training. While sharing the complete graph information with each worker resolves the issue and preserves link prediction accuracy, it incurs a high communication cost. We propose SpLPG, which effectively leverages graph sparsification to mitigate the issue of performance degradation at a reduced communication cost. Experiment results on several public real-world datasets demonstrate the effectiveness of SpLPG, which reduces the communication overhead by up to about 80% while mostly preserving link prediction accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful tools for solving graph-relatedproblems. Distributed GNN frameworks and systems enhance the scalability ofGNNs and accelerate model training, yet most are optimized for nodeclassification. Their performance on link prediction remains underexplored.This paper demystifies distributed training of GNNs for link prediction byinvestigating the issue of performance degradation when each worker trains aGNN on its assigned partitioned subgraph without having access to the entiregraph. We discover that the main sources of the issue come from not only theinformation loss caused by graph partitioning but also the ways of drawingnegative samples during model training. While sharing the complete graphinformation with each worker resolves the issue and preserves link predictionaccuracy, it incurs a high communication cost. We propose SpLPG, whicheffectively leverages graph sparsification to mitigate the issue of performancedegradation at a reduced communication cost. Experiment results on severalpublic real-world datasets demonstrate the effectiveness of SpLPG, whichreduces the communication overhead by up to about 80% while mostly preservinglink prediction accuracy.</description>
      <author>example@mail.com (Xin Huang, Chul-Ho Lee)</author>
      <guid isPermaLink="false">2506.20818v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Sub-action Tree for Continuous Sign Language Recognition</title>
      <link>http://arxiv.org/abs/2506.20947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了HST-CSLR，即层次子动作树连续手语识别方法，用于将未剪辑的视频转录为文本词汇，以解决手语识别领域的数据集和标注不足的问题。&lt;h4&gt;背景&lt;/h4&gt;连续手语识别（CSLR）由于缺乏大型数据集和精确标注而面临瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来有效地结合词汇知识与视觉表示学习，提高手语识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;构建了一个层次子动作树（HST）用于文本信息表示，逐步对视觉和文本模态进行对齐，并利用树结构来降低计算复杂度。此外，采用对比对齐增强来弥合两种模态之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;实验在四个数据集上证明了HST-CSLR的有效性。&lt;h4&gt;结论&lt;/h4&gt;HST-CSLR能够有效结合词汇知识，提高连续手语识别的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous sign language recognition (CSLR) aims to transcribe untrimmedvideos into glosses, which are typically textual words. Recent studies indicatethat the lack of large datasets and precise annotations has become a bottleneckfor CSLR due to insufficient training data. To address this, some works havedeveloped cross-modal solutions to align visual and textual modalities.However, they typically extract textual features from glosses without fullyutilizing their knowledge. In this paper, we propose the HierarchicalSub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledgewith visual representation learning. By incorporating gloss-specific knowledgefrom large language models, our approach leverages textual information moreeffectively. Specifically, we construct an HST for textual informationrepresentation, aligning visual and textual modalities step-by-step andbenefiting from the tree structure to reduce computational complexity.Additionally, we impose a contrastive alignment enhancement to bridge the gapbetween the two modalities. Experiments on four datasets (PHOENIX-2014,PHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate theeffectiveness of our HST-CSLR.</description>
      <author>example@mail.com (Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu)</author>
      <guid isPermaLink="false">2506.20947v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.21006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种结合Segment Anything Model (SAM)和Forward-Forward Contrastive Learning (FFCL)的深度学习框架，用于提高乳腺癌手术中肿瘤边缘评估的准确性和速度。&lt;h4&gt;背景&lt;/h4&gt;目前评估术中肿瘤边缘状态的方法是2D标本放射摄影（SR），但该方法准确性有限，导致近四分之一的病人需要额外的手术。&lt;h4&gt;目的&lt;/h4&gt;提高乳腺癌手术中肿瘤边缘评估的准确性和速度，以减少复发率。&lt;h4&gt;方法&lt;/h4&gt;使用FFCL预训练ResNet-18骨干网络进行边缘状态分类，然后使用SAM进行精细的肿瘤边缘分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在边缘分类上达到了0.8455的AUC，相较于基线模型在Dice相似性上提高了27.4%，同时将推理时间缩短到每张图像47毫秒。&lt;h4&gt;结论&lt;/h4&gt;FFCL-SAM显著提高了术中边缘评估的速度和准确性，有潜力减少再次手术率并改善乳腺癌治疗效果。&lt;h4&gt;翻译&lt;/h4&gt;Complete removal of cancer tumors with a negative specimen margin during lumpectomy is essential in reducing breast cancer recurrence. However, 2D specimen radiography (SR), the current method used to assess intraoperative specimen margin status, has limited accuracy, resulting in nearly a quarter of patients requiring additional surgery. To address this, we propose a novel deep learning framework combining the Segment Anything Model (SAM) with Forward-Forward Contrastive Learning (FFCL), a pre-training strategy leveraging both local and global contrastive learning for patch-level classification of SR images. After annotating SR images with regions of known malignancy, non-malignant tissue, and pathology-confirmed margins, we pre-train a ResNet-18 backbone with FFCL to classify margin status, then reconstruct coarse binary masks to prompt SAM for refined tumor margin segmentation. Our approach achieved an AUC of 0.8455 for margin classification and segmented margins with a 27.4% improvement in Dice similarity over baseline models, while reducing inference time to 47 milliseconds per image. These results demonstrate that FFCL-SAM significantly enhances both the speed and accuracy of intraoperative margin assessment, with strong potential to reduce re-excision rates and improve surgical outcomes in breast cancer treatment. Our code is available at https://github.com/tbwa233/FFCL-SAM/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complete removal of cancer tumors with a negative specimen margin duringlumpectomy is essential in reducing breast cancer recurrence. However, 2Dspecimen radiography (SR), the current method used to assess intraoperativespecimen margin status, has limited accuracy, resulting in nearly a quarter ofpatients requiring additional surgery. To address this, we propose a novel deeplearning framework combining the Segment Anything Model (SAM) withForward-Forward Contrastive Learning (FFCL), a pre-training strategy leveragingboth local and global contrastive learning for patch-level classification of SRimages. After annotating SR images with regions of known maligancy,non-malignant tissue, and pathology-confirmed margins, we pre-train a ResNet-18backbone with FFCL to classify margin status, then reconstruct coarse binarymasks to prompt SAM for refined tumor margin segmentation. Our approachachieved an AUC of 0.8455 for margin classification and segmented margins witha 27.4% improvement in Dice similarity over baseline models, while reducinginference time to 47 milliseconds per image. These results demonstrate thatFFCL-SAM significantly enhances both the speed and accuracy of intraoperativemargin assessment, with strong potential to reduce re-excision rates andimprove surgical outcomes in breast cancer treatment. Our code is available athttps://github.com/tbwa233/FFCL-SAM/.</description>
      <author>example@mail.com (Tyler Ward, Xiaoqin Wang, Braxton McFarland, Md Atik Ahamed, Sahar Nozad, Talal Arshad, Hafsa Nebbache, Jin Chen, Abdullah Imran)</author>
      <guid isPermaLink="false">2506.21006v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster</title>
      <link>http://arxiv.org/abs/2506.21263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DiLoCoX，一种低通信的大规模去中心化集群训练框架，用于解决大规模语言模型（LLMs）在慢速网络上的训练问题。&lt;h4&gt;背景&lt;/h4&gt;分布式训练大型语言模型需要大量的通信，通常依赖于高速可靠的集中式集群。&lt;h4&gt;目的&lt;/h4&gt;探讨在慢速网络上进行训练，释放去中心化集群在处理超过1000亿参数模型时的潜力。&lt;h4&gt;方法&lt;/h4&gt;DiLoCoX结合了管道并行、双重优化策略、一步延迟通信重叠和本地训练，以及自适应梯度压缩方案。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，一步延迟通信重叠和本地训练以及自适应梯度压缩方案具有优势，并通过实证研究证明了DiLoCoX能够在1Gbps网络上预训练107B的基准模型。&lt;h4&gt;结论&lt;/h4&gt;与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的速度提升，同时模型收敛的下降可以忽略不计。DiLoCoX是第一个成功应用于超过1000亿参数模型的去中心化训练框架。&lt;h4&gt;翻译&lt;/h4&gt;The distributed training of foundation models, particularly large languagemodels (LLMs), demands a high level of communication. Consequently, it ishighly dependent on a centralized cluster with fast and reliable interconnects.Can we conduct training on slow networks and thereby unleash the power ofdecentralized clusters when dealing with models exceeding 100 billionparameters? In this paper, we propose DiLoCoX, a low-communication large-scaledecentralized cluster training framework. It combines Pipeline Parallelism withDual Optimizer Policy, One-Step-Delay Overlap of Communication and LocalTraining, and an Adaptive Gradient Compression Scheme. This combinationsignificantly improves the scale of parameters and the speed of modelpre-training. We justify the benefits of one-step-delay overlap of communicationand local training, as well as the adaptive gradient compression scheme, through atheoretical analysis of convergence. Empirically, we demonstrate that DiLoCoX iscapable of pre-training a 107B foundation model over a 1Gbps network. Compared tovanilla AllReduce, DiLoCoX can achieve a 357xspeedup in distributed training while maintaining negligible degradation inmodel convergence. To the best of our knowledge, this is the firstdecentralized training framework successfully applied to models with over 100billion parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The distributed training of foundation models, particularly large languagemodels (LLMs), demands a high level of communication. Consequently, it ishighly dependent on a centralized cluster with fast and reliable interconnects.Can we conduct training on slow networks and thereby unleash the power ofdecentralized clusters when dealing with models exceeding 100 billionparameters? In this paper, we propose DiLoCoX, a low-communication large-scaledecentralized cluster training framework. It combines Pipeline Parallelism withDual Optimizer Policy, One-Step-Delay Overlap of Communication and LocalTraining, and an Adaptive Gradient Compression Scheme. This combinationsignificantly improves the scale of parameters and the speed of modelpre-training. We justify the benefits of one-step-delay overlap ofcommunication and local training, as well as the adaptive gradient compressionscheme, through a theoretical analysis of convergence. Empirically, wedemonstrate that DiLoCoX is capable of pre-training a 107B foundation modelover a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357xspeedup in distributed training while maintaining negligible degradation inmodel convergence. To the best of our knowledge, this is the firstdecentralized training framework successfully applied to models with over 100billion parameters.</description>
      <author>example@mail.com (Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich)</author>
      <guid isPermaLink="false">2506.21263v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation</title>
      <link>http://arxiv.org/abs/2506.21206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种预处理技术，用于生成高质量粒子分布，适用于二维和三维几何形状，特别是针对平滑粒子流体动力学（SPH）和其他基于粒子的方法。&lt;h4&gt;背景&lt;/h4&gt;在复杂几何形状中进行稳定和准确的粒子模拟面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种预处理技术，以优化基于粒子的模拟，尤其是SPH。&lt;h4&gt;方法&lt;/h4&gt;该方法包括以下步骤：1）使用基于面的邻域搜索在几何形状表面附近生成分辨率自适应的点云；2）通过点云生成有符号距离场，实现表面区域的高效、局部计算；3）应用分层缠绕数方法创建初始粒子配置；4）使用SPH启发的方案松弛粒子位置，同时打包边界粒子，确保全核支持和各向同性分布，同时保留几何界面；5）该方法利用基于粒子的方法的无网格特性，无需连接信息，易于集成到现有的基于粒子的框架中。&lt;h4&gt;主要发现&lt;/h4&gt;该技术对不完美的输入几何形状鲁棒，内存高效，且性能不受影响。实验表明，随着分辨率越来越高，生成的粒子分布收敛到精确的几何形状。&lt;h4&gt;结论&lt;/h4&gt;该预处理技术能够为基于粒子的模拟提供高质量的粒子分布，适用于复杂几何形状，且易于集成和高效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obtaining high-quality particle distributions for stable and accurateparticle-based simulations poses significant challenges, especially for complexgeometries. We introduce a preprocessing technique for 2D and 3D geometries,optimized for smoothed particle hydrodynamics (SPH) and other particle-basedmethods. Our pipeline begins with the generation of a resolution-adaptive pointcloud near the geometry's surface employing a face-based neighborhood search.This point cloud forms the basis for a signed distance field, enablingefficient, localized computations near surface regions. To create an initialparticle configuration, we apply a hierarchical winding number method for fastand accurate inside-outside segmentation. Particle positions are then relaxedusing an SPH-inspired scheme, which also serves to pack boundary particles.This ensures full kernel support and promotes isotropic distributions whilepreserving the geometry interface. By leveraging the meshless nature ofparticle-based methods, our approach does not require connectivity informationand is thus straightforward to integrate into existing particle-basedframeworks. It is robust to imperfect input geometries and memory-efficientwithout compromising performance. Moreover, our experiments demonstrate thatwith increasingly higher resolution, the resulting particle distributionconverges to the exact geometry.</description>
      <author>example@mail.com (Niklas S. Neher, Erik Faulhaber, Sven Berger, Christian Weißenfels, Gregor J. Gassner, Michael Schlottke-Lakemper)</author>
      <guid isPermaLink="false">2506.21206v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs</title>
      <link>http://arxiv.org/abs/2506.20980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RASH的新型对比学习框架，用于在异构图中捕捉节点异质性，同时解决异构性和异质性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;现实世界网络通常具有节点异质性的特性，即连接的节点通常具有不同的特征或标签。在异构图中捕捉节点异质性是一个挑战，因为需要考虑节点/边异质性和节点异质性。&lt;h4&gt;目的&lt;/h4&gt;提出RASH框架，以解决在异构图中捕捉节点异质性的问题，并保持异构关系的潜在异质性。&lt;h4&gt;方法&lt;/h4&gt;RASH通过引入双重异构超图来编码多关系双图子图，并根据关系重要性动态构建同质图和异质图。此外，设计了一种多关系对比损失函数，通过最大化互信息来对齐异构和同质/异质视图。&lt;h4&gt;主要发现&lt;/h4&gt;RASH在基准数据集上进行了广泛的实验，证明了其在各种下游任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;RASH同时解决了异构图中的异质性和异质性的挑战，并在多个任务中展示了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的网络通常具有节点异质性的特性，即连接的节点通常具有不同的特征或标签。这种异质性问题在同构图中被广泛研究，但在存在多种节点和边的异构图中的研究仍然很少。在异构图中捕捉节点异质性非常具有挑战性，因为需要仔细考虑节点/边异质性和节点异质性。现有的方法通常将异构图转换为同构图来学习节点异质性，这不可避免地会失去由异构关系传达的潜在异质性。为了弥合这一差距，我们提出了关系感知的同质性和异质性分离（RASH），这是一种新的对比学习框架，它明确地建模了异构交互的高阶语义，并自适应地分离同质性和异质性模式。特别是，RASH引入了双重异构超图来编码多关系双图子图，并根据关系重要性动态构建同质图和异质图。设计了一种多关系对比损失函数，通过最大化互信息来对齐异构和同质/异质视图。这样，RASH同时解决了异构图中的异质性和异质性的挑战。在基准数据集上进行的广泛实验证明了RASH在各种下游任务中的有效性。代码可在以下网址找到：https://github.com/zhengziyu77/RASH。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world networks usually have a property of node heterophily, that is, theconnected nodes usually have different features or different labels. Thisheterophily issue has been extensively studied in homogeneous graphs butremains under-explored in heterogeneous graphs, where there are multiple typesof nodes and edges. Capturing node heterophily in heterogeneous graphs is verychallenging since both node/edge heterogeneity and node heterophily should becarefully taken into consideration. Existing methods typically convertheterogeneous graphs into homogeneous ones to learn node heterophily, whichwill inevitably lose the potential heterophily conveyed by heterogeneousrelations. To bridge this gap, we propose Relation-Aware Separation ofHomophily and Heterophily (RASH), a novel contrastive learning framework thatexplicitly models high-order semantics of heterogeneous interactions andadaptively separates homophilic and heterophilic patterns. Particularly, RASHintroduces dual heterogeneous hypergraphs to encode multi-relational bipartitesubgraphs and dynamically constructs homophilic graphs and heterophilic graphsbased on relation importance. A multi-relation contrastive loss is designed toalign heterogeneous and homophilic/heterophilic views by maximizing mutualinformation. In this way, RASH simultaneously resolves the challenges ofheterogeneity and heterophily in heterogeneous graphs. Extensive experiments onbenchmark datasets demonstrate the effectiveness of RASH across variousdownstream tasks. The code is available at:https://github.com/zhengziyu77/RASH.</description>
      <author>example@mail.com (Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu)</author>
      <guid isPermaLink="false">2506.20980v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision</title>
      <link>http://arxiv.org/abs/2506.20850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的对比学习框架，用于提升医学视觉领域中的像素级自监督预训练。&lt;h4&gt;背景&lt;/h4&gt;对比学习在自监督预训练中已成为基础模型的关键，但将其扩展到像素级表示在医学视觉中仍是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;解决标准对比学习中过度追求特征分散导致的问题，以及破坏像素级特征相关性和类内分布的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种向量对比学习（vector CL），将其重新定义为向量回归问题，通过回归位移向量来建模特征距离，以量化像素级预训练中的分散度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的COntrast in VEctor Regression (COVER)框架通过基于向量的自学习、一致的优化流程以及向量金字塔架构来实现这一新范式，从而在自监督预训练中保留了像素级特征相关性。&lt;h4&gt;结论&lt;/h4&gt;在8个跨越2个维度和4个模态的任务上的广泛实验表明，COVER显著提高了像素级自监督预训练，推进了可推广的医学视觉基础模型。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning (CL) has become a cornerstone of self-supervised pretraining (SSP) in foundation models, however, extending CL to pixel-wise representation, crucial for medical vision, remains an open problem. Standard CL formulates SSP as a binary optimization problem (binary CL) where the excessive pursuit of feature dispersion leads to an over-dispersion problem, breaking pixel-wise feature correlation thus disrupting the intra-class distribution. Our vector CL reformulates CL as a vector regression problem, enabling dispersion quantification in pixel-wise pretraining via modeling feature distances in regressing displacement vectors. To implement this novel paradigm, we propose the COntrast in VEctor Regression (COVER) framework. COVER establishes an extendable vector-based self-learning, enforces a consistent optimization flow from vector regression to distance modeling, and leverages a vector pyramid architecture for granularity adaptation, thus preserving pixel-wise feature correlations in SSP. Extensive experiments across 8 tasks, spanning 2 dimensions and 4 modalities, show that COVER significantly improves pixel-wise SSP, advancing generalizable medical visual foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has become a cornerstone of self-supervisedpretraining (SSP) in foundation models, however, extending CL to pixel-wiserepresentation, crucial for medical vision, remains an open problem. StandardCL formulates SSP as a binary optimization problem (binary CL) where theexcessive pursuit of feature dispersion leads to an over-dispersion problem,breaking pixel-wise feature correlation thus disrupting the intra-classdistribution. Our vector CL reformulates CL as a vector regression problem,enabling dispersion quantification in pixel-wise pretraining via modelingfeature distances in regressing displacement vectors. To implement this novelparadigm, we propose the COntrast in VEctor Regression (COVER) framework. COVERestablishes an extendable vector-based self-learning, enforces a consistentoptimization flow from vector regression to distance modeling, and leverages avector pyramid architecture for granularity adaptation, thus preservingpixel-wise feature correlations in SSP. Extensive experiments across 8 tasks,spanning 2 dimensions and 4 modalities, show that COVER significantly improvespixel-wise SSP, advancing generalizable medical visual foundation models.</description>
      <author>example@mail.com (Yuting He, Shuo Li)</author>
      <guid isPermaLink="false">2506.20850v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Representation Learning for Additive Rule Ensembles</title>
      <link>http://arxiv.org/abs/2506.20927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于逻辑命题和可学习稀疏线性变换的规则集成方法，以提高预测模型的可解释性和效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于简单阈值命题的规则集成方法在可解释性上具有优势，但需要大量的独立输入特征，且当缺乏这些特征时，增加规则数量和复杂性会降低模型的可解释性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入可学习稀疏线性变换的逻辑命题，扩展经典规则集成方法，以构建更可解释且高效的预测模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于迭代加权的逻辑回归的序列贪婪优化学习方法，用于构建规则集成模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在保持测试风险与最先进方法相当的同时，显著降低了模型在多个基准数据集上的复杂性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地构建了具有高可解释性和效率的规则集成模型，为预测建模提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small additive ensembles of symbolic rules offer interpretable predictionmodels. Traditionally, these ensembles use rule conditions based onconjunctions of simple threshold propositions $x \geq t$ on a single inputvariable $x$ and threshold $t$, resulting geometrically in axis-parallelpolytopes as decision regions. While this form ensures a high degree ofinterpretability for individual rules and can be learned efficiently using thegradient boosting approach, it relies on having access to a curated set ofexpressive and ideally independent input features so that a small ensemble ofaxis-parallel regions can describe the target variable well. Absent suchfeatures, reaching sufficient accuracy requires increasing the number andcomplexity of individual rules, which diminishes the interpretability of themodel. Here, we extend classical rule ensembles by introducing logicalpropositions with learnable sparse linear transformations of input variables,i.e., propositions of the form $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$, where$\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions asgeneral polytopes with oblique faces. We propose a learning method usingsequential greedy optimization based on an iteratively reweighted formulationof logistic regression. Experimental results demonstrate that the proposedmethod efficiently constructs rule ensembles with the same test risk asstate-of-the-art methods while significantly reducing model complexity acrossten benchmark datasets.</description>
      <author>example@mail.com (Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley)</author>
      <guid isPermaLink="false">2506.20927v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization</title>
      <link>http://arxiv.org/abs/2506.20841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FixCLR的半监督领域泛化方法，用于解决在标签稀缺的情况下，如何将模型泛化到分布外数据的问题。&lt;h4&gt;背景&lt;/h4&gt;由于标签稀缺，现有的领域泛化方法往往表现不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入FixCLR方法，解决现有方法未明确正则化学习领域不变表示的问题。&lt;h4&gt;方法&lt;/h4&gt;FixCLR受到自监督学习的启发，通过改变对比学习的两个关键组件来实现：利用伪标签中的类信息和仅使用排斥项。&lt;h4&gt;主要发现&lt;/h4&gt;FixCLR可以添加到大多数现有的半监督方法和领域泛化方法之上，以实现互补的性能提升。实验表明，FixCLR在多种数据集上均表现出色。&lt;h4&gt;结论&lt;/h4&gt;FixCLR是一种有效的半监督领域泛化方法，尤其与其它半监督方法结合时效果更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised domain generalization (SSDG) aims to solve the problem ofgeneralizing to out-of-distribution data when only a few labels are available.Due to label scarcity, applying domain generalization methods oftenunderperform. Consequently, existing SSDG methods combine semi-supervisedlearning methods with various regularization terms. However, these methods donot explicitly regularize to learn domains invariant representations across alldomains, which is a key goal for domain generalization. To address this, weintroduce FixCLR. Inspired by success in self-supervised learning, we changetwo crucial components to adapt contrastive learning for explicit domaininvariance regularization: utilization of class information from pseudo-labelsand using only a repelling term. FixCLR can also be added on top of mostexisting SSDG and semi-supervised methods for complementary performanceimprovements. Our research includes extensive experiments that have not beenpreviously explored in SSDG studies. These experiments include benchmarkingdifferent improvements to semi-supervised methods, evaluating the performanceof pretrained versus non-pretrained models, and testing on datasets with manydomains. Overall, FixCLR proves to be an effective SSDG method, especially whencombined with other semi-supervised methods.</description>
      <author>example@mail.com (Ha Min Son, Shahbaz Rezaei, Xin Liu)</author>
      <guid isPermaLink="false">2506.20841v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis</title>
      <link>http://arxiv.org/abs/2506.20806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Poster accepted at the 10th IEEE European Symposium on Security and  Privacy (Euro S&amp;P 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）增强图神经网络（GNNs）鲁棒性和泛化能力的方法，用于网络入侵检测系统（NIDS），尤其是在物联网环境中。&lt;h4&gt;背景&lt;/h4&gt;GNNs在NIDS中具有巨大潜力，但在物联网环境中，由于分布漂移和对抗攻击的脆弱性，其性能会下降。&lt;h4&gt;目的&lt;/h4&gt;提高GNN在NIDS中的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;通过在代理管道中使用LLMs作为模拟网络安全专家代理，审查从网络流量数据中提取的图结构，识别并可能减轻可疑或被对抗性扰动的元素。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，集成LLM分析可以显著提高基于GNN的NIDS的弹性，展示了LLM代理作为入侵检测架构中辅助层的潜力。&lt;h4&gt;结论&lt;/h4&gt;LLMs在增强GNN鲁棒性和泛化能力方面具有潜力，可以作为NIDS中的一种补充层。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) show great promise for Network IntrusionDetection Systems (NIDS), particularly in IoT environments, but sufferperformance degradation due to distribution drift and lack robustness againstrealistic adversarial attacks. Current robustness evaluations often rely onunrealistic synthetic perturbations and lack demonstrations on systematicanalysis of different kinds of adversarial attack, which encompass bothblack-box and white-box scenarios. This work proposes a novel approach toenhance GNN robustness and generalization by employing Large Language Models(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. Theseagents scrutinize graph structures derived from network flow data, identifyingand potentially mitigating suspicious or adversarially perturbed elementsbefore GNN processing. Our experiments, using a framework designed forrealistic evaluation and testing with a variety of adversarial attacksincluding a dataset collected from physical testbed experiments, demonstratethat integrating LLM analysis can significantly improve the resilience ofGNN-based NIDS against challenges, showcasing the potential of LLM agent as acomplementary layer in intrusion detection architectures.</description>
      <author>example@mail.com (Zhonghao Zhan, Huichi Zhou, Hamed Haddadi)</author>
      <guid isPermaLink="false">2506.20806v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations</title>
      <link>http://arxiv.org/abs/2506.20757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ConViTac的视觉-触觉表示学习网络，用于增强特征融合过程中的特征对齐，并通过对比嵌入条件（CEC）机制提高下游任务的性能。&lt;h4&gt;背景&lt;/h4&gt;视觉和触觉是机器人两种基本的感觉模态，它们提供互补信息，可以增强感知和操作任务。先前的研究尝试联合学习视觉-触觉表示以提取更有意义的信息，但这些方法通常依赖于直接组合，如特征添加和连接，以进行模态融合，这往往导致特征集成不良。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高视觉和触觉融合过程中的特征对齐，从而提升机器人在下游任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为ConViTac的视觉-触觉表示学习网络，该网络使用对比嵌入条件（CEC）机制，通过自监督对比学习预训练的对比编码器将视觉和触觉输入投影到统一的潜在嵌入中。这些嵌入用于通过跨模态注意力耦合视觉-触觉特征融合，旨在对齐统一表示并提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比嵌入条件（CEC）机制，ConViTac在现实世界中的表现优于当前最先进的方法，并且在材料分类和抓取预测任务中，CEC机制使准确性提高了高达12.0%。&lt;h4&gt;结论&lt;/h4&gt;ConViTac网络通过对比嵌入条件（CEC）机制有效地提高了视觉-触觉特征融合的性能，为机器人在感知和操作任务中提供了更强大的支持。&lt;h4&gt;翻译&lt;/h4&gt;Vision and touch are two fundamental sensory modalities for robots, offering complementary information that enhances perception and manipulation tasks. Previous research has attempted to jointly learn visual-tactile representations to extract more meaningful information. However, these approaches often rely on direct combination, such as feature addition and concatenation, for modality fusion, which tend to result in poor feature integration. In this paper, we propose ConViTac, a visual-tactile representation learning network designed to enhance the alignment of features during fusion using contrastive representations. Our key contribution is a Contrastive Embedding Conditioning (CEC) mechanism that leverages a contrastive encoder pretrained through self-supervised contrastive learning to project visual and tactile inputs into unified latent embeddings. These embeddings are used to couple visual-tactile feature fusion through cross-modal attention, aiming at aligning the unified representations and enhancing performance on downstream tasks. We conduct extensive experiments to demonstrate the superiority of ConViTac in real world over current state-of-the-art methods and the effectiveness of our proposed CEC mechanism, which improves accuracy by up to 12.0% in material classification and grasping prediction tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision and touch are two fundamental sensory modalities for robots, offeringcomplementary information that enhances perception and manipulation tasks.Previous research has attempted to jointly learn visual-tactile representationsto extract more meaningful information. However, these approaches often rely ondirect combination, such as feature addition and concatenation, for modalityfusion, which tend to result in poor feature integration. In this paper, wepropose ConViTac, a visual-tactile representation learning network designed toenhance the alignment of features during fusion using contrastiverepresentations. Our key contribution is a Contrastive Embedding Conditioning(CEC) mechanism that leverages a contrastive encoder pretrained throughself-supervised contrastive learning to project visual and tactile inputs intounified latent embeddings. These embeddings are used to couple visual-tactilefeature fusion through cross-modal attention, aiming at aligning the unifiedrepresentations and enhancing performance on downstream tasks. We conductextensive experiments to demonstrate the superiority of ConViTac in real worldover current state-of-the-art methods and the effectiveness of our proposed CECmechanism, which improves accuracy by up to 12.0% in material classificationand grasping prediction tasks.</description>
      <author>example@mail.com (Zhiyuan Wu, Yongqiang Zhao, Shan Luo)</author>
      <guid isPermaLink="false">2506.20757v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Segment Anything in Pathology Images with Natural Language</title>
      <link>http://arxiv.org/abs/2506.20988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PathSegmentor是一种针对病理图像设计的文本提示分割基础模型，解决了当前病理图像分割方法在临床应用中面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;病理图像分割对于分析与癌症诊断和预后相关的组织学特征至关重要，但现有方法由于标注数据有限和类别定义受限而面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出PathSegmentor和PathSeg，以解决病理图像分割中的数据限制和类别定义问题。&lt;h4&gt;方法&lt;/h4&gt;PathSegmentor是一种基于文本提示的分割模型，PathSeg是一个包含275k图像-掩码-标签三元组的数据集，由17个公共来源构建。&lt;h4&gt;主要发现&lt;/h4&gt;PathSegmentor在语义分割任务中表现优于专业模型，具有更高的准确性和更广泛的应用性，同时保持紧凑的架构。它在分割复杂结构和泛化到外部数据集方面表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;PathSegmentor的输出通过特征重要性估计和成像生物标志物发现增强了诊断模型的可解释性，为病理学家提供基于证据的临床决策支持，推动了可解释AI在精准肿瘤学的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理图像分割在计算病理学中对于分析与癌症诊断和预后相关的组织学特征至关重要。然而，由于有限的标注数据和受限的类别定义，当前的方法在临床应用中面临重大挑战。为了解决这些限制，我们提出了PathSegmentor，这是第一个专门为病理图像设计的文本提示分割基础模型。我们还引入了PathSeg，这是用于病理分割的最大和最全面的数据库，由17个公共来源构建，包含275k图像-掩码-标签三元组，跨越160个不同的类别。使用PathSegmentor，用户可以通过自然语言提示执行语义分割，消除了需要繁琐的空间输入，如点或框。广泛的实验表明，PathSegmentor在准确性和适用性方面优于专业模型，同时保持紧凑的架构。它在分割复杂结构和泛化到外部数据集方面分别比现有的空间和文本提示模型高出0.145和0.429的总体Dice分数，显示出强大的鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和成像生物标志物发现增强了诊断模型的可解释性，为病理学家提供基于证据的临床决策支持。这项工作推动了可解释AI在精准肿瘤学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology image segmentation is crucial in computational pathology foranalyzing histological features relevant to cancer diagnosis and prognosis.However, current methods face major challenges in clinical applications due tolimited annotated data and restricted category definitions. To address theselimitations, we propose PathSegmentor, the first text-prompted segmentationfoundation model designed specifically for pathology images. We also introducePathSeg , the largest and most comprehensive dataset for pathologysegmentation, built from 17 public sources and containing 275k image-mask-labeltriples across 160 diverse categories. With PathSegmentor, users can performsemantic segmentation using natural language prompts, eliminating the need forlaborious spatial inputs such as points or boxes. Extensive experimentsdemonstrate that PathSegmentor outperforms specialized models with higheraccuracy and broader applicability, while maintaining a compact architecture.It significantly surpasses existing spatial- and text-prompted models by 0.145and 0.429 in overall Dice scores, respectively, showing strong robustness insegmenting complex structures and generalizing to external datasets. Moreover,PathSegmentor's outputs enhance the interpretability of diagnostic modelsthrough feature importance estimation and imaging biomarker discovery, offeringpathologists evidence-based support for clinical decision-making. This workadvances the development of explainable AI in precision oncology.</description>
      <author>example@mail.com (Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan, Hao Chen)</author>
      <guid isPermaLink="false">2506.20988v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model</title>
      <link>http://arxiv.org/abs/2506.20923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:  substantial text overlap with arXiv:2501.01028&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为KaLM-Embedding-V2的多功能紧凑型嵌入模型，在通用文本嵌入任务中表现出色，这得益于卓越的训练技术和数据。&lt;h4&gt;背景&lt;/h4&gt;为了在文本嵌入任务中取得更好的表现，研究人员开发了新的嵌入模型。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够高效处理通用文本嵌入任务的嵌入模型。&lt;h4&gt;方法&lt;/h4&gt;1) 修改架构以更好地与表示学习对齐，采用全双向变换器和均值池化来产生固定长度的嵌入。2) 实施多阶段训练流程：在大型弱监督开源语料库上预训练，在高质量检索和非检索数据集上微调，以及模型支持参数平均以实现鲁棒泛化。3) 引入聚焦样式的重加权机制和在线困难负样本混合策略。4) 收集超过20种数据类别进行预训练和100种数据类别进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在MTEB（大规模文本嵌入基准）的中文和英语评估中，KaLM-Embedding-V2模型显著优于同类大小的其他模型，并能与参数量大的模型相媲美，为具有小于1B参数的多功能紧凑型嵌入模型树立了新标准。&lt;h4&gt;结论&lt;/h4&gt;KaLM-Embedding-V2模型在通用文本嵌入任务中表现出色，为紧凑型嵌入模型提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了KaLM-Embedding-V2，一种通用且紧凑的嵌入模型。通过利用优越的训练技术和数据，它在通用文本嵌入任务中取得了令人印象深刻的性能。我们的关键创新包括：（1）为了更好地将架构与表示学习对齐，我们去掉了因果注意力掩码，并采用了一个简单但有效的全双向变换器和均值池化来生成固定长度的嵌入；（2）我们采用了一个多阶段训练流程：（i）在大型弱监督开源语料库上预训练；（ii）在高质量检索和非检索数据集上微调；（iii）通过模型支持参数平均来实现鲁棒的泛化。此外，我们引入了一种聚焦样式的重加权机制，该机制将学习集中在困难样本上，以及一个在线困难负样本混合策略，以连续丰富困难负样本而不需要进行昂贵的离线挖掘；（3）我们收集了超过20种数据类别用于预训练和100种数据类别用于微调，以提升嵌入模型的性能和泛化能力。在MTEB（大规模文本嵌入基准）的中文和英语评估中，我们的模型显著优于其他同类大小的模型，并能与3x、14x、18x和26x更大的嵌入模型相媲美，为具有小于1B参数的多功能紧凑型嵌入模型设定了新的标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose KaLM-Embedding-V2, a versatile and compactembedding model, which achieves impressive performance in general-purpose textembedding tasks by leveraging superior training techniques and data. Our keyinnovations include: (1) To better align the architecture with representationlearning, we remove the causal attention mask and adopt a fully bidirectionaltransformer with simple yet effective mean-pooling to produce fixed-lengthembeddings; (2) We employ a multi-stage training pipeline: (i) pre-training onlarge-scale weakly supervised open-source corpora; (ii) fine-tuning onhigh-quality retrieval and non-retrieval datasets; and (iii) model-soupparameter averaging for robust generalization. Besides, we introduce afocal-style reweighting mechanism that concentrates learning on difficultsamples and an online hard-negative mixing strategy to continuously enrich hardnegatives without expensive offline mining; (3) We collect over 20 categoriesof data for pre-training and 100 categories of data for fine-tuning, to boostboth the performance and generalization of the embedding model. Extensiveevaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and Englishshow that our model significantly outperforms others of comparable size, andcompetes with 3x, 14x, 18x, and 26x larger embedding models, setting a newstandard for a versatile and compact embedding model with less than 1Bparameters.</description>
      <author>example@mail.com (Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Qian Chen, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, Min Zhang)</author>
      <guid isPermaLink="false">2506.20923v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>scMamba: A Scalable Foundation Model for Single-Cell Multi-Omics Integration Beyond Highly Variable Feature Selection</title>
      <link>http://arxiv.org/abs/2506.20697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;scMamba是一种用于整合单细胞多组学数据的基础模型，能够在不进行预先特征选择的情况下，同时保留基因组位置信息。&lt;h4&gt;背景&lt;/h4&gt;单细胞多组学技术的出现使得在单个细胞中同时分析多种组学层提供了前所未有的见解。然而，现有的方法在预处理阶段通常依赖于选择高度可变的基因或峰，这可能会无意中丢弃重要的生物学信息。&lt;h4&gt;目的&lt;/h4&gt;开发一个不需要预先特征选择的模型来整合单细胞多组学数据，同时保留基因组位置信息。&lt;h4&gt;方法&lt;/h4&gt;scMamba采用基于补丁的细胞标记化策略，将基因组区域视为单词（标记），细胞视为句子。它基于状态空间二重性的概念，从高维、稀疏的单细胞多组学数据中提取丰富的生物学见解。此外，它引入了一种新的对比学习方法，并辅以余弦相似性正则化，使跨组学层的对齐优于传统方法。&lt;h4&gt;主要发现&lt;/h4&gt;scMamba在保留生物学变异、对齐组学层以及增强关键下游任务（如聚类、细胞类型注释和轨迹推理）方面显著优于最先进的方法。系统基准测试表明，scMamba在处理大规模图谱和推进生物学发现方面是一种强大的工具。&lt;h4&gt;结论&lt;/h4&gt;scMamba是一种强大的工具，可以用于大规模单细胞多组学整合，能够处理大规模图谱并推进生物学发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of single-cell multi-omics technologies has enabled thesimultaneous profiling of diverse omics layers within individual cells.Integrating such multimodal data provides unprecedented insights into cellularidentity, regulatory processes, and disease mechanisms. However, it remainschallenging, as current methods often rely on selecting highly variable genesor peaks during preprocessing, which may inadvertently discard crucialbiological information. Here, we present scMamba, a foundation model designedto integrate single-cell multi-omics data without the need for prior featureselection while preserving genomic positional information. scMamba introduces apatch-based cell tokenization strategy that treats genomics regions as words(tokens) and cells as sentences. Building upon the concept of state spaceduality, scMamba distills rich biological insights from high-dimensional,sparse single-cell multi-omics data. Additionally, our novel contrastivelearning approach, enhanced with cosine similarity regularization, enablessuperior alignment across omics layers compared to traditional methods.Systematic benchmarking across multiple datasets demonstrates that scMambasignificantly outperforms state-of-the-art methods in preserving biologicalvariation, aligning omics layers, and enhancing key downstream tasks such asclustering, cell type annotation, and trajectory inference. Our findingsposition scMamba as a powerful tool for large-scale single-cell multi-omicsintegration, capable of handling large-scale atlases and advancing biologicaldiscovery.</description>
      <author>example@mail.com (Zhen Yuan, Shaoqing Jiao, Yihang Xiao, Jiajie Peng)</author>
      <guid isPermaLink="false">2506.20697v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Environment-Based Channel Knowledge Map Construction</title>
      <link>http://arxiv.org/abs/2506.21112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模型和数据驱动的Channel knowledge map (CKM)构建方法，通过利用点云环境数据和少量位置标记的信道信息，提高CKM的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的CKM构建方案采用过于简化的环境信息，这显著降低了其准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来构建CKM，以减少频繁的信道状态信息（CSI）获取的开销，并提高CKM的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种新的点选择器，通过构建基于不同到达时间（ToA）的共焦点椭球体，识别包含与多径信道增益相关的环境信息的点云子集。2. 训练一个神经信道增益估计器，通过使用我们通过现场测量收集的包含环境点云和相应信道数据的真实世界数据集，学习每个选定子集与其对应信道增益之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;1. 对于功率延迟剖面（PDP）的CKM构建，该方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB。2. 对于接收功率值（即无线电地图）的CKM构建，该方法实现了1.04 dB的RMSE，超过了Kriging插值方法的1.68 dB。&lt;h4&gt;结论&lt;/h4&gt;该方法在CKM构建中表现出色，能够显著提高CKM的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Channel知识地图（CKM）为感兴趣区域提供一定级别的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键推动者。然而，现有的CKM构建方案采用过于简化的环境信息，这显著降低了它们的准确性。为了解决这个问题，本研究提出了一种联合模型和数据驱动的方法来构建CKM，通过利用点云环境数据以及少量位置标记的信道信息。首先，我们提出了一种新的点选择器，通过构建基于不同到达时间（ToA）的共焦点椭球体，识别包含与多径信道增益相关的环境信息的点云子集。然后，我们训练了一个神经信道增益估计器，通过使用我们通过现场测量收集的包含环境点云和相应信道数据的真实世界数据集，学习每个选定子集与其对应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提出的方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，该方法实现了1.04 dB的RMSE，超过了Kriging插值方法的1.68 dB。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Channel knowledge map (CKM) provides certain levels of channel stateinformation (CSI) for an area of interest, serving as a critical enabler forenvironment-aware communications by reducing the overhead of frequent CSIacquisition. However, existing CKM construction schemes adopt over-simplifiedenvironment information, which significantly compromises their accuracy. Toaddress this issue, this work proposes a joint model- and data-driven approachto construct CKM by leveraging point cloud environmental data along with a fewsamples of location-tagged channel information. First, we propose a novel pointselector to identify subsets of point cloud that contain environmentalinformation relevant to multipath channel gains, by constructing a set ofco-focal ellipsoids based on different time of arrival (ToAs). Then, we traineda neural channel gain estimator to learn the mapping between each selectedsubset and its corresponding channel gain, using a real-world dataset wecollected through field measurements, comprising environmental point clouds andcorresponding channel data. Finally, experimental results demonstrate that: ForCKM construction of power delay profile (PDP), the proposed method achieves aroot mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dBachieved by the conventional ray-tracing method; for CKM construction ofreceived power values, i.e., radio map, it achieves an RMSE of 1.04 dB,surpassing the Kriging interpolation method with an RMSE of 1.68 dB.</description>
      <author>example@mail.com (Yancheng Wang, Wei Guo, Guanying Chen, Ye Zhang, Shuguang Cui)</author>
      <guid isPermaLink="false">2506.21112v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends</title>
      <link>http://arxiv.org/abs/2506.20966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉语言动作（VLA）模型的后训练策略，从人类运动学习角度出发，重点关注环境、实体和任务三个维度，提出了一个与人类学习机制相一致的结构化分类法。&lt;h4&gt;背景&lt;/h4&gt;VLA模型通过集成动作生成模块扩展了视觉语言模型（VLM），在多样化操作任务中展现出良好的泛化能力。然而，对于需要高精度和准确性的应用，VLA模型在未经进一步适应的情况下存在性能差距。&lt;h4&gt;目的&lt;/h4&gt;旨在通过后训练策略提高VLA模型与特定任务环境交互的能力，类似于人类运动技能的习得过程。&lt;h4&gt;方法&lt;/h4&gt;本文通过类比人类运动学习，从环境感知、实体意识、任务理解和多组件集成四个方面，对VLA模型的后训练策略进行了综述。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，后训练VLA模型的关键挑战和趋势包括环境感知增强、实体意识提升、任务理解深化以及多组件集成。&lt;h4&gt;结论&lt;/h4&gt;本文建立了指导未来研究的概念框架，提供了对当前VLA模型后训练方法的全面概述，并为VLA模型的发展提供了实际见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the post-training strategies for VLA models from the perspective of human motor learning, focusing on three dimensions: environments, embodiments, and tasks. A structured taxonomy is introduced aligned with human learning mechanisms: (1) enhancing environmental perception, (2) improving embodiment awareness, (3) deepening task comprehension, and (4) multi-component integration. Finally, key challenges and trends in post-training VLA models are identified, establishing a conceptual framework to guide future research. This work delivers both a comprehensive overview of current VLA model post-training methods from a human motor learning perspective and practical insights for VLA model development.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action (VLA) models extend vision-language models (VLM) byintegrating action generation modules for robotic manipulation. Leveragingstrengths of VLM in vision perception and instruction understanding, VLA modelsexhibit promising generalization across diverse manipulation tasks. However,applications demanding high precision and accuracy reveal performance gapswithout further adaptation. Evidence from multiple domains highlights thecritical role of post-training to align foundational models with downstreamapplications, spurring extensive research on post-training VLA models. VLAmodel post-training aims to address the challenge of improving an embodiment'sability to interact with the environment for the given tasks, analogous to theprocess of humans motor skills acquisition. Accordingly, this paper reviewspost-training strategies for VLA models through the lens of human motorlearning, focusing on three dimensions: environments, embodiments, and tasks. Astructured taxonomy is introduced aligned with human learning mechanisms: (1)enhancing environmental perception, (2) improving embodiment awareness, (3)deepening task comprehension, and (4) multi-component integration. Finally, keychallenges and trends in post-training VLA models are identified, establishinga conceptual framework to guide future research. This work delivers both acomprehensive overview of current VLA model post-training methods from a humanmotor learning perspective and practical insights for VLA model development.(Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)</description>
      <author>example@mail.com (Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou)</author>
      <guid isPermaLink="false">2506.20966v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization</title>
      <link>http://arxiv.org/abs/2506.20807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 page paper plus Appendices. Accepted to the ES-FoMo "Efficient  Systems for Foundation Models" workshop at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的自动化方法，用于迭代优化GPU内核，以应对针对新或文档不足的GPU架构的挑战。&lt;h4&gt;背景&lt;/h4&gt;优化GPU内核以实现高性能是一个复杂的任务，通常需要深入的架构知识、广泛的性能分析和迭代实验。在针对较新或文档较少的GPU架构时，这一挑战更加明显，因为传统开发工具资源有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化方法，以迭代优化加速器内核，特别是针对资源受限或硬件快速发展的环境。&lt;h4&gt;方法&lt;/h4&gt;该方法采用LLM进行多阶段的进化过程：首先战略性地选择有希望的先前代码版本作为新迭代的起点；其次，基于现有代码和从通用GPU文献中获取的知识生成优化实验的假设；最后，通过代码修改和将实验提交给外部评估系统来自动执行这些实验，仅使用观察到的计时数据作为性能反馈。&lt;h4&gt;主要发现&lt;/h4&gt;详细介绍了该方法如何应对AMD MI300目标架构的挑战，并利用LLM来弥补特定领域人类专业知识的不足。&lt;h4&gt;结论&lt;/h4&gt;由于论文提交日期时，性能竞赛的定量结果被限制，因此本文展示了架构设计、操作工作流程和定性见解，突出了LLM驱动代理在民主化和加速GPU内核优化方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的自动化方法，用于迭代优化GPU内核，以应对针对新或文档不足的GPU架构的挑战。该方法采用LLM进行多阶段的进化过程，首先选择有希望的先前代码版本作为新迭代的起点，然后基于现有代码和从通用GPU文献中获取的知识生成优化实验的假设，最后通过代码修改和将实验提交给外部评估系统来自动执行这些实验，仅使用观察到的计时数据作为性能反馈。详细介绍了该方法如何应对AMD MI300目标架构的挑战，并利用LLM来弥补特定领域人类专业知识的不足。由于论文提交日期时，性能竞赛的定量结果被限制，因此本文展示了架构设计、操作工作流程和定性见解，突出了LLM驱动代理在民主化和加速GPU内核优化方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimizing GPU kernels for high performance is a complex task, oftendemanding deep architectural knowledge, extensive profiling, and iterativeexperimentation. This challenge is amplified when targeting newer orless-documented GPU architectures where traditional development aids arescarce. This paper introduces an LLM-powered "GPU Kernel Scientist," anautomated methodology for iteratively refining accelerator kernels.  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)strategically selecting promising prior code versions as a basis for newiterations; (b) generating hypotheses for optimization experiments, based onexisting code and assimilated knowledge from general GPU literature; and (c)autonomously implementing these experiments through code modification andsubsequent submission to an external evaluation system, using only observedtiming data as performance feedback. We detail how this approach navigates thechallenges of the AMD MI300 target architecture and leverages LLMs tocompensate for limited domain-specific human expertise.  Since quantitative results from an ongoing performance competition wereembargoed on paper submission date, we present the architectural design,operational workflow, and qualitative insights, highlighting the potential ofLLM-driven agents to democratise and accelerate GPU kernel optimization,especially in resource-constrained or rapidly evolving hardware environments.</description>
      <author>example@mail.com (Martin Andrews, Sam Witteveen)</author>
      <guid isPermaLink="false">2506.20807v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG</title>
      <link>http://arxiv.org/abs/2506.20683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to MICCAI 2025 (Springer LNCS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PTACL的多模态对比学习框架，通过整合来自心脏磁共振（CMR）的空间时间信息来增强心电图（ECG）的表现，以改善非侵入性心脏诊断。&lt;h4&gt;背景&lt;/h4&gt;心电图是一种常用的检测心脏电异常的工具，但无法直接测量功能参数，如心室容积和射血分数。心脏磁共振是这些测量的金标准，但成本高且不易获得。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，提出了一种名为PTACL的多模态对比学习框架，以提高ECG表现。&lt;h4&gt;方法&lt;/h4&gt;PTACL使用全局患者级对比损失和局部时间级对比损失。全局损失通过拉近同一患者的ECG和CMR嵌入，推开不同患者的嵌入来对齐患者级表示。局部损失通过对比编码的ECG段与相应的编码CMR帧来强制执行每个患者内的细粒度时间对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在来自英国生物库的27,951个受试者的配对ECG-CMR数据上评估PTACL。与基线方法相比，PTACL在两个临床相关任务中取得了更好的性能：(1)检索具有相似心脏表型的患者和(2)预测由CMR得出的心脏功能参数，如心室容积和射血分数。&lt;h4&gt;结论&lt;/h4&gt;PTACL有望增强使用ECG的非侵入性心脏诊断。&lt;h4&gt;翻译&lt;/h4&gt;An electrocardiogram (ECG) is a widely used, cost-effective tool for detecting electrical abnormalities in the heart. However, it cannot directly measure functional parameters, such as ventricular volumes and ejection fraction, which are crucial for assessing cardiac function. Cardiac magnetic resonance (CMR) is the gold standard for these measurements, providing detailed structural and functional insights, but is expensive and less accessible. To bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive Learning), a multimodal contrastive learning framework that enhances ECG representations by integrating spatio-temporal information from CMR. PTACL uses global patient-level contrastive loss and local temporal-level contrastive loss. The global loss aligns patient-level representations by pulling ECG and CMR embeddings from the same patient closer together, while pushing apart embeddings from different patients. Local loss enforces fine-grained temporal alignment within each patient by contrasting encoded ECG segments with corresponding encoded CMR frames. This approach enriches ECG representations with diagnostic information beyond electrical activity and transfers more insights between modalities than global alignment alone, all without introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL achieves better performance in two clinically relevant tasks: (1) retrieving patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac function parameters, such as ventricular volumes and ejection fraction. Our results highlight the potential of PTACL to enhance non-invasive cardiac diagnostics using ECG. The code is available at: https://github.com/alsalivan/ecgcmr&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An electrocardiogram (ECG) is a widely used, cost-effective tool fordetecting electrical abnormalities in the heart. However, it cannot directlymeasure functional parameters, such as ventricular volumes and ejectionfraction, which are crucial for assessing cardiac function. Cardiac magneticresonance (CMR) is the gold standard for these measurements, providing detailedstructural and functional insights, but is expensive and less accessible. Tobridge this gap, we propose PTACL (Patient and Temporal Alignment ContrastiveLearning), a multimodal contrastive learning framework that enhances ECGrepresentations by integrating spatio-temporal information from CMR. PTACL usesglobal patient-level contrastive loss and local temporal-level contrastiveloss. The global loss aligns patient-level representations by pulling ECG andCMR embeddings from the same patient closer together, while pushing apartembeddings from different patients. Local loss enforces fine-grained temporalalignment within each patient by contrasting encoded ECG segments withcorresponding encoded CMR frames. This approach enriches ECG representationswith diagnostic information beyond electrical activity and transfers moreinsights between modalities than global alignment alone, all withoutintroducing new learnable weights. We evaluate PTACL on paired ECG-CMR datafrom 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACLachieves better performance in two clinically relevant tasks: (1) retrievingpatients with similar cardiac phenotypes and (2) predicting CMR-derived cardiacfunction parameters, such as ventricular volumes and ejection fraction. Ourresults highlight the potential of PTACL to enhance non-invasive cardiacdiagnostics using ECG. The code is available at:https://github.com/alsalivan/ecgcmr</description>
      <author>example@mail.com (Alexander Selivanov, Philip Müller, Özgün Turgut, Nil Stolt-Ansó, Daniel Rückert)</author>
      <guid isPermaLink="false">2506.20683v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>CURL-SLAM: Continuous and Compact LiDAR Mapping</title>
      <link>http://arxiv.org/abs/2506.21077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了3D激光雷达制图，重点开发了一种可更新和可定位的地图表示方法，该方法能够确保3D地图的连续性、紧凑性和一致性。&lt;h4&gt;背景&lt;/h4&gt;传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这在大规模环境中通常需要大量存储空间来保留结构细节。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于连续和超紧凑表示的激光雷达（CURL）的新颖SLAM范式，以实现紧凑的3D地图，并确保在闭环后全局地图的一致性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CURL-SLAM的激光雷达制图方法，它利用CURL的球谐隐式编码产生紧凑的3D地图，并在不同密度下实现连续重建。CURL-SLAM将激光雷达位姿估计作为针对CURL的独特优化问题进行公理化，并将其扩展到局部捆绑调整（BA），以实现位姿和地图的同时优化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CURL-SLAM实现了最先进的3D制图质量，并具有竞争力的激光雷达轨迹精度，在CPU上实现了传感器速率的实时性能（10 Hz）。&lt;h4&gt;结论&lt;/h4&gt;CURL-SLAM将被开源社区发布。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了3D激光雷达制图，重点关注开发一种可更新和可定位的地图表示方法，该方法能够确保3D地图的连续性、紧凑性和一致性。传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这在大规模环境中通常需要大量存储空间来保留结构细节。在本文中，我们通过利用[1]中提出的连续和超紧凑表示的激光雷达（CURL）范式，提出了一种新颖的激光雷达SLAM范式。我们提出的激光雷达制图方法，CURL-SLAM，通过CURL的球谐隐式编码产生紧凑的3D地图，能够在不同密度下实现连续重建，并在闭环后实现全局地图的一致性。与基于迭代最近点（ICP）的激光雷达测距技术不同，CURL-SLAM将激光雷达位姿估计作为针对CURL的独特优化问题进行公理化，并将其扩展到局部捆绑调整（BA），以实现位姿和地图的同时优化。实验结果表明，CURL-SLAM实现了最先进的3D制图质量，并具有竞争力的激光雷达轨迹精度，在CPU上实现了传感器速率的实时性能（10 Hz）。我们将在社区中发布CURL-SLAM的实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies 3D LiDAR mapping with a focus on developing an updatableand localizable map representation that enables continuity, compactness andconsistency in 3D maps. Traditional LiDAR Simultaneous Localization and Mapping(SLAM) systems often rely on 3D point cloud maps, which typically requireextensive storage to preserve structural details in large-scale environments.In this paper, we propose a novel paradigm for LiDAR SLAM by leveraging theContinuous and Ultra-compact Representation of LiDAR (CURL) introduced in [1].Our proposed LiDAR mapping approach, CURL-SLAM, produces compact 3D mapscapable of continuous reconstruction at variable densities using CURL'sspherical harmonics implicit encoding, and achieves global map consistencyafter loop closure. Unlike popular Iterative Closest Point (ICP)-based LiDARodometry techniques, CURL-SLAM formulates LiDAR pose estimation as a uniqueoptimization problem tailored for CURL and extends it to local BundleAdjustment (BA), enabling simultaneous pose refinement and map correction.Experimental results demonstrate that CURL-SLAM achieves state-of-the-art 3Dmapping quality and competitive LiDAR trajectory accuracy, deliveringsensor-rate real-time performance (10 Hz) on a CPU. We will release theCURL-SLAM implementation to the community.</description>
      <author>example@mail.com (Kaicheng Zhang, Shida Xu, Yining Ding, Xianwen Kong, Sen Wang)</author>
      <guid isPermaLink="false">2506.21077v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?</title>
      <link>http://arxiv.org/abs/2506.20795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了将Vision Foundation Models (VFMs) 和Vision Language Models (VLMs) 应用于动态全身手势识别，并评估了不同手势识别方法的性能。&lt;h4&gt;背景&lt;/h4&gt;手势在嘈杂环境中的人机非语言交流中非常重要，传统的手势识别依赖于特定的深度学习架构。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用VFMs和VLMs的泛化能力来减少系统复杂性，并通过比较不同的模型来评估其性能。&lt;h4&gt;方法&lt;/h4&gt;引入了NUGGET数据集，用于评估不同手势识别方法；比较了V-JEPA、Gemini Flash 2.0和HD-GCN三种模型。&lt;h4&gt;主要发现&lt;/h4&gt;HD-GCN在实验中表现最佳，V-JEPA通过简单的任务特定分类头接近最佳性能；Gemini在零样本设置下难以仅根据文本描述区分手势。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，通过使用V-JEPA作为共享的多任务模型，有可能减少系统复杂性，并指出需要进一步研究手势的合适输入表示方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gestures enable non-verbal human-robot communication, especially in noisyenvironments like agile production. Traditional deep learning-based gesturerecognition relies on task-specific architectures using images, videos, orskeletal pose estimates as input. Meanwhile, Vision Foundation Models (VFMs)and Vision Language Models (VLMs) with their strong generalization abilitiesoffer potential to reduce system complexity by replacing dedicatedtask-specific modules. This study investigates adapting such models fordynamic, full-body gesture recognition, comparing V-JEPA (a state-of-the-artVFM), Gemini Flash 2.0 (a multimodal VLM), and HD-GCN (a top-performingskeleton-based approach). We introduce NUGGET, a dataset tailored forhuman-robot communication in intralogistics environments, to evaluate thedifferent gesture recognition approaches. In our experiments, HD-GCN achievesbest performance, but V-JEPA comes close with a simple, task-specificclassification head - thus paving a possible way towards reducing systemcomplexity, by using it as a shared multi-task model. In contrast, Geministruggles to differentiate gestures based solely on textual descriptions in thezero-shot setting, highlighting the need of further research on suitable inputrepresentations for gestures.</description>
      <author>example@mail.com (Stephanie Käs, Anton Burenko, Louis Markert, Onur Alp Culha, Dennis Mack, Timm Linder, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.20795v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools</title>
      <link>http://arxiv.org/abs/2506.20743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型（FMs）在材料科学（MatSci）中的应用，探讨了其在科学发现中的作用，以及支持这一领域的系统、数据集和计算工具。&lt;h4&gt;背景&lt;/h4&gt;基础模型正在推动材料科学领域的变革，它们能够实现可扩展、通用和多模态的人工智能系统，与传统的机器学习模型相比，具有跨领域的泛化能力和涌现能力。&lt;h4&gt;目的&lt;/h4&gt;提供对基础模型、代理系统、数据集和计算工具的全面概述，并评估其在材料科学中的应用。&lt;h4&gt;方法&lt;/h4&gt;介绍了一个涵盖六个主要应用领域的任务驱动分类法，包括数据提取、解释和问答；原子模拟；性质预测；材料结构、设计和发现；工艺规划、发现和优化；以及多尺度建模。讨论了单模态和多模态基础模型的最新进展，以及新兴的大型语言模型（LLM）代理。此外，还回顾了标准化数据集、开源工具和自主实验平台。&lt;h4&gt;主要发现&lt;/h4&gt;评估了基础模型的早期成功，并确定了持续的局限性，包括泛化性、可解释性、数据不平衡、安全问题和多模态融合的局限性。&lt;h4&gt;结论&lt;/h4&gt;提出了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了基础模型在材料科学中的应用，探讨了其在科学发现中的作用，以及支持这一领域的系统、数据集和计算工具。基础模型正在推动材料科学领域的变革，它们能够实现可扩展、通用和多模态的人工智能系统，与传统的机器学习模型相比，具有跨领域的泛化能力和涌现能力。本文提供对基础模型、代理系统、数据集和计算工具的全面概述，并评估其在材料科学中的应用。介绍了一个涵盖六个主要应用领域的任务驱动分类法，包括数据提取、解释和问答；原子模拟；性质预测；材料结构、设计和发现；工艺规划、发现和优化；以及多尺度建模。讨论了单模态和多模态基础模型的最新进展，以及新兴的大型语言模型（LLM）代理。此外，还回顾了标准化数据集、开源工具和自主实验平台。评估了基础模型的早期成功，并确定了持续的局限性，包括泛化性、可解释性、数据不平衡、安全问题和多模态融合的局限性。提出了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) are catalyzing a transformative shift in materialsscience (MatSci) by enabling scalable, general-purpose, and multimodal AIsystems for scientific discovery. Unlike traditional machine learning models,which are typically narrow in scope and require task-specific engineering, FMsoffer cross-domain generalization and exhibit emergent capabilities. Theirversatility is especially well-suited to materials science, where researchchallenges span diverse data types and scales. This survey provides acomprehensive overview of foundation models, agentic systems, datasets, andcomputational tools supporting this growing field. We introduce a task-driventaxonomy encompassing six broad application areas: data extraction,interpretation and Q\&amp;A; atomistic simulation; property prediction; materialsstructure, design and discovery; process planning, discovery, and optimization;and multiscale modeling. We discuss recent advances in both unimodal andmultimodal FMs, as well as emerging large language model (LLM) agents.Furthermore, we review standardized datasets, open-source tools, and autonomousexperimental platforms that collectively fuel the development and integrationof FMs into research workflows. We assess the early successes of foundationmodels and identify persistent limitations, including challenges ingeneralizability, interpretability, data imbalance, safety concerns, andlimited multimodal fusion. Finally, we articulate future research directionscentered on scalable pretraining, continual learning, data governance, andtrustworthiness.</description>
      <author>example@mail.com (Minh-Hao Van, Prateek Verma, Chen Zhao, Xintao Wu)</author>
      <guid isPermaLink="false">2506.20743v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining</title>
      <link>http://arxiv.org/abs/2506.18221v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了迁移学习在机器学习中的关键作用，特别是在使用少量新数据适应新任务时的应用。研究发现了深度学习模型中的一个基本限制，即“信息饱和瓶颈”，并提出了更丰富的特征表示作为潜在解决方案。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是现代机器学习的基础，它允许将在大批量数据上预训练的模型适应新的任务，但确保迁移特征足以处理未见数据集是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;评估从预训练混合模型到其各个组件任务的模型迁移，并确定预训练特征是否能达到特定任务直接训练的性能。&lt;h4&gt;方法&lt;/h4&gt;研究通过评估预训练特征在处理未见数据集时的表现，来识别深度学习模型中的信息饱和瓶颈。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，当网络在训练过程中编码了相似的特征后，它们将无法学习新的特征。此外，这种信息饱和现象在深度学习架构中普遍存在。&lt;h4&gt;结论&lt;/h4&gt;研究建议，当可用时，关注特定任务的训练可能比依赖大规模网络更有效。并提出了一种新的方法来改进新数据集的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习是现代机器学习的基础，它承诺了一种方法，即通过最小的新数据量将在大批量数据上预训练的模型适应到新任务中。然而，确保迁移特征足以处理未见数据集仍然是一个重大挑战，这种挑战因量化两个任务是否“相关”的困难而加剧。为了解决这些挑战，我们评估了从预训练混合模型到其各个组件任务的模型迁移，评估预训练特征是否能匹配特定任务直接训练的性能。我们确定了深度学习模型中的一个基本限制——“信息饱和瓶颈”，其中网络在训练过程中编码了相似的特征后无法学习新的特征。当限制在预训练期间仅学习关键特征子集时，模型将永久失去迁移的临界特征，在数据分布上表现不一致，甚至在训练混合的组成部分上也是如此。来自已发表研究的经验证据表明，这种现象在深度学习架构中普遍存在——数据分布或排序等因素会影响当前表示学习方法随时间学习到的特征。本研究表明，当可用时，仅依赖大规模网络可能不如关注特定任务的训练有效。我们提出了更丰富的特征表示作为潜在解决方案，以更好地泛化到新数据集，并具体介绍了现有方法以及一种新颖的方法，这是解决这一挑战的初步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a cornerstone of modern machine learning, promising away to adapt models pretrained on a broad mix of data to new tasks with minimalnew data. However, a significant challenge remains in ensuring that transferredfeatures are sufficient to handle unseen datasets, amplified by the difficultyof quantifying whether two tasks are "related". To address these challenges, weevaluate model transfer from a pretraining mixture to each of its componenttasks, assessing whether pretrained features can match the performance oftask-specific direct training. We identify a fundamental limitation in deeplearning models -- an "information saturation bottleneck" -- where networksfail to learn new features once they encode similar competing features duringtraining. When restricted to learning only a subset of key features duringpretraining, models will permanently lose critical features for transfer andperform inconsistently on data distributions, even components of the trainingmixture. Empirical evidence from published studies suggests that thisphenomenon is pervasive in deep learning architectures -- factors such as datadistribution or ordering affect the features that current representationlearning methods can learn over time. This study suggests that relying solelyon large-scale networks may not be as effective as focusing on task-specifictraining, when available. We propose richer feature representations as apotential solution to better generalize across new datasets and, specifically,present existing methods alongside a novel approach, the initial steps towardsaddressing this challenge.</description>
      <author>example@mail.com (Xingyu Alice Yang, Jianyu Zhang, Léon Bottou)</author>
      <guid isPermaLink="false">2506.18221v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers</title>
      <link>http://arxiv.org/abs/2506.19686v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Updates: added other funding sources; formatted title correctly&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了人类和动物的学习效率，以及Transformer在模拟情境下强化学习中的应用。&lt;h4&gt;背景&lt;/h4&gt;人类和动物能够以最小的经验适应新环境，但这种能力在标准的强化学习算法中并未得到充分体现。&lt;h4&gt;目的&lt;/h4&gt;研究目的是通过训练Transformer来在情境下进行强化学习，并分析模型中出现的算法。&lt;h4&gt;方法&lt;/h4&gt;研究人员训练了一个Transformer，使其在受老鼠行为启发的规划任务中进行情境下强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，表示学习得益于情境结构学习和跨情境对齐，表示在不同感官刺激的环境中被对齐。此外，模型开发的强化学习策略不同于标准的模型无关或模型基规划，而是通过在模型的记忆标记内缓存中间计算，并在决策时访问这些计算来支持情境下强化学习。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，记忆可能作为一种计算资源，存储原始经验和缓存的计算以支持灵活的行为，并且模型中的表示与大脑中海马体-内嗅系统相关的计算相似，表明这些发现可能与自然认知相关。&lt;h4&gt;翻译&lt;/h4&gt;This study explores the learning efficiency of humans and animals and the application of Transformers in contextual reinforcement learning. Research has found that representation learning is supported by contextual structure learning and cross-context alignment, and the reinforcement learning strategies developed by the model are different from standard model-free or model-based planning. Instead, contextual reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. The research results show that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior, and the representations developed in the model are similar to computations associated with the hippocampal-entorhinal system in the brain, suggesting that these findings may be relevant to natural cognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans and animals show remarkable learning efficiency, adapting to newenvironments with minimal experience. This capability is not well captured bystandard reinforcement learning algorithms that rely on incremental valueupdates. Rapid adaptation likely depends on episodic memory -- the ability toretrieve specific past experiences to guide decisions in novel contexts.Transformers provide a useful setting for studying these questions because oftheir ability to learn rapidly in-context and because their key-valuearchitecture resembles episodic memory systems in the brain. We train atransformer to in-context reinforcement learn in a distribution of planningtasks inspired by rodent behavior. We then characterize the learning algorithmsthat emerge in the model. We first find that representation learning issupported by in-context structure learning and cross-context alignment, whererepresentations are aligned across environments with different sensory stimuli.We next demonstrate that the reinforcement learning strategies developed by themodel are not interpretable as standard model-free or model-based planning.Instead, we show that in-context reinforcement learning is supported by cachingintermediate computations within the model's memory tokens, which are thenaccessed at decision time. Overall, we find that memory may serve as acomputational resource, storing both raw experience and cached computations tosupport flexible behavior. Furthermore, the representations developed in themodel resemble computations associated with the hippocampal-entorhinal systemin the brain, suggesting that our findings may be relevant for naturalcognition. Taken together, our work offers a mechanistic hypothesis for therapid adaptation that underlies in-context learning in artificial and naturalsettings.</description>
      <author>example@mail.com (Ching Fang, Kanaka Rajan)</author>
      <guid isPermaLink="false">2506.19686v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition</title>
      <link>http://arxiv.org/abs/2506.20174v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了使用预训练模型来提升地球观测数据挖掘的性能。&lt;h4&gt;背景&lt;/h4&gt;目前地球观测数据挖掘主要依赖于从大量地球观测数据集从头开始训练的大模型，而预训练模型的重用和组合策略尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型在地球观测任务中的组合使用是否能够有效提升性能。&lt;h4&gt;方法&lt;/h4&gt;使用GEO-Bench基准，评估了包括Prithvi、Hiera和DOFA在内的几个突出模型，在涵盖多种空间分辨率、传感器模态和任务类型的11个数据集上进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;小型预训练模型的特征级集成可以匹配甚至超越大型模型的性能，同时需要更少的训练时间和计算资源。&lt;h4&gt;结论&lt;/h4&gt;知识蒸馏技术在将集成模型的优点转移到更紧凑的模型中具有潜力，为在实际地球观测应用中部署基础模型提供了一条实用路径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型正在迅速改变地球观测数据挖掘，通过为场景分类和语义分割等关键任务提供可泛化和可扩展的解决方案。虽然大多数地球空间领域的努力都集中在开发从大量地球观测数据集从头开始训练的大模型上，但一个尚未充分探索的替代策略是重用和组合现有预训练模型。在本研究中，我们调查了在遥感视觉数据集上预训练的基础模型是否可以有效地组合以提升一系列关键地球观测任务的性能。使用GEO-Bench基准，我们对包括Prithvi、Hiera和DOFA在内的几个突出模型在覆盖多种空间分辨率、传感器模态和任务类型的11个数据集上进行了评估。结果显示，小型预训练模型的特征级集成可以匹配甚至超越大型模型的性能，同时需要更少的训练时间和计算资源。此外，该研究突出了应用知识蒸馏技术将集成模型的优点转移到更紧凑模型中的潜力，为在实际地球观测应用中部署基础模型提供了一条实用路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are rapidly transforming Earth Observation data mining byenabling generalizable and scalable solutions for key tasks such as sceneclassification and semantic segmentation. While most efforts in the geospatialdomain have focused on developing large models trained from scratch usingmassive Earth Observation datasets, an alternative strategy that remainsunderexplored is the reuse and combination of existing pretrained models. Inthis study, we investigate whether foundation models pretrained on remotesensing and general vision datasets can be effectively combined to improveperformance across a diverse set of key Earth Observation tasks. Using theGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,sensor modalities, and task types. The results show that feature-levelensembling of smaller pretrained models can match or exceed the performance ofmuch larger models, while requiring less training time and computationalresources. Moreover, the study highlights the potential of applying knowledgedistillation to transfer the strengths of ensembles into more compact models,offering a practical path for deploying foundation models in real-world EarthObservation applications.</description>
      <author>example@mail.com (Man Duc Chuc)</author>
      <guid isPermaLink="false">2506.20174v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Finetuning a Weather Foundation Model with Lightweight Decoders for Unseen Physical Processes</title>
      <link>http://arxiv.org/abs/2506.19088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了AI天气预报中的基础模型，特别是Aurora模型在预测水文变量方面的性能。提出了一种轻量级方法，通过在预训练模型的潜在表示上训练浅层解码器来预测新的变量，并与其他方法进行了比较。&lt;h4&gt;背景&lt;/h4&gt;AI天气预报领域出现了所谓的基础模型，这些模型通常通过昂贵的预训练和下游任务中的最小微调来定义。在自然科学中，理想的基础模型还应编码底层物理变量之间的有意义统计关系。&lt;h4&gt;目的&lt;/h4&gt;评估Aurora基础模型在预测预训练期间未考虑的水文变量方面的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种轻量级方法，使用在预训练模型的潜在表示上训练的浅层解码器来预测这些新变量。以微调整个模型作为基线，这允许进一步优化潜在空间，同时将新变量纳入输入和输出。&lt;h4&gt;主要发现&lt;/h4&gt;解码器方法需要50%的培训时间和35%的内存，同时在各种水文变量上实现了强大的准确性，并保留了基础模型的有益属性，如自回归稳定性。解码器的准确性取决于新变量与预训练期间使用的变量之间的物理相关性，表明Aurora的潜在空间捕捉到了有意义的物理关系。&lt;h4&gt;结论&lt;/h4&gt;提出，对于地球科学中的基础模型，一个重要的质量指标是它们在不进行完全微调的情况下扩展到新变量的能力。这为使基础模型对计算资源有限的社区更加可访问提供了新的视角，同时支持其在地球科学中的更广泛采用。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in AI weather forecasting have led to the emergence ofso-called 'foundation models', typically defined by expensive pretraining andminimal fine-tuning for downstream tasks. However, in the natural sciences, adesirable foundation model should also encode meaningful statistical relationships between the underlying physical variables. This study evaluates the performance of the state-of-the-art Aurora foundation model in predicting hydrological variables, which were not considered during pretraining. We introduce a lightweight approach using shallow decoders trained on the latent representations of the pretrained model to predict these new variables. As a baseline, we compare this to fine-tuning the full model, which allows further optimization of the latent space while incorporating new variables into both inputs and outputs. The decoder-based approach requires 50% less training time and 35% less memory, while achieving strong accuracy across various hydrological variables and preserving desirable properties of the foundation model, such as autoregressive stability. Notably, decoder accuracy depends on the physical correlation between the new variables and those used during pretraining, indicating that Aurora's latent space captures meaningful physical relationships. In this sense, we argue that an important quality metric for foundation models in Earth sciences is their ability to be extended to new variables without a full fine-tuning. This provides a new perspective for making foundation models more accessible to communities with limited computational resources, while supporting broader adoption in Earth sciences.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI weather forecasting have led to the emergence ofso-called "foundation models", typically defined by expensive pretraining andminimal fine-tuning for downstream tasks. However, in the natural sciences, adesirable foundation model should also encode meaningful statisticalrelationships between the underlying physical variables. This study evaluatesthe performance of the state-of-the-art Aurora foundation model in predictinghydrological variables, which were not considered during pretraining. Weintroduce a lightweight approach using shallow decoders trained on the latentrepresentations of the pretrained model to predict these new variables. As abaseline, we compare this to fine-tuning the full model, which allows furtheroptimization of the latent space while incorporating new variables into bothinputs and outputs. The decoder-based approach requires 50% less training timeand 35% less memory, while achieving strong accuracy across varioushydrological variables and preserving desirable properties of the foundationmodel, such as autoregressive stability. Notably, decoder accuracy depends onthe physical correlation between the new variables and those used duringpretraining, indicating that Aurora's latent space captures meaningful physicalrelationships. In this sense, we argue that an important quality metric forfoundation models in Earth sciences is their ability to be extended to newvariables without a full fine-tuning. This provides a new perspective formaking foundation models more accessible to communities with limitedcomputational resources, while supporting broader adoption in Earth sciences.</description>
      <author>example@mail.com (Fanny Lehmann, Firat Ozdemir, Benedikt Soja, Torsten Hoefler, Siddhartha Mishra, Sebastian Schemm)</author>
      <guid isPermaLink="false">2506.19088v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
  <item>
      <title>Disentangled representations of microscopy images</title>
      <link>http://arxiv.org/abs/2506.20649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in: International Joint Conference on Neural Networks  (IJCNN 2025). Project page:  https://github.com/JacopoDapueto/disentangled_microscopy&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于解耦表示学习（DRL）的方法，用于提高显微镜图像分类的可解释性。&lt;h4&gt;背景&lt;/h4&gt;显微镜图像分析在不同应用中至关重要，如诊断、合成工程和环境影响监测。现代获取系统可以获取大量图像，需要相应地开发基于深度学习的自动图像分析方法。&lt;h4&gt;目的&lt;/h4&gt;提高显微镜图像分类模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用来自三个不同显微镜图像领域（浮游生物、酵母空泡和人类细胞）的基准数据集，展示了一种基于从合成数据中学习到的表示的DRL框架，如何在保证准确性的同时提供良好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;DRL框架在显微镜图像分类领域提供了准确性和可解释性之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;DRL方法在显微镜图像分析中具有提高模型可解释性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge. This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Microscopy image analysis is fundamental for different applications, fromdiagnosis to synthetic engineering and environmental monitoring. Modernacquisition systems have granted the possibility to acquire an escalatingamount of images, requiring a consequent development of a large collection ofdeep learning-based automatic image analysis methods. Although deep neuralnetworks have demonstrated great performance in this field, interpretability,an essential requirement for microscopy image analysis, remains an openchallenge.  This work proposes a Disentangled Representation Learning (DRL) methodologyto enhance model interpretability for microscopy image classification.Exploiting benchmark datasets from three different microscopic image domains(plankton, yeast vacuoles, and human cells), we show how a DRL framework, basedon transferring a representation learnt from synthetic data, can provide a goodtrade-off between accuracy and interpretability in this domain.</description>
      <author>example@mail.com (Jacopo Dapueto, Vito Paolo Pastore, Nicoletta Noceti, Francesca Odone)</author>
      <guid isPermaLink="false">2506.20649v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Ship Motion Prediction Capabilities of the Open-Source Model NEMOH Against Field Observations</title>
      <link>http://arxiv.org/abs/2506.20186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了开源边界元求解器NEMOH在预测真实海洋环境船舶运动方面的能力。&lt;h4&gt;背景&lt;/h4&gt;精确的船舶运动预测对于开放海洋环境中的航海安全与效率至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究目的是评估NEMOH在预测真实开放海洋条件下船舶运动的能力。&lt;h4&gt;方法&lt;/h4&gt;使用NEMOH获得了线性模型RAO，并通过WaMoS-II海洋雷达获取的波向谱驱动。预测结果与船载惯性测量单元（IMU）记录的船舶运动观测值进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;比较结果显示，NEMOH在波浪运动预测方面具有可靠性：垂荡预测的相关系数为0.89，散布指数为0.41；纵摇预测的相关系数为0.80，散布指数为0.47；横摇预测的相关系数为0.63，散布指数为0.84。在特定极端海况下，纵摇和横摇的预测误差更大。&lt;h4&gt;结论&lt;/h4&gt;结果表明NEMOH在现实世界航海操作中的适用性，并为其实际应用提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：精确的船舶运动预测对于航海安全与效率至关重要，特别是在开放海洋环境中。本研究评估了开源势流边界元求解器NEMOH在预测真实海洋环境船舶运动方面的能力。通过NEMOH获得了线性模型RAO，并用WaMoS-II海洋雷达在阿克ademik Tryoshnikov号研究船进行的南极圈航行探险（ACE）期间获取的波向谱进行驱动。预测结果与船载惯性测量单元（IMU）记录的船舶运动观测值进行了比较。基于船舶运动谱的零阶矩的比较表明，NEMOH在垂荡预测方面具有可靠性（皮尔逊相关系数r=0.89，散布指数SI=0.41），在纵摇预测方面合理（r=0.80，SI=0.47），在横摇预测方面可接受（r=0.63，SI=0.84）。在特定极端海况下，纵摇和横摇的预测误差更大。结果表明NEMOH的能力，为其在现实世界航海操作中的应用提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate ship motion prediction is critical for safe and efficient maritimeoperations, particularly in open ocean environments. This study evaluates thecapability of NEMOH, an open-source potential flow boundary element solver, forpredicting ship motions in real-world open ocean conditions. A linear model,known as the Response Amplitude Operator (RAO), is obtained using NEMOH, and isdriven by the wave directional spectrum obtained from the WaMoS-II marine radaron the research vessel Akademik Tryoshnikov during the AntarcticCircumnavigation Expedition (ACE). Predictions are benchmarked againstconcurrent ship motion observations recorded by an onboard inertial measurementunit (IMU). The comparisons, based on the zeroth order moment of the shipmotion spectrum, demonstrate a reliable heave prediction (Pearson correlationcoefficient r=0.89, scatter index SI=0.41), a reasonable pitch prediction(r=0.80, SI=0.47), and an acceptable roll prediction (r=0.63, SI=0.84). Moresignificant discrepancies for pitch and roll are identified under specificextreme sea conditions. The results demonstrate the capability of NEMOH,offering insights into its applicability for real-world maritime operations.</description>
      <author>example@mail.com (Tianshi Yu, Ziyue Wang, Filippo Nelli, Ying Tan, Guillaume Ducrozet, Alessandro Toffoli)</author>
      <guid isPermaLink="false">2506.20186v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Causal Representation Learning with Observational Grouping for CXR Classification</title>
      <link>http://arxiv.org/abs/2506.20582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过分组学习可识别表示的方法，用于胸部X光片的疾病分类，以增强特定任务的泛化性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在医学影像中，可识别的因果表示学习旨在揭示数据生成过程中的真实因果关系，这为提高特定任务的潜在特征泛化性和鲁棒性提供了机会。&lt;h4&gt;目的&lt;/h4&gt;通过引入分组观察的概念，利用端到端框架学习胸部X光片疾病分类的可识别表示。&lt;h4&gt;方法&lt;/h4&gt;实验中采用了分组方法来强制执行不变性，以w.r.trace、性别和成像视图来增强泛化性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，当使用分组来强制执行不变性时，这些因果表示在多个分类任务中提高了泛化性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;分组学习可识别表示的方法在胸部X光片疾病分类中有效，可以增强特定任务的泛化性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.trace, sex, and imaging views.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifiable causal representation learning seeks to uncover the true causalrelationships underlying a data generation process. In medical imaging, thispresents opportunities to improve the generalisability and robustness oftask-specific latent features. This work introduces the concept of groupingobservations to learn identifiable representations for disease classificationin chest X-rays via an end-to-end framework. Our experiments demonstrate thatthese causal representations improve generalisability and robustness acrossmultiple classification tasks when grouping is used to enforce invariance w.r.trace, sex, and imaging views.</description>
      <author>example@mail.com (Rajat Rasal, Avinash Kori, Ben Glocker)</author>
      <guid isPermaLink="false">2506.20582v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios</title>
      <link>http://arxiv.org/abs/2506.20531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures, under-review conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于复杂风险场景中的主动操作决策，以提高自动驾驶系统的决策准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在安全关键场景中驾驶需要基于情境理解和经验推理的快速、情境感知的决策。大型语言模型（LLMs）具有强大的通用推理能力，但在自动驾驶领域的直接应用受到领域适应性、情境基础和缺乏动态高风险环境中可靠和可解释决策所需的经验知识的限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文旨在提出一种框架，以增强LLMs在自动驾驶中的决策能力。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了语义场景理解（来自行车记录仪视频输入）和与过去驾驶案例的相关检索，使LLMs能够生成既情境敏感又符合人类操作的建议。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架提高了决策准确性、论证质量和与人类专家行为的契合度。风险感知提示策略进一步提高了不同风险类型的表现，而基于相似性的案例检索在指导情境学习方面始终优于随机抽样。&lt;h4&gt;结论&lt;/h4&gt;案例研究进一步证明了该框架在具有挑战性的现实条件下的鲁棒性，强调了其作为智能驾驶系统自适应和可信决策支持工具的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在安全关键场景中驾驶需要基于情境理解和经验推理的快速、情境感知的决策。大型语言模型（LLMs）具有强大的通用推理能力，但其直接应用于自动驾驶仍受到领域适应性、情境基础和缺乏动态高风险环境中可靠和可解释决策所需的经验知识的限制。为了解决这一差距，本文提出了一种用于复杂风险场景中主动操作决策的案例推理增强大型语言模型（CBR-LLM）框架。我们的方法结合了来自行车记录仪视频输入的语义场景理解与相关过去驾驶案例的检索，使LLMs能够生成既情境敏感又符合人类操作的建议。在多个开源LLMs上的实验表明，我们的框架提高了决策准确性、论证质量和与人类专家行为的契合度。风险感知提示策略进一步提高了不同风险类型的表现，而基于相似性的案例检索在指导情境学习方面始终优于随机抽样。案例研究进一步证明了该框架在具有挑战性的现实条件下的鲁棒性，强调了其作为智能驾驶系统自适应和可信决策支持工具的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driving in safety-critical scenarios requires quick, context-awaredecision-making grounded in both situational understanding and experientialreasoning. Large Language Models (LLMs), with their powerful general-purposereasoning capabilities, offer a promising foundation for such decision-making.However, their direct application to autonomous driving remains limited due tochallenges in domain adaptation, contextual grounding, and the lack ofexperiential knowledge needed to make reliable and interpretable decisions indynamic, high-risk environments. To address this gap, this paper presents aCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework forevasive maneuver decision-making in complex risk scenarios. Our approachintegrates semantic scene understanding from dashcam video inputs with theretrieval of relevant past driving cases, enabling LLMs to generate maneuverrecommendations that are both context-sensitive and human-aligned. Experimentsacross multiple open-source LLMs show that our framework improves decisionaccuracy, justification quality, and alignment with human expert behavior.Risk-aware prompting strategies further enhance performance across diverse risktypes, while similarity-based case retrieval consistently outperforms randomsampling in guiding in-context learning. Case studies further demonstrate theframework's robustness in challenging real-world conditions, underscoring itspotential as an adaptive and trustworthy decision-support tool for intelligentdriving systems.</description>
      <author>example@mail.com (Wenbin Gan, Minh-Son Dao, Koji Zettsu)</author>
      <guid isPermaLink="false">2506.20531v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion</title>
      <link>http://arxiv.org/abs/2506.20537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FEA-PINN的高效建模框架，用于加速激光粉末床熔融（LPBF）过程中的热场预测，同时保持有限元分析（FEA）的精度。&lt;h4&gt;背景&lt;/h4&gt;传统数值方法如有限元分析（FEA）在模拟LPBF过程中存在计算成本高的长期问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的方法来预测LPBF过程中的热场，同时保持FEA的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的动态材料更新策略，以捕捉PINN模型中粉末-液体-固体的动态相变。2. PINN模型通过显热容方法结合了温度相关的材料属性和相变行为。3. 为了克服时间相关问题中计算成本高的问题，FEA-PINN框架在推理过程中集成校正FEA模拟，以强制执行物理一致性并减少误差漂移。&lt;h4&gt;主要发现&lt;/h4&gt;FEA-PINN模型在具有少量训练数据的情况下表现出高精度，并通过迁移学习实现了对新过程参数的泛化。此外，与FEA相比，FEA-PINN在保持等效精度的同时显著降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;FEA-PINN框架在LPBF中的应用验证了其有效性和准确性，为LPBF过程中的热场预测提供了一种高效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process prediction due to the lasting issue of high computation cost using traditional numerical methods such as finite element analysis (FEA). This study presents an efficient modeling framework termed FEA-Regulated Physics-Informed Neural Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process while maintaining the FEA accuracy. A novel dynamic material updating strategy is developed to capture the dynamic phase change of powder-liquid-solid in the PINN model. The PINN model incorporates temperature-dependent material properties and phase change behavior using the apparent heat capacity method. While the PINN model demonstrates high accuracy with a small training data and enables generalization of new process parameters via transfer learning, it faces the challenge of high computation cost in time-dependent problems due to the residual accumulation. To overcome this issue, the FEA-PINN framework integrates corrective FEA simulations during inference to enforce physical consistency and reduce error drift. A comparative analysis shows that FEA-PINN achieves equivalent accuracy to FEA while significantly reducing computational cost. The framework has been validated using the benchmark FEA data and demonstrated through single-track scanning in LPBF.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for processprediction due to the lasting issue of high computation cost using traditionalnumerical methods such as finite element analysis (FEA). This study presents anefficient modeling framework termed FEA-Regulated Physics-Informed NeuralNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF processwhile maintaining the FEA accuracy. A novel dynamic material updating strategyis developed to capture the dynamic phase change of powder-liquid-solid in thePINN model. The PINN model incorporates temperature-dependent materialproperties and phase change behavior using the apparent heat capacity method.While the PINN model demonstrates high accuracy with a small training data andenables generalization of new process parameters via transfer learning, itfaces the challenge of high computation cost in time-dependent problems due tothe residual accumulation. To overcome this issue, the FEA-PINN frameworkintegrates corrective FEA simulations during inference to enforce physicalconsistency and reduce error drift. A comparative analysis shows that FEA-PINNachieves equivalent accuracy to FEA while significantly reducing computationalcost. The framework has been validated using the benchmark FEA data anddemonstrated through single-track scanning in LPBF.</description>
      <author>example@mail.com (R. Sharma, M. Raissi, Y. B. Guo)</author>
      <guid isPermaLink="false">2506.20537v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Causal Inference for Latent Outcomes Learned with Factor Models</title>
      <link>http://arxiv.org/abs/2506.20549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 1 table (+ references and supplement). For  open-source R software package, see https://github.com/jennalandy/causalLFO.  For all code used in the simulation studies and data application, see  https://github.com/jennalandy/causalLFO_PAPER&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在因子模型或表示学习背景下，利用非负矩阵分解对高维观测数据中导出的潜在结果进行因果效应分析。&lt;h4&gt;背景&lt;/h4&gt;在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等领域，解决因果问题变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的算法，以估计潜在结果上的因果效应，同时减轻学习引起的干扰并提高估计效率。&lt;h4&gt;方法&lt;/h4&gt;本文使用非负矩阵分解来研究潜在结果上的因果效应，并提出了一个新颖的、直观的、理论上有根据的算法来解决这个问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文将估计潜在因子模型可能导致的个体学习到的潜在结果依赖于其他个体的处理方式的问题，称为学习引起的干扰，并提出了缓解这一问题的方法。&lt;h4&gt;结论&lt;/h4&gt;本文通过模拟研究和癌症突变特征分析的应用，证明了所提算法的实用性和理论保证。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在因子模型或表示学习背景下，利用非负矩阵分解对高维观测数据中导出的潜在结果进行因果效应分析。在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等领域，解决因果问题变得越来越重要。本文旨在提出一种新的算法，以估计潜在结果上的因果效应，同时减轻学习引起的干扰并提高估计效率。本文使用非负矩阵分解来研究潜在结果上的因果效应，并提出了一个新颖的、直观的、理论上有根据的算法来解决这个问题。本文将估计潜在因子模型可能导致的个体学习到的潜在结果依赖于其他个体的处理方式的问题，称为学习引起的干扰，并提出了缓解这一问题的方法。通过模拟研究和癌症突变特征分析的应用，本文证明了所提算法的实用性和理论保证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many fields$\unicode{x2013}$including genomics, epidemiology, naturallanguage processing, social and behavioral sciences, andeconomics$\unicode{x2013}$it is increasingly important to address causalquestions in the context of factor models or representation learning. In thiswork, we investigate causal effects on $\textit{latent outcomes}$ derived fromhigh-dimensional observed data using nonnegative matrix factorization. To thebest of our knowledge, this is the first study to formally address causalinference in this setting. A central challenge is that estimating a latentfactor model can cause an individual's learned latent outcome to depend onother individuals' treatments, thereby violating the standard causal inferenceassumption of no interference. We formalize this issue as$\textit{learning-induced interference}$ and distinguish it from interferencepresent in a data-generating process. To address this, we propose a novel,intuitive, and theoretically grounded algorithm to estimate causal effects onlatent outcomes while mitigating learning-induced interference and improvingestimation efficiency. We establish theoretical guarantees for the consistencyof our estimator and demonstrate its practical utility through simulationstudies and an application to cancer mutational signature analysis. Allbaseline and proposed methods are available in our open-source R package, ${\ttcausalLFO}$.</description>
      <author>example@mail.com (Jenna M. Landy, Dafne Zorzetto, Roberta De Vito, Giovanni Parmigiani)</author>
      <guid isPermaLink="false">2506.20549v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Directed Link Prediction using GNN with Local and Global Feature Fusion</title>
      <link>http://arxiv.org/abs/2506.20235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）框架，用于融合特征嵌入与社区信息，以改善有向链接预测的性能。&lt;h4&gt;背景&lt;/h4&gt;链接预测是图分析中的经典问题，有广泛应用。对于有向图，近期发展的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。&lt;h4&gt;目的&lt;/h4&gt;提高有向链接预测的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的GNN框架，用于融合特征嵌入与社区信息。2. 提出了一种方法，将输入图转换为有向线图，以便在图卷积过程中节点可以聚合更多信息。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了这种混合特征可以改善有向链接预测的性能。实验结果表明，在30%，40%，50%，和60%的连接链接作为训练数据的情况下，该方法在大多数情况下优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在大多数情况下优于现有技术，证明了融合特征和转换图结构对于有向链接预测的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a classical problem in graph analysis with many practicalapplications. For directed graphs, recently developed deep learning approachestypically analyze node similarities through contrastive learning and aggregateneighborhood information through graph convolutions. In this work, we propose anovel graph neural network (GNN) framework to fuse feature embedding withcommunity information. We theoretically demonstrate that such hybrid featurescan improve the performance of directed link prediction. To utilize suchfeatures efficiently, we also propose an approach to transform input graphsinto directed line graphs so that nodes in the transformed graph can aggregatemore information during graph convolutions. Experiments on benchmark datasetsshow that our approach outperforms the state-of-the-art in most cases when 30%,40%, 50%, and 60% of the connected links are used as training data,respectively.</description>
      <author>example@mail.com (Yuyang Zhang, Xu Shen, Yu Xie, Ka-Chun Wong, Weidun Xie, Chengbin Peng)</author>
      <guid isPermaLink="false">2506.20235v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Learning-based safety lifting monitoring system for cranes on construction sites</title>
      <link>http://arxiv.org/abs/2506.20475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究设计了一种基于学习方法的自动化安全提升监测算法流程，用于减少建筑工地上提升作业的安全风险，特别是针对大型模块化集成建筑（MiC）的提升作业。&lt;h4&gt;背景&lt;/h4&gt;提升作业在建筑工地上是常见的操作，但由于MiC重量大、体积大，存在安全风险，可能导致事故、损坏模块或对现场工人造成安全危害。&lt;h4&gt;目的&lt;/h4&gt;旨在通过自动化技术提高MiC提升过程的安全性和效率，减少提升作业中的安全风险。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含1007个图像-点云对（37个MiC提升）的数据集，并训练了先进的物体检测模型进行MiC和人类的自动二维（2D）检测。将2D检测结果与点云信息融合，以准确确定MiC和人类的三维（3D）位置。系统设计为自动触发警报，通知MiC提升危险区域的个人，并为起重机操作员提供实时提升信息和早期预警。&lt;h4&gt;主要发现&lt;/h4&gt;该算法流程在MiC和人类感知方面显示出有希望的结果，平均距离误差分别为1.5640米和0.7824米。此外，该系统在真实建筑工地上成功执行了安全风险监测和警报功能，对人工干预的需求有限。&lt;h4&gt;结论&lt;/h4&gt;该系统在减少MiC提升作业中的安全风险方面具有潜力，能够有效提高施工安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifting on construction sites, as a frequent operation, works still withsafety risks, especially for modular integrated construction (MiC) lifting dueto its large weight and size, probably leading to accidents, causing damage tothe modules, or more critically, posing safety hazards to on-site workers.Aiming to reduce the safety risks in lifting scenarios, we design an automatedsafe lifting monitoring algorithm pipeline based on learning-based methods, anddeploy it on construction sites. This work is potentially to increase thesafety and efficiency of MiC lifting process via automation technologies. Adataset is created consisting of 1007 image-point cloud pairs (37 MiCliftings). Advanced object detection models are trained for automatedtwo-dimensional (2D) detection of MiCs and humans. Fusing the 2D detectionresults with the point cloud information allows accurate determination of thethree-dimensional (3D) positions of MiCs and humans. The system is designed toautomatically trigger alarms that notify individuals in the MiC lifting dangerzone, while providing the crane operator with real-time lifting information andearly warnings. The monitoring process minimizes the human intervention and noor less signal men are required on real sites assisted by our system. Aquantitative analysis is conducted to evaluate the effectiveness of thealgorithmic pipeline. The pipeline shows promising results in MiC and humanperception with the mean distance error of 1.5640 m and 0.7824 m respectively.Furthermore, the developed system successfully executes safety risk monitoringand alarm functionalities during the MiC lifting process with limited manualwork on real construction sites.</description>
      <author>example@mail.com (Hao Chen, Yu Hin Ng, Ching-Wei Chang, Haobo Liang, Yanke Wang)</author>
      <guid isPermaLink="false">2506.20475v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs</title>
      <link>http://arxiv.org/abs/2506.20073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STReason是一个结合大型语言模型和时空模型进行多任务推理和执行的新框架。&lt;h4&gt;背景&lt;/h4&gt;现有的时空数据挖掘模型通常局限于特定任务，缺乏多任务推理和复杂长格式推理的能力。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够处理复杂时空场景的框架，以支持更深入的决策。&lt;h4&gt;方法&lt;/h4&gt;STReason利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，然后执行这些程序以生成解决方案和详细理由。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STReason在所有指标上均显著优于先进的LLM基线，尤其在复杂的推理密集型时空场景中表现出色。&lt;h4&gt;结论&lt;/h4&gt;STReason为开发更强大和更具通用性的时空推理系统提供了有希望的途径。&lt;h4&gt;翻译&lt;/h4&gt;时空数据挖掘在各个领域的信息化决策中发挥着关键作用。然而，现有的模型通常局限于狭窄的任务，缺乏进行多任务推理和复杂长格式推理的能力，这需要生成深入的、解释性的输出。这些限制限制了它们在现实世界、多方面的决策场景中的应用。在这项工作中，我们引入了STReason，这是一个将大型语言模型（LLM）的推理优势与时空模型的解析能力相结合的新框架，无需针对特定任务进行微调。STReason利用上下文学习将复杂的自然语言查询分解为模块化、可解释的程序，然后系统地执行这些程序以生成解决方案和详细的理由。为了便于严格评估，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，其中包含专门为长格式时空推理设计的指标。实验结果表明，STReason在所有指标上均显著优于先进的LLM基线，尤其是在复杂的推理密集型时空场景中表现出色。人工评估进一步验证了STReason的可信度和实用性，证明了其减少专家工作量和拓宽现实世界时空任务应用范围的可能性。我们认为STReason为开发更强大和更具通用性的时空推理系统提供了有希望的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal data mining plays a pivotal role in informed decision makingacross diverse domains. However, existing models are often restricted to narrowtasks, lacking the capacity for multi-task inference and complex long-formreasoning that require generation of in-depth, explanatory outputs. Theselimitations restrict their applicability to real-world, multi-faceted decisionscenarios. In this work, we introduce STReason, a novel framework thatintegrates the reasoning strengths of large language models (LLMs) with theanalytical capabilities of spatio-temporal models for multi-task inference andexecution. Without requiring task-specific finetuning, STReason leveragesin-context learning to decompose complex natural language queries into modular,interpretable programs, which are then systematically executed to generate bothsolutions and detailed rationales. To facilitate rigorous evaluation, weconstruct a new benchmark dataset and propose a unified evaluation frameworkwith metrics specifically designed for long-form spatio-temporal reasoning.Experimental results show that STReason significantly outperforms advanced LLMbaselines across all metrics, particularly excelling in complex,reasoning-intensive spatio-temporal scenarios. Human evaluations furthervalidate STReason's credibility and practical utility, demonstrating itspotential to reduce expert workload and broaden the applicability to real-worldspatio-temporal tasks. We believe STReason provides a promising direction fordeveloping more capable and generalizable spatio-temporal reasoning systems.</description>
      <author>example@mail.com (Kethmi Hirushini Hettige, Jiahao Ji, Cheng Long, Shili Xiang, Gao Cong, Jingyuan Wang)</author>
      <guid isPermaLink="false">2506.20073v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>DreamAnywhere: Object-Centric Panoramic 3D Scene Generation</title>
      <link>http://arxiv.org/abs/2506.20367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DreamAnywhere系统，该系统可以快速生成和原型设计3D场景，具有沉浸式导航和直观的对象级别编辑功能，适用于场景探索、视觉模拟和快速原型设计，尤其适合低成本电影制作。&lt;h4&gt;背景&lt;/h4&gt;近年来，文本到3D场景生成的技术取得了显著进展，但在生成具有真实感的场景、理解场景和适应室内外环境等方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在生成3D场景时存在的问题，如场景仅面向前方、缺乏视觉真实感、场景理解有限等。&lt;h4&gt;方法&lt;/h4&gt;DreamAnywhere系统通过以下步骤生成3D场景：从文本生成360度全景图像，将其分解为背景和对象，通过混合修复构建完整的3D表示，并将对象掩码提升为详细的三维对象，放置在虚拟环境中。&lt;h4&gt;主要发现&lt;/h4&gt;DreamAnywhere系统在新颖视图合成中的连贯性方面有显著提升，并且实现了有竞争力的图像质量，证明其在多样化和具有挑战性的场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过用户研究，证明DreamAnywhere方法在技术稳健性和实用价值方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，在文本到3D场景生成技术方面的进展展示了在多个行业中转换内容创作的巨大潜力。尽管研究界在解决这一复杂任务的挑战方面取得了令人印象深刻的进步，但现有方法往往生成的环境仅面向前方，缺乏视觉真实感，场景理解有限，并且通常针对室内或室外环境进行微调。在这项工作中，我们解决了这些问题，并提出了DreamAnywhere，一个用于快速生成和原型设计3D场景的模块化系统。我们的系统从文本合成360度全景图像，将其分解为背景和对象，通过混合修复构建完整的3D表示，并将对象掩码提升为放置在虚拟环境中的详细三维对象。DreamAnywhere支持沉浸式导航和直观的对象级别编辑，使其非常适合场景探索、视觉模拟和快速原型设计——所有这些都可以实现最小化的手动建模。这些功能使我们的系统特别适合低成本电影制作，可以在不增加传统3D工作流程的负担的情况下快速迭代场景布局和视觉色调。我们的模块化管道高度可定制，因为它允许独立替换组件。与当前的基于文本和图像的3D场景生成方法相比，DreamAnywhere在新颖视图合成中的连贯性方面有显著提升，并实现了有竞争力的图像质量，证明了其在多样化和具有挑战性的场景中的有效性。一项综合用户研究证明了我们的方法优于现有方法，验证了其技术稳健性和实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in text-to-3D scene generation have demonstrated significantpotential to transform content creation across multiple industries. Althoughthe research community has made impressive progress in addressing thechallenges of this complex task, existing methods often generate environmentsthat are only front-facing, lack visual fidelity, exhibit limited sceneunderstanding, and are typically fine-tuned for either indoor or outdoorsettings. In this work, we address these issues and propose DreamAnywhere, amodular system for the fast generation and prototyping of 3D scenes. Our systemsynthesizes a 360{\deg} panoramic image from text, decomposes it intobackground and objects, constructs a complete 3D representation through hybridinpainting, and lifts object masks to detailed 3D objects that are placed inthe virtual environment. DreamAnywhere supports immersive navigation andintuitive object-level editing, making it ideal for scene exploration, visualmock-ups, and rapid prototyping -- all with minimal manual modeling. Thesefeatures make our system particularly suitable for low-budget movie production,enabling quick iteration on scene layout and visual tone without the overheadof traditional 3D workflows. Our modular pipeline is highly customizable as itallows components to be replaced independently. Compared to currentstate-of-the-art text and image-based 3D scene generation approaches,DreamAnywhere shows significant improvements in coherence in novel viewsynthesis and achieves competitive image quality, demonstrating itseffectiveness across diverse and challenging scenarios. A comprehensive userstudy demonstrates a clear preference for our method over existing approaches,validating both its technical robustness and practical usefulness.</description>
      <author>example@mail.com (Edoardo Alberto Dominici, Jozef Hladky, Floor Verhoeven, Lukas Radl, Thomas Deixelberger, Stefan Ainetter, Philipp Drescher, Stefan Hauswiesner, Arno Coomans, Giacomo Nazzaro, Konstantinos Vardis, Markus Steinberger)</author>
      <guid isPermaLink="false">2506.20367v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling</title>
      <link>http://arxiv.org/abs/2506.20512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages; The first three authors contribute to this work equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在中训练策略如何影响强化学习（RL）动态，重点关注Qwen和Llama两种模型，并提出了一个两阶段的中训练策略Stable-then-Decay，以提升基础模型的RL兼容性。&lt;h4&gt;背景&lt;/h4&gt;不同的基础语言模型在强化学习后训练中表现出不同的行为，尤其是在推理密集型任务上。理解哪些基础语言模型适合强化学习对于开发下一代可扩展的RL基础模型至关重要。&lt;h4&gt;目的&lt;/h4&gt;深入探究中训练策略如何影响RL动态，为开发下一代RL可扩展的基础模型提供见解。&lt;h4&gt;方法&lt;/h4&gt;研究聚焦于Qwen和Llama两种模型，通过实验对比了不同数学语料库和QA数据对模型的影响，并提出了Stable-then-Decay中训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;1. 高质量的数学语料库如MegaMath-Web-Pro能显著提升基础模型和RL性能；2. 添加QA数据，特别是长思维链（CoT）推理示例，能增强RL结果；3. 长CoT虽然提高了推理深度，但也可能导致模型响应的冗长和RL训练的不稳定性；4. 一致地扩展中训练会导致更强的下游RL性能。&lt;h4&gt;结论&lt;/h4&gt;提出的Stable-then-Decay中训练策略能够提升基础模型的RL兼容性，并缩小与更友好的RL模型家族的性能差距。研究有助于塑造RL时代的预训练策略。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Based on these insights, a two-stage mid-training strategy, Stable-then-Decay, is introduced, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This leads to OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. The study contributes to shaping pre-training strategies for foundation models in the RL era.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different base language model families, such as Llama and Qwen, exhibitdivergent behaviors during post-training with reinforcement learning (RL),especially on reasoning-intensive tasks. What makes a base language modelsuitable for reinforcement learning? Gaining deeper insight into this questionis essential for developing RL-scalable foundation models of the nextgeneration. In this work, we investigate how mid-training strategies shape RLdynamics, focusing on two representative model families: Qwen and Llama. Ourstudy reveals that (1) high-quality mathematical corpora, such asMegaMath-Web-Pro, significantly improve both base model and RL performance,while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) furtheradding QA-style data, particularly long chain-of-thought (CoT) reasoningexamples, enhances RL outcomes, and instruction data further unlocks thiseffect; (3) while long-CoT improves reasoning depth, it can also induceverbosity of model responses and unstability of RL training, underscoring theimportance of data formatting; (4) scaling mid-training consistently leads tostronger downstream RL performance. Building on these insights, we introduce atwo-stage mid-training strategy, Stable-then-Decay, in which base models arefirst trained on 200B tokens with a constant learning rate, followed by 20Btokens across three CoT-focused branches with learning rate decay. This yieldsOctoThinker, a family of models demonstrating strong RL compatibility andclosing the performance gap with more RL-friendly model families, i.e., Qwen.We hope our work will help shape pre-training strategies for foundation modelsin the RL era. To support further research, we release our open-source modelsalong with a curated math reasoning-intensive corpus of over 70 billion tokens(i.e., MegaMath-Web-Pro-Max).</description>
      <author>example@mail.com (Zengzhi Wang, Fan Zhou, Xuefeng Li, Pengfei Liu)</author>
      <guid isPermaLink="false">2506.20512v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Graph-Transformer Out-of-Distribution Generalization Abilities</title>
      <link>http://arxiv.org/abs/2506.20575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络在分布外泛化（OOD）上的挑战，特别关注了骨干架构的影响，并通过实验证明了图变换器（GT）和混合GT-MPNN骨架在OOD设置中优于传统的消息传递神经网络（MPNNs）。&lt;h4&gt;背景&lt;/h4&gt;深度学习在图上的应用取得了显著成功，但现有方法通常假设训练和测试数据具有相同的分布，这在现实场景中很少发生。尽管图变换器（GT）在多个内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNNs），但其在分布变化下的有效性仍需进一步探索。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决图神经网络在分布外泛化（OOD）上的挑战，并重点研究骨干架构的影响。&lt;h4&gt;方法&lt;/h4&gt;本文系统地评估了GT和混合骨架在OOD设置中的表现，并与MPNNs进行了比较。此外，还提出了一种新的后训练分析方法，通过比较内部分布和分布外测试数据集的聚类结构，特别研究了领域对齐和类别分离。&lt;h4&gt;主要发现&lt;/h4&gt;GT和混合GT-MPNN骨架在OOD设置中表现出比MPNNs更强的泛化能力，即使在没有专门领域泛化（DG）算法的情况下也是如此。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，图变换器对于鲁棒的、现实世界的图学习具有巨大潜力，并为未来在OOD泛化方向上的研究指明了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在图上的深度学习在各种应用中表现出色，包括社交网络、生物物理、交通网络和推荐系统。尽管它们取得了成功，但当前方法通常依赖于训练和测试数据具有相同分布的假设，而在现实场景中这种条件很少得到满足。尽管图变换器（GT）最近在多个内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNNs），但它们在分布变化下的有效性仍然没有得到充分探索。在这项工作中，我们针对图神经网络在分布外（OOD）泛化上的挑战进行了研究，特别关注骨干架构的影响。我们系统地评估了GT和混合骨架在OOD设置中的表现，并将它们与MPNNs进行了比较。为此，我们将几种领先的领域泛化（DG）算法改编为与GT一起工作，并评估了它们在测试各种分布变化的基准上的性能。我们的结果表明，GT和混合GT-MPNN骨架在OOD设置中表现出比MPNNs更强的泛化能力，即使在没有专门的DG算法的情况下也是如此。此外，我们还提出了一种新的后训练分析方法，通过比较内部分布和分布外测试数据集的聚类结构，特别是检查领域对齐和类别分离。这种模型无关的设计不仅为GT和MPNN骨架提供了有意义的见解，而且也显示出对领域泛化问题（超出图学习之外）的更广泛适用性的承诺，提供了超越标准准确度指标的泛化能力的更深入视角。总之，我们的研究结果突出了图变换器在鲁棒的、现实世界的图学习中的潜力，并为未来在OOD泛化方面的研究设定了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning on graphs has shown remarkable success across numerousapplications, including social networks, bio-physics, traffic networks, andrecommendation systems. Regardless of their successes, current methodsfrequently depend on the assumption that training and testing data share thesame distribution, a condition rarely met in real-world scenarios. Whilegraph-transformer (GT) backbones have recently outperformed traditionalmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)benchmarks, their effectiveness under distribution shifts remains largelyunexplored.  In this work, we address the challenge of out-of-distribution (OOD)generalization for graph neural networks, with a special focus on the impact ofbackbone architecture. We systematically evaluate GT and hybrid backbones inOOD settings and compare them to MPNNs. To do so, we adapt several leadingdomain generalization (DG) algorithms to work with GTs and assess theirperformance on a benchmark designed to test a variety of distribution shifts.Our results reveal that GT and hybrid GT-MPNN backbones consistentlydemonstrate stronger generalization ability compared to MPNNs, even withoutspecialized DG algorithms.  Additionally, we propose a novel post-training analysis approach thatcompares the clustering structure of the entire ID and OOD test datasets,specifically examining domain alignment and class separation. Demonstrating itsmodel-agnostic design, this approach not only provided meaningful insights intoGT and MPNN backbones. It also shows promise for broader applicability to DGproblems beyond graph learning, offering a deeper perspective on generalizationabilities that goes beyond standard accuracy metrics. Together, our findingshighlight the promise of graph-transformers for robust, real-world graphlearning and set a new direction for future research in OOD generalization.</description>
      <author>example@mail.com (Itay Niv, Neta Rabin)</author>
      <guid isPermaLink="false">2506.20575v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2506.20323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一个由人工智能驱动的作物病害检测系统，旨在帮助资源有限的农村地区农民。系统通过比较不同的深度学习模型，重点关注其在迁移学习中的有效性，实现了对植物病害的有效分类。&lt;h4&gt;背景&lt;/h4&gt;农村地区农民往往面临资源限制，需要一种高效的方法来检测作物病害。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于人工智能的作物病害检测系统，并比较不同深度学习模型在迁移学习中的效果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了包括EfficientNet、ResNet101、MobileNetV2和自定义卷积神经网络（CNN）在内的深度学习模型，并通过验证准确率达到了95.76%。&lt;h4&gt;主要发现&lt;/h4&gt;研究证明了迁移学习在改变农业实践、改善作物健康管理以及支持农村环境的可持续农业中的潜力。&lt;h4&gt;结论&lt;/h4&gt;所开发的系统在迁移学习方面表现出色，有望为农村地区提供有效的作物病害检测手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research presents the development of an Artificial Intelligence (AI) -driven crop disease detection system designed to assist farmers in rural areaswith limited resources. We aim to compare different deep learning models for acomparative analysis, focusing on their efficacy in transfer learning. Byleveraging deep learning models, including EfficientNet, ResNet101,MobileNetV2, and our custom CNN, which achieved a validation accuracy of95.76%, the system effectively classifies plant diseases. This researchdemonstrates the potential of transfer learning in reshaping agriculturalpractices, improving crop health management, and supporting sustainable farmingin rural environments.</description>
      <author>example@mail.com (Saundarya Subramaniam, Shalini Majumdar, Shantanu Nadar, Kaustubh Kulkarni)</author>
      <guid isPermaLink="false">2506.20323v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Representation Learning and Fusion</title>
      <link>http://arxiv.org/abs/2506.20494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多模态学习是人工智能领域快速发展的一个分支，通过结合图像、文本和音频等不同来源的信息，帮助机器理解复杂事物，并增强AI系统的内部表示，提高其在现实生活中的理解和决策能力。&lt;h4&gt;背景&lt;/h4&gt;多模态学习旨在通过融合不同模态的信息，帮助机器更好地理解和处理复杂情况。&lt;h4&gt;目的&lt;/h4&gt;多模态学习的目的是提高AI系统的理解和决策能力，使其在现实世界中的应用更加灵活、上下文感知并能处理复杂问题。&lt;h4&gt;方法&lt;/h4&gt;多模态学习方法包括代表学习（从不同数据类型中获取共享特征）、对齐方法（匹配跨模态信息）和融合策略（通过深度学习模型结合信息）。&lt;h4&gt;主要发现&lt;/h4&gt;尽管多模态学习取得了一定的进展，但仍存在一些主要问题，如处理不同数据格式、缺失或不完整输入以及防御对抗攻击。研究者正在探索新的方法，如无监督或半监督学习、AutoML工具等，以提高模型效率并简化扩展。同时，更注重设计更好的评估指标或建立共享基准，以便跨任务和领域比较模型性能。&lt;h4&gt;结论&lt;/h4&gt;随着多模态学习领域的持续发展，预计将改善计算机视觉、自然语言处理、语音识别和医疗保健等多个领域。未来，它可能有助于构建更接近人类理解世界的AI系统，具有灵活性、上下文感知和应对现实世界复杂性的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal learning is a fast growing area in artificial intelligence. Ittries to help machines understand complex things by combining information fromdifferent sources, like images, text, and audio. By using the strengths of eachmodality, multi-modal learning allows AI systems to build stronger and richerinternal representations. These help machines better interpretation, reasoning,and making decisions in real-life situations. This field includes coretechniques such as representation learning (to get shared features fromdifferent data types), alignment methods (to match information acrossmodalities), and fusion strategies (to combine them by deep learning models).Although there has been good progress, some major problems still remain. Likedealing with different data formats, missing or incomplete inputs, anddefending against adversarial attacks. Researchers now are exploring newmethods, such as unsupervised or semi-supervised learning, AutoML tools, tomake models more efficient and easier to scale. And also more attention ondesigning better evaluation metrics or building shared benchmarks, make iteasier to compare model performance across tasks and domains. As the fieldcontinues to grow, multi-modal learning is expected to improve many areas:computer vision, natural language processing, speech recognition, andhealthcare. In the future, it may help to build AI systems that can understandthe world in a way more like humans, flexible, context aware, and able to dealwith real-world complexity.</description>
      <author>example@mail.com (Qihang Jin, Enze Ge, Yuhang Xie, Hongying Luo, Junhao Song, Ziqian Bi, Chia Xin Liang, Jibin Guan, Joe Yeong, Junfeng Hao)</author>
      <guid isPermaLink="false">2506.20494v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration</title>
      <link>http://arxiv.org/abs/2506.19975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VoxelOpt是一种基于离散优化的DIR框架，结合了学习方法和迭代方法的优点，在注册精度和运行时间之间取得了更好的平衡。&lt;h4&gt;背景&lt;/h4&gt;神经网络的最新进展提高了DIR的准确性，但学习方法在训练数据有限、大变形以及无标签监督的情况下往往表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出VoxelOpt以解决学习方法和迭代方法在DIR中的局限性。&lt;h4&gt;方法&lt;/h4&gt;VoxelOpt使用位移熵来测量每个体素的位移信号强度，并引入了体素级的自适应消息传递、多级图像金字塔和预训练的基础分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;在腹部CT注册中，VoxelOpt在效率和精度方面优于领先的迭代方法，同时与使用标签监督训练的顶级学习方法相当。&lt;h4&gt;结论&lt;/h4&gt;VoxelOpt是一个有效的DIR框架，它结合了学习方法和迭代方法的优点，提高了DIR的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Recent developments in neural networks have improved deformable imageregistration (DIR) by amortizing iterative optimization, enabling fast and accurate DIR results. However, learning-based methods often face challenges with limited training data, large deformations, and tend to underperform compared to iterative approaches when label supervision is unavailable. While iterative methods can achieve higher accuracy in such scenarios, they are considerably slower than learning-based methods. To address these limitations, we propose VoxelOpt, a discrete optimization-based DIR framework that combines the strengths of learning-based and iterative methods to achieve a better balance between registration accuracy and runtime. VoxelOpt uses displacement entropy from local cost volumes to measure displacement signal strength at each voxel, which differs from earlier approaches in three key aspects. First, it introduces voxel-wise adaptive message passing, where voxels with lower entropy receive less influence from their neighbors. Second, it employs a multi-level image pyramid with 27-neighbor cost volumes at each level, avoiding exponential complexity growth. Third, it replaces hand-crafted features or contrastive learning with a pretrained foundational segmentation model for feature extraction. In abdominal CT registration, these changes allow VoxelOpt to outperform leading iterative in both efficiency and accuracy, while matching state-of-the-art learning-based methods trained with label supervision. The source code will be available at https://github.com/tinymilky/VoxelOpt&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developments in neural networks have improved deformable imageregistration (DIR) by amortizing iterative optimization, enabling fast andaccurate DIR results. However, learning-based methods often face challengeswith limited training data, large deformations, and tend to underperformcompared to iterative approaches when label supervision is unavailable. Whileiterative methods can achieve higher accuracy in such scenarios, they areconsiderably slower than learning-based methods. To address these limitations,we propose VoxelOpt, a discrete optimization-based DIR framework that combinesthe strengths of learning-based and iterative methods to achieve a betterbalance between registration accuracy and runtime. VoxelOpt uses displacemententropy from local cost volumes to measure displacement signal strength at eachvoxel, which differs from earlier approaches in three key aspects. First, itintroduces voxel-wise adaptive message passing, where voxels with lower entropyreceives less influence from their neighbors. Second, it employs a multi-levelimage pyramid with 27-neighbor cost volumes at each level, avoiding exponentialcomplexity growth. Third, it replaces hand-crafted features or contrastivelearning with a pretrained foundational segmentation model for featureextraction. In abdominal CT registration, these changes allow VoxelOpt tooutperform leading iterative in both efficiency and accuracy, while matchingstate-of-the-art learning-based methods trained with label supervision. Thesource code will be available at https://github.com/tinymilky/VoxelOpt</description>
      <author>example@mail.com (Hang Zhang, Yuxi Zhang, Jiazheng Wang, Xiang Chen, Renjiu Hu, Xin Tian, Gaolei Li, Min Liu)</author>
      <guid isPermaLink="false">2506.19975v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners</title>
      <link>http://arxiv.org/abs/2506.20464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在地下矿井中利用移动激光扫描器获取的中到大规模3D点云自动识别岩石锚杆的方法，提出了一种名为DeepBolt的新方法，通过改进的深度学习架构，提高了锚杆识别的精度和效率。&lt;h4&gt;背景&lt;/h4&gt;岩石锚杆是地下矿井支撑系统中的关键组成部分，其稳定性对于预防岩体滑坡等意外事故至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过自动化检测岩石锚杆，来解决传统手动检测的困难，如井下光线昏暗和过程耗时。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DeepBolt的两阶段深度学习架构，用于处理大规模3D点云中的岩石锚杆自动识别，特别针对数据噪声、多变环境和复杂周围结构的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;DeepBolt方法在岩石锚杆点上的Intersection over Union（IoU）达到了42.5%的提升，且在分类岩石锚杆时，精度和召回率分别达到96.41%和96.96%。&lt;h4&gt;结论&lt;/h4&gt;DeepBolt方法在复杂地下环境中展现出其鲁棒性和有效性，显著优于现有的岩石锚杆识别技术。&lt;h4&gt;翻译&lt;/h4&gt;摘要：岩石锚杆是地下矿井地下支撑系统的关键组成部分，为岩体提供足够的结构加固，以防止意外灾害如岩崩。这使得对这种锚杆的频繁评估对于维持岩体稳定性以及降低地下开采风险至关重要。由于井下光线昏暗和过程耗时，手动检测岩石锚杆具有挑战性，因此自动检测岩石锚杆成为了一种可行的解决方案。为此，本研究专注于使用移动激光扫描器从地下矿井获取的中到大规模3D点云中自动识别岩石锚杆。现有的自动岩石锚杆识别技术主要依赖于特征工程和传统的机器学习方法。然而，由于这些点云存在数据噪声、多变环境和复杂周围结构等问题，这些方法缺乏鲁棒性。此外，目标岩石锚杆在大规模点云中是极其微小的物体，通常由于加固喷射混凝土的应用而部分被遮挡。为了解决这些挑战，本文提出了一种名为DeepBolt的方法，该方法采用了一种新颖的两阶段深度学习架构，专门用于处理严重类别不平衡，以自动和高效地识别复杂3D点云中的岩石锚杆。所提出的方法在岩石锚杆点上的Intersection over Union（IoU）方面优于现有最先进的语义分割模型高达42.5%。此外，它在分类岩石锚杆时，实现了96.41%的精度和96.96%的召回率，证明了其在复杂地下环境中的鲁棒性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rock bolts are crucial components of the subterranean support systems inunderground mines that provide adequate structural reinforcement to the rockmass to prevent unforeseen hazards like rockfalls. This makes frequentassessments of such bolts critical for maintaining rock mass stability andminimising risks in underground mining operations. Where manual surveying ofrock bolts is challenging due to the low light conditions in the undergroundmines and the time-intensive nature of the process, automated detection of rockbolts serves as a plausible solution. To that end, this study focuses on theautomatic identification of rock bolts within medium to large-scale 3D pointclouds obtained from underground mines using mobile laser scanners. Existingtechniques for automated rock bolt identification primarily rely on featureengineering and traditional machine learning approaches. However, suchtechniques lack robustness as these point clouds present several challenges dueto data noise, varying environments, and complex surrounding structures.Moreover, the target rock bolts are extremely small objects within large-scalepoint clouds and are often partially obscured due to the application ofreinforcement shotcrete. Addressing these challenges, this paper proposes anapproach termed DeepBolt, which employs a novel two-stage deep learningarchitecture specifically designed for handling severe class imbalance for theautomatic and efficient identification of rock bolts in complex 3D pointclouds. The proposed method surpasses state-of-the-art semantic segmentationmodels by up to 42.5% in Intersection over Union (IoU) for rock bolt points.Additionally, it outperforms existing rock bolt identification techniques,achieving a 96.41% precision and 96.96% recall in classifying rock bolts,demonstrating its robustness and effectiveness in complex undergroundenvironments.</description>
      <author>example@mail.com (Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval)</author>
      <guid isPermaLink="false">2506.20464v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment</title>
      <link>http://arxiv.org/abs/2506.20303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FundaQ-8的专家验证框架，用于系统地评估眼底图像质量，并开发了一个基于ResNet18的回归模型来预测图像质量分数，同时验证了该框架在临床诊断中的可靠性。&lt;h4&gt;背景&lt;/h4&gt;由于图像采集和主观专家评估的差异，自动眼底图像质量评估（FIQA）仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架和模型来系统地评估眼底图像质量，并提高糖尿病视网膜病变诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;FundaQ-8框架基于八个关键参数（如视野覆盖、解剖可见性、照明和图像伪影）进行评估。使用FundaQ-8作为结构化评分参考，开发了一个基于ResNet18的回归模型。模型在1800张真实临床来源和Kaggle数据集的图像上训练，采用了迁移学习、均方误差优化和标准化预处理。&lt;h4&gt;主要发现&lt;/h4&gt;FundaQ-8框架的可靠性得到了EyeQ数据集的验证和统计分析的确认。将FundaQ-8集成到深度学习模型中用于糖尿病视网膜病变分级，也提高了诊断的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;FundaQ-8框架和基于ResNet18的模型在提高眼底图像质量评估和糖尿病视网膜病变诊断的准确性方面具有价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated fundus image quality assessment (FIQA) remains a challenge due tovariations in image acquisition and subjective expert evaluations. We introduceFundaQ-8, a novel expert-validated framework for systematically assessingfundus image quality using eight critical parameters, including field coverage,anatomical visibility, illumination, and image artifacts. Using FundaQ-8 as astructured scoring reference, we develop a ResNet18-based regression model topredict continuous quality scores in the 0 to 1 range. The model is trained on1800 fundus images from real-world clinical sources and Kaggle datasets, usingtransfer learning, mean squared error optimization, and standardizedpreprocessing. Validation against the EyeQ dataset and statistical analysesconfirm the framework's reliability and clinical interpretability.Incorporating FundaQ-8 into deep learning models for diabetic retinopathygrading also improves diagnostic robustness, highlighting the value ofquality-aware training in real-world screening applications.</description>
      <author>example@mail.com (Lee Qi Zun, Oscar Wong Jin Hao, Nor Anita Binti Che Omar, Zalifa Zakiah Binti Asnir, Mohamad Sabri bin Sinal Zainal, Goh Man Fye)</author>
      <guid isPermaLink="false">2506.20303v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning</title>
      <link>http://arxiv.org/abs/2506.20394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在线更新服务机器人通过多种方式获取的信息，包括几何和语义数据，并介绍了一种名为SPARK的框架，用于从环境嵌入的线索中提取语义信息并更新场景图，以支持动态环境中的任务规划和适应非传统空间线索。&lt;h4&gt;背景&lt;/h4&gt;在任务执行过程中，服务机器人需要更新通过在线方式获取的信息，包括几何和语义数据。SLAM可以处理二维地图或三维点云的几何更新，但在线更新语义信息尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究在线语义信息的图表示，并开发一种能够处理在线场景图表示的框架。&lt;h4&gt;方法&lt;/h4&gt;基于离线场景图表示的研究，本文提出了SPARK框架，该框架能够从环境嵌入的线索中提取语义信息并更新场景图，进而用于后续的任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，空间关系的图表示可以增强机器人系统在动态环境中执行任务的能力，并适应诸如手势等非传统空间线索。&lt;h4&gt;结论&lt;/h4&gt;SPARK框架能够有效更新语义信息，并提高机器人在动态环境中的任务执行能力和适应性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了服务机器人在任务执行过程中通过多种在线方式获取的信息更新能力，包括几何和语义数据。虽然SLAM可以处理二维地图或三维点云的几何更新，但在线更新语义信息仍是一个未充分探索的领域。本文基于离线场景图表示的研究，提出了SPARK框架，该框架能够从环境嵌入的线索中提取语义信息并相应地更新场景图，进而用于后续的任务规划。研究结果表明，空间关系的图表示可以增强机器人系统在动态环境中执行任务的能力，并适应诸如手势等非传统空间线索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to update information acquired through various means onlineduring task execution is crucial for a general-purpose service robot. Thisinformation includes geometric and semantic data. While SLAM handles geometricupdates on 2D maps or 3D point clouds, online updates of semantic informationremain unexplored. We attribute the challenge to the online scene graphrepresentation, for its utility and scalability. Building on previous worksregarding offline scene graph representations, we study online graphrepresentations of semantic information in this work. We introduce SPARK:Spatial Perception and Robot Knowledge Integration. This framework extractssemantic information from environment-embedded cues and updates the scene graphaccordingly, which is then used for subsequent task planning. We demonstratethat graph representations of spatial relationships enhance the robot system'sability to perform tasks in dynamic environments and adapt to unconventionalspatial cues, like gestures.</description>
      <author>example@mail.com (Mimo Shirasaka, Yuya Ikeda, Tatsuya Matsushima, Yutaka Matsuo, Yusuke Iwasawa)</author>
      <guid isPermaLink="false">2506.20394v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots</title>
      <link>http://arxiv.org/abs/2506.20487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了行为基础模型（BFMs）在类人机器人全身体重控制（WBC）中的应用，探讨了其发展历程、实际应用、当前局限性、挑战和未来机遇。&lt;h4&gt;背景&lt;/h4&gt;类人机器人在复杂运动控制、人机交互和通用物理智能领域受到广泛关注，但实现高效的全身体重控制仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍BFMs在类人机器人全身体重控制中的应用，并展望其未来发展。&lt;h4&gt;方法&lt;/h4&gt;通过分析不同预训练管道，对BFMs的发展进行综述，并讨论其在实际应用中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;BFMs通过大规模预训练学习可重用的基本技能和行为先验，实现了零样本或快速适应多种下游任务。&lt;h4&gt;结论&lt;/h4&gt;BFMs是向可扩展和通用的人形智能迈进的关键方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：类人机器人在复杂运动控制、人机交互和通用物理智能方面引起了广泛关注。然而，由于复杂的动力学、欠驱动和多样化的任务需求，实现类人机器人的高效全身体重控制（WBC）仍然是一个基本挑战。尽管基于学习的控制器在复杂任务中显示出希望，但它们对新场景的依赖性在于劳动密集型和昂贵的再培训，限制了其现实世界的适用性。为了解决这些限制，行为基础模型（BFMs）作为一种新的范例已经出现，它利用大规模预训练来学习可重用的基本技能和行为先验，使得能够零样本或快速适应广泛的后台任务。在本文中，我们提出对BFMs用于类人机器人WBC的全面概述，追溯其在不同预训练管道中的发展。此外，我们讨论了现实世界的应用、当前限制、紧迫挑战和未来机遇，将BFMs定位为向可扩展和通用的人形智能迈进的关键方法。最后，我们提供了一个精心策划的长期列表的BFM论文和项目，以促进后续研究，该列表可在https://github.com/yuanmingqi/awesome-bfm-papers上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots are drawing significant attention as versatile platforms forcomplex motor control, human-robot interaction, and general-purpose physicalintelligence. However, achieving efficient whole-body control (WBC) inhumanoids remains a fundamental challenge due to sophisticated dynamics,underactuation, and diverse task requirements. While learning-based controllershave shown promise for complex tasks, their reliance on labor-intensive andcostly retraining for new scenarios limits real-world applicability. To addressthese limitations, behavior(al) foundation models (BFMs) have emerged as a newparadigm that leverages large-scale pretraining to learn reusable primitiveskills and behavioral priors, enabling zero-shot or rapid adaptation to a widerange of downstream tasks. In this paper, we present a comprehensive overviewof BFMs for humanoid WBC, tracing their development across diverse pre-trainingpipelines. Furthermore, we discuss real-world applications, currentlimitations, urgent challenges, and future opportunities, positioning BFMs as akey approach toward scalable and general-purpose humanoid intelligence.Finally, we provide a curated and long-term list of BFM papers and projects tofacilitate more subsequent research, which is available athttps://github.com/yuanmingqi/awesome-bfm-papers.</description>
      <author>example@mail.com (Mingqi Yuan, Tao Yu, Wenqi Ge, Xiuyong Yao, Dapeng Li, Huijiang Wang, Jiayu Chen, Xin Jin, Bo Li, Hua Chen, Wei Zhang, Wenjun Zeng)</author>
      <guid isPermaLink="false">2506.20487v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Supergeo Design: A Scalable Framework for Geographic Marketing Experiments</title>
      <link>http://arxiv.org/abs/2506.20499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为自适应超级地理设计（ASD）的框架，用于大规模测量广告支出的增量回报率（iROAS），解决了地理实验设计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;地理实验在测量iROAS方面是金标准，但其设计具有挑战性，因为单位数量少，异质性大，且最优超级地理分区问题为NP-hard。&lt;h4&gt;目的&lt;/h4&gt;设计一种可行的框架，使超级地理设计适用于成千上万的地区。&lt;h4&gt;方法&lt;/h4&gt;ASD采用两阶段框架：首先，通过定制图神经网络学习地理嵌入并提出一个简洁的候选“超级地理”集合；其次，使用CP-SAT求解器选择一个分区，平衡基线结果和预处理的协变量，这些协变量被认为会改变治疗效果。&lt;h4&gt;主要发现&lt;/h4&gt;在轻微的社区结构假设下，ASD的目标值在全局最优解的(1+epsilon)范围内。模拟结果表明，在标准硬件上，ASD可以在几分钟内完成，保留所有媒体美元，并将iROAS偏差显著降低。&lt;h4&gt;结论&lt;/h4&gt;ASD将地理提升测试转变为媒体规划的常规、可扩展组件，同时保持了统计严谨性。&lt;h4&gt;翻译&lt;/h4&gt;Geographic experiments are a gold-standard for measuring incremental return-on ad spend (iROAS) at scale, yet their design is challenging: the unit count is small, heterogeneity is large, and the optimal Supergeo partitioning problem is NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage framework that renders Supergeo designs practical for thousands of markets. A bespoke graph-neural network first learns geo-embeddings and proposes a concise candidate set of 'supergeos'; a CP-SAT solver then selects a partition that balances both baseline outcomes and pre-treatment covariates believed to modify the treatment effect. We prove that ASD's objective value is within (1+epsilon) of the global optimum under mild community-structure assumptions. In simulations with up to 1,000 Designated Market Areas ASD completes in minutes on standard hardware, retains every media dollar, and cuts iROAS bias substantially relative to existing methods. ASD therefore turns geo-lift testing into a routine, scalable component of media planning while preserving statistical rigour.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geographic experiments are a gold-standard for measuring incremental returnon ad spend (iROAS) at scale, yet their design is challenging: the unit countis small, heterogeneity is large, and the optimal Supergeo partitioning problemis NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage frameworkthat renders Supergeo designs practical for thousands of markets. A bespokegraph-neural network first learns geo-embeddings and proposes a concisecandidate set of 'supergeos'; a CP-SAT solver then selects a partition thatbalances both baseline outcomes and pre-treatment covariates believed to modifythe treatment effect. We prove that ASD's objective value is within (1+epsilon)of the global optimum under mild community-structure assumptions. Insimulations with up to 1,000 Designated Market Areas ASD completes in minuteson standard hardware, retains every media dollar, and cuts iROAS biassubstantively relative to existing methods. ASD therefore turns geo-lifttesting into a routine, scalable component of media planning while preservingstatistical rigour.</description>
      <author>example@mail.com (Charles Shaw)</author>
      <guid isPermaLink="false">2506.20499v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2506.20324v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Permutation Equivariant Neural Graph CDEs，这是一种高效的图神经网络模型，在模拟动态系统和真实世界任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;动态图因为节点特征和网络结构的演变而展现出复杂的时序动力学。&lt;h4&gt;目的&lt;/h4&gt;将Graph Neural CDEs投影到置换等变函数空间，以减少模型参数数量，同时保持其表示能力，从而提高训练效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入Permutation Equivariant Neural Graph CDEs，并通过对模拟动态系统和真实世界任务的实验来验证其优势。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在插值和外推场景中均表现出改进的性能。&lt;h4&gt;结论&lt;/h4&gt;Permutation Equivariant Neural Graph CDEs是一种高效且有效的图神经网络模型，在处理动态图时具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic graphs exhibit complex temporal dynamics due to the interplay between evolving node features and changing network structures. Recently, Graph Neural Controlled Differential Equations (Graph Neural CDEs) successfully adapted Neural CDEs from paths on Euclidean domains to paths on graph domains. Building on this foundation, we introduce Permutation Equivariant Neural Graph CDEs, which project Graph Neural CDEs onto permutation equivariant function spaces. This significantly reduces the model's parameter count without compromising representational power, resulting in more efficient training and improved generalisation. We empirically demonstrate the advantages of our approach through experiments on simulated dynamical systems and real-world tasks, showing improved performance in both interpolation and extrapolation scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs exhibit complex temporal dynamics due to the interplay betweenevolving node features and changing network structures. Recently, Graph NeuralControlled Differential Equations (Graph Neural CDEs) successfully adaptedNeural CDEs from paths on Euclidean domains to paths on graph domains. Buildingon this foundation, we introduce Permutation Equivariant Neural Graph CDEs,which project Graph Neural CDEs onto permutation equivariant function spaces.This significantly reduces the model's parameter count without compromisingrepresentational power, resulting in more efficient training and improvedgeneralisation. We empirically demonstrate the advantages of our approachthrough experiments on simulated dynamical systems and real-world tasks,showing improved performance in both interpolation and extrapolation scenarios.</description>
      <author>example@mail.com (Torben Berndt, Benjamin Walker, Tiexin Qin, Jan Stühmer, Andrey Kormilitzin)</author>
      <guid isPermaLink="false">2506.20324v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Counterfactual Influence as a Distributional Quantity</title>
      <link>http://arxiv.org/abs/2506.20481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop on The Impact of Memorization on Trustworthy Foundation  Models (MemFM) @ ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习模型的记忆化问题，发现仅通过自我影响来衡量记忆化会严重低估实际风险，并提出全影响分布更能捕捉记忆化的复杂交互。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型存在记忆化问题，可能导致隐私泄露和泛化能力下降。&lt;h4&gt;目的&lt;/h4&gt;研究记忆化问题，并探索更全面的衡量方法。&lt;h4&gt;方法&lt;/h4&gt;将反事实影响视为分布量，考虑所有训练样本对样本记忆化的影响，并分析其对语言模型和图像分类的影响。&lt;h4&gt;主要发现&lt;/h4&gt;仅考虑自我影响会低估风险，存在（近）重复样本会降低自我影响，但这些样本可能被提取。&lt;h4&gt;结论&lt;/h4&gt;记忆化源于训练数据之间的复杂交互，全影响分布比自我影响更能全面地捕捉记忆化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习模型因记忆化样本而闻名，这引发了隐私和泛化方面的担忧。反事实自我影响是衡量记忆化的流行指标，量化了模型的预测随样本是否包含在训练数据集中而变化的情况。然而，最近的研究表明，记忆化受到自我影响以外的因素的影响，特别是其他训练样本，尤其是（近）重复样本，有重大影响。在这里，我们将记忆化研究为分布量，将反事实影响作为分布量，考虑所有训练样本如何影响样本的记忆化。对于一个小型语言模型，我们计算了训练样本对彼此的完整影响分布，并分析了其属性。我们发现，仅通过自我影响来看会严重低估与记忆化相关的实际风险：存在（近）重复样本会严重降低自我影响，而我们认为这些样本是（近）可提取的。我们在图像分类中也观察到类似的模式，即简单地查看影响分布揭示了CIFAR-10中存在近重复样本。我们的发现强调，记忆化源于训练数据之间的复杂交互，比单独的自我影响更能被全影响分布所捕捉。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models are known to memorize samples from their trainingdata, raising concerns around privacy and generalization. Counterfactualself-influence is a popular metric to study memorization, quantifying how themodel's prediction for a sample changes depending on the sample's inclusion inthe training dataset. However, recent work has shown memorization to beaffected by factors beyond self-influence, with other training samples, inparticular (near-)duplicates, having a large impact. We here study memorizationtreating counterfactual influence as a distributional quantity, taking intoaccount how all training samples influence how a sample is memorized. For asmall language model, we compute the full influence distribution of trainingsamples on each other and analyze its properties. We find that solely lookingat self-influence can severely underestimate tangible risks associated withmemorization: the presence of (near-)duplicates seriously reducesself-influence, while we find these samples to be (near-)extractable. Weobserve similar patterns for image classification, where simply looking at theinfluence distributions reveals the presence of near-duplicates in CIFAR-10.Our findings highlight that memorization stems from complex interactions acrosstraining data and is better captured by the full influence distribution than byself-influence alone.</description>
      <author>example@mail.com (Matthieu Meeus, Igor Shilov, Georgios Kaissis, Yves-Alexandre de Montjoye)</author>
      <guid isPermaLink="false">2506.20481v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations</title>
      <link>http://arxiv.org/abs/2506.20362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  LaplaceGNN is a novel graph learning framework that employs a  bootstrapped teacher-student architecture. Its precomputed spectral  augmentations and adversarial training enable robust performance,  outperforming SOTA methods while scaling linearly&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LaplaceGNN，这是一种新的自监督图学习框架，通过利用频谱引导技术避免负采样需求，有效地捕捉丰富的结构表示，同时提供了一种简单、高效的图神经网络自监督方法。&lt;h4&gt;背景&lt;/h4&gt;现有图学习方法依赖负采样或手工增强，限制了模型的性能和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需负采样且效率更高的自监督图学习框架。&lt;h4&gt;方法&lt;/h4&gt;LaplaceGNN通过将基于拉普拉斯的信号整合到学习过程中，使用频谱增强技术进行预计算，并结合对抗性引导训练方案以增强特征学习和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;LaplaceGNN在多个基准数据集上实现了比最先进的自监督图学习方法更优的性能。&lt;h4&gt;结论&lt;/h4&gt;LaplaceGNN为高效学习可表达图表示提供了一个有希望的方向，并提供了一种简单、高效的图神经网络自监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LaplaceGNN, a novel self-supervised graph learning framework thatbypasses the need for negative sampling by leveraging spectral bootstrappingtechniques. Our method integrates Laplacian-based signals into the learningprocess, allowing the model to effectively capture rich structuralrepresentations without relying on contrastive objectives or handcraftedaugmentations. By focusing on positive alignment, LaplaceGNN achieves linearscaling while offering a simpler, more efficient, self-supervised alternativefor graph neural networks, applicable across diverse domains. Our contributionsare twofold: we precompute spectral augmentations through max-mincentrality-guided optimization, enabling rich structural supervision withoutrelying on handcrafted augmentations, then we integrate an adversarialbootstrapped training scheme that further strengthens feature learning androbustness. Our extensive experiments on different benchmark datasets show thatLaplaceGNN achieves superior performance compared to state-of-the-artself-supervised graph methods, offering a promising direction for efficientlylearning expressive graph representations.</description>
      <author>example@mail.com (Lorenzo Bini, Stephane Marchand-Maillet)</author>
      <guid isPermaLink="false">2506.20362v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management</title>
      <link>http://arxiv.org/abs/2506.20388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型视觉基础模型（LVFM）的高分辨率冠层高度图（CHM）生成新模型，用于准确、经济地监测人工林地上生物量（AGB），支持当地生计和碳汇项目。&lt;h4&gt;背景&lt;/h4&gt;精确、经济地监测人工林地上生物量对于支持当地生计和碳汇项目（如中国的CCER项目）至关重要。高分辨率冠层高度图对于此目的至关重要，但基于激光雷达的标准方法成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模型，使用大型视觉基础模型（LVFM）生成高分辨率冠层高度图，以准确、经济地监测人工林地上生物量。&lt;h4&gt;方法&lt;/h4&gt;该模型集成了特征提取器、一个自监督特征增强模块以保留空间细节，以及一个高度估算器。使用1米分辨率的Google Earth图像在北京房山区进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在房山区测试中优于现有方法，包括传统的卷积神经网络（CNN）。它达到了0.09米的平均绝对误差、0.24米的均方根误差和0.78的相关性。生成的CHM实现了超过90%的个体树检测成功率，在AGB估算中具有高精度，并有效地跟踪了人工林的生长，证明了其在非训练区域中的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法为评估人工林和天然林中的碳汇提供了有希望且可扩展的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)is crucial for supporting local livelihoods and carbon sequestrationinitiatives like the China Certified Emission Reduction (CCER) program.High-resolution canopy height maps (CHMs) are essential for this, but standardlidar-based methods are expensive. While deep learning with RGB imagery offersan alternative, accurately extracting canopy height features remainschallenging. To address this, we developed a novel model for high-resolutionCHM generation using a Large Vision Foundation Model (LVFM). Our modelintegrates a feature extractor, a self-supervised feature enhancement module topreserve spatial details, and a height estimator. Tested in Beijing's FangshanDistrict using 1-meter Google Earth imagery, our model outperformed existingmethods, including conventional CNNs. It achieved a mean absolute error of 0.09m, a root mean square error of 0.24 m, and a correlation of 0.78 againstlidar-based CHMs. The resulting CHMs enabled over 90% success in individualtree detection, high accuracy in AGB estimation, and effective tracking ofplantation growth, demonstrating strong generalization to non-training areas.This approach presents a promising, scalable tool for evaluating carbonsequestration in both plantations and natural forests.</description>
      <author>example@mail.com (Shen Tan, Xin Zhang, Liangxiu Han, Huaguo Huang, Han Wang)</author>
      <guid isPermaLink="false">2506.20388v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Forensic Study of Paintings Through the Comparison of Fabrics</title>
      <link>http://arxiv.org/abs/2506.20272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的艺术作品画布织物研究方法，用于认证、归因和保护。&lt;h4&gt;背景&lt;/h4&gt;传统的画布织物研究方法依赖于线密度图匹配，但当画布不是来自连续的卷轴位置时，这种方法无法应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖线密度图，通过深度学习评估织物相似性的自动工具。&lt;h4&gt;方法&lt;/h4&gt;设计并训练了一种Siamese深度学习模型，通过利用扫描学习到的特征表示来比较图像对。此外，提出了一种相似度估计方法，通过聚合多个布样对的预测来提供稳健的相似度评分。&lt;h4&gt;主要发现&lt;/h4&gt;该方法应用于普拉多国家博物馆的画布，证实了即使是线密度相似的平纹画布，也可以有效地进行比较。&lt;h4&gt;结论&lt;/h4&gt;该方法可行且准确，为名作的分析开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;The study of canvas fabrics in works of art is a crucial tool for authentication, attribution and conservation. Traditional methods are based on thread density map matching, which cannot be applied when canvases do not come from contiguous positions on a roll. This paper presents a novel approach based on deep learning to assess the similarity of textiles. We introduce an automatic tool that evaluates the similarity between canvases without relying on thread density maps. A Siamese deep learning model is designed and trained to compare pairs of images by exploiting the feature representations learned from the scans. In addition, a similarity estimation method is proposed, aggregating predictions from multiple pairs of cloth samples to provide a robust similarity score. Our approach is applied to canvases from the Museo Nacional del Prado, corroborating the hypothesis that plain weave canvases, widely used in painting, can be effectively compared even when their thread densities are similar. The results demonstrate the feasibility and accuracy of the proposed method, opening new avenues for the analysis of masterpieces.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of canvas fabrics in works of art is a crucial tool forauthentication, attribution and conservation. Traditional methods are based onthread density map matching, which cannot be applied when canvases do not comefrom contiguous positions on a roll. This paper presents a novel approach basedon deep learning to assess the similarity of textiles. We introduce anautomatic tool that evaluates the similarity between canvases without relyingon thread density maps. A Siamese deep learning model is designed and trainedto compare pairs of images by exploiting the feature representations learnedfrom the scans. In addition, a similarity estimation method is proposed,aggregating predictions from multiple pairs of cloth samples to provide arobust similarity score. Our approach is applied to canvases from the MuseoNacional del Prado, corroborating the hypothesis that plain weave canvases,widely used in painting, can be effectively compared even when their threaddensities are similar. The results demonstrate the feasibility and accuracy ofthe proposed method, opening new avenues for the analysis of masterpieces.</description>
      <author>example@mail.com (Juan José Murillo-Fuentes, Pablo M. Olmos, Laura Alba-Carcelén)</author>
      <guid isPermaLink="false">2506.20272v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis</title>
      <link>http://arxiv.org/abs/2506.20380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TESSERA的新型遥感基础模型（RSFM），利用自监督学习生成全球、稳健的10米分辨率表征，应用于地球观测、气候模型、碳核算以及 conservation and sustainable land use 策略。&lt;h4&gt;背景&lt;/h4&gt;卫星遥感（RS）在地球观测（EO）应用中发挥着重要作用，如气候建模、碳核算和可持续土地使用策略。&lt;h4&gt;目的&lt;/h4&gt;提出TESSERA模型，以实现全球范围内从像素级卫星时间序列数据生成高分辨率表征。&lt;h4&gt;方法&lt;/h4&gt;TESSERA使用两个并行的Transformer编码器分别处理Sentinel-1 SAR极化数据和Sentinel-2 MSI数据（10个光谱波段），然后通过多层感知器（MLP）融合信息，生成全球表征图。&lt;h4&gt;主要发现&lt;/h4&gt;TESSERA在五个不同任务中的性能优于传统的遥感基线模型和领先的地理空间基础模型，并建立了新的性能基准。&lt;h4&gt;结论&lt;/h4&gt;TESSERA通过开源方法实现了高性能、高分辨率表征的普及，为地球观测和地理空间数据应用提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Satellite remote sensing (RS) enables a wide array of downstream Earthobservation (EO) applications, including climate modeling, carbon accounting, and strategies for conservation and sustainable land use. We present TESSERA, a novel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning (SSL) to generate global, robust representations at 10m scale from pixel-level satellite time series data. TESSERA combines information from only optical and SAR data streams using two parallel Transformer-based encoders: one dedicated to Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected spectral bands) to create representations that are then fused using a multilayer perceptron (MLP), resulting in a global representation map covering the years 2017 to 2024. Our precomputed representations set a new state-of-the-art performance benchmark and our open-source approach democratizes access to high-performance, high-resolution representations. We benchmark the performance of TESSERA in five diverse tasks, comparing our work with state-of-the-art task-specific models and other foundation models. Our results show that TESSERA outperforms both traditional RS baselines and the leading geospatial foundation models in these diverse downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite remote sensing (RS) enables a wide array of downstream Earthobservation (EO) applications, including climate modeling, carbon accounting,and strategies for conservation and sustainable land use. We present TESSERA, anovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning(SSL) to generate global, robust representations at 10m scale from pixel-levelsatellite time series data. TESSERA combines information from only optical andSAR data streams using two parallel Transformer-based encoders: one dedicatedto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selectedspectral bands) to create representations that are then fused using amultilayer perceptron (MLP), resulting in a global representation map coveringthe years 2017 to 2024. Our precomputed representations set a newstate-of-the-art performance benchmark and our open-source approachdemocratizes access to high-performance, high-resolution representations. Webenchmark the performance of TESSERA in five diverse tasks, comparing our workwith state-of-the-art task-specific models and other foundation models. Ourresults show that TESSERA outperforms both traditional RS baselines and theleading geospatial foundation models in these diverse downstream tasks.</description>
      <author>example@mail.com (Zhengpeng Feng, Sadiq Jaffer, Jovana Knezevic, Silja Sormunen, Robin Young, Madeline Lisaius, Markus Immitzer, James Ball, Clement Atzberger, David A. Coomes, Anil Madhavapeddy, Andrew Blake, Srinivasan Keshav)</author>
      <guid isPermaLink="false">2506.20380v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features</title>
      <link>http://arxiv.org/abs/2506.20255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的手写识别方法，该方法结合了栅格化复杂符号和笔迹轨迹的互补线索，并引入了一个端到端网络，在共享潜在空间中对离线图像和在线笔迹数据进行早期融合。&lt;h4&gt;背景&lt;/h4&gt;目前大多数手写识别系统只利用单一模态的数据，而忽略了其他可能有助于提高识别准确性的线索。&lt;h4&gt;目的&lt;/h4&gt;提高手写识别的准确性和稳定性，减少对特定书写者的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一种端到端网络，该网络包括一个将灰度图像转换为固定长度视觉标记的补丁编码器，以及一个轻量级的Transformer，用于嵌入$(x, y, ext{pen})$序列。可学习的潜在查询共同关注这两个标记流，生成增强的笔迹嵌入，这些嵌入在跨熵损失目标下进行池化和解码。&lt;h4&gt;主要发现&lt;/h4&gt;在IAMOn-DB和VNOn-DB数据集上的实验表明，该方法达到了最先进的准确率，比之前的最佳方法提高了最多1%。此外，该方法在ISI-Air数据集上也进行了手势识别的适应性调整。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在手写识别任务中取得了显著的性能提升，证明了结合多种模态数据的重要性。&lt;h4&gt;翻译&lt;/h4&gt;We posit that handwriting recognition benefits from complementary cues carried by the rasterized complex glyph and the pen's trajectory, yet most systems exploit only one modality. We introduce an end-to-end network that performs early fusion of offline images and online stroke data within a shared latent space. A patch encoder converts the grayscale crop into fixed-length visual tokens, while a lightweight transformer embeds the $(x, y, ext{pen})$ sequence. Learnable latent queries attend jointly to both token streams, yielding context-enhanced stroke embeddings that are pooled and decoded under a cross-entropy loss objective. Because integration occurs before any high-level classification, temporal cues reinforce each other during representation learning, producing stronger writer independence. Comprehensive experiments on IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art accuracy, exceeding previous bests by up to 1%. Our study also shows adaptation of this pipeline with gesturification on the ISI-Air dataset. Our code can be found here.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We posit that handwriting recognition benefits from complementary cuescarried by the rasterized complex glyph and the pen's trajectory, yet mostsystems exploit only one modality. We introduce an end-to-end network thatperforms early fusion of offline images and online stroke data within a sharedlatent space. A patch encoder converts the grayscale crop into fixed-lengthvisual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$sequence. Learnable latent queries attend jointly to both token streams,yielding context-enhanced stroke embeddings that are pooled and decoded under across-entropy loss objective. Because integration occurs before any high-levelclassification, temporal cues reinforce each other during representationlearning, producing stronger writer independence. Comprehensive experiments onIAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-artaccuracy, exceeding previous bests by up to 1\%. Our study also showsadaptation of this pipeline with gesturification on the ISI-Air dataset. Ourcode can be found here.</description>
      <author>example@mail.com (Ayush Lodh, Ritabrata Chakraborty, Shivakumara Palaiahnakote, Umapada Pal)</author>
      <guid isPermaLink="false">2506.20255v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.19269v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机化的环境中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;AnchorDP3框架的提出是为了解决在高度随机化环境中进行双臂机器人操作时遇到的挑战。&lt;h4&gt;目的&lt;/h4&gt;目的是提高双臂机器人在高度随机化环境中的操作性能。&lt;h4&gt;方法&lt;/h4&gt;AnchorDP3集成了三个关键创新：(1) 使用渲染的真实标签进行模拟器监督语义分割，以在点云中明确分割任务关键对象，提供强烈的先验能力；(2) 任务条件特征编码器，轻量级模块处理每个任务的增强点云，通过共享的基于扩散的动作专家实现高效的多任务学习；(3) 基于能力的锚点关键姿态扩散，带有完整状态监督，用稀疏、几何上有意义的动作锚点（如预抓取姿态、直接锚定到能力的抓取姿态）替换密集轨迹预测，大大简化了预测空间；动作专家被迫同时预测机器人关节角度和末端执行器的位置，这利用了几何一致性来加速收敛并提高准确性。&lt;h4&gt;主要发现&lt;/h4&gt;AnchorDP3在RoboTwin基准测试中实现了98.7%的平均成功率，测试包括极端随机化的对象、杂乱、桌面高度、照明和背景下的各种任务。&lt;h4&gt;结论&lt;/h4&gt;当与RoboTwin的真实到模拟流程集成时，此框架有可能仅从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除人类示范来学习操作技能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机化的环境中实现了最先进的性能。AnchorDP3集成了三个关键创新：1) 使用渲染的真实标签进行模拟器监督语义分割，在点云中明确分割任务关键对象，提供强烈的先验能力；2) 任务条件特征编码器，轻量级模块处理每个任务的增强点云，通过共享的基于扩散的动作专家实现高效的多任务学习；3) 基于能力的锚点关键姿态扩散，带有完整状态监督，用稀疏、几何上有意义的动作锚点（如预抓取姿态、直接锚定到能力的抓取姿态）替换密集轨迹预测，大大简化了预测空间；动作专家被迫同时预测机器人关节角度和末端执行器的位置，这利用了几何一致性来加速收敛并提高准确性。在大型、程序生成的模拟数据上训练的AnchorDP3在RoboTwin基准测试中实现了98.7%的平均成功率，测试包括极端随机化的对象、杂乱、桌面高度、照明和背景下的各种任务。当与RoboTwin的真实到模拟流程集成时，此框架有可能仅从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除人类示范来学习操作技能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present AnchorDP3, a diffusion policy framework for dual-arm roboticmanipulation that achieves state-of-the-art performance in highly randomizedenvironments. AnchorDP3 integrates three key innovations: (1)Simulator-Supervised Semantic Segmentation, using rendered ground truth toexplicitly segment task-critical objects within the point cloud, which providesstrong affordance priors; (2) Task-Conditioned Feature Encoders, lightweightmodules processing augmented point clouds per task, enabling efficientmulti-task learning through a shared diffusion-based action expert; (3)Affordance-Anchored Keypose Diffusion with Full State Supervision, replacingdense trajectory prediction with sparse, geometrically meaningful actionanchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored toaffordances, drastically simplifying the prediction space; the action expert isforced to predict both robot joint angles and end-effector posessimultaneously, which exploits geometric consistency to accelerate convergenceand boost accuracy. Trained on large-scale, procedurally generated simulationdata, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmarkacross diverse tasks under extreme randomization of objects, clutter, tableheight, lighting, and backgrounds. This framework, when integrated with theRoboTwin real-to-sim pipeline, has the potential to enable fully autonomousgeneration of deployable visuomotor policies from only scene and instruction,totally eliminating human demonstrations from learning manipulation skills.</description>
      <author>example@mail.com (Ziyan Zhao, Ke Fan, He-Yang Xu, Ning Qiao, Bo Peng, Wenlong Gao, Dongjiang Li, Hui Shen)</author>
      <guid isPermaLink="false">2506.19269v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>GNN's Uncertainty Quantification using Self-Distillation</title>
      <link>http://arxiv.org/abs/2506.20046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper has been accepted in the International Conference on AI in  Healthcare (AIiH) 2025 and will appear in the conference proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于知识蒸馏的新方法，用于更高效、更精确地量化图神经网络（GNN）的预测不确定性。&lt;h4&gt;背景&lt;/h4&gt;GNN在医疗领域表现出色，但其预测不确定性的量化一直是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种更高效且精确的方法来量化GNN的预测不确定性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自我蒸馏的方法，其中相同的网络同时作为教师和学生模型，避免了独立训练多个网络的需要。同时，开发了一个不确定性度量，通过为每个GNN分类器分配不同的权重来捕捉网络的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法可以有效地捕捉模型的预测不确定性，同时性能与MC Dropout和集成方法相似。&lt;h4&gt;结论&lt;/h4&gt;该方法为量化GNN的预测不确定性提供了一种高效且精确的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have shown remarkable performance in the healthcare domain. However, what remained challenging is quantifying the predictive uncertainty of GNNs, which is an important aspect of trustworthiness in clinical settings. While Bayesian and ensemble methods can be used to quantify uncertainty, they are computationally expensive. Additionally, the disagreement metric used by ensemble methods to compute uncertainty cannot capture the diversity of models in an ensemble network. In this paper, we propose a novel method, based on knowledge distillation, to quantify GNNs' uncertainty more efficiently and with higher precision. We apply self-distillation, where the same network serves as both the teacher and student models, thereby avoiding the need to train several networks independently. To ensure the impact of self-distillation, we develop an uncertainty metric that captures the diverse nature of the network by assigning different weights to each GNN classifier. We experimentally evaluate the precision, performance, and ability of our approach in distinguishing out-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The evaluation results demonstrate that the proposed method can effectively capture the predictive uncertainty of the model while having performance similar to that of the MC Dropout and ensemble methods. The code is publicly available at https://github.com/tailabTMU/UQ_GNN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown remarkable performance in thehealthcare domain. However, what remained challenging is quantifying thepredictive uncertainty of GNNs, which is an important aspect of trustworthinessin clinical settings. While Bayesian and ensemble methods can be used toquantify uncertainty, they are computationally expensive. Additionally, thedisagreement metric used by ensemble methods to compute uncertainty cannotcapture the diversity of models in an ensemble network. In this paper, wepropose a novel method, based on knowledge distillation, to quantify GNNs'uncertainty more efficiently and with higher precision. We applyself-distillation, where the same network serves as both the teacher andstudent models, thereby avoiding the need to train several networksindependently. To ensure the impact of self-distillation, we develop anuncertainty metric that captures the diverse nature of the network by assigningdifferent weights to each GNN classifier. We experimentally evaluate theprecision, performance, and ability of our approach in distinguishingout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. Theevaluation results demonstrate that the proposed method can effectively capturethe predictive uncertainty of the model while having performance similar tothat of the MC Dropout and ensemble methods. The code is publicly available athttps://github.com/tailabTMU/UQ_GNN.</description>
      <author>example@mail.com (Hirad Daneshvar, Reza Samavi)</author>
      <guid isPermaLink="false">2506.20046v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A foundation model with multi-variate parallel attention to generate neuronal activity</title>
      <link>http://arxiv.org/abs/2506.20354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG  dataset is available at  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为多变量并行注意力（MVPA）的新型自注意力机制，用于处理具有不同通道配置的多变量时间序列数据，并构建了MVPFormer，这是一种用于预测人类电生理学信号演变的生成性基础模型。同时，发布了SWEC iEEG数据集，这是一个包含近10,000小时记录的最大公开iEEG数据集。&lt;h4&gt;背景&lt;/h4&gt;学习具有不同通道配置的多变量时间序列数据是深度神经网络的一个基本挑战，特别是在iEEG等临床领域。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够灵活、通用和高效地建模具有不同通道数和配置的时间序列数据的机制，并构建一个能够预测iEEG信号演变的模型。&lt;h4&gt;方法&lt;/h4&gt;引入了MVPA机制，并使用它来构建MVPFormer模型，同时发布了SWEC iEEG数据集。&lt;h4&gt;主要发现&lt;/h4&gt;MVPFormer在iEEG信号预测和癫痫检测方面表现出专家级性能，并在SWEC、MAYO和FNUSA数据集上优于最先进的Transformer基线模型。MVPA在标准时间序列预测和分类任务上也表现出色。&lt;h4&gt;结论&lt;/h4&gt;MVPA是一种适用于异构时间序列的通用注意力机制，MVPFormer是首个开源、公开权重和公开数据的iEEG基础模型，具有最先进的临床性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从具有异构通道配置的多变量时间序列中学习仍然是深度神经网络（DNNs）的一个基本挑战，特别是在颅内电图（iEEG）等临床领域，不同受试者的通道设置差异很大。在这项工作中，我们引入了多变量并行注意力（MVPA），这是一种新颖的自注意力机制，它将内容、时间和空间注意力解耦，使得能够灵活、通用和高效地建模具有不同通道数和配置的时间序列数据。我们使用MVPA构建了MVPFormer，这是一种针对人类电生理学进行训练的生成性基础模型，用于预测不同受试者的iEEG信号演变。为了支持社区的努力，我们发布了SWEC iEEG数据集，这是迄今为止最大的公开iEEG数据集，包含来自异构临床来源的近10,000小时记录。MVPFormer利用MVPA实现了跨受试者的强大泛化能力，在癫痫检测方面表现出专家级性能，并在我们的SWEC、MAYO和FNUSA数据集上优于最先进的Transformer基线模型。我们还在标准时间序列预测和分类任务上进一步验证了MVPA，其性能与现有基于注意力的模型相当或更好。我们的贡献将MVPA确立为适用于异构时间序列的通用注意力机制，并将MVPFormer确立为首个开源、公开权重和公开数据的iEEG基础模型，具有最先进的临床性能。代码可在https://github.com/IBM/multi-variate-parallel-transformer上获得。SWEC iEEG数据集可在https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from multi-variate time-series with heterogeneous channelconfigurations remains a fundamental challenge for deep neural networks (DNNs),particularly in clinical domains such as intracranial electroencephalography(iEEG), where channel setups vary widely across subjects. In this work, weintroduce multi-variate parallel attention (MVPA), a novel self-attentionmechanism that disentangles content, temporal, and spatial attention, enablingflexible, generalizable, and efficient modeling of time-series data withvarying channel counts and configurations. We use MVPA to build MVPFormer, agenerative foundation model for human electrophysiology, trained to predict theevolution of iEEG signals across diverse subjects. To support this and futureeffort by the community, we release the SWEC iEEG dataset, the largest publiclyavailable iEEG dataset to date, comprising nearly 10,000 hours of recordingsfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve stronggeneralization across subjects, demonstrating expert-level performance inseizure detection and outperforming state-of-the-art Transformer baselines onour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standardtime-series forecasting and classification tasks, where it matches or exceedsexisting attention-based models. Together, our contributions establish MVPA asa general-purpose attention mechanism for heterogeneous time-series andMVPFormer as the first open-source, open-weights, and open-data iEEG foundationmodel with state-of-the-art clinical performance. The code is available athttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEGdataset is available athttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.</description>
      <author>example@mail.com (Francesco Carzaniga, Michael Hersche, Abu Sebastian, Kaspar Schindler, Abbas Rahimi)</author>
      <guid isPermaLink="false">2506.20354v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning</title>
      <link>http://arxiv.org/abs/2506.20031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的理论公式和计算框架，用于生成具有软变化代理-任务兼容性的多样化行动方案（COA）池。&lt;h4&gt;背景&lt;/h4&gt;在灾害响应、搜救和军事任务中，涉及多个代理的操作需要自动化流程来支持行动方案（COA）的规划。环境变化（如雨、雪、封锁等）可能影响COA的预期性能，因此需要一个多样化的COA池，以适应不同的任务分配。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一个能够处理代理能力变化（包括人类机组人员和/或自主系统）的COA规划过程，并量化COA池的多样性。&lt;h4&gt;方法&lt;/h4&gt;本文采用图抽象来表示任务空间和COA池本身，以量化其多样性。将COA规划问题表述为集中式多机器人任务分配问题，使用遗传算法对每个代理的任务分配进行（不考虑顺序）分配，以在COA池内联合最大化多样性和代理-任务映射的整体兼容性。然后，使用策略梯度方法训练图神经网络，以在每个COA中执行单代理任务排序，从而最大化适应任务特征的完成率。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟环境中的COA生成过程测试表明，与随机游走基线相比，具有显著性能提升，任务排序的优化差距较小，规划20个COA（针对5个代理/100个任务操作）的执行时间约为50分钟。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效生成多样化的COA池，并提高了任务分配和排序的效率，为涉及多个代理的操作提供了有效的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Operations in disaster response, search \&amp; rescue, and military missions thatinvolve multiple agents demand automated processes to support the planning ofthe courses of action (COA). Moreover, traverse-affecting changes in theenvironment (rain, snow, blockades, etc.) may impact the expected performanceof a COA, making it desirable to have a pool of COAs that are diverse in taskdistributions across agents. Further, variations in agent capabilities, whichcould be human crews and/or autonomous systems, present practical opportunitiesand computational challenges to the planning process. This paper presents a newtheoretical formulation and computational framework to generate such diversepools of COAs for operations with soft variations in agent-task compatibility.Key to the problem formulation is a graph abstraction of the task space and thepool of COAs itself to quantify its diversity. Formulating the COAs as acentralized multi-robot task allocation problem, a genetic algorithm is usedfor (order-ignoring) allocations of tasks to each agent that jointly maximizediversity within the COA pool and overall compatibility of the agent-taskmappings. A graph neural network is trained using a policy gradient approach tothen perform single agent task sequencing in each COA, which maximizescompletion rates adaptive to task features. Our tests of the COA generationprocess in a simulated environment demonstrate significant performance gainover a random walk baseline, small optimality gap in task sequencing, andexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 taskoperations.</description>
      <author>example@mail.com (Prithvi Poddar, Ehsan Tarkesh Esfahani, Karthik Dantu, Souma Chowdhury)</author>
      <guid isPermaLink="false">2506.20031v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs</title>
      <link>http://arxiv.org/abs/2506.20167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SEED的结构编码器，用于嵌入驱动的解码，旨在解决多元时间序列预测中的结构-语义建模差距。&lt;h4&gt;背景&lt;/h4&gt;多元时间序列预测需要模型同时捕捉变量间的结构依赖并泛化到不同任务，而现有的结构编码器和大型语言模型各有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出SEED模型，以解决结构编码器缺乏语义推理和任务适应能力，以及大型语言模型与原始时间序列数据不兼容的问题。&lt;h4&gt;方法&lt;/h4&gt;SEED模型包含四个阶段：一个标记感知编码器用于提取补丁，一个投影模块将补丁与语言模型嵌入对齐，一个语义重编程机制将补丁映射到任务感知原型，以及一个用于预测的冻结语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;SEED模型在多个数据集上实现了对强基线的持续改进，并通过比较研究证实了其在解决结构-语义建模差距中的作用。&lt;h4&gt;结论&lt;/h4&gt;SEED模型通过模块化架构解耦了表示学习和推理，实现了数值模式和语义推理之间的有效对齐，为统一的、可迁移的预测系统的发展提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series forecasting requires models to simultaneouslycapture variable-wise structural dependencies and generalize across diversetasks. While structural encoders are effective in modeling featureinteractions, they lack the capacity to support semantic-level reasoning ortask adaptation. Conversely, large language models (LLMs) possess stronggeneralization capabilities but remain incompatible with raw time seriesinputs. This gap limits the development of unified, transferable predictionsystems. Therefore, we introduce SEED, a structural encoder forembedding-driven decoding, which integrates four stages: a token-aware encoderfor patch extraction, a projection module that aligns patches with languagemodel embeddings, a semantic reprogramming mechanism that maps patches totask-aware prototypes, and a frozen language model for prediction. This modulararchitecture decouples representation learning from inference, enablingefficient alignment between numerical patterns and semantic reasoning.Empirical results demonstrate that the proposed method achieves consistentimprovements over strong baselines, and comparative studies on various datasetsconfirm SEED's role in addressing the structural-semantic modeling gap.</description>
      <author>example@mail.com (Fengze Li, Yue Wang, Yangle Liu, Ming Huang, Dou Hong, Jieming Ma)</author>
      <guid isPermaLink="false">2506.20167v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</title>
      <link>http://arxiv.org/abs/2506.20254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Surgical Phase Anywhere（SPA）框架，这是一个轻量级的通用手术工作流程理解框架，可以适应不同机构的环境，并通过少量标注对基础模型进行定制化。SPA通过空间自适应和扩散模型保证时间一致性，并通过动态测试时间自适应提高模型的可靠性。&lt;h4&gt;背景&lt;/h4&gt;手术流程的复杂性和多样性，由于手术室设置、机构协议和解剖结构的差异，对跨机构和跨手术流程的手术理解模型的开发提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够适应不同机构环境，并且可以通过少量标注快速定制的轻量级手术工作流程理解框架。&lt;h4&gt;方法&lt;/h4&gt;SPA框架利用少量样本的空间自适应来对齐特定机构手术场景和阶段的多模态嵌入，并通过扩散模型确保时间一致性。它还采用了动态测试时间自适应，通过利用多模态阶段预测流之间的相互一致来对模型进行自适应。&lt;h4&gt;主要发现&lt;/h4&gt;SPA框架在多机构和多手术流程的少量样本手术阶段识别上取得了最先进的性能，甚至在32个样本的标注数据下也优于全样本模型。&lt;h4&gt;结论&lt;/h4&gt;SPA框架为医院提供了快速定制阶段识别模型的能力，只需用自然语言定义阶段、标注少量图像以及提供定义阶段转换的任务图。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Surgical Phase Anywhere（SPA）的轻量级框架，用于通用的手术工作流程理解。该框架能够适应不同机构的设置，并可以通过最小程度的标注对基础模型进行定制。SPA利用少量样本的空间自适应来对齐特定机构手术场景和阶段的多模态嵌入，并通过扩散模型保证时间一致性。此外，它还采用了动态测试时间自适应，通过利用多模态阶段预测流之间的相互一致来对模型进行自适应。实验结果表明，SPA框架在少量样本手术阶段识别上达到了最先进的性能，甚至在拥有32个样本标注数据的情况下也优于全样本模型。代码可在https://github.com/CAMMA-public/SPA上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity and diversity of surgical workflows, driven by heterogeneousoperating room settings, institutional protocols, and anatomical variability,present a significant challenge in developing generalizable models forcross-institutional and cross-procedural surgical understanding. While recentsurgical foundation models pretrained on large-scale vision-language data offerpromising transferability, their zero-shot performance remains constrained bydomain shifts, limiting their utility in unseen surgical environments. Toaddress this, we introduce Surgical Phase Anywhere (SPA), a lightweightframework for versatile surgical workflow understanding that adapts foundationmodels to institutional settings with minimal annotation. SPA leveragesfew-shot spatial adaptation to align multi-modal embeddings withinstitution-specific surgical scenes and phases. It also ensures temporalconsistency through diffusion modeling, which encodes task-graph priors derivedfrom institutional procedure protocols. Finally, SPA employs dynamic test-timeadaptation, exploiting the mutual agreement between multi-modal phaseprediction streams to adapt the model to a given test video in aself-supervised manner, enhancing the reliability under test-time distributionshifts. SPA is a lightweight adaptation framework, allowing hospitals torapidly customize phase recognition models by defining phases in naturallanguage text, annotating a few images with the phase labels, and providing atask graph defining phase transitions. The experimental results show that theSPA framework achieves state-of-the-art performance in few-shot surgical phaserecognition across multiple institutions and procedures, even outperformingfull-shot models with 32-shot labeled data. Code is available athttps://github.com/CAMMA-public/SPA</description>
      <author>example@mail.com (Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, Long Bai, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy)</author>
      <guid isPermaLink="false">2506.20254v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty</title>
      <link>http://arxiv.org/abs/2506.19442v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code:  https://anonymous.4open.science/r/sampling_matters_reproducibility-BB60/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图像归因分析，通过整合梯度来强调视觉模型学习的特征表示，并提高输入的像素重要性。提出了一种基于抑制输入特征的半优化采样方法，以解决样本分布不匹配问题，并证明了其在ImageNet数据集上的有效性。&lt;h4&gt;背景&lt;/h4&gt;图像归因分析旨在强调视觉模型学习到的特征表示，梯度整合是归因分析的一个基本方法。然而，现有的方法在样本分布不匹配和加入噪声时，可能导致解释的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提高归因分析的可靠性，减少样本分布不匹配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于抑制输入特征的半优化采样方法，该方法通过模拟自然图像分布来生成样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，额外信息可能会饱和神经网络，而半优化采样方法能够有效解决样本分布不匹配问题，并在ImageNet数据集上提供了比现有方法更满意的解释。&lt;h4&gt;结论&lt;/h4&gt;抑制输入特征的半优化采样方法能够提高图像归因分析的可靠性，并有效解决样本分布不匹配问题。&lt;h4&gt;翻译&lt;/h4&gt;Image attribution analysis aims to highlight the feature representations learned by visual models so that the highlighted feature maps can reflect the pixel-wise importance of inputs. Gradient integration is a building block in the attribution analysis by integrating the gradients from multiple derived samples to highlight the semantic features relevant to inferences. Such a building block often combines with other information from visual models such as activation or attention maps to form ultimate explanations. Yet, our theoretical analysis demonstrates that the extent to the alignment of the sample distribution in gradient integration with respect to natural image distribution gives a lower bound of explanation certainty. Prior works add noise into images as samples and the noise distributions can lead to low explanation certainty. Counter-intuitively, our experiment shows that extra information can saturate neural networks. To this end, building trustworthy attribution analysis needs to settle the sample distribution misalignment problem. Instead of adding extra information into input images, we present a semi-optimal sampling approach by suppressing features from inputs. The sampled distribution by suppressing features is approximately identical to the distribution of natural images. Our extensive quantitative evaluation on large-scale dataset ImageNet affirms that our approach is effective and able to yield more satisfactory explanations against state-of-the-art baselines throughout all experimental models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5281/zenodo.8204453&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image attribution analysis seeks to highlight the feature representationslearned by visual models such that the highlighted feature maps can reflect thepixel-wise importance of inputs. Gradient integration is a building block inthe attribution analysis by integrating the gradients from multiple derivedsamples to highlight the semantic features relevant to inferences. Such abuilding block often combines with other information from visual models such asactivation or attention maps to form ultimate explanations. Yet, ourtheoretical analysis demonstrates that the extent to the alignment of thesample distribution in gradient integration with respect to natural imagedistribution gives a lower bound of explanation certainty. Prior works addnoise into images as samples and the noise distributions can lead to lowexplanation certainty. Counter-intuitively, our experiment shows that extrainformation can saturate neural networks. To this end, building trustworthyattribution analysis needs to settle the sample distribution misalignmentproblem. Instead of adding extra information into input images, we present asemi-optimal sampling approach by suppressing features from inputs. The sampledistribution by suppressing features is approximately identical to thedistribution of natural images. Our extensive quantitative evaluation on largescale dataset ImageNet affirms that our approach is effective and able to yieldmore satisfactory explanations against state-of-the-art baselines throughoutall experimental models.</description>
      <author>example@mail.com (Róisín Luo, James McDermott, Colm O'Riordan)</author>
      <guid isPermaLink="false">2506.19442v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees</title>
      <link>http://arxiv.org/abs/2506.20178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为COIN的不确定性量化框架，用于检测和减轻自动生成文本中的潜在幻觉，并提高样本保留率。&lt;h4&gt;背景&lt;/h4&gt;对基础模型的不确定性量化对于识别和减轻自动生成文本中的潜在幻觉至关重要。传统的启发式方法在关键指标如选择性预测中的假发现率（FDR）方面缺乏正式保证。&lt;h4&gt;目的&lt;/h4&gt;提高自动生成文本的不确定性量化，确保在用户指定的FDR约束下，每个问题的单个生成答案经过有效筛选。&lt;h4&gt;方法&lt;/h4&gt;COIN通过构建预测集并使用统计上有效的阈值来筛选单个生成答案。它估计校准集上的经验误差率，并应用Clopper-Pearson置信区间方法来建立真实误差率的高概率上界。&lt;h4&gt;主要发现&lt;/h4&gt;COIN在风险控制、保持可接受答案的强测试时间功率以及有限的校准数据下的预测效率方面表现出鲁棒性。此外，使用不同的上界构建和不确定性量化策略可以进一步提高COIN的性能。&lt;h4&gt;结论&lt;/h4&gt;COIN是一种灵活且适应性强的不确定性量化框架，可以有效地应用于各种文本生成任务，并提高样本保留率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a framework named COIN for uncertainty quantification in foundation models, aiming to detect and mitigate potential hallucinations in automatically generated text and enhance sample retention. The background of the paper is that uncertainty quantification for foundation models is essential for identifying and mitigating potential hallucinations in automatically generated text, while heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. The purpose of the paper is to improve the uncertainty quantification of automatically generated text, ensuring that each question's single generated answer is effectively filtered under user-specified FDR constraints. The method of COIN involves constructing prediction sets and using statistically valid thresholds to filter a single generated answer per question. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). The main findings of the paper show that COIN exhibits robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, the paper demonstrates that employing alternative upper bound constructions and UQ strategies can further boost the performance of COIN, highlighting its flexibility and adaptability to diverse application scenarios. The conclusion of the paper is that COIN is a flexible and adaptable uncertainty quantification framework that can be effectively applied to various text generation tasks and enhance sample retention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty quantification (UQ) for foundation models is essential toidentify and mitigate potential hallucinations in automatically generated text.However, heuristic UQ approaches lack formal guarantees for key metrics such asthe false discovery rate (FDR) in selective prediction. Previous work adoptsthe split conformal prediction (SCP) framework to ensure desired coverage ofadmissible answers by constructing prediction sets, but these sets oftencontain incorrect candidates, limiting their practical utility. To addressthis, we propose COIN, an uncertainty-guarding selection framework thatcalibrates statistically valid thresholds to filter a single generated answerper question under user-specified FDR constraints. COIN estimates the empiricalerror rate on a calibration set and applies confidence interval methods such asClopper-Pearson to establish a high-probability upper bound on the true errorrate (i.e., FDR). This enables the selection of the largest uncertaintythreshold that ensures FDR control on test data while significantly increasingsample retention. We demonstrate COIN's robustness in risk control, strongtest-time power in retaining admissible answers, and predictive efficiencyunder limited calibration data across both general and multimodal textgeneration tasks. Furthermore, we show that employing alternative upper boundconstructions and UQ strategies can further boost COIN's power performance,which underscores its extensibility and adaptability to diverse applicationscenarios.</description>
      <author>example@mail.com (Zhiyuan Wang, Jinhao Duan, Qingni Wang, Xiaofeng Zhu, Tianlong Chen, Xiaoshuang Shi, Kaidi Xu)</author>
      <guid isPermaLink="false">2506.20178v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition</title>
      <link>http://arxiv.org/abs/2506.20174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了在地球观测数据挖掘中，通过结合现有预训练模型来提升性能的方法。&lt;h4&gt;背景&lt;/h4&gt;目前地球观测领域大部分研究集中在开发大型模型，而复用和组合现有预训练模型的方法未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究是否可以通过结合预训练模型来提升地球观测任务（如场景分类和语义分割）的性能。&lt;h4&gt;方法&lt;/h4&gt;使用GEO-Bench基准，在覆盖不同空间分辨率、传感器模态和任务类型的11个数据集上，评估了包括Prithvi、Hiera和DOFA在内的几个突出模型。&lt;h4&gt;主要发现&lt;/h4&gt;特征级联较小的预训练模型在性能上可以与更大的模型相匹配或超过，同时需要更少的训练时间和计算资源。此外，研究还强调了知识蒸馏技术在将集成模型的优点转移到更紧凑模型中的潜力。&lt;h4&gt;结论&lt;/h4&gt;知识蒸馏技术可以作为一个将预训练模型应用于实际地球观测应用中的实用途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are rapidly transforming Earth Observation data mining byenabling generalizable and scalable solutions for key tasks such as sceneclassification and semantic segmentation. While most efforts in the geospatialdomain have focused on developing large models trained from scratch usingmassive Earth Observation datasets, an alternative strategy that remainsunderexplored is the reuse and combination of existing pretrained models. Inthis study, we investigate whether foundation models pretrained on remotesensing and general vision datasets can be effectively combined to improveperformance across a diverse set of key Earth Observation tasks. Using theGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,sensor modalities, and task types. The results show that feature-levelensembling of smaller pretrained models can match or exceed the performance ofmuch larger models, while requiring less training time and computationalresources. Moreover, the study highlights the potential of applying knowledgedistillation to transfer the strengths of ensembles into more compact models,offering a practical path for deploying foundation models in real-world EarthObservation applications.</description>
      <author>example@mail.com (Man Duc Chuc)</author>
      <guid isPermaLink="false">2506.20174v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking</title>
      <link>http://arxiv.org/abs/2506.19960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Orbformer的新型可迁移波函数模型，通过预训练在22,000个平衡和离解结构上，实现了量子化学中解决薛定谔方程的成本分摊，提高了计算效率。&lt;h4&gt;背景&lt;/h4&gt;在量子化学中，由于离解物种电子结构的多参考特性，可靠地描述键断裂是一个主要挑战。多参考方法在计算成本上存在较大问题，因为传统范式下，对于每个系统都需要重新支付全价，忽略了分子间电子结构的共性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的计算范式，通过预训练可迁移的波函数模型，利用分子间电子结构的共性，降低量子化学中键断裂描述的计算成本。&lt;h4&gt;方法&lt;/h4&gt;提出了Orbformer模型，该模型在22,000个平衡和离解结构上进行预训练，并可以在未见过的分子上进行微调，以达到与经典多参考方法相当的成本-精度比。&lt;h4&gt;主要发现&lt;/h4&gt;Orbformer在已建立的基准测试以及更具挑战性的键离解和Diels-Alder反应中，是唯一一种能够持续收敛到化学精度（1 kcal/mol）的方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作将解决薛定谔方程在许多分子上的成本分摊的想法转化为量子化学中的实用方法。&lt;h4&gt;翻译&lt;/h4&gt;可靠的键断裂描述仍然是量子化学的一个主要挑战，因为离解物种的电子结构具有多参考特性。特别是，多参考方法在计算成本上存在较大问题，在正常范式下，对于每个系统都必须重新支付全价，忽略了分子间电子结构的共性。量子蒙特卡罗与深度神经网络（深度QMC）的独特之处在于能够利用这种共性，通过预训练可迁移的波函数模型。但是，迄今为止，所有此类尝试都受到了范围的限制。在这里，我们通过Orbformer实现了这一新范式，Orbformer是一种新型的可迁移波函数模型，在22,000个平衡和离解结构上进行预训练，可以在未见过的分子上进行微调，达到与经典多参考方法相当的成本-精度比。在已建立的基准测试以及更具挑战性的键离解和Diels-Alder反应中，Orbformer是唯一一种能够持续收敛到化学精度（1 kcal/mol）的方法。这项工作将解决薛定谔方程在许多分子上的成本分摊的想法转化为量子化学中的实用方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable description of bond breaking remains a major challenge for quantumchemistry due to the multireferential character of the electronic structure indissociating species. Multireferential methods in particular suffer from largecomputational cost, which under the normal paradigm has to be paid anew foreach system at a full price, ignoring commonalities in electronic structureacross molecules. Quantum Monte Carlo with deep neural networks (deep QMC)uniquely offers to exploit such commonalities by pretraining transferablewavefunction models, but all such attempts were so far limited in scope. Here,we bring this new paradigm to fruition with Orbformer, a novel transferablewavefunction model pretrained on 22,000 equilibrium and dissociating structuresthat can be fine-tuned on unseen molecules reaching an accuracy-cost ratiorivalling classical multireferential methods. On established benchmarks as wellas more challenging bond dissociations and Diels-Alder reactions, Orbformer isthe only method that consistently converges to chemical accuracy (1 kcal/mol).This work turns the idea of amortizing the cost of solving the Schr\"odingerequation over many molecules into a practical approach in quantum chemistry.</description>
      <author>example@mail.com (Adam Foster, Zeno Schätzle, P. Bernát Szabó, Lixue Cheng, Jonas Köhler, Gino Cassella, Nicholas Gao, Jiawei Li, Frank Noé, Jan Hermann)</author>
      <guid isPermaLink="false">2506.19960v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Machine Learning Algorithms using Path Signatures</title>
      <link>http://arxiv.org/abs/2506.17634v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了随机分析与机器学习之间的接口，并研究了路径签名在可扩展机器学习管道中的应用。路径签名是路径的忠实和层次化表示，适合于建模动态变化、长期依赖和不规则采样等现实世界时间序列和图数据中的常见挑战。&lt;h4&gt;背景&lt;/h4&gt;随机分析与机器学习交叉领域快速发展，路径签名作为路径的迭代积分，提供了一种原则性和通用的特征映射，适用于序列和结构化数据。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用路径签名的表达能力，在可扩展的机器学习管道中实现。&lt;h4&gt;方法&lt;/h4&gt;本文引入了一系列模型，结合了理论稳健性和计算效率，将粗糙路径理论、概率建模、深度学习和核方法相结合。包括基于签名核的高斯过程协方差函数、Seq2Tens框架和基于图的模型等。&lt;h4&gt;主要发现&lt;/h4&gt;主要贡献包括：具有签名核协方差函数的高斯过程，用于不确定性感知的时间序列建模；Seq2Tens框架，在权重空间中采用低秩张量结构，以可扩展的方式建模长期依赖；以及基于图的模型，其中图上的预期签名诱导拟椭圆扩散过程，提供了一种表达能力强且易于处理的替代方案。&lt;h4&gt;结论&lt;/h4&gt;本文旨在提供一个方法论工具包和概念桥梁，为可扩展的基于签名的序列和结构化数据学习提供有用的参考。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了随机分析与机器学习之间的接口，路径签名——提供路径忠实、分层表示的迭代积分——为序列和结构化数据提供了一种原则性和通用的特征映射。路径签名根植于粗糙路径理论，对重新参数化不变，非常适合于建模动态变化、长期依赖和不规则采样——这些是现实世界时间序列和图数据中的常见挑战。本文探讨了如何在可扩展的机器学习管道中利用路径签名的表达能力。它介绍了一系列模型，这些模型结合了理论稳健性和计算效率，将粗糙路径理论、概率建模、深度学习和核方法相结合。主要贡献包括：具有签名核协方差函数的高斯过程，用于不确定性感知的时间序列建模；Seq2Tens框架，在权重空间中采用低秩张量结构，以可扩展的方式建模长期依赖；以及基于图的模型，其中图上的预期签名诱导拟椭圆扩散过程，提供了一种表达能力强且易于处理的替代方案。进一步的发展包括随机傅里叶签名特征，这是一种具有理论保证的可扩展核近似，以及循环稀疏频谱签名高斯过程，它结合了高斯过程、签名核和随机特征，并具有一种原则性的遗忘机制，用于具有自适应上下文长度的多 horizon 时间序列预测。我们希望本文既是一个方法论工具包，也是一个概念桥梁，并为可扩展的基于签名的序列和结构化数据学习提供有用的参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The interface between stochastic analysis and machine learning is a rapidlyevolving field, with path signatures - iterated integrals that providefaithful, hierarchical representations of paths - offering a principled anduniversal feature map for sequential and structured data. Rooted in rough paththeory, path signatures are invariant to reparameterization and well-suited formodelling evolving dynamics, long-range dependencies, and irregular sampling -common challenges in real-world time series and graph data.  This thesis investigates how to harness the expressive power of pathsignatures within scalable machine learning pipelines. It introduces a suite ofmodels that combine theoretical robustness with computational efficiency,bridging rough path theory with probabilistic modelling, deep learning, andkernel methods. Key contributions include: Gaussian processes with signaturekernel-based covariance functions for uncertainty-aware time series modelling;the Seq2Tens framework, which employs low-rank tensor structure in the weightspace for scalable deep modelling of long-range dependencies; and graph-basedmodels where expected signatures over graphs induce hypo-elliptic diffusionprocesses, offering expressive yet tractable alternatives to standard graphneural networks. Further developments include Random Fourier SignatureFeatures, a scalable kernel approximation with theoretical guarantees, andRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussianprocesses, signature kernels, and random features with a principled forgettingmechanism for multi-horizon time series forecasting with adaptive contextlength.  We hope this thesis serves as both a methodological toolkit and a conceptualbridge, and provides a useful reference for the current state of the art inscalable, signature-based learning for sequential and structured data.</description>
      <author>example@mail.com (Csaba Tóth)</author>
      <guid isPermaLink="false">2506.17634v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    </channel>
</rss>